\chapter{Fundamentos de Aprendizaje Profundo}\label{ch:fundamentos-de-aprendizaje-profundo}
%Fundamentos de Aprendizaje Profundo: Explica los conceptos básicos, incluyendo redes neuronales convolucionales.
\section{Definición de Aprendizaje Profundo}\label{sec:definicion-de-aprendizaje-profundo}
El \textbf{aprendizaje profundo} (Deep Learning) es una subcategoría del aprendizaje automático que se basa
en el uso de \textbf{redes neuronales artificiales} con muchas capas (de ahí el término \("\)profundo\("\)).
Estas redes están diseñadas para imitar el funcionamiento del cerebro humano, lo que les permite aprender
representaciones complejas de los datos de manera jerárquica. \\[2pt]

La principal diferencia entre el \textbf{aprendizaje automático tradicional} y el aprendizaje profundo es la manera en
que se manejan las características de los datos:
\begin{itemize}
    \item En los enfoques tradicionales, el ingeniero o científico de datos debe extraer manualmente las
características más importantes para entrenar al modelo (por ejemplo, bordes, formas, texturas en imágenes).
En el aprendizaje profundo, las redes neuronales son capaces de
\textbf{aprender automáticamente las representaciones de los datos} a partir de los datos crudos (por ejemplo,
imágenes, texto, sonido).
    \item Este proceso es denominado \textbf{aprendizaje de características} (feature learning), lo que reduce la
necesidad de intervención humana.
\end{itemize}

El aprendizaje profundo ha mostrado un rendimiento sobresaliente en diversas tareas, como el reconocimiento de
imágenes, el procesamiento del lenguaje natural, la conducción autónoma y el diagnóstico médico, gracias a su capacidad
para \textbf{capturar patrones complejos} en grandes volúmenes de datos.

\section{Redes Neuronales Artificiales}\label{sec:redes-neuronales-artificiales}
Las \textbf{redes neuronales artificiales} (ANN)~\cite{Handbook of measuring system design} son el corazón del
aprendizaje profundo.
Estas redes están compuestas por neuronas artificiales, que son unidades matemáticas inspiradas en las neuronas
biológicas.
Cada neurona toma varias entradas, las procesa mediante una \textbf{función de activación}, y produce una salida.
Cuando se combinan muchas de estas neuronas en capas, forman una red neuronal.

\subsection{Componentes de una Red Neuronal}\label{subsec:componentes-de-una-red-neuronal}
\begin{enumerate}
    \item \textbf{Neuronas o Unidades}:
    \begin{figure}[htp] \label{fig:neuron}
        \begin{center}
            \includegraphics[width=0.5\textwidth]{imagenes/neuron}
        \end{center}
        \caption[Neurona Artificial]{}
    \end{figure}

Cada \textbf{neurona} realiza una operación simple: recibe varias entradas, las
pondera por medio de \textbf{pesos} $w_{i}$, suma estos valores junto con un \textbf{sesgo} $b$, y aplica una función
de activación.
La salida de la neurona se expresa como:

$z =w_{1}x_{1} + w_{2}x_{2} + \dots + w_{n}x_{n} + b_{z} = w_{1}x_{1} + w_{2}x_{2} + \dots + w_{n}x_{n} + b$

Luego, el valor $z$ pasa por una función de activación, que introduce la no linealidad en el sistema, permitiendo que
las redes neuronales modelen relaciones complejas.
    \item \textbf{Capas de la Red}:
    \begin{figure}[htp] \label{fig:capas-red-neuronal}
        \begin{center}
            \includegraphics[width=0.5\textwidth]{imagenes/capas_red_neuronal}
        \end{center}
        \caption[Capas de la Red Neuonial Artificial]{}
    \end{figure}
\begin{itemize}
    \item \textbf{Capa de entrada}: Es la primera capa de la red neuronal, que recibe los datos crudos (por ejemplo,
píxeles de una imagen).
    \item \textbf{Capas ocultas}: Estas capas intermedias entre la entrada y la salida aprenden representaciones
abstractas de los datos.
En una red profunda, hay múltiples capas ocultas, lo que permite la \textbf{transformación jerárquica} de los datos.
    \item \textbf{Capa de salida}: Produce la predicción final, que puede ser una clase (en problemas de clasificación)
o un valor numérico (en problemas de regresión).
\end{itemize}
    \item \textbf{Pesos y Bias}: Los \textbf{pesos} son parámetros ajustables que determinan la importancia de cada
entrada en la neurona.
El \textbf{bias} es otro parámetro que se suma al valor ponderado para desplazar la activación de la neurona y permitir
que el modelo ajuste mejor los datos.

    \item \textbf{Funciones de Activación}: Las funciones de activación son fundamentales para que las redes neuronales
puedan aprender relaciones no lineales.
Entre las más comunes se encuentran:
\begin{itemize}
    \item \textbf{ReLU(Rectified Linear Unit)}: $ReLU(x)=\max(0,x)$, que activa solo valores positivos.
    \item \textbf{Sigmoide}: Que transforma los valores en un rango entre 0 y 1.
    \item \textbf{Tanh (Tangente hiperbólica)}: Transforma los valores en un rango entre -1 y 1.
\end{itemize}
\end{enumerate}

El uso de \textbf{backpropagation} o retropropagación permite ajustar los pesos y biases durante el entrenamiento
mediante un algoritmo de optimización, como el descenso de gradiente.
De esta manera, la red aprende minimizando la diferencia entre sus predicciones y las respuestas correctas.
\section{Redes Neuronales Convolucionales}\label{sec:redes-neuronales-convolucionales}
Las \textbf{Redes Neuronales Convolucionales} (Convolutional Neural Networks, CNNs) son una clase de redes neuronales
profundas especialmente efectivas para el procesamiento de datos que tienen una estructura de tipo rejilla, como las
imágenes.
Fueron inspiradas por el sistema visual de los mamíferos, donde diferentes capas de neuronas responden a estímulos
visuales de manera jerárquica. \\[2pt]

Las CNNs son ampliamente utilizadas en tareas de \textbf{visión por computador}, como el reconocimiento de imágenes, la
segmentación de objetos y la clasificación de imágenes.
Lo que diferencia a las CNNs de las redes neuronales tradicionales es su capacidad para detectar
\textbf{patrones espaciales} como bordes, texturas, y formas, sin necesidad de un procesamiento manual de las
características.


\subsection{Componentes principales de una CNN}\label{subsec:componentes-principales-de-una-cnn}
\begin{figure}[htp] \label{fig:convolution-layer}
    \begin{center}
        \includegraphics[width=1\textwidth]{imagenes/convolution_layer}
    \end{center}
    \caption[Puntos globales y locales]{En esta imagen extraída de
    \cite{A review of convolutional neural networks in computer vision} puede observarse de la estructura de una red
    neuronale convolucional. Junto a sus capas convolucionales. }
\end{figure}

\begin{enumerate}
    \item \textbf{Capas Convolucionales}: Estas capas aplican \textbf{filtros o kernels} sobre las imágenes de entrada
para detectar características locales, como bordes, esquinas o texturas.
Un filtro convolucional es una pequeña matriz que se mueve a lo largo de la imagen, calculando productos escalares en
cada posición para producir un mapa de características.

Las convoluciones son útiles porque explotan la \textbf{localidad de las características}, es decir, las relaciones
espaciales entre píxeles cercanos.
Además, la cantidad de parámetros se reduce drásticamente en comparación con las capas densas, ya que el filtro se
comparte a lo largo de la imagen.
    \item \textbf{Pooling (Submuestreo o Agrupamiento)}: Las capas de pooling reducen la dimensionalidad de las
características extraídas por las capas convolucionales, lo que hace que las representaciones sean más manejables y
robustas frente a pequeños cambios o desplazamientos en la imagen.

El max-pooling es la técnica de pooling más común, donde se toma el valor máximo dentro de una ventana de píxeles,
reduciendo el tamaño de la imagen, pero reteniendo las características más importantes.
    \item \textbf{Capas Densas}: Después de varias capas convolucionales y de pooling, se agregan una o más
\textbf{capas densas} (fully connected) para realizar la clasificación o predicción final.
Estas capas toman todas las características aprendidas en las capas convolucionales y las combinan para generar una
decisión final.
    \item \textbf{Batch Normalization}: Esta técnica se utiliza para \textbf{normalizar} las salidas de las capas
intermedias de una red neuronal.
Batch Normalization ayuda a \textbf{acelerar el entrenamiento} y a hacer que la red sea más estable, al reducir el
\textbf{desplazamiento covariante} (cambios en las distribuciones de las entradas de las capas intermedias a lo largo
del entrenamiento).
Esto se logra al normalizar las entradas de cada capa convolucional o densa antes de aplicar la activación, ajustando
su media y varianza.

    \item \textbf{Dropout}: El Dropout es una técnica de \textbf{regularización} que se utiliza para prevenir el
\textbf{sobreajuste} (overfitting) durante el entrenamiento de una red neuronal.
Durante cada iteración del entrenamiento, Dropout \textbf{desactiva aleatoriamente} un porcentaje de las neuronas, lo
que obliga a la red a no depender excesivamente de ciertas neuronas y a ser más robusta.
Esta técnica mejora la generalización de la red, lo que la hace funcionar mejor en datos no vistos.

\end{enumerate}

\subsection{Funcionamiento General de una CNN}\label{subsec:funcionamiento-general-de-una-cnn}
Al pasar una imagen a través de varias capas convolucionales, la red aprende a identificar características simples como
líneas y bordes.
Conforme avanza a capas más profundas, las características se vuelven más abstractas, capturando patrones más complejos
como formas, texturas y, finalmente, estructuras completas como objetos. \\[2pt]

Por ejemplo, en una red entrenada para reconocer caras, las primeras capas pueden detectar bordes o contornos, las
capas intermedias pueden aprender a reconocer ojos, nariz o boca, y las últimas capas pueden identificar una cara
completa.

\subsection{Aplicaciones de las CNN}\label{subsec:aplicaciones-de-las-cnn}
\begin{itemize}
    \item \textbf{Clasificación de imágenes}: Etiquetar imágenes en distintas categorías, como identificar animales o
vehículos.
    \item \textbf{Detección de objetos}: Identificar y localizar objetos en imágenes.
    \item \textbf{Reconocimiento facial}: Utilizado en sistemas de seguridad, como el desbloqueo de teléfonos móviles.
\end{itemize}

Las CNN son fundamentales en muchas aplicaciones modernas debido a su capacidad para procesar y entender datos visuales
de manera eficiente y automática.

\section{Datasets}\label{sec:datasets}
En el aprendizaje profundo, los datasets son colecciones de datos etiquetados o no etiquetados que se utilizan para
entrenar modelos.
Estos conjuntos de datos suelen contener ejemplos organizados que representan la entrada para el modelo, y en muchos
casos, también las etiquetas correspondientes que indican la salida deseada.
Los datasets varían en tamaño, calidad y tipo, dependiendo de la tarea a resolver, como la clasificación de imágenes,
el reconocimiento de patrones o la predicción de series temporales.

\subsection{Rock, Paper, Scissors (Piedra, Papel, Tijera)}\label{subsec:rock-paper-scissors}
\textbf{Rock, Paper, Scissors}~\cite{Rock Paper Scissors Dataset} fue creado originalmente por Laurence Moroney y se
utiliza para clasificar imágenes de las manos representando los gestos de `piedra', `papel' y `tijeras'.
El conjunto de datos contiene alrededor de 2,500 imágenes distribuidas en tres categorías: piedra, papel y tijeras.
Las imágenes están en color y tienen un tamaño de 300x300 píxeles.

En este trabajo, se ha utilizado el dataset de \textbf{Rock, Paper, Scissors} para evaluar el rendimiento del modelo en
un problema de clasificación de imágenes más variado y natural, que involucra múltiples clases.
Además, permite explorar la eficacia de los algoritmos meméticos en un entorno más cercano al reconocimiento de
objetos, lo que añade mayor complejidad al problema.

\subsection{MNIST (Modified National Institute of Standards and Technology)}\label{subsec:mnist}
\textbf{MNIST}~\cite{MNIST Dataset} es uno de los datasets más utilizados en el campo del aprendizaje automático y el
aprendizaje profundo.
Contiene 70,000 imágenes de dígitos escritos a mano (60,000 para el conjunto de entrenamiento y 10,000 para el de
prueba).
Las imágenes son en escala de grises y tienen un tamaño de 28x28 píxeles, con cada píxel representando una intensidad
de color entre 0 (negro) y 255 (blanco).

Este dataset se utiliza comúnmente como \textbf{benchmark} para evaluar modelos de clasificación de imágenes,
particularmente en arquitecturas convolucionales.

La simplicidad de \textbf{MNIST} lo hace ideal para probar modelos de redes neuronales convolucionales, ya que ofrece un
equilibrio entre un problema fácil de entender, pero con suficiente complejidad para que los modelos más avanzados
demuestren mejoras.

\subsection{Comparación con otros datasets}\label{subsec:comparacion-con-otros-datasets}
La selección de estos dos datasets responde a la necesidad de evaluar los algoritmos meméticos en distintos niveles de
complejidad.
\textbf{MNIST}, con imágenes en escala de grises de bajo nivel de complejidad, proporciona una referencia clara y
estandarizada para comparar el rendimiento y la reducción de datos.
Por otro lado, el dataset de \textbf{Rock, Paper, Scissors} introduce más desafíos visuales y complejidades,
permitiendo analizar cómo los algoritmos meméticos se comportan en escenarios más complejos que podrían ser
representativos de aplicaciones más reales en visión por computadora.
