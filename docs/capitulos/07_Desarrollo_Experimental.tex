\chapter{Desarrollo Experimental}\label{ch:desarrollo-experimental}

Tras la explicación del contenido necesario para el entendimiento y desarrollo del TFG en los capítulos anteriores, en
este capítulo se procederá a explicar las pruebas realizadas, las mejoras implementadas y los resultados obtenidos.
\\[6pt]

Las pruebas iniciales se plantearon tomando un dataset simple para realizar las primeras evaluaciones.
Una vez que el modelo funcionara correctamente con este conjunto de datos, se probaría con un dataset más complejo o
realista.
Para ello, se decidió utilizar el dataset de \textbf{RPS} \hyperref[subsec:rock-paper-scissors]{[Rock Paper Scissors]}.
\\[6pt]

Para obtener los primeros resultados con este dataset, se utilizó el modelo \textbf{ResNet50}.
Se realizaron pruebas con distintos porcentajes de datos para evaluar su impacto en el rendimiento del modelo. \\[6pt]

Tras las primeras pruebas, se observó que los resultados variaban entre ejecuciones.
Para abordar este problema y garantizar la reproducibilidad de los experimentos, se decidió fijar la semilla en Python
y en todas las librerías que empleaban algún tipo de aleatoriedad (\texttt{torch}, \texttt{cuda}, \texttt{numpy} y
\texttt{random}). \\[6pt]

Además, al investigar las posibles causas de esta variabilidad, se identificó que \texttt{cuDNN} puede utilizar ciertos
algoritmos no deterministas.
Para mitigar este efecto, se optó por forzar el uso de algoritmos deterministas en
\texttt{cuDNN}~\cite{noauthor_cublas_nodate}. \\[6pt]

Con estas configuraciones establecidas, se obtuvieron los primeros datos:


\begin{table}[htp]
    \centering
    \resizebox{\textwidth}{!}{
        \begin{tabular}{lp{2cm}lp{2cm}p{2cm}p{2cm}p{2cm}p{2.2cm}}
            \toprule
            \textbf{Algoritmo} & \textbf{Porcentaje Inicial} & \textbf{Duracion} & \textbf{Accuracy (Avg)} &
            \textbf{Precision (Avg)} & \textbf{Recall (Avg)} & \textbf{F1-score (Avg)} &
            \textbf{Evaluaciones Realizadas} \\
            \midrule
            aleatorio & 10 & 00:45:08 & 76,55\% & 81,80\% & 76,55\% & 76,25\% & 100 \\
            aleatorio & 20 & 01:10:27 & 81,77\% & 84,70\% & 81,77\% & 81,59\% & 100 \\
            aleatorio & 50 & 02:24:49 & 87,14\% & 88,09\% & 87,14\% & 86,97\% & 100 \\
            aleatorio & 100 & 00:02:42 & 87,90\% & 88,96\% & 87,90\% & 87,81\% & 1 \\
            \bottomrule
        \end{tabular}
    }
    \caption{Resultados de la generación inicial con \textbf{Resnet50}}
    \label{tab:initial-generation-resnet}
\end{table}

Los resultados de la Tabla~\ref{tab:initial-generation-resnet} muestran que, a medida que se incrementa el porcentaje
inicial de datos utilizados, se observa una mejora en las métricas de precisión, recall y F1-score.
Esto indica que el modelo logra aprender mejor con una mayor cantidad de datos disponibles; sin embargo, también se
evidencia un incremento significativo en el tiempo de entrenamiento.
De hecho, las duraciones indicadas en la tabla corresponden al tiempo necesario para completar todas las evaluaciones
especificadas, y se observa que estos tiempos son considerablemente elevados.
Debido a esta limitación, se decidió probar el algoritmo \textbf{MobileNet} con el objetivo de agilizar el proceso.

\begin{table}[htp]
    \centering
    \resizebox{\textwidth}{!}{
        \begin{tabular}{lp{2cm}lp{2cm}p{2cm}p{2cm}p{2cm}p{2.2cm}}
            \toprule
        \textbf{Algoritmo} & \textbf{Porcentaje Inicial} & \textbf{Duracion} & \textbf{Accuracy (Avg)} &
        \textbf{Precision (Avg)} & \textbf{Recall (Avg)} & \textbf{F1-score (Avg)} & \textbf{Evaluaciones Realizadas} \\
        \midrule
        aleatorio & 10 & 00:29:29 & 72,31\% & 76,40\% & 72,31\% & 69,62\% & 100 \\
        aleatorio & 20 & 00:50:36 & 76,48\% & 78,82\% & 76,48\% & 75,58\% & 100 \\
        aleatorio & 50 & 01:54:09 & 75,56\% & 79,72\% & 75,56\% & 74,67\% & 100 \\
        aleatorio & 100 & 00:02:12 & 76,08\% & 79,97\% & 76,08\% & 75,61\% & 1 \\
        \bottomrule
        \end{tabular}
    }
    \caption{Resultados de la generación inicial con \textbf{MobileNet}}
    \label{tab:initial-generation-mobilenet}
\end{table}


\section{Datasets}\label{sec:datasets}
En el aprendizaje profundo, los datasets son colecciones de datos etiquetados o no etiquetados que se utilizan para
entrenar modelos.
Estos conjuntos de datos contienen ejemplos organizados que representan la entrada para el modelo y, en muchos casos,
también las etiquetas correspondientes que indican la salida deseada.
Los datasets varían en tamaño, calidad y tipo, dependiendo de la tarea a resolver, como la clasificación de imágenes,
el reconocimiento de patrones o la predicción de series temporales.

\subsection{Rock, Paper, Scissors (Piedra, Papel, Tijera)}\label{subsec:rock-paper-scissors}
\textbf{Rock, Paper, Scissors}~\cite{noauthor_rock_nodate} es un conjunto de datos creado por Laurence Moroney
que se utiliza para la clasificación de imágenes de manos representando los gestos de `piedra', `papel' y `tijeras'.

\subsubsection{Estructura del Dataset}
El conjunto de datos contiene aproximadamente 2,500 imágenes, distribuidas en tres categorías: piedra, papel y tijeras.
Las imágenes están en color y tienen un tamaño de 300x300 píxeles.

Las imágenes están organizadas en directorios según su categoría artística:
\begin{verbatim}
+-- train
|   +-- rock
|   |   +-- image1.jpg
|   |   +-- image2.jpg
|   |   \-- ...
|   +-- paper
|   |   +-- image1.jpg
|   |   +-- image2.jpg
|   |   \-- ...
|   \-- scissors
+-- test (originalmente valid)
|   +-- rock
|   +-- paper
|   \-- scissors
+-- valid (originalmente test)
|   +-- rock
|   +-- paper
|   \-- scissors
\end{verbatim}


\subsubsection{Formato de los Datos}
Las imágenes están en formato JPEG (\texttt{.jpg}). Para su procesamiento, se han aplicado técnicas de preprocesamiento
adaptadas a los requerimientos del modelo.

\subsubsection{Uso del Dataset}
Este dataset se ha utilizado para evaluar el rendimiento del modelo en un problema de clasificación de imágenes con
múltiples clases, pero siendo un dataset sencillo y con un número de clases pequeño.
Además, permite explorar la eficacia de los algoritmos meméticos en un entorno más cercano al reconocimiento de objetos.

\subsubsection{Correcciones en la División de Datos}
Según la nota observada en el README del dataset:
\begin{quote}
\textit{Note: in the source, Laurence calls ``validation'' as the ``test'', and ``test'' the ``validation''.}
\end{quote}
se han renombrado las particiones de \texttt{test} y \texttt{valid} para que correspondan correctamente con sus
propósitos.

\subsubsection{Licencia y uso}
 Este conjunto de datos se distribuye bajo la licencia
\textbf{Creative Commons Attribution 4.0 International (CC BY 4.0)}, lo que permite su uso, modificación y distribución
con la condición de otorgar el crédito adecuado a los creadores originales~\cite{moroney_laurence_nodate}.


\subsection{PAINTING (Art Images: Drawing/Painting/Sculptures/Engravings)}\label{subsec:painting}
El dataset \textbf{Art Images: Drawing/Painting/Sculptures/Engravings} es una colección de aproximadamente 9,000
imágenes organizadas en cinco categorías de arte: dibujos, pinturas, esculturas, grabados y arte iconográfico.

\subsubsection{Estructura del Dataset}
Las imágenes están organizadas en directorios según su categoría artística:
\begin{verbatim}
+-- Train (originalmente training_set)
|   +-- drawings
|   |   +-- image1.jpg
|   |   +-- image2.jpg
|   |   \-- ...
|   +-- paintings
|   |   +-- image1.jpg
|   |   +-- image2.jpg
|   |   \-- ...
|   +-- sculptures
|   +-- engravings
|   \-- iconography
+-- Test (originalmente validation_set)
|   +-- drawings
|   +-- paintings
|   +-- sculptures
|   +-- engravings
|   \-- iconography
\end{verbatim}

\subsubsection{Formato de los Datos}
Todas las imágenes están en formato JPEG (\texttt{.jpg}) y presentan variaciones en resolución y dimensiones.
Se han aplicado técnicas de preprocesamiento para homogenizar las características de las imágenes.

\subsubsection{Uso del Dataset}
Este dataset se ha utilizado para entrenar y evaluar modelos de clasificación de imágenes en un entorno diferente al
RPS\@.
Con este dataset, se ha comprobado el funcionamiento para evaluar los algoritmos con un dataset un poco mas complejo
que el RPS, con un par de clases más y con un número mayor de imágenes.

\subsubsection{Correcciones en la División de Datos}
Observando los tamaños de la división de los datos, y teniendo en cuenta que la divisón de los datos suele ser en train
y test, se ha decidido por renombrar las particiones de \texttt{valid} por \texttt{test} para que corresponda
correctamente con su propósito.
Y el set de validation lo he obtenido separando el set de train, normalmente haciendo una división 80\% test y 20\%
valid.

\subsubsection{Acceso al Dataset}
Inicialmente, el dataset se descargó desde Kaggle~\cite{noauthor_original_nodate}

Sin embargo, debido a la presencia de archivos innecesarios y algunas imágenes corruptas, se optó por una versión
limpia disponible en Kaggle~\cite{noauthor_cleaned_nodate}.

\subsubsection{Licencia y Uso}
Antes de su uso, se revisaron los términos y condiciones establecidos en la página de Kaggle para asegurar el
cumplimiento con las licencias y restricciones aplicables.

\subsection{MNIST (Modified National Institute of Standards and Technology)}\label{subsec:mnist}
\textbf{MNIST}~\cite{noauthor_mnist_nodate} es un dataset ampliamente utilizado en aprendizaje profundo.
Contiene 70,000 imágenes de dígitos escritos a mano, divididas en 60,000 imágenes para el entrenamiento y 10,000 para
la prueba.

\subsubsection{Estructura del Dataset}
Las imágenes tienen un tamaño de 28x28 píxeles y están en escala de grises, con valores de intensidad entre 0 (negro) y
255 (blanco).

\subsubsection{Formato de los Datos}
Las imágenes están almacenadas en formato IDX, un formato binario específico para este dataset.
Se ha realizado una conversión a matrices NumPy para su procesamiento eficiente.

\subsubsection{Uso del Dataset}
Este conjunto de datos se ha empleado como benchmark para evaluar modelos de clasificación de imágenes, especialmente
en arquitecturas convolucionales.

\subsubsection{Licencia y uso}
El dataset MNIST se distribuye bajo una licencia de dominio público.
Fue creado a partir de los datos originales del NIST y está disponible en diversas plataformas, incluyendo la página
oficial de Yann LeCun~\cite{lecun_yann_nodate}.


\subsection{Comparación con otros datasets}\label{subsec:comparacion-con-otros-datasets}
La selección de estos dos datasets responde a la necesidad de evaluar los algoritmos meméticos en distintos niveles de
complejidad.
\textbf{MNIST}, con imágenes en escala de grises de bajo nivel de complejidad, proporciona una referencia clara y
estandarizada para comparar el rendimiento y la reducción de datos.
Por otro lado, el dataset de \textbf{Rock, Paper, Scissors} introduce más desafíos visuales y complejidades,
permitiendo analizar cómo los algoritmos meméticos se comportan en escenarios más complejos que podrían ser
representativos de aplicaciones más reales en visión por computadora.
