% !TeX root = ../proyecto.tex

\chapter{Implementación}\label{ch:implementacion}
En este capítulo se presenta en detalle la arquitectura técnica del sistema implementado, incluyendo los componentes y
módulos principales, las herramientas específicas empleadas en la construcción del sistema, y los elementos clave para
optimizar el rendimiento de los algoritmos y su evaluación.


\section{Descripción del Sistema}\label{sec:descripcion-del-sistema}
%Descripción del Sistema: Detalla la arquitectura del sistema que estás implementando.
La estructura del proyecto se organizó modularmente para facilitar el acceso, el mantenimiento y la extensibilidad del código fuente.
La organización de carpetas es la siguiente:
\begin{itemize}
      \item \texttt{data} -- Conjunto de datos utilizados en los experimentos.
      \item \texttt{docs} -- Documentación del proyecto en latex.
            \begin{itemize}
                  \item \texttt{bibliografia} -- Archivos relacionados con las referencias bibliográficas.
                  \item \texttt{capitulos} -- Archivos individuales para cada capítulo del documento.
                  \item \texttt{config} -- Archivos de configuraciones de la documentación LaTeX.
                  \item \texttt{imagenes} -- Imágenes utilizadas en la documentación.
                  \item \texttt{out} -- Archivos generados por el compilador de LaTeX.
                  \item \texttt{portada} -- Archivo portada del documento.
                  \item \texttt{prefacio} -- Archivo prefacio del documento.
                  \item \texttt{proyecto.tex} -- Archivo principal de LaTeX que compila el documento.
            \end{itemize}
      \item \texttt{img} -- Imágenes generadas automáticamente durante los experimentos.
      \item \texttt{LICENSE} -- Términos de distribución del proyecto.
      \item \texttt{logs} -- Registros de las ejecuciones, incluyendo tiempos de inicio, fin y resultados intermedios de los algoritmos.
      \item \texttt{README.md} -- Descripción general.
      \item \texttt{requirements.txt} -- Dependencias del proyecto.
      \item \texttt{results} -- Resultados de los experimentos.
            \begin{itemize}
                  \item \texttt{csvs} -- Resultados de las ejecuciones guardados en tablas.
                  \item \texttt{salidas} -- Salidas en bruto de consola.
            \end{itemize}
      \item \texttt{scripts} -- Scripts de ejecución automática, comparación de experimentos y generación de gráficos finales.
      \item \texttt{src} -- Código fuente principal del proyecto.
            \begin{itemize}
                  \item \texttt{algorithms} -- Implementaciones de los algoritmos.
                  \item \texttt{main.py} -- Módulo principal de ejecución individual.
            \end{itemize}
      \item \texttt{tmp} -- Ficheros temporales generados durante la ejecución.
      \item \texttt{utils} -- Módulos de apoyo, como clases auxiliares, generación de gráficos y funciones utilitarias.
\end{itemize}

\section{Herramientas y Lenguajes de Programación}\label{sec:herramientas-y-lenguajes-de-programacion}
%Herramientas y Lenguajes de Programación: Lista las herramientas y tecnologías que usarás.
El desarrollo del proyecto se ha llevado a cabo utilizando \textbf{Python 3.10}~\cite{vanderplas_python_2016} como
lenguaje principal, debido a su versatilidad y amplia adopción en el campo del \textbf{aprendizaje profundo} y la
\textbf{manipulación de datos}.
Python es conocido por su facilidad de uso, extensibilidad y la gran cantidad de bibliotecas disponibles para el
procesamiento de datos y la implementación de modelos de \textbf{machine learning}.


Las principales bibliotecas empleadas durante el desarrollo son las siguientes:
\begin{itemize}
      \item \textbf{PyTorch 2.3.1}~\cite{ketkar_introduction_2021, noauthor_torchcuda_nodate}: Para la construcción,
            entrenamiento y optimización de modelos de aprendizaje profundo.
            PyTorch fue elegido por su flexibilidad y capacidad para ejecutarse eficientemente en GPU\@.
      \item \textbf{Scikit-learn 1.5.2}~\cite{kramer_scikit-learn_2016}: Utilizado en la selección de características y
            la validación cruzada de modelos.
            Su API permite una integración fluida con PyTorch y otros módulos.
      \item \textbf{Numpy 2.0.0}~\cite{noauthor_numpy_nodate}: Para operaciones matemáticas y manipulación de matrices,
            siendo una herramienta esencial en el procesamiento de datos.
      \item \textbf{Polars 1.9.0}~\cite{noauthor_polars_nodate}: Biblioteca para manejar DataFrames de gran tamaño,
            elegida por su rendimiento superior en comparación con Pandas.
      \item \textbf{Matplotlib 3.9.2}~\cite{noauthor_matplotlib_nodate}: Biblioteca utilizada para la generación y
            visualización de gráficas.
      \item \textbf{Seaborn 0.13.2}~\cite{noauthor_seaborn_nodate}: Estilización avanzada de gráficos estadísticos.
      \item \textbf{Openpyxl 3.1.5}~\cite{noauthor_openpyxl_nodate}: Generación automática de archivos Excel a partir de resultados experimentales.
\end{itemize}

Cada una de estas herramientas fue seleccionada por su robustez y su idoneidad para cumplir con los requisitos
específicos del proyecto, facilitando tanto la implementación de los algoritmos meméticos como la reducción y el
análisis de los datos utilizados en los modelos de aprendizaje profundo.

\section{Gestión de Dependencias}\label{sec:gestion-de-dependencias}
Para garantizar que el proyecto se ejecute correctamente y todas las bibliotecas necesarias estén disponibles, se ha
utilizado un archivo \texttt{requirements.txt}.
Este archivo contiene una lista de todas las bibliotecas y sus versiones específicas que el proyecto requiere.


Para el \textbf{desarrollo local}, se ha optado por crear un entorno virtual utilizando
\texttt{venv}~\cite{noauthor_creation_nodate}.
Esta práctica permite aislar las dependencias del proyecto de otros proyectos en la máquina, evitando conflictos entre
versiones de bibliotecas.


Para la \textbf{implementación en el servidor}, se ha utilizado \texttt{conda}~\cite{noauthor_conda_nodate} como gestor
de paquetes y entornos.
Conda facilita la gestión de entornos y la instalación de bibliotecas, especialmente en configuraciones más complejas.



Esto facilita la reproducibilidad del proyecto y minimiza posibles conflictos de versión, lo que es fundamental para
mantener la integridad del código y el rendimiento de las aplicaciones.

\section{Arquitectura de la Implementación}\label{sec:arquitectura-de-la-implementacion}
La arquitectura de la implementación se organiza en varios módulos, que a continuación se describen en detalle:

\subsection{Módulo de Algoritmos}\label{subsec:modulo-de-algoritmos}
Ubicado en \texttt{src/algorithms/} este módulo contiene las implementaciones principales de los
algoritmos desarrollados en el proyecto.

Este módulo utiliza la arquitectura GPU para maximizar la velocidad de ejecución y está diseñado para ser escalable,
permitiendo la inclusión de nuevos operadores meméticos si es necesario.

\subsection{Núcleo de Ejecución}\label{subsec:nucleo-de-ejecucion}
El módulo \texttt{main.py} centraliza la ejecución de un experimento individual, inicializando configuraciones,
entrenando el modelo y generando gráficos.


Los pasos de la función principal de \texttt{main.py} es:
\begin{enumerate}
      \item \textbf{Establece Configuración Inicial}: Configura una semilla, elige el dataset y prepara un archivo de log.
      \item \textbf{Inicia el Proceso del Algoritmo}: Según el nombre del algoritmo (algoritmo) especificado, se llama a
            la función correspondiente (por ejemplo, genetic\_algorithm, memetic\_algorithm, etc.).
      \item \textbf{Almacena Resultados}: Una vez que el algoritmo termina, registra la duración, los resultados y la
            métrica final en un archivo.
      \item \textbf{Visualiza Resultados}: Si hay datos de fitness, genera una gráfica de la evolución del fitness a lo
            largo del proceso.
      \item \textbf{Genera un Resumen}: Calcula estadísticas adicionales (como porcentaje de clases seleccionadas en
            Paper, Rock y Scissors), y devuelve estos resultados junto con el historial de fitness.
\end{enumerate}


Adicionalmente, los scripts \texttt{generator.py} y \texttt{generator\_initial.py} permiten automatizar experimentos masivos combinando distintos algoritmos, porcentajes iniciales y modelos de red neuronal.

\subsection{Módulo de Utilidades}\label{subsec:modulo-de-utilidades}
La carpeta \texttt{utils/} contiene funciones auxiliares:
\begin{itemize}
      \item \textbf{utils\_plot.py}: Generación de gráficos.
      \item \textbf{classes.py}: Definición de enumeraciones para algoritmos, métricas, datasets y modelos.
      \item \textbf{utils.py}: Funciones de ayuda como el cálculo de métricas o la creación de diccionarios de selección de imágenes.
\end{itemize}

Estos módulos se encargan de generar gráficas comparativas entre distintos porcentajes o algoritmos y en
generar un CSV con los datos finales para ser analizados.

\subsection{Scripts de Ejecución en GPU}\label{subsec:scripts-de-ejecucion-en-gpu}
En scripts, se encuentran los programas necesarios para ejecutar los algoritmos en un servidor GPU, lo que permite
maximizar la eficiencia en el entrenamiento y la evaluación de modelos.
\begin{enumerate}
      \item \textbf{Configuración de GPU}: Los scripts están configurados para identificar y utilizar las GPU disponibles
            en el servidor, reduciendo los tiempos de entrenamiento de modelos.
      \item \textbf{Optimización de Ejecución}: Se implementaron configuraciones de batch size y técnicas de
            procesamiento paralelo en PyTorch, aprovechando la memoria y el poder de procesamiento de las GPU\@.
\end{enumerate}

Estos scripts están diseñados para ser ejecutados en un entorno de servidor, reduciendo los tiempos de prueba en el
entorno local y permitiendo un análisis iterativo más rápido.

\section{Consideraciones de Optimización}\label{sec:consideraciones-de-optimizacion}
Durante el desarrollo, se optimizaron varios aspectos para mejorar el rendimiento del sistema:

\begin{enumerate}
      \item \textbf{Aceleración en GPU}: Todas las operaciones de cálculo intensivo fueron migradas a la GPU mediante
            PyTorch.
      \item \textbf{Uso Eficiente de Memoria}: Con Polars y Numpy, se optimizó el manejo de grandes volúmenes de datos,
            utilizando tipos de datos específicos para reducir el uso de memoria.
      \item \textbf{Automatización de Evaluaciones}: Las pruebas de rendimiento se automatizaron, permitiendo una
            evaluación continua sin intervención manual.
      \item \textbf{Control de reproducibilidad}: Se fijaron semillas aleatorias en todas las librerías involucradas
            (random, numpy, torch, cuda) y se desactivaron los algoritmos no deterministas de cuDNN~\cite{noauthor_cublas_nodate}.
            Esta medida garantiza que las ejecuciones del sistema produzcan resultados consistentes entre sesiones,
            algo esencial en entornos de evaluación comparativa.
      \item \textbf{Diagnóstico automático de GPU}: Implementación de un script (cuda-diagnostic.py) que comprueba disponibilidad
            de CUDA y dispositivos antes de lanzar experimentos, garantizando un entorno correcto.
\end{enumerate}

Además, se implementó un mecanismo de \textbf{early stopping} basado en la ausencia de mejora del valor de fitness durante
un número determinado de evaluaciones consecutivas.
Aunque no se utiliza una pérdida de validación explícita como en enfoques tradicionales, este enfoque funcionalmente cumple el mismo propósito:
detener el algoritmo cuando se detecta estancamiento, reduciendo así el coste computacional innecesario.


Gracias a estas optimizaciones, el sistema permite explorar un amplio abanico de configuraciones de manera eficiente, manteniendo la robustez y estabilidad de los resultados.