\chapter{Introducción}\label{ch:introduccion}

\section{Contexto}\label{sec:contexto}
%Contexto: Breve introducción al tema y su relevancia.
En la actualidad, nos encontramos en una era caracterizada por la generación de datos, que crece a un ritmo sin
precedentes.
Este fenómeno plantea la necesidad de desarrollar métodos capaces de procesar y analizar grandes volúmenes de
información de manera eficiente.
Los \textbf{modelos de aprendizaje profundo} —especialmente las \textbf{redes neuronales convolucionales} (CNNs)— han
demostrado ser particularmente efectivos en tareas como la \textbf{clasificación de imágenes}, el
\textbf{reconocimiento de patrones} y otras aplicaciones complejas.
Sin embargo, el entrenamiento de estos modelos requiere numerosas cantidades de datos, lo que trae consigo importantes
desafíos relacionados con el \textbf{tiempo} obtenerlos y el \textbf{costo económico} de obtener tantos datos. \\[6pt]

A medida que los modelos de inteligencia artificial avanzan hacia configuraciones más complejas y precisas, la
necesidad de disponer de datos de entrenamiento adecuados y en gran cantidad se hace cada vez más evidente.
No obstante, la recolección, almacenamiento y procesamiento de estos datos representan barreras significativas para
muchas organizaciones —especialmente aquellas con recursos limitados—, lo que subraya la importancia de explorar
enfoques innovadores que permitan la \textbf{optimización y reducción} de los conjuntos de datos necesarios para
entrenar estos modelos. \\[6pt]

\section{Motivación}\label{sec:motivacion}
La necesidad de \textbf{reducir los conjuntos de datos de entrenamiento} surge de la búsqueda por optimizar la
\textbf{eficiencia} en el desarrollo de modelos de aprendizaje profundo.
Si bien las redes neuronales convolucionales han alcanzado resultados impresionantes, sus
\textbf{altos costos computacionales} y la extensa cantidad de datos que requieren suponen limitaciones para muchos
entornos.
Entrenar estos modelos utilizando solo una parte de los datos —seleccionados de manera óptima— podría reducir
considerablemente los recursos necesarios (sin comprometer la precisión de los resultados); ello marcaría un avance
significativo para la \textbf{inteligencia artificial} y sus aplicaciones en entornos con
\textbf{restricciones de recursos}. \\[6pt]

La selección de subconjuntos de datos más representativos permite reducir los tiempos de procesamiento y el consumo de
recursos sin afectar el rendimiento de los modelos.
Es aquí donde las \textbf{metaheurísticas} entran en juego: las metaheurísticas son métodos de optimización avanzados
diseñados para resolver problemas complejos donde los métodos tradicionales resultan ineficaces.
Funcionan a través de \textbf{estrategias de búsqueda} y \textbf{exploración del espacio de soluciones}, combinando
heurísticas específicas para encontrar soluciones aproximadas en tiempos razonables.
Son útiles en problemas donde encontrar la solución óptima es computacionalmente costoso o impracticable.
Así, las metaheurísticas se posicionan como una solución prometedora para hacer que el aprendizaje profundo sea
más \textbf{accesible y eficiente} —incluso en escenarios donde los recursos son limitados—, lo cual es crucial para
democratizar el uso de la inteligencia artificial en una amplia gama de aplicaciones. \\[6pt]

Este trabajo de fin de grado busca utilizar el uso de metaheurísticas para hacer una selección inteligente de ejemplos
para reducir los datos de entrenamiento manteniendo, en la medida de lo posible, los buenos resultados del
entrenamiento.
La investigación pretende abrir nuevas vías para el desarrollo de modelos más \textbf{eficientes}, accesibles y
económicamente viables, lo que favorecerá un futuro en el que la inteligencia artificial sea \textbf{inclusiva} y más
\textbf{sostenible}. \\[6pt]

\section{Objetivos}\label{sec:objetivos}
%Objetivos: Especifica qué pretendes lograr con tu TFG.
El objetivo principal de este TFG es investigar la aplicación de \textbf{metaheurísticas} para la
\textbf{reducción de conjuntos de datos de entrenamiento} en modelos de \textbf{aprendizaje profundo convolucionales}.
Este estudio permitirá evaluar el impacto de dichos algoritmos en la \textbf{eficiencia computacional} y en el
\textbf{rendimiento de los modelos}.
Para cumplir con este objetivo general, se plantean los siguientes \textbf{objetivos específicos}:

\begin{itemize}
    \item \textbf{Desarrollar} e implementar metaheurísticas que busquen conjuntos reducidos de datos de
entrenamiento, con el fin de reducir el volumen de datos requerido para entrenar modelos convolucionales —sin
comprometer la precisión de los resultados—.
    \item \textbf{Evaluar} el impacto de la reducción de datos en el rendimiento de los modelos, comparando aspectos
clave como la precisión, eficacia y el tiempo de entrenamiento —en modelos entrenados con conjuntos de datos completos
frente a conjuntos reducidos—.
    \item \textbf{Mejorar la eficiencia} del entrenamiento de redes neuronales convolucionales mediante el uso de
metaheurísticas, analizando los beneficios en términos de reducción de tiempo y costo computacional.
    \item \textbf{Contribuir al avance} de soluciones innovadoras en el campo del aprendizaje profundo, especialmente
en escenarios con limitaciones de datos; facilitando así el acceso a esta tecnología a sectores que, de otro modo,
tendrían dificultades para implementarla de manera efectiva.
\end{itemize}

A través de este estudio, se busca no solo mejorar el rendimiento y la eficiencia de los modelos convolucionales, sino
también fomentar el desarrollo de soluciones más \textbf{sostenibles y accesibles} en el ámbito de la inteligencia
artificial.
