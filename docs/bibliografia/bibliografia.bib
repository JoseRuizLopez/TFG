@article{alnuaimHumanComputerInteractionHand2022,
  title = {Human-Computer Interaction with Hand Gesture Recognition Using ResNet and MobileNet},
  author = {Alnuaim, Abeer and Zakariah, Mohammed and Hatamleh, Wesam Atef and Tarazi, Hussam and Tripathi, Vikas and Amoatey, Enoch Tetteh},
  year = {2022},
  journal = {Computational Intelligence and Neuroscience},
  volume = {2022},
  number = {1},
  pages = {8777355},
  issn = {1687-5273},
  doi = {10.1155/2022/8777355},
  abstract = {Sign language is the native language of deaf people, which they use in their daily life, and it facilitates the communication process between deaf people. The problem faced by deaf people is targeted using sign language technique. Sign language refers to the use of the arms and hands to communicate, particularly among those who are deaf. This varies depending on the person and the location from which they come. As a result, there is no standardization about the sign language to be used; for example, American, British, Chinese, and Arab sign languages are all distinct. Here, in this study we trained a model, which will be able to classify the Arabic sign language, which consists of 32 Arabic alphabet sign classes. In images, sign language is detected through the pose of the hand. In this study, we proposed a framework, which consists of two CNN models, and each of them is individually trained on the training set. The final predictions of the two models were ensembled to achieve higher results. The dataset used in this study is released in 2019 and is called as ArSL2018. It is launched at the Prince Mohammad Bin Fahd University, Al Khobar, Saudi Arabia. The main contribution in this study is resizing the images to 64 {$\ast$} 64 pixels, converting from grayscale images to three-channel images, and then applying the median filter to the images, which acts as lowpass filtering in order to smooth the images and reduce noise and to make the model more robust to avoid overfitting. Then, the preprocessed image is fed into two different models, which are ResNet50 and MobileNetV2. ResNet50 and MobileNetV2 architectures were implemented together. The results we achieved on the test set for the whole data are with an accuracy of about 97\% after applying many preprocessing techniques and different hyperparameters for each model, and also different data augmentation techniques.},
  langid = {english},
  note = {\url{https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/8777355}}
}

@book{chaconProGit2014,
  title = {Pro Git},
  author = {Chacon, Scott and Straub, Ben},
  year = {2014},
  edition = {Second},
  publisher = {Apress},
  address = {New York},
  doi = {10.1007/978-1-4842-0076-6},
  abstract = {Pro Git (Second Edition) is your fully-updated guide to Git and its usage in the modern world. Git has come a long way since it was first developed by Linus Torvalds for Linux kernel development. It has taken the open source world by storm since its inception in 2005, and this book teaches you how to use it like a pro. Effective and well-implemented version control is a necessity for successful web projects, whether large or small. With this book you'll learn how to master the world of distributed version workflow, use the distributed features of Git to the full, and extend Git to meet your every need. Written by Git pros Scott Chacon and Ben Straub, Pro Git (Second Edition) builds on the hugely successful first edition, and is now fully updated for Git version 2.0, as well as including an indispensable chapter on GitHub. It's the best book for all your Git needs.},
  isbn = {978-1-4842-0076-6},
  langid = {english},
  keywords = {git version-control},
  note = {\url{https://git-scm.com/book/en/v2}}
}

@misc{CleanedArtImages,
  title = {(Cleaned) Art Images: Drawing/Painting/Sculptures/Engravings},
  shorttitle = {Art Images},
  abstract = {Dataset with about 9000 images containing 5 types of arts},
  howpublished = {\url{https://www.kaggle.com/datasets/moosecat/art-images-drawings-painting-sculpture-engraving}},
  langid = {english}
}

@misc{CondaDocumentation,
  title = {Conda Documentation},
  howpublished = {\url{https://docs.conda.io/en/latest/}}
}

@misc{CreationVirtualEnvironments,
  title = {Creation of virtual environments},
  journal = {Python documentation},
  abstract = {C{\'o}digo fuente: Lib/venv/ El m{\'o}dulo venv admite la creaci{\'o}n de <<entornos virtuales>> ligeros, cada uno con su propio conjunto independiente de paquetes de Python instalados en sus directorios site. S...},
  howpublished = {\url{https://docs.python.org/3/library/venv.html}},
  langid = {spanish}
}

@misc{CuBLASDeterministicAlgorithms,
  title = {cuBLAS Deterministic Algorithms},
  howpublished = {\url{https://docs.nvidia.com/cuda/cublas/index.html\#cublasApi_reproducibility}}
}

@inproceedings{dongMemeticAlgorithmEvolving2020,
  title = {A Memetic Algorithm for Evolving Deep Convolutional Neural Network in Image Classification},
  author = {Dong, Junwei and Zhang, Liangjie and Hou, Boyu and Feng, Liang},
  year = {2020},
  month = dec,
  pages = {2663--2669},
  doi = {10.1109/SSCI47803.2020.9308162}
}

@misc{EarlyStoppingDiscussion2024,
  title = {Early Stopping Discussion},
  year = {2024},
  month = feb,
  journal = {GeeksforGeeks},
  abstract = {A Computer Science portal for geeks. It contains well written, well thought and well explained computer science and programming articles, quizzes and practice/competitive programming/company interview Questions.},
  chapter = {AI-ML-DS},
  howpublished = {\url{https://www.geeksforgeeks.org/early-stopping-on-validation-loss-or-on-accuracy/}},
  langid = {spanish}
}

@book{goldbergGeneticAlgorithmsSearch1989,
  title = {Genetic Algorithms in Search, Optimization, and Machine Learning},
  author = {Goldberg, D.E.},
  year = {1989},
  series = {Addison Wesley series in artificial intelligence},
  publisher = {Addison-Wesley},
  isbn = {978-0-201-15767-3},
  lccn = {lc88006276},
  note = {\url{https://books.google.es/books?id=2IIJAAAACAAJ}}
}

@book{goodfellowDeepLearning2016,
  title = {Deep Learning},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year = {2016},
  publisher = {MIT Press}
}

@inproceedings{heDeepResidualLearning2016,
  title = {Deep Residual Learning for Image Recognition},
  booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year = {2016},
  pages = {770--778},
  doi = {10.1109/CVPR.2016.90},
  keywords = {Complexity theory,Degradation,Image recognition,Image segmentation,Neural networks,Training,Visualization}
}

@book{hollandAdaptationNaturalArtificial1975,
  title = {Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence},
  author = {Holland, J.H.},
  year = {1975},
  publisher = {University of Michigan Press},
  isbn = {978-0-472-08460-9},
  lccn = {lc74078988},
  note = {\url{https://books.google.es/books?id=YE5RAAAAMAAJ}}
}

@misc{howardMobileNetsEfficientConvolutional2017,
  title = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
  shorttitle = {MobileNets},
  author = {Howard, Andrew G. and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  year = {2017},
  month = apr,
  number = {arXiv:1704.04861},
  eprint = {1704.04861},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1704.04861},
  abstract = {We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization.},
  archiveprefix = {arXiv},
  howpublished = {\url{http://arxiv.org/abs/1704.04861}},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@incollection{ketkarIntroductionPyTorch2021,
  title = {Introduction to PyTorch},
  booktitle = {Deep Learning with Python: Learn Best Practices of Deep Learning Models with PyTorch},
  author = {Ketkar, Nikhil and Moolayil, Jojo},
  year = {2021},
  pages = {27--91},
  publisher = {Apress},
  address = {Berkeley, CA},
  doi = {10.1007/978-1-4842-5364-9_2},
  abstract = {The recent years have witnessed major releases of frameworks and tools to democratize deep learning to the masses. Today, we have a plethora of options at our disposal. A few popular names include PyTorch, TensorFlow, Keras, and MXNet---the list is never-ending. This chapter aims to provide an overview of PyTorch. We will be using PyTorch extensively throughout the book for implementing deep learning examples. Note that this chapter is not a comprehensive guide for PyTorch, so you should consult the additional materials suggested in the chapter for a deeper understanding of the framework. A basic overview will be offered and the necessary additions to the topic will be provided in the course of the examples implemented later in the book.},
  isbn = {978-1-4842-5364-9},
  note = {\url{https://doi.org/10.1007/978-1-4842-5364-9_2}}
}

@incollection{kramerScikitLearn2016,
  title = {Scikit-Learn},
  booktitle = {Machine Learning for Evolution Strategies},
  author = {Kramer, Oliver},
  year = {2016},
  pages = {45--53},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-33383-0_5},
  abstract = {scikit-learn is an open source machine learning library written in Python.},
  isbn = {978-3-319-33383-0},
  note = {\url{https://doi.org/10.1007/978-3-319-33383-0_5}}
}

@article{lecunDeepLearning2015,
  title = {Deep learning},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  year = {2015},
  month = may,
  journal = {Nature},
  volume = {521},
  number = {7553},
  pages = {436--444},
  issn = {1476-4687},
  doi = {10.1038/nature14539},
  abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
  note = {\url{https://doi.org/10.1038/nature14539}}
}

@misc{lecunYannLeCunsWeb,
  title = {Yann LeCun's Web Page},
  author = {LeCun, Yann},
  howpublished = {\url{http://yann.lecun.com/}}
}

@misc{Matplotlib393Documentation,
  title = {Matplotlib 3.9.3 documentation},
  howpublished = {\url{https://matplotlib.org/3.9.3/index.html}}
}

@misc{MNISTDataset,
  title = {MNIST Dataset},
  abstract = {The MNIST database of handwritten digits (http://yann.lecun.com)},
  howpublished = {\url{https://www.kaggle.com/datasets/hojjatk/mnist-dataset}},
  langid = {english}
}

@misc{moroneyLaurenceMoroneyAI,
  title = {Laurence Moroney - The AI Guy.},
  author = {Moroney, Laurence},
  howpublished = {\url{https://laurencemoroney.com/}}
}

@article{moscatoEvolutionSearchOptimization2000,
  title = {On Evolution, Search, Optimization, Genetic Algorithms and Martial Arts - Towards Memetic Algorithms},
  author = {Moscato, Pablo},
  year = {2000},
  month = oct,
  journal = {Caltech Concurrent Computation Program}
}

@book{neriHandbookMemeticAlgorithms2012,
  title = {Handbook of Memetic Algorithms},
  editor = {Neri, Ferrante and Cotta, Carlos and Moscato, Pablo and Kacprzyk, Janusz},
  year = {2012},
  series = {Studies in Computational Intelligence},
  volume = {379},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-23247-3},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-642-23246-6 978-3-642-23247-3},
  langid = {english},
  keywords = {Computational Intelligence,Memetic Algorithms,Memetic Computing},
  note = {\url{http://link.springer.com/10.1007/978-3-642-23247-3}}
}

@misc{NotionGestionTareas,
  title = {Notion - Gesti{\'o}n de Tareas},
  journal = {Notion},
  abstract = {Crea un panel personalizado para gestionar todas tus tareas de trabajo personales, a la vez que aportas informaci{\'o}n relevante de todo tu espacio de trabajo de Notion.},
  howpublished = {\url{https://www.notion.com/es-es/help/guides/personal-work-dashboard}},
  langid = {spanish}
}

@misc{NumPyV20Manual,
  title = {NumPy v2.0 Manual},
  howpublished = {\url{https://numpy.org/doc/2.0/index.html}}
}

@misc{Openpyxl313Documentation,
  title = {Openpyxl 3.1.3 documentation},
  howpublished = {\url{https://openpyxl.readthedocs.io/en/stable/}}
}

@misc{OriginalArtImages,
  title = {(Original) Art Images: Drawing/Painting/Sculptures/Engravings},
  shorttitle = {Art Images},
  abstract = {Dataset with about 9000 images containing 5 types of arts},
  howpublished = {\url{https://www.kaggle.com/datasets/thedownhill/art-images-drawings-painting-sculpture-engraving}},
  langid = {english}
}

@misc{OverviewGoogleCloud,
  title = {Overview Google Cloud},
  abstract = {An overview of Google Cloud Platform.},
  howpublished = {\url{https://cloud.google.com/docs/overview?hl=es-419}},
  langid = {spanish}
}

@misc{PolarsPythonAPI,
  title = {Polars --- Python API reference},
  howpublished = {\url{https://docs.pola.rs/api/python/stable/reference/}}
}

@misc{ReglamentoIA2024,
  title = {Reglamento (UE) 2024/1689 del Parlamento Europeo y del Consejo, de 13 de junio de 2024, sobre normas armonizadas en materia de inteligencia artificial},
  author = {{Parlamento Europeo y Consejo de la Uni{\'o}n Europea}},
  year = {2024},
  month = jul,
  howpublished = {\url{https://eur-lex.europa.eu/legal-content/ES/TXT/?uri=CELEX:32024R1689}},
  langid = {spanish}
}

@misc{ResNet50,
  title = {ResNet50},
  journal = {PyTorch},
  abstract = {Model Description},
  howpublished = {\url{https://pytorch.org/hub/nvidia_deeplearningexamples_resnet50/}},
  langid = {english}
}

@misc{RockPaperScissors,
  title = {Rock Paper Scissors Dataset},
  journal = {Roboflow},
  abstract = {Download 2925 free images labeled for classification.},
  howpublished = {\url{https://public.roboflow.com/classification/rock-paper-scissors}}
}

@misc{SalarioParaData,
  title = {Salario para Data Scientist en Espa{\~n}a - Salario Medio},
  journal = {Talent.com},
  abstract = {Data Scientist en Espa{\~n}a perciben un salario medio mensual {\texteuro} 3.389. Prueba la herramienta de salarios de Talent.com y descubre cu{\'a}l es el salario medio de los profesionales de la industria.},
  howpublished = {\url{https://es.talent.com/salary}},
  langid = {spanish}
}

@misc{sandlerMobileNetV2InvertedResiduals2019,
  title = {MobileNetV2: Inverted Residuals and Linear Bottlenecks},
  shorttitle = {MobileNetV2},
  author = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  year = {2019},
  month = mar,
  number = {arXiv:1801.04381},
  eprint = {1801.04381},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1801.04381},
  abstract = {In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3. The MobileNetV2 architecture is based on an inverted residual structure where the input and output of the residual block are thin bottleneck layers opposite to traditional residual models which use expanded representations in the input an MobileNetV2 uses lightweight depthwise convolutions to filter features in the intermediate expansion layer. Additionally, we find that it is important to remove non-linearities in the narrow layers in order to maintain representational power. We demonstrate that this improves performance and provide an intuition that led to this design. Finally, our approach allows decoupling of the input/output domains from the expressiveness of the transformation, which provides a convenient framework for further analysis. We measure our performance on Imagenet classification, COCO object detection, VOC image segmentation. We evaluate the trade-offs between accuracy, and number of operations measured by multiply-adds (MAdd), as well as the number of parameters},
  archiveprefix = {arXiv},
  howpublished = {\url{http://arxiv.org/abs/1801.04381}},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@misc{ScrumGuide,
  title = {Scrum Guide},
  howpublished = {\url{https://scrumguides.org/scrum-guide.html}}
}

@misc{Seaborn0132Documentation,
  title = {Seaborn 0.13.2 documentation},
  howpublished = {\url{https://seaborn.pydata.org/tutorial.html}}
}

@article{shortenSurveyImageData2019,
  title = {A survey on Image Data Augmentation for Deep Learning},
  author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
  year = {2019},
  month = jul,
  journal = {Journal of Big Data},
  volume = {6},
  number = {1},
  pages = {60},
  issn = {2196-1115},
  doi = {10.1186/s40537-019-0197-0},
  abstract = {Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.},
  note = {\url{https://doi.org/10.1186/s40537-019-0197-0}}
}

@book{sydenhamHandbookMeasuringSystem2005,
  title = {Handbook of measuring system design},
  editor = {Sydenham, Peter H. and Thorn, Richard},
  year = {2005},
  publisher = {Wiley},
  address = {Chichester},
  isbn = {978-0-470-02143-9},
  langid = {english}
}

@misc{TorchcudaPyTorch24,
  title = {torch.cuda --- PyTorch 2.4 documentation},
  howpublished = {\url{https://pytorch.org/docs/stable/cuda.html}}
}

@book{vanderplasPythonDataScience2016,
  title = {Python Data Science Handbook: Essential Tools for Working with Data},
  shorttitle = {Python Data Science Handbook},
  author = {VanderPlas, Jake},
  year = {2016},
  month = nov,
  publisher = {"O'Reilly Media, Inc."},
  abstract = {For many researchers, Python is a first-class tool mainly because of its libraries for storing, manipulating, and gaining insight from data. Several resources exist for individual pieces of this data science stack, but only with the Python Data Science Handbook do you get them all---IPython, NumPy, Pandas, Matplotlib, Scikit-Learn, and other related tools.Working scientists and data crunchers familiar with reading and writing Python code will find this comprehensive desk reference ideal for tackling day-to-day issues: manipulating, transforming, and cleaning data; visualizing different types of data; and using data to build statistical or machine learning models. Quite simply, this is the must-have reference for scientific computing in Python.With this handbook, you'll learn how to use:IPython and Jupyter: provide computational environments for data scientists using PythonNumPy: includes the ndarray for efficient storage and manipulation of dense data arrays in PythonPandas: features the DataFrame for efficient storage and manipulation of labeled/columnar data in PythonMatplotlib: includes capabilities for a flexible range of data visualizations in PythonScikit-Learn: for efficient and clean Python implementations of the most important and established machine learning algorithms},
  googlebooks = {xYmNDQAAQBAJ},
  isbn = {978-1-4919-1214-0},
  langid = {english},
  keywords = {Computers / Data Science / Data Modeling & Design,Computers / Data Science / Data Visualization,Computers / Languages / General,Computers / Languages / Python,Computers / Programming / Open Source,Science / Research & Methodology},
  note = {\url{https://books.google.es/books?hl=es&lr=&id=xYmNDQAAQBAJ&oi=fnd&pg=PR2&dq=Python+Data+Science+Handbook&ots=Xs9Rj3qj-M&sig=f5K5ixzKjH7pc2Uo2IYW9jrPNI8\#v=onepage&q=Python\%20Data\%20Science\%20Handbook&f=false}}
}

@book{weidmanDeepLearningScratch2019,
  title = {Deep Learning from Scratch: Building with Python from First Principles},
  author = {Weidman, S.},
  year = {2019},
  publisher = {O'Reilly Media, Incorporated},
  isbn = {978-1-4920-4141-2},
  lccn = {2020301331},
  note = {\url{https://books.google.es/books?id=PRSCwwEACAAJ}}
}

@misc{WhatCloudRun,
  title = {What is Cloud Run {\textbar} Cloud Run Documentation},
  howpublished = {\url{https://cloud.google.com/run/docs/overview/what-is-cloud-run}},
  langid = {english}
}

@article{zhaoReviewConvolutionalNeural2024,
  title = {A review of convolutional neural networks in computer vision},
  author = {Zhao, Xia and Wang, Limin and Zhang, Yufei and Han, Xuming and Deveci, Muhammet and Parmar, Milan},
  year = {2024},
  month = mar,
  journal = {Artificial Intelligence Review},
  volume = {57},
  number = {4},
  pages = {99},
  issn = {1573-7462},
  doi = {10.1007/s10462-024-10721-6},
  abstract = {In computer vision, a series of exemplary advances have been made in several areas involving image classification, semantic segmentation, object detection, and image super-resolution reconstruction with the rapid development of deep convolutional neural network (CNN). The CNN has superior features for autonomous learning and expression, and feature extraction from original input data can be realized by means of training CNN models that match practical applications. Due to the rapid progress in deep learning technology, the structure of CNN is becoming more and more complex and diverse. Consequently, it gradually replaces the traditional machine learning methods. This paper presents an elementary understanding of CNN components and their functions, including input layers, convolution layers, pooling layers, activation functions, batch normalization, dropout, fully connected layers, and output layers. On this basis, this paper gives a comprehensive overview of the past and current research status of the applications of CNN models in computer vision fields, e.g., image classification, object detection, and video prediction. In addition, we summarize the challenges and solutions of the deep CNN, and future research directions are also discussed.},
  langid = {english},
  keywords = {Artificial Intelligence,Computer vision,Convolutional neural networks,Deep learning,Status quo review},
  note = {\url{https://doi.org/10.1007/s10462-024-10721-6}}
}
