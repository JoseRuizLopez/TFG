\chapter*{}
%\thispagestyle{empty}
%\cleardoublepage

%\thispagestyle{empty}


\cleardoublepage
\thispagestyle{empty}

\begin{center}
{\large\bfseries Algoritmos meméticos para reducir datos de entrenamiento en modelos de aprendizaje profundo
convolucionales}\\
\end{center}
\begin{center}
José Ruiz López (alumno)\\
\end{center}

%\vspace{0.7cm}
\noindent{\textbf{Palabras clave}: Algoritmos meméticos, Imágenes, Modelos de Aprendizaje profundo convolucionales}\\

\vspace{0.7cm}
\noindent{\textbf{Resumen}}\\

Los \textbf{modelos de Aprendizaje Profundo} (Deep Learning) han supuesto un verdadero hito en la
\textbf{Inteligencia Artificial}, ya que son capaces de procesar grandes volúmenes de datos\ldots y, además, reconocer
patrones sumamente complejos.
Dentro de estos, los \textbf{modelos convolucionales} se han destacado como particularmente efectivos a la hora de
identificar objetos y características en imágenes —una capacidad esencial para muchas aplicaciones modernas—.
Sin embargo, a diferencia de los seres humanos, estos modelos requieren un número extremadamente alto de datos de
entrenamiento para cada categoría que deben aprender.
Esto implica un proceso de entrenamiento más largo y, muchas veces, la recolección de los datos necesarios puede ser
problemática, según el tipo de información que se necesite. \\[6pt]

Además de la dificultad en la obtención de datos, la reciente \textbf{legislación europea sobre IA}
(IA Act)~\cite{noauthor_ley_2024} establece la necesidad de auditar no solo los modelos, sino también los datos
utilizados para entrenarlos, especialmente cuando se trata de aplicaciones de IA que manejan datos sensibles.
Estas auditorías, por su propia naturaleza, se volverán más complejas conforme aumente el tamaño del conjunto de
entrenamiento.
Por lo tanto, se vuelve completamente necesario desarrollar estrategias que permitan
\textbf{reducir el tamaño de los conjuntos de datos de entrenamiento}\ldots sin comprometer la calidad del modelo.
\\[6pt]

Ya se ha demostrado que aumentar el número de imágenes de entrenamiento puede, en ciertos casos, mejorar el proceso;
sin embargo, esto solo sucede cuando las imágenes adicionales realmente contribuyen al aprendizaje.
De hecho, las \textbf{técnicas de aumento de datos} (Data Augmentation) permiten reducir la necesidad de muchas
imágenes similares, ya que estas pueden generarse de manera automática a partir de las ya existentes\ldots lo que además
evita problemas legales asociados a la autoría de los datos. \\[6pt]

En este trabajo, proponemos el uso de \textbf{algoritmos meméticos} combinados con
\textbf{métricas de similitud entre imágenes} para establecer un proceso de reducción del conjunto de
\textbf{entrenamiento} —lo que se conoce como \textbf{selección de instancias}—.
La idea es seleccionar un conjunto reducido de imágenes representativas que, junto con las técnicas de aumento de
datos, sean suficientes para entrenar modelos convolucionales con una calidad óptima.
De este modo, se podría reducir significativamente el tamaño del conjunto de entrenamiento, manteniendo la calidad
del aprendizaje y, a su vez, facilitando tanto el proceso de auditoría como la eficiencia computacional del sistema.
\\[6pt]


\cleardoublepage


\thispagestyle{empty}


\begin{center}
{\large\bfseries Memetic Algorithms for Reducing Training Data in Convolutional Deep Learning Models}\\
\end{center}
\begin{center}
José, Ruiz López (student)\\
\end{center}

%\vspace{0.7cm}
\noindent{\textbf{Keywords}: Memetic Algorithms, Images, Convolutional Deep Learning Models}\\

\vspace{0.7cm}
\noindent{\textbf{Abstract}}\\

\textbf{Deep Learning models} have marked a true milestone in \textbf{Artificial Intelligence}, as they are capable of
processing large volumes of data\ldots and, moreover, recognizing highly complex patterns.
Among these, \textbf{convolutional models} have proven to be particularly effective in identifying objects and
characteristics in images — an essential capability for many modern applications.
However, unlike humans, these models require an extremely high number of training data for each category they need to
learn.
This implies a longer training process, and often, the collection of the necessary data can be problematic, depending
on the type of information required. \\[6pt]

In addition to the difficulty of obtaining data, the recent \textbf{European AI legislation}
(IA Act)~\cite{noauthor_ley_2024} establishes the need to audit not only the models but also the data used to train
them, especially when dealing with AI applications that handle sensitive data.
These audits, by their very nature, will become more complex as the size of the training set increases.
Therefore, it becomes completely necessary to develop strategies that allow for
\textbf{reducing the size of training datasets}\ldots without compromising the quality of the model. \\[6pt]

It has already been demonstrated that increasing the number of training images can, in certain cases, improve the
process; however, this only happens when the additional images actually contribute to learning.
In fact, \textbf{Data Augmentation techniques} help reduce the need for many similar images, as these can be
automatically generated from existing ones\ldots which also avoids legal issues related to data authorship. \\[6pt]

In this work, we propose the use of \textbf{memetic algorithms}, combined with \textbf{image similarity metrics}, to
establish a process of \textbf{training dataset reduction} — known as \textbf{instance selection}.
The idea is to select a reduced set of representative images that, along with data augmentation techniques, are
sufficient to train convolutional models with optimal quality.
In this way, the size of the training dataset could be significantly reduced, while maintaining the quality of
learning and, at the same time, facilitating both the auditing process and the computational efficiency of the system.
\\[6pt]

\chapter*{}
\thispagestyle{empty}

\noindent\rule[-1ex]{\textwidth}{2pt}\\[4.5ex]

Yo, \textbf{José Ruiz López}, alumno de la titulación INGENIERÍA INFORMÁTICA de la \textbf{Escuela Técnica Superior
de Ingenierías Informática y de Telecomunicación de la Universidad de Granada}, con DNI \textbf{77964364E}, autorizo la
ubicación de la siguiente copia de mi Trabajo Fin de Grado en la biblioteca del centro para que pueda ser
consultada por las personas que lo deseen.

\vspace{6cm}

\noindent Fdo: José Ruiz López

\vspace{2cm}

\begin{flushright}
Granada a X de mes de 201 .
\end{flushright}


\chapter*{}
\thispagestyle{empty}

\noindent\rule[-1ex]{\textwidth}{2pt}\\[4.5ex]

D. \textbf{Daniel Molina Cabrera (tutor}, Profesor del Departamento Ciencias de la Computación e Inteligencia
Artificial de la Universidad de Granada.

\vspace{0.5cm}

\textbf{Informan:}

\vspace{0.5cm}

Que el presente trabajo, titulado \textit{\textbf{Algoritmos meméticos para reducir datos de entrenamiento en modelos
de aprendizaje profundo convolucionales}},
ha sido realizado bajo su supervisión por \textbf{José Ruiz López (alumno)}, y autorizamos la defensa de dicho trabajo
ante el tribunal que corresponda.

\vspace{0.5cm}

Y para que conste, expiden y firman el presente informe en Granada a X de mes de 201 .

\vspace{1cm}

\textbf{Los directores:}

\vspace{5cm}

\noindent \textbf{Daniel Molina Cabrera (tutor)}

\chapter*{Agradecimientos}
\thispagestyle{empty}

       \vspace{1cm}


Poner aquí agradecimientos...

