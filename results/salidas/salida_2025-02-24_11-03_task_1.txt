Task ID recibido: 1
GPU: True


--------------------------------------mobilenet  ALEATORIO  10%-------------------------------------------------
Start time: 2025-02-24 09:04:09.814417
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.00 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3456
Epoch 1/10, Batch 20/20, Loss: 1.2858
Epoch 1/10, Train Loss: 1.2999, Valid Loss: 1.0984
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9844
Epoch 2/10, Batch 20/20, Loss: 0.7927
Epoch 2/10, Train Loss: 0.8370, Valid Loss: 0.7854
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8123
Epoch 3/10, Batch 20/20, Loss: 0.9213
Epoch 3/10, Train Loss: 0.6442, Valid Loss: 0.6484
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5171
Epoch 4/10, Batch 20/20, Loss: 0.5158
Epoch 4/10, Train Loss: 0.5218, Valid Loss: 0.6016
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4658
Epoch 5/10, Batch 20/20, Loss: 0.4298
Epoch 5/10, Train Loss: 0.4496, Valid Loss: 0.5274
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6494
Epoch 6/10, Batch 20/20, Loss: 0.6205
Epoch 6/10, Train Loss: 0.4272, Valid Loss: 0.5181
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4017
Epoch 7/10, Batch 20/20, Loss: 0.3755
Epoch 7/10, Train Loss: 0.3627, Valid Loss: 0.4816
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4408
Epoch 8/10, Batch 20/20, Loss: 0.6091
Epoch 8/10, Train Loss: 0.3583, Valid Loss: 0.4741
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3408
Epoch 9/10, Batch 20/20, Loss: 0.3615
Epoch 9/10, Train Loss: 0.3096, Valid Loss: 0.4473
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3118
Epoch 10/10, Batch 20/20, Loss: 0.6187
Epoch 10/10, Train Loss: 0.3034, Valid Loss: 0.4417
Model saved!
Accuracy: 0.8785
Precision: 0.8731
Recall: 0.8785
F1-score: 0.8752
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 1. Fitness: 0.8785
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2281
Epoch 1/10, Batch 20/20, Loss: 1.2354
Epoch 1/10, Train Loss: 1.2820, Valid Loss: 1.0973
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9679
Epoch 2/10, Batch 20/20, Loss: 0.7288
Epoch 2/10, Train Loss: 0.8331, Valid Loss: 0.7795
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7613
Epoch 3/10, Batch 20/20, Loss: 0.6813
Epoch 3/10, Train Loss: 0.6344, Valid Loss: 0.6430
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5086
Epoch 4/10, Batch 20/20, Loss: 0.4881
Epoch 4/10, Train Loss: 0.5156, Valid Loss: 0.5710
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5033
Epoch 5/10, Batch 20/20, Loss: 0.7854
Epoch 5/10, Train Loss: 0.4774, Valid Loss: 0.5253
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6570
Epoch 6/10, Batch 20/20, Loss: 0.4226
Epoch 6/10, Train Loss: 0.4348, Valid Loss: 0.4808
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3558
Epoch 7/10, Batch 20/20, Loss: 0.4202
Epoch 7/10, Train Loss: 0.3785, Valid Loss: 0.4539
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4977
Epoch 8/10, Batch 20/20, Loss: 0.5224
Epoch 8/10, Train Loss: 0.3625, Valid Loss: 0.4420
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5525
Epoch 9/10, Batch 20/20, Loss: 0.3953
Epoch 9/10, Train Loss: 0.3269, Valid Loss: 0.4122
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3202
Epoch 10/10, Batch 20/20, Loss: 0.7211
Epoch 10/10, Train Loss: 0.3216, Valid Loss: 0.4043
Model saved!
Accuracy: 0.8832
Precision: 0.8790
Recall: 0.8832
F1-score: 0.8795
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 2. Fitness: 0.8832
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1690
Epoch 1/10, Batch 20/20, Loss: 1.4319
Epoch 1/10, Train Loss: 1.2763, Valid Loss: 1.0442
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9111
Epoch 2/10, Batch 20/20, Loss: 0.6478
Epoch 2/10, Train Loss: 0.7986, Valid Loss: 0.7428
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7871
Epoch 3/10, Batch 20/20, Loss: 0.8399
Epoch 3/10, Train Loss: 0.6142, Valid Loss: 0.6161
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4403
Epoch 4/10, Batch 20/20, Loss: 0.6244
Epoch 4/10, Train Loss: 0.5000, Valid Loss: 0.5388
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4681
Epoch 5/10, Batch 20/20, Loss: 0.6977
Epoch 5/10, Train Loss: 0.4351, Valid Loss: 0.4957
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4679
Epoch 6/10, Batch 20/20, Loss: 0.3687
Epoch 6/10, Train Loss: 0.3821, Valid Loss: 0.4658
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3969
Epoch 7/10, Batch 20/20, Loss: 0.5456
Epoch 7/10, Train Loss: 0.3498, Valid Loss: 0.4266
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4221
Epoch 8/10, Batch 20/20, Loss: 0.6250
Epoch 8/10, Train Loss: 0.3327, Valid Loss: 0.4128
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3423
Epoch 9/10, Batch 20/20, Loss: 0.4220
Epoch 9/10, Train Loss: 0.3018, Valid Loss: 0.3924
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.4444
Epoch 10/10, Batch 20/20, Loss: 0.3905
Epoch 10/10, Train Loss: 0.2680, Valid Loss: 0.3761
Model saved!
Accuracy: 0.8797
Precision: 0.8741
Recall: 0.8797
F1-score: 0.8744
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3620
Epoch 1/10, Batch 20/20, Loss: 1.3109
Epoch 1/10, Train Loss: 1.2954, Valid Loss: 1.0843
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9543
Epoch 2/10, Batch 20/20, Loss: 0.7638
Epoch 2/10, Train Loss: 0.8253, Valid Loss: 0.7606
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7502
Epoch 3/10, Batch 20/20, Loss: 0.9653
Epoch 3/10, Train Loss: 0.6404, Valid Loss: 0.6390
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5136
Epoch 4/10, Batch 20/20, Loss: 0.4242
Epoch 4/10, Train Loss: 0.5031, Valid Loss: 0.5760
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3761
Epoch 5/10, Batch 20/20, Loss: 0.7041
Epoch 5/10, Train Loss: 0.4504, Valid Loss: 0.5252
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5133
Epoch 6/10, Batch 20/20, Loss: 0.4259
Epoch 6/10, Train Loss: 0.4089, Valid Loss: 0.4909
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2499
Epoch 7/10, Batch 20/20, Loss: 0.3717
Epoch 7/10, Train Loss: 0.3497, Valid Loss: 0.4677
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3712
Epoch 8/10, Batch 20/20, Loss: 0.3442
Epoch 8/10, Train Loss: 0.3305, Valid Loss: 0.4499
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3407
Epoch 9/10, Batch 20/20, Loss: 0.6470
Epoch 9/10, Train Loss: 0.3077, Valid Loss: 0.4402
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2441
Epoch 10/10, Batch 20/20, Loss: 0.5407
Epoch 10/10, Train Loss: 0.2881, Valid Loss: 0.4286
Model saved!
Accuracy: 0.8843
Precision: 0.8787
Recall: 0.8843
F1-score: 0.8797
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 4. Fitness: 0.8843
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1926
Epoch 1/10, Batch 20/20, Loss: 1.2162
Epoch 1/10, Train Loss: 1.2764, Valid Loss: 1.0034
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9851
Epoch 2/10, Batch 20/20, Loss: 0.5704
Epoch 2/10, Train Loss: 0.7864, Valid Loss: 0.6827
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7531
Epoch 3/10, Batch 20/20, Loss: 0.6879
Epoch 3/10, Train Loss: 0.5928, Valid Loss: 0.5620
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3294
Epoch 4/10, Batch 20/20, Loss: 0.4289
Epoch 4/10, Train Loss: 0.4725, Valid Loss: 0.4906
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4067
Epoch 5/10, Batch 20/20, Loss: 0.7373
Epoch 5/10, Train Loss: 0.4290, Valid Loss: 0.4507
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5181
Epoch 6/10, Batch 20/20, Loss: 0.2942
Epoch 6/10, Train Loss: 0.3608, Valid Loss: 0.4083
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3528
Epoch 7/10, Batch 20/20, Loss: 0.5654
Epoch 7/10, Train Loss: 0.3345, Valid Loss: 0.3948
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4050
Epoch 8/10, Batch 20/20, Loss: 0.5599
Epoch 8/10, Train Loss: 0.3143, Valid Loss: 0.3879
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3805
Epoch 9/10, Batch 20/20, Loss: 0.5013
Epoch 9/10, Train Loss: 0.2842, Valid Loss: 0.3673
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2251
Epoch 10/10, Batch 20/20, Loss: 0.7908
Epoch 10/10, Train Loss: 0.2749, Valid Loss: 0.3619
Model saved!
Accuracy: 0.8820
Precision: 0.8753
Recall: 0.8820
F1-score: 0.8752
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3668
Epoch 1/10, Batch 20/20, Loss: 1.2316
Epoch 1/10, Train Loss: 1.2906, Valid Loss: 1.1409
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0611
Epoch 2/10, Batch 20/20, Loss: 0.6690
Epoch 2/10, Train Loss: 0.8364, Valid Loss: 0.8391
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8659
Epoch 3/10, Batch 20/20, Loss: 0.8521
Epoch 3/10, Train Loss: 0.6534, Valid Loss: 0.7053
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4331
Epoch 4/10, Batch 20/20, Loss: 0.8521
Epoch 4/10, Train Loss: 0.5464, Valid Loss: 0.6262
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4797
Epoch 5/10, Batch 20/20, Loss: 0.6421
Epoch 5/10, Train Loss: 0.4625, Valid Loss: 0.5877
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5031
Epoch 6/10, Batch 20/20, Loss: 0.4643
Epoch 6/10, Train Loss: 0.4112, Valid Loss: 0.5411
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4067
Epoch 7/10, Batch 20/20, Loss: 0.4545
Epoch 7/10, Train Loss: 0.3688, Valid Loss: 0.5234
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3979
Epoch 8/10, Batch 20/20, Loss: 0.6512
Epoch 8/10, Train Loss: 0.3566, Valid Loss: 0.4941
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3083
Epoch 9/10, Batch 20/20, Loss: 0.3718
Epoch 9/10, Train Loss: 0.3160, Valid Loss: 0.4913
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3568
Epoch 10/10, Batch 20/20, Loss: 0.4826
Epoch 10/10, Train Loss: 0.2925, Valid Loss: 0.4864
Model saved!
Accuracy: 0.8797
Precision: 0.8751
Recall: 0.8797
F1-score: 0.8754
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1871
Epoch 1/10, Batch 20/20, Loss: 1.3154
Epoch 1/10, Train Loss: 1.2896, Valid Loss: 1.0483
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9807
Epoch 2/10, Batch 20/20, Loss: 0.5442
Epoch 2/10, Train Loss: 0.8135, Valid Loss: 0.7744
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7475
Epoch 3/10, Batch 20/20, Loss: 0.7478
Epoch 3/10, Train Loss: 0.6226, Valid Loss: 0.6557
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5213
Epoch 4/10, Batch 20/20, Loss: 0.7397
Epoch 4/10, Train Loss: 0.5170, Valid Loss: 0.5929
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5795
Epoch 5/10, Batch 20/20, Loss: 0.6287
Epoch 5/10, Train Loss: 0.4425, Valid Loss: 0.5476
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5304
Epoch 6/10, Batch 20/20, Loss: 0.3273
Epoch 6/10, Train Loss: 0.3878, Valid Loss: 0.5235
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2672
Epoch 7/10, Batch 20/20, Loss: 0.6084
Epoch 7/10, Train Loss: 0.3571, Valid Loss: 0.5159
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4661
Epoch 8/10, Batch 20/20, Loss: 0.3870
Epoch 8/10, Train Loss: 0.3247, Valid Loss: 0.4962
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4020
Epoch 9/10, Batch 20/20, Loss: 0.5188
Epoch 9/10, Train Loss: 0.3029, Valid Loss: 0.4714
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2800
Epoch 10/10, Batch 20/20, Loss: 0.6116
Epoch 10/10, Train Loss: 0.2923, Valid Loss: 0.4777
Accuracy: 0.8949
Precision: 0.8909
Recall: 0.8949
F1-score: 0.8923
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 7. Fitness: 0.8949
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2040
Epoch 1/10, Batch 20/20, Loss: 1.2694
Epoch 1/10, Train Loss: 1.2806, Valid Loss: 1.0332
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0119
Epoch 2/10, Batch 20/20, Loss: 0.7725
Epoch 2/10, Train Loss: 0.8278, Valid Loss: 0.7160
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7865
Epoch 3/10, Batch 20/20, Loss: 0.8990
Epoch 3/10, Train Loss: 0.6351, Valid Loss: 0.5814
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4101
Epoch 4/10, Batch 20/20, Loss: 0.6674
Epoch 4/10, Train Loss: 0.5129, Valid Loss: 0.5130
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4207
Epoch 5/10, Batch 20/20, Loss: 0.6629
Epoch 5/10, Train Loss: 0.4343, Valid Loss: 0.4614
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6001
Epoch 6/10, Batch 20/20, Loss: 0.3802
Epoch 6/10, Train Loss: 0.3940, Valid Loss: 0.4228
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2869
Epoch 7/10, Batch 20/20, Loss: 0.5920
Epoch 7/10, Train Loss: 0.3530, Valid Loss: 0.3984
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4178
Epoch 8/10, Batch 20/20, Loss: 0.5947
Epoch 8/10, Train Loss: 0.3433, Valid Loss: 0.3881
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2758
Epoch 9/10, Batch 20/20, Loss: 0.5486
Epoch 9/10, Train Loss: 0.3153, Valid Loss: 0.3711
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3894
Epoch 10/10, Batch 20/20, Loss: 0.7816
Epoch 10/10, Train Loss: 0.3027, Valid Loss: 0.3585
Model saved!
Accuracy: 0.8890
Precision: 0.8881
Recall: 0.8890
F1-score: 0.8865
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3135
Epoch 1/10, Batch 20/20, Loss: 1.1877
Epoch 1/10, Train Loss: 1.2941, Valid Loss: 1.0882
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0545
Epoch 2/10, Batch 20/20, Loss: 0.6337
Epoch 2/10, Train Loss: 0.8331, Valid Loss: 0.7812
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7355
Epoch 3/10, Batch 20/20, Loss: 0.7892
Epoch 3/10, Train Loss: 0.6407, Valid Loss: 0.6578
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5152
Epoch 4/10, Batch 20/20, Loss: 0.4700
Epoch 4/10, Train Loss: 0.5295, Valid Loss: 0.5738
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4273
Epoch 5/10, Batch 20/20, Loss: 0.7518
Epoch 5/10, Train Loss: 0.4776, Valid Loss: 0.5331
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5891
Epoch 6/10, Batch 20/20, Loss: 0.8944
Epoch 6/10, Train Loss: 0.4296, Valid Loss: 0.4964
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2631
Epoch 7/10, Batch 20/20, Loss: 0.5022
Epoch 7/10, Train Loss: 0.3719, Valid Loss: 0.4736
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3597
Epoch 8/10, Batch 20/20, Loss: 0.2405
Epoch 8/10, Train Loss: 0.3436, Valid Loss: 0.4474
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4357
Epoch 9/10, Batch 20/20, Loss: 0.4028
Epoch 9/10, Train Loss: 0.3110, Valid Loss: 0.4323
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3033
Epoch 10/10, Batch 20/20, Loss: 0.5932
Epoch 10/10, Train Loss: 0.3063, Valid Loss: 0.4269
Model saved!
Accuracy: 0.8890
Precision: 0.8848
Recall: 0.8890
F1-score: 0.8856
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2766
Epoch 1/10, Batch 20/20, Loss: 1.2727
Epoch 1/10, Train Loss: 1.2893, Valid Loss: 1.0693
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9214
Epoch 2/10, Batch 20/20, Loss: 0.6116
Epoch 2/10, Train Loss: 0.8078, Valid Loss: 0.7560
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7025
Epoch 3/10, Batch 20/20, Loss: 0.7800
Epoch 3/10, Train Loss: 0.6199, Valid Loss: 0.6174
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5723
Epoch 4/10, Batch 20/20, Loss: 0.5983
Epoch 4/10, Train Loss: 0.4953, Valid Loss: 0.5471
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3602
Epoch 5/10, Batch 20/20, Loss: 0.5935
Epoch 5/10, Train Loss: 0.4339, Valid Loss: 0.4821
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5045
Epoch 6/10, Batch 20/20, Loss: 0.3318
Epoch 6/10, Train Loss: 0.3847, Valid Loss: 0.4478
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3652
Epoch 7/10, Batch 20/20, Loss: 0.4332
Epoch 7/10, Train Loss: 0.3517, Valid Loss: 0.4195
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4016
Epoch 8/10, Batch 20/20, Loss: 0.3574
Epoch 8/10, Train Loss: 0.3221, Valid Loss: 0.4018
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2861
Epoch 9/10, Batch 20/20, Loss: 0.7415
Epoch 9/10, Train Loss: 0.3133, Valid Loss: 0.3796
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3131
Epoch 10/10, Batch 20/20, Loss: 0.5130
Epoch 10/10, Train Loss: 0.2826, Valid Loss: 0.3671
Model saved!
Accuracy: 0.8925
Precision: 0.8881
Recall: 0.8925
F1-score: 0.8892
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2404
Epoch 1/10, Batch 20/20, Loss: 1.2490
Epoch 1/10, Train Loss: 1.2876, Valid Loss: 1.0630
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9193
Epoch 2/10, Batch 20/20, Loss: 0.6128
Epoch 2/10, Train Loss: 0.8164, Valid Loss: 0.7709
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7457
Epoch 3/10, Batch 20/20, Loss: 0.7153
Epoch 3/10, Train Loss: 0.6182, Valid Loss: 0.6457
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5282
Epoch 4/10, Batch 20/20, Loss: 0.5817
Epoch 4/10, Train Loss: 0.5201, Valid Loss: 0.5680
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4506
Epoch 5/10, Batch 20/20, Loss: 0.7438
Epoch 5/10, Train Loss: 0.4554, Valid Loss: 0.5347
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6148
Epoch 6/10, Batch 20/20, Loss: 0.5898
Epoch 6/10, Train Loss: 0.4118, Valid Loss: 0.4898
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4008
Epoch 7/10, Batch 20/20, Loss: 0.4544
Epoch 7/10, Train Loss: 0.3595, Valid Loss: 0.4743
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3333
Epoch 8/10, Batch 20/20, Loss: 0.5704
Epoch 8/10, Train Loss: 0.3408, Valid Loss: 0.4484
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4486
Epoch 9/10, Batch 20/20, Loss: 0.7721
Epoch 9/10, Train Loss: 0.3196, Valid Loss: 0.4330
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2859
Epoch 10/10, Batch 20/20, Loss: 0.4731
Epoch 10/10, Train Loss: 0.2893, Valid Loss: 0.4273
Model saved!
Accuracy: 0.8867
Precision: 0.8810
Recall: 0.8867
F1-score: 0.8809
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2750
Epoch 1/10, Batch 20/20, Loss: 1.1829
Epoch 1/10, Train Loss: 1.2866, Valid Loss: 1.0466
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9326
Epoch 2/10, Batch 20/20, Loss: 0.5880
Epoch 2/10, Train Loss: 0.7961, Valid Loss: 0.7380
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6785
Epoch 3/10, Batch 20/20, Loss: 0.7536
Epoch 3/10, Train Loss: 0.6131, Valid Loss: 0.6166
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4961
Epoch 4/10, Batch 20/20, Loss: 0.3916
Epoch 4/10, Train Loss: 0.4891, Valid Loss: 0.5535
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3461
Epoch 5/10, Batch 20/20, Loss: 0.5355
Epoch 5/10, Train Loss: 0.4428, Valid Loss: 0.5065
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5860
Epoch 6/10, Batch 20/20, Loss: 0.2967
Epoch 6/10, Train Loss: 0.4004, Valid Loss: 0.4713
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2964
Epoch 7/10, Batch 20/20, Loss: 0.2828
Epoch 7/10, Train Loss: 0.3392, Valid Loss: 0.4463
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3560
Epoch 8/10, Batch 20/20, Loss: 0.2442
Epoch 8/10, Train Loss: 0.3225, Valid Loss: 0.4301
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3309
Epoch 9/10, Batch 20/20, Loss: 0.2585
Epoch 9/10, Train Loss: 0.2942, Valid Loss: 0.4201
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3484
Epoch 10/10, Batch 20/20, Loss: 0.7467
Epoch 10/10, Train Loss: 0.3107, Valid Loss: 0.4124
Model saved!
Accuracy: 0.8797
Precision: 0.8719
Recall: 0.8797
F1-score: 0.8726
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2247
Epoch 1/10, Batch 20/20, Loss: 1.3694
Epoch 1/10, Train Loss: 1.2680, Valid Loss: 1.0088
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8330
Epoch 2/10, Batch 20/20, Loss: 0.6516
Epoch 2/10, Train Loss: 0.7968, Valid Loss: 0.6873
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7780
Epoch 3/10, Batch 20/20, Loss: 0.9539
Epoch 3/10, Train Loss: 0.6215, Valid Loss: 0.5647
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4604
Epoch 4/10, Batch 20/20, Loss: 0.5500
Epoch 4/10, Train Loss: 0.4984, Valid Loss: 0.4846
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5605
Epoch 5/10, Batch 20/20, Loss: 0.7430
Epoch 5/10, Train Loss: 0.4450, Valid Loss: 0.4363
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4451
Epoch 6/10, Batch 20/20, Loss: 0.7055
Epoch 6/10, Train Loss: 0.3872, Valid Loss: 0.4073
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3275
Epoch 7/10, Batch 20/20, Loss: 0.3924
Epoch 7/10, Train Loss: 0.3477, Valid Loss: 0.3809
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4844
Epoch 8/10, Batch 20/20, Loss: 0.4872
Epoch 8/10, Train Loss: 0.3382, Valid Loss: 0.3645
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4485
Epoch 9/10, Batch 20/20, Loss: 0.3115
Epoch 9/10, Train Loss: 0.2886, Valid Loss: 0.3486
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1902
Epoch 10/10, Batch 20/20, Loss: 0.2959
Epoch 10/10, Train Loss: 0.2619, Valid Loss: 0.3294
Model saved!
Accuracy: 0.8808
Precision: 0.8775
Recall: 0.8808
F1-score: 0.8765
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3635
Epoch 1/10, Batch 20/20, Loss: 1.2774
Epoch 1/10, Train Loss: 1.2790, Valid Loss: 1.0698
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8966
Epoch 2/10, Batch 20/20, Loss: 0.5978
Epoch 2/10, Train Loss: 0.7978, Valid Loss: 0.7444
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8444
Epoch 3/10, Batch 20/20, Loss: 0.6892
Epoch 3/10, Train Loss: 0.6090, Valid Loss: 0.6148
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4396
Epoch 4/10, Batch 20/20, Loss: 0.4212
Epoch 4/10, Train Loss: 0.4832, Valid Loss: 0.5391
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4042
Epoch 5/10, Batch 20/20, Loss: 0.6391
Epoch 5/10, Train Loss: 0.4229, Valid Loss: 0.4821
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5007
Epoch 6/10, Batch 20/20, Loss: 0.5034
Epoch 6/10, Train Loss: 0.3892, Valid Loss: 0.4476
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3139
Epoch 7/10, Batch 20/20, Loss: 0.3522
Epoch 7/10, Train Loss: 0.3369, Valid Loss: 0.4272
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3105
Epoch 8/10, Batch 20/20, Loss: 0.1798
Epoch 8/10, Train Loss: 0.3068, Valid Loss: 0.4038
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3392
Epoch 9/10, Batch 20/20, Loss: 0.6954
Epoch 9/10, Train Loss: 0.3141, Valid Loss: 0.3860
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2252
Epoch 10/10, Batch 20/20, Loss: 0.7544
Epoch 10/10, Train Loss: 0.2910, Valid Loss: 0.3857
Model saved!
Accuracy: 0.8797
Precision: 0.8786
Recall: 0.8797
F1-score: 0.8741
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1679
Epoch 1/10, Batch 20/20, Loss: 1.2494
Epoch 1/10, Train Loss: 1.2869, Valid Loss: 1.0714
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9537
Epoch 2/10, Batch 20/20, Loss: 0.8241
Epoch 2/10, Train Loss: 0.8190, Valid Loss: 0.7457
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7049
Epoch 3/10, Batch 20/20, Loss: 0.7180
Epoch 3/10, Train Loss: 0.6119, Valid Loss: 0.6242
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4876
Epoch 4/10, Batch 20/20, Loss: 0.5616
Epoch 4/10, Train Loss: 0.4936, Valid Loss: 0.5516
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3720
Epoch 5/10, Batch 20/20, Loss: 0.4515
Epoch 5/10, Train Loss: 0.4422, Valid Loss: 0.4982
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6153
Epoch 6/10, Batch 20/20, Loss: 0.5255
Epoch 6/10, Train Loss: 0.4135, Valid Loss: 0.4583
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2162
Epoch 7/10, Batch 20/20, Loss: 0.5048
Epoch 7/10, Train Loss: 0.3438, Valid Loss: 0.4361
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5485
Epoch 8/10, Batch 20/20, Loss: 0.3728
Epoch 8/10, Train Loss: 0.3316, Valid Loss: 0.4232
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3020
Epoch 9/10, Batch 20/20, Loss: 0.7712
Epoch 9/10, Train Loss: 0.3266, Valid Loss: 0.3953
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3178
Epoch 10/10, Batch 20/20, Loss: 0.9310
Epoch 10/10, Train Loss: 0.3056, Valid Loss: 0.4080
Accuracy: 0.8843
Precision: 0.8766
Recall: 0.8843
F1-score: 0.8778
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2316
Epoch 1/10, Batch 20/20, Loss: 1.2937
Epoch 1/10, Train Loss: 1.2998, Valid Loss: 1.0611
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8517
Epoch 2/10, Batch 20/20, Loss: 0.5728
Epoch 2/10, Train Loss: 0.8033, Valid Loss: 0.7443
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6977
Epoch 3/10, Batch 20/20, Loss: 0.8291
Epoch 3/10, Train Loss: 0.6184, Valid Loss: 0.6128
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5692
Epoch 4/10, Batch 20/20, Loss: 0.4228
Epoch 4/10, Train Loss: 0.4905, Valid Loss: 0.5294
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4961
Epoch 5/10, Batch 20/20, Loss: 0.6279
Epoch 5/10, Train Loss: 0.4411, Valid Loss: 0.4786
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4681
Epoch 6/10, Batch 20/20, Loss: 0.3789
Epoch 6/10, Train Loss: 0.3827, Valid Loss: 0.4486
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3450
Epoch 7/10, Batch 20/20, Loss: 0.3032
Epoch 7/10, Train Loss: 0.3410, Valid Loss: 0.4305
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4088
Epoch 8/10, Batch 20/20, Loss: 0.2961
Epoch 8/10, Train Loss: 0.3188, Valid Loss: 0.3930
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3829
Epoch 9/10, Batch 20/20, Loss: 0.5108
Epoch 9/10, Train Loss: 0.3064, Valid Loss: 0.3833
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2175
Epoch 10/10, Batch 20/20, Loss: 0.6555
Epoch 10/10, Train Loss: 0.2756, Valid Loss: 0.3723
Model saved!
Accuracy: 0.8914
Precision: 0.8858
Recall: 0.8914
F1-score: 0.8872
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2028
Epoch 1/10, Batch 20/20, Loss: 1.4314
Epoch 1/10, Train Loss: 1.3064, Valid Loss: 1.1157
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9949
Epoch 2/10, Batch 20/20, Loss: 0.5181
Epoch 2/10, Train Loss: 0.8389, Valid Loss: 0.7901
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8429
Epoch 3/10, Batch 20/20, Loss: 0.7618
Epoch 3/10, Train Loss: 0.6542, Valid Loss: 0.6687
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5000
Epoch 4/10, Batch 20/20, Loss: 0.4232
Epoch 4/10, Train Loss: 0.5173, Valid Loss: 0.5755
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4709
Epoch 5/10, Batch 20/20, Loss: 0.8670
Epoch 5/10, Train Loss: 0.4653, Valid Loss: 0.5381
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5813
Epoch 6/10, Batch 20/20, Loss: 0.3633
Epoch 6/10, Train Loss: 0.4009, Valid Loss: 0.5039
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4324
Epoch 7/10, Batch 20/20, Loss: 0.5992
Epoch 7/10, Train Loss: 0.3675, Valid Loss: 0.4760
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4777
Epoch 8/10, Batch 20/20, Loss: 0.6259
Epoch 8/10, Train Loss: 0.3382, Valid Loss: 0.4550
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3113
Epoch 9/10, Batch 20/20, Loss: 0.4665
Epoch 9/10, Train Loss: 0.3002, Valid Loss: 0.4330
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3011
Epoch 10/10, Batch 20/20, Loss: 0.6921
Epoch 10/10, Train Loss: 0.3086, Valid Loss: 0.4323
Model saved!
Accuracy: 0.8914
Precision: 0.8883
Recall: 0.8914
F1-score: 0.8872
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1466
Epoch 1/10, Batch 20/20, Loss: 1.1213
Epoch 1/10, Train Loss: 1.2637, Valid Loss: 0.9978
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9649
Epoch 2/10, Batch 20/20, Loss: 0.6357
Epoch 2/10, Train Loss: 0.7866, Valid Loss: 0.7155
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6514
Epoch 3/10, Batch 20/20, Loss: 0.7686
Epoch 3/10, Train Loss: 0.6046, Valid Loss: 0.6049
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4677
Epoch 4/10, Batch 20/20, Loss: 0.5326
Epoch 4/10, Train Loss: 0.4941, Valid Loss: 0.5363
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4817
Epoch 5/10, Batch 20/20, Loss: 0.7694
Epoch 5/10, Train Loss: 0.4338, Valid Loss: 0.4958
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4601
Epoch 6/10, Batch 20/20, Loss: 0.5216
Epoch 6/10, Train Loss: 0.3772, Valid Loss: 0.4761
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2248
Epoch 7/10, Batch 20/20, Loss: 0.4254
Epoch 7/10, Train Loss: 0.3430, Valid Loss: 0.4511
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3453
Epoch 8/10, Batch 20/20, Loss: 0.4398
Epoch 8/10, Train Loss: 0.3181, Valid Loss: 0.4318
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2603
Epoch 9/10, Batch 20/20, Loss: 0.5577
Epoch 9/10, Train Loss: 0.3023, Valid Loss: 0.4150
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2733
Epoch 10/10, Batch 20/20, Loss: 0.9045
Epoch 10/10, Train Loss: 0.2920, Valid Loss: 0.4200
Accuracy: 0.8902
Precision: 0.8837
Recall: 0.8902
F1-score: 0.8825
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1836
Epoch 1/10, Batch 20/20, Loss: 1.2280
Epoch 1/10, Train Loss: 1.2877, Valid Loss: 1.0255
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9582
Epoch 2/10, Batch 20/20, Loss: 0.6194
Epoch 2/10, Train Loss: 0.8131, Valid Loss: 0.7174
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6903
Epoch 3/10, Batch 20/20, Loss: 0.7996
Epoch 3/10, Train Loss: 0.6270, Valid Loss: 0.6065
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5370
Epoch 4/10, Batch 20/20, Loss: 0.6469
Epoch 4/10, Train Loss: 0.5045, Valid Loss: 0.5349
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4199
Epoch 5/10, Batch 20/20, Loss: 0.6522
Epoch 5/10, Train Loss: 0.4377, Valid Loss: 0.5023
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5460
Epoch 6/10, Batch 20/20, Loss: 0.3901
Epoch 6/10, Train Loss: 0.3824, Valid Loss: 0.4680
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3068
Epoch 7/10, Batch 20/20, Loss: 0.3591
Epoch 7/10, Train Loss: 0.3320, Valid Loss: 0.4479
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4391
Epoch 8/10, Batch 20/20, Loss: 0.3498
Epoch 8/10, Train Loss: 0.3128, Valid Loss: 0.4379
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3497
Epoch 9/10, Batch 20/20, Loss: 0.6476
Epoch 9/10, Train Loss: 0.3161, Valid Loss: 0.4269
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3333
Epoch 10/10, Batch 20/20, Loss: 0.9533
Epoch 10/10, Train Loss: 0.3001, Valid Loss: 0.4163
Model saved!
Accuracy: 0.8855
Precision: 0.8794
Recall: 0.8855
F1-score: 0.8801
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2484
Epoch 1/10, Batch 20/20, Loss: 1.3665
Epoch 1/10, Train Loss: 1.2895, Valid Loss: 1.0147
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9566
Epoch 2/10, Batch 20/20, Loss: 0.5179
Epoch 2/10, Train Loss: 0.8116, Valid Loss: 0.6907
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7449
Epoch 3/10, Batch 20/20, Loss: 0.8940
Epoch 3/10, Train Loss: 0.6332, Valid Loss: 0.5620
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5185
Epoch 4/10, Batch 20/20, Loss: 0.4738
Epoch 4/10, Train Loss: 0.5032, Valid Loss: 0.4983
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5359
Epoch 5/10, Batch 20/20, Loss: 0.4576
Epoch 5/10, Train Loss: 0.4381, Valid Loss: 0.4581
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5012
Epoch 6/10, Batch 20/20, Loss: 0.7225
Epoch 6/10, Train Loss: 0.4079, Valid Loss: 0.4257
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2857
Epoch 7/10, Batch 20/20, Loss: 0.4869
Epoch 7/10, Train Loss: 0.3387, Valid Loss: 0.4084
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4367
Epoch 8/10, Batch 20/20, Loss: 0.4783
Epoch 8/10, Train Loss: 0.3224, Valid Loss: 0.3908
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4314
Epoch 9/10, Batch 20/20, Loss: 0.4261
Epoch 9/10, Train Loss: 0.3008, Valid Loss: 0.3750
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3392
Epoch 10/10, Batch 20/20, Loss: 0.6824
Epoch 10/10, Train Loss: 0.2929, Valid Loss: 0.3812
Accuracy: 0.8902
Precision: 0.8841
Recall: 0.8902
F1-score: 0.8843
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1956
Epoch 1/10, Batch 20/20, Loss: 1.2852
Epoch 1/10, Train Loss: 1.2817, Valid Loss: 1.1307
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8714
Epoch 2/10, Batch 20/20, Loss: 0.5400
Epoch 2/10, Train Loss: 0.7892, Valid Loss: 0.8142
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6946
Epoch 3/10, Batch 20/20, Loss: 0.8012
Epoch 3/10, Train Loss: 0.6050, Valid Loss: 0.6974
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4043
Epoch 4/10, Batch 20/20, Loss: 0.4640
Epoch 4/10, Train Loss: 0.4783, Valid Loss: 0.6162
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3525
Epoch 5/10, Batch 20/20, Loss: 0.4799
Epoch 5/10, Train Loss: 0.4005, Valid Loss: 0.5757
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5171
Epoch 6/10, Batch 20/20, Loss: 0.4224
Epoch 6/10, Train Loss: 0.3709, Valid Loss: 0.5393
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2668
Epoch 7/10, Batch 20/20, Loss: 0.3099
Epoch 7/10, Train Loss: 0.3127, Valid Loss: 0.5114
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3955
Epoch 8/10, Batch 20/20, Loss: 0.4929
Epoch 8/10, Train Loss: 0.3081, Valid Loss: 0.4867
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2894
Epoch 9/10, Batch 20/20, Loss: 0.4715
Epoch 9/10, Train Loss: 0.2776, Valid Loss: 0.4814
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1687
Epoch 10/10, Batch 20/20, Loss: 0.7125
Epoch 10/10, Train Loss: 0.2633, Valid Loss: 0.4705
Model saved!
Accuracy: 0.8785
Precision: 0.8730
Recall: 0.8785
F1-score: 0.8729
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2804
Epoch 1/10, Batch 20/20, Loss: 1.2360
Epoch 1/10, Train Loss: 1.2919, Valid Loss: 1.0921
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8369
Epoch 2/10, Batch 20/20, Loss: 0.7879
Epoch 2/10, Train Loss: 0.8293, Valid Loss: 0.7827
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8120
Epoch 3/10, Batch 20/20, Loss: 0.9136
Epoch 3/10, Train Loss: 0.6453, Valid Loss: 0.6540
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5078
Epoch 4/10, Batch 20/20, Loss: 0.5386
Epoch 4/10, Train Loss: 0.5092, Valid Loss: 0.5960
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3772
Epoch 5/10, Batch 20/20, Loss: 0.7494
Epoch 5/10, Train Loss: 0.4581, Valid Loss: 0.5483
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4684
Epoch 6/10, Batch 20/20, Loss: 0.6033
Epoch 6/10, Train Loss: 0.4216, Valid Loss: 0.5177
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2996
Epoch 7/10, Batch 20/20, Loss: 0.4708
Epoch 7/10, Train Loss: 0.3572, Valid Loss: 0.4974
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3929
Epoch 8/10, Batch 20/20, Loss: 0.2761
Epoch 8/10, Train Loss: 0.3270, Valid Loss: 0.4837
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3254
Epoch 9/10, Batch 20/20, Loss: 0.7551
Epoch 9/10, Train Loss: 0.3250, Valid Loss: 0.4694
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2783
Epoch 10/10, Batch 20/20, Loss: 0.4577
Epoch 10/10, Train Loss: 0.2957, Valid Loss: 0.4800
Accuracy: 0.8808
Precision: 0.8758
Recall: 0.8808
F1-score: 0.8771
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2139
Epoch 1/10, Batch 20/20, Loss: 1.3364
Epoch 1/10, Train Loss: 1.2719, Valid Loss: 1.0678
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9250
Epoch 2/10, Batch 20/20, Loss: 0.7087
Epoch 2/10, Train Loss: 0.7877, Valid Loss: 0.7526
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7628
Epoch 3/10, Batch 20/20, Loss: 0.8661
Epoch 3/10, Train Loss: 0.5997, Valid Loss: 0.6330
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5913
Epoch 4/10, Batch 20/20, Loss: 0.3597
Epoch 4/10, Train Loss: 0.4596, Valid Loss: 0.5610
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4476
Epoch 5/10, Batch 20/20, Loss: 0.6306
Epoch 5/10, Train Loss: 0.4115, Valid Loss: 0.5173
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5391
Epoch 6/10, Batch 20/20, Loss: 0.5202
Epoch 6/10, Train Loss: 0.3602, Valid Loss: 0.4835
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2542
Epoch 7/10, Batch 20/20, Loss: 0.3544
Epoch 7/10, Train Loss: 0.3200, Valid Loss: 0.4576
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3432
Epoch 8/10, Batch 20/20, Loss: 0.2233
Epoch 8/10, Train Loss: 0.2890, Valid Loss: 0.4418
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3419
Epoch 9/10, Batch 20/20, Loss: 0.4593
Epoch 9/10, Train Loss: 0.2701, Valid Loss: 0.4368
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3041
Epoch 10/10, Batch 20/20, Loss: 0.3753
Epoch 10/10, Train Loss: 0.2488, Valid Loss: 0.4251
Model saved!
Accuracy: 0.8832
Precision: 0.8747
Recall: 0.8832
F1-score: 0.8756
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3293
Epoch 1/10, Batch 20/20, Loss: 1.3720
Epoch 1/10, Train Loss: 1.2889, Valid Loss: 1.0529
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8209
Epoch 2/10, Batch 20/20, Loss: 0.6748
Epoch 2/10, Train Loss: 0.8125, Valid Loss: 0.7366
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8591
Epoch 3/10, Batch 20/20, Loss: 0.8309
Epoch 3/10, Train Loss: 0.6231, Valid Loss: 0.6165
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4466
Epoch 4/10, Batch 20/20, Loss: 0.5108
Epoch 4/10, Train Loss: 0.4946, Valid Loss: 0.5493
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4756
Epoch 5/10, Batch 20/20, Loss: 0.7171
Epoch 5/10, Train Loss: 0.4348, Valid Loss: 0.5036
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6315
Epoch 6/10, Batch 20/20, Loss: 0.4242
Epoch 6/10, Train Loss: 0.3905, Valid Loss: 0.4700
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2886
Epoch 7/10, Batch 20/20, Loss: 0.3686
Epoch 7/10, Train Loss: 0.3434, Valid Loss: 0.4442
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4332
Epoch 8/10, Batch 20/20, Loss: 0.3560
Epoch 8/10, Train Loss: 0.3142, Valid Loss: 0.4404
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3373
Epoch 9/10, Batch 20/20, Loss: 0.4234
Epoch 9/10, Train Loss: 0.2992, Valid Loss: 0.4162
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2707
Epoch 10/10, Batch 20/20, Loss: 0.5196
Epoch 10/10, Train Loss: 0.2835, Valid Loss: 0.4211
Accuracy: 0.8960
Precision: 0.8908
Recall: 0.8960
F1-score: 0.8924
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 24. Fitness: 0.8960
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1727
Epoch 1/10, Batch 20/20, Loss: 1.3449
Epoch 1/10, Train Loss: 1.2802, Valid Loss: 0.9703
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9185
Epoch 2/10, Batch 20/20, Loss: 0.5652
Epoch 2/10, Train Loss: 0.7808, Valid Loss: 0.6885
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7604
Epoch 3/10, Batch 20/20, Loss: 0.8497
Epoch 3/10, Train Loss: 0.6066, Valid Loss: 0.5586
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5426
Epoch 4/10, Batch 20/20, Loss: 0.5520
Epoch 4/10, Train Loss: 0.4883, Valid Loss: 0.4870
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3868
Epoch 5/10, Batch 20/20, Loss: 0.7074
Epoch 5/10, Train Loss: 0.4351, Valid Loss: 0.4359
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6014
Epoch 6/10, Batch 20/20, Loss: 0.4169
Epoch 6/10, Train Loss: 0.3789, Valid Loss: 0.4051
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3932
Epoch 7/10, Batch 20/20, Loss: 0.2914
Epoch 7/10, Train Loss: 0.3285, Valid Loss: 0.3866
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5402
Epoch 8/10, Batch 20/20, Loss: 0.5014
Epoch 8/10, Train Loss: 0.3230, Valid Loss: 0.3762
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3854
Epoch 9/10, Batch 20/20, Loss: 0.5278
Epoch 9/10, Train Loss: 0.2828, Valid Loss: 0.3509
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3475
Epoch 10/10, Batch 20/20, Loss: 0.7904
Epoch 10/10, Train Loss: 0.2942, Valid Loss: 0.3359
Model saved!
Accuracy: 0.8890
Precision: 0.8825
Recall: 0.8890
F1-score: 0.8822
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3006
Epoch 1/10, Batch 20/20, Loss: 1.2341
Epoch 1/10, Train Loss: 1.2852, Valid Loss: 1.0741
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8214
Epoch 2/10, Batch 20/20, Loss: 0.7342
Epoch 2/10, Train Loss: 0.8137, Valid Loss: 0.7372
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7169
Epoch 3/10, Batch 20/20, Loss: 0.7195
Epoch 3/10, Train Loss: 0.6163, Valid Loss: 0.6169
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4033
Epoch 4/10, Batch 20/20, Loss: 0.8223
Epoch 4/10, Train Loss: 0.5191, Valid Loss: 0.5473
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3532
Epoch 5/10, Batch 20/20, Loss: 0.5745
Epoch 5/10, Train Loss: 0.4414, Valid Loss: 0.5094
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5439
Epoch 6/10, Batch 20/20, Loss: 0.4420
Epoch 6/10, Train Loss: 0.3943, Valid Loss: 0.4757
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2697
Epoch 7/10, Batch 20/20, Loss: 0.3875
Epoch 7/10, Train Loss: 0.3636, Valid Loss: 0.4537
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5115
Epoch 8/10, Batch 20/20, Loss: 0.5636
Epoch 8/10, Train Loss: 0.3469, Valid Loss: 0.4351
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3088
Epoch 9/10, Batch 20/20, Loss: 0.4883
Epoch 9/10, Train Loss: 0.3012, Valid Loss: 0.4210
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3429
Epoch 10/10, Batch 20/20, Loss: 0.7966
Epoch 10/10, Train Loss: 0.3025, Valid Loss: 0.4257
Accuracy: 0.8902
Precision: 0.8841
Recall: 0.8902
F1-score: 0.8859
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2903
Epoch 1/10, Batch 20/20, Loss: 1.4880
Epoch 1/10, Train Loss: 1.3071, Valid Loss: 1.0954
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9015
Epoch 2/10, Batch 20/20, Loss: 0.6181
Epoch 2/10, Train Loss: 0.8163, Valid Loss: 0.8019
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6559
Epoch 3/10, Batch 20/20, Loss: 0.7784
Epoch 3/10, Train Loss: 0.6172, Valid Loss: 0.6786
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5045
Epoch 4/10, Batch 20/20, Loss: 0.3852
Epoch 4/10, Train Loss: 0.4848, Valid Loss: 0.6197
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4253
Epoch 5/10, Batch 20/20, Loss: 0.8208
Epoch 5/10, Train Loss: 0.4380, Valid Loss: 0.5714
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4699
Epoch 6/10, Batch 20/20, Loss: 0.6293
Epoch 6/10, Train Loss: 0.3934, Valid Loss: 0.5393
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4052
Epoch 7/10, Batch 20/20, Loss: 0.3379
Epoch 7/10, Train Loss: 0.3416, Valid Loss: 0.5210
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4192
Epoch 8/10, Batch 20/20, Loss: 0.4841
Epoch 8/10, Train Loss: 0.3262, Valid Loss: 0.5107
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4365
Epoch 9/10, Batch 20/20, Loss: 0.6288
Epoch 9/10, Train Loss: 0.3035, Valid Loss: 0.5014
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2949
Epoch 10/10, Batch 20/20, Loss: 0.3077
Epoch 10/10, Train Loss: 0.2629, Valid Loss: 0.5025
Accuracy: 0.8843
Precision: 0.8806
Recall: 0.8843
F1-score: 0.8815
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1936
Epoch 1/10, Batch 20/20, Loss: 1.2866
Epoch 1/10, Train Loss: 1.2770, Valid Loss: 1.0822
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9927
Epoch 2/10, Batch 20/20, Loss: 0.4375
Epoch 2/10, Train Loss: 0.8038, Valid Loss: 0.7539
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6515
Epoch 3/10, Batch 20/20, Loss: 0.7591
Epoch 3/10, Train Loss: 0.6051, Valid Loss: 0.6234
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4549
Epoch 4/10, Batch 20/20, Loss: 0.4545
Epoch 4/10, Train Loss: 0.4860, Valid Loss: 0.5545
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4319
Epoch 5/10, Batch 20/20, Loss: 0.7210
Epoch 5/10, Train Loss: 0.4370, Valid Loss: 0.5104
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6205
Epoch 6/10, Batch 20/20, Loss: 0.3945
Epoch 6/10, Train Loss: 0.3799, Valid Loss: 0.4736
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2728
Epoch 7/10, Batch 20/20, Loss: 0.6756
Epoch 7/10, Train Loss: 0.3546, Valid Loss: 0.4504
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4050
Epoch 8/10, Batch 20/20, Loss: 0.2089
Epoch 8/10, Train Loss: 0.3170, Valid Loss: 0.4274
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3044
Epoch 9/10, Batch 20/20, Loss: 0.6050
Epoch 9/10, Train Loss: 0.3062, Valid Loss: 0.4169
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1734
Epoch 10/10, Batch 20/20, Loss: 0.8839
Epoch 10/10, Train Loss: 0.2925, Valid Loss: 0.4085
Model saved!
Accuracy: 0.8785
Precision: 0.8743
Recall: 0.8785
F1-score: 0.8723
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1586
Epoch 1/10, Batch 20/20, Loss: 1.2603
Epoch 1/10, Train Loss: 1.2797, Valid Loss: 1.0236
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9963
Epoch 2/10, Batch 20/20, Loss: 0.7026
Epoch 2/10, Train Loss: 0.8064, Valid Loss: 0.7239
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7167
Epoch 3/10, Batch 20/20, Loss: 0.8162
Epoch 3/10, Train Loss: 0.6265, Valid Loss: 0.5872
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6139
Epoch 4/10, Batch 20/20, Loss: 0.5569
Epoch 4/10, Train Loss: 0.5002, Valid Loss: 0.5255
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3685
Epoch 5/10, Batch 20/20, Loss: 0.7415
Epoch 5/10, Train Loss: 0.4403, Valid Loss: 0.4613
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5835
Epoch 6/10, Batch 20/20, Loss: 0.5651
Epoch 6/10, Train Loss: 0.3941, Valid Loss: 0.4320
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2441
Epoch 7/10, Batch 20/20, Loss: 0.4416
Epoch 7/10, Train Loss: 0.3476, Valid Loss: 0.4037
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3821
Epoch 8/10, Batch 20/20, Loss: 0.5289
Epoch 8/10, Train Loss: 0.3286, Valid Loss: 0.3851
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4396
Epoch 9/10, Batch 20/20, Loss: 0.7425
Epoch 9/10, Train Loss: 0.3153, Valid Loss: 0.3647
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2452
Epoch 10/10, Batch 20/20, Loss: 0.5119
Epoch 10/10, Train Loss: 0.2850, Valid Loss: 0.3590
Model saved!
Accuracy: 0.8832
Precision: 0.8777
Recall: 0.8832
F1-score: 0.8766
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1482
Epoch 1/10, Batch 20/20, Loss: 1.4397
Epoch 1/10, Train Loss: 1.2775, Valid Loss: 1.0211
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9498
Epoch 2/10, Batch 20/20, Loss: 0.6314
Epoch 2/10, Train Loss: 0.7924, Valid Loss: 0.7196
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6430
Epoch 3/10, Batch 20/20, Loss: 0.7390
Epoch 3/10, Train Loss: 0.6101, Valid Loss: 0.6068
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5341
Epoch 4/10, Batch 20/20, Loss: 0.6547
Epoch 4/10, Train Loss: 0.4966, Valid Loss: 0.5406
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.2838
Epoch 5/10, Batch 20/20, Loss: 0.5648
Epoch 5/10, Train Loss: 0.4286, Valid Loss: 0.4958
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5249
Epoch 6/10, Batch 20/20, Loss: 0.3818
Epoch 6/10, Train Loss: 0.3739, Valid Loss: 0.4743
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.1886
Epoch 7/10, Batch 20/20, Loss: 0.4450
Epoch 7/10, Train Loss: 0.3383, Valid Loss: 0.4569
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3495
Epoch 8/10, Batch 20/20, Loss: 0.2713
Epoch 8/10, Train Loss: 0.3201, Valid Loss: 0.4432
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4307
Epoch 9/10, Batch 20/20, Loss: 0.3179
Epoch 9/10, Train Loss: 0.2761, Valid Loss: 0.4211
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.4591
Epoch 10/10, Batch 20/20, Loss: 0.8670
Epoch 10/10, Train Loss: 0.3002, Valid Loss: 0.4212
Accuracy: 0.8785
Precision: 0.8696
Recall: 0.8785
F1-score: 0.8719
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2175
Epoch 1/10, Batch 20/20, Loss: 1.2413
Epoch 1/10, Train Loss: 1.2797, Valid Loss: 1.0291
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9317
Epoch 2/10, Batch 20/20, Loss: 0.5723
Epoch 2/10, Train Loss: 0.8147, Valid Loss: 0.7286
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8203
Epoch 3/10, Batch 20/20, Loss: 0.7548
Epoch 3/10, Train Loss: 0.6204, Valid Loss: 0.6055
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5000
Epoch 4/10, Batch 20/20, Loss: 0.5739
Epoch 4/10, Train Loss: 0.5048, Valid Loss: 0.5408
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5122
Epoch 5/10, Batch 20/20, Loss: 0.6947
Epoch 5/10, Train Loss: 0.4561, Valid Loss: 0.4858
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5327
Epoch 6/10, Batch 20/20, Loss: 0.3075
Epoch 6/10, Train Loss: 0.3917, Valid Loss: 0.4555
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3107
Epoch 7/10, Batch 20/20, Loss: 0.4465
Epoch 7/10, Train Loss: 0.3538, Valid Loss: 0.4330
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4411
Epoch 8/10, Batch 20/20, Loss: 0.4948
Epoch 8/10, Train Loss: 0.3636, Valid Loss: 0.4225
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3691
Epoch 9/10, Batch 20/20, Loss: 0.5834
Epoch 9/10, Train Loss: 0.3149, Valid Loss: 0.4015
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2968
Epoch 10/10, Batch 20/20, Loss: 0.5619
Epoch 10/10, Train Loss: 0.2918, Valid Loss: 0.3993
Model saved!
Accuracy: 0.8832
Precision: 0.8784
Recall: 0.8832
F1-score: 0.8783
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2060
Epoch 1/10, Batch 20/20, Loss: 1.4800
Epoch 1/10, Train Loss: 1.2795, Valid Loss: 1.0842
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0195
Epoch 2/10, Batch 20/20, Loss: 0.6304
Epoch 2/10, Train Loss: 0.8074, Valid Loss: 0.7803
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6918
Epoch 3/10, Batch 20/20, Loss: 0.8835
Epoch 3/10, Train Loss: 0.6179, Valid Loss: 0.6630
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4075
Epoch 4/10, Batch 20/20, Loss: 0.4620
Epoch 4/10, Train Loss: 0.4936, Valid Loss: 0.5846
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4697
Epoch 5/10, Batch 20/20, Loss: 0.4951
Epoch 5/10, Train Loss: 0.4331, Valid Loss: 0.5502
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5274
Epoch 6/10, Batch 20/20, Loss: 0.6994
Epoch 6/10, Train Loss: 0.4008, Valid Loss: 0.5135
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4050
Epoch 7/10, Batch 20/20, Loss: 0.4497
Epoch 7/10, Train Loss: 0.3490, Valid Loss: 0.4909
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3520
Epoch 8/10, Batch 20/20, Loss: 0.4690
Epoch 8/10, Train Loss: 0.3234, Valid Loss: 0.4691
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3750
Epoch 9/10, Batch 20/20, Loss: 0.7489
Epoch 9/10, Train Loss: 0.3059, Valid Loss: 0.4744
Epoch 10/10, Batch 10/20, Loss: 0.2547
Epoch 10/10, Batch 20/20, Loss: 0.4389
Epoch 10/10, Train Loss: 0.2734, Valid Loss: 0.4635
Model saved!
Accuracy: 0.8879
Precision: 0.8888
Recall: 0.8879
F1-score: 0.8844
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2055
Epoch 1/10, Batch 20/20, Loss: 1.5204
Epoch 1/10, Train Loss: 1.3023, Valid Loss: 1.0222
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0199
Epoch 2/10, Batch 20/20, Loss: 0.6532
Epoch 2/10, Train Loss: 0.8289, Valid Loss: 0.7216
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7231
Epoch 3/10, Batch 20/20, Loss: 0.9689
Epoch 3/10, Train Loss: 0.6533, Valid Loss: 0.5922
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4923
Epoch 4/10, Batch 20/20, Loss: 0.2742
Epoch 4/10, Train Loss: 0.5181, Valid Loss: 0.5175
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5723
Epoch 5/10, Batch 20/20, Loss: 0.5595
Epoch 5/10, Train Loss: 0.4502, Valid Loss: 0.4670
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6347
Epoch 6/10, Batch 20/20, Loss: 0.4155
Epoch 6/10, Train Loss: 0.4048, Valid Loss: 0.4326
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3048
Epoch 7/10, Batch 20/20, Loss: 0.3940
Epoch 7/10, Train Loss: 0.3485, Valid Loss: 0.4161
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3911
Epoch 8/10, Batch 20/20, Loss: 0.3472
Epoch 8/10, Train Loss: 0.3237, Valid Loss: 0.3946
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4004
Epoch 9/10, Batch 20/20, Loss: 0.6699
Epoch 9/10, Train Loss: 0.3268, Valid Loss: 0.3774
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2439
Epoch 10/10, Batch 20/20, Loss: 0.5354
Epoch 10/10, Train Loss: 0.3014, Valid Loss: 0.3690
Model saved!
Accuracy: 0.8867
Precision: 0.8839
Recall: 0.8867
F1-score: 0.8819
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2227
Epoch 1/10, Batch 20/20, Loss: 1.3116
Epoch 1/10, Train Loss: 1.2774, Valid Loss: 1.0035
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0284
Epoch 2/10, Batch 20/20, Loss: 0.5720
Epoch 2/10, Train Loss: 0.8018, Valid Loss: 0.7038
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6761
Epoch 3/10, Batch 20/20, Loss: 0.9080
Epoch 3/10, Train Loss: 0.6061, Valid Loss: 0.5855
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5550
Epoch 4/10, Batch 20/20, Loss: 0.4523
Epoch 4/10, Train Loss: 0.4736, Valid Loss: 0.5178
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4362
Epoch 5/10, Batch 20/20, Loss: 0.6473
Epoch 5/10, Train Loss: 0.4184, Valid Loss: 0.4731
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5009
Epoch 6/10, Batch 20/20, Loss: 0.4965
Epoch 6/10, Train Loss: 0.3730, Valid Loss: 0.4482
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3069
Epoch 7/10, Batch 20/20, Loss: 0.2439
Epoch 7/10, Train Loss: 0.3192, Valid Loss: 0.4231
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4735
Epoch 8/10, Batch 20/20, Loss: 0.6965
Epoch 8/10, Train Loss: 0.3284, Valid Loss: 0.4141
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3506
Epoch 9/10, Batch 20/20, Loss: 0.3683
Epoch 9/10, Train Loss: 0.2871, Valid Loss: 0.3969
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3770
Epoch 10/10, Batch 20/20, Loss: 0.6044
Epoch 10/10, Train Loss: 0.2735, Valid Loss: 0.3968
Model saved!
Accuracy: 0.8902
Precision: 0.8866
Recall: 0.8902
F1-score: 0.8852
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3547
Epoch 1/10, Batch 20/20, Loss: 1.3335
Epoch 1/10, Train Loss: 1.2969, Valid Loss: 1.0468
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9391
Epoch 2/10, Batch 20/20, Loss: 0.7919
Epoch 2/10, Train Loss: 0.8301, Valid Loss: 0.7315
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7704
Epoch 3/10, Batch 20/20, Loss: 0.8942
Epoch 3/10, Train Loss: 0.6338, Valid Loss: 0.5859
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5542
Epoch 4/10, Batch 20/20, Loss: 0.5450
Epoch 4/10, Train Loss: 0.5036, Valid Loss: 0.5137
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4041
Epoch 5/10, Batch 20/20, Loss: 0.6508
Epoch 5/10, Train Loss: 0.4360, Valid Loss: 0.4598
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4900
Epoch 6/10, Batch 20/20, Loss: 0.6704
Epoch 6/10, Train Loss: 0.4029, Valid Loss: 0.4328
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2746
Epoch 7/10, Batch 20/20, Loss: 0.4453
Epoch 7/10, Train Loss: 0.3414, Valid Loss: 0.4126
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3563
Epoch 8/10, Batch 20/20, Loss: 0.3849
Epoch 8/10, Train Loss: 0.3254, Valid Loss: 0.3927
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2739
Epoch 9/10, Batch 20/20, Loss: 0.5500
Epoch 9/10, Train Loss: 0.2922, Valid Loss: 0.3684
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1848
Epoch 10/10, Batch 20/20, Loss: 0.7102
Epoch 10/10, Train Loss: 0.2954, Valid Loss: 0.3750
Accuracy: 0.8843
Precision: 0.8793
Recall: 0.8843
F1-score: 0.8807
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2148
Epoch 1/10, Batch 20/20, Loss: 1.1647
Epoch 1/10, Train Loss: 1.2670, Valid Loss: 1.0527
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8810
Epoch 2/10, Batch 20/20, Loss: 0.6749
Epoch 2/10, Train Loss: 0.7941, Valid Loss: 0.7275
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6233
Epoch 3/10, Batch 20/20, Loss: 0.7144
Epoch 3/10, Train Loss: 0.5958, Valid Loss: 0.5880
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4034
Epoch 4/10, Batch 20/20, Loss: 0.5811
Epoch 4/10, Train Loss: 0.4909, Valid Loss: 0.5006
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4649
Epoch 5/10, Batch 20/20, Loss: 0.6485
Epoch 5/10, Train Loss: 0.4196, Valid Loss: 0.4510
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4520
Epoch 6/10, Batch 20/20, Loss: 0.3687
Epoch 6/10, Train Loss: 0.3678, Valid Loss: 0.4268
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3455
Epoch 7/10, Batch 20/20, Loss: 0.4228
Epoch 7/10, Train Loss: 0.3442, Valid Loss: 0.3942
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3725
Epoch 8/10, Batch 20/20, Loss: 0.2649
Epoch 8/10, Train Loss: 0.3190, Valid Loss: 0.3787
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3522
Epoch 9/10, Batch 20/20, Loss: 0.4260
Epoch 9/10, Train Loss: 0.2880, Valid Loss: 0.3425
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1793
Epoch 10/10, Batch 20/20, Loss: 0.4189
Epoch 10/10, Train Loss: 0.2755, Valid Loss: 0.3390
Model saved!
Accuracy: 0.8808
Precision: 0.8755
Recall: 0.8808
F1-score: 0.8764
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3256
Epoch 1/10, Batch 20/20, Loss: 1.3987
Epoch 1/10, Train Loss: 1.3036, Valid Loss: 1.1114
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0038
Epoch 2/10, Batch 20/20, Loss: 1.0397
Epoch 2/10, Train Loss: 0.8441, Valid Loss: 0.7938
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.9197
Epoch 3/10, Batch 20/20, Loss: 0.8710
Epoch 3/10, Train Loss: 0.6337, Valid Loss: 0.6725
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5638
Epoch 4/10, Batch 20/20, Loss: 0.6305
Epoch 4/10, Train Loss: 0.5079, Valid Loss: 0.5918
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4189
Epoch 5/10, Batch 20/20, Loss: 0.6620
Epoch 5/10, Train Loss: 0.4544, Valid Loss: 0.5586
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5576
Epoch 6/10, Batch 20/20, Loss: 0.5549
Epoch 6/10, Train Loss: 0.4115, Valid Loss: 0.5230
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3545
Epoch 7/10, Batch 20/20, Loss: 0.4831
Epoch 7/10, Train Loss: 0.3620, Valid Loss: 0.5005
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3090
Epoch 8/10, Batch 20/20, Loss: 0.6052
Epoch 8/10, Train Loss: 0.3424, Valid Loss: 0.4780
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2733
Epoch 9/10, Batch 20/20, Loss: 0.5829
Epoch 9/10, Train Loss: 0.3080, Valid Loss: 0.4655
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3390
Epoch 10/10, Batch 20/20, Loss: 0.6111
Epoch 10/10, Train Loss: 0.2831, Valid Loss: 0.4649
Model saved!
Accuracy: 0.8890
Precision: 0.8850
Recall: 0.8890
F1-score: 0.8840
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2039
Epoch 1/10, Batch 20/20, Loss: 1.3831
Epoch 1/10, Train Loss: 1.2852, Valid Loss: 1.0774
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9623
Epoch 2/10, Batch 20/20, Loss: 0.6219
Epoch 2/10, Train Loss: 0.7920, Valid Loss: 0.7561
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6512
Epoch 3/10, Batch 20/20, Loss: 0.8858
Epoch 3/10, Train Loss: 0.6006, Valid Loss: 0.6376
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5415
Epoch 4/10, Batch 20/20, Loss: 0.4154
Epoch 4/10, Train Loss: 0.4655, Valid Loss: 0.5717
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3982
Epoch 5/10, Batch 20/20, Loss: 0.4726
Epoch 5/10, Train Loss: 0.3995, Valid Loss: 0.5079
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5484
Epoch 6/10, Batch 20/20, Loss: 0.5412
Epoch 6/10, Train Loss: 0.3680, Valid Loss: 0.4842
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3367
Epoch 7/10, Batch 20/20, Loss: 0.3195
Epoch 7/10, Train Loss: 0.3279, Valid Loss: 0.4620
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3468
Epoch 8/10, Batch 20/20, Loss: 0.3901
Epoch 8/10, Train Loss: 0.2978, Valid Loss: 0.4382
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2913
Epoch 9/10, Batch 20/20, Loss: 0.5168
Epoch 9/10, Train Loss: 0.2862, Valid Loss: 0.4077
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2474
Epoch 10/10, Batch 20/20, Loss: 0.3064
Epoch 10/10, Train Loss: 0.2455, Valid Loss: 0.4125
Accuracy: 0.8855
Precision: 0.8829
Recall: 0.8855
F1-score: 0.8833
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1739
Epoch 1/10, Batch 20/20, Loss: 1.2079
Epoch 1/10, Train Loss: 1.2772, Valid Loss: 0.9835
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9610
Epoch 2/10, Batch 20/20, Loss: 0.6560
Epoch 2/10, Train Loss: 0.7960, Valid Loss: 0.6905
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7022
Epoch 3/10, Batch 20/20, Loss: 0.7695
Epoch 3/10, Train Loss: 0.6059, Valid Loss: 0.5651
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5787
Epoch 4/10, Batch 20/20, Loss: 0.3482
Epoch 4/10, Train Loss: 0.4722, Valid Loss: 0.4869
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4724
Epoch 5/10, Batch 20/20, Loss: 0.4662
Epoch 5/10, Train Loss: 0.4191, Valid Loss: 0.4546
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5997
Epoch 6/10, Batch 20/20, Loss: 0.5223
Epoch 6/10, Train Loss: 0.3660, Valid Loss: 0.4159
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3032
Epoch 7/10, Batch 20/20, Loss: 0.8544
Epoch 7/10, Train Loss: 0.3430, Valid Loss: 0.3981
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3806
Epoch 8/10, Batch 20/20, Loss: 0.5354
Epoch 8/10, Train Loss: 0.3279, Valid Loss: 0.3816
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3473
Epoch 9/10, Batch 20/20, Loss: 0.5748
Epoch 9/10, Train Loss: 0.2879, Valid Loss: 0.3826
Epoch 10/10, Batch 10/20, Loss: 0.3214
Epoch 10/10, Batch 20/20, Loss: 0.5962
Epoch 10/10, Train Loss: 0.2786, Valid Loss: 0.3569
Model saved!
Accuracy: 0.8867
Precision: 0.8830
Recall: 0.8867
F1-score: 0.8811
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2040
Epoch 1/10, Batch 20/20, Loss: 1.4114
Epoch 1/10, Train Loss: 1.2799, Valid Loss: 1.0181
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8970
Epoch 2/10, Batch 20/20, Loss: 0.6597
Epoch 2/10, Train Loss: 0.8178, Valid Loss: 0.7149
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7727
Epoch 3/10, Batch 20/20, Loss: 0.8744
Epoch 3/10, Train Loss: 0.6370, Valid Loss: 0.5871
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4806
Epoch 4/10, Batch 20/20, Loss: 0.6787
Epoch 4/10, Train Loss: 0.5224, Valid Loss: 0.5229
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4218
Epoch 5/10, Batch 20/20, Loss: 1.1052
Epoch 5/10, Train Loss: 0.4596, Valid Loss: 0.4835
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4617
Epoch 6/10, Batch 20/20, Loss: 0.4516
Epoch 6/10, Train Loss: 0.4025, Valid Loss: 0.4549
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3428
Epoch 7/10, Batch 20/20, Loss: 0.3235
Epoch 7/10, Train Loss: 0.3554, Valid Loss: 0.4332
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3512
Epoch 8/10, Batch 20/20, Loss: 0.3377
Epoch 8/10, Train Loss: 0.3391, Valid Loss: 0.4192
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3813
Epoch 9/10, Batch 20/20, Loss: 0.5732
Epoch 9/10, Train Loss: 0.3197, Valid Loss: 0.4081
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2372
Epoch 10/10, Batch 20/20, Loss: 0.4881
Epoch 10/10, Train Loss: 0.2885, Valid Loss: 0.3951
Model saved!
Accuracy: 0.8808
Precision: 0.8732
Recall: 0.8808
F1-score: 0.8750
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2934
Epoch 1/10, Batch 20/20, Loss: 1.2405
Epoch 1/10, Train Loss: 1.2875, Valid Loss: 1.0726
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9007
Epoch 2/10, Batch 20/20, Loss: 0.6282
Epoch 2/10, Train Loss: 0.8022, Valid Loss: 0.7522
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7314
Epoch 3/10, Batch 20/20, Loss: 0.9371
Epoch 3/10, Train Loss: 0.6161, Valid Loss: 0.6246
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3947
Epoch 4/10, Batch 20/20, Loss: 0.5604
Epoch 4/10, Train Loss: 0.4771, Valid Loss: 0.5555
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3580
Epoch 5/10, Batch 20/20, Loss: 0.6089
Epoch 5/10, Train Loss: 0.4203, Valid Loss: 0.5066
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5105
Epoch 6/10, Batch 20/20, Loss: 0.4872
Epoch 6/10, Train Loss: 0.3769, Valid Loss: 0.4801
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2826
Epoch 7/10, Batch 20/20, Loss: 0.2516
Epoch 7/10, Train Loss: 0.3144, Valid Loss: 0.4551
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4662
Epoch 8/10, Batch 20/20, Loss: 0.4004
Epoch 8/10, Train Loss: 0.3181, Valid Loss: 0.4491
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3538
Epoch 9/10, Batch 20/20, Loss: 0.3279
Epoch 9/10, Train Loss: 0.2730, Valid Loss: 0.4322
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2638
Epoch 10/10, Batch 20/20, Loss: 0.5275
Epoch 10/10, Train Loss: 0.2660, Valid Loss: 0.4291
Model saved!
Accuracy: 0.8867
Precision: 0.8860
Recall: 0.8867
F1-score: 0.8845
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2291
Epoch 1/10, Batch 20/20, Loss: 1.3596
Epoch 1/10, Train Loss: 1.2875, Valid Loss: 1.0737
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9830
Epoch 2/10, Batch 20/20, Loss: 0.6160
Epoch 2/10, Train Loss: 0.8125, Valid Loss: 0.7478
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6762
Epoch 3/10, Batch 20/20, Loss: 1.0690
Epoch 3/10, Train Loss: 0.6412, Valid Loss: 0.6199
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4147
Epoch 4/10, Batch 20/20, Loss: 0.3790
Epoch 4/10, Train Loss: 0.4919, Valid Loss: 0.5523
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3188
Epoch 5/10, Batch 20/20, Loss: 0.6505
Epoch 5/10, Train Loss: 0.4347, Valid Loss: 0.5081
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5096
Epoch 6/10, Batch 20/20, Loss: 0.5000
Epoch 6/10, Train Loss: 0.4003, Valid Loss: 0.4734
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3403
Epoch 7/10, Batch 20/20, Loss: 0.5244
Epoch 7/10, Train Loss: 0.3527, Valid Loss: 0.4536
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3970
Epoch 8/10, Batch 20/20, Loss: 0.4134
Epoch 8/10, Train Loss: 0.3343, Valid Loss: 0.4289
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3811
Epoch 9/10, Batch 20/20, Loss: 0.5909
Epoch 9/10, Train Loss: 0.3074, Valid Loss: 0.4084
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2013
Epoch 10/10, Batch 20/20, Loss: 0.6191
Epoch 10/10, Train Loss: 0.2908, Valid Loss: 0.4171
Accuracy: 0.8925
Precision: 0.8878
Recall: 0.8925
F1-score: 0.8884
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3346
Epoch 1/10, Batch 20/20, Loss: 1.3417
Epoch 1/10, Train Loss: 1.3120, Valid Loss: 1.1056
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9686
Epoch 2/10, Batch 20/20, Loss: 0.7395
Epoch 2/10, Train Loss: 0.8581, Valid Loss: 0.8028
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7220
Epoch 3/10, Batch 20/20, Loss: 0.7863
Epoch 3/10, Train Loss: 0.6576, Valid Loss: 0.6790
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4752
Epoch 4/10, Batch 20/20, Loss: 0.4295
Epoch 4/10, Train Loss: 0.5321, Valid Loss: 0.6103
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4688
Epoch 5/10, Batch 20/20, Loss: 0.8312
Epoch 5/10, Train Loss: 0.4661, Valid Loss: 0.5744
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6420
Epoch 6/10, Batch 20/20, Loss: 0.4226
Epoch 6/10, Train Loss: 0.4185, Valid Loss: 0.5147
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3970
Epoch 7/10, Batch 20/20, Loss: 0.3435
Epoch 7/10, Train Loss: 0.3665, Valid Loss: 0.4985
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4836
Epoch 8/10, Batch 20/20, Loss: 0.5298
Epoch 8/10, Train Loss: 0.3491, Valid Loss: 0.4924
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5302
Epoch 9/10, Batch 20/20, Loss: 0.6509
Epoch 9/10, Train Loss: 0.3372, Valid Loss: 0.4721
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3213
Epoch 10/10, Batch 20/20, Loss: 0.7048
Epoch 10/10, Train Loss: 0.3124, Valid Loss: 0.4689
Model saved!
Accuracy: 0.8937
Precision: 0.8883
Recall: 0.8937
F1-score: 0.8881
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2283
Epoch 1/10, Batch 20/20, Loss: 1.3448
Epoch 1/10, Train Loss: 1.2705, Valid Loss: 1.0093
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8918
Epoch 2/10, Batch 20/20, Loss: 0.5325
Epoch 2/10, Train Loss: 0.7842, Valid Loss: 0.7251
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6401
Epoch 3/10, Batch 20/20, Loss: 0.6678
Epoch 3/10, Train Loss: 0.5832, Valid Loss: 0.6063
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3850
Epoch 4/10, Batch 20/20, Loss: 0.6814
Epoch 4/10, Train Loss: 0.4752, Valid Loss: 0.5337
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4374
Epoch 5/10, Batch 20/20, Loss: 0.5744
Epoch 5/10, Train Loss: 0.4069, Valid Loss: 0.4983
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4520
Epoch 6/10, Batch 20/20, Loss: 0.4190
Epoch 6/10, Train Loss: 0.3757, Valid Loss: 0.4624
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2947
Epoch 7/10, Batch 20/20, Loss: 0.5369
Epoch 7/10, Train Loss: 0.3348, Valid Loss: 0.4517
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4106
Epoch 8/10, Batch 20/20, Loss: 0.5319
Epoch 8/10, Train Loss: 0.3147, Valid Loss: 0.4328
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3759
Epoch 9/10, Batch 20/20, Loss: 0.6616
Epoch 9/10, Train Loss: 0.3005, Valid Loss: 0.4211
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2812
Epoch 10/10, Batch 20/20, Loss: 0.8847
Epoch 10/10, Train Loss: 0.2859, Valid Loss: 0.4229
Accuracy: 0.8832
Precision: 0.8777
Recall: 0.8832
F1-score: 0.8756
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3359
Epoch 1/10, Batch 20/20, Loss: 1.0933
Epoch 1/10, Train Loss: 1.2939, Valid Loss: 1.0665
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9245
Epoch 2/10, Batch 20/20, Loss: 0.6459
Epoch 2/10, Train Loss: 0.8226, Valid Loss: 0.7541
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8337
Epoch 3/10, Batch 20/20, Loss: 0.8177
Epoch 3/10, Train Loss: 0.6389, Valid Loss: 0.6254
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4681
Epoch 4/10, Batch 20/20, Loss: 0.6534
Epoch 4/10, Train Loss: 0.5175, Valid Loss: 0.5571
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5905
Epoch 5/10, Batch 20/20, Loss: 0.5588
Epoch 5/10, Train Loss: 0.4424, Valid Loss: 0.4986
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5300
Epoch 6/10, Batch 20/20, Loss: 0.5321
Epoch 6/10, Train Loss: 0.4105, Valid Loss: 0.4758
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3230
Epoch 7/10, Batch 20/20, Loss: 0.3930
Epoch 7/10, Train Loss: 0.3488, Valid Loss: 0.4574
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3696
Epoch 8/10, Batch 20/20, Loss: 0.2693
Epoch 8/10, Train Loss: 0.3267, Valid Loss: 0.4282
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2620
Epoch 9/10, Batch 20/20, Loss: 0.4279
Epoch 9/10, Train Loss: 0.3015, Valid Loss: 0.4077
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2653
Epoch 10/10, Batch 20/20, Loss: 0.4536
Epoch 10/10, Train Loss: 0.2892, Valid Loss: 0.4220
Accuracy: 0.8797
Precision: 0.8756
Recall: 0.8797
F1-score: 0.8769
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2230
Epoch 1/10, Batch 20/20, Loss: 1.3579
Epoch 1/10, Train Loss: 1.2908, Valid Loss: 1.0692
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8752
Epoch 2/10, Batch 20/20, Loss: 0.6880
Epoch 2/10, Train Loss: 0.8100, Valid Loss: 0.7529
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6961
Epoch 3/10, Batch 20/20, Loss: 0.8411
Epoch 3/10, Train Loss: 0.6119, Valid Loss: 0.6233
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4552
Epoch 4/10, Batch 20/20, Loss: 0.3172
Epoch 4/10, Train Loss: 0.4850, Valid Loss: 0.5557
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4844
Epoch 5/10, Batch 20/20, Loss: 0.5096
Epoch 5/10, Train Loss: 0.4198, Valid Loss: 0.5045
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5386
Epoch 6/10, Batch 20/20, Loss: 0.3755
Epoch 6/10, Train Loss: 0.3816, Valid Loss: 0.4757
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3962
Epoch 7/10, Batch 20/20, Loss: 0.3444
Epoch 7/10, Train Loss: 0.3309, Valid Loss: 0.4523
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4184
Epoch 8/10, Batch 20/20, Loss: 0.2068
Epoch 8/10, Train Loss: 0.3130, Valid Loss: 0.4501
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3300
Epoch 9/10, Batch 20/20, Loss: 0.7698
Epoch 9/10, Train Loss: 0.3034, Valid Loss: 0.4230
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1884
Epoch 10/10, Batch 20/20, Loss: 0.5535
Epoch 10/10, Train Loss: 0.2701, Valid Loss: 0.4320
Accuracy: 0.8832
Precision: 0.8772
Recall: 0.8832
F1-score: 0.8785
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2262
Epoch 1/10, Batch 20/20, Loss: 1.3666
Epoch 1/10, Train Loss: 1.2770, Valid Loss: 1.0639
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9823
Epoch 2/10, Batch 20/20, Loss: 0.7058
Epoch 2/10, Train Loss: 0.7971, Valid Loss: 0.7426
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6486
Epoch 3/10, Batch 20/20, Loss: 0.8807
Epoch 3/10, Train Loss: 0.6142, Valid Loss: 0.6268
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5375
Epoch 4/10, Batch 20/20, Loss: 0.3686
Epoch 4/10, Train Loss: 0.4851, Valid Loss: 0.5436
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4730
Epoch 5/10, Batch 20/20, Loss: 0.6466
Epoch 5/10, Train Loss: 0.4320, Valid Loss: 0.5159
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5126
Epoch 6/10, Batch 20/20, Loss: 0.4058
Epoch 6/10, Train Loss: 0.3810, Valid Loss: 0.4797
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2928
Epoch 7/10, Batch 20/20, Loss: 0.3551
Epoch 7/10, Train Loss: 0.3432, Valid Loss: 0.4511
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3469
Epoch 8/10, Batch 20/20, Loss: 0.3930
Epoch 8/10, Train Loss: 0.3239, Valid Loss: 0.4429
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3528
Epoch 9/10, Batch 20/20, Loss: 0.7144
Epoch 9/10, Train Loss: 0.3079, Valid Loss: 0.4186
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2330
Epoch 10/10, Batch 20/20, Loss: 0.7593
Epoch 10/10, Train Loss: 0.2882, Valid Loss: 0.4303
Accuracy: 0.8785
Precision: 0.8738
Recall: 0.8785
F1-score: 0.8744
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2772
Epoch 1/10, Batch 20/20, Loss: 1.1547
Epoch 1/10, Train Loss: 1.2840, Valid Loss: 1.0581
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8913
Epoch 2/10, Batch 20/20, Loss: 0.8084
Epoch 2/10, Train Loss: 0.8200, Valid Loss: 0.7339
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8198
Epoch 3/10, Batch 20/20, Loss: 0.7483
Epoch 3/10, Train Loss: 0.6331, Valid Loss: 0.5967
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5236
Epoch 4/10, Batch 20/20, Loss: 0.5986
Epoch 4/10, Train Loss: 0.5213, Valid Loss: 0.5132
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4795
Epoch 5/10, Batch 20/20, Loss: 0.8924
Epoch 5/10, Train Loss: 0.4643, Valid Loss: 0.4792
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6611
Epoch 6/10, Batch 20/20, Loss: 0.4196
Epoch 6/10, Train Loss: 0.4003, Valid Loss: 0.4371
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3109
Epoch 7/10, Batch 20/20, Loss: 0.6750
Epoch 7/10, Train Loss: 0.3686, Valid Loss: 0.4126
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3348
Epoch 8/10, Batch 20/20, Loss: 0.4953
Epoch 8/10, Train Loss: 0.3362, Valid Loss: 0.3893
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2712
Epoch 9/10, Batch 20/20, Loss: 0.3648
Epoch 9/10, Train Loss: 0.2970, Valid Loss: 0.3684
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2706
Epoch 10/10, Batch 20/20, Loss: 0.4028
Epoch 10/10, Train Loss: 0.2912, Valid Loss: 0.3615
Model saved!
Accuracy: 0.8832
Precision: 0.8786
Recall: 0.8832
F1-score: 0.8755
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2906
Epoch 1/10, Batch 20/20, Loss: 1.3083
Epoch 1/10, Train Loss: 1.2839, Valid Loss: 1.0817
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9253
Epoch 2/10, Batch 20/20, Loss: 0.6786
Epoch 2/10, Train Loss: 0.8067, Valid Loss: 0.7625
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7906
Epoch 3/10, Batch 20/20, Loss: 0.8314
Epoch 3/10, Train Loss: 0.6277, Valid Loss: 0.6311
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4885
Epoch 4/10, Batch 20/20, Loss: 0.4622
Epoch 4/10, Train Loss: 0.4968, Valid Loss: 0.5673
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4086
Epoch 5/10, Batch 20/20, Loss: 0.6101
Epoch 5/10, Train Loss: 0.4339, Valid Loss: 0.5089
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4243
Epoch 6/10, Batch 20/20, Loss: 0.4194
Epoch 6/10, Train Loss: 0.3909, Valid Loss: 0.4904
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3070
Epoch 7/10, Batch 20/20, Loss: 0.3702
Epoch 7/10, Train Loss: 0.3439, Valid Loss: 0.4708
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3910
Epoch 8/10, Batch 20/20, Loss: 0.3151
Epoch 8/10, Train Loss: 0.3311, Valid Loss: 0.4532
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2936
Epoch 9/10, Batch 20/20, Loss: 0.2353
Epoch 9/10, Train Loss: 0.2915, Valid Loss: 0.4218
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2005
Epoch 10/10, Batch 20/20, Loss: 0.6216
Epoch 10/10, Train Loss: 0.2916, Valid Loss: 0.4306
Accuracy: 0.8750
Precision: 0.8707
Recall: 0.8750
F1-score: 0.8717
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2117
Epoch 1/10, Batch 20/20, Loss: 1.1788
Epoch 1/10, Train Loss: 1.2791, Valid Loss: 1.0489
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9391
Epoch 2/10, Batch 20/20, Loss: 0.5441
Epoch 2/10, Train Loss: 0.7864, Valid Loss: 0.7372
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7034
Epoch 3/10, Batch 20/20, Loss: 0.8709
Epoch 3/10, Train Loss: 0.5932, Valid Loss: 0.6141
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3688
Epoch 4/10, Batch 20/20, Loss: 0.4680
Epoch 4/10, Train Loss: 0.4633, Valid Loss: 0.5371
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3798
Epoch 5/10, Batch 20/20, Loss: 0.4783
Epoch 5/10, Train Loss: 0.4100, Valid Loss: 0.4983
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5502
Epoch 6/10, Batch 20/20, Loss: 0.2914
Epoch 6/10, Train Loss: 0.3632, Valid Loss: 0.4623
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3639
Epoch 7/10, Batch 20/20, Loss: 0.3485
Epoch 7/10, Train Loss: 0.3230, Valid Loss: 0.4398
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3631
Epoch 8/10, Batch 20/20, Loss: 0.2614
Epoch 8/10, Train Loss: 0.2965, Valid Loss: 0.4222
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2524
Epoch 9/10, Batch 20/20, Loss: 0.4049
Epoch 9/10, Train Loss: 0.2739, Valid Loss: 0.4056
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2135
Epoch 10/10, Batch 20/20, Loss: 0.4230
Epoch 10/10, Train Loss: 0.2658, Valid Loss: 0.4077
Accuracy: 0.8785
Precision: 0.8732
Recall: 0.8785
F1-score: 0.8748
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2866
Epoch 1/10, Batch 20/20, Loss: 1.2298
Epoch 1/10, Train Loss: 1.2912, Valid Loss: 1.0631
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8702
Epoch 2/10, Batch 20/20, Loss: 0.5783
Epoch 2/10, Train Loss: 0.8131, Valid Loss: 0.7340
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8395
Epoch 3/10, Batch 20/20, Loss: 0.7332
Epoch 3/10, Train Loss: 0.6317, Valid Loss: 0.6110
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5320
Epoch 4/10, Batch 20/20, Loss: 0.3869
Epoch 4/10, Train Loss: 0.5005, Valid Loss: 0.5358
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5022
Epoch 5/10, Batch 20/20, Loss: 0.6679
Epoch 5/10, Train Loss: 0.4533, Valid Loss: 0.4844
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6286
Epoch 6/10, Batch 20/20, Loss: 0.5470
Epoch 6/10, Train Loss: 0.4099, Valid Loss: 0.4409
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2873
Epoch 7/10, Batch 20/20, Loss: 0.2706
Epoch 7/10, Train Loss: 0.3518, Valid Loss: 0.4186
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3343
Epoch 8/10, Batch 20/20, Loss: 0.6734
Epoch 8/10, Train Loss: 0.3453, Valid Loss: 0.3980
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3186
Epoch 9/10, Batch 20/20, Loss: 0.6123
Epoch 9/10, Train Loss: 0.3149, Valid Loss: 0.3855
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3470
Epoch 10/10, Batch 20/20, Loss: 0.4982
Epoch 10/10, Train Loss: 0.2905, Valid Loss: 0.3878
Accuracy: 0.8902
Precision: 0.8839
Recall: 0.8902
F1-score: 0.8850
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3209
Epoch 1/10, Batch 20/20, Loss: 1.2452
Epoch 1/10, Train Loss: 1.2920, Valid Loss: 1.0540
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9596
Epoch 2/10, Batch 20/20, Loss: 0.7132
Epoch 2/10, Train Loss: 0.8267, Valid Loss: 0.7392
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8225
Epoch 3/10, Batch 20/20, Loss: 0.7723
Epoch 3/10, Train Loss: 0.6356, Valid Loss: 0.6035
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5071
Epoch 4/10, Batch 20/20, Loss: 0.4371
Epoch 4/10, Train Loss: 0.5093, Valid Loss: 0.5407
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3663
Epoch 5/10, Batch 20/20, Loss: 0.6512
Epoch 5/10, Train Loss: 0.4526, Valid Loss: 0.4937
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4988
Epoch 6/10, Batch 20/20, Loss: 0.8902
Epoch 6/10, Train Loss: 0.4275, Valid Loss: 0.4495
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2604
Epoch 7/10, Batch 20/20, Loss: 0.4076
Epoch 7/10, Train Loss: 0.3587, Valid Loss: 0.4261
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4822
Epoch 8/10, Batch 20/20, Loss: 0.3085
Epoch 8/10, Train Loss: 0.3469, Valid Loss: 0.3965
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3099
Epoch 9/10, Batch 20/20, Loss: 0.5798
Epoch 9/10, Train Loss: 0.3262, Valid Loss: 0.3894
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2723
Epoch 10/10, Batch 20/20, Loss: 0.3512
Epoch 10/10, Train Loss: 0.2930, Valid Loss: 0.3863
Model saved!
Accuracy: 0.8773
Precision: 0.8717
Recall: 0.8773
F1-score: 0.8718
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3568
Epoch 1/10, Batch 20/20, Loss: 1.2288
Epoch 1/10, Train Loss: 1.2831, Valid Loss: 1.0424
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9110
Epoch 2/10, Batch 20/20, Loss: 0.7780
Epoch 2/10, Train Loss: 0.8112, Valid Loss: 0.7257
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7141
Epoch 3/10, Batch 20/20, Loss: 1.0412
Epoch 3/10, Train Loss: 0.6180, Valid Loss: 0.5989
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3667
Epoch 4/10, Batch 20/20, Loss: 0.6219
Epoch 4/10, Train Loss: 0.5005, Valid Loss: 0.5334
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4917
Epoch 5/10, Batch 20/20, Loss: 0.5518
Epoch 5/10, Train Loss: 0.4218, Valid Loss: 0.4842
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6442
Epoch 6/10, Batch 20/20, Loss: 0.5094
Epoch 6/10, Train Loss: 0.3790, Valid Loss: 0.4446
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2670
Epoch 7/10, Batch 20/20, Loss: 0.3927
Epoch 7/10, Train Loss: 0.3399, Valid Loss: 0.4249
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4099
Epoch 8/10, Batch 20/20, Loss: 0.2422
Epoch 8/10, Train Loss: 0.3113, Valid Loss: 0.4012
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3360
Epoch 9/10, Batch 20/20, Loss: 0.3771
Epoch 9/10, Train Loss: 0.2930, Valid Loss: 0.3864
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2951
Epoch 10/10, Batch 20/20, Loss: 0.4434
Epoch 10/10, Train Loss: 0.2793, Valid Loss: 0.3839
Model saved!
Accuracy: 0.8925
Precision: 0.8871
Recall: 0.8925
F1-score: 0.8864
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2900
Epoch 1/10, Batch 20/20, Loss: 1.2053
Epoch 1/10, Train Loss: 1.2835, Valid Loss: 1.0753
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8942
Epoch 2/10, Batch 20/20, Loss: 0.6461
Epoch 2/10, Train Loss: 0.8030, Valid Loss: 0.7683
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7212
Epoch 3/10, Batch 20/20, Loss: 0.7642
Epoch 3/10, Train Loss: 0.6095, Valid Loss: 0.6360
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4692
Epoch 4/10, Batch 20/20, Loss: 0.5583
Epoch 4/10, Train Loss: 0.4988, Valid Loss: 0.5714
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3567
Epoch 5/10, Batch 20/20, Loss: 0.6987
Epoch 5/10, Train Loss: 0.4327, Valid Loss: 0.5218
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6070
Epoch 6/10, Batch 20/20, Loss: 0.4408
Epoch 6/10, Train Loss: 0.3856, Valid Loss: 0.4880
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3384
Epoch 7/10, Batch 20/20, Loss: 0.3379
Epoch 7/10, Train Loss: 0.3443, Valid Loss: 0.4614
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3660
Epoch 8/10, Batch 20/20, Loss: 0.3398
Epoch 8/10, Train Loss: 0.3258, Valid Loss: 0.4374
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2931
Epoch 9/10, Batch 20/20, Loss: 0.5688
Epoch 9/10, Train Loss: 0.3095, Valid Loss: 0.4265
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1847
Epoch 10/10, Batch 20/20, Loss: 0.7260
Epoch 10/10, Train Loss: 0.2955, Valid Loss: 0.4083
Model saved!
Accuracy: 0.8914
Precision: 0.8863
Recall: 0.8914
F1-score: 0.8868
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2233
Epoch 1/10, Batch 20/20, Loss: 1.3865
Epoch 1/10, Train Loss: 1.2800, Valid Loss: 1.0735
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8464
Epoch 2/10, Batch 20/20, Loss: 0.7116
Epoch 2/10, Train Loss: 0.8039, Valid Loss: 0.7632
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7612
Epoch 3/10, Batch 20/20, Loss: 0.8423
Epoch 3/10, Train Loss: 0.6160, Valid Loss: 0.6436
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3990
Epoch 4/10, Batch 20/20, Loss: 0.3854
Epoch 4/10, Train Loss: 0.4771, Valid Loss: 0.5540
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3893
Epoch 5/10, Batch 20/20, Loss: 0.4731
Epoch 5/10, Train Loss: 0.4217, Valid Loss: 0.5189
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5944
Epoch 6/10, Batch 20/20, Loss: 0.5543
Epoch 6/10, Train Loss: 0.3842, Valid Loss: 0.4757
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3037
Epoch 7/10, Batch 20/20, Loss: 0.7378
Epoch 7/10, Train Loss: 0.3506, Valid Loss: 0.4454
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3840
Epoch 8/10, Batch 20/20, Loss: 0.3701
Epoch 8/10, Train Loss: 0.3127, Valid Loss: 0.4347
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2990
Epoch 9/10, Batch 20/20, Loss: 0.3884
Epoch 9/10, Train Loss: 0.2838, Valid Loss: 0.4146
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2634
Epoch 10/10, Batch 20/20, Loss: 0.4221
Epoch 10/10, Train Loss: 0.2697, Valid Loss: 0.4082
Model saved!
Accuracy: 0.8762
Precision: 0.8732
Recall: 0.8762
F1-score: 0.8703
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1886
Epoch 1/10, Batch 20/20, Loss: 1.2925
Epoch 1/10, Train Loss: 1.2658, Valid Loss: 1.0543
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9903
Epoch 2/10, Batch 20/20, Loss: 0.6336
Epoch 2/10, Train Loss: 0.7828, Valid Loss: 0.7248
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8621
Epoch 3/10, Batch 20/20, Loss: 0.6978
Epoch 3/10, Train Loss: 0.5869, Valid Loss: 0.5900
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4437
Epoch 4/10, Batch 20/20, Loss: 0.4139
Epoch 4/10, Train Loss: 0.4689, Valid Loss: 0.5240
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5475
Epoch 5/10, Batch 20/20, Loss: 0.5993
Epoch 5/10, Train Loss: 0.4089, Valid Loss: 0.4834
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5020
Epoch 6/10, Batch 20/20, Loss: 0.3884
Epoch 6/10, Train Loss: 0.3515, Valid Loss: 0.4505
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2184
Epoch 7/10, Batch 20/20, Loss: 0.3709
Epoch 7/10, Train Loss: 0.3184, Valid Loss: 0.4296
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4821
Epoch 8/10, Batch 20/20, Loss: 0.3613
Epoch 8/10, Train Loss: 0.3037, Valid Loss: 0.4226
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2885
Epoch 9/10, Batch 20/20, Loss: 0.5174
Epoch 9/10, Train Loss: 0.2603, Valid Loss: 0.3961
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2724
Epoch 10/10, Batch 20/20, Loss: 0.6663
Epoch 10/10, Train Loss: 0.2611, Valid Loss: 0.4027
Accuracy: 0.8808
Precision: 0.8805
Recall: 0.8808
F1-score: 0.8794
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2359
Epoch 1/10, Batch 20/20, Loss: 1.2981
Epoch 1/10, Train Loss: 1.2794, Valid Loss: 0.9996
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9332
Epoch 2/10, Batch 20/20, Loss: 0.6812
Epoch 2/10, Train Loss: 0.7997, Valid Loss: 0.7105
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7423
Epoch 3/10, Batch 20/20, Loss: 0.6904
Epoch 3/10, Train Loss: 0.6043, Valid Loss: 0.5816
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4746
Epoch 4/10, Batch 20/20, Loss: 0.4156
Epoch 4/10, Train Loss: 0.4876, Valid Loss: 0.5125
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3831
Epoch 5/10, Batch 20/20, Loss: 0.8797
Epoch 5/10, Train Loss: 0.4364, Valid Loss: 0.4591
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.3970
Epoch 6/10, Batch 20/20, Loss: 0.3794
Epoch 6/10, Train Loss: 0.3818, Valid Loss: 0.4257
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2483
Epoch 7/10, Batch 20/20, Loss: 0.3670
Epoch 7/10, Train Loss: 0.3388, Valid Loss: 0.4051
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4159
Epoch 8/10, Batch 20/20, Loss: 0.2942
Epoch 8/10, Train Loss: 0.3233, Valid Loss: 0.3974
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3869
Epoch 9/10, Batch 20/20, Loss: 0.5833
Epoch 9/10, Train Loss: 0.3004, Valid Loss: 0.3716
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3899
Epoch 10/10, Batch 20/20, Loss: 0.5370
Epoch 10/10, Train Loss: 0.2757, Valid Loss: 0.3613
Model saved!
Accuracy: 0.8914
Precision: 0.8884
Recall: 0.8914
F1-score: 0.8875
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2095
Epoch 1/10, Batch 20/20, Loss: 1.1968
Epoch 1/10, Train Loss: 1.2782, Valid Loss: 1.0178
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8476
Epoch 2/10, Batch 20/20, Loss: 0.7824
Epoch 2/10, Train Loss: 0.7979, Valid Loss: 0.7200
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7596
Epoch 3/10, Batch 20/20, Loss: 0.8684
Epoch 3/10, Train Loss: 0.6021, Valid Loss: 0.6062
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3828
Epoch 4/10, Batch 20/20, Loss: 0.4493
Epoch 4/10, Train Loss: 0.4784, Valid Loss: 0.5346
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.2957
Epoch 5/10, Batch 20/20, Loss: 0.6354
Epoch 5/10, Train Loss: 0.4192, Valid Loss: 0.5050
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4854
Epoch 6/10, Batch 20/20, Loss: 0.3725
Epoch 6/10, Train Loss: 0.3773, Valid Loss: 0.4606
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2773
Epoch 7/10, Batch 20/20, Loss: 0.2832
Epoch 7/10, Train Loss: 0.3242, Valid Loss: 0.4498
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3618
Epoch 8/10, Batch 20/20, Loss: 0.6603
Epoch 8/10, Train Loss: 0.3214, Valid Loss: 0.4332
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3748
Epoch 9/10, Batch 20/20, Loss: 0.4611
Epoch 9/10, Train Loss: 0.2946, Valid Loss: 0.4241
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2157
Epoch 10/10, Batch 20/20, Loss: 0.7880
Epoch 10/10, Train Loss: 0.2928, Valid Loss: 0.4199
Model saved!
Accuracy: 0.8703
Precision: 0.8669
Recall: 0.8703
F1-score: 0.8627
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2138
Epoch 1/10, Batch 20/20, Loss: 1.2351
Epoch 1/10, Train Loss: 1.2856, Valid Loss: 1.0028
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8787
Epoch 2/10, Batch 20/20, Loss: 0.7148
Epoch 2/10, Train Loss: 0.8237, Valid Loss: 0.7138
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7465
Epoch 3/10, Batch 20/20, Loss: 0.7634
Epoch 3/10, Train Loss: 0.6289, Valid Loss: 0.5737
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4321
Epoch 4/10, Batch 20/20, Loss: 0.4440
Epoch 4/10, Train Loss: 0.4841, Valid Loss: 0.5089
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3955
Epoch 5/10, Batch 20/20, Loss: 0.6434
Epoch 5/10, Train Loss: 0.4502, Valid Loss: 0.4503
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4815
Epoch 6/10, Batch 20/20, Loss: 0.4633
Epoch 6/10, Train Loss: 0.3988, Valid Loss: 0.4307
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3965
Epoch 7/10, Batch 20/20, Loss: 0.7067
Epoch 7/10, Train Loss: 0.3544, Valid Loss: 0.4089
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3722
Epoch 8/10, Batch 20/20, Loss: 0.3554
Epoch 8/10, Train Loss: 0.3254, Valid Loss: 0.3839
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5252
Epoch 9/10, Batch 20/20, Loss: 0.3442
Epoch 9/10, Train Loss: 0.2941, Valid Loss: 0.3657
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2736
Epoch 10/10, Batch 20/20, Loss: 0.6014
Epoch 10/10, Train Loss: 0.2754, Valid Loss: 0.3680
Accuracy: 0.8855
Precision: 0.8800
Recall: 0.8855
F1-score: 0.8819
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1172
Epoch 1/10, Batch 20/20, Loss: 1.1643
Epoch 1/10, Train Loss: 1.2675, Valid Loss: 0.9770
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9688
Epoch 2/10, Batch 20/20, Loss: 0.6462
Epoch 2/10, Train Loss: 0.7896, Valid Loss: 0.6839
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7100
Epoch 3/10, Batch 20/20, Loss: 0.8397
Epoch 3/10, Train Loss: 0.5984, Valid Loss: 0.5642
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5234
Epoch 4/10, Batch 20/20, Loss: 0.6618
Epoch 4/10, Train Loss: 0.4730, Valid Loss: 0.4968
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3794
Epoch 5/10, Batch 20/20, Loss: 0.6232
Epoch 5/10, Train Loss: 0.4060, Valid Loss: 0.4573
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4302
Epoch 6/10, Batch 20/20, Loss: 0.6183
Epoch 6/10, Train Loss: 0.3716, Valid Loss: 0.4253
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3472
Epoch 7/10, Batch 20/20, Loss: 0.2046
Epoch 7/10, Train Loss: 0.3027, Valid Loss: 0.4082
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3788
Epoch 8/10, Batch 20/20, Loss: 0.5421
Epoch 8/10, Train Loss: 0.2934, Valid Loss: 0.4029
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3170
Epoch 9/10, Batch 20/20, Loss: 0.3954
Epoch 9/10, Train Loss: 0.2705, Valid Loss: 0.3857
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2289
Epoch 10/10, Batch 20/20, Loss: 1.0237
Epoch 10/10, Train Loss: 0.2830, Valid Loss: 0.3871
Accuracy: 0.8972
Precision: 0.8904
Recall: 0.8972
F1-score: 0.8912
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 60. Fitness: 0.8972
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2067
Epoch 1/10, Batch 20/20, Loss: 1.3692
Epoch 1/10, Train Loss: 1.2970, Valid Loss: 1.0690
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9640
Epoch 2/10, Batch 20/20, Loss: 0.9010
Epoch 2/10, Train Loss: 0.8274, Valid Loss: 0.7366
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7078
Epoch 3/10, Batch 20/20, Loss: 0.8434
Epoch 3/10, Train Loss: 0.6352, Valid Loss: 0.6131
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4709
Epoch 4/10, Batch 20/20, Loss: 0.4461
Epoch 4/10, Train Loss: 0.5085, Valid Loss: 0.5332
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4204
Epoch 5/10, Batch 20/20, Loss: 0.4294
Epoch 5/10, Train Loss: 0.4338, Valid Loss: 0.4845
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4890
Epoch 6/10, Batch 20/20, Loss: 0.4731
Epoch 6/10, Train Loss: 0.3965, Valid Loss: 0.4508
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3533
Epoch 7/10, Batch 20/20, Loss: 0.3623
Epoch 7/10, Train Loss: 0.3678, Valid Loss: 0.4384
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3326
Epoch 8/10, Batch 20/20, Loss: 0.4487
Epoch 8/10, Train Loss: 0.3403, Valid Loss: 0.4252
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3555
Epoch 9/10, Batch 20/20, Loss: 0.6947
Epoch 9/10, Train Loss: 0.3188, Valid Loss: 0.4020
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3404
Epoch 10/10, Batch 20/20, Loss: 0.6870
Epoch 10/10, Train Loss: 0.3087, Valid Loss: 0.3982
Model saved!
Accuracy: 0.8797
Precision: 0.8731
Recall: 0.8797
F1-score: 0.8744
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3520
Epoch 1/10, Batch 20/20, Loss: 1.3227
Epoch 1/10, Train Loss: 1.3008, Valid Loss: 1.0784
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9619
Epoch 2/10, Batch 20/20, Loss: 0.5605
Epoch 2/10, Train Loss: 0.8460, Valid Loss: 0.7619
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7811
Epoch 3/10, Batch 20/20, Loss: 0.9717
Epoch 3/10, Train Loss: 0.6604, Valid Loss: 0.6204
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4872
Epoch 4/10, Batch 20/20, Loss: 0.5298
Epoch 4/10, Train Loss: 0.5274, Valid Loss: 0.5570
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3907
Epoch 5/10, Batch 20/20, Loss: 0.8228
Epoch 5/10, Train Loss: 0.4893, Valid Loss: 0.5149
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5204
Epoch 6/10, Batch 20/20, Loss: 0.6711
Epoch 6/10, Train Loss: 0.4238, Valid Loss: 0.4705
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3877
Epoch 7/10, Batch 20/20, Loss: 0.3712
Epoch 7/10, Train Loss: 0.3774, Valid Loss: 0.4432
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4253
Epoch 8/10, Batch 20/20, Loss: 0.5928
Epoch 8/10, Train Loss: 0.3584, Valid Loss: 0.4326
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3563
Epoch 9/10, Batch 20/20, Loss: 0.3443
Epoch 9/10, Train Loss: 0.3184, Valid Loss: 0.4181
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.4510
Epoch 10/10, Batch 20/20, Loss: 0.4233
Epoch 10/10, Train Loss: 0.3078, Valid Loss: 0.4188
Accuracy: 0.8832
Precision: 0.8802
Recall: 0.8832
F1-score: 0.8811
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1935
Epoch 1/10, Batch 20/20, Loss: 1.2337
Epoch 1/10, Train Loss: 1.2784, Valid Loss: 1.0271
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0147
Epoch 2/10, Batch 20/20, Loss: 0.5985
Epoch 2/10, Train Loss: 0.8155, Valid Loss: 0.6965
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6774
Epoch 3/10, Batch 20/20, Loss: 0.6768
Epoch 3/10, Train Loss: 0.6143, Valid Loss: 0.5525
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4700
Epoch 4/10, Batch 20/20, Loss: 0.5042
Epoch 4/10, Train Loss: 0.5031, Valid Loss: 0.4983
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4228
Epoch 5/10, Batch 20/20, Loss: 0.5391
Epoch 5/10, Train Loss: 0.4348, Valid Loss: 0.4336
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5008
Epoch 6/10, Batch 20/20, Loss: 0.3749
Epoch 6/10, Train Loss: 0.3863, Valid Loss: 0.4019
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3754
Epoch 7/10, Batch 20/20, Loss: 0.5480
Epoch 7/10, Train Loss: 0.3406, Valid Loss: 0.3831
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4395
Epoch 8/10, Batch 20/20, Loss: 0.4759
Epoch 8/10, Train Loss: 0.3253, Valid Loss: 0.3645
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3846
Epoch 9/10, Batch 20/20, Loss: 0.4891
Epoch 9/10, Train Loss: 0.3067, Valid Loss: 0.3429
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3570
Epoch 10/10, Batch 20/20, Loss: 0.5836
Epoch 10/10, Train Loss: 0.2884, Valid Loss: 0.3452
Accuracy: 0.8937
Precision: 0.8877
Recall: 0.8937
F1-score: 0.8895
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1571
Epoch 1/10, Batch 20/20, Loss: 1.3496
Epoch 1/10, Train Loss: 1.2736, Valid Loss: 1.0174
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0775
Epoch 2/10, Batch 20/20, Loss: 0.5257
Epoch 2/10, Train Loss: 0.7924, Valid Loss: 0.7099
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5414
Epoch 3/10, Batch 20/20, Loss: 0.7320
Epoch 3/10, Train Loss: 0.6119, Valid Loss: 0.5875
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5632
Epoch 4/10, Batch 20/20, Loss: 0.5628
Epoch 4/10, Train Loss: 0.4982, Valid Loss: 0.5033
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4724
Epoch 5/10, Batch 20/20, Loss: 0.5153
Epoch 5/10, Train Loss: 0.4144, Valid Loss: 0.4446
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4523
Epoch 6/10, Batch 20/20, Loss: 0.6224
Epoch 6/10, Train Loss: 0.3816, Valid Loss: 0.4103
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3271
Epoch 7/10, Batch 20/20, Loss: 0.5192
Epoch 7/10, Train Loss: 0.3338, Valid Loss: 0.3752
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4215
Epoch 8/10, Batch 20/20, Loss: 0.4377
Epoch 8/10, Train Loss: 0.3132, Valid Loss: 0.3634
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3672
Epoch 9/10, Batch 20/20, Loss: 0.4954
Epoch 9/10, Train Loss: 0.2863, Valid Loss: 0.3398
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3452
Epoch 10/10, Batch 20/20, Loss: 0.7504
Epoch 10/10, Train Loss: 0.2794, Valid Loss: 0.3239
Model saved!
Accuracy: 0.8867
Precision: 0.8809
Recall: 0.8867
F1-score: 0.8827
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1524
Epoch 1/10, Batch 20/20, Loss: 1.2798
Epoch 1/10, Train Loss: 1.2710, Valid Loss: 0.9961
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9263
Epoch 2/10, Batch 20/20, Loss: 0.6725
Epoch 2/10, Train Loss: 0.8054, Valid Loss: 0.6836
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7505
Epoch 3/10, Batch 20/20, Loss: 0.8993
Epoch 3/10, Train Loss: 0.6139, Valid Loss: 0.5494
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4755
Epoch 4/10, Batch 20/20, Loss: 0.2807
Epoch 4/10, Train Loss: 0.4810, Valid Loss: 0.4759
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4241
Epoch 5/10, Batch 20/20, Loss: 0.7488
Epoch 5/10, Train Loss: 0.4380, Valid Loss: 0.4328
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6436
Epoch 6/10, Batch 20/20, Loss: 0.3438
Epoch 6/10, Train Loss: 0.3631, Valid Loss: 0.3901
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2767
Epoch 7/10, Batch 20/20, Loss: 0.5707
Epoch 7/10, Train Loss: 0.3454, Valid Loss: 0.3645
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4765
Epoch 8/10, Batch 20/20, Loss: 0.5041
Epoch 8/10, Train Loss: 0.3246, Valid Loss: 0.3585
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2945
Epoch 9/10, Batch 20/20, Loss: 0.3542
Epoch 9/10, Train Loss: 0.2810, Valid Loss: 0.3384
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3600
Epoch 10/10, Batch 20/20, Loss: 0.4035
Epoch 10/10, Train Loss: 0.2719, Valid Loss: 0.3332
Model saved!
Accuracy: 0.8808
Precision: 0.8755
Recall: 0.8808
F1-score: 0.8752
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1809
Epoch 1/10, Batch 20/20, Loss: 1.2516
Epoch 1/10, Train Loss: 1.2890, Valid Loss: 1.0628
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9686
Epoch 2/10, Batch 20/20, Loss: 0.7897
Epoch 2/10, Train Loss: 0.8118, Valid Loss: 0.7379
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7372
Epoch 3/10, Batch 20/20, Loss: 0.7640
Epoch 3/10, Train Loss: 0.6173, Valid Loss: 0.5976
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5069
Epoch 4/10, Batch 20/20, Loss: 0.4063
Epoch 4/10, Train Loss: 0.4960, Valid Loss: 0.5264
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4402
Epoch 5/10, Batch 20/20, Loss: 0.5601
Epoch 5/10, Train Loss: 0.4388, Valid Loss: 0.4798
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4873
Epoch 6/10, Batch 20/20, Loss: 0.4695
Epoch 6/10, Train Loss: 0.3956, Valid Loss: 0.4400
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3203
Epoch 7/10, Batch 20/20, Loss: 0.5850
Epoch 7/10, Train Loss: 0.3619, Valid Loss: 0.4085
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3360
Epoch 8/10, Batch 20/20, Loss: 0.4411
Epoch 8/10, Train Loss: 0.3174, Valid Loss: 0.3875
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3453
Epoch 9/10, Batch 20/20, Loss: 0.5290
Epoch 9/10, Train Loss: 0.2951, Valid Loss: 0.3794
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2444
Epoch 10/10, Batch 20/20, Loss: 0.8944
Epoch 10/10, Train Loss: 0.3012, Valid Loss: 0.3667
Model saved!
Accuracy: 0.8855
Precision: 0.8808
Recall: 0.8855
F1-score: 0.8806
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2239
Epoch 1/10, Batch 20/20, Loss: 1.3426
Epoch 1/10, Train Loss: 1.2720, Valid Loss: 1.0160
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8784
Epoch 2/10, Batch 20/20, Loss: 0.6012
Epoch 2/10, Train Loss: 0.7744, Valid Loss: 0.7298
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6527
Epoch 3/10, Batch 20/20, Loss: 0.7951
Epoch 3/10, Train Loss: 0.5903, Valid Loss: 0.6199
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5868
Epoch 4/10, Batch 20/20, Loss: 0.4493
Epoch 4/10, Train Loss: 0.4795, Valid Loss: 0.5522
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3856
Epoch 5/10, Batch 20/20, Loss: 0.5627
Epoch 5/10, Train Loss: 0.4154, Valid Loss: 0.5194
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4878
Epoch 6/10, Batch 20/20, Loss: 0.4429
Epoch 6/10, Train Loss: 0.3746, Valid Loss: 0.4948
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2660
Epoch 7/10, Batch 20/20, Loss: 0.3982
Epoch 7/10, Train Loss: 0.3449, Valid Loss: 0.4692
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4435
Epoch 8/10, Batch 20/20, Loss: 0.6395
Epoch 8/10, Train Loss: 0.3224, Valid Loss: 0.4635
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3109
Epoch 9/10, Batch 20/20, Loss: 0.6204
Epoch 9/10, Train Loss: 0.2819, Valid Loss: 0.4483
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3188
Epoch 10/10, Batch 20/20, Loss: 0.7248
Epoch 10/10, Train Loss: 0.2789, Valid Loss: 0.4414
Model saved!
Accuracy: 0.8843
Precision: 0.8795
Recall: 0.8843
F1-score: 0.8790
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3648
Epoch 1/10, Batch 20/20, Loss: 1.2994
Epoch 1/10, Train Loss: 1.2817, Valid Loss: 1.0740
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9545
Epoch 2/10, Batch 20/20, Loss: 0.7328
Epoch 2/10, Train Loss: 0.8220, Valid Loss: 0.7335
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7170
Epoch 3/10, Batch 20/20, Loss: 0.9262
Epoch 3/10, Train Loss: 0.6263, Valid Loss: 0.6015
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4598
Epoch 4/10, Batch 20/20, Loss: 0.4931
Epoch 4/10, Train Loss: 0.4979, Valid Loss: 0.5291
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3969
Epoch 5/10, Batch 20/20, Loss: 0.7022
Epoch 5/10, Train Loss: 0.4215, Valid Loss: 0.4732
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6716
Epoch 6/10, Batch 20/20, Loss: 0.4347
Epoch 6/10, Train Loss: 0.3728, Valid Loss: 0.4435
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3112
Epoch 7/10, Batch 20/20, Loss: 0.3087
Epoch 7/10, Train Loss: 0.3264, Valid Loss: 0.4116
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3575
Epoch 8/10, Batch 20/20, Loss: 0.6357
Epoch 8/10, Train Loss: 0.3183, Valid Loss: 0.3957
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2920
Epoch 9/10, Batch 20/20, Loss: 0.7326
Epoch 9/10, Train Loss: 0.2966, Valid Loss: 0.3786
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2726
Epoch 10/10, Batch 20/20, Loss: 0.7411
Epoch 10/10, Train Loss: 0.2708, Valid Loss: 0.3649
Model saved!
Accuracy: 0.8855
Precision: 0.8824
Recall: 0.8855
F1-score: 0.8821
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2260
Epoch 1/10, Batch 20/20, Loss: 1.2858
Epoch 1/10, Train Loss: 1.2788, Valid Loss: 1.0539
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9245
Epoch 2/10, Batch 20/20, Loss: 0.6123
Epoch 2/10, Train Loss: 0.8052, Valid Loss: 0.7477
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.9652
Epoch 3/10, Batch 20/20, Loss: 0.8926
Epoch 3/10, Train Loss: 0.6228, Valid Loss: 0.6264
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5108
Epoch 4/10, Batch 20/20, Loss: 0.5197
Epoch 4/10, Train Loss: 0.5042, Valid Loss: 0.5541
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3829
Epoch 5/10, Batch 20/20, Loss: 0.6489
Epoch 5/10, Train Loss: 0.4465, Valid Loss: 0.5073
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5575
Epoch 6/10, Batch 20/20, Loss: 0.4048
Epoch 6/10, Train Loss: 0.3871, Valid Loss: 0.4816
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2769
Epoch 7/10, Batch 20/20, Loss: 0.6239
Epoch 7/10, Train Loss: 0.3645, Valid Loss: 0.4557
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4273
Epoch 8/10, Batch 20/20, Loss: 0.4981
Epoch 8/10, Train Loss: 0.3417, Valid Loss: 0.4397
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3390
Epoch 9/10, Batch 20/20, Loss: 0.2963
Epoch 9/10, Train Loss: 0.2981, Valid Loss: 0.4229
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2708
Epoch 10/10, Batch 20/20, Loss: 0.4090
Epoch 10/10, Train Loss: 0.2829, Valid Loss: 0.4099
Model saved!
Accuracy: 0.8879
Precision: 0.8826
Recall: 0.8879
F1-score: 0.8806
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.4022
Epoch 1/10, Batch 20/20, Loss: 1.3643
Epoch 1/10, Train Loss: 1.2883, Valid Loss: 1.0682
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8430
Epoch 2/10, Batch 20/20, Loss: 0.7156
Epoch 2/10, Train Loss: 0.8175, Valid Loss: 0.7537
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7306
Epoch 3/10, Batch 20/20, Loss: 0.6974
Epoch 3/10, Train Loss: 0.6158, Valid Loss: 0.6208
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4704
Epoch 4/10, Batch 20/20, Loss: 0.3855
Epoch 4/10, Train Loss: 0.4748, Valid Loss: 0.5426
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4767
Epoch 5/10, Batch 20/20, Loss: 0.7059
Epoch 5/10, Train Loss: 0.4382, Valid Loss: 0.4835
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4790
Epoch 6/10, Batch 20/20, Loss: 0.3180
Epoch 6/10, Train Loss: 0.3904, Valid Loss: 0.4566
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2433
Epoch 7/10, Batch 20/20, Loss: 0.8047
Epoch 7/10, Train Loss: 0.3675, Valid Loss: 0.4308
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3058
Epoch 8/10, Batch 20/20, Loss: 0.8775
Epoch 8/10, Train Loss: 0.3458, Valid Loss: 0.4093
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3234
Epoch 9/10, Batch 20/20, Loss: 0.5559
Epoch 9/10, Train Loss: 0.3026, Valid Loss: 0.3773
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2575
Epoch 10/10, Batch 20/20, Loss: 0.6166
Epoch 10/10, Train Loss: 0.2836, Valid Loss: 0.3760
Model saved!
Accuracy: 0.8820
Precision: 0.8806
Recall: 0.8820
F1-score: 0.8776
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2765
Epoch 1/10, Batch 20/20, Loss: 1.2580
Epoch 1/10, Train Loss: 1.2848, Valid Loss: 1.0564
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8739
Epoch 2/10, Batch 20/20, Loss: 0.5131
Epoch 2/10, Train Loss: 0.8068, Valid Loss: 0.7340
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7493
Epoch 3/10, Batch 20/20, Loss: 0.8527
Epoch 3/10, Train Loss: 0.6292, Valid Loss: 0.6117
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4772
Epoch 4/10, Batch 20/20, Loss: 0.7561
Epoch 4/10, Train Loss: 0.5055, Valid Loss: 0.5470
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3183
Epoch 5/10, Batch 20/20, Loss: 0.6681
Epoch 5/10, Train Loss: 0.4391, Valid Loss: 0.4983
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5574
Epoch 6/10, Batch 20/20, Loss: 0.5556
Epoch 6/10, Train Loss: 0.3860, Valid Loss: 0.4725
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2480
Epoch 7/10, Batch 20/20, Loss: 0.3276
Epoch 7/10, Train Loss: 0.3526, Valid Loss: 0.4530
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5439
Epoch 8/10, Batch 20/20, Loss: 0.8397
Epoch 8/10, Train Loss: 0.3564, Valid Loss: 0.4452
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4217
Epoch 9/10, Batch 20/20, Loss: 0.4452
Epoch 9/10, Train Loss: 0.3015, Valid Loss: 0.4174
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3513
Epoch 10/10, Batch 20/20, Loss: 0.6811
Epoch 10/10, Train Loss: 0.2927, Valid Loss: 0.4208
Accuracy: 0.8879
Precision: 0.8846
Recall: 0.8879
F1-score: 0.8814
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2326
Epoch 1/10, Batch 20/20, Loss: 1.3827
Epoch 1/10, Train Loss: 1.2827, Valid Loss: 1.0679
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9185
Epoch 2/10, Batch 20/20, Loss: 0.5983
Epoch 2/10, Train Loss: 0.8053, Valid Loss: 0.7606
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8516
Epoch 3/10, Batch 20/20, Loss: 0.8562
Epoch 3/10, Train Loss: 0.6214, Valid Loss: 0.6385
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4124
Epoch 4/10, Batch 20/20, Loss: 0.5429
Epoch 4/10, Train Loss: 0.4978, Valid Loss: 0.5809
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4251
Epoch 5/10, Batch 20/20, Loss: 0.6421
Epoch 5/10, Train Loss: 0.4339, Valid Loss: 0.5286
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4687
Epoch 6/10, Batch 20/20, Loss: 0.2973
Epoch 6/10, Train Loss: 0.3942, Valid Loss: 0.4969
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3212
Epoch 7/10, Batch 20/20, Loss: 0.7336
Epoch 7/10, Train Loss: 0.3595, Valid Loss: 0.4747
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3653
Epoch 8/10, Batch 20/20, Loss: 0.2284
Epoch 8/10, Train Loss: 0.3257, Valid Loss: 0.4654
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2934
Epoch 9/10, Batch 20/20, Loss: 0.4517
Epoch 9/10, Train Loss: 0.3184, Valid Loss: 0.4410
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3503
Epoch 10/10, Batch 20/20, Loss: 0.4412
Epoch 10/10, Train Loss: 0.2745, Valid Loss: 0.4381
Model saved!
Accuracy: 0.8843
Precision: 0.8795
Recall: 0.8843
F1-score: 0.8783
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3714
Epoch 1/10, Batch 20/20, Loss: 1.3842
Epoch 1/10, Train Loss: 1.3094, Valid Loss: 1.0672
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.1005
Epoch 2/10, Batch 20/20, Loss: 0.5774
Epoch 2/10, Train Loss: 0.8279, Valid Loss: 0.7449
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7599
Epoch 3/10, Batch 20/20, Loss: 0.9754
Epoch 3/10, Train Loss: 0.6361, Valid Loss: 0.6266
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5255
Epoch 4/10, Batch 20/20, Loss: 0.6755
Epoch 4/10, Train Loss: 0.5261, Valid Loss: 0.5347
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4454
Epoch 5/10, Batch 20/20, Loss: 0.5448
Epoch 5/10, Train Loss: 0.4537, Valid Loss: 0.5046
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5185
Epoch 6/10, Batch 20/20, Loss: 0.7185
Epoch 6/10, Train Loss: 0.4204, Valid Loss: 0.4604
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2958
Epoch 7/10, Batch 20/20, Loss: 0.3977
Epoch 7/10, Train Loss: 0.3603, Valid Loss: 0.4400
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5573
Epoch 8/10, Batch 20/20, Loss: 0.3707
Epoch 8/10, Train Loss: 0.3446, Valid Loss: 0.4222
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2867
Epoch 9/10, Batch 20/20, Loss: 0.3596
Epoch 9/10, Train Loss: 0.3049, Valid Loss: 0.4075
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3661
Epoch 10/10, Batch 20/20, Loss: 0.7512
Epoch 10/10, Train Loss: 0.3025, Valid Loss: 0.3996
Model saved!
Accuracy: 0.8738
Precision: 0.8712
Recall: 0.8738
F1-score: 0.8695
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1927
Epoch 1/10, Batch 20/20, Loss: 1.1647
Epoch 1/10, Train Loss: 1.2747, Valid Loss: 1.0679
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9687
Epoch 2/10, Batch 20/20, Loss: 0.5808
Epoch 2/10, Train Loss: 0.8040, Valid Loss: 0.7680
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7261
Epoch 3/10, Batch 20/20, Loss: 0.7625
Epoch 3/10, Train Loss: 0.6319, Valid Loss: 0.6553
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3975
Epoch 4/10, Batch 20/20, Loss: 0.4862
Epoch 4/10, Train Loss: 0.4921, Valid Loss: 0.5790
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3480
Epoch 5/10, Batch 20/20, Loss: 0.6460
Epoch 5/10, Train Loss: 0.4530, Valid Loss: 0.5364
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6208
Epoch 6/10, Batch 20/20, Loss: 0.5343
Epoch 6/10, Train Loss: 0.3883, Valid Loss: 0.4991
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3038
Epoch 7/10, Batch 20/20, Loss: 0.4122
Epoch 7/10, Train Loss: 0.3586, Valid Loss: 0.4777
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4056
Epoch 8/10, Batch 20/20, Loss: 0.5246
Epoch 8/10, Train Loss: 0.3368, Valid Loss: 0.4559
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3558
Epoch 9/10, Batch 20/20, Loss: 0.5562
Epoch 9/10, Train Loss: 0.3210, Valid Loss: 0.4475
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2486
Epoch 10/10, Batch 20/20, Loss: 0.6974
Epoch 10/10, Train Loss: 0.3158, Valid Loss: 0.4326
Model saved!
Accuracy: 0.8855
Precision: 0.8793
Recall: 0.8855
F1-score: 0.8780
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1583
Epoch 1/10, Batch 20/20, Loss: 1.3921
Epoch 1/10, Train Loss: 1.2688, Valid Loss: 1.0421
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8564
Epoch 2/10, Batch 20/20, Loss: 0.7719
Epoch 2/10, Train Loss: 0.7826, Valid Loss: 0.7350
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6877
Epoch 3/10, Batch 20/20, Loss: 0.6375
Epoch 3/10, Train Loss: 0.5994, Valid Loss: 0.6101
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5162
Epoch 4/10, Batch 20/20, Loss: 0.4698
Epoch 4/10, Train Loss: 0.4744, Valid Loss: 0.5367
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3150
Epoch 5/10, Batch 20/20, Loss: 0.5354
Epoch 5/10, Train Loss: 0.4041, Valid Loss: 0.4809
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5124
Epoch 6/10, Batch 20/20, Loss: 0.2253
Epoch 6/10, Train Loss: 0.3631, Valid Loss: 0.4436
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2406
Epoch 7/10, Batch 20/20, Loss: 0.3880
Epoch 7/10, Train Loss: 0.3216, Valid Loss: 0.4105
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3426
Epoch 8/10, Batch 20/20, Loss: 0.3221
Epoch 8/10, Train Loss: 0.2972, Valid Loss: 0.3987
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3346
Epoch 9/10, Batch 20/20, Loss: 0.9559
Epoch 9/10, Train Loss: 0.2978, Valid Loss: 0.3678
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2429
Epoch 10/10, Batch 20/20, Loss: 0.4851
Epoch 10/10, Train Loss: 0.2718, Valid Loss: 0.3782
Accuracy: 0.8937
Precision: 0.8891
Recall: 0.8937
F1-score: 0.8889
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1404
Epoch 1/10, Batch 20/20, Loss: 1.2292
Epoch 1/10, Train Loss: 1.2779, Valid Loss: 1.0024
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9624
Epoch 2/10, Batch 20/20, Loss: 0.5779
Epoch 2/10, Train Loss: 0.8065, Valid Loss: 0.7162
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7064
Epoch 3/10, Batch 20/20, Loss: 1.0524
Epoch 3/10, Train Loss: 0.6220, Valid Loss: 0.5882
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5955
Epoch 4/10, Batch 20/20, Loss: 0.5278
Epoch 4/10, Train Loss: 0.4924, Valid Loss: 0.5176
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3895
Epoch 5/10, Batch 20/20, Loss: 0.6305
Epoch 5/10, Train Loss: 0.4329, Valid Loss: 0.4790
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5763
Epoch 6/10, Batch 20/20, Loss: 0.4403
Epoch 6/10, Train Loss: 0.3756, Valid Loss: 0.4465
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2413
Epoch 7/10, Batch 20/20, Loss: 0.5617
Epoch 7/10, Train Loss: 0.3435, Valid Loss: 0.4210
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4114
Epoch 8/10, Batch 20/20, Loss: 0.6433
Epoch 8/10, Train Loss: 0.3260, Valid Loss: 0.4139
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3393
Epoch 9/10, Batch 20/20, Loss: 0.7001
Epoch 9/10, Train Loss: 0.2940, Valid Loss: 0.3880
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2508
Epoch 10/10, Batch 20/20, Loss: 0.7763
Epoch 10/10, Train Loss: 0.2807, Valid Loss: 0.3869
Model saved!
Accuracy: 0.8914
Precision: 0.8896
Recall: 0.8914
F1-score: 0.8860
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1955
Epoch 1/10, Batch 20/20, Loss: 1.2001
Epoch 1/10, Train Loss: 1.2800, Valid Loss: 0.9528
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8983
Epoch 2/10, Batch 20/20, Loss: 0.6826
Epoch 2/10, Train Loss: 0.7961, Valid Loss: 0.6577
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7164
Epoch 3/10, Batch 20/20, Loss: 0.8859
Epoch 3/10, Train Loss: 0.6091, Valid Loss: 0.5374
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3643
Epoch 4/10, Batch 20/20, Loss: 0.5158
Epoch 4/10, Train Loss: 0.4782, Valid Loss: 0.4708
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5382
Epoch 5/10, Batch 20/20, Loss: 0.6965
Epoch 5/10, Train Loss: 0.4218, Valid Loss: 0.4308
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5567
Epoch 6/10, Batch 20/20, Loss: 0.2963
Epoch 6/10, Train Loss: 0.3790, Valid Loss: 0.3939
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2614
Epoch 7/10, Batch 20/20, Loss: 0.6492
Epoch 7/10, Train Loss: 0.3336, Valid Loss: 0.3770
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4559
Epoch 8/10, Batch 20/20, Loss: 0.9656
Epoch 8/10, Train Loss: 0.3360, Valid Loss: 0.3666
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3375
Epoch 9/10, Batch 20/20, Loss: 0.7678
Epoch 9/10, Train Loss: 0.3045, Valid Loss: 0.3664
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2032
Epoch 10/10, Batch 20/20, Loss: 0.7390
Epoch 10/10, Train Loss: 0.2903, Valid Loss: 0.3549
Model saved!
Accuracy: 0.8820
Precision: 0.8784
Recall: 0.8820
F1-score: 0.8766
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1793
Epoch 1/10, Batch 20/20, Loss: 1.2955
Epoch 1/10, Train Loss: 1.2697, Valid Loss: 0.9662
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9264
Epoch 2/10, Batch 20/20, Loss: 0.7904
Epoch 2/10, Train Loss: 0.8039, Valid Loss: 0.6930
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7062
Epoch 3/10, Batch 20/20, Loss: 0.7470
Epoch 3/10, Train Loss: 0.6053, Valid Loss: 0.5866
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5581
Epoch 4/10, Batch 20/20, Loss: 0.4159
Epoch 4/10, Train Loss: 0.4779, Valid Loss: 0.5096
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4257
Epoch 5/10, Batch 20/20, Loss: 0.6314
Epoch 5/10, Train Loss: 0.4364, Valid Loss: 0.4785
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5227
Epoch 6/10, Batch 20/20, Loss: 0.4259
Epoch 6/10, Train Loss: 0.3831, Valid Loss: 0.4467
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2964
Epoch 7/10, Batch 20/20, Loss: 0.4183
Epoch 7/10, Train Loss: 0.3411, Valid Loss: 0.4255
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4695
Epoch 8/10, Batch 20/20, Loss: 0.2469
Epoch 8/10, Train Loss: 0.3144, Valid Loss: 0.4199
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4867
Epoch 9/10, Batch 20/20, Loss: 0.4502
Epoch 9/10, Train Loss: 0.2886, Valid Loss: 0.4069
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2217
Epoch 10/10, Batch 20/20, Loss: 0.7701
Epoch 10/10, Train Loss: 0.2950, Valid Loss: 0.3940
Model saved!
Accuracy: 0.8808
Precision: 0.8753
Recall: 0.8808
F1-score: 0.8747
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1780
Epoch 1/10, Batch 20/20, Loss: 1.1897
Epoch 1/10, Train Loss: 1.2775, Valid Loss: 1.0611
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9745
Epoch 2/10, Batch 20/20, Loss: 0.6000
Epoch 2/10, Train Loss: 0.7997, Valid Loss: 0.7171
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7767
Epoch 3/10, Batch 20/20, Loss: 0.6968
Epoch 3/10, Train Loss: 0.5996, Valid Loss: 0.5915
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5131
Epoch 4/10, Batch 20/20, Loss: 0.6769
Epoch 4/10, Train Loss: 0.5048, Valid Loss: 0.5281
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5008
Epoch 5/10, Batch 20/20, Loss: 0.6174
Epoch 5/10, Train Loss: 0.4309, Valid Loss: 0.4723
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4252
Epoch 6/10, Batch 20/20, Loss: 0.2563
Epoch 6/10, Train Loss: 0.3701, Valid Loss: 0.4479
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3370
Epoch 7/10, Batch 20/20, Loss: 0.3381
Epoch 7/10, Train Loss: 0.3404, Valid Loss: 0.4192
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3735
Epoch 8/10, Batch 20/20, Loss: 0.3529
Epoch 8/10, Train Loss: 0.3069, Valid Loss: 0.4081
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2954
Epoch 9/10, Batch 20/20, Loss: 0.6850
Epoch 9/10, Train Loss: 0.2935, Valid Loss: 0.3895
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2483
Epoch 10/10, Batch 20/20, Loss: 0.5157
Epoch 10/10, Train Loss: 0.2819, Valid Loss: 0.3941
Accuracy: 0.8867
Precision: 0.8813
Recall: 0.8867
F1-score: 0.8818
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1973
Epoch 1/10, Batch 20/20, Loss: 1.2874
Epoch 1/10, Train Loss: 1.2770, Valid Loss: 1.0307
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9352
Epoch 2/10, Batch 20/20, Loss: 0.6809
Epoch 2/10, Train Loss: 0.8135, Valid Loss: 0.7066
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6450
Epoch 3/10, Batch 20/20, Loss: 0.8074
Epoch 3/10, Train Loss: 0.6104, Valid Loss: 0.5830
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5105
Epoch 4/10, Batch 20/20, Loss: 0.4661
Epoch 4/10, Train Loss: 0.4833, Valid Loss: 0.5069
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3554
Epoch 5/10, Batch 20/20, Loss: 0.4951
Epoch 5/10, Train Loss: 0.4124, Valid Loss: 0.4664
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5668
Epoch 6/10, Batch 20/20, Loss: 0.6009
Epoch 6/10, Train Loss: 0.3858, Valid Loss: 0.4394
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2956
Epoch 7/10, Batch 20/20, Loss: 0.3904
Epoch 7/10, Train Loss: 0.3337, Valid Loss: 0.4128
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4288
Epoch 8/10, Batch 20/20, Loss: 0.4159
Epoch 8/10, Train Loss: 0.3139, Valid Loss: 0.3993
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4560
Epoch 9/10, Batch 20/20, Loss: 0.5821
Epoch 9/10, Train Loss: 0.2805, Valid Loss: 0.3881
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2736
Epoch 10/10, Batch 20/20, Loss: 0.7273
Epoch 10/10, Train Loss: 0.2931, Valid Loss: 0.3806
Model saved!
Accuracy: 0.8808
Precision: 0.8751
Recall: 0.8808
F1-score: 0.8748
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2335
Epoch 1/10, Batch 20/20, Loss: 1.3093
Epoch 1/10, Train Loss: 1.2948, Valid Loss: 1.0261
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9330
Epoch 2/10, Batch 20/20, Loss: 0.5893
Epoch 2/10, Train Loss: 0.8156, Valid Loss: 0.7537
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6852
Epoch 3/10, Batch 20/20, Loss: 0.9443
Epoch 3/10, Train Loss: 0.6354, Valid Loss: 0.6337
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5134
Epoch 4/10, Batch 20/20, Loss: 0.4930
Epoch 4/10, Train Loss: 0.5058, Valid Loss: 0.5644
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3690
Epoch 5/10, Batch 20/20, Loss: 0.5050
Epoch 5/10, Train Loss: 0.4483, Valid Loss: 0.5142
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4702
Epoch 6/10, Batch 20/20, Loss: 0.5415
Epoch 6/10, Train Loss: 0.4063, Valid Loss: 0.4807
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2663
Epoch 7/10, Batch 20/20, Loss: 0.3019
Epoch 7/10, Train Loss: 0.3404, Valid Loss: 0.4590
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4704
Epoch 8/10, Batch 20/20, Loss: 0.3878
Epoch 8/10, Train Loss: 0.3386, Valid Loss: 0.4419
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4263
Epoch 9/10, Batch 20/20, Loss: 0.8260
Epoch 9/10, Train Loss: 0.3250, Valid Loss: 0.4303
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2871
Epoch 10/10, Batch 20/20, Loss: 0.7537
Epoch 10/10, Train Loss: 0.3052, Valid Loss: 0.4119
Model saved!
Accuracy: 0.8925
Precision: 0.8880
Recall: 0.8925
F1-score: 0.8885
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2567
Epoch 1/10, Batch 20/20, Loss: 1.3312
Epoch 1/10, Train Loss: 1.3007, Valid Loss: 1.0191
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9211
Epoch 2/10, Batch 20/20, Loss: 0.6399
Epoch 2/10, Train Loss: 0.8238, Valid Loss: 0.7006
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7219
Epoch 3/10, Batch 20/20, Loss: 0.9788
Epoch 3/10, Train Loss: 0.6445, Valid Loss: 0.5753
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4875
Epoch 4/10, Batch 20/20, Loss: 0.4055
Epoch 4/10, Train Loss: 0.5093, Valid Loss: 0.5047
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3917
Epoch 5/10, Batch 20/20, Loss: 0.6276
Epoch 5/10, Train Loss: 0.4516, Valid Loss: 0.4463
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4907
Epoch 6/10, Batch 20/20, Loss: 0.6413
Epoch 6/10, Train Loss: 0.4120, Valid Loss: 0.4082
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3067
Epoch 7/10, Batch 20/20, Loss: 0.6259
Epoch 7/10, Train Loss: 0.3621, Valid Loss: 0.3822
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4307
Epoch 8/10, Batch 20/20, Loss: 0.4318
Epoch 8/10, Train Loss: 0.3320, Valid Loss: 0.3703
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4288
Epoch 9/10, Batch 20/20, Loss: 0.6782
Epoch 9/10, Train Loss: 0.3151, Valid Loss: 0.3469
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2668
Epoch 10/10, Batch 20/20, Loss: 0.6883
Epoch 10/10, Train Loss: 0.2924, Valid Loss: 0.3462
Model saved!
Accuracy: 0.8890
Precision: 0.8852
Recall: 0.8890
F1-score: 0.8855
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2320
Epoch 1/10, Batch 20/20, Loss: 1.2929
Epoch 1/10, Train Loss: 1.2804, Valid Loss: 1.0668
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9403
Epoch 2/10, Batch 20/20, Loss: 0.5538
Epoch 2/10, Train Loss: 0.7968, Valid Loss: 0.7162
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6728
Epoch 3/10, Batch 20/20, Loss: 0.8645
Epoch 3/10, Train Loss: 0.6143, Valid Loss: 0.5932
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5867
Epoch 4/10, Batch 20/20, Loss: 0.4241
Epoch 4/10, Train Loss: 0.4952, Valid Loss: 0.5233
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4946
Epoch 5/10, Batch 20/20, Loss: 0.6562
Epoch 5/10, Train Loss: 0.4430, Valid Loss: 0.4707
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5001
Epoch 6/10, Batch 20/20, Loss: 0.5015
Epoch 6/10, Train Loss: 0.3922, Valid Loss: 0.4376
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3671
Epoch 7/10, Batch 20/20, Loss: 0.2907
Epoch 7/10, Train Loss: 0.3504, Valid Loss: 0.4016
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2995
Epoch 8/10, Batch 20/20, Loss: 0.3930
Epoch 8/10, Train Loss: 0.3368, Valid Loss: 0.3932
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3878
Epoch 9/10, Batch 20/20, Loss: 0.2970
Epoch 9/10, Train Loss: 0.2920, Valid Loss: 0.3723
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3609
Epoch 10/10, Batch 20/20, Loss: 0.4996
Epoch 10/10, Train Loss: 0.2814, Valid Loss: 0.3707
Model saved!
Accuracy: 0.8949
Precision: 0.8899
Recall: 0.8949
F1-score: 0.8906
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1174
Epoch 1/10, Batch 20/20, Loss: 1.3090
Epoch 1/10, Train Loss: 1.2874, Valid Loss: 0.9775
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0104
Epoch 2/10, Batch 20/20, Loss: 0.6625
Epoch 2/10, Train Loss: 0.8047, Valid Loss: 0.6888
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6191
Epoch 3/10, Batch 20/20, Loss: 0.9192
Epoch 3/10, Train Loss: 0.6168, Valid Loss: 0.5491
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4194
Epoch 4/10, Batch 20/20, Loss: 0.5043
Epoch 4/10, Train Loss: 0.5069, Valid Loss: 0.4910
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4206
Epoch 5/10, Batch 20/20, Loss: 0.7085
Epoch 5/10, Train Loss: 0.4477, Valid Loss: 0.4466
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5022
Epoch 6/10, Batch 20/20, Loss: 0.5382
Epoch 6/10, Train Loss: 0.3885, Valid Loss: 0.4058
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3050
Epoch 7/10, Batch 20/20, Loss: 0.4025
Epoch 7/10, Train Loss: 0.3387, Valid Loss: 0.3967
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4197
Epoch 8/10, Batch 20/20, Loss: 0.5106
Epoch 8/10, Train Loss: 0.3142, Valid Loss: 0.3854
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4910
Epoch 9/10, Batch 20/20, Loss: 0.4622
Epoch 9/10, Train Loss: 0.2871, Valid Loss: 0.3632
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2179
Epoch 10/10, Batch 20/20, Loss: 0.7536
Epoch 10/10, Train Loss: 0.2959, Valid Loss: 0.3687
Accuracy: 0.8890
Precision: 0.8814
Recall: 0.8890
F1-score: 0.8831
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2942
Epoch 1/10, Batch 20/20, Loss: 1.2170
Epoch 1/10, Train Loss: 1.2722, Valid Loss: 1.0745
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9427
Epoch 2/10, Batch 20/20, Loss: 0.6639
Epoch 2/10, Train Loss: 0.8065, Valid Loss: 0.7593
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7624
Epoch 3/10, Batch 20/20, Loss: 0.6191
Epoch 3/10, Train Loss: 0.6221, Valid Loss: 0.6296
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3525
Epoch 4/10, Batch 20/20, Loss: 0.6155
Epoch 4/10, Train Loss: 0.4987, Valid Loss: 0.5411
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3953
Epoch 5/10, Batch 20/20, Loss: 0.6904
Epoch 5/10, Train Loss: 0.4430, Valid Loss: 0.4904
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6372
Epoch 6/10, Batch 20/20, Loss: 0.5378
Epoch 6/10, Train Loss: 0.3909, Valid Loss: 0.4569
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3039
Epoch 7/10, Batch 20/20, Loss: 0.5451
Epoch 7/10, Train Loss: 0.3477, Valid Loss: 0.4381
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3443
Epoch 8/10, Batch 20/20, Loss: 0.3298
Epoch 8/10, Train Loss: 0.3421, Valid Loss: 0.4225
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3044
Epoch 9/10, Batch 20/20, Loss: 0.5647
Epoch 9/10, Train Loss: 0.2950, Valid Loss: 0.4057
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3524
Epoch 10/10, Batch 20/20, Loss: 0.3363
Epoch 10/10, Train Loss: 0.2680, Valid Loss: 0.4056
Model saved!
Accuracy: 0.8750
Precision: 0.8717
Recall: 0.8750
F1-score: 0.8713
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2479
Epoch 1/10, Batch 20/20, Loss: 1.2014
Epoch 1/10, Train Loss: 1.2816, Valid Loss: 1.0009
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0059
Epoch 2/10, Batch 20/20, Loss: 0.9529
Epoch 2/10, Train Loss: 0.8340, Valid Loss: 0.7212
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7545
Epoch 3/10, Batch 20/20, Loss: 0.7116
Epoch 3/10, Train Loss: 0.6178, Valid Loss: 0.6054
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5553
Epoch 4/10, Batch 20/20, Loss: 0.4451
Epoch 4/10, Train Loss: 0.5012, Valid Loss: 0.5249
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4593
Epoch 5/10, Batch 20/20, Loss: 0.6169
Epoch 5/10, Train Loss: 0.4389, Valid Loss: 0.4926
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4977
Epoch 6/10, Batch 20/20, Loss: 0.3792
Epoch 6/10, Train Loss: 0.3886, Valid Loss: 0.4516
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3117
Epoch 7/10, Batch 20/20, Loss: 0.3778
Epoch 7/10, Train Loss: 0.3431, Valid Loss: 0.4308
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4017
Epoch 8/10, Batch 20/20, Loss: 0.3773
Epoch 8/10, Train Loss: 0.3234, Valid Loss: 0.4100
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4396
Epoch 9/10, Batch 20/20, Loss: 0.7993
Epoch 9/10, Train Loss: 0.3181, Valid Loss: 0.4000
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3662
Epoch 10/10, Batch 20/20, Loss: 0.6373
Epoch 10/10, Train Loss: 0.2892, Valid Loss: 0.3909
Model saved!
Accuracy: 0.8914
Precision: 0.8864
Recall: 0.8914
F1-score: 0.8850
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2427
Epoch 1/10, Batch 20/20, Loss: 1.2085
Epoch 1/10, Train Loss: 1.2810, Valid Loss: 0.9869
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9758
Epoch 2/10, Batch 20/20, Loss: 0.7866
Epoch 2/10, Train Loss: 0.8278, Valid Loss: 0.7027
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7528
Epoch 3/10, Batch 20/20, Loss: 0.6460
Epoch 3/10, Train Loss: 0.6162, Valid Loss: 0.5734
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5230
Epoch 4/10, Batch 20/20, Loss: 0.6280
Epoch 4/10, Train Loss: 0.5118, Valid Loss: 0.5013
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3635
Epoch 5/10, Batch 20/20, Loss: 0.5980
Epoch 5/10, Train Loss: 0.4454, Valid Loss: 0.4579
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5098
Epoch 6/10, Batch 20/20, Loss: 0.3739
Epoch 6/10, Train Loss: 0.3897, Valid Loss: 0.4201
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2728
Epoch 7/10, Batch 20/20, Loss: 0.2270
Epoch 7/10, Train Loss: 0.3531, Valid Loss: 0.4016
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4300
Epoch 8/10, Batch 20/20, Loss: 0.4148
Epoch 8/10, Train Loss: 0.3147, Valid Loss: 0.3925
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4027
Epoch 9/10, Batch 20/20, Loss: 0.4654
Epoch 9/10, Train Loss: 0.3072, Valid Loss: 0.3787
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2611
Epoch 10/10, Batch 20/20, Loss: 0.8257
Epoch 10/10, Train Loss: 0.3006, Valid Loss: 0.3746
Model saved!
Accuracy: 0.8820
Precision: 0.8785
Recall: 0.8820
F1-score: 0.8756
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3619
Epoch 1/10, Batch 20/20, Loss: 1.2948
Epoch 1/10, Train Loss: 1.2908, Valid Loss: 1.0357
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9324
Epoch 2/10, Batch 20/20, Loss: 0.6865
Epoch 2/10, Train Loss: 0.8274, Valid Loss: 0.7224
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6431
Epoch 3/10, Batch 20/20, Loss: 0.9180
Epoch 3/10, Train Loss: 0.6324, Valid Loss: 0.5998
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5594
Epoch 4/10, Batch 20/20, Loss: 0.5453
Epoch 4/10, Train Loss: 0.4998, Valid Loss: 0.5415
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4095
Epoch 5/10, Batch 20/20, Loss: 0.6464
Epoch 5/10, Train Loss: 0.4421, Valid Loss: 0.5021
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5404
Epoch 6/10, Batch 20/20, Loss: 0.5917
Epoch 6/10, Train Loss: 0.4150, Valid Loss: 0.4718
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3509
Epoch 7/10, Batch 20/20, Loss: 0.6359
Epoch 7/10, Train Loss: 0.3685, Valid Loss: 0.4451
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2951
Epoch 8/10, Batch 20/20, Loss: 0.5441
Epoch 8/10, Train Loss: 0.3492, Valid Loss: 0.4384
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3699
Epoch 9/10, Batch 20/20, Loss: 0.4661
Epoch 9/10, Train Loss: 0.3223, Valid Loss: 0.4255
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3655
Epoch 10/10, Batch 20/20, Loss: 0.5091
Epoch 10/10, Train Loss: 0.2972, Valid Loss: 0.4282
Accuracy: 0.8890
Precision: 0.8831
Recall: 0.8890
F1-score: 0.8840
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1490
Epoch 1/10, Batch 20/20, Loss: 1.0451
Epoch 1/10, Train Loss: 1.2514, Valid Loss: 0.9674
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8920
Epoch 2/10, Batch 20/20, Loss: 0.7535
Epoch 2/10, Train Loss: 0.7949, Valid Loss: 0.6690
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7375
Epoch 3/10, Batch 20/20, Loss: 0.6120
Epoch 3/10, Train Loss: 0.6030, Valid Loss: 0.5381
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4718
Epoch 4/10, Batch 20/20, Loss: 0.7236
Epoch 4/10, Train Loss: 0.4985, Valid Loss: 0.4811
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3791
Epoch 5/10, Batch 20/20, Loss: 0.4782
Epoch 5/10, Train Loss: 0.4155, Valid Loss: 0.4322
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5584
Epoch 6/10, Batch 20/20, Loss: 0.4880
Epoch 6/10, Train Loss: 0.3770, Valid Loss: 0.3931
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2006
Epoch 7/10, Batch 20/20, Loss: 0.4192
Epoch 7/10, Train Loss: 0.3433, Valid Loss: 0.3752
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3374
Epoch 8/10, Batch 20/20, Loss: 0.6153
Epoch 8/10, Train Loss: 0.3056, Valid Loss: 0.3543
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2787
Epoch 9/10, Batch 20/20, Loss: 0.6435
Epoch 9/10, Train Loss: 0.2891, Valid Loss: 0.3368
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3298
Epoch 10/10, Batch 20/20, Loss: 0.8319
Epoch 10/10, Train Loss: 0.2829, Valid Loss: 0.3367
Model saved!
Accuracy: 0.8762
Precision: 0.8716
Recall: 0.8762
F1-score: 0.8717
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3081
Epoch 1/10, Batch 20/20, Loss: 1.2899
Epoch 1/10, Train Loss: 1.2925, Valid Loss: 1.0509
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9022
Epoch 2/10, Batch 20/20, Loss: 0.7247
Epoch 2/10, Train Loss: 0.8224, Valid Loss: 0.7410
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6950
Epoch 3/10, Batch 20/20, Loss: 0.7779
Epoch 3/10, Train Loss: 0.6223, Valid Loss: 0.6137
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4851
Epoch 4/10, Batch 20/20, Loss: 0.5004
Epoch 4/10, Train Loss: 0.5020, Valid Loss: 0.5441
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4053
Epoch 5/10, Batch 20/20, Loss: 0.7403
Epoch 5/10, Train Loss: 0.4328, Valid Loss: 0.4928
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5249
Epoch 6/10, Batch 20/20, Loss: 0.6282
Epoch 6/10, Train Loss: 0.4012, Valid Loss: 0.4660
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2989
Epoch 7/10, Batch 20/20, Loss: 0.4430
Epoch 7/10, Train Loss: 0.3494, Valid Loss: 0.4448
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4062
Epoch 8/10, Batch 20/20, Loss: 0.3148
Epoch 8/10, Train Loss: 0.3259, Valid Loss: 0.4235
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3303
Epoch 9/10, Batch 20/20, Loss: 0.4607
Epoch 9/10, Train Loss: 0.2989, Valid Loss: 0.4142
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3285
Epoch 10/10, Batch 20/20, Loss: 0.4553
Epoch 10/10, Train Loss: 0.2966, Valid Loss: 0.4136
Model saved!
Accuracy: 0.8855
Precision: 0.8819
Recall: 0.8855
F1-score: 0.8818
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1442
Epoch 1/10, Batch 20/20, Loss: 1.1988
Epoch 1/10, Train Loss: 1.2808, Valid Loss: 0.9969
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8834
Epoch 2/10, Batch 20/20, Loss: 0.6565
Epoch 2/10, Train Loss: 0.8041, Valid Loss: 0.7035
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6976
Epoch 3/10, Batch 20/20, Loss: 0.8841
Epoch 3/10, Train Loss: 0.6237, Valid Loss: 0.5941
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5626
Epoch 4/10, Batch 20/20, Loss: 0.5290
Epoch 4/10, Train Loss: 0.5035, Valid Loss: 0.5182
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3322
Epoch 5/10, Batch 20/20, Loss: 0.8078
Epoch 5/10, Train Loss: 0.4378, Valid Loss: 0.4706
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5116
Epoch 6/10, Batch 20/20, Loss: 0.5435
Epoch 6/10, Train Loss: 0.3832, Valid Loss: 0.4272
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3501
Epoch 7/10, Batch 20/20, Loss: 0.5237
Epoch 7/10, Train Loss: 0.3476, Valid Loss: 0.4095
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2875
Epoch 8/10, Batch 20/20, Loss: 0.5535
Epoch 8/10, Train Loss: 0.3270, Valid Loss: 0.3923
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4016
Epoch 9/10, Batch 20/20, Loss: 0.3309
Epoch 9/10, Train Loss: 0.3002, Valid Loss: 0.3734
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2579
Epoch 10/10, Batch 20/20, Loss: 0.8166
Epoch 10/10, Train Loss: 0.2884, Valid Loss: 0.3794
Accuracy: 0.8808
Precision: 0.8732
Recall: 0.8808
F1-score: 0.8732
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2433
Epoch 1/10, Batch 20/20, Loss: 1.3072
Epoch 1/10, Train Loss: 1.2655, Valid Loss: 1.0462
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9906
Epoch 2/10, Batch 20/20, Loss: 0.5327
Epoch 2/10, Train Loss: 0.7859, Valid Loss: 0.7370
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6851
Epoch 3/10, Batch 20/20, Loss: 0.8045
Epoch 3/10, Train Loss: 0.5989, Valid Loss: 0.6117
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4260
Epoch 4/10, Batch 20/20, Loss: 0.3885
Epoch 4/10, Train Loss: 0.4762, Valid Loss: 0.5356
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3181
Epoch 5/10, Batch 20/20, Loss: 0.6236
Epoch 5/10, Train Loss: 0.4140, Valid Loss: 0.4921
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4580
Epoch 6/10, Batch 20/20, Loss: 0.3055
Epoch 6/10, Train Loss: 0.3605, Valid Loss: 0.4611
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2869
Epoch 7/10, Batch 20/20, Loss: 0.5603
Epoch 7/10, Train Loss: 0.3389, Valid Loss: 0.4381
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4096
Epoch 8/10, Batch 20/20, Loss: 0.4674
Epoch 8/10, Train Loss: 0.3072, Valid Loss: 0.4195
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3310
Epoch 9/10, Batch 20/20, Loss: 0.5548
Epoch 9/10, Train Loss: 0.2781, Valid Loss: 0.4186
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2141
Epoch 10/10, Batch 20/20, Loss: 0.5129
Epoch 10/10, Train Loss: 0.2662, Valid Loss: 0.3954
Model saved!
Accuracy: 0.8762
Precision: 0.8762
Recall: 0.8762
F1-score: 0.8730
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1127
Epoch 1/10, Batch 20/20, Loss: 0.9781
Epoch 1/10, Train Loss: 1.2345, Valid Loss: 0.9367
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9137
Epoch 2/10, Batch 20/20, Loss: 0.6646
Epoch 2/10, Train Loss: 0.7683, Valid Loss: 0.6576
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8138
Epoch 3/10, Batch 20/20, Loss: 0.7546
Epoch 3/10, Train Loss: 0.5811, Valid Loss: 0.5272
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5502
Epoch 4/10, Batch 20/20, Loss: 0.4920
Epoch 4/10, Train Loss: 0.4627, Valid Loss: 0.4630
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3681
Epoch 5/10, Batch 20/20, Loss: 0.7395
Epoch 5/10, Train Loss: 0.4186, Valid Loss: 0.4069
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5317
Epoch 6/10, Batch 20/20, Loss: 0.5518
Epoch 6/10, Train Loss: 0.3567, Valid Loss: 0.3777
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2788
Epoch 7/10, Batch 20/20, Loss: 0.4350
Epoch 7/10, Train Loss: 0.3065, Valid Loss: 0.3625
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3504
Epoch 8/10, Batch 20/20, Loss: 0.4684
Epoch 8/10, Train Loss: 0.2964, Valid Loss: 0.3452
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2019
Epoch 9/10, Batch 20/20, Loss: 0.5453
Epoch 9/10, Train Loss: 0.2515, Valid Loss: 0.3282
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2109
Epoch 10/10, Batch 20/20, Loss: 0.5780
Epoch 10/10, Train Loss: 0.2458, Valid Loss: 0.3177
Model saved!
Accuracy: 0.8785
Precision: 0.8737
Recall: 0.8785
F1-score: 0.8727
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1971
Epoch 1/10, Batch 20/20, Loss: 1.2074
Epoch 1/10, Train Loss: 1.2923, Valid Loss: 1.0516
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9896
Epoch 2/10, Batch 20/20, Loss: 0.5373
Epoch 2/10, Train Loss: 0.8286, Valid Loss: 0.7074
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6198
Epoch 3/10, Batch 20/20, Loss: 0.9633
Epoch 3/10, Train Loss: 0.6422, Valid Loss: 0.5621
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6240
Epoch 4/10, Batch 20/20, Loss: 0.5345
Epoch 4/10, Train Loss: 0.4983, Valid Loss: 0.4816
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4260
Epoch 5/10, Batch 20/20, Loss: 0.5536
Epoch 5/10, Train Loss: 0.4427, Valid Loss: 0.4197
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4817
Epoch 6/10, Batch 20/20, Loss: 0.2968
Epoch 6/10, Train Loss: 0.3845, Valid Loss: 0.3856
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3362
Epoch 7/10, Batch 20/20, Loss: 0.3705
Epoch 7/10, Train Loss: 0.3424, Valid Loss: 0.3569
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5305
Epoch 8/10, Batch 20/20, Loss: 0.2509
Epoch 8/10, Train Loss: 0.3125, Valid Loss: 0.3396
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2678
Epoch 9/10, Batch 20/20, Loss: 0.6757
Epoch 9/10, Train Loss: 0.3105, Valid Loss: 0.3079
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2647
Epoch 10/10, Batch 20/20, Loss: 0.5318
Epoch 10/10, Train Loss: 0.2798, Valid Loss: 0.3048
Model saved!
Accuracy: 0.8832
Precision: 0.8783
Recall: 0.8832
F1-score: 0.8766
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1981
Epoch 1/10, Batch 20/20, Loss: 1.3817
Epoch 1/10, Train Loss: 1.2957, Valid Loss: 1.0535
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9149
Epoch 2/10, Batch 20/20, Loss: 0.7974
Epoch 2/10, Train Loss: 0.8338, Valid Loss: 0.7590
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7020
Epoch 3/10, Batch 20/20, Loss: 0.7415
Epoch 3/10, Train Loss: 0.6412, Valid Loss: 0.6452
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5505
Epoch 4/10, Batch 20/20, Loss: 0.5283
Epoch 4/10, Train Loss: 0.5263, Valid Loss: 0.5819
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4292
Epoch 5/10, Batch 20/20, Loss: 0.5474
Epoch 5/10, Train Loss: 0.4622, Valid Loss: 0.5430
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5653
Epoch 6/10, Batch 20/20, Loss: 0.4120
Epoch 6/10, Train Loss: 0.4123, Valid Loss: 0.5094
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3819
Epoch 7/10, Batch 20/20, Loss: 0.4173
Epoch 7/10, Train Loss: 0.3704, Valid Loss: 0.4959
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4959
Epoch 8/10, Batch 20/20, Loss: 0.6180
Epoch 8/10, Train Loss: 0.3614, Valid Loss: 0.4790
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4627
Epoch 9/10, Batch 20/20, Loss: 0.5398
Epoch 9/10, Train Loss: 0.3346, Valid Loss: 0.4697
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3068
Epoch 10/10, Batch 20/20, Loss: 0.8062
Epoch 10/10, Train Loss: 0.3274, Valid Loss: 0.4684
Model saved!
Accuracy: 0.8785
Precision: 0.8742
Recall: 0.8785
F1-score: 0.8740
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2097
Epoch 1/10, Batch 20/20, Loss: 1.2654
Epoch 1/10, Train Loss: 1.2565, Valid Loss: 1.0814
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0150
Epoch 2/10, Batch 20/20, Loss: 0.4827
Epoch 2/10, Train Loss: 0.7732, Valid Loss: 0.7718
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6863
Epoch 3/10, Batch 20/20, Loss: 0.7530
Epoch 3/10, Train Loss: 0.5911, Valid Loss: 0.6598
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3710
Epoch 4/10, Batch 20/20, Loss: 0.3599
Epoch 4/10, Train Loss: 0.4657, Valid Loss: 0.5860
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3472
Epoch 5/10, Batch 20/20, Loss: 0.4927
Epoch 5/10, Train Loss: 0.4054, Valid Loss: 0.5508
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5413
Epoch 6/10, Batch 20/20, Loss: 0.3664
Epoch 6/10, Train Loss: 0.3644, Valid Loss: 0.5165
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2844
Epoch 7/10, Batch 20/20, Loss: 0.3450
Epoch 7/10, Train Loss: 0.3176, Valid Loss: 0.4947
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3277
Epoch 8/10, Batch 20/20, Loss: 0.3104
Epoch 8/10, Train Loss: 0.3050, Valid Loss: 0.4825
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3238
Epoch 9/10, Batch 20/20, Loss: 0.5439
Epoch 9/10, Train Loss: 0.2777, Valid Loss: 0.4584
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2239
Epoch 10/10, Batch 20/20, Loss: 0.3900
Epoch 10/10, Train Loss: 0.2647, Valid Loss: 0.4632
Accuracy: 0.8902
Precision: 0.8863
Recall: 0.8902
F1-score: 0.8862
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2642
Epoch 1/10, Batch 20/20, Loss: 1.2527
Epoch 1/10, Train Loss: 1.2847, Valid Loss: 1.1036
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0143
Epoch 2/10, Batch 20/20, Loss: 0.6552
Epoch 2/10, Train Loss: 0.8150, Valid Loss: 0.7853
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7337
Epoch 3/10, Batch 20/20, Loss: 0.9377
Epoch 3/10, Train Loss: 0.6226, Valid Loss: 0.6587
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4814
Epoch 4/10, Batch 20/20, Loss: 0.3047
Epoch 4/10, Train Loss: 0.4994, Valid Loss: 0.5921
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4321
Epoch 5/10, Batch 20/20, Loss: 0.5401
Epoch 5/10, Train Loss: 0.4362, Valid Loss: 0.5427
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4941
Epoch 6/10, Batch 20/20, Loss: 0.5972
Epoch 6/10, Train Loss: 0.3904, Valid Loss: 0.5047
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3201
Epoch 7/10, Batch 20/20, Loss: 0.3941
Epoch 7/10, Train Loss: 0.3489, Valid Loss: 0.4645
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4136
Epoch 8/10, Batch 20/20, Loss: 0.6498
Epoch 8/10, Train Loss: 0.3436, Valid Loss: 0.4479
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3165
Epoch 9/10, Batch 20/20, Loss: 0.8687
Epoch 9/10, Train Loss: 0.3278, Valid Loss: 0.4365
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2994
Epoch 10/10, Batch 20/20, Loss: 0.4886
Epoch 10/10, Train Loss: 0.2773, Valid Loss: 0.4195
Model saved!
Accuracy: 0.8843
Precision: 0.8802
Recall: 0.8843
F1-score: 0.8808
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2072
Epoch 1/10, Batch 20/20, Loss: 1.3017
Epoch 1/10, Train Loss: 1.2699, Valid Loss: 1.0812
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0184
Epoch 2/10, Batch 20/20, Loss: 0.5917
Epoch 2/10, Train Loss: 0.7686, Valid Loss: 0.7456
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6476
Epoch 3/10, Batch 20/20, Loss: 0.9115
Epoch 3/10, Train Loss: 0.5794, Valid Loss: 0.6074
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4179
Epoch 4/10, Batch 20/20, Loss: 0.4940
Epoch 4/10, Train Loss: 0.4467, Valid Loss: 0.5363
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3428
Epoch 5/10, Batch 20/20, Loss: 0.5296
Epoch 5/10, Train Loss: 0.3797, Valid Loss: 0.4838
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5609
Epoch 6/10, Batch 20/20, Loss: 0.6093
Epoch 6/10, Train Loss: 0.3583, Valid Loss: 0.4533
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2710
Epoch 7/10, Batch 20/20, Loss: 0.3831
Epoch 7/10, Train Loss: 0.3026, Valid Loss: 0.4164
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3519
Epoch 8/10, Batch 20/20, Loss: 0.4148
Epoch 8/10, Train Loss: 0.2781, Valid Loss: 0.4093
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3925
Epoch 9/10, Batch 20/20, Loss: 0.6379
Epoch 9/10, Train Loss: 0.2545, Valid Loss: 0.3830
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2394
Epoch 10/10, Batch 20/20, Loss: 0.4550
Epoch 10/10, Train Loss: 0.2394, Valid Loss: 0.3924
Accuracy: 0.8820
Precision: 0.8781
Recall: 0.8820
F1-score: 0.8789
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1948
Epoch 1/10, Batch 20/20, Loss: 1.2506
Epoch 1/10, Train Loss: 1.2713, Valid Loss: 1.0595
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9291
Epoch 2/10, Batch 20/20, Loss: 0.5229
Epoch 2/10, Train Loss: 0.7960, Valid Loss: 0.7117
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7130
Epoch 3/10, Batch 20/20, Loss: 0.8393
Epoch 3/10, Train Loss: 0.6091, Valid Loss: 0.5708
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3814
Epoch 4/10, Batch 20/20, Loss: 0.5324
Epoch 4/10, Train Loss: 0.4818, Valid Loss: 0.4881
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4045
Epoch 5/10, Batch 20/20, Loss: 0.8904
Epoch 5/10, Train Loss: 0.4325, Valid Loss: 0.4429
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4536
Epoch 6/10, Batch 20/20, Loss: 0.3672
Epoch 6/10, Train Loss: 0.3642, Valid Loss: 0.3998
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2491
Epoch 7/10, Batch 20/20, Loss: 0.2835
Epoch 7/10, Train Loss: 0.3210, Valid Loss: 0.3703
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4760
Epoch 8/10, Batch 20/20, Loss: 0.1984
Epoch 8/10, Train Loss: 0.3006, Valid Loss: 0.3557
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3149
Epoch 9/10, Batch 20/20, Loss: 0.4667
Epoch 9/10, Train Loss: 0.2775, Valid Loss: 0.3333
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2247
Epoch 10/10, Batch 20/20, Loss: 0.4566
Epoch 10/10, Train Loss: 0.2640, Valid Loss: 0.3346
Accuracy: 0.8879
Precision: 0.8829
Recall: 0.8879
F1-score: 0.8830
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3330
Epoch 1/10, Batch 20/20, Loss: 1.4868
Epoch 1/10, Train Loss: 1.2906, Valid Loss: 1.0843
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9846
Epoch 2/10, Batch 20/20, Loss: 0.6724
Epoch 2/10, Train Loss: 0.8228, Valid Loss: 0.7876
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7159
Epoch 3/10, Batch 20/20, Loss: 0.8331
Epoch 3/10, Train Loss: 0.6404, Valid Loss: 0.6620
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5680
Epoch 4/10, Batch 20/20, Loss: 0.5743
Epoch 4/10, Train Loss: 0.5151, Valid Loss: 0.5891
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4661
Epoch 5/10, Batch 20/20, Loss: 0.5801
Epoch 5/10, Train Loss: 0.4561, Valid Loss: 0.5483
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6242
Epoch 6/10, Batch 20/20, Loss: 0.6273
Epoch 6/10, Train Loss: 0.4082, Valid Loss: 0.5133
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3071
Epoch 7/10, Batch 20/20, Loss: 0.8685
Epoch 7/10, Train Loss: 0.3726, Valid Loss: 0.4887
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4409
Epoch 8/10, Batch 20/20, Loss: 0.6023
Epoch 8/10, Train Loss: 0.3559, Valid Loss: 0.4752
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3646
Epoch 9/10, Batch 20/20, Loss: 0.4677
Epoch 9/10, Train Loss: 0.3050, Valid Loss: 0.4675
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2951
Epoch 10/10, Batch 20/20, Loss: 0.4333
Epoch 10/10, Train Loss: 0.2940, Valid Loss: 0.4665
Model saved!
Accuracy: 0.8832
Precision: 0.8809
Recall: 0.8832
F1-score: 0.8793
Memory Allocated after cleanup: 17.76 MB
End time: 2025-02-24 10:37:02.676484
Duration: 1:32:52


Mejor accuracy al acabar el algoritmo: 0.8972


Fitness check:

Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1172
Epoch 1/10, Batch 20/20, Loss: 1.1643
Epoch 1/10, Train Loss: 1.2675, Valid Loss: 0.9770
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9688
Epoch 2/10, Batch 20/20, Loss: 0.6462
Epoch 2/10, Train Loss: 0.7896, Valid Loss: 0.6839
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7100
Epoch 3/10, Batch 20/20, Loss: 0.8397
Epoch 3/10, Train Loss: 0.5984, Valid Loss: 0.5642
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5234
Epoch 4/10, Batch 20/20, Loss: 0.6618
Epoch 4/10, Train Loss: 0.4730, Valid Loss: 0.4968
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3794
Epoch 5/10, Batch 20/20, Loss: 0.6232
Epoch 5/10, Train Loss: 0.4060, Valid Loss: 0.4573
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4302
Epoch 6/10, Batch 20/20, Loss: 0.6183
Epoch 6/10, Train Loss: 0.3716, Valid Loss: 0.4253
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3472
Epoch 7/10, Batch 20/20, Loss: 0.2046
Epoch 7/10, Train Loss: 0.3027, Valid Loss: 0.4082
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3788
Epoch 8/10, Batch 20/20, Loss: 0.5421
Epoch 8/10, Train Loss: 0.2934, Valid Loss: 0.4029
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3170
Epoch 9/10, Batch 20/20, Loss: 0.3954
Epoch 9/10, Train Loss: 0.2705, Valid Loss: 0.3857
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2289
Epoch 10/10, Batch 20/20, Loss: 1.0237
Epoch 10/10, Train Loss: 0.2830, Valid Loss: 0.3871
Accuracy: 0.8972
Precision: 0.8904
Recall: 0.8972
F1-score: 0.8912
Memory Allocated after cleanup: 17.76 MB


Mejor accuracy encontrado: 0.8972


--------------------------------------mobilenet  ALEATORIO  25%-------------------------------------------------
Start time: 2025-02-24 10:37:57.863419
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2795
Epoch 1/10, Batch 20/49, Loss: 1.1004
Epoch 1/10, Batch 30/49, Loss: 0.8759
Epoch 1/10, Batch 40/49, Loss: 0.8277
Epoch 1/10, Train Loss: 1.0318, Valid Loss: 0.6517
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6034
Epoch 2/10, Batch 20/49, Loss: 0.7492
Epoch 2/10, Batch 30/49, Loss: 0.5079
Epoch 2/10, Batch 40/49, Loss: 0.4299
Epoch 2/10, Train Loss: 0.5696, Valid Loss: 0.4508
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5579
Epoch 3/10, Batch 20/49, Loss: 0.3376
Epoch 3/10, Batch 30/49, Loss: 0.4292
Epoch 3/10, Batch 40/49, Loss: 0.3682
Epoch 3/10, Train Loss: 0.4294, Valid Loss: 0.3888
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4180
Epoch 4/10, Batch 20/49, Loss: 0.4729
Epoch 4/10, Batch 30/49, Loss: 0.3217
Epoch 4/10, Batch 40/49, Loss: 0.4313
Epoch 4/10, Train Loss: 0.3886, Valid Loss: 0.3566
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3863
Epoch 5/10, Batch 20/49, Loss: 0.2760
Epoch 5/10, Batch 30/49, Loss: 0.2897
Epoch 5/10, Batch 40/49, Loss: 0.2183
Epoch 5/10, Train Loss: 0.3416, Valid Loss: 0.3257
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3222
Epoch 6/10, Batch 20/49, Loss: 0.1867
Epoch 6/10, Batch 30/49, Loss: 0.2133
Epoch 6/10, Batch 40/49, Loss: 0.2148
Epoch 6/10, Train Loss: 0.3081, Valid Loss: 0.2919
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1934
Epoch 7/10, Batch 20/49, Loss: 0.3305
Epoch 7/10, Batch 30/49, Loss: 0.3806
Epoch 7/10, Batch 40/49, Loss: 0.2437
Epoch 7/10, Train Loss: 0.2905, Valid Loss: 0.2828
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2958
Epoch 8/10, Batch 20/49, Loss: 0.2297
Epoch 8/10, Batch 30/49, Loss: 0.2570
Epoch 8/10, Batch 40/49, Loss: 0.3088
Epoch 8/10, Train Loss: 0.2736, Valid Loss: 0.2800
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2709
Epoch 9/10, Batch 20/49, Loss: 0.2287
Epoch 9/10, Batch 30/49, Loss: 0.3255
Epoch 9/10, Batch 40/49, Loss: 0.4891
Epoch 9/10, Train Loss: 0.2672, Valid Loss: 0.2777
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2919
Epoch 10/10, Batch 20/49, Loss: 0.1974
Epoch 10/10, Batch 30/49, Loss: 0.2790
Epoch 10/10, Batch 40/49, Loss: 0.2609
Epoch 10/10, Train Loss: 0.2416, Valid Loss: 0.2607
Model saved!
Accuracy: 0.9007
Precision: 0.8978
Recall: 0.9007
F1-score: 0.8984
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 1. Fitness: 0.9007
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2223
Epoch 1/10, Batch 20/49, Loss: 1.1554
Epoch 1/10, Batch 30/49, Loss: 0.8661
Epoch 1/10, Batch 40/49, Loss: 0.8760
Epoch 1/10, Train Loss: 1.0159, Valid Loss: 0.6308
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5993
Epoch 2/10, Batch 20/49, Loss: 0.5955
Epoch 2/10, Batch 30/49, Loss: 0.3849
Epoch 2/10, Batch 40/49, Loss: 0.4545
Epoch 2/10, Train Loss: 0.5405, Valid Loss: 0.4435
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4621
Epoch 3/10, Batch 20/49, Loss: 0.3920
Epoch 3/10, Batch 30/49, Loss: 0.4950
Epoch 3/10, Batch 40/49, Loss: 0.4160
Epoch 3/10, Train Loss: 0.4194, Valid Loss: 0.3836
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4119
Epoch 4/10, Batch 20/49, Loss: 0.2945
Epoch 4/10, Batch 30/49, Loss: 0.2834
Epoch 4/10, Batch 40/49, Loss: 0.3885
Epoch 4/10, Train Loss: 0.3531, Valid Loss: 0.3430
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3881
Epoch 5/10, Batch 20/49, Loss: 0.3337
Epoch 5/10, Batch 30/49, Loss: 0.2175
Epoch 5/10, Batch 40/49, Loss: 0.2542
Epoch 5/10, Train Loss: 0.3083, Valid Loss: 0.3181
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2050
Epoch 6/10, Batch 20/49, Loss: 0.3229
Epoch 6/10, Batch 30/49, Loss: 0.1746
Epoch 6/10, Batch 40/49, Loss: 0.3548
Epoch 6/10, Train Loss: 0.2862, Valid Loss: 0.2972
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2640
Epoch 7/10, Batch 20/49, Loss: 0.2002
Epoch 7/10, Batch 30/49, Loss: 0.3172
Epoch 7/10, Batch 40/49, Loss: 0.1553
Epoch 7/10, Train Loss: 0.2411, Valid Loss: 0.2973
Epoch 8/10, Batch 10/49, Loss: 0.1665
Epoch 8/10, Batch 20/49, Loss: 0.1743
Epoch 8/10, Batch 30/49, Loss: 0.1104
Epoch 8/10, Batch 40/49, Loss: 0.1958
Epoch 8/10, Train Loss: 0.2392, Valid Loss: 0.2873
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1901
Epoch 9/10, Batch 20/49, Loss: 0.1459
Epoch 9/10, Batch 30/49, Loss: 0.2899
Epoch 9/10, Batch 40/49, Loss: 0.2433
Epoch 9/10, Train Loss: 0.2174, Valid Loss: 0.2756
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1684
Epoch 10/10, Batch 20/49, Loss: 0.3733
Epoch 10/10, Batch 30/49, Loss: 0.1227
Epoch 10/10, Batch 40/49, Loss: 0.1417
Epoch 10/10, Train Loss: 0.2073, Valid Loss: 0.2637
Model saved!
Accuracy: 0.9065
Precision: 0.9033
Recall: 0.9065
F1-score: 0.9037
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 2. Fitness: 0.9065
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3033
Epoch 1/10, Batch 20/49, Loss: 1.1419
Epoch 1/10, Batch 30/49, Loss: 0.8426
Epoch 1/10, Batch 40/49, Loss: 0.9052
Epoch 1/10, Train Loss: 1.0158, Valid Loss: 0.5783
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5873
Epoch 2/10, Batch 20/49, Loss: 0.7558
Epoch 2/10, Batch 30/49, Loss: 0.5822
Epoch 2/10, Batch 40/49, Loss: 0.4646
Epoch 2/10, Train Loss: 0.5414, Valid Loss: 0.4040
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4010
Epoch 3/10, Batch 20/49, Loss: 0.4093
Epoch 3/10, Batch 30/49, Loss: 0.3162
Epoch 3/10, Batch 40/49, Loss: 0.3392
Epoch 3/10, Train Loss: 0.4190, Valid Loss: 0.3590
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3051
Epoch 4/10, Batch 20/49, Loss: 0.3869
Epoch 4/10, Batch 30/49, Loss: 0.2984
Epoch 4/10, Batch 40/49, Loss: 0.3217
Epoch 4/10, Train Loss: 0.3713, Valid Loss: 0.2944
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4175
Epoch 5/10, Batch 20/49, Loss: 0.2808
Epoch 5/10, Batch 30/49, Loss: 0.2184
Epoch 5/10, Batch 40/49, Loss: 0.2274
Epoch 5/10, Train Loss: 0.3245, Valid Loss: 0.2724
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3523
Epoch 6/10, Batch 20/49, Loss: 0.3135
Epoch 6/10, Batch 30/49, Loss: 0.4253
Epoch 6/10, Batch 40/49, Loss: 0.2471
Epoch 6/10, Train Loss: 0.2926, Valid Loss: 0.2605
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2089
Epoch 7/10, Batch 20/49, Loss: 0.3480
Epoch 7/10, Batch 30/49, Loss: 0.1890
Epoch 7/10, Batch 40/49, Loss: 0.1657
Epoch 7/10, Train Loss: 0.2644, Valid Loss: 0.2550
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2620
Epoch 8/10, Batch 20/49, Loss: 0.2434
Epoch 8/10, Batch 30/49, Loss: 0.2614
Epoch 8/10, Batch 40/49, Loss: 0.1254
Epoch 8/10, Train Loss: 0.2618, Valid Loss: 0.2371
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2730
Epoch 9/10, Batch 20/49, Loss: 0.1301
Epoch 9/10, Batch 30/49, Loss: 0.4224
Epoch 9/10, Batch 40/49, Loss: 0.4317
Epoch 9/10, Train Loss: 0.2352, Valid Loss: 0.2287
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3393
Epoch 10/10, Batch 20/49, Loss: 0.2306
Epoch 10/10, Batch 30/49, Loss: 0.2394
Epoch 10/10, Batch 40/49, Loss: 0.2147
Epoch 10/10, Train Loss: 0.2213, Valid Loss: 0.2271
Model saved!
Accuracy: 0.9089
Precision: 0.9065
Recall: 0.9089
F1-score: 0.9061
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 3. Fitness: 0.9089
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2054
Epoch 1/10, Batch 20/49, Loss: 1.0773
Epoch 1/10, Batch 30/49, Loss: 0.8995
Epoch 1/10, Batch 40/49, Loss: 0.7751
Epoch 1/10, Train Loss: 1.0100, Valid Loss: 0.6230
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6281
Epoch 2/10, Batch 20/49, Loss: 0.5971
Epoch 2/10, Batch 30/49, Loss: 0.5157
Epoch 2/10, Batch 40/49, Loss: 0.5345
Epoch 2/10, Train Loss: 0.5534, Valid Loss: 0.4379
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3649
Epoch 3/10, Batch 20/49, Loss: 0.3694
Epoch 3/10, Batch 30/49, Loss: 0.3419
Epoch 3/10, Batch 40/49, Loss: 0.5441
Epoch 3/10, Train Loss: 0.4175, Valid Loss: 0.3799
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3632
Epoch 4/10, Batch 20/49, Loss: 0.3797
Epoch 4/10, Batch 30/49, Loss: 0.3483
Epoch 4/10, Batch 40/49, Loss: 0.3108
Epoch 4/10, Train Loss: 0.3686, Valid Loss: 0.3344
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3614
Epoch 5/10, Batch 20/49, Loss: 0.2584
Epoch 5/10, Batch 30/49, Loss: 0.2069
Epoch 5/10, Batch 40/49, Loss: 0.3502
Epoch 5/10, Train Loss: 0.3301, Valid Loss: 0.3063
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2915
Epoch 6/10, Batch 20/49, Loss: 0.2597
Epoch 6/10, Batch 30/49, Loss: 0.2723
Epoch 6/10, Batch 40/49, Loss: 0.2476
Epoch 6/10, Train Loss: 0.3027, Valid Loss: 0.2878
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2409
Epoch 7/10, Batch 20/49, Loss: 0.2944
Epoch 7/10, Batch 30/49, Loss: 0.2264
Epoch 7/10, Batch 40/49, Loss: 0.1814
Epoch 7/10, Train Loss: 0.2707, Valid Loss: 0.2742
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1889
Epoch 8/10, Batch 20/49, Loss: 0.2545
Epoch 8/10, Batch 30/49, Loss: 0.4316
Epoch 8/10, Batch 40/49, Loss: 0.2381
Epoch 8/10, Train Loss: 0.2540, Valid Loss: 0.2812
Epoch 9/10, Batch 10/49, Loss: 0.1645
Epoch 9/10, Batch 20/49, Loss: 0.1974
Epoch 9/10, Batch 30/49, Loss: 0.2793
Epoch 9/10, Batch 40/49, Loss: 0.3020
Epoch 9/10, Train Loss: 0.2428, Valid Loss: 0.2572
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2410
Epoch 10/10, Batch 20/49, Loss: 0.1782
Epoch 10/10, Batch 30/49, Loss: 0.1793
Epoch 10/10, Batch 40/49, Loss: 0.2096
Epoch 10/10, Train Loss: 0.2320, Valid Loss: 0.2535
Model saved!
Accuracy: 0.9077
Precision: 0.9044
Recall: 0.9077
F1-score: 0.9056
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1627
Epoch 1/10, Batch 20/49, Loss: 1.0990
Epoch 1/10, Batch 30/49, Loss: 0.8386
Epoch 1/10, Batch 40/49, Loss: 0.7499
Epoch 1/10, Train Loss: 1.0179, Valid Loss: 0.6218
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5861
Epoch 2/10, Batch 20/49, Loss: 0.6793
Epoch 2/10, Batch 30/49, Loss: 0.4221
Epoch 2/10, Batch 40/49, Loss: 0.4727
Epoch 2/10, Train Loss: 0.5533, Valid Loss: 0.4281
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4127
Epoch 3/10, Batch 20/49, Loss: 0.2954
Epoch 3/10, Batch 30/49, Loss: 0.6290
Epoch 3/10, Batch 40/49, Loss: 0.6427
Epoch 3/10, Train Loss: 0.4311, Valid Loss: 0.3586
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3757
Epoch 4/10, Batch 20/49, Loss: 0.2637
Epoch 4/10, Batch 30/49, Loss: 0.3456
Epoch 4/10, Batch 40/49, Loss: 0.3324
Epoch 4/10, Train Loss: 0.3629, Valid Loss: 0.3091
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3561
Epoch 5/10, Batch 20/49, Loss: 0.2326
Epoch 5/10, Batch 30/49, Loss: 0.2708
Epoch 5/10, Batch 40/49, Loss: 0.2728
Epoch 5/10, Train Loss: 0.3314, Valid Loss: 0.2859
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2531
Epoch 6/10, Batch 20/49, Loss: 0.1798
Epoch 6/10, Batch 30/49, Loss: 0.2620
Epoch 6/10, Batch 40/49, Loss: 0.2501
Epoch 6/10, Train Loss: 0.2994, Valid Loss: 0.2600
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2739
Epoch 7/10, Batch 20/49, Loss: 0.2720
Epoch 7/10, Batch 30/49, Loss: 0.3342
Epoch 7/10, Batch 40/49, Loss: 0.1361
Epoch 7/10, Train Loss: 0.2646, Valid Loss: 0.2490
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2901
Epoch 8/10, Batch 20/49, Loss: 0.1595
Epoch 8/10, Batch 30/49, Loss: 0.1916
Epoch 8/10, Batch 40/49, Loss: 0.1801
Epoch 8/10, Train Loss: 0.2618, Valid Loss: 0.2475
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2109
Epoch 9/10, Batch 20/49, Loss: 0.1379
Epoch 9/10, Batch 30/49, Loss: 0.2175
Epoch 9/10, Batch 40/49, Loss: 0.2894
Epoch 9/10, Train Loss: 0.2344, Valid Loss: 0.2275
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2788
Epoch 10/10, Batch 20/49, Loss: 0.1451
Epoch 10/10, Batch 30/49, Loss: 0.1243
Epoch 10/10, Batch 40/49, Loss: 0.1833
Epoch 10/10, Train Loss: 0.2244, Valid Loss: 0.2279
Accuracy: 0.9054
Precision: 0.9021
Recall: 0.9054
F1-score: 0.9022
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2885
Epoch 1/10, Batch 20/49, Loss: 1.1573
Epoch 1/10, Batch 30/49, Loss: 0.8417
Epoch 1/10, Batch 40/49, Loss: 0.8425
Epoch 1/10, Train Loss: 1.0239, Valid Loss: 0.6358
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6513
Epoch 2/10, Batch 20/49, Loss: 0.5838
Epoch 2/10, Batch 30/49, Loss: 0.6922
Epoch 2/10, Batch 40/49, Loss: 0.3992
Epoch 2/10, Train Loss: 0.5686, Valid Loss: 0.4462
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4415
Epoch 3/10, Batch 20/49, Loss: 0.3538
Epoch 3/10, Batch 30/49, Loss: 0.4759
Epoch 3/10, Batch 40/49, Loss: 0.5427
Epoch 3/10, Train Loss: 0.4287, Valid Loss: 0.3850
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3382
Epoch 4/10, Batch 20/49, Loss: 0.3587
Epoch 4/10, Batch 30/49, Loss: 0.3878
Epoch 4/10, Batch 40/49, Loss: 0.3552
Epoch 4/10, Train Loss: 0.3811, Valid Loss: 0.3379
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.6258
Epoch 5/10, Batch 20/49, Loss: 0.2442
Epoch 5/10, Batch 30/49, Loss: 0.3097
Epoch 5/10, Batch 40/49, Loss: 0.2182
Epoch 5/10, Train Loss: 0.3398, Valid Loss: 0.3112
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3003
Epoch 6/10, Batch 20/49, Loss: 0.2885
Epoch 6/10, Batch 30/49, Loss: 0.1985
Epoch 6/10, Batch 40/49, Loss: 0.2093
Epoch 6/10, Train Loss: 0.3062, Valid Loss: 0.2921
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2363
Epoch 7/10, Batch 20/49, Loss: 0.2458
Epoch 7/10, Batch 30/49, Loss: 0.2795
Epoch 7/10, Batch 40/49, Loss: 0.1661
Epoch 7/10, Train Loss: 0.2783, Valid Loss: 0.2952
Epoch 8/10, Batch 10/49, Loss: 0.2438
Epoch 8/10, Batch 20/49, Loss: 0.1814
Epoch 8/10, Batch 30/49, Loss: 0.2241
Epoch 8/10, Batch 40/49, Loss: 0.3145
Epoch 8/10, Train Loss: 0.2627, Valid Loss: 0.2864
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1675
Epoch 9/10, Batch 20/49, Loss: 0.1959
Epoch 9/10, Batch 30/49, Loss: 0.2740
Epoch 9/10, Batch 40/49, Loss: 0.2630
Epoch 9/10, Train Loss: 0.2468, Valid Loss: 0.2613
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2201
Epoch 10/10, Batch 20/49, Loss: 0.1334
Epoch 10/10, Batch 30/49, Loss: 0.4347
Epoch 10/10, Batch 40/49, Loss: 0.3800
Epoch 10/10, Train Loss: 0.2339, Valid Loss: 0.2732
Accuracy: 0.9007
Precision: 0.8963
Recall: 0.9007
F1-score: 0.8964
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2708
Epoch 1/10, Batch 20/49, Loss: 1.0639
Epoch 1/10, Batch 30/49, Loss: 0.8514
Epoch 1/10, Batch 40/49, Loss: 0.8579
Epoch 1/10, Train Loss: 0.9976, Valid Loss: 0.6441
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6469
Epoch 2/10, Batch 20/49, Loss: 0.5892
Epoch 2/10, Batch 30/49, Loss: 0.4742
Epoch 2/10, Batch 40/49, Loss: 0.6050
Epoch 2/10, Train Loss: 0.5422, Valid Loss: 0.4507
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3716
Epoch 3/10, Batch 20/49, Loss: 0.4190
Epoch 3/10, Batch 30/49, Loss: 0.3842
Epoch 3/10, Batch 40/49, Loss: 0.4896
Epoch 3/10, Train Loss: 0.4191, Valid Loss: 0.3901
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3402
Epoch 4/10, Batch 20/49, Loss: 0.4260
Epoch 4/10, Batch 30/49, Loss: 0.3006
Epoch 4/10, Batch 40/49, Loss: 0.3986
Epoch 4/10, Train Loss: 0.3634, Valid Loss: 0.3359
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4544
Epoch 5/10, Batch 20/49, Loss: 0.2073
Epoch 5/10, Batch 30/49, Loss: 0.1495
Epoch 5/10, Batch 40/49, Loss: 0.2397
Epoch 5/10, Train Loss: 0.3199, Valid Loss: 0.3102
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2399
Epoch 6/10, Batch 20/49, Loss: 0.1904
Epoch 6/10, Batch 30/49, Loss: 0.3027
Epoch 6/10, Batch 40/49, Loss: 0.2977
Epoch 6/10, Train Loss: 0.2900, Valid Loss: 0.2922
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2862
Epoch 7/10, Batch 20/49, Loss: 0.2455
Epoch 7/10, Batch 30/49, Loss: 0.2929
Epoch 7/10, Batch 40/49, Loss: 0.1956
Epoch 7/10, Train Loss: 0.2535, Valid Loss: 0.2890
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2929
Epoch 8/10, Batch 20/49, Loss: 0.3738
Epoch 8/10, Batch 30/49, Loss: 0.1522
Epoch 8/10, Batch 40/49, Loss: 0.2252
Epoch 8/10, Train Loss: 0.2577, Valid Loss: 0.2688
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2490
Epoch 9/10, Batch 20/49, Loss: 0.2314
Epoch 9/10, Batch 30/49, Loss: 0.2494
Epoch 9/10, Batch 40/49, Loss: 0.4436
Epoch 9/10, Train Loss: 0.2429, Valid Loss: 0.2560
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2555
Epoch 10/10, Batch 20/49, Loss: 0.1709
Epoch 10/10, Batch 30/49, Loss: 0.0835
Epoch 10/10, Batch 40/49, Loss: 0.1178
Epoch 10/10, Train Loss: 0.2188, Valid Loss: 0.2601
Accuracy: 0.9112
Precision: 0.9075
Recall: 0.9112
F1-score: 0.9085
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 7. Fitness: 0.9112
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2538
Epoch 1/10, Batch 20/49, Loss: 1.1668
Epoch 1/10, Batch 30/49, Loss: 0.9059
Epoch 1/10, Batch 40/49, Loss: 0.7976
Epoch 1/10, Train Loss: 0.9900, Valid Loss: 0.5758
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6162
Epoch 2/10, Batch 20/49, Loss: 0.4858
Epoch 2/10, Batch 30/49, Loss: 0.4129
Epoch 2/10, Batch 40/49, Loss: 0.5854
Epoch 2/10, Train Loss: 0.5252, Valid Loss: 0.3994
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4537
Epoch 3/10, Batch 20/49, Loss: 0.3703
Epoch 3/10, Batch 30/49, Loss: 0.4368
Epoch 3/10, Batch 40/49, Loss: 0.3195
Epoch 3/10, Train Loss: 0.4045, Valid Loss: 0.3389
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3325
Epoch 4/10, Batch 20/49, Loss: 0.3997
Epoch 4/10, Batch 30/49, Loss: 0.2854
Epoch 4/10, Batch 40/49, Loss: 0.4236
Epoch 4/10, Train Loss: 0.3484, Valid Loss: 0.2960
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3781
Epoch 5/10, Batch 20/49, Loss: 0.2108
Epoch 5/10, Batch 30/49, Loss: 0.2145
Epoch 5/10, Batch 40/49, Loss: 0.3455
Epoch 5/10, Train Loss: 0.3028, Valid Loss: 0.2729
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2910
Epoch 6/10, Batch 20/49, Loss: 0.1733
Epoch 6/10, Batch 30/49, Loss: 0.2658
Epoch 6/10, Batch 40/49, Loss: 0.2779
Epoch 6/10, Train Loss: 0.2723, Valid Loss: 0.2677
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1523
Epoch 7/10, Batch 20/49, Loss: 0.2129
Epoch 7/10, Batch 30/49, Loss: 0.2403
Epoch 7/10, Batch 40/49, Loss: 0.2186
Epoch 7/10, Train Loss: 0.2460, Valid Loss: 0.2662
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2438
Epoch 8/10, Batch 20/49, Loss: 0.2000
Epoch 8/10, Batch 30/49, Loss: 0.3729
Epoch 8/10, Batch 40/49, Loss: 0.1752
Epoch 8/10, Train Loss: 0.2338, Valid Loss: 0.2607
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3038
Epoch 9/10, Batch 20/49, Loss: 0.1565
Epoch 9/10, Batch 30/49, Loss: 0.1395
Epoch 9/10, Batch 40/49, Loss: 0.3875
Epoch 9/10, Train Loss: 0.2239, Valid Loss: 0.2432
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1680
Epoch 10/10, Batch 20/49, Loss: 0.1705
Epoch 10/10, Batch 30/49, Loss: 0.0939
Epoch 10/10, Batch 40/49, Loss: 0.1641
Epoch 10/10, Train Loss: 0.2006, Valid Loss: 0.2467
Accuracy: 0.9065
Precision: 0.9028
Recall: 0.9065
F1-score: 0.9031
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2135
Epoch 1/10, Batch 20/49, Loss: 1.1182
Epoch 1/10, Batch 30/49, Loss: 0.8004
Epoch 1/10, Batch 40/49, Loss: 0.7934
Epoch 1/10, Train Loss: 1.0164, Valid Loss: 0.6317
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6641
Epoch 2/10, Batch 20/49, Loss: 0.6408
Epoch 2/10, Batch 30/49, Loss: 0.6046
Epoch 2/10, Batch 40/49, Loss: 0.4590
Epoch 2/10, Train Loss: 0.5494, Valid Loss: 0.4348
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3709
Epoch 3/10, Batch 20/49, Loss: 0.2714
Epoch 3/10, Batch 30/49, Loss: 0.3847
Epoch 3/10, Batch 40/49, Loss: 0.5226
Epoch 3/10, Train Loss: 0.4279, Valid Loss: 0.3719
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3091
Epoch 4/10, Batch 20/49, Loss: 0.6660
Epoch 4/10, Batch 30/49, Loss: 0.4578
Epoch 4/10, Batch 40/49, Loss: 0.4495
Epoch 4/10, Train Loss: 0.3779, Valid Loss: 0.3361
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3800
Epoch 5/10, Batch 20/49, Loss: 0.2252
Epoch 5/10, Batch 30/49, Loss: 0.2681
Epoch 5/10, Batch 40/49, Loss: 0.2781
Epoch 5/10, Train Loss: 0.3398, Valid Loss: 0.3083
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3408
Epoch 6/10, Batch 20/49, Loss: 0.2366
Epoch 6/10, Batch 30/49, Loss: 0.2739
Epoch 6/10, Batch 40/49, Loss: 0.2957
Epoch 6/10, Train Loss: 0.3045, Valid Loss: 0.2944
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2706
Epoch 7/10, Batch 20/49, Loss: 0.2289
Epoch 7/10, Batch 30/49, Loss: 0.2524
Epoch 7/10, Batch 40/49, Loss: 0.3261
Epoch 7/10, Train Loss: 0.2697, Valid Loss: 0.2873
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3361
Epoch 8/10, Batch 20/49, Loss: 0.3804
Epoch 8/10, Batch 30/49, Loss: 0.1640
Epoch 8/10, Batch 40/49, Loss: 0.1714
Epoch 8/10, Train Loss: 0.2638, Valid Loss: 0.2653
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2564
Epoch 9/10, Batch 20/49, Loss: 0.4040
Epoch 9/10, Batch 30/49, Loss: 0.4504
Epoch 9/10, Batch 40/49, Loss: 0.4001
Epoch 9/10, Train Loss: 0.2546, Valid Loss: 0.2610
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3107
Epoch 10/10, Batch 20/49, Loss: 0.2078
Epoch 10/10, Batch 30/49, Loss: 0.1835
Epoch 10/10, Batch 40/49, Loss: 0.1913
Epoch 10/10, Train Loss: 0.2183, Valid Loss: 0.2584
Model saved!
Accuracy: 0.9194
Precision: 0.9175
Recall: 0.9194
F1-score: 0.9181
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 9. Fitness: 0.9194
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2149
Epoch 1/10, Batch 20/49, Loss: 1.1671
Epoch 1/10, Batch 30/49, Loss: 0.7779
Epoch 1/10, Batch 40/49, Loss: 0.8753
Epoch 1/10, Train Loss: 1.0060, Valid Loss: 0.6482
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6587
Epoch 2/10, Batch 20/49, Loss: 0.6167
Epoch 2/10, Batch 30/49, Loss: 0.5051
Epoch 2/10, Batch 40/49, Loss: 0.5103
Epoch 2/10, Train Loss: 0.5395, Valid Loss: 0.4613
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4173
Epoch 3/10, Batch 20/49, Loss: 0.3081
Epoch 3/10, Batch 30/49, Loss: 0.4245
Epoch 3/10, Batch 40/49, Loss: 0.4309
Epoch 3/10, Train Loss: 0.4280, Valid Loss: 0.4009
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3489
Epoch 4/10, Batch 20/49, Loss: 0.4231
Epoch 4/10, Batch 30/49, Loss: 0.3323
Epoch 4/10, Batch 40/49, Loss: 0.4349
Epoch 4/10, Train Loss: 0.3675, Valid Loss: 0.3435
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4216
Epoch 5/10, Batch 20/49, Loss: 0.2390
Epoch 5/10, Batch 30/49, Loss: 0.2732
Epoch 5/10, Batch 40/49, Loss: 0.3200
Epoch 5/10, Train Loss: 0.3210, Valid Loss: 0.3213
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1598
Epoch 6/10, Batch 20/49, Loss: 0.2506
Epoch 6/10, Batch 30/49, Loss: 0.2741
Epoch 6/10, Batch 40/49, Loss: 0.2194
Epoch 6/10, Train Loss: 0.2950, Valid Loss: 0.3031
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2946
Epoch 7/10, Batch 20/49, Loss: 0.2778
Epoch 7/10, Batch 30/49, Loss: 0.2270
Epoch 7/10, Batch 40/49, Loss: 0.2090
Epoch 7/10, Train Loss: 0.2657, Valid Loss: 0.3050
Epoch 8/10, Batch 10/49, Loss: 0.3602
Epoch 8/10, Batch 20/49, Loss: 0.1961
Epoch 8/10, Batch 30/49, Loss: 0.2678
Epoch 8/10, Batch 40/49, Loss: 0.2532
Epoch 8/10, Train Loss: 0.2445, Valid Loss: 0.3038
Epoch 9/10, Batch 10/49, Loss: 0.1790
Epoch 9/10, Batch 20/49, Loss: 0.1190
Epoch 9/10, Batch 30/49, Loss: 0.3470
Epoch 9/10, Batch 40/49, Loss: 0.2091
Epoch 9/10, Train Loss: 0.2478, Valid Loss: 0.2946
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3198
Epoch 10/10, Batch 20/49, Loss: 0.1075
Epoch 10/10, Batch 30/49, Loss: 0.1153
Epoch 10/10, Batch 40/49, Loss: 0.2150
Epoch 10/10, Train Loss: 0.2190, Valid Loss: 0.2825
Model saved!
Accuracy: 0.8995
Precision: 0.8970
Recall: 0.8995
F1-score: 0.8977
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2228
Epoch 1/10, Batch 20/49, Loss: 1.1189
Epoch 1/10, Batch 30/49, Loss: 0.7872
Epoch 1/10, Batch 40/49, Loss: 0.7806
Epoch 1/10, Train Loss: 1.0060, Valid Loss: 0.6649
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7153
Epoch 2/10, Batch 20/49, Loss: 0.6266
Epoch 2/10, Batch 30/49, Loss: 0.4536
Epoch 2/10, Batch 40/49, Loss: 0.4957
Epoch 2/10, Train Loss: 0.5554, Valid Loss: 0.4525
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3759
Epoch 3/10, Batch 20/49, Loss: 0.2840
Epoch 3/10, Batch 30/49, Loss: 0.4800
Epoch 3/10, Batch 40/49, Loss: 0.4366
Epoch 3/10, Train Loss: 0.4121, Valid Loss: 0.3947
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2708
Epoch 4/10, Batch 20/49, Loss: 0.4497
Epoch 4/10, Batch 30/49, Loss: 0.3937
Epoch 4/10, Batch 40/49, Loss: 0.2998
Epoch 4/10, Train Loss: 0.3740, Valid Loss: 0.3494
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4291
Epoch 5/10, Batch 20/49, Loss: 0.2115
Epoch 5/10, Batch 30/49, Loss: 0.3640
Epoch 5/10, Batch 40/49, Loss: 0.3152
Epoch 5/10, Train Loss: 0.3246, Valid Loss: 0.3199
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2040
Epoch 6/10, Batch 20/49, Loss: 0.2602
Epoch 6/10, Batch 30/49, Loss: 0.2226
Epoch 6/10, Batch 40/49, Loss: 0.2409
Epoch 6/10, Train Loss: 0.3049, Valid Loss: 0.2952
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2775
Epoch 7/10, Batch 20/49, Loss: 0.3192
Epoch 7/10, Batch 30/49, Loss: 0.2189
Epoch 7/10, Batch 40/49, Loss: 0.1537
Epoch 7/10, Train Loss: 0.2644, Valid Loss: 0.3051
Epoch 8/10, Batch 10/49, Loss: 0.2920
Epoch 8/10, Batch 20/49, Loss: 0.2223
Epoch 8/10, Batch 30/49, Loss: 0.1503
Epoch 8/10, Batch 40/49, Loss: 0.1794
Epoch 8/10, Train Loss: 0.2562, Valid Loss: 0.2873
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1784
Epoch 9/10, Batch 20/49, Loss: 0.1954
Epoch 9/10, Batch 30/49, Loss: 0.2025
Epoch 9/10, Batch 40/49, Loss: 0.2549
Epoch 9/10, Train Loss: 0.2355, Valid Loss: 0.2719
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3689
Epoch 10/10, Batch 20/49, Loss: 0.1584
Epoch 10/10, Batch 30/49, Loss: 0.2171
Epoch 10/10, Batch 40/49, Loss: 0.2251
Epoch 10/10, Train Loss: 0.2326, Valid Loss: 0.2766
Accuracy: 0.9030
Precision: 0.9000
Recall: 0.9030
F1-score: 0.9007
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1825
Epoch 1/10, Batch 20/49, Loss: 1.0702
Epoch 1/10, Batch 30/49, Loss: 0.8350
Epoch 1/10, Batch 40/49, Loss: 0.8568
Epoch 1/10, Train Loss: 1.0195, Valid Loss: 0.6229
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7195
Epoch 2/10, Batch 20/49, Loss: 0.6299
Epoch 2/10, Batch 30/49, Loss: 0.4333
Epoch 2/10, Batch 40/49, Loss: 0.4226
Epoch 2/10, Train Loss: 0.5596, Valid Loss: 0.4114
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4816
Epoch 3/10, Batch 20/49, Loss: 0.3235
Epoch 3/10, Batch 30/49, Loss: 0.3638
Epoch 3/10, Batch 40/49, Loss: 0.4197
Epoch 3/10, Train Loss: 0.4188, Valid Loss: 0.3640
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2278
Epoch 4/10, Batch 20/49, Loss: 0.3525
Epoch 4/10, Batch 30/49, Loss: 0.3592
Epoch 4/10, Batch 40/49, Loss: 0.3837
Epoch 4/10, Train Loss: 0.3777, Valid Loss: 0.3164
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3774
Epoch 5/10, Batch 20/49, Loss: 0.2888
Epoch 5/10, Batch 30/49, Loss: 0.2580
Epoch 5/10, Batch 40/49, Loss: 0.1761
Epoch 5/10, Train Loss: 0.3304, Valid Loss: 0.2890
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2829
Epoch 6/10, Batch 20/49, Loss: 0.2453
Epoch 6/10, Batch 30/49, Loss: 0.2658
Epoch 6/10, Batch 40/49, Loss: 0.2439
Epoch 6/10, Train Loss: 0.3006, Valid Loss: 0.2773
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2952
Epoch 7/10, Batch 20/49, Loss: 0.3376
Epoch 7/10, Batch 30/49, Loss: 0.2029
Epoch 7/10, Batch 40/49, Loss: 0.1561
Epoch 7/10, Train Loss: 0.2644, Valid Loss: 0.2894
Epoch 8/10, Batch 10/49, Loss: 0.3056
Epoch 8/10, Batch 20/49, Loss: 0.2155
Epoch 8/10, Batch 30/49, Loss: 0.1871
Epoch 8/10, Batch 40/49, Loss: 0.2827
Epoch 8/10, Train Loss: 0.2474, Valid Loss: 0.2714
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2625
Epoch 9/10, Batch 20/49, Loss: 0.2101
Epoch 9/10, Batch 30/49, Loss: 0.2264
Epoch 9/10, Batch 40/49, Loss: 0.1644
Epoch 9/10, Train Loss: 0.2331, Valid Loss: 0.2622
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2731
Epoch 10/10, Batch 20/49, Loss: 0.1682
Epoch 10/10, Batch 30/49, Loss: 0.1566
Epoch 10/10, Batch 40/49, Loss: 0.3324
Epoch 10/10, Train Loss: 0.2134, Valid Loss: 0.2657
Accuracy: 0.9065
Precision: 0.9048
Recall: 0.9065
F1-score: 0.9027
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1917
Epoch 1/10, Batch 20/49, Loss: 1.0321
Epoch 1/10, Batch 30/49, Loss: 0.8920
Epoch 1/10, Batch 40/49, Loss: 0.7677
Epoch 1/10, Train Loss: 1.0101, Valid Loss: 0.5849
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6164
Epoch 2/10, Batch 20/49, Loss: 0.6231
Epoch 2/10, Batch 30/49, Loss: 0.4365
Epoch 2/10, Batch 40/49, Loss: 0.3830
Epoch 2/10, Train Loss: 0.5417, Valid Loss: 0.3980
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4832
Epoch 3/10, Batch 20/49, Loss: 0.3377
Epoch 3/10, Batch 30/49, Loss: 0.4340
Epoch 3/10, Batch 40/49, Loss: 0.2989
Epoch 3/10, Train Loss: 0.4078, Valid Loss: 0.3398
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4416
Epoch 4/10, Batch 20/49, Loss: 0.2358
Epoch 4/10, Batch 30/49, Loss: 0.2628
Epoch 4/10, Batch 40/49, Loss: 0.5121
Epoch 4/10, Train Loss: 0.3464, Valid Loss: 0.2934
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3301
Epoch 5/10, Batch 20/49, Loss: 0.3473
Epoch 5/10, Batch 30/49, Loss: 0.1696
Epoch 5/10, Batch 40/49, Loss: 0.2900
Epoch 5/10, Train Loss: 0.3038, Valid Loss: 0.2713
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2661
Epoch 6/10, Batch 20/49, Loss: 0.2238
Epoch 6/10, Batch 30/49, Loss: 0.2804
Epoch 6/10, Batch 40/49, Loss: 0.2500
Epoch 6/10, Train Loss: 0.2792, Valid Loss: 0.2519
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2297
Epoch 7/10, Batch 20/49, Loss: 0.3243
Epoch 7/10, Batch 30/49, Loss: 0.3246
Epoch 7/10, Batch 40/49, Loss: 0.1766
Epoch 7/10, Train Loss: 0.2369, Valid Loss: 0.2501
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3560
Epoch 8/10, Batch 20/49, Loss: 0.1767
Epoch 8/10, Batch 30/49, Loss: 0.3224
Epoch 8/10, Batch 40/49, Loss: 0.2142
Epoch 8/10, Train Loss: 0.2421, Valid Loss: 0.2359
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1184
Epoch 9/10, Batch 20/49, Loss: 0.1893
Epoch 9/10, Batch 30/49, Loss: 0.3546
Epoch 9/10, Batch 40/49, Loss: 0.3080
Epoch 9/10, Train Loss: 0.2226, Valid Loss: 0.2271
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2766
Epoch 10/10, Batch 20/49, Loss: 0.2134
Epoch 10/10, Batch 30/49, Loss: 0.1965
Epoch 10/10, Batch 40/49, Loss: 0.1492
Epoch 10/10, Train Loss: 0.2077, Valid Loss: 0.2326
Accuracy: 0.8937
Precision: 0.8898
Recall: 0.8937
F1-score: 0.8904
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2568
Epoch 1/10, Batch 20/49, Loss: 1.0803
Epoch 1/10, Batch 30/49, Loss: 0.8547
Epoch 1/10, Batch 40/49, Loss: 0.8324
Epoch 1/10, Train Loss: 1.0091, Valid Loss: 0.6502
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6260
Epoch 2/10, Batch 20/49, Loss: 0.6672
Epoch 2/10, Batch 30/49, Loss: 0.4191
Epoch 2/10, Batch 40/49, Loss: 0.4677
Epoch 2/10, Train Loss: 0.5619, Valid Loss: 0.4658
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3622
Epoch 3/10, Batch 20/49, Loss: 0.3199
Epoch 3/10, Batch 30/49, Loss: 0.3227
Epoch 3/10, Batch 40/49, Loss: 0.3032
Epoch 3/10, Train Loss: 0.4265, Valid Loss: 0.4172
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3647
Epoch 4/10, Batch 20/49, Loss: 0.3379
Epoch 4/10, Batch 30/49, Loss: 0.3707
Epoch 4/10, Batch 40/49, Loss: 0.3063
Epoch 4/10, Train Loss: 0.3566, Valid Loss: 0.3483
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4079
Epoch 5/10, Batch 20/49, Loss: 0.2188
Epoch 5/10, Batch 30/49, Loss: 0.2851
Epoch 5/10, Batch 40/49, Loss: 0.3147
Epoch 5/10, Train Loss: 0.3177, Valid Loss: 0.3231
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2973
Epoch 6/10, Batch 20/49, Loss: 0.1586
Epoch 6/10, Batch 30/49, Loss: 0.1913
Epoch 6/10, Batch 40/49, Loss: 0.3159
Epoch 6/10, Train Loss: 0.2938, Valid Loss: 0.3083
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3327
Epoch 7/10, Batch 20/49, Loss: 0.2958
Epoch 7/10, Batch 30/49, Loss: 0.1886
Epoch 7/10, Batch 40/49, Loss: 0.1905
Epoch 7/10, Train Loss: 0.2573, Valid Loss: 0.3271
Epoch 8/10, Batch 10/49, Loss: 0.2760
Epoch 8/10, Batch 20/49, Loss: 0.1701
Epoch 8/10, Batch 30/49, Loss: 0.2337
Epoch 8/10, Batch 40/49, Loss: 0.2800
Epoch 8/10, Train Loss: 0.2548, Valid Loss: 0.3018
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3092
Epoch 9/10, Batch 20/49, Loss: 0.1801
Epoch 9/10, Batch 30/49, Loss: 0.2668
Epoch 9/10, Batch 40/49, Loss: 0.1992
Epoch 9/10, Train Loss: 0.2260, Valid Loss: 0.2829
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2024
Epoch 10/10, Batch 20/49, Loss: 0.1921
Epoch 10/10, Batch 30/49, Loss: 0.1463
Epoch 10/10, Batch 40/49, Loss: 0.1873
Epoch 10/10, Train Loss: 0.2162, Valid Loss: 0.2846
Accuracy: 0.8984
Precision: 0.8937
Recall: 0.8984
F1-score: 0.8941
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2600
Epoch 1/10, Batch 20/49, Loss: 1.1671
Epoch 1/10, Batch 30/49, Loss: 0.9078
Epoch 1/10, Batch 40/49, Loss: 0.7548
Epoch 1/10, Train Loss: 1.0099, Valid Loss: 0.6278
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5761
Epoch 2/10, Batch 20/49, Loss: 0.5218
Epoch 2/10, Batch 30/49, Loss: 0.5781
Epoch 2/10, Batch 40/49, Loss: 0.4973
Epoch 2/10, Train Loss: 0.5474, Valid Loss: 0.4405
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4236
Epoch 3/10, Batch 20/49, Loss: 0.2624
Epoch 3/10, Batch 30/49, Loss: 0.4146
Epoch 3/10, Batch 40/49, Loss: 0.5098
Epoch 3/10, Train Loss: 0.4162, Valid Loss: 0.3870
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4460
Epoch 4/10, Batch 20/49, Loss: 0.3116
Epoch 4/10, Batch 30/49, Loss: 0.2772
Epoch 4/10, Batch 40/49, Loss: 0.4271
Epoch 4/10, Train Loss: 0.3654, Valid Loss: 0.3557
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3328
Epoch 5/10, Batch 20/49, Loss: 0.2489
Epoch 5/10, Batch 30/49, Loss: 0.2395
Epoch 5/10, Batch 40/49, Loss: 0.2940
Epoch 5/10, Train Loss: 0.3204, Valid Loss: 0.3252
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3322
Epoch 6/10, Batch 20/49, Loss: 0.1922
Epoch 6/10, Batch 30/49, Loss: 0.3608
Epoch 6/10, Batch 40/49, Loss: 0.2286
Epoch 6/10, Train Loss: 0.2946, Valid Loss: 0.3035
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2090
Epoch 7/10, Batch 20/49, Loss: 0.2760
Epoch 7/10, Batch 30/49, Loss: 0.4049
Epoch 7/10, Batch 40/49, Loss: 0.1557
Epoch 7/10, Train Loss: 0.2580, Valid Loss: 0.3096
Epoch 8/10, Batch 10/49, Loss: 0.3301
Epoch 8/10, Batch 20/49, Loss: 0.1634
Epoch 8/10, Batch 30/49, Loss: 0.1832
Epoch 8/10, Batch 40/49, Loss: 0.1551
Epoch 8/10, Train Loss: 0.2515, Valid Loss: 0.2903
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2697
Epoch 9/10, Batch 20/49, Loss: 0.1149
Epoch 9/10, Batch 30/49, Loss: 0.4044
Epoch 9/10, Batch 40/49, Loss: 0.2083
Epoch 9/10, Train Loss: 0.2333, Valid Loss: 0.2813
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3507
Epoch 10/10, Batch 20/49, Loss: 0.1554
Epoch 10/10, Batch 30/49, Loss: 0.1621
Epoch 10/10, Batch 40/49, Loss: 0.1604
Epoch 10/10, Train Loss: 0.2107, Valid Loss: 0.2776
Model saved!
Accuracy: 0.9077
Precision: 0.9056
Recall: 0.9077
F1-score: 0.9029
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2276
Epoch 1/10, Batch 20/49, Loss: 1.0544
Epoch 1/10, Batch 30/49, Loss: 0.9540
Epoch 1/10, Batch 40/49, Loss: 0.7941
Epoch 1/10, Train Loss: 1.0150, Valid Loss: 0.6237
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6164
Epoch 2/10, Batch 20/49, Loss: 0.6848
Epoch 2/10, Batch 30/49, Loss: 0.4741
Epoch 2/10, Batch 40/49, Loss: 0.3483
Epoch 2/10, Train Loss: 0.5422, Valid Loss: 0.4195
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4212
Epoch 3/10, Batch 20/49, Loss: 0.3414
Epoch 3/10, Batch 30/49, Loss: 0.4304
Epoch 3/10, Batch 40/49, Loss: 0.4097
Epoch 3/10, Train Loss: 0.4115, Valid Loss: 0.3491
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2941
Epoch 4/10, Batch 20/49, Loss: 0.2977
Epoch 4/10, Batch 30/49, Loss: 0.2653
Epoch 4/10, Batch 40/49, Loss: 0.3554
Epoch 4/10, Train Loss: 0.3634, Valid Loss: 0.3195
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4684
Epoch 5/10, Batch 20/49, Loss: 0.2347
Epoch 5/10, Batch 30/49, Loss: 0.2503
Epoch 5/10, Batch 40/49, Loss: 0.2337
Epoch 5/10, Train Loss: 0.3279, Valid Loss: 0.2912
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3410
Epoch 6/10, Batch 20/49, Loss: 0.2947
Epoch 6/10, Batch 30/49, Loss: 0.2921
Epoch 6/10, Batch 40/49, Loss: 0.2462
Epoch 6/10, Train Loss: 0.2896, Valid Loss: 0.2742
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2760
Epoch 7/10, Batch 20/49, Loss: 0.2023
Epoch 7/10, Batch 30/49, Loss: 0.3794
Epoch 7/10, Batch 40/49, Loss: 0.1329
Epoch 7/10, Train Loss: 0.2509, Valid Loss: 0.2658
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3550
Epoch 8/10, Batch 20/49, Loss: 0.2886
Epoch 8/10, Batch 30/49, Loss: 0.2324
Epoch 8/10, Batch 40/49, Loss: 0.2408
Epoch 8/10, Train Loss: 0.2577, Valid Loss: 0.2665
Epoch 9/10, Batch 10/49, Loss: 0.3055
Epoch 9/10, Batch 20/49, Loss: 0.2162
Epoch 9/10, Batch 30/49, Loss: 0.3340
Epoch 9/10, Batch 40/49, Loss: 0.3158
Epoch 9/10, Train Loss: 0.2393, Valid Loss: 0.2458
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2670
Epoch 10/10, Batch 20/49, Loss: 0.1817
Epoch 10/10, Batch 30/49, Loss: 0.1351
Epoch 10/10, Batch 40/49, Loss: 0.1641
Epoch 10/10, Train Loss: 0.2200, Valid Loss: 0.2401
Model saved!
Accuracy: 0.9182
Precision: 0.9156
Recall: 0.9182
F1-score: 0.9165
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2515
Epoch 1/10, Batch 20/49, Loss: 1.1405
Epoch 1/10, Batch 30/49, Loss: 0.8007
Epoch 1/10, Batch 40/49, Loss: 0.7326
Epoch 1/10, Train Loss: 1.0078, Valid Loss: 0.6394
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5308
Epoch 2/10, Batch 20/49, Loss: 0.7009
Epoch 2/10, Batch 30/49, Loss: 0.4853
Epoch 2/10, Batch 40/49, Loss: 0.5820
Epoch 2/10, Train Loss: 0.5530, Valid Loss: 0.4472
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3102
Epoch 3/10, Batch 20/49, Loss: 0.3043
Epoch 3/10, Batch 30/49, Loss: 0.3871
Epoch 3/10, Batch 40/49, Loss: 0.2912
Epoch 3/10, Train Loss: 0.4229, Valid Loss: 0.3850
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2563
Epoch 4/10, Batch 20/49, Loss: 0.3253
Epoch 4/10, Batch 30/49, Loss: 0.3781
Epoch 4/10, Batch 40/49, Loss: 0.3558
Epoch 4/10, Train Loss: 0.3706, Valid Loss: 0.3456
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4168
Epoch 5/10, Batch 20/49, Loss: 0.2161
Epoch 5/10, Batch 30/49, Loss: 0.3001
Epoch 5/10, Batch 40/49, Loss: 0.2906
Epoch 5/10, Train Loss: 0.3227, Valid Loss: 0.3234
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2796
Epoch 6/10, Batch 20/49, Loss: 0.1780
Epoch 6/10, Batch 30/49, Loss: 0.2388
Epoch 6/10, Batch 40/49, Loss: 0.2575
Epoch 6/10, Train Loss: 0.2985, Valid Loss: 0.2926
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2105
Epoch 7/10, Batch 20/49, Loss: 0.3918
Epoch 7/10, Batch 30/49, Loss: 0.1748
Epoch 7/10, Batch 40/49, Loss: 0.1927
Epoch 7/10, Train Loss: 0.2689, Valid Loss: 0.3011
Epoch 8/10, Batch 10/49, Loss: 0.3120
Epoch 8/10, Batch 20/49, Loss: 0.1814
Epoch 8/10, Batch 30/49, Loss: 0.2427
Epoch 8/10, Batch 40/49, Loss: 0.1930
Epoch 8/10, Train Loss: 0.2580, Valid Loss: 0.2777
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1628
Epoch 9/10, Batch 20/49, Loss: 0.1437
Epoch 9/10, Batch 30/49, Loss: 0.2795
Epoch 9/10, Batch 40/49, Loss: 0.2383
Epoch 9/10, Train Loss: 0.2483, Valid Loss: 0.2732
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2781
Epoch 10/10, Batch 20/49, Loss: 0.2410
Epoch 10/10, Batch 30/49, Loss: 0.1793
Epoch 10/10, Batch 40/49, Loss: 0.2318
Epoch 10/10, Train Loss: 0.2257, Valid Loss: 0.2750
Accuracy: 0.9159
Precision: 0.9150
Recall: 0.9159
F1-score: 0.9138
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2531
Epoch 1/10, Batch 20/49, Loss: 1.2152
Epoch 1/10, Batch 30/49, Loss: 0.7652
Epoch 1/10, Batch 40/49, Loss: 0.6806
Epoch 1/10, Train Loss: 0.9960, Valid Loss: 0.6305
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6178
Epoch 2/10, Batch 20/49, Loss: 0.5794
Epoch 2/10, Batch 30/49, Loss: 0.4909
Epoch 2/10, Batch 40/49, Loss: 0.5893
Epoch 2/10, Train Loss: 0.5166, Valid Loss: 0.4385
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4008
Epoch 3/10, Batch 20/49, Loss: 0.2975
Epoch 3/10, Batch 30/49, Loss: 0.4581
Epoch 3/10, Batch 40/49, Loss: 0.2592
Epoch 3/10, Train Loss: 0.3959, Valid Loss: 0.3754
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3533
Epoch 4/10, Batch 20/49, Loss: 0.4598
Epoch 4/10, Batch 30/49, Loss: 0.3444
Epoch 4/10, Batch 40/49, Loss: 0.3529
Epoch 4/10, Train Loss: 0.3492, Valid Loss: 0.3362
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4102
Epoch 5/10, Batch 20/49, Loss: 0.1411
Epoch 5/10, Batch 30/49, Loss: 0.3216
Epoch 5/10, Batch 40/49, Loss: 0.3169
Epoch 5/10, Train Loss: 0.3142, Valid Loss: 0.3137
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1932
Epoch 6/10, Batch 20/49, Loss: 0.2331
Epoch 6/10, Batch 30/49, Loss: 0.2195
Epoch 6/10, Batch 40/49, Loss: 0.3236
Epoch 6/10, Train Loss: 0.2804, Valid Loss: 0.2884
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1471
Epoch 7/10, Batch 20/49, Loss: 0.1843
Epoch 7/10, Batch 30/49, Loss: 0.2597
Epoch 7/10, Batch 40/49, Loss: 0.2367
Epoch 7/10, Train Loss: 0.2527, Valid Loss: 0.2934
Epoch 8/10, Batch 10/49, Loss: 0.2289
Epoch 8/10, Batch 20/49, Loss: 0.1315
Epoch 8/10, Batch 30/49, Loss: 0.1608
Epoch 8/10, Batch 40/49, Loss: 0.1979
Epoch 8/10, Train Loss: 0.2367, Valid Loss: 0.2809
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2263
Epoch 9/10, Batch 20/49, Loss: 0.1773
Epoch 9/10, Batch 30/49, Loss: 0.3367
Epoch 9/10, Batch 40/49, Loss: 0.2700
Epoch 9/10, Train Loss: 0.2231, Valid Loss: 0.2663
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3222
Epoch 10/10, Batch 20/49, Loss: 0.1612
Epoch 10/10, Batch 30/49, Loss: 0.1345
Epoch 10/10, Batch 40/49, Loss: 0.3112
Epoch 10/10, Train Loss: 0.2030, Valid Loss: 0.2563
Model saved!
Accuracy: 0.8995
Precision: 0.8976
Recall: 0.8995
F1-score: 0.8946
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2114
Epoch 1/10, Batch 20/49, Loss: 1.1400
Epoch 1/10, Batch 30/49, Loss: 0.8480
Epoch 1/10, Batch 40/49, Loss: 0.7508
Epoch 1/10, Train Loss: 0.9996, Valid Loss: 0.6821
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6033
Epoch 2/10, Batch 20/49, Loss: 0.6386
Epoch 2/10, Batch 30/49, Loss: 0.5674
Epoch 2/10, Batch 40/49, Loss: 0.4223
Epoch 2/10, Train Loss: 0.5312, Valid Loss: 0.4877
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.6107
Epoch 3/10, Batch 20/49, Loss: 0.3905
Epoch 3/10, Batch 30/49, Loss: 0.4440
Epoch 3/10, Batch 40/49, Loss: 0.4325
Epoch 3/10, Train Loss: 0.4077, Valid Loss: 0.4305
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.5181
Epoch 4/10, Batch 20/49, Loss: 0.3105
Epoch 4/10, Batch 30/49, Loss: 0.3334
Epoch 4/10, Batch 40/49, Loss: 0.3379
Epoch 4/10, Train Loss: 0.3581, Valid Loss: 0.3935
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3453
Epoch 5/10, Batch 20/49, Loss: 0.2804
Epoch 5/10, Batch 30/49, Loss: 0.2736
Epoch 5/10, Batch 40/49, Loss: 0.2001
Epoch 5/10, Train Loss: 0.3073, Valid Loss: 0.3545
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2670
Epoch 6/10, Batch 20/49, Loss: 0.1224
Epoch 6/10, Batch 30/49, Loss: 0.2427
Epoch 6/10, Batch 40/49, Loss: 0.2571
Epoch 6/10, Train Loss: 0.2863, Valid Loss: 0.3396
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2053
Epoch 7/10, Batch 20/49, Loss: 0.2781
Epoch 7/10, Batch 30/49, Loss: 0.2091
Epoch 7/10, Batch 40/49, Loss: 0.1970
Epoch 7/10, Train Loss: 0.2612, Valid Loss: 0.3306
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2197
Epoch 8/10, Batch 20/49, Loss: 0.2161
Epoch 8/10, Batch 30/49, Loss: 0.2151
Epoch 8/10, Batch 40/49, Loss: 0.2105
Epoch 8/10, Train Loss: 0.2423, Valid Loss: 0.3318
Epoch 9/10, Batch 10/49, Loss: 0.2286
Epoch 9/10, Batch 20/49, Loss: 0.1473
Epoch 9/10, Batch 30/49, Loss: 0.2865
Epoch 9/10, Batch 40/49, Loss: 0.3872
Epoch 9/10, Train Loss: 0.2331, Valid Loss: 0.3017
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1707
Epoch 10/10, Batch 20/49, Loss: 0.2162
Epoch 10/10, Batch 30/49, Loss: 0.2187
Epoch 10/10, Batch 40/49, Loss: 0.1495
Epoch 10/10, Train Loss: 0.2179, Valid Loss: 0.3157
Accuracy: 0.9089
Precision: 0.9056
Recall: 0.9089
F1-score: 0.9057
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2390
Epoch 1/10, Batch 20/49, Loss: 1.1590
Epoch 1/10, Batch 30/49, Loss: 0.8134
Epoch 1/10, Batch 40/49, Loss: 0.7372
Epoch 1/10, Train Loss: 0.9973, Valid Loss: 0.5849
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6121
Epoch 2/10, Batch 20/49, Loss: 0.6954
Epoch 2/10, Batch 30/49, Loss: 0.5116
Epoch 2/10, Batch 40/49, Loss: 0.3783
Epoch 2/10, Train Loss: 0.5352, Valid Loss: 0.4109
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3894
Epoch 3/10, Batch 20/49, Loss: 0.4004
Epoch 3/10, Batch 30/49, Loss: 0.4789
Epoch 3/10, Batch 40/49, Loss: 0.4026
Epoch 3/10, Train Loss: 0.4070, Valid Loss: 0.3611
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2778
Epoch 4/10, Batch 20/49, Loss: 0.3446
Epoch 4/10, Batch 30/49, Loss: 0.4031
Epoch 4/10, Batch 40/49, Loss: 0.3477
Epoch 4/10, Train Loss: 0.3556, Valid Loss: 0.3166
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3615
Epoch 5/10, Batch 20/49, Loss: 0.1902
Epoch 5/10, Batch 30/49, Loss: 0.3640
Epoch 5/10, Batch 40/49, Loss: 0.4650
Epoch 5/10, Train Loss: 0.3057, Valid Loss: 0.2861
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2935
Epoch 6/10, Batch 20/49, Loss: 0.2865
Epoch 6/10, Batch 30/49, Loss: 0.2086
Epoch 6/10, Batch 40/49, Loss: 0.3253
Epoch 6/10, Train Loss: 0.2922, Valid Loss: 0.2722
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1834
Epoch 7/10, Batch 20/49, Loss: 0.3739
Epoch 7/10, Batch 30/49, Loss: 0.1849
Epoch 7/10, Batch 40/49, Loss: 0.2864
Epoch 7/10, Train Loss: 0.2524, Valid Loss: 0.2689
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2455
Epoch 8/10, Batch 20/49, Loss: 0.1813
Epoch 8/10, Batch 30/49, Loss: 0.2002
Epoch 8/10, Batch 40/49, Loss: 0.3307
Epoch 8/10, Train Loss: 0.2552, Valid Loss: 0.2633
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2279
Epoch 9/10, Batch 20/49, Loss: 0.1166
Epoch 9/10, Batch 30/49, Loss: 0.3008
Epoch 9/10, Batch 40/49, Loss: 0.3926
Epoch 9/10, Train Loss: 0.2236, Valid Loss: 0.2543
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2032
Epoch 10/10, Batch 20/49, Loss: 0.1277
Epoch 10/10, Batch 30/49, Loss: 0.0832
Epoch 10/10, Batch 40/49, Loss: 0.1335
Epoch 10/10, Train Loss: 0.2087, Valid Loss: 0.2457
Model saved!
Accuracy: 0.9042
Precision: 0.9022
Recall: 0.9042
F1-score: 0.9001
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2504
Epoch 1/10, Batch 20/49, Loss: 1.0767
Epoch 1/10, Batch 30/49, Loss: 0.9214
Epoch 1/10, Batch 40/49, Loss: 0.9031
Epoch 1/10, Train Loss: 1.0117, Valid Loss: 0.6360
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5431
Epoch 2/10, Batch 20/49, Loss: 0.6235
Epoch 2/10, Batch 30/49, Loss: 0.6299
Epoch 2/10, Batch 40/49, Loss: 0.4451
Epoch 2/10, Train Loss: 0.5535, Valid Loss: 0.4355
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4344
Epoch 3/10, Batch 20/49, Loss: 0.2665
Epoch 3/10, Batch 30/49, Loss: 0.3564
Epoch 3/10, Batch 40/49, Loss: 0.4268
Epoch 3/10, Train Loss: 0.4147, Valid Loss: 0.3811
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2808
Epoch 4/10, Batch 20/49, Loss: 0.3421
Epoch 4/10, Batch 30/49, Loss: 0.3413
Epoch 4/10, Batch 40/49, Loss: 0.4316
Epoch 4/10, Train Loss: 0.3756, Valid Loss: 0.3285
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5871
Epoch 5/10, Batch 20/49, Loss: 0.2589
Epoch 5/10, Batch 30/49, Loss: 0.2380
Epoch 5/10, Batch 40/49, Loss: 0.2436
Epoch 5/10, Train Loss: 0.3261, Valid Loss: 0.3049
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2863
Epoch 6/10, Batch 20/49, Loss: 0.3234
Epoch 6/10, Batch 30/49, Loss: 0.3664
Epoch 6/10, Batch 40/49, Loss: 0.3072
Epoch 6/10, Train Loss: 0.2934, Valid Loss: 0.2817
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2064
Epoch 7/10, Batch 20/49, Loss: 0.4314
Epoch 7/10, Batch 30/49, Loss: 0.2905
Epoch 7/10, Batch 40/49, Loss: 0.1103
Epoch 7/10, Train Loss: 0.2700, Valid Loss: 0.2848
Epoch 8/10, Batch 10/49, Loss: 0.2705
Epoch 8/10, Batch 20/49, Loss: 0.2922
Epoch 8/10, Batch 30/49, Loss: 0.2103
Epoch 8/10, Batch 40/49, Loss: 0.1419
Epoch 8/10, Train Loss: 0.2503, Valid Loss: 0.2754
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1913
Epoch 9/10, Batch 20/49, Loss: 0.1389
Epoch 9/10, Batch 30/49, Loss: 0.1683
Epoch 9/10, Batch 40/49, Loss: 0.2112
Epoch 9/10, Train Loss: 0.2348, Valid Loss: 0.2584
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2931
Epoch 10/10, Batch 20/49, Loss: 0.2244
Epoch 10/10, Batch 30/49, Loss: 0.1877
Epoch 10/10, Batch 40/49, Loss: 0.1609
Epoch 10/10, Train Loss: 0.2180, Valid Loss: 0.2530
Model saved!
Accuracy: 0.9030
Precision: 0.9011
Recall: 0.9030
F1-score: 0.9004
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2294
Epoch 1/10, Batch 20/49, Loss: 1.1932
Epoch 1/10, Batch 30/49, Loss: 0.8719
Epoch 1/10, Batch 40/49, Loss: 0.9384
Epoch 1/10, Train Loss: 1.0294, Valid Loss: 0.6136
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6625
Epoch 2/10, Batch 20/49, Loss: 0.5769
Epoch 2/10, Batch 30/49, Loss: 0.5614
Epoch 2/10, Batch 40/49, Loss: 0.5029
Epoch 2/10, Train Loss: 0.5607, Valid Loss: 0.4312
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.6405
Epoch 3/10, Batch 20/49, Loss: 0.3042
Epoch 3/10, Batch 30/49, Loss: 0.4356
Epoch 3/10, Batch 40/49, Loss: 0.4467
Epoch 3/10, Train Loss: 0.4184, Valid Loss: 0.3622
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4091
Epoch 4/10, Batch 20/49, Loss: 0.2697
Epoch 4/10, Batch 30/49, Loss: 0.2677
Epoch 4/10, Batch 40/49, Loss: 0.3956
Epoch 4/10, Train Loss: 0.3786, Valid Loss: 0.3168
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4488
Epoch 5/10, Batch 20/49, Loss: 0.2762
Epoch 5/10, Batch 30/49, Loss: 0.3423
Epoch 5/10, Batch 40/49, Loss: 0.3198
Epoch 5/10, Train Loss: 0.3285, Valid Loss: 0.2955
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3169
Epoch 6/10, Batch 20/49, Loss: 0.2537
Epoch 6/10, Batch 30/49, Loss: 0.2458
Epoch 6/10, Batch 40/49, Loss: 0.3091
Epoch 6/10, Train Loss: 0.3005, Valid Loss: 0.2860
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2340
Epoch 7/10, Batch 20/49, Loss: 0.3884
Epoch 7/10, Batch 30/49, Loss: 0.2563
Epoch 7/10, Batch 40/49, Loss: 0.1871
Epoch 7/10, Train Loss: 0.2710, Valid Loss: 0.2911
Epoch 8/10, Batch 10/49, Loss: 0.3156
Epoch 8/10, Batch 20/49, Loss: 0.2261
Epoch 8/10, Batch 30/49, Loss: 0.2735
Epoch 8/10, Batch 40/49, Loss: 0.1693
Epoch 8/10, Train Loss: 0.2664, Valid Loss: 0.2719
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2665
Epoch 9/10, Batch 20/49, Loss: 0.1522
Epoch 9/10, Batch 30/49, Loss: 0.1650
Epoch 9/10, Batch 40/49, Loss: 0.3656
Epoch 9/10, Train Loss: 0.2420, Valid Loss: 0.2510
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3376
Epoch 10/10, Batch 20/49, Loss: 0.1465
Epoch 10/10, Batch 30/49, Loss: 0.2230
Epoch 10/10, Batch 40/49, Loss: 0.2383
Epoch 10/10, Train Loss: 0.2232, Valid Loss: 0.2599
Accuracy: 0.9124
Precision: 0.9089
Recall: 0.9124
F1-score: 0.9092
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2746
Epoch 1/10, Batch 20/49, Loss: 1.1118
Epoch 1/10, Batch 30/49, Loss: 0.9229
Epoch 1/10, Batch 40/49, Loss: 0.7202
Epoch 1/10, Train Loss: 1.0030, Valid Loss: 0.6297
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6054
Epoch 2/10, Batch 20/49, Loss: 0.5620
Epoch 2/10, Batch 30/49, Loss: 0.4562
Epoch 2/10, Batch 40/49, Loss: 0.4073
Epoch 2/10, Train Loss: 0.5241, Valid Loss: 0.4287
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3528
Epoch 3/10, Batch 20/49, Loss: 0.3129
Epoch 3/10, Batch 30/49, Loss: 0.4684
Epoch 3/10, Batch 40/49, Loss: 0.3112
Epoch 3/10, Train Loss: 0.4032, Valid Loss: 0.3649
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4017
Epoch 4/10, Batch 20/49, Loss: 0.3504
Epoch 4/10, Batch 30/49, Loss: 0.2934
Epoch 4/10, Batch 40/49, Loss: 0.4209
Epoch 4/10, Train Loss: 0.3446, Valid Loss: 0.3189
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4333
Epoch 5/10, Batch 20/49, Loss: 0.3106
Epoch 5/10, Batch 30/49, Loss: 0.2153
Epoch 5/10, Batch 40/49, Loss: 0.2693
Epoch 5/10, Train Loss: 0.3137, Valid Loss: 0.3035
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2467
Epoch 6/10, Batch 20/49, Loss: 0.2170
Epoch 6/10, Batch 30/49, Loss: 0.2584
Epoch 6/10, Batch 40/49, Loss: 0.1569
Epoch 6/10, Train Loss: 0.2747, Valid Loss: 0.2825
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1905
Epoch 7/10, Batch 20/49, Loss: 0.3263
Epoch 7/10, Batch 30/49, Loss: 0.1531
Epoch 7/10, Batch 40/49, Loss: 0.1036
Epoch 7/10, Train Loss: 0.2381, Valid Loss: 0.2884
Epoch 8/10, Batch 10/49, Loss: 0.2361
Epoch 8/10, Batch 20/49, Loss: 0.3064
Epoch 8/10, Batch 30/49, Loss: 0.2562
Epoch 8/10, Batch 40/49, Loss: 0.2187
Epoch 8/10, Train Loss: 0.2433, Valid Loss: 0.2687
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3089
Epoch 9/10, Batch 20/49, Loss: 0.2897
Epoch 9/10, Batch 30/49, Loss: 0.3516
Epoch 9/10, Batch 40/49, Loss: 0.3553
Epoch 9/10, Train Loss: 0.2191, Valid Loss: 0.2603
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2876
Epoch 10/10, Batch 20/49, Loss: 0.1672
Epoch 10/10, Batch 30/49, Loss: 0.2192
Epoch 10/10, Batch 40/49, Loss: 0.2063
Epoch 10/10, Train Loss: 0.1971, Valid Loss: 0.2593
Model saved!
Accuracy: 0.8949
Precision: 0.8931
Recall: 0.8949
F1-score: 0.8889
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2614
Epoch 1/10, Batch 20/49, Loss: 1.1821
Epoch 1/10, Batch 30/49, Loss: 0.9630
Epoch 1/10, Batch 40/49, Loss: 0.7021
Epoch 1/10, Train Loss: 1.0123, Valid Loss: 0.6023
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6071
Epoch 2/10, Batch 20/49, Loss: 0.6929
Epoch 2/10, Batch 30/49, Loss: 0.5662
Epoch 2/10, Batch 40/49, Loss: 0.5173
Epoch 2/10, Train Loss: 0.5369, Valid Loss: 0.4186
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4217
Epoch 3/10, Batch 20/49, Loss: 0.4962
Epoch 3/10, Batch 30/49, Loss: 0.3532
Epoch 3/10, Batch 40/49, Loss: 0.3376
Epoch 3/10, Train Loss: 0.4117, Valid Loss: 0.3573
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4621
Epoch 4/10, Batch 20/49, Loss: 0.4013
Epoch 4/10, Batch 30/49, Loss: 0.2990
Epoch 4/10, Batch 40/49, Loss: 0.3429
Epoch 4/10, Train Loss: 0.3564, Valid Loss: 0.3191
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3170
Epoch 5/10, Batch 20/49, Loss: 0.2404
Epoch 5/10, Batch 30/49, Loss: 0.2539
Epoch 5/10, Batch 40/49, Loss: 0.2635
Epoch 5/10, Train Loss: 0.3224, Valid Loss: 0.2926
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3209
Epoch 6/10, Batch 20/49, Loss: 0.2142
Epoch 6/10, Batch 30/49, Loss: 0.2967
Epoch 6/10, Batch 40/49, Loss: 0.2248
Epoch 6/10, Train Loss: 0.2942, Valid Loss: 0.2802
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1985
Epoch 7/10, Batch 20/49, Loss: 0.3218
Epoch 7/10, Batch 30/49, Loss: 0.1637
Epoch 7/10, Batch 40/49, Loss: 0.1149
Epoch 7/10, Train Loss: 0.2517, Valid Loss: 0.2821
Epoch 8/10, Batch 10/49, Loss: 0.3861
Epoch 8/10, Batch 20/49, Loss: 0.2111
Epoch 8/10, Batch 30/49, Loss: 0.2095
Epoch 8/10, Batch 40/49, Loss: 0.2126
Epoch 8/10, Train Loss: 0.2451, Valid Loss: 0.2713
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1921
Epoch 9/10, Batch 20/49, Loss: 0.1414
Epoch 9/10, Batch 30/49, Loss: 0.2593
Epoch 9/10, Batch 40/49, Loss: 0.3434
Epoch 9/10, Train Loss: 0.2286, Valid Loss: 0.2601
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.4824
Epoch 10/10, Batch 20/49, Loss: 0.2008
Epoch 10/10, Batch 30/49, Loss: 0.1281
Epoch 10/10, Batch 40/49, Loss: 0.1735
Epoch 10/10, Train Loss: 0.2206, Valid Loss: 0.2507
Model saved!
Accuracy: 0.8995
Precision: 0.8979
Recall: 0.8995
F1-score: 0.8953
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2022
Epoch 1/10, Batch 20/49, Loss: 1.0889
Epoch 1/10, Batch 30/49, Loss: 0.7843
Epoch 1/10, Batch 40/49, Loss: 0.7189
Epoch 1/10, Train Loss: 1.0023, Valid Loss: 0.5916
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6070
Epoch 2/10, Batch 20/49, Loss: 0.6583
Epoch 2/10, Batch 30/49, Loss: 0.3692
Epoch 2/10, Batch 40/49, Loss: 0.6423
Epoch 2/10, Train Loss: 0.5440, Valid Loss: 0.4293
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5797
Epoch 3/10, Batch 20/49, Loss: 0.3179
Epoch 3/10, Batch 30/49, Loss: 0.4147
Epoch 3/10, Batch 40/49, Loss: 0.5427
Epoch 3/10, Train Loss: 0.4012, Valid Loss: 0.3833
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3056
Epoch 4/10, Batch 20/49, Loss: 0.3683
Epoch 4/10, Batch 30/49, Loss: 0.4013
Epoch 4/10, Batch 40/49, Loss: 0.4061
Epoch 4/10, Train Loss: 0.3580, Valid Loss: 0.3416
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5380
Epoch 5/10, Batch 20/49, Loss: 0.3572
Epoch 5/10, Batch 30/49, Loss: 0.3240
Epoch 5/10, Batch 40/49, Loss: 0.1941
Epoch 5/10, Train Loss: 0.3187, Valid Loss: 0.3204
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3041
Epoch 6/10, Batch 20/49, Loss: 0.2384
Epoch 6/10, Batch 30/49, Loss: 0.1884
Epoch 6/10, Batch 40/49, Loss: 0.2359
Epoch 6/10, Train Loss: 0.2914, Valid Loss: 0.3056
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2435
Epoch 7/10, Batch 20/49, Loss: 0.1848
Epoch 7/10, Batch 30/49, Loss: 0.2364
Epoch 7/10, Batch 40/49, Loss: 0.0920
Epoch 7/10, Train Loss: 0.2474, Valid Loss: 0.3094
Epoch 8/10, Batch 10/49, Loss: 0.3291
Epoch 8/10, Batch 20/49, Loss: 0.3054
Epoch 8/10, Batch 30/49, Loss: 0.1332
Epoch 8/10, Batch 40/49, Loss: 0.2984
Epoch 8/10, Train Loss: 0.2424, Valid Loss: 0.2965
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2555
Epoch 9/10, Batch 20/49, Loss: 0.1708
Epoch 9/10, Batch 30/49, Loss: 0.2440
Epoch 9/10, Batch 40/49, Loss: 0.3176
Epoch 9/10, Train Loss: 0.2382, Valid Loss: 0.2909
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2673
Epoch 10/10, Batch 20/49, Loss: 0.1712
Epoch 10/10, Batch 30/49, Loss: 0.1394
Epoch 10/10, Batch 40/49, Loss: 0.2295
Epoch 10/10, Train Loss: 0.2050, Valid Loss: 0.2825
Model saved!
Accuracy: 0.9030
Precision: 0.8988
Recall: 0.9030
F1-score: 0.8988
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2697
Epoch 1/10, Batch 20/49, Loss: 1.1874
Epoch 1/10, Batch 30/49, Loss: 0.9864
Epoch 1/10, Batch 40/49, Loss: 0.7624
Epoch 1/10, Train Loss: 1.0188, Valid Loss: 0.6658
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5870
Epoch 2/10, Batch 20/49, Loss: 0.7079
Epoch 2/10, Batch 30/49, Loss: 0.5395
Epoch 2/10, Batch 40/49, Loss: 0.5038
Epoch 2/10, Train Loss: 0.5512, Valid Loss: 0.4664
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3014
Epoch 3/10, Batch 20/49, Loss: 0.3862
Epoch 3/10, Batch 30/49, Loss: 0.3749
Epoch 3/10, Batch 40/49, Loss: 0.4945
Epoch 3/10, Train Loss: 0.4127, Valid Loss: 0.4119
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.1802
Epoch 4/10, Batch 20/49, Loss: 0.3994
Epoch 4/10, Batch 30/49, Loss: 0.3129
Epoch 4/10, Batch 40/49, Loss: 0.3420
Epoch 4/10, Train Loss: 0.3743, Valid Loss: 0.3591
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4655
Epoch 5/10, Batch 20/49, Loss: 0.1774
Epoch 5/10, Batch 30/49, Loss: 0.2504
Epoch 5/10, Batch 40/49, Loss: 0.2101
Epoch 5/10, Train Loss: 0.3248, Valid Loss: 0.3404
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3053
Epoch 6/10, Batch 20/49, Loss: 0.1607
Epoch 6/10, Batch 30/49, Loss: 0.2114
Epoch 6/10, Batch 40/49, Loss: 0.2442
Epoch 6/10, Train Loss: 0.2924, Valid Loss: 0.3155
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1843
Epoch 7/10, Batch 20/49, Loss: 0.2242
Epoch 7/10, Batch 30/49, Loss: 0.1888
Epoch 7/10, Batch 40/49, Loss: 0.1852
Epoch 7/10, Train Loss: 0.2591, Valid Loss: 0.3126
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3265
Epoch 8/10, Batch 20/49, Loss: 0.2523
Epoch 8/10, Batch 30/49, Loss: 0.2428
Epoch 8/10, Batch 40/49, Loss: 0.2651
Epoch 8/10, Train Loss: 0.2508, Valid Loss: 0.3072
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2196
Epoch 9/10, Batch 20/49, Loss: 0.1841
Epoch 9/10, Batch 30/49, Loss: 0.1933
Epoch 9/10, Batch 40/49, Loss: 0.2455
Epoch 9/10, Train Loss: 0.2359, Valid Loss: 0.2933
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3322
Epoch 10/10, Batch 20/49, Loss: 0.1864
Epoch 10/10, Batch 30/49, Loss: 0.1386
Epoch 10/10, Batch 40/49, Loss: 0.2958
Epoch 10/10, Train Loss: 0.2248, Valid Loss: 0.2870
Model saved!
Accuracy: 0.8890
Precision: 0.8861
Recall: 0.8890
F1-score: 0.8851
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2097
Epoch 1/10, Batch 20/49, Loss: 1.1790
Epoch 1/10, Batch 30/49, Loss: 0.7892
Epoch 1/10, Batch 40/49, Loss: 0.7220
Epoch 1/10, Train Loss: 1.0182, Valid Loss: 0.6230
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5829
Epoch 2/10, Batch 20/49, Loss: 0.6763
Epoch 2/10, Batch 30/49, Loss: 0.5263
Epoch 2/10, Batch 40/49, Loss: 0.3762
Epoch 2/10, Train Loss: 0.5506, Valid Loss: 0.4441
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4779
Epoch 3/10, Batch 20/49, Loss: 0.4047
Epoch 3/10, Batch 30/49, Loss: 0.5026
Epoch 3/10, Batch 40/49, Loss: 0.2887
Epoch 3/10, Train Loss: 0.4254, Valid Loss: 0.3866
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3466
Epoch 4/10, Batch 20/49, Loss: 0.3246
Epoch 4/10, Batch 30/49, Loss: 0.3729
Epoch 4/10, Batch 40/49, Loss: 0.4602
Epoch 4/10, Train Loss: 0.3754, Valid Loss: 0.3443
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3731
Epoch 5/10, Batch 20/49, Loss: 0.1948
Epoch 5/10, Batch 30/49, Loss: 0.2211
Epoch 5/10, Batch 40/49, Loss: 0.2267
Epoch 5/10, Train Loss: 0.3172, Valid Loss: 0.3100
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3789
Epoch 6/10, Batch 20/49, Loss: 0.2475
Epoch 6/10, Batch 30/49, Loss: 0.3346
Epoch 6/10, Batch 40/49, Loss: 0.3546
Epoch 6/10, Train Loss: 0.3028, Valid Loss: 0.3012
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3664
Epoch 7/10, Batch 20/49, Loss: 0.3312
Epoch 7/10, Batch 30/49, Loss: 0.2026
Epoch 7/10, Batch 40/49, Loss: 0.2413
Epoch 7/10, Train Loss: 0.2632, Valid Loss: 0.3096
Epoch 8/10, Batch 10/49, Loss: 0.2295
Epoch 8/10, Batch 20/49, Loss: 0.2155
Epoch 8/10, Batch 30/49, Loss: 0.3277
Epoch 8/10, Batch 40/49, Loss: 0.1283
Epoch 8/10, Train Loss: 0.2630, Valid Loss: 0.2926
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3852
Epoch 9/10, Batch 20/49, Loss: 0.1849
Epoch 9/10, Batch 30/49, Loss: 0.2949
Epoch 9/10, Batch 40/49, Loss: 0.2931
Epoch 9/10, Train Loss: 0.2501, Valid Loss: 0.2828
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3129
Epoch 10/10, Batch 20/49, Loss: 0.2062
Epoch 10/10, Batch 30/49, Loss: 0.2714
Epoch 10/10, Batch 40/49, Loss: 0.2580
Epoch 10/10, Train Loss: 0.2164, Valid Loss: 0.2739
Model saved!
Accuracy: 0.9019
Precision: 0.8993
Recall: 0.9019
F1-score: 0.8976
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3063
Epoch 1/10, Batch 20/49, Loss: 1.1283
Epoch 1/10, Batch 30/49, Loss: 0.9179
Epoch 1/10, Batch 40/49, Loss: 0.8132
Epoch 1/10, Train Loss: 1.0147, Valid Loss: 0.6053
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5911
Epoch 2/10, Batch 20/49, Loss: 0.6555
Epoch 2/10, Batch 30/49, Loss: 0.5679
Epoch 2/10, Batch 40/49, Loss: 0.4485
Epoch 2/10, Train Loss: 0.5451, Valid Loss: 0.4156
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4453
Epoch 3/10, Batch 20/49, Loss: 0.3241
Epoch 3/10, Batch 30/49, Loss: 0.4836
Epoch 3/10, Batch 40/49, Loss: 0.2983
Epoch 3/10, Train Loss: 0.4160, Valid Loss: 0.3604
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3118
Epoch 4/10, Batch 20/49, Loss: 0.3638
Epoch 4/10, Batch 30/49, Loss: 0.3345
Epoch 4/10, Batch 40/49, Loss: 0.4439
Epoch 4/10, Train Loss: 0.3676, Valid Loss: 0.3041
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4467
Epoch 5/10, Batch 20/49, Loss: 0.2022
Epoch 5/10, Batch 30/49, Loss: 0.1829
Epoch 5/10, Batch 40/49, Loss: 0.2908
Epoch 5/10, Train Loss: 0.3273, Valid Loss: 0.2797
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3019
Epoch 6/10, Batch 20/49, Loss: 0.3634
Epoch 6/10, Batch 30/49, Loss: 0.3349
Epoch 6/10, Batch 40/49, Loss: 0.1975
Epoch 6/10, Train Loss: 0.2864, Valid Loss: 0.2682
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.4218
Epoch 7/10, Batch 20/49, Loss: 0.3037
Epoch 7/10, Batch 30/49, Loss: 0.1546
Epoch 7/10, Batch 40/49, Loss: 0.1707
Epoch 7/10, Train Loss: 0.2625, Valid Loss: 0.2642
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2558
Epoch 8/10, Batch 20/49, Loss: 0.2558
Epoch 8/10, Batch 30/49, Loss: 0.2321
Epoch 8/10, Batch 40/49, Loss: 0.1424
Epoch 8/10, Train Loss: 0.2612, Valid Loss: 0.2502
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2755
Epoch 9/10, Batch 20/49, Loss: 0.3084
Epoch 9/10, Batch 30/49, Loss: 0.1582
Epoch 9/10, Batch 40/49, Loss: 0.4646
Epoch 9/10, Train Loss: 0.2395, Valid Loss: 0.2379
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2097
Epoch 10/10, Batch 20/49, Loss: 0.2557
Epoch 10/10, Batch 30/49, Loss: 0.1279
Epoch 10/10, Batch 40/49, Loss: 0.1534
Epoch 10/10, Train Loss: 0.2174, Valid Loss: 0.2509
Accuracy: 0.8995
Precision: 0.8963
Recall: 0.8995
F1-score: 0.8960
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2545
Epoch 1/10, Batch 20/49, Loss: 1.1597
Epoch 1/10, Batch 30/49, Loss: 0.7276
Epoch 1/10, Batch 40/49, Loss: 0.8229
Epoch 1/10, Train Loss: 1.0072, Valid Loss: 0.6318
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5541
Epoch 2/10, Batch 20/49, Loss: 0.5954
Epoch 2/10, Batch 30/49, Loss: 0.4360
Epoch 2/10, Batch 40/49, Loss: 0.5056
Epoch 2/10, Train Loss: 0.5461, Valid Loss: 0.4346
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4014
Epoch 3/10, Batch 20/49, Loss: 0.3600
Epoch 3/10, Batch 30/49, Loss: 0.3837
Epoch 3/10, Batch 40/49, Loss: 0.2270
Epoch 3/10, Train Loss: 0.4135, Valid Loss: 0.3758
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4822
Epoch 4/10, Batch 20/49, Loss: 0.3821
Epoch 4/10, Batch 30/49, Loss: 0.3945
Epoch 4/10, Batch 40/49, Loss: 0.4026
Epoch 4/10, Train Loss: 0.3770, Valid Loss: 0.3293
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3399
Epoch 5/10, Batch 20/49, Loss: 0.2546
Epoch 5/10, Batch 30/49, Loss: 0.1398
Epoch 5/10, Batch 40/49, Loss: 0.3109
Epoch 5/10, Train Loss: 0.3213, Valid Loss: 0.2977
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1900
Epoch 6/10, Batch 20/49, Loss: 0.1399
Epoch 6/10, Batch 30/49, Loss: 0.2874
Epoch 6/10, Batch 40/49, Loss: 0.3355
Epoch 6/10, Train Loss: 0.2968, Valid Loss: 0.2746
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2526
Epoch 7/10, Batch 20/49, Loss: 0.2818
Epoch 7/10, Batch 30/49, Loss: 0.3403
Epoch 7/10, Batch 40/49, Loss: 0.1842
Epoch 7/10, Train Loss: 0.2646, Valid Loss: 0.2695
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2716
Epoch 8/10, Batch 20/49, Loss: 0.2191
Epoch 8/10, Batch 30/49, Loss: 0.4469
Epoch 8/10, Batch 40/49, Loss: 0.1345
Epoch 8/10, Train Loss: 0.2525, Valid Loss: 0.2570
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1521
Epoch 9/10, Batch 20/49, Loss: 0.1595
Epoch 9/10, Batch 30/49, Loss: 0.2306
Epoch 9/10, Batch 40/49, Loss: 0.2725
Epoch 9/10, Train Loss: 0.2357, Valid Loss: 0.2490
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2316
Epoch 10/10, Batch 20/49, Loss: 0.2877
Epoch 10/10, Batch 30/49, Loss: 0.0872
Epoch 10/10, Batch 40/49, Loss: 0.2036
Epoch 10/10, Train Loss: 0.2240, Valid Loss: 0.2427
Model saved!
Accuracy: 0.9077
Precision: 0.9052
Recall: 0.9077
F1-score: 0.9051
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2051
Epoch 1/10, Batch 20/49, Loss: 1.0959
Epoch 1/10, Batch 30/49, Loss: 0.7707
Epoch 1/10, Batch 40/49, Loss: 0.8421
Epoch 1/10, Train Loss: 1.0219, Valid Loss: 0.6125
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6407
Epoch 2/10, Batch 20/49, Loss: 0.7383
Epoch 2/10, Batch 30/49, Loss: 0.4771
Epoch 2/10, Batch 40/49, Loss: 0.4455
Epoch 2/10, Train Loss: 0.5572, Valid Loss: 0.4287
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4228
Epoch 3/10, Batch 20/49, Loss: 0.3032
Epoch 3/10, Batch 30/49, Loss: 0.5199
Epoch 3/10, Batch 40/49, Loss: 0.4315
Epoch 3/10, Train Loss: 0.4179, Valid Loss: 0.3745
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3257
Epoch 4/10, Batch 20/49, Loss: 0.4632
Epoch 4/10, Batch 30/49, Loss: 0.3829
Epoch 4/10, Batch 40/49, Loss: 0.4199
Epoch 4/10, Train Loss: 0.3897, Valid Loss: 0.3352
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3817
Epoch 5/10, Batch 20/49, Loss: 0.2235
Epoch 5/10, Batch 30/49, Loss: 0.3283
Epoch 5/10, Batch 40/49, Loss: 0.2698
Epoch 5/10, Train Loss: 0.3388, Valid Loss: 0.3079
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2506
Epoch 6/10, Batch 20/49, Loss: 0.2493
Epoch 6/10, Batch 30/49, Loss: 0.2603
Epoch 6/10, Batch 40/49, Loss: 0.2617
Epoch 6/10, Train Loss: 0.3041, Valid Loss: 0.2960
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2892
Epoch 7/10, Batch 20/49, Loss: 0.3410
Epoch 7/10, Batch 30/49, Loss: 0.2274
Epoch 7/10, Batch 40/49, Loss: 0.1429
Epoch 7/10, Train Loss: 0.2799, Valid Loss: 0.2987
Epoch 8/10, Batch 10/49, Loss: 0.3073
Epoch 8/10, Batch 20/49, Loss: 0.2389
Epoch 8/10, Batch 30/49, Loss: 0.2758
Epoch 8/10, Batch 40/49, Loss: 0.2574
Epoch 8/10, Train Loss: 0.2660, Valid Loss: 0.3049
Epoch 9/10, Batch 10/49, Loss: 0.2555
Epoch 9/10, Batch 20/49, Loss: 0.2654
Epoch 9/10, Batch 30/49, Loss: 0.3159
Epoch 9/10, Batch 40/49, Loss: 0.2847
Epoch 9/10, Train Loss: 0.2581, Valid Loss: 0.2693
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3699
Epoch 10/10, Batch 20/49, Loss: 0.3224
Epoch 10/10, Batch 30/49, Loss: 0.2335
Epoch 10/10, Batch 40/49, Loss: 0.2230
Epoch 10/10, Train Loss: 0.2359, Valid Loss: 0.2744
Accuracy: 0.9019
Precision: 0.8975
Recall: 0.9019
F1-score: 0.8976
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1987
Epoch 1/10, Batch 20/49, Loss: 1.1508
Epoch 1/10, Batch 30/49, Loss: 0.7952
Epoch 1/10, Batch 40/49, Loss: 0.8093
Epoch 1/10, Train Loss: 1.0058, Valid Loss: 0.5974
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.4713
Epoch 2/10, Batch 20/49, Loss: 0.6385
Epoch 2/10, Batch 30/49, Loss: 0.3976
Epoch 2/10, Batch 40/49, Loss: 0.5074
Epoch 2/10, Train Loss: 0.5412, Valid Loss: 0.4082
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4839
Epoch 3/10, Batch 20/49, Loss: 0.3586
Epoch 3/10, Batch 30/49, Loss: 0.3761
Epoch 3/10, Batch 40/49, Loss: 0.4568
Epoch 3/10, Train Loss: 0.4146, Valid Loss: 0.3491
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2305
Epoch 4/10, Batch 20/49, Loss: 0.4923
Epoch 4/10, Batch 30/49, Loss: 0.4100
Epoch 4/10, Batch 40/49, Loss: 0.3138
Epoch 4/10, Train Loss: 0.3683, Valid Loss: 0.3099
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3576
Epoch 5/10, Batch 20/49, Loss: 0.1773
Epoch 5/10, Batch 30/49, Loss: 0.3114
Epoch 5/10, Batch 40/49, Loss: 0.3269
Epoch 5/10, Train Loss: 0.3067, Valid Loss: 0.2902
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2389
Epoch 6/10, Batch 20/49, Loss: 0.2697
Epoch 6/10, Batch 30/49, Loss: 0.1755
Epoch 6/10, Batch 40/49, Loss: 0.3313
Epoch 6/10, Train Loss: 0.2906, Valid Loss: 0.2585
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2557
Epoch 7/10, Batch 20/49, Loss: 0.2920
Epoch 7/10, Batch 30/49, Loss: 0.2916
Epoch 7/10, Batch 40/49, Loss: 0.2539
Epoch 7/10, Train Loss: 0.2501, Valid Loss: 0.2657
Epoch 8/10, Batch 10/49, Loss: 0.2397
Epoch 8/10, Batch 20/49, Loss: 0.2779
Epoch 8/10, Batch 30/49, Loss: 0.2361
Epoch 8/10, Batch 40/49, Loss: 0.3089
Epoch 8/10, Train Loss: 0.2524, Valid Loss: 0.2597
Epoch 9/10, Batch 10/49, Loss: 0.2584
Epoch 9/10, Batch 20/49, Loss: 0.1439
Epoch 9/10, Batch 30/49, Loss: 0.2055
Epoch 9/10, Batch 40/49, Loss: 0.4153
Epoch 9/10, Train Loss: 0.2308, Valid Loss: 0.2451
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2349
Epoch 10/10, Batch 20/49, Loss: 0.2989
Epoch 10/10, Batch 30/49, Loss: 0.1413
Epoch 10/10, Batch 40/49, Loss: 0.1901
Epoch 10/10, Train Loss: 0.2126, Valid Loss: 0.2416
Model saved!
Accuracy: 0.9042
Precision: 0.9003
Recall: 0.9042
F1-score: 0.9003
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1734
Epoch 1/10, Batch 20/49, Loss: 1.1009
Epoch 1/10, Batch 30/49, Loss: 0.7969
Epoch 1/10, Batch 40/49, Loss: 0.9004
Epoch 1/10, Train Loss: 0.9943, Valid Loss: 0.6198
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5690
Epoch 2/10, Batch 20/49, Loss: 0.7240
Epoch 2/10, Batch 30/49, Loss: 0.6314
Epoch 2/10, Batch 40/49, Loss: 0.4149
Epoch 2/10, Train Loss: 0.5366, Valid Loss: 0.4263
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3155
Epoch 3/10, Batch 20/49, Loss: 0.3709
Epoch 3/10, Batch 30/49, Loss: 0.5288
Epoch 3/10, Batch 40/49, Loss: 0.3625
Epoch 3/10, Train Loss: 0.4103, Valid Loss: 0.3675
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3017
Epoch 4/10, Batch 20/49, Loss: 0.3410
Epoch 4/10, Batch 30/49, Loss: 0.3188
Epoch 4/10, Batch 40/49, Loss: 0.3698
Epoch 4/10, Train Loss: 0.3645, Valid Loss: 0.3264
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5430
Epoch 5/10, Batch 20/49, Loss: 0.3423
Epoch 5/10, Batch 30/49, Loss: 0.1981
Epoch 5/10, Batch 40/49, Loss: 0.3666
Epoch 5/10, Train Loss: 0.3245, Valid Loss: 0.2978
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3221
Epoch 6/10, Batch 20/49, Loss: 0.2186
Epoch 6/10, Batch 30/49, Loss: 0.4437
Epoch 6/10, Batch 40/49, Loss: 0.3819
Epoch 6/10, Train Loss: 0.3029, Valid Loss: 0.2867
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3582
Epoch 7/10, Batch 20/49, Loss: 0.1995
Epoch 7/10, Batch 30/49, Loss: 0.2978
Epoch 7/10, Batch 40/49, Loss: 0.2126
Epoch 7/10, Train Loss: 0.2612, Valid Loss: 0.2844
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2505
Epoch 8/10, Batch 20/49, Loss: 0.1499
Epoch 8/10, Batch 30/49, Loss: 0.1591
Epoch 8/10, Batch 40/49, Loss: 0.2914
Epoch 8/10, Train Loss: 0.2488, Valid Loss: 0.2722
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1691
Epoch 9/10, Batch 20/49, Loss: 0.1153
Epoch 9/10, Batch 30/49, Loss: 0.3967
Epoch 9/10, Batch 40/49, Loss: 0.2245
Epoch 9/10, Train Loss: 0.2277, Valid Loss: 0.2661
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2018
Epoch 10/10, Batch 20/49, Loss: 0.1453
Epoch 10/10, Batch 30/49, Loss: 0.2160
Epoch 10/10, Batch 40/49, Loss: 0.2009
Epoch 10/10, Train Loss: 0.2206, Valid Loss: 0.2589
Model saved!
Accuracy: 0.9054
Precision: 0.9012
Recall: 0.9054
F1-score: 0.9020
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2445
Epoch 1/10, Batch 20/49, Loss: 1.1529
Epoch 1/10, Batch 30/49, Loss: 0.9898
Epoch 1/10, Batch 40/49, Loss: 0.7239
Epoch 1/10, Train Loss: 1.0155, Valid Loss: 0.6575
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7094
Epoch 2/10, Batch 20/49, Loss: 0.5776
Epoch 2/10, Batch 30/49, Loss: 0.4618
Epoch 2/10, Batch 40/49, Loss: 0.5098
Epoch 2/10, Train Loss: 0.5442, Valid Loss: 0.4633
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3668
Epoch 3/10, Batch 20/49, Loss: 0.2892
Epoch 3/10, Batch 30/49, Loss: 0.3521
Epoch 3/10, Batch 40/49, Loss: 0.4108
Epoch 3/10, Train Loss: 0.4167, Valid Loss: 0.3892
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4530
Epoch 4/10, Batch 20/49, Loss: 0.3153
Epoch 4/10, Batch 30/49, Loss: 0.4206
Epoch 4/10, Batch 40/49, Loss: 0.4772
Epoch 4/10, Train Loss: 0.3576, Valid Loss: 0.3464
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3872
Epoch 5/10, Batch 20/49, Loss: 0.2657
Epoch 5/10, Batch 30/49, Loss: 0.2558
Epoch 5/10, Batch 40/49, Loss: 0.1971
Epoch 5/10, Train Loss: 0.3159, Valid Loss: 0.3212
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2834
Epoch 6/10, Batch 20/49, Loss: 0.2093
Epoch 6/10, Batch 30/49, Loss: 0.2624
Epoch 6/10, Batch 40/49, Loss: 0.2402
Epoch 6/10, Train Loss: 0.2933, Valid Loss: 0.2998
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3659
Epoch 7/10, Batch 20/49, Loss: 0.2563
Epoch 7/10, Batch 30/49, Loss: 0.2398
Epoch 7/10, Batch 40/49, Loss: 0.1716
Epoch 7/10, Train Loss: 0.2554, Valid Loss: 0.2915
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3421
Epoch 8/10, Batch 20/49, Loss: 0.2304
Epoch 8/10, Batch 30/49, Loss: 0.1879
Epoch 8/10, Batch 40/49, Loss: 0.1567
Epoch 8/10, Train Loss: 0.2553, Valid Loss: 0.2880
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1640
Epoch 9/10, Batch 20/49, Loss: 0.2433
Epoch 9/10, Batch 30/49, Loss: 0.2191
Epoch 9/10, Batch 40/49, Loss: 0.3156
Epoch 9/10, Train Loss: 0.2368, Valid Loss: 0.2730
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2592
Epoch 10/10, Batch 20/49, Loss: 0.1807
Epoch 10/10, Batch 30/49, Loss: 0.1884
Epoch 10/10, Batch 40/49, Loss: 0.1845
Epoch 10/10, Train Loss: 0.2222, Valid Loss: 0.2808
Accuracy: 0.8984
Precision: 0.8936
Recall: 0.8984
F1-score: 0.8948
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2629
Epoch 1/10, Batch 20/49, Loss: 1.2006
Epoch 1/10, Batch 30/49, Loss: 0.9743
Epoch 1/10, Batch 40/49, Loss: 0.7588
Epoch 1/10, Train Loss: 1.0266, Valid Loss: 0.6434
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5205
Epoch 2/10, Batch 20/49, Loss: 0.7105
Epoch 2/10, Batch 30/49, Loss: 0.5228
Epoch 2/10, Batch 40/49, Loss: 0.5058
Epoch 2/10, Train Loss: 0.5523, Valid Loss: 0.4452
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4128
Epoch 3/10, Batch 20/49, Loss: 0.4267
Epoch 3/10, Batch 30/49, Loss: 0.5538
Epoch 3/10, Batch 40/49, Loss: 0.4692
Epoch 3/10, Train Loss: 0.4260, Valid Loss: 0.3874
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3566
Epoch 4/10, Batch 20/49, Loss: 0.4112
Epoch 4/10, Batch 30/49, Loss: 0.4526
Epoch 4/10, Batch 40/49, Loss: 0.4320
Epoch 4/10, Train Loss: 0.3673, Valid Loss: 0.3267
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3730
Epoch 5/10, Batch 20/49, Loss: 0.2354
Epoch 5/10, Batch 30/49, Loss: 0.3160
Epoch 5/10, Batch 40/49, Loss: 0.2818
Epoch 5/10, Train Loss: 0.3260, Valid Loss: 0.3011
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2974
Epoch 6/10, Batch 20/49, Loss: 0.1772
Epoch 6/10, Batch 30/49, Loss: 0.1669
Epoch 6/10, Batch 40/49, Loss: 0.2340
Epoch 6/10, Train Loss: 0.2973, Valid Loss: 0.2799
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2223
Epoch 7/10, Batch 20/49, Loss: 0.2983
Epoch 7/10, Batch 30/49, Loss: 0.3172
Epoch 7/10, Batch 40/49, Loss: 0.1981
Epoch 7/10, Train Loss: 0.2667, Valid Loss: 0.2757
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3159
Epoch 8/10, Batch 20/49, Loss: 0.3643
Epoch 8/10, Batch 30/49, Loss: 0.3030
Epoch 8/10, Batch 40/49, Loss: 0.1940
Epoch 8/10, Train Loss: 0.2533, Valid Loss: 0.2563
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3025
Epoch 9/10, Batch 20/49, Loss: 0.1832
Epoch 9/10, Batch 30/49, Loss: 0.2767
Epoch 9/10, Batch 40/49, Loss: 0.2339
Epoch 9/10, Train Loss: 0.2347, Valid Loss: 0.2499
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2395
Epoch 10/10, Batch 20/49, Loss: 0.1941
Epoch 10/10, Batch 30/49, Loss: 0.1098
Epoch 10/10, Batch 40/49, Loss: 0.2098
Epoch 10/10, Train Loss: 0.2194, Valid Loss: 0.2458
Model saved!
Accuracy: 0.9030
Precision: 0.9001
Recall: 0.9030
F1-score: 0.9002
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2195
Epoch 1/10, Batch 20/49, Loss: 1.1040
Epoch 1/10, Batch 30/49, Loss: 0.7924
Epoch 1/10, Batch 40/49, Loss: 0.7501
Epoch 1/10, Train Loss: 1.0177, Valid Loss: 0.6050
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6212
Epoch 2/10, Batch 20/49, Loss: 0.6292
Epoch 2/10, Batch 30/49, Loss: 0.4585
Epoch 2/10, Batch 40/49, Loss: 0.4450
Epoch 2/10, Train Loss: 0.5509, Valid Loss: 0.4102
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4414
Epoch 3/10, Batch 20/49, Loss: 0.4511
Epoch 3/10, Batch 30/49, Loss: 0.3719
Epoch 3/10, Batch 40/49, Loss: 0.3364
Epoch 3/10, Train Loss: 0.4091, Valid Loss: 0.3569
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3824
Epoch 4/10, Batch 20/49, Loss: 0.3190
Epoch 4/10, Batch 30/49, Loss: 0.4951
Epoch 4/10, Batch 40/49, Loss: 0.3512
Epoch 4/10, Train Loss: 0.3648, Valid Loss: 0.3051
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2856
Epoch 5/10, Batch 20/49, Loss: 0.2610
Epoch 5/10, Batch 30/49, Loss: 0.2186
Epoch 5/10, Batch 40/49, Loss: 0.3980
Epoch 5/10, Train Loss: 0.3226, Valid Loss: 0.2844
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3917
Epoch 6/10, Batch 20/49, Loss: 0.3062
Epoch 6/10, Batch 30/49, Loss: 0.2553
Epoch 6/10, Batch 40/49, Loss: 0.3206
Epoch 6/10, Train Loss: 0.3016, Valid Loss: 0.2644
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2985
Epoch 7/10, Batch 20/49, Loss: 0.4082
Epoch 7/10, Batch 30/49, Loss: 0.2380
Epoch 7/10, Batch 40/49, Loss: 0.2155
Epoch 7/10, Train Loss: 0.2713, Valid Loss: 0.2730
Epoch 8/10, Batch 10/49, Loss: 0.2851
Epoch 8/10, Batch 20/49, Loss: 0.1965
Epoch 8/10, Batch 30/49, Loss: 0.1970
Epoch 8/10, Batch 40/49, Loss: 0.2259
Epoch 8/10, Train Loss: 0.2539, Valid Loss: 0.2602
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3120
Epoch 9/10, Batch 20/49, Loss: 0.2567
Epoch 9/10, Batch 30/49, Loss: 0.2118
Epoch 9/10, Batch 40/49, Loss: 0.2254
Epoch 9/10, Train Loss: 0.2408, Valid Loss: 0.2468
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3422
Epoch 10/10, Batch 20/49, Loss: 0.1385
Epoch 10/10, Batch 30/49, Loss: 0.2803
Epoch 10/10, Batch 40/49, Loss: 0.2021
Epoch 10/10, Train Loss: 0.2332, Valid Loss: 0.2453
Model saved!
Accuracy: 0.9124
Precision: 0.9097
Recall: 0.9124
F1-score: 0.9096
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1565
Epoch 1/10, Batch 20/49, Loss: 1.1399
Epoch 1/10, Batch 30/49, Loss: 0.9010
Epoch 1/10, Batch 40/49, Loss: 0.7359
Epoch 1/10, Train Loss: 1.0113, Valid Loss: 0.5869
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.4983
Epoch 2/10, Batch 20/49, Loss: 0.7241
Epoch 2/10, Batch 30/49, Loss: 0.4105
Epoch 2/10, Batch 40/49, Loss: 0.5619
Epoch 2/10, Train Loss: 0.5423, Valid Loss: 0.4056
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4123
Epoch 3/10, Batch 20/49, Loss: 0.2878
Epoch 3/10, Batch 30/49, Loss: 0.4195
Epoch 3/10, Batch 40/49, Loss: 0.3251
Epoch 3/10, Train Loss: 0.4196, Valid Loss: 0.3605
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3395
Epoch 4/10, Batch 20/49, Loss: 0.4165
Epoch 4/10, Batch 30/49, Loss: 0.3590
Epoch 4/10, Batch 40/49, Loss: 0.4679
Epoch 4/10, Train Loss: 0.3688, Valid Loss: 0.3136
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.6029
Epoch 5/10, Batch 20/49, Loss: 0.1648
Epoch 5/10, Batch 30/49, Loss: 0.2025
Epoch 5/10, Batch 40/49, Loss: 0.3297
Epoch 5/10, Train Loss: 0.3233, Valid Loss: 0.2872
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2507
Epoch 6/10, Batch 20/49, Loss: 0.1747
Epoch 6/10, Batch 30/49, Loss: 0.3384
Epoch 6/10, Batch 40/49, Loss: 0.3596
Epoch 6/10, Train Loss: 0.2874, Valid Loss: 0.2754
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2333
Epoch 7/10, Batch 20/49, Loss: 0.3154
Epoch 7/10, Batch 30/49, Loss: 0.2649
Epoch 7/10, Batch 40/49, Loss: 0.1833
Epoch 7/10, Train Loss: 0.2602, Valid Loss: 0.2981
Epoch 8/10, Batch 10/49, Loss: 0.3908
Epoch 8/10, Batch 20/49, Loss: 0.2826
Epoch 8/10, Batch 30/49, Loss: 0.2272
Epoch 8/10, Batch 40/49, Loss: 0.2548
Epoch 8/10, Train Loss: 0.2573, Valid Loss: 0.2674
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1629
Epoch 9/10, Batch 20/49, Loss: 0.2739
Epoch 9/10, Batch 30/49, Loss: 0.4026
Epoch 9/10, Batch 40/49, Loss: 0.1910
Epoch 9/10, Train Loss: 0.2344, Valid Loss: 0.2528
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2801
Epoch 10/10, Batch 20/49, Loss: 0.2408
Epoch 10/10, Batch 30/49, Loss: 0.1143
Epoch 10/10, Batch 40/49, Loss: 0.2448
Epoch 10/10, Train Loss: 0.2200, Valid Loss: 0.2531
Accuracy: 0.9042
Precision: 0.9014
Recall: 0.9042
F1-score: 0.9021
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2565
Epoch 1/10, Batch 20/49, Loss: 1.0899
Epoch 1/10, Batch 30/49, Loss: 0.8101
Epoch 1/10, Batch 40/49, Loss: 0.6946
Epoch 1/10, Train Loss: 1.0022, Valid Loss: 0.6102
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6580
Epoch 2/10, Batch 20/49, Loss: 0.6407
Epoch 2/10, Batch 30/49, Loss: 0.4753
Epoch 2/10, Batch 40/49, Loss: 0.5140
Epoch 2/10, Train Loss: 0.5432, Valid Loss: 0.4205
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4390
Epoch 3/10, Batch 20/49, Loss: 0.3953
Epoch 3/10, Batch 30/49, Loss: 0.3449
Epoch 3/10, Batch 40/49, Loss: 0.4143
Epoch 3/10, Train Loss: 0.4191, Valid Loss: 0.3679
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3267
Epoch 4/10, Batch 20/49, Loss: 0.3469
Epoch 4/10, Batch 30/49, Loss: 0.4196
Epoch 4/10, Batch 40/49, Loss: 0.3510
Epoch 4/10, Train Loss: 0.3664, Valid Loss: 0.3236
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3781
Epoch 5/10, Batch 20/49, Loss: 0.1547
Epoch 5/10, Batch 30/49, Loss: 0.2908
Epoch 5/10, Batch 40/49, Loss: 0.2804
Epoch 5/10, Train Loss: 0.3324, Valid Loss: 0.3040
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3193
Epoch 6/10, Batch 20/49, Loss: 0.2146
Epoch 6/10, Batch 30/49, Loss: 0.2089
Epoch 6/10, Batch 40/49, Loss: 0.2236
Epoch 6/10, Train Loss: 0.2887, Valid Loss: 0.2883
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3774
Epoch 7/10, Batch 20/49, Loss: 0.2421
Epoch 7/10, Batch 30/49, Loss: 0.2043
Epoch 7/10, Batch 40/49, Loss: 0.1680
Epoch 7/10, Train Loss: 0.2657, Valid Loss: 0.2936
Epoch 8/10, Batch 10/49, Loss: 0.2838
Epoch 8/10, Batch 20/49, Loss: 0.1549
Epoch 8/10, Batch 30/49, Loss: 0.2530
Epoch 8/10, Batch 40/49, Loss: 0.2795
Epoch 8/10, Train Loss: 0.2693, Valid Loss: 0.2692
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2576
Epoch 9/10, Batch 20/49, Loss: 0.1504
Epoch 9/10, Batch 30/49, Loss: 0.3184
Epoch 9/10, Batch 40/49, Loss: 0.3153
Epoch 9/10, Train Loss: 0.2497, Valid Loss: 0.2638
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2954
Epoch 10/10, Batch 20/49, Loss: 0.2827
Epoch 10/10, Batch 30/49, Loss: 0.1776
Epoch 10/10, Batch 40/49, Loss: 0.2828
Epoch 10/10, Train Loss: 0.2261, Valid Loss: 0.2646
Accuracy: 0.9007
Precision: 0.8980
Recall: 0.9007
F1-score: 0.8970
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1749
Epoch 1/10, Batch 20/49, Loss: 1.1237
Epoch 1/10, Batch 30/49, Loss: 0.8229
Epoch 1/10, Batch 40/49, Loss: 0.7363
Epoch 1/10, Train Loss: 1.0040, Valid Loss: 0.6094
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6185
Epoch 2/10, Batch 20/49, Loss: 0.7048
Epoch 2/10, Batch 30/49, Loss: 0.5934
Epoch 2/10, Batch 40/49, Loss: 0.4947
Epoch 2/10, Train Loss: 0.5388, Valid Loss: 0.4213
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4407
Epoch 3/10, Batch 20/49, Loss: 0.3639
Epoch 3/10, Batch 30/49, Loss: 0.4456
Epoch 3/10, Batch 40/49, Loss: 0.4530
Epoch 3/10, Train Loss: 0.4118, Valid Loss: 0.3718
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2461
Epoch 4/10, Batch 20/49, Loss: 0.3707
Epoch 4/10, Batch 30/49, Loss: 0.3791
Epoch 4/10, Batch 40/49, Loss: 0.4182
Epoch 4/10, Train Loss: 0.3389, Valid Loss: 0.3277
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3498
Epoch 5/10, Batch 20/49, Loss: 0.2768
Epoch 5/10, Batch 30/49, Loss: 0.2553
Epoch 5/10, Batch 40/49, Loss: 0.3753
Epoch 5/10, Train Loss: 0.3072, Valid Loss: 0.3050
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3450
Epoch 6/10, Batch 20/49, Loss: 0.2168
Epoch 6/10, Batch 30/49, Loss: 0.2215
Epoch 6/10, Batch 40/49, Loss: 0.2503
Epoch 6/10, Train Loss: 0.2747, Valid Loss: 0.2862
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2118
Epoch 7/10, Batch 20/49, Loss: 0.4245
Epoch 7/10, Batch 30/49, Loss: 0.2379
Epoch 7/10, Batch 40/49, Loss: 0.0851
Epoch 7/10, Train Loss: 0.2434, Valid Loss: 0.2823
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1799
Epoch 8/10, Batch 20/49, Loss: 0.2008
Epoch 8/10, Batch 30/49, Loss: 0.2080
Epoch 8/10, Batch 40/49, Loss: 0.2715
Epoch 8/10, Train Loss: 0.2358, Valid Loss: 0.2758
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1416
Epoch 9/10, Batch 20/49, Loss: 0.1065
Epoch 9/10, Batch 30/49, Loss: 0.2591
Epoch 9/10, Batch 40/49, Loss: 0.2077
Epoch 9/10, Train Loss: 0.2271, Valid Loss: 0.2596
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2016
Epoch 10/10, Batch 20/49, Loss: 0.2642
Epoch 10/10, Batch 30/49, Loss: 0.1968
Epoch 10/10, Batch 40/49, Loss: 0.2029
Epoch 10/10, Train Loss: 0.2099, Valid Loss: 0.2573
Model saved!
Accuracy: 0.9136
Precision: 0.9118
Recall: 0.9136
F1-score: 0.9116
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2000
Epoch 1/10, Batch 20/49, Loss: 1.1959
Epoch 1/10, Batch 30/49, Loss: 0.8739
Epoch 1/10, Batch 40/49, Loss: 0.8353
Epoch 1/10, Train Loss: 0.9822, Valid Loss: 0.6140
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.4667
Epoch 2/10, Batch 20/49, Loss: 0.5250
Epoch 2/10, Batch 30/49, Loss: 0.4663
Epoch 2/10, Batch 40/49, Loss: 0.3828
Epoch 2/10, Train Loss: 0.5190, Valid Loss: 0.4444
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4095
Epoch 3/10, Batch 20/49, Loss: 0.3723
Epoch 3/10, Batch 30/49, Loss: 0.3749
Epoch 3/10, Batch 40/49, Loss: 0.4304
Epoch 3/10, Train Loss: 0.3971, Valid Loss: 0.4028
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3216
Epoch 4/10, Batch 20/49, Loss: 0.3697
Epoch 4/10, Batch 30/49, Loss: 0.3841
Epoch 4/10, Batch 40/49, Loss: 0.3735
Epoch 4/10, Train Loss: 0.3400, Valid Loss: 0.3674
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2865
Epoch 5/10, Batch 20/49, Loss: 0.2471
Epoch 5/10, Batch 30/49, Loss: 0.1426
Epoch 5/10, Batch 40/49, Loss: 0.2239
Epoch 5/10, Train Loss: 0.2962, Valid Loss: 0.3377
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1878
Epoch 6/10, Batch 20/49, Loss: 0.2205
Epoch 6/10, Batch 30/49, Loss: 0.2265
Epoch 6/10, Batch 40/49, Loss: 0.3352
Epoch 6/10, Train Loss: 0.2737, Valid Loss: 0.3298
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3048
Epoch 7/10, Batch 20/49, Loss: 0.2631
Epoch 7/10, Batch 30/49, Loss: 0.2400
Epoch 7/10, Batch 40/49, Loss: 0.1907
Epoch 7/10, Train Loss: 0.2352, Valid Loss: 0.3307
Epoch 8/10, Batch 10/49, Loss: 0.2754
Epoch 8/10, Batch 20/49, Loss: 0.2896
Epoch 8/10, Batch 30/49, Loss: 0.1920
Epoch 8/10, Batch 40/49, Loss: 0.2000
Epoch 8/10, Train Loss: 0.2283, Valid Loss: 0.3174
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2951
Epoch 9/10, Batch 20/49, Loss: 0.1866
Epoch 9/10, Batch 30/49, Loss: 0.2588
Epoch 9/10, Batch 40/49, Loss: 0.3035
Epoch 9/10, Train Loss: 0.2193, Valid Loss: 0.3145
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1931
Epoch 10/10, Batch 20/49, Loss: 0.2477
Epoch 10/10, Batch 30/49, Loss: 0.1129
Epoch 10/10, Batch 40/49, Loss: 0.1811
Epoch 10/10, Train Loss: 0.2007, Valid Loss: 0.3100
Model saved!
Accuracy: 0.9089
Precision: 0.9076
Recall: 0.9089
F1-score: 0.9049
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2323
Epoch 1/10, Batch 20/49, Loss: 1.1493
Epoch 1/10, Batch 30/49, Loss: 0.7894
Epoch 1/10, Batch 40/49, Loss: 0.8224
Epoch 1/10, Train Loss: 1.0307, Valid Loss: 0.6435
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5070
Epoch 2/10, Batch 20/49, Loss: 0.6949
Epoch 2/10, Batch 30/49, Loss: 0.4061
Epoch 2/10, Batch 40/49, Loss: 0.5061
Epoch 2/10, Train Loss: 0.5683, Valid Loss: 0.4255
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4186
Epoch 3/10, Batch 20/49, Loss: 0.4330
Epoch 3/10, Batch 30/49, Loss: 0.4306
Epoch 3/10, Batch 40/49, Loss: 0.3342
Epoch 3/10, Train Loss: 0.4433, Valid Loss: 0.3603
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2812
Epoch 4/10, Batch 20/49, Loss: 0.3406
Epoch 4/10, Batch 30/49, Loss: 0.3537
Epoch 4/10, Batch 40/49, Loss: 0.4197
Epoch 4/10, Train Loss: 0.3878, Valid Loss: 0.3176
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3660
Epoch 5/10, Batch 20/49, Loss: 0.3281
Epoch 5/10, Batch 30/49, Loss: 0.2673
Epoch 5/10, Batch 40/49, Loss: 0.2431
Epoch 5/10, Train Loss: 0.3401, Valid Loss: 0.2807
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.4246
Epoch 6/10, Batch 20/49, Loss: 0.1384
Epoch 6/10, Batch 30/49, Loss: 0.2882
Epoch 6/10, Batch 40/49, Loss: 0.3043
Epoch 6/10, Train Loss: 0.3176, Valid Loss: 0.2795
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2355
Epoch 7/10, Batch 20/49, Loss: 0.2795
Epoch 7/10, Batch 30/49, Loss: 0.2674
Epoch 7/10, Batch 40/49, Loss: 0.2254
Epoch 7/10, Train Loss: 0.2733, Valid Loss: 0.2637
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2611
Epoch 8/10, Batch 20/49, Loss: 0.2792
Epoch 8/10, Batch 30/49, Loss: 0.1875
Epoch 8/10, Batch 40/49, Loss: 0.1712
Epoch 8/10, Train Loss: 0.2733, Valid Loss: 0.2516
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1471
Epoch 9/10, Batch 20/49, Loss: 0.1828
Epoch 9/10, Batch 30/49, Loss: 0.3320
Epoch 9/10, Batch 40/49, Loss: 0.2947
Epoch 9/10, Train Loss: 0.2497, Valid Loss: 0.2458
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2872
Epoch 10/10, Batch 20/49, Loss: 0.1961
Epoch 10/10, Batch 30/49, Loss: 0.1793
Epoch 10/10, Batch 40/49, Loss: 0.2457
Epoch 10/10, Train Loss: 0.2293, Valid Loss: 0.2461
Accuracy: 0.9019
Precision: 0.8990
Recall: 0.9019
F1-score: 0.8965
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2173
Epoch 1/10, Batch 20/49, Loss: 1.1648
Epoch 1/10, Batch 30/49, Loss: 0.8122
Epoch 1/10, Batch 40/49, Loss: 0.8688
Epoch 1/10, Train Loss: 1.0311, Valid Loss: 0.5960
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6009
Epoch 2/10, Batch 20/49, Loss: 0.6253
Epoch 2/10, Batch 30/49, Loss: 0.5434
Epoch 2/10, Batch 40/49, Loss: 0.4165
Epoch 2/10, Train Loss: 0.5568, Valid Loss: 0.4060
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4704
Epoch 3/10, Batch 20/49, Loss: 0.3684
Epoch 3/10, Batch 30/49, Loss: 0.4566
Epoch 3/10, Batch 40/49, Loss: 0.3811
Epoch 3/10, Train Loss: 0.4114, Valid Loss: 0.3527
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3994
Epoch 4/10, Batch 20/49, Loss: 0.3317
Epoch 4/10, Batch 30/49, Loss: 0.3271
Epoch 4/10, Batch 40/49, Loss: 0.3991
Epoch 4/10, Train Loss: 0.3665, Valid Loss: 0.3122
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3481
Epoch 5/10, Batch 20/49, Loss: 0.1990
Epoch 5/10, Batch 30/49, Loss: 0.2408
Epoch 5/10, Batch 40/49, Loss: 0.3139
Epoch 5/10, Train Loss: 0.3223, Valid Loss: 0.2921
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2282
Epoch 6/10, Batch 20/49, Loss: 0.2162
Epoch 6/10, Batch 30/49, Loss: 0.1794
Epoch 6/10, Batch 40/49, Loss: 0.2879
Epoch 6/10, Train Loss: 0.2987, Valid Loss: 0.2774
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2400
Epoch 7/10, Batch 20/49, Loss: 0.2141
Epoch 7/10, Batch 30/49, Loss: 0.3944
Epoch 7/10, Batch 40/49, Loss: 0.3055
Epoch 7/10, Train Loss: 0.2603, Valid Loss: 0.2869
Epoch 8/10, Batch 10/49, Loss: 0.1818
Epoch 8/10, Batch 20/49, Loss: 0.1513
Epoch 8/10, Batch 30/49, Loss: 0.1311
Epoch 8/10, Batch 40/49, Loss: 0.1556
Epoch 8/10, Train Loss: 0.2529, Valid Loss: 0.2704
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1662
Epoch 9/10, Batch 20/49, Loss: 0.1271
Epoch 9/10, Batch 30/49, Loss: 0.3196
Epoch 9/10, Batch 40/49, Loss: 0.2719
Epoch 9/10, Train Loss: 0.2428, Valid Loss: 0.2599
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1259
Epoch 10/10, Batch 20/49, Loss: 0.1725
Epoch 10/10, Batch 30/49, Loss: 0.1201
Epoch 10/10, Batch 40/49, Loss: 0.1924
Epoch 10/10, Train Loss: 0.2180, Valid Loss: 0.2634
Accuracy: 0.8995
Precision: 0.8949
Recall: 0.8995
F1-score: 0.8961
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2589
Epoch 1/10, Batch 20/49, Loss: 1.1619
Epoch 1/10, Batch 30/49, Loss: 0.8564
Epoch 1/10, Batch 40/49, Loss: 0.7968
Epoch 1/10, Train Loss: 1.0011, Valid Loss: 0.6450
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5686
Epoch 2/10, Batch 20/49, Loss: 0.6059
Epoch 2/10, Batch 30/49, Loss: 0.4782
Epoch 2/10, Batch 40/49, Loss: 0.4621
Epoch 2/10, Train Loss: 0.5404, Valid Loss: 0.4730
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3823
Epoch 3/10, Batch 20/49, Loss: 0.3020
Epoch 3/10, Batch 30/49, Loss: 0.3499
Epoch 3/10, Batch 40/49, Loss: 0.2503
Epoch 3/10, Train Loss: 0.4153, Valid Loss: 0.4128
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3095
Epoch 4/10, Batch 20/49, Loss: 0.3428
Epoch 4/10, Batch 30/49, Loss: 0.3600
Epoch 4/10, Batch 40/49, Loss: 0.4705
Epoch 4/10, Train Loss: 0.3619, Valid Loss: 0.3651
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5096
Epoch 5/10, Batch 20/49, Loss: 0.4710
Epoch 5/10, Batch 30/49, Loss: 0.3265
Epoch 5/10, Batch 40/49, Loss: 0.2279
Epoch 5/10, Train Loss: 0.3140, Valid Loss: 0.3537
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1957
Epoch 6/10, Batch 20/49, Loss: 0.3305
Epoch 6/10, Batch 30/49, Loss: 0.3071
Epoch 6/10, Batch 40/49, Loss: 0.3493
Epoch 6/10, Train Loss: 0.2865, Valid Loss: 0.3143
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2980
Epoch 7/10, Batch 20/49, Loss: 0.1891
Epoch 7/10, Batch 30/49, Loss: 0.2682
Epoch 7/10, Batch 40/49, Loss: 0.1877
Epoch 7/10, Train Loss: 0.2641, Valid Loss: 0.3319
Epoch 8/10, Batch 10/49, Loss: 0.2091
Epoch 8/10, Batch 20/49, Loss: 0.2607
Epoch 8/10, Batch 30/49, Loss: 0.1554
Epoch 8/10, Batch 40/49, Loss: 0.2879
Epoch 8/10, Train Loss: 0.2482, Valid Loss: 0.3014
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.4104
Epoch 9/10, Batch 20/49, Loss: 0.1865
Epoch 9/10, Batch 30/49, Loss: 0.2345
Epoch 9/10, Batch 40/49, Loss: 0.4587
Epoch 9/10, Train Loss: 0.2326, Valid Loss: 0.3031
Epoch 10/10, Batch 10/49, Loss: 0.2024
Epoch 10/10, Batch 20/49, Loss: 0.1468
Epoch 10/10, Batch 30/49, Loss: 0.1834
Epoch 10/10, Batch 40/49, Loss: 0.1515
Epoch 10/10, Train Loss: 0.2203, Valid Loss: 0.3058
Accuracy: 0.8937
Precision: 0.8901
Recall: 0.8937
F1-score: 0.8887
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2318
Epoch 1/10, Batch 20/49, Loss: 1.1515
Epoch 1/10, Batch 30/49, Loss: 0.8660
Epoch 1/10, Batch 40/49, Loss: 0.8118
Epoch 1/10, Train Loss: 1.0261, Valid Loss: 0.6266
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6378
Epoch 2/10, Batch 20/49, Loss: 0.6851
Epoch 2/10, Batch 30/49, Loss: 0.5557
Epoch 2/10, Batch 40/49, Loss: 0.5170
Epoch 2/10, Train Loss: 0.5570, Valid Loss: 0.4334
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3777
Epoch 3/10, Batch 20/49, Loss: 0.4449
Epoch 3/10, Batch 30/49, Loss: 0.3927
Epoch 3/10, Batch 40/49, Loss: 0.4178
Epoch 3/10, Train Loss: 0.4303, Valid Loss: 0.3697
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3573
Epoch 4/10, Batch 20/49, Loss: 0.3183
Epoch 4/10, Batch 30/49, Loss: 0.3548
Epoch 4/10, Batch 40/49, Loss: 0.2883
Epoch 4/10, Train Loss: 0.3830, Valid Loss: 0.3342
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5631
Epoch 5/10, Batch 20/49, Loss: 0.2525
Epoch 5/10, Batch 30/49, Loss: 0.2221
Epoch 5/10, Batch 40/49, Loss: 0.1849
Epoch 5/10, Train Loss: 0.3308, Valid Loss: 0.3013
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2810
Epoch 6/10, Batch 20/49, Loss: 0.2210
Epoch 6/10, Batch 30/49, Loss: 0.2529
Epoch 6/10, Batch 40/49, Loss: 0.2557
Epoch 6/10, Train Loss: 0.3025, Valid Loss: 0.2826
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1640
Epoch 7/10, Batch 20/49, Loss: 0.3402
Epoch 7/10, Batch 30/49, Loss: 0.2105
Epoch 7/10, Batch 40/49, Loss: 0.1699
Epoch 7/10, Train Loss: 0.2707, Valid Loss: 0.2812
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3868
Epoch 8/10, Batch 20/49, Loss: 0.3047
Epoch 8/10, Batch 30/49, Loss: 0.2657
Epoch 8/10, Batch 40/49, Loss: 0.2155
Epoch 8/10, Train Loss: 0.2647, Valid Loss: 0.2625
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3090
Epoch 9/10, Batch 20/49, Loss: 0.2898
Epoch 9/10, Batch 30/49, Loss: 0.2999
Epoch 9/10, Batch 40/49, Loss: 0.3935
Epoch 9/10, Train Loss: 0.2536, Valid Loss: 0.2609
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3902
Epoch 10/10, Batch 20/49, Loss: 0.2294
Epoch 10/10, Batch 30/49, Loss: 0.1391
Epoch 10/10, Batch 40/49, Loss: 0.2720
Epoch 10/10, Train Loss: 0.2255, Valid Loss: 0.2518
Model saved!
Accuracy: 0.9007
Precision: 0.8983
Recall: 0.9007
F1-score: 0.8980
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1944
Epoch 1/10, Batch 20/49, Loss: 1.1060
Epoch 1/10, Batch 30/49, Loss: 0.7781
Epoch 1/10, Batch 40/49, Loss: 0.7539
Epoch 1/10, Train Loss: 0.9952, Valid Loss: 0.6620
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7563
Epoch 2/10, Batch 20/49, Loss: 0.7955
Epoch 2/10, Batch 30/49, Loss: 0.4991
Epoch 2/10, Batch 40/49, Loss: 0.4171
Epoch 2/10, Train Loss: 0.5324, Valid Loss: 0.4918
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4843
Epoch 3/10, Batch 20/49, Loss: 0.3270
Epoch 3/10, Batch 30/49, Loss: 0.4573
Epoch 3/10, Batch 40/49, Loss: 0.3956
Epoch 3/10, Train Loss: 0.4099, Valid Loss: 0.4446
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3097
Epoch 4/10, Batch 20/49, Loss: 0.4171
Epoch 4/10, Batch 30/49, Loss: 0.3041
Epoch 4/10, Batch 40/49, Loss: 0.4154
Epoch 4/10, Train Loss: 0.3571, Valid Loss: 0.3877
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3587
Epoch 5/10, Batch 20/49, Loss: 0.2710
Epoch 5/10, Batch 30/49, Loss: 0.2844
Epoch 5/10, Batch 40/49, Loss: 0.2570
Epoch 5/10, Train Loss: 0.3099, Valid Loss: 0.3635
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2846
Epoch 6/10, Batch 20/49, Loss: 0.1942
Epoch 6/10, Batch 30/49, Loss: 0.3140
Epoch 6/10, Batch 40/49, Loss: 0.1523
Epoch 6/10, Train Loss: 0.2815, Valid Loss: 0.3596
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2839
Epoch 7/10, Batch 20/49, Loss: 0.2335
Epoch 7/10, Batch 30/49, Loss: 0.2062
Epoch 7/10, Batch 40/49, Loss: 0.1557
Epoch 7/10, Train Loss: 0.2615, Valid Loss: 0.3564
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2584
Epoch 8/10, Batch 20/49, Loss: 0.1880
Epoch 8/10, Batch 30/49, Loss: 0.1726
Epoch 8/10, Batch 40/49, Loss: 0.1702
Epoch 8/10, Train Loss: 0.2542, Valid Loss: 0.3519
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2584
Epoch 9/10, Batch 20/49, Loss: 0.1681
Epoch 9/10, Batch 30/49, Loss: 0.2455
Epoch 9/10, Batch 40/49, Loss: 0.4318
Epoch 9/10, Train Loss: 0.2361, Valid Loss: 0.3422
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2715
Epoch 10/10, Batch 20/49, Loss: 0.1898
Epoch 10/10, Batch 30/49, Loss: 0.2328
Epoch 10/10, Batch 40/49, Loss: 0.2652
Epoch 10/10, Train Loss: 0.2149, Valid Loss: 0.3405
Model saved!
Accuracy: 0.8995
Precision: 0.8959
Recall: 0.8995
F1-score: 0.8954
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1957
Epoch 1/10, Batch 20/49, Loss: 1.0345
Epoch 1/10, Batch 30/49, Loss: 0.8607
Epoch 1/10, Batch 40/49, Loss: 0.7276
Epoch 1/10, Train Loss: 1.0259, Valid Loss: 0.6273
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6461
Epoch 2/10, Batch 20/49, Loss: 0.6634
Epoch 2/10, Batch 30/49, Loss: 0.4867
Epoch 2/10, Batch 40/49, Loss: 0.5730
Epoch 2/10, Train Loss: 0.5570, Valid Loss: 0.4211
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3720
Epoch 3/10, Batch 20/49, Loss: 0.2791
Epoch 3/10, Batch 30/49, Loss: 0.3558
Epoch 3/10, Batch 40/49, Loss: 0.4663
Epoch 3/10, Train Loss: 0.4124, Valid Loss: 0.3676
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3021
Epoch 4/10, Batch 20/49, Loss: 0.3401
Epoch 4/10, Batch 30/49, Loss: 0.3551
Epoch 4/10, Batch 40/49, Loss: 0.3462
Epoch 4/10, Train Loss: 0.3639, Valid Loss: 0.3191
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5292
Epoch 5/10, Batch 20/49, Loss: 0.3895
Epoch 5/10, Batch 30/49, Loss: 0.3243
Epoch 5/10, Batch 40/49, Loss: 0.3028
Epoch 5/10, Train Loss: 0.3327, Valid Loss: 0.2884
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2108
Epoch 6/10, Batch 20/49, Loss: 0.2275
Epoch 6/10, Batch 30/49, Loss: 0.2013
Epoch 6/10, Batch 40/49, Loss: 0.3298
Epoch 6/10, Train Loss: 0.3016, Valid Loss: 0.2672
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1689
Epoch 7/10, Batch 20/49, Loss: 0.2339
Epoch 7/10, Batch 30/49, Loss: 0.2001
Epoch 7/10, Batch 40/49, Loss: 0.2171
Epoch 7/10, Train Loss: 0.2619, Valid Loss: 0.2653
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2576
Epoch 8/10, Batch 20/49, Loss: 0.1888
Epoch 8/10, Batch 30/49, Loss: 0.1580
Epoch 8/10, Batch 40/49, Loss: 0.2964
Epoch 8/10, Train Loss: 0.2585, Valid Loss: 0.2665
Epoch 9/10, Batch 10/49, Loss: 0.3598
Epoch 9/10, Batch 20/49, Loss: 0.0935
Epoch 9/10, Batch 30/49, Loss: 0.2861
Epoch 9/10, Batch 40/49, Loss: 0.2288
Epoch 9/10, Train Loss: 0.2396, Valid Loss: 0.2440
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2913
Epoch 10/10, Batch 20/49, Loss: 0.1827
Epoch 10/10, Batch 30/49, Loss: 0.1479
Epoch 10/10, Batch 40/49, Loss: 0.3577
Epoch 10/10, Train Loss: 0.2294, Valid Loss: 0.2354
Model saved!
Accuracy: 0.9030
Precision: 0.9006
Recall: 0.9030
F1-score: 0.9002
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2154
Epoch 1/10, Batch 20/49, Loss: 0.9948
Epoch 1/10, Batch 30/49, Loss: 0.8201
Epoch 1/10, Batch 40/49, Loss: 0.7720
Epoch 1/10, Train Loss: 1.0029, Valid Loss: 0.6023
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6145
Epoch 2/10, Batch 20/49, Loss: 0.6313
Epoch 2/10, Batch 30/49, Loss: 0.5094
Epoch 2/10, Batch 40/49, Loss: 0.4720
Epoch 2/10, Train Loss: 0.5457, Valid Loss: 0.4073
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4110
Epoch 3/10, Batch 20/49, Loss: 0.3623
Epoch 3/10, Batch 30/49, Loss: 0.4063
Epoch 3/10, Batch 40/49, Loss: 0.3684
Epoch 3/10, Train Loss: 0.4071, Valid Loss: 0.3382
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3053
Epoch 4/10, Batch 20/49, Loss: 0.3174
Epoch 4/10, Batch 30/49, Loss: 0.3291
Epoch 4/10, Batch 40/49, Loss: 0.3938
Epoch 4/10, Train Loss: 0.3572, Valid Loss: 0.3041
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5569
Epoch 5/10, Batch 20/49, Loss: 0.1646
Epoch 5/10, Batch 30/49, Loss: 0.2909
Epoch 5/10, Batch 40/49, Loss: 0.2395
Epoch 5/10, Train Loss: 0.3263, Valid Loss: 0.2729
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2635
Epoch 6/10, Batch 20/49, Loss: 0.1734
Epoch 6/10, Batch 30/49, Loss: 0.2555
Epoch 6/10, Batch 40/49, Loss: 0.3467
Epoch 6/10, Train Loss: 0.2919, Valid Loss: 0.2566
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2384
Epoch 7/10, Batch 20/49, Loss: 0.3583
Epoch 7/10, Batch 30/49, Loss: 0.1799
Epoch 7/10, Batch 40/49, Loss: 0.1375
Epoch 7/10, Train Loss: 0.2611, Valid Loss: 0.2537
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3037
Epoch 8/10, Batch 20/49, Loss: 0.1803
Epoch 8/10, Batch 30/49, Loss: 0.2510
Epoch 8/10, Batch 40/49, Loss: 0.2108
Epoch 8/10, Train Loss: 0.2452, Valid Loss: 0.2515
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2491
Epoch 9/10, Batch 20/49, Loss: 0.1536
Epoch 9/10, Batch 30/49, Loss: 0.3923
Epoch 9/10, Batch 40/49, Loss: 0.2751
Epoch 9/10, Train Loss: 0.2403, Valid Loss: 0.2285
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2851
Epoch 10/10, Batch 20/49, Loss: 0.2555
Epoch 10/10, Batch 30/49, Loss: 0.3420
Epoch 10/10, Batch 40/49, Loss: 0.2436
Epoch 10/10, Train Loss: 0.2198, Valid Loss: 0.2269
Model saved!
Accuracy: 0.9089
Precision: 0.9061
Recall: 0.9089
F1-score: 0.9059
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2397
Epoch 1/10, Batch 20/49, Loss: 1.1563
Epoch 1/10, Batch 30/49, Loss: 0.9154
Epoch 1/10, Batch 40/49, Loss: 0.8368
Epoch 1/10, Train Loss: 1.0125, Valid Loss: 0.5995
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5163
Epoch 2/10, Batch 20/49, Loss: 0.5999
Epoch 2/10, Batch 30/49, Loss: 0.4857
Epoch 2/10, Batch 40/49, Loss: 0.4654
Epoch 2/10, Train Loss: 0.5380, Valid Loss: 0.4211
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4153
Epoch 3/10, Batch 20/49, Loss: 0.2908
Epoch 3/10, Batch 30/49, Loss: 0.3692
Epoch 3/10, Batch 40/49, Loss: 0.5746
Epoch 3/10, Train Loss: 0.4145, Valid Loss: 0.3514
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3017
Epoch 4/10, Batch 20/49, Loss: 0.6010
Epoch 4/10, Batch 30/49, Loss: 0.3902
Epoch 4/10, Batch 40/49, Loss: 0.3934
Epoch 4/10, Train Loss: 0.3682, Valid Loss: 0.3114
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4178
Epoch 5/10, Batch 20/49, Loss: 0.2458
Epoch 5/10, Batch 30/49, Loss: 0.1749
Epoch 5/10, Batch 40/49, Loss: 0.4043
Epoch 5/10, Train Loss: 0.3251, Valid Loss: 0.2870
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2755
Epoch 6/10, Batch 20/49, Loss: 0.1391
Epoch 6/10, Batch 30/49, Loss: 0.2528
Epoch 6/10, Batch 40/49, Loss: 0.3255
Epoch 6/10, Train Loss: 0.2958, Valid Loss: 0.2800
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3509
Epoch 7/10, Batch 20/49, Loss: 0.3351
Epoch 7/10, Batch 30/49, Loss: 0.3315
Epoch 7/10, Batch 40/49, Loss: 0.1782
Epoch 7/10, Train Loss: 0.2672, Valid Loss: 0.2991
Epoch 8/10, Batch 10/49, Loss: 0.2421
Epoch 8/10, Batch 20/49, Loss: 0.1503
Epoch 8/10, Batch 30/49, Loss: 0.3307
Epoch 8/10, Batch 40/49, Loss: 0.1764
Epoch 8/10, Train Loss: 0.2590, Valid Loss: 0.2739
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2064
Epoch 9/10, Batch 20/49, Loss: 0.2005
Epoch 9/10, Batch 30/49, Loss: 0.2674
Epoch 9/10, Batch 40/49, Loss: 0.3121
Epoch 9/10, Train Loss: 0.2320, Valid Loss: 0.2643
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1781
Epoch 10/10, Batch 20/49, Loss: 0.3054
Epoch 10/10, Batch 30/49, Loss: 0.1634
Epoch 10/10, Batch 40/49, Loss: 0.1471
Epoch 10/10, Train Loss: 0.2232, Valid Loss: 0.2699
Accuracy: 0.9077
Precision: 0.9035
Recall: 0.9077
F1-score: 0.9034
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1999
Epoch 1/10, Batch 20/49, Loss: 1.1342
Epoch 1/10, Batch 30/49, Loss: 0.8693
Epoch 1/10, Batch 40/49, Loss: 0.8415
Epoch 1/10, Train Loss: 1.0126, Valid Loss: 0.6573
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6528
Epoch 2/10, Batch 20/49, Loss: 0.6932
Epoch 2/10, Batch 30/49, Loss: 0.4671
Epoch 2/10, Batch 40/49, Loss: 0.3876
Epoch 2/10, Train Loss: 0.5477, Valid Loss: 0.4792
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4740
Epoch 3/10, Batch 20/49, Loss: 0.5628
Epoch 3/10, Batch 30/49, Loss: 0.4384
Epoch 3/10, Batch 40/49, Loss: 0.3152
Epoch 3/10, Train Loss: 0.4265, Valid Loss: 0.4200
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3500
Epoch 4/10, Batch 20/49, Loss: 0.3956
Epoch 4/10, Batch 30/49, Loss: 0.2962
Epoch 4/10, Batch 40/49, Loss: 0.5037
Epoch 4/10, Train Loss: 0.3753, Valid Loss: 0.3627
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4811
Epoch 5/10, Batch 20/49, Loss: 0.2441
Epoch 5/10, Batch 30/49, Loss: 0.2921
Epoch 5/10, Batch 40/49, Loss: 0.3107
Epoch 5/10, Train Loss: 0.3336, Valid Loss: 0.3336
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3587
Epoch 6/10, Batch 20/49, Loss: 0.3124
Epoch 6/10, Batch 30/49, Loss: 0.4162
Epoch 6/10, Batch 40/49, Loss: 0.3332
Epoch 6/10, Train Loss: 0.2995, Valid Loss: 0.3196
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3306
Epoch 7/10, Batch 20/49, Loss: 0.3676
Epoch 7/10, Batch 30/49, Loss: 0.2178
Epoch 7/10, Batch 40/49, Loss: 0.1549
Epoch 7/10, Train Loss: 0.2735, Valid Loss: 0.3113
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2428
Epoch 8/10, Batch 20/49, Loss: 0.1412
Epoch 8/10, Batch 30/49, Loss: 0.2766
Epoch 8/10, Batch 40/49, Loss: 0.2246
Epoch 8/10, Train Loss: 0.2570, Valid Loss: 0.3017
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2738
Epoch 9/10, Batch 20/49, Loss: 0.1926
Epoch 9/10, Batch 30/49, Loss: 0.3373
Epoch 9/10, Batch 40/49, Loss: 0.3522
Epoch 9/10, Train Loss: 0.2509, Valid Loss: 0.2895
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.4196
Epoch 10/10, Batch 20/49, Loss: 0.1522
Epoch 10/10, Batch 30/49, Loss: 0.2344
Epoch 10/10, Batch 40/49, Loss: 0.2913
Epoch 10/10, Train Loss: 0.2411, Valid Loss: 0.2837
Model saved!
Accuracy: 0.9007
Precision: 0.8992
Recall: 0.9007
F1-score: 0.8964
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2409
Epoch 1/10, Batch 20/49, Loss: 1.1373
Epoch 1/10, Batch 30/49, Loss: 0.8763
Epoch 1/10, Batch 40/49, Loss: 0.8113
Epoch 1/10, Train Loss: 1.0227, Valid Loss: 0.6154
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5651
Epoch 2/10, Batch 20/49, Loss: 0.6765
Epoch 2/10, Batch 30/49, Loss: 0.4839
Epoch 2/10, Batch 40/49, Loss: 0.4800
Epoch 2/10, Train Loss: 0.5715, Valid Loss: 0.4125
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4302
Epoch 3/10, Batch 20/49, Loss: 0.3373
Epoch 3/10, Batch 30/49, Loss: 0.4339
Epoch 3/10, Batch 40/49, Loss: 0.3009
Epoch 3/10, Train Loss: 0.4284, Valid Loss: 0.3598
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2606
Epoch 4/10, Batch 20/49, Loss: 0.3906
Epoch 4/10, Batch 30/49, Loss: 0.3283
Epoch 4/10, Batch 40/49, Loss: 0.4576
Epoch 4/10, Train Loss: 0.3778, Valid Loss: 0.3020
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3401
Epoch 5/10, Batch 20/49, Loss: 0.1921
Epoch 5/10, Batch 30/49, Loss: 0.2233
Epoch 5/10, Batch 40/49, Loss: 0.2238
Epoch 5/10, Train Loss: 0.3370, Valid Loss: 0.2726
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2188
Epoch 6/10, Batch 20/49, Loss: 0.2828
Epoch 6/10, Batch 30/49, Loss: 0.2533
Epoch 6/10, Batch 40/49, Loss: 0.3744
Epoch 6/10, Train Loss: 0.3007, Valid Loss: 0.2561
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2549
Epoch 7/10, Batch 20/49, Loss: 0.4295
Epoch 7/10, Batch 30/49, Loss: 0.3275
Epoch 7/10, Batch 40/49, Loss: 0.1475
Epoch 7/10, Train Loss: 0.2751, Valid Loss: 0.2599
Epoch 8/10, Batch 10/49, Loss: 0.3567
Epoch 8/10, Batch 20/49, Loss: 0.2288
Epoch 8/10, Batch 30/49, Loss: 0.1517
Epoch 8/10, Batch 40/49, Loss: 0.2100
Epoch 8/10, Train Loss: 0.2589, Valid Loss: 0.2420
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2190
Epoch 9/10, Batch 20/49, Loss: 0.2342
Epoch 9/10, Batch 30/49, Loss: 0.4004
Epoch 9/10, Batch 40/49, Loss: 0.3267
Epoch 9/10, Train Loss: 0.2444, Valid Loss: 0.2324
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3223
Epoch 10/10, Batch 20/49, Loss: 0.2790
Epoch 10/10, Batch 30/49, Loss: 0.2858
Epoch 10/10, Batch 40/49, Loss: 0.2763
Epoch 10/10, Train Loss: 0.2235, Valid Loss: 0.2271
Model saved!
Accuracy: 0.9100
Precision: 0.9081
Recall: 0.9100
F1-score: 0.9084
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1968
Epoch 1/10, Batch 20/49, Loss: 1.1254
Epoch 1/10, Batch 30/49, Loss: 0.8472
Epoch 1/10, Batch 40/49, Loss: 0.7499
Epoch 1/10, Train Loss: 0.9966, Valid Loss: 0.6182
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5325
Epoch 2/10, Batch 20/49, Loss: 0.5665
Epoch 2/10, Batch 30/49, Loss: 0.4806
Epoch 2/10, Batch 40/49, Loss: 0.3577
Epoch 2/10, Train Loss: 0.5386, Valid Loss: 0.4386
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4840
Epoch 3/10, Batch 20/49, Loss: 0.3060
Epoch 3/10, Batch 30/49, Loss: 0.3242
Epoch 3/10, Batch 40/49, Loss: 0.4102
Epoch 3/10, Train Loss: 0.3973, Valid Loss: 0.3805
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4218
Epoch 4/10, Batch 20/49, Loss: 0.2998
Epoch 4/10, Batch 30/49, Loss: 0.3435
Epoch 4/10, Batch 40/49, Loss: 0.4343
Epoch 4/10, Train Loss: 0.3509, Valid Loss: 0.3389
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4303
Epoch 5/10, Batch 20/49, Loss: 0.1392
Epoch 5/10, Batch 30/49, Loss: 0.2156
Epoch 5/10, Batch 40/49, Loss: 0.1748
Epoch 5/10, Train Loss: 0.3102, Valid Loss: 0.3227
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3486
Epoch 6/10, Batch 20/49, Loss: 0.1989
Epoch 6/10, Batch 30/49, Loss: 0.2184
Epoch 6/10, Batch 40/49, Loss: 0.2425
Epoch 6/10, Train Loss: 0.2733, Valid Loss: 0.3050
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3214
Epoch 7/10, Batch 20/49, Loss: 0.1730
Epoch 7/10, Batch 30/49, Loss: 0.2240
Epoch 7/10, Batch 40/49, Loss: 0.1289
Epoch 7/10, Train Loss: 0.2448, Valid Loss: 0.3010
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3446
Epoch 8/10, Batch 20/49, Loss: 0.2324
Epoch 8/10, Batch 30/49, Loss: 0.1644
Epoch 8/10, Batch 40/49, Loss: 0.1512
Epoch 8/10, Train Loss: 0.2433, Valid Loss: 0.2910
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1714
Epoch 9/10, Batch 20/49, Loss: 0.1482
Epoch 9/10, Batch 30/49, Loss: 0.3042
Epoch 9/10, Batch 40/49, Loss: 0.3566
Epoch 9/10, Train Loss: 0.2245, Valid Loss: 0.2814
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3350
Epoch 10/10, Batch 20/49, Loss: 0.1015
Epoch 10/10, Batch 30/49, Loss: 0.1669
Epoch 10/10, Batch 40/49, Loss: 0.1748
Epoch 10/10, Train Loss: 0.2097, Valid Loss: 0.2838
Accuracy: 0.8995
Precision: 0.8961
Recall: 0.8995
F1-score: 0.8963
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2372
Epoch 1/10, Batch 20/49, Loss: 1.0802
Epoch 1/10, Batch 30/49, Loss: 0.8800
Epoch 1/10, Batch 40/49, Loss: 0.7906
Epoch 1/10, Train Loss: 1.0152, Valid Loss: 0.6362
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5765
Epoch 2/10, Batch 20/49, Loss: 0.6006
Epoch 2/10, Batch 30/49, Loss: 0.4566
Epoch 2/10, Batch 40/49, Loss: 0.4184
Epoch 2/10, Train Loss: 0.5285, Valid Loss: 0.4343
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4994
Epoch 3/10, Batch 20/49, Loss: 0.2582
Epoch 3/10, Batch 30/49, Loss: 0.3994
Epoch 3/10, Batch 40/49, Loss: 0.3531
Epoch 3/10, Train Loss: 0.4005, Valid Loss: 0.3634
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3668
Epoch 4/10, Batch 20/49, Loss: 0.3255
Epoch 4/10, Batch 30/49, Loss: 0.2758
Epoch 4/10, Batch 40/49, Loss: 0.3558
Epoch 4/10, Train Loss: 0.3481, Valid Loss: 0.3238
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2807
Epoch 5/10, Batch 20/49, Loss: 0.1912
Epoch 5/10, Batch 30/49, Loss: 0.3501
Epoch 5/10, Batch 40/49, Loss: 0.2390
Epoch 5/10, Train Loss: 0.3081, Valid Loss: 0.2982
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1438
Epoch 6/10, Batch 20/49, Loss: 0.2223
Epoch 6/10, Batch 30/49, Loss: 0.2331
Epoch 6/10, Batch 40/49, Loss: 0.2740
Epoch 6/10, Train Loss: 0.2806, Valid Loss: 0.2801
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2233
Epoch 7/10, Batch 20/49, Loss: 0.2341
Epoch 7/10, Batch 30/49, Loss: 0.1996
Epoch 7/10, Batch 40/49, Loss: 0.2338
Epoch 7/10, Train Loss: 0.2484, Valid Loss: 0.2777
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2866
Epoch 8/10, Batch 20/49, Loss: 0.1238
Epoch 8/10, Batch 30/49, Loss: 0.2606
Epoch 8/10, Batch 40/49, Loss: 0.2449
Epoch 8/10, Train Loss: 0.2417, Valid Loss: 0.2701
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.4333
Epoch 9/10, Batch 20/49, Loss: 0.1103
Epoch 9/10, Batch 30/49, Loss: 0.2244
Epoch 9/10, Batch 40/49, Loss: 0.1612
Epoch 9/10, Train Loss: 0.2326, Valid Loss: 0.2513
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2595
Epoch 10/10, Batch 20/49, Loss: 0.1564
Epoch 10/10, Batch 30/49, Loss: 0.1124
Epoch 10/10, Batch 40/49, Loss: 0.1289
Epoch 10/10, Train Loss: 0.2086, Valid Loss: 0.2639
Accuracy: 0.9100
Precision: 0.9068
Recall: 0.9100
F1-score: 0.9061
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1970
Epoch 1/10, Batch 20/49, Loss: 1.0951
Epoch 1/10, Batch 30/49, Loss: 0.9122
Epoch 1/10, Batch 40/49, Loss: 0.7823
Epoch 1/10, Train Loss: 1.0161, Valid Loss: 0.6261
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7095
Epoch 2/10, Batch 20/49, Loss: 0.5883
Epoch 2/10, Batch 30/49, Loss: 0.4615
Epoch 2/10, Batch 40/49, Loss: 0.4061
Epoch 2/10, Train Loss: 0.5558, Valid Loss: 0.4297
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3680
Epoch 3/10, Batch 20/49, Loss: 0.4853
Epoch 3/10, Batch 30/49, Loss: 0.4765
Epoch 3/10, Batch 40/49, Loss: 0.5585
Epoch 3/10, Train Loss: 0.4340, Valid Loss: 0.3661
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2623
Epoch 4/10, Batch 20/49, Loss: 0.4521
Epoch 4/10, Batch 30/49, Loss: 0.3854
Epoch 4/10, Batch 40/49, Loss: 0.4823
Epoch 4/10, Train Loss: 0.3740, Valid Loss: 0.3294
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5104
Epoch 5/10, Batch 20/49, Loss: 0.2578
Epoch 5/10, Batch 30/49, Loss: 0.2872
Epoch 5/10, Batch 40/49, Loss: 0.2593
Epoch 5/10, Train Loss: 0.3474, Valid Loss: 0.3118
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3849
Epoch 6/10, Batch 20/49, Loss: 0.1966
Epoch 6/10, Batch 30/49, Loss: 0.2624
Epoch 6/10, Batch 40/49, Loss: 0.2849
Epoch 6/10, Train Loss: 0.3122, Valid Loss: 0.2915
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2822
Epoch 7/10, Batch 20/49, Loss: 0.4387
Epoch 7/10, Batch 30/49, Loss: 0.2882
Epoch 7/10, Batch 40/49, Loss: 0.1717
Epoch 7/10, Train Loss: 0.2705, Valid Loss: 0.2823
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2565
Epoch 8/10, Batch 20/49, Loss: 0.2791
Epoch 8/10, Batch 30/49, Loss: 0.1895
Epoch 8/10, Batch 40/49, Loss: 0.3173
Epoch 8/10, Train Loss: 0.2784, Valid Loss: 0.2783
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2820
Epoch 9/10, Batch 20/49, Loss: 0.1231
Epoch 9/10, Batch 30/49, Loss: 0.3361
Epoch 9/10, Batch 40/49, Loss: 0.2877
Epoch 9/10, Train Loss: 0.2614, Valid Loss: 0.2728
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2783
Epoch 10/10, Batch 20/49, Loss: 0.2061
Epoch 10/10, Batch 30/49, Loss: 0.1811
Epoch 10/10, Batch 40/49, Loss: 0.2247
Epoch 10/10, Train Loss: 0.2276, Valid Loss: 0.2681
Model saved!
Accuracy: 0.9077
Precision: 0.9049
Recall: 0.9077
F1-score: 0.9042
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2082
Epoch 1/10, Batch 20/49, Loss: 1.1807
Epoch 1/10, Batch 30/49, Loss: 0.8913
Epoch 1/10, Batch 40/49, Loss: 0.7272
Epoch 1/10, Train Loss: 1.0173, Valid Loss: 0.6275
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6205
Epoch 2/10, Batch 20/49, Loss: 0.5881
Epoch 2/10, Batch 30/49, Loss: 0.5897
Epoch 2/10, Batch 40/49, Loss: 0.4568
Epoch 2/10, Train Loss: 0.5571, Valid Loss: 0.4458
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3548
Epoch 3/10, Batch 20/49, Loss: 0.3384
Epoch 3/10, Batch 30/49, Loss: 0.3529
Epoch 3/10, Batch 40/49, Loss: 0.3014
Epoch 3/10, Train Loss: 0.4266, Valid Loss: 0.3809
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4711
Epoch 4/10, Batch 20/49, Loss: 0.3204
Epoch 4/10, Batch 30/49, Loss: 0.3618
Epoch 4/10, Batch 40/49, Loss: 0.3065
Epoch 4/10, Train Loss: 0.3784, Valid Loss: 0.3372
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4833
Epoch 5/10, Batch 20/49, Loss: 0.2292
Epoch 5/10, Batch 30/49, Loss: 0.2200
Epoch 5/10, Batch 40/49, Loss: 0.3432
Epoch 5/10, Train Loss: 0.3399, Valid Loss: 0.3212
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2471
Epoch 6/10, Batch 20/49, Loss: 0.2493
Epoch 6/10, Batch 30/49, Loss: 0.3191
Epoch 6/10, Batch 40/49, Loss: 0.2002
Epoch 6/10, Train Loss: 0.2998, Valid Loss: 0.2974
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2677
Epoch 7/10, Batch 20/49, Loss: 0.2994
Epoch 7/10, Batch 30/49, Loss: 0.2124
Epoch 7/10, Batch 40/49, Loss: 0.1321
Epoch 7/10, Train Loss: 0.2714, Valid Loss: 0.2929
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3844
Epoch 8/10, Batch 20/49, Loss: 0.2291
Epoch 8/10, Batch 30/49, Loss: 0.3555
Epoch 8/10, Batch 40/49, Loss: 0.3495
Epoch 8/10, Train Loss: 0.2688, Valid Loss: 0.2885
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1631
Epoch 9/10, Batch 20/49, Loss: 0.2620
Epoch 9/10, Batch 30/49, Loss: 0.3462
Epoch 9/10, Batch 40/49, Loss: 0.4571
Epoch 9/10, Train Loss: 0.2486, Valid Loss: 0.2779
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3652
Epoch 10/10, Batch 20/49, Loss: 0.2618
Epoch 10/10, Batch 30/49, Loss: 0.1419
Epoch 10/10, Batch 40/49, Loss: 0.2482
Epoch 10/10, Train Loss: 0.2292, Valid Loss: 0.2721
Model saved!
Accuracy: 0.9007
Precision: 0.8983
Recall: 0.9007
F1-score: 0.8975
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2337
Epoch 1/10, Batch 20/49, Loss: 1.1399
Epoch 1/10, Batch 30/49, Loss: 0.8963
Epoch 1/10, Batch 40/49, Loss: 0.7340
Epoch 1/10, Train Loss: 1.0203, Valid Loss: 0.6056
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5500
Epoch 2/10, Batch 20/49, Loss: 0.5705
Epoch 2/10, Batch 30/49, Loss: 0.4042
Epoch 2/10, Batch 40/49, Loss: 0.5215
Epoch 2/10, Train Loss: 0.5502, Valid Loss: 0.4115
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4463
Epoch 3/10, Batch 20/49, Loss: 0.3408
Epoch 3/10, Batch 30/49, Loss: 0.4692
Epoch 3/10, Batch 40/49, Loss: 0.3665
Epoch 3/10, Train Loss: 0.4086, Valid Loss: 0.3502
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3571
Epoch 4/10, Batch 20/49, Loss: 0.3073
Epoch 4/10, Batch 30/49, Loss: 0.2367
Epoch 4/10, Batch 40/49, Loss: 0.3650
Epoch 4/10, Train Loss: 0.3647, Valid Loss: 0.3000
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4528
Epoch 5/10, Batch 20/49, Loss: 0.1807
Epoch 5/10, Batch 30/49, Loss: 0.3053
Epoch 5/10, Batch 40/49, Loss: 0.3025
Epoch 5/10, Train Loss: 0.3169, Valid Loss: 0.2750
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3311
Epoch 6/10, Batch 20/49, Loss: 0.1864
Epoch 6/10, Batch 30/49, Loss: 0.2051
Epoch 6/10, Batch 40/49, Loss: 0.1989
Epoch 6/10, Train Loss: 0.3005, Valid Loss: 0.2615
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1982
Epoch 7/10, Batch 20/49, Loss: 0.2711
Epoch 7/10, Batch 30/49, Loss: 0.2357
Epoch 7/10, Batch 40/49, Loss: 0.2185
Epoch 7/10, Train Loss: 0.2520, Valid Loss: 0.2645
Epoch 8/10, Batch 10/49, Loss: 0.2596
Epoch 8/10, Batch 20/49, Loss: 0.2050
Epoch 8/10, Batch 30/49, Loss: 0.1577
Epoch 8/10, Batch 40/49, Loss: 0.2089
Epoch 8/10, Train Loss: 0.2580, Valid Loss: 0.2462
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3531
Epoch 9/10, Batch 20/49, Loss: 0.2258
Epoch 9/10, Batch 30/49, Loss: 0.2872
Epoch 9/10, Batch 40/49, Loss: 0.3084
Epoch 9/10, Train Loss: 0.2406, Valid Loss: 0.2405
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1612
Epoch 10/10, Batch 20/49, Loss: 0.2450
Epoch 10/10, Batch 30/49, Loss: 0.1764
Epoch 10/10, Batch 40/49, Loss: 0.2285
Epoch 10/10, Train Loss: 0.2176, Valid Loss: 0.2449
Accuracy: 0.9089
Precision: 0.9052
Recall: 0.9089
F1-score: 0.9062
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2315
Epoch 1/10, Batch 20/49, Loss: 1.0749
Epoch 1/10, Batch 30/49, Loss: 0.8801
Epoch 1/10, Batch 40/49, Loss: 0.7461
Epoch 1/10, Train Loss: 1.0153, Valid Loss: 0.6428
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5575
Epoch 2/10, Batch 20/49, Loss: 0.5667
Epoch 2/10, Batch 30/49, Loss: 0.5686
Epoch 2/10, Batch 40/49, Loss: 0.4787
Epoch 2/10, Train Loss: 0.5470, Valid Loss: 0.4501
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4018
Epoch 3/10, Batch 20/49, Loss: 0.3531
Epoch 3/10, Batch 30/49, Loss: 0.2765
Epoch 3/10, Batch 40/49, Loss: 0.3889
Epoch 3/10, Train Loss: 0.4178, Valid Loss: 0.3810
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3457
Epoch 4/10, Batch 20/49, Loss: 0.5292
Epoch 4/10, Batch 30/49, Loss: 0.3666
Epoch 4/10, Batch 40/49, Loss: 0.3595
Epoch 4/10, Train Loss: 0.3661, Valid Loss: 0.3364
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4967
Epoch 5/10, Batch 20/49, Loss: 0.1771
Epoch 5/10, Batch 30/49, Loss: 0.3578
Epoch 5/10, Batch 40/49, Loss: 0.1922
Epoch 5/10, Train Loss: 0.3224, Valid Loss: 0.3141
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2235
Epoch 6/10, Batch 20/49, Loss: 0.4137
Epoch 6/10, Batch 30/49, Loss: 0.1806
Epoch 6/10, Batch 40/49, Loss: 0.3290
Epoch 6/10, Train Loss: 0.2890, Valid Loss: 0.2858
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2968
Epoch 7/10, Batch 20/49, Loss: 0.2490
Epoch 7/10, Batch 30/49, Loss: 0.2070
Epoch 7/10, Batch 40/49, Loss: 0.3354
Epoch 7/10, Train Loss: 0.2584, Valid Loss: 0.2824
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2368
Epoch 8/10, Batch 20/49, Loss: 0.2202
Epoch 8/10, Batch 30/49, Loss: 0.2360
Epoch 8/10, Batch 40/49, Loss: 0.2412
Epoch 8/10, Train Loss: 0.2672, Valid Loss: 0.2731
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3309
Epoch 9/10, Batch 20/49, Loss: 0.2195
Epoch 9/10, Batch 30/49, Loss: 0.3248
Epoch 9/10, Batch 40/49, Loss: 0.3864
Epoch 9/10, Train Loss: 0.2400, Valid Loss: 0.2714
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1998
Epoch 10/10, Batch 20/49, Loss: 0.1271
Epoch 10/10, Batch 30/49, Loss: 0.1091
Epoch 10/10, Batch 40/49, Loss: 0.1817
Epoch 10/10, Train Loss: 0.2182, Valid Loss: 0.2623
Model saved!
Accuracy: 0.8960
Precision: 0.8907
Recall: 0.8960
F1-score: 0.8918
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2150
Epoch 1/10, Batch 20/49, Loss: 1.1915
Epoch 1/10, Batch 30/49, Loss: 0.8120
Epoch 1/10, Batch 40/49, Loss: 0.7516
Epoch 1/10, Train Loss: 1.0039, Valid Loss: 0.5983
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6582
Epoch 2/10, Batch 20/49, Loss: 0.6479
Epoch 2/10, Batch 30/49, Loss: 0.4070
Epoch 2/10, Batch 40/49, Loss: 0.4578
Epoch 2/10, Train Loss: 0.5528, Valid Loss: 0.4098
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4311
Epoch 3/10, Batch 20/49, Loss: 0.4010
Epoch 3/10, Batch 30/49, Loss: 0.5250
Epoch 3/10, Batch 40/49, Loss: 0.3788
Epoch 3/10, Train Loss: 0.4205, Valid Loss: 0.3519
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3765
Epoch 4/10, Batch 20/49, Loss: 0.4172
Epoch 4/10, Batch 30/49, Loss: 0.4696
Epoch 4/10, Batch 40/49, Loss: 0.5275
Epoch 4/10, Train Loss: 0.3692, Valid Loss: 0.3009
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3780
Epoch 5/10, Batch 20/49, Loss: 0.3204
Epoch 5/10, Batch 30/49, Loss: 0.3136
Epoch 5/10, Batch 40/49, Loss: 0.3372
Epoch 5/10, Train Loss: 0.3186, Valid Loss: 0.2733
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2445
Epoch 6/10, Batch 20/49, Loss: 0.3089
Epoch 6/10, Batch 30/49, Loss: 0.2234
Epoch 6/10, Batch 40/49, Loss: 0.2801
Epoch 6/10, Train Loss: 0.3030, Valid Loss: 0.2567
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1636
Epoch 7/10, Batch 20/49, Loss: 0.2959
Epoch 7/10, Batch 30/49, Loss: 0.2390
Epoch 7/10, Batch 40/49, Loss: 0.2046
Epoch 7/10, Train Loss: 0.2680, Valid Loss: 0.2612
Epoch 8/10, Batch 10/49, Loss: 0.2502
Epoch 8/10, Batch 20/49, Loss: 0.1343
Epoch 8/10, Batch 30/49, Loss: 0.2632
Epoch 8/10, Batch 40/49, Loss: 0.2003
Epoch 8/10, Train Loss: 0.2573, Valid Loss: 0.2429
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2249
Epoch 9/10, Batch 20/49, Loss: 0.0850
Epoch 9/10, Batch 30/49, Loss: 0.3291
Epoch 9/10, Batch 40/49, Loss: 0.4319
Epoch 9/10, Train Loss: 0.2426, Valid Loss: 0.2376
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2358
Epoch 10/10, Batch 20/49, Loss: 0.1783
Epoch 10/10, Batch 30/49, Loss: 0.1916
Epoch 10/10, Batch 40/49, Loss: 0.1237
Epoch 10/10, Train Loss: 0.2318, Valid Loss: 0.2281
Model saved!
Accuracy: 0.8995
Precision: 0.8972
Recall: 0.8995
F1-score: 0.8964
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2577
Epoch 1/10, Batch 20/49, Loss: 1.1140
Epoch 1/10, Batch 30/49, Loss: 0.8652
Epoch 1/10, Batch 40/49, Loss: 0.8440
Epoch 1/10, Train Loss: 1.0093, Valid Loss: 0.6289
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5054
Epoch 2/10, Batch 20/49, Loss: 0.5764
Epoch 2/10, Batch 30/49, Loss: 0.4215
Epoch 2/10, Batch 40/49, Loss: 0.3880
Epoch 2/10, Train Loss: 0.5365, Valid Loss: 0.4527
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3955
Epoch 3/10, Batch 20/49, Loss: 0.3364
Epoch 3/10, Batch 30/49, Loss: 0.4427
Epoch 3/10, Batch 40/49, Loss: 0.4244
Epoch 3/10, Train Loss: 0.4028, Valid Loss: 0.3965
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3203
Epoch 4/10, Batch 20/49, Loss: 0.3462
Epoch 4/10, Batch 30/49, Loss: 0.3170
Epoch 4/10, Batch 40/49, Loss: 0.4444
Epoch 4/10, Train Loss: 0.3569, Valid Loss: 0.3535
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4051
Epoch 5/10, Batch 20/49, Loss: 0.2969
Epoch 5/10, Batch 30/49, Loss: 0.2041
Epoch 5/10, Batch 40/49, Loss: 0.2857
Epoch 5/10, Train Loss: 0.3194, Valid Loss: 0.3315
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3989
Epoch 6/10, Batch 20/49, Loss: 0.2025
Epoch 6/10, Batch 30/49, Loss: 0.3170
Epoch 6/10, Batch 40/49, Loss: 0.2125
Epoch 6/10, Train Loss: 0.2834, Valid Loss: 0.3132
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2419
Epoch 7/10, Batch 20/49, Loss: 0.1792
Epoch 7/10, Batch 30/49, Loss: 0.2350
Epoch 7/10, Batch 40/49, Loss: 0.1585
Epoch 7/10, Train Loss: 0.2515, Valid Loss: 0.3318
Epoch 8/10, Batch 10/49, Loss: 0.1697
Epoch 8/10, Batch 20/49, Loss: 0.1769
Epoch 8/10, Batch 30/49, Loss: 0.2506
Epoch 8/10, Batch 40/49, Loss: 0.2084
Epoch 8/10, Train Loss: 0.2430, Valid Loss: 0.3257
Epoch 9/10, Batch 10/49, Loss: 0.1548
Epoch 9/10, Batch 20/49, Loss: 0.1371
Epoch 9/10, Batch 30/49, Loss: 0.1910
Epoch 9/10, Batch 40/49, Loss: 0.3405
Epoch 9/10, Train Loss: 0.2210, Valid Loss: 0.3035
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2690
Epoch 10/10, Batch 20/49, Loss: 0.2528
Epoch 10/10, Batch 30/49, Loss: 0.1925
Epoch 10/10, Batch 40/49, Loss: 0.2293
Epoch 10/10, Train Loss: 0.2116, Valid Loss: 0.3134
Accuracy: 0.9065
Precision: 0.9032
Recall: 0.9065
F1-score: 0.9040
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2435
Epoch 1/10, Batch 20/49, Loss: 1.1084
Epoch 1/10, Batch 30/49, Loss: 0.7189
Epoch 1/10, Batch 40/49, Loss: 0.7343
Epoch 1/10, Train Loss: 0.9993, Valid Loss: 0.6344
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6169
Epoch 2/10, Batch 20/49, Loss: 0.6944
Epoch 2/10, Batch 30/49, Loss: 0.5188
Epoch 2/10, Batch 40/49, Loss: 0.3997
Epoch 2/10, Train Loss: 0.5341, Valid Loss: 0.4425
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4652
Epoch 3/10, Batch 20/49, Loss: 0.2815
Epoch 3/10, Batch 30/49, Loss: 0.2714
Epoch 3/10, Batch 40/49, Loss: 0.4725
Epoch 3/10, Train Loss: 0.4037, Valid Loss: 0.3833
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3332
Epoch 4/10, Batch 20/49, Loss: 0.2976
Epoch 4/10, Batch 30/49, Loss: 0.1968
Epoch 4/10, Batch 40/49, Loss: 0.3786
Epoch 4/10, Train Loss: 0.3531, Valid Loss: 0.3387
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4554
Epoch 5/10, Batch 20/49, Loss: 0.2983
Epoch 5/10, Batch 30/49, Loss: 0.3082
Epoch 5/10, Batch 40/49, Loss: 0.3143
Epoch 5/10, Train Loss: 0.3102, Valid Loss: 0.3101
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2324
Epoch 6/10, Batch 20/49, Loss: 0.1787
Epoch 6/10, Batch 30/49, Loss: 0.2476
Epoch 6/10, Batch 40/49, Loss: 0.2370
Epoch 6/10, Train Loss: 0.2878, Valid Loss: 0.2912
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2079
Epoch 7/10, Batch 20/49, Loss: 0.2161
Epoch 7/10, Batch 30/49, Loss: 0.2232
Epoch 7/10, Batch 40/49, Loss: 0.2032
Epoch 7/10, Train Loss: 0.2487, Valid Loss: 0.2961
Epoch 8/10, Batch 10/49, Loss: 0.2135
Epoch 8/10, Batch 20/49, Loss: 0.1727
Epoch 8/10, Batch 30/49, Loss: 0.2014
Epoch 8/10, Batch 40/49, Loss: 0.1395
Epoch 8/10, Train Loss: 0.2453, Valid Loss: 0.2899
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1686
Epoch 9/10, Batch 20/49, Loss: 0.1929
Epoch 9/10, Batch 30/49, Loss: 0.2709
Epoch 9/10, Batch 40/49, Loss: 0.2307
Epoch 9/10, Train Loss: 0.2317, Valid Loss: 0.2787
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2053
Epoch 10/10, Batch 20/49, Loss: 0.2057
Epoch 10/10, Batch 30/49, Loss: 0.2010
Epoch 10/10, Batch 40/49, Loss: 0.1413
Epoch 10/10, Train Loss: 0.2096, Valid Loss: 0.2738
Model saved!
Accuracy: 0.9030
Precision: 0.9017
Recall: 0.9030
F1-score: 0.8983
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1983
Epoch 1/10, Batch 20/49, Loss: 1.1114
Epoch 1/10, Batch 30/49, Loss: 0.7437
Epoch 1/10, Batch 40/49, Loss: 0.9089
Epoch 1/10, Train Loss: 1.0101, Valid Loss: 0.5924
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5422
Epoch 2/10, Batch 20/49, Loss: 0.6988
Epoch 2/10, Batch 30/49, Loss: 0.5658
Epoch 2/10, Batch 40/49, Loss: 0.3588
Epoch 2/10, Train Loss: 0.5401, Valid Loss: 0.4055
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4357
Epoch 3/10, Batch 20/49, Loss: 0.3261
Epoch 3/10, Batch 30/49, Loss: 0.2953
Epoch 3/10, Batch 40/49, Loss: 0.3783
Epoch 3/10, Train Loss: 0.4083, Valid Loss: 0.3413
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3322
Epoch 4/10, Batch 20/49, Loss: 0.5589
Epoch 4/10, Batch 30/49, Loss: 0.3802
Epoch 4/10, Batch 40/49, Loss: 0.3852
Epoch 4/10, Train Loss: 0.3732, Valid Loss: 0.3185
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4663
Epoch 5/10, Batch 20/49, Loss: 0.2961
Epoch 5/10, Batch 30/49, Loss: 0.2710
Epoch 5/10, Batch 40/49, Loss: 0.3273
Epoch 5/10, Train Loss: 0.3328, Valid Loss: 0.2863
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3934
Epoch 6/10, Batch 20/49, Loss: 0.2189
Epoch 6/10, Batch 30/49, Loss: 0.3514
Epoch 6/10, Batch 40/49, Loss: 0.1618
Epoch 6/10, Train Loss: 0.2978, Valid Loss: 0.2742
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2635
Epoch 7/10, Batch 20/49, Loss: 0.2757
Epoch 7/10, Batch 30/49, Loss: 0.2538
Epoch 7/10, Batch 40/49, Loss: 0.0954
Epoch 7/10, Train Loss: 0.2629, Valid Loss: 0.2734
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2180
Epoch 8/10, Batch 20/49, Loss: 0.2677
Epoch 8/10, Batch 30/49, Loss: 0.2452
Epoch 8/10, Batch 40/49, Loss: 0.1406
Epoch 8/10, Train Loss: 0.2431, Valid Loss: 0.2575
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2145
Epoch 9/10, Batch 20/49, Loss: 0.2283
Epoch 9/10, Batch 30/49, Loss: 0.2838
Epoch 9/10, Batch 40/49, Loss: 0.3426
Epoch 9/10, Train Loss: 0.2356, Valid Loss: 0.2481
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2458
Epoch 10/10, Batch 20/49, Loss: 0.1735
Epoch 10/10, Batch 30/49, Loss: 0.0894
Epoch 10/10, Batch 40/49, Loss: 0.1624
Epoch 10/10, Train Loss: 0.2196, Valid Loss: 0.2521
Accuracy: 0.8949
Precision: 0.8897
Recall: 0.8949
F1-score: 0.8899
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2401
Epoch 1/10, Batch 20/49, Loss: 1.2148
Epoch 1/10, Batch 30/49, Loss: 0.8723
Epoch 1/10, Batch 40/49, Loss: 0.9968
Epoch 1/10, Train Loss: 1.0172, Valid Loss: 0.5997
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6081
Epoch 2/10, Batch 20/49, Loss: 0.5064
Epoch 2/10, Batch 30/49, Loss: 0.5390
Epoch 2/10, Batch 40/49, Loss: 0.4480
Epoch 2/10, Train Loss: 0.5359, Valid Loss: 0.4070
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4282
Epoch 3/10, Batch 20/49, Loss: 0.3984
Epoch 3/10, Batch 30/49, Loss: 0.3840
Epoch 3/10, Batch 40/49, Loss: 0.3850
Epoch 3/10, Train Loss: 0.4140, Valid Loss: 0.3442
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3524
Epoch 4/10, Batch 20/49, Loss: 0.4021
Epoch 4/10, Batch 30/49, Loss: 0.2833
Epoch 4/10, Batch 40/49, Loss: 0.4005
Epoch 4/10, Train Loss: 0.3668, Valid Loss: 0.3083
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3717
Epoch 5/10, Batch 20/49, Loss: 0.2867
Epoch 5/10, Batch 30/49, Loss: 0.2084
Epoch 5/10, Batch 40/49, Loss: 0.3341
Epoch 5/10, Train Loss: 0.3109, Valid Loss: 0.2813
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1979
Epoch 6/10, Batch 20/49, Loss: 0.1596
Epoch 6/10, Batch 30/49, Loss: 0.1812
Epoch 6/10, Batch 40/49, Loss: 0.2358
Epoch 6/10, Train Loss: 0.2832, Valid Loss: 0.2648
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2015
Epoch 7/10, Batch 20/49, Loss: 0.2531
Epoch 7/10, Batch 30/49, Loss: 0.3851
Epoch 7/10, Batch 40/49, Loss: 0.1825
Epoch 7/10, Train Loss: 0.2563, Valid Loss: 0.2600
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2849
Epoch 8/10, Batch 20/49, Loss: 0.2346
Epoch 8/10, Batch 30/49, Loss: 0.2712
Epoch 8/10, Batch 40/49, Loss: 0.1197
Epoch 8/10, Train Loss: 0.2405, Valid Loss: 0.2553
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1318
Epoch 9/10, Batch 20/49, Loss: 0.1203
Epoch 9/10, Batch 30/49, Loss: 0.3637
Epoch 9/10, Batch 40/49, Loss: 0.3310
Epoch 9/10, Train Loss: 0.2305, Valid Loss: 0.2478
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.4587
Epoch 10/10, Batch 20/49, Loss: 0.2428
Epoch 10/10, Batch 30/49, Loss: 0.1047
Epoch 10/10, Batch 40/49, Loss: 0.1894
Epoch 10/10, Train Loss: 0.2114, Valid Loss: 0.2493
Accuracy: 0.8984
Precision: 0.8950
Recall: 0.8984
F1-score: 0.8918
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2281
Epoch 1/10, Batch 20/49, Loss: 1.1565
Epoch 1/10, Batch 30/49, Loss: 0.8506
Epoch 1/10, Batch 40/49, Loss: 0.8917
Epoch 1/10, Train Loss: 1.0096, Valid Loss: 0.6221
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5955
Epoch 2/10, Batch 20/49, Loss: 0.8813
Epoch 2/10, Batch 30/49, Loss: 0.5418
Epoch 2/10, Batch 40/49, Loss: 0.4604
Epoch 2/10, Train Loss: 0.5422, Valid Loss: 0.4269
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4248
Epoch 3/10, Batch 20/49, Loss: 0.3046
Epoch 3/10, Batch 30/49, Loss: 0.4317
Epoch 3/10, Batch 40/49, Loss: 0.4717
Epoch 3/10, Train Loss: 0.4036, Valid Loss: 0.3706
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4120
Epoch 4/10, Batch 20/49, Loss: 0.3748
Epoch 4/10, Batch 30/49, Loss: 0.3472
Epoch 4/10, Batch 40/49, Loss: 0.3173
Epoch 4/10, Train Loss: 0.3724, Valid Loss: 0.3254
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4638
Epoch 5/10, Batch 20/49, Loss: 0.2272
Epoch 5/10, Batch 30/49, Loss: 0.3500
Epoch 5/10, Batch 40/49, Loss: 0.2894
Epoch 5/10, Train Loss: 0.3202, Valid Loss: 0.2999
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2984
Epoch 6/10, Batch 20/49, Loss: 0.2404
Epoch 6/10, Batch 30/49, Loss: 0.3209
Epoch 6/10, Batch 40/49, Loss: 0.3572
Epoch 6/10, Train Loss: 0.2958, Valid Loss: 0.2806
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3246
Epoch 7/10, Batch 20/49, Loss: 0.3136
Epoch 7/10, Batch 30/49, Loss: 0.2723
Epoch 7/10, Batch 40/49, Loss: 0.1770
Epoch 7/10, Train Loss: 0.2555, Valid Loss: 0.2897
Epoch 8/10, Batch 10/49, Loss: 0.1855
Epoch 8/10, Batch 20/49, Loss: 0.2348
Epoch 8/10, Batch 30/49, Loss: 0.2526
Epoch 8/10, Batch 40/49, Loss: 0.1475
Epoch 8/10, Train Loss: 0.2552, Valid Loss: 0.2736
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3424
Epoch 9/10, Batch 20/49, Loss: 0.1405
Epoch 9/10, Batch 30/49, Loss: 0.3802
Epoch 9/10, Batch 40/49, Loss: 0.4579
Epoch 9/10, Train Loss: 0.2334, Valid Loss: 0.2593
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2295
Epoch 10/10, Batch 20/49, Loss: 0.2404
Epoch 10/10, Batch 30/49, Loss: 0.2704
Epoch 10/10, Batch 40/49, Loss: 0.1315
Epoch 10/10, Train Loss: 0.2162, Valid Loss: 0.2641
Accuracy: 0.8984
Precision: 0.8956
Recall: 0.8984
F1-score: 0.8933
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2172
Epoch 1/10, Batch 20/49, Loss: 1.0903
Epoch 1/10, Batch 30/49, Loss: 0.8709
Epoch 1/10, Batch 40/49, Loss: 0.8330
Epoch 1/10, Train Loss: 1.0085, Valid Loss: 0.6073
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5218
Epoch 2/10, Batch 20/49, Loss: 0.5373
Epoch 2/10, Batch 30/49, Loss: 0.4947
Epoch 2/10, Batch 40/49, Loss: 0.5581
Epoch 2/10, Train Loss: 0.5470, Valid Loss: 0.4324
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4828
Epoch 3/10, Batch 20/49, Loss: 0.2308
Epoch 3/10, Batch 30/49, Loss: 0.3083
Epoch 3/10, Batch 40/49, Loss: 0.3764
Epoch 3/10, Train Loss: 0.4058, Valid Loss: 0.3693
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4422
Epoch 4/10, Batch 20/49, Loss: 0.2784
Epoch 4/10, Batch 30/49, Loss: 0.4245
Epoch 4/10, Batch 40/49, Loss: 0.4176
Epoch 4/10, Train Loss: 0.3590, Valid Loss: 0.3258
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4419
Epoch 5/10, Batch 20/49, Loss: 0.4030
Epoch 5/10, Batch 30/49, Loss: 0.2449
Epoch 5/10, Batch 40/49, Loss: 0.2860
Epoch 5/10, Train Loss: 0.3122, Valid Loss: 0.2998
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2097
Epoch 6/10, Batch 20/49, Loss: 0.1950
Epoch 6/10, Batch 30/49, Loss: 0.3579
Epoch 6/10, Batch 40/49, Loss: 0.3106
Epoch 6/10, Train Loss: 0.2809, Valid Loss: 0.2852
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2376
Epoch 7/10, Batch 20/49, Loss: 0.2813
Epoch 7/10, Batch 30/49, Loss: 0.3077
Epoch 7/10, Batch 40/49, Loss: 0.2181
Epoch 7/10, Train Loss: 0.2546, Valid Loss: 0.2925
Epoch 8/10, Batch 10/49, Loss: 0.3673
Epoch 8/10, Batch 20/49, Loss: 0.2164
Epoch 8/10, Batch 30/49, Loss: 0.3393
Epoch 8/10, Batch 40/49, Loss: 0.2077
Epoch 8/10, Train Loss: 0.2509, Valid Loss: 0.2716
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3102
Epoch 9/10, Batch 20/49, Loss: 0.1488
Epoch 9/10, Batch 30/49, Loss: 0.2448
Epoch 9/10, Batch 40/49, Loss: 0.1907
Epoch 9/10, Train Loss: 0.2267, Valid Loss: 0.2623
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1629
Epoch 10/10, Batch 20/49, Loss: 0.1536
Epoch 10/10, Batch 30/49, Loss: 0.1128
Epoch 10/10, Batch 40/49, Loss: 0.1706
Epoch 10/10, Train Loss: 0.2186, Valid Loss: 0.2510
Model saved!
Accuracy: 0.9089
Precision: 0.9069
Recall: 0.9089
F1-score: 0.9069
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1792
Epoch 1/10, Batch 20/49, Loss: 1.1710
Epoch 1/10, Batch 30/49, Loss: 0.8114
Epoch 1/10, Batch 40/49, Loss: 0.7307
Epoch 1/10, Train Loss: 1.0143, Valid Loss: 0.6187
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6384
Epoch 2/10, Batch 20/49, Loss: 0.8664
Epoch 2/10, Batch 30/49, Loss: 0.6051
Epoch 2/10, Batch 40/49, Loss: 0.4209
Epoch 2/10, Train Loss: 0.5617, Valid Loss: 0.4375
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3576
Epoch 3/10, Batch 20/49, Loss: 0.4287
Epoch 3/10, Batch 30/49, Loss: 0.4301
Epoch 3/10, Batch 40/49, Loss: 0.4396
Epoch 3/10, Train Loss: 0.4343, Valid Loss: 0.3722
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3852
Epoch 4/10, Batch 20/49, Loss: 0.2903
Epoch 4/10, Batch 30/49, Loss: 0.3400
Epoch 4/10, Batch 40/49, Loss: 0.5094
Epoch 4/10, Train Loss: 0.3816, Valid Loss: 0.3189
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4184
Epoch 5/10, Batch 20/49, Loss: 0.2638
Epoch 5/10, Batch 30/49, Loss: 0.3058
Epoch 5/10, Batch 40/49, Loss: 0.2687
Epoch 5/10, Train Loss: 0.3375, Valid Loss: 0.2975
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2029
Epoch 6/10, Batch 20/49, Loss: 0.1508
Epoch 6/10, Batch 30/49, Loss: 0.3512
Epoch 6/10, Batch 40/49, Loss: 0.2934
Epoch 6/10, Train Loss: 0.3089, Valid Loss: 0.2870
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2984
Epoch 7/10, Batch 20/49, Loss: 0.2732
Epoch 7/10, Batch 30/49, Loss: 0.1819
Epoch 7/10, Batch 40/49, Loss: 0.1332
Epoch 7/10, Train Loss: 0.2681, Valid Loss: 0.2884
Epoch 8/10, Batch 10/49, Loss: 0.4329
Epoch 8/10, Batch 20/49, Loss: 0.2232
Epoch 8/10, Batch 30/49, Loss: 0.2660
Epoch 8/10, Batch 40/49, Loss: 0.1321
Epoch 8/10, Train Loss: 0.2747, Valid Loss: 0.2833
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1940
Epoch 9/10, Batch 20/49, Loss: 0.2018
Epoch 9/10, Batch 30/49, Loss: 0.3184
Epoch 9/10, Batch 40/49, Loss: 0.3597
Epoch 9/10, Train Loss: 0.2607, Valid Loss: 0.2676
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2257
Epoch 10/10, Batch 20/49, Loss: 0.2592
Epoch 10/10, Batch 30/49, Loss: 0.2205
Epoch 10/10, Batch 40/49, Loss: 0.1860
Epoch 10/10, Train Loss: 0.2377, Valid Loss: 0.2576
Model saved!
Accuracy: 0.9019
Precision: 0.8990
Recall: 0.9019
F1-score: 0.8985
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2478
Epoch 1/10, Batch 20/49, Loss: 1.1834
Epoch 1/10, Batch 30/49, Loss: 0.8571
Epoch 1/10, Batch 40/49, Loss: 0.7511
Epoch 1/10, Train Loss: 0.9921, Valid Loss: 0.6197
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.4450
Epoch 2/10, Batch 20/49, Loss: 0.5722
Epoch 2/10, Batch 30/49, Loss: 0.4149
Epoch 2/10, Batch 40/49, Loss: 0.5567
Epoch 2/10, Train Loss: 0.5319, Valid Loss: 0.4234
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4418
Epoch 3/10, Batch 20/49, Loss: 0.3762
Epoch 3/10, Batch 30/49, Loss: 0.3597
Epoch 3/10, Batch 40/49, Loss: 0.3982
Epoch 3/10, Train Loss: 0.4057, Valid Loss: 0.3753
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2953
Epoch 4/10, Batch 20/49, Loss: 0.3900
Epoch 4/10, Batch 30/49, Loss: 0.3850
Epoch 4/10, Batch 40/49, Loss: 0.2808
Epoch 4/10, Train Loss: 0.3499, Valid Loss: 0.3218
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4347
Epoch 5/10, Batch 20/49, Loss: 0.2237
Epoch 5/10, Batch 30/49, Loss: 0.2044
Epoch 5/10, Batch 40/49, Loss: 0.2860
Epoch 5/10, Train Loss: 0.3145, Valid Loss: 0.2864
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2350
Epoch 6/10, Batch 20/49, Loss: 0.2038
Epoch 6/10, Batch 30/49, Loss: 0.3958
Epoch 6/10, Batch 40/49, Loss: 0.2299
Epoch 6/10, Train Loss: 0.2815, Valid Loss: 0.2796
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2227
Epoch 7/10, Batch 20/49, Loss: 0.2942
Epoch 7/10, Batch 30/49, Loss: 0.2602
Epoch 7/10, Batch 40/49, Loss: 0.0862
Epoch 7/10, Train Loss: 0.2422, Valid Loss: 0.2948
Epoch 8/10, Batch 10/49, Loss: 0.3513
Epoch 8/10, Batch 20/49, Loss: 0.1721
Epoch 8/10, Batch 30/49, Loss: 0.1559
Epoch 8/10, Batch 40/49, Loss: 0.2339
Epoch 8/10, Train Loss: 0.2412, Valid Loss: 0.2672
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3130
Epoch 9/10, Batch 20/49, Loss: 0.1944
Epoch 9/10, Batch 30/49, Loss: 0.2106
Epoch 9/10, Batch 40/49, Loss: 0.2966
Epoch 9/10, Train Loss: 0.2331, Valid Loss: 0.2590
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3036
Epoch 10/10, Batch 20/49, Loss: 0.1445
Epoch 10/10, Batch 30/49, Loss: 0.1213
Epoch 10/10, Batch 40/49, Loss: 0.2460
Epoch 10/10, Train Loss: 0.2100, Valid Loss: 0.2648
Accuracy: 0.8995
Precision: 0.8957
Recall: 0.8995
F1-score: 0.8938
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2435
Epoch 1/10, Batch 20/49, Loss: 1.1384
Epoch 1/10, Batch 30/49, Loss: 0.8079
Epoch 1/10, Batch 40/49, Loss: 0.8635
Epoch 1/10, Train Loss: 0.9959, Valid Loss: 0.6094
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.4762
Epoch 2/10, Batch 20/49, Loss: 0.4766
Epoch 2/10, Batch 30/49, Loss: 0.3710
Epoch 2/10, Batch 40/49, Loss: 0.5585
Epoch 2/10, Train Loss: 0.5368, Valid Loss: 0.4234
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4919
Epoch 3/10, Batch 20/49, Loss: 0.3992
Epoch 3/10, Batch 30/49, Loss: 0.4930
Epoch 3/10, Batch 40/49, Loss: 0.2807
Epoch 3/10, Train Loss: 0.4097, Valid Loss: 0.3545
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3708
Epoch 4/10, Batch 20/49, Loss: 0.2808
Epoch 4/10, Batch 30/49, Loss: 0.3363
Epoch 4/10, Batch 40/49, Loss: 0.4884
Epoch 4/10, Train Loss: 0.3525, Valid Loss: 0.3050
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.7282
Epoch 5/10, Batch 20/49, Loss: 0.3164
Epoch 5/10, Batch 30/49, Loss: 0.2669
Epoch 5/10, Batch 40/49, Loss: 0.2824
Epoch 5/10, Train Loss: 0.3254, Valid Loss: 0.2791
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2902
Epoch 6/10, Batch 20/49, Loss: 0.2939
Epoch 6/10, Batch 30/49, Loss: 0.2080
Epoch 6/10, Batch 40/49, Loss: 0.2140
Epoch 6/10, Train Loss: 0.2835, Valid Loss: 0.2781
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1321
Epoch 7/10, Batch 20/49, Loss: 0.3126
Epoch 7/10, Batch 30/49, Loss: 0.1504
Epoch 7/10, Batch 40/49, Loss: 0.2267
Epoch 7/10, Train Loss: 0.2578, Valid Loss: 0.2675
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2965
Epoch 8/10, Batch 20/49, Loss: 0.1318
Epoch 8/10, Batch 30/49, Loss: 0.2011
Epoch 8/10, Batch 40/49, Loss: 0.2623
Epoch 8/10, Train Loss: 0.2419, Valid Loss: 0.2468
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2638
Epoch 9/10, Batch 20/49, Loss: 0.1228
Epoch 9/10, Batch 30/49, Loss: 0.2696
Epoch 9/10, Batch 40/49, Loss: 0.3080
Epoch 9/10, Train Loss: 0.2279, Valid Loss: 0.2309
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1778
Epoch 10/10, Batch 20/49, Loss: 0.2170
Epoch 10/10, Batch 30/49, Loss: 0.1852
Epoch 10/10, Batch 40/49, Loss: 0.2029
Epoch 10/10, Train Loss: 0.2247, Valid Loss: 0.2463
Accuracy: 0.8972
Precision: 0.8933
Recall: 0.8972
F1-score: 0.8918
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2320
Epoch 1/10, Batch 20/49, Loss: 1.1380
Epoch 1/10, Batch 30/49, Loss: 0.8302
Epoch 1/10, Batch 40/49, Loss: 0.6265
Epoch 1/10, Train Loss: 1.0128, Valid Loss: 0.6202
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5691
Epoch 2/10, Batch 20/49, Loss: 0.6539
Epoch 2/10, Batch 30/49, Loss: 0.4560
Epoch 2/10, Batch 40/49, Loss: 0.4759
Epoch 2/10, Train Loss: 0.5358, Valid Loss: 0.4349
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3315
Epoch 3/10, Batch 20/49, Loss: 0.3612
Epoch 3/10, Batch 30/49, Loss: 0.4084
Epoch 3/10, Batch 40/49, Loss: 0.4135
Epoch 3/10, Train Loss: 0.4056, Valid Loss: 0.3782
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2792
Epoch 4/10, Batch 20/49, Loss: 0.3679
Epoch 4/10, Batch 30/49, Loss: 0.2735
Epoch 4/10, Batch 40/49, Loss: 0.3064
Epoch 4/10, Train Loss: 0.3486, Valid Loss: 0.3338
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3474
Epoch 5/10, Batch 20/49, Loss: 0.2027
Epoch 5/10, Batch 30/49, Loss: 0.3329
Epoch 5/10, Batch 40/49, Loss: 0.3881
Epoch 5/10, Train Loss: 0.3101, Valid Loss: 0.3047
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2766
Epoch 6/10, Batch 20/49, Loss: 0.1894
Epoch 6/10, Batch 30/49, Loss: 0.1952
Epoch 6/10, Batch 40/49, Loss: 0.2849
Epoch 6/10, Train Loss: 0.2831, Valid Loss: 0.2887
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2400
Epoch 7/10, Batch 20/49, Loss: 0.2588
Epoch 7/10, Batch 30/49, Loss: 0.1526
Epoch 7/10, Batch 40/49, Loss: 0.2139
Epoch 7/10, Train Loss: 0.2527, Valid Loss: 0.2868
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2672
Epoch 8/10, Batch 20/49, Loss: 0.1116
Epoch 8/10, Batch 30/49, Loss: 0.2110
Epoch 8/10, Batch 40/49, Loss: 0.2075
Epoch 8/10, Train Loss: 0.2343, Valid Loss: 0.2818
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1901
Epoch 9/10, Batch 20/49, Loss: 0.1347
Epoch 9/10, Batch 30/49, Loss: 0.2146
Epoch 9/10, Batch 40/49, Loss: 0.1582
Epoch 9/10, Train Loss: 0.2250, Valid Loss: 0.2742
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2807
Epoch 10/10, Batch 20/49, Loss: 0.1675
Epoch 10/10, Batch 30/49, Loss: 0.1755
Epoch 10/10, Batch 40/49, Loss: 0.1653
Epoch 10/10, Train Loss: 0.2119, Valid Loss: 0.2622
Model saved!
Accuracy: 0.9054
Precision: 0.9034
Recall: 0.9054
F1-score: 0.9023
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1872
Epoch 1/10, Batch 20/49, Loss: 1.1752
Epoch 1/10, Batch 30/49, Loss: 0.9120
Epoch 1/10, Batch 40/49, Loss: 0.7373
Epoch 1/10, Train Loss: 1.0204, Valid Loss: 0.6067
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5487
Epoch 2/10, Batch 20/49, Loss: 0.5706
Epoch 2/10, Batch 30/49, Loss: 0.4696
Epoch 2/10, Batch 40/49, Loss: 0.4998
Epoch 2/10, Train Loss: 0.5591, Valid Loss: 0.4156
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4101
Epoch 3/10, Batch 20/49, Loss: 0.3118
Epoch 3/10, Batch 30/49, Loss: 0.3555
Epoch 3/10, Batch 40/49, Loss: 0.5359
Epoch 3/10, Train Loss: 0.4275, Valid Loss: 0.3458
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2620
Epoch 4/10, Batch 20/49, Loss: 0.3829
Epoch 4/10, Batch 30/49, Loss: 0.4407
Epoch 4/10, Batch 40/49, Loss: 0.3444
Epoch 4/10, Train Loss: 0.3719, Valid Loss: 0.3198
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4078
Epoch 5/10, Batch 20/49, Loss: 0.2465
Epoch 5/10, Batch 30/49, Loss: 0.2792
Epoch 5/10, Batch 40/49, Loss: 0.4012
Epoch 5/10, Train Loss: 0.3405, Valid Loss: 0.2888
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2363
Epoch 6/10, Batch 20/49, Loss: 0.1523
Epoch 6/10, Batch 30/49, Loss: 0.3120
Epoch 6/10, Batch 40/49, Loss: 0.3856
Epoch 6/10, Train Loss: 0.2981, Valid Loss: 0.2784
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2777
Epoch 7/10, Batch 20/49, Loss: 0.2727
Epoch 7/10, Batch 30/49, Loss: 0.2319
Epoch 7/10, Batch 40/49, Loss: 0.2138
Epoch 7/10, Train Loss: 0.2701, Valid Loss: 0.2690
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2663
Epoch 8/10, Batch 20/49, Loss: 0.2430
Epoch 8/10, Batch 30/49, Loss: 0.2123
Epoch 8/10, Batch 40/49, Loss: 0.1892
Epoch 8/10, Train Loss: 0.2696, Valid Loss: 0.2520
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3652
Epoch 9/10, Batch 20/49, Loss: 0.1063
Epoch 9/10, Batch 30/49, Loss: 0.2766
Epoch 9/10, Batch 40/49, Loss: 0.1883
Epoch 9/10, Train Loss: 0.2441, Valid Loss: 0.2432
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3961
Epoch 10/10, Batch 20/49, Loss: 0.1512
Epoch 10/10, Batch 30/49, Loss: 0.1483
Epoch 10/10, Batch 40/49, Loss: 0.1530
Epoch 10/10, Train Loss: 0.2317, Valid Loss: 0.2430
Model saved!
Accuracy: 0.9054
Precision: 0.9027
Recall: 0.9054
F1-score: 0.9033
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2136
Epoch 1/10, Batch 20/49, Loss: 1.1135
Epoch 1/10, Batch 30/49, Loss: 0.8374
Epoch 1/10, Batch 40/49, Loss: 0.8115
Epoch 1/10, Train Loss: 1.0133, Valid Loss: 0.6061
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5676
Epoch 2/10, Batch 20/49, Loss: 0.7004
Epoch 2/10, Batch 30/49, Loss: 0.3982
Epoch 2/10, Batch 40/49, Loss: 0.4676
Epoch 2/10, Train Loss: 0.5477, Valid Loss: 0.3981
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4343
Epoch 3/10, Batch 20/49, Loss: 0.3029
Epoch 3/10, Batch 30/49, Loss: 0.3951
Epoch 3/10, Batch 40/49, Loss: 0.3954
Epoch 3/10, Train Loss: 0.4133, Valid Loss: 0.3488
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3808
Epoch 4/10, Batch 20/49, Loss: 0.2790
Epoch 4/10, Batch 30/49, Loss: 0.4234
Epoch 4/10, Batch 40/49, Loss: 0.4711
Epoch 4/10, Train Loss: 0.3705, Valid Loss: 0.3018
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4410
Epoch 5/10, Batch 20/49, Loss: 0.2072
Epoch 5/10, Batch 30/49, Loss: 0.3635
Epoch 5/10, Batch 40/49, Loss: 0.4175
Epoch 5/10, Train Loss: 0.3200, Valid Loss: 0.2754
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2394
Epoch 6/10, Batch 20/49, Loss: 0.2930
Epoch 6/10, Batch 30/49, Loss: 0.2696
Epoch 6/10, Batch 40/49, Loss: 0.4151
Epoch 6/10, Train Loss: 0.2909, Valid Loss: 0.2572
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1980
Epoch 7/10, Batch 20/49, Loss: 0.2835
Epoch 7/10, Batch 30/49, Loss: 0.1537
Epoch 7/10, Batch 40/49, Loss: 0.0962
Epoch 7/10, Train Loss: 0.2544, Valid Loss: 0.2616
Epoch 8/10, Batch 10/49, Loss: 0.3644
Epoch 8/10, Batch 20/49, Loss: 0.1651
Epoch 8/10, Batch 30/49, Loss: 0.1683
Epoch 8/10, Batch 40/49, Loss: 0.2630
Epoch 8/10, Train Loss: 0.2498, Valid Loss: 0.2585
Epoch 9/10, Batch 10/49, Loss: 0.2595
Epoch 9/10, Batch 20/49, Loss: 0.2764
Epoch 9/10, Batch 30/49, Loss: 0.3175
Epoch 9/10, Batch 40/49, Loss: 0.2879
Epoch 9/10, Train Loss: 0.2370, Valid Loss: 0.2435
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1994
Epoch 10/10, Batch 20/49, Loss: 0.2954
Epoch 10/10, Batch 30/49, Loss: 0.2414
Epoch 10/10, Batch 40/49, Loss: 0.2226
Epoch 10/10, Train Loss: 0.2153, Valid Loss: 0.2375
Model saved!
Accuracy: 0.9077
Precision: 0.9039
Recall: 0.9077
F1-score: 0.9043
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2008
Epoch 1/10, Batch 20/49, Loss: 1.0877
Epoch 1/10, Batch 30/49, Loss: 0.7875
Epoch 1/10, Batch 40/49, Loss: 0.8621
Epoch 1/10, Train Loss: 1.0005, Valid Loss: 0.6030
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6427
Epoch 2/10, Batch 20/49, Loss: 0.7276
Epoch 2/10, Batch 30/49, Loss: 0.4489
Epoch 2/10, Batch 40/49, Loss: 0.3818
Epoch 2/10, Train Loss: 0.5413, Valid Loss: 0.4191
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4709
Epoch 3/10, Batch 20/49, Loss: 0.3492
Epoch 3/10, Batch 30/49, Loss: 0.3158
Epoch 3/10, Batch 40/49, Loss: 0.3620
Epoch 3/10, Train Loss: 0.4050, Valid Loss: 0.3677
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4108
Epoch 4/10, Batch 20/49, Loss: 0.4733
Epoch 4/10, Batch 30/49, Loss: 0.3134
Epoch 4/10, Batch 40/49, Loss: 0.4220
Epoch 4/10, Train Loss: 0.3585, Valid Loss: 0.3172
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3735
Epoch 5/10, Batch 20/49, Loss: 0.2559
Epoch 5/10, Batch 30/49, Loss: 0.1545
Epoch 5/10, Batch 40/49, Loss: 0.2132
Epoch 5/10, Train Loss: 0.3238, Valid Loss: 0.2895
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2164
Epoch 6/10, Batch 20/49, Loss: 0.1762
Epoch 6/10, Batch 30/49, Loss: 0.2102
Epoch 6/10, Batch 40/49, Loss: 0.2058
Epoch 6/10, Train Loss: 0.2892, Valid Loss: 0.2752
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2590
Epoch 7/10, Batch 20/49, Loss: 0.2734
Epoch 7/10, Batch 30/49, Loss: 0.1858
Epoch 7/10, Batch 40/49, Loss: 0.3067
Epoch 7/10, Train Loss: 0.2495, Valid Loss: 0.2723
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2255
Epoch 8/10, Batch 20/49, Loss: 0.1644
Epoch 8/10, Batch 30/49, Loss: 0.2216
Epoch 8/10, Batch 40/49, Loss: 0.1882
Epoch 8/10, Train Loss: 0.2508, Valid Loss: 0.2676
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2214
Epoch 9/10, Batch 20/49, Loss: 0.1909
Epoch 9/10, Batch 30/49, Loss: 0.2000
Epoch 9/10, Batch 40/49, Loss: 0.3595
Epoch 9/10, Train Loss: 0.2244, Valid Loss: 0.2503
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2209
Epoch 10/10, Batch 20/49, Loss: 0.1835
Epoch 10/10, Batch 30/49, Loss: 0.1879
Epoch 10/10, Batch 40/49, Loss: 0.0958
Epoch 10/10, Train Loss: 0.2146, Valid Loss: 0.2409
Model saved!
Accuracy: 0.9054
Precision: 0.9023
Recall: 0.9054
F1-score: 0.9023
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2312
Epoch 1/10, Batch 20/49, Loss: 1.0477
Epoch 1/10, Batch 30/49, Loss: 0.9101
Epoch 1/10, Batch 40/49, Loss: 0.7198
Epoch 1/10, Train Loss: 1.0225, Valid Loss: 0.6231
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6061
Epoch 2/10, Batch 20/49, Loss: 0.7683
Epoch 2/10, Batch 30/49, Loss: 0.7311
Epoch 2/10, Batch 40/49, Loss: 0.5321
Epoch 2/10, Train Loss: 0.5641, Valid Loss: 0.4184
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3880
Epoch 3/10, Batch 20/49, Loss: 0.2850
Epoch 3/10, Batch 30/49, Loss: 0.4395
Epoch 3/10, Batch 40/49, Loss: 0.3709
Epoch 3/10, Train Loss: 0.4318, Valid Loss: 0.3695
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3377
Epoch 4/10, Batch 20/49, Loss: 0.4617
Epoch 4/10, Batch 30/49, Loss: 0.4003
Epoch 4/10, Batch 40/49, Loss: 0.4082
Epoch 4/10, Train Loss: 0.3857, Valid Loss: 0.3220
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3106
Epoch 5/10, Batch 20/49, Loss: 0.2766
Epoch 5/10, Batch 30/49, Loss: 0.3583
Epoch 5/10, Batch 40/49, Loss: 0.3636
Epoch 5/10, Train Loss: 0.3344, Valid Loss: 0.3021
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1927
Epoch 6/10, Batch 20/49, Loss: 0.2532
Epoch 6/10, Batch 30/49, Loss: 0.1812
Epoch 6/10, Batch 40/49, Loss: 0.2547
Epoch 6/10, Train Loss: 0.3132, Valid Loss: 0.2875
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1895
Epoch 7/10, Batch 20/49, Loss: 0.2110
Epoch 7/10, Batch 30/49, Loss: 0.3115
Epoch 7/10, Batch 40/49, Loss: 0.1506
Epoch 7/10, Train Loss: 0.2786, Valid Loss: 0.2933
Epoch 8/10, Batch 10/49, Loss: 0.4349
Epoch 8/10, Batch 20/49, Loss: 0.1985
Epoch 8/10, Batch 30/49, Loss: 0.2232
Epoch 8/10, Batch 40/49, Loss: 0.2315
Epoch 8/10, Train Loss: 0.2635, Valid Loss: 0.2741
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2100
Epoch 9/10, Batch 20/49, Loss: 0.1480
Epoch 9/10, Batch 30/49, Loss: 0.3677
Epoch 9/10, Batch 40/49, Loss: 0.2275
Epoch 9/10, Train Loss: 0.2471, Valid Loss: 0.2664
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3408
Epoch 10/10, Batch 20/49, Loss: 0.1837
Epoch 10/10, Batch 30/49, Loss: 0.2588
Epoch 10/10, Batch 40/49, Loss: 0.2381
Epoch 10/10, Train Loss: 0.2430, Valid Loss: 0.2777
Accuracy: 0.9007
Precision: 0.8965
Recall: 0.9007
F1-score: 0.8978
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2846
Epoch 1/10, Batch 20/49, Loss: 1.1058
Epoch 1/10, Batch 30/49, Loss: 0.8600
Epoch 1/10, Batch 40/49, Loss: 0.7255
Epoch 1/10, Train Loss: 1.0127, Valid Loss: 0.6076
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6049
Epoch 2/10, Batch 20/49, Loss: 0.5654
Epoch 2/10, Batch 30/49, Loss: 0.4800
Epoch 2/10, Batch 40/49, Loss: 0.4437
Epoch 2/10, Train Loss: 0.5600, Valid Loss: 0.4126
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4253
Epoch 3/10, Batch 20/49, Loss: 0.4486
Epoch 3/10, Batch 30/49, Loss: 0.4486
Epoch 3/10, Batch 40/49, Loss: 0.4733
Epoch 3/10, Train Loss: 0.4241, Valid Loss: 0.3544
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3479
Epoch 4/10, Batch 20/49, Loss: 0.2952
Epoch 4/10, Batch 30/49, Loss: 0.3639
Epoch 4/10, Batch 40/49, Loss: 0.3557
Epoch 4/10, Train Loss: 0.3685, Valid Loss: 0.3154
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5422
Epoch 5/10, Batch 20/49, Loss: 0.1822
Epoch 5/10, Batch 30/49, Loss: 0.3744
Epoch 5/10, Batch 40/49, Loss: 0.3898
Epoch 5/10, Train Loss: 0.3410, Valid Loss: 0.2952
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2558
Epoch 6/10, Batch 20/49, Loss: 0.2221
Epoch 6/10, Batch 30/49, Loss: 0.2140
Epoch 6/10, Batch 40/49, Loss: 0.3075
Epoch 6/10, Train Loss: 0.2979, Valid Loss: 0.2688
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2135
Epoch 7/10, Batch 20/49, Loss: 0.2578
Epoch 7/10, Batch 30/49, Loss: 0.4053
Epoch 7/10, Batch 40/49, Loss: 0.2010
Epoch 7/10, Train Loss: 0.2719, Valid Loss: 0.2894
Epoch 8/10, Batch 10/49, Loss: 0.2779
Epoch 8/10, Batch 20/49, Loss: 0.1272
Epoch 8/10, Batch 30/49, Loss: 0.3353
Epoch 8/10, Batch 40/49, Loss: 0.1475
Epoch 8/10, Train Loss: 0.2607, Valid Loss: 0.2565
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1517
Epoch 9/10, Batch 20/49, Loss: 0.1400
Epoch 9/10, Batch 30/49, Loss: 0.3702
Epoch 9/10, Batch 40/49, Loss: 0.3949
Epoch 9/10, Train Loss: 0.2408, Valid Loss: 0.2383
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3355
Epoch 10/10, Batch 20/49, Loss: 0.1995
Epoch 10/10, Batch 30/49, Loss: 0.1935
Epoch 10/10, Batch 40/49, Loss: 0.1237
Epoch 10/10, Train Loss: 0.2263, Valid Loss: 0.2412
Accuracy: 0.9030
Precision: 0.9002
Recall: 0.9030
F1-score: 0.9013
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2763
Epoch 1/10, Batch 20/49, Loss: 1.2120
Epoch 1/10, Batch 30/49, Loss: 0.9005
Epoch 1/10, Batch 40/49, Loss: 0.8252
Epoch 1/10, Train Loss: 1.0079, Valid Loss: 0.6117
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6637
Epoch 2/10, Batch 20/49, Loss: 0.6378
Epoch 2/10, Batch 30/49, Loss: 0.4128
Epoch 2/10, Batch 40/49, Loss: 0.4538
Epoch 2/10, Train Loss: 0.5581, Valid Loss: 0.4341
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4004
Epoch 3/10, Batch 20/49, Loss: 0.3825
Epoch 3/10, Batch 30/49, Loss: 0.5720
Epoch 3/10, Batch 40/49, Loss: 0.3834
Epoch 3/10, Train Loss: 0.4227, Valid Loss: 0.3688
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4075
Epoch 4/10, Batch 20/49, Loss: 0.3004
Epoch 4/10, Batch 30/49, Loss: 0.4074
Epoch 4/10, Batch 40/49, Loss: 0.5845
Epoch 4/10, Train Loss: 0.3659, Valid Loss: 0.3278
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4046
Epoch 5/10, Batch 20/49, Loss: 0.3412
Epoch 5/10, Batch 30/49, Loss: 0.2379
Epoch 5/10, Batch 40/49, Loss: 0.3221
Epoch 5/10, Train Loss: 0.3259, Valid Loss: 0.2900
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2834
Epoch 6/10, Batch 20/49, Loss: 0.3481
Epoch 6/10, Batch 30/49, Loss: 0.3065
Epoch 6/10, Batch 40/49, Loss: 0.3060
Epoch 6/10, Train Loss: 0.2910, Valid Loss: 0.2719
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1779
Epoch 7/10, Batch 20/49, Loss: 0.2931
Epoch 7/10, Batch 30/49, Loss: 0.1824
Epoch 7/10, Batch 40/49, Loss: 0.1498
Epoch 7/10, Train Loss: 0.2567, Valid Loss: 0.2863
Epoch 8/10, Batch 10/49, Loss: 0.2770
Epoch 8/10, Batch 20/49, Loss: 0.2081
Epoch 8/10, Batch 30/49, Loss: 0.2299
Epoch 8/10, Batch 40/49, Loss: 0.1935
Epoch 8/10, Train Loss: 0.2427, Valid Loss: 0.2594
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3104
Epoch 9/10, Batch 20/49, Loss: 0.1292
Epoch 9/10, Batch 30/49, Loss: 0.2652
Epoch 9/10, Batch 40/49, Loss: 0.2583
Epoch 9/10, Train Loss: 0.2334, Valid Loss: 0.2479
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3907
Epoch 10/10, Batch 20/49, Loss: 0.2306
Epoch 10/10, Batch 30/49, Loss: 0.1872
Epoch 10/10, Batch 40/49, Loss: 0.1802
Epoch 10/10, Train Loss: 0.2088, Valid Loss: 0.2527
Accuracy: 0.9042
Precision: 0.9013
Recall: 0.9042
F1-score: 0.9004
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1637
Epoch 1/10, Batch 20/49, Loss: 1.0938
Epoch 1/10, Batch 30/49, Loss: 0.8119
Epoch 1/10, Batch 40/49, Loss: 0.8883
Epoch 1/10, Train Loss: 1.0298, Valid Loss: 0.6287
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5593
Epoch 2/10, Batch 20/49, Loss: 0.6217
Epoch 2/10, Batch 30/49, Loss: 0.5705
Epoch 2/10, Batch 40/49, Loss: 0.4900
Epoch 2/10, Train Loss: 0.5684, Valid Loss: 0.4186
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4438
Epoch 3/10, Batch 20/49, Loss: 0.3872
Epoch 3/10, Batch 30/49, Loss: 0.3632
Epoch 3/10, Batch 40/49, Loss: 0.3614
Epoch 3/10, Train Loss: 0.4288, Valid Loss: 0.3585
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2857
Epoch 4/10, Batch 20/49, Loss: 0.3474
Epoch 4/10, Batch 30/49, Loss: 0.4873
Epoch 4/10, Batch 40/49, Loss: 0.3436
Epoch 4/10, Train Loss: 0.3761, Valid Loss: 0.3142
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3561
Epoch 5/10, Batch 20/49, Loss: 0.3052
Epoch 5/10, Batch 30/49, Loss: 0.3063
Epoch 5/10, Batch 40/49, Loss: 0.2640
Epoch 5/10, Train Loss: 0.3381, Valid Loss: 0.2868
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2845
Epoch 6/10, Batch 20/49, Loss: 0.1431
Epoch 6/10, Batch 30/49, Loss: 0.2383
Epoch 6/10, Batch 40/49, Loss: 0.2319
Epoch 6/10, Train Loss: 0.3120, Valid Loss: 0.2743
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1887
Epoch 7/10, Batch 20/49, Loss: 0.3827
Epoch 7/10, Batch 30/49, Loss: 0.3135
Epoch 7/10, Batch 40/49, Loss: 0.1782
Epoch 7/10, Train Loss: 0.2641, Valid Loss: 0.2707
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3417
Epoch 8/10, Batch 20/49, Loss: 0.2005
Epoch 8/10, Batch 30/49, Loss: 0.2459
Epoch 8/10, Batch 40/49, Loss: 0.2172
Epoch 8/10, Train Loss: 0.2569, Valid Loss: 0.2504
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2125
Epoch 9/10, Batch 20/49, Loss: 0.1772
Epoch 9/10, Batch 30/49, Loss: 0.3370
Epoch 9/10, Batch 40/49, Loss: 0.4095
Epoch 9/10, Train Loss: 0.2434, Valid Loss: 0.2390
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3043
Epoch 10/10, Batch 20/49, Loss: 0.2843
Epoch 10/10, Batch 30/49, Loss: 0.3251
Epoch 10/10, Batch 40/49, Loss: 0.2403
Epoch 10/10, Train Loss: 0.2308, Valid Loss: 0.2436
Accuracy: 0.9077
Precision: 0.9046
Recall: 0.9077
F1-score: 0.9051
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2833
Epoch 1/10, Batch 20/49, Loss: 1.1096
Epoch 1/10, Batch 30/49, Loss: 0.8757
Epoch 1/10, Batch 40/49, Loss: 0.8428
Epoch 1/10, Train Loss: 1.0377, Valid Loss: 0.6471
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5779
Epoch 2/10, Batch 20/49, Loss: 0.7254
Epoch 2/10, Batch 30/49, Loss: 0.5083
Epoch 2/10, Batch 40/49, Loss: 0.4002
Epoch 2/10, Train Loss: 0.5588, Valid Loss: 0.4708
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3782
Epoch 3/10, Batch 20/49, Loss: 0.3259
Epoch 3/10, Batch 30/49, Loss: 0.5574
Epoch 3/10, Batch 40/49, Loss: 0.3742
Epoch 3/10, Train Loss: 0.4394, Valid Loss: 0.4129
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3076
Epoch 4/10, Batch 20/49, Loss: 0.2880
Epoch 4/10, Batch 30/49, Loss: 0.3589
Epoch 4/10, Batch 40/49, Loss: 0.4759
Epoch 4/10, Train Loss: 0.3764, Valid Loss: 0.3709
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5052
Epoch 5/10, Batch 20/49, Loss: 0.2869
Epoch 5/10, Batch 30/49, Loss: 0.2661
Epoch 5/10, Batch 40/49, Loss: 0.1801
Epoch 5/10, Train Loss: 0.3394, Valid Loss: 0.3464
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3471
Epoch 6/10, Batch 20/49, Loss: 0.2587
Epoch 6/10, Batch 30/49, Loss: 0.1808
Epoch 6/10, Batch 40/49, Loss: 0.2261
Epoch 6/10, Train Loss: 0.3095, Valid Loss: 0.3315
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3208
Epoch 7/10, Batch 20/49, Loss: 0.2407
Epoch 7/10, Batch 30/49, Loss: 0.2144
Epoch 7/10, Batch 40/49, Loss: 0.1396
Epoch 7/10, Train Loss: 0.2716, Valid Loss: 0.3379
Epoch 8/10, Batch 10/49, Loss: 0.2863
Epoch 8/10, Batch 20/49, Loss: 0.2215
Epoch 8/10, Batch 30/49, Loss: 0.2184
Epoch 8/10, Batch 40/49, Loss: 0.2549
Epoch 8/10, Train Loss: 0.2651, Valid Loss: 0.3160
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3776
Epoch 9/10, Batch 20/49, Loss: 0.1979
Epoch 9/10, Batch 30/49, Loss: 0.2887
Epoch 9/10, Batch 40/49, Loss: 0.2682
Epoch 9/10, Train Loss: 0.2483, Valid Loss: 0.3184
Epoch 10/10, Batch 10/49, Loss: 0.3218
Epoch 10/10, Batch 20/49, Loss: 0.3471
Epoch 10/10, Batch 30/49, Loss: 0.2353
Epoch 10/10, Batch 40/49, Loss: 0.1490
Epoch 10/10, Train Loss: 0.2278, Valid Loss: 0.3162
Accuracy: 0.9019
Precision: 0.8982
Recall: 0.9019
F1-score: 0.8977
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2055
Epoch 1/10, Batch 20/49, Loss: 1.1149
Epoch 1/10, Batch 30/49, Loss: 0.8409
Epoch 1/10, Batch 40/49, Loss: 0.7861
Epoch 1/10, Train Loss: 1.0149, Valid Loss: 0.6152
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5798
Epoch 2/10, Batch 20/49, Loss: 0.5878
Epoch 2/10, Batch 30/49, Loss: 0.5052
Epoch 2/10, Batch 40/49, Loss: 0.3936
Epoch 2/10, Train Loss: 0.5605, Valid Loss: 0.4306
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4326
Epoch 3/10, Batch 20/49, Loss: 0.2620
Epoch 3/10, Batch 30/49, Loss: 0.4504
Epoch 3/10, Batch 40/49, Loss: 0.4163
Epoch 3/10, Train Loss: 0.4253, Valid Loss: 0.3720
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4622
Epoch 4/10, Batch 20/49, Loss: 0.3966
Epoch 4/10, Batch 30/49, Loss: 0.4888
Epoch 4/10, Batch 40/49, Loss: 0.3787
Epoch 4/10, Train Loss: 0.3674, Valid Loss: 0.3315
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4443
Epoch 5/10, Batch 20/49, Loss: 0.2658
Epoch 5/10, Batch 30/49, Loss: 0.1885
Epoch 5/10, Batch 40/49, Loss: 0.2154
Epoch 5/10, Train Loss: 0.3244, Valid Loss: 0.3021
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2815
Epoch 6/10, Batch 20/49, Loss: 0.1554
Epoch 6/10, Batch 30/49, Loss: 0.2881
Epoch 6/10, Batch 40/49, Loss: 0.2476
Epoch 6/10, Train Loss: 0.2947, Valid Loss: 0.2867
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2641
Epoch 7/10, Batch 20/49, Loss: 0.2818
Epoch 7/10, Batch 30/49, Loss: 0.2787
Epoch 7/10, Batch 40/49, Loss: 0.2032
Epoch 7/10, Train Loss: 0.2621, Valid Loss: 0.2752
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2453
Epoch 8/10, Batch 20/49, Loss: 0.1242
Epoch 8/10, Batch 30/49, Loss: 0.1814
Epoch 8/10, Batch 40/49, Loss: 0.2680
Epoch 8/10, Train Loss: 0.2625, Valid Loss: 0.2770
Epoch 9/10, Batch 10/49, Loss: 0.2929
Epoch 9/10, Batch 20/49, Loss: 0.1064
Epoch 9/10, Batch 30/49, Loss: 0.3302
Epoch 9/10, Batch 40/49, Loss: 0.3607
Epoch 9/10, Train Loss: 0.2384, Valid Loss: 0.2556
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2725
Epoch 10/10, Batch 20/49, Loss: 0.1330
Epoch 10/10, Batch 30/49, Loss: 0.1458
Epoch 10/10, Batch 40/49, Loss: 0.2138
Epoch 10/10, Train Loss: 0.2219, Valid Loss: 0.2495
Model saved!
Accuracy: 0.9065
Precision: 0.9038
Recall: 0.9065
F1-score: 0.9023
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2425
Epoch 1/10, Batch 20/49, Loss: 1.1159
Epoch 1/10, Batch 30/49, Loss: 0.9155
Epoch 1/10, Batch 40/49, Loss: 0.9845
Epoch 1/10, Train Loss: 1.0349, Valid Loss: 0.6539
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5864
Epoch 2/10, Batch 20/49, Loss: 0.5924
Epoch 2/10, Batch 30/49, Loss: 0.5900
Epoch 2/10, Batch 40/49, Loss: 0.4217
Epoch 2/10, Train Loss: 0.5600, Valid Loss: 0.4559
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5601
Epoch 3/10, Batch 20/49, Loss: 0.4240
Epoch 3/10, Batch 30/49, Loss: 0.4076
Epoch 3/10, Batch 40/49, Loss: 0.4163
Epoch 3/10, Train Loss: 0.4312, Valid Loss: 0.3900
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3047
Epoch 4/10, Batch 20/49, Loss: 0.4125
Epoch 4/10, Batch 30/49, Loss: 0.3905
Epoch 4/10, Batch 40/49, Loss: 0.5336
Epoch 4/10, Train Loss: 0.3700, Valid Loss: 0.3523
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5262
Epoch 5/10, Batch 20/49, Loss: 0.2798
Epoch 5/10, Batch 30/49, Loss: 0.3289
Epoch 5/10, Batch 40/49, Loss: 0.3542
Epoch 5/10, Train Loss: 0.3269, Valid Loss: 0.3200
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3225
Epoch 6/10, Batch 20/49, Loss: 0.1934
Epoch 6/10, Batch 30/49, Loss: 0.2068
Epoch 6/10, Batch 40/49, Loss: 0.2849
Epoch 6/10, Train Loss: 0.3010, Valid Loss: 0.2970
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3126
Epoch 7/10, Batch 20/49, Loss: 0.1680
Epoch 7/10, Batch 30/49, Loss: 0.2986
Epoch 7/10, Batch 40/49, Loss: 0.1633
Epoch 7/10, Train Loss: 0.2631, Valid Loss: 0.3053
Epoch 8/10, Batch 10/49, Loss: 0.3644
Epoch 8/10, Batch 20/49, Loss: 0.1669
Epoch 8/10, Batch 30/49, Loss: 0.3002
Epoch 8/10, Batch 40/49, Loss: 0.3818
Epoch 8/10, Train Loss: 0.2646, Valid Loss: 0.2931
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2093
Epoch 9/10, Batch 20/49, Loss: 0.2750
Epoch 9/10, Batch 30/49, Loss: 0.3555
Epoch 9/10, Batch 40/49, Loss: 0.4196
Epoch 9/10, Train Loss: 0.2349, Valid Loss: 0.2821
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2926
Epoch 10/10, Batch 20/49, Loss: 0.1512
Epoch 10/10, Batch 30/49, Loss: 0.1935
Epoch 10/10, Batch 40/49, Loss: 0.1316
Epoch 10/10, Train Loss: 0.2186, Valid Loss: 0.2706
Model saved!
Accuracy: 0.9089
Precision: 0.9059
Recall: 0.9089
F1-score: 0.9064
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2361
Epoch 1/10, Batch 20/49, Loss: 1.2606
Epoch 1/10, Batch 30/49, Loss: 0.8396
Epoch 1/10, Batch 40/49, Loss: 0.8635
Epoch 1/10, Train Loss: 1.0089, Valid Loss: 0.5908
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5783
Epoch 2/10, Batch 20/49, Loss: 0.6110
Epoch 2/10, Batch 30/49, Loss: 0.5027
Epoch 2/10, Batch 40/49, Loss: 0.6139
Epoch 2/10, Train Loss: 0.5390, Valid Loss: 0.3915
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4183
Epoch 3/10, Batch 20/49, Loss: 0.5169
Epoch 3/10, Batch 30/49, Loss: 0.5788
Epoch 3/10, Batch 40/49, Loss: 0.3041
Epoch 3/10, Train Loss: 0.4195, Valid Loss: 0.3427
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3348
Epoch 4/10, Batch 20/49, Loss: 0.3590
Epoch 4/10, Batch 30/49, Loss: 0.3435
Epoch 4/10, Batch 40/49, Loss: 0.3098
Epoch 4/10, Train Loss: 0.3618, Valid Loss: 0.3020
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4068
Epoch 5/10, Batch 20/49, Loss: 0.4128
Epoch 5/10, Batch 30/49, Loss: 0.2224
Epoch 5/10, Batch 40/49, Loss: 0.1911
Epoch 5/10, Train Loss: 0.3342, Valid Loss: 0.2771
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3671
Epoch 6/10, Batch 20/49, Loss: 0.2447
Epoch 6/10, Batch 30/49, Loss: 0.3924
Epoch 6/10, Batch 40/49, Loss: 0.2764
Epoch 6/10, Train Loss: 0.2967, Valid Loss: 0.2600
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1936
Epoch 7/10, Batch 20/49, Loss: 0.2708
Epoch 7/10, Batch 30/49, Loss: 0.2518
Epoch 7/10, Batch 40/49, Loss: 0.1253
Epoch 7/10, Train Loss: 0.2603, Valid Loss: 0.2555
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1795
Epoch 8/10, Batch 20/49, Loss: 0.1491
Epoch 8/10, Batch 30/49, Loss: 0.1159
Epoch 8/10, Batch 40/49, Loss: 0.1143
Epoch 8/10, Train Loss: 0.2569, Valid Loss: 0.2562
Epoch 9/10, Batch 10/49, Loss: 0.2486
Epoch 9/10, Batch 20/49, Loss: 0.2236
Epoch 9/10, Batch 30/49, Loss: 0.3754
Epoch 9/10, Batch 40/49, Loss: 0.4127
Epoch 9/10, Train Loss: 0.2368, Valid Loss: 0.2418
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2988
Epoch 10/10, Batch 20/49, Loss: 0.1774
Epoch 10/10, Batch 30/49, Loss: 0.0854
Epoch 10/10, Batch 40/49, Loss: 0.2318
Epoch 10/10, Train Loss: 0.2219, Valid Loss: 0.2384
Model saved!
Accuracy: 0.8949
Precision: 0.8912
Recall: 0.8949
F1-score: 0.8897
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1969
Epoch 1/10, Batch 20/49, Loss: 1.1053
Epoch 1/10, Batch 30/49, Loss: 0.7511
Epoch 1/10, Batch 40/49, Loss: 0.7561
Epoch 1/10, Train Loss: 1.0213, Valid Loss: 0.5857
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6203
Epoch 2/10, Batch 20/49, Loss: 0.6787
Epoch 2/10, Batch 30/49, Loss: 0.5601
Epoch 2/10, Batch 40/49, Loss: 0.4595
Epoch 2/10, Train Loss: 0.5473, Valid Loss: 0.3869
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5046
Epoch 3/10, Batch 20/49, Loss: 0.4843
Epoch 3/10, Batch 30/49, Loss: 0.4110
Epoch 3/10, Batch 40/49, Loss: 0.4112
Epoch 3/10, Train Loss: 0.4244, Valid Loss: 0.3278
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3379
Epoch 4/10, Batch 20/49, Loss: 0.4040
Epoch 4/10, Batch 30/49, Loss: 0.3923
Epoch 4/10, Batch 40/49, Loss: 0.3009
Epoch 4/10, Train Loss: 0.3635, Valid Loss: 0.2831
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3037
Epoch 5/10, Batch 20/49, Loss: 0.2133
Epoch 5/10, Batch 30/49, Loss: 0.3605
Epoch 5/10, Batch 40/49, Loss: 0.2584
Epoch 5/10, Train Loss: 0.3276, Valid Loss: 0.2591
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2843
Epoch 6/10, Batch 20/49, Loss: 0.2250
Epoch 6/10, Batch 30/49, Loss: 0.2162
Epoch 6/10, Batch 40/49, Loss: 0.3448
Epoch 6/10, Train Loss: 0.2943, Valid Loss: 0.2484
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2254
Epoch 7/10, Batch 20/49, Loss: 0.2684
Epoch 7/10, Batch 30/49, Loss: 0.2836
Epoch 7/10, Batch 40/49, Loss: 0.0969
Epoch 7/10, Train Loss: 0.2606, Valid Loss: 0.2481
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2858
Epoch 8/10, Batch 20/49, Loss: 0.2040
Epoch 8/10, Batch 30/49, Loss: 0.2283
Epoch 8/10, Batch 40/49, Loss: 0.2125
Epoch 8/10, Train Loss: 0.2538, Valid Loss: 0.2335
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2822
Epoch 9/10, Batch 20/49, Loss: 0.1465
Epoch 9/10, Batch 30/49, Loss: 0.2552
Epoch 9/10, Batch 40/49, Loss: 0.2556
Epoch 9/10, Train Loss: 0.2419, Valid Loss: 0.2215
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.4565
Epoch 10/10, Batch 20/49, Loss: 0.1902
Epoch 10/10, Batch 30/49, Loss: 0.2188
Epoch 10/10, Batch 40/49, Loss: 0.2381
Epoch 10/10, Train Loss: 0.2184, Valid Loss: 0.2120
Model saved!
Accuracy: 0.9077
Precision: 0.9052
Recall: 0.9077
F1-score: 0.9060
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1981
Epoch 1/10, Batch 20/49, Loss: 1.1200
Epoch 1/10, Batch 30/49, Loss: 0.8490
Epoch 1/10, Batch 40/49, Loss: 0.7455
Epoch 1/10, Train Loss: 1.0131, Valid Loss: 0.5806
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5590
Epoch 2/10, Batch 20/49, Loss: 0.7447
Epoch 2/10, Batch 30/49, Loss: 0.4946
Epoch 2/10, Batch 40/49, Loss: 0.4650
Epoch 2/10, Train Loss: 0.5434, Valid Loss: 0.3803
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4150
Epoch 3/10, Batch 20/49, Loss: 0.3066
Epoch 3/10, Batch 30/49, Loss: 0.5369
Epoch 3/10, Batch 40/49, Loss: 0.3895
Epoch 3/10, Train Loss: 0.4158, Valid Loss: 0.3265
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2800
Epoch 4/10, Batch 20/49, Loss: 0.3242
Epoch 4/10, Batch 30/49, Loss: 0.3756
Epoch 4/10, Batch 40/49, Loss: 0.3858
Epoch 4/10, Train Loss: 0.3695, Valid Loss: 0.2852
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3441
Epoch 5/10, Batch 20/49, Loss: 0.2904
Epoch 5/10, Batch 30/49, Loss: 0.2659
Epoch 5/10, Batch 40/49, Loss: 0.4093
Epoch 5/10, Train Loss: 0.3203, Valid Loss: 0.2630
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3556
Epoch 6/10, Batch 20/49, Loss: 0.2833
Epoch 6/10, Batch 30/49, Loss: 0.1875
Epoch 6/10, Batch 40/49, Loss: 0.2858
Epoch 6/10, Train Loss: 0.2950, Valid Loss: 0.2478
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3568
Epoch 7/10, Batch 20/49, Loss: 0.3456
Epoch 7/10, Batch 30/49, Loss: 0.1415
Epoch 7/10, Batch 40/49, Loss: 0.2030
Epoch 7/10, Train Loss: 0.2604, Valid Loss: 0.2567
Epoch 8/10, Batch 10/49, Loss: 0.2979
Epoch 8/10, Batch 20/49, Loss: 0.3196
Epoch 8/10, Batch 30/49, Loss: 0.2154
Epoch 8/10, Batch 40/49, Loss: 0.1503
Epoch 8/10, Train Loss: 0.2438, Valid Loss: 0.2366
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1474
Epoch 9/10, Batch 20/49, Loss: 0.1719
Epoch 9/10, Batch 30/49, Loss: 0.4337
Epoch 9/10, Batch 40/49, Loss: 0.2984
Epoch 9/10, Train Loss: 0.2429, Valid Loss: 0.2346
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3430
Epoch 10/10, Batch 20/49, Loss: 0.1745
Epoch 10/10, Batch 30/49, Loss: 0.2393
Epoch 10/10, Batch 40/49, Loss: 0.2021
Epoch 10/10, Train Loss: 0.2219, Valid Loss: 0.2389
Accuracy: 0.9089
Precision: 0.9054
Recall: 0.9089
F1-score: 0.9062
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2043
Epoch 1/10, Batch 20/49, Loss: 1.1185
Epoch 1/10, Batch 30/49, Loss: 0.8739
Epoch 1/10, Batch 40/49, Loss: 0.7449
Epoch 1/10, Train Loss: 0.9974, Valid Loss: 0.6287
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5435
Epoch 2/10, Batch 20/49, Loss: 0.5120
Epoch 2/10, Batch 30/49, Loss: 0.4859
Epoch 2/10, Batch 40/49, Loss: 0.4572
Epoch 2/10, Train Loss: 0.5221, Valid Loss: 0.4328
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4258
Epoch 3/10, Batch 20/49, Loss: 0.3849
Epoch 3/10, Batch 30/49, Loss: 0.4478
Epoch 3/10, Batch 40/49, Loss: 0.4072
Epoch 3/10, Train Loss: 0.3931, Valid Loss: 0.3704
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2734
Epoch 4/10, Batch 20/49, Loss: 0.3178
Epoch 4/10, Batch 30/49, Loss: 0.4037
Epoch 4/10, Batch 40/49, Loss: 0.3919
Epoch 4/10, Train Loss: 0.3405, Valid Loss: 0.3144
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4198
Epoch 5/10, Batch 20/49, Loss: 0.2245
Epoch 5/10, Batch 30/49, Loss: 0.2130
Epoch 5/10, Batch 40/49, Loss: 0.3471
Epoch 5/10, Train Loss: 0.3052, Valid Loss: 0.2837
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3527
Epoch 6/10, Batch 20/49, Loss: 0.1611
Epoch 6/10, Batch 30/49, Loss: 0.3014
Epoch 6/10, Batch 40/49, Loss: 0.2980
Epoch 6/10, Train Loss: 0.2825, Valid Loss: 0.2669
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2348
Epoch 7/10, Batch 20/49, Loss: 0.2035
Epoch 7/10, Batch 30/49, Loss: 0.2716
Epoch 7/10, Batch 40/49, Loss: 0.2154
Epoch 7/10, Train Loss: 0.2429, Valid Loss: 0.2641
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1663
Epoch 8/10, Batch 20/49, Loss: 0.1739
Epoch 8/10, Batch 30/49, Loss: 0.2594
Epoch 8/10, Batch 40/49, Loss: 0.2175
Epoch 8/10, Train Loss: 0.2338, Valid Loss: 0.2485
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1976
Epoch 9/10, Batch 20/49, Loss: 0.1446
Epoch 9/10, Batch 30/49, Loss: 0.3912
Epoch 9/10, Batch 40/49, Loss: 0.2948
Epoch 9/10, Train Loss: 0.2223, Valid Loss: 0.2371
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1864
Epoch 10/10, Batch 20/49, Loss: 0.1806
Epoch 10/10, Batch 30/49, Loss: 0.1524
Epoch 10/10, Batch 40/49, Loss: 0.2019
Epoch 10/10, Train Loss: 0.2073, Valid Loss: 0.2400
Accuracy: 0.9054
Precision: 0.9020
Recall: 0.9054
F1-score: 0.9026
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2449
Epoch 1/10, Batch 20/49, Loss: 1.0553
Epoch 1/10, Batch 30/49, Loss: 0.7873
Epoch 1/10, Batch 40/49, Loss: 0.8764
Epoch 1/10, Train Loss: 1.0354, Valid Loss: 0.6600
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6894
Epoch 2/10, Batch 20/49, Loss: 0.7647
Epoch 2/10, Batch 30/49, Loss: 0.4936
Epoch 2/10, Batch 40/49, Loss: 0.5800
Epoch 2/10, Train Loss: 0.5712, Valid Loss: 0.4537
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4775
Epoch 3/10, Batch 20/49, Loss: 0.3363
Epoch 3/10, Batch 30/49, Loss: 0.3511
Epoch 3/10, Batch 40/49, Loss: 0.4190
Epoch 3/10, Train Loss: 0.4300, Valid Loss: 0.3922
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3513
Epoch 4/10, Batch 20/49, Loss: 0.3470
Epoch 4/10, Batch 30/49, Loss: 0.5044
Epoch 4/10, Batch 40/49, Loss: 0.3997
Epoch 4/10, Train Loss: 0.3976, Valid Loss: 0.3508
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3524
Epoch 5/10, Batch 20/49, Loss: 0.3502
Epoch 5/10, Batch 30/49, Loss: 0.2865
Epoch 5/10, Batch 40/49, Loss: 0.2733
Epoch 5/10, Train Loss: 0.3254, Valid Loss: 0.3283
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2117
Epoch 6/10, Batch 20/49, Loss: 0.2057
Epoch 6/10, Batch 30/49, Loss: 0.2901
Epoch 6/10, Batch 40/49, Loss: 0.3161
Epoch 6/10, Train Loss: 0.3029, Valid Loss: 0.3028
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2806
Epoch 7/10, Batch 20/49, Loss: 0.3297
Epoch 7/10, Batch 30/49, Loss: 0.2229
Epoch 7/10, Batch 40/49, Loss: 0.1741
Epoch 7/10, Train Loss: 0.2684, Valid Loss: 0.3002
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2476
Epoch 8/10, Batch 20/49, Loss: 0.1672
Epoch 8/10, Batch 30/49, Loss: 0.2571
Epoch 8/10, Batch 40/49, Loss: 0.1875
Epoch 8/10, Train Loss: 0.2684, Valid Loss: 0.2920
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3529
Epoch 9/10, Batch 20/49, Loss: 0.1259
Epoch 9/10, Batch 30/49, Loss: 0.3732
Epoch 9/10, Batch 40/49, Loss: 0.3993
Epoch 9/10, Train Loss: 0.2551, Valid Loss: 0.2753
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3568
Epoch 10/10, Batch 20/49, Loss: 0.2170
Epoch 10/10, Batch 30/49, Loss: 0.2435
Epoch 10/10, Batch 40/49, Loss: 0.1728
Epoch 10/10, Train Loss: 0.2260, Valid Loss: 0.2766
Accuracy: 0.9159
Precision: 0.9132
Recall: 0.9159
F1-score: 0.9141
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2931
Epoch 1/10, Batch 20/49, Loss: 1.1209
Epoch 1/10, Batch 30/49, Loss: 0.9144
Epoch 1/10, Batch 40/49, Loss: 0.8618
Epoch 1/10, Train Loss: 0.9980, Valid Loss: 0.6115
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6445
Epoch 2/10, Batch 20/49, Loss: 0.7511
Epoch 2/10, Batch 30/49, Loss: 0.5307
Epoch 2/10, Batch 40/49, Loss: 0.4249
Epoch 2/10, Train Loss: 0.5338, Valid Loss: 0.4172
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3033
Epoch 3/10, Batch 20/49, Loss: 0.3211
Epoch 3/10, Batch 30/49, Loss: 0.3555
Epoch 3/10, Batch 40/49, Loss: 0.3769
Epoch 3/10, Train Loss: 0.3945, Valid Loss: 0.3648
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3857
Epoch 4/10, Batch 20/49, Loss: 0.3083
Epoch 4/10, Batch 30/49, Loss: 0.3943
Epoch 4/10, Batch 40/49, Loss: 0.4593
Epoch 4/10, Train Loss: 0.3514, Valid Loss: 0.3181
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5437
Epoch 5/10, Batch 20/49, Loss: 0.2401
Epoch 5/10, Batch 30/49, Loss: 0.2610
Epoch 5/10, Batch 40/49, Loss: 0.2787
Epoch 5/10, Train Loss: 0.3186, Valid Loss: 0.2997
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.4282
Epoch 6/10, Batch 20/49, Loss: 0.2357
Epoch 6/10, Batch 30/49, Loss: 0.2626
Epoch 6/10, Batch 40/49, Loss: 0.1599
Epoch 6/10, Train Loss: 0.2919, Valid Loss: 0.2824
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3050
Epoch 7/10, Batch 20/49, Loss: 0.2670
Epoch 7/10, Batch 30/49, Loss: 0.2432
Epoch 7/10, Batch 40/49, Loss: 0.1705
Epoch 7/10, Train Loss: 0.2571, Valid Loss: 0.2861
Epoch 8/10, Batch 10/49, Loss: 0.1402
Epoch 8/10, Batch 20/49, Loss: 0.2263
Epoch 8/10, Batch 30/49, Loss: 0.2152
Epoch 8/10, Batch 40/49, Loss: 0.2125
Epoch 8/10, Train Loss: 0.2463, Valid Loss: 0.2657
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1428
Epoch 9/10, Batch 20/49, Loss: 0.1320
Epoch 9/10, Batch 30/49, Loss: 0.2773
Epoch 9/10, Batch 40/49, Loss: 0.4076
Epoch 9/10, Train Loss: 0.2221, Valid Loss: 0.2586
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1152
Epoch 10/10, Batch 20/49, Loss: 0.3087
Epoch 10/10, Batch 30/49, Loss: 0.2754
Epoch 10/10, Batch 40/49, Loss: 0.1773
Epoch 10/10, Train Loss: 0.2118, Valid Loss: 0.2556
Model saved!
Accuracy: 0.9065
Precision: 0.9033
Recall: 0.9065
F1-score: 0.9036
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2907
Epoch 1/10, Batch 20/49, Loss: 1.1526
Epoch 1/10, Batch 30/49, Loss: 0.8538
Epoch 1/10, Batch 40/49, Loss: 0.6976
Epoch 1/10, Train Loss: 1.0001, Valid Loss: 0.5930
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5615
Epoch 2/10, Batch 20/49, Loss: 0.6072
Epoch 2/10, Batch 30/49, Loss: 0.3966
Epoch 2/10, Batch 40/49, Loss: 0.4365
Epoch 2/10, Train Loss: 0.5362, Valid Loss: 0.4152
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4392
Epoch 3/10, Batch 20/49, Loss: 0.3786
Epoch 3/10, Batch 30/49, Loss: 0.4553
Epoch 3/10, Batch 40/49, Loss: 0.3074
Epoch 3/10, Train Loss: 0.3950, Valid Loss: 0.3646
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4070
Epoch 4/10, Batch 20/49, Loss: 0.3271
Epoch 4/10, Batch 30/49, Loss: 0.3768
Epoch 4/10, Batch 40/49, Loss: 0.4855
Epoch 4/10, Train Loss: 0.3536, Valid Loss: 0.3169
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4764
Epoch 5/10, Batch 20/49, Loss: 0.2725
Epoch 5/10, Batch 30/49, Loss: 0.1973
Epoch 5/10, Batch 40/49, Loss: 0.2881
Epoch 5/10, Train Loss: 0.3136, Valid Loss: 0.2928
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3724
Epoch 6/10, Batch 20/49, Loss: 0.2868
Epoch 6/10, Batch 30/49, Loss: 0.2841
Epoch 6/10, Batch 40/49, Loss: 0.2201
Epoch 6/10, Train Loss: 0.2858, Valid Loss: 0.2863
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2507
Epoch 7/10, Batch 20/49, Loss: 0.2298
Epoch 7/10, Batch 30/49, Loss: 0.1422
Epoch 7/10, Batch 40/49, Loss: 0.1838
Epoch 7/10, Train Loss: 0.2407, Valid Loss: 0.2731
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2809
Epoch 8/10, Batch 20/49, Loss: 0.1706
Epoch 8/10, Batch 30/49, Loss: 0.2091
Epoch 8/10, Batch 40/49, Loss: 0.1195
Epoch 8/10, Train Loss: 0.2444, Valid Loss: 0.2760
Epoch 9/10, Batch 10/49, Loss: 0.2343
Epoch 9/10, Batch 20/49, Loss: 0.1617
Epoch 9/10, Batch 30/49, Loss: 0.2287
Epoch 9/10, Batch 40/49, Loss: 0.4546
Epoch 9/10, Train Loss: 0.2261, Valid Loss: 0.2620
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3067
Epoch 10/10, Batch 20/49, Loss: 0.1692
Epoch 10/10, Batch 30/49, Loss: 0.1424
Epoch 10/10, Batch 40/49, Loss: 0.2396
Epoch 10/10, Train Loss: 0.2125, Valid Loss: 0.2644
Accuracy: 0.9054
Precision: 0.9024
Recall: 0.9054
F1-score: 0.9026
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2229
Epoch 1/10, Batch 20/49, Loss: 1.0724
Epoch 1/10, Batch 30/49, Loss: 0.8284
Epoch 1/10, Batch 40/49, Loss: 0.7667
Epoch 1/10, Train Loss: 1.0193, Valid Loss: 0.5990
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6202
Epoch 2/10, Batch 20/49, Loss: 0.5704
Epoch 2/10, Batch 30/49, Loss: 0.4155
Epoch 2/10, Batch 40/49, Loss: 0.4297
Epoch 2/10, Train Loss: 0.5469, Valid Loss: 0.4078
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3606
Epoch 3/10, Batch 20/49, Loss: 0.3560
Epoch 3/10, Batch 30/49, Loss: 0.3776
Epoch 3/10, Batch 40/49, Loss: 0.4677
Epoch 3/10, Train Loss: 0.4253, Valid Loss: 0.3523
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3208
Epoch 4/10, Batch 20/49, Loss: 0.3645
Epoch 4/10, Batch 30/49, Loss: 0.3908
Epoch 4/10, Batch 40/49, Loss: 0.3383
Epoch 4/10, Train Loss: 0.3710, Valid Loss: 0.3066
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3844
Epoch 5/10, Batch 20/49, Loss: 0.3219
Epoch 5/10, Batch 30/49, Loss: 0.2192
Epoch 5/10, Batch 40/49, Loss: 0.2455
Epoch 5/10, Train Loss: 0.3183, Valid Loss: 0.2845
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2636
Epoch 6/10, Batch 20/49, Loss: 0.3055
Epoch 6/10, Batch 30/49, Loss: 0.2753
Epoch 6/10, Batch 40/49, Loss: 0.2169
Epoch 6/10, Train Loss: 0.2921, Valid Loss: 0.2652
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2345
Epoch 7/10, Batch 20/49, Loss: 0.2853
Epoch 7/10, Batch 30/49, Loss: 0.1929
Epoch 7/10, Batch 40/49, Loss: 0.1384
Epoch 7/10, Train Loss: 0.2713, Valid Loss: 0.2732
Epoch 8/10, Batch 10/49, Loss: 0.2643
Epoch 8/10, Batch 20/49, Loss: 0.2642
Epoch 8/10, Batch 30/49, Loss: 0.3695
Epoch 8/10, Batch 40/49, Loss: 0.2779
Epoch 8/10, Train Loss: 0.2583, Valid Loss: 0.2537
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3211
Epoch 9/10, Batch 20/49, Loss: 0.1756
Epoch 9/10, Batch 30/49, Loss: 0.3893
Epoch 9/10, Batch 40/49, Loss: 0.3073
Epoch 9/10, Train Loss: 0.2400, Valid Loss: 0.2403
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1914
Epoch 10/10, Batch 20/49, Loss: 0.2226
Epoch 10/10, Batch 30/49, Loss: 0.1461
Epoch 10/10, Batch 40/49, Loss: 0.1778
Epoch 10/10, Train Loss: 0.2161, Valid Loss: 0.2415
Accuracy: 0.9007
Precision: 0.8959
Recall: 0.9007
F1-score: 0.8976
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2076
Epoch 1/10, Batch 20/49, Loss: 1.1784
Epoch 1/10, Batch 30/49, Loss: 0.7831
Epoch 1/10, Batch 40/49, Loss: 0.9568
Epoch 1/10, Train Loss: 1.0275, Valid Loss: 0.6422
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6884
Epoch 2/10, Batch 20/49, Loss: 0.6007
Epoch 2/10, Batch 30/49, Loss: 0.4647
Epoch 2/10, Batch 40/49, Loss: 0.5898
Epoch 2/10, Train Loss: 0.5548, Valid Loss: 0.4296
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4294
Epoch 3/10, Batch 20/49, Loss: 0.4229
Epoch 3/10, Batch 30/49, Loss: 0.5105
Epoch 3/10, Batch 40/49, Loss: 0.4167
Epoch 3/10, Train Loss: 0.4266, Valid Loss: 0.3749
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3703
Epoch 4/10, Batch 20/49, Loss: 0.5467
Epoch 4/10, Batch 30/49, Loss: 0.5329
Epoch 4/10, Batch 40/49, Loss: 0.3475
Epoch 4/10, Train Loss: 0.3703, Valid Loss: 0.3150
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4969
Epoch 5/10, Batch 20/49, Loss: 0.2388
Epoch 5/10, Batch 30/49, Loss: 0.3863
Epoch 5/10, Batch 40/49, Loss: 0.3030
Epoch 5/10, Train Loss: 0.3240, Valid Loss: 0.2825
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2815
Epoch 6/10, Batch 20/49, Loss: 0.1763
Epoch 6/10, Batch 30/49, Loss: 0.3628
Epoch 6/10, Batch 40/49, Loss: 0.2843
Epoch 6/10, Train Loss: 0.2990, Valid Loss: 0.2632
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2320
Epoch 7/10, Batch 20/49, Loss: 0.2575
Epoch 7/10, Batch 30/49, Loss: 0.2056
Epoch 7/10, Batch 40/49, Loss: 0.1946
Epoch 7/10, Train Loss: 0.2670, Valid Loss: 0.2690
Epoch 8/10, Batch 10/49, Loss: 0.2299
Epoch 8/10, Batch 20/49, Loss: 0.2324
Epoch 8/10, Batch 30/49, Loss: 0.2789
Epoch 8/10, Batch 40/49, Loss: 0.2099
Epoch 8/10, Train Loss: 0.2575, Valid Loss: 0.2490
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2434
Epoch 9/10, Batch 20/49, Loss: 0.2658
Epoch 9/10, Batch 30/49, Loss: 0.1976
Epoch 9/10, Batch 40/49, Loss: 0.1969
Epoch 9/10, Train Loss: 0.2432, Valid Loss: 0.2367
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2396
Epoch 10/10, Batch 20/49, Loss: 0.3216
Epoch 10/10, Batch 30/49, Loss: 0.2406
Epoch 10/10, Batch 40/49, Loss: 0.1726
Epoch 10/10, Train Loss: 0.2247, Valid Loss: 0.2461
Accuracy: 0.9019
Precision: 0.8989
Recall: 0.9019
F1-score: 0.8998
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2247
Epoch 1/10, Batch 20/49, Loss: 1.2642
Epoch 1/10, Batch 30/49, Loss: 1.0325
Epoch 1/10, Batch 40/49, Loss: 0.8438
Epoch 1/10, Train Loss: 1.0142, Valid Loss: 0.6361
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5254
Epoch 2/10, Batch 20/49, Loss: 0.5989
Epoch 2/10, Batch 30/49, Loss: 0.5901
Epoch 2/10, Batch 40/49, Loss: 0.4202
Epoch 2/10, Train Loss: 0.5484, Valid Loss: 0.4494
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4335
Epoch 3/10, Batch 20/49, Loss: 0.2882
Epoch 3/10, Batch 30/49, Loss: 0.4192
Epoch 3/10, Batch 40/49, Loss: 0.2661
Epoch 3/10, Train Loss: 0.4126, Valid Loss: 0.3871
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2538
Epoch 4/10, Batch 20/49, Loss: 0.3701
Epoch 4/10, Batch 30/49, Loss: 0.4770
Epoch 4/10, Batch 40/49, Loss: 0.3417
Epoch 4/10, Train Loss: 0.3714, Valid Loss: 0.3341
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3297
Epoch 5/10, Batch 20/49, Loss: 0.2089
Epoch 5/10, Batch 30/49, Loss: 0.2222
Epoch 5/10, Batch 40/49, Loss: 0.3803
Epoch 5/10, Train Loss: 0.3198, Valid Loss: 0.3136
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3486
Epoch 6/10, Batch 20/49, Loss: 0.2339
Epoch 6/10, Batch 30/49, Loss: 0.2945
Epoch 6/10, Batch 40/49, Loss: 0.3215
Epoch 6/10, Train Loss: 0.2979, Valid Loss: 0.2959
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2639
Epoch 7/10, Batch 20/49, Loss: 0.3337
Epoch 7/10, Batch 30/49, Loss: 0.3484
Epoch 7/10, Batch 40/49, Loss: 0.1500
Epoch 7/10, Train Loss: 0.2565, Valid Loss: 0.3048
Epoch 8/10, Batch 10/49, Loss: 0.2279
Epoch 8/10, Batch 20/49, Loss: 0.2237
Epoch 8/10, Batch 30/49, Loss: 0.2206
Epoch 8/10, Batch 40/49, Loss: 0.2768
Epoch 8/10, Train Loss: 0.2471, Valid Loss: 0.2828
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2152
Epoch 9/10, Batch 20/49, Loss: 0.1301
Epoch 9/10, Batch 30/49, Loss: 0.3248
Epoch 9/10, Batch 40/49, Loss: 0.4561
Epoch 9/10, Train Loss: 0.2364, Valid Loss: 0.2742
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2365
Epoch 10/10, Batch 20/49, Loss: 0.2128
Epoch 10/10, Batch 30/49, Loss: 0.1689
Epoch 10/10, Batch 40/49, Loss: 0.2612
Epoch 10/10, Train Loss: 0.2156, Valid Loss: 0.2760
Accuracy: 0.9030
Precision: 0.8989
Recall: 0.9030
F1-score: 0.8983
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2093
Epoch 1/10, Batch 20/49, Loss: 1.1449
Epoch 1/10, Batch 30/49, Loss: 0.8379
Epoch 1/10, Batch 40/49, Loss: 0.9112
Epoch 1/10, Train Loss: 1.0270, Valid Loss: 0.6542
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.4964
Epoch 2/10, Batch 20/49, Loss: 0.6216
Epoch 2/10, Batch 30/49, Loss: 0.4535
Epoch 2/10, Batch 40/49, Loss: 0.5074
Epoch 2/10, Train Loss: 0.5511, Valid Loss: 0.4726
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5082
Epoch 3/10, Batch 20/49, Loss: 0.2716
Epoch 3/10, Batch 30/49, Loss: 0.3986
Epoch 3/10, Batch 40/49, Loss: 0.3728
Epoch 3/10, Train Loss: 0.4123, Valid Loss: 0.4258
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3808
Epoch 4/10, Batch 20/49, Loss: 0.3210
Epoch 4/10, Batch 30/49, Loss: 0.4430
Epoch 4/10, Batch 40/49, Loss: 0.3380
Epoch 4/10, Train Loss: 0.3673, Valid Loss: 0.3748
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4196
Epoch 5/10, Batch 20/49, Loss: 0.2628
Epoch 5/10, Batch 30/49, Loss: 0.2843
Epoch 5/10, Batch 40/49, Loss: 0.3060
Epoch 5/10, Train Loss: 0.3166, Valid Loss: 0.3566
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2097
Epoch 6/10, Batch 20/49, Loss: 0.2368
Epoch 6/10, Batch 30/49, Loss: 0.2540
Epoch 6/10, Batch 40/49, Loss: 0.2340
Epoch 6/10, Train Loss: 0.2853, Valid Loss: 0.3521
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2702
Epoch 7/10, Batch 20/49, Loss: 0.3331
Epoch 7/10, Batch 30/49, Loss: 0.2347
Epoch 7/10, Batch 40/49, Loss: 0.1096
Epoch 7/10, Train Loss: 0.2542, Valid Loss: 0.3466
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2064
Epoch 8/10, Batch 20/49, Loss: 0.2811
Epoch 8/10, Batch 30/49, Loss: 0.1775
Epoch 8/10, Batch 40/49, Loss: 0.2157
Epoch 8/10, Train Loss: 0.2542, Valid Loss: 0.3376
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2001
Epoch 9/10, Batch 20/49, Loss: 0.1616
Epoch 9/10, Batch 30/49, Loss: 0.3129
Epoch 9/10, Batch 40/49, Loss: 0.3825
Epoch 9/10, Train Loss: 0.2343, Valid Loss: 0.3296
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2785
Epoch 10/10, Batch 20/49, Loss: 0.2054
Epoch 10/10, Batch 30/49, Loss: 0.1104
Epoch 10/10, Batch 40/49, Loss: 0.1227
Epoch 10/10, Train Loss: 0.2128, Valid Loss: 0.3319
Accuracy: 0.9077
Precision: 0.9055
Recall: 0.9077
F1-score: 0.9037
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2983
Epoch 1/10, Batch 20/49, Loss: 1.2064
Epoch 1/10, Batch 30/49, Loss: 0.8670
Epoch 1/10, Batch 40/49, Loss: 0.7896
Epoch 1/10, Train Loss: 0.9985, Valid Loss: 0.6710
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.4867
Epoch 2/10, Batch 20/49, Loss: 0.6092
Epoch 2/10, Batch 30/49, Loss: 0.4833
Epoch 2/10, Batch 40/49, Loss: 0.4318
Epoch 2/10, Train Loss: 0.5361, Valid Loss: 0.4810
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4207
Epoch 3/10, Batch 20/49, Loss: 0.3437
Epoch 3/10, Batch 30/49, Loss: 0.4723
Epoch 3/10, Batch 40/49, Loss: 0.3811
Epoch 3/10, Train Loss: 0.3979, Valid Loss: 0.4216
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.5401
Epoch 4/10, Batch 20/49, Loss: 0.2621
Epoch 4/10, Batch 30/49, Loss: 0.3997
Epoch 4/10, Batch 40/49, Loss: 0.4273
Epoch 4/10, Train Loss: 0.3530, Valid Loss: 0.3888
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4611
Epoch 5/10, Batch 20/49, Loss: 0.2526
Epoch 5/10, Batch 30/49, Loss: 0.2453
Epoch 5/10, Batch 40/49, Loss: 0.3698
Epoch 5/10, Train Loss: 0.3045, Valid Loss: 0.3568
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2839
Epoch 6/10, Batch 20/49, Loss: 0.1695
Epoch 6/10, Batch 30/49, Loss: 0.2279
Epoch 6/10, Batch 40/49, Loss: 0.1077
Epoch 6/10, Train Loss: 0.2707, Valid Loss: 0.3351
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2455
Epoch 7/10, Batch 20/49, Loss: 0.3506
Epoch 7/10, Batch 30/49, Loss: 0.3063
Epoch 7/10, Batch 40/49, Loss: 0.2514
Epoch 7/10, Train Loss: 0.2532, Valid Loss: 0.3554
Epoch 8/10, Batch 10/49, Loss: 0.1658
Epoch 8/10, Batch 20/49, Loss: 0.1256
Epoch 8/10, Batch 30/49, Loss: 0.1478
Epoch 8/10, Batch 40/49, Loss: 0.2229
Epoch 8/10, Train Loss: 0.2312, Valid Loss: 0.3195
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2480
Epoch 9/10, Batch 20/49, Loss: 0.1918
Epoch 9/10, Batch 30/49, Loss: 0.1424
Epoch 9/10, Batch 40/49, Loss: 0.3525
Epoch 9/10, Train Loss: 0.2177, Valid Loss: 0.3098
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2029
Epoch 10/10, Batch 20/49, Loss: 0.0928
Epoch 10/10, Batch 30/49, Loss: 0.1896
Epoch 10/10, Batch 40/49, Loss: 0.1469
Epoch 10/10, Train Loss: 0.2043, Valid Loss: 0.3177
Accuracy: 0.9054
Precision: 0.9012
Recall: 0.9054
F1-score: 0.9013
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2059
Epoch 1/10, Batch 20/49, Loss: 1.2225
Epoch 1/10, Batch 30/49, Loss: 0.7936
Epoch 1/10, Batch 40/49, Loss: 0.7697
Epoch 1/10, Train Loss: 1.0150, Valid Loss: 0.6138
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5485
Epoch 2/10, Batch 20/49, Loss: 0.6675
Epoch 2/10, Batch 30/49, Loss: 0.4929
Epoch 2/10, Batch 40/49, Loss: 0.3853
Epoch 2/10, Train Loss: 0.5449, Valid Loss: 0.4312
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5260
Epoch 3/10, Batch 20/49, Loss: 0.3830
Epoch 3/10, Batch 30/49, Loss: 0.3607
Epoch 3/10, Batch 40/49, Loss: 0.5100
Epoch 3/10, Train Loss: 0.4200, Valid Loss: 0.3797
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3555
Epoch 4/10, Batch 20/49, Loss: 0.3906
Epoch 4/10, Batch 30/49, Loss: 0.3807
Epoch 4/10, Batch 40/49, Loss: 0.3885
Epoch 4/10, Train Loss: 0.3616, Valid Loss: 0.3385
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3349
Epoch 5/10, Batch 20/49, Loss: 0.2897
Epoch 5/10, Batch 30/49, Loss: 0.2049
Epoch 5/10, Batch 40/49, Loss: 0.2771
Epoch 5/10, Train Loss: 0.3200, Valid Loss: 0.3180
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3446
Epoch 6/10, Batch 20/49, Loss: 0.1631
Epoch 6/10, Batch 30/49, Loss: 0.2925
Epoch 6/10, Batch 40/49, Loss: 0.2422
Epoch 6/10, Train Loss: 0.2909, Valid Loss: 0.3065
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1630
Epoch 7/10, Batch 20/49, Loss: 0.3915
Epoch 7/10, Batch 30/49, Loss: 0.3524
Epoch 7/10, Batch 40/49, Loss: 0.2148
Epoch 7/10, Train Loss: 0.2584, Valid Loss: 0.3142
Epoch 8/10, Batch 10/49, Loss: 0.2958
Epoch 8/10, Batch 20/49, Loss: 0.1536
Epoch 8/10, Batch 30/49, Loss: 0.2711
Epoch 8/10, Batch 40/49, Loss: 0.1089
Epoch 8/10, Train Loss: 0.2573, Valid Loss: 0.2939
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2058
Epoch 9/10, Batch 20/49, Loss: 0.1635
Epoch 9/10, Batch 30/49, Loss: 0.2365
Epoch 9/10, Batch 40/49, Loss: 0.4852
Epoch 9/10, Train Loss: 0.2304, Valid Loss: 0.2846
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3268
Epoch 10/10, Batch 20/49, Loss: 0.1904
Epoch 10/10, Batch 30/49, Loss: 0.2071
Epoch 10/10, Batch 40/49, Loss: 0.2559
Epoch 10/10, Train Loss: 0.2258, Valid Loss: 0.2876
Accuracy: 0.9030
Precision: 0.8993
Recall: 0.9030
F1-score: 0.8991
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2742
Epoch 1/10, Batch 20/49, Loss: 1.0939
Epoch 1/10, Batch 30/49, Loss: 0.8360
Epoch 1/10, Batch 40/49, Loss: 0.8833
Epoch 1/10, Train Loss: 1.0108, Valid Loss: 0.6647
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6416
Epoch 2/10, Batch 20/49, Loss: 0.6457
Epoch 2/10, Batch 30/49, Loss: 0.4962
Epoch 2/10, Batch 40/49, Loss: 0.3197
Epoch 2/10, Train Loss: 0.5370, Valid Loss: 0.4560
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3770
Epoch 3/10, Batch 20/49, Loss: 0.3973
Epoch 3/10, Batch 30/49, Loss: 0.4406
Epoch 3/10, Batch 40/49, Loss: 0.2803
Epoch 3/10, Train Loss: 0.4082, Valid Loss: 0.3900
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4928
Epoch 4/10, Batch 20/49, Loss: 0.4481
Epoch 4/10, Batch 30/49, Loss: 0.3488
Epoch 4/10, Batch 40/49, Loss: 0.4309
Epoch 4/10, Train Loss: 0.3609, Valid Loss: 0.3422
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3466
Epoch 5/10, Batch 20/49, Loss: 0.2085
Epoch 5/10, Batch 30/49, Loss: 0.2455
Epoch 5/10, Batch 40/49, Loss: 0.2511
Epoch 5/10, Train Loss: 0.3184, Valid Loss: 0.3180
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3506
Epoch 6/10, Batch 20/49, Loss: 0.2673
Epoch 6/10, Batch 30/49, Loss: 0.2143
Epoch 6/10, Batch 40/49, Loss: 0.3320
Epoch 6/10, Train Loss: 0.2840, Valid Loss: 0.2985
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2016
Epoch 7/10, Batch 20/49, Loss: 0.3638
Epoch 7/10, Batch 30/49, Loss: 0.1509
Epoch 7/10, Batch 40/49, Loss: 0.1103
Epoch 7/10, Train Loss: 0.2515, Valid Loss: 0.2943
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2554
Epoch 8/10, Batch 20/49, Loss: 0.2212
Epoch 8/10, Batch 30/49, Loss: 0.2885
Epoch 8/10, Batch 40/49, Loss: 0.2087
Epoch 8/10, Train Loss: 0.2455, Valid Loss: 0.2820
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1414
Epoch 9/10, Batch 20/49, Loss: 0.1871
Epoch 9/10, Batch 30/49, Loss: 0.3813
Epoch 9/10, Batch 40/49, Loss: 0.2880
Epoch 9/10, Train Loss: 0.2365, Valid Loss: 0.2685
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1983
Epoch 10/10, Batch 20/49, Loss: 0.1523
Epoch 10/10, Batch 30/49, Loss: 0.1940
Epoch 10/10, Batch 40/49, Loss: 0.1486
Epoch 10/10, Train Loss: 0.2135, Valid Loss: 0.2684
Model saved!
Accuracy: 0.8960
Precision: 0.8932
Recall: 0.8960
F1-score: 0.8931
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2491
Epoch 1/10, Batch 20/49, Loss: 1.1465
Epoch 1/10, Batch 30/49, Loss: 0.8480
Epoch 1/10, Batch 40/49, Loss: 0.8197
Epoch 1/10, Train Loss: 0.9985, Valid Loss: 0.6443
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5376
Epoch 2/10, Batch 20/49, Loss: 0.6144
Epoch 2/10, Batch 30/49, Loss: 0.4664
Epoch 2/10, Batch 40/49, Loss: 0.5100
Epoch 2/10, Train Loss: 0.5367, Valid Loss: 0.4549
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5061
Epoch 3/10, Batch 20/49, Loss: 0.3507
Epoch 3/10, Batch 30/49, Loss: 0.4154
Epoch 3/10, Batch 40/49, Loss: 0.3103
Epoch 3/10, Train Loss: 0.4128, Valid Loss: 0.3907
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3042
Epoch 4/10, Batch 20/49, Loss: 0.2646
Epoch 4/10, Batch 30/49, Loss: 0.4157
Epoch 4/10, Batch 40/49, Loss: 0.2397
Epoch 4/10, Train Loss: 0.3599, Valid Loss: 0.3525
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4227
Epoch 5/10, Batch 20/49, Loss: 0.2219
Epoch 5/10, Batch 30/49, Loss: 0.3238
Epoch 5/10, Batch 40/49, Loss: 0.2739
Epoch 5/10, Train Loss: 0.3077, Valid Loss: 0.3211
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2551
Epoch 6/10, Batch 20/49, Loss: 0.2304
Epoch 6/10, Batch 30/49, Loss: 0.3621
Epoch 6/10, Batch 40/49, Loss: 0.3373
Epoch 6/10, Train Loss: 0.2898, Valid Loss: 0.2972
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2340
Epoch 7/10, Batch 20/49, Loss: 0.3309
Epoch 7/10, Batch 30/49, Loss: 0.1814
Epoch 7/10, Batch 40/49, Loss: 0.2448
Epoch 7/10, Train Loss: 0.2486, Valid Loss: 0.2929
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1663
Epoch 8/10, Batch 20/49, Loss: 0.1536
Epoch 8/10, Batch 30/49, Loss: 0.1566
Epoch 8/10, Batch 40/49, Loss: 0.1497
Epoch 8/10, Train Loss: 0.2444, Valid Loss: 0.2875
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2282
Epoch 9/10, Batch 20/49, Loss: 0.1430
Epoch 9/10, Batch 30/49, Loss: 0.1823
Epoch 9/10, Batch 40/49, Loss: 0.3054
Epoch 9/10, Train Loss: 0.2243, Valid Loss: 0.2781
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2209
Epoch 10/10, Batch 20/49, Loss: 0.2425
Epoch 10/10, Batch 30/49, Loss: 0.1861
Epoch 10/10, Batch 40/49, Loss: 0.1592
Epoch 10/10, Train Loss: 0.2053, Valid Loss: 0.2758
Model saved!
Accuracy: 0.8984
Precision: 0.8970
Recall: 0.8984
F1-score: 0.8930
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1913
Epoch 1/10, Batch 20/49, Loss: 1.0467
Epoch 1/10, Batch 30/49, Loss: 0.8274
Epoch 1/10, Batch 40/49, Loss: 0.8517
Epoch 1/10, Train Loss: 1.0015, Valid Loss: 0.6107
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5478
Epoch 2/10, Batch 20/49, Loss: 0.6607
Epoch 2/10, Batch 30/49, Loss: 0.5914
Epoch 2/10, Batch 40/49, Loss: 0.5024
Epoch 2/10, Train Loss: 0.5418, Valid Loss: 0.4296
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5123
Epoch 3/10, Batch 20/49, Loss: 0.3576
Epoch 3/10, Batch 30/49, Loss: 0.5161
Epoch 3/10, Batch 40/49, Loss: 0.2657
Epoch 3/10, Train Loss: 0.4058, Valid Loss: 0.3651
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2797
Epoch 4/10, Batch 20/49, Loss: 0.5097
Epoch 4/10, Batch 30/49, Loss: 0.3629
Epoch 4/10, Batch 40/49, Loss: 0.3534
Epoch 4/10, Train Loss: 0.3577, Valid Loss: 0.3195
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3720
Epoch 5/10, Batch 20/49, Loss: 0.1811
Epoch 5/10, Batch 30/49, Loss: 0.2170
Epoch 5/10, Batch 40/49, Loss: 0.3254
Epoch 5/10, Train Loss: 0.3121, Valid Loss: 0.2953
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.4528
Epoch 6/10, Batch 20/49, Loss: 0.2524
Epoch 6/10, Batch 30/49, Loss: 0.2561
Epoch 6/10, Batch 40/49, Loss: 0.1945
Epoch 6/10, Train Loss: 0.2757, Valid Loss: 0.2753
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2868
Epoch 7/10, Batch 20/49, Loss: 0.1744
Epoch 7/10, Batch 30/49, Loss: 0.4159
Epoch 7/10, Batch 40/49, Loss: 0.2486
Epoch 7/10, Train Loss: 0.2460, Valid Loss: 0.2781
Epoch 8/10, Batch 10/49, Loss: 0.2040
Epoch 8/10, Batch 20/49, Loss: 0.2439
Epoch 8/10, Batch 30/49, Loss: 0.2512
Epoch 8/10, Batch 40/49, Loss: 0.3779
Epoch 8/10, Train Loss: 0.2543, Valid Loss: 0.2771
Epoch 9/10, Batch 10/49, Loss: 0.1622
Epoch 9/10, Batch 20/49, Loss: 0.1605
Epoch 9/10, Batch 30/49, Loss: 0.2147
Epoch 9/10, Batch 40/49, Loss: 0.2720
Epoch 9/10, Train Loss: 0.2277, Valid Loss: 0.2471
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2084
Epoch 10/10, Batch 20/49, Loss: 0.2996
Epoch 10/10, Batch 30/49, Loss: 0.1267
Epoch 10/10, Batch 40/49, Loss: 0.2515
Epoch 10/10, Train Loss: 0.2073, Valid Loss: 0.2533
Accuracy: 0.8995
Precision: 0.8949
Recall: 0.8995
F1-score: 0.8965
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1754
Epoch 1/10, Batch 20/49, Loss: 1.2025
Epoch 1/10, Batch 30/49, Loss: 0.9028
Epoch 1/10, Batch 40/49, Loss: 0.8407
Epoch 1/10, Train Loss: 1.0000, Valid Loss: 0.6135
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5961
Epoch 2/10, Batch 20/49, Loss: 0.6563
Epoch 2/10, Batch 30/49, Loss: 0.4310
Epoch 2/10, Batch 40/49, Loss: 0.3961
Epoch 2/10, Train Loss: 0.5297, Valid Loss: 0.4530
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3737
Epoch 3/10, Batch 20/49, Loss: 0.3640
Epoch 3/10, Batch 30/49, Loss: 0.5389
Epoch 3/10, Batch 40/49, Loss: 0.3922
Epoch 3/10, Train Loss: 0.4064, Valid Loss: 0.3851
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2501
Epoch 4/10, Batch 20/49, Loss: 0.2949
Epoch 4/10, Batch 30/49, Loss: 0.3455
Epoch 4/10, Batch 40/49, Loss: 0.5308
Epoch 4/10, Train Loss: 0.3501, Valid Loss: 0.3432
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2766
Epoch 5/10, Batch 20/49, Loss: 0.2470
Epoch 5/10, Batch 30/49, Loss: 0.3411
Epoch 5/10, Batch 40/49, Loss: 0.3692
Epoch 5/10, Train Loss: 0.3147, Valid Loss: 0.3142
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2323
Epoch 6/10, Batch 20/49, Loss: 0.1649
Epoch 6/10, Batch 30/49, Loss: 0.2293
Epoch 6/10, Batch 40/49, Loss: 0.1827
Epoch 6/10, Train Loss: 0.2837, Valid Loss: 0.3101
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1891
Epoch 7/10, Batch 20/49, Loss: 0.3768
Epoch 7/10, Batch 30/49, Loss: 0.2199
Epoch 7/10, Batch 40/49, Loss: 0.1033
Epoch 7/10, Train Loss: 0.2400, Valid Loss: 0.3100
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2328
Epoch 8/10, Batch 20/49, Loss: 0.1341
Epoch 8/10, Batch 30/49, Loss: 0.1924
Epoch 8/10, Batch 40/49, Loss: 0.2079
Epoch 8/10, Train Loss: 0.2425, Valid Loss: 0.2865
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1654
Epoch 9/10, Batch 20/49, Loss: 0.1736
Epoch 9/10, Batch 30/49, Loss: 0.1389
Epoch 9/10, Batch 40/49, Loss: 0.3734
Epoch 9/10, Train Loss: 0.2241, Valid Loss: 0.2847
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2028
Epoch 10/10, Batch 20/49, Loss: 0.2014
Epoch 10/10, Batch 30/49, Loss: 0.2516
Epoch 10/10, Batch 40/49, Loss: 0.2222
Epoch 10/10, Train Loss: 0.2007, Valid Loss: 0.2871
Accuracy: 0.9007
Precision: 0.8980
Recall: 0.9007
F1-score: 0.8970
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2286
Epoch 1/10, Batch 20/49, Loss: 1.0920
Epoch 1/10, Batch 30/49, Loss: 0.8281
Epoch 1/10, Batch 40/49, Loss: 0.7293
Epoch 1/10, Train Loss: 1.0212, Valid Loss: 0.6471
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6292
Epoch 2/10, Batch 20/49, Loss: 0.8027
Epoch 2/10, Batch 30/49, Loss: 0.3982
Epoch 2/10, Batch 40/49, Loss: 0.6250
Epoch 2/10, Train Loss: 0.5459, Valid Loss: 0.4592
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4496
Epoch 3/10, Batch 20/49, Loss: 0.4168
Epoch 3/10, Batch 30/49, Loss: 0.4047
Epoch 3/10, Batch 40/49, Loss: 0.4015
Epoch 3/10, Train Loss: 0.4167, Valid Loss: 0.3881
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3525
Epoch 4/10, Batch 20/49, Loss: 0.2595
Epoch 4/10, Batch 30/49, Loss: 0.4115
Epoch 4/10, Batch 40/49, Loss: 0.3597
Epoch 4/10, Train Loss: 0.3670, Valid Loss: 0.3299
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2611
Epoch 5/10, Batch 20/49, Loss: 0.2794
Epoch 5/10, Batch 30/49, Loss: 0.3627
Epoch 5/10, Batch 40/49, Loss: 0.2421
Epoch 5/10, Train Loss: 0.3274, Valid Loss: 0.3116
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2580
Epoch 6/10, Batch 20/49, Loss: 0.3492
Epoch 6/10, Batch 30/49, Loss: 0.2149
Epoch 6/10, Batch 40/49, Loss: 0.3103
Epoch 6/10, Train Loss: 0.2888, Valid Loss: 0.2948
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2423
Epoch 7/10, Batch 20/49, Loss: 0.3240
Epoch 7/10, Batch 30/49, Loss: 0.2265
Epoch 7/10, Batch 40/49, Loss: 0.2227
Epoch 7/10, Train Loss: 0.2556, Valid Loss: 0.2863
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3725
Epoch 8/10, Batch 20/49, Loss: 0.1232
Epoch 8/10, Batch 30/49, Loss: 0.2529
Epoch 8/10, Batch 40/49, Loss: 0.2786
Epoch 8/10, Train Loss: 0.2609, Valid Loss: 0.2875
Epoch 9/10, Batch 10/49, Loss: 0.3306
Epoch 9/10, Batch 20/49, Loss: 0.1801
Epoch 9/10, Batch 30/49, Loss: 0.3113
Epoch 9/10, Batch 40/49, Loss: 0.3325
Epoch 9/10, Train Loss: 0.2278, Valid Loss: 0.2666
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2840
Epoch 10/10, Batch 20/49, Loss: 0.2351
Epoch 10/10, Batch 30/49, Loss: 0.1080
Epoch 10/10, Batch 40/49, Loss: 0.2121
Epoch 10/10, Train Loss: 0.2215, Valid Loss: 0.2691
Accuracy: 0.9019
Precision: 0.8988
Recall: 0.9019
F1-score: 0.8986
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1866
Epoch 1/10, Batch 20/49, Loss: 1.1610
Epoch 1/10, Batch 30/49, Loss: 0.8741
Epoch 1/10, Batch 40/49, Loss: 0.8563
Epoch 1/10, Train Loss: 1.0146, Valid Loss: 0.6624
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6856
Epoch 2/10, Batch 20/49, Loss: 0.7020
Epoch 2/10, Batch 30/49, Loss: 0.5297
Epoch 2/10, Batch 40/49, Loss: 0.4939
Epoch 2/10, Train Loss: 0.5463, Valid Loss: 0.4784
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4618
Epoch 3/10, Batch 20/49, Loss: 0.4480
Epoch 3/10, Batch 30/49, Loss: 0.4836
Epoch 3/10, Batch 40/49, Loss: 0.4853
Epoch 3/10, Train Loss: 0.4262, Valid Loss: 0.4156
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3305
Epoch 4/10, Batch 20/49, Loss: 0.3080
Epoch 4/10, Batch 30/49, Loss: 0.3247
Epoch 4/10, Batch 40/49, Loss: 0.3952
Epoch 4/10, Train Loss: 0.3656, Valid Loss: 0.3691
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3570
Epoch 5/10, Batch 20/49, Loss: 0.2908
Epoch 5/10, Batch 30/49, Loss: 0.2144
Epoch 5/10, Batch 40/49, Loss: 0.3448
Epoch 5/10, Train Loss: 0.3382, Valid Loss: 0.3348
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2972
Epoch 6/10, Batch 20/49, Loss: 0.3063
Epoch 6/10, Batch 30/49, Loss: 0.1818
Epoch 6/10, Batch 40/49, Loss: 0.2552
Epoch 6/10, Train Loss: 0.3031, Valid Loss: 0.3182
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2319
Epoch 7/10, Batch 20/49, Loss: 0.3212
Epoch 7/10, Batch 30/49, Loss: 0.2852
Epoch 7/10, Batch 40/49, Loss: 0.1843
Epoch 7/10, Train Loss: 0.2711, Valid Loss: 0.3258
Epoch 8/10, Batch 10/49, Loss: 0.2527
Epoch 8/10, Batch 20/49, Loss: 0.1930
Epoch 8/10, Batch 30/49, Loss: 0.2746
Epoch 8/10, Batch 40/49, Loss: 0.1305
Epoch 8/10, Train Loss: 0.2719, Valid Loss: 0.3053
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3202
Epoch 9/10, Batch 20/49, Loss: 0.2594
Epoch 9/10, Batch 30/49, Loss: 0.2936
Epoch 9/10, Batch 40/49, Loss: 0.3601
Epoch 9/10, Train Loss: 0.2473, Valid Loss: 0.2953
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3336
Epoch 10/10, Batch 20/49, Loss: 0.1508
Epoch 10/10, Batch 30/49, Loss: 0.1833
Epoch 10/10, Batch 40/49, Loss: 0.2053
Epoch 10/10, Train Loss: 0.2302, Valid Loss: 0.2857
Model saved!
Accuracy: 0.9042
Precision: 0.9032
Recall: 0.9042
F1-score: 0.9000
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2056
Epoch 1/10, Batch 20/49, Loss: 1.0993
Epoch 1/10, Batch 30/49, Loss: 0.8243
Epoch 1/10, Batch 40/49, Loss: 0.7773
Epoch 1/10, Train Loss: 1.0037, Valid Loss: 0.6591
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6349
Epoch 2/10, Batch 20/49, Loss: 0.6230
Epoch 2/10, Batch 30/49, Loss: 0.4434
Epoch 2/10, Batch 40/49, Loss: 0.5100
Epoch 2/10, Train Loss: 0.5384, Valid Loss: 0.4719
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4101
Epoch 3/10, Batch 20/49, Loss: 0.3633
Epoch 3/10, Batch 30/49, Loss: 0.3533
Epoch 3/10, Batch 40/49, Loss: 0.4175
Epoch 3/10, Train Loss: 0.4016, Valid Loss: 0.4140
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3846
Epoch 4/10, Batch 20/49, Loss: 0.4511
Epoch 4/10, Batch 30/49, Loss: 0.3894
Epoch 4/10, Batch 40/49, Loss: 0.4334
Epoch 4/10, Train Loss: 0.3472, Valid Loss: 0.3549
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3831
Epoch 5/10, Batch 20/49, Loss: 0.1719
Epoch 5/10, Batch 30/49, Loss: 0.1646
Epoch 5/10, Batch 40/49, Loss: 0.3354
Epoch 5/10, Train Loss: 0.3085, Valid Loss: 0.3321
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2884
Epoch 6/10, Batch 20/49, Loss: 0.1922
Epoch 6/10, Batch 30/49, Loss: 0.2198
Epoch 6/10, Batch 40/49, Loss: 0.2612
Epoch 6/10, Train Loss: 0.2724, Valid Loss: 0.3183
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3075
Epoch 7/10, Batch 20/49, Loss: 0.2829
Epoch 7/10, Batch 30/49, Loss: 0.1878
Epoch 7/10, Batch 40/49, Loss: 0.2650
Epoch 7/10, Train Loss: 0.2419, Valid Loss: 0.3194
Epoch 8/10, Batch 10/49, Loss: 0.3504
Epoch 8/10, Batch 20/49, Loss: 0.1047
Epoch 8/10, Batch 30/49, Loss: 0.1297
Epoch 8/10, Batch 40/49, Loss: 0.2140
Epoch 8/10, Train Loss: 0.2596, Valid Loss: 0.3080
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1060
Epoch 9/10, Batch 20/49, Loss: 0.1466
Epoch 9/10, Batch 30/49, Loss: 0.2090
Epoch 9/10, Batch 40/49, Loss: 0.4015
Epoch 9/10, Train Loss: 0.2228, Valid Loss: 0.2843
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2015
Epoch 10/10, Batch 20/49, Loss: 0.2092
Epoch 10/10, Batch 30/49, Loss: 0.2568
Epoch 10/10, Batch 40/49, Loss: 0.2442
Epoch 10/10, Train Loss: 0.2144, Valid Loss: 0.2956
Accuracy: 0.9019
Precision: 0.9005
Recall: 0.9019
F1-score: 0.9006
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2687
Epoch 1/10, Batch 20/49, Loss: 1.1404
Epoch 1/10, Batch 30/49, Loss: 0.8348
Epoch 1/10, Batch 40/49, Loss: 0.8217
Epoch 1/10, Train Loss: 1.0436, Valid Loss: 0.6417
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5753
Epoch 2/10, Batch 20/49, Loss: 0.7569
Epoch 2/10, Batch 30/49, Loss: 0.5548
Epoch 2/10, Batch 40/49, Loss: 0.5047
Epoch 2/10, Train Loss: 0.5722, Valid Loss: 0.4354
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3882
Epoch 3/10, Batch 20/49, Loss: 0.3802
Epoch 3/10, Batch 30/49, Loss: 0.5869
Epoch 3/10, Batch 40/49, Loss: 0.2500
Epoch 3/10, Train Loss: 0.4435, Valid Loss: 0.3677
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3445
Epoch 4/10, Batch 20/49, Loss: 0.3447
Epoch 4/10, Batch 30/49, Loss: 0.4058
Epoch 4/10, Batch 40/49, Loss: 0.4099
Epoch 4/10, Train Loss: 0.3780, Valid Loss: 0.3095
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4999
Epoch 5/10, Batch 20/49, Loss: 0.3102
Epoch 5/10, Batch 30/49, Loss: 0.3461
Epoch 5/10, Batch 40/49, Loss: 0.2847
Epoch 5/10, Train Loss: 0.3331, Valid Loss: 0.2840
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3052
Epoch 6/10, Batch 20/49, Loss: 0.2649
Epoch 6/10, Batch 30/49, Loss: 0.2523
Epoch 6/10, Batch 40/49, Loss: 0.2759
Epoch 6/10, Train Loss: 0.3076, Valid Loss: 0.2678
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1991
Epoch 7/10, Batch 20/49, Loss: 0.2819
Epoch 7/10, Batch 30/49, Loss: 0.3156
Epoch 7/10, Batch 40/49, Loss: 0.1014
Epoch 7/10, Train Loss: 0.2751, Valid Loss: 0.2582
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3153
Epoch 8/10, Batch 20/49, Loss: 0.2771
Epoch 8/10, Batch 30/49, Loss: 0.1882
Epoch 8/10, Batch 40/49, Loss: 0.1668
Epoch 8/10, Train Loss: 0.2544, Valid Loss: 0.2556
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1665
Epoch 9/10, Batch 20/49, Loss: 0.1171
Epoch 9/10, Batch 30/49, Loss: 0.3768
Epoch 9/10, Batch 40/49, Loss: 0.3179
Epoch 9/10, Train Loss: 0.2447, Valid Loss: 0.2404
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2639
Epoch 10/10, Batch 20/49, Loss: 0.1659
Epoch 10/10, Batch 30/49, Loss: 0.1998
Epoch 10/10, Batch 40/49, Loss: 0.2099
Epoch 10/10, Train Loss: 0.2411, Valid Loss: 0.2507
Accuracy: 0.9089
Precision: 0.9070
Recall: 0.9089
F1-score: 0.9058
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2888
Epoch 1/10, Batch 20/49, Loss: 1.1522
Epoch 1/10, Batch 30/49, Loss: 0.9154
Epoch 1/10, Batch 40/49, Loss: 0.8034
Epoch 1/10, Train Loss: 1.0112, Valid Loss: 0.5971
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5462
Epoch 2/10, Batch 20/49, Loss: 0.6353
Epoch 2/10, Batch 30/49, Loss: 0.5607
Epoch 2/10, Batch 40/49, Loss: 0.5044
Epoch 2/10, Train Loss: 0.5466, Valid Loss: 0.4245
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3845
Epoch 3/10, Batch 20/49, Loss: 0.4663
Epoch 3/10, Batch 30/49, Loss: 0.4213
Epoch 3/10, Batch 40/49, Loss: 0.3898
Epoch 3/10, Train Loss: 0.4206, Valid Loss: 0.3611
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.1985
Epoch 4/10, Batch 20/49, Loss: 0.2823
Epoch 4/10, Batch 30/49, Loss: 0.3410
Epoch 4/10, Batch 40/49, Loss: 0.3397
Epoch 4/10, Train Loss: 0.3599, Valid Loss: 0.3097
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3974
Epoch 5/10, Batch 20/49, Loss: 0.2173
Epoch 5/10, Batch 30/49, Loss: 0.2132
Epoch 5/10, Batch 40/49, Loss: 0.2741
Epoch 5/10, Train Loss: 0.3213, Valid Loss: 0.2885
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2422
Epoch 6/10, Batch 20/49, Loss: 0.2508
Epoch 6/10, Batch 30/49, Loss: 0.2028
Epoch 6/10, Batch 40/49, Loss: 0.2316
Epoch 6/10, Train Loss: 0.2952, Valid Loss: 0.2706
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1960
Epoch 7/10, Batch 20/49, Loss: 0.2899
Epoch 7/10, Batch 30/49, Loss: 0.2171
Epoch 7/10, Batch 40/49, Loss: 0.1007
Epoch 7/10, Train Loss: 0.2542, Valid Loss: 0.2629
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3859
Epoch 8/10, Batch 20/49, Loss: 0.1638
Epoch 8/10, Batch 30/49, Loss: 0.2447
Epoch 8/10, Batch 40/49, Loss: 0.2410
Epoch 8/10, Train Loss: 0.2550, Valid Loss: 0.2557
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2816
Epoch 9/10, Batch 20/49, Loss: 0.2244
Epoch 9/10, Batch 30/49, Loss: 0.2539
Epoch 9/10, Batch 40/49, Loss: 0.3981
Epoch 9/10, Train Loss: 0.2337, Valid Loss: 0.2527
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2017
Epoch 10/10, Batch 20/49, Loss: 0.1431
Epoch 10/10, Batch 30/49, Loss: 0.1586
Epoch 10/10, Batch 40/49, Loss: 0.2084
Epoch 10/10, Train Loss: 0.2114, Valid Loss: 0.2457
Model saved!
Accuracy: 0.9100
Precision: 0.9068
Recall: 0.9100
F1-score: 0.9071
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1994
Epoch 1/10, Batch 20/49, Loss: 1.0785
Epoch 1/10, Batch 30/49, Loss: 0.8161
Epoch 1/10, Batch 40/49, Loss: 0.7335
Epoch 1/10, Train Loss: 0.9871, Valid Loss: 0.5725
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5584
Epoch 2/10, Batch 20/49, Loss: 0.6137
Epoch 2/10, Batch 30/49, Loss: 0.6292
Epoch 2/10, Batch 40/49, Loss: 0.3410
Epoch 2/10, Train Loss: 0.5262, Valid Loss: 0.3923
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3995
Epoch 3/10, Batch 20/49, Loss: 0.3024
Epoch 3/10, Batch 30/49, Loss: 0.3699
Epoch 3/10, Batch 40/49, Loss: 0.4518
Epoch 3/10, Train Loss: 0.4048, Valid Loss: 0.3338
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3820
Epoch 4/10, Batch 20/49, Loss: 0.3477
Epoch 4/10, Batch 30/49, Loss: 0.3547
Epoch 4/10, Batch 40/49, Loss: 0.4197
Epoch 4/10, Train Loss: 0.3500, Valid Loss: 0.2902
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2900
Epoch 5/10, Batch 20/49, Loss: 0.2102
Epoch 5/10, Batch 30/49, Loss: 0.2229
Epoch 5/10, Batch 40/49, Loss: 0.1943
Epoch 5/10, Train Loss: 0.3001, Valid Loss: 0.2669
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2617
Epoch 6/10, Batch 20/49, Loss: 0.2104
Epoch 6/10, Batch 30/49, Loss: 0.2422
Epoch 6/10, Batch 40/49, Loss: 0.2464
Epoch 6/10, Train Loss: 0.2770, Valid Loss: 0.2507
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1953
Epoch 7/10, Batch 20/49, Loss: 0.2415
Epoch 7/10, Batch 30/49, Loss: 0.1762
Epoch 7/10, Batch 40/49, Loss: 0.1113
Epoch 7/10, Train Loss: 0.2446, Valid Loss: 0.2450
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2351
Epoch 8/10, Batch 20/49, Loss: 0.2228
Epoch 8/10, Batch 30/49, Loss: 0.1553
Epoch 8/10, Batch 40/49, Loss: 0.3513
Epoch 8/10, Train Loss: 0.2356, Valid Loss: 0.2408
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1872
Epoch 9/10, Batch 20/49, Loss: 0.1067
Epoch 9/10, Batch 30/49, Loss: 0.2882
Epoch 9/10, Batch 40/49, Loss: 0.3103
Epoch 9/10, Train Loss: 0.2266, Valid Loss: 0.2251
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2419
Epoch 10/10, Batch 20/49, Loss: 0.2027
Epoch 10/10, Batch 30/49, Loss: 0.2595
Epoch 10/10, Batch 40/49, Loss: 0.0956
Epoch 10/10, Train Loss: 0.2148, Valid Loss: 0.2201
Model saved!
Accuracy: 0.8984
Precision: 0.8948
Recall: 0.8984
F1-score: 0.8941
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1806
Epoch 1/10, Batch 20/49, Loss: 1.1037
Epoch 1/10, Batch 30/49, Loss: 0.8521
Epoch 1/10, Batch 40/49, Loss: 0.7735
Epoch 1/10, Train Loss: 1.0074, Valid Loss: 0.6831
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5879
Epoch 2/10, Batch 20/49, Loss: 0.6920
Epoch 2/10, Batch 30/49, Loss: 0.4924
Epoch 2/10, Batch 40/49, Loss: 0.5585
Epoch 2/10, Train Loss: 0.5485, Valid Loss: 0.4943
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4192
Epoch 3/10, Batch 20/49, Loss: 0.2888
Epoch 3/10, Batch 30/49, Loss: 0.3583
Epoch 3/10, Batch 40/49, Loss: 0.2452
Epoch 3/10, Train Loss: 0.4236, Valid Loss: 0.4429
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3141
Epoch 4/10, Batch 20/49, Loss: 0.2568
Epoch 4/10, Batch 30/49, Loss: 0.2760
Epoch 4/10, Batch 40/49, Loss: 0.4365
Epoch 4/10, Train Loss: 0.3779, Valid Loss: 0.3944
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3670
Epoch 5/10, Batch 20/49, Loss: 0.3365
Epoch 5/10, Batch 30/49, Loss: 0.2008
Epoch 5/10, Batch 40/49, Loss: 0.4218
Epoch 5/10, Train Loss: 0.3222, Valid Loss: 0.3699
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1808
Epoch 6/10, Batch 20/49, Loss: 0.2707
Epoch 6/10, Batch 30/49, Loss: 0.2499
Epoch 6/10, Batch 40/49, Loss: 0.3037
Epoch 6/10, Train Loss: 0.3113, Valid Loss: 0.3617
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2956
Epoch 7/10, Batch 20/49, Loss: 0.3706
Epoch 7/10, Batch 30/49, Loss: 0.2611
Epoch 7/10, Batch 40/49, Loss: 0.2582
Epoch 7/10, Train Loss: 0.2670, Valid Loss: 0.3578
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2780
Epoch 8/10, Batch 20/49, Loss: 0.1875
Epoch 8/10, Batch 30/49, Loss: 0.1950
Epoch 8/10, Batch 40/49, Loss: 0.1705
Epoch 8/10, Train Loss: 0.2548, Valid Loss: 0.3446
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3414
Epoch 9/10, Batch 20/49, Loss: 0.1799
Epoch 9/10, Batch 30/49, Loss: 0.2529
Epoch 9/10, Batch 40/49, Loss: 0.3712
Epoch 9/10, Train Loss: 0.2456, Valid Loss: 0.3291
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1766
Epoch 10/10, Batch 20/49, Loss: 0.3372
Epoch 10/10, Batch 30/49, Loss: 0.1504
Epoch 10/10, Batch 40/49, Loss: 0.1181
Epoch 10/10, Train Loss: 0.2159, Valid Loss: 0.3207
Model saved!
Accuracy: 0.9054
Precision: 0.9015
Recall: 0.9054
F1-score: 0.9023
Memory Allocated after cleanup: 17.76 MB
End time: 2025-02-24 14:09:22.640891
Duration: 3:31:24


Mejor accuracy al acabar el algoritmo: 0.9194


Fitness check:

Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2135
Epoch 1/10, Batch 20/49, Loss: 1.1182
Epoch 1/10, Batch 30/49, Loss: 0.8004
Epoch 1/10, Batch 40/49, Loss: 0.7934
Epoch 1/10, Train Loss: 1.0164, Valid Loss: 0.6317
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6641
Epoch 2/10, Batch 20/49, Loss: 0.6408
Epoch 2/10, Batch 30/49, Loss: 0.6046
Epoch 2/10, Batch 40/49, Loss: 0.4590
Epoch 2/10, Train Loss: 0.5494, Valid Loss: 0.4348
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3709
Epoch 3/10, Batch 20/49, Loss: 0.2714
Epoch 3/10, Batch 30/49, Loss: 0.3847
Epoch 3/10, Batch 40/49, Loss: 0.5226
Epoch 3/10, Train Loss: 0.4279, Valid Loss: 0.3719
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3091
Epoch 4/10, Batch 20/49, Loss: 0.6660
Epoch 4/10, Batch 30/49, Loss: 0.4578
Epoch 4/10, Batch 40/49, Loss: 0.4495
Epoch 4/10, Train Loss: 0.3779, Valid Loss: 0.3361
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3800
Epoch 5/10, Batch 20/49, Loss: 0.2252
Epoch 5/10, Batch 30/49, Loss: 0.2681
Epoch 5/10, Batch 40/49, Loss: 0.2781
Epoch 5/10, Train Loss: 0.3398, Valid Loss: 0.3083
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3408
Epoch 6/10, Batch 20/49, Loss: 0.2366
Epoch 6/10, Batch 30/49, Loss: 0.2739
Epoch 6/10, Batch 40/49, Loss: 0.2957
Epoch 6/10, Train Loss: 0.3045, Valid Loss: 0.2944
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2706
Epoch 7/10, Batch 20/49, Loss: 0.2289
Epoch 7/10, Batch 30/49, Loss: 0.2524
Epoch 7/10, Batch 40/49, Loss: 0.3261
Epoch 7/10, Train Loss: 0.2697, Valid Loss: 0.2873
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3361
Epoch 8/10, Batch 20/49, Loss: 0.3804
Epoch 8/10, Batch 30/49, Loss: 0.1640
Epoch 8/10, Batch 40/49, Loss: 0.1714
Epoch 8/10, Train Loss: 0.2638, Valid Loss: 0.2653
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2564
Epoch 9/10, Batch 20/49, Loss: 0.4040
Epoch 9/10, Batch 30/49, Loss: 0.4504
Epoch 9/10, Batch 40/49, Loss: 0.4001
Epoch 9/10, Train Loss: 0.2546, Valid Loss: 0.2610
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3107
Epoch 10/10, Batch 20/49, Loss: 0.2078
Epoch 10/10, Batch 30/49, Loss: 0.1835
Epoch 10/10, Batch 40/49, Loss: 0.1913
Epoch 10/10, Train Loss: 0.2183, Valid Loss: 0.2584
Model saved!
Accuracy: 0.9194
Precision: 0.9175
Recall: 0.9194
F1-score: 0.9181
Memory Allocated after cleanup: 17.76 MB


Mejor accuracy encontrado: 0.9194


--------------------------------------mobilenet  ALEATORIO  50%-------------------------------------------------
Start time: 2025-02-24 14:11:28.944397
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2789
Epoch 1/10, Batch 20/97, Loss: 1.1758
Epoch 1/10, Batch 30/97, Loss: 0.7151
Epoch 1/10, Batch 40/97, Loss: 0.7187
Epoch 1/10, Batch 50/97, Loss: 0.6363
Epoch 1/10, Batch 60/97, Loss: 0.6500
Epoch 1/10, Batch 70/97, Loss: 0.6647
Epoch 1/10, Batch 80/97, Loss: 0.6169
Epoch 1/10, Batch 90/97, Loss: 0.6921
Epoch 1/10, Train Loss: 0.8069, Valid Loss: 0.4314
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5756
Epoch 2/10, Batch 20/97, Loss: 0.4278
Epoch 2/10, Batch 30/97, Loss: 0.3465
Epoch 2/10, Batch 40/97, Loss: 0.3855
Epoch 2/10, Batch 50/97, Loss: 0.3569
Epoch 2/10, Batch 60/97, Loss: 0.4299
Epoch 2/10, Batch 70/97, Loss: 0.4248
Epoch 2/10, Batch 80/97, Loss: 0.3488
Epoch 2/10, Batch 90/97, Loss: 0.3915
Epoch 2/10, Train Loss: 0.4218, Valid Loss: 0.3288
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.5110
Epoch 3/10, Batch 20/97, Loss: 0.3121
Epoch 3/10, Batch 30/97, Loss: 0.4178
Epoch 3/10, Batch 40/97, Loss: 0.2465
Epoch 3/10, Batch 50/97, Loss: 0.4070
Epoch 3/10, Batch 60/97, Loss: 0.3082
Epoch 3/10, Batch 70/97, Loss: 0.3878
Epoch 3/10, Batch 80/97, Loss: 0.3929
Epoch 3/10, Batch 90/97, Loss: 0.2681
Epoch 3/10, Train Loss: 0.3433, Valid Loss: 0.2790
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3707
Epoch 4/10, Batch 20/97, Loss: 0.2366
Epoch 4/10, Batch 30/97, Loss: 0.2457
Epoch 4/10, Batch 40/97, Loss: 0.2459
Epoch 4/10, Batch 50/97, Loss: 0.3668
Epoch 4/10, Batch 60/97, Loss: 0.2690
Epoch 4/10, Batch 70/97, Loss: 0.2746
Epoch 4/10, Batch 80/97, Loss: 0.3024
Epoch 4/10, Batch 90/97, Loss: 0.1820
Epoch 4/10, Train Loss: 0.2945, Valid Loss: 0.2599
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2563
Epoch 5/10, Batch 20/97, Loss: 0.3100
Epoch 5/10, Batch 30/97, Loss: 0.1881
Epoch 5/10, Batch 40/97, Loss: 0.2480
Epoch 5/10, Batch 50/97, Loss: 0.1918
Epoch 5/10, Batch 60/97, Loss: 0.3575
Epoch 5/10, Batch 70/97, Loss: 0.2762
Epoch 5/10, Batch 80/97, Loss: 0.3282
Epoch 5/10, Batch 90/97, Loss: 0.2382
Epoch 5/10, Train Loss: 0.2741, Valid Loss: 0.2470
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1512
Epoch 6/10, Batch 20/97, Loss: 0.2773
Epoch 6/10, Batch 30/97, Loss: 0.1441
Epoch 6/10, Batch 40/97, Loss: 0.2048
Epoch 6/10, Batch 50/97, Loss: 0.2710
Epoch 6/10, Batch 60/97, Loss: 0.3277
Epoch 6/10, Batch 70/97, Loss: 0.2886
Epoch 6/10, Batch 80/97, Loss: 0.3345
Epoch 6/10, Batch 90/97, Loss: 0.2177
Epoch 6/10, Train Loss: 0.2529, Valid Loss: 0.2376
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1554
Epoch 7/10, Batch 20/97, Loss: 0.4749
Epoch 7/10, Batch 30/97, Loss: 0.1602
Epoch 7/10, Batch 40/97, Loss: 0.1300
Epoch 7/10, Batch 50/97, Loss: 0.3067
Epoch 7/10, Batch 60/97, Loss: 0.1030
Epoch 7/10, Batch 70/97, Loss: 0.2908
Epoch 7/10, Batch 80/97, Loss: 0.3194
Epoch 7/10, Batch 90/97, Loss: 0.1374
Epoch 7/10, Train Loss: 0.2341, Valid Loss: 0.2276
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1003
Epoch 8/10, Batch 20/97, Loss: 0.2411
Epoch 8/10, Batch 30/97, Loss: 0.1005
Epoch 8/10, Batch 40/97, Loss: 0.1420
Epoch 8/10, Batch 50/97, Loss: 0.1684
Epoch 8/10, Batch 60/97, Loss: 0.2049
Epoch 8/10, Batch 70/97, Loss: 0.2956
Epoch 8/10, Batch 80/97, Loss: 0.1228
Epoch 8/10, Batch 90/97, Loss: 0.1963
Epoch 8/10, Train Loss: 0.2196, Valid Loss: 0.2309
Epoch 9/10, Batch 10/97, Loss: 0.0926
Epoch 9/10, Batch 20/97, Loss: 0.2847
Epoch 9/10, Batch 30/97, Loss: 0.1541
Epoch 9/10, Batch 40/97, Loss: 0.3346
Epoch 9/10, Batch 50/97, Loss: 0.1631
Epoch 9/10, Batch 60/97, Loss: 0.2140
Epoch 9/10, Batch 70/97, Loss: 0.1770
Epoch 9/10, Batch 80/97, Loss: 0.1077
Epoch 9/10, Batch 90/97, Loss: 0.1944
Epoch 9/10, Train Loss: 0.2145, Valid Loss: 0.2217
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.4044
Epoch 10/10, Batch 20/97, Loss: 0.0695
Epoch 10/10, Batch 30/97, Loss: 0.1738
Epoch 10/10, Batch 40/97, Loss: 0.3422
Epoch 10/10, Batch 50/97, Loss: 0.2580
Epoch 10/10, Batch 60/97, Loss: 0.1266
Epoch 10/10, Batch 70/97, Loss: 0.1723
Epoch 10/10, Batch 80/97, Loss: 0.1509
Epoch 10/10, Batch 90/97, Loss: 0.1856
Epoch 10/10, Train Loss: 0.2086, Valid Loss: 0.2195
Model saved!
Accuracy: 0.9182
Precision: 0.9153
Recall: 0.9182
F1-score: 0.9159
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 1. Fitness: 0.9182
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2446
Epoch 1/10, Batch 20/97, Loss: 1.0381
Epoch 1/10, Batch 30/97, Loss: 0.7830
Epoch 1/10, Batch 40/97, Loss: 0.7014
Epoch 1/10, Batch 50/97, Loss: 0.5748
Epoch 1/10, Batch 60/97, Loss: 0.6801
Epoch 1/10, Batch 70/97, Loss: 0.6686
Epoch 1/10, Batch 80/97, Loss: 0.6266
Epoch 1/10, Batch 90/97, Loss: 0.5567
Epoch 1/10, Train Loss: 0.8081, Valid Loss: 0.4544
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4326
Epoch 2/10, Batch 20/97, Loss: 0.3847
Epoch 2/10, Batch 30/97, Loss: 0.3287
Epoch 2/10, Batch 40/97, Loss: 0.2853
Epoch 2/10, Batch 50/97, Loss: 0.4126
Epoch 2/10, Batch 60/97, Loss: 0.3835
Epoch 2/10, Batch 70/97, Loss: 0.3032
Epoch 2/10, Batch 80/97, Loss: 0.2789
Epoch 2/10, Batch 90/97, Loss: 0.3314
Epoch 2/10, Train Loss: 0.4166, Valid Loss: 0.3406
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4550
Epoch 3/10, Batch 20/97, Loss: 0.2359
Epoch 3/10, Batch 30/97, Loss: 0.2472
Epoch 3/10, Batch 40/97, Loss: 0.3289
Epoch 3/10, Batch 50/97, Loss: 0.4246
Epoch 3/10, Batch 60/97, Loss: 0.2026
Epoch 3/10, Batch 70/97, Loss: 0.4297
Epoch 3/10, Batch 80/97, Loss: 0.4435
Epoch 3/10, Batch 90/97, Loss: 0.1619
Epoch 3/10, Train Loss: 0.3365, Valid Loss: 0.3028
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2617
Epoch 4/10, Batch 20/97, Loss: 0.2977
Epoch 4/10, Batch 30/97, Loss: 0.3163
Epoch 4/10, Batch 40/97, Loss: 0.1842
Epoch 4/10, Batch 50/97, Loss: 0.2843
Epoch 4/10, Batch 60/97, Loss: 0.2747
Epoch 4/10, Batch 70/97, Loss: 0.1610
Epoch 4/10, Batch 80/97, Loss: 0.2189
Epoch 4/10, Batch 90/97, Loss: 0.1800
Epoch 4/10, Train Loss: 0.2863, Valid Loss: 0.2776
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2282
Epoch 5/10, Batch 20/97, Loss: 0.2429
Epoch 5/10, Batch 30/97, Loss: 0.3099
Epoch 5/10, Batch 40/97, Loss: 0.3261
Epoch 5/10, Batch 50/97, Loss: 0.3144
Epoch 5/10, Batch 60/97, Loss: 0.1402
Epoch 5/10, Batch 70/97, Loss: 0.4151
Epoch 5/10, Batch 80/97, Loss: 0.2790
Epoch 5/10, Batch 90/97, Loss: 0.2137
Epoch 5/10, Train Loss: 0.2747, Valid Loss: 0.2657
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2285
Epoch 6/10, Batch 20/97, Loss: 0.3476
Epoch 6/10, Batch 30/97, Loss: 0.1492
Epoch 6/10, Batch 40/97, Loss: 0.1552
Epoch 6/10, Batch 50/97, Loss: 0.3051
Epoch 6/10, Batch 60/97, Loss: 0.3860
Epoch 6/10, Batch 70/97, Loss: 0.3199
Epoch 6/10, Batch 80/97, Loss: 0.2599
Epoch 6/10, Batch 90/97, Loss: 0.3931
Epoch 6/10, Train Loss: 0.2440, Valid Loss: 0.2571
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2019
Epoch 7/10, Batch 20/97, Loss: 0.1743
Epoch 7/10, Batch 30/97, Loss: 0.1860
Epoch 7/10, Batch 40/97, Loss: 0.1786
Epoch 7/10, Batch 50/97, Loss: 0.0998
Epoch 7/10, Batch 60/97, Loss: 0.1586
Epoch 7/10, Batch 70/97, Loss: 0.2434
Epoch 7/10, Batch 80/97, Loss: 0.2876
Epoch 7/10, Batch 90/97, Loss: 0.3506
Epoch 7/10, Train Loss: 0.2191, Valid Loss: 0.2492
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2481
Epoch 8/10, Batch 20/97, Loss: 0.1655
Epoch 8/10, Batch 30/97, Loss: 0.1884
Epoch 8/10, Batch 40/97, Loss: 0.1933
Epoch 8/10, Batch 50/97, Loss: 0.2252
Epoch 8/10, Batch 60/97, Loss: 0.2246
Epoch 8/10, Batch 70/97, Loss: 0.2018
Epoch 8/10, Batch 80/97, Loss: 0.2172
Epoch 8/10, Batch 90/97, Loss: 0.1542
Epoch 8/10, Train Loss: 0.2190, Valid Loss: 0.2506
Epoch 9/10, Batch 10/97, Loss: 0.1145
Epoch 9/10, Batch 20/97, Loss: 0.1235
Epoch 9/10, Batch 30/97, Loss: 0.3433
Epoch 9/10, Batch 40/97, Loss: 0.2741
Epoch 9/10, Batch 50/97, Loss: 0.1103
Epoch 9/10, Batch 60/97, Loss: 0.1867
Epoch 9/10, Batch 70/97, Loss: 0.2403
Epoch 9/10, Batch 80/97, Loss: 0.1037
Epoch 9/10, Batch 90/97, Loss: 0.1233
Epoch 9/10, Train Loss: 0.2050, Valid Loss: 0.2415
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2331
Epoch 10/10, Batch 20/97, Loss: 0.1234
Epoch 10/10, Batch 30/97, Loss: 0.1006
Epoch 10/10, Batch 40/97, Loss: 0.3078
Epoch 10/10, Batch 50/97, Loss: 0.1646
Epoch 10/10, Batch 60/97, Loss: 0.2506
Epoch 10/10, Batch 70/97, Loss: 0.3128
Epoch 10/10, Batch 80/97, Loss: 0.2349
Epoch 10/10, Batch 90/97, Loss: 0.0623
Epoch 10/10, Train Loss: 0.1975, Valid Loss: 0.2336
Model saved!
Accuracy: 0.9136
Precision: 0.9110
Recall: 0.9136
F1-score: 0.9108
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2616
Epoch 1/10, Batch 20/97, Loss: 1.1231
Epoch 1/10, Batch 30/97, Loss: 0.6994
Epoch 1/10, Batch 40/97, Loss: 0.6992
Epoch 1/10, Batch 50/97, Loss: 0.6120
Epoch 1/10, Batch 60/97, Loss: 0.9001
Epoch 1/10, Batch 70/97, Loss: 0.5352
Epoch 1/10, Batch 80/97, Loss: 0.7169
Epoch 1/10, Batch 90/97, Loss: 0.5290
Epoch 1/10, Train Loss: 0.8007, Valid Loss: 0.4470
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5973
Epoch 2/10, Batch 20/97, Loss: 0.3715
Epoch 2/10, Batch 30/97, Loss: 0.3728
Epoch 2/10, Batch 40/97, Loss: 0.4060
Epoch 2/10, Batch 50/97, Loss: 0.3866
Epoch 2/10, Batch 60/97, Loss: 0.4710
Epoch 2/10, Batch 70/97, Loss: 0.4359
Epoch 2/10, Batch 80/97, Loss: 0.3543
Epoch 2/10, Batch 90/97, Loss: 0.4321
Epoch 2/10, Train Loss: 0.4033, Valid Loss: 0.3327
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3385
Epoch 3/10, Batch 20/97, Loss: 0.3119
Epoch 3/10, Batch 30/97, Loss: 0.4787
Epoch 3/10, Batch 40/97, Loss: 0.3724
Epoch 3/10, Batch 50/97, Loss: 0.3498
Epoch 3/10, Batch 60/97, Loss: 0.1923
Epoch 3/10, Batch 70/97, Loss: 0.4078
Epoch 3/10, Batch 80/97, Loss: 0.2799
Epoch 3/10, Batch 90/97, Loss: 0.2131
Epoch 3/10, Train Loss: 0.3267, Valid Loss: 0.2901
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4642
Epoch 4/10, Batch 20/97, Loss: 0.1367
Epoch 4/10, Batch 30/97, Loss: 0.3318
Epoch 4/10, Batch 40/97, Loss: 0.2798
Epoch 4/10, Batch 50/97, Loss: 0.3152
Epoch 4/10, Batch 60/97, Loss: 0.2861
Epoch 4/10, Batch 70/97, Loss: 0.3270
Epoch 4/10, Batch 80/97, Loss: 0.2501
Epoch 4/10, Batch 90/97, Loss: 0.2487
Epoch 4/10, Train Loss: 0.2774, Valid Loss: 0.2668
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2064
Epoch 5/10, Batch 20/97, Loss: 0.3332
Epoch 5/10, Batch 30/97, Loss: 0.2048
Epoch 5/10, Batch 40/97, Loss: 0.1984
Epoch 5/10, Batch 50/97, Loss: 0.3460
Epoch 5/10, Batch 60/97, Loss: 0.2138
Epoch 5/10, Batch 70/97, Loss: 0.3514
Epoch 5/10, Batch 80/97, Loss: 0.1903
Epoch 5/10, Batch 90/97, Loss: 0.2469
Epoch 5/10, Train Loss: 0.2593, Valid Loss: 0.2551
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2059
Epoch 6/10, Batch 20/97, Loss: 0.2908
Epoch 6/10, Batch 30/97, Loss: 0.2478
Epoch 6/10, Batch 40/97, Loss: 0.2151
Epoch 6/10, Batch 50/97, Loss: 0.2636
Epoch 6/10, Batch 60/97, Loss: 0.3742
Epoch 6/10, Batch 70/97, Loss: 0.2052
Epoch 6/10, Batch 80/97, Loss: 0.1867
Epoch 6/10, Batch 90/97, Loss: 0.2474
Epoch 6/10, Train Loss: 0.2353, Valid Loss: 0.2343
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2447
Epoch 7/10, Batch 20/97, Loss: 0.2473
Epoch 7/10, Batch 30/97, Loss: 0.1476
Epoch 7/10, Batch 40/97, Loss: 0.1305
Epoch 7/10, Batch 50/97, Loss: 0.2114
Epoch 7/10, Batch 60/97, Loss: 0.1832
Epoch 7/10, Batch 70/97, Loss: 0.2435
Epoch 7/10, Batch 80/97, Loss: 0.1536
Epoch 7/10, Batch 90/97, Loss: 0.2657
Epoch 7/10, Train Loss: 0.2260, Valid Loss: 0.2372
Epoch 8/10, Batch 10/97, Loss: 0.1161
Epoch 8/10, Batch 20/97, Loss: 0.1326
Epoch 8/10, Batch 30/97, Loss: 0.1601
Epoch 8/10, Batch 40/97, Loss: 0.1312
Epoch 8/10, Batch 50/97, Loss: 0.1886
Epoch 8/10, Batch 60/97, Loss: 0.1001
Epoch 8/10, Batch 70/97, Loss: 0.2288
Epoch 8/10, Batch 80/97, Loss: 0.2963
Epoch 8/10, Batch 90/97, Loss: 0.1412
Epoch 8/10, Train Loss: 0.2124, Valid Loss: 0.2218
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0888
Epoch 9/10, Batch 20/97, Loss: 0.1074
Epoch 9/10, Batch 30/97, Loss: 0.2823
Epoch 9/10, Batch 40/97, Loss: 0.2874
Epoch 9/10, Batch 50/97, Loss: 0.2070
Epoch 9/10, Batch 60/97, Loss: 0.2451
Epoch 9/10, Batch 70/97, Loss: 0.2157
Epoch 9/10, Batch 80/97, Loss: 0.2006
Epoch 9/10, Batch 90/97, Loss: 0.1386
Epoch 9/10, Train Loss: 0.2030, Valid Loss: 0.2193
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1392
Epoch 10/10, Batch 20/97, Loss: 0.2323
Epoch 10/10, Batch 30/97, Loss: 0.2179
Epoch 10/10, Batch 40/97, Loss: 0.2266
Epoch 10/10, Batch 50/97, Loss: 0.1920
Epoch 10/10, Batch 60/97, Loss: 0.1438
Epoch 10/10, Batch 70/97, Loss: 0.1759
Epoch 10/10, Batch 80/97, Loss: 0.2462
Epoch 10/10, Batch 90/97, Loss: 0.1927
Epoch 10/10, Train Loss: 0.1997, Valid Loss: 0.2284
Accuracy: 0.9217
Precision: 0.9195
Recall: 0.9217
F1-score: 0.9202
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 3. Fitness: 0.9217
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2456
Epoch 1/10, Batch 20/97, Loss: 1.0756
Epoch 1/10, Batch 30/97, Loss: 0.7352
Epoch 1/10, Batch 40/97, Loss: 0.8135
Epoch 1/10, Batch 50/97, Loss: 0.6796
Epoch 1/10, Batch 60/97, Loss: 0.7854
Epoch 1/10, Batch 70/97, Loss: 0.6390
Epoch 1/10, Batch 80/97, Loss: 0.6265
Epoch 1/10, Batch 90/97, Loss: 0.6009
Epoch 1/10, Train Loss: 0.8141, Valid Loss: 0.4485
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5993
Epoch 2/10, Batch 20/97, Loss: 0.3537
Epoch 2/10, Batch 30/97, Loss: 0.3525
Epoch 2/10, Batch 40/97, Loss: 0.3510
Epoch 2/10, Batch 50/97, Loss: 0.4260
Epoch 2/10, Batch 60/97, Loss: 0.5141
Epoch 2/10, Batch 70/97, Loss: 0.3778
Epoch 2/10, Batch 80/97, Loss: 0.3723
Epoch 2/10, Batch 90/97, Loss: 0.4198
Epoch 2/10, Train Loss: 0.4212, Valid Loss: 0.3368
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2268
Epoch 3/10, Batch 20/97, Loss: 0.3870
Epoch 3/10, Batch 30/97, Loss: 0.3850
Epoch 3/10, Batch 40/97, Loss: 0.3864
Epoch 3/10, Batch 50/97, Loss: 0.3917
Epoch 3/10, Batch 60/97, Loss: 0.3230
Epoch 3/10, Batch 70/97, Loss: 0.2732
Epoch 3/10, Batch 80/97, Loss: 0.2707
Epoch 3/10, Batch 90/97, Loss: 0.4615
Epoch 3/10, Train Loss: 0.3458, Valid Loss: 0.3025
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2479
Epoch 4/10, Batch 20/97, Loss: 0.2045
Epoch 4/10, Batch 30/97, Loss: 0.4161
Epoch 4/10, Batch 40/97, Loss: 0.2283
Epoch 4/10, Batch 50/97, Loss: 0.2999
Epoch 4/10, Batch 60/97, Loss: 0.2329
Epoch 4/10, Batch 70/97, Loss: 0.2003
Epoch 4/10, Batch 80/97, Loss: 0.1710
Epoch 4/10, Batch 90/97, Loss: 0.2851
Epoch 4/10, Train Loss: 0.3026, Valid Loss: 0.2817
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2512
Epoch 5/10, Batch 20/97, Loss: 0.2686
Epoch 5/10, Batch 30/97, Loss: 0.1870
Epoch 5/10, Batch 40/97, Loss: 0.3129
Epoch 5/10, Batch 50/97, Loss: 0.3054
Epoch 5/10, Batch 60/97, Loss: 0.2914
Epoch 5/10, Batch 70/97, Loss: 0.2274
Epoch 5/10, Batch 80/97, Loss: 0.1319
Epoch 5/10, Batch 90/97, Loss: 0.2045
Epoch 5/10, Train Loss: 0.2800, Valid Loss: 0.2726
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3707
Epoch 6/10, Batch 20/97, Loss: 0.2533
Epoch 6/10, Batch 30/97, Loss: 0.1100
Epoch 6/10, Batch 40/97, Loss: 0.1899
Epoch 6/10, Batch 50/97, Loss: 0.2043
Epoch 6/10, Batch 60/97, Loss: 0.3340
Epoch 6/10, Batch 70/97, Loss: 0.3414
Epoch 6/10, Batch 80/97, Loss: 0.3605
Epoch 6/10, Batch 90/97, Loss: 0.2723
Epoch 6/10, Train Loss: 0.2542, Valid Loss: 0.2585
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1581
Epoch 7/10, Batch 20/97, Loss: 0.3133
Epoch 7/10, Batch 30/97, Loss: 0.3323
Epoch 7/10, Batch 40/97, Loss: 0.1643
Epoch 7/10, Batch 50/97, Loss: 0.2295
Epoch 7/10, Batch 60/97, Loss: 0.1398
Epoch 7/10, Batch 70/97, Loss: 0.2120
Epoch 7/10, Batch 80/97, Loss: 0.3064
Epoch 7/10, Batch 90/97, Loss: 0.1614
Epoch 7/10, Train Loss: 0.2299, Valid Loss: 0.2512
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.3095
Epoch 8/10, Batch 20/97, Loss: 0.2338
Epoch 8/10, Batch 30/97, Loss: 0.1703
Epoch 8/10, Batch 40/97, Loss: 0.1876
Epoch 8/10, Batch 50/97, Loss: 0.1626
Epoch 8/10, Batch 60/97, Loss: 0.1145
Epoch 8/10, Batch 70/97, Loss: 0.2783
Epoch 8/10, Batch 80/97, Loss: 0.2535
Epoch 8/10, Batch 90/97, Loss: 0.2439
Epoch 8/10, Train Loss: 0.2284, Valid Loss: 0.2508
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0897
Epoch 9/10, Batch 20/97, Loss: 0.1368
Epoch 9/10, Batch 30/97, Loss: 0.3109
Epoch 9/10, Batch 40/97, Loss: 0.2334
Epoch 9/10, Batch 50/97, Loss: 0.1306
Epoch 9/10, Batch 60/97, Loss: 0.1079
Epoch 9/10, Batch 70/97, Loss: 0.1304
Epoch 9/10, Batch 80/97, Loss: 0.2046
Epoch 9/10, Batch 90/97, Loss: 0.1039
Epoch 9/10, Train Loss: 0.2184, Valid Loss: 0.2489
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3276
Epoch 10/10, Batch 20/97, Loss: 0.1608
Epoch 10/10, Batch 30/97, Loss: 0.3296
Epoch 10/10, Batch 40/97, Loss: 0.1795
Epoch 10/10, Batch 50/97, Loss: 0.1895
Epoch 10/10, Batch 60/97, Loss: 0.1353
Epoch 10/10, Batch 70/97, Loss: 0.1499
Epoch 10/10, Batch 80/97, Loss: 0.1159
Epoch 10/10, Batch 90/97, Loss: 0.0878
Epoch 10/10, Train Loss: 0.2130, Valid Loss: 0.2465
Model saved!
Accuracy: 0.9042
Precision: 0.9013
Recall: 0.9042
F1-score: 0.9000
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2724
Epoch 1/10, Batch 20/97, Loss: 1.1708
Epoch 1/10, Batch 30/97, Loss: 0.6626
Epoch 1/10, Batch 40/97, Loss: 0.7831
Epoch 1/10, Batch 50/97, Loss: 0.6775
Epoch 1/10, Batch 60/97, Loss: 0.5736
Epoch 1/10, Batch 70/97, Loss: 0.6018
Epoch 1/10, Batch 80/97, Loss: 0.6036
Epoch 1/10, Batch 90/97, Loss: 0.4377
Epoch 1/10, Train Loss: 0.8044, Valid Loss: 0.4483
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4927
Epoch 2/10, Batch 20/97, Loss: 0.4009
Epoch 2/10, Batch 30/97, Loss: 0.3561
Epoch 2/10, Batch 40/97, Loss: 0.3277
Epoch 2/10, Batch 50/97, Loss: 0.3563
Epoch 2/10, Batch 60/97, Loss: 0.5237
Epoch 2/10, Batch 70/97, Loss: 0.4204
Epoch 2/10, Batch 80/97, Loss: 0.5522
Epoch 2/10, Batch 90/97, Loss: 0.4205
Epoch 2/10, Train Loss: 0.4135, Valid Loss: 0.3391
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3373
Epoch 3/10, Batch 20/97, Loss: 0.3787
Epoch 3/10, Batch 30/97, Loss: 0.4122
Epoch 3/10, Batch 40/97, Loss: 0.1979
Epoch 3/10, Batch 50/97, Loss: 0.4113
Epoch 3/10, Batch 60/97, Loss: 0.1687
Epoch 3/10, Batch 70/97, Loss: 0.3113
Epoch 3/10, Batch 80/97, Loss: 0.2709
Epoch 3/10, Batch 90/97, Loss: 0.2849
Epoch 3/10, Train Loss: 0.3311, Valid Loss: 0.3086
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3337
Epoch 4/10, Batch 20/97, Loss: 0.1857
Epoch 4/10, Batch 30/97, Loss: 0.3384
Epoch 4/10, Batch 40/97, Loss: 0.2250
Epoch 4/10, Batch 50/97, Loss: 0.3831
Epoch 4/10, Batch 60/97, Loss: 0.2413
Epoch 4/10, Batch 70/97, Loss: 0.1627
Epoch 4/10, Batch 80/97, Loss: 0.2538
Epoch 4/10, Batch 90/97, Loss: 0.2412
Epoch 4/10, Train Loss: 0.2766, Valid Loss: 0.2803
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2976
Epoch 5/10, Batch 20/97, Loss: 0.2463
Epoch 5/10, Batch 30/97, Loss: 0.2622
Epoch 5/10, Batch 40/97, Loss: 0.1931
Epoch 5/10, Batch 50/97, Loss: 0.2304
Epoch 5/10, Batch 60/97, Loss: 0.3544
Epoch 5/10, Batch 70/97, Loss: 0.2722
Epoch 5/10, Batch 80/97, Loss: 0.1954
Epoch 5/10, Batch 90/97, Loss: 0.1950
Epoch 5/10, Train Loss: 0.2573, Valid Loss: 0.2641
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2503
Epoch 6/10, Batch 20/97, Loss: 0.4245
Epoch 6/10, Batch 30/97, Loss: 0.1800
Epoch 6/10, Batch 40/97, Loss: 0.1008
Epoch 6/10, Batch 50/97, Loss: 0.2444
Epoch 6/10, Batch 60/97, Loss: 0.2759
Epoch 6/10, Batch 70/97, Loss: 0.1188
Epoch 6/10, Batch 80/97, Loss: 0.2356
Epoch 6/10, Batch 90/97, Loss: 0.3097
Epoch 6/10, Train Loss: 0.2401, Valid Loss: 0.2582
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2061
Epoch 7/10, Batch 20/97, Loss: 0.3452
Epoch 7/10, Batch 30/97, Loss: 0.1162
Epoch 7/10, Batch 40/97, Loss: 0.1805
Epoch 7/10, Batch 50/97, Loss: 0.2957
Epoch 7/10, Batch 60/97, Loss: 0.0868
Epoch 7/10, Batch 70/97, Loss: 0.2057
Epoch 7/10, Batch 80/97, Loss: 0.2020
Epoch 7/10, Batch 90/97, Loss: 0.1067
Epoch 7/10, Train Loss: 0.2164, Valid Loss: 0.2529
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2793
Epoch 8/10, Batch 20/97, Loss: 0.2393
Epoch 8/10, Batch 30/97, Loss: 0.1021
Epoch 8/10, Batch 40/97, Loss: 0.2651
Epoch 8/10, Batch 50/97, Loss: 0.1591
Epoch 8/10, Batch 60/97, Loss: 0.1706
Epoch 8/10, Batch 70/97, Loss: 0.1926
Epoch 8/10, Batch 80/97, Loss: 0.2810
Epoch 8/10, Batch 90/97, Loss: 0.2477
Epoch 8/10, Train Loss: 0.2132, Valid Loss: 0.2443
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1584
Epoch 9/10, Batch 20/97, Loss: 0.1310
Epoch 9/10, Batch 30/97, Loss: 0.2472
Epoch 9/10, Batch 40/97, Loss: 0.2552
Epoch 9/10, Batch 50/97, Loss: 0.1632
Epoch 9/10, Batch 60/97, Loss: 0.2342
Epoch 9/10, Batch 70/97, Loss: 0.1157
Epoch 9/10, Batch 80/97, Loss: 0.1760
Epoch 9/10, Batch 90/97, Loss: 0.2701
Epoch 9/10, Train Loss: 0.1990, Valid Loss: 0.2436
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2203
Epoch 10/10, Batch 20/97, Loss: 0.2288
Epoch 10/10, Batch 30/97, Loss: 0.2142
Epoch 10/10, Batch 40/97, Loss: 0.2331
Epoch 10/10, Batch 50/97, Loss: 0.0832
Epoch 10/10, Batch 60/97, Loss: 0.2658
Epoch 10/10, Batch 70/97, Loss: 0.2965
Epoch 10/10, Batch 80/97, Loss: 0.2594
Epoch 10/10, Batch 90/97, Loss: 0.2669
Epoch 10/10, Train Loss: 0.1954, Valid Loss: 0.2589
Accuracy: 0.9217
Precision: 0.9194
Recall: 0.9217
F1-score: 0.9201
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2340
Epoch 1/10, Batch 20/97, Loss: 1.1435
Epoch 1/10, Batch 30/97, Loss: 0.7863
Epoch 1/10, Batch 40/97, Loss: 0.7787
Epoch 1/10, Batch 50/97, Loss: 0.5362
Epoch 1/10, Batch 60/97, Loss: 0.8096
Epoch 1/10, Batch 70/97, Loss: 0.7561
Epoch 1/10, Batch 80/97, Loss: 0.6876
Epoch 1/10, Batch 90/97, Loss: 0.5305
Epoch 1/10, Train Loss: 0.8080, Valid Loss: 0.4715
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5592
Epoch 2/10, Batch 20/97, Loss: 0.4533
Epoch 2/10, Batch 30/97, Loss: 0.4541
Epoch 2/10, Batch 40/97, Loss: 0.4051
Epoch 2/10, Batch 50/97, Loss: 0.3591
Epoch 2/10, Batch 60/97, Loss: 0.3607
Epoch 2/10, Batch 70/97, Loss: 0.2700
Epoch 2/10, Batch 80/97, Loss: 0.3668
Epoch 2/10, Batch 90/97, Loss: 0.4316
Epoch 2/10, Train Loss: 0.4066, Valid Loss: 0.3707
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2225
Epoch 3/10, Batch 20/97, Loss: 0.2418
Epoch 3/10, Batch 30/97, Loss: 0.3045
Epoch 3/10, Batch 40/97, Loss: 0.3389
Epoch 3/10, Batch 50/97, Loss: 0.3319
Epoch 3/10, Batch 60/97, Loss: 0.1791
Epoch 3/10, Batch 70/97, Loss: 0.4260
Epoch 3/10, Batch 80/97, Loss: 0.2666
Epoch 3/10, Batch 90/97, Loss: 0.2763
Epoch 3/10, Train Loss: 0.3347, Valid Loss: 0.3282
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3146
Epoch 4/10, Batch 20/97, Loss: 0.3287
Epoch 4/10, Batch 30/97, Loss: 0.2346
Epoch 4/10, Batch 40/97, Loss: 0.2633
Epoch 4/10, Batch 50/97, Loss: 0.2719
Epoch 4/10, Batch 60/97, Loss: 0.3458
Epoch 4/10, Batch 70/97, Loss: 0.1909
Epoch 4/10, Batch 80/97, Loss: 0.1318
Epoch 4/10, Batch 90/97, Loss: 0.2877
Epoch 4/10, Train Loss: 0.2930, Valid Loss: 0.3092
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3755
Epoch 5/10, Batch 20/97, Loss: 0.2403
Epoch 5/10, Batch 30/97, Loss: 0.1574
Epoch 5/10, Batch 40/97, Loss: 0.1928
Epoch 5/10, Batch 50/97, Loss: 0.2972
Epoch 5/10, Batch 60/97, Loss: 0.2120
Epoch 5/10, Batch 70/97, Loss: 0.1963
Epoch 5/10, Batch 80/97, Loss: 0.2257
Epoch 5/10, Batch 90/97, Loss: 0.2395
Epoch 5/10, Train Loss: 0.2684, Valid Loss: 0.2929
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1962
Epoch 6/10, Batch 20/97, Loss: 0.2109
Epoch 6/10, Batch 30/97, Loss: 0.3889
Epoch 6/10, Batch 40/97, Loss: 0.1313
Epoch 6/10, Batch 50/97, Loss: 0.2995
Epoch 6/10, Batch 60/97, Loss: 0.3955
Epoch 6/10, Batch 70/97, Loss: 0.1902
Epoch 6/10, Batch 80/97, Loss: 0.3272
Epoch 6/10, Batch 90/97, Loss: 0.2356
Epoch 6/10, Train Loss: 0.2435, Valid Loss: 0.2770
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2919
Epoch 7/10, Batch 20/97, Loss: 0.1921
Epoch 7/10, Batch 30/97, Loss: 0.1736
Epoch 7/10, Batch 40/97, Loss: 0.1296
Epoch 7/10, Batch 50/97, Loss: 0.2646
Epoch 7/10, Batch 60/97, Loss: 0.0858
Epoch 7/10, Batch 70/97, Loss: 0.2571
Epoch 7/10, Batch 80/97, Loss: 0.1876
Epoch 7/10, Batch 90/97, Loss: 0.1213
Epoch 7/10, Train Loss: 0.2233, Valid Loss: 0.2725
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1775
Epoch 8/10, Batch 20/97, Loss: 0.1739
Epoch 8/10, Batch 30/97, Loss: 0.2985
Epoch 8/10, Batch 40/97, Loss: 0.2032
Epoch 8/10, Batch 50/97, Loss: 0.1795
Epoch 8/10, Batch 60/97, Loss: 0.2040
Epoch 8/10, Batch 70/97, Loss: 0.2234
Epoch 8/10, Batch 80/97, Loss: 0.2792
Epoch 8/10, Batch 90/97, Loss: 0.1819
Epoch 8/10, Train Loss: 0.2256, Valid Loss: 0.2689
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1124
Epoch 9/10, Batch 20/97, Loss: 0.1151
Epoch 9/10, Batch 30/97, Loss: 0.1876
Epoch 9/10, Batch 40/97, Loss: 0.2150
Epoch 9/10, Batch 50/97, Loss: 0.0860
Epoch 9/10, Batch 60/97, Loss: 0.2633
Epoch 9/10, Batch 70/97, Loss: 0.1116
Epoch 9/10, Batch 80/97, Loss: 0.1911
Epoch 9/10, Batch 90/97, Loss: 0.2022
Epoch 9/10, Train Loss: 0.2113, Valid Loss: 0.2612
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1030
Epoch 10/10, Batch 20/97, Loss: 0.1729
Epoch 10/10, Batch 30/97, Loss: 0.2788
Epoch 10/10, Batch 40/97, Loss: 0.1596
Epoch 10/10, Batch 50/97, Loss: 0.1783
Epoch 10/10, Batch 60/97, Loss: 0.0867
Epoch 10/10, Batch 70/97, Loss: 0.1663
Epoch 10/10, Batch 80/97, Loss: 0.3029
Epoch 10/10, Batch 90/97, Loss: 0.2218
Epoch 10/10, Train Loss: 0.2045, Valid Loss: 0.2620
Accuracy: 0.9124
Precision: 0.9099
Recall: 0.9124
F1-score: 0.9101
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.3513
Epoch 1/10, Batch 20/97, Loss: 1.1130
Epoch 1/10, Batch 30/97, Loss: 0.6189
Epoch 1/10, Batch 40/97, Loss: 0.6139
Epoch 1/10, Batch 50/97, Loss: 0.6577
Epoch 1/10, Batch 60/97, Loss: 0.7293
Epoch 1/10, Batch 70/97, Loss: 0.7043
Epoch 1/10, Batch 80/97, Loss: 0.5704
Epoch 1/10, Batch 90/97, Loss: 0.4741
Epoch 1/10, Train Loss: 0.7945, Valid Loss: 0.4423
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5646
Epoch 2/10, Batch 20/97, Loss: 0.5183
Epoch 2/10, Batch 30/97, Loss: 0.3200
Epoch 2/10, Batch 40/97, Loss: 0.3913
Epoch 2/10, Batch 50/97, Loss: 0.5897
Epoch 2/10, Batch 60/97, Loss: 0.2847
Epoch 2/10, Batch 70/97, Loss: 0.4818
Epoch 2/10, Batch 80/97, Loss: 0.4267
Epoch 2/10, Batch 90/97, Loss: 0.4000
Epoch 2/10, Train Loss: 0.4161, Valid Loss: 0.3288
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3912
Epoch 3/10, Batch 20/97, Loss: 0.3001
Epoch 3/10, Batch 30/97, Loss: 0.4290
Epoch 3/10, Batch 40/97, Loss: 0.2867
Epoch 3/10, Batch 50/97, Loss: 0.3489
Epoch 3/10, Batch 60/97, Loss: 0.4745
Epoch 3/10, Batch 70/97, Loss: 0.1918
Epoch 3/10, Batch 80/97, Loss: 0.2814
Epoch 3/10, Batch 90/97, Loss: 0.2584
Epoch 3/10, Train Loss: 0.3293, Valid Loss: 0.2802
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3816
Epoch 4/10, Batch 20/97, Loss: 0.2453
Epoch 4/10, Batch 30/97, Loss: 0.2109
Epoch 4/10, Batch 40/97, Loss: 0.1698
Epoch 4/10, Batch 50/97, Loss: 0.3407
Epoch 4/10, Batch 60/97, Loss: 0.2194
Epoch 4/10, Batch 70/97, Loss: 0.2819
Epoch 4/10, Batch 80/97, Loss: 0.2747
Epoch 4/10, Batch 90/97, Loss: 0.2898
Epoch 4/10, Train Loss: 0.2826, Valid Loss: 0.2603
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1979
Epoch 5/10, Batch 20/97, Loss: 0.3121
Epoch 5/10, Batch 30/97, Loss: 0.2362
Epoch 5/10, Batch 40/97, Loss: 0.1811
Epoch 5/10, Batch 50/97, Loss: 0.2912
Epoch 5/10, Batch 60/97, Loss: 0.1725
Epoch 5/10, Batch 70/97, Loss: 0.3141
Epoch 5/10, Batch 80/97, Loss: 0.2124
Epoch 5/10, Batch 90/97, Loss: 0.2991
Epoch 5/10, Train Loss: 0.2640, Valid Loss: 0.2493
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3698
Epoch 6/10, Batch 20/97, Loss: 0.3398
Epoch 6/10, Batch 30/97, Loss: 0.1883
Epoch 6/10, Batch 40/97, Loss: 0.2126
Epoch 6/10, Batch 50/97, Loss: 0.2197
Epoch 6/10, Batch 60/97, Loss: 0.2330
Epoch 6/10, Batch 70/97, Loss: 0.2721
Epoch 6/10, Batch 80/97, Loss: 0.2903
Epoch 6/10, Batch 90/97, Loss: 0.1531
Epoch 6/10, Train Loss: 0.2426, Valid Loss: 0.2389
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1985
Epoch 7/10, Batch 20/97, Loss: 0.2537
Epoch 7/10, Batch 30/97, Loss: 0.2076
Epoch 7/10, Batch 40/97, Loss: 0.1187
Epoch 7/10, Batch 50/97, Loss: 0.2804
Epoch 7/10, Batch 60/97, Loss: 0.1996
Epoch 7/10, Batch 70/97, Loss: 0.2754
Epoch 7/10, Batch 80/97, Loss: 0.1452
Epoch 7/10, Batch 90/97, Loss: 0.2106
Epoch 7/10, Train Loss: 0.2253, Valid Loss: 0.2332
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2826
Epoch 8/10, Batch 20/97, Loss: 0.2777
Epoch 8/10, Batch 30/97, Loss: 0.1637
Epoch 8/10, Batch 40/97, Loss: 0.2162
Epoch 8/10, Batch 50/97, Loss: 0.3042
Epoch 8/10, Batch 60/97, Loss: 0.3569
Epoch 8/10, Batch 70/97, Loss: 0.2916
Epoch 8/10, Batch 80/97, Loss: 0.1728
Epoch 8/10, Batch 90/97, Loss: 0.2093
Epoch 8/10, Train Loss: 0.2248, Valid Loss: 0.2318
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2213
Epoch 9/10, Batch 20/97, Loss: 0.1076
Epoch 9/10, Batch 30/97, Loss: 0.2848
Epoch 9/10, Batch 40/97, Loss: 0.1903
Epoch 9/10, Batch 50/97, Loss: 0.1157
Epoch 9/10, Batch 60/97, Loss: 0.1721
Epoch 9/10, Batch 70/97, Loss: 0.0844
Epoch 9/10, Batch 80/97, Loss: 0.1549
Epoch 9/10, Batch 90/97, Loss: 0.2046
Epoch 9/10, Train Loss: 0.2054, Valid Loss: 0.2230
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3808
Epoch 10/10, Batch 20/97, Loss: 0.1623
Epoch 10/10, Batch 30/97, Loss: 0.1867
Epoch 10/10, Batch 40/97, Loss: 0.1721
Epoch 10/10, Batch 50/97, Loss: 0.1066
Epoch 10/10, Batch 60/97, Loss: 0.1472
Epoch 10/10, Batch 70/97, Loss: 0.2370
Epoch 10/10, Batch 80/97, Loss: 0.1830
Epoch 10/10, Batch 90/97, Loss: 0.1322
Epoch 10/10, Train Loss: 0.1954, Valid Loss: 0.2185
Model saved!
Accuracy: 0.9182
Precision: 0.9161
Recall: 0.9182
F1-score: 0.9155
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2728
Epoch 1/10, Batch 20/97, Loss: 1.0680
Epoch 1/10, Batch 30/97, Loss: 0.6959
Epoch 1/10, Batch 40/97, Loss: 0.6509
Epoch 1/10, Batch 50/97, Loss: 0.7280
Epoch 1/10, Batch 60/97, Loss: 0.6598
Epoch 1/10, Batch 70/97, Loss: 0.6241
Epoch 1/10, Batch 80/97, Loss: 0.6122
Epoch 1/10, Batch 90/97, Loss: 0.4951
Epoch 1/10, Train Loss: 0.7864, Valid Loss: 0.4248
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5349
Epoch 2/10, Batch 20/97, Loss: 0.4331
Epoch 2/10, Batch 30/97, Loss: 0.4153
Epoch 2/10, Batch 40/97, Loss: 0.4389
Epoch 2/10, Batch 50/97, Loss: 0.4245
Epoch 2/10, Batch 60/97, Loss: 0.4977
Epoch 2/10, Batch 70/97, Loss: 0.3562
Epoch 2/10, Batch 80/97, Loss: 0.3396
Epoch 2/10, Batch 90/97, Loss: 0.5343
Epoch 2/10, Train Loss: 0.4036, Valid Loss: 0.3232
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4272
Epoch 3/10, Batch 20/97, Loss: 0.2923
Epoch 3/10, Batch 30/97, Loss: 0.4732
Epoch 3/10, Batch 40/97, Loss: 0.1593
Epoch 3/10, Batch 50/97, Loss: 0.3704
Epoch 3/10, Batch 60/97, Loss: 0.2834
Epoch 3/10, Batch 70/97, Loss: 0.3124
Epoch 3/10, Batch 80/97, Loss: 0.2316
Epoch 3/10, Batch 90/97, Loss: 0.1609
Epoch 3/10, Train Loss: 0.3272, Valid Loss: 0.2844
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3569
Epoch 4/10, Batch 20/97, Loss: 0.3335
Epoch 4/10, Batch 30/97, Loss: 0.2140
Epoch 4/10, Batch 40/97, Loss: 0.3402
Epoch 4/10, Batch 50/97, Loss: 0.4757
Epoch 4/10, Batch 60/97, Loss: 0.3029
Epoch 4/10, Batch 70/97, Loss: 0.3562
Epoch 4/10, Batch 80/97, Loss: 0.1908
Epoch 4/10, Batch 90/97, Loss: 0.1717
Epoch 4/10, Train Loss: 0.2866, Valid Loss: 0.2702
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3004
Epoch 5/10, Batch 20/97, Loss: 0.4661
Epoch 5/10, Batch 30/97, Loss: 0.2235
Epoch 5/10, Batch 40/97, Loss: 0.1611
Epoch 5/10, Batch 50/97, Loss: 0.3178
Epoch 5/10, Batch 60/97, Loss: 0.2673
Epoch 5/10, Batch 70/97, Loss: 0.2690
Epoch 5/10, Batch 80/97, Loss: 0.2124
Epoch 5/10, Batch 90/97, Loss: 0.2771
Epoch 5/10, Train Loss: 0.2620, Valid Loss: 0.2441
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2151
Epoch 6/10, Batch 20/97, Loss: 0.3436
Epoch 6/10, Batch 30/97, Loss: 0.1430
Epoch 6/10, Batch 40/97, Loss: 0.2014
Epoch 6/10, Batch 50/97, Loss: 0.4304
Epoch 6/10, Batch 60/97, Loss: 0.2239
Epoch 6/10, Batch 70/97, Loss: 0.1848
Epoch 6/10, Batch 80/97, Loss: 0.2887
Epoch 6/10, Batch 90/97, Loss: 0.0938
Epoch 6/10, Train Loss: 0.2332, Valid Loss: 0.2368
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2303
Epoch 7/10, Batch 20/97, Loss: 0.2151
Epoch 7/10, Batch 30/97, Loss: 0.1840
Epoch 7/10, Batch 40/97, Loss: 0.1547
Epoch 7/10, Batch 50/97, Loss: 0.1412
Epoch 7/10, Batch 60/97, Loss: 0.1059
Epoch 7/10, Batch 70/97, Loss: 0.4631
Epoch 7/10, Batch 80/97, Loss: 0.1564
Epoch 7/10, Batch 90/97, Loss: 0.0975
Epoch 7/10, Train Loss: 0.2203, Valid Loss: 0.2287
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2579
Epoch 8/10, Batch 20/97, Loss: 0.2143
Epoch 8/10, Batch 30/97, Loss: 0.1994
Epoch 8/10, Batch 40/97, Loss: 0.3672
Epoch 8/10, Batch 50/97, Loss: 0.2126
Epoch 8/10, Batch 60/97, Loss: 0.1479
Epoch 8/10, Batch 70/97, Loss: 0.2612
Epoch 8/10, Batch 80/97, Loss: 0.2761
Epoch 8/10, Batch 90/97, Loss: 0.2024
Epoch 8/10, Train Loss: 0.2130, Valid Loss: 0.2293
Epoch 9/10, Batch 10/97, Loss: 0.2543
Epoch 9/10, Batch 20/97, Loss: 0.1817
Epoch 9/10, Batch 30/97, Loss: 0.1400
Epoch 9/10, Batch 40/97, Loss: 0.2827
Epoch 9/10, Batch 50/97, Loss: 0.1226
Epoch 9/10, Batch 60/97, Loss: 0.2626
Epoch 9/10, Batch 70/97, Loss: 0.1945
Epoch 9/10, Batch 80/97, Loss: 0.2516
Epoch 9/10, Batch 90/97, Loss: 0.1335
Epoch 9/10, Train Loss: 0.1998, Valid Loss: 0.2210
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1925
Epoch 10/10, Batch 20/97, Loss: 0.0838
Epoch 10/10, Batch 30/97, Loss: 0.2294
Epoch 10/10, Batch 40/97, Loss: 0.1633
Epoch 10/10, Batch 50/97, Loss: 0.2343
Epoch 10/10, Batch 60/97, Loss: 0.1720
Epoch 10/10, Batch 70/97, Loss: 0.1631
Epoch 10/10, Batch 80/97, Loss: 0.1761
Epoch 10/10, Batch 90/97, Loss: 0.1898
Epoch 10/10, Train Loss: 0.1926, Valid Loss: 0.2178
Model saved!
Accuracy: 0.9171
Precision: 0.9142
Recall: 0.9171
F1-score: 0.9141
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2319
Epoch 1/10, Batch 20/97, Loss: 1.0249
Epoch 1/10, Batch 30/97, Loss: 0.8300
Epoch 1/10, Batch 40/97, Loss: 0.8743
Epoch 1/10, Batch 50/97, Loss: 0.7338
Epoch 1/10, Batch 60/97, Loss: 0.7399
Epoch 1/10, Batch 70/97, Loss: 0.5332
Epoch 1/10, Batch 80/97, Loss: 0.7759
Epoch 1/10, Batch 90/97, Loss: 0.4504
Epoch 1/10, Train Loss: 0.8158, Valid Loss: 0.4307
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5285
Epoch 2/10, Batch 20/97, Loss: 0.5364
Epoch 2/10, Batch 30/97, Loss: 0.3846
Epoch 2/10, Batch 40/97, Loss: 0.3556
Epoch 2/10, Batch 50/97, Loss: 0.3456
Epoch 2/10, Batch 60/97, Loss: 0.4230
Epoch 2/10, Batch 70/97, Loss: 0.4185
Epoch 2/10, Batch 80/97, Loss: 0.2713
Epoch 2/10, Batch 90/97, Loss: 0.3550
Epoch 2/10, Train Loss: 0.4258, Valid Loss: 0.3217
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4422
Epoch 3/10, Batch 20/97, Loss: 0.3806
Epoch 3/10, Batch 30/97, Loss: 0.3132
Epoch 3/10, Batch 40/97, Loss: 0.3631
Epoch 3/10, Batch 50/97, Loss: 0.3034
Epoch 3/10, Batch 60/97, Loss: 0.3204
Epoch 3/10, Batch 70/97, Loss: 0.1638
Epoch 3/10, Batch 80/97, Loss: 0.2415
Epoch 3/10, Batch 90/97, Loss: 0.2306
Epoch 3/10, Train Loss: 0.3472, Valid Loss: 0.2784
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4095
Epoch 4/10, Batch 20/97, Loss: 0.2171
Epoch 4/10, Batch 30/97, Loss: 0.2743
Epoch 4/10, Batch 40/97, Loss: 0.2792
Epoch 4/10, Batch 50/97, Loss: 0.2790
Epoch 4/10, Batch 60/97, Loss: 0.3404
Epoch 4/10, Batch 70/97, Loss: 0.3606
Epoch 4/10, Batch 80/97, Loss: 0.2839
Epoch 4/10, Batch 90/97, Loss: 0.1878
Epoch 4/10, Train Loss: 0.2995, Valid Loss: 0.2544
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2933
Epoch 5/10, Batch 20/97, Loss: 0.5305
Epoch 5/10, Batch 30/97, Loss: 0.2049
Epoch 5/10, Batch 40/97, Loss: 0.2025
Epoch 5/10, Batch 50/97, Loss: 0.2272
Epoch 5/10, Batch 60/97, Loss: 0.2324
Epoch 5/10, Batch 70/97, Loss: 0.2594
Epoch 5/10, Batch 80/97, Loss: 0.2786
Epoch 5/10, Batch 90/97, Loss: 0.4307
Epoch 5/10, Train Loss: 0.2666, Valid Loss: 0.2469
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1398
Epoch 6/10, Batch 20/97, Loss: 0.2219
Epoch 6/10, Batch 30/97, Loss: 0.2226
Epoch 6/10, Batch 40/97, Loss: 0.2393
Epoch 6/10, Batch 50/97, Loss: 0.1580
Epoch 6/10, Batch 60/97, Loss: 0.2427
Epoch 6/10, Batch 70/97, Loss: 0.3147
Epoch 6/10, Batch 80/97, Loss: 0.3530
Epoch 6/10, Batch 90/97, Loss: 0.2234
Epoch 6/10, Train Loss: 0.2508, Valid Loss: 0.2339
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2668
Epoch 7/10, Batch 20/97, Loss: 0.1865
Epoch 7/10, Batch 30/97, Loss: 0.1475
Epoch 7/10, Batch 40/97, Loss: 0.2712
Epoch 7/10, Batch 50/97, Loss: 0.1900
Epoch 7/10, Batch 60/97, Loss: 0.1681
Epoch 7/10, Batch 70/97, Loss: 0.1605
Epoch 7/10, Batch 80/97, Loss: 0.1306
Epoch 7/10, Batch 90/97, Loss: 0.1948
Epoch 7/10, Train Loss: 0.2380, Valid Loss: 0.2284
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2388
Epoch 8/10, Batch 20/97, Loss: 0.2177
Epoch 8/10, Batch 30/97, Loss: 0.1566
Epoch 8/10, Batch 40/97, Loss: 0.1743
Epoch 8/10, Batch 50/97, Loss: 0.2726
Epoch 8/10, Batch 60/97, Loss: 0.1446
Epoch 8/10, Batch 70/97, Loss: 0.3378
Epoch 8/10, Batch 80/97, Loss: 0.1005
Epoch 8/10, Batch 90/97, Loss: 0.1929
Epoch 8/10, Train Loss: 0.2263, Valid Loss: 0.2268
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0891
Epoch 9/10, Batch 20/97, Loss: 0.1523
Epoch 9/10, Batch 30/97, Loss: 0.2583
Epoch 9/10, Batch 40/97, Loss: 0.1344
Epoch 9/10, Batch 50/97, Loss: 0.1758
Epoch 9/10, Batch 60/97, Loss: 0.2264
Epoch 9/10, Batch 70/97, Loss: 0.1171
Epoch 9/10, Batch 80/97, Loss: 0.2595
Epoch 9/10, Batch 90/97, Loss: 0.2070
Epoch 9/10, Train Loss: 0.2228, Valid Loss: 0.2225
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2328
Epoch 10/10, Batch 20/97, Loss: 0.1296
Epoch 10/10, Batch 30/97, Loss: 0.3413
Epoch 10/10, Batch 40/97, Loss: 0.2487
Epoch 10/10, Batch 50/97, Loss: 0.1283
Epoch 10/10, Batch 60/97, Loss: 0.1409
Epoch 10/10, Batch 70/97, Loss: 0.1699
Epoch 10/10, Batch 80/97, Loss: 0.1333
Epoch 10/10, Batch 90/97, Loss: 0.2190
Epoch 10/10, Train Loss: 0.2175, Valid Loss: 0.2264
Accuracy: 0.9136
Precision: 0.9118
Recall: 0.9136
F1-score: 0.9118
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2776
Epoch 1/10, Batch 20/97, Loss: 1.1228
Epoch 1/10, Batch 30/97, Loss: 0.8016
Epoch 1/10, Batch 40/97, Loss: 0.6717
Epoch 1/10, Batch 50/97, Loss: 0.7420
Epoch 1/10, Batch 60/97, Loss: 0.6590
Epoch 1/10, Batch 70/97, Loss: 0.5614
Epoch 1/10, Batch 80/97, Loss: 0.7301
Epoch 1/10, Batch 90/97, Loss: 0.4512
Epoch 1/10, Train Loss: 0.8163, Valid Loss: 0.4307
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4959
Epoch 2/10, Batch 20/97, Loss: 0.4043
Epoch 2/10, Batch 30/97, Loss: 0.4188
Epoch 2/10, Batch 40/97, Loss: 0.3068
Epoch 2/10, Batch 50/97, Loss: 0.5096
Epoch 2/10, Batch 60/97, Loss: 0.4163
Epoch 2/10, Batch 70/97, Loss: 0.3290
Epoch 2/10, Batch 80/97, Loss: 0.4384
Epoch 2/10, Batch 90/97, Loss: 0.3969
Epoch 2/10, Train Loss: 0.4245, Valid Loss: 0.3228
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2666
Epoch 3/10, Batch 20/97, Loss: 0.3762
Epoch 3/10, Batch 30/97, Loss: 0.3320
Epoch 3/10, Batch 40/97, Loss: 0.3449
Epoch 3/10, Batch 50/97, Loss: 0.3602
Epoch 3/10, Batch 60/97, Loss: 0.3527
Epoch 3/10, Batch 70/97, Loss: 0.2750
Epoch 3/10, Batch 80/97, Loss: 0.2866
Epoch 3/10, Batch 90/97, Loss: 0.2986
Epoch 3/10, Train Loss: 0.3358, Valid Loss: 0.2861
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3715
Epoch 4/10, Batch 20/97, Loss: 0.2000
Epoch 4/10, Batch 30/97, Loss: 0.2864
Epoch 4/10, Batch 40/97, Loss: 0.1858
Epoch 4/10, Batch 50/97, Loss: 0.2705
Epoch 4/10, Batch 60/97, Loss: 0.3102
Epoch 4/10, Batch 70/97, Loss: 0.4124
Epoch 4/10, Batch 80/97, Loss: 0.1752
Epoch 4/10, Batch 90/97, Loss: 0.2006
Epoch 4/10, Train Loss: 0.2951, Valid Loss: 0.2678
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3173
Epoch 5/10, Batch 20/97, Loss: 0.3816
Epoch 5/10, Batch 30/97, Loss: 0.2465
Epoch 5/10, Batch 40/97, Loss: 0.1860
Epoch 5/10, Batch 50/97, Loss: 0.2158
Epoch 5/10, Batch 60/97, Loss: 0.1450
Epoch 5/10, Batch 70/97, Loss: 0.3146
Epoch 5/10, Batch 80/97, Loss: 0.1828
Epoch 5/10, Batch 90/97, Loss: 0.2327
Epoch 5/10, Train Loss: 0.2683, Valid Loss: 0.2570
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3016
Epoch 6/10, Batch 20/97, Loss: 0.3669
Epoch 6/10, Batch 30/97, Loss: 0.3030
Epoch 6/10, Batch 40/97, Loss: 0.3924
Epoch 6/10, Batch 50/97, Loss: 0.1472
Epoch 6/10, Batch 60/97, Loss: 0.1250
Epoch 6/10, Batch 70/97, Loss: 0.2144
Epoch 6/10, Batch 80/97, Loss: 0.3240
Epoch 6/10, Batch 90/97, Loss: 0.4087
Epoch 6/10, Train Loss: 0.2550, Valid Loss: 0.2437
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2580
Epoch 7/10, Batch 20/97, Loss: 0.5009
Epoch 7/10, Batch 30/97, Loss: 0.1944
Epoch 7/10, Batch 40/97, Loss: 0.2044
Epoch 7/10, Batch 50/97, Loss: 0.2243
Epoch 7/10, Batch 60/97, Loss: 0.1950
Epoch 7/10, Batch 70/97, Loss: 0.3641
Epoch 7/10, Batch 80/97, Loss: 0.2123
Epoch 7/10, Batch 90/97, Loss: 0.1236
Epoch 7/10, Train Loss: 0.2346, Valid Loss: 0.2372
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1277
Epoch 8/10, Batch 20/97, Loss: 0.1349
Epoch 8/10, Batch 30/97, Loss: 0.2656
Epoch 8/10, Batch 40/97, Loss: 0.2481
Epoch 8/10, Batch 50/97, Loss: 0.2079
Epoch 8/10, Batch 60/97, Loss: 0.2983
Epoch 8/10, Batch 70/97, Loss: 0.2434
Epoch 8/10, Batch 80/97, Loss: 0.2681
Epoch 8/10, Batch 90/97, Loss: 0.2227
Epoch 8/10, Train Loss: 0.2264, Valid Loss: 0.2325
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1508
Epoch 9/10, Batch 20/97, Loss: 0.0939
Epoch 9/10, Batch 30/97, Loss: 0.2054
Epoch 9/10, Batch 40/97, Loss: 0.4207
Epoch 9/10, Batch 50/97, Loss: 0.0906
Epoch 9/10, Batch 60/97, Loss: 0.3011
Epoch 9/10, Batch 70/97, Loss: 0.1974
Epoch 9/10, Batch 80/97, Loss: 0.1553
Epoch 9/10, Batch 90/97, Loss: 0.1426
Epoch 9/10, Train Loss: 0.2072, Valid Loss: 0.2256
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3039
Epoch 10/10, Batch 20/97, Loss: 0.1441
Epoch 10/10, Batch 30/97, Loss: 0.1466
Epoch 10/10, Batch 40/97, Loss: 0.1112
Epoch 10/10, Batch 50/97, Loss: 0.1221
Epoch 10/10, Batch 60/97, Loss: 0.2153
Epoch 10/10, Batch 70/97, Loss: 0.3712
Epoch 10/10, Batch 80/97, Loss: 0.0786
Epoch 10/10, Batch 90/97, Loss: 0.2246
Epoch 10/10, Train Loss: 0.2154, Valid Loss: 0.2211
Model saved!
Accuracy: 0.9147
Precision: 0.9128
Recall: 0.9147
F1-score: 0.9127
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.3007
Epoch 1/10, Batch 20/97, Loss: 1.0902
Epoch 1/10, Batch 30/97, Loss: 0.7233
Epoch 1/10, Batch 40/97, Loss: 0.6515
Epoch 1/10, Batch 50/97, Loss: 0.7302
Epoch 1/10, Batch 60/97, Loss: 0.6037
Epoch 1/10, Batch 70/97, Loss: 0.6206
Epoch 1/10, Batch 80/97, Loss: 0.5710
Epoch 1/10, Batch 90/97, Loss: 0.6074
Epoch 1/10, Train Loss: 0.7995, Valid Loss: 0.4378
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5912
Epoch 2/10, Batch 20/97, Loss: 0.4191
Epoch 2/10, Batch 30/97, Loss: 0.4304
Epoch 2/10, Batch 40/97, Loss: 0.2762
Epoch 2/10, Batch 50/97, Loss: 0.4533
Epoch 2/10, Batch 60/97, Loss: 0.3664
Epoch 2/10, Batch 70/97, Loss: 0.2595
Epoch 2/10, Batch 80/97, Loss: 0.2787
Epoch 2/10, Batch 90/97, Loss: 0.4309
Epoch 2/10, Train Loss: 0.4107, Valid Loss: 0.3287
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3970
Epoch 3/10, Batch 20/97, Loss: 0.3663
Epoch 3/10, Batch 30/97, Loss: 0.3380
Epoch 3/10, Batch 40/97, Loss: 0.2626
Epoch 3/10, Batch 50/97, Loss: 0.4246
Epoch 3/10, Batch 60/97, Loss: 0.2688
Epoch 3/10, Batch 70/97, Loss: 0.3065
Epoch 3/10, Batch 80/97, Loss: 0.1970
Epoch 3/10, Batch 90/97, Loss: 0.2488
Epoch 3/10, Train Loss: 0.3301, Valid Loss: 0.2810
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4030
Epoch 4/10, Batch 20/97, Loss: 0.2205
Epoch 4/10, Batch 30/97, Loss: 0.2851
Epoch 4/10, Batch 40/97, Loss: 0.1743
Epoch 4/10, Batch 50/97, Loss: 0.2131
Epoch 4/10, Batch 60/97, Loss: 0.2929
Epoch 4/10, Batch 70/97, Loss: 0.2875
Epoch 4/10, Batch 80/97, Loss: 0.1816
Epoch 4/10, Batch 90/97, Loss: 0.2544
Epoch 4/10, Train Loss: 0.2848, Valid Loss: 0.2683
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.4085
Epoch 5/10, Batch 20/97, Loss: 0.4552
Epoch 5/10, Batch 30/97, Loss: 0.1972
Epoch 5/10, Batch 40/97, Loss: 0.3740
Epoch 5/10, Batch 50/97, Loss: 0.3623
Epoch 5/10, Batch 60/97, Loss: 0.1992
Epoch 5/10, Batch 70/97, Loss: 0.1798
Epoch 5/10, Batch 80/97, Loss: 0.1826
Epoch 5/10, Batch 90/97, Loss: 0.1906
Epoch 5/10, Train Loss: 0.2666, Valid Loss: 0.2450
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2398
Epoch 6/10, Batch 20/97, Loss: 0.3364
Epoch 6/10, Batch 30/97, Loss: 0.1464
Epoch 6/10, Batch 40/97, Loss: 0.1726
Epoch 6/10, Batch 50/97, Loss: 0.3827
Epoch 6/10, Batch 60/97, Loss: 0.3788
Epoch 6/10, Batch 70/97, Loss: 0.1854
Epoch 6/10, Batch 80/97, Loss: 0.3368
Epoch 6/10, Batch 90/97, Loss: 0.2247
Epoch 6/10, Train Loss: 0.2440, Valid Loss: 0.2383
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2985
Epoch 7/10, Batch 20/97, Loss: 0.2106
Epoch 7/10, Batch 30/97, Loss: 0.2468
Epoch 7/10, Batch 40/97, Loss: 0.1788
Epoch 7/10, Batch 50/97, Loss: 0.1683
Epoch 7/10, Batch 60/97, Loss: 0.2592
Epoch 7/10, Batch 70/97, Loss: 0.0813
Epoch 7/10, Batch 80/97, Loss: 0.2304
Epoch 7/10, Batch 90/97, Loss: 0.2109
Epoch 7/10, Train Loss: 0.2288, Valid Loss: 0.2321
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2818
Epoch 8/10, Batch 20/97, Loss: 0.1275
Epoch 8/10, Batch 30/97, Loss: 0.0999
Epoch 8/10, Batch 40/97, Loss: 0.2037
Epoch 8/10, Batch 50/97, Loss: 0.1757
Epoch 8/10, Batch 60/97, Loss: 0.1791
Epoch 8/10, Batch 70/97, Loss: 0.2695
Epoch 8/10, Batch 80/97, Loss: 0.1469
Epoch 8/10, Batch 90/97, Loss: 0.2259
Epoch 8/10, Train Loss: 0.2153, Valid Loss: 0.2267
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2318
Epoch 9/10, Batch 20/97, Loss: 0.1560
Epoch 9/10, Batch 30/97, Loss: 0.2139
Epoch 9/10, Batch 40/97, Loss: 0.2355
Epoch 9/10, Batch 50/97, Loss: 0.1894
Epoch 9/10, Batch 60/97, Loss: 0.2128
Epoch 9/10, Batch 70/97, Loss: 0.0594
Epoch 9/10, Batch 80/97, Loss: 0.2186
Epoch 9/10, Batch 90/97, Loss: 0.1612
Epoch 9/10, Train Loss: 0.2097, Valid Loss: 0.2238
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1800
Epoch 10/10, Batch 20/97, Loss: 0.0748
Epoch 10/10, Batch 30/97, Loss: 0.1609
Epoch 10/10, Batch 40/97, Loss: 0.2181
Epoch 10/10, Batch 50/97, Loss: 0.1264
Epoch 10/10, Batch 60/97, Loss: 0.1692
Epoch 10/10, Batch 70/97, Loss: 0.2831
Epoch 10/10, Batch 80/97, Loss: 0.1362
Epoch 10/10, Batch 90/97, Loss: 0.2283
Epoch 10/10, Train Loss: 0.2105, Valid Loss: 0.2225
Model saved!
Accuracy: 0.9124
Precision: 0.9089
Recall: 0.9124
F1-score: 0.9089
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2669
Epoch 1/10, Batch 20/97, Loss: 1.0321
Epoch 1/10, Batch 30/97, Loss: 0.8260
Epoch 1/10, Batch 40/97, Loss: 0.7559
Epoch 1/10, Batch 50/97, Loss: 0.6173
Epoch 1/10, Batch 60/97, Loss: 0.6101
Epoch 1/10, Batch 70/97, Loss: 0.6701
Epoch 1/10, Batch 80/97, Loss: 0.6711
Epoch 1/10, Batch 90/97, Loss: 0.5929
Epoch 1/10, Train Loss: 0.8036, Valid Loss: 0.4383
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4687
Epoch 2/10, Batch 20/97, Loss: 0.3700
Epoch 2/10, Batch 30/97, Loss: 0.3794
Epoch 2/10, Batch 40/97, Loss: 0.3374
Epoch 2/10, Batch 50/97, Loss: 0.4338
Epoch 2/10, Batch 60/97, Loss: 0.3423
Epoch 2/10, Batch 70/97, Loss: 0.2941
Epoch 2/10, Batch 80/97, Loss: 0.5179
Epoch 2/10, Batch 90/97, Loss: 0.3605
Epoch 2/10, Train Loss: 0.4109, Valid Loss: 0.3379
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3977
Epoch 3/10, Batch 20/97, Loss: 0.3344
Epoch 3/10, Batch 30/97, Loss: 0.5528
Epoch 3/10, Batch 40/97, Loss: 0.2610
Epoch 3/10, Batch 50/97, Loss: 0.3739
Epoch 3/10, Batch 60/97, Loss: 0.2326
Epoch 3/10, Batch 70/97, Loss: 0.2997
Epoch 3/10, Batch 80/97, Loss: 0.2322
Epoch 3/10, Batch 90/97, Loss: 0.2620
Epoch 3/10, Train Loss: 0.3327, Valid Loss: 0.2995
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.5328
Epoch 4/10, Batch 20/97, Loss: 0.2282
Epoch 4/10, Batch 30/97, Loss: 0.3592
Epoch 4/10, Batch 40/97, Loss: 0.1701
Epoch 4/10, Batch 50/97, Loss: 0.2495
Epoch 4/10, Batch 60/97, Loss: 0.2873
Epoch 4/10, Batch 70/97, Loss: 0.2819
Epoch 4/10, Batch 80/97, Loss: 0.2256
Epoch 4/10, Batch 90/97, Loss: 0.3245
Epoch 4/10, Train Loss: 0.2818, Valid Loss: 0.2832
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.4758
Epoch 5/10, Batch 20/97, Loss: 0.3159
Epoch 5/10, Batch 30/97, Loss: 0.1763
Epoch 5/10, Batch 40/97, Loss: 0.2470
Epoch 5/10, Batch 50/97, Loss: 0.4293
Epoch 5/10, Batch 60/97, Loss: 0.2335
Epoch 5/10, Batch 70/97, Loss: 0.3341
Epoch 5/10, Batch 80/97, Loss: 0.3064
Epoch 5/10, Batch 90/97, Loss: 0.2218
Epoch 5/10, Train Loss: 0.2623, Valid Loss: 0.2763
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2795
Epoch 6/10, Batch 20/97, Loss: 0.4031
Epoch 6/10, Batch 30/97, Loss: 0.1238
Epoch 6/10, Batch 40/97, Loss: 0.2393
Epoch 6/10, Batch 50/97, Loss: 0.2454
Epoch 6/10, Batch 60/97, Loss: 0.2855
Epoch 6/10, Batch 70/97, Loss: 0.2142
Epoch 6/10, Batch 80/97, Loss: 0.3630
Epoch 6/10, Batch 90/97, Loss: 0.2376
Epoch 6/10, Train Loss: 0.2413, Valid Loss: 0.2649
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.0944
Epoch 7/10, Batch 20/97, Loss: 0.2746
Epoch 7/10, Batch 30/97, Loss: 0.2386
Epoch 7/10, Batch 40/97, Loss: 0.3190
Epoch 7/10, Batch 50/97, Loss: 0.2045
Epoch 7/10, Batch 60/97, Loss: 0.1156
Epoch 7/10, Batch 70/97, Loss: 0.1585
Epoch 7/10, Batch 80/97, Loss: 0.1730
Epoch 7/10, Batch 90/97, Loss: 0.1907
Epoch 7/10, Train Loss: 0.2257, Valid Loss: 0.2577
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1086
Epoch 8/10, Batch 20/97, Loss: 0.2015
Epoch 8/10, Batch 30/97, Loss: 0.1881
Epoch 8/10, Batch 40/97, Loss: 0.1989
Epoch 8/10, Batch 50/97, Loss: 0.2092
Epoch 8/10, Batch 60/97, Loss: 0.2125
Epoch 8/10, Batch 70/97, Loss: 0.1755
Epoch 8/10, Batch 80/97, Loss: 0.2085
Epoch 8/10, Batch 90/97, Loss: 0.2196
Epoch 8/10, Train Loss: 0.2196, Valid Loss: 0.2547
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2010
Epoch 9/10, Batch 20/97, Loss: 0.2350
Epoch 9/10, Batch 30/97, Loss: 0.2298
Epoch 9/10, Batch 40/97, Loss: 0.1637
Epoch 9/10, Batch 50/97, Loss: 0.1515
Epoch 9/10, Batch 60/97, Loss: 0.2654
Epoch 9/10, Batch 70/97, Loss: 0.1273
Epoch 9/10, Batch 80/97, Loss: 0.1871
Epoch 9/10, Batch 90/97, Loss: 0.0960
Epoch 9/10, Train Loss: 0.2089, Valid Loss: 0.2473
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1795
Epoch 10/10, Batch 20/97, Loss: 0.1108
Epoch 10/10, Batch 30/97, Loss: 0.0942
Epoch 10/10, Batch 40/97, Loss: 0.1828
Epoch 10/10, Batch 50/97, Loss: 0.1456
Epoch 10/10, Batch 60/97, Loss: 0.0931
Epoch 10/10, Batch 70/97, Loss: 0.3097
Epoch 10/10, Batch 80/97, Loss: 0.0986
Epoch 10/10, Batch 90/97, Loss: 0.1507
Epoch 10/10, Train Loss: 0.1916, Valid Loss: 0.2506
Accuracy: 0.9194
Precision: 0.9168
Recall: 0.9194
F1-score: 0.9175
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2474
Epoch 1/10, Batch 20/97, Loss: 1.0922
Epoch 1/10, Batch 30/97, Loss: 0.7123
Epoch 1/10, Batch 40/97, Loss: 0.6572
Epoch 1/10, Batch 50/97, Loss: 0.5655
Epoch 1/10, Batch 60/97, Loss: 0.7515
Epoch 1/10, Batch 70/97, Loss: 0.6241
Epoch 1/10, Batch 80/97, Loss: 0.5453
Epoch 1/10, Batch 90/97, Loss: 0.5858
Epoch 1/10, Train Loss: 0.7964, Valid Loss: 0.4433
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3727
Epoch 2/10, Batch 20/97, Loss: 0.4835
Epoch 2/10, Batch 30/97, Loss: 0.4325
Epoch 2/10, Batch 40/97, Loss: 0.4250
Epoch 2/10, Batch 50/97, Loss: 0.4499
Epoch 2/10, Batch 60/97, Loss: 0.4401
Epoch 2/10, Batch 70/97, Loss: 0.2754
Epoch 2/10, Batch 80/97, Loss: 0.3090
Epoch 2/10, Batch 90/97, Loss: 0.4300
Epoch 2/10, Train Loss: 0.4041, Valid Loss: 0.3438
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3853
Epoch 3/10, Batch 20/97, Loss: 0.2253
Epoch 3/10, Batch 30/97, Loss: 0.3405
Epoch 3/10, Batch 40/97, Loss: 0.3037
Epoch 3/10, Batch 50/97, Loss: 0.2143
Epoch 3/10, Batch 60/97, Loss: 0.4079
Epoch 3/10, Batch 70/97, Loss: 0.3949
Epoch 3/10, Batch 80/97, Loss: 0.2528
Epoch 3/10, Batch 90/97, Loss: 0.2876
Epoch 3/10, Train Loss: 0.3260, Valid Loss: 0.3051
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3829
Epoch 4/10, Batch 20/97, Loss: 0.1811
Epoch 4/10, Batch 30/97, Loss: 0.2615
Epoch 4/10, Batch 40/97, Loss: 0.3370
Epoch 4/10, Batch 50/97, Loss: 0.3789
Epoch 4/10, Batch 60/97, Loss: 0.1822
Epoch 4/10, Batch 70/97, Loss: 0.3135
Epoch 4/10, Batch 80/97, Loss: 0.3491
Epoch 4/10, Batch 90/97, Loss: 0.2295
Epoch 4/10, Train Loss: 0.2749, Valid Loss: 0.2745
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1935
Epoch 5/10, Batch 20/97, Loss: 0.2047
Epoch 5/10, Batch 30/97, Loss: 0.1435
Epoch 5/10, Batch 40/97, Loss: 0.2229
Epoch 5/10, Batch 50/97, Loss: 0.1523
Epoch 5/10, Batch 60/97, Loss: 0.2537
Epoch 5/10, Batch 70/97, Loss: 0.2187
Epoch 5/10, Batch 80/97, Loss: 0.2198
Epoch 5/10, Batch 90/97, Loss: 0.2087
Epoch 5/10, Train Loss: 0.2584, Valid Loss: 0.2643
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2452
Epoch 6/10, Batch 20/97, Loss: 0.4461
Epoch 6/10, Batch 30/97, Loss: 0.1376
Epoch 6/10, Batch 40/97, Loss: 0.1589
Epoch 6/10, Batch 50/97, Loss: 0.2049
Epoch 6/10, Batch 60/97, Loss: 0.2644
Epoch 6/10, Batch 70/97, Loss: 0.1594
Epoch 6/10, Batch 80/97, Loss: 0.3333
Epoch 6/10, Batch 90/97, Loss: 0.2073
Epoch 6/10, Train Loss: 0.2410, Valid Loss: 0.2483
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1715
Epoch 7/10, Batch 20/97, Loss: 0.3870
Epoch 7/10, Batch 30/97, Loss: 0.1614
Epoch 7/10, Batch 40/97, Loss: 0.1421
Epoch 7/10, Batch 50/97, Loss: 0.1672
Epoch 7/10, Batch 60/97, Loss: 0.1181
Epoch 7/10, Batch 70/97, Loss: 0.1505
Epoch 7/10, Batch 80/97, Loss: 0.2340
Epoch 7/10, Batch 90/97, Loss: 0.1818
Epoch 7/10, Train Loss: 0.2174, Valid Loss: 0.2539
Epoch 8/10, Batch 10/97, Loss: 0.1614
Epoch 8/10, Batch 20/97, Loss: 0.1841
Epoch 8/10, Batch 30/97, Loss: 0.1522
Epoch 8/10, Batch 40/97, Loss: 0.3069
Epoch 8/10, Batch 50/97, Loss: 0.2867
Epoch 8/10, Batch 60/97, Loss: 0.1916
Epoch 8/10, Batch 70/97, Loss: 0.1521
Epoch 8/10, Batch 80/97, Loss: 0.3288
Epoch 8/10, Batch 90/97, Loss: 0.2014
Epoch 8/10, Train Loss: 0.2088, Valid Loss: 0.2419
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1555
Epoch 9/10, Batch 20/97, Loss: 0.2549
Epoch 9/10, Batch 30/97, Loss: 0.3545
Epoch 9/10, Batch 40/97, Loss: 0.2171
Epoch 9/10, Batch 50/97, Loss: 0.1362
Epoch 9/10, Batch 60/97, Loss: 0.2109
Epoch 9/10, Batch 70/97, Loss: 0.2671
Epoch 9/10, Batch 80/97, Loss: 0.1587
Epoch 9/10, Batch 90/97, Loss: 0.1688
Epoch 9/10, Train Loss: 0.1926, Valid Loss: 0.2418
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1996
Epoch 10/10, Batch 20/97, Loss: 0.1113
Epoch 10/10, Batch 30/97, Loss: 0.2076
Epoch 10/10, Batch 40/97, Loss: 0.0675
Epoch 10/10, Batch 50/97, Loss: 0.3864
Epoch 10/10, Batch 60/97, Loss: 0.1822
Epoch 10/10, Batch 70/97, Loss: 0.2806
Epoch 10/10, Batch 80/97, Loss: 0.1554
Epoch 10/10, Batch 90/97, Loss: 0.2036
Epoch 10/10, Train Loss: 0.1951, Valid Loss: 0.2364
Model saved!
Accuracy: 0.9171
Precision: 0.9138
Recall: 0.9171
F1-score: 0.9147
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2405
Epoch 1/10, Batch 20/97, Loss: 1.0366
Epoch 1/10, Batch 30/97, Loss: 0.7205
Epoch 1/10, Batch 40/97, Loss: 0.8498
Epoch 1/10, Batch 50/97, Loss: 0.6465
Epoch 1/10, Batch 60/97, Loss: 0.7081
Epoch 1/10, Batch 70/97, Loss: 0.5808
Epoch 1/10, Batch 80/97, Loss: 0.7826
Epoch 1/10, Batch 90/97, Loss: 0.5702
Epoch 1/10, Train Loss: 0.7927, Valid Loss: 0.4634
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4862
Epoch 2/10, Batch 20/97, Loss: 0.3285
Epoch 2/10, Batch 30/97, Loss: 0.3605
Epoch 2/10, Batch 40/97, Loss: 0.3714
Epoch 2/10, Batch 50/97, Loss: 0.4564
Epoch 2/10, Batch 60/97, Loss: 0.4224
Epoch 2/10, Batch 70/97, Loss: 0.5299
Epoch 2/10, Batch 80/97, Loss: 0.1847
Epoch 2/10, Batch 90/97, Loss: 0.3845
Epoch 2/10, Train Loss: 0.4071, Valid Loss: 0.3469
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3663
Epoch 3/10, Batch 20/97, Loss: 0.3133
Epoch 3/10, Batch 30/97, Loss: 0.4685
Epoch 3/10, Batch 40/97, Loss: 0.2722
Epoch 3/10, Batch 50/97, Loss: 0.5532
Epoch 3/10, Batch 60/97, Loss: 0.2953
Epoch 3/10, Batch 70/97, Loss: 0.4240
Epoch 3/10, Batch 80/97, Loss: 0.2176
Epoch 3/10, Batch 90/97, Loss: 0.3788
Epoch 3/10, Train Loss: 0.3292, Valid Loss: 0.2962
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3267
Epoch 4/10, Batch 20/97, Loss: 0.3039
Epoch 4/10, Batch 30/97, Loss: 0.3210
Epoch 4/10, Batch 40/97, Loss: 0.2519
Epoch 4/10, Batch 50/97, Loss: 0.2974
Epoch 4/10, Batch 60/97, Loss: 0.2355
Epoch 4/10, Batch 70/97, Loss: 0.2480
Epoch 4/10, Batch 80/97, Loss: 0.3437
Epoch 4/10, Batch 90/97, Loss: 0.2640
Epoch 4/10, Train Loss: 0.2801, Valid Loss: 0.2841
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2908
Epoch 5/10, Batch 20/97, Loss: 0.3024
Epoch 5/10, Batch 30/97, Loss: 0.1852
Epoch 5/10, Batch 40/97, Loss: 0.4109
Epoch 5/10, Batch 50/97, Loss: 0.1980
Epoch 5/10, Batch 60/97, Loss: 0.2022
Epoch 5/10, Batch 70/97, Loss: 0.2352
Epoch 5/10, Batch 80/97, Loss: 0.2485
Epoch 5/10, Batch 90/97, Loss: 0.3685
Epoch 5/10, Train Loss: 0.2597, Valid Loss: 0.2661
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2510
Epoch 6/10, Batch 20/97, Loss: 0.2151
Epoch 6/10, Batch 30/97, Loss: 0.1496
Epoch 6/10, Batch 40/97, Loss: 0.2220
Epoch 6/10, Batch 50/97, Loss: 0.2209
Epoch 6/10, Batch 60/97, Loss: 0.2550
Epoch 6/10, Batch 70/97, Loss: 0.1145
Epoch 6/10, Batch 80/97, Loss: 0.3170
Epoch 6/10, Batch 90/97, Loss: 0.1967
Epoch 6/10, Train Loss: 0.2352, Valid Loss: 0.2500
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2117
Epoch 7/10, Batch 20/97, Loss: 0.3149
Epoch 7/10, Batch 30/97, Loss: 0.1188
Epoch 7/10, Batch 40/97, Loss: 0.1502
Epoch 7/10, Batch 50/97, Loss: 0.1792
Epoch 7/10, Batch 60/97, Loss: 0.1177
Epoch 7/10, Batch 70/97, Loss: 0.1362
Epoch 7/10, Batch 80/97, Loss: 0.1727
Epoch 7/10, Batch 90/97, Loss: 0.2059
Epoch 7/10, Train Loss: 0.2210, Valid Loss: 0.2480
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1639
Epoch 8/10, Batch 20/97, Loss: 0.2988
Epoch 8/10, Batch 30/97, Loss: 0.2180
Epoch 8/10, Batch 40/97, Loss: 0.1680
Epoch 8/10, Batch 50/97, Loss: 0.3338
Epoch 8/10, Batch 60/97, Loss: 0.2068
Epoch 8/10, Batch 70/97, Loss: 0.2017
Epoch 8/10, Batch 80/97, Loss: 0.3164
Epoch 8/10, Batch 90/97, Loss: 0.1780
Epoch 8/10, Train Loss: 0.2144, Valid Loss: 0.2360
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1193
Epoch 9/10, Batch 20/97, Loss: 0.1291
Epoch 9/10, Batch 30/97, Loss: 0.2817
Epoch 9/10, Batch 40/97, Loss: 0.1500
Epoch 9/10, Batch 50/97, Loss: 0.1068
Epoch 9/10, Batch 60/97, Loss: 0.1542
Epoch 9/10, Batch 70/97, Loss: 0.0897
Epoch 9/10, Batch 80/97, Loss: 0.2542
Epoch 9/10, Batch 90/97, Loss: 0.1451
Epoch 9/10, Train Loss: 0.2001, Valid Loss: 0.2325
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2758
Epoch 10/10, Batch 20/97, Loss: 0.1347
Epoch 10/10, Batch 30/97, Loss: 0.1236
Epoch 10/10, Batch 40/97, Loss: 0.1245
Epoch 10/10, Batch 50/97, Loss: 0.2244
Epoch 10/10, Batch 60/97, Loss: 0.1510
Epoch 10/10, Batch 70/97, Loss: 0.1523
Epoch 10/10, Batch 80/97, Loss: 0.1728
Epoch 10/10, Batch 90/97, Loss: 0.1557
Epoch 10/10, Train Loss: 0.1978, Valid Loss: 0.2352
Accuracy: 0.9276
Precision: 0.9253
Recall: 0.9276
F1-score: 0.9260
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 14. Fitness: 0.9276
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2268
Epoch 1/10, Batch 20/97, Loss: 1.0995
Epoch 1/10, Batch 30/97, Loss: 0.7398
Epoch 1/10, Batch 40/97, Loss: 0.8003
Epoch 1/10, Batch 50/97, Loss: 0.5571
Epoch 1/10, Batch 60/97, Loss: 0.6291
Epoch 1/10, Batch 70/97, Loss: 0.6801
Epoch 1/10, Batch 80/97, Loss: 0.5139
Epoch 1/10, Batch 90/97, Loss: 0.6325
Epoch 1/10, Train Loss: 0.7944, Valid Loss: 0.4732
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4861
Epoch 2/10, Batch 20/97, Loss: 0.4292
Epoch 2/10, Batch 30/97, Loss: 0.3219
Epoch 2/10, Batch 40/97, Loss: 0.3142
Epoch 2/10, Batch 50/97, Loss: 0.5307
Epoch 2/10, Batch 60/97, Loss: 0.4380
Epoch 2/10, Batch 70/97, Loss: 0.2990
Epoch 2/10, Batch 80/97, Loss: 0.4609
Epoch 2/10, Batch 90/97, Loss: 0.4519
Epoch 2/10, Train Loss: 0.4039, Valid Loss: 0.3595
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3602
Epoch 3/10, Batch 20/97, Loss: 0.3100
Epoch 3/10, Batch 30/97, Loss: 0.4420
Epoch 3/10, Batch 40/97, Loss: 0.1996
Epoch 3/10, Batch 50/97, Loss: 0.4501
Epoch 3/10, Batch 60/97, Loss: 0.1554
Epoch 3/10, Batch 70/97, Loss: 0.4998
Epoch 3/10, Batch 80/97, Loss: 0.2771
Epoch 3/10, Batch 90/97, Loss: 0.3152
Epoch 3/10, Train Loss: 0.3272, Valid Loss: 0.3179
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3037
Epoch 4/10, Batch 20/97, Loss: 0.2930
Epoch 4/10, Batch 30/97, Loss: 0.2155
Epoch 4/10, Batch 40/97, Loss: 0.3005
Epoch 4/10, Batch 50/97, Loss: 0.4502
Epoch 4/10, Batch 60/97, Loss: 0.1925
Epoch 4/10, Batch 70/97, Loss: 0.1692
Epoch 4/10, Batch 80/97, Loss: 0.2059
Epoch 4/10, Batch 90/97, Loss: 0.1878
Epoch 4/10, Train Loss: 0.2789, Valid Loss: 0.3067
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2804
Epoch 5/10, Batch 20/97, Loss: 0.2962
Epoch 5/10, Batch 30/97, Loss: 0.2028
Epoch 5/10, Batch 40/97, Loss: 0.1885
Epoch 5/10, Batch 50/97, Loss: 0.2712
Epoch 5/10, Batch 60/97, Loss: 0.2504
Epoch 5/10, Batch 70/97, Loss: 0.4231
Epoch 5/10, Batch 80/97, Loss: 0.1615
Epoch 5/10, Batch 90/97, Loss: 0.2211
Epoch 5/10, Train Loss: 0.2575, Valid Loss: 0.2885
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2040
Epoch 6/10, Batch 20/97, Loss: 0.2246
Epoch 6/10, Batch 30/97, Loss: 0.1708
Epoch 6/10, Batch 40/97, Loss: 0.2770
Epoch 6/10, Batch 50/97, Loss: 0.1263
Epoch 6/10, Batch 60/97, Loss: 0.2803
Epoch 6/10, Batch 70/97, Loss: 0.2595
Epoch 6/10, Batch 80/97, Loss: 0.3479
Epoch 6/10, Batch 90/97, Loss: 0.3708
Epoch 6/10, Train Loss: 0.2463, Valid Loss: 0.2754
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1350
Epoch 7/10, Batch 20/97, Loss: 0.4185
Epoch 7/10, Batch 30/97, Loss: 0.1748
Epoch 7/10, Batch 40/97, Loss: 0.2096
Epoch 7/10, Batch 50/97, Loss: 0.2682
Epoch 7/10, Batch 60/97, Loss: 0.1134
Epoch 7/10, Batch 70/97, Loss: 0.1427
Epoch 7/10, Batch 80/97, Loss: 0.1233
Epoch 7/10, Batch 90/97, Loss: 0.2108
Epoch 7/10, Train Loss: 0.2241, Valid Loss: 0.2688
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1861
Epoch 8/10, Batch 20/97, Loss: 0.1448
Epoch 8/10, Batch 30/97, Loss: 0.1685
Epoch 8/10, Batch 40/97, Loss: 0.2186
Epoch 8/10, Batch 50/97, Loss: 0.1937
Epoch 8/10, Batch 60/97, Loss: 0.1947
Epoch 8/10, Batch 70/97, Loss: 0.1742
Epoch 8/10, Batch 80/97, Loss: 0.2075
Epoch 8/10, Batch 90/97, Loss: 0.3090
Epoch 8/10, Train Loss: 0.2053, Valid Loss: 0.2659
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1586
Epoch 9/10, Batch 20/97, Loss: 0.2068
Epoch 9/10, Batch 30/97, Loss: 0.1556
Epoch 9/10, Batch 40/97, Loss: 0.3100
Epoch 9/10, Batch 50/97, Loss: 0.1583
Epoch 9/10, Batch 60/97, Loss: 0.2760
Epoch 9/10, Batch 70/97, Loss: 0.1153
Epoch 9/10, Batch 80/97, Loss: 0.2912
Epoch 9/10, Batch 90/97, Loss: 0.1130
Epoch 9/10, Train Loss: 0.2040, Valid Loss: 0.2598
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1613
Epoch 10/10, Batch 20/97, Loss: 0.2279
Epoch 10/10, Batch 30/97, Loss: 0.2274
Epoch 10/10, Batch 40/97, Loss: 0.2011
Epoch 10/10, Batch 50/97, Loss: 0.1867
Epoch 10/10, Batch 60/97, Loss: 0.1332
Epoch 10/10, Batch 70/97, Loss: 0.2896
Epoch 10/10, Batch 80/97, Loss: 0.1748
Epoch 10/10, Batch 90/97, Loss: 0.1382
Epoch 10/10, Train Loss: 0.1930, Valid Loss: 0.2559
Model saved!
Accuracy: 0.9100
Precision: 0.9060
Recall: 0.9100
F1-score: 0.9060
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2503
Epoch 1/10, Batch 20/97, Loss: 1.0709
Epoch 1/10, Batch 30/97, Loss: 0.7566
Epoch 1/10, Batch 40/97, Loss: 0.7676
Epoch 1/10, Batch 50/97, Loss: 0.5658
Epoch 1/10, Batch 60/97, Loss: 0.7567
Epoch 1/10, Batch 70/97, Loss: 0.6554
Epoch 1/10, Batch 80/97, Loss: 0.6556
Epoch 1/10, Batch 90/97, Loss: 0.6460
Epoch 1/10, Train Loss: 0.8029, Valid Loss: 0.4339
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4494
Epoch 2/10, Batch 20/97, Loss: 0.4073
Epoch 2/10, Batch 30/97, Loss: 0.3656
Epoch 2/10, Batch 40/97, Loss: 0.3818
Epoch 2/10, Batch 50/97, Loss: 0.4232
Epoch 2/10, Batch 60/97, Loss: 0.5609
Epoch 2/10, Batch 70/97, Loss: 0.4337
Epoch 2/10, Batch 80/97, Loss: 0.3223
Epoch 2/10, Batch 90/97, Loss: 0.4338
Epoch 2/10, Train Loss: 0.4146, Valid Loss: 0.3266
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3083
Epoch 3/10, Batch 20/97, Loss: 0.5116
Epoch 3/10, Batch 30/97, Loss: 0.4131
Epoch 3/10, Batch 40/97, Loss: 0.2144
Epoch 3/10, Batch 50/97, Loss: 0.3315
Epoch 3/10, Batch 60/97, Loss: 0.1897
Epoch 3/10, Batch 70/97, Loss: 0.3079
Epoch 3/10, Batch 80/97, Loss: 0.3199
Epoch 3/10, Batch 90/97, Loss: 0.2017
Epoch 3/10, Train Loss: 0.3362, Valid Loss: 0.2874
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3839
Epoch 4/10, Batch 20/97, Loss: 0.1982
Epoch 4/10, Batch 30/97, Loss: 0.2488
Epoch 4/10, Batch 40/97, Loss: 0.2671
Epoch 4/10, Batch 50/97, Loss: 0.4202
Epoch 4/10, Batch 60/97, Loss: 0.1812
Epoch 4/10, Batch 70/97, Loss: 0.2893
Epoch 4/10, Batch 80/97, Loss: 0.2671
Epoch 4/10, Batch 90/97, Loss: 0.2615
Epoch 4/10, Train Loss: 0.2871, Valid Loss: 0.2688
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3246
Epoch 5/10, Batch 20/97, Loss: 0.2567
Epoch 5/10, Batch 30/97, Loss: 0.2638
Epoch 5/10, Batch 40/97, Loss: 0.2623
Epoch 5/10, Batch 50/97, Loss: 0.2824
Epoch 5/10, Batch 60/97, Loss: 0.2703
Epoch 5/10, Batch 70/97, Loss: 0.2293
Epoch 5/10, Batch 80/97, Loss: 0.2534
Epoch 5/10, Batch 90/97, Loss: 0.1884
Epoch 5/10, Train Loss: 0.2695, Valid Loss: 0.2686
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1651
Epoch 6/10, Batch 20/97, Loss: 0.3509
Epoch 6/10, Batch 30/97, Loss: 0.1042
Epoch 6/10, Batch 40/97, Loss: 0.1840
Epoch 6/10, Batch 50/97, Loss: 0.3020
Epoch 6/10, Batch 60/97, Loss: 0.4002
Epoch 6/10, Batch 70/97, Loss: 0.2780
Epoch 6/10, Batch 80/97, Loss: 0.3648
Epoch 6/10, Batch 90/97, Loss: 0.2158
Epoch 6/10, Train Loss: 0.2502, Valid Loss: 0.2530
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1253
Epoch 7/10, Batch 20/97, Loss: 0.2168
Epoch 7/10, Batch 30/97, Loss: 0.2159
Epoch 7/10, Batch 40/97, Loss: 0.1423
Epoch 7/10, Batch 50/97, Loss: 0.2146
Epoch 7/10, Batch 60/97, Loss: 0.1717
Epoch 7/10, Batch 70/97, Loss: 0.3295
Epoch 7/10, Batch 80/97, Loss: 0.2681
Epoch 7/10, Batch 90/97, Loss: 0.2144
Epoch 7/10, Train Loss: 0.2275, Valid Loss: 0.2419
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1562
Epoch 8/10, Batch 20/97, Loss: 0.1741
Epoch 8/10, Batch 30/97, Loss: 0.2240
Epoch 8/10, Batch 40/97, Loss: 0.2502
Epoch 8/10, Batch 50/97, Loss: 0.3071
Epoch 8/10, Batch 60/97, Loss: 0.1920
Epoch 8/10, Batch 70/97, Loss: 0.2394
Epoch 8/10, Batch 80/97, Loss: 0.1560
Epoch 8/10, Batch 90/97, Loss: 0.2923
Epoch 8/10, Train Loss: 0.2245, Valid Loss: 0.2410
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0944
Epoch 9/10, Batch 20/97, Loss: 0.1590
Epoch 9/10, Batch 30/97, Loss: 0.2105
Epoch 9/10, Batch 40/97, Loss: 0.3027
Epoch 9/10, Batch 50/97, Loss: 0.1624
Epoch 9/10, Batch 60/97, Loss: 0.3029
Epoch 9/10, Batch 70/97, Loss: 0.1561
Epoch 9/10, Batch 80/97, Loss: 0.1773
Epoch 9/10, Batch 90/97, Loss: 0.1318
Epoch 9/10, Train Loss: 0.2093, Valid Loss: 0.2370
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1360
Epoch 10/10, Batch 20/97, Loss: 0.1179
Epoch 10/10, Batch 30/97, Loss: 0.2354
Epoch 10/10, Batch 40/97, Loss: 0.1103
Epoch 10/10, Batch 50/97, Loss: 0.3337
Epoch 10/10, Batch 60/97, Loss: 0.2259
Epoch 10/10, Batch 70/97, Loss: 0.1147
Epoch 10/10, Batch 80/97, Loss: 0.1873
Epoch 10/10, Batch 90/97, Loss: 0.1305
Epoch 10/10, Train Loss: 0.2043, Valid Loss: 0.2417
Accuracy: 0.9194
Precision: 0.9174
Recall: 0.9194
F1-score: 0.9173
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2883
Epoch 1/10, Batch 20/97, Loss: 1.1037
Epoch 1/10, Batch 30/97, Loss: 0.7655
Epoch 1/10, Batch 40/97, Loss: 0.8123
Epoch 1/10, Batch 50/97, Loss: 0.6075
Epoch 1/10, Batch 60/97, Loss: 0.7239
Epoch 1/10, Batch 70/97, Loss: 0.6952
Epoch 1/10, Batch 80/97, Loss: 0.5966
Epoch 1/10, Batch 90/97, Loss: 0.5621
Epoch 1/10, Train Loss: 0.8048, Valid Loss: 0.4498
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5202
Epoch 2/10, Batch 20/97, Loss: 0.4585
Epoch 2/10, Batch 30/97, Loss: 0.4382
Epoch 2/10, Batch 40/97, Loss: 0.3505
Epoch 2/10, Batch 50/97, Loss: 0.3663
Epoch 2/10, Batch 60/97, Loss: 0.4194
Epoch 2/10, Batch 70/97, Loss: 0.3141
Epoch 2/10, Batch 80/97, Loss: 0.5143
Epoch 2/10, Batch 90/97, Loss: 0.5000
Epoch 2/10, Train Loss: 0.4138, Valid Loss: 0.3343
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4855
Epoch 3/10, Batch 20/97, Loss: 0.3105
Epoch 3/10, Batch 30/97, Loss: 0.4782
Epoch 3/10, Batch 40/97, Loss: 0.2019
Epoch 3/10, Batch 50/97, Loss: 0.5646
Epoch 3/10, Batch 60/97, Loss: 0.2951
Epoch 3/10, Batch 70/97, Loss: 0.3906
Epoch 3/10, Batch 80/97, Loss: 0.3835
Epoch 3/10, Batch 90/97, Loss: 0.2051
Epoch 3/10, Train Loss: 0.3343, Valid Loss: 0.2991
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4044
Epoch 4/10, Batch 20/97, Loss: 0.3425
Epoch 4/10, Batch 30/97, Loss: 0.1632
Epoch 4/10, Batch 40/97, Loss: 0.3793
Epoch 4/10, Batch 50/97, Loss: 0.2358
Epoch 4/10, Batch 60/97, Loss: 0.2367
Epoch 4/10, Batch 70/97, Loss: 0.3859
Epoch 4/10, Batch 80/97, Loss: 0.3099
Epoch 4/10, Batch 90/97, Loss: 0.1695
Epoch 4/10, Train Loss: 0.2853, Valid Loss: 0.2752
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2359
Epoch 5/10, Batch 20/97, Loss: 0.5962
Epoch 5/10, Batch 30/97, Loss: 0.2190
Epoch 5/10, Batch 40/97, Loss: 0.2985
Epoch 5/10, Batch 50/97, Loss: 0.2399
Epoch 5/10, Batch 60/97, Loss: 0.2094
Epoch 5/10, Batch 70/97, Loss: 0.2332
Epoch 5/10, Batch 80/97, Loss: 0.1828
Epoch 5/10, Batch 90/97, Loss: 0.1539
Epoch 5/10, Train Loss: 0.2729, Valid Loss: 0.2573
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1958
Epoch 6/10, Batch 20/97, Loss: 0.3303
Epoch 6/10, Batch 30/97, Loss: 0.2337
Epoch 6/10, Batch 40/97, Loss: 0.2311
Epoch 6/10, Batch 50/97, Loss: 0.1666
Epoch 6/10, Batch 60/97, Loss: 0.1645
Epoch 6/10, Batch 70/97, Loss: 0.2543
Epoch 6/10, Batch 80/97, Loss: 0.3276
Epoch 6/10, Batch 90/97, Loss: 0.5256
Epoch 6/10, Train Loss: 0.2479, Valid Loss: 0.2353
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1629
Epoch 7/10, Batch 20/97, Loss: 0.2458
Epoch 7/10, Batch 30/97, Loss: 0.2827
Epoch 7/10, Batch 40/97, Loss: 0.1676
Epoch 7/10, Batch 50/97, Loss: 0.5404
Epoch 7/10, Batch 60/97, Loss: 0.1821
Epoch 7/10, Batch 70/97, Loss: 0.2583
Epoch 7/10, Batch 80/97, Loss: 0.1522
Epoch 7/10, Batch 90/97, Loss: 0.1466
Epoch 7/10, Train Loss: 0.2295, Valid Loss: 0.2297
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2790
Epoch 8/10, Batch 20/97, Loss: 0.2752
Epoch 8/10, Batch 30/97, Loss: 0.1376
Epoch 8/10, Batch 40/97, Loss: 0.1097
Epoch 8/10, Batch 50/97, Loss: 0.1853
Epoch 8/10, Batch 60/97, Loss: 0.1470
Epoch 8/10, Batch 70/97, Loss: 0.1586
Epoch 8/10, Batch 80/97, Loss: 0.1188
Epoch 8/10, Batch 90/97, Loss: 0.1494
Epoch 8/10, Train Loss: 0.2127, Valid Loss: 0.2333
Epoch 9/10, Batch 10/97, Loss: 0.0919
Epoch 9/10, Batch 20/97, Loss: 0.2687
Epoch 9/10, Batch 30/97, Loss: 0.2266
Epoch 9/10, Batch 40/97, Loss: 0.2084
Epoch 9/10, Batch 50/97, Loss: 0.1342
Epoch 9/10, Batch 60/97, Loss: 0.1106
Epoch 9/10, Batch 70/97, Loss: 0.1997
Epoch 9/10, Batch 80/97, Loss: 0.2173
Epoch 9/10, Batch 90/97, Loss: 0.2837
Epoch 9/10, Train Loss: 0.2115, Valid Loss: 0.2194
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1501
Epoch 10/10, Batch 20/97, Loss: 0.2086
Epoch 10/10, Batch 30/97, Loss: 0.3278
Epoch 10/10, Batch 40/97, Loss: 0.2331
Epoch 10/10, Batch 50/97, Loss: 0.1453
Epoch 10/10, Batch 60/97, Loss: 0.1920
Epoch 10/10, Batch 70/97, Loss: 0.1431
Epoch 10/10, Batch 80/97, Loss: 0.2068
Epoch 10/10, Batch 90/97, Loss: 0.2139
Epoch 10/10, Train Loss: 0.2022, Valid Loss: 0.2175
Model saved!
Accuracy: 0.9159
Precision: 0.9132
Recall: 0.9159
F1-score: 0.9135
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.3068
Epoch 1/10, Batch 20/97, Loss: 1.0678
Epoch 1/10, Batch 30/97, Loss: 0.6972
Epoch 1/10, Batch 40/97, Loss: 0.7285
Epoch 1/10, Batch 50/97, Loss: 0.6164
Epoch 1/10, Batch 60/97, Loss: 0.7365
Epoch 1/10, Batch 70/97, Loss: 0.6750
Epoch 1/10, Batch 80/97, Loss: 0.5581
Epoch 1/10, Batch 90/97, Loss: 0.5591
Epoch 1/10, Train Loss: 0.7954, Valid Loss: 0.4364
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4728
Epoch 2/10, Batch 20/97, Loss: 0.5067
Epoch 2/10, Batch 30/97, Loss: 0.3800
Epoch 2/10, Batch 40/97, Loss: 0.4080
Epoch 2/10, Batch 50/97, Loss: 0.5983
Epoch 2/10, Batch 60/97, Loss: 0.4600
Epoch 2/10, Batch 70/97, Loss: 0.3406
Epoch 2/10, Batch 80/97, Loss: 0.3573
Epoch 2/10, Batch 90/97, Loss: 0.4155
Epoch 2/10, Train Loss: 0.4036, Valid Loss: 0.3367
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2770
Epoch 3/10, Batch 20/97, Loss: 0.3111
Epoch 3/10, Batch 30/97, Loss: 0.3574
Epoch 3/10, Batch 40/97, Loss: 0.2400
Epoch 3/10, Batch 50/97, Loss: 0.4387
Epoch 3/10, Batch 60/97, Loss: 0.1809
Epoch 3/10, Batch 70/97, Loss: 0.3479
Epoch 3/10, Batch 80/97, Loss: 0.2939
Epoch 3/10, Batch 90/97, Loss: 0.3810
Epoch 3/10, Train Loss: 0.3236, Valid Loss: 0.2939
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4435
Epoch 4/10, Batch 20/97, Loss: 0.1812
Epoch 4/10, Batch 30/97, Loss: 0.2465
Epoch 4/10, Batch 40/97, Loss: 0.2007
Epoch 4/10, Batch 50/97, Loss: 0.2842
Epoch 4/10, Batch 60/97, Loss: 0.2089
Epoch 4/10, Batch 70/97, Loss: 0.2907
Epoch 4/10, Batch 80/97, Loss: 0.3029
Epoch 4/10, Batch 90/97, Loss: 0.3085
Epoch 4/10, Train Loss: 0.2732, Valid Loss: 0.2820
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1860
Epoch 5/10, Batch 20/97, Loss: 0.2183
Epoch 5/10, Batch 30/97, Loss: 0.2374
Epoch 5/10, Batch 40/97, Loss: 0.2461
Epoch 5/10, Batch 50/97, Loss: 0.2334
Epoch 5/10, Batch 60/97, Loss: 0.1433
Epoch 5/10, Batch 70/97, Loss: 0.2732
Epoch 5/10, Batch 80/97, Loss: 0.1571
Epoch 5/10, Batch 90/97, Loss: 0.1922
Epoch 5/10, Train Loss: 0.2516, Valid Loss: 0.2614
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2328
Epoch 6/10, Batch 20/97, Loss: 0.3087
Epoch 6/10, Batch 30/97, Loss: 0.2752
Epoch 6/10, Batch 40/97, Loss: 0.1416
Epoch 6/10, Batch 50/97, Loss: 0.3639
Epoch 6/10, Batch 60/97, Loss: 0.1187
Epoch 6/10, Batch 70/97, Loss: 0.1948
Epoch 6/10, Batch 80/97, Loss: 0.4208
Epoch 6/10, Batch 90/97, Loss: 0.3165
Epoch 6/10, Train Loss: 0.2359, Valid Loss: 0.2541
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1883
Epoch 7/10, Batch 20/97, Loss: 0.2123
Epoch 7/10, Batch 30/97, Loss: 0.1834
Epoch 7/10, Batch 40/97, Loss: 0.1103
Epoch 7/10, Batch 50/97, Loss: 0.1244
Epoch 7/10, Batch 60/97, Loss: 0.1069
Epoch 7/10, Batch 70/97, Loss: 0.2270
Epoch 7/10, Batch 80/97, Loss: 0.2206
Epoch 7/10, Batch 90/97, Loss: 0.3276
Epoch 7/10, Train Loss: 0.2169, Valid Loss: 0.2459
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1599
Epoch 8/10, Batch 20/97, Loss: 0.1159
Epoch 8/10, Batch 30/97, Loss: 0.1400
Epoch 8/10, Batch 40/97, Loss: 0.2572
Epoch 8/10, Batch 50/97, Loss: 0.1298
Epoch 8/10, Batch 60/97, Loss: 0.1665
Epoch 8/10, Batch 70/97, Loss: 0.3904
Epoch 8/10, Batch 80/97, Loss: 0.1445
Epoch 8/10, Batch 90/97, Loss: 0.1831
Epoch 8/10, Train Loss: 0.2114, Valid Loss: 0.2372
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1580
Epoch 9/10, Batch 20/97, Loss: 0.1950
Epoch 9/10, Batch 30/97, Loss: 0.2679
Epoch 9/10, Batch 40/97, Loss: 0.3693
Epoch 9/10, Batch 50/97, Loss: 0.1242
Epoch 9/10, Batch 60/97, Loss: 0.1745
Epoch 9/10, Batch 70/97, Loss: 0.0835
Epoch 9/10, Batch 80/97, Loss: 0.2411
Epoch 9/10, Batch 90/97, Loss: 0.1348
Epoch 9/10, Train Loss: 0.1970, Valid Loss: 0.2326
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1410
Epoch 10/10, Batch 20/97, Loss: 0.1544
Epoch 10/10, Batch 30/97, Loss: 0.2221
Epoch 10/10, Batch 40/97, Loss: 0.0755
Epoch 10/10, Batch 50/97, Loss: 0.1114
Epoch 10/10, Batch 60/97, Loss: 0.1873
Epoch 10/10, Batch 70/97, Loss: 0.3484
Epoch 10/10, Batch 80/97, Loss: 0.2054
Epoch 10/10, Batch 90/97, Loss: 0.1611
Epoch 10/10, Train Loss: 0.1958, Valid Loss: 0.2280
Model saved!
Accuracy: 0.9042
Precision: 0.9000
Recall: 0.9042
F1-score: 0.9002
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2750
Epoch 1/10, Batch 20/97, Loss: 1.0457
Epoch 1/10, Batch 30/97, Loss: 0.8288
Epoch 1/10, Batch 40/97, Loss: 0.7324
Epoch 1/10, Batch 50/97, Loss: 0.6419
Epoch 1/10, Batch 60/97, Loss: 0.7810
Epoch 1/10, Batch 70/97, Loss: 0.5533
Epoch 1/10, Batch 80/97, Loss: 0.5486
Epoch 1/10, Batch 90/97, Loss: 0.4614
Epoch 1/10, Train Loss: 0.7985, Valid Loss: 0.4586
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6449
Epoch 2/10, Batch 20/97, Loss: 0.3752
Epoch 2/10, Batch 30/97, Loss: 0.3837
Epoch 2/10, Batch 40/97, Loss: 0.2670
Epoch 2/10, Batch 50/97, Loss: 0.3714
Epoch 2/10, Batch 60/97, Loss: 0.4204
Epoch 2/10, Batch 70/97, Loss: 0.2675
Epoch 2/10, Batch 80/97, Loss: 0.3862
Epoch 2/10, Batch 90/97, Loss: 0.5564
Epoch 2/10, Train Loss: 0.4050, Valid Loss: 0.3530
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2587
Epoch 3/10, Batch 20/97, Loss: 0.3978
Epoch 3/10, Batch 30/97, Loss: 0.4095
Epoch 3/10, Batch 40/97, Loss: 0.2904
Epoch 3/10, Batch 50/97, Loss: 0.2671
Epoch 3/10, Batch 60/97, Loss: 0.3173
Epoch 3/10, Batch 70/97, Loss: 0.3115
Epoch 3/10, Batch 80/97, Loss: 0.3294
Epoch 3/10, Batch 90/97, Loss: 0.4075
Epoch 3/10, Train Loss: 0.3315, Valid Loss: 0.3087
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.5020
Epoch 4/10, Batch 20/97, Loss: 0.2365
Epoch 4/10, Batch 30/97, Loss: 0.4105
Epoch 4/10, Batch 40/97, Loss: 0.2247
Epoch 4/10, Batch 50/97, Loss: 0.2245
Epoch 4/10, Batch 60/97, Loss: 0.2628
Epoch 4/10, Batch 70/97, Loss: 0.3831
Epoch 4/10, Batch 80/97, Loss: 0.1418
Epoch 4/10, Batch 90/97, Loss: 0.2158
Epoch 4/10, Train Loss: 0.2851, Valid Loss: 0.2812
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1612
Epoch 5/10, Batch 20/97, Loss: 0.5067
Epoch 5/10, Batch 30/97, Loss: 0.2532
Epoch 5/10, Batch 40/97, Loss: 0.2049
Epoch 5/10, Batch 50/97, Loss: 0.3067
Epoch 5/10, Batch 60/97, Loss: 0.2545
Epoch 5/10, Batch 70/97, Loss: 0.1782
Epoch 5/10, Batch 80/97, Loss: 0.2829
Epoch 5/10, Batch 90/97, Loss: 0.2750
Epoch 5/10, Train Loss: 0.2641, Valid Loss: 0.2703
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2643
Epoch 6/10, Batch 20/97, Loss: 0.4371
Epoch 6/10, Batch 30/97, Loss: 0.1452
Epoch 6/10, Batch 40/97, Loss: 0.1980
Epoch 6/10, Batch 50/97, Loss: 0.1594
Epoch 6/10, Batch 60/97, Loss: 0.3942
Epoch 6/10, Batch 70/97, Loss: 0.1218
Epoch 6/10, Batch 80/97, Loss: 0.3672
Epoch 6/10, Batch 90/97, Loss: 0.2673
Epoch 6/10, Train Loss: 0.2408, Valid Loss: 0.2577
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1404
Epoch 7/10, Batch 20/97, Loss: 0.3409
Epoch 7/10, Batch 30/97, Loss: 0.1879
Epoch 7/10, Batch 40/97, Loss: 0.1028
Epoch 7/10, Batch 50/97, Loss: 0.1961
Epoch 7/10, Batch 60/97, Loss: 0.2005
Epoch 7/10, Batch 70/97, Loss: 0.1808
Epoch 7/10, Batch 80/97, Loss: 0.3561
Epoch 7/10, Batch 90/97, Loss: 0.1954
Epoch 7/10, Train Loss: 0.2246, Valid Loss: 0.2525
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2829
Epoch 8/10, Batch 20/97, Loss: 0.1517
Epoch 8/10, Batch 30/97, Loss: 0.1253
Epoch 8/10, Batch 40/97, Loss: 0.1794
Epoch 8/10, Batch 50/97, Loss: 0.1340
Epoch 8/10, Batch 60/97, Loss: 0.1853
Epoch 8/10, Batch 70/97, Loss: 0.2768
Epoch 8/10, Batch 80/97, Loss: 0.1950
Epoch 8/10, Batch 90/97, Loss: 0.2127
Epoch 8/10, Train Loss: 0.2165, Valid Loss: 0.2521
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2077
Epoch 9/10, Batch 20/97, Loss: 0.1575
Epoch 9/10, Batch 30/97, Loss: 0.2314
Epoch 9/10, Batch 40/97, Loss: 0.2036
Epoch 9/10, Batch 50/97, Loss: 0.1149
Epoch 9/10, Batch 60/97, Loss: 0.4191
Epoch 9/10, Batch 70/97, Loss: 0.1666
Epoch 9/10, Batch 80/97, Loss: 0.1640
Epoch 9/10, Batch 90/97, Loss: 0.2429
Epoch 9/10, Train Loss: 0.2063, Valid Loss: 0.2418
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3196
Epoch 10/10, Batch 20/97, Loss: 0.1642
Epoch 10/10, Batch 30/97, Loss: 0.1422
Epoch 10/10, Batch 40/97, Loss: 0.0883
Epoch 10/10, Batch 50/97, Loss: 0.1241
Epoch 10/10, Batch 60/97, Loss: 0.2144
Epoch 10/10, Batch 70/97, Loss: 0.2294
Epoch 10/10, Batch 80/97, Loss: 0.1604
Epoch 10/10, Batch 90/97, Loss: 0.1313
Epoch 10/10, Train Loss: 0.1997, Valid Loss: 0.2445
Accuracy: 0.9171
Precision: 0.9152
Recall: 0.9171
F1-score: 0.9157
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2263
Epoch 1/10, Batch 20/97, Loss: 0.9985
Epoch 1/10, Batch 30/97, Loss: 0.8168
Epoch 1/10, Batch 40/97, Loss: 0.7308
Epoch 1/10, Batch 50/97, Loss: 0.6214
Epoch 1/10, Batch 60/97, Loss: 0.6751
Epoch 1/10, Batch 70/97, Loss: 0.5579
Epoch 1/10, Batch 80/97, Loss: 0.6966
Epoch 1/10, Batch 90/97, Loss: 0.4811
Epoch 1/10, Train Loss: 0.7948, Valid Loss: 0.4515
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5925
Epoch 2/10, Batch 20/97, Loss: 0.4470
Epoch 2/10, Batch 30/97, Loss: 0.2826
Epoch 2/10, Batch 40/97, Loss: 0.4806
Epoch 2/10, Batch 50/97, Loss: 0.4943
Epoch 2/10, Batch 60/97, Loss: 0.4070
Epoch 2/10, Batch 70/97, Loss: 0.3707
Epoch 2/10, Batch 80/97, Loss: 0.4489
Epoch 2/10, Batch 90/97, Loss: 0.3980
Epoch 2/10, Train Loss: 0.4138, Valid Loss: 0.3333
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4189
Epoch 3/10, Batch 20/97, Loss: 0.3487
Epoch 3/10, Batch 30/97, Loss: 0.5222
Epoch 3/10, Batch 40/97, Loss: 0.2654
Epoch 3/10, Batch 50/97, Loss: 0.3373
Epoch 3/10, Batch 60/97, Loss: 0.1981
Epoch 3/10, Batch 70/97, Loss: 0.3504
Epoch 3/10, Batch 80/97, Loss: 0.3095
Epoch 3/10, Batch 90/97, Loss: 0.2189
Epoch 3/10, Train Loss: 0.3408, Valid Loss: 0.2919
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4023
Epoch 4/10, Batch 20/97, Loss: 0.1856
Epoch 4/10, Batch 30/97, Loss: 0.2616
Epoch 4/10, Batch 40/97, Loss: 0.2334
Epoch 4/10, Batch 50/97, Loss: 0.2174
Epoch 4/10, Batch 60/97, Loss: 0.1748
Epoch 4/10, Batch 70/97, Loss: 0.2147
Epoch 4/10, Batch 80/97, Loss: 0.3672
Epoch 4/10, Batch 90/97, Loss: 0.3335
Epoch 4/10, Train Loss: 0.2833, Valid Loss: 0.2737
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1978
Epoch 5/10, Batch 20/97, Loss: 0.2389
Epoch 5/10, Batch 30/97, Loss: 0.2329
Epoch 5/10, Batch 40/97, Loss: 0.2221
Epoch 5/10, Batch 50/97, Loss: 0.3480
Epoch 5/10, Batch 60/97, Loss: 0.2080
Epoch 5/10, Batch 70/97, Loss: 0.2823
Epoch 5/10, Batch 80/97, Loss: 0.2214
Epoch 5/10, Batch 90/97, Loss: 0.2983
Epoch 5/10, Train Loss: 0.2729, Valid Loss: 0.2538
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2289
Epoch 6/10, Batch 20/97, Loss: 0.2166
Epoch 6/10, Batch 30/97, Loss: 0.1535
Epoch 6/10, Batch 40/97, Loss: 0.1196
Epoch 6/10, Batch 50/97, Loss: 0.2326
Epoch 6/10, Batch 60/97, Loss: 0.3011
Epoch 6/10, Batch 70/97, Loss: 0.1918
Epoch 6/10, Batch 80/97, Loss: 0.2062
Epoch 6/10, Batch 90/97, Loss: 0.3152
Epoch 6/10, Train Loss: 0.2423, Valid Loss: 0.2371
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1751
Epoch 7/10, Batch 20/97, Loss: 0.3600
Epoch 7/10, Batch 30/97, Loss: 0.2221
Epoch 7/10, Batch 40/97, Loss: 0.2015
Epoch 7/10, Batch 50/97, Loss: 0.2161
Epoch 7/10, Batch 60/97, Loss: 0.1863
Epoch 7/10, Batch 70/97, Loss: 0.2507
Epoch 7/10, Batch 80/97, Loss: 0.4917
Epoch 7/10, Batch 90/97, Loss: 0.2425
Epoch 7/10, Train Loss: 0.2217, Valid Loss: 0.2337
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1845
Epoch 8/10, Batch 20/97, Loss: 0.1755
Epoch 8/10, Batch 30/97, Loss: 0.2758
Epoch 8/10, Batch 40/97, Loss: 0.2245
Epoch 8/10, Batch 50/97, Loss: 0.2882
Epoch 8/10, Batch 60/97, Loss: 0.2220
Epoch 8/10, Batch 70/97, Loss: 0.2058
Epoch 8/10, Batch 80/97, Loss: 0.2580
Epoch 8/10, Batch 90/97, Loss: 0.1435
Epoch 8/10, Train Loss: 0.2212, Valid Loss: 0.2264
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1146
Epoch 9/10, Batch 20/97, Loss: 0.1401
Epoch 9/10, Batch 30/97, Loss: 0.2193
Epoch 9/10, Batch 40/97, Loss: 0.3460
Epoch 9/10, Batch 50/97, Loss: 0.0924
Epoch 9/10, Batch 60/97, Loss: 0.2417
Epoch 9/10, Batch 70/97, Loss: 0.1409
Epoch 9/10, Batch 80/97, Loss: 0.0735
Epoch 9/10, Batch 90/97, Loss: 0.2111
Epoch 9/10, Train Loss: 0.2057, Valid Loss: 0.2201
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1656
Epoch 10/10, Batch 20/97, Loss: 0.2149
Epoch 10/10, Batch 30/97, Loss: 0.0650
Epoch 10/10, Batch 40/97, Loss: 0.2190
Epoch 10/10, Batch 50/97, Loss: 0.1955
Epoch 10/10, Batch 60/97, Loss: 0.1630
Epoch 10/10, Batch 70/97, Loss: 0.1229
Epoch 10/10, Batch 80/97, Loss: 0.1974
Epoch 10/10, Batch 90/97, Loss: 0.1124
Epoch 10/10, Train Loss: 0.2053, Valid Loss: 0.2249
Accuracy: 0.9147
Precision: 0.9123
Recall: 0.9147
F1-score: 0.9121
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2321
Epoch 1/10, Batch 20/97, Loss: 1.1334
Epoch 1/10, Batch 30/97, Loss: 0.7492
Epoch 1/10, Batch 40/97, Loss: 0.7162
Epoch 1/10, Batch 50/97, Loss: 0.5964
Epoch 1/10, Batch 60/97, Loss: 0.6930
Epoch 1/10, Batch 70/97, Loss: 0.8271
Epoch 1/10, Batch 80/97, Loss: 0.5580
Epoch 1/10, Batch 90/97, Loss: 0.4747
Epoch 1/10, Train Loss: 0.7961, Valid Loss: 0.4647
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5996
Epoch 2/10, Batch 20/97, Loss: 0.4085
Epoch 2/10, Batch 30/97, Loss: 0.4243
Epoch 2/10, Batch 40/97, Loss: 0.4737
Epoch 2/10, Batch 50/97, Loss: 0.5400
Epoch 2/10, Batch 60/97, Loss: 0.3558
Epoch 2/10, Batch 70/97, Loss: 0.2703
Epoch 2/10, Batch 80/97, Loss: 0.3297
Epoch 2/10, Batch 90/97, Loss: 0.4420
Epoch 2/10, Train Loss: 0.4086, Valid Loss: 0.3562
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3706
Epoch 3/10, Batch 20/97, Loss: 0.2803
Epoch 3/10, Batch 30/97, Loss: 0.5033
Epoch 3/10, Batch 40/97, Loss: 0.1964
Epoch 3/10, Batch 50/97, Loss: 0.6097
Epoch 3/10, Batch 60/97, Loss: 0.3400
Epoch 3/10, Batch 70/97, Loss: 0.4073
Epoch 3/10, Batch 80/97, Loss: 0.4433
Epoch 3/10, Batch 90/97, Loss: 0.2531
Epoch 3/10, Train Loss: 0.3328, Valid Loss: 0.3102
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2930
Epoch 4/10, Batch 20/97, Loss: 0.1880
Epoch 4/10, Batch 30/97, Loss: 0.4911
Epoch 4/10, Batch 40/97, Loss: 0.2818
Epoch 4/10, Batch 50/97, Loss: 0.3065
Epoch 4/10, Batch 60/97, Loss: 0.1970
Epoch 4/10, Batch 70/97, Loss: 0.3419
Epoch 4/10, Batch 80/97, Loss: 0.2264
Epoch 4/10, Batch 90/97, Loss: 0.2068
Epoch 4/10, Train Loss: 0.2912, Valid Loss: 0.2940
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3192
Epoch 5/10, Batch 20/97, Loss: 0.4603
Epoch 5/10, Batch 30/97, Loss: 0.1745
Epoch 5/10, Batch 40/97, Loss: 0.2459
Epoch 5/10, Batch 50/97, Loss: 0.2825
Epoch 5/10, Batch 60/97, Loss: 0.2356
Epoch 5/10, Batch 70/97, Loss: 0.4761
Epoch 5/10, Batch 80/97, Loss: 0.2187
Epoch 5/10, Batch 90/97, Loss: 0.2896
Epoch 5/10, Train Loss: 0.2664, Valid Loss: 0.2795
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2273
Epoch 6/10, Batch 20/97, Loss: 0.2061
Epoch 6/10, Batch 30/97, Loss: 0.1669
Epoch 6/10, Batch 40/97, Loss: 0.1492
Epoch 6/10, Batch 50/97, Loss: 0.3068
Epoch 6/10, Batch 60/97, Loss: 0.5206
Epoch 6/10, Batch 70/97, Loss: 0.3136
Epoch 6/10, Batch 80/97, Loss: 0.3392
Epoch 6/10, Batch 90/97, Loss: 0.3457
Epoch 6/10, Train Loss: 0.2509, Valid Loss: 0.2599
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1540
Epoch 7/10, Batch 20/97, Loss: 0.3284
Epoch 7/10, Batch 30/97, Loss: 0.1106
Epoch 7/10, Batch 40/97, Loss: 0.2823
Epoch 7/10, Batch 50/97, Loss: 0.2259
Epoch 7/10, Batch 60/97, Loss: 0.0473
Epoch 7/10, Batch 70/97, Loss: 0.2193
Epoch 7/10, Batch 80/97, Loss: 0.2552
Epoch 7/10, Batch 90/97, Loss: 0.1368
Epoch 7/10, Train Loss: 0.2245, Valid Loss: 0.2532
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.3173
Epoch 8/10, Batch 20/97, Loss: 0.1988
Epoch 8/10, Batch 30/97, Loss: 0.2289
Epoch 8/10, Batch 40/97, Loss: 0.3355
Epoch 8/10, Batch 50/97, Loss: 0.2119
Epoch 8/10, Batch 60/97, Loss: 0.2685
Epoch 8/10, Batch 70/97, Loss: 0.2196
Epoch 8/10, Batch 80/97, Loss: 0.0876
Epoch 8/10, Batch 90/97, Loss: 0.1768
Epoch 8/10, Train Loss: 0.2216, Valid Loss: 0.2544
Epoch 9/10, Batch 10/97, Loss: 0.2579
Epoch 9/10, Batch 20/97, Loss: 0.1633
Epoch 9/10, Batch 30/97, Loss: 0.1557
Epoch 9/10, Batch 40/97, Loss: 0.2661
Epoch 9/10, Batch 50/97, Loss: 0.1820
Epoch 9/10, Batch 60/97, Loss: 0.2119
Epoch 9/10, Batch 70/97, Loss: 0.1920
Epoch 9/10, Batch 80/97, Loss: 0.1438
Epoch 9/10, Batch 90/97, Loss: 0.1460
Epoch 9/10, Train Loss: 0.2053, Valid Loss: 0.2395
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2608
Epoch 10/10, Batch 20/97, Loss: 0.1407
Epoch 10/10, Batch 30/97, Loss: 0.2432
Epoch 10/10, Batch 40/97, Loss: 0.3189
Epoch 10/10, Batch 50/97, Loss: 0.4372
Epoch 10/10, Batch 60/97, Loss: 0.2104
Epoch 10/10, Batch 70/97, Loss: 0.1842
Epoch 10/10, Batch 80/97, Loss: 0.2963
Epoch 10/10, Batch 90/97, Loss: 0.2161
Epoch 10/10, Train Loss: 0.2023, Valid Loss: 0.2389
Model saved!
Accuracy: 0.9124
Precision: 0.9104
Recall: 0.9124
F1-score: 0.9091
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2540
Epoch 1/10, Batch 20/97, Loss: 1.0744
Epoch 1/10, Batch 30/97, Loss: 0.7799
Epoch 1/10, Batch 40/97, Loss: 0.6659
Epoch 1/10, Batch 50/97, Loss: 0.5746
Epoch 1/10, Batch 60/97, Loss: 0.7363
Epoch 1/10, Batch 70/97, Loss: 0.6381
Epoch 1/10, Batch 80/97, Loss: 0.5784
Epoch 1/10, Batch 90/97, Loss: 0.5495
Epoch 1/10, Train Loss: 0.8037, Valid Loss: 0.4389
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5657
Epoch 2/10, Batch 20/97, Loss: 0.4089
Epoch 2/10, Batch 30/97, Loss: 0.4751
Epoch 2/10, Batch 40/97, Loss: 0.3317
Epoch 2/10, Batch 50/97, Loss: 0.5000
Epoch 2/10, Batch 60/97, Loss: 0.4246
Epoch 2/10, Batch 70/97, Loss: 0.3408
Epoch 2/10, Batch 80/97, Loss: 0.4570
Epoch 2/10, Batch 90/97, Loss: 0.4009
Epoch 2/10, Train Loss: 0.4181, Valid Loss: 0.3332
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3295
Epoch 3/10, Batch 20/97, Loss: 0.2201
Epoch 3/10, Batch 30/97, Loss: 0.2773
Epoch 3/10, Batch 40/97, Loss: 0.2854
Epoch 3/10, Batch 50/97, Loss: 0.3600
Epoch 3/10, Batch 60/97, Loss: 0.3121
Epoch 3/10, Batch 70/97, Loss: 0.3645
Epoch 3/10, Batch 80/97, Loss: 0.3505
Epoch 3/10, Batch 90/97, Loss: 0.3166
Epoch 3/10, Train Loss: 0.3340, Valid Loss: 0.2938
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2426
Epoch 4/10, Batch 20/97, Loss: 0.3517
Epoch 4/10, Batch 30/97, Loss: 0.2472
Epoch 4/10, Batch 40/97, Loss: 0.1778
Epoch 4/10, Batch 50/97, Loss: 0.2862
Epoch 4/10, Batch 60/97, Loss: 0.3272
Epoch 4/10, Batch 70/97, Loss: 0.2102
Epoch 4/10, Batch 80/97, Loss: 0.2571
Epoch 4/10, Batch 90/97, Loss: 0.1882
Epoch 4/10, Train Loss: 0.2837, Valid Loss: 0.2808
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3578
Epoch 5/10, Batch 20/97, Loss: 0.1961
Epoch 5/10, Batch 30/97, Loss: 0.3249
Epoch 5/10, Batch 40/97, Loss: 0.1865
Epoch 5/10, Batch 50/97, Loss: 0.2989
Epoch 5/10, Batch 60/97, Loss: 0.1720
Epoch 5/10, Batch 70/97, Loss: 0.3865
Epoch 5/10, Batch 80/97, Loss: 0.1724
Epoch 5/10, Batch 90/97, Loss: 0.2452
Epoch 5/10, Train Loss: 0.2636, Valid Loss: 0.2611
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2811
Epoch 6/10, Batch 20/97, Loss: 0.3723
Epoch 6/10, Batch 30/97, Loss: 0.2585
Epoch 6/10, Batch 40/97, Loss: 0.1910
Epoch 6/10, Batch 50/97, Loss: 0.2801
Epoch 6/10, Batch 60/97, Loss: 0.2052
Epoch 6/10, Batch 70/97, Loss: 0.1944
Epoch 6/10, Batch 80/97, Loss: 0.3002
Epoch 6/10, Batch 90/97, Loss: 0.2989
Epoch 6/10, Train Loss: 0.2457, Valid Loss: 0.2504
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2806
Epoch 7/10, Batch 20/97, Loss: 0.3390
Epoch 7/10, Batch 30/97, Loss: 0.1628
Epoch 7/10, Batch 40/97, Loss: 0.1427
Epoch 7/10, Batch 50/97, Loss: 0.1479
Epoch 7/10, Batch 60/97, Loss: 0.2359
Epoch 7/10, Batch 70/97, Loss: 0.2798
Epoch 7/10, Batch 80/97, Loss: 0.2511
Epoch 7/10, Batch 90/97, Loss: 0.2026
Epoch 7/10, Train Loss: 0.2271, Valid Loss: 0.2479
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1786
Epoch 8/10, Batch 20/97, Loss: 0.1688
Epoch 8/10, Batch 30/97, Loss: 0.2331
Epoch 8/10, Batch 40/97, Loss: 0.2745
Epoch 8/10, Batch 50/97, Loss: 0.3642
Epoch 8/10, Batch 60/97, Loss: 0.1927
Epoch 8/10, Batch 70/97, Loss: 0.2551
Epoch 8/10, Batch 80/97, Loss: 0.2111
Epoch 8/10, Batch 90/97, Loss: 0.2542
Epoch 8/10, Train Loss: 0.2201, Valid Loss: 0.2481
Epoch 9/10, Batch 10/97, Loss: 0.1568
Epoch 9/10, Batch 20/97, Loss: 0.2139
Epoch 9/10, Batch 30/97, Loss: 0.2379
Epoch 9/10, Batch 40/97, Loss: 0.2330
Epoch 9/10, Batch 50/97, Loss: 0.2232
Epoch 9/10, Batch 60/97, Loss: 0.2964
Epoch 9/10, Batch 70/97, Loss: 0.2127
Epoch 9/10, Batch 80/97, Loss: 0.1431
Epoch 9/10, Batch 90/97, Loss: 0.1873
Epoch 9/10, Train Loss: 0.2068, Valid Loss: 0.2398
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2908
Epoch 10/10, Batch 20/97, Loss: 0.1238
Epoch 10/10, Batch 30/97, Loss: 0.2759
Epoch 10/10, Batch 40/97, Loss: 0.0530
Epoch 10/10, Batch 50/97, Loss: 0.1948
Epoch 10/10, Batch 60/97, Loss: 0.1241
Epoch 10/10, Batch 70/97, Loss: 0.2483
Epoch 10/10, Batch 80/97, Loss: 0.1840
Epoch 10/10, Batch 90/97, Loss: 0.2371
Epoch 10/10, Train Loss: 0.2061, Valid Loss: 0.2408
Accuracy: 0.9182
Precision: 0.9166
Recall: 0.9182
F1-score: 0.9169
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.1894
Epoch 1/10, Batch 20/97, Loss: 1.1400
Epoch 1/10, Batch 30/97, Loss: 0.7692
Epoch 1/10, Batch 40/97, Loss: 0.7105
Epoch 1/10, Batch 50/97, Loss: 0.7331
Epoch 1/10, Batch 60/97, Loss: 0.8057
Epoch 1/10, Batch 70/97, Loss: 0.6238
Epoch 1/10, Batch 80/97, Loss: 0.8088
Epoch 1/10, Batch 90/97, Loss: 0.6306
Epoch 1/10, Train Loss: 0.8070, Valid Loss: 0.4606
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5517
Epoch 2/10, Batch 20/97, Loss: 0.5098
Epoch 2/10, Batch 30/97, Loss: 0.3478
Epoch 2/10, Batch 40/97, Loss: 0.2859
Epoch 2/10, Batch 50/97, Loss: 0.4191
Epoch 2/10, Batch 60/97, Loss: 0.4862
Epoch 2/10, Batch 70/97, Loss: 0.3560
Epoch 2/10, Batch 80/97, Loss: 0.3387
Epoch 2/10, Batch 90/97, Loss: 0.6026
Epoch 2/10, Train Loss: 0.4210, Valid Loss: 0.3439
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3188
Epoch 3/10, Batch 20/97, Loss: 0.3029
Epoch 3/10, Batch 30/97, Loss: 0.3168
Epoch 3/10, Batch 40/97, Loss: 0.3733
Epoch 3/10, Batch 50/97, Loss: 0.4766
Epoch 3/10, Batch 60/97, Loss: 0.4193
Epoch 3/10, Batch 70/97, Loss: 0.3532
Epoch 3/10, Batch 80/97, Loss: 0.3233
Epoch 3/10, Batch 90/97, Loss: 0.3330
Epoch 3/10, Train Loss: 0.3404, Valid Loss: 0.3063
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3931
Epoch 4/10, Batch 20/97, Loss: 0.1970
Epoch 4/10, Batch 30/97, Loss: 0.3333
Epoch 4/10, Batch 40/97, Loss: 0.1868
Epoch 4/10, Batch 50/97, Loss: 0.3842
Epoch 4/10, Batch 60/97, Loss: 0.3213
Epoch 4/10, Batch 70/97, Loss: 0.1984
Epoch 4/10, Batch 80/97, Loss: 0.1283
Epoch 4/10, Batch 90/97, Loss: 0.3067
Epoch 4/10, Train Loss: 0.2946, Valid Loss: 0.2778
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2591
Epoch 5/10, Batch 20/97, Loss: 0.3175
Epoch 5/10, Batch 30/97, Loss: 0.1867
Epoch 5/10, Batch 40/97, Loss: 0.2461
Epoch 5/10, Batch 50/97, Loss: 0.2115
Epoch 5/10, Batch 60/97, Loss: 0.3031
Epoch 5/10, Batch 70/97, Loss: 0.3965
Epoch 5/10, Batch 80/97, Loss: 0.1382
Epoch 5/10, Batch 90/97, Loss: 0.4018
Epoch 5/10, Train Loss: 0.2706, Valid Loss: 0.2665
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1927
Epoch 6/10, Batch 20/97, Loss: 0.1774
Epoch 6/10, Batch 30/97, Loss: 0.1079
Epoch 6/10, Batch 40/97, Loss: 0.2118
Epoch 6/10, Batch 50/97, Loss: 0.2145
Epoch 6/10, Batch 60/97, Loss: 0.2275
Epoch 6/10, Batch 70/97, Loss: 0.2131
Epoch 6/10, Batch 80/97, Loss: 0.3677
Epoch 6/10, Batch 90/97, Loss: 0.2738
Epoch 6/10, Train Loss: 0.2580, Valid Loss: 0.2542
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1725
Epoch 7/10, Batch 20/97, Loss: 0.2126
Epoch 7/10, Batch 30/97, Loss: 0.1827
Epoch 7/10, Batch 40/97, Loss: 0.2044
Epoch 7/10, Batch 50/97, Loss: 0.2204
Epoch 7/10, Batch 60/97, Loss: 0.1090
Epoch 7/10, Batch 70/97, Loss: 0.2416
Epoch 7/10, Batch 80/97, Loss: 0.2379
Epoch 7/10, Batch 90/97, Loss: 0.1700
Epoch 7/10, Train Loss: 0.2311, Valid Loss: 0.2511
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1561
Epoch 8/10, Batch 20/97, Loss: 0.2094
Epoch 8/10, Batch 30/97, Loss: 0.2279
Epoch 8/10, Batch 40/97, Loss: 0.1971
Epoch 8/10, Batch 50/97, Loss: 0.1662
Epoch 8/10, Batch 60/97, Loss: 0.1241
Epoch 8/10, Batch 70/97, Loss: 0.2433
Epoch 8/10, Batch 80/97, Loss: 0.1693
Epoch 8/10, Batch 90/97, Loss: 0.1310
Epoch 8/10, Train Loss: 0.2156, Valid Loss: 0.2410
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1279
Epoch 9/10, Batch 20/97, Loss: 0.0970
Epoch 9/10, Batch 30/97, Loss: 0.3918
Epoch 9/10, Batch 40/97, Loss: 0.2562
Epoch 9/10, Batch 50/97, Loss: 0.1267
Epoch 9/10, Batch 60/97, Loss: 0.1513
Epoch 9/10, Batch 70/97, Loss: 0.1032
Epoch 9/10, Batch 80/97, Loss: 0.3704
Epoch 9/10, Batch 90/97, Loss: 0.1824
Epoch 9/10, Train Loss: 0.2141, Valid Loss: 0.2371
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1002
Epoch 10/10, Batch 20/97, Loss: 0.1995
Epoch 10/10, Batch 30/97, Loss: 0.1367
Epoch 10/10, Batch 40/97, Loss: 0.1462
Epoch 10/10, Batch 50/97, Loss: 0.3526
Epoch 10/10, Batch 60/97, Loss: 0.2185
Epoch 10/10, Batch 70/97, Loss: 0.1310
Epoch 10/10, Batch 80/97, Loss: 0.1673
Epoch 10/10, Batch 90/97, Loss: 0.1528
Epoch 10/10, Train Loss: 0.1987, Valid Loss: 0.2302
Model saved!
Accuracy: 0.9124
Precision: 0.9084
Recall: 0.9124
F1-score: 0.9095
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2862
Epoch 1/10, Batch 20/97, Loss: 1.0098
Epoch 1/10, Batch 30/97, Loss: 0.6962
Epoch 1/10, Batch 40/97, Loss: 0.7538
Epoch 1/10, Batch 50/97, Loss: 0.6464
Epoch 1/10, Batch 60/97, Loss: 0.7510
Epoch 1/10, Batch 70/97, Loss: 0.4562
Epoch 1/10, Batch 80/97, Loss: 0.5988
Epoch 1/10, Batch 90/97, Loss: 0.5089
Epoch 1/10, Train Loss: 0.8089, Valid Loss: 0.4552
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4891
Epoch 2/10, Batch 20/97, Loss: 0.5387
Epoch 2/10, Batch 30/97, Loss: 0.4623
Epoch 2/10, Batch 40/97, Loss: 0.4611
Epoch 2/10, Batch 50/97, Loss: 0.3190
Epoch 2/10, Batch 60/97, Loss: 0.4082
Epoch 2/10, Batch 70/97, Loss: 0.3406
Epoch 2/10, Batch 80/97, Loss: 0.4051
Epoch 2/10, Batch 90/97, Loss: 0.4151
Epoch 2/10, Train Loss: 0.4140, Valid Loss: 0.3419
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3134
Epoch 3/10, Batch 20/97, Loss: 0.2823
Epoch 3/10, Batch 30/97, Loss: 0.4282
Epoch 3/10, Batch 40/97, Loss: 0.3556
Epoch 3/10, Batch 50/97, Loss: 0.4002
Epoch 3/10, Batch 60/97, Loss: 0.2544
Epoch 3/10, Batch 70/97, Loss: 0.3517
Epoch 3/10, Batch 80/97, Loss: 0.3645
Epoch 3/10, Batch 90/97, Loss: 0.3413
Epoch 3/10, Train Loss: 0.3339, Valid Loss: 0.2968
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4157
Epoch 4/10, Batch 20/97, Loss: 0.2038
Epoch 4/10, Batch 30/97, Loss: 0.3237
Epoch 4/10, Batch 40/97, Loss: 0.1769
Epoch 4/10, Batch 50/97, Loss: 0.2767
Epoch 4/10, Batch 60/97, Loss: 0.2432
Epoch 4/10, Batch 70/97, Loss: 0.3021
Epoch 4/10, Batch 80/97, Loss: 0.2790
Epoch 4/10, Batch 90/97, Loss: 0.3554
Epoch 4/10, Train Loss: 0.2894, Valid Loss: 0.2772
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2545
Epoch 5/10, Batch 20/97, Loss: 0.3209
Epoch 5/10, Batch 30/97, Loss: 0.2354
Epoch 5/10, Batch 40/97, Loss: 0.2604
Epoch 5/10, Batch 50/97, Loss: 0.2337
Epoch 5/10, Batch 60/97, Loss: 0.1658
Epoch 5/10, Batch 70/97, Loss: 0.2934
Epoch 5/10, Batch 80/97, Loss: 0.1782
Epoch 5/10, Batch 90/97, Loss: 0.2687
Epoch 5/10, Train Loss: 0.2668, Valid Loss: 0.2580
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2009
Epoch 6/10, Batch 20/97, Loss: 0.3969
Epoch 6/10, Batch 30/97, Loss: 0.1639
Epoch 6/10, Batch 40/97, Loss: 0.1522
Epoch 6/10, Batch 50/97, Loss: 0.2938
Epoch 6/10, Batch 60/97, Loss: 0.2796
Epoch 6/10, Batch 70/97, Loss: 0.1248
Epoch 6/10, Batch 80/97, Loss: 0.3400
Epoch 6/10, Batch 90/97, Loss: 0.3219
Epoch 6/10, Train Loss: 0.2484, Valid Loss: 0.2537
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1287
Epoch 7/10, Batch 20/97, Loss: 0.2249
Epoch 7/10, Batch 30/97, Loss: 0.2030
Epoch 7/10, Batch 40/97, Loss: 0.0737
Epoch 7/10, Batch 50/97, Loss: 0.2780
Epoch 7/10, Batch 60/97, Loss: 0.0762
Epoch 7/10, Batch 70/97, Loss: 0.1783
Epoch 7/10, Batch 80/97, Loss: 0.1862
Epoch 7/10, Batch 90/97, Loss: 0.1885
Epoch 7/10, Train Loss: 0.2279, Valid Loss: 0.2442
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2856
Epoch 8/10, Batch 20/97, Loss: 0.3838
Epoch 8/10, Batch 30/97, Loss: 0.1670
Epoch 8/10, Batch 40/97, Loss: 0.2602
Epoch 8/10, Batch 50/97, Loss: 0.2035
Epoch 8/10, Batch 60/97, Loss: 0.2306
Epoch 8/10, Batch 70/97, Loss: 0.1864
Epoch 8/10, Batch 80/97, Loss: 0.1548
Epoch 8/10, Batch 90/97, Loss: 0.2366
Epoch 8/10, Train Loss: 0.2233, Valid Loss: 0.2410
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2100
Epoch 9/10, Batch 20/97, Loss: 0.1620
Epoch 9/10, Batch 30/97, Loss: 0.2754
Epoch 9/10, Batch 40/97, Loss: 0.2450
Epoch 9/10, Batch 50/97, Loss: 0.1664
Epoch 9/10, Batch 60/97, Loss: 0.1356
Epoch 9/10, Batch 70/97, Loss: 0.1890
Epoch 9/10, Batch 80/97, Loss: 0.1020
Epoch 9/10, Batch 90/97, Loss: 0.2474
Epoch 9/10, Train Loss: 0.2051, Valid Loss: 0.2329
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2081
Epoch 10/10, Batch 20/97, Loss: 0.2142
Epoch 10/10, Batch 30/97, Loss: 0.1734
Epoch 10/10, Batch 40/97, Loss: 0.1166
Epoch 10/10, Batch 50/97, Loss: 0.1700
Epoch 10/10, Batch 60/97, Loss: 0.2545
Epoch 10/10, Batch 70/97, Loss: 0.2250
Epoch 10/10, Batch 80/97, Loss: 0.1439
Epoch 10/10, Batch 90/97, Loss: 0.0969
Epoch 10/10, Train Loss: 0.2057, Valid Loss: 0.2363
Accuracy: 0.9100
Precision: 0.9072
Recall: 0.9100
F1-score: 0.9077
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2333
Epoch 1/10, Batch 20/97, Loss: 1.1433
Epoch 1/10, Batch 30/97, Loss: 0.7982
Epoch 1/10, Batch 40/97, Loss: 0.7132
Epoch 1/10, Batch 50/97, Loss: 0.6053
Epoch 1/10, Batch 60/97, Loss: 0.7572
Epoch 1/10, Batch 70/97, Loss: 0.7017
Epoch 1/10, Batch 80/97, Loss: 0.5256
Epoch 1/10, Batch 90/97, Loss: 0.5214
Epoch 1/10, Train Loss: 0.7985, Valid Loss: 0.4504
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4540
Epoch 2/10, Batch 20/97, Loss: 0.2799
Epoch 2/10, Batch 30/97, Loss: 0.3361
Epoch 2/10, Batch 40/97, Loss: 0.2954
Epoch 2/10, Batch 50/97, Loss: 0.3479
Epoch 2/10, Batch 60/97, Loss: 0.3885
Epoch 2/10, Batch 70/97, Loss: 0.3231
Epoch 2/10, Batch 80/97, Loss: 0.3922
Epoch 2/10, Batch 90/97, Loss: 0.4257
Epoch 2/10, Train Loss: 0.4142, Valid Loss: 0.3367
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3022
Epoch 3/10, Batch 20/97, Loss: 0.2922
Epoch 3/10, Batch 30/97, Loss: 0.3165
Epoch 3/10, Batch 40/97, Loss: 0.2497
Epoch 3/10, Batch 50/97, Loss: 0.3219
Epoch 3/10, Batch 60/97, Loss: 0.1908
Epoch 3/10, Batch 70/97, Loss: 0.2967
Epoch 3/10, Batch 80/97, Loss: 0.2938
Epoch 3/10, Batch 90/97, Loss: 0.3431
Epoch 3/10, Train Loss: 0.3265, Valid Loss: 0.2974
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4862
Epoch 4/10, Batch 20/97, Loss: 0.1502
Epoch 4/10, Batch 30/97, Loss: 0.1866
Epoch 4/10, Batch 40/97, Loss: 0.2317
Epoch 4/10, Batch 50/97, Loss: 0.2007
Epoch 4/10, Batch 60/97, Loss: 0.3891
Epoch 4/10, Batch 70/97, Loss: 0.3587
Epoch 4/10, Batch 80/97, Loss: 0.2744
Epoch 4/10, Batch 90/97, Loss: 0.1726
Epoch 4/10, Train Loss: 0.2849, Valid Loss: 0.2673
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1606
Epoch 5/10, Batch 20/97, Loss: 0.2791
Epoch 5/10, Batch 30/97, Loss: 0.1514
Epoch 5/10, Batch 40/97, Loss: 0.2901
Epoch 5/10, Batch 50/97, Loss: 0.2883
Epoch 5/10, Batch 60/97, Loss: 0.2258
Epoch 5/10, Batch 70/97, Loss: 0.3852
Epoch 5/10, Batch 80/97, Loss: 0.2446
Epoch 5/10, Batch 90/97, Loss: 0.2632
Epoch 5/10, Train Loss: 0.2652, Valid Loss: 0.2638
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3318
Epoch 6/10, Batch 20/97, Loss: 0.3751
Epoch 6/10, Batch 30/97, Loss: 0.2941
Epoch 6/10, Batch 40/97, Loss: 0.2788
Epoch 6/10, Batch 50/97, Loss: 0.1589
Epoch 6/10, Batch 60/97, Loss: 0.4196
Epoch 6/10, Batch 70/97, Loss: 0.2010
Epoch 6/10, Batch 80/97, Loss: 0.2888
Epoch 6/10, Batch 90/97, Loss: 0.5072
Epoch 6/10, Train Loss: 0.2450, Valid Loss: 0.2388
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2473
Epoch 7/10, Batch 20/97, Loss: 0.3031
Epoch 7/10, Batch 30/97, Loss: 0.2349
Epoch 7/10, Batch 40/97, Loss: 0.0944
Epoch 7/10, Batch 50/97, Loss: 0.1526
Epoch 7/10, Batch 60/97, Loss: 0.1402
Epoch 7/10, Batch 70/97, Loss: 0.2169
Epoch 7/10, Batch 80/97, Loss: 0.1766
Epoch 7/10, Batch 90/97, Loss: 0.1930
Epoch 7/10, Train Loss: 0.2224, Valid Loss: 0.2316
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.0859
Epoch 8/10, Batch 20/97, Loss: 0.2364
Epoch 8/10, Batch 30/97, Loss: 0.3353
Epoch 8/10, Batch 40/97, Loss: 0.1453
Epoch 8/10, Batch 50/97, Loss: 0.2757
Epoch 8/10, Batch 60/97, Loss: 0.3146
Epoch 8/10, Batch 70/97, Loss: 0.3286
Epoch 8/10, Batch 80/97, Loss: 0.2398
Epoch 8/10, Batch 90/97, Loss: 0.1489
Epoch 8/10, Train Loss: 0.2206, Valid Loss: 0.2317
Epoch 9/10, Batch 10/97, Loss: 0.2794
Epoch 9/10, Batch 20/97, Loss: 0.1838
Epoch 9/10, Batch 30/97, Loss: 0.2596
Epoch 9/10, Batch 40/97, Loss: 0.2145
Epoch 9/10, Batch 50/97, Loss: 0.1747
Epoch 9/10, Batch 60/97, Loss: 0.1541
Epoch 9/10, Batch 70/97, Loss: 0.1410
Epoch 9/10, Batch 80/97, Loss: 0.1073
Epoch 9/10, Batch 90/97, Loss: 0.2017
Epoch 9/10, Train Loss: 0.2116, Valid Loss: 0.2214
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3072
Epoch 10/10, Batch 20/97, Loss: 0.2204
Epoch 10/10, Batch 30/97, Loss: 0.2274
Epoch 10/10, Batch 40/97, Loss: 0.2534
Epoch 10/10, Batch 50/97, Loss: 0.2001
Epoch 10/10, Batch 60/97, Loss: 0.1228
Epoch 10/10, Batch 70/97, Loss: 0.2619
Epoch 10/10, Batch 80/97, Loss: 0.2314
Epoch 10/10, Batch 90/97, Loss: 0.1925
Epoch 10/10, Train Loss: 0.2028, Valid Loss: 0.2276
Accuracy: 0.9124
Precision: 0.9082
Recall: 0.9124
F1-score: 0.9093
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2356
Epoch 1/10, Batch 20/97, Loss: 0.9653
Epoch 1/10, Batch 30/97, Loss: 0.7455
Epoch 1/10, Batch 40/97, Loss: 0.6587
Epoch 1/10, Batch 50/97, Loss: 0.5284
Epoch 1/10, Batch 60/97, Loss: 0.7429
Epoch 1/10, Batch 70/97, Loss: 0.7581
Epoch 1/10, Batch 80/97, Loss: 0.6069
Epoch 1/10, Batch 90/97, Loss: 0.5911
Epoch 1/10, Train Loss: 0.7993, Valid Loss: 0.4511
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6545
Epoch 2/10, Batch 20/97, Loss: 0.5249
Epoch 2/10, Batch 30/97, Loss: 0.3327
Epoch 2/10, Batch 40/97, Loss: 0.3278
Epoch 2/10, Batch 50/97, Loss: 0.3208
Epoch 2/10, Batch 60/97, Loss: 0.3195
Epoch 2/10, Batch 70/97, Loss: 0.2572
Epoch 2/10, Batch 80/97, Loss: 0.2665
Epoch 2/10, Batch 90/97, Loss: 0.3946
Epoch 2/10, Train Loss: 0.4095, Valid Loss: 0.3464
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3855
Epoch 3/10, Batch 20/97, Loss: 0.4793
Epoch 3/10, Batch 30/97, Loss: 0.4923
Epoch 3/10, Batch 40/97, Loss: 0.2694
Epoch 3/10, Batch 50/97, Loss: 0.3478
Epoch 3/10, Batch 60/97, Loss: 0.2233
Epoch 3/10, Batch 70/97, Loss: 0.3063
Epoch 3/10, Batch 80/97, Loss: 0.3679
Epoch 3/10, Batch 90/97, Loss: 0.2254
Epoch 3/10, Train Loss: 0.3306, Valid Loss: 0.3036
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3325
Epoch 4/10, Batch 20/97, Loss: 0.2798
Epoch 4/10, Batch 30/97, Loss: 0.2905
Epoch 4/10, Batch 40/97, Loss: 0.3617
Epoch 4/10, Batch 50/97, Loss: 0.3315
Epoch 4/10, Batch 60/97, Loss: 0.2207
Epoch 4/10, Batch 70/97, Loss: 0.2520
Epoch 4/10, Batch 80/97, Loss: 0.2045
Epoch 4/10, Batch 90/97, Loss: 0.1441
Epoch 4/10, Train Loss: 0.2817, Valid Loss: 0.2948
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3037
Epoch 5/10, Batch 20/97, Loss: 0.4415
Epoch 5/10, Batch 30/97, Loss: 0.2504
Epoch 5/10, Batch 40/97, Loss: 0.3499
Epoch 5/10, Batch 50/97, Loss: 0.3348
Epoch 5/10, Batch 60/97, Loss: 0.3388
Epoch 5/10, Batch 70/97, Loss: 0.2178
Epoch 5/10, Batch 80/97, Loss: 0.1613
Epoch 5/10, Batch 90/97, Loss: 0.1909
Epoch 5/10, Train Loss: 0.2610, Valid Loss: 0.2694
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2767
Epoch 6/10, Batch 20/97, Loss: 0.4013
Epoch 6/10, Batch 30/97, Loss: 0.3532
Epoch 6/10, Batch 40/97, Loss: 0.3666
Epoch 6/10, Batch 50/97, Loss: 0.3543
Epoch 6/10, Batch 60/97, Loss: 0.3313
Epoch 6/10, Batch 70/97, Loss: 0.2183
Epoch 6/10, Batch 80/97, Loss: 0.2146
Epoch 6/10, Batch 90/97, Loss: 0.2905
Epoch 6/10, Train Loss: 0.2507, Valid Loss: 0.2571
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1566
Epoch 7/10, Batch 20/97, Loss: 0.4058
Epoch 7/10, Batch 30/97, Loss: 0.2947
Epoch 7/10, Batch 40/97, Loss: 0.1938
Epoch 7/10, Batch 50/97, Loss: 0.3494
Epoch 7/10, Batch 60/97, Loss: 0.1633
Epoch 7/10, Batch 70/97, Loss: 0.2137
Epoch 7/10, Batch 80/97, Loss: 0.1621
Epoch 7/10, Batch 90/97, Loss: 0.1680
Epoch 7/10, Train Loss: 0.2289, Valid Loss: 0.2462
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1624
Epoch 8/10, Batch 20/97, Loss: 0.1883
Epoch 8/10, Batch 30/97, Loss: 0.1319
Epoch 8/10, Batch 40/97, Loss: 0.2651
Epoch 8/10, Batch 50/97, Loss: 0.1768
Epoch 8/10, Batch 60/97, Loss: 0.1733
Epoch 8/10, Batch 70/97, Loss: 0.3038
Epoch 8/10, Batch 80/97, Loss: 0.0849
Epoch 8/10, Batch 90/97, Loss: 0.2205
Epoch 8/10, Train Loss: 0.2182, Valid Loss: 0.2498
Epoch 9/10, Batch 10/97, Loss: 0.1551
Epoch 9/10, Batch 20/97, Loss: 0.1673
Epoch 9/10, Batch 30/97, Loss: 0.2502
Epoch 9/10, Batch 40/97, Loss: 0.1663
Epoch 9/10, Batch 50/97, Loss: 0.0851
Epoch 9/10, Batch 60/97, Loss: 0.2383
Epoch 9/10, Batch 70/97, Loss: 0.1843
Epoch 9/10, Batch 80/97, Loss: 0.2008
Epoch 9/10, Batch 90/97, Loss: 0.1347
Epoch 9/10, Train Loss: 0.2104, Valid Loss: 0.2389
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1931
Epoch 10/10, Batch 20/97, Loss: 0.1525
Epoch 10/10, Batch 30/97, Loss: 0.2006
Epoch 10/10, Batch 40/97, Loss: 0.3161
Epoch 10/10, Batch 50/97, Loss: 0.1999
Epoch 10/10, Batch 60/97, Loss: 0.1369
Epoch 10/10, Batch 70/97, Loss: 0.2593
Epoch 10/10, Batch 80/97, Loss: 0.2642
Epoch 10/10, Batch 90/97, Loss: 0.0915
Epoch 10/10, Train Loss: 0.2020, Valid Loss: 0.2407
Accuracy: 0.9124
Precision: 0.9096
Recall: 0.9124
F1-score: 0.9099
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2662
Epoch 1/10, Batch 20/97, Loss: 1.1112
Epoch 1/10, Batch 30/97, Loss: 0.6998
Epoch 1/10, Batch 40/97, Loss: 0.6380
Epoch 1/10, Batch 50/97, Loss: 0.7461
Epoch 1/10, Batch 60/97, Loss: 0.7450
Epoch 1/10, Batch 70/97, Loss: 0.5421
Epoch 1/10, Batch 80/97, Loss: 0.6742
Epoch 1/10, Batch 90/97, Loss: 0.5733
Epoch 1/10, Train Loss: 0.8022, Valid Loss: 0.4359
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4471
Epoch 2/10, Batch 20/97, Loss: 0.4424
Epoch 2/10, Batch 30/97, Loss: 0.3658
Epoch 2/10, Batch 40/97, Loss: 0.3503
Epoch 2/10, Batch 50/97, Loss: 0.6442
Epoch 2/10, Batch 60/97, Loss: 0.4264
Epoch 2/10, Batch 70/97, Loss: 0.3321
Epoch 2/10, Batch 80/97, Loss: 0.3611
Epoch 2/10, Batch 90/97, Loss: 0.5477
Epoch 2/10, Train Loss: 0.4181, Valid Loss: 0.3237
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3939
Epoch 3/10, Batch 20/97, Loss: 0.3428
Epoch 3/10, Batch 30/97, Loss: 0.3422
Epoch 3/10, Batch 40/97, Loss: 0.2632
Epoch 3/10, Batch 50/97, Loss: 0.2905
Epoch 3/10, Batch 60/97, Loss: 0.2701
Epoch 3/10, Batch 70/97, Loss: 0.4078
Epoch 3/10, Batch 80/97, Loss: 0.2202
Epoch 3/10, Batch 90/97, Loss: 0.2310
Epoch 3/10, Train Loss: 0.3326, Valid Loss: 0.2750
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3708
Epoch 4/10, Batch 20/97, Loss: 0.2006
Epoch 4/10, Batch 30/97, Loss: 0.2436
Epoch 4/10, Batch 40/97, Loss: 0.3683
Epoch 4/10, Batch 50/97, Loss: 0.2641
Epoch 4/10, Batch 60/97, Loss: 0.1674
Epoch 4/10, Batch 70/97, Loss: 0.3937
Epoch 4/10, Batch 80/97, Loss: 0.2076
Epoch 4/10, Batch 90/97, Loss: 0.3102
Epoch 4/10, Train Loss: 0.2846, Valid Loss: 0.2549
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1891
Epoch 5/10, Batch 20/97, Loss: 0.5441
Epoch 5/10, Batch 30/97, Loss: 0.3496
Epoch 5/10, Batch 40/97, Loss: 0.2069
Epoch 5/10, Batch 50/97, Loss: 0.2582
Epoch 5/10, Batch 60/97, Loss: 0.4081
Epoch 5/10, Batch 70/97, Loss: 0.3118
Epoch 5/10, Batch 80/97, Loss: 0.2723
Epoch 5/10, Batch 90/97, Loss: 0.2319
Epoch 5/10, Train Loss: 0.2693, Valid Loss: 0.2375
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2009
Epoch 6/10, Batch 20/97, Loss: 0.4033
Epoch 6/10, Batch 30/97, Loss: 0.2190
Epoch 6/10, Batch 40/97, Loss: 0.1125
Epoch 6/10, Batch 50/97, Loss: 0.2045
Epoch 6/10, Batch 60/97, Loss: 0.2601
Epoch 6/10, Batch 70/97, Loss: 0.2124
Epoch 6/10, Batch 80/97, Loss: 0.3101
Epoch 6/10, Batch 90/97, Loss: 0.3173
Epoch 6/10, Train Loss: 0.2533, Valid Loss: 0.2241
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1764
Epoch 7/10, Batch 20/97, Loss: 0.2924
Epoch 7/10, Batch 30/97, Loss: 0.1888
Epoch 7/10, Batch 40/97, Loss: 0.2085
Epoch 7/10, Batch 50/97, Loss: 0.3464
Epoch 7/10, Batch 60/97, Loss: 0.2289
Epoch 7/10, Batch 70/97, Loss: 0.2113
Epoch 7/10, Batch 80/97, Loss: 0.2721
Epoch 7/10, Batch 90/97, Loss: 0.1268
Epoch 7/10, Train Loss: 0.2312, Valid Loss: 0.2210
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1170
Epoch 8/10, Batch 20/97, Loss: 0.1478
Epoch 8/10, Batch 30/97, Loss: 0.1495
Epoch 8/10, Batch 40/97, Loss: 0.1896
Epoch 8/10, Batch 50/97, Loss: 0.2130
Epoch 8/10, Batch 60/97, Loss: 0.2292
Epoch 8/10, Batch 70/97, Loss: 0.1221
Epoch 8/10, Batch 80/97, Loss: 0.2536
Epoch 8/10, Batch 90/97, Loss: 0.2773
Epoch 8/10, Train Loss: 0.2219, Valid Loss: 0.2164
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2127
Epoch 9/10, Batch 20/97, Loss: 0.1222
Epoch 9/10, Batch 30/97, Loss: 0.1746
Epoch 9/10, Batch 40/97, Loss: 0.1814
Epoch 9/10, Batch 50/97, Loss: 0.0633
Epoch 9/10, Batch 60/97, Loss: 0.2097
Epoch 9/10, Batch 70/97, Loss: 0.1561
Epoch 9/10, Batch 80/97, Loss: 0.2014
Epoch 9/10, Batch 90/97, Loss: 0.2206
Epoch 9/10, Train Loss: 0.2093, Valid Loss: 0.2172
Epoch 10/10, Batch 10/97, Loss: 0.2960
Epoch 10/10, Batch 20/97, Loss: 0.2065
Epoch 10/10, Batch 30/97, Loss: 0.2010
Epoch 10/10, Batch 40/97, Loss: 0.1715
Epoch 10/10, Batch 50/97, Loss: 0.1648
Epoch 10/10, Batch 60/97, Loss: 0.2722
Epoch 10/10, Batch 70/97, Loss: 0.3764
Epoch 10/10, Batch 80/97, Loss: 0.1147
Epoch 10/10, Batch 90/97, Loss: 0.2430
Epoch 10/10, Train Loss: 0.2040, Valid Loss: 0.2173
Accuracy: 0.9112
Precision: 0.9080
Recall: 0.9112
F1-score: 0.9084
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2542
Epoch 1/10, Batch 20/97, Loss: 1.0162
Epoch 1/10, Batch 30/97, Loss: 0.8439
Epoch 1/10, Batch 40/97, Loss: 0.7759
Epoch 1/10, Batch 50/97, Loss: 0.6275
Epoch 1/10, Batch 60/97, Loss: 0.6126
Epoch 1/10, Batch 70/97, Loss: 0.7102
Epoch 1/10, Batch 80/97, Loss: 0.8170
Epoch 1/10, Batch 90/97, Loss: 0.4944
Epoch 1/10, Train Loss: 0.8066, Valid Loss: 0.4418
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5040
Epoch 2/10, Batch 20/97, Loss: 0.4082
Epoch 2/10, Batch 30/97, Loss: 0.3563
Epoch 2/10, Batch 40/97, Loss: 0.3424
Epoch 2/10, Batch 50/97, Loss: 0.5296
Epoch 2/10, Batch 60/97, Loss: 0.4730
Epoch 2/10, Batch 70/97, Loss: 0.5187
Epoch 2/10, Batch 80/97, Loss: 0.2588
Epoch 2/10, Batch 90/97, Loss: 0.3377
Epoch 2/10, Train Loss: 0.4141, Valid Loss: 0.3356
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3358
Epoch 3/10, Batch 20/97, Loss: 0.4655
Epoch 3/10, Batch 30/97, Loss: 0.3467
Epoch 3/10, Batch 40/97, Loss: 0.3483
Epoch 3/10, Batch 50/97, Loss: 0.5104
Epoch 3/10, Batch 60/97, Loss: 0.3140
Epoch 3/10, Batch 70/97, Loss: 0.3328
Epoch 3/10, Batch 80/97, Loss: 0.3667
Epoch 3/10, Batch 90/97, Loss: 0.2576
Epoch 3/10, Train Loss: 0.3373, Valid Loss: 0.2962
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3810
Epoch 4/10, Batch 20/97, Loss: 0.2348
Epoch 4/10, Batch 30/97, Loss: 0.2676
Epoch 4/10, Batch 40/97, Loss: 0.2257
Epoch 4/10, Batch 50/97, Loss: 0.6018
Epoch 4/10, Batch 60/97, Loss: 0.2388
Epoch 4/10, Batch 70/97, Loss: 0.2121
Epoch 4/10, Batch 80/97, Loss: 0.3283
Epoch 4/10, Batch 90/97, Loss: 0.2491
Epoch 4/10, Train Loss: 0.2877, Valid Loss: 0.2791
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2349
Epoch 5/10, Batch 20/97, Loss: 0.2737
Epoch 5/10, Batch 30/97, Loss: 0.2704
Epoch 5/10, Batch 40/97, Loss: 0.1763
Epoch 5/10, Batch 50/97, Loss: 0.2127
Epoch 5/10, Batch 60/97, Loss: 0.1971
Epoch 5/10, Batch 70/97, Loss: 0.1752
Epoch 5/10, Batch 80/97, Loss: 0.3303
Epoch 5/10, Batch 90/97, Loss: 0.3155
Epoch 5/10, Train Loss: 0.2644, Valid Loss: 0.2643
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2431
Epoch 6/10, Batch 20/97, Loss: 0.3357
Epoch 6/10, Batch 30/97, Loss: 0.1786
Epoch 6/10, Batch 40/97, Loss: 0.1269
Epoch 6/10, Batch 50/97, Loss: 0.2849
Epoch 6/10, Batch 60/97, Loss: 0.2859
Epoch 6/10, Batch 70/97, Loss: 0.2963
Epoch 6/10, Batch 80/97, Loss: 0.3056
Epoch 6/10, Batch 90/97, Loss: 0.1798
Epoch 6/10, Train Loss: 0.2454, Valid Loss: 0.2506
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1930
Epoch 7/10, Batch 20/97, Loss: 0.3306
Epoch 7/10, Batch 30/97, Loss: 0.2809
Epoch 7/10, Batch 40/97, Loss: 0.1926
Epoch 7/10, Batch 50/97, Loss: 0.2868
Epoch 7/10, Batch 60/97, Loss: 0.1706
Epoch 7/10, Batch 70/97, Loss: 0.2672
Epoch 7/10, Batch 80/97, Loss: 0.1836
Epoch 7/10, Batch 90/97, Loss: 0.1548
Epoch 7/10, Train Loss: 0.2266, Valid Loss: 0.2496
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2038
Epoch 8/10, Batch 20/97, Loss: 0.2621
Epoch 8/10, Batch 30/97, Loss: 0.1851
Epoch 8/10, Batch 40/97, Loss: 0.2281
Epoch 8/10, Batch 50/97, Loss: 0.2938
Epoch 8/10, Batch 60/97, Loss: 0.2536
Epoch 8/10, Batch 70/97, Loss: 0.1975
Epoch 8/10, Batch 80/97, Loss: 0.2020
Epoch 8/10, Batch 90/97, Loss: 0.2645
Epoch 8/10, Train Loss: 0.2270, Valid Loss: 0.2381
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0769
Epoch 9/10, Batch 20/97, Loss: 0.1142
Epoch 9/10, Batch 30/97, Loss: 0.2262
Epoch 9/10, Batch 40/97, Loss: 0.2603
Epoch 9/10, Batch 50/97, Loss: 0.1964
Epoch 9/10, Batch 60/97, Loss: 0.1876
Epoch 9/10, Batch 70/97, Loss: 0.1510
Epoch 9/10, Batch 80/97, Loss: 0.2104
Epoch 9/10, Batch 90/97, Loss: 0.1320
Epoch 9/10, Train Loss: 0.2077, Valid Loss: 0.2407
Epoch 10/10, Batch 10/97, Loss: 0.2575
Epoch 10/10, Batch 20/97, Loss: 0.0607
Epoch 10/10, Batch 30/97, Loss: 0.2313
Epoch 10/10, Batch 40/97, Loss: 0.2841
Epoch 10/10, Batch 50/97, Loss: 0.1659
Epoch 10/10, Batch 60/97, Loss: 0.1302
Epoch 10/10, Batch 70/97, Loss: 0.3196
Epoch 10/10, Batch 80/97, Loss: 0.1869
Epoch 10/10, Batch 90/97, Loss: 0.1392
Epoch 10/10, Train Loss: 0.1983, Valid Loss: 0.2346
Model saved!
Accuracy: 0.9100
Precision: 0.9067
Recall: 0.9100
F1-score: 0.9064
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2110
Epoch 1/10, Batch 20/97, Loss: 1.0562
Epoch 1/10, Batch 30/97, Loss: 0.8179
Epoch 1/10, Batch 40/97, Loss: 0.8553
Epoch 1/10, Batch 50/97, Loss: 0.5943
Epoch 1/10, Batch 60/97, Loss: 0.8049
Epoch 1/10, Batch 70/97, Loss: 0.5109
Epoch 1/10, Batch 80/97, Loss: 0.5252
Epoch 1/10, Batch 90/97, Loss: 0.6371
Epoch 1/10, Train Loss: 0.8008, Valid Loss: 0.4562
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5199
Epoch 2/10, Batch 20/97, Loss: 0.4174
Epoch 2/10, Batch 30/97, Loss: 0.2965
Epoch 2/10, Batch 40/97, Loss: 0.3541
Epoch 2/10, Batch 50/97, Loss: 0.3873
Epoch 2/10, Batch 60/97, Loss: 0.4448
Epoch 2/10, Batch 70/97, Loss: 0.3159
Epoch 2/10, Batch 80/97, Loss: 0.2568
Epoch 2/10, Batch 90/97, Loss: 0.4990
Epoch 2/10, Train Loss: 0.4078, Valid Loss: 0.3526
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3767
Epoch 3/10, Batch 20/97, Loss: 0.3473
Epoch 3/10, Batch 30/97, Loss: 0.2846
Epoch 3/10, Batch 40/97, Loss: 0.2121
Epoch 3/10, Batch 50/97, Loss: 0.3389
Epoch 3/10, Batch 60/97, Loss: 0.2596
Epoch 3/10, Batch 70/97, Loss: 0.4934
Epoch 3/10, Batch 80/97, Loss: 0.3119
Epoch 3/10, Batch 90/97, Loss: 0.3009
Epoch 3/10, Train Loss: 0.3335, Valid Loss: 0.3079
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3477
Epoch 4/10, Batch 20/97, Loss: 0.2329
Epoch 4/10, Batch 30/97, Loss: 0.1972
Epoch 4/10, Batch 40/97, Loss: 0.3854
Epoch 4/10, Batch 50/97, Loss: 0.2455
Epoch 4/10, Batch 60/97, Loss: 0.2813
Epoch 4/10, Batch 70/97, Loss: 0.2793
Epoch 4/10, Batch 80/97, Loss: 0.1990
Epoch 4/10, Batch 90/97, Loss: 0.4052
Epoch 4/10, Train Loss: 0.2814, Valid Loss: 0.2948
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1897
Epoch 5/10, Batch 20/97, Loss: 0.3316
Epoch 5/10, Batch 30/97, Loss: 0.1843
Epoch 5/10, Batch 40/97, Loss: 0.1584
Epoch 5/10, Batch 50/97, Loss: 0.2800
Epoch 5/10, Batch 60/97, Loss: 0.2149
Epoch 5/10, Batch 70/97, Loss: 0.3023
Epoch 5/10, Batch 80/97, Loss: 0.1845
Epoch 5/10, Batch 90/97, Loss: 0.2588
Epoch 5/10, Train Loss: 0.2582, Valid Loss: 0.2831
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1781
Epoch 6/10, Batch 20/97, Loss: 0.4528
Epoch 6/10, Batch 30/97, Loss: 0.0992
Epoch 6/10, Batch 40/97, Loss: 0.1732
Epoch 6/10, Batch 50/97, Loss: 0.2652
Epoch 6/10, Batch 60/97, Loss: 0.1813
Epoch 6/10, Batch 70/97, Loss: 0.2543
Epoch 6/10, Batch 80/97, Loss: 0.2399
Epoch 6/10, Batch 90/97, Loss: 0.3393
Epoch 6/10, Train Loss: 0.2413, Valid Loss: 0.2589
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1760
Epoch 7/10, Batch 20/97, Loss: 0.2496
Epoch 7/10, Batch 30/97, Loss: 0.3095
Epoch 7/10, Batch 40/97, Loss: 0.1749
Epoch 7/10, Batch 50/97, Loss: 0.1460
Epoch 7/10, Batch 60/97, Loss: 0.2119
Epoch 7/10, Batch 70/97, Loss: 0.2485
Epoch 7/10, Batch 80/97, Loss: 0.2100
Epoch 7/10, Batch 90/97, Loss: 0.1715
Epoch 7/10, Train Loss: 0.2220, Valid Loss: 0.2585
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1436
Epoch 8/10, Batch 20/97, Loss: 0.1857
Epoch 8/10, Batch 30/97, Loss: 0.2051
Epoch 8/10, Batch 40/97, Loss: 0.2035
Epoch 8/10, Batch 50/97, Loss: 0.1596
Epoch 8/10, Batch 60/97, Loss: 0.2704
Epoch 8/10, Batch 70/97, Loss: 0.2210
Epoch 8/10, Batch 80/97, Loss: 0.2654
Epoch 8/10, Batch 90/97, Loss: 0.1759
Epoch 8/10, Train Loss: 0.2176, Valid Loss: 0.2597
Epoch 9/10, Batch 10/97, Loss: 0.0858
Epoch 9/10, Batch 20/97, Loss: 0.0818
Epoch 9/10, Batch 30/97, Loss: 0.1983
Epoch 9/10, Batch 40/97, Loss: 0.2565
Epoch 9/10, Batch 50/97, Loss: 0.1560
Epoch 9/10, Batch 60/97, Loss: 0.4032
Epoch 9/10, Batch 70/97, Loss: 0.2466
Epoch 9/10, Batch 80/97, Loss: 0.1282
Epoch 9/10, Batch 90/97, Loss: 0.1860
Epoch 9/10, Train Loss: 0.2096, Valid Loss: 0.2529
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1545
Epoch 10/10, Batch 20/97, Loss: 0.1807
Epoch 10/10, Batch 30/97, Loss: 0.2409
Epoch 10/10, Batch 40/97, Loss: 0.1257
Epoch 10/10, Batch 50/97, Loss: 0.1746
Epoch 10/10, Batch 60/97, Loss: 0.2567
Epoch 10/10, Batch 70/97, Loss: 0.1080
Epoch 10/10, Batch 80/97, Loss: 0.4003
Epoch 10/10, Batch 90/97, Loss: 0.2915
Epoch 10/10, Train Loss: 0.2010, Valid Loss: 0.2483
Model saved!
Accuracy: 0.9159
Precision: 0.9129
Recall: 0.9159
F1-score: 0.9135
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2457
Epoch 1/10, Batch 20/97, Loss: 1.0645
Epoch 1/10, Batch 30/97, Loss: 0.7807
Epoch 1/10, Batch 40/97, Loss: 0.7380
Epoch 1/10, Batch 50/97, Loss: 0.7044
Epoch 1/10, Batch 60/97, Loss: 0.7532
Epoch 1/10, Batch 70/97, Loss: 0.6728
Epoch 1/10, Batch 80/97, Loss: 0.6528
Epoch 1/10, Batch 90/97, Loss: 0.6125
Epoch 1/10, Train Loss: 0.8028, Valid Loss: 0.4680
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5077
Epoch 2/10, Batch 20/97, Loss: 0.4582
Epoch 2/10, Batch 30/97, Loss: 0.3345
Epoch 2/10, Batch 40/97, Loss: 0.2319
Epoch 2/10, Batch 50/97, Loss: 0.4768
Epoch 2/10, Batch 60/97, Loss: 0.4336
Epoch 2/10, Batch 70/97, Loss: 0.3467
Epoch 2/10, Batch 80/97, Loss: 0.2854
Epoch 2/10, Batch 90/97, Loss: 0.3589
Epoch 2/10, Train Loss: 0.4099, Valid Loss: 0.3558
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3766
Epoch 3/10, Batch 20/97, Loss: 0.2752
Epoch 3/10, Batch 30/97, Loss: 0.3538
Epoch 3/10, Batch 40/97, Loss: 0.1532
Epoch 3/10, Batch 50/97, Loss: 0.3471
Epoch 3/10, Batch 60/97, Loss: 0.2042
Epoch 3/10, Batch 70/97, Loss: 0.3836
Epoch 3/10, Batch 80/97, Loss: 0.3190
Epoch 3/10, Batch 90/97, Loss: 0.3994
Epoch 3/10, Train Loss: 0.3370, Valid Loss: 0.3142
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.5541
Epoch 4/10, Batch 20/97, Loss: 0.2466
Epoch 4/10, Batch 30/97, Loss: 0.2753
Epoch 4/10, Batch 40/97, Loss: 0.2074
Epoch 4/10, Batch 50/97, Loss: 0.3151
Epoch 4/10, Batch 60/97, Loss: 0.2844
Epoch 4/10, Batch 70/97, Loss: 0.1581
Epoch 4/10, Batch 80/97, Loss: 0.4589
Epoch 4/10, Batch 90/97, Loss: 0.2010
Epoch 4/10, Train Loss: 0.2895, Valid Loss: 0.2999
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3175
Epoch 5/10, Batch 20/97, Loss: 0.3235
Epoch 5/10, Batch 30/97, Loss: 0.1472
Epoch 5/10, Batch 40/97, Loss: 0.2379
Epoch 5/10, Batch 50/97, Loss: 0.2371
Epoch 5/10, Batch 60/97, Loss: 0.2467
Epoch 5/10, Batch 70/97, Loss: 0.1841
Epoch 5/10, Batch 80/97, Loss: 0.2677
Epoch 5/10, Batch 90/97, Loss: 0.3305
Epoch 5/10, Train Loss: 0.2771, Valid Loss: 0.2787
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2757
Epoch 6/10, Batch 20/97, Loss: 0.3883
Epoch 6/10, Batch 30/97, Loss: 0.1207
Epoch 6/10, Batch 40/97, Loss: 0.2424
Epoch 6/10, Batch 50/97, Loss: 0.2563
Epoch 6/10, Batch 60/97, Loss: 0.4399
Epoch 6/10, Batch 70/97, Loss: 0.2180
Epoch 6/10, Batch 80/97, Loss: 0.3118
Epoch 6/10, Batch 90/97, Loss: 0.3215
Epoch 6/10, Train Loss: 0.2492, Valid Loss: 0.2650
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2276
Epoch 7/10, Batch 20/97, Loss: 0.4405
Epoch 7/10, Batch 30/97, Loss: 0.2620
Epoch 7/10, Batch 40/97, Loss: 0.1937
Epoch 7/10, Batch 50/97, Loss: 0.2848
Epoch 7/10, Batch 60/97, Loss: 0.0942
Epoch 7/10, Batch 70/97, Loss: 0.1565
Epoch 7/10, Batch 80/97, Loss: 0.2347
Epoch 7/10, Batch 90/97, Loss: 0.2200
Epoch 7/10, Train Loss: 0.2371, Valid Loss: 0.2648
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1385
Epoch 8/10, Batch 20/97, Loss: 0.1963
Epoch 8/10, Batch 30/97, Loss: 0.1748
Epoch 8/10, Batch 40/97, Loss: 0.1714
Epoch 8/10, Batch 50/97, Loss: 0.3203
Epoch 8/10, Batch 60/97, Loss: 0.2179
Epoch 8/10, Batch 70/97, Loss: 0.3665
Epoch 8/10, Batch 80/97, Loss: 0.2283
Epoch 8/10, Batch 90/97, Loss: 0.1690
Epoch 8/10, Train Loss: 0.2233, Valid Loss: 0.2629
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0911
Epoch 9/10, Batch 20/97, Loss: 0.2844
Epoch 9/10, Batch 30/97, Loss: 0.2136
Epoch 9/10, Batch 40/97, Loss: 0.1607
Epoch 9/10, Batch 50/97, Loss: 0.1371
Epoch 9/10, Batch 60/97, Loss: 0.2817
Epoch 9/10, Batch 70/97, Loss: 0.1220
Epoch 9/10, Batch 80/97, Loss: 0.1081
Epoch 9/10, Batch 90/97, Loss: 0.1361
Epoch 9/10, Train Loss: 0.2044, Valid Loss: 0.2537
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2051
Epoch 10/10, Batch 20/97, Loss: 0.1581
Epoch 10/10, Batch 30/97, Loss: 0.3083
Epoch 10/10, Batch 40/97, Loss: 0.1201
Epoch 10/10, Batch 50/97, Loss: 0.2320
Epoch 10/10, Batch 60/97, Loss: 0.1306
Epoch 10/10, Batch 70/97, Loss: 0.2017
Epoch 10/10, Batch 80/97, Loss: 0.1988
Epoch 10/10, Batch 90/97, Loss: 0.2116
Epoch 10/10, Train Loss: 0.2090, Valid Loss: 0.2522
Model saved!
Accuracy: 0.9124
Precision: 0.9103
Recall: 0.9124
F1-score: 0.9089
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2266
Epoch 1/10, Batch 20/97, Loss: 1.0387
Epoch 1/10, Batch 30/97, Loss: 0.7829
Epoch 1/10, Batch 40/97, Loss: 0.6487
Epoch 1/10, Batch 50/97, Loss: 0.6294
Epoch 1/10, Batch 60/97, Loss: 0.6159
Epoch 1/10, Batch 70/97, Loss: 0.7503
Epoch 1/10, Batch 80/97, Loss: 0.6219
Epoch 1/10, Batch 90/97, Loss: 0.6060
Epoch 1/10, Train Loss: 0.7974, Valid Loss: 0.4587
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6312
Epoch 2/10, Batch 20/97, Loss: 0.3704
Epoch 2/10, Batch 30/97, Loss: 0.3641
Epoch 2/10, Batch 40/97, Loss: 0.4782
Epoch 2/10, Batch 50/97, Loss: 0.3540
Epoch 2/10, Batch 60/97, Loss: 0.3487
Epoch 2/10, Batch 70/97, Loss: 0.3468
Epoch 2/10, Batch 80/97, Loss: 0.4096
Epoch 2/10, Batch 90/97, Loss: 0.4108
Epoch 2/10, Train Loss: 0.4136, Valid Loss: 0.3482
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4104
Epoch 3/10, Batch 20/97, Loss: 0.4166
Epoch 3/10, Batch 30/97, Loss: 0.4784
Epoch 3/10, Batch 40/97, Loss: 0.2825
Epoch 3/10, Batch 50/97, Loss: 0.4673
Epoch 3/10, Batch 60/97, Loss: 0.1809
Epoch 3/10, Batch 70/97, Loss: 0.4744
Epoch 3/10, Batch 80/97, Loss: 0.3773
Epoch 3/10, Batch 90/97, Loss: 0.3225
Epoch 3/10, Train Loss: 0.3413, Valid Loss: 0.3067
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3248
Epoch 4/10, Batch 20/97, Loss: 0.2311
Epoch 4/10, Batch 30/97, Loss: 0.3790
Epoch 4/10, Batch 40/97, Loss: 0.3021
Epoch 4/10, Batch 50/97, Loss: 0.3402
Epoch 4/10, Batch 60/97, Loss: 0.1742
Epoch 4/10, Batch 70/97, Loss: 0.3217
Epoch 4/10, Batch 80/97, Loss: 0.1783
Epoch 4/10, Batch 90/97, Loss: 0.1426
Epoch 4/10, Train Loss: 0.2925, Valid Loss: 0.2852
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2807
Epoch 5/10, Batch 20/97, Loss: 0.3524
Epoch 5/10, Batch 30/97, Loss: 0.2778
Epoch 5/10, Batch 40/97, Loss: 0.1830
Epoch 5/10, Batch 50/97, Loss: 0.3090
Epoch 5/10, Batch 60/97, Loss: 0.3308
Epoch 5/10, Batch 70/97, Loss: 0.2423
Epoch 5/10, Batch 80/97, Loss: 0.3049
Epoch 5/10, Batch 90/97, Loss: 0.2390
Epoch 5/10, Train Loss: 0.2736, Valid Loss: 0.2743
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2657
Epoch 6/10, Batch 20/97, Loss: 0.4041
Epoch 6/10, Batch 30/97, Loss: 0.1676
Epoch 6/10, Batch 40/97, Loss: 0.2555
Epoch 6/10, Batch 50/97, Loss: 0.1938
Epoch 6/10, Batch 60/97, Loss: 0.3304
Epoch 6/10, Batch 70/97, Loss: 0.1541
Epoch 6/10, Batch 80/97, Loss: 0.3383
Epoch 6/10, Batch 90/97, Loss: 0.3522
Epoch 6/10, Train Loss: 0.2613, Valid Loss: 0.2543
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2263
Epoch 7/10, Batch 20/97, Loss: 0.2699
Epoch 7/10, Batch 30/97, Loss: 0.1983
Epoch 7/10, Batch 40/97, Loss: 0.1455
Epoch 7/10, Batch 50/97, Loss: 0.2435
Epoch 7/10, Batch 60/97, Loss: 0.1152
Epoch 7/10, Batch 70/97, Loss: 0.3606
Epoch 7/10, Batch 80/97, Loss: 0.1640
Epoch 7/10, Batch 90/97, Loss: 0.1843
Epoch 7/10, Train Loss: 0.2303, Valid Loss: 0.2518
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1354
Epoch 8/10, Batch 20/97, Loss: 0.1541
Epoch 8/10, Batch 30/97, Loss: 0.3560
Epoch 8/10, Batch 40/97, Loss: 0.1676
Epoch 8/10, Batch 50/97, Loss: 0.2039
Epoch 8/10, Batch 60/97, Loss: 0.2386
Epoch 8/10, Batch 70/97, Loss: 0.2266
Epoch 8/10, Batch 80/97, Loss: 0.2218
Epoch 8/10, Batch 90/97, Loss: 0.1693
Epoch 8/10, Train Loss: 0.2250, Valid Loss: 0.2529
Epoch 9/10, Batch 10/97, Loss: 0.1217
Epoch 9/10, Batch 20/97, Loss: 0.1639
Epoch 9/10, Batch 30/97, Loss: 0.2519
Epoch 9/10, Batch 40/97, Loss: 0.1718
Epoch 9/10, Batch 50/97, Loss: 0.1558
Epoch 9/10, Batch 60/97, Loss: 0.1740
Epoch 9/10, Batch 70/97, Loss: 0.2027
Epoch 9/10, Batch 80/97, Loss: 0.1718
Epoch 9/10, Batch 90/97, Loss: 0.1836
Epoch 9/10, Train Loss: 0.2143, Valid Loss: 0.2489
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1805
Epoch 10/10, Batch 20/97, Loss: 0.2174
Epoch 10/10, Batch 30/97, Loss: 0.1472
Epoch 10/10, Batch 40/97, Loss: 0.1637
Epoch 10/10, Batch 50/97, Loss: 0.2429
Epoch 10/10, Batch 60/97, Loss: 0.2060
Epoch 10/10, Batch 70/97, Loss: 0.2101
Epoch 10/10, Batch 80/97, Loss: 0.1767
Epoch 10/10, Batch 90/97, Loss: 0.2250
Epoch 10/10, Train Loss: 0.2029, Valid Loss: 0.2433
Model saved!
Accuracy: 0.9124
Precision: 0.9084
Recall: 0.9124
F1-score: 0.9091
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2068
Epoch 1/10, Batch 20/97, Loss: 1.1927
Epoch 1/10, Batch 30/97, Loss: 0.6867
Epoch 1/10, Batch 40/97, Loss: 0.7352
Epoch 1/10, Batch 50/97, Loss: 0.6856
Epoch 1/10, Batch 60/97, Loss: 0.7190
Epoch 1/10, Batch 70/97, Loss: 0.7435
Epoch 1/10, Batch 80/97, Loss: 0.6789
Epoch 1/10, Batch 90/97, Loss: 0.5568
Epoch 1/10, Train Loss: 0.7947, Valid Loss: 0.4604
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5988
Epoch 2/10, Batch 20/97, Loss: 0.3639
Epoch 2/10, Batch 30/97, Loss: 0.3829
Epoch 2/10, Batch 40/97, Loss: 0.3320
Epoch 2/10, Batch 50/97, Loss: 0.3687
Epoch 2/10, Batch 60/97, Loss: 0.3027
Epoch 2/10, Batch 70/97, Loss: 0.3542
Epoch 2/10, Batch 80/97, Loss: 0.4349
Epoch 2/10, Batch 90/97, Loss: 0.6015
Epoch 2/10, Train Loss: 0.4025, Valid Loss: 0.3513
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3596
Epoch 3/10, Batch 20/97, Loss: 0.2178
Epoch 3/10, Batch 30/97, Loss: 0.1788
Epoch 3/10, Batch 40/97, Loss: 0.2767
Epoch 3/10, Batch 50/97, Loss: 0.3290
Epoch 3/10, Batch 60/97, Loss: 0.2931
Epoch 3/10, Batch 70/97, Loss: 0.3294
Epoch 3/10, Batch 80/97, Loss: 0.2445
Epoch 3/10, Batch 90/97, Loss: 0.2970
Epoch 3/10, Train Loss: 0.3127, Valid Loss: 0.3173
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3784
Epoch 4/10, Batch 20/97, Loss: 0.2537
Epoch 4/10, Batch 30/97, Loss: 0.1958
Epoch 4/10, Batch 40/97, Loss: 0.2240
Epoch 4/10, Batch 50/97, Loss: 0.3194
Epoch 4/10, Batch 60/97, Loss: 0.3140
Epoch 4/10, Batch 70/97, Loss: 0.3643
Epoch 4/10, Batch 80/97, Loss: 0.2155
Epoch 4/10, Batch 90/97, Loss: 0.2512
Epoch 4/10, Train Loss: 0.2732, Valid Loss: 0.3057
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1525
Epoch 5/10, Batch 20/97, Loss: 0.3059
Epoch 5/10, Batch 30/97, Loss: 0.2526
Epoch 5/10, Batch 40/97, Loss: 0.2395
Epoch 5/10, Batch 50/97, Loss: 0.2614
Epoch 5/10, Batch 60/97, Loss: 0.2635
Epoch 5/10, Batch 70/97, Loss: 0.2801
Epoch 5/10, Batch 80/97, Loss: 0.2237
Epoch 5/10, Batch 90/97, Loss: 0.3254
Epoch 5/10, Train Loss: 0.2556, Valid Loss: 0.2906
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1627
Epoch 6/10, Batch 20/97, Loss: 0.2034
Epoch 6/10, Batch 30/97, Loss: 0.1545
Epoch 6/10, Batch 40/97, Loss: 0.2576
Epoch 6/10, Batch 50/97, Loss: 0.2107
Epoch 6/10, Batch 60/97, Loss: 0.3133
Epoch 6/10, Batch 70/97, Loss: 0.1756
Epoch 6/10, Batch 80/97, Loss: 0.2835
Epoch 6/10, Batch 90/97, Loss: 0.4860
Epoch 6/10, Train Loss: 0.2384, Valid Loss: 0.2825
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1441
Epoch 7/10, Batch 20/97, Loss: 0.4217
Epoch 7/10, Batch 30/97, Loss: 0.1933
Epoch 7/10, Batch 40/97, Loss: 0.1555
Epoch 7/10, Batch 50/97, Loss: 0.1564
Epoch 7/10, Batch 60/97, Loss: 0.2417
Epoch 7/10, Batch 70/97, Loss: 0.2692
Epoch 7/10, Batch 80/97, Loss: 0.2437
Epoch 7/10, Batch 90/97, Loss: 0.2213
Epoch 7/10, Train Loss: 0.2122, Valid Loss: 0.2792
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2436
Epoch 8/10, Batch 20/97, Loss: 0.2033
Epoch 8/10, Batch 30/97, Loss: 0.2556
Epoch 8/10, Batch 40/97, Loss: 0.2173
Epoch 8/10, Batch 50/97, Loss: 0.2358
Epoch 8/10, Batch 60/97, Loss: 0.1395
Epoch 8/10, Batch 70/97, Loss: 0.2697
Epoch 8/10, Batch 80/97, Loss: 0.1156
Epoch 8/10, Batch 90/97, Loss: 0.1672
Epoch 8/10, Train Loss: 0.2076, Valid Loss: 0.2747
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0799
Epoch 9/10, Batch 20/97, Loss: 0.2527
Epoch 9/10, Batch 30/97, Loss: 0.1662
Epoch 9/10, Batch 40/97, Loss: 0.3668
Epoch 9/10, Batch 50/97, Loss: 0.1479
Epoch 9/10, Batch 60/97, Loss: 0.3084
Epoch 9/10, Batch 70/97, Loss: 0.1940
Epoch 9/10, Batch 80/97, Loss: 0.1956
Epoch 9/10, Batch 90/97, Loss: 0.1549
Epoch 9/10, Train Loss: 0.1930, Valid Loss: 0.2728
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1046
Epoch 10/10, Batch 20/97, Loss: 0.1447
Epoch 10/10, Batch 30/97, Loss: 0.1887
Epoch 10/10, Batch 40/97, Loss: 0.1761
Epoch 10/10, Batch 50/97, Loss: 0.1745
Epoch 10/10, Batch 60/97, Loss: 0.0639
Epoch 10/10, Batch 70/97, Loss: 0.3622
Epoch 10/10, Batch 80/97, Loss: 0.1904
Epoch 10/10, Batch 90/97, Loss: 0.2004
Epoch 10/10, Train Loss: 0.1916, Valid Loss: 0.2643
Model saved!
Accuracy: 0.9124
Precision: 0.9091
Recall: 0.9124
F1-score: 0.9086
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2452
Epoch 1/10, Batch 20/97, Loss: 1.0385
Epoch 1/10, Batch 30/97, Loss: 0.7394
Epoch 1/10, Batch 40/97, Loss: 0.7169
Epoch 1/10, Batch 50/97, Loss: 0.6980
Epoch 1/10, Batch 60/97, Loss: 0.8736
Epoch 1/10, Batch 70/97, Loss: 0.4965
Epoch 1/10, Batch 80/97, Loss: 0.6487
Epoch 1/10, Batch 90/97, Loss: 0.5823
Epoch 1/10, Train Loss: 0.8088, Valid Loss: 0.4469
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.7114
Epoch 2/10, Batch 20/97, Loss: 0.4187
Epoch 2/10, Batch 30/97, Loss: 0.2530
Epoch 2/10, Batch 40/97, Loss: 0.3930
Epoch 2/10, Batch 50/97, Loss: 0.4522
Epoch 2/10, Batch 60/97, Loss: 0.3396
Epoch 2/10, Batch 70/97, Loss: 0.3713
Epoch 2/10, Batch 80/97, Loss: 0.3830
Epoch 2/10, Batch 90/97, Loss: 0.4456
Epoch 2/10, Train Loss: 0.4135, Valid Loss: 0.3361
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2851
Epoch 3/10, Batch 20/97, Loss: 0.3035
Epoch 3/10, Batch 30/97, Loss: 0.3657
Epoch 3/10, Batch 40/97, Loss: 0.2037
Epoch 3/10, Batch 50/97, Loss: 0.4269
Epoch 3/10, Batch 60/97, Loss: 0.3571
Epoch 3/10, Batch 70/97, Loss: 0.3115
Epoch 3/10, Batch 80/97, Loss: 0.4886
Epoch 3/10, Batch 90/97, Loss: 0.2502
Epoch 3/10, Train Loss: 0.3255, Valid Loss: 0.2945
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4473
Epoch 4/10, Batch 20/97, Loss: 0.2208
Epoch 4/10, Batch 30/97, Loss: 0.3292
Epoch 4/10, Batch 40/97, Loss: 0.3084
Epoch 4/10, Batch 50/97, Loss: 0.3754
Epoch 4/10, Batch 60/97, Loss: 0.1823
Epoch 4/10, Batch 70/97, Loss: 0.2346
Epoch 4/10, Batch 80/97, Loss: 0.2248
Epoch 4/10, Batch 90/97, Loss: 0.2689
Epoch 4/10, Train Loss: 0.2872, Valid Loss: 0.2741
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2829
Epoch 5/10, Batch 20/97, Loss: 0.3093
Epoch 5/10, Batch 30/97, Loss: 0.1501
Epoch 5/10, Batch 40/97, Loss: 0.1778
Epoch 5/10, Batch 50/97, Loss: 0.2660
Epoch 5/10, Batch 60/97, Loss: 0.3216
Epoch 5/10, Batch 70/97, Loss: 0.1621
Epoch 5/10, Batch 80/97, Loss: 0.2757
Epoch 5/10, Batch 90/97, Loss: 0.1448
Epoch 5/10, Train Loss: 0.2642, Valid Loss: 0.2656
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.4139
Epoch 6/10, Batch 20/97, Loss: 0.3159
Epoch 6/10, Batch 30/97, Loss: 0.1641
Epoch 6/10, Batch 40/97, Loss: 0.2025
Epoch 6/10, Batch 50/97, Loss: 0.1931
Epoch 6/10, Batch 60/97, Loss: 0.3135
Epoch 6/10, Batch 70/97, Loss: 0.3270
Epoch 6/10, Batch 80/97, Loss: 0.4200
Epoch 6/10, Batch 90/97, Loss: 0.3254
Epoch 6/10, Train Loss: 0.2430, Valid Loss: 0.2583
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1963
Epoch 7/10, Batch 20/97, Loss: 0.2379
Epoch 7/10, Batch 30/97, Loss: 0.1404
Epoch 7/10, Batch 40/97, Loss: 0.0957
Epoch 7/10, Batch 50/97, Loss: 0.2549
Epoch 7/10, Batch 60/97, Loss: 0.2187
Epoch 7/10, Batch 70/97, Loss: 0.3045
Epoch 7/10, Batch 80/97, Loss: 0.3667
Epoch 7/10, Batch 90/97, Loss: 0.1913
Epoch 7/10, Train Loss: 0.2292, Valid Loss: 0.2499
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2576
Epoch 8/10, Batch 20/97, Loss: 0.1451
Epoch 8/10, Batch 30/97, Loss: 0.2820
Epoch 8/10, Batch 40/97, Loss: 0.1313
Epoch 8/10, Batch 50/97, Loss: 0.2235
Epoch 8/10, Batch 60/97, Loss: 0.3284
Epoch 8/10, Batch 70/97, Loss: 0.1929
Epoch 8/10, Batch 80/97, Loss: 0.1963
Epoch 8/10, Batch 90/97, Loss: 0.2153
Epoch 8/10, Train Loss: 0.2119, Valid Loss: 0.2590
Epoch 9/10, Batch 10/97, Loss: 0.3320
Epoch 9/10, Batch 20/97, Loss: 0.1153
Epoch 9/10, Batch 30/97, Loss: 0.1840
Epoch 9/10, Batch 40/97, Loss: 0.3691
Epoch 9/10, Batch 50/97, Loss: 0.1231
Epoch 9/10, Batch 60/97, Loss: 0.2969
Epoch 9/10, Batch 70/97, Loss: 0.2229
Epoch 9/10, Batch 80/97, Loss: 0.1669
Epoch 9/10, Batch 90/97, Loss: 0.0906
Epoch 9/10, Train Loss: 0.2106, Valid Loss: 0.2367
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1850
Epoch 10/10, Batch 20/97, Loss: 0.1467
Epoch 10/10, Batch 30/97, Loss: 0.3626
Epoch 10/10, Batch 40/97, Loss: 0.1617
Epoch 10/10, Batch 50/97, Loss: 0.1583
Epoch 10/10, Batch 60/97, Loss: 0.1892
Epoch 10/10, Batch 70/97, Loss: 0.2763
Epoch 10/10, Batch 80/97, Loss: 0.2811
Epoch 10/10, Batch 90/97, Loss: 0.2761
Epoch 10/10, Train Loss: 0.2039, Valid Loss: 0.2429
Accuracy: 0.9136
Precision: 0.9107
Recall: 0.9136
F1-score: 0.9114
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2699
Epoch 1/10, Batch 20/97, Loss: 1.1046
Epoch 1/10, Batch 30/97, Loss: 0.8124
Epoch 1/10, Batch 40/97, Loss: 0.6862
Epoch 1/10, Batch 50/97, Loss: 0.6710
Epoch 1/10, Batch 60/97, Loss: 0.6625
Epoch 1/10, Batch 70/97, Loss: 0.5868
Epoch 1/10, Batch 80/97, Loss: 0.6261
Epoch 1/10, Batch 90/97, Loss: 0.5405
Epoch 1/10, Train Loss: 0.7942, Valid Loss: 0.4380
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4890
Epoch 2/10, Batch 20/97, Loss: 0.3577
Epoch 2/10, Batch 30/97, Loss: 0.3286
Epoch 2/10, Batch 40/97, Loss: 0.4183
Epoch 2/10, Batch 50/97, Loss: 0.4228
Epoch 2/10, Batch 60/97, Loss: 0.3842
Epoch 2/10, Batch 70/97, Loss: 0.4218
Epoch 2/10, Batch 80/97, Loss: 0.4311
Epoch 2/10, Batch 90/97, Loss: 0.4162
Epoch 2/10, Train Loss: 0.4160, Valid Loss: 0.3257
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4206
Epoch 3/10, Batch 20/97, Loss: 0.2544
Epoch 3/10, Batch 30/97, Loss: 0.3735
Epoch 3/10, Batch 40/97, Loss: 0.2067
Epoch 3/10, Batch 50/97, Loss: 0.4113
Epoch 3/10, Batch 60/97, Loss: 0.3432
Epoch 3/10, Batch 70/97, Loss: 0.3095
Epoch 3/10, Batch 80/97, Loss: 0.3636
Epoch 3/10, Batch 90/97, Loss: 0.3937
Epoch 3/10, Train Loss: 0.3306, Valid Loss: 0.2730
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4778
Epoch 4/10, Batch 20/97, Loss: 0.2696
Epoch 4/10, Batch 30/97, Loss: 0.2993
Epoch 4/10, Batch 40/97, Loss: 0.1486
Epoch 4/10, Batch 50/97, Loss: 0.3313
Epoch 4/10, Batch 60/97, Loss: 0.2029
Epoch 4/10, Batch 70/97, Loss: 0.2530
Epoch 4/10, Batch 80/97, Loss: 0.2333
Epoch 4/10, Batch 90/97, Loss: 0.2219
Epoch 4/10, Train Loss: 0.2846, Valid Loss: 0.2551
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2182
Epoch 5/10, Batch 20/97, Loss: 0.2357
Epoch 5/10, Batch 30/97, Loss: 0.2592
Epoch 5/10, Batch 40/97, Loss: 0.3374
Epoch 5/10, Batch 50/97, Loss: 0.2279
Epoch 5/10, Batch 60/97, Loss: 0.2774
Epoch 5/10, Batch 70/97, Loss: 0.3071
Epoch 5/10, Batch 80/97, Loss: 0.2479
Epoch 5/10, Batch 90/97, Loss: 0.2220
Epoch 5/10, Train Loss: 0.2648, Valid Loss: 0.2346
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1814
Epoch 6/10, Batch 20/97, Loss: 0.3604
Epoch 6/10, Batch 30/97, Loss: 0.2177
Epoch 6/10, Batch 40/97, Loss: 0.1544
Epoch 6/10, Batch 50/97, Loss: 0.1178
Epoch 6/10, Batch 60/97, Loss: 0.2005
Epoch 6/10, Batch 70/97, Loss: 0.2143
Epoch 6/10, Batch 80/97, Loss: 0.5640
Epoch 6/10, Batch 90/97, Loss: 0.2260
Epoch 6/10, Train Loss: 0.2539, Valid Loss: 0.2252
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2023
Epoch 7/10, Batch 20/97, Loss: 0.4185
Epoch 7/10, Batch 30/97, Loss: 0.1998
Epoch 7/10, Batch 40/97, Loss: 0.2012
Epoch 7/10, Batch 50/97, Loss: 0.1957
Epoch 7/10, Batch 60/97, Loss: 0.1165
Epoch 7/10, Batch 70/97, Loss: 0.2676
Epoch 7/10, Batch 80/97, Loss: 0.2961
Epoch 7/10, Batch 90/97, Loss: 0.2238
Epoch 7/10, Train Loss: 0.2316, Valid Loss: 0.2182
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1793
Epoch 8/10, Batch 20/97, Loss: 0.2444
Epoch 8/10, Batch 30/97, Loss: 0.1717
Epoch 8/10, Batch 40/97, Loss: 0.2313
Epoch 8/10, Batch 50/97, Loss: 0.3114
Epoch 8/10, Batch 60/97, Loss: 0.2769
Epoch 8/10, Batch 70/97, Loss: 0.2578
Epoch 8/10, Batch 80/97, Loss: 0.2589
Epoch 8/10, Batch 90/97, Loss: 0.3524
Epoch 8/10, Train Loss: 0.2189, Valid Loss: 0.2072
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2922
Epoch 9/10, Batch 20/97, Loss: 0.1036
Epoch 9/10, Batch 30/97, Loss: 0.2840
Epoch 9/10, Batch 40/97, Loss: 0.3284
Epoch 9/10, Batch 50/97, Loss: 0.2368
Epoch 9/10, Batch 60/97, Loss: 0.2027
Epoch 9/10, Batch 70/97, Loss: 0.1200
Epoch 9/10, Batch 80/97, Loss: 0.1248
Epoch 9/10, Batch 90/97, Loss: 0.2499
Epoch 9/10, Train Loss: 0.2015, Valid Loss: 0.2033
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2291
Epoch 10/10, Batch 20/97, Loss: 0.1111
Epoch 10/10, Batch 30/97, Loss: 0.1972
Epoch 10/10, Batch 40/97, Loss: 0.1744
Epoch 10/10, Batch 50/97, Loss: 0.3233
Epoch 10/10, Batch 60/97, Loss: 0.1939
Epoch 10/10, Batch 70/97, Loss: 0.1125
Epoch 10/10, Batch 80/97, Loss: 0.1428
Epoch 10/10, Batch 90/97, Loss: 0.2031
Epoch 10/10, Train Loss: 0.2135, Valid Loss: 0.2022
Model saved!
Accuracy: 0.9065
Precision: 0.9027
Recall: 0.9065
F1-score: 0.9034
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2171
Epoch 1/10, Batch 20/97, Loss: 1.0033
Epoch 1/10, Batch 30/97, Loss: 0.7905
Epoch 1/10, Batch 40/97, Loss: 0.6436
Epoch 1/10, Batch 50/97, Loss: 0.6959
Epoch 1/10, Batch 60/97, Loss: 0.7365
Epoch 1/10, Batch 70/97, Loss: 0.6663
Epoch 1/10, Batch 80/97, Loss: 0.6294
Epoch 1/10, Batch 90/97, Loss: 0.5217
Epoch 1/10, Train Loss: 0.8027, Valid Loss: 0.4454
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5390
Epoch 2/10, Batch 20/97, Loss: 0.5723
Epoch 2/10, Batch 30/97, Loss: 0.3624
Epoch 2/10, Batch 40/97, Loss: 0.3579
Epoch 2/10, Batch 50/97, Loss: 0.4905
Epoch 2/10, Batch 60/97, Loss: 0.4225
Epoch 2/10, Batch 70/97, Loss: 0.3260
Epoch 2/10, Batch 80/97, Loss: 0.5628
Epoch 2/10, Batch 90/97, Loss: 0.4512
Epoch 2/10, Train Loss: 0.4154, Valid Loss: 0.3361
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4251
Epoch 3/10, Batch 20/97, Loss: 0.3196
Epoch 3/10, Batch 30/97, Loss: 0.4639
Epoch 3/10, Batch 40/97, Loss: 0.2313
Epoch 3/10, Batch 50/97, Loss: 0.4355
Epoch 3/10, Batch 60/97, Loss: 0.2524
Epoch 3/10, Batch 70/97, Loss: 0.4650
Epoch 3/10, Batch 80/97, Loss: 0.2861
Epoch 3/10, Batch 90/97, Loss: 0.2614
Epoch 3/10, Train Loss: 0.3391, Valid Loss: 0.3052
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2442
Epoch 4/10, Batch 20/97, Loss: 0.1814
Epoch 4/10, Batch 30/97, Loss: 0.4095
Epoch 4/10, Batch 40/97, Loss: 0.2773
Epoch 4/10, Batch 50/97, Loss: 0.3802
Epoch 4/10, Batch 60/97, Loss: 0.2654
Epoch 4/10, Batch 70/97, Loss: 0.3144
Epoch 4/10, Batch 80/97, Loss: 0.1998
Epoch 4/10, Batch 90/97, Loss: 0.3740
Epoch 4/10, Train Loss: 0.2913, Valid Loss: 0.2837
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2237
Epoch 5/10, Batch 20/97, Loss: 0.3224
Epoch 5/10, Batch 30/97, Loss: 0.2131
Epoch 5/10, Batch 40/97, Loss: 0.2705
Epoch 5/10, Batch 50/97, Loss: 0.1437
Epoch 5/10, Batch 60/97, Loss: 0.2171
Epoch 5/10, Batch 70/97, Loss: 0.1818
Epoch 5/10, Batch 80/97, Loss: 0.2809
Epoch 5/10, Batch 90/97, Loss: 0.1384
Epoch 5/10, Train Loss: 0.2604, Valid Loss: 0.2679
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2462
Epoch 6/10, Batch 20/97, Loss: 0.3003
Epoch 6/10, Batch 30/97, Loss: 0.1210
Epoch 6/10, Batch 40/97, Loss: 0.1451
Epoch 6/10, Batch 50/97, Loss: 0.2214
Epoch 6/10, Batch 60/97, Loss: 0.2891
Epoch 6/10, Batch 70/97, Loss: 0.2113
Epoch 6/10, Batch 80/97, Loss: 0.3329
Epoch 6/10, Batch 90/97, Loss: 0.4026
Epoch 6/10, Train Loss: 0.2452, Valid Loss: 0.2538
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1529
Epoch 7/10, Batch 20/97, Loss: 0.1939
Epoch 7/10, Batch 30/97, Loss: 0.1406
Epoch 7/10, Batch 40/97, Loss: 0.0649
Epoch 7/10, Batch 50/97, Loss: 0.2114
Epoch 7/10, Batch 60/97, Loss: 0.1655
Epoch 7/10, Batch 70/97, Loss: 0.1479
Epoch 7/10, Batch 80/97, Loss: 0.2107
Epoch 7/10, Batch 90/97, Loss: 0.2141
Epoch 7/10, Train Loss: 0.2201, Valid Loss: 0.2446
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.0943
Epoch 8/10, Batch 20/97, Loss: 0.1623
Epoch 8/10, Batch 30/97, Loss: 0.2822
Epoch 8/10, Batch 40/97, Loss: 0.2778
Epoch 8/10, Batch 50/97, Loss: 0.2030
Epoch 8/10, Batch 60/97, Loss: 0.1975
Epoch 8/10, Batch 70/97, Loss: 0.2445
Epoch 8/10, Batch 80/97, Loss: 0.1153
Epoch 8/10, Batch 90/97, Loss: 0.1542
Epoch 8/10, Train Loss: 0.2247, Valid Loss: 0.2422
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1266
Epoch 9/10, Batch 20/97, Loss: 0.2012
Epoch 9/10, Batch 30/97, Loss: 0.2984
Epoch 9/10, Batch 40/97, Loss: 0.1649
Epoch 9/10, Batch 50/97, Loss: 0.1896
Epoch 9/10, Batch 60/97, Loss: 0.1550
Epoch 9/10, Batch 70/97, Loss: 0.1632
Epoch 9/10, Batch 80/97, Loss: 0.1147
Epoch 9/10, Batch 90/97, Loss: 0.2706
Epoch 9/10, Train Loss: 0.2078, Valid Loss: 0.2410
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2440
Epoch 10/10, Batch 20/97, Loss: 0.0948
Epoch 10/10, Batch 30/97, Loss: 0.1881
Epoch 10/10, Batch 40/97, Loss: 0.1609
Epoch 10/10, Batch 50/97, Loss: 0.1678
Epoch 10/10, Batch 60/97, Loss: 0.1458
Epoch 10/10, Batch 70/97, Loss: 0.3000
Epoch 10/10, Batch 80/97, Loss: 0.1420
Epoch 10/10, Batch 90/97, Loss: 0.1307
Epoch 10/10, Train Loss: 0.2004, Valid Loss: 0.2410
Accuracy: 0.9112
Precision: 0.9085
Recall: 0.9112
F1-score: 0.9086
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2408
Epoch 1/10, Batch 20/97, Loss: 1.0634
Epoch 1/10, Batch 30/97, Loss: 0.7499
Epoch 1/10, Batch 40/97, Loss: 0.6570
Epoch 1/10, Batch 50/97, Loss: 0.6237
Epoch 1/10, Batch 60/97, Loss: 0.7261
Epoch 1/10, Batch 70/97, Loss: 0.7528
Epoch 1/10, Batch 80/97, Loss: 0.5754
Epoch 1/10, Batch 90/97, Loss: 0.6241
Epoch 1/10, Train Loss: 0.8159, Valid Loss: 0.4595
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5676
Epoch 2/10, Batch 20/97, Loss: 0.5306
Epoch 2/10, Batch 30/97, Loss: 0.2629
Epoch 2/10, Batch 40/97, Loss: 0.3938
Epoch 2/10, Batch 50/97, Loss: 0.4506
Epoch 2/10, Batch 60/97, Loss: 0.5772
Epoch 2/10, Batch 70/97, Loss: 0.3682
Epoch 2/10, Batch 80/97, Loss: 0.4077
Epoch 2/10, Batch 90/97, Loss: 0.4726
Epoch 2/10, Train Loss: 0.4118, Valid Loss: 0.3574
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3868
Epoch 3/10, Batch 20/97, Loss: 0.2339
Epoch 3/10, Batch 30/97, Loss: 0.2868
Epoch 3/10, Batch 40/97, Loss: 0.1992
Epoch 3/10, Batch 50/97, Loss: 0.4525
Epoch 3/10, Batch 60/97, Loss: 0.2184
Epoch 3/10, Batch 70/97, Loss: 0.2922
Epoch 3/10, Batch 80/97, Loss: 0.2608
Epoch 3/10, Batch 90/97, Loss: 0.3519
Epoch 3/10, Train Loss: 0.3373, Valid Loss: 0.3144
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1850
Epoch 4/10, Batch 20/97, Loss: 0.3515
Epoch 4/10, Batch 30/97, Loss: 0.2976
Epoch 4/10, Batch 40/97, Loss: 0.2630
Epoch 4/10, Batch 50/97, Loss: 0.4695
Epoch 4/10, Batch 60/97, Loss: 0.2647
Epoch 4/10, Batch 70/97, Loss: 0.2293
Epoch 4/10, Batch 80/97, Loss: 0.4494
Epoch 4/10, Batch 90/97, Loss: 0.2897
Epoch 4/10, Train Loss: 0.2775, Valid Loss: 0.2943
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2708
Epoch 5/10, Batch 20/97, Loss: 0.4457
Epoch 5/10, Batch 30/97, Loss: 0.2092
Epoch 5/10, Batch 40/97, Loss: 0.2198
Epoch 5/10, Batch 50/97, Loss: 0.2487
Epoch 5/10, Batch 60/97, Loss: 0.2955
Epoch 5/10, Batch 70/97, Loss: 0.3212
Epoch 5/10, Batch 80/97, Loss: 0.1380
Epoch 5/10, Batch 90/97, Loss: 0.2686
Epoch 5/10, Train Loss: 0.2619, Valid Loss: 0.2820
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2599
Epoch 6/10, Batch 20/97, Loss: 0.2081
Epoch 6/10, Batch 30/97, Loss: 0.2341
Epoch 6/10, Batch 40/97, Loss: 0.1667
Epoch 6/10, Batch 50/97, Loss: 0.2960
Epoch 6/10, Batch 60/97, Loss: 0.3006
Epoch 6/10, Batch 70/97, Loss: 0.1732
Epoch 6/10, Batch 80/97, Loss: 0.2184
Epoch 6/10, Batch 90/97, Loss: 0.3248
Epoch 6/10, Train Loss: 0.2396, Valid Loss: 0.2686
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2034
Epoch 7/10, Batch 20/97, Loss: 0.2700
Epoch 7/10, Batch 30/97, Loss: 0.2298
Epoch 7/10, Batch 40/97, Loss: 0.1068
Epoch 7/10, Batch 50/97, Loss: 0.2145
Epoch 7/10, Batch 60/97, Loss: 0.1322
Epoch 7/10, Batch 70/97, Loss: 0.1892
Epoch 7/10, Batch 80/97, Loss: 0.1151
Epoch 7/10, Batch 90/97, Loss: 0.1837
Epoch 7/10, Train Loss: 0.2268, Valid Loss: 0.2623
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.3149
Epoch 8/10, Batch 20/97, Loss: 0.3209
Epoch 8/10, Batch 30/97, Loss: 0.1264
Epoch 8/10, Batch 40/97, Loss: 0.2332
Epoch 8/10, Batch 50/97, Loss: 0.2660
Epoch 8/10, Batch 60/97, Loss: 0.2036
Epoch 8/10, Batch 70/97, Loss: 0.2802
Epoch 8/10, Batch 80/97, Loss: 0.1673
Epoch 8/10, Batch 90/97, Loss: 0.3077
Epoch 8/10, Train Loss: 0.2194, Valid Loss: 0.2592
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1447
Epoch 9/10, Batch 20/97, Loss: 0.3018
Epoch 9/10, Batch 30/97, Loss: 0.2895
Epoch 9/10, Batch 40/97, Loss: 0.2862
Epoch 9/10, Batch 50/97, Loss: 0.2545
Epoch 9/10, Batch 60/97, Loss: 0.1485
Epoch 9/10, Batch 70/97, Loss: 0.1816
Epoch 9/10, Batch 80/97, Loss: 0.1947
Epoch 9/10, Batch 90/97, Loss: 0.1890
Epoch 9/10, Train Loss: 0.2014, Valid Loss: 0.2494
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1638
Epoch 10/10, Batch 20/97, Loss: 0.2665
Epoch 10/10, Batch 30/97, Loss: 0.2079
Epoch 10/10, Batch 40/97, Loss: 0.1473
Epoch 10/10, Batch 50/97, Loss: 0.1000
Epoch 10/10, Batch 60/97, Loss: 0.1313
Epoch 10/10, Batch 70/97, Loss: 0.2850
Epoch 10/10, Batch 80/97, Loss: 0.2072
Epoch 10/10, Batch 90/97, Loss: 0.1984
Epoch 10/10, Train Loss: 0.1996, Valid Loss: 0.2488
Model saved!
Accuracy: 0.9206
Precision: 0.9179
Recall: 0.9206
F1-score: 0.9184
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2925
Epoch 1/10, Batch 20/97, Loss: 1.0553
Epoch 1/10, Batch 30/97, Loss: 0.6881
Epoch 1/10, Batch 40/97, Loss: 0.7175
Epoch 1/10, Batch 50/97, Loss: 0.5836
Epoch 1/10, Batch 60/97, Loss: 0.7033
Epoch 1/10, Batch 70/97, Loss: 0.5809
Epoch 1/10, Batch 80/97, Loss: 0.6177
Epoch 1/10, Batch 90/97, Loss: 0.6280
Epoch 1/10, Train Loss: 0.7995, Valid Loss: 0.4438
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4997
Epoch 2/10, Batch 20/97, Loss: 0.3652
Epoch 2/10, Batch 30/97, Loss: 0.3611
Epoch 2/10, Batch 40/97, Loss: 0.3816
Epoch 2/10, Batch 50/97, Loss: 0.4540
Epoch 2/10, Batch 60/97, Loss: 0.3508
Epoch 2/10, Batch 70/97, Loss: 0.3075
Epoch 2/10, Batch 80/97, Loss: 0.3401
Epoch 2/10, Batch 90/97, Loss: 0.3492
Epoch 2/10, Train Loss: 0.4001, Valid Loss: 0.3324
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3404
Epoch 3/10, Batch 20/97, Loss: 0.4540
Epoch 3/10, Batch 30/97, Loss: 0.4417
Epoch 3/10, Batch 40/97, Loss: 0.2468
Epoch 3/10, Batch 50/97, Loss: 0.2693
Epoch 3/10, Batch 60/97, Loss: 0.4095
Epoch 3/10, Batch 70/97, Loss: 0.2314
Epoch 3/10, Batch 80/97, Loss: 0.2095
Epoch 3/10, Batch 90/97, Loss: 0.2208
Epoch 3/10, Train Loss: 0.3339, Valid Loss: 0.2954
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3174
Epoch 4/10, Batch 20/97, Loss: 0.2379
Epoch 4/10, Batch 30/97, Loss: 0.2577
Epoch 4/10, Batch 40/97, Loss: 0.2808
Epoch 4/10, Batch 50/97, Loss: 0.3468
Epoch 4/10, Batch 60/97, Loss: 0.2229
Epoch 4/10, Batch 70/97, Loss: 0.2206
Epoch 4/10, Batch 80/97, Loss: 0.2389
Epoch 4/10, Batch 90/97, Loss: 0.2010
Epoch 4/10, Train Loss: 0.2809, Valid Loss: 0.2696
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2721
Epoch 5/10, Batch 20/97, Loss: 0.2631
Epoch 5/10, Batch 30/97, Loss: 0.2121
Epoch 5/10, Batch 40/97, Loss: 0.2227
Epoch 5/10, Batch 50/97, Loss: 0.2160
Epoch 5/10, Batch 60/97, Loss: 0.1637
Epoch 5/10, Batch 70/97, Loss: 0.3277
Epoch 5/10, Batch 80/97, Loss: 0.2769
Epoch 5/10, Batch 90/97, Loss: 0.2058
Epoch 5/10, Train Loss: 0.2665, Valid Loss: 0.2586
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.0945
Epoch 6/10, Batch 20/97, Loss: 0.3365
Epoch 6/10, Batch 30/97, Loss: 0.1874
Epoch 6/10, Batch 40/97, Loss: 0.1421
Epoch 6/10, Batch 50/97, Loss: 0.3736
Epoch 6/10, Batch 60/97, Loss: 0.3204
Epoch 6/10, Batch 70/97, Loss: 0.2860
Epoch 6/10, Batch 80/97, Loss: 0.3465
Epoch 6/10, Batch 90/97, Loss: 0.4446
Epoch 6/10, Train Loss: 0.2414, Valid Loss: 0.2410
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1327
Epoch 7/10, Batch 20/97, Loss: 0.3627
Epoch 7/10, Batch 30/97, Loss: 0.2116
Epoch 7/10, Batch 40/97, Loss: 0.1963
Epoch 7/10, Batch 50/97, Loss: 0.1322
Epoch 7/10, Batch 60/97, Loss: 0.1304
Epoch 7/10, Batch 70/97, Loss: 0.1116
Epoch 7/10, Batch 80/97, Loss: 0.2867
Epoch 7/10, Batch 90/97, Loss: 0.2105
Epoch 7/10, Train Loss: 0.2291, Valid Loss: 0.2449
Epoch 8/10, Batch 10/97, Loss: 0.1196
Epoch 8/10, Batch 20/97, Loss: 0.1705
Epoch 8/10, Batch 30/97, Loss: 0.3030
Epoch 8/10, Batch 40/97, Loss: 0.2360
Epoch 8/10, Batch 50/97, Loss: 0.1743
Epoch 8/10, Batch 60/97, Loss: 0.1506
Epoch 8/10, Batch 70/97, Loss: 0.1995
Epoch 8/10, Batch 80/97, Loss: 0.2883
Epoch 8/10, Batch 90/97, Loss: 0.2292
Epoch 8/10, Train Loss: 0.2187, Valid Loss: 0.2335
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1672
Epoch 9/10, Batch 20/97, Loss: 0.2089
Epoch 9/10, Batch 30/97, Loss: 0.2574
Epoch 9/10, Batch 40/97, Loss: 0.4515
Epoch 9/10, Batch 50/97, Loss: 0.2265
Epoch 9/10, Batch 60/97, Loss: 0.1326
Epoch 9/10, Batch 70/97, Loss: 0.1259
Epoch 9/10, Batch 80/97, Loss: 0.1310
Epoch 9/10, Batch 90/97, Loss: 0.3049
Epoch 9/10, Train Loss: 0.2047, Valid Loss: 0.2299
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1487
Epoch 10/10, Batch 20/97, Loss: 0.1825
Epoch 10/10, Batch 30/97, Loss: 0.2320
Epoch 10/10, Batch 40/97, Loss: 0.2073
Epoch 10/10, Batch 50/97, Loss: 0.2557
Epoch 10/10, Batch 60/97, Loss: 0.1326
Epoch 10/10, Batch 70/97, Loss: 0.1193
Epoch 10/10, Batch 80/97, Loss: 0.1854
Epoch 10/10, Batch 90/97, Loss: 0.1908
Epoch 10/10, Train Loss: 0.1966, Valid Loss: 0.2261
Model saved!
Accuracy: 0.9217
Precision: 0.9197
Recall: 0.9217
F1-score: 0.9190
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2462
Epoch 1/10, Batch 20/97, Loss: 1.0725
Epoch 1/10, Batch 30/97, Loss: 0.7575
Epoch 1/10, Batch 40/97, Loss: 0.7186
Epoch 1/10, Batch 50/97, Loss: 0.7067
Epoch 1/10, Batch 60/97, Loss: 0.6362
Epoch 1/10, Batch 70/97, Loss: 0.5252
Epoch 1/10, Batch 80/97, Loss: 0.6319
Epoch 1/10, Batch 90/97, Loss: 0.5538
Epoch 1/10, Train Loss: 0.7981, Valid Loss: 0.4618
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5232
Epoch 2/10, Batch 20/97, Loss: 0.5235
Epoch 2/10, Batch 30/97, Loss: 0.3201
Epoch 2/10, Batch 40/97, Loss: 0.4394
Epoch 2/10, Batch 50/97, Loss: 0.3503
Epoch 2/10, Batch 60/97, Loss: 0.5150
Epoch 2/10, Batch 70/97, Loss: 0.3303
Epoch 2/10, Batch 80/97, Loss: 0.2772
Epoch 2/10, Batch 90/97, Loss: 0.3736
Epoch 2/10, Train Loss: 0.4107, Valid Loss: 0.3549
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2376
Epoch 3/10, Batch 20/97, Loss: 0.3070
Epoch 3/10, Batch 30/97, Loss: 0.3605
Epoch 3/10, Batch 40/97, Loss: 0.2433
Epoch 3/10, Batch 50/97, Loss: 0.3159
Epoch 3/10, Batch 60/97, Loss: 0.1178
Epoch 3/10, Batch 70/97, Loss: 0.3772
Epoch 3/10, Batch 80/97, Loss: 0.3650
Epoch 3/10, Batch 90/97, Loss: 0.1534
Epoch 3/10, Train Loss: 0.3276, Valid Loss: 0.3129
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4725
Epoch 4/10, Batch 20/97, Loss: 0.2001
Epoch 4/10, Batch 30/97, Loss: 0.2575
Epoch 4/10, Batch 40/97, Loss: 0.2489
Epoch 4/10, Batch 50/97, Loss: 0.3174
Epoch 4/10, Batch 60/97, Loss: 0.3377
Epoch 4/10, Batch 70/97, Loss: 0.2030
Epoch 4/10, Batch 80/97, Loss: 0.2584
Epoch 4/10, Batch 90/97, Loss: 0.3008
Epoch 4/10, Train Loss: 0.2797, Valid Loss: 0.2979
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2864
Epoch 5/10, Batch 20/97, Loss: 0.2384
Epoch 5/10, Batch 30/97, Loss: 0.1233
Epoch 5/10, Batch 40/97, Loss: 0.4035
Epoch 5/10, Batch 50/97, Loss: 0.2071
Epoch 5/10, Batch 60/97, Loss: 0.2872
Epoch 5/10, Batch 70/97, Loss: 0.3375
Epoch 5/10, Batch 80/97, Loss: 0.1682
Epoch 5/10, Batch 90/97, Loss: 0.2645
Epoch 5/10, Train Loss: 0.2673, Valid Loss: 0.2795
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1742
Epoch 6/10, Batch 20/97, Loss: 0.1956
Epoch 6/10, Batch 30/97, Loss: 0.2614
Epoch 6/10, Batch 40/97, Loss: 0.3195
Epoch 6/10, Batch 50/97, Loss: 0.1651
Epoch 6/10, Batch 60/97, Loss: 0.2865
Epoch 6/10, Batch 70/97, Loss: 0.2843
Epoch 6/10, Batch 80/97, Loss: 0.2745
Epoch 6/10, Batch 90/97, Loss: 0.3985
Epoch 6/10, Train Loss: 0.2420, Valid Loss: 0.2690
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1348
Epoch 7/10, Batch 20/97, Loss: 0.3349
Epoch 7/10, Batch 30/97, Loss: 0.1871
Epoch 7/10, Batch 40/97, Loss: 0.1480
Epoch 7/10, Batch 50/97, Loss: 0.4046
Epoch 7/10, Batch 60/97, Loss: 0.0665
Epoch 7/10, Batch 70/97, Loss: 0.3091
Epoch 7/10, Batch 80/97, Loss: 0.1890
Epoch 7/10, Batch 90/97, Loss: 0.1792
Epoch 7/10, Train Loss: 0.2246, Valid Loss: 0.2573
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.0936
Epoch 8/10, Batch 20/97, Loss: 0.2066
Epoch 8/10, Batch 30/97, Loss: 0.2857
Epoch 8/10, Batch 40/97, Loss: 0.2543
Epoch 8/10, Batch 50/97, Loss: 0.2874
Epoch 8/10, Batch 60/97, Loss: 0.2047
Epoch 8/10, Batch 70/97, Loss: 0.1318
Epoch 8/10, Batch 80/97, Loss: 0.1639
Epoch 8/10, Batch 90/97, Loss: 0.2353
Epoch 8/10, Train Loss: 0.2157, Valid Loss: 0.2541
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1816
Epoch 9/10, Batch 20/97, Loss: 0.1278
Epoch 9/10, Batch 30/97, Loss: 0.1795
Epoch 9/10, Batch 40/97, Loss: 0.2096
Epoch 9/10, Batch 50/97, Loss: 0.1240
Epoch 9/10, Batch 60/97, Loss: 0.2767
Epoch 9/10, Batch 70/97, Loss: 0.1673
Epoch 9/10, Batch 80/97, Loss: 0.1764
Epoch 9/10, Batch 90/97, Loss: 0.1262
Epoch 9/10, Train Loss: 0.1984, Valid Loss: 0.2509
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1254
Epoch 10/10, Batch 20/97, Loss: 0.1260
Epoch 10/10, Batch 30/97, Loss: 0.1244
Epoch 10/10, Batch 40/97, Loss: 0.2574
Epoch 10/10, Batch 50/97, Loss: 0.1670
Epoch 10/10, Batch 60/97, Loss: 0.1177
Epoch 10/10, Batch 70/97, Loss: 0.4675
Epoch 10/10, Batch 80/97, Loss: 0.2348
Epoch 10/10, Batch 90/97, Loss: 0.1125
Epoch 10/10, Train Loss: 0.1967, Valid Loss: 0.2475
Model saved!
Accuracy: 0.9136
Precision: 0.9100
Recall: 0.9136
F1-score: 0.9096
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2662
Epoch 1/10, Batch 20/97, Loss: 1.0237
Epoch 1/10, Batch 30/97, Loss: 0.7863
Epoch 1/10, Batch 40/97, Loss: 0.6774
Epoch 1/10, Batch 50/97, Loss: 0.6548
Epoch 1/10, Batch 60/97, Loss: 0.6666
Epoch 1/10, Batch 70/97, Loss: 0.7468
Epoch 1/10, Batch 80/97, Loss: 0.5630
Epoch 1/10, Batch 90/97, Loss: 0.5916
Epoch 1/10, Train Loss: 0.7888, Valid Loss: 0.4185
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5633
Epoch 2/10, Batch 20/97, Loss: 0.4387
Epoch 2/10, Batch 30/97, Loss: 0.3385
Epoch 2/10, Batch 40/97, Loss: 0.5013
Epoch 2/10, Batch 50/97, Loss: 0.4431
Epoch 2/10, Batch 60/97, Loss: 0.4559
Epoch 2/10, Batch 70/97, Loss: 0.3170
Epoch 2/10, Batch 80/97, Loss: 0.4199
Epoch 2/10, Batch 90/97, Loss: 0.3552
Epoch 2/10, Train Loss: 0.4104, Valid Loss: 0.3133
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3105
Epoch 3/10, Batch 20/97, Loss: 0.2424
Epoch 3/10, Batch 30/97, Loss: 0.2786
Epoch 3/10, Batch 40/97, Loss: 0.2041
Epoch 3/10, Batch 50/97, Loss: 0.3552
Epoch 3/10, Batch 60/97, Loss: 0.4103
Epoch 3/10, Batch 70/97, Loss: 0.2941
Epoch 3/10, Batch 80/97, Loss: 0.2133
Epoch 3/10, Batch 90/97, Loss: 0.3632
Epoch 3/10, Train Loss: 0.3325, Valid Loss: 0.2674
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3418
Epoch 4/10, Batch 20/97, Loss: 0.3290
Epoch 4/10, Batch 30/97, Loss: 0.2329
Epoch 4/10, Batch 40/97, Loss: 0.2482
Epoch 4/10, Batch 50/97, Loss: 0.3695
Epoch 4/10, Batch 60/97, Loss: 0.3733
Epoch 4/10, Batch 70/97, Loss: 0.2877
Epoch 4/10, Batch 80/97, Loss: 0.1801
Epoch 4/10, Batch 90/97, Loss: 0.1766
Epoch 4/10, Train Loss: 0.2885, Valid Loss: 0.2536
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2343
Epoch 5/10, Batch 20/97, Loss: 0.2225
Epoch 5/10, Batch 30/97, Loss: 0.2315
Epoch 5/10, Batch 40/97, Loss: 0.1230
Epoch 5/10, Batch 50/97, Loss: 0.1797
Epoch 5/10, Batch 60/97, Loss: 0.1627
Epoch 5/10, Batch 70/97, Loss: 0.2367
Epoch 5/10, Batch 80/97, Loss: 0.2875
Epoch 5/10, Batch 90/97, Loss: 0.2030
Epoch 5/10, Train Loss: 0.2633, Valid Loss: 0.2331
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1698
Epoch 6/10, Batch 20/97, Loss: 0.3535
Epoch 6/10, Batch 30/97, Loss: 0.1703
Epoch 6/10, Batch 40/97, Loss: 0.1958
Epoch 6/10, Batch 50/97, Loss: 0.2242
Epoch 6/10, Batch 60/97, Loss: 0.3380
Epoch 6/10, Batch 70/97, Loss: 0.1552
Epoch 6/10, Batch 80/97, Loss: 0.4239
Epoch 6/10, Batch 90/97, Loss: 0.1842
Epoch 6/10, Train Loss: 0.2453, Valid Loss: 0.2232
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2333
Epoch 7/10, Batch 20/97, Loss: 0.2471
Epoch 7/10, Batch 30/97, Loss: 0.1599
Epoch 7/10, Batch 40/97, Loss: 0.1089
Epoch 7/10, Batch 50/97, Loss: 0.1853
Epoch 7/10, Batch 60/97, Loss: 0.2368
Epoch 7/10, Batch 70/97, Loss: 0.2006
Epoch 7/10, Batch 80/97, Loss: 0.2382
Epoch 7/10, Batch 90/97, Loss: 0.2328
Epoch 7/10, Train Loss: 0.2295, Valid Loss: 0.2157
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1950
Epoch 8/10, Batch 20/97, Loss: 0.1648
Epoch 8/10, Batch 30/97, Loss: 0.1874
Epoch 8/10, Batch 40/97, Loss: 0.2165
Epoch 8/10, Batch 50/97, Loss: 0.3235
Epoch 8/10, Batch 60/97, Loss: 0.2806
Epoch 8/10, Batch 70/97, Loss: 0.1886
Epoch 8/10, Batch 80/97, Loss: 0.1981
Epoch 8/10, Batch 90/97, Loss: 0.2666
Epoch 8/10, Train Loss: 0.2240, Valid Loss: 0.2191
Epoch 9/10, Batch 10/97, Loss: 0.2265
Epoch 9/10, Batch 20/97, Loss: 0.1528
Epoch 9/10, Batch 30/97, Loss: 0.2252
Epoch 9/10, Batch 40/97, Loss: 0.2660
Epoch 9/10, Batch 50/97, Loss: 0.0890
Epoch 9/10, Batch 60/97, Loss: 0.1161
Epoch 9/10, Batch 70/97, Loss: 0.2088
Epoch 9/10, Batch 80/97, Loss: 0.1276
Epoch 9/10, Batch 90/97, Loss: 0.1394
Epoch 9/10, Train Loss: 0.2079, Valid Loss: 0.2089
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1314
Epoch 10/10, Batch 20/97, Loss: 0.2212
Epoch 10/10, Batch 30/97, Loss: 0.1573
Epoch 10/10, Batch 40/97, Loss: 0.1345
Epoch 10/10, Batch 50/97, Loss: 0.1672
Epoch 10/10, Batch 60/97, Loss: 0.0977
Epoch 10/10, Batch 70/97, Loss: 0.1205
Epoch 10/10, Batch 80/97, Loss: 0.1925
Epoch 10/10, Batch 90/97, Loss: 0.1460
Epoch 10/10, Train Loss: 0.2043, Valid Loss: 0.2076
Model saved!
Accuracy: 0.9054
Precision: 0.9024
Recall: 0.9054
F1-score: 0.9026
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2660
Epoch 1/10, Batch 20/97, Loss: 1.1110
Epoch 1/10, Batch 30/97, Loss: 0.7900
Epoch 1/10, Batch 40/97, Loss: 0.6929
Epoch 1/10, Batch 50/97, Loss: 0.6449
Epoch 1/10, Batch 60/97, Loss: 0.7243
Epoch 1/10, Batch 70/97, Loss: 0.6526
Epoch 1/10, Batch 80/97, Loss: 0.7232
Epoch 1/10, Batch 90/97, Loss: 0.5192
Epoch 1/10, Train Loss: 0.8087, Valid Loss: 0.4630
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4691
Epoch 2/10, Batch 20/97, Loss: 0.4074
Epoch 2/10, Batch 30/97, Loss: 0.4393
Epoch 2/10, Batch 40/97, Loss: 0.3487
Epoch 2/10, Batch 50/97, Loss: 0.4307
Epoch 2/10, Batch 60/97, Loss: 0.4296
Epoch 2/10, Batch 70/97, Loss: 0.3609
Epoch 2/10, Batch 80/97, Loss: 0.3768
Epoch 2/10, Batch 90/97, Loss: 0.4262
Epoch 2/10, Train Loss: 0.4151, Valid Loss: 0.3593
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4560
Epoch 3/10, Batch 20/97, Loss: 0.3946
Epoch 3/10, Batch 30/97, Loss: 0.3770
Epoch 3/10, Batch 40/97, Loss: 0.3346
Epoch 3/10, Batch 50/97, Loss: 0.4184
Epoch 3/10, Batch 60/97, Loss: 0.1784
Epoch 3/10, Batch 70/97, Loss: 0.3158
Epoch 3/10, Batch 80/97, Loss: 0.3649
Epoch 3/10, Batch 90/97, Loss: 0.2471
Epoch 3/10, Train Loss: 0.3328, Valid Loss: 0.3149
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.5002
Epoch 4/10, Batch 20/97, Loss: 0.3113
Epoch 4/10, Batch 30/97, Loss: 0.2792
Epoch 4/10, Batch 40/97, Loss: 0.3765
Epoch 4/10, Batch 50/97, Loss: 0.2223
Epoch 4/10, Batch 60/97, Loss: 0.1578
Epoch 4/10, Batch 70/97, Loss: 0.3946
Epoch 4/10, Batch 80/97, Loss: 0.2803
Epoch 4/10, Batch 90/97, Loss: 0.1759
Epoch 4/10, Train Loss: 0.2860, Valid Loss: 0.3001
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2210
Epoch 5/10, Batch 20/97, Loss: 0.2359
Epoch 5/10, Batch 30/97, Loss: 0.3134
Epoch 5/10, Batch 40/97, Loss: 0.2117
Epoch 5/10, Batch 50/97, Loss: 0.2062
Epoch 5/10, Batch 60/97, Loss: 0.2036
Epoch 5/10, Batch 70/97, Loss: 0.2308
Epoch 5/10, Batch 80/97, Loss: 0.2186
Epoch 5/10, Batch 90/97, Loss: 0.2414
Epoch 5/10, Train Loss: 0.2662, Valid Loss: 0.2773
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1431
Epoch 6/10, Batch 20/97, Loss: 0.2824
Epoch 6/10, Batch 30/97, Loss: 0.1230
Epoch 6/10, Batch 40/97, Loss: 0.1646
Epoch 6/10, Batch 50/97, Loss: 0.2397
Epoch 6/10, Batch 60/97, Loss: 0.2335
Epoch 6/10, Batch 70/97, Loss: 0.1396
Epoch 6/10, Batch 80/97, Loss: 0.1490
Epoch 6/10, Batch 90/97, Loss: 0.3163
Epoch 6/10, Train Loss: 0.2554, Valid Loss: 0.2726
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2823
Epoch 7/10, Batch 20/97, Loss: 0.4612
Epoch 7/10, Batch 30/97, Loss: 0.2555
Epoch 7/10, Batch 40/97, Loss: 0.1874
Epoch 7/10, Batch 50/97, Loss: 0.2990
Epoch 7/10, Batch 60/97, Loss: 0.1073
Epoch 7/10, Batch 70/97, Loss: 0.4618
Epoch 7/10, Batch 80/97, Loss: 0.2479
Epoch 7/10, Batch 90/97, Loss: 0.2143
Epoch 7/10, Train Loss: 0.2357, Valid Loss: 0.2646
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2395
Epoch 8/10, Batch 20/97, Loss: 0.1908
Epoch 8/10, Batch 30/97, Loss: 0.1516
Epoch 8/10, Batch 40/97, Loss: 0.3084
Epoch 8/10, Batch 50/97, Loss: 0.1423
Epoch 8/10, Batch 60/97, Loss: 0.2890
Epoch 8/10, Batch 70/97, Loss: 0.1543
Epoch 8/10, Batch 80/97, Loss: 0.1899
Epoch 8/10, Batch 90/97, Loss: 0.2302
Epoch 8/10, Train Loss: 0.2215, Valid Loss: 0.2612
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2052
Epoch 9/10, Batch 20/97, Loss: 0.1833
Epoch 9/10, Batch 30/97, Loss: 0.3287
Epoch 9/10, Batch 40/97, Loss: 0.2279
Epoch 9/10, Batch 50/97, Loss: 0.1290
Epoch 9/10, Batch 60/97, Loss: 0.1919
Epoch 9/10, Batch 70/97, Loss: 0.1541
Epoch 9/10, Batch 80/97, Loss: 0.2132
Epoch 9/10, Batch 90/97, Loss: 0.1702
Epoch 9/10, Train Loss: 0.2124, Valid Loss: 0.2501
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2678
Epoch 10/10, Batch 20/97, Loss: 0.1593
Epoch 10/10, Batch 30/97, Loss: 0.1594
Epoch 10/10, Batch 40/97, Loss: 0.0668
Epoch 10/10, Batch 50/97, Loss: 0.1684
Epoch 10/10, Batch 60/97, Loss: 0.1278
Epoch 10/10, Batch 70/97, Loss: 0.1792
Epoch 10/10, Batch 80/97, Loss: 0.2732
Epoch 10/10, Batch 90/97, Loss: 0.1277
Epoch 10/10, Train Loss: 0.2049, Valid Loss: 0.2520
Accuracy: 0.9112
Precision: 0.9082
Recall: 0.9112
F1-score: 0.9090
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2381
Epoch 1/10, Batch 20/97, Loss: 1.1464
Epoch 1/10, Batch 30/97, Loss: 0.6558
Epoch 1/10, Batch 40/97, Loss: 0.7825
Epoch 1/10, Batch 50/97, Loss: 0.6325
Epoch 1/10, Batch 60/97, Loss: 0.6541
Epoch 1/10, Batch 70/97, Loss: 0.7553
Epoch 1/10, Batch 80/97, Loss: 0.6248
Epoch 1/10, Batch 90/97, Loss: 0.4935
Epoch 1/10, Train Loss: 0.7980, Valid Loss: 0.4378
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4788
Epoch 2/10, Batch 20/97, Loss: 0.3255
Epoch 2/10, Batch 30/97, Loss: 0.3482
Epoch 2/10, Batch 40/97, Loss: 0.3035
Epoch 2/10, Batch 50/97, Loss: 0.2906
Epoch 2/10, Batch 60/97, Loss: 0.5124
Epoch 2/10, Batch 70/97, Loss: 0.3334
Epoch 2/10, Batch 80/97, Loss: 0.4094
Epoch 2/10, Batch 90/97, Loss: 0.4868
Epoch 2/10, Train Loss: 0.4082, Valid Loss: 0.3311
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.5114
Epoch 3/10, Batch 20/97, Loss: 0.4738
Epoch 3/10, Batch 30/97, Loss: 0.5430
Epoch 3/10, Batch 40/97, Loss: 0.3761
Epoch 3/10, Batch 50/97, Loss: 0.6074
Epoch 3/10, Batch 60/97, Loss: 0.2680
Epoch 3/10, Batch 70/97, Loss: 0.2918
Epoch 3/10, Batch 80/97, Loss: 0.2538
Epoch 3/10, Batch 90/97, Loss: 0.3688
Epoch 3/10, Train Loss: 0.3338, Valid Loss: 0.2956
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3090
Epoch 4/10, Batch 20/97, Loss: 0.2469
Epoch 4/10, Batch 30/97, Loss: 0.2299
Epoch 4/10, Batch 40/97, Loss: 0.1579
Epoch 4/10, Batch 50/97, Loss: 0.1933
Epoch 4/10, Batch 60/97, Loss: 0.2360
Epoch 4/10, Batch 70/97, Loss: 0.1767
Epoch 4/10, Batch 80/97, Loss: 0.2941
Epoch 4/10, Batch 90/97, Loss: 0.3234
Epoch 4/10, Train Loss: 0.2869, Valid Loss: 0.2720
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1712
Epoch 5/10, Batch 20/97, Loss: 0.3420
Epoch 5/10, Batch 30/97, Loss: 0.2146
Epoch 5/10, Batch 40/97, Loss: 0.3226
Epoch 5/10, Batch 50/97, Loss: 0.2734
Epoch 5/10, Batch 60/97, Loss: 0.2126
Epoch 5/10, Batch 70/97, Loss: 0.1763
Epoch 5/10, Batch 80/97, Loss: 0.2385
Epoch 5/10, Batch 90/97, Loss: 0.2534
Epoch 5/10, Train Loss: 0.2640, Valid Loss: 0.2558
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1177
Epoch 6/10, Batch 20/97, Loss: 0.4045
Epoch 6/10, Batch 30/97, Loss: 0.1677
Epoch 6/10, Batch 40/97, Loss: 0.2334
Epoch 6/10, Batch 50/97, Loss: 0.1945
Epoch 6/10, Batch 60/97, Loss: 0.1987
Epoch 6/10, Batch 70/97, Loss: 0.3426
Epoch 6/10, Batch 80/97, Loss: 0.4995
Epoch 6/10, Batch 90/97, Loss: 0.1869
Epoch 6/10, Train Loss: 0.2483, Valid Loss: 0.2424
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1977
Epoch 7/10, Batch 20/97, Loss: 0.3170
Epoch 7/10, Batch 30/97, Loss: 0.1504
Epoch 7/10, Batch 40/97, Loss: 0.2187
Epoch 7/10, Batch 50/97, Loss: 0.3044
Epoch 7/10, Batch 60/97, Loss: 0.1305
Epoch 7/10, Batch 70/97, Loss: 0.3051
Epoch 7/10, Batch 80/97, Loss: 0.3428
Epoch 7/10, Batch 90/97, Loss: 0.0793
Epoch 7/10, Train Loss: 0.2286, Valid Loss: 0.2355
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2451
Epoch 8/10, Batch 20/97, Loss: 0.1383
Epoch 8/10, Batch 30/97, Loss: 0.1476
Epoch 8/10, Batch 40/97, Loss: 0.1553
Epoch 8/10, Batch 50/97, Loss: 0.2067
Epoch 8/10, Batch 60/97, Loss: 0.1019
Epoch 8/10, Batch 70/97, Loss: 0.2450
Epoch 8/10, Batch 80/97, Loss: 0.1220
Epoch 8/10, Batch 90/97, Loss: 0.2235
Epoch 8/10, Train Loss: 0.2225, Valid Loss: 0.2320
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1738
Epoch 9/10, Batch 20/97, Loss: 0.2680
Epoch 9/10, Batch 30/97, Loss: 0.2851
Epoch 9/10, Batch 40/97, Loss: 0.3191
Epoch 9/10, Batch 50/97, Loss: 0.1658
Epoch 9/10, Batch 60/97, Loss: 0.1476
Epoch 9/10, Batch 70/97, Loss: 0.1477
Epoch 9/10, Batch 80/97, Loss: 0.1003
Epoch 9/10, Batch 90/97, Loss: 0.3065
Epoch 9/10, Train Loss: 0.2024, Valid Loss: 0.2242
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1570
Epoch 10/10, Batch 20/97, Loss: 0.1253
Epoch 10/10, Batch 30/97, Loss: 0.1646
Epoch 10/10, Batch 40/97, Loss: 0.1539
Epoch 10/10, Batch 50/97, Loss: 0.2365
Epoch 10/10, Batch 60/97, Loss: 0.0704
Epoch 10/10, Batch 70/97, Loss: 0.1721
Epoch 10/10, Batch 80/97, Loss: 0.1364
Epoch 10/10, Batch 90/97, Loss: 0.2619
Epoch 10/10, Train Loss: 0.2121, Valid Loss: 0.2320
Accuracy: 0.9112
Precision: 0.9084
Recall: 0.9112
F1-score: 0.9093
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2949
Epoch 1/10, Batch 20/97, Loss: 1.1008
Epoch 1/10, Batch 30/97, Loss: 0.8086
Epoch 1/10, Batch 40/97, Loss: 0.6874
Epoch 1/10, Batch 50/97, Loss: 0.6927
Epoch 1/10, Batch 60/97, Loss: 0.6502
Epoch 1/10, Batch 70/97, Loss: 0.5988
Epoch 1/10, Batch 80/97, Loss: 0.7437
Epoch 1/10, Batch 90/97, Loss: 0.4954
Epoch 1/10, Train Loss: 0.8011, Valid Loss: 0.4454
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4522
Epoch 2/10, Batch 20/97, Loss: 0.3555
Epoch 2/10, Batch 30/97, Loss: 0.4275
Epoch 2/10, Batch 40/97, Loss: 0.3198
Epoch 2/10, Batch 50/97, Loss: 0.5040
Epoch 2/10, Batch 60/97, Loss: 0.3687
Epoch 2/10, Batch 70/97, Loss: 0.3612
Epoch 2/10, Batch 80/97, Loss: 0.4621
Epoch 2/10, Batch 90/97, Loss: 0.4113
Epoch 2/10, Train Loss: 0.4110, Valid Loss: 0.3337
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2949
Epoch 3/10, Batch 20/97, Loss: 0.2342
Epoch 3/10, Batch 30/97, Loss: 0.3581
Epoch 3/10, Batch 40/97, Loss: 0.2249
Epoch 3/10, Batch 50/97, Loss: 0.4469
Epoch 3/10, Batch 60/97, Loss: 0.2542
Epoch 3/10, Batch 70/97, Loss: 0.4605
Epoch 3/10, Batch 80/97, Loss: 0.2737
Epoch 3/10, Batch 90/97, Loss: 0.2145
Epoch 3/10, Train Loss: 0.3390, Valid Loss: 0.2877
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2698
Epoch 4/10, Batch 20/97, Loss: 0.1823
Epoch 4/10, Batch 30/97, Loss: 0.2822
Epoch 4/10, Batch 40/97, Loss: 0.3091
Epoch 4/10, Batch 50/97, Loss: 0.2247
Epoch 4/10, Batch 60/97, Loss: 0.2126
Epoch 4/10, Batch 70/97, Loss: 0.1598
Epoch 4/10, Batch 80/97, Loss: 0.2930
Epoch 4/10, Batch 90/97, Loss: 0.2599
Epoch 4/10, Train Loss: 0.2868, Valid Loss: 0.2752
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2442
Epoch 5/10, Batch 20/97, Loss: 0.4132
Epoch 5/10, Batch 30/97, Loss: 0.2242
Epoch 5/10, Batch 40/97, Loss: 0.3561
Epoch 5/10, Batch 50/97, Loss: 0.3459
Epoch 5/10, Batch 60/97, Loss: 0.2910
Epoch 5/10, Batch 70/97, Loss: 0.2863
Epoch 5/10, Batch 80/97, Loss: 0.1634
Epoch 5/10, Batch 90/97, Loss: 0.1929
Epoch 5/10, Train Loss: 0.2654, Valid Loss: 0.2568
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.0751
Epoch 6/10, Batch 20/97, Loss: 0.2322
Epoch 6/10, Batch 30/97, Loss: 0.2711
Epoch 6/10, Batch 40/97, Loss: 0.1614
Epoch 6/10, Batch 50/97, Loss: 0.1723
Epoch 6/10, Batch 60/97, Loss: 0.2087
Epoch 6/10, Batch 70/97, Loss: 0.3491
Epoch 6/10, Batch 80/97, Loss: 0.3149
Epoch 6/10, Batch 90/97, Loss: 0.2344
Epoch 6/10, Train Loss: 0.2503, Valid Loss: 0.2418
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1849
Epoch 7/10, Batch 20/97, Loss: 0.3281
Epoch 7/10, Batch 30/97, Loss: 0.1630
Epoch 7/10, Batch 40/97, Loss: 0.2761
Epoch 7/10, Batch 50/97, Loss: 0.1802
Epoch 7/10, Batch 60/97, Loss: 0.2050
Epoch 7/10, Batch 70/97, Loss: 0.4584
Epoch 7/10, Batch 80/97, Loss: 0.1426
Epoch 7/10, Batch 90/97, Loss: 0.2570
Epoch 7/10, Train Loss: 0.2312, Valid Loss: 0.2415
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1130
Epoch 8/10, Batch 20/97, Loss: 0.1724
Epoch 8/10, Batch 30/97, Loss: 0.0836
Epoch 8/10, Batch 40/97, Loss: 0.1789
Epoch 8/10, Batch 50/97, Loss: 0.3236
Epoch 8/10, Batch 60/97, Loss: 0.2318
Epoch 8/10, Batch 70/97, Loss: 0.1828
Epoch 8/10, Batch 80/97, Loss: 0.3339
Epoch 8/10, Batch 90/97, Loss: 0.2279
Epoch 8/10, Train Loss: 0.2232, Valid Loss: 0.2345
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1057
Epoch 9/10, Batch 20/97, Loss: 0.3053
Epoch 9/10, Batch 30/97, Loss: 0.2122
Epoch 9/10, Batch 40/97, Loss: 0.2302
Epoch 9/10, Batch 50/97, Loss: 0.1269
Epoch 9/10, Batch 60/97, Loss: 0.1499
Epoch 9/10, Batch 70/97, Loss: 0.1976
Epoch 9/10, Batch 80/97, Loss: 0.1731
Epoch 9/10, Batch 90/97, Loss: 0.2715
Epoch 9/10, Train Loss: 0.2127, Valid Loss: 0.2388
Epoch 10/10, Batch 10/97, Loss: 0.1597
Epoch 10/10, Batch 20/97, Loss: 0.1898
Epoch 10/10, Batch 30/97, Loss: 0.2145
Epoch 10/10, Batch 40/97, Loss: 0.1165
Epoch 10/10, Batch 50/97, Loss: 0.1934
Epoch 10/10, Batch 60/97, Loss: 0.2183
Epoch 10/10, Batch 70/97, Loss: 0.2378
Epoch 10/10, Batch 80/97, Loss: 0.1041
Epoch 10/10, Batch 90/97, Loss: 0.2918
Epoch 10/10, Train Loss: 0.1930, Valid Loss: 0.2293
Model saved!
Accuracy: 0.9089
Precision: 0.9058
Recall: 0.9089
F1-score: 0.9045
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2516
Epoch 1/10, Batch 20/97, Loss: 1.0587
Epoch 1/10, Batch 30/97, Loss: 0.7475
Epoch 1/10, Batch 40/97, Loss: 0.7337
Epoch 1/10, Batch 50/97, Loss: 0.6526
Epoch 1/10, Batch 60/97, Loss: 0.6727
Epoch 1/10, Batch 70/97, Loss: 0.4945
Epoch 1/10, Batch 80/97, Loss: 0.5517
Epoch 1/10, Batch 90/97, Loss: 0.5228
Epoch 1/10, Train Loss: 0.7983, Valid Loss: 0.4535
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5661
Epoch 2/10, Batch 20/97, Loss: 0.4110
Epoch 2/10, Batch 30/97, Loss: 0.3179
Epoch 2/10, Batch 40/97, Loss: 0.4575
Epoch 2/10, Batch 50/97, Loss: 0.4375
Epoch 2/10, Batch 60/97, Loss: 0.4427
Epoch 2/10, Batch 70/97, Loss: 0.2762
Epoch 2/10, Batch 80/97, Loss: 0.4492
Epoch 2/10, Batch 90/97, Loss: 0.5212
Epoch 2/10, Train Loss: 0.4133, Valid Loss: 0.3458
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4813
Epoch 3/10, Batch 20/97, Loss: 0.2793
Epoch 3/10, Batch 30/97, Loss: 0.3437
Epoch 3/10, Batch 40/97, Loss: 0.3148
Epoch 3/10, Batch 50/97, Loss: 0.3551
Epoch 3/10, Batch 60/97, Loss: 0.1927
Epoch 3/10, Batch 70/97, Loss: 0.3077
Epoch 3/10, Batch 80/97, Loss: 0.3470
Epoch 3/10, Batch 90/97, Loss: 0.2699
Epoch 3/10, Train Loss: 0.3345, Valid Loss: 0.3085
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3889
Epoch 4/10, Batch 20/97, Loss: 0.1708
Epoch 4/10, Batch 30/97, Loss: 0.2667
Epoch 4/10, Batch 40/97, Loss: 0.3125
Epoch 4/10, Batch 50/97, Loss: 0.3972
Epoch 4/10, Batch 60/97, Loss: 0.3067
Epoch 4/10, Batch 70/97, Loss: 0.2760
Epoch 4/10, Batch 80/97, Loss: 0.3646
Epoch 4/10, Batch 90/97, Loss: 0.2278
Epoch 4/10, Train Loss: 0.2864, Valid Loss: 0.2863
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2542
Epoch 5/10, Batch 20/97, Loss: 0.3406
Epoch 5/10, Batch 30/97, Loss: 0.3306
Epoch 5/10, Batch 40/97, Loss: 0.4171
Epoch 5/10, Batch 50/97, Loss: 0.1968
Epoch 5/10, Batch 60/97, Loss: 0.2373
Epoch 5/10, Batch 70/97, Loss: 0.2118
Epoch 5/10, Batch 80/97, Loss: 0.2335
Epoch 5/10, Batch 90/97, Loss: 0.1407
Epoch 5/10, Train Loss: 0.2677, Valid Loss: 0.2720
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1346
Epoch 6/10, Batch 20/97, Loss: 0.4284
Epoch 6/10, Batch 30/97, Loss: 0.2211
Epoch 6/10, Batch 40/97, Loss: 0.1473
Epoch 6/10, Batch 50/97, Loss: 0.2782
Epoch 6/10, Batch 60/97, Loss: 0.3369
Epoch 6/10, Batch 70/97, Loss: 0.1459
Epoch 6/10, Batch 80/97, Loss: 0.3298
Epoch 6/10, Batch 90/97, Loss: 0.4846
Epoch 6/10, Train Loss: 0.2468, Valid Loss: 0.2564
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1212
Epoch 7/10, Batch 20/97, Loss: 0.2895
Epoch 7/10, Batch 30/97, Loss: 0.3587
Epoch 7/10, Batch 40/97, Loss: 0.3101
Epoch 7/10, Batch 50/97, Loss: 0.2445
Epoch 7/10, Batch 60/97, Loss: 0.1378
Epoch 7/10, Batch 70/97, Loss: 0.4620
Epoch 7/10, Batch 80/97, Loss: 0.1854
Epoch 7/10, Batch 90/97, Loss: 0.2311
Epoch 7/10, Train Loss: 0.2243, Valid Loss: 0.2545
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1865
Epoch 8/10, Batch 20/97, Loss: 0.1410
Epoch 8/10, Batch 30/97, Loss: 0.1287
Epoch 8/10, Batch 40/97, Loss: 0.1344
Epoch 8/10, Batch 50/97, Loss: 0.1273
Epoch 8/10, Batch 60/97, Loss: 0.2756
Epoch 8/10, Batch 70/97, Loss: 0.2964
Epoch 8/10, Batch 80/97, Loss: 0.1269
Epoch 8/10, Batch 90/97, Loss: 0.2841
Epoch 8/10, Train Loss: 0.2215, Valid Loss: 0.2504
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2416
Epoch 9/10, Batch 20/97, Loss: 0.1967
Epoch 9/10, Batch 30/97, Loss: 0.2094
Epoch 9/10, Batch 40/97, Loss: 0.2457
Epoch 9/10, Batch 50/97, Loss: 0.1834
Epoch 9/10, Batch 60/97, Loss: 0.2202
Epoch 9/10, Batch 70/97, Loss: 0.1889
Epoch 9/10, Batch 80/97, Loss: 0.1687
Epoch 9/10, Batch 90/97, Loss: 0.2331
Epoch 9/10, Train Loss: 0.2025, Valid Loss: 0.2475
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1679
Epoch 10/10, Batch 20/97, Loss: 0.1568
Epoch 10/10, Batch 30/97, Loss: 0.2708
Epoch 10/10, Batch 40/97, Loss: 0.1651
Epoch 10/10, Batch 50/97, Loss: 0.2252
Epoch 10/10, Batch 60/97, Loss: 0.1134
Epoch 10/10, Batch 70/97, Loss: 0.3411
Epoch 10/10, Batch 80/97, Loss: 0.1330
Epoch 10/10, Batch 90/97, Loss: 0.2005
Epoch 10/10, Train Loss: 0.2006, Valid Loss: 0.2452
Model saved!
Accuracy: 0.9042
Precision: 0.9023
Recall: 0.9042
F1-score: 0.8999
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2612
Epoch 1/10, Batch 20/97, Loss: 1.0586
Epoch 1/10, Batch 30/97, Loss: 0.8550
Epoch 1/10, Batch 40/97, Loss: 0.6776
Epoch 1/10, Batch 50/97, Loss: 0.5872
Epoch 1/10, Batch 60/97, Loss: 0.7150
Epoch 1/10, Batch 70/97, Loss: 0.6541
Epoch 1/10, Batch 80/97, Loss: 0.5381
Epoch 1/10, Batch 90/97, Loss: 0.5922
Epoch 1/10, Train Loss: 0.7986, Valid Loss: 0.4441
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4997
Epoch 2/10, Batch 20/97, Loss: 0.4269
Epoch 2/10, Batch 30/97, Loss: 0.3286
Epoch 2/10, Batch 40/97, Loss: 0.3271
Epoch 2/10, Batch 50/97, Loss: 0.4780
Epoch 2/10, Batch 60/97, Loss: 0.3559
Epoch 2/10, Batch 70/97, Loss: 0.2966
Epoch 2/10, Batch 80/97, Loss: 0.3107
Epoch 2/10, Batch 90/97, Loss: 0.3319
Epoch 2/10, Train Loss: 0.4132, Valid Loss: 0.3413
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3815
Epoch 3/10, Batch 20/97, Loss: 0.2946
Epoch 3/10, Batch 30/97, Loss: 0.3860
Epoch 3/10, Batch 40/97, Loss: 0.1705
Epoch 3/10, Batch 50/97, Loss: 0.3923
Epoch 3/10, Batch 60/97, Loss: 0.3071
Epoch 3/10, Batch 70/97, Loss: 0.4084
Epoch 3/10, Batch 80/97, Loss: 0.3457
Epoch 3/10, Batch 90/97, Loss: 0.4150
Epoch 3/10, Train Loss: 0.3351, Valid Loss: 0.3014
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3746
Epoch 4/10, Batch 20/97, Loss: 0.1738
Epoch 4/10, Batch 30/97, Loss: 0.2762
Epoch 4/10, Batch 40/97, Loss: 0.2225
Epoch 4/10, Batch 50/97, Loss: 0.2571
Epoch 4/10, Batch 60/97, Loss: 0.3402
Epoch 4/10, Batch 70/97, Loss: 0.2662
Epoch 4/10, Batch 80/97, Loss: 0.2667
Epoch 4/10, Batch 90/97, Loss: 0.2481
Epoch 4/10, Train Loss: 0.2860, Valid Loss: 0.2786
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2370
Epoch 5/10, Batch 20/97, Loss: 0.2582
Epoch 5/10, Batch 30/97, Loss: 0.1529
Epoch 5/10, Batch 40/97, Loss: 0.2118
Epoch 5/10, Batch 50/97, Loss: 0.1942
Epoch 5/10, Batch 60/97, Loss: 0.2260
Epoch 5/10, Batch 70/97, Loss: 0.2272
Epoch 5/10, Batch 80/97, Loss: 0.2320
Epoch 5/10, Batch 90/97, Loss: 0.3112
Epoch 5/10, Train Loss: 0.2691, Valid Loss: 0.2637
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1667
Epoch 6/10, Batch 20/97, Loss: 0.4058
Epoch 6/10, Batch 30/97, Loss: 0.2181
Epoch 6/10, Batch 40/97, Loss: 0.3398
Epoch 6/10, Batch 50/97, Loss: 0.2536
Epoch 6/10, Batch 60/97, Loss: 0.3763
Epoch 6/10, Batch 70/97, Loss: 0.2544
Epoch 6/10, Batch 80/97, Loss: 0.2431
Epoch 6/10, Batch 90/97, Loss: 0.3719
Epoch 6/10, Train Loss: 0.2502, Valid Loss: 0.2497
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1997
Epoch 7/10, Batch 20/97, Loss: 0.2010
Epoch 7/10, Batch 30/97, Loss: 0.1924
Epoch 7/10, Batch 40/97, Loss: 0.1749
Epoch 7/10, Batch 50/97, Loss: 0.1830
Epoch 7/10, Batch 60/97, Loss: 0.1257
Epoch 7/10, Batch 70/97, Loss: 0.2251
Epoch 7/10, Batch 80/97, Loss: 0.2224
Epoch 7/10, Batch 90/97, Loss: 0.2598
Epoch 7/10, Train Loss: 0.2252, Valid Loss: 0.2459
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1895
Epoch 8/10, Batch 20/97, Loss: 0.2708
Epoch 8/10, Batch 30/97, Loss: 0.3209
Epoch 8/10, Batch 40/97, Loss: 0.2427
Epoch 8/10, Batch 50/97, Loss: 0.1828
Epoch 8/10, Batch 60/97, Loss: 0.2108
Epoch 8/10, Batch 70/97, Loss: 0.2173
Epoch 8/10, Batch 80/97, Loss: 0.1553
Epoch 8/10, Batch 90/97, Loss: 0.2088
Epoch 8/10, Train Loss: 0.2215, Valid Loss: 0.2390
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1833
Epoch 9/10, Batch 20/97, Loss: 0.1942
Epoch 9/10, Batch 30/97, Loss: 0.2233
Epoch 9/10, Batch 40/97, Loss: 0.3312
Epoch 9/10, Batch 50/97, Loss: 0.1537
Epoch 9/10, Batch 60/97, Loss: 0.2527
Epoch 9/10, Batch 70/97, Loss: 0.2163
Epoch 9/10, Batch 80/97, Loss: 0.2151
Epoch 9/10, Batch 90/97, Loss: 0.2021
Epoch 9/10, Train Loss: 0.2048, Valid Loss: 0.2349
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1488
Epoch 10/10, Batch 20/97, Loss: 0.2030
Epoch 10/10, Batch 30/97, Loss: 0.3459
Epoch 10/10, Batch 40/97, Loss: 0.1517
Epoch 10/10, Batch 50/97, Loss: 0.2579
Epoch 10/10, Batch 60/97, Loss: 0.1353
Epoch 10/10, Batch 70/97, Loss: 0.2444
Epoch 10/10, Batch 80/97, Loss: 0.2301
Epoch 10/10, Batch 90/97, Loss: 0.3068
Epoch 10/10, Train Loss: 0.2046, Valid Loss: 0.2423
Accuracy: 0.9229
Precision: 0.9208
Recall: 0.9229
F1-score: 0.9216
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2263
Epoch 1/10, Batch 20/97, Loss: 1.0709
Epoch 1/10, Batch 30/97, Loss: 0.7037
Epoch 1/10, Batch 40/97, Loss: 0.6548
Epoch 1/10, Batch 50/97, Loss: 0.6156
Epoch 1/10, Batch 60/97, Loss: 0.7594
Epoch 1/10, Batch 70/97, Loss: 0.6168
Epoch 1/10, Batch 80/97, Loss: 0.4776
Epoch 1/10, Batch 90/97, Loss: 0.4827
Epoch 1/10, Train Loss: 0.8019, Valid Loss: 0.4386
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4541
Epoch 2/10, Batch 20/97, Loss: 0.4939
Epoch 2/10, Batch 30/97, Loss: 0.3148
Epoch 2/10, Batch 40/97, Loss: 0.4218
Epoch 2/10, Batch 50/97, Loss: 0.3718
Epoch 2/10, Batch 60/97, Loss: 0.5080
Epoch 2/10, Batch 70/97, Loss: 0.3542
Epoch 2/10, Batch 80/97, Loss: 0.5222
Epoch 2/10, Batch 90/97, Loss: 0.4069
Epoch 2/10, Train Loss: 0.4177, Valid Loss: 0.3270
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4020
Epoch 3/10, Batch 20/97, Loss: 0.4647
Epoch 3/10, Batch 30/97, Loss: 0.5504
Epoch 3/10, Batch 40/97, Loss: 0.3675
Epoch 3/10, Batch 50/97, Loss: 0.5028
Epoch 3/10, Batch 60/97, Loss: 0.3526
Epoch 3/10, Batch 70/97, Loss: 0.4343
Epoch 3/10, Batch 80/97, Loss: 0.2891
Epoch 3/10, Batch 90/97, Loss: 0.2872
Epoch 3/10, Train Loss: 0.3451, Valid Loss: 0.2779
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3469
Epoch 4/10, Batch 20/97, Loss: 0.2386
Epoch 4/10, Batch 30/97, Loss: 0.2635
Epoch 4/10, Batch 40/97, Loss: 0.2183
Epoch 4/10, Batch 50/97, Loss: 0.3518
Epoch 4/10, Batch 60/97, Loss: 0.1748
Epoch 4/10, Batch 70/97, Loss: 0.2086
Epoch 4/10, Batch 80/97, Loss: 0.2765
Epoch 4/10, Batch 90/97, Loss: 0.2064
Epoch 4/10, Train Loss: 0.2901, Valid Loss: 0.2703
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2793
Epoch 5/10, Batch 20/97, Loss: 0.3259
Epoch 5/10, Batch 30/97, Loss: 0.2639
Epoch 5/10, Batch 40/97, Loss: 0.2113
Epoch 5/10, Batch 50/97, Loss: 0.2051
Epoch 5/10, Batch 60/97, Loss: 0.2932
Epoch 5/10, Batch 70/97, Loss: 0.3796
Epoch 5/10, Batch 80/97, Loss: 0.2999
Epoch 5/10, Batch 90/97, Loss: 0.1999
Epoch 5/10, Train Loss: 0.2715, Valid Loss: 0.2521
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3502
Epoch 6/10, Batch 20/97, Loss: 0.3464
Epoch 6/10, Batch 30/97, Loss: 0.2142
Epoch 6/10, Batch 40/97, Loss: 0.1681
Epoch 6/10, Batch 50/97, Loss: 0.2319
Epoch 6/10, Batch 60/97, Loss: 0.3089
Epoch 6/10, Batch 70/97, Loss: 0.3306
Epoch 6/10, Batch 80/97, Loss: 0.3902
Epoch 6/10, Batch 90/97, Loss: 0.5550
Epoch 6/10, Train Loss: 0.2574, Valid Loss: 0.2353
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2321
Epoch 7/10, Batch 20/97, Loss: 0.2700
Epoch 7/10, Batch 30/97, Loss: 0.2340
Epoch 7/10, Batch 40/97, Loss: 0.2187
Epoch 7/10, Batch 50/97, Loss: 0.2354
Epoch 7/10, Batch 60/97, Loss: 0.1130
Epoch 7/10, Batch 70/97, Loss: 0.3423
Epoch 7/10, Batch 80/97, Loss: 0.1619
Epoch 7/10, Batch 90/97, Loss: 0.2074
Epoch 7/10, Train Loss: 0.2242, Valid Loss: 0.2229
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2110
Epoch 8/10, Batch 20/97, Loss: 0.2623
Epoch 8/10, Batch 30/97, Loss: 0.1776
Epoch 8/10, Batch 40/97, Loss: 0.2121
Epoch 8/10, Batch 50/97, Loss: 0.2129
Epoch 8/10, Batch 60/97, Loss: 0.1815
Epoch 8/10, Batch 70/97, Loss: 0.3446
Epoch 8/10, Batch 80/97, Loss: 0.2049
Epoch 8/10, Batch 90/97, Loss: 0.1089
Epoch 8/10, Train Loss: 0.2229, Valid Loss: 0.2199
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1732
Epoch 9/10, Batch 20/97, Loss: 0.1683
Epoch 9/10, Batch 30/97, Loss: 0.1895
Epoch 9/10, Batch 40/97, Loss: 0.2798
Epoch 9/10, Batch 50/97, Loss: 0.1928
Epoch 9/10, Batch 60/97, Loss: 0.2029
Epoch 9/10, Batch 70/97, Loss: 0.2559
Epoch 9/10, Batch 80/97, Loss: 0.2344
Epoch 9/10, Batch 90/97, Loss: 0.2155
Epoch 9/10, Train Loss: 0.2186, Valid Loss: 0.2200
Epoch 10/10, Batch 10/97, Loss: 0.1848
Epoch 10/10, Batch 20/97, Loss: 0.2703
Epoch 10/10, Batch 30/97, Loss: 0.1811
Epoch 10/10, Batch 40/97, Loss: 0.1291
Epoch 10/10, Batch 50/97, Loss: 0.2962
Epoch 10/10, Batch 60/97, Loss: 0.1589
Epoch 10/10, Batch 70/97, Loss: 0.2019
Epoch 10/10, Batch 80/97, Loss: 0.2447
Epoch 10/10, Batch 90/97, Loss: 0.2475
Epoch 10/10, Train Loss: 0.2064, Valid Loss: 0.2112
Model saved!
Accuracy: 0.9241
Precision: 0.9223
Recall: 0.9241
F1-score: 0.9221
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.3162
Epoch 1/10, Batch 20/97, Loss: 1.1498
Epoch 1/10, Batch 30/97, Loss: 0.7671
Epoch 1/10, Batch 40/97, Loss: 0.8170
Epoch 1/10, Batch 50/97, Loss: 0.6247
Epoch 1/10, Batch 60/97, Loss: 0.8151
Epoch 1/10, Batch 70/97, Loss: 0.6002
Epoch 1/10, Batch 80/97, Loss: 0.6189
Epoch 1/10, Batch 90/97, Loss: 0.5364
Epoch 1/10, Train Loss: 0.7978, Valid Loss: 0.4783
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4852
Epoch 2/10, Batch 20/97, Loss: 0.4105
Epoch 2/10, Batch 30/97, Loss: 0.3861
Epoch 2/10, Batch 40/97, Loss: 0.3305
Epoch 2/10, Batch 50/97, Loss: 0.4239
Epoch 2/10, Batch 60/97, Loss: 0.3457
Epoch 2/10, Batch 70/97, Loss: 0.3012
Epoch 2/10, Batch 80/97, Loss: 0.4394
Epoch 2/10, Batch 90/97, Loss: 0.3791
Epoch 2/10, Train Loss: 0.4020, Valid Loss: 0.3768
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2891
Epoch 3/10, Batch 20/97, Loss: 0.3292
Epoch 3/10, Batch 30/97, Loss: 0.6140
Epoch 3/10, Batch 40/97, Loss: 0.1717
Epoch 3/10, Batch 50/97, Loss: 0.5529
Epoch 3/10, Batch 60/97, Loss: 0.2758
Epoch 3/10, Batch 70/97, Loss: 0.2979
Epoch 3/10, Batch 80/97, Loss: 0.2744
Epoch 3/10, Batch 90/97, Loss: 0.2322
Epoch 3/10, Train Loss: 0.3275, Valid Loss: 0.3326
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4473
Epoch 4/10, Batch 20/97, Loss: 0.3084
Epoch 4/10, Batch 30/97, Loss: 0.2701
Epoch 4/10, Batch 40/97, Loss: 0.3038
Epoch 4/10, Batch 50/97, Loss: 0.2967
Epoch 4/10, Batch 60/97, Loss: 0.1683
Epoch 4/10, Batch 70/97, Loss: 0.4080
Epoch 4/10, Batch 80/97, Loss: 0.3424
Epoch 4/10, Batch 90/97, Loss: 0.3395
Epoch 4/10, Train Loss: 0.2813, Valid Loss: 0.3163
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2611
Epoch 5/10, Batch 20/97, Loss: 0.1784
Epoch 5/10, Batch 30/97, Loss: 0.2519
Epoch 5/10, Batch 40/97, Loss: 0.1275
Epoch 5/10, Batch 50/97, Loss: 0.3351
Epoch 5/10, Batch 60/97, Loss: 0.3100
Epoch 5/10, Batch 70/97, Loss: 0.2016
Epoch 5/10, Batch 80/97, Loss: 0.3259
Epoch 5/10, Batch 90/97, Loss: 0.4735
Epoch 5/10, Train Loss: 0.2585, Valid Loss: 0.2986
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2790
Epoch 6/10, Batch 20/97, Loss: 0.2349
Epoch 6/10, Batch 30/97, Loss: 0.2111
Epoch 6/10, Batch 40/97, Loss: 0.1412
Epoch 6/10, Batch 50/97, Loss: 0.3147
Epoch 6/10, Batch 60/97, Loss: 0.2496
Epoch 6/10, Batch 70/97, Loss: 0.2568
Epoch 6/10, Batch 80/97, Loss: 0.2785
Epoch 6/10, Batch 90/97, Loss: 0.3031
Epoch 6/10, Train Loss: 0.2362, Valid Loss: 0.2794
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1249
Epoch 7/10, Batch 20/97, Loss: 0.4014
Epoch 7/10, Batch 30/97, Loss: 0.3097
Epoch 7/10, Batch 40/97, Loss: 0.1336
Epoch 7/10, Batch 50/97, Loss: 0.3011
Epoch 7/10, Batch 60/97, Loss: 0.2913
Epoch 7/10, Batch 70/97, Loss: 0.2258
Epoch 7/10, Batch 80/97, Loss: 0.1686
Epoch 7/10, Batch 90/97, Loss: 0.1398
Epoch 7/10, Train Loss: 0.2205, Valid Loss: 0.2731
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.3163
Epoch 8/10, Batch 20/97, Loss: 0.1663
Epoch 8/10, Batch 30/97, Loss: 0.1335
Epoch 8/10, Batch 40/97, Loss: 0.1060
Epoch 8/10, Batch 50/97, Loss: 0.1597
Epoch 8/10, Batch 60/97, Loss: 0.2379
Epoch 8/10, Batch 70/97, Loss: 0.1828
Epoch 8/10, Batch 80/97, Loss: 0.1774
Epoch 8/10, Batch 90/97, Loss: 0.2116
Epoch 8/10, Train Loss: 0.2078, Valid Loss: 0.2746
Epoch 9/10, Batch 10/97, Loss: 0.2014
Epoch 9/10, Batch 20/97, Loss: 0.1076
Epoch 9/10, Batch 30/97, Loss: 0.1589
Epoch 9/10, Batch 40/97, Loss: 0.3392
Epoch 9/10, Batch 50/97, Loss: 0.1192
Epoch 9/10, Batch 60/97, Loss: 0.1138
Epoch 9/10, Batch 70/97, Loss: 0.0908
Epoch 9/10, Batch 80/97, Loss: 0.2292
Epoch 9/10, Batch 90/97, Loss: 0.2636
Epoch 9/10, Train Loss: 0.1975, Valid Loss: 0.2661
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1865
Epoch 10/10, Batch 20/97, Loss: 0.2671
Epoch 10/10, Batch 30/97, Loss: 0.1343
Epoch 10/10, Batch 40/97, Loss: 0.1722
Epoch 10/10, Batch 50/97, Loss: 0.2028
Epoch 10/10, Batch 60/97, Loss: 0.2817
Epoch 10/10, Batch 70/97, Loss: 0.1803
Epoch 10/10, Batch 80/97, Loss: 0.1395
Epoch 10/10, Batch 90/97, Loss: 0.2164
Epoch 10/10, Train Loss: 0.1935, Valid Loss: 0.2698
Accuracy: 0.9159
Precision: 0.9135
Recall: 0.9159
F1-score: 0.9145
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2656
Epoch 1/10, Batch 20/97, Loss: 1.0207
Epoch 1/10, Batch 30/97, Loss: 0.8037
Epoch 1/10, Batch 40/97, Loss: 0.7214
Epoch 1/10, Batch 50/97, Loss: 0.6366
Epoch 1/10, Batch 60/97, Loss: 0.7600
Epoch 1/10, Batch 70/97, Loss: 0.6813
Epoch 1/10, Batch 80/97, Loss: 0.5951
Epoch 1/10, Batch 90/97, Loss: 0.5087
Epoch 1/10, Train Loss: 0.8117, Valid Loss: 0.4337
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4643
Epoch 2/10, Batch 20/97, Loss: 0.4423
Epoch 2/10, Batch 30/97, Loss: 0.4913
Epoch 2/10, Batch 40/97, Loss: 0.3971
Epoch 2/10, Batch 50/97, Loss: 0.4552
Epoch 2/10, Batch 60/97, Loss: 0.5247
Epoch 2/10, Batch 70/97, Loss: 0.3003
Epoch 2/10, Batch 80/97, Loss: 0.4768
Epoch 2/10, Batch 90/97, Loss: 0.5228
Epoch 2/10, Train Loss: 0.4130, Valid Loss: 0.3186
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3700
Epoch 3/10, Batch 20/97, Loss: 0.4727
Epoch 3/10, Batch 30/97, Loss: 0.3446
Epoch 3/10, Batch 40/97, Loss: 0.2626
Epoch 3/10, Batch 50/97, Loss: 0.2948
Epoch 3/10, Batch 60/97, Loss: 0.2908
Epoch 3/10, Batch 70/97, Loss: 0.4678
Epoch 3/10, Batch 80/97, Loss: 0.1956
Epoch 3/10, Batch 90/97, Loss: 0.3428
Epoch 3/10, Train Loss: 0.3278, Valid Loss: 0.2769
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3558
Epoch 4/10, Batch 20/97, Loss: 0.2416
Epoch 4/10, Batch 30/97, Loss: 0.3263
Epoch 4/10, Batch 40/97, Loss: 0.1543
Epoch 4/10, Batch 50/97, Loss: 0.4680
Epoch 4/10, Batch 60/97, Loss: 0.3295
Epoch 4/10, Batch 70/97, Loss: 0.3487
Epoch 4/10, Batch 80/97, Loss: 0.2410
Epoch 4/10, Batch 90/97, Loss: 0.2859
Epoch 4/10, Train Loss: 0.2897, Valid Loss: 0.2513
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2551
Epoch 5/10, Batch 20/97, Loss: 0.3547
Epoch 5/10, Batch 30/97, Loss: 0.2742
Epoch 5/10, Batch 40/97, Loss: 0.3492
Epoch 5/10, Batch 50/97, Loss: 0.2410
Epoch 5/10, Batch 60/97, Loss: 0.2327
Epoch 5/10, Batch 70/97, Loss: 0.2210
Epoch 5/10, Batch 80/97, Loss: 0.3046
Epoch 5/10, Batch 90/97, Loss: 0.2955
Epoch 5/10, Train Loss: 0.2633, Valid Loss: 0.2367
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2145
Epoch 6/10, Batch 20/97, Loss: 0.4137
Epoch 6/10, Batch 30/97, Loss: 0.1510
Epoch 6/10, Batch 40/97, Loss: 0.2257
Epoch 6/10, Batch 50/97, Loss: 0.2557
Epoch 6/10, Batch 60/97, Loss: 0.2852
Epoch 6/10, Batch 70/97, Loss: 0.3133
Epoch 6/10, Batch 80/97, Loss: 0.3469
Epoch 6/10, Batch 90/97, Loss: 0.3519
Epoch 6/10, Train Loss: 0.2484, Valid Loss: 0.2259
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2065
Epoch 7/10, Batch 20/97, Loss: 0.2042
Epoch 7/10, Batch 30/97, Loss: 0.2577
Epoch 7/10, Batch 40/97, Loss: 0.0861
Epoch 7/10, Batch 50/97, Loss: 0.1690
Epoch 7/10, Batch 60/97, Loss: 0.1459
Epoch 7/10, Batch 70/97, Loss: 0.2681
Epoch 7/10, Batch 80/97, Loss: 0.2231
Epoch 7/10, Batch 90/97, Loss: 0.3046
Epoch 7/10, Train Loss: 0.2298, Valid Loss: 0.2123
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1846
Epoch 8/10, Batch 20/97, Loss: 0.1974
Epoch 8/10, Batch 30/97, Loss: 0.1549
Epoch 8/10, Batch 40/97, Loss: 0.3127
Epoch 8/10, Batch 50/97, Loss: 0.1196
Epoch 8/10, Batch 60/97, Loss: 0.1682
Epoch 8/10, Batch 70/97, Loss: 0.1134
Epoch 8/10, Batch 80/97, Loss: 0.1324
Epoch 8/10, Batch 90/97, Loss: 0.2936
Epoch 8/10, Train Loss: 0.2182, Valid Loss: 0.2176
Epoch 9/10, Batch 10/97, Loss: 0.2538
Epoch 9/10, Batch 20/97, Loss: 0.2372
Epoch 9/10, Batch 30/97, Loss: 0.2824
Epoch 9/10, Batch 40/97, Loss: 0.1978
Epoch 9/10, Batch 50/97, Loss: 0.0977
Epoch 9/10, Batch 60/97, Loss: 0.2612
Epoch 9/10, Batch 70/97, Loss: 0.1733
Epoch 9/10, Batch 80/97, Loss: 0.1462
Epoch 9/10, Batch 90/97, Loss: 0.2842
Epoch 9/10, Train Loss: 0.2095, Valid Loss: 0.2086
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1340
Epoch 10/10, Batch 20/97, Loss: 0.1574
Epoch 10/10, Batch 30/97, Loss: 0.1806
Epoch 10/10, Batch 40/97, Loss: 0.2440
Epoch 10/10, Batch 50/97, Loss: 0.1373
Epoch 10/10, Batch 60/97, Loss: 0.1008
Epoch 10/10, Batch 70/97, Loss: 0.2142
Epoch 10/10, Batch 80/97, Loss: 0.1984
Epoch 10/10, Batch 90/97, Loss: 0.1397
Epoch 10/10, Train Loss: 0.1989, Valid Loss: 0.2105
Accuracy: 0.9194
Precision: 0.9172
Recall: 0.9194
F1-score: 0.9177
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.1781
Epoch 1/10, Batch 20/97, Loss: 1.0417
Epoch 1/10, Batch 30/97, Loss: 0.7693
Epoch 1/10, Batch 40/97, Loss: 0.7173
Epoch 1/10, Batch 50/97, Loss: 0.5551
Epoch 1/10, Batch 60/97, Loss: 0.6671
Epoch 1/10, Batch 70/97, Loss: 0.5866
Epoch 1/10, Batch 80/97, Loss: 0.7097
Epoch 1/10, Batch 90/97, Loss: 0.5169
Epoch 1/10, Train Loss: 0.8004, Valid Loss: 0.4687
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5432
Epoch 2/10, Batch 20/97, Loss: 0.3035
Epoch 2/10, Batch 30/97, Loss: 0.2297
Epoch 2/10, Batch 40/97, Loss: 0.4610
Epoch 2/10, Batch 50/97, Loss: 0.2738
Epoch 2/10, Batch 60/97, Loss: 0.3752
Epoch 2/10, Batch 70/97, Loss: 0.2826
Epoch 2/10, Batch 80/97, Loss: 0.2867
Epoch 2/10, Batch 90/97, Loss: 0.3893
Epoch 2/10, Train Loss: 0.4076, Valid Loss: 0.3624
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3270
Epoch 3/10, Batch 20/97, Loss: 0.3041
Epoch 3/10, Batch 30/97, Loss: 0.3169
Epoch 3/10, Batch 40/97, Loss: 0.2508
Epoch 3/10, Batch 50/97, Loss: 0.3759
Epoch 3/10, Batch 60/97, Loss: 0.2032
Epoch 3/10, Batch 70/97, Loss: 0.4086
Epoch 3/10, Batch 80/97, Loss: 0.2483
Epoch 3/10, Batch 90/97, Loss: 0.3325
Epoch 3/10, Train Loss: 0.3301, Valid Loss: 0.3084
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4636
Epoch 4/10, Batch 20/97, Loss: 0.2453
Epoch 4/10, Batch 30/97, Loss: 0.3241
Epoch 4/10, Batch 40/97, Loss: 0.2403
Epoch 4/10, Batch 50/97, Loss: 0.3338
Epoch 4/10, Batch 60/97, Loss: 0.3076
Epoch 4/10, Batch 70/97, Loss: 0.1566
Epoch 4/10, Batch 80/97, Loss: 0.4307
Epoch 4/10, Batch 90/97, Loss: 0.1570
Epoch 4/10, Train Loss: 0.2819, Valid Loss: 0.2849
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3128
Epoch 5/10, Batch 20/97, Loss: 0.2942
Epoch 5/10, Batch 30/97, Loss: 0.2198
Epoch 5/10, Batch 40/97, Loss: 0.2395
Epoch 5/10, Batch 50/97, Loss: 0.2467
Epoch 5/10, Batch 60/97, Loss: 0.2170
Epoch 5/10, Batch 70/97, Loss: 0.2508
Epoch 5/10, Batch 80/97, Loss: 0.1904
Epoch 5/10, Batch 90/97, Loss: 0.1717
Epoch 5/10, Train Loss: 0.2653, Valid Loss: 0.2700
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2824
Epoch 6/10, Batch 20/97, Loss: 0.3757
Epoch 6/10, Batch 30/97, Loss: 0.0943
Epoch 6/10, Batch 40/97, Loss: 0.1192
Epoch 6/10, Batch 50/97, Loss: 0.2366
Epoch 6/10, Batch 60/97, Loss: 0.3385
Epoch 6/10, Batch 70/97, Loss: 0.0834
Epoch 6/10, Batch 80/97, Loss: 0.2402
Epoch 6/10, Batch 90/97, Loss: 0.4629
Epoch 6/10, Train Loss: 0.2410, Valid Loss: 0.2491
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1825
Epoch 7/10, Batch 20/97, Loss: 0.3721
Epoch 7/10, Batch 30/97, Loss: 0.2359
Epoch 7/10, Batch 40/97, Loss: 0.1350
Epoch 7/10, Batch 50/97, Loss: 0.1172
Epoch 7/10, Batch 60/97, Loss: 0.1266
Epoch 7/10, Batch 70/97, Loss: 0.1456
Epoch 7/10, Batch 80/97, Loss: 0.2179
Epoch 7/10, Batch 90/97, Loss: 0.1704
Epoch 7/10, Train Loss: 0.2206, Valid Loss: 0.2406
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1665
Epoch 8/10, Batch 20/97, Loss: 0.2191
Epoch 8/10, Batch 30/97, Loss: 0.1734
Epoch 8/10, Batch 40/97, Loss: 0.3148
Epoch 8/10, Batch 50/97, Loss: 0.1855
Epoch 8/10, Batch 60/97, Loss: 0.2609
Epoch 8/10, Batch 70/97, Loss: 0.2702
Epoch 8/10, Batch 80/97, Loss: 0.1520
Epoch 8/10, Batch 90/97, Loss: 0.1013
Epoch 8/10, Train Loss: 0.2146, Valid Loss: 0.2331
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.4056
Epoch 9/10, Batch 20/97, Loss: 0.1171
Epoch 9/10, Batch 30/97, Loss: 0.2466
Epoch 9/10, Batch 40/97, Loss: 0.2582
Epoch 9/10, Batch 50/97, Loss: 0.2990
Epoch 9/10, Batch 60/97, Loss: 0.3161
Epoch 9/10, Batch 70/97, Loss: 0.1292
Epoch 9/10, Batch 80/97, Loss: 0.2149
Epoch 9/10, Batch 90/97, Loss: 0.1565
Epoch 9/10, Train Loss: 0.2137, Valid Loss: 0.2258
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2676
Epoch 10/10, Batch 20/97, Loss: 0.1219
Epoch 10/10, Batch 30/97, Loss: 0.1667
Epoch 10/10, Batch 40/97, Loss: 0.2354
Epoch 10/10, Batch 50/97, Loss: 0.2047
Epoch 10/10, Batch 60/97, Loss: 0.1548
Epoch 10/10, Batch 70/97, Loss: 0.2277
Epoch 10/10, Batch 80/97, Loss: 0.1824
Epoch 10/10, Batch 90/97, Loss: 0.3278
Epoch 10/10, Train Loss: 0.2027, Valid Loss: 0.2248
Model saved!
Accuracy: 0.9159
Precision: 0.9133
Recall: 0.9159
F1-score: 0.9141
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2434
Epoch 1/10, Batch 20/97, Loss: 1.0650
Epoch 1/10, Batch 30/97, Loss: 0.7536
Epoch 1/10, Batch 40/97, Loss: 0.7511
Epoch 1/10, Batch 50/97, Loss: 0.6605
Epoch 1/10, Batch 60/97, Loss: 0.6482
Epoch 1/10, Batch 70/97, Loss: 0.7338
Epoch 1/10, Batch 80/97, Loss: 0.6070
Epoch 1/10, Batch 90/97, Loss: 0.5478
Epoch 1/10, Train Loss: 0.8033, Valid Loss: 0.4602
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5739
Epoch 2/10, Batch 20/97, Loss: 0.3223
Epoch 2/10, Batch 30/97, Loss: 0.3450
Epoch 2/10, Batch 40/97, Loss: 0.4568
Epoch 2/10, Batch 50/97, Loss: 0.3995
Epoch 2/10, Batch 60/97, Loss: 0.4020
Epoch 2/10, Batch 70/97, Loss: 0.1993
Epoch 2/10, Batch 80/97, Loss: 0.3546
Epoch 2/10, Batch 90/97, Loss: 0.4838
Epoch 2/10, Train Loss: 0.4138, Valid Loss: 0.3441
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4155
Epoch 3/10, Batch 20/97, Loss: 0.3749
Epoch 3/10, Batch 30/97, Loss: 0.4178
Epoch 3/10, Batch 40/97, Loss: 0.3663
Epoch 3/10, Batch 50/97, Loss: 0.2769
Epoch 3/10, Batch 60/97, Loss: 0.2515
Epoch 3/10, Batch 70/97, Loss: 0.2884
Epoch 3/10, Batch 80/97, Loss: 0.3202
Epoch 3/10, Batch 90/97, Loss: 0.3843
Epoch 3/10, Train Loss: 0.3374, Valid Loss: 0.3026
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4406
Epoch 4/10, Batch 20/97, Loss: 0.2244
Epoch 4/10, Batch 30/97, Loss: 0.2221
Epoch 4/10, Batch 40/97, Loss: 0.3365
Epoch 4/10, Batch 50/97, Loss: 0.3927
Epoch 4/10, Batch 60/97, Loss: 0.3624
Epoch 4/10, Batch 70/97, Loss: 0.2167
Epoch 4/10, Batch 80/97, Loss: 0.1954
Epoch 4/10, Batch 90/97, Loss: 0.4332
Epoch 4/10, Train Loss: 0.2925, Valid Loss: 0.2914
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2411
Epoch 5/10, Batch 20/97, Loss: 0.5479
Epoch 5/10, Batch 30/97, Loss: 0.2003
Epoch 5/10, Batch 40/97, Loss: 0.1695
Epoch 5/10, Batch 50/97, Loss: 0.2233
Epoch 5/10, Batch 60/97, Loss: 0.4559
Epoch 5/10, Batch 70/97, Loss: 0.3490
Epoch 5/10, Batch 80/97, Loss: 0.1594
Epoch 5/10, Batch 90/97, Loss: 0.1607
Epoch 5/10, Train Loss: 0.2707, Valid Loss: 0.2672
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3050
Epoch 6/10, Batch 20/97, Loss: 0.2564
Epoch 6/10, Batch 30/97, Loss: 0.2295
Epoch 6/10, Batch 40/97, Loss: 0.1512
Epoch 6/10, Batch 50/97, Loss: 0.1088
Epoch 6/10, Batch 60/97, Loss: 0.2950
Epoch 6/10, Batch 70/97, Loss: 0.1936
Epoch 6/10, Batch 80/97, Loss: 0.3501
Epoch 6/10, Batch 90/97, Loss: 0.3039
Epoch 6/10, Train Loss: 0.2519, Valid Loss: 0.2516
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2406
Epoch 7/10, Batch 20/97, Loss: 0.2784
Epoch 7/10, Batch 30/97, Loss: 0.2258
Epoch 7/10, Batch 40/97, Loss: 0.2655
Epoch 7/10, Batch 50/97, Loss: 0.1439
Epoch 7/10, Batch 60/97, Loss: 0.1234
Epoch 7/10, Batch 70/97, Loss: 0.1908
Epoch 7/10, Batch 80/97, Loss: 0.2189
Epoch 7/10, Batch 90/97, Loss: 0.1199
Epoch 7/10, Train Loss: 0.2319, Valid Loss: 0.2446
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1681
Epoch 8/10, Batch 20/97, Loss: 0.1662
Epoch 8/10, Batch 30/97, Loss: 0.0861
Epoch 8/10, Batch 40/97, Loss: 0.1990
Epoch 8/10, Batch 50/97, Loss: 0.1543
Epoch 8/10, Batch 60/97, Loss: 0.2678
Epoch 8/10, Batch 70/97, Loss: 0.1687
Epoch 8/10, Batch 80/97, Loss: 0.1121
Epoch 8/10, Batch 90/97, Loss: 0.2332
Epoch 8/10, Train Loss: 0.2230, Valid Loss: 0.2392
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1772
Epoch 9/10, Batch 20/97, Loss: 0.1023
Epoch 9/10, Batch 30/97, Loss: 0.2197
Epoch 9/10, Batch 40/97, Loss: 0.1682
Epoch 9/10, Batch 50/97, Loss: 0.2701
Epoch 9/10, Batch 60/97, Loss: 0.2865
Epoch 9/10, Batch 70/97, Loss: 0.1993
Epoch 9/10, Batch 80/97, Loss: 0.2292
Epoch 9/10, Batch 90/97, Loss: 0.1842
Epoch 9/10, Train Loss: 0.2174, Valid Loss: 0.2361
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1985
Epoch 10/10, Batch 20/97, Loss: 0.2628
Epoch 10/10, Batch 30/97, Loss: 0.1323
Epoch 10/10, Batch 40/97, Loss: 0.2334
Epoch 10/10, Batch 50/97, Loss: 0.1561
Epoch 10/10, Batch 60/97, Loss: 0.2808
Epoch 10/10, Batch 70/97, Loss: 0.2370
Epoch 10/10, Batch 80/97, Loss: 0.2498
Epoch 10/10, Batch 90/97, Loss: 0.1925
Epoch 10/10, Train Loss: 0.2015, Valid Loss: 0.2339
Model saved!
Accuracy: 0.9159
Precision: 0.9134
Recall: 0.9159
F1-score: 0.9142
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2965
Epoch 1/10, Batch 20/97, Loss: 1.0831
Epoch 1/10, Batch 30/97, Loss: 0.7918
Epoch 1/10, Batch 40/97, Loss: 0.7436
Epoch 1/10, Batch 50/97, Loss: 0.6752
Epoch 1/10, Batch 60/97, Loss: 0.7114
Epoch 1/10, Batch 70/97, Loss: 0.6587
Epoch 1/10, Batch 80/97, Loss: 0.6176
Epoch 1/10, Batch 90/97, Loss: 0.5300
Epoch 1/10, Train Loss: 0.8008, Valid Loss: 0.4509
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4174
Epoch 2/10, Batch 20/97, Loss: 0.3939
Epoch 2/10, Batch 30/97, Loss: 0.3658
Epoch 2/10, Batch 40/97, Loss: 0.4484
Epoch 2/10, Batch 50/97, Loss: 0.3191
Epoch 2/10, Batch 60/97, Loss: 0.4882
Epoch 2/10, Batch 70/97, Loss: 0.3934
Epoch 2/10, Batch 80/97, Loss: 0.4859
Epoch 2/10, Batch 90/97, Loss: 0.3619
Epoch 2/10, Train Loss: 0.4110, Valid Loss: 0.3388
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.1871
Epoch 3/10, Batch 20/97, Loss: 0.3265
Epoch 3/10, Batch 30/97, Loss: 0.4225
Epoch 3/10, Batch 40/97, Loss: 0.2872
Epoch 3/10, Batch 50/97, Loss: 0.4666
Epoch 3/10, Batch 60/97, Loss: 0.2130
Epoch 3/10, Batch 70/97, Loss: 0.3598
Epoch 3/10, Batch 80/97, Loss: 0.2518
Epoch 3/10, Batch 90/97, Loss: 0.3522
Epoch 3/10, Train Loss: 0.3372, Valid Loss: 0.2891
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2717
Epoch 4/10, Batch 20/97, Loss: 0.3076
Epoch 4/10, Batch 30/97, Loss: 0.2197
Epoch 4/10, Batch 40/97, Loss: 0.2853
Epoch 4/10, Batch 50/97, Loss: 0.4017
Epoch 4/10, Batch 60/97, Loss: 0.2230
Epoch 4/10, Batch 70/97, Loss: 0.2388
Epoch 4/10, Batch 80/97, Loss: 0.2681
Epoch 4/10, Batch 90/97, Loss: 0.2678
Epoch 4/10, Train Loss: 0.2885, Valid Loss: 0.2649
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2362
Epoch 5/10, Batch 20/97, Loss: 0.3673
Epoch 5/10, Batch 30/97, Loss: 0.3002
Epoch 5/10, Batch 40/97, Loss: 0.2166
Epoch 5/10, Batch 50/97, Loss: 0.1871
Epoch 5/10, Batch 60/97, Loss: 0.2804
Epoch 5/10, Batch 70/97, Loss: 0.3617
Epoch 5/10, Batch 80/97, Loss: 0.1896
Epoch 5/10, Batch 90/97, Loss: 0.1013
Epoch 5/10, Train Loss: 0.2617, Valid Loss: 0.2531
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1749
Epoch 6/10, Batch 20/97, Loss: 0.3180
Epoch 6/10, Batch 30/97, Loss: 0.1671
Epoch 6/10, Batch 40/97, Loss: 0.1351
Epoch 6/10, Batch 50/97, Loss: 0.2461
Epoch 6/10, Batch 60/97, Loss: 0.2281
Epoch 6/10, Batch 70/97, Loss: 0.2128
Epoch 6/10, Batch 80/97, Loss: 0.2986
Epoch 6/10, Batch 90/97, Loss: 0.3790
Epoch 6/10, Train Loss: 0.2444, Valid Loss: 0.2472
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1692
Epoch 7/10, Batch 20/97, Loss: 0.3464
Epoch 7/10, Batch 30/97, Loss: 0.1379
Epoch 7/10, Batch 40/97, Loss: 0.1448
Epoch 7/10, Batch 50/97, Loss: 0.1719
Epoch 7/10, Batch 60/97, Loss: 0.1468
Epoch 7/10, Batch 70/97, Loss: 0.2235
Epoch 7/10, Batch 80/97, Loss: 0.2994
Epoch 7/10, Batch 90/97, Loss: 0.2708
Epoch 7/10, Train Loss: 0.2345, Valid Loss: 0.2319
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1580
Epoch 8/10, Batch 20/97, Loss: 0.1607
Epoch 8/10, Batch 30/97, Loss: 0.2138
Epoch 8/10, Batch 40/97, Loss: 0.2113
Epoch 8/10, Batch 50/97, Loss: 0.2670
Epoch 8/10, Batch 60/97, Loss: 0.3419
Epoch 8/10, Batch 70/97, Loss: 0.2072
Epoch 8/10, Batch 80/97, Loss: 0.2317
Epoch 8/10, Batch 90/97, Loss: 0.2813
Epoch 8/10, Train Loss: 0.2145, Valid Loss: 0.2273
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2130
Epoch 9/10, Batch 20/97, Loss: 0.0915
Epoch 9/10, Batch 30/97, Loss: 0.2677
Epoch 9/10, Batch 40/97, Loss: 0.2264
Epoch 9/10, Batch 50/97, Loss: 0.3292
Epoch 9/10, Batch 60/97, Loss: 0.1955
Epoch 9/10, Batch 70/97, Loss: 0.1396
Epoch 9/10, Batch 80/97, Loss: 0.2019
Epoch 9/10, Batch 90/97, Loss: 0.1979
Epoch 9/10, Train Loss: 0.2115, Valid Loss: 0.2283
Epoch 10/10, Batch 10/97, Loss: 0.2206
Epoch 10/10, Batch 20/97, Loss: 0.1896
Epoch 10/10, Batch 30/97, Loss: 0.1132
Epoch 10/10, Batch 40/97, Loss: 0.1415
Epoch 10/10, Batch 50/97, Loss: 0.2046
Epoch 10/10, Batch 60/97, Loss: 0.2528
Epoch 10/10, Batch 70/97, Loss: 0.2321
Epoch 10/10, Batch 80/97, Loss: 0.1331
Epoch 10/10, Batch 90/97, Loss: 0.1655
Epoch 10/10, Train Loss: 0.2038, Valid Loss: 0.2218
Model saved!
Accuracy: 0.9159
Precision: 0.9140
Recall: 0.9159
F1-score: 0.9133
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2165
Epoch 1/10, Batch 20/97, Loss: 1.1338
Epoch 1/10, Batch 30/97, Loss: 0.7994
Epoch 1/10, Batch 40/97, Loss: 0.7132
Epoch 1/10, Batch 50/97, Loss: 0.5797
Epoch 1/10, Batch 60/97, Loss: 0.6935
Epoch 1/10, Batch 70/97, Loss: 0.5908
Epoch 1/10, Batch 80/97, Loss: 0.6708
Epoch 1/10, Batch 90/97, Loss: 0.5038
Epoch 1/10, Train Loss: 0.7969, Valid Loss: 0.4433
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4821
Epoch 2/10, Batch 20/97, Loss: 0.4393
Epoch 2/10, Batch 30/97, Loss: 0.3626
Epoch 2/10, Batch 40/97, Loss: 0.3042
Epoch 2/10, Batch 50/97, Loss: 0.2977
Epoch 2/10, Batch 60/97, Loss: 0.4510
Epoch 2/10, Batch 70/97, Loss: 0.3589
Epoch 2/10, Batch 80/97, Loss: 0.3384
Epoch 2/10, Batch 90/97, Loss: 0.5350
Epoch 2/10, Train Loss: 0.4048, Valid Loss: 0.3363
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3425
Epoch 3/10, Batch 20/97, Loss: 0.2736
Epoch 3/10, Batch 30/97, Loss: 0.3023
Epoch 3/10, Batch 40/97, Loss: 0.2694
Epoch 3/10, Batch 50/97, Loss: 0.4877
Epoch 3/10, Batch 60/97, Loss: 0.2537
Epoch 3/10, Batch 70/97, Loss: 0.4500
Epoch 3/10, Batch 80/97, Loss: 0.3120
Epoch 3/10, Batch 90/97, Loss: 0.1740
Epoch 3/10, Train Loss: 0.3270, Valid Loss: 0.2887
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4050
Epoch 4/10, Batch 20/97, Loss: 0.1533
Epoch 4/10, Batch 30/97, Loss: 0.2723
Epoch 4/10, Batch 40/97, Loss: 0.2681
Epoch 4/10, Batch 50/97, Loss: 0.2558
Epoch 4/10, Batch 60/97, Loss: 0.2889
Epoch 4/10, Batch 70/97, Loss: 0.1916
Epoch 4/10, Batch 80/97, Loss: 0.2434
Epoch 4/10, Batch 90/97, Loss: 0.1763
Epoch 4/10, Train Loss: 0.2729, Valid Loss: 0.2727
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2047
Epoch 5/10, Batch 20/97, Loss: 0.4440
Epoch 5/10, Batch 30/97, Loss: 0.1351
Epoch 5/10, Batch 40/97, Loss: 0.2256
Epoch 5/10, Batch 50/97, Loss: 0.1836
Epoch 5/10, Batch 60/97, Loss: 0.4359
Epoch 5/10, Batch 70/97, Loss: 0.2244
Epoch 5/10, Batch 80/97, Loss: 0.3144
Epoch 5/10, Batch 90/97, Loss: 0.2260
Epoch 5/10, Train Loss: 0.2617, Valid Loss: 0.2614
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1502
Epoch 6/10, Batch 20/97, Loss: 0.3224
Epoch 6/10, Batch 30/97, Loss: 0.2941
Epoch 6/10, Batch 40/97, Loss: 0.2533
Epoch 6/10, Batch 50/97, Loss: 0.3156
Epoch 6/10, Batch 60/97, Loss: 0.4411
Epoch 6/10, Batch 70/97, Loss: 0.2773
Epoch 6/10, Batch 80/97, Loss: 0.2884
Epoch 6/10, Batch 90/97, Loss: 0.4769
Epoch 6/10, Train Loss: 0.2441, Valid Loss: 0.2468
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2392
Epoch 7/10, Batch 20/97, Loss: 0.3556
Epoch 7/10, Batch 30/97, Loss: 0.2264
Epoch 7/10, Batch 40/97, Loss: 0.1282
Epoch 7/10, Batch 50/97, Loss: 0.2091
Epoch 7/10, Batch 60/97, Loss: 0.0786
Epoch 7/10, Batch 70/97, Loss: 0.2032
Epoch 7/10, Batch 80/97, Loss: 0.1993
Epoch 7/10, Batch 90/97, Loss: 0.1378
Epoch 7/10, Train Loss: 0.2174, Valid Loss: 0.2433
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2018
Epoch 8/10, Batch 20/97, Loss: 0.1233
Epoch 8/10, Batch 30/97, Loss: 0.1312
Epoch 8/10, Batch 40/97, Loss: 0.3183
Epoch 8/10, Batch 50/97, Loss: 0.2686
Epoch 8/10, Batch 60/97, Loss: 0.2261
Epoch 8/10, Batch 70/97, Loss: 0.4086
Epoch 8/10, Batch 80/97, Loss: 0.2488
Epoch 8/10, Batch 90/97, Loss: 0.1932
Epoch 8/10, Train Loss: 0.2156, Valid Loss: 0.2449
Epoch 9/10, Batch 10/97, Loss: 0.1453
Epoch 9/10, Batch 20/97, Loss: 0.1396
Epoch 9/10, Batch 30/97, Loss: 0.2937
Epoch 9/10, Batch 40/97, Loss: 0.1679
Epoch 9/10, Batch 50/97, Loss: 0.1107
Epoch 9/10, Batch 60/97, Loss: 0.1937
Epoch 9/10, Batch 70/97, Loss: 0.0898
Epoch 9/10, Batch 80/97, Loss: 0.1466
Epoch 9/10, Batch 90/97, Loss: 0.1241
Epoch 9/10, Train Loss: 0.1979, Valid Loss: 0.2303
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3285
Epoch 10/10, Batch 20/97, Loss: 0.1051
Epoch 10/10, Batch 30/97, Loss: 0.3115
Epoch 10/10, Batch 40/97, Loss: 0.1395
Epoch 10/10, Batch 50/97, Loss: 0.3116
Epoch 10/10, Batch 60/97, Loss: 0.1034
Epoch 10/10, Batch 70/97, Loss: 0.2268
Epoch 10/10, Batch 80/97, Loss: 0.1915
Epoch 10/10, Batch 90/97, Loss: 0.1879
Epoch 10/10, Train Loss: 0.1893, Valid Loss: 0.2336
Accuracy: 0.9182
Precision: 0.9155
Recall: 0.9182
F1-score: 0.9156
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2266
Epoch 1/10, Batch 20/97, Loss: 1.0887
Epoch 1/10, Batch 30/97, Loss: 0.7984
Epoch 1/10, Batch 40/97, Loss: 0.7427
Epoch 1/10, Batch 50/97, Loss: 0.6701
Epoch 1/10, Batch 60/97, Loss: 0.6626
Epoch 1/10, Batch 70/97, Loss: 0.6891
Epoch 1/10, Batch 80/97, Loss: 0.6940
Epoch 1/10, Batch 90/97, Loss: 0.5837
Epoch 1/10, Train Loss: 0.8017, Valid Loss: 0.4460
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4907
Epoch 2/10, Batch 20/97, Loss: 0.4070
Epoch 2/10, Batch 30/97, Loss: 0.3310
Epoch 2/10, Batch 40/97, Loss: 0.3862
Epoch 2/10, Batch 50/97, Loss: 0.3292
Epoch 2/10, Batch 60/97, Loss: 0.4366
Epoch 2/10, Batch 70/97, Loss: 0.3851
Epoch 2/10, Batch 80/97, Loss: 0.4310
Epoch 2/10, Batch 90/97, Loss: 0.5975
Epoch 2/10, Train Loss: 0.4160, Valid Loss: 0.3345
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3518
Epoch 3/10, Batch 20/97, Loss: 0.2785
Epoch 3/10, Batch 30/97, Loss: 0.6159
Epoch 3/10, Batch 40/97, Loss: 0.3181
Epoch 3/10, Batch 50/97, Loss: 0.5134
Epoch 3/10, Batch 60/97, Loss: 0.1990
Epoch 3/10, Batch 70/97, Loss: 0.3375
Epoch 3/10, Batch 80/97, Loss: 0.2002
Epoch 3/10, Batch 90/97, Loss: 0.3614
Epoch 3/10, Train Loss: 0.3395, Valid Loss: 0.2976
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3531
Epoch 4/10, Batch 20/97, Loss: 0.2645
Epoch 4/10, Batch 30/97, Loss: 0.4243
Epoch 4/10, Batch 40/97, Loss: 0.2396
Epoch 4/10, Batch 50/97, Loss: 0.3251
Epoch 4/10, Batch 60/97, Loss: 0.2848
Epoch 4/10, Batch 70/97, Loss: 0.1341
Epoch 4/10, Batch 80/97, Loss: 0.1925
Epoch 4/10, Batch 90/97, Loss: 0.1395
Epoch 4/10, Train Loss: 0.2893, Valid Loss: 0.2810
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2848
Epoch 5/10, Batch 20/97, Loss: 0.1410
Epoch 5/10, Batch 30/97, Loss: 0.2531
Epoch 5/10, Batch 40/97, Loss: 0.2717
Epoch 5/10, Batch 50/97, Loss: 0.3686
Epoch 5/10, Batch 60/97, Loss: 0.2335
Epoch 5/10, Batch 70/97, Loss: 0.5315
Epoch 5/10, Batch 80/97, Loss: 0.3009
Epoch 5/10, Batch 90/97, Loss: 0.2427
Epoch 5/10, Train Loss: 0.2729, Valid Loss: 0.2754
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2286
Epoch 6/10, Batch 20/97, Loss: 0.2657
Epoch 6/10, Batch 30/97, Loss: 0.1708
Epoch 6/10, Batch 40/97, Loss: 0.1065
Epoch 6/10, Batch 50/97, Loss: 0.3504
Epoch 6/10, Batch 60/97, Loss: 0.3423
Epoch 6/10, Batch 70/97, Loss: 0.1835
Epoch 6/10, Batch 80/97, Loss: 0.3407
Epoch 6/10, Batch 90/97, Loss: 0.2005
Epoch 6/10, Train Loss: 0.2521, Valid Loss: 0.2566
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1791
Epoch 7/10, Batch 20/97, Loss: 0.2746
Epoch 7/10, Batch 30/97, Loss: 0.1463
Epoch 7/10, Batch 40/97, Loss: 0.2561
Epoch 7/10, Batch 50/97, Loss: 0.1942
Epoch 7/10, Batch 60/97, Loss: 0.2864
Epoch 7/10, Batch 70/97, Loss: 0.4391
Epoch 7/10, Batch 80/97, Loss: 0.2052
Epoch 7/10, Batch 90/97, Loss: 0.2766
Epoch 7/10, Train Loss: 0.2362, Valid Loss: 0.2412
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1225
Epoch 8/10, Batch 20/97, Loss: 0.1156
Epoch 8/10, Batch 30/97, Loss: 0.3151
Epoch 8/10, Batch 40/97, Loss: 0.1884
Epoch 8/10, Batch 50/97, Loss: 0.2008
Epoch 8/10, Batch 60/97, Loss: 0.1074
Epoch 8/10, Batch 70/97, Loss: 0.2075
Epoch 8/10, Batch 80/97, Loss: 0.2457
Epoch 8/10, Batch 90/97, Loss: 0.2390
Epoch 8/10, Train Loss: 0.2271, Valid Loss: 0.2457
Epoch 9/10, Batch 10/97, Loss: 0.1975
Epoch 9/10, Batch 20/97, Loss: 0.1225
Epoch 9/10, Batch 30/97, Loss: 0.1961
Epoch 9/10, Batch 40/97, Loss: 0.1779
Epoch 9/10, Batch 50/97, Loss: 0.1517
Epoch 9/10, Batch 60/97, Loss: 0.2415
Epoch 9/10, Batch 70/97, Loss: 0.1618
Epoch 9/10, Batch 80/97, Loss: 0.1841
Epoch 9/10, Batch 90/97, Loss: 0.1686
Epoch 9/10, Train Loss: 0.2143, Valid Loss: 0.2388
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1112
Epoch 10/10, Batch 20/97, Loss: 0.2242
Epoch 10/10, Batch 30/97, Loss: 0.1363
Epoch 10/10, Batch 40/97, Loss: 0.1912
Epoch 10/10, Batch 50/97, Loss: 0.1638
Epoch 10/10, Batch 60/97, Loss: 0.2216
Epoch 10/10, Batch 70/97, Loss: 0.2307
Epoch 10/10, Batch 80/97, Loss: 0.2352
Epoch 10/10, Batch 90/97, Loss: 0.1290
Epoch 10/10, Train Loss: 0.2121, Valid Loss: 0.2323
Model saved!
Accuracy: 0.9147
Precision: 0.9117
Recall: 0.9147
F1-score: 0.9120
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2859
Epoch 1/10, Batch 20/97, Loss: 1.1160
Epoch 1/10, Batch 30/97, Loss: 0.7328
Epoch 1/10, Batch 40/97, Loss: 0.6610
Epoch 1/10, Batch 50/97, Loss: 0.5880
Epoch 1/10, Batch 60/97, Loss: 0.6160
Epoch 1/10, Batch 70/97, Loss: 0.5985
Epoch 1/10, Batch 80/97, Loss: 0.7402
Epoch 1/10, Batch 90/97, Loss: 0.4704
Epoch 1/10, Train Loss: 0.8096, Valid Loss: 0.4348
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.7106
Epoch 2/10, Batch 20/97, Loss: 0.4935
Epoch 2/10, Batch 30/97, Loss: 0.2567
Epoch 2/10, Batch 40/97, Loss: 0.4233
Epoch 2/10, Batch 50/97, Loss: 0.4307
Epoch 2/10, Batch 60/97, Loss: 0.3901
Epoch 2/10, Batch 70/97, Loss: 0.3650
Epoch 2/10, Batch 80/97, Loss: 0.3926
Epoch 2/10, Batch 90/97, Loss: 0.4865
Epoch 2/10, Train Loss: 0.4249, Valid Loss: 0.3285
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4099
Epoch 3/10, Batch 20/97, Loss: 0.3478
Epoch 3/10, Batch 30/97, Loss: 0.3886
Epoch 3/10, Batch 40/97, Loss: 0.2877
Epoch 3/10, Batch 50/97, Loss: 0.3006
Epoch 3/10, Batch 60/97, Loss: 0.1997
Epoch 3/10, Batch 70/97, Loss: 0.4795
Epoch 3/10, Batch 80/97, Loss: 0.3887
Epoch 3/10, Batch 90/97, Loss: 0.3017
Epoch 3/10, Train Loss: 0.3405, Valid Loss: 0.2990
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3714
Epoch 4/10, Batch 20/97, Loss: 0.1672
Epoch 4/10, Batch 30/97, Loss: 0.2748
Epoch 4/10, Batch 40/97, Loss: 0.3235
Epoch 4/10, Batch 50/97, Loss: 0.4129
Epoch 4/10, Batch 60/97, Loss: 0.3165
Epoch 4/10, Batch 70/97, Loss: 0.3452
Epoch 4/10, Batch 80/97, Loss: 0.1207
Epoch 4/10, Batch 90/97, Loss: 0.2156
Epoch 4/10, Train Loss: 0.3001, Valid Loss: 0.2704
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2289
Epoch 5/10, Batch 20/97, Loss: 0.3272
Epoch 5/10, Batch 30/97, Loss: 0.1981
Epoch 5/10, Batch 40/97, Loss: 0.2098
Epoch 5/10, Batch 50/97, Loss: 0.3260
Epoch 5/10, Batch 60/97, Loss: 0.2356
Epoch 5/10, Batch 70/97, Loss: 0.3135
Epoch 5/10, Batch 80/97, Loss: 0.2438
Epoch 5/10, Batch 90/97, Loss: 0.1752
Epoch 5/10, Train Loss: 0.2718, Valid Loss: 0.2578
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2420
Epoch 6/10, Batch 20/97, Loss: 0.4401
Epoch 6/10, Batch 30/97, Loss: 0.3691
Epoch 6/10, Batch 40/97, Loss: 0.2780
Epoch 6/10, Batch 50/97, Loss: 0.2006
Epoch 6/10, Batch 60/97, Loss: 0.2195
Epoch 6/10, Batch 70/97, Loss: 0.1933
Epoch 6/10, Batch 80/97, Loss: 0.4687
Epoch 6/10, Batch 90/97, Loss: 0.1815
Epoch 6/10, Train Loss: 0.2572, Valid Loss: 0.2416
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1540
Epoch 7/10, Batch 20/97, Loss: 0.1510
Epoch 7/10, Batch 30/97, Loss: 0.2395
Epoch 7/10, Batch 40/97, Loss: 0.0990
Epoch 7/10, Batch 50/97, Loss: 0.3467
Epoch 7/10, Batch 60/97, Loss: 0.1869
Epoch 7/10, Batch 70/97, Loss: 0.2951
Epoch 7/10, Batch 80/97, Loss: 0.2127
Epoch 7/10, Batch 90/97, Loss: 0.2724
Epoch 7/10, Train Loss: 0.2328, Valid Loss: 0.2308
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.4241
Epoch 8/10, Batch 20/97, Loss: 0.2530
Epoch 8/10, Batch 30/97, Loss: 0.3512
Epoch 8/10, Batch 40/97, Loss: 0.4746
Epoch 8/10, Batch 50/97, Loss: 0.3166
Epoch 8/10, Batch 60/97, Loss: 0.1453
Epoch 8/10, Batch 70/97, Loss: 0.2050
Epoch 8/10, Batch 80/97, Loss: 0.2324
Epoch 8/10, Batch 90/97, Loss: 0.2628
Epoch 8/10, Train Loss: 0.2280, Valid Loss: 0.2416
Epoch 9/10, Batch 10/97, Loss: 0.2283
Epoch 9/10, Batch 20/97, Loss: 0.1851
Epoch 9/10, Batch 30/97, Loss: 0.1001
Epoch 9/10, Batch 40/97, Loss: 0.3463
Epoch 9/10, Batch 50/97, Loss: 0.2204
Epoch 9/10, Batch 60/97, Loss: 0.2064
Epoch 9/10, Batch 70/97, Loss: 0.2078
Epoch 9/10, Batch 80/97, Loss: 0.1454
Epoch 9/10, Batch 90/97, Loss: 0.1005
Epoch 9/10, Train Loss: 0.2086, Valid Loss: 0.2243
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2161
Epoch 10/10, Batch 20/97, Loss: 0.2238
Epoch 10/10, Batch 30/97, Loss: 0.1950
Epoch 10/10, Batch 40/97, Loss: 0.0999
Epoch 10/10, Batch 50/97, Loss: 0.1833
Epoch 10/10, Batch 60/97, Loss: 0.1519
Epoch 10/10, Batch 70/97, Loss: 0.3843
Epoch 10/10, Batch 80/97, Loss: 0.2895
Epoch 10/10, Batch 90/97, Loss: 0.2146
Epoch 10/10, Train Loss: 0.2118, Valid Loss: 0.2252
Accuracy: 0.9182
Precision: 0.9155
Recall: 0.9182
F1-score: 0.9164
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2608
Epoch 1/10, Batch 20/97, Loss: 1.0926
Epoch 1/10, Batch 30/97, Loss: 0.7495
Epoch 1/10, Batch 40/97, Loss: 0.7044
Epoch 1/10, Batch 50/97, Loss: 0.6238
Epoch 1/10, Batch 60/97, Loss: 0.6565
Epoch 1/10, Batch 70/97, Loss: 0.8518
Epoch 1/10, Batch 80/97, Loss: 0.5340
Epoch 1/10, Batch 90/97, Loss: 0.5068
Epoch 1/10, Train Loss: 0.8030, Valid Loss: 0.4278
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4784
Epoch 2/10, Batch 20/97, Loss: 0.4146
Epoch 2/10, Batch 30/97, Loss: 0.2924
Epoch 2/10, Batch 40/97, Loss: 0.3799
Epoch 2/10, Batch 50/97, Loss: 0.3232
Epoch 2/10, Batch 60/97, Loss: 0.4740
Epoch 2/10, Batch 70/97, Loss: 0.2937
Epoch 2/10, Batch 80/97, Loss: 0.4644
Epoch 2/10, Batch 90/97, Loss: 0.4317
Epoch 2/10, Train Loss: 0.4117, Valid Loss: 0.3168
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3988
Epoch 3/10, Batch 20/97, Loss: 0.2423
Epoch 3/10, Batch 30/97, Loss: 0.4232
Epoch 3/10, Batch 40/97, Loss: 0.3274
Epoch 3/10, Batch 50/97, Loss: 0.3291
Epoch 3/10, Batch 60/97, Loss: 0.3175
Epoch 3/10, Batch 70/97, Loss: 0.2825
Epoch 3/10, Batch 80/97, Loss: 0.3529
Epoch 3/10, Batch 90/97, Loss: 0.2704
Epoch 3/10, Train Loss: 0.3320, Valid Loss: 0.2709
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3708
Epoch 4/10, Batch 20/97, Loss: 0.2430
Epoch 4/10, Batch 30/97, Loss: 0.3388
Epoch 4/10, Batch 40/97, Loss: 0.1912
Epoch 4/10, Batch 50/97, Loss: 0.2476
Epoch 4/10, Batch 60/97, Loss: 0.3469
Epoch 4/10, Batch 70/97, Loss: 0.2469
Epoch 4/10, Batch 80/97, Loss: 0.1700
Epoch 4/10, Batch 90/97, Loss: 0.1902
Epoch 4/10, Train Loss: 0.2786, Valid Loss: 0.2479
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1908
Epoch 5/10, Batch 20/97, Loss: 0.3272
Epoch 5/10, Batch 30/97, Loss: 0.2157
Epoch 5/10, Batch 40/97, Loss: 0.3001
Epoch 5/10, Batch 50/97, Loss: 0.3145
Epoch 5/10, Batch 60/97, Loss: 0.2563
Epoch 5/10, Batch 70/97, Loss: 0.2128
Epoch 5/10, Batch 80/97, Loss: 0.2217
Epoch 5/10, Batch 90/97, Loss: 0.2013
Epoch 5/10, Train Loss: 0.2589, Valid Loss: 0.2353
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2901
Epoch 6/10, Batch 20/97, Loss: 0.3231
Epoch 6/10, Batch 30/97, Loss: 0.1835
Epoch 6/10, Batch 40/97, Loss: 0.1546
Epoch 6/10, Batch 50/97, Loss: 0.2899
Epoch 6/10, Batch 60/97, Loss: 0.3072
Epoch 6/10, Batch 70/97, Loss: 0.2327
Epoch 6/10, Batch 80/97, Loss: 0.2800
Epoch 6/10, Batch 90/97, Loss: 0.2513
Epoch 6/10, Train Loss: 0.2362, Valid Loss: 0.2273
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2817
Epoch 7/10, Batch 20/97, Loss: 0.2379
Epoch 7/10, Batch 30/97, Loss: 0.1630
Epoch 7/10, Batch 40/97, Loss: 0.1664
Epoch 7/10, Batch 50/97, Loss: 0.2260
Epoch 7/10, Batch 60/97, Loss: 0.2872
Epoch 7/10, Batch 70/97, Loss: 0.2462
Epoch 7/10, Batch 80/97, Loss: 0.2167
Epoch 7/10, Batch 90/97, Loss: 0.1239
Epoch 7/10, Train Loss: 0.2233, Valid Loss: 0.2206
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1712
Epoch 8/10, Batch 20/97, Loss: 0.3160
Epoch 8/10, Batch 30/97, Loss: 0.3002
Epoch 8/10, Batch 40/97, Loss: 0.2212
Epoch 8/10, Batch 50/97, Loss: 0.2431
Epoch 8/10, Batch 60/97, Loss: 0.1891
Epoch 8/10, Batch 70/97, Loss: 0.1487
Epoch 8/10, Batch 80/97, Loss: 0.1635
Epoch 8/10, Batch 90/97, Loss: 0.3124
Epoch 8/10, Train Loss: 0.2204, Valid Loss: 0.2125
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1274
Epoch 9/10, Batch 20/97, Loss: 0.2709
Epoch 9/10, Batch 30/97, Loss: 0.3126
Epoch 9/10, Batch 40/97, Loss: 0.1598
Epoch 9/10, Batch 50/97, Loss: 0.1136
Epoch 9/10, Batch 60/97, Loss: 0.1609
Epoch 9/10, Batch 70/97, Loss: 0.1893
Epoch 9/10, Batch 80/97, Loss: 0.1279
Epoch 9/10, Batch 90/97, Loss: 0.1683
Epoch 9/10, Train Loss: 0.2075, Valid Loss: 0.2151
Epoch 10/10, Batch 10/97, Loss: 0.2184
Epoch 10/10, Batch 20/97, Loss: 0.0950
Epoch 10/10, Batch 30/97, Loss: 0.2738
Epoch 10/10, Batch 40/97, Loss: 0.1767
Epoch 10/10, Batch 50/97, Loss: 0.1662
Epoch 10/10, Batch 60/97, Loss: 0.0623
Epoch 10/10, Batch 70/97, Loss: 0.2154
Epoch 10/10, Batch 80/97, Loss: 0.1824
Epoch 10/10, Batch 90/97, Loss: 0.1491
Epoch 10/10, Train Loss: 0.2001, Valid Loss: 0.2156
Accuracy: 0.9112
Precision: 0.9080
Recall: 0.9112
F1-score: 0.9090
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2309
Epoch 1/10, Batch 20/97, Loss: 1.1371
Epoch 1/10, Batch 30/97, Loss: 0.7922
Epoch 1/10, Batch 40/97, Loss: 0.7364
Epoch 1/10, Batch 50/97, Loss: 0.5943
Epoch 1/10, Batch 60/97, Loss: 0.7874
Epoch 1/10, Batch 70/97, Loss: 0.7033
Epoch 1/10, Batch 80/97, Loss: 0.6813
Epoch 1/10, Batch 90/97, Loss: 0.4457
Epoch 1/10, Train Loss: 0.8036, Valid Loss: 0.4349
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5517
Epoch 2/10, Batch 20/97, Loss: 0.4855
Epoch 2/10, Batch 30/97, Loss: 0.3924
Epoch 2/10, Batch 40/97, Loss: 0.3968
Epoch 2/10, Batch 50/97, Loss: 0.4331
Epoch 2/10, Batch 60/97, Loss: 0.4045
Epoch 2/10, Batch 70/97, Loss: 0.3517
Epoch 2/10, Batch 80/97, Loss: 0.3687
Epoch 2/10, Batch 90/97, Loss: 0.3867
Epoch 2/10, Train Loss: 0.4158, Valid Loss: 0.3253
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3882
Epoch 3/10, Batch 20/97, Loss: 0.3932
Epoch 3/10, Batch 30/97, Loss: 0.5298
Epoch 3/10, Batch 40/97, Loss: 0.2820
Epoch 3/10, Batch 50/97, Loss: 0.5218
Epoch 3/10, Batch 60/97, Loss: 0.2214
Epoch 3/10, Batch 70/97, Loss: 0.3264
Epoch 3/10, Batch 80/97, Loss: 0.3230
Epoch 3/10, Batch 90/97, Loss: 0.2146
Epoch 3/10, Train Loss: 0.3443, Valid Loss: 0.2825
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3043
Epoch 4/10, Batch 20/97, Loss: 0.2695
Epoch 4/10, Batch 30/97, Loss: 0.2622
Epoch 4/10, Batch 40/97, Loss: 0.1905
Epoch 4/10, Batch 50/97, Loss: 0.4276
Epoch 4/10, Batch 60/97, Loss: 0.2063
Epoch 4/10, Batch 70/97, Loss: 0.2654
Epoch 4/10, Batch 80/97, Loss: 0.3575
Epoch 4/10, Batch 90/97, Loss: 0.1634
Epoch 4/10, Train Loss: 0.2894, Valid Loss: 0.2672
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2044
Epoch 5/10, Batch 20/97, Loss: 0.3065
Epoch 5/10, Batch 30/97, Loss: 0.1390
Epoch 5/10, Batch 40/97, Loss: 0.2575
Epoch 5/10, Batch 50/97, Loss: 0.2971
Epoch 5/10, Batch 60/97, Loss: 0.1405
Epoch 5/10, Batch 70/97, Loss: 0.3797
Epoch 5/10, Batch 80/97, Loss: 0.2932
Epoch 5/10, Batch 90/97, Loss: 0.5186
Epoch 5/10, Train Loss: 0.2698, Valid Loss: 0.2661
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2452
Epoch 6/10, Batch 20/97, Loss: 0.3367
Epoch 6/10, Batch 30/97, Loss: 0.2634
Epoch 6/10, Batch 40/97, Loss: 0.2667
Epoch 6/10, Batch 50/97, Loss: 0.1645
Epoch 6/10, Batch 60/97, Loss: 0.2917
Epoch 6/10, Batch 70/97, Loss: 0.2380
Epoch 6/10, Batch 80/97, Loss: 0.3505
Epoch 6/10, Batch 90/97, Loss: 0.3934
Epoch 6/10, Train Loss: 0.2515, Valid Loss: 0.2421
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1979
Epoch 7/10, Batch 20/97, Loss: 0.1801
Epoch 7/10, Batch 30/97, Loss: 0.1671
Epoch 7/10, Batch 40/97, Loss: 0.2138
Epoch 7/10, Batch 50/97, Loss: 0.1998
Epoch 7/10, Batch 60/97, Loss: 0.1252
Epoch 7/10, Batch 70/97, Loss: 0.2394
Epoch 7/10, Batch 80/97, Loss: 0.1843
Epoch 7/10, Batch 90/97, Loss: 0.1444
Epoch 7/10, Train Loss: 0.2207, Valid Loss: 0.2407
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2505
Epoch 8/10, Batch 20/97, Loss: 0.1306
Epoch 8/10, Batch 30/97, Loss: 0.1730
Epoch 8/10, Batch 40/97, Loss: 0.2248
Epoch 8/10, Batch 50/97, Loss: 0.2380
Epoch 8/10, Batch 60/97, Loss: 0.1118
Epoch 8/10, Batch 70/97, Loss: 0.1508
Epoch 8/10, Batch 80/97, Loss: 0.1972
Epoch 8/10, Batch 90/97, Loss: 0.2135
Epoch 8/10, Train Loss: 0.2131, Valid Loss: 0.2390
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1506
Epoch 9/10, Batch 20/97, Loss: 0.1036
Epoch 9/10, Batch 30/97, Loss: 0.2234
Epoch 9/10, Batch 40/97, Loss: 0.2832
Epoch 9/10, Batch 50/97, Loss: 0.1596
Epoch 9/10, Batch 60/97, Loss: 0.2160
Epoch 9/10, Batch 70/97, Loss: 0.1297
Epoch 9/10, Batch 80/97, Loss: 0.1010
Epoch 9/10, Batch 90/97, Loss: 0.1091
Epoch 9/10, Train Loss: 0.2141, Valid Loss: 0.2342
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1856
Epoch 10/10, Batch 20/97, Loss: 0.1630
Epoch 10/10, Batch 30/97, Loss: 0.2271
Epoch 10/10, Batch 40/97, Loss: 0.1275
Epoch 10/10, Batch 50/97, Loss: 0.1790
Epoch 10/10, Batch 60/97, Loss: 0.1567
Epoch 10/10, Batch 70/97, Loss: 0.2327
Epoch 10/10, Batch 80/97, Loss: 0.2009
Epoch 10/10, Batch 90/97, Loss: 0.1440
Epoch 10/10, Train Loss: 0.2011, Valid Loss: 0.2388
Accuracy: 0.9147
Precision: 0.9124
Recall: 0.9147
F1-score: 0.9133
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2237
Epoch 1/10, Batch 20/97, Loss: 1.0779
Epoch 1/10, Batch 30/97, Loss: 0.6903
Epoch 1/10, Batch 40/97, Loss: 0.7533
Epoch 1/10, Batch 50/97, Loss: 0.5616
Epoch 1/10, Batch 60/97, Loss: 0.6408
Epoch 1/10, Batch 70/97, Loss: 0.6254
Epoch 1/10, Batch 80/97, Loss: 0.7559
Epoch 1/10, Batch 90/97, Loss: 0.5159
Epoch 1/10, Train Loss: 0.7924, Valid Loss: 0.4447
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6071
Epoch 2/10, Batch 20/97, Loss: 0.4728
Epoch 2/10, Batch 30/97, Loss: 0.2404
Epoch 2/10, Batch 40/97, Loss: 0.3267
Epoch 2/10, Batch 50/97, Loss: 0.3387
Epoch 2/10, Batch 60/97, Loss: 0.3753
Epoch 2/10, Batch 70/97, Loss: 0.3778
Epoch 2/10, Batch 80/97, Loss: 0.2853
Epoch 2/10, Batch 90/97, Loss: 0.4633
Epoch 2/10, Train Loss: 0.4116, Valid Loss: 0.3287
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4105
Epoch 3/10, Batch 20/97, Loss: 0.4059
Epoch 3/10, Batch 30/97, Loss: 0.2353
Epoch 3/10, Batch 40/97, Loss: 0.3030
Epoch 3/10, Batch 50/97, Loss: 0.5801
Epoch 3/10, Batch 60/97, Loss: 0.2430
Epoch 3/10, Batch 70/97, Loss: 0.3609
Epoch 3/10, Batch 80/97, Loss: 0.2371
Epoch 3/10, Batch 90/97, Loss: 0.3161
Epoch 3/10, Train Loss: 0.3367, Valid Loss: 0.2815
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2530
Epoch 4/10, Batch 20/97, Loss: 0.3211
Epoch 4/10, Batch 30/97, Loss: 0.2622
Epoch 4/10, Batch 40/97, Loss: 0.1540
Epoch 4/10, Batch 50/97, Loss: 0.3151
Epoch 4/10, Batch 60/97, Loss: 0.2289
Epoch 4/10, Batch 70/97, Loss: 0.2998
Epoch 4/10, Batch 80/97, Loss: 0.2623
Epoch 4/10, Batch 90/97, Loss: 0.1581
Epoch 4/10, Train Loss: 0.2839, Valid Loss: 0.2655
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2908
Epoch 5/10, Batch 20/97, Loss: 0.2536
Epoch 5/10, Batch 30/97, Loss: 0.2449
Epoch 5/10, Batch 40/97, Loss: 0.3856
Epoch 5/10, Batch 50/97, Loss: 0.1968
Epoch 5/10, Batch 60/97, Loss: 0.1697
Epoch 5/10, Batch 70/97, Loss: 0.2921
Epoch 5/10, Batch 80/97, Loss: 0.2018
Epoch 5/10, Batch 90/97, Loss: 0.1929
Epoch 5/10, Train Loss: 0.2669, Valid Loss: 0.2519
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.0890
Epoch 6/10, Batch 20/97, Loss: 0.2397
Epoch 6/10, Batch 30/97, Loss: 0.1246
Epoch 6/10, Batch 40/97, Loss: 0.1612
Epoch 6/10, Batch 50/97, Loss: 0.2099
Epoch 6/10, Batch 60/97, Loss: 0.2483
Epoch 6/10, Batch 70/97, Loss: 0.3217
Epoch 6/10, Batch 80/97, Loss: 0.2691
Epoch 6/10, Batch 90/97, Loss: 0.2375
Epoch 6/10, Train Loss: 0.2482, Valid Loss: 0.2309
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1360
Epoch 7/10, Batch 20/97, Loss: 0.2896
Epoch 7/10, Batch 30/97, Loss: 0.2067
Epoch 7/10, Batch 40/97, Loss: 0.1483
Epoch 7/10, Batch 50/97, Loss: 0.1537
Epoch 7/10, Batch 60/97, Loss: 0.1099
Epoch 7/10, Batch 70/97, Loss: 0.3567
Epoch 7/10, Batch 80/97, Loss: 0.2050
Epoch 7/10, Batch 90/97, Loss: 0.1184
Epoch 7/10, Train Loss: 0.2256, Valid Loss: 0.2297
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2794
Epoch 8/10, Batch 20/97, Loss: 0.1501
Epoch 8/10, Batch 30/97, Loss: 0.2250
Epoch 8/10, Batch 40/97, Loss: 0.1846
Epoch 8/10, Batch 50/97, Loss: 0.2940
Epoch 8/10, Batch 60/97, Loss: 0.1915
Epoch 8/10, Batch 70/97, Loss: 0.2706
Epoch 8/10, Batch 80/97, Loss: 0.1009
Epoch 8/10, Batch 90/97, Loss: 0.1915
Epoch 8/10, Train Loss: 0.2188, Valid Loss: 0.2222
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2209
Epoch 9/10, Batch 20/97, Loss: 0.2015
Epoch 9/10, Batch 30/97, Loss: 0.3126
Epoch 9/10, Batch 40/97, Loss: 0.2012
Epoch 9/10, Batch 50/97, Loss: 0.0988
Epoch 9/10, Batch 60/97, Loss: 0.1669
Epoch 9/10, Batch 70/97, Loss: 0.1744
Epoch 9/10, Batch 80/97, Loss: 0.1701
Epoch 9/10, Batch 90/97, Loss: 0.2286
Epoch 9/10, Train Loss: 0.2061, Valid Loss: 0.2108
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1983
Epoch 10/10, Batch 20/97, Loss: 0.1346
Epoch 10/10, Batch 30/97, Loss: 0.1608
Epoch 10/10, Batch 40/97, Loss: 0.1755
Epoch 10/10, Batch 50/97, Loss: 0.1852
Epoch 10/10, Batch 60/97, Loss: 0.1508
Epoch 10/10, Batch 70/97, Loss: 0.1874
Epoch 10/10, Batch 80/97, Loss: 0.2290
Epoch 10/10, Batch 90/97, Loss: 0.1864
Epoch 10/10, Train Loss: 0.2030, Valid Loss: 0.2184
Accuracy: 0.9065
Precision: 0.9040
Recall: 0.9065
F1-score: 0.9048
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2611
Epoch 1/10, Batch 20/97, Loss: 1.1232
Epoch 1/10, Batch 30/97, Loss: 0.6896
Epoch 1/10, Batch 40/97, Loss: 0.6842
Epoch 1/10, Batch 50/97, Loss: 0.5349
Epoch 1/10, Batch 60/97, Loss: 0.8551
Epoch 1/10, Batch 70/97, Loss: 0.6791
Epoch 1/10, Batch 80/97, Loss: 0.5922
Epoch 1/10, Batch 90/97, Loss: 0.5376
Epoch 1/10, Train Loss: 0.8109, Valid Loss: 0.4140
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.7098
Epoch 2/10, Batch 20/97, Loss: 0.5096
Epoch 2/10, Batch 30/97, Loss: 0.2929
Epoch 2/10, Batch 40/97, Loss: 0.3690
Epoch 2/10, Batch 50/97, Loss: 0.5507
Epoch 2/10, Batch 60/97, Loss: 0.4888
Epoch 2/10, Batch 70/97, Loss: 0.2416
Epoch 2/10, Batch 80/97, Loss: 0.3273
Epoch 2/10, Batch 90/97, Loss: 0.3346
Epoch 2/10, Train Loss: 0.4128, Valid Loss: 0.3097
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4286
Epoch 3/10, Batch 20/97, Loss: 0.3401
Epoch 3/10, Batch 30/97, Loss: 0.4248
Epoch 3/10, Batch 40/97, Loss: 0.3603
Epoch 3/10, Batch 50/97, Loss: 0.3317
Epoch 3/10, Batch 60/97, Loss: 0.2968
Epoch 3/10, Batch 70/97, Loss: 0.3675
Epoch 3/10, Batch 80/97, Loss: 0.3251
Epoch 3/10, Batch 90/97, Loss: 0.2530
Epoch 3/10, Train Loss: 0.3330, Valid Loss: 0.2679
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4058
Epoch 4/10, Batch 20/97, Loss: 0.2125
Epoch 4/10, Batch 30/97, Loss: 0.3274
Epoch 4/10, Batch 40/97, Loss: 0.2959
Epoch 4/10, Batch 50/97, Loss: 0.3608
Epoch 4/10, Batch 60/97, Loss: 0.2703
Epoch 4/10, Batch 70/97, Loss: 0.2908
Epoch 4/10, Batch 80/97, Loss: 0.3114
Epoch 4/10, Batch 90/97, Loss: 0.2201
Epoch 4/10, Train Loss: 0.2873, Valid Loss: 0.2437
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2697
Epoch 5/10, Batch 20/97, Loss: 0.2522
Epoch 5/10, Batch 30/97, Loss: 0.3363
Epoch 5/10, Batch 40/97, Loss: 0.3294
Epoch 5/10, Batch 50/97, Loss: 0.2943
Epoch 5/10, Batch 60/97, Loss: 0.2837
Epoch 5/10, Batch 70/97, Loss: 0.1929
Epoch 5/10, Batch 80/97, Loss: 0.3123
Epoch 5/10, Batch 90/97, Loss: 0.1426
Epoch 5/10, Train Loss: 0.2563, Valid Loss: 0.2305
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2125
Epoch 6/10, Batch 20/97, Loss: 0.3099
Epoch 6/10, Batch 30/97, Loss: 0.1156
Epoch 6/10, Batch 40/97, Loss: 0.2584
Epoch 6/10, Batch 50/97, Loss: 0.1669
Epoch 6/10, Batch 60/97, Loss: 0.3625
Epoch 6/10, Batch 70/97, Loss: 0.2257
Epoch 6/10, Batch 80/97, Loss: 0.2786
Epoch 6/10, Batch 90/97, Loss: 0.4301
Epoch 6/10, Train Loss: 0.2425, Valid Loss: 0.2169
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2265
Epoch 7/10, Batch 20/97, Loss: 0.2429
Epoch 7/10, Batch 30/97, Loss: 0.1781
Epoch 7/10, Batch 40/97, Loss: 0.1013
Epoch 7/10, Batch 50/97, Loss: 0.1643
Epoch 7/10, Batch 60/97, Loss: 0.2832
Epoch 7/10, Batch 70/97, Loss: 0.2073
Epoch 7/10, Batch 80/97, Loss: 0.2591
Epoch 7/10, Batch 90/97, Loss: 0.1632
Epoch 7/10, Train Loss: 0.2235, Valid Loss: 0.2083
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2483
Epoch 8/10, Batch 20/97, Loss: 0.1501
Epoch 8/10, Batch 30/97, Loss: 0.1988
Epoch 8/10, Batch 40/97, Loss: 0.2543
Epoch 8/10, Batch 50/97, Loss: 0.1794
Epoch 8/10, Batch 60/97, Loss: 0.1774
Epoch 8/10, Batch 70/97, Loss: 0.2707
Epoch 8/10, Batch 80/97, Loss: 0.2271
Epoch 8/10, Batch 90/97, Loss: 0.1777
Epoch 8/10, Train Loss: 0.2127, Valid Loss: 0.2049
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0827
Epoch 9/10, Batch 20/97, Loss: 0.0909
Epoch 9/10, Batch 30/97, Loss: 0.1766
Epoch 9/10, Batch 40/97, Loss: 0.4477
Epoch 9/10, Batch 50/97, Loss: 0.1641
Epoch 9/10, Batch 60/97, Loss: 0.2321
Epoch 9/10, Batch 70/97, Loss: 0.1312
Epoch 9/10, Batch 80/97, Loss: 0.2244
Epoch 9/10, Batch 90/97, Loss: 0.1310
Epoch 9/10, Train Loss: 0.1996, Valid Loss: 0.1963
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3194
Epoch 10/10, Batch 20/97, Loss: 0.2973
Epoch 10/10, Batch 30/97, Loss: 0.0760
Epoch 10/10, Batch 40/97, Loss: 0.1341
Epoch 10/10, Batch 50/97, Loss: 0.1846
Epoch 10/10, Batch 60/97, Loss: 0.1954
Epoch 10/10, Batch 70/97, Loss: 0.2924
Epoch 10/10, Batch 80/97, Loss: 0.1788
Epoch 10/10, Batch 90/97, Loss: 0.2436
Epoch 10/10, Train Loss: 0.1991, Valid Loss: 0.1999
Accuracy: 0.9147
Precision: 0.9121
Recall: 0.9147
F1-score: 0.9129
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2603
Epoch 1/10, Batch 20/97, Loss: 1.2008
Epoch 1/10, Batch 30/97, Loss: 0.7209
Epoch 1/10, Batch 40/97, Loss: 0.6446
Epoch 1/10, Batch 50/97, Loss: 0.6187
Epoch 1/10, Batch 60/97, Loss: 0.5865
Epoch 1/10, Batch 70/97, Loss: 0.8201
Epoch 1/10, Batch 80/97, Loss: 0.6479
Epoch 1/10, Batch 90/97, Loss: 0.4871
Epoch 1/10, Train Loss: 0.7924, Valid Loss: 0.4674
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5603
Epoch 2/10, Batch 20/97, Loss: 0.4378
Epoch 2/10, Batch 30/97, Loss: 0.3114
Epoch 2/10, Batch 40/97, Loss: 0.3383
Epoch 2/10, Batch 50/97, Loss: 0.5501
Epoch 2/10, Batch 60/97, Loss: 0.3530
Epoch 2/10, Batch 70/97, Loss: 0.3694
Epoch 2/10, Batch 80/97, Loss: 0.4416
Epoch 2/10, Batch 90/97, Loss: 0.4338
Epoch 2/10, Train Loss: 0.3961, Valid Loss: 0.3633
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3842
Epoch 3/10, Batch 20/97, Loss: 0.3607
Epoch 3/10, Batch 30/97, Loss: 0.5197
Epoch 3/10, Batch 40/97, Loss: 0.2774
Epoch 3/10, Batch 50/97, Loss: 0.3402
Epoch 3/10, Batch 60/97, Loss: 0.1947
Epoch 3/10, Batch 70/97, Loss: 0.3515
Epoch 3/10, Batch 80/97, Loss: 0.2701
Epoch 3/10, Batch 90/97, Loss: 0.3083
Epoch 3/10, Train Loss: 0.3151, Valid Loss: 0.3189
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3981
Epoch 4/10, Batch 20/97, Loss: 0.2273
Epoch 4/10, Batch 30/97, Loss: 0.1619
Epoch 4/10, Batch 40/97, Loss: 0.2381
Epoch 4/10, Batch 50/97, Loss: 0.3056
Epoch 4/10, Batch 60/97, Loss: 0.1416
Epoch 4/10, Batch 70/97, Loss: 0.2146
Epoch 4/10, Batch 80/97, Loss: 0.1556
Epoch 4/10, Batch 90/97, Loss: 0.2481
Epoch 4/10, Train Loss: 0.2723, Valid Loss: 0.3014
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1883
Epoch 5/10, Batch 20/97, Loss: 0.3017
Epoch 5/10, Batch 30/97, Loss: 0.1755
Epoch 5/10, Batch 40/97, Loss: 0.2882
Epoch 5/10, Batch 50/97, Loss: 0.3386
Epoch 5/10, Batch 60/97, Loss: 0.2503
Epoch 5/10, Batch 70/97, Loss: 0.2819
Epoch 5/10, Batch 80/97, Loss: 0.1897
Epoch 5/10, Batch 90/97, Loss: 0.2634
Epoch 5/10, Train Loss: 0.2523, Valid Loss: 0.2833
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1978
Epoch 6/10, Batch 20/97, Loss: 0.2070
Epoch 6/10, Batch 30/97, Loss: 0.1930
Epoch 6/10, Batch 40/97, Loss: 0.3217
Epoch 6/10, Batch 50/97, Loss: 0.2176
Epoch 6/10, Batch 60/97, Loss: 0.3390
Epoch 6/10, Batch 70/97, Loss: 0.2821
Epoch 6/10, Batch 80/97, Loss: 0.3932
Epoch 6/10, Batch 90/97, Loss: 0.2730
Epoch 6/10, Train Loss: 0.2270, Valid Loss: 0.2663
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2517
Epoch 7/10, Batch 20/97, Loss: 0.3076
Epoch 7/10, Batch 30/97, Loss: 0.1503
Epoch 7/10, Batch 40/97, Loss: 0.1111
Epoch 7/10, Batch 50/97, Loss: 0.3182
Epoch 7/10, Batch 60/97, Loss: 0.1118
Epoch 7/10, Batch 70/97, Loss: 0.1545
Epoch 7/10, Batch 80/97, Loss: 0.3027
Epoch 7/10, Batch 90/97, Loss: 0.2058
Epoch 7/10, Train Loss: 0.2143, Valid Loss: 0.2628
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1260
Epoch 8/10, Batch 20/97, Loss: 0.1622
Epoch 8/10, Batch 30/97, Loss: 0.1633
Epoch 8/10, Batch 40/97, Loss: 0.1748
Epoch 8/10, Batch 50/97, Loss: 0.2131
Epoch 8/10, Batch 60/97, Loss: 0.2901
Epoch 8/10, Batch 70/97, Loss: 0.1421
Epoch 8/10, Batch 80/97, Loss: 0.3007
Epoch 8/10, Batch 90/97, Loss: 0.1266
Epoch 8/10, Train Loss: 0.1993, Valid Loss: 0.2564
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0951
Epoch 9/10, Batch 20/97, Loss: 0.1470
Epoch 9/10, Batch 30/97, Loss: 0.2644
Epoch 9/10, Batch 40/97, Loss: 0.2712
Epoch 9/10, Batch 50/97, Loss: 0.1969
Epoch 9/10, Batch 60/97, Loss: 0.2281
Epoch 9/10, Batch 70/97, Loss: 0.1354
Epoch 9/10, Batch 80/97, Loss: 0.4365
Epoch 9/10, Batch 90/97, Loss: 0.1188
Epoch 9/10, Train Loss: 0.1937, Valid Loss: 0.2483
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1696
Epoch 10/10, Batch 20/97, Loss: 0.1405
Epoch 10/10, Batch 30/97, Loss: 0.1786
Epoch 10/10, Batch 40/97, Loss: 0.1410
Epoch 10/10, Batch 50/97, Loss: 0.1831
Epoch 10/10, Batch 60/97, Loss: 0.2276
Epoch 10/10, Batch 70/97, Loss: 0.2231
Epoch 10/10, Batch 80/97, Loss: 0.2604
Epoch 10/10, Batch 90/97, Loss: 0.1139
Epoch 10/10, Train Loss: 0.1866, Valid Loss: 0.2572
Accuracy: 0.9182
Precision: 0.9153
Recall: 0.9182
F1-score: 0.9158
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2371
Epoch 1/10, Batch 20/97, Loss: 1.0525
Epoch 1/10, Batch 30/97, Loss: 0.7452
Epoch 1/10, Batch 40/97, Loss: 0.6496
Epoch 1/10, Batch 50/97, Loss: 0.5553
Epoch 1/10, Batch 60/97, Loss: 0.7333
Epoch 1/10, Batch 70/97, Loss: 0.6386
Epoch 1/10, Batch 80/97, Loss: 0.6601
Epoch 1/10, Batch 90/97, Loss: 0.5503
Epoch 1/10, Train Loss: 0.7996, Valid Loss: 0.4536
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5387
Epoch 2/10, Batch 20/97, Loss: 0.5112
Epoch 2/10, Batch 30/97, Loss: 0.3419
Epoch 2/10, Batch 40/97, Loss: 0.3608
Epoch 2/10, Batch 50/97, Loss: 0.4233
Epoch 2/10, Batch 60/97, Loss: 0.3546
Epoch 2/10, Batch 70/97, Loss: 0.3293
Epoch 2/10, Batch 80/97, Loss: 0.4403
Epoch 2/10, Batch 90/97, Loss: 0.4416
Epoch 2/10, Train Loss: 0.4102, Valid Loss: 0.3344
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3009
Epoch 3/10, Batch 20/97, Loss: 0.2674
Epoch 3/10, Batch 30/97, Loss: 0.4099
Epoch 3/10, Batch 40/97, Loss: 0.3441
Epoch 3/10, Batch 50/97, Loss: 0.4426
Epoch 3/10, Batch 60/97, Loss: 0.5095
Epoch 3/10, Batch 70/97, Loss: 0.3483
Epoch 3/10, Batch 80/97, Loss: 0.4211
Epoch 3/10, Batch 90/97, Loss: 0.1430
Epoch 3/10, Train Loss: 0.3363, Valid Loss: 0.2899
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4268
Epoch 4/10, Batch 20/97, Loss: 0.3248
Epoch 4/10, Batch 30/97, Loss: 0.2422
Epoch 4/10, Batch 40/97, Loss: 0.3648
Epoch 4/10, Batch 50/97, Loss: 0.4681
Epoch 4/10, Batch 60/97, Loss: 0.2433
Epoch 4/10, Batch 70/97, Loss: 0.2549
Epoch 4/10, Batch 80/97, Loss: 0.2966
Epoch 4/10, Batch 90/97, Loss: 0.3316
Epoch 4/10, Train Loss: 0.2861, Valid Loss: 0.2767
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2737
Epoch 5/10, Batch 20/97, Loss: 0.2077
Epoch 5/10, Batch 30/97, Loss: 0.1833
Epoch 5/10, Batch 40/97, Loss: 0.2735
Epoch 5/10, Batch 50/97, Loss: 0.2513
Epoch 5/10, Batch 60/97, Loss: 0.3212
Epoch 5/10, Batch 70/97, Loss: 0.2836
Epoch 5/10, Batch 80/97, Loss: 0.1328
Epoch 5/10, Batch 90/97, Loss: 0.2423
Epoch 5/10, Train Loss: 0.2657, Valid Loss: 0.2589
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1438
Epoch 6/10, Batch 20/97, Loss: 0.2653
Epoch 6/10, Batch 30/97, Loss: 0.2107
Epoch 6/10, Batch 40/97, Loss: 0.2516
Epoch 6/10, Batch 50/97, Loss: 0.2858
Epoch 6/10, Batch 60/97, Loss: 0.2294
Epoch 6/10, Batch 70/97, Loss: 0.2326
Epoch 6/10, Batch 80/97, Loss: 0.3571
Epoch 6/10, Batch 90/97, Loss: 0.2543
Epoch 6/10, Train Loss: 0.2472, Valid Loss: 0.2466
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1660
Epoch 7/10, Batch 20/97, Loss: 0.1757
Epoch 7/10, Batch 30/97, Loss: 0.1362
Epoch 7/10, Batch 40/97, Loss: 0.1941
Epoch 7/10, Batch 50/97, Loss: 0.2036
Epoch 7/10, Batch 60/97, Loss: 0.1347
Epoch 7/10, Batch 70/97, Loss: 0.1963
Epoch 7/10, Batch 80/97, Loss: 0.1982
Epoch 7/10, Batch 90/97, Loss: 0.2417
Epoch 7/10, Train Loss: 0.2281, Valid Loss: 0.2353
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1801
Epoch 8/10, Batch 20/97, Loss: 0.2046
Epoch 8/10, Batch 30/97, Loss: 0.0966
Epoch 8/10, Batch 40/97, Loss: 0.1954
Epoch 8/10, Batch 50/97, Loss: 0.2696
Epoch 8/10, Batch 60/97, Loss: 0.1154
Epoch 8/10, Batch 70/97, Loss: 0.2264
Epoch 8/10, Batch 80/97, Loss: 0.3270
Epoch 8/10, Batch 90/97, Loss: 0.2123
Epoch 8/10, Train Loss: 0.2261, Valid Loss: 0.2272
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1758
Epoch 9/10, Batch 20/97, Loss: 0.2283
Epoch 9/10, Batch 30/97, Loss: 0.2328
Epoch 9/10, Batch 40/97, Loss: 0.1540
Epoch 9/10, Batch 50/97, Loss: 0.2561
Epoch 9/10, Batch 60/97, Loss: 0.1325
Epoch 9/10, Batch 70/97, Loss: 0.1341
Epoch 9/10, Batch 80/97, Loss: 0.1180
Epoch 9/10, Batch 90/97, Loss: 0.2306
Epoch 9/10, Train Loss: 0.2038, Valid Loss: 0.2222
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2969
Epoch 10/10, Batch 20/97, Loss: 0.1507
Epoch 10/10, Batch 30/97, Loss: 0.1798
Epoch 10/10, Batch 40/97, Loss: 0.1960
Epoch 10/10, Batch 50/97, Loss: 0.1996
Epoch 10/10, Batch 60/97, Loss: 0.1501
Epoch 10/10, Batch 70/97, Loss: 0.1704
Epoch 10/10, Batch 80/97, Loss: 0.1842
Epoch 10/10, Batch 90/97, Loss: 0.1753
Epoch 10/10, Train Loss: 0.2001, Valid Loss: 0.2196
Model saved!
Accuracy: 0.9124
Precision: 0.9088
Recall: 0.9124
F1-score: 0.9091
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2967
Epoch 1/10, Batch 20/97, Loss: 1.0328
Epoch 1/10, Batch 30/97, Loss: 0.6824
Epoch 1/10, Batch 40/97, Loss: 0.7046
Epoch 1/10, Batch 50/97, Loss: 0.5832
Epoch 1/10, Batch 60/97, Loss: 0.9117
Epoch 1/10, Batch 70/97, Loss: 0.7205
Epoch 1/10, Batch 80/97, Loss: 0.6858
Epoch 1/10, Batch 90/97, Loss: 0.5193
Epoch 1/10, Train Loss: 0.7939, Valid Loss: 0.4244
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5129
Epoch 2/10, Batch 20/97, Loss: 0.2878
Epoch 2/10, Batch 30/97, Loss: 0.3238
Epoch 2/10, Batch 40/97, Loss: 0.3186
Epoch 2/10, Batch 50/97, Loss: 0.4732
Epoch 2/10, Batch 60/97, Loss: 0.5275
Epoch 2/10, Batch 70/97, Loss: 0.3107
Epoch 2/10, Batch 80/97, Loss: 0.2902
Epoch 2/10, Batch 90/97, Loss: 0.4007
Epoch 2/10, Train Loss: 0.4020, Valid Loss: 0.3150
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3683
Epoch 3/10, Batch 20/97, Loss: 0.2615
Epoch 3/10, Batch 30/97, Loss: 0.3507
Epoch 3/10, Batch 40/97, Loss: 0.2227
Epoch 3/10, Batch 50/97, Loss: 0.4868
Epoch 3/10, Batch 60/97, Loss: 0.3475
Epoch 3/10, Batch 70/97, Loss: 0.3573
Epoch 3/10, Batch 80/97, Loss: 0.2881
Epoch 3/10, Batch 90/97, Loss: 0.2524
Epoch 3/10, Train Loss: 0.3175, Valid Loss: 0.2794
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.5706
Epoch 4/10, Batch 20/97, Loss: 0.2673
Epoch 4/10, Batch 30/97, Loss: 0.3646
Epoch 4/10, Batch 40/97, Loss: 0.2223
Epoch 4/10, Batch 50/97, Loss: 0.1901
Epoch 4/10, Batch 60/97, Loss: 0.2270
Epoch 4/10, Batch 70/97, Loss: 0.1911
Epoch 4/10, Batch 80/97, Loss: 0.3587
Epoch 4/10, Batch 90/97, Loss: 0.3447
Epoch 4/10, Train Loss: 0.2760, Valid Loss: 0.2578
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3044
Epoch 5/10, Batch 20/97, Loss: 0.2518
Epoch 5/10, Batch 30/97, Loss: 0.1889
Epoch 5/10, Batch 40/97, Loss: 0.2541
Epoch 5/10, Batch 50/97, Loss: 0.2905
Epoch 5/10, Batch 60/97, Loss: 0.2369
Epoch 5/10, Batch 70/97, Loss: 0.2833
Epoch 5/10, Batch 80/97, Loss: 0.3880
Epoch 5/10, Batch 90/97, Loss: 0.2078
Epoch 5/10, Train Loss: 0.2563, Valid Loss: 0.2424
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2224
Epoch 6/10, Batch 20/97, Loss: 0.3581
Epoch 6/10, Batch 30/97, Loss: 0.2052
Epoch 6/10, Batch 40/97, Loss: 0.1833
Epoch 6/10, Batch 50/97, Loss: 0.1440
Epoch 6/10, Batch 60/97, Loss: 0.2856
Epoch 6/10, Batch 70/97, Loss: 0.2954
Epoch 6/10, Batch 80/97, Loss: 0.2725
Epoch 6/10, Batch 90/97, Loss: 0.2525
Epoch 6/10, Train Loss: 0.2256, Valid Loss: 0.2282
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1062
Epoch 7/10, Batch 20/97, Loss: 0.2292
Epoch 7/10, Batch 30/97, Loss: 0.2267
Epoch 7/10, Batch 40/97, Loss: 0.0890
Epoch 7/10, Batch 50/97, Loss: 0.2445
Epoch 7/10, Batch 60/97, Loss: 0.1498
Epoch 7/10, Batch 70/97, Loss: 0.1819
Epoch 7/10, Batch 80/97, Loss: 0.2408
Epoch 7/10, Batch 90/97, Loss: 0.0968
Epoch 7/10, Train Loss: 0.2195, Valid Loss: 0.2178
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2749
Epoch 8/10, Batch 20/97, Loss: 0.2001
Epoch 8/10, Batch 30/97, Loss: 0.1805
Epoch 8/10, Batch 40/97, Loss: 0.4005
Epoch 8/10, Batch 50/97, Loss: 0.1969
Epoch 8/10, Batch 60/97, Loss: 0.1791
Epoch 8/10, Batch 70/97, Loss: 0.2305
Epoch 8/10, Batch 80/97, Loss: 0.2537
Epoch 8/10, Batch 90/97, Loss: 0.0964
Epoch 8/10, Train Loss: 0.2089, Valid Loss: 0.2143
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1862
Epoch 9/10, Batch 20/97, Loss: 0.2189
Epoch 9/10, Batch 30/97, Loss: 0.2338
Epoch 9/10, Batch 40/97, Loss: 0.1724
Epoch 9/10, Batch 50/97, Loss: 0.1192
Epoch 9/10, Batch 60/97, Loss: 0.3418
Epoch 9/10, Batch 70/97, Loss: 0.0802
Epoch 9/10, Batch 80/97, Loss: 0.2139
Epoch 9/10, Batch 90/97, Loss: 0.1126
Epoch 9/10, Train Loss: 0.1915, Valid Loss: 0.2097
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1581
Epoch 10/10, Batch 20/97, Loss: 0.2015
Epoch 10/10, Batch 30/97, Loss: 0.2492
Epoch 10/10, Batch 40/97, Loss: 0.0917
Epoch 10/10, Batch 50/97, Loss: 0.2660
Epoch 10/10, Batch 60/97, Loss: 0.1974
Epoch 10/10, Batch 70/97, Loss: 0.1809
Epoch 10/10, Batch 80/97, Loss: 0.2768
Epoch 10/10, Batch 90/97, Loss: 0.1697
Epoch 10/10, Train Loss: 0.1880, Valid Loss: 0.2145
Accuracy: 0.9147
Precision: 0.9130
Recall: 0.9147
F1-score: 0.9124
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2441
Epoch 1/10, Batch 20/97, Loss: 1.0046
Epoch 1/10, Batch 30/97, Loss: 0.7812
Epoch 1/10, Batch 40/97, Loss: 0.7789
Epoch 1/10, Batch 50/97, Loss: 0.7394
Epoch 1/10, Batch 60/97, Loss: 0.6760
Epoch 1/10, Batch 70/97, Loss: 0.6163
Epoch 1/10, Batch 80/97, Loss: 0.6930
Epoch 1/10, Batch 90/97, Loss: 0.5974
Epoch 1/10, Train Loss: 0.7969, Valid Loss: 0.4523
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5105
Epoch 2/10, Batch 20/97, Loss: 0.4994
Epoch 2/10, Batch 30/97, Loss: 0.3433
Epoch 2/10, Batch 40/97, Loss: 0.3830
Epoch 2/10, Batch 50/97, Loss: 0.5039
Epoch 2/10, Batch 60/97, Loss: 0.4221
Epoch 2/10, Batch 70/97, Loss: 0.3921
Epoch 2/10, Batch 80/97, Loss: 0.5792
Epoch 2/10, Batch 90/97, Loss: 0.4874
Epoch 2/10, Train Loss: 0.4130, Valid Loss: 0.3435
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2971
Epoch 3/10, Batch 20/97, Loss: 0.2505
Epoch 3/10, Batch 30/97, Loss: 0.4392
Epoch 3/10, Batch 40/97, Loss: 0.2495
Epoch 3/10, Batch 50/97, Loss: 0.3303
Epoch 3/10, Batch 60/97, Loss: 0.2520
Epoch 3/10, Batch 70/97, Loss: 0.3050
Epoch 3/10, Batch 80/97, Loss: 0.1938
Epoch 3/10, Batch 90/97, Loss: 0.3415
Epoch 3/10, Train Loss: 0.3364, Valid Loss: 0.2875
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3436
Epoch 4/10, Batch 20/97, Loss: 0.2895
Epoch 4/10, Batch 30/97, Loss: 0.2453
Epoch 4/10, Batch 40/97, Loss: 0.2575
Epoch 4/10, Batch 50/97, Loss: 0.4047
Epoch 4/10, Batch 60/97, Loss: 0.1989
Epoch 4/10, Batch 70/97, Loss: 0.1466
Epoch 4/10, Batch 80/97, Loss: 0.1976
Epoch 4/10, Batch 90/97, Loss: 0.3326
Epoch 4/10, Train Loss: 0.2899, Valid Loss: 0.2757
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1421
Epoch 5/10, Batch 20/97, Loss: 0.2853
Epoch 5/10, Batch 30/97, Loss: 0.2419
Epoch 5/10, Batch 40/97, Loss: 0.3034
Epoch 5/10, Batch 50/97, Loss: 0.3095
Epoch 5/10, Batch 60/97, Loss: 0.1626
Epoch 5/10, Batch 70/97, Loss: 0.3320
Epoch 5/10, Batch 80/97, Loss: 0.3245
Epoch 5/10, Batch 90/97, Loss: 0.3153
Epoch 5/10, Train Loss: 0.2685, Valid Loss: 0.2559
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1721
Epoch 6/10, Batch 20/97, Loss: 0.3487
Epoch 6/10, Batch 30/97, Loss: 0.1293
Epoch 6/10, Batch 40/97, Loss: 0.1626
Epoch 6/10, Batch 50/97, Loss: 0.4304
Epoch 6/10, Batch 60/97, Loss: 0.2801
Epoch 6/10, Batch 70/97, Loss: 0.1213
Epoch 6/10, Batch 80/97, Loss: 0.3738
Epoch 6/10, Batch 90/97, Loss: 0.2605
Epoch 6/10, Train Loss: 0.2445, Valid Loss: 0.2468
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1396
Epoch 7/10, Batch 20/97, Loss: 0.2983
Epoch 7/10, Batch 30/97, Loss: 0.1485
Epoch 7/10, Batch 40/97, Loss: 0.2008
Epoch 7/10, Batch 50/97, Loss: 0.2496
Epoch 7/10, Batch 60/97, Loss: 0.3119
Epoch 7/10, Batch 70/97, Loss: 0.4893
Epoch 7/10, Batch 80/97, Loss: 0.1313
Epoch 7/10, Batch 90/97, Loss: 0.1808
Epoch 7/10, Train Loss: 0.2273, Valid Loss: 0.2427
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2159
Epoch 8/10, Batch 20/97, Loss: 0.1329
Epoch 8/10, Batch 30/97, Loss: 0.2107
Epoch 8/10, Batch 40/97, Loss: 0.2677
Epoch 8/10, Batch 50/97, Loss: 0.1865
Epoch 8/10, Batch 60/97, Loss: 0.3006
Epoch 8/10, Batch 70/97, Loss: 0.1698
Epoch 8/10, Batch 80/97, Loss: 0.2762
Epoch 8/10, Batch 90/97, Loss: 0.1301
Epoch 8/10, Train Loss: 0.2104, Valid Loss: 0.2379
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1097
Epoch 9/10, Batch 20/97, Loss: 0.1168
Epoch 9/10, Batch 30/97, Loss: 0.2271
Epoch 9/10, Batch 40/97, Loss: 0.2315
Epoch 9/10, Batch 50/97, Loss: 0.1194
Epoch 9/10, Batch 60/97, Loss: 0.2147
Epoch 9/10, Batch 70/97, Loss: 0.2643
Epoch 9/10, Batch 80/97, Loss: 0.1533
Epoch 9/10, Batch 90/97, Loss: 0.2979
Epoch 9/10, Train Loss: 0.2049, Valid Loss: 0.2309
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1361
Epoch 10/10, Batch 20/97, Loss: 0.2565
Epoch 10/10, Batch 30/97, Loss: 0.2826
Epoch 10/10, Batch 40/97, Loss: 0.1597
Epoch 10/10, Batch 50/97, Loss: 0.1644
Epoch 10/10, Batch 60/97, Loss: 0.2308
Epoch 10/10, Batch 70/97, Loss: 0.2809
Epoch 10/10, Batch 80/97, Loss: 0.2797
Epoch 10/10, Batch 90/97, Loss: 0.1009
Epoch 10/10, Train Loss: 0.1985, Valid Loss: 0.2259
Model saved!
Accuracy: 0.9124
Precision: 0.9099
Recall: 0.9124
F1-score: 0.9098
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2324
Epoch 1/10, Batch 20/97, Loss: 1.0467
Epoch 1/10, Batch 30/97, Loss: 0.7473
Epoch 1/10, Batch 40/97, Loss: 0.7226
Epoch 1/10, Batch 50/97, Loss: 0.7885
Epoch 1/10, Batch 60/97, Loss: 0.7326
Epoch 1/10, Batch 70/97, Loss: 0.6392
Epoch 1/10, Batch 80/97, Loss: 0.6040
Epoch 1/10, Batch 90/97, Loss: 0.7017
Epoch 1/10, Train Loss: 0.7961, Valid Loss: 0.4423
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5438
Epoch 2/10, Batch 20/97, Loss: 0.3659
Epoch 2/10, Batch 30/97, Loss: 0.3510
Epoch 2/10, Batch 40/97, Loss: 0.4022
Epoch 2/10, Batch 50/97, Loss: 0.3474
Epoch 2/10, Batch 60/97, Loss: 0.4742
Epoch 2/10, Batch 70/97, Loss: 0.4497
Epoch 2/10, Batch 80/97, Loss: 0.3108
Epoch 2/10, Batch 90/97, Loss: 0.3963
Epoch 2/10, Train Loss: 0.4133, Valid Loss: 0.3401
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3774
Epoch 3/10, Batch 20/97, Loss: 0.3248
Epoch 3/10, Batch 30/97, Loss: 0.2191
Epoch 3/10, Batch 40/97, Loss: 0.3039
Epoch 3/10, Batch 50/97, Loss: 0.5864
Epoch 3/10, Batch 60/97, Loss: 0.2710
Epoch 3/10, Batch 70/97, Loss: 0.4436
Epoch 3/10, Batch 80/97, Loss: 0.3219
Epoch 3/10, Batch 90/97, Loss: 0.2669
Epoch 3/10, Train Loss: 0.3319, Valid Loss: 0.2979
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3252
Epoch 4/10, Batch 20/97, Loss: 0.2087
Epoch 4/10, Batch 30/97, Loss: 0.3066
Epoch 4/10, Batch 40/97, Loss: 0.2692
Epoch 4/10, Batch 50/97, Loss: 0.4585
Epoch 4/10, Batch 60/97, Loss: 0.2557
Epoch 4/10, Batch 70/97, Loss: 0.1730
Epoch 4/10, Batch 80/97, Loss: 0.2069
Epoch 4/10, Batch 90/97, Loss: 0.2798
Epoch 4/10, Train Loss: 0.2885, Valid Loss: 0.2716
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1628
Epoch 5/10, Batch 20/97, Loss: 0.2513
Epoch 5/10, Batch 30/97, Loss: 0.2024
Epoch 5/10, Batch 40/97, Loss: 0.2758
Epoch 5/10, Batch 50/97, Loss: 0.2536
Epoch 5/10, Batch 60/97, Loss: 0.2861
Epoch 5/10, Batch 70/97, Loss: 0.2685
Epoch 5/10, Batch 80/97, Loss: 0.1904
Epoch 5/10, Batch 90/97, Loss: 0.2508
Epoch 5/10, Train Loss: 0.2657, Valid Loss: 0.2577
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1325
Epoch 6/10, Batch 20/97, Loss: 0.2351
Epoch 6/10, Batch 30/97, Loss: 0.2024
Epoch 6/10, Batch 40/97, Loss: 0.1234
Epoch 6/10, Batch 50/97, Loss: 0.3785
Epoch 6/10, Batch 60/97, Loss: 0.2429
Epoch 6/10, Batch 70/97, Loss: 0.1572
Epoch 6/10, Batch 80/97, Loss: 0.2700
Epoch 6/10, Batch 90/97, Loss: 0.3777
Epoch 6/10, Train Loss: 0.2429, Valid Loss: 0.2427
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1652
Epoch 7/10, Batch 20/97, Loss: 0.3151
Epoch 7/10, Batch 30/97, Loss: 0.1853
Epoch 7/10, Batch 40/97, Loss: 0.2403
Epoch 7/10, Batch 50/97, Loss: 0.2331
Epoch 7/10, Batch 60/97, Loss: 0.1106
Epoch 7/10, Batch 70/97, Loss: 0.3069
Epoch 7/10, Batch 80/97, Loss: 0.1682
Epoch 7/10, Batch 90/97, Loss: 0.1932
Epoch 7/10, Train Loss: 0.2212, Valid Loss: 0.2400
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2802
Epoch 8/10, Batch 20/97, Loss: 0.1669
Epoch 8/10, Batch 30/97, Loss: 0.2065
Epoch 8/10, Batch 40/97, Loss: 0.1630
Epoch 8/10, Batch 50/97, Loss: 0.2301
Epoch 8/10, Batch 60/97, Loss: 0.1191
Epoch 8/10, Batch 70/97, Loss: 0.3243
Epoch 8/10, Batch 80/97, Loss: 0.1800
Epoch 8/10, Batch 90/97, Loss: 0.1997
Epoch 8/10, Train Loss: 0.2151, Valid Loss: 0.2418
Epoch 9/10, Batch 10/97, Loss: 0.2512
Epoch 9/10, Batch 20/97, Loss: 0.2185
Epoch 9/10, Batch 30/97, Loss: 0.2374
Epoch 9/10, Batch 40/97, Loss: 0.1552
Epoch 9/10, Batch 50/97, Loss: 0.1909
Epoch 9/10, Batch 60/97, Loss: 0.1535
Epoch 9/10, Batch 70/97, Loss: 0.1905
Epoch 9/10, Batch 80/97, Loss: 0.1920
Epoch 9/10, Batch 90/97, Loss: 0.1345
Epoch 9/10, Train Loss: 0.2025, Valid Loss: 0.2296
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2668
Epoch 10/10, Batch 20/97, Loss: 0.1326
Epoch 10/10, Batch 30/97, Loss: 0.2235
Epoch 10/10, Batch 40/97, Loss: 0.0646
Epoch 10/10, Batch 50/97, Loss: 0.1622
Epoch 10/10, Batch 60/97, Loss: 0.1257
Epoch 10/10, Batch 70/97, Loss: 0.1719
Epoch 10/10, Batch 80/97, Loss: 0.2399
Epoch 10/10, Batch 90/97, Loss: 0.2221
Epoch 10/10, Train Loss: 0.2011, Valid Loss: 0.2311
Accuracy: 0.9171
Precision: 0.9144
Recall: 0.9171
F1-score: 0.9152
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2630
Epoch 1/10, Batch 20/97, Loss: 1.1045
Epoch 1/10, Batch 30/97, Loss: 0.7673
Epoch 1/10, Batch 40/97, Loss: 0.8663
Epoch 1/10, Batch 50/97, Loss: 0.7752
Epoch 1/10, Batch 60/97, Loss: 0.7535
Epoch 1/10, Batch 70/97, Loss: 0.6098
Epoch 1/10, Batch 80/97, Loss: 0.6647
Epoch 1/10, Batch 90/97, Loss: 0.4901
Epoch 1/10, Train Loss: 0.8102, Valid Loss: 0.4599
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4120
Epoch 2/10, Batch 20/97, Loss: 0.4400
Epoch 2/10, Batch 30/97, Loss: 0.4205
Epoch 2/10, Batch 40/97, Loss: 0.4409
Epoch 2/10, Batch 50/97, Loss: 0.5444
Epoch 2/10, Batch 60/97, Loss: 0.4133
Epoch 2/10, Batch 70/97, Loss: 0.4048
Epoch 2/10, Batch 80/97, Loss: 0.3354
Epoch 2/10, Batch 90/97, Loss: 0.3933
Epoch 2/10, Train Loss: 0.4078, Valid Loss: 0.3602
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3122
Epoch 3/10, Batch 20/97, Loss: 0.3025
Epoch 3/10, Batch 30/97, Loss: 0.3972
Epoch 3/10, Batch 40/97, Loss: 0.3437
Epoch 3/10, Batch 50/97, Loss: 0.4578
Epoch 3/10, Batch 60/97, Loss: 0.2254
Epoch 3/10, Batch 70/97, Loss: 0.4629
Epoch 3/10, Batch 80/97, Loss: 0.2218
Epoch 3/10, Batch 90/97, Loss: 0.3508
Epoch 3/10, Train Loss: 0.3383, Valid Loss: 0.3193
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3436
Epoch 4/10, Batch 20/97, Loss: 0.1672
Epoch 4/10, Batch 30/97, Loss: 0.1573
Epoch 4/10, Batch 40/97, Loss: 0.3417
Epoch 4/10, Batch 50/97, Loss: 0.2746
Epoch 4/10, Batch 60/97, Loss: 0.2517
Epoch 4/10, Batch 70/97, Loss: 0.2538
Epoch 4/10, Batch 80/97, Loss: 0.2409
Epoch 4/10, Batch 90/97, Loss: 0.2852
Epoch 4/10, Train Loss: 0.2878, Valid Loss: 0.2991
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2045
Epoch 5/10, Batch 20/97, Loss: 0.1801
Epoch 5/10, Batch 30/97, Loss: 0.1620
Epoch 5/10, Batch 40/97, Loss: 0.3681
Epoch 5/10, Batch 50/97, Loss: 0.2077
Epoch 5/10, Batch 60/97, Loss: 0.1864
Epoch 5/10, Batch 70/97, Loss: 0.2841
Epoch 5/10, Batch 80/97, Loss: 0.2158
Epoch 5/10, Batch 90/97, Loss: 0.3212
Epoch 5/10, Train Loss: 0.2631, Valid Loss: 0.2895
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3137
Epoch 6/10, Batch 20/97, Loss: 0.3992
Epoch 6/10, Batch 30/97, Loss: 0.2412
Epoch 6/10, Batch 40/97, Loss: 0.1278
Epoch 6/10, Batch 50/97, Loss: 0.1742
Epoch 6/10, Batch 60/97, Loss: 0.1322
Epoch 6/10, Batch 70/97, Loss: 0.2429
Epoch 6/10, Batch 80/97, Loss: 0.2951
Epoch 6/10, Batch 90/97, Loss: 0.1583
Epoch 6/10, Train Loss: 0.2442, Valid Loss: 0.2707
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2181
Epoch 7/10, Batch 20/97, Loss: 0.4641
Epoch 7/10, Batch 30/97, Loss: 0.1444
Epoch 7/10, Batch 40/97, Loss: 0.1873
Epoch 7/10, Batch 50/97, Loss: 0.1867
Epoch 7/10, Batch 60/97, Loss: 0.1604
Epoch 7/10, Batch 70/97, Loss: 0.1817
Epoch 7/10, Batch 80/97, Loss: 0.2760
Epoch 7/10, Batch 90/97, Loss: 0.1471
Epoch 7/10, Train Loss: 0.2235, Valid Loss: 0.2670
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1363
Epoch 8/10, Batch 20/97, Loss: 0.2885
Epoch 8/10, Batch 30/97, Loss: 0.1646
Epoch 8/10, Batch 40/97, Loss: 0.1852
Epoch 8/10, Batch 50/97, Loss: 0.1614
Epoch 8/10, Batch 60/97, Loss: 0.1986
Epoch 8/10, Batch 70/97, Loss: 0.2454
Epoch 8/10, Batch 80/97, Loss: 0.1758
Epoch 8/10, Batch 90/97, Loss: 0.1819
Epoch 8/10, Train Loss: 0.2191, Valid Loss: 0.2623
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1281
Epoch 9/10, Batch 20/97, Loss: 0.1575
Epoch 9/10, Batch 30/97, Loss: 0.1816
Epoch 9/10, Batch 40/97, Loss: 0.3426
Epoch 9/10, Batch 50/97, Loss: 0.1510
Epoch 9/10, Batch 60/97, Loss: 0.1164
Epoch 9/10, Batch 70/97, Loss: 0.1888
Epoch 9/10, Batch 80/97, Loss: 0.1825
Epoch 9/10, Batch 90/97, Loss: 0.2179
Epoch 9/10, Train Loss: 0.2079, Valid Loss: 0.2556
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2000
Epoch 10/10, Batch 20/97, Loss: 0.2831
Epoch 10/10, Batch 30/97, Loss: 0.1909
Epoch 10/10, Batch 40/97, Loss: 0.0806
Epoch 10/10, Batch 50/97, Loss: 0.1536
Epoch 10/10, Batch 60/97, Loss: 0.1624
Epoch 10/10, Batch 70/97, Loss: 0.1671
Epoch 10/10, Batch 80/97, Loss: 0.2589
Epoch 10/10, Batch 90/97, Loss: 0.2144
Epoch 10/10, Train Loss: 0.2083, Valid Loss: 0.2681
Accuracy: 0.9206
Precision: 0.9182
Recall: 0.9206
F1-score: 0.9186
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2528
Epoch 1/10, Batch 20/97, Loss: 1.1077
Epoch 1/10, Batch 30/97, Loss: 0.7618
Epoch 1/10, Batch 40/97, Loss: 0.8284
Epoch 1/10, Batch 50/97, Loss: 0.6318
Epoch 1/10, Batch 60/97, Loss: 0.7843
Epoch 1/10, Batch 70/97, Loss: 0.5369
Epoch 1/10, Batch 80/97, Loss: 0.5722
Epoch 1/10, Batch 90/97, Loss: 0.6757
Epoch 1/10, Train Loss: 0.7996, Valid Loss: 0.4153
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4556
Epoch 2/10, Batch 20/97, Loss: 0.4169
Epoch 2/10, Batch 30/97, Loss: 0.2640
Epoch 2/10, Batch 40/97, Loss: 0.4063
Epoch 2/10, Batch 50/97, Loss: 0.4316
Epoch 2/10, Batch 60/97, Loss: 0.3363
Epoch 2/10, Batch 70/97, Loss: 0.3864
Epoch 2/10, Batch 80/97, Loss: 0.4375
Epoch 2/10, Batch 90/97, Loss: 0.4323
Epoch 2/10, Train Loss: 0.4069, Valid Loss: 0.3032
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3934
Epoch 3/10, Batch 20/97, Loss: 0.2788
Epoch 3/10, Batch 30/97, Loss: 0.4007
Epoch 3/10, Batch 40/97, Loss: 0.2127
Epoch 3/10, Batch 50/97, Loss: 0.4700
Epoch 3/10, Batch 60/97, Loss: 0.3256
Epoch 3/10, Batch 70/97, Loss: 0.4631
Epoch 3/10, Batch 80/97, Loss: 0.3282
Epoch 3/10, Batch 90/97, Loss: 0.2503
Epoch 3/10, Train Loss: 0.3337, Valid Loss: 0.2602
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2940
Epoch 4/10, Batch 20/97, Loss: 0.3285
Epoch 4/10, Batch 30/97, Loss: 0.2430
Epoch 4/10, Batch 40/97, Loss: 0.2419
Epoch 4/10, Batch 50/97, Loss: 0.2875
Epoch 4/10, Batch 60/97, Loss: 0.1992
Epoch 4/10, Batch 70/97, Loss: 0.2140
Epoch 4/10, Batch 80/97, Loss: 0.2395
Epoch 4/10, Batch 90/97, Loss: 0.2645
Epoch 4/10, Train Loss: 0.2823, Valid Loss: 0.2373
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2441
Epoch 5/10, Batch 20/97, Loss: 0.2215
Epoch 5/10, Batch 30/97, Loss: 0.2824
Epoch 5/10, Batch 40/97, Loss: 0.2458
Epoch 5/10, Batch 50/97, Loss: 0.1724
Epoch 5/10, Batch 60/97, Loss: 0.2721
Epoch 5/10, Batch 70/97, Loss: 0.2454
Epoch 5/10, Batch 80/97, Loss: 0.3137
Epoch 5/10, Batch 90/97, Loss: 0.3110
Epoch 5/10, Train Loss: 0.2639, Valid Loss: 0.2276
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1220
Epoch 6/10, Batch 20/97, Loss: 0.3193
Epoch 6/10, Batch 30/97, Loss: 0.2122
Epoch 6/10, Batch 40/97, Loss: 0.1924
Epoch 6/10, Batch 50/97, Loss: 0.2266
Epoch 6/10, Batch 60/97, Loss: 0.1938
Epoch 6/10, Batch 70/97, Loss: 0.2932
Epoch 6/10, Batch 80/97, Loss: 0.3514
Epoch 6/10, Batch 90/97, Loss: 0.2879
Epoch 6/10, Train Loss: 0.2392, Valid Loss: 0.2107
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2214
Epoch 7/10, Batch 20/97, Loss: 0.1917
Epoch 7/10, Batch 30/97, Loss: 0.1485
Epoch 7/10, Batch 40/97, Loss: 0.1103
Epoch 7/10, Batch 50/97, Loss: 0.1606
Epoch 7/10, Batch 60/97, Loss: 0.1830
Epoch 7/10, Batch 70/97, Loss: 0.1709
Epoch 7/10, Batch 80/97, Loss: 0.2224
Epoch 7/10, Batch 90/97, Loss: 0.1586
Epoch 7/10, Train Loss: 0.2171, Valid Loss: 0.2100
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1284
Epoch 8/10, Batch 20/97, Loss: 0.2245
Epoch 8/10, Batch 30/97, Loss: 0.0965
Epoch 8/10, Batch 40/97, Loss: 0.1770
Epoch 8/10, Batch 50/97, Loss: 0.1380
Epoch 8/10, Batch 60/97, Loss: 0.1348
Epoch 8/10, Batch 70/97, Loss: 0.2029
Epoch 8/10, Batch 80/97, Loss: 0.2047
Epoch 8/10, Batch 90/97, Loss: 0.3047
Epoch 8/10, Train Loss: 0.2086, Valid Loss: 0.2055
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1366
Epoch 9/10, Batch 20/97, Loss: 0.1744
Epoch 9/10, Batch 30/97, Loss: 0.0998
Epoch 9/10, Batch 40/97, Loss: 0.3217
Epoch 9/10, Batch 50/97, Loss: 0.1264
Epoch 9/10, Batch 60/97, Loss: 0.3210
Epoch 9/10, Batch 70/97, Loss: 0.0794
Epoch 9/10, Batch 80/97, Loss: 0.2547
Epoch 9/10, Batch 90/97, Loss: 0.2154
Epoch 9/10, Train Loss: 0.2014, Valid Loss: 0.1955
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1831
Epoch 10/10, Batch 20/97, Loss: 0.1333
Epoch 10/10, Batch 30/97, Loss: 0.1354
Epoch 10/10, Batch 40/97, Loss: 0.1877
Epoch 10/10, Batch 50/97, Loss: 0.2230
Epoch 10/10, Batch 60/97, Loss: 0.2539
Epoch 10/10, Batch 70/97, Loss: 0.1418
Epoch 10/10, Batch 80/97, Loss: 0.1516
Epoch 10/10, Batch 90/97, Loss: 0.1936
Epoch 10/10, Train Loss: 0.1910, Valid Loss: 0.2052
Accuracy: 0.9264
Precision: 0.9243
Recall: 0.9264
F1-score: 0.9251
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.3000
Epoch 1/10, Batch 20/97, Loss: 1.0300
Epoch 1/10, Batch 30/97, Loss: 0.7396
Epoch 1/10, Batch 40/97, Loss: 0.7266
Epoch 1/10, Batch 50/97, Loss: 0.7897
Epoch 1/10, Batch 60/97, Loss: 0.6393
Epoch 1/10, Batch 70/97, Loss: 0.5185
Epoch 1/10, Batch 80/97, Loss: 0.5745
Epoch 1/10, Batch 90/97, Loss: 0.5482
Epoch 1/10, Train Loss: 0.8049, Valid Loss: 0.4398
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5534
Epoch 2/10, Batch 20/97, Loss: 0.3837
Epoch 2/10, Batch 30/97, Loss: 0.4214
Epoch 2/10, Batch 40/97, Loss: 0.3372
Epoch 2/10, Batch 50/97, Loss: 0.3241
Epoch 2/10, Batch 60/97, Loss: 0.3570
Epoch 2/10, Batch 70/97, Loss: 0.3384
Epoch 2/10, Batch 80/97, Loss: 0.3584
Epoch 2/10, Batch 90/97, Loss: 0.5144
Epoch 2/10, Train Loss: 0.4145, Valid Loss: 0.3256
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3478
Epoch 3/10, Batch 20/97, Loss: 0.2733
Epoch 3/10, Batch 30/97, Loss: 0.3241
Epoch 3/10, Batch 40/97, Loss: 0.2678
Epoch 3/10, Batch 50/97, Loss: 0.2484
Epoch 3/10, Batch 60/97, Loss: 0.3698
Epoch 3/10, Batch 70/97, Loss: 0.4498
Epoch 3/10, Batch 80/97, Loss: 0.3567
Epoch 3/10, Batch 90/97, Loss: 0.3558
Epoch 3/10, Train Loss: 0.3368, Valid Loss: 0.2737
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2799
Epoch 4/10, Batch 20/97, Loss: 0.2437
Epoch 4/10, Batch 30/97, Loss: 0.2822
Epoch 4/10, Batch 40/97, Loss: 0.2043
Epoch 4/10, Batch 50/97, Loss: 0.4353
Epoch 4/10, Batch 60/97, Loss: 0.2255
Epoch 4/10, Batch 70/97, Loss: 0.2254
Epoch 4/10, Batch 80/97, Loss: 0.1822
Epoch 4/10, Batch 90/97, Loss: 0.2467
Epoch 4/10, Train Loss: 0.2961, Valid Loss: 0.2619
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2227
Epoch 5/10, Batch 20/97, Loss: 0.3442
Epoch 5/10, Batch 30/97, Loss: 0.2745
Epoch 5/10, Batch 40/97, Loss: 0.3276
Epoch 5/10, Batch 50/97, Loss: 0.2583
Epoch 5/10, Batch 60/97, Loss: 0.2941
Epoch 5/10, Batch 70/97, Loss: 0.2725
Epoch 5/10, Batch 80/97, Loss: 0.2689
Epoch 5/10, Batch 90/97, Loss: 0.2029
Epoch 5/10, Train Loss: 0.2730, Valid Loss: 0.2413
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3419
Epoch 6/10, Batch 20/97, Loss: 0.3051
Epoch 6/10, Batch 30/97, Loss: 0.1665
Epoch 6/10, Batch 40/97, Loss: 0.2058
Epoch 6/10, Batch 50/97, Loss: 0.2585
Epoch 6/10, Batch 60/97, Loss: 0.1650
Epoch 6/10, Batch 70/97, Loss: 0.3562
Epoch 6/10, Batch 80/97, Loss: 0.3730
Epoch 6/10, Batch 90/97, Loss: 0.2533
Epoch 6/10, Train Loss: 0.2520, Valid Loss: 0.2301
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1656
Epoch 7/10, Batch 20/97, Loss: 0.1982
Epoch 7/10, Batch 30/97, Loss: 0.1537
Epoch 7/10, Batch 40/97, Loss: 0.2119
Epoch 7/10, Batch 50/97, Loss: 0.2291
Epoch 7/10, Batch 60/97, Loss: 0.2566
Epoch 7/10, Batch 70/97, Loss: 0.1159
Epoch 7/10, Batch 80/97, Loss: 0.1709
Epoch 7/10, Batch 90/97, Loss: 0.2335
Epoch 7/10, Train Loss: 0.2223, Valid Loss: 0.2235
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2853
Epoch 8/10, Batch 20/97, Loss: 0.1285
Epoch 8/10, Batch 30/97, Loss: 0.2700
Epoch 8/10, Batch 40/97, Loss: 0.2045
Epoch 8/10, Batch 50/97, Loss: 0.2095
Epoch 8/10, Batch 60/97, Loss: 0.1019
Epoch 8/10, Batch 70/97, Loss: 0.2630
Epoch 8/10, Batch 80/97, Loss: 0.1889
Epoch 8/10, Batch 90/97, Loss: 0.1159
Epoch 8/10, Train Loss: 0.2230, Valid Loss: 0.2256
Epoch 9/10, Batch 10/97, Loss: 0.2135
Epoch 9/10, Batch 20/97, Loss: 0.1951
Epoch 9/10, Batch 30/97, Loss: 0.3582
Epoch 9/10, Batch 40/97, Loss: 0.1609
Epoch 9/10, Batch 50/97, Loss: 0.1002
Epoch 9/10, Batch 60/97, Loss: 0.2133
Epoch 9/10, Batch 70/97, Loss: 0.0950
Epoch 9/10, Batch 80/97, Loss: 0.1840
Epoch 9/10, Batch 90/97, Loss: 0.1512
Epoch 9/10, Train Loss: 0.2086, Valid Loss: 0.2235
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2638
Epoch 10/10, Batch 20/97, Loss: 0.1253
Epoch 10/10, Batch 30/97, Loss: 0.2193
Epoch 10/10, Batch 40/97, Loss: 0.2008
Epoch 10/10, Batch 50/97, Loss: 0.1344
Epoch 10/10, Batch 60/97, Loss: 0.1458
Epoch 10/10, Batch 70/97, Loss: 0.2022
Epoch 10/10, Batch 80/97, Loss: 0.2032
Epoch 10/10, Batch 90/97, Loss: 0.1831
Epoch 10/10, Train Loss: 0.2116, Valid Loss: 0.2234
Model saved!
Accuracy: 0.9054
Precision: 0.9039
Recall: 0.9054
F1-score: 0.9022
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.3294
Epoch 1/10, Batch 20/97, Loss: 1.1270
Epoch 1/10, Batch 30/97, Loss: 0.7441
Epoch 1/10, Batch 40/97, Loss: 0.7042
Epoch 1/10, Batch 50/97, Loss: 0.6238
Epoch 1/10, Batch 60/97, Loss: 0.6728
Epoch 1/10, Batch 70/97, Loss: 0.7705
Epoch 1/10, Batch 80/97, Loss: 0.6467
Epoch 1/10, Batch 90/97, Loss: 0.5866
Epoch 1/10, Train Loss: 0.8023, Valid Loss: 0.4485
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5020
Epoch 2/10, Batch 20/97, Loss: 0.4548
Epoch 2/10, Batch 30/97, Loss: 0.3914
Epoch 2/10, Batch 40/97, Loss: 0.4275
Epoch 2/10, Batch 50/97, Loss: 0.4462
Epoch 2/10, Batch 60/97, Loss: 0.4679
Epoch 2/10, Batch 70/97, Loss: 0.5218
Epoch 2/10, Batch 80/97, Loss: 0.2963
Epoch 2/10, Batch 90/97, Loss: 0.3632
Epoch 2/10, Train Loss: 0.4083, Valid Loss: 0.3323
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2355
Epoch 3/10, Batch 20/97, Loss: 0.3403
Epoch 3/10, Batch 30/97, Loss: 0.3263
Epoch 3/10, Batch 40/97, Loss: 0.2434
Epoch 3/10, Batch 50/97, Loss: 0.3513
Epoch 3/10, Batch 60/97, Loss: 0.2796
Epoch 3/10, Batch 70/97, Loss: 0.2882
Epoch 3/10, Batch 80/97, Loss: 0.3061
Epoch 3/10, Batch 90/97, Loss: 0.3394
Epoch 3/10, Train Loss: 0.3255, Valid Loss: 0.2833
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3811
Epoch 4/10, Batch 20/97, Loss: 0.3229
Epoch 4/10, Batch 30/97, Loss: 0.2774
Epoch 4/10, Batch 40/97, Loss: 0.3015
Epoch 4/10, Batch 50/97, Loss: 0.4139
Epoch 4/10, Batch 60/97, Loss: 0.3135
Epoch 4/10, Batch 70/97, Loss: 0.1886
Epoch 4/10, Batch 80/97, Loss: 0.3451
Epoch 4/10, Batch 90/97, Loss: 0.2384
Epoch 4/10, Train Loss: 0.2823, Valid Loss: 0.2640
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2805
Epoch 5/10, Batch 20/97, Loss: 0.2341
Epoch 5/10, Batch 30/97, Loss: 0.2405
Epoch 5/10, Batch 40/97, Loss: 0.2483
Epoch 5/10, Batch 50/97, Loss: 0.3070
Epoch 5/10, Batch 60/97, Loss: 0.2202
Epoch 5/10, Batch 70/97, Loss: 0.2465
Epoch 5/10, Batch 80/97, Loss: 0.1865
Epoch 5/10, Batch 90/97, Loss: 0.2999
Epoch 5/10, Train Loss: 0.2588, Valid Loss: 0.2475
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1585
Epoch 6/10, Batch 20/97, Loss: 0.3228
Epoch 6/10, Batch 30/97, Loss: 0.2684
Epoch 6/10, Batch 40/97, Loss: 0.2316
Epoch 6/10, Batch 50/97, Loss: 0.1607
Epoch 6/10, Batch 60/97, Loss: 0.3655
Epoch 6/10, Batch 70/97, Loss: 0.1901
Epoch 6/10, Batch 80/97, Loss: 0.2841
Epoch 6/10, Batch 90/97, Loss: 0.2886
Epoch 6/10, Train Loss: 0.2328, Valid Loss: 0.2323
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1710
Epoch 7/10, Batch 20/97, Loss: 0.2954
Epoch 7/10, Batch 30/97, Loss: 0.1651
Epoch 7/10, Batch 40/97, Loss: 0.1486
Epoch 7/10, Batch 50/97, Loss: 0.1488
Epoch 7/10, Batch 60/97, Loss: 0.1217
Epoch 7/10, Batch 70/97, Loss: 0.2027
Epoch 7/10, Batch 80/97, Loss: 0.2640
Epoch 7/10, Batch 90/97, Loss: 0.1494
Epoch 7/10, Train Loss: 0.2215, Valid Loss: 0.2314
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1063
Epoch 8/10, Batch 20/97, Loss: 0.1861
Epoch 8/10, Batch 30/97, Loss: 0.1304
Epoch 8/10, Batch 40/97, Loss: 0.2486
Epoch 8/10, Batch 50/97, Loss: 0.2433
Epoch 8/10, Batch 60/97, Loss: 0.1607
Epoch 8/10, Batch 70/97, Loss: 0.1289
Epoch 8/10, Batch 80/97, Loss: 0.1930
Epoch 8/10, Batch 90/97, Loss: 0.1794
Epoch 8/10, Train Loss: 0.2059, Valid Loss: 0.2229
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2665
Epoch 9/10, Batch 20/97, Loss: 0.1557
Epoch 9/10, Batch 30/97, Loss: 0.1833
Epoch 9/10, Batch 40/97, Loss: 0.3242
Epoch 9/10, Batch 50/97, Loss: 0.1749
Epoch 9/10, Batch 60/97, Loss: 0.2351
Epoch 9/10, Batch 70/97, Loss: 0.1013
Epoch 9/10, Batch 80/97, Loss: 0.2041
Epoch 9/10, Batch 90/97, Loss: 0.1815
Epoch 9/10, Train Loss: 0.1958, Valid Loss: 0.2194
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2919
Epoch 10/10, Batch 20/97, Loss: 0.1485
Epoch 10/10, Batch 30/97, Loss: 0.1667
Epoch 10/10, Batch 40/97, Loss: 0.2020
Epoch 10/10, Batch 50/97, Loss: 0.1488
Epoch 10/10, Batch 60/97, Loss: 0.1685
Epoch 10/10, Batch 70/97, Loss: 0.1670
Epoch 10/10, Batch 80/97, Loss: 0.3272
Epoch 10/10, Batch 90/97, Loss: 0.1357
Epoch 10/10, Train Loss: 0.1907, Valid Loss: 0.2133
Model saved!
Accuracy: 0.9124
Precision: 0.9101
Recall: 0.9124
F1-score: 0.9089
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2450
Epoch 1/10, Batch 20/97, Loss: 1.0652
Epoch 1/10, Batch 30/97, Loss: 0.7384
Epoch 1/10, Batch 40/97, Loss: 0.7320
Epoch 1/10, Batch 50/97, Loss: 0.6201
Epoch 1/10, Batch 60/97, Loss: 0.7229
Epoch 1/10, Batch 70/97, Loss: 0.6279
Epoch 1/10, Batch 80/97, Loss: 0.5435
Epoch 1/10, Batch 90/97, Loss: 0.5716
Epoch 1/10, Train Loss: 0.7974, Valid Loss: 0.4431
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5848
Epoch 2/10, Batch 20/97, Loss: 0.5895
Epoch 2/10, Batch 30/97, Loss: 0.4494
Epoch 2/10, Batch 40/97, Loss: 0.5116
Epoch 2/10, Batch 50/97, Loss: 0.3635
Epoch 2/10, Batch 60/97, Loss: 0.5178
Epoch 2/10, Batch 70/97, Loss: 0.3158
Epoch 2/10, Batch 80/97, Loss: 0.4209
Epoch 2/10, Batch 90/97, Loss: 0.3566
Epoch 2/10, Train Loss: 0.4171, Valid Loss: 0.3378
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3349
Epoch 3/10, Batch 20/97, Loss: 0.3224
Epoch 3/10, Batch 30/97, Loss: 0.2907
Epoch 3/10, Batch 40/97, Loss: 0.2167
Epoch 3/10, Batch 50/97, Loss: 0.4920
Epoch 3/10, Batch 60/97, Loss: 0.1548
Epoch 3/10, Batch 70/97, Loss: 0.3182
Epoch 3/10, Batch 80/97, Loss: 0.2951
Epoch 3/10, Batch 90/97, Loss: 0.2519
Epoch 3/10, Train Loss: 0.3431, Valid Loss: 0.2983
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2585
Epoch 4/10, Batch 20/97, Loss: 0.1176
Epoch 4/10, Batch 30/97, Loss: 0.3555
Epoch 4/10, Batch 40/97, Loss: 0.1033
Epoch 4/10, Batch 50/97, Loss: 0.2683
Epoch 4/10, Batch 60/97, Loss: 0.2314
Epoch 4/10, Batch 70/97, Loss: 0.1743
Epoch 4/10, Batch 80/97, Loss: 0.3747
Epoch 4/10, Batch 90/97, Loss: 0.2428
Epoch 4/10, Train Loss: 0.2878, Valid Loss: 0.2836
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2041
Epoch 5/10, Batch 20/97, Loss: 0.3793
Epoch 5/10, Batch 30/97, Loss: 0.2444
Epoch 5/10, Batch 40/97, Loss: 0.1820
Epoch 5/10, Batch 50/97, Loss: 0.3117
Epoch 5/10, Batch 60/97, Loss: 0.3762
Epoch 5/10, Batch 70/97, Loss: 0.2094
Epoch 5/10, Batch 80/97, Loss: 0.2204
Epoch 5/10, Batch 90/97, Loss: 0.2851
Epoch 5/10, Train Loss: 0.2679, Valid Loss: 0.2630
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1663
Epoch 6/10, Batch 20/97, Loss: 0.2603
Epoch 6/10, Batch 30/97, Loss: 0.1500
Epoch 6/10, Batch 40/97, Loss: 0.2435
Epoch 6/10, Batch 50/97, Loss: 0.3534
Epoch 6/10, Batch 60/97, Loss: 0.2270
Epoch 6/10, Batch 70/97, Loss: 0.2658
Epoch 6/10, Batch 80/97, Loss: 0.2305
Epoch 6/10, Batch 90/97, Loss: 0.2775
Epoch 6/10, Train Loss: 0.2473, Valid Loss: 0.2523
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1755
Epoch 7/10, Batch 20/97, Loss: 0.1475
Epoch 7/10, Batch 30/97, Loss: 0.1228
Epoch 7/10, Batch 40/97, Loss: 0.0886
Epoch 7/10, Batch 50/97, Loss: 0.3570
Epoch 7/10, Batch 60/97, Loss: 0.0960
Epoch 7/10, Batch 70/97, Loss: 0.1056
Epoch 7/10, Batch 80/97, Loss: 0.2084
Epoch 7/10, Batch 90/97, Loss: 0.2223
Epoch 7/10, Train Loss: 0.2333, Valid Loss: 0.2489
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1435
Epoch 8/10, Batch 20/97, Loss: 0.1906
Epoch 8/10, Batch 30/97, Loss: 0.0939
Epoch 8/10, Batch 40/97, Loss: 0.2249
Epoch 8/10, Batch 50/97, Loss: 0.3110
Epoch 8/10, Batch 60/97, Loss: 0.1207
Epoch 8/10, Batch 70/97, Loss: 0.2226
Epoch 8/10, Batch 80/97, Loss: 0.0886
Epoch 8/10, Batch 90/97, Loss: 0.2990
Epoch 8/10, Train Loss: 0.2192, Valid Loss: 0.2486
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1374
Epoch 9/10, Batch 20/97, Loss: 0.2894
Epoch 9/10, Batch 30/97, Loss: 0.2885
Epoch 9/10, Batch 40/97, Loss: 0.2004
Epoch 9/10, Batch 50/97, Loss: 0.1246
Epoch 9/10, Batch 60/97, Loss: 0.1778
Epoch 9/10, Batch 70/97, Loss: 0.1793
Epoch 9/10, Batch 80/97, Loss: 0.2737
Epoch 9/10, Batch 90/97, Loss: 0.1640
Epoch 9/10, Train Loss: 0.2053, Valid Loss: 0.2408
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2330
Epoch 10/10, Batch 20/97, Loss: 0.1660
Epoch 10/10, Batch 30/97, Loss: 0.1914
Epoch 10/10, Batch 40/97, Loss: 0.1640
Epoch 10/10, Batch 50/97, Loss: 0.1901
Epoch 10/10, Batch 60/97, Loss: 0.1221
Epoch 10/10, Batch 70/97, Loss: 0.2757
Epoch 10/10, Batch 80/97, Loss: 0.1654
Epoch 10/10, Batch 90/97, Loss: 0.1761
Epoch 10/10, Train Loss: 0.1963, Valid Loss: 0.2402
Model saved!
Accuracy: 0.9077
Precision: 0.9053
Recall: 0.9077
F1-score: 0.9051
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2608
Epoch 1/10, Batch 20/97, Loss: 1.0558
Epoch 1/10, Batch 30/97, Loss: 0.8477
Epoch 1/10, Batch 40/97, Loss: 0.7234
Epoch 1/10, Batch 50/97, Loss: 0.7413
Epoch 1/10, Batch 60/97, Loss: 0.7295
Epoch 1/10, Batch 70/97, Loss: 0.6473
Epoch 1/10, Batch 80/97, Loss: 0.6927
Epoch 1/10, Batch 90/97, Loss: 0.4560
Epoch 1/10, Train Loss: 0.8108, Valid Loss: 0.4446
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5150
Epoch 2/10, Batch 20/97, Loss: 0.4945
Epoch 2/10, Batch 30/97, Loss: 0.3068
Epoch 2/10, Batch 40/97, Loss: 0.4029
Epoch 2/10, Batch 50/97, Loss: 0.4485
Epoch 2/10, Batch 60/97, Loss: 0.4890
Epoch 2/10, Batch 70/97, Loss: 0.4106
Epoch 2/10, Batch 80/97, Loss: 0.4506
Epoch 2/10, Batch 90/97, Loss: 0.3506
Epoch 2/10, Train Loss: 0.4185, Valid Loss: 0.3394
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2810
Epoch 3/10, Batch 20/97, Loss: 0.2422
Epoch 3/10, Batch 30/97, Loss: 0.4600
Epoch 3/10, Batch 40/97, Loss: 0.2731
Epoch 3/10, Batch 50/97, Loss: 0.4132
Epoch 3/10, Batch 60/97, Loss: 0.2845
Epoch 3/10, Batch 70/97, Loss: 0.3832
Epoch 3/10, Batch 80/97, Loss: 0.2732
Epoch 3/10, Batch 90/97, Loss: 0.3176
Epoch 3/10, Train Loss: 0.3436, Valid Loss: 0.2984
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3219
Epoch 4/10, Batch 20/97, Loss: 0.2631
Epoch 4/10, Batch 30/97, Loss: 0.3262
Epoch 4/10, Batch 40/97, Loss: 0.2941
Epoch 4/10, Batch 50/97, Loss: 0.3451
Epoch 4/10, Batch 60/97, Loss: 0.3184
Epoch 4/10, Batch 70/97, Loss: 0.2407
Epoch 4/10, Batch 80/97, Loss: 0.2301
Epoch 4/10, Batch 90/97, Loss: 0.2238
Epoch 4/10, Train Loss: 0.2941, Valid Loss: 0.3009
Epoch 5/10, Batch 10/97, Loss: 0.2900
Epoch 5/10, Batch 20/97, Loss: 0.3017
Epoch 5/10, Batch 30/97, Loss: 0.2080
Epoch 5/10, Batch 40/97, Loss: 0.3953
Epoch 5/10, Batch 50/97, Loss: 0.2449
Epoch 5/10, Batch 60/97, Loss: 0.2126
Epoch 5/10, Batch 70/97, Loss: 0.2462
Epoch 5/10, Batch 80/97, Loss: 0.1848
Epoch 5/10, Batch 90/97, Loss: 0.2020
Epoch 5/10, Train Loss: 0.2719, Valid Loss: 0.2819
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1577
Epoch 6/10, Batch 20/97, Loss: 0.4968
Epoch 6/10, Batch 30/97, Loss: 0.2350
Epoch 6/10, Batch 40/97, Loss: 0.1655
Epoch 6/10, Batch 50/97, Loss: 0.3510
Epoch 6/10, Batch 60/97, Loss: 0.3262
Epoch 6/10, Batch 70/97, Loss: 0.2731
Epoch 6/10, Batch 80/97, Loss: 0.2663
Epoch 6/10, Batch 90/97, Loss: 0.3284
Epoch 6/10, Train Loss: 0.2463, Valid Loss: 0.2682
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2046
Epoch 7/10, Batch 20/97, Loss: 0.2141
Epoch 7/10, Batch 30/97, Loss: 0.2275
Epoch 7/10, Batch 40/97, Loss: 0.2344
Epoch 7/10, Batch 50/97, Loss: 0.3150
Epoch 7/10, Batch 60/97, Loss: 0.1066
Epoch 7/10, Batch 70/97, Loss: 0.2552
Epoch 7/10, Batch 80/97, Loss: 0.3137
Epoch 7/10, Batch 90/97, Loss: 0.1669
Epoch 7/10, Train Loss: 0.2208, Valid Loss: 0.2680
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1728
Epoch 8/10, Batch 20/97, Loss: 0.1537
Epoch 8/10, Batch 30/97, Loss: 0.1404
Epoch 8/10, Batch 40/97, Loss: 0.2010
Epoch 8/10, Batch 50/97, Loss: 0.1830
Epoch 8/10, Batch 60/97, Loss: 0.2617
Epoch 8/10, Batch 70/97, Loss: 0.1281
Epoch 8/10, Batch 80/97, Loss: 0.1908
Epoch 8/10, Batch 90/97, Loss: 0.1870
Epoch 8/10, Train Loss: 0.2231, Valid Loss: 0.2683
Epoch 9/10, Batch 10/97, Loss: 0.1412
Epoch 9/10, Batch 20/97, Loss: 0.1355
Epoch 9/10, Batch 30/97, Loss: 0.2047
Epoch 9/10, Batch 40/97, Loss: 0.1966
Epoch 9/10, Batch 50/97, Loss: 0.1822
Epoch 9/10, Batch 60/97, Loss: 0.1663
Epoch 9/10, Batch 70/97, Loss: 0.1414
Epoch 9/10, Batch 80/97, Loss: 0.1909
Epoch 9/10, Batch 90/97, Loss: 0.1365
Epoch 9/10, Train Loss: 0.2063, Valid Loss: 0.2590
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1854
Epoch 10/10, Batch 20/97, Loss: 0.1092
Epoch 10/10, Batch 30/97, Loss: 0.1930
Epoch 10/10, Batch 40/97, Loss: 0.1211
Epoch 10/10, Batch 50/97, Loss: 0.2362
Epoch 10/10, Batch 60/97, Loss: 0.2536
Epoch 10/10, Batch 70/97, Loss: 0.1402
Epoch 10/10, Batch 80/97, Loss: 0.1639
Epoch 10/10, Batch 90/97, Loss: 0.1789
Epoch 10/10, Train Loss: 0.2017, Valid Loss: 0.2650
Accuracy: 0.9171
Precision: 0.9160
Recall: 0.9171
F1-score: 0.9163
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2334
Epoch 1/10, Batch 20/97, Loss: 1.0148
Epoch 1/10, Batch 30/97, Loss: 0.7138
Epoch 1/10, Batch 40/97, Loss: 0.7394
Epoch 1/10, Batch 50/97, Loss: 0.6221
Epoch 1/10, Batch 60/97, Loss: 0.6458
Epoch 1/10, Batch 70/97, Loss: 0.7096
Epoch 1/10, Batch 80/97, Loss: 0.6123
Epoch 1/10, Batch 90/97, Loss: 0.5898
Epoch 1/10, Train Loss: 0.8097, Valid Loss: 0.4604
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6748
Epoch 2/10, Batch 20/97, Loss: 0.5346
Epoch 2/10, Batch 30/97, Loss: 0.4387
Epoch 2/10, Batch 40/97, Loss: 0.2726
Epoch 2/10, Batch 50/97, Loss: 0.5434
Epoch 2/10, Batch 60/97, Loss: 0.4083
Epoch 2/10, Batch 70/97, Loss: 0.3379
Epoch 2/10, Batch 80/97, Loss: 0.4465
Epoch 2/10, Batch 90/97, Loss: 0.3038
Epoch 2/10, Train Loss: 0.4161, Valid Loss: 0.3384
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4462
Epoch 3/10, Batch 20/97, Loss: 0.3923
Epoch 3/10, Batch 30/97, Loss: 0.3274
Epoch 3/10, Batch 40/97, Loss: 0.3102
Epoch 3/10, Batch 50/97, Loss: 0.4683
Epoch 3/10, Batch 60/97, Loss: 0.1922
Epoch 3/10, Batch 70/97, Loss: 0.3839
Epoch 3/10, Batch 80/97, Loss: 0.2468
Epoch 3/10, Batch 90/97, Loss: 0.4207
Epoch 3/10, Train Loss: 0.3347, Valid Loss: 0.2985
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3912
Epoch 4/10, Batch 20/97, Loss: 0.2186
Epoch 4/10, Batch 30/97, Loss: 0.2632
Epoch 4/10, Batch 40/97, Loss: 0.1943
Epoch 4/10, Batch 50/97, Loss: 0.4302
Epoch 4/10, Batch 60/97, Loss: 0.2686
Epoch 4/10, Batch 70/97, Loss: 0.3066
Epoch 4/10, Batch 80/97, Loss: 0.2615
Epoch 4/10, Batch 90/97, Loss: 0.2395
Epoch 4/10, Train Loss: 0.2888, Valid Loss: 0.2832
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2538
Epoch 5/10, Batch 20/97, Loss: 0.3450
Epoch 5/10, Batch 30/97, Loss: 0.2345
Epoch 5/10, Batch 40/97, Loss: 0.2326
Epoch 5/10, Batch 50/97, Loss: 0.1294
Epoch 5/10, Batch 60/97, Loss: 0.4122
Epoch 5/10, Batch 70/97, Loss: 0.3538
Epoch 5/10, Batch 80/97, Loss: 0.1658
Epoch 5/10, Batch 90/97, Loss: 0.1502
Epoch 5/10, Train Loss: 0.2681, Valid Loss: 0.2614
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1623
Epoch 6/10, Batch 20/97, Loss: 0.2580
Epoch 6/10, Batch 30/97, Loss: 0.2691
Epoch 6/10, Batch 40/97, Loss: 0.1561
Epoch 6/10, Batch 50/97, Loss: 0.2118
Epoch 6/10, Batch 60/97, Loss: 0.2523
Epoch 6/10, Batch 70/97, Loss: 0.3132
Epoch 6/10, Batch 80/97, Loss: 0.1513
Epoch 6/10, Batch 90/97, Loss: 0.3552
Epoch 6/10, Train Loss: 0.2501, Valid Loss: 0.2515
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1990
Epoch 7/10, Batch 20/97, Loss: 0.4167
Epoch 7/10, Batch 30/97, Loss: 0.2560
Epoch 7/10, Batch 40/97, Loss: 0.1701
Epoch 7/10, Batch 50/97, Loss: 0.4342
Epoch 7/10, Batch 60/97, Loss: 0.1880
Epoch 7/10, Batch 70/97, Loss: 0.3844
Epoch 7/10, Batch 80/97, Loss: 0.3259
Epoch 7/10, Batch 90/97, Loss: 0.2016
Epoch 7/10, Train Loss: 0.2294, Valid Loss: 0.2406
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1106
Epoch 8/10, Batch 20/97, Loss: 0.1395
Epoch 8/10, Batch 30/97, Loss: 0.2312
Epoch 8/10, Batch 40/97, Loss: 0.2346
Epoch 8/10, Batch 50/97, Loss: 0.2851
Epoch 8/10, Batch 60/97, Loss: 0.1977
Epoch 8/10, Batch 70/97, Loss: 0.1561
Epoch 8/10, Batch 80/97, Loss: 0.1231
Epoch 8/10, Batch 90/97, Loss: 0.1140
Epoch 8/10, Train Loss: 0.2201, Valid Loss: 0.2433
Epoch 9/10, Batch 10/97, Loss: 0.1335
Epoch 9/10, Batch 20/97, Loss: 0.1261
Epoch 9/10, Batch 30/97, Loss: 0.2583
Epoch 9/10, Batch 40/97, Loss: 0.1924
Epoch 9/10, Batch 50/97, Loss: 0.1863
Epoch 9/10, Batch 60/97, Loss: 0.2357
Epoch 9/10, Batch 70/97, Loss: 0.1376
Epoch 9/10, Batch 80/97, Loss: 0.1744
Epoch 9/10, Batch 90/97, Loss: 0.2263
Epoch 9/10, Train Loss: 0.2067, Valid Loss: 0.2375
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2001
Epoch 10/10, Batch 20/97, Loss: 0.1961
Epoch 10/10, Batch 30/97, Loss: 0.2151
Epoch 10/10, Batch 40/97, Loss: 0.1315
Epoch 10/10, Batch 50/97, Loss: 0.2884
Epoch 10/10, Batch 60/97, Loss: 0.1145
Epoch 10/10, Batch 70/97, Loss: 0.1918
Epoch 10/10, Batch 80/97, Loss: 0.3172
Epoch 10/10, Batch 90/97, Loss: 0.2402
Epoch 10/10, Train Loss: 0.2108, Valid Loss: 0.2344
Model saved!
Accuracy: 0.9112
Precision: 0.9084
Recall: 0.9112
F1-score: 0.9078
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.3110
Epoch 1/10, Batch 20/97, Loss: 1.1577
Epoch 1/10, Batch 30/97, Loss: 0.7479
Epoch 1/10, Batch 40/97, Loss: 0.7536
Epoch 1/10, Batch 50/97, Loss: 0.6879
Epoch 1/10, Batch 60/97, Loss: 0.8454
Epoch 1/10, Batch 70/97, Loss: 0.5272
Epoch 1/10, Batch 80/97, Loss: 0.5807
Epoch 1/10, Batch 90/97, Loss: 0.6054
Epoch 1/10, Train Loss: 0.8049, Valid Loss: 0.4427
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5865
Epoch 2/10, Batch 20/97, Loss: 0.3512
Epoch 2/10, Batch 30/97, Loss: 0.4492
Epoch 2/10, Batch 40/97, Loss: 0.3587
Epoch 2/10, Batch 50/97, Loss: 0.3681
Epoch 2/10, Batch 60/97, Loss: 0.4540
Epoch 2/10, Batch 70/97, Loss: 0.3813
Epoch 2/10, Batch 80/97, Loss: 0.3408
Epoch 2/10, Batch 90/97, Loss: 0.2930
Epoch 2/10, Train Loss: 0.4170, Valid Loss: 0.3372
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3454
Epoch 3/10, Batch 20/97, Loss: 0.5421
Epoch 3/10, Batch 30/97, Loss: 0.3623
Epoch 3/10, Batch 40/97, Loss: 0.3496
Epoch 3/10, Batch 50/97, Loss: 0.5240
Epoch 3/10, Batch 60/97, Loss: 0.3203
Epoch 3/10, Batch 70/97, Loss: 0.4479
Epoch 3/10, Batch 80/97, Loss: 0.3154
Epoch 3/10, Batch 90/97, Loss: 0.1959
Epoch 3/10, Train Loss: 0.3394, Valid Loss: 0.3009
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3308
Epoch 4/10, Batch 20/97, Loss: 0.2346
Epoch 4/10, Batch 30/97, Loss: 0.2552
Epoch 4/10, Batch 40/97, Loss: 0.2492
Epoch 4/10, Batch 50/97, Loss: 0.2950
Epoch 4/10, Batch 60/97, Loss: 0.1672
Epoch 4/10, Batch 70/97, Loss: 0.3098
Epoch 4/10, Batch 80/97, Loss: 0.3084
Epoch 4/10, Batch 90/97, Loss: 0.2519
Epoch 4/10, Train Loss: 0.2960, Valid Loss: 0.2811
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3302
Epoch 5/10, Batch 20/97, Loss: 0.4534
Epoch 5/10, Batch 30/97, Loss: 0.1950
Epoch 5/10, Batch 40/97, Loss: 0.2215
Epoch 5/10, Batch 50/97, Loss: 0.2737
Epoch 5/10, Batch 60/97, Loss: 0.2907
Epoch 5/10, Batch 70/97, Loss: 0.2363
Epoch 5/10, Batch 80/97, Loss: 0.2118
Epoch 5/10, Batch 90/97, Loss: 0.1983
Epoch 5/10, Train Loss: 0.2701, Valid Loss: 0.2710
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3540
Epoch 6/10, Batch 20/97, Loss: 0.3234
Epoch 6/10, Batch 30/97, Loss: 0.1330
Epoch 6/10, Batch 40/97, Loss: 0.1138
Epoch 6/10, Batch 50/97, Loss: 0.1952
Epoch 6/10, Batch 60/97, Loss: 0.2887
Epoch 6/10, Batch 70/97, Loss: 0.1797
Epoch 6/10, Batch 80/97, Loss: 0.2736
Epoch 6/10, Batch 90/97, Loss: 0.5276
Epoch 6/10, Train Loss: 0.2509, Valid Loss: 0.2569
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2288
Epoch 7/10, Batch 20/97, Loss: 0.2544
Epoch 7/10, Batch 30/97, Loss: 0.2186
Epoch 7/10, Batch 40/97, Loss: 0.1422
Epoch 7/10, Batch 50/97, Loss: 0.2478
Epoch 7/10, Batch 60/97, Loss: 0.1122
Epoch 7/10, Batch 70/97, Loss: 0.1825
Epoch 7/10, Batch 80/97, Loss: 0.2385
Epoch 7/10, Batch 90/97, Loss: 0.1505
Epoch 7/10, Train Loss: 0.2435, Valid Loss: 0.2550
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1379
Epoch 8/10, Batch 20/97, Loss: 0.2448
Epoch 8/10, Batch 30/97, Loss: 0.1253
Epoch 8/10, Batch 40/97, Loss: 0.2386
Epoch 8/10, Batch 50/97, Loss: 0.2018
Epoch 8/10, Batch 60/97, Loss: 0.0948
Epoch 8/10, Batch 70/97, Loss: 0.1661
Epoch 8/10, Batch 80/97, Loss: 0.1993
Epoch 8/10, Batch 90/97, Loss: 0.2119
Epoch 8/10, Train Loss: 0.2264, Valid Loss: 0.2480
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2111
Epoch 9/10, Batch 20/97, Loss: 0.1039
Epoch 9/10, Batch 30/97, Loss: 0.2184
Epoch 9/10, Batch 40/97, Loss: 0.2821
Epoch 9/10, Batch 50/97, Loss: 0.1635
Epoch 9/10, Batch 60/97, Loss: 0.2783
Epoch 9/10, Batch 70/97, Loss: 0.1033
Epoch 9/10, Batch 80/97, Loss: 0.1425
Epoch 9/10, Batch 90/97, Loss: 0.1561
Epoch 9/10, Train Loss: 0.2079, Valid Loss: 0.2423
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3101
Epoch 10/10, Batch 20/97, Loss: 0.1934
Epoch 10/10, Batch 30/97, Loss: 0.1040
Epoch 10/10, Batch 40/97, Loss: 0.1364
Epoch 10/10, Batch 50/97, Loss: 0.2413
Epoch 10/10, Batch 60/97, Loss: 0.2155
Epoch 10/10, Batch 70/97, Loss: 0.1721
Epoch 10/10, Batch 80/97, Loss: 0.1803
Epoch 10/10, Batch 90/97, Loss: 0.1983
Epoch 10/10, Train Loss: 0.2065, Valid Loss: 0.2473
Accuracy: 0.9171
Precision: 0.9161
Recall: 0.9171
F1-score: 0.9152
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2500
Epoch 1/10, Batch 20/97, Loss: 1.1475
Epoch 1/10, Batch 30/97, Loss: 0.8945
Epoch 1/10, Batch 40/97, Loss: 0.7442
Epoch 1/10, Batch 50/97, Loss: 0.5093
Epoch 1/10, Batch 60/97, Loss: 0.5931
Epoch 1/10, Batch 70/97, Loss: 0.6811
Epoch 1/10, Batch 80/97, Loss: 0.6487
Epoch 1/10, Batch 90/97, Loss: 0.5111
Epoch 1/10, Train Loss: 0.8107, Valid Loss: 0.4623
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4531
Epoch 2/10, Batch 20/97, Loss: 0.4400
Epoch 2/10, Batch 30/97, Loss: 0.3150
Epoch 2/10, Batch 40/97, Loss: 0.4519
Epoch 2/10, Batch 50/97, Loss: 0.3927
Epoch 2/10, Batch 60/97, Loss: 0.5409
Epoch 2/10, Batch 70/97, Loss: 0.4422
Epoch 2/10, Batch 80/97, Loss: 0.3098
Epoch 2/10, Batch 90/97, Loss: 0.3868
Epoch 2/10, Train Loss: 0.4148, Valid Loss: 0.3547
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4204
Epoch 3/10, Batch 20/97, Loss: 0.3249
Epoch 3/10, Batch 30/97, Loss: 0.4547
Epoch 3/10, Batch 40/97, Loss: 0.2365
Epoch 3/10, Batch 50/97, Loss: 0.2950
Epoch 3/10, Batch 60/97, Loss: 0.3508
Epoch 3/10, Batch 70/97, Loss: 0.3842
Epoch 3/10, Batch 80/97, Loss: 0.3316
Epoch 3/10, Batch 90/97, Loss: 0.4309
Epoch 3/10, Train Loss: 0.3307, Valid Loss: 0.3148
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3871
Epoch 4/10, Batch 20/97, Loss: 0.2275
Epoch 4/10, Batch 30/97, Loss: 0.3778
Epoch 4/10, Batch 40/97, Loss: 0.1735
Epoch 4/10, Batch 50/97, Loss: 0.3054
Epoch 4/10, Batch 60/97, Loss: 0.2384
Epoch 4/10, Batch 70/97, Loss: 0.3473
Epoch 4/10, Batch 80/97, Loss: 0.2438
Epoch 4/10, Batch 90/97, Loss: 0.1477
Epoch 4/10, Train Loss: 0.2813, Valid Loss: 0.2917
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2552
Epoch 5/10, Batch 20/97, Loss: 0.3595
Epoch 5/10, Batch 30/97, Loss: 0.2136
Epoch 5/10, Batch 40/97, Loss: 0.2188
Epoch 5/10, Batch 50/97, Loss: 0.1858
Epoch 5/10, Batch 60/97, Loss: 0.1753
Epoch 5/10, Batch 70/97, Loss: 0.2828
Epoch 5/10, Batch 80/97, Loss: 0.2154
Epoch 5/10, Batch 90/97, Loss: 0.2166
Epoch 5/10, Train Loss: 0.2679, Valid Loss: 0.2893
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.0950
Epoch 6/10, Batch 20/97, Loss: 0.2892
Epoch 6/10, Batch 30/97, Loss: 0.2180
Epoch 6/10, Batch 40/97, Loss: 0.1109
Epoch 6/10, Batch 50/97, Loss: 0.1792
Epoch 6/10, Batch 60/97, Loss: 0.4573
Epoch 6/10, Batch 70/97, Loss: 0.1664
Epoch 6/10, Batch 80/97, Loss: 0.3240
Epoch 6/10, Batch 90/97, Loss: 0.3642
Epoch 6/10, Train Loss: 0.2416, Valid Loss: 0.2720
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1493
Epoch 7/10, Batch 20/97, Loss: 0.1791
Epoch 7/10, Batch 30/97, Loss: 0.1737
Epoch 7/10, Batch 40/97, Loss: 0.1280
Epoch 7/10, Batch 50/97, Loss: 0.1628
Epoch 7/10, Batch 60/97, Loss: 0.1108
Epoch 7/10, Batch 70/97, Loss: 0.2402
Epoch 7/10, Batch 80/97, Loss: 0.2369
Epoch 7/10, Batch 90/97, Loss: 0.1870
Epoch 7/10, Train Loss: 0.2261, Valid Loss: 0.2702
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1937
Epoch 8/10, Batch 20/97, Loss: 0.1484
Epoch 8/10, Batch 30/97, Loss: 0.1298
Epoch 8/10, Batch 40/97, Loss: 0.1371
Epoch 8/10, Batch 50/97, Loss: 0.1803
Epoch 8/10, Batch 60/97, Loss: 0.1865
Epoch 8/10, Batch 70/97, Loss: 0.3660
Epoch 8/10, Batch 80/97, Loss: 0.2132
Epoch 8/10, Batch 90/97, Loss: 0.1256
Epoch 8/10, Train Loss: 0.2148, Valid Loss: 0.2599
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1515
Epoch 9/10, Batch 20/97, Loss: 0.1841
Epoch 9/10, Batch 30/97, Loss: 0.2386
Epoch 9/10, Batch 40/97, Loss: 0.1752
Epoch 9/10, Batch 50/97, Loss: 0.2770
Epoch 9/10, Batch 60/97, Loss: 0.2451
Epoch 9/10, Batch 70/97, Loss: 0.1166
Epoch 9/10, Batch 80/97, Loss: 0.2070
Epoch 9/10, Batch 90/97, Loss: 0.1325
Epoch 9/10, Train Loss: 0.2065, Valid Loss: 0.2608
Epoch 10/10, Batch 10/97, Loss: 0.2041
Epoch 10/10, Batch 20/97, Loss: 0.1553
Epoch 10/10, Batch 30/97, Loss: 0.1966
Epoch 10/10, Batch 40/97, Loss: 0.1093
Epoch 10/10, Batch 50/97, Loss: 0.1316
Epoch 10/10, Batch 60/97, Loss: 0.1116
Epoch 10/10, Batch 70/97, Loss: 0.2526
Epoch 10/10, Batch 80/97, Loss: 0.1972
Epoch 10/10, Batch 90/97, Loss: 0.1939
Epoch 10/10, Train Loss: 0.2037, Valid Loss: 0.2605
Accuracy: 0.9112
Precision: 0.9082
Recall: 0.9112
F1-score: 0.9090
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2359
Epoch 1/10, Batch 20/97, Loss: 1.0210
Epoch 1/10, Batch 30/97, Loss: 0.7408
Epoch 1/10, Batch 40/97, Loss: 0.7726
Epoch 1/10, Batch 50/97, Loss: 0.6710
Epoch 1/10, Batch 60/97, Loss: 0.7588
Epoch 1/10, Batch 70/97, Loss: 0.5184
Epoch 1/10, Batch 80/97, Loss: 0.5826
Epoch 1/10, Batch 90/97, Loss: 0.6765
Epoch 1/10, Train Loss: 0.8141, Valid Loss: 0.4579
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5275
Epoch 2/10, Batch 20/97, Loss: 0.4154
Epoch 2/10, Batch 30/97, Loss: 0.4045
Epoch 2/10, Batch 40/97, Loss: 0.3396
Epoch 2/10, Batch 50/97, Loss: 0.3399
Epoch 2/10, Batch 60/97, Loss: 0.4138
Epoch 2/10, Batch 70/97, Loss: 0.2726
Epoch 2/10, Batch 80/97, Loss: 0.5212
Epoch 2/10, Batch 90/97, Loss: 0.3018
Epoch 2/10, Train Loss: 0.4158, Valid Loss: 0.3488
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3029
Epoch 3/10, Batch 20/97, Loss: 0.3541
Epoch 3/10, Batch 30/97, Loss: 0.3580
Epoch 3/10, Batch 40/97, Loss: 0.2567
Epoch 3/10, Batch 50/97, Loss: 0.2548
Epoch 3/10, Batch 60/97, Loss: 0.3461
Epoch 3/10, Batch 70/97, Loss: 0.3837
Epoch 3/10, Batch 80/97, Loss: 0.3474
Epoch 3/10, Batch 90/97, Loss: 0.2240
Epoch 3/10, Train Loss: 0.3416, Valid Loss: 0.2991
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.7187
Epoch 4/10, Batch 20/97, Loss: 0.2403
Epoch 4/10, Batch 30/97, Loss: 0.2628
Epoch 4/10, Batch 40/97, Loss: 0.3081
Epoch 4/10, Batch 50/97, Loss: 0.4017
Epoch 4/10, Batch 60/97, Loss: 0.2507
Epoch 4/10, Batch 70/97, Loss: 0.5077
Epoch 4/10, Batch 80/97, Loss: 0.2610
Epoch 4/10, Batch 90/97, Loss: 0.2466
Epoch 4/10, Train Loss: 0.2901, Valid Loss: 0.2956
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2343
Epoch 5/10, Batch 20/97, Loss: 0.4417
Epoch 5/10, Batch 30/97, Loss: 0.1555
Epoch 5/10, Batch 40/97, Loss: 0.2596
Epoch 5/10, Batch 50/97, Loss: 0.3122
Epoch 5/10, Batch 60/97, Loss: 0.1464
Epoch 5/10, Batch 70/97, Loss: 0.2887
Epoch 5/10, Batch 80/97, Loss: 0.2428
Epoch 5/10, Batch 90/97, Loss: 0.2119
Epoch 5/10, Train Loss: 0.2718, Valid Loss: 0.2733
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3499
Epoch 6/10, Batch 20/97, Loss: 0.4750
Epoch 6/10, Batch 30/97, Loss: 0.2549
Epoch 6/10, Batch 40/97, Loss: 0.1394
Epoch 6/10, Batch 50/97, Loss: 0.1352
Epoch 6/10, Batch 60/97, Loss: 0.3307
Epoch 6/10, Batch 70/97, Loss: 0.2960
Epoch 6/10, Batch 80/97, Loss: 0.3137
Epoch 6/10, Batch 90/97, Loss: 0.2183
Epoch 6/10, Train Loss: 0.2561, Valid Loss: 0.2469
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2569
Epoch 7/10, Batch 20/97, Loss: 0.2810
Epoch 7/10, Batch 30/97, Loss: 0.2676
Epoch 7/10, Batch 40/97, Loss: 0.0838
Epoch 7/10, Batch 50/97, Loss: 0.1592
Epoch 7/10, Batch 60/97, Loss: 0.1438
Epoch 7/10, Batch 70/97, Loss: 0.1907
Epoch 7/10, Batch 80/97, Loss: 0.2575
Epoch 7/10, Batch 90/97, Loss: 0.2829
Epoch 7/10, Train Loss: 0.2289, Valid Loss: 0.2449
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1700
Epoch 8/10, Batch 20/97, Loss: 0.3086
Epoch 8/10, Batch 30/97, Loss: 0.2214
Epoch 8/10, Batch 40/97, Loss: 0.2505
Epoch 8/10, Batch 50/97, Loss: 0.1488
Epoch 8/10, Batch 60/97, Loss: 0.1264
Epoch 8/10, Batch 70/97, Loss: 0.2869
Epoch 8/10, Batch 80/97, Loss: 0.1884
Epoch 8/10, Batch 90/97, Loss: 0.2237
Epoch 8/10, Train Loss: 0.2222, Valid Loss: 0.2440
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2708
Epoch 9/10, Batch 20/97, Loss: 0.1015
Epoch 9/10, Batch 30/97, Loss: 0.2191
Epoch 9/10, Batch 40/97, Loss: 0.2359
Epoch 9/10, Batch 50/97, Loss: 0.1408
Epoch 9/10, Batch 60/97, Loss: 0.3501
Epoch 9/10, Batch 70/97, Loss: 0.1345
Epoch 9/10, Batch 80/97, Loss: 0.0783
Epoch 9/10, Batch 90/97, Loss: 0.1198
Epoch 9/10, Train Loss: 0.2188, Valid Loss: 0.2331
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1969
Epoch 10/10, Batch 20/97, Loss: 0.0942
Epoch 10/10, Batch 30/97, Loss: 0.1171
Epoch 10/10, Batch 40/97, Loss: 0.2191
Epoch 10/10, Batch 50/97, Loss: 0.1205
Epoch 10/10, Batch 60/97, Loss: 0.1703
Epoch 10/10, Batch 70/97, Loss: 0.2556
Epoch 10/10, Batch 80/97, Loss: 0.2885
Epoch 10/10, Batch 90/97, Loss: 0.1529
Epoch 10/10, Train Loss: 0.2044, Valid Loss: 0.2308
Model saved!
Accuracy: 0.9159
Precision: 0.9151
Recall: 0.9159
F1-score: 0.9134
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2578
Epoch 1/10, Batch 20/97, Loss: 1.0574
Epoch 1/10, Batch 30/97, Loss: 0.7167
Epoch 1/10, Batch 40/97, Loss: 0.6698
Epoch 1/10, Batch 50/97, Loss: 0.5351
Epoch 1/10, Batch 60/97, Loss: 0.7064
Epoch 1/10, Batch 70/97, Loss: 0.7169
Epoch 1/10, Batch 80/97, Loss: 0.6411
Epoch 1/10, Batch 90/97, Loss: 0.7115
Epoch 1/10, Train Loss: 0.8038, Valid Loss: 0.4364
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5465
Epoch 2/10, Batch 20/97, Loss: 0.4235
Epoch 2/10, Batch 30/97, Loss: 0.2940
Epoch 2/10, Batch 40/97, Loss: 0.3667
Epoch 2/10, Batch 50/97, Loss: 0.3755
Epoch 2/10, Batch 60/97, Loss: 0.4310
Epoch 2/10, Batch 70/97, Loss: 0.2510
Epoch 2/10, Batch 80/97, Loss: 0.3044
Epoch 2/10, Batch 90/97, Loss: 0.5361
Epoch 2/10, Train Loss: 0.4182, Valid Loss: 0.3371
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3925
Epoch 3/10, Batch 20/97, Loss: 0.3623
Epoch 3/10, Batch 30/97, Loss: 0.4307
Epoch 3/10, Batch 40/97, Loss: 0.3229
Epoch 3/10, Batch 50/97, Loss: 0.4211
Epoch 3/10, Batch 60/97, Loss: 0.2694
Epoch 3/10, Batch 70/97, Loss: 0.2893
Epoch 3/10, Batch 80/97, Loss: 0.3504
Epoch 3/10, Batch 90/97, Loss: 0.1663
Epoch 3/10, Train Loss: 0.3406, Valid Loss: 0.2918
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3926
Epoch 4/10, Batch 20/97, Loss: 0.1662
Epoch 4/10, Batch 30/97, Loss: 0.2708
Epoch 4/10, Batch 40/97, Loss: 0.1896
Epoch 4/10, Batch 50/97, Loss: 0.3313
Epoch 4/10, Batch 60/97, Loss: 0.2651
Epoch 4/10, Batch 70/97, Loss: 0.3173
Epoch 4/10, Batch 80/97, Loss: 0.1756
Epoch 4/10, Batch 90/97, Loss: 0.1751
Epoch 4/10, Train Loss: 0.2893, Valid Loss: 0.2733
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2357
Epoch 5/10, Batch 20/97, Loss: 0.2649
Epoch 5/10, Batch 30/97, Loss: 0.2690
Epoch 5/10, Batch 40/97, Loss: 0.2441
Epoch 5/10, Batch 50/97, Loss: 0.3014
Epoch 5/10, Batch 60/97, Loss: 0.3485
Epoch 5/10, Batch 70/97, Loss: 0.2771
Epoch 5/10, Batch 80/97, Loss: 0.2198
Epoch 5/10, Batch 90/97, Loss: 0.2667
Epoch 5/10, Train Loss: 0.2722, Valid Loss: 0.2420
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1320
Epoch 6/10, Batch 20/97, Loss: 0.2481
Epoch 6/10, Batch 30/97, Loss: 0.1046
Epoch 6/10, Batch 40/97, Loss: 0.1967
Epoch 6/10, Batch 50/97, Loss: 0.1244
Epoch 6/10, Batch 60/97, Loss: 0.2722
Epoch 6/10, Batch 70/97, Loss: 0.3189
Epoch 6/10, Batch 80/97, Loss: 0.3937
Epoch 6/10, Batch 90/97, Loss: 0.2688
Epoch 6/10, Train Loss: 0.2462, Valid Loss: 0.2310
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2745
Epoch 7/10, Batch 20/97, Loss: 0.3190
Epoch 7/10, Batch 30/97, Loss: 0.2488
Epoch 7/10, Batch 40/97, Loss: 0.1748
Epoch 7/10, Batch 50/97, Loss: 0.3645
Epoch 7/10, Batch 60/97, Loss: 0.1220
Epoch 7/10, Batch 70/97, Loss: 0.2793
Epoch 7/10, Batch 80/97, Loss: 0.1502
Epoch 7/10, Batch 90/97, Loss: 0.1314
Epoch 7/10, Train Loss: 0.2271, Valid Loss: 0.2299
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2197
Epoch 8/10, Batch 20/97, Loss: 0.2179
Epoch 8/10, Batch 30/97, Loss: 0.1096
Epoch 8/10, Batch 40/97, Loss: 0.1658
Epoch 8/10, Batch 50/97, Loss: 0.2226
Epoch 8/10, Batch 60/97, Loss: 0.1074
Epoch 8/10, Batch 70/97, Loss: 0.1889
Epoch 8/10, Batch 80/97, Loss: 0.3499
Epoch 8/10, Batch 90/97, Loss: 0.1294
Epoch 8/10, Train Loss: 0.2237, Valid Loss: 0.2209
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1825
Epoch 9/10, Batch 20/97, Loss: 0.2761
Epoch 9/10, Batch 30/97, Loss: 0.2929
Epoch 9/10, Batch 40/97, Loss: 0.3103
Epoch 9/10, Batch 50/97, Loss: 0.1955
Epoch 9/10, Batch 60/97, Loss: 0.1890
Epoch 9/10, Batch 70/97, Loss: 0.1569
Epoch 9/10, Batch 80/97, Loss: 0.1201
Epoch 9/10, Batch 90/97, Loss: 0.1378
Epoch 9/10, Train Loss: 0.2085, Valid Loss: 0.2157
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1429
Epoch 10/10, Batch 20/97, Loss: 0.1747
Epoch 10/10, Batch 30/97, Loss: 0.2513
Epoch 10/10, Batch 40/97, Loss: 0.1557
Epoch 10/10, Batch 50/97, Loss: 0.1682
Epoch 10/10, Batch 60/97, Loss: 0.3807
Epoch 10/10, Batch 70/97, Loss: 0.1784
Epoch 10/10, Batch 80/97, Loss: 0.2360
Epoch 10/10, Batch 90/97, Loss: 0.2069
Epoch 10/10, Train Loss: 0.2079, Valid Loss: 0.2147
Model saved!
Accuracy: 0.9194
Precision: 0.9166
Recall: 0.9194
F1-score: 0.9168
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2506
Epoch 1/10, Batch 20/97, Loss: 1.0622
Epoch 1/10, Batch 30/97, Loss: 0.7507
Epoch 1/10, Batch 40/97, Loss: 0.7686
Epoch 1/10, Batch 50/97, Loss: 0.7233
Epoch 1/10, Batch 60/97, Loss: 0.8274
Epoch 1/10, Batch 70/97, Loss: 0.5275
Epoch 1/10, Batch 80/97, Loss: 0.6835
Epoch 1/10, Batch 90/97, Loss: 0.5086
Epoch 1/10, Train Loss: 0.7979, Valid Loss: 0.4677
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5322
Epoch 2/10, Batch 20/97, Loss: 0.3810
Epoch 2/10, Batch 30/97, Loss: 0.3123
Epoch 2/10, Batch 40/97, Loss: 0.3929
Epoch 2/10, Batch 50/97, Loss: 0.4614
Epoch 2/10, Batch 60/97, Loss: 0.3002
Epoch 2/10, Batch 70/97, Loss: 0.3884
Epoch 2/10, Batch 80/97, Loss: 0.3596
Epoch 2/10, Batch 90/97, Loss: 0.4504
Epoch 2/10, Train Loss: 0.4063, Valid Loss: 0.3555
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3933
Epoch 3/10, Batch 20/97, Loss: 0.3496
Epoch 3/10, Batch 30/97, Loss: 0.2109
Epoch 3/10, Batch 40/97, Loss: 0.3115
Epoch 3/10, Batch 50/97, Loss: 0.2610
Epoch 3/10, Batch 60/97, Loss: 0.2659
Epoch 3/10, Batch 70/97, Loss: 0.4137
Epoch 3/10, Batch 80/97, Loss: 0.2361
Epoch 3/10, Batch 90/97, Loss: 0.2679
Epoch 3/10, Train Loss: 0.3328, Valid Loss: 0.3163
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3081
Epoch 4/10, Batch 20/97, Loss: 0.2909
Epoch 4/10, Batch 30/97, Loss: 0.3094
Epoch 4/10, Batch 40/97, Loss: 0.2704
Epoch 4/10, Batch 50/97, Loss: 0.2899
Epoch 4/10, Batch 60/97, Loss: 0.2319
Epoch 4/10, Batch 70/97, Loss: 0.2329
Epoch 4/10, Batch 80/97, Loss: 0.2128
Epoch 4/10, Batch 90/97, Loss: 0.1413
Epoch 4/10, Train Loss: 0.2863, Valid Loss: 0.3003
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1141
Epoch 5/10, Batch 20/97, Loss: 0.2594
Epoch 5/10, Batch 30/97, Loss: 0.3372
Epoch 5/10, Batch 40/97, Loss: 0.2236
Epoch 5/10, Batch 50/97, Loss: 0.1665
Epoch 5/10, Batch 60/97, Loss: 0.2009
Epoch 5/10, Batch 70/97, Loss: 0.2913
Epoch 5/10, Batch 80/97, Loss: 0.3158
Epoch 5/10, Batch 90/97, Loss: 0.1083
Epoch 5/10, Train Loss: 0.2626, Valid Loss: 0.2966
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2485
Epoch 6/10, Batch 20/97, Loss: 0.5594
Epoch 6/10, Batch 30/97, Loss: 0.1605
Epoch 6/10, Batch 40/97, Loss: 0.3350
Epoch 6/10, Batch 50/97, Loss: 0.1932
Epoch 6/10, Batch 60/97, Loss: 0.1729
Epoch 6/10, Batch 70/97, Loss: 0.2626
Epoch 6/10, Batch 80/97, Loss: 0.3052
Epoch 6/10, Batch 90/97, Loss: 0.2278
Epoch 6/10, Train Loss: 0.2488, Valid Loss: 0.2674
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1133
Epoch 7/10, Batch 20/97, Loss: 0.2380
Epoch 7/10, Batch 30/97, Loss: 0.3766
Epoch 7/10, Batch 40/97, Loss: 0.2244
Epoch 7/10, Batch 50/97, Loss: 0.2211
Epoch 7/10, Batch 60/97, Loss: 0.1144
Epoch 7/10, Batch 70/97, Loss: 0.3035
Epoch 7/10, Batch 80/97, Loss: 0.1382
Epoch 7/10, Batch 90/97, Loss: 0.1419
Epoch 7/10, Train Loss: 0.2267, Valid Loss: 0.2607
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2797
Epoch 8/10, Batch 20/97, Loss: 0.1455
Epoch 8/10, Batch 30/97, Loss: 0.1881
Epoch 8/10, Batch 40/97, Loss: 0.1077
Epoch 8/10, Batch 50/97, Loss: 0.1950
Epoch 8/10, Batch 60/97, Loss: 0.2361
Epoch 8/10, Batch 70/97, Loss: 0.1658
Epoch 8/10, Batch 80/97, Loss: 0.3230
Epoch 8/10, Batch 90/97, Loss: 0.2309
Epoch 8/10, Train Loss: 0.2192, Valid Loss: 0.2569
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2801
Epoch 9/10, Batch 20/97, Loss: 0.0918
Epoch 9/10, Batch 30/97, Loss: 0.2178
Epoch 9/10, Batch 40/97, Loss: 0.2660
Epoch 9/10, Batch 50/97, Loss: 0.2329
Epoch 9/10, Batch 60/97, Loss: 0.2173
Epoch 9/10, Batch 70/97, Loss: 0.2726
Epoch 9/10, Batch 80/97, Loss: 0.2105
Epoch 9/10, Batch 90/97, Loss: 0.1699
Epoch 9/10, Train Loss: 0.2095, Valid Loss: 0.2546
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2284
Epoch 10/10, Batch 20/97, Loss: 0.1517
Epoch 10/10, Batch 30/97, Loss: 0.1555
Epoch 10/10, Batch 40/97, Loss: 0.1410
Epoch 10/10, Batch 50/97, Loss: 0.1283
Epoch 10/10, Batch 60/97, Loss: 0.2000
Epoch 10/10, Batch 70/97, Loss: 0.3242
Epoch 10/10, Batch 80/97, Loss: 0.2057
Epoch 10/10, Batch 90/97, Loss: 0.0826
Epoch 10/10, Train Loss: 0.2013, Valid Loss: 0.2595
Accuracy: 0.9077
Precision: 0.9060
Recall: 0.9077
F1-score: 0.9062
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2057
Epoch 1/10, Batch 20/97, Loss: 1.1439
Epoch 1/10, Batch 30/97, Loss: 0.7941
Epoch 1/10, Batch 40/97, Loss: 0.6969
Epoch 1/10, Batch 50/97, Loss: 0.5761
Epoch 1/10, Batch 60/97, Loss: 0.7568
Epoch 1/10, Batch 70/97, Loss: 0.6283
Epoch 1/10, Batch 80/97, Loss: 0.6121
Epoch 1/10, Batch 90/97, Loss: 0.6121
Epoch 1/10, Train Loss: 0.7981, Valid Loss: 0.4503
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6171
Epoch 2/10, Batch 20/97, Loss: 0.3395
Epoch 2/10, Batch 30/97, Loss: 0.5159
Epoch 2/10, Batch 40/97, Loss: 0.2605
Epoch 2/10, Batch 50/97, Loss: 0.3279
Epoch 2/10, Batch 60/97, Loss: 0.4623
Epoch 2/10, Batch 70/97, Loss: 0.3040
Epoch 2/10, Batch 80/97, Loss: 0.3395
Epoch 2/10, Batch 90/97, Loss: 0.5151
Epoch 2/10, Train Loss: 0.4122, Valid Loss: 0.3478
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2911
Epoch 3/10, Batch 20/97, Loss: 0.3521
Epoch 3/10, Batch 30/97, Loss: 0.5229
Epoch 3/10, Batch 40/97, Loss: 0.2100
Epoch 3/10, Batch 50/97, Loss: 0.3965
Epoch 3/10, Batch 60/97, Loss: 0.3575
Epoch 3/10, Batch 70/97, Loss: 0.3315
Epoch 3/10, Batch 80/97, Loss: 0.3328
Epoch 3/10, Batch 90/97, Loss: 0.4235
Epoch 3/10, Train Loss: 0.3377, Valid Loss: 0.3036
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3116
Epoch 4/10, Batch 20/97, Loss: 0.2026
Epoch 4/10, Batch 30/97, Loss: 0.1836
Epoch 4/10, Batch 40/97, Loss: 0.2456
Epoch 4/10, Batch 50/97, Loss: 0.3988
Epoch 4/10, Batch 60/97, Loss: 0.3329
Epoch 4/10, Batch 70/97, Loss: 0.2303
Epoch 4/10, Batch 80/97, Loss: 0.2521
Epoch 4/10, Batch 90/97, Loss: 0.1716
Epoch 4/10, Train Loss: 0.2818, Valid Loss: 0.2888
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2329
Epoch 5/10, Batch 20/97, Loss: 0.3757
Epoch 5/10, Batch 30/97, Loss: 0.2389
Epoch 5/10, Batch 40/97, Loss: 0.2736
Epoch 5/10, Batch 50/97, Loss: 0.3325
Epoch 5/10, Batch 60/97, Loss: 0.2044
Epoch 5/10, Batch 70/97, Loss: 0.2212
Epoch 5/10, Batch 80/97, Loss: 0.2258
Epoch 5/10, Batch 90/97, Loss: 0.2562
Epoch 5/10, Train Loss: 0.2689, Valid Loss: 0.2780
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2357
Epoch 6/10, Batch 20/97, Loss: 0.3044
Epoch 6/10, Batch 30/97, Loss: 0.2022
Epoch 6/10, Batch 40/97, Loss: 0.2007
Epoch 6/10, Batch 50/97, Loss: 0.2325
Epoch 6/10, Batch 60/97, Loss: 0.3479
Epoch 6/10, Batch 70/97, Loss: 0.2113
Epoch 6/10, Batch 80/97, Loss: 0.2215
Epoch 6/10, Batch 90/97, Loss: 0.4954
Epoch 6/10, Train Loss: 0.2464, Valid Loss: 0.2727
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.0941
Epoch 7/10, Batch 20/97, Loss: 0.2541
Epoch 7/10, Batch 30/97, Loss: 0.1487
Epoch 7/10, Batch 40/97, Loss: 0.1422
Epoch 7/10, Batch 50/97, Loss: 0.2270
Epoch 7/10, Batch 60/97, Loss: 0.2275
Epoch 7/10, Batch 70/97, Loss: 0.2240
Epoch 7/10, Batch 80/97, Loss: 0.1301
Epoch 7/10, Batch 90/97, Loss: 0.1733
Epoch 7/10, Train Loss: 0.2181, Valid Loss: 0.2581
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1984
Epoch 8/10, Batch 20/97, Loss: 0.2676
Epoch 8/10, Batch 30/97, Loss: 0.2877
Epoch 8/10, Batch 40/97, Loss: 0.2151
Epoch 8/10, Batch 50/97, Loss: 0.2708
Epoch 8/10, Batch 60/97, Loss: 0.1952
Epoch 8/10, Batch 70/97, Loss: 0.1571
Epoch 8/10, Batch 80/97, Loss: 0.1868
Epoch 8/10, Batch 90/97, Loss: 0.2031
Epoch 8/10, Train Loss: 0.2239, Valid Loss: 0.2517
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1492
Epoch 9/10, Batch 20/97, Loss: 0.1369
Epoch 9/10, Batch 30/97, Loss: 0.1249
Epoch 9/10, Batch 40/97, Loss: 0.2759
Epoch 9/10, Batch 50/97, Loss: 0.1262
Epoch 9/10, Batch 60/97, Loss: 0.1666
Epoch 9/10, Batch 70/97, Loss: 0.1714
Epoch 9/10, Batch 80/97, Loss: 0.1466
Epoch 9/10, Batch 90/97, Loss: 0.1429
Epoch 9/10, Train Loss: 0.2054, Valid Loss: 0.2448
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2597
Epoch 10/10, Batch 20/97, Loss: 0.1720
Epoch 10/10, Batch 30/97, Loss: 0.1479
Epoch 10/10, Batch 40/97, Loss: 0.1421
Epoch 10/10, Batch 50/97, Loss: 0.1892
Epoch 10/10, Batch 60/97, Loss: 0.1354
Epoch 10/10, Batch 70/97, Loss: 0.2496
Epoch 10/10, Batch 80/97, Loss: 0.2053
Epoch 10/10, Batch 90/97, Loss: 0.1481
Epoch 10/10, Train Loss: 0.1961, Valid Loss: 0.2416
Model saved!
Accuracy: 0.9147
Precision: 0.9123
Recall: 0.9147
F1-score: 0.9121
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2225
Epoch 1/10, Batch 20/97, Loss: 1.1136
Epoch 1/10, Batch 30/97, Loss: 0.7340
Epoch 1/10, Batch 40/97, Loss: 0.7763
Epoch 1/10, Batch 50/97, Loss: 0.6252
Epoch 1/10, Batch 60/97, Loss: 0.7636
Epoch 1/10, Batch 70/97, Loss: 0.6473
Epoch 1/10, Batch 80/97, Loss: 0.5101
Epoch 1/10, Batch 90/97, Loss: 0.4898
Epoch 1/10, Train Loss: 0.8137, Valid Loss: 0.4415
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4664
Epoch 2/10, Batch 20/97, Loss: 0.5696
Epoch 2/10, Batch 30/97, Loss: 0.3344
Epoch 2/10, Batch 40/97, Loss: 0.4429
Epoch 2/10, Batch 50/97, Loss: 0.4395
Epoch 2/10, Batch 60/97, Loss: 0.5898
Epoch 2/10, Batch 70/97, Loss: 0.4144
Epoch 2/10, Batch 80/97, Loss: 0.3388
Epoch 2/10, Batch 90/97, Loss: 0.4340
Epoch 2/10, Train Loss: 0.4225, Valid Loss: 0.3472
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2952
Epoch 3/10, Batch 20/97, Loss: 0.3538
Epoch 3/10, Batch 30/97, Loss: 0.3476
Epoch 3/10, Batch 40/97, Loss: 0.1949
Epoch 3/10, Batch 50/97, Loss: 0.4723
Epoch 3/10, Batch 60/97, Loss: 0.2117
Epoch 3/10, Batch 70/97, Loss: 0.3426
Epoch 3/10, Batch 80/97, Loss: 0.3789
Epoch 3/10, Batch 90/97, Loss: 0.3295
Epoch 3/10, Train Loss: 0.3425, Valid Loss: 0.3031
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3959
Epoch 4/10, Batch 20/97, Loss: 0.2954
Epoch 4/10, Batch 30/97, Loss: 0.2849
Epoch 4/10, Batch 40/97, Loss: 0.2630
Epoch 4/10, Batch 50/97, Loss: 0.3209
Epoch 4/10, Batch 60/97, Loss: 0.3429
Epoch 4/10, Batch 70/97, Loss: 0.2853
Epoch 4/10, Batch 80/97, Loss: 0.3151
Epoch 4/10, Batch 90/97, Loss: 0.2823
Epoch 4/10, Train Loss: 0.2894, Valid Loss: 0.2880
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2709
Epoch 5/10, Batch 20/97, Loss: 0.2238
Epoch 5/10, Batch 30/97, Loss: 0.1958
Epoch 5/10, Batch 40/97, Loss: 0.2370
Epoch 5/10, Batch 50/97, Loss: 0.2522
Epoch 5/10, Batch 60/97, Loss: 0.4028
Epoch 5/10, Batch 70/97, Loss: 0.2842
Epoch 5/10, Batch 80/97, Loss: 0.1723
Epoch 5/10, Batch 90/97, Loss: 0.2907
Epoch 5/10, Train Loss: 0.2763, Valid Loss: 0.2794
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2999
Epoch 6/10, Batch 20/97, Loss: 0.2475
Epoch 6/10, Batch 30/97, Loss: 0.2140
Epoch 6/10, Batch 40/97, Loss: 0.1788
Epoch 6/10, Batch 50/97, Loss: 0.1948
Epoch 6/10, Batch 60/97, Loss: 0.2767
Epoch 6/10, Batch 70/97, Loss: 0.2916
Epoch 6/10, Batch 80/97, Loss: 0.2128
Epoch 6/10, Batch 90/97, Loss: 0.3023
Epoch 6/10, Train Loss: 0.2486, Valid Loss: 0.2589
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2016
Epoch 7/10, Batch 20/97, Loss: 0.2647
Epoch 7/10, Batch 30/97, Loss: 0.1844
Epoch 7/10, Batch 40/97, Loss: 0.2425
Epoch 7/10, Batch 50/97, Loss: 0.1765
Epoch 7/10, Batch 60/97, Loss: 0.1568
Epoch 7/10, Batch 70/97, Loss: 0.2190
Epoch 7/10, Batch 80/97, Loss: 0.1622
Epoch 7/10, Batch 90/97, Loss: 0.1757
Epoch 7/10, Train Loss: 0.2309, Valid Loss: 0.2488
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.3377
Epoch 8/10, Batch 20/97, Loss: 0.2276
Epoch 8/10, Batch 30/97, Loss: 0.1791
Epoch 8/10, Batch 40/97, Loss: 0.2131
Epoch 8/10, Batch 50/97, Loss: 0.2769
Epoch 8/10, Batch 60/97, Loss: 0.3078
Epoch 8/10, Batch 70/97, Loss: 0.2888
Epoch 8/10, Batch 80/97, Loss: 0.1142
Epoch 8/10, Batch 90/97, Loss: 0.2333
Epoch 8/10, Train Loss: 0.2272, Valid Loss: 0.2582
Epoch 9/10, Batch 10/97, Loss: 0.1510
Epoch 9/10, Batch 20/97, Loss: 0.1233
Epoch 9/10, Batch 30/97, Loss: 0.2241
Epoch 9/10, Batch 40/97, Loss: 0.2197
Epoch 9/10, Batch 50/97, Loss: 0.0608
Epoch 9/10, Batch 60/97, Loss: 0.2524
Epoch 9/10, Batch 70/97, Loss: 0.2036
Epoch 9/10, Batch 80/97, Loss: 0.3641
Epoch 9/10, Batch 90/97, Loss: 0.2115
Epoch 9/10, Train Loss: 0.2175, Valid Loss: 0.2426
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2922
Epoch 10/10, Batch 20/97, Loss: 0.3057
Epoch 10/10, Batch 30/97, Loss: 0.1235
Epoch 10/10, Batch 40/97, Loss: 0.1600
Epoch 10/10, Batch 50/97, Loss: 0.1569
Epoch 10/10, Batch 60/97, Loss: 0.1094
Epoch 10/10, Batch 70/97, Loss: 0.1770
Epoch 10/10, Batch 80/97, Loss: 0.1125
Epoch 10/10, Batch 90/97, Loss: 0.2800
Epoch 10/10, Train Loss: 0.1995, Valid Loss: 0.2449
Accuracy: 0.9124
Precision: 0.9103
Recall: 0.9124
F1-score: 0.9110
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2350
Epoch 1/10, Batch 20/97, Loss: 1.1874
Epoch 1/10, Batch 30/97, Loss: 0.7798
Epoch 1/10, Batch 40/97, Loss: 0.8240
Epoch 1/10, Batch 50/97, Loss: 0.6282
Epoch 1/10, Batch 60/97, Loss: 0.6953
Epoch 1/10, Batch 70/97, Loss: 0.6024
Epoch 1/10, Batch 80/97, Loss: 0.6599
Epoch 1/10, Batch 90/97, Loss: 0.5813
Epoch 1/10, Train Loss: 0.8066, Valid Loss: 0.4368
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5809
Epoch 2/10, Batch 20/97, Loss: 0.4942
Epoch 2/10, Batch 30/97, Loss: 0.2905
Epoch 2/10, Batch 40/97, Loss: 0.4824
Epoch 2/10, Batch 50/97, Loss: 0.4769
Epoch 2/10, Batch 60/97, Loss: 0.3758
Epoch 2/10, Batch 70/97, Loss: 0.2681
Epoch 2/10, Batch 80/97, Loss: 0.4419
Epoch 2/10, Batch 90/97, Loss: 0.4379
Epoch 2/10, Train Loss: 0.4164, Valid Loss: 0.3246
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3542
Epoch 3/10, Batch 20/97, Loss: 0.4293
Epoch 3/10, Batch 30/97, Loss: 0.3175
Epoch 3/10, Batch 40/97, Loss: 0.2742
Epoch 3/10, Batch 50/97, Loss: 0.3058
Epoch 3/10, Batch 60/97, Loss: 0.3395
Epoch 3/10, Batch 70/97, Loss: 0.3171
Epoch 3/10, Batch 80/97, Loss: 0.3295
Epoch 3/10, Batch 90/97, Loss: 0.3766
Epoch 3/10, Train Loss: 0.3415, Valid Loss: 0.2861
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3570
Epoch 4/10, Batch 20/97, Loss: 0.3131
Epoch 4/10, Batch 30/97, Loss: 0.1684
Epoch 4/10, Batch 40/97, Loss: 0.1862
Epoch 4/10, Batch 50/97, Loss: 0.2747
Epoch 4/10, Batch 60/97, Loss: 0.2517
Epoch 4/10, Batch 70/97, Loss: 0.4375
Epoch 4/10, Batch 80/97, Loss: 0.2084
Epoch 4/10, Batch 90/97, Loss: 0.3173
Epoch 4/10, Train Loss: 0.2899, Valid Loss: 0.2572
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2308
Epoch 5/10, Batch 20/97, Loss: 0.3152
Epoch 5/10, Batch 30/97, Loss: 0.1765
Epoch 5/10, Batch 40/97, Loss: 0.2093
Epoch 5/10, Batch 50/97, Loss: 0.3058
Epoch 5/10, Batch 60/97, Loss: 0.3396
Epoch 5/10, Batch 70/97, Loss: 0.3215
Epoch 5/10, Batch 80/97, Loss: 0.2869
Epoch 5/10, Batch 90/97, Loss: 0.1478
Epoch 5/10, Train Loss: 0.2682, Valid Loss: 0.2495
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1546
Epoch 6/10, Batch 20/97, Loss: 0.5361
Epoch 6/10, Batch 30/97, Loss: 0.2018
Epoch 6/10, Batch 40/97, Loss: 0.1910
Epoch 6/10, Batch 50/97, Loss: 0.2313
Epoch 6/10, Batch 60/97, Loss: 0.3287
Epoch 6/10, Batch 70/97, Loss: 0.2523
Epoch 6/10, Batch 80/97, Loss: 0.2601
Epoch 6/10, Batch 90/97, Loss: 0.3234
Epoch 6/10, Train Loss: 0.2534, Valid Loss: 0.2299
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2439
Epoch 7/10, Batch 20/97, Loss: 0.2712
Epoch 7/10, Batch 30/97, Loss: 0.2230
Epoch 7/10, Batch 40/97, Loss: 0.1160
Epoch 7/10, Batch 50/97, Loss: 0.1693
Epoch 7/10, Batch 60/97, Loss: 0.2292
Epoch 7/10, Batch 70/97, Loss: 0.1927
Epoch 7/10, Batch 80/97, Loss: 0.1261
Epoch 7/10, Batch 90/97, Loss: 0.1605
Epoch 7/10, Train Loss: 0.2351, Valid Loss: 0.2289
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1716
Epoch 8/10, Batch 20/97, Loss: 0.1738
Epoch 8/10, Batch 30/97, Loss: 0.2920
Epoch 8/10, Batch 40/97, Loss: 0.2475
Epoch 8/10, Batch 50/97, Loss: 0.3476
Epoch 8/10, Batch 60/97, Loss: 0.1341
Epoch 8/10, Batch 70/97, Loss: 0.1553
Epoch 8/10, Batch 80/97, Loss: 0.1797
Epoch 8/10, Batch 90/97, Loss: 0.1987
Epoch 8/10, Train Loss: 0.2292, Valid Loss: 0.2241
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1287
Epoch 9/10, Batch 20/97, Loss: 0.1500
Epoch 9/10, Batch 30/97, Loss: 0.2139
Epoch 9/10, Batch 40/97, Loss: 0.1891
Epoch 9/10, Batch 50/97, Loss: 0.1370
Epoch 9/10, Batch 60/97, Loss: 0.2950
Epoch 9/10, Batch 70/97, Loss: 0.2228
Epoch 9/10, Batch 80/97, Loss: 0.1881
Epoch 9/10, Batch 90/97, Loss: 0.3052
Epoch 9/10, Train Loss: 0.2082, Valid Loss: 0.2160
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2951
Epoch 10/10, Batch 20/97, Loss: 0.2628
Epoch 10/10, Batch 30/97, Loss: 0.1327
Epoch 10/10, Batch 40/97, Loss: 0.1118
Epoch 10/10, Batch 50/97, Loss: 0.1959
Epoch 10/10, Batch 60/97, Loss: 0.1277
Epoch 10/10, Batch 70/97, Loss: 0.4153
Epoch 10/10, Batch 80/97, Loss: 0.2766
Epoch 10/10, Batch 90/97, Loss: 0.1546
Epoch 10/10, Train Loss: 0.2059, Valid Loss: 0.2182
Accuracy: 0.9159
Precision: 0.9136
Recall: 0.9159
F1-score: 0.9140
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2142
Epoch 1/10, Batch 20/97, Loss: 1.0821
Epoch 1/10, Batch 30/97, Loss: 0.8609
Epoch 1/10, Batch 40/97, Loss: 0.8554
Epoch 1/10, Batch 50/97, Loss: 0.6012
Epoch 1/10, Batch 60/97, Loss: 0.6610
Epoch 1/10, Batch 70/97, Loss: 0.6401
Epoch 1/10, Batch 80/97, Loss: 0.5465
Epoch 1/10, Batch 90/97, Loss: 0.5687
Epoch 1/10, Train Loss: 0.8034, Valid Loss: 0.4403
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3922
Epoch 2/10, Batch 20/97, Loss: 0.4397
Epoch 2/10, Batch 30/97, Loss: 0.3375
Epoch 2/10, Batch 40/97, Loss: 0.5059
Epoch 2/10, Batch 50/97, Loss: 0.4417
Epoch 2/10, Batch 60/97, Loss: 0.4316
Epoch 2/10, Batch 70/97, Loss: 0.3476
Epoch 2/10, Batch 80/97, Loss: 0.5939
Epoch 2/10, Batch 90/97, Loss: 0.3627
Epoch 2/10, Train Loss: 0.4044, Valid Loss: 0.3277
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3334
Epoch 3/10, Batch 20/97, Loss: 0.3243
Epoch 3/10, Batch 30/97, Loss: 0.4715
Epoch 3/10, Batch 40/97, Loss: 0.2984
Epoch 3/10, Batch 50/97, Loss: 0.3252
Epoch 3/10, Batch 60/97, Loss: 0.3615
Epoch 3/10, Batch 70/97, Loss: 0.3477
Epoch 3/10, Batch 80/97, Loss: 0.3539
Epoch 3/10, Batch 90/97, Loss: 0.2373
Epoch 3/10, Train Loss: 0.3264, Valid Loss: 0.2813
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3527
Epoch 4/10, Batch 20/97, Loss: 0.1798
Epoch 4/10, Batch 30/97, Loss: 0.2668
Epoch 4/10, Batch 40/97, Loss: 0.2736
Epoch 4/10, Batch 50/97, Loss: 0.2451
Epoch 4/10, Batch 60/97, Loss: 0.2215
Epoch 4/10, Batch 70/97, Loss: 0.2426
Epoch 4/10, Batch 80/97, Loss: 0.1811
Epoch 4/10, Batch 90/97, Loss: 0.1450
Epoch 4/10, Train Loss: 0.2771, Valid Loss: 0.2565
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3784
Epoch 5/10, Batch 20/97, Loss: 0.2421
Epoch 5/10, Batch 30/97, Loss: 0.2593
Epoch 5/10, Batch 40/97, Loss: 0.2422
Epoch 5/10, Batch 50/97, Loss: 0.4382
Epoch 5/10, Batch 60/97, Loss: 0.1442
Epoch 5/10, Batch 70/97, Loss: 0.2951
Epoch 5/10, Batch 80/97, Loss: 0.3270
Epoch 5/10, Batch 90/97, Loss: 0.1844
Epoch 5/10, Train Loss: 0.2589, Valid Loss: 0.2480
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2869
Epoch 6/10, Batch 20/97, Loss: 0.2649
Epoch 6/10, Batch 30/97, Loss: 0.1423
Epoch 6/10, Batch 40/97, Loss: 0.0973
Epoch 6/10, Batch 50/97, Loss: 0.2658
Epoch 6/10, Batch 60/97, Loss: 0.2503
Epoch 6/10, Batch 70/97, Loss: 0.3567
Epoch 6/10, Batch 80/97, Loss: 0.3602
Epoch 6/10, Batch 90/97, Loss: 0.2558
Epoch 6/10, Train Loss: 0.2409, Valid Loss: 0.2329
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1802
Epoch 7/10, Batch 20/97, Loss: 0.2839
Epoch 7/10, Batch 30/97, Loss: 0.2139
Epoch 7/10, Batch 40/97, Loss: 0.1618
Epoch 7/10, Batch 50/97, Loss: 0.1424
Epoch 7/10, Batch 60/97, Loss: 0.2282
Epoch 7/10, Batch 70/97, Loss: 0.3419
Epoch 7/10, Batch 80/97, Loss: 0.1245
Epoch 7/10, Batch 90/97, Loss: 0.1557
Epoch 7/10, Train Loss: 0.2267, Valid Loss: 0.2260
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2578
Epoch 8/10, Batch 20/97, Loss: 0.2379
Epoch 8/10, Batch 30/97, Loss: 0.1923
Epoch 8/10, Batch 40/97, Loss: 0.1662
Epoch 8/10, Batch 50/97, Loss: 0.3193
Epoch 8/10, Batch 60/97, Loss: 0.1816
Epoch 8/10, Batch 70/97, Loss: 0.2733
Epoch 8/10, Batch 80/97, Loss: 0.2958
Epoch 8/10, Batch 90/97, Loss: 0.2010
Epoch 8/10, Train Loss: 0.2112, Valid Loss: 0.2261
Epoch 9/10, Batch 10/97, Loss: 0.1297
Epoch 9/10, Batch 20/97, Loss: 0.1232
Epoch 9/10, Batch 30/97, Loss: 0.2128
Epoch 9/10, Batch 40/97, Loss: 0.3332
Epoch 9/10, Batch 50/97, Loss: 0.1574
Epoch 9/10, Batch 60/97, Loss: 0.2258
Epoch 9/10, Batch 70/97, Loss: 0.1312
Epoch 9/10, Batch 80/97, Loss: 0.1911
Epoch 9/10, Batch 90/97, Loss: 0.1772
Epoch 9/10, Train Loss: 0.2028, Valid Loss: 0.2196
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1357
Epoch 10/10, Batch 20/97, Loss: 0.2120
Epoch 10/10, Batch 30/97, Loss: 0.1725
Epoch 10/10, Batch 40/97, Loss: 0.3824
Epoch 10/10, Batch 50/97, Loss: 0.1379
Epoch 10/10, Batch 60/97, Loss: 0.1384
Epoch 10/10, Batch 70/97, Loss: 0.2327
Epoch 10/10, Batch 80/97, Loss: 0.1989
Epoch 10/10, Batch 90/97, Loss: 0.1791
Epoch 10/10, Train Loss: 0.1955, Valid Loss: 0.2219
Accuracy: 0.9194
Precision: 0.9182
Recall: 0.9194
F1-score: 0.9178
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2754
Epoch 1/10, Batch 20/97, Loss: 1.0693
Epoch 1/10, Batch 30/97, Loss: 0.7998
Epoch 1/10, Batch 40/97, Loss: 0.7280
Epoch 1/10, Batch 50/97, Loss: 0.6005
Epoch 1/10, Batch 60/97, Loss: 0.6023
Epoch 1/10, Batch 70/97, Loss: 0.6270
Epoch 1/10, Batch 80/97, Loss: 0.6766
Epoch 1/10, Batch 90/97, Loss: 0.4813
Epoch 1/10, Train Loss: 0.7939, Valid Loss: 0.4545
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6255
Epoch 2/10, Batch 20/97, Loss: 0.3836
Epoch 2/10, Batch 30/97, Loss: 0.3865
Epoch 2/10, Batch 40/97, Loss: 0.3780
Epoch 2/10, Batch 50/97, Loss: 0.4467
Epoch 2/10, Batch 60/97, Loss: 0.6216
Epoch 2/10, Batch 70/97, Loss: 0.2929
Epoch 2/10, Batch 80/97, Loss: 0.3048
Epoch 2/10, Batch 90/97, Loss: 0.5849
Epoch 2/10, Train Loss: 0.4038, Valid Loss: 0.3368
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3696
Epoch 3/10, Batch 20/97, Loss: 0.2712
Epoch 3/10, Batch 30/97, Loss: 0.4303
Epoch 3/10, Batch 40/97, Loss: 0.1610
Epoch 3/10, Batch 50/97, Loss: 0.4868
Epoch 3/10, Batch 60/97, Loss: 0.2235
Epoch 3/10, Batch 70/97, Loss: 0.2688
Epoch 3/10, Batch 80/97, Loss: 0.2276
Epoch 3/10, Batch 90/97, Loss: 0.2439
Epoch 3/10, Train Loss: 0.3237, Valid Loss: 0.2873
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2989
Epoch 4/10, Batch 20/97, Loss: 0.2572
Epoch 4/10, Batch 30/97, Loss: 0.1812
Epoch 4/10, Batch 40/97, Loss: 0.2913
Epoch 4/10, Batch 50/97, Loss: 0.2520
Epoch 4/10, Batch 60/97, Loss: 0.1652
Epoch 4/10, Batch 70/97, Loss: 0.3230
Epoch 4/10, Batch 80/97, Loss: 0.3337
Epoch 4/10, Batch 90/97, Loss: 0.2174
Epoch 4/10, Train Loss: 0.2758, Valid Loss: 0.2656
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2070
Epoch 5/10, Batch 20/97, Loss: 0.3189
Epoch 5/10, Batch 30/97, Loss: 0.1386
Epoch 5/10, Batch 40/97, Loss: 0.2129
Epoch 5/10, Batch 50/97, Loss: 0.2059
Epoch 5/10, Batch 60/97, Loss: 0.1825
Epoch 5/10, Batch 70/97, Loss: 0.3664
Epoch 5/10, Batch 80/97, Loss: 0.1769
Epoch 5/10, Batch 90/97, Loss: 0.1644
Epoch 5/10, Train Loss: 0.2482, Valid Loss: 0.2492
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1196
Epoch 6/10, Batch 20/97, Loss: 0.2770
Epoch 6/10, Batch 30/97, Loss: 0.2379
Epoch 6/10, Batch 40/97, Loss: 0.1569
Epoch 6/10, Batch 50/97, Loss: 0.1723
Epoch 6/10, Batch 60/97, Loss: 0.5477
Epoch 6/10, Batch 70/97, Loss: 0.1504
Epoch 6/10, Batch 80/97, Loss: 0.2492
Epoch 6/10, Batch 90/97, Loss: 0.2132
Epoch 6/10, Train Loss: 0.2403, Valid Loss: 0.2364
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2379
Epoch 7/10, Batch 20/97, Loss: 0.3002
Epoch 7/10, Batch 30/97, Loss: 0.1720
Epoch 7/10, Batch 40/97, Loss: 0.1504
Epoch 7/10, Batch 50/97, Loss: 0.1534
Epoch 7/10, Batch 60/97, Loss: 0.1248
Epoch 7/10, Batch 70/97, Loss: 0.1422
Epoch 7/10, Batch 80/97, Loss: 0.1326
Epoch 7/10, Batch 90/97, Loss: 0.2219
Epoch 7/10, Train Loss: 0.2191, Valid Loss: 0.2291
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2558
Epoch 8/10, Batch 20/97, Loss: 0.2055
Epoch 8/10, Batch 30/97, Loss: 0.0864
Epoch 8/10, Batch 40/97, Loss: 0.1381
Epoch 8/10, Batch 50/97, Loss: 0.2888
Epoch 8/10, Batch 60/97, Loss: 0.1236
Epoch 8/10, Batch 70/97, Loss: 0.2506
Epoch 8/10, Batch 80/97, Loss: 0.2696
Epoch 8/10, Batch 90/97, Loss: 0.1467
Epoch 8/10, Train Loss: 0.2051, Valid Loss: 0.2231
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1808
Epoch 9/10, Batch 20/97, Loss: 0.2089
Epoch 9/10, Batch 30/97, Loss: 0.1280
Epoch 9/10, Batch 40/97, Loss: 0.4027
Epoch 9/10, Batch 50/97, Loss: 0.1515
Epoch 9/10, Batch 60/97, Loss: 0.1963
Epoch 9/10, Batch 70/97, Loss: 0.1343
Epoch 9/10, Batch 80/97, Loss: 0.0986
Epoch 9/10, Batch 90/97, Loss: 0.1946
Epoch 9/10, Train Loss: 0.1960, Valid Loss: 0.2214
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2762
Epoch 10/10, Batch 20/97, Loss: 0.1917
Epoch 10/10, Batch 30/97, Loss: 0.3045
Epoch 10/10, Batch 40/97, Loss: 0.2088
Epoch 10/10, Batch 50/97, Loss: 0.1824
Epoch 10/10, Batch 60/97, Loss: 0.1699
Epoch 10/10, Batch 70/97, Loss: 0.1995
Epoch 10/10, Batch 80/97, Loss: 0.1781
Epoch 10/10, Batch 90/97, Loss: 0.0800
Epoch 10/10, Train Loss: 0.1911, Valid Loss: 0.2230
Accuracy: 0.9159
Precision: 0.9135
Recall: 0.9159
F1-score: 0.9142
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.3066
Epoch 1/10, Batch 20/97, Loss: 1.0528
Epoch 1/10, Batch 30/97, Loss: 0.7968
Epoch 1/10, Batch 40/97, Loss: 0.7391
Epoch 1/10, Batch 50/97, Loss: 0.6030
Epoch 1/10, Batch 60/97, Loss: 0.9043
Epoch 1/10, Batch 70/97, Loss: 0.5589
Epoch 1/10, Batch 80/97, Loss: 0.5832
Epoch 1/10, Batch 90/97, Loss: 0.5213
Epoch 1/10, Train Loss: 0.7979, Valid Loss: 0.4315
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6318
Epoch 2/10, Batch 20/97, Loss: 0.4919
Epoch 2/10, Batch 30/97, Loss: 0.3509
Epoch 2/10, Batch 40/97, Loss: 0.3131
Epoch 2/10, Batch 50/97, Loss: 0.3816
Epoch 2/10, Batch 60/97, Loss: 0.5130
Epoch 2/10, Batch 70/97, Loss: 0.2935
Epoch 2/10, Batch 80/97, Loss: 0.4462
Epoch 2/10, Batch 90/97, Loss: 0.4708
Epoch 2/10, Train Loss: 0.4058, Valid Loss: 0.3194
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3881
Epoch 3/10, Batch 20/97, Loss: 0.4968
Epoch 3/10, Batch 30/97, Loss: 0.3174
Epoch 3/10, Batch 40/97, Loss: 0.2327
Epoch 3/10, Batch 50/97, Loss: 0.2602
Epoch 3/10, Batch 60/97, Loss: 0.1577
Epoch 3/10, Batch 70/97, Loss: 0.3614
Epoch 3/10, Batch 80/97, Loss: 0.3171
Epoch 3/10, Batch 90/97, Loss: 0.5176
Epoch 3/10, Train Loss: 0.3346, Valid Loss: 0.2719
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2530
Epoch 4/10, Batch 20/97, Loss: 0.2031
Epoch 4/10, Batch 30/97, Loss: 0.2314
Epoch 4/10, Batch 40/97, Loss: 0.3329
Epoch 4/10, Batch 50/97, Loss: 0.3901
Epoch 4/10, Batch 60/97, Loss: 0.2604
Epoch 4/10, Batch 70/97, Loss: 0.2733
Epoch 4/10, Batch 80/97, Loss: 0.3121
Epoch 4/10, Batch 90/97, Loss: 0.2185
Epoch 4/10, Train Loss: 0.2839, Valid Loss: 0.2577
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2170
Epoch 5/10, Batch 20/97, Loss: 0.3953
Epoch 5/10, Batch 30/97, Loss: 0.2149
Epoch 5/10, Batch 40/97, Loss: 0.1464
Epoch 5/10, Batch 50/97, Loss: 0.3277
Epoch 5/10, Batch 60/97, Loss: 0.3127
Epoch 5/10, Batch 70/97, Loss: 0.3136
Epoch 5/10, Batch 80/97, Loss: 0.1332
Epoch 5/10, Batch 90/97, Loss: 0.1897
Epoch 5/10, Train Loss: 0.2656, Valid Loss: 0.2436
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1039
Epoch 6/10, Batch 20/97, Loss: 0.2439
Epoch 6/10, Batch 30/97, Loss: 0.1874
Epoch 6/10, Batch 40/97, Loss: 0.1412
Epoch 6/10, Batch 50/97, Loss: 0.2651
Epoch 6/10, Batch 60/97, Loss: 0.2851
Epoch 6/10, Batch 70/97, Loss: 0.2780
Epoch 6/10, Batch 80/97, Loss: 0.2246
Epoch 6/10, Batch 90/97, Loss: 0.2170
Epoch 6/10, Train Loss: 0.2478, Valid Loss: 0.2191
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1215
Epoch 7/10, Batch 20/97, Loss: 0.2509
Epoch 7/10, Batch 30/97, Loss: 0.1739
Epoch 7/10, Batch 40/97, Loss: 0.2566
Epoch 7/10, Batch 50/97, Loss: 0.1534
Epoch 7/10, Batch 60/97, Loss: 0.1086
Epoch 7/10, Batch 70/97, Loss: 0.2526
Epoch 7/10, Batch 80/97, Loss: 0.1588
Epoch 7/10, Batch 90/97, Loss: 0.1765
Epoch 7/10, Train Loss: 0.2267, Valid Loss: 0.2156
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1624
Epoch 8/10, Batch 20/97, Loss: 0.2005
Epoch 8/10, Batch 30/97, Loss: 0.2894
Epoch 8/10, Batch 40/97, Loss: 0.1996
Epoch 8/10, Batch 50/97, Loss: 0.1497
Epoch 8/10, Batch 60/97, Loss: 0.1038
Epoch 8/10, Batch 70/97, Loss: 0.2030
Epoch 8/10, Batch 80/97, Loss: 0.1939
Epoch 8/10, Batch 90/97, Loss: 0.1745
Epoch 8/10, Train Loss: 0.2218, Valid Loss: 0.2080
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1639
Epoch 9/10, Batch 20/97, Loss: 0.1637
Epoch 9/10, Batch 30/97, Loss: 0.2512
Epoch 9/10, Batch 40/97, Loss: 0.2069
Epoch 9/10, Batch 50/97, Loss: 0.2181
Epoch 9/10, Batch 60/97, Loss: 0.1315
Epoch 9/10, Batch 70/97, Loss: 0.1749
Epoch 9/10, Batch 80/97, Loss: 0.1356
Epoch 9/10, Batch 90/97, Loss: 0.1515
Epoch 9/10, Train Loss: 0.2083, Valid Loss: 0.2077
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1274
Epoch 10/10, Batch 20/97, Loss: 0.1846
Epoch 10/10, Batch 30/97, Loss: 0.1625
Epoch 10/10, Batch 40/97, Loss: 0.0763
Epoch 10/10, Batch 50/97, Loss: 0.1767
Epoch 10/10, Batch 60/97, Loss: 0.1585
Epoch 10/10, Batch 70/97, Loss: 0.1989
Epoch 10/10, Batch 80/97, Loss: 0.1020
Epoch 10/10, Batch 90/97, Loss: 0.1500
Epoch 10/10, Train Loss: 0.2016, Valid Loss: 0.2053
Model saved!
Accuracy: 0.9089
Precision: 0.9047
Recall: 0.9089
F1-score: 0.9051
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.3056
Epoch 1/10, Batch 20/97, Loss: 1.0689
Epoch 1/10, Batch 30/97, Loss: 0.7540
Epoch 1/10, Batch 40/97, Loss: 0.6904
Epoch 1/10, Batch 50/97, Loss: 0.5327
Epoch 1/10, Batch 60/97, Loss: 0.8099
Epoch 1/10, Batch 70/97, Loss: 0.6307
Epoch 1/10, Batch 80/97, Loss: 0.6594
Epoch 1/10, Batch 90/97, Loss: 0.4889
Epoch 1/10, Train Loss: 0.8101, Valid Loss: 0.4536
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5169
Epoch 2/10, Batch 20/97, Loss: 0.4694
Epoch 2/10, Batch 30/97, Loss: 0.3694
Epoch 2/10, Batch 40/97, Loss: 0.4101
Epoch 2/10, Batch 50/97, Loss: 0.2778
Epoch 2/10, Batch 60/97, Loss: 0.4231
Epoch 2/10, Batch 70/97, Loss: 0.4175
Epoch 2/10, Batch 80/97, Loss: 0.4812
Epoch 2/10, Batch 90/97, Loss: 0.4487
Epoch 2/10, Train Loss: 0.4221, Valid Loss: 0.3540
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4323
Epoch 3/10, Batch 20/97, Loss: 0.2953
Epoch 3/10, Batch 30/97, Loss: 0.4630
Epoch 3/10, Batch 40/97, Loss: 0.2912
Epoch 3/10, Batch 50/97, Loss: 0.5150
Epoch 3/10, Batch 60/97, Loss: 0.2457
Epoch 3/10, Batch 70/97, Loss: 0.3356
Epoch 3/10, Batch 80/97, Loss: 0.2563
Epoch 3/10, Batch 90/97, Loss: 0.2924
Epoch 3/10, Train Loss: 0.3344, Valid Loss: 0.3139
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4149
Epoch 4/10, Batch 20/97, Loss: 0.2253
Epoch 4/10, Batch 30/97, Loss: 0.3274
Epoch 4/10, Batch 40/97, Loss: 0.2723
Epoch 4/10, Batch 50/97, Loss: 0.1633
Epoch 4/10, Batch 60/97, Loss: 0.2746
Epoch 4/10, Batch 70/97, Loss: 0.1832
Epoch 4/10, Batch 80/97, Loss: 0.2224
Epoch 4/10, Batch 90/97, Loss: 0.2932
Epoch 4/10, Train Loss: 0.2829, Valid Loss: 0.3003
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2407
Epoch 5/10, Batch 20/97, Loss: 0.1925
Epoch 5/10, Batch 30/97, Loss: 0.1390
Epoch 5/10, Batch 40/97, Loss: 0.3063
Epoch 5/10, Batch 50/97, Loss: 0.2505
Epoch 5/10, Batch 60/97, Loss: 0.1731
Epoch 5/10, Batch 70/97, Loss: 0.1675
Epoch 5/10, Batch 80/97, Loss: 0.3494
Epoch 5/10, Batch 90/97, Loss: 0.2326
Epoch 5/10, Train Loss: 0.2686, Valid Loss: 0.2858
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2782
Epoch 6/10, Batch 20/97, Loss: 0.3114
Epoch 6/10, Batch 30/97, Loss: 0.1957
Epoch 6/10, Batch 40/97, Loss: 0.1774
Epoch 6/10, Batch 50/97, Loss: 0.1246
Epoch 6/10, Batch 60/97, Loss: 0.3304
Epoch 6/10, Batch 70/97, Loss: 0.2761
Epoch 6/10, Batch 80/97, Loss: 0.2116
Epoch 6/10, Batch 90/97, Loss: 0.2156
Epoch 6/10, Train Loss: 0.2532, Valid Loss: 0.2733
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2422
Epoch 7/10, Batch 20/97, Loss: 0.1702
Epoch 7/10, Batch 30/97, Loss: 0.1118
Epoch 7/10, Batch 40/97, Loss: 0.2282
Epoch 7/10, Batch 50/97, Loss: 0.2692
Epoch 7/10, Batch 60/97, Loss: 0.2828
Epoch 7/10, Batch 70/97, Loss: 0.3902
Epoch 7/10, Batch 80/97, Loss: 0.3078
Epoch 7/10, Batch 90/97, Loss: 0.1176
Epoch 7/10, Train Loss: 0.2255, Valid Loss: 0.2641
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1647
Epoch 8/10, Batch 20/97, Loss: 0.1367
Epoch 8/10, Batch 30/97, Loss: 0.1863
Epoch 8/10, Batch 40/97, Loss: 0.3862
Epoch 8/10, Batch 50/97, Loss: 0.2859
Epoch 8/10, Batch 60/97, Loss: 0.1487
Epoch 8/10, Batch 70/97, Loss: 0.2873
Epoch 8/10, Batch 80/97, Loss: 0.0883
Epoch 8/10, Batch 90/97, Loss: 0.2562
Epoch 8/10, Train Loss: 0.2211, Valid Loss: 0.2655
Epoch 9/10, Batch 10/97, Loss: 0.1680
Epoch 9/10, Batch 20/97, Loss: 0.2059
Epoch 9/10, Batch 30/97, Loss: 0.2779
Epoch 9/10, Batch 40/97, Loss: 0.3166
Epoch 9/10, Batch 50/97, Loss: 0.2187
Epoch 9/10, Batch 60/97, Loss: 0.2433
Epoch 9/10, Batch 70/97, Loss: 0.2941
Epoch 9/10, Batch 80/97, Loss: 0.0919
Epoch 9/10, Batch 90/97, Loss: 0.1529
Epoch 9/10, Train Loss: 0.2086, Valid Loss: 0.2602
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2153
Epoch 10/10, Batch 20/97, Loss: 0.3106
Epoch 10/10, Batch 30/97, Loss: 0.1216
Epoch 10/10, Batch 40/97, Loss: 0.1837
Epoch 10/10, Batch 50/97, Loss: 0.1335
Epoch 10/10, Batch 60/97, Loss: 0.2685
Epoch 10/10, Batch 70/97, Loss: 0.2662
Epoch 10/10, Batch 80/97, Loss: 0.1336
Epoch 10/10, Batch 90/97, Loss: 0.1245
Epoch 10/10, Train Loss: 0.1965, Valid Loss: 0.2601
Model saved!
Accuracy: 0.9171
Precision: 0.9140
Recall: 0.9171
F1-score: 0.9147
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2602
Epoch 1/10, Batch 20/97, Loss: 1.1121
Epoch 1/10, Batch 30/97, Loss: 0.8439
Epoch 1/10, Batch 40/97, Loss: 0.7200
Epoch 1/10, Batch 50/97, Loss: 0.6750
Epoch 1/10, Batch 60/97, Loss: 0.6860
Epoch 1/10, Batch 70/97, Loss: 0.5207
Epoch 1/10, Batch 80/97, Loss: 0.6678
Epoch 1/10, Batch 90/97, Loss: 0.5717
Epoch 1/10, Train Loss: 0.8036, Valid Loss: 0.4465
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4972
Epoch 2/10, Batch 20/97, Loss: 0.3425
Epoch 2/10, Batch 30/97, Loss: 0.4169
Epoch 2/10, Batch 40/97, Loss: 0.4794
Epoch 2/10, Batch 50/97, Loss: 0.3452
Epoch 2/10, Batch 60/97, Loss: 0.4875
Epoch 2/10, Batch 70/97, Loss: 0.2524
Epoch 2/10, Batch 80/97, Loss: 0.2616
Epoch 2/10, Batch 90/97, Loss: 0.4170
Epoch 2/10, Train Loss: 0.4120, Valid Loss: 0.3437
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2743
Epoch 3/10, Batch 20/97, Loss: 0.3855
Epoch 3/10, Batch 30/97, Loss: 0.4807
Epoch 3/10, Batch 40/97, Loss: 0.2842
Epoch 3/10, Batch 50/97, Loss: 0.4476
Epoch 3/10, Batch 60/97, Loss: 0.2448
Epoch 3/10, Batch 70/97, Loss: 0.3890
Epoch 3/10, Batch 80/97, Loss: 0.4353
Epoch 3/10, Batch 90/97, Loss: 0.2964
Epoch 3/10, Train Loss: 0.3374, Valid Loss: 0.3059
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4512
Epoch 4/10, Batch 20/97, Loss: 0.3597
Epoch 4/10, Batch 30/97, Loss: 0.2939
Epoch 4/10, Batch 40/97, Loss: 0.2110
Epoch 4/10, Batch 50/97, Loss: 0.2731
Epoch 4/10, Batch 60/97, Loss: 0.2158
Epoch 4/10, Batch 70/97, Loss: 0.2452
Epoch 4/10, Batch 80/97, Loss: 0.2464
Epoch 4/10, Batch 90/97, Loss: 0.1898
Epoch 4/10, Train Loss: 0.2865, Valid Loss: 0.2912
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2716
Epoch 5/10, Batch 20/97, Loss: 0.2935
Epoch 5/10, Batch 30/97, Loss: 0.2760
Epoch 5/10, Batch 40/97, Loss: 0.2954
Epoch 5/10, Batch 50/97, Loss: 0.1661
Epoch 5/10, Batch 60/97, Loss: 0.1634
Epoch 5/10, Batch 70/97, Loss: 0.2807
Epoch 5/10, Batch 80/97, Loss: 0.1745
Epoch 5/10, Batch 90/97, Loss: 0.2669
Epoch 5/10, Train Loss: 0.2652, Valid Loss: 0.2867
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3191
Epoch 6/10, Batch 20/97, Loss: 0.3883
Epoch 6/10, Batch 30/97, Loss: 0.2691
Epoch 6/10, Batch 40/97, Loss: 0.2499
Epoch 6/10, Batch 50/97, Loss: 0.1688
Epoch 6/10, Batch 60/97, Loss: 0.4066
Epoch 6/10, Batch 70/97, Loss: 0.2219
Epoch 6/10, Batch 80/97, Loss: 0.3167
Epoch 6/10, Batch 90/97, Loss: 0.2748
Epoch 6/10, Train Loss: 0.2512, Valid Loss: 0.2643
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3033
Epoch 7/10, Batch 20/97, Loss: 0.2253
Epoch 7/10, Batch 30/97, Loss: 0.1957
Epoch 7/10, Batch 40/97, Loss: 0.2892
Epoch 7/10, Batch 50/97, Loss: 0.2406
Epoch 7/10, Batch 60/97, Loss: 0.2425
Epoch 7/10, Batch 70/97, Loss: 0.3734
Epoch 7/10, Batch 80/97, Loss: 0.1668
Epoch 7/10, Batch 90/97, Loss: 0.1367
Epoch 7/10, Train Loss: 0.2288, Valid Loss: 0.2592
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1775
Epoch 8/10, Batch 20/97, Loss: 0.1595
Epoch 8/10, Batch 30/97, Loss: 0.1236
Epoch 8/10, Batch 40/97, Loss: 0.3032
Epoch 8/10, Batch 50/97, Loss: 0.1428
Epoch 8/10, Batch 60/97, Loss: 0.3194
Epoch 8/10, Batch 70/97, Loss: 0.1656
Epoch 8/10, Batch 80/97, Loss: 0.2102
Epoch 8/10, Batch 90/97, Loss: 0.2560
Epoch 8/10, Train Loss: 0.2202, Valid Loss: 0.2568
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1842
Epoch 9/10, Batch 20/97, Loss: 0.1428
Epoch 9/10, Batch 30/97, Loss: 0.2095
Epoch 9/10, Batch 40/97, Loss: 0.3620
Epoch 9/10, Batch 50/97, Loss: 0.1552
Epoch 9/10, Batch 60/97, Loss: 0.2062
Epoch 9/10, Batch 70/97, Loss: 0.1787
Epoch 9/10, Batch 80/97, Loss: 0.1277
Epoch 9/10, Batch 90/97, Loss: 0.1367
Epoch 9/10, Train Loss: 0.2126, Valid Loss: 0.2517
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1667
Epoch 10/10, Batch 20/97, Loss: 0.1236
Epoch 10/10, Batch 30/97, Loss: 0.2719
Epoch 10/10, Batch 40/97, Loss: 0.1705
Epoch 10/10, Batch 50/97, Loss: 0.3005
Epoch 10/10, Batch 60/97, Loss: 0.2268
Epoch 10/10, Batch 70/97, Loss: 0.2172
Epoch 10/10, Batch 80/97, Loss: 0.1842
Epoch 10/10, Batch 90/97, Loss: 0.2802
Epoch 10/10, Train Loss: 0.2040, Valid Loss: 0.2542
Accuracy: 0.9077
Precision: 0.9038
Recall: 0.9077
F1-score: 0.9049
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2493
Epoch 1/10, Batch 20/97, Loss: 1.0901
Epoch 1/10, Batch 30/97, Loss: 0.7828
Epoch 1/10, Batch 40/97, Loss: 0.7380
Epoch 1/10, Batch 50/97, Loss: 0.6727
Epoch 1/10, Batch 60/97, Loss: 0.7258
Epoch 1/10, Batch 70/97, Loss: 0.6603
Epoch 1/10, Batch 80/97, Loss: 0.5706
Epoch 1/10, Batch 90/97, Loss: 0.5844
Epoch 1/10, Train Loss: 0.7987, Valid Loss: 0.4528
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4305
Epoch 2/10, Batch 20/97, Loss: 0.4028
Epoch 2/10, Batch 30/97, Loss: 0.3332
Epoch 2/10, Batch 40/97, Loss: 0.3514
Epoch 2/10, Batch 50/97, Loss: 0.4616
Epoch 2/10, Batch 60/97, Loss: 0.3611
Epoch 2/10, Batch 70/97, Loss: 0.4439
Epoch 2/10, Batch 80/97, Loss: 0.4224
Epoch 2/10, Batch 90/97, Loss: 0.4655
Epoch 2/10, Train Loss: 0.4159, Valid Loss: 0.3508
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3375
Epoch 3/10, Batch 20/97, Loss: 0.3622
Epoch 3/10, Batch 30/97, Loss: 0.4360
Epoch 3/10, Batch 40/97, Loss: 0.2427
Epoch 3/10, Batch 50/97, Loss: 0.1929
Epoch 3/10, Batch 60/97, Loss: 0.2282
Epoch 3/10, Batch 70/97, Loss: 0.4716
Epoch 3/10, Batch 80/97, Loss: 0.2709
Epoch 3/10, Batch 90/97, Loss: 0.2037
Epoch 3/10, Train Loss: 0.3322, Valid Loss: 0.3008
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3423
Epoch 4/10, Batch 20/97, Loss: 0.1936
Epoch 4/10, Batch 30/97, Loss: 0.3206
Epoch 4/10, Batch 40/97, Loss: 0.2047
Epoch 4/10, Batch 50/97, Loss: 0.1727
Epoch 4/10, Batch 60/97, Loss: 0.3483
Epoch 4/10, Batch 70/97, Loss: 0.2871
Epoch 4/10, Batch 80/97, Loss: 0.1808
Epoch 4/10, Batch 90/97, Loss: 0.2702
Epoch 4/10, Train Loss: 0.2793, Valid Loss: 0.2811
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1946
Epoch 5/10, Batch 20/97, Loss: 0.2231
Epoch 5/10, Batch 30/97, Loss: 0.2195
Epoch 5/10, Batch 40/97, Loss: 0.2048
Epoch 5/10, Batch 50/97, Loss: 0.2773
Epoch 5/10, Batch 60/97, Loss: 0.2746
Epoch 5/10, Batch 70/97, Loss: 0.4413
Epoch 5/10, Batch 80/97, Loss: 0.2441
Epoch 5/10, Batch 90/97, Loss: 0.1940
Epoch 5/10, Train Loss: 0.2641, Valid Loss: 0.2700
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3286
Epoch 6/10, Batch 20/97, Loss: 0.3796
Epoch 6/10, Batch 30/97, Loss: 0.3019
Epoch 6/10, Batch 40/97, Loss: 0.1269
Epoch 6/10, Batch 50/97, Loss: 0.2040
Epoch 6/10, Batch 60/97, Loss: 0.2302
Epoch 6/10, Batch 70/97, Loss: 0.1734
Epoch 6/10, Batch 80/97, Loss: 0.3986
Epoch 6/10, Batch 90/97, Loss: 0.2277
Epoch 6/10, Train Loss: 0.2407, Valid Loss: 0.2604
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2166
Epoch 7/10, Batch 20/97, Loss: 0.1929
Epoch 7/10, Batch 30/97, Loss: 0.2211
Epoch 7/10, Batch 40/97, Loss: 0.1266
Epoch 7/10, Batch 50/97, Loss: 0.1374
Epoch 7/10, Batch 60/97, Loss: 0.3183
Epoch 7/10, Batch 70/97, Loss: 0.1732
Epoch 7/10, Batch 80/97, Loss: 0.2086
Epoch 7/10, Batch 90/97, Loss: 0.1899
Epoch 7/10, Train Loss: 0.2231, Valid Loss: 0.2536
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1003
Epoch 8/10, Batch 20/97, Loss: 0.1170
Epoch 8/10, Batch 30/97, Loss: 0.2391
Epoch 8/10, Batch 40/97, Loss: 0.3520
Epoch 8/10, Batch 50/97, Loss: 0.2576
Epoch 8/10, Batch 60/97, Loss: 0.2001
Epoch 8/10, Batch 70/97, Loss: 0.2352
Epoch 8/10, Batch 80/97, Loss: 0.1672
Epoch 8/10, Batch 90/97, Loss: 0.1866
Epoch 8/10, Train Loss: 0.2170, Valid Loss: 0.2556
Epoch 9/10, Batch 10/97, Loss: 0.2514
Epoch 9/10, Batch 20/97, Loss: 0.1403
Epoch 9/10, Batch 30/97, Loss: 0.2892
Epoch 9/10, Batch 40/97, Loss: 0.3660
Epoch 9/10, Batch 50/97, Loss: 0.2777
Epoch 9/10, Batch 60/97, Loss: 0.3111
Epoch 9/10, Batch 70/97, Loss: 0.1181
Epoch 9/10, Batch 80/97, Loss: 0.1421
Epoch 9/10, Batch 90/97, Loss: 0.1858
Epoch 9/10, Train Loss: 0.2068, Valid Loss: 0.2505
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2050
Epoch 10/10, Batch 20/97, Loss: 0.1489
Epoch 10/10, Batch 30/97, Loss: 0.2096
Epoch 10/10, Batch 40/97, Loss: 0.1965
Epoch 10/10, Batch 50/97, Loss: 0.1638
Epoch 10/10, Batch 60/97, Loss: 0.0646
Epoch 10/10, Batch 70/97, Loss: 0.2740
Epoch 10/10, Batch 80/97, Loss: 0.1033
Epoch 10/10, Batch 90/97, Loss: 0.2408
Epoch 10/10, Train Loss: 0.2024, Valid Loss: 0.2615
Accuracy: 0.9112
Precision: 0.9082
Recall: 0.9112
F1-score: 0.9090
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2614
Epoch 1/10, Batch 20/97, Loss: 1.1013
Epoch 1/10, Batch 30/97, Loss: 0.8766
Epoch 1/10, Batch 40/97, Loss: 0.8763
Epoch 1/10, Batch 50/97, Loss: 0.8143
Epoch 1/10, Batch 60/97, Loss: 0.7947
Epoch 1/10, Batch 70/97, Loss: 0.6711
Epoch 1/10, Batch 80/97, Loss: 0.5877
Epoch 1/10, Batch 90/97, Loss: 0.4425
Epoch 1/10, Train Loss: 0.8131, Valid Loss: 0.4353
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6199
Epoch 2/10, Batch 20/97, Loss: 0.5013
Epoch 2/10, Batch 30/97, Loss: 0.4195
Epoch 2/10, Batch 40/97, Loss: 0.4117
Epoch 2/10, Batch 50/97, Loss: 0.3934
Epoch 2/10, Batch 60/97, Loss: 0.4151
Epoch 2/10, Batch 70/97, Loss: 0.3556
Epoch 2/10, Batch 80/97, Loss: 0.3412
Epoch 2/10, Batch 90/97, Loss: 0.4595
Epoch 2/10, Train Loss: 0.4209, Valid Loss: 0.3289
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2852
Epoch 3/10, Batch 20/97, Loss: 0.3569
Epoch 3/10, Batch 30/97, Loss: 0.3682
Epoch 3/10, Batch 40/97, Loss: 0.2928
Epoch 3/10, Batch 50/97, Loss: 0.3921
Epoch 3/10, Batch 60/97, Loss: 0.2574
Epoch 3/10, Batch 70/97, Loss: 0.3321
Epoch 3/10, Batch 80/97, Loss: 0.1952
Epoch 3/10, Batch 90/97, Loss: 0.2722
Epoch 3/10, Train Loss: 0.3420, Valid Loss: 0.2863
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4808
Epoch 4/10, Batch 20/97, Loss: 0.1553
Epoch 4/10, Batch 30/97, Loss: 0.2194
Epoch 4/10, Batch 40/97, Loss: 0.2267
Epoch 4/10, Batch 50/97, Loss: 0.2869
Epoch 4/10, Batch 60/97, Loss: 0.1543
Epoch 4/10, Batch 70/97, Loss: 0.3253
Epoch 4/10, Batch 80/97, Loss: 0.2041
Epoch 4/10, Batch 90/97, Loss: 0.1860
Epoch 4/10, Train Loss: 0.2970, Valid Loss: 0.2644
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2932
Epoch 5/10, Batch 20/97, Loss: 0.2878
Epoch 5/10, Batch 30/97, Loss: 0.1042
Epoch 5/10, Batch 40/97, Loss: 0.2242
Epoch 5/10, Batch 50/97, Loss: 0.2032
Epoch 5/10, Batch 60/97, Loss: 0.2720
Epoch 5/10, Batch 70/97, Loss: 0.2465
Epoch 5/10, Batch 80/97, Loss: 0.1885
Epoch 5/10, Batch 90/97, Loss: 0.1482
Epoch 5/10, Train Loss: 0.2700, Valid Loss: 0.2531
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2434
Epoch 6/10, Batch 20/97, Loss: 0.2383
Epoch 6/10, Batch 30/97, Loss: 0.1739
Epoch 6/10, Batch 40/97, Loss: 0.1784
Epoch 6/10, Batch 50/97, Loss: 0.2676
Epoch 6/10, Batch 60/97, Loss: 0.3034
Epoch 6/10, Batch 70/97, Loss: 0.2172
Epoch 6/10, Batch 80/97, Loss: 0.2045
Epoch 6/10, Batch 90/97, Loss: 0.2529
Epoch 6/10, Train Loss: 0.2521, Valid Loss: 0.2389
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2993
Epoch 7/10, Batch 20/97, Loss: 0.3649
Epoch 7/10, Batch 30/97, Loss: 0.1152
Epoch 7/10, Batch 40/97, Loss: 0.2578
Epoch 7/10, Batch 50/97, Loss: 0.1547
Epoch 7/10, Batch 60/97, Loss: 0.2465
Epoch 7/10, Batch 70/97, Loss: 0.3655
Epoch 7/10, Batch 80/97, Loss: 0.2522
Epoch 7/10, Batch 90/97, Loss: 0.1627
Epoch 7/10, Train Loss: 0.2283, Valid Loss: 0.2350
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2885
Epoch 8/10, Batch 20/97, Loss: 0.2248
Epoch 8/10, Batch 30/97, Loss: 0.1454
Epoch 8/10, Batch 40/97, Loss: 0.3163
Epoch 8/10, Batch 50/97, Loss: 0.3164
Epoch 8/10, Batch 60/97, Loss: 0.2783
Epoch 8/10, Batch 70/97, Loss: 0.2377
Epoch 8/10, Batch 80/97, Loss: 0.2232
Epoch 8/10, Batch 90/97, Loss: 0.1959
Epoch 8/10, Train Loss: 0.2232, Valid Loss: 0.2262
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1605
Epoch 9/10, Batch 20/97, Loss: 0.1554
Epoch 9/10, Batch 30/97, Loss: 0.1985
Epoch 9/10, Batch 40/97, Loss: 0.2627
Epoch 9/10, Batch 50/97, Loss: 0.1145
Epoch 9/10, Batch 60/97, Loss: 0.1814
Epoch 9/10, Batch 70/97, Loss: 0.2933
Epoch 9/10, Batch 80/97, Loss: 0.2442
Epoch 9/10, Batch 90/97, Loss: 0.2657
Epoch 9/10, Train Loss: 0.2116, Valid Loss: 0.2269
Epoch 10/10, Batch 10/97, Loss: 0.2093
Epoch 10/10, Batch 20/97, Loss: 0.1094
Epoch 10/10, Batch 30/97, Loss: 0.2208
Epoch 10/10, Batch 40/97, Loss: 0.1453
Epoch 10/10, Batch 50/97, Loss: 0.1736
Epoch 10/10, Batch 60/97, Loss: 0.1655
Epoch 10/10, Batch 70/97, Loss: 0.1804
Epoch 10/10, Batch 80/97, Loss: 0.1093
Epoch 10/10, Batch 90/97, Loss: 0.1290
Epoch 10/10, Train Loss: 0.2084, Valid Loss: 0.2291
Accuracy: 0.9147
Precision: 0.9113
Recall: 0.9147
F1-score: 0.9125
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2796
Epoch 1/10, Batch 20/97, Loss: 1.1018
Epoch 1/10, Batch 30/97, Loss: 0.7162
Epoch 1/10, Batch 40/97, Loss: 0.7292
Epoch 1/10, Batch 50/97, Loss: 0.6121
Epoch 1/10, Batch 60/97, Loss: 0.6818
Epoch 1/10, Batch 70/97, Loss: 0.6400
Epoch 1/10, Batch 80/97, Loss: 0.6388
Epoch 1/10, Batch 90/97, Loss: 0.5040
Epoch 1/10, Train Loss: 0.8029, Valid Loss: 0.4555
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3843
Epoch 2/10, Batch 20/97, Loss: 0.5382
Epoch 2/10, Batch 30/97, Loss: 0.2848
Epoch 2/10, Batch 40/97, Loss: 0.4162
Epoch 2/10, Batch 50/97, Loss: 0.3015
Epoch 2/10, Batch 60/97, Loss: 0.3836
Epoch 2/10, Batch 70/97, Loss: 0.3756
Epoch 2/10, Batch 80/97, Loss: 0.5118
Epoch 2/10, Batch 90/97, Loss: 0.3051
Epoch 2/10, Train Loss: 0.4182, Valid Loss: 0.3427
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2791
Epoch 3/10, Batch 20/97, Loss: 0.2621
Epoch 3/10, Batch 30/97, Loss: 0.4582
Epoch 3/10, Batch 40/97, Loss: 0.3208
Epoch 3/10, Batch 50/97, Loss: 0.3906
Epoch 3/10, Batch 60/97, Loss: 0.2497
Epoch 3/10, Batch 70/97, Loss: 0.4052
Epoch 3/10, Batch 80/97, Loss: 0.4599
Epoch 3/10, Batch 90/97, Loss: 0.2289
Epoch 3/10, Train Loss: 0.3333, Valid Loss: 0.2953
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3969
Epoch 4/10, Batch 20/97, Loss: 0.2816
Epoch 4/10, Batch 30/97, Loss: 0.1819
Epoch 4/10, Batch 40/97, Loss: 0.2252
Epoch 4/10, Batch 50/97, Loss: 0.3607
Epoch 4/10, Batch 60/97, Loss: 0.2475
Epoch 4/10, Batch 70/97, Loss: 0.2148
Epoch 4/10, Batch 80/97, Loss: 0.2083
Epoch 4/10, Batch 90/97, Loss: 0.2795
Epoch 4/10, Train Loss: 0.2886, Valid Loss: 0.2769
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2562
Epoch 5/10, Batch 20/97, Loss: 0.3192
Epoch 5/10, Batch 30/97, Loss: 0.1837
Epoch 5/10, Batch 40/97, Loss: 0.2535
Epoch 5/10, Batch 50/97, Loss: 0.3455
Epoch 5/10, Batch 60/97, Loss: 0.2453
Epoch 5/10, Batch 70/97, Loss: 0.1935
Epoch 5/10, Batch 80/97, Loss: 0.2175
Epoch 5/10, Batch 90/97, Loss: 0.1969
Epoch 5/10, Train Loss: 0.2704, Valid Loss: 0.2642
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2977
Epoch 6/10, Batch 20/97, Loss: 0.1761
Epoch 6/10, Batch 30/97, Loss: 0.1693
Epoch 6/10, Batch 40/97, Loss: 0.1673
Epoch 6/10, Batch 50/97, Loss: 0.3257
Epoch 6/10, Batch 60/97, Loss: 0.3109
Epoch 6/10, Batch 70/97, Loss: 0.2530
Epoch 6/10, Batch 80/97, Loss: 0.2443
Epoch 6/10, Batch 90/97, Loss: 0.2360
Epoch 6/10, Train Loss: 0.2468, Valid Loss: 0.2529
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2848
Epoch 7/10, Batch 20/97, Loss: 0.2462
Epoch 7/10, Batch 30/97, Loss: 0.1771
Epoch 7/10, Batch 40/97, Loss: 0.1932
Epoch 7/10, Batch 50/97, Loss: 0.2303
Epoch 7/10, Batch 60/97, Loss: 0.1308
Epoch 7/10, Batch 70/97, Loss: 0.2386
Epoch 7/10, Batch 80/97, Loss: 0.2343
Epoch 7/10, Batch 90/97, Loss: 0.3025
Epoch 7/10, Train Loss: 0.2326, Valid Loss: 0.2418
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2528
Epoch 8/10, Batch 20/97, Loss: 0.2310
Epoch 8/10, Batch 30/97, Loss: 0.1541
Epoch 8/10, Batch 40/97, Loss: 0.1291
Epoch 8/10, Batch 50/97, Loss: 0.1980
Epoch 8/10, Batch 60/97, Loss: 0.1614
Epoch 8/10, Batch 70/97, Loss: 0.3160
Epoch 8/10, Batch 80/97, Loss: 0.1551
Epoch 8/10, Batch 90/97, Loss: 0.2744
Epoch 8/10, Train Loss: 0.2178, Valid Loss: 0.2393
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1515
Epoch 9/10, Batch 20/97, Loss: 0.1572
Epoch 9/10, Batch 30/97, Loss: 0.2013
Epoch 9/10, Batch 40/97, Loss: 0.2573
Epoch 9/10, Batch 50/97, Loss: 0.1703
Epoch 9/10, Batch 60/97, Loss: 0.2633
Epoch 9/10, Batch 70/97, Loss: 0.0893
Epoch 9/10, Batch 80/97, Loss: 0.3332
Epoch 9/10, Batch 90/97, Loss: 0.2448
Epoch 9/10, Train Loss: 0.2090, Valid Loss: 0.2309
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1615
Epoch 10/10, Batch 20/97, Loss: 0.1986
Epoch 10/10, Batch 30/97, Loss: 0.4494
Epoch 10/10, Batch 40/97, Loss: 0.2073
Epoch 10/10, Batch 50/97, Loss: 0.1655
Epoch 10/10, Batch 60/97, Loss: 0.1443
Epoch 10/10, Batch 70/97, Loss: 0.1978
Epoch 10/10, Batch 80/97, Loss: 0.2138
Epoch 10/10, Batch 90/97, Loss: 0.1095
Epoch 10/10, Train Loss: 0.2007, Valid Loss: 0.2298
Model saved!
Accuracy: 0.9112
Precision: 0.9075
Recall: 0.9112
F1-score: 0.9079
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2558
Epoch 1/10, Batch 20/97, Loss: 1.0943
Epoch 1/10, Batch 30/97, Loss: 0.8048
Epoch 1/10, Batch 40/97, Loss: 0.7559
Epoch 1/10, Batch 50/97, Loss: 0.7008
Epoch 1/10, Batch 60/97, Loss: 0.7306
Epoch 1/10, Batch 70/97, Loss: 0.5840
Epoch 1/10, Batch 80/97, Loss: 0.7833
Epoch 1/10, Batch 90/97, Loss: 0.5848
Epoch 1/10, Train Loss: 0.8023, Valid Loss: 0.4396
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5828
Epoch 2/10, Batch 20/97, Loss: 0.3123
Epoch 2/10, Batch 30/97, Loss: 0.3683
Epoch 2/10, Batch 40/97, Loss: 0.4203
Epoch 2/10, Batch 50/97, Loss: 0.4154
Epoch 2/10, Batch 60/97, Loss: 0.4400
Epoch 2/10, Batch 70/97, Loss: 0.2881
Epoch 2/10, Batch 80/97, Loss: 0.3950
Epoch 2/10, Batch 90/97, Loss: 0.4388
Epoch 2/10, Train Loss: 0.4210, Valid Loss: 0.3322
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3013
Epoch 3/10, Batch 20/97, Loss: 0.5451
Epoch 3/10, Batch 30/97, Loss: 0.5658
Epoch 3/10, Batch 40/97, Loss: 0.2158
Epoch 3/10, Batch 50/97, Loss: 0.4341
Epoch 3/10, Batch 60/97, Loss: 0.3921
Epoch 3/10, Batch 70/97, Loss: 0.4711
Epoch 3/10, Batch 80/97, Loss: 0.3525
Epoch 3/10, Batch 90/97, Loss: 0.3173
Epoch 3/10, Train Loss: 0.3403, Valid Loss: 0.2891
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3983
Epoch 4/10, Batch 20/97, Loss: 0.2537
Epoch 4/10, Batch 30/97, Loss: 0.4094
Epoch 4/10, Batch 40/97, Loss: 0.2781
Epoch 4/10, Batch 50/97, Loss: 0.3097
Epoch 4/10, Batch 60/97, Loss: 0.2939
Epoch 4/10, Batch 70/97, Loss: 0.2796
Epoch 4/10, Batch 80/97, Loss: 0.3096
Epoch 4/10, Batch 90/97, Loss: 0.1936
Epoch 4/10, Train Loss: 0.2959, Valid Loss: 0.2727
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3371
Epoch 5/10, Batch 20/97, Loss: 0.2686
Epoch 5/10, Batch 30/97, Loss: 0.1767
Epoch 5/10, Batch 40/97, Loss: 0.2290
Epoch 5/10, Batch 50/97, Loss: 0.2087
Epoch 5/10, Batch 60/97, Loss: 0.2421
Epoch 5/10, Batch 70/97, Loss: 0.2356
Epoch 5/10, Batch 80/97, Loss: 0.3310
Epoch 5/10, Batch 90/97, Loss: 0.1710
Epoch 5/10, Train Loss: 0.2687, Valid Loss: 0.2549
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2009
Epoch 6/10, Batch 20/97, Loss: 0.2195
Epoch 6/10, Batch 30/97, Loss: 0.1299
Epoch 6/10, Batch 40/97, Loss: 0.1060
Epoch 6/10, Batch 50/97, Loss: 0.3984
Epoch 6/10, Batch 60/97, Loss: 0.2456
Epoch 6/10, Batch 70/97, Loss: 0.2401
Epoch 6/10, Batch 80/97, Loss: 0.2980
Epoch 6/10, Batch 90/97, Loss: 0.2716
Epoch 6/10, Train Loss: 0.2445, Valid Loss: 0.2357
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2407
Epoch 7/10, Batch 20/97, Loss: 0.2489
Epoch 7/10, Batch 30/97, Loss: 0.1485
Epoch 7/10, Batch 40/97, Loss: 0.2196
Epoch 7/10, Batch 50/97, Loss: 0.1165
Epoch 7/10, Batch 60/97, Loss: 0.1378
Epoch 7/10, Batch 70/97, Loss: 0.2647
Epoch 7/10, Batch 80/97, Loss: 0.3352
Epoch 7/10, Batch 90/97, Loss: 0.1263
Epoch 7/10, Train Loss: 0.2236, Valid Loss: 0.2381
Epoch 8/10, Batch 10/97, Loss: 0.2136
Epoch 8/10, Batch 20/97, Loss: 0.2552
Epoch 8/10, Batch 30/97, Loss: 0.1413
Epoch 8/10, Batch 40/97, Loss: 0.2307
Epoch 8/10, Batch 50/97, Loss: 0.1903
Epoch 8/10, Batch 60/97, Loss: 0.0897
Epoch 8/10, Batch 70/97, Loss: 0.2154
Epoch 8/10, Batch 80/97, Loss: 0.3098
Epoch 8/10, Batch 90/97, Loss: 0.0849
Epoch 8/10, Train Loss: 0.2261, Valid Loss: 0.2303
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1939
Epoch 9/10, Batch 20/97, Loss: 0.2068
Epoch 9/10, Batch 30/97, Loss: 0.3053
Epoch 9/10, Batch 40/97, Loss: 0.3073
Epoch 9/10, Batch 50/97, Loss: 0.1124
Epoch 9/10, Batch 60/97, Loss: 0.1666
Epoch 9/10, Batch 70/97, Loss: 0.1749
Epoch 9/10, Batch 80/97, Loss: 0.1408
Epoch 9/10, Batch 90/97, Loss: 0.1547
Epoch 9/10, Train Loss: 0.2072, Valid Loss: 0.2281
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3435
Epoch 10/10, Batch 20/97, Loss: 0.2856
Epoch 10/10, Batch 30/97, Loss: 0.1102
Epoch 10/10, Batch 40/97, Loss: 0.2256
Epoch 10/10, Batch 50/97, Loss: 0.1784
Epoch 10/10, Batch 60/97, Loss: 0.0717
Epoch 10/10, Batch 70/97, Loss: 0.1429
Epoch 10/10, Batch 80/97, Loss: 0.1856
Epoch 10/10, Batch 90/97, Loss: 0.1183
Epoch 10/10, Train Loss: 0.2041, Valid Loss: 0.2190
Model saved!
Accuracy: 0.9147
Precision: 0.9116
Recall: 0.9147
F1-score: 0.9125
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2142
Epoch 1/10, Batch 20/97, Loss: 1.0768
Epoch 1/10, Batch 30/97, Loss: 0.8418
Epoch 1/10, Batch 40/97, Loss: 0.7621
Epoch 1/10, Batch 50/97, Loss: 0.6010
Epoch 1/10, Batch 60/97, Loss: 0.7348
Epoch 1/10, Batch 70/97, Loss: 0.6652
Epoch 1/10, Batch 80/97, Loss: 0.6041
Epoch 1/10, Batch 90/97, Loss: 0.4977
Epoch 1/10, Train Loss: 0.8081, Valid Loss: 0.4714
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4732
Epoch 2/10, Batch 20/97, Loss: 0.3442
Epoch 2/10, Batch 30/97, Loss: 0.3654
Epoch 2/10, Batch 40/97, Loss: 0.3418
Epoch 2/10, Batch 50/97, Loss: 0.3673
Epoch 2/10, Batch 60/97, Loss: 0.3999
Epoch 2/10, Batch 70/97, Loss: 0.4268
Epoch 2/10, Batch 80/97, Loss: 0.2832
Epoch 2/10, Batch 90/97, Loss: 0.4788
Epoch 2/10, Train Loss: 0.4065, Valid Loss: 0.3562
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3359
Epoch 3/10, Batch 20/97, Loss: 0.2635
Epoch 3/10, Batch 30/97, Loss: 0.3746
Epoch 3/10, Batch 40/97, Loss: 0.3328
Epoch 3/10, Batch 50/97, Loss: 0.3483
Epoch 3/10, Batch 60/97, Loss: 0.1595
Epoch 3/10, Batch 70/97, Loss: 0.4296
Epoch 3/10, Batch 80/97, Loss: 0.3281
Epoch 3/10, Batch 90/97, Loss: 0.2700
Epoch 3/10, Train Loss: 0.3310, Valid Loss: 0.3133
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3059
Epoch 4/10, Batch 20/97, Loss: 0.2285
Epoch 4/10, Batch 30/97, Loss: 0.2023
Epoch 4/10, Batch 40/97, Loss: 0.2099
Epoch 4/10, Batch 50/97, Loss: 0.4240
Epoch 4/10, Batch 60/97, Loss: 0.2819
Epoch 4/10, Batch 70/97, Loss: 0.2619
Epoch 4/10, Batch 80/97, Loss: 0.1843
Epoch 4/10, Batch 90/97, Loss: 0.2322
Epoch 4/10, Train Loss: 0.2846, Valid Loss: 0.2994
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3177
Epoch 5/10, Batch 20/97, Loss: 0.2388
Epoch 5/10, Batch 30/97, Loss: 0.1252
Epoch 5/10, Batch 40/97, Loss: 0.1831
Epoch 5/10, Batch 50/97, Loss: 0.1904
Epoch 5/10, Batch 60/97, Loss: 0.2564
Epoch 5/10, Batch 70/97, Loss: 0.2408
Epoch 5/10, Batch 80/97, Loss: 0.2787
Epoch 5/10, Batch 90/97, Loss: 0.1712
Epoch 5/10, Train Loss: 0.2612, Valid Loss: 0.2846
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2610
Epoch 6/10, Batch 20/97, Loss: 0.3671
Epoch 6/10, Batch 30/97, Loss: 0.1508
Epoch 6/10, Batch 40/97, Loss: 0.1632
Epoch 6/10, Batch 50/97, Loss: 0.3252
Epoch 6/10, Batch 60/97, Loss: 0.2311
Epoch 6/10, Batch 70/97, Loss: 0.1457
Epoch 6/10, Batch 80/97, Loss: 0.2948
Epoch 6/10, Batch 90/97, Loss: 0.3531
Epoch 6/10, Train Loss: 0.2450, Valid Loss: 0.2704
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1781
Epoch 7/10, Batch 20/97, Loss: 0.2693
Epoch 7/10, Batch 30/97, Loss: 0.1818
Epoch 7/10, Batch 40/97, Loss: 0.1424
Epoch 7/10, Batch 50/97, Loss: 0.3533
Epoch 7/10, Batch 60/97, Loss: 0.1453
Epoch 7/10, Batch 70/97, Loss: 0.2311
Epoch 7/10, Batch 80/97, Loss: 0.3085
Epoch 7/10, Batch 90/97, Loss: 0.1252
Epoch 7/10, Train Loss: 0.2183, Valid Loss: 0.2677
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1591
Epoch 8/10, Batch 20/97, Loss: 0.1989
Epoch 8/10, Batch 30/97, Loss: 0.1550
Epoch 8/10, Batch 40/97, Loss: 0.1366
Epoch 8/10, Batch 50/97, Loss: 0.1609
Epoch 8/10, Batch 60/97, Loss: 0.2721
Epoch 8/10, Batch 70/97, Loss: 0.2284
Epoch 8/10, Batch 80/97, Loss: 0.1091
Epoch 8/10, Batch 90/97, Loss: 0.1523
Epoch 8/10, Train Loss: 0.2125, Valid Loss: 0.2578
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2507
Epoch 9/10, Batch 20/97, Loss: 0.1117
Epoch 9/10, Batch 30/97, Loss: 0.2917
Epoch 9/10, Batch 40/97, Loss: 0.3022
Epoch 9/10, Batch 50/97, Loss: 0.2229
Epoch 9/10, Batch 60/97, Loss: 0.2065
Epoch 9/10, Batch 70/97, Loss: 0.1356
Epoch 9/10, Batch 80/97, Loss: 0.0881
Epoch 9/10, Batch 90/97, Loss: 0.2466
Epoch 9/10, Train Loss: 0.2023, Valid Loss: 0.2552
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3083
Epoch 10/10, Batch 20/97, Loss: 0.0866
Epoch 10/10, Batch 30/97, Loss: 0.1051
Epoch 10/10, Batch 40/97, Loss: 0.1100
Epoch 10/10, Batch 50/97, Loss: 0.3265
Epoch 10/10, Batch 60/97, Loss: 0.1596
Epoch 10/10, Batch 70/97, Loss: 0.2923
Epoch 10/10, Batch 80/97, Loss: 0.1751
Epoch 10/10, Batch 90/97, Loss: 0.1503
Epoch 10/10, Train Loss: 0.1933, Valid Loss: 0.2572
Accuracy: 0.9159
Precision: 0.9133
Recall: 0.9159
F1-score: 0.9131
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2788
Epoch 1/10, Batch 20/97, Loss: 1.0067
Epoch 1/10, Batch 30/97, Loss: 0.7090
Epoch 1/10, Batch 40/97, Loss: 0.6983
Epoch 1/10, Batch 50/97, Loss: 0.5181
Epoch 1/10, Batch 60/97, Loss: 0.6055
Epoch 1/10, Batch 70/97, Loss: 0.7476
Epoch 1/10, Batch 80/97, Loss: 0.6533
Epoch 1/10, Batch 90/97, Loss: 0.6465
Epoch 1/10, Train Loss: 0.7922, Valid Loss: 0.4648
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4143
Epoch 2/10, Batch 20/97, Loss: 0.3599
Epoch 2/10, Batch 30/97, Loss: 0.3043
Epoch 2/10, Batch 40/97, Loss: 0.4059
Epoch 2/10, Batch 50/97, Loss: 0.3868
Epoch 2/10, Batch 60/97, Loss: 0.4726
Epoch 2/10, Batch 70/97, Loss: 0.4265
Epoch 2/10, Batch 80/97, Loss: 0.4977
Epoch 2/10, Batch 90/97, Loss: 0.5217
Epoch 2/10, Train Loss: 0.4055, Valid Loss: 0.3407
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3954
Epoch 3/10, Batch 20/97, Loss: 0.3235
Epoch 3/10, Batch 30/97, Loss: 0.5125
Epoch 3/10, Batch 40/97, Loss: 0.2695
Epoch 3/10, Batch 50/97, Loss: 0.4587
Epoch 3/10, Batch 60/97, Loss: 0.2008
Epoch 3/10, Batch 70/97, Loss: 0.3328
Epoch 3/10, Batch 80/97, Loss: 0.3752
Epoch 3/10, Batch 90/97, Loss: 0.2971
Epoch 3/10, Train Loss: 0.3285, Valid Loss: 0.2987
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4206
Epoch 4/10, Batch 20/97, Loss: 0.3021
Epoch 4/10, Batch 30/97, Loss: 0.2710
Epoch 4/10, Batch 40/97, Loss: 0.3508
Epoch 4/10, Batch 50/97, Loss: 0.3050
Epoch 4/10, Batch 60/97, Loss: 0.1892
Epoch 4/10, Batch 70/97, Loss: 0.1743
Epoch 4/10, Batch 80/97, Loss: 0.1845
Epoch 4/10, Batch 90/97, Loss: 0.2574
Epoch 4/10, Train Loss: 0.2750, Valid Loss: 0.2775
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1609
Epoch 5/10, Batch 20/97, Loss: 0.3796
Epoch 5/10, Batch 30/97, Loss: 0.1591
Epoch 5/10, Batch 40/97, Loss: 0.2011
Epoch 5/10, Batch 50/97, Loss: 0.1057
Epoch 5/10, Batch 60/97, Loss: 0.1913
Epoch 5/10, Batch 70/97, Loss: 0.4875
Epoch 5/10, Batch 80/97, Loss: 0.1475
Epoch 5/10, Batch 90/97, Loss: 0.1992
Epoch 5/10, Train Loss: 0.2604, Valid Loss: 0.2635
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1337
Epoch 6/10, Batch 20/97, Loss: 0.2983
Epoch 6/10, Batch 30/97, Loss: 0.1298
Epoch 6/10, Batch 40/97, Loss: 0.2799
Epoch 6/10, Batch 50/97, Loss: 0.2908
Epoch 6/10, Batch 60/97, Loss: 0.3031
Epoch 6/10, Batch 70/97, Loss: 0.1537
Epoch 6/10, Batch 80/97, Loss: 0.2873
Epoch 6/10, Batch 90/97, Loss: 0.1903
Epoch 6/10, Train Loss: 0.2361, Valid Loss: 0.2498
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1492
Epoch 7/10, Batch 20/97, Loss: 0.2493
Epoch 7/10, Batch 30/97, Loss: 0.1666
Epoch 7/10, Batch 40/97, Loss: 0.2219
Epoch 7/10, Batch 50/97, Loss: 0.2186
Epoch 7/10, Batch 60/97, Loss: 0.1501
Epoch 7/10, Batch 70/97, Loss: 0.2313
Epoch 7/10, Batch 80/97, Loss: 0.2925
Epoch 7/10, Batch 90/97, Loss: 0.2338
Epoch 7/10, Train Loss: 0.2148, Valid Loss: 0.2455
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2029
Epoch 8/10, Batch 20/97, Loss: 0.3134
Epoch 8/10, Batch 30/97, Loss: 0.1422
Epoch 8/10, Batch 40/97, Loss: 0.1574
Epoch 8/10, Batch 50/97, Loss: 0.2711
Epoch 8/10, Batch 60/97, Loss: 0.2106
Epoch 8/10, Batch 70/97, Loss: 0.2686
Epoch 8/10, Batch 80/97, Loss: 0.1753
Epoch 8/10, Batch 90/97, Loss: 0.1916
Epoch 8/10, Train Loss: 0.2093, Valid Loss: 0.2395
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1738
Epoch 9/10, Batch 20/97, Loss: 0.0923
Epoch 9/10, Batch 30/97, Loss: 0.2811
Epoch 9/10, Batch 40/97, Loss: 0.2942
Epoch 9/10, Batch 50/97, Loss: 0.1624
Epoch 9/10, Batch 60/97, Loss: 0.1849
Epoch 9/10, Batch 70/97, Loss: 0.1723
Epoch 9/10, Batch 80/97, Loss: 0.1306
Epoch 9/10, Batch 90/97, Loss: 0.1506
Epoch 9/10, Train Loss: 0.2066, Valid Loss: 0.2309
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1296
Epoch 10/10, Batch 20/97, Loss: 0.1460
Epoch 10/10, Batch 30/97, Loss: 0.3625
Epoch 10/10, Batch 40/97, Loss: 0.0903
Epoch 10/10, Batch 50/97, Loss: 0.2607
Epoch 10/10, Batch 60/97, Loss: 0.1594
Epoch 10/10, Batch 70/97, Loss: 0.1204
Epoch 10/10, Batch 80/97, Loss: 0.2809
Epoch 10/10, Batch 90/97, Loss: 0.2284
Epoch 10/10, Train Loss: 0.1927, Valid Loss: 0.2337
Accuracy: 0.9112
Precision: 0.9080
Recall: 0.9112
F1-score: 0.9085
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2321
Epoch 1/10, Batch 20/97, Loss: 1.0740
Epoch 1/10, Batch 30/97, Loss: 0.8276
Epoch 1/10, Batch 40/97, Loss: 0.8139
Epoch 1/10, Batch 50/97, Loss: 0.7038
Epoch 1/10, Batch 60/97, Loss: 0.6938
Epoch 1/10, Batch 70/97, Loss: 0.6065
Epoch 1/10, Batch 80/97, Loss: 0.6822
Epoch 1/10, Batch 90/97, Loss: 0.6368
Epoch 1/10, Train Loss: 0.8005, Valid Loss: 0.4404
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4946
Epoch 2/10, Batch 20/97, Loss: 0.4737
Epoch 2/10, Batch 30/97, Loss: 0.2772
Epoch 2/10, Batch 40/97, Loss: 0.3903
Epoch 2/10, Batch 50/97, Loss: 0.5147
Epoch 2/10, Batch 60/97, Loss: 0.3880
Epoch 2/10, Batch 70/97, Loss: 0.4553
Epoch 2/10, Batch 80/97, Loss: 0.4760
Epoch 2/10, Batch 90/97, Loss: 0.3385
Epoch 2/10, Train Loss: 0.4101, Valid Loss: 0.3329
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3722
Epoch 3/10, Batch 20/97, Loss: 0.3039
Epoch 3/10, Batch 30/97, Loss: 0.3487
Epoch 3/10, Batch 40/97, Loss: 0.2032
Epoch 3/10, Batch 50/97, Loss: 0.4663
Epoch 3/10, Batch 60/97, Loss: 0.2355
Epoch 3/10, Batch 70/97, Loss: 0.2996
Epoch 3/10, Batch 80/97, Loss: 0.2431
Epoch 3/10, Batch 90/97, Loss: 0.2315
Epoch 3/10, Train Loss: 0.3286, Valid Loss: 0.2921
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.5709
Epoch 4/10, Batch 20/97, Loss: 0.2559
Epoch 4/10, Batch 30/97, Loss: 0.3366
Epoch 4/10, Batch 40/97, Loss: 0.2670
Epoch 4/10, Batch 50/97, Loss: 0.3755
Epoch 4/10, Batch 60/97, Loss: 0.3971
Epoch 4/10, Batch 70/97, Loss: 0.3044
Epoch 4/10, Batch 80/97, Loss: 0.2151
Epoch 4/10, Batch 90/97, Loss: 0.2148
Epoch 4/10, Train Loss: 0.2797, Valid Loss: 0.2693
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3055
Epoch 5/10, Batch 20/97, Loss: 0.2321
Epoch 5/10, Batch 30/97, Loss: 0.2354
Epoch 5/10, Batch 40/97, Loss: 0.3227
Epoch 5/10, Batch 50/97, Loss: 0.2583
Epoch 5/10, Batch 60/97, Loss: 0.2294
Epoch 5/10, Batch 70/97, Loss: 0.2794
Epoch 5/10, Batch 80/97, Loss: 0.3023
Epoch 5/10, Batch 90/97, Loss: 0.1280
Epoch 5/10, Train Loss: 0.2684, Valid Loss: 0.2539
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1604
Epoch 6/10, Batch 20/97, Loss: 0.3559
Epoch 6/10, Batch 30/97, Loss: 0.1671
Epoch 6/10, Batch 40/97, Loss: 0.2077
Epoch 6/10, Batch 50/97, Loss: 0.1923
Epoch 6/10, Batch 60/97, Loss: 0.2528
Epoch 6/10, Batch 70/97, Loss: 0.2972
Epoch 6/10, Batch 80/97, Loss: 0.3101
Epoch 6/10, Batch 90/97, Loss: 0.2655
Epoch 6/10, Train Loss: 0.2400, Valid Loss: 0.2412
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1806
Epoch 7/10, Batch 20/97, Loss: 0.2754
Epoch 7/10, Batch 30/97, Loss: 0.1087
Epoch 7/10, Batch 40/97, Loss: 0.1706
Epoch 7/10, Batch 50/97, Loss: 0.3187
Epoch 7/10, Batch 60/97, Loss: 0.3326
Epoch 7/10, Batch 70/97, Loss: 0.1441
Epoch 7/10, Batch 80/97, Loss: 0.2288
Epoch 7/10, Batch 90/97, Loss: 0.2266
Epoch 7/10, Train Loss: 0.2157, Valid Loss: 0.2344
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2203
Epoch 8/10, Batch 20/97, Loss: 0.1801
Epoch 8/10, Batch 30/97, Loss: 0.1623
Epoch 8/10, Batch 40/97, Loss: 0.2482
Epoch 8/10, Batch 50/97, Loss: 0.2084
Epoch 8/10, Batch 60/97, Loss: 0.2402
Epoch 8/10, Batch 70/97, Loss: 0.1511
Epoch 8/10, Batch 80/97, Loss: 0.3007
Epoch 8/10, Batch 90/97, Loss: 0.2441
Epoch 8/10, Train Loss: 0.2128, Valid Loss: 0.2309
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2914
Epoch 9/10, Batch 20/97, Loss: 0.1835
Epoch 9/10, Batch 30/97, Loss: 0.1651
Epoch 9/10, Batch 40/97, Loss: 0.3088
Epoch 9/10, Batch 50/97, Loss: 0.1859
Epoch 9/10, Batch 60/97, Loss: 0.2050
Epoch 9/10, Batch 70/97, Loss: 0.1475
Epoch 9/10, Batch 80/97, Loss: 0.1160
Epoch 9/10, Batch 90/97, Loss: 0.2010
Epoch 9/10, Train Loss: 0.2020, Valid Loss: 0.2249
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1960
Epoch 10/10, Batch 20/97, Loss: 0.2761
Epoch 10/10, Batch 30/97, Loss: 0.1146
Epoch 10/10, Batch 40/97, Loss: 0.1721
Epoch 10/10, Batch 50/97, Loss: 0.3127
Epoch 10/10, Batch 60/97, Loss: 0.1232
Epoch 10/10, Batch 70/97, Loss: 0.1962
Epoch 10/10, Batch 80/97, Loss: 0.2107
Epoch 10/10, Batch 90/97, Loss: 0.1319
Epoch 10/10, Train Loss: 0.1988, Valid Loss: 0.2250
Accuracy: 0.9217
Precision: 0.9199
Recall: 0.9217
F1-score: 0.9202
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2079
Epoch 1/10, Batch 20/97, Loss: 1.0524
Epoch 1/10, Batch 30/97, Loss: 0.7802
Epoch 1/10, Batch 40/97, Loss: 0.6952
Epoch 1/10, Batch 50/97, Loss: 0.6442
Epoch 1/10, Batch 60/97, Loss: 0.7937
Epoch 1/10, Batch 70/97, Loss: 0.6734
Epoch 1/10, Batch 80/97, Loss: 0.6272
Epoch 1/10, Batch 90/97, Loss: 0.5540
Epoch 1/10, Train Loss: 0.8096, Valid Loss: 0.4436
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5368
Epoch 2/10, Batch 20/97, Loss: 0.4641
Epoch 2/10, Batch 30/97, Loss: 0.3581
Epoch 2/10, Batch 40/97, Loss: 0.4971
Epoch 2/10, Batch 50/97, Loss: 0.4486
Epoch 2/10, Batch 60/97, Loss: 0.3915
Epoch 2/10, Batch 70/97, Loss: 0.3286
Epoch 2/10, Batch 80/97, Loss: 0.4188
Epoch 2/10, Batch 90/97, Loss: 0.3042
Epoch 2/10, Train Loss: 0.4123, Valid Loss: 0.3254
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3253
Epoch 3/10, Batch 20/97, Loss: 0.3344
Epoch 3/10, Batch 30/97, Loss: 0.3853
Epoch 3/10, Batch 40/97, Loss: 0.2285
Epoch 3/10, Batch 50/97, Loss: 0.3016
Epoch 3/10, Batch 60/97, Loss: 0.1959
Epoch 3/10, Batch 70/97, Loss: 0.4589
Epoch 3/10, Batch 80/97, Loss: 0.2118
Epoch 3/10, Batch 90/97, Loss: 0.3631
Epoch 3/10, Train Loss: 0.3335, Valid Loss: 0.2831
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2711
Epoch 4/10, Batch 20/97, Loss: 0.1950
Epoch 4/10, Batch 30/97, Loss: 0.2595
Epoch 4/10, Batch 40/97, Loss: 0.2669
Epoch 4/10, Batch 50/97, Loss: 0.2469
Epoch 4/10, Batch 60/97, Loss: 0.2888
Epoch 4/10, Batch 70/97, Loss: 0.1908
Epoch 4/10, Batch 80/97, Loss: 0.3919
Epoch 4/10, Batch 90/97, Loss: 0.2868
Epoch 4/10, Train Loss: 0.2809, Valid Loss: 0.2630
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3154
Epoch 5/10, Batch 20/97, Loss: 0.2931
Epoch 5/10, Batch 30/97, Loss: 0.2507
Epoch 5/10, Batch 40/97, Loss: 0.2599
Epoch 5/10, Batch 50/97, Loss: 0.1805
Epoch 5/10, Batch 60/97, Loss: 0.3845
Epoch 5/10, Batch 70/97, Loss: 0.1781
Epoch 5/10, Batch 80/97, Loss: 0.2412
Epoch 5/10, Batch 90/97, Loss: 0.1957
Epoch 5/10, Train Loss: 0.2603, Valid Loss: 0.2487
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2714
Epoch 6/10, Batch 20/97, Loss: 0.3756
Epoch 6/10, Batch 30/97, Loss: 0.1874
Epoch 6/10, Batch 40/97, Loss: 0.2077
Epoch 6/10, Batch 50/97, Loss: 0.2607
Epoch 6/10, Batch 60/97, Loss: 0.2748
Epoch 6/10, Batch 70/97, Loss: 0.1709
Epoch 6/10, Batch 80/97, Loss: 0.2391
Epoch 6/10, Batch 90/97, Loss: 0.2294
Epoch 6/10, Train Loss: 0.2393, Valid Loss: 0.2420
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.0816
Epoch 7/10, Batch 20/97, Loss: 0.2066
Epoch 7/10, Batch 30/97, Loss: 0.1478
Epoch 7/10, Batch 40/97, Loss: 0.1467
Epoch 7/10, Batch 50/97, Loss: 0.1561
Epoch 7/10, Batch 60/97, Loss: 0.1185
Epoch 7/10, Batch 70/97, Loss: 0.2578
Epoch 7/10, Batch 80/97, Loss: 0.2880
Epoch 7/10, Batch 90/97, Loss: 0.1722
Epoch 7/10, Train Loss: 0.2239, Valid Loss: 0.2401
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1261
Epoch 8/10, Batch 20/97, Loss: 0.2216
Epoch 8/10, Batch 30/97, Loss: 0.1506
Epoch 8/10, Batch 40/97, Loss: 0.1717
Epoch 8/10, Batch 50/97, Loss: 0.1979
Epoch 8/10, Batch 60/97, Loss: 0.2709
Epoch 8/10, Batch 70/97, Loss: 0.3802
Epoch 8/10, Batch 80/97, Loss: 0.2044
Epoch 8/10, Batch 90/97, Loss: 0.0971
Epoch 8/10, Train Loss: 0.2205, Valid Loss: 0.2336
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1680
Epoch 9/10, Batch 20/97, Loss: 0.1865
Epoch 9/10, Batch 30/97, Loss: 0.2553
Epoch 9/10, Batch 40/97, Loss: 0.2077
Epoch 9/10, Batch 50/97, Loss: 0.2572
Epoch 9/10, Batch 60/97, Loss: 0.0873
Epoch 9/10, Batch 70/97, Loss: 0.2121
Epoch 9/10, Batch 80/97, Loss: 0.3262
Epoch 9/10, Batch 90/97, Loss: 0.1342
Epoch 9/10, Train Loss: 0.2050, Valid Loss: 0.2373
Epoch 10/10, Batch 10/97, Loss: 0.2651
Epoch 10/10, Batch 20/97, Loss: 0.1230
Epoch 10/10, Batch 30/97, Loss: 0.2936
Epoch 10/10, Batch 40/97, Loss: 0.1729
Epoch 10/10, Batch 50/97, Loss: 0.1629
Epoch 10/10, Batch 60/97, Loss: 0.1175
Epoch 10/10, Batch 70/97, Loss: 0.2330
Epoch 10/10, Batch 80/97, Loss: 0.1190
Epoch 10/10, Batch 90/97, Loss: 0.1660
Epoch 10/10, Train Loss: 0.1997, Valid Loss: 0.2264
Model saved!
Accuracy: 0.9077
Precision: 0.9047
Recall: 0.9077
F1-score: 0.9038
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2570
Epoch 1/10, Batch 20/97, Loss: 1.1389
Epoch 1/10, Batch 30/97, Loss: 0.7452
Epoch 1/10, Batch 40/97, Loss: 0.7478
Epoch 1/10, Batch 50/97, Loss: 0.5604
Epoch 1/10, Batch 60/97, Loss: 0.7029
Epoch 1/10, Batch 70/97, Loss: 0.4678
Epoch 1/10, Batch 80/97, Loss: 0.5872
Epoch 1/10, Batch 90/97, Loss: 0.5187
Epoch 1/10, Train Loss: 0.8012, Valid Loss: 0.4281
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4651
Epoch 2/10, Batch 20/97, Loss: 0.4250
Epoch 2/10, Batch 30/97, Loss: 0.3787
Epoch 2/10, Batch 40/97, Loss: 0.3326
Epoch 2/10, Batch 50/97, Loss: 0.4100
Epoch 2/10, Batch 60/97, Loss: 0.4375
Epoch 2/10, Batch 70/97, Loss: 0.2815
Epoch 2/10, Batch 80/97, Loss: 0.3329
Epoch 2/10, Batch 90/97, Loss: 0.4520
Epoch 2/10, Train Loss: 0.4055, Valid Loss: 0.3272
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3734
Epoch 3/10, Batch 20/97, Loss: 0.2308
Epoch 3/10, Batch 30/97, Loss: 0.3531
Epoch 3/10, Batch 40/97, Loss: 0.3034
Epoch 3/10, Batch 50/97, Loss: 0.3822
Epoch 3/10, Batch 60/97, Loss: 0.3257
Epoch 3/10, Batch 70/97, Loss: 0.3349
Epoch 3/10, Batch 80/97, Loss: 0.2972
Epoch 3/10, Batch 90/97, Loss: 0.2930
Epoch 3/10, Train Loss: 0.3340, Valid Loss: 0.2814
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3735
Epoch 4/10, Batch 20/97, Loss: 0.1993
Epoch 4/10, Batch 30/97, Loss: 0.2437
Epoch 4/10, Batch 40/97, Loss: 0.2116
Epoch 4/10, Batch 50/97, Loss: 0.4206
Epoch 4/10, Batch 60/97, Loss: 0.2558
Epoch 4/10, Batch 70/97, Loss: 0.1958
Epoch 4/10, Batch 80/97, Loss: 0.2364
Epoch 4/10, Batch 90/97, Loss: 0.3990
Epoch 4/10, Train Loss: 0.2781, Valid Loss: 0.2584
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3421
Epoch 5/10, Batch 20/97, Loss: 0.3176
Epoch 5/10, Batch 30/97, Loss: 0.2038
Epoch 5/10, Batch 40/97, Loss: 0.2086
Epoch 5/10, Batch 50/97, Loss: 0.3886
Epoch 5/10, Batch 60/97, Loss: 0.3481
Epoch 5/10, Batch 70/97, Loss: 0.1777
Epoch 5/10, Batch 80/97, Loss: 0.1329
Epoch 5/10, Batch 90/97, Loss: 0.1676
Epoch 5/10, Train Loss: 0.2596, Valid Loss: 0.2450
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2098
Epoch 6/10, Batch 20/97, Loss: 0.2269
Epoch 6/10, Batch 30/97, Loss: 0.1716
Epoch 6/10, Batch 40/97, Loss: 0.0952
Epoch 6/10, Batch 50/97, Loss: 0.1699
Epoch 6/10, Batch 60/97, Loss: 0.2872
Epoch 6/10, Batch 70/97, Loss: 0.2224
Epoch 6/10, Batch 80/97, Loss: 0.3089
Epoch 6/10, Batch 90/97, Loss: 0.2279
Epoch 6/10, Train Loss: 0.2398, Valid Loss: 0.2328
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1713
Epoch 7/10, Batch 20/97, Loss: 0.3733
Epoch 7/10, Batch 30/97, Loss: 0.2023
Epoch 7/10, Batch 40/97, Loss: 0.0894
Epoch 7/10, Batch 50/97, Loss: 0.2194
Epoch 7/10, Batch 60/97, Loss: 0.1522
Epoch 7/10, Batch 70/97, Loss: 0.2897
Epoch 7/10, Batch 80/97, Loss: 0.2120
Epoch 7/10, Batch 90/97, Loss: 0.1325
Epoch 7/10, Train Loss: 0.2207, Valid Loss: 0.2196
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.3101
Epoch 8/10, Batch 20/97, Loss: 0.1003
Epoch 8/10, Batch 30/97, Loss: 0.1187
Epoch 8/10, Batch 40/97, Loss: 0.1640
Epoch 8/10, Batch 50/97, Loss: 0.2022
Epoch 8/10, Batch 60/97, Loss: 0.1232
Epoch 8/10, Batch 70/97, Loss: 0.2102
Epoch 8/10, Batch 80/97, Loss: 0.3148
Epoch 8/10, Batch 90/97, Loss: 0.3956
Epoch 8/10, Train Loss: 0.2149, Valid Loss: 0.2224
Epoch 9/10, Batch 10/97, Loss: 0.1844
Epoch 9/10, Batch 20/97, Loss: 0.1397
Epoch 9/10, Batch 30/97, Loss: 0.1434
Epoch 9/10, Batch 40/97, Loss: 0.3281
Epoch 9/10, Batch 50/97, Loss: 0.1095
Epoch 9/10, Batch 60/97, Loss: 0.2473
Epoch 9/10, Batch 70/97, Loss: 0.0786
Epoch 9/10, Batch 80/97, Loss: 0.1075
Epoch 9/10, Batch 90/97, Loss: 0.1966
Epoch 9/10, Train Loss: 0.1989, Valid Loss: 0.2102
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2654
Epoch 10/10, Batch 20/97, Loss: 0.1119
Epoch 10/10, Batch 30/97, Loss: 0.1345
Epoch 10/10, Batch 40/97, Loss: 0.1496
Epoch 10/10, Batch 50/97, Loss: 0.2528
Epoch 10/10, Batch 60/97, Loss: 0.2010
Epoch 10/10, Batch 70/97, Loss: 0.1860
Epoch 10/10, Batch 80/97, Loss: 0.3452
Epoch 10/10, Batch 90/97, Loss: 0.2565
Epoch 10/10, Train Loss: 0.1924, Valid Loss: 0.2133
Accuracy: 0.9136
Precision: 0.9104
Recall: 0.9136
F1-score: 0.9113
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.3245
Epoch 1/10, Batch 20/97, Loss: 1.0854
Epoch 1/10, Batch 30/97, Loss: 0.7257
Epoch 1/10, Batch 40/97, Loss: 0.6889
Epoch 1/10, Batch 50/97, Loss: 0.5180
Epoch 1/10, Batch 60/97, Loss: 0.6808
Epoch 1/10, Batch 70/97, Loss: 0.5200
Epoch 1/10, Batch 80/97, Loss: 0.7027
Epoch 1/10, Batch 90/97, Loss: 0.4276
Epoch 1/10, Train Loss: 0.7919, Valid Loss: 0.4344
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6998
Epoch 2/10, Batch 20/97, Loss: 0.2914
Epoch 2/10, Batch 30/97, Loss: 0.4117
Epoch 2/10, Batch 40/97, Loss: 0.3806
Epoch 2/10, Batch 50/97, Loss: 0.3561
Epoch 2/10, Batch 60/97, Loss: 0.3331
Epoch 2/10, Batch 70/97, Loss: 0.2926
Epoch 2/10, Batch 80/97, Loss: 0.3696
Epoch 2/10, Batch 90/97, Loss: 0.3552
Epoch 2/10, Train Loss: 0.4048, Valid Loss: 0.3259
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2983
Epoch 3/10, Batch 20/97, Loss: 0.3243
Epoch 3/10, Batch 30/97, Loss: 0.4922
Epoch 3/10, Batch 40/97, Loss: 0.3105
Epoch 3/10, Batch 50/97, Loss: 0.3088
Epoch 3/10, Batch 60/97, Loss: 0.2927
Epoch 3/10, Batch 70/97, Loss: 0.4030
Epoch 3/10, Batch 80/97, Loss: 0.4232
Epoch 3/10, Batch 90/97, Loss: 0.2900
Epoch 3/10, Train Loss: 0.3256, Valid Loss: 0.2804
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3565
Epoch 4/10, Batch 20/97, Loss: 0.2220
Epoch 4/10, Batch 30/97, Loss: 0.2378
Epoch 4/10, Batch 40/97, Loss: 0.2344
Epoch 4/10, Batch 50/97, Loss: 0.2764
Epoch 4/10, Batch 60/97, Loss: 0.2509
Epoch 4/10, Batch 70/97, Loss: 0.2826
Epoch 4/10, Batch 80/97, Loss: 0.1179
Epoch 4/10, Batch 90/97, Loss: 0.2014
Epoch 4/10, Train Loss: 0.2797, Valid Loss: 0.2643
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2549
Epoch 5/10, Batch 20/97, Loss: 0.1868
Epoch 5/10, Batch 30/97, Loss: 0.2481
Epoch 5/10, Batch 40/97, Loss: 0.2687
Epoch 5/10, Batch 50/97, Loss: 0.1790
Epoch 5/10, Batch 60/97, Loss: 0.3072
Epoch 5/10, Batch 70/97, Loss: 0.1582
Epoch 5/10, Batch 80/97, Loss: 0.2620
Epoch 5/10, Batch 90/97, Loss: 0.3129
Epoch 5/10, Train Loss: 0.2589, Valid Loss: 0.2557
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1557
Epoch 6/10, Batch 20/97, Loss: 0.3429
Epoch 6/10, Batch 30/97, Loss: 0.1509
Epoch 6/10, Batch 40/97, Loss: 0.2765
Epoch 6/10, Batch 50/97, Loss: 0.2695
Epoch 6/10, Batch 60/97, Loss: 0.3180
Epoch 6/10, Batch 70/97, Loss: 0.1752
Epoch 6/10, Batch 80/97, Loss: 0.2183
Epoch 6/10, Batch 90/97, Loss: 0.3953
Epoch 6/10, Train Loss: 0.2440, Valid Loss: 0.2351
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3195
Epoch 7/10, Batch 20/97, Loss: 0.2457
Epoch 7/10, Batch 30/97, Loss: 0.1481
Epoch 7/10, Batch 40/97, Loss: 0.1096
Epoch 7/10, Batch 50/97, Loss: 0.1492
Epoch 7/10, Batch 60/97, Loss: 0.1535
Epoch 7/10, Batch 70/97, Loss: 0.2772
Epoch 7/10, Batch 80/97, Loss: 0.3816
Epoch 7/10, Batch 90/97, Loss: 0.2576
Epoch 7/10, Train Loss: 0.2256, Valid Loss: 0.2294
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1940
Epoch 8/10, Batch 20/97, Loss: 0.2012
Epoch 8/10, Batch 30/97, Loss: 0.1386
Epoch 8/10, Batch 40/97, Loss: 0.2353
Epoch 8/10, Batch 50/97, Loss: 0.2993
Epoch 8/10, Batch 60/97, Loss: 0.2339
Epoch 8/10, Batch 70/97, Loss: 0.2064
Epoch 8/10, Batch 80/97, Loss: 0.2843
Epoch 8/10, Batch 90/97, Loss: 0.2908
Epoch 8/10, Train Loss: 0.2148, Valid Loss: 0.2265
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1614
Epoch 9/10, Batch 20/97, Loss: 0.1787
Epoch 9/10, Batch 30/97, Loss: 0.3276
Epoch 9/10, Batch 40/97, Loss: 0.1335
Epoch 9/10, Batch 50/97, Loss: 0.1966
Epoch 9/10, Batch 60/97, Loss: 0.1091
Epoch 9/10, Batch 70/97, Loss: 0.2755
Epoch 9/10, Batch 80/97, Loss: 0.1027
Epoch 9/10, Batch 90/97, Loss: 0.1436
Epoch 9/10, Train Loss: 0.2011, Valid Loss: 0.2214
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1873
Epoch 10/10, Batch 20/97, Loss: 0.0769
Epoch 10/10, Batch 30/97, Loss: 0.2312
Epoch 10/10, Batch 40/97, Loss: 0.1869
Epoch 10/10, Batch 50/97, Loss: 0.1814
Epoch 10/10, Batch 60/97, Loss: 0.1011
Epoch 10/10, Batch 70/97, Loss: 0.2809
Epoch 10/10, Batch 80/97, Loss: 0.1923
Epoch 10/10, Batch 90/97, Loss: 0.1947
Epoch 10/10, Train Loss: 0.2019, Valid Loss: 0.2222
Accuracy: 0.9182
Precision: 0.9159
Recall: 0.9182
F1-score: 0.9165
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2265
Epoch 1/10, Batch 20/97, Loss: 1.0295
Epoch 1/10, Batch 30/97, Loss: 0.7986
Epoch 1/10, Batch 40/97, Loss: 0.7097
Epoch 1/10, Batch 50/97, Loss: 0.6301
Epoch 1/10, Batch 60/97, Loss: 0.6992
Epoch 1/10, Batch 70/97, Loss: 0.5941
Epoch 1/10, Batch 80/97, Loss: 0.6495
Epoch 1/10, Batch 90/97, Loss: 0.5469
Epoch 1/10, Train Loss: 0.7964, Valid Loss: 0.4311
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5649
Epoch 2/10, Batch 20/97, Loss: 0.3650
Epoch 2/10, Batch 30/97, Loss: 0.4083
Epoch 2/10, Batch 40/97, Loss: 0.3808
Epoch 2/10, Batch 50/97, Loss: 0.4523
Epoch 2/10, Batch 60/97, Loss: 0.4802
Epoch 2/10, Batch 70/97, Loss: 0.2959
Epoch 2/10, Batch 80/97, Loss: 0.3502
Epoch 2/10, Batch 90/97, Loss: 0.4996
Epoch 2/10, Train Loss: 0.4142, Valid Loss: 0.3228
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3284
Epoch 3/10, Batch 20/97, Loss: 0.3201
Epoch 3/10, Batch 30/97, Loss: 0.4785
Epoch 3/10, Batch 40/97, Loss: 0.2465
Epoch 3/10, Batch 50/97, Loss: 0.4218
Epoch 3/10, Batch 60/97, Loss: 0.2666
Epoch 3/10, Batch 70/97, Loss: 0.4158
Epoch 3/10, Batch 80/97, Loss: 0.2254
Epoch 3/10, Batch 90/97, Loss: 0.2408
Epoch 3/10, Train Loss: 0.3380, Valid Loss: 0.2771
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3821
Epoch 4/10, Batch 20/97, Loss: 0.2706
Epoch 4/10, Batch 30/97, Loss: 0.1637
Epoch 4/10, Batch 40/97, Loss: 0.2338
Epoch 4/10, Batch 50/97, Loss: 0.2785
Epoch 4/10, Batch 60/97, Loss: 0.4053
Epoch 4/10, Batch 70/97, Loss: 0.2333
Epoch 4/10, Batch 80/97, Loss: 0.2107
Epoch 4/10, Batch 90/97, Loss: 0.2297
Epoch 4/10, Train Loss: 0.2890, Valid Loss: 0.2508
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2319
Epoch 5/10, Batch 20/97, Loss: 0.2536
Epoch 5/10, Batch 30/97, Loss: 0.1668
Epoch 5/10, Batch 40/97, Loss: 0.3081
Epoch 5/10, Batch 50/97, Loss: 0.2455
Epoch 5/10, Batch 60/97, Loss: 0.2192
Epoch 5/10, Batch 70/97, Loss: 0.2422
Epoch 5/10, Batch 80/97, Loss: 0.3602
Epoch 5/10, Batch 90/97, Loss: 0.2546
Epoch 5/10, Train Loss: 0.2589, Valid Loss: 0.2448
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1739
Epoch 6/10, Batch 20/97, Loss: 0.2500
Epoch 6/10, Batch 30/97, Loss: 0.3685
Epoch 6/10, Batch 40/97, Loss: 0.1989
Epoch 6/10, Batch 50/97, Loss: 0.3192
Epoch 6/10, Batch 60/97, Loss: 0.3390
Epoch 6/10, Batch 70/97, Loss: 0.2170
Epoch 6/10, Batch 80/97, Loss: 0.3013
Epoch 6/10, Batch 90/97, Loss: 0.2656
Epoch 6/10, Train Loss: 0.2461, Valid Loss: 0.2349
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1539
Epoch 7/10, Batch 20/97, Loss: 0.2189
Epoch 7/10, Batch 30/97, Loss: 0.2078
Epoch 7/10, Batch 40/97, Loss: 0.1368
Epoch 7/10, Batch 50/97, Loss: 0.2219
Epoch 7/10, Batch 60/97, Loss: 0.2889
Epoch 7/10, Batch 70/97, Loss: 0.2522
Epoch 7/10, Batch 80/97, Loss: 0.2850
Epoch 7/10, Batch 90/97, Loss: 0.3042
Epoch 7/10, Train Loss: 0.2274, Valid Loss: 0.2279
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1473
Epoch 8/10, Batch 20/97, Loss: 0.2532
Epoch 8/10, Batch 30/97, Loss: 0.2124
Epoch 8/10, Batch 40/97, Loss: 0.2775
Epoch 8/10, Batch 50/97, Loss: 0.2052
Epoch 8/10, Batch 60/97, Loss: 0.1419
Epoch 8/10, Batch 70/97, Loss: 0.2489
Epoch 8/10, Batch 80/97, Loss: 0.2526
Epoch 8/10, Batch 90/97, Loss: 0.2695
Epoch 8/10, Train Loss: 0.2179, Valid Loss: 0.2259
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1180
Epoch 9/10, Batch 20/97, Loss: 0.2676
Epoch 9/10, Batch 30/97, Loss: 0.2305
Epoch 9/10, Batch 40/97, Loss: 0.2761
Epoch 9/10, Batch 50/97, Loss: 0.0754
Epoch 9/10, Batch 60/97, Loss: 0.1630
Epoch 9/10, Batch 70/97, Loss: 0.0966
Epoch 9/10, Batch 80/97, Loss: 0.1084
Epoch 9/10, Batch 90/97, Loss: 0.2156
Epoch 9/10, Train Loss: 0.2049, Valid Loss: 0.2192
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2519
Epoch 10/10, Batch 20/97, Loss: 0.1247
Epoch 10/10, Batch 30/97, Loss: 0.0824
Epoch 10/10, Batch 40/97, Loss: 0.1969
Epoch 10/10, Batch 50/97, Loss: 0.1485
Epoch 10/10, Batch 60/97, Loss: 0.0866
Epoch 10/10, Batch 70/97, Loss: 0.1266
Epoch 10/10, Batch 80/97, Loss: 0.1580
Epoch 10/10, Batch 90/97, Loss: 0.1381
Epoch 10/10, Train Loss: 0.1931, Valid Loss: 0.2132
Model saved!
Accuracy: 0.9112
Precision: 0.9094
Recall: 0.9112
F1-score: 0.9089
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2638
Epoch 1/10, Batch 20/97, Loss: 1.1347
Epoch 1/10, Batch 30/97, Loss: 0.6793
Epoch 1/10, Batch 40/97, Loss: 0.8153
Epoch 1/10, Batch 50/97, Loss: 0.5903
Epoch 1/10, Batch 60/97, Loss: 0.7257
Epoch 1/10, Batch 70/97, Loss: 0.6784
Epoch 1/10, Batch 80/97, Loss: 0.5897
Epoch 1/10, Batch 90/97, Loss: 0.5860
Epoch 1/10, Train Loss: 0.8128, Valid Loss: 0.4568
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4931
Epoch 2/10, Batch 20/97, Loss: 0.5504
Epoch 2/10, Batch 30/97, Loss: 0.4046
Epoch 2/10, Batch 40/97, Loss: 0.6352
Epoch 2/10, Batch 50/97, Loss: 0.5811
Epoch 2/10, Batch 60/97, Loss: 0.4647
Epoch 2/10, Batch 70/97, Loss: 0.2706
Epoch 2/10, Batch 80/97, Loss: 0.4492
Epoch 2/10, Batch 90/97, Loss: 0.3389
Epoch 2/10, Train Loss: 0.4255, Valid Loss: 0.3503
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4288
Epoch 3/10, Batch 20/97, Loss: 0.2225
Epoch 3/10, Batch 30/97, Loss: 0.3361
Epoch 3/10, Batch 40/97, Loss: 0.3501
Epoch 3/10, Batch 50/97, Loss: 0.3196
Epoch 3/10, Batch 60/97, Loss: 0.2031
Epoch 3/10, Batch 70/97, Loss: 0.2661
Epoch 3/10, Batch 80/97, Loss: 0.3649
Epoch 3/10, Batch 90/97, Loss: 0.2583
Epoch 3/10, Train Loss: 0.3402, Valid Loss: 0.3025
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3720
Epoch 4/10, Batch 20/97, Loss: 0.2429
Epoch 4/10, Batch 30/97, Loss: 0.2843
Epoch 4/10, Batch 40/97, Loss: 0.1668
Epoch 4/10, Batch 50/97, Loss: 0.3637
Epoch 4/10, Batch 60/97, Loss: 0.2677
Epoch 4/10, Batch 70/97, Loss: 0.2461
Epoch 4/10, Batch 80/97, Loss: 0.2625
Epoch 4/10, Batch 90/97, Loss: 0.1869
Epoch 4/10, Train Loss: 0.2877, Valid Loss: 0.2888
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2638
Epoch 5/10, Batch 20/97, Loss: 0.4432
Epoch 5/10, Batch 30/97, Loss: 0.2818
Epoch 5/10, Batch 40/97, Loss: 0.2231
Epoch 5/10, Batch 50/97, Loss: 0.1573
Epoch 5/10, Batch 60/97, Loss: 0.1785
Epoch 5/10, Batch 70/97, Loss: 0.2244
Epoch 5/10, Batch 80/97, Loss: 0.2075
Epoch 5/10, Batch 90/97, Loss: 0.2494
Epoch 5/10, Train Loss: 0.2679, Valid Loss: 0.2727
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2090
Epoch 6/10, Batch 20/97, Loss: 0.2208
Epoch 6/10, Batch 30/97, Loss: 0.1726
Epoch 6/10, Batch 40/97, Loss: 0.1893
Epoch 6/10, Batch 50/97, Loss: 0.2357
Epoch 6/10, Batch 60/97, Loss: 0.2750
Epoch 6/10, Batch 70/97, Loss: 0.1284
Epoch 6/10, Batch 80/97, Loss: 0.2219
Epoch 6/10, Batch 90/97, Loss: 0.2969
Epoch 6/10, Train Loss: 0.2429, Valid Loss: 0.2590
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1181
Epoch 7/10, Batch 20/97, Loss: 0.2023
Epoch 7/10, Batch 30/97, Loss: 0.2225
Epoch 7/10, Batch 40/97, Loss: 0.2180
Epoch 7/10, Batch 50/97, Loss: 0.1608
Epoch 7/10, Batch 60/97, Loss: 0.1432
Epoch 7/10, Batch 70/97, Loss: 0.2133
Epoch 7/10, Batch 80/97, Loss: 0.1982
Epoch 7/10, Batch 90/97, Loss: 0.2049
Epoch 7/10, Train Loss: 0.2270, Valid Loss: 0.2568
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2525
Epoch 8/10, Batch 20/97, Loss: 0.1614
Epoch 8/10, Batch 30/97, Loss: 0.2930
Epoch 8/10, Batch 40/97, Loss: 0.2300
Epoch 8/10, Batch 50/97, Loss: 0.1468
Epoch 8/10, Batch 60/97, Loss: 0.2071
Epoch 8/10, Batch 70/97, Loss: 0.2881
Epoch 8/10, Batch 80/97, Loss: 0.3387
Epoch 8/10, Batch 90/97, Loss: 0.2587
Epoch 8/10, Train Loss: 0.2246, Valid Loss: 0.2541
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1623
Epoch 9/10, Batch 20/97, Loss: 0.1633
Epoch 9/10, Batch 30/97, Loss: 0.2955
Epoch 9/10, Batch 40/97, Loss: 0.2095
Epoch 9/10, Batch 50/97, Loss: 0.1978
Epoch 9/10, Batch 60/97, Loss: 0.1550
Epoch 9/10, Batch 70/97, Loss: 0.0799
Epoch 9/10, Batch 80/97, Loss: 0.0662
Epoch 9/10, Batch 90/97, Loss: 0.2087
Epoch 9/10, Train Loss: 0.2100, Valid Loss: 0.2488
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1712
Epoch 10/10, Batch 20/97, Loss: 0.1815
Epoch 10/10, Batch 30/97, Loss: 0.2270
Epoch 10/10, Batch 40/97, Loss: 0.0962
Epoch 10/10, Batch 50/97, Loss: 0.1493
Epoch 10/10, Batch 60/97, Loss: 0.1374
Epoch 10/10, Batch 70/97, Loss: 0.1370
Epoch 10/10, Batch 80/97, Loss: 0.1832
Epoch 10/10, Batch 90/97, Loss: 0.1454
Epoch 10/10, Train Loss: 0.1987, Valid Loss: 0.2553
Accuracy: 0.9065
Precision: 0.9045
Recall: 0.9065
F1-score: 0.9044
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2588
Epoch 1/10, Batch 20/97, Loss: 1.1208
Epoch 1/10, Batch 30/97, Loss: 0.7883
Epoch 1/10, Batch 40/97, Loss: 0.6483
Epoch 1/10, Batch 50/97, Loss: 0.5622
Epoch 1/10, Batch 60/97, Loss: 0.6698
Epoch 1/10, Batch 70/97, Loss: 0.7006
Epoch 1/10, Batch 80/97, Loss: 0.5668
Epoch 1/10, Batch 90/97, Loss: 0.5865
Epoch 1/10, Train Loss: 0.8014, Valid Loss: 0.4412
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5601
Epoch 2/10, Batch 20/97, Loss: 0.4971
Epoch 2/10, Batch 30/97, Loss: 0.4901
Epoch 2/10, Batch 40/97, Loss: 0.3436
Epoch 2/10, Batch 50/97, Loss: 0.3612
Epoch 2/10, Batch 60/97, Loss: 0.4839
Epoch 2/10, Batch 70/97, Loss: 0.4402
Epoch 2/10, Batch 80/97, Loss: 0.4113
Epoch 2/10, Batch 90/97, Loss: 0.5551
Epoch 2/10, Train Loss: 0.4169, Valid Loss: 0.3245
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3499
Epoch 3/10, Batch 20/97, Loss: 0.4069
Epoch 3/10, Batch 30/97, Loss: 0.4063
Epoch 3/10, Batch 40/97, Loss: 0.3484
Epoch 3/10, Batch 50/97, Loss: 0.3302
Epoch 3/10, Batch 60/97, Loss: 0.2102
Epoch 3/10, Batch 70/97, Loss: 0.4893
Epoch 3/10, Batch 80/97, Loss: 0.3797
Epoch 3/10, Batch 90/97, Loss: 0.3403
Epoch 3/10, Train Loss: 0.3410, Valid Loss: 0.2855
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4107
Epoch 4/10, Batch 20/97, Loss: 0.2429
Epoch 4/10, Batch 30/97, Loss: 0.1627
Epoch 4/10, Batch 40/97, Loss: 0.2178
Epoch 4/10, Batch 50/97, Loss: 0.2365
Epoch 4/10, Batch 60/97, Loss: 0.1321
Epoch 4/10, Batch 70/97, Loss: 0.2290
Epoch 4/10, Batch 80/97, Loss: 0.1983
Epoch 4/10, Batch 90/97, Loss: 0.3282
Epoch 4/10, Train Loss: 0.2953, Valid Loss: 0.2707
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2256
Epoch 5/10, Batch 20/97, Loss: 0.3482
Epoch 5/10, Batch 30/97, Loss: 0.2140
Epoch 5/10, Batch 40/97, Loss: 0.2707
Epoch 5/10, Batch 50/97, Loss: 0.2650
Epoch 5/10, Batch 60/97, Loss: 0.2232
Epoch 5/10, Batch 70/97, Loss: 0.2386
Epoch 5/10, Batch 80/97, Loss: 0.2279
Epoch 5/10, Batch 90/97, Loss: 0.1950
Epoch 5/10, Train Loss: 0.2691, Valid Loss: 0.2452
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2549
Epoch 6/10, Batch 20/97, Loss: 0.3347
Epoch 6/10, Batch 30/97, Loss: 0.1029
Epoch 6/10, Batch 40/97, Loss: 0.1591
Epoch 6/10, Batch 50/97, Loss: 0.2395
Epoch 6/10, Batch 60/97, Loss: 0.2259
Epoch 6/10, Batch 70/97, Loss: 0.2710
Epoch 6/10, Batch 80/97, Loss: 0.3748
Epoch 6/10, Batch 90/97, Loss: 0.3087
Epoch 6/10, Train Loss: 0.2482, Valid Loss: 0.2379
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2076
Epoch 7/10, Batch 20/97, Loss: 0.4828
Epoch 7/10, Batch 30/97, Loss: 0.1369
Epoch 7/10, Batch 40/97, Loss: 0.1362
Epoch 7/10, Batch 50/97, Loss: 0.2201
Epoch 7/10, Batch 60/97, Loss: 0.1334
Epoch 7/10, Batch 70/97, Loss: 0.2251
Epoch 7/10, Batch 80/97, Loss: 0.2942
Epoch 7/10, Batch 90/97, Loss: 0.1572
Epoch 7/10, Train Loss: 0.2375, Valid Loss: 0.2296
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2759
Epoch 8/10, Batch 20/97, Loss: 0.2726
Epoch 8/10, Batch 30/97, Loss: 0.0780
Epoch 8/10, Batch 40/97, Loss: 0.2822
Epoch 8/10, Batch 50/97, Loss: 0.3228
Epoch 8/10, Batch 60/97, Loss: 0.2257
Epoch 8/10, Batch 70/97, Loss: 0.2190
Epoch 8/10, Batch 80/97, Loss: 0.1332
Epoch 8/10, Batch 90/97, Loss: 0.1281
Epoch 8/10, Train Loss: 0.2281, Valid Loss: 0.2326
Epoch 9/10, Batch 10/97, Loss: 0.1725
Epoch 9/10, Batch 20/97, Loss: 0.1818
Epoch 9/10, Batch 30/97, Loss: 0.1599
Epoch 9/10, Batch 40/97, Loss: 0.3215
Epoch 9/10, Batch 50/97, Loss: 0.1600
Epoch 9/10, Batch 60/97, Loss: 0.1940
Epoch 9/10, Batch 70/97, Loss: 0.1617
Epoch 9/10, Batch 80/97, Loss: 0.2067
Epoch 9/10, Batch 90/97, Loss: 0.1818
Epoch 9/10, Train Loss: 0.2141, Valid Loss: 0.2151
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2462
Epoch 10/10, Batch 20/97, Loss: 0.2526
Epoch 10/10, Batch 30/97, Loss: 0.1469
Epoch 10/10, Batch 40/97, Loss: 0.1595
Epoch 10/10, Batch 50/97, Loss: 0.2248
Epoch 10/10, Batch 60/97, Loss: 0.1158
Epoch 10/10, Batch 70/97, Loss: 0.3083
Epoch 10/10, Batch 80/97, Loss: 0.1526
Epoch 10/10, Batch 90/97, Loss: 0.1818
Epoch 10/10, Train Loss: 0.2075, Valid Loss: 0.2161
Accuracy: 0.9159
Precision: 0.9139
Recall: 0.9159
F1-score: 0.9137
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2641
Epoch 1/10, Batch 20/97, Loss: 1.0682
Epoch 1/10, Batch 30/97, Loss: 0.8268
Epoch 1/10, Batch 40/97, Loss: 0.7102
Epoch 1/10, Batch 50/97, Loss: 0.6009
Epoch 1/10, Batch 60/97, Loss: 0.6102
Epoch 1/10, Batch 70/97, Loss: 0.6666
Epoch 1/10, Batch 80/97, Loss: 0.5888
Epoch 1/10, Batch 90/97, Loss: 0.5386
Epoch 1/10, Train Loss: 0.8059, Valid Loss: 0.4501
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3241
Epoch 2/10, Batch 20/97, Loss: 0.4114
Epoch 2/10, Batch 30/97, Loss: 0.6252
Epoch 2/10, Batch 40/97, Loss: 0.4151
Epoch 2/10, Batch 50/97, Loss: 0.3289
Epoch 2/10, Batch 60/97, Loss: 0.3976
Epoch 2/10, Batch 70/97, Loss: 0.5264
Epoch 2/10, Batch 80/97, Loss: 0.3326
Epoch 2/10, Batch 90/97, Loss: 0.3222
Epoch 2/10, Train Loss: 0.4140, Valid Loss: 0.3382
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2127
Epoch 3/10, Batch 20/97, Loss: 0.2985
Epoch 3/10, Batch 30/97, Loss: 0.3805
Epoch 3/10, Batch 40/97, Loss: 0.2497
Epoch 3/10, Batch 50/97, Loss: 0.4118
Epoch 3/10, Batch 60/97, Loss: 0.2008
Epoch 3/10, Batch 70/97, Loss: 0.3593
Epoch 3/10, Batch 80/97, Loss: 0.2537
Epoch 3/10, Batch 90/97, Loss: 0.2549
Epoch 3/10, Train Loss: 0.3334, Valid Loss: 0.2978
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3297
Epoch 4/10, Batch 20/97, Loss: 0.1884
Epoch 4/10, Batch 30/97, Loss: 0.4053
Epoch 4/10, Batch 40/97, Loss: 0.4264
Epoch 4/10, Batch 50/97, Loss: 0.4297
Epoch 4/10, Batch 60/97, Loss: 0.2661
Epoch 4/10, Batch 70/97, Loss: 0.2468
Epoch 4/10, Batch 80/97, Loss: 0.2516
Epoch 4/10, Batch 90/97, Loss: 0.3902
Epoch 4/10, Train Loss: 0.2883, Valid Loss: 0.2755
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2290
Epoch 5/10, Batch 20/97, Loss: 0.2783
Epoch 5/10, Batch 30/97, Loss: 0.2038
Epoch 5/10, Batch 40/97, Loss: 0.1972
Epoch 5/10, Batch 50/97, Loss: 0.2188
Epoch 5/10, Batch 60/97, Loss: 0.3455
Epoch 5/10, Batch 70/97, Loss: 0.3152
Epoch 5/10, Batch 80/97, Loss: 0.2095
Epoch 5/10, Batch 90/97, Loss: 0.2265
Epoch 5/10, Train Loss: 0.2644, Valid Loss: 0.2593
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1510
Epoch 6/10, Batch 20/97, Loss: 0.3075
Epoch 6/10, Batch 30/97, Loss: 0.2208
Epoch 6/10, Batch 40/97, Loss: 0.1745
Epoch 6/10, Batch 50/97, Loss: 0.3394
Epoch 6/10, Batch 60/97, Loss: 0.2957
Epoch 6/10, Batch 70/97, Loss: 0.2332
Epoch 6/10, Batch 80/97, Loss: 0.2340
Epoch 6/10, Batch 90/97, Loss: 0.2590
Epoch 6/10, Train Loss: 0.2452, Valid Loss: 0.2463
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1241
Epoch 7/10, Batch 20/97, Loss: 0.2838
Epoch 7/10, Batch 30/97, Loss: 0.2617
Epoch 7/10, Batch 40/97, Loss: 0.1483
Epoch 7/10, Batch 50/97, Loss: 0.1989
Epoch 7/10, Batch 60/97, Loss: 0.1114
Epoch 7/10, Batch 70/97, Loss: 0.3057
Epoch 7/10, Batch 80/97, Loss: 0.2906
Epoch 7/10, Batch 90/97, Loss: 0.2404
Epoch 7/10, Train Loss: 0.2299, Valid Loss: 0.2365
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1741
Epoch 8/10, Batch 20/97, Loss: 0.2844
Epoch 8/10, Batch 30/97, Loss: 0.1231
Epoch 8/10, Batch 40/97, Loss: 0.2668
Epoch 8/10, Batch 50/97, Loss: 0.1583
Epoch 8/10, Batch 60/97, Loss: 0.1515
Epoch 8/10, Batch 70/97, Loss: 0.4196
Epoch 8/10, Batch 80/97, Loss: 0.1731
Epoch 8/10, Batch 90/97, Loss: 0.2968
Epoch 8/10, Train Loss: 0.2181, Valid Loss: 0.2346
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2591
Epoch 9/10, Batch 20/97, Loss: 0.1238
Epoch 9/10, Batch 30/97, Loss: 0.1449
Epoch 9/10, Batch 40/97, Loss: 0.2947
Epoch 9/10, Batch 50/97, Loss: 0.1873
Epoch 9/10, Batch 60/97, Loss: 0.3327
Epoch 9/10, Batch 70/97, Loss: 0.1924
Epoch 9/10, Batch 80/97, Loss: 0.1542
Epoch 9/10, Batch 90/97, Loss: 0.2291
Epoch 9/10, Train Loss: 0.2039, Valid Loss: 0.2310
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1460
Epoch 10/10, Batch 20/97, Loss: 0.1459
Epoch 10/10, Batch 30/97, Loss: 0.1247
Epoch 10/10, Batch 40/97, Loss: 0.1496
Epoch 10/10, Batch 50/97, Loss: 0.1813
Epoch 10/10, Batch 60/97, Loss: 0.1757
Epoch 10/10, Batch 70/97, Loss: 0.1158
Epoch 10/10, Batch 80/97, Loss: 0.1323
Epoch 10/10, Batch 90/97, Loss: 0.1656
Epoch 10/10, Train Loss: 0.2024, Valid Loss: 0.2278
Model saved!
Accuracy: 0.9100
Precision: 0.9073
Recall: 0.9100
F1-score: 0.9075
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2298
Epoch 1/10, Batch 20/97, Loss: 1.0830
Epoch 1/10, Batch 30/97, Loss: 0.7424
Epoch 1/10, Batch 40/97, Loss: 0.6663
Epoch 1/10, Batch 50/97, Loss: 0.6752
Epoch 1/10, Batch 60/97, Loss: 0.6941
Epoch 1/10, Batch 70/97, Loss: 0.7116
Epoch 1/10, Batch 80/97, Loss: 0.6013
Epoch 1/10, Batch 90/97, Loss: 0.5707
Epoch 1/10, Train Loss: 0.8053, Valid Loss: 0.4349
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5348
Epoch 2/10, Batch 20/97, Loss: 0.5113
Epoch 2/10, Batch 30/97, Loss: 0.4514
Epoch 2/10, Batch 40/97, Loss: 0.4004
Epoch 2/10, Batch 50/97, Loss: 0.5107
Epoch 2/10, Batch 60/97, Loss: 0.3802
Epoch 2/10, Batch 70/97, Loss: 0.3357
Epoch 2/10, Batch 80/97, Loss: 0.3682
Epoch 2/10, Batch 90/97, Loss: 0.6005
Epoch 2/10, Train Loss: 0.4199, Valid Loss: 0.3227
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3739
Epoch 3/10, Batch 20/97, Loss: 0.2832
Epoch 3/10, Batch 30/97, Loss: 0.2965
Epoch 3/10, Batch 40/97, Loss: 0.2010
Epoch 3/10, Batch 50/97, Loss: 0.4161
Epoch 3/10, Batch 60/97, Loss: 0.2544
Epoch 3/10, Batch 70/97, Loss: 0.3410
Epoch 3/10, Batch 80/97, Loss: 0.3075
Epoch 3/10, Batch 90/97, Loss: 0.2121
Epoch 3/10, Train Loss: 0.3386, Valid Loss: 0.2784
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2888
Epoch 4/10, Batch 20/97, Loss: 0.1798
Epoch 4/10, Batch 30/97, Loss: 0.1758
Epoch 4/10, Batch 40/97, Loss: 0.4549
Epoch 4/10, Batch 50/97, Loss: 0.3084
Epoch 4/10, Batch 60/97, Loss: 0.3284
Epoch 4/10, Batch 70/97, Loss: 0.3156
Epoch 4/10, Batch 80/97, Loss: 0.1726
Epoch 4/10, Batch 90/97, Loss: 0.1453
Epoch 4/10, Train Loss: 0.2906, Valid Loss: 0.2616
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2056
Epoch 5/10, Batch 20/97, Loss: 0.3857
Epoch 5/10, Batch 30/97, Loss: 0.2085
Epoch 5/10, Batch 40/97, Loss: 0.1874
Epoch 5/10, Batch 50/97, Loss: 0.1792
Epoch 5/10, Batch 60/97, Loss: 0.2303
Epoch 5/10, Batch 70/97, Loss: 0.1598
Epoch 5/10, Batch 80/97, Loss: 0.2493
Epoch 5/10, Batch 90/97, Loss: 0.1739
Epoch 5/10, Train Loss: 0.2616, Valid Loss: 0.2505
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.0851
Epoch 6/10, Batch 20/97, Loss: 0.2561
Epoch 6/10, Batch 30/97, Loss: 0.1291
Epoch 6/10, Batch 40/97, Loss: 0.2777
Epoch 6/10, Batch 50/97, Loss: 0.2139
Epoch 6/10, Batch 60/97, Loss: 0.2668
Epoch 6/10, Batch 70/97, Loss: 0.2538
Epoch 6/10, Batch 80/97, Loss: 0.3699
Epoch 6/10, Batch 90/97, Loss: 0.3799
Epoch 6/10, Train Loss: 0.2450, Valid Loss: 0.2305
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1464
Epoch 7/10, Batch 20/97, Loss: 0.2233
Epoch 7/10, Batch 30/97, Loss: 0.1535
Epoch 7/10, Batch 40/97, Loss: 0.1955
Epoch 7/10, Batch 50/97, Loss: 0.2976
Epoch 7/10, Batch 60/97, Loss: 0.1404
Epoch 7/10, Batch 70/97, Loss: 0.1958
Epoch 7/10, Batch 80/97, Loss: 0.2308
Epoch 7/10, Batch 90/97, Loss: 0.1931
Epoch 7/10, Train Loss: 0.2320, Valid Loss: 0.2235
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2425
Epoch 8/10, Batch 20/97, Loss: 0.2635
Epoch 8/10, Batch 30/97, Loss: 0.2212
Epoch 8/10, Batch 40/97, Loss: 0.1134
Epoch 8/10, Batch 50/97, Loss: 0.2792
Epoch 8/10, Batch 60/97, Loss: 0.1369
Epoch 8/10, Batch 70/97, Loss: 0.1616
Epoch 8/10, Batch 80/97, Loss: 0.1658
Epoch 8/10, Batch 90/97, Loss: 0.3318
Epoch 8/10, Train Loss: 0.2234, Valid Loss: 0.2259
Epoch 9/10, Batch 10/97, Loss: 0.2084
Epoch 9/10, Batch 20/97, Loss: 0.1059
Epoch 9/10, Batch 30/97, Loss: 0.1746
Epoch 9/10, Batch 40/97, Loss: 0.2175
Epoch 9/10, Batch 50/97, Loss: 0.1942
Epoch 9/10, Batch 60/97, Loss: 0.1959
Epoch 9/10, Batch 70/97, Loss: 0.2907
Epoch 9/10, Batch 80/97, Loss: 0.1823
Epoch 9/10, Batch 90/97, Loss: 0.1295
Epoch 9/10, Train Loss: 0.2052, Valid Loss: 0.2093
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2684
Epoch 10/10, Batch 20/97, Loss: 0.0994
Epoch 10/10, Batch 30/97, Loss: 0.3821
Epoch 10/10, Batch 40/97, Loss: 0.0968
Epoch 10/10, Batch 50/97, Loss: 0.2130
Epoch 10/10, Batch 60/97, Loss: 0.1288
Epoch 10/10, Batch 70/97, Loss: 0.1272
Epoch 10/10, Batch 80/97, Loss: 0.1667
Epoch 10/10, Batch 90/97, Loss: 0.3503
Epoch 10/10, Train Loss: 0.2034, Valid Loss: 0.2208
Accuracy: 0.9229
Precision: 0.9212
Recall: 0.9229
F1-score: 0.9213
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2859
Epoch 1/10, Batch 20/97, Loss: 1.0834
Epoch 1/10, Batch 30/97, Loss: 0.7745
Epoch 1/10, Batch 40/97, Loss: 0.6305
Epoch 1/10, Batch 50/97, Loss: 0.5469
Epoch 1/10, Batch 60/97, Loss: 0.7316
Epoch 1/10, Batch 70/97, Loss: 0.7550
Epoch 1/10, Batch 80/97, Loss: 0.5763
Epoch 1/10, Batch 90/97, Loss: 0.6735
Epoch 1/10, Train Loss: 0.8107, Valid Loss: 0.4414
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4732
Epoch 2/10, Batch 20/97, Loss: 0.3828
Epoch 2/10, Batch 30/97, Loss: 0.3471
Epoch 2/10, Batch 40/97, Loss: 0.4724
Epoch 2/10, Batch 50/97, Loss: 0.3057
Epoch 2/10, Batch 60/97, Loss: 0.2994
Epoch 2/10, Batch 70/97, Loss: 0.3510
Epoch 2/10, Batch 80/97, Loss: 0.4479
Epoch 2/10, Batch 90/97, Loss: 0.4875
Epoch 2/10, Train Loss: 0.4170, Valid Loss: 0.3270
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4680
Epoch 3/10, Batch 20/97, Loss: 0.2272
Epoch 3/10, Batch 30/97, Loss: 0.5194
Epoch 3/10, Batch 40/97, Loss: 0.3188
Epoch 3/10, Batch 50/97, Loss: 0.5140
Epoch 3/10, Batch 60/97, Loss: 0.2722
Epoch 3/10, Batch 70/97, Loss: 0.4010
Epoch 3/10, Batch 80/97, Loss: 0.3986
Epoch 3/10, Batch 90/97, Loss: 0.3333
Epoch 3/10, Train Loss: 0.3388, Valid Loss: 0.2884
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3224
Epoch 4/10, Batch 20/97, Loss: 0.2779
Epoch 4/10, Batch 30/97, Loss: 0.2427
Epoch 4/10, Batch 40/97, Loss: 0.2154
Epoch 4/10, Batch 50/97, Loss: 0.2402
Epoch 4/10, Batch 60/97, Loss: 0.2408
Epoch 4/10, Batch 70/97, Loss: 0.2509
Epoch 4/10, Batch 80/97, Loss: 0.3174
Epoch 4/10, Batch 90/97, Loss: 0.2248
Epoch 4/10, Train Loss: 0.2873, Valid Loss: 0.2705
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2463
Epoch 5/10, Batch 20/97, Loss: 0.3225
Epoch 5/10, Batch 30/97, Loss: 0.2433
Epoch 5/10, Batch 40/97, Loss: 0.3065
Epoch 5/10, Batch 50/97, Loss: 0.2198
Epoch 5/10, Batch 60/97, Loss: 0.2486
Epoch 5/10, Batch 70/97, Loss: 0.2698
Epoch 5/10, Batch 80/97, Loss: 0.1827
Epoch 5/10, Batch 90/97, Loss: 0.2703
Epoch 5/10, Train Loss: 0.2686, Valid Loss: 0.2542
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2239
Epoch 6/10, Batch 20/97, Loss: 0.2626
Epoch 6/10, Batch 30/97, Loss: 0.1883
Epoch 6/10, Batch 40/97, Loss: 0.2674
Epoch 6/10, Batch 50/97, Loss: 0.3498
Epoch 6/10, Batch 60/97, Loss: 0.3803
Epoch 6/10, Batch 70/97, Loss: 0.3280
Epoch 6/10, Batch 80/97, Loss: 0.3069
Epoch 6/10, Batch 90/97, Loss: 0.5332
Epoch 6/10, Train Loss: 0.2529, Valid Loss: 0.2491
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4201
Epoch 7/10, Batch 20/97, Loss: 0.2418
Epoch 7/10, Batch 30/97, Loss: 0.2407
Epoch 7/10, Batch 40/97, Loss: 0.2230
Epoch 7/10, Batch 50/97, Loss: 0.3009
Epoch 7/10, Batch 60/97, Loss: 0.1178
Epoch 7/10, Batch 70/97, Loss: 0.1618
Epoch 7/10, Batch 80/97, Loss: 0.1976
Epoch 7/10, Batch 90/97, Loss: 0.1998
Epoch 7/10, Train Loss: 0.2263, Valid Loss: 0.2478
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2242
Epoch 8/10, Batch 20/97, Loss: 0.1150
Epoch 8/10, Batch 30/97, Loss: 0.2420
Epoch 8/10, Batch 40/97, Loss: 0.3085
Epoch 8/10, Batch 50/97, Loss: 0.2258
Epoch 8/10, Batch 60/97, Loss: 0.2411
Epoch 8/10, Batch 70/97, Loss: 0.1565
Epoch 8/10, Batch 80/97, Loss: 0.1882
Epoch 8/10, Batch 90/97, Loss: 0.2426
Epoch 8/10, Train Loss: 0.2131, Valid Loss: 0.2379
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0923
Epoch 9/10, Batch 20/97, Loss: 0.1121
Epoch 9/10, Batch 30/97, Loss: 0.2630
Epoch 9/10, Batch 40/97, Loss: 0.3368
Epoch 9/10, Batch 50/97, Loss: 0.1804
Epoch 9/10, Batch 60/97, Loss: 0.2723
Epoch 9/10, Batch 70/97, Loss: 0.1873
Epoch 9/10, Batch 80/97, Loss: 0.2616
Epoch 9/10, Batch 90/97, Loss: 0.1843
Epoch 9/10, Train Loss: 0.2110, Valid Loss: 0.2371
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2123
Epoch 10/10, Batch 20/97, Loss: 0.0752
Epoch 10/10, Batch 30/97, Loss: 0.2967
Epoch 10/10, Batch 40/97, Loss: 0.1793
Epoch 10/10, Batch 50/97, Loss: 0.1250
Epoch 10/10, Batch 60/97, Loss: 0.1561
Epoch 10/10, Batch 70/97, Loss: 0.1711
Epoch 10/10, Batch 80/97, Loss: 0.2008
Epoch 10/10, Batch 90/97, Loss: 0.1349
Epoch 10/10, Train Loss: 0.2045, Valid Loss: 0.2394
Accuracy: 0.9206
Precision: 0.9177
Recall: 0.9206
F1-score: 0.9186
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2518
Epoch 1/10, Batch 20/97, Loss: 0.9943
Epoch 1/10, Batch 30/97, Loss: 0.7873
Epoch 1/10, Batch 40/97, Loss: 0.7330
Epoch 1/10, Batch 50/97, Loss: 0.6847
Epoch 1/10, Batch 60/97, Loss: 0.7352
Epoch 1/10, Batch 70/97, Loss: 0.6597
Epoch 1/10, Batch 80/97, Loss: 0.7649
Epoch 1/10, Batch 90/97, Loss: 0.5232
Epoch 1/10, Train Loss: 0.7965, Valid Loss: 0.4459
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5052
Epoch 2/10, Batch 20/97, Loss: 0.4575
Epoch 2/10, Batch 30/97, Loss: 0.5256
Epoch 2/10, Batch 40/97, Loss: 0.3833
Epoch 2/10, Batch 50/97, Loss: 0.4828
Epoch 2/10, Batch 60/97, Loss: 0.4772
Epoch 2/10, Batch 70/97, Loss: 0.3518
Epoch 2/10, Batch 80/97, Loss: 0.2762
Epoch 2/10, Batch 90/97, Loss: 0.4568
Epoch 2/10, Train Loss: 0.4090, Valid Loss: 0.3474
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3992
Epoch 3/10, Batch 20/97, Loss: 0.3026
Epoch 3/10, Batch 30/97, Loss: 0.3956
Epoch 3/10, Batch 40/97, Loss: 0.2834
Epoch 3/10, Batch 50/97, Loss: 0.5012
Epoch 3/10, Batch 60/97, Loss: 0.2843
Epoch 3/10, Batch 70/97, Loss: 0.2304
Epoch 3/10, Batch 80/97, Loss: 0.2552
Epoch 3/10, Batch 90/97, Loss: 0.2532
Epoch 3/10, Train Loss: 0.3271, Valid Loss: 0.3075
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3325
Epoch 4/10, Batch 20/97, Loss: 0.3226
Epoch 4/10, Batch 30/97, Loss: 0.2513
Epoch 4/10, Batch 40/97, Loss: 0.2220
Epoch 4/10, Batch 50/97, Loss: 0.3699
Epoch 4/10, Batch 60/97, Loss: 0.2308
Epoch 4/10, Batch 70/97, Loss: 0.3064
Epoch 4/10, Batch 80/97, Loss: 0.3017
Epoch 4/10, Batch 90/97, Loss: 0.4277
Epoch 4/10, Train Loss: 0.2845, Valid Loss: 0.2958
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2596
Epoch 5/10, Batch 20/97, Loss: 0.3459
Epoch 5/10, Batch 30/97, Loss: 0.1737
Epoch 5/10, Batch 40/97, Loss: 0.3136
Epoch 5/10, Batch 50/97, Loss: 0.1977
Epoch 5/10, Batch 60/97, Loss: 0.2628
Epoch 5/10, Batch 70/97, Loss: 0.3316
Epoch 5/10, Batch 80/97, Loss: 0.2067
Epoch 5/10, Batch 90/97, Loss: 0.2523
Epoch 5/10, Train Loss: 0.2607, Valid Loss: 0.2867
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1875
Epoch 6/10, Batch 20/97, Loss: 0.2654
Epoch 6/10, Batch 30/97, Loss: 0.2042
Epoch 6/10, Batch 40/97, Loss: 0.1634
Epoch 6/10, Batch 50/97, Loss: 0.3818
Epoch 6/10, Batch 60/97, Loss: 0.2362
Epoch 6/10, Batch 70/97, Loss: 0.2144
Epoch 6/10, Batch 80/97, Loss: 0.2585
Epoch 6/10, Batch 90/97, Loss: 0.3276
Epoch 6/10, Train Loss: 0.2458, Valid Loss: 0.2702
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1465
Epoch 7/10, Batch 20/97, Loss: 0.2464
Epoch 7/10, Batch 30/97, Loss: 0.2046
Epoch 7/10, Batch 40/97, Loss: 0.0747
Epoch 7/10, Batch 50/97, Loss: 0.1576
Epoch 7/10, Batch 60/97, Loss: 0.1723
Epoch 7/10, Batch 70/97, Loss: 0.2641
Epoch 7/10, Batch 80/97, Loss: 0.1665
Epoch 7/10, Batch 90/97, Loss: 0.1898
Epoch 7/10, Train Loss: 0.2229, Valid Loss: 0.2644
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2166
Epoch 8/10, Batch 20/97, Loss: 0.3116
Epoch 8/10, Batch 30/97, Loss: 0.1883
Epoch 8/10, Batch 40/97, Loss: 0.1554
Epoch 8/10, Batch 50/97, Loss: 0.3582
Epoch 8/10, Batch 60/97, Loss: 0.2522
Epoch 8/10, Batch 70/97, Loss: 0.1466
Epoch 8/10, Batch 80/97, Loss: 0.2228
Epoch 8/10, Batch 90/97, Loss: 0.1346
Epoch 8/10, Train Loss: 0.2199, Valid Loss: 0.2533
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1263
Epoch 9/10, Batch 20/97, Loss: 0.2476
Epoch 9/10, Batch 30/97, Loss: 0.0991
Epoch 9/10, Batch 40/97, Loss: 0.2883
Epoch 9/10, Batch 50/97, Loss: 0.1167
Epoch 9/10, Batch 60/97, Loss: 0.1881
Epoch 9/10, Batch 70/97, Loss: 0.1159
Epoch 9/10, Batch 80/97, Loss: 0.2915
Epoch 9/10, Batch 90/97, Loss: 0.1477
Epoch 9/10, Train Loss: 0.2039, Valid Loss: 0.2521
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1856
Epoch 10/10, Batch 20/97, Loss: 0.1687
Epoch 10/10, Batch 30/97, Loss: 0.1455
Epoch 10/10, Batch 40/97, Loss: 0.1566
Epoch 10/10, Batch 50/97, Loss: 0.2033
Epoch 10/10, Batch 60/97, Loss: 0.1604
Epoch 10/10, Batch 70/97, Loss: 0.2504
Epoch 10/10, Batch 80/97, Loss: 0.1820
Epoch 10/10, Batch 90/97, Loss: 0.2254
Epoch 10/10, Train Loss: 0.2014, Valid Loss: 0.2474
Model saved!
Accuracy: 0.9112
Precision: 0.9087
Recall: 0.9112
F1-score: 0.9076
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2341
Epoch 1/10, Batch 20/97, Loss: 1.1136
Epoch 1/10, Batch 30/97, Loss: 0.8362
Epoch 1/10, Batch 40/97, Loss: 0.7074
Epoch 1/10, Batch 50/97, Loss: 0.5544
Epoch 1/10, Batch 60/97, Loss: 0.6445
Epoch 1/10, Batch 70/97, Loss: 0.7532
Epoch 1/10, Batch 80/97, Loss: 0.5132
Epoch 1/10, Batch 90/97, Loss: 0.5619
Epoch 1/10, Train Loss: 0.8053, Valid Loss: 0.4738
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5659
Epoch 2/10, Batch 20/97, Loss: 0.4411
Epoch 2/10, Batch 30/97, Loss: 0.3750
Epoch 2/10, Batch 40/97, Loss: 0.3975
Epoch 2/10, Batch 50/97, Loss: 0.4295
Epoch 2/10, Batch 60/97, Loss: 0.3770
Epoch 2/10, Batch 70/97, Loss: 0.4163
Epoch 2/10, Batch 80/97, Loss: 0.5070
Epoch 2/10, Batch 90/97, Loss: 0.3764
Epoch 2/10, Train Loss: 0.4156, Valid Loss: 0.3635
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4552
Epoch 3/10, Batch 20/97, Loss: 0.4461
Epoch 3/10, Batch 30/97, Loss: 0.2106
Epoch 3/10, Batch 40/97, Loss: 0.2508
Epoch 3/10, Batch 50/97, Loss: 0.4627
Epoch 3/10, Batch 60/97, Loss: 0.1926
Epoch 3/10, Batch 70/97, Loss: 0.3792
Epoch 3/10, Batch 80/97, Loss: 0.3099
Epoch 3/10, Batch 90/97, Loss: 0.3444
Epoch 3/10, Train Loss: 0.3358, Valid Loss: 0.3068
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.5040
Epoch 4/10, Batch 20/97, Loss: 0.3241
Epoch 4/10, Batch 30/97, Loss: 0.3102
Epoch 4/10, Batch 40/97, Loss: 0.1682
Epoch 4/10, Batch 50/97, Loss: 0.3990
Epoch 4/10, Batch 60/97, Loss: 0.3128
Epoch 4/10, Batch 70/97, Loss: 0.4079
Epoch 4/10, Batch 80/97, Loss: 0.3047
Epoch 4/10, Batch 90/97, Loss: 0.2069
Epoch 4/10, Train Loss: 0.2917, Valid Loss: 0.2931
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2940
Epoch 5/10, Batch 20/97, Loss: 0.3861
Epoch 5/10, Batch 30/97, Loss: 0.3236
Epoch 5/10, Batch 40/97, Loss: 0.2815
Epoch 5/10, Batch 50/97, Loss: 0.3184
Epoch 5/10, Batch 60/97, Loss: 0.2479
Epoch 5/10, Batch 70/97, Loss: 0.3898
Epoch 5/10, Batch 80/97, Loss: 0.3300
Epoch 5/10, Batch 90/97, Loss: 0.1426
Epoch 5/10, Train Loss: 0.2763, Valid Loss: 0.2759
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2004
Epoch 6/10, Batch 20/97, Loss: 0.4099
Epoch 6/10, Batch 30/97, Loss: 0.1498
Epoch 6/10, Batch 40/97, Loss: 0.3040
Epoch 6/10, Batch 50/97, Loss: 0.2409
Epoch 6/10, Batch 60/97, Loss: 0.2554
Epoch 6/10, Batch 70/97, Loss: 0.2696
Epoch 6/10, Batch 80/97, Loss: 0.3214
Epoch 6/10, Batch 90/97, Loss: 0.4214
Epoch 6/10, Train Loss: 0.2557, Valid Loss: 0.2655
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2040
Epoch 7/10, Batch 20/97, Loss: 0.3647
Epoch 7/10, Batch 30/97, Loss: 0.3285
Epoch 7/10, Batch 40/97, Loss: 0.1104
Epoch 7/10, Batch 50/97, Loss: 0.2406
Epoch 7/10, Batch 60/97, Loss: 0.2654
Epoch 7/10, Batch 70/97, Loss: 0.2804
Epoch 7/10, Batch 80/97, Loss: 0.2261
Epoch 7/10, Batch 90/97, Loss: 0.1147
Epoch 7/10, Train Loss: 0.2356, Valid Loss: 0.2647
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1845
Epoch 8/10, Batch 20/97, Loss: 0.1401
Epoch 8/10, Batch 30/97, Loss: 0.1085
Epoch 8/10, Batch 40/97, Loss: 0.1940
Epoch 8/10, Batch 50/97, Loss: 0.3119
Epoch 8/10, Batch 60/97, Loss: 0.2659
Epoch 8/10, Batch 70/97, Loss: 0.2456
Epoch 8/10, Batch 80/97, Loss: 0.1076
Epoch 8/10, Batch 90/97, Loss: 0.1204
Epoch 8/10, Train Loss: 0.2245, Valid Loss: 0.2576
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1250
Epoch 9/10, Batch 20/97, Loss: 0.1196
Epoch 9/10, Batch 30/97, Loss: 0.2386
Epoch 9/10, Batch 40/97, Loss: 0.3368
Epoch 9/10, Batch 50/97, Loss: 0.1779
Epoch 9/10, Batch 60/97, Loss: 0.3186
Epoch 9/10, Batch 70/97, Loss: 0.2847
Epoch 9/10, Batch 80/97, Loss: 0.2056
Epoch 9/10, Batch 90/97, Loss: 0.2266
Epoch 9/10, Train Loss: 0.2144, Valid Loss: 0.2510
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3566
Epoch 10/10, Batch 20/97, Loss: 0.1034
Epoch 10/10, Batch 30/97, Loss: 0.2019
Epoch 10/10, Batch 40/97, Loss: 0.2505
Epoch 10/10, Batch 50/97, Loss: 0.2143
Epoch 10/10, Batch 60/97, Loss: 0.1314
Epoch 10/10, Batch 70/97, Loss: 0.1770
Epoch 10/10, Batch 80/97, Loss: 0.2301
Epoch 10/10, Batch 90/97, Loss: 0.2090
Epoch 10/10, Train Loss: 0.2054, Valid Loss: 0.2491
Model saved!
Accuracy: 0.9194
Precision: 0.9170
Recall: 0.9194
F1-score: 0.9173
Memory Allocated after cleanup: 17.76 MB
End time: 2025-02-24 21:24:06.928328
Duration: 7:12:37


Mejor accuracy al acabar el algoritmo: 0.9276


Fitness check:

Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2405
Epoch 1/10, Batch 20/97, Loss: 1.0366
Epoch 1/10, Batch 30/97, Loss: 0.7205
Epoch 1/10, Batch 40/97, Loss: 0.8498
Epoch 1/10, Batch 50/97, Loss: 0.6465
Epoch 1/10, Batch 60/97, Loss: 0.7081
Epoch 1/10, Batch 70/97, Loss: 0.5808
Epoch 1/10, Batch 80/97, Loss: 0.7826
Epoch 1/10, Batch 90/97, Loss: 0.5702
Epoch 1/10, Train Loss: 0.7927, Valid Loss: 0.4634
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4862
Epoch 2/10, Batch 20/97, Loss: 0.3285
Epoch 2/10, Batch 30/97, Loss: 0.3605
Epoch 2/10, Batch 40/97, Loss: 0.3714
Epoch 2/10, Batch 50/97, Loss: 0.4564
Epoch 2/10, Batch 60/97, Loss: 0.4224
Epoch 2/10, Batch 70/97, Loss: 0.5299
Epoch 2/10, Batch 80/97, Loss: 0.1847
Epoch 2/10, Batch 90/97, Loss: 0.3845
Epoch 2/10, Train Loss: 0.4071, Valid Loss: 0.3469
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3663
Epoch 3/10, Batch 20/97, Loss: 0.3133
Epoch 3/10, Batch 30/97, Loss: 0.4685
Epoch 3/10, Batch 40/97, Loss: 0.2722
Epoch 3/10, Batch 50/97, Loss: 0.5532
Epoch 3/10, Batch 60/97, Loss: 0.2953
Epoch 3/10, Batch 70/97, Loss: 0.4240
Epoch 3/10, Batch 80/97, Loss: 0.2176
Epoch 3/10, Batch 90/97, Loss: 0.3788
Epoch 3/10, Train Loss: 0.3292, Valid Loss: 0.2962
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3267
Epoch 4/10, Batch 20/97, Loss: 0.3039
Epoch 4/10, Batch 30/97, Loss: 0.3210
Epoch 4/10, Batch 40/97, Loss: 0.2519
Epoch 4/10, Batch 50/97, Loss: 0.2974
Epoch 4/10, Batch 60/97, Loss: 0.2355
Epoch 4/10, Batch 70/97, Loss: 0.2480
Epoch 4/10, Batch 80/97, Loss: 0.3437
Epoch 4/10, Batch 90/97, Loss: 0.2640
Epoch 4/10, Train Loss: 0.2801, Valid Loss: 0.2841
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2908
Epoch 5/10, Batch 20/97, Loss: 0.3024
Epoch 5/10, Batch 30/97, Loss: 0.1852
Epoch 5/10, Batch 40/97, Loss: 0.4109
Epoch 5/10, Batch 50/97, Loss: 0.1980
Epoch 5/10, Batch 60/97, Loss: 0.2022
Epoch 5/10, Batch 70/97, Loss: 0.2352
Epoch 5/10, Batch 80/97, Loss: 0.2485
Epoch 5/10, Batch 90/97, Loss: 0.3685
Epoch 5/10, Train Loss: 0.2597, Valid Loss: 0.2661
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2510
Epoch 6/10, Batch 20/97, Loss: 0.2151
Epoch 6/10, Batch 30/97, Loss: 0.1496
Epoch 6/10, Batch 40/97, Loss: 0.2220
Epoch 6/10, Batch 50/97, Loss: 0.2209
Epoch 6/10, Batch 60/97, Loss: 0.2550
Epoch 6/10, Batch 70/97, Loss: 0.1145
Epoch 6/10, Batch 80/97, Loss: 0.3170
Epoch 6/10, Batch 90/97, Loss: 0.1967
Epoch 6/10, Train Loss: 0.2352, Valid Loss: 0.2500
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2117
Epoch 7/10, Batch 20/97, Loss: 0.3149
Epoch 7/10, Batch 30/97, Loss: 0.1188
Epoch 7/10, Batch 40/97, Loss: 0.1502
Epoch 7/10, Batch 50/97, Loss: 0.1792
Epoch 7/10, Batch 60/97, Loss: 0.1177
Epoch 7/10, Batch 70/97, Loss: 0.1362
Epoch 7/10, Batch 80/97, Loss: 0.1727
Epoch 7/10, Batch 90/97, Loss: 0.2059
Epoch 7/10, Train Loss: 0.2210, Valid Loss: 0.2480
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1639
Epoch 8/10, Batch 20/97, Loss: 0.2988
Epoch 8/10, Batch 30/97, Loss: 0.2180
Epoch 8/10, Batch 40/97, Loss: 0.1680
Epoch 8/10, Batch 50/97, Loss: 0.3338
Epoch 8/10, Batch 60/97, Loss: 0.2068
Epoch 8/10, Batch 70/97, Loss: 0.2017
Epoch 8/10, Batch 80/97, Loss: 0.3164
Epoch 8/10, Batch 90/97, Loss: 0.1780
Epoch 8/10, Train Loss: 0.2144, Valid Loss: 0.2360
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1193
Epoch 9/10, Batch 20/97, Loss: 0.1291
Epoch 9/10, Batch 30/97, Loss: 0.2817
Epoch 9/10, Batch 40/97, Loss: 0.1500
Epoch 9/10, Batch 50/97, Loss: 0.1068
Epoch 9/10, Batch 60/97, Loss: 0.1542
Epoch 9/10, Batch 70/97, Loss: 0.0897
Epoch 9/10, Batch 80/97, Loss: 0.2542
Epoch 9/10, Batch 90/97, Loss: 0.1451
Epoch 9/10, Train Loss: 0.2001, Valid Loss: 0.2325
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2758
Epoch 10/10, Batch 20/97, Loss: 0.1347
Epoch 10/10, Batch 30/97, Loss: 0.1236
Epoch 10/10, Batch 40/97, Loss: 0.1245
Epoch 10/10, Batch 50/97, Loss: 0.2244
Epoch 10/10, Batch 60/97, Loss: 0.1510
Epoch 10/10, Batch 70/97, Loss: 0.1523
Epoch 10/10, Batch 80/97, Loss: 0.1728
Epoch 10/10, Batch 90/97, Loss: 0.1557
Epoch 10/10, Train Loss: 0.1978, Valid Loss: 0.2352
Accuracy: 0.9276
Precision: 0.9253
Recall: 0.9276
F1-score: 0.9260
Memory Allocated after cleanup: 17.76 MB


Mejor accuracy encontrado: 0.9276


--------------------------------------mobilenet  ALEATORIO  75%-------------------------------------------------
Start time: 2025-02-24 21:28:09.081578
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4741
Epoch 1/10, Batch 20/145, Loss: 0.9618
Epoch 1/10, Batch 30/145, Loss: 0.9818
Epoch 1/10, Batch 40/145, Loss: 0.7594
Epoch 1/10, Batch 50/145, Loss: 0.5808
Epoch 1/10, Batch 60/145, Loss: 0.5115
Epoch 1/10, Batch 70/145, Loss: 0.7111
Epoch 1/10, Batch 80/145, Loss: 0.5542
Epoch 1/10, Batch 90/145, Loss: 0.4416
Epoch 1/10, Batch 100/145, Loss: 0.4193
Epoch 1/10, Batch 110/145, Loss: 0.4272
Epoch 1/10, Batch 120/145, Loss: 0.6263
Epoch 1/10, Batch 130/145, Loss: 0.3637
Epoch 1/10, Batch 140/145, Loss: 0.3706
Epoch 1/10, Train Loss: 0.6917, Valid Loss: 0.3787
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2739
Epoch 2/10, Batch 20/145, Loss: 0.4435
Epoch 2/10, Batch 30/145, Loss: 0.3822
Epoch 2/10, Batch 40/145, Loss: 0.4281
Epoch 2/10, Batch 50/145, Loss: 0.3378
Epoch 2/10, Batch 60/145, Loss: 0.3030
Epoch 2/10, Batch 70/145, Loss: 0.4733
Epoch 2/10, Batch 80/145, Loss: 0.2646
Epoch 2/10, Batch 90/145, Loss: 0.2800
Epoch 2/10, Batch 100/145, Loss: 0.4048
Epoch 2/10, Batch 110/145, Loss: 0.2042
Epoch 2/10, Batch 120/145, Loss: 0.3498
Epoch 2/10, Batch 130/145, Loss: 0.3786
Epoch 2/10, Batch 140/145, Loss: 0.3927
Epoch 2/10, Train Loss: 0.3676, Valid Loss: 0.2893
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1726
Epoch 3/10, Batch 20/145, Loss: 0.4103
Epoch 3/10, Batch 30/145, Loss: 0.2272
Epoch 3/10, Batch 40/145, Loss: 0.3520
Epoch 3/10, Batch 50/145, Loss: 0.2249
Epoch 3/10, Batch 60/145, Loss: 0.5011
Epoch 3/10, Batch 70/145, Loss: 0.1553
Epoch 3/10, Batch 80/145, Loss: 0.2734
Epoch 3/10, Batch 90/145, Loss: 0.6773
Epoch 3/10, Batch 100/145, Loss: 0.1727
Epoch 3/10, Batch 110/145, Loss: 0.2354
Epoch 3/10, Batch 120/145, Loss: 0.2646
Epoch 3/10, Batch 130/145, Loss: 0.2219
Epoch 3/10, Batch 140/145, Loss: 0.1643
Epoch 3/10, Train Loss: 0.3097, Valid Loss: 0.2603
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1529
Epoch 4/10, Batch 20/145, Loss: 0.1951
Epoch 4/10, Batch 30/145, Loss: 0.2264
Epoch 4/10, Batch 40/145, Loss: 0.3275
Epoch 4/10, Batch 50/145, Loss: 0.1677
Epoch 4/10, Batch 60/145, Loss: 0.1769
Epoch 4/10, Batch 70/145, Loss: 0.1479
Epoch 4/10, Batch 80/145, Loss: 0.3179
Epoch 4/10, Batch 90/145, Loss: 0.3109
Epoch 4/10, Batch 100/145, Loss: 0.1846
Epoch 4/10, Batch 110/145, Loss: 0.2842
Epoch 4/10, Batch 120/145, Loss: 0.2578
Epoch 4/10, Batch 130/145, Loss: 0.2048
Epoch 4/10, Batch 140/145, Loss: 0.2909
Epoch 4/10, Train Loss: 0.2691, Valid Loss: 0.2466
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1663
Epoch 5/10, Batch 20/145, Loss: 0.3136
Epoch 5/10, Batch 30/145, Loss: 0.1487
Epoch 5/10, Batch 40/145, Loss: 0.2828
Epoch 5/10, Batch 50/145, Loss: 0.2852
Epoch 5/10, Batch 60/145, Loss: 0.1464
Epoch 5/10, Batch 70/145, Loss: 0.2390
Epoch 5/10, Batch 80/145, Loss: 0.4191
Epoch 5/10, Batch 90/145, Loss: 0.1138
Epoch 5/10, Batch 100/145, Loss: 0.2631
Epoch 5/10, Batch 110/145, Loss: 0.2029
Epoch 5/10, Batch 120/145, Loss: 0.2497
Epoch 5/10, Batch 130/145, Loss: 0.3038
Epoch 5/10, Batch 140/145, Loss: 0.3329
Epoch 5/10, Train Loss: 0.2414, Valid Loss: 0.2429
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1381
Epoch 6/10, Batch 20/145, Loss: 0.1711
Epoch 6/10, Batch 30/145, Loss: 0.3103
Epoch 6/10, Batch 40/145, Loss: 0.1351
Epoch 6/10, Batch 50/145, Loss: 0.5066
Epoch 6/10, Batch 60/145, Loss: 0.0954
Epoch 6/10, Batch 70/145, Loss: 0.2054
Epoch 6/10, Batch 80/145, Loss: 0.3873
Epoch 6/10, Batch 90/145, Loss: 0.2101
Epoch 6/10, Batch 100/145, Loss: 0.2540
Epoch 6/10, Batch 110/145, Loss: 0.1968
Epoch 6/10, Batch 120/145, Loss: 0.1953
Epoch 6/10, Batch 130/145, Loss: 0.2194
Epoch 6/10, Batch 140/145, Loss: 0.1905
Epoch 6/10, Train Loss: 0.2327, Valid Loss: 0.2440
Epoch 7/10, Batch 10/145, Loss: 0.3986
Epoch 7/10, Batch 20/145, Loss: 0.1323
Epoch 7/10, Batch 30/145, Loss: 0.1772
Epoch 7/10, Batch 40/145, Loss: 0.5106
Epoch 7/10, Batch 50/145, Loss: 0.2097
Epoch 7/10, Batch 60/145, Loss: 0.1536
Epoch 7/10, Batch 70/145, Loss: 0.2315
Epoch 7/10, Batch 80/145, Loss: 0.0700
Epoch 7/10, Batch 90/145, Loss: 0.2263
Epoch 7/10, Batch 100/145, Loss: 0.2064
Epoch 7/10, Batch 110/145, Loss: 0.1812
Epoch 7/10, Batch 120/145, Loss: 0.1476
Epoch 7/10, Batch 130/145, Loss: 0.2045
Epoch 7/10, Batch 140/145, Loss: 0.2034
Epoch 7/10, Train Loss: 0.2247, Valid Loss: 0.2304
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1985
Epoch 8/10, Batch 20/145, Loss: 0.2256
Epoch 8/10, Batch 30/145, Loss: 0.1466
Epoch 8/10, Batch 40/145, Loss: 0.2980
Epoch 8/10, Batch 50/145, Loss: 0.2974
Epoch 8/10, Batch 60/145, Loss: 0.1954
Epoch 8/10, Batch 70/145, Loss: 0.1308
Epoch 8/10, Batch 80/145, Loss: 0.1886
Epoch 8/10, Batch 90/145, Loss: 0.1262
Epoch 8/10, Batch 100/145, Loss: 0.2907
Epoch 8/10, Batch 110/145, Loss: 0.1463
Epoch 8/10, Batch 120/145, Loss: 0.1156
Epoch 8/10, Batch 130/145, Loss: 0.1147
Epoch 8/10, Batch 140/145, Loss: 0.1830
Epoch 8/10, Train Loss: 0.2159, Valid Loss: 0.2209
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3573
Epoch 9/10, Batch 20/145, Loss: 0.1758
Epoch 9/10, Batch 30/145, Loss: 0.0816
Epoch 9/10, Batch 40/145, Loss: 0.1503
Epoch 9/10, Batch 50/145, Loss: 0.1383
Epoch 9/10, Batch 60/145, Loss: 0.0943
Epoch 9/10, Batch 70/145, Loss: 0.2811
Epoch 9/10, Batch 80/145, Loss: 0.3139
Epoch 9/10, Batch 90/145, Loss: 0.2035
Epoch 9/10, Batch 100/145, Loss: 0.1831
Epoch 9/10, Batch 110/145, Loss: 0.1213
Epoch 9/10, Batch 120/145, Loss: 0.1542
Epoch 9/10, Batch 130/145, Loss: 0.2872
Epoch 9/10, Batch 140/145, Loss: 0.0862
Epoch 9/10, Train Loss: 0.2050, Valid Loss: 0.2230
Epoch 10/10, Batch 10/145, Loss: 0.1440
Epoch 10/10, Batch 20/145, Loss: 0.1416
Epoch 10/10, Batch 30/145, Loss: 0.1436
Epoch 10/10, Batch 40/145, Loss: 0.1538
Epoch 10/10, Batch 50/145, Loss: 0.2821
Epoch 10/10, Batch 60/145, Loss: 0.1895
Epoch 10/10, Batch 70/145, Loss: 0.1538
Epoch 10/10, Batch 80/145, Loss: 0.2595
Epoch 10/10, Batch 90/145, Loss: 0.1640
Epoch 10/10, Batch 100/145, Loss: 0.0884
Epoch 10/10, Batch 110/145, Loss: 0.2981
Epoch 10/10, Batch 120/145, Loss: 0.1916
Epoch 10/10, Batch 130/145, Loss: 0.2503
Epoch 10/10, Batch 140/145, Loss: 0.3418
Epoch 10/10, Train Loss: 0.2012, Valid Loss: 0.2178
Model saved!
Accuracy: 0.9182
Precision: 0.9168
Recall: 0.9182
F1-score: 0.9175
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 1. Fitness: 0.9182
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5681
Epoch 1/10, Batch 20/145, Loss: 0.8424
Epoch 1/10, Batch 30/145, Loss: 0.8466
Epoch 1/10, Batch 40/145, Loss: 0.8319
Epoch 1/10, Batch 50/145, Loss: 0.6774
Epoch 1/10, Batch 60/145, Loss: 0.6041
Epoch 1/10, Batch 70/145, Loss: 0.5745
Epoch 1/10, Batch 80/145, Loss: 0.5447
Epoch 1/10, Batch 90/145, Loss: 0.6611
Epoch 1/10, Batch 100/145, Loss: 0.5524
Epoch 1/10, Batch 110/145, Loss: 0.4260
Epoch 1/10, Batch 120/145, Loss: 0.5262
Epoch 1/10, Batch 130/145, Loss: 0.5831
Epoch 1/10, Batch 140/145, Loss: 0.2940
Epoch 1/10, Train Loss: 0.6935, Valid Loss: 0.3566
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2538
Epoch 2/10, Batch 20/145, Loss: 0.4046
Epoch 2/10, Batch 30/145, Loss: 0.2819
Epoch 2/10, Batch 40/145, Loss: 0.5042
Epoch 2/10, Batch 50/145, Loss: 0.2560
Epoch 2/10, Batch 60/145, Loss: 0.6885
Epoch 2/10, Batch 70/145, Loss: 0.3641
Epoch 2/10, Batch 80/145, Loss: 0.4445
Epoch 2/10, Batch 90/145, Loss: 0.2430
Epoch 2/10, Batch 100/145, Loss: 0.2782
Epoch 2/10, Batch 110/145, Loss: 0.3499
Epoch 2/10, Batch 120/145, Loss: 0.3934
Epoch 2/10, Batch 130/145, Loss: 0.3471
Epoch 2/10, Batch 140/145, Loss: 0.2796
Epoch 2/10, Train Loss: 0.3603, Valid Loss: 0.2725
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3593
Epoch 3/10, Batch 20/145, Loss: 0.3011
Epoch 3/10, Batch 30/145, Loss: 0.3326
Epoch 3/10, Batch 40/145, Loss: 0.2313
Epoch 3/10, Batch 50/145, Loss: 0.2431
Epoch 3/10, Batch 60/145, Loss: 0.1906
Epoch 3/10, Batch 70/145, Loss: 0.2546
Epoch 3/10, Batch 80/145, Loss: 0.1976
Epoch 3/10, Batch 90/145, Loss: 0.4670
Epoch 3/10, Batch 100/145, Loss: 0.2533
Epoch 3/10, Batch 110/145, Loss: 0.3006
Epoch 3/10, Batch 120/145, Loss: 0.1355
Epoch 3/10, Batch 130/145, Loss: 0.2710
Epoch 3/10, Batch 140/145, Loss: 0.1821
Epoch 3/10, Train Loss: 0.3036, Valid Loss: 0.2434
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1905
Epoch 4/10, Batch 20/145, Loss: 0.2855
Epoch 4/10, Batch 30/145, Loss: 0.3613
Epoch 4/10, Batch 40/145, Loss: 0.3017
Epoch 4/10, Batch 50/145, Loss: 0.1747
Epoch 4/10, Batch 60/145, Loss: 0.2335
Epoch 4/10, Batch 70/145, Loss: 0.1718
Epoch 4/10, Batch 80/145, Loss: 0.3377
Epoch 4/10, Batch 90/145, Loss: 0.2207
Epoch 4/10, Batch 100/145, Loss: 0.2423
Epoch 4/10, Batch 110/145, Loss: 0.1980
Epoch 4/10, Batch 120/145, Loss: 0.1990
Epoch 4/10, Batch 130/145, Loss: 0.2372
Epoch 4/10, Batch 140/145, Loss: 0.2323
Epoch 4/10, Train Loss: 0.2617, Valid Loss: 0.2372
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1218
Epoch 5/10, Batch 20/145, Loss: 0.1687
Epoch 5/10, Batch 30/145, Loss: 0.1125
Epoch 5/10, Batch 40/145, Loss: 0.1432
Epoch 5/10, Batch 50/145, Loss: 0.1292
Epoch 5/10, Batch 60/145, Loss: 0.1785
Epoch 5/10, Batch 70/145, Loss: 0.2081
Epoch 5/10, Batch 80/145, Loss: 0.2437
Epoch 5/10, Batch 90/145, Loss: 0.2885
Epoch 5/10, Batch 100/145, Loss: 0.3131
Epoch 5/10, Batch 110/145, Loss: 0.1412
Epoch 5/10, Batch 120/145, Loss: 0.2664
Epoch 5/10, Batch 130/145, Loss: 0.1128
Epoch 5/10, Batch 140/145, Loss: 0.2036
Epoch 5/10, Train Loss: 0.2413, Valid Loss: 0.2186
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1259
Epoch 6/10, Batch 20/145, Loss: 0.3985
Epoch 6/10, Batch 30/145, Loss: 0.3412
Epoch 6/10, Batch 40/145, Loss: 0.1547
Epoch 6/10, Batch 50/145, Loss: 0.2475
Epoch 6/10, Batch 60/145, Loss: 0.2257
Epoch 6/10, Batch 70/145, Loss: 0.2629
Epoch 6/10, Batch 80/145, Loss: 0.2256
Epoch 6/10, Batch 90/145, Loss: 0.3076
Epoch 6/10, Batch 100/145, Loss: 0.2712
Epoch 6/10, Batch 110/145, Loss: 0.0828
Epoch 6/10, Batch 120/145, Loss: 0.3026
Epoch 6/10, Batch 130/145, Loss: 0.1382
Epoch 6/10, Batch 140/145, Loss: 0.1997
Epoch 6/10, Train Loss: 0.2312, Valid Loss: 0.2389
Epoch 7/10, Batch 10/145, Loss: 0.2343
Epoch 7/10, Batch 20/145, Loss: 0.1666
Epoch 7/10, Batch 30/145, Loss: 0.1545
Epoch 7/10, Batch 40/145, Loss: 0.3052
Epoch 7/10, Batch 50/145, Loss: 0.1778
Epoch 7/10, Batch 60/145, Loss: 0.1619
Epoch 7/10, Batch 70/145, Loss: 0.1963
Epoch 7/10, Batch 80/145, Loss: 0.1580
Epoch 7/10, Batch 90/145, Loss: 0.2038
Epoch 7/10, Batch 100/145, Loss: 0.1222
Epoch 7/10, Batch 110/145, Loss: 0.3106
Epoch 7/10, Batch 120/145, Loss: 0.1973
Epoch 7/10, Batch 130/145, Loss: 0.2169
Epoch 7/10, Batch 140/145, Loss: 0.1791
Epoch 7/10, Train Loss: 0.2141, Valid Loss: 0.2105
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1507
Epoch 8/10, Batch 20/145, Loss: 0.0850
Epoch 8/10, Batch 30/145, Loss: 0.2157
Epoch 8/10, Batch 40/145, Loss: 0.1164
Epoch 8/10, Batch 50/145, Loss: 0.1429
Epoch 8/10, Batch 60/145, Loss: 0.4103
Epoch 8/10, Batch 70/145, Loss: 0.0899
Epoch 8/10, Batch 80/145, Loss: 0.3436
Epoch 8/10, Batch 90/145, Loss: 0.1827
Epoch 8/10, Batch 100/145, Loss: 0.4328
Epoch 8/10, Batch 110/145, Loss: 0.2626
Epoch 8/10, Batch 120/145, Loss: 0.3310
Epoch 8/10, Batch 130/145, Loss: 0.2550
Epoch 8/10, Batch 140/145, Loss: 0.0821
Epoch 8/10, Train Loss: 0.2190, Valid Loss: 0.2116
Epoch 9/10, Batch 10/145, Loss: 0.1702
Epoch 9/10, Batch 20/145, Loss: 0.1625
Epoch 9/10, Batch 30/145, Loss: 0.1214
Epoch 9/10, Batch 40/145, Loss: 0.2172
Epoch 9/10, Batch 50/145, Loss: 0.1188
Epoch 9/10, Batch 60/145, Loss: 0.1848
Epoch 9/10, Batch 70/145, Loss: 0.2087
Epoch 9/10, Batch 80/145, Loss: 0.2961
Epoch 9/10, Batch 90/145, Loss: 0.1197
Epoch 9/10, Batch 100/145, Loss: 0.1928
Epoch 9/10, Batch 110/145, Loss: 0.0749
Epoch 9/10, Batch 120/145, Loss: 0.4006
Epoch 9/10, Batch 130/145, Loss: 0.1785
Epoch 9/10, Batch 140/145, Loss: 0.1383
Epoch 9/10, Train Loss: 0.2044, Valid Loss: 0.2026
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1544
Epoch 10/10, Batch 20/145, Loss: 0.1459
Epoch 10/10, Batch 30/145, Loss: 0.1003
Epoch 10/10, Batch 40/145, Loss: 0.1844
Epoch 10/10, Batch 50/145, Loss: 0.2969
Epoch 10/10, Batch 60/145, Loss: 0.1607
Epoch 10/10, Batch 70/145, Loss: 0.1785
Epoch 10/10, Batch 80/145, Loss: 0.3787
Epoch 10/10, Batch 90/145, Loss: 0.1245
Epoch 10/10, Batch 100/145, Loss: 0.2499
Epoch 10/10, Batch 110/145, Loss: 0.2234
Epoch 10/10, Batch 120/145, Loss: 0.2699
Epoch 10/10, Batch 130/145, Loss: 0.3359
Epoch 10/10, Batch 140/145, Loss: 0.1074
Epoch 10/10, Train Loss: 0.1945, Valid Loss: 0.1954
Model saved!
Accuracy: 0.9241
Precision: 0.9225
Recall: 0.9241
F1-score: 0.9231
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 2. Fitness: 0.9241
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4914
Epoch 1/10, Batch 20/145, Loss: 0.9263
Epoch 1/10, Batch 30/145, Loss: 0.8843
Epoch 1/10, Batch 40/145, Loss: 0.7923
Epoch 1/10, Batch 50/145, Loss: 0.6348
Epoch 1/10, Batch 60/145, Loss: 0.5999
Epoch 1/10, Batch 70/145, Loss: 0.5721
Epoch 1/10, Batch 80/145, Loss: 0.4921
Epoch 1/10, Batch 90/145, Loss: 0.5973
Epoch 1/10, Batch 100/145, Loss: 0.6314
Epoch 1/10, Batch 110/145, Loss: 0.3572
Epoch 1/10, Batch 120/145, Loss: 0.6309
Epoch 1/10, Batch 130/145, Loss: 0.4384
Epoch 1/10, Batch 140/145, Loss: 0.3827
Epoch 1/10, Train Loss: 0.6858, Valid Loss: 0.3712
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3882
Epoch 2/10, Batch 20/145, Loss: 0.5509
Epoch 2/10, Batch 30/145, Loss: 0.1708
Epoch 2/10, Batch 40/145, Loss: 0.3420
Epoch 2/10, Batch 50/145, Loss: 0.3499
Epoch 2/10, Batch 60/145, Loss: 0.3139
Epoch 2/10, Batch 70/145, Loss: 0.3267
Epoch 2/10, Batch 80/145, Loss: 0.3774
Epoch 2/10, Batch 90/145, Loss: 0.3185
Epoch 2/10, Batch 100/145, Loss: 0.2997
Epoch 2/10, Batch 110/145, Loss: 0.3055
Epoch 2/10, Batch 120/145, Loss: 0.5105
Epoch 2/10, Batch 130/145, Loss: 0.3301
Epoch 2/10, Batch 140/145, Loss: 0.2724
Epoch 2/10, Train Loss: 0.3576, Valid Loss: 0.2817
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1929
Epoch 3/10, Batch 20/145, Loss: 0.2470
Epoch 3/10, Batch 30/145, Loss: 0.2504
Epoch 3/10, Batch 40/145, Loss: 0.1466
Epoch 3/10, Batch 50/145, Loss: 0.1752
Epoch 3/10, Batch 60/145, Loss: 0.2502
Epoch 3/10, Batch 70/145, Loss: 0.2184
Epoch 3/10, Batch 80/145, Loss: 0.2635
Epoch 3/10, Batch 90/145, Loss: 0.4096
Epoch 3/10, Batch 100/145, Loss: 0.2456
Epoch 3/10, Batch 110/145, Loss: 0.2256
Epoch 3/10, Batch 120/145, Loss: 0.1571
Epoch 3/10, Batch 130/145, Loss: 0.3234
Epoch 3/10, Batch 140/145, Loss: 0.1200
Epoch 3/10, Train Loss: 0.2988, Valid Loss: 0.2504
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1906
Epoch 4/10, Batch 20/145, Loss: 0.1962
Epoch 4/10, Batch 30/145, Loss: 0.2532
Epoch 4/10, Batch 40/145, Loss: 0.2547
Epoch 4/10, Batch 50/145, Loss: 0.1260
Epoch 4/10, Batch 60/145, Loss: 0.1034
Epoch 4/10, Batch 70/145, Loss: 0.2009
Epoch 4/10, Batch 80/145, Loss: 0.3649
Epoch 4/10, Batch 90/145, Loss: 0.3737
Epoch 4/10, Batch 100/145, Loss: 0.1366
Epoch 4/10, Batch 110/145, Loss: 0.1319
Epoch 4/10, Batch 120/145, Loss: 0.3209
Epoch 4/10, Batch 130/145, Loss: 0.2249
Epoch 4/10, Batch 140/145, Loss: 0.1942
Epoch 4/10, Train Loss: 0.2604, Valid Loss: 0.2432
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1160
Epoch 5/10, Batch 20/145, Loss: 0.2891
Epoch 5/10, Batch 30/145, Loss: 0.1530
Epoch 5/10, Batch 40/145, Loss: 0.2998
Epoch 5/10, Batch 50/145, Loss: 0.1640
Epoch 5/10, Batch 60/145, Loss: 0.1962
Epoch 5/10, Batch 70/145, Loss: 0.1886
Epoch 5/10, Batch 80/145, Loss: 0.3104
Epoch 5/10, Batch 90/145, Loss: 0.2506
Epoch 5/10, Batch 100/145, Loss: 0.2011
Epoch 5/10, Batch 110/145, Loss: 0.1298
Epoch 5/10, Batch 120/145, Loss: 0.1255
Epoch 5/10, Batch 130/145, Loss: 0.2139
Epoch 5/10, Batch 140/145, Loss: 0.1939
Epoch 5/10, Train Loss: 0.2342, Valid Loss: 0.2304
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1508
Epoch 6/10, Batch 20/145, Loss: 0.2674
Epoch 6/10, Batch 30/145, Loss: 0.2946
Epoch 6/10, Batch 40/145, Loss: 0.0940
Epoch 6/10, Batch 50/145, Loss: 0.2771
Epoch 6/10, Batch 60/145, Loss: 0.2509
Epoch 6/10, Batch 70/145, Loss: 0.3171
Epoch 6/10, Batch 80/145, Loss: 0.1947
Epoch 6/10, Batch 90/145, Loss: 0.1335
Epoch 6/10, Batch 100/145, Loss: 0.2591
Epoch 6/10, Batch 110/145, Loss: 0.1354
Epoch 6/10, Batch 120/145, Loss: 0.2538
Epoch 6/10, Batch 130/145, Loss: 0.1259
Epoch 6/10, Batch 140/145, Loss: 0.1980
Epoch 6/10, Train Loss: 0.2205, Valid Loss: 0.2304
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2858
Epoch 7/10, Batch 20/145, Loss: 0.1666
Epoch 7/10, Batch 30/145, Loss: 0.2218
Epoch 7/10, Batch 40/145, Loss: 0.3347
Epoch 7/10, Batch 50/145, Loss: 0.1453
Epoch 7/10, Batch 60/145, Loss: 0.1235
Epoch 7/10, Batch 70/145, Loss: 0.3134
Epoch 7/10, Batch 80/145, Loss: 0.2577
Epoch 7/10, Batch 90/145, Loss: 0.2963
Epoch 7/10, Batch 100/145, Loss: 0.2245
Epoch 7/10, Batch 110/145, Loss: 0.1662
Epoch 7/10, Batch 120/145, Loss: 0.2525
Epoch 7/10, Batch 130/145, Loss: 0.1063
Epoch 7/10, Batch 140/145, Loss: 0.1079
Epoch 7/10, Train Loss: 0.2136, Valid Loss: 0.2287
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0923
Epoch 8/10, Batch 20/145, Loss: 0.0966
Epoch 8/10, Batch 30/145, Loss: 0.2358
Epoch 8/10, Batch 40/145, Loss: 0.3446
Epoch 8/10, Batch 50/145, Loss: 0.2353
Epoch 8/10, Batch 60/145, Loss: 0.3340
Epoch 8/10, Batch 70/145, Loss: 0.2331
Epoch 8/10, Batch 80/145, Loss: 0.2043
Epoch 8/10, Batch 90/145, Loss: 0.1364
Epoch 8/10, Batch 100/145, Loss: 0.2338
Epoch 8/10, Batch 110/145, Loss: 0.2570
Epoch 8/10, Batch 120/145, Loss: 0.1840
Epoch 8/10, Batch 130/145, Loss: 0.1908
Epoch 8/10, Batch 140/145, Loss: 0.2486
Epoch 8/10, Train Loss: 0.2156, Valid Loss: 0.2159
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3731
Epoch 9/10, Batch 20/145, Loss: 0.1214
Epoch 9/10, Batch 30/145, Loss: 0.1588
Epoch 9/10, Batch 40/145, Loss: 0.2239
Epoch 9/10, Batch 50/145, Loss: 0.0982
Epoch 9/10, Batch 60/145, Loss: 0.1755
Epoch 9/10, Batch 70/145, Loss: 0.2122
Epoch 9/10, Batch 80/145, Loss: 0.0753
Epoch 9/10, Batch 90/145, Loss: 0.1308
Epoch 9/10, Batch 100/145, Loss: 0.2041
Epoch 9/10, Batch 110/145, Loss: 0.1253
Epoch 9/10, Batch 120/145, Loss: 0.2009
Epoch 9/10, Batch 130/145, Loss: 0.2412
Epoch 9/10, Batch 140/145, Loss: 0.1532
Epoch 9/10, Train Loss: 0.2000, Valid Loss: 0.2164
Epoch 10/10, Batch 10/145, Loss: 0.1739
Epoch 10/10, Batch 20/145, Loss: 0.1076
Epoch 10/10, Batch 30/145, Loss: 0.0808
Epoch 10/10, Batch 40/145, Loss: 0.1650
Epoch 10/10, Batch 50/145, Loss: 0.1761
Epoch 10/10, Batch 60/145, Loss: 0.3368
Epoch 10/10, Batch 70/145, Loss: 0.1403
Epoch 10/10, Batch 80/145, Loss: 0.3408
Epoch 10/10, Batch 90/145, Loss: 0.1529
Epoch 10/10, Batch 100/145, Loss: 0.1231
Epoch 10/10, Batch 110/145, Loss: 0.0961
Epoch 10/10, Batch 120/145, Loss: 0.2176
Epoch 10/10, Batch 130/145, Loss: 0.2046
Epoch 10/10, Batch 140/145, Loss: 0.2299
Epoch 10/10, Train Loss: 0.1878, Valid Loss: 0.2043
Model saved!
Accuracy: 0.9264
Precision: 0.9249
Recall: 0.9264
F1-score: 0.9250
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 3. Fitness: 0.9264
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5151
Epoch 1/10, Batch 20/145, Loss: 1.0136
Epoch 1/10, Batch 30/145, Loss: 0.8296
Epoch 1/10, Batch 40/145, Loss: 0.8418
Epoch 1/10, Batch 50/145, Loss: 0.5894
Epoch 1/10, Batch 60/145, Loss: 0.5171
Epoch 1/10, Batch 70/145, Loss: 0.5870
Epoch 1/10, Batch 80/145, Loss: 0.5037
Epoch 1/10, Batch 90/145, Loss: 0.5735
Epoch 1/10, Batch 100/145, Loss: 0.4585
Epoch 1/10, Batch 110/145, Loss: 0.2931
Epoch 1/10, Batch 120/145, Loss: 0.6292
Epoch 1/10, Batch 130/145, Loss: 0.3480
Epoch 1/10, Batch 140/145, Loss: 0.4951
Epoch 1/10, Train Loss: 0.6930, Valid Loss: 0.4015
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3990
Epoch 2/10, Batch 20/145, Loss: 0.4629
Epoch 2/10, Batch 30/145, Loss: 0.3200
Epoch 2/10, Batch 40/145, Loss: 0.5860
Epoch 2/10, Batch 50/145, Loss: 0.2114
Epoch 2/10, Batch 60/145, Loss: 0.3870
Epoch 2/10, Batch 70/145, Loss: 0.4194
Epoch 2/10, Batch 80/145, Loss: 0.3104
Epoch 2/10, Batch 90/145, Loss: 0.3498
Epoch 2/10, Batch 100/145, Loss: 0.4997
Epoch 2/10, Batch 110/145, Loss: 0.3517
Epoch 2/10, Batch 120/145, Loss: 0.3018
Epoch 2/10, Batch 130/145, Loss: 0.2757
Epoch 2/10, Batch 140/145, Loss: 0.3010
Epoch 2/10, Train Loss: 0.3633, Valid Loss: 0.3121
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1871
Epoch 3/10, Batch 20/145, Loss: 0.2433
Epoch 3/10, Batch 30/145, Loss: 0.2109
Epoch 3/10, Batch 40/145, Loss: 0.4268
Epoch 3/10, Batch 50/145, Loss: 0.1654
Epoch 3/10, Batch 60/145, Loss: 0.2929
Epoch 3/10, Batch 70/145, Loss: 0.2874
Epoch 3/10, Batch 80/145, Loss: 0.3152
Epoch 3/10, Batch 90/145, Loss: 0.4871
Epoch 3/10, Batch 100/145, Loss: 0.3830
Epoch 3/10, Batch 110/145, Loss: 0.2326
Epoch 3/10, Batch 120/145, Loss: 0.2451
Epoch 3/10, Batch 130/145, Loss: 0.2107
Epoch 3/10, Batch 140/145, Loss: 0.2375
Epoch 3/10, Train Loss: 0.3090, Valid Loss: 0.2793
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1692
Epoch 4/10, Batch 20/145, Loss: 0.2302
Epoch 4/10, Batch 30/145, Loss: 0.2837
Epoch 4/10, Batch 40/145, Loss: 0.3891
Epoch 4/10, Batch 50/145, Loss: 0.0970
Epoch 4/10, Batch 60/145, Loss: 0.3247
Epoch 4/10, Batch 70/145, Loss: 0.2130
Epoch 4/10, Batch 80/145, Loss: 0.2241
Epoch 4/10, Batch 90/145, Loss: 0.2909
Epoch 4/10, Batch 100/145, Loss: 0.1636
Epoch 4/10, Batch 110/145, Loss: 0.3247
Epoch 4/10, Batch 120/145, Loss: 0.1400
Epoch 4/10, Batch 130/145, Loss: 0.1711
Epoch 4/10, Batch 140/145, Loss: 0.2218
Epoch 4/10, Train Loss: 0.2673, Valid Loss: 0.2709
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1761
Epoch 5/10, Batch 20/145, Loss: 0.2304
Epoch 5/10, Batch 30/145, Loss: 0.1261
Epoch 5/10, Batch 40/145, Loss: 0.2421
Epoch 5/10, Batch 50/145, Loss: 0.1163
Epoch 5/10, Batch 60/145, Loss: 0.2319
Epoch 5/10, Batch 70/145, Loss: 0.4366
Epoch 5/10, Batch 80/145, Loss: 0.3438
Epoch 5/10, Batch 90/145, Loss: 0.2066
Epoch 5/10, Batch 100/145, Loss: 0.2236
Epoch 5/10, Batch 110/145, Loss: 0.2057
Epoch 5/10, Batch 120/145, Loss: 0.2622
Epoch 5/10, Batch 130/145, Loss: 0.2057
Epoch 5/10, Batch 140/145, Loss: 0.2359
Epoch 5/10, Train Loss: 0.2421, Valid Loss: 0.2529
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2290
Epoch 6/10, Batch 20/145, Loss: 0.3014
Epoch 6/10, Batch 30/145, Loss: 0.2238
Epoch 6/10, Batch 40/145, Loss: 0.0746
Epoch 6/10, Batch 50/145, Loss: 0.2683
Epoch 6/10, Batch 60/145, Loss: 0.1906
Epoch 6/10, Batch 70/145, Loss: 0.3025
Epoch 6/10, Batch 80/145, Loss: 0.3086
Epoch 6/10, Batch 90/145, Loss: 0.1611
Epoch 6/10, Batch 100/145, Loss: 0.1873
Epoch 6/10, Batch 110/145, Loss: 0.1795
Epoch 6/10, Batch 120/145, Loss: 0.4661
Epoch 6/10, Batch 130/145, Loss: 0.1610
Epoch 6/10, Batch 140/145, Loss: 0.2905
Epoch 6/10, Train Loss: 0.2306, Valid Loss: 0.2431
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1922
Epoch 7/10, Batch 20/145, Loss: 0.1345
Epoch 7/10, Batch 30/145, Loss: 0.2637
Epoch 7/10, Batch 40/145, Loss: 0.2339
Epoch 7/10, Batch 50/145, Loss: 0.1316
Epoch 7/10, Batch 60/145, Loss: 0.1099
Epoch 7/10, Batch 70/145, Loss: 0.1954
Epoch 7/10, Batch 80/145, Loss: 0.1242
Epoch 7/10, Batch 90/145, Loss: 0.2617
Epoch 7/10, Batch 100/145, Loss: 0.1642
Epoch 7/10, Batch 110/145, Loss: 0.2621
Epoch 7/10, Batch 120/145, Loss: 0.2227
Epoch 7/10, Batch 130/145, Loss: 0.1670
Epoch 7/10, Batch 140/145, Loss: 0.1855
Epoch 7/10, Train Loss: 0.2162, Valid Loss: 0.2404
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2052
Epoch 8/10, Batch 20/145, Loss: 0.1253
Epoch 8/10, Batch 30/145, Loss: 0.2119
Epoch 8/10, Batch 40/145, Loss: 0.1860
Epoch 8/10, Batch 50/145, Loss: 0.1841
Epoch 8/10, Batch 60/145, Loss: 0.1789
Epoch 8/10, Batch 70/145, Loss: 0.1132
Epoch 8/10, Batch 80/145, Loss: 0.2110
Epoch 8/10, Batch 90/145, Loss: 0.2592
Epoch 8/10, Batch 100/145, Loss: 0.2612
Epoch 8/10, Batch 110/145, Loss: 0.2035
Epoch 8/10, Batch 120/145, Loss: 0.3099
Epoch 8/10, Batch 130/145, Loss: 0.3085
Epoch 8/10, Batch 140/145, Loss: 0.3899
Epoch 8/10, Train Loss: 0.2109, Valid Loss: 0.2397
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3501
Epoch 9/10, Batch 20/145, Loss: 0.2097
Epoch 9/10, Batch 30/145, Loss: 0.2290
Epoch 9/10, Batch 40/145, Loss: 0.2369
Epoch 9/10, Batch 50/145, Loss: 0.3539
Epoch 9/10, Batch 60/145, Loss: 0.1752
Epoch 9/10, Batch 70/145, Loss: 0.1122
Epoch 9/10, Batch 80/145, Loss: 0.2590
Epoch 9/10, Batch 90/145, Loss: 0.1321
Epoch 9/10, Batch 100/145, Loss: 0.1949
Epoch 9/10, Batch 110/145, Loss: 0.0841
Epoch 9/10, Batch 120/145, Loss: 0.1549
Epoch 9/10, Batch 130/145, Loss: 0.0723
Epoch 9/10, Batch 140/145, Loss: 0.1725
Epoch 9/10, Train Loss: 0.2071, Valid Loss: 0.2254
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1711
Epoch 10/10, Batch 20/145, Loss: 0.1726
Epoch 10/10, Batch 30/145, Loss: 0.1228
Epoch 10/10, Batch 40/145, Loss: 0.1839
Epoch 10/10, Batch 50/145, Loss: 0.2549
Epoch 10/10, Batch 60/145, Loss: 0.1896
Epoch 10/10, Batch 70/145, Loss: 0.1758
Epoch 10/10, Batch 80/145, Loss: 0.4147
Epoch 10/10, Batch 90/145, Loss: 0.2784
Epoch 10/10, Batch 100/145, Loss: 0.2735
Epoch 10/10, Batch 110/145, Loss: 0.2442
Epoch 10/10, Batch 120/145, Loss: 0.2077
Epoch 10/10, Batch 130/145, Loss: 0.2429
Epoch 10/10, Batch 140/145, Loss: 0.1302
Epoch 10/10, Train Loss: 0.1963, Valid Loss: 0.2230
Model saved!
Accuracy: 0.9276
Precision: 0.9261
Recall: 0.9276
F1-score: 0.9267
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 4. Fitness: 0.9276
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4797
Epoch 1/10, Batch 20/145, Loss: 0.8795
Epoch 1/10, Batch 30/145, Loss: 0.8113
Epoch 1/10, Batch 40/145, Loss: 0.7884
Epoch 1/10, Batch 50/145, Loss: 0.6457
Epoch 1/10, Batch 60/145, Loss: 0.6235
Epoch 1/10, Batch 70/145, Loss: 0.5477
Epoch 1/10, Batch 80/145, Loss: 0.6255
Epoch 1/10, Batch 90/145, Loss: 0.4681
Epoch 1/10, Batch 100/145, Loss: 0.6033
Epoch 1/10, Batch 110/145, Loss: 0.3865
Epoch 1/10, Batch 120/145, Loss: 0.5309
Epoch 1/10, Batch 130/145, Loss: 0.3145
Epoch 1/10, Batch 140/145, Loss: 0.3160
Epoch 1/10, Train Loss: 0.6887, Valid Loss: 0.3843
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3191
Epoch 2/10, Batch 20/145, Loss: 0.3874
Epoch 2/10, Batch 30/145, Loss: 0.2211
Epoch 2/10, Batch 40/145, Loss: 0.5045
Epoch 2/10, Batch 50/145, Loss: 0.2724
Epoch 2/10, Batch 60/145, Loss: 0.4213
Epoch 2/10, Batch 70/145, Loss: 0.3975
Epoch 2/10, Batch 80/145, Loss: 0.4204
Epoch 2/10, Batch 90/145, Loss: 0.2844
Epoch 2/10, Batch 100/145, Loss: 0.5005
Epoch 2/10, Batch 110/145, Loss: 0.3285
Epoch 2/10, Batch 120/145, Loss: 0.4355
Epoch 2/10, Batch 130/145, Loss: 0.2831
Epoch 2/10, Batch 140/145, Loss: 0.2872
Epoch 2/10, Train Loss: 0.3650, Valid Loss: 0.2937
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1773
Epoch 3/10, Batch 20/145, Loss: 0.2293
Epoch 3/10, Batch 30/145, Loss: 0.2255
Epoch 3/10, Batch 40/145, Loss: 0.2213
Epoch 3/10, Batch 50/145, Loss: 0.1271
Epoch 3/10, Batch 60/145, Loss: 0.3300
Epoch 3/10, Batch 70/145, Loss: 0.1725
Epoch 3/10, Batch 80/145, Loss: 0.3632
Epoch 3/10, Batch 90/145, Loss: 0.5458
Epoch 3/10, Batch 100/145, Loss: 0.1610
Epoch 3/10, Batch 110/145, Loss: 0.2945
Epoch 3/10, Batch 120/145, Loss: 0.2736
Epoch 3/10, Batch 130/145, Loss: 0.2176
Epoch 3/10, Batch 140/145, Loss: 0.1455
Epoch 3/10, Train Loss: 0.3116, Valid Loss: 0.2597
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2306
Epoch 4/10, Batch 20/145, Loss: 0.2437
Epoch 4/10, Batch 30/145, Loss: 0.2864
Epoch 4/10, Batch 40/145, Loss: 0.2204
Epoch 4/10, Batch 50/145, Loss: 0.2602
Epoch 4/10, Batch 60/145, Loss: 0.2615
Epoch 4/10, Batch 70/145, Loss: 0.1801
Epoch 4/10, Batch 80/145, Loss: 0.2608
Epoch 4/10, Batch 90/145, Loss: 0.3015
Epoch 4/10, Batch 100/145, Loss: 0.3905
Epoch 4/10, Batch 110/145, Loss: 0.1850
Epoch 4/10, Batch 120/145, Loss: 0.2246
Epoch 4/10, Batch 130/145, Loss: 0.2380
Epoch 4/10, Batch 140/145, Loss: 0.1587
Epoch 4/10, Train Loss: 0.2631, Valid Loss: 0.2562
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2555
Epoch 5/10, Batch 20/145, Loss: 0.1452
Epoch 5/10, Batch 30/145, Loss: 0.1995
Epoch 5/10, Batch 40/145, Loss: 0.2756
Epoch 5/10, Batch 50/145, Loss: 0.1835
Epoch 5/10, Batch 60/145, Loss: 0.1554
Epoch 5/10, Batch 70/145, Loss: 0.2513
Epoch 5/10, Batch 80/145, Loss: 0.2600
Epoch 5/10, Batch 90/145, Loss: 0.2857
Epoch 5/10, Batch 100/145, Loss: 0.1733
Epoch 5/10, Batch 110/145, Loss: 0.1500
Epoch 5/10, Batch 120/145, Loss: 0.2445
Epoch 5/10, Batch 130/145, Loss: 0.1431
Epoch 5/10, Batch 140/145, Loss: 0.3677
Epoch 5/10, Train Loss: 0.2424, Valid Loss: 0.2413
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2025
Epoch 6/10, Batch 20/145, Loss: 0.2769
Epoch 6/10, Batch 30/145, Loss: 0.1759
Epoch 6/10, Batch 40/145, Loss: 0.1471
Epoch 6/10, Batch 50/145, Loss: 0.2545
Epoch 6/10, Batch 60/145, Loss: 0.1645
Epoch 6/10, Batch 70/145, Loss: 0.1457
Epoch 6/10, Batch 80/145, Loss: 0.3653
Epoch 6/10, Batch 90/145, Loss: 0.2138
Epoch 6/10, Batch 100/145, Loss: 0.1792
Epoch 6/10, Batch 110/145, Loss: 0.2922
Epoch 6/10, Batch 120/145, Loss: 0.1540
Epoch 6/10, Batch 130/145, Loss: 0.1292
Epoch 6/10, Batch 140/145, Loss: 0.1905
Epoch 6/10, Train Loss: 0.2271, Valid Loss: 0.2349
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2084
Epoch 7/10, Batch 20/145, Loss: 0.2302
Epoch 7/10, Batch 30/145, Loss: 0.0832
Epoch 7/10, Batch 40/145, Loss: 0.5131
Epoch 7/10, Batch 50/145, Loss: 0.1198
Epoch 7/10, Batch 60/145, Loss: 0.1057
Epoch 7/10, Batch 70/145, Loss: 0.3203
Epoch 7/10, Batch 80/145, Loss: 0.1370
Epoch 7/10, Batch 90/145, Loss: 0.2339
Epoch 7/10, Batch 100/145, Loss: 0.0614
Epoch 7/10, Batch 110/145, Loss: 0.2464
Epoch 7/10, Batch 120/145, Loss: 0.1300
Epoch 7/10, Batch 130/145, Loss: 0.2169
Epoch 7/10, Batch 140/145, Loss: 0.2285
Epoch 7/10, Train Loss: 0.2145, Valid Loss: 0.2234
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1083
Epoch 8/10, Batch 20/145, Loss: 0.0860
Epoch 8/10, Batch 30/145, Loss: 0.1327
Epoch 8/10, Batch 40/145, Loss: 0.2431
Epoch 8/10, Batch 50/145, Loss: 0.2797
Epoch 8/10, Batch 60/145, Loss: 0.1874
Epoch 8/10, Batch 70/145, Loss: 0.2742
Epoch 8/10, Batch 80/145, Loss: 0.1899
Epoch 8/10, Batch 90/145, Loss: 0.1735
Epoch 8/10, Batch 100/145, Loss: 0.1263
Epoch 8/10, Batch 110/145, Loss: 0.2288
Epoch 8/10, Batch 120/145, Loss: 0.0782
Epoch 8/10, Batch 130/145, Loss: 0.2107
Epoch 8/10, Batch 140/145, Loss: 0.2314
Epoch 8/10, Train Loss: 0.2157, Valid Loss: 0.2153
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1465
Epoch 9/10, Batch 20/145, Loss: 0.1185
Epoch 9/10, Batch 30/145, Loss: 0.1161
Epoch 9/10, Batch 40/145, Loss: 0.2529
Epoch 9/10, Batch 50/145, Loss: 0.1800
Epoch 9/10, Batch 60/145, Loss: 0.1542
Epoch 9/10, Batch 70/145, Loss: 0.2521
Epoch 9/10, Batch 80/145, Loss: 0.3463
Epoch 9/10, Batch 90/145, Loss: 0.0838
Epoch 9/10, Batch 100/145, Loss: 0.3119
Epoch 9/10, Batch 110/145, Loss: 0.0886
Epoch 9/10, Batch 120/145, Loss: 0.1359
Epoch 9/10, Batch 130/145, Loss: 0.2203
Epoch 9/10, Batch 140/145, Loss: 0.0618
Epoch 9/10, Train Loss: 0.2040, Valid Loss: 0.2102
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1782
Epoch 10/10, Batch 20/145, Loss: 0.1572
Epoch 10/10, Batch 30/145, Loss: 0.1337
Epoch 10/10, Batch 40/145, Loss: 0.2875
Epoch 10/10, Batch 50/145, Loss: 0.1326
Epoch 10/10, Batch 60/145, Loss: 0.1104
Epoch 10/10, Batch 70/145, Loss: 0.1492
Epoch 10/10, Batch 80/145, Loss: 0.4559
Epoch 10/10, Batch 90/145, Loss: 0.1355
Epoch 10/10, Batch 100/145, Loss: 0.1556
Epoch 10/10, Batch 110/145, Loss: 0.2860
Epoch 10/10, Batch 120/145, Loss: 0.1305
Epoch 10/10, Batch 130/145, Loss: 0.1519
Epoch 10/10, Batch 140/145, Loss: 0.1561
Epoch 10/10, Train Loss: 0.2004, Valid Loss: 0.2065
Model saved!
Accuracy: 0.9287
Precision: 0.9269
Recall: 0.9287
F1-score: 0.9274
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 5. Fitness: 0.9287
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4508
Epoch 1/10, Batch 20/145, Loss: 0.8553
Epoch 1/10, Batch 30/145, Loss: 0.8413
Epoch 1/10, Batch 40/145, Loss: 0.8976
Epoch 1/10, Batch 50/145, Loss: 0.6491
Epoch 1/10, Batch 60/145, Loss: 0.5713
Epoch 1/10, Batch 70/145, Loss: 0.6413
Epoch 1/10, Batch 80/145, Loss: 0.5587
Epoch 1/10, Batch 90/145, Loss: 0.5635
Epoch 1/10, Batch 100/145, Loss: 0.4719
Epoch 1/10, Batch 110/145, Loss: 0.4215
Epoch 1/10, Batch 120/145, Loss: 0.5630
Epoch 1/10, Batch 130/145, Loss: 0.3708
Epoch 1/10, Batch 140/145, Loss: 0.3115
Epoch 1/10, Train Loss: 0.6783, Valid Loss: 0.3993
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2793
Epoch 2/10, Batch 20/145, Loss: 0.4840
Epoch 2/10, Batch 30/145, Loss: 0.3370
Epoch 2/10, Batch 40/145, Loss: 0.3535
Epoch 2/10, Batch 50/145, Loss: 0.2546
Epoch 2/10, Batch 60/145, Loss: 0.6471
Epoch 2/10, Batch 70/145, Loss: 0.3902
Epoch 2/10, Batch 80/145, Loss: 0.4830
Epoch 2/10, Batch 90/145, Loss: 0.4161
Epoch 2/10, Batch 100/145, Loss: 0.3481
Epoch 2/10, Batch 110/145, Loss: 0.2348
Epoch 2/10, Batch 120/145, Loss: 0.2866
Epoch 2/10, Batch 130/145, Loss: 0.3671
Epoch 2/10, Batch 140/145, Loss: 0.1814
Epoch 2/10, Train Loss: 0.3539, Valid Loss: 0.3112
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1897
Epoch 3/10, Batch 20/145, Loss: 0.3798
Epoch 3/10, Batch 30/145, Loss: 0.2568
Epoch 3/10, Batch 40/145, Loss: 0.2918
Epoch 3/10, Batch 50/145, Loss: 0.1596
Epoch 3/10, Batch 60/145, Loss: 0.3114
Epoch 3/10, Batch 70/145, Loss: 0.3570
Epoch 3/10, Batch 80/145, Loss: 0.1862
Epoch 3/10, Batch 90/145, Loss: 0.4403
Epoch 3/10, Batch 100/145, Loss: 0.2763
Epoch 3/10, Batch 110/145, Loss: 0.1740
Epoch 3/10, Batch 120/145, Loss: 0.1238
Epoch 3/10, Batch 130/145, Loss: 0.2124
Epoch 3/10, Batch 140/145, Loss: 0.2022
Epoch 3/10, Train Loss: 0.3006, Valid Loss: 0.2845
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2172
Epoch 4/10, Batch 20/145, Loss: 0.2707
Epoch 4/10, Batch 30/145, Loss: 0.3115
Epoch 4/10, Batch 40/145, Loss: 0.4074
Epoch 4/10, Batch 50/145, Loss: 0.1487
Epoch 4/10, Batch 60/145, Loss: 0.3639
Epoch 4/10, Batch 70/145, Loss: 0.2677
Epoch 4/10, Batch 80/145, Loss: 0.3061
Epoch 4/10, Batch 90/145, Loss: 0.3033
Epoch 4/10, Batch 100/145, Loss: 0.1951
Epoch 4/10, Batch 110/145, Loss: 0.3022
Epoch 4/10, Batch 120/145, Loss: 0.4255
Epoch 4/10, Batch 130/145, Loss: 0.1635
Epoch 4/10, Batch 140/145, Loss: 0.2809
Epoch 4/10, Train Loss: 0.2593, Valid Loss: 0.2643
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2877
Epoch 5/10, Batch 20/145, Loss: 0.1906
Epoch 5/10, Batch 30/145, Loss: 0.2257
Epoch 5/10, Batch 40/145, Loss: 0.3449
Epoch 5/10, Batch 50/145, Loss: 0.0789
Epoch 5/10, Batch 60/145, Loss: 0.2120
Epoch 5/10, Batch 70/145, Loss: 0.1831
Epoch 5/10, Batch 80/145, Loss: 0.4141
Epoch 5/10, Batch 90/145, Loss: 0.2445
Epoch 5/10, Batch 100/145, Loss: 0.2315
Epoch 5/10, Batch 110/145, Loss: 0.2010
Epoch 5/10, Batch 120/145, Loss: 0.2087
Epoch 5/10, Batch 130/145, Loss: 0.2086
Epoch 5/10, Batch 140/145, Loss: 0.1866
Epoch 5/10, Train Loss: 0.2341, Valid Loss: 0.2565
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1219
Epoch 6/10, Batch 20/145, Loss: 0.1671
Epoch 6/10, Batch 30/145, Loss: 0.1593
Epoch 6/10, Batch 40/145, Loss: 0.0905
Epoch 6/10, Batch 50/145, Loss: 0.3140
Epoch 6/10, Batch 60/145, Loss: 0.1939
Epoch 6/10, Batch 70/145, Loss: 0.3716
Epoch 6/10, Batch 80/145, Loss: 0.3721
Epoch 6/10, Batch 90/145, Loss: 0.2004
Epoch 6/10, Batch 100/145, Loss: 0.2218
Epoch 6/10, Batch 110/145, Loss: 0.1963
Epoch 6/10, Batch 120/145, Loss: 0.3112
Epoch 6/10, Batch 130/145, Loss: 0.1552
Epoch 6/10, Batch 140/145, Loss: 0.3230
Epoch 6/10, Train Loss: 0.2234, Valid Loss: 0.2490
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3778
Epoch 7/10, Batch 20/145, Loss: 0.2197
Epoch 7/10, Batch 30/145, Loss: 0.1831
Epoch 7/10, Batch 40/145, Loss: 0.3733
Epoch 7/10, Batch 50/145, Loss: 0.1758
Epoch 7/10, Batch 60/145, Loss: 0.1490
Epoch 7/10, Batch 70/145, Loss: 0.4139
Epoch 7/10, Batch 80/145, Loss: 0.1057
Epoch 7/10, Batch 90/145, Loss: 0.1457
Epoch 7/10, Batch 100/145, Loss: 0.1862
Epoch 7/10, Batch 110/145, Loss: 0.3726
Epoch 7/10, Batch 120/145, Loss: 0.1659
Epoch 7/10, Batch 130/145, Loss: 0.2339
Epoch 7/10, Batch 140/145, Loss: 0.0713
Epoch 7/10, Train Loss: 0.2145, Valid Loss: 0.2492
Epoch 8/10, Batch 10/145, Loss: 0.1540
Epoch 8/10, Batch 20/145, Loss: 0.1421
Epoch 8/10, Batch 30/145, Loss: 0.1750
Epoch 8/10, Batch 40/145, Loss: 0.1317
Epoch 8/10, Batch 50/145, Loss: 0.1735
Epoch 8/10, Batch 60/145, Loss: 0.2540
Epoch 8/10, Batch 70/145, Loss: 0.3411
Epoch 8/10, Batch 80/145, Loss: 0.1857
Epoch 8/10, Batch 90/145, Loss: 0.0685
Epoch 8/10, Batch 100/145, Loss: 0.2365
Epoch 8/10, Batch 110/145, Loss: 0.3863
Epoch 8/10, Batch 120/145, Loss: 0.2004
Epoch 8/10, Batch 130/145, Loss: 0.0836
Epoch 8/10, Batch 140/145, Loss: 0.2692
Epoch 8/10, Train Loss: 0.2050, Valid Loss: 0.2390
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2811
Epoch 9/10, Batch 20/145, Loss: 0.0895
Epoch 9/10, Batch 30/145, Loss: 0.2178
Epoch 9/10, Batch 40/145, Loss: 0.2283
Epoch 9/10, Batch 50/145, Loss: 0.2782
Epoch 9/10, Batch 60/145, Loss: 0.2154
Epoch 9/10, Batch 70/145, Loss: 0.2511
Epoch 9/10, Batch 80/145, Loss: 0.2393
Epoch 9/10, Batch 90/145, Loss: 0.1271
Epoch 9/10, Batch 100/145, Loss: 0.2720
Epoch 9/10, Batch 110/145, Loss: 0.1025
Epoch 9/10, Batch 120/145, Loss: 0.2480
Epoch 9/10, Batch 130/145, Loss: 0.2309
Epoch 9/10, Batch 140/145, Loss: 0.2073
Epoch 9/10, Train Loss: 0.2054, Valid Loss: 0.2272
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2107
Epoch 10/10, Batch 20/145, Loss: 0.1519
Epoch 10/10, Batch 30/145, Loss: 0.1053
Epoch 10/10, Batch 40/145, Loss: 0.1804
Epoch 10/10, Batch 50/145, Loss: 0.3513
Epoch 10/10, Batch 60/145, Loss: 0.1340
Epoch 10/10, Batch 70/145, Loss: 0.1567
Epoch 10/10, Batch 80/145, Loss: 0.3451
Epoch 10/10, Batch 90/145, Loss: 0.2727
Epoch 10/10, Batch 100/145, Loss: 0.1941
Epoch 10/10, Batch 110/145, Loss: 0.2194
Epoch 10/10, Batch 120/145, Loss: 0.2293
Epoch 10/10, Batch 130/145, Loss: 0.3162
Epoch 10/10, Batch 140/145, Loss: 0.1442
Epoch 10/10, Train Loss: 0.1905, Valid Loss: 0.2216
Model saved!
Accuracy: 0.9171
Precision: 0.9168
Recall: 0.9171
F1-score: 0.9164
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5744
Epoch 1/10, Batch 20/145, Loss: 0.8745
Epoch 1/10, Batch 30/145, Loss: 0.9242
Epoch 1/10, Batch 40/145, Loss: 0.7713
Epoch 1/10, Batch 50/145, Loss: 0.5943
Epoch 1/10, Batch 60/145, Loss: 0.5686
Epoch 1/10, Batch 70/145, Loss: 0.5765
Epoch 1/10, Batch 80/145, Loss: 0.5662
Epoch 1/10, Batch 90/145, Loss: 0.5599
Epoch 1/10, Batch 100/145, Loss: 0.4843
Epoch 1/10, Batch 110/145, Loss: 0.3724
Epoch 1/10, Batch 120/145, Loss: 0.5119
Epoch 1/10, Batch 130/145, Loss: 0.3760
Epoch 1/10, Batch 140/145, Loss: 0.2476
Epoch 1/10, Train Loss: 0.6851, Valid Loss: 0.3702
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3746
Epoch 2/10, Batch 20/145, Loss: 0.5703
Epoch 2/10, Batch 30/145, Loss: 0.2913
Epoch 2/10, Batch 40/145, Loss: 0.4411
Epoch 2/10, Batch 50/145, Loss: 0.4738
Epoch 2/10, Batch 60/145, Loss: 0.3329
Epoch 2/10, Batch 70/145, Loss: 0.4085
Epoch 2/10, Batch 80/145, Loss: 0.2641
Epoch 2/10, Batch 90/145, Loss: 0.2684
Epoch 2/10, Batch 100/145, Loss: 0.1803
Epoch 2/10, Batch 110/145, Loss: 0.2282
Epoch 2/10, Batch 120/145, Loss: 0.4441
Epoch 2/10, Batch 130/145, Loss: 0.3360
Epoch 2/10, Batch 140/145, Loss: 0.3518
Epoch 2/10, Train Loss: 0.3580, Valid Loss: 0.2903
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3536
Epoch 3/10, Batch 20/145, Loss: 0.2284
Epoch 3/10, Batch 30/145, Loss: 0.2324
Epoch 3/10, Batch 40/145, Loss: 0.2333
Epoch 3/10, Batch 50/145, Loss: 0.2143
Epoch 3/10, Batch 60/145, Loss: 0.3058
Epoch 3/10, Batch 70/145, Loss: 0.2412
Epoch 3/10, Batch 80/145, Loss: 0.2901
Epoch 3/10, Batch 90/145, Loss: 0.6101
Epoch 3/10, Batch 100/145, Loss: 0.3372
Epoch 3/10, Batch 110/145, Loss: 0.3888
Epoch 3/10, Batch 120/145, Loss: 0.3009
Epoch 3/10, Batch 130/145, Loss: 0.2184
Epoch 3/10, Batch 140/145, Loss: 0.4518
Epoch 3/10, Train Loss: 0.3073, Valid Loss: 0.2569
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2736
Epoch 4/10, Batch 20/145, Loss: 0.2993
Epoch 4/10, Batch 30/145, Loss: 0.4616
Epoch 4/10, Batch 40/145, Loss: 0.3949
Epoch 4/10, Batch 50/145, Loss: 0.2418
Epoch 4/10, Batch 60/145, Loss: 0.2393
Epoch 4/10, Batch 70/145, Loss: 0.2534
Epoch 4/10, Batch 80/145, Loss: 0.3523
Epoch 4/10, Batch 90/145, Loss: 0.2591
Epoch 4/10, Batch 100/145, Loss: 0.1724
Epoch 4/10, Batch 110/145, Loss: 0.1574
Epoch 4/10, Batch 120/145, Loss: 0.2839
Epoch 4/10, Batch 130/145, Loss: 0.1588
Epoch 4/10, Batch 140/145, Loss: 0.1709
Epoch 4/10, Train Loss: 0.2586, Valid Loss: 0.2530
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1548
Epoch 5/10, Batch 20/145, Loss: 0.3235
Epoch 5/10, Batch 30/145, Loss: 0.1268
Epoch 5/10, Batch 40/145, Loss: 0.1907
Epoch 5/10, Batch 50/145, Loss: 0.1509
Epoch 5/10, Batch 60/145, Loss: 0.3047
Epoch 5/10, Batch 70/145, Loss: 0.3812
Epoch 5/10, Batch 80/145, Loss: 0.3128
Epoch 5/10, Batch 90/145, Loss: 0.1298
Epoch 5/10, Batch 100/145, Loss: 0.3130
Epoch 5/10, Batch 110/145, Loss: 0.1335
Epoch 5/10, Batch 120/145, Loss: 0.1411
Epoch 5/10, Batch 130/145, Loss: 0.2089
Epoch 5/10, Batch 140/145, Loss: 0.2963
Epoch 5/10, Train Loss: 0.2335, Valid Loss: 0.2507
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1718
Epoch 6/10, Batch 20/145, Loss: 0.2676
Epoch 6/10, Batch 30/145, Loss: 0.2721
Epoch 6/10, Batch 40/145, Loss: 0.1841
Epoch 6/10, Batch 50/145, Loss: 0.2361
Epoch 6/10, Batch 60/145, Loss: 0.1307
Epoch 6/10, Batch 70/145, Loss: 0.2610
Epoch 6/10, Batch 80/145, Loss: 0.3608
Epoch 6/10, Batch 90/145, Loss: 0.3206
Epoch 6/10, Batch 100/145, Loss: 0.4831
Epoch 6/10, Batch 110/145, Loss: 0.1168
Epoch 6/10, Batch 120/145, Loss: 0.2877
Epoch 6/10, Batch 130/145, Loss: 0.1722
Epoch 6/10, Batch 140/145, Loss: 0.3727
Epoch 6/10, Train Loss: 0.2294, Valid Loss: 0.2382
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3374
Epoch 7/10, Batch 20/145, Loss: 0.1429
Epoch 7/10, Batch 30/145, Loss: 0.2581
Epoch 7/10, Batch 40/145, Loss: 0.4429
Epoch 7/10, Batch 50/145, Loss: 0.1955
Epoch 7/10, Batch 60/145, Loss: 0.2265
Epoch 7/10, Batch 70/145, Loss: 0.2532
Epoch 7/10, Batch 80/145, Loss: 0.1779
Epoch 7/10, Batch 90/145, Loss: 0.1741
Epoch 7/10, Batch 100/145, Loss: 0.2597
Epoch 7/10, Batch 110/145, Loss: 0.3210
Epoch 7/10, Batch 120/145, Loss: 0.2416
Epoch 7/10, Batch 130/145, Loss: 0.1073
Epoch 7/10, Batch 140/145, Loss: 0.1063
Epoch 7/10, Train Loss: 0.2158, Valid Loss: 0.2251
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1396
Epoch 8/10, Batch 20/145, Loss: 0.1410
Epoch 8/10, Batch 30/145, Loss: 0.1603
Epoch 8/10, Batch 40/145, Loss: 0.1792
Epoch 8/10, Batch 50/145, Loss: 0.2962
Epoch 8/10, Batch 60/145, Loss: 0.2108
Epoch 8/10, Batch 70/145, Loss: 0.1184
Epoch 8/10, Batch 80/145, Loss: 0.1601
Epoch 8/10, Batch 90/145, Loss: 0.1902
Epoch 8/10, Batch 100/145, Loss: 0.1824
Epoch 8/10, Batch 110/145, Loss: 0.2692
Epoch 8/10, Batch 120/145, Loss: 0.1971
Epoch 8/10, Batch 130/145, Loss: 0.1506
Epoch 8/10, Batch 140/145, Loss: 0.1786
Epoch 8/10, Train Loss: 0.2046, Valid Loss: 0.2184
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2689
Epoch 9/10, Batch 20/145, Loss: 0.0828
Epoch 9/10, Batch 30/145, Loss: 0.0884
Epoch 9/10, Batch 40/145, Loss: 0.1839
Epoch 9/10, Batch 50/145, Loss: 0.1372
Epoch 9/10, Batch 60/145, Loss: 0.3049
Epoch 9/10, Batch 70/145, Loss: 0.1603
Epoch 9/10, Batch 80/145, Loss: 0.1603
Epoch 9/10, Batch 90/145, Loss: 0.1652
Epoch 9/10, Batch 100/145, Loss: 0.1881
Epoch 9/10, Batch 110/145, Loss: 0.1170
Epoch 9/10, Batch 120/145, Loss: 0.3472
Epoch 9/10, Batch 130/145, Loss: 0.4109
Epoch 9/10, Batch 140/145, Loss: 0.0734
Epoch 9/10, Train Loss: 0.2034, Valid Loss: 0.2101
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0601
Epoch 10/10, Batch 20/145, Loss: 0.2069
Epoch 10/10, Batch 30/145, Loss: 0.1095
Epoch 10/10, Batch 40/145, Loss: 0.3081
Epoch 10/10, Batch 50/145, Loss: 0.2188
Epoch 10/10, Batch 60/145, Loss: 0.2011
Epoch 10/10, Batch 70/145, Loss: 0.2595
Epoch 10/10, Batch 80/145, Loss: 0.2791
Epoch 10/10, Batch 90/145, Loss: 0.0789
Epoch 10/10, Batch 100/145, Loss: 0.0967
Epoch 10/10, Batch 110/145, Loss: 0.1565
Epoch 10/10, Batch 120/145, Loss: 0.2598
Epoch 10/10, Batch 130/145, Loss: 0.1116
Epoch 10/10, Batch 140/145, Loss: 0.2078
Epoch 10/10, Train Loss: 0.1898, Valid Loss: 0.2153
Accuracy: 0.9182
Precision: 0.9169
Recall: 0.9182
F1-score: 0.9171
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4317
Epoch 1/10, Batch 20/145, Loss: 0.9070
Epoch 1/10, Batch 30/145, Loss: 0.8876
Epoch 1/10, Batch 40/145, Loss: 0.7407
Epoch 1/10, Batch 50/145, Loss: 0.5675
Epoch 1/10, Batch 60/145, Loss: 0.6849
Epoch 1/10, Batch 70/145, Loss: 0.7086
Epoch 1/10, Batch 80/145, Loss: 0.5649
Epoch 1/10, Batch 90/145, Loss: 0.7045
Epoch 1/10, Batch 100/145, Loss: 0.5168
Epoch 1/10, Batch 110/145, Loss: 0.4059
Epoch 1/10, Batch 120/145, Loss: 0.5588
Epoch 1/10, Batch 130/145, Loss: 0.5862
Epoch 1/10, Batch 140/145, Loss: 0.4400
Epoch 1/10, Train Loss: 0.6855, Valid Loss: 0.3524
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3310
Epoch 2/10, Batch 20/145, Loss: 0.6581
Epoch 2/10, Batch 30/145, Loss: 0.3294
Epoch 2/10, Batch 40/145, Loss: 0.4111
Epoch 2/10, Batch 50/145, Loss: 0.3445
Epoch 2/10, Batch 60/145, Loss: 0.4062
Epoch 2/10, Batch 70/145, Loss: 0.2932
Epoch 2/10, Batch 80/145, Loss: 0.5391
Epoch 2/10, Batch 90/145, Loss: 0.2198
Epoch 2/10, Batch 100/145, Loss: 0.2642
Epoch 2/10, Batch 110/145, Loss: 0.2749
Epoch 2/10, Batch 120/145, Loss: 0.5200
Epoch 2/10, Batch 130/145, Loss: 0.3148
Epoch 2/10, Batch 140/145, Loss: 0.2885
Epoch 2/10, Train Loss: 0.3634, Valid Loss: 0.2725
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2514
Epoch 3/10, Batch 20/145, Loss: 0.2421
Epoch 3/10, Batch 30/145, Loss: 0.3777
Epoch 3/10, Batch 40/145, Loss: 0.2567
Epoch 3/10, Batch 50/145, Loss: 0.2484
Epoch 3/10, Batch 60/145, Loss: 0.2926
Epoch 3/10, Batch 70/145, Loss: 0.2222
Epoch 3/10, Batch 80/145, Loss: 0.4776
Epoch 3/10, Batch 90/145, Loss: 0.4455
Epoch 3/10, Batch 100/145, Loss: 0.3209
Epoch 3/10, Batch 110/145, Loss: 0.2062
Epoch 3/10, Batch 120/145, Loss: 0.2653
Epoch 3/10, Batch 130/145, Loss: 0.2545
Epoch 3/10, Batch 140/145, Loss: 0.3635
Epoch 3/10, Train Loss: 0.3032, Valid Loss: 0.2375
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3065
Epoch 4/10, Batch 20/145, Loss: 0.3039
Epoch 4/10, Batch 30/145, Loss: 0.3286
Epoch 4/10, Batch 40/145, Loss: 0.2776
Epoch 4/10, Batch 50/145, Loss: 0.1500
Epoch 4/10, Batch 60/145, Loss: 0.3764
Epoch 4/10, Batch 70/145, Loss: 0.3366
Epoch 4/10, Batch 80/145, Loss: 0.2509
Epoch 4/10, Batch 90/145, Loss: 0.2736
Epoch 4/10, Batch 100/145, Loss: 0.3237
Epoch 4/10, Batch 110/145, Loss: 0.2041
Epoch 4/10, Batch 120/145, Loss: 0.1510
Epoch 4/10, Batch 130/145, Loss: 0.2366
Epoch 4/10, Batch 140/145, Loss: 0.2382
Epoch 4/10, Train Loss: 0.2581, Valid Loss: 0.2299
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3815
Epoch 5/10, Batch 20/145, Loss: 0.2156
Epoch 5/10, Batch 30/145, Loss: 0.2058
Epoch 5/10, Batch 40/145, Loss: 0.1942
Epoch 5/10, Batch 50/145, Loss: 0.1078
Epoch 5/10, Batch 60/145, Loss: 0.2660
Epoch 5/10, Batch 70/145, Loss: 0.3622
Epoch 5/10, Batch 80/145, Loss: 0.4454
Epoch 5/10, Batch 90/145, Loss: 0.3921
Epoch 5/10, Batch 100/145, Loss: 0.1663
Epoch 5/10, Batch 110/145, Loss: 0.1920
Epoch 5/10, Batch 120/145, Loss: 0.1918
Epoch 5/10, Batch 130/145, Loss: 0.2676
Epoch 5/10, Batch 140/145, Loss: 0.1894
Epoch 5/10, Train Loss: 0.2383, Valid Loss: 0.2109
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2691
Epoch 6/10, Batch 20/145, Loss: 0.2858
Epoch 6/10, Batch 30/145, Loss: 0.2331
Epoch 6/10, Batch 40/145, Loss: 0.1669
Epoch 6/10, Batch 50/145, Loss: 0.4228
Epoch 6/10, Batch 60/145, Loss: 0.1333
Epoch 6/10, Batch 70/145, Loss: 0.3239
Epoch 6/10, Batch 80/145, Loss: 0.1641
Epoch 6/10, Batch 90/145, Loss: 0.2102
Epoch 6/10, Batch 100/145, Loss: 0.1910
Epoch 6/10, Batch 110/145, Loss: 0.1979
Epoch 6/10, Batch 120/145, Loss: 0.2343
Epoch 6/10, Batch 130/145, Loss: 0.1922
Epoch 6/10, Batch 140/145, Loss: 0.2213
Epoch 6/10, Train Loss: 0.2306, Valid Loss: 0.2172
Epoch 7/10, Batch 10/145, Loss: 0.2096
Epoch 7/10, Batch 20/145, Loss: 0.3041
Epoch 7/10, Batch 30/145, Loss: 0.2013
Epoch 7/10, Batch 40/145, Loss: 0.3686
Epoch 7/10, Batch 50/145, Loss: 0.1640
Epoch 7/10, Batch 60/145, Loss: 0.1313
Epoch 7/10, Batch 70/145, Loss: 0.2379
Epoch 7/10, Batch 80/145, Loss: 0.2305
Epoch 7/10, Batch 90/145, Loss: 0.2410
Epoch 7/10, Batch 100/145, Loss: 0.1578
Epoch 7/10, Batch 110/145, Loss: 0.3318
Epoch 7/10, Batch 120/145, Loss: 0.1641
Epoch 7/10, Batch 130/145, Loss: 0.2348
Epoch 7/10, Batch 140/145, Loss: 0.1322
Epoch 7/10, Train Loss: 0.2200, Valid Loss: 0.1945
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1696
Epoch 8/10, Batch 20/145, Loss: 0.2944
Epoch 8/10, Batch 30/145, Loss: 0.0754
Epoch 8/10, Batch 40/145, Loss: 0.1965
Epoch 8/10, Batch 50/145, Loss: 0.1593
Epoch 8/10, Batch 60/145, Loss: 0.1409
Epoch 8/10, Batch 70/145, Loss: 0.1945
Epoch 8/10, Batch 80/145, Loss: 0.3476
Epoch 8/10, Batch 90/145, Loss: 0.2166
Epoch 8/10, Batch 100/145, Loss: 0.1744
Epoch 8/10, Batch 110/145, Loss: 0.2616
Epoch 8/10, Batch 120/145, Loss: 0.1258
Epoch 8/10, Batch 130/145, Loss: 0.1262
Epoch 8/10, Batch 140/145, Loss: 0.2788
Epoch 8/10, Train Loss: 0.2081, Valid Loss: 0.1942
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2236
Epoch 9/10, Batch 20/145, Loss: 0.2080
Epoch 9/10, Batch 30/145, Loss: 0.1496
Epoch 9/10, Batch 40/145, Loss: 0.1317
Epoch 9/10, Batch 50/145, Loss: 0.1466
Epoch 9/10, Batch 60/145, Loss: 0.1302
Epoch 9/10, Batch 70/145, Loss: 0.1059
Epoch 9/10, Batch 80/145, Loss: 0.2085
Epoch 9/10, Batch 90/145, Loss: 0.2042
Epoch 9/10, Batch 100/145, Loss: 0.2633
Epoch 9/10, Batch 110/145, Loss: 0.0921
Epoch 9/10, Batch 120/145, Loss: 0.2517
Epoch 9/10, Batch 130/145, Loss: 0.0801
Epoch 9/10, Batch 140/145, Loss: 0.2349
Epoch 9/10, Train Loss: 0.1994, Valid Loss: 0.1837
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2197
Epoch 10/10, Batch 20/145, Loss: 0.2328
Epoch 10/10, Batch 30/145, Loss: 0.2053
Epoch 10/10, Batch 40/145, Loss: 0.2381
Epoch 10/10, Batch 50/145, Loss: 0.3994
Epoch 10/10, Batch 60/145, Loss: 0.2811
Epoch 10/10, Batch 70/145, Loss: 0.2043
Epoch 10/10, Batch 80/145, Loss: 0.3296
Epoch 10/10, Batch 90/145, Loss: 0.1560
Epoch 10/10, Batch 100/145, Loss: 0.0820
Epoch 10/10, Batch 110/145, Loss: 0.3074
Epoch 10/10, Batch 120/145, Loss: 0.1116
Epoch 10/10, Batch 130/145, Loss: 0.1898
Epoch 10/10, Batch 140/145, Loss: 0.2276
Epoch 10/10, Train Loss: 0.2014, Valid Loss: 0.1759
Model saved!
Accuracy: 0.9287
Precision: 0.9283
Recall: 0.9287
F1-score: 0.9284
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4607
Epoch 1/10, Batch 20/145, Loss: 0.9411
Epoch 1/10, Batch 30/145, Loss: 0.8809
Epoch 1/10, Batch 40/145, Loss: 0.8006
Epoch 1/10, Batch 50/145, Loss: 0.6321
Epoch 1/10, Batch 60/145, Loss: 0.5816
Epoch 1/10, Batch 70/145, Loss: 0.6516
Epoch 1/10, Batch 80/145, Loss: 0.5076
Epoch 1/10, Batch 90/145, Loss: 0.5431
Epoch 1/10, Batch 100/145, Loss: 0.4773
Epoch 1/10, Batch 110/145, Loss: 0.3562
Epoch 1/10, Batch 120/145, Loss: 0.5646
Epoch 1/10, Batch 130/145, Loss: 0.5241
Epoch 1/10, Batch 140/145, Loss: 0.4908
Epoch 1/10, Train Loss: 0.6765, Valid Loss: 0.3885
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3734
Epoch 2/10, Batch 20/145, Loss: 0.5398
Epoch 2/10, Batch 30/145, Loss: 0.2580
Epoch 2/10, Batch 40/145, Loss: 0.5191
Epoch 2/10, Batch 50/145, Loss: 0.2285
Epoch 2/10, Batch 60/145, Loss: 0.3382
Epoch 2/10, Batch 70/145, Loss: 0.4287
Epoch 2/10, Batch 80/145, Loss: 0.3311
Epoch 2/10, Batch 90/145, Loss: 0.2282
Epoch 2/10, Batch 100/145, Loss: 0.3321
Epoch 2/10, Batch 110/145, Loss: 0.3785
Epoch 2/10, Batch 120/145, Loss: 0.4428
Epoch 2/10, Batch 130/145, Loss: 0.3324
Epoch 2/10, Batch 140/145, Loss: 0.3557
Epoch 2/10, Train Loss: 0.3538, Valid Loss: 0.3073
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2781
Epoch 3/10, Batch 20/145, Loss: 0.5670
Epoch 3/10, Batch 30/145, Loss: 0.1956
Epoch 3/10, Batch 40/145, Loss: 0.1860
Epoch 3/10, Batch 50/145, Loss: 0.3603
Epoch 3/10, Batch 60/145, Loss: 0.2705
Epoch 3/10, Batch 70/145, Loss: 0.3654
Epoch 3/10, Batch 80/145, Loss: 0.3264
Epoch 3/10, Batch 90/145, Loss: 0.4610
Epoch 3/10, Batch 100/145, Loss: 0.3590
Epoch 3/10, Batch 110/145, Loss: 0.2049
Epoch 3/10, Batch 120/145, Loss: 0.2713
Epoch 3/10, Batch 130/145, Loss: 0.2796
Epoch 3/10, Batch 140/145, Loss: 0.2301
Epoch 3/10, Train Loss: 0.3036, Valid Loss: 0.2777
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1608
Epoch 4/10, Batch 20/145, Loss: 0.2166
Epoch 4/10, Batch 30/145, Loss: 0.3353
Epoch 4/10, Batch 40/145, Loss: 0.3587
Epoch 4/10, Batch 50/145, Loss: 0.2759
Epoch 4/10, Batch 60/145, Loss: 0.1514
Epoch 4/10, Batch 70/145, Loss: 0.3699
Epoch 4/10, Batch 80/145, Loss: 0.1599
Epoch 4/10, Batch 90/145, Loss: 0.2487
Epoch 4/10, Batch 100/145, Loss: 0.2200
Epoch 4/10, Batch 110/145, Loss: 0.1799
Epoch 4/10, Batch 120/145, Loss: 0.2362
Epoch 4/10, Batch 130/145, Loss: 0.1533
Epoch 4/10, Batch 140/145, Loss: 0.1280
Epoch 4/10, Train Loss: 0.2621, Valid Loss: 0.2633
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2102
Epoch 5/10, Batch 20/145, Loss: 0.5461
Epoch 5/10, Batch 30/145, Loss: 0.1902
Epoch 5/10, Batch 40/145, Loss: 0.2142
Epoch 5/10, Batch 50/145, Loss: 0.2137
Epoch 5/10, Batch 60/145, Loss: 0.4031
Epoch 5/10, Batch 70/145, Loss: 0.2331
Epoch 5/10, Batch 80/145, Loss: 0.2593
Epoch 5/10, Batch 90/145, Loss: 0.2125
Epoch 5/10, Batch 100/145, Loss: 0.1595
Epoch 5/10, Batch 110/145, Loss: 0.1229
Epoch 5/10, Batch 120/145, Loss: 0.3682
Epoch 5/10, Batch 130/145, Loss: 0.2437
Epoch 5/10, Batch 140/145, Loss: 0.1604
Epoch 5/10, Train Loss: 0.2331, Valid Loss: 0.2535
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2587
Epoch 6/10, Batch 20/145, Loss: 0.1706
Epoch 6/10, Batch 30/145, Loss: 0.3156
Epoch 6/10, Batch 40/145, Loss: 0.2089
Epoch 6/10, Batch 50/145, Loss: 0.2336
Epoch 6/10, Batch 60/145, Loss: 0.2677
Epoch 6/10, Batch 70/145, Loss: 0.2499
Epoch 6/10, Batch 80/145, Loss: 0.3692
Epoch 6/10, Batch 90/145, Loss: 0.4074
Epoch 6/10, Batch 100/145, Loss: 0.2893
Epoch 6/10, Batch 110/145, Loss: 0.1555
Epoch 6/10, Batch 120/145, Loss: 0.2572
Epoch 6/10, Batch 130/145, Loss: 0.0640
Epoch 6/10, Batch 140/145, Loss: 0.2559
Epoch 6/10, Train Loss: 0.2246, Valid Loss: 0.2518
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1580
Epoch 7/10, Batch 20/145, Loss: 0.2125
Epoch 7/10, Batch 30/145, Loss: 0.1242
Epoch 7/10, Batch 40/145, Loss: 0.5094
Epoch 7/10, Batch 50/145, Loss: 0.2457
Epoch 7/10, Batch 60/145, Loss: 0.1482
Epoch 7/10, Batch 70/145, Loss: 0.3713
Epoch 7/10, Batch 80/145, Loss: 0.1333
Epoch 7/10, Batch 90/145, Loss: 0.4969
Epoch 7/10, Batch 100/145, Loss: 0.2413
Epoch 7/10, Batch 110/145, Loss: 0.2947
Epoch 7/10, Batch 120/145, Loss: 0.3217
Epoch 7/10, Batch 130/145, Loss: 0.2851
Epoch 7/10, Batch 140/145, Loss: 0.0718
Epoch 7/10, Train Loss: 0.2196, Valid Loss: 0.2396
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1211
Epoch 8/10, Batch 20/145, Loss: 0.1839
Epoch 8/10, Batch 30/145, Loss: 0.1825
Epoch 8/10, Batch 40/145, Loss: 0.1918
Epoch 8/10, Batch 50/145, Loss: 0.2145
Epoch 8/10, Batch 60/145, Loss: 0.1757
Epoch 8/10, Batch 70/145, Loss: 0.1644
Epoch 8/10, Batch 80/145, Loss: 0.1050
Epoch 8/10, Batch 90/145, Loss: 0.1396
Epoch 8/10, Batch 100/145, Loss: 0.2304
Epoch 8/10, Batch 110/145, Loss: 0.2811
Epoch 8/10, Batch 120/145, Loss: 0.1363
Epoch 8/10, Batch 130/145, Loss: 0.1699
Epoch 8/10, Batch 140/145, Loss: 0.2642
Epoch 8/10, Train Loss: 0.2058, Valid Loss: 0.2430
Epoch 9/10, Batch 10/145, Loss: 0.0932
Epoch 9/10, Batch 20/145, Loss: 0.1444
Epoch 9/10, Batch 30/145, Loss: 0.0861
Epoch 9/10, Batch 40/145, Loss: 0.0951
Epoch 9/10, Batch 50/145, Loss: 0.3253
Epoch 9/10, Batch 60/145, Loss: 0.1314
Epoch 9/10, Batch 70/145, Loss: 0.1542
Epoch 9/10, Batch 80/145, Loss: 0.2625
Epoch 9/10, Batch 90/145, Loss: 0.1476
Epoch 9/10, Batch 100/145, Loss: 0.1995
Epoch 9/10, Batch 110/145, Loss: 0.1102
Epoch 9/10, Batch 120/145, Loss: 0.1434
Epoch 9/10, Batch 130/145, Loss: 0.1978
Epoch 9/10, Batch 140/145, Loss: 0.0926
Epoch 9/10, Train Loss: 0.2029, Valid Loss: 0.2309
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2289
Epoch 10/10, Batch 20/145, Loss: 0.1081
Epoch 10/10, Batch 30/145, Loss: 0.1367
Epoch 10/10, Batch 40/145, Loss: 0.1489
Epoch 10/10, Batch 50/145, Loss: 0.2638
Epoch 10/10, Batch 60/145, Loss: 0.2038
Epoch 10/10, Batch 70/145, Loss: 0.0711
Epoch 10/10, Batch 80/145, Loss: 0.3644
Epoch 10/10, Batch 90/145, Loss: 0.1948
Epoch 10/10, Batch 100/145, Loss: 0.1502
Epoch 10/10, Batch 110/145, Loss: 0.1717
Epoch 10/10, Batch 120/145, Loss: 0.1696
Epoch 10/10, Batch 130/145, Loss: 0.2408
Epoch 10/10, Batch 140/145, Loss: 0.2090
Epoch 10/10, Train Loss: 0.1875, Valid Loss: 0.2385
Accuracy: 0.9217
Precision: 0.9195
Recall: 0.9217
F1-score: 0.9204
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4887
Epoch 1/10, Batch 20/145, Loss: 0.9439
Epoch 1/10, Batch 30/145, Loss: 0.8461
Epoch 1/10, Batch 40/145, Loss: 0.9366
Epoch 1/10, Batch 50/145, Loss: 0.6399
Epoch 1/10, Batch 60/145, Loss: 0.6376
Epoch 1/10, Batch 70/145, Loss: 0.6030
Epoch 1/10, Batch 80/145, Loss: 0.5242
Epoch 1/10, Batch 90/145, Loss: 0.5731
Epoch 1/10, Batch 100/145, Loss: 0.7007
Epoch 1/10, Batch 110/145, Loss: 0.3317
Epoch 1/10, Batch 120/145, Loss: 0.5376
Epoch 1/10, Batch 130/145, Loss: 0.4078
Epoch 1/10, Batch 140/145, Loss: 0.3575
Epoch 1/10, Train Loss: 0.6922, Valid Loss: 0.3601
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4904
Epoch 2/10, Batch 20/145, Loss: 0.4122
Epoch 2/10, Batch 30/145, Loss: 0.3568
Epoch 2/10, Batch 40/145, Loss: 0.4271
Epoch 2/10, Batch 50/145, Loss: 0.4712
Epoch 2/10, Batch 60/145, Loss: 0.4256
Epoch 2/10, Batch 70/145, Loss: 0.2575
Epoch 2/10, Batch 80/145, Loss: 0.2155
Epoch 2/10, Batch 90/145, Loss: 0.2702
Epoch 2/10, Batch 100/145, Loss: 0.3174
Epoch 2/10, Batch 110/145, Loss: 0.2827
Epoch 2/10, Batch 120/145, Loss: 0.3432
Epoch 2/10, Batch 130/145, Loss: 0.5000
Epoch 2/10, Batch 140/145, Loss: 0.2446
Epoch 2/10, Train Loss: 0.3655, Valid Loss: 0.2779
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2752
Epoch 3/10, Batch 20/145, Loss: 0.2799
Epoch 3/10, Batch 30/145, Loss: 0.1838
Epoch 3/10, Batch 40/145, Loss: 0.2454
Epoch 3/10, Batch 50/145, Loss: 0.1420
Epoch 3/10, Batch 60/145, Loss: 0.4495
Epoch 3/10, Batch 70/145, Loss: 0.2311
Epoch 3/10, Batch 80/145, Loss: 0.1473
Epoch 3/10, Batch 90/145, Loss: 0.3451
Epoch 3/10, Batch 100/145, Loss: 0.2983
Epoch 3/10, Batch 110/145, Loss: 0.2417
Epoch 3/10, Batch 120/145, Loss: 0.3007
Epoch 3/10, Batch 130/145, Loss: 0.3909
Epoch 3/10, Batch 140/145, Loss: 0.2077
Epoch 3/10, Train Loss: 0.3079, Valid Loss: 0.2479
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2166
Epoch 4/10, Batch 20/145, Loss: 0.2968
Epoch 4/10, Batch 30/145, Loss: 0.2622
Epoch 4/10, Batch 40/145, Loss: 0.5410
Epoch 4/10, Batch 50/145, Loss: 0.2450
Epoch 4/10, Batch 60/145, Loss: 0.1708
Epoch 4/10, Batch 70/145, Loss: 0.2116
Epoch 4/10, Batch 80/145, Loss: 0.3226
Epoch 4/10, Batch 90/145, Loss: 0.3346
Epoch 4/10, Batch 100/145, Loss: 0.1841
Epoch 4/10, Batch 110/145, Loss: 0.2724
Epoch 4/10, Batch 120/145, Loss: 0.2051
Epoch 4/10, Batch 130/145, Loss: 0.1899
Epoch 4/10, Batch 140/145, Loss: 0.1549
Epoch 4/10, Train Loss: 0.2698, Valid Loss: 0.2354
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2669
Epoch 5/10, Batch 20/145, Loss: 0.4133
Epoch 5/10, Batch 30/145, Loss: 0.2508
Epoch 5/10, Batch 40/145, Loss: 0.2144
Epoch 5/10, Batch 50/145, Loss: 0.1214
Epoch 5/10, Batch 60/145, Loss: 0.2973
Epoch 5/10, Batch 70/145, Loss: 0.3396
Epoch 5/10, Batch 80/145, Loss: 0.2673
Epoch 5/10, Batch 90/145, Loss: 0.1073
Epoch 5/10, Batch 100/145, Loss: 0.2762
Epoch 5/10, Batch 110/145, Loss: 0.1798
Epoch 5/10, Batch 120/145, Loss: 0.1340
Epoch 5/10, Batch 130/145, Loss: 0.2602
Epoch 5/10, Batch 140/145, Loss: 0.2336
Epoch 5/10, Train Loss: 0.2474, Valid Loss: 0.2296
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1410
Epoch 6/10, Batch 20/145, Loss: 0.2686
Epoch 6/10, Batch 30/145, Loss: 0.1823
Epoch 6/10, Batch 40/145, Loss: 0.2411
Epoch 6/10, Batch 50/145, Loss: 0.4679
Epoch 6/10, Batch 60/145, Loss: 0.1717
Epoch 6/10, Batch 70/145, Loss: 0.2592
Epoch 6/10, Batch 80/145, Loss: 0.2836
Epoch 6/10, Batch 90/145, Loss: 0.2903
Epoch 6/10, Batch 100/145, Loss: 0.2109
Epoch 6/10, Batch 110/145, Loss: 0.1906
Epoch 6/10, Batch 120/145, Loss: 0.4099
Epoch 6/10, Batch 130/145, Loss: 0.1763
Epoch 6/10, Batch 140/145, Loss: 0.3324
Epoch 6/10, Train Loss: 0.2300, Valid Loss: 0.2155
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.5274
Epoch 7/10, Batch 20/145, Loss: 0.2371
Epoch 7/10, Batch 30/145, Loss: 0.1264
Epoch 7/10, Batch 40/145, Loss: 0.5616
Epoch 7/10, Batch 50/145, Loss: 0.1756
Epoch 7/10, Batch 60/145, Loss: 0.1336
Epoch 7/10, Batch 70/145, Loss: 0.1613
Epoch 7/10, Batch 80/145, Loss: 0.1052
Epoch 7/10, Batch 90/145, Loss: 0.2553
Epoch 7/10, Batch 100/145, Loss: 0.0776
Epoch 7/10, Batch 110/145, Loss: 0.1831
Epoch 7/10, Batch 120/145, Loss: 0.1618
Epoch 7/10, Batch 130/145, Loss: 0.2183
Epoch 7/10, Batch 140/145, Loss: 0.1692
Epoch 7/10, Train Loss: 0.2189, Valid Loss: 0.2039
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2288
Epoch 8/10, Batch 20/145, Loss: 0.1258
Epoch 8/10, Batch 30/145, Loss: 0.2392
Epoch 8/10, Batch 40/145, Loss: 0.3870
Epoch 8/10, Batch 50/145, Loss: 0.2313
Epoch 8/10, Batch 60/145, Loss: 0.2568
Epoch 8/10, Batch 70/145, Loss: 0.2058
Epoch 8/10, Batch 80/145, Loss: 0.2081
Epoch 8/10, Batch 90/145, Loss: 0.1317
Epoch 8/10, Batch 100/145, Loss: 0.2940
Epoch 8/10, Batch 110/145, Loss: 0.2774
Epoch 8/10, Batch 120/145, Loss: 0.2877
Epoch 8/10, Batch 130/145, Loss: 0.1576
Epoch 8/10, Batch 140/145, Loss: 0.2391
Epoch 8/10, Train Loss: 0.2192, Valid Loss: 0.2033
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2253
Epoch 9/10, Batch 20/145, Loss: 0.1194
Epoch 9/10, Batch 30/145, Loss: 0.0817
Epoch 9/10, Batch 40/145, Loss: 0.1069
Epoch 9/10, Batch 50/145, Loss: 0.0811
Epoch 9/10, Batch 60/145, Loss: 0.1485
Epoch 9/10, Batch 70/145, Loss: 0.1842
Epoch 9/10, Batch 80/145, Loss: 0.2269
Epoch 9/10, Batch 90/145, Loss: 0.1413
Epoch 9/10, Batch 100/145, Loss: 0.3292
Epoch 9/10, Batch 110/145, Loss: 0.0895
Epoch 9/10, Batch 120/145, Loss: 0.1521
Epoch 9/10, Batch 130/145, Loss: 0.1683
Epoch 9/10, Batch 140/145, Loss: 0.2125
Epoch 9/10, Train Loss: 0.2076, Valid Loss: 0.1990
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1733
Epoch 10/10, Batch 20/145, Loss: 0.1032
Epoch 10/10, Batch 30/145, Loss: 0.0907
Epoch 10/10, Batch 40/145, Loss: 0.3048
Epoch 10/10, Batch 50/145, Loss: 0.1391
Epoch 10/10, Batch 60/145, Loss: 0.1608
Epoch 10/10, Batch 70/145, Loss: 0.2803
Epoch 10/10, Batch 80/145, Loss: 0.2959
Epoch 10/10, Batch 90/145, Loss: 0.1614
Epoch 10/10, Batch 100/145, Loss: 0.2031
Epoch 10/10, Batch 110/145, Loss: 0.2297
Epoch 10/10, Batch 120/145, Loss: 0.2644
Epoch 10/10, Batch 130/145, Loss: 0.3487
Epoch 10/10, Batch 140/145, Loss: 0.3032
Epoch 10/10, Train Loss: 0.1995, Valid Loss: 0.2034
Accuracy: 0.9206
Precision: 0.9189
Recall: 0.9206
F1-score: 0.9186
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4530
Epoch 1/10, Batch 20/145, Loss: 0.9119
Epoch 1/10, Batch 30/145, Loss: 0.8611
Epoch 1/10, Batch 40/145, Loss: 0.9111
Epoch 1/10, Batch 50/145, Loss: 0.5527
Epoch 1/10, Batch 60/145, Loss: 0.5816
Epoch 1/10, Batch 70/145, Loss: 0.6477
Epoch 1/10, Batch 80/145, Loss: 0.4802
Epoch 1/10, Batch 90/145, Loss: 0.5572
Epoch 1/10, Batch 100/145, Loss: 0.6478
Epoch 1/10, Batch 110/145, Loss: 0.4441
Epoch 1/10, Batch 120/145, Loss: 0.5368
Epoch 1/10, Batch 130/145, Loss: 0.3529
Epoch 1/10, Batch 140/145, Loss: 0.4197
Epoch 1/10, Train Loss: 0.6827, Valid Loss: 0.3866
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2588
Epoch 2/10, Batch 20/145, Loss: 0.3937
Epoch 2/10, Batch 30/145, Loss: 0.4231
Epoch 2/10, Batch 40/145, Loss: 0.4521
Epoch 2/10, Batch 50/145, Loss: 0.3561
Epoch 2/10, Batch 60/145, Loss: 0.3268
Epoch 2/10, Batch 70/145, Loss: 0.4361
Epoch 2/10, Batch 80/145, Loss: 0.4091
Epoch 2/10, Batch 90/145, Loss: 0.1855
Epoch 2/10, Batch 100/145, Loss: 0.3758
Epoch 2/10, Batch 110/145, Loss: 0.2214
Epoch 2/10, Batch 120/145, Loss: 0.4265
Epoch 2/10, Batch 130/145, Loss: 0.3405
Epoch 2/10, Batch 140/145, Loss: 0.2539
Epoch 2/10, Train Loss: 0.3577, Valid Loss: 0.3047
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3007
Epoch 3/10, Batch 20/145, Loss: 0.2314
Epoch 3/10, Batch 30/145, Loss: 0.4016
Epoch 3/10, Batch 40/145, Loss: 0.2373
Epoch 3/10, Batch 50/145, Loss: 0.2456
Epoch 3/10, Batch 60/145, Loss: 0.5230
Epoch 3/10, Batch 70/145, Loss: 0.3570
Epoch 3/10, Batch 80/145, Loss: 0.2461
Epoch 3/10, Batch 90/145, Loss: 0.4638
Epoch 3/10, Batch 100/145, Loss: 0.3200
Epoch 3/10, Batch 110/145, Loss: 0.2245
Epoch 3/10, Batch 120/145, Loss: 0.1438
Epoch 3/10, Batch 130/145, Loss: 0.2748
Epoch 3/10, Batch 140/145, Loss: 0.1989
Epoch 3/10, Train Loss: 0.3012, Valid Loss: 0.2744
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2899
Epoch 4/10, Batch 20/145, Loss: 0.2614
Epoch 4/10, Batch 30/145, Loss: 0.1889
Epoch 4/10, Batch 40/145, Loss: 0.3505
Epoch 4/10, Batch 50/145, Loss: 0.1996
Epoch 4/10, Batch 60/145, Loss: 0.2849
Epoch 4/10, Batch 70/145, Loss: 0.2567
Epoch 4/10, Batch 80/145, Loss: 0.2829
Epoch 4/10, Batch 90/145, Loss: 0.2527
Epoch 4/10, Batch 100/145, Loss: 0.1841
Epoch 4/10, Batch 110/145, Loss: 0.4449
Epoch 4/10, Batch 120/145, Loss: 0.1835
Epoch 4/10, Batch 130/145, Loss: 0.1284
Epoch 4/10, Batch 140/145, Loss: 0.2420
Epoch 4/10, Train Loss: 0.2565, Valid Loss: 0.2664
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2007
Epoch 5/10, Batch 20/145, Loss: 0.1912
Epoch 5/10, Batch 30/145, Loss: 0.1393
Epoch 5/10, Batch 40/145, Loss: 0.2381
Epoch 5/10, Batch 50/145, Loss: 0.1985
Epoch 5/10, Batch 60/145, Loss: 0.1711
Epoch 5/10, Batch 70/145, Loss: 0.3414
Epoch 5/10, Batch 80/145, Loss: 0.2799
Epoch 5/10, Batch 90/145, Loss: 0.2478
Epoch 5/10, Batch 100/145, Loss: 0.1671
Epoch 5/10, Batch 110/145, Loss: 0.0788
Epoch 5/10, Batch 120/145, Loss: 0.3883
Epoch 5/10, Batch 130/145, Loss: 0.1474
Epoch 5/10, Batch 140/145, Loss: 0.2688
Epoch 5/10, Train Loss: 0.2376, Valid Loss: 0.2534
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3350
Epoch 6/10, Batch 20/145, Loss: 0.2206
Epoch 6/10, Batch 30/145, Loss: 0.3913
Epoch 6/10, Batch 40/145, Loss: 0.0886
Epoch 6/10, Batch 50/145, Loss: 0.2442
Epoch 6/10, Batch 60/145, Loss: 0.1267
Epoch 6/10, Batch 70/145, Loss: 0.3161
Epoch 6/10, Batch 80/145, Loss: 0.2463
Epoch 6/10, Batch 90/145, Loss: 0.1089
Epoch 6/10, Batch 100/145, Loss: 0.2130
Epoch 6/10, Batch 110/145, Loss: 0.1312
Epoch 6/10, Batch 120/145, Loss: 0.2291
Epoch 6/10, Batch 130/145, Loss: 0.2704
Epoch 6/10, Batch 140/145, Loss: 0.1350
Epoch 6/10, Train Loss: 0.2262, Valid Loss: 0.2607
Epoch 7/10, Batch 10/145, Loss: 0.2204
Epoch 7/10, Batch 20/145, Loss: 0.1541
Epoch 7/10, Batch 30/145, Loss: 0.1447
Epoch 7/10, Batch 40/145, Loss: 0.4025
Epoch 7/10, Batch 50/145, Loss: 0.1596
Epoch 7/10, Batch 60/145, Loss: 0.2384
Epoch 7/10, Batch 70/145, Loss: 0.2271
Epoch 7/10, Batch 80/145, Loss: 0.1100
Epoch 7/10, Batch 90/145, Loss: 0.2555
Epoch 7/10, Batch 100/145, Loss: 0.1405
Epoch 7/10, Batch 110/145, Loss: 0.1847
Epoch 7/10, Batch 120/145, Loss: 0.1215
Epoch 7/10, Batch 130/145, Loss: 0.1477
Epoch 7/10, Batch 140/145, Loss: 0.1797
Epoch 7/10, Train Loss: 0.2061, Valid Loss: 0.2524
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1527
Epoch 8/10, Batch 20/145, Loss: 0.1957
Epoch 8/10, Batch 30/145, Loss: 0.2846
Epoch 8/10, Batch 40/145, Loss: 0.3583
Epoch 8/10, Batch 50/145, Loss: 0.1202
Epoch 8/10, Batch 60/145, Loss: 0.2042
Epoch 8/10, Batch 70/145, Loss: 0.2527
Epoch 8/10, Batch 80/145, Loss: 0.1602
Epoch 8/10, Batch 90/145, Loss: 0.1079
Epoch 8/10, Batch 100/145, Loss: 0.3538
Epoch 8/10, Batch 110/145, Loss: 0.1118
Epoch 8/10, Batch 120/145, Loss: 0.1802
Epoch 8/10, Batch 130/145, Loss: 0.1297
Epoch 8/10, Batch 140/145, Loss: 0.3675
Epoch 8/10, Train Loss: 0.2008, Valid Loss: 0.2418
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2001
Epoch 9/10, Batch 20/145, Loss: 0.1454
Epoch 9/10, Batch 30/145, Loss: 0.1417
Epoch 9/10, Batch 40/145, Loss: 0.1005
Epoch 9/10, Batch 50/145, Loss: 0.1638
Epoch 9/10, Batch 60/145, Loss: 0.1475
Epoch 9/10, Batch 70/145, Loss: 0.1318
Epoch 9/10, Batch 80/145, Loss: 0.1991
Epoch 9/10, Batch 90/145, Loss: 0.3085
Epoch 9/10, Batch 100/145, Loss: 0.2994
Epoch 9/10, Batch 110/145, Loss: 0.1100
Epoch 9/10, Batch 120/145, Loss: 0.3262
Epoch 9/10, Batch 130/145, Loss: 0.3517
Epoch 9/10, Batch 140/145, Loss: 0.2002
Epoch 9/10, Train Loss: 0.1974, Valid Loss: 0.2413
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2256
Epoch 10/10, Batch 20/145, Loss: 0.1051
Epoch 10/10, Batch 30/145, Loss: 0.1894
Epoch 10/10, Batch 40/145, Loss: 0.1389
Epoch 10/10, Batch 50/145, Loss: 0.3205
Epoch 10/10, Batch 60/145, Loss: 0.1641
Epoch 10/10, Batch 70/145, Loss: 0.1251
Epoch 10/10, Batch 80/145, Loss: 0.3796
Epoch 10/10, Batch 90/145, Loss: 0.1530
Epoch 10/10, Batch 100/145, Loss: 0.0974
Epoch 10/10, Batch 110/145, Loss: 0.1968
Epoch 10/10, Batch 120/145, Loss: 0.1707
Epoch 10/10, Batch 130/145, Loss: 0.3795
Epoch 10/10, Batch 140/145, Loss: 0.2636
Epoch 10/10, Train Loss: 0.1980, Valid Loss: 0.2386
Model saved!
Accuracy: 0.9229
Precision: 0.9205
Recall: 0.9229
F1-score: 0.9209
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4356
Epoch 1/10, Batch 20/145, Loss: 0.9129
Epoch 1/10, Batch 30/145, Loss: 0.8437
Epoch 1/10, Batch 40/145, Loss: 0.7504
Epoch 1/10, Batch 50/145, Loss: 0.6765
Epoch 1/10, Batch 60/145, Loss: 0.7089
Epoch 1/10, Batch 70/145, Loss: 0.5948
Epoch 1/10, Batch 80/145, Loss: 0.4697
Epoch 1/10, Batch 90/145, Loss: 0.6898
Epoch 1/10, Batch 100/145, Loss: 0.6738
Epoch 1/10, Batch 110/145, Loss: 0.3800
Epoch 1/10, Batch 120/145, Loss: 0.5945
Epoch 1/10, Batch 130/145, Loss: 0.4392
Epoch 1/10, Batch 140/145, Loss: 0.3992
Epoch 1/10, Train Loss: 0.6844, Valid Loss: 0.3689
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2827
Epoch 2/10, Batch 20/145, Loss: 0.4970
Epoch 2/10, Batch 30/145, Loss: 0.2779
Epoch 2/10, Batch 40/145, Loss: 0.4088
Epoch 2/10, Batch 50/145, Loss: 0.4440
Epoch 2/10, Batch 60/145, Loss: 0.3753
Epoch 2/10, Batch 70/145, Loss: 0.4030
Epoch 2/10, Batch 80/145, Loss: 0.3802
Epoch 2/10, Batch 90/145, Loss: 0.2346
Epoch 2/10, Batch 100/145, Loss: 0.4595
Epoch 2/10, Batch 110/145, Loss: 0.2876
Epoch 2/10, Batch 120/145, Loss: 0.3849
Epoch 2/10, Batch 130/145, Loss: 0.2414
Epoch 2/10, Batch 140/145, Loss: 0.2859
Epoch 2/10, Train Loss: 0.3625, Valid Loss: 0.2796
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2503
Epoch 3/10, Batch 20/145, Loss: 0.4515
Epoch 3/10, Batch 30/145, Loss: 0.3003
Epoch 3/10, Batch 40/145, Loss: 0.2604
Epoch 3/10, Batch 50/145, Loss: 0.2580
Epoch 3/10, Batch 60/145, Loss: 0.2474
Epoch 3/10, Batch 70/145, Loss: 0.2225
Epoch 3/10, Batch 80/145, Loss: 0.2421
Epoch 3/10, Batch 90/145, Loss: 0.5148
Epoch 3/10, Batch 100/145, Loss: 0.2941
Epoch 3/10, Batch 110/145, Loss: 0.2857
Epoch 3/10, Batch 120/145, Loss: 0.1800
Epoch 3/10, Batch 130/145, Loss: 0.3020
Epoch 3/10, Batch 140/145, Loss: 0.2378
Epoch 3/10, Train Loss: 0.3088, Valid Loss: 0.2432
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2202
Epoch 4/10, Batch 20/145, Loss: 0.1996
Epoch 4/10, Batch 30/145, Loss: 0.2605
Epoch 4/10, Batch 40/145, Loss: 0.3026
Epoch 4/10, Batch 50/145, Loss: 0.1644
Epoch 4/10, Batch 60/145, Loss: 0.2096
Epoch 4/10, Batch 70/145, Loss: 0.2119
Epoch 4/10, Batch 80/145, Loss: 0.3830
Epoch 4/10, Batch 90/145, Loss: 0.3591
Epoch 4/10, Batch 100/145, Loss: 0.2654
Epoch 4/10, Batch 110/145, Loss: 0.4992
Epoch 4/10, Batch 120/145, Loss: 0.1787
Epoch 4/10, Batch 130/145, Loss: 0.2872
Epoch 4/10, Batch 140/145, Loss: 0.2024
Epoch 4/10, Train Loss: 0.2667, Valid Loss: 0.2388
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2916
Epoch 5/10, Batch 20/145, Loss: 0.3039
Epoch 5/10, Batch 30/145, Loss: 0.2194
Epoch 5/10, Batch 40/145, Loss: 0.3322
Epoch 5/10, Batch 50/145, Loss: 0.1613
Epoch 5/10, Batch 60/145, Loss: 0.1852
Epoch 5/10, Batch 70/145, Loss: 0.3196
Epoch 5/10, Batch 80/145, Loss: 0.2448
Epoch 5/10, Batch 90/145, Loss: 0.2851
Epoch 5/10, Batch 100/145, Loss: 0.1649
Epoch 5/10, Batch 110/145, Loss: 0.1515
Epoch 5/10, Batch 120/145, Loss: 0.2332
Epoch 5/10, Batch 130/145, Loss: 0.2049
Epoch 5/10, Batch 140/145, Loss: 0.2953
Epoch 5/10, Train Loss: 0.2398, Valid Loss: 0.2180
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2219
Epoch 6/10, Batch 20/145, Loss: 0.1828
Epoch 6/10, Batch 30/145, Loss: 0.1320
Epoch 6/10, Batch 40/145, Loss: 0.1710
Epoch 6/10, Batch 50/145, Loss: 0.3103
Epoch 6/10, Batch 60/145, Loss: 0.2099
Epoch 6/10, Batch 70/145, Loss: 0.2523
Epoch 6/10, Batch 80/145, Loss: 0.3800
Epoch 6/10, Batch 90/145, Loss: 0.3086
Epoch 6/10, Batch 100/145, Loss: 0.1385
Epoch 6/10, Batch 110/145, Loss: 0.0765
Epoch 6/10, Batch 120/145, Loss: 0.2589
Epoch 6/10, Batch 130/145, Loss: 0.2802
Epoch 6/10, Batch 140/145, Loss: 0.2762
Epoch 6/10, Train Loss: 0.2248, Valid Loss: 0.2121
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2906
Epoch 7/10, Batch 20/145, Loss: 0.2862
Epoch 7/10, Batch 30/145, Loss: 0.2184
Epoch 7/10, Batch 40/145, Loss: 0.4818
Epoch 7/10, Batch 50/145, Loss: 0.2995
Epoch 7/10, Batch 60/145, Loss: 0.1635
Epoch 7/10, Batch 70/145, Loss: 0.1520
Epoch 7/10, Batch 80/145, Loss: 0.1888
Epoch 7/10, Batch 90/145, Loss: 0.2423
Epoch 7/10, Batch 100/145, Loss: 0.2038
Epoch 7/10, Batch 110/145, Loss: 0.1857
Epoch 7/10, Batch 120/145, Loss: 0.2712
Epoch 7/10, Batch 130/145, Loss: 0.1203
Epoch 7/10, Batch 140/145, Loss: 0.1347
Epoch 7/10, Train Loss: 0.2155, Valid Loss: 0.2036
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.3446
Epoch 8/10, Batch 20/145, Loss: 0.1430
Epoch 8/10, Batch 30/145, Loss: 0.2295
Epoch 8/10, Batch 40/145, Loss: 0.2017
Epoch 8/10, Batch 50/145, Loss: 0.1622
Epoch 8/10, Batch 60/145, Loss: 0.1589
Epoch 8/10, Batch 70/145, Loss: 0.1690
Epoch 8/10, Batch 80/145, Loss: 0.2700
Epoch 8/10, Batch 90/145, Loss: 0.0928
Epoch 8/10, Batch 100/145, Loss: 0.2315
Epoch 8/10, Batch 110/145, Loss: 0.2384
Epoch 8/10, Batch 120/145, Loss: 0.1518
Epoch 8/10, Batch 130/145, Loss: 0.0960
Epoch 8/10, Batch 140/145, Loss: 0.3056
Epoch 8/10, Train Loss: 0.2101, Valid Loss: 0.2089
Epoch 9/10, Batch 10/145, Loss: 0.1361
Epoch 9/10, Batch 20/145, Loss: 0.1551
Epoch 9/10, Batch 30/145, Loss: 0.1669
Epoch 9/10, Batch 40/145, Loss: 0.2751
Epoch 9/10, Batch 50/145, Loss: 0.2857
Epoch 9/10, Batch 60/145, Loss: 0.1852
Epoch 9/10, Batch 70/145, Loss: 0.2778
Epoch 9/10, Batch 80/145, Loss: 0.1871
Epoch 9/10, Batch 90/145, Loss: 0.1235
Epoch 9/10, Batch 100/145, Loss: 0.1718
Epoch 9/10, Batch 110/145, Loss: 0.1305
Epoch 9/10, Batch 120/145, Loss: 0.3232
Epoch 9/10, Batch 130/145, Loss: 0.1172
Epoch 9/10, Batch 140/145, Loss: 0.1485
Epoch 9/10, Train Loss: 0.2049, Valid Loss: 0.1927
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1147
Epoch 10/10, Batch 20/145, Loss: 0.1073
Epoch 10/10, Batch 30/145, Loss: 0.1609
Epoch 10/10, Batch 40/145, Loss: 0.2015
Epoch 10/10, Batch 50/145, Loss: 0.3520
Epoch 10/10, Batch 60/145, Loss: 0.1758
Epoch 10/10, Batch 70/145, Loss: 0.1302
Epoch 10/10, Batch 80/145, Loss: 0.4378
Epoch 10/10, Batch 90/145, Loss: 0.1550
Epoch 10/10, Batch 100/145, Loss: 0.1816
Epoch 10/10, Batch 110/145, Loss: 0.1623
Epoch 10/10, Batch 120/145, Loss: 0.1644
Epoch 10/10, Batch 130/145, Loss: 0.1769
Epoch 10/10, Batch 140/145, Loss: 0.3112
Epoch 10/10, Train Loss: 0.1937, Valid Loss: 0.1882
Model saved!
Accuracy: 0.9217
Precision: 0.9197
Recall: 0.9217
F1-score: 0.9203
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5074
Epoch 1/10, Batch 20/145, Loss: 0.7972
Epoch 1/10, Batch 30/145, Loss: 0.8852
Epoch 1/10, Batch 40/145, Loss: 0.8859
Epoch 1/10, Batch 50/145, Loss: 0.5879
Epoch 1/10, Batch 60/145, Loss: 0.6011
Epoch 1/10, Batch 70/145, Loss: 0.6582
Epoch 1/10, Batch 80/145, Loss: 0.6238
Epoch 1/10, Batch 90/145, Loss: 0.7114
Epoch 1/10, Batch 100/145, Loss: 0.5812
Epoch 1/10, Batch 110/145, Loss: 0.4928
Epoch 1/10, Batch 120/145, Loss: 0.4963
Epoch 1/10, Batch 130/145, Loss: 0.3275
Epoch 1/10, Batch 140/145, Loss: 0.4396
Epoch 1/10, Train Loss: 0.6821, Valid Loss: 0.3744
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.5014
Epoch 2/10, Batch 20/145, Loss: 0.4771
Epoch 2/10, Batch 30/145, Loss: 0.2506
Epoch 2/10, Batch 40/145, Loss: 0.5842
Epoch 2/10, Batch 50/145, Loss: 0.2813
Epoch 2/10, Batch 60/145, Loss: 0.4394
Epoch 2/10, Batch 70/145, Loss: 0.3999
Epoch 2/10, Batch 80/145, Loss: 0.4438
Epoch 2/10, Batch 90/145, Loss: 0.2128
Epoch 2/10, Batch 100/145, Loss: 0.3992
Epoch 2/10, Batch 110/145, Loss: 0.2450
Epoch 2/10, Batch 120/145, Loss: 0.4119
Epoch 2/10, Batch 130/145, Loss: 0.3170
Epoch 2/10, Batch 140/145, Loss: 0.2272
Epoch 2/10, Train Loss: 0.3556, Valid Loss: 0.2781
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1451
Epoch 3/10, Batch 20/145, Loss: 0.2956
Epoch 3/10, Batch 30/145, Loss: 0.2008
Epoch 3/10, Batch 40/145, Loss: 0.2782
Epoch 3/10, Batch 50/145, Loss: 0.1907
Epoch 3/10, Batch 60/145, Loss: 0.2553
Epoch 3/10, Batch 70/145, Loss: 0.2753
Epoch 3/10, Batch 80/145, Loss: 0.2284
Epoch 3/10, Batch 90/145, Loss: 0.7294
Epoch 3/10, Batch 100/145, Loss: 0.2190
Epoch 3/10, Batch 110/145, Loss: 0.3936
Epoch 3/10, Batch 120/145, Loss: 0.1977
Epoch 3/10, Batch 130/145, Loss: 0.3343
Epoch 3/10, Batch 140/145, Loss: 0.2517
Epoch 3/10, Train Loss: 0.3035, Valid Loss: 0.2436
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1563
Epoch 4/10, Batch 20/145, Loss: 0.3859
Epoch 4/10, Batch 30/145, Loss: 0.2484
Epoch 4/10, Batch 40/145, Loss: 0.3900
Epoch 4/10, Batch 50/145, Loss: 0.1985
Epoch 4/10, Batch 60/145, Loss: 0.1260
Epoch 4/10, Batch 70/145, Loss: 0.2280
Epoch 4/10, Batch 80/145, Loss: 0.1709
Epoch 4/10, Batch 90/145, Loss: 0.2828
Epoch 4/10, Batch 100/145, Loss: 0.2337
Epoch 4/10, Batch 110/145, Loss: 0.2104
Epoch 4/10, Batch 120/145, Loss: 0.2293
Epoch 4/10, Batch 130/145, Loss: 0.1597
Epoch 4/10, Batch 140/145, Loss: 0.1777
Epoch 4/10, Train Loss: 0.2581, Valid Loss: 0.2318
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1491
Epoch 5/10, Batch 20/145, Loss: 0.2311
Epoch 5/10, Batch 30/145, Loss: 0.2353
Epoch 5/10, Batch 40/145, Loss: 0.4299
Epoch 5/10, Batch 50/145, Loss: 0.1608
Epoch 5/10, Batch 60/145, Loss: 0.1776
Epoch 5/10, Batch 70/145, Loss: 0.1851
Epoch 5/10, Batch 80/145, Loss: 0.2716
Epoch 5/10, Batch 90/145, Loss: 0.2267
Epoch 5/10, Batch 100/145, Loss: 0.2620
Epoch 5/10, Batch 110/145, Loss: 0.1221
Epoch 5/10, Batch 120/145, Loss: 0.1832
Epoch 5/10, Batch 130/145, Loss: 0.1712
Epoch 5/10, Batch 140/145, Loss: 0.1952
Epoch 5/10, Train Loss: 0.2369, Valid Loss: 0.2123
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3977
Epoch 6/10, Batch 20/145, Loss: 0.2788
Epoch 6/10, Batch 30/145, Loss: 0.2930
Epoch 6/10, Batch 40/145, Loss: 0.1967
Epoch 6/10, Batch 50/145, Loss: 0.2153
Epoch 6/10, Batch 60/145, Loss: 0.0846
Epoch 6/10, Batch 70/145, Loss: 0.1707
Epoch 6/10, Batch 80/145, Loss: 0.3441
Epoch 6/10, Batch 90/145, Loss: 0.1564
Epoch 6/10, Batch 100/145, Loss: 0.1103
Epoch 6/10, Batch 110/145, Loss: 0.2052
Epoch 6/10, Batch 120/145, Loss: 0.1419
Epoch 6/10, Batch 130/145, Loss: 0.2553
Epoch 6/10, Batch 140/145, Loss: 0.3233
Epoch 6/10, Train Loss: 0.2252, Valid Loss: 0.2017
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1226
Epoch 7/10, Batch 20/145, Loss: 0.2594
Epoch 7/10, Batch 30/145, Loss: 0.1459
Epoch 7/10, Batch 40/145, Loss: 0.3466
Epoch 7/10, Batch 50/145, Loss: 0.1054
Epoch 7/10, Batch 60/145, Loss: 0.2217
Epoch 7/10, Batch 70/145, Loss: 0.3007
Epoch 7/10, Batch 80/145, Loss: 0.1885
Epoch 7/10, Batch 90/145, Loss: 0.2025
Epoch 7/10, Batch 100/145, Loss: 0.1541
Epoch 7/10, Batch 110/145, Loss: 0.2901
Epoch 7/10, Batch 120/145, Loss: 0.1625
Epoch 7/10, Batch 130/145, Loss: 0.1764
Epoch 7/10, Batch 140/145, Loss: 0.1511
Epoch 7/10, Train Loss: 0.2113, Valid Loss: 0.1976
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0947
Epoch 8/10, Batch 20/145, Loss: 0.1128
Epoch 8/10, Batch 30/145, Loss: 0.1745
Epoch 8/10, Batch 40/145, Loss: 0.2140
Epoch 8/10, Batch 50/145, Loss: 0.2140
Epoch 8/10, Batch 60/145, Loss: 0.2158
Epoch 8/10, Batch 70/145, Loss: 0.1588
Epoch 8/10, Batch 80/145, Loss: 0.2265
Epoch 8/10, Batch 90/145, Loss: 0.1319
Epoch 8/10, Batch 100/145, Loss: 0.2302
Epoch 8/10, Batch 110/145, Loss: 0.1137
Epoch 8/10, Batch 120/145, Loss: 0.1783
Epoch 8/10, Batch 130/145, Loss: 0.1651
Epoch 8/10, Batch 140/145, Loss: 0.2478
Epoch 8/10, Train Loss: 0.2012, Valid Loss: 0.1922
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2111
Epoch 9/10, Batch 20/145, Loss: 0.2097
Epoch 9/10, Batch 30/145, Loss: 0.0896
Epoch 9/10, Batch 40/145, Loss: 0.1630
Epoch 9/10, Batch 50/145, Loss: 0.1685
Epoch 9/10, Batch 60/145, Loss: 0.0710
Epoch 9/10, Batch 70/145, Loss: 0.1242
Epoch 9/10, Batch 80/145, Loss: 0.2245
Epoch 9/10, Batch 90/145, Loss: 0.2443
Epoch 9/10, Batch 100/145, Loss: 0.1574
Epoch 9/10, Batch 110/145, Loss: 0.0663
Epoch 9/10, Batch 120/145, Loss: 0.1916
Epoch 9/10, Batch 130/145, Loss: 0.1845
Epoch 9/10, Batch 140/145, Loss: 0.2137
Epoch 9/10, Train Loss: 0.1968, Valid Loss: 0.1931
Epoch 10/10, Batch 10/145, Loss: 0.3661
Epoch 10/10, Batch 20/145, Loss: 0.1360
Epoch 10/10, Batch 30/145, Loss: 0.0932
Epoch 10/10, Batch 40/145, Loss: 0.2936
Epoch 10/10, Batch 50/145, Loss: 0.1355
Epoch 10/10, Batch 60/145, Loss: 0.1945
Epoch 10/10, Batch 70/145, Loss: 0.0705
Epoch 10/10, Batch 80/145, Loss: 0.4393
Epoch 10/10, Batch 90/145, Loss: 0.0710
Epoch 10/10, Batch 100/145, Loss: 0.1665
Epoch 10/10, Batch 110/145, Loss: 0.1330
Epoch 10/10, Batch 120/145, Loss: 0.1872
Epoch 10/10, Batch 130/145, Loss: 0.2074
Epoch 10/10, Batch 140/145, Loss: 0.2995
Epoch 10/10, Train Loss: 0.1832, Valid Loss: 0.1904
Model saved!
Accuracy: 0.9206
Precision: 0.9189
Recall: 0.9206
F1-score: 0.9195
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5241
Epoch 1/10, Batch 20/145, Loss: 0.9386
Epoch 1/10, Batch 30/145, Loss: 0.8336
Epoch 1/10, Batch 40/145, Loss: 0.7688
Epoch 1/10, Batch 50/145, Loss: 0.6805
Epoch 1/10, Batch 60/145, Loss: 0.5767
Epoch 1/10, Batch 70/145, Loss: 0.6452
Epoch 1/10, Batch 80/145, Loss: 0.4902
Epoch 1/10, Batch 90/145, Loss: 0.4763
Epoch 1/10, Batch 100/145, Loss: 0.6138
Epoch 1/10, Batch 110/145, Loss: 0.3379
Epoch 1/10, Batch 120/145, Loss: 0.5404
Epoch 1/10, Batch 130/145, Loss: 0.4162
Epoch 1/10, Batch 140/145, Loss: 0.3638
Epoch 1/10, Train Loss: 0.6815, Valid Loss: 0.3778
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2724
Epoch 2/10, Batch 20/145, Loss: 0.4272
Epoch 2/10, Batch 30/145, Loss: 0.3496
Epoch 2/10, Batch 40/145, Loss: 0.4181
Epoch 2/10, Batch 50/145, Loss: 0.2728
Epoch 2/10, Batch 60/145, Loss: 0.3329
Epoch 2/10, Batch 70/145, Loss: 0.4088
Epoch 2/10, Batch 80/145, Loss: 0.2336
Epoch 2/10, Batch 90/145, Loss: 0.3172
Epoch 2/10, Batch 100/145, Loss: 0.3634
Epoch 2/10, Batch 110/145, Loss: 0.2316
Epoch 2/10, Batch 120/145, Loss: 0.4380
Epoch 2/10, Batch 130/145, Loss: 0.3441
Epoch 2/10, Batch 140/145, Loss: 0.3032
Epoch 2/10, Train Loss: 0.3522, Valid Loss: 0.2859
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2279
Epoch 3/10, Batch 20/145, Loss: 0.2628
Epoch 3/10, Batch 30/145, Loss: 0.1840
Epoch 3/10, Batch 40/145, Loss: 0.2446
Epoch 3/10, Batch 50/145, Loss: 0.1443
Epoch 3/10, Batch 60/145, Loss: 0.2861
Epoch 3/10, Batch 70/145, Loss: 0.2967
Epoch 3/10, Batch 80/145, Loss: 0.2234
Epoch 3/10, Batch 90/145, Loss: 0.3517
Epoch 3/10, Batch 100/145, Loss: 0.1837
Epoch 3/10, Batch 110/145, Loss: 0.1529
Epoch 3/10, Batch 120/145, Loss: 0.2005
Epoch 3/10, Batch 130/145, Loss: 0.2991
Epoch 3/10, Batch 140/145, Loss: 0.1306
Epoch 3/10, Train Loss: 0.2929, Valid Loss: 0.2561
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2042
Epoch 4/10, Batch 20/145, Loss: 0.2130
Epoch 4/10, Batch 30/145, Loss: 0.1933
Epoch 4/10, Batch 40/145, Loss: 0.3026
Epoch 4/10, Batch 50/145, Loss: 0.2328
Epoch 4/10, Batch 60/145, Loss: 0.2254
Epoch 4/10, Batch 70/145, Loss: 0.1705
Epoch 4/10, Batch 80/145, Loss: 0.2960
Epoch 4/10, Batch 90/145, Loss: 0.3084
Epoch 4/10, Batch 100/145, Loss: 0.2505
Epoch 4/10, Batch 110/145, Loss: 0.3985
Epoch 4/10, Batch 120/145, Loss: 0.2969
Epoch 4/10, Batch 130/145, Loss: 0.1048
Epoch 4/10, Batch 140/145, Loss: 0.3121
Epoch 4/10, Train Loss: 0.2637, Valid Loss: 0.2451
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1715
Epoch 5/10, Batch 20/145, Loss: 0.1437
Epoch 5/10, Batch 30/145, Loss: 0.1820
Epoch 5/10, Batch 40/145, Loss: 0.3414
Epoch 5/10, Batch 50/145, Loss: 0.1736
Epoch 5/10, Batch 60/145, Loss: 0.3651
Epoch 5/10, Batch 70/145, Loss: 0.2441
Epoch 5/10, Batch 80/145, Loss: 0.2455
Epoch 5/10, Batch 90/145, Loss: 0.1220
Epoch 5/10, Batch 100/145, Loss: 0.2157
Epoch 5/10, Batch 110/145, Loss: 0.0772
Epoch 5/10, Batch 120/145, Loss: 0.2915
Epoch 5/10, Batch 130/145, Loss: 0.1518
Epoch 5/10, Batch 140/145, Loss: 0.1532
Epoch 5/10, Train Loss: 0.2317, Valid Loss: 0.2323
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1551
Epoch 6/10, Batch 20/145, Loss: 0.1458
Epoch 6/10, Batch 30/145, Loss: 0.1929
Epoch 6/10, Batch 40/145, Loss: 0.1097
Epoch 6/10, Batch 50/145, Loss: 0.2677
Epoch 6/10, Batch 60/145, Loss: 0.0812
Epoch 6/10, Batch 70/145, Loss: 0.2348
Epoch 6/10, Batch 80/145, Loss: 0.2807
Epoch 6/10, Batch 90/145, Loss: 0.2758
Epoch 6/10, Batch 100/145, Loss: 0.3377
Epoch 6/10, Batch 110/145, Loss: 0.1941
Epoch 6/10, Batch 120/145, Loss: 0.2048
Epoch 6/10, Batch 130/145, Loss: 0.1779
Epoch 6/10, Batch 140/145, Loss: 0.2047
Epoch 6/10, Train Loss: 0.2274, Valid Loss: 0.2316
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2877
Epoch 7/10, Batch 20/145, Loss: 0.1644
Epoch 7/10, Batch 30/145, Loss: 0.1467
Epoch 7/10, Batch 40/145, Loss: 0.4097
Epoch 7/10, Batch 50/145, Loss: 0.1777
Epoch 7/10, Batch 60/145, Loss: 0.0977
Epoch 7/10, Batch 70/145, Loss: 0.5783
Epoch 7/10, Batch 80/145, Loss: 0.1376
Epoch 7/10, Batch 90/145, Loss: 0.2331
Epoch 7/10, Batch 100/145, Loss: 0.1050
Epoch 7/10, Batch 110/145, Loss: 0.1487
Epoch 7/10, Batch 120/145, Loss: 0.1718
Epoch 7/10, Batch 130/145, Loss: 0.3136
Epoch 7/10, Batch 140/145, Loss: 0.3340
Epoch 7/10, Train Loss: 0.2186, Valid Loss: 0.2217
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1649
Epoch 8/10, Batch 20/145, Loss: 0.1526
Epoch 8/10, Batch 30/145, Loss: 0.1506
Epoch 8/10, Batch 40/145, Loss: 0.1451
Epoch 8/10, Batch 50/145, Loss: 0.3311
Epoch 8/10, Batch 60/145, Loss: 0.2171
Epoch 8/10, Batch 70/145, Loss: 0.0840
Epoch 8/10, Batch 80/145, Loss: 0.3331
Epoch 8/10, Batch 90/145, Loss: 0.1555
Epoch 8/10, Batch 100/145, Loss: 0.2952
Epoch 8/10, Batch 110/145, Loss: 0.1823
Epoch 8/10, Batch 120/145, Loss: 0.2154
Epoch 8/10, Batch 130/145, Loss: 0.1438
Epoch 8/10, Batch 140/145, Loss: 0.2797
Epoch 8/10, Train Loss: 0.2036, Valid Loss: 0.2118
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3232
Epoch 9/10, Batch 20/145, Loss: 0.1905
Epoch 9/10, Batch 30/145, Loss: 0.0624
Epoch 9/10, Batch 40/145, Loss: 0.1936
Epoch 9/10, Batch 50/145, Loss: 0.1928
Epoch 9/10, Batch 60/145, Loss: 0.3016
Epoch 9/10, Batch 70/145, Loss: 0.1777
Epoch 9/10, Batch 80/145, Loss: 0.1635
Epoch 9/10, Batch 90/145, Loss: 0.0535
Epoch 9/10, Batch 100/145, Loss: 0.2401
Epoch 9/10, Batch 110/145, Loss: 0.1388
Epoch 9/10, Batch 120/145, Loss: 0.0961
Epoch 9/10, Batch 130/145, Loss: 0.3528
Epoch 9/10, Batch 140/145, Loss: 0.0735
Epoch 9/10, Train Loss: 0.2089, Valid Loss: 0.2114
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2088
Epoch 10/10, Batch 20/145, Loss: 0.2191
Epoch 10/10, Batch 30/145, Loss: 0.1467
Epoch 10/10, Batch 40/145, Loss: 0.1272
Epoch 10/10, Batch 50/145, Loss: 0.2431
Epoch 10/10, Batch 60/145, Loss: 0.1660
Epoch 10/10, Batch 70/145, Loss: 0.1630
Epoch 10/10, Batch 80/145, Loss: 0.2778
Epoch 10/10, Batch 90/145, Loss: 0.1966
Epoch 10/10, Batch 100/145, Loss: 0.1799
Epoch 10/10, Batch 110/145, Loss: 0.1500
Epoch 10/10, Batch 120/145, Loss: 0.1515
Epoch 10/10, Batch 130/145, Loss: 0.2949
Epoch 10/10, Batch 140/145, Loss: 0.3436
Epoch 10/10, Train Loss: 0.1973, Valid Loss: 0.2065
Model saved!
Accuracy: 0.9252
Precision: 0.9239
Recall: 0.9252
F1-score: 0.9243
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5051
Epoch 1/10, Batch 20/145, Loss: 0.8821
Epoch 1/10, Batch 30/145, Loss: 0.9519
Epoch 1/10, Batch 40/145, Loss: 0.7188
Epoch 1/10, Batch 50/145, Loss: 0.6159
Epoch 1/10, Batch 60/145, Loss: 0.5384
Epoch 1/10, Batch 70/145, Loss: 0.6010
Epoch 1/10, Batch 80/145, Loss: 0.5141
Epoch 1/10, Batch 90/145, Loss: 0.6717
Epoch 1/10, Batch 100/145, Loss: 0.5310
Epoch 1/10, Batch 110/145, Loss: 0.4764
Epoch 1/10, Batch 120/145, Loss: 0.6220
Epoch 1/10, Batch 130/145, Loss: 0.4067
Epoch 1/10, Batch 140/145, Loss: 0.3746
Epoch 1/10, Train Loss: 0.6846, Valid Loss: 0.3713
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3729
Epoch 2/10, Batch 20/145, Loss: 0.4969
Epoch 2/10, Batch 30/145, Loss: 0.2103
Epoch 2/10, Batch 40/145, Loss: 0.4758
Epoch 2/10, Batch 50/145, Loss: 0.2872
Epoch 2/10, Batch 60/145, Loss: 0.4200
Epoch 2/10, Batch 70/145, Loss: 0.3775
Epoch 2/10, Batch 80/145, Loss: 0.2946
Epoch 2/10, Batch 90/145, Loss: 0.1719
Epoch 2/10, Batch 100/145, Loss: 0.3170
Epoch 2/10, Batch 110/145, Loss: 0.2849
Epoch 2/10, Batch 120/145, Loss: 0.4310
Epoch 2/10, Batch 130/145, Loss: 0.3921
Epoch 2/10, Batch 140/145, Loss: 0.2144
Epoch 2/10, Train Loss: 0.3587, Valid Loss: 0.2911
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2846
Epoch 3/10, Batch 20/145, Loss: 0.3443
Epoch 3/10, Batch 30/145, Loss: 0.2353
Epoch 3/10, Batch 40/145, Loss: 0.1813
Epoch 3/10, Batch 50/145, Loss: 0.2203
Epoch 3/10, Batch 60/145, Loss: 0.2164
Epoch 3/10, Batch 70/145, Loss: 0.2669
Epoch 3/10, Batch 80/145, Loss: 0.2608
Epoch 3/10, Batch 90/145, Loss: 0.5079
Epoch 3/10, Batch 100/145, Loss: 0.2765
Epoch 3/10, Batch 110/145, Loss: 0.3203
Epoch 3/10, Batch 120/145, Loss: 0.2749
Epoch 3/10, Batch 130/145, Loss: 0.2670
Epoch 3/10, Batch 140/145, Loss: 0.1731
Epoch 3/10, Train Loss: 0.3063, Valid Loss: 0.2653
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2387
Epoch 4/10, Batch 20/145, Loss: 0.2989
Epoch 4/10, Batch 30/145, Loss: 0.3566
Epoch 4/10, Batch 40/145, Loss: 0.1888
Epoch 4/10, Batch 50/145, Loss: 0.1691
Epoch 4/10, Batch 60/145, Loss: 0.2354
Epoch 4/10, Batch 70/145, Loss: 0.2073
Epoch 4/10, Batch 80/145, Loss: 0.1924
Epoch 4/10, Batch 90/145, Loss: 0.1643
Epoch 4/10, Batch 100/145, Loss: 0.2567
Epoch 4/10, Batch 110/145, Loss: 0.1627
Epoch 4/10, Batch 120/145, Loss: 0.1549
Epoch 4/10, Batch 130/145, Loss: 0.3334
Epoch 4/10, Batch 140/145, Loss: 0.2755
Epoch 4/10, Train Loss: 0.2630, Valid Loss: 0.2592
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2018
Epoch 5/10, Batch 20/145, Loss: 0.1941
Epoch 5/10, Batch 30/145, Loss: 0.1786
Epoch 5/10, Batch 40/145, Loss: 0.3199
Epoch 5/10, Batch 50/145, Loss: 0.3282
Epoch 5/10, Batch 60/145, Loss: 0.1846
Epoch 5/10, Batch 70/145, Loss: 0.2824
Epoch 5/10, Batch 80/145, Loss: 0.2905
Epoch 5/10, Batch 90/145, Loss: 0.1280
Epoch 5/10, Batch 100/145, Loss: 0.2830
Epoch 5/10, Batch 110/145, Loss: 0.1759
Epoch 5/10, Batch 120/145, Loss: 0.3506
Epoch 5/10, Batch 130/145, Loss: 0.2301
Epoch 5/10, Batch 140/145, Loss: 0.3336
Epoch 5/10, Train Loss: 0.2351, Valid Loss: 0.2394
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2503
Epoch 6/10, Batch 20/145, Loss: 0.1991
Epoch 6/10, Batch 30/145, Loss: 0.3125
Epoch 6/10, Batch 40/145, Loss: 0.2456
Epoch 6/10, Batch 50/145, Loss: 0.4160
Epoch 6/10, Batch 60/145, Loss: 0.3147
Epoch 6/10, Batch 70/145, Loss: 0.1755
Epoch 6/10, Batch 80/145, Loss: 0.3406
Epoch 6/10, Batch 90/145, Loss: 0.1508
Epoch 6/10, Batch 100/145, Loss: 0.1842
Epoch 6/10, Batch 110/145, Loss: 0.1404
Epoch 6/10, Batch 120/145, Loss: 0.2208
Epoch 6/10, Batch 130/145, Loss: 0.2053
Epoch 6/10, Batch 140/145, Loss: 0.1700
Epoch 6/10, Train Loss: 0.2272, Valid Loss: 0.2347
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1918
Epoch 7/10, Batch 20/145, Loss: 0.1738
Epoch 7/10, Batch 30/145, Loss: 0.1522
Epoch 7/10, Batch 40/145, Loss: 0.4562
Epoch 7/10, Batch 50/145, Loss: 0.1954
Epoch 7/10, Batch 60/145, Loss: 0.2422
Epoch 7/10, Batch 70/145, Loss: 0.2079
Epoch 7/10, Batch 80/145, Loss: 0.0780
Epoch 7/10, Batch 90/145, Loss: 0.2561
Epoch 7/10, Batch 100/145, Loss: 0.1872
Epoch 7/10, Batch 110/145, Loss: 0.1345
Epoch 7/10, Batch 120/145, Loss: 0.1730
Epoch 7/10, Batch 130/145, Loss: 0.1520
Epoch 7/10, Batch 140/145, Loss: 0.2752
Epoch 7/10, Train Loss: 0.2159, Valid Loss: 0.2262
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2135
Epoch 8/10, Batch 20/145, Loss: 0.2462
Epoch 8/10, Batch 30/145, Loss: 0.2563
Epoch 8/10, Batch 40/145, Loss: 0.1566
Epoch 8/10, Batch 50/145, Loss: 0.1150
Epoch 8/10, Batch 60/145, Loss: 0.2324
Epoch 8/10, Batch 70/145, Loss: 0.1587
Epoch 8/10, Batch 80/145, Loss: 0.1571
Epoch 8/10, Batch 90/145, Loss: 0.0763
Epoch 8/10, Batch 100/145, Loss: 0.1812
Epoch 8/10, Batch 110/145, Loss: 0.1756
Epoch 8/10, Batch 120/145, Loss: 0.2103
Epoch 8/10, Batch 130/145, Loss: 0.1477
Epoch 8/10, Batch 140/145, Loss: 0.3507
Epoch 8/10, Train Loss: 0.2100, Valid Loss: 0.2219
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1641
Epoch 9/10, Batch 20/145, Loss: 0.1398
Epoch 9/10, Batch 30/145, Loss: 0.1094
Epoch 9/10, Batch 40/145, Loss: 0.1597
Epoch 9/10, Batch 50/145, Loss: 0.2736
Epoch 9/10, Batch 60/145, Loss: 0.1427
Epoch 9/10, Batch 70/145, Loss: 0.1785
Epoch 9/10, Batch 80/145, Loss: 0.2472
Epoch 9/10, Batch 90/145, Loss: 0.1654
Epoch 9/10, Batch 100/145, Loss: 0.2101
Epoch 9/10, Batch 110/145, Loss: 0.0930
Epoch 9/10, Batch 120/145, Loss: 0.1595
Epoch 9/10, Batch 130/145, Loss: 0.1532
Epoch 9/10, Batch 140/145, Loss: 0.2285
Epoch 9/10, Train Loss: 0.2016, Valid Loss: 0.2161
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1191
Epoch 10/10, Batch 20/145, Loss: 0.1981
Epoch 10/10, Batch 30/145, Loss: 0.1451
Epoch 10/10, Batch 40/145, Loss: 0.1789
Epoch 10/10, Batch 50/145, Loss: 0.2877
Epoch 10/10, Batch 60/145, Loss: 0.1817
Epoch 10/10, Batch 70/145, Loss: 0.0775
Epoch 10/10, Batch 80/145, Loss: 0.3425
Epoch 10/10, Batch 90/145, Loss: 0.1954
Epoch 10/10, Batch 100/145, Loss: 0.2216
Epoch 10/10, Batch 110/145, Loss: 0.1196
Epoch 10/10, Batch 120/145, Loss: 0.2057
Epoch 10/10, Batch 130/145, Loss: 0.1381
Epoch 10/10, Batch 140/145, Loss: 0.2974
Epoch 10/10, Train Loss: 0.1922, Valid Loss: 0.2151
Model saved!
Accuracy: 0.9182
Precision: 0.9158
Recall: 0.9182
F1-score: 0.9164
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5154
Epoch 1/10, Batch 20/145, Loss: 0.9046
Epoch 1/10, Batch 30/145, Loss: 0.8073
Epoch 1/10, Batch 40/145, Loss: 0.7812
Epoch 1/10, Batch 50/145, Loss: 0.5504
Epoch 1/10, Batch 60/145, Loss: 0.5920
Epoch 1/10, Batch 70/145, Loss: 0.5981
Epoch 1/10, Batch 80/145, Loss: 0.4949
Epoch 1/10, Batch 90/145, Loss: 0.5716
Epoch 1/10, Batch 100/145, Loss: 0.5732
Epoch 1/10, Batch 110/145, Loss: 0.4174
Epoch 1/10, Batch 120/145, Loss: 0.5312
Epoch 1/10, Batch 130/145, Loss: 0.4206
Epoch 1/10, Batch 140/145, Loss: 0.3942
Epoch 1/10, Train Loss: 0.6838, Valid Loss: 0.3730
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3503
Epoch 2/10, Batch 20/145, Loss: 0.5071
Epoch 2/10, Batch 30/145, Loss: 0.1813
Epoch 2/10, Batch 40/145, Loss: 0.4205
Epoch 2/10, Batch 50/145, Loss: 0.2148
Epoch 2/10, Batch 60/145, Loss: 0.3308
Epoch 2/10, Batch 70/145, Loss: 0.3175
Epoch 2/10, Batch 80/145, Loss: 0.2354
Epoch 2/10, Batch 90/145, Loss: 0.1965
Epoch 2/10, Batch 100/145, Loss: 0.2416
Epoch 2/10, Batch 110/145, Loss: 0.3414
Epoch 2/10, Batch 120/145, Loss: 0.4731
Epoch 2/10, Batch 130/145, Loss: 0.2360
Epoch 2/10, Batch 140/145, Loss: 0.1603
Epoch 2/10, Train Loss: 0.3545, Valid Loss: 0.2861
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2882
Epoch 3/10, Batch 20/145, Loss: 0.2007
Epoch 3/10, Batch 30/145, Loss: 0.1927
Epoch 3/10, Batch 40/145, Loss: 0.1739
Epoch 3/10, Batch 50/145, Loss: 0.2582
Epoch 3/10, Batch 60/145, Loss: 0.3005
Epoch 3/10, Batch 70/145, Loss: 0.2406
Epoch 3/10, Batch 80/145, Loss: 0.2120
Epoch 3/10, Batch 90/145, Loss: 0.4914
Epoch 3/10, Batch 100/145, Loss: 0.2590
Epoch 3/10, Batch 110/145, Loss: 0.3003
Epoch 3/10, Batch 120/145, Loss: 0.2743
Epoch 3/10, Batch 130/145, Loss: 0.3276
Epoch 3/10, Batch 140/145, Loss: 0.2157
Epoch 3/10, Train Loss: 0.2993, Valid Loss: 0.2621
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3355
Epoch 4/10, Batch 20/145, Loss: 0.1289
Epoch 4/10, Batch 30/145, Loss: 0.2049
Epoch 4/10, Batch 40/145, Loss: 0.3423
Epoch 4/10, Batch 50/145, Loss: 0.2598
Epoch 4/10, Batch 60/145, Loss: 0.1649
Epoch 4/10, Batch 70/145, Loss: 0.2573
Epoch 4/10, Batch 80/145, Loss: 0.2370
Epoch 4/10, Batch 90/145, Loss: 0.3800
Epoch 4/10, Batch 100/145, Loss: 0.1747
Epoch 4/10, Batch 110/145, Loss: 0.1590
Epoch 4/10, Batch 120/145, Loss: 0.1429
Epoch 4/10, Batch 130/145, Loss: 0.1665
Epoch 4/10, Batch 140/145, Loss: 0.2165
Epoch 4/10, Train Loss: 0.2649, Valid Loss: 0.2570
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2237
Epoch 5/10, Batch 20/145, Loss: 0.2316
Epoch 5/10, Batch 30/145, Loss: 0.1604
Epoch 5/10, Batch 40/145, Loss: 0.3136
Epoch 5/10, Batch 50/145, Loss: 0.2117
Epoch 5/10, Batch 60/145, Loss: 0.1750
Epoch 5/10, Batch 70/145, Loss: 0.3187
Epoch 5/10, Batch 80/145, Loss: 0.3707
Epoch 5/10, Batch 90/145, Loss: 0.1860
Epoch 5/10, Batch 100/145, Loss: 0.2961
Epoch 5/10, Batch 110/145, Loss: 0.1650
Epoch 5/10, Batch 120/145, Loss: 0.1859
Epoch 5/10, Batch 130/145, Loss: 0.2054
Epoch 5/10, Batch 140/145, Loss: 0.1830
Epoch 5/10, Train Loss: 0.2392, Valid Loss: 0.2335
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2714
Epoch 6/10, Batch 20/145, Loss: 0.2113
Epoch 6/10, Batch 30/145, Loss: 0.2012
Epoch 6/10, Batch 40/145, Loss: 0.0829
Epoch 6/10, Batch 50/145, Loss: 0.4025
Epoch 6/10, Batch 60/145, Loss: 0.2407
Epoch 6/10, Batch 70/145, Loss: 0.2345
Epoch 6/10, Batch 80/145, Loss: 0.3410
Epoch 6/10, Batch 90/145, Loss: 0.1960
Epoch 6/10, Batch 100/145, Loss: 0.2128
Epoch 6/10, Batch 110/145, Loss: 0.2231
Epoch 6/10, Batch 120/145, Loss: 0.2758
Epoch 6/10, Batch 130/145, Loss: 0.1574
Epoch 6/10, Batch 140/145, Loss: 0.2115
Epoch 6/10, Train Loss: 0.2227, Valid Loss: 0.2318
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2824
Epoch 7/10, Batch 20/145, Loss: 0.3392
Epoch 7/10, Batch 30/145, Loss: 0.1286
Epoch 7/10, Batch 40/145, Loss: 0.3771
Epoch 7/10, Batch 50/145, Loss: 0.1464
Epoch 7/10, Batch 60/145, Loss: 0.1199
Epoch 7/10, Batch 70/145, Loss: 0.3842
Epoch 7/10, Batch 80/145, Loss: 0.2235
Epoch 7/10, Batch 90/145, Loss: 0.3060
Epoch 7/10, Batch 100/145, Loss: 0.1331
Epoch 7/10, Batch 110/145, Loss: 0.3418
Epoch 7/10, Batch 120/145, Loss: 0.0681
Epoch 7/10, Batch 130/145, Loss: 0.1416
Epoch 7/10, Batch 140/145, Loss: 0.1163
Epoch 7/10, Train Loss: 0.2165, Valid Loss: 0.2260
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.3149
Epoch 8/10, Batch 20/145, Loss: 0.0677
Epoch 8/10, Batch 30/145, Loss: 0.1484
Epoch 8/10, Batch 40/145, Loss: 0.2701
Epoch 8/10, Batch 50/145, Loss: 0.3818
Epoch 8/10, Batch 60/145, Loss: 0.2618
Epoch 8/10, Batch 70/145, Loss: 0.2311
Epoch 8/10, Batch 80/145, Loss: 0.1884
Epoch 8/10, Batch 90/145, Loss: 0.1833
Epoch 8/10, Batch 100/145, Loss: 0.2406
Epoch 8/10, Batch 110/145, Loss: 0.2386
Epoch 8/10, Batch 120/145, Loss: 0.2053
Epoch 8/10, Batch 130/145, Loss: 0.3789
Epoch 8/10, Batch 140/145, Loss: 0.2700
Epoch 8/10, Train Loss: 0.2085, Valid Loss: 0.2153
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1745
Epoch 9/10, Batch 20/145, Loss: 0.1017
Epoch 9/10, Batch 30/145, Loss: 0.1072
Epoch 9/10, Batch 40/145, Loss: 0.1311
Epoch 9/10, Batch 50/145, Loss: 0.1765
Epoch 9/10, Batch 60/145, Loss: 0.1090
Epoch 9/10, Batch 70/145, Loss: 0.2270
Epoch 9/10, Batch 80/145, Loss: 0.1757
Epoch 9/10, Batch 90/145, Loss: 0.3501
Epoch 9/10, Batch 100/145, Loss: 0.2336
Epoch 9/10, Batch 110/145, Loss: 0.0951
Epoch 9/10, Batch 120/145, Loss: 0.3371
Epoch 9/10, Batch 130/145, Loss: 0.2190
Epoch 9/10, Batch 140/145, Loss: 0.1566
Epoch 9/10, Train Loss: 0.2034, Valid Loss: 0.2081
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1294
Epoch 10/10, Batch 20/145, Loss: 0.1080
Epoch 10/10, Batch 30/145, Loss: 0.0663
Epoch 10/10, Batch 40/145, Loss: 0.1638
Epoch 10/10, Batch 50/145, Loss: 0.2620
Epoch 10/10, Batch 60/145, Loss: 0.2462
Epoch 10/10, Batch 70/145, Loss: 0.1133
Epoch 10/10, Batch 80/145, Loss: 0.4296
Epoch 10/10, Batch 90/145, Loss: 0.1627
Epoch 10/10, Batch 100/145, Loss: 0.0905
Epoch 10/10, Batch 110/145, Loss: 0.2110
Epoch 10/10, Batch 120/145, Loss: 0.1441
Epoch 10/10, Batch 130/145, Loss: 0.0910
Epoch 10/10, Batch 140/145, Loss: 0.2193
Epoch 10/10, Train Loss: 0.1919, Valid Loss: 0.2076
Model saved!
Accuracy: 0.9369
Precision: 0.9360
Recall: 0.9369
F1-score: 0.9364
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 16. Fitness: 0.9369
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4928
Epoch 1/10, Batch 20/145, Loss: 0.8320
Epoch 1/10, Batch 30/145, Loss: 0.7959
Epoch 1/10, Batch 40/145, Loss: 0.7871
Epoch 1/10, Batch 50/145, Loss: 0.7062
Epoch 1/10, Batch 60/145, Loss: 0.6301
Epoch 1/10, Batch 70/145, Loss: 0.7384
Epoch 1/10, Batch 80/145, Loss: 0.4416
Epoch 1/10, Batch 90/145, Loss: 0.5280
Epoch 1/10, Batch 100/145, Loss: 0.5704
Epoch 1/10, Batch 110/145, Loss: 0.3776
Epoch 1/10, Batch 120/145, Loss: 0.4684
Epoch 1/10, Batch 130/145, Loss: 0.3855
Epoch 1/10, Batch 140/145, Loss: 0.3752
Epoch 1/10, Train Loss: 0.6919, Valid Loss: 0.3762
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4126
Epoch 2/10, Batch 20/145, Loss: 0.5345
Epoch 2/10, Batch 30/145, Loss: 0.3633
Epoch 2/10, Batch 40/145, Loss: 0.3645
Epoch 2/10, Batch 50/145, Loss: 0.2901
Epoch 2/10, Batch 60/145, Loss: 0.5594
Epoch 2/10, Batch 70/145, Loss: 0.2710
Epoch 2/10, Batch 80/145, Loss: 0.2585
Epoch 2/10, Batch 90/145, Loss: 0.1833
Epoch 2/10, Batch 100/145, Loss: 0.1538
Epoch 2/10, Batch 110/145, Loss: 0.2362
Epoch 2/10, Batch 120/145, Loss: 0.3394
Epoch 2/10, Batch 130/145, Loss: 0.3359
Epoch 2/10, Batch 140/145, Loss: 0.2450
Epoch 2/10, Train Loss: 0.3613, Valid Loss: 0.2949
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2472
Epoch 3/10, Batch 20/145, Loss: 0.2779
Epoch 3/10, Batch 30/145, Loss: 0.3264
Epoch 3/10, Batch 40/145, Loss: 0.2865
Epoch 3/10, Batch 50/145, Loss: 0.2107
Epoch 3/10, Batch 60/145, Loss: 0.3785
Epoch 3/10, Batch 70/145, Loss: 0.1443
Epoch 3/10, Batch 80/145, Loss: 0.2773
Epoch 3/10, Batch 90/145, Loss: 0.3705
Epoch 3/10, Batch 100/145, Loss: 0.2564
Epoch 3/10, Batch 110/145, Loss: 0.3178
Epoch 3/10, Batch 120/145, Loss: 0.2040
Epoch 3/10, Batch 130/145, Loss: 0.2909
Epoch 3/10, Batch 140/145, Loss: 0.1590
Epoch 3/10, Train Loss: 0.3076, Valid Loss: 0.2692
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3416
Epoch 4/10, Batch 20/145, Loss: 0.2853
Epoch 4/10, Batch 30/145, Loss: 0.1798
Epoch 4/10, Batch 40/145, Loss: 0.2024
Epoch 4/10, Batch 50/145, Loss: 0.1465
Epoch 4/10, Batch 60/145, Loss: 0.1667
Epoch 4/10, Batch 70/145, Loss: 0.2608
Epoch 4/10, Batch 80/145, Loss: 0.2906
Epoch 4/10, Batch 90/145, Loss: 0.3355
Epoch 4/10, Batch 100/145, Loss: 0.2931
Epoch 4/10, Batch 110/145, Loss: 0.1643
Epoch 4/10, Batch 120/145, Loss: 0.3059
Epoch 4/10, Batch 130/145, Loss: 0.1743
Epoch 4/10, Batch 140/145, Loss: 0.1017
Epoch 4/10, Train Loss: 0.2661, Valid Loss: 0.2534
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2619
Epoch 5/10, Batch 20/145, Loss: 0.2949
Epoch 5/10, Batch 30/145, Loss: 0.3150
Epoch 5/10, Batch 40/145, Loss: 0.1930
Epoch 5/10, Batch 50/145, Loss: 0.0956
Epoch 5/10, Batch 60/145, Loss: 0.3524
Epoch 5/10, Batch 70/145, Loss: 0.2321
Epoch 5/10, Batch 80/145, Loss: 0.2057
Epoch 5/10, Batch 90/145, Loss: 0.1209
Epoch 5/10, Batch 100/145, Loss: 0.3296
Epoch 5/10, Batch 110/145, Loss: 0.1331
Epoch 5/10, Batch 120/145, Loss: 0.2565
Epoch 5/10, Batch 130/145, Loss: 0.2895
Epoch 5/10, Batch 140/145, Loss: 0.3417
Epoch 5/10, Train Loss: 0.2400, Valid Loss: 0.2419
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2225
Epoch 6/10, Batch 20/145, Loss: 0.2511
Epoch 6/10, Batch 30/145, Loss: 0.2605
Epoch 6/10, Batch 40/145, Loss: 0.1021
Epoch 6/10, Batch 50/145, Loss: 0.2602
Epoch 6/10, Batch 60/145, Loss: 0.1546
Epoch 6/10, Batch 70/145, Loss: 0.1956
Epoch 6/10, Batch 80/145, Loss: 0.2845
Epoch 6/10, Batch 90/145, Loss: 0.1914
Epoch 6/10, Batch 100/145, Loss: 0.1345
Epoch 6/10, Batch 110/145, Loss: 0.1434
Epoch 6/10, Batch 120/145, Loss: 0.1836
Epoch 6/10, Batch 130/145, Loss: 0.0650
Epoch 6/10, Batch 140/145, Loss: 0.2087
Epoch 6/10, Train Loss: 0.2299, Valid Loss: 0.2359
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3446
Epoch 7/10, Batch 20/145, Loss: 0.2390
Epoch 7/10, Batch 30/145, Loss: 0.2313
Epoch 7/10, Batch 40/145, Loss: 0.4056
Epoch 7/10, Batch 50/145, Loss: 0.1050
Epoch 7/10, Batch 60/145, Loss: 0.1444
Epoch 7/10, Batch 70/145, Loss: 0.2099
Epoch 7/10, Batch 80/145, Loss: 0.1017
Epoch 7/10, Batch 90/145, Loss: 0.2398
Epoch 7/10, Batch 100/145, Loss: 0.1989
Epoch 7/10, Batch 110/145, Loss: 0.2493
Epoch 7/10, Batch 120/145, Loss: 0.3306
Epoch 7/10, Batch 130/145, Loss: 0.1863
Epoch 7/10, Batch 140/145, Loss: 0.1641
Epoch 7/10, Train Loss: 0.2197, Valid Loss: 0.2371
Epoch 8/10, Batch 10/145, Loss: 0.3508
Epoch 8/10, Batch 20/145, Loss: 0.2291
Epoch 8/10, Batch 30/145, Loss: 0.0944
Epoch 8/10, Batch 40/145, Loss: 0.1623
Epoch 8/10, Batch 50/145, Loss: 0.2285
Epoch 8/10, Batch 60/145, Loss: 0.2808
Epoch 8/10, Batch 70/145, Loss: 0.0561
Epoch 8/10, Batch 80/145, Loss: 0.2348
Epoch 8/10, Batch 90/145, Loss: 0.1715
Epoch 8/10, Batch 100/145, Loss: 0.4030
Epoch 8/10, Batch 110/145, Loss: 0.3853
Epoch 8/10, Batch 120/145, Loss: 0.1327
Epoch 8/10, Batch 130/145, Loss: 0.0807
Epoch 8/10, Batch 140/145, Loss: 0.3040
Epoch 8/10, Train Loss: 0.2131, Valid Loss: 0.2241
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.4386
Epoch 9/10, Batch 20/145, Loss: 0.1729
Epoch 9/10, Batch 30/145, Loss: 0.0835
Epoch 9/10, Batch 40/145, Loss: 0.3014
Epoch 9/10, Batch 50/145, Loss: 0.2457
Epoch 9/10, Batch 60/145, Loss: 0.1920
Epoch 9/10, Batch 70/145, Loss: 0.2758
Epoch 9/10, Batch 80/145, Loss: 0.3424
Epoch 9/10, Batch 90/145, Loss: 0.0937
Epoch 9/10, Batch 100/145, Loss: 0.2731
Epoch 9/10, Batch 110/145, Loss: 0.1578
Epoch 9/10, Batch 120/145, Loss: 0.2890
Epoch 9/10, Batch 130/145, Loss: 0.2941
Epoch 9/10, Batch 140/145, Loss: 0.1882
Epoch 9/10, Train Loss: 0.2013, Valid Loss: 0.2141
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2607
Epoch 10/10, Batch 20/145, Loss: 0.1397
Epoch 10/10, Batch 30/145, Loss: 0.1208
Epoch 10/10, Batch 40/145, Loss: 0.1733
Epoch 10/10, Batch 50/145, Loss: 0.1823
Epoch 10/10, Batch 60/145, Loss: 0.1317
Epoch 10/10, Batch 70/145, Loss: 0.0958
Epoch 10/10, Batch 80/145, Loss: 0.5183
Epoch 10/10, Batch 90/145, Loss: 0.1574
Epoch 10/10, Batch 100/145, Loss: 0.1818
Epoch 10/10, Batch 110/145, Loss: 0.2356
Epoch 10/10, Batch 120/145, Loss: 0.2435
Epoch 10/10, Batch 130/145, Loss: 0.1195
Epoch 10/10, Batch 140/145, Loss: 0.2477
Epoch 10/10, Train Loss: 0.1966, Valid Loss: 0.2144
Accuracy: 0.9171
Precision: 0.9153
Recall: 0.9171
F1-score: 0.9157
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4476
Epoch 1/10, Batch 20/145, Loss: 1.0021
Epoch 1/10, Batch 30/145, Loss: 0.7904
Epoch 1/10, Batch 40/145, Loss: 0.8905
Epoch 1/10, Batch 50/145, Loss: 0.5905
Epoch 1/10, Batch 60/145, Loss: 0.5990
Epoch 1/10, Batch 70/145, Loss: 0.5694
Epoch 1/10, Batch 80/145, Loss: 0.5792
Epoch 1/10, Batch 90/145, Loss: 0.7207
Epoch 1/10, Batch 100/145, Loss: 0.6644
Epoch 1/10, Batch 110/145, Loss: 0.3721
Epoch 1/10, Batch 120/145, Loss: 0.6760
Epoch 1/10, Batch 130/145, Loss: 0.3046
Epoch 1/10, Batch 140/145, Loss: 0.5037
Epoch 1/10, Train Loss: 0.6802, Valid Loss: 0.3682
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2468
Epoch 2/10, Batch 20/145, Loss: 0.5057
Epoch 2/10, Batch 30/145, Loss: 0.2519
Epoch 2/10, Batch 40/145, Loss: 0.4741
Epoch 2/10, Batch 50/145, Loss: 0.2452
Epoch 2/10, Batch 60/145, Loss: 0.3989
Epoch 2/10, Batch 70/145, Loss: 0.4155
Epoch 2/10, Batch 80/145, Loss: 0.3197
Epoch 2/10, Batch 90/145, Loss: 0.2691
Epoch 2/10, Batch 100/145, Loss: 0.3188
Epoch 2/10, Batch 110/145, Loss: 0.3559
Epoch 2/10, Batch 120/145, Loss: 0.5051
Epoch 2/10, Batch 130/145, Loss: 0.2330
Epoch 2/10, Batch 140/145, Loss: 0.2390
Epoch 2/10, Train Loss: 0.3628, Valid Loss: 0.2841
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1977
Epoch 3/10, Batch 20/145, Loss: 0.4157
Epoch 3/10, Batch 30/145, Loss: 0.2823
Epoch 3/10, Batch 40/145, Loss: 0.2155
Epoch 3/10, Batch 50/145, Loss: 0.1481
Epoch 3/10, Batch 60/145, Loss: 0.3587
Epoch 3/10, Batch 70/145, Loss: 0.1993
Epoch 3/10, Batch 80/145, Loss: 0.2535
Epoch 3/10, Batch 90/145, Loss: 0.5017
Epoch 3/10, Batch 100/145, Loss: 0.2858
Epoch 3/10, Batch 110/145, Loss: 0.3226
Epoch 3/10, Batch 120/145, Loss: 0.2577
Epoch 3/10, Batch 130/145, Loss: 0.3925
Epoch 3/10, Batch 140/145, Loss: 0.1831
Epoch 3/10, Train Loss: 0.3050, Valid Loss: 0.2678
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2608
Epoch 4/10, Batch 20/145, Loss: 0.1975
Epoch 4/10, Batch 30/145, Loss: 0.3865
Epoch 4/10, Batch 40/145, Loss: 0.3783
Epoch 4/10, Batch 50/145, Loss: 0.1968
Epoch 4/10, Batch 60/145, Loss: 0.1469
Epoch 4/10, Batch 70/145, Loss: 0.2606
Epoch 4/10, Batch 80/145, Loss: 0.2721
Epoch 4/10, Batch 90/145, Loss: 0.2293
Epoch 4/10, Batch 100/145, Loss: 0.3758
Epoch 4/10, Batch 110/145, Loss: 0.1907
Epoch 4/10, Batch 120/145, Loss: 0.1386
Epoch 4/10, Batch 130/145, Loss: 0.2052
Epoch 4/10, Batch 140/145, Loss: 0.1793
Epoch 4/10, Train Loss: 0.2661, Valid Loss: 0.2524
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2645
Epoch 5/10, Batch 20/145, Loss: 0.3991
Epoch 5/10, Batch 30/145, Loss: 0.1412
Epoch 5/10, Batch 40/145, Loss: 0.2992
Epoch 5/10, Batch 50/145, Loss: 0.1945
Epoch 5/10, Batch 60/145, Loss: 0.2853
Epoch 5/10, Batch 70/145, Loss: 0.3815
Epoch 5/10, Batch 80/145, Loss: 0.3219
Epoch 5/10, Batch 90/145, Loss: 0.2477
Epoch 5/10, Batch 100/145, Loss: 0.2465
Epoch 5/10, Batch 110/145, Loss: 0.2085
Epoch 5/10, Batch 120/145, Loss: 0.1979
Epoch 5/10, Batch 130/145, Loss: 0.1609
Epoch 5/10, Batch 140/145, Loss: 0.3735
Epoch 5/10, Train Loss: 0.2426, Valid Loss: 0.2344
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2010
Epoch 6/10, Batch 20/145, Loss: 0.3403
Epoch 6/10, Batch 30/145, Loss: 0.2156
Epoch 6/10, Batch 40/145, Loss: 0.2407
Epoch 6/10, Batch 50/145, Loss: 0.2630
Epoch 6/10, Batch 60/145, Loss: 0.1141
Epoch 6/10, Batch 70/145, Loss: 0.3156
Epoch 6/10, Batch 80/145, Loss: 0.2657
Epoch 6/10, Batch 90/145, Loss: 0.2071
Epoch 6/10, Batch 100/145, Loss: 0.2998
Epoch 6/10, Batch 110/145, Loss: 0.2227
Epoch 6/10, Batch 120/145, Loss: 0.2647
Epoch 6/10, Batch 130/145, Loss: 0.2387
Epoch 6/10, Batch 140/145, Loss: 0.1089
Epoch 6/10, Train Loss: 0.2270, Valid Loss: 0.2292
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2185
Epoch 7/10, Batch 20/145, Loss: 0.3193
Epoch 7/10, Batch 30/145, Loss: 0.1337
Epoch 7/10, Batch 40/145, Loss: 0.4854
Epoch 7/10, Batch 50/145, Loss: 0.1242
Epoch 7/10, Batch 60/145, Loss: 0.2418
Epoch 7/10, Batch 70/145, Loss: 0.2511
Epoch 7/10, Batch 80/145, Loss: 0.1936
Epoch 7/10, Batch 90/145, Loss: 0.2388
Epoch 7/10, Batch 100/145, Loss: 0.2017
Epoch 7/10, Batch 110/145, Loss: 0.3001
Epoch 7/10, Batch 120/145, Loss: 0.1928
Epoch 7/10, Batch 130/145, Loss: 0.3242
Epoch 7/10, Batch 140/145, Loss: 0.1644
Epoch 7/10, Train Loss: 0.2229, Valid Loss: 0.2193
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1249
Epoch 8/10, Batch 20/145, Loss: 0.1648
Epoch 8/10, Batch 30/145, Loss: 0.3157
Epoch 8/10, Batch 40/145, Loss: 0.4134
Epoch 8/10, Batch 50/145, Loss: 0.1076
Epoch 8/10, Batch 60/145, Loss: 0.2223
Epoch 8/10, Batch 70/145, Loss: 0.1646
Epoch 8/10, Batch 80/145, Loss: 0.2269
Epoch 8/10, Batch 90/145, Loss: 0.1186
Epoch 8/10, Batch 100/145, Loss: 0.1871
Epoch 8/10, Batch 110/145, Loss: 0.2126
Epoch 8/10, Batch 120/145, Loss: 0.2799
Epoch 8/10, Batch 130/145, Loss: 0.2059
Epoch 8/10, Batch 140/145, Loss: 0.1775
Epoch 8/10, Train Loss: 0.2082, Valid Loss: 0.2135
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3285
Epoch 9/10, Batch 20/145, Loss: 0.1563
Epoch 9/10, Batch 30/145, Loss: 0.1638
Epoch 9/10, Batch 40/145, Loss: 0.1937
Epoch 9/10, Batch 50/145, Loss: 0.1787
Epoch 9/10, Batch 60/145, Loss: 0.1626
Epoch 9/10, Batch 70/145, Loss: 0.1639
Epoch 9/10, Batch 80/145, Loss: 0.1176
Epoch 9/10, Batch 90/145, Loss: 0.0868
Epoch 9/10, Batch 100/145, Loss: 0.1910
Epoch 9/10, Batch 110/145, Loss: 0.0842
Epoch 9/10, Batch 120/145, Loss: 0.1928
Epoch 9/10, Batch 130/145, Loss: 0.2681
Epoch 9/10, Batch 140/145, Loss: 0.1043
Epoch 9/10, Train Loss: 0.1978, Valid Loss: 0.2120
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0713
Epoch 10/10, Batch 20/145, Loss: 0.1439
Epoch 10/10, Batch 30/145, Loss: 0.0960
Epoch 10/10, Batch 40/145, Loss: 0.3301
Epoch 10/10, Batch 50/145, Loss: 0.2511
Epoch 10/10, Batch 60/145, Loss: 0.1408
Epoch 10/10, Batch 70/145, Loss: 0.0895
Epoch 10/10, Batch 80/145, Loss: 0.4612
Epoch 10/10, Batch 90/145, Loss: 0.1572
Epoch 10/10, Batch 100/145, Loss: 0.1898
Epoch 10/10, Batch 110/145, Loss: 0.3127
Epoch 10/10, Batch 120/145, Loss: 0.2120
Epoch 10/10, Batch 130/145, Loss: 0.2065
Epoch 10/10, Batch 140/145, Loss: 0.2821
Epoch 10/10, Train Loss: 0.1967, Valid Loss: 0.2108
Model saved!
Accuracy: 0.9089
Precision: 0.9068
Recall: 0.9089
F1-score: 0.9067
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5075
Epoch 1/10, Batch 20/145, Loss: 0.9008
Epoch 1/10, Batch 30/145, Loss: 0.7256
Epoch 1/10, Batch 40/145, Loss: 0.8405
Epoch 1/10, Batch 50/145, Loss: 0.7227
Epoch 1/10, Batch 60/145, Loss: 0.5341
Epoch 1/10, Batch 70/145, Loss: 0.5716
Epoch 1/10, Batch 80/145, Loss: 0.5884
Epoch 1/10, Batch 90/145, Loss: 0.4796
Epoch 1/10, Batch 100/145, Loss: 0.6560
Epoch 1/10, Batch 110/145, Loss: 0.4559
Epoch 1/10, Batch 120/145, Loss: 0.5727
Epoch 1/10, Batch 130/145, Loss: 0.3635
Epoch 1/10, Batch 140/145, Loss: 0.3830
Epoch 1/10, Train Loss: 0.6833, Valid Loss: 0.3831
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3784
Epoch 2/10, Batch 20/145, Loss: 0.5376
Epoch 2/10, Batch 30/145, Loss: 0.3471
Epoch 2/10, Batch 40/145, Loss: 0.5798
Epoch 2/10, Batch 50/145, Loss: 0.3854
Epoch 2/10, Batch 60/145, Loss: 0.3573
Epoch 2/10, Batch 70/145, Loss: 0.3431
Epoch 2/10, Batch 80/145, Loss: 0.4256
Epoch 2/10, Batch 90/145, Loss: 0.3118
Epoch 2/10, Batch 100/145, Loss: 0.3109
Epoch 2/10, Batch 110/145, Loss: 0.3046
Epoch 2/10, Batch 120/145, Loss: 0.3191
Epoch 2/10, Batch 130/145, Loss: 0.3067
Epoch 2/10, Batch 140/145, Loss: 0.4112
Epoch 2/10, Train Loss: 0.3601, Valid Loss: 0.3023
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3006
Epoch 3/10, Batch 20/145, Loss: 0.3185
Epoch 3/10, Batch 30/145, Loss: 0.2409
Epoch 3/10, Batch 40/145, Loss: 0.2807
Epoch 3/10, Batch 50/145, Loss: 0.1406
Epoch 3/10, Batch 60/145, Loss: 0.3309
Epoch 3/10, Batch 70/145, Loss: 0.1722
Epoch 3/10, Batch 80/145, Loss: 0.2229
Epoch 3/10, Batch 90/145, Loss: 0.6532
Epoch 3/10, Batch 100/145, Loss: 0.2766
Epoch 3/10, Batch 110/145, Loss: 0.3009
Epoch 3/10, Batch 120/145, Loss: 0.1381
Epoch 3/10, Batch 130/145, Loss: 0.2214
Epoch 3/10, Batch 140/145, Loss: 0.1412
Epoch 3/10, Train Loss: 0.3036, Valid Loss: 0.2644
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2572
Epoch 4/10, Batch 20/145, Loss: 0.1648
Epoch 4/10, Batch 30/145, Loss: 0.4319
Epoch 4/10, Batch 40/145, Loss: 0.3242
Epoch 4/10, Batch 50/145, Loss: 0.2451
Epoch 4/10, Batch 60/145, Loss: 0.1624
Epoch 4/10, Batch 70/145, Loss: 0.2333
Epoch 4/10, Batch 80/145, Loss: 0.2506
Epoch 4/10, Batch 90/145, Loss: 0.2293
Epoch 4/10, Batch 100/145, Loss: 0.2188
Epoch 4/10, Batch 110/145, Loss: 0.2552
Epoch 4/10, Batch 120/145, Loss: 0.2621
Epoch 4/10, Batch 130/145, Loss: 0.1744
Epoch 4/10, Batch 140/145, Loss: 0.2017
Epoch 4/10, Train Loss: 0.2675, Valid Loss: 0.2648
Epoch 5/10, Batch 10/145, Loss: 0.2413
Epoch 5/10, Batch 20/145, Loss: 0.1757
Epoch 5/10, Batch 30/145, Loss: 0.4164
Epoch 5/10, Batch 40/145, Loss: 0.3009
Epoch 5/10, Batch 50/145, Loss: 0.1603
Epoch 5/10, Batch 60/145, Loss: 0.1648
Epoch 5/10, Batch 70/145, Loss: 0.3316
Epoch 5/10, Batch 80/145, Loss: 0.2300
Epoch 5/10, Batch 90/145, Loss: 0.1288
Epoch 5/10, Batch 100/145, Loss: 0.3312
Epoch 5/10, Batch 110/145, Loss: 0.2233
Epoch 5/10, Batch 120/145, Loss: 0.2498
Epoch 5/10, Batch 130/145, Loss: 0.3631
Epoch 5/10, Batch 140/145, Loss: 0.1488
Epoch 5/10, Train Loss: 0.2371, Valid Loss: 0.2455
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2168
Epoch 6/10, Batch 20/145, Loss: 0.2340
Epoch 6/10, Batch 30/145, Loss: 0.1971
Epoch 6/10, Batch 40/145, Loss: 0.1639
Epoch 6/10, Batch 50/145, Loss: 0.4813
Epoch 6/10, Batch 60/145, Loss: 0.2087
Epoch 6/10, Batch 70/145, Loss: 0.2907
Epoch 6/10, Batch 80/145, Loss: 0.2600
Epoch 6/10, Batch 90/145, Loss: 0.2433
Epoch 6/10, Batch 100/145, Loss: 0.2868
Epoch 6/10, Batch 110/145, Loss: 0.2083
Epoch 6/10, Batch 120/145, Loss: 0.3029
Epoch 6/10, Batch 130/145, Loss: 0.1596
Epoch 6/10, Batch 140/145, Loss: 0.3812
Epoch 6/10, Train Loss: 0.2324, Valid Loss: 0.2447
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1807
Epoch 7/10, Batch 20/145, Loss: 0.3393
Epoch 7/10, Batch 30/145, Loss: 0.1547
Epoch 7/10, Batch 40/145, Loss: 0.4238
Epoch 7/10, Batch 50/145, Loss: 0.2495
Epoch 7/10, Batch 60/145, Loss: 0.1809
Epoch 7/10, Batch 70/145, Loss: 0.2156
Epoch 7/10, Batch 80/145, Loss: 0.1881
Epoch 7/10, Batch 90/145, Loss: 0.3052
Epoch 7/10, Batch 100/145, Loss: 0.1294
Epoch 7/10, Batch 110/145, Loss: 0.3160
Epoch 7/10, Batch 120/145, Loss: 0.0729
Epoch 7/10, Batch 130/145, Loss: 0.3384
Epoch 7/10, Batch 140/145, Loss: 0.1691
Epoch 7/10, Train Loss: 0.2251, Valid Loss: 0.2339
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2380
Epoch 8/10, Batch 20/145, Loss: 0.1173
Epoch 8/10, Batch 30/145, Loss: 0.1646
Epoch 8/10, Batch 40/145, Loss: 0.3948
Epoch 8/10, Batch 50/145, Loss: 0.2902
Epoch 8/10, Batch 60/145, Loss: 0.3154
Epoch 8/10, Batch 70/145, Loss: 0.0935
Epoch 8/10, Batch 80/145, Loss: 0.2674
Epoch 8/10, Batch 90/145, Loss: 0.1343
Epoch 8/10, Batch 100/145, Loss: 0.3053
Epoch 8/10, Batch 110/145, Loss: 0.3724
Epoch 8/10, Batch 120/145, Loss: 0.2237
Epoch 8/10, Batch 130/145, Loss: 0.1130
Epoch 8/10, Batch 140/145, Loss: 0.2682
Epoch 8/10, Train Loss: 0.2096, Valid Loss: 0.2289
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3108
Epoch 9/10, Batch 20/145, Loss: 0.1550
Epoch 9/10, Batch 30/145, Loss: 0.1632
Epoch 9/10, Batch 40/145, Loss: 0.1292
Epoch 9/10, Batch 50/145, Loss: 0.2130
Epoch 9/10, Batch 60/145, Loss: 0.1861
Epoch 9/10, Batch 70/145, Loss: 0.2125
Epoch 9/10, Batch 80/145, Loss: 0.2405
Epoch 9/10, Batch 90/145, Loss: 0.1952
Epoch 9/10, Batch 100/145, Loss: 0.1741
Epoch 9/10, Batch 110/145, Loss: 0.1564
Epoch 9/10, Batch 120/145, Loss: 0.1756
Epoch 9/10, Batch 130/145, Loss: 0.3372
Epoch 9/10, Batch 140/145, Loss: 0.1274
Epoch 9/10, Train Loss: 0.2052, Valid Loss: 0.2197
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2147
Epoch 10/10, Batch 20/145, Loss: 0.1074
Epoch 10/10, Batch 30/145, Loss: 0.0404
Epoch 10/10, Batch 40/145, Loss: 0.1817
Epoch 10/10, Batch 50/145, Loss: 0.0983
Epoch 10/10, Batch 60/145, Loss: 0.1052
Epoch 10/10, Batch 70/145, Loss: 0.1586
Epoch 10/10, Batch 80/145, Loss: 0.4087
Epoch 10/10, Batch 90/145, Loss: 0.0921
Epoch 10/10, Batch 100/145, Loss: 0.2357
Epoch 10/10, Batch 110/145, Loss: 0.2469
Epoch 10/10, Batch 120/145, Loss: 0.3393
Epoch 10/10, Batch 130/145, Loss: 0.0827
Epoch 10/10, Batch 140/145, Loss: 0.2410
Epoch 10/10, Train Loss: 0.2005, Valid Loss: 0.2098
Model saved!
Accuracy: 0.9194
Precision: 0.9185
Recall: 0.9194
F1-score: 0.9188
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4893
Epoch 1/10, Batch 20/145, Loss: 0.9193
Epoch 1/10, Batch 30/145, Loss: 0.8688
Epoch 1/10, Batch 40/145, Loss: 0.9296
Epoch 1/10, Batch 50/145, Loss: 0.6976
Epoch 1/10, Batch 60/145, Loss: 0.5658
Epoch 1/10, Batch 70/145, Loss: 0.5025
Epoch 1/10, Batch 80/145, Loss: 0.5187
Epoch 1/10, Batch 90/145, Loss: 0.6322
Epoch 1/10, Batch 100/145, Loss: 0.4921
Epoch 1/10, Batch 110/145, Loss: 0.3630
Epoch 1/10, Batch 120/145, Loss: 0.5104
Epoch 1/10, Batch 130/145, Loss: 0.3199
Epoch 1/10, Batch 140/145, Loss: 0.3586
Epoch 1/10, Train Loss: 0.6896, Valid Loss: 0.3692
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4352
Epoch 2/10, Batch 20/145, Loss: 0.4281
Epoch 2/10, Batch 30/145, Loss: 0.3840
Epoch 2/10, Batch 40/145, Loss: 0.5063
Epoch 2/10, Batch 50/145, Loss: 0.1951
Epoch 2/10, Batch 60/145, Loss: 0.4027
Epoch 2/10, Batch 70/145, Loss: 0.3847
Epoch 2/10, Batch 80/145, Loss: 0.3434
Epoch 2/10, Batch 90/145, Loss: 0.2499
Epoch 2/10, Batch 100/145, Loss: 0.2708
Epoch 2/10, Batch 110/145, Loss: 0.2574
Epoch 2/10, Batch 120/145, Loss: 0.4079
Epoch 2/10, Batch 130/145, Loss: 0.3078
Epoch 2/10, Batch 140/145, Loss: 0.2514
Epoch 2/10, Train Loss: 0.3683, Valid Loss: 0.2892
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1772
Epoch 3/10, Batch 20/145, Loss: 0.3472
Epoch 3/10, Batch 30/145, Loss: 0.2436
Epoch 3/10, Batch 40/145, Loss: 0.2751
Epoch 3/10, Batch 50/145, Loss: 0.1733
Epoch 3/10, Batch 60/145, Loss: 0.2844
Epoch 3/10, Batch 70/145, Loss: 0.3180
Epoch 3/10, Batch 80/145, Loss: 0.3617
Epoch 3/10, Batch 90/145, Loss: 0.4712
Epoch 3/10, Batch 100/145, Loss: 0.2456
Epoch 3/10, Batch 110/145, Loss: 0.3112
Epoch 3/10, Batch 120/145, Loss: 0.1721
Epoch 3/10, Batch 130/145, Loss: 0.2983
Epoch 3/10, Batch 140/145, Loss: 0.2386
Epoch 3/10, Train Loss: 0.3080, Valid Loss: 0.2542
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2208
Epoch 4/10, Batch 20/145, Loss: 0.3529
Epoch 4/10, Batch 30/145, Loss: 0.2895
Epoch 4/10, Batch 40/145, Loss: 0.3219
Epoch 4/10, Batch 50/145, Loss: 0.1860
Epoch 4/10, Batch 60/145, Loss: 0.2241
Epoch 4/10, Batch 70/145, Loss: 0.4349
Epoch 4/10, Batch 80/145, Loss: 0.2531
Epoch 4/10, Batch 90/145, Loss: 0.2768
Epoch 4/10, Batch 100/145, Loss: 0.2189
Epoch 4/10, Batch 110/145, Loss: 0.2338
Epoch 4/10, Batch 120/145, Loss: 0.2503
Epoch 4/10, Batch 130/145, Loss: 0.2794
Epoch 4/10, Batch 140/145, Loss: 0.1618
Epoch 4/10, Train Loss: 0.2704, Valid Loss: 0.2595
Epoch 5/10, Batch 10/145, Loss: 0.2045
Epoch 5/10, Batch 20/145, Loss: 0.3543
Epoch 5/10, Batch 30/145, Loss: 0.2386
Epoch 5/10, Batch 40/145, Loss: 0.2093
Epoch 5/10, Batch 50/145, Loss: 0.1903
Epoch 5/10, Batch 60/145, Loss: 0.1687
Epoch 5/10, Batch 70/145, Loss: 0.2698
Epoch 5/10, Batch 80/145, Loss: 0.3423
Epoch 5/10, Batch 90/145, Loss: 0.3767
Epoch 5/10, Batch 100/145, Loss: 0.3051
Epoch 5/10, Batch 110/145, Loss: 0.1000
Epoch 5/10, Batch 120/145, Loss: 0.1905
Epoch 5/10, Batch 130/145, Loss: 0.2622
Epoch 5/10, Batch 140/145, Loss: 0.3486
Epoch 5/10, Train Loss: 0.2477, Valid Loss: 0.2288
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3157
Epoch 6/10, Batch 20/145, Loss: 0.2483
Epoch 6/10, Batch 30/145, Loss: 0.1544
Epoch 6/10, Batch 40/145, Loss: 0.1719
Epoch 6/10, Batch 50/145, Loss: 0.3347
Epoch 6/10, Batch 60/145, Loss: 0.1378
Epoch 6/10, Batch 70/145, Loss: 0.3534
Epoch 6/10, Batch 80/145, Loss: 0.2655
Epoch 6/10, Batch 90/145, Loss: 0.2970
Epoch 6/10, Batch 100/145, Loss: 0.2345
Epoch 6/10, Batch 110/145, Loss: 0.1483
Epoch 6/10, Batch 120/145, Loss: 0.2872
Epoch 6/10, Batch 130/145, Loss: 0.1714
Epoch 6/10, Batch 140/145, Loss: 0.2795
Epoch 6/10, Train Loss: 0.2348, Valid Loss: 0.2205
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2784
Epoch 7/10, Batch 20/145, Loss: 0.2689
Epoch 7/10, Batch 30/145, Loss: 0.2433
Epoch 7/10, Batch 40/145, Loss: 0.4325
Epoch 7/10, Batch 50/145, Loss: 0.2660
Epoch 7/10, Batch 60/145, Loss: 0.1068
Epoch 7/10, Batch 70/145, Loss: 0.2461
Epoch 7/10, Batch 80/145, Loss: 0.2007
Epoch 7/10, Batch 90/145, Loss: 0.3142
Epoch 7/10, Batch 100/145, Loss: 0.1382
Epoch 7/10, Batch 110/145, Loss: 0.3275
Epoch 7/10, Batch 120/145, Loss: 0.2707
Epoch 7/10, Batch 130/145, Loss: 0.2319
Epoch 7/10, Batch 140/145, Loss: 0.1134
Epoch 7/10, Train Loss: 0.2218, Valid Loss: 0.2162
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1484
Epoch 8/10, Batch 20/145, Loss: 0.1727
Epoch 8/10, Batch 30/145, Loss: 0.1764
Epoch 8/10, Batch 40/145, Loss: 0.2838
Epoch 8/10, Batch 50/145, Loss: 0.1756
Epoch 8/10, Batch 60/145, Loss: 0.1805
Epoch 8/10, Batch 70/145, Loss: 0.1720
Epoch 8/10, Batch 80/145, Loss: 0.1968
Epoch 8/10, Batch 90/145, Loss: 0.1665
Epoch 8/10, Batch 100/145, Loss: 0.2275
Epoch 8/10, Batch 110/145, Loss: 0.2210
Epoch 8/10, Batch 120/145, Loss: 0.2900
Epoch 8/10, Batch 130/145, Loss: 0.1672
Epoch 8/10, Batch 140/145, Loss: 0.2198
Epoch 8/10, Train Loss: 0.2114, Valid Loss: 0.2177
Epoch 9/10, Batch 10/145, Loss: 0.3565
Epoch 9/10, Batch 20/145, Loss: 0.1424
Epoch 9/10, Batch 30/145, Loss: 0.1749
Epoch 9/10, Batch 40/145, Loss: 0.1548
Epoch 9/10, Batch 50/145, Loss: 0.1063
Epoch 9/10, Batch 60/145, Loss: 0.1360
Epoch 9/10, Batch 70/145, Loss: 0.1616
Epoch 9/10, Batch 80/145, Loss: 0.3556
Epoch 9/10, Batch 90/145, Loss: 0.2013
Epoch 9/10, Batch 100/145, Loss: 0.2077
Epoch 9/10, Batch 110/145, Loss: 0.1130
Epoch 9/10, Batch 120/145, Loss: 0.2654
Epoch 9/10, Batch 130/145, Loss: 0.3120
Epoch 9/10, Batch 140/145, Loss: 0.0847
Epoch 9/10, Train Loss: 0.2077, Valid Loss: 0.2094
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2400
Epoch 10/10, Batch 20/145, Loss: 0.2570
Epoch 10/10, Batch 30/145, Loss: 0.0884
Epoch 10/10, Batch 40/145, Loss: 0.2061
Epoch 10/10, Batch 50/145, Loss: 0.1940
Epoch 10/10, Batch 60/145, Loss: 0.2534
Epoch 10/10, Batch 70/145, Loss: 0.1555
Epoch 10/10, Batch 80/145, Loss: 0.3539
Epoch 10/10, Batch 90/145, Loss: 0.1839
Epoch 10/10, Batch 100/145, Loss: 0.1615
Epoch 10/10, Batch 110/145, Loss: 0.3302
Epoch 10/10, Batch 120/145, Loss: 0.1209
Epoch 10/10, Batch 130/145, Loss: 0.2546
Epoch 10/10, Batch 140/145, Loss: 0.1971
Epoch 10/10, Train Loss: 0.2017, Valid Loss: 0.2107
Accuracy: 0.9206
Precision: 0.9178
Recall: 0.9206
F1-score: 0.9184
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5578
Epoch 1/10, Batch 20/145, Loss: 0.9784
Epoch 1/10, Batch 30/145, Loss: 0.8289
Epoch 1/10, Batch 40/145, Loss: 0.7546
Epoch 1/10, Batch 50/145, Loss: 0.6346
Epoch 1/10, Batch 60/145, Loss: 0.5997
Epoch 1/10, Batch 70/145, Loss: 0.5832
Epoch 1/10, Batch 80/145, Loss: 0.6001
Epoch 1/10, Batch 90/145, Loss: 0.5264
Epoch 1/10, Batch 100/145, Loss: 0.6054
Epoch 1/10, Batch 110/145, Loss: 0.3708
Epoch 1/10, Batch 120/145, Loss: 0.6394
Epoch 1/10, Batch 130/145, Loss: 0.3947
Epoch 1/10, Batch 140/145, Loss: 0.4954
Epoch 1/10, Train Loss: 0.6834, Valid Loss: 0.4051
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3318
Epoch 2/10, Batch 20/145, Loss: 0.5731
Epoch 2/10, Batch 30/145, Loss: 0.2847
Epoch 2/10, Batch 40/145, Loss: 0.3378
Epoch 2/10, Batch 50/145, Loss: 0.4312
Epoch 2/10, Batch 60/145, Loss: 0.4076
Epoch 2/10, Batch 70/145, Loss: 0.3872
Epoch 2/10, Batch 80/145, Loss: 0.3878
Epoch 2/10, Batch 90/145, Loss: 0.2618
Epoch 2/10, Batch 100/145, Loss: 0.3602
Epoch 2/10, Batch 110/145, Loss: 0.3829
Epoch 2/10, Batch 120/145, Loss: 0.4188
Epoch 2/10, Batch 130/145, Loss: 0.4541
Epoch 2/10, Batch 140/145, Loss: 0.4216
Epoch 2/10, Train Loss: 0.3595, Valid Loss: 0.3095
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1794
Epoch 3/10, Batch 20/145, Loss: 0.2610
Epoch 3/10, Batch 30/145, Loss: 0.2488
Epoch 3/10, Batch 40/145, Loss: 0.1699
Epoch 3/10, Batch 50/145, Loss: 0.1694
Epoch 3/10, Batch 60/145, Loss: 0.3230
Epoch 3/10, Batch 70/145, Loss: 0.2842
Epoch 3/10, Batch 80/145, Loss: 0.2795
Epoch 3/10, Batch 90/145, Loss: 0.4543
Epoch 3/10, Batch 100/145, Loss: 0.3198
Epoch 3/10, Batch 110/145, Loss: 0.2661
Epoch 3/10, Batch 120/145, Loss: 0.1336
Epoch 3/10, Batch 130/145, Loss: 0.1536
Epoch 3/10, Batch 140/145, Loss: 0.1404
Epoch 3/10, Train Loss: 0.3052, Valid Loss: 0.2829
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1997
Epoch 4/10, Batch 20/145, Loss: 0.4649
Epoch 4/10, Batch 30/145, Loss: 0.2253
Epoch 4/10, Batch 40/145, Loss: 0.3082
Epoch 4/10, Batch 50/145, Loss: 0.3307
Epoch 4/10, Batch 60/145, Loss: 0.1791
Epoch 4/10, Batch 70/145, Loss: 0.1994
Epoch 4/10, Batch 80/145, Loss: 0.2490
Epoch 4/10, Batch 90/145, Loss: 0.2369
Epoch 4/10, Batch 100/145, Loss: 0.1793
Epoch 4/10, Batch 110/145, Loss: 0.2082
Epoch 4/10, Batch 120/145, Loss: 0.1986
Epoch 4/10, Batch 130/145, Loss: 0.1175
Epoch 4/10, Batch 140/145, Loss: 0.2901
Epoch 4/10, Train Loss: 0.2607, Valid Loss: 0.2712
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1740
Epoch 5/10, Batch 20/145, Loss: 0.2201
Epoch 5/10, Batch 30/145, Loss: 0.2020
Epoch 5/10, Batch 40/145, Loss: 0.2056
Epoch 5/10, Batch 50/145, Loss: 0.1679
Epoch 5/10, Batch 60/145, Loss: 0.3745
Epoch 5/10, Batch 70/145, Loss: 0.1613
Epoch 5/10, Batch 80/145, Loss: 0.2648
Epoch 5/10, Batch 90/145, Loss: 0.1696
Epoch 5/10, Batch 100/145, Loss: 0.2101
Epoch 5/10, Batch 110/145, Loss: 0.2086
Epoch 5/10, Batch 120/145, Loss: 0.3139
Epoch 5/10, Batch 130/145, Loss: 0.3062
Epoch 5/10, Batch 140/145, Loss: 0.2409
Epoch 5/10, Train Loss: 0.2373, Valid Loss: 0.2586
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3008
Epoch 6/10, Batch 20/145, Loss: 0.2588
Epoch 6/10, Batch 30/145, Loss: 0.1825
Epoch 6/10, Batch 40/145, Loss: 0.2105
Epoch 6/10, Batch 50/145, Loss: 0.2948
Epoch 6/10, Batch 60/145, Loss: 0.1782
Epoch 6/10, Batch 70/145, Loss: 0.1918
Epoch 6/10, Batch 80/145, Loss: 0.2475
Epoch 6/10, Batch 90/145, Loss: 0.2044
Epoch 6/10, Batch 100/145, Loss: 0.1362
Epoch 6/10, Batch 110/145, Loss: 0.0611
Epoch 6/10, Batch 120/145, Loss: 0.1702
Epoch 6/10, Batch 130/145, Loss: 0.1301
Epoch 6/10, Batch 140/145, Loss: 0.2735
Epoch 6/10, Train Loss: 0.2259, Valid Loss: 0.2536
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3247
Epoch 7/10, Batch 20/145, Loss: 0.1461
Epoch 7/10, Batch 30/145, Loss: 0.2247
Epoch 7/10, Batch 40/145, Loss: 0.3912
Epoch 7/10, Batch 50/145, Loss: 0.1537
Epoch 7/10, Batch 60/145, Loss: 0.1872
Epoch 7/10, Batch 70/145, Loss: 0.3520
Epoch 7/10, Batch 80/145, Loss: 0.1483
Epoch 7/10, Batch 90/145, Loss: 0.4504
Epoch 7/10, Batch 100/145, Loss: 0.1190
Epoch 7/10, Batch 110/145, Loss: 0.2142
Epoch 7/10, Batch 120/145, Loss: 0.1908
Epoch 7/10, Batch 130/145, Loss: 0.2747
Epoch 7/10, Batch 140/145, Loss: 0.1459
Epoch 7/10, Train Loss: 0.2100, Valid Loss: 0.2438
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0798
Epoch 8/10, Batch 20/145, Loss: 0.1472
Epoch 8/10, Batch 30/145, Loss: 0.2538
Epoch 8/10, Batch 40/145, Loss: 0.3251
Epoch 8/10, Batch 50/145, Loss: 0.1507
Epoch 8/10, Batch 60/145, Loss: 0.1766
Epoch 8/10, Batch 70/145, Loss: 0.1533
Epoch 8/10, Batch 80/145, Loss: 0.1297
Epoch 8/10, Batch 90/145, Loss: 0.1358
Epoch 8/10, Batch 100/145, Loss: 0.3096
Epoch 8/10, Batch 110/145, Loss: 0.2224
Epoch 8/10, Batch 120/145, Loss: 0.3110
Epoch 8/10, Batch 130/145, Loss: 0.2824
Epoch 8/10, Batch 140/145, Loss: 0.3257
Epoch 8/10, Train Loss: 0.2106, Valid Loss: 0.2390
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2432
Epoch 9/10, Batch 20/145, Loss: 0.1299
Epoch 9/10, Batch 30/145, Loss: 0.0803
Epoch 9/10, Batch 40/145, Loss: 0.1564
Epoch 9/10, Batch 50/145, Loss: 0.1459
Epoch 9/10, Batch 60/145, Loss: 0.1870
Epoch 9/10, Batch 70/145, Loss: 0.1238
Epoch 9/10, Batch 80/145, Loss: 0.2312
Epoch 9/10, Batch 90/145, Loss: 0.2004
Epoch 9/10, Batch 100/145, Loss: 0.2810
Epoch 9/10, Batch 110/145, Loss: 0.0885
Epoch 9/10, Batch 120/145, Loss: 0.2433
Epoch 9/10, Batch 130/145, Loss: 0.1355
Epoch 9/10, Batch 140/145, Loss: 0.1108
Epoch 9/10, Train Loss: 0.2029, Valid Loss: 0.2276
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.4030
Epoch 10/10, Batch 20/145, Loss: 0.0687
Epoch 10/10, Batch 30/145, Loss: 0.1853
Epoch 10/10, Batch 40/145, Loss: 0.2070
Epoch 10/10, Batch 50/145, Loss: 0.3805
Epoch 10/10, Batch 60/145, Loss: 0.2042
Epoch 10/10, Batch 70/145, Loss: 0.1164
Epoch 10/10, Batch 80/145, Loss: 0.3678
Epoch 10/10, Batch 90/145, Loss: 0.1629
Epoch 10/10, Batch 100/145, Loss: 0.1216
Epoch 10/10, Batch 110/145, Loss: 0.1594
Epoch 10/10, Batch 120/145, Loss: 0.2392
Epoch 10/10, Batch 130/145, Loss: 0.1903
Epoch 10/10, Batch 140/145, Loss: 0.1555
Epoch 10/10, Train Loss: 0.2030, Valid Loss: 0.2260
Model saved!
Accuracy: 0.9252
Precision: 0.9239
Recall: 0.9252
F1-score: 0.9238
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4745
Epoch 1/10, Batch 20/145, Loss: 0.9411
Epoch 1/10, Batch 30/145, Loss: 0.8733
Epoch 1/10, Batch 40/145, Loss: 0.7765
Epoch 1/10, Batch 50/145, Loss: 0.5109
Epoch 1/10, Batch 60/145, Loss: 0.6918
Epoch 1/10, Batch 70/145, Loss: 0.5868
Epoch 1/10, Batch 80/145, Loss: 0.5229
Epoch 1/10, Batch 90/145, Loss: 0.5353
Epoch 1/10, Batch 100/145, Loss: 0.5781
Epoch 1/10, Batch 110/145, Loss: 0.5399
Epoch 1/10, Batch 120/145, Loss: 0.5726
Epoch 1/10, Batch 130/145, Loss: 0.3329
Epoch 1/10, Batch 140/145, Loss: 0.4560
Epoch 1/10, Train Loss: 0.6864, Valid Loss: 0.3712
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3757
Epoch 2/10, Batch 20/145, Loss: 0.4866
Epoch 2/10, Batch 30/145, Loss: 0.4388
Epoch 2/10, Batch 40/145, Loss: 0.4035
Epoch 2/10, Batch 50/145, Loss: 0.3828
Epoch 2/10, Batch 60/145, Loss: 0.5257
Epoch 2/10, Batch 70/145, Loss: 0.5449
Epoch 2/10, Batch 80/145, Loss: 0.4546
Epoch 2/10, Batch 90/145, Loss: 0.2870
Epoch 2/10, Batch 100/145, Loss: 0.2513
Epoch 2/10, Batch 110/145, Loss: 0.2409
Epoch 2/10, Batch 120/145, Loss: 0.3597
Epoch 2/10, Batch 130/145, Loss: 0.3952
Epoch 2/10, Batch 140/145, Loss: 0.3100
Epoch 2/10, Train Loss: 0.3581, Valid Loss: 0.2932
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1908
Epoch 3/10, Batch 20/145, Loss: 0.3448
Epoch 3/10, Batch 30/145, Loss: 0.4060
Epoch 3/10, Batch 40/145, Loss: 0.3493
Epoch 3/10, Batch 50/145, Loss: 0.1646
Epoch 3/10, Batch 60/145, Loss: 0.2596
Epoch 3/10, Batch 70/145, Loss: 0.2934
Epoch 3/10, Batch 80/145, Loss: 0.2673
Epoch 3/10, Batch 90/145, Loss: 0.5927
Epoch 3/10, Batch 100/145, Loss: 0.2962
Epoch 3/10, Batch 110/145, Loss: 0.2163
Epoch 3/10, Batch 120/145, Loss: 0.2181
Epoch 3/10, Batch 130/145, Loss: 0.2048
Epoch 3/10, Batch 140/145, Loss: 0.3491
Epoch 3/10, Train Loss: 0.3132, Valid Loss: 0.2594
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2742
Epoch 4/10, Batch 20/145, Loss: 0.2000
Epoch 4/10, Batch 30/145, Loss: 0.2707
Epoch 4/10, Batch 40/145, Loss: 0.3807
Epoch 4/10, Batch 50/145, Loss: 0.1256
Epoch 4/10, Batch 60/145, Loss: 0.1769
Epoch 4/10, Batch 70/145, Loss: 0.2266
Epoch 4/10, Batch 80/145, Loss: 0.2861
Epoch 4/10, Batch 90/145, Loss: 0.2737
Epoch 4/10, Batch 100/145, Loss: 0.1905
Epoch 4/10, Batch 110/145, Loss: 0.1927
Epoch 4/10, Batch 120/145, Loss: 0.2134
Epoch 4/10, Batch 130/145, Loss: 0.1783
Epoch 4/10, Batch 140/145, Loss: 0.2499
Epoch 4/10, Train Loss: 0.2596, Valid Loss: 0.2513
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3820
Epoch 5/10, Batch 20/145, Loss: 0.2955
Epoch 5/10, Batch 30/145, Loss: 0.1596
Epoch 5/10, Batch 40/145, Loss: 0.1385
Epoch 5/10, Batch 50/145, Loss: 0.2690
Epoch 5/10, Batch 60/145, Loss: 0.2263
Epoch 5/10, Batch 70/145, Loss: 0.1969
Epoch 5/10, Batch 80/145, Loss: 0.2904
Epoch 5/10, Batch 90/145, Loss: 0.2835
Epoch 5/10, Batch 100/145, Loss: 0.2751
Epoch 5/10, Batch 110/145, Loss: 0.2224
Epoch 5/10, Batch 120/145, Loss: 0.2509
Epoch 5/10, Batch 130/145, Loss: 0.2070
Epoch 5/10, Batch 140/145, Loss: 0.2338
Epoch 5/10, Train Loss: 0.2408, Valid Loss: 0.2379
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1917
Epoch 6/10, Batch 20/145, Loss: 0.1148
Epoch 6/10, Batch 30/145, Loss: 0.2915
Epoch 6/10, Batch 40/145, Loss: 0.1388
Epoch 6/10, Batch 50/145, Loss: 0.2983
Epoch 6/10, Batch 60/145, Loss: 0.2154
Epoch 6/10, Batch 70/145, Loss: 0.2422
Epoch 6/10, Batch 80/145, Loss: 0.2579
Epoch 6/10, Batch 90/145, Loss: 0.2260
Epoch 6/10, Batch 100/145, Loss: 0.1846
Epoch 6/10, Batch 110/145, Loss: 0.3265
Epoch 6/10, Batch 120/145, Loss: 0.2418
Epoch 6/10, Batch 130/145, Loss: 0.2091
Epoch 6/10, Batch 140/145, Loss: 0.4542
Epoch 6/10, Train Loss: 0.2319, Valid Loss: 0.2373
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3519
Epoch 7/10, Batch 20/145, Loss: 0.1812
Epoch 7/10, Batch 30/145, Loss: 0.2134
Epoch 7/10, Batch 40/145, Loss: 0.3305
Epoch 7/10, Batch 50/145, Loss: 0.1982
Epoch 7/10, Batch 60/145, Loss: 0.1091
Epoch 7/10, Batch 70/145, Loss: 0.3731
Epoch 7/10, Batch 80/145, Loss: 0.0810
Epoch 7/10, Batch 90/145, Loss: 0.2561
Epoch 7/10, Batch 100/145, Loss: 0.1404
Epoch 7/10, Batch 110/145, Loss: 0.1515
Epoch 7/10, Batch 120/145, Loss: 0.1313
Epoch 7/10, Batch 130/145, Loss: 0.2459
Epoch 7/10, Batch 140/145, Loss: 0.1086
Epoch 7/10, Train Loss: 0.2114, Valid Loss: 0.2277
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2245
Epoch 8/10, Batch 20/145, Loss: 0.1561
Epoch 8/10, Batch 30/145, Loss: 0.2097
Epoch 8/10, Batch 40/145, Loss: 0.3051
Epoch 8/10, Batch 50/145, Loss: 0.1368
Epoch 8/10, Batch 60/145, Loss: 0.2288
Epoch 8/10, Batch 70/145, Loss: 0.1076
Epoch 8/10, Batch 80/145, Loss: 0.2153
Epoch 8/10, Batch 90/145, Loss: 0.1992
Epoch 8/10, Batch 100/145, Loss: 0.2843
Epoch 8/10, Batch 110/145, Loss: 0.2020
Epoch 8/10, Batch 120/145, Loss: 0.1581
Epoch 8/10, Batch 130/145, Loss: 0.1233
Epoch 8/10, Batch 140/145, Loss: 0.3587
Epoch 8/10, Train Loss: 0.2143, Valid Loss: 0.2273
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1825
Epoch 9/10, Batch 20/145, Loss: 0.0817
Epoch 9/10, Batch 30/145, Loss: 0.2066
Epoch 9/10, Batch 40/145, Loss: 0.1198
Epoch 9/10, Batch 50/145, Loss: 0.2493
Epoch 9/10, Batch 60/145, Loss: 0.1664
Epoch 9/10, Batch 70/145, Loss: 0.2201
Epoch 9/10, Batch 80/145, Loss: 0.2144
Epoch 9/10, Batch 90/145, Loss: 0.1055
Epoch 9/10, Batch 100/145, Loss: 0.1722
Epoch 9/10, Batch 110/145, Loss: 0.1324
Epoch 9/10, Batch 120/145, Loss: 0.0689
Epoch 9/10, Batch 130/145, Loss: 0.1739
Epoch 9/10, Batch 140/145, Loss: 0.2104
Epoch 9/10, Train Loss: 0.2066, Valid Loss: 0.2204
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0695
Epoch 10/10, Batch 20/145, Loss: 0.1467
Epoch 10/10, Batch 30/145, Loss: 0.1025
Epoch 10/10, Batch 40/145, Loss: 0.2611
Epoch 10/10, Batch 50/145, Loss: 0.2907
Epoch 10/10, Batch 60/145, Loss: 0.2348
Epoch 10/10, Batch 70/145, Loss: 0.2101
Epoch 10/10, Batch 80/145, Loss: 0.3861
Epoch 10/10, Batch 90/145, Loss: 0.1250
Epoch 10/10, Batch 100/145, Loss: 0.1021
Epoch 10/10, Batch 110/145, Loss: 0.1678
Epoch 10/10, Batch 120/145, Loss: 0.1068
Epoch 10/10, Batch 130/145, Loss: 0.2372
Epoch 10/10, Batch 140/145, Loss: 0.1835
Epoch 10/10, Train Loss: 0.1969, Valid Loss: 0.2160
Model saved!
Accuracy: 0.9241
Precision: 0.9222
Recall: 0.9241
F1-score: 0.9228
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5208
Epoch 1/10, Batch 20/145, Loss: 0.9220
Epoch 1/10, Batch 30/145, Loss: 0.8806
Epoch 1/10, Batch 40/145, Loss: 0.8318
Epoch 1/10, Batch 50/145, Loss: 0.6408
Epoch 1/10, Batch 60/145, Loss: 0.4512
Epoch 1/10, Batch 70/145, Loss: 0.6378
Epoch 1/10, Batch 80/145, Loss: 0.5287
Epoch 1/10, Batch 90/145, Loss: 0.5936
Epoch 1/10, Batch 100/145, Loss: 0.5530
Epoch 1/10, Batch 110/145, Loss: 0.4470
Epoch 1/10, Batch 120/145, Loss: 0.6725
Epoch 1/10, Batch 130/145, Loss: 0.4529
Epoch 1/10, Batch 140/145, Loss: 0.4202
Epoch 1/10, Train Loss: 0.6900, Valid Loss: 0.4012
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3071
Epoch 2/10, Batch 20/145, Loss: 0.6827
Epoch 2/10, Batch 30/145, Loss: 0.3515
Epoch 2/10, Batch 40/145, Loss: 0.3836
Epoch 2/10, Batch 50/145, Loss: 0.2235
Epoch 2/10, Batch 60/145, Loss: 0.4370
Epoch 2/10, Batch 70/145, Loss: 0.3894
Epoch 2/10, Batch 80/145, Loss: 0.3526
Epoch 2/10, Batch 90/145, Loss: 0.2336
Epoch 2/10, Batch 100/145, Loss: 0.3603
Epoch 2/10, Batch 110/145, Loss: 0.2190
Epoch 2/10, Batch 120/145, Loss: 0.3662
Epoch 2/10, Batch 130/145, Loss: 0.4216
Epoch 2/10, Batch 140/145, Loss: 0.2645
Epoch 2/10, Train Loss: 0.3645, Valid Loss: 0.3138
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2524
Epoch 3/10, Batch 20/145, Loss: 0.3731
Epoch 3/10, Batch 30/145, Loss: 0.2525
Epoch 3/10, Batch 40/145, Loss: 0.2395
Epoch 3/10, Batch 50/145, Loss: 0.2632
Epoch 3/10, Batch 60/145, Loss: 0.2685
Epoch 3/10, Batch 70/145, Loss: 0.1984
Epoch 3/10, Batch 80/145, Loss: 0.2126
Epoch 3/10, Batch 90/145, Loss: 0.4965
Epoch 3/10, Batch 100/145, Loss: 0.4751
Epoch 3/10, Batch 110/145, Loss: 0.2316
Epoch 3/10, Batch 120/145, Loss: 0.2296
Epoch 3/10, Batch 130/145, Loss: 0.1285
Epoch 3/10, Batch 140/145, Loss: 0.3195
Epoch 3/10, Train Loss: 0.3056, Valid Loss: 0.2838
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1428
Epoch 4/10, Batch 20/145, Loss: 0.3324
Epoch 4/10, Batch 30/145, Loss: 0.1753
Epoch 4/10, Batch 40/145, Loss: 0.2623
Epoch 4/10, Batch 50/145, Loss: 0.1984
Epoch 4/10, Batch 60/145, Loss: 0.2882
Epoch 4/10, Batch 70/145, Loss: 0.1940
Epoch 4/10, Batch 80/145, Loss: 0.1952
Epoch 4/10, Batch 90/145, Loss: 0.2632
Epoch 4/10, Batch 100/145, Loss: 0.2070
Epoch 4/10, Batch 110/145, Loss: 0.2771
Epoch 4/10, Batch 120/145, Loss: 0.1502
Epoch 4/10, Batch 130/145, Loss: 0.1039
Epoch 4/10, Batch 140/145, Loss: 0.1646
Epoch 4/10, Train Loss: 0.2625, Valid Loss: 0.2735
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1785
Epoch 5/10, Batch 20/145, Loss: 0.3189
Epoch 5/10, Batch 30/145, Loss: 0.2413
Epoch 5/10, Batch 40/145, Loss: 0.1942
Epoch 5/10, Batch 50/145, Loss: 0.1619
Epoch 5/10, Batch 60/145, Loss: 0.1973
Epoch 5/10, Batch 70/145, Loss: 0.3006
Epoch 5/10, Batch 80/145, Loss: 0.2569
Epoch 5/10, Batch 90/145, Loss: 0.1327
Epoch 5/10, Batch 100/145, Loss: 0.3238
Epoch 5/10, Batch 110/145, Loss: 0.1670
Epoch 5/10, Batch 120/145, Loss: 0.2607
Epoch 5/10, Batch 130/145, Loss: 0.1186
Epoch 5/10, Batch 140/145, Loss: 0.2857
Epoch 5/10, Train Loss: 0.2411, Valid Loss: 0.2553
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1104
Epoch 6/10, Batch 20/145, Loss: 0.2055
Epoch 6/10, Batch 30/145, Loss: 0.3963
Epoch 6/10, Batch 40/145, Loss: 0.2944
Epoch 6/10, Batch 50/145, Loss: 0.3489
Epoch 6/10, Batch 60/145, Loss: 0.1021
Epoch 6/10, Batch 70/145, Loss: 0.1715
Epoch 6/10, Batch 80/145, Loss: 0.2442
Epoch 6/10, Batch 90/145, Loss: 0.3287
Epoch 6/10, Batch 100/145, Loss: 0.2762
Epoch 6/10, Batch 110/145, Loss: 0.2769
Epoch 6/10, Batch 120/145, Loss: 0.2406
Epoch 6/10, Batch 130/145, Loss: 0.2429
Epoch 6/10, Batch 140/145, Loss: 0.3032
Epoch 6/10, Train Loss: 0.2205, Valid Loss: 0.2582
Epoch 7/10, Batch 10/145, Loss: 0.4061
Epoch 7/10, Batch 20/145, Loss: 0.1156
Epoch 7/10, Batch 30/145, Loss: 0.2756
Epoch 7/10, Batch 40/145, Loss: 0.3691
Epoch 7/10, Batch 50/145, Loss: 0.1786
Epoch 7/10, Batch 60/145, Loss: 0.1967
Epoch 7/10, Batch 70/145, Loss: 0.1185
Epoch 7/10, Batch 80/145, Loss: 0.1129
Epoch 7/10, Batch 90/145, Loss: 0.1171
Epoch 7/10, Batch 100/145, Loss: 0.2143
Epoch 7/10, Batch 110/145, Loss: 0.2531
Epoch 7/10, Batch 120/145, Loss: 0.1424
Epoch 7/10, Batch 130/145, Loss: 0.1252
Epoch 7/10, Batch 140/145, Loss: 0.1330
Epoch 7/10, Train Loss: 0.2176, Valid Loss: 0.2441
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2364
Epoch 8/10, Batch 20/145, Loss: 0.1768
Epoch 8/10, Batch 30/145, Loss: 0.1080
Epoch 8/10, Batch 40/145, Loss: 0.3227
Epoch 8/10, Batch 50/145, Loss: 0.3290
Epoch 8/10, Batch 60/145, Loss: 0.2533
Epoch 8/10, Batch 70/145, Loss: 0.1231
Epoch 8/10, Batch 80/145, Loss: 0.1129
Epoch 8/10, Batch 90/145, Loss: 0.2590
Epoch 8/10, Batch 100/145, Loss: 0.4067
Epoch 8/10, Batch 110/145, Loss: 0.2303
Epoch 8/10, Batch 120/145, Loss: 0.1665
Epoch 8/10, Batch 130/145, Loss: 0.1431
Epoch 8/10, Batch 140/145, Loss: 0.4454
Epoch 8/10, Train Loss: 0.2055, Valid Loss: 0.2422
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1496
Epoch 9/10, Batch 20/145, Loss: 0.1239
Epoch 9/10, Batch 30/145, Loss: 0.0383
Epoch 9/10, Batch 40/145, Loss: 0.1227
Epoch 9/10, Batch 50/145, Loss: 0.2434
Epoch 9/10, Batch 60/145, Loss: 0.2161
Epoch 9/10, Batch 70/145, Loss: 0.1886
Epoch 9/10, Batch 80/145, Loss: 0.1694
Epoch 9/10, Batch 90/145, Loss: 0.1085
Epoch 9/10, Batch 100/145, Loss: 0.2626
Epoch 9/10, Batch 110/145, Loss: 0.1192
Epoch 9/10, Batch 120/145, Loss: 0.1683
Epoch 9/10, Batch 130/145, Loss: 0.1548
Epoch 9/10, Batch 140/145, Loss: 0.1190
Epoch 9/10, Train Loss: 0.2011, Valid Loss: 0.2356
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1476
Epoch 10/10, Batch 20/145, Loss: 0.1963
Epoch 10/10, Batch 30/145, Loss: 0.1543
Epoch 10/10, Batch 40/145, Loss: 0.2890
Epoch 10/10, Batch 50/145, Loss: 0.3510
Epoch 10/10, Batch 60/145, Loss: 0.1108
Epoch 10/10, Batch 70/145, Loss: 0.1879
Epoch 10/10, Batch 80/145, Loss: 0.1760
Epoch 10/10, Batch 90/145, Loss: 0.1847
Epoch 10/10, Batch 100/145, Loss: 0.1578
Epoch 10/10, Batch 110/145, Loss: 0.2858
Epoch 10/10, Batch 120/145, Loss: 0.2014
Epoch 10/10, Batch 130/145, Loss: 0.1701
Epoch 10/10, Batch 140/145, Loss: 0.2482
Epoch 10/10, Train Loss: 0.1929, Valid Loss: 0.2396
Accuracy: 0.9276
Precision: 0.9262
Recall: 0.9276
F1-score: 0.9267
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4909
Epoch 1/10, Batch 20/145, Loss: 0.8799
Epoch 1/10, Batch 30/145, Loss: 0.8282
Epoch 1/10, Batch 40/145, Loss: 0.8481
Epoch 1/10, Batch 50/145, Loss: 0.6462
Epoch 1/10, Batch 60/145, Loss: 0.7151
Epoch 1/10, Batch 70/145, Loss: 0.6199
Epoch 1/10, Batch 80/145, Loss: 0.4618
Epoch 1/10, Batch 90/145, Loss: 0.5459
Epoch 1/10, Batch 100/145, Loss: 0.5972
Epoch 1/10, Batch 110/145, Loss: 0.4254
Epoch 1/10, Batch 120/145, Loss: 0.6352
Epoch 1/10, Batch 130/145, Loss: 0.3113
Epoch 1/10, Batch 140/145, Loss: 0.3936
Epoch 1/10, Train Loss: 0.6873, Valid Loss: 0.3850
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3949
Epoch 2/10, Batch 20/145, Loss: 0.6124
Epoch 2/10, Batch 30/145, Loss: 0.3167
Epoch 2/10, Batch 40/145, Loss: 0.4845
Epoch 2/10, Batch 50/145, Loss: 0.2875
Epoch 2/10, Batch 60/145, Loss: 0.4954
Epoch 2/10, Batch 70/145, Loss: 0.4235
Epoch 2/10, Batch 80/145, Loss: 0.2568
Epoch 2/10, Batch 90/145, Loss: 0.2837
Epoch 2/10, Batch 100/145, Loss: 0.2812
Epoch 2/10, Batch 110/145, Loss: 0.3870
Epoch 2/10, Batch 120/145, Loss: 0.3203
Epoch 2/10, Batch 130/145, Loss: 0.3728
Epoch 2/10, Batch 140/145, Loss: 0.3493
Epoch 2/10, Train Loss: 0.3633, Valid Loss: 0.2936
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3064
Epoch 3/10, Batch 20/145, Loss: 0.4411
Epoch 3/10, Batch 30/145, Loss: 0.2779
Epoch 3/10, Batch 40/145, Loss: 0.2854
Epoch 3/10, Batch 50/145, Loss: 0.1635
Epoch 3/10, Batch 60/145, Loss: 0.2922
Epoch 3/10, Batch 70/145, Loss: 0.2305
Epoch 3/10, Batch 80/145, Loss: 0.2481
Epoch 3/10, Batch 90/145, Loss: 0.5497
Epoch 3/10, Batch 100/145, Loss: 0.2842
Epoch 3/10, Batch 110/145, Loss: 0.2894
Epoch 3/10, Batch 120/145, Loss: 0.2322
Epoch 3/10, Batch 130/145, Loss: 0.2682
Epoch 3/10, Batch 140/145, Loss: 0.1705
Epoch 3/10, Train Loss: 0.3092, Valid Loss: 0.2594
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1109
Epoch 4/10, Batch 20/145, Loss: 0.1787
Epoch 4/10, Batch 30/145, Loss: 0.2070
Epoch 4/10, Batch 40/145, Loss: 0.4429
Epoch 4/10, Batch 50/145, Loss: 0.2586
Epoch 4/10, Batch 60/145, Loss: 0.2557
Epoch 4/10, Batch 70/145, Loss: 0.2443
Epoch 4/10, Batch 80/145, Loss: 0.2391
Epoch 4/10, Batch 90/145, Loss: 0.3077
Epoch 4/10, Batch 100/145, Loss: 0.2730
Epoch 4/10, Batch 110/145, Loss: 0.2023
Epoch 4/10, Batch 120/145, Loss: 0.2027
Epoch 4/10, Batch 130/145, Loss: 0.1539
Epoch 4/10, Batch 140/145, Loss: 0.2084
Epoch 4/10, Train Loss: 0.2660, Valid Loss: 0.2466
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1427
Epoch 5/10, Batch 20/145, Loss: 0.1874
Epoch 5/10, Batch 30/145, Loss: 0.2938
Epoch 5/10, Batch 40/145, Loss: 0.2963
Epoch 5/10, Batch 50/145, Loss: 0.0968
Epoch 5/10, Batch 60/145, Loss: 0.2120
Epoch 5/10, Batch 70/145, Loss: 0.4368
Epoch 5/10, Batch 80/145, Loss: 0.3734
Epoch 5/10, Batch 90/145, Loss: 0.1664
Epoch 5/10, Batch 100/145, Loss: 0.3812
Epoch 5/10, Batch 110/145, Loss: 0.1104
Epoch 5/10, Batch 120/145, Loss: 0.3012
Epoch 5/10, Batch 130/145, Loss: 0.2106
Epoch 5/10, Batch 140/145, Loss: 0.3472
Epoch 5/10, Train Loss: 0.2432, Valid Loss: 0.2311
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1673
Epoch 6/10, Batch 20/145, Loss: 0.1640
Epoch 6/10, Batch 30/145, Loss: 0.2728
Epoch 6/10, Batch 40/145, Loss: 0.1881
Epoch 6/10, Batch 50/145, Loss: 0.1435
Epoch 6/10, Batch 60/145, Loss: 0.1789
Epoch 6/10, Batch 70/145, Loss: 0.3743
Epoch 6/10, Batch 80/145, Loss: 0.2893
Epoch 6/10, Batch 90/145, Loss: 0.2830
Epoch 6/10, Batch 100/145, Loss: 0.1733
Epoch 6/10, Batch 110/145, Loss: 0.1249
Epoch 6/10, Batch 120/145, Loss: 0.1823
Epoch 6/10, Batch 130/145, Loss: 0.0748
Epoch 6/10, Batch 140/145, Loss: 0.2995
Epoch 6/10, Train Loss: 0.2290, Valid Loss: 0.2333
Epoch 7/10, Batch 10/145, Loss: 0.2439
Epoch 7/10, Batch 20/145, Loss: 0.2357
Epoch 7/10, Batch 30/145, Loss: 0.1438
Epoch 7/10, Batch 40/145, Loss: 0.5243
Epoch 7/10, Batch 50/145, Loss: 0.1900
Epoch 7/10, Batch 60/145, Loss: 0.2514
Epoch 7/10, Batch 70/145, Loss: 0.1275
Epoch 7/10, Batch 80/145, Loss: 0.2546
Epoch 7/10, Batch 90/145, Loss: 0.1907
Epoch 7/10, Batch 100/145, Loss: 0.1703
Epoch 7/10, Batch 110/145, Loss: 0.1902
Epoch 7/10, Batch 120/145, Loss: 0.1599
Epoch 7/10, Batch 130/145, Loss: 0.1440
Epoch 7/10, Batch 140/145, Loss: 0.1774
Epoch 7/10, Train Loss: 0.2242, Valid Loss: 0.2251
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2704
Epoch 8/10, Batch 20/145, Loss: 0.1446
Epoch 8/10, Batch 30/145, Loss: 0.0655
Epoch 8/10, Batch 40/145, Loss: 0.1127
Epoch 8/10, Batch 50/145, Loss: 0.1271
Epoch 8/10, Batch 60/145, Loss: 0.2811
Epoch 8/10, Batch 70/145, Loss: 0.0943
Epoch 8/10, Batch 80/145, Loss: 0.1601
Epoch 8/10, Batch 90/145, Loss: 0.1344
Epoch 8/10, Batch 100/145, Loss: 0.2301
Epoch 8/10, Batch 110/145, Loss: 0.2504
Epoch 8/10, Batch 120/145, Loss: 0.4677
Epoch 8/10, Batch 130/145, Loss: 0.0997
Epoch 8/10, Batch 140/145, Loss: 0.3370
Epoch 8/10, Train Loss: 0.2210, Valid Loss: 0.2118
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1675
Epoch 9/10, Batch 20/145, Loss: 0.1452
Epoch 9/10, Batch 30/145, Loss: 0.1100
Epoch 9/10, Batch 40/145, Loss: 0.2322
Epoch 9/10, Batch 50/145, Loss: 0.2068
Epoch 9/10, Batch 60/145, Loss: 0.1053
Epoch 9/10, Batch 70/145, Loss: 0.1338
Epoch 9/10, Batch 80/145, Loss: 0.2333
Epoch 9/10, Batch 90/145, Loss: 0.0997
Epoch 9/10, Batch 100/145, Loss: 0.2200
Epoch 9/10, Batch 110/145, Loss: 0.1326
Epoch 9/10, Batch 120/145, Loss: 0.1423
Epoch 9/10, Batch 130/145, Loss: 0.1904
Epoch 9/10, Batch 140/145, Loss: 0.2075
Epoch 9/10, Train Loss: 0.2047, Valid Loss: 0.2090
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2631
Epoch 10/10, Batch 20/145, Loss: 0.1841
Epoch 10/10, Batch 30/145, Loss: 0.1006
Epoch 10/10, Batch 40/145, Loss: 0.2207
Epoch 10/10, Batch 50/145, Loss: 0.2586
Epoch 10/10, Batch 60/145, Loss: 0.1179
Epoch 10/10, Batch 70/145, Loss: 0.2552
Epoch 10/10, Batch 80/145, Loss: 0.4679
Epoch 10/10, Batch 90/145, Loss: 0.2605
Epoch 10/10, Batch 100/145, Loss: 0.0896
Epoch 10/10, Batch 110/145, Loss: 0.1053
Epoch 10/10, Batch 120/145, Loss: 0.1606
Epoch 10/10, Batch 130/145, Loss: 0.2138
Epoch 10/10, Batch 140/145, Loss: 0.1284
Epoch 10/10, Train Loss: 0.1951, Valid Loss: 0.2059
Model saved!
Accuracy: 0.9229
Precision: 0.9216
Recall: 0.9229
F1-score: 0.9220
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4490
Epoch 1/10, Batch 20/145, Loss: 0.9772
Epoch 1/10, Batch 30/145, Loss: 0.9144
Epoch 1/10, Batch 40/145, Loss: 0.7759
Epoch 1/10, Batch 50/145, Loss: 0.6754
Epoch 1/10, Batch 60/145, Loss: 0.4922
Epoch 1/10, Batch 70/145, Loss: 0.6120
Epoch 1/10, Batch 80/145, Loss: 0.4493
Epoch 1/10, Batch 90/145, Loss: 0.5444
Epoch 1/10, Batch 100/145, Loss: 0.5884
Epoch 1/10, Batch 110/145, Loss: 0.4043
Epoch 1/10, Batch 120/145, Loss: 0.6002
Epoch 1/10, Batch 130/145, Loss: 0.3985
Epoch 1/10, Batch 140/145, Loss: 0.4904
Epoch 1/10, Train Loss: 0.6841, Valid Loss: 0.3518
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3890
Epoch 2/10, Batch 20/145, Loss: 0.4599
Epoch 2/10, Batch 30/145, Loss: 0.4697
Epoch 2/10, Batch 40/145, Loss: 0.4112
Epoch 2/10, Batch 50/145, Loss: 0.3584
Epoch 2/10, Batch 60/145, Loss: 0.4710
Epoch 2/10, Batch 70/145, Loss: 0.4807
Epoch 2/10, Batch 80/145, Loss: 0.3029
Epoch 2/10, Batch 90/145, Loss: 0.3523
Epoch 2/10, Batch 100/145, Loss: 0.3437
Epoch 2/10, Batch 110/145, Loss: 0.2676
Epoch 2/10, Batch 120/145, Loss: 0.4497
Epoch 2/10, Batch 130/145, Loss: 0.2192
Epoch 2/10, Batch 140/145, Loss: 0.2229
Epoch 2/10, Train Loss: 0.3568, Valid Loss: 0.2677
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1909
Epoch 3/10, Batch 20/145, Loss: 0.2927
Epoch 3/10, Batch 30/145, Loss: 0.4086
Epoch 3/10, Batch 40/145, Loss: 0.2250
Epoch 3/10, Batch 50/145, Loss: 0.2349
Epoch 3/10, Batch 60/145, Loss: 0.3685
Epoch 3/10, Batch 70/145, Loss: 0.3374
Epoch 3/10, Batch 80/145, Loss: 0.2842
Epoch 3/10, Batch 90/145, Loss: 0.4473
Epoch 3/10, Batch 100/145, Loss: 0.5454
Epoch 3/10, Batch 110/145, Loss: 0.1932
Epoch 3/10, Batch 120/145, Loss: 0.4081
Epoch 3/10, Batch 130/145, Loss: 0.3938
Epoch 3/10, Batch 140/145, Loss: 0.1261
Epoch 3/10, Train Loss: 0.3108, Valid Loss: 0.2385
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2587
Epoch 4/10, Batch 20/145, Loss: 0.1289
Epoch 4/10, Batch 30/145, Loss: 0.2803
Epoch 4/10, Batch 40/145, Loss: 0.4063
Epoch 4/10, Batch 50/145, Loss: 0.1721
Epoch 4/10, Batch 60/145, Loss: 0.2191
Epoch 4/10, Batch 70/145, Loss: 0.2980
Epoch 4/10, Batch 80/145, Loss: 0.3249
Epoch 4/10, Batch 90/145, Loss: 0.2442
Epoch 4/10, Batch 100/145, Loss: 0.2678
Epoch 4/10, Batch 110/145, Loss: 0.3275
Epoch 4/10, Batch 120/145, Loss: 0.1732
Epoch 4/10, Batch 130/145, Loss: 0.1455
Epoch 4/10, Batch 140/145, Loss: 0.3065
Epoch 4/10, Train Loss: 0.2616, Valid Loss: 0.2360
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.4303
Epoch 5/10, Batch 20/145, Loss: 0.2534
Epoch 5/10, Batch 30/145, Loss: 0.1291
Epoch 5/10, Batch 40/145, Loss: 0.1297
Epoch 5/10, Batch 50/145, Loss: 0.1668
Epoch 5/10, Batch 60/145, Loss: 0.1999
Epoch 5/10, Batch 70/145, Loss: 0.2639
Epoch 5/10, Batch 80/145, Loss: 0.5114
Epoch 5/10, Batch 90/145, Loss: 0.1433
Epoch 5/10, Batch 100/145, Loss: 0.3550
Epoch 5/10, Batch 110/145, Loss: 0.1774
Epoch 5/10, Batch 120/145, Loss: 0.1432
Epoch 5/10, Batch 130/145, Loss: 0.2257
Epoch 5/10, Batch 140/145, Loss: 0.3725
Epoch 5/10, Train Loss: 0.2387, Valid Loss: 0.2155
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1353
Epoch 6/10, Batch 20/145, Loss: 0.2812
Epoch 6/10, Batch 30/145, Loss: 0.1984
Epoch 6/10, Batch 40/145, Loss: 0.0814
Epoch 6/10, Batch 50/145, Loss: 0.4321
Epoch 6/10, Batch 60/145, Loss: 0.0908
Epoch 6/10, Batch 70/145, Loss: 0.4045
Epoch 6/10, Batch 80/145, Loss: 0.1692
Epoch 6/10, Batch 90/145, Loss: 0.2488
Epoch 6/10, Batch 100/145, Loss: 0.1941
Epoch 6/10, Batch 110/145, Loss: 0.2169
Epoch 6/10, Batch 120/145, Loss: 0.2577
Epoch 6/10, Batch 130/145, Loss: 0.1585
Epoch 6/10, Batch 140/145, Loss: 0.3355
Epoch 6/10, Train Loss: 0.2319, Valid Loss: 0.2258
Epoch 7/10, Batch 10/145, Loss: 0.2740
Epoch 7/10, Batch 20/145, Loss: 0.1719
Epoch 7/10, Batch 30/145, Loss: 0.1484
Epoch 7/10, Batch 40/145, Loss: 0.2236
Epoch 7/10, Batch 50/145, Loss: 0.2189
Epoch 7/10, Batch 60/145, Loss: 0.1635
Epoch 7/10, Batch 70/145, Loss: 0.0860
Epoch 7/10, Batch 80/145, Loss: 0.2361
Epoch 7/10, Batch 90/145, Loss: 0.2882
Epoch 7/10, Batch 100/145, Loss: 0.1484
Epoch 7/10, Batch 110/145, Loss: 0.2265
Epoch 7/10, Batch 120/145, Loss: 0.1754
Epoch 7/10, Batch 130/145, Loss: 0.3669
Epoch 7/10, Batch 140/145, Loss: 0.1135
Epoch 7/10, Train Loss: 0.2209, Valid Loss: 0.2057
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0972
Epoch 8/10, Batch 20/145, Loss: 0.2484
Epoch 8/10, Batch 30/145, Loss: 0.1293
Epoch 8/10, Batch 40/145, Loss: 0.2087
Epoch 8/10, Batch 50/145, Loss: 0.2231
Epoch 8/10, Batch 60/145, Loss: 0.2036
Epoch 8/10, Batch 70/145, Loss: 0.2415
Epoch 8/10, Batch 80/145, Loss: 0.2088
Epoch 8/10, Batch 90/145, Loss: 0.0711
Epoch 8/10, Batch 100/145, Loss: 0.1666
Epoch 8/10, Batch 110/145, Loss: 0.3176
Epoch 8/10, Batch 120/145, Loss: 0.3370
Epoch 8/10, Batch 130/145, Loss: 0.1087
Epoch 8/10, Batch 140/145, Loss: 0.2576
Epoch 8/10, Train Loss: 0.2116, Valid Loss: 0.1980
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2153
Epoch 9/10, Batch 20/145, Loss: 0.1693
Epoch 9/10, Batch 30/145, Loss: 0.0714
Epoch 9/10, Batch 40/145, Loss: 0.1793
Epoch 9/10, Batch 50/145, Loss: 0.0643
Epoch 9/10, Batch 60/145, Loss: 0.2118
Epoch 9/10, Batch 70/145, Loss: 0.1414
Epoch 9/10, Batch 80/145, Loss: 0.0914
Epoch 9/10, Batch 90/145, Loss: 0.1633
Epoch 9/10, Batch 100/145, Loss: 0.1885
Epoch 9/10, Batch 110/145, Loss: 0.1329
Epoch 9/10, Batch 120/145, Loss: 0.1154
Epoch 9/10, Batch 130/145, Loss: 0.1046
Epoch 9/10, Batch 140/145, Loss: 0.1025
Epoch 9/10, Train Loss: 0.2050, Valid Loss: 0.1977
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1669
Epoch 10/10, Batch 20/145, Loss: 0.1167
Epoch 10/10, Batch 30/145, Loss: 0.1386
Epoch 10/10, Batch 40/145, Loss: 0.4040
Epoch 10/10, Batch 50/145, Loss: 0.2323
Epoch 10/10, Batch 60/145, Loss: 0.1549
Epoch 10/10, Batch 70/145, Loss: 0.2257
Epoch 10/10, Batch 80/145, Loss: 0.2692
Epoch 10/10, Batch 90/145, Loss: 0.1372
Epoch 10/10, Batch 100/145, Loss: 0.1797
Epoch 10/10, Batch 110/145, Loss: 0.2499
Epoch 10/10, Batch 120/145, Loss: 0.1882
Epoch 10/10, Batch 130/145, Loss: 0.2174
Epoch 10/10, Batch 140/145, Loss: 0.2771
Epoch 10/10, Train Loss: 0.2013, Valid Loss: 0.1924
Model saved!
Accuracy: 0.9194
Precision: 0.9171
Recall: 0.9194
F1-score: 0.9180
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5370
Epoch 1/10, Batch 20/145, Loss: 0.9246
Epoch 1/10, Batch 30/145, Loss: 0.8696
Epoch 1/10, Batch 40/145, Loss: 0.8060
Epoch 1/10, Batch 50/145, Loss: 0.5944
Epoch 1/10, Batch 60/145, Loss: 0.5215
Epoch 1/10, Batch 70/145, Loss: 0.5958
Epoch 1/10, Batch 80/145, Loss: 0.5078
Epoch 1/10, Batch 90/145, Loss: 0.5246
Epoch 1/10, Batch 100/145, Loss: 0.4956
Epoch 1/10, Batch 110/145, Loss: 0.4853
Epoch 1/10, Batch 120/145, Loss: 0.6669
Epoch 1/10, Batch 130/145, Loss: 0.4944
Epoch 1/10, Batch 140/145, Loss: 0.3852
Epoch 1/10, Train Loss: 0.6934, Valid Loss: 0.3680
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3641
Epoch 2/10, Batch 20/145, Loss: 0.4135
Epoch 2/10, Batch 30/145, Loss: 0.3689
Epoch 2/10, Batch 40/145, Loss: 0.5007
Epoch 2/10, Batch 50/145, Loss: 0.2951
Epoch 2/10, Batch 60/145, Loss: 0.5417
Epoch 2/10, Batch 70/145, Loss: 0.4905
Epoch 2/10, Batch 80/145, Loss: 0.4196
Epoch 2/10, Batch 90/145, Loss: 0.4766
Epoch 2/10, Batch 100/145, Loss: 0.2246
Epoch 2/10, Batch 110/145, Loss: 0.2291
Epoch 2/10, Batch 120/145, Loss: 0.3885
Epoch 2/10, Batch 130/145, Loss: 0.3679
Epoch 2/10, Batch 140/145, Loss: 0.2659
Epoch 2/10, Train Loss: 0.3687, Valid Loss: 0.2846
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2038
Epoch 3/10, Batch 20/145, Loss: 0.3477
Epoch 3/10, Batch 30/145, Loss: 0.1787
Epoch 3/10, Batch 40/145, Loss: 0.2701
Epoch 3/10, Batch 50/145, Loss: 0.1813
Epoch 3/10, Batch 60/145, Loss: 0.1957
Epoch 3/10, Batch 70/145, Loss: 0.1685
Epoch 3/10, Batch 80/145, Loss: 0.3121
Epoch 3/10, Batch 90/145, Loss: 0.4077
Epoch 3/10, Batch 100/145, Loss: 0.2463
Epoch 3/10, Batch 110/145, Loss: 0.4129
Epoch 3/10, Batch 120/145, Loss: 0.1576
Epoch 3/10, Batch 130/145, Loss: 0.2154
Epoch 3/10, Batch 140/145, Loss: 0.2106
Epoch 3/10, Train Loss: 0.3072, Valid Loss: 0.2537
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1519
Epoch 4/10, Batch 20/145, Loss: 0.2723
Epoch 4/10, Batch 30/145, Loss: 0.3445
Epoch 4/10, Batch 40/145, Loss: 0.2717
Epoch 4/10, Batch 50/145, Loss: 0.2970
Epoch 4/10, Batch 60/145, Loss: 0.2568
Epoch 4/10, Batch 70/145, Loss: 0.2047
Epoch 4/10, Batch 80/145, Loss: 0.2978
Epoch 4/10, Batch 90/145, Loss: 0.1844
Epoch 4/10, Batch 100/145, Loss: 0.3685
Epoch 4/10, Batch 110/145, Loss: 0.3730
Epoch 4/10, Batch 120/145, Loss: 0.4417
Epoch 4/10, Batch 130/145, Loss: 0.1733
Epoch 4/10, Batch 140/145, Loss: 0.1258
Epoch 4/10, Train Loss: 0.2628, Valid Loss: 0.2530
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2346
Epoch 5/10, Batch 20/145, Loss: 0.3952
Epoch 5/10, Batch 30/145, Loss: 0.1446
Epoch 5/10, Batch 40/145, Loss: 0.2704
Epoch 5/10, Batch 50/145, Loss: 0.1955
Epoch 5/10, Batch 60/145, Loss: 0.3353
Epoch 5/10, Batch 70/145, Loss: 0.3105
Epoch 5/10, Batch 80/145, Loss: 0.2684
Epoch 5/10, Batch 90/145, Loss: 0.1572
Epoch 5/10, Batch 100/145, Loss: 0.2247
Epoch 5/10, Batch 110/145, Loss: 0.1120
Epoch 5/10, Batch 120/145, Loss: 0.1551
Epoch 5/10, Batch 130/145, Loss: 0.2568
Epoch 5/10, Batch 140/145, Loss: 0.1842
Epoch 5/10, Train Loss: 0.2437, Valid Loss: 0.2413
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3025
Epoch 6/10, Batch 20/145, Loss: 0.1614
Epoch 6/10, Batch 30/145, Loss: 0.3288
Epoch 6/10, Batch 40/145, Loss: 0.2259
Epoch 6/10, Batch 50/145, Loss: 0.4861
Epoch 6/10, Batch 60/145, Loss: 0.1881
Epoch 6/10, Batch 70/145, Loss: 0.3215
Epoch 6/10, Batch 80/145, Loss: 0.1774
Epoch 6/10, Batch 90/145, Loss: 0.2306
Epoch 6/10, Batch 100/145, Loss: 0.2870
Epoch 6/10, Batch 110/145, Loss: 0.1399
Epoch 6/10, Batch 120/145, Loss: 0.1950
Epoch 6/10, Batch 130/145, Loss: 0.1128
Epoch 6/10, Batch 140/145, Loss: 0.3223
Epoch 6/10, Train Loss: 0.2319, Valid Loss: 0.2429
Epoch 7/10, Batch 10/145, Loss: 0.4418
Epoch 7/10, Batch 20/145, Loss: 0.1578
Epoch 7/10, Batch 30/145, Loss: 0.1342
Epoch 7/10, Batch 40/145, Loss: 0.3590
Epoch 7/10, Batch 50/145, Loss: 0.1644
Epoch 7/10, Batch 60/145, Loss: 0.1882
Epoch 7/10, Batch 70/145, Loss: 0.2949
Epoch 7/10, Batch 80/145, Loss: 0.1577
Epoch 7/10, Batch 90/145, Loss: 0.3557
Epoch 7/10, Batch 100/145, Loss: 0.2709
Epoch 7/10, Batch 110/145, Loss: 0.3382
Epoch 7/10, Batch 120/145, Loss: 0.1461
Epoch 7/10, Batch 130/145, Loss: 0.3526
Epoch 7/10, Batch 140/145, Loss: 0.1845
Epoch 7/10, Train Loss: 0.2227, Valid Loss: 0.2217
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1912
Epoch 8/10, Batch 20/145, Loss: 0.2539
Epoch 8/10, Batch 30/145, Loss: 0.1075
Epoch 8/10, Batch 40/145, Loss: 0.2700
Epoch 8/10, Batch 50/145, Loss: 0.1462
Epoch 8/10, Batch 60/145, Loss: 0.1202
Epoch 8/10, Batch 70/145, Loss: 0.2847
Epoch 8/10, Batch 80/145, Loss: 0.2124
Epoch 8/10, Batch 90/145, Loss: 0.1558
Epoch 8/10, Batch 100/145, Loss: 0.3665
Epoch 8/10, Batch 110/145, Loss: 0.3283
Epoch 8/10, Batch 120/145, Loss: 0.1822
Epoch 8/10, Batch 130/145, Loss: 0.2954
Epoch 8/10, Batch 140/145, Loss: 0.3595
Epoch 8/10, Train Loss: 0.2157, Valid Loss: 0.2194
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2225
Epoch 9/10, Batch 20/145, Loss: 0.1386
Epoch 9/10, Batch 30/145, Loss: 0.1384
Epoch 9/10, Batch 40/145, Loss: 0.1829
Epoch 9/10, Batch 50/145, Loss: 0.2202
Epoch 9/10, Batch 60/145, Loss: 0.3367
Epoch 9/10, Batch 70/145, Loss: 0.1761
Epoch 9/10, Batch 80/145, Loss: 0.2022
Epoch 9/10, Batch 90/145, Loss: 0.1763
Epoch 9/10, Batch 100/145, Loss: 0.2819
Epoch 9/10, Batch 110/145, Loss: 0.0527
Epoch 9/10, Batch 120/145, Loss: 0.2083
Epoch 9/10, Batch 130/145, Loss: 0.2972
Epoch 9/10, Batch 140/145, Loss: 0.1244
Epoch 9/10, Train Loss: 0.2039, Valid Loss: 0.2156
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1767
Epoch 10/10, Batch 20/145, Loss: 0.1887
Epoch 10/10, Batch 30/145, Loss: 0.1726
Epoch 10/10, Batch 40/145, Loss: 0.2198
Epoch 10/10, Batch 50/145, Loss: 0.3940
Epoch 10/10, Batch 60/145, Loss: 0.2879
Epoch 10/10, Batch 70/145, Loss: 0.0697
Epoch 10/10, Batch 80/145, Loss: 0.4336
Epoch 10/10, Batch 90/145, Loss: 0.1616
Epoch 10/10, Batch 100/145, Loss: 0.1076
Epoch 10/10, Batch 110/145, Loss: 0.1985
Epoch 10/10, Batch 120/145, Loss: 0.1541
Epoch 10/10, Batch 130/145, Loss: 0.2230
Epoch 10/10, Batch 140/145, Loss: 0.1778
Epoch 10/10, Train Loss: 0.1995, Valid Loss: 0.2149
Model saved!
Accuracy: 0.9264
Precision: 0.9255
Recall: 0.9264
F1-score: 0.9257
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5012
Epoch 1/10, Batch 20/145, Loss: 0.8159
Epoch 1/10, Batch 30/145, Loss: 0.7770
Epoch 1/10, Batch 40/145, Loss: 0.8641
Epoch 1/10, Batch 50/145, Loss: 0.4986
Epoch 1/10, Batch 60/145, Loss: 0.6059
Epoch 1/10, Batch 70/145, Loss: 0.6299
Epoch 1/10, Batch 80/145, Loss: 0.6175
Epoch 1/10, Batch 90/145, Loss: 0.4632
Epoch 1/10, Batch 100/145, Loss: 0.5245
Epoch 1/10, Batch 110/145, Loss: 0.5021
Epoch 1/10, Batch 120/145, Loss: 0.5346
Epoch 1/10, Batch 130/145, Loss: 0.5525
Epoch 1/10, Batch 140/145, Loss: 0.4814
Epoch 1/10, Train Loss: 0.6868, Valid Loss: 0.3576
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2477
Epoch 2/10, Batch 20/145, Loss: 0.5172
Epoch 2/10, Batch 30/145, Loss: 0.4043
Epoch 2/10, Batch 40/145, Loss: 0.3734
Epoch 2/10, Batch 50/145, Loss: 0.4591
Epoch 2/10, Batch 60/145, Loss: 0.3712
Epoch 2/10, Batch 70/145, Loss: 0.4461
Epoch 2/10, Batch 80/145, Loss: 0.3174
Epoch 2/10, Batch 90/145, Loss: 0.2969
Epoch 2/10, Batch 100/145, Loss: 0.2886
Epoch 2/10, Batch 110/145, Loss: 0.3785
Epoch 2/10, Batch 120/145, Loss: 0.3429
Epoch 2/10, Batch 130/145, Loss: 0.3722
Epoch 2/10, Batch 140/145, Loss: 0.2288
Epoch 2/10, Train Loss: 0.3616, Valid Loss: 0.2678
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2303
Epoch 3/10, Batch 20/145, Loss: 0.2065
Epoch 3/10, Batch 30/145, Loss: 0.2351
Epoch 3/10, Batch 40/145, Loss: 0.2155
Epoch 3/10, Batch 50/145, Loss: 0.2507
Epoch 3/10, Batch 60/145, Loss: 0.3650
Epoch 3/10, Batch 70/145, Loss: 0.1375
Epoch 3/10, Batch 80/145, Loss: 0.2015
Epoch 3/10, Batch 90/145, Loss: 0.3695
Epoch 3/10, Batch 100/145, Loss: 0.3321
Epoch 3/10, Batch 110/145, Loss: 0.2226
Epoch 3/10, Batch 120/145, Loss: 0.2474
Epoch 3/10, Batch 130/145, Loss: 0.1716
Epoch 3/10, Batch 140/145, Loss: 0.1558
Epoch 3/10, Train Loss: 0.3013, Valid Loss: 0.2379
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2566
Epoch 4/10, Batch 20/145, Loss: 0.3475
Epoch 4/10, Batch 30/145, Loss: 0.3211
Epoch 4/10, Batch 40/145, Loss: 0.4629
Epoch 4/10, Batch 50/145, Loss: 0.1620
Epoch 4/10, Batch 60/145, Loss: 0.2327
Epoch 4/10, Batch 70/145, Loss: 0.2151
Epoch 4/10, Batch 80/145, Loss: 0.2353
Epoch 4/10, Batch 90/145, Loss: 0.2458
Epoch 4/10, Batch 100/145, Loss: 0.2181
Epoch 4/10, Batch 110/145, Loss: 0.1711
Epoch 4/10, Batch 120/145, Loss: 0.1589
Epoch 4/10, Batch 130/145, Loss: 0.2608
Epoch 4/10, Batch 140/145, Loss: 0.3188
Epoch 4/10, Train Loss: 0.2606, Valid Loss: 0.2293
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3058
Epoch 5/10, Batch 20/145, Loss: 0.4340
Epoch 5/10, Batch 30/145, Loss: 0.1714
Epoch 5/10, Batch 40/145, Loss: 0.1957
Epoch 5/10, Batch 50/145, Loss: 0.1856
Epoch 5/10, Batch 60/145, Loss: 0.2077
Epoch 5/10, Batch 70/145, Loss: 0.3339
Epoch 5/10, Batch 80/145, Loss: 0.2508
Epoch 5/10, Batch 90/145, Loss: 0.2831
Epoch 5/10, Batch 100/145, Loss: 0.2168
Epoch 5/10, Batch 110/145, Loss: 0.1590
Epoch 5/10, Batch 120/145, Loss: 0.1389
Epoch 5/10, Batch 130/145, Loss: 0.1146
Epoch 5/10, Batch 140/145, Loss: 0.2530
Epoch 5/10, Train Loss: 0.2453, Valid Loss: 0.2205
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2295
Epoch 6/10, Batch 20/145, Loss: 0.1763
Epoch 6/10, Batch 30/145, Loss: 0.2203
Epoch 6/10, Batch 40/145, Loss: 0.1652
Epoch 6/10, Batch 50/145, Loss: 0.4856
Epoch 6/10, Batch 60/145, Loss: 0.2455
Epoch 6/10, Batch 70/145, Loss: 0.2716
Epoch 6/10, Batch 80/145, Loss: 0.1943
Epoch 6/10, Batch 90/145, Loss: 0.1339
Epoch 6/10, Batch 100/145, Loss: 0.2532
Epoch 6/10, Batch 110/145, Loss: 0.2687
Epoch 6/10, Batch 120/145, Loss: 0.2650
Epoch 6/10, Batch 130/145, Loss: 0.1034
Epoch 6/10, Batch 140/145, Loss: 0.2217
Epoch 6/10, Train Loss: 0.2323, Valid Loss: 0.2020
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3196
Epoch 7/10, Batch 20/145, Loss: 0.1978
Epoch 7/10, Batch 30/145, Loss: 0.2351
Epoch 7/10, Batch 40/145, Loss: 0.3887
Epoch 7/10, Batch 50/145, Loss: 0.1655
Epoch 7/10, Batch 60/145, Loss: 0.2644
Epoch 7/10, Batch 70/145, Loss: 0.5072
Epoch 7/10, Batch 80/145, Loss: 0.1382
Epoch 7/10, Batch 90/145, Loss: 0.3325
Epoch 7/10, Batch 100/145, Loss: 0.1759
Epoch 7/10, Batch 110/145, Loss: 0.1879
Epoch 7/10, Batch 120/145, Loss: 0.2094
Epoch 7/10, Batch 130/145, Loss: 0.1225
Epoch 7/10, Batch 140/145, Loss: 0.1511
Epoch 7/10, Train Loss: 0.2243, Valid Loss: 0.2020
Epoch 8/10, Batch 10/145, Loss: 0.1172
Epoch 8/10, Batch 20/145, Loss: 0.1257
Epoch 8/10, Batch 30/145, Loss: 0.1838
Epoch 8/10, Batch 40/145, Loss: 0.2215
Epoch 8/10, Batch 50/145, Loss: 0.1601
Epoch 8/10, Batch 60/145, Loss: 0.2019
Epoch 8/10, Batch 70/145, Loss: 0.1230
Epoch 8/10, Batch 80/145, Loss: 0.2290
Epoch 8/10, Batch 90/145, Loss: 0.1520
Epoch 8/10, Batch 100/145, Loss: 0.2841
Epoch 8/10, Batch 110/145, Loss: 0.2608
Epoch 8/10, Batch 120/145, Loss: 0.1445
Epoch 8/10, Batch 130/145, Loss: 0.1473
Epoch 8/10, Batch 140/145, Loss: 0.2118
Epoch 8/10, Train Loss: 0.2104, Valid Loss: 0.1996
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2427
Epoch 9/10, Batch 20/145, Loss: 0.1616
Epoch 9/10, Batch 30/145, Loss: 0.1328
Epoch 9/10, Batch 40/145, Loss: 0.1369
Epoch 9/10, Batch 50/145, Loss: 0.2117
Epoch 9/10, Batch 60/145, Loss: 0.1461
Epoch 9/10, Batch 70/145, Loss: 0.1733
Epoch 9/10, Batch 80/145, Loss: 0.1153
Epoch 9/10, Batch 90/145, Loss: 0.2668
Epoch 9/10, Batch 100/145, Loss: 0.2406
Epoch 9/10, Batch 110/145, Loss: 0.1088
Epoch 9/10, Batch 120/145, Loss: 0.1805
Epoch 9/10, Batch 130/145, Loss: 0.1572
Epoch 9/10, Batch 140/145, Loss: 0.1576
Epoch 9/10, Train Loss: 0.2018, Valid Loss: 0.1918
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2073
Epoch 10/10, Batch 20/145, Loss: 0.1352
Epoch 10/10, Batch 30/145, Loss: 0.1757
Epoch 10/10, Batch 40/145, Loss: 0.2361
Epoch 10/10, Batch 50/145, Loss: 0.4039
Epoch 10/10, Batch 60/145, Loss: 0.1829
Epoch 10/10, Batch 70/145, Loss: 0.1188
Epoch 10/10, Batch 80/145, Loss: 0.3800
Epoch 10/10, Batch 90/145, Loss: 0.1874
Epoch 10/10, Batch 100/145, Loss: 0.2560
Epoch 10/10, Batch 110/145, Loss: 0.3023
Epoch 10/10, Batch 120/145, Loss: 0.1879
Epoch 10/10, Batch 130/145, Loss: 0.2189
Epoch 10/10, Batch 140/145, Loss: 0.1721
Epoch 10/10, Train Loss: 0.1980, Valid Loss: 0.1950
Accuracy: 0.9159
Precision: 0.9141
Recall: 0.9159
F1-score: 0.9146
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5656
Epoch 1/10, Batch 20/145, Loss: 0.9176
Epoch 1/10, Batch 30/145, Loss: 0.8523
Epoch 1/10, Batch 40/145, Loss: 0.8062
Epoch 1/10, Batch 50/145, Loss: 0.5402
Epoch 1/10, Batch 60/145, Loss: 0.6228
Epoch 1/10, Batch 70/145, Loss: 0.6489
Epoch 1/10, Batch 80/145, Loss: 0.4081
Epoch 1/10, Batch 90/145, Loss: 0.4642
Epoch 1/10, Batch 100/145, Loss: 0.5882
Epoch 1/10, Batch 110/145, Loss: 0.3833
Epoch 1/10, Batch 120/145, Loss: 0.6862
Epoch 1/10, Batch 130/145, Loss: 0.3873
Epoch 1/10, Batch 140/145, Loss: 0.3573
Epoch 1/10, Train Loss: 0.6921, Valid Loss: 0.3797
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3722
Epoch 2/10, Batch 20/145, Loss: 0.4021
Epoch 2/10, Batch 30/145, Loss: 0.3458
Epoch 2/10, Batch 40/145, Loss: 0.5752
Epoch 2/10, Batch 50/145, Loss: 0.1885
Epoch 2/10, Batch 60/145, Loss: 0.4525
Epoch 2/10, Batch 70/145, Loss: 0.3988
Epoch 2/10, Batch 80/145, Loss: 0.2613
Epoch 2/10, Batch 90/145, Loss: 0.2071
Epoch 2/10, Batch 100/145, Loss: 0.3910
Epoch 2/10, Batch 110/145, Loss: 0.2108
Epoch 2/10, Batch 120/145, Loss: 0.4802
Epoch 2/10, Batch 130/145, Loss: 0.4214
Epoch 2/10, Batch 140/145, Loss: 0.3741
Epoch 2/10, Train Loss: 0.3589, Valid Loss: 0.2869
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2427
Epoch 3/10, Batch 20/145, Loss: 0.4462
Epoch 3/10, Batch 30/145, Loss: 0.2975
Epoch 3/10, Batch 40/145, Loss: 0.2193
Epoch 3/10, Batch 50/145, Loss: 0.1434
Epoch 3/10, Batch 60/145, Loss: 0.3140
Epoch 3/10, Batch 70/145, Loss: 0.1473
Epoch 3/10, Batch 80/145, Loss: 0.3430
Epoch 3/10, Batch 90/145, Loss: 0.4197
Epoch 3/10, Batch 100/145, Loss: 0.4347
Epoch 3/10, Batch 110/145, Loss: 0.1787
Epoch 3/10, Batch 120/145, Loss: 0.2852
Epoch 3/10, Batch 130/145, Loss: 0.3597
Epoch 3/10, Batch 140/145, Loss: 0.2407
Epoch 3/10, Train Loss: 0.3128, Valid Loss: 0.2589
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2373
Epoch 4/10, Batch 20/145, Loss: 0.3415
Epoch 4/10, Batch 30/145, Loss: 0.2183
Epoch 4/10, Batch 40/145, Loss: 0.5056
Epoch 4/10, Batch 50/145, Loss: 0.1938
Epoch 4/10, Batch 60/145, Loss: 0.2159
Epoch 4/10, Batch 70/145, Loss: 0.1747
Epoch 4/10, Batch 80/145, Loss: 0.3385
Epoch 4/10, Batch 90/145, Loss: 0.2296
Epoch 4/10, Batch 100/145, Loss: 0.2002
Epoch 4/10, Batch 110/145, Loss: 0.2932
Epoch 4/10, Batch 120/145, Loss: 0.2724
Epoch 4/10, Batch 130/145, Loss: 0.1741
Epoch 4/10, Batch 140/145, Loss: 0.1612
Epoch 4/10, Train Loss: 0.2666, Valid Loss: 0.2443
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1591
Epoch 5/10, Batch 20/145, Loss: 0.2526
Epoch 5/10, Batch 30/145, Loss: 0.2572
Epoch 5/10, Batch 40/145, Loss: 0.2786
Epoch 5/10, Batch 50/145, Loss: 0.1895
Epoch 5/10, Batch 60/145, Loss: 0.2102
Epoch 5/10, Batch 70/145, Loss: 0.2231
Epoch 5/10, Batch 80/145, Loss: 0.3417
Epoch 5/10, Batch 90/145, Loss: 0.1679
Epoch 5/10, Batch 100/145, Loss: 0.2332
Epoch 5/10, Batch 110/145, Loss: 0.1708
Epoch 5/10, Batch 120/145, Loss: 0.1212
Epoch 5/10, Batch 130/145, Loss: 0.2447
Epoch 5/10, Batch 140/145, Loss: 0.1776
Epoch 5/10, Train Loss: 0.2495, Valid Loss: 0.2321
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2606
Epoch 6/10, Batch 20/145, Loss: 0.1398
Epoch 6/10, Batch 30/145, Loss: 0.1294
Epoch 6/10, Batch 40/145, Loss: 0.2100
Epoch 6/10, Batch 50/145, Loss: 0.2288
Epoch 6/10, Batch 60/145, Loss: 0.2102
Epoch 6/10, Batch 70/145, Loss: 0.3670
Epoch 6/10, Batch 80/145, Loss: 0.2746
Epoch 6/10, Batch 90/145, Loss: 0.1638
Epoch 6/10, Batch 100/145, Loss: 0.2867
Epoch 6/10, Batch 110/145, Loss: 0.1671
Epoch 6/10, Batch 120/145, Loss: 0.1849
Epoch 6/10, Batch 130/145, Loss: 0.1717
Epoch 6/10, Batch 140/145, Loss: 0.3650
Epoch 6/10, Train Loss: 0.2282, Valid Loss: 0.2249
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1218
Epoch 7/10, Batch 20/145, Loss: 0.1937
Epoch 7/10, Batch 30/145, Loss: 0.1178
Epoch 7/10, Batch 40/145, Loss: 0.4836
Epoch 7/10, Batch 50/145, Loss: 0.3025
Epoch 7/10, Batch 60/145, Loss: 0.2512
Epoch 7/10, Batch 70/145, Loss: 0.2514
Epoch 7/10, Batch 80/145, Loss: 0.1264
Epoch 7/10, Batch 90/145, Loss: 0.2238
Epoch 7/10, Batch 100/145, Loss: 0.2721
Epoch 7/10, Batch 110/145, Loss: 0.1972
Epoch 7/10, Batch 120/145, Loss: 0.1773
Epoch 7/10, Batch 130/145, Loss: 0.1247
Epoch 7/10, Batch 140/145, Loss: 0.0836
Epoch 7/10, Train Loss: 0.2157, Valid Loss: 0.2112
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2894
Epoch 8/10, Batch 20/145, Loss: 0.1161
Epoch 8/10, Batch 30/145, Loss: 0.4208
Epoch 8/10, Batch 40/145, Loss: 0.1890
Epoch 8/10, Batch 50/145, Loss: 0.2427
Epoch 8/10, Batch 60/145, Loss: 0.1400
Epoch 8/10, Batch 70/145, Loss: 0.1183
Epoch 8/10, Batch 80/145, Loss: 0.2391
Epoch 8/10, Batch 90/145, Loss: 0.0665
Epoch 8/10, Batch 100/145, Loss: 0.3328
Epoch 8/10, Batch 110/145, Loss: 0.1686
Epoch 8/10, Batch 120/145, Loss: 0.1611
Epoch 8/10, Batch 130/145, Loss: 0.0959
Epoch 8/10, Batch 140/145, Loss: 0.4186
Epoch 8/10, Train Loss: 0.2109, Valid Loss: 0.2120
Epoch 9/10, Batch 10/145, Loss: 0.1943
Epoch 9/10, Batch 20/145, Loss: 0.1152
Epoch 9/10, Batch 30/145, Loss: 0.1903
Epoch 9/10, Batch 40/145, Loss: 0.1667
Epoch 9/10, Batch 50/145, Loss: 0.2900
Epoch 9/10, Batch 60/145, Loss: 0.2977
Epoch 9/10, Batch 70/145, Loss: 0.2112
Epoch 9/10, Batch 80/145, Loss: 0.1945
Epoch 9/10, Batch 90/145, Loss: 0.1219
Epoch 9/10, Batch 100/145, Loss: 0.1542
Epoch 9/10, Batch 110/145, Loss: 0.1173
Epoch 9/10, Batch 120/145, Loss: 0.3365
Epoch 9/10, Batch 130/145, Loss: 0.1327
Epoch 9/10, Batch 140/145, Loss: 0.1395
Epoch 9/10, Train Loss: 0.2066, Valid Loss: 0.2059
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1500
Epoch 10/10, Batch 20/145, Loss: 0.1653
Epoch 10/10, Batch 30/145, Loss: 0.0634
Epoch 10/10, Batch 40/145, Loss: 0.1499
Epoch 10/10, Batch 50/145, Loss: 0.3286
Epoch 10/10, Batch 60/145, Loss: 0.1242
Epoch 10/10, Batch 70/145, Loss: 0.1621
Epoch 10/10, Batch 80/145, Loss: 0.3506
Epoch 10/10, Batch 90/145, Loss: 0.3105
Epoch 10/10, Batch 100/145, Loss: 0.1175
Epoch 10/10, Batch 110/145, Loss: 0.2287
Epoch 10/10, Batch 120/145, Loss: 0.0860
Epoch 10/10, Batch 130/145, Loss: 0.2182
Epoch 10/10, Batch 140/145, Loss: 0.1115
Epoch 10/10, Train Loss: 0.2019, Valid Loss: 0.2036
Model saved!
Accuracy: 0.9252
Precision: 0.9240
Recall: 0.9252
F1-score: 0.9241
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4979
Epoch 1/10, Batch 20/145, Loss: 0.9475
Epoch 1/10, Batch 30/145, Loss: 0.8819
Epoch 1/10, Batch 40/145, Loss: 0.8841
Epoch 1/10, Batch 50/145, Loss: 0.6158
Epoch 1/10, Batch 60/145, Loss: 0.6365
Epoch 1/10, Batch 70/145, Loss: 0.5072
Epoch 1/10, Batch 80/145, Loss: 0.4999
Epoch 1/10, Batch 90/145, Loss: 0.6091
Epoch 1/10, Batch 100/145, Loss: 0.6149
Epoch 1/10, Batch 110/145, Loss: 0.4131
Epoch 1/10, Batch 120/145, Loss: 0.5168
Epoch 1/10, Batch 130/145, Loss: 0.4914
Epoch 1/10, Batch 140/145, Loss: 0.3499
Epoch 1/10, Train Loss: 0.6920, Valid Loss: 0.3976
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3303
Epoch 2/10, Batch 20/145, Loss: 0.5568
Epoch 2/10, Batch 30/145, Loss: 0.3630
Epoch 2/10, Batch 40/145, Loss: 0.4088
Epoch 2/10, Batch 50/145, Loss: 0.3358
Epoch 2/10, Batch 60/145, Loss: 0.3154
Epoch 2/10, Batch 70/145, Loss: 0.3964
Epoch 2/10, Batch 80/145, Loss: 0.4397
Epoch 2/10, Batch 90/145, Loss: 0.2524
Epoch 2/10, Batch 100/145, Loss: 0.3286
Epoch 2/10, Batch 110/145, Loss: 0.2936
Epoch 2/10, Batch 120/145, Loss: 0.3885
Epoch 2/10, Batch 130/145, Loss: 0.3307
Epoch 2/10, Batch 140/145, Loss: 0.4998
Epoch 2/10, Train Loss: 0.3541, Valid Loss: 0.3124
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1634
Epoch 3/10, Batch 20/145, Loss: 0.2057
Epoch 3/10, Batch 30/145, Loss: 0.1656
Epoch 3/10, Batch 40/145, Loss: 0.2222
Epoch 3/10, Batch 50/145, Loss: 0.2484
Epoch 3/10, Batch 60/145, Loss: 0.3428
Epoch 3/10, Batch 70/145, Loss: 0.3544
Epoch 3/10, Batch 80/145, Loss: 0.1461
Epoch 3/10, Batch 90/145, Loss: 0.4109
Epoch 3/10, Batch 100/145, Loss: 0.1957
Epoch 3/10, Batch 110/145, Loss: 0.2258
Epoch 3/10, Batch 120/145, Loss: 0.1785
Epoch 3/10, Batch 130/145, Loss: 0.2160
Epoch 3/10, Batch 140/145, Loss: 0.1656
Epoch 3/10, Train Loss: 0.3061, Valid Loss: 0.2901
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2065
Epoch 4/10, Batch 20/145, Loss: 0.2290
Epoch 4/10, Batch 30/145, Loss: 0.3324
Epoch 4/10, Batch 40/145, Loss: 0.4954
Epoch 4/10, Batch 50/145, Loss: 0.2351
Epoch 4/10, Batch 60/145, Loss: 0.3138
Epoch 4/10, Batch 70/145, Loss: 0.2623
Epoch 4/10, Batch 80/145, Loss: 0.1558
Epoch 4/10, Batch 90/145, Loss: 0.2292
Epoch 4/10, Batch 100/145, Loss: 0.1477
Epoch 4/10, Batch 110/145, Loss: 0.3017
Epoch 4/10, Batch 120/145, Loss: 0.2662
Epoch 4/10, Batch 130/145, Loss: 0.2530
Epoch 4/10, Batch 140/145, Loss: 0.2772
Epoch 4/10, Train Loss: 0.2659, Valid Loss: 0.2776
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1449
Epoch 5/10, Batch 20/145, Loss: 0.2018
Epoch 5/10, Batch 30/145, Loss: 0.1791
Epoch 5/10, Batch 40/145, Loss: 0.2147
Epoch 5/10, Batch 50/145, Loss: 0.2142
Epoch 5/10, Batch 60/145, Loss: 0.1860
Epoch 5/10, Batch 70/145, Loss: 0.2163
Epoch 5/10, Batch 80/145, Loss: 0.3624
Epoch 5/10, Batch 90/145, Loss: 0.1965
Epoch 5/10, Batch 100/145, Loss: 0.3347
Epoch 5/10, Batch 110/145, Loss: 0.3479
Epoch 5/10, Batch 120/145, Loss: 0.1613
Epoch 5/10, Batch 130/145, Loss: 0.2997
Epoch 5/10, Batch 140/145, Loss: 0.1736
Epoch 5/10, Train Loss: 0.2428, Valid Loss: 0.2634
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2898
Epoch 6/10, Batch 20/145, Loss: 0.3433
Epoch 6/10, Batch 30/145, Loss: 0.1755
Epoch 6/10, Batch 40/145, Loss: 0.1344
Epoch 6/10, Batch 50/145, Loss: 0.3108
Epoch 6/10, Batch 60/145, Loss: 0.1140
Epoch 6/10, Batch 70/145, Loss: 0.2885
Epoch 6/10, Batch 80/145, Loss: 0.1951
Epoch 6/10, Batch 90/145, Loss: 0.2216
Epoch 6/10, Batch 100/145, Loss: 0.2347
Epoch 6/10, Batch 110/145, Loss: 0.1158
Epoch 6/10, Batch 120/145, Loss: 0.1971
Epoch 6/10, Batch 130/145, Loss: 0.0735
Epoch 6/10, Batch 140/145, Loss: 0.2374
Epoch 6/10, Train Loss: 0.2263, Valid Loss: 0.2591
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2791
Epoch 7/10, Batch 20/145, Loss: 0.2010
Epoch 7/10, Batch 30/145, Loss: 0.2469
Epoch 7/10, Batch 40/145, Loss: 0.3990
Epoch 7/10, Batch 50/145, Loss: 0.1866
Epoch 7/10, Batch 60/145, Loss: 0.1638
Epoch 7/10, Batch 70/145, Loss: 0.2645
Epoch 7/10, Batch 80/145, Loss: 0.0783
Epoch 7/10, Batch 90/145, Loss: 0.3923
Epoch 7/10, Batch 100/145, Loss: 0.1585
Epoch 7/10, Batch 110/145, Loss: 0.1184
Epoch 7/10, Batch 120/145, Loss: 0.1808
Epoch 7/10, Batch 130/145, Loss: 0.1299
Epoch 7/10, Batch 140/145, Loss: 0.2540
Epoch 7/10, Train Loss: 0.2209, Valid Loss: 0.2494
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1862
Epoch 8/10, Batch 20/145, Loss: 0.2369
Epoch 8/10, Batch 30/145, Loss: 0.2026
Epoch 8/10, Batch 40/145, Loss: 0.3313
Epoch 8/10, Batch 50/145, Loss: 0.2521
Epoch 8/10, Batch 60/145, Loss: 0.2330
Epoch 8/10, Batch 70/145, Loss: 0.1425
Epoch 8/10, Batch 80/145, Loss: 0.0993
Epoch 8/10, Batch 90/145, Loss: 0.1193
Epoch 8/10, Batch 100/145, Loss: 0.1849
Epoch 8/10, Batch 110/145, Loss: 0.3146
Epoch 8/10, Batch 120/145, Loss: 0.1580
Epoch 8/10, Batch 130/145, Loss: 0.2621
Epoch 8/10, Batch 140/145, Loss: 0.4073
Epoch 8/10, Train Loss: 0.2093, Valid Loss: 0.2489
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2830
Epoch 9/10, Batch 20/145, Loss: 0.1426
Epoch 9/10, Batch 30/145, Loss: 0.1454
Epoch 9/10, Batch 40/145, Loss: 0.1131
Epoch 9/10, Batch 50/145, Loss: 0.1660
Epoch 9/10, Batch 60/145, Loss: 0.1459
Epoch 9/10, Batch 70/145, Loss: 0.3312
Epoch 9/10, Batch 80/145, Loss: 0.1624
Epoch 9/10, Batch 90/145, Loss: 0.1667
Epoch 9/10, Batch 100/145, Loss: 0.1064
Epoch 9/10, Batch 110/145, Loss: 0.0816
Epoch 9/10, Batch 120/145, Loss: 0.2372
Epoch 9/10, Batch 130/145, Loss: 0.1323
Epoch 9/10, Batch 140/145, Loss: 0.1410
Epoch 9/10, Train Loss: 0.2048, Valid Loss: 0.2384
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2531
Epoch 10/10, Batch 20/145, Loss: 0.1170
Epoch 10/10, Batch 30/145, Loss: 0.0832
Epoch 10/10, Batch 40/145, Loss: 0.1281
Epoch 10/10, Batch 50/145, Loss: 0.1985
Epoch 10/10, Batch 60/145, Loss: 0.1659
Epoch 10/10, Batch 70/145, Loss: 0.1277
Epoch 10/10, Batch 80/145, Loss: 0.4054
Epoch 10/10, Batch 90/145, Loss: 0.1182
Epoch 10/10, Batch 100/145, Loss: 0.2381
Epoch 10/10, Batch 110/145, Loss: 0.1748
Epoch 10/10, Batch 120/145, Loss: 0.2259
Epoch 10/10, Batch 130/145, Loss: 0.1681
Epoch 10/10, Batch 140/145, Loss: 0.2788
Epoch 10/10, Train Loss: 0.1961, Valid Loss: 0.2401
Accuracy: 0.9182
Precision: 0.9162
Recall: 0.9182
F1-score: 0.9166
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4541
Epoch 1/10, Batch 20/145, Loss: 0.9176
Epoch 1/10, Batch 30/145, Loss: 0.8104
Epoch 1/10, Batch 40/145, Loss: 0.8149
Epoch 1/10, Batch 50/145, Loss: 0.5484
Epoch 1/10, Batch 60/145, Loss: 0.5553
Epoch 1/10, Batch 70/145, Loss: 0.6733
Epoch 1/10, Batch 80/145, Loss: 0.4530
Epoch 1/10, Batch 90/145, Loss: 0.5841
Epoch 1/10, Batch 100/145, Loss: 0.6861
Epoch 1/10, Batch 110/145, Loss: 0.4957
Epoch 1/10, Batch 120/145, Loss: 0.6268
Epoch 1/10, Batch 130/145, Loss: 0.4906
Epoch 1/10, Batch 140/145, Loss: 0.3821
Epoch 1/10, Train Loss: 0.6910, Valid Loss: 0.3677
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3374
Epoch 2/10, Batch 20/145, Loss: 0.5539
Epoch 2/10, Batch 30/145, Loss: 0.2695
Epoch 2/10, Batch 40/145, Loss: 0.3192
Epoch 2/10, Batch 50/145, Loss: 0.3007
Epoch 2/10, Batch 60/145, Loss: 0.4231
Epoch 2/10, Batch 70/145, Loss: 0.3749
Epoch 2/10, Batch 80/145, Loss: 0.4308
Epoch 2/10, Batch 90/145, Loss: 0.3170
Epoch 2/10, Batch 100/145, Loss: 0.3340
Epoch 2/10, Batch 110/145, Loss: 0.3580
Epoch 2/10, Batch 120/145, Loss: 0.3977
Epoch 2/10, Batch 130/145, Loss: 0.3676
Epoch 2/10, Batch 140/145, Loss: 0.3189
Epoch 2/10, Train Loss: 0.3647, Valid Loss: 0.2833
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2671
Epoch 3/10, Batch 20/145, Loss: 0.2984
Epoch 3/10, Batch 30/145, Loss: 0.2896
Epoch 3/10, Batch 40/145, Loss: 0.2713
Epoch 3/10, Batch 50/145, Loss: 0.1731
Epoch 3/10, Batch 60/145, Loss: 0.2195
Epoch 3/10, Batch 70/145, Loss: 0.1981
Epoch 3/10, Batch 80/145, Loss: 0.2655
Epoch 3/10, Batch 90/145, Loss: 0.6152
Epoch 3/10, Batch 100/145, Loss: 0.2690
Epoch 3/10, Batch 110/145, Loss: 0.2758
Epoch 3/10, Batch 120/145, Loss: 0.2060
Epoch 3/10, Batch 130/145, Loss: 0.2667
Epoch 3/10, Batch 140/145, Loss: 0.2720
Epoch 3/10, Train Loss: 0.3105, Valid Loss: 0.2546
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1430
Epoch 4/10, Batch 20/145, Loss: 0.2805
Epoch 4/10, Batch 30/145, Loss: 0.2121
Epoch 4/10, Batch 40/145, Loss: 0.5040
Epoch 4/10, Batch 50/145, Loss: 0.1168
Epoch 4/10, Batch 60/145, Loss: 0.3114
Epoch 4/10, Batch 70/145, Loss: 0.2827
Epoch 4/10, Batch 80/145, Loss: 0.3186
Epoch 4/10, Batch 90/145, Loss: 0.3645
Epoch 4/10, Batch 100/145, Loss: 0.2842
Epoch 4/10, Batch 110/145, Loss: 0.1309
Epoch 4/10, Batch 120/145, Loss: 0.3417
Epoch 4/10, Batch 130/145, Loss: 0.1989
Epoch 4/10, Batch 140/145, Loss: 0.3031
Epoch 4/10, Train Loss: 0.2698, Valid Loss: 0.2433
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2249
Epoch 5/10, Batch 20/145, Loss: 0.1083
Epoch 5/10, Batch 30/145, Loss: 0.1432
Epoch 5/10, Batch 40/145, Loss: 0.2120
Epoch 5/10, Batch 50/145, Loss: 0.1138
Epoch 5/10, Batch 60/145, Loss: 0.1727
Epoch 5/10, Batch 70/145, Loss: 0.2522
Epoch 5/10, Batch 80/145, Loss: 0.2875
Epoch 5/10, Batch 90/145, Loss: 0.1699
Epoch 5/10, Batch 100/145, Loss: 0.2806
Epoch 5/10, Batch 110/145, Loss: 0.1369
Epoch 5/10, Batch 120/145, Loss: 0.2106
Epoch 5/10, Batch 130/145, Loss: 0.1374
Epoch 5/10, Batch 140/145, Loss: 0.3221
Epoch 5/10, Train Loss: 0.2398, Valid Loss: 0.2369
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.5482
Epoch 6/10, Batch 20/145, Loss: 0.2770
Epoch 6/10, Batch 30/145, Loss: 0.3007
Epoch 6/10, Batch 40/145, Loss: 0.1680
Epoch 6/10, Batch 50/145, Loss: 0.4139
Epoch 6/10, Batch 60/145, Loss: 0.2018
Epoch 6/10, Batch 70/145, Loss: 0.2321
Epoch 6/10, Batch 80/145, Loss: 0.4109
Epoch 6/10, Batch 90/145, Loss: 0.1534
Epoch 6/10, Batch 100/145, Loss: 0.2208
Epoch 6/10, Batch 110/145, Loss: 0.2087
Epoch 6/10, Batch 120/145, Loss: 0.1278
Epoch 6/10, Batch 130/145, Loss: 0.2113
Epoch 6/10, Batch 140/145, Loss: 0.2234
Epoch 6/10, Train Loss: 0.2329, Valid Loss: 0.2396
Epoch 7/10, Batch 10/145, Loss: 0.3991
Epoch 7/10, Batch 20/145, Loss: 0.2219
Epoch 7/10, Batch 30/145, Loss: 0.1493
Epoch 7/10, Batch 40/145, Loss: 0.5271
Epoch 7/10, Batch 50/145, Loss: 0.2146
Epoch 7/10, Batch 60/145, Loss: 0.1391
Epoch 7/10, Batch 70/145, Loss: 0.3423
Epoch 7/10, Batch 80/145, Loss: 0.1112
Epoch 7/10, Batch 90/145, Loss: 0.2304
Epoch 7/10, Batch 100/145, Loss: 0.1728
Epoch 7/10, Batch 110/145, Loss: 0.2516
Epoch 7/10, Batch 120/145, Loss: 0.1519
Epoch 7/10, Batch 130/145, Loss: 0.1267
Epoch 7/10, Batch 140/145, Loss: 0.1659
Epoch 7/10, Train Loss: 0.2250, Valid Loss: 0.2369
Epoch 8/10, Batch 10/145, Loss: 0.1141
Epoch 8/10, Batch 20/145, Loss: 0.1458
Epoch 8/10, Batch 30/145, Loss: 0.1846
Epoch 8/10, Batch 40/145, Loss: 0.2409
Epoch 8/10, Batch 50/145, Loss: 0.2614
Epoch 8/10, Batch 60/145, Loss: 0.1910
Epoch 8/10, Batch 70/145, Loss: 0.1628
Epoch 8/10, Batch 80/145, Loss: 0.3040
Epoch 8/10, Batch 90/145, Loss: 0.2152
Epoch 8/10, Batch 100/145, Loss: 0.2789
Epoch 8/10, Batch 110/145, Loss: 0.2495
Epoch 8/10, Batch 120/145, Loss: 0.0898
Epoch 8/10, Batch 130/145, Loss: 0.1035
Epoch 8/10, Batch 140/145, Loss: 0.1781
Epoch 8/10, Train Loss: 0.2125, Valid Loss: 0.2142
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2067
Epoch 9/10, Batch 20/145, Loss: 0.1822
Epoch 9/10, Batch 30/145, Loss: 0.1039
Epoch 9/10, Batch 40/145, Loss: 0.1082
Epoch 9/10, Batch 50/145, Loss: 0.2250
Epoch 9/10, Batch 60/145, Loss: 0.2244
Epoch 9/10, Batch 70/145, Loss: 0.1890
Epoch 9/10, Batch 80/145, Loss: 0.1555
Epoch 9/10, Batch 90/145, Loss: 0.1696
Epoch 9/10, Batch 100/145, Loss: 0.3000
Epoch 9/10, Batch 110/145, Loss: 0.2074
Epoch 9/10, Batch 120/145, Loss: 0.2734
Epoch 9/10, Batch 130/145, Loss: 0.3958
Epoch 9/10, Batch 140/145, Loss: 0.0700
Epoch 9/10, Train Loss: 0.1973, Valid Loss: 0.2088
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2270
Epoch 10/10, Batch 20/145, Loss: 0.1058
Epoch 10/10, Batch 30/145, Loss: 0.0936
Epoch 10/10, Batch 40/145, Loss: 0.3252
Epoch 10/10, Batch 50/145, Loss: 0.2623
Epoch 10/10, Batch 60/145, Loss: 0.1363
Epoch 10/10, Batch 70/145, Loss: 0.2740
Epoch 10/10, Batch 80/145, Loss: 0.3089
Epoch 10/10, Batch 90/145, Loss: 0.1410
Epoch 10/10, Batch 100/145, Loss: 0.1303
Epoch 10/10, Batch 110/145, Loss: 0.1061
Epoch 10/10, Batch 120/145, Loss: 0.1789
Epoch 10/10, Batch 130/145, Loss: 0.3394
Epoch 10/10, Batch 140/145, Loss: 0.3465
Epoch 10/10, Train Loss: 0.2000, Valid Loss: 0.2069
Model saved!
Accuracy: 0.9276
Precision: 0.9264
Recall: 0.9276
F1-score: 0.9269
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5202
Epoch 1/10, Batch 20/145, Loss: 0.9321
Epoch 1/10, Batch 30/145, Loss: 0.8408
Epoch 1/10, Batch 40/145, Loss: 0.8297
Epoch 1/10, Batch 50/145, Loss: 0.6041
Epoch 1/10, Batch 60/145, Loss: 0.4914
Epoch 1/10, Batch 70/145, Loss: 0.6601
Epoch 1/10, Batch 80/145, Loss: 0.4231
Epoch 1/10, Batch 90/145, Loss: 0.5133
Epoch 1/10, Batch 100/145, Loss: 0.6514
Epoch 1/10, Batch 110/145, Loss: 0.4152
Epoch 1/10, Batch 120/145, Loss: 0.6443
Epoch 1/10, Batch 130/145, Loss: 0.3813
Epoch 1/10, Batch 140/145, Loss: 0.3409
Epoch 1/10, Train Loss: 0.6894, Valid Loss: 0.3678
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3308
Epoch 2/10, Batch 20/145, Loss: 0.5380
Epoch 2/10, Batch 30/145, Loss: 0.2753
Epoch 2/10, Batch 40/145, Loss: 0.5746
Epoch 2/10, Batch 50/145, Loss: 0.3313
Epoch 2/10, Batch 60/145, Loss: 0.3787
Epoch 2/10, Batch 70/145, Loss: 0.4280
Epoch 2/10, Batch 80/145, Loss: 0.2421
Epoch 2/10, Batch 90/145, Loss: 0.3106
Epoch 2/10, Batch 100/145, Loss: 0.6663
Epoch 2/10, Batch 110/145, Loss: 0.2380
Epoch 2/10, Batch 120/145, Loss: 0.3686
Epoch 2/10, Batch 130/145, Loss: 0.2537
Epoch 2/10, Batch 140/145, Loss: 0.2538
Epoch 2/10, Train Loss: 0.3669, Valid Loss: 0.2859
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2368
Epoch 3/10, Batch 20/145, Loss: 0.1687
Epoch 3/10, Batch 30/145, Loss: 0.2258
Epoch 3/10, Batch 40/145, Loss: 0.2906
Epoch 3/10, Batch 50/145, Loss: 0.1634
Epoch 3/10, Batch 60/145, Loss: 0.3431
Epoch 3/10, Batch 70/145, Loss: 0.3741
Epoch 3/10, Batch 80/145, Loss: 0.2047
Epoch 3/10, Batch 90/145, Loss: 0.5735
Epoch 3/10, Batch 100/145, Loss: 0.2473
Epoch 3/10, Batch 110/145, Loss: 0.2859
Epoch 3/10, Batch 120/145, Loss: 0.2833
Epoch 3/10, Batch 130/145, Loss: 0.3873
Epoch 3/10, Batch 140/145, Loss: 0.1625
Epoch 3/10, Train Loss: 0.3018, Valid Loss: 0.2578
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2163
Epoch 4/10, Batch 20/145, Loss: 0.3252
Epoch 4/10, Batch 30/145, Loss: 0.2674
Epoch 4/10, Batch 40/145, Loss: 0.2995
Epoch 4/10, Batch 50/145, Loss: 0.1718
Epoch 4/10, Batch 60/145, Loss: 0.1597
Epoch 4/10, Batch 70/145, Loss: 0.2468
Epoch 4/10, Batch 80/145, Loss: 0.3052
Epoch 4/10, Batch 90/145, Loss: 0.2986
Epoch 4/10, Batch 100/145, Loss: 0.1862
Epoch 4/10, Batch 110/145, Loss: 0.2873
Epoch 4/10, Batch 120/145, Loss: 0.1345
Epoch 4/10, Batch 130/145, Loss: 0.2362
Epoch 4/10, Batch 140/145, Loss: 0.2420
Epoch 4/10, Train Loss: 0.2591, Valid Loss: 0.2528
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2116
Epoch 5/10, Batch 20/145, Loss: 0.1748
Epoch 5/10, Batch 30/145, Loss: 0.1746
Epoch 5/10, Batch 40/145, Loss: 0.4178
Epoch 5/10, Batch 50/145, Loss: 0.1345
Epoch 5/10, Batch 60/145, Loss: 0.2103
Epoch 5/10, Batch 70/145, Loss: 0.4899
Epoch 5/10, Batch 80/145, Loss: 0.1990
Epoch 5/10, Batch 90/145, Loss: 0.1537
Epoch 5/10, Batch 100/145, Loss: 0.2070
Epoch 5/10, Batch 110/145, Loss: 0.2344
Epoch 5/10, Batch 120/145, Loss: 0.1985
Epoch 5/10, Batch 130/145, Loss: 0.2134
Epoch 5/10, Batch 140/145, Loss: 0.2299
Epoch 5/10, Train Loss: 0.2437, Valid Loss: 0.2354
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2514
Epoch 6/10, Batch 20/145, Loss: 0.1935
Epoch 6/10, Batch 30/145, Loss: 0.2672
Epoch 6/10, Batch 40/145, Loss: 0.2636
Epoch 6/10, Batch 50/145, Loss: 0.3907
Epoch 6/10, Batch 60/145, Loss: 0.1537
Epoch 6/10, Batch 70/145, Loss: 0.1843
Epoch 6/10, Batch 80/145, Loss: 0.4227
Epoch 6/10, Batch 90/145, Loss: 0.2817
Epoch 6/10, Batch 100/145, Loss: 0.1764
Epoch 6/10, Batch 110/145, Loss: 0.1816
Epoch 6/10, Batch 120/145, Loss: 0.2336
Epoch 6/10, Batch 130/145, Loss: 0.0944
Epoch 6/10, Batch 140/145, Loss: 0.1695
Epoch 6/10, Train Loss: 0.2294, Valid Loss: 0.2383
Epoch 7/10, Batch 10/145, Loss: 0.2310
Epoch 7/10, Batch 20/145, Loss: 0.1634
Epoch 7/10, Batch 30/145, Loss: 0.1252
Epoch 7/10, Batch 40/145, Loss: 0.3738
Epoch 7/10, Batch 50/145, Loss: 0.2147
Epoch 7/10, Batch 60/145, Loss: 0.1321
Epoch 7/10, Batch 70/145, Loss: 0.2731
Epoch 7/10, Batch 80/145, Loss: 0.1630
Epoch 7/10, Batch 90/145, Loss: 0.2503
Epoch 7/10, Batch 100/145, Loss: 0.1970
Epoch 7/10, Batch 110/145, Loss: 0.3368
Epoch 7/10, Batch 120/145, Loss: 0.1127
Epoch 7/10, Batch 130/145, Loss: 0.2520
Epoch 7/10, Batch 140/145, Loss: 0.1431
Epoch 7/10, Train Loss: 0.2226, Valid Loss: 0.2295
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1636
Epoch 8/10, Batch 20/145, Loss: 0.1487
Epoch 8/10, Batch 30/145, Loss: 0.1560
Epoch 8/10, Batch 40/145, Loss: 0.2927
Epoch 8/10, Batch 50/145, Loss: 0.2558
Epoch 8/10, Batch 60/145, Loss: 0.1352
Epoch 8/10, Batch 70/145, Loss: 0.2400
Epoch 8/10, Batch 80/145, Loss: 0.1976
Epoch 8/10, Batch 90/145, Loss: 0.2103
Epoch 8/10, Batch 100/145, Loss: 0.1554
Epoch 8/10, Batch 110/145, Loss: 0.2318
Epoch 8/10, Batch 120/145, Loss: 0.1895
Epoch 8/10, Batch 130/145, Loss: 0.1284
Epoch 8/10, Batch 140/145, Loss: 0.3641
Epoch 8/10, Train Loss: 0.2050, Valid Loss: 0.2205
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2220
Epoch 9/10, Batch 20/145, Loss: 0.0897
Epoch 9/10, Batch 30/145, Loss: 0.1573
Epoch 9/10, Batch 40/145, Loss: 0.2367
Epoch 9/10, Batch 50/145, Loss: 0.1516
Epoch 9/10, Batch 60/145, Loss: 0.2186
Epoch 9/10, Batch 70/145, Loss: 0.2644
Epoch 9/10, Batch 80/145, Loss: 0.1282
Epoch 9/10, Batch 90/145, Loss: 0.1431
Epoch 9/10, Batch 100/145, Loss: 0.1270
Epoch 9/10, Batch 110/145, Loss: 0.0566
Epoch 9/10, Batch 120/145, Loss: 0.2571
Epoch 9/10, Batch 130/145, Loss: 0.1505
Epoch 9/10, Batch 140/145, Loss: 0.1055
Epoch 9/10, Train Loss: 0.2071, Valid Loss: 0.2139
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2233
Epoch 10/10, Batch 20/145, Loss: 0.2631
Epoch 10/10, Batch 30/145, Loss: 0.1184
Epoch 10/10, Batch 40/145, Loss: 0.2134
Epoch 10/10, Batch 50/145, Loss: 0.2796
Epoch 10/10, Batch 60/145, Loss: 0.4613
Epoch 10/10, Batch 70/145, Loss: 0.1676
Epoch 10/10, Batch 80/145, Loss: 0.2922
Epoch 10/10, Batch 90/145, Loss: 0.1301
Epoch 10/10, Batch 100/145, Loss: 0.1335
Epoch 10/10, Batch 110/145, Loss: 0.2306
Epoch 10/10, Batch 120/145, Loss: 0.1419
Epoch 10/10, Batch 130/145, Loss: 0.2877
Epoch 10/10, Batch 140/145, Loss: 0.2407
Epoch 10/10, Train Loss: 0.1947, Valid Loss: 0.2080
Model saved!
Accuracy: 0.9159
Precision: 0.9149
Recall: 0.9159
F1-score: 0.9151
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4423
Epoch 1/10, Batch 20/145, Loss: 0.9179
Epoch 1/10, Batch 30/145, Loss: 0.9493
Epoch 1/10, Batch 40/145, Loss: 0.7686
Epoch 1/10, Batch 50/145, Loss: 0.6355
Epoch 1/10, Batch 60/145, Loss: 0.4846
Epoch 1/10, Batch 70/145, Loss: 0.6399
Epoch 1/10, Batch 80/145, Loss: 0.4898
Epoch 1/10, Batch 90/145, Loss: 0.5858
Epoch 1/10, Batch 100/145, Loss: 0.5310
Epoch 1/10, Batch 110/145, Loss: 0.2975
Epoch 1/10, Batch 120/145, Loss: 0.5915
Epoch 1/10, Batch 130/145, Loss: 0.3771
Epoch 1/10, Batch 140/145, Loss: 0.5396
Epoch 1/10, Train Loss: 0.6881, Valid Loss: 0.3693
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3943
Epoch 2/10, Batch 20/145, Loss: 0.5945
Epoch 2/10, Batch 30/145, Loss: 0.3098
Epoch 2/10, Batch 40/145, Loss: 0.5747
Epoch 2/10, Batch 50/145, Loss: 0.3428
Epoch 2/10, Batch 60/145, Loss: 0.5030
Epoch 2/10, Batch 70/145, Loss: 0.2728
Epoch 2/10, Batch 80/145, Loss: 0.4217
Epoch 2/10, Batch 90/145, Loss: 0.2785
Epoch 2/10, Batch 100/145, Loss: 0.4269
Epoch 2/10, Batch 110/145, Loss: 0.2582
Epoch 2/10, Batch 120/145, Loss: 0.3969
Epoch 2/10, Batch 130/145, Loss: 0.4449
Epoch 2/10, Batch 140/145, Loss: 0.1620
Epoch 2/10, Train Loss: 0.3666, Valid Loss: 0.2784
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1261
Epoch 3/10, Batch 20/145, Loss: 0.2670
Epoch 3/10, Batch 30/145, Loss: 0.2362
Epoch 3/10, Batch 40/145, Loss: 0.2388
Epoch 3/10, Batch 50/145, Loss: 0.2348
Epoch 3/10, Batch 60/145, Loss: 0.3645
Epoch 3/10, Batch 70/145, Loss: 0.1861
Epoch 3/10, Batch 80/145, Loss: 0.2504
Epoch 3/10, Batch 90/145, Loss: 0.4687
Epoch 3/10, Batch 100/145, Loss: 0.2495
Epoch 3/10, Batch 110/145, Loss: 0.2214
Epoch 3/10, Batch 120/145, Loss: 0.2311
Epoch 3/10, Batch 130/145, Loss: 0.2511
Epoch 3/10, Batch 140/145, Loss: 0.3311
Epoch 3/10, Train Loss: 0.3101, Valid Loss: 0.2533
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1754
Epoch 4/10, Batch 20/145, Loss: 0.3777
Epoch 4/10, Batch 30/145, Loss: 0.2372
Epoch 4/10, Batch 40/145, Loss: 0.5268
Epoch 4/10, Batch 50/145, Loss: 0.1897
Epoch 4/10, Batch 60/145, Loss: 0.3053
Epoch 4/10, Batch 70/145, Loss: 0.1587
Epoch 4/10, Batch 80/145, Loss: 0.3200
Epoch 4/10, Batch 90/145, Loss: 0.2980
Epoch 4/10, Batch 100/145, Loss: 0.3065
Epoch 4/10, Batch 110/145, Loss: 0.3867
Epoch 4/10, Batch 120/145, Loss: 0.1652
Epoch 4/10, Batch 130/145, Loss: 0.3033
Epoch 4/10, Batch 140/145, Loss: 0.2125
Epoch 4/10, Train Loss: 0.2741, Valid Loss: 0.2503
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2816
Epoch 5/10, Batch 20/145, Loss: 0.2522
Epoch 5/10, Batch 30/145, Loss: 0.1775
Epoch 5/10, Batch 40/145, Loss: 0.3491
Epoch 5/10, Batch 50/145, Loss: 0.0958
Epoch 5/10, Batch 60/145, Loss: 0.2535
Epoch 5/10, Batch 70/145, Loss: 0.3381
Epoch 5/10, Batch 80/145, Loss: 0.2587
Epoch 5/10, Batch 90/145, Loss: 0.2310
Epoch 5/10, Batch 100/145, Loss: 0.3145
Epoch 5/10, Batch 110/145, Loss: 0.2206
Epoch 5/10, Batch 120/145, Loss: 0.2209
Epoch 5/10, Batch 130/145, Loss: 0.2207
Epoch 5/10, Batch 140/145, Loss: 0.3653
Epoch 5/10, Train Loss: 0.2437, Valid Loss: 0.2232
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3128
Epoch 6/10, Batch 20/145, Loss: 0.1895
Epoch 6/10, Batch 30/145, Loss: 0.2297
Epoch 6/10, Batch 40/145, Loss: 0.0950
Epoch 6/10, Batch 50/145, Loss: 0.3177
Epoch 6/10, Batch 60/145, Loss: 0.1657
Epoch 6/10, Batch 70/145, Loss: 0.1222
Epoch 6/10, Batch 80/145, Loss: 0.1507
Epoch 6/10, Batch 90/145, Loss: 0.2200
Epoch 6/10, Batch 100/145, Loss: 0.2357
Epoch 6/10, Batch 110/145, Loss: 0.1936
Epoch 6/10, Batch 120/145, Loss: 0.1854
Epoch 6/10, Batch 130/145, Loss: 0.1228
Epoch 6/10, Batch 140/145, Loss: 0.2288
Epoch 6/10, Train Loss: 0.2328, Valid Loss: 0.2195
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3008
Epoch 7/10, Batch 20/145, Loss: 0.1375
Epoch 7/10, Batch 30/145, Loss: 0.1671
Epoch 7/10, Batch 40/145, Loss: 0.5907
Epoch 7/10, Batch 50/145, Loss: 0.1704
Epoch 7/10, Batch 60/145, Loss: 0.3124
Epoch 7/10, Batch 70/145, Loss: 0.1297
Epoch 7/10, Batch 80/145, Loss: 0.1801
Epoch 7/10, Batch 90/145, Loss: 0.2512
Epoch 7/10, Batch 100/145, Loss: 0.1124
Epoch 7/10, Batch 110/145, Loss: 0.1824
Epoch 7/10, Batch 120/145, Loss: 0.1892
Epoch 7/10, Batch 130/145, Loss: 0.2692
Epoch 7/10, Batch 140/145, Loss: 0.2145
Epoch 7/10, Train Loss: 0.2244, Valid Loss: 0.2139
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2703
Epoch 8/10, Batch 20/145, Loss: 0.1231
Epoch 8/10, Batch 30/145, Loss: 0.2714
Epoch 8/10, Batch 40/145, Loss: 0.2192
Epoch 8/10, Batch 50/145, Loss: 0.0604
Epoch 8/10, Batch 60/145, Loss: 0.1597
Epoch 8/10, Batch 70/145, Loss: 0.1016
Epoch 8/10, Batch 80/145, Loss: 0.3066
Epoch 8/10, Batch 90/145, Loss: 0.1543
Epoch 8/10, Batch 100/145, Loss: 0.1481
Epoch 8/10, Batch 110/145, Loss: 0.3266
Epoch 8/10, Batch 120/145, Loss: 0.1513
Epoch 8/10, Batch 130/145, Loss: 0.1834
Epoch 8/10, Batch 140/145, Loss: 0.1977
Epoch 8/10, Train Loss: 0.2186, Valid Loss: 0.2171
Epoch 9/10, Batch 10/145, Loss: 0.1548
Epoch 9/10, Batch 20/145, Loss: 0.1466
Epoch 9/10, Batch 30/145, Loss: 0.1438
Epoch 9/10, Batch 40/145, Loss: 0.1303
Epoch 9/10, Batch 50/145, Loss: 0.1661
Epoch 9/10, Batch 60/145, Loss: 0.2170
Epoch 9/10, Batch 70/145, Loss: 0.2209
Epoch 9/10, Batch 80/145, Loss: 0.2962
Epoch 9/10, Batch 90/145, Loss: 0.1216
Epoch 9/10, Batch 100/145, Loss: 0.2511
Epoch 9/10, Batch 110/145, Loss: 0.1889
Epoch 9/10, Batch 120/145, Loss: 0.2329
Epoch 9/10, Batch 130/145, Loss: 0.0919
Epoch 9/10, Batch 140/145, Loss: 0.0358
Epoch 9/10, Train Loss: 0.2089, Valid Loss: 0.1962
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2173
Epoch 10/10, Batch 20/145, Loss: 0.2827
Epoch 10/10, Batch 30/145, Loss: 0.0931
Epoch 10/10, Batch 40/145, Loss: 0.2082
Epoch 10/10, Batch 50/145, Loss: 0.3214
Epoch 10/10, Batch 60/145, Loss: 0.4032
Epoch 10/10, Batch 70/145, Loss: 0.1133
Epoch 10/10, Batch 80/145, Loss: 0.2555
Epoch 10/10, Batch 90/145, Loss: 0.1964
Epoch 10/10, Batch 100/145, Loss: 0.1954
Epoch 10/10, Batch 110/145, Loss: 0.3273
Epoch 10/10, Batch 120/145, Loss: 0.2157
Epoch 10/10, Batch 130/145, Loss: 0.2137
Epoch 10/10, Batch 140/145, Loss: 0.3312
Epoch 10/10, Train Loss: 0.2047, Valid Loss: 0.2013
Accuracy: 0.9194
Precision: 0.9178
Recall: 0.9194
F1-score: 0.9182
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4571
Epoch 1/10, Batch 20/145, Loss: 0.9219
Epoch 1/10, Batch 30/145, Loss: 0.9654
Epoch 1/10, Batch 40/145, Loss: 0.7754
Epoch 1/10, Batch 50/145, Loss: 0.6090
Epoch 1/10, Batch 60/145, Loss: 0.7532
Epoch 1/10, Batch 70/145, Loss: 0.6093
Epoch 1/10, Batch 80/145, Loss: 0.5265
Epoch 1/10, Batch 90/145, Loss: 0.5258
Epoch 1/10, Batch 100/145, Loss: 0.5619
Epoch 1/10, Batch 110/145, Loss: 0.4124
Epoch 1/10, Batch 120/145, Loss: 0.5515
Epoch 1/10, Batch 130/145, Loss: 0.4388
Epoch 1/10, Batch 140/145, Loss: 0.5494
Epoch 1/10, Train Loss: 0.6880, Valid Loss: 0.3728
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2971
Epoch 2/10, Batch 20/145, Loss: 0.5197
Epoch 2/10, Batch 30/145, Loss: 0.3245
Epoch 2/10, Batch 40/145, Loss: 0.4199
Epoch 2/10, Batch 50/145, Loss: 0.2235
Epoch 2/10, Batch 60/145, Loss: 0.3797
Epoch 2/10, Batch 70/145, Loss: 0.4562
Epoch 2/10, Batch 80/145, Loss: 0.3483
Epoch 2/10, Batch 90/145, Loss: 0.2916
Epoch 2/10, Batch 100/145, Loss: 0.3467
Epoch 2/10, Batch 110/145, Loss: 0.2419
Epoch 2/10, Batch 120/145, Loss: 0.4731
Epoch 2/10, Batch 130/145, Loss: 0.2438
Epoch 2/10, Batch 140/145, Loss: 0.2691
Epoch 2/10, Train Loss: 0.3601, Valid Loss: 0.2929
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1945
Epoch 3/10, Batch 20/145, Loss: 0.2523
Epoch 3/10, Batch 30/145, Loss: 0.1876
Epoch 3/10, Batch 40/145, Loss: 0.3799
Epoch 3/10, Batch 50/145, Loss: 0.2071
Epoch 3/10, Batch 60/145, Loss: 0.2781
Epoch 3/10, Batch 70/145, Loss: 0.2486
Epoch 3/10, Batch 80/145, Loss: 0.1867
Epoch 3/10, Batch 90/145, Loss: 0.2975
Epoch 3/10, Batch 100/145, Loss: 0.2283
Epoch 3/10, Batch 110/145, Loss: 0.1717
Epoch 3/10, Batch 120/145, Loss: 0.1981
Epoch 3/10, Batch 130/145, Loss: 0.3395
Epoch 3/10, Batch 140/145, Loss: 0.1829
Epoch 3/10, Train Loss: 0.3061, Valid Loss: 0.2579
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1725
Epoch 4/10, Batch 20/145, Loss: 0.2972
Epoch 4/10, Batch 30/145, Loss: 0.2491
Epoch 4/10, Batch 40/145, Loss: 0.2155
Epoch 4/10, Batch 50/145, Loss: 0.2235
Epoch 4/10, Batch 60/145, Loss: 0.2275
Epoch 4/10, Batch 70/145, Loss: 0.1257
Epoch 4/10, Batch 80/145, Loss: 0.1776
Epoch 4/10, Batch 90/145, Loss: 0.1689
Epoch 4/10, Batch 100/145, Loss: 0.2427
Epoch 4/10, Batch 110/145, Loss: 0.2969
Epoch 4/10, Batch 120/145, Loss: 0.1593
Epoch 4/10, Batch 130/145, Loss: 0.2016
Epoch 4/10, Batch 140/145, Loss: 0.3552
Epoch 4/10, Train Loss: 0.2618, Valid Loss: 0.2536
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1728
Epoch 5/10, Batch 20/145, Loss: 0.2401
Epoch 5/10, Batch 30/145, Loss: 0.2607
Epoch 5/10, Batch 40/145, Loss: 0.2306
Epoch 5/10, Batch 50/145, Loss: 0.1940
Epoch 5/10, Batch 60/145, Loss: 0.1552
Epoch 5/10, Batch 70/145, Loss: 0.3142
Epoch 5/10, Batch 80/145, Loss: 0.3375
Epoch 5/10, Batch 90/145, Loss: 0.3082
Epoch 5/10, Batch 100/145, Loss: 0.1991
Epoch 5/10, Batch 110/145, Loss: 0.1223
Epoch 5/10, Batch 120/145, Loss: 0.2994
Epoch 5/10, Batch 130/145, Loss: 0.3166
Epoch 5/10, Batch 140/145, Loss: 0.3269
Epoch 5/10, Train Loss: 0.2358, Valid Loss: 0.2401
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2164
Epoch 6/10, Batch 20/145, Loss: 0.2034
Epoch 6/10, Batch 30/145, Loss: 0.2179
Epoch 6/10, Batch 40/145, Loss: 0.1282
Epoch 6/10, Batch 50/145, Loss: 0.1947
Epoch 6/10, Batch 60/145, Loss: 0.1066
Epoch 6/10, Batch 70/145, Loss: 0.2525
Epoch 6/10, Batch 80/145, Loss: 0.2927
Epoch 6/10, Batch 90/145, Loss: 0.1423
Epoch 6/10, Batch 100/145, Loss: 0.1852
Epoch 6/10, Batch 110/145, Loss: 0.1398
Epoch 6/10, Batch 120/145, Loss: 0.1497
Epoch 6/10, Batch 130/145, Loss: 0.1171
Epoch 6/10, Batch 140/145, Loss: 0.2405
Epoch 6/10, Train Loss: 0.2243, Valid Loss: 0.2285
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1620
Epoch 7/10, Batch 20/145, Loss: 0.1882
Epoch 7/10, Batch 30/145, Loss: 0.1600
Epoch 7/10, Batch 40/145, Loss: 0.4962
Epoch 7/10, Batch 50/145, Loss: 0.2277
Epoch 7/10, Batch 60/145, Loss: 0.1213
Epoch 7/10, Batch 70/145, Loss: 0.1361
Epoch 7/10, Batch 80/145, Loss: 0.1670
Epoch 7/10, Batch 90/145, Loss: 0.3473
Epoch 7/10, Batch 100/145, Loss: 0.2850
Epoch 7/10, Batch 110/145, Loss: 0.3681
Epoch 7/10, Batch 120/145, Loss: 0.2088
Epoch 7/10, Batch 130/145, Loss: 0.2126
Epoch 7/10, Batch 140/145, Loss: 0.1160
Epoch 7/10, Train Loss: 0.2202, Valid Loss: 0.2234
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0623
Epoch 8/10, Batch 20/145, Loss: 0.2856
Epoch 8/10, Batch 30/145, Loss: 0.2745
Epoch 8/10, Batch 40/145, Loss: 0.1772
Epoch 8/10, Batch 50/145, Loss: 0.1842
Epoch 8/10, Batch 60/145, Loss: 0.2429
Epoch 8/10, Batch 70/145, Loss: 0.1149
Epoch 8/10, Batch 80/145, Loss: 0.2776
Epoch 8/10, Batch 90/145, Loss: 0.1449
Epoch 8/10, Batch 100/145, Loss: 0.2467
Epoch 8/10, Batch 110/145, Loss: 0.3982
Epoch 8/10, Batch 120/145, Loss: 0.1422
Epoch 8/10, Batch 130/145, Loss: 0.0907
Epoch 8/10, Batch 140/145, Loss: 0.2217
Epoch 8/10, Train Loss: 0.2120, Valid Loss: 0.2195
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2487
Epoch 9/10, Batch 20/145, Loss: 0.2226
Epoch 9/10, Batch 30/145, Loss: 0.1723
Epoch 9/10, Batch 40/145, Loss: 0.2695
Epoch 9/10, Batch 50/145, Loss: 0.2352
Epoch 9/10, Batch 60/145, Loss: 0.0985
Epoch 9/10, Batch 70/145, Loss: 0.1781
Epoch 9/10, Batch 80/145, Loss: 0.1724
Epoch 9/10, Batch 90/145, Loss: 0.1194
Epoch 9/10, Batch 100/145, Loss: 0.1985
Epoch 9/10, Batch 110/145, Loss: 0.1140
Epoch 9/10, Batch 120/145, Loss: 0.1420
Epoch 9/10, Batch 130/145, Loss: 0.1743
Epoch 9/10, Batch 140/145, Loss: 0.2807
Epoch 9/10, Train Loss: 0.2057, Valid Loss: 0.2132
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1414
Epoch 10/10, Batch 20/145, Loss: 0.1740
Epoch 10/10, Batch 30/145, Loss: 0.1997
Epoch 10/10, Batch 40/145, Loss: 0.4291
Epoch 10/10, Batch 50/145, Loss: 0.1829
Epoch 10/10, Batch 60/145, Loss: 0.2159
Epoch 10/10, Batch 70/145, Loss: 0.1688
Epoch 10/10, Batch 80/145, Loss: 0.2657
Epoch 10/10, Batch 90/145, Loss: 0.1472
Epoch 10/10, Batch 100/145, Loss: 0.0931
Epoch 10/10, Batch 110/145, Loss: 0.2602
Epoch 10/10, Batch 120/145, Loss: 0.1897
Epoch 10/10, Batch 130/145, Loss: 0.1501
Epoch 10/10, Batch 140/145, Loss: 0.1358
Epoch 10/10, Train Loss: 0.1918, Valid Loss: 0.2138
Accuracy: 0.9147
Precision: 0.9127
Recall: 0.9147
F1-score: 0.9129
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5075
Epoch 1/10, Batch 20/145, Loss: 0.9374
Epoch 1/10, Batch 30/145, Loss: 0.9499
Epoch 1/10, Batch 40/145, Loss: 0.8943
Epoch 1/10, Batch 50/145, Loss: 0.6066
Epoch 1/10, Batch 60/145, Loss: 0.5380
Epoch 1/10, Batch 70/145, Loss: 0.6524
Epoch 1/10, Batch 80/145, Loss: 0.4580
Epoch 1/10, Batch 90/145, Loss: 0.5575
Epoch 1/10, Batch 100/145, Loss: 0.4941
Epoch 1/10, Batch 110/145, Loss: 0.3982
Epoch 1/10, Batch 120/145, Loss: 0.5673
Epoch 1/10, Batch 130/145, Loss: 0.4038
Epoch 1/10, Batch 140/145, Loss: 0.3688
Epoch 1/10, Train Loss: 0.7006, Valid Loss: 0.3511
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4089
Epoch 2/10, Batch 20/145, Loss: 0.4533
Epoch 2/10, Batch 30/145, Loss: 0.2558
Epoch 2/10, Batch 40/145, Loss: 0.5399
Epoch 2/10, Batch 50/145, Loss: 0.3125
Epoch 2/10, Batch 60/145, Loss: 0.5169
Epoch 2/10, Batch 70/145, Loss: 0.4383
Epoch 2/10, Batch 80/145, Loss: 0.2917
Epoch 2/10, Batch 90/145, Loss: 0.2369
Epoch 2/10, Batch 100/145, Loss: 0.2729
Epoch 2/10, Batch 110/145, Loss: 0.3592
Epoch 2/10, Batch 120/145, Loss: 0.4658
Epoch 2/10, Batch 130/145, Loss: 0.5129
Epoch 2/10, Batch 140/145, Loss: 0.3389
Epoch 2/10, Train Loss: 0.3727, Valid Loss: 0.2616
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1819
Epoch 3/10, Batch 20/145, Loss: 0.2705
Epoch 3/10, Batch 30/145, Loss: 0.2629
Epoch 3/10, Batch 40/145, Loss: 0.2563
Epoch 3/10, Batch 50/145, Loss: 0.2305
Epoch 3/10, Batch 60/145, Loss: 0.2938
Epoch 3/10, Batch 70/145, Loss: 0.2215
Epoch 3/10, Batch 80/145, Loss: 0.2511
Epoch 3/10, Batch 90/145, Loss: 0.5780
Epoch 3/10, Batch 100/145, Loss: 0.3860
Epoch 3/10, Batch 110/145, Loss: 0.1683
Epoch 3/10, Batch 120/145, Loss: 0.1748
Epoch 3/10, Batch 130/145, Loss: 0.1539
Epoch 3/10, Batch 140/145, Loss: 0.1344
Epoch 3/10, Train Loss: 0.3171, Valid Loss: 0.2359
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1773
Epoch 4/10, Batch 20/145, Loss: 0.2796
Epoch 4/10, Batch 30/145, Loss: 0.1713
Epoch 4/10, Batch 40/145, Loss: 0.4457
Epoch 4/10, Batch 50/145, Loss: 0.2273
Epoch 4/10, Batch 60/145, Loss: 0.1551
Epoch 4/10, Batch 70/145, Loss: 0.3910
Epoch 4/10, Batch 80/145, Loss: 0.2046
Epoch 4/10, Batch 90/145, Loss: 0.3795
Epoch 4/10, Batch 100/145, Loss: 0.2745
Epoch 4/10, Batch 110/145, Loss: 0.2445
Epoch 4/10, Batch 120/145, Loss: 0.1700
Epoch 4/10, Batch 130/145, Loss: 0.3566
Epoch 4/10, Batch 140/145, Loss: 0.3225
Epoch 4/10, Train Loss: 0.2733, Valid Loss: 0.2252
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3671
Epoch 5/10, Batch 20/145, Loss: 0.1905
Epoch 5/10, Batch 30/145, Loss: 0.2005
Epoch 5/10, Batch 40/145, Loss: 0.3109
Epoch 5/10, Batch 50/145, Loss: 0.2444
Epoch 5/10, Batch 60/145, Loss: 0.1790
Epoch 5/10, Batch 70/145, Loss: 0.3034
Epoch 5/10, Batch 80/145, Loss: 0.2014
Epoch 5/10, Batch 90/145, Loss: 0.2032
Epoch 5/10, Batch 100/145, Loss: 0.2692
Epoch 5/10, Batch 110/145, Loss: 0.0708
Epoch 5/10, Batch 120/145, Loss: 0.2963
Epoch 5/10, Batch 130/145, Loss: 0.1727
Epoch 5/10, Batch 140/145, Loss: 0.2873
Epoch 5/10, Train Loss: 0.2470, Valid Loss: 0.2043
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1378
Epoch 6/10, Batch 20/145, Loss: 0.2450
Epoch 6/10, Batch 30/145, Loss: 0.1705
Epoch 6/10, Batch 40/145, Loss: 0.1318
Epoch 6/10, Batch 50/145, Loss: 0.2974
Epoch 6/10, Batch 60/145, Loss: 0.2044
Epoch 6/10, Batch 70/145, Loss: 0.2529
Epoch 6/10, Batch 80/145, Loss: 0.2808
Epoch 6/10, Batch 90/145, Loss: 0.2210
Epoch 6/10, Batch 100/145, Loss: 0.2925
Epoch 6/10, Batch 110/145, Loss: 0.2007
Epoch 6/10, Batch 120/145, Loss: 0.3625
Epoch 6/10, Batch 130/145, Loss: 0.0869
Epoch 6/10, Batch 140/145, Loss: 0.0995
Epoch 6/10, Train Loss: 0.2327, Valid Loss: 0.2022
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2779
Epoch 7/10, Batch 20/145, Loss: 0.2476
Epoch 7/10, Batch 30/145, Loss: 0.1303
Epoch 7/10, Batch 40/145, Loss: 0.4202
Epoch 7/10, Batch 50/145, Loss: 0.1394
Epoch 7/10, Batch 60/145, Loss: 0.1720
Epoch 7/10, Batch 70/145, Loss: 0.2467
Epoch 7/10, Batch 80/145, Loss: 0.1574
Epoch 7/10, Batch 90/145, Loss: 0.1839
Epoch 7/10, Batch 100/145, Loss: 0.0978
Epoch 7/10, Batch 110/145, Loss: 0.4078
Epoch 7/10, Batch 120/145, Loss: 0.1495
Epoch 7/10, Batch 130/145, Loss: 0.3062
Epoch 7/10, Batch 140/145, Loss: 0.2125
Epoch 7/10, Train Loss: 0.2305, Valid Loss: 0.1950
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2356
Epoch 8/10, Batch 20/145, Loss: 0.0848
Epoch 8/10, Batch 30/145, Loss: 0.3390
Epoch 8/10, Batch 40/145, Loss: 0.1538
Epoch 8/10, Batch 50/145, Loss: 0.2172
Epoch 8/10, Batch 60/145, Loss: 0.2160
Epoch 8/10, Batch 70/145, Loss: 0.1328
Epoch 8/10, Batch 80/145, Loss: 0.2455
Epoch 8/10, Batch 90/145, Loss: 0.1663
Epoch 8/10, Batch 100/145, Loss: 0.2966
Epoch 8/10, Batch 110/145, Loss: 0.2684
Epoch 8/10, Batch 120/145, Loss: 0.2186
Epoch 8/10, Batch 130/145, Loss: 0.1233
Epoch 8/10, Batch 140/145, Loss: 0.4773
Epoch 8/10, Train Loss: 0.2206, Valid Loss: 0.1931
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2004
Epoch 9/10, Batch 20/145, Loss: 0.0924
Epoch 9/10, Batch 30/145, Loss: 0.0635
Epoch 9/10, Batch 40/145, Loss: 0.1558
Epoch 9/10, Batch 50/145, Loss: 0.1950
Epoch 9/10, Batch 60/145, Loss: 0.2672
Epoch 9/10, Batch 70/145, Loss: 0.1753
Epoch 9/10, Batch 80/145, Loss: 0.2302
Epoch 9/10, Batch 90/145, Loss: 0.0726
Epoch 9/10, Batch 100/145, Loss: 0.2905
Epoch 9/10, Batch 110/145, Loss: 0.2431
Epoch 9/10, Batch 120/145, Loss: 0.2539
Epoch 9/10, Batch 130/145, Loss: 0.1771
Epoch 9/10, Batch 140/145, Loss: 0.0783
Epoch 9/10, Train Loss: 0.2146, Valid Loss: 0.1825
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1042
Epoch 10/10, Batch 20/145, Loss: 0.2524
Epoch 10/10, Batch 30/145, Loss: 0.1574
Epoch 10/10, Batch 40/145, Loss: 0.3079
Epoch 10/10, Batch 50/145, Loss: 0.1790
Epoch 10/10, Batch 60/145, Loss: 0.1805
Epoch 10/10, Batch 70/145, Loss: 0.2030
Epoch 10/10, Batch 80/145, Loss: 0.4942
Epoch 10/10, Batch 90/145, Loss: 0.1428
Epoch 10/10, Batch 100/145, Loss: 0.1400
Epoch 10/10, Batch 110/145, Loss: 0.2605
Epoch 10/10, Batch 120/145, Loss: 0.1245
Epoch 10/10, Batch 130/145, Loss: 0.3030
Epoch 10/10, Batch 140/145, Loss: 0.1853
Epoch 10/10, Train Loss: 0.2002, Valid Loss: 0.1805
Model saved!
Accuracy: 0.9241
Precision: 0.9228
Recall: 0.9241
F1-score: 0.9234
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4551
Epoch 1/10, Batch 20/145, Loss: 0.8649
Epoch 1/10, Batch 30/145, Loss: 0.8374
Epoch 1/10, Batch 40/145, Loss: 0.7117
Epoch 1/10, Batch 50/145, Loss: 0.6538
Epoch 1/10, Batch 60/145, Loss: 0.6197
Epoch 1/10, Batch 70/145, Loss: 0.7185
Epoch 1/10, Batch 80/145, Loss: 0.4724
Epoch 1/10, Batch 90/145, Loss: 0.4856
Epoch 1/10, Batch 100/145, Loss: 0.7155
Epoch 1/10, Batch 110/145, Loss: 0.3782
Epoch 1/10, Batch 120/145, Loss: 0.5532
Epoch 1/10, Batch 130/145, Loss: 0.3105
Epoch 1/10, Batch 140/145, Loss: 0.3520
Epoch 1/10, Train Loss: 0.6936, Valid Loss: 0.3691
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3549
Epoch 2/10, Batch 20/145, Loss: 0.4243
Epoch 2/10, Batch 30/145, Loss: 0.4814
Epoch 2/10, Batch 40/145, Loss: 0.4254
Epoch 2/10, Batch 50/145, Loss: 0.2518
Epoch 2/10, Batch 60/145, Loss: 0.4432
Epoch 2/10, Batch 70/145, Loss: 0.4364
Epoch 2/10, Batch 80/145, Loss: 0.2936
Epoch 2/10, Batch 90/145, Loss: 0.4087
Epoch 2/10, Batch 100/145, Loss: 0.4099
Epoch 2/10, Batch 110/145, Loss: 0.3038
Epoch 2/10, Batch 120/145, Loss: 0.3344
Epoch 2/10, Batch 130/145, Loss: 0.4599
Epoch 2/10, Batch 140/145, Loss: 0.3923
Epoch 2/10, Train Loss: 0.3687, Valid Loss: 0.2875
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2816
Epoch 3/10, Batch 20/145, Loss: 0.2905
Epoch 3/10, Batch 30/145, Loss: 0.3360
Epoch 3/10, Batch 40/145, Loss: 0.3202
Epoch 3/10, Batch 50/145, Loss: 0.2768
Epoch 3/10, Batch 60/145, Loss: 0.4062
Epoch 3/10, Batch 70/145, Loss: 0.1499
Epoch 3/10, Batch 80/145, Loss: 0.3800
Epoch 3/10, Batch 90/145, Loss: 0.4343
Epoch 3/10, Batch 100/145, Loss: 0.2242
Epoch 3/10, Batch 110/145, Loss: 0.2110
Epoch 3/10, Batch 120/145, Loss: 0.1482
Epoch 3/10, Batch 130/145, Loss: 0.3249
Epoch 3/10, Batch 140/145, Loss: 0.1606
Epoch 3/10, Train Loss: 0.3130, Valid Loss: 0.2519
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3351
Epoch 4/10, Batch 20/145, Loss: 0.2822
Epoch 4/10, Batch 30/145, Loss: 0.2215
Epoch 4/10, Batch 40/145, Loss: 0.3091
Epoch 4/10, Batch 50/145, Loss: 0.3400
Epoch 4/10, Batch 60/145, Loss: 0.2681
Epoch 4/10, Batch 70/145, Loss: 0.2584
Epoch 4/10, Batch 80/145, Loss: 0.1883
Epoch 4/10, Batch 90/145, Loss: 0.2209
Epoch 4/10, Batch 100/145, Loss: 0.2069
Epoch 4/10, Batch 110/145, Loss: 0.2699
Epoch 4/10, Batch 120/145, Loss: 0.2398
Epoch 4/10, Batch 130/145, Loss: 0.1778
Epoch 4/10, Batch 140/145, Loss: 0.1405
Epoch 4/10, Train Loss: 0.2698, Valid Loss: 0.2487
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2665
Epoch 5/10, Batch 20/145, Loss: 0.2382
Epoch 5/10, Batch 30/145, Loss: 0.2208
Epoch 5/10, Batch 40/145, Loss: 0.2316
Epoch 5/10, Batch 50/145, Loss: 0.1957
Epoch 5/10, Batch 60/145, Loss: 0.2711
Epoch 5/10, Batch 70/145, Loss: 0.3129
Epoch 5/10, Batch 80/145, Loss: 0.3777
Epoch 5/10, Batch 90/145, Loss: 0.2674
Epoch 5/10, Batch 100/145, Loss: 0.2770
Epoch 5/10, Batch 110/145, Loss: 0.1200
Epoch 5/10, Batch 120/145, Loss: 0.4518
Epoch 5/10, Batch 130/145, Loss: 0.3071
Epoch 5/10, Batch 140/145, Loss: 0.2498
Epoch 5/10, Train Loss: 0.2475, Valid Loss: 0.2425
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2331
Epoch 6/10, Batch 20/145, Loss: 0.2510
Epoch 6/10, Batch 30/145, Loss: 0.2462
Epoch 6/10, Batch 40/145, Loss: 0.2741
Epoch 6/10, Batch 50/145, Loss: 0.2699
Epoch 6/10, Batch 60/145, Loss: 0.2353
Epoch 6/10, Batch 70/145, Loss: 0.3983
Epoch 6/10, Batch 80/145, Loss: 0.1926
Epoch 6/10, Batch 90/145, Loss: 0.2584
Epoch 6/10, Batch 100/145, Loss: 0.2118
Epoch 6/10, Batch 110/145, Loss: 0.1476
Epoch 6/10, Batch 120/145, Loss: 0.2792
Epoch 6/10, Batch 130/145, Loss: 0.1080
Epoch 6/10, Batch 140/145, Loss: 0.3664
Epoch 6/10, Train Loss: 0.2370, Valid Loss: 0.2306
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2907
Epoch 7/10, Batch 20/145, Loss: 0.2571
Epoch 7/10, Batch 30/145, Loss: 0.2044
Epoch 7/10, Batch 40/145, Loss: 0.6282
Epoch 7/10, Batch 50/145, Loss: 0.1286
Epoch 7/10, Batch 60/145, Loss: 0.1039
Epoch 7/10, Batch 70/145, Loss: 0.4844
Epoch 7/10, Batch 80/145, Loss: 0.0887
Epoch 7/10, Batch 90/145, Loss: 0.1592
Epoch 7/10, Batch 100/145, Loss: 0.2449
Epoch 7/10, Batch 110/145, Loss: 0.2383
Epoch 7/10, Batch 120/145, Loss: 0.2154
Epoch 7/10, Batch 130/145, Loss: 0.1257
Epoch 7/10, Batch 140/145, Loss: 0.1231
Epoch 7/10, Train Loss: 0.2295, Valid Loss: 0.2108
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1680
Epoch 8/10, Batch 20/145, Loss: 0.2337
Epoch 8/10, Batch 30/145, Loss: 0.1753
Epoch 8/10, Batch 40/145, Loss: 0.2833
Epoch 8/10, Batch 50/145, Loss: 0.3825
Epoch 8/10, Batch 60/145, Loss: 0.1471
Epoch 8/10, Batch 70/145, Loss: 0.2786
Epoch 8/10, Batch 80/145, Loss: 0.3782
Epoch 8/10, Batch 90/145, Loss: 0.1655
Epoch 8/10, Batch 100/145, Loss: 0.4139
Epoch 8/10, Batch 110/145, Loss: 0.2943
Epoch 8/10, Batch 120/145, Loss: 0.1495
Epoch 8/10, Batch 130/145, Loss: 0.1163
Epoch 8/10, Batch 140/145, Loss: 0.2584
Epoch 8/10, Train Loss: 0.2180, Valid Loss: 0.2091
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1576
Epoch 9/10, Batch 20/145, Loss: 0.0853
Epoch 9/10, Batch 30/145, Loss: 0.1047
Epoch 9/10, Batch 40/145, Loss: 0.1315
Epoch 9/10, Batch 50/145, Loss: 0.2412
Epoch 9/10, Batch 60/145, Loss: 0.1801
Epoch 9/10, Batch 70/145, Loss: 0.1538
Epoch 9/10, Batch 80/145, Loss: 0.1837
Epoch 9/10, Batch 90/145, Loss: 0.1273
Epoch 9/10, Batch 100/145, Loss: 0.3027
Epoch 9/10, Batch 110/145, Loss: 0.2231
Epoch 9/10, Batch 120/145, Loss: 0.2548
Epoch 9/10, Batch 130/145, Loss: 0.1082
Epoch 9/10, Batch 140/145, Loss: 0.0699
Epoch 9/10, Train Loss: 0.2112, Valid Loss: 0.2042
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1082
Epoch 10/10, Batch 20/145, Loss: 0.1647
Epoch 10/10, Batch 30/145, Loss: 0.1032
Epoch 10/10, Batch 40/145, Loss: 0.1388
Epoch 10/10, Batch 50/145, Loss: 0.1635
Epoch 10/10, Batch 60/145, Loss: 0.1764
Epoch 10/10, Batch 70/145, Loss: 0.2697
Epoch 10/10, Batch 80/145, Loss: 0.3171
Epoch 10/10, Batch 90/145, Loss: 0.2135
Epoch 10/10, Batch 100/145, Loss: 0.0517
Epoch 10/10, Batch 110/145, Loss: 0.3945
Epoch 10/10, Batch 120/145, Loss: 0.1503
Epoch 10/10, Batch 130/145, Loss: 0.1785
Epoch 10/10, Batch 140/145, Loss: 0.1989
Epoch 10/10, Train Loss: 0.2007, Valid Loss: 0.1923
Model saved!
Accuracy: 0.9229
Precision: 0.9218
Recall: 0.9229
F1-score: 0.9221
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4369
Epoch 1/10, Batch 20/145, Loss: 0.8897
Epoch 1/10, Batch 30/145, Loss: 0.7994
Epoch 1/10, Batch 40/145, Loss: 0.9224
Epoch 1/10, Batch 50/145, Loss: 0.5579
Epoch 1/10, Batch 60/145, Loss: 0.5743
Epoch 1/10, Batch 70/145, Loss: 0.6724
Epoch 1/10, Batch 80/145, Loss: 0.6172
Epoch 1/10, Batch 90/145, Loss: 0.5461
Epoch 1/10, Batch 100/145, Loss: 0.5558
Epoch 1/10, Batch 110/145, Loss: 0.3236
Epoch 1/10, Batch 120/145, Loss: 0.5279
Epoch 1/10, Batch 130/145, Loss: 0.4053
Epoch 1/10, Batch 140/145, Loss: 0.3228
Epoch 1/10, Train Loss: 0.6879, Valid Loss: 0.3795
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3382
Epoch 2/10, Batch 20/145, Loss: 0.6221
Epoch 2/10, Batch 30/145, Loss: 0.3713
Epoch 2/10, Batch 40/145, Loss: 0.4462
Epoch 2/10, Batch 50/145, Loss: 0.3198
Epoch 2/10, Batch 60/145, Loss: 0.3795
Epoch 2/10, Batch 70/145, Loss: 0.3537
Epoch 2/10, Batch 80/145, Loss: 0.3510
Epoch 2/10, Batch 90/145, Loss: 0.2804
Epoch 2/10, Batch 100/145, Loss: 0.3308
Epoch 2/10, Batch 110/145, Loss: 0.4766
Epoch 2/10, Batch 120/145, Loss: 0.3827
Epoch 2/10, Batch 130/145, Loss: 0.3737
Epoch 2/10, Batch 140/145, Loss: 0.3325
Epoch 2/10, Train Loss: 0.3617, Valid Loss: 0.2839
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2077
Epoch 3/10, Batch 20/145, Loss: 0.2418
Epoch 3/10, Batch 30/145, Loss: 0.3264
Epoch 3/10, Batch 40/145, Loss: 0.2135
Epoch 3/10, Batch 50/145, Loss: 0.2558
Epoch 3/10, Batch 60/145, Loss: 0.2513
Epoch 3/10, Batch 70/145, Loss: 0.3312
Epoch 3/10, Batch 80/145, Loss: 0.3533
Epoch 3/10, Batch 90/145, Loss: 0.5892
Epoch 3/10, Batch 100/145, Loss: 0.3768
Epoch 3/10, Batch 110/145, Loss: 0.1650
Epoch 3/10, Batch 120/145, Loss: 0.3288
Epoch 3/10, Batch 130/145, Loss: 0.2118
Epoch 3/10, Batch 140/145, Loss: 0.1607
Epoch 3/10, Train Loss: 0.3018, Valid Loss: 0.2489
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2086
Epoch 4/10, Batch 20/145, Loss: 0.2256
Epoch 4/10, Batch 30/145, Loss: 0.2463
Epoch 4/10, Batch 40/145, Loss: 0.2104
Epoch 4/10, Batch 50/145, Loss: 0.1426
Epoch 4/10, Batch 60/145, Loss: 0.2365
Epoch 4/10, Batch 70/145, Loss: 0.2389
Epoch 4/10, Batch 80/145, Loss: 0.4150
Epoch 4/10, Batch 90/145, Loss: 0.2452
Epoch 4/10, Batch 100/145, Loss: 0.2254
Epoch 4/10, Batch 110/145, Loss: 0.1843
Epoch 4/10, Batch 120/145, Loss: 0.2600
Epoch 4/10, Batch 130/145, Loss: 0.2244
Epoch 4/10, Batch 140/145, Loss: 0.2518
Epoch 4/10, Train Loss: 0.2643, Valid Loss: 0.2414
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2745
Epoch 5/10, Batch 20/145, Loss: 0.2098
Epoch 5/10, Batch 30/145, Loss: 0.1675
Epoch 5/10, Batch 40/145, Loss: 0.1924
Epoch 5/10, Batch 50/145, Loss: 0.1719
Epoch 5/10, Batch 60/145, Loss: 0.1462
Epoch 5/10, Batch 70/145, Loss: 0.3544
Epoch 5/10, Batch 80/145, Loss: 0.2310
Epoch 5/10, Batch 90/145, Loss: 0.2619
Epoch 5/10, Batch 100/145, Loss: 0.1626
Epoch 5/10, Batch 110/145, Loss: 0.2008
Epoch 5/10, Batch 120/145, Loss: 0.3414
Epoch 5/10, Batch 130/145, Loss: 0.1422
Epoch 5/10, Batch 140/145, Loss: 0.3764
Epoch 5/10, Train Loss: 0.2390, Valid Loss: 0.2248
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2642
Epoch 6/10, Batch 20/145, Loss: 0.1871
Epoch 6/10, Batch 30/145, Loss: 0.2182
Epoch 6/10, Batch 40/145, Loss: 0.1503
Epoch 6/10, Batch 50/145, Loss: 0.2936
Epoch 6/10, Batch 60/145, Loss: 0.2653
Epoch 6/10, Batch 70/145, Loss: 0.2804
Epoch 6/10, Batch 80/145, Loss: 0.2104
Epoch 6/10, Batch 90/145, Loss: 0.2414
Epoch 6/10, Batch 100/145, Loss: 0.1926
Epoch 6/10, Batch 110/145, Loss: 0.1392
Epoch 6/10, Batch 120/145, Loss: 0.3110
Epoch 6/10, Batch 130/145, Loss: 0.1481
Epoch 6/10, Batch 140/145, Loss: 0.2635
Epoch 6/10, Train Loss: 0.2277, Valid Loss: 0.2332
Epoch 7/10, Batch 10/145, Loss: 0.3163
Epoch 7/10, Batch 20/145, Loss: 0.1812
Epoch 7/10, Batch 30/145, Loss: 0.1145
Epoch 7/10, Batch 40/145, Loss: 0.3245
Epoch 7/10, Batch 50/145, Loss: 0.3522
Epoch 7/10, Batch 60/145, Loss: 0.1139
Epoch 7/10, Batch 70/145, Loss: 0.4384
Epoch 7/10, Batch 80/145, Loss: 0.2400
Epoch 7/10, Batch 90/145, Loss: 0.2562
Epoch 7/10, Batch 100/145, Loss: 0.1162
Epoch 7/10, Batch 110/145, Loss: 0.3507
Epoch 7/10, Batch 120/145, Loss: 0.1549
Epoch 7/10, Batch 130/145, Loss: 0.2168
Epoch 7/10, Batch 140/145, Loss: 0.0828
Epoch 7/10, Train Loss: 0.2157, Valid Loss: 0.2156
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2196
Epoch 8/10, Batch 20/145, Loss: 0.1709
Epoch 8/10, Batch 30/145, Loss: 0.1190
Epoch 8/10, Batch 40/145, Loss: 0.1618
Epoch 8/10, Batch 50/145, Loss: 0.3152
Epoch 8/10, Batch 60/145, Loss: 0.1827
Epoch 8/10, Batch 70/145, Loss: 0.0731
Epoch 8/10, Batch 80/145, Loss: 0.1725
Epoch 8/10, Batch 90/145, Loss: 0.1272
Epoch 8/10, Batch 100/145, Loss: 0.1472
Epoch 8/10, Batch 110/145, Loss: 0.2528
Epoch 8/10, Batch 120/145, Loss: 0.2406
Epoch 8/10, Batch 130/145, Loss: 0.2648
Epoch 8/10, Batch 140/145, Loss: 0.2029
Epoch 8/10, Train Loss: 0.2161, Valid Loss: 0.2185
Epoch 9/10, Batch 10/145, Loss: 0.1712
Epoch 9/10, Batch 20/145, Loss: 0.1834
Epoch 9/10, Batch 30/145, Loss: 0.1279
Epoch 9/10, Batch 40/145, Loss: 0.1553
Epoch 9/10, Batch 50/145, Loss: 0.1296
Epoch 9/10, Batch 60/145, Loss: 0.2576
Epoch 9/10, Batch 70/145, Loss: 0.2217
Epoch 9/10, Batch 80/145, Loss: 0.1932
Epoch 9/10, Batch 90/145, Loss: 0.1017
Epoch 9/10, Batch 100/145, Loss: 0.2128
Epoch 9/10, Batch 110/145, Loss: 0.2212
Epoch 9/10, Batch 120/145, Loss: 0.3319
Epoch 9/10, Batch 130/145, Loss: 0.1072
Epoch 9/10, Batch 140/145, Loss: 0.0801
Epoch 9/10, Train Loss: 0.2065, Valid Loss: 0.2040
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1131
Epoch 10/10, Batch 20/145, Loss: 0.1457
Epoch 10/10, Batch 30/145, Loss: 0.1060
Epoch 10/10, Batch 40/145, Loss: 0.1465
Epoch 10/10, Batch 50/145, Loss: 0.2868
Epoch 10/10, Batch 60/145, Loss: 0.1226
Epoch 10/10, Batch 70/145, Loss: 0.1099
Epoch 10/10, Batch 80/145, Loss: 0.4130
Epoch 10/10, Batch 90/145, Loss: 0.2337
Epoch 10/10, Batch 100/145, Loss: 0.1996
Epoch 10/10, Batch 110/145, Loss: 0.1918
Epoch 10/10, Batch 120/145, Loss: 0.1995
Epoch 10/10, Batch 130/145, Loss: 0.2389
Epoch 10/10, Batch 140/145, Loss: 0.1729
Epoch 10/10, Train Loss: 0.1975, Valid Loss: 0.2002
Model saved!
Accuracy: 0.9217
Precision: 0.9202
Recall: 0.9217
F1-score: 0.9209
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5408
Epoch 1/10, Batch 20/145, Loss: 0.8677
Epoch 1/10, Batch 30/145, Loss: 0.8331
Epoch 1/10, Batch 40/145, Loss: 0.9129
Epoch 1/10, Batch 50/145, Loss: 0.5580
Epoch 1/10, Batch 60/145, Loss: 0.5704
Epoch 1/10, Batch 70/145, Loss: 0.6397
Epoch 1/10, Batch 80/145, Loss: 0.5041
Epoch 1/10, Batch 90/145, Loss: 0.5673
Epoch 1/10, Batch 100/145, Loss: 0.5986
Epoch 1/10, Batch 110/145, Loss: 0.4188
Epoch 1/10, Batch 120/145, Loss: 0.6142
Epoch 1/10, Batch 130/145, Loss: 0.4380
Epoch 1/10, Batch 140/145, Loss: 0.4454
Epoch 1/10, Train Loss: 0.6857, Valid Loss: 0.3821
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2889
Epoch 2/10, Batch 20/145, Loss: 0.4769
Epoch 2/10, Batch 30/145, Loss: 0.2734
Epoch 2/10, Batch 40/145, Loss: 0.5048
Epoch 2/10, Batch 50/145, Loss: 0.3798
Epoch 2/10, Batch 60/145, Loss: 0.3568
Epoch 2/10, Batch 70/145, Loss: 0.3572
Epoch 2/10, Batch 80/145, Loss: 0.2108
Epoch 2/10, Batch 90/145, Loss: 0.3297
Epoch 2/10, Batch 100/145, Loss: 0.3600
Epoch 2/10, Batch 110/145, Loss: 0.3456
Epoch 2/10, Batch 120/145, Loss: 0.4759
Epoch 2/10, Batch 130/145, Loss: 0.2526
Epoch 2/10, Batch 140/145, Loss: 0.3525
Epoch 2/10, Train Loss: 0.3518, Valid Loss: 0.2993
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1531
Epoch 3/10, Batch 20/145, Loss: 0.2022
Epoch 3/10, Batch 30/145, Loss: 0.2437
Epoch 3/10, Batch 40/145, Loss: 0.2060
Epoch 3/10, Batch 50/145, Loss: 0.3069
Epoch 3/10, Batch 60/145, Loss: 0.2099
Epoch 3/10, Batch 70/145, Loss: 0.2291
Epoch 3/10, Batch 80/145, Loss: 0.2320
Epoch 3/10, Batch 90/145, Loss: 0.4899
Epoch 3/10, Batch 100/145, Loss: 0.2004
Epoch 3/10, Batch 110/145, Loss: 0.1941
Epoch 3/10, Batch 120/145, Loss: 0.2899
Epoch 3/10, Batch 130/145, Loss: 0.3747
Epoch 3/10, Batch 140/145, Loss: 0.2630
Epoch 3/10, Train Loss: 0.3008, Valid Loss: 0.2625
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2084
Epoch 4/10, Batch 20/145, Loss: 0.3092
Epoch 4/10, Batch 30/145, Loss: 0.2634
Epoch 4/10, Batch 40/145, Loss: 0.3819
Epoch 4/10, Batch 50/145, Loss: 0.4144
Epoch 4/10, Batch 60/145, Loss: 0.1794
Epoch 4/10, Batch 70/145, Loss: 0.2920
Epoch 4/10, Batch 80/145, Loss: 0.2532
Epoch 4/10, Batch 90/145, Loss: 0.2568
Epoch 4/10, Batch 100/145, Loss: 0.1413
Epoch 4/10, Batch 110/145, Loss: 0.2635
Epoch 4/10, Batch 120/145, Loss: 0.2069
Epoch 4/10, Batch 130/145, Loss: 0.1983
Epoch 4/10, Batch 140/145, Loss: 0.1893
Epoch 4/10, Train Loss: 0.2584, Valid Loss: 0.2586
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2428
Epoch 5/10, Batch 20/145, Loss: 0.3115
Epoch 5/10, Batch 30/145, Loss: 0.2517
Epoch 5/10, Batch 40/145, Loss: 0.2996
Epoch 5/10, Batch 50/145, Loss: 0.2289
Epoch 5/10, Batch 60/145, Loss: 0.3258
Epoch 5/10, Batch 70/145, Loss: 0.3482
Epoch 5/10, Batch 80/145, Loss: 0.2316
Epoch 5/10, Batch 90/145, Loss: 0.3367
Epoch 5/10, Batch 100/145, Loss: 0.0883
Epoch 5/10, Batch 110/145, Loss: 0.1389
Epoch 5/10, Batch 120/145, Loss: 0.2208
Epoch 5/10, Batch 130/145, Loss: 0.2016
Epoch 5/10, Batch 140/145, Loss: 0.3111
Epoch 5/10, Train Loss: 0.2347, Valid Loss: 0.2448
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3181
Epoch 6/10, Batch 20/145, Loss: 0.1682
Epoch 6/10, Batch 30/145, Loss: 0.1800
Epoch 6/10, Batch 40/145, Loss: 0.2428
Epoch 6/10, Batch 50/145, Loss: 0.2635
Epoch 6/10, Batch 60/145, Loss: 0.2297
Epoch 6/10, Batch 70/145, Loss: 0.2529
Epoch 6/10, Batch 80/145, Loss: 0.1611
Epoch 6/10, Batch 90/145, Loss: 0.2535
Epoch 6/10, Batch 100/145, Loss: 0.1377
Epoch 6/10, Batch 110/145, Loss: 0.1838
Epoch 6/10, Batch 120/145, Loss: 0.2869
Epoch 6/10, Batch 130/145, Loss: 0.2465
Epoch 6/10, Batch 140/145, Loss: 0.1828
Epoch 6/10, Train Loss: 0.2274, Valid Loss: 0.2394
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.4705
Epoch 7/10, Batch 20/145, Loss: 0.2169
Epoch 7/10, Batch 30/145, Loss: 0.1118
Epoch 7/10, Batch 40/145, Loss: 0.3786
Epoch 7/10, Batch 50/145, Loss: 0.1908
Epoch 7/10, Batch 60/145, Loss: 0.1777
Epoch 7/10, Batch 70/145, Loss: 0.1921
Epoch 7/10, Batch 80/145, Loss: 0.1268
Epoch 7/10, Batch 90/145, Loss: 0.2543
Epoch 7/10, Batch 100/145, Loss: 0.1448
Epoch 7/10, Batch 110/145, Loss: 0.2655
Epoch 7/10, Batch 120/145, Loss: 0.1974
Epoch 7/10, Batch 130/145, Loss: 0.2856
Epoch 7/10, Batch 140/145, Loss: 0.2580
Epoch 7/10, Train Loss: 0.2158, Valid Loss: 0.2307
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0794
Epoch 8/10, Batch 20/145, Loss: 0.1031
Epoch 8/10, Batch 30/145, Loss: 0.1064
Epoch 8/10, Batch 40/145, Loss: 0.2435
Epoch 8/10, Batch 50/145, Loss: 0.2221
Epoch 8/10, Batch 60/145, Loss: 0.1795
Epoch 8/10, Batch 70/145, Loss: 0.1390
Epoch 8/10, Batch 80/145, Loss: 0.2248
Epoch 8/10, Batch 90/145, Loss: 0.0814
Epoch 8/10, Batch 100/145, Loss: 0.3489
Epoch 8/10, Batch 110/145, Loss: 0.2444
Epoch 8/10, Batch 120/145, Loss: 0.1673
Epoch 8/10, Batch 130/145, Loss: 0.0936
Epoch 8/10, Batch 140/145, Loss: 0.2488
Epoch 8/10, Train Loss: 0.2076, Valid Loss: 0.2306
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2784
Epoch 9/10, Batch 20/145, Loss: 0.0766
Epoch 9/10, Batch 30/145, Loss: 0.2121
Epoch 9/10, Batch 40/145, Loss: 0.1425
Epoch 9/10, Batch 50/145, Loss: 0.1394
Epoch 9/10, Batch 60/145, Loss: 0.1412
Epoch 9/10, Batch 70/145, Loss: 0.1526
Epoch 9/10, Batch 80/145, Loss: 0.1812
Epoch 9/10, Batch 90/145, Loss: 0.2604
Epoch 9/10, Batch 100/145, Loss: 0.5469
Epoch 9/10, Batch 110/145, Loss: 0.2441
Epoch 9/10, Batch 120/145, Loss: 0.2671
Epoch 9/10, Batch 130/145, Loss: 0.2486
Epoch 9/10, Batch 140/145, Loss: 0.1636
Epoch 9/10, Train Loss: 0.2019, Valid Loss: 0.2166
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0699
Epoch 10/10, Batch 20/145, Loss: 0.1309
Epoch 10/10, Batch 30/145, Loss: 0.1025
Epoch 10/10, Batch 40/145, Loss: 0.1639
Epoch 10/10, Batch 50/145, Loss: 0.2307
Epoch 10/10, Batch 60/145, Loss: 0.1335
Epoch 10/10, Batch 70/145, Loss: 0.1571
Epoch 10/10, Batch 80/145, Loss: 0.3726
Epoch 10/10, Batch 90/145, Loss: 0.3528
Epoch 10/10, Batch 100/145, Loss: 0.0929
Epoch 10/10, Batch 110/145, Loss: 0.1632
Epoch 10/10, Batch 120/145, Loss: 0.2763
Epoch 10/10, Batch 130/145, Loss: 0.1437
Epoch 10/10, Batch 140/145, Loss: 0.3463
Epoch 10/10, Train Loss: 0.1930, Valid Loss: 0.2084
Model saved!
Accuracy: 0.9276
Precision: 0.9262
Recall: 0.9276
F1-score: 0.9266
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5960
Epoch 1/10, Batch 20/145, Loss: 0.8581
Epoch 1/10, Batch 30/145, Loss: 0.8513
Epoch 1/10, Batch 40/145, Loss: 0.8439
Epoch 1/10, Batch 50/145, Loss: 0.5553
Epoch 1/10, Batch 60/145, Loss: 0.4793
Epoch 1/10, Batch 70/145, Loss: 0.5770
Epoch 1/10, Batch 80/145, Loss: 0.4808
Epoch 1/10, Batch 90/145, Loss: 0.5051
Epoch 1/10, Batch 100/145, Loss: 0.4677
Epoch 1/10, Batch 110/145, Loss: 0.4031
Epoch 1/10, Batch 120/145, Loss: 0.5477
Epoch 1/10, Batch 130/145, Loss: 0.4460
Epoch 1/10, Batch 140/145, Loss: 0.3714
Epoch 1/10, Train Loss: 0.6872, Valid Loss: 0.3932
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2331
Epoch 2/10, Batch 20/145, Loss: 0.4209
Epoch 2/10, Batch 30/145, Loss: 0.2472
Epoch 2/10, Batch 40/145, Loss: 0.4282
Epoch 2/10, Batch 50/145, Loss: 0.2597
Epoch 2/10, Batch 60/145, Loss: 0.3611
Epoch 2/10, Batch 70/145, Loss: 0.3621
Epoch 2/10, Batch 80/145, Loss: 0.3859
Epoch 2/10, Batch 90/145, Loss: 0.3994
Epoch 2/10, Batch 100/145, Loss: 0.3686
Epoch 2/10, Batch 110/145, Loss: 0.3009
Epoch 2/10, Batch 120/145, Loss: 0.5128
Epoch 2/10, Batch 130/145, Loss: 0.4021
Epoch 2/10, Batch 140/145, Loss: 0.3388
Epoch 2/10, Train Loss: 0.3608, Valid Loss: 0.3043
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2182
Epoch 3/10, Batch 20/145, Loss: 0.1653
Epoch 3/10, Batch 30/145, Loss: 0.2321
Epoch 3/10, Batch 40/145, Loss: 0.2961
Epoch 3/10, Batch 50/145, Loss: 0.2688
Epoch 3/10, Batch 60/145, Loss: 0.2350
Epoch 3/10, Batch 70/145, Loss: 0.1540
Epoch 3/10, Batch 80/145, Loss: 0.3110
Epoch 3/10, Batch 90/145, Loss: 0.4539
Epoch 3/10, Batch 100/145, Loss: 0.3632
Epoch 3/10, Batch 110/145, Loss: 0.2839
Epoch 3/10, Batch 120/145, Loss: 0.1719
Epoch 3/10, Batch 130/145, Loss: 0.2418
Epoch 3/10, Batch 140/145, Loss: 0.2382
Epoch 3/10, Train Loss: 0.3040, Valid Loss: 0.2829
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1997
Epoch 4/10, Batch 20/145, Loss: 0.2012
Epoch 4/10, Batch 30/145, Loss: 0.3159
Epoch 4/10, Batch 40/145, Loss: 0.3389
Epoch 4/10, Batch 50/145, Loss: 0.2576
Epoch 4/10, Batch 60/145, Loss: 0.2041
Epoch 4/10, Batch 70/145, Loss: 0.1533
Epoch 4/10, Batch 80/145, Loss: 0.3462
Epoch 4/10, Batch 90/145, Loss: 0.1828
Epoch 4/10, Batch 100/145, Loss: 0.1628
Epoch 4/10, Batch 110/145, Loss: 0.2045
Epoch 4/10, Batch 120/145, Loss: 0.2709
Epoch 4/10, Batch 130/145, Loss: 0.2315
Epoch 4/10, Batch 140/145, Loss: 0.2498
Epoch 4/10, Train Loss: 0.2619, Valid Loss: 0.2763
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2348
Epoch 5/10, Batch 20/145, Loss: 0.2676
Epoch 5/10, Batch 30/145, Loss: 0.2006
Epoch 5/10, Batch 40/145, Loss: 0.2300
Epoch 5/10, Batch 50/145, Loss: 0.1752
Epoch 5/10, Batch 60/145, Loss: 0.2767
Epoch 5/10, Batch 70/145, Loss: 0.2709
Epoch 5/10, Batch 80/145, Loss: 0.4071
Epoch 5/10, Batch 90/145, Loss: 0.1779
Epoch 5/10, Batch 100/145, Loss: 0.1412
Epoch 5/10, Batch 110/145, Loss: 0.0650
Epoch 5/10, Batch 120/145, Loss: 0.1744
Epoch 5/10, Batch 130/145, Loss: 0.2028
Epoch 5/10, Batch 140/145, Loss: 0.3451
Epoch 5/10, Train Loss: 0.2389, Valid Loss: 0.2585
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2436
Epoch 6/10, Batch 20/145, Loss: 0.2487
Epoch 6/10, Batch 30/145, Loss: 0.2192
Epoch 6/10, Batch 40/145, Loss: 0.1183
Epoch 6/10, Batch 50/145, Loss: 0.3410
Epoch 6/10, Batch 60/145, Loss: 0.1188
Epoch 6/10, Batch 70/145, Loss: 0.2351
Epoch 6/10, Batch 80/145, Loss: 0.3137
Epoch 6/10, Batch 90/145, Loss: 0.1502
Epoch 6/10, Batch 100/145, Loss: 0.1488
Epoch 6/10, Batch 110/145, Loss: 0.1235
Epoch 6/10, Batch 120/145, Loss: 0.2889
Epoch 6/10, Batch 130/145, Loss: 0.1789
Epoch 6/10, Batch 140/145, Loss: 0.1764
Epoch 6/10, Train Loss: 0.2250, Valid Loss: 0.2622
Epoch 7/10, Batch 10/145, Loss: 0.3261
Epoch 7/10, Batch 20/145, Loss: 0.1508
Epoch 7/10, Batch 30/145, Loss: 0.1162
Epoch 7/10, Batch 40/145, Loss: 0.4939
Epoch 7/10, Batch 50/145, Loss: 0.1562
Epoch 7/10, Batch 60/145, Loss: 0.1038
Epoch 7/10, Batch 70/145, Loss: 0.2555
Epoch 7/10, Batch 80/145, Loss: 0.2102
Epoch 7/10, Batch 90/145, Loss: 0.2984
Epoch 7/10, Batch 100/145, Loss: 0.3281
Epoch 7/10, Batch 110/145, Loss: 0.2649
Epoch 7/10, Batch 120/145, Loss: 0.1849
Epoch 7/10, Batch 130/145, Loss: 0.2517
Epoch 7/10, Batch 140/145, Loss: 0.0907
Epoch 7/10, Train Loss: 0.2177, Valid Loss: 0.2573
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0836
Epoch 8/10, Batch 20/145, Loss: 0.1038
Epoch 8/10, Batch 30/145, Loss: 0.1138
Epoch 8/10, Batch 40/145, Loss: 0.2840
Epoch 8/10, Batch 50/145, Loss: 0.1406
Epoch 8/10, Batch 60/145, Loss: 0.1959
Epoch 8/10, Batch 70/145, Loss: 0.1433
Epoch 8/10, Batch 80/145, Loss: 0.2485
Epoch 8/10, Batch 90/145, Loss: 0.1990
Epoch 8/10, Batch 100/145, Loss: 0.1732
Epoch 8/10, Batch 110/145, Loss: 0.2503
Epoch 8/10, Batch 120/145, Loss: 0.2636
Epoch 8/10, Batch 130/145, Loss: 0.1777
Epoch 8/10, Batch 140/145, Loss: 0.3124
Epoch 8/10, Train Loss: 0.2101, Valid Loss: 0.2357
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2235
Epoch 9/10, Batch 20/145, Loss: 0.1120
Epoch 9/10, Batch 30/145, Loss: 0.2452
Epoch 9/10, Batch 40/145, Loss: 0.1685
Epoch 9/10, Batch 50/145, Loss: 0.1306
Epoch 9/10, Batch 60/145, Loss: 0.1398
Epoch 9/10, Batch 70/145, Loss: 0.2507
Epoch 9/10, Batch 80/145, Loss: 0.1604
Epoch 9/10, Batch 90/145, Loss: 0.1799
Epoch 9/10, Batch 100/145, Loss: 0.2224
Epoch 9/10, Batch 110/145, Loss: 0.1403
Epoch 9/10, Batch 120/145, Loss: 0.2942
Epoch 9/10, Batch 130/145, Loss: 0.1265
Epoch 9/10, Batch 140/145, Loss: 0.0747
Epoch 9/10, Train Loss: 0.1955, Valid Loss: 0.2331
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1488
Epoch 10/10, Batch 20/145, Loss: 0.1138
Epoch 10/10, Batch 30/145, Loss: 0.0969
Epoch 10/10, Batch 40/145, Loss: 0.2161
Epoch 10/10, Batch 50/145, Loss: 0.2890
Epoch 10/10, Batch 60/145, Loss: 0.2549
Epoch 10/10, Batch 70/145, Loss: 0.1034
Epoch 10/10, Batch 80/145, Loss: 0.4945
Epoch 10/10, Batch 90/145, Loss: 0.2139
Epoch 10/10, Batch 100/145, Loss: 0.1120
Epoch 10/10, Batch 110/145, Loss: 0.2216
Epoch 10/10, Batch 120/145, Loss: 0.1349
Epoch 10/10, Batch 130/145, Loss: 0.1636
Epoch 10/10, Batch 140/145, Loss: 0.1627
Epoch 10/10, Train Loss: 0.1986, Valid Loss: 0.2262
Model saved!
Accuracy: 0.9287
Precision: 0.9273
Recall: 0.9287
F1-score: 0.9278
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5028
Epoch 1/10, Batch 20/145, Loss: 0.8925
Epoch 1/10, Batch 30/145, Loss: 0.8170
Epoch 1/10, Batch 40/145, Loss: 0.8059
Epoch 1/10, Batch 50/145, Loss: 0.6478
Epoch 1/10, Batch 60/145, Loss: 0.6856
Epoch 1/10, Batch 70/145, Loss: 0.6706
Epoch 1/10, Batch 80/145, Loss: 0.5582
Epoch 1/10, Batch 90/145, Loss: 0.6199
Epoch 1/10, Batch 100/145, Loss: 0.4230
Epoch 1/10, Batch 110/145, Loss: 0.3918
Epoch 1/10, Batch 120/145, Loss: 0.6063
Epoch 1/10, Batch 130/145, Loss: 0.4536
Epoch 1/10, Batch 140/145, Loss: 0.3513
Epoch 1/10, Train Loss: 0.6822, Valid Loss: 0.4181
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2465
Epoch 2/10, Batch 20/145, Loss: 0.4314
Epoch 2/10, Batch 30/145, Loss: 0.3328
Epoch 2/10, Batch 40/145, Loss: 0.5239
Epoch 2/10, Batch 50/145, Loss: 0.2951
Epoch 2/10, Batch 60/145, Loss: 0.4593
Epoch 2/10, Batch 70/145, Loss: 0.2470
Epoch 2/10, Batch 80/145, Loss: 0.3604
Epoch 2/10, Batch 90/145, Loss: 0.2698
Epoch 2/10, Batch 100/145, Loss: 0.2944
Epoch 2/10, Batch 110/145, Loss: 0.2128
Epoch 2/10, Batch 120/145, Loss: 0.4850
Epoch 2/10, Batch 130/145, Loss: 0.3487
Epoch 2/10, Batch 140/145, Loss: 0.2276
Epoch 2/10, Train Loss: 0.3538, Valid Loss: 0.3261
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2370
Epoch 3/10, Batch 20/145, Loss: 0.2585
Epoch 3/10, Batch 30/145, Loss: 0.2299
Epoch 3/10, Batch 40/145, Loss: 0.2696
Epoch 3/10, Batch 50/145, Loss: 0.2155
Epoch 3/10, Batch 60/145, Loss: 0.2025
Epoch 3/10, Batch 70/145, Loss: 0.2655
Epoch 3/10, Batch 80/145, Loss: 0.3032
Epoch 3/10, Batch 90/145, Loss: 0.3748
Epoch 3/10, Batch 100/145, Loss: 0.3456
Epoch 3/10, Batch 110/145, Loss: 0.2707
Epoch 3/10, Batch 120/145, Loss: 0.2222
Epoch 3/10, Batch 130/145, Loss: 0.1888
Epoch 3/10, Batch 140/145, Loss: 0.1297
Epoch 3/10, Train Loss: 0.2925, Valid Loss: 0.2900
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1688
Epoch 4/10, Batch 20/145, Loss: 0.4924
Epoch 4/10, Batch 30/145, Loss: 0.2367
Epoch 4/10, Batch 40/145, Loss: 0.2837
Epoch 4/10, Batch 50/145, Loss: 0.2407
Epoch 4/10, Batch 60/145, Loss: 0.0992
Epoch 4/10, Batch 70/145, Loss: 0.3303
Epoch 4/10, Batch 80/145, Loss: 0.2515
Epoch 4/10, Batch 90/145, Loss: 0.2691
Epoch 4/10, Batch 100/145, Loss: 0.2812
Epoch 4/10, Batch 110/145, Loss: 0.1072
Epoch 4/10, Batch 120/145, Loss: 0.2242
Epoch 4/10, Batch 130/145, Loss: 0.1953
Epoch 4/10, Batch 140/145, Loss: 0.2114
Epoch 4/10, Train Loss: 0.2584, Valid Loss: 0.2809
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3698
Epoch 5/10, Batch 20/145, Loss: 0.1877
Epoch 5/10, Batch 30/145, Loss: 0.1468
Epoch 5/10, Batch 40/145, Loss: 0.3524
Epoch 5/10, Batch 50/145, Loss: 0.1321
Epoch 5/10, Batch 60/145, Loss: 0.2255
Epoch 5/10, Batch 70/145, Loss: 0.2677
Epoch 5/10, Batch 80/145, Loss: 0.1748
Epoch 5/10, Batch 90/145, Loss: 0.2065
Epoch 5/10, Batch 100/145, Loss: 0.1680
Epoch 5/10, Batch 110/145, Loss: 0.1891
Epoch 5/10, Batch 120/145, Loss: 0.1961
Epoch 5/10, Batch 130/145, Loss: 0.1265
Epoch 5/10, Batch 140/145, Loss: 0.2204
Epoch 5/10, Train Loss: 0.2320, Valid Loss: 0.2627
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1456
Epoch 6/10, Batch 20/145, Loss: 0.4860
Epoch 6/10, Batch 30/145, Loss: 0.2394
Epoch 6/10, Batch 40/145, Loss: 0.1887
Epoch 6/10, Batch 50/145, Loss: 0.4024
Epoch 6/10, Batch 60/145, Loss: 0.1837
Epoch 6/10, Batch 70/145, Loss: 0.1969
Epoch 6/10, Batch 80/145, Loss: 0.2445
Epoch 6/10, Batch 90/145, Loss: 0.2372
Epoch 6/10, Batch 100/145, Loss: 0.1536
Epoch 6/10, Batch 110/145, Loss: 0.1874
Epoch 6/10, Batch 120/145, Loss: 0.2285
Epoch 6/10, Batch 130/145, Loss: 0.2683
Epoch 6/10, Batch 140/145, Loss: 0.1682
Epoch 6/10, Train Loss: 0.2209, Valid Loss: 0.2593
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2545
Epoch 7/10, Batch 20/145, Loss: 0.1495
Epoch 7/10, Batch 30/145, Loss: 0.2812
Epoch 7/10, Batch 40/145, Loss: 0.5642
Epoch 7/10, Batch 50/145, Loss: 0.2268
Epoch 7/10, Batch 60/145, Loss: 0.1455
Epoch 7/10, Batch 70/145, Loss: 0.2548
Epoch 7/10, Batch 80/145, Loss: 0.1358
Epoch 7/10, Batch 90/145, Loss: 0.2367
Epoch 7/10, Batch 100/145, Loss: 0.1790
Epoch 7/10, Batch 110/145, Loss: 0.2186
Epoch 7/10, Batch 120/145, Loss: 0.1831
Epoch 7/10, Batch 130/145, Loss: 0.3557
Epoch 7/10, Batch 140/145, Loss: 0.2232
Epoch 7/10, Train Loss: 0.2191, Valid Loss: 0.2557
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1481
Epoch 8/10, Batch 20/145, Loss: 0.1150
Epoch 8/10, Batch 30/145, Loss: 0.1376
Epoch 8/10, Batch 40/145, Loss: 0.2204
Epoch 8/10, Batch 50/145, Loss: 0.2439
Epoch 8/10, Batch 60/145, Loss: 0.3283
Epoch 8/10, Batch 70/145, Loss: 0.1402
Epoch 8/10, Batch 80/145, Loss: 0.1829
Epoch 8/10, Batch 90/145, Loss: 0.1072
Epoch 8/10, Batch 100/145, Loss: 0.1864
Epoch 8/10, Batch 110/145, Loss: 0.0937
Epoch 8/10, Batch 120/145, Loss: 0.0741
Epoch 8/10, Batch 130/145, Loss: 0.2768
Epoch 8/10, Batch 140/145, Loss: 0.2421
Epoch 8/10, Train Loss: 0.1963, Valid Loss: 0.2440
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1135
Epoch 9/10, Batch 20/145, Loss: 0.1727
Epoch 9/10, Batch 30/145, Loss: 0.1434
Epoch 9/10, Batch 40/145, Loss: 0.2062
Epoch 9/10, Batch 50/145, Loss: 0.0874
Epoch 9/10, Batch 60/145, Loss: 0.1369
Epoch 9/10, Batch 70/145, Loss: 0.3525
Epoch 9/10, Batch 80/145, Loss: 0.1850
Epoch 9/10, Batch 90/145, Loss: 0.0861
Epoch 9/10, Batch 100/145, Loss: 0.2453
Epoch 9/10, Batch 110/145, Loss: 0.0759
Epoch 9/10, Batch 120/145, Loss: 0.1612
Epoch 9/10, Batch 130/145, Loss: 0.1912
Epoch 9/10, Batch 140/145, Loss: 0.2146
Epoch 9/10, Train Loss: 0.1939, Valid Loss: 0.2442
Epoch 10/10, Batch 10/145, Loss: 0.1728
Epoch 10/10, Batch 20/145, Loss: 0.1419
Epoch 10/10, Batch 30/145, Loss: 0.1248
Epoch 10/10, Batch 40/145, Loss: 0.3514
Epoch 10/10, Batch 50/145, Loss: 0.1546
Epoch 10/10, Batch 60/145, Loss: 0.1366
Epoch 10/10, Batch 70/145, Loss: 0.2290
Epoch 10/10, Batch 80/145, Loss: 0.2689
Epoch 10/10, Batch 90/145, Loss: 0.1599
Epoch 10/10, Batch 100/145, Loss: 0.0929
Epoch 10/10, Batch 110/145, Loss: 0.2561
Epoch 10/10, Batch 120/145, Loss: 0.2295
Epoch 10/10, Batch 130/145, Loss: 0.2615
Epoch 10/10, Batch 140/145, Loss: 0.2789
Epoch 10/10, Train Loss: 0.1969, Valid Loss: 0.2377
Model saved!
Accuracy: 0.9229
Precision: 0.9213
Recall: 0.9229
F1-score: 0.9216
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5526
Epoch 1/10, Batch 20/145, Loss: 0.9967
Epoch 1/10, Batch 30/145, Loss: 0.9008
Epoch 1/10, Batch 40/145, Loss: 0.7702
Epoch 1/10, Batch 50/145, Loss: 0.6218
Epoch 1/10, Batch 60/145, Loss: 0.6369
Epoch 1/10, Batch 70/145, Loss: 0.5380
Epoch 1/10, Batch 80/145, Loss: 0.4654
Epoch 1/10, Batch 90/145, Loss: 0.5345
Epoch 1/10, Batch 100/145, Loss: 0.5916
Epoch 1/10, Batch 110/145, Loss: 0.4075
Epoch 1/10, Batch 120/145, Loss: 0.5757
Epoch 1/10, Batch 130/145, Loss: 0.3373
Epoch 1/10, Batch 140/145, Loss: 0.4552
Epoch 1/10, Train Loss: 0.6904, Valid Loss: 0.3434
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4086
Epoch 2/10, Batch 20/145, Loss: 0.4643
Epoch 2/10, Batch 30/145, Loss: 0.3912
Epoch 2/10, Batch 40/145, Loss: 0.3734
Epoch 2/10, Batch 50/145, Loss: 0.2594
Epoch 2/10, Batch 60/145, Loss: 0.5606
Epoch 2/10, Batch 70/145, Loss: 0.4560
Epoch 2/10, Batch 80/145, Loss: 0.2585
Epoch 2/10, Batch 90/145, Loss: 0.2970
Epoch 2/10, Batch 100/145, Loss: 0.3044
Epoch 2/10, Batch 110/145, Loss: 0.3058
Epoch 2/10, Batch 120/145, Loss: 0.4127
Epoch 2/10, Batch 130/145, Loss: 0.5227
Epoch 2/10, Batch 140/145, Loss: 0.1999
Epoch 2/10, Train Loss: 0.3676, Valid Loss: 0.2595
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2502
Epoch 3/10, Batch 20/145, Loss: 0.1932
Epoch 3/10, Batch 30/145, Loss: 0.2045
Epoch 3/10, Batch 40/145, Loss: 0.2668
Epoch 3/10, Batch 50/145, Loss: 0.2546
Epoch 3/10, Batch 60/145, Loss: 0.2622
Epoch 3/10, Batch 70/145, Loss: 0.2385
Epoch 3/10, Batch 80/145, Loss: 0.2178
Epoch 3/10, Batch 90/145, Loss: 0.6150
Epoch 3/10, Batch 100/145, Loss: 0.3374
Epoch 3/10, Batch 110/145, Loss: 0.2605
Epoch 3/10, Batch 120/145, Loss: 0.1922
Epoch 3/10, Batch 130/145, Loss: 0.2157
Epoch 3/10, Batch 140/145, Loss: 0.2664
Epoch 3/10, Train Loss: 0.3098, Valid Loss: 0.2416
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3212
Epoch 4/10, Batch 20/145, Loss: 0.2068
Epoch 4/10, Batch 30/145, Loss: 0.4446
Epoch 4/10, Batch 40/145, Loss: 0.3638
Epoch 4/10, Batch 50/145, Loss: 0.1688
Epoch 4/10, Batch 60/145, Loss: 0.1444
Epoch 4/10, Batch 70/145, Loss: 0.2553
Epoch 4/10, Batch 80/145, Loss: 0.2640
Epoch 4/10, Batch 90/145, Loss: 0.3972
Epoch 4/10, Batch 100/145, Loss: 0.1859
Epoch 4/10, Batch 110/145, Loss: 0.2034
Epoch 4/10, Batch 120/145, Loss: 0.3752
Epoch 4/10, Batch 130/145, Loss: 0.1921
Epoch 4/10, Batch 140/145, Loss: 0.2725
Epoch 4/10, Train Loss: 0.2697, Valid Loss: 0.2328
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3168
Epoch 5/10, Batch 20/145, Loss: 0.3434
Epoch 5/10, Batch 30/145, Loss: 0.1470
Epoch 5/10, Batch 40/145, Loss: 0.1077
Epoch 5/10, Batch 50/145, Loss: 0.2263
Epoch 5/10, Batch 60/145, Loss: 0.3013
Epoch 5/10, Batch 70/145, Loss: 0.3000
Epoch 5/10, Batch 80/145, Loss: 0.3930
Epoch 5/10, Batch 90/145, Loss: 0.2000
Epoch 5/10, Batch 100/145, Loss: 0.3468
Epoch 5/10, Batch 110/145, Loss: 0.1362
Epoch 5/10, Batch 120/145, Loss: 0.1231
Epoch 5/10, Batch 130/145, Loss: 0.2083
Epoch 5/10, Batch 140/145, Loss: 0.4816
Epoch 5/10, Train Loss: 0.2440, Valid Loss: 0.2261
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1617
Epoch 6/10, Batch 20/145, Loss: 0.1873
Epoch 6/10, Batch 30/145, Loss: 0.2797
Epoch 6/10, Batch 40/145, Loss: 0.2256
Epoch 6/10, Batch 50/145, Loss: 0.4532
Epoch 6/10, Batch 60/145, Loss: 0.0735
Epoch 6/10, Batch 70/145, Loss: 0.3892
Epoch 6/10, Batch 80/145, Loss: 0.2548
Epoch 6/10, Batch 90/145, Loss: 0.3107
Epoch 6/10, Batch 100/145, Loss: 0.4403
Epoch 6/10, Batch 110/145, Loss: 0.0614
Epoch 6/10, Batch 120/145, Loss: 0.2372
Epoch 6/10, Batch 130/145, Loss: 0.1366
Epoch 6/10, Batch 140/145, Loss: 0.2645
Epoch 6/10, Train Loss: 0.2334, Valid Loss: 0.2220
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3153
Epoch 7/10, Batch 20/145, Loss: 0.2459
Epoch 7/10, Batch 30/145, Loss: 0.2262
Epoch 7/10, Batch 40/145, Loss: 0.2930
Epoch 7/10, Batch 50/145, Loss: 0.3004
Epoch 7/10, Batch 60/145, Loss: 0.0884
Epoch 7/10, Batch 70/145, Loss: 0.1695
Epoch 7/10, Batch 80/145, Loss: 0.1418
Epoch 7/10, Batch 90/145, Loss: 0.2732
Epoch 7/10, Batch 100/145, Loss: 0.1051
Epoch 7/10, Batch 110/145, Loss: 0.1718
Epoch 7/10, Batch 120/145, Loss: 0.2588
Epoch 7/10, Batch 130/145, Loss: 0.2058
Epoch 7/10, Batch 140/145, Loss: 0.1798
Epoch 7/10, Train Loss: 0.2283, Valid Loss: 0.2202
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2287
Epoch 8/10, Batch 20/145, Loss: 0.2285
Epoch 8/10, Batch 30/145, Loss: 0.1904
Epoch 8/10, Batch 40/145, Loss: 0.1381
Epoch 8/10, Batch 50/145, Loss: 0.2025
Epoch 8/10, Batch 60/145, Loss: 0.2064
Epoch 8/10, Batch 70/145, Loss: 0.2639
Epoch 8/10, Batch 80/145, Loss: 0.1402
Epoch 8/10, Batch 90/145, Loss: 0.1110
Epoch 8/10, Batch 100/145, Loss: 0.1399
Epoch 8/10, Batch 110/145, Loss: 0.3216
Epoch 8/10, Batch 120/145, Loss: 0.1645
Epoch 8/10, Batch 130/145, Loss: 0.1381
Epoch 8/10, Batch 140/145, Loss: 0.4378
Epoch 8/10, Train Loss: 0.2162, Valid Loss: 0.2117
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2151
Epoch 9/10, Batch 20/145, Loss: 0.1951
Epoch 9/10, Batch 30/145, Loss: 0.1028
Epoch 9/10, Batch 40/145, Loss: 0.1428
Epoch 9/10, Batch 50/145, Loss: 0.2191
Epoch 9/10, Batch 60/145, Loss: 0.1177
Epoch 9/10, Batch 70/145, Loss: 0.2209
Epoch 9/10, Batch 80/145, Loss: 0.1968
Epoch 9/10, Batch 90/145, Loss: 0.4110
Epoch 9/10, Batch 100/145, Loss: 0.1270
Epoch 9/10, Batch 110/145, Loss: 0.1089
Epoch 9/10, Batch 120/145, Loss: 0.2513
Epoch 9/10, Batch 130/145, Loss: 0.3151
Epoch 9/10, Batch 140/145, Loss: 0.1854
Epoch 9/10, Train Loss: 0.2066, Valid Loss: 0.2043
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.3269
Epoch 10/10, Batch 20/145, Loss: 0.1249
Epoch 10/10, Batch 30/145, Loss: 0.0635
Epoch 10/10, Batch 40/145, Loss: 0.1547
Epoch 10/10, Batch 50/145, Loss: 0.4262
Epoch 10/10, Batch 60/145, Loss: 0.1360
Epoch 10/10, Batch 70/145, Loss: 0.1334
Epoch 10/10, Batch 80/145, Loss: 0.3885
Epoch 10/10, Batch 90/145, Loss: 0.1431
Epoch 10/10, Batch 100/145, Loss: 0.1743
Epoch 10/10, Batch 110/145, Loss: 0.3949
Epoch 10/10, Batch 120/145, Loss: 0.1625
Epoch 10/10, Batch 130/145, Loss: 0.2817
Epoch 10/10, Batch 140/145, Loss: 0.1591
Epoch 10/10, Train Loss: 0.1969, Valid Loss: 0.2019
Model saved!
Accuracy: 0.9194
Precision: 0.9173
Recall: 0.9194
F1-score: 0.9179
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5086
Epoch 1/10, Batch 20/145, Loss: 0.9100
Epoch 1/10, Batch 30/145, Loss: 0.7282
Epoch 1/10, Batch 40/145, Loss: 0.7946
Epoch 1/10, Batch 50/145, Loss: 0.5992
Epoch 1/10, Batch 60/145, Loss: 0.6139
Epoch 1/10, Batch 70/145, Loss: 0.6936
Epoch 1/10, Batch 80/145, Loss: 0.5069
Epoch 1/10, Batch 90/145, Loss: 0.4482
Epoch 1/10, Batch 100/145, Loss: 0.4876
Epoch 1/10, Batch 110/145, Loss: 0.4693
Epoch 1/10, Batch 120/145, Loss: 0.6239
Epoch 1/10, Batch 130/145, Loss: 0.3681
Epoch 1/10, Batch 140/145, Loss: 0.4684
Epoch 1/10, Train Loss: 0.6855, Valid Loss: 0.3642
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3596
Epoch 2/10, Batch 20/145, Loss: 0.5156
Epoch 2/10, Batch 30/145, Loss: 0.2534
Epoch 2/10, Batch 40/145, Loss: 0.4727
Epoch 2/10, Batch 50/145, Loss: 0.3321
Epoch 2/10, Batch 60/145, Loss: 0.4244
Epoch 2/10, Batch 70/145, Loss: 0.2929
Epoch 2/10, Batch 80/145, Loss: 0.2964
Epoch 2/10, Batch 90/145, Loss: 0.3562
Epoch 2/10, Batch 100/145, Loss: 0.3169
Epoch 2/10, Batch 110/145, Loss: 0.3076
Epoch 2/10, Batch 120/145, Loss: 0.3083
Epoch 2/10, Batch 130/145, Loss: 0.4749
Epoch 2/10, Batch 140/145, Loss: 0.2249
Epoch 2/10, Train Loss: 0.3586, Valid Loss: 0.2757
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2438
Epoch 3/10, Batch 20/145, Loss: 0.2672
Epoch 3/10, Batch 30/145, Loss: 0.2096
Epoch 3/10, Batch 40/145, Loss: 0.1933
Epoch 3/10, Batch 50/145, Loss: 0.2489
Epoch 3/10, Batch 60/145, Loss: 0.2498
Epoch 3/10, Batch 70/145, Loss: 0.1563
Epoch 3/10, Batch 80/145, Loss: 0.3489
Epoch 3/10, Batch 90/145, Loss: 0.6162
Epoch 3/10, Batch 100/145, Loss: 0.2316
Epoch 3/10, Batch 110/145, Loss: 0.2798
Epoch 3/10, Batch 120/145, Loss: 0.3221
Epoch 3/10, Batch 130/145, Loss: 0.1707
Epoch 3/10, Batch 140/145, Loss: 0.1766
Epoch 3/10, Train Loss: 0.3046, Valid Loss: 0.2464
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2435
Epoch 4/10, Batch 20/145, Loss: 0.2949
Epoch 4/10, Batch 30/145, Loss: 0.2375
Epoch 4/10, Batch 40/145, Loss: 0.3769
Epoch 4/10, Batch 50/145, Loss: 0.2199
Epoch 4/10, Batch 60/145, Loss: 0.1255
Epoch 4/10, Batch 70/145, Loss: 0.3619
Epoch 4/10, Batch 80/145, Loss: 0.2817
Epoch 4/10, Batch 90/145, Loss: 0.2254
Epoch 4/10, Batch 100/145, Loss: 0.2754
Epoch 4/10, Batch 110/145, Loss: 0.2368
Epoch 4/10, Batch 120/145, Loss: 0.1420
Epoch 4/10, Batch 130/145, Loss: 0.1647
Epoch 4/10, Batch 140/145, Loss: 0.1036
Epoch 4/10, Train Loss: 0.2625, Valid Loss: 0.2465
Epoch 5/10, Batch 10/145, Loss: 0.4012
Epoch 5/10, Batch 20/145, Loss: 0.3795
Epoch 5/10, Batch 30/145, Loss: 0.3099
Epoch 5/10, Batch 40/145, Loss: 0.1709
Epoch 5/10, Batch 50/145, Loss: 0.1553
Epoch 5/10, Batch 60/145, Loss: 0.1850
Epoch 5/10, Batch 70/145, Loss: 0.2904
Epoch 5/10, Batch 80/145, Loss: 0.2174
Epoch 5/10, Batch 90/145, Loss: 0.3131
Epoch 5/10, Batch 100/145, Loss: 0.2400
Epoch 5/10, Batch 110/145, Loss: 0.2798
Epoch 5/10, Batch 120/145, Loss: 0.2356
Epoch 5/10, Batch 130/145, Loss: 0.2034
Epoch 5/10, Batch 140/145, Loss: 0.2175
Epoch 5/10, Train Loss: 0.2397, Valid Loss: 0.2240
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2207
Epoch 6/10, Batch 20/145, Loss: 0.1837
Epoch 6/10, Batch 30/145, Loss: 0.2341
Epoch 6/10, Batch 40/145, Loss: 0.0893
Epoch 6/10, Batch 50/145, Loss: 0.3018
Epoch 6/10, Batch 60/145, Loss: 0.1872
Epoch 6/10, Batch 70/145, Loss: 0.2235
Epoch 6/10, Batch 80/145, Loss: 0.3464
Epoch 6/10, Batch 90/145, Loss: 0.2276
Epoch 6/10, Batch 100/145, Loss: 0.2890
Epoch 6/10, Batch 110/145, Loss: 0.3077
Epoch 6/10, Batch 120/145, Loss: 0.3462
Epoch 6/10, Batch 130/145, Loss: 0.1557
Epoch 6/10, Batch 140/145, Loss: 0.2544
Epoch 6/10, Train Loss: 0.2245, Valid Loss: 0.2280
Epoch 7/10, Batch 10/145, Loss: 0.2770
Epoch 7/10, Batch 20/145, Loss: 0.1810
Epoch 7/10, Batch 30/145, Loss: 0.2150
Epoch 7/10, Batch 40/145, Loss: 0.5654
Epoch 7/10, Batch 50/145, Loss: 0.1701
Epoch 7/10, Batch 60/145, Loss: 0.2579
Epoch 7/10, Batch 70/145, Loss: 0.3054
Epoch 7/10, Batch 80/145, Loss: 0.2517
Epoch 7/10, Batch 90/145, Loss: 0.4183
Epoch 7/10, Batch 100/145, Loss: 0.2232
Epoch 7/10, Batch 110/145, Loss: 0.1623
Epoch 7/10, Batch 120/145, Loss: 0.1518
Epoch 7/10, Batch 130/145, Loss: 0.1641
Epoch 7/10, Batch 140/145, Loss: 0.3112
Epoch 7/10, Train Loss: 0.2211, Valid Loss: 0.2123
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1709
Epoch 8/10, Batch 20/145, Loss: 0.1466
Epoch 8/10, Batch 30/145, Loss: 0.2389
Epoch 8/10, Batch 40/145, Loss: 0.1063
Epoch 8/10, Batch 50/145, Loss: 0.2486
Epoch 8/10, Batch 60/145, Loss: 0.1494
Epoch 8/10, Batch 70/145, Loss: 0.1545
Epoch 8/10, Batch 80/145, Loss: 0.2913
Epoch 8/10, Batch 90/145, Loss: 0.3266
Epoch 8/10, Batch 100/145, Loss: 0.2149
Epoch 8/10, Batch 110/145, Loss: 0.3129
Epoch 8/10, Batch 120/145, Loss: 0.2781
Epoch 8/10, Batch 130/145, Loss: 0.1904
Epoch 8/10, Batch 140/145, Loss: 0.2300
Epoch 8/10, Train Loss: 0.2090, Valid Loss: 0.2066
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1816
Epoch 9/10, Batch 20/145, Loss: 0.1254
Epoch 9/10, Batch 30/145, Loss: 0.0635
Epoch 9/10, Batch 40/145, Loss: 0.1951
Epoch 9/10, Batch 50/145, Loss: 0.0883
Epoch 9/10, Batch 60/145, Loss: 0.1252
Epoch 9/10, Batch 70/145, Loss: 0.1923
Epoch 9/10, Batch 80/145, Loss: 0.1389
Epoch 9/10, Batch 90/145, Loss: 0.2542
Epoch 9/10, Batch 100/145, Loss: 0.2427
Epoch 9/10, Batch 110/145, Loss: 0.1277
Epoch 9/10, Batch 120/145, Loss: 0.2018
Epoch 9/10, Batch 130/145, Loss: 0.2609
Epoch 9/10, Batch 140/145, Loss: 0.1470
Epoch 9/10, Train Loss: 0.2024, Valid Loss: 0.2009
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1670
Epoch 10/10, Batch 20/145, Loss: 0.1178
Epoch 10/10, Batch 30/145, Loss: 0.1195
Epoch 10/10, Batch 40/145, Loss: 0.3320
Epoch 10/10, Batch 50/145, Loss: 0.1876
Epoch 10/10, Batch 60/145, Loss: 0.2098
Epoch 10/10, Batch 70/145, Loss: 0.2442
Epoch 10/10, Batch 80/145, Loss: 0.4666
Epoch 10/10, Batch 90/145, Loss: 0.1534
Epoch 10/10, Batch 100/145, Loss: 0.1797
Epoch 10/10, Batch 110/145, Loss: 0.2350
Epoch 10/10, Batch 120/145, Loss: 0.1426
Epoch 10/10, Batch 130/145, Loss: 0.1682
Epoch 10/10, Batch 140/145, Loss: 0.2217
Epoch 10/10, Train Loss: 0.1966, Valid Loss: 0.1986
Model saved!
Accuracy: 0.9136
Precision: 0.9122
Recall: 0.9136
F1-score: 0.9121
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4636
Epoch 1/10, Batch 20/145, Loss: 0.8152
Epoch 1/10, Batch 30/145, Loss: 0.7953
Epoch 1/10, Batch 40/145, Loss: 0.7601
Epoch 1/10, Batch 50/145, Loss: 0.6245
Epoch 1/10, Batch 60/145, Loss: 0.6189
Epoch 1/10, Batch 70/145, Loss: 0.6333
Epoch 1/10, Batch 80/145, Loss: 0.4828
Epoch 1/10, Batch 90/145, Loss: 0.4512
Epoch 1/10, Batch 100/145, Loss: 0.5432
Epoch 1/10, Batch 110/145, Loss: 0.3987
Epoch 1/10, Batch 120/145, Loss: 0.6643
Epoch 1/10, Batch 130/145, Loss: 0.3956
Epoch 1/10, Batch 140/145, Loss: 0.3832
Epoch 1/10, Train Loss: 0.6853, Valid Loss: 0.3687
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2566
Epoch 2/10, Batch 20/145, Loss: 0.5255
Epoch 2/10, Batch 30/145, Loss: 0.2666
Epoch 2/10, Batch 40/145, Loss: 0.4988
Epoch 2/10, Batch 50/145, Loss: 0.3371
Epoch 2/10, Batch 60/145, Loss: 0.4529
Epoch 2/10, Batch 70/145, Loss: 0.5111
Epoch 2/10, Batch 80/145, Loss: 0.2440
Epoch 2/10, Batch 90/145, Loss: 0.3311
Epoch 2/10, Batch 100/145, Loss: 0.4063
Epoch 2/10, Batch 110/145, Loss: 0.2515
Epoch 2/10, Batch 120/145, Loss: 0.4285
Epoch 2/10, Batch 130/145, Loss: 0.2935
Epoch 2/10, Batch 140/145, Loss: 0.3270
Epoch 2/10, Train Loss: 0.3641, Valid Loss: 0.2856
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2296
Epoch 3/10, Batch 20/145, Loss: 0.4629
Epoch 3/10, Batch 30/145, Loss: 0.2601
Epoch 3/10, Batch 40/145, Loss: 0.2848
Epoch 3/10, Batch 50/145, Loss: 0.2159
Epoch 3/10, Batch 60/145, Loss: 0.3267
Epoch 3/10, Batch 70/145, Loss: 0.2967
Epoch 3/10, Batch 80/145, Loss: 0.1888
Epoch 3/10, Batch 90/145, Loss: 0.3614
Epoch 3/10, Batch 100/145, Loss: 0.3059
Epoch 3/10, Batch 110/145, Loss: 0.3225
Epoch 3/10, Batch 120/145, Loss: 0.2024
Epoch 3/10, Batch 130/145, Loss: 0.2965
Epoch 3/10, Batch 140/145, Loss: 0.3899
Epoch 3/10, Train Loss: 0.3067, Valid Loss: 0.2720
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2488
Epoch 4/10, Batch 20/145, Loss: 0.2976
Epoch 4/10, Batch 30/145, Loss: 0.1853
Epoch 4/10, Batch 40/145, Loss: 0.3184
Epoch 4/10, Batch 50/145, Loss: 0.1635
Epoch 4/10, Batch 60/145, Loss: 0.2821
Epoch 4/10, Batch 70/145, Loss: 0.1669
Epoch 4/10, Batch 80/145, Loss: 0.3933
Epoch 4/10, Batch 90/145, Loss: 0.3417
Epoch 4/10, Batch 100/145, Loss: 0.2761
Epoch 4/10, Batch 110/145, Loss: 0.3716
Epoch 4/10, Batch 120/145, Loss: 0.3335
Epoch 4/10, Batch 130/145, Loss: 0.1425
Epoch 4/10, Batch 140/145, Loss: 0.2344
Epoch 4/10, Train Loss: 0.2646, Valid Loss: 0.2554
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2386
Epoch 5/10, Batch 20/145, Loss: 0.4063
Epoch 5/10, Batch 30/145, Loss: 0.3352
Epoch 5/10, Batch 40/145, Loss: 0.3152
Epoch 5/10, Batch 50/145, Loss: 0.1747
Epoch 5/10, Batch 60/145, Loss: 0.1420
Epoch 5/10, Batch 70/145, Loss: 0.2430
Epoch 5/10, Batch 80/145, Loss: 0.3214
Epoch 5/10, Batch 90/145, Loss: 0.1815
Epoch 5/10, Batch 100/145, Loss: 0.1853
Epoch 5/10, Batch 110/145, Loss: 0.2128
Epoch 5/10, Batch 120/145, Loss: 0.1805
Epoch 5/10, Batch 130/145, Loss: 0.2605
Epoch 5/10, Batch 140/145, Loss: 0.2220
Epoch 5/10, Train Loss: 0.2488, Valid Loss: 0.2332
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1555
Epoch 6/10, Batch 20/145, Loss: 0.1668
Epoch 6/10, Batch 30/145, Loss: 0.1969
Epoch 6/10, Batch 40/145, Loss: 0.1934
Epoch 6/10, Batch 50/145, Loss: 0.2554
Epoch 6/10, Batch 60/145, Loss: 0.1368
Epoch 6/10, Batch 70/145, Loss: 0.2318
Epoch 6/10, Batch 80/145, Loss: 0.5597
Epoch 6/10, Batch 90/145, Loss: 0.2067
Epoch 6/10, Batch 100/145, Loss: 0.2372
Epoch 6/10, Batch 110/145, Loss: 0.2902
Epoch 6/10, Batch 120/145, Loss: 0.2495
Epoch 6/10, Batch 130/145, Loss: 0.1163
Epoch 6/10, Batch 140/145, Loss: 0.2791
Epoch 6/10, Train Loss: 0.2304, Valid Loss: 0.2353
Epoch 7/10, Batch 10/145, Loss: 0.5365
Epoch 7/10, Batch 20/145, Loss: 0.1554
Epoch 7/10, Batch 30/145, Loss: 0.1325
Epoch 7/10, Batch 40/145, Loss: 0.5312
Epoch 7/10, Batch 50/145, Loss: 0.1579
Epoch 7/10, Batch 60/145, Loss: 0.1298
Epoch 7/10, Batch 70/145, Loss: 0.1398
Epoch 7/10, Batch 80/145, Loss: 0.1270
Epoch 7/10, Batch 90/145, Loss: 0.4702
Epoch 7/10, Batch 100/145, Loss: 0.1379
Epoch 7/10, Batch 110/145, Loss: 0.1772
Epoch 7/10, Batch 120/145, Loss: 0.1593
Epoch 7/10, Batch 130/145, Loss: 0.2299
Epoch 7/10, Batch 140/145, Loss: 0.1846
Epoch 7/10, Train Loss: 0.2183, Valid Loss: 0.2275
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1249
Epoch 8/10, Batch 20/145, Loss: 0.0814
Epoch 8/10, Batch 30/145, Loss: 0.1828
Epoch 8/10, Batch 40/145, Loss: 0.2355
Epoch 8/10, Batch 50/145, Loss: 0.2663
Epoch 8/10, Batch 60/145, Loss: 0.1524
Epoch 8/10, Batch 70/145, Loss: 0.1396
Epoch 8/10, Batch 80/145, Loss: 0.2457
Epoch 8/10, Batch 90/145, Loss: 0.2031
Epoch 8/10, Batch 100/145, Loss: 0.2661
Epoch 8/10, Batch 110/145, Loss: 0.2674
Epoch 8/10, Batch 120/145, Loss: 0.2246
Epoch 8/10, Batch 130/145, Loss: 0.1244
Epoch 8/10, Batch 140/145, Loss: 0.1617
Epoch 8/10, Train Loss: 0.2070, Valid Loss: 0.2228
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2122
Epoch 9/10, Batch 20/145, Loss: 0.0974
Epoch 9/10, Batch 30/145, Loss: 0.1320
Epoch 9/10, Batch 40/145, Loss: 0.2009
Epoch 9/10, Batch 50/145, Loss: 0.1557
Epoch 9/10, Batch 60/145, Loss: 0.1527
Epoch 9/10, Batch 70/145, Loss: 0.2534
Epoch 9/10, Batch 80/145, Loss: 0.1937
Epoch 9/10, Batch 90/145, Loss: 0.1559
Epoch 9/10, Batch 100/145, Loss: 0.2560
Epoch 9/10, Batch 110/145, Loss: 0.2073
Epoch 9/10, Batch 120/145, Loss: 0.2496
Epoch 9/10, Batch 130/145, Loss: 0.2861
Epoch 9/10, Batch 140/145, Loss: 0.1176
Epoch 9/10, Train Loss: 0.2003, Valid Loss: 0.2173
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2102
Epoch 10/10, Batch 20/145, Loss: 0.2192
Epoch 10/10, Batch 30/145, Loss: 0.1667
Epoch 10/10, Batch 40/145, Loss: 0.1606
Epoch 10/10, Batch 50/145, Loss: 0.1711
Epoch 10/10, Batch 60/145, Loss: 0.1769
Epoch 10/10, Batch 70/145, Loss: 0.1382
Epoch 10/10, Batch 80/145, Loss: 0.3528
Epoch 10/10, Batch 90/145, Loss: 0.2589
Epoch 10/10, Batch 100/145, Loss: 0.0971
Epoch 10/10, Batch 110/145, Loss: 0.4925
Epoch 10/10, Batch 120/145, Loss: 0.2406
Epoch 10/10, Batch 130/145, Loss: 0.2591
Epoch 10/10, Batch 140/145, Loss: 0.2586
Epoch 10/10, Train Loss: 0.1999, Valid Loss: 0.2177
Accuracy: 0.9136
Precision: 0.9126
Recall: 0.9136
F1-score: 0.9115
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5113
Epoch 1/10, Batch 20/145, Loss: 0.8792
Epoch 1/10, Batch 30/145, Loss: 0.8117
Epoch 1/10, Batch 40/145, Loss: 0.8221
Epoch 1/10, Batch 50/145, Loss: 0.6183
Epoch 1/10, Batch 60/145, Loss: 0.6049
Epoch 1/10, Batch 70/145, Loss: 0.5734
Epoch 1/10, Batch 80/145, Loss: 0.5424
Epoch 1/10, Batch 90/145, Loss: 0.5155
Epoch 1/10, Batch 100/145, Loss: 0.5076
Epoch 1/10, Batch 110/145, Loss: 0.3878
Epoch 1/10, Batch 120/145, Loss: 0.5817
Epoch 1/10, Batch 130/145, Loss: 0.3464
Epoch 1/10, Batch 140/145, Loss: 0.4381
Epoch 1/10, Train Loss: 0.6940, Valid Loss: 0.3892
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3647
Epoch 2/10, Batch 20/145, Loss: 0.5108
Epoch 2/10, Batch 30/145, Loss: 0.3905
Epoch 2/10, Batch 40/145, Loss: 0.6345
Epoch 2/10, Batch 50/145, Loss: 0.2816
Epoch 2/10, Batch 60/145, Loss: 0.3947
Epoch 2/10, Batch 70/145, Loss: 0.3574
Epoch 2/10, Batch 80/145, Loss: 0.3554
Epoch 2/10, Batch 90/145, Loss: 0.1872
Epoch 2/10, Batch 100/145, Loss: 0.2604
Epoch 2/10, Batch 110/145, Loss: 0.2804
Epoch 2/10, Batch 120/145, Loss: 0.2660
Epoch 2/10, Batch 130/145, Loss: 0.3594
Epoch 2/10, Batch 140/145, Loss: 0.2010
Epoch 2/10, Train Loss: 0.3606, Valid Loss: 0.3095
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2815
Epoch 3/10, Batch 20/145, Loss: 0.3142
Epoch 3/10, Batch 30/145, Loss: 0.1249
Epoch 3/10, Batch 40/145, Loss: 0.2308
Epoch 3/10, Batch 50/145, Loss: 0.2018
Epoch 3/10, Batch 60/145, Loss: 0.4454
Epoch 3/10, Batch 70/145, Loss: 0.3449
Epoch 3/10, Batch 80/145, Loss: 0.2650
Epoch 3/10, Batch 90/145, Loss: 0.2856
Epoch 3/10, Batch 100/145, Loss: 0.2856
Epoch 3/10, Batch 110/145, Loss: 0.2800
Epoch 3/10, Batch 120/145, Loss: 0.2033
Epoch 3/10, Batch 130/145, Loss: 0.2293
Epoch 3/10, Batch 140/145, Loss: 0.1631
Epoch 3/10, Train Loss: 0.3053, Valid Loss: 0.2833
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2145
Epoch 4/10, Batch 20/145, Loss: 0.2830
Epoch 4/10, Batch 30/145, Loss: 0.2955
Epoch 4/10, Batch 40/145, Loss: 0.3267
Epoch 4/10, Batch 50/145, Loss: 0.1447
Epoch 4/10, Batch 60/145, Loss: 0.1686
Epoch 4/10, Batch 70/145, Loss: 0.1653
Epoch 4/10, Batch 80/145, Loss: 0.3714
Epoch 4/10, Batch 90/145, Loss: 0.3138
Epoch 4/10, Batch 100/145, Loss: 0.2661
Epoch 4/10, Batch 110/145, Loss: 0.2106
Epoch 4/10, Batch 120/145, Loss: 0.2248
Epoch 4/10, Batch 130/145, Loss: 0.1513
Epoch 4/10, Batch 140/145, Loss: 0.2709
Epoch 4/10, Train Loss: 0.2627, Valid Loss: 0.2655
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2113
Epoch 5/10, Batch 20/145, Loss: 0.1221
Epoch 5/10, Batch 30/145, Loss: 0.2105
Epoch 5/10, Batch 40/145, Loss: 0.1542
Epoch 5/10, Batch 50/145, Loss: 0.1807
Epoch 5/10, Batch 60/145, Loss: 0.3821
Epoch 5/10, Batch 70/145, Loss: 0.2300
Epoch 5/10, Batch 80/145, Loss: 0.3540
Epoch 5/10, Batch 90/145, Loss: 0.2349
Epoch 5/10, Batch 100/145, Loss: 0.2616
Epoch 5/10, Batch 110/145, Loss: 0.1405
Epoch 5/10, Batch 120/145, Loss: 0.2654
Epoch 5/10, Batch 130/145, Loss: 0.2218
Epoch 5/10, Batch 140/145, Loss: 0.4474
Epoch 5/10, Train Loss: 0.2435, Valid Loss: 0.2511
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2322
Epoch 6/10, Batch 20/145, Loss: 0.2590
Epoch 6/10, Batch 30/145, Loss: 0.2538
Epoch 6/10, Batch 40/145, Loss: 0.1434
Epoch 6/10, Batch 50/145, Loss: 0.3768
Epoch 6/10, Batch 60/145, Loss: 0.1267
Epoch 6/10, Batch 70/145, Loss: 0.4008
Epoch 6/10, Batch 80/145, Loss: 0.2866
Epoch 6/10, Batch 90/145, Loss: 0.2436
Epoch 6/10, Batch 100/145, Loss: 0.1802
Epoch 6/10, Batch 110/145, Loss: 0.1257
Epoch 6/10, Batch 120/145, Loss: 0.1644
Epoch 6/10, Batch 130/145, Loss: 0.1743
Epoch 6/10, Batch 140/145, Loss: 0.1584
Epoch 6/10, Train Loss: 0.2283, Valid Loss: 0.2503
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2119
Epoch 7/10, Batch 20/145, Loss: 0.2164
Epoch 7/10, Batch 30/145, Loss: 0.1941
Epoch 7/10, Batch 40/145, Loss: 0.4715
Epoch 7/10, Batch 50/145, Loss: 0.2700
Epoch 7/10, Batch 60/145, Loss: 0.1508
Epoch 7/10, Batch 70/145, Loss: 0.1605
Epoch 7/10, Batch 80/145, Loss: 0.1051
Epoch 7/10, Batch 90/145, Loss: 0.2151
Epoch 7/10, Batch 100/145, Loss: 0.1840
Epoch 7/10, Batch 110/145, Loss: 0.1603
Epoch 7/10, Batch 120/145, Loss: 0.1649
Epoch 7/10, Batch 130/145, Loss: 0.2569
Epoch 7/10, Batch 140/145, Loss: 0.1426
Epoch 7/10, Train Loss: 0.2175, Valid Loss: 0.2493
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2407
Epoch 8/10, Batch 20/145, Loss: 0.1176
Epoch 8/10, Batch 30/145, Loss: 0.2067
Epoch 8/10, Batch 40/145, Loss: 0.1798
Epoch 8/10, Batch 50/145, Loss: 0.1951
Epoch 8/10, Batch 60/145, Loss: 0.1899
Epoch 8/10, Batch 70/145, Loss: 0.2100
Epoch 8/10, Batch 80/145, Loss: 0.1932
Epoch 8/10, Batch 90/145, Loss: 0.1823
Epoch 8/10, Batch 100/145, Loss: 0.1940
Epoch 8/10, Batch 110/145, Loss: 0.1966
Epoch 8/10, Batch 120/145, Loss: 0.1258
Epoch 8/10, Batch 130/145, Loss: 0.1051
Epoch 8/10, Batch 140/145, Loss: 0.1929
Epoch 8/10, Train Loss: 0.2035, Valid Loss: 0.2377
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1425
Epoch 9/10, Batch 20/145, Loss: 0.1659
Epoch 9/10, Batch 30/145, Loss: 0.2452
Epoch 9/10, Batch 40/145, Loss: 0.1855
Epoch 9/10, Batch 50/145, Loss: 0.1802
Epoch 9/10, Batch 60/145, Loss: 0.1945
Epoch 9/10, Batch 70/145, Loss: 0.1096
Epoch 9/10, Batch 80/145, Loss: 0.2244
Epoch 9/10, Batch 90/145, Loss: 0.1605
Epoch 9/10, Batch 100/145, Loss: 0.2554
Epoch 9/10, Batch 110/145, Loss: 0.1383
Epoch 9/10, Batch 120/145, Loss: 0.3140
Epoch 9/10, Batch 130/145, Loss: 0.1337
Epoch 9/10, Batch 140/145, Loss: 0.1045
Epoch 9/10, Train Loss: 0.2001, Valid Loss: 0.2373
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1453
Epoch 10/10, Batch 20/145, Loss: 0.2681
Epoch 10/10, Batch 30/145, Loss: 0.0778
Epoch 10/10, Batch 40/145, Loss: 0.2300
Epoch 10/10, Batch 50/145, Loss: 0.2276
Epoch 10/10, Batch 60/145, Loss: 0.1457
Epoch 10/10, Batch 70/145, Loss: 0.1188
Epoch 10/10, Batch 80/145, Loss: 0.4041
Epoch 10/10, Batch 90/145, Loss: 0.0926
Epoch 10/10, Batch 100/145, Loss: 0.1367
Epoch 10/10, Batch 110/145, Loss: 0.2043
Epoch 10/10, Batch 120/145, Loss: 0.2153
Epoch 10/10, Batch 130/145, Loss: 0.1657
Epoch 10/10, Batch 140/145, Loss: 0.3931
Epoch 10/10, Train Loss: 0.1949, Valid Loss: 0.2292
Model saved!
Accuracy: 0.9252
Precision: 0.9230
Recall: 0.9252
F1-score: 0.9234
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5843
Epoch 1/10, Batch 20/145, Loss: 0.9727
Epoch 1/10, Batch 30/145, Loss: 0.8023
Epoch 1/10, Batch 40/145, Loss: 0.8906
Epoch 1/10, Batch 50/145, Loss: 0.7118
Epoch 1/10, Batch 60/145, Loss: 0.5762
Epoch 1/10, Batch 70/145, Loss: 0.6399
Epoch 1/10, Batch 80/145, Loss: 0.4471
Epoch 1/10, Batch 90/145, Loss: 0.5168
Epoch 1/10, Batch 100/145, Loss: 0.4767
Epoch 1/10, Batch 110/145, Loss: 0.4986
Epoch 1/10, Batch 120/145, Loss: 0.4732
Epoch 1/10, Batch 130/145, Loss: 0.3970
Epoch 1/10, Batch 140/145, Loss: 0.4816
Epoch 1/10, Train Loss: 0.6990, Valid Loss: 0.3704
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4464
Epoch 2/10, Batch 20/145, Loss: 0.3676
Epoch 2/10, Batch 30/145, Loss: 0.3627
Epoch 2/10, Batch 40/145, Loss: 0.5422
Epoch 2/10, Batch 50/145, Loss: 0.3500
Epoch 2/10, Batch 60/145, Loss: 0.4535
Epoch 2/10, Batch 70/145, Loss: 0.4460
Epoch 2/10, Batch 80/145, Loss: 0.4281
Epoch 2/10, Batch 90/145, Loss: 0.2956
Epoch 2/10, Batch 100/145, Loss: 0.3229
Epoch 2/10, Batch 110/145, Loss: 0.3399
Epoch 2/10, Batch 120/145, Loss: 0.3312
Epoch 2/10, Batch 130/145, Loss: 0.4343
Epoch 2/10, Batch 140/145, Loss: 0.1925
Epoch 2/10, Train Loss: 0.3726, Valid Loss: 0.2809
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1926
Epoch 3/10, Batch 20/145, Loss: 0.3803
Epoch 3/10, Batch 30/145, Loss: 0.2042
Epoch 3/10, Batch 40/145, Loss: 0.2120
Epoch 3/10, Batch 50/145, Loss: 0.2797
Epoch 3/10, Batch 60/145, Loss: 0.2217
Epoch 3/10, Batch 70/145, Loss: 0.2533
Epoch 3/10, Batch 80/145, Loss: 0.4751
Epoch 3/10, Batch 90/145, Loss: 0.4418
Epoch 3/10, Batch 100/145, Loss: 0.2584
Epoch 3/10, Batch 110/145, Loss: 0.3655
Epoch 3/10, Batch 120/145, Loss: 0.2182
Epoch 3/10, Batch 130/145, Loss: 0.2509
Epoch 3/10, Batch 140/145, Loss: 0.1844
Epoch 3/10, Train Loss: 0.3143, Valid Loss: 0.2450
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2391
Epoch 4/10, Batch 20/145, Loss: 0.2276
Epoch 4/10, Batch 30/145, Loss: 0.2911
Epoch 4/10, Batch 40/145, Loss: 0.3752
Epoch 4/10, Batch 50/145, Loss: 0.1733
Epoch 4/10, Batch 60/145, Loss: 0.2948
Epoch 4/10, Batch 70/145, Loss: 0.1401
Epoch 4/10, Batch 80/145, Loss: 0.2583
Epoch 4/10, Batch 90/145, Loss: 0.2300
Epoch 4/10, Batch 100/145, Loss: 0.2389
Epoch 4/10, Batch 110/145, Loss: 0.2075
Epoch 4/10, Batch 120/145, Loss: 0.2198
Epoch 4/10, Batch 130/145, Loss: 0.3319
Epoch 4/10, Batch 140/145, Loss: 0.1627
Epoch 4/10, Train Loss: 0.2694, Valid Loss: 0.2380
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2487
Epoch 5/10, Batch 20/145, Loss: 0.1234
Epoch 5/10, Batch 30/145, Loss: 0.2424
Epoch 5/10, Batch 40/145, Loss: 0.2953
Epoch 5/10, Batch 50/145, Loss: 0.1517
Epoch 5/10, Batch 60/145, Loss: 0.1989
Epoch 5/10, Batch 70/145, Loss: 0.2752
Epoch 5/10, Batch 80/145, Loss: 0.2212
Epoch 5/10, Batch 90/145, Loss: 0.1584
Epoch 5/10, Batch 100/145, Loss: 0.2640
Epoch 5/10, Batch 110/145, Loss: 0.1108
Epoch 5/10, Batch 120/145, Loss: 0.2431
Epoch 5/10, Batch 130/145, Loss: 0.2373
Epoch 5/10, Batch 140/145, Loss: 0.4789
Epoch 5/10, Train Loss: 0.2440, Valid Loss: 0.2238
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2194
Epoch 6/10, Batch 20/145, Loss: 0.1785
Epoch 6/10, Batch 30/145, Loss: 0.1393
Epoch 6/10, Batch 40/145, Loss: 0.1936
Epoch 6/10, Batch 50/145, Loss: 0.3389
Epoch 6/10, Batch 60/145, Loss: 0.3407
Epoch 6/10, Batch 70/145, Loss: 0.2675
Epoch 6/10, Batch 80/145, Loss: 0.3658
Epoch 6/10, Batch 90/145, Loss: 0.1853
Epoch 6/10, Batch 100/145, Loss: 0.2027
Epoch 6/10, Batch 110/145, Loss: 0.2147
Epoch 6/10, Batch 120/145, Loss: 0.1734
Epoch 6/10, Batch 130/145, Loss: 0.0958
Epoch 6/10, Batch 140/145, Loss: 0.3135
Epoch 6/10, Train Loss: 0.2332, Valid Loss: 0.2144
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1467
Epoch 7/10, Batch 20/145, Loss: 0.1761
Epoch 7/10, Batch 30/145, Loss: 0.1456
Epoch 7/10, Batch 40/145, Loss: 0.3541
Epoch 7/10, Batch 50/145, Loss: 0.1640
Epoch 7/10, Batch 60/145, Loss: 0.1406
Epoch 7/10, Batch 70/145, Loss: 0.1839
Epoch 7/10, Batch 80/145, Loss: 0.1275
Epoch 7/10, Batch 90/145, Loss: 0.2645
Epoch 7/10, Batch 100/145, Loss: 0.2611
Epoch 7/10, Batch 110/145, Loss: 0.4522
Epoch 7/10, Batch 120/145, Loss: 0.2323
Epoch 7/10, Batch 130/145, Loss: 0.1324
Epoch 7/10, Batch 140/145, Loss: 0.2293
Epoch 7/10, Train Loss: 0.2248, Valid Loss: 0.2070
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1774
Epoch 8/10, Batch 20/145, Loss: 0.1321
Epoch 8/10, Batch 30/145, Loss: 0.2158
Epoch 8/10, Batch 40/145, Loss: 0.2868
Epoch 8/10, Batch 50/145, Loss: 0.2313
Epoch 8/10, Batch 60/145, Loss: 0.2195
Epoch 8/10, Batch 70/145, Loss: 0.2317
Epoch 8/10, Batch 80/145, Loss: 0.1493
Epoch 8/10, Batch 90/145, Loss: 0.1322
Epoch 8/10, Batch 100/145, Loss: 0.1720
Epoch 8/10, Batch 110/145, Loss: 0.2730
Epoch 8/10, Batch 120/145, Loss: 0.1985
Epoch 8/10, Batch 130/145, Loss: 0.2054
Epoch 8/10, Batch 140/145, Loss: 0.3243
Epoch 8/10, Train Loss: 0.2169, Valid Loss: 0.2009
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1826
Epoch 9/10, Batch 20/145, Loss: 0.1566
Epoch 9/10, Batch 30/145, Loss: 0.1619
Epoch 9/10, Batch 40/145, Loss: 0.2451
Epoch 9/10, Batch 50/145, Loss: 0.2865
Epoch 9/10, Batch 60/145, Loss: 0.1848
Epoch 9/10, Batch 70/145, Loss: 0.1198
Epoch 9/10, Batch 80/145, Loss: 0.2021
Epoch 9/10, Batch 90/145, Loss: 0.1806
Epoch 9/10, Batch 100/145, Loss: 0.2490
Epoch 9/10, Batch 110/145, Loss: 0.1857
Epoch 9/10, Batch 120/145, Loss: 0.1693
Epoch 9/10, Batch 130/145, Loss: 0.2329
Epoch 9/10, Batch 140/145, Loss: 0.2258
Epoch 9/10, Train Loss: 0.2072, Valid Loss: 0.2005
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0973
Epoch 10/10, Batch 20/145, Loss: 0.1085
Epoch 10/10, Batch 30/145, Loss: 0.1036
Epoch 10/10, Batch 40/145, Loss: 0.3119
Epoch 10/10, Batch 50/145, Loss: 0.4959
Epoch 10/10, Batch 60/145, Loss: 0.1911
Epoch 10/10, Batch 70/145, Loss: 0.1333
Epoch 10/10, Batch 80/145, Loss: 0.4499
Epoch 10/10, Batch 90/145, Loss: 0.1424
Epoch 10/10, Batch 100/145, Loss: 0.1143
Epoch 10/10, Batch 110/145, Loss: 0.2001
Epoch 10/10, Batch 120/145, Loss: 0.1074
Epoch 10/10, Batch 130/145, Loss: 0.1263
Epoch 10/10, Batch 140/145, Loss: 0.3701
Epoch 10/10, Train Loss: 0.2014, Valid Loss: 0.1995
Model saved!
Accuracy: 0.9206
Precision: 0.9197
Recall: 0.9206
F1-score: 0.9200
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5289
Epoch 1/10, Batch 20/145, Loss: 0.8489
Epoch 1/10, Batch 30/145, Loss: 0.8332
Epoch 1/10, Batch 40/145, Loss: 0.7746
Epoch 1/10, Batch 50/145, Loss: 0.5641
Epoch 1/10, Batch 60/145, Loss: 0.5447
Epoch 1/10, Batch 70/145, Loss: 0.7249
Epoch 1/10, Batch 80/145, Loss: 0.5911
Epoch 1/10, Batch 90/145, Loss: 0.5071
Epoch 1/10, Batch 100/145, Loss: 0.7066
Epoch 1/10, Batch 110/145, Loss: 0.3347
Epoch 1/10, Batch 120/145, Loss: 0.6895
Epoch 1/10, Batch 130/145, Loss: 0.3111
Epoch 1/10, Batch 140/145, Loss: 0.4701
Epoch 1/10, Train Loss: 0.6952, Valid Loss: 0.3774
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4121
Epoch 2/10, Batch 20/145, Loss: 0.4547
Epoch 2/10, Batch 30/145, Loss: 0.3759
Epoch 2/10, Batch 40/145, Loss: 0.4592
Epoch 2/10, Batch 50/145, Loss: 0.3439
Epoch 2/10, Batch 60/145, Loss: 0.4419
Epoch 2/10, Batch 70/145, Loss: 0.3632
Epoch 2/10, Batch 80/145, Loss: 0.2350
Epoch 2/10, Batch 90/145, Loss: 0.2280
Epoch 2/10, Batch 100/145, Loss: 0.2453
Epoch 2/10, Batch 110/145, Loss: 0.3592
Epoch 2/10, Batch 120/145, Loss: 0.3281
Epoch 2/10, Batch 130/145, Loss: 0.3340
Epoch 2/10, Batch 140/145, Loss: 0.2242
Epoch 2/10, Train Loss: 0.3660, Valid Loss: 0.2905
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1647
Epoch 3/10, Batch 20/145, Loss: 0.4202
Epoch 3/10, Batch 30/145, Loss: 0.3122
Epoch 3/10, Batch 40/145, Loss: 0.2772
Epoch 3/10, Batch 50/145, Loss: 0.1253
Epoch 3/10, Batch 60/145, Loss: 0.3604
Epoch 3/10, Batch 70/145, Loss: 0.1334
Epoch 3/10, Batch 80/145, Loss: 0.2633
Epoch 3/10, Batch 90/145, Loss: 0.4739
Epoch 3/10, Batch 100/145, Loss: 0.2470
Epoch 3/10, Batch 110/145, Loss: 0.2926
Epoch 3/10, Batch 120/145, Loss: 0.2761
Epoch 3/10, Batch 130/145, Loss: 0.3583
Epoch 3/10, Batch 140/145, Loss: 0.2768
Epoch 3/10, Train Loss: 0.3115, Valid Loss: 0.2681
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1946
Epoch 4/10, Batch 20/145, Loss: 0.1932
Epoch 4/10, Batch 30/145, Loss: 0.1937
Epoch 4/10, Batch 40/145, Loss: 0.3315
Epoch 4/10, Batch 50/145, Loss: 0.2151
Epoch 4/10, Batch 60/145, Loss: 0.3274
Epoch 4/10, Batch 70/145, Loss: 0.3295
Epoch 4/10, Batch 80/145, Loss: 0.2593
Epoch 4/10, Batch 90/145, Loss: 0.3047
Epoch 4/10, Batch 100/145, Loss: 0.3317
Epoch 4/10, Batch 110/145, Loss: 0.2704
Epoch 4/10, Batch 120/145, Loss: 0.1285
Epoch 4/10, Batch 130/145, Loss: 0.1726
Epoch 4/10, Batch 140/145, Loss: 0.1317
Epoch 4/10, Train Loss: 0.2725, Valid Loss: 0.2587
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1867
Epoch 5/10, Batch 20/145, Loss: 0.1606
Epoch 5/10, Batch 30/145, Loss: 0.1873
Epoch 5/10, Batch 40/145, Loss: 0.1924
Epoch 5/10, Batch 50/145, Loss: 0.1367
Epoch 5/10, Batch 60/145, Loss: 0.1555
Epoch 5/10, Batch 70/145, Loss: 0.3260
Epoch 5/10, Batch 80/145, Loss: 0.3540
Epoch 5/10, Batch 90/145, Loss: 0.2839
Epoch 5/10, Batch 100/145, Loss: 0.2440
Epoch 5/10, Batch 110/145, Loss: 0.1660
Epoch 5/10, Batch 120/145, Loss: 0.2822
Epoch 5/10, Batch 130/145, Loss: 0.2096
Epoch 5/10, Batch 140/145, Loss: 0.3087
Epoch 5/10, Train Loss: 0.2421, Valid Loss: 0.2373
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1546
Epoch 6/10, Batch 20/145, Loss: 0.2959
Epoch 6/10, Batch 30/145, Loss: 0.2583
Epoch 6/10, Batch 40/145, Loss: 0.1347
Epoch 6/10, Batch 50/145, Loss: 0.1553
Epoch 6/10, Batch 60/145, Loss: 0.0824
Epoch 6/10, Batch 70/145, Loss: 0.2647
Epoch 6/10, Batch 80/145, Loss: 0.4085
Epoch 6/10, Batch 90/145, Loss: 0.3394
Epoch 6/10, Batch 100/145, Loss: 0.2685
Epoch 6/10, Batch 110/145, Loss: 0.1676
Epoch 6/10, Batch 120/145, Loss: 0.2190
Epoch 6/10, Batch 130/145, Loss: 0.2807
Epoch 6/10, Batch 140/145, Loss: 0.5451
Epoch 6/10, Train Loss: 0.2330, Valid Loss: 0.2343
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3216
Epoch 7/10, Batch 20/145, Loss: 0.2726
Epoch 7/10, Batch 30/145, Loss: 0.4178
Epoch 7/10, Batch 40/145, Loss: 0.3503
Epoch 7/10, Batch 50/145, Loss: 0.2060
Epoch 7/10, Batch 60/145, Loss: 0.3051
Epoch 7/10, Batch 70/145, Loss: 0.2280
Epoch 7/10, Batch 80/145, Loss: 0.0861
Epoch 7/10, Batch 90/145, Loss: 0.2616
Epoch 7/10, Batch 100/145, Loss: 0.1247
Epoch 7/10, Batch 110/145, Loss: 0.2289
Epoch 7/10, Batch 120/145, Loss: 0.1803
Epoch 7/10, Batch 130/145, Loss: 0.2954
Epoch 7/10, Batch 140/145, Loss: 0.1461
Epoch 7/10, Train Loss: 0.2290, Valid Loss: 0.2357
Epoch 8/10, Batch 10/145, Loss: 0.3171
Epoch 8/10, Batch 20/145, Loss: 0.1317
Epoch 8/10, Batch 30/145, Loss: 0.1725
Epoch 8/10, Batch 40/145, Loss: 0.2579
Epoch 8/10, Batch 50/145, Loss: 0.2487
Epoch 8/10, Batch 60/145, Loss: 0.3051
Epoch 8/10, Batch 70/145, Loss: 0.2652
Epoch 8/10, Batch 80/145, Loss: 0.2507
Epoch 8/10, Batch 90/145, Loss: 0.0826
Epoch 8/10, Batch 100/145, Loss: 0.3104
Epoch 8/10, Batch 110/145, Loss: 0.2324
Epoch 8/10, Batch 120/145, Loss: 0.1808
Epoch 8/10, Batch 130/145, Loss: 0.1996
Epoch 8/10, Batch 140/145, Loss: 0.4256
Epoch 8/10, Train Loss: 0.2150, Valid Loss: 0.2210
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3004
Epoch 9/10, Batch 20/145, Loss: 0.2162
Epoch 9/10, Batch 30/145, Loss: 0.2434
Epoch 9/10, Batch 40/145, Loss: 0.2138
Epoch 9/10, Batch 50/145, Loss: 0.1264
Epoch 9/10, Batch 60/145, Loss: 0.1569
Epoch 9/10, Batch 70/145, Loss: 0.2276
Epoch 9/10, Batch 80/145, Loss: 0.2475
Epoch 9/10, Batch 90/145, Loss: 0.1975
Epoch 9/10, Batch 100/145, Loss: 0.3791
Epoch 9/10, Batch 110/145, Loss: 0.1222
Epoch 9/10, Batch 120/145, Loss: 0.2262
Epoch 9/10, Batch 130/145, Loss: 0.2434
Epoch 9/10, Batch 140/145, Loss: 0.1317
Epoch 9/10, Train Loss: 0.2037, Valid Loss: 0.2172
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1993
Epoch 10/10, Batch 20/145, Loss: 0.3164
Epoch 10/10, Batch 30/145, Loss: 0.1353
Epoch 10/10, Batch 40/145, Loss: 0.1555
Epoch 10/10, Batch 50/145, Loss: 0.2387
Epoch 10/10, Batch 60/145, Loss: 0.1304
Epoch 10/10, Batch 70/145, Loss: 0.1557
Epoch 10/10, Batch 80/145, Loss: 0.2699
Epoch 10/10, Batch 90/145, Loss: 0.2980
Epoch 10/10, Batch 100/145, Loss: 0.1570
Epoch 10/10, Batch 110/145, Loss: 0.3124
Epoch 10/10, Batch 120/145, Loss: 0.1401
Epoch 10/10, Batch 130/145, Loss: 0.2890
Epoch 10/10, Batch 140/145, Loss: 0.2098
Epoch 10/10, Train Loss: 0.1970, Valid Loss: 0.2114
Model saved!
Accuracy: 0.9276
Precision: 0.9282
Recall: 0.9276
F1-score: 0.9276
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4874
Epoch 1/10, Batch 20/145, Loss: 0.8541
Epoch 1/10, Batch 30/145, Loss: 0.8329
Epoch 1/10, Batch 40/145, Loss: 0.8650
Epoch 1/10, Batch 50/145, Loss: 0.5923
Epoch 1/10, Batch 60/145, Loss: 0.4947
Epoch 1/10, Batch 70/145, Loss: 0.7226
Epoch 1/10, Batch 80/145, Loss: 0.5511
Epoch 1/10, Batch 90/145, Loss: 0.5113
Epoch 1/10, Batch 100/145, Loss: 0.6407
Epoch 1/10, Batch 110/145, Loss: 0.4298
Epoch 1/10, Batch 120/145, Loss: 0.6286
Epoch 1/10, Batch 130/145, Loss: 0.4036
Epoch 1/10, Batch 140/145, Loss: 0.4181
Epoch 1/10, Train Loss: 0.6865, Valid Loss: 0.3781
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2515
Epoch 2/10, Batch 20/145, Loss: 0.5189
Epoch 2/10, Batch 30/145, Loss: 0.2340
Epoch 2/10, Batch 40/145, Loss: 0.3280
Epoch 2/10, Batch 50/145, Loss: 0.2762
Epoch 2/10, Batch 60/145, Loss: 0.5765
Epoch 2/10, Batch 70/145, Loss: 0.4991
Epoch 2/10, Batch 80/145, Loss: 0.3406
Epoch 2/10, Batch 90/145, Loss: 0.2755
Epoch 2/10, Batch 100/145, Loss: 0.2768
Epoch 2/10, Batch 110/145, Loss: 0.2027
Epoch 2/10, Batch 120/145, Loss: 0.3694
Epoch 2/10, Batch 130/145, Loss: 0.3703
Epoch 2/10, Batch 140/145, Loss: 0.2166
Epoch 2/10, Train Loss: 0.3609, Valid Loss: 0.2924
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2255
Epoch 3/10, Batch 20/145, Loss: 0.3195
Epoch 3/10, Batch 30/145, Loss: 0.3053
Epoch 3/10, Batch 40/145, Loss: 0.2270
Epoch 3/10, Batch 50/145, Loss: 0.2491
Epoch 3/10, Batch 60/145, Loss: 0.2213
Epoch 3/10, Batch 70/145, Loss: 0.2788
Epoch 3/10, Batch 80/145, Loss: 0.3283
Epoch 3/10, Batch 90/145, Loss: 0.5528
Epoch 3/10, Batch 100/145, Loss: 0.1926
Epoch 3/10, Batch 110/145, Loss: 0.2420
Epoch 3/10, Batch 120/145, Loss: 0.1850
Epoch 3/10, Batch 130/145, Loss: 0.2070
Epoch 3/10, Batch 140/145, Loss: 0.2248
Epoch 3/10, Train Loss: 0.3040, Valid Loss: 0.2654
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1883
Epoch 4/10, Batch 20/145, Loss: 0.3074
Epoch 4/10, Batch 30/145, Loss: 0.1747
Epoch 4/10, Batch 40/145, Loss: 0.3772
Epoch 4/10, Batch 50/145, Loss: 0.1911
Epoch 4/10, Batch 60/145, Loss: 0.1681
Epoch 4/10, Batch 70/145, Loss: 0.3010
Epoch 4/10, Batch 80/145, Loss: 0.2713
Epoch 4/10, Batch 90/145, Loss: 0.2762
Epoch 4/10, Batch 100/145, Loss: 0.2351
Epoch 4/10, Batch 110/145, Loss: 0.2136
Epoch 4/10, Batch 120/145, Loss: 0.2269
Epoch 4/10, Batch 130/145, Loss: 0.2948
Epoch 4/10, Batch 140/145, Loss: 0.1865
Epoch 4/10, Train Loss: 0.2555, Valid Loss: 0.2521
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1672
Epoch 5/10, Batch 20/145, Loss: 0.1116
Epoch 5/10, Batch 30/145, Loss: 0.1491
Epoch 5/10, Batch 40/145, Loss: 0.1768
Epoch 5/10, Batch 50/145, Loss: 0.1540
Epoch 5/10, Batch 60/145, Loss: 0.2468
Epoch 5/10, Batch 70/145, Loss: 0.1983
Epoch 5/10, Batch 80/145, Loss: 0.3139
Epoch 5/10, Batch 90/145, Loss: 0.2462
Epoch 5/10, Batch 100/145, Loss: 0.2793
Epoch 5/10, Batch 110/145, Loss: 0.0957
Epoch 5/10, Batch 120/145, Loss: 0.2571
Epoch 5/10, Batch 130/145, Loss: 0.0948
Epoch 5/10, Batch 140/145, Loss: 0.1412
Epoch 5/10, Train Loss: 0.2377, Valid Loss: 0.2454
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2997
Epoch 6/10, Batch 20/145, Loss: 0.2381
Epoch 6/10, Batch 30/145, Loss: 0.2508
Epoch 6/10, Batch 40/145, Loss: 0.1119
Epoch 6/10, Batch 50/145, Loss: 0.2960
Epoch 6/10, Batch 60/145, Loss: 0.1259
Epoch 6/10, Batch 70/145, Loss: 0.2172
Epoch 6/10, Batch 80/145, Loss: 0.2764
Epoch 6/10, Batch 90/145, Loss: 0.2107
Epoch 6/10, Batch 100/145, Loss: 0.1784
Epoch 6/10, Batch 110/145, Loss: 0.0972
Epoch 6/10, Batch 120/145, Loss: 0.2485
Epoch 6/10, Batch 130/145, Loss: 0.1934
Epoch 6/10, Batch 140/145, Loss: 0.3218
Epoch 6/10, Train Loss: 0.2251, Valid Loss: 0.2358
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2823
Epoch 7/10, Batch 20/145, Loss: 0.1743
Epoch 7/10, Batch 30/145, Loss: 0.3228
Epoch 7/10, Batch 40/145, Loss: 0.4568
Epoch 7/10, Batch 50/145, Loss: 0.2254
Epoch 7/10, Batch 60/145, Loss: 0.0836
Epoch 7/10, Batch 70/145, Loss: 0.2839
Epoch 7/10, Batch 80/145, Loss: 0.2417
Epoch 7/10, Batch 90/145, Loss: 0.1561
Epoch 7/10, Batch 100/145, Loss: 0.3336
Epoch 7/10, Batch 110/145, Loss: 0.2514
Epoch 7/10, Batch 120/145, Loss: 0.1468
Epoch 7/10, Batch 130/145, Loss: 0.0911
Epoch 7/10, Batch 140/145, Loss: 0.1955
Epoch 7/10, Train Loss: 0.2147, Valid Loss: 0.2279
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0968
Epoch 8/10, Batch 20/145, Loss: 0.2012
Epoch 8/10, Batch 30/145, Loss: 0.1660
Epoch 8/10, Batch 40/145, Loss: 0.2739
Epoch 8/10, Batch 50/145, Loss: 0.1153
Epoch 8/10, Batch 60/145, Loss: 0.2767
Epoch 8/10, Batch 70/145, Loss: 0.1122
Epoch 8/10, Batch 80/145, Loss: 0.1565
Epoch 8/10, Batch 90/145, Loss: 0.2103
Epoch 8/10, Batch 100/145, Loss: 0.2853
Epoch 8/10, Batch 110/145, Loss: 0.1859
Epoch 8/10, Batch 120/145, Loss: 0.0919
Epoch 8/10, Batch 130/145, Loss: 0.1794
Epoch 8/10, Batch 140/145, Loss: 0.1619
Epoch 8/10, Train Loss: 0.2062, Valid Loss: 0.2204
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2305
Epoch 9/10, Batch 20/145, Loss: 0.0951
Epoch 9/10, Batch 30/145, Loss: 0.0859
Epoch 9/10, Batch 40/145, Loss: 0.2524
Epoch 9/10, Batch 50/145, Loss: 0.1937
Epoch 9/10, Batch 60/145, Loss: 0.2144
Epoch 9/10, Batch 70/145, Loss: 0.2381
Epoch 9/10, Batch 80/145, Loss: 0.3416
Epoch 9/10, Batch 90/145, Loss: 0.0729
Epoch 9/10, Batch 100/145, Loss: 0.1232
Epoch 9/10, Batch 110/145, Loss: 0.0975
Epoch 9/10, Batch 120/145, Loss: 0.1632
Epoch 9/10, Batch 130/145, Loss: 0.0914
Epoch 9/10, Batch 140/145, Loss: 0.0850
Epoch 9/10, Train Loss: 0.2015, Valid Loss: 0.2123
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1118
Epoch 10/10, Batch 20/145, Loss: 0.2154
Epoch 10/10, Batch 30/145, Loss: 0.0890
Epoch 10/10, Batch 40/145, Loss: 0.4215
Epoch 10/10, Batch 50/145, Loss: 0.2073
Epoch 10/10, Batch 60/145, Loss: 0.1753
Epoch 10/10, Batch 70/145, Loss: 0.1781
Epoch 10/10, Batch 80/145, Loss: 0.4070
Epoch 10/10, Batch 90/145, Loss: 0.4688
Epoch 10/10, Batch 100/145, Loss: 0.0990
Epoch 10/10, Batch 110/145, Loss: 0.0864
Epoch 10/10, Batch 120/145, Loss: 0.1327
Epoch 10/10, Batch 130/145, Loss: 0.1409
Epoch 10/10, Batch 140/145, Loss: 0.1885
Epoch 10/10, Train Loss: 0.1942, Valid Loss: 0.2136
Accuracy: 0.9182
Precision: 0.9152
Recall: 0.9182
F1-score: 0.9157
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5410
Epoch 1/10, Batch 20/145, Loss: 0.8117
Epoch 1/10, Batch 30/145, Loss: 0.9077
Epoch 1/10, Batch 40/145, Loss: 0.8552
Epoch 1/10, Batch 50/145, Loss: 0.6488
Epoch 1/10, Batch 60/145, Loss: 0.6308
Epoch 1/10, Batch 70/145, Loss: 0.6345
Epoch 1/10, Batch 80/145, Loss: 0.4959
Epoch 1/10, Batch 90/145, Loss: 0.4988
Epoch 1/10, Batch 100/145, Loss: 0.6907
Epoch 1/10, Batch 110/145, Loss: 0.3586
Epoch 1/10, Batch 120/145, Loss: 0.4946
Epoch 1/10, Batch 130/145, Loss: 0.3090
Epoch 1/10, Batch 140/145, Loss: 0.3909
Epoch 1/10, Train Loss: 0.6848, Valid Loss: 0.3784
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2636
Epoch 2/10, Batch 20/145, Loss: 0.5007
Epoch 2/10, Batch 30/145, Loss: 0.4652
Epoch 2/10, Batch 40/145, Loss: 0.5021
Epoch 2/10, Batch 50/145, Loss: 0.2861
Epoch 2/10, Batch 60/145, Loss: 0.4191
Epoch 2/10, Batch 70/145, Loss: 0.4235
Epoch 2/10, Batch 80/145, Loss: 0.3522
Epoch 2/10, Batch 90/145, Loss: 0.2201
Epoch 2/10, Batch 100/145, Loss: 0.2795
Epoch 2/10, Batch 110/145, Loss: 0.2340
Epoch 2/10, Batch 120/145, Loss: 0.3401
Epoch 2/10, Batch 130/145, Loss: 0.3676
Epoch 2/10, Batch 140/145, Loss: 0.2693
Epoch 2/10, Train Loss: 0.3622, Valid Loss: 0.2948
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2182
Epoch 3/10, Batch 20/145, Loss: 0.4588
Epoch 3/10, Batch 30/145, Loss: 0.3013
Epoch 3/10, Batch 40/145, Loss: 0.3532
Epoch 3/10, Batch 50/145, Loss: 0.2017
Epoch 3/10, Batch 60/145, Loss: 0.3234
Epoch 3/10, Batch 70/145, Loss: 0.2137
Epoch 3/10, Batch 80/145, Loss: 0.2418
Epoch 3/10, Batch 90/145, Loss: 0.5472
Epoch 3/10, Batch 100/145, Loss: 0.3370
Epoch 3/10, Batch 110/145, Loss: 0.2226
Epoch 3/10, Batch 120/145, Loss: 0.1309
Epoch 3/10, Batch 130/145, Loss: 0.2769
Epoch 3/10, Batch 140/145, Loss: 0.3040
Epoch 3/10, Train Loss: 0.3090, Valid Loss: 0.2645
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1919
Epoch 4/10, Batch 20/145, Loss: 0.2949
Epoch 4/10, Batch 30/145, Loss: 0.3708
Epoch 4/10, Batch 40/145, Loss: 0.6450
Epoch 4/10, Batch 50/145, Loss: 0.2247
Epoch 4/10, Batch 60/145, Loss: 0.1756
Epoch 4/10, Batch 70/145, Loss: 0.1965
Epoch 4/10, Batch 80/145, Loss: 0.3160
Epoch 4/10, Batch 90/145, Loss: 0.2170
Epoch 4/10, Batch 100/145, Loss: 0.2775
Epoch 4/10, Batch 110/145, Loss: 0.1646
Epoch 4/10, Batch 120/145, Loss: 0.2963
Epoch 4/10, Batch 130/145, Loss: 0.1874
Epoch 4/10, Batch 140/145, Loss: 0.2874
Epoch 4/10, Train Loss: 0.2610, Valid Loss: 0.2581
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1167
Epoch 5/10, Batch 20/145, Loss: 0.1738
Epoch 5/10, Batch 30/145, Loss: 0.1769
Epoch 5/10, Batch 40/145, Loss: 0.2384
Epoch 5/10, Batch 50/145, Loss: 0.1166
Epoch 5/10, Batch 60/145, Loss: 0.3133
Epoch 5/10, Batch 70/145, Loss: 0.3604
Epoch 5/10, Batch 80/145, Loss: 0.2901
Epoch 5/10, Batch 90/145, Loss: 0.2595
Epoch 5/10, Batch 100/145, Loss: 0.2120
Epoch 5/10, Batch 110/145, Loss: 0.2086
Epoch 5/10, Batch 120/145, Loss: 0.2371
Epoch 5/10, Batch 130/145, Loss: 0.1462
Epoch 5/10, Batch 140/145, Loss: 0.3204
Epoch 5/10, Train Loss: 0.2439, Valid Loss: 0.2382
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2673
Epoch 6/10, Batch 20/145, Loss: 0.3142
Epoch 6/10, Batch 30/145, Loss: 0.3338
Epoch 6/10, Batch 40/145, Loss: 0.3382
Epoch 6/10, Batch 50/145, Loss: 0.4123
Epoch 6/10, Batch 60/145, Loss: 0.2089
Epoch 6/10, Batch 70/145, Loss: 0.2536
Epoch 6/10, Batch 80/145, Loss: 0.2545
Epoch 6/10, Batch 90/145, Loss: 0.2039
Epoch 6/10, Batch 100/145, Loss: 0.1825
Epoch 6/10, Batch 110/145, Loss: 0.1085
Epoch 6/10, Batch 120/145, Loss: 0.2270
Epoch 6/10, Batch 130/145, Loss: 0.1971
Epoch 6/10, Batch 140/145, Loss: 0.2006
Epoch 6/10, Train Loss: 0.2277, Valid Loss: 0.2285
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1867
Epoch 7/10, Batch 20/145, Loss: 0.2005
Epoch 7/10, Batch 30/145, Loss: 0.1124
Epoch 7/10, Batch 40/145, Loss: 0.6397
Epoch 7/10, Batch 50/145, Loss: 0.1077
Epoch 7/10, Batch 60/145, Loss: 0.1268
Epoch 7/10, Batch 70/145, Loss: 0.2371
Epoch 7/10, Batch 80/145, Loss: 0.1050
Epoch 7/10, Batch 90/145, Loss: 0.1091
Epoch 7/10, Batch 100/145, Loss: 0.2115
Epoch 7/10, Batch 110/145, Loss: 0.1790
Epoch 7/10, Batch 120/145, Loss: 0.0817
Epoch 7/10, Batch 130/145, Loss: 0.3463
Epoch 7/10, Batch 140/145, Loss: 0.2095
Epoch 7/10, Train Loss: 0.2168, Valid Loss: 0.2108
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2931
Epoch 8/10, Batch 20/145, Loss: 0.1012
Epoch 8/10, Batch 30/145, Loss: 0.1544
Epoch 8/10, Batch 40/145, Loss: 0.1708
Epoch 8/10, Batch 50/145, Loss: 0.3049
Epoch 8/10, Batch 60/145, Loss: 0.2077
Epoch 8/10, Batch 70/145, Loss: 0.1225
Epoch 8/10, Batch 80/145, Loss: 0.2031
Epoch 8/10, Batch 90/145, Loss: 0.1268
Epoch 8/10, Batch 100/145, Loss: 0.2044
Epoch 8/10, Batch 110/145, Loss: 0.1787
Epoch 8/10, Batch 120/145, Loss: 0.1744
Epoch 8/10, Batch 130/145, Loss: 0.1222
Epoch 8/10, Batch 140/145, Loss: 0.2215
Epoch 8/10, Train Loss: 0.2096, Valid Loss: 0.2186
Epoch 9/10, Batch 10/145, Loss: 0.1832
Epoch 9/10, Batch 20/145, Loss: 0.1171
Epoch 9/10, Batch 30/145, Loss: 0.1684
Epoch 9/10, Batch 40/145, Loss: 0.1697
Epoch 9/10, Batch 50/145, Loss: 0.1314
Epoch 9/10, Batch 60/145, Loss: 0.2172
Epoch 9/10, Batch 70/145, Loss: 0.2462
Epoch 9/10, Batch 80/145, Loss: 0.2050
Epoch 9/10, Batch 90/145, Loss: 0.1943
Epoch 9/10, Batch 100/145, Loss: 0.3033
Epoch 9/10, Batch 110/145, Loss: 0.1505
Epoch 9/10, Batch 120/145, Loss: 0.1704
Epoch 9/10, Batch 130/145, Loss: 0.2180
Epoch 9/10, Batch 140/145, Loss: 0.2009
Epoch 9/10, Train Loss: 0.1958, Valid Loss: 0.2010
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0756
Epoch 10/10, Batch 20/145, Loss: 0.2240
Epoch 10/10, Batch 30/145, Loss: 0.1565
Epoch 10/10, Batch 40/145, Loss: 0.3034
Epoch 10/10, Batch 50/145, Loss: 0.2528
Epoch 10/10, Batch 60/145, Loss: 0.1656
Epoch 10/10, Batch 70/145, Loss: 0.1087
Epoch 10/10, Batch 80/145, Loss: 0.5235
Epoch 10/10, Batch 90/145, Loss: 0.1293
Epoch 10/10, Batch 100/145, Loss: 0.1475
Epoch 10/10, Batch 110/145, Loss: 0.2428
Epoch 10/10, Batch 120/145, Loss: 0.1804
Epoch 10/10, Batch 130/145, Loss: 0.2147
Epoch 10/10, Batch 140/145, Loss: 0.3157
Epoch 10/10, Train Loss: 0.1953, Valid Loss: 0.2100
Accuracy: 0.9241
Precision: 0.9227
Recall: 0.9241
F1-score: 0.9231
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4501
Epoch 1/10, Batch 20/145, Loss: 0.8944
Epoch 1/10, Batch 30/145, Loss: 0.8835
Epoch 1/10, Batch 40/145, Loss: 0.7841
Epoch 1/10, Batch 50/145, Loss: 0.6905
Epoch 1/10, Batch 60/145, Loss: 0.6001
Epoch 1/10, Batch 70/145, Loss: 0.5873
Epoch 1/10, Batch 80/145, Loss: 0.5622
Epoch 1/10, Batch 90/145, Loss: 0.4879
Epoch 1/10, Batch 100/145, Loss: 0.5729
Epoch 1/10, Batch 110/145, Loss: 0.4306
Epoch 1/10, Batch 120/145, Loss: 0.5615
Epoch 1/10, Batch 130/145, Loss: 0.3832
Epoch 1/10, Batch 140/145, Loss: 0.4693
Epoch 1/10, Train Loss: 0.6912, Valid Loss: 0.3724
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3260
Epoch 2/10, Batch 20/145, Loss: 0.4430
Epoch 2/10, Batch 30/145, Loss: 0.3771
Epoch 2/10, Batch 40/145, Loss: 0.5017
Epoch 2/10, Batch 50/145, Loss: 0.2263
Epoch 2/10, Batch 60/145, Loss: 0.4368
Epoch 2/10, Batch 70/145, Loss: 0.3205
Epoch 2/10, Batch 80/145, Loss: 0.3884
Epoch 2/10, Batch 90/145, Loss: 0.3213
Epoch 2/10, Batch 100/145, Loss: 0.3716
Epoch 2/10, Batch 110/145, Loss: 0.3416
Epoch 2/10, Batch 120/145, Loss: 0.3918
Epoch 2/10, Batch 130/145, Loss: 0.4166
Epoch 2/10, Batch 140/145, Loss: 0.3526
Epoch 2/10, Train Loss: 0.3610, Valid Loss: 0.2782
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3255
Epoch 3/10, Batch 20/145, Loss: 0.2030
Epoch 3/10, Batch 30/145, Loss: 0.3903
Epoch 3/10, Batch 40/145, Loss: 0.1658
Epoch 3/10, Batch 50/145, Loss: 0.1925
Epoch 3/10, Batch 60/145, Loss: 0.3169
Epoch 3/10, Batch 70/145, Loss: 0.3031
Epoch 3/10, Batch 80/145, Loss: 0.3690
Epoch 3/10, Batch 90/145, Loss: 0.3942
Epoch 3/10, Batch 100/145, Loss: 0.2565
Epoch 3/10, Batch 110/145, Loss: 0.2679
Epoch 3/10, Batch 120/145, Loss: 0.3056
Epoch 3/10, Batch 130/145, Loss: 0.2639
Epoch 3/10, Batch 140/145, Loss: 0.1878
Epoch 3/10, Train Loss: 0.3055, Valid Loss: 0.2471
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2287
Epoch 4/10, Batch 20/145, Loss: 0.2429
Epoch 4/10, Batch 30/145, Loss: 0.3314
Epoch 4/10, Batch 40/145, Loss: 0.3194
Epoch 4/10, Batch 50/145, Loss: 0.1786
Epoch 4/10, Batch 60/145, Loss: 0.3370
Epoch 4/10, Batch 70/145, Loss: 0.2257
Epoch 4/10, Batch 80/145, Loss: 0.3361
Epoch 4/10, Batch 90/145, Loss: 0.2711
Epoch 4/10, Batch 100/145, Loss: 0.3916
Epoch 4/10, Batch 110/145, Loss: 0.3261
Epoch 4/10, Batch 120/145, Loss: 0.2842
Epoch 4/10, Batch 130/145, Loss: 0.1509
Epoch 4/10, Batch 140/145, Loss: 0.1968
Epoch 4/10, Train Loss: 0.2680, Valid Loss: 0.2357
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2094
Epoch 5/10, Batch 20/145, Loss: 0.1756
Epoch 5/10, Batch 30/145, Loss: 0.2385
Epoch 5/10, Batch 40/145, Loss: 0.2967
Epoch 5/10, Batch 50/145, Loss: 0.2378
Epoch 5/10, Batch 60/145, Loss: 0.2023
Epoch 5/10, Batch 70/145, Loss: 0.3004
Epoch 5/10, Batch 80/145, Loss: 0.3110
Epoch 5/10, Batch 90/145, Loss: 0.3170
Epoch 5/10, Batch 100/145, Loss: 0.3203
Epoch 5/10, Batch 110/145, Loss: 0.2142
Epoch 5/10, Batch 120/145, Loss: 0.2682
Epoch 5/10, Batch 130/145, Loss: 0.2268
Epoch 5/10, Batch 140/145, Loss: 0.2191
Epoch 5/10, Train Loss: 0.2413, Valid Loss: 0.2174
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1926
Epoch 6/10, Batch 20/145, Loss: 0.1436
Epoch 6/10, Batch 30/145, Loss: 0.1592
Epoch 6/10, Batch 40/145, Loss: 0.2352
Epoch 6/10, Batch 50/145, Loss: 0.2327
Epoch 6/10, Batch 60/145, Loss: 0.2010
Epoch 6/10, Batch 70/145, Loss: 0.4690
Epoch 6/10, Batch 80/145, Loss: 0.2592
Epoch 6/10, Batch 90/145, Loss: 0.1787
Epoch 6/10, Batch 100/145, Loss: 0.1757
Epoch 6/10, Batch 110/145, Loss: 0.1000
Epoch 6/10, Batch 120/145, Loss: 0.2343
Epoch 6/10, Batch 130/145, Loss: 0.1765
Epoch 6/10, Batch 140/145, Loss: 0.1482
Epoch 6/10, Train Loss: 0.2251, Valid Loss: 0.2122
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.4741
Epoch 7/10, Batch 20/145, Loss: 0.2230
Epoch 7/10, Batch 30/145, Loss: 0.1564
Epoch 7/10, Batch 40/145, Loss: 0.4330
Epoch 7/10, Batch 50/145, Loss: 0.2336
Epoch 7/10, Batch 60/145, Loss: 0.1915
Epoch 7/10, Batch 70/145, Loss: 0.2500
Epoch 7/10, Batch 80/145, Loss: 0.1182
Epoch 7/10, Batch 90/145, Loss: 0.1766
Epoch 7/10, Batch 100/145, Loss: 0.1659
Epoch 7/10, Batch 110/145, Loss: 0.3123
Epoch 7/10, Batch 120/145, Loss: 0.2626
Epoch 7/10, Batch 130/145, Loss: 0.1922
Epoch 7/10, Batch 140/145, Loss: 0.0791
Epoch 7/10, Train Loss: 0.2141, Valid Loss: 0.2098
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1256
Epoch 8/10, Batch 20/145, Loss: 0.1546
Epoch 8/10, Batch 30/145, Loss: 0.2983
Epoch 8/10, Batch 40/145, Loss: 0.1643
Epoch 8/10, Batch 50/145, Loss: 0.2061
Epoch 8/10, Batch 60/145, Loss: 0.1545
Epoch 8/10, Batch 70/145, Loss: 0.1689
Epoch 8/10, Batch 80/145, Loss: 0.0930
Epoch 8/10, Batch 90/145, Loss: 0.1680
Epoch 8/10, Batch 100/145, Loss: 0.1738
Epoch 8/10, Batch 110/145, Loss: 0.2432
Epoch 8/10, Batch 120/145, Loss: 0.2094
Epoch 8/10, Batch 130/145, Loss: 0.3025
Epoch 8/10, Batch 140/145, Loss: 0.2753
Epoch 8/10, Train Loss: 0.2202, Valid Loss: 0.1968
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3810
Epoch 9/10, Batch 20/145, Loss: 0.0914
Epoch 9/10, Batch 30/145, Loss: 0.1649
Epoch 9/10, Batch 40/145, Loss: 0.1823
Epoch 9/10, Batch 50/145, Loss: 0.2113
Epoch 9/10, Batch 60/145, Loss: 0.2225
Epoch 9/10, Batch 70/145, Loss: 0.1911
Epoch 9/10, Batch 80/145, Loss: 0.3527
Epoch 9/10, Batch 90/145, Loss: 0.1331
Epoch 9/10, Batch 100/145, Loss: 0.2071
Epoch 9/10, Batch 110/145, Loss: 0.0976
Epoch 9/10, Batch 120/145, Loss: 0.1828
Epoch 9/10, Batch 130/145, Loss: 0.2308
Epoch 9/10, Batch 140/145, Loss: 0.0958
Epoch 9/10, Train Loss: 0.2052, Valid Loss: 0.1879
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1625
Epoch 10/10, Batch 20/145, Loss: 0.1925
Epoch 10/10, Batch 30/145, Loss: 0.2074
Epoch 10/10, Batch 40/145, Loss: 0.1931
Epoch 10/10, Batch 50/145, Loss: 0.2171
Epoch 10/10, Batch 60/145, Loss: 0.2407
Epoch 10/10, Batch 70/145, Loss: 0.1608
Epoch 10/10, Batch 80/145, Loss: 0.4194
Epoch 10/10, Batch 90/145, Loss: 0.1149
Epoch 10/10, Batch 100/145, Loss: 0.1074
Epoch 10/10, Batch 110/145, Loss: 0.1387
Epoch 10/10, Batch 120/145, Loss: 0.2156
Epoch 10/10, Batch 130/145, Loss: 0.1914
Epoch 10/10, Batch 140/145, Loss: 0.2032
Epoch 10/10, Train Loss: 0.1931, Valid Loss: 0.1857
Model saved!
Accuracy: 0.9217
Precision: 0.9204
Recall: 0.9217
F1-score: 0.9209
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4824
Epoch 1/10, Batch 20/145, Loss: 0.9355
Epoch 1/10, Batch 30/145, Loss: 0.8601
Epoch 1/10, Batch 40/145, Loss: 0.9186
Epoch 1/10, Batch 50/145, Loss: 0.7472
Epoch 1/10, Batch 60/145, Loss: 0.5019
Epoch 1/10, Batch 70/145, Loss: 0.7003
Epoch 1/10, Batch 80/145, Loss: 0.4950
Epoch 1/10, Batch 90/145, Loss: 0.5392
Epoch 1/10, Batch 100/145, Loss: 0.4780
Epoch 1/10, Batch 110/145, Loss: 0.4450
Epoch 1/10, Batch 120/145, Loss: 0.5604
Epoch 1/10, Batch 130/145, Loss: 0.3610
Epoch 1/10, Batch 140/145, Loss: 0.3577
Epoch 1/10, Train Loss: 0.6927, Valid Loss: 0.3604
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.5729
Epoch 2/10, Batch 20/145, Loss: 0.6366
Epoch 2/10, Batch 30/145, Loss: 0.2213
Epoch 2/10, Batch 40/145, Loss: 0.6045
Epoch 2/10, Batch 50/145, Loss: 0.3965
Epoch 2/10, Batch 60/145, Loss: 0.4080
Epoch 2/10, Batch 70/145, Loss: 0.3015
Epoch 2/10, Batch 80/145, Loss: 0.2948
Epoch 2/10, Batch 90/145, Loss: 0.4270
Epoch 2/10, Batch 100/145, Loss: 0.2313
Epoch 2/10, Batch 110/145, Loss: 0.3005
Epoch 2/10, Batch 120/145, Loss: 0.5735
Epoch 2/10, Batch 130/145, Loss: 0.3911
Epoch 2/10, Batch 140/145, Loss: 0.2933
Epoch 2/10, Train Loss: 0.3697, Valid Loss: 0.2721
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3308
Epoch 3/10, Batch 20/145, Loss: 0.2334
Epoch 3/10, Batch 30/145, Loss: 0.2551
Epoch 3/10, Batch 40/145, Loss: 0.2608
Epoch 3/10, Batch 50/145, Loss: 0.2760
Epoch 3/10, Batch 60/145, Loss: 0.2696
Epoch 3/10, Batch 70/145, Loss: 0.1787
Epoch 3/10, Batch 80/145, Loss: 0.2293
Epoch 3/10, Batch 90/145, Loss: 0.4883
Epoch 3/10, Batch 100/145, Loss: 0.2753
Epoch 3/10, Batch 110/145, Loss: 0.2447
Epoch 3/10, Batch 120/145, Loss: 0.2260
Epoch 3/10, Batch 130/145, Loss: 0.2101
Epoch 3/10, Batch 140/145, Loss: 0.2665
Epoch 3/10, Train Loss: 0.3201, Valid Loss: 0.2390
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1701
Epoch 4/10, Batch 20/145, Loss: 0.3321
Epoch 4/10, Batch 30/145, Loss: 0.2322
Epoch 4/10, Batch 40/145, Loss: 0.3412
Epoch 4/10, Batch 50/145, Loss: 0.1128
Epoch 4/10, Batch 60/145, Loss: 0.1454
Epoch 4/10, Batch 70/145, Loss: 0.1956
Epoch 4/10, Batch 80/145, Loss: 0.2653
Epoch 4/10, Batch 90/145, Loss: 0.2568
Epoch 4/10, Batch 100/145, Loss: 0.2521
Epoch 4/10, Batch 110/145, Loss: 0.1582
Epoch 4/10, Batch 120/145, Loss: 0.3291
Epoch 4/10, Batch 130/145, Loss: 0.1804
Epoch 4/10, Batch 140/145, Loss: 0.1606
Epoch 4/10, Train Loss: 0.2691, Valid Loss: 0.2219
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3106
Epoch 5/10, Batch 20/145, Loss: 0.2856
Epoch 5/10, Batch 30/145, Loss: 0.1745
Epoch 5/10, Batch 40/145, Loss: 0.1767
Epoch 5/10, Batch 50/145, Loss: 0.2238
Epoch 5/10, Batch 60/145, Loss: 0.1747
Epoch 5/10, Batch 70/145, Loss: 0.1865
Epoch 5/10, Batch 80/145, Loss: 0.2538
Epoch 5/10, Batch 90/145, Loss: 0.1459
Epoch 5/10, Batch 100/145, Loss: 0.1904
Epoch 5/10, Batch 110/145, Loss: 0.1559
Epoch 5/10, Batch 120/145, Loss: 0.1555
Epoch 5/10, Batch 130/145, Loss: 0.1670
Epoch 5/10, Batch 140/145, Loss: 0.2476
Epoch 5/10, Train Loss: 0.2471, Valid Loss: 0.2122
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1385
Epoch 6/10, Batch 20/145, Loss: 0.1013
Epoch 6/10, Batch 30/145, Loss: 0.3653
Epoch 6/10, Batch 40/145, Loss: 0.1609
Epoch 6/10, Batch 50/145, Loss: 0.5217
Epoch 6/10, Batch 60/145, Loss: 0.2503
Epoch 6/10, Batch 70/145, Loss: 0.2272
Epoch 6/10, Batch 80/145, Loss: 0.3126
Epoch 6/10, Batch 90/145, Loss: 0.3881
Epoch 6/10, Batch 100/145, Loss: 0.3645
Epoch 6/10, Batch 110/145, Loss: 0.1386
Epoch 6/10, Batch 120/145, Loss: 0.1876
Epoch 6/10, Batch 130/145, Loss: 0.1475
Epoch 6/10, Batch 140/145, Loss: 0.1445
Epoch 6/10, Train Loss: 0.2363, Valid Loss: 0.2133
Epoch 7/10, Batch 10/145, Loss: 0.2173
Epoch 7/10, Batch 20/145, Loss: 0.2132
Epoch 7/10, Batch 30/145, Loss: 0.1339
Epoch 7/10, Batch 40/145, Loss: 0.5328
Epoch 7/10, Batch 50/145, Loss: 0.1132
Epoch 7/10, Batch 60/145, Loss: 0.0987
Epoch 7/10, Batch 70/145, Loss: 0.4513
Epoch 7/10, Batch 80/145, Loss: 0.2183
Epoch 7/10, Batch 90/145, Loss: 0.1832
Epoch 7/10, Batch 100/145, Loss: 0.1987
Epoch 7/10, Batch 110/145, Loss: 0.1991
Epoch 7/10, Batch 120/145, Loss: 0.2110
Epoch 7/10, Batch 130/145, Loss: 0.2455
Epoch 7/10, Batch 140/145, Loss: 0.0880
Epoch 7/10, Train Loss: 0.2274, Valid Loss: 0.1957
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2705
Epoch 8/10, Batch 20/145, Loss: 0.1113
Epoch 8/10, Batch 30/145, Loss: 0.0790
Epoch 8/10, Batch 40/145, Loss: 0.1298
Epoch 8/10, Batch 50/145, Loss: 0.1625
Epoch 8/10, Batch 60/145, Loss: 0.3046
Epoch 8/10, Batch 70/145, Loss: 0.1165
Epoch 8/10, Batch 80/145, Loss: 0.1118
Epoch 8/10, Batch 90/145, Loss: 0.1255
Epoch 8/10, Batch 100/145, Loss: 0.1776
Epoch 8/10, Batch 110/145, Loss: 0.2300
Epoch 8/10, Batch 120/145, Loss: 0.2055
Epoch 8/10, Batch 130/145, Loss: 0.2187
Epoch 8/10, Batch 140/145, Loss: 0.2545
Epoch 8/10, Train Loss: 0.2233, Valid Loss: 0.1919
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2327
Epoch 9/10, Batch 20/145, Loss: 0.1993
Epoch 9/10, Batch 30/145, Loss: 0.0826
Epoch 9/10, Batch 40/145, Loss: 0.3177
Epoch 9/10, Batch 50/145, Loss: 0.1510
Epoch 9/10, Batch 60/145, Loss: 0.1167
Epoch 9/10, Batch 70/145, Loss: 0.1760
Epoch 9/10, Batch 80/145, Loss: 0.2954
Epoch 9/10, Batch 90/145, Loss: 0.0850
Epoch 9/10, Batch 100/145, Loss: 0.2794
Epoch 9/10, Batch 110/145, Loss: 0.1040
Epoch 9/10, Batch 120/145, Loss: 0.2197
Epoch 9/10, Batch 130/145, Loss: 0.1407
Epoch 9/10, Batch 140/145, Loss: 0.2002
Epoch 9/10, Train Loss: 0.2061, Valid Loss: 0.1848
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2275
Epoch 10/10, Batch 20/145, Loss: 0.1106
Epoch 10/10, Batch 30/145, Loss: 0.0832
Epoch 10/10, Batch 40/145, Loss: 0.2011
Epoch 10/10, Batch 50/145, Loss: 0.1117
Epoch 10/10, Batch 60/145, Loss: 0.1911
Epoch 10/10, Batch 70/145, Loss: 0.2678
Epoch 10/10, Batch 80/145, Loss: 0.3013
Epoch 10/10, Batch 90/145, Loss: 0.1425
Epoch 10/10, Batch 100/145, Loss: 0.2503
Epoch 10/10, Batch 110/145, Loss: 0.2114
Epoch 10/10, Batch 120/145, Loss: 0.2005
Epoch 10/10, Batch 130/145, Loss: 0.3057
Epoch 10/10, Batch 140/145, Loss: 0.2760
Epoch 10/10, Train Loss: 0.2090, Valid Loss: 0.1788
Model saved!
Accuracy: 0.9159
Precision: 0.9140
Recall: 0.9159
F1-score: 0.9147
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5187
Epoch 1/10, Batch 20/145, Loss: 0.9220
Epoch 1/10, Batch 30/145, Loss: 0.8445
Epoch 1/10, Batch 40/145, Loss: 0.9063
Epoch 1/10, Batch 50/145, Loss: 0.6060
Epoch 1/10, Batch 60/145, Loss: 0.5126
Epoch 1/10, Batch 70/145, Loss: 0.7263
Epoch 1/10, Batch 80/145, Loss: 0.5341
Epoch 1/10, Batch 90/145, Loss: 0.5949
Epoch 1/10, Batch 100/145, Loss: 0.5405
Epoch 1/10, Batch 110/145, Loss: 0.4129
Epoch 1/10, Batch 120/145, Loss: 0.6767
Epoch 1/10, Batch 130/145, Loss: 0.4193
Epoch 1/10, Batch 140/145, Loss: 0.5034
Epoch 1/10, Train Loss: 0.6910, Valid Loss: 0.3747
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4644
Epoch 2/10, Batch 20/145, Loss: 0.4230
Epoch 2/10, Batch 30/145, Loss: 0.3174
Epoch 2/10, Batch 40/145, Loss: 0.3764
Epoch 2/10, Batch 50/145, Loss: 0.2771
Epoch 2/10, Batch 60/145, Loss: 0.4734
Epoch 2/10, Batch 70/145, Loss: 0.5624
Epoch 2/10, Batch 80/145, Loss: 0.3216
Epoch 2/10, Batch 90/145, Loss: 0.2901
Epoch 2/10, Batch 100/145, Loss: 0.3224
Epoch 2/10, Batch 110/145, Loss: 0.3602
Epoch 2/10, Batch 120/145, Loss: 0.3575
Epoch 2/10, Batch 130/145, Loss: 0.3079
Epoch 2/10, Batch 140/145, Loss: 0.3682
Epoch 2/10, Train Loss: 0.3664, Valid Loss: 0.2828
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3048
Epoch 3/10, Batch 20/145, Loss: 0.2189
Epoch 3/10, Batch 30/145, Loss: 0.3734
Epoch 3/10, Batch 40/145, Loss: 0.3089
Epoch 3/10, Batch 50/145, Loss: 0.1428
Epoch 3/10, Batch 60/145, Loss: 0.2266
Epoch 3/10, Batch 70/145, Loss: 0.1893
Epoch 3/10, Batch 80/145, Loss: 0.2346
Epoch 3/10, Batch 90/145, Loss: 0.5472
Epoch 3/10, Batch 100/145, Loss: 0.2181
Epoch 3/10, Batch 110/145, Loss: 0.2120
Epoch 3/10, Batch 120/145, Loss: 0.4069
Epoch 3/10, Batch 130/145, Loss: 0.1809
Epoch 3/10, Batch 140/145, Loss: 0.2902
Epoch 3/10, Train Loss: 0.3076, Valid Loss: 0.2461
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2934
Epoch 4/10, Batch 20/145, Loss: 0.2488
Epoch 4/10, Batch 30/145, Loss: 0.3064
Epoch 4/10, Batch 40/145, Loss: 0.3808
Epoch 4/10, Batch 50/145, Loss: 0.2260
Epoch 4/10, Batch 60/145, Loss: 0.2139
Epoch 4/10, Batch 70/145, Loss: 0.1560
Epoch 4/10, Batch 80/145, Loss: 0.3304
Epoch 4/10, Batch 90/145, Loss: 0.2113
Epoch 4/10, Batch 100/145, Loss: 0.2821
Epoch 4/10, Batch 110/145, Loss: 0.3607
Epoch 4/10, Batch 120/145, Loss: 0.3787
Epoch 4/10, Batch 130/145, Loss: 0.2596
Epoch 4/10, Batch 140/145, Loss: 0.2115
Epoch 4/10, Train Loss: 0.2629, Valid Loss: 0.2351
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1144
Epoch 5/10, Batch 20/145, Loss: 0.2790
Epoch 5/10, Batch 30/145, Loss: 0.2475
Epoch 5/10, Batch 40/145, Loss: 0.1573
Epoch 5/10, Batch 50/145, Loss: 0.2036
Epoch 5/10, Batch 60/145, Loss: 0.2165
Epoch 5/10, Batch 70/145, Loss: 0.2627
Epoch 5/10, Batch 80/145, Loss: 0.1700
Epoch 5/10, Batch 90/145, Loss: 0.2047
Epoch 5/10, Batch 100/145, Loss: 0.3182
Epoch 5/10, Batch 110/145, Loss: 0.1396
Epoch 5/10, Batch 120/145, Loss: 0.1386
Epoch 5/10, Batch 130/145, Loss: 0.2345
Epoch 5/10, Batch 140/145, Loss: 0.1553
Epoch 5/10, Train Loss: 0.2367, Valid Loss: 0.2183
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2771
Epoch 6/10, Batch 20/145, Loss: 0.3791
Epoch 6/10, Batch 30/145, Loss: 0.3031
Epoch 6/10, Batch 40/145, Loss: 0.1412
Epoch 6/10, Batch 50/145, Loss: 0.5008
Epoch 6/10, Batch 60/145, Loss: 0.1016
Epoch 6/10, Batch 70/145, Loss: 0.2045
Epoch 6/10, Batch 80/145, Loss: 0.2845
Epoch 6/10, Batch 90/145, Loss: 0.1602
Epoch 6/10, Batch 100/145, Loss: 0.2494
Epoch 6/10, Batch 110/145, Loss: 0.0735
Epoch 6/10, Batch 120/145, Loss: 0.2084
Epoch 6/10, Batch 130/145, Loss: 0.0960
Epoch 6/10, Batch 140/145, Loss: 0.2247
Epoch 6/10, Train Loss: 0.2266, Valid Loss: 0.2206
Epoch 7/10, Batch 10/145, Loss: 0.3857
Epoch 7/10, Batch 20/145, Loss: 0.1830
Epoch 7/10, Batch 30/145, Loss: 0.2237
Epoch 7/10, Batch 40/145, Loss: 0.3733
Epoch 7/10, Batch 50/145, Loss: 0.2403
Epoch 7/10, Batch 60/145, Loss: 0.1804
Epoch 7/10, Batch 70/145, Loss: 0.3312
Epoch 7/10, Batch 80/145, Loss: 0.1782
Epoch 7/10, Batch 90/145, Loss: 0.3962
Epoch 7/10, Batch 100/145, Loss: 0.2270
Epoch 7/10, Batch 110/145, Loss: 0.3202
Epoch 7/10, Batch 120/145, Loss: 0.0668
Epoch 7/10, Batch 130/145, Loss: 0.2789
Epoch 7/10, Batch 140/145, Loss: 0.1947
Epoch 7/10, Train Loss: 0.2190, Valid Loss: 0.2133
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1962
Epoch 8/10, Batch 20/145, Loss: 0.1752
Epoch 8/10, Batch 30/145, Loss: 0.1793
Epoch 8/10, Batch 40/145, Loss: 0.4790
Epoch 8/10, Batch 50/145, Loss: 0.3042
Epoch 8/10, Batch 60/145, Loss: 0.1150
Epoch 8/10, Batch 70/145, Loss: 0.3060
Epoch 8/10, Batch 80/145, Loss: 0.1773
Epoch 8/10, Batch 90/145, Loss: 0.0628
Epoch 8/10, Batch 100/145, Loss: 0.2610
Epoch 8/10, Batch 110/145, Loss: 0.2781
Epoch 8/10, Batch 120/145, Loss: 0.0755
Epoch 8/10, Batch 130/145, Loss: 0.2355
Epoch 8/10, Batch 140/145, Loss: 0.2515
Epoch 8/10, Train Loss: 0.2059, Valid Loss: 0.2080
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2014
Epoch 9/10, Batch 20/145, Loss: 0.2593
Epoch 9/10, Batch 30/145, Loss: 0.1740
Epoch 9/10, Batch 40/145, Loss: 0.1905
Epoch 9/10, Batch 50/145, Loss: 0.2186
Epoch 9/10, Batch 60/145, Loss: 0.1392
Epoch 9/10, Batch 70/145, Loss: 0.2075
Epoch 9/10, Batch 80/145, Loss: 0.2362
Epoch 9/10, Batch 90/145, Loss: 0.2025
Epoch 9/10, Batch 100/145, Loss: 0.2158
Epoch 9/10, Batch 110/145, Loss: 0.0821
Epoch 9/10, Batch 120/145, Loss: 0.3880
Epoch 9/10, Batch 130/145, Loss: 0.3024
Epoch 9/10, Batch 140/145, Loss: 0.1449
Epoch 9/10, Train Loss: 0.2046, Valid Loss: 0.2064
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.3146
Epoch 10/10, Batch 20/145, Loss: 0.1322
Epoch 10/10, Batch 30/145, Loss: 0.1386
Epoch 10/10, Batch 40/145, Loss: 0.2835
Epoch 10/10, Batch 50/145, Loss: 0.1417
Epoch 10/10, Batch 60/145, Loss: 0.1978
Epoch 10/10, Batch 70/145, Loss: 0.1545
Epoch 10/10, Batch 80/145, Loss: 0.4442
Epoch 10/10, Batch 90/145, Loss: 0.1970
Epoch 10/10, Batch 100/145, Loss: 0.1865
Epoch 10/10, Batch 110/145, Loss: 0.2461
Epoch 10/10, Batch 120/145, Loss: 0.1507
Epoch 10/10, Batch 130/145, Loss: 0.2531
Epoch 10/10, Batch 140/145, Loss: 0.2419
Epoch 10/10, Train Loss: 0.2011, Valid Loss: 0.2011
Model saved!
Accuracy: 0.9287
Precision: 0.9294
Recall: 0.9287
F1-score: 0.9289
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5277
Epoch 1/10, Batch 20/145, Loss: 0.8935
Epoch 1/10, Batch 30/145, Loss: 0.8558
Epoch 1/10, Batch 40/145, Loss: 0.7849
Epoch 1/10, Batch 50/145, Loss: 0.5788
Epoch 1/10, Batch 60/145, Loss: 0.5323
Epoch 1/10, Batch 70/145, Loss: 0.6514
Epoch 1/10, Batch 80/145, Loss: 0.4492
Epoch 1/10, Batch 90/145, Loss: 0.5352
Epoch 1/10, Batch 100/145, Loss: 0.6253
Epoch 1/10, Batch 110/145, Loss: 0.5021
Epoch 1/10, Batch 120/145, Loss: 0.5950
Epoch 1/10, Batch 130/145, Loss: 0.3738
Epoch 1/10, Batch 140/145, Loss: 0.4792
Epoch 1/10, Train Loss: 0.6802, Valid Loss: 0.3653
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2844
Epoch 2/10, Batch 20/145, Loss: 0.5461
Epoch 2/10, Batch 30/145, Loss: 0.4847
Epoch 2/10, Batch 40/145, Loss: 0.4878
Epoch 2/10, Batch 50/145, Loss: 0.3211
Epoch 2/10, Batch 60/145, Loss: 0.4125
Epoch 2/10, Batch 70/145, Loss: 0.4993
Epoch 2/10, Batch 80/145, Loss: 0.2947
Epoch 2/10, Batch 90/145, Loss: 0.3400
Epoch 2/10, Batch 100/145, Loss: 0.2603
Epoch 2/10, Batch 110/145, Loss: 0.3412
Epoch 2/10, Batch 120/145, Loss: 0.3638
Epoch 2/10, Batch 130/145, Loss: 0.4874
Epoch 2/10, Batch 140/145, Loss: 0.2382
Epoch 2/10, Train Loss: 0.3555, Valid Loss: 0.2827
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2281
Epoch 3/10, Batch 20/145, Loss: 0.2163
Epoch 3/10, Batch 30/145, Loss: 0.1845
Epoch 3/10, Batch 40/145, Loss: 0.3464
Epoch 3/10, Batch 50/145, Loss: 0.2772
Epoch 3/10, Batch 60/145, Loss: 0.3349
Epoch 3/10, Batch 70/145, Loss: 0.2289
Epoch 3/10, Batch 80/145, Loss: 0.2994
Epoch 3/10, Batch 90/145, Loss: 0.4805
Epoch 3/10, Batch 100/145, Loss: 0.4435
Epoch 3/10, Batch 110/145, Loss: 0.2848
Epoch 3/10, Batch 120/145, Loss: 0.3042
Epoch 3/10, Batch 130/145, Loss: 0.3800
Epoch 3/10, Batch 140/145, Loss: 0.1583
Epoch 3/10, Train Loss: 0.3037, Valid Loss: 0.2591
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2148
Epoch 4/10, Batch 20/145, Loss: 0.1952
Epoch 4/10, Batch 30/145, Loss: 0.3207
Epoch 4/10, Batch 40/145, Loss: 0.2502
Epoch 4/10, Batch 50/145, Loss: 0.1289
Epoch 4/10, Batch 60/145, Loss: 0.2409
Epoch 4/10, Batch 70/145, Loss: 0.3605
Epoch 4/10, Batch 80/145, Loss: 0.3277
Epoch 4/10, Batch 90/145, Loss: 0.2397
Epoch 4/10, Batch 100/145, Loss: 0.2573
Epoch 4/10, Batch 110/145, Loss: 0.1693
Epoch 4/10, Batch 120/145, Loss: 0.2054
Epoch 4/10, Batch 130/145, Loss: 0.4071
Epoch 4/10, Batch 140/145, Loss: 0.1340
Epoch 4/10, Train Loss: 0.2637, Valid Loss: 0.2534
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2266
Epoch 5/10, Batch 20/145, Loss: 0.1799
Epoch 5/10, Batch 30/145, Loss: 0.1900
Epoch 5/10, Batch 40/145, Loss: 0.2554
Epoch 5/10, Batch 50/145, Loss: 0.0877
Epoch 5/10, Batch 60/145, Loss: 0.1355
Epoch 5/10, Batch 70/145, Loss: 0.1773
Epoch 5/10, Batch 80/145, Loss: 0.3235
Epoch 5/10, Batch 90/145, Loss: 0.1336
Epoch 5/10, Batch 100/145, Loss: 0.2349
Epoch 5/10, Batch 110/145, Loss: 0.0895
Epoch 5/10, Batch 120/145, Loss: 0.3296
Epoch 5/10, Batch 130/145, Loss: 0.2591
Epoch 5/10, Batch 140/145, Loss: 0.3394
Epoch 5/10, Train Loss: 0.2344, Valid Loss: 0.2402
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2575
Epoch 6/10, Batch 20/145, Loss: 0.2342
Epoch 6/10, Batch 30/145, Loss: 0.1371
Epoch 6/10, Batch 40/145, Loss: 0.2223
Epoch 6/10, Batch 50/145, Loss: 0.2787
Epoch 6/10, Batch 60/145, Loss: 0.2242
Epoch 6/10, Batch 70/145, Loss: 0.3077
Epoch 6/10, Batch 80/145, Loss: 0.1014
Epoch 6/10, Batch 90/145, Loss: 0.2758
Epoch 6/10, Batch 100/145, Loss: 0.2583
Epoch 6/10, Batch 110/145, Loss: 0.0868
Epoch 6/10, Batch 120/145, Loss: 0.1600
Epoch 6/10, Batch 130/145, Loss: 0.1174
Epoch 6/10, Batch 140/145, Loss: 0.2622
Epoch 6/10, Train Loss: 0.2308, Valid Loss: 0.2331
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2885
Epoch 7/10, Batch 20/145, Loss: 0.2187
Epoch 7/10, Batch 30/145, Loss: 0.1707
Epoch 7/10, Batch 40/145, Loss: 0.4526
Epoch 7/10, Batch 50/145, Loss: 0.1618
Epoch 7/10, Batch 60/145, Loss: 0.1517
Epoch 7/10, Batch 70/145, Loss: 0.1885
Epoch 7/10, Batch 80/145, Loss: 0.1759
Epoch 7/10, Batch 90/145, Loss: 0.3894
Epoch 7/10, Batch 100/145, Loss: 0.1571
Epoch 7/10, Batch 110/145, Loss: 0.2631
Epoch 7/10, Batch 120/145, Loss: 0.1827
Epoch 7/10, Batch 130/145, Loss: 0.2557
Epoch 7/10, Batch 140/145, Loss: 0.1413
Epoch 7/10, Train Loss: 0.2142, Valid Loss: 0.2206
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2398
Epoch 8/10, Batch 20/145, Loss: 0.2405
Epoch 8/10, Batch 30/145, Loss: 0.1419
Epoch 8/10, Batch 40/145, Loss: 0.1407
Epoch 8/10, Batch 50/145, Loss: 0.0999
Epoch 8/10, Batch 60/145, Loss: 0.3576
Epoch 8/10, Batch 70/145, Loss: 0.1032
Epoch 8/10, Batch 80/145, Loss: 0.2984
Epoch 8/10, Batch 90/145, Loss: 0.0999
Epoch 8/10, Batch 100/145, Loss: 0.2030
Epoch 8/10, Batch 110/145, Loss: 0.4896
Epoch 8/10, Batch 120/145, Loss: 0.1003
Epoch 8/10, Batch 130/145, Loss: 0.1215
Epoch 8/10, Batch 140/145, Loss: 0.3515
Epoch 8/10, Train Loss: 0.2021, Valid Loss: 0.2146
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2206
Epoch 9/10, Batch 20/145, Loss: 0.2300
Epoch 9/10, Batch 30/145, Loss: 0.3613
Epoch 9/10, Batch 40/145, Loss: 0.2037
Epoch 9/10, Batch 50/145, Loss: 0.0899
Epoch 9/10, Batch 60/145, Loss: 0.1435
Epoch 9/10, Batch 70/145, Loss: 0.1511
Epoch 9/10, Batch 80/145, Loss: 0.1973
Epoch 9/10, Batch 90/145, Loss: 0.1742
Epoch 9/10, Batch 100/145, Loss: 0.1886
Epoch 9/10, Batch 110/145, Loss: 0.1282
Epoch 9/10, Batch 120/145, Loss: 0.1640
Epoch 9/10, Batch 130/145, Loss: 0.2259
Epoch 9/10, Batch 140/145, Loss: 0.1613
Epoch 9/10, Train Loss: 0.2011, Valid Loss: 0.2109
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1416
Epoch 10/10, Batch 20/145, Loss: 0.0534
Epoch 10/10, Batch 30/145, Loss: 0.1379
Epoch 10/10, Batch 40/145, Loss: 0.3237
Epoch 10/10, Batch 50/145, Loss: 0.2128
Epoch 10/10, Batch 60/145, Loss: 0.1693
Epoch 10/10, Batch 70/145, Loss: 0.1080
Epoch 10/10, Batch 80/145, Loss: 0.2114
Epoch 10/10, Batch 90/145, Loss: 0.1688
Epoch 10/10, Batch 100/145, Loss: 0.1275
Epoch 10/10, Batch 110/145, Loss: 0.1700
Epoch 10/10, Batch 120/145, Loss: 0.2453
Epoch 10/10, Batch 130/145, Loss: 0.1657
Epoch 10/10, Batch 140/145, Loss: 0.2226
Epoch 10/10, Train Loss: 0.1883, Valid Loss: 0.2040
Model saved!
Accuracy: 0.9217
Precision: 0.9201
Recall: 0.9217
F1-score: 0.9203
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4392
Epoch 1/10, Batch 20/145, Loss: 0.8641
Epoch 1/10, Batch 30/145, Loss: 0.8472
Epoch 1/10, Batch 40/145, Loss: 0.8421
Epoch 1/10, Batch 50/145, Loss: 0.5327
Epoch 1/10, Batch 60/145, Loss: 0.5204
Epoch 1/10, Batch 70/145, Loss: 0.6236
Epoch 1/10, Batch 80/145, Loss: 0.4033
Epoch 1/10, Batch 90/145, Loss: 0.6331
Epoch 1/10, Batch 100/145, Loss: 0.4900
Epoch 1/10, Batch 110/145, Loss: 0.3790
Epoch 1/10, Batch 120/145, Loss: 0.5335
Epoch 1/10, Batch 130/145, Loss: 0.4554
Epoch 1/10, Batch 140/145, Loss: 0.3282
Epoch 1/10, Train Loss: 0.6885, Valid Loss: 0.3884
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2565
Epoch 2/10, Batch 20/145, Loss: 0.4223
Epoch 2/10, Batch 30/145, Loss: 0.2141
Epoch 2/10, Batch 40/145, Loss: 0.4472
Epoch 2/10, Batch 50/145, Loss: 0.2998
Epoch 2/10, Batch 60/145, Loss: 0.4600
Epoch 2/10, Batch 70/145, Loss: 0.3898
Epoch 2/10, Batch 80/145, Loss: 0.2531
Epoch 2/10, Batch 90/145, Loss: 0.3355
Epoch 2/10, Batch 100/145, Loss: 0.5407
Epoch 2/10, Batch 110/145, Loss: 0.2916
Epoch 2/10, Batch 120/145, Loss: 0.4991
Epoch 2/10, Batch 130/145, Loss: 0.2551
Epoch 2/10, Batch 140/145, Loss: 0.2752
Epoch 2/10, Train Loss: 0.3676, Valid Loss: 0.2975
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2954
Epoch 3/10, Batch 20/145, Loss: 0.2949
Epoch 3/10, Batch 30/145, Loss: 0.3140
Epoch 3/10, Batch 40/145, Loss: 0.2257
Epoch 3/10, Batch 50/145, Loss: 0.2986
Epoch 3/10, Batch 60/145, Loss: 0.3291
Epoch 3/10, Batch 70/145, Loss: 0.3392
Epoch 3/10, Batch 80/145, Loss: 0.1935
Epoch 3/10, Batch 90/145, Loss: 0.4377
Epoch 3/10, Batch 100/145, Loss: 0.3463
Epoch 3/10, Batch 110/145, Loss: 0.2257
Epoch 3/10, Batch 120/145, Loss: 0.1863
Epoch 3/10, Batch 130/145, Loss: 0.1776
Epoch 3/10, Batch 140/145, Loss: 0.2842
Epoch 3/10, Train Loss: 0.3087, Valid Loss: 0.2692
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2733
Epoch 4/10, Batch 20/145, Loss: 0.2407
Epoch 4/10, Batch 30/145, Loss: 0.2207
Epoch 4/10, Batch 40/145, Loss: 0.3238
Epoch 4/10, Batch 50/145, Loss: 0.1650
Epoch 4/10, Batch 60/145, Loss: 0.3211
Epoch 4/10, Batch 70/145, Loss: 0.1968
Epoch 4/10, Batch 80/145, Loss: 0.2559
Epoch 4/10, Batch 90/145, Loss: 0.2526
Epoch 4/10, Batch 100/145, Loss: 0.1376
Epoch 4/10, Batch 110/145, Loss: 0.1729
Epoch 4/10, Batch 120/145, Loss: 0.2293
Epoch 4/10, Batch 130/145, Loss: 0.1735
Epoch 4/10, Batch 140/145, Loss: 0.2470
Epoch 4/10, Train Loss: 0.2653, Valid Loss: 0.2557
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2256
Epoch 5/10, Batch 20/145, Loss: 0.2239
Epoch 5/10, Batch 30/145, Loss: 0.1415
Epoch 5/10, Batch 40/145, Loss: 0.1971
Epoch 5/10, Batch 50/145, Loss: 0.1138
Epoch 5/10, Batch 60/145, Loss: 0.1933
Epoch 5/10, Batch 70/145, Loss: 0.3785
Epoch 5/10, Batch 80/145, Loss: 0.3086
Epoch 5/10, Batch 90/145, Loss: 0.2800
Epoch 5/10, Batch 100/145, Loss: 0.1987
Epoch 5/10, Batch 110/145, Loss: 0.2096
Epoch 5/10, Batch 120/145, Loss: 0.1737
Epoch 5/10, Batch 130/145, Loss: 0.1297
Epoch 5/10, Batch 140/145, Loss: 0.2274
Epoch 5/10, Train Loss: 0.2401, Valid Loss: 0.2406
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3086
Epoch 6/10, Batch 20/145, Loss: 0.1046
Epoch 6/10, Batch 30/145, Loss: 0.2260
Epoch 6/10, Batch 40/145, Loss: 0.1925
Epoch 6/10, Batch 50/145, Loss: 0.2258
Epoch 6/10, Batch 60/145, Loss: 0.2364
Epoch 6/10, Batch 70/145, Loss: 0.2680
Epoch 6/10, Batch 80/145, Loss: 0.2898
Epoch 6/10, Batch 90/145, Loss: 0.2763
Epoch 6/10, Batch 100/145, Loss: 0.1688
Epoch 6/10, Batch 110/145, Loss: 0.2028
Epoch 6/10, Batch 120/145, Loss: 0.2427
Epoch 6/10, Batch 130/145, Loss: 0.1871
Epoch 6/10, Batch 140/145, Loss: 0.1997
Epoch 6/10, Train Loss: 0.2297, Valid Loss: 0.2383
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1801
Epoch 7/10, Batch 20/145, Loss: 0.1483
Epoch 7/10, Batch 30/145, Loss: 0.1697
Epoch 7/10, Batch 40/145, Loss: 0.5995
Epoch 7/10, Batch 50/145, Loss: 0.1707
Epoch 7/10, Batch 60/145, Loss: 0.2099
Epoch 7/10, Batch 70/145, Loss: 0.2240
Epoch 7/10, Batch 80/145, Loss: 0.1191
Epoch 7/10, Batch 90/145, Loss: 0.1539
Epoch 7/10, Batch 100/145, Loss: 0.1171
Epoch 7/10, Batch 110/145, Loss: 0.2242
Epoch 7/10, Batch 120/145, Loss: 0.2150
Epoch 7/10, Batch 130/145, Loss: 0.1018
Epoch 7/10, Batch 140/145, Loss: 0.1103
Epoch 7/10, Train Loss: 0.2161, Valid Loss: 0.2297
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2869
Epoch 8/10, Batch 20/145, Loss: 0.2281
Epoch 8/10, Batch 30/145, Loss: 0.1354
Epoch 8/10, Batch 40/145, Loss: 0.1335
Epoch 8/10, Batch 50/145, Loss: 0.1218
Epoch 8/10, Batch 60/145, Loss: 0.1433
Epoch 8/10, Batch 70/145, Loss: 0.1244
Epoch 8/10, Batch 80/145, Loss: 0.1552
Epoch 8/10, Batch 90/145, Loss: 0.2052
Epoch 8/10, Batch 100/145, Loss: 0.1760
Epoch 8/10, Batch 110/145, Loss: 0.3196
Epoch 8/10, Batch 120/145, Loss: 0.1685
Epoch 8/10, Batch 130/145, Loss: 0.2305
Epoch 8/10, Batch 140/145, Loss: 0.2725
Epoch 8/10, Train Loss: 0.2132, Valid Loss: 0.2222
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1219
Epoch 9/10, Batch 20/145, Loss: 0.2993
Epoch 9/10, Batch 30/145, Loss: 0.1853
Epoch 9/10, Batch 40/145, Loss: 0.1713
Epoch 9/10, Batch 50/145, Loss: 0.1989
Epoch 9/10, Batch 60/145, Loss: 0.1860
Epoch 9/10, Batch 70/145, Loss: 0.1033
Epoch 9/10, Batch 80/145, Loss: 0.1662
Epoch 9/10, Batch 90/145, Loss: 0.1418
Epoch 9/10, Batch 100/145, Loss: 0.2130
Epoch 9/10, Batch 110/145, Loss: 0.1078
Epoch 9/10, Batch 120/145, Loss: 0.2201
Epoch 9/10, Batch 130/145, Loss: 0.2583
Epoch 9/10, Batch 140/145, Loss: 0.0931
Epoch 9/10, Train Loss: 0.2095, Valid Loss: 0.2221
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1317
Epoch 10/10, Batch 20/145, Loss: 0.1343
Epoch 10/10, Batch 30/145, Loss: 0.1072
Epoch 10/10, Batch 40/145, Loss: 0.2141
Epoch 10/10, Batch 50/145, Loss: 0.4366
Epoch 10/10, Batch 60/145, Loss: 0.3099
Epoch 10/10, Batch 70/145, Loss: 0.1123
Epoch 10/10, Batch 80/145, Loss: 0.2767
Epoch 10/10, Batch 90/145, Loss: 0.2018
Epoch 10/10, Batch 100/145, Loss: 0.2206
Epoch 10/10, Batch 110/145, Loss: 0.1852
Epoch 10/10, Batch 120/145, Loss: 0.1322
Epoch 10/10, Batch 130/145, Loss: 0.2272
Epoch 10/10, Batch 140/145, Loss: 0.4860
Epoch 10/10, Train Loss: 0.1991, Valid Loss: 0.2132
Model saved!
Accuracy: 0.9252
Precision: 0.9237
Recall: 0.9252
F1-score: 0.9243
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5312
Epoch 1/10, Batch 20/145, Loss: 0.8766
Epoch 1/10, Batch 30/145, Loss: 0.9223
Epoch 1/10, Batch 40/145, Loss: 0.8635
Epoch 1/10, Batch 50/145, Loss: 0.5221
Epoch 1/10, Batch 60/145, Loss: 0.5753
Epoch 1/10, Batch 70/145, Loss: 0.5951
Epoch 1/10, Batch 80/145, Loss: 0.5338
Epoch 1/10, Batch 90/145, Loss: 0.5100
Epoch 1/10, Batch 100/145, Loss: 0.5669
Epoch 1/10, Batch 110/145, Loss: 0.4178
Epoch 1/10, Batch 120/145, Loss: 0.5564
Epoch 1/10, Batch 130/145, Loss: 0.4183
Epoch 1/10, Batch 140/145, Loss: 0.4158
Epoch 1/10, Train Loss: 0.6837, Valid Loss: 0.3930
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4264
Epoch 2/10, Batch 20/145, Loss: 0.3947
Epoch 2/10, Batch 30/145, Loss: 0.2988
Epoch 2/10, Batch 40/145, Loss: 0.5206
Epoch 2/10, Batch 50/145, Loss: 0.3823
Epoch 2/10, Batch 60/145, Loss: 0.4699
Epoch 2/10, Batch 70/145, Loss: 0.5212
Epoch 2/10, Batch 80/145, Loss: 0.3986
Epoch 2/10, Batch 90/145, Loss: 0.1153
Epoch 2/10, Batch 100/145, Loss: 0.3492
Epoch 2/10, Batch 110/145, Loss: 0.2994
Epoch 2/10, Batch 120/145, Loss: 0.4848
Epoch 2/10, Batch 130/145, Loss: 0.3330
Epoch 2/10, Batch 140/145, Loss: 0.2208
Epoch 2/10, Train Loss: 0.3612, Valid Loss: 0.3017
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2450
Epoch 3/10, Batch 20/145, Loss: 0.3471
Epoch 3/10, Batch 30/145, Loss: 0.2905
Epoch 3/10, Batch 40/145, Loss: 0.2323
Epoch 3/10, Batch 50/145, Loss: 0.2099
Epoch 3/10, Batch 60/145, Loss: 0.3509
Epoch 3/10, Batch 70/145, Loss: 0.0787
Epoch 3/10, Batch 80/145, Loss: 0.1782
Epoch 3/10, Batch 90/145, Loss: 0.4713
Epoch 3/10, Batch 100/145, Loss: 0.2141
Epoch 3/10, Batch 110/145, Loss: 0.2888
Epoch 3/10, Batch 120/145, Loss: 0.2109
Epoch 3/10, Batch 130/145, Loss: 0.2193
Epoch 3/10, Batch 140/145, Loss: 0.1888
Epoch 3/10, Train Loss: 0.3065, Valid Loss: 0.2720
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1276
Epoch 4/10, Batch 20/145, Loss: 0.1971
Epoch 4/10, Batch 30/145, Loss: 0.4862
Epoch 4/10, Batch 40/145, Loss: 0.3729
Epoch 4/10, Batch 50/145, Loss: 0.2617
Epoch 4/10, Batch 60/145, Loss: 0.2010
Epoch 4/10, Batch 70/145, Loss: 0.2601
Epoch 4/10, Batch 80/145, Loss: 0.2389
Epoch 4/10, Batch 90/145, Loss: 0.3388
Epoch 4/10, Batch 100/145, Loss: 0.3126
Epoch 4/10, Batch 110/145, Loss: 0.1892
Epoch 4/10, Batch 120/145, Loss: 0.1806
Epoch 4/10, Batch 130/145, Loss: 0.2817
Epoch 4/10, Batch 140/145, Loss: 0.2406
Epoch 4/10, Train Loss: 0.2645, Valid Loss: 0.2633
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2176
Epoch 5/10, Batch 20/145, Loss: 0.2132
Epoch 5/10, Batch 30/145, Loss: 0.1749
Epoch 5/10, Batch 40/145, Loss: 0.1528
Epoch 5/10, Batch 50/145, Loss: 0.2260
Epoch 5/10, Batch 60/145, Loss: 0.3291
Epoch 5/10, Batch 70/145, Loss: 0.2238
Epoch 5/10, Batch 80/145, Loss: 0.3242
Epoch 5/10, Batch 90/145, Loss: 0.3430
Epoch 5/10, Batch 100/145, Loss: 0.3052
Epoch 5/10, Batch 110/145, Loss: 0.1655
Epoch 5/10, Batch 120/145, Loss: 0.1970
Epoch 5/10, Batch 130/145, Loss: 0.2718
Epoch 5/10, Batch 140/145, Loss: 0.2097
Epoch 5/10, Train Loss: 0.2419, Valid Loss: 0.2499
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1988
Epoch 6/10, Batch 20/145, Loss: 0.2714
Epoch 6/10, Batch 30/145, Loss: 0.2621
Epoch 6/10, Batch 40/145, Loss: 0.1468
Epoch 6/10, Batch 50/145, Loss: 0.2324
Epoch 6/10, Batch 60/145, Loss: 0.0937
Epoch 6/10, Batch 70/145, Loss: 0.3469
Epoch 6/10, Batch 80/145, Loss: 0.3392
Epoch 6/10, Batch 90/145, Loss: 0.1873
Epoch 6/10, Batch 100/145, Loss: 0.1408
Epoch 6/10, Batch 110/145, Loss: 0.2857
Epoch 6/10, Batch 120/145, Loss: 0.1621
Epoch 6/10, Batch 130/145, Loss: 0.1082
Epoch 6/10, Batch 140/145, Loss: 0.2330
Epoch 6/10, Train Loss: 0.2259, Valid Loss: 0.2522
Epoch 7/10, Batch 10/145, Loss: 0.1318
Epoch 7/10, Batch 20/145, Loss: 0.1304
Epoch 7/10, Batch 30/145, Loss: 0.1705
Epoch 7/10, Batch 40/145, Loss: 0.3657
Epoch 7/10, Batch 50/145, Loss: 0.1985
Epoch 7/10, Batch 60/145, Loss: 0.1736
Epoch 7/10, Batch 70/145, Loss: 0.3302
Epoch 7/10, Batch 80/145, Loss: 0.2788
Epoch 7/10, Batch 90/145, Loss: 0.2510
Epoch 7/10, Batch 100/145, Loss: 0.2793
Epoch 7/10, Batch 110/145, Loss: 0.3065
Epoch 7/10, Batch 120/145, Loss: 0.0762
Epoch 7/10, Batch 130/145, Loss: 0.2756
Epoch 7/10, Batch 140/145, Loss: 0.3411
Epoch 7/10, Train Loss: 0.2195, Valid Loss: 0.2521
Epoch 8/10, Batch 10/145, Loss: 0.1973
Epoch 8/10, Batch 20/145, Loss: 0.1864
Epoch 8/10, Batch 30/145, Loss: 0.1048
Epoch 8/10, Batch 40/145, Loss: 0.2420
Epoch 8/10, Batch 50/145, Loss: 0.2893
Epoch 8/10, Batch 60/145, Loss: 0.1768
Epoch 8/10, Batch 70/145, Loss: 0.2172
Epoch 8/10, Batch 80/145, Loss: 0.3702
Epoch 8/10, Batch 90/145, Loss: 0.2183
Epoch 8/10, Batch 100/145, Loss: 0.4109
Epoch 8/10, Batch 110/145, Loss: 0.2721
Epoch 8/10, Batch 120/145, Loss: 0.1752
Epoch 8/10, Batch 130/145, Loss: 0.1883
Epoch 8/10, Batch 140/145, Loss: 0.1714
Epoch 8/10, Train Loss: 0.2108, Valid Loss: 0.2399
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1272
Epoch 9/10, Batch 20/145, Loss: 0.2858
Epoch 9/10, Batch 30/145, Loss: 0.1618
Epoch 9/10, Batch 40/145, Loss: 0.2543
Epoch 9/10, Batch 50/145, Loss: 0.2056
Epoch 9/10, Batch 60/145, Loss: 0.1319
Epoch 9/10, Batch 70/145, Loss: 0.3145
Epoch 9/10, Batch 80/145, Loss: 0.2993
Epoch 9/10, Batch 90/145, Loss: 0.1278
Epoch 9/10, Batch 100/145, Loss: 0.2124
Epoch 9/10, Batch 110/145, Loss: 0.0961
Epoch 9/10, Batch 120/145, Loss: 0.2429
Epoch 9/10, Batch 130/145, Loss: 0.1099
Epoch 9/10, Batch 140/145, Loss: 0.1322
Epoch 9/10, Train Loss: 0.2083, Valid Loss: 0.2422
Epoch 10/10, Batch 10/145, Loss: 0.2257
Epoch 10/10, Batch 20/145, Loss: 0.0944
Epoch 10/10, Batch 30/145, Loss: 0.1937
Epoch 10/10, Batch 40/145, Loss: 0.2727
Epoch 10/10, Batch 50/145, Loss: 0.2665
Epoch 10/10, Batch 60/145, Loss: 0.2048
Epoch 10/10, Batch 70/145, Loss: 0.2210
Epoch 10/10, Batch 80/145, Loss: 0.2636
Epoch 10/10, Batch 90/145, Loss: 0.1405
Epoch 10/10, Batch 100/145, Loss: 0.2349
Epoch 10/10, Batch 110/145, Loss: 0.2999
Epoch 10/10, Batch 120/145, Loss: 0.3795
Epoch 10/10, Batch 130/145, Loss: 0.1168
Epoch 10/10, Batch 140/145, Loss: 0.1743
Epoch 10/10, Train Loss: 0.1961, Valid Loss: 0.2275
Model saved!
Accuracy: 0.9252
Precision: 0.9231
Recall: 0.9252
F1-score: 0.9239
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5080
Epoch 1/10, Batch 20/145, Loss: 0.8871
Epoch 1/10, Batch 30/145, Loss: 0.8243
Epoch 1/10, Batch 40/145, Loss: 0.7308
Epoch 1/10, Batch 50/145, Loss: 0.6858
Epoch 1/10, Batch 60/145, Loss: 0.5038
Epoch 1/10, Batch 70/145, Loss: 0.5630
Epoch 1/10, Batch 80/145, Loss: 0.4700
Epoch 1/10, Batch 90/145, Loss: 0.4418
Epoch 1/10, Batch 100/145, Loss: 0.6163
Epoch 1/10, Batch 110/145, Loss: 0.4180
Epoch 1/10, Batch 120/145, Loss: 0.5625
Epoch 1/10, Batch 130/145, Loss: 0.3468
Epoch 1/10, Batch 140/145, Loss: 0.5462
Epoch 1/10, Train Loss: 0.6837, Valid Loss: 0.3893
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3764
Epoch 2/10, Batch 20/145, Loss: 0.4797
Epoch 2/10, Batch 30/145, Loss: 0.3426
Epoch 2/10, Batch 40/145, Loss: 0.3966
Epoch 2/10, Batch 50/145, Loss: 0.4275
Epoch 2/10, Batch 60/145, Loss: 0.4268
Epoch 2/10, Batch 70/145, Loss: 0.5685
Epoch 2/10, Batch 80/145, Loss: 0.3739
Epoch 2/10, Batch 90/145, Loss: 0.3993
Epoch 2/10, Batch 100/145, Loss: 0.2788
Epoch 2/10, Batch 110/145, Loss: 0.3601
Epoch 2/10, Batch 120/145, Loss: 0.4518
Epoch 2/10, Batch 130/145, Loss: 0.3102
Epoch 2/10, Batch 140/145, Loss: 0.2392
Epoch 2/10, Train Loss: 0.3581, Valid Loss: 0.3076
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2963
Epoch 3/10, Batch 20/145, Loss: 0.2278
Epoch 3/10, Batch 30/145, Loss: 0.3614
Epoch 3/10, Batch 40/145, Loss: 0.3539
Epoch 3/10, Batch 50/145, Loss: 0.2940
Epoch 3/10, Batch 60/145, Loss: 0.3633
Epoch 3/10, Batch 70/145, Loss: 0.1989
Epoch 3/10, Batch 80/145, Loss: 0.2149
Epoch 3/10, Batch 90/145, Loss: 0.6651
Epoch 3/10, Batch 100/145, Loss: 0.2904
Epoch 3/10, Batch 110/145, Loss: 0.3423
Epoch 3/10, Batch 120/145, Loss: 0.2525
Epoch 3/10, Batch 130/145, Loss: 0.1846
Epoch 3/10, Batch 140/145, Loss: 0.2126
Epoch 3/10, Train Loss: 0.3082, Valid Loss: 0.2734
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1762
Epoch 4/10, Batch 20/145, Loss: 0.1782
Epoch 4/10, Batch 30/145, Loss: 0.3208
Epoch 4/10, Batch 40/145, Loss: 0.3473
Epoch 4/10, Batch 50/145, Loss: 0.2371
Epoch 4/10, Batch 60/145, Loss: 0.1002
Epoch 4/10, Batch 70/145, Loss: 0.2505
Epoch 4/10, Batch 80/145, Loss: 0.3062
Epoch 4/10, Batch 90/145, Loss: 0.4025
Epoch 4/10, Batch 100/145, Loss: 0.2337
Epoch 4/10, Batch 110/145, Loss: 0.1600
Epoch 4/10, Batch 120/145, Loss: 0.1726
Epoch 4/10, Batch 130/145, Loss: 0.1651
Epoch 4/10, Batch 140/145, Loss: 0.3328
Epoch 4/10, Train Loss: 0.2653, Valid Loss: 0.2617
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1596
Epoch 5/10, Batch 20/145, Loss: 0.2865
Epoch 5/10, Batch 30/145, Loss: 0.2362
Epoch 5/10, Batch 40/145, Loss: 0.2069
Epoch 5/10, Batch 50/145, Loss: 0.1907
Epoch 5/10, Batch 60/145, Loss: 0.2703
Epoch 5/10, Batch 70/145, Loss: 0.3370
Epoch 5/10, Batch 80/145, Loss: 0.2280
Epoch 5/10, Batch 90/145, Loss: 0.1263
Epoch 5/10, Batch 100/145, Loss: 0.1319
Epoch 5/10, Batch 110/145, Loss: 0.1106
Epoch 5/10, Batch 120/145, Loss: 0.5274
Epoch 5/10, Batch 130/145, Loss: 0.3157
Epoch 5/10, Batch 140/145, Loss: 0.2222
Epoch 5/10, Train Loss: 0.2308, Valid Loss: 0.2495
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1940
Epoch 6/10, Batch 20/145, Loss: 0.2667
Epoch 6/10, Batch 30/145, Loss: 0.2479
Epoch 6/10, Batch 40/145, Loss: 0.1449
Epoch 6/10, Batch 50/145, Loss: 0.2940
Epoch 6/10, Batch 60/145, Loss: 0.1488
Epoch 6/10, Batch 70/145, Loss: 0.2969
Epoch 6/10, Batch 80/145, Loss: 0.2777
Epoch 6/10, Batch 90/145, Loss: 0.2299
Epoch 6/10, Batch 100/145, Loss: 0.2366
Epoch 6/10, Batch 110/145, Loss: 0.1277
Epoch 6/10, Batch 120/145, Loss: 0.2386
Epoch 6/10, Batch 130/145, Loss: 0.1953
Epoch 6/10, Batch 140/145, Loss: 0.2487
Epoch 6/10, Train Loss: 0.2200, Valid Loss: 0.2462
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2761
Epoch 7/10, Batch 20/145, Loss: 0.1728
Epoch 7/10, Batch 30/145, Loss: 0.1279
Epoch 7/10, Batch 40/145, Loss: 0.3944
Epoch 7/10, Batch 50/145, Loss: 0.1945
Epoch 7/10, Batch 60/145, Loss: 0.1671
Epoch 7/10, Batch 70/145, Loss: 0.2654
Epoch 7/10, Batch 80/145, Loss: 0.1623
Epoch 7/10, Batch 90/145, Loss: 0.2595
Epoch 7/10, Batch 100/145, Loss: 0.2204
Epoch 7/10, Batch 110/145, Loss: 0.3549
Epoch 7/10, Batch 120/145, Loss: 0.1278
Epoch 7/10, Batch 130/145, Loss: 0.3563
Epoch 7/10, Batch 140/145, Loss: 0.0898
Epoch 7/10, Train Loss: 0.2124, Valid Loss: 0.2415
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1600
Epoch 8/10, Batch 20/145, Loss: 0.1444
Epoch 8/10, Batch 30/145, Loss: 0.2298
Epoch 8/10, Batch 40/145, Loss: 0.2711
Epoch 8/10, Batch 50/145, Loss: 0.1423
Epoch 8/10, Batch 60/145, Loss: 0.2283
Epoch 8/10, Batch 70/145, Loss: 0.0856
Epoch 8/10, Batch 80/145, Loss: 0.1725
Epoch 8/10, Batch 90/145, Loss: 0.2798
Epoch 8/10, Batch 100/145, Loss: 0.3439
Epoch 8/10, Batch 110/145, Loss: 0.1550
Epoch 8/10, Batch 120/145, Loss: 0.1985
Epoch 8/10, Batch 130/145, Loss: 0.2551
Epoch 8/10, Batch 140/145, Loss: 0.1927
Epoch 8/10, Train Loss: 0.2079, Valid Loss: 0.2274
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1287
Epoch 9/10, Batch 20/145, Loss: 0.1595
Epoch 9/10, Batch 30/145, Loss: 0.1299
Epoch 9/10, Batch 40/145, Loss: 0.1232
Epoch 9/10, Batch 50/145, Loss: 0.2985
Epoch 9/10, Batch 60/145, Loss: 0.2063
Epoch 9/10, Batch 70/145, Loss: 0.0903
Epoch 9/10, Batch 80/145, Loss: 0.1715
Epoch 9/10, Batch 90/145, Loss: 0.1391
Epoch 9/10, Batch 100/145, Loss: 0.2244
Epoch 9/10, Batch 110/145, Loss: 0.1651
Epoch 9/10, Batch 120/145, Loss: 0.2161
Epoch 9/10, Batch 130/145, Loss: 0.2738
Epoch 9/10, Batch 140/145, Loss: 0.0533
Epoch 9/10, Train Loss: 0.1985, Valid Loss: 0.2255
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2778
Epoch 10/10, Batch 20/145, Loss: 0.1099
Epoch 10/10, Batch 30/145, Loss: 0.1653
Epoch 10/10, Batch 40/145, Loss: 0.1441
Epoch 10/10, Batch 50/145, Loss: 0.2537
Epoch 10/10, Batch 60/145, Loss: 0.1559
Epoch 10/10, Batch 70/145, Loss: 0.2081
Epoch 10/10, Batch 80/145, Loss: 0.4587
Epoch 10/10, Batch 90/145, Loss: 0.1412
Epoch 10/10, Batch 100/145, Loss: 0.2104
Epoch 10/10, Batch 110/145, Loss: 0.2218
Epoch 10/10, Batch 120/145, Loss: 0.1821
Epoch 10/10, Batch 130/145, Loss: 0.0912
Epoch 10/10, Batch 140/145, Loss: 0.2730
Epoch 10/10, Train Loss: 0.1937, Valid Loss: 0.2230
Model saved!
Accuracy: 0.9182
Precision: 0.9163
Recall: 0.9182
F1-score: 0.9169
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5592
Epoch 1/10, Batch 20/145, Loss: 0.9490
Epoch 1/10, Batch 30/145, Loss: 0.8998
Epoch 1/10, Batch 40/145, Loss: 0.8446
Epoch 1/10, Batch 50/145, Loss: 0.6943
Epoch 1/10, Batch 60/145, Loss: 0.5302
Epoch 1/10, Batch 70/145, Loss: 0.9288
Epoch 1/10, Batch 80/145, Loss: 0.4404
Epoch 1/10, Batch 90/145, Loss: 0.6834
Epoch 1/10, Batch 100/145, Loss: 0.6158
Epoch 1/10, Batch 110/145, Loss: 0.3906
Epoch 1/10, Batch 120/145, Loss: 0.5406
Epoch 1/10, Batch 130/145, Loss: 0.4268
Epoch 1/10, Batch 140/145, Loss: 0.4468
Epoch 1/10, Train Loss: 0.6886, Valid Loss: 0.3752
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3223
Epoch 2/10, Batch 20/145, Loss: 0.5249
Epoch 2/10, Batch 30/145, Loss: 0.3864
Epoch 2/10, Batch 40/145, Loss: 0.7293
Epoch 2/10, Batch 50/145, Loss: 0.3452
Epoch 2/10, Batch 60/145, Loss: 0.4275
Epoch 2/10, Batch 70/145, Loss: 0.5128
Epoch 2/10, Batch 80/145, Loss: 0.3406
Epoch 2/10, Batch 90/145, Loss: 0.3238
Epoch 2/10, Batch 100/145, Loss: 0.3512
Epoch 2/10, Batch 110/145, Loss: 0.2574
Epoch 2/10, Batch 120/145, Loss: 0.3746
Epoch 2/10, Batch 130/145, Loss: 0.2412
Epoch 2/10, Batch 140/145, Loss: 0.2707
Epoch 2/10, Train Loss: 0.3669, Valid Loss: 0.2915
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3324
Epoch 3/10, Batch 20/145, Loss: 0.3350
Epoch 3/10, Batch 30/145, Loss: 0.2223
Epoch 3/10, Batch 40/145, Loss: 0.2096
Epoch 3/10, Batch 50/145, Loss: 0.2404
Epoch 3/10, Batch 60/145, Loss: 0.2151
Epoch 3/10, Batch 70/145, Loss: 0.1812
Epoch 3/10, Batch 80/145, Loss: 0.2378
Epoch 3/10, Batch 90/145, Loss: 0.3369
Epoch 3/10, Batch 100/145, Loss: 0.3006
Epoch 3/10, Batch 110/145, Loss: 0.2015
Epoch 3/10, Batch 120/145, Loss: 0.1183
Epoch 3/10, Batch 130/145, Loss: 0.1796
Epoch 3/10, Batch 140/145, Loss: 0.2274
Epoch 3/10, Train Loss: 0.3036, Valid Loss: 0.2632
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1839
Epoch 4/10, Batch 20/145, Loss: 0.4051
Epoch 4/10, Batch 30/145, Loss: 0.3343
Epoch 4/10, Batch 40/145, Loss: 0.2668
Epoch 4/10, Batch 50/145, Loss: 0.2402
Epoch 4/10, Batch 60/145, Loss: 0.2620
Epoch 4/10, Batch 70/145, Loss: 0.1155
Epoch 4/10, Batch 80/145, Loss: 0.2234
Epoch 4/10, Batch 90/145, Loss: 0.2122
Epoch 4/10, Batch 100/145, Loss: 0.2324
Epoch 4/10, Batch 110/145, Loss: 0.3521
Epoch 4/10, Batch 120/145, Loss: 0.2718
Epoch 4/10, Batch 130/145, Loss: 0.2609
Epoch 4/10, Batch 140/145, Loss: 0.1987
Epoch 4/10, Train Loss: 0.2640, Valid Loss: 0.2526
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2550
Epoch 5/10, Batch 20/145, Loss: 0.2567
Epoch 5/10, Batch 30/145, Loss: 0.1445
Epoch 5/10, Batch 40/145, Loss: 0.2312
Epoch 5/10, Batch 50/145, Loss: 0.2003
Epoch 5/10, Batch 60/145, Loss: 0.1403
Epoch 5/10, Batch 70/145, Loss: 0.1621
Epoch 5/10, Batch 80/145, Loss: 0.2463
Epoch 5/10, Batch 90/145, Loss: 0.2388
Epoch 5/10, Batch 100/145, Loss: 0.2539
Epoch 5/10, Batch 110/145, Loss: 0.2107
Epoch 5/10, Batch 120/145, Loss: 0.1930
Epoch 5/10, Batch 130/145, Loss: 0.3291
Epoch 5/10, Batch 140/145, Loss: 0.2192
Epoch 5/10, Train Loss: 0.2383, Valid Loss: 0.2332
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2591
Epoch 6/10, Batch 20/145, Loss: 0.3729
Epoch 6/10, Batch 30/145, Loss: 0.3360
Epoch 6/10, Batch 40/145, Loss: 0.1666
Epoch 6/10, Batch 50/145, Loss: 0.3241
Epoch 6/10, Batch 60/145, Loss: 0.1124
Epoch 6/10, Batch 70/145, Loss: 0.2622
Epoch 6/10, Batch 80/145, Loss: 0.3111
Epoch 6/10, Batch 90/145, Loss: 0.1380
Epoch 6/10, Batch 100/145, Loss: 0.2055
Epoch 6/10, Batch 110/145, Loss: 0.0824
Epoch 6/10, Batch 120/145, Loss: 0.1948
Epoch 6/10, Batch 130/145, Loss: 0.2018
Epoch 6/10, Batch 140/145, Loss: 0.3190
Epoch 6/10, Train Loss: 0.2307, Valid Loss: 0.2345
Epoch 7/10, Batch 10/145, Loss: 0.4263
Epoch 7/10, Batch 20/145, Loss: 0.3711
Epoch 7/10, Batch 30/145, Loss: 0.1247
Epoch 7/10, Batch 40/145, Loss: 0.3647
Epoch 7/10, Batch 50/145, Loss: 0.2423
Epoch 7/10, Batch 60/145, Loss: 0.2365
Epoch 7/10, Batch 70/145, Loss: 0.2619
Epoch 7/10, Batch 80/145, Loss: 0.2153
Epoch 7/10, Batch 90/145, Loss: 0.3264
Epoch 7/10, Batch 100/145, Loss: 0.1655
Epoch 7/10, Batch 110/145, Loss: 0.1604
Epoch 7/10, Batch 120/145, Loss: 0.1759
Epoch 7/10, Batch 130/145, Loss: 0.4959
Epoch 7/10, Batch 140/145, Loss: 0.1472
Epoch 7/10, Train Loss: 0.2217, Valid Loss: 0.2229
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1973
Epoch 8/10, Batch 20/145, Loss: 0.1241
Epoch 8/10, Batch 30/145, Loss: 0.2363
Epoch 8/10, Batch 40/145, Loss: 0.2219
Epoch 8/10, Batch 50/145, Loss: 0.1093
Epoch 8/10, Batch 60/145, Loss: 0.2244
Epoch 8/10, Batch 70/145, Loss: 0.1319
Epoch 8/10, Batch 80/145, Loss: 0.0946
Epoch 8/10, Batch 90/145, Loss: 0.0796
Epoch 8/10, Batch 100/145, Loss: 0.1921
Epoch 8/10, Batch 110/145, Loss: 0.4050
Epoch 8/10, Batch 120/145, Loss: 0.1358
Epoch 8/10, Batch 130/145, Loss: 0.1636
Epoch 8/10, Batch 140/145, Loss: 0.2356
Epoch 8/10, Train Loss: 0.2151, Valid Loss: 0.2089
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3498
Epoch 9/10, Batch 20/145, Loss: 0.1133
Epoch 9/10, Batch 30/145, Loss: 0.1027
Epoch 9/10, Batch 40/145, Loss: 0.4437
Epoch 9/10, Batch 50/145, Loss: 0.2464
Epoch 9/10, Batch 60/145, Loss: 0.2158
Epoch 9/10, Batch 70/145, Loss: 0.1283
Epoch 9/10, Batch 80/145, Loss: 0.2009
Epoch 9/10, Batch 90/145, Loss: 0.2344
Epoch 9/10, Batch 100/145, Loss: 0.2299
Epoch 9/10, Batch 110/145, Loss: 0.2497
Epoch 9/10, Batch 120/145, Loss: 0.1834
Epoch 9/10, Batch 130/145, Loss: 0.2521
Epoch 9/10, Batch 140/145, Loss: 0.0789
Epoch 9/10, Train Loss: 0.2110, Valid Loss: 0.2041
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1262
Epoch 10/10, Batch 20/145, Loss: 0.3993
Epoch 10/10, Batch 30/145, Loss: 0.1938
Epoch 10/10, Batch 40/145, Loss: 0.2000
Epoch 10/10, Batch 50/145, Loss: 0.2174
Epoch 10/10, Batch 60/145, Loss: 0.4701
Epoch 10/10, Batch 70/145, Loss: 0.2225
Epoch 10/10, Batch 80/145, Loss: 0.3037
Epoch 10/10, Batch 90/145, Loss: 0.2057
Epoch 10/10, Batch 100/145, Loss: 0.2180
Epoch 10/10, Batch 110/145, Loss: 0.1975
Epoch 10/10, Batch 120/145, Loss: 0.1537
Epoch 10/10, Batch 130/145, Loss: 0.1978
Epoch 10/10, Batch 140/145, Loss: 0.1191
Epoch 10/10, Train Loss: 0.1977, Valid Loss: 0.2051
Accuracy: 0.9206
Precision: 0.9189
Recall: 0.9206
F1-score: 0.9191
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4978
Epoch 1/10, Batch 20/145, Loss: 0.9543
Epoch 1/10, Batch 30/145, Loss: 0.7896
Epoch 1/10, Batch 40/145, Loss: 0.8252
Epoch 1/10, Batch 50/145, Loss: 0.6200
Epoch 1/10, Batch 60/145, Loss: 0.5716
Epoch 1/10, Batch 70/145, Loss: 0.7540
Epoch 1/10, Batch 80/145, Loss: 0.4795
Epoch 1/10, Batch 90/145, Loss: 0.4843
Epoch 1/10, Batch 100/145, Loss: 0.6097
Epoch 1/10, Batch 110/145, Loss: 0.4526
Epoch 1/10, Batch 120/145, Loss: 0.5326
Epoch 1/10, Batch 130/145, Loss: 0.4580
Epoch 1/10, Batch 140/145, Loss: 0.4107
Epoch 1/10, Train Loss: 0.6849, Valid Loss: 0.3727
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4123
Epoch 2/10, Batch 20/145, Loss: 0.5745
Epoch 2/10, Batch 30/145, Loss: 0.4271
Epoch 2/10, Batch 40/145, Loss: 0.5955
Epoch 2/10, Batch 50/145, Loss: 0.4489
Epoch 2/10, Batch 60/145, Loss: 0.4045
Epoch 2/10, Batch 70/145, Loss: 0.4251
Epoch 2/10, Batch 80/145, Loss: 0.4644
Epoch 2/10, Batch 90/145, Loss: 0.2889
Epoch 2/10, Batch 100/145, Loss: 0.2420
Epoch 2/10, Batch 110/145, Loss: 0.2992
Epoch 2/10, Batch 120/145, Loss: 0.5021
Epoch 2/10, Batch 130/145, Loss: 0.3084
Epoch 2/10, Batch 140/145, Loss: 0.3159
Epoch 2/10, Train Loss: 0.3621, Valid Loss: 0.2895
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3013
Epoch 3/10, Batch 20/145, Loss: 0.2587
Epoch 3/10, Batch 30/145, Loss: 0.2476
Epoch 3/10, Batch 40/145, Loss: 0.2596
Epoch 3/10, Batch 50/145, Loss: 0.2400
Epoch 3/10, Batch 60/145, Loss: 0.2907
Epoch 3/10, Batch 70/145, Loss: 0.2699
Epoch 3/10, Batch 80/145, Loss: 0.3171
Epoch 3/10, Batch 90/145, Loss: 0.4786
Epoch 3/10, Batch 100/145, Loss: 0.2791
Epoch 3/10, Batch 110/145, Loss: 0.2541
Epoch 3/10, Batch 120/145, Loss: 0.2118
Epoch 3/10, Batch 130/145, Loss: 0.2556
Epoch 3/10, Batch 140/145, Loss: 0.2214
Epoch 3/10, Train Loss: 0.3075, Valid Loss: 0.2518
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2279
Epoch 4/10, Batch 20/145, Loss: 0.3922
Epoch 4/10, Batch 30/145, Loss: 0.2625
Epoch 4/10, Batch 40/145, Loss: 0.3115
Epoch 4/10, Batch 50/145, Loss: 0.3816
Epoch 4/10, Batch 60/145, Loss: 0.2897
Epoch 4/10, Batch 70/145, Loss: 0.1887
Epoch 4/10, Batch 80/145, Loss: 0.3116
Epoch 4/10, Batch 90/145, Loss: 0.2748
Epoch 4/10, Batch 100/145, Loss: 0.1874
Epoch 4/10, Batch 110/145, Loss: 0.1164
Epoch 4/10, Batch 120/145, Loss: 0.2606
Epoch 4/10, Batch 130/145, Loss: 0.1553
Epoch 4/10, Batch 140/145, Loss: 0.1611
Epoch 4/10, Train Loss: 0.2649, Valid Loss: 0.2431
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2110
Epoch 5/10, Batch 20/145, Loss: 0.2036
Epoch 5/10, Batch 30/145, Loss: 0.1472
Epoch 5/10, Batch 40/145, Loss: 0.1856
Epoch 5/10, Batch 50/145, Loss: 0.1924
Epoch 5/10, Batch 60/145, Loss: 0.1436
Epoch 5/10, Batch 70/145, Loss: 0.1790
Epoch 5/10, Batch 80/145, Loss: 0.2563
Epoch 5/10, Batch 90/145, Loss: 0.2202
Epoch 5/10, Batch 100/145, Loss: 0.1908
Epoch 5/10, Batch 110/145, Loss: 0.2662
Epoch 5/10, Batch 120/145, Loss: 0.2177
Epoch 5/10, Batch 130/145, Loss: 0.2169
Epoch 5/10, Batch 140/145, Loss: 0.1886
Epoch 5/10, Train Loss: 0.2371, Valid Loss: 0.2216
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1615
Epoch 6/10, Batch 20/145, Loss: 0.1840
Epoch 6/10, Batch 30/145, Loss: 0.2405
Epoch 6/10, Batch 40/145, Loss: 0.2895
Epoch 6/10, Batch 50/145, Loss: 0.3318
Epoch 6/10, Batch 60/145, Loss: 0.1571
Epoch 6/10, Batch 70/145, Loss: 0.2200
Epoch 6/10, Batch 80/145, Loss: 0.2424
Epoch 6/10, Batch 90/145, Loss: 0.1959
Epoch 6/10, Batch 100/145, Loss: 0.2304
Epoch 6/10, Batch 110/145, Loss: 0.2075
Epoch 6/10, Batch 120/145, Loss: 0.2819
Epoch 6/10, Batch 130/145, Loss: 0.1053
Epoch 6/10, Batch 140/145, Loss: 0.1682
Epoch 6/10, Train Loss: 0.2274, Valid Loss: 0.2197
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3690
Epoch 7/10, Batch 20/145, Loss: 0.2100
Epoch 7/10, Batch 30/145, Loss: 0.1068
Epoch 7/10, Batch 40/145, Loss: 0.4501
Epoch 7/10, Batch 50/145, Loss: 0.2235
Epoch 7/10, Batch 60/145, Loss: 0.1673
Epoch 7/10, Batch 70/145, Loss: 0.2234
Epoch 7/10, Batch 80/145, Loss: 0.1064
Epoch 7/10, Batch 90/145, Loss: 0.2582
Epoch 7/10, Batch 100/145, Loss: 0.1798
Epoch 7/10, Batch 110/145, Loss: 0.2031
Epoch 7/10, Batch 120/145, Loss: 0.1064
Epoch 7/10, Batch 130/145, Loss: 0.4524
Epoch 7/10, Batch 140/145, Loss: 0.2041
Epoch 7/10, Train Loss: 0.2156, Valid Loss: 0.2166
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2237
Epoch 8/10, Batch 20/145, Loss: 0.1267
Epoch 8/10, Batch 30/145, Loss: 0.1717
Epoch 8/10, Batch 40/145, Loss: 0.2948
Epoch 8/10, Batch 50/145, Loss: 0.1327
Epoch 8/10, Batch 60/145, Loss: 0.3024
Epoch 8/10, Batch 70/145, Loss: 0.0881
Epoch 8/10, Batch 80/145, Loss: 0.1729
Epoch 8/10, Batch 90/145, Loss: 0.2075
Epoch 8/10, Batch 100/145, Loss: 0.1767
Epoch 8/10, Batch 110/145, Loss: 0.2839
Epoch 8/10, Batch 120/145, Loss: 0.2316
Epoch 8/10, Batch 130/145, Loss: 0.1522
Epoch 8/10, Batch 140/145, Loss: 0.1889
Epoch 8/10, Train Loss: 0.2107, Valid Loss: 0.2126
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1793
Epoch 9/10, Batch 20/145, Loss: 0.1847
Epoch 9/10, Batch 30/145, Loss: 0.0924
Epoch 9/10, Batch 40/145, Loss: 0.2422
Epoch 9/10, Batch 50/145, Loss: 0.1851
Epoch 9/10, Batch 60/145, Loss: 0.1306
Epoch 9/10, Batch 70/145, Loss: 0.2886
Epoch 9/10, Batch 80/145, Loss: 0.2728
Epoch 9/10, Batch 90/145, Loss: 0.2646
Epoch 9/10, Batch 100/145, Loss: 0.3340
Epoch 9/10, Batch 110/145, Loss: 0.1852
Epoch 9/10, Batch 120/145, Loss: 0.2057
Epoch 9/10, Batch 130/145, Loss: 0.1697
Epoch 9/10, Batch 140/145, Loss: 0.1122
Epoch 9/10, Train Loss: 0.2075, Valid Loss: 0.2035
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1154
Epoch 10/10, Batch 20/145, Loss: 0.2447
Epoch 10/10, Batch 30/145, Loss: 0.1238
Epoch 10/10, Batch 40/145, Loss: 0.1763
Epoch 10/10, Batch 50/145, Loss: 0.2217
Epoch 10/10, Batch 60/145, Loss: 0.2791
Epoch 10/10, Batch 70/145, Loss: 0.2078
Epoch 10/10, Batch 80/145, Loss: 0.5328
Epoch 10/10, Batch 90/145, Loss: 0.1303
Epoch 10/10, Batch 100/145, Loss: 0.2358
Epoch 10/10, Batch 110/145, Loss: 0.2587
Epoch 10/10, Batch 120/145, Loss: 0.1508
Epoch 10/10, Batch 130/145, Loss: 0.1400
Epoch 10/10, Batch 140/145, Loss: 0.2320
Epoch 10/10, Train Loss: 0.2022, Valid Loss: 0.1980
Model saved!
Accuracy: 0.9241
Precision: 0.9221
Recall: 0.9241
F1-score: 0.9229
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4198
Epoch 1/10, Batch 20/145, Loss: 0.9164
Epoch 1/10, Batch 30/145, Loss: 0.7787
Epoch 1/10, Batch 40/145, Loss: 0.7414
Epoch 1/10, Batch 50/145, Loss: 0.6479
Epoch 1/10, Batch 60/145, Loss: 0.4314
Epoch 1/10, Batch 70/145, Loss: 0.7428
Epoch 1/10, Batch 80/145, Loss: 0.4746
Epoch 1/10, Batch 90/145, Loss: 0.5530
Epoch 1/10, Batch 100/145, Loss: 0.4378
Epoch 1/10, Batch 110/145, Loss: 0.3589
Epoch 1/10, Batch 120/145, Loss: 0.5186
Epoch 1/10, Batch 130/145, Loss: 0.3887
Epoch 1/10, Batch 140/145, Loss: 0.3174
Epoch 1/10, Train Loss: 0.6867, Valid Loss: 0.3612
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2973
Epoch 2/10, Batch 20/145, Loss: 0.5881
Epoch 2/10, Batch 30/145, Loss: 0.2749
Epoch 2/10, Batch 40/145, Loss: 0.4772
Epoch 2/10, Batch 50/145, Loss: 0.2250
Epoch 2/10, Batch 60/145, Loss: 0.5275
Epoch 2/10, Batch 70/145, Loss: 0.5328
Epoch 2/10, Batch 80/145, Loss: 0.2228
Epoch 2/10, Batch 90/145, Loss: 0.1874
Epoch 2/10, Batch 100/145, Loss: 0.3318
Epoch 2/10, Batch 110/145, Loss: 0.3168
Epoch 2/10, Batch 120/145, Loss: 0.4181
Epoch 2/10, Batch 130/145, Loss: 0.2398
Epoch 2/10, Batch 140/145, Loss: 0.2398
Epoch 2/10, Train Loss: 0.3612, Valid Loss: 0.2702
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2606
Epoch 3/10, Batch 20/145, Loss: 0.2050
Epoch 3/10, Batch 30/145, Loss: 0.2975
Epoch 3/10, Batch 40/145, Loss: 0.2747
Epoch 3/10, Batch 50/145, Loss: 0.3676
Epoch 3/10, Batch 60/145, Loss: 0.2625
Epoch 3/10, Batch 70/145, Loss: 0.1991
Epoch 3/10, Batch 80/145, Loss: 0.2560
Epoch 3/10, Batch 90/145, Loss: 0.6756
Epoch 3/10, Batch 100/145, Loss: 0.2887
Epoch 3/10, Batch 110/145, Loss: 0.2494
Epoch 3/10, Batch 120/145, Loss: 0.1769
Epoch 3/10, Batch 130/145, Loss: 0.2532
Epoch 3/10, Batch 140/145, Loss: 0.1626
Epoch 3/10, Train Loss: 0.3056, Valid Loss: 0.2472
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2417
Epoch 4/10, Batch 20/145, Loss: 0.2884
Epoch 4/10, Batch 30/145, Loss: 0.2901
Epoch 4/10, Batch 40/145, Loss: 0.2006
Epoch 4/10, Batch 50/145, Loss: 0.2029
Epoch 4/10, Batch 60/145, Loss: 0.2624
Epoch 4/10, Batch 70/145, Loss: 0.3061
Epoch 4/10, Batch 80/145, Loss: 0.2041
Epoch 4/10, Batch 90/145, Loss: 0.4235
Epoch 4/10, Batch 100/145, Loss: 0.1442
Epoch 4/10, Batch 110/145, Loss: 0.1387
Epoch 4/10, Batch 120/145, Loss: 0.1747
Epoch 4/10, Batch 130/145, Loss: 0.2769
Epoch 4/10, Batch 140/145, Loss: 0.1783
Epoch 4/10, Train Loss: 0.2653, Valid Loss: 0.2326
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1838
Epoch 5/10, Batch 20/145, Loss: 0.1358
Epoch 5/10, Batch 30/145, Loss: 0.3278
Epoch 5/10, Batch 40/145, Loss: 0.2394
Epoch 5/10, Batch 50/145, Loss: 0.1227
Epoch 5/10, Batch 60/145, Loss: 0.1477
Epoch 5/10, Batch 70/145, Loss: 0.2393
Epoch 5/10, Batch 80/145, Loss: 0.2003
Epoch 5/10, Batch 90/145, Loss: 0.1256
Epoch 5/10, Batch 100/145, Loss: 0.2776
Epoch 5/10, Batch 110/145, Loss: 0.1072
Epoch 5/10, Batch 120/145, Loss: 0.2711
Epoch 5/10, Batch 130/145, Loss: 0.1515
Epoch 5/10, Batch 140/145, Loss: 0.2378
Epoch 5/10, Train Loss: 0.2335, Valid Loss: 0.2253
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1493
Epoch 6/10, Batch 20/145, Loss: 0.3029
Epoch 6/10, Batch 30/145, Loss: 0.2184
Epoch 6/10, Batch 40/145, Loss: 0.2729
Epoch 6/10, Batch 50/145, Loss: 0.2696
Epoch 6/10, Batch 60/145, Loss: 0.2096
Epoch 6/10, Batch 70/145, Loss: 0.2235
Epoch 6/10, Batch 80/145, Loss: 0.4263
Epoch 6/10, Batch 90/145, Loss: 0.1865
Epoch 6/10, Batch 100/145, Loss: 0.1303
Epoch 6/10, Batch 110/145, Loss: 0.0936
Epoch 6/10, Batch 120/145, Loss: 0.3133
Epoch 6/10, Batch 130/145, Loss: 0.0801
Epoch 6/10, Batch 140/145, Loss: 0.2664
Epoch 6/10, Train Loss: 0.2236, Valid Loss: 0.2127
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1734
Epoch 7/10, Batch 20/145, Loss: 0.2218
Epoch 7/10, Batch 30/145, Loss: 0.2692
Epoch 7/10, Batch 40/145, Loss: 0.2428
Epoch 7/10, Batch 50/145, Loss: 0.2512
Epoch 7/10, Batch 60/145, Loss: 0.1419
Epoch 7/10, Batch 70/145, Loss: 0.2820
Epoch 7/10, Batch 80/145, Loss: 0.1727
Epoch 7/10, Batch 90/145, Loss: 0.3869
Epoch 7/10, Batch 100/145, Loss: 0.1403
Epoch 7/10, Batch 110/145, Loss: 0.3006
Epoch 7/10, Batch 120/145, Loss: 0.2238
Epoch 7/10, Batch 130/145, Loss: 0.3217
Epoch 7/10, Batch 140/145, Loss: 0.1460
Epoch 7/10, Train Loss: 0.2166, Valid Loss: 0.1994
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1561
Epoch 8/10, Batch 20/145, Loss: 0.0862
Epoch 8/10, Batch 30/145, Loss: 0.2161
Epoch 8/10, Batch 40/145, Loss: 0.2648
Epoch 8/10, Batch 50/145, Loss: 0.2935
Epoch 8/10, Batch 60/145, Loss: 0.2018
Epoch 8/10, Batch 70/145, Loss: 0.1284
Epoch 8/10, Batch 80/145, Loss: 0.2064
Epoch 8/10, Batch 90/145, Loss: 0.2319
Epoch 8/10, Batch 100/145, Loss: 0.4355
Epoch 8/10, Batch 110/145, Loss: 0.2196
Epoch 8/10, Batch 120/145, Loss: 0.1677
Epoch 8/10, Batch 130/145, Loss: 0.1691
Epoch 8/10, Batch 140/145, Loss: 0.3208
Epoch 8/10, Train Loss: 0.2110, Valid Loss: 0.2062
Epoch 9/10, Batch 10/145, Loss: 0.2014
Epoch 9/10, Batch 20/145, Loss: 0.2029
Epoch 9/10, Batch 30/145, Loss: 0.1401
Epoch 9/10, Batch 40/145, Loss: 0.1772
Epoch 9/10, Batch 50/145, Loss: 0.2505
Epoch 9/10, Batch 60/145, Loss: 0.1950
Epoch 9/10, Batch 70/145, Loss: 0.1855
Epoch 9/10, Batch 80/145, Loss: 0.0815
Epoch 9/10, Batch 90/145, Loss: 0.1170
Epoch 9/10, Batch 100/145, Loss: 0.2273
Epoch 9/10, Batch 110/145, Loss: 0.1013
Epoch 9/10, Batch 120/145, Loss: 0.1884
Epoch 9/10, Batch 130/145, Loss: 0.2897
Epoch 9/10, Batch 140/145, Loss: 0.1020
Epoch 9/10, Train Loss: 0.1984, Valid Loss: 0.1943
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1918
Epoch 10/10, Batch 20/145, Loss: 0.1189
Epoch 10/10, Batch 30/145, Loss: 0.1156
Epoch 10/10, Batch 40/145, Loss: 0.3002
Epoch 10/10, Batch 50/145, Loss: 0.2170
Epoch 10/10, Batch 60/145, Loss: 0.3214
Epoch 10/10, Batch 70/145, Loss: 0.0990
Epoch 10/10, Batch 80/145, Loss: 0.3356
Epoch 10/10, Batch 90/145, Loss: 0.1875
Epoch 10/10, Batch 100/145, Loss: 0.1269
Epoch 10/10, Batch 110/145, Loss: 0.3004
Epoch 10/10, Batch 120/145, Loss: 0.2644
Epoch 10/10, Batch 130/145, Loss: 0.1435
Epoch 10/10, Batch 140/145, Loss: 0.3286
Epoch 10/10, Train Loss: 0.1962, Valid Loss: 0.1919
Model saved!
Accuracy: 0.9171
Precision: 0.9155
Recall: 0.9171
F1-score: 0.9161
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5174
Epoch 1/10, Batch 20/145, Loss: 0.9131
Epoch 1/10, Batch 30/145, Loss: 0.8568
Epoch 1/10, Batch 40/145, Loss: 0.9650
Epoch 1/10, Batch 50/145, Loss: 0.4912
Epoch 1/10, Batch 60/145, Loss: 0.6226
Epoch 1/10, Batch 70/145, Loss: 0.5399
Epoch 1/10, Batch 80/145, Loss: 0.4756
Epoch 1/10, Batch 90/145, Loss: 0.4871
Epoch 1/10, Batch 100/145, Loss: 0.6126
Epoch 1/10, Batch 110/145, Loss: 0.4301
Epoch 1/10, Batch 120/145, Loss: 0.7333
Epoch 1/10, Batch 130/145, Loss: 0.3600
Epoch 1/10, Batch 140/145, Loss: 0.4193
Epoch 1/10, Train Loss: 0.6846, Valid Loss: 0.3807
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2801
Epoch 2/10, Batch 20/145, Loss: 0.3844
Epoch 2/10, Batch 30/145, Loss: 0.4517
Epoch 2/10, Batch 40/145, Loss: 0.4600
Epoch 2/10, Batch 50/145, Loss: 0.3891
Epoch 2/10, Batch 60/145, Loss: 0.4290
Epoch 2/10, Batch 70/145, Loss: 0.4984
Epoch 2/10, Batch 80/145, Loss: 0.3582
Epoch 2/10, Batch 90/145, Loss: 0.3374
Epoch 2/10, Batch 100/145, Loss: 0.4174
Epoch 2/10, Batch 110/145, Loss: 0.2440
Epoch 2/10, Batch 120/145, Loss: 0.3173
Epoch 2/10, Batch 130/145, Loss: 0.3561
Epoch 2/10, Batch 140/145, Loss: 0.2687
Epoch 2/10, Train Loss: 0.3638, Valid Loss: 0.2961
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1736
Epoch 3/10, Batch 20/145, Loss: 0.2782
Epoch 3/10, Batch 30/145, Loss: 0.1792
Epoch 3/10, Batch 40/145, Loss: 0.2500
Epoch 3/10, Batch 50/145, Loss: 0.3413
Epoch 3/10, Batch 60/145, Loss: 0.5302
Epoch 3/10, Batch 70/145, Loss: 0.2091
Epoch 3/10, Batch 80/145, Loss: 0.2772
Epoch 3/10, Batch 90/145, Loss: 0.5202
Epoch 3/10, Batch 100/145, Loss: 0.3477
Epoch 3/10, Batch 110/145, Loss: 0.2249
Epoch 3/10, Batch 120/145, Loss: 0.1628
Epoch 3/10, Batch 130/145, Loss: 0.1911
Epoch 3/10, Batch 140/145, Loss: 0.3423
Epoch 3/10, Train Loss: 0.3038, Valid Loss: 0.2733
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2706
Epoch 4/10, Batch 20/145, Loss: 0.3936
Epoch 4/10, Batch 30/145, Loss: 0.3482
Epoch 4/10, Batch 40/145, Loss: 0.2706
Epoch 4/10, Batch 50/145, Loss: 0.2308
Epoch 4/10, Batch 60/145, Loss: 0.1772
Epoch 4/10, Batch 70/145, Loss: 0.2985
Epoch 4/10, Batch 80/145, Loss: 0.2900
Epoch 4/10, Batch 90/145, Loss: 0.2089
Epoch 4/10, Batch 100/145, Loss: 0.2311
Epoch 4/10, Batch 110/145, Loss: 0.2037
Epoch 4/10, Batch 120/145, Loss: 0.1342
Epoch 4/10, Batch 130/145, Loss: 0.3117
Epoch 4/10, Batch 140/145, Loss: 0.2268
Epoch 4/10, Train Loss: 0.2668, Valid Loss: 0.2504
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2844
Epoch 5/10, Batch 20/145, Loss: 0.1946
Epoch 5/10, Batch 30/145, Loss: 0.1759
Epoch 5/10, Batch 40/145, Loss: 0.1874
Epoch 5/10, Batch 50/145, Loss: 0.1587
Epoch 5/10, Batch 60/145, Loss: 0.2272
Epoch 5/10, Batch 70/145, Loss: 0.4162
Epoch 5/10, Batch 80/145, Loss: 0.2860
Epoch 5/10, Batch 90/145, Loss: 0.2504
Epoch 5/10, Batch 100/145, Loss: 0.1837
Epoch 5/10, Batch 110/145, Loss: 0.1746
Epoch 5/10, Batch 120/145, Loss: 0.1930
Epoch 5/10, Batch 130/145, Loss: 0.3668
Epoch 5/10, Batch 140/145, Loss: 0.2361
Epoch 5/10, Train Loss: 0.2403, Valid Loss: 0.2405
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2356
Epoch 6/10, Batch 20/145, Loss: 0.2206
Epoch 6/10, Batch 30/145, Loss: 0.3620
Epoch 6/10, Batch 40/145, Loss: 0.1315
Epoch 6/10, Batch 50/145, Loss: 0.2290
Epoch 6/10, Batch 60/145, Loss: 0.2552
Epoch 6/10, Batch 70/145, Loss: 0.4577
Epoch 6/10, Batch 80/145, Loss: 0.5213
Epoch 6/10, Batch 90/145, Loss: 0.2438
Epoch 6/10, Batch 100/145, Loss: 0.2673
Epoch 6/10, Batch 110/145, Loss: 0.2347
Epoch 6/10, Batch 120/145, Loss: 0.2350
Epoch 6/10, Batch 130/145, Loss: 0.1112
Epoch 6/10, Batch 140/145, Loss: 0.4079
Epoch 6/10, Train Loss: 0.2318, Valid Loss: 0.2396
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3687
Epoch 7/10, Batch 20/145, Loss: 0.1766
Epoch 7/10, Batch 30/145, Loss: 0.1156
Epoch 7/10, Batch 40/145, Loss: 0.3546
Epoch 7/10, Batch 50/145, Loss: 0.3970
Epoch 7/10, Batch 60/145, Loss: 0.2453
Epoch 7/10, Batch 70/145, Loss: 0.3752
Epoch 7/10, Batch 80/145, Loss: 0.1641
Epoch 7/10, Batch 90/145, Loss: 0.1924
Epoch 7/10, Batch 100/145, Loss: 0.1511
Epoch 7/10, Batch 110/145, Loss: 0.3950
Epoch 7/10, Batch 120/145, Loss: 0.2769
Epoch 7/10, Batch 130/145, Loss: 0.1672
Epoch 7/10, Batch 140/145, Loss: 0.1623
Epoch 7/10, Train Loss: 0.2190, Valid Loss: 0.2293
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1711
Epoch 8/10, Batch 20/145, Loss: 0.1641
Epoch 8/10, Batch 30/145, Loss: 0.2256
Epoch 8/10, Batch 40/145, Loss: 0.4494
Epoch 8/10, Batch 50/145, Loss: 0.3663
Epoch 8/10, Batch 60/145, Loss: 0.2277
Epoch 8/10, Batch 70/145, Loss: 0.1452
Epoch 8/10, Batch 80/145, Loss: 0.1911
Epoch 8/10, Batch 90/145, Loss: 0.1213
Epoch 8/10, Batch 100/145, Loss: 0.4017
Epoch 8/10, Batch 110/145, Loss: 0.3361
Epoch 8/10, Batch 120/145, Loss: 0.1219
Epoch 8/10, Batch 130/145, Loss: 0.1129
Epoch 8/10, Batch 140/145, Loss: 0.2692
Epoch 8/10, Train Loss: 0.2107, Valid Loss: 0.2212
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2456
Epoch 9/10, Batch 20/145, Loss: 0.2330
Epoch 9/10, Batch 30/145, Loss: 0.1760
Epoch 9/10, Batch 40/145, Loss: 0.1593
Epoch 9/10, Batch 50/145, Loss: 0.1753
Epoch 9/10, Batch 60/145, Loss: 0.2614
Epoch 9/10, Batch 70/145, Loss: 0.1951
Epoch 9/10, Batch 80/145, Loss: 0.3073
Epoch 9/10, Batch 90/145, Loss: 0.0948
Epoch 9/10, Batch 100/145, Loss: 0.2873
Epoch 9/10, Batch 110/145, Loss: 0.0995
Epoch 9/10, Batch 120/145, Loss: 0.2946
Epoch 9/10, Batch 130/145, Loss: 0.2409
Epoch 9/10, Batch 140/145, Loss: 0.2027
Epoch 9/10, Train Loss: 0.2048, Valid Loss: 0.2157
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2389
Epoch 10/10, Batch 20/145, Loss: 0.1520
Epoch 10/10, Batch 30/145, Loss: 0.0796
Epoch 10/10, Batch 40/145, Loss: 0.2424
Epoch 10/10, Batch 50/145, Loss: 0.1358
Epoch 10/10, Batch 60/145, Loss: 0.2167
Epoch 10/10, Batch 70/145, Loss: 0.2525
Epoch 10/10, Batch 80/145, Loss: 0.3757
Epoch 10/10, Batch 90/145, Loss: 0.2591
Epoch 10/10, Batch 100/145, Loss: 0.2408
Epoch 10/10, Batch 110/145, Loss: 0.3105
Epoch 10/10, Batch 120/145, Loss: 0.1208
Epoch 10/10, Batch 130/145, Loss: 0.3153
Epoch 10/10, Batch 140/145, Loss: 0.0990
Epoch 10/10, Train Loss: 0.1940, Valid Loss: 0.2149
Model saved!
Accuracy: 0.9159
Precision: 0.9139
Recall: 0.9159
F1-score: 0.9141
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4461
Epoch 1/10, Batch 20/145, Loss: 0.8623
Epoch 1/10, Batch 30/145, Loss: 0.8433
Epoch 1/10, Batch 40/145, Loss: 0.8168
Epoch 1/10, Batch 50/145, Loss: 0.6226
Epoch 1/10, Batch 60/145, Loss: 0.6594
Epoch 1/10, Batch 70/145, Loss: 0.5815
Epoch 1/10, Batch 80/145, Loss: 0.4957
Epoch 1/10, Batch 90/145, Loss: 0.4733
Epoch 1/10, Batch 100/145, Loss: 0.6180
Epoch 1/10, Batch 110/145, Loss: 0.5057
Epoch 1/10, Batch 120/145, Loss: 0.4951
Epoch 1/10, Batch 130/145, Loss: 0.5332
Epoch 1/10, Batch 140/145, Loss: 0.4759
Epoch 1/10, Train Loss: 0.6827, Valid Loss: 0.3793
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2754
Epoch 2/10, Batch 20/145, Loss: 0.5188
Epoch 2/10, Batch 30/145, Loss: 0.2440
Epoch 2/10, Batch 40/145, Loss: 0.3655
Epoch 2/10, Batch 50/145, Loss: 0.2273
Epoch 2/10, Batch 60/145, Loss: 0.4012
Epoch 2/10, Batch 70/145, Loss: 0.4725
Epoch 2/10, Batch 80/145, Loss: 0.4674
Epoch 2/10, Batch 90/145, Loss: 0.2830
Epoch 2/10, Batch 100/145, Loss: 0.3574
Epoch 2/10, Batch 110/145, Loss: 0.1934
Epoch 2/10, Batch 120/145, Loss: 0.2750
Epoch 2/10, Batch 130/145, Loss: 0.3273
Epoch 2/10, Batch 140/145, Loss: 0.3308
Epoch 2/10, Train Loss: 0.3588, Valid Loss: 0.3001
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2317
Epoch 3/10, Batch 20/145, Loss: 0.3236
Epoch 3/10, Batch 30/145, Loss: 0.2330
Epoch 3/10, Batch 40/145, Loss: 0.2124
Epoch 3/10, Batch 50/145, Loss: 0.4019
Epoch 3/10, Batch 60/145, Loss: 0.2390
Epoch 3/10, Batch 70/145, Loss: 0.3417
Epoch 3/10, Batch 80/145, Loss: 0.3141
Epoch 3/10, Batch 90/145, Loss: 0.3803
Epoch 3/10, Batch 100/145, Loss: 0.1908
Epoch 3/10, Batch 110/145, Loss: 0.1807
Epoch 3/10, Batch 120/145, Loss: 0.2667
Epoch 3/10, Batch 130/145, Loss: 0.3716
Epoch 3/10, Batch 140/145, Loss: 0.2079
Epoch 3/10, Train Loss: 0.2961, Valid Loss: 0.2674
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2307
Epoch 4/10, Batch 20/145, Loss: 0.2870
Epoch 4/10, Batch 30/145, Loss: 0.2796
Epoch 4/10, Batch 40/145, Loss: 0.1896
Epoch 4/10, Batch 50/145, Loss: 0.1228
Epoch 4/10, Batch 60/145, Loss: 0.1731
Epoch 4/10, Batch 70/145, Loss: 0.2833
Epoch 4/10, Batch 80/145, Loss: 0.2395
Epoch 4/10, Batch 90/145, Loss: 0.2472
Epoch 4/10, Batch 100/145, Loss: 0.1613
Epoch 4/10, Batch 110/145, Loss: 0.1830
Epoch 4/10, Batch 120/145, Loss: 0.3211
Epoch 4/10, Batch 130/145, Loss: 0.2440
Epoch 4/10, Batch 140/145, Loss: 0.1882
Epoch 4/10, Train Loss: 0.2576, Valid Loss: 0.2586
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1985
Epoch 5/10, Batch 20/145, Loss: 0.2705
Epoch 5/10, Batch 30/145, Loss: 0.1468
Epoch 5/10, Batch 40/145, Loss: 0.2958
Epoch 5/10, Batch 50/145, Loss: 0.1284
Epoch 5/10, Batch 60/145, Loss: 0.3215
Epoch 5/10, Batch 70/145, Loss: 0.2727
Epoch 5/10, Batch 80/145, Loss: 0.4290
Epoch 5/10, Batch 90/145, Loss: 0.2768
Epoch 5/10, Batch 100/145, Loss: 0.1713
Epoch 5/10, Batch 110/145, Loss: 0.1111
Epoch 5/10, Batch 120/145, Loss: 0.2781
Epoch 5/10, Batch 130/145, Loss: 0.3055
Epoch 5/10, Batch 140/145, Loss: 0.1540
Epoch 5/10, Train Loss: 0.2354, Valid Loss: 0.2499
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1543
Epoch 6/10, Batch 20/145, Loss: 0.2841
Epoch 6/10, Batch 30/145, Loss: 0.2218
Epoch 6/10, Batch 40/145, Loss: 0.2724
Epoch 6/10, Batch 50/145, Loss: 0.3538
Epoch 6/10, Batch 60/145, Loss: 0.2557
Epoch 6/10, Batch 70/145, Loss: 0.2725
Epoch 6/10, Batch 80/145, Loss: 0.3198
Epoch 6/10, Batch 90/145, Loss: 0.3166
Epoch 6/10, Batch 100/145, Loss: 0.1927
Epoch 6/10, Batch 110/145, Loss: 0.2133
Epoch 6/10, Batch 120/145, Loss: 0.2897
Epoch 6/10, Batch 130/145, Loss: 0.2578
Epoch 6/10, Batch 140/145, Loss: 0.2608
Epoch 6/10, Train Loss: 0.2238, Valid Loss: 0.2458
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.4740
Epoch 7/10, Batch 20/145, Loss: 0.2912
Epoch 7/10, Batch 30/145, Loss: 0.1999
Epoch 7/10, Batch 40/145, Loss: 0.4441
Epoch 7/10, Batch 50/145, Loss: 0.2365
Epoch 7/10, Batch 60/145, Loss: 0.1330
Epoch 7/10, Batch 70/145, Loss: 0.2049
Epoch 7/10, Batch 80/145, Loss: 0.2335
Epoch 7/10, Batch 90/145, Loss: 0.3165
Epoch 7/10, Batch 100/145, Loss: 0.1153
Epoch 7/10, Batch 110/145, Loss: 0.3260
Epoch 7/10, Batch 120/145, Loss: 0.1473
Epoch 7/10, Batch 130/145, Loss: 0.2197
Epoch 7/10, Batch 140/145, Loss: 0.1334
Epoch 7/10, Train Loss: 0.2098, Valid Loss: 0.2369
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1098
Epoch 8/10, Batch 20/145, Loss: 0.1516
Epoch 8/10, Batch 30/145, Loss: 0.1993
Epoch 8/10, Batch 40/145, Loss: 0.2685
Epoch 8/10, Batch 50/145, Loss: 0.1615
Epoch 8/10, Batch 60/145, Loss: 0.2394
Epoch 8/10, Batch 70/145, Loss: 0.1033
Epoch 8/10, Batch 80/145, Loss: 0.0917
Epoch 8/10, Batch 90/145, Loss: 0.0742
Epoch 8/10, Batch 100/145, Loss: 0.2895
Epoch 8/10, Batch 110/145, Loss: 0.1475
Epoch 8/10, Batch 120/145, Loss: 0.0725
Epoch 8/10, Batch 130/145, Loss: 0.3275
Epoch 8/10, Batch 140/145, Loss: 0.2232
Epoch 8/10, Train Loss: 0.2076, Valid Loss: 0.2356
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1581
Epoch 9/10, Batch 20/145, Loss: 0.1451
Epoch 9/10, Batch 30/145, Loss: 0.1780
Epoch 9/10, Batch 40/145, Loss: 0.2204
Epoch 9/10, Batch 50/145, Loss: 0.1440
Epoch 9/10, Batch 60/145, Loss: 0.1126
Epoch 9/10, Batch 70/145, Loss: 0.2202
Epoch 9/10, Batch 80/145, Loss: 0.1205
Epoch 9/10, Batch 90/145, Loss: 0.1061
Epoch 9/10, Batch 100/145, Loss: 0.1262
Epoch 9/10, Batch 110/145, Loss: 0.0744
Epoch 9/10, Batch 120/145, Loss: 0.1782
Epoch 9/10, Batch 130/145, Loss: 0.2205
Epoch 9/10, Batch 140/145, Loss: 0.0791
Epoch 9/10, Train Loss: 0.1964, Valid Loss: 0.2286
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1023
Epoch 10/10, Batch 20/145, Loss: 0.1892
Epoch 10/10, Batch 30/145, Loss: 0.1261
Epoch 10/10, Batch 40/145, Loss: 0.1708
Epoch 10/10, Batch 50/145, Loss: 0.3564
Epoch 10/10, Batch 60/145, Loss: 0.1421
Epoch 10/10, Batch 70/145, Loss: 0.2184
Epoch 10/10, Batch 80/145, Loss: 0.4037
Epoch 10/10, Batch 90/145, Loss: 0.0986
Epoch 10/10, Batch 100/145, Loss: 0.3467
Epoch 10/10, Batch 110/145, Loss: 0.1892
Epoch 10/10, Batch 120/145, Loss: 0.1764
Epoch 10/10, Batch 130/145, Loss: 0.1978
Epoch 10/10, Batch 140/145, Loss: 0.3144
Epoch 10/10, Train Loss: 0.1975, Valid Loss: 0.2285
Model saved!
Accuracy: 0.9229
Precision: 0.9206
Recall: 0.9229
F1-score: 0.9213
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4570
Epoch 1/10, Batch 20/145, Loss: 0.9302
Epoch 1/10, Batch 30/145, Loss: 0.8440
Epoch 1/10, Batch 40/145, Loss: 0.8416
Epoch 1/10, Batch 50/145, Loss: 0.6027
Epoch 1/10, Batch 60/145, Loss: 0.6631
Epoch 1/10, Batch 70/145, Loss: 0.6589
Epoch 1/10, Batch 80/145, Loss: 0.4835
Epoch 1/10, Batch 90/145, Loss: 0.4762
Epoch 1/10, Batch 100/145, Loss: 0.5944
Epoch 1/10, Batch 110/145, Loss: 0.3141
Epoch 1/10, Batch 120/145, Loss: 0.5874
Epoch 1/10, Batch 130/145, Loss: 0.4773
Epoch 1/10, Batch 140/145, Loss: 0.3114
Epoch 1/10, Train Loss: 0.6789, Valid Loss: 0.3687
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3751
Epoch 2/10, Batch 20/145, Loss: 0.5808
Epoch 2/10, Batch 30/145, Loss: 0.3834
Epoch 2/10, Batch 40/145, Loss: 0.3594
Epoch 2/10, Batch 50/145, Loss: 0.2082
Epoch 2/10, Batch 60/145, Loss: 0.4262
Epoch 2/10, Batch 70/145, Loss: 0.3847
Epoch 2/10, Batch 80/145, Loss: 0.4621
Epoch 2/10, Batch 90/145, Loss: 0.2297
Epoch 2/10, Batch 100/145, Loss: 0.2044
Epoch 2/10, Batch 110/145, Loss: 0.2556
Epoch 2/10, Batch 120/145, Loss: 0.4893
Epoch 2/10, Batch 130/145, Loss: 0.3256
Epoch 2/10, Batch 140/145, Loss: 0.1697
Epoch 2/10, Train Loss: 0.3529, Valid Loss: 0.2785
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2539
Epoch 3/10, Batch 20/145, Loss: 0.3346
Epoch 3/10, Batch 30/145, Loss: 0.2422
Epoch 3/10, Batch 40/145, Loss: 0.3472
Epoch 3/10, Batch 50/145, Loss: 0.1500
Epoch 3/10, Batch 60/145, Loss: 0.3153
Epoch 3/10, Batch 70/145, Loss: 0.1844
Epoch 3/10, Batch 80/145, Loss: 0.2617
Epoch 3/10, Batch 90/145, Loss: 0.5390
Epoch 3/10, Batch 100/145, Loss: 0.2123
Epoch 3/10, Batch 110/145, Loss: 0.2021
Epoch 3/10, Batch 120/145, Loss: 0.1796
Epoch 3/10, Batch 130/145, Loss: 0.3052
Epoch 3/10, Batch 140/145, Loss: 0.2537
Epoch 3/10, Train Loss: 0.2959, Valid Loss: 0.2529
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1475
Epoch 4/10, Batch 20/145, Loss: 0.3420
Epoch 4/10, Batch 30/145, Loss: 0.2011
Epoch 4/10, Batch 40/145, Loss: 0.3208
Epoch 4/10, Batch 50/145, Loss: 0.2259
Epoch 4/10, Batch 60/145, Loss: 0.2783
Epoch 4/10, Batch 70/145, Loss: 0.2718
Epoch 4/10, Batch 80/145, Loss: 0.2072
Epoch 4/10, Batch 90/145, Loss: 0.1682
Epoch 4/10, Batch 100/145, Loss: 0.2728
Epoch 4/10, Batch 110/145, Loss: 0.2178
Epoch 4/10, Batch 120/145, Loss: 0.1622
Epoch 4/10, Batch 130/145, Loss: 0.2285
Epoch 4/10, Batch 140/145, Loss: 0.1939
Epoch 4/10, Train Loss: 0.2598, Valid Loss: 0.2358
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2111
Epoch 5/10, Batch 20/145, Loss: 0.3591
Epoch 5/10, Batch 30/145, Loss: 0.2741
Epoch 5/10, Batch 40/145, Loss: 0.2622
Epoch 5/10, Batch 50/145, Loss: 0.0899
Epoch 5/10, Batch 60/145, Loss: 0.2006
Epoch 5/10, Batch 70/145, Loss: 0.1853
Epoch 5/10, Batch 80/145, Loss: 0.3419
Epoch 5/10, Batch 90/145, Loss: 0.1852
Epoch 5/10, Batch 100/145, Loss: 0.2457
Epoch 5/10, Batch 110/145, Loss: 0.1287
Epoch 5/10, Batch 120/145, Loss: 0.1592
Epoch 5/10, Batch 130/145, Loss: 0.1469
Epoch 5/10, Batch 140/145, Loss: 0.1910
Epoch 5/10, Train Loss: 0.2318, Valid Loss: 0.2295
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1404
Epoch 6/10, Batch 20/145, Loss: 0.1349
Epoch 6/10, Batch 30/145, Loss: 0.2298
Epoch 6/10, Batch 40/145, Loss: 0.1453
Epoch 6/10, Batch 50/145, Loss: 0.2774
Epoch 6/10, Batch 60/145, Loss: 0.1173
Epoch 6/10, Batch 70/145, Loss: 0.0902
Epoch 6/10, Batch 80/145, Loss: 0.2256
Epoch 6/10, Batch 90/145, Loss: 0.2230
Epoch 6/10, Batch 100/145, Loss: 0.2897
Epoch 6/10, Batch 110/145, Loss: 0.1176
Epoch 6/10, Batch 120/145, Loss: 0.1993
Epoch 6/10, Batch 130/145, Loss: 0.1201
Epoch 6/10, Batch 140/145, Loss: 0.2203
Epoch 6/10, Train Loss: 0.2156, Valid Loss: 0.2366
Epoch 7/10, Batch 10/145, Loss: 0.3116
Epoch 7/10, Batch 20/145, Loss: 0.1674
Epoch 7/10, Batch 30/145, Loss: 0.2172
Epoch 7/10, Batch 40/145, Loss: 0.4758
Epoch 7/10, Batch 50/145, Loss: 0.2101
Epoch 7/10, Batch 60/145, Loss: 0.1974
Epoch 7/10, Batch 70/145, Loss: 0.2921
Epoch 7/10, Batch 80/145, Loss: 0.1128
Epoch 7/10, Batch 90/145, Loss: 0.2613
Epoch 7/10, Batch 100/145, Loss: 0.1113
Epoch 7/10, Batch 110/145, Loss: 0.2216
Epoch 7/10, Batch 120/145, Loss: 0.0867
Epoch 7/10, Batch 130/145, Loss: 0.2197
Epoch 7/10, Batch 140/145, Loss: 0.0936
Epoch 7/10, Train Loss: 0.2190, Valid Loss: 0.2233
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2068
Epoch 8/10, Batch 20/145, Loss: 0.1421
Epoch 8/10, Batch 30/145, Loss: 0.1388
Epoch 8/10, Batch 40/145, Loss: 0.2056
Epoch 8/10, Batch 50/145, Loss: 0.2464
Epoch 8/10, Batch 60/145, Loss: 0.1414
Epoch 8/10, Batch 70/145, Loss: 0.2287
Epoch 8/10, Batch 80/145, Loss: 0.1389
Epoch 8/10, Batch 90/145, Loss: 0.0704
Epoch 8/10, Batch 100/145, Loss: 0.3288
Epoch 8/10, Batch 110/145, Loss: 0.1703
Epoch 8/10, Batch 120/145, Loss: 0.2810
Epoch 8/10, Batch 130/145, Loss: 0.2921
Epoch 8/10, Batch 140/145, Loss: 0.1917
Epoch 8/10, Train Loss: 0.2003, Valid Loss: 0.2089
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2476
Epoch 9/10, Batch 20/145, Loss: 0.0931
Epoch 9/10, Batch 30/145, Loss: 0.1170
Epoch 9/10, Batch 40/145, Loss: 0.1201
Epoch 9/10, Batch 50/145, Loss: 0.1536
Epoch 9/10, Batch 60/145, Loss: 0.2434
Epoch 9/10, Batch 70/145, Loss: 0.1703
Epoch 9/10, Batch 80/145, Loss: 0.1071
Epoch 9/10, Batch 90/145, Loss: 0.1871
Epoch 9/10, Batch 100/145, Loss: 0.1572
Epoch 9/10, Batch 110/145, Loss: 0.1522
Epoch 9/10, Batch 120/145, Loss: 0.1803
Epoch 9/10, Batch 130/145, Loss: 0.1858
Epoch 9/10, Batch 140/145, Loss: 0.2241
Epoch 9/10, Train Loss: 0.1966, Valid Loss: 0.2017
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2500
Epoch 10/10, Batch 20/145, Loss: 0.2307
Epoch 10/10, Batch 30/145, Loss: 0.0949
Epoch 10/10, Batch 40/145, Loss: 0.3444
Epoch 10/10, Batch 50/145, Loss: 0.2257
Epoch 10/10, Batch 60/145, Loss: 0.1923
Epoch 10/10, Batch 70/145, Loss: 0.1707
Epoch 10/10, Batch 80/145, Loss: 0.2975
Epoch 10/10, Batch 90/145, Loss: 0.1460
Epoch 10/10, Batch 100/145, Loss: 0.2453
Epoch 10/10, Batch 110/145, Loss: 0.2716
Epoch 10/10, Batch 120/145, Loss: 0.0793
Epoch 10/10, Batch 130/145, Loss: 0.1714
Epoch 10/10, Batch 140/145, Loss: 0.0853
Epoch 10/10, Train Loss: 0.1922, Valid Loss: 0.2032
Accuracy: 0.9241
Precision: 0.9221
Recall: 0.9241
F1-score: 0.9225
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5269
Epoch 1/10, Batch 20/145, Loss: 0.9605
Epoch 1/10, Batch 30/145, Loss: 0.8873
Epoch 1/10, Batch 40/145, Loss: 0.8552
Epoch 1/10, Batch 50/145, Loss: 0.6547
Epoch 1/10, Batch 60/145, Loss: 0.5834
Epoch 1/10, Batch 70/145, Loss: 0.7142
Epoch 1/10, Batch 80/145, Loss: 0.5843
Epoch 1/10, Batch 90/145, Loss: 0.5787
Epoch 1/10, Batch 100/145, Loss: 0.4990
Epoch 1/10, Batch 110/145, Loss: 0.3970
Epoch 1/10, Batch 120/145, Loss: 0.6723
Epoch 1/10, Batch 130/145, Loss: 0.3159
Epoch 1/10, Batch 140/145, Loss: 0.4993
Epoch 1/10, Train Loss: 0.6863, Valid Loss: 0.3702
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3744
Epoch 2/10, Batch 20/145, Loss: 0.4676
Epoch 2/10, Batch 30/145, Loss: 0.3199
Epoch 2/10, Batch 40/145, Loss: 0.4180
Epoch 2/10, Batch 50/145, Loss: 0.4373
Epoch 2/10, Batch 60/145, Loss: 0.3738
Epoch 2/10, Batch 70/145, Loss: 0.4702
Epoch 2/10, Batch 80/145, Loss: 0.4379
Epoch 2/10, Batch 90/145, Loss: 0.1948
Epoch 2/10, Batch 100/145, Loss: 0.3241
Epoch 2/10, Batch 110/145, Loss: 0.2990
Epoch 2/10, Batch 120/145, Loss: 0.2952
Epoch 2/10, Batch 130/145, Loss: 0.3689
Epoch 2/10, Batch 140/145, Loss: 0.2346
Epoch 2/10, Train Loss: 0.3575, Valid Loss: 0.2884
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2181
Epoch 3/10, Batch 20/145, Loss: 0.3586
Epoch 3/10, Batch 30/145, Loss: 0.3663
Epoch 3/10, Batch 40/145, Loss: 0.3198
Epoch 3/10, Batch 50/145, Loss: 0.2648
Epoch 3/10, Batch 60/145, Loss: 0.2672
Epoch 3/10, Batch 70/145, Loss: 0.2065
Epoch 3/10, Batch 80/145, Loss: 0.3336
Epoch 3/10, Batch 90/145, Loss: 0.4974
Epoch 3/10, Batch 100/145, Loss: 0.1460
Epoch 3/10, Batch 110/145, Loss: 0.1624
Epoch 3/10, Batch 120/145, Loss: 0.2913
Epoch 3/10, Batch 130/145, Loss: 0.5180
Epoch 3/10, Batch 140/145, Loss: 0.2520
Epoch 3/10, Train Loss: 0.2992, Valid Loss: 0.2551
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3534
Epoch 4/10, Batch 20/145, Loss: 0.1901
Epoch 4/10, Batch 30/145, Loss: 0.2606
Epoch 4/10, Batch 40/145, Loss: 0.3175
Epoch 4/10, Batch 50/145, Loss: 0.1643
Epoch 4/10, Batch 60/145, Loss: 0.1644
Epoch 4/10, Batch 70/145, Loss: 0.1591
Epoch 4/10, Batch 80/145, Loss: 0.4014
Epoch 4/10, Batch 90/145, Loss: 0.2811
Epoch 4/10, Batch 100/145, Loss: 0.3429
Epoch 4/10, Batch 110/145, Loss: 0.2830
Epoch 4/10, Batch 120/145, Loss: 0.1848
Epoch 4/10, Batch 130/145, Loss: 0.1612
Epoch 4/10, Batch 140/145, Loss: 0.2740
Epoch 4/10, Train Loss: 0.2609, Valid Loss: 0.2518
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2518
Epoch 5/10, Batch 20/145, Loss: 0.1687
Epoch 5/10, Batch 30/145, Loss: 0.1959
Epoch 5/10, Batch 40/145, Loss: 0.2104
Epoch 5/10, Batch 50/145, Loss: 0.1133
Epoch 5/10, Batch 60/145, Loss: 0.2460
Epoch 5/10, Batch 70/145, Loss: 0.2393
Epoch 5/10, Batch 80/145, Loss: 0.5400
Epoch 5/10, Batch 90/145, Loss: 0.4836
Epoch 5/10, Batch 100/145, Loss: 0.2638
Epoch 5/10, Batch 110/145, Loss: 0.1673
Epoch 5/10, Batch 120/145, Loss: 0.2549
Epoch 5/10, Batch 130/145, Loss: 0.1056
Epoch 5/10, Batch 140/145, Loss: 0.4928
Epoch 5/10, Train Loss: 0.2365, Valid Loss: 0.2280
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3322
Epoch 6/10, Batch 20/145, Loss: 0.2570
Epoch 6/10, Batch 30/145, Loss: 0.3744
Epoch 6/10, Batch 40/145, Loss: 0.1826
Epoch 6/10, Batch 50/145, Loss: 0.2077
Epoch 6/10, Batch 60/145, Loss: 0.1418
Epoch 6/10, Batch 70/145, Loss: 0.2264
Epoch 6/10, Batch 80/145, Loss: 0.4300
Epoch 6/10, Batch 90/145, Loss: 0.2382
Epoch 6/10, Batch 100/145, Loss: 0.2141
Epoch 6/10, Batch 110/145, Loss: 0.2303
Epoch 6/10, Batch 120/145, Loss: 0.2856
Epoch 6/10, Batch 130/145, Loss: 0.1366
Epoch 6/10, Batch 140/145, Loss: 0.3534
Epoch 6/10, Train Loss: 0.2260, Valid Loss: 0.2272
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2200
Epoch 7/10, Batch 20/145, Loss: 0.4044
Epoch 7/10, Batch 30/145, Loss: 0.1632
Epoch 7/10, Batch 40/145, Loss: 0.3681
Epoch 7/10, Batch 50/145, Loss: 0.2030
Epoch 7/10, Batch 60/145, Loss: 0.1613
Epoch 7/10, Batch 70/145, Loss: 0.1273
Epoch 7/10, Batch 80/145, Loss: 0.1872
Epoch 7/10, Batch 90/145, Loss: 0.1343
Epoch 7/10, Batch 100/145, Loss: 0.1915
Epoch 7/10, Batch 110/145, Loss: 0.2440
Epoch 7/10, Batch 120/145, Loss: 0.1845
Epoch 7/10, Batch 130/145, Loss: 0.3332
Epoch 7/10, Batch 140/145, Loss: 0.1123
Epoch 7/10, Train Loss: 0.2183, Valid Loss: 0.2146
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1373
Epoch 8/10, Batch 20/145, Loss: 0.1086
Epoch 8/10, Batch 30/145, Loss: 0.2077
Epoch 8/10, Batch 40/145, Loss: 0.1364
Epoch 8/10, Batch 50/145, Loss: 0.2185
Epoch 8/10, Batch 60/145, Loss: 0.1455
Epoch 8/10, Batch 70/145, Loss: 0.2766
Epoch 8/10, Batch 80/145, Loss: 0.2150
Epoch 8/10, Batch 90/145, Loss: 0.1818
Epoch 8/10, Batch 100/145, Loss: 0.1714
Epoch 8/10, Batch 110/145, Loss: 0.2950
Epoch 8/10, Batch 120/145, Loss: 0.1698
Epoch 8/10, Batch 130/145, Loss: 0.1559
Epoch 8/10, Batch 140/145, Loss: 0.1842
Epoch 8/10, Train Loss: 0.2012, Valid Loss: 0.1991
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3161
Epoch 9/10, Batch 20/145, Loss: 0.1680
Epoch 9/10, Batch 30/145, Loss: 0.2116
Epoch 9/10, Batch 40/145, Loss: 0.4454
Epoch 9/10, Batch 50/145, Loss: 0.1769
Epoch 9/10, Batch 60/145, Loss: 0.1776
Epoch 9/10, Batch 70/145, Loss: 0.2001
Epoch 9/10, Batch 80/145, Loss: 0.1979
Epoch 9/10, Batch 90/145, Loss: 0.1168
Epoch 9/10, Batch 100/145, Loss: 0.1693
Epoch 9/10, Batch 110/145, Loss: 0.2072
Epoch 9/10, Batch 120/145, Loss: 0.3229
Epoch 9/10, Batch 130/145, Loss: 0.2585
Epoch 9/10, Batch 140/145, Loss: 0.1326
Epoch 9/10, Train Loss: 0.2031, Valid Loss: 0.2008
Epoch 10/10, Batch 10/145, Loss: 0.1066
Epoch 10/10, Batch 20/145, Loss: 0.1127
Epoch 10/10, Batch 30/145, Loss: 0.0738
Epoch 10/10, Batch 40/145, Loss: 0.3261
Epoch 10/10, Batch 50/145, Loss: 0.3761
Epoch 10/10, Batch 60/145, Loss: 0.1932
Epoch 10/10, Batch 70/145, Loss: 0.0767
Epoch 10/10, Batch 80/145, Loss: 0.3500
Epoch 10/10, Batch 90/145, Loss: 0.0651
Epoch 10/10, Batch 100/145, Loss: 0.2404
Epoch 10/10, Batch 110/145, Loss: 0.2476
Epoch 10/10, Batch 120/145, Loss: 0.1288
Epoch 10/10, Batch 130/145, Loss: 0.0966
Epoch 10/10, Batch 140/145, Loss: 0.1540
Epoch 10/10, Train Loss: 0.1917, Valid Loss: 0.1951
Model saved!
Accuracy: 0.9217
Precision: 0.9197
Recall: 0.9217
F1-score: 0.9203
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4853
Epoch 1/10, Batch 20/145, Loss: 0.8447
Epoch 1/10, Batch 30/145, Loss: 0.8330
Epoch 1/10, Batch 40/145, Loss: 0.7681
Epoch 1/10, Batch 50/145, Loss: 0.4880
Epoch 1/10, Batch 60/145, Loss: 0.6371
Epoch 1/10, Batch 70/145, Loss: 0.6784
Epoch 1/10, Batch 80/145, Loss: 0.5245
Epoch 1/10, Batch 90/145, Loss: 0.6337
Epoch 1/10, Batch 100/145, Loss: 0.5069
Epoch 1/10, Batch 110/145, Loss: 0.4508
Epoch 1/10, Batch 120/145, Loss: 0.5190
Epoch 1/10, Batch 130/145, Loss: 0.3106
Epoch 1/10, Batch 140/145, Loss: 0.3634
Epoch 1/10, Train Loss: 0.6894, Valid Loss: 0.3696
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3574
Epoch 2/10, Batch 20/145, Loss: 0.4984
Epoch 2/10, Batch 30/145, Loss: 0.4502
Epoch 2/10, Batch 40/145, Loss: 0.5031
Epoch 2/10, Batch 50/145, Loss: 0.3800
Epoch 2/10, Batch 60/145, Loss: 0.3271
Epoch 2/10, Batch 70/145, Loss: 0.4652
Epoch 2/10, Batch 80/145, Loss: 0.2231
Epoch 2/10, Batch 90/145, Loss: 0.2843
Epoch 2/10, Batch 100/145, Loss: 0.4257
Epoch 2/10, Batch 110/145, Loss: 0.1969
Epoch 2/10, Batch 120/145, Loss: 0.2314
Epoch 2/10, Batch 130/145, Loss: 0.3265
Epoch 2/10, Batch 140/145, Loss: 0.2351
Epoch 2/10, Train Loss: 0.3629, Valid Loss: 0.2847
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3014
Epoch 3/10, Batch 20/145, Loss: 0.3764
Epoch 3/10, Batch 30/145, Loss: 0.3095
Epoch 3/10, Batch 40/145, Loss: 0.1884
Epoch 3/10, Batch 50/145, Loss: 0.2130
Epoch 3/10, Batch 60/145, Loss: 0.2744
Epoch 3/10, Batch 70/145, Loss: 0.1591
Epoch 3/10, Batch 80/145, Loss: 0.2430
Epoch 3/10, Batch 90/145, Loss: 0.3787
Epoch 3/10, Batch 100/145, Loss: 0.2989
Epoch 3/10, Batch 110/145, Loss: 0.2115
Epoch 3/10, Batch 120/145, Loss: 0.3006
Epoch 3/10, Batch 130/145, Loss: 0.1937
Epoch 3/10, Batch 140/145, Loss: 0.1719
Epoch 3/10, Train Loss: 0.3145, Valid Loss: 0.2540
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1452
Epoch 4/10, Batch 20/145, Loss: 0.1443
Epoch 4/10, Batch 30/145, Loss: 0.1720
Epoch 4/10, Batch 40/145, Loss: 0.3672
Epoch 4/10, Batch 50/145, Loss: 0.2320
Epoch 4/10, Batch 60/145, Loss: 0.1998
Epoch 4/10, Batch 70/145, Loss: 0.2896
Epoch 4/10, Batch 80/145, Loss: 0.3471
Epoch 4/10, Batch 90/145, Loss: 0.3418
Epoch 4/10, Batch 100/145, Loss: 0.2378
Epoch 4/10, Batch 110/145, Loss: 0.2362
Epoch 4/10, Batch 120/145, Loss: 0.2583
Epoch 4/10, Batch 130/145, Loss: 0.2088
Epoch 4/10, Batch 140/145, Loss: 0.3380
Epoch 4/10, Train Loss: 0.2684, Valid Loss: 0.2455
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2148
Epoch 5/10, Batch 20/145, Loss: 0.2616
Epoch 5/10, Batch 30/145, Loss: 0.1636
Epoch 5/10, Batch 40/145, Loss: 0.2938
Epoch 5/10, Batch 50/145, Loss: 0.2459
Epoch 5/10, Batch 60/145, Loss: 0.2601
Epoch 5/10, Batch 70/145, Loss: 0.3488
Epoch 5/10, Batch 80/145, Loss: 0.2272
Epoch 5/10, Batch 90/145, Loss: 0.1883
Epoch 5/10, Batch 100/145, Loss: 0.3596
Epoch 5/10, Batch 110/145, Loss: 0.2346
Epoch 5/10, Batch 120/145, Loss: 0.1842
Epoch 5/10, Batch 130/145, Loss: 0.1425
Epoch 5/10, Batch 140/145, Loss: 0.3795
Epoch 5/10, Train Loss: 0.2433, Valid Loss: 0.2257
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3152
Epoch 6/10, Batch 20/145, Loss: 0.1614
Epoch 6/10, Batch 30/145, Loss: 0.1771
Epoch 6/10, Batch 40/145, Loss: 0.2126
Epoch 6/10, Batch 50/145, Loss: 0.2691
Epoch 6/10, Batch 60/145, Loss: 0.2051
Epoch 6/10, Batch 70/145, Loss: 0.3219
Epoch 6/10, Batch 80/145, Loss: 0.3278
Epoch 6/10, Batch 90/145, Loss: 0.1818
Epoch 6/10, Batch 100/145, Loss: 0.1610
Epoch 6/10, Batch 110/145, Loss: 0.1287
Epoch 6/10, Batch 120/145, Loss: 0.2536
Epoch 6/10, Batch 130/145, Loss: 0.2241
Epoch 6/10, Batch 140/145, Loss: 0.2636
Epoch 6/10, Train Loss: 0.2312, Valid Loss: 0.2179
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3139
Epoch 7/10, Batch 20/145, Loss: 0.1656
Epoch 7/10, Batch 30/145, Loss: 0.1487
Epoch 7/10, Batch 40/145, Loss: 0.5357
Epoch 7/10, Batch 50/145, Loss: 0.2713
Epoch 7/10, Batch 60/145, Loss: 0.1564
Epoch 7/10, Batch 70/145, Loss: 0.2319
Epoch 7/10, Batch 80/145, Loss: 0.1853
Epoch 7/10, Batch 90/145, Loss: 0.2465
Epoch 7/10, Batch 100/145, Loss: 0.2014
Epoch 7/10, Batch 110/145, Loss: 0.2474
Epoch 7/10, Batch 120/145, Loss: 0.1998
Epoch 7/10, Batch 130/145, Loss: 0.2733
Epoch 7/10, Batch 140/145, Loss: 0.1207
Epoch 7/10, Train Loss: 0.2235, Valid Loss: 0.2162
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1615
Epoch 8/10, Batch 20/145, Loss: 0.2317
Epoch 8/10, Batch 30/145, Loss: 0.1785
Epoch 8/10, Batch 40/145, Loss: 0.2249
Epoch 8/10, Batch 50/145, Loss: 0.1840
Epoch 8/10, Batch 60/145, Loss: 0.0867
Epoch 8/10, Batch 70/145, Loss: 0.1487
Epoch 8/10, Batch 80/145, Loss: 0.1671
Epoch 8/10, Batch 90/145, Loss: 0.0583
Epoch 8/10, Batch 100/145, Loss: 0.2744
Epoch 8/10, Batch 110/145, Loss: 0.1616
Epoch 8/10, Batch 120/145, Loss: 0.3539
Epoch 8/10, Batch 130/145, Loss: 0.1851
Epoch 8/10, Batch 140/145, Loss: 0.1376
Epoch 8/10, Train Loss: 0.2136, Valid Loss: 0.2140
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2779
Epoch 9/10, Batch 20/145, Loss: 0.1820
Epoch 9/10, Batch 30/145, Loss: 0.0921
Epoch 9/10, Batch 40/145, Loss: 0.1294
Epoch 9/10, Batch 50/145, Loss: 0.2710
Epoch 9/10, Batch 60/145, Loss: 0.1459
Epoch 9/10, Batch 70/145, Loss: 0.2085
Epoch 9/10, Batch 80/145, Loss: 0.3062
Epoch 9/10, Batch 90/145, Loss: 0.1350
Epoch 9/10, Batch 100/145, Loss: 0.3129
Epoch 9/10, Batch 110/145, Loss: 0.1036
Epoch 9/10, Batch 120/145, Loss: 0.3365
Epoch 9/10, Batch 130/145, Loss: 0.1657
Epoch 9/10, Batch 140/145, Loss: 0.1131
Epoch 9/10, Train Loss: 0.2080, Valid Loss: 0.2042
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2344
Epoch 10/10, Batch 20/145, Loss: 0.0896
Epoch 10/10, Batch 30/145, Loss: 0.1733
Epoch 10/10, Batch 40/145, Loss: 0.1914
Epoch 10/10, Batch 50/145, Loss: 0.0867
Epoch 10/10, Batch 60/145, Loss: 0.2159
Epoch 10/10, Batch 70/145, Loss: 0.1729
Epoch 10/10, Batch 80/145, Loss: 0.2882
Epoch 10/10, Batch 90/145, Loss: 0.2033
Epoch 10/10, Batch 100/145, Loss: 0.1096
Epoch 10/10, Batch 110/145, Loss: 0.1280
Epoch 10/10, Batch 120/145, Loss: 0.1757
Epoch 10/10, Batch 130/145, Loss: 0.2294
Epoch 10/10, Batch 140/145, Loss: 0.3047
Epoch 10/10, Train Loss: 0.1998, Valid Loss: 0.2027
Model saved!
Accuracy: 0.9229
Precision: 0.9211
Recall: 0.9229
F1-score: 0.9217
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4659
Epoch 1/10, Batch 20/145, Loss: 0.8689
Epoch 1/10, Batch 30/145, Loss: 0.8393
Epoch 1/10, Batch 40/145, Loss: 0.7484
Epoch 1/10, Batch 50/145, Loss: 0.7023
Epoch 1/10, Batch 60/145, Loss: 0.5945
Epoch 1/10, Batch 70/145, Loss: 0.6313
Epoch 1/10, Batch 80/145, Loss: 0.5377
Epoch 1/10, Batch 90/145, Loss: 0.4181
Epoch 1/10, Batch 100/145, Loss: 0.7574
Epoch 1/10, Batch 110/145, Loss: 0.4340
Epoch 1/10, Batch 120/145, Loss: 0.4783
Epoch 1/10, Batch 130/145, Loss: 0.3704
Epoch 1/10, Batch 140/145, Loss: 0.3686
Epoch 1/10, Train Loss: 0.6888, Valid Loss: 0.3717
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3766
Epoch 2/10, Batch 20/145, Loss: 0.3424
Epoch 2/10, Batch 30/145, Loss: 0.2837
Epoch 2/10, Batch 40/145, Loss: 0.5071
Epoch 2/10, Batch 50/145, Loss: 0.4320
Epoch 2/10, Batch 60/145, Loss: 0.4294
Epoch 2/10, Batch 70/145, Loss: 0.3985
Epoch 2/10, Batch 80/145, Loss: 0.3625
Epoch 2/10, Batch 90/145, Loss: 0.2483
Epoch 2/10, Batch 100/145, Loss: 0.2071
Epoch 2/10, Batch 110/145, Loss: 0.2105
Epoch 2/10, Batch 120/145, Loss: 0.4242
Epoch 2/10, Batch 130/145, Loss: 0.3015
Epoch 2/10, Batch 140/145, Loss: 0.3636
Epoch 2/10, Train Loss: 0.3641, Valid Loss: 0.2906
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2371
Epoch 3/10, Batch 20/145, Loss: 0.3292
Epoch 3/10, Batch 30/145, Loss: 0.2307
Epoch 3/10, Batch 40/145, Loss: 0.2610
Epoch 3/10, Batch 50/145, Loss: 0.2699
Epoch 3/10, Batch 60/145, Loss: 0.3395
Epoch 3/10, Batch 70/145, Loss: 0.3469
Epoch 3/10, Batch 80/145, Loss: 0.1584
Epoch 3/10, Batch 90/145, Loss: 0.6086
Epoch 3/10, Batch 100/145, Loss: 0.5006
Epoch 3/10, Batch 110/145, Loss: 0.3412
Epoch 3/10, Batch 120/145, Loss: 0.3073
Epoch 3/10, Batch 130/145, Loss: 0.2905
Epoch 3/10, Batch 140/145, Loss: 0.1433
Epoch 3/10, Train Loss: 0.3071, Valid Loss: 0.2572
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1879
Epoch 4/10, Batch 20/145, Loss: 0.4242
Epoch 4/10, Batch 30/145, Loss: 0.4152
Epoch 4/10, Batch 40/145, Loss: 0.5417
Epoch 4/10, Batch 50/145, Loss: 0.1938
Epoch 4/10, Batch 60/145, Loss: 0.1821
Epoch 4/10, Batch 70/145, Loss: 0.1862
Epoch 4/10, Batch 80/145, Loss: 0.1800
Epoch 4/10, Batch 90/145, Loss: 0.2399
Epoch 4/10, Batch 100/145, Loss: 0.3111
Epoch 4/10, Batch 110/145, Loss: 0.2001
Epoch 4/10, Batch 120/145, Loss: 0.2843
Epoch 4/10, Batch 130/145, Loss: 0.1657
Epoch 4/10, Batch 140/145, Loss: 0.1710
Epoch 4/10, Train Loss: 0.2587, Valid Loss: 0.2462
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1441
Epoch 5/10, Batch 20/145, Loss: 0.2817
Epoch 5/10, Batch 30/145, Loss: 0.2256
Epoch 5/10, Batch 40/145, Loss: 0.2597
Epoch 5/10, Batch 50/145, Loss: 0.1827
Epoch 5/10, Batch 60/145, Loss: 0.2948
Epoch 5/10, Batch 70/145, Loss: 0.4017
Epoch 5/10, Batch 80/145, Loss: 0.4013
Epoch 5/10, Batch 90/145, Loss: 0.2041
Epoch 5/10, Batch 100/145, Loss: 0.2447
Epoch 5/10, Batch 110/145, Loss: 0.1914
Epoch 5/10, Batch 120/145, Loss: 0.1604
Epoch 5/10, Batch 130/145, Loss: 0.1851
Epoch 5/10, Batch 140/145, Loss: 0.2413
Epoch 5/10, Train Loss: 0.2423, Valid Loss: 0.2465
Epoch 6/10, Batch 10/145, Loss: 0.2691
Epoch 6/10, Batch 20/145, Loss: 0.2792
Epoch 6/10, Batch 30/145, Loss: 0.2781
Epoch 6/10, Batch 40/145, Loss: 0.1830
Epoch 6/10, Batch 50/145, Loss: 0.3227
Epoch 6/10, Batch 60/145, Loss: 0.2151
Epoch 6/10, Batch 70/145, Loss: 0.3382
Epoch 6/10, Batch 80/145, Loss: 0.2802
Epoch 6/10, Batch 90/145, Loss: 0.1011
Epoch 6/10, Batch 100/145, Loss: 0.1995
Epoch 6/10, Batch 110/145, Loss: 0.2220
Epoch 6/10, Batch 120/145, Loss: 0.1712
Epoch 6/10, Batch 130/145, Loss: 0.1295
Epoch 6/10, Batch 140/145, Loss: 0.1709
Epoch 6/10, Train Loss: 0.2319, Valid Loss: 0.2366
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.4065
Epoch 7/10, Batch 20/145, Loss: 0.2747
Epoch 7/10, Batch 30/145, Loss: 0.0899
Epoch 7/10, Batch 40/145, Loss: 0.3582
Epoch 7/10, Batch 50/145, Loss: 0.2024
Epoch 7/10, Batch 60/145, Loss: 0.1746
Epoch 7/10, Batch 70/145, Loss: 0.2098
Epoch 7/10, Batch 80/145, Loss: 0.0737
Epoch 7/10, Batch 90/145, Loss: 0.2429
Epoch 7/10, Batch 100/145, Loss: 0.0734
Epoch 7/10, Batch 110/145, Loss: 0.1430
Epoch 7/10, Batch 120/145, Loss: 0.2023
Epoch 7/10, Batch 130/145, Loss: 0.1883
Epoch 7/10, Batch 140/145, Loss: 0.1237
Epoch 7/10, Train Loss: 0.2238, Valid Loss: 0.2303
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0933
Epoch 8/10, Batch 20/145, Loss: 0.1607
Epoch 8/10, Batch 30/145, Loss: 0.1595
Epoch 8/10, Batch 40/145, Loss: 0.2708
Epoch 8/10, Batch 50/145, Loss: 0.2610
Epoch 8/10, Batch 60/145, Loss: 0.2690
Epoch 8/10, Batch 70/145, Loss: 0.1902
Epoch 8/10, Batch 80/145, Loss: 0.2569
Epoch 8/10, Batch 90/145, Loss: 0.2168
Epoch 8/10, Batch 100/145, Loss: 0.1237
Epoch 8/10, Batch 110/145, Loss: 0.4105
Epoch 8/10, Batch 120/145, Loss: 0.0993
Epoch 8/10, Batch 130/145, Loss: 0.1664
Epoch 8/10, Batch 140/145, Loss: 0.3856
Epoch 8/10, Train Loss: 0.2144, Valid Loss: 0.2236
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1531
Epoch 9/10, Batch 20/145, Loss: 0.0756
Epoch 9/10, Batch 30/145, Loss: 0.1118
Epoch 9/10, Batch 40/145, Loss: 0.1703
Epoch 9/10, Batch 50/145, Loss: 0.1602
Epoch 9/10, Batch 60/145, Loss: 0.1587
Epoch 9/10, Batch 70/145, Loss: 0.3429
Epoch 9/10, Batch 80/145, Loss: 0.2901
Epoch 9/10, Batch 90/145, Loss: 0.2265
Epoch 9/10, Batch 100/145, Loss: 0.2264
Epoch 9/10, Batch 110/145, Loss: 0.0765
Epoch 9/10, Batch 120/145, Loss: 0.2623
Epoch 9/10, Batch 130/145, Loss: 0.2434
Epoch 9/10, Batch 140/145, Loss: 0.1518
Epoch 9/10, Train Loss: 0.2091, Valid Loss: 0.2163
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2711
Epoch 10/10, Batch 20/145, Loss: 0.0800
Epoch 10/10, Batch 30/145, Loss: 0.0524
Epoch 10/10, Batch 40/145, Loss: 0.2417
Epoch 10/10, Batch 50/145, Loss: 0.1695
Epoch 10/10, Batch 60/145, Loss: 0.1752
Epoch 10/10, Batch 70/145, Loss: 0.0925
Epoch 10/10, Batch 80/145, Loss: 0.3534
Epoch 10/10, Batch 90/145, Loss: 0.3344
Epoch 10/10, Batch 100/145, Loss: 0.0997
Epoch 10/10, Batch 110/145, Loss: 0.3221
Epoch 10/10, Batch 120/145, Loss: 0.1662
Epoch 10/10, Batch 130/145, Loss: 0.1329
Epoch 10/10, Batch 140/145, Loss: 0.1041
Epoch 10/10, Train Loss: 0.1976, Valid Loss: 0.2139
Model saved!
Accuracy: 0.9252
Precision: 0.9243
Recall: 0.9252
F1-score: 0.9241
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4791
Epoch 1/10, Batch 20/145, Loss: 0.9288
Epoch 1/10, Batch 30/145, Loss: 0.8778
Epoch 1/10, Batch 40/145, Loss: 0.7745
Epoch 1/10, Batch 50/145, Loss: 0.5910
Epoch 1/10, Batch 60/145, Loss: 0.5722
Epoch 1/10, Batch 70/145, Loss: 0.6926
Epoch 1/10, Batch 80/145, Loss: 0.4427
Epoch 1/10, Batch 90/145, Loss: 0.7908
Epoch 1/10, Batch 100/145, Loss: 0.7197
Epoch 1/10, Batch 110/145, Loss: 0.3352
Epoch 1/10, Batch 120/145, Loss: 0.5134
Epoch 1/10, Batch 130/145, Loss: 0.3785
Epoch 1/10, Batch 140/145, Loss: 0.3649
Epoch 1/10, Train Loss: 0.6780, Valid Loss: 0.3714
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2689
Epoch 2/10, Batch 20/145, Loss: 0.4241
Epoch 2/10, Batch 30/145, Loss: 0.2856
Epoch 2/10, Batch 40/145, Loss: 0.3880
Epoch 2/10, Batch 50/145, Loss: 0.2413
Epoch 2/10, Batch 60/145, Loss: 0.5716
Epoch 2/10, Batch 70/145, Loss: 0.3770
Epoch 2/10, Batch 80/145, Loss: 0.3802
Epoch 2/10, Batch 90/145, Loss: 0.3853
Epoch 2/10, Batch 100/145, Loss: 0.2637
Epoch 2/10, Batch 110/145, Loss: 0.4050
Epoch 2/10, Batch 120/145, Loss: 0.4031
Epoch 2/10, Batch 130/145, Loss: 0.4002
Epoch 2/10, Batch 140/145, Loss: 0.4076
Epoch 2/10, Train Loss: 0.3563, Valid Loss: 0.2927
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2235
Epoch 3/10, Batch 20/145, Loss: 0.3037
Epoch 3/10, Batch 30/145, Loss: 0.1826
Epoch 3/10, Batch 40/145, Loss: 0.3254
Epoch 3/10, Batch 50/145, Loss: 0.2184
Epoch 3/10, Batch 60/145, Loss: 0.3218
Epoch 3/10, Batch 70/145, Loss: 0.2609
Epoch 3/10, Batch 80/145, Loss: 0.2839
Epoch 3/10, Batch 90/145, Loss: 0.5020
Epoch 3/10, Batch 100/145, Loss: 0.3571
Epoch 3/10, Batch 110/145, Loss: 0.2957
Epoch 3/10, Batch 120/145, Loss: 0.2654
Epoch 3/10, Batch 130/145, Loss: 0.3160
Epoch 3/10, Batch 140/145, Loss: 0.2957
Epoch 3/10, Train Loss: 0.3005, Valid Loss: 0.2694
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3877
Epoch 4/10, Batch 20/145, Loss: 0.4204
Epoch 4/10, Batch 30/145, Loss: 0.3579
Epoch 4/10, Batch 40/145, Loss: 0.1264
Epoch 4/10, Batch 50/145, Loss: 0.2335
Epoch 4/10, Batch 60/145, Loss: 0.2677
Epoch 4/10, Batch 70/145, Loss: 0.3117
Epoch 4/10, Batch 80/145, Loss: 0.2645
Epoch 4/10, Batch 90/145, Loss: 0.3444
Epoch 4/10, Batch 100/145, Loss: 0.1740
Epoch 4/10, Batch 110/145, Loss: 0.3487
Epoch 4/10, Batch 120/145, Loss: 0.1223
Epoch 4/10, Batch 130/145, Loss: 0.4057
Epoch 4/10, Batch 140/145, Loss: 0.2281
Epoch 4/10, Train Loss: 0.2555, Valid Loss: 0.2534
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1635
Epoch 5/10, Batch 20/145, Loss: 0.3446
Epoch 5/10, Batch 30/145, Loss: 0.2491
Epoch 5/10, Batch 40/145, Loss: 0.2497
Epoch 5/10, Batch 50/145, Loss: 0.1980
Epoch 5/10, Batch 60/145, Loss: 0.2456
Epoch 5/10, Batch 70/145, Loss: 0.2148
Epoch 5/10, Batch 80/145, Loss: 0.2654
Epoch 5/10, Batch 90/145, Loss: 0.3310
Epoch 5/10, Batch 100/145, Loss: 0.2904
Epoch 5/10, Batch 110/145, Loss: 0.1198
Epoch 5/10, Batch 120/145, Loss: 0.2136
Epoch 5/10, Batch 130/145, Loss: 0.3530
Epoch 5/10, Batch 140/145, Loss: 0.2559
Epoch 5/10, Train Loss: 0.2343, Valid Loss: 0.2387
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2458
Epoch 6/10, Batch 20/145, Loss: 0.2362
Epoch 6/10, Batch 30/145, Loss: 0.2085
Epoch 6/10, Batch 40/145, Loss: 0.1122
Epoch 6/10, Batch 50/145, Loss: 0.2971
Epoch 6/10, Batch 60/145, Loss: 0.1050
Epoch 6/10, Batch 70/145, Loss: 0.1553
Epoch 6/10, Batch 80/145, Loss: 0.2891
Epoch 6/10, Batch 90/145, Loss: 0.1506
Epoch 6/10, Batch 100/145, Loss: 0.2992
Epoch 6/10, Batch 110/145, Loss: 0.1741
Epoch 6/10, Batch 120/145, Loss: 0.2002
Epoch 6/10, Batch 130/145, Loss: 0.2552
Epoch 6/10, Batch 140/145, Loss: 0.1935
Epoch 6/10, Train Loss: 0.2241, Valid Loss: 0.2315
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.4149
Epoch 7/10, Batch 20/145, Loss: 0.1966
Epoch 7/10, Batch 30/145, Loss: 0.2659
Epoch 7/10, Batch 40/145, Loss: 0.3015
Epoch 7/10, Batch 50/145, Loss: 0.2924
Epoch 7/10, Batch 60/145, Loss: 0.1575
Epoch 7/10, Batch 70/145, Loss: 0.2732
Epoch 7/10, Batch 80/145, Loss: 0.1908
Epoch 7/10, Batch 90/145, Loss: 0.1894
Epoch 7/10, Batch 100/145, Loss: 0.1647
Epoch 7/10, Batch 110/145, Loss: 0.1206
Epoch 7/10, Batch 120/145, Loss: 0.2336
Epoch 7/10, Batch 130/145, Loss: 0.1830
Epoch 7/10, Batch 140/145, Loss: 0.2662
Epoch 7/10, Train Loss: 0.2089, Valid Loss: 0.2316
Epoch 8/10, Batch 10/145, Loss: 0.1471
Epoch 8/10, Batch 20/145, Loss: 0.1658
Epoch 8/10, Batch 30/145, Loss: 0.1700
Epoch 8/10, Batch 40/145, Loss: 0.4268
Epoch 8/10, Batch 50/145, Loss: 0.0925
Epoch 8/10, Batch 60/145, Loss: 0.1700
Epoch 8/10, Batch 70/145, Loss: 0.1241
Epoch 8/10, Batch 80/145, Loss: 0.2349
Epoch 8/10, Batch 90/145, Loss: 0.2701
Epoch 8/10, Batch 100/145, Loss: 0.2454
Epoch 8/10, Batch 110/145, Loss: 0.2773
Epoch 8/10, Batch 120/145, Loss: 0.3331
Epoch 8/10, Batch 130/145, Loss: 0.1846
Epoch 8/10, Batch 140/145, Loss: 0.2937
Epoch 8/10, Train Loss: 0.2113, Valid Loss: 0.2271
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1418
Epoch 9/10, Batch 20/145, Loss: 0.1225
Epoch 9/10, Batch 30/145, Loss: 0.1046
Epoch 9/10, Batch 40/145, Loss: 0.1367
Epoch 9/10, Batch 50/145, Loss: 0.2307
Epoch 9/10, Batch 60/145, Loss: 0.3091
Epoch 9/10, Batch 70/145, Loss: 0.0548
Epoch 9/10, Batch 80/145, Loss: 0.1516
Epoch 9/10, Batch 90/145, Loss: 0.1329
Epoch 9/10, Batch 100/145, Loss: 0.2032
Epoch 9/10, Batch 110/145, Loss: 0.1076
Epoch 9/10, Batch 120/145, Loss: 0.2147
Epoch 9/10, Batch 130/145, Loss: 0.1887
Epoch 9/10, Batch 140/145, Loss: 0.1159
Epoch 9/10, Train Loss: 0.1973, Valid Loss: 0.2195
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1205
Epoch 10/10, Batch 20/145, Loss: 0.0973
Epoch 10/10, Batch 30/145, Loss: 0.1017
Epoch 10/10, Batch 40/145, Loss: 0.1637
Epoch 10/10, Batch 50/145, Loss: 0.2149
Epoch 10/10, Batch 60/145, Loss: 0.1551
Epoch 10/10, Batch 70/145, Loss: 0.1333
Epoch 10/10, Batch 80/145, Loss: 0.2812
Epoch 10/10, Batch 90/145, Loss: 0.2012
Epoch 10/10, Batch 100/145, Loss: 0.2714
Epoch 10/10, Batch 110/145, Loss: 0.3268
Epoch 10/10, Batch 120/145, Loss: 0.1156
Epoch 10/10, Batch 130/145, Loss: 0.1921
Epoch 10/10, Batch 140/145, Loss: 0.1985
Epoch 10/10, Train Loss: 0.1861, Valid Loss: 0.2256
Accuracy: 0.9241
Precision: 0.9218
Recall: 0.9241
F1-score: 0.9224
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5024
Epoch 1/10, Batch 20/145, Loss: 0.8364
Epoch 1/10, Batch 30/145, Loss: 0.8262
Epoch 1/10, Batch 40/145, Loss: 0.7913
Epoch 1/10, Batch 50/145, Loss: 0.6841
Epoch 1/10, Batch 60/145, Loss: 0.5100
Epoch 1/10, Batch 70/145, Loss: 0.5939
Epoch 1/10, Batch 80/145, Loss: 0.5182
Epoch 1/10, Batch 90/145, Loss: 0.5063
Epoch 1/10, Batch 100/145, Loss: 0.5001
Epoch 1/10, Batch 110/145, Loss: 0.3862
Epoch 1/10, Batch 120/145, Loss: 0.5304
Epoch 1/10, Batch 130/145, Loss: 0.2994
Epoch 1/10, Batch 140/145, Loss: 0.5631
Epoch 1/10, Train Loss: 0.6860, Valid Loss: 0.3649
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3733
Epoch 2/10, Batch 20/145, Loss: 0.3665
Epoch 2/10, Batch 30/145, Loss: 0.3750
Epoch 2/10, Batch 40/145, Loss: 0.5395
Epoch 2/10, Batch 50/145, Loss: 0.2898
Epoch 2/10, Batch 60/145, Loss: 0.3733
Epoch 2/10, Batch 70/145, Loss: 0.3520
Epoch 2/10, Batch 80/145, Loss: 0.2834
Epoch 2/10, Batch 90/145, Loss: 0.2511
Epoch 2/10, Batch 100/145, Loss: 0.2304
Epoch 2/10, Batch 110/145, Loss: 0.2868
Epoch 2/10, Batch 120/145, Loss: 0.4626
Epoch 2/10, Batch 130/145, Loss: 0.2868
Epoch 2/10, Batch 140/145, Loss: 0.2090
Epoch 2/10, Train Loss: 0.3629, Valid Loss: 0.2879
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3011
Epoch 3/10, Batch 20/145, Loss: 0.2687
Epoch 3/10, Batch 30/145, Loss: 0.2896
Epoch 3/10, Batch 40/145, Loss: 0.2162
Epoch 3/10, Batch 50/145, Loss: 0.1376
Epoch 3/10, Batch 60/145, Loss: 0.1943
Epoch 3/10, Batch 70/145, Loss: 0.2036
Epoch 3/10, Batch 80/145, Loss: 0.3726
Epoch 3/10, Batch 90/145, Loss: 0.5046
Epoch 3/10, Batch 100/145, Loss: 0.1835
Epoch 3/10, Batch 110/145, Loss: 0.2424
Epoch 3/10, Batch 120/145, Loss: 0.2084
Epoch 3/10, Batch 130/145, Loss: 0.2784
Epoch 3/10, Batch 140/145, Loss: 0.1538
Epoch 3/10, Train Loss: 0.3042, Valid Loss: 0.2561
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2989
Epoch 4/10, Batch 20/145, Loss: 0.2547
Epoch 4/10, Batch 30/145, Loss: 0.2634
Epoch 4/10, Batch 40/145, Loss: 0.2505
Epoch 4/10, Batch 50/145, Loss: 0.2331
Epoch 4/10, Batch 60/145, Loss: 0.2982
Epoch 4/10, Batch 70/145, Loss: 0.4854
Epoch 4/10, Batch 80/145, Loss: 0.1796
Epoch 4/10, Batch 90/145, Loss: 0.2873
Epoch 4/10, Batch 100/145, Loss: 0.1866
Epoch 4/10, Batch 110/145, Loss: 0.2462
Epoch 4/10, Batch 120/145, Loss: 0.2736
Epoch 4/10, Batch 130/145, Loss: 0.1854
Epoch 4/10, Batch 140/145, Loss: 0.1828
Epoch 4/10, Train Loss: 0.2593, Valid Loss: 0.2407
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1938
Epoch 5/10, Batch 20/145, Loss: 0.2654
Epoch 5/10, Batch 30/145, Loss: 0.3947
Epoch 5/10, Batch 40/145, Loss: 0.2628
Epoch 5/10, Batch 50/145, Loss: 0.1537
Epoch 5/10, Batch 60/145, Loss: 0.3502
Epoch 5/10, Batch 70/145, Loss: 0.3367
Epoch 5/10, Batch 80/145, Loss: 0.3239
Epoch 5/10, Batch 90/145, Loss: 0.1191
Epoch 5/10, Batch 100/145, Loss: 0.2154
Epoch 5/10, Batch 110/145, Loss: 0.1423
Epoch 5/10, Batch 120/145, Loss: 0.1785
Epoch 5/10, Batch 130/145, Loss: 0.3299
Epoch 5/10, Batch 140/145, Loss: 0.2979
Epoch 5/10, Train Loss: 0.2386, Valid Loss: 0.2404
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2123
Epoch 6/10, Batch 20/145, Loss: 0.2639
Epoch 6/10, Batch 30/145, Loss: 0.2111
Epoch 6/10, Batch 40/145, Loss: 0.2002
Epoch 6/10, Batch 50/145, Loss: 0.1992
Epoch 6/10, Batch 60/145, Loss: 0.1407
Epoch 6/10, Batch 70/145, Loss: 0.1996
Epoch 6/10, Batch 80/145, Loss: 0.2997
Epoch 6/10, Batch 90/145, Loss: 0.2931
Epoch 6/10, Batch 100/145, Loss: 0.2221
Epoch 6/10, Batch 110/145, Loss: 0.1299
Epoch 6/10, Batch 120/145, Loss: 0.1580
Epoch 6/10, Batch 130/145, Loss: 0.0835
Epoch 6/10, Batch 140/145, Loss: 0.2452
Epoch 6/10, Train Loss: 0.2220, Valid Loss: 0.2277
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1950
Epoch 7/10, Batch 20/145, Loss: 0.1442
Epoch 7/10, Batch 30/145, Loss: 0.1715
Epoch 7/10, Batch 40/145, Loss: 0.4332
Epoch 7/10, Batch 50/145, Loss: 0.3102
Epoch 7/10, Batch 60/145, Loss: 0.1664
Epoch 7/10, Batch 70/145, Loss: 0.2113
Epoch 7/10, Batch 80/145, Loss: 0.0868
Epoch 7/10, Batch 90/145, Loss: 0.2769
Epoch 7/10, Batch 100/145, Loss: 0.1863
Epoch 7/10, Batch 110/145, Loss: 0.2721
Epoch 7/10, Batch 120/145, Loss: 0.1533
Epoch 7/10, Batch 130/145, Loss: 0.2714
Epoch 7/10, Batch 140/145, Loss: 0.1793
Epoch 7/10, Train Loss: 0.2163, Valid Loss: 0.2229
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1372
Epoch 8/10, Batch 20/145, Loss: 0.2184
Epoch 8/10, Batch 30/145, Loss: 0.1738
Epoch 8/10, Batch 40/145, Loss: 0.1797
Epoch 8/10, Batch 50/145, Loss: 0.2985
Epoch 8/10, Batch 60/145, Loss: 0.3052
Epoch 8/10, Batch 70/145, Loss: 0.1205
Epoch 8/10, Batch 80/145, Loss: 0.1809
Epoch 8/10, Batch 90/145, Loss: 0.1401
Epoch 8/10, Batch 100/145, Loss: 0.1824
Epoch 8/10, Batch 110/145, Loss: 0.2358
Epoch 8/10, Batch 120/145, Loss: 0.1859
Epoch 8/10, Batch 130/145, Loss: 0.1763
Epoch 8/10, Batch 140/145, Loss: 0.3784
Epoch 8/10, Train Loss: 0.2086, Valid Loss: 0.2133
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2861
Epoch 9/10, Batch 20/145, Loss: 0.1211
Epoch 9/10, Batch 30/145, Loss: 0.1070
Epoch 9/10, Batch 40/145, Loss: 0.1409
Epoch 9/10, Batch 50/145, Loss: 0.1497
Epoch 9/10, Batch 60/145, Loss: 0.1578
Epoch 9/10, Batch 70/145, Loss: 0.0996
Epoch 9/10, Batch 80/145, Loss: 0.1586
Epoch 9/10, Batch 90/145, Loss: 0.0900
Epoch 9/10, Batch 100/145, Loss: 0.3273
Epoch 9/10, Batch 110/145, Loss: 0.1212
Epoch 9/10, Batch 120/145, Loss: 0.2030
Epoch 9/10, Batch 130/145, Loss: 0.3712
Epoch 9/10, Batch 140/145, Loss: 0.0877
Epoch 9/10, Train Loss: 0.1997, Valid Loss: 0.2122
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2481
Epoch 10/10, Batch 20/145, Loss: 0.0875
Epoch 10/10, Batch 30/145, Loss: 0.0669
Epoch 10/10, Batch 40/145, Loss: 0.1342
Epoch 10/10, Batch 50/145, Loss: 0.2434
Epoch 10/10, Batch 60/145, Loss: 0.2798
Epoch 10/10, Batch 70/145, Loss: 0.0917
Epoch 10/10, Batch 80/145, Loss: 0.3470
Epoch 10/10, Batch 90/145, Loss: 0.1353
Epoch 10/10, Batch 100/145, Loss: 0.2429
Epoch 10/10, Batch 110/145, Loss: 0.1833
Epoch 10/10, Batch 120/145, Loss: 0.1726
Epoch 10/10, Batch 130/145, Loss: 0.2731
Epoch 10/10, Batch 140/145, Loss: 0.1829
Epoch 10/10, Train Loss: 0.1928, Valid Loss: 0.2089
Model saved!
Accuracy: 0.9252
Precision: 0.9241
Recall: 0.9252
F1-score: 0.9246
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5136
Epoch 1/10, Batch 20/145, Loss: 0.8180
Epoch 1/10, Batch 30/145, Loss: 0.8214
Epoch 1/10, Batch 40/145, Loss: 0.8249
Epoch 1/10, Batch 50/145, Loss: 0.6532
Epoch 1/10, Batch 60/145, Loss: 0.6070
Epoch 1/10, Batch 70/145, Loss: 0.5770
Epoch 1/10, Batch 80/145, Loss: 0.4755
Epoch 1/10, Batch 90/145, Loss: 0.4932
Epoch 1/10, Batch 100/145, Loss: 0.5036
Epoch 1/10, Batch 110/145, Loss: 0.4342
Epoch 1/10, Batch 120/145, Loss: 0.6610
Epoch 1/10, Batch 130/145, Loss: 0.5332
Epoch 1/10, Batch 140/145, Loss: 0.3330
Epoch 1/10, Train Loss: 0.6863, Valid Loss: 0.3715
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4183
Epoch 2/10, Batch 20/145, Loss: 0.7174
Epoch 2/10, Batch 30/145, Loss: 0.4859
Epoch 2/10, Batch 40/145, Loss: 0.4669
Epoch 2/10, Batch 50/145, Loss: 0.3713
Epoch 2/10, Batch 60/145, Loss: 0.3694
Epoch 2/10, Batch 70/145, Loss: 0.3954
Epoch 2/10, Batch 80/145, Loss: 0.2590
Epoch 2/10, Batch 90/145, Loss: 0.3254
Epoch 2/10, Batch 100/145, Loss: 0.5561
Epoch 2/10, Batch 110/145, Loss: 0.2704
Epoch 2/10, Batch 120/145, Loss: 0.3076
Epoch 2/10, Batch 130/145, Loss: 0.3131
Epoch 2/10, Batch 140/145, Loss: 0.2551
Epoch 2/10, Train Loss: 0.3620, Valid Loss: 0.3019
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3137
Epoch 3/10, Batch 20/145, Loss: 0.4304
Epoch 3/10, Batch 30/145, Loss: 0.4390
Epoch 3/10, Batch 40/145, Loss: 0.2625
Epoch 3/10, Batch 50/145, Loss: 0.1994
Epoch 3/10, Batch 60/145, Loss: 0.4505
Epoch 3/10, Batch 70/145, Loss: 0.2237
Epoch 3/10, Batch 80/145, Loss: 0.4050
Epoch 3/10, Batch 90/145, Loss: 0.5097
Epoch 3/10, Batch 100/145, Loss: 0.3497
Epoch 3/10, Batch 110/145, Loss: 0.2216
Epoch 3/10, Batch 120/145, Loss: 0.2517
Epoch 3/10, Batch 130/145, Loss: 0.1669
Epoch 3/10, Batch 140/145, Loss: 0.2142
Epoch 3/10, Train Loss: 0.3030, Valid Loss: 0.2696
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1773
Epoch 4/10, Batch 20/145, Loss: 0.2860
Epoch 4/10, Batch 30/145, Loss: 0.3226
Epoch 4/10, Batch 40/145, Loss: 0.3549
Epoch 4/10, Batch 50/145, Loss: 0.3349
Epoch 4/10, Batch 60/145, Loss: 0.2198
Epoch 4/10, Batch 70/145, Loss: 0.1920
Epoch 4/10, Batch 80/145, Loss: 0.2672
Epoch 4/10, Batch 90/145, Loss: 0.3388
Epoch 4/10, Batch 100/145, Loss: 0.1722
Epoch 4/10, Batch 110/145, Loss: 0.2587
Epoch 4/10, Batch 120/145, Loss: 0.1953
Epoch 4/10, Batch 130/145, Loss: 0.2393
Epoch 4/10, Batch 140/145, Loss: 0.1225
Epoch 4/10, Train Loss: 0.2586, Valid Loss: 0.2625
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3312
Epoch 5/10, Batch 20/145, Loss: 0.3680
Epoch 5/10, Batch 30/145, Loss: 0.2044
Epoch 5/10, Batch 40/145, Loss: 0.2443
Epoch 5/10, Batch 50/145, Loss: 0.1618
Epoch 5/10, Batch 60/145, Loss: 0.2332
Epoch 5/10, Batch 70/145, Loss: 0.3254
Epoch 5/10, Batch 80/145, Loss: 0.2800
Epoch 5/10, Batch 90/145, Loss: 0.1977
Epoch 5/10, Batch 100/145, Loss: 0.2823
Epoch 5/10, Batch 110/145, Loss: 0.0740
Epoch 5/10, Batch 120/145, Loss: 0.1523
Epoch 5/10, Batch 130/145, Loss: 0.1789
Epoch 5/10, Batch 140/145, Loss: 0.2120
Epoch 5/10, Train Loss: 0.2420, Valid Loss: 0.2478
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1753
Epoch 6/10, Batch 20/145, Loss: 0.1888
Epoch 6/10, Batch 30/145, Loss: 0.2155
Epoch 6/10, Batch 40/145, Loss: 0.1986
Epoch 6/10, Batch 50/145, Loss: 0.3660
Epoch 6/10, Batch 60/145, Loss: 0.0486
Epoch 6/10, Batch 70/145, Loss: 0.1441
Epoch 6/10, Batch 80/145, Loss: 0.2409
Epoch 6/10, Batch 90/145, Loss: 0.2178
Epoch 6/10, Batch 100/145, Loss: 0.2965
Epoch 6/10, Batch 110/145, Loss: 0.3618
Epoch 6/10, Batch 120/145, Loss: 0.2347
Epoch 6/10, Batch 130/145, Loss: 0.1907
Epoch 6/10, Batch 140/145, Loss: 0.1363
Epoch 6/10, Train Loss: 0.2261, Valid Loss: 0.2466
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1945
Epoch 7/10, Batch 20/145, Loss: 0.1186
Epoch 7/10, Batch 30/145, Loss: 0.1734
Epoch 7/10, Batch 40/145, Loss: 0.2949
Epoch 7/10, Batch 50/145, Loss: 0.2377
Epoch 7/10, Batch 60/145, Loss: 0.1663
Epoch 7/10, Batch 70/145, Loss: 0.3486
Epoch 7/10, Batch 80/145, Loss: 0.1016
Epoch 7/10, Batch 90/145, Loss: 0.4178
Epoch 7/10, Batch 100/145, Loss: 0.1585
Epoch 7/10, Batch 110/145, Loss: 0.1277
Epoch 7/10, Batch 120/145, Loss: 0.0899
Epoch 7/10, Batch 130/145, Loss: 0.1690
Epoch 7/10, Batch 140/145, Loss: 0.2481
Epoch 7/10, Train Loss: 0.2160, Valid Loss: 0.2377
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2051
Epoch 8/10, Batch 20/145, Loss: 0.2113
Epoch 8/10, Batch 30/145, Loss: 0.1854
Epoch 8/10, Batch 40/145, Loss: 0.1637
Epoch 8/10, Batch 50/145, Loss: 0.1823
Epoch 8/10, Batch 60/145, Loss: 0.2986
Epoch 8/10, Batch 70/145, Loss: 0.1560
Epoch 8/10, Batch 80/145, Loss: 0.1676
Epoch 8/10, Batch 90/145, Loss: 0.1055
Epoch 8/10, Batch 100/145, Loss: 0.1910
Epoch 8/10, Batch 110/145, Loss: 0.3162
Epoch 8/10, Batch 120/145, Loss: 0.0883
Epoch 8/10, Batch 130/145, Loss: 0.1837
Epoch 8/10, Batch 140/145, Loss: 0.2168
Epoch 8/10, Train Loss: 0.2029, Valid Loss: 0.2280
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2763
Epoch 9/10, Batch 20/145, Loss: 0.2067
Epoch 9/10, Batch 30/145, Loss: 0.1393
Epoch 9/10, Batch 40/145, Loss: 0.1616
Epoch 9/10, Batch 50/145, Loss: 0.3316
Epoch 9/10, Batch 60/145, Loss: 0.1554
Epoch 9/10, Batch 70/145, Loss: 0.4211
Epoch 9/10, Batch 80/145, Loss: 0.2695
Epoch 9/10, Batch 90/145, Loss: 0.1525
Epoch 9/10, Batch 100/145, Loss: 0.2395
Epoch 9/10, Batch 110/145, Loss: 0.1851
Epoch 9/10, Batch 120/145, Loss: 0.1756
Epoch 9/10, Batch 130/145, Loss: 0.1947
Epoch 9/10, Batch 140/145, Loss: 0.0591
Epoch 9/10, Train Loss: 0.1999, Valid Loss: 0.2192
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2507
Epoch 10/10, Batch 20/145, Loss: 0.1492
Epoch 10/10, Batch 30/145, Loss: 0.1475
Epoch 10/10, Batch 40/145, Loss: 0.1493
Epoch 10/10, Batch 50/145, Loss: 0.1113
Epoch 10/10, Batch 60/145, Loss: 0.1031
Epoch 10/10, Batch 70/145, Loss: 0.2627
Epoch 10/10, Batch 80/145, Loss: 0.3958
Epoch 10/10, Batch 90/145, Loss: 0.1191
Epoch 10/10, Batch 100/145, Loss: 0.1000
Epoch 10/10, Batch 110/145, Loss: 0.3135
Epoch 10/10, Batch 120/145, Loss: 0.1418
Epoch 10/10, Batch 130/145, Loss: 0.2203
Epoch 10/10, Batch 140/145, Loss: 0.1097
Epoch 10/10, Train Loss: 0.1918, Valid Loss: 0.2161
Model saved!
Accuracy: 0.9264
Precision: 0.9250
Recall: 0.9264
F1-score: 0.9251
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4701
Epoch 1/10, Batch 20/145, Loss: 0.8763
Epoch 1/10, Batch 30/145, Loss: 0.8794
Epoch 1/10, Batch 40/145, Loss: 0.8835
Epoch 1/10, Batch 50/145, Loss: 0.5312
Epoch 1/10, Batch 60/145, Loss: 0.4563
Epoch 1/10, Batch 70/145, Loss: 0.5752
Epoch 1/10, Batch 80/145, Loss: 0.4023
Epoch 1/10, Batch 90/145, Loss: 0.4770
Epoch 1/10, Batch 100/145, Loss: 0.5968
Epoch 1/10, Batch 110/145, Loss: 0.4587
Epoch 1/10, Batch 120/145, Loss: 0.5095
Epoch 1/10, Batch 130/145, Loss: 0.4148
Epoch 1/10, Batch 140/145, Loss: 0.4392
Epoch 1/10, Train Loss: 0.6820, Valid Loss: 0.3928
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4355
Epoch 2/10, Batch 20/145, Loss: 0.5473
Epoch 2/10, Batch 30/145, Loss: 0.2346
Epoch 2/10, Batch 40/145, Loss: 0.5462
Epoch 2/10, Batch 50/145, Loss: 0.2995
Epoch 2/10, Batch 60/145, Loss: 0.4642
Epoch 2/10, Batch 70/145, Loss: 0.3215
Epoch 2/10, Batch 80/145, Loss: 0.4010
Epoch 2/10, Batch 90/145, Loss: 0.2674
Epoch 2/10, Batch 100/145, Loss: 0.2715
Epoch 2/10, Batch 110/145, Loss: 0.3227
Epoch 2/10, Batch 120/145, Loss: 0.3101
Epoch 2/10, Batch 130/145, Loss: 0.4218
Epoch 2/10, Batch 140/145, Loss: 0.2088
Epoch 2/10, Train Loss: 0.3549, Valid Loss: 0.3111
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2284
Epoch 3/10, Batch 20/145, Loss: 0.2402
Epoch 3/10, Batch 30/145, Loss: 0.1259
Epoch 3/10, Batch 40/145, Loss: 0.1989
Epoch 3/10, Batch 50/145, Loss: 0.2842
Epoch 3/10, Batch 60/145, Loss: 0.4217
Epoch 3/10, Batch 70/145, Loss: 0.2097
Epoch 3/10, Batch 80/145, Loss: 0.3087
Epoch 3/10, Batch 90/145, Loss: 0.5072
Epoch 3/10, Batch 100/145, Loss: 0.3233
Epoch 3/10, Batch 110/145, Loss: 0.1759
Epoch 3/10, Batch 120/145, Loss: 0.1840
Epoch 3/10, Batch 130/145, Loss: 0.2432
Epoch 3/10, Batch 140/145, Loss: 0.2436
Epoch 3/10, Train Loss: 0.2994, Valid Loss: 0.2809
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1292
Epoch 4/10, Batch 20/145, Loss: 0.2061
Epoch 4/10, Batch 30/145, Loss: 0.3033
Epoch 4/10, Batch 40/145, Loss: 0.4730
Epoch 4/10, Batch 50/145, Loss: 0.1548
Epoch 4/10, Batch 60/145, Loss: 0.2066
Epoch 4/10, Batch 70/145, Loss: 0.2767
Epoch 4/10, Batch 80/145, Loss: 0.4022
Epoch 4/10, Batch 90/145, Loss: 0.2396
Epoch 4/10, Batch 100/145, Loss: 0.2710
Epoch 4/10, Batch 110/145, Loss: 0.1293
Epoch 4/10, Batch 120/145, Loss: 0.2869
Epoch 4/10, Batch 130/145, Loss: 0.2154
Epoch 4/10, Batch 140/145, Loss: 0.1910
Epoch 4/10, Train Loss: 0.2584, Valid Loss: 0.2740
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1959
Epoch 5/10, Batch 20/145, Loss: 0.2110
Epoch 5/10, Batch 30/145, Loss: 0.2384
Epoch 5/10, Batch 40/145, Loss: 0.1815
Epoch 5/10, Batch 50/145, Loss: 0.1412
Epoch 5/10, Batch 60/145, Loss: 0.2473
Epoch 5/10, Batch 70/145, Loss: 0.1721
Epoch 5/10, Batch 80/145, Loss: 0.2012
Epoch 5/10, Batch 90/145, Loss: 0.2010
Epoch 5/10, Batch 100/145, Loss: 0.3305
Epoch 5/10, Batch 110/145, Loss: 0.0949
Epoch 5/10, Batch 120/145, Loss: 0.2512
Epoch 5/10, Batch 130/145, Loss: 0.1705
Epoch 5/10, Batch 140/145, Loss: 0.2936
Epoch 5/10, Train Loss: 0.2319, Valid Loss: 0.2551
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1298
Epoch 6/10, Batch 20/145, Loss: 0.1916
Epoch 6/10, Batch 30/145, Loss: 0.1962
Epoch 6/10, Batch 40/145, Loss: 0.2150
Epoch 6/10, Batch 50/145, Loss: 0.3085
Epoch 6/10, Batch 60/145, Loss: 0.1003
Epoch 6/10, Batch 70/145, Loss: 0.3365
Epoch 6/10, Batch 80/145, Loss: 0.2992
Epoch 6/10, Batch 90/145, Loss: 0.1568
Epoch 6/10, Batch 100/145, Loss: 0.2718
Epoch 6/10, Batch 110/145, Loss: 0.1470
Epoch 6/10, Batch 120/145, Loss: 0.2860
Epoch 6/10, Batch 130/145, Loss: 0.2496
Epoch 6/10, Batch 140/145, Loss: 0.1456
Epoch 6/10, Train Loss: 0.2174, Valid Loss: 0.2558
Epoch 7/10, Batch 10/145, Loss: 0.2053
Epoch 7/10, Batch 20/145, Loss: 0.2247
Epoch 7/10, Batch 30/145, Loss: 0.2127
Epoch 7/10, Batch 40/145, Loss: 0.5056
Epoch 7/10, Batch 50/145, Loss: 0.1636
Epoch 7/10, Batch 60/145, Loss: 0.0995
Epoch 7/10, Batch 70/145, Loss: 0.2180
Epoch 7/10, Batch 80/145, Loss: 0.1703
Epoch 7/10, Batch 90/145, Loss: 0.3892
Epoch 7/10, Batch 100/145, Loss: 0.2084
Epoch 7/10, Batch 110/145, Loss: 0.1993
Epoch 7/10, Batch 120/145, Loss: 0.1892
Epoch 7/10, Batch 130/145, Loss: 0.3127
Epoch 7/10, Batch 140/145, Loss: 0.1556
Epoch 7/10, Train Loss: 0.2128, Valid Loss: 0.2529
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1914
Epoch 8/10, Batch 20/145, Loss: 0.1504
Epoch 8/10, Batch 30/145, Loss: 0.1482
Epoch 8/10, Batch 40/145, Loss: 0.2300
Epoch 8/10, Batch 50/145, Loss: 0.1783
Epoch 8/10, Batch 60/145, Loss: 0.1540
Epoch 8/10, Batch 70/145, Loss: 0.1338
Epoch 8/10, Batch 80/145, Loss: 0.2167
Epoch 8/10, Batch 90/145, Loss: 0.1318
Epoch 8/10, Batch 100/145, Loss: 0.2716
Epoch 8/10, Batch 110/145, Loss: 0.2932
Epoch 8/10, Batch 120/145, Loss: 0.2600
Epoch 8/10, Batch 130/145, Loss: 0.1644
Epoch 8/10, Batch 140/145, Loss: 0.1211
Epoch 8/10, Train Loss: 0.1991, Valid Loss: 0.2497
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1706
Epoch 9/10, Batch 20/145, Loss: 0.2273
Epoch 9/10, Batch 30/145, Loss: 0.0986
Epoch 9/10, Batch 40/145, Loss: 0.2091
Epoch 9/10, Batch 50/145, Loss: 0.1150
Epoch 9/10, Batch 60/145, Loss: 0.1220
Epoch 9/10, Batch 70/145, Loss: 0.2198
Epoch 9/10, Batch 80/145, Loss: 0.2088
Epoch 9/10, Batch 90/145, Loss: 0.2882
Epoch 9/10, Batch 100/145, Loss: 0.1629
Epoch 9/10, Batch 110/145, Loss: 0.1384
Epoch 9/10, Batch 120/145, Loss: 0.1049
Epoch 9/10, Batch 130/145, Loss: 0.3799
Epoch 9/10, Batch 140/145, Loss: 0.1376
Epoch 9/10, Train Loss: 0.1931, Valid Loss: 0.2341
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0795
Epoch 10/10, Batch 20/145, Loss: 0.0872
Epoch 10/10, Batch 30/145, Loss: 0.1037
Epoch 10/10, Batch 40/145, Loss: 0.2095
Epoch 10/10, Batch 50/145, Loss: 0.1774
Epoch 10/10, Batch 60/145, Loss: 0.1388
Epoch 10/10, Batch 70/145, Loss: 0.1444
Epoch 10/10, Batch 80/145, Loss: 0.3237
Epoch 10/10, Batch 90/145, Loss: 0.1157
Epoch 10/10, Batch 100/145, Loss: 0.2513
Epoch 10/10, Batch 110/145, Loss: 0.1613
Epoch 10/10, Batch 120/145, Loss: 0.1593
Epoch 10/10, Batch 130/145, Loss: 0.1096
Epoch 10/10, Batch 140/145, Loss: 0.2762
Epoch 10/10, Train Loss: 0.1863, Valid Loss: 0.2344
Accuracy: 0.9194
Precision: 0.9176
Recall: 0.9194
F1-score: 0.9180
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4604
Epoch 1/10, Batch 20/145, Loss: 0.9363
Epoch 1/10, Batch 30/145, Loss: 0.8094
Epoch 1/10, Batch 40/145, Loss: 0.8276
Epoch 1/10, Batch 50/145, Loss: 0.5566
Epoch 1/10, Batch 60/145, Loss: 0.6660
Epoch 1/10, Batch 70/145, Loss: 0.5757
Epoch 1/10, Batch 80/145, Loss: 0.4958
Epoch 1/10, Batch 90/145, Loss: 0.5060
Epoch 1/10, Batch 100/145, Loss: 0.5232
Epoch 1/10, Batch 110/145, Loss: 0.4347
Epoch 1/10, Batch 120/145, Loss: 0.5290
Epoch 1/10, Batch 130/145, Loss: 0.4218
Epoch 1/10, Batch 140/145, Loss: 0.5047
Epoch 1/10, Train Loss: 0.6859, Valid Loss: 0.3797
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3350
Epoch 2/10, Batch 20/145, Loss: 0.5415
Epoch 2/10, Batch 30/145, Loss: 0.3446
Epoch 2/10, Batch 40/145, Loss: 0.3967
Epoch 2/10, Batch 50/145, Loss: 0.6026
Epoch 2/10, Batch 60/145, Loss: 0.4268
Epoch 2/10, Batch 70/145, Loss: 0.4126
Epoch 2/10, Batch 80/145, Loss: 0.1994
Epoch 2/10, Batch 90/145, Loss: 0.2956
Epoch 2/10, Batch 100/145, Loss: 0.3207
Epoch 2/10, Batch 110/145, Loss: 0.4011
Epoch 2/10, Batch 120/145, Loss: 0.4920
Epoch 2/10, Batch 130/145, Loss: 0.3465
Epoch 2/10, Batch 140/145, Loss: 0.2419
Epoch 2/10, Train Loss: 0.3602, Valid Loss: 0.3060
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2186
Epoch 3/10, Batch 20/145, Loss: 0.2004
Epoch 3/10, Batch 30/145, Loss: 0.2700
Epoch 3/10, Batch 40/145, Loss: 0.2594
Epoch 3/10, Batch 50/145, Loss: 0.2246
Epoch 3/10, Batch 60/145, Loss: 0.3916
Epoch 3/10, Batch 70/145, Loss: 0.2687
Epoch 3/10, Batch 80/145, Loss: 0.2443
Epoch 3/10, Batch 90/145, Loss: 0.5185
Epoch 3/10, Batch 100/145, Loss: 0.4051
Epoch 3/10, Batch 110/145, Loss: 0.2430
Epoch 3/10, Batch 120/145, Loss: 0.3025
Epoch 3/10, Batch 130/145, Loss: 0.2273
Epoch 3/10, Batch 140/145, Loss: 0.1261
Epoch 3/10, Train Loss: 0.3052, Valid Loss: 0.2704
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1565
Epoch 4/10, Batch 20/145, Loss: 0.3569
Epoch 4/10, Batch 30/145, Loss: 0.2927
Epoch 4/10, Batch 40/145, Loss: 0.3112
Epoch 4/10, Batch 50/145, Loss: 0.1803
Epoch 4/10, Batch 60/145, Loss: 0.2043
Epoch 4/10, Batch 70/145, Loss: 0.1192
Epoch 4/10, Batch 80/145, Loss: 0.3080
Epoch 4/10, Batch 90/145, Loss: 0.3654
Epoch 4/10, Batch 100/145, Loss: 0.3049
Epoch 4/10, Batch 110/145, Loss: 0.2143
Epoch 4/10, Batch 120/145, Loss: 0.2038
Epoch 4/10, Batch 130/145, Loss: 0.1465
Epoch 4/10, Batch 140/145, Loss: 0.2548
Epoch 4/10, Train Loss: 0.2618, Valid Loss: 0.2737
Epoch 5/10, Batch 10/145, Loss: 0.2462
Epoch 5/10, Batch 20/145, Loss: 0.2311
Epoch 5/10, Batch 30/145, Loss: 0.2249
Epoch 5/10, Batch 40/145, Loss: 0.2571
Epoch 5/10, Batch 50/145, Loss: 0.2113
Epoch 5/10, Batch 60/145, Loss: 0.1641
Epoch 5/10, Batch 70/145, Loss: 0.3906
Epoch 5/10, Batch 80/145, Loss: 0.2798
Epoch 5/10, Batch 90/145, Loss: 0.3553
Epoch 5/10, Batch 100/145, Loss: 0.2739
Epoch 5/10, Batch 110/145, Loss: 0.2162
Epoch 5/10, Batch 120/145, Loss: 0.1490
Epoch 5/10, Batch 130/145, Loss: 0.1680
Epoch 5/10, Batch 140/145, Loss: 0.2256
Epoch 5/10, Train Loss: 0.2358, Valid Loss: 0.2537
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.0914
Epoch 6/10, Batch 20/145, Loss: 0.1657
Epoch 6/10, Batch 30/145, Loss: 0.2188
Epoch 6/10, Batch 40/145, Loss: 0.2268
Epoch 6/10, Batch 50/145, Loss: 0.4088
Epoch 6/10, Batch 60/145, Loss: 0.2044
Epoch 6/10, Batch 70/145, Loss: 0.3815
Epoch 6/10, Batch 80/145, Loss: 0.4126
Epoch 6/10, Batch 90/145, Loss: 0.1148
Epoch 6/10, Batch 100/145, Loss: 0.2566
Epoch 6/10, Batch 110/145, Loss: 0.2970
Epoch 6/10, Batch 120/145, Loss: 0.1718
Epoch 6/10, Batch 130/145, Loss: 0.3193
Epoch 6/10, Batch 140/145, Loss: 0.4258
Epoch 6/10, Train Loss: 0.2282, Valid Loss: 0.2542
Epoch 7/10, Batch 10/145, Loss: 0.3368
Epoch 7/10, Batch 20/145, Loss: 0.1509
Epoch 7/10, Batch 30/145, Loss: 0.1403
Epoch 7/10, Batch 40/145, Loss: 0.5954
Epoch 7/10, Batch 50/145, Loss: 0.1654
Epoch 7/10, Batch 60/145, Loss: 0.3167
Epoch 7/10, Batch 70/145, Loss: 0.1253
Epoch 7/10, Batch 80/145, Loss: 0.1400
Epoch 7/10, Batch 90/145, Loss: 0.1622
Epoch 7/10, Batch 100/145, Loss: 0.2392
Epoch 7/10, Batch 110/145, Loss: 0.2574
Epoch 7/10, Batch 120/145, Loss: 0.1923
Epoch 7/10, Batch 130/145, Loss: 0.2466
Epoch 7/10, Batch 140/145, Loss: 0.1357
Epoch 7/10, Train Loss: 0.2188, Valid Loss: 0.2373
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1428
Epoch 8/10, Batch 20/145, Loss: 0.1000
Epoch 8/10, Batch 30/145, Loss: 0.2278
Epoch 8/10, Batch 40/145, Loss: 0.2054
Epoch 8/10, Batch 50/145, Loss: 0.2513
Epoch 8/10, Batch 60/145, Loss: 0.2436
Epoch 8/10, Batch 70/145, Loss: 0.2281
Epoch 8/10, Batch 80/145, Loss: 0.0879
Epoch 8/10, Batch 90/145, Loss: 0.1444
Epoch 8/10, Batch 100/145, Loss: 0.1999
Epoch 8/10, Batch 110/145, Loss: 0.1972
Epoch 8/10, Batch 120/145, Loss: 0.1783
Epoch 8/10, Batch 130/145, Loss: 0.1131
Epoch 8/10, Batch 140/145, Loss: 0.2998
Epoch 8/10, Train Loss: 0.2129, Valid Loss: 0.2353
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1262
Epoch 9/10, Batch 20/145, Loss: 0.1225
Epoch 9/10, Batch 30/145, Loss: 0.1398
Epoch 9/10, Batch 40/145, Loss: 0.1980
Epoch 9/10, Batch 50/145, Loss: 0.2220
Epoch 9/10, Batch 60/145, Loss: 0.2300
Epoch 9/10, Batch 70/145, Loss: 0.2566
Epoch 9/10, Batch 80/145, Loss: 0.2391
Epoch 9/10, Batch 90/145, Loss: 0.1242
Epoch 9/10, Batch 100/145, Loss: 0.2324
Epoch 9/10, Batch 110/145, Loss: 0.2025
Epoch 9/10, Batch 120/145, Loss: 0.2462
Epoch 9/10, Batch 130/145, Loss: 0.1544
Epoch 9/10, Batch 140/145, Loss: 0.2025
Epoch 9/10, Train Loss: 0.1986, Valid Loss: 0.2282
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0823
Epoch 10/10, Batch 20/145, Loss: 0.2378
Epoch 10/10, Batch 30/145, Loss: 0.1203
Epoch 10/10, Batch 40/145, Loss: 0.2600
Epoch 10/10, Batch 50/145, Loss: 0.2010
Epoch 10/10, Batch 60/145, Loss: 0.1376
Epoch 10/10, Batch 70/145, Loss: 0.1467
Epoch 10/10, Batch 80/145, Loss: 0.2015
Epoch 10/10, Batch 90/145, Loss: 0.0843
Epoch 10/10, Batch 100/145, Loss: 0.1224
Epoch 10/10, Batch 110/145, Loss: 0.3547
Epoch 10/10, Batch 120/145, Loss: 0.1596
Epoch 10/10, Batch 130/145, Loss: 0.3411
Epoch 10/10, Batch 140/145, Loss: 0.1477
Epoch 10/10, Train Loss: 0.1934, Valid Loss: 0.2192
Model saved!
Accuracy: 0.9217
Precision: 0.9199
Recall: 0.9217
F1-score: 0.9204
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5374
Epoch 1/10, Batch 20/145, Loss: 0.9018
Epoch 1/10, Batch 30/145, Loss: 0.7895
Epoch 1/10, Batch 40/145, Loss: 0.7836
Epoch 1/10, Batch 50/145, Loss: 0.6713
Epoch 1/10, Batch 60/145, Loss: 0.4348
Epoch 1/10, Batch 70/145, Loss: 0.6247
Epoch 1/10, Batch 80/145, Loss: 0.5046
Epoch 1/10, Batch 90/145, Loss: 0.5557
Epoch 1/10, Batch 100/145, Loss: 0.6848
Epoch 1/10, Batch 110/145, Loss: 0.4054
Epoch 1/10, Batch 120/145, Loss: 0.5567
Epoch 1/10, Batch 130/145, Loss: 0.3564
Epoch 1/10, Batch 140/145, Loss: 0.3318
Epoch 1/10, Train Loss: 0.6909, Valid Loss: 0.3887
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3757
Epoch 2/10, Batch 20/145, Loss: 0.3158
Epoch 2/10, Batch 30/145, Loss: 0.2644
Epoch 2/10, Batch 40/145, Loss: 0.3887
Epoch 2/10, Batch 50/145, Loss: 0.3770
Epoch 2/10, Batch 60/145, Loss: 0.3623
Epoch 2/10, Batch 70/145, Loss: 0.5501
Epoch 2/10, Batch 80/145, Loss: 0.3622
Epoch 2/10, Batch 90/145, Loss: 0.3523
Epoch 2/10, Batch 100/145, Loss: 0.2587
Epoch 2/10, Batch 110/145, Loss: 0.3126
Epoch 2/10, Batch 120/145, Loss: 0.4796
Epoch 2/10, Batch 130/145, Loss: 0.2274
Epoch 2/10, Batch 140/145, Loss: 0.2986
Epoch 2/10, Train Loss: 0.3653, Valid Loss: 0.3010
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2334
Epoch 3/10, Batch 20/145, Loss: 0.2681
Epoch 3/10, Batch 30/145, Loss: 0.3360
Epoch 3/10, Batch 40/145, Loss: 0.2345
Epoch 3/10, Batch 50/145, Loss: 0.2601
Epoch 3/10, Batch 60/145, Loss: 0.1940
Epoch 3/10, Batch 70/145, Loss: 0.3175
Epoch 3/10, Batch 80/145, Loss: 0.2575
Epoch 3/10, Batch 90/145, Loss: 0.4905
Epoch 3/10, Batch 100/145, Loss: 0.2439
Epoch 3/10, Batch 110/145, Loss: 0.3154
Epoch 3/10, Batch 120/145, Loss: 0.1296
Epoch 3/10, Batch 130/145, Loss: 0.1828
Epoch 3/10, Batch 140/145, Loss: 0.2064
Epoch 3/10, Train Loss: 0.3053, Valid Loss: 0.2679
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2775
Epoch 4/10, Batch 20/145, Loss: 0.1845
Epoch 4/10, Batch 30/145, Loss: 0.2309
Epoch 4/10, Batch 40/145, Loss: 0.3122
Epoch 4/10, Batch 50/145, Loss: 0.1619
Epoch 4/10, Batch 60/145, Loss: 0.1964
Epoch 4/10, Batch 70/145, Loss: 0.1887
Epoch 4/10, Batch 80/145, Loss: 0.2424
Epoch 4/10, Batch 90/145, Loss: 0.1556
Epoch 4/10, Batch 100/145, Loss: 0.2787
Epoch 4/10, Batch 110/145, Loss: 0.2565
Epoch 4/10, Batch 120/145, Loss: 0.2086
Epoch 4/10, Batch 130/145, Loss: 0.2447
Epoch 4/10, Batch 140/145, Loss: 0.1895
Epoch 4/10, Train Loss: 0.2639, Valid Loss: 0.2577
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1992
Epoch 5/10, Batch 20/145, Loss: 0.2028
Epoch 5/10, Batch 30/145, Loss: 0.2606
Epoch 5/10, Batch 40/145, Loss: 0.1589
Epoch 5/10, Batch 50/145, Loss: 0.1130
Epoch 5/10, Batch 60/145, Loss: 0.2778
Epoch 5/10, Batch 70/145, Loss: 0.3610
Epoch 5/10, Batch 80/145, Loss: 0.2360
Epoch 5/10, Batch 90/145, Loss: 0.1401
Epoch 5/10, Batch 100/145, Loss: 0.1477
Epoch 5/10, Batch 110/145, Loss: 0.1440
Epoch 5/10, Batch 120/145, Loss: 0.3088
Epoch 5/10, Batch 130/145, Loss: 0.3307
Epoch 5/10, Batch 140/145, Loss: 0.4227
Epoch 5/10, Train Loss: 0.2477, Valid Loss: 0.2392
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2311
Epoch 6/10, Batch 20/145, Loss: 0.2193
Epoch 6/10, Batch 30/145, Loss: 0.2448
Epoch 6/10, Batch 40/145, Loss: 0.1647
Epoch 6/10, Batch 50/145, Loss: 0.3147
Epoch 6/10, Batch 60/145, Loss: 0.2507
Epoch 6/10, Batch 70/145, Loss: 0.3814
Epoch 6/10, Batch 80/145, Loss: 0.3198
Epoch 6/10, Batch 90/145, Loss: 0.3016
Epoch 6/10, Batch 100/145, Loss: 0.3672
Epoch 6/10, Batch 110/145, Loss: 0.1442
Epoch 6/10, Batch 120/145, Loss: 0.2938
Epoch 6/10, Batch 130/145, Loss: 0.1220
Epoch 6/10, Batch 140/145, Loss: 0.2744
Epoch 6/10, Train Loss: 0.2358, Valid Loss: 0.2385
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.4648
Epoch 7/10, Batch 20/145, Loss: 0.2135
Epoch 7/10, Batch 30/145, Loss: 0.3039
Epoch 7/10, Batch 40/145, Loss: 0.5008
Epoch 7/10, Batch 50/145, Loss: 0.2071
Epoch 7/10, Batch 60/145, Loss: 0.1032
Epoch 7/10, Batch 70/145, Loss: 0.2014
Epoch 7/10, Batch 80/145, Loss: 0.2408
Epoch 7/10, Batch 90/145, Loss: 0.2111
Epoch 7/10, Batch 100/145, Loss: 0.2938
Epoch 7/10, Batch 110/145, Loss: 0.2758
Epoch 7/10, Batch 120/145, Loss: 0.2110
Epoch 7/10, Batch 130/145, Loss: 0.2013
Epoch 7/10, Batch 140/145, Loss: 0.3240
Epoch 7/10, Train Loss: 0.2280, Valid Loss: 0.2236
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2158
Epoch 8/10, Batch 20/145, Loss: 0.1504
Epoch 8/10, Batch 30/145, Loss: 0.1929
Epoch 8/10, Batch 40/145, Loss: 0.3649
Epoch 8/10, Batch 50/145, Loss: 0.1359
Epoch 8/10, Batch 60/145, Loss: 0.2095
Epoch 8/10, Batch 70/145, Loss: 0.1322
Epoch 8/10, Batch 80/145, Loss: 0.2217
Epoch 8/10, Batch 90/145, Loss: 0.1686
Epoch 8/10, Batch 100/145, Loss: 0.3204
Epoch 8/10, Batch 110/145, Loss: 0.2108
Epoch 8/10, Batch 120/145, Loss: 0.1777
Epoch 8/10, Batch 130/145, Loss: 0.1956
Epoch 8/10, Batch 140/145, Loss: 0.2575
Epoch 8/10, Train Loss: 0.2098, Valid Loss: 0.2292
Epoch 9/10, Batch 10/145, Loss: 0.1751
Epoch 9/10, Batch 20/145, Loss: 0.0819
Epoch 9/10, Batch 30/145, Loss: 0.1232
Epoch 9/10, Batch 40/145, Loss: 0.1238
Epoch 9/10, Batch 50/145, Loss: 0.1778
Epoch 9/10, Batch 60/145, Loss: 0.1126
Epoch 9/10, Batch 70/145, Loss: 0.2301
Epoch 9/10, Batch 80/145, Loss: 0.1708
Epoch 9/10, Batch 90/145, Loss: 0.3936
Epoch 9/10, Batch 100/145, Loss: 0.2771
Epoch 9/10, Batch 110/145, Loss: 0.1004
Epoch 9/10, Batch 120/145, Loss: 0.1627
Epoch 9/10, Batch 130/145, Loss: 0.1420
Epoch 9/10, Batch 140/145, Loss: 0.1795
Epoch 9/10, Train Loss: 0.2057, Valid Loss: 0.2215
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1030
Epoch 10/10, Batch 20/145, Loss: 0.1470
Epoch 10/10, Batch 30/145, Loss: 0.0888
Epoch 10/10, Batch 40/145, Loss: 0.2093
Epoch 10/10, Batch 50/145, Loss: 0.2016
Epoch 10/10, Batch 60/145, Loss: 0.1741
Epoch 10/10, Batch 70/145, Loss: 0.1882
Epoch 10/10, Batch 80/145, Loss: 0.4731
Epoch 10/10, Batch 90/145, Loss: 0.1431
Epoch 10/10, Batch 100/145, Loss: 0.0719
Epoch 10/10, Batch 110/145, Loss: 0.1561
Epoch 10/10, Batch 120/145, Loss: 0.2357
Epoch 10/10, Batch 130/145, Loss: 0.2015
Epoch 10/10, Batch 140/145, Loss: 0.2142
Epoch 10/10, Train Loss: 0.2053, Valid Loss: 0.2157
Model saved!
Accuracy: 0.9252
Precision: 0.9241
Recall: 0.9252
F1-score: 0.9238
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5052
Epoch 1/10, Batch 20/145, Loss: 0.9010
Epoch 1/10, Batch 30/145, Loss: 0.7572
Epoch 1/10, Batch 40/145, Loss: 0.9229
Epoch 1/10, Batch 50/145, Loss: 0.5977
Epoch 1/10, Batch 60/145, Loss: 0.6247
Epoch 1/10, Batch 70/145, Loss: 0.7462
Epoch 1/10, Batch 80/145, Loss: 0.5426
Epoch 1/10, Batch 90/145, Loss: 0.5338
Epoch 1/10, Batch 100/145, Loss: 0.5142
Epoch 1/10, Batch 110/145, Loss: 0.3652
Epoch 1/10, Batch 120/145, Loss: 0.6564
Epoch 1/10, Batch 130/145, Loss: 0.4264
Epoch 1/10, Batch 140/145, Loss: 0.4394
Epoch 1/10, Train Loss: 0.6852, Valid Loss: 0.3682
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4324
Epoch 2/10, Batch 20/145, Loss: 0.4370
Epoch 2/10, Batch 30/145, Loss: 0.4166
Epoch 2/10, Batch 40/145, Loss: 0.5727
Epoch 2/10, Batch 50/145, Loss: 0.2516
Epoch 2/10, Batch 60/145, Loss: 0.4508
Epoch 2/10, Batch 70/145, Loss: 0.4390
Epoch 2/10, Batch 80/145, Loss: 0.5727
Epoch 2/10, Batch 90/145, Loss: 0.2517
Epoch 2/10, Batch 100/145, Loss: 0.4501
Epoch 2/10, Batch 110/145, Loss: 0.3762
Epoch 2/10, Batch 120/145, Loss: 0.2679
Epoch 2/10, Batch 130/145, Loss: 0.3762
Epoch 2/10, Batch 140/145, Loss: 0.3451
Epoch 2/10, Train Loss: 0.3687, Valid Loss: 0.2922
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1945
Epoch 3/10, Batch 20/145, Loss: 0.2628
Epoch 3/10, Batch 30/145, Loss: 0.2920
Epoch 3/10, Batch 40/145, Loss: 0.1517
Epoch 3/10, Batch 50/145, Loss: 0.2010
Epoch 3/10, Batch 60/145, Loss: 0.2275
Epoch 3/10, Batch 70/145, Loss: 0.2436
Epoch 3/10, Batch 80/145, Loss: 0.2244
Epoch 3/10, Batch 90/145, Loss: 0.3843
Epoch 3/10, Batch 100/145, Loss: 0.3050
Epoch 3/10, Batch 110/145, Loss: 0.2254
Epoch 3/10, Batch 120/145, Loss: 0.1206
Epoch 3/10, Batch 130/145, Loss: 0.1660
Epoch 3/10, Batch 140/145, Loss: 0.1933
Epoch 3/10, Train Loss: 0.3117, Valid Loss: 0.2717
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1679
Epoch 4/10, Batch 20/145, Loss: 0.2945
Epoch 4/10, Batch 30/145, Loss: 0.1650
Epoch 4/10, Batch 40/145, Loss: 0.4667
Epoch 4/10, Batch 50/145, Loss: 0.3061
Epoch 4/10, Batch 60/145, Loss: 0.2859
Epoch 4/10, Batch 70/145, Loss: 0.3337
Epoch 4/10, Batch 80/145, Loss: 0.2852
Epoch 4/10, Batch 90/145, Loss: 0.3723
Epoch 4/10, Batch 100/145, Loss: 0.2156
Epoch 4/10, Batch 110/145, Loss: 0.1940
Epoch 4/10, Batch 120/145, Loss: 0.2785
Epoch 4/10, Batch 130/145, Loss: 0.2093
Epoch 4/10, Batch 140/145, Loss: 0.1967
Epoch 4/10, Train Loss: 0.2675, Valid Loss: 0.2600
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1989
Epoch 5/10, Batch 20/145, Loss: 0.1024
Epoch 5/10, Batch 30/145, Loss: 0.3018
Epoch 5/10, Batch 40/145, Loss: 0.2405
Epoch 5/10, Batch 50/145, Loss: 0.1296
Epoch 5/10, Batch 60/145, Loss: 0.1779
Epoch 5/10, Batch 70/145, Loss: 0.2375
Epoch 5/10, Batch 80/145, Loss: 0.4493
Epoch 5/10, Batch 90/145, Loss: 0.1531
Epoch 5/10, Batch 100/145, Loss: 0.1401
Epoch 5/10, Batch 110/145, Loss: 0.1919
Epoch 5/10, Batch 120/145, Loss: 0.3673
Epoch 5/10, Batch 130/145, Loss: 0.2501
Epoch 5/10, Batch 140/145, Loss: 0.2220
Epoch 5/10, Train Loss: 0.2450, Valid Loss: 0.2434
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2236
Epoch 6/10, Batch 20/145, Loss: 0.1007
Epoch 6/10, Batch 30/145, Loss: 0.1698
Epoch 6/10, Batch 40/145, Loss: 0.0809
Epoch 6/10, Batch 50/145, Loss: 0.2705
Epoch 6/10, Batch 60/145, Loss: 0.2152
Epoch 6/10, Batch 70/145, Loss: 0.2164
Epoch 6/10, Batch 80/145, Loss: 0.4257
Epoch 6/10, Batch 90/145, Loss: 0.2064
Epoch 6/10, Batch 100/145, Loss: 0.1794
Epoch 6/10, Batch 110/145, Loss: 0.2075
Epoch 6/10, Batch 120/145, Loss: 0.2609
Epoch 6/10, Batch 130/145, Loss: 0.3010
Epoch 6/10, Batch 140/145, Loss: 0.3440
Epoch 6/10, Train Loss: 0.2348, Valid Loss: 0.2467
Epoch 7/10, Batch 10/145, Loss: 0.2187
Epoch 7/10, Batch 20/145, Loss: 0.2251
Epoch 7/10, Batch 30/145, Loss: 0.2121
Epoch 7/10, Batch 40/145, Loss: 0.4800
Epoch 7/10, Batch 50/145, Loss: 0.2056
Epoch 7/10, Batch 60/145, Loss: 0.2449
Epoch 7/10, Batch 70/145, Loss: 0.1618
Epoch 7/10, Batch 80/145, Loss: 0.1866
Epoch 7/10, Batch 90/145, Loss: 0.1940
Epoch 7/10, Batch 100/145, Loss: 0.1840
Epoch 7/10, Batch 110/145, Loss: 0.2235
Epoch 7/10, Batch 120/145, Loss: 0.1395
Epoch 7/10, Batch 130/145, Loss: 0.3006
Epoch 7/10, Batch 140/145, Loss: 0.1154
Epoch 7/10, Train Loss: 0.2240, Valid Loss: 0.2342
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2034
Epoch 8/10, Batch 20/145, Loss: 0.1743
Epoch 8/10, Batch 30/145, Loss: 0.1874
Epoch 8/10, Batch 40/145, Loss: 0.2146
Epoch 8/10, Batch 50/145, Loss: 0.5428
Epoch 8/10, Batch 60/145, Loss: 0.2569
Epoch 8/10, Batch 70/145, Loss: 0.3946
Epoch 8/10, Batch 80/145, Loss: 0.1580
Epoch 8/10, Batch 90/145, Loss: 0.1501
Epoch 8/10, Batch 100/145, Loss: 0.2665
Epoch 8/10, Batch 110/145, Loss: 0.1856
Epoch 8/10, Batch 120/145, Loss: 0.1229
Epoch 8/10, Batch 130/145, Loss: 0.1539
Epoch 8/10, Batch 140/145, Loss: 0.1532
Epoch 8/10, Train Loss: 0.2178, Valid Loss: 0.2293
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1960
Epoch 9/10, Batch 20/145, Loss: 0.1963
Epoch 9/10, Batch 30/145, Loss: 0.1477
Epoch 9/10, Batch 40/145, Loss: 0.1420
Epoch 9/10, Batch 50/145, Loss: 0.0732
Epoch 9/10, Batch 60/145, Loss: 0.1840
Epoch 9/10, Batch 70/145, Loss: 0.1970
Epoch 9/10, Batch 80/145, Loss: 0.2332
Epoch 9/10, Batch 90/145, Loss: 0.2567
Epoch 9/10, Batch 100/145, Loss: 0.2638
Epoch 9/10, Batch 110/145, Loss: 0.0537
Epoch 9/10, Batch 120/145, Loss: 0.1788
Epoch 9/10, Batch 130/145, Loss: 0.1912
Epoch 9/10, Batch 140/145, Loss: 0.1367
Epoch 9/10, Train Loss: 0.2104, Valid Loss: 0.2208
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2501
Epoch 10/10, Batch 20/145, Loss: 0.1021
Epoch 10/10, Batch 30/145, Loss: 0.2222
Epoch 10/10, Batch 40/145, Loss: 0.1885
Epoch 10/10, Batch 50/145, Loss: 0.2709
Epoch 10/10, Batch 60/145, Loss: 0.4312
Epoch 10/10, Batch 70/145, Loss: 0.1041
Epoch 10/10, Batch 80/145, Loss: 0.4771
Epoch 10/10, Batch 90/145, Loss: 0.1019
Epoch 10/10, Batch 100/145, Loss: 0.1261
Epoch 10/10, Batch 110/145, Loss: 0.2203
Epoch 10/10, Batch 120/145, Loss: 0.0942
Epoch 10/10, Batch 130/145, Loss: 0.5100
Epoch 10/10, Batch 140/145, Loss: 0.1363
Epoch 10/10, Train Loss: 0.2029, Valid Loss: 0.2191
Model saved!
Accuracy: 0.9206
Precision: 0.9189
Recall: 0.9206
F1-score: 0.9194
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5439
Epoch 1/10, Batch 20/145, Loss: 0.8377
Epoch 1/10, Batch 30/145, Loss: 0.8043
Epoch 1/10, Batch 40/145, Loss: 0.7170
Epoch 1/10, Batch 50/145, Loss: 0.6853
Epoch 1/10, Batch 60/145, Loss: 0.6348
Epoch 1/10, Batch 70/145, Loss: 0.7116
Epoch 1/10, Batch 80/145, Loss: 0.6026
Epoch 1/10, Batch 90/145, Loss: 0.5390
Epoch 1/10, Batch 100/145, Loss: 0.4892
Epoch 1/10, Batch 110/145, Loss: 0.3956
Epoch 1/10, Batch 120/145, Loss: 0.5852
Epoch 1/10, Batch 130/145, Loss: 0.3905
Epoch 1/10, Batch 140/145, Loss: 0.4203
Epoch 1/10, Train Loss: 0.6832, Valid Loss: 0.3634
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4075
Epoch 2/10, Batch 20/145, Loss: 0.4935
Epoch 2/10, Batch 30/145, Loss: 0.4142
Epoch 2/10, Batch 40/145, Loss: 0.4664
Epoch 2/10, Batch 50/145, Loss: 0.2636
Epoch 2/10, Batch 60/145, Loss: 0.3937
Epoch 2/10, Batch 70/145, Loss: 0.4683
Epoch 2/10, Batch 80/145, Loss: 0.2838
Epoch 2/10, Batch 90/145, Loss: 0.2148
Epoch 2/10, Batch 100/145, Loss: 0.3974
Epoch 2/10, Batch 110/145, Loss: 0.2676
Epoch 2/10, Batch 120/145, Loss: 0.4201
Epoch 2/10, Batch 130/145, Loss: 0.3845
Epoch 2/10, Batch 140/145, Loss: 0.3846
Epoch 2/10, Train Loss: 0.3619, Valid Loss: 0.2726
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3035
Epoch 3/10, Batch 20/145, Loss: 0.1928
Epoch 3/10, Batch 30/145, Loss: 0.3463
Epoch 3/10, Batch 40/145, Loss: 0.2152
Epoch 3/10, Batch 50/145, Loss: 0.1399
Epoch 3/10, Batch 60/145, Loss: 0.3492
Epoch 3/10, Batch 70/145, Loss: 0.2944
Epoch 3/10, Batch 80/145, Loss: 0.2928
Epoch 3/10, Batch 90/145, Loss: 0.5266
Epoch 3/10, Batch 100/145, Loss: 0.2438
Epoch 3/10, Batch 110/145, Loss: 0.2997
Epoch 3/10, Batch 120/145, Loss: 0.2114
Epoch 3/10, Batch 130/145, Loss: 0.3246
Epoch 3/10, Batch 140/145, Loss: 0.1993
Epoch 3/10, Train Loss: 0.3122, Valid Loss: 0.2338
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2196
Epoch 4/10, Batch 20/145, Loss: 0.3405
Epoch 4/10, Batch 30/145, Loss: 0.2995
Epoch 4/10, Batch 40/145, Loss: 0.2889
Epoch 4/10, Batch 50/145, Loss: 0.1836
Epoch 4/10, Batch 60/145, Loss: 0.2484
Epoch 4/10, Batch 70/145, Loss: 0.2502
Epoch 4/10, Batch 80/145, Loss: 0.3153
Epoch 4/10, Batch 90/145, Loss: 0.2180
Epoch 4/10, Batch 100/145, Loss: 0.2609
Epoch 4/10, Batch 110/145, Loss: 0.2469
Epoch 4/10, Batch 120/145, Loss: 0.2215
Epoch 4/10, Batch 130/145, Loss: 0.1942
Epoch 4/10, Batch 140/145, Loss: 0.2670
Epoch 4/10, Train Loss: 0.2641, Valid Loss: 0.2276
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1157
Epoch 5/10, Batch 20/145, Loss: 0.2484
Epoch 5/10, Batch 30/145, Loss: 0.1534
Epoch 5/10, Batch 40/145, Loss: 0.3146
Epoch 5/10, Batch 50/145, Loss: 0.1555
Epoch 5/10, Batch 60/145, Loss: 0.3231
Epoch 5/10, Batch 70/145, Loss: 0.2647
Epoch 5/10, Batch 80/145, Loss: 0.3622
Epoch 5/10, Batch 90/145, Loss: 0.2522
Epoch 5/10, Batch 100/145, Loss: 0.2899
Epoch 5/10, Batch 110/145, Loss: 0.0762
Epoch 5/10, Batch 120/145, Loss: 0.2950
Epoch 5/10, Batch 130/145, Loss: 0.3162
Epoch 5/10, Batch 140/145, Loss: 0.1492
Epoch 5/10, Train Loss: 0.2513, Valid Loss: 0.2109
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2561
Epoch 6/10, Batch 20/145, Loss: 0.3050
Epoch 6/10, Batch 30/145, Loss: 0.2104
Epoch 6/10, Batch 40/145, Loss: 0.2175
Epoch 6/10, Batch 50/145, Loss: 0.3238
Epoch 6/10, Batch 60/145, Loss: 0.1603
Epoch 6/10, Batch 70/145, Loss: 0.3002
Epoch 6/10, Batch 80/145, Loss: 0.1929
Epoch 6/10, Batch 90/145, Loss: 0.3057
Epoch 6/10, Batch 100/145, Loss: 0.3374
Epoch 6/10, Batch 110/145, Loss: 0.2156
Epoch 6/10, Batch 120/145, Loss: 0.4057
Epoch 6/10, Batch 130/145, Loss: 0.1349
Epoch 6/10, Batch 140/145, Loss: 0.1628
Epoch 6/10, Train Loss: 0.2309, Valid Loss: 0.2066
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2934
Epoch 7/10, Batch 20/145, Loss: 0.1197
Epoch 7/10, Batch 30/145, Loss: 0.2364
Epoch 7/10, Batch 40/145, Loss: 0.3441
Epoch 7/10, Batch 50/145, Loss: 0.1356
Epoch 7/10, Batch 60/145, Loss: 0.2012
Epoch 7/10, Batch 70/145, Loss: 0.2669
Epoch 7/10, Batch 80/145, Loss: 0.1205
Epoch 7/10, Batch 90/145, Loss: 0.2533
Epoch 7/10, Batch 100/145, Loss: 0.1139
Epoch 7/10, Batch 110/145, Loss: 0.2902
Epoch 7/10, Batch 120/145, Loss: 0.2514
Epoch 7/10, Batch 130/145, Loss: 0.2485
Epoch 7/10, Batch 140/145, Loss: 0.1680
Epoch 7/10, Train Loss: 0.2209, Valid Loss: 0.1942
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1870
Epoch 8/10, Batch 20/145, Loss: 0.1145
Epoch 8/10, Batch 30/145, Loss: 0.1643
Epoch 8/10, Batch 40/145, Loss: 0.1745
Epoch 8/10, Batch 50/145, Loss: 0.1502
Epoch 8/10, Batch 60/145, Loss: 0.1819
Epoch 8/10, Batch 70/145, Loss: 0.1991
Epoch 8/10, Batch 80/145, Loss: 0.1857
Epoch 8/10, Batch 90/145, Loss: 0.1415
Epoch 8/10, Batch 100/145, Loss: 0.4160
Epoch 8/10, Batch 110/145, Loss: 0.2216
Epoch 8/10, Batch 120/145, Loss: 0.1801
Epoch 8/10, Batch 130/145, Loss: 0.1061
Epoch 8/10, Batch 140/145, Loss: 0.3284
Epoch 8/10, Train Loss: 0.2080, Valid Loss: 0.2010
Epoch 9/10, Batch 10/145, Loss: 0.3014
Epoch 9/10, Batch 20/145, Loss: 0.2450
Epoch 9/10, Batch 30/145, Loss: 0.0928
Epoch 9/10, Batch 40/145, Loss: 0.1237
Epoch 9/10, Batch 50/145, Loss: 0.1642
Epoch 9/10, Batch 60/145, Loss: 0.1901
Epoch 9/10, Batch 70/145, Loss: 0.3553
Epoch 9/10, Batch 80/145, Loss: 0.3473
Epoch 9/10, Batch 90/145, Loss: 0.1270
Epoch 9/10, Batch 100/145, Loss: 0.1889
Epoch 9/10, Batch 110/145, Loss: 0.0815
Epoch 9/10, Batch 120/145, Loss: 0.1723
Epoch 9/10, Batch 130/145, Loss: 0.1962
Epoch 9/10, Batch 140/145, Loss: 0.1554
Epoch 9/10, Train Loss: 0.2126, Valid Loss: 0.1881
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2340
Epoch 10/10, Batch 20/145, Loss: 0.1159
Epoch 10/10, Batch 30/145, Loss: 0.1566
Epoch 10/10, Batch 40/145, Loss: 0.2309
Epoch 10/10, Batch 50/145, Loss: 0.2457
Epoch 10/10, Batch 60/145, Loss: 0.1326
Epoch 10/10, Batch 70/145, Loss: 0.1523
Epoch 10/10, Batch 80/145, Loss: 0.3746
Epoch 10/10, Batch 90/145, Loss: 0.2928
Epoch 10/10, Batch 100/145, Loss: 0.1386
Epoch 10/10, Batch 110/145, Loss: 0.1682
Epoch 10/10, Batch 120/145, Loss: 0.0898
Epoch 10/10, Batch 130/145, Loss: 0.2324
Epoch 10/10, Batch 140/145, Loss: 0.2837
Epoch 10/10, Train Loss: 0.1954, Valid Loss: 0.1873
Model saved!
Accuracy: 0.9276
Precision: 0.9263
Recall: 0.9276
F1-score: 0.9268
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5260
Epoch 1/10, Batch 20/145, Loss: 0.9061
Epoch 1/10, Batch 30/145, Loss: 0.8563
Epoch 1/10, Batch 40/145, Loss: 0.7632
Epoch 1/10, Batch 50/145, Loss: 0.6778
Epoch 1/10, Batch 60/145, Loss: 0.6076
Epoch 1/10, Batch 70/145, Loss: 0.5961
Epoch 1/10, Batch 80/145, Loss: 0.5117
Epoch 1/10, Batch 90/145, Loss: 0.4708
Epoch 1/10, Batch 100/145, Loss: 0.5597
Epoch 1/10, Batch 110/145, Loss: 0.3408
Epoch 1/10, Batch 120/145, Loss: 0.8049
Epoch 1/10, Batch 130/145, Loss: 0.3215
Epoch 1/10, Batch 140/145, Loss: 0.3514
Epoch 1/10, Train Loss: 0.6867, Valid Loss: 0.3632
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2308
Epoch 2/10, Batch 20/145, Loss: 0.5379
Epoch 2/10, Batch 30/145, Loss: 0.2860
Epoch 2/10, Batch 40/145, Loss: 0.6132
Epoch 2/10, Batch 50/145, Loss: 0.2663
Epoch 2/10, Batch 60/145, Loss: 0.4798
Epoch 2/10, Batch 70/145, Loss: 0.4027
Epoch 2/10, Batch 80/145, Loss: 0.3168
Epoch 2/10, Batch 90/145, Loss: 0.1601
Epoch 2/10, Batch 100/145, Loss: 0.3200
Epoch 2/10, Batch 110/145, Loss: 0.2016
Epoch 2/10, Batch 120/145, Loss: 0.4249
Epoch 2/10, Batch 130/145, Loss: 0.2717
Epoch 2/10, Batch 140/145, Loss: 0.2677
Epoch 2/10, Train Loss: 0.3644, Valid Loss: 0.2816
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2721
Epoch 3/10, Batch 20/145, Loss: 0.3929
Epoch 3/10, Batch 30/145, Loss: 0.1936
Epoch 3/10, Batch 40/145, Loss: 0.2629
Epoch 3/10, Batch 50/145, Loss: 0.2166
Epoch 3/10, Batch 60/145, Loss: 0.1923
Epoch 3/10, Batch 70/145, Loss: 0.2250
Epoch 3/10, Batch 80/145, Loss: 0.2691
Epoch 3/10, Batch 90/145, Loss: 0.3345
Epoch 3/10, Batch 100/145, Loss: 0.1710
Epoch 3/10, Batch 110/145, Loss: 0.3015
Epoch 3/10, Batch 120/145, Loss: 0.2851
Epoch 3/10, Batch 130/145, Loss: 0.2905
Epoch 3/10, Batch 140/145, Loss: 0.1697
Epoch 3/10, Train Loss: 0.3068, Valid Loss: 0.2496
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2370
Epoch 4/10, Batch 20/145, Loss: 0.3176
Epoch 4/10, Batch 30/145, Loss: 0.3461
Epoch 4/10, Batch 40/145, Loss: 0.3592
Epoch 4/10, Batch 50/145, Loss: 0.2219
Epoch 4/10, Batch 60/145, Loss: 0.2012
Epoch 4/10, Batch 70/145, Loss: 0.3327
Epoch 4/10, Batch 80/145, Loss: 0.3675
Epoch 4/10, Batch 90/145, Loss: 0.2415
Epoch 4/10, Batch 100/145, Loss: 0.1916
Epoch 4/10, Batch 110/145, Loss: 0.2472
Epoch 4/10, Batch 120/145, Loss: 0.1917
Epoch 4/10, Batch 130/145, Loss: 0.1809
Epoch 4/10, Batch 140/145, Loss: 0.1661
Epoch 4/10, Train Loss: 0.2687, Valid Loss: 0.2414
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1929
Epoch 5/10, Batch 20/145, Loss: 0.1749
Epoch 5/10, Batch 30/145, Loss: 0.1835
Epoch 5/10, Batch 40/145, Loss: 0.3500
Epoch 5/10, Batch 50/145, Loss: 0.1073
Epoch 5/10, Batch 60/145, Loss: 0.1615
Epoch 5/10, Batch 70/145, Loss: 0.1448
Epoch 5/10, Batch 80/145, Loss: 0.3037
Epoch 5/10, Batch 90/145, Loss: 0.2451
Epoch 5/10, Batch 100/145, Loss: 0.1992
Epoch 5/10, Batch 110/145, Loss: 0.1243
Epoch 5/10, Batch 120/145, Loss: 0.2434
Epoch 5/10, Batch 130/145, Loss: 0.2589
Epoch 5/10, Batch 140/145, Loss: 0.3439
Epoch 5/10, Train Loss: 0.2419, Valid Loss: 0.2277
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2903
Epoch 6/10, Batch 20/145, Loss: 0.2278
Epoch 6/10, Batch 30/145, Loss: 0.2255
Epoch 6/10, Batch 40/145, Loss: 0.2401
Epoch 6/10, Batch 50/145, Loss: 0.3197
Epoch 6/10, Batch 60/145, Loss: 0.2002
Epoch 6/10, Batch 70/145, Loss: 0.2202
Epoch 6/10, Batch 80/145, Loss: 0.2355
Epoch 6/10, Batch 90/145, Loss: 0.2207
Epoch 6/10, Batch 100/145, Loss: 0.1750
Epoch 6/10, Batch 110/145, Loss: 0.1284
Epoch 6/10, Batch 120/145, Loss: 0.3252
Epoch 6/10, Batch 130/145, Loss: 0.3236
Epoch 6/10, Batch 140/145, Loss: 0.1955
Epoch 6/10, Train Loss: 0.2335, Valid Loss: 0.2271
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1538
Epoch 7/10, Batch 20/145, Loss: 0.0965
Epoch 7/10, Batch 30/145, Loss: 0.2628
Epoch 7/10, Batch 40/145, Loss: 0.4900
Epoch 7/10, Batch 50/145, Loss: 0.1822
Epoch 7/10, Batch 60/145, Loss: 0.1116
Epoch 7/10, Batch 70/145, Loss: 0.2387
Epoch 7/10, Batch 80/145, Loss: 0.2175
Epoch 7/10, Batch 90/145, Loss: 0.1341
Epoch 7/10, Batch 100/145, Loss: 0.1521
Epoch 7/10, Batch 110/145, Loss: 0.2425
Epoch 7/10, Batch 120/145, Loss: 0.1477
Epoch 7/10, Batch 130/145, Loss: 0.2860
Epoch 7/10, Batch 140/145, Loss: 0.1007
Epoch 7/10, Train Loss: 0.2213, Valid Loss: 0.2179
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0931
Epoch 8/10, Batch 20/145, Loss: 0.1716
Epoch 8/10, Batch 30/145, Loss: 0.1211
Epoch 8/10, Batch 40/145, Loss: 0.1735
Epoch 8/10, Batch 50/145, Loss: 0.1226
Epoch 8/10, Batch 60/145, Loss: 0.2067
Epoch 8/10, Batch 70/145, Loss: 0.2241
Epoch 8/10, Batch 80/145, Loss: 0.2238
Epoch 8/10, Batch 90/145, Loss: 0.1822
Epoch 8/10, Batch 100/145, Loss: 0.2265
Epoch 8/10, Batch 110/145, Loss: 0.2057
Epoch 8/10, Batch 120/145, Loss: 0.2875
Epoch 8/10, Batch 130/145, Loss: 0.1175
Epoch 8/10, Batch 140/145, Loss: 0.2980
Epoch 8/10, Train Loss: 0.2097, Valid Loss: 0.2105
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.4134
Epoch 9/10, Batch 20/145, Loss: 0.1372
Epoch 9/10, Batch 30/145, Loss: 0.2339
Epoch 9/10, Batch 40/145, Loss: 0.1314
Epoch 9/10, Batch 50/145, Loss: 0.1224
Epoch 9/10, Batch 60/145, Loss: 0.1912
Epoch 9/10, Batch 70/145, Loss: 0.1364
Epoch 9/10, Batch 80/145, Loss: 0.1964
Epoch 9/10, Batch 90/145, Loss: 0.2313
Epoch 9/10, Batch 100/145, Loss: 0.1564
Epoch 9/10, Batch 110/145, Loss: 0.1119
Epoch 9/10, Batch 120/145, Loss: 0.1230
Epoch 9/10, Batch 130/145, Loss: 0.1920
Epoch 9/10, Batch 140/145, Loss: 0.0805
Epoch 9/10, Train Loss: 0.2071, Valid Loss: 0.2003
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0767
Epoch 10/10, Batch 20/145, Loss: 0.1484
Epoch 10/10, Batch 30/145, Loss: 0.4480
Epoch 10/10, Batch 40/145, Loss: 0.2778
Epoch 10/10, Batch 50/145, Loss: 0.1619
Epoch 10/10, Batch 60/145, Loss: 0.2074
Epoch 10/10, Batch 70/145, Loss: 0.1520
Epoch 10/10, Batch 80/145, Loss: 0.3671
Epoch 10/10, Batch 90/145, Loss: 0.1437
Epoch 10/10, Batch 100/145, Loss: 0.1074
Epoch 10/10, Batch 110/145, Loss: 0.1633
Epoch 10/10, Batch 120/145, Loss: 0.1713
Epoch 10/10, Batch 130/145, Loss: 0.3112
Epoch 10/10, Batch 140/145, Loss: 0.4834
Epoch 10/10, Train Loss: 0.2015, Valid Loss: 0.1966
Model saved!
Accuracy: 0.9276
Precision: 0.9259
Recall: 0.9276
F1-score: 0.9264
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4524
Epoch 1/10, Batch 20/145, Loss: 0.9434
Epoch 1/10, Batch 30/145, Loss: 0.8472
Epoch 1/10, Batch 40/145, Loss: 0.8920
Epoch 1/10, Batch 50/145, Loss: 0.6458
Epoch 1/10, Batch 60/145, Loss: 0.6384
Epoch 1/10, Batch 70/145, Loss: 0.6672
Epoch 1/10, Batch 80/145, Loss: 0.4667
Epoch 1/10, Batch 90/145, Loss: 0.4889
Epoch 1/10, Batch 100/145, Loss: 0.6623
Epoch 1/10, Batch 110/145, Loss: 0.4972
Epoch 1/10, Batch 120/145, Loss: 0.4850
Epoch 1/10, Batch 130/145, Loss: 0.3942
Epoch 1/10, Batch 140/145, Loss: 0.4937
Epoch 1/10, Train Loss: 0.6928, Valid Loss: 0.3768
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2829
Epoch 2/10, Batch 20/145, Loss: 0.4549
Epoch 2/10, Batch 30/145, Loss: 0.2663
Epoch 2/10, Batch 40/145, Loss: 0.5736
Epoch 2/10, Batch 50/145, Loss: 0.3809
Epoch 2/10, Batch 60/145, Loss: 0.4160
Epoch 2/10, Batch 70/145, Loss: 0.3487
Epoch 2/10, Batch 80/145, Loss: 0.3491
Epoch 2/10, Batch 90/145, Loss: 0.2237
Epoch 2/10, Batch 100/145, Loss: 0.3292
Epoch 2/10, Batch 110/145, Loss: 0.3831
Epoch 2/10, Batch 120/145, Loss: 0.4107
Epoch 2/10, Batch 130/145, Loss: 0.5311
Epoch 2/10, Batch 140/145, Loss: 0.3245
Epoch 2/10, Train Loss: 0.3584, Valid Loss: 0.2853
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2185
Epoch 3/10, Batch 20/145, Loss: 0.2349
Epoch 3/10, Batch 30/145, Loss: 0.2446
Epoch 3/10, Batch 40/145, Loss: 0.2685
Epoch 3/10, Batch 50/145, Loss: 0.2154
Epoch 3/10, Batch 60/145, Loss: 0.2534
Epoch 3/10, Batch 70/145, Loss: 0.3078
Epoch 3/10, Batch 80/145, Loss: 0.1649
Epoch 3/10, Batch 90/145, Loss: 0.4842
Epoch 3/10, Batch 100/145, Loss: 0.2581
Epoch 3/10, Batch 110/145, Loss: 0.1888
Epoch 3/10, Batch 120/145, Loss: 0.1960
Epoch 3/10, Batch 130/145, Loss: 0.2915
Epoch 3/10, Batch 140/145, Loss: 0.0708
Epoch 3/10, Train Loss: 0.3054, Valid Loss: 0.2528
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2443
Epoch 4/10, Batch 20/145, Loss: 0.2467
Epoch 4/10, Batch 30/145, Loss: 0.2899
Epoch 4/10, Batch 40/145, Loss: 0.2627
Epoch 4/10, Batch 50/145, Loss: 0.3978
Epoch 4/10, Batch 60/145, Loss: 0.1547
Epoch 4/10, Batch 70/145, Loss: 0.2320
Epoch 4/10, Batch 80/145, Loss: 0.3148
Epoch 4/10, Batch 90/145, Loss: 0.3583
Epoch 4/10, Batch 100/145, Loss: 0.2483
Epoch 4/10, Batch 110/145, Loss: 0.3664
Epoch 4/10, Batch 120/145, Loss: 0.2491
Epoch 4/10, Batch 130/145, Loss: 0.1746
Epoch 4/10, Batch 140/145, Loss: 0.4026
Epoch 4/10, Train Loss: 0.2685, Valid Loss: 0.2487
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2154
Epoch 5/10, Batch 20/145, Loss: 0.1944
Epoch 5/10, Batch 30/145, Loss: 0.1854
Epoch 5/10, Batch 40/145, Loss: 0.2357
Epoch 5/10, Batch 50/145, Loss: 0.1072
Epoch 5/10, Batch 60/145, Loss: 0.3231
Epoch 5/10, Batch 70/145, Loss: 0.2178
Epoch 5/10, Batch 80/145, Loss: 0.2513
Epoch 5/10, Batch 90/145, Loss: 0.1506
Epoch 5/10, Batch 100/145, Loss: 0.1288
Epoch 5/10, Batch 110/145, Loss: 0.1691
Epoch 5/10, Batch 120/145, Loss: 0.2814
Epoch 5/10, Batch 130/145, Loss: 0.1754
Epoch 5/10, Batch 140/145, Loss: 0.3041
Epoch 5/10, Train Loss: 0.2391, Valid Loss: 0.2341
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2498
Epoch 6/10, Batch 20/145, Loss: 0.2760
Epoch 6/10, Batch 30/145, Loss: 0.2520
Epoch 6/10, Batch 40/145, Loss: 0.1901
Epoch 6/10, Batch 50/145, Loss: 0.2285
Epoch 6/10, Batch 60/145, Loss: 0.1576
Epoch 6/10, Batch 70/145, Loss: 0.2904
Epoch 6/10, Batch 80/145, Loss: 0.4202
Epoch 6/10, Batch 90/145, Loss: 0.3055
Epoch 6/10, Batch 100/145, Loss: 0.1639
Epoch 6/10, Batch 110/145, Loss: 0.1519
Epoch 6/10, Batch 120/145, Loss: 0.2173
Epoch 6/10, Batch 130/145, Loss: 0.1193
Epoch 6/10, Batch 140/145, Loss: 0.2036
Epoch 6/10, Train Loss: 0.2283, Valid Loss: 0.2315
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2408
Epoch 7/10, Batch 20/145, Loss: 0.1462
Epoch 7/10, Batch 30/145, Loss: 0.0841
Epoch 7/10, Batch 40/145, Loss: 0.4150
Epoch 7/10, Batch 50/145, Loss: 0.2064
Epoch 7/10, Batch 60/145, Loss: 0.1549
Epoch 7/10, Batch 70/145, Loss: 0.5253
Epoch 7/10, Batch 80/145, Loss: 0.0786
Epoch 7/10, Batch 90/145, Loss: 0.2690
Epoch 7/10, Batch 100/145, Loss: 0.2491
Epoch 7/10, Batch 110/145, Loss: 0.2687
Epoch 7/10, Batch 120/145, Loss: 0.3367
Epoch 7/10, Batch 130/145, Loss: 0.2285
Epoch 7/10, Batch 140/145, Loss: 0.1198
Epoch 7/10, Train Loss: 0.2176, Valid Loss: 0.2201
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2597
Epoch 8/10, Batch 20/145, Loss: 0.2172
Epoch 8/10, Batch 30/145, Loss: 0.1108
Epoch 8/10, Batch 40/145, Loss: 0.1629
Epoch 8/10, Batch 50/145, Loss: 0.1164
Epoch 8/10, Batch 60/145, Loss: 0.2090
Epoch 8/10, Batch 70/145, Loss: 0.1236
Epoch 8/10, Batch 80/145, Loss: 0.2079
Epoch 8/10, Batch 90/145, Loss: 0.3349
Epoch 8/10, Batch 100/145, Loss: 0.2270
Epoch 8/10, Batch 110/145, Loss: 0.2518
Epoch 8/10, Batch 120/145, Loss: 0.1695
Epoch 8/10, Batch 130/145, Loss: 0.1569
Epoch 8/10, Batch 140/145, Loss: 0.2328
Epoch 8/10, Train Loss: 0.2124, Valid Loss: 0.2145
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2790
Epoch 9/10, Batch 20/145, Loss: 0.0837
Epoch 9/10, Batch 30/145, Loss: 0.1028
Epoch 9/10, Batch 40/145, Loss: 0.3277
Epoch 9/10, Batch 50/145, Loss: 0.2303
Epoch 9/10, Batch 60/145, Loss: 0.1548
Epoch 9/10, Batch 70/145, Loss: 0.2471
Epoch 9/10, Batch 80/145, Loss: 0.2327
Epoch 9/10, Batch 90/145, Loss: 0.1553
Epoch 9/10, Batch 100/145, Loss: 0.2791
Epoch 9/10, Batch 110/145, Loss: 0.1581
Epoch 9/10, Batch 120/145, Loss: 0.2943
Epoch 9/10, Batch 130/145, Loss: 0.2021
Epoch 9/10, Batch 140/145, Loss: 0.1554
Epoch 9/10, Train Loss: 0.2072, Valid Loss: 0.2104
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2182
Epoch 10/10, Batch 20/145, Loss: 0.1708
Epoch 10/10, Batch 30/145, Loss: 0.1197
Epoch 10/10, Batch 40/145, Loss: 0.1627
Epoch 10/10, Batch 50/145, Loss: 0.2675
Epoch 10/10, Batch 60/145, Loss: 0.0879
Epoch 10/10, Batch 70/145, Loss: 0.1122
Epoch 10/10, Batch 80/145, Loss: 0.3142
Epoch 10/10, Batch 90/145, Loss: 0.2272
Epoch 10/10, Batch 100/145, Loss: 0.0738
Epoch 10/10, Batch 110/145, Loss: 0.1794
Epoch 10/10, Batch 120/145, Loss: 0.2243
Epoch 10/10, Batch 130/145, Loss: 0.3669
Epoch 10/10, Batch 140/145, Loss: 0.0857
Epoch 10/10, Train Loss: 0.1965, Valid Loss: 0.2097
Model saved!
Accuracy: 0.9276
Precision: 0.9265
Recall: 0.9276
F1-score: 0.9270
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5129
Epoch 1/10, Batch 20/145, Loss: 0.9196
Epoch 1/10, Batch 30/145, Loss: 0.9629
Epoch 1/10, Batch 40/145, Loss: 0.9510
Epoch 1/10, Batch 50/145, Loss: 0.6492
Epoch 1/10, Batch 60/145, Loss: 0.7403
Epoch 1/10, Batch 70/145, Loss: 0.6171
Epoch 1/10, Batch 80/145, Loss: 0.5211
Epoch 1/10, Batch 90/145, Loss: 0.5006
Epoch 1/10, Batch 100/145, Loss: 0.6603
Epoch 1/10, Batch 110/145, Loss: 0.2986
Epoch 1/10, Batch 120/145, Loss: 0.6198
Epoch 1/10, Batch 130/145, Loss: 0.5300
Epoch 1/10, Batch 140/145, Loss: 0.5177
Epoch 1/10, Train Loss: 0.6899, Valid Loss: 0.3979
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4536
Epoch 2/10, Batch 20/145, Loss: 0.6980
Epoch 2/10, Batch 30/145, Loss: 0.2595
Epoch 2/10, Batch 40/145, Loss: 0.4458
Epoch 2/10, Batch 50/145, Loss: 0.3333
Epoch 2/10, Batch 60/145, Loss: 0.3881
Epoch 2/10, Batch 70/145, Loss: 0.3531
Epoch 2/10, Batch 80/145, Loss: 0.3570
Epoch 2/10, Batch 90/145, Loss: 0.2212
Epoch 2/10, Batch 100/145, Loss: 0.4806
Epoch 2/10, Batch 110/145, Loss: 0.3201
Epoch 2/10, Batch 120/145, Loss: 0.4119
Epoch 2/10, Batch 130/145, Loss: 0.3183
Epoch 2/10, Batch 140/145, Loss: 0.4613
Epoch 2/10, Train Loss: 0.3671, Valid Loss: 0.3048
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2598
Epoch 3/10, Batch 20/145, Loss: 0.3474
Epoch 3/10, Batch 30/145, Loss: 0.2204
Epoch 3/10, Batch 40/145, Loss: 0.3102
Epoch 3/10, Batch 50/145, Loss: 0.3339
Epoch 3/10, Batch 60/145, Loss: 0.2256
Epoch 3/10, Batch 70/145, Loss: 0.1394
Epoch 3/10, Batch 80/145, Loss: 0.2297
Epoch 3/10, Batch 90/145, Loss: 0.6282
Epoch 3/10, Batch 100/145, Loss: 0.3547
Epoch 3/10, Batch 110/145, Loss: 0.2069
Epoch 3/10, Batch 120/145, Loss: 0.1378
Epoch 3/10, Batch 130/145, Loss: 0.4370
Epoch 3/10, Batch 140/145, Loss: 0.2046
Epoch 3/10, Train Loss: 0.3120, Valid Loss: 0.2756
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2743
Epoch 4/10, Batch 20/145, Loss: 0.2778
Epoch 4/10, Batch 30/145, Loss: 0.2207
Epoch 4/10, Batch 40/145, Loss: 0.3673
Epoch 4/10, Batch 50/145, Loss: 0.1524
Epoch 4/10, Batch 60/145, Loss: 0.1413
Epoch 4/10, Batch 70/145, Loss: 0.2436
Epoch 4/10, Batch 80/145, Loss: 0.1981
Epoch 4/10, Batch 90/145, Loss: 0.2765
Epoch 4/10, Batch 100/145, Loss: 0.3690
Epoch 4/10, Batch 110/145, Loss: 0.3442
Epoch 4/10, Batch 120/145, Loss: 0.2471
Epoch 4/10, Batch 130/145, Loss: 0.1609
Epoch 4/10, Batch 140/145, Loss: 0.1344
Epoch 4/10, Train Loss: 0.2624, Valid Loss: 0.2618
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2593
Epoch 5/10, Batch 20/145, Loss: 0.2803
Epoch 5/10, Batch 30/145, Loss: 0.2209
Epoch 5/10, Batch 40/145, Loss: 0.2288
Epoch 5/10, Batch 50/145, Loss: 0.1288
Epoch 5/10, Batch 60/145, Loss: 0.1057
Epoch 5/10, Batch 70/145, Loss: 0.2920
Epoch 5/10, Batch 80/145, Loss: 0.2210
Epoch 5/10, Batch 90/145, Loss: 0.2117
Epoch 5/10, Batch 100/145, Loss: 0.1850
Epoch 5/10, Batch 110/145, Loss: 0.1968
Epoch 5/10, Batch 120/145, Loss: 0.1392
Epoch 5/10, Batch 130/145, Loss: 0.2614
Epoch 5/10, Batch 140/145, Loss: 0.2762
Epoch 5/10, Train Loss: 0.2458, Valid Loss: 0.2510
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1825
Epoch 6/10, Batch 20/145, Loss: 0.2145
Epoch 6/10, Batch 30/145, Loss: 0.2775
Epoch 6/10, Batch 40/145, Loss: 0.1287
Epoch 6/10, Batch 50/145, Loss: 0.1616
Epoch 6/10, Batch 60/145, Loss: 0.0871
Epoch 6/10, Batch 70/145, Loss: 0.3469
Epoch 6/10, Batch 80/145, Loss: 0.1920
Epoch 6/10, Batch 90/145, Loss: 0.2417
Epoch 6/10, Batch 100/145, Loss: 0.1707
Epoch 6/10, Batch 110/145, Loss: 0.1318
Epoch 6/10, Batch 120/145, Loss: 0.2008
Epoch 6/10, Batch 130/145, Loss: 0.1273
Epoch 6/10, Batch 140/145, Loss: 0.2103
Epoch 6/10, Train Loss: 0.2336, Valid Loss: 0.2519
Epoch 7/10, Batch 10/145, Loss: 0.2074
Epoch 7/10, Batch 20/145, Loss: 0.3217
Epoch 7/10, Batch 30/145, Loss: 0.1388
Epoch 7/10, Batch 40/145, Loss: 0.4855
Epoch 7/10, Batch 50/145, Loss: 0.0921
Epoch 7/10, Batch 60/145, Loss: 0.2017
Epoch 7/10, Batch 70/145, Loss: 0.2237
Epoch 7/10, Batch 80/145, Loss: 0.1787
Epoch 7/10, Batch 90/145, Loss: 0.2157
Epoch 7/10, Batch 100/145, Loss: 0.1995
Epoch 7/10, Batch 110/145, Loss: 0.4442
Epoch 7/10, Batch 120/145, Loss: 0.0884
Epoch 7/10, Batch 130/145, Loss: 0.3654
Epoch 7/10, Batch 140/145, Loss: 0.1406
Epoch 7/10, Train Loss: 0.2193, Valid Loss: 0.2397
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2362
Epoch 8/10, Batch 20/145, Loss: 0.1786
Epoch 8/10, Batch 30/145, Loss: 0.1592
Epoch 8/10, Batch 40/145, Loss: 0.2937
Epoch 8/10, Batch 50/145, Loss: 0.1539
Epoch 8/10, Batch 60/145, Loss: 0.1269
Epoch 8/10, Batch 70/145, Loss: 0.0878
Epoch 8/10, Batch 80/145, Loss: 0.4082
Epoch 8/10, Batch 90/145, Loss: 0.2619
Epoch 8/10, Batch 100/145, Loss: 0.3519
Epoch 8/10, Batch 110/145, Loss: 0.1890
Epoch 8/10, Batch 120/145, Loss: 0.2350
Epoch 8/10, Batch 130/145, Loss: 0.1223
Epoch 8/10, Batch 140/145, Loss: 0.1722
Epoch 8/10, Train Loss: 0.2134, Valid Loss: 0.2377
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2097
Epoch 9/10, Batch 20/145, Loss: 0.1060
Epoch 9/10, Batch 30/145, Loss: 0.2123
Epoch 9/10, Batch 40/145, Loss: 0.1765
Epoch 9/10, Batch 50/145, Loss: 0.1530
Epoch 9/10, Batch 60/145, Loss: 0.1615
Epoch 9/10, Batch 70/145, Loss: 0.0829
Epoch 9/10, Batch 80/145, Loss: 0.2589
Epoch 9/10, Batch 90/145, Loss: 0.2018
Epoch 9/10, Batch 100/145, Loss: 0.1494
Epoch 9/10, Batch 110/145, Loss: 0.0946
Epoch 9/10, Batch 120/145, Loss: 0.1340
Epoch 9/10, Batch 130/145, Loss: 0.2224
Epoch 9/10, Batch 140/145, Loss: 0.1129
Epoch 9/10, Train Loss: 0.2005, Valid Loss: 0.2257
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0918
Epoch 10/10, Batch 20/145, Loss: 0.1998
Epoch 10/10, Batch 30/145, Loss: 0.1229
Epoch 10/10, Batch 40/145, Loss: 0.2134
Epoch 10/10, Batch 50/145, Loss: 0.2042
Epoch 10/10, Batch 60/145, Loss: 0.2636
Epoch 10/10, Batch 70/145, Loss: 0.1834
Epoch 10/10, Batch 80/145, Loss: 0.3980
Epoch 10/10, Batch 90/145, Loss: 0.1699
Epoch 10/10, Batch 100/145, Loss: 0.2634
Epoch 10/10, Batch 110/145, Loss: 0.2378
Epoch 10/10, Batch 120/145, Loss: 0.1586
Epoch 10/10, Batch 130/145, Loss: 0.1414
Epoch 10/10, Batch 140/145, Loss: 0.1770
Epoch 10/10, Train Loss: 0.1997, Valid Loss: 0.2265
Accuracy: 0.9159
Precision: 0.9143
Recall: 0.9159
F1-score: 0.9145
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4868
Epoch 1/10, Batch 20/145, Loss: 0.8880
Epoch 1/10, Batch 30/145, Loss: 0.9043
Epoch 1/10, Batch 40/145, Loss: 0.8690
Epoch 1/10, Batch 50/145, Loss: 0.5943
Epoch 1/10, Batch 60/145, Loss: 0.5079
Epoch 1/10, Batch 70/145, Loss: 0.6637
Epoch 1/10, Batch 80/145, Loss: 0.4777
Epoch 1/10, Batch 90/145, Loss: 0.5858
Epoch 1/10, Batch 100/145, Loss: 0.6204
Epoch 1/10, Batch 110/145, Loss: 0.3981
Epoch 1/10, Batch 120/145, Loss: 0.6198
Epoch 1/10, Batch 130/145, Loss: 0.3605
Epoch 1/10, Batch 140/145, Loss: 0.3901
Epoch 1/10, Train Loss: 0.6943, Valid Loss: 0.3865
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3341
Epoch 2/10, Batch 20/145, Loss: 0.4389
Epoch 2/10, Batch 30/145, Loss: 0.4008
Epoch 2/10, Batch 40/145, Loss: 0.5771
Epoch 2/10, Batch 50/145, Loss: 0.4167
Epoch 2/10, Batch 60/145, Loss: 0.3498
Epoch 2/10, Batch 70/145, Loss: 0.5403
Epoch 2/10, Batch 80/145, Loss: 0.3527
Epoch 2/10, Batch 90/145, Loss: 0.5006
Epoch 2/10, Batch 100/145, Loss: 0.3822
Epoch 2/10, Batch 110/145, Loss: 0.2905
Epoch 2/10, Batch 120/145, Loss: 0.3500
Epoch 2/10, Batch 130/145, Loss: 0.3130
Epoch 2/10, Batch 140/145, Loss: 0.3616
Epoch 2/10, Train Loss: 0.3683, Valid Loss: 0.2964
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3755
Epoch 3/10, Batch 20/145, Loss: 0.2449
Epoch 3/10, Batch 30/145, Loss: 0.3278
Epoch 3/10, Batch 40/145, Loss: 0.2759
Epoch 3/10, Batch 50/145, Loss: 0.2616
Epoch 3/10, Batch 60/145, Loss: 0.3057
Epoch 3/10, Batch 70/145, Loss: 0.2120
Epoch 3/10, Batch 80/145, Loss: 0.1302
Epoch 3/10, Batch 90/145, Loss: 0.5408
Epoch 3/10, Batch 100/145, Loss: 0.2749
Epoch 3/10, Batch 110/145, Loss: 0.2374
Epoch 3/10, Batch 120/145, Loss: 0.2096
Epoch 3/10, Batch 130/145, Loss: 0.2012
Epoch 3/10, Batch 140/145, Loss: 0.2764
Epoch 3/10, Train Loss: 0.3067, Valid Loss: 0.2714
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1619
Epoch 4/10, Batch 20/145, Loss: 0.2741
Epoch 4/10, Batch 30/145, Loss: 0.2226
Epoch 4/10, Batch 40/145, Loss: 0.3576
Epoch 4/10, Batch 50/145, Loss: 0.2687
Epoch 4/10, Batch 60/145, Loss: 0.2224
Epoch 4/10, Batch 70/145, Loss: 0.2120
Epoch 4/10, Batch 80/145, Loss: 0.2893
Epoch 4/10, Batch 90/145, Loss: 0.2658
Epoch 4/10, Batch 100/145, Loss: 0.1731
Epoch 4/10, Batch 110/145, Loss: 0.2078
Epoch 4/10, Batch 120/145, Loss: 0.1366
Epoch 4/10, Batch 130/145, Loss: 0.2028
Epoch 4/10, Batch 140/145, Loss: 0.3189
Epoch 4/10, Train Loss: 0.2638, Valid Loss: 0.2484
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2150
Epoch 5/10, Batch 20/145, Loss: 0.3306
Epoch 5/10, Batch 30/145, Loss: 0.2559
Epoch 5/10, Batch 40/145, Loss: 0.2373
Epoch 5/10, Batch 50/145, Loss: 0.2393
Epoch 5/10, Batch 60/145, Loss: 0.1979
Epoch 5/10, Batch 70/145, Loss: 0.2631
Epoch 5/10, Batch 80/145, Loss: 0.2211
Epoch 5/10, Batch 90/145, Loss: 0.2591
Epoch 5/10, Batch 100/145, Loss: 0.1633
Epoch 5/10, Batch 110/145, Loss: 0.2339
Epoch 5/10, Batch 120/145, Loss: 0.1618
Epoch 5/10, Batch 130/145, Loss: 0.2513
Epoch 5/10, Batch 140/145, Loss: 0.1466
Epoch 5/10, Train Loss: 0.2445, Valid Loss: 0.2439
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1634
Epoch 6/10, Batch 20/145, Loss: 0.4386
Epoch 6/10, Batch 30/145, Loss: 0.2478
Epoch 6/10, Batch 40/145, Loss: 0.1852
Epoch 6/10, Batch 50/145, Loss: 0.2446
Epoch 6/10, Batch 60/145, Loss: 0.1886
Epoch 6/10, Batch 70/145, Loss: 0.2785
Epoch 6/10, Batch 80/145, Loss: 0.3898
Epoch 6/10, Batch 90/145, Loss: 0.2451
Epoch 6/10, Batch 100/145, Loss: 0.1771
Epoch 6/10, Batch 110/145, Loss: 0.1438
Epoch 6/10, Batch 120/145, Loss: 0.1808
Epoch 6/10, Batch 130/145, Loss: 0.0814
Epoch 6/10, Batch 140/145, Loss: 0.1822
Epoch 6/10, Train Loss: 0.2269, Valid Loss: 0.2299
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2935
Epoch 7/10, Batch 20/145, Loss: 0.1703
Epoch 7/10, Batch 30/145, Loss: 0.1918
Epoch 7/10, Batch 40/145, Loss: 0.4926
Epoch 7/10, Batch 50/145, Loss: 0.1932
Epoch 7/10, Batch 60/145, Loss: 0.3002
Epoch 7/10, Batch 70/145, Loss: 0.2019
Epoch 7/10, Batch 80/145, Loss: 0.2001
Epoch 7/10, Batch 90/145, Loss: 0.2463
Epoch 7/10, Batch 100/145, Loss: 0.2140
Epoch 7/10, Batch 110/145, Loss: 0.1186
Epoch 7/10, Batch 120/145, Loss: 0.1979
Epoch 7/10, Batch 130/145, Loss: 0.1920
Epoch 7/10, Batch 140/145, Loss: 0.2217
Epoch 7/10, Train Loss: 0.2209, Valid Loss: 0.2251
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1247
Epoch 8/10, Batch 20/145, Loss: 0.2117
Epoch 8/10, Batch 30/145, Loss: 0.2604
Epoch 8/10, Batch 40/145, Loss: 0.4040
Epoch 8/10, Batch 50/145, Loss: 0.2739
Epoch 8/10, Batch 60/145, Loss: 0.1483
Epoch 8/10, Batch 70/145, Loss: 0.2895
Epoch 8/10, Batch 80/145, Loss: 0.3110
Epoch 8/10, Batch 90/145, Loss: 0.1145
Epoch 8/10, Batch 100/145, Loss: 0.4968
Epoch 8/10, Batch 110/145, Loss: 0.2933
Epoch 8/10, Batch 120/145, Loss: 0.2023
Epoch 8/10, Batch 130/145, Loss: 0.2070
Epoch 8/10, Batch 140/145, Loss: 0.2798
Epoch 8/10, Train Loss: 0.2097, Valid Loss: 0.2172
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2414
Epoch 9/10, Batch 20/145, Loss: 0.1615
Epoch 9/10, Batch 30/145, Loss: 0.0568
Epoch 9/10, Batch 40/145, Loss: 0.1404
Epoch 9/10, Batch 50/145, Loss: 0.1402
Epoch 9/10, Batch 60/145, Loss: 0.1476
Epoch 9/10, Batch 70/145, Loss: 0.1059
Epoch 9/10, Batch 80/145, Loss: 0.1134
Epoch 9/10, Batch 90/145, Loss: 0.1683
Epoch 9/10, Batch 100/145, Loss: 0.2256
Epoch 9/10, Batch 110/145, Loss: 0.0804
Epoch 9/10, Batch 120/145, Loss: 0.1268
Epoch 9/10, Batch 130/145, Loss: 0.2204
Epoch 9/10, Batch 140/145, Loss: 0.1107
Epoch 9/10, Train Loss: 0.2000, Valid Loss: 0.2091
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1487
Epoch 10/10, Batch 20/145, Loss: 0.2035
Epoch 10/10, Batch 30/145, Loss: 0.1172
Epoch 10/10, Batch 40/145, Loss: 0.1510
Epoch 10/10, Batch 50/145, Loss: 0.1737
Epoch 10/10, Batch 60/145, Loss: 0.1889
Epoch 10/10, Batch 70/145, Loss: 0.1300
Epoch 10/10, Batch 80/145, Loss: 0.3282
Epoch 10/10, Batch 90/145, Loss: 0.1912
Epoch 10/10, Batch 100/145, Loss: 0.1738
Epoch 10/10, Batch 110/145, Loss: 0.1766
Epoch 10/10, Batch 120/145, Loss: 0.2145
Epoch 10/10, Batch 130/145, Loss: 0.2874
Epoch 10/10, Batch 140/145, Loss: 0.1931
Epoch 10/10, Train Loss: 0.1964, Valid Loss: 0.2083
Model saved!
Accuracy: 0.9264
Precision: 0.9258
Recall: 0.9264
F1-score: 0.9259
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5503
Epoch 1/10, Batch 20/145, Loss: 0.9048
Epoch 1/10, Batch 30/145, Loss: 0.9696
Epoch 1/10, Batch 40/145, Loss: 0.7350
Epoch 1/10, Batch 50/145, Loss: 0.6096
Epoch 1/10, Batch 60/145, Loss: 0.6546
Epoch 1/10, Batch 70/145, Loss: 0.5846
Epoch 1/10, Batch 80/145, Loss: 0.4704
Epoch 1/10, Batch 90/145, Loss: 0.4972
Epoch 1/10, Batch 100/145, Loss: 0.5420
Epoch 1/10, Batch 110/145, Loss: 0.5526
Epoch 1/10, Batch 120/145, Loss: 0.4979
Epoch 1/10, Batch 130/145, Loss: 0.4897
Epoch 1/10, Batch 140/145, Loss: 0.3161
Epoch 1/10, Train Loss: 0.6893, Valid Loss: 0.3874
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2294
Epoch 2/10, Batch 20/145, Loss: 0.4370
Epoch 2/10, Batch 30/145, Loss: 0.3064
Epoch 2/10, Batch 40/145, Loss: 0.5326
Epoch 2/10, Batch 50/145, Loss: 0.2479
Epoch 2/10, Batch 60/145, Loss: 0.3817
Epoch 2/10, Batch 70/145, Loss: 0.3414
Epoch 2/10, Batch 80/145, Loss: 0.4456
Epoch 2/10, Batch 90/145, Loss: 0.2187
Epoch 2/10, Batch 100/145, Loss: 0.2928
Epoch 2/10, Batch 110/145, Loss: 0.2605
Epoch 2/10, Batch 120/145, Loss: 0.3593
Epoch 2/10, Batch 130/145, Loss: 0.3481
Epoch 2/10, Batch 140/145, Loss: 0.3963
Epoch 2/10, Train Loss: 0.3610, Valid Loss: 0.3039
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3089
Epoch 3/10, Batch 20/145, Loss: 0.2026
Epoch 3/10, Batch 30/145, Loss: 0.3397
Epoch 3/10, Batch 40/145, Loss: 0.3357
Epoch 3/10, Batch 50/145, Loss: 0.3190
Epoch 3/10, Batch 60/145, Loss: 0.4465
Epoch 3/10, Batch 70/145, Loss: 0.3901
Epoch 3/10, Batch 80/145, Loss: 0.1434
Epoch 3/10, Batch 90/145, Loss: 0.6594
Epoch 3/10, Batch 100/145, Loss: 0.5299
Epoch 3/10, Batch 110/145, Loss: 0.2080
Epoch 3/10, Batch 120/145, Loss: 0.1661
Epoch 3/10, Batch 130/145, Loss: 0.3280
Epoch 3/10, Batch 140/145, Loss: 0.1554
Epoch 3/10, Train Loss: 0.3053, Valid Loss: 0.2761
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3196
Epoch 4/10, Batch 20/145, Loss: 0.2899
Epoch 4/10, Batch 30/145, Loss: 0.2251
Epoch 4/10, Batch 40/145, Loss: 0.2142
Epoch 4/10, Batch 50/145, Loss: 0.1606
Epoch 4/10, Batch 60/145, Loss: 0.1950
Epoch 4/10, Batch 70/145, Loss: 0.3315
Epoch 4/10, Batch 80/145, Loss: 0.4317
Epoch 4/10, Batch 90/145, Loss: 0.1699
Epoch 4/10, Batch 100/145, Loss: 0.1813
Epoch 4/10, Batch 110/145, Loss: 0.1765
Epoch 4/10, Batch 120/145, Loss: 0.3128
Epoch 4/10, Batch 130/145, Loss: 0.2689
Epoch 4/10, Batch 140/145, Loss: 0.1898
Epoch 4/10, Train Loss: 0.2644, Valid Loss: 0.2578
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3500
Epoch 5/10, Batch 20/145, Loss: 0.1489
Epoch 5/10, Batch 30/145, Loss: 0.1564
Epoch 5/10, Batch 40/145, Loss: 0.2541
Epoch 5/10, Batch 50/145, Loss: 0.1199
Epoch 5/10, Batch 60/145, Loss: 0.2421
Epoch 5/10, Batch 70/145, Loss: 0.2404
Epoch 5/10, Batch 80/145, Loss: 0.4261
Epoch 5/10, Batch 90/145, Loss: 0.1021
Epoch 5/10, Batch 100/145, Loss: 0.2635
Epoch 5/10, Batch 110/145, Loss: 0.1274
Epoch 5/10, Batch 120/145, Loss: 0.2471
Epoch 5/10, Batch 130/145, Loss: 0.1572
Epoch 5/10, Batch 140/145, Loss: 0.2226
Epoch 5/10, Train Loss: 0.2365, Valid Loss: 0.2444
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1911
Epoch 6/10, Batch 20/145, Loss: 0.2601
Epoch 6/10, Batch 30/145, Loss: 0.1939
Epoch 6/10, Batch 40/145, Loss: 0.1723
Epoch 6/10, Batch 50/145, Loss: 0.2411
Epoch 6/10, Batch 60/145, Loss: 0.1075
Epoch 6/10, Batch 70/145, Loss: 0.2564
Epoch 6/10, Batch 80/145, Loss: 0.3122
Epoch 6/10, Batch 90/145, Loss: 0.3370
Epoch 6/10, Batch 100/145, Loss: 0.4162
Epoch 6/10, Batch 110/145, Loss: 0.1720
Epoch 6/10, Batch 120/145, Loss: 0.3222
Epoch 6/10, Batch 130/145, Loss: 0.2127
Epoch 6/10, Batch 140/145, Loss: 0.1621
Epoch 6/10, Train Loss: 0.2273, Valid Loss: 0.2479
Epoch 7/10, Batch 10/145, Loss: 0.3755
Epoch 7/10, Batch 20/145, Loss: 0.1755
Epoch 7/10, Batch 30/145, Loss: 0.2081
Epoch 7/10, Batch 40/145, Loss: 0.3596
Epoch 7/10, Batch 50/145, Loss: 0.2200
Epoch 7/10, Batch 60/145, Loss: 0.1658
Epoch 7/10, Batch 70/145, Loss: 0.1162
Epoch 7/10, Batch 80/145, Loss: 0.1640
Epoch 7/10, Batch 90/145, Loss: 0.2604
Epoch 7/10, Batch 100/145, Loss: 0.1293
Epoch 7/10, Batch 110/145, Loss: 0.1879
Epoch 7/10, Batch 120/145, Loss: 0.1907
Epoch 7/10, Batch 130/145, Loss: 0.2322
Epoch 7/10, Batch 140/145, Loss: 0.1314
Epoch 7/10, Train Loss: 0.2194, Valid Loss: 0.2443
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1251
Epoch 8/10, Batch 20/145, Loss: 0.1671
Epoch 8/10, Batch 30/145, Loss: 0.2390
Epoch 8/10, Batch 40/145, Loss: 0.2079
Epoch 8/10, Batch 50/145, Loss: 0.2477
Epoch 8/10, Batch 60/145, Loss: 0.1313
Epoch 8/10, Batch 70/145, Loss: 0.0590
Epoch 8/10, Batch 80/145, Loss: 0.3296
Epoch 8/10, Batch 90/145, Loss: 0.2706
Epoch 8/10, Batch 100/145, Loss: 0.3945
Epoch 8/10, Batch 110/145, Loss: 0.1894
Epoch 8/10, Batch 120/145, Loss: 0.2042
Epoch 8/10, Batch 130/145, Loss: 0.2052
Epoch 8/10, Batch 140/145, Loss: 0.2135
Epoch 8/10, Train Loss: 0.2093, Valid Loss: 0.2319
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1515
Epoch 9/10, Batch 20/145, Loss: 0.2244
Epoch 9/10, Batch 30/145, Loss: 0.1009
Epoch 9/10, Batch 40/145, Loss: 0.4386
Epoch 9/10, Batch 50/145, Loss: 0.2216
Epoch 9/10, Batch 60/145, Loss: 0.2218
Epoch 9/10, Batch 70/145, Loss: 0.1067
Epoch 9/10, Batch 80/145, Loss: 0.3371
Epoch 9/10, Batch 90/145, Loss: 0.2181
Epoch 9/10, Batch 100/145, Loss: 0.2110
Epoch 9/10, Batch 110/145, Loss: 0.2330
Epoch 9/10, Batch 120/145, Loss: 0.2398
Epoch 9/10, Batch 130/145, Loss: 0.3719
Epoch 9/10, Batch 140/145, Loss: 0.1502
Epoch 9/10, Train Loss: 0.2115, Valid Loss: 0.2333
Epoch 10/10, Batch 10/145, Loss: 0.2556
Epoch 10/10, Batch 20/145, Loss: 0.1707
Epoch 10/10, Batch 30/145, Loss: 0.1505
Epoch 10/10, Batch 40/145, Loss: 0.2581
Epoch 10/10, Batch 50/145, Loss: 0.3375
Epoch 10/10, Batch 60/145, Loss: 0.1118
Epoch 10/10, Batch 70/145, Loss: 0.0916
Epoch 10/10, Batch 80/145, Loss: 0.3718
Epoch 10/10, Batch 90/145, Loss: 0.1668
Epoch 10/10, Batch 100/145, Loss: 0.0731
Epoch 10/10, Batch 110/145, Loss: 0.1562
Epoch 10/10, Batch 120/145, Loss: 0.2640
Epoch 10/10, Batch 130/145, Loss: 0.1207
Epoch 10/10, Batch 140/145, Loss: 0.1188
Epoch 10/10, Train Loss: 0.1931, Valid Loss: 0.2227
Model saved!
Accuracy: 0.9252
Precision: 0.9231
Recall: 0.9252
F1-score: 0.9238
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4488
Epoch 1/10, Batch 20/145, Loss: 0.9144
Epoch 1/10, Batch 30/145, Loss: 0.8422
Epoch 1/10, Batch 40/145, Loss: 0.8125
Epoch 1/10, Batch 50/145, Loss: 0.6026
Epoch 1/10, Batch 60/145, Loss: 0.6158
Epoch 1/10, Batch 70/145, Loss: 0.5958
Epoch 1/10, Batch 80/145, Loss: 0.5631
Epoch 1/10, Batch 90/145, Loss: 0.6084
Epoch 1/10, Batch 100/145, Loss: 0.6536
Epoch 1/10, Batch 110/145, Loss: 0.3530
Epoch 1/10, Batch 120/145, Loss: 0.6411
Epoch 1/10, Batch 130/145, Loss: 0.2898
Epoch 1/10, Batch 140/145, Loss: 0.4923
Epoch 1/10, Train Loss: 0.6902, Valid Loss: 0.3960
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3487
Epoch 2/10, Batch 20/145, Loss: 0.4928
Epoch 2/10, Batch 30/145, Loss: 0.2588
Epoch 2/10, Batch 40/145, Loss: 0.4661
Epoch 2/10, Batch 50/145, Loss: 0.2775
Epoch 2/10, Batch 60/145, Loss: 0.3365
Epoch 2/10, Batch 70/145, Loss: 0.4888
Epoch 2/10, Batch 80/145, Loss: 0.3126
Epoch 2/10, Batch 90/145, Loss: 0.3705
Epoch 2/10, Batch 100/145, Loss: 0.2302
Epoch 2/10, Batch 110/145, Loss: 0.3370
Epoch 2/10, Batch 120/145, Loss: 0.2973
Epoch 2/10, Batch 130/145, Loss: 0.3235
Epoch 2/10, Batch 140/145, Loss: 0.2114
Epoch 2/10, Train Loss: 0.3662, Valid Loss: 0.3001
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2630
Epoch 3/10, Batch 20/145, Loss: 0.1615
Epoch 3/10, Batch 30/145, Loss: 0.1924
Epoch 3/10, Batch 40/145, Loss: 0.3152
Epoch 3/10, Batch 50/145, Loss: 0.1894
Epoch 3/10, Batch 60/145, Loss: 0.2456
Epoch 3/10, Batch 70/145, Loss: 0.3095
Epoch 3/10, Batch 80/145, Loss: 0.4070
Epoch 3/10, Batch 90/145, Loss: 0.5330
Epoch 3/10, Batch 100/145, Loss: 0.3147
Epoch 3/10, Batch 110/145, Loss: 0.3091
Epoch 3/10, Batch 120/145, Loss: 0.2929
Epoch 3/10, Batch 130/145, Loss: 0.3883
Epoch 3/10, Batch 140/145, Loss: 0.1693
Epoch 3/10, Train Loss: 0.3052, Valid Loss: 0.2742
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1965
Epoch 4/10, Batch 20/145, Loss: 0.3627
Epoch 4/10, Batch 30/145, Loss: 0.2512
Epoch 4/10, Batch 40/145, Loss: 0.3123
Epoch 4/10, Batch 50/145, Loss: 0.2015
Epoch 4/10, Batch 60/145, Loss: 0.2773
Epoch 4/10, Batch 70/145, Loss: 0.1957
Epoch 4/10, Batch 80/145, Loss: 0.3190
Epoch 4/10, Batch 90/145, Loss: 0.2971
Epoch 4/10, Batch 100/145, Loss: 0.3192
Epoch 4/10, Batch 110/145, Loss: 0.1609
Epoch 4/10, Batch 120/145, Loss: 0.2376
Epoch 4/10, Batch 130/145, Loss: 0.2525
Epoch 4/10, Batch 140/145, Loss: 0.1176
Epoch 4/10, Train Loss: 0.2693, Valid Loss: 0.2677
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2150
Epoch 5/10, Batch 20/145, Loss: 0.2939
Epoch 5/10, Batch 30/145, Loss: 0.2493
Epoch 5/10, Batch 40/145, Loss: 0.2208
Epoch 5/10, Batch 50/145, Loss: 0.1061
Epoch 5/10, Batch 60/145, Loss: 0.0835
Epoch 5/10, Batch 70/145, Loss: 0.3110
Epoch 5/10, Batch 80/145, Loss: 0.2859
Epoch 5/10, Batch 90/145, Loss: 0.3100
Epoch 5/10, Batch 100/145, Loss: 0.1545
Epoch 5/10, Batch 110/145, Loss: 0.0807
Epoch 5/10, Batch 120/145, Loss: 0.3226
Epoch 5/10, Batch 130/145, Loss: 0.0864
Epoch 5/10, Batch 140/145, Loss: 0.2124
Epoch 5/10, Train Loss: 0.2422, Valid Loss: 0.2433
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1071
Epoch 6/10, Batch 20/145, Loss: 0.4096
Epoch 6/10, Batch 30/145, Loss: 0.1973
Epoch 6/10, Batch 40/145, Loss: 0.0850
Epoch 6/10, Batch 50/145, Loss: 0.2721
Epoch 6/10, Batch 60/145, Loss: 0.1220
Epoch 6/10, Batch 70/145, Loss: 0.2549
Epoch 6/10, Batch 80/145, Loss: 0.2578
Epoch 6/10, Batch 90/145, Loss: 0.2682
Epoch 6/10, Batch 100/145, Loss: 0.3326
Epoch 6/10, Batch 110/145, Loss: 0.1898
Epoch 6/10, Batch 120/145, Loss: 0.3029
Epoch 6/10, Batch 130/145, Loss: 0.2459
Epoch 6/10, Batch 140/145, Loss: 0.1639
Epoch 6/10, Train Loss: 0.2326, Valid Loss: 0.2379
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3261
Epoch 7/10, Batch 20/145, Loss: 0.3392
Epoch 7/10, Batch 30/145, Loss: 0.1250
Epoch 7/10, Batch 40/145, Loss: 0.2907
Epoch 7/10, Batch 50/145, Loss: 0.3799
Epoch 7/10, Batch 60/145, Loss: 0.1589
Epoch 7/10, Batch 70/145, Loss: 0.1837
Epoch 7/10, Batch 80/145, Loss: 0.0902
Epoch 7/10, Batch 90/145, Loss: 0.1915
Epoch 7/10, Batch 100/145, Loss: 0.2404
Epoch 7/10, Batch 110/145, Loss: 0.2271
Epoch 7/10, Batch 120/145, Loss: 0.1844
Epoch 7/10, Batch 130/145, Loss: 0.3127
Epoch 7/10, Batch 140/145, Loss: 0.2452
Epoch 7/10, Train Loss: 0.2191, Valid Loss: 0.2274
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1413
Epoch 8/10, Batch 20/145, Loss: 0.1570
Epoch 8/10, Batch 30/145, Loss: 0.2201
Epoch 8/10, Batch 40/145, Loss: 0.3168
Epoch 8/10, Batch 50/145, Loss: 0.1915
Epoch 8/10, Batch 60/145, Loss: 0.2608
Epoch 8/10, Batch 70/145, Loss: 0.1912
Epoch 8/10, Batch 80/145, Loss: 0.1457
Epoch 8/10, Batch 90/145, Loss: 0.1159
Epoch 8/10, Batch 100/145, Loss: 0.2211
Epoch 8/10, Batch 110/145, Loss: 0.1741
Epoch 8/10, Batch 120/145, Loss: 0.0971
Epoch 8/10, Batch 130/145, Loss: 0.1121
Epoch 8/10, Batch 140/145, Loss: 0.2380
Epoch 8/10, Train Loss: 0.2143, Valid Loss: 0.2209
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1189
Epoch 9/10, Batch 20/145, Loss: 0.2293
Epoch 9/10, Batch 30/145, Loss: 0.1523
Epoch 9/10, Batch 40/145, Loss: 0.1160
Epoch 9/10, Batch 50/145, Loss: 0.1064
Epoch 9/10, Batch 60/145, Loss: 0.1195
Epoch 9/10, Batch 70/145, Loss: 0.3152
Epoch 9/10, Batch 80/145, Loss: 0.2501
Epoch 9/10, Batch 90/145, Loss: 0.1094
Epoch 9/10, Batch 100/145, Loss: 0.2783
Epoch 9/10, Batch 110/145, Loss: 0.0590
Epoch 9/10, Batch 120/145, Loss: 0.3618
Epoch 9/10, Batch 130/145, Loss: 0.1428
Epoch 9/10, Batch 140/145, Loss: 0.0807
Epoch 9/10, Train Loss: 0.2044, Valid Loss: 0.2179
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1589
Epoch 10/10, Batch 20/145, Loss: 0.1380
Epoch 10/10, Batch 30/145, Loss: 0.0705
Epoch 10/10, Batch 40/145, Loss: 0.0897
Epoch 10/10, Batch 50/145, Loss: 0.1761
Epoch 10/10, Batch 60/145, Loss: 0.2561
Epoch 10/10, Batch 70/145, Loss: 0.2484
Epoch 10/10, Batch 80/145, Loss: 0.2992
Epoch 10/10, Batch 90/145, Loss: 0.1168
Epoch 10/10, Batch 100/145, Loss: 0.0668
Epoch 10/10, Batch 110/145, Loss: 0.3564
Epoch 10/10, Batch 120/145, Loss: 0.1435
Epoch 10/10, Batch 130/145, Loss: 0.2220
Epoch 10/10, Batch 140/145, Loss: 0.3088
Epoch 10/10, Train Loss: 0.1973, Valid Loss: 0.2175
Model saved!
Accuracy: 0.9241
Precision: 0.9228
Recall: 0.9241
F1-score: 0.9231
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3872
Epoch 1/10, Batch 20/145, Loss: 0.8715
Epoch 1/10, Batch 30/145, Loss: 0.8541
Epoch 1/10, Batch 40/145, Loss: 0.8931
Epoch 1/10, Batch 50/145, Loss: 0.5603
Epoch 1/10, Batch 60/145, Loss: 0.6228
Epoch 1/10, Batch 70/145, Loss: 0.7333
Epoch 1/10, Batch 80/145, Loss: 0.5087
Epoch 1/10, Batch 90/145, Loss: 0.4800
Epoch 1/10, Batch 100/145, Loss: 0.6843
Epoch 1/10, Batch 110/145, Loss: 0.3904
Epoch 1/10, Batch 120/145, Loss: 0.4746
Epoch 1/10, Batch 130/145, Loss: 0.4086
Epoch 1/10, Batch 140/145, Loss: 0.3939
Epoch 1/10, Train Loss: 0.6859, Valid Loss: 0.3557
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3262
Epoch 2/10, Batch 20/145, Loss: 0.4246
Epoch 2/10, Batch 30/145, Loss: 0.2964
Epoch 2/10, Batch 40/145, Loss: 0.4558
Epoch 2/10, Batch 50/145, Loss: 0.2870
Epoch 2/10, Batch 60/145, Loss: 0.4281
Epoch 2/10, Batch 70/145, Loss: 0.4745
Epoch 2/10, Batch 80/145, Loss: 0.2950
Epoch 2/10, Batch 90/145, Loss: 0.3616
Epoch 2/10, Batch 100/145, Loss: 0.3620
Epoch 2/10, Batch 110/145, Loss: 0.2455
Epoch 2/10, Batch 120/145, Loss: 0.3616
Epoch 2/10, Batch 130/145, Loss: 0.3795
Epoch 2/10, Batch 140/145, Loss: 0.2817
Epoch 2/10, Train Loss: 0.3618, Valid Loss: 0.2713
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3012
Epoch 3/10, Batch 20/145, Loss: 0.2846
Epoch 3/10, Batch 30/145, Loss: 0.2661
Epoch 3/10, Batch 40/145, Loss: 0.4079
Epoch 3/10, Batch 50/145, Loss: 0.2151
Epoch 3/10, Batch 60/145, Loss: 0.3316
Epoch 3/10, Batch 70/145, Loss: 0.2092
Epoch 3/10, Batch 80/145, Loss: 0.2514
Epoch 3/10, Batch 90/145, Loss: 0.5662
Epoch 3/10, Batch 100/145, Loss: 0.4332
Epoch 3/10, Batch 110/145, Loss: 0.1909
Epoch 3/10, Batch 120/145, Loss: 0.1766
Epoch 3/10, Batch 130/145, Loss: 0.3070
Epoch 3/10, Batch 140/145, Loss: 0.1391
Epoch 3/10, Train Loss: 0.3086, Valid Loss: 0.2420
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3337
Epoch 4/10, Batch 20/145, Loss: 0.3981
Epoch 4/10, Batch 30/145, Loss: 0.3047
Epoch 4/10, Batch 40/145, Loss: 0.2964
Epoch 4/10, Batch 50/145, Loss: 0.2525
Epoch 4/10, Batch 60/145, Loss: 0.2467
Epoch 4/10, Batch 70/145, Loss: 0.2541
Epoch 4/10, Batch 80/145, Loss: 0.3574
Epoch 4/10, Batch 90/145, Loss: 0.2032
Epoch 4/10, Batch 100/145, Loss: 0.2371
Epoch 4/10, Batch 110/145, Loss: 0.1381
Epoch 4/10, Batch 120/145, Loss: 0.2079
Epoch 4/10, Batch 130/145, Loss: 0.2273
Epoch 4/10, Batch 140/145, Loss: 0.2818
Epoch 4/10, Train Loss: 0.2610, Valid Loss: 0.2338
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1905
Epoch 5/10, Batch 20/145, Loss: 0.2143
Epoch 5/10, Batch 30/145, Loss: 0.1094
Epoch 5/10, Batch 40/145, Loss: 0.2618
Epoch 5/10, Batch 50/145, Loss: 0.2047
Epoch 5/10, Batch 60/145, Loss: 0.1469
Epoch 5/10, Batch 70/145, Loss: 0.2347
Epoch 5/10, Batch 80/145, Loss: 0.2432
Epoch 5/10, Batch 90/145, Loss: 0.1223
Epoch 5/10, Batch 100/145, Loss: 0.2895
Epoch 5/10, Batch 110/145, Loss: 0.1701
Epoch 5/10, Batch 120/145, Loss: 0.2638
Epoch 5/10, Batch 130/145, Loss: 0.3226
Epoch 5/10, Batch 140/145, Loss: 0.2254
Epoch 5/10, Train Loss: 0.2415, Valid Loss: 0.2179
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1841
Epoch 6/10, Batch 20/145, Loss: 0.3106
Epoch 6/10, Batch 30/145, Loss: 0.2655
Epoch 6/10, Batch 40/145, Loss: 0.1978
Epoch 6/10, Batch 50/145, Loss: 0.1629
Epoch 6/10, Batch 60/145, Loss: 0.2022
Epoch 6/10, Batch 70/145, Loss: 0.3667
Epoch 6/10, Batch 80/145, Loss: 0.1880
Epoch 6/10, Batch 90/145, Loss: 0.3624
Epoch 6/10, Batch 100/145, Loss: 0.1472
Epoch 6/10, Batch 110/145, Loss: 0.1040
Epoch 6/10, Batch 120/145, Loss: 0.2583
Epoch 6/10, Batch 130/145, Loss: 0.1591
Epoch 6/10, Batch 140/145, Loss: 0.2864
Epoch 6/10, Train Loss: 0.2259, Valid Loss: 0.2079
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3364
Epoch 7/10, Batch 20/145, Loss: 0.2345
Epoch 7/10, Batch 30/145, Loss: 0.1295
Epoch 7/10, Batch 40/145, Loss: 0.4086
Epoch 7/10, Batch 50/145, Loss: 0.2119
Epoch 7/10, Batch 60/145, Loss: 0.1604
Epoch 7/10, Batch 70/145, Loss: 0.2772
Epoch 7/10, Batch 80/145, Loss: 0.1791
Epoch 7/10, Batch 90/145, Loss: 0.1411
Epoch 7/10, Batch 100/145, Loss: 0.3208
Epoch 7/10, Batch 110/145, Loss: 0.1927
Epoch 7/10, Batch 120/145, Loss: 0.1509
Epoch 7/10, Batch 130/145, Loss: 0.2615
Epoch 7/10, Batch 140/145, Loss: 0.1646
Epoch 7/10, Train Loss: 0.2207, Valid Loss: 0.2002
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2196
Epoch 8/10, Batch 20/145, Loss: 0.1821
Epoch 8/10, Batch 30/145, Loss: 0.2352
Epoch 8/10, Batch 40/145, Loss: 0.1300
Epoch 8/10, Batch 50/145, Loss: 0.2340
Epoch 8/10, Batch 60/145, Loss: 0.3395
Epoch 8/10, Batch 70/145, Loss: 0.0978
Epoch 8/10, Batch 80/145, Loss: 0.2610
Epoch 8/10, Batch 90/145, Loss: 0.2960
Epoch 8/10, Batch 100/145, Loss: 0.2491
Epoch 8/10, Batch 110/145, Loss: 0.2172
Epoch 8/10, Batch 120/145, Loss: 0.2071
Epoch 8/10, Batch 130/145, Loss: 0.1717
Epoch 8/10, Batch 140/145, Loss: 0.2926
Epoch 8/10, Train Loss: 0.2180, Valid Loss: 0.1958
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2337
Epoch 9/10, Batch 20/145, Loss: 0.1487
Epoch 9/10, Batch 30/145, Loss: 0.1202
Epoch 9/10, Batch 40/145, Loss: 0.2547
Epoch 9/10, Batch 50/145, Loss: 0.1294
Epoch 9/10, Batch 60/145, Loss: 0.1504
Epoch 9/10, Batch 70/145, Loss: 0.2189
Epoch 9/10, Batch 80/145, Loss: 0.1971
Epoch 9/10, Batch 90/145, Loss: 0.1401
Epoch 9/10, Batch 100/145, Loss: 0.2352
Epoch 9/10, Batch 110/145, Loss: 0.0868
Epoch 9/10, Batch 120/145, Loss: 0.1922
Epoch 9/10, Batch 130/145, Loss: 0.3755
Epoch 9/10, Batch 140/145, Loss: 0.2679
Epoch 9/10, Train Loss: 0.2042, Valid Loss: 0.1842
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1484
Epoch 10/10, Batch 20/145, Loss: 0.1011
Epoch 10/10, Batch 30/145, Loss: 0.1199
Epoch 10/10, Batch 40/145, Loss: 0.3049
Epoch 10/10, Batch 50/145, Loss: 0.2064
Epoch 10/10, Batch 60/145, Loss: 0.1229
Epoch 10/10, Batch 70/145, Loss: 0.2100
Epoch 10/10, Batch 80/145, Loss: 0.2961
Epoch 10/10, Batch 90/145, Loss: 0.1684
Epoch 10/10, Batch 100/145, Loss: 0.2385
Epoch 10/10, Batch 110/145, Loss: 0.2014
Epoch 10/10, Batch 120/145, Loss: 0.1688
Epoch 10/10, Batch 130/145, Loss: 0.1521
Epoch 10/10, Batch 140/145, Loss: 0.1873
Epoch 10/10, Train Loss: 0.1963, Valid Loss: 0.1796
Model saved!
Accuracy: 0.9241
Precision: 0.9225
Recall: 0.9241
F1-score: 0.9231
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5129
Epoch 1/10, Batch 20/145, Loss: 0.8688
Epoch 1/10, Batch 30/145, Loss: 0.8202
Epoch 1/10, Batch 40/145, Loss: 0.8876
Epoch 1/10, Batch 50/145, Loss: 0.5245
Epoch 1/10, Batch 60/145, Loss: 0.6228
Epoch 1/10, Batch 70/145, Loss: 0.5648
Epoch 1/10, Batch 80/145, Loss: 0.4562
Epoch 1/10, Batch 90/145, Loss: 0.3656
Epoch 1/10, Batch 100/145, Loss: 0.6575
Epoch 1/10, Batch 110/145, Loss: 0.4716
Epoch 1/10, Batch 120/145, Loss: 0.4970
Epoch 1/10, Batch 130/145, Loss: 0.4869
Epoch 1/10, Batch 140/145, Loss: 0.3195
Epoch 1/10, Train Loss: 0.6760, Valid Loss: 0.3610
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2505
Epoch 2/10, Batch 20/145, Loss: 0.4107
Epoch 2/10, Batch 30/145, Loss: 0.3642
Epoch 2/10, Batch 40/145, Loss: 0.3605
Epoch 2/10, Batch 50/145, Loss: 0.3236
Epoch 2/10, Batch 60/145, Loss: 0.4322
Epoch 2/10, Batch 70/145, Loss: 0.4001
Epoch 2/10, Batch 80/145, Loss: 0.3522
Epoch 2/10, Batch 90/145, Loss: 0.2782
Epoch 2/10, Batch 100/145, Loss: 0.2290
Epoch 2/10, Batch 110/145, Loss: 0.3055
Epoch 2/10, Batch 120/145, Loss: 0.3818
Epoch 2/10, Batch 130/145, Loss: 0.2997
Epoch 2/10, Batch 140/145, Loss: 0.2530
Epoch 2/10, Train Loss: 0.3430, Valid Loss: 0.2748
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2598
Epoch 3/10, Batch 20/145, Loss: 0.2250
Epoch 3/10, Batch 30/145, Loss: 0.2451
Epoch 3/10, Batch 40/145, Loss: 0.2509
Epoch 3/10, Batch 50/145, Loss: 0.1935
Epoch 3/10, Batch 60/145, Loss: 0.3961
Epoch 3/10, Batch 70/145, Loss: 0.1399
Epoch 3/10, Batch 80/145, Loss: 0.2337
Epoch 3/10, Batch 90/145, Loss: 0.3810
Epoch 3/10, Batch 100/145, Loss: 0.2401
Epoch 3/10, Batch 110/145, Loss: 0.2387
Epoch 3/10, Batch 120/145, Loss: 0.2027
Epoch 3/10, Batch 130/145, Loss: 0.1734
Epoch 3/10, Batch 140/145, Loss: 0.2393
Epoch 3/10, Train Loss: 0.2916, Valid Loss: 0.2391
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2328
Epoch 4/10, Batch 20/145, Loss: 0.2096
Epoch 4/10, Batch 30/145, Loss: 0.2776
Epoch 4/10, Batch 40/145, Loss: 0.5375
Epoch 4/10, Batch 50/145, Loss: 0.4211
Epoch 4/10, Batch 60/145, Loss: 0.1271
Epoch 4/10, Batch 70/145, Loss: 0.2330
Epoch 4/10, Batch 80/145, Loss: 0.3309
Epoch 4/10, Batch 90/145, Loss: 0.2355
Epoch 4/10, Batch 100/145, Loss: 0.2878
Epoch 4/10, Batch 110/145, Loss: 0.1770
Epoch 4/10, Batch 120/145, Loss: 0.1560
Epoch 4/10, Batch 130/145, Loss: 0.2004
Epoch 4/10, Batch 140/145, Loss: 0.3392
Epoch 4/10, Train Loss: 0.2580, Valid Loss: 0.2340
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3003
Epoch 5/10, Batch 20/145, Loss: 0.2284
Epoch 5/10, Batch 30/145, Loss: 0.2029
Epoch 5/10, Batch 40/145, Loss: 0.1273
Epoch 5/10, Batch 50/145, Loss: 0.1973
Epoch 5/10, Batch 60/145, Loss: 0.3535
Epoch 5/10, Batch 70/145, Loss: 0.3008
Epoch 5/10, Batch 80/145, Loss: 0.2564
Epoch 5/10, Batch 90/145, Loss: 0.1864
Epoch 5/10, Batch 100/145, Loss: 0.2369
Epoch 5/10, Batch 110/145, Loss: 0.0844
Epoch 5/10, Batch 120/145, Loss: 0.2304
Epoch 5/10, Batch 130/145, Loss: 0.3237
Epoch 5/10, Batch 140/145, Loss: 0.1900
Epoch 5/10, Train Loss: 0.2292, Valid Loss: 0.2120
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1624
Epoch 6/10, Batch 20/145, Loss: 0.4443
Epoch 6/10, Batch 30/145, Loss: 0.1993
Epoch 6/10, Batch 40/145, Loss: 0.1543
Epoch 6/10, Batch 50/145, Loss: 0.1568
Epoch 6/10, Batch 60/145, Loss: 0.0572
Epoch 6/10, Batch 70/145, Loss: 0.3705
Epoch 6/10, Batch 80/145, Loss: 0.3080
Epoch 6/10, Batch 90/145, Loss: 0.3294
Epoch 6/10, Batch 100/145, Loss: 0.2893
Epoch 6/10, Batch 110/145, Loss: 0.1639
Epoch 6/10, Batch 120/145, Loss: 0.2022
Epoch 6/10, Batch 130/145, Loss: 0.1412
Epoch 6/10, Batch 140/145, Loss: 0.2817
Epoch 6/10, Train Loss: 0.2240, Valid Loss: 0.2095
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.4137
Epoch 7/10, Batch 20/145, Loss: 0.1112
Epoch 7/10, Batch 30/145, Loss: 0.1117
Epoch 7/10, Batch 40/145, Loss: 0.2827
Epoch 7/10, Batch 50/145, Loss: 0.2830
Epoch 7/10, Batch 60/145, Loss: 0.3412
Epoch 7/10, Batch 70/145, Loss: 0.2465
Epoch 7/10, Batch 80/145, Loss: 0.2473
Epoch 7/10, Batch 90/145, Loss: 0.2406
Epoch 7/10, Batch 100/145, Loss: 0.2917
Epoch 7/10, Batch 110/145, Loss: 0.2045
Epoch 7/10, Batch 120/145, Loss: 0.0858
Epoch 7/10, Batch 130/145, Loss: 0.1802
Epoch 7/10, Batch 140/145, Loss: 0.0572
Epoch 7/10, Train Loss: 0.2090, Valid Loss: 0.2056
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2041
Epoch 8/10, Batch 20/145, Loss: 0.1069
Epoch 8/10, Batch 30/145, Loss: 0.0946
Epoch 8/10, Batch 40/145, Loss: 0.2323
Epoch 8/10, Batch 50/145, Loss: 0.2700
Epoch 8/10, Batch 60/145, Loss: 0.0784
Epoch 8/10, Batch 70/145, Loss: 0.2334
Epoch 8/10, Batch 80/145, Loss: 0.1099
Epoch 8/10, Batch 90/145, Loss: 0.1115
Epoch 8/10, Batch 100/145, Loss: 0.2735
Epoch 8/10, Batch 110/145, Loss: 0.2094
Epoch 8/10, Batch 120/145, Loss: 0.3413
Epoch 8/10, Batch 130/145, Loss: 0.1502
Epoch 8/10, Batch 140/145, Loss: 0.3723
Epoch 8/10, Train Loss: 0.2026, Valid Loss: 0.1957
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2583
Epoch 9/10, Batch 20/145, Loss: 0.0927
Epoch 9/10, Batch 30/145, Loss: 0.1763
Epoch 9/10, Batch 40/145, Loss: 0.1309
Epoch 9/10, Batch 50/145, Loss: 0.1723
Epoch 9/10, Batch 60/145, Loss: 0.1725
Epoch 9/10, Batch 70/145, Loss: 0.3000
Epoch 9/10, Batch 80/145, Loss: 0.3483
Epoch 9/10, Batch 90/145, Loss: 0.1648
Epoch 9/10, Batch 100/145, Loss: 0.1845
Epoch 9/10, Batch 110/145, Loss: 0.1198
Epoch 9/10, Batch 120/145, Loss: 0.3898
Epoch 9/10, Batch 130/145, Loss: 0.4540
Epoch 9/10, Batch 140/145, Loss: 0.1682
Epoch 9/10, Train Loss: 0.1915, Valid Loss: 0.1933
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1951
Epoch 10/10, Batch 20/145, Loss: 0.1308
Epoch 10/10, Batch 30/145, Loss: 0.0838
Epoch 10/10, Batch 40/145, Loss: 0.1274
Epoch 10/10, Batch 50/145, Loss: 0.2229
Epoch 10/10, Batch 60/145, Loss: 0.1664
Epoch 10/10, Batch 70/145, Loss: 0.2547
Epoch 10/10, Batch 80/145, Loss: 0.2527
Epoch 10/10, Batch 90/145, Loss: 0.1464
Epoch 10/10, Batch 100/145, Loss: 0.2035
Epoch 10/10, Batch 110/145, Loss: 0.2366
Epoch 10/10, Batch 120/145, Loss: 0.2026
Epoch 10/10, Batch 130/145, Loss: 0.1524
Epoch 10/10, Batch 140/145, Loss: 0.2582
Epoch 10/10, Train Loss: 0.1865, Valid Loss: 0.1844
Model saved!
Accuracy: 0.9206
Precision: 0.9200
Recall: 0.9206
F1-score: 0.9198
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4865
Epoch 1/10, Batch 20/145, Loss: 0.8860
Epoch 1/10, Batch 30/145, Loss: 0.7606
Epoch 1/10, Batch 40/145, Loss: 0.8141
Epoch 1/10, Batch 50/145, Loss: 0.6060
Epoch 1/10, Batch 60/145, Loss: 0.5246
Epoch 1/10, Batch 70/145, Loss: 0.6110
Epoch 1/10, Batch 80/145, Loss: 0.4526
Epoch 1/10, Batch 90/145, Loss: 0.4440
Epoch 1/10, Batch 100/145, Loss: 0.6062
Epoch 1/10, Batch 110/145, Loss: 0.4857
Epoch 1/10, Batch 120/145, Loss: 0.4922
Epoch 1/10, Batch 130/145, Loss: 0.3553
Epoch 1/10, Batch 140/145, Loss: 0.3503
Epoch 1/10, Train Loss: 0.6809, Valid Loss: 0.3688
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2843
Epoch 2/10, Batch 20/145, Loss: 0.4259
Epoch 2/10, Batch 30/145, Loss: 0.4113
Epoch 2/10, Batch 40/145, Loss: 0.6594
Epoch 2/10, Batch 50/145, Loss: 0.3402
Epoch 2/10, Batch 60/145, Loss: 0.3352
Epoch 2/10, Batch 70/145, Loss: 0.5198
Epoch 2/10, Batch 80/145, Loss: 0.5384
Epoch 2/10, Batch 90/145, Loss: 0.1933
Epoch 2/10, Batch 100/145, Loss: 0.2023
Epoch 2/10, Batch 110/145, Loss: 0.2338
Epoch 2/10, Batch 120/145, Loss: 0.3755
Epoch 2/10, Batch 130/145, Loss: 0.2898
Epoch 2/10, Batch 140/145, Loss: 0.2016
Epoch 2/10, Train Loss: 0.3572, Valid Loss: 0.2818
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1978
Epoch 3/10, Batch 20/145, Loss: 0.4044
Epoch 3/10, Batch 30/145, Loss: 0.2125
Epoch 3/10, Batch 40/145, Loss: 0.2547
Epoch 3/10, Batch 50/145, Loss: 0.1843
Epoch 3/10, Batch 60/145, Loss: 0.2897
Epoch 3/10, Batch 70/145, Loss: 0.2345
Epoch 3/10, Batch 80/145, Loss: 0.2721
Epoch 3/10, Batch 90/145, Loss: 0.3923
Epoch 3/10, Batch 100/145, Loss: 0.5171
Epoch 3/10, Batch 110/145, Loss: 0.2355
Epoch 3/10, Batch 120/145, Loss: 0.2066
Epoch 3/10, Batch 130/145, Loss: 0.1983
Epoch 3/10, Batch 140/145, Loss: 0.1804
Epoch 3/10, Train Loss: 0.2959, Valid Loss: 0.2510
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2450
Epoch 4/10, Batch 20/145, Loss: 0.1940
Epoch 4/10, Batch 30/145, Loss: 0.3981
Epoch 4/10, Batch 40/145, Loss: 0.5691
Epoch 4/10, Batch 50/145, Loss: 0.2602
Epoch 4/10, Batch 60/145, Loss: 0.1453
Epoch 4/10, Batch 70/145, Loss: 0.1319
Epoch 4/10, Batch 80/145, Loss: 0.2487
Epoch 4/10, Batch 90/145, Loss: 0.2453
Epoch 4/10, Batch 100/145, Loss: 0.2935
Epoch 4/10, Batch 110/145, Loss: 0.2677
Epoch 4/10, Batch 120/145, Loss: 0.2460
Epoch 4/10, Batch 130/145, Loss: 0.2127
Epoch 4/10, Batch 140/145, Loss: 0.1552
Epoch 4/10, Train Loss: 0.2568, Valid Loss: 0.2456
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2433
Epoch 5/10, Batch 20/145, Loss: 0.1481
Epoch 5/10, Batch 30/145, Loss: 0.1827
Epoch 5/10, Batch 40/145, Loss: 0.3160
Epoch 5/10, Batch 50/145, Loss: 0.1449
Epoch 5/10, Batch 60/145, Loss: 0.1773
Epoch 5/10, Batch 70/145, Loss: 0.2361
Epoch 5/10, Batch 80/145, Loss: 0.1934
Epoch 5/10, Batch 90/145, Loss: 0.1129
Epoch 5/10, Batch 100/145, Loss: 0.3081
Epoch 5/10, Batch 110/145, Loss: 0.1731
Epoch 5/10, Batch 120/145, Loss: 0.2576
Epoch 5/10, Batch 130/145, Loss: 0.2035
Epoch 5/10, Batch 140/145, Loss: 0.3406
Epoch 5/10, Train Loss: 0.2342, Valid Loss: 0.2371
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1426
Epoch 6/10, Batch 20/145, Loss: 0.1800
Epoch 6/10, Batch 30/145, Loss: 0.2822
Epoch 6/10, Batch 40/145, Loss: 0.2022
Epoch 6/10, Batch 50/145, Loss: 0.2202
Epoch 6/10, Batch 60/145, Loss: 0.1847
Epoch 6/10, Batch 70/145, Loss: 0.4096
Epoch 6/10, Batch 80/145, Loss: 0.2109
Epoch 6/10, Batch 90/145, Loss: 0.1663
Epoch 6/10, Batch 100/145, Loss: 0.1516
Epoch 6/10, Batch 110/145, Loss: 0.1239
Epoch 6/10, Batch 120/145, Loss: 0.1147
Epoch 6/10, Batch 130/145, Loss: 0.1713
Epoch 6/10, Batch 140/145, Loss: 0.2180
Epoch 6/10, Train Loss: 0.2216, Valid Loss: 0.2414
Epoch 7/10, Batch 10/145, Loss: 0.1865
Epoch 7/10, Batch 20/145, Loss: 0.1970
Epoch 7/10, Batch 30/145, Loss: 0.2013
Epoch 7/10, Batch 40/145, Loss: 0.5217
Epoch 7/10, Batch 50/145, Loss: 0.2789
Epoch 7/10, Batch 60/145, Loss: 0.1168
Epoch 7/10, Batch 70/145, Loss: 0.1965
Epoch 7/10, Batch 80/145, Loss: 0.1077
Epoch 7/10, Batch 90/145, Loss: 0.1429
Epoch 7/10, Batch 100/145, Loss: 0.0990
Epoch 7/10, Batch 110/145, Loss: 0.2253
Epoch 7/10, Batch 120/145, Loss: 0.1414
Epoch 7/10, Batch 130/145, Loss: 0.1518
Epoch 7/10, Batch 140/145, Loss: 0.1552
Epoch 7/10, Train Loss: 0.2054, Valid Loss: 0.2217
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2748
Epoch 8/10, Batch 20/145, Loss: 0.1308
Epoch 8/10, Batch 30/145, Loss: 0.1493
Epoch 8/10, Batch 40/145, Loss: 0.2818
Epoch 8/10, Batch 50/145, Loss: 0.3120
Epoch 8/10, Batch 60/145, Loss: 0.1891
Epoch 8/10, Batch 70/145, Loss: 0.1303
Epoch 8/10, Batch 80/145, Loss: 0.1774
Epoch 8/10, Batch 90/145, Loss: 0.1682
Epoch 8/10, Batch 100/145, Loss: 0.2150
Epoch 8/10, Batch 110/145, Loss: 0.2007
Epoch 8/10, Batch 120/145, Loss: 0.1941
Epoch 8/10, Batch 130/145, Loss: 0.1435
Epoch 8/10, Batch 140/145, Loss: 0.1817
Epoch 8/10, Train Loss: 0.2048, Valid Loss: 0.2139
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2151
Epoch 9/10, Batch 20/145, Loss: 0.1210
Epoch 9/10, Batch 30/145, Loss: 0.1186
Epoch 9/10, Batch 40/145, Loss: 0.1376
Epoch 9/10, Batch 50/145, Loss: 0.2858
Epoch 9/10, Batch 60/145, Loss: 0.1960
Epoch 9/10, Batch 70/145, Loss: 0.2809
Epoch 9/10, Batch 80/145, Loss: 0.1168
Epoch 9/10, Batch 90/145, Loss: 0.1831
Epoch 9/10, Batch 100/145, Loss: 0.2015
Epoch 9/10, Batch 110/145, Loss: 0.0871
Epoch 9/10, Batch 120/145, Loss: 0.1356
Epoch 9/10, Batch 130/145, Loss: 0.1400
Epoch 9/10, Batch 140/145, Loss: 0.0904
Epoch 9/10, Train Loss: 0.1938, Valid Loss: 0.2105
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2269
Epoch 10/10, Batch 20/145, Loss: 0.1707
Epoch 10/10, Batch 30/145, Loss: 0.1141
Epoch 10/10, Batch 40/145, Loss: 0.3984
Epoch 10/10, Batch 50/145, Loss: 0.1381
Epoch 10/10, Batch 60/145, Loss: 0.1203
Epoch 10/10, Batch 70/145, Loss: 0.1190
Epoch 10/10, Batch 80/145, Loss: 0.3264
Epoch 10/10, Batch 90/145, Loss: 0.1895
Epoch 10/10, Batch 100/145, Loss: 0.2566
Epoch 10/10, Batch 110/145, Loss: 0.1944
Epoch 10/10, Batch 120/145, Loss: 0.1833
Epoch 10/10, Batch 130/145, Loss: 0.1026
Epoch 10/10, Batch 140/145, Loss: 0.1572
Epoch 10/10, Train Loss: 0.1920, Valid Loss: 0.2108
Accuracy: 0.9182
Precision: 0.9161
Recall: 0.9182
F1-score: 0.9169
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5419
Epoch 1/10, Batch 20/145, Loss: 0.8776
Epoch 1/10, Batch 30/145, Loss: 0.9777
Epoch 1/10, Batch 40/145, Loss: 0.7661
Epoch 1/10, Batch 50/145, Loss: 0.6295
Epoch 1/10, Batch 60/145, Loss: 0.6115
Epoch 1/10, Batch 70/145, Loss: 0.6445
Epoch 1/10, Batch 80/145, Loss: 0.5013
Epoch 1/10, Batch 90/145, Loss: 0.5271
Epoch 1/10, Batch 100/145, Loss: 0.7215
Epoch 1/10, Batch 110/145, Loss: 0.4455
Epoch 1/10, Batch 120/145, Loss: 0.6789
Epoch 1/10, Batch 130/145, Loss: 0.3340
Epoch 1/10, Batch 140/145, Loss: 0.5277
Epoch 1/10, Train Loss: 0.6885, Valid Loss: 0.3721
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3190
Epoch 2/10, Batch 20/145, Loss: 0.4176
Epoch 2/10, Batch 30/145, Loss: 0.3815
Epoch 2/10, Batch 40/145, Loss: 0.4548
Epoch 2/10, Batch 50/145, Loss: 0.3432
Epoch 2/10, Batch 60/145, Loss: 0.3557
Epoch 2/10, Batch 70/145, Loss: 0.2981
Epoch 2/10, Batch 80/145, Loss: 0.2894
Epoch 2/10, Batch 90/145, Loss: 0.1852
Epoch 2/10, Batch 100/145, Loss: 0.4105
Epoch 2/10, Batch 110/145, Loss: 0.4069
Epoch 2/10, Batch 120/145, Loss: 0.4754
Epoch 2/10, Batch 130/145, Loss: 0.3524
Epoch 2/10, Batch 140/145, Loss: 0.2424
Epoch 2/10, Train Loss: 0.3611, Valid Loss: 0.2907
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1777
Epoch 3/10, Batch 20/145, Loss: 0.2411
Epoch 3/10, Batch 30/145, Loss: 0.5128
Epoch 3/10, Batch 40/145, Loss: 0.3241
Epoch 3/10, Batch 50/145, Loss: 0.2714
Epoch 3/10, Batch 60/145, Loss: 0.1795
Epoch 3/10, Batch 70/145, Loss: 0.2006
Epoch 3/10, Batch 80/145, Loss: 0.2085
Epoch 3/10, Batch 90/145, Loss: 0.5470
Epoch 3/10, Batch 100/145, Loss: 0.3002
Epoch 3/10, Batch 110/145, Loss: 0.1589
Epoch 3/10, Batch 120/145, Loss: 0.3668
Epoch 3/10, Batch 130/145, Loss: 0.3579
Epoch 3/10, Batch 140/145, Loss: 0.2594
Epoch 3/10, Train Loss: 0.3116, Valid Loss: 0.2594
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2255
Epoch 4/10, Batch 20/145, Loss: 0.1852
Epoch 4/10, Batch 30/145, Loss: 0.2057
Epoch 4/10, Batch 40/145, Loss: 0.4572
Epoch 4/10, Batch 50/145, Loss: 0.1860
Epoch 4/10, Batch 60/145, Loss: 0.2319
Epoch 4/10, Batch 70/145, Loss: 0.2184
Epoch 4/10, Batch 80/145, Loss: 0.4111
Epoch 4/10, Batch 90/145, Loss: 0.2212
Epoch 4/10, Batch 100/145, Loss: 0.1861
Epoch 4/10, Batch 110/145, Loss: 0.1579
Epoch 4/10, Batch 120/145, Loss: 0.1470
Epoch 4/10, Batch 130/145, Loss: 0.1651
Epoch 4/10, Batch 140/145, Loss: 0.1955
Epoch 4/10, Train Loss: 0.2642, Valid Loss: 0.2502
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3249
Epoch 5/10, Batch 20/145, Loss: 0.2499
Epoch 5/10, Batch 30/145, Loss: 0.2440
Epoch 5/10, Batch 40/145, Loss: 0.1373
Epoch 5/10, Batch 50/145, Loss: 0.2278
Epoch 5/10, Batch 60/145, Loss: 0.1532
Epoch 5/10, Batch 70/145, Loss: 0.3756
Epoch 5/10, Batch 80/145, Loss: 0.3775
Epoch 5/10, Batch 90/145, Loss: 0.1159
Epoch 5/10, Batch 100/145, Loss: 0.2999
Epoch 5/10, Batch 110/145, Loss: 0.1848
Epoch 5/10, Batch 120/145, Loss: 0.3383
Epoch 5/10, Batch 130/145, Loss: 0.1759
Epoch 5/10, Batch 140/145, Loss: 0.4128
Epoch 5/10, Train Loss: 0.2467, Valid Loss: 0.2369
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2213
Epoch 6/10, Batch 20/145, Loss: 0.3220
Epoch 6/10, Batch 30/145, Loss: 0.4211
Epoch 6/10, Batch 40/145, Loss: 0.2706
Epoch 6/10, Batch 50/145, Loss: 0.2660
Epoch 6/10, Batch 60/145, Loss: 0.1583
Epoch 6/10, Batch 70/145, Loss: 0.3173
Epoch 6/10, Batch 80/145, Loss: 0.2781
Epoch 6/10, Batch 90/145, Loss: 0.2116
Epoch 6/10, Batch 100/145, Loss: 0.1965
Epoch 6/10, Batch 110/145, Loss: 0.3308
Epoch 6/10, Batch 120/145, Loss: 0.3583
Epoch 6/10, Batch 130/145, Loss: 0.2412
Epoch 6/10, Batch 140/145, Loss: 0.2248
Epoch 6/10, Train Loss: 0.2291, Valid Loss: 0.2233
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2325
Epoch 7/10, Batch 20/145, Loss: 0.1691
Epoch 7/10, Batch 30/145, Loss: 0.1643
Epoch 7/10, Batch 40/145, Loss: 0.4180
Epoch 7/10, Batch 50/145, Loss: 0.0848
Epoch 7/10, Batch 60/145, Loss: 0.1492
Epoch 7/10, Batch 70/145, Loss: 0.1770
Epoch 7/10, Batch 80/145, Loss: 0.1316
Epoch 7/10, Batch 90/145, Loss: 0.2938
Epoch 7/10, Batch 100/145, Loss: 0.1960
Epoch 7/10, Batch 110/145, Loss: 0.1237
Epoch 7/10, Batch 120/145, Loss: 0.1954
Epoch 7/10, Batch 130/145, Loss: 0.2352
Epoch 7/10, Batch 140/145, Loss: 0.1637
Epoch 7/10, Train Loss: 0.2243, Valid Loss: 0.2197
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2221
Epoch 8/10, Batch 20/145, Loss: 0.0985
Epoch 8/10, Batch 30/145, Loss: 0.1790
Epoch 8/10, Batch 40/145, Loss: 0.2582
Epoch 8/10, Batch 50/145, Loss: 0.3072
Epoch 8/10, Batch 60/145, Loss: 0.1730
Epoch 8/10, Batch 70/145, Loss: 0.0907
Epoch 8/10, Batch 80/145, Loss: 0.2424
Epoch 8/10, Batch 90/145, Loss: 0.0603
Epoch 8/10, Batch 100/145, Loss: 0.1820
Epoch 8/10, Batch 110/145, Loss: 0.1418
Epoch 8/10, Batch 120/145, Loss: 0.1476
Epoch 8/10, Batch 130/145, Loss: 0.1881
Epoch 8/10, Batch 140/145, Loss: 0.3427
Epoch 8/10, Train Loss: 0.2109, Valid Loss: 0.2142
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2390
Epoch 9/10, Batch 20/145, Loss: 0.0942
Epoch 9/10, Batch 30/145, Loss: 0.1946
Epoch 9/10, Batch 40/145, Loss: 0.1286
Epoch 9/10, Batch 50/145, Loss: 0.0788
Epoch 9/10, Batch 60/145, Loss: 0.2009
Epoch 9/10, Batch 70/145, Loss: 0.1900
Epoch 9/10, Batch 80/145, Loss: 0.2187
Epoch 9/10, Batch 90/145, Loss: 0.1395
Epoch 9/10, Batch 100/145, Loss: 0.2517
Epoch 9/10, Batch 110/145, Loss: 0.0930
Epoch 9/10, Batch 120/145, Loss: 0.2583
Epoch 9/10, Batch 130/145, Loss: 0.2887
Epoch 9/10, Batch 140/145, Loss: 0.1033
Epoch 9/10, Train Loss: 0.2060, Valid Loss: 0.2077
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2074
Epoch 10/10, Batch 20/145, Loss: 0.1437
Epoch 10/10, Batch 30/145, Loss: 0.2092
Epoch 10/10, Batch 40/145, Loss: 0.2679
Epoch 10/10, Batch 50/145, Loss: 0.2321
Epoch 10/10, Batch 60/145, Loss: 0.1738
Epoch 10/10, Batch 70/145, Loss: 0.1581
Epoch 10/10, Batch 80/145, Loss: 0.4751
Epoch 10/10, Batch 90/145, Loss: 0.1133
Epoch 10/10, Batch 100/145, Loss: 0.1444
Epoch 10/10, Batch 110/145, Loss: 0.3423
Epoch 10/10, Batch 120/145, Loss: 0.1213
Epoch 10/10, Batch 130/145, Loss: 0.1340
Epoch 10/10, Batch 140/145, Loss: 0.1821
Epoch 10/10, Train Loss: 0.1983, Valid Loss: 0.2065
Model saved!
Accuracy: 0.9217
Precision: 0.9203
Recall: 0.9217
F1-score: 0.9208
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4345
Epoch 1/10, Batch 20/145, Loss: 0.8529
Epoch 1/10, Batch 30/145, Loss: 0.9323
Epoch 1/10, Batch 40/145, Loss: 0.8562
Epoch 1/10, Batch 50/145, Loss: 0.5816
Epoch 1/10, Batch 60/145, Loss: 0.5269
Epoch 1/10, Batch 70/145, Loss: 0.7186
Epoch 1/10, Batch 80/145, Loss: 0.4667
Epoch 1/10, Batch 90/145, Loss: 0.7276
Epoch 1/10, Batch 100/145, Loss: 0.4745
Epoch 1/10, Batch 110/145, Loss: 0.4187
Epoch 1/10, Batch 120/145, Loss: 0.4419
Epoch 1/10, Batch 130/145, Loss: 0.2914
Epoch 1/10, Batch 140/145, Loss: 0.4563
Epoch 1/10, Train Loss: 0.6810, Valid Loss: 0.3715
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4257
Epoch 2/10, Batch 20/145, Loss: 0.4264
Epoch 2/10, Batch 30/145, Loss: 0.2944
Epoch 2/10, Batch 40/145, Loss: 0.4739
Epoch 2/10, Batch 50/145, Loss: 0.1868
Epoch 2/10, Batch 60/145, Loss: 0.3807
Epoch 2/10, Batch 70/145, Loss: 0.3297
Epoch 2/10, Batch 80/145, Loss: 0.2960
Epoch 2/10, Batch 90/145, Loss: 0.3289
Epoch 2/10, Batch 100/145, Loss: 0.2754
Epoch 2/10, Batch 110/145, Loss: 0.2279
Epoch 2/10, Batch 120/145, Loss: 0.4240
Epoch 2/10, Batch 130/145, Loss: 0.4131
Epoch 2/10, Batch 140/145, Loss: 0.2739
Epoch 2/10, Train Loss: 0.3588, Valid Loss: 0.2986
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2845
Epoch 3/10, Batch 20/145, Loss: 0.3487
Epoch 3/10, Batch 30/145, Loss: 0.2441
Epoch 3/10, Batch 40/145, Loss: 0.2784
Epoch 3/10, Batch 50/145, Loss: 0.1152
Epoch 3/10, Batch 60/145, Loss: 0.1481
Epoch 3/10, Batch 70/145, Loss: 0.2049
Epoch 3/10, Batch 80/145, Loss: 0.2448
Epoch 3/10, Batch 90/145, Loss: 0.5364
Epoch 3/10, Batch 100/145, Loss: 0.2717
Epoch 3/10, Batch 110/145, Loss: 0.2841
Epoch 3/10, Batch 120/145, Loss: 0.2737
Epoch 3/10, Batch 130/145, Loss: 0.2999
Epoch 3/10, Batch 140/145, Loss: 0.3563
Epoch 3/10, Train Loss: 0.3049, Valid Loss: 0.2716
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1468
Epoch 4/10, Batch 20/145, Loss: 0.2779
Epoch 4/10, Batch 30/145, Loss: 0.3992
Epoch 4/10, Batch 40/145, Loss: 0.4784
Epoch 4/10, Batch 50/145, Loss: 0.2841
Epoch 4/10, Batch 60/145, Loss: 0.1387
Epoch 4/10, Batch 70/145, Loss: 0.2107
Epoch 4/10, Batch 80/145, Loss: 0.2348
Epoch 4/10, Batch 90/145, Loss: 0.3060
Epoch 4/10, Batch 100/145, Loss: 0.2176
Epoch 4/10, Batch 110/145, Loss: 0.0794
Epoch 4/10, Batch 120/145, Loss: 0.1469
Epoch 4/10, Batch 130/145, Loss: 0.1567
Epoch 4/10, Batch 140/145, Loss: 0.1939
Epoch 4/10, Train Loss: 0.2622, Valid Loss: 0.2651
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1959
Epoch 5/10, Batch 20/145, Loss: 0.1581
Epoch 5/10, Batch 30/145, Loss: 0.2433
Epoch 5/10, Batch 40/145, Loss: 0.1772
Epoch 5/10, Batch 50/145, Loss: 0.0960
Epoch 5/10, Batch 60/145, Loss: 0.1759
Epoch 5/10, Batch 70/145, Loss: 0.1894
Epoch 5/10, Batch 80/145, Loss: 0.2757
Epoch 5/10, Batch 90/145, Loss: 0.2094
Epoch 5/10, Batch 100/145, Loss: 0.1545
Epoch 5/10, Batch 110/145, Loss: 0.1503
Epoch 5/10, Batch 120/145, Loss: 0.2224
Epoch 5/10, Batch 130/145, Loss: 0.1693
Epoch 5/10, Batch 140/145, Loss: 0.2943
Epoch 5/10, Train Loss: 0.2398, Valid Loss: 0.2451
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3288
Epoch 6/10, Batch 20/145, Loss: 0.2639
Epoch 6/10, Batch 30/145, Loss: 0.4813
Epoch 6/10, Batch 40/145, Loss: 0.1242
Epoch 6/10, Batch 50/145, Loss: 0.5965
Epoch 6/10, Batch 60/145, Loss: 0.1185
Epoch 6/10, Batch 70/145, Loss: 0.1473
Epoch 6/10, Batch 80/145, Loss: 0.1768
Epoch 6/10, Batch 90/145, Loss: 0.4094
Epoch 6/10, Batch 100/145, Loss: 0.1974
Epoch 6/10, Batch 110/145, Loss: 0.1632
Epoch 6/10, Batch 120/145, Loss: 0.1897
Epoch 6/10, Batch 130/145, Loss: 0.2180
Epoch 6/10, Batch 140/145, Loss: 0.2270
Epoch 6/10, Train Loss: 0.2287, Valid Loss: 0.2390
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3960
Epoch 7/10, Batch 20/145, Loss: 0.2485
Epoch 7/10, Batch 30/145, Loss: 0.1836
Epoch 7/10, Batch 40/145, Loss: 0.2976
Epoch 7/10, Batch 50/145, Loss: 0.1489
Epoch 7/10, Batch 60/145, Loss: 0.1383
Epoch 7/10, Batch 70/145, Loss: 0.2924
Epoch 7/10, Batch 80/145, Loss: 0.2662
Epoch 7/10, Batch 90/145, Loss: 0.1105
Epoch 7/10, Batch 100/145, Loss: 0.1861
Epoch 7/10, Batch 110/145, Loss: 0.3829
Epoch 7/10, Batch 120/145, Loss: 0.2450
Epoch 7/10, Batch 130/145, Loss: 0.2304
Epoch 7/10, Batch 140/145, Loss: 0.1759
Epoch 7/10, Train Loss: 0.2093, Valid Loss: 0.2304
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1745
Epoch 8/10, Batch 20/145, Loss: 0.1766
Epoch 8/10, Batch 30/145, Loss: 0.3301
Epoch 8/10, Batch 40/145, Loss: 0.1398
Epoch 8/10, Batch 50/145, Loss: 0.2643
Epoch 8/10, Batch 60/145, Loss: 0.2876
Epoch 8/10, Batch 70/145, Loss: 0.1941
Epoch 8/10, Batch 80/145, Loss: 0.1191
Epoch 8/10, Batch 90/145, Loss: 0.1214
Epoch 8/10, Batch 100/145, Loss: 0.2228
Epoch 8/10, Batch 110/145, Loss: 0.2244
Epoch 8/10, Batch 120/145, Loss: 0.2239
Epoch 8/10, Batch 130/145, Loss: 0.2622
Epoch 8/10, Batch 140/145, Loss: 0.4652
Epoch 8/10, Train Loss: 0.2057, Valid Loss: 0.2317
Epoch 9/10, Batch 10/145, Loss: 0.1659
Epoch 9/10, Batch 20/145, Loss: 0.1020
Epoch 9/10, Batch 30/145, Loss: 0.1573
Epoch 9/10, Batch 40/145, Loss: 0.2383
Epoch 9/10, Batch 50/145, Loss: 0.1551
Epoch 9/10, Batch 60/145, Loss: 0.1861
Epoch 9/10, Batch 70/145, Loss: 0.1895
Epoch 9/10, Batch 80/145, Loss: 0.0996
Epoch 9/10, Batch 90/145, Loss: 0.0689
Epoch 9/10, Batch 100/145, Loss: 0.4412
Epoch 9/10, Batch 110/145, Loss: 0.1728
Epoch 9/10, Batch 120/145, Loss: 0.0845
Epoch 9/10, Batch 130/145, Loss: 0.2882
Epoch 9/10, Batch 140/145, Loss: 0.1268
Epoch 9/10, Train Loss: 0.1986, Valid Loss: 0.2262
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1913
Epoch 10/10, Batch 20/145, Loss: 0.1086
Epoch 10/10, Batch 30/145, Loss: 0.0507
Epoch 10/10, Batch 40/145, Loss: 0.1583
Epoch 10/10, Batch 50/145, Loss: 0.2427
Epoch 10/10, Batch 60/145, Loss: 0.2553
Epoch 10/10, Batch 70/145, Loss: 0.1050
Epoch 10/10, Batch 80/145, Loss: 0.3889
Epoch 10/10, Batch 90/145, Loss: 0.0717
Epoch 10/10, Batch 100/145, Loss: 0.1203
Epoch 10/10, Batch 110/145, Loss: 0.1880
Epoch 10/10, Batch 120/145, Loss: 0.2142
Epoch 10/10, Batch 130/145, Loss: 0.1882
Epoch 10/10, Batch 140/145, Loss: 0.3715
Epoch 10/10, Train Loss: 0.1905, Valid Loss: 0.2236
Model saved!
Accuracy: 0.9194
Precision: 0.9177
Recall: 0.9194
F1-score: 0.9183
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5182
Epoch 1/10, Batch 20/145, Loss: 0.9307
Epoch 1/10, Batch 30/145, Loss: 0.9025
Epoch 1/10, Batch 40/145, Loss: 0.7935
Epoch 1/10, Batch 50/145, Loss: 0.6003
Epoch 1/10, Batch 60/145, Loss: 0.6031
Epoch 1/10, Batch 70/145, Loss: 0.4950
Epoch 1/10, Batch 80/145, Loss: 0.4714
Epoch 1/10, Batch 90/145, Loss: 0.5408
Epoch 1/10, Batch 100/145, Loss: 0.4933
Epoch 1/10, Batch 110/145, Loss: 0.4564
Epoch 1/10, Batch 120/145, Loss: 0.6266
Epoch 1/10, Batch 130/145, Loss: 0.4002
Epoch 1/10, Batch 140/145, Loss: 0.4171
Epoch 1/10, Train Loss: 0.6834, Valid Loss: 0.3864
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3022
Epoch 2/10, Batch 20/145, Loss: 0.4177
Epoch 2/10, Batch 30/145, Loss: 0.4060
Epoch 2/10, Batch 40/145, Loss: 0.4596
Epoch 2/10, Batch 50/145, Loss: 0.3904
Epoch 2/10, Batch 60/145, Loss: 0.4934
Epoch 2/10, Batch 70/145, Loss: 0.5158
Epoch 2/10, Batch 80/145, Loss: 0.3222
Epoch 2/10, Batch 90/145, Loss: 0.2921
Epoch 2/10, Batch 100/145, Loss: 0.5330
Epoch 2/10, Batch 110/145, Loss: 0.2485
Epoch 2/10, Batch 120/145, Loss: 0.3863
Epoch 2/10, Batch 130/145, Loss: 0.2603
Epoch 2/10, Batch 140/145, Loss: 0.2301
Epoch 2/10, Train Loss: 0.3585, Valid Loss: 0.2995
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2457
Epoch 3/10, Batch 20/145, Loss: 0.2212
Epoch 3/10, Batch 30/145, Loss: 0.3762
Epoch 3/10, Batch 40/145, Loss: 0.2443
Epoch 3/10, Batch 50/145, Loss: 0.1317
Epoch 3/10, Batch 60/145, Loss: 0.2501
Epoch 3/10, Batch 70/145, Loss: 0.3377
Epoch 3/10, Batch 80/145, Loss: 0.1863
Epoch 3/10, Batch 90/145, Loss: 0.5283
Epoch 3/10, Batch 100/145, Loss: 0.3093
Epoch 3/10, Batch 110/145, Loss: 0.2833
Epoch 3/10, Batch 120/145, Loss: 0.1677
Epoch 3/10, Batch 130/145, Loss: 0.1482
Epoch 3/10, Batch 140/145, Loss: 0.1999
Epoch 3/10, Train Loss: 0.2991, Valid Loss: 0.2675
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1874
Epoch 4/10, Batch 20/145, Loss: 0.1971
Epoch 4/10, Batch 30/145, Loss: 0.2262
Epoch 4/10, Batch 40/145, Loss: 0.6110
Epoch 4/10, Batch 50/145, Loss: 0.1276
Epoch 4/10, Batch 60/145, Loss: 0.2057
Epoch 4/10, Batch 70/145, Loss: 0.1610
Epoch 4/10, Batch 80/145, Loss: 0.2838
Epoch 4/10, Batch 90/145, Loss: 0.2627
Epoch 4/10, Batch 100/145, Loss: 0.1896
Epoch 4/10, Batch 110/145, Loss: 0.2146
Epoch 4/10, Batch 120/145, Loss: 0.1630
Epoch 4/10, Batch 130/145, Loss: 0.1489
Epoch 4/10, Batch 140/145, Loss: 0.2377
Epoch 4/10, Train Loss: 0.2599, Valid Loss: 0.2590
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2848
Epoch 5/10, Batch 20/145, Loss: 0.2932
Epoch 5/10, Batch 30/145, Loss: 0.1896
Epoch 5/10, Batch 40/145, Loss: 0.2034
Epoch 5/10, Batch 50/145, Loss: 0.2487
Epoch 5/10, Batch 60/145, Loss: 0.1004
Epoch 5/10, Batch 70/145, Loss: 0.1997
Epoch 5/10, Batch 80/145, Loss: 0.4442
Epoch 5/10, Batch 90/145, Loss: 0.2819
Epoch 5/10, Batch 100/145, Loss: 0.1433
Epoch 5/10, Batch 110/145, Loss: 0.0696
Epoch 5/10, Batch 120/145, Loss: 0.1947
Epoch 5/10, Batch 130/145, Loss: 0.3916
Epoch 5/10, Batch 140/145, Loss: 0.2055
Epoch 5/10, Train Loss: 0.2393, Valid Loss: 0.2495
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3230
Epoch 6/10, Batch 20/145, Loss: 0.1597
Epoch 6/10, Batch 30/145, Loss: 0.2520
Epoch 6/10, Batch 40/145, Loss: 0.1188
Epoch 6/10, Batch 50/145, Loss: 0.5074
Epoch 6/10, Batch 60/145, Loss: 0.2212
Epoch 6/10, Batch 70/145, Loss: 0.1836
Epoch 6/10, Batch 80/145, Loss: 0.2437
Epoch 6/10, Batch 90/145, Loss: 0.3395
Epoch 6/10, Batch 100/145, Loss: 0.1171
Epoch 6/10, Batch 110/145, Loss: 0.2031
Epoch 6/10, Batch 120/145, Loss: 0.1083
Epoch 6/10, Batch 130/145, Loss: 0.1255
Epoch 6/10, Batch 140/145, Loss: 0.1606
Epoch 6/10, Train Loss: 0.2224, Valid Loss: 0.2423
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1804
Epoch 7/10, Batch 20/145, Loss: 0.2426
Epoch 7/10, Batch 30/145, Loss: 0.1571
Epoch 7/10, Batch 40/145, Loss: 0.2821
Epoch 7/10, Batch 50/145, Loss: 0.2737
Epoch 7/10, Batch 60/145, Loss: 0.1001
Epoch 7/10, Batch 70/145, Loss: 0.3450
Epoch 7/10, Batch 80/145, Loss: 0.0617
Epoch 7/10, Batch 90/145, Loss: 0.1584
Epoch 7/10, Batch 100/145, Loss: 0.1673
Epoch 7/10, Batch 110/145, Loss: 0.3473
Epoch 7/10, Batch 120/145, Loss: 0.1664
Epoch 7/10, Batch 130/145, Loss: 0.3857
Epoch 7/10, Batch 140/145, Loss: 0.2123
Epoch 7/10, Train Loss: 0.2142, Valid Loss: 0.2339
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0734
Epoch 8/10, Batch 20/145, Loss: 0.1968
Epoch 8/10, Batch 30/145, Loss: 0.1084
Epoch 8/10, Batch 40/145, Loss: 0.2163
Epoch 8/10, Batch 50/145, Loss: 0.2118
Epoch 8/10, Batch 60/145, Loss: 0.2646
Epoch 8/10, Batch 70/145, Loss: 0.1056
Epoch 8/10, Batch 80/145, Loss: 0.2116
Epoch 8/10, Batch 90/145, Loss: 0.1355
Epoch 8/10, Batch 100/145, Loss: 0.2928
Epoch 8/10, Batch 110/145, Loss: 0.3307
Epoch 8/10, Batch 120/145, Loss: 0.1825
Epoch 8/10, Batch 130/145, Loss: 0.0926
Epoch 8/10, Batch 140/145, Loss: 0.2876
Epoch 8/10, Train Loss: 0.2015, Valid Loss: 0.2353
Epoch 9/10, Batch 10/145, Loss: 0.2000
Epoch 9/10, Batch 20/145, Loss: 0.1613
Epoch 9/10, Batch 30/145, Loss: 0.1724
Epoch 9/10, Batch 40/145, Loss: 0.1849
Epoch 9/10, Batch 50/145, Loss: 0.0754
Epoch 9/10, Batch 60/145, Loss: 0.2878
Epoch 9/10, Batch 70/145, Loss: 0.1493
Epoch 9/10, Batch 80/145, Loss: 0.1702
Epoch 9/10, Batch 90/145, Loss: 0.0773
Epoch 9/10, Batch 100/145, Loss: 0.1916
Epoch 9/10, Batch 110/145, Loss: 0.1021
Epoch 9/10, Batch 120/145, Loss: 0.1485
Epoch 9/10, Batch 130/145, Loss: 0.1532
Epoch 9/10, Batch 140/145, Loss: 0.1338
Epoch 9/10, Train Loss: 0.1947, Valid Loss: 0.2224
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0995
Epoch 10/10, Batch 20/145, Loss: 0.0964
Epoch 10/10, Batch 30/145, Loss: 0.2129
Epoch 10/10, Batch 40/145, Loss: 0.2325
Epoch 10/10, Batch 50/145, Loss: 0.1843
Epoch 10/10, Batch 60/145, Loss: 0.1765
Epoch 10/10, Batch 70/145, Loss: 0.1271
Epoch 10/10, Batch 80/145, Loss: 0.2731
Epoch 10/10, Batch 90/145, Loss: 0.1339
Epoch 10/10, Batch 100/145, Loss: 0.1108
Epoch 10/10, Batch 110/145, Loss: 0.1457
Epoch 10/10, Batch 120/145, Loss: 0.1659
Epoch 10/10, Batch 130/145, Loss: 0.3340
Epoch 10/10, Batch 140/145, Loss: 0.1890
Epoch 10/10, Train Loss: 0.1901, Valid Loss: 0.2234
Accuracy: 0.9276
Precision: 0.9279
Recall: 0.9276
F1-score: 0.9265
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4492
Epoch 1/10, Batch 20/145, Loss: 0.9125
Epoch 1/10, Batch 30/145, Loss: 0.8506
Epoch 1/10, Batch 40/145, Loss: 0.7110
Epoch 1/10, Batch 50/145, Loss: 0.6760
Epoch 1/10, Batch 60/145, Loss: 0.7021
Epoch 1/10, Batch 70/145, Loss: 0.7107
Epoch 1/10, Batch 80/145, Loss: 0.5472
Epoch 1/10, Batch 90/145, Loss: 0.4702
Epoch 1/10, Batch 100/145, Loss: 0.5587
Epoch 1/10, Batch 110/145, Loss: 0.3524
Epoch 1/10, Batch 120/145, Loss: 0.6629
Epoch 1/10, Batch 130/145, Loss: 0.3930
Epoch 1/10, Batch 140/145, Loss: 0.3945
Epoch 1/10, Train Loss: 0.6814, Valid Loss: 0.3702
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3913
Epoch 2/10, Batch 20/145, Loss: 0.4353
Epoch 2/10, Batch 30/145, Loss: 0.3406
Epoch 2/10, Batch 40/145, Loss: 0.4954
Epoch 2/10, Batch 50/145, Loss: 0.4379
Epoch 2/10, Batch 60/145, Loss: 0.3825
Epoch 2/10, Batch 70/145, Loss: 0.2712
Epoch 2/10, Batch 80/145, Loss: 0.3249
Epoch 2/10, Batch 90/145, Loss: 0.3485
Epoch 2/10, Batch 100/145, Loss: 0.2111
Epoch 2/10, Batch 110/145, Loss: 0.3257
Epoch 2/10, Batch 120/145, Loss: 0.2872
Epoch 2/10, Batch 130/145, Loss: 0.3409
Epoch 2/10, Batch 140/145, Loss: 0.2547
Epoch 2/10, Train Loss: 0.3575, Valid Loss: 0.2921
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1938
Epoch 3/10, Batch 20/145, Loss: 0.4383
Epoch 3/10, Batch 30/145, Loss: 0.3732
Epoch 3/10, Batch 40/145, Loss: 0.2613
Epoch 3/10, Batch 50/145, Loss: 0.2335
Epoch 3/10, Batch 60/145, Loss: 0.3024
Epoch 3/10, Batch 70/145, Loss: 0.1880
Epoch 3/10, Batch 80/145, Loss: 0.3644
Epoch 3/10, Batch 90/145, Loss: 0.5733
Epoch 3/10, Batch 100/145, Loss: 0.2620
Epoch 3/10, Batch 110/145, Loss: 0.2974
Epoch 3/10, Batch 120/145, Loss: 0.1397
Epoch 3/10, Batch 130/145, Loss: 0.2778
Epoch 3/10, Batch 140/145, Loss: 0.1843
Epoch 3/10, Train Loss: 0.3073, Valid Loss: 0.2616
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2462
Epoch 4/10, Batch 20/145, Loss: 0.2600
Epoch 4/10, Batch 30/145, Loss: 0.2571
Epoch 4/10, Batch 40/145, Loss: 0.3122
Epoch 4/10, Batch 50/145, Loss: 0.1696
Epoch 4/10, Batch 60/145, Loss: 0.2028
Epoch 4/10, Batch 70/145, Loss: 0.2719
Epoch 4/10, Batch 80/145, Loss: 0.1867
Epoch 4/10, Batch 90/145, Loss: 0.3569
Epoch 4/10, Batch 100/145, Loss: 0.2590
Epoch 4/10, Batch 110/145, Loss: 0.2275
Epoch 4/10, Batch 120/145, Loss: 0.1659
Epoch 4/10, Batch 130/145, Loss: 0.2164
Epoch 4/10, Batch 140/145, Loss: 0.2192
Epoch 4/10, Train Loss: 0.2641, Valid Loss: 0.2551
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2560
Epoch 5/10, Batch 20/145, Loss: 0.0803
Epoch 5/10, Batch 30/145, Loss: 0.2143
Epoch 5/10, Batch 40/145, Loss: 0.3033
Epoch 5/10, Batch 50/145, Loss: 0.1810
Epoch 5/10, Batch 60/145, Loss: 0.1472
Epoch 5/10, Batch 70/145, Loss: 0.3322
Epoch 5/10, Batch 80/145, Loss: 0.3420
Epoch 5/10, Batch 90/145, Loss: 0.2763
Epoch 5/10, Batch 100/145, Loss: 0.2303
Epoch 5/10, Batch 110/145, Loss: 0.1430
Epoch 5/10, Batch 120/145, Loss: 0.4197
Epoch 5/10, Batch 130/145, Loss: 0.1753
Epoch 5/10, Batch 140/145, Loss: 0.3740
Epoch 5/10, Train Loss: 0.2410, Valid Loss: 0.2400
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1756
Epoch 6/10, Batch 20/145, Loss: 0.1097
Epoch 6/10, Batch 30/145, Loss: 0.3603
Epoch 6/10, Batch 40/145, Loss: 0.0609
Epoch 6/10, Batch 50/145, Loss: 0.2337
Epoch 6/10, Batch 60/145, Loss: 0.2055
Epoch 6/10, Batch 70/145, Loss: 0.3123
Epoch 6/10, Batch 80/145, Loss: 0.1803
Epoch 6/10, Batch 90/145, Loss: 0.2156
Epoch 6/10, Batch 100/145, Loss: 0.1813
Epoch 6/10, Batch 110/145, Loss: 0.1636
Epoch 6/10, Batch 120/145, Loss: 0.2127
Epoch 6/10, Batch 130/145, Loss: 0.2608
Epoch 6/10, Batch 140/145, Loss: 0.1236
Epoch 6/10, Train Loss: 0.2291, Valid Loss: 0.2416
Epoch 7/10, Batch 10/145, Loss: 0.3445
Epoch 7/10, Batch 20/145, Loss: 0.1801
Epoch 7/10, Batch 30/145, Loss: 0.0861
Epoch 7/10, Batch 40/145, Loss: 0.2816
Epoch 7/10, Batch 50/145, Loss: 0.1226
Epoch 7/10, Batch 60/145, Loss: 0.2121
Epoch 7/10, Batch 70/145, Loss: 0.1216
Epoch 7/10, Batch 80/145, Loss: 0.1712
Epoch 7/10, Batch 90/145, Loss: 0.3134
Epoch 7/10, Batch 100/145, Loss: 0.1364
Epoch 7/10, Batch 110/145, Loss: 0.1714
Epoch 7/10, Batch 120/145, Loss: 0.1407
Epoch 7/10, Batch 130/145, Loss: 0.1550
Epoch 7/10, Batch 140/145, Loss: 0.0847
Epoch 7/10, Train Loss: 0.2169, Valid Loss: 0.2309
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2792
Epoch 8/10, Batch 20/145, Loss: 0.1312
Epoch 8/10, Batch 30/145, Loss: 0.1451
Epoch 8/10, Batch 40/145, Loss: 0.2266
Epoch 8/10, Batch 50/145, Loss: 0.2113
Epoch 8/10, Batch 60/145, Loss: 0.1718
Epoch 8/10, Batch 70/145, Loss: 0.1542
Epoch 8/10, Batch 80/145, Loss: 0.2909
Epoch 8/10, Batch 90/145, Loss: 0.1489
Epoch 8/10, Batch 100/145, Loss: 0.3204
Epoch 8/10, Batch 110/145, Loss: 0.3596
Epoch 8/10, Batch 120/145, Loss: 0.3013
Epoch 8/10, Batch 130/145, Loss: 0.1573
Epoch 8/10, Batch 140/145, Loss: 0.1977
Epoch 8/10, Train Loss: 0.2048, Valid Loss: 0.2306
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2898
Epoch 9/10, Batch 20/145, Loss: 0.1017
Epoch 9/10, Batch 30/145, Loss: 0.0775
Epoch 9/10, Batch 40/145, Loss: 0.1074
Epoch 9/10, Batch 50/145, Loss: 0.1501
Epoch 9/10, Batch 60/145, Loss: 0.2051
Epoch 9/10, Batch 70/145, Loss: 0.0972
Epoch 9/10, Batch 80/145, Loss: 0.2203
Epoch 9/10, Batch 90/145, Loss: 0.2327
Epoch 9/10, Batch 100/145, Loss: 0.2739
Epoch 9/10, Batch 110/145, Loss: 0.1341
Epoch 9/10, Batch 120/145, Loss: 0.3546
Epoch 9/10, Batch 130/145, Loss: 0.2157
Epoch 9/10, Batch 140/145, Loss: 0.1783
Epoch 9/10, Train Loss: 0.2008, Valid Loss: 0.2204
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1513
Epoch 10/10, Batch 20/145, Loss: 0.1555
Epoch 10/10, Batch 30/145, Loss: 0.0676
Epoch 10/10, Batch 40/145, Loss: 0.2334
Epoch 10/10, Batch 50/145, Loss: 0.2185
Epoch 10/10, Batch 60/145, Loss: 0.1435
Epoch 10/10, Batch 70/145, Loss: 0.1306
Epoch 10/10, Batch 80/145, Loss: 0.4956
Epoch 10/10, Batch 90/145, Loss: 0.2524
Epoch 10/10, Batch 100/145, Loss: 0.1715
Epoch 10/10, Batch 110/145, Loss: 0.2409
Epoch 10/10, Batch 120/145, Loss: 0.1664
Epoch 10/10, Batch 130/145, Loss: 0.2346
Epoch 10/10, Batch 140/145, Loss: 0.2095
Epoch 10/10, Train Loss: 0.1930, Valid Loss: 0.2153
Model saved!
Accuracy: 0.9276
Precision: 0.9258
Recall: 0.9276
F1-score: 0.9263
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4721
Epoch 1/10, Batch 20/145, Loss: 0.8770
Epoch 1/10, Batch 30/145, Loss: 0.8106
Epoch 1/10, Batch 40/145, Loss: 0.8007
Epoch 1/10, Batch 50/145, Loss: 0.7612
Epoch 1/10, Batch 60/145, Loss: 0.6053
Epoch 1/10, Batch 70/145, Loss: 0.5664
Epoch 1/10, Batch 80/145, Loss: 0.5457
Epoch 1/10, Batch 90/145, Loss: 0.5205
Epoch 1/10, Batch 100/145, Loss: 0.5425
Epoch 1/10, Batch 110/145, Loss: 0.3707
Epoch 1/10, Batch 120/145, Loss: 0.5776
Epoch 1/10, Batch 130/145, Loss: 0.3246
Epoch 1/10, Batch 140/145, Loss: 0.3782
Epoch 1/10, Train Loss: 0.6863, Valid Loss: 0.3646
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3077
Epoch 2/10, Batch 20/145, Loss: 0.5325
Epoch 2/10, Batch 30/145, Loss: 0.3442
Epoch 2/10, Batch 40/145, Loss: 0.6155
Epoch 2/10, Batch 50/145, Loss: 0.2951
Epoch 2/10, Batch 60/145, Loss: 0.4207
Epoch 2/10, Batch 70/145, Loss: 0.4065
Epoch 2/10, Batch 80/145, Loss: 0.3222
Epoch 2/10, Batch 90/145, Loss: 0.3371
Epoch 2/10, Batch 100/145, Loss: 0.4791
Epoch 2/10, Batch 110/145, Loss: 0.3270
Epoch 2/10, Batch 120/145, Loss: 0.2614
Epoch 2/10, Batch 130/145, Loss: 0.4003
Epoch 2/10, Batch 140/145, Loss: 0.2606
Epoch 2/10, Train Loss: 0.3601, Valid Loss: 0.2851
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3105
Epoch 3/10, Batch 20/145, Loss: 0.4205
Epoch 3/10, Batch 30/145, Loss: 0.4006
Epoch 3/10, Batch 40/145, Loss: 0.2426
Epoch 3/10, Batch 50/145, Loss: 0.2195
Epoch 3/10, Batch 60/145, Loss: 0.2502
Epoch 3/10, Batch 70/145, Loss: 0.1866
Epoch 3/10, Batch 80/145, Loss: 0.2603
Epoch 3/10, Batch 90/145, Loss: 0.7491
Epoch 3/10, Batch 100/145, Loss: 0.2075
Epoch 3/10, Batch 110/145, Loss: 0.2289
Epoch 3/10, Batch 120/145, Loss: 0.1986
Epoch 3/10, Batch 130/145, Loss: 0.2698
Epoch 3/10, Batch 140/145, Loss: 0.2133
Epoch 3/10, Train Loss: 0.3100, Valid Loss: 0.2532
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2271
Epoch 4/10, Batch 20/145, Loss: 0.3034
Epoch 4/10, Batch 30/145, Loss: 0.2296
Epoch 4/10, Batch 40/145, Loss: 0.3496
Epoch 4/10, Batch 50/145, Loss: 0.1055
Epoch 4/10, Batch 60/145, Loss: 0.2510
Epoch 4/10, Batch 70/145, Loss: 0.2434
Epoch 4/10, Batch 80/145, Loss: 0.3810
Epoch 4/10, Batch 90/145, Loss: 0.2886
Epoch 4/10, Batch 100/145, Loss: 0.2549
Epoch 4/10, Batch 110/145, Loss: 0.1981
Epoch 4/10, Batch 120/145, Loss: 0.2183
Epoch 4/10, Batch 130/145, Loss: 0.1732
Epoch 4/10, Batch 140/145, Loss: 0.1331
Epoch 4/10, Train Loss: 0.2612, Valid Loss: 0.2438
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3201
Epoch 5/10, Batch 20/145, Loss: 0.2511
Epoch 5/10, Batch 30/145, Loss: 0.2515
Epoch 5/10, Batch 40/145, Loss: 0.2596
Epoch 5/10, Batch 50/145, Loss: 0.1701
Epoch 5/10, Batch 60/145, Loss: 0.1420
Epoch 5/10, Batch 70/145, Loss: 0.2227
Epoch 5/10, Batch 80/145, Loss: 0.3234
Epoch 5/10, Batch 90/145, Loss: 0.1637
Epoch 5/10, Batch 100/145, Loss: 0.3987
Epoch 5/10, Batch 110/145, Loss: 0.1199
Epoch 5/10, Batch 120/145, Loss: 0.1810
Epoch 5/10, Batch 130/145, Loss: 0.1593
Epoch 5/10, Batch 140/145, Loss: 0.3911
Epoch 5/10, Train Loss: 0.2387, Valid Loss: 0.2289
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2369
Epoch 6/10, Batch 20/145, Loss: 0.2744
Epoch 6/10, Batch 30/145, Loss: 0.1601
Epoch 6/10, Batch 40/145, Loss: 0.1310
Epoch 6/10, Batch 50/145, Loss: 0.3047
Epoch 6/10, Batch 60/145, Loss: 0.1612
Epoch 6/10, Batch 70/145, Loss: 0.3677
Epoch 6/10, Batch 80/145, Loss: 0.3838
Epoch 6/10, Batch 90/145, Loss: 0.1811
Epoch 6/10, Batch 100/145, Loss: 0.1748
Epoch 6/10, Batch 110/145, Loss: 0.1691
Epoch 6/10, Batch 120/145, Loss: 0.2353
Epoch 6/10, Batch 130/145, Loss: 0.1069
Epoch 6/10, Batch 140/145, Loss: 0.3521
Epoch 6/10, Train Loss: 0.2288, Valid Loss: 0.2217
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2480
Epoch 7/10, Batch 20/145, Loss: 0.2699
Epoch 7/10, Batch 30/145, Loss: 0.1920
Epoch 7/10, Batch 40/145, Loss: 0.2937
Epoch 7/10, Batch 50/145, Loss: 0.1438
Epoch 7/10, Batch 60/145, Loss: 0.0798
Epoch 7/10, Batch 70/145, Loss: 0.1196
Epoch 7/10, Batch 80/145, Loss: 0.0691
Epoch 7/10, Batch 90/145, Loss: 0.2263
Epoch 7/10, Batch 100/145, Loss: 0.2581
Epoch 7/10, Batch 110/145, Loss: 0.1430
Epoch 7/10, Batch 120/145, Loss: 0.2337
Epoch 7/10, Batch 130/145, Loss: 0.2353
Epoch 7/10, Batch 140/145, Loss: 0.2681
Epoch 7/10, Train Loss: 0.2165, Valid Loss: 0.2179
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1378
Epoch 8/10, Batch 20/145, Loss: 0.1289
Epoch 8/10, Batch 30/145, Loss: 0.1240
Epoch 8/10, Batch 40/145, Loss: 0.2865
Epoch 8/10, Batch 50/145, Loss: 0.1914
Epoch 8/10, Batch 60/145, Loss: 0.2256
Epoch 8/10, Batch 70/145, Loss: 0.2391
Epoch 8/10, Batch 80/145, Loss: 0.1415
Epoch 8/10, Batch 90/145, Loss: 0.1489
Epoch 8/10, Batch 100/145, Loss: 0.3328
Epoch 8/10, Batch 110/145, Loss: 0.3419
Epoch 8/10, Batch 120/145, Loss: 0.2865
Epoch 8/10, Batch 130/145, Loss: 0.1547
Epoch 8/10, Batch 140/145, Loss: 0.2547
Epoch 8/10, Train Loss: 0.2045, Valid Loss: 0.2230
Epoch 9/10, Batch 10/145, Loss: 0.2037
Epoch 9/10, Batch 20/145, Loss: 0.1723
Epoch 9/10, Batch 30/145, Loss: 0.3057
Epoch 9/10, Batch 40/145, Loss: 0.2018
Epoch 9/10, Batch 50/145, Loss: 0.1547
Epoch 9/10, Batch 60/145, Loss: 0.1360
Epoch 9/10, Batch 70/145, Loss: 0.1694
Epoch 9/10, Batch 80/145, Loss: 0.2670
Epoch 9/10, Batch 90/145, Loss: 0.1279
Epoch 9/10, Batch 100/145, Loss: 0.2127
Epoch 9/10, Batch 110/145, Loss: 0.2064
Epoch 9/10, Batch 120/145, Loss: 0.1374
Epoch 9/10, Batch 130/145, Loss: 0.2140
Epoch 9/10, Batch 140/145, Loss: 0.1537
Epoch 9/10, Train Loss: 0.2030, Valid Loss: 0.2170
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1955
Epoch 10/10, Batch 20/145, Loss: 0.2456
Epoch 10/10, Batch 30/145, Loss: 0.1505
Epoch 10/10, Batch 40/145, Loss: 0.1987
Epoch 10/10, Batch 50/145, Loss: 0.2003
Epoch 10/10, Batch 60/145, Loss: 0.1623
Epoch 10/10, Batch 70/145, Loss: 0.0510
Epoch 10/10, Batch 80/145, Loss: 0.3701
Epoch 10/10, Batch 90/145, Loss: 0.2865
Epoch 10/10, Batch 100/145, Loss: 0.1348
Epoch 10/10, Batch 110/145, Loss: 0.2377
Epoch 10/10, Batch 120/145, Loss: 0.2481
Epoch 10/10, Batch 130/145, Loss: 0.2297
Epoch 10/10, Batch 140/145, Loss: 0.3100
Epoch 10/10, Train Loss: 0.1979, Valid Loss: 0.2127
Model saved!
Accuracy: 0.9217
Precision: 0.9203
Recall: 0.9217
F1-score: 0.9208
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5286
Epoch 1/10, Batch 20/145, Loss: 0.9184
Epoch 1/10, Batch 30/145, Loss: 0.7805
Epoch 1/10, Batch 40/145, Loss: 0.8122
Epoch 1/10, Batch 50/145, Loss: 0.6181
Epoch 1/10, Batch 60/145, Loss: 0.6742
Epoch 1/10, Batch 70/145, Loss: 0.6195
Epoch 1/10, Batch 80/145, Loss: 0.4978
Epoch 1/10, Batch 90/145, Loss: 0.4764
Epoch 1/10, Batch 100/145, Loss: 0.5343
Epoch 1/10, Batch 110/145, Loss: 0.3880
Epoch 1/10, Batch 120/145, Loss: 0.7130
Epoch 1/10, Batch 130/145, Loss: 0.2573
Epoch 1/10, Batch 140/145, Loss: 0.4406
Epoch 1/10, Train Loss: 0.6895, Valid Loss: 0.3705
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4342
Epoch 2/10, Batch 20/145, Loss: 0.4541
Epoch 2/10, Batch 30/145, Loss: 0.2700
Epoch 2/10, Batch 40/145, Loss: 0.6083
Epoch 2/10, Batch 50/145, Loss: 0.2101
Epoch 2/10, Batch 60/145, Loss: 0.4772
Epoch 2/10, Batch 70/145, Loss: 0.3696
Epoch 2/10, Batch 80/145, Loss: 0.2788
Epoch 2/10, Batch 90/145, Loss: 0.3183
Epoch 2/10, Batch 100/145, Loss: 0.3048
Epoch 2/10, Batch 110/145, Loss: 0.2244
Epoch 2/10, Batch 120/145, Loss: 0.3484
Epoch 2/10, Batch 130/145, Loss: 0.2770
Epoch 2/10, Batch 140/145, Loss: 0.5663
Epoch 2/10, Train Loss: 0.3632, Valid Loss: 0.2843
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2447
Epoch 3/10, Batch 20/145, Loss: 0.2473
Epoch 3/10, Batch 30/145, Loss: 0.2613
Epoch 3/10, Batch 40/145, Loss: 0.2232
Epoch 3/10, Batch 50/145, Loss: 0.2295
Epoch 3/10, Batch 60/145, Loss: 0.4788
Epoch 3/10, Batch 70/145, Loss: 0.3463
Epoch 3/10, Batch 80/145, Loss: 0.2722
Epoch 3/10, Batch 90/145, Loss: 0.4483
Epoch 3/10, Batch 100/145, Loss: 0.2954
Epoch 3/10, Batch 110/145, Loss: 0.2236
Epoch 3/10, Batch 120/145, Loss: 0.1398
Epoch 3/10, Batch 130/145, Loss: 0.2538
Epoch 3/10, Batch 140/145, Loss: 0.1292
Epoch 3/10, Train Loss: 0.3097, Valid Loss: 0.2577
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2704
Epoch 4/10, Batch 20/145, Loss: 0.1741
Epoch 4/10, Batch 30/145, Loss: 0.2680
Epoch 4/10, Batch 40/145, Loss: 0.1919
Epoch 4/10, Batch 50/145, Loss: 0.2298
Epoch 4/10, Batch 60/145, Loss: 0.1434
Epoch 4/10, Batch 70/145, Loss: 0.2180
Epoch 4/10, Batch 80/145, Loss: 0.3661
Epoch 4/10, Batch 90/145, Loss: 0.2879
Epoch 4/10, Batch 100/145, Loss: 0.1953
Epoch 4/10, Batch 110/145, Loss: 0.2976
Epoch 4/10, Batch 120/145, Loss: 0.2935
Epoch 4/10, Batch 130/145, Loss: 0.2078
Epoch 4/10, Batch 140/145, Loss: 0.2208
Epoch 4/10, Train Loss: 0.2585, Valid Loss: 0.2513
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2172
Epoch 5/10, Batch 20/145, Loss: 0.3168
Epoch 5/10, Batch 30/145, Loss: 0.2520
Epoch 5/10, Batch 40/145, Loss: 0.1645
Epoch 5/10, Batch 50/145, Loss: 0.1572
Epoch 5/10, Batch 60/145, Loss: 0.2216
Epoch 5/10, Batch 70/145, Loss: 0.3753
Epoch 5/10, Batch 80/145, Loss: 0.2108
Epoch 5/10, Batch 90/145, Loss: 0.1290
Epoch 5/10, Batch 100/145, Loss: 0.2850
Epoch 5/10, Batch 110/145, Loss: 0.3053
Epoch 5/10, Batch 120/145, Loss: 0.1467
Epoch 5/10, Batch 130/145, Loss: 0.1593
Epoch 5/10, Batch 140/145, Loss: 0.4318
Epoch 5/10, Train Loss: 0.2371, Valid Loss: 0.2421
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3838
Epoch 6/10, Batch 20/145, Loss: 0.2696
Epoch 6/10, Batch 30/145, Loss: 0.1693
Epoch 6/10, Batch 40/145, Loss: 0.1387
Epoch 6/10, Batch 50/145, Loss: 0.3803
Epoch 6/10, Batch 60/145, Loss: 0.1628
Epoch 6/10, Batch 70/145, Loss: 0.2235
Epoch 6/10, Batch 80/145, Loss: 0.3390
Epoch 6/10, Batch 90/145, Loss: 0.2474
Epoch 6/10, Batch 100/145, Loss: 0.1175
Epoch 6/10, Batch 110/145, Loss: 0.1635
Epoch 6/10, Batch 120/145, Loss: 0.2044
Epoch 6/10, Batch 130/145, Loss: 0.2263
Epoch 6/10, Batch 140/145, Loss: 0.2247
Epoch 6/10, Train Loss: 0.2240, Valid Loss: 0.2384
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3217
Epoch 7/10, Batch 20/145, Loss: 0.4595
Epoch 7/10, Batch 30/145, Loss: 0.1512
Epoch 7/10, Batch 40/145, Loss: 0.3783
Epoch 7/10, Batch 50/145, Loss: 0.1412
Epoch 7/10, Batch 60/145, Loss: 0.2052
Epoch 7/10, Batch 70/145, Loss: 0.2225
Epoch 7/10, Batch 80/145, Loss: 0.2527
Epoch 7/10, Batch 90/145, Loss: 0.4612
Epoch 7/10, Batch 100/145, Loss: 0.1680
Epoch 7/10, Batch 110/145, Loss: 0.1820
Epoch 7/10, Batch 120/145, Loss: 0.2145
Epoch 7/10, Batch 130/145, Loss: 0.2244
Epoch 7/10, Batch 140/145, Loss: 0.0992
Epoch 7/10, Train Loss: 0.2156, Valid Loss: 0.2203
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1669
Epoch 8/10, Batch 20/145, Loss: 0.1387
Epoch 8/10, Batch 30/145, Loss: 0.2253
Epoch 8/10, Batch 40/145, Loss: 0.3349
Epoch 8/10, Batch 50/145, Loss: 0.1779
Epoch 8/10, Batch 60/145, Loss: 0.2525
Epoch 8/10, Batch 70/145, Loss: 0.2759
Epoch 8/10, Batch 80/145, Loss: 0.2815
Epoch 8/10, Batch 90/145, Loss: 0.3142
Epoch 8/10, Batch 100/145, Loss: 0.2266
Epoch 8/10, Batch 110/145, Loss: 0.4290
Epoch 8/10, Batch 120/145, Loss: 0.1350
Epoch 8/10, Batch 130/145, Loss: 0.1348
Epoch 8/10, Batch 140/145, Loss: 0.2601
Epoch 8/10, Train Loss: 0.2096, Valid Loss: 0.2190
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1740
Epoch 9/10, Batch 20/145, Loss: 0.0739
Epoch 9/10, Batch 30/145, Loss: 0.1847
Epoch 9/10, Batch 40/145, Loss: 0.2365
Epoch 9/10, Batch 50/145, Loss: 0.1480
Epoch 9/10, Batch 60/145, Loss: 0.1741
Epoch 9/10, Batch 70/145, Loss: 0.1540
Epoch 9/10, Batch 80/145, Loss: 0.3052
Epoch 9/10, Batch 90/145, Loss: 0.1378
Epoch 9/10, Batch 100/145, Loss: 0.2618
Epoch 9/10, Batch 110/145, Loss: 0.1284
Epoch 9/10, Batch 120/145, Loss: 0.3178
Epoch 9/10, Batch 130/145, Loss: 0.3024
Epoch 9/10, Batch 140/145, Loss: 0.0501
Epoch 9/10, Train Loss: 0.2000, Valid Loss: 0.2055
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1680
Epoch 10/10, Batch 20/145, Loss: 0.0830
Epoch 10/10, Batch 30/145, Loss: 0.2126
Epoch 10/10, Batch 40/145, Loss: 0.2097
Epoch 10/10, Batch 50/145, Loss: 0.2688
Epoch 10/10, Batch 60/145, Loss: 0.2044
Epoch 10/10, Batch 70/145, Loss: 0.1980
Epoch 10/10, Batch 80/145, Loss: 0.4637
Epoch 10/10, Batch 90/145, Loss: 0.1940
Epoch 10/10, Batch 100/145, Loss: 0.1074
Epoch 10/10, Batch 110/145, Loss: 0.2475
Epoch 10/10, Batch 120/145, Loss: 0.2553
Epoch 10/10, Batch 130/145, Loss: 0.1915
Epoch 10/10, Batch 140/145, Loss: 0.3079
Epoch 10/10, Train Loss: 0.1943, Valid Loss: 0.2121
Accuracy: 0.9276
Precision: 0.9257
Recall: 0.9276
F1-score: 0.9262
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4558
Epoch 1/10, Batch 20/145, Loss: 0.9881
Epoch 1/10, Batch 30/145, Loss: 0.8099
Epoch 1/10, Batch 40/145, Loss: 0.8560
Epoch 1/10, Batch 50/145, Loss: 0.6658
Epoch 1/10, Batch 60/145, Loss: 0.4962
Epoch 1/10, Batch 70/145, Loss: 0.6871
Epoch 1/10, Batch 80/145, Loss: 0.4672
Epoch 1/10, Batch 90/145, Loss: 0.4974
Epoch 1/10, Batch 100/145, Loss: 0.5538
Epoch 1/10, Batch 110/145, Loss: 0.4055
Epoch 1/10, Batch 120/145, Loss: 0.5851
Epoch 1/10, Batch 130/145, Loss: 0.4260
Epoch 1/10, Batch 140/145, Loss: 0.3802
Epoch 1/10, Train Loss: 0.6855, Valid Loss: 0.3969
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3916
Epoch 2/10, Batch 20/145, Loss: 0.3738
Epoch 2/10, Batch 30/145, Loss: 0.2485
Epoch 2/10, Batch 40/145, Loss: 0.4714
Epoch 2/10, Batch 50/145, Loss: 0.3259
Epoch 2/10, Batch 60/145, Loss: 0.5284
Epoch 2/10, Batch 70/145, Loss: 0.3052
Epoch 2/10, Batch 80/145, Loss: 0.3511
Epoch 2/10, Batch 90/145, Loss: 0.3823
Epoch 2/10, Batch 100/145, Loss: 0.3149
Epoch 2/10, Batch 110/145, Loss: 0.2175
Epoch 2/10, Batch 120/145, Loss: 0.3378
Epoch 2/10, Batch 130/145, Loss: 0.3686
Epoch 2/10, Batch 140/145, Loss: 0.3808
Epoch 2/10, Train Loss: 0.3636, Valid Loss: 0.3107
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3192
Epoch 3/10, Batch 20/145, Loss: 0.3327
Epoch 3/10, Batch 30/145, Loss: 0.3218
Epoch 3/10, Batch 40/145, Loss: 0.2478
Epoch 3/10, Batch 50/145, Loss: 0.2690
Epoch 3/10, Batch 60/145, Loss: 0.3424
Epoch 3/10, Batch 70/145, Loss: 0.2232
Epoch 3/10, Batch 80/145, Loss: 0.1750
Epoch 3/10, Batch 90/145, Loss: 0.5046
Epoch 3/10, Batch 100/145, Loss: 0.1957
Epoch 3/10, Batch 110/145, Loss: 0.2824
Epoch 3/10, Batch 120/145, Loss: 0.1778
Epoch 3/10, Batch 130/145, Loss: 0.2465
Epoch 3/10, Batch 140/145, Loss: 0.2698
Epoch 3/10, Train Loss: 0.3084, Valid Loss: 0.2813
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1369
Epoch 4/10, Batch 20/145, Loss: 0.2830
Epoch 4/10, Batch 30/145, Loss: 0.4285
Epoch 4/10, Batch 40/145, Loss: 0.2935
Epoch 4/10, Batch 50/145, Loss: 0.1468
Epoch 4/10, Batch 60/145, Loss: 0.1855
Epoch 4/10, Batch 70/145, Loss: 0.1982
Epoch 4/10, Batch 80/145, Loss: 0.2070
Epoch 4/10, Batch 90/145, Loss: 0.1987
Epoch 4/10, Batch 100/145, Loss: 0.2469
Epoch 4/10, Batch 110/145, Loss: 0.2101
Epoch 4/10, Batch 120/145, Loss: 0.1447
Epoch 4/10, Batch 130/145, Loss: 0.1522
Epoch 4/10, Batch 140/145, Loss: 0.2198
Epoch 4/10, Train Loss: 0.2549, Valid Loss: 0.2689
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3580
Epoch 5/10, Batch 20/145, Loss: 0.2109
Epoch 5/10, Batch 30/145, Loss: 0.3344
Epoch 5/10, Batch 40/145, Loss: 0.3775
Epoch 5/10, Batch 50/145, Loss: 0.1507
Epoch 5/10, Batch 60/145, Loss: 0.2037
Epoch 5/10, Batch 70/145, Loss: 0.1798
Epoch 5/10, Batch 80/145, Loss: 0.1752
Epoch 5/10, Batch 90/145, Loss: 0.1668
Epoch 5/10, Batch 100/145, Loss: 0.2156
Epoch 5/10, Batch 110/145, Loss: 0.1272
Epoch 5/10, Batch 120/145, Loss: 0.1490
Epoch 5/10, Batch 130/145, Loss: 0.3378
Epoch 5/10, Batch 140/145, Loss: 0.1885
Epoch 5/10, Train Loss: 0.2365, Valid Loss: 0.2528
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2888
Epoch 6/10, Batch 20/145, Loss: 0.1697
Epoch 6/10, Batch 30/145, Loss: 0.4808
Epoch 6/10, Batch 40/145, Loss: 0.1784
Epoch 6/10, Batch 50/145, Loss: 0.2635
Epoch 6/10, Batch 60/145, Loss: 0.1339
Epoch 6/10, Batch 70/145, Loss: 0.2178
Epoch 6/10, Batch 80/145, Loss: 0.2787
Epoch 6/10, Batch 90/145, Loss: 0.1854
Epoch 6/10, Batch 100/145, Loss: 0.1941
Epoch 6/10, Batch 110/145, Loss: 0.1747
Epoch 6/10, Batch 120/145, Loss: 0.2402
Epoch 6/10, Batch 130/145, Loss: 0.2061
Epoch 6/10, Batch 140/145, Loss: 0.2363
Epoch 6/10, Train Loss: 0.2226, Valid Loss: 0.2524
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1959
Epoch 7/10, Batch 20/145, Loss: 0.1550
Epoch 7/10, Batch 30/145, Loss: 0.1323
Epoch 7/10, Batch 40/145, Loss: 0.4651
Epoch 7/10, Batch 50/145, Loss: 0.3235
Epoch 7/10, Batch 60/145, Loss: 0.1626
Epoch 7/10, Batch 70/145, Loss: 0.3704
Epoch 7/10, Batch 80/145, Loss: 0.0994
Epoch 7/10, Batch 90/145, Loss: 0.2699
Epoch 7/10, Batch 100/145, Loss: 0.1279
Epoch 7/10, Batch 110/145, Loss: 0.1777
Epoch 7/10, Batch 120/145, Loss: 0.2001
Epoch 7/10, Batch 130/145, Loss: 0.1751
Epoch 7/10, Batch 140/145, Loss: 0.0929
Epoch 7/10, Train Loss: 0.2131, Valid Loss: 0.2399
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1576
Epoch 8/10, Batch 20/145, Loss: 0.2149
Epoch 8/10, Batch 30/145, Loss: 0.1790
Epoch 8/10, Batch 40/145, Loss: 0.2127
Epoch 8/10, Batch 50/145, Loss: 0.2387
Epoch 8/10, Batch 60/145, Loss: 0.2588
Epoch 8/10, Batch 70/145, Loss: 0.2163
Epoch 8/10, Batch 80/145, Loss: 0.2310
Epoch 8/10, Batch 90/145, Loss: 0.1616
Epoch 8/10, Batch 100/145, Loss: 0.3432
Epoch 8/10, Batch 110/145, Loss: 0.2234
Epoch 8/10, Batch 120/145, Loss: 0.1844
Epoch 8/10, Batch 130/145, Loss: 0.0830
Epoch 8/10, Batch 140/145, Loss: 0.2505
Epoch 8/10, Train Loss: 0.2114, Valid Loss: 0.2293
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2341
Epoch 9/10, Batch 20/145, Loss: 0.1599
Epoch 9/10, Batch 30/145, Loss: 0.1193
Epoch 9/10, Batch 40/145, Loss: 0.2389
Epoch 9/10, Batch 50/145, Loss: 0.1600
Epoch 9/10, Batch 60/145, Loss: 0.1720
Epoch 9/10, Batch 70/145, Loss: 0.3113
Epoch 9/10, Batch 80/145, Loss: 0.2091
Epoch 9/10, Batch 90/145, Loss: 0.2292
Epoch 9/10, Batch 100/145, Loss: 0.3072
Epoch 9/10, Batch 110/145, Loss: 0.1765
Epoch 9/10, Batch 120/145, Loss: 0.2701
Epoch 9/10, Batch 130/145, Loss: 0.1962
Epoch 9/10, Batch 140/145, Loss: 0.1595
Epoch 9/10, Train Loss: 0.2048, Valid Loss: 0.2348
Epoch 10/10, Batch 10/145, Loss: 0.1184
Epoch 10/10, Batch 20/145, Loss: 0.0592
Epoch 10/10, Batch 30/145, Loss: 0.1988
Epoch 10/10, Batch 40/145, Loss: 0.2079
Epoch 10/10, Batch 50/145, Loss: 0.2671
Epoch 10/10, Batch 60/145, Loss: 0.1494
Epoch 10/10, Batch 70/145, Loss: 0.1361
Epoch 10/10, Batch 80/145, Loss: 0.4725
Epoch 10/10, Batch 90/145, Loss: 0.2186
Epoch 10/10, Batch 100/145, Loss: 0.1099
Epoch 10/10, Batch 110/145, Loss: 0.1000
Epoch 10/10, Batch 120/145, Loss: 0.1397
Epoch 10/10, Batch 130/145, Loss: 0.2574
Epoch 10/10, Batch 140/145, Loss: 0.2959
Epoch 10/10, Train Loss: 0.2005, Valid Loss: 0.2261
Model saved!
Accuracy: 0.9217
Precision: 0.9211
Recall: 0.9217
F1-score: 0.9208
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4854
Epoch 1/10, Batch 20/145, Loss: 1.0022
Epoch 1/10, Batch 30/145, Loss: 0.8938
Epoch 1/10, Batch 40/145, Loss: 0.7649
Epoch 1/10, Batch 50/145, Loss: 0.7609
Epoch 1/10, Batch 60/145, Loss: 0.6119
Epoch 1/10, Batch 70/145, Loss: 0.6131
Epoch 1/10, Batch 80/145, Loss: 0.5625
Epoch 1/10, Batch 90/145, Loss: 0.5308
Epoch 1/10, Batch 100/145, Loss: 0.5708
Epoch 1/10, Batch 110/145, Loss: 0.4019
Epoch 1/10, Batch 120/145, Loss: 0.5147
Epoch 1/10, Batch 130/145, Loss: 0.3430
Epoch 1/10, Batch 140/145, Loss: 0.3965
Epoch 1/10, Train Loss: 0.6905, Valid Loss: 0.3634
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3739
Epoch 2/10, Batch 20/145, Loss: 0.4416
Epoch 2/10, Batch 30/145, Loss: 0.2532
Epoch 2/10, Batch 40/145, Loss: 0.4590
Epoch 2/10, Batch 50/145, Loss: 0.2784
Epoch 2/10, Batch 60/145, Loss: 0.3003
Epoch 2/10, Batch 70/145, Loss: 0.2935
Epoch 2/10, Batch 80/145, Loss: 0.2476
Epoch 2/10, Batch 90/145, Loss: 0.2734
Epoch 2/10, Batch 100/145, Loss: 0.3092
Epoch 2/10, Batch 110/145, Loss: 0.2881
Epoch 2/10, Batch 120/145, Loss: 0.6400
Epoch 2/10, Batch 130/145, Loss: 0.2782
Epoch 2/10, Batch 140/145, Loss: 0.2933
Epoch 2/10, Train Loss: 0.3633, Valid Loss: 0.2873
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2453
Epoch 3/10, Batch 20/145, Loss: 0.3468
Epoch 3/10, Batch 30/145, Loss: 0.3034
Epoch 3/10, Batch 40/145, Loss: 0.1731
Epoch 3/10, Batch 50/145, Loss: 0.2661
Epoch 3/10, Batch 60/145, Loss: 0.3728
Epoch 3/10, Batch 70/145, Loss: 0.2858
Epoch 3/10, Batch 80/145, Loss: 0.1469
Epoch 3/10, Batch 90/145, Loss: 0.6064
Epoch 3/10, Batch 100/145, Loss: 0.2197
Epoch 3/10, Batch 110/145, Loss: 0.2964
Epoch 3/10, Batch 120/145, Loss: 0.1379
Epoch 3/10, Batch 130/145, Loss: 0.1768
Epoch 3/10, Batch 140/145, Loss: 0.1739
Epoch 3/10, Train Loss: 0.3035, Valid Loss: 0.2442
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2306
Epoch 4/10, Batch 20/145, Loss: 0.3519
Epoch 4/10, Batch 30/145, Loss: 0.3216
Epoch 4/10, Batch 40/145, Loss: 0.3552
Epoch 4/10, Batch 50/145, Loss: 0.2206
Epoch 4/10, Batch 60/145, Loss: 0.1626
Epoch 4/10, Batch 70/145, Loss: 0.3441
Epoch 4/10, Batch 80/145, Loss: 0.2653
Epoch 4/10, Batch 90/145, Loss: 0.2118
Epoch 4/10, Batch 100/145, Loss: 0.2475
Epoch 4/10, Batch 110/145, Loss: 0.1896
Epoch 4/10, Batch 120/145, Loss: 0.2054
Epoch 4/10, Batch 130/145, Loss: 0.2286
Epoch 4/10, Batch 140/145, Loss: 0.2099
Epoch 4/10, Train Loss: 0.2661, Valid Loss: 0.2390
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1536
Epoch 5/10, Batch 20/145, Loss: 0.2201
Epoch 5/10, Batch 30/145, Loss: 0.2020
Epoch 5/10, Batch 40/145, Loss: 0.2261
Epoch 5/10, Batch 50/145, Loss: 0.1270
Epoch 5/10, Batch 60/145, Loss: 0.1308
Epoch 5/10, Batch 70/145, Loss: 0.1883
Epoch 5/10, Batch 80/145, Loss: 0.2063
Epoch 5/10, Batch 90/145, Loss: 0.3051
Epoch 5/10, Batch 100/145, Loss: 0.3689
Epoch 5/10, Batch 110/145, Loss: 0.1289
Epoch 5/10, Batch 120/145, Loss: 0.1853
Epoch 5/10, Batch 130/145, Loss: 0.2677
Epoch 5/10, Batch 140/145, Loss: 0.1846
Epoch 5/10, Train Loss: 0.2373, Valid Loss: 0.2223
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2648
Epoch 6/10, Batch 20/145, Loss: 0.1690
Epoch 6/10, Batch 30/145, Loss: 0.3272
Epoch 6/10, Batch 40/145, Loss: 0.1039
Epoch 6/10, Batch 50/145, Loss: 0.1449
Epoch 6/10, Batch 60/145, Loss: 0.1965
Epoch 6/10, Batch 70/145, Loss: 0.1950
Epoch 6/10, Batch 80/145, Loss: 0.2298
Epoch 6/10, Batch 90/145, Loss: 0.1604
Epoch 6/10, Batch 100/145, Loss: 0.1424
Epoch 6/10, Batch 110/145, Loss: 0.2139
Epoch 6/10, Batch 120/145, Loss: 0.3036
Epoch 6/10, Batch 130/145, Loss: 0.1123
Epoch 6/10, Batch 140/145, Loss: 0.3118
Epoch 6/10, Train Loss: 0.2244, Valid Loss: 0.2129
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.4260
Epoch 7/10, Batch 20/145, Loss: 0.2450
Epoch 7/10, Batch 30/145, Loss: 0.2062
Epoch 7/10, Batch 40/145, Loss: 0.5444
Epoch 7/10, Batch 50/145, Loss: 0.2312
Epoch 7/10, Batch 60/145, Loss: 0.1648
Epoch 7/10, Batch 70/145, Loss: 0.2079
Epoch 7/10, Batch 80/145, Loss: 0.1634
Epoch 7/10, Batch 90/145, Loss: 0.1493
Epoch 7/10, Batch 100/145, Loss: 0.1746
Epoch 7/10, Batch 110/145, Loss: 0.1630
Epoch 7/10, Batch 120/145, Loss: 0.1985
Epoch 7/10, Batch 130/145, Loss: 0.2721
Epoch 7/10, Batch 140/145, Loss: 0.1592
Epoch 7/10, Train Loss: 0.2143, Valid Loss: 0.2053
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1241
Epoch 8/10, Batch 20/145, Loss: 0.1945
Epoch 8/10, Batch 30/145, Loss: 0.2078
Epoch 8/10, Batch 40/145, Loss: 0.1906
Epoch 8/10, Batch 50/145, Loss: 0.2061
Epoch 8/10, Batch 60/145, Loss: 0.2858
Epoch 8/10, Batch 70/145, Loss: 0.1470
Epoch 8/10, Batch 80/145, Loss: 0.1106
Epoch 8/10, Batch 90/145, Loss: 0.1634
Epoch 8/10, Batch 100/145, Loss: 0.1569
Epoch 8/10, Batch 110/145, Loss: 0.2086
Epoch 8/10, Batch 120/145, Loss: 0.1477
Epoch 8/10, Batch 130/145, Loss: 0.1963
Epoch 8/10, Batch 140/145, Loss: 0.2162
Epoch 8/10, Train Loss: 0.2046, Valid Loss: 0.2092
Epoch 9/10, Batch 10/145, Loss: 0.3311
Epoch 9/10, Batch 20/145, Loss: 0.1884
Epoch 9/10, Batch 30/145, Loss: 0.1028
Epoch 9/10, Batch 40/145, Loss: 0.1348
Epoch 9/10, Batch 50/145, Loss: 0.1562
Epoch 9/10, Batch 60/145, Loss: 0.1770
Epoch 9/10, Batch 70/145, Loss: 0.1662
Epoch 9/10, Batch 80/145, Loss: 0.2138
Epoch 9/10, Batch 90/145, Loss: 0.1105
Epoch 9/10, Batch 100/145, Loss: 0.1870
Epoch 9/10, Batch 110/145, Loss: 0.0641
Epoch 9/10, Batch 120/145, Loss: 0.1907
Epoch 9/10, Batch 130/145, Loss: 0.2506
Epoch 9/10, Batch 140/145, Loss: 0.0482
Epoch 9/10, Train Loss: 0.2034, Valid Loss: 0.1962
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2504
Epoch 10/10, Batch 20/145, Loss: 0.1478
Epoch 10/10, Batch 30/145, Loss: 0.1357
Epoch 10/10, Batch 40/145, Loss: 0.1568
Epoch 10/10, Batch 50/145, Loss: 0.1356
Epoch 10/10, Batch 60/145, Loss: 0.2292
Epoch 10/10, Batch 70/145, Loss: 0.1408
Epoch 10/10, Batch 80/145, Loss: 0.2068
Epoch 10/10, Batch 90/145, Loss: 0.1339
Epoch 10/10, Batch 100/145, Loss: 0.2168
Epoch 10/10, Batch 110/145, Loss: 0.3364
Epoch 10/10, Batch 120/145, Loss: 0.1157
Epoch 10/10, Batch 130/145, Loss: 0.2916
Epoch 10/10, Batch 140/145, Loss: 0.2013
Epoch 10/10, Train Loss: 0.1968, Valid Loss: 0.1992
Accuracy: 0.9229
Precision: 0.9210
Recall: 0.9229
F1-score: 0.9217
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5323
Epoch 1/10, Batch 20/145, Loss: 0.8453
Epoch 1/10, Batch 30/145, Loss: 0.8882
Epoch 1/10, Batch 40/145, Loss: 0.8916
Epoch 1/10, Batch 50/145, Loss: 0.6765
Epoch 1/10, Batch 60/145, Loss: 0.4799
Epoch 1/10, Batch 70/145, Loss: 0.7382
Epoch 1/10, Batch 80/145, Loss: 0.4266
Epoch 1/10, Batch 90/145, Loss: 0.5775
Epoch 1/10, Batch 100/145, Loss: 0.6663
Epoch 1/10, Batch 110/145, Loss: 0.3679
Epoch 1/10, Batch 120/145, Loss: 0.5848
Epoch 1/10, Batch 130/145, Loss: 0.3926
Epoch 1/10, Batch 140/145, Loss: 0.4331
Epoch 1/10, Train Loss: 0.6889, Valid Loss: 0.3813
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3585
Epoch 2/10, Batch 20/145, Loss: 0.4796
Epoch 2/10, Batch 30/145, Loss: 0.3989
Epoch 2/10, Batch 40/145, Loss: 0.5667
Epoch 2/10, Batch 50/145, Loss: 0.2650
Epoch 2/10, Batch 60/145, Loss: 0.3384
Epoch 2/10, Batch 70/145, Loss: 0.3510
Epoch 2/10, Batch 80/145, Loss: 0.2728
Epoch 2/10, Batch 90/145, Loss: 0.3106
Epoch 2/10, Batch 100/145, Loss: 0.2449
Epoch 2/10, Batch 110/145, Loss: 0.2354
Epoch 2/10, Batch 120/145, Loss: 0.4194
Epoch 2/10, Batch 130/145, Loss: 0.4579
Epoch 2/10, Batch 140/145, Loss: 0.3374
Epoch 2/10, Train Loss: 0.3597, Valid Loss: 0.3014
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2984
Epoch 3/10, Batch 20/145, Loss: 0.1412
Epoch 3/10, Batch 30/145, Loss: 0.2444
Epoch 3/10, Batch 40/145, Loss: 0.2489
Epoch 3/10, Batch 50/145, Loss: 0.2963
Epoch 3/10, Batch 60/145, Loss: 0.2938
Epoch 3/10, Batch 70/145, Loss: 0.2009
Epoch 3/10, Batch 80/145, Loss: 0.2656
Epoch 3/10, Batch 90/145, Loss: 0.6840
Epoch 3/10, Batch 100/145, Loss: 0.2834
Epoch 3/10, Batch 110/145, Loss: 0.3584
Epoch 3/10, Batch 120/145, Loss: 0.1052
Epoch 3/10, Batch 130/145, Loss: 0.2424
Epoch 3/10, Batch 140/145, Loss: 0.2058
Epoch 3/10, Train Loss: 0.3012, Valid Loss: 0.2683
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1972
Epoch 4/10, Batch 20/145, Loss: 0.1519
Epoch 4/10, Batch 30/145, Loss: 0.2432
Epoch 4/10, Batch 40/145, Loss: 0.2878
Epoch 4/10, Batch 50/145, Loss: 0.2426
Epoch 4/10, Batch 60/145, Loss: 0.1879
Epoch 4/10, Batch 70/145, Loss: 0.3094
Epoch 4/10, Batch 80/145, Loss: 0.1938
Epoch 4/10, Batch 90/145, Loss: 0.1977
Epoch 4/10, Batch 100/145, Loss: 0.2194
Epoch 4/10, Batch 110/145, Loss: 0.1854
Epoch 4/10, Batch 120/145, Loss: 0.1436
Epoch 4/10, Batch 130/145, Loss: 0.1880
Epoch 4/10, Batch 140/145, Loss: 0.1661
Epoch 4/10, Train Loss: 0.2596, Valid Loss: 0.2441
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2612
Epoch 5/10, Batch 20/145, Loss: 0.2524
Epoch 5/10, Batch 30/145, Loss: 0.0897
Epoch 5/10, Batch 40/145, Loss: 0.2400
Epoch 5/10, Batch 50/145, Loss: 0.1114
Epoch 5/10, Batch 60/145, Loss: 0.3479
Epoch 5/10, Batch 70/145, Loss: 0.2320
Epoch 5/10, Batch 80/145, Loss: 0.2607
Epoch 5/10, Batch 90/145, Loss: 0.1915
Epoch 5/10, Batch 100/145, Loss: 0.3138
Epoch 5/10, Batch 110/145, Loss: 0.0880
Epoch 5/10, Batch 120/145, Loss: 0.1704
Epoch 5/10, Batch 130/145, Loss: 0.2307
Epoch 5/10, Batch 140/145, Loss: 0.2045
Epoch 5/10, Train Loss: 0.2282, Valid Loss: 0.2355
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2053
Epoch 6/10, Batch 20/145, Loss: 0.2739
Epoch 6/10, Batch 30/145, Loss: 0.2660
Epoch 6/10, Batch 40/145, Loss: 0.1188
Epoch 6/10, Batch 50/145, Loss: 0.2007
Epoch 6/10, Batch 60/145, Loss: 0.1136
Epoch 6/10, Batch 70/145, Loss: 0.2897
Epoch 6/10, Batch 80/145, Loss: 0.2255
Epoch 6/10, Batch 90/145, Loss: 0.2418
Epoch 6/10, Batch 100/145, Loss: 0.1897
Epoch 6/10, Batch 110/145, Loss: 0.1255
Epoch 6/10, Batch 120/145, Loss: 0.3225
Epoch 6/10, Batch 130/145, Loss: 0.1529
Epoch 6/10, Batch 140/145, Loss: 0.3200
Epoch 6/10, Train Loss: 0.2232, Valid Loss: 0.2380
Epoch 7/10, Batch 10/145, Loss: 0.3600
Epoch 7/10, Batch 20/145, Loss: 0.2297
Epoch 7/10, Batch 30/145, Loss: 0.1662
Epoch 7/10, Batch 40/145, Loss: 0.3721
Epoch 7/10, Batch 50/145, Loss: 0.1890
Epoch 7/10, Batch 60/145, Loss: 0.2296
Epoch 7/10, Batch 70/145, Loss: 0.3119
Epoch 7/10, Batch 80/145, Loss: 0.2233
Epoch 7/10, Batch 90/145, Loss: 0.2418
Epoch 7/10, Batch 100/145, Loss: 0.1381
Epoch 7/10, Batch 110/145, Loss: 0.2243
Epoch 7/10, Batch 120/145, Loss: 0.2177
Epoch 7/10, Batch 130/145, Loss: 0.2167
Epoch 7/10, Batch 140/145, Loss: 0.1028
Epoch 7/10, Train Loss: 0.2154, Valid Loss: 0.2303
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1084
Epoch 8/10, Batch 20/145, Loss: 0.1352
Epoch 8/10, Batch 30/145, Loss: 0.2035
Epoch 8/10, Batch 40/145, Loss: 0.1687
Epoch 8/10, Batch 50/145, Loss: 0.1976
Epoch 8/10, Batch 60/145, Loss: 0.2149
Epoch 8/10, Batch 70/145, Loss: 0.3731
Epoch 8/10, Batch 80/145, Loss: 0.1897
Epoch 8/10, Batch 90/145, Loss: 0.1357
Epoch 8/10, Batch 100/145, Loss: 0.2292
Epoch 8/10, Batch 110/145, Loss: 0.3005
Epoch 8/10, Batch 120/145, Loss: 0.2409
Epoch 8/10, Batch 130/145, Loss: 0.2101
Epoch 8/10, Batch 140/145, Loss: 0.2471
Epoch 8/10, Train Loss: 0.2006, Valid Loss: 0.2302
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2293
Epoch 9/10, Batch 20/145, Loss: 0.1201
Epoch 9/10, Batch 30/145, Loss: 0.1292
Epoch 9/10, Batch 40/145, Loss: 0.2836
Epoch 9/10, Batch 50/145, Loss: 0.1179
Epoch 9/10, Batch 60/145, Loss: 0.2178
Epoch 9/10, Batch 70/145, Loss: 0.1924
Epoch 9/10, Batch 80/145, Loss: 0.1596
Epoch 9/10, Batch 90/145, Loss: 0.2575
Epoch 9/10, Batch 100/145, Loss: 0.1393
Epoch 9/10, Batch 110/145, Loss: 0.1430
Epoch 9/10, Batch 120/145, Loss: 0.3686
Epoch 9/10, Batch 130/145, Loss: 0.1689
Epoch 9/10, Batch 140/145, Loss: 0.0937
Epoch 9/10, Train Loss: 0.1977, Valid Loss: 0.2246
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2361
Epoch 10/10, Batch 20/145, Loss: 0.1077
Epoch 10/10, Batch 30/145, Loss: 0.1230
Epoch 10/10, Batch 40/145, Loss: 0.1623
Epoch 10/10, Batch 50/145, Loss: 0.2003
Epoch 10/10, Batch 60/145, Loss: 0.1962
Epoch 10/10, Batch 70/145, Loss: 0.1379
Epoch 10/10, Batch 80/145, Loss: 0.4654
Epoch 10/10, Batch 90/145, Loss: 0.1444
Epoch 10/10, Batch 100/145, Loss: 0.2032
Epoch 10/10, Batch 110/145, Loss: 0.2011
Epoch 10/10, Batch 120/145, Loss: 0.3023
Epoch 10/10, Batch 130/145, Loss: 0.2261
Epoch 10/10, Batch 140/145, Loss: 0.0906
Epoch 10/10, Train Loss: 0.1894, Valid Loss: 0.2249
Accuracy: 0.9182
Precision: 0.9162
Recall: 0.9182
F1-score: 0.9164
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5280
Epoch 1/10, Batch 20/145, Loss: 0.9109
Epoch 1/10, Batch 30/145, Loss: 0.8593
Epoch 1/10, Batch 40/145, Loss: 0.7444
Epoch 1/10, Batch 50/145, Loss: 0.6468
Epoch 1/10, Batch 60/145, Loss: 0.6262
Epoch 1/10, Batch 70/145, Loss: 0.5543
Epoch 1/10, Batch 80/145, Loss: 0.4892
Epoch 1/10, Batch 90/145, Loss: 0.5112
Epoch 1/10, Batch 100/145, Loss: 0.6289
Epoch 1/10, Batch 110/145, Loss: 0.4901
Epoch 1/10, Batch 120/145, Loss: 0.6377
Epoch 1/10, Batch 130/145, Loss: 0.5114
Epoch 1/10, Batch 140/145, Loss: 0.3540
Epoch 1/10, Train Loss: 0.6832, Valid Loss: 0.3869
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2853
Epoch 2/10, Batch 20/145, Loss: 0.5078
Epoch 2/10, Batch 30/145, Loss: 0.2270
Epoch 2/10, Batch 40/145, Loss: 0.5987
Epoch 2/10, Batch 50/145, Loss: 0.3886
Epoch 2/10, Batch 60/145, Loss: 0.4198
Epoch 2/10, Batch 70/145, Loss: 0.4827
Epoch 2/10, Batch 80/145, Loss: 0.2486
Epoch 2/10, Batch 90/145, Loss: 0.2571
Epoch 2/10, Batch 100/145, Loss: 0.2205
Epoch 2/10, Batch 110/145, Loss: 0.2408
Epoch 2/10, Batch 120/145, Loss: 0.5200
Epoch 2/10, Batch 130/145, Loss: 0.4518
Epoch 2/10, Batch 140/145, Loss: 0.2802
Epoch 2/10, Train Loss: 0.3589, Valid Loss: 0.2945
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2302
Epoch 3/10, Batch 20/145, Loss: 0.3663
Epoch 3/10, Batch 30/145, Loss: 0.2811
Epoch 3/10, Batch 40/145, Loss: 0.1613
Epoch 3/10, Batch 50/145, Loss: 0.2641
Epoch 3/10, Batch 60/145, Loss: 0.2885
Epoch 3/10, Batch 70/145, Loss: 0.3950
Epoch 3/10, Batch 80/145, Loss: 0.3000
Epoch 3/10, Batch 90/145, Loss: 0.5575
Epoch 3/10, Batch 100/145, Loss: 0.3263
Epoch 3/10, Batch 110/145, Loss: 0.1595
Epoch 3/10, Batch 120/145, Loss: 0.2057
Epoch 3/10, Batch 130/145, Loss: 0.2972
Epoch 3/10, Batch 140/145, Loss: 0.1933
Epoch 3/10, Train Loss: 0.3048, Valid Loss: 0.2695
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1299
Epoch 4/10, Batch 20/145, Loss: 0.3347
Epoch 4/10, Batch 30/145, Loss: 0.2964
Epoch 4/10, Batch 40/145, Loss: 0.3439
Epoch 4/10, Batch 50/145, Loss: 0.3654
Epoch 4/10, Batch 60/145, Loss: 0.2042
Epoch 4/10, Batch 70/145, Loss: 0.1629
Epoch 4/10, Batch 80/145, Loss: 0.2627
Epoch 4/10, Batch 90/145, Loss: 0.2594
Epoch 4/10, Batch 100/145, Loss: 0.1594
Epoch 4/10, Batch 110/145, Loss: 0.0988
Epoch 4/10, Batch 120/145, Loss: 0.2105
Epoch 4/10, Batch 130/145, Loss: 0.2150
Epoch 4/10, Batch 140/145, Loss: 0.2640
Epoch 4/10, Train Loss: 0.2694, Valid Loss: 0.2541
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1943
Epoch 5/10, Batch 20/145, Loss: 0.2219
Epoch 5/10, Batch 30/145, Loss: 0.1879
Epoch 5/10, Batch 40/145, Loss: 0.2582
Epoch 5/10, Batch 50/145, Loss: 0.1464
Epoch 5/10, Batch 60/145, Loss: 0.4057
Epoch 5/10, Batch 70/145, Loss: 0.2562
Epoch 5/10, Batch 80/145, Loss: 0.2350
Epoch 5/10, Batch 90/145, Loss: 0.2254
Epoch 5/10, Batch 100/145, Loss: 0.4355
Epoch 5/10, Batch 110/145, Loss: 0.1732
Epoch 5/10, Batch 120/145, Loss: 0.1658
Epoch 5/10, Batch 130/145, Loss: 0.1986
Epoch 5/10, Batch 140/145, Loss: 0.4328
Epoch 5/10, Train Loss: 0.2426, Valid Loss: 0.2309
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1946
Epoch 6/10, Batch 20/145, Loss: 0.2178
Epoch 6/10, Batch 30/145, Loss: 0.2070
Epoch 6/10, Batch 40/145, Loss: 0.1726
Epoch 6/10, Batch 50/145, Loss: 0.1653
Epoch 6/10, Batch 60/145, Loss: 0.1226
Epoch 6/10, Batch 70/145, Loss: 0.2769
Epoch 6/10, Batch 80/145, Loss: 0.3870
Epoch 6/10, Batch 90/145, Loss: 0.2471
Epoch 6/10, Batch 100/145, Loss: 0.1015
Epoch 6/10, Batch 110/145, Loss: 0.1361
Epoch 6/10, Batch 120/145, Loss: 0.4314
Epoch 6/10, Batch 130/145, Loss: 0.2018
Epoch 6/10, Batch 140/145, Loss: 0.2210
Epoch 6/10, Train Loss: 0.2284, Valid Loss: 0.2437
Epoch 7/10, Batch 10/145, Loss: 0.2916
Epoch 7/10, Batch 20/145, Loss: 0.2752
Epoch 7/10, Batch 30/145, Loss: 0.0895
Epoch 7/10, Batch 40/145, Loss: 0.4596
Epoch 7/10, Batch 50/145, Loss: 0.2559
Epoch 7/10, Batch 60/145, Loss: 0.1443
Epoch 7/10, Batch 70/145, Loss: 0.1771
Epoch 7/10, Batch 80/145, Loss: 0.1354
Epoch 7/10, Batch 90/145, Loss: 0.3613
Epoch 7/10, Batch 100/145, Loss: 0.2111
Epoch 7/10, Batch 110/145, Loss: 0.3084
Epoch 7/10, Batch 120/145, Loss: 0.1639
Epoch 7/10, Batch 130/145, Loss: 0.2215
Epoch 7/10, Batch 140/145, Loss: 0.1396
Epoch 7/10, Train Loss: 0.2183, Valid Loss: 0.2333
Epoch 8/10, Batch 10/145, Loss: 0.2240
Epoch 8/10, Batch 20/145, Loss: 0.1676
Epoch 8/10, Batch 30/145, Loss: 0.1325
Epoch 8/10, Batch 40/145, Loss: 0.2423
Epoch 8/10, Batch 50/145, Loss: 0.1588
Epoch 8/10, Batch 60/145, Loss: 0.1403
Epoch 8/10, Batch 70/145, Loss: 0.1551
Epoch 8/10, Batch 80/145, Loss: 0.1192
Epoch 8/10, Batch 90/145, Loss: 0.1123
Epoch 8/10, Batch 100/145, Loss: 0.2228
Epoch 8/10, Batch 110/145, Loss: 0.3137
Epoch 8/10, Batch 120/145, Loss: 0.1009
Epoch 8/10, Batch 130/145, Loss: 0.1024
Epoch 8/10, Batch 140/145, Loss: 0.3112
Epoch 8/10, Train Loss: 0.2096, Valid Loss: 0.2230
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2314
Epoch 9/10, Batch 20/145, Loss: 0.1687
Epoch 9/10, Batch 30/145, Loss: 0.2317
Epoch 9/10, Batch 40/145, Loss: 0.2243
Epoch 9/10, Batch 50/145, Loss: 0.1606
Epoch 9/10, Batch 60/145, Loss: 0.2137
Epoch 9/10, Batch 70/145, Loss: 0.1384
Epoch 9/10, Batch 80/145, Loss: 0.1898
Epoch 9/10, Batch 90/145, Loss: 0.0962
Epoch 9/10, Batch 100/145, Loss: 0.1949
Epoch 9/10, Batch 110/145, Loss: 0.1059
Epoch 9/10, Batch 120/145, Loss: 0.1846
Epoch 9/10, Batch 130/145, Loss: 0.1724
Epoch 9/10, Batch 140/145, Loss: 0.1019
Epoch 9/10, Train Loss: 0.1945, Valid Loss: 0.2103
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2030
Epoch 10/10, Batch 20/145, Loss: 0.2971
Epoch 10/10, Batch 30/145, Loss: 0.2303
Epoch 10/10, Batch 40/145, Loss: 0.2777
Epoch 10/10, Batch 50/145, Loss: 0.3131
Epoch 10/10, Batch 60/145, Loss: 0.2006
Epoch 10/10, Batch 70/145, Loss: 0.1310
Epoch 10/10, Batch 80/145, Loss: 0.4801
Epoch 10/10, Batch 90/145, Loss: 0.1791
Epoch 10/10, Batch 100/145, Loss: 0.1726
Epoch 10/10, Batch 110/145, Loss: 0.2221
Epoch 10/10, Batch 120/145, Loss: 0.1679
Epoch 10/10, Batch 130/145, Loss: 0.1055
Epoch 10/10, Batch 140/145, Loss: 0.2171
Epoch 10/10, Train Loss: 0.1973, Valid Loss: 0.2120
Accuracy: 0.9171
Precision: 0.9162
Recall: 0.9171
F1-score: 0.9153
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5271
Epoch 1/10, Batch 20/145, Loss: 0.8593
Epoch 1/10, Batch 30/145, Loss: 0.8681
Epoch 1/10, Batch 40/145, Loss: 0.8738
Epoch 1/10, Batch 50/145, Loss: 0.6002
Epoch 1/10, Batch 60/145, Loss: 0.7054
Epoch 1/10, Batch 70/145, Loss: 0.5703
Epoch 1/10, Batch 80/145, Loss: 0.5879
Epoch 1/10, Batch 90/145, Loss: 0.5308
Epoch 1/10, Batch 100/145, Loss: 0.5731
Epoch 1/10, Batch 110/145, Loss: 0.3903
Epoch 1/10, Batch 120/145, Loss: 0.5602
Epoch 1/10, Batch 130/145, Loss: 0.4549
Epoch 1/10, Batch 140/145, Loss: 0.4162
Epoch 1/10, Train Loss: 0.6817, Valid Loss: 0.3980
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2830
Epoch 2/10, Batch 20/145, Loss: 0.4810
Epoch 2/10, Batch 30/145, Loss: 0.3708
Epoch 2/10, Batch 40/145, Loss: 0.3917
Epoch 2/10, Batch 50/145, Loss: 0.3951
Epoch 2/10, Batch 60/145, Loss: 0.3861
Epoch 2/10, Batch 70/145, Loss: 0.5097
Epoch 2/10, Batch 80/145, Loss: 0.3903
Epoch 2/10, Batch 90/145, Loss: 0.2380
Epoch 2/10, Batch 100/145, Loss: 0.2693
Epoch 2/10, Batch 110/145, Loss: 0.1771
Epoch 2/10, Batch 120/145, Loss: 0.3238
Epoch 2/10, Batch 130/145, Loss: 0.3924
Epoch 2/10, Batch 140/145, Loss: 0.2894
Epoch 2/10, Train Loss: 0.3593, Valid Loss: 0.3112
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2250
Epoch 3/10, Batch 20/145, Loss: 0.2502
Epoch 3/10, Batch 30/145, Loss: 0.3861
Epoch 3/10, Batch 40/145, Loss: 0.4476
Epoch 3/10, Batch 50/145, Loss: 0.1942
Epoch 3/10, Batch 60/145, Loss: 0.2906
Epoch 3/10, Batch 70/145, Loss: 0.2049
Epoch 3/10, Batch 80/145, Loss: 0.3267
Epoch 3/10, Batch 90/145, Loss: 0.5858
Epoch 3/10, Batch 100/145, Loss: 0.2483
Epoch 3/10, Batch 110/145, Loss: 0.2278
Epoch 3/10, Batch 120/145, Loss: 0.2175
Epoch 3/10, Batch 130/145, Loss: 0.2162
Epoch 3/10, Batch 140/145, Loss: 0.2683
Epoch 3/10, Train Loss: 0.3006, Valid Loss: 0.2860
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1797
Epoch 4/10, Batch 20/145, Loss: 0.1873
Epoch 4/10, Batch 30/145, Loss: 0.3481
Epoch 4/10, Batch 40/145, Loss: 0.3902
Epoch 4/10, Batch 50/145, Loss: 0.2864
Epoch 4/10, Batch 60/145, Loss: 0.1774
Epoch 4/10, Batch 70/145, Loss: 0.1464
Epoch 4/10, Batch 80/145, Loss: 0.2041
Epoch 4/10, Batch 90/145, Loss: 0.2826
Epoch 4/10, Batch 100/145, Loss: 0.1799
Epoch 4/10, Batch 110/145, Loss: 0.1803
Epoch 4/10, Batch 120/145, Loss: 0.2063
Epoch 4/10, Batch 130/145, Loss: 0.2228
Epoch 4/10, Batch 140/145, Loss: 0.3711
Epoch 4/10, Train Loss: 0.2588, Valid Loss: 0.2821
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3275
Epoch 5/10, Batch 20/145, Loss: 0.1775
Epoch 5/10, Batch 30/145, Loss: 0.2868
Epoch 5/10, Batch 40/145, Loss: 0.3113
Epoch 5/10, Batch 50/145, Loss: 0.1835
Epoch 5/10, Batch 60/145, Loss: 0.2654
Epoch 5/10, Batch 70/145, Loss: 0.4025
Epoch 5/10, Batch 80/145, Loss: 0.2119
Epoch 5/10, Batch 90/145, Loss: 0.1831
Epoch 5/10, Batch 100/145, Loss: 0.1699
Epoch 5/10, Batch 110/145, Loss: 0.1323
Epoch 5/10, Batch 120/145, Loss: 0.1947
Epoch 5/10, Batch 130/145, Loss: 0.3061
Epoch 5/10, Batch 140/145, Loss: 0.2534
Epoch 5/10, Train Loss: 0.2397, Valid Loss: 0.2591
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2582
Epoch 6/10, Batch 20/145, Loss: 0.2858
Epoch 6/10, Batch 30/145, Loss: 0.1833
Epoch 6/10, Batch 40/145, Loss: 0.2714
Epoch 6/10, Batch 50/145, Loss: 0.3920
Epoch 6/10, Batch 60/145, Loss: 0.1637
Epoch 6/10, Batch 70/145, Loss: 0.2018
Epoch 6/10, Batch 80/145, Loss: 0.2120
Epoch 6/10, Batch 90/145, Loss: 0.2872
Epoch 6/10, Batch 100/145, Loss: 0.3632
Epoch 6/10, Batch 110/145, Loss: 0.2787
Epoch 6/10, Batch 120/145, Loss: 0.2469
Epoch 6/10, Batch 130/145, Loss: 0.1918
Epoch 6/10, Batch 140/145, Loss: 0.2672
Epoch 6/10, Train Loss: 0.2252, Valid Loss: 0.2643
Epoch 7/10, Batch 10/145, Loss: 0.1379
Epoch 7/10, Batch 20/145, Loss: 0.2249
Epoch 7/10, Batch 30/145, Loss: 0.1170
Epoch 7/10, Batch 40/145, Loss: 0.3488
Epoch 7/10, Batch 50/145, Loss: 0.1747
Epoch 7/10, Batch 60/145, Loss: 0.2394
Epoch 7/10, Batch 70/145, Loss: 0.2081
Epoch 7/10, Batch 80/145, Loss: 0.1002
Epoch 7/10, Batch 90/145, Loss: 0.3237
Epoch 7/10, Batch 100/145, Loss: 0.2079
Epoch 7/10, Batch 110/145, Loss: 0.2722
Epoch 7/10, Batch 120/145, Loss: 0.1320
Epoch 7/10, Batch 130/145, Loss: 0.2057
Epoch 7/10, Batch 140/145, Loss: 0.1271
Epoch 7/10, Train Loss: 0.2094, Valid Loss: 0.2427
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1438
Epoch 8/10, Batch 20/145, Loss: 0.1936
Epoch 8/10, Batch 30/145, Loss: 0.1738
Epoch 8/10, Batch 40/145, Loss: 0.1661
Epoch 8/10, Batch 50/145, Loss: 0.2379
Epoch 8/10, Batch 60/145, Loss: 0.1618
Epoch 8/10, Batch 70/145, Loss: 0.2241
Epoch 8/10, Batch 80/145, Loss: 0.1358
Epoch 8/10, Batch 90/145, Loss: 0.1486
Epoch 8/10, Batch 100/145, Loss: 0.1501
Epoch 8/10, Batch 110/145, Loss: 0.3359
Epoch 8/10, Batch 120/145, Loss: 0.2058
Epoch 8/10, Batch 130/145, Loss: 0.1231
Epoch 8/10, Batch 140/145, Loss: 0.3182
Epoch 8/10, Train Loss: 0.2000, Valid Loss: 0.2326
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1096
Epoch 9/10, Batch 20/145, Loss: 0.1991
Epoch 9/10, Batch 30/145, Loss: 0.1077
Epoch 9/10, Batch 40/145, Loss: 0.1129
Epoch 9/10, Batch 50/145, Loss: 0.1676
Epoch 9/10, Batch 60/145, Loss: 0.2089
Epoch 9/10, Batch 70/145, Loss: 0.0585
Epoch 9/10, Batch 80/145, Loss: 0.1759
Epoch 9/10, Batch 90/145, Loss: 0.1147
Epoch 9/10, Batch 100/145, Loss: 0.2827
Epoch 9/10, Batch 110/145, Loss: 0.1497
Epoch 9/10, Batch 120/145, Loss: 0.1404
Epoch 9/10, Batch 130/145, Loss: 0.1936
Epoch 9/10, Batch 140/145, Loss: 0.1026
Epoch 9/10, Train Loss: 0.1962, Valid Loss: 0.2291
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2466
Epoch 10/10, Batch 20/145, Loss: 0.1951
Epoch 10/10, Batch 30/145, Loss: 0.0751
Epoch 10/10, Batch 40/145, Loss: 0.2976
Epoch 10/10, Batch 50/145, Loss: 0.3964
Epoch 10/10, Batch 60/145, Loss: 0.2771
Epoch 10/10, Batch 70/145, Loss: 0.1309
Epoch 10/10, Batch 80/145, Loss: 0.3940
Epoch 10/10, Batch 90/145, Loss: 0.2643
Epoch 10/10, Batch 100/145, Loss: 0.1624
Epoch 10/10, Batch 110/145, Loss: 0.3061
Epoch 10/10, Batch 120/145, Loss: 0.3448
Epoch 10/10, Batch 130/145, Loss: 0.2374
Epoch 10/10, Batch 140/145, Loss: 0.2215
Epoch 10/10, Train Loss: 0.1991, Valid Loss: 0.2250
Model saved!
Accuracy: 0.9241
Precision: 0.9218
Recall: 0.9241
F1-score: 0.9224
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4831
Epoch 1/10, Batch 20/145, Loss: 0.8508
Epoch 1/10, Batch 30/145, Loss: 0.8721
Epoch 1/10, Batch 40/145, Loss: 0.7656
Epoch 1/10, Batch 50/145, Loss: 0.7372
Epoch 1/10, Batch 60/145, Loss: 0.5632
Epoch 1/10, Batch 70/145, Loss: 0.7085
Epoch 1/10, Batch 80/145, Loss: 0.5170
Epoch 1/10, Batch 90/145, Loss: 0.7698
Epoch 1/10, Batch 100/145, Loss: 0.3899
Epoch 1/10, Batch 110/145, Loss: 0.4692
Epoch 1/10, Batch 120/145, Loss: 0.5813
Epoch 1/10, Batch 130/145, Loss: 0.4487
Epoch 1/10, Batch 140/145, Loss: 0.3642
Epoch 1/10, Train Loss: 0.6908, Valid Loss: 0.3755
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3331
Epoch 2/10, Batch 20/145, Loss: 0.6318
Epoch 2/10, Batch 30/145, Loss: 0.4157
Epoch 2/10, Batch 40/145, Loss: 0.3884
Epoch 2/10, Batch 50/145, Loss: 0.5309
Epoch 2/10, Batch 60/145, Loss: 0.3702
Epoch 2/10, Batch 70/145, Loss: 0.3429
Epoch 2/10, Batch 80/145, Loss: 0.3326
Epoch 2/10, Batch 90/145, Loss: 0.3074
Epoch 2/10, Batch 100/145, Loss: 0.1884
Epoch 2/10, Batch 110/145, Loss: 0.2223
Epoch 2/10, Batch 120/145, Loss: 0.4129
Epoch 2/10, Batch 130/145, Loss: 0.3220
Epoch 2/10, Batch 140/145, Loss: 0.2644
Epoch 2/10, Train Loss: 0.3684, Valid Loss: 0.2913
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2965
Epoch 3/10, Batch 20/145, Loss: 0.4997
Epoch 3/10, Batch 30/145, Loss: 0.1978
Epoch 3/10, Batch 40/145, Loss: 0.2623
Epoch 3/10, Batch 50/145, Loss: 0.2560
Epoch 3/10, Batch 60/145, Loss: 0.4398
Epoch 3/10, Batch 70/145, Loss: 0.3496
Epoch 3/10, Batch 80/145, Loss: 0.2787
Epoch 3/10, Batch 90/145, Loss: 0.3201
Epoch 3/10, Batch 100/145, Loss: 0.2832
Epoch 3/10, Batch 110/145, Loss: 0.1817
Epoch 3/10, Batch 120/145, Loss: 0.1887
Epoch 3/10, Batch 130/145, Loss: 0.1868
Epoch 3/10, Batch 140/145, Loss: 0.2403
Epoch 3/10, Train Loss: 0.3114, Valid Loss: 0.2627
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2115
Epoch 4/10, Batch 20/145, Loss: 0.3134
Epoch 4/10, Batch 30/145, Loss: 0.3033
Epoch 4/10, Batch 40/145, Loss: 0.2850
Epoch 4/10, Batch 50/145, Loss: 0.1638
Epoch 4/10, Batch 60/145, Loss: 0.1797
Epoch 4/10, Batch 70/145, Loss: 0.2158
Epoch 4/10, Batch 80/145, Loss: 0.3908
Epoch 4/10, Batch 90/145, Loss: 0.2963
Epoch 4/10, Batch 100/145, Loss: 0.1796
Epoch 4/10, Batch 110/145, Loss: 0.2146
Epoch 4/10, Batch 120/145, Loss: 0.2279
Epoch 4/10, Batch 130/145, Loss: 0.1664
Epoch 4/10, Batch 140/145, Loss: 0.2449
Epoch 4/10, Train Loss: 0.2669, Valid Loss: 0.2630
Epoch 5/10, Batch 10/145, Loss: 0.2950
Epoch 5/10, Batch 20/145, Loss: 0.1795
Epoch 5/10, Batch 30/145, Loss: 0.1885
Epoch 5/10, Batch 40/145, Loss: 0.4388
Epoch 5/10, Batch 50/145, Loss: 0.1534
Epoch 5/10, Batch 60/145, Loss: 0.2595
Epoch 5/10, Batch 70/145, Loss: 0.2212
Epoch 5/10, Batch 80/145, Loss: 0.4638
Epoch 5/10, Batch 90/145, Loss: 0.2154
Epoch 5/10, Batch 100/145, Loss: 0.3296
Epoch 5/10, Batch 110/145, Loss: 0.0935
Epoch 5/10, Batch 120/145, Loss: 0.1832
Epoch 5/10, Batch 130/145, Loss: 0.3300
Epoch 5/10, Batch 140/145, Loss: 0.4315
Epoch 5/10, Train Loss: 0.2463, Valid Loss: 0.2313
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2879
Epoch 6/10, Batch 20/145, Loss: 0.3726
Epoch 6/10, Batch 30/145, Loss: 0.1816
Epoch 6/10, Batch 40/145, Loss: 0.1274
Epoch 6/10, Batch 50/145, Loss: 0.2634
Epoch 6/10, Batch 60/145, Loss: 0.1086
Epoch 6/10, Batch 70/145, Loss: 0.1330
Epoch 6/10, Batch 80/145, Loss: 0.4148
Epoch 6/10, Batch 90/145, Loss: 0.2769
Epoch 6/10, Batch 100/145, Loss: 0.1221
Epoch 6/10, Batch 110/145, Loss: 0.1764
Epoch 6/10, Batch 120/145, Loss: 0.3094
Epoch 6/10, Batch 130/145, Loss: 0.2133
Epoch 6/10, Batch 140/145, Loss: 0.2123
Epoch 6/10, Train Loss: 0.2356, Valid Loss: 0.2360
Epoch 7/10, Batch 10/145, Loss: 0.1296
Epoch 7/10, Batch 20/145, Loss: 0.2570
Epoch 7/10, Batch 30/145, Loss: 0.1802
Epoch 7/10, Batch 40/145, Loss: 0.6276
Epoch 7/10, Batch 50/145, Loss: 0.3379
Epoch 7/10, Batch 60/145, Loss: 0.1020
Epoch 7/10, Batch 70/145, Loss: 0.3075
Epoch 7/10, Batch 80/145, Loss: 0.1833
Epoch 7/10, Batch 90/145, Loss: 0.2020
Epoch 7/10, Batch 100/145, Loss: 0.1868
Epoch 7/10, Batch 110/145, Loss: 0.1793
Epoch 7/10, Batch 120/145, Loss: 0.2121
Epoch 7/10, Batch 130/145, Loss: 0.2361
Epoch 7/10, Batch 140/145, Loss: 0.0648
Epoch 7/10, Train Loss: 0.2209, Valid Loss: 0.2210
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1786
Epoch 8/10, Batch 20/145, Loss: 0.1102
Epoch 8/10, Batch 30/145, Loss: 0.1907
Epoch 8/10, Batch 40/145, Loss: 0.1746
Epoch 8/10, Batch 50/145, Loss: 0.2411
Epoch 8/10, Batch 60/145, Loss: 0.4413
Epoch 8/10, Batch 70/145, Loss: 0.1713
Epoch 8/10, Batch 80/145, Loss: 0.1634
Epoch 8/10, Batch 90/145, Loss: 0.0644
Epoch 8/10, Batch 100/145, Loss: 0.2714
Epoch 8/10, Batch 110/145, Loss: 0.2135
Epoch 8/10, Batch 120/145, Loss: 0.2037
Epoch 8/10, Batch 130/145, Loss: 0.1278
Epoch 8/10, Batch 140/145, Loss: 0.3446
Epoch 8/10, Train Loss: 0.2202, Valid Loss: 0.2231
Epoch 9/10, Batch 10/145, Loss: 0.2084
Epoch 9/10, Batch 20/145, Loss: 0.1578
Epoch 9/10, Batch 30/145, Loss: 0.1756
Epoch 9/10, Batch 40/145, Loss: 0.2240
Epoch 9/10, Batch 50/145, Loss: 0.2610
Epoch 9/10, Batch 60/145, Loss: 0.2936
Epoch 9/10, Batch 70/145, Loss: 0.2356
Epoch 9/10, Batch 80/145, Loss: 0.2651
Epoch 9/10, Batch 90/145, Loss: 0.1079
Epoch 9/10, Batch 100/145, Loss: 0.3787
Epoch 9/10, Batch 110/145, Loss: 0.2304
Epoch 9/10, Batch 120/145, Loss: 0.2201
Epoch 9/10, Batch 130/145, Loss: 0.1382
Epoch 9/10, Batch 140/145, Loss: 0.1380
Epoch 9/10, Train Loss: 0.2107, Valid Loss: 0.2120
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1583
Epoch 10/10, Batch 20/145, Loss: 0.1334
Epoch 10/10, Batch 30/145, Loss: 0.2540
Epoch 10/10, Batch 40/145, Loss: 0.1505
Epoch 10/10, Batch 50/145, Loss: 0.2573
Epoch 10/10, Batch 60/145, Loss: 0.2080
Epoch 10/10, Batch 70/145, Loss: 0.2028
Epoch 10/10, Batch 80/145, Loss: 0.5736
Epoch 10/10, Batch 90/145, Loss: 0.1502
Epoch 10/10, Batch 100/145, Loss: 0.1171
Epoch 10/10, Batch 110/145, Loss: 0.1942
Epoch 10/10, Batch 120/145, Loss: 0.1304
Epoch 10/10, Batch 130/145, Loss: 0.1833
Epoch 10/10, Batch 140/145, Loss: 0.1846
Epoch 10/10, Train Loss: 0.2047, Valid Loss: 0.2102
Model saved!
Accuracy: 0.9241
Precision: 0.9227
Recall: 0.9241
F1-score: 0.9233
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4512
Epoch 1/10, Batch 20/145, Loss: 0.8492
Epoch 1/10, Batch 30/145, Loss: 0.8771
Epoch 1/10, Batch 40/145, Loss: 0.8314
Epoch 1/10, Batch 50/145, Loss: 0.5620
Epoch 1/10, Batch 60/145, Loss: 0.5477
Epoch 1/10, Batch 70/145, Loss: 0.7702
Epoch 1/10, Batch 80/145, Loss: 0.5292
Epoch 1/10, Batch 90/145, Loss: 0.5069
Epoch 1/10, Batch 100/145, Loss: 0.4944
Epoch 1/10, Batch 110/145, Loss: 0.4928
Epoch 1/10, Batch 120/145, Loss: 0.6923
Epoch 1/10, Batch 130/145, Loss: 0.4650
Epoch 1/10, Batch 140/145, Loss: 0.6031
Epoch 1/10, Train Loss: 0.6867, Valid Loss: 0.3513
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3160
Epoch 2/10, Batch 20/145, Loss: 0.5556
Epoch 2/10, Batch 30/145, Loss: 0.5999
Epoch 2/10, Batch 40/145, Loss: 0.3609
Epoch 2/10, Batch 50/145, Loss: 0.3216
Epoch 2/10, Batch 60/145, Loss: 0.5986
Epoch 2/10, Batch 70/145, Loss: 0.5022
Epoch 2/10, Batch 80/145, Loss: 0.3236
Epoch 2/10, Batch 90/145, Loss: 0.2837
Epoch 2/10, Batch 100/145, Loss: 0.3111
Epoch 2/10, Batch 110/145, Loss: 0.3905
Epoch 2/10, Batch 120/145, Loss: 0.4577
Epoch 2/10, Batch 130/145, Loss: 0.3747
Epoch 2/10, Batch 140/145, Loss: 0.3534
Epoch 2/10, Train Loss: 0.3647, Valid Loss: 0.2632
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2555
Epoch 3/10, Batch 20/145, Loss: 0.2297
Epoch 3/10, Batch 30/145, Loss: 0.1892
Epoch 3/10, Batch 40/145, Loss: 0.3830
Epoch 3/10, Batch 50/145, Loss: 0.2316
Epoch 3/10, Batch 60/145, Loss: 0.3781
Epoch 3/10, Batch 70/145, Loss: 0.2242
Epoch 3/10, Batch 80/145, Loss: 0.2334
Epoch 3/10, Batch 90/145, Loss: 0.5660
Epoch 3/10, Batch 100/145, Loss: 0.3889
Epoch 3/10, Batch 110/145, Loss: 0.2227
Epoch 3/10, Batch 120/145, Loss: 0.3428
Epoch 3/10, Batch 130/145, Loss: 0.2870
Epoch 3/10, Batch 140/145, Loss: 0.2995
Epoch 3/10, Train Loss: 0.3084, Valid Loss: 0.2337
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2269
Epoch 4/10, Batch 20/145, Loss: 0.3073
Epoch 4/10, Batch 30/145, Loss: 0.2976
Epoch 4/10, Batch 40/145, Loss: 0.2538
Epoch 4/10, Batch 50/145, Loss: 0.2228
Epoch 4/10, Batch 60/145, Loss: 0.2585
Epoch 4/10, Batch 70/145, Loss: 0.2638
Epoch 4/10, Batch 80/145, Loss: 0.3114
Epoch 4/10, Batch 90/145, Loss: 0.3421
Epoch 4/10, Batch 100/145, Loss: 0.1829
Epoch 4/10, Batch 110/145, Loss: 0.3386
Epoch 4/10, Batch 120/145, Loss: 0.3232
Epoch 4/10, Batch 130/145, Loss: 0.1749
Epoch 4/10, Batch 140/145, Loss: 0.1976
Epoch 4/10, Train Loss: 0.2655, Valid Loss: 0.2184
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2567
Epoch 5/10, Batch 20/145, Loss: 0.2180
Epoch 5/10, Batch 30/145, Loss: 0.2316
Epoch 5/10, Batch 40/145, Loss: 0.2020
Epoch 5/10, Batch 50/145, Loss: 0.1624
Epoch 5/10, Batch 60/145, Loss: 0.2581
Epoch 5/10, Batch 70/145, Loss: 0.3949
Epoch 5/10, Batch 80/145, Loss: 0.2492
Epoch 5/10, Batch 90/145, Loss: 0.2059
Epoch 5/10, Batch 100/145, Loss: 0.2917
Epoch 5/10, Batch 110/145, Loss: 0.2194
Epoch 5/10, Batch 120/145, Loss: 0.2009
Epoch 5/10, Batch 130/145, Loss: 0.2641
Epoch 5/10, Batch 140/145, Loss: 0.3867
Epoch 5/10, Train Loss: 0.2379, Valid Loss: 0.2055
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1293
Epoch 6/10, Batch 20/145, Loss: 0.1711
Epoch 6/10, Batch 30/145, Loss: 0.2469
Epoch 6/10, Batch 40/145, Loss: 0.3239
Epoch 6/10, Batch 50/145, Loss: 0.3924
Epoch 6/10, Batch 60/145, Loss: 0.1621
Epoch 6/10, Batch 70/145, Loss: 0.3538
Epoch 6/10, Batch 80/145, Loss: 0.1511
Epoch 6/10, Batch 90/145, Loss: 0.2865
Epoch 6/10, Batch 100/145, Loss: 0.3501
Epoch 6/10, Batch 110/145, Loss: 0.1600
Epoch 6/10, Batch 120/145, Loss: 0.4137
Epoch 6/10, Batch 130/145, Loss: 0.1784
Epoch 6/10, Batch 140/145, Loss: 0.3266
Epoch 6/10, Train Loss: 0.2353, Valid Loss: 0.2088
Epoch 7/10, Batch 10/145, Loss: 0.2412
Epoch 7/10, Batch 20/145, Loss: 0.1876
Epoch 7/10, Batch 30/145, Loss: 0.1464
Epoch 7/10, Batch 40/145, Loss: 0.4952
Epoch 7/10, Batch 50/145, Loss: 0.1319
Epoch 7/10, Batch 60/145, Loss: 0.1807
Epoch 7/10, Batch 70/145, Loss: 0.1579
Epoch 7/10, Batch 80/145, Loss: 0.1451
Epoch 7/10, Batch 90/145, Loss: 0.1598
Epoch 7/10, Batch 100/145, Loss: 0.1411
Epoch 7/10, Batch 110/145, Loss: 0.1609
Epoch 7/10, Batch 120/145, Loss: 0.1449
Epoch 7/10, Batch 130/145, Loss: 0.2429
Epoch 7/10, Batch 140/145, Loss: 0.0991
Epoch 7/10, Train Loss: 0.2208, Valid Loss: 0.2063
Epoch 8/10, Batch 10/145, Loss: 0.2809
Epoch 8/10, Batch 20/145, Loss: 0.1808
Epoch 8/10, Batch 30/145, Loss: 0.0923
Epoch 8/10, Batch 40/145, Loss: 0.2112
Epoch 8/10, Batch 50/145, Loss: 0.3665
Epoch 8/10, Batch 60/145, Loss: 0.2600
Epoch 8/10, Batch 70/145, Loss: 0.1099
Epoch 8/10, Batch 80/145, Loss: 0.1347
Epoch 8/10, Batch 90/145, Loss: 0.1293
Epoch 8/10, Batch 100/145, Loss: 0.4066
Epoch 8/10, Batch 110/145, Loss: 0.4378
Epoch 8/10, Batch 120/145, Loss: 0.1873
Epoch 8/10, Batch 130/145, Loss: 0.0717
Epoch 8/10, Batch 140/145, Loss: 0.2111
Epoch 8/10, Train Loss: 0.2200, Valid Loss: 0.1918
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1347
Epoch 9/10, Batch 20/145, Loss: 0.1104
Epoch 9/10, Batch 30/145, Loss: 0.1600
Epoch 9/10, Batch 40/145, Loss: 0.3214
Epoch 9/10, Batch 50/145, Loss: 0.1392
Epoch 9/10, Batch 60/145, Loss: 0.1392
Epoch 9/10, Batch 70/145, Loss: 0.2001
Epoch 9/10, Batch 80/145, Loss: 0.3412
Epoch 9/10, Batch 90/145, Loss: 0.2338
Epoch 9/10, Batch 100/145, Loss: 0.2030
Epoch 9/10, Batch 110/145, Loss: 0.1558
Epoch 9/10, Batch 120/145, Loss: 0.2568
Epoch 9/10, Batch 130/145, Loss: 0.2838
Epoch 9/10, Batch 140/145, Loss: 0.1117
Epoch 9/10, Train Loss: 0.2013, Valid Loss: 0.1833
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.3178
Epoch 10/10, Batch 20/145, Loss: 0.0960
Epoch 10/10, Batch 30/145, Loss: 0.1515
Epoch 10/10, Batch 40/145, Loss: 0.1629
Epoch 10/10, Batch 50/145, Loss: 0.2811
Epoch 10/10, Batch 60/145, Loss: 0.2373
Epoch 10/10, Batch 70/145, Loss: 0.2385
Epoch 10/10, Batch 80/145, Loss: 0.4648
Epoch 10/10, Batch 90/145, Loss: 0.1579
Epoch 10/10, Batch 100/145, Loss: 0.1014
Epoch 10/10, Batch 110/145, Loss: 0.2143
Epoch 10/10, Batch 120/145, Loss: 0.1828
Epoch 10/10, Batch 130/145, Loss: 0.2223
Epoch 10/10, Batch 140/145, Loss: 0.2248
Epoch 10/10, Train Loss: 0.1987, Valid Loss: 0.1827
Model saved!
Accuracy: 0.9217
Precision: 0.9197
Recall: 0.9217
F1-score: 0.9205
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5385
Epoch 1/10, Batch 20/145, Loss: 0.9133
Epoch 1/10, Batch 30/145, Loss: 0.7860
Epoch 1/10, Batch 40/145, Loss: 0.8135
Epoch 1/10, Batch 50/145, Loss: 0.5624
Epoch 1/10, Batch 60/145, Loss: 0.6635
Epoch 1/10, Batch 70/145, Loss: 0.6596
Epoch 1/10, Batch 80/145, Loss: 0.4536
Epoch 1/10, Batch 90/145, Loss: 0.4226
Epoch 1/10, Batch 100/145, Loss: 0.4645
Epoch 1/10, Batch 110/145, Loss: 0.5301
Epoch 1/10, Batch 120/145, Loss: 0.5627
Epoch 1/10, Batch 130/145, Loss: 0.2882
Epoch 1/10, Batch 140/145, Loss: 0.3492
Epoch 1/10, Train Loss: 0.6921, Valid Loss: 0.3766
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3291
Epoch 2/10, Batch 20/145, Loss: 0.4108
Epoch 2/10, Batch 30/145, Loss: 0.4693
Epoch 2/10, Batch 40/145, Loss: 0.5818
Epoch 2/10, Batch 50/145, Loss: 0.4258
Epoch 2/10, Batch 60/145, Loss: 0.3034
Epoch 2/10, Batch 70/145, Loss: 0.3909
Epoch 2/10, Batch 80/145, Loss: 0.3362
Epoch 2/10, Batch 90/145, Loss: 0.3598
Epoch 2/10, Batch 100/145, Loss: 0.3139
Epoch 2/10, Batch 110/145, Loss: 0.2549
Epoch 2/10, Batch 120/145, Loss: 0.3134
Epoch 2/10, Batch 130/145, Loss: 0.4176
Epoch 2/10, Batch 140/145, Loss: 0.2516
Epoch 2/10, Train Loss: 0.3635, Valid Loss: 0.2984
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2250
Epoch 3/10, Batch 20/145, Loss: 0.4555
Epoch 3/10, Batch 30/145, Loss: 0.2151
Epoch 3/10, Batch 40/145, Loss: 0.2574
Epoch 3/10, Batch 50/145, Loss: 0.2073
Epoch 3/10, Batch 60/145, Loss: 0.2527
Epoch 3/10, Batch 70/145, Loss: 0.1694
Epoch 3/10, Batch 80/145, Loss: 0.2815
Epoch 3/10, Batch 90/145, Loss: 0.3882
Epoch 3/10, Batch 100/145, Loss: 0.2535
Epoch 3/10, Batch 110/145, Loss: 0.2619
Epoch 3/10, Batch 120/145, Loss: 0.3469
Epoch 3/10, Batch 130/145, Loss: 0.2703
Epoch 3/10, Batch 140/145, Loss: 0.2763
Epoch 3/10, Train Loss: 0.3123, Valid Loss: 0.2676
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2881
Epoch 4/10, Batch 20/145, Loss: 0.3131
Epoch 4/10, Batch 30/145, Loss: 0.3410
Epoch 4/10, Batch 40/145, Loss: 0.4241
Epoch 4/10, Batch 50/145, Loss: 0.1890
Epoch 4/10, Batch 60/145, Loss: 0.3881
Epoch 4/10, Batch 70/145, Loss: 0.1393
Epoch 4/10, Batch 80/145, Loss: 0.1995
Epoch 4/10, Batch 90/145, Loss: 0.3014
Epoch 4/10, Batch 100/145, Loss: 0.1806
Epoch 4/10, Batch 110/145, Loss: 0.2022
Epoch 4/10, Batch 120/145, Loss: 0.2922
Epoch 4/10, Batch 130/145, Loss: 0.1136
Epoch 4/10, Batch 140/145, Loss: 0.2752
Epoch 4/10, Train Loss: 0.2709, Valid Loss: 0.2607
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1964
Epoch 5/10, Batch 20/145, Loss: 0.3061
Epoch 5/10, Batch 30/145, Loss: 0.1504
Epoch 5/10, Batch 40/145, Loss: 0.3574
Epoch 5/10, Batch 50/145, Loss: 0.3110
Epoch 5/10, Batch 60/145, Loss: 0.2606
Epoch 5/10, Batch 70/145, Loss: 0.2579
Epoch 5/10, Batch 80/145, Loss: 0.2034
Epoch 5/10, Batch 90/145, Loss: 0.2843
Epoch 5/10, Batch 100/145, Loss: 0.3460
Epoch 5/10, Batch 110/145, Loss: 0.0728
Epoch 5/10, Batch 120/145, Loss: 0.2192
Epoch 5/10, Batch 130/145, Loss: 0.2901
Epoch 5/10, Batch 140/145, Loss: 0.3909
Epoch 5/10, Train Loss: 0.2461, Valid Loss: 0.2382
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2522
Epoch 6/10, Batch 20/145, Loss: 0.1880
Epoch 6/10, Batch 30/145, Loss: 0.1628
Epoch 6/10, Batch 40/145, Loss: 0.1973
Epoch 6/10, Batch 50/145, Loss: 0.2739
Epoch 6/10, Batch 60/145, Loss: 0.1040
Epoch 6/10, Batch 70/145, Loss: 0.2185
Epoch 6/10, Batch 80/145, Loss: 0.2967
Epoch 6/10, Batch 90/145, Loss: 0.2120
Epoch 6/10, Batch 100/145, Loss: 0.2631
Epoch 6/10, Batch 110/145, Loss: 0.2762
Epoch 6/10, Batch 120/145, Loss: 0.3092
Epoch 6/10, Batch 130/145, Loss: 0.1633
Epoch 6/10, Batch 140/145, Loss: 0.1788
Epoch 6/10, Train Loss: 0.2253, Valid Loss: 0.2381
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2033
Epoch 7/10, Batch 20/145, Loss: 0.1500
Epoch 7/10, Batch 30/145, Loss: 0.1611
Epoch 7/10, Batch 40/145, Loss: 0.5565
Epoch 7/10, Batch 50/145, Loss: 0.1376
Epoch 7/10, Batch 60/145, Loss: 0.0936
Epoch 7/10, Batch 70/145, Loss: 0.6045
Epoch 7/10, Batch 80/145, Loss: 0.1395
Epoch 7/10, Batch 90/145, Loss: 0.2688
Epoch 7/10, Batch 100/145, Loss: 0.1186
Epoch 7/10, Batch 110/145, Loss: 0.2486
Epoch 7/10, Batch 120/145, Loss: 0.1524
Epoch 7/10, Batch 130/145, Loss: 0.2027
Epoch 7/10, Batch 140/145, Loss: 0.1866
Epoch 7/10, Train Loss: 0.2228, Valid Loss: 0.2235
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1623
Epoch 8/10, Batch 20/145, Loss: 0.0951
Epoch 8/10, Batch 30/145, Loss: 0.1217
Epoch 8/10, Batch 40/145, Loss: 0.3135
Epoch 8/10, Batch 50/145, Loss: 0.3895
Epoch 8/10, Batch 60/145, Loss: 0.1643
Epoch 8/10, Batch 70/145, Loss: 0.3155
Epoch 8/10, Batch 80/145, Loss: 0.1247
Epoch 8/10, Batch 90/145, Loss: 0.1395
Epoch 8/10, Batch 100/145, Loss: 0.2357
Epoch 8/10, Batch 110/145, Loss: 0.1626
Epoch 8/10, Batch 120/145, Loss: 0.1879
Epoch 8/10, Batch 130/145, Loss: 0.1968
Epoch 8/10, Batch 140/145, Loss: 0.3149
Epoch 8/10, Train Loss: 0.2155, Valid Loss: 0.2331
Epoch 9/10, Batch 10/145, Loss: 0.2794
Epoch 9/10, Batch 20/145, Loss: 0.1484
Epoch 9/10, Batch 30/145, Loss: 0.1178
Epoch 9/10, Batch 40/145, Loss: 0.2201
Epoch 9/10, Batch 50/145, Loss: 0.1489
Epoch 9/10, Batch 60/145, Loss: 0.1314
Epoch 9/10, Batch 70/145, Loss: 0.2568
Epoch 9/10, Batch 80/145, Loss: 0.3572
Epoch 9/10, Batch 90/145, Loss: 0.1625
Epoch 9/10, Batch 100/145, Loss: 0.1844
Epoch 9/10, Batch 110/145, Loss: 0.0841
Epoch 9/10, Batch 120/145, Loss: 0.3899
Epoch 9/10, Batch 130/145, Loss: 0.1654
Epoch 9/10, Batch 140/145, Loss: 0.1933
Epoch 9/10, Train Loss: 0.2137, Valid Loss: 0.2245
Epoch 10/10, Batch 10/145, Loss: 0.1477
Epoch 10/10, Batch 20/145, Loss: 0.1054
Epoch 10/10, Batch 30/145, Loss: 0.2264
Epoch 10/10, Batch 40/145, Loss: 0.1925
Epoch 10/10, Batch 50/145, Loss: 0.3108
Epoch 10/10, Batch 60/145, Loss: 0.1774
Epoch 10/10, Batch 70/145, Loss: 0.2671
Epoch 10/10, Batch 80/145, Loss: 0.3154
Epoch 10/10, Batch 90/145, Loss: 0.3067
Epoch 10/10, Batch 100/145, Loss: 0.1306
Epoch 10/10, Batch 110/145, Loss: 0.1194
Epoch 10/10, Batch 120/145, Loss: 0.1813
Epoch 10/10, Batch 130/145, Loss: 0.2566
Epoch 10/10, Batch 140/145, Loss: 0.1588
Epoch 10/10, Train Loss: 0.1938, Valid Loss: 0.2171
Model saved!
Accuracy: 0.9229
Precision: 0.9210
Recall: 0.9229
F1-score: 0.9217
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5314
Epoch 1/10, Batch 20/145, Loss: 0.8902
Epoch 1/10, Batch 30/145, Loss: 0.8120
Epoch 1/10, Batch 40/145, Loss: 0.8029
Epoch 1/10, Batch 50/145, Loss: 0.6525
Epoch 1/10, Batch 60/145, Loss: 0.5595
Epoch 1/10, Batch 70/145, Loss: 0.6421
Epoch 1/10, Batch 80/145, Loss: 0.4632
Epoch 1/10, Batch 90/145, Loss: 0.5917
Epoch 1/10, Batch 100/145, Loss: 0.5875
Epoch 1/10, Batch 110/145, Loss: 0.3952
Epoch 1/10, Batch 120/145, Loss: 0.5984
Epoch 1/10, Batch 130/145, Loss: 0.4196
Epoch 1/10, Batch 140/145, Loss: 0.3729
Epoch 1/10, Train Loss: 0.6885, Valid Loss: 0.3898
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4416
Epoch 2/10, Batch 20/145, Loss: 0.6128
Epoch 2/10, Batch 30/145, Loss: 0.4066
Epoch 2/10, Batch 40/145, Loss: 0.4724
Epoch 2/10, Batch 50/145, Loss: 0.3880
Epoch 2/10, Batch 60/145, Loss: 0.5691
Epoch 2/10, Batch 70/145, Loss: 0.5146
Epoch 2/10, Batch 80/145, Loss: 0.4591
Epoch 2/10, Batch 90/145, Loss: 0.2035
Epoch 2/10, Batch 100/145, Loss: 0.5043
Epoch 2/10, Batch 110/145, Loss: 0.3327
Epoch 2/10, Batch 120/145, Loss: 0.2987
Epoch 2/10, Batch 130/145, Loss: 0.3089
Epoch 2/10, Batch 140/145, Loss: 0.3064
Epoch 2/10, Train Loss: 0.3670, Valid Loss: 0.3048
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2617
Epoch 3/10, Batch 20/145, Loss: 0.1883
Epoch 3/10, Batch 30/145, Loss: 0.2105
Epoch 3/10, Batch 40/145, Loss: 0.2054
Epoch 3/10, Batch 50/145, Loss: 0.1368
Epoch 3/10, Batch 60/145, Loss: 0.4169
Epoch 3/10, Batch 70/145, Loss: 0.2181
Epoch 3/10, Batch 80/145, Loss: 0.2435
Epoch 3/10, Batch 90/145, Loss: 0.3772
Epoch 3/10, Batch 100/145, Loss: 0.2127
Epoch 3/10, Batch 110/145, Loss: 0.1721
Epoch 3/10, Batch 120/145, Loss: 0.2229
Epoch 3/10, Batch 130/145, Loss: 0.2155
Epoch 3/10, Batch 140/145, Loss: 0.1511
Epoch 3/10, Train Loss: 0.3076, Valid Loss: 0.2721
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2700
Epoch 4/10, Batch 20/145, Loss: 0.2344
Epoch 4/10, Batch 30/145, Loss: 0.2664
Epoch 4/10, Batch 40/145, Loss: 0.2805
Epoch 4/10, Batch 50/145, Loss: 0.3039
Epoch 4/10, Batch 60/145, Loss: 0.3207
Epoch 4/10, Batch 70/145, Loss: 0.1219
Epoch 4/10, Batch 80/145, Loss: 0.5164
Epoch 4/10, Batch 90/145, Loss: 0.2409
Epoch 4/10, Batch 100/145, Loss: 0.1989
Epoch 4/10, Batch 110/145, Loss: 0.3781
Epoch 4/10, Batch 120/145, Loss: 0.2918
Epoch 4/10, Batch 130/145, Loss: 0.2268
Epoch 4/10, Batch 140/145, Loss: 0.3247
Epoch 4/10, Train Loss: 0.2633, Valid Loss: 0.2599
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2019
Epoch 5/10, Batch 20/145, Loss: 0.2877
Epoch 5/10, Batch 30/145, Loss: 0.2714
Epoch 5/10, Batch 40/145, Loss: 0.1721
Epoch 5/10, Batch 50/145, Loss: 0.1964
Epoch 5/10, Batch 60/145, Loss: 0.2544
Epoch 5/10, Batch 70/145, Loss: 0.2321
Epoch 5/10, Batch 80/145, Loss: 0.2406
Epoch 5/10, Batch 90/145, Loss: 0.1577
Epoch 5/10, Batch 100/145, Loss: 0.3101
Epoch 5/10, Batch 110/145, Loss: 0.2053
Epoch 5/10, Batch 120/145, Loss: 0.3065
Epoch 5/10, Batch 130/145, Loss: 0.1611
Epoch 5/10, Batch 140/145, Loss: 0.2310
Epoch 5/10, Train Loss: 0.2340, Valid Loss: 0.2381
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1321
Epoch 6/10, Batch 20/145, Loss: 0.1708
Epoch 6/10, Batch 30/145, Loss: 0.2743
Epoch 6/10, Batch 40/145, Loss: 0.1486
Epoch 6/10, Batch 50/145, Loss: 0.3802
Epoch 6/10, Batch 60/145, Loss: 0.1527
Epoch 6/10, Batch 70/145, Loss: 0.2892
Epoch 6/10, Batch 80/145, Loss: 0.3025
Epoch 6/10, Batch 90/145, Loss: 0.2482
Epoch 6/10, Batch 100/145, Loss: 0.2987
Epoch 6/10, Batch 110/145, Loss: 0.0868
Epoch 6/10, Batch 120/145, Loss: 0.4773
Epoch 6/10, Batch 130/145, Loss: 0.1074
Epoch 6/10, Batch 140/145, Loss: 0.1702
Epoch 6/10, Train Loss: 0.2302, Valid Loss: 0.2418
Epoch 7/10, Batch 10/145, Loss: 0.2566
Epoch 7/10, Batch 20/145, Loss: 0.2078
Epoch 7/10, Batch 30/145, Loss: 0.1264
Epoch 7/10, Batch 40/145, Loss: 0.3944
Epoch 7/10, Batch 50/145, Loss: 0.1107
Epoch 7/10, Batch 60/145, Loss: 0.1467
Epoch 7/10, Batch 70/145, Loss: 0.2526
Epoch 7/10, Batch 80/145, Loss: 0.1984
Epoch 7/10, Batch 90/145, Loss: 0.3039
Epoch 7/10, Batch 100/145, Loss: 0.2055
Epoch 7/10, Batch 110/145, Loss: 0.2090
Epoch 7/10, Batch 120/145, Loss: 0.0998
Epoch 7/10, Batch 130/145, Loss: 0.3544
Epoch 7/10, Batch 140/145, Loss: 0.1795
Epoch 7/10, Train Loss: 0.2155, Valid Loss: 0.2347
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1398
Epoch 8/10, Batch 20/145, Loss: 0.1344
Epoch 8/10, Batch 30/145, Loss: 0.1699
Epoch 8/10, Batch 40/145, Loss: 0.0955
Epoch 8/10, Batch 50/145, Loss: 0.1406
Epoch 8/10, Batch 60/145, Loss: 0.2022
Epoch 8/10, Batch 70/145, Loss: 0.0632
Epoch 8/10, Batch 80/145, Loss: 0.1882
Epoch 8/10, Batch 90/145, Loss: 0.1867
Epoch 8/10, Batch 100/145, Loss: 0.2621
Epoch 8/10, Batch 110/145, Loss: 0.4750
Epoch 8/10, Batch 120/145, Loss: 0.1575
Epoch 8/10, Batch 130/145, Loss: 0.1497
Epoch 8/10, Batch 140/145, Loss: 0.2959
Epoch 8/10, Train Loss: 0.2067, Valid Loss: 0.2259
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.0957
Epoch 9/10, Batch 20/145, Loss: 0.2051
Epoch 9/10, Batch 30/145, Loss: 0.2134
Epoch 9/10, Batch 40/145, Loss: 0.1221
Epoch 9/10, Batch 50/145, Loss: 0.1058
Epoch 9/10, Batch 60/145, Loss: 0.1370
Epoch 9/10, Batch 70/145, Loss: 0.2251
Epoch 9/10, Batch 80/145, Loss: 0.2460
Epoch 9/10, Batch 90/145, Loss: 0.2741
Epoch 9/10, Batch 100/145, Loss: 0.1465
Epoch 9/10, Batch 110/145, Loss: 0.0961
Epoch 9/10, Batch 120/145, Loss: 0.1524
Epoch 9/10, Batch 130/145, Loss: 0.2063
Epoch 9/10, Batch 140/145, Loss: 0.2005
Epoch 9/10, Train Loss: 0.1962, Valid Loss: 0.2212
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.3235
Epoch 10/10, Batch 20/145, Loss: 0.0969
Epoch 10/10, Batch 30/145, Loss: 0.1715
Epoch 10/10, Batch 40/145, Loss: 0.1744
Epoch 10/10, Batch 50/145, Loss: 0.1153
Epoch 10/10, Batch 60/145, Loss: 0.3668
Epoch 10/10, Batch 70/145, Loss: 0.1370
Epoch 10/10, Batch 80/145, Loss: 0.5822
Epoch 10/10, Batch 90/145, Loss: 0.0701
Epoch 10/10, Batch 100/145, Loss: 0.2108
Epoch 10/10, Batch 110/145, Loss: 0.2421
Epoch 10/10, Batch 120/145, Loss: 0.2867
Epoch 10/10, Batch 130/145, Loss: 0.1913
Epoch 10/10, Batch 140/145, Loss: 0.2309
Epoch 10/10, Train Loss: 0.1905, Valid Loss: 0.2184
Model saved!
Accuracy: 0.9241
Precision: 0.9228
Recall: 0.9241
F1-score: 0.9226
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4921
Epoch 1/10, Batch 20/145, Loss: 0.8983
Epoch 1/10, Batch 30/145, Loss: 0.8220
Epoch 1/10, Batch 40/145, Loss: 0.8491
Epoch 1/10, Batch 50/145, Loss: 0.6049
Epoch 1/10, Batch 60/145, Loss: 0.5562
Epoch 1/10, Batch 70/145, Loss: 0.6664
Epoch 1/10, Batch 80/145, Loss: 0.5195
Epoch 1/10, Batch 90/145, Loss: 0.6142
Epoch 1/10, Batch 100/145, Loss: 0.6292
Epoch 1/10, Batch 110/145, Loss: 0.4093
Epoch 1/10, Batch 120/145, Loss: 0.5408
Epoch 1/10, Batch 130/145, Loss: 0.3877
Epoch 1/10, Batch 140/145, Loss: 0.4018
Epoch 1/10, Train Loss: 0.6917, Valid Loss: 0.3800
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3096
Epoch 2/10, Batch 20/145, Loss: 0.3443
Epoch 2/10, Batch 30/145, Loss: 0.4242
Epoch 2/10, Batch 40/145, Loss: 0.5153
Epoch 2/10, Batch 50/145, Loss: 0.3931
Epoch 2/10, Batch 60/145, Loss: 0.3689
Epoch 2/10, Batch 70/145, Loss: 0.2955
Epoch 2/10, Batch 80/145, Loss: 0.4601
Epoch 2/10, Batch 90/145, Loss: 0.3832
Epoch 2/10, Batch 100/145, Loss: 0.3379
Epoch 2/10, Batch 110/145, Loss: 0.3365
Epoch 2/10, Batch 120/145, Loss: 0.3565
Epoch 2/10, Batch 130/145, Loss: 0.4908
Epoch 2/10, Batch 140/145, Loss: 0.2638
Epoch 2/10, Train Loss: 0.3694, Valid Loss: 0.3004
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2431
Epoch 3/10, Batch 20/145, Loss: 0.4833
Epoch 3/10, Batch 30/145, Loss: 0.1563
Epoch 3/10, Batch 40/145, Loss: 0.2134
Epoch 3/10, Batch 50/145, Loss: 0.1795
Epoch 3/10, Batch 60/145, Loss: 0.1697
Epoch 3/10, Batch 70/145, Loss: 0.2087
Epoch 3/10, Batch 80/145, Loss: 0.3043
Epoch 3/10, Batch 90/145, Loss: 0.4548
Epoch 3/10, Batch 100/145, Loss: 0.3732
Epoch 3/10, Batch 110/145, Loss: 0.2116
Epoch 3/10, Batch 120/145, Loss: 0.3211
Epoch 3/10, Batch 130/145, Loss: 0.2704
Epoch 3/10, Batch 140/145, Loss: 0.1617
Epoch 3/10, Train Loss: 0.3092, Valid Loss: 0.2694
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2638
Epoch 4/10, Batch 20/145, Loss: 0.4251
Epoch 4/10, Batch 30/145, Loss: 0.2856
Epoch 4/10, Batch 40/145, Loss: 0.2743
Epoch 4/10, Batch 50/145, Loss: 0.2114
Epoch 4/10, Batch 60/145, Loss: 0.2096
Epoch 4/10, Batch 70/145, Loss: 0.2863
Epoch 4/10, Batch 80/145, Loss: 0.2560
Epoch 4/10, Batch 90/145, Loss: 0.2209
Epoch 4/10, Batch 100/145, Loss: 0.1891
Epoch 4/10, Batch 110/145, Loss: 0.2456
Epoch 4/10, Batch 120/145, Loss: 0.1939
Epoch 4/10, Batch 130/145, Loss: 0.3464
Epoch 4/10, Batch 140/145, Loss: 0.3790
Epoch 4/10, Train Loss: 0.2647, Valid Loss: 0.2522
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2477
Epoch 5/10, Batch 20/145, Loss: 0.3350
Epoch 5/10, Batch 30/145, Loss: 0.1091
Epoch 5/10, Batch 40/145, Loss: 0.1107
Epoch 5/10, Batch 50/145, Loss: 0.1551
Epoch 5/10, Batch 60/145, Loss: 0.3675
Epoch 5/10, Batch 70/145, Loss: 0.3462
Epoch 5/10, Batch 80/145, Loss: 0.2590
Epoch 5/10, Batch 90/145, Loss: 0.1630
Epoch 5/10, Batch 100/145, Loss: 0.2562
Epoch 5/10, Batch 110/145, Loss: 0.0653
Epoch 5/10, Batch 120/145, Loss: 0.3236
Epoch 5/10, Batch 130/145, Loss: 0.2119
Epoch 5/10, Batch 140/145, Loss: 0.2353
Epoch 5/10, Train Loss: 0.2348, Valid Loss: 0.2498
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2314
Epoch 6/10, Batch 20/145, Loss: 0.2168
Epoch 6/10, Batch 30/145, Loss: 0.2623
Epoch 6/10, Batch 40/145, Loss: 0.2171
Epoch 6/10, Batch 50/145, Loss: 0.3581
Epoch 6/10, Batch 60/145, Loss: 0.1905
Epoch 6/10, Batch 70/145, Loss: 0.3746
Epoch 6/10, Batch 80/145, Loss: 0.2875
Epoch 6/10, Batch 90/145, Loss: 0.1253
Epoch 6/10, Batch 100/145, Loss: 0.2573
Epoch 6/10, Batch 110/145, Loss: 0.1460
Epoch 6/10, Batch 120/145, Loss: 0.2528
Epoch 6/10, Batch 130/145, Loss: 0.1147
Epoch 6/10, Batch 140/145, Loss: 0.1338
Epoch 6/10, Train Loss: 0.2332, Valid Loss: 0.2479
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1616
Epoch 7/10, Batch 20/145, Loss: 0.2907
Epoch 7/10, Batch 30/145, Loss: 0.1242
Epoch 7/10, Batch 40/145, Loss: 0.2694
Epoch 7/10, Batch 50/145, Loss: 0.3837
Epoch 7/10, Batch 60/145, Loss: 0.1241
Epoch 7/10, Batch 70/145, Loss: 0.2040
Epoch 7/10, Batch 80/145, Loss: 0.1874
Epoch 7/10, Batch 90/145, Loss: 0.3147
Epoch 7/10, Batch 100/145, Loss: 0.2843
Epoch 7/10, Batch 110/145, Loss: 0.2662
Epoch 7/10, Batch 120/145, Loss: 0.2727
Epoch 7/10, Batch 130/145, Loss: 0.2225
Epoch 7/10, Batch 140/145, Loss: 0.1426
Epoch 7/10, Train Loss: 0.2190, Valid Loss: 0.2333
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1777
Epoch 8/10, Batch 20/145, Loss: 0.1605
Epoch 8/10, Batch 30/145, Loss: 0.2170
Epoch 8/10, Batch 40/145, Loss: 0.3745
Epoch 8/10, Batch 50/145, Loss: 0.1817
Epoch 8/10, Batch 60/145, Loss: 0.1060
Epoch 8/10, Batch 70/145, Loss: 0.1558
Epoch 8/10, Batch 80/145, Loss: 0.1625
Epoch 8/10, Batch 90/145, Loss: 0.1210
Epoch 8/10, Batch 100/145, Loss: 0.2658
Epoch 8/10, Batch 110/145, Loss: 0.4921
Epoch 8/10, Batch 120/145, Loss: 0.1779
Epoch 8/10, Batch 130/145, Loss: 0.0801
Epoch 8/10, Batch 140/145, Loss: 0.3123
Epoch 8/10, Train Loss: 0.2143, Valid Loss: 0.2262
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2384
Epoch 9/10, Batch 20/145, Loss: 0.1137
Epoch 9/10, Batch 30/145, Loss: 0.0671
Epoch 9/10, Batch 40/145, Loss: 0.1471
Epoch 9/10, Batch 50/145, Loss: 0.4473
Epoch 9/10, Batch 60/145, Loss: 0.1627
Epoch 9/10, Batch 70/145, Loss: 0.1262
Epoch 9/10, Batch 80/145, Loss: 0.2412
Epoch 9/10, Batch 90/145, Loss: 0.1752
Epoch 9/10, Batch 100/145, Loss: 0.2720
Epoch 9/10, Batch 110/145, Loss: 0.0702
Epoch 9/10, Batch 120/145, Loss: 0.2190
Epoch 9/10, Batch 130/145, Loss: 0.2173
Epoch 9/10, Batch 140/145, Loss: 0.2564
Epoch 9/10, Train Loss: 0.2050, Valid Loss: 0.2190
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1847
Epoch 10/10, Batch 20/145, Loss: 0.1056
Epoch 10/10, Batch 30/145, Loss: 0.1359
Epoch 10/10, Batch 40/145, Loss: 0.2424
Epoch 10/10, Batch 50/145, Loss: 0.2618
Epoch 10/10, Batch 60/145, Loss: 0.1065
Epoch 10/10, Batch 70/145, Loss: 0.1986
Epoch 10/10, Batch 80/145, Loss: 0.3120
Epoch 10/10, Batch 90/145, Loss: 0.0795
Epoch 10/10, Batch 100/145, Loss: 0.1530
Epoch 10/10, Batch 110/145, Loss: 0.3161
Epoch 10/10, Batch 120/145, Loss: 0.1027
Epoch 10/10, Batch 130/145, Loss: 0.2605
Epoch 10/10, Batch 140/145, Loss: 0.2320
Epoch 10/10, Train Loss: 0.1970, Valid Loss: 0.2149
Model saved!
Accuracy: 0.9217
Precision: 0.9204
Recall: 0.9217
F1-score: 0.9210
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5447
Epoch 1/10, Batch 20/145, Loss: 0.9415
Epoch 1/10, Batch 30/145, Loss: 0.7978
Epoch 1/10, Batch 40/145, Loss: 0.7222
Epoch 1/10, Batch 50/145, Loss: 0.7387
Epoch 1/10, Batch 60/145, Loss: 0.5876
Epoch 1/10, Batch 70/145, Loss: 0.7962
Epoch 1/10, Batch 80/145, Loss: 0.4843
Epoch 1/10, Batch 90/145, Loss: 0.5547
Epoch 1/10, Batch 100/145, Loss: 0.6838
Epoch 1/10, Batch 110/145, Loss: 0.3858
Epoch 1/10, Batch 120/145, Loss: 0.5205
Epoch 1/10, Batch 130/145, Loss: 0.3226
Epoch 1/10, Batch 140/145, Loss: 0.4624
Epoch 1/10, Train Loss: 0.6930, Valid Loss: 0.3663
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3042
Epoch 2/10, Batch 20/145, Loss: 0.5081
Epoch 2/10, Batch 30/145, Loss: 0.3117
Epoch 2/10, Batch 40/145, Loss: 0.5461
Epoch 2/10, Batch 50/145, Loss: 0.3248
Epoch 2/10, Batch 60/145, Loss: 0.4411
Epoch 2/10, Batch 70/145, Loss: 0.3118
Epoch 2/10, Batch 80/145, Loss: 0.2290
Epoch 2/10, Batch 90/145, Loss: 0.2226
Epoch 2/10, Batch 100/145, Loss: 0.2837
Epoch 2/10, Batch 110/145, Loss: 0.2433
Epoch 2/10, Batch 120/145, Loss: 0.4999
Epoch 2/10, Batch 130/145, Loss: 0.3491
Epoch 2/10, Batch 140/145, Loss: 0.3060
Epoch 2/10, Train Loss: 0.3632, Valid Loss: 0.2745
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1530
Epoch 3/10, Batch 20/145, Loss: 0.2905
Epoch 3/10, Batch 30/145, Loss: 0.2313
Epoch 3/10, Batch 40/145, Loss: 0.3213
Epoch 3/10, Batch 50/145, Loss: 0.2460
Epoch 3/10, Batch 60/145, Loss: 0.2016
Epoch 3/10, Batch 70/145, Loss: 0.1661
Epoch 3/10, Batch 80/145, Loss: 0.3579
Epoch 3/10, Batch 90/145, Loss: 0.6125
Epoch 3/10, Batch 100/145, Loss: 0.2488
Epoch 3/10, Batch 110/145, Loss: 0.1647
Epoch 3/10, Batch 120/145, Loss: 0.2927
Epoch 3/10, Batch 130/145, Loss: 0.1159
Epoch 3/10, Batch 140/145, Loss: 0.2029
Epoch 3/10, Train Loss: 0.3083, Valid Loss: 0.2493
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2323
Epoch 4/10, Batch 20/145, Loss: 0.3449
Epoch 4/10, Batch 30/145, Loss: 0.4360
Epoch 4/10, Batch 40/145, Loss: 0.3283
Epoch 4/10, Batch 50/145, Loss: 0.5052
Epoch 4/10, Batch 60/145, Loss: 0.2635
Epoch 4/10, Batch 70/145, Loss: 0.2751
Epoch 4/10, Batch 80/145, Loss: 0.2455
Epoch 4/10, Batch 90/145, Loss: 0.2898
Epoch 4/10, Batch 100/145, Loss: 0.3150
Epoch 4/10, Batch 110/145, Loss: 0.2209
Epoch 4/10, Batch 120/145, Loss: 0.2345
Epoch 4/10, Batch 130/145, Loss: 0.1512
Epoch 4/10, Batch 140/145, Loss: 0.2605
Epoch 4/10, Train Loss: 0.2676, Valid Loss: 0.2283
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1858
Epoch 5/10, Batch 20/145, Loss: 0.2008
Epoch 5/10, Batch 30/145, Loss: 0.2493
Epoch 5/10, Batch 40/145, Loss: 0.2169
Epoch 5/10, Batch 50/145, Loss: 0.1656
Epoch 5/10, Batch 60/145, Loss: 0.3399
Epoch 5/10, Batch 70/145, Loss: 0.2884
Epoch 5/10, Batch 80/145, Loss: 0.3572
Epoch 5/10, Batch 90/145, Loss: 0.1845
Epoch 5/10, Batch 100/145, Loss: 0.2253
Epoch 5/10, Batch 110/145, Loss: 0.1390
Epoch 5/10, Batch 120/145, Loss: 0.2403
Epoch 5/10, Batch 130/145, Loss: 0.2973
Epoch 5/10, Batch 140/145, Loss: 0.2333
Epoch 5/10, Train Loss: 0.2416, Valid Loss: 0.2207
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1722
Epoch 6/10, Batch 20/145, Loss: 0.2166
Epoch 6/10, Batch 30/145, Loss: 0.3427
Epoch 6/10, Batch 40/145, Loss: 0.1372
Epoch 6/10, Batch 50/145, Loss: 0.2998
Epoch 6/10, Batch 60/145, Loss: 0.1987
Epoch 6/10, Batch 70/145, Loss: 0.2467
Epoch 6/10, Batch 80/145, Loss: 0.2339
Epoch 6/10, Batch 90/145, Loss: 0.2167
Epoch 6/10, Batch 100/145, Loss: 0.1056
Epoch 6/10, Batch 110/145, Loss: 0.1217
Epoch 6/10, Batch 120/145, Loss: 0.2885
Epoch 6/10, Batch 130/145, Loss: 0.1484
Epoch 6/10, Batch 140/145, Loss: 0.1940
Epoch 6/10, Train Loss: 0.2237, Valid Loss: 0.2140
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.5034
Epoch 7/10, Batch 20/145, Loss: 0.2410
Epoch 7/10, Batch 30/145, Loss: 0.1274
Epoch 7/10, Batch 40/145, Loss: 0.4742
Epoch 7/10, Batch 50/145, Loss: 0.1952
Epoch 7/10, Batch 60/145, Loss: 0.1329
Epoch 7/10, Batch 70/145, Loss: 0.2995
Epoch 7/10, Batch 80/145, Loss: 0.2230
Epoch 7/10, Batch 90/145, Loss: 0.3320
Epoch 7/10, Batch 100/145, Loss: 0.3084
Epoch 7/10, Batch 110/145, Loss: 0.3516
Epoch 7/10, Batch 120/145, Loss: 0.3029
Epoch 7/10, Batch 130/145, Loss: 0.2216
Epoch 7/10, Batch 140/145, Loss: 0.2509
Epoch 7/10, Train Loss: 0.2220, Valid Loss: 0.2078
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1394
Epoch 8/10, Batch 20/145, Loss: 0.1389
Epoch 8/10, Batch 30/145, Loss: 0.1361
Epoch 8/10, Batch 40/145, Loss: 0.2364
Epoch 8/10, Batch 50/145, Loss: 0.1932
Epoch 8/10, Batch 60/145, Loss: 0.2358
Epoch 8/10, Batch 70/145, Loss: 0.2239
Epoch 8/10, Batch 80/145, Loss: 0.1740
Epoch 8/10, Batch 90/145, Loss: 0.1903
Epoch 8/10, Batch 100/145, Loss: 0.2617
Epoch 8/10, Batch 110/145, Loss: 0.5746
Epoch 8/10, Batch 120/145, Loss: 0.1245
Epoch 8/10, Batch 130/145, Loss: 0.1787
Epoch 8/10, Batch 140/145, Loss: 0.2416
Epoch 8/10, Train Loss: 0.2091, Valid Loss: 0.2072
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2972
Epoch 9/10, Batch 20/145, Loss: 0.0414
Epoch 9/10, Batch 30/145, Loss: 0.0958
Epoch 9/10, Batch 40/145, Loss: 0.1243
Epoch 9/10, Batch 50/145, Loss: 0.1282
Epoch 9/10, Batch 60/145, Loss: 0.1035
Epoch 9/10, Batch 70/145, Loss: 0.1530
Epoch 9/10, Batch 80/145, Loss: 0.1042
Epoch 9/10, Batch 90/145, Loss: 0.1071
Epoch 9/10, Batch 100/145, Loss: 0.3238
Epoch 9/10, Batch 110/145, Loss: 0.1252
Epoch 9/10, Batch 120/145, Loss: 0.3052
Epoch 9/10, Batch 130/145, Loss: 0.1787
Epoch 9/10, Batch 140/145, Loss: 0.1490
Epoch 9/10, Train Loss: 0.2054, Valid Loss: 0.1927
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1293
Epoch 10/10, Batch 20/145, Loss: 0.1774
Epoch 10/10, Batch 30/145, Loss: 0.1245
Epoch 10/10, Batch 40/145, Loss: 0.2245
Epoch 10/10, Batch 50/145, Loss: 0.2467
Epoch 10/10, Batch 60/145, Loss: 0.1884
Epoch 10/10, Batch 70/145, Loss: 0.1844
Epoch 10/10, Batch 80/145, Loss: 0.3479
Epoch 10/10, Batch 90/145, Loss: 0.2178
Epoch 10/10, Batch 100/145, Loss: 0.1648
Epoch 10/10, Batch 110/145, Loss: 0.1616
Epoch 10/10, Batch 120/145, Loss: 0.2334
Epoch 10/10, Batch 130/145, Loss: 0.1389
Epoch 10/10, Batch 140/145, Loss: 0.3852
Epoch 10/10, Train Loss: 0.1998, Valid Loss: 0.1944
Accuracy: 0.9194
Precision: 0.9183
Recall: 0.9194
F1-score: 0.9184
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4447
Epoch 1/10, Batch 20/145, Loss: 0.9546
Epoch 1/10, Batch 30/145, Loss: 0.8308
Epoch 1/10, Batch 40/145, Loss: 0.7066
Epoch 1/10, Batch 50/145, Loss: 0.5908
Epoch 1/10, Batch 60/145, Loss: 0.5677
Epoch 1/10, Batch 70/145, Loss: 0.6377
Epoch 1/10, Batch 80/145, Loss: 0.6501
Epoch 1/10, Batch 90/145, Loss: 0.4542
Epoch 1/10, Batch 100/145, Loss: 0.4732
Epoch 1/10, Batch 110/145, Loss: 0.4055
Epoch 1/10, Batch 120/145, Loss: 0.7339
Epoch 1/10, Batch 130/145, Loss: 0.4313
Epoch 1/10, Batch 140/145, Loss: 0.4578
Epoch 1/10, Train Loss: 0.6810, Valid Loss: 0.3591
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3280
Epoch 2/10, Batch 20/145, Loss: 0.4564
Epoch 2/10, Batch 30/145, Loss: 0.3545
Epoch 2/10, Batch 40/145, Loss: 0.4697
Epoch 2/10, Batch 50/145, Loss: 0.3047
Epoch 2/10, Batch 60/145, Loss: 0.4705
Epoch 2/10, Batch 70/145, Loss: 0.3751
Epoch 2/10, Batch 80/145, Loss: 0.3619
Epoch 2/10, Batch 90/145, Loss: 0.2285
Epoch 2/10, Batch 100/145, Loss: 0.3798
Epoch 2/10, Batch 110/145, Loss: 0.2233
Epoch 2/10, Batch 120/145, Loss: 0.4598
Epoch 2/10, Batch 130/145, Loss: 0.3378
Epoch 2/10, Batch 140/145, Loss: 0.2211
Epoch 2/10, Train Loss: 0.3634, Valid Loss: 0.2780
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1659
Epoch 3/10, Batch 20/145, Loss: 0.2417
Epoch 3/10, Batch 30/145, Loss: 0.2377
Epoch 3/10, Batch 40/145, Loss: 0.2089
Epoch 3/10, Batch 50/145, Loss: 0.1812
Epoch 3/10, Batch 60/145, Loss: 0.3223
Epoch 3/10, Batch 70/145, Loss: 0.2438
Epoch 3/10, Batch 80/145, Loss: 0.2713
Epoch 3/10, Batch 90/145, Loss: 0.3658
Epoch 3/10, Batch 100/145, Loss: 0.1611
Epoch 3/10, Batch 110/145, Loss: 0.3856
Epoch 3/10, Batch 120/145, Loss: 0.1332
Epoch 3/10, Batch 130/145, Loss: 0.3096
Epoch 3/10, Batch 140/145, Loss: 0.2130
Epoch 3/10, Train Loss: 0.2977, Valid Loss: 0.2529
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2741
Epoch 4/10, Batch 20/145, Loss: 0.2292
Epoch 4/10, Batch 30/145, Loss: 0.4152
Epoch 4/10, Batch 40/145, Loss: 0.3086
Epoch 4/10, Batch 50/145, Loss: 0.1342
Epoch 4/10, Batch 60/145, Loss: 0.1769
Epoch 4/10, Batch 70/145, Loss: 0.2727
Epoch 4/10, Batch 80/145, Loss: 0.2018
Epoch 4/10, Batch 90/145, Loss: 0.2376
Epoch 4/10, Batch 100/145, Loss: 0.1289
Epoch 4/10, Batch 110/145, Loss: 0.1918
Epoch 4/10, Batch 120/145, Loss: 0.2471
Epoch 4/10, Batch 130/145, Loss: 0.2632
Epoch 4/10, Batch 140/145, Loss: 0.2543
Epoch 4/10, Train Loss: 0.2614, Valid Loss: 0.2395
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2287
Epoch 5/10, Batch 20/145, Loss: 0.1959
Epoch 5/10, Batch 30/145, Loss: 0.1260
Epoch 5/10, Batch 40/145, Loss: 0.3310
Epoch 5/10, Batch 50/145, Loss: 0.1461
Epoch 5/10, Batch 60/145, Loss: 0.3222
Epoch 5/10, Batch 70/145, Loss: 0.2832
Epoch 5/10, Batch 80/145, Loss: 0.4459
Epoch 5/10, Batch 90/145, Loss: 0.1842
Epoch 5/10, Batch 100/145, Loss: 0.1370
Epoch 5/10, Batch 110/145, Loss: 0.1616
Epoch 5/10, Batch 120/145, Loss: 0.1568
Epoch 5/10, Batch 130/145, Loss: 0.2843
Epoch 5/10, Batch 140/145, Loss: 0.3187
Epoch 5/10, Train Loss: 0.2310, Valid Loss: 0.2298
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2109
Epoch 6/10, Batch 20/145, Loss: 0.2165
Epoch 6/10, Batch 30/145, Loss: 0.2147
Epoch 6/10, Batch 40/145, Loss: 0.1040
Epoch 6/10, Batch 50/145, Loss: 0.1812
Epoch 6/10, Batch 60/145, Loss: 0.1041
Epoch 6/10, Batch 70/145, Loss: 0.2130
Epoch 6/10, Batch 80/145, Loss: 0.3260
Epoch 6/10, Batch 90/145, Loss: 0.3796
Epoch 6/10, Batch 100/145, Loss: 0.1631
Epoch 6/10, Batch 110/145, Loss: 0.1931
Epoch 6/10, Batch 120/145, Loss: 0.2987
Epoch 6/10, Batch 130/145, Loss: 0.1273
Epoch 6/10, Batch 140/145, Loss: 0.1913
Epoch 6/10, Train Loss: 0.2254, Valid Loss: 0.2260
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2358
Epoch 7/10, Batch 20/145, Loss: 0.2690
Epoch 7/10, Batch 30/145, Loss: 0.1924
Epoch 7/10, Batch 40/145, Loss: 0.5587
Epoch 7/10, Batch 50/145, Loss: 0.1773
Epoch 7/10, Batch 60/145, Loss: 0.1305
Epoch 7/10, Batch 70/145, Loss: 0.4755
Epoch 7/10, Batch 80/145, Loss: 0.1313
Epoch 7/10, Batch 90/145, Loss: 0.2089
Epoch 7/10, Batch 100/145, Loss: 0.3302
Epoch 7/10, Batch 110/145, Loss: 0.3023
Epoch 7/10, Batch 120/145, Loss: 0.2893
Epoch 7/10, Batch 130/145, Loss: 0.2193
Epoch 7/10, Batch 140/145, Loss: 0.0742
Epoch 7/10, Train Loss: 0.2203, Valid Loss: 0.2212
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1926
Epoch 8/10, Batch 20/145, Loss: 0.1136
Epoch 8/10, Batch 30/145, Loss: 0.1111
Epoch 8/10, Batch 40/145, Loss: 0.1666
Epoch 8/10, Batch 50/145, Loss: 0.1179
Epoch 8/10, Batch 60/145, Loss: 0.1857
Epoch 8/10, Batch 70/145, Loss: 0.1044
Epoch 8/10, Batch 80/145, Loss: 0.2587
Epoch 8/10, Batch 90/145, Loss: 0.2271
Epoch 8/10, Batch 100/145, Loss: 0.3074
Epoch 8/10, Batch 110/145, Loss: 0.4199
Epoch 8/10, Batch 120/145, Loss: 0.1708
Epoch 8/10, Batch 130/145, Loss: 0.2229
Epoch 8/10, Batch 140/145, Loss: 0.2339
Epoch 8/10, Train Loss: 0.2106, Valid Loss: 0.2101
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2022
Epoch 9/10, Batch 20/145, Loss: 0.1563
Epoch 9/10, Batch 30/145, Loss: 0.1325
Epoch 9/10, Batch 40/145, Loss: 0.1911
Epoch 9/10, Batch 50/145, Loss: 0.1391
Epoch 9/10, Batch 60/145, Loss: 0.1237
Epoch 9/10, Batch 70/145, Loss: 0.2719
Epoch 9/10, Batch 80/145, Loss: 0.2234
Epoch 9/10, Batch 90/145, Loss: 0.1189
Epoch 9/10, Batch 100/145, Loss: 0.2814
Epoch 9/10, Batch 110/145, Loss: 0.1048
Epoch 9/10, Batch 120/145, Loss: 0.2116
Epoch 9/10, Batch 130/145, Loss: 0.1920
Epoch 9/10, Batch 140/145, Loss: 0.1431
Epoch 9/10, Train Loss: 0.1989, Valid Loss: 0.2039
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1115
Epoch 10/10, Batch 20/145, Loss: 0.2600
Epoch 10/10, Batch 30/145, Loss: 0.1268
Epoch 10/10, Batch 40/145, Loss: 0.1367
Epoch 10/10, Batch 50/145, Loss: 0.3016
Epoch 10/10, Batch 60/145, Loss: 0.1702
Epoch 10/10, Batch 70/145, Loss: 0.1323
Epoch 10/10, Batch 80/145, Loss: 0.2648
Epoch 10/10, Batch 90/145, Loss: 0.1386
Epoch 10/10, Batch 100/145, Loss: 0.2384
Epoch 10/10, Batch 110/145, Loss: 0.1799
Epoch 10/10, Batch 120/145, Loss: 0.3525
Epoch 10/10, Batch 130/145, Loss: 0.1011
Epoch 10/10, Batch 140/145, Loss: 0.1356
Epoch 10/10, Train Loss: 0.1908, Valid Loss: 0.2043
Accuracy: 0.9264
Precision: 0.9247
Recall: 0.9264
F1-score: 0.9249
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4894
Epoch 1/10, Batch 20/145, Loss: 0.9101
Epoch 1/10, Batch 30/145, Loss: 0.8317
Epoch 1/10, Batch 40/145, Loss: 0.7176
Epoch 1/10, Batch 50/145, Loss: 0.6794
Epoch 1/10, Batch 60/145, Loss: 0.6241
Epoch 1/10, Batch 70/145, Loss: 0.7097
Epoch 1/10, Batch 80/145, Loss: 0.5027
Epoch 1/10, Batch 90/145, Loss: 0.5738
Epoch 1/10, Batch 100/145, Loss: 0.6614
Epoch 1/10, Batch 110/145, Loss: 0.3824
Epoch 1/10, Batch 120/145, Loss: 0.6756
Epoch 1/10, Batch 130/145, Loss: 0.4915
Epoch 1/10, Batch 140/145, Loss: 0.3318
Epoch 1/10, Train Loss: 0.6865, Valid Loss: 0.3690
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3267
Epoch 2/10, Batch 20/145, Loss: 0.5812
Epoch 2/10, Batch 30/145, Loss: 0.4589
Epoch 2/10, Batch 40/145, Loss: 0.3543
Epoch 2/10, Batch 50/145, Loss: 0.3956
Epoch 2/10, Batch 60/145, Loss: 0.4481
Epoch 2/10, Batch 70/145, Loss: 0.4267
Epoch 2/10, Batch 80/145, Loss: 0.4250
Epoch 2/10, Batch 90/145, Loss: 0.2916
Epoch 2/10, Batch 100/145, Loss: 0.3688
Epoch 2/10, Batch 110/145, Loss: 0.2408
Epoch 2/10, Batch 120/145, Loss: 0.3145
Epoch 2/10, Batch 130/145, Loss: 0.3759
Epoch 2/10, Batch 140/145, Loss: 0.3066
Epoch 2/10, Train Loss: 0.3587, Valid Loss: 0.2901
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2653
Epoch 3/10, Batch 20/145, Loss: 0.2019
Epoch 3/10, Batch 30/145, Loss: 0.2571
Epoch 3/10, Batch 40/145, Loss: 0.1830
Epoch 3/10, Batch 50/145, Loss: 0.1840
Epoch 3/10, Batch 60/145, Loss: 0.2426
Epoch 3/10, Batch 70/145, Loss: 0.2147
Epoch 3/10, Batch 80/145, Loss: 0.2237
Epoch 3/10, Batch 90/145, Loss: 0.7447
Epoch 3/10, Batch 100/145, Loss: 0.2335
Epoch 3/10, Batch 110/145, Loss: 0.4247
Epoch 3/10, Batch 120/145, Loss: 0.2446
Epoch 3/10, Batch 130/145, Loss: 0.2300
Epoch 3/10, Batch 140/145, Loss: 0.1574
Epoch 3/10, Train Loss: 0.2956, Valid Loss: 0.2635
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2632
Epoch 4/10, Batch 20/145, Loss: 0.3309
Epoch 4/10, Batch 30/145, Loss: 0.2753
Epoch 4/10, Batch 40/145, Loss: 0.2585
Epoch 4/10, Batch 50/145, Loss: 0.2644
Epoch 4/10, Batch 60/145, Loss: 0.1915
Epoch 4/10, Batch 70/145, Loss: 0.2114
Epoch 4/10, Batch 80/145, Loss: 0.2850
Epoch 4/10, Batch 90/145, Loss: 0.2016
Epoch 4/10, Batch 100/145, Loss: 0.2070
Epoch 4/10, Batch 110/145, Loss: 0.2965
Epoch 4/10, Batch 120/145, Loss: 0.2288
Epoch 4/10, Batch 130/145, Loss: 0.2110
Epoch 4/10, Batch 140/145, Loss: 0.1316
Epoch 4/10, Train Loss: 0.2589, Valid Loss: 0.2521
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1859
Epoch 5/10, Batch 20/145, Loss: 0.1392
Epoch 5/10, Batch 30/145, Loss: 0.1662
Epoch 5/10, Batch 40/145, Loss: 0.2958
Epoch 5/10, Batch 50/145, Loss: 0.0747
Epoch 5/10, Batch 60/145, Loss: 0.2127
Epoch 5/10, Batch 70/145, Loss: 0.2863
Epoch 5/10, Batch 80/145, Loss: 0.1967
Epoch 5/10, Batch 90/145, Loss: 0.2006
Epoch 5/10, Batch 100/145, Loss: 0.3848
Epoch 5/10, Batch 110/145, Loss: 0.1158
Epoch 5/10, Batch 120/145, Loss: 0.2174
Epoch 5/10, Batch 130/145, Loss: 0.1968
Epoch 5/10, Batch 140/145, Loss: 0.2031
Epoch 5/10, Train Loss: 0.2339, Valid Loss: 0.2409
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2612
Epoch 6/10, Batch 20/145, Loss: 0.1696
Epoch 6/10, Batch 30/145, Loss: 0.2086
Epoch 6/10, Batch 40/145, Loss: 0.1459
Epoch 6/10, Batch 50/145, Loss: 0.2649
Epoch 6/10, Batch 60/145, Loss: 0.1415
Epoch 6/10, Batch 70/145, Loss: 0.2914
Epoch 6/10, Batch 80/145, Loss: 0.3320
Epoch 6/10, Batch 90/145, Loss: 0.2634
Epoch 6/10, Batch 100/145, Loss: 0.2079
Epoch 6/10, Batch 110/145, Loss: 0.1542
Epoch 6/10, Batch 120/145, Loss: 0.2794
Epoch 6/10, Batch 130/145, Loss: 0.1546
Epoch 6/10, Batch 140/145, Loss: 0.3302
Epoch 6/10, Train Loss: 0.2184, Valid Loss: 0.2330
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2054
Epoch 7/10, Batch 20/145, Loss: 0.1595
Epoch 7/10, Batch 30/145, Loss: 0.2180
Epoch 7/10, Batch 40/145, Loss: 0.3467
Epoch 7/10, Batch 50/145, Loss: 0.2728
Epoch 7/10, Batch 60/145, Loss: 0.2688
Epoch 7/10, Batch 70/145, Loss: 0.1783
Epoch 7/10, Batch 80/145, Loss: 0.1018
Epoch 7/10, Batch 90/145, Loss: 0.2528
Epoch 7/10, Batch 100/145, Loss: 0.3897
Epoch 7/10, Batch 110/145, Loss: 0.3510
Epoch 7/10, Batch 120/145, Loss: 0.1121
Epoch 7/10, Batch 130/145, Loss: 0.2627
Epoch 7/10, Batch 140/145, Loss: 0.1360
Epoch 7/10, Train Loss: 0.2134, Valid Loss: 0.2263
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0870
Epoch 8/10, Batch 20/145, Loss: 0.1595
Epoch 8/10, Batch 30/145, Loss: 0.2530
Epoch 8/10, Batch 40/145, Loss: 0.2551
Epoch 8/10, Batch 50/145, Loss: 0.1157
Epoch 8/10, Batch 60/145, Loss: 0.1805
Epoch 8/10, Batch 70/145, Loss: 0.1589
Epoch 8/10, Batch 80/145, Loss: 0.2628
Epoch 8/10, Batch 90/145, Loss: 0.2518
Epoch 8/10, Batch 100/145, Loss: 0.2925
Epoch 8/10, Batch 110/145, Loss: 0.2254
Epoch 8/10, Batch 120/145, Loss: 0.1425
Epoch 8/10, Batch 130/145, Loss: 0.1964
Epoch 8/10, Batch 140/145, Loss: 0.2690
Epoch 8/10, Train Loss: 0.2030, Valid Loss: 0.2217
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2387
Epoch 9/10, Batch 20/145, Loss: 0.1685
Epoch 9/10, Batch 30/145, Loss: 0.1469
Epoch 9/10, Batch 40/145, Loss: 0.1931
Epoch 9/10, Batch 50/145, Loss: 0.1423
Epoch 9/10, Batch 60/145, Loss: 0.1148
Epoch 9/10, Batch 70/145, Loss: 0.1594
Epoch 9/10, Batch 80/145, Loss: 0.0840
Epoch 9/10, Batch 90/145, Loss: 0.0870
Epoch 9/10, Batch 100/145, Loss: 0.2288
Epoch 9/10, Batch 110/145, Loss: 0.2531
Epoch 9/10, Batch 120/145, Loss: 0.1255
Epoch 9/10, Batch 130/145, Loss: 0.1974
Epoch 9/10, Batch 140/145, Loss: 0.2661
Epoch 9/10, Train Loss: 0.1984, Valid Loss: 0.2088
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1035
Epoch 10/10, Batch 20/145, Loss: 0.0870
Epoch 10/10, Batch 30/145, Loss: 0.0595
Epoch 10/10, Batch 40/145, Loss: 0.1251
Epoch 10/10, Batch 50/145, Loss: 0.3695
Epoch 10/10, Batch 60/145, Loss: 0.2324
Epoch 10/10, Batch 70/145, Loss: 0.1439
Epoch 10/10, Batch 80/145, Loss: 0.2838
Epoch 10/10, Batch 90/145, Loss: 0.1423
Epoch 10/10, Batch 100/145, Loss: 0.1180
Epoch 10/10, Batch 110/145, Loss: 0.1666
Epoch 10/10, Batch 120/145, Loss: 0.2348
Epoch 10/10, Batch 130/145, Loss: 0.1830
Epoch 10/10, Batch 140/145, Loss: 0.1136
Epoch 10/10, Train Loss: 0.1972, Valid Loss: 0.2110
Accuracy: 0.9159
Precision: 0.9141
Recall: 0.9159
F1-score: 0.9145
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4584
Epoch 1/10, Batch 20/145, Loss: 0.9619
Epoch 1/10, Batch 30/145, Loss: 0.8605
Epoch 1/10, Batch 40/145, Loss: 0.8993
Epoch 1/10, Batch 50/145, Loss: 0.6188
Epoch 1/10, Batch 60/145, Loss: 0.5807
Epoch 1/10, Batch 70/145, Loss: 0.7172
Epoch 1/10, Batch 80/145, Loss: 0.6114
Epoch 1/10, Batch 90/145, Loss: 0.5128
Epoch 1/10, Batch 100/145, Loss: 0.5088
Epoch 1/10, Batch 110/145, Loss: 0.5174
Epoch 1/10, Batch 120/145, Loss: 0.5365
Epoch 1/10, Batch 130/145, Loss: 0.2569
Epoch 1/10, Batch 140/145, Loss: 0.4055
Epoch 1/10, Train Loss: 0.6895, Valid Loss: 0.3808
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4698
Epoch 2/10, Batch 20/145, Loss: 0.4944
Epoch 2/10, Batch 30/145, Loss: 0.3878
Epoch 2/10, Batch 40/145, Loss: 0.3310
Epoch 2/10, Batch 50/145, Loss: 0.3850
Epoch 2/10, Batch 60/145, Loss: 0.3834
Epoch 2/10, Batch 70/145, Loss: 0.3662
Epoch 2/10, Batch 80/145, Loss: 0.2079
Epoch 2/10, Batch 90/145, Loss: 0.2494
Epoch 2/10, Batch 100/145, Loss: 0.2862
Epoch 2/10, Batch 110/145, Loss: 0.2562
Epoch 2/10, Batch 120/145, Loss: 0.3761
Epoch 2/10, Batch 130/145, Loss: 0.4262
Epoch 2/10, Batch 140/145, Loss: 0.2272
Epoch 2/10, Train Loss: 0.3637, Valid Loss: 0.2875
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2106
Epoch 3/10, Batch 20/145, Loss: 0.2926
Epoch 3/10, Batch 30/145, Loss: 0.2951
Epoch 3/10, Batch 40/145, Loss: 0.2993
Epoch 3/10, Batch 50/145, Loss: 0.1834
Epoch 3/10, Batch 60/145, Loss: 0.2771
Epoch 3/10, Batch 70/145, Loss: 0.1818
Epoch 3/10, Batch 80/145, Loss: 0.2557
Epoch 3/10, Batch 90/145, Loss: 0.5435
Epoch 3/10, Batch 100/145, Loss: 0.2438
Epoch 3/10, Batch 110/145, Loss: 0.1970
Epoch 3/10, Batch 120/145, Loss: 0.2731
Epoch 3/10, Batch 130/145, Loss: 0.1998
Epoch 3/10, Batch 140/145, Loss: 0.1728
Epoch 3/10, Train Loss: 0.3118, Valid Loss: 0.2514
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2425
Epoch 4/10, Batch 20/145, Loss: 0.2990
Epoch 4/10, Batch 30/145, Loss: 0.3067
Epoch 4/10, Batch 40/145, Loss: 0.2654
Epoch 4/10, Batch 50/145, Loss: 0.2673
Epoch 4/10, Batch 60/145, Loss: 0.2063
Epoch 4/10, Batch 70/145, Loss: 0.1631
Epoch 4/10, Batch 80/145, Loss: 0.3224
Epoch 4/10, Batch 90/145, Loss: 0.3514
Epoch 4/10, Batch 100/145, Loss: 0.1679
Epoch 4/10, Batch 110/145, Loss: 0.2377
Epoch 4/10, Batch 120/145, Loss: 0.1532
Epoch 4/10, Batch 130/145, Loss: 0.1719
Epoch 4/10, Batch 140/145, Loss: 0.0976
Epoch 4/10, Train Loss: 0.2701, Valid Loss: 0.2561
Epoch 5/10, Batch 10/145, Loss: 0.1813
Epoch 5/10, Batch 20/145, Loss: 0.2692
Epoch 5/10, Batch 30/145, Loss: 0.2661
Epoch 5/10, Batch 40/145, Loss: 0.1470
Epoch 5/10, Batch 50/145, Loss: 0.1997
Epoch 5/10, Batch 60/145, Loss: 0.2682
Epoch 5/10, Batch 70/145, Loss: 0.1994
Epoch 5/10, Batch 80/145, Loss: 0.2600
Epoch 5/10, Batch 90/145, Loss: 0.1921
Epoch 5/10, Batch 100/145, Loss: 0.3553
Epoch 5/10, Batch 110/145, Loss: 0.1866
Epoch 5/10, Batch 120/145, Loss: 0.1755
Epoch 5/10, Batch 130/145, Loss: 0.3352
Epoch 5/10, Batch 140/145, Loss: 0.1795
Epoch 5/10, Train Loss: 0.2443, Valid Loss: 0.2316
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3601
Epoch 6/10, Batch 20/145, Loss: 0.1973
Epoch 6/10, Batch 30/145, Loss: 0.2695
Epoch 6/10, Batch 40/145, Loss: 0.1547
Epoch 6/10, Batch 50/145, Loss: 0.2409
Epoch 6/10, Batch 60/145, Loss: 0.1501
Epoch 6/10, Batch 70/145, Loss: 0.2314
Epoch 6/10, Batch 80/145, Loss: 0.4913
Epoch 6/10, Batch 90/145, Loss: 0.2456
Epoch 6/10, Batch 100/145, Loss: 0.1469
Epoch 6/10, Batch 110/145, Loss: 0.1336
Epoch 6/10, Batch 120/145, Loss: 0.1389
Epoch 6/10, Batch 130/145, Loss: 0.1378
Epoch 6/10, Batch 140/145, Loss: 0.5096
Epoch 6/10, Train Loss: 0.2308, Valid Loss: 0.2154
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3598
Epoch 7/10, Batch 20/145, Loss: 0.1908
Epoch 7/10, Batch 30/145, Loss: 0.1576
Epoch 7/10, Batch 40/145, Loss: 0.2690
Epoch 7/10, Batch 50/145, Loss: 0.2128
Epoch 7/10, Batch 60/145, Loss: 0.1489
Epoch 7/10, Batch 70/145, Loss: 0.2445
Epoch 7/10, Batch 80/145, Loss: 0.1088
Epoch 7/10, Batch 90/145, Loss: 0.2346
Epoch 7/10, Batch 100/145, Loss: 0.2464
Epoch 7/10, Batch 110/145, Loss: 0.1414
Epoch 7/10, Batch 120/145, Loss: 0.1537
Epoch 7/10, Batch 130/145, Loss: 0.2104
Epoch 7/10, Batch 140/145, Loss: 0.0929
Epoch 7/10, Train Loss: 0.2182, Valid Loss: 0.2103
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2330
Epoch 8/10, Batch 20/145, Loss: 0.3011
Epoch 8/10, Batch 30/145, Loss: 0.2015
Epoch 8/10, Batch 40/145, Loss: 0.2127
Epoch 8/10, Batch 50/145, Loss: 0.2191
Epoch 8/10, Batch 60/145, Loss: 0.2179
Epoch 8/10, Batch 70/145, Loss: 0.1014
Epoch 8/10, Batch 80/145, Loss: 0.2195
Epoch 8/10, Batch 90/145, Loss: 0.1178
Epoch 8/10, Batch 100/145, Loss: 0.1773
Epoch 8/10, Batch 110/145, Loss: 0.2478
Epoch 8/10, Batch 120/145, Loss: 0.1500
Epoch 8/10, Batch 130/145, Loss: 0.1231
Epoch 8/10, Batch 140/145, Loss: 0.2838
Epoch 8/10, Train Loss: 0.2136, Valid Loss: 0.2069
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1217
Epoch 9/10, Batch 20/145, Loss: 0.2443
Epoch 9/10, Batch 30/145, Loss: 0.2048
Epoch 9/10, Batch 40/145, Loss: 0.2398
Epoch 9/10, Batch 50/145, Loss: 0.1708
Epoch 9/10, Batch 60/145, Loss: 0.2114
Epoch 9/10, Batch 70/145, Loss: 0.3485
Epoch 9/10, Batch 80/145, Loss: 0.2494
Epoch 9/10, Batch 90/145, Loss: 0.1292
Epoch 9/10, Batch 100/145, Loss: 0.3450
Epoch 9/10, Batch 110/145, Loss: 0.1655
Epoch 9/10, Batch 120/145, Loss: 0.1722
Epoch 9/10, Batch 130/145, Loss: 0.1023
Epoch 9/10, Batch 140/145, Loss: 0.3508
Epoch 9/10, Train Loss: 0.2113, Valid Loss: 0.2029
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1005
Epoch 10/10, Batch 20/145, Loss: 0.1312
Epoch 10/10, Batch 30/145, Loss: 0.1554
Epoch 10/10, Batch 40/145, Loss: 0.3453
Epoch 10/10, Batch 50/145, Loss: 0.2449
Epoch 10/10, Batch 60/145, Loss: 0.1823
Epoch 10/10, Batch 70/145, Loss: 0.1241
Epoch 10/10, Batch 80/145, Loss: 0.3621
Epoch 10/10, Batch 90/145, Loss: 0.2145
Epoch 10/10, Batch 100/145, Loss: 0.0835
Epoch 10/10, Batch 110/145, Loss: 0.2569
Epoch 10/10, Batch 120/145, Loss: 0.2106
Epoch 10/10, Batch 130/145, Loss: 0.2138
Epoch 10/10, Batch 140/145, Loss: 0.2198
Epoch 10/10, Train Loss: 0.2016, Valid Loss: 0.2033
Accuracy: 0.9194
Precision: 0.9181
Recall: 0.9194
F1-score: 0.9186
Memory Allocated after cleanup: 17.76 MB
End time: 2025-02-25 07:15:25.713154
Duration: 9:47:16


Mejor accuracy al acabar el algoritmo: 0.9369


Fitness check:

Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5154
Epoch 1/10, Batch 20/145, Loss: 0.9046
Epoch 1/10, Batch 30/145, Loss: 0.8073
Epoch 1/10, Batch 40/145, Loss: 0.7812
Epoch 1/10, Batch 50/145, Loss: 0.5504
Epoch 1/10, Batch 60/145, Loss: 0.5920
Epoch 1/10, Batch 70/145, Loss: 0.5981
Epoch 1/10, Batch 80/145, Loss: 0.4949
Epoch 1/10, Batch 90/145, Loss: 0.5716
Epoch 1/10, Batch 100/145, Loss: 0.5732
Epoch 1/10, Batch 110/145, Loss: 0.4174
Epoch 1/10, Batch 120/145, Loss: 0.5312
Epoch 1/10, Batch 130/145, Loss: 0.4206
Epoch 1/10, Batch 140/145, Loss: 0.3942
Epoch 1/10, Train Loss: 0.6838, Valid Loss: 0.3730
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3503
Epoch 2/10, Batch 20/145, Loss: 0.5071
Epoch 2/10, Batch 30/145, Loss: 0.1813
Epoch 2/10, Batch 40/145, Loss: 0.4205
Epoch 2/10, Batch 50/145, Loss: 0.2148
Epoch 2/10, Batch 60/145, Loss: 0.3308
Epoch 2/10, Batch 70/145, Loss: 0.3175
Epoch 2/10, Batch 80/145, Loss: 0.2354
Epoch 2/10, Batch 90/145, Loss: 0.1965
Epoch 2/10, Batch 100/145, Loss: 0.2416
Epoch 2/10, Batch 110/145, Loss: 0.3414
Epoch 2/10, Batch 120/145, Loss: 0.4731
Epoch 2/10, Batch 130/145, Loss: 0.2360
Epoch 2/10, Batch 140/145, Loss: 0.1603
Epoch 2/10, Train Loss: 0.3545, Valid Loss: 0.2861
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2882
Epoch 3/10, Batch 20/145, Loss: 0.2007
Epoch 3/10, Batch 30/145, Loss: 0.1927
Epoch 3/10, Batch 40/145, Loss: 0.1739
Epoch 3/10, Batch 50/145, Loss: 0.2582
Epoch 3/10, Batch 60/145, Loss: 0.3005
Epoch 3/10, Batch 70/145, Loss: 0.2406
Epoch 3/10, Batch 80/145, Loss: 0.2120
Epoch 3/10, Batch 90/145, Loss: 0.4914
Epoch 3/10, Batch 100/145, Loss: 0.2590
Epoch 3/10, Batch 110/145, Loss: 0.3003
Epoch 3/10, Batch 120/145, Loss: 0.2743
Epoch 3/10, Batch 130/145, Loss: 0.3276
Epoch 3/10, Batch 140/145, Loss: 0.2157
Epoch 3/10, Train Loss: 0.2993, Valid Loss: 0.2621
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3355
Epoch 4/10, Batch 20/145, Loss: 0.1289
Epoch 4/10, Batch 30/145, Loss: 0.2049
Epoch 4/10, Batch 40/145, Loss: 0.3423
Epoch 4/10, Batch 50/145, Loss: 0.2598
Epoch 4/10, Batch 60/145, Loss: 0.1649
Epoch 4/10, Batch 70/145, Loss: 0.2573
Epoch 4/10, Batch 80/145, Loss: 0.2370
Epoch 4/10, Batch 90/145, Loss: 0.3800
Epoch 4/10, Batch 100/145, Loss: 0.1747
Epoch 4/10, Batch 110/145, Loss: 0.1590
Epoch 4/10, Batch 120/145, Loss: 0.1429
Epoch 4/10, Batch 130/145, Loss: 0.1665
Epoch 4/10, Batch 140/145, Loss: 0.2165
Epoch 4/10, Train Loss: 0.2649, Valid Loss: 0.2570
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2237
Epoch 5/10, Batch 20/145, Loss: 0.2316
Epoch 5/10, Batch 30/145, Loss: 0.1604
Epoch 5/10, Batch 40/145, Loss: 0.3136
Epoch 5/10, Batch 50/145, Loss: 0.2117
Epoch 5/10, Batch 60/145, Loss: 0.1750
Epoch 5/10, Batch 70/145, Loss: 0.3187
Epoch 5/10, Batch 80/145, Loss: 0.3707
Epoch 5/10, Batch 90/145, Loss: 0.1860
Epoch 5/10, Batch 100/145, Loss: 0.2961
Epoch 5/10, Batch 110/145, Loss: 0.1650
Epoch 5/10, Batch 120/145, Loss: 0.1859
Epoch 5/10, Batch 130/145, Loss: 0.2054
Epoch 5/10, Batch 140/145, Loss: 0.1830
Epoch 5/10, Train Loss: 0.2392, Valid Loss: 0.2335
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2714
Epoch 6/10, Batch 20/145, Loss: 0.2113
Epoch 6/10, Batch 30/145, Loss: 0.2012
Epoch 6/10, Batch 40/145, Loss: 0.0829
Epoch 6/10, Batch 50/145, Loss: 0.4025
Epoch 6/10, Batch 60/145, Loss: 0.2407
Epoch 6/10, Batch 70/145, Loss: 0.2345
Epoch 6/10, Batch 80/145, Loss: 0.3410
Epoch 6/10, Batch 90/145, Loss: 0.1960
Epoch 6/10, Batch 100/145, Loss: 0.2128
Epoch 6/10, Batch 110/145, Loss: 0.2231
Epoch 6/10, Batch 120/145, Loss: 0.2758
Epoch 6/10, Batch 130/145, Loss: 0.1574
Epoch 6/10, Batch 140/145, Loss: 0.2115
Epoch 6/10, Train Loss: 0.2227, Valid Loss: 0.2318
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2824
Epoch 7/10, Batch 20/145, Loss: 0.3392
Epoch 7/10, Batch 30/145, Loss: 0.1286
Epoch 7/10, Batch 40/145, Loss: 0.3771
Epoch 7/10, Batch 50/145, Loss: 0.1464
Epoch 7/10, Batch 60/145, Loss: 0.1199
Epoch 7/10, Batch 70/145, Loss: 0.3842
Epoch 7/10, Batch 80/145, Loss: 0.2235
Epoch 7/10, Batch 90/145, Loss: 0.3060
Epoch 7/10, Batch 100/145, Loss: 0.1331
Epoch 7/10, Batch 110/145, Loss: 0.3418
Epoch 7/10, Batch 120/145, Loss: 0.0681
Epoch 7/10, Batch 130/145, Loss: 0.1416
Epoch 7/10, Batch 140/145, Loss: 0.1163
Epoch 7/10, Train Loss: 0.2165, Valid Loss: 0.2260
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.3149
Epoch 8/10, Batch 20/145, Loss: 0.0677
Epoch 8/10, Batch 30/145, Loss: 0.1484
Epoch 8/10, Batch 40/145, Loss: 0.2701
Epoch 8/10, Batch 50/145, Loss: 0.3818
Epoch 8/10, Batch 60/145, Loss: 0.2618
Epoch 8/10, Batch 70/145, Loss: 0.2311
Epoch 8/10, Batch 80/145, Loss: 0.1884
Epoch 8/10, Batch 90/145, Loss: 0.1833
Epoch 8/10, Batch 100/145, Loss: 0.2406
Epoch 8/10, Batch 110/145, Loss: 0.2386
Epoch 8/10, Batch 120/145, Loss: 0.2053
Epoch 8/10, Batch 130/145, Loss: 0.3789
Epoch 8/10, Batch 140/145, Loss: 0.2700
Epoch 8/10, Train Loss: 0.2085, Valid Loss: 0.2153
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1745
Epoch 9/10, Batch 20/145, Loss: 0.1017
Epoch 9/10, Batch 30/145, Loss: 0.1072
Epoch 9/10, Batch 40/145, Loss: 0.1311
Epoch 9/10, Batch 50/145, Loss: 0.1765
Epoch 9/10, Batch 60/145, Loss: 0.1090
Epoch 9/10, Batch 70/145, Loss: 0.2270
Epoch 9/10, Batch 80/145, Loss: 0.1757
Epoch 9/10, Batch 90/145, Loss: 0.3501
Epoch 9/10, Batch 100/145, Loss: 0.2336
Epoch 9/10, Batch 110/145, Loss: 0.0951
Epoch 9/10, Batch 120/145, Loss: 0.3371
Epoch 9/10, Batch 130/145, Loss: 0.2190
Epoch 9/10, Batch 140/145, Loss: 0.1566
Epoch 9/10, Train Loss: 0.2034, Valid Loss: 0.2081
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1294
Epoch 10/10, Batch 20/145, Loss: 0.1080
Epoch 10/10, Batch 30/145, Loss: 0.0663
Epoch 10/10, Batch 40/145, Loss: 0.1638
Epoch 10/10, Batch 50/145, Loss: 0.2620
Epoch 10/10, Batch 60/145, Loss: 0.2462
Epoch 10/10, Batch 70/145, Loss: 0.1133
Epoch 10/10, Batch 80/145, Loss: 0.4296
Epoch 10/10, Batch 90/145, Loss: 0.1627
Epoch 10/10, Batch 100/145, Loss: 0.0905
Epoch 10/10, Batch 110/145, Loss: 0.2110
Epoch 10/10, Batch 120/145, Loss: 0.1441
Epoch 10/10, Batch 130/145, Loss: 0.0910
Epoch 10/10, Batch 140/145, Loss: 0.2193
Epoch 10/10, Train Loss: 0.1919, Valid Loss: 0.2076
Model saved!
Accuracy: 0.9369
Precision: 0.9360
Recall: 0.9369
F1-score: 0.9364
Memory Allocated after cleanup: 17.76 MB


Mejor accuracy encontrado: 0.9369


--------------------------------------mobilenet  BUSQUEDA LOCAL  10%-------------------------------------------------
Start time: 2025-02-25 07:21:11.404738
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3456
Epoch 1/10, Batch 20/20, Loss: 1.2858
Epoch 1/10, Train Loss: 1.2999, Valid Loss: 1.0984
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9844
Epoch 2/10, Batch 20/20, Loss: 0.7927
Epoch 2/10, Train Loss: 0.8370, Valid Loss: 0.7854
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8123
Epoch 3/10, Batch 20/20, Loss: 0.9213
Epoch 3/10, Train Loss: 0.6442, Valid Loss: 0.6484
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5171
Epoch 4/10, Batch 20/20, Loss: 0.5158
Epoch 4/10, Train Loss: 0.5218, Valid Loss: 0.6016
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4658
Epoch 5/10, Batch 20/20, Loss: 0.4298
Epoch 5/10, Train Loss: 0.4496, Valid Loss: 0.5274
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6494
Epoch 6/10, Batch 20/20, Loss: 0.6205
Epoch 6/10, Train Loss: 0.4272, Valid Loss: 0.5181
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4017
Epoch 7/10, Batch 20/20, Loss: 0.3755
Epoch 7/10, Train Loss: 0.3627, Valid Loss: 0.4816
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4408
Epoch 8/10, Batch 20/20, Loss: 0.6091
Epoch 8/10, Train Loss: 0.3583, Valid Loss: 0.4741
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3408
Epoch 9/10, Batch 20/20, Loss: 0.3615
Epoch 9/10, Train Loss: 0.3096, Valid Loss: 0.4473
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3118
Epoch 10/10, Batch 20/20, Loss: 0.6187
Epoch 10/10, Train Loss: 0.3034, Valid Loss: 0.4417
Model saved!
Accuracy: 0.8785
Precision: 0.8731
Recall: 0.8785
F1-score: 0.8752
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1828
Epoch 1/10, Batch 20/20, Loss: 1.4072
Epoch 1/10, Train Loss: 1.2884, Valid Loss: 1.0874
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9825
Epoch 2/10, Batch 20/20, Loss: 0.5173
Epoch 2/10, Train Loss: 0.8169, Valid Loss: 0.7479
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7940
Epoch 3/10, Batch 20/20, Loss: 0.6946
Epoch 3/10, Train Loss: 0.6312, Valid Loss: 0.6279
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4788
Epoch 4/10, Batch 20/20, Loss: 0.5135
Epoch 4/10, Train Loss: 0.5140, Valid Loss: 0.5474
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4060
Epoch 5/10, Batch 20/20, Loss: 0.8118
Epoch 5/10, Train Loss: 0.4510, Valid Loss: 0.4984
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5563
Epoch 6/10, Batch 20/20, Loss: 0.5623
Epoch 6/10, Train Loss: 0.4024, Valid Loss: 0.4587
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3185
Epoch 7/10, Batch 20/20, Loss: 0.6475
Epoch 7/10, Train Loss: 0.3701, Valid Loss: 0.4385
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4101
Epoch 8/10, Batch 20/20, Loss: 0.3254
Epoch 8/10, Train Loss: 0.3413, Valid Loss: 0.4138
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3444
Epoch 9/10, Batch 20/20, Loss: 0.6448
Epoch 9/10, Train Loss: 0.3216, Valid Loss: 0.3937
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2435
Epoch 10/10, Batch 20/20, Loss: 0.3011
Epoch 10/10, Train Loss: 0.2874, Valid Loss: 0.3864
Model saved!
Accuracy: 0.8738
Precision: 0.8670
Recall: 0.8738
F1-score: 0.8677
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1704
Epoch 1/10, Batch 20/20, Loss: 1.2017
Epoch 1/10, Train Loss: 1.2690, Valid Loss: 1.0512
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0104
Epoch 2/10, Batch 20/20, Loss: 0.9025
Epoch 2/10, Train Loss: 0.8210, Valid Loss: 0.7635
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6977
Epoch 3/10, Batch 20/20, Loss: 0.7062
Epoch 3/10, Train Loss: 0.6309, Valid Loss: 0.6352
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4077
Epoch 4/10, Batch 20/20, Loss: 0.4615
Epoch 4/10, Train Loss: 0.5045, Valid Loss: 0.5655
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4866
Epoch 5/10, Batch 20/20, Loss: 0.8626
Epoch 5/10, Train Loss: 0.4646, Valid Loss: 0.5162
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5976
Epoch 6/10, Batch 20/20, Loss: 0.2617
Epoch 6/10, Train Loss: 0.4040, Valid Loss: 0.4837
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4340
Epoch 7/10, Batch 20/20, Loss: 0.5712
Epoch 7/10, Train Loss: 0.3629, Valid Loss: 0.4671
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4679
Epoch 8/10, Batch 20/20, Loss: 0.4370
Epoch 8/10, Train Loss: 0.3332, Valid Loss: 0.4474
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3698
Epoch 9/10, Batch 20/20, Loss: 0.2345
Epoch 9/10, Train Loss: 0.3180, Valid Loss: 0.4297
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2591
Epoch 10/10, Batch 20/20, Loss: 0.7898
Epoch 10/10, Train Loss: 0.3075, Valid Loss: 0.4215
Model saved!
Accuracy: 0.8832
Precision: 0.8820
Recall: 0.8832
F1-score: 0.8786
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 3. Fitness: 0.8832
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1688
Epoch 1/10, Batch 20/20, Loss: 1.1939
Epoch 1/10, Train Loss: 1.2863, Valid Loss: 0.9954
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9130
Epoch 2/10, Batch 20/20, Loss: 0.7839
Epoch 2/10, Train Loss: 0.8167, Valid Loss: 0.7117
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6880
Epoch 3/10, Batch 20/20, Loss: 0.6985
Epoch 3/10, Train Loss: 0.6306, Valid Loss: 0.6013
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5872
Epoch 4/10, Batch 20/20, Loss: 0.4881
Epoch 4/10, Train Loss: 0.5064, Valid Loss: 0.5301
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5163
Epoch 5/10, Batch 20/20, Loss: 0.6659
Epoch 5/10, Train Loss: 0.4529, Valid Loss: 0.4977
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.7375
Epoch 6/10, Batch 20/20, Loss: 0.3330
Epoch 6/10, Train Loss: 0.4013, Valid Loss: 0.4645
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3304
Epoch 7/10, Batch 20/20, Loss: 0.4685
Epoch 7/10, Train Loss: 0.3520, Valid Loss: 0.4495
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3549
Epoch 8/10, Batch 20/20, Loss: 0.6270
Epoch 8/10, Train Loss: 0.3390, Valid Loss: 0.4343
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4202
Epoch 9/10, Batch 20/20, Loss: 0.4723
Epoch 9/10, Train Loss: 0.3138, Valid Loss: 0.4261
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3081
Epoch 10/10, Batch 20/20, Loss: 0.8765
Epoch 10/10, Train Loss: 0.3039, Valid Loss: 0.4132
Model saved!
Accuracy: 0.8692
Precision: 0.8661
Recall: 0.8692
F1-score: 0.8606
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1947
Epoch 1/10, Batch 20/20, Loss: 1.2331
Epoch 1/10, Train Loss: 1.2732, Valid Loss: 1.0295
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9724
Epoch 2/10, Batch 20/20, Loss: 0.6563
Epoch 2/10, Train Loss: 0.7941, Valid Loss: 0.7344
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7201
Epoch 3/10, Batch 20/20, Loss: 0.7864
Epoch 3/10, Train Loss: 0.6136, Valid Loss: 0.6206
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5311
Epoch 4/10, Batch 20/20, Loss: 0.7127
Epoch 4/10, Train Loss: 0.5032, Valid Loss: 0.5393
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4080
Epoch 5/10, Batch 20/20, Loss: 0.9095
Epoch 5/10, Train Loss: 0.4568, Valid Loss: 0.5140
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.7378
Epoch 6/10, Batch 20/20, Loss: 0.4032
Epoch 6/10, Train Loss: 0.3875, Valid Loss: 0.4804
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3967
Epoch 7/10, Batch 20/20, Loss: 0.4317
Epoch 7/10, Train Loss: 0.3386, Valid Loss: 0.4598
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5096
Epoch 8/10, Batch 20/20, Loss: 0.2298
Epoch 8/10, Train Loss: 0.3331, Valid Loss: 0.4495
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3027
Epoch 9/10, Batch 20/20, Loss: 0.3984
Epoch 9/10, Train Loss: 0.3050, Valid Loss: 0.4375
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2805
Epoch 10/10, Batch 20/20, Loss: 0.3781
Epoch 10/10, Train Loss: 0.2752, Valid Loss: 0.4363
Model saved!
Accuracy: 0.8902
Precision: 0.8857
Recall: 0.8902
F1-score: 0.8847
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 5. Fitness: 0.8902
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2094
Epoch 1/10, Batch 20/20, Loss: 1.3198
Epoch 1/10, Train Loss: 1.2868, Valid Loss: 1.0542
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9618
Epoch 2/10, Batch 20/20, Loss: 0.6273
Epoch 2/10, Train Loss: 0.8124, Valid Loss: 0.7437
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6473
Epoch 3/10, Batch 20/20, Loss: 0.7760
Epoch 3/10, Train Loss: 0.6280, Valid Loss: 0.6206
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3494
Epoch 4/10, Batch 20/20, Loss: 0.7222
Epoch 4/10, Train Loss: 0.5021, Valid Loss: 0.5455
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3902
Epoch 5/10, Batch 20/20, Loss: 0.7168
Epoch 5/10, Train Loss: 0.4449, Valid Loss: 0.5002
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4956
Epoch 6/10, Batch 20/20, Loss: 0.6797
Epoch 6/10, Train Loss: 0.4154, Valid Loss: 0.4703
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3671
Epoch 7/10, Batch 20/20, Loss: 0.4653
Epoch 7/10, Train Loss: 0.3586, Valid Loss: 0.4358
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4802
Epoch 8/10, Batch 20/20, Loss: 0.3992
Epoch 8/10, Train Loss: 0.3345, Valid Loss: 0.4248
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2562
Epoch 9/10, Batch 20/20, Loss: 0.6878
Epoch 9/10, Train Loss: 0.3239, Valid Loss: 0.4141
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2902
Epoch 10/10, Batch 20/20, Loss: 0.7351
Epoch 10/10, Train Loss: 0.3060, Valid Loss: 0.3975
Model saved!
Accuracy: 0.8855
Precision: 0.8804
Recall: 0.8855
F1-score: 0.8816
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1694
Epoch 1/10, Batch 20/20, Loss: 1.3367
Epoch 1/10, Train Loss: 1.2881, Valid Loss: 1.0336
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0051
Epoch 2/10, Batch 20/20, Loss: 0.9010
Epoch 2/10, Train Loss: 0.8191, Valid Loss: 0.7419
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8258
Epoch 3/10, Batch 20/20, Loss: 0.9522
Epoch 3/10, Train Loss: 0.6354, Valid Loss: 0.6350
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4114
Epoch 4/10, Batch 20/20, Loss: 0.3413
Epoch 4/10, Train Loss: 0.5007, Valid Loss: 0.5679
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.6018
Epoch 5/10, Batch 20/20, Loss: 0.8470
Epoch 5/10, Train Loss: 0.4609, Valid Loss: 0.5331
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6486
Epoch 6/10, Batch 20/20, Loss: 0.6274
Epoch 6/10, Train Loss: 0.4091, Valid Loss: 0.4926
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3393
Epoch 7/10, Batch 20/20, Loss: 0.5506
Epoch 7/10, Train Loss: 0.3547, Valid Loss: 0.4744
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3813
Epoch 8/10, Batch 20/20, Loss: 0.6407
Epoch 8/10, Train Loss: 0.3618, Valid Loss: 0.4519
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4295
Epoch 9/10, Batch 20/20, Loss: 0.6924
Epoch 9/10, Train Loss: 0.3375, Valid Loss: 0.4590
Epoch 10/10, Batch 10/20, Loss: 0.4418
Epoch 10/10, Batch 20/20, Loss: 0.6483
Epoch 10/10, Train Loss: 0.3044, Valid Loss: 0.4315
Model saved!
Accuracy: 0.8808
Precision: 0.8770
Recall: 0.8808
F1-score: 0.8775
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2949
Epoch 1/10, Batch 20/20, Loss: 1.2805
Epoch 1/10, Train Loss: 1.2993, Valid Loss: 1.0617
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8608
Epoch 2/10, Batch 20/20, Loss: 0.5683
Epoch 2/10, Train Loss: 0.8240, Valid Loss: 0.7212
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7067
Epoch 3/10, Batch 20/20, Loss: 1.0171
Epoch 3/10, Train Loss: 0.6434, Valid Loss: 0.5912
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5131
Epoch 4/10, Batch 20/20, Loss: 0.9086
Epoch 4/10, Train Loss: 0.5275, Valid Loss: 0.5068
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4170
Epoch 5/10, Batch 20/20, Loss: 0.4606
Epoch 5/10, Train Loss: 0.4491, Valid Loss: 0.4669
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5118
Epoch 6/10, Batch 20/20, Loss: 0.4500
Epoch 6/10, Train Loss: 0.3956, Valid Loss: 0.4184
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3109
Epoch 7/10, Batch 20/20, Loss: 0.4652
Epoch 7/10, Train Loss: 0.3562, Valid Loss: 0.3907
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3726
Epoch 8/10, Batch 20/20, Loss: 0.4651
Epoch 8/10, Train Loss: 0.3463, Valid Loss: 0.3791
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3078
Epoch 9/10, Batch 20/20, Loss: 0.6117
Epoch 9/10, Train Loss: 0.3107, Valid Loss: 0.3631
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2939
Epoch 10/10, Batch 20/20, Loss: 0.5037
Epoch 10/10, Train Loss: 0.2823, Valid Loss: 0.3482
Model saved!
Accuracy: 0.8855
Precision: 0.8818
Recall: 0.8855
F1-score: 0.8808
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2377
Epoch 1/10, Batch 20/20, Loss: 1.2113
Epoch 1/10, Train Loss: 1.2623, Valid Loss: 1.0442
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9045
Epoch 2/10, Batch 20/20, Loss: 0.6310
Epoch 2/10, Train Loss: 0.7713, Valid Loss: 0.7420
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7453
Epoch 3/10, Batch 20/20, Loss: 0.9937
Epoch 3/10, Train Loss: 0.5975, Valid Loss: 0.6194
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5245
Epoch 4/10, Batch 20/20, Loss: 0.6263
Epoch 4/10, Train Loss: 0.4887, Valid Loss: 0.5553
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4957
Epoch 5/10, Batch 20/20, Loss: 0.9246
Epoch 5/10, Train Loss: 0.4353, Valid Loss: 0.5142
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5849
Epoch 6/10, Batch 20/20, Loss: 0.5915
Epoch 6/10, Train Loss: 0.3868, Valid Loss: 0.4853
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3747
Epoch 7/10, Batch 20/20, Loss: 0.7440
Epoch 7/10, Train Loss: 0.3563, Valid Loss: 0.4617
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3295
Epoch 8/10, Batch 20/20, Loss: 0.4741
Epoch 8/10, Train Loss: 0.3274, Valid Loss: 0.4454
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3061
Epoch 9/10, Batch 20/20, Loss: 0.4982
Epoch 9/10, Train Loss: 0.2896, Valid Loss: 0.4216
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2852
Epoch 10/10, Batch 20/20, Loss: 0.3424
Epoch 10/10, Train Loss: 0.2693, Valid Loss: 0.4253
Accuracy: 0.8820
Precision: 0.8772
Recall: 0.8820
F1-score: 0.8753
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1299
Epoch 1/10, Batch 20/20, Loss: 1.3249
Epoch 1/10, Train Loss: 1.2742, Valid Loss: 0.9947
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0705
Epoch 2/10, Batch 20/20, Loss: 0.6752
Epoch 2/10, Train Loss: 0.7917, Valid Loss: 0.6880
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6832
Epoch 3/10, Batch 20/20, Loss: 0.8697
Epoch 3/10, Train Loss: 0.6096, Valid Loss: 0.5670
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4768
Epoch 4/10, Batch 20/20, Loss: 0.3616
Epoch 4/10, Train Loss: 0.4888, Valid Loss: 0.5059
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3815
Epoch 5/10, Batch 20/20, Loss: 0.6760
Epoch 5/10, Train Loss: 0.4437, Valid Loss: 0.4599
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5631
Epoch 6/10, Batch 20/20, Loss: 0.3499
Epoch 6/10, Train Loss: 0.3798, Valid Loss: 0.4236
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2526
Epoch 7/10, Batch 20/20, Loss: 0.3012
Epoch 7/10, Train Loss: 0.3384, Valid Loss: 0.4080
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3659
Epoch 8/10, Batch 20/20, Loss: 0.5915
Epoch 8/10, Train Loss: 0.3333, Valid Loss: 0.3955
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3445
Epoch 9/10, Batch 20/20, Loss: 0.3865
Epoch 9/10, Train Loss: 0.2942, Valid Loss: 0.3774
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3787
Epoch 10/10, Batch 20/20, Loss: 1.0477
Epoch 10/10, Train Loss: 0.3067, Valid Loss: 0.3713
Model saved!
Accuracy: 0.8914
Precision: 0.8861
Recall: 0.8914
F1-score: 0.8864
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 10. Fitness: 0.8914
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1745
Epoch 1/10, Batch 20/20, Loss: 1.3301
Epoch 1/10, Train Loss: 1.2736, Valid Loss: 0.9307
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9009
Epoch 2/10, Batch 20/20, Loss: 0.7115
Epoch 2/10, Train Loss: 0.7978, Valid Loss: 0.6115
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6467
Epoch 3/10, Batch 20/20, Loss: 0.7742
Epoch 3/10, Train Loss: 0.6133, Valid Loss: 0.4779
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4290
Epoch 4/10, Batch 20/20, Loss: 0.5363
Epoch 4/10, Train Loss: 0.4783, Valid Loss: 0.3972
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.2992
Epoch 5/10, Batch 20/20, Loss: 0.4895
Epoch 5/10, Train Loss: 0.4161, Valid Loss: 0.3550
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4544
Epoch 6/10, Batch 20/20, Loss: 0.2431
Epoch 6/10, Train Loss: 0.3697, Valid Loss: 0.3167
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2272
Epoch 7/10, Batch 20/20, Loss: 0.5443
Epoch 7/10, Train Loss: 0.3411, Valid Loss: 0.2910
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4772
Epoch 8/10, Batch 20/20, Loss: 0.5685
Epoch 8/10, Train Loss: 0.3233, Valid Loss: 0.2763
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3709
Epoch 9/10, Batch 20/20, Loss: 0.4037
Epoch 9/10, Train Loss: 0.2880, Valid Loss: 0.2589
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3231
Epoch 10/10, Batch 20/20, Loss: 0.3624
Epoch 10/10, Train Loss: 0.2754, Valid Loss: 0.2524
Model saved!
Accuracy: 0.8773
Precision: 0.8718
Recall: 0.8773
F1-score: 0.8721
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2100
Epoch 1/10, Batch 20/20, Loss: 1.3370
Epoch 1/10, Train Loss: 1.2845, Valid Loss: 1.0110
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8019
Epoch 2/10, Batch 20/20, Loss: 0.6686
Epoch 2/10, Train Loss: 0.8155, Valid Loss: 0.7226
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6645
Epoch 3/10, Batch 20/20, Loss: 0.7578
Epoch 3/10, Train Loss: 0.6160, Valid Loss: 0.5936
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5569
Epoch 4/10, Batch 20/20, Loss: 0.3655
Epoch 4/10, Train Loss: 0.5024, Valid Loss: 0.5174
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4027
Epoch 5/10, Batch 20/20, Loss: 0.5887
Epoch 5/10, Train Loss: 0.4305, Valid Loss: 0.4746
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6848
Epoch 6/10, Batch 20/20, Loss: 0.5673
Epoch 6/10, Train Loss: 0.3948, Valid Loss: 0.4432
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2848
Epoch 7/10, Batch 20/20, Loss: 0.2879
Epoch 7/10, Train Loss: 0.3316, Valid Loss: 0.4178
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4091
Epoch 8/10, Batch 20/20, Loss: 0.4099
Epoch 8/10, Train Loss: 0.3264, Valid Loss: 0.4070
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3861
Epoch 9/10, Batch 20/20, Loss: 0.6902
Epoch 9/10, Train Loss: 0.3147, Valid Loss: 0.3962
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2693
Epoch 10/10, Batch 20/20, Loss: 0.6705
Epoch 10/10, Train Loss: 0.2932, Valid Loss: 0.3779
Model saved!
Accuracy: 0.8855
Precision: 0.8812
Recall: 0.8855
F1-score: 0.8811
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1431
Epoch 1/10, Batch 20/20, Loss: 1.3636
Epoch 1/10, Train Loss: 1.2703, Valid Loss: 1.0441
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8858
Epoch 2/10, Batch 20/20, Loss: 0.5358
Epoch 2/10, Train Loss: 0.7921, Valid Loss: 0.7316
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8476
Epoch 3/10, Batch 20/20, Loss: 0.7011
Epoch 3/10, Train Loss: 0.6150, Valid Loss: 0.6192
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5087
Epoch 4/10, Batch 20/20, Loss: 0.3893
Epoch 4/10, Train Loss: 0.4921, Valid Loss: 0.5388
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4580
Epoch 5/10, Batch 20/20, Loss: 0.4962
Epoch 5/10, Train Loss: 0.4247, Valid Loss: 0.5048
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5744
Epoch 6/10, Batch 20/20, Loss: 0.3816
Epoch 6/10, Train Loss: 0.3805, Valid Loss: 0.4693
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3443
Epoch 7/10, Batch 20/20, Loss: 0.4947
Epoch 7/10, Train Loss: 0.3412, Valid Loss: 0.4507
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3382
Epoch 8/10, Batch 20/20, Loss: 0.2905
Epoch 8/10, Train Loss: 0.3167, Valid Loss: 0.4317
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3550
Epoch 9/10, Batch 20/20, Loss: 0.5934
Epoch 9/10, Train Loss: 0.3072, Valid Loss: 0.4241
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3353
Epoch 10/10, Batch 20/20, Loss: 0.2688
Epoch 10/10, Train Loss: 0.2729, Valid Loss: 0.4175
Model saved!
Accuracy: 0.8703
Precision: 0.8653
Recall: 0.8703
F1-score: 0.8644
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1481
Epoch 1/10, Batch 20/20, Loss: 1.3293
Epoch 1/10, Train Loss: 1.2682, Valid Loss: 1.0441
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9413
Epoch 2/10, Batch 20/20, Loss: 0.5023
Epoch 2/10, Train Loss: 0.7946, Valid Loss: 0.7557
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8344
Epoch 3/10, Batch 20/20, Loss: 0.7955
Epoch 3/10, Train Loss: 0.6189, Valid Loss: 0.6288
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4293
Epoch 4/10, Batch 20/20, Loss: 0.6097
Epoch 4/10, Train Loss: 0.4976, Valid Loss: 0.5694
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3839
Epoch 5/10, Batch 20/20, Loss: 0.4906
Epoch 5/10, Train Loss: 0.4253, Valid Loss: 0.5226
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4859
Epoch 6/10, Batch 20/20, Loss: 0.7302
Epoch 6/10, Train Loss: 0.3933, Valid Loss: 0.4919
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2827
Epoch 7/10, Batch 20/20, Loss: 0.5015
Epoch 7/10, Train Loss: 0.3382, Valid Loss: 0.4730
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4495
Epoch 8/10, Batch 20/20, Loss: 0.5875
Epoch 8/10, Train Loss: 0.3333, Valid Loss: 0.4580
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3486
Epoch 9/10, Batch 20/20, Loss: 0.4575
Epoch 9/10, Train Loss: 0.2968, Valid Loss: 0.4369
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3438
Epoch 10/10, Batch 20/20, Loss: 0.9796
Epoch 10/10, Train Loss: 0.3050, Valid Loss: 0.4463
Accuracy: 0.8867
Precision: 0.8841
Recall: 0.8867
F1-score: 0.8837
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1712
Epoch 1/10, Batch 20/20, Loss: 1.2968
Epoch 1/10, Train Loss: 1.2782, Valid Loss: 1.0010
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0058
Epoch 2/10, Batch 20/20, Loss: 0.6657
Epoch 2/10, Train Loss: 0.7926, Valid Loss: 0.7154
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6996
Epoch 3/10, Batch 20/20, Loss: 0.6280
Epoch 3/10, Train Loss: 0.6018, Valid Loss: 0.5742
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5335
Epoch 4/10, Batch 20/20, Loss: 0.4947
Epoch 4/10, Train Loss: 0.4868, Valid Loss: 0.5134
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4229
Epoch 5/10, Batch 20/20, Loss: 0.5939
Epoch 5/10, Train Loss: 0.4376, Valid Loss: 0.4507
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5935
Epoch 6/10, Batch 20/20, Loss: 0.5273
Epoch 6/10, Train Loss: 0.3811, Valid Loss: 0.4253
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3347
Epoch 7/10, Batch 20/20, Loss: 0.4997
Epoch 7/10, Train Loss: 0.3315, Valid Loss: 0.4036
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3781
Epoch 8/10, Batch 20/20, Loss: 0.5067
Epoch 8/10, Train Loss: 0.3247, Valid Loss: 0.4053
Epoch 9/10, Batch 10/20, Loss: 0.3950
Epoch 9/10, Batch 20/20, Loss: 0.5952
Epoch 9/10, Train Loss: 0.2976, Valid Loss: 0.3616
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3027
Epoch 10/10, Batch 20/20, Loss: 0.5780
Epoch 10/10, Train Loss: 0.2829, Valid Loss: 0.3670
Accuracy: 0.8750
Precision: 0.8649
Recall: 0.8750
F1-score: 0.8658
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1714
Epoch 1/10, Batch 20/20, Loss: 1.3699
Epoch 1/10, Train Loss: 1.2750, Valid Loss: 1.0816
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9873
Epoch 2/10, Batch 20/20, Loss: 0.6213
Epoch 2/10, Train Loss: 0.8316, Valid Loss: 0.7283
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7092
Epoch 3/10, Batch 20/20, Loss: 0.6973
Epoch 3/10, Train Loss: 0.6276, Valid Loss: 0.5970
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5543
Epoch 4/10, Batch 20/20, Loss: 0.5553
Epoch 4/10, Train Loss: 0.5211, Valid Loss: 0.5269
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4530
Epoch 5/10, Batch 20/20, Loss: 0.6738
Epoch 5/10, Train Loss: 0.4609, Valid Loss: 0.4710
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5843
Epoch 6/10, Batch 20/20, Loss: 0.4022
Epoch 6/10, Train Loss: 0.4080, Valid Loss: 0.4322
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4102
Epoch 7/10, Batch 20/20, Loss: 0.5475
Epoch 7/10, Train Loss: 0.3632, Valid Loss: 0.4045
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4422
Epoch 8/10, Batch 20/20, Loss: 0.3838
Epoch 8/10, Train Loss: 0.3337, Valid Loss: 0.3808
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3061
Epoch 9/10, Batch 20/20, Loss: 0.6290
Epoch 9/10, Train Loss: 0.3191, Valid Loss: 0.3570
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3210
Epoch 10/10, Batch 20/20, Loss: 0.4218
Epoch 10/10, Train Loss: 0.2878, Valid Loss: 0.3628
Accuracy: 0.8925
Precision: 0.8876
Recall: 0.8925
F1-score: 0.8892
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 16. Fitness: 0.8925
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2207
Epoch 1/10, Batch 20/20, Loss: 1.0228
Epoch 1/10, Train Loss: 1.2689, Valid Loss: 1.0774
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9259
Epoch 2/10, Batch 20/20, Loss: 0.6023
Epoch 2/10, Train Loss: 0.7972, Valid Loss: 0.8009
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7492
Epoch 3/10, Batch 20/20, Loss: 0.8454
Epoch 3/10, Train Loss: 0.6144, Valid Loss: 0.6741
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4002
Epoch 4/10, Batch 20/20, Loss: 0.4852
Epoch 4/10, Train Loss: 0.5136, Valid Loss: 0.6323
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3597
Epoch 5/10, Batch 20/20, Loss: 0.9167
Epoch 5/10, Train Loss: 0.4520, Valid Loss: 0.5887
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5452
Epoch 6/10, Batch 20/20, Loss: 0.3474
Epoch 6/10, Train Loss: 0.3905, Valid Loss: 0.5556
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.1985
Epoch 7/10, Batch 20/20, Loss: 0.4230
Epoch 7/10, Train Loss: 0.3444, Valid Loss: 0.5329
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5233
Epoch 8/10, Batch 20/20, Loss: 0.2621
Epoch 8/10, Train Loss: 0.3264, Valid Loss: 0.5183
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2978
Epoch 9/10, Batch 20/20, Loss: 0.2936
Epoch 9/10, Train Loss: 0.2829, Valid Loss: 0.4947
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3799
Epoch 10/10, Batch 20/20, Loss: 0.3988
Epoch 10/10, Train Loss: 0.2798, Valid Loss: 0.5066
Accuracy: 0.8785
Precision: 0.8742
Recall: 0.8785
F1-score: 0.8759
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3073
Epoch 1/10, Batch 20/20, Loss: 1.3362
Epoch 1/10, Train Loss: 1.3057, Valid Loss: 1.0742
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9076
Epoch 2/10, Batch 20/20, Loss: 0.6967
Epoch 2/10, Train Loss: 0.8256, Valid Loss: 0.7335
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7385
Epoch 3/10, Batch 20/20, Loss: 0.7628
Epoch 3/10, Train Loss: 0.6293, Valid Loss: 0.6055
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4749
Epoch 4/10, Batch 20/20, Loss: 0.6240
Epoch 4/10, Train Loss: 0.5109, Valid Loss: 0.5255
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4649
Epoch 5/10, Batch 20/20, Loss: 0.6321
Epoch 5/10, Train Loss: 0.4479, Valid Loss: 0.4921
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6307
Epoch 6/10, Batch 20/20, Loss: 0.7255
Epoch 6/10, Train Loss: 0.4146, Valid Loss: 0.4473
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3314
Epoch 7/10, Batch 20/20, Loss: 0.3975
Epoch 7/10, Train Loss: 0.3621, Valid Loss: 0.4291
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4986
Epoch 8/10, Batch 20/20, Loss: 0.3346
Epoch 8/10, Train Loss: 0.3180, Valid Loss: 0.4158
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2555
Epoch 9/10, Batch 20/20, Loss: 0.4898
Epoch 9/10, Train Loss: 0.3108, Valid Loss: 0.3999
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2924
Epoch 10/10, Batch 20/20, Loss: 0.5283
Epoch 10/10, Train Loss: 0.2896, Valid Loss: 0.4109
Accuracy: 0.8914
Precision: 0.8878
Recall: 0.8914
F1-score: 0.8872
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1644
Epoch 1/10, Batch 20/20, Loss: 1.2939
Epoch 1/10, Train Loss: 1.2740, Valid Loss: 1.0032
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8723
Epoch 2/10, Batch 20/20, Loss: 0.5476
Epoch 2/10, Train Loss: 0.7963, Valid Loss: 0.7065
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7558
Epoch 3/10, Batch 20/20, Loss: 0.7882
Epoch 3/10, Train Loss: 0.6265, Valid Loss: 0.5732
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4636
Epoch 4/10, Batch 20/20, Loss: 0.5465
Epoch 4/10, Train Loss: 0.5031, Valid Loss: 0.5081
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4755
Epoch 5/10, Batch 20/20, Loss: 0.8149
Epoch 5/10, Train Loss: 0.4509, Valid Loss: 0.4663
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5560
Epoch 6/10, Batch 20/20, Loss: 0.6419
Epoch 6/10, Train Loss: 0.4024, Valid Loss: 0.4262
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3173
Epoch 7/10, Batch 20/20, Loss: 0.4352
Epoch 7/10, Train Loss: 0.3502, Valid Loss: 0.4097
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5557
Epoch 8/10, Batch 20/20, Loss: 0.5760
Epoch 8/10, Train Loss: 0.3433, Valid Loss: 0.3960
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4531
Epoch 9/10, Batch 20/20, Loss: 0.5082
Epoch 9/10, Train Loss: 0.2980, Valid Loss: 0.3688
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2966
Epoch 10/10, Batch 20/20, Loss: 0.7112
Epoch 10/10, Train Loss: 0.2994, Valid Loss: 0.3591
Model saved!
Accuracy: 0.8879
Precision: 0.8834
Recall: 0.8879
F1-score: 0.8819
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1425
Epoch 1/10, Batch 20/20, Loss: 1.2724
Epoch 1/10, Train Loss: 1.2593, Valid Loss: 1.0311
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8717
Epoch 2/10, Batch 20/20, Loss: 0.5918
Epoch 2/10, Train Loss: 0.7642, Valid Loss: 0.7220
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6253
Epoch 3/10, Batch 20/20, Loss: 0.8844
Epoch 3/10, Train Loss: 0.5825, Valid Loss: 0.5961
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3958
Epoch 4/10, Batch 20/20, Loss: 0.5404
Epoch 4/10, Train Loss: 0.4743, Valid Loss: 0.5170
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3558
Epoch 5/10, Batch 20/20, Loss: 0.3644
Epoch 5/10, Train Loss: 0.4074, Valid Loss: 0.4670
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4373
Epoch 6/10, Batch 20/20, Loss: 0.4184
Epoch 6/10, Train Loss: 0.3643, Valid Loss: 0.4337
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3971
Epoch 7/10, Batch 20/20, Loss: 0.2372
Epoch 7/10, Train Loss: 0.3051, Valid Loss: 0.4099
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3766
Epoch 8/10, Batch 20/20, Loss: 0.4358
Epoch 8/10, Train Loss: 0.2950, Valid Loss: 0.3946
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3656
Epoch 9/10, Batch 20/20, Loss: 0.3098
Epoch 9/10, Train Loss: 0.2491, Valid Loss: 0.3749
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2205
Epoch 10/10, Batch 20/20, Loss: 0.5745
Epoch 10/10, Train Loss: 0.2709, Valid Loss: 0.3661
Model saved!
Accuracy: 0.8785
Precision: 0.8729
Recall: 0.8785
F1-score: 0.8725
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2318
Epoch 1/10, Batch 20/20, Loss: 1.2442
Epoch 1/10, Train Loss: 1.2921, Valid Loss: 1.0480
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9797
Epoch 2/10, Batch 20/20, Loss: 0.6334
Epoch 2/10, Train Loss: 0.8336, Valid Loss: 0.7308
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7645
Epoch 3/10, Batch 20/20, Loss: 0.7861
Epoch 3/10, Train Loss: 0.6467, Valid Loss: 0.5969
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4965
Epoch 4/10, Batch 20/20, Loss: 0.4267
Epoch 4/10, Train Loss: 0.5209, Valid Loss: 0.5300
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3812
Epoch 5/10, Batch 20/20, Loss: 0.6225
Epoch 5/10, Train Loss: 0.4584, Valid Loss: 0.4628
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5814
Epoch 6/10, Batch 20/20, Loss: 0.6101
Epoch 6/10, Train Loss: 0.4253, Valid Loss: 0.4345
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3538
Epoch 7/10, Batch 20/20, Loss: 0.5350
Epoch 7/10, Train Loss: 0.3698, Valid Loss: 0.4076
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4387
Epoch 8/10, Batch 20/20, Loss: 0.2971
Epoch 8/10, Train Loss: 0.3454, Valid Loss: 0.3879
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3461
Epoch 9/10, Batch 20/20, Loss: 0.6466
Epoch 9/10, Train Loss: 0.3210, Valid Loss: 0.3613
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2663
Epoch 10/10, Batch 20/20, Loss: 0.4632
Epoch 10/10, Train Loss: 0.3043, Valid Loss: 0.3626
Accuracy: 0.8995
Precision: 0.8937
Recall: 0.8995
F1-score: 0.8951
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 21. Fitness: 0.8995
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2593
Epoch 1/10, Batch 20/20, Loss: 1.3513
Epoch 1/10, Train Loss: 1.2966, Valid Loss: 1.0784
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0307
Epoch 2/10, Batch 20/20, Loss: 0.8155
Epoch 2/10, Train Loss: 0.8396, Valid Loss: 0.7499
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8150
Epoch 3/10, Batch 20/20, Loss: 0.8537
Epoch 3/10, Train Loss: 0.6537, Valid Loss: 0.6056
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5262
Epoch 4/10, Batch 20/20, Loss: 0.6933
Epoch 4/10, Train Loss: 0.5298, Valid Loss: 0.5326
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4656
Epoch 5/10, Batch 20/20, Loss: 0.6249
Epoch 5/10, Train Loss: 0.4711, Valid Loss: 0.4781
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6228
Epoch 6/10, Batch 20/20, Loss: 0.4093
Epoch 6/10, Train Loss: 0.4284, Valid Loss: 0.4362
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4521
Epoch 7/10, Batch 20/20, Loss: 0.4414
Epoch 7/10, Train Loss: 0.3797, Valid Loss: 0.4048
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5347
Epoch 8/10, Batch 20/20, Loss: 0.3284
Epoch 8/10, Train Loss: 0.3482, Valid Loss: 0.3883
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3652
Epoch 9/10, Batch 20/20, Loss: 0.3441
Epoch 9/10, Train Loss: 0.3133, Valid Loss: 0.3592
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3350
Epoch 10/10, Batch 20/20, Loss: 0.3294
Epoch 10/10, Train Loss: 0.3029, Valid Loss: 0.3586
Model saved!
Accuracy: 0.8890
Precision: 0.8870
Recall: 0.8890
F1-score: 0.8863
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1840
Epoch 1/10, Batch 20/20, Loss: 1.0671
Epoch 1/10, Train Loss: 1.2616, Valid Loss: 1.0236
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9071
Epoch 2/10, Batch 20/20, Loss: 0.5426
Epoch 2/10, Train Loss: 0.7913, Valid Loss: 0.7275
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6512
Epoch 3/10, Batch 20/20, Loss: 0.7776
Epoch 3/10, Train Loss: 0.6035, Valid Loss: 0.5899
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4478
Epoch 4/10, Batch 20/20, Loss: 0.2664
Epoch 4/10, Train Loss: 0.4787, Valid Loss: 0.5204
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3623
Epoch 5/10, Batch 20/20, Loss: 0.6277
Epoch 5/10, Train Loss: 0.4359, Valid Loss: 0.4795
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5620
Epoch 6/10, Batch 20/20, Loss: 0.6063
Epoch 6/10, Train Loss: 0.3738, Valid Loss: 0.4360
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2490
Epoch 7/10, Batch 20/20, Loss: 0.4693
Epoch 7/10, Train Loss: 0.3437, Valid Loss: 0.4092
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5264
Epoch 8/10, Batch 20/20, Loss: 0.4661
Epoch 8/10, Train Loss: 0.3328, Valid Loss: 0.3969
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2744
Epoch 9/10, Batch 20/20, Loss: 0.7203
Epoch 9/10, Train Loss: 0.3070, Valid Loss: 0.3809
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3915
Epoch 10/10, Batch 20/20, Loss: 0.4344
Epoch 10/10, Train Loss: 0.2731, Valid Loss: 0.3742
Model saved!
Accuracy: 0.8890
Precision: 0.8849
Recall: 0.8890
F1-score: 0.8831
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3386
Epoch 1/10, Batch 20/20, Loss: 1.2934
Epoch 1/10, Train Loss: 1.2997, Valid Loss: 1.0946
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8966
Epoch 2/10, Batch 20/20, Loss: 0.9615
Epoch 2/10, Train Loss: 0.8479, Valid Loss: 0.7724
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8725
Epoch 3/10, Batch 20/20, Loss: 0.7198
Epoch 3/10, Train Loss: 0.6474, Valid Loss: 0.6556
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4514
Epoch 4/10, Batch 20/20, Loss: 0.3260
Epoch 4/10, Train Loss: 0.5032, Valid Loss: 0.5768
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4962
Epoch 5/10, Batch 20/20, Loss: 0.6985
Epoch 5/10, Train Loss: 0.4582, Valid Loss: 0.5364
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5645
Epoch 6/10, Batch 20/20, Loss: 0.3920
Epoch 6/10, Train Loss: 0.4040, Valid Loss: 0.5070
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2798
Epoch 7/10, Batch 20/20, Loss: 0.5290
Epoch 7/10, Train Loss: 0.3673, Valid Loss: 0.4906
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3972
Epoch 8/10, Batch 20/20, Loss: 0.3455
Epoch 8/10, Train Loss: 0.3518, Valid Loss: 0.4755
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3153
Epoch 9/10, Batch 20/20, Loss: 0.5482
Epoch 9/10, Train Loss: 0.3105, Valid Loss: 0.4626
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2607
Epoch 10/10, Batch 20/20, Loss: 0.5755
Epoch 10/10, Train Loss: 0.3044, Valid Loss: 0.4507
Model saved!
Accuracy: 0.8832
Precision: 0.8791
Recall: 0.8832
F1-score: 0.8775
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2063
Epoch 1/10, Batch 20/20, Loss: 1.2835
Epoch 1/10, Train Loss: 1.2882, Valid Loss: 1.0320
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9584
Epoch 2/10, Batch 20/20, Loss: 0.6562
Epoch 2/10, Train Loss: 0.8294, Valid Loss: 0.7038
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8077
Epoch 3/10, Batch 20/20, Loss: 0.6953
Epoch 3/10, Train Loss: 0.6364, Valid Loss: 0.5715
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4819
Epoch 4/10, Batch 20/20, Loss: 0.3489
Epoch 4/10, Train Loss: 0.5074, Valid Loss: 0.4918
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5132
Epoch 5/10, Batch 20/20, Loss: 0.5344
Epoch 5/10, Train Loss: 0.4419, Valid Loss: 0.4458
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5822
Epoch 6/10, Batch 20/20, Loss: 0.3391
Epoch 6/10, Train Loss: 0.4085, Valid Loss: 0.4115
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2900
Epoch 7/10, Batch 20/20, Loss: 0.2252
Epoch 7/10, Train Loss: 0.3522, Valid Loss: 0.3845
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4308
Epoch 8/10, Batch 20/20, Loss: 0.3474
Epoch 8/10, Train Loss: 0.3300, Valid Loss: 0.3640
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3820
Epoch 9/10, Batch 20/20, Loss: 0.7192
Epoch 9/10, Train Loss: 0.3245, Valid Loss: 0.3518
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2844
Epoch 10/10, Batch 20/20, Loss: 0.5171
Epoch 10/10, Train Loss: 0.3046, Valid Loss: 0.3480
Model saved!
Accuracy: 0.8785
Precision: 0.8737
Recall: 0.8785
F1-score: 0.8740
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2144
Epoch 1/10, Batch 20/20, Loss: 1.2812
Epoch 1/10, Train Loss: 1.2951, Valid Loss: 1.0582
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9639
Epoch 2/10, Batch 20/20, Loss: 0.7037
Epoch 2/10, Train Loss: 0.8259, Valid Loss: 0.7401
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7888
Epoch 3/10, Batch 20/20, Loss: 0.9012
Epoch 3/10, Train Loss: 0.6435, Valid Loss: 0.6156
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4725
Epoch 4/10, Batch 20/20, Loss: 0.4509
Epoch 4/10, Train Loss: 0.4955, Valid Loss: 0.5447
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4582
Epoch 5/10, Batch 20/20, Loss: 0.5731
Epoch 5/10, Train Loss: 0.4467, Valid Loss: 0.4815
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5166
Epoch 6/10, Batch 20/20, Loss: 0.2899
Epoch 6/10, Train Loss: 0.3890, Valid Loss: 0.4527
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3343
Epoch 7/10, Batch 20/20, Loss: 0.6566
Epoch 7/10, Train Loss: 0.3599, Valid Loss: 0.4331
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3691
Epoch 8/10, Batch 20/20, Loss: 0.2776
Epoch 8/10, Train Loss: 0.3279, Valid Loss: 0.4209
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3785
Epoch 9/10, Batch 20/20, Loss: 0.4506
Epoch 9/10, Train Loss: 0.3018, Valid Loss: 0.3873
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.4136
Epoch 10/10, Batch 20/20, Loss: 0.2907
Epoch 10/10, Train Loss: 0.2855, Valid Loss: 0.4031
Accuracy: 0.8855
Precision: 0.8779
Recall: 0.8855
F1-score: 0.8801
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2731
Epoch 1/10, Batch 20/20, Loss: 1.3053
Epoch 1/10, Train Loss: 1.2734, Valid Loss: 1.0738
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0769
Epoch 2/10, Batch 20/20, Loss: 0.5923
Epoch 2/10, Train Loss: 0.8091, Valid Loss: 0.7672
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7775
Epoch 3/10, Batch 20/20, Loss: 1.0343
Epoch 3/10, Train Loss: 0.6367, Valid Loss: 0.6285
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5214
Epoch 4/10, Batch 20/20, Loss: 0.5178
Epoch 4/10, Train Loss: 0.5216, Valid Loss: 0.5562
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5327
Epoch 5/10, Batch 20/20, Loss: 0.5763
Epoch 5/10, Train Loss: 0.4413, Valid Loss: 0.5182
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5066
Epoch 6/10, Batch 20/20, Loss: 0.5011
Epoch 6/10, Train Loss: 0.4126, Valid Loss: 0.4732
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3111
Epoch 7/10, Batch 20/20, Loss: 0.3423
Epoch 7/10, Train Loss: 0.3485, Valid Loss: 0.4423
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3267
Epoch 8/10, Batch 20/20, Loss: 0.4635
Epoch 8/10, Train Loss: 0.3430, Valid Loss: 0.4339
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4037
Epoch 9/10, Batch 20/20, Loss: 0.4678
Epoch 9/10, Train Loss: 0.3024, Valid Loss: 0.4162
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2845
Epoch 10/10, Batch 20/20, Loss: 0.3940
Epoch 10/10, Train Loss: 0.2815, Valid Loss: 0.4107
Model saved!
Accuracy: 0.8762
Precision: 0.8721
Recall: 0.8762
F1-score: 0.8721
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3509
Epoch 1/10, Batch 20/20, Loss: 1.4696
Epoch 1/10, Train Loss: 1.3067, Valid Loss: 1.1019
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0049
Epoch 2/10, Batch 20/20, Loss: 0.4919
Epoch 2/10, Train Loss: 0.8121, Valid Loss: 0.7802
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8381
Epoch 3/10, Batch 20/20, Loss: 0.7297
Epoch 3/10, Train Loss: 0.6353, Valid Loss: 0.6434
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4440
Epoch 4/10, Batch 20/20, Loss: 0.7179
Epoch 4/10, Train Loss: 0.5091, Valid Loss: 0.5767
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4780
Epoch 5/10, Batch 20/20, Loss: 0.9233
Epoch 5/10, Train Loss: 0.4486, Valid Loss: 0.5284
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4760
Epoch 6/10, Batch 20/20, Loss: 0.3174
Epoch 6/10, Train Loss: 0.3730, Valid Loss: 0.4966
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3692
Epoch 7/10, Batch 20/20, Loss: 0.3658
Epoch 7/10, Train Loss: 0.3406, Valid Loss: 0.4784
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3742
Epoch 8/10, Batch 20/20, Loss: 0.4070
Epoch 8/10, Train Loss: 0.3205, Valid Loss: 0.4663
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3452
Epoch 9/10, Batch 20/20, Loss: 0.4834
Epoch 9/10, Train Loss: 0.2927, Valid Loss: 0.4354
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2730
Epoch 10/10, Batch 20/20, Loss: 0.3880
Epoch 10/10, Train Loss: 0.2642, Valid Loss: 0.4425
Accuracy: 0.8843
Precision: 0.8778
Recall: 0.8843
F1-score: 0.8794
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2553
Epoch 1/10, Batch 20/20, Loss: 1.5504
Epoch 1/10, Train Loss: 1.3016, Valid Loss: 1.0868
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9990
Epoch 2/10, Batch 20/20, Loss: 0.6045
Epoch 2/10, Train Loss: 0.8121, Valid Loss: 0.7658
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6510
Epoch 3/10, Batch 20/20, Loss: 0.7665
Epoch 3/10, Train Loss: 0.6331, Valid Loss: 0.6436
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3846
Epoch 4/10, Batch 20/20, Loss: 0.5825
Epoch 4/10, Train Loss: 0.5028, Valid Loss: 0.5584
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4295
Epoch 5/10, Batch 20/20, Loss: 0.4777
Epoch 5/10, Train Loss: 0.4443, Valid Loss: 0.5080
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5744
Epoch 6/10, Batch 20/20, Loss: 0.3843
Epoch 6/10, Train Loss: 0.3869, Valid Loss: 0.4729
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2568
Epoch 7/10, Batch 20/20, Loss: 0.3713
Epoch 7/10, Train Loss: 0.3363, Valid Loss: 0.4432
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2944
Epoch 8/10, Batch 20/20, Loss: 0.5909
Epoch 8/10, Train Loss: 0.3280, Valid Loss: 0.4315
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4460
Epoch 9/10, Batch 20/20, Loss: 0.5232
Epoch 9/10, Train Loss: 0.3024, Valid Loss: 0.4172
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2358
Epoch 10/10, Batch 20/20, Loss: 1.0308
Epoch 10/10, Train Loss: 0.3091, Valid Loss: 0.4073
Model saved!
Accuracy: 0.8855
Precision: 0.8797
Recall: 0.8855
F1-score: 0.8803
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2717
Epoch 1/10, Batch 20/20, Loss: 1.3692
Epoch 1/10, Train Loss: 1.2758, Valid Loss: 1.0620
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8096
Epoch 2/10, Batch 20/20, Loss: 0.6564
Epoch 2/10, Train Loss: 0.8074, Valid Loss: 0.7424
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8285
Epoch 3/10, Batch 20/20, Loss: 0.7681
Epoch 3/10, Train Loss: 0.6296, Valid Loss: 0.6267
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4680
Epoch 4/10, Batch 20/20, Loss: 0.4329
Epoch 4/10, Train Loss: 0.5013, Valid Loss: 0.5384
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4633
Epoch 5/10, Batch 20/20, Loss: 0.5495
Epoch 5/10, Train Loss: 0.4407, Valid Loss: 0.4923
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5871
Epoch 6/10, Batch 20/20, Loss: 0.4022
Epoch 6/10, Train Loss: 0.4053, Valid Loss: 0.4423
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2353
Epoch 7/10, Batch 20/20, Loss: 0.5334
Epoch 7/10, Train Loss: 0.3548, Valid Loss: 0.4260
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3300
Epoch 8/10, Batch 20/20, Loss: 0.3304
Epoch 8/10, Train Loss: 0.3335, Valid Loss: 0.4055
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3627
Epoch 9/10, Batch 20/20, Loss: 0.6265
Epoch 9/10, Train Loss: 0.3130, Valid Loss: 0.3802
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2853
Epoch 10/10, Batch 20/20, Loss: 0.8228
Epoch 10/10, Train Loss: 0.3109, Valid Loss: 0.3751
Model saved!
Accuracy: 0.8797
Precision: 0.8756
Recall: 0.8797
F1-score: 0.8764
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2437
Epoch 1/10, Batch 20/20, Loss: 1.1987
Epoch 1/10, Train Loss: 1.2814, Valid Loss: 1.0961
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9231
Epoch 2/10, Batch 20/20, Loss: 0.6691
Epoch 2/10, Train Loss: 0.8096, Valid Loss: 0.7673
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5937
Epoch 3/10, Batch 20/20, Loss: 0.6906
Epoch 3/10, Train Loss: 0.6130, Valid Loss: 0.6533
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4712
Epoch 4/10, Batch 20/20, Loss: 0.7233
Epoch 4/10, Train Loss: 0.5118, Valid Loss: 0.5852
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4210
Epoch 5/10, Batch 20/20, Loss: 0.8672
Epoch 5/10, Train Loss: 0.4392, Valid Loss: 0.5370
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5725
Epoch 6/10, Batch 20/20, Loss: 0.3825
Epoch 6/10, Train Loss: 0.3824, Valid Loss: 0.5056
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3231
Epoch 7/10, Batch 20/20, Loss: 0.3817
Epoch 7/10, Train Loss: 0.3421, Valid Loss: 0.4862
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5627
Epoch 8/10, Batch 20/20, Loss: 0.3954
Epoch 8/10, Train Loss: 0.3254, Valid Loss: 0.4596
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3117
Epoch 9/10, Batch 20/20, Loss: 0.4397
Epoch 9/10, Train Loss: 0.2947, Valid Loss: 0.4534
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2707
Epoch 10/10, Batch 20/20, Loss: 0.6247
Epoch 10/10, Train Loss: 0.2807, Valid Loss: 0.4504
Model saved!
Accuracy: 0.8879
Precision: 0.8860
Recall: 0.8879
F1-score: 0.8840
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3115
Epoch 1/10, Batch 20/20, Loss: 1.1680
Epoch 1/10, Train Loss: 1.2708, Valid Loss: 1.0708
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9070
Epoch 2/10, Batch 20/20, Loss: 0.5742
Epoch 2/10, Train Loss: 0.7867, Valid Loss: 0.7465
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8279
Epoch 3/10, Batch 20/20, Loss: 0.9150
Epoch 3/10, Train Loss: 0.6161, Valid Loss: 0.6046
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3517
Epoch 4/10, Batch 20/20, Loss: 0.4216
Epoch 4/10, Train Loss: 0.4777, Valid Loss: 0.5265
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4155
Epoch 5/10, Batch 20/20, Loss: 0.5344
Epoch 5/10, Train Loss: 0.4234, Valid Loss: 0.4654
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5321
Epoch 6/10, Batch 20/20, Loss: 0.3831
Epoch 6/10, Train Loss: 0.3686, Valid Loss: 0.4233
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2683
Epoch 7/10, Batch 20/20, Loss: 0.6296
Epoch 7/10, Train Loss: 0.3663, Valid Loss: 0.3936
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3225
Epoch 8/10, Batch 20/20, Loss: 0.3538
Epoch 8/10, Train Loss: 0.3083, Valid Loss: 0.3736
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3720
Epoch 9/10, Batch 20/20, Loss: 0.3317
Epoch 9/10, Train Loss: 0.2696, Valid Loss: 0.3564
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2382
Epoch 10/10, Batch 20/20, Loss: 0.4888
Epoch 10/10, Train Loss: 0.2683, Valid Loss: 0.3500
Model saved!
Accuracy: 0.8820
Precision: 0.8769
Recall: 0.8820
F1-score: 0.8780
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2708
Epoch 1/10, Batch 20/20, Loss: 1.2320
Epoch 1/10, Train Loss: 1.2780, Valid Loss: 0.9872
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8562
Epoch 2/10, Batch 20/20, Loss: 0.6305
Epoch 2/10, Train Loss: 0.7982, Valid Loss: 0.6855
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7041
Epoch 3/10, Batch 20/20, Loss: 0.6668
Epoch 3/10, Train Loss: 0.6166, Valid Loss: 0.5561
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5278
Epoch 4/10, Batch 20/20, Loss: 0.9134
Epoch 4/10, Train Loss: 0.5041, Valid Loss: 0.4911
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3840
Epoch 5/10, Batch 20/20, Loss: 0.6213
Epoch 5/10, Train Loss: 0.4299, Valid Loss: 0.4429
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4950
Epoch 6/10, Batch 20/20, Loss: 0.6655
Epoch 6/10, Train Loss: 0.4001, Valid Loss: 0.4198
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3291
Epoch 7/10, Batch 20/20, Loss: 0.5096
Epoch 7/10, Train Loss: 0.3492, Valid Loss: 0.3955
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4827
Epoch 8/10, Batch 20/20, Loss: 0.4428
Epoch 8/10, Train Loss: 0.3119, Valid Loss: 0.3894
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3897
Epoch 9/10, Batch 20/20, Loss: 0.5885
Epoch 9/10, Train Loss: 0.3038, Valid Loss: 0.3565
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2362
Epoch 10/10, Batch 20/20, Loss: 0.7405
Epoch 10/10, Train Loss: 0.2995, Valid Loss: 0.3655
Accuracy: 0.8925
Precision: 0.8877
Recall: 0.8925
F1-score: 0.8880
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1956
Epoch 1/10, Batch 20/20, Loss: 1.2534
Epoch 1/10, Train Loss: 1.2726, Valid Loss: 1.0152
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8842
Epoch 2/10, Batch 20/20, Loss: 0.7107
Epoch 2/10, Train Loss: 0.8012, Valid Loss: 0.7283
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7876
Epoch 3/10, Batch 20/20, Loss: 1.0193
Epoch 3/10, Train Loss: 0.6183, Valid Loss: 0.5901
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4805
Epoch 4/10, Batch 20/20, Loss: 0.5188
Epoch 4/10, Train Loss: 0.5019, Valid Loss: 0.5245
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4083
Epoch 5/10, Batch 20/20, Loss: 0.8106
Epoch 5/10, Train Loss: 0.4440, Valid Loss: 0.4762
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5079
Epoch 6/10, Batch 20/20, Loss: 0.4829
Epoch 6/10, Train Loss: 0.3826, Valid Loss: 0.4463
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3244
Epoch 7/10, Batch 20/20, Loss: 0.2947
Epoch 7/10, Train Loss: 0.3297, Valid Loss: 0.4254
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4801
Epoch 8/10, Batch 20/20, Loss: 0.6172
Epoch 8/10, Train Loss: 0.3283, Valid Loss: 0.4085
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3143
Epoch 9/10, Batch 20/20, Loss: 0.4719
Epoch 9/10, Train Loss: 0.2973, Valid Loss: 0.3875
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2705
Epoch 10/10, Batch 20/20, Loss: 0.5519
Epoch 10/10, Train Loss: 0.2694, Valid Loss: 0.3765
Model saved!
Accuracy: 0.8914
Precision: 0.8846
Recall: 0.8914
F1-score: 0.8857
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3023
Epoch 1/10, Batch 20/20, Loss: 1.4773
Epoch 1/10, Train Loss: 1.2901, Valid Loss: 1.0772
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0210
Epoch 2/10, Batch 20/20, Loss: 0.6868
Epoch 2/10, Train Loss: 0.8062, Valid Loss: 0.7442
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7928
Epoch 3/10, Batch 20/20, Loss: 0.7672
Epoch 3/10, Train Loss: 0.6109, Valid Loss: 0.6043
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3768
Epoch 4/10, Batch 20/20, Loss: 0.5219
Epoch 4/10, Train Loss: 0.4917, Valid Loss: 0.5229
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4323
Epoch 5/10, Batch 20/20, Loss: 0.4865
Epoch 5/10, Train Loss: 0.4353, Valid Loss: 0.4739
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5152
Epoch 6/10, Batch 20/20, Loss: 0.3328
Epoch 6/10, Train Loss: 0.3704, Valid Loss: 0.4368
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2501
Epoch 7/10, Batch 20/20, Loss: 0.4294
Epoch 7/10, Train Loss: 0.3551, Valid Loss: 0.4128
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2849
Epoch 8/10, Batch 20/20, Loss: 0.5037
Epoch 8/10, Train Loss: 0.3172, Valid Loss: 0.3945
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3251
Epoch 9/10, Batch 20/20, Loss: 0.3710
Epoch 9/10, Train Loss: 0.2964, Valid Loss: 0.3831
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2947
Epoch 10/10, Batch 20/20, Loss: 0.6307
Epoch 10/10, Train Loss: 0.2934, Valid Loss: 0.3775
Model saved!
Accuracy: 0.8879
Precision: 0.8845
Recall: 0.8879
F1-score: 0.8841
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2877
Epoch 1/10, Batch 20/20, Loss: 1.3180
Epoch 1/10, Train Loss: 1.2941, Valid Loss: 1.0553
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9079
Epoch 2/10, Batch 20/20, Loss: 0.6719
Epoch 2/10, Train Loss: 0.8168, Valid Loss: 0.7451
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8101
Epoch 3/10, Batch 20/20, Loss: 0.7259
Epoch 3/10, Train Loss: 0.6333, Valid Loss: 0.6143
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5322
Epoch 4/10, Batch 20/20, Loss: 0.4064
Epoch 4/10, Train Loss: 0.5057, Valid Loss: 0.5328
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3252
Epoch 5/10, Batch 20/20, Loss: 0.7130
Epoch 5/10, Train Loss: 0.4661, Valid Loss: 0.4788
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5241
Epoch 6/10, Batch 20/20, Loss: 0.5108
Epoch 6/10, Train Loss: 0.4050, Valid Loss: 0.4483
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4279
Epoch 7/10, Batch 20/20, Loss: 0.4662
Epoch 7/10, Train Loss: 0.3668, Valid Loss: 0.4176
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3765
Epoch 8/10, Batch 20/20, Loss: 0.4722
Epoch 8/10, Train Loss: 0.3451, Valid Loss: 0.4041
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2845
Epoch 9/10, Batch 20/20, Loss: 0.5889
Epoch 9/10, Train Loss: 0.3117, Valid Loss: 0.3904
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2970
Epoch 10/10, Batch 20/20, Loss: 0.4145
Epoch 10/10, Train Loss: 0.2919, Valid Loss: 0.3656
Model saved!
Accuracy: 0.8902
Precision: 0.8886
Recall: 0.8902
F1-score: 0.8864
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2370
Epoch 1/10, Batch 20/20, Loss: 1.2130
Epoch 1/10, Train Loss: 1.2828, Valid Loss: 1.0372
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9545
Epoch 2/10, Batch 20/20, Loss: 0.6492
Epoch 2/10, Train Loss: 0.8080, Valid Loss: 0.7100
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7833
Epoch 3/10, Batch 20/20, Loss: 0.7286
Epoch 3/10, Train Loss: 0.6156, Valid Loss: 0.5736
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4304
Epoch 4/10, Batch 20/20, Loss: 0.5490
Epoch 4/10, Train Loss: 0.4976, Valid Loss: 0.4936
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3491
Epoch 5/10, Batch 20/20, Loss: 0.6308
Epoch 5/10, Train Loss: 0.4351, Valid Loss: 0.4479
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4079
Epoch 6/10, Batch 20/20, Loss: 0.2866
Epoch 6/10, Train Loss: 0.3695, Valid Loss: 0.4114
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2170
Epoch 7/10, Batch 20/20, Loss: 0.3278
Epoch 7/10, Train Loss: 0.3399, Valid Loss: 0.3770
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3114
Epoch 8/10, Batch 20/20, Loss: 0.2102
Epoch 8/10, Train Loss: 0.3013, Valid Loss: 0.3617
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2395
Epoch 9/10, Batch 20/20, Loss: 0.5688
Epoch 9/10, Train Loss: 0.2969, Valid Loss: 0.3428
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1623
Epoch 10/10, Batch 20/20, Loss: 0.3931
Epoch 10/10, Train Loss: 0.2734, Valid Loss: 0.3375
Model saved!
Accuracy: 0.8843
Precision: 0.8796
Recall: 0.8843
F1-score: 0.8797
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1151
Epoch 1/10, Batch 20/20, Loss: 1.3371
Epoch 1/10, Train Loss: 1.2653, Valid Loss: 0.9398
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8386
Epoch 2/10, Batch 20/20, Loss: 0.6497
Epoch 2/10, Train Loss: 0.7760, Valid Loss: 0.6555
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6798
Epoch 3/10, Batch 20/20, Loss: 0.6843
Epoch 3/10, Train Loss: 0.5822, Valid Loss: 0.5316
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6263
Epoch 4/10, Batch 20/20, Loss: 0.4088
Epoch 4/10, Train Loss: 0.4739, Valid Loss: 0.4684
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3138
Epoch 5/10, Batch 20/20, Loss: 0.7076
Epoch 5/10, Train Loss: 0.4135, Valid Loss: 0.4153
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6752
Epoch 6/10, Batch 20/20, Loss: 0.5020
Epoch 6/10, Train Loss: 0.3821, Valid Loss: 0.3893
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2902
Epoch 7/10, Batch 20/20, Loss: 0.5826
Epoch 7/10, Train Loss: 0.3365, Valid Loss: 0.3719
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5224
Epoch 8/10, Batch 20/20, Loss: 0.5758
Epoch 8/10, Train Loss: 0.3252, Valid Loss: 0.3698
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2825
Epoch 9/10, Batch 20/20, Loss: 0.5150
Epoch 9/10, Train Loss: 0.2890, Valid Loss: 0.3241
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2392
Epoch 10/10, Batch 20/20, Loss: 0.7996
Epoch 10/10, Train Loss: 0.2895, Valid Loss: 0.3428
Accuracy: 0.8890
Precision: 0.8828
Recall: 0.8890
F1-score: 0.8843
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2268
Epoch 1/10, Batch 20/20, Loss: 1.3237
Epoch 1/10, Train Loss: 1.2763, Valid Loss: 1.0788
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0187
Epoch 2/10, Batch 20/20, Loss: 0.5316
Epoch 2/10, Train Loss: 0.7921, Valid Loss: 0.7893
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7468
Epoch 3/10, Batch 20/20, Loss: 0.7808
Epoch 3/10, Train Loss: 0.6086, Valid Loss: 0.6455
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3800
Epoch 4/10, Batch 20/20, Loss: 0.3329
Epoch 4/10, Train Loss: 0.4674, Valid Loss: 0.5858
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3723
Epoch 5/10, Batch 20/20, Loss: 0.8259
Epoch 5/10, Train Loss: 0.4283, Valid Loss: 0.5307
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4886
Epoch 6/10, Batch 20/20, Loss: 0.6985
Epoch 6/10, Train Loss: 0.3791, Valid Loss: 0.4914
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2484
Epoch 7/10, Batch 20/20, Loss: 0.4091
Epoch 7/10, Train Loss: 0.3195, Valid Loss: 0.4705
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4315
Epoch 8/10, Batch 20/20, Loss: 0.3749
Epoch 8/10, Train Loss: 0.3070, Valid Loss: 0.4552
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3571
Epoch 9/10, Batch 20/20, Loss: 0.7743
Epoch 9/10, Train Loss: 0.2938, Valid Loss: 0.4242
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3195
Epoch 10/10, Batch 20/20, Loss: 0.4757
Epoch 10/10, Train Loss: 0.2632, Valid Loss: 0.4258
Accuracy: 0.8750
Precision: 0.8714
Recall: 0.8750
F1-score: 0.8721
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3008
Epoch 1/10, Batch 20/20, Loss: 1.1837
Epoch 1/10, Train Loss: 1.2917, Valid Loss: 1.0811
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0345
Epoch 2/10, Batch 20/20, Loss: 0.7779
Epoch 2/10, Train Loss: 0.8170, Valid Loss: 0.7507
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7464
Epoch 3/10, Batch 20/20, Loss: 0.8483
Epoch 3/10, Train Loss: 0.6185, Valid Loss: 0.6051
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3937
Epoch 4/10, Batch 20/20, Loss: 0.5603
Epoch 4/10, Train Loss: 0.4959, Valid Loss: 0.5217
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4069
Epoch 5/10, Batch 20/20, Loss: 0.7521
Epoch 5/10, Train Loss: 0.4309, Valid Loss: 0.4709
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5324
Epoch 6/10, Batch 20/20, Loss: 0.5772
Epoch 6/10, Train Loss: 0.3941, Valid Loss: 0.4259
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3187
Epoch 7/10, Batch 20/20, Loss: 0.5923
Epoch 7/10, Train Loss: 0.3424, Valid Loss: 0.3993
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4311
Epoch 8/10, Batch 20/20, Loss: 0.5124
Epoch 8/10, Train Loss: 0.3155, Valid Loss: 0.3862
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.1875
Epoch 9/10, Batch 20/20, Loss: 0.3987
Epoch 9/10, Train Loss: 0.2818, Valid Loss: 0.3711
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3070
Epoch 10/10, Batch 20/20, Loss: 0.6898
Epoch 10/10, Train Loss: 0.2666, Valid Loss: 0.3654
Model saved!
Accuracy: 0.8855
Precision: 0.8805
Recall: 0.8855
F1-score: 0.8808
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1730
Epoch 1/10, Batch 20/20, Loss: 1.2011
Epoch 1/10, Train Loss: 1.2768, Valid Loss: 1.0180
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9484
Epoch 2/10, Batch 20/20, Loss: 0.6975
Epoch 2/10, Train Loss: 0.8033, Valid Loss: 0.7141
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7881
Epoch 3/10, Batch 20/20, Loss: 0.7073
Epoch 3/10, Train Loss: 0.6231, Valid Loss: 0.5907
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4116
Epoch 4/10, Batch 20/20, Loss: 0.6600
Epoch 4/10, Train Loss: 0.5093, Valid Loss: 0.5171
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3860
Epoch 5/10, Batch 20/20, Loss: 0.7560
Epoch 5/10, Train Loss: 0.4490, Valid Loss: 0.4723
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6486
Epoch 6/10, Batch 20/20, Loss: 0.4655
Epoch 6/10, Train Loss: 0.3923, Valid Loss: 0.4327
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2851
Epoch 7/10, Batch 20/20, Loss: 0.3585
Epoch 7/10, Train Loss: 0.3342, Valid Loss: 0.4147
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4471
Epoch 8/10, Batch 20/20, Loss: 0.5153
Epoch 8/10, Train Loss: 0.3291, Valid Loss: 0.4061
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4145
Epoch 9/10, Batch 20/20, Loss: 0.7017
Epoch 9/10, Train Loss: 0.3128, Valid Loss: 0.3719
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2023
Epoch 10/10, Batch 20/20, Loss: 0.8638
Epoch 10/10, Train Loss: 0.2950, Valid Loss: 0.3822
Accuracy: 0.9007
Precision: 0.8967
Recall: 0.9007
F1-score: 0.8969
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 41. Fitness: 0.9007
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1341
Epoch 1/10, Batch 20/20, Loss: 1.3262
Epoch 1/10, Train Loss: 1.2806, Valid Loss: 1.0173
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8733
Epoch 2/10, Batch 20/20, Loss: 0.6746
Epoch 2/10, Train Loss: 0.8063, Valid Loss: 0.7313
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6970
Epoch 3/10, Batch 20/20, Loss: 0.8740
Epoch 3/10, Train Loss: 0.6279, Valid Loss: 0.6057
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4758
Epoch 4/10, Batch 20/20, Loss: 0.4805
Epoch 4/10, Train Loss: 0.5020, Valid Loss: 0.5460
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4145
Epoch 5/10, Batch 20/20, Loss: 0.8242
Epoch 5/10, Train Loss: 0.4558, Valid Loss: 0.4905
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5813
Epoch 6/10, Batch 20/20, Loss: 0.4520
Epoch 6/10, Train Loss: 0.4061, Valid Loss: 0.4608
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2314
Epoch 7/10, Batch 20/20, Loss: 0.2820
Epoch 7/10, Train Loss: 0.3458, Valid Loss: 0.4494
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3905
Epoch 8/10, Batch 20/20, Loss: 0.4184
Epoch 8/10, Train Loss: 0.3338, Valid Loss: 0.4240
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4240
Epoch 9/10, Batch 20/20, Loss: 0.4762
Epoch 9/10, Train Loss: 0.3081, Valid Loss: 0.3998
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3536
Epoch 10/10, Batch 20/20, Loss: 0.9361
Epoch 10/10, Train Loss: 0.3133, Valid Loss: 0.4043
Accuracy: 0.8820
Precision: 0.8757
Recall: 0.8820
F1-score: 0.8774
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2797
Epoch 1/10, Batch 20/20, Loss: 1.3690
Epoch 1/10, Train Loss: 1.2896, Valid Loss: 1.0741
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9514
Epoch 2/10, Batch 20/20, Loss: 0.8372
Epoch 2/10, Train Loss: 0.8104, Valid Loss: 0.7333
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7444
Epoch 3/10, Batch 20/20, Loss: 0.8591
Epoch 3/10, Train Loss: 0.6075, Valid Loss: 0.6031
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3932
Epoch 4/10, Batch 20/20, Loss: 0.5384
Epoch 4/10, Train Loss: 0.4871, Valid Loss: 0.5258
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3537
Epoch 5/10, Batch 20/20, Loss: 0.6258
Epoch 5/10, Train Loss: 0.4324, Valid Loss: 0.4794
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5139
Epoch 6/10, Batch 20/20, Loss: 0.4887
Epoch 6/10, Train Loss: 0.3761, Valid Loss: 0.4373
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3765
Epoch 7/10, Batch 20/20, Loss: 0.5216
Epoch 7/10, Train Loss: 0.3497, Valid Loss: 0.4125
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3806
Epoch 8/10, Batch 20/20, Loss: 0.4293
Epoch 8/10, Train Loss: 0.3218, Valid Loss: 0.3978
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2917
Epoch 9/10, Batch 20/20, Loss: 0.3393
Epoch 9/10, Train Loss: 0.2756, Valid Loss: 0.3782
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2438
Epoch 10/10, Batch 20/20, Loss: 0.4413
Epoch 10/10, Train Loss: 0.2770, Valid Loss: 0.3784
Accuracy: 0.8902
Precision: 0.8856
Recall: 0.8902
F1-score: 0.8871
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2292
Epoch 1/10, Batch 20/20, Loss: 1.3492
Epoch 1/10, Train Loss: 1.3132, Valid Loss: 1.0583
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0726
Epoch 2/10, Batch 20/20, Loss: 0.6952
Epoch 2/10, Train Loss: 0.8549, Valid Loss: 0.7344
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8419
Epoch 3/10, Batch 20/20, Loss: 0.5740
Epoch 3/10, Train Loss: 0.6475, Valid Loss: 0.5863
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5263
Epoch 4/10, Batch 20/20, Loss: 0.4131
Epoch 4/10, Train Loss: 0.5278, Valid Loss: 0.5123
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4334
Epoch 5/10, Batch 20/20, Loss: 0.8399
Epoch 5/10, Train Loss: 0.4859, Valid Loss: 0.4571
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5939
Epoch 6/10, Batch 20/20, Loss: 0.4612
Epoch 6/10, Train Loss: 0.4283, Valid Loss: 0.4231
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3280
Epoch 7/10, Batch 20/20, Loss: 0.4772
Epoch 7/10, Train Loss: 0.3793, Valid Loss: 0.4012
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4997
Epoch 8/10, Batch 20/20, Loss: 0.3449
Epoch 8/10, Train Loss: 0.3448, Valid Loss: 0.3854
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4300
Epoch 9/10, Batch 20/20, Loss: 0.5505
Epoch 9/10, Train Loss: 0.3407, Valid Loss: 0.3588
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2419
Epoch 10/10, Batch 20/20, Loss: 0.5818
Epoch 10/10, Train Loss: 0.3161, Valid Loss: 0.3498
Model saved!
Accuracy: 0.8890
Precision: 0.8857
Recall: 0.8890
F1-score: 0.8856
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2125
Epoch 1/10, Batch 20/20, Loss: 1.2771
Epoch 1/10, Train Loss: 1.2750, Valid Loss: 1.0734
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0022
Epoch 2/10, Batch 20/20, Loss: 0.6816
Epoch 2/10, Train Loss: 0.8091, Valid Loss: 0.7346
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6948
Epoch 3/10, Batch 20/20, Loss: 0.9892
Epoch 3/10, Train Loss: 0.6194, Valid Loss: 0.6165
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5069
Epoch 4/10, Batch 20/20, Loss: 0.5014
Epoch 4/10, Train Loss: 0.4900, Valid Loss: 0.5397
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3571
Epoch 5/10, Batch 20/20, Loss: 0.6095
Epoch 5/10, Train Loss: 0.4201, Valid Loss: 0.4926
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4222
Epoch 6/10, Batch 20/20, Loss: 0.4312
Epoch 6/10, Train Loss: 0.3740, Valid Loss: 0.4634
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2081
Epoch 7/10, Batch 20/20, Loss: 0.3502
Epoch 7/10, Train Loss: 0.3208, Valid Loss: 0.4348
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3293
Epoch 8/10, Batch 20/20, Loss: 0.4034
Epoch 8/10, Train Loss: 0.3234, Valid Loss: 0.4264
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2853
Epoch 9/10, Batch 20/20, Loss: 0.7592
Epoch 9/10, Train Loss: 0.3014, Valid Loss: 0.4105
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2730
Epoch 10/10, Batch 20/20, Loss: 0.4021
Epoch 10/10, Train Loss: 0.2672, Valid Loss: 0.4038
Model saved!
Accuracy: 0.8797
Precision: 0.8752
Recall: 0.8797
F1-score: 0.8763
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2446
Epoch 1/10, Batch 20/20, Loss: 1.3494
Epoch 1/10, Train Loss: 1.2970, Valid Loss: 1.0623
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9649
Epoch 2/10, Batch 20/20, Loss: 0.5822
Epoch 2/10, Train Loss: 0.8292, Valid Loss: 0.7475
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6490
Epoch 3/10, Batch 20/20, Loss: 0.7079
Epoch 3/10, Train Loss: 0.6294, Valid Loss: 0.6264
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4797
Epoch 4/10, Batch 20/20, Loss: 0.5254
Epoch 4/10, Train Loss: 0.5140, Valid Loss: 0.5493
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3869
Epoch 5/10, Batch 20/20, Loss: 0.7256
Epoch 5/10, Train Loss: 0.4576, Valid Loss: 0.5096
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.7130
Epoch 6/10, Batch 20/20, Loss: 0.4433
Epoch 6/10, Train Loss: 0.4159, Valid Loss: 0.4709
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2704
Epoch 7/10, Batch 20/20, Loss: 0.8373
Epoch 7/10, Train Loss: 0.3879, Valid Loss: 0.4541
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5408
Epoch 8/10, Batch 20/20, Loss: 0.4201
Epoch 8/10, Train Loss: 0.3365, Valid Loss: 0.4296
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4057
Epoch 9/10, Batch 20/20, Loss: 0.5050
Epoch 9/10, Train Loss: 0.3212, Valid Loss: 0.4122
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2931
Epoch 10/10, Batch 20/20, Loss: 0.4063
Epoch 10/10, Train Loss: 0.2959, Valid Loss: 0.3963
Model saved!
Accuracy: 0.8890
Precision: 0.8882
Recall: 0.8890
F1-score: 0.8847
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1958
Epoch 1/10, Batch 20/20, Loss: 1.1998
Epoch 1/10, Train Loss: 1.2827, Valid Loss: 1.0280
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9530
Epoch 2/10, Batch 20/20, Loss: 0.6645
Epoch 2/10, Train Loss: 0.8089, Valid Loss: 0.7415
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8174
Epoch 3/10, Batch 20/20, Loss: 0.7433
Epoch 3/10, Train Loss: 0.6162, Valid Loss: 0.6144
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4882
Epoch 4/10, Batch 20/20, Loss: 0.3840
Epoch 4/10, Train Loss: 0.4840, Valid Loss: 0.5610
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3927
Epoch 5/10, Batch 20/20, Loss: 0.7911
Epoch 5/10, Train Loss: 0.4422, Valid Loss: 0.5078
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5251
Epoch 6/10, Batch 20/20, Loss: 0.3928
Epoch 6/10, Train Loss: 0.3778, Valid Loss: 0.4837
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2703
Epoch 7/10, Batch 20/20, Loss: 0.3309
Epoch 7/10, Train Loss: 0.3300, Valid Loss: 0.4691
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5188
Epoch 8/10, Batch 20/20, Loss: 0.5423
Epoch 8/10, Train Loss: 0.3198, Valid Loss: 0.4566
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2718
Epoch 9/10, Batch 20/20, Loss: 0.5865
Epoch 9/10, Train Loss: 0.2955, Valid Loss: 0.4446
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2350
Epoch 10/10, Batch 20/20, Loss: 0.9008
Epoch 10/10, Train Loss: 0.2976, Valid Loss: 0.4490
Accuracy: 0.8867
Precision: 0.8831
Recall: 0.8867
F1-score: 0.8800
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2563
Epoch 1/10, Batch 20/20, Loss: 1.2807
Epoch 1/10, Train Loss: 1.2922, Valid Loss: 1.0493
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9027
Epoch 2/10, Batch 20/20, Loss: 0.7357
Epoch 2/10, Train Loss: 0.8113, Valid Loss: 0.7419
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6870
Epoch 3/10, Batch 20/20, Loss: 0.7778
Epoch 3/10, Train Loss: 0.6117, Valid Loss: 0.6358
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4519
Epoch 4/10, Batch 20/20, Loss: 0.5280
Epoch 4/10, Train Loss: 0.4874, Valid Loss: 0.5563
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4204
Epoch 5/10, Batch 20/20, Loss: 0.7882
Epoch 5/10, Train Loss: 0.4385, Valid Loss: 0.5220
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4652
Epoch 6/10, Batch 20/20, Loss: 0.3453
Epoch 6/10, Train Loss: 0.3669, Valid Loss: 0.4844
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2493
Epoch 7/10, Batch 20/20, Loss: 0.3473
Epoch 7/10, Train Loss: 0.3478, Valid Loss: 0.4630
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3813
Epoch 8/10, Batch 20/20, Loss: 0.4136
Epoch 8/10, Train Loss: 0.3173, Valid Loss: 0.4473
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2653
Epoch 9/10, Batch 20/20, Loss: 0.5678
Epoch 9/10, Train Loss: 0.2899, Valid Loss: 0.4300
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1904
Epoch 10/10, Batch 20/20, Loss: 0.4024
Epoch 10/10, Train Loss: 0.2700, Valid Loss: 0.4348
Accuracy: 0.8914
Precision: 0.8860
Recall: 0.8914
F1-score: 0.8876
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2801
Epoch 1/10, Batch 20/20, Loss: 1.1701
Epoch 1/10, Train Loss: 1.2695, Valid Loss: 1.0483
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8788
Epoch 2/10, Batch 20/20, Loss: 0.4306
Epoch 2/10, Train Loss: 0.7853, Valid Loss: 0.7554
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7540
Epoch 3/10, Batch 20/20, Loss: 0.9604
Epoch 3/10, Train Loss: 0.6179, Valid Loss: 0.6457
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4915
Epoch 4/10, Batch 20/20, Loss: 0.5112
Epoch 4/10, Train Loss: 0.4771, Valid Loss: 0.5746
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4647
Epoch 5/10, Batch 20/20, Loss: 0.4648
Epoch 5/10, Train Loss: 0.4240, Valid Loss: 0.5334
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5782
Epoch 6/10, Batch 20/20, Loss: 0.5328
Epoch 6/10, Train Loss: 0.3870, Valid Loss: 0.5079
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3690
Epoch 7/10, Batch 20/20, Loss: 0.2768
Epoch 7/10, Train Loss: 0.3421, Valid Loss: 0.4841
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3175
Epoch 8/10, Batch 20/20, Loss: 0.4540
Epoch 8/10, Train Loss: 0.3151, Valid Loss: 0.4607
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3792
Epoch 9/10, Batch 20/20, Loss: 0.6759
Epoch 9/10, Train Loss: 0.2949, Valid Loss: 0.4666
Epoch 10/10, Batch 10/20, Loss: 0.3074
Epoch 10/10, Batch 20/20, Loss: 0.7008
Epoch 10/10, Train Loss: 0.2844, Valid Loss: 0.4481
Model saved!
Accuracy: 0.8855
Precision: 0.8794
Recall: 0.8855
F1-score: 0.8803
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2940
Epoch 1/10, Batch 20/20, Loss: 1.2601
Epoch 1/10, Train Loss: 1.2682, Valid Loss: 1.1080
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8915
Epoch 2/10, Batch 20/20, Loss: 0.7921
Epoch 2/10, Train Loss: 0.7950, Valid Loss: 0.7936
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8122
Epoch 3/10, Batch 20/20, Loss: 0.6835
Epoch 3/10, Train Loss: 0.6051, Valid Loss: 0.6783
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4605
Epoch 4/10, Batch 20/20, Loss: 0.5721
Epoch 4/10, Train Loss: 0.4853, Valid Loss: 0.6096
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4193
Epoch 5/10, Batch 20/20, Loss: 0.5414
Epoch 5/10, Train Loss: 0.4275, Valid Loss: 0.5665
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4096
Epoch 6/10, Batch 20/20, Loss: 0.5110
Epoch 6/10, Train Loss: 0.3797, Valid Loss: 0.5306
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2840
Epoch 7/10, Batch 20/20, Loss: 0.3445
Epoch 7/10, Train Loss: 0.3304, Valid Loss: 0.5188
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3453
Epoch 8/10, Batch 20/20, Loss: 0.3249
Epoch 8/10, Train Loss: 0.3079, Valid Loss: 0.4938
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2962
Epoch 9/10, Batch 20/20, Loss: 0.4009
Epoch 9/10, Train Loss: 0.2885, Valid Loss: 0.4753
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2978
Epoch 10/10, Batch 20/20, Loss: 0.3269
Epoch 10/10, Train Loss: 0.2653, Valid Loss: 0.4664
Model saved!
Accuracy: 0.8797
Precision: 0.8753
Recall: 0.8797
F1-score: 0.8752
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1886
Epoch 1/10, Batch 20/20, Loss: 1.4796
Epoch 1/10, Train Loss: 1.2820, Valid Loss: 0.9794
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0465
Epoch 2/10, Batch 20/20, Loss: 0.4095
Epoch 2/10, Train Loss: 0.7988, Valid Loss: 0.6820
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6973
Epoch 3/10, Batch 20/20, Loss: 0.8859
Epoch 3/10, Train Loss: 0.6240, Valid Loss: 0.5573
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3743
Epoch 4/10, Batch 20/20, Loss: 0.4039
Epoch 4/10, Train Loss: 0.4928, Valid Loss: 0.4921
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3936
Epoch 5/10, Batch 20/20, Loss: 0.5038
Epoch 5/10, Train Loss: 0.4304, Valid Loss: 0.4454
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4696
Epoch 6/10, Batch 20/20, Loss: 0.4719
Epoch 6/10, Train Loss: 0.3823, Valid Loss: 0.4097
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2205
Epoch 7/10, Batch 20/20, Loss: 0.4296
Epoch 7/10, Train Loss: 0.3371, Valid Loss: 0.3935
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5653
Epoch 8/10, Batch 20/20, Loss: 0.3161
Epoch 8/10, Train Loss: 0.3070, Valid Loss: 0.3789
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3521
Epoch 9/10, Batch 20/20, Loss: 0.6080
Epoch 9/10, Train Loss: 0.2992, Valid Loss: 0.3621
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1509
Epoch 10/10, Batch 20/20, Loss: 0.8952
Epoch 10/10, Train Loss: 0.2788, Valid Loss: 0.3546
Model saved!
Accuracy: 0.8703
Precision: 0.8684
Recall: 0.8703
F1-score: 0.8658
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2005
Epoch 1/10, Batch 20/20, Loss: 1.3534
Epoch 1/10, Train Loss: 1.2810, Valid Loss: 1.0044
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9731
Epoch 2/10, Batch 20/20, Loss: 0.5645
Epoch 2/10, Train Loss: 0.8034, Valid Loss: 0.7442
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6421
Epoch 3/10, Batch 20/20, Loss: 0.8021
Epoch 3/10, Train Loss: 0.6321, Valid Loss: 0.6138
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4726
Epoch 4/10, Batch 20/20, Loss: 0.4008
Epoch 4/10, Train Loss: 0.5074, Valid Loss: 0.5528
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4182
Epoch 5/10, Batch 20/20, Loss: 0.6716
Epoch 5/10, Train Loss: 0.4485, Valid Loss: 0.4981
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5854
Epoch 6/10, Batch 20/20, Loss: 0.4084
Epoch 6/10, Train Loss: 0.4152, Valid Loss: 0.4708
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3103
Epoch 7/10, Batch 20/20, Loss: 0.5884
Epoch 7/10, Train Loss: 0.3702, Valid Loss: 0.4506
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5182
Epoch 8/10, Batch 20/20, Loss: 0.3524
Epoch 8/10, Train Loss: 0.3384, Valid Loss: 0.4341
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3468
Epoch 9/10, Batch 20/20, Loss: 0.3754
Epoch 9/10, Train Loss: 0.3111, Valid Loss: 0.4236
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2563
Epoch 10/10, Batch 20/20, Loss: 0.5290
Epoch 10/10, Train Loss: 0.2963, Valid Loss: 0.4047
Model saved!
Accuracy: 0.8773
Precision: 0.8727
Recall: 0.8773
F1-score: 0.8737
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1569
Epoch 1/10, Batch 20/20, Loss: 1.3282
Epoch 1/10, Train Loss: 1.2780, Valid Loss: 1.0691
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9268
Epoch 2/10, Batch 20/20, Loss: 0.7324
Epoch 2/10, Train Loss: 0.7983, Valid Loss: 0.7548
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7879
Epoch 3/10, Batch 20/20, Loss: 0.8533
Epoch 3/10, Train Loss: 0.6161, Valid Loss: 0.6316
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3997
Epoch 4/10, Batch 20/20, Loss: 0.5382
Epoch 4/10, Train Loss: 0.4933, Valid Loss: 0.5611
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3119
Epoch 5/10, Batch 20/20, Loss: 0.7158
Epoch 5/10, Train Loss: 0.4359, Valid Loss: 0.5196
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5722
Epoch 6/10, Batch 20/20, Loss: 0.5239
Epoch 6/10, Train Loss: 0.3681, Valid Loss: 0.4815
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3732
Epoch 7/10, Batch 20/20, Loss: 0.6725
Epoch 7/10, Train Loss: 0.3550, Valid Loss: 0.4580
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5147
Epoch 8/10, Batch 20/20, Loss: 0.4319
Epoch 8/10, Train Loss: 0.3278, Valid Loss: 0.4449
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4325
Epoch 9/10, Batch 20/20, Loss: 0.5807
Epoch 9/10, Train Loss: 0.3095, Valid Loss: 0.4259
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3566
Epoch 10/10, Batch 20/20, Loss: 0.4938
Epoch 10/10, Train Loss: 0.2742, Valid Loss: 0.4215
Model saved!
Accuracy: 0.8855
Precision: 0.8824
Recall: 0.8855
F1-score: 0.8806
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2098
Epoch 1/10, Batch 20/20, Loss: 1.3081
Epoch 1/10, Train Loss: 1.2618, Valid Loss: 1.0705
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9068
Epoch 2/10, Batch 20/20, Loss: 0.4441
Epoch 2/10, Train Loss: 0.8001, Valid Loss: 0.7446
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7035
Epoch 3/10, Batch 20/20, Loss: 0.8105
Epoch 3/10, Train Loss: 0.6211, Valid Loss: 0.6048
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4559
Epoch 4/10, Batch 20/20, Loss: 0.5017
Epoch 4/10, Train Loss: 0.5107, Valid Loss: 0.5420
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4195
Epoch 5/10, Batch 20/20, Loss: 0.9340
Epoch 5/10, Train Loss: 0.4562, Valid Loss: 0.5014
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4988
Epoch 6/10, Batch 20/20, Loss: 0.3895
Epoch 6/10, Train Loss: 0.3914, Valid Loss: 0.4558
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3112
Epoch 7/10, Batch 20/20, Loss: 0.4755
Epoch 7/10, Train Loss: 0.3494, Valid Loss: 0.4342
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3906
Epoch 8/10, Batch 20/20, Loss: 0.5852
Epoch 8/10, Train Loss: 0.3313, Valid Loss: 0.4231
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4003
Epoch 9/10, Batch 20/20, Loss: 0.5020
Epoch 9/10, Train Loss: 0.3015, Valid Loss: 0.3989
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2405
Epoch 10/10, Batch 20/20, Loss: 0.6653
Epoch 10/10, Train Loss: 0.2806, Valid Loss: 0.4056
Accuracy: 0.8867
Precision: 0.8821
Recall: 0.8867
F1-score: 0.8827
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1965
Epoch 1/10, Batch 20/20, Loss: 1.3609
Epoch 1/10, Train Loss: 1.2861, Valid Loss: 1.0939
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8584
Epoch 2/10, Batch 20/20, Loss: 0.6036
Epoch 2/10, Train Loss: 0.8108, Valid Loss: 0.7504
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7122
Epoch 3/10, Batch 20/20, Loss: 0.7761
Epoch 3/10, Train Loss: 0.6103, Valid Loss: 0.6361
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4713
Epoch 4/10, Batch 20/20, Loss: 0.4215
Epoch 4/10, Train Loss: 0.5018, Valid Loss: 0.5521
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4423
Epoch 5/10, Batch 20/20, Loss: 1.0567
Epoch 5/10, Train Loss: 0.4438, Valid Loss: 0.5126
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5735
Epoch 6/10, Batch 20/20, Loss: 0.3070
Epoch 6/10, Train Loss: 0.3601, Valid Loss: 0.4755
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2964
Epoch 7/10, Batch 20/20, Loss: 0.4914
Epoch 7/10, Train Loss: 0.3262, Valid Loss: 0.4586
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2810
Epoch 8/10, Batch 20/20, Loss: 0.4479
Epoch 8/10, Train Loss: 0.3249, Valid Loss: 0.4418
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4072
Epoch 9/10, Batch 20/20, Loss: 0.5891
Epoch 9/10, Train Loss: 0.2958, Valid Loss: 0.4325
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2690
Epoch 10/10, Batch 20/20, Loss: 0.5741
Epoch 10/10, Train Loss: 0.2707, Valid Loss: 0.4244
Model saved!
Accuracy: 0.8855
Precision: 0.8784
Recall: 0.8855
F1-score: 0.8796
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1482
Epoch 1/10, Batch 20/20, Loss: 1.2982
Epoch 1/10, Train Loss: 1.2854, Valid Loss: 1.0195
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0388
Epoch 2/10, Batch 20/20, Loss: 0.6878
Epoch 2/10, Train Loss: 0.8217, Valid Loss: 0.7262
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7557
Epoch 3/10, Batch 20/20, Loss: 0.8689
Epoch 3/10, Train Loss: 0.6384, Valid Loss: 0.5886
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4857
Epoch 4/10, Batch 20/20, Loss: 0.4763
Epoch 4/10, Train Loss: 0.5064, Valid Loss: 0.5250
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4680
Epoch 5/10, Batch 20/20, Loss: 0.5935
Epoch 5/10, Train Loss: 0.4437, Valid Loss: 0.4772
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5383
Epoch 6/10, Batch 20/20, Loss: 0.3427
Epoch 6/10, Train Loss: 0.3923, Valid Loss: 0.4339
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2640
Epoch 7/10, Batch 20/20, Loss: 0.4002
Epoch 7/10, Train Loss: 0.3554, Valid Loss: 0.4153
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4818
Epoch 8/10, Batch 20/20, Loss: 0.6057
Epoch 8/10, Train Loss: 0.3397, Valid Loss: 0.3975
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3897
Epoch 9/10, Batch 20/20, Loss: 0.6571
Epoch 9/10, Train Loss: 0.3228, Valid Loss: 0.3758
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3153
Epoch 10/10, Batch 20/20, Loss: 0.5266
Epoch 10/10, Train Loss: 0.2971, Valid Loss: 0.3713
Model saved!
Accuracy: 0.8820
Precision: 0.8789
Recall: 0.8820
F1-score: 0.8745
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1527
Epoch 1/10, Batch 20/20, Loss: 1.3830
Epoch 1/10, Train Loss: 1.2719, Valid Loss: 1.0195
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0638
Epoch 2/10, Batch 20/20, Loss: 0.5510
Epoch 2/10, Train Loss: 0.7920, Valid Loss: 0.7119
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7048
Epoch 3/10, Batch 20/20, Loss: 0.8675
Epoch 3/10, Train Loss: 0.6136, Valid Loss: 0.5775
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5134
Epoch 4/10, Batch 20/20, Loss: 0.3744
Epoch 4/10, Train Loss: 0.4899, Valid Loss: 0.5111
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3775
Epoch 5/10, Batch 20/20, Loss: 0.5474
Epoch 5/10, Train Loss: 0.4476, Valid Loss: 0.4607
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4604
Epoch 6/10, Batch 20/20, Loss: 0.7439
Epoch 6/10, Train Loss: 0.3987, Valid Loss: 0.4293
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2518
Epoch 7/10, Batch 20/20, Loss: 0.4890
Epoch 7/10, Train Loss: 0.3477, Valid Loss: 0.4065
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4380
Epoch 8/10, Batch 20/20, Loss: 0.4218
Epoch 8/10, Train Loss: 0.3335, Valid Loss: 0.3848
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4107
Epoch 9/10, Batch 20/20, Loss: 0.4423
Epoch 9/10, Train Loss: 0.3009, Valid Loss: 0.3739
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2204
Epoch 10/10, Batch 20/20, Loss: 0.7321
Epoch 10/10, Train Loss: 0.2978, Valid Loss: 0.3599
Model saved!
Accuracy: 0.8855
Precision: 0.8870
Recall: 0.8855
F1-score: 0.8795
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2834
Epoch 1/10, Batch 20/20, Loss: 1.2954
Epoch 1/10, Train Loss: 1.2782, Valid Loss: 1.0731
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9202
Epoch 2/10, Batch 20/20, Loss: 0.5316
Epoch 2/10, Train Loss: 0.7826, Valid Loss: 0.7268
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7580
Epoch 3/10, Batch 20/20, Loss: 0.6579
Epoch 3/10, Train Loss: 0.5976, Valid Loss: 0.6142
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3730
Epoch 4/10, Batch 20/20, Loss: 0.4508
Epoch 4/10, Train Loss: 0.4698, Valid Loss: 0.5402
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4012
Epoch 5/10, Batch 20/20, Loss: 0.6498
Epoch 5/10, Train Loss: 0.4124, Valid Loss: 0.4937
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4685
Epoch 6/10, Batch 20/20, Loss: 0.6101
Epoch 6/10, Train Loss: 0.3803, Valid Loss: 0.4567
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2840
Epoch 7/10, Batch 20/20, Loss: 0.5448
Epoch 7/10, Train Loss: 0.3303, Valid Loss: 0.4335
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4102
Epoch 8/10, Batch 20/20, Loss: 0.4847
Epoch 8/10, Train Loss: 0.3038, Valid Loss: 0.4144
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2373
Epoch 9/10, Batch 20/20, Loss: 0.5580
Epoch 9/10, Train Loss: 0.2791, Valid Loss: 0.3936
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2536
Epoch 10/10, Batch 20/20, Loss: 0.6716
Epoch 10/10, Train Loss: 0.2750, Valid Loss: 0.4053
Accuracy: 0.8832
Precision: 0.8815
Recall: 0.8832
F1-score: 0.8788
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1784
Epoch 1/10, Batch 20/20, Loss: 1.5119
Epoch 1/10, Train Loss: 1.2847, Valid Loss: 0.9763
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8347
Epoch 2/10, Batch 20/20, Loss: 0.6432
Epoch 2/10, Train Loss: 0.7860, Valid Loss: 0.6673
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8105
Epoch 3/10, Batch 20/20, Loss: 0.9928
Epoch 3/10, Train Loss: 0.6136, Valid Loss: 0.5328
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4024
Epoch 4/10, Batch 20/20, Loss: 0.3392
Epoch 4/10, Train Loss: 0.4791, Valid Loss: 0.4702
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3897
Epoch 5/10, Batch 20/20, Loss: 0.7110
Epoch 5/10, Train Loss: 0.4191, Valid Loss: 0.4201
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5224
Epoch 6/10, Batch 20/20, Loss: 0.5233
Epoch 6/10, Train Loss: 0.3810, Valid Loss: 0.3899
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2715
Epoch 7/10, Batch 20/20, Loss: 0.2272
Epoch 7/10, Train Loss: 0.3227, Valid Loss: 0.3702
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4339
Epoch 8/10, Batch 20/20, Loss: 0.3529
Epoch 8/10, Train Loss: 0.3122, Valid Loss: 0.3603
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3230
Epoch 9/10, Batch 20/20, Loss: 0.7014
Epoch 9/10, Train Loss: 0.2977, Valid Loss: 0.3355
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3241
Epoch 10/10, Batch 20/20, Loss: 0.7417
Epoch 10/10, Train Loss: 0.2802, Valid Loss: 0.3526
Accuracy: 0.8879
Precision: 0.8838
Recall: 0.8879
F1-score: 0.8827
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3438
Epoch 1/10, Batch 20/20, Loss: 1.1528
Epoch 1/10, Train Loss: 1.2919, Valid Loss: 1.1057
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9607
Epoch 2/10, Batch 20/20, Loss: 0.7691
Epoch 2/10, Train Loss: 0.8299, Valid Loss: 0.7916
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8259
Epoch 3/10, Batch 20/20, Loss: 0.9600
Epoch 3/10, Train Loss: 0.6551, Valid Loss: 0.6524
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4644
Epoch 4/10, Batch 20/20, Loss: 0.6242
Epoch 4/10, Train Loss: 0.5407, Valid Loss: 0.5830
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4530
Epoch 5/10, Batch 20/20, Loss: 0.7647
Epoch 5/10, Train Loss: 0.4774, Valid Loss: 0.5277
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6223
Epoch 6/10, Batch 20/20, Loss: 0.5725
Epoch 6/10, Train Loss: 0.4296, Valid Loss: 0.5012
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4977
Epoch 7/10, Batch 20/20, Loss: 0.2843
Epoch 7/10, Train Loss: 0.3711, Valid Loss: 0.4687
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5338
Epoch 8/10, Batch 20/20, Loss: 0.3721
Epoch 8/10, Train Loss: 0.3576, Valid Loss: 0.4481
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4141
Epoch 9/10, Batch 20/20, Loss: 0.4085
Epoch 9/10, Train Loss: 0.3055, Valid Loss: 0.4265
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.5131
Epoch 10/10, Batch 20/20, Loss: 0.7061
Epoch 10/10, Train Loss: 0.3327, Valid Loss: 0.4116
Model saved!
Accuracy: 0.8890
Precision: 0.8855
Recall: 0.8890
F1-score: 0.8857
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1827
Epoch 1/10, Batch 20/20, Loss: 1.3043
Epoch 1/10, Train Loss: 1.2771, Valid Loss: 1.0067
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9065
Epoch 2/10, Batch 20/20, Loss: 0.6816
Epoch 2/10, Train Loss: 0.8008, Valid Loss: 0.7055
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7450
Epoch 3/10, Batch 20/20, Loss: 0.8039
Epoch 3/10, Train Loss: 0.6136, Valid Loss: 0.5642
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4808
Epoch 4/10, Batch 20/20, Loss: 0.5562
Epoch 4/10, Train Loss: 0.4917, Valid Loss: 0.4895
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3534
Epoch 5/10, Batch 20/20, Loss: 0.6884
Epoch 5/10, Train Loss: 0.4233, Valid Loss: 0.4276
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5526
Epoch 6/10, Batch 20/20, Loss: 0.3026
Epoch 6/10, Train Loss: 0.3661, Valid Loss: 0.3943
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3593
Epoch 7/10, Batch 20/20, Loss: 0.4480
Epoch 7/10, Train Loss: 0.3381, Valid Loss: 0.3746
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4121
Epoch 8/10, Batch 20/20, Loss: 0.2333
Epoch 8/10, Train Loss: 0.3109, Valid Loss: 0.3626
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3429
Epoch 9/10, Batch 20/20, Loss: 0.4165
Epoch 9/10, Train Loss: 0.2878, Valid Loss: 0.3388
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3040
Epoch 10/10, Batch 20/20, Loss: 0.9750
Epoch 10/10, Train Loss: 0.2879, Valid Loss: 0.3346
Model saved!
Accuracy: 0.8843
Precision: 0.8825
Recall: 0.8843
F1-score: 0.8808
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2204
Epoch 1/10, Batch 20/20, Loss: 1.3488
Epoch 1/10, Train Loss: 1.2903, Valid Loss: 0.9523
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8750
Epoch 2/10, Batch 20/20, Loss: 0.7367
Epoch 2/10, Train Loss: 0.8310, Valid Loss: 0.6752
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7689
Epoch 3/10, Batch 20/20, Loss: 0.8712
Epoch 3/10, Train Loss: 0.6373, Valid Loss: 0.5392
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4426
Epoch 4/10, Batch 20/20, Loss: 0.5278
Epoch 4/10, Train Loss: 0.5247, Valid Loss: 0.4673
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3040
Epoch 5/10, Batch 20/20, Loss: 0.7724
Epoch 5/10, Train Loss: 0.4513, Valid Loss: 0.4184
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6007
Epoch 6/10, Batch 20/20, Loss: 0.3219
Epoch 6/10, Train Loss: 0.3970, Valid Loss: 0.3877
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2633
Epoch 7/10, Batch 20/20, Loss: 0.4993
Epoch 7/10, Train Loss: 0.3501, Valid Loss: 0.3519
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4394
Epoch 8/10, Batch 20/20, Loss: 0.3383
Epoch 8/10, Train Loss: 0.3215, Valid Loss: 0.3394
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4917
Epoch 9/10, Batch 20/20, Loss: 0.4999
Epoch 9/10, Train Loss: 0.3013, Valid Loss: 0.3218
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3756
Epoch 10/10, Batch 20/20, Loss: 0.7677
Epoch 10/10, Train Loss: 0.3033, Valid Loss: 0.3154
Model saved!
Accuracy: 0.8808
Precision: 0.8764
Recall: 0.8808
F1-score: 0.8774
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2310
Epoch 1/10, Batch 20/20, Loss: 1.2471
Epoch 1/10, Train Loss: 1.2791, Valid Loss: 0.9971
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0024
Epoch 2/10, Batch 20/20, Loss: 0.5200
Epoch 2/10, Train Loss: 0.7931, Valid Loss: 0.6979
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7213
Epoch 3/10, Batch 20/20, Loss: 0.8591
Epoch 3/10, Train Loss: 0.6098, Valid Loss: 0.5810
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4492
Epoch 4/10, Batch 20/20, Loss: 0.3391
Epoch 4/10, Train Loss: 0.4864, Valid Loss: 0.5090
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4203
Epoch 5/10, Batch 20/20, Loss: 0.9003
Epoch 5/10, Train Loss: 0.4337, Valid Loss: 0.4670
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6545
Epoch 6/10, Batch 20/20, Loss: 0.2727
Epoch 6/10, Train Loss: 0.3806, Valid Loss: 0.4346
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3343
Epoch 7/10, Batch 20/20, Loss: 0.3001
Epoch 7/10, Train Loss: 0.3288, Valid Loss: 0.4072
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3543
Epoch 8/10, Batch 20/20, Loss: 0.6265
Epoch 8/10, Train Loss: 0.3232, Valid Loss: 0.3871
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2972
Epoch 9/10, Batch 20/20, Loss: 0.6021
Epoch 9/10, Train Loss: 0.3037, Valid Loss: 0.3674
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3050
Epoch 10/10, Batch 20/20, Loss: 0.6035
Epoch 10/10, Train Loss: 0.2788, Valid Loss: 0.3710
Accuracy: 0.8890
Precision: 0.8836
Recall: 0.8890
F1-score: 0.8853
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2806
Epoch 1/10, Batch 20/20, Loss: 1.2140
Epoch 1/10, Train Loss: 1.2937, Valid Loss: 1.0553
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9089
Epoch 2/10, Batch 20/20, Loss: 0.5263
Epoch 2/10, Train Loss: 0.8119, Valid Loss: 0.7652
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6908
Epoch 3/10, Batch 20/20, Loss: 0.9569
Epoch 3/10, Train Loss: 0.6328, Valid Loss: 0.6338
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4888
Epoch 4/10, Batch 20/20, Loss: 0.5651
Epoch 4/10, Train Loss: 0.4991, Valid Loss: 0.5685
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4490
Epoch 5/10, Batch 20/20, Loss: 0.8578
Epoch 5/10, Train Loss: 0.4390, Valid Loss: 0.5170
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4745
Epoch 6/10, Batch 20/20, Loss: 0.2963
Epoch 6/10, Train Loss: 0.3784, Valid Loss: 0.4816
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2355
Epoch 7/10, Batch 20/20, Loss: 0.3347
Epoch 7/10, Train Loss: 0.3317, Valid Loss: 0.4594
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3539
Epoch 8/10, Batch 20/20, Loss: 0.5627
Epoch 8/10, Train Loss: 0.3137, Valid Loss: 0.4376
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2807
Epoch 9/10, Batch 20/20, Loss: 0.6070
Epoch 9/10, Train Loss: 0.3053, Valid Loss: 0.4288
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2175
Epoch 10/10, Batch 20/20, Loss: 0.3745
Epoch 10/10, Train Loss: 0.2755, Valid Loss: 0.4197
Model saved!
Accuracy: 0.8914
Precision: 0.8854
Recall: 0.8914
F1-score: 0.8857
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3154
Epoch 1/10, Batch 20/20, Loss: 1.3422
Epoch 1/10, Train Loss: 1.2899, Valid Loss: 1.1066
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9096
Epoch 2/10, Batch 20/20, Loss: 0.8203
Epoch 2/10, Train Loss: 0.8218, Valid Loss: 0.7900
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8438
Epoch 3/10, Batch 20/20, Loss: 0.7905
Epoch 3/10, Train Loss: 0.6345, Valid Loss: 0.6699
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6175
Epoch 4/10, Batch 20/20, Loss: 0.5883
Epoch 4/10, Train Loss: 0.5071, Valid Loss: 0.5957
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5391
Epoch 5/10, Batch 20/20, Loss: 0.5216
Epoch 5/10, Train Loss: 0.4563, Valid Loss: 0.5578
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5744
Epoch 6/10, Batch 20/20, Loss: 0.4436
Epoch 6/10, Train Loss: 0.4007, Valid Loss: 0.5099
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4085
Epoch 7/10, Batch 20/20, Loss: 0.8953
Epoch 7/10, Train Loss: 0.3735, Valid Loss: 0.4852
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3821
Epoch 8/10, Batch 20/20, Loss: 0.3741
Epoch 8/10, Train Loss: 0.3441, Valid Loss: 0.4611
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2834
Epoch 9/10, Batch 20/20, Loss: 0.9846
Epoch 9/10, Train Loss: 0.3328, Valid Loss: 0.4470
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3642
Epoch 10/10, Batch 20/20, Loss: 0.6547
Epoch 10/10, Train Loss: 0.2953, Valid Loss: 0.4395
Model saved!
Accuracy: 0.8820
Precision: 0.8774
Recall: 0.8820
F1-score: 0.8765
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2206
Epoch 1/10, Batch 20/20, Loss: 1.3717
Epoch 1/10, Train Loss: 1.2889, Valid Loss: 1.0138
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0728
Epoch 2/10, Batch 20/20, Loss: 0.7037
Epoch 2/10, Train Loss: 0.8128, Valid Loss: 0.7068
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7265
Epoch 3/10, Batch 20/20, Loss: 0.6239
Epoch 3/10, Train Loss: 0.6111, Valid Loss: 0.5826
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4803
Epoch 4/10, Batch 20/20, Loss: 0.5405
Epoch 4/10, Train Loss: 0.5015, Valid Loss: 0.5033
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4181
Epoch 5/10, Batch 20/20, Loss: 0.7052
Epoch 5/10, Train Loss: 0.4377, Valid Loss: 0.4558
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6226
Epoch 6/10, Batch 20/20, Loss: 0.6058
Epoch 6/10, Train Loss: 0.4003, Valid Loss: 0.4240
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2791
Epoch 7/10, Batch 20/20, Loss: 0.2749
Epoch 7/10, Train Loss: 0.3535, Valid Loss: 0.4076
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4806
Epoch 8/10, Batch 20/20, Loss: 0.4591
Epoch 8/10, Train Loss: 0.3287, Valid Loss: 0.4001
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3947
Epoch 9/10, Batch 20/20, Loss: 0.4876
Epoch 9/10, Train Loss: 0.2990, Valid Loss: 0.3808
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2928
Epoch 10/10, Batch 20/20, Loss: 0.7471
Epoch 10/10, Train Loss: 0.2811, Valid Loss: 0.3782
Model saved!
Accuracy: 0.8902
Precision: 0.8847
Recall: 0.8902
F1-score: 0.8848
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2443
Epoch 1/10, Batch 20/20, Loss: 1.2179
Epoch 1/10, Train Loss: 1.2889, Valid Loss: 1.0897
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9632
Epoch 2/10, Batch 20/20, Loss: 0.7183
Epoch 2/10, Train Loss: 0.8201, Valid Loss: 0.7388
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8485
Epoch 3/10, Batch 20/20, Loss: 0.9530
Epoch 3/10, Train Loss: 0.6326, Valid Loss: 0.6056
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4990
Epoch 4/10, Batch 20/20, Loss: 0.8295
Epoch 4/10, Train Loss: 0.5206, Valid Loss: 0.5156
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3240
Epoch 5/10, Batch 20/20, Loss: 0.5534
Epoch 5/10, Train Loss: 0.4463, Valid Loss: 0.4797
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4591
Epoch 6/10, Batch 20/20, Loss: 0.4633
Epoch 6/10, Train Loss: 0.3944, Valid Loss: 0.4428
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2799
Epoch 7/10, Batch 20/20, Loss: 0.5288
Epoch 7/10, Train Loss: 0.3660, Valid Loss: 0.4128
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4522
Epoch 8/10, Batch 20/20, Loss: 0.6029
Epoch 8/10, Train Loss: 0.3529, Valid Loss: 0.3915
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2930
Epoch 9/10, Batch 20/20, Loss: 0.5423
Epoch 9/10, Train Loss: 0.3123, Valid Loss: 0.3851
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2481
Epoch 10/10, Batch 20/20, Loss: 0.6294
Epoch 10/10, Train Loss: 0.2979, Valid Loss: 0.3618
Model saved!
Accuracy: 0.8925
Precision: 0.8874
Recall: 0.8925
F1-score: 0.8884
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1369
Epoch 1/10, Batch 20/20, Loss: 1.3394
Epoch 1/10, Train Loss: 1.2895, Valid Loss: 0.9964
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8934
Epoch 2/10, Batch 20/20, Loss: 0.5448
Epoch 2/10, Train Loss: 0.8148, Valid Loss: 0.7038
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.9177
Epoch 3/10, Batch 20/20, Loss: 0.7629
Epoch 3/10, Train Loss: 0.6386, Valid Loss: 0.5806
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5349
Epoch 4/10, Batch 20/20, Loss: 0.4513
Epoch 4/10, Train Loss: 0.5015, Valid Loss: 0.5110
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3610
Epoch 5/10, Batch 20/20, Loss: 0.9920
Epoch 5/10, Train Loss: 0.4617, Valid Loss: 0.4629
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5858
Epoch 6/10, Batch 20/20, Loss: 0.4379
Epoch 6/10, Train Loss: 0.3981, Valid Loss: 0.4320
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3870
Epoch 7/10, Batch 20/20, Loss: 0.5005
Epoch 7/10, Train Loss: 0.3633, Valid Loss: 0.4049
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4382
Epoch 8/10, Batch 20/20, Loss: 0.3983
Epoch 8/10, Train Loss: 0.3355, Valid Loss: 0.3954
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2941
Epoch 9/10, Batch 20/20, Loss: 0.7431
Epoch 9/10, Train Loss: 0.3105, Valid Loss: 0.3713
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3535
Epoch 10/10, Batch 20/20, Loss: 0.5827
Epoch 10/10, Train Loss: 0.2954, Valid Loss: 0.3715
Accuracy: 0.8843
Precision: 0.8757
Recall: 0.8843
F1-score: 0.8779
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3166
Epoch 1/10, Batch 20/20, Loss: 1.4115
Epoch 1/10, Train Loss: 1.3030, Valid Loss: 1.0300
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9451
Epoch 2/10, Batch 20/20, Loss: 0.6831
Epoch 2/10, Train Loss: 0.8266, Valid Loss: 0.7094
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7707
Epoch 3/10, Batch 20/20, Loss: 0.8404
Epoch 3/10, Train Loss: 0.6421, Valid Loss: 0.5794
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5642
Epoch 4/10, Batch 20/20, Loss: 0.4275
Epoch 4/10, Train Loss: 0.5157, Valid Loss: 0.5185
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4093
Epoch 5/10, Batch 20/20, Loss: 0.8476
Epoch 5/10, Train Loss: 0.4573, Valid Loss: 0.4643
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5286
Epoch 6/10, Batch 20/20, Loss: 0.4928
Epoch 6/10, Train Loss: 0.3956, Valid Loss: 0.4423
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3025
Epoch 7/10, Batch 20/20, Loss: 0.5536
Epoch 7/10, Train Loss: 0.3703, Valid Loss: 0.4276
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4340
Epoch 8/10, Batch 20/20, Loss: 0.4867
Epoch 8/10, Train Loss: 0.3444, Valid Loss: 0.4070
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3011
Epoch 9/10, Batch 20/20, Loss: 0.5347
Epoch 9/10, Train Loss: 0.3022, Valid Loss: 0.3904
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2587
Epoch 10/10, Batch 20/20, Loss: 0.5790
Epoch 10/10, Train Loss: 0.2842, Valid Loss: 0.3886
Model saved!
Accuracy: 0.8925
Precision: 0.8890
Recall: 0.8925
F1-score: 0.8899
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2591
Epoch 1/10, Batch 20/20, Loss: 1.3906
Epoch 1/10, Train Loss: 1.2918, Valid Loss: 1.0949
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8772
Epoch 2/10, Batch 20/20, Loss: 0.8287
Epoch 2/10, Train Loss: 0.8270, Valid Loss: 0.7677
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6536
Epoch 3/10, Batch 20/20, Loss: 0.9742
Epoch 3/10, Train Loss: 0.6293, Valid Loss: 0.6303
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5138
Epoch 4/10, Batch 20/20, Loss: 0.7161
Epoch 4/10, Train Loss: 0.5142, Valid Loss: 0.5631
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3709
Epoch 5/10, Batch 20/20, Loss: 0.6517
Epoch 5/10, Train Loss: 0.4408, Valid Loss: 0.5106
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5221
Epoch 6/10, Batch 20/20, Loss: 0.3951
Epoch 6/10, Train Loss: 0.3842, Valid Loss: 0.4809
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3173
Epoch 7/10, Batch 20/20, Loss: 0.3875
Epoch 7/10, Train Loss: 0.3434, Valid Loss: 0.4595
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5339
Epoch 8/10, Batch 20/20, Loss: 0.3115
Epoch 8/10, Train Loss: 0.3188, Valid Loss: 0.4353
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3778
Epoch 9/10, Batch 20/20, Loss: 0.4548
Epoch 9/10, Train Loss: 0.2973, Valid Loss: 0.4123
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2902
Epoch 10/10, Batch 20/20, Loss: 0.6162
Epoch 10/10, Train Loss: 0.2919, Valid Loss: 0.4102
Model saved!
Accuracy: 0.8820
Precision: 0.8750
Recall: 0.8820
F1-score: 0.8769
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2282
Epoch 1/10, Batch 20/20, Loss: 1.3796
Epoch 1/10, Train Loss: 1.2784, Valid Loss: 1.0078
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9753
Epoch 2/10, Batch 20/20, Loss: 0.5549
Epoch 2/10, Train Loss: 0.8091, Valid Loss: 0.7288
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6930
Epoch 3/10, Batch 20/20, Loss: 0.7126
Epoch 3/10, Train Loss: 0.6170, Valid Loss: 0.5973
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4858
Epoch 4/10, Batch 20/20, Loss: 0.3498
Epoch 4/10, Train Loss: 0.4833, Valid Loss: 0.5349
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4305
Epoch 5/10, Batch 20/20, Loss: 0.5380
Epoch 5/10, Train Loss: 0.4348, Valid Loss: 0.4869
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5841
Epoch 6/10, Batch 20/20, Loss: 0.2893
Epoch 6/10, Train Loss: 0.3850, Valid Loss: 0.4556
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3057
Epoch 7/10, Batch 20/20, Loss: 0.4055
Epoch 7/10, Train Loss: 0.3418, Valid Loss: 0.4278
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4612
Epoch 8/10, Batch 20/20, Loss: 0.2834
Epoch 8/10, Train Loss: 0.3223, Valid Loss: 0.4105
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4979
Epoch 9/10, Batch 20/20, Loss: 0.4557
Epoch 9/10, Train Loss: 0.2906, Valid Loss: 0.3983
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2800
Epoch 10/10, Batch 20/20, Loss: 0.7428
Epoch 10/10, Train Loss: 0.2866, Valid Loss: 0.3735
Model saved!
Accuracy: 0.8855
Precision: 0.8832
Recall: 0.8855
F1-score: 0.8823
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2091
Epoch 1/10, Batch 20/20, Loss: 1.3540
Epoch 1/10, Train Loss: 1.2891, Valid Loss: 1.0063
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8577
Epoch 2/10, Batch 20/20, Loss: 0.9440
Epoch 2/10, Train Loss: 0.8203, Valid Loss: 0.7347
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7152
Epoch 3/10, Batch 20/20, Loss: 0.8923
Epoch 3/10, Train Loss: 0.6235, Valid Loss: 0.6187
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4618
Epoch 4/10, Batch 20/20, Loss: 0.5121
Epoch 4/10, Train Loss: 0.4915, Valid Loss: 0.5391
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3384
Epoch 5/10, Batch 20/20, Loss: 0.7694
Epoch 5/10, Train Loss: 0.4366, Valid Loss: 0.5102
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.7194
Epoch 6/10, Batch 20/20, Loss: 0.5854
Epoch 6/10, Train Loss: 0.3950, Valid Loss: 0.4785
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3238
Epoch 7/10, Batch 20/20, Loss: 0.5302
Epoch 7/10, Train Loss: 0.3646, Valid Loss: 0.4528
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4233
Epoch 8/10, Batch 20/20, Loss: 0.2727
Epoch 8/10, Train Loss: 0.3250, Valid Loss: 0.4414
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3804
Epoch 9/10, Batch 20/20, Loss: 0.4321
Epoch 9/10, Train Loss: 0.2941, Valid Loss: 0.4329
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3285
Epoch 10/10, Batch 20/20, Loss: 0.7242
Epoch 10/10, Train Loss: 0.2882, Valid Loss: 0.4102
Model saved!
Accuracy: 0.8914
Precision: 0.8859
Recall: 0.8914
F1-score: 0.8869
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1445
Epoch 1/10, Batch 20/20, Loss: 1.3630
Epoch 1/10, Train Loss: 1.2743, Valid Loss: 1.0507
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8871
Epoch 2/10, Batch 20/20, Loss: 0.7965
Epoch 2/10, Train Loss: 0.8063, Valid Loss: 0.7516
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7425
Epoch 3/10, Batch 20/20, Loss: 0.8384
Epoch 3/10, Train Loss: 0.6162, Valid Loss: 0.6350
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4979
Epoch 4/10, Batch 20/20, Loss: 0.6105
Epoch 4/10, Train Loss: 0.4947, Valid Loss: 0.5607
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3785
Epoch 5/10, Batch 20/20, Loss: 0.4482
Epoch 5/10, Train Loss: 0.4226, Valid Loss: 0.5217
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4758
Epoch 6/10, Batch 20/20, Loss: 0.2806
Epoch 6/10, Train Loss: 0.3817, Valid Loss: 0.4782
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3263
Epoch 7/10, Batch 20/20, Loss: 0.4117
Epoch 7/10, Train Loss: 0.3378, Valid Loss: 0.4513
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4364
Epoch 8/10, Batch 20/20, Loss: 0.3572
Epoch 8/10, Train Loss: 0.3205, Valid Loss: 0.4371
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3830
Epoch 9/10, Batch 20/20, Loss: 0.6491
Epoch 9/10, Train Loss: 0.3199, Valid Loss: 0.4244
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2354
Epoch 10/10, Batch 20/20, Loss: 0.4910
Epoch 10/10, Train Loss: 0.2732, Valid Loss: 0.4152
Model saved!
Accuracy: 0.8832
Precision: 0.8764
Recall: 0.8832
F1-score: 0.8770
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1693
Epoch 1/10, Batch 20/20, Loss: 1.3044
Epoch 1/10, Train Loss: 1.2964, Valid Loss: 1.0139
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9635
Epoch 2/10, Batch 20/20, Loss: 0.5471
Epoch 2/10, Train Loss: 0.8070, Valid Loss: 0.7248
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6709
Epoch 3/10, Batch 20/20, Loss: 0.7532
Epoch 3/10, Train Loss: 0.6157, Valid Loss: 0.6046
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4739
Epoch 4/10, Batch 20/20, Loss: 0.7067
Epoch 4/10, Train Loss: 0.5078, Valid Loss: 0.5292
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4219
Epoch 5/10, Batch 20/20, Loss: 0.7047
Epoch 5/10, Train Loss: 0.4438, Valid Loss: 0.4930
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6637
Epoch 6/10, Batch 20/20, Loss: 0.3703
Epoch 6/10, Train Loss: 0.3908, Valid Loss: 0.4571
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3027
Epoch 7/10, Batch 20/20, Loss: 0.4288
Epoch 7/10, Train Loss: 0.3511, Valid Loss: 0.4345
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4702
Epoch 8/10, Batch 20/20, Loss: 0.4124
Epoch 8/10, Train Loss: 0.3304, Valid Loss: 0.4149
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4619
Epoch 9/10, Batch 20/20, Loss: 0.4838
Epoch 9/10, Train Loss: 0.2943, Valid Loss: 0.4094
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3132
Epoch 10/10, Batch 20/20, Loss: 0.8242
Epoch 10/10, Train Loss: 0.3029, Valid Loss: 0.3988
Model saved!
Accuracy: 0.8808
Precision: 0.8744
Recall: 0.8808
F1-score: 0.8749
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2555
Epoch 1/10, Batch 20/20, Loss: 1.2965
Epoch 1/10, Train Loss: 1.3041, Valid Loss: 1.0819
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9749
Epoch 2/10, Batch 20/20, Loss: 0.7161
Epoch 2/10, Train Loss: 0.8304, Valid Loss: 0.7621
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7206
Epoch 3/10, Batch 20/20, Loss: 0.7765
Epoch 3/10, Train Loss: 0.6532, Valid Loss: 0.6396
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4859
Epoch 4/10, Batch 20/20, Loss: 0.4183
Epoch 4/10, Train Loss: 0.5139, Valid Loss: 0.5499
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4111
Epoch 5/10, Batch 20/20, Loss: 0.5794
Epoch 5/10, Train Loss: 0.4516, Valid Loss: 0.4993
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5619
Epoch 6/10, Batch 20/20, Loss: 0.6396
Epoch 6/10, Train Loss: 0.4151, Valid Loss: 0.4658
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2982
Epoch 7/10, Batch 20/20, Loss: 0.4895
Epoch 7/10, Train Loss: 0.3640, Valid Loss: 0.4329
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4910
Epoch 8/10, Batch 20/20, Loss: 0.3509
Epoch 8/10, Train Loss: 0.3336, Valid Loss: 0.4171
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2784
Epoch 9/10, Batch 20/20, Loss: 0.5453
Epoch 9/10, Train Loss: 0.3113, Valid Loss: 0.3926
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2777
Epoch 10/10, Batch 20/20, Loss: 0.6070
Epoch 10/10, Train Loss: 0.3049, Valid Loss: 0.3864
Model saved!
Accuracy: 0.8879
Precision: 0.8818
Recall: 0.8879
F1-score: 0.8817
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2369
Epoch 1/10, Batch 20/20, Loss: 1.3457
Epoch 1/10, Train Loss: 1.2885, Valid Loss: 1.0517
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9774
Epoch 2/10, Batch 20/20, Loss: 0.9057
Epoch 2/10, Train Loss: 0.8439, Valid Loss: 0.7407
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8568
Epoch 3/10, Batch 20/20, Loss: 1.1671
Epoch 3/10, Train Loss: 0.6843, Valid Loss: 0.6046
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4407
Epoch 4/10, Batch 20/20, Loss: 0.4801
Epoch 4/10, Train Loss: 0.5552, Valid Loss: 0.5252
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3297
Epoch 5/10, Batch 20/20, Loss: 0.7396
Epoch 5/10, Train Loss: 0.4841, Valid Loss: 0.4769
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5508
Epoch 6/10, Batch 20/20, Loss: 0.6172
Epoch 6/10, Train Loss: 0.4427, Valid Loss: 0.4404
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4111
Epoch 7/10, Batch 20/20, Loss: 0.5516
Epoch 7/10, Train Loss: 0.3920, Valid Loss: 0.4177
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3416
Epoch 8/10, Batch 20/20, Loss: 0.5546
Epoch 8/10, Train Loss: 0.3751, Valid Loss: 0.3827
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3774
Epoch 9/10, Batch 20/20, Loss: 0.4521
Epoch 9/10, Train Loss: 0.3431, Valid Loss: 0.3754
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3245
Epoch 10/10, Batch 20/20, Loss: 0.7688
Epoch 10/10, Train Loss: 0.3345, Valid Loss: 0.3682
Model saved!
Accuracy: 0.8808
Precision: 0.8771
Recall: 0.8808
F1-score: 0.8774
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3116
Epoch 1/10, Batch 20/20, Loss: 1.2461
Epoch 1/10, Train Loss: 1.2961, Valid Loss: 1.0403
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0314
Epoch 2/10, Batch 20/20, Loss: 0.6620
Epoch 2/10, Train Loss: 0.8243, Valid Loss: 0.7193
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8256
Epoch 3/10, Batch 20/20, Loss: 0.8829
Epoch 3/10, Train Loss: 0.6502, Valid Loss: 0.5919
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4355
Epoch 4/10, Batch 20/20, Loss: 0.6293
Epoch 4/10, Train Loss: 0.5190, Valid Loss: 0.5124
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4076
Epoch 5/10, Batch 20/20, Loss: 0.5672
Epoch 5/10, Train Loss: 0.4487, Valid Loss: 0.4720
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5240
Epoch 6/10, Batch 20/20, Loss: 0.4294
Epoch 6/10, Train Loss: 0.4093, Valid Loss: 0.4320
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3046
Epoch 7/10, Batch 20/20, Loss: 0.3592
Epoch 7/10, Train Loss: 0.3708, Valid Loss: 0.4113
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4080
Epoch 8/10, Batch 20/20, Loss: 0.3034
Epoch 8/10, Train Loss: 0.3509, Valid Loss: 0.3953
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2850
Epoch 9/10, Batch 20/20, Loss: 0.4870
Epoch 9/10, Train Loss: 0.3204, Valid Loss: 0.3791
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3763
Epoch 10/10, Batch 20/20, Loss: 0.6317
Epoch 10/10, Train Loss: 0.3084, Valid Loss: 0.3746
Model saved!
Accuracy: 0.8925
Precision: 0.8874
Recall: 0.8925
F1-score: 0.8868
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2804
Epoch 1/10, Batch 20/20, Loss: 1.2737
Epoch 1/10, Train Loss: 1.2981, Valid Loss: 1.0866
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0033
Epoch 2/10, Batch 20/20, Loss: 0.6351
Epoch 2/10, Train Loss: 0.8325, Valid Loss: 0.7673
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7608
Epoch 3/10, Batch 20/20, Loss: 0.9583
Epoch 3/10, Train Loss: 0.6536, Valid Loss: 0.6486
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4770
Epoch 4/10, Batch 20/20, Loss: 0.5477
Epoch 4/10, Train Loss: 0.5152, Valid Loss: 0.5738
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3450
Epoch 5/10, Batch 20/20, Loss: 0.6588
Epoch 5/10, Train Loss: 0.4553, Valid Loss: 0.5228
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5134
Epoch 6/10, Batch 20/20, Loss: 0.4175
Epoch 6/10, Train Loss: 0.3973, Valid Loss: 0.4866
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4167
Epoch 7/10, Batch 20/20, Loss: 0.3471
Epoch 7/10, Train Loss: 0.3630, Valid Loss: 0.4562
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5153
Epoch 8/10, Batch 20/20, Loss: 0.4043
Epoch 8/10, Train Loss: 0.3430, Valid Loss: 0.4548
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3783
Epoch 9/10, Batch 20/20, Loss: 0.5738
Epoch 9/10, Train Loss: 0.3150, Valid Loss: 0.4182
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2075
Epoch 10/10, Batch 20/20, Loss: 0.5930
Epoch 10/10, Train Loss: 0.3004, Valid Loss: 0.4236
Accuracy: 0.8843
Precision: 0.8803
Recall: 0.8843
F1-score: 0.8815
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1678
Epoch 1/10, Batch 20/20, Loss: 1.3697
Epoch 1/10, Train Loss: 1.2765, Valid Loss: 1.0835
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9068
Epoch 2/10, Batch 20/20, Loss: 0.4955
Epoch 2/10, Train Loss: 0.8106, Valid Loss: 0.7599
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7199
Epoch 3/10, Batch 20/20, Loss: 0.8763
Epoch 3/10, Train Loss: 0.6366, Valid Loss: 0.6336
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4940
Epoch 4/10, Batch 20/20, Loss: 0.4140
Epoch 4/10, Train Loss: 0.5230, Valid Loss: 0.5471
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4223
Epoch 5/10, Batch 20/20, Loss: 0.9123
Epoch 5/10, Train Loss: 0.4783, Valid Loss: 0.5055
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5165
Epoch 6/10, Batch 20/20, Loss: 0.5195
Epoch 6/10, Train Loss: 0.4129, Valid Loss: 0.4572
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2523
Epoch 7/10, Batch 20/20, Loss: 0.3829
Epoch 7/10, Train Loss: 0.3675, Valid Loss: 0.4254
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4364
Epoch 8/10, Batch 20/20, Loss: 0.5284
Epoch 8/10, Train Loss: 0.3585, Valid Loss: 0.4042
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3276
Epoch 9/10, Batch 20/20, Loss: 0.4504
Epoch 9/10, Train Loss: 0.3149, Valid Loss: 0.3876
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2693
Epoch 10/10, Batch 20/20, Loss: 0.3976
Epoch 10/10, Train Loss: 0.2883, Valid Loss: 0.3776
Model saved!
Accuracy: 0.8855
Precision: 0.8845
Recall: 0.8855
F1-score: 0.8816
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3285
Epoch 1/10, Batch 20/20, Loss: 1.3199
Epoch 1/10, Train Loss: 1.2999, Valid Loss: 1.0622
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9408
Epoch 2/10, Batch 20/20, Loss: 0.6463
Epoch 2/10, Train Loss: 0.8087, Valid Loss: 0.7397
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7947
Epoch 3/10, Batch 20/20, Loss: 0.8241
Epoch 3/10, Train Loss: 0.6132, Valid Loss: 0.6103
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3906
Epoch 4/10, Batch 20/20, Loss: 0.2942
Epoch 4/10, Train Loss: 0.4813, Valid Loss: 0.5425
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3896
Epoch 5/10, Batch 20/20, Loss: 0.5999
Epoch 5/10, Train Loss: 0.4274, Valid Loss: 0.4870
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5334
Epoch 6/10, Batch 20/20, Loss: 0.4386
Epoch 6/10, Train Loss: 0.3801, Valid Loss: 0.4576
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3122
Epoch 7/10, Batch 20/20, Loss: 0.3915
Epoch 7/10, Train Loss: 0.3273, Valid Loss: 0.4251
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3492
Epoch 8/10, Batch 20/20, Loss: 0.3978
Epoch 8/10, Train Loss: 0.3199, Valid Loss: 0.4103
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3276
Epoch 9/10, Batch 20/20, Loss: 0.5341
Epoch 9/10, Train Loss: 0.2962, Valid Loss: 0.3949
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2489
Epoch 10/10, Batch 20/20, Loss: 0.4227
Epoch 10/10, Train Loss: 0.2642, Valid Loss: 0.3997
Accuracy: 0.8843
Precision: 0.8777
Recall: 0.8843
F1-score: 0.8797
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2059
Epoch 1/10, Batch 20/20, Loss: 1.5835
Epoch 1/10, Train Loss: 1.2928, Valid Loss: 0.9699
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.1103
Epoch 2/10, Batch 20/20, Loss: 0.7146
Epoch 2/10, Train Loss: 0.7937, Valid Loss: 0.6893
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7323
Epoch 3/10, Batch 20/20, Loss: 0.6454
Epoch 3/10, Train Loss: 0.6134, Valid Loss: 0.5495
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5728
Epoch 4/10, Batch 20/20, Loss: 0.5168
Epoch 4/10, Train Loss: 0.4943, Valid Loss: 0.4916
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4003
Epoch 5/10, Batch 20/20, Loss: 0.5636
Epoch 5/10, Train Loss: 0.4271, Valid Loss: 0.4438
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4913
Epoch 6/10, Batch 20/20, Loss: 0.3406
Epoch 6/10, Train Loss: 0.3752, Valid Loss: 0.4151
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2757
Epoch 7/10, Batch 20/20, Loss: 0.5627
Epoch 7/10, Train Loss: 0.3421, Valid Loss: 0.3973
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3387
Epoch 8/10, Batch 20/20, Loss: 0.6600
Epoch 8/10, Train Loss: 0.3301, Valid Loss: 0.3964
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4704
Epoch 9/10, Batch 20/20, Loss: 0.4217
Epoch 9/10, Train Loss: 0.2845, Valid Loss: 0.3622
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3414
Epoch 10/10, Batch 20/20, Loss: 0.6696
Epoch 10/10, Train Loss: 0.2782, Valid Loss: 0.3641
Accuracy: 0.8832
Precision: 0.8771
Recall: 0.8832
F1-score: 0.8790
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1352
Epoch 1/10, Batch 20/20, Loss: 1.2965
Epoch 1/10, Train Loss: 1.2588, Valid Loss: 1.0314
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0191
Epoch 2/10, Batch 20/20, Loss: 0.5713
Epoch 2/10, Train Loss: 0.7725, Valid Loss: 0.7337
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7221
Epoch 3/10, Batch 20/20, Loss: 0.5657
Epoch 3/10, Train Loss: 0.5787, Valid Loss: 0.6173
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5366
Epoch 4/10, Batch 20/20, Loss: 0.6727
Epoch 4/10, Train Loss: 0.4965, Valid Loss: 0.5537
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3936
Epoch 5/10, Batch 20/20, Loss: 0.4746
Epoch 5/10, Train Loss: 0.4218, Valid Loss: 0.5050
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6095
Epoch 6/10, Batch 20/20, Loss: 0.4954
Epoch 6/10, Train Loss: 0.3773, Valid Loss: 0.4767
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3112
Epoch 7/10, Batch 20/20, Loss: 0.5926
Epoch 7/10, Train Loss: 0.3296, Valid Loss: 0.4573
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4915
Epoch 8/10, Batch 20/20, Loss: 0.5781
Epoch 8/10, Train Loss: 0.3330, Valid Loss: 0.4445
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3425
Epoch 9/10, Batch 20/20, Loss: 0.4107
Epoch 9/10, Train Loss: 0.2799, Valid Loss: 0.4279
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2559
Epoch 10/10, Batch 20/20, Loss: 0.7247
Epoch 10/10, Train Loss: 0.2864, Valid Loss: 0.4277
Model saved!
Accuracy: 0.8750
Precision: 0.8726
Recall: 0.8750
F1-score: 0.8698
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1594
Epoch 1/10, Batch 20/20, Loss: 1.2934
Epoch 1/10, Train Loss: 1.2688, Valid Loss: 1.0040
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9643
Epoch 2/10, Batch 20/20, Loss: 0.5676
Epoch 2/10, Train Loss: 0.7996, Valid Loss: 0.7031
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7555
Epoch 3/10, Batch 20/20, Loss: 0.6989
Epoch 3/10, Train Loss: 0.5976, Valid Loss: 0.5705
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.3873
Epoch 4/10, Batch 20/20, Loss: 0.4783
Epoch 4/10, Train Loss: 0.4708, Valid Loss: 0.5089
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4081
Epoch 5/10, Batch 20/20, Loss: 0.5528
Epoch 5/10, Train Loss: 0.4140, Valid Loss: 0.4546
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4884
Epoch 6/10, Batch 20/20, Loss: 0.7349
Epoch 6/10, Train Loss: 0.3778, Valid Loss: 0.4299
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2823
Epoch 7/10, Batch 20/20, Loss: 0.2655
Epoch 7/10, Train Loss: 0.3258, Valid Loss: 0.4083
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3939
Epoch 8/10, Batch 20/20, Loss: 0.3455
Epoch 8/10, Train Loss: 0.2962, Valid Loss: 0.3891
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3237
Epoch 9/10, Batch 20/20, Loss: 0.5090
Epoch 9/10, Train Loss: 0.2903, Valid Loss: 0.3710
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3484
Epoch 10/10, Batch 20/20, Loss: 0.5495
Epoch 10/10, Train Loss: 0.2673, Valid Loss: 0.3641
Model saved!
Accuracy: 0.8843
Precision: 0.8792
Recall: 0.8843
F1-score: 0.8772
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1905
Epoch 1/10, Batch 20/20, Loss: 1.4383
Epoch 1/10, Train Loss: 1.2779, Valid Loss: 0.9845
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9609
Epoch 2/10, Batch 20/20, Loss: 0.5709
Epoch 2/10, Train Loss: 0.7971, Valid Loss: 0.7133
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7084
Epoch 3/10, Batch 20/20, Loss: 0.8692
Epoch 3/10, Train Loss: 0.6100, Valid Loss: 0.5867
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4390
Epoch 4/10, Batch 20/20, Loss: 0.5041
Epoch 4/10, Train Loss: 0.4889, Valid Loss: 0.5316
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3692
Epoch 5/10, Batch 20/20, Loss: 0.6809
Epoch 5/10, Train Loss: 0.4311, Valid Loss: 0.4758
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5653
Epoch 6/10, Batch 20/20, Loss: 0.3734
Epoch 6/10, Train Loss: 0.3782, Valid Loss: 0.4562
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2998
Epoch 7/10, Batch 20/20, Loss: 0.2925
Epoch 7/10, Train Loss: 0.3364, Valid Loss: 0.4332
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4221
Epoch 8/10, Batch 20/20, Loss: 0.4302
Epoch 8/10, Train Loss: 0.3124, Valid Loss: 0.4194
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4724
Epoch 9/10, Batch 20/20, Loss: 0.9114
Epoch 9/10, Train Loss: 0.3045, Valid Loss: 0.3901
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2508
Epoch 10/10, Batch 20/20, Loss: 0.5711
Epoch 10/10, Train Loss: 0.2781, Valid Loss: 0.3931
Accuracy: 0.8820
Precision: 0.8759
Recall: 0.8820
F1-score: 0.8773
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2183
Epoch 1/10, Batch 20/20, Loss: 1.2540
Epoch 1/10, Train Loss: 1.2878, Valid Loss: 1.0067
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0548
Epoch 2/10, Batch 20/20, Loss: 0.6560
Epoch 2/10, Train Loss: 0.8353, Valid Loss: 0.6841
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7922
Epoch 3/10, Batch 20/20, Loss: 0.7756
Epoch 3/10, Train Loss: 0.6594, Valid Loss: 0.5578
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5742
Epoch 4/10, Batch 20/20, Loss: 0.5914
Epoch 4/10, Train Loss: 0.5378, Valid Loss: 0.4741
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4430
Epoch 5/10, Batch 20/20, Loss: 0.7632
Epoch 5/10, Train Loss: 0.4845, Valid Loss: 0.4414
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6375
Epoch 6/10, Batch 20/20, Loss: 0.7391
Epoch 6/10, Train Loss: 0.4499, Valid Loss: 0.4030
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2607
Epoch 7/10, Batch 20/20, Loss: 0.4254
Epoch 7/10, Train Loss: 0.3909, Valid Loss: 0.3837
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4309
Epoch 8/10, Batch 20/20, Loss: 0.2448
Epoch 8/10, Train Loss: 0.3602, Valid Loss: 0.3664
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4432
Epoch 9/10, Batch 20/20, Loss: 0.5408
Epoch 9/10, Train Loss: 0.3392, Valid Loss: 0.3559
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3768
Epoch 10/10, Batch 20/20, Loss: 0.7976
Epoch 10/10, Train Loss: 0.3339, Valid Loss: 0.3489
Model saved!
Accuracy: 0.8808
Precision: 0.8791
Recall: 0.8808
F1-score: 0.8778
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2952
Epoch 1/10, Batch 20/20, Loss: 1.2000
Epoch 1/10, Train Loss: 1.3019, Valid Loss: 1.0684
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9677
Epoch 2/10, Batch 20/20, Loss: 0.6741
Epoch 2/10, Train Loss: 0.8273, Valid Loss: 0.7495
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7738
Epoch 3/10, Batch 20/20, Loss: 0.8502
Epoch 3/10, Train Loss: 0.6382, Valid Loss: 0.6047
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5490
Epoch 4/10, Batch 20/20, Loss: 0.2907
Epoch 4/10, Train Loss: 0.5084, Valid Loss: 0.5594
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4332
Epoch 5/10, Batch 20/20, Loss: 0.7533
Epoch 5/10, Train Loss: 0.4699, Valid Loss: 0.4981
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6992
Epoch 6/10, Batch 20/20, Loss: 0.6673
Epoch 6/10, Train Loss: 0.4302, Valid Loss: 0.4767
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3278
Epoch 7/10, Batch 20/20, Loss: 0.4809
Epoch 7/10, Train Loss: 0.3704, Valid Loss: 0.4479
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3901
Epoch 8/10, Batch 20/20, Loss: 0.2232
Epoch 8/10, Train Loss: 0.3434, Valid Loss: 0.4358
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2803
Epoch 9/10, Batch 20/20, Loss: 0.4370
Epoch 9/10, Train Loss: 0.3110, Valid Loss: 0.4145
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3043
Epoch 10/10, Batch 20/20, Loss: 0.5011
Epoch 10/10, Train Loss: 0.3055, Valid Loss: 0.4069
Model saved!
Accuracy: 0.8914
Precision: 0.8874
Recall: 0.8914
F1-score: 0.8876
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2349
Epoch 1/10, Batch 20/20, Loss: 1.3333
Epoch 1/10, Train Loss: 1.2935, Valid Loss: 1.0210
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9944
Epoch 2/10, Batch 20/20, Loss: 0.6854
Epoch 2/10, Train Loss: 0.8205, Valid Loss: 0.7149
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6622
Epoch 3/10, Batch 20/20, Loss: 0.7505
Epoch 3/10, Train Loss: 0.6280, Valid Loss: 0.5807
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4946
Epoch 4/10, Batch 20/20, Loss: 0.6412
Epoch 4/10, Train Loss: 0.5123, Valid Loss: 0.4949
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3589
Epoch 5/10, Batch 20/20, Loss: 0.7029
Epoch 5/10, Train Loss: 0.4392, Valid Loss: 0.4472
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4198
Epoch 6/10, Batch 20/20, Loss: 0.3769
Epoch 6/10, Train Loss: 0.4009, Valid Loss: 0.4105
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2355
Epoch 7/10, Batch 20/20, Loss: 0.3266
Epoch 7/10, Train Loss: 0.3410, Valid Loss: 0.3802
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2692
Epoch 8/10, Batch 20/20, Loss: 0.5024
Epoch 8/10, Train Loss: 0.3279, Valid Loss: 0.3596
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3877
Epoch 9/10, Batch 20/20, Loss: 0.5405
Epoch 9/10, Train Loss: 0.3149, Valid Loss: 0.3537
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3461
Epoch 10/10, Batch 20/20, Loss: 0.5564
Epoch 10/10, Train Loss: 0.2928, Valid Loss: 0.3275
Model saved!
Accuracy: 0.8925
Precision: 0.8893
Recall: 0.8925
F1-score: 0.8874
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1836
Epoch 1/10, Batch 20/20, Loss: 1.2971
Epoch 1/10, Train Loss: 1.2854, Valid Loss: 0.9804
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9783
Epoch 2/10, Batch 20/20, Loss: 0.5997
Epoch 2/10, Train Loss: 0.8137, Valid Loss: 0.6814
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7024
Epoch 3/10, Batch 20/20, Loss: 0.8280
Epoch 3/10, Train Loss: 0.6254, Valid Loss: 0.5483
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6208
Epoch 4/10, Batch 20/20, Loss: 0.5224
Epoch 4/10, Train Loss: 0.5025, Valid Loss: 0.4811
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3562
Epoch 5/10, Batch 20/20, Loss: 0.6439
Epoch 5/10, Train Loss: 0.4510, Valid Loss: 0.4316
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5508
Epoch 6/10, Batch 20/20, Loss: 0.6845
Epoch 6/10, Train Loss: 0.4057, Valid Loss: 0.3949
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2303
Epoch 7/10, Batch 20/20, Loss: 0.4568
Epoch 7/10, Train Loss: 0.3492, Valid Loss: 0.3758
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4809
Epoch 8/10, Batch 20/20, Loss: 0.6760
Epoch 8/10, Train Loss: 0.3421, Valid Loss: 0.3584
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3598
Epoch 9/10, Batch 20/20, Loss: 0.5534
Epoch 9/10, Train Loss: 0.3226, Valid Loss: 0.3382
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3865
Epoch 10/10, Batch 20/20, Loss: 0.5839
Epoch 10/10, Train Loss: 0.3004, Valid Loss: 0.3415
Accuracy: 0.8879
Precision: 0.8817
Recall: 0.8879
F1-score: 0.8836
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2599
Epoch 1/10, Batch 20/20, Loss: 1.3157
Epoch 1/10, Train Loss: 1.2873, Valid Loss: 1.0647
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9154
Epoch 2/10, Batch 20/20, Loss: 0.5663
Epoch 2/10, Train Loss: 0.7916, Valid Loss: 0.7763
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6039
Epoch 3/10, Batch 20/20, Loss: 0.9858
Epoch 3/10, Train Loss: 0.6153, Valid Loss: 0.6598
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4687
Epoch 4/10, Batch 20/20, Loss: 0.4430
Epoch 4/10, Train Loss: 0.4802, Valid Loss: 0.6084
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4191
Epoch 5/10, Batch 20/20, Loss: 0.7995
Epoch 5/10, Train Loss: 0.4361, Valid Loss: 0.5541
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4840
Epoch 6/10, Batch 20/20, Loss: 0.4651
Epoch 6/10, Train Loss: 0.3731, Valid Loss: 0.5372
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2309
Epoch 7/10, Batch 20/20, Loss: 0.5334
Epoch 7/10, Train Loss: 0.3451, Valid Loss: 0.5160
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4071
Epoch 8/10, Batch 20/20, Loss: 0.2496
Epoch 8/10, Train Loss: 0.3149, Valid Loss: 0.5005
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2994
Epoch 9/10, Batch 20/20, Loss: 0.3992
Epoch 9/10, Train Loss: 0.2806, Valid Loss: 0.4615
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3201
Epoch 10/10, Batch 20/20, Loss: 0.4198
Epoch 10/10, Train Loss: 0.2667, Valid Loss: 0.4814
Accuracy: 0.8902
Precision: 0.8844
Recall: 0.8902
F1-score: 0.8865
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2496
Epoch 1/10, Batch 20/20, Loss: 1.3288
Epoch 1/10, Train Loss: 1.2830, Valid Loss: 1.0321
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9342
Epoch 2/10, Batch 20/20, Loss: 0.5933
Epoch 2/10, Train Loss: 0.8025, Valid Loss: 0.7153
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7912
Epoch 3/10, Batch 20/20, Loss: 0.7314
Epoch 3/10, Train Loss: 0.6094, Valid Loss: 0.5992
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5107
Epoch 4/10, Batch 20/20, Loss: 0.5188
Epoch 4/10, Train Loss: 0.4936, Valid Loss: 0.5299
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5171
Epoch 5/10, Batch 20/20, Loss: 0.7570
Epoch 5/10, Train Loss: 0.4354, Valid Loss: 0.4839
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5291
Epoch 6/10, Batch 20/20, Loss: 0.3820
Epoch 6/10, Train Loss: 0.3753, Valid Loss: 0.4592
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3910
Epoch 7/10, Batch 20/20, Loss: 0.5630
Epoch 7/10, Train Loss: 0.3469, Valid Loss: 0.4440
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5578
Epoch 8/10, Batch 20/20, Loss: 0.3368
Epoch 8/10, Train Loss: 0.3210, Valid Loss: 0.4299
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3762
Epoch 9/10, Batch 20/20, Loss: 0.6472
Epoch 9/10, Train Loss: 0.2988, Valid Loss: 0.4222
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3187
Epoch 10/10, Batch 20/20, Loss: 0.4067
Epoch 10/10, Train Loss: 0.2666, Valid Loss: 0.4206
Model saved!
Accuracy: 0.8914
Precision: 0.8874
Recall: 0.8914
F1-score: 0.8878
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2568
Epoch 1/10, Batch 20/20, Loss: 1.1220
Epoch 1/10, Train Loss: 1.2712, Valid Loss: 1.0120
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9558
Epoch 2/10, Batch 20/20, Loss: 0.6972
Epoch 2/10, Train Loss: 0.8058, Valid Loss: 0.7051
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7146
Epoch 3/10, Batch 20/20, Loss: 0.6526
Epoch 3/10, Train Loss: 0.6090, Valid Loss: 0.5821
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5036
Epoch 4/10, Batch 20/20, Loss: 0.6697
Epoch 4/10, Train Loss: 0.5011, Valid Loss: 0.5018
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3618
Epoch 5/10, Batch 20/20, Loss: 0.7340
Epoch 5/10, Train Loss: 0.4400, Valid Loss: 0.4562
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6300
Epoch 6/10, Batch 20/20, Loss: 0.7263
Epoch 6/10, Train Loss: 0.4033, Valid Loss: 0.4229
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3667
Epoch 7/10, Batch 20/20, Loss: 0.4337
Epoch 7/10, Train Loss: 0.3497, Valid Loss: 0.3970
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4223
Epoch 8/10, Batch 20/20, Loss: 0.3426
Epoch 8/10, Train Loss: 0.3254, Valid Loss: 0.3679
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2973
Epoch 9/10, Batch 20/20, Loss: 0.5460
Epoch 9/10, Train Loss: 0.3023, Valid Loss: 0.3654
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3681
Epoch 10/10, Batch 20/20, Loss: 0.9803
Epoch 10/10, Train Loss: 0.3030, Valid Loss: 0.3399
Model saved!
Accuracy: 0.8902
Precision: 0.8850
Recall: 0.8902
F1-score: 0.8854
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2055
Epoch 1/10, Batch 20/20, Loss: 1.2036
Epoch 1/10, Train Loss: 1.2806, Valid Loss: 0.9811
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8645
Epoch 2/10, Batch 20/20, Loss: 0.5998
Epoch 2/10, Train Loss: 0.8134, Valid Loss: 0.6856
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8330
Epoch 3/10, Batch 20/20, Loss: 0.9770
Epoch 3/10, Train Loss: 0.6332, Valid Loss: 0.5563
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4890
Epoch 4/10, Batch 20/20, Loss: 0.6256
Epoch 4/10, Train Loss: 0.5086, Valid Loss: 0.4757
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4619
Epoch 5/10, Batch 20/20, Loss: 0.6353
Epoch 5/10, Train Loss: 0.4428, Valid Loss: 0.4343
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5978
Epoch 6/10, Batch 20/20, Loss: 0.3354
Epoch 6/10, Train Loss: 0.3994, Valid Loss: 0.4012
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3173
Epoch 7/10, Batch 20/20, Loss: 0.4254
Epoch 7/10, Train Loss: 0.3521, Valid Loss: 0.3768
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4879
Epoch 8/10, Batch 20/20, Loss: 0.2917
Epoch 8/10, Train Loss: 0.3238, Valid Loss: 0.3645
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4233
Epoch 9/10, Batch 20/20, Loss: 0.6584
Epoch 9/10, Train Loss: 0.3037, Valid Loss: 0.3390
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2790
Epoch 10/10, Batch 20/20, Loss: 0.4441
Epoch 10/10, Train Loss: 0.2870, Valid Loss: 0.3280
Model saved!
Accuracy: 0.8937
Precision: 0.8897
Recall: 0.8937
F1-score: 0.8904
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3530
Epoch 1/10, Batch 20/20, Loss: 1.3835
Epoch 1/10, Train Loss: 1.3158, Valid Loss: 1.0871
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9715
Epoch 2/10, Batch 20/20, Loss: 0.8058
Epoch 2/10, Train Loss: 0.8642, Valid Loss: 0.7528
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.8838
Epoch 3/10, Batch 20/20, Loss: 1.0712
Epoch 3/10, Train Loss: 0.6830, Valid Loss: 0.6052
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4756
Epoch 4/10, Batch 20/20, Loss: 0.7103
Epoch 4/10, Train Loss: 0.5540, Valid Loss: 0.5454
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4640
Epoch 5/10, Batch 20/20, Loss: 0.6581
Epoch 5/10, Train Loss: 0.4897, Valid Loss: 0.4791
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5962
Epoch 6/10, Batch 20/20, Loss: 0.4506
Epoch 6/10, Train Loss: 0.4474, Valid Loss: 0.4397
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3859
Epoch 7/10, Batch 20/20, Loss: 0.3744
Epoch 7/10, Train Loss: 0.3919, Valid Loss: 0.4183
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5192
Epoch 8/10, Batch 20/20, Loss: 0.7233
Epoch 8/10, Train Loss: 0.3838, Valid Loss: 0.3909
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3866
Epoch 9/10, Batch 20/20, Loss: 0.6822
Epoch 9/10, Train Loss: 0.3474, Valid Loss: 0.3748
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3812
Epoch 10/10, Batch 20/20, Loss: 1.2054
Epoch 10/10, Train Loss: 0.3448, Valid Loss: 0.3832
Accuracy: 0.8902
Precision: 0.8858
Recall: 0.8902
F1-score: 0.8873
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1454
Epoch 1/10, Batch 20/20, Loss: 1.2884
Epoch 1/10, Train Loss: 1.2651, Valid Loss: 1.0177
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9000
Epoch 2/10, Batch 20/20, Loss: 0.6488
Epoch 2/10, Train Loss: 0.7875, Valid Loss: 0.7201
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7736
Epoch 3/10, Batch 20/20, Loss: 0.8183
Epoch 3/10, Train Loss: 0.6045, Valid Loss: 0.5944
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4023
Epoch 4/10, Batch 20/20, Loss: 0.5107
Epoch 4/10, Train Loss: 0.4875, Valid Loss: 0.5297
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3829
Epoch 5/10, Batch 20/20, Loss: 0.5230
Epoch 5/10, Train Loss: 0.4371, Valid Loss: 0.4831
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6568
Epoch 6/10, Batch 20/20, Loss: 0.4554
Epoch 6/10, Train Loss: 0.3872, Valid Loss: 0.4624
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4373
Epoch 7/10, Batch 20/20, Loss: 0.4357
Epoch 7/10, Train Loss: 0.3448, Valid Loss: 0.4291
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3505
Epoch 8/10, Batch 20/20, Loss: 0.3132
Epoch 8/10, Train Loss: 0.3143, Valid Loss: 0.4174
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3895
Epoch 9/10, Batch 20/20, Loss: 0.8163
Epoch 9/10, Train Loss: 0.3148, Valid Loss: 0.4047
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2625
Epoch 10/10, Batch 20/20, Loss: 0.6734
Epoch 10/10, Train Loss: 0.2858, Valid Loss: 0.4001
Model saved!
Accuracy: 0.8808
Precision: 0.8769
Recall: 0.8808
F1-score: 0.8769
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1888
Epoch 1/10, Batch 20/20, Loss: 1.2933
Epoch 1/10, Train Loss: 1.2863, Valid Loss: 1.0043
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9263
Epoch 2/10, Batch 20/20, Loss: 0.6435
Epoch 2/10, Train Loss: 0.8163, Valid Loss: 0.7090
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6770
Epoch 3/10, Batch 20/20, Loss: 0.8950
Epoch 3/10, Train Loss: 0.6361, Valid Loss: 0.5828
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4509
Epoch 4/10, Batch 20/20, Loss: 0.5397
Epoch 4/10, Train Loss: 0.5167, Valid Loss: 0.5175
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3328
Epoch 5/10, Batch 20/20, Loss: 0.6571
Epoch 5/10, Train Loss: 0.4513, Valid Loss: 0.4661
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6726
Epoch 6/10, Batch 20/20, Loss: 0.4626
Epoch 6/10, Train Loss: 0.3953, Valid Loss: 0.4360
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3589
Epoch 7/10, Batch 20/20, Loss: 0.7609
Epoch 7/10, Train Loss: 0.3666, Valid Loss: 0.4049
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3509
Epoch 8/10, Batch 20/20, Loss: 0.3760
Epoch 8/10, Train Loss: 0.3263, Valid Loss: 0.3935
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3342
Epoch 9/10, Batch 20/20, Loss: 0.7506
Epoch 9/10, Train Loss: 0.3225, Valid Loss: 0.3750
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2414
Epoch 10/10, Batch 20/20, Loss: 0.9006
Epoch 10/10, Train Loss: 0.3018, Valid Loss: 0.3675
Model saved!
Accuracy: 0.8820
Precision: 0.8790
Recall: 0.8820
F1-score: 0.8772
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3441
Epoch 1/10, Batch 20/20, Loss: 1.3257
Epoch 1/10, Train Loss: 1.2840, Valid Loss: 1.0553
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9687
Epoch 2/10, Batch 20/20, Loss: 0.7318
Epoch 2/10, Train Loss: 0.8119, Valid Loss: 0.7569
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6918
Epoch 3/10, Batch 20/20, Loss: 0.8726
Epoch 3/10, Train Loss: 0.6356, Valid Loss: 0.6204
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4377
Epoch 4/10, Batch 20/20, Loss: 0.3604
Epoch 4/10, Train Loss: 0.5105, Valid Loss: 0.5697
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4641
Epoch 5/10, Batch 20/20, Loss: 0.8172
Epoch 5/10, Train Loss: 0.4490, Valid Loss: 0.5191
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5999
Epoch 6/10, Batch 20/20, Loss: 0.5683
Epoch 6/10, Train Loss: 0.4009, Valid Loss: 0.4885
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4363
Epoch 7/10, Batch 20/20, Loss: 0.3545
Epoch 7/10, Train Loss: 0.3440, Valid Loss: 0.4816
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.5766
Epoch 8/10, Batch 20/20, Loss: 0.4468
Epoch 8/10, Train Loss: 0.3382, Valid Loss: 0.4624
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3447
Epoch 9/10, Batch 20/20, Loss: 0.3539
Epoch 9/10, Train Loss: 0.2879, Valid Loss: 0.4426
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3392
Epoch 10/10, Batch 20/20, Loss: 0.3986
Epoch 10/10, Train Loss: 0.2829, Valid Loss: 0.4442
Accuracy: 0.8914
Precision: 0.8869
Recall: 0.8914
F1-score: 0.8886
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2710
Epoch 1/10, Batch 20/20, Loss: 1.2328
Epoch 1/10, Train Loss: 1.2838, Valid Loss: 1.0951
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9026
Epoch 2/10, Batch 20/20, Loss: 0.7711
Epoch 2/10, Train Loss: 0.8151, Valid Loss: 0.7798
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7845
Epoch 3/10, Batch 20/20, Loss: 0.7921
Epoch 3/10, Train Loss: 0.6177, Valid Loss: 0.6453
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5310
Epoch 4/10, Batch 20/20, Loss: 0.5364
Epoch 4/10, Train Loss: 0.4874, Valid Loss: 0.5645
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3525
Epoch 5/10, Batch 20/20, Loss: 0.5135
Epoch 5/10, Train Loss: 0.4259, Valid Loss: 0.5154
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4997
Epoch 6/10, Batch 20/20, Loss: 0.2745
Epoch 6/10, Train Loss: 0.3794, Valid Loss: 0.4853
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2858
Epoch 7/10, Batch 20/20, Loss: 0.2724
Epoch 7/10, Train Loss: 0.3301, Valid Loss: 0.4596
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4513
Epoch 8/10, Batch 20/20, Loss: 0.2857
Epoch 8/10, Train Loss: 0.3080, Valid Loss: 0.4431
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2905
Epoch 9/10, Batch 20/20, Loss: 0.3414
Epoch 9/10, Train Loss: 0.2844, Valid Loss: 0.4193
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2476
Epoch 10/10, Batch 20/20, Loss: 0.4966
Epoch 10/10, Train Loss: 0.2692, Valid Loss: 0.4176
Model saved!
Accuracy: 0.8843
Precision: 0.8800
Recall: 0.8843
F1-score: 0.8803
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2263
Epoch 1/10, Batch 20/20, Loss: 1.3734
Epoch 1/10, Train Loss: 1.2954, Valid Loss: 1.0441
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9684
Epoch 2/10, Batch 20/20, Loss: 0.7241
Epoch 2/10, Train Loss: 0.8287, Valid Loss: 0.7219
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6999
Epoch 3/10, Batch 20/20, Loss: 1.1568
Epoch 3/10, Train Loss: 0.6536, Valid Loss: 0.5972
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4402
Epoch 4/10, Batch 20/20, Loss: 0.6954
Epoch 4/10, Train Loss: 0.5243, Valid Loss: 0.5137
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4397
Epoch 5/10, Batch 20/20, Loss: 0.8801
Epoch 5/10, Train Loss: 0.4519, Valid Loss: 0.4713
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4634
Epoch 6/10, Batch 20/20, Loss: 0.4389
Epoch 6/10, Train Loss: 0.3977, Valid Loss: 0.4423
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4030
Epoch 7/10, Batch 20/20, Loss: 0.5296
Epoch 7/10, Train Loss: 0.3609, Valid Loss: 0.4178
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4369
Epoch 8/10, Batch 20/20, Loss: 0.8721
Epoch 8/10, Train Loss: 0.3665, Valid Loss: 0.3994
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4202
Epoch 9/10, Batch 20/20, Loss: 0.8452
Epoch 9/10, Train Loss: 0.3250, Valid Loss: 0.3895
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3799
Epoch 10/10, Batch 20/20, Loss: 0.5604
Epoch 10/10, Train Loss: 0.2882, Valid Loss: 0.3762
Model saved!
Accuracy: 0.8902
Precision: 0.8862
Recall: 0.8902
F1-score: 0.8840
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2078
Epoch 1/10, Batch 20/20, Loss: 1.2742
Epoch 1/10, Train Loss: 1.2834, Valid Loss: 1.0855
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9207
Epoch 2/10, Batch 20/20, Loss: 0.5850
Epoch 2/10, Train Loss: 0.8219, Valid Loss: 0.7957
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7793
Epoch 3/10, Batch 20/20, Loss: 0.8205
Epoch 3/10, Train Loss: 0.6298, Valid Loss: 0.6718
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5002
Epoch 4/10, Batch 20/20, Loss: 0.6211
Epoch 4/10, Train Loss: 0.5174, Valid Loss: 0.5996
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4636
Epoch 5/10, Batch 20/20, Loss: 0.5947
Epoch 5/10, Train Loss: 0.4526, Valid Loss: 0.5574
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5019
Epoch 6/10, Batch 20/20, Loss: 0.3354
Epoch 6/10, Train Loss: 0.3794, Valid Loss: 0.5219
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3099
Epoch 7/10, Batch 20/20, Loss: 0.4233
Epoch 7/10, Train Loss: 0.3577, Valid Loss: 0.4919
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3643
Epoch 8/10, Batch 20/20, Loss: 0.3552
Epoch 8/10, Train Loss: 0.3351, Valid Loss: 0.4681
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.2798
Epoch 9/10, Batch 20/20, Loss: 0.5762
Epoch 9/10, Train Loss: 0.3068, Valid Loss: 0.4539
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.4135
Epoch 10/10, Batch 20/20, Loss: 0.3522
Epoch 10/10, Train Loss: 0.2722, Valid Loss: 0.4460
Model saved!
Accuracy: 0.8738
Precision: 0.8709
Recall: 0.8738
F1-score: 0.8701
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1768
Epoch 1/10, Batch 20/20, Loss: 1.3997
Epoch 1/10, Train Loss: 1.2898, Valid Loss: 1.0586
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9103
Epoch 2/10, Batch 20/20, Loss: 0.5635
Epoch 2/10, Train Loss: 0.8089, Valid Loss: 0.7667
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7585
Epoch 3/10, Batch 20/20, Loss: 0.7790
Epoch 3/10, Train Loss: 0.6199, Valid Loss: 0.6684
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5064
Epoch 4/10, Batch 20/20, Loss: 0.4811
Epoch 4/10, Train Loss: 0.4850, Valid Loss: 0.5970
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3933
Epoch 5/10, Batch 20/20, Loss: 0.7024
Epoch 5/10, Train Loss: 0.4436, Valid Loss: 0.5682
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6132
Epoch 6/10, Batch 20/20, Loss: 0.6072
Epoch 6/10, Train Loss: 0.3990, Valid Loss: 0.5293
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3261
Epoch 7/10, Batch 20/20, Loss: 0.4529
Epoch 7/10, Train Loss: 0.3469, Valid Loss: 0.5166
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3803
Epoch 8/10, Batch 20/20, Loss: 0.3042
Epoch 8/10, Train Loss: 0.3188, Valid Loss: 0.5061
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4133
Epoch 9/10, Batch 20/20, Loss: 0.5041
Epoch 9/10, Train Loss: 0.3111, Valid Loss: 0.4930
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3297
Epoch 10/10, Batch 20/20, Loss: 0.5649
Epoch 10/10, Train Loss: 0.2790, Valid Loss: 0.4899
Model saved!
Accuracy: 0.8855
Precision: 0.8823
Recall: 0.8855
F1-score: 0.8810
Memory Allocated after cleanup: 17.76 MB
End time: 2025-02-25 08:50:32.697865
Duration: 1:29:21


Mejor accuracy al acabar el algoritmo: 0.9007


Fitness check:

Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1730
Epoch 1/10, Batch 20/20, Loss: 1.2011
Epoch 1/10, Train Loss: 1.2768, Valid Loss: 1.0180
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9484
Epoch 2/10, Batch 20/20, Loss: 0.6975
Epoch 2/10, Train Loss: 0.8033, Valid Loss: 0.7141
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7881
Epoch 3/10, Batch 20/20, Loss: 0.7073
Epoch 3/10, Train Loss: 0.6231, Valid Loss: 0.5907
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4116
Epoch 4/10, Batch 20/20, Loss: 0.6600
Epoch 4/10, Train Loss: 0.5093, Valid Loss: 0.5171
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3860
Epoch 5/10, Batch 20/20, Loss: 0.7560
Epoch 5/10, Train Loss: 0.4490, Valid Loss: 0.4723
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6486
Epoch 6/10, Batch 20/20, Loss: 0.4655
Epoch 6/10, Train Loss: 0.3923, Valid Loss: 0.4327
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2851
Epoch 7/10, Batch 20/20, Loss: 0.3585
Epoch 7/10, Train Loss: 0.3342, Valid Loss: 0.4147
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4471
Epoch 8/10, Batch 20/20, Loss: 0.5153
Epoch 8/10, Train Loss: 0.3291, Valid Loss: 0.4061
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4145
Epoch 9/10, Batch 20/20, Loss: 0.7017
Epoch 9/10, Train Loss: 0.3128, Valid Loss: 0.3719
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2023
Epoch 10/10, Batch 20/20, Loss: 0.8638
Epoch 10/10, Train Loss: 0.2950, Valid Loss: 0.3822
Accuracy: 0.9007
Precision: 0.8967
Recall: 0.9007
F1-score: 0.8969
Memory Allocated after cleanup: 17.76 MB


Mejor accuracy encontrado: 0.9007


--------------------------------------mobilenet  BUSQUEDA LOCAL  25%-------------------------------------------------
Start time: 2025-02-25 08:51:26.504182
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2795
Epoch 1/10, Batch 20/49, Loss: 1.1004
Epoch 1/10, Batch 30/49, Loss: 0.8759
Epoch 1/10, Batch 40/49, Loss: 0.8277
Epoch 1/10, Train Loss: 1.0318, Valid Loss: 0.6517
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6034
Epoch 2/10, Batch 20/49, Loss: 0.7492
Epoch 2/10, Batch 30/49, Loss: 0.5079
Epoch 2/10, Batch 40/49, Loss: 0.4299
Epoch 2/10, Train Loss: 0.5696, Valid Loss: 0.4508
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5579
Epoch 3/10, Batch 20/49, Loss: 0.3376
Epoch 3/10, Batch 30/49, Loss: 0.4292
Epoch 3/10, Batch 40/49, Loss: 0.3682
Epoch 3/10, Train Loss: 0.4294, Valid Loss: 0.3888
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4180
Epoch 4/10, Batch 20/49, Loss: 0.4729
Epoch 4/10, Batch 30/49, Loss: 0.3217
Epoch 4/10, Batch 40/49, Loss: 0.4313
Epoch 4/10, Train Loss: 0.3886, Valid Loss: 0.3566
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3863
Epoch 5/10, Batch 20/49, Loss: 0.2760
Epoch 5/10, Batch 30/49, Loss: 0.2897
Epoch 5/10, Batch 40/49, Loss: 0.2183
Epoch 5/10, Train Loss: 0.3416, Valid Loss: 0.3257
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3222
Epoch 6/10, Batch 20/49, Loss: 0.1867
Epoch 6/10, Batch 30/49, Loss: 0.2133
Epoch 6/10, Batch 40/49, Loss: 0.2148
Epoch 6/10, Train Loss: 0.3081, Valid Loss: 0.2919
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1934
Epoch 7/10, Batch 20/49, Loss: 0.3305
Epoch 7/10, Batch 30/49, Loss: 0.3806
Epoch 7/10, Batch 40/49, Loss: 0.2437
Epoch 7/10, Train Loss: 0.2905, Valid Loss: 0.2828
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2958
Epoch 8/10, Batch 20/49, Loss: 0.2297
Epoch 8/10, Batch 30/49, Loss: 0.2570
Epoch 8/10, Batch 40/49, Loss: 0.3088
Epoch 8/10, Train Loss: 0.2736, Valid Loss: 0.2800
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2709
Epoch 9/10, Batch 20/49, Loss: 0.2287
Epoch 9/10, Batch 30/49, Loss: 0.3255
Epoch 9/10, Batch 40/49, Loss: 0.4891
Epoch 9/10, Train Loss: 0.2672, Valid Loss: 0.2777
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2919
Epoch 10/10, Batch 20/49, Loss: 0.1974
Epoch 10/10, Batch 30/49, Loss: 0.2790
Epoch 10/10, Batch 40/49, Loss: 0.2609
Epoch 10/10, Train Loss: 0.2416, Valid Loss: 0.2607
Model saved!
Accuracy: 0.9007
Precision: 0.8978
Recall: 0.9007
F1-score: 0.8984
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2197
Epoch 1/10, Batch 20/49, Loss: 1.1643
Epoch 1/10, Batch 30/49, Loss: 0.7636
Epoch 1/10, Batch 40/49, Loss: 0.7974
Epoch 1/10, Train Loss: 0.9993, Valid Loss: 0.6113
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5852
Epoch 2/10, Batch 20/49, Loss: 0.6929
Epoch 2/10, Batch 30/49, Loss: 0.4637
Epoch 2/10, Batch 40/49, Loss: 0.4435
Epoch 2/10, Train Loss: 0.5407, Valid Loss: 0.4231
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3422
Epoch 3/10, Batch 20/49, Loss: 0.3095
Epoch 3/10, Batch 30/49, Loss: 0.4111
Epoch 3/10, Batch 40/49, Loss: 0.3335
Epoch 3/10, Train Loss: 0.4181, Valid Loss: 0.3854
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4159
Epoch 4/10, Batch 20/49, Loss: 0.2802
Epoch 4/10, Batch 30/49, Loss: 0.3134
Epoch 4/10, Batch 40/49, Loss: 0.4183
Epoch 4/10, Train Loss: 0.3665, Valid Loss: 0.3299
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4882
Epoch 5/10, Batch 20/49, Loss: 0.1666
Epoch 5/10, Batch 30/49, Loss: 0.2304
Epoch 5/10, Batch 40/49, Loss: 0.2684
Epoch 5/10, Train Loss: 0.3306, Valid Loss: 0.3274
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2878
Epoch 6/10, Batch 20/49, Loss: 0.2378
Epoch 6/10, Batch 30/49, Loss: 0.2799
Epoch 6/10, Batch 40/49, Loss: 0.2473
Epoch 6/10, Train Loss: 0.2985, Valid Loss: 0.2967
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3299
Epoch 7/10, Batch 20/49, Loss: 0.3855
Epoch 7/10, Batch 30/49, Loss: 0.2224
Epoch 7/10, Batch 40/49, Loss: 0.1552
Epoch 7/10, Train Loss: 0.2690, Valid Loss: 0.2840
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3474
Epoch 8/10, Batch 20/49, Loss: 0.2214
Epoch 8/10, Batch 30/49, Loss: 0.2685
Epoch 8/10, Batch 40/49, Loss: 0.2190
Epoch 8/10, Train Loss: 0.2578, Valid Loss: 0.2886
Epoch 9/10, Batch 10/49, Loss: 0.2587
Epoch 9/10, Batch 20/49, Loss: 0.1090
Epoch 9/10, Batch 30/49, Loss: 0.2152
Epoch 9/10, Batch 40/49, Loss: 0.2635
Epoch 9/10, Train Loss: 0.2489, Valid Loss: 0.2722
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3172
Epoch 10/10, Batch 20/49, Loss: 0.1995
Epoch 10/10, Batch 30/49, Loss: 0.1648
Epoch 10/10, Batch 40/49, Loss: 0.2735
Epoch 10/10, Train Loss: 0.2250, Valid Loss: 0.2727
Accuracy: 0.9100
Precision: 0.9060
Recall: 0.9100
F1-score: 0.9070
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 2. Fitness: 0.9100
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2217
Epoch 1/10, Batch 20/49, Loss: 1.2778
Epoch 1/10, Batch 30/49, Loss: 0.8436
Epoch 1/10, Batch 40/49, Loss: 0.8530
Epoch 1/10, Train Loss: 0.9996, Valid Loss: 0.6373
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6287
Epoch 2/10, Batch 20/49, Loss: 0.6244
Epoch 2/10, Batch 30/49, Loss: 0.4793
Epoch 2/10, Batch 40/49, Loss: 0.5533
Epoch 2/10, Train Loss: 0.5453, Valid Loss: 0.4449
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4253
Epoch 3/10, Batch 20/49, Loss: 0.3299
Epoch 3/10, Batch 30/49, Loss: 0.4122
Epoch 3/10, Batch 40/49, Loss: 0.3380
Epoch 3/10, Train Loss: 0.4153, Valid Loss: 0.3882
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3573
Epoch 4/10, Batch 20/49, Loss: 0.3836
Epoch 4/10, Batch 30/49, Loss: 0.3766
Epoch 4/10, Batch 40/49, Loss: 0.4869
Epoch 4/10, Train Loss: 0.3688, Valid Loss: 0.3432
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4143
Epoch 5/10, Batch 20/49, Loss: 0.3835
Epoch 5/10, Batch 30/49, Loss: 0.2500
Epoch 5/10, Batch 40/49, Loss: 0.3943
Epoch 5/10, Train Loss: 0.3378, Valid Loss: 0.3109
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2746
Epoch 6/10, Batch 20/49, Loss: 0.1780
Epoch 6/10, Batch 30/49, Loss: 0.2491
Epoch 6/10, Batch 40/49, Loss: 0.1947
Epoch 6/10, Train Loss: 0.3043, Valid Loss: 0.3028
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3338
Epoch 7/10, Batch 20/49, Loss: 0.4004
Epoch 7/10, Batch 30/49, Loss: 0.2466
Epoch 7/10, Batch 40/49, Loss: 0.1307
Epoch 7/10, Train Loss: 0.2646, Valid Loss: 0.2980
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1963
Epoch 8/10, Batch 20/49, Loss: 0.1848
Epoch 8/10, Batch 30/49, Loss: 0.2819
Epoch 8/10, Batch 40/49, Loss: 0.1657
Epoch 8/10, Train Loss: 0.2634, Valid Loss: 0.2806
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2547
Epoch 9/10, Batch 20/49, Loss: 0.1996
Epoch 9/10, Batch 30/49, Loss: 0.2583
Epoch 9/10, Batch 40/49, Loss: 0.2746
Epoch 9/10, Train Loss: 0.2389, Valid Loss: 0.2784
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.4382
Epoch 10/10, Batch 20/49, Loss: 0.1917
Epoch 10/10, Batch 30/49, Loss: 0.3307
Epoch 10/10, Batch 40/49, Loss: 0.2244
Epoch 10/10, Train Loss: 0.2253, Valid Loss: 0.2668
Model saved!
Accuracy: 0.9019
Precision: 0.8992
Recall: 0.9019
F1-score: 0.8981
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2480
Epoch 1/10, Batch 20/49, Loss: 1.1940
Epoch 1/10, Batch 30/49, Loss: 0.8296
Epoch 1/10, Batch 40/49, Loss: 0.8204
Epoch 1/10, Train Loss: 1.0139, Valid Loss: 0.6035
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6205
Epoch 2/10, Batch 20/49, Loss: 0.6353
Epoch 2/10, Batch 30/49, Loss: 0.4888
Epoch 2/10, Batch 40/49, Loss: 0.4654
Epoch 2/10, Train Loss: 0.5514, Valid Loss: 0.4101
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3282
Epoch 3/10, Batch 20/49, Loss: 0.2441
Epoch 3/10, Batch 30/49, Loss: 0.4781
Epoch 3/10, Batch 40/49, Loss: 0.4904
Epoch 3/10, Train Loss: 0.4208, Valid Loss: 0.3463
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3062
Epoch 4/10, Batch 20/49, Loss: 0.4363
Epoch 4/10, Batch 30/49, Loss: 0.3539
Epoch 4/10, Batch 40/49, Loss: 0.3863
Epoch 4/10, Train Loss: 0.3740, Valid Loss: 0.3008
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3767
Epoch 5/10, Batch 20/49, Loss: 0.2466
Epoch 5/10, Batch 30/49, Loss: 0.2227
Epoch 5/10, Batch 40/49, Loss: 0.4424
Epoch 5/10, Train Loss: 0.3362, Valid Loss: 0.2800
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2658
Epoch 6/10, Batch 20/49, Loss: 0.1547
Epoch 6/10, Batch 30/49, Loss: 0.2983
Epoch 6/10, Batch 40/49, Loss: 0.3384
Epoch 6/10, Train Loss: 0.3032, Valid Loss: 0.2586
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2140
Epoch 7/10, Batch 20/49, Loss: 0.3817
Epoch 7/10, Batch 30/49, Loss: 0.1950
Epoch 7/10, Batch 40/49, Loss: 0.1750
Epoch 7/10, Train Loss: 0.2695, Valid Loss: 0.2563
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2870
Epoch 8/10, Batch 20/49, Loss: 0.1002
Epoch 8/10, Batch 30/49, Loss: 0.2387
Epoch 8/10, Batch 40/49, Loss: 0.3052
Epoch 8/10, Train Loss: 0.2664, Valid Loss: 0.2483
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1994
Epoch 9/10, Batch 20/49, Loss: 0.1914
Epoch 9/10, Batch 30/49, Loss: 0.3216
Epoch 9/10, Batch 40/49, Loss: 0.3340
Epoch 9/10, Train Loss: 0.2521, Valid Loss: 0.2331
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2293
Epoch 10/10, Batch 20/49, Loss: 0.2802
Epoch 10/10, Batch 30/49, Loss: 0.1650
Epoch 10/10, Batch 40/49, Loss: 0.1190
Epoch 10/10, Train Loss: 0.2246, Valid Loss: 0.2352
Accuracy: 0.9112
Precision: 0.9089
Recall: 0.9112
F1-score: 0.9096
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 4. Fitness: 0.9112
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1752
Epoch 1/10, Batch 20/49, Loss: 1.1032
Epoch 1/10, Batch 30/49, Loss: 0.8069
Epoch 1/10, Batch 40/49, Loss: 0.8458
Epoch 1/10, Train Loss: 1.0154, Valid Loss: 0.6368
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6255
Epoch 2/10, Batch 20/49, Loss: 0.6519
Epoch 2/10, Batch 30/49, Loss: 0.4545
Epoch 2/10, Batch 40/49, Loss: 0.4779
Epoch 2/10, Train Loss: 0.5510, Valid Loss: 0.4405
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4365
Epoch 3/10, Batch 20/49, Loss: 0.2728
Epoch 3/10, Batch 30/49, Loss: 0.5121
Epoch 3/10, Batch 40/49, Loss: 0.4821
Epoch 3/10, Train Loss: 0.4127, Valid Loss: 0.4067
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2579
Epoch 4/10, Batch 20/49, Loss: 0.5715
Epoch 4/10, Batch 30/49, Loss: 0.4348
Epoch 4/10, Batch 40/49, Loss: 0.3583
Epoch 4/10, Train Loss: 0.3712, Valid Loss: 0.3477
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3060
Epoch 5/10, Batch 20/49, Loss: 0.3825
Epoch 5/10, Batch 30/49, Loss: 0.2436
Epoch 5/10, Batch 40/49, Loss: 0.2728
Epoch 5/10, Train Loss: 0.3341, Valid Loss: 0.3219
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3631
Epoch 6/10, Batch 20/49, Loss: 0.2274
Epoch 6/10, Batch 30/49, Loss: 0.2340
Epoch 6/10, Batch 40/49, Loss: 0.3303
Epoch 6/10, Train Loss: 0.2989, Valid Loss: 0.3084
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2088
Epoch 7/10, Batch 20/49, Loss: 0.4151
Epoch 7/10, Batch 30/49, Loss: 0.3502
Epoch 7/10, Batch 40/49, Loss: 0.1838
Epoch 7/10, Train Loss: 0.2601, Valid Loss: 0.3250
Epoch 8/10, Batch 10/49, Loss: 0.2219
Epoch 8/10, Batch 20/49, Loss: 0.1585
Epoch 8/10, Batch 30/49, Loss: 0.2946
Epoch 8/10, Batch 40/49, Loss: 0.1550
Epoch 8/10, Train Loss: 0.2462, Valid Loss: 0.2947
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1768
Epoch 9/10, Batch 20/49, Loss: 0.1383
Epoch 9/10, Batch 30/49, Loss: 0.3025
Epoch 9/10, Batch 40/49, Loss: 0.2985
Epoch 9/10, Train Loss: 0.2284, Valid Loss: 0.2812
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2752
Epoch 10/10, Batch 20/49, Loss: 0.1101
Epoch 10/10, Batch 30/49, Loss: 0.2076
Epoch 10/10, Batch 40/49, Loss: 0.3056
Epoch 10/10, Train Loss: 0.2203, Valid Loss: 0.2927
Accuracy: 0.9065
Precision: 0.9029
Recall: 0.9065
F1-score: 0.9041
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2463
Epoch 1/10, Batch 20/49, Loss: 1.1105
Epoch 1/10, Batch 30/49, Loss: 0.8320
Epoch 1/10, Batch 40/49, Loss: 0.8003
Epoch 1/10, Train Loss: 1.0106, Valid Loss: 0.5910
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5158
Epoch 2/10, Batch 20/49, Loss: 0.6162
Epoch 2/10, Batch 30/49, Loss: 0.4605
Epoch 2/10, Batch 40/49, Loss: 0.4629
Epoch 2/10, Train Loss: 0.5286, Valid Loss: 0.4076
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5300
Epoch 3/10, Batch 20/49, Loss: 0.3266
Epoch 3/10, Batch 30/49, Loss: 0.4297
Epoch 3/10, Batch 40/49, Loss: 0.3135
Epoch 3/10, Train Loss: 0.3980, Valid Loss: 0.3494
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3657
Epoch 4/10, Batch 20/49, Loss: 0.3414
Epoch 4/10, Batch 30/49, Loss: 0.3964
Epoch 4/10, Batch 40/49, Loss: 0.4481
Epoch 4/10, Train Loss: 0.3468, Valid Loss: 0.2959
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4008
Epoch 5/10, Batch 20/49, Loss: 0.2664
Epoch 5/10, Batch 30/49, Loss: 0.2646
Epoch 5/10, Batch 40/49, Loss: 0.2710
Epoch 5/10, Train Loss: 0.3153, Valid Loss: 0.2856
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2304
Epoch 6/10, Batch 20/49, Loss: 0.1937
Epoch 6/10, Batch 30/49, Loss: 0.2134
Epoch 6/10, Batch 40/49, Loss: 0.2383
Epoch 6/10, Train Loss: 0.2750, Valid Loss: 0.2572
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1660
Epoch 7/10, Batch 20/49, Loss: 0.2428
Epoch 7/10, Batch 30/49, Loss: 0.3478
Epoch 7/10, Batch 40/49, Loss: 0.2716
Epoch 7/10, Train Loss: 0.2392, Valid Loss: 0.2615
Epoch 8/10, Batch 10/49, Loss: 0.1888
Epoch 8/10, Batch 20/49, Loss: 0.2479
Epoch 8/10, Batch 30/49, Loss: 0.1756
Epoch 8/10, Batch 40/49, Loss: 0.1993
Epoch 8/10, Train Loss: 0.2362, Valid Loss: 0.2493
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2895
Epoch 9/10, Batch 20/49, Loss: 0.2075
Epoch 9/10, Batch 30/49, Loss: 0.3599
Epoch 9/10, Batch 40/49, Loss: 0.3509
Epoch 9/10, Train Loss: 0.2202, Valid Loss: 0.2398
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2722
Epoch 10/10, Batch 20/49, Loss: 0.2339
Epoch 10/10, Batch 30/49, Loss: 0.1185
Epoch 10/10, Batch 40/49, Loss: 0.2248
Epoch 10/10, Train Loss: 0.2070, Valid Loss: 0.2298
Model saved!
Accuracy: 0.9007
Precision: 0.8964
Recall: 0.9007
F1-score: 0.8963
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2214
Epoch 1/10, Batch 20/49, Loss: 1.2301
Epoch 1/10, Batch 30/49, Loss: 0.8965
Epoch 1/10, Batch 40/49, Loss: 0.8600
Epoch 1/10, Train Loss: 1.0018, Valid Loss: 0.6341
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6088
Epoch 2/10, Batch 20/49, Loss: 0.6869
Epoch 2/10, Batch 30/49, Loss: 0.4920
Epoch 2/10, Batch 40/49, Loss: 0.3914
Epoch 2/10, Train Loss: 0.5352, Valid Loss: 0.4520
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3836
Epoch 3/10, Batch 20/49, Loss: 0.4147
Epoch 3/10, Batch 30/49, Loss: 0.4025
Epoch 3/10, Batch 40/49, Loss: 0.4045
Epoch 3/10, Train Loss: 0.4151, Valid Loss: 0.3928
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4024
Epoch 4/10, Batch 20/49, Loss: 0.3763
Epoch 4/10, Batch 30/49, Loss: 0.3220
Epoch 4/10, Batch 40/49, Loss: 0.5174
Epoch 4/10, Train Loss: 0.3517, Valid Loss: 0.3584
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3100
Epoch 5/10, Batch 20/49, Loss: 0.3221
Epoch 5/10, Batch 30/49, Loss: 0.2376
Epoch 5/10, Batch 40/49, Loss: 0.2933
Epoch 5/10, Train Loss: 0.3194, Valid Loss: 0.3217
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2564
Epoch 6/10, Batch 20/49, Loss: 0.2788
Epoch 6/10, Batch 30/49, Loss: 0.2499
Epoch 6/10, Batch 40/49, Loss: 0.1926
Epoch 6/10, Train Loss: 0.2966, Valid Loss: 0.2937
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2704
Epoch 7/10, Batch 20/49, Loss: 0.2502
Epoch 7/10, Batch 30/49, Loss: 0.3218
Epoch 7/10, Batch 40/49, Loss: 0.1795
Epoch 7/10, Train Loss: 0.2529, Valid Loss: 0.2989
Epoch 8/10, Batch 10/49, Loss: 0.3710
Epoch 8/10, Batch 20/49, Loss: 0.1331
Epoch 8/10, Batch 30/49, Loss: 0.2344
Epoch 8/10, Batch 40/49, Loss: 0.2559
Epoch 8/10, Train Loss: 0.2437, Valid Loss: 0.2815
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2195
Epoch 9/10, Batch 20/49, Loss: 0.1761
Epoch 9/10, Batch 30/49, Loss: 0.2009
Epoch 9/10, Batch 40/49, Loss: 0.2358
Epoch 9/10, Train Loss: 0.2328, Valid Loss: 0.2725
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2715
Epoch 10/10, Batch 20/49, Loss: 0.2082
Epoch 10/10, Batch 30/49, Loss: 0.2616
Epoch 10/10, Batch 40/49, Loss: 0.3188
Epoch 10/10, Train Loss: 0.2219, Valid Loss: 0.2620
Model saved!
Accuracy: 0.9030
Precision: 0.8998
Recall: 0.9030
F1-score: 0.9003
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2483
Epoch 1/10, Batch 20/49, Loss: 1.0936
Epoch 1/10, Batch 30/49, Loss: 0.8831
Epoch 1/10, Batch 40/49, Loss: 0.8333
Epoch 1/10, Train Loss: 1.0074, Valid Loss: 0.6214
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6146
Epoch 2/10, Batch 20/49, Loss: 0.6236
Epoch 2/10, Batch 30/49, Loss: 0.4129
Epoch 2/10, Batch 40/49, Loss: 0.3804
Epoch 2/10, Train Loss: 0.5564, Valid Loss: 0.4366
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3983
Epoch 3/10, Batch 20/49, Loss: 0.3037
Epoch 3/10, Batch 30/49, Loss: 0.4817
Epoch 3/10, Batch 40/49, Loss: 0.3308
Epoch 3/10, Train Loss: 0.4200, Valid Loss: 0.3793
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3992
Epoch 4/10, Batch 20/49, Loss: 0.3868
Epoch 4/10, Batch 30/49, Loss: 0.3530
Epoch 4/10, Batch 40/49, Loss: 0.4765
Epoch 4/10, Train Loss: 0.3648, Valid Loss: 0.3424
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4079
Epoch 5/10, Batch 20/49, Loss: 0.2358
Epoch 5/10, Batch 30/49, Loss: 0.2518
Epoch 5/10, Batch 40/49, Loss: 0.3081
Epoch 5/10, Train Loss: 0.3395, Valid Loss: 0.3211
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3575
Epoch 6/10, Batch 20/49, Loss: 0.2202
Epoch 6/10, Batch 30/49, Loss: 0.3348
Epoch 6/10, Batch 40/49, Loss: 0.2754
Epoch 6/10, Train Loss: 0.3086, Valid Loss: 0.3051
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1552
Epoch 7/10, Batch 20/49, Loss: 0.2606
Epoch 7/10, Batch 30/49, Loss: 0.2158
Epoch 7/10, Batch 40/49, Loss: 0.1589
Epoch 7/10, Train Loss: 0.2718, Valid Loss: 0.3150
Epoch 8/10, Batch 10/49, Loss: 0.3137
Epoch 8/10, Batch 20/49, Loss: 0.1711
Epoch 8/10, Batch 30/49, Loss: 0.3056
Epoch 8/10, Batch 40/49, Loss: 0.2923
Epoch 8/10, Train Loss: 0.2525, Valid Loss: 0.2966
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2185
Epoch 9/10, Batch 20/49, Loss: 0.2130
Epoch 9/10, Batch 30/49, Loss: 0.3535
Epoch 9/10, Batch 40/49, Loss: 0.3007
Epoch 9/10, Train Loss: 0.2569, Valid Loss: 0.2830
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2111
Epoch 10/10, Batch 20/49, Loss: 0.2217
Epoch 10/10, Batch 30/49, Loss: 0.2110
Epoch 10/10, Batch 40/49, Loss: 0.2332
Epoch 10/10, Train Loss: 0.2418, Valid Loss: 0.2823
Model saved!
Accuracy: 0.9100
Precision: 0.9079
Recall: 0.9100
F1-score: 0.9071
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1611
Epoch 1/10, Batch 20/49, Loss: 1.1567
Epoch 1/10, Batch 30/49, Loss: 0.8079
Epoch 1/10, Batch 40/49, Loss: 0.8397
Epoch 1/10, Train Loss: 1.0122, Valid Loss: 0.6340
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6649
Epoch 2/10, Batch 20/49, Loss: 0.5977
Epoch 2/10, Batch 30/49, Loss: 0.5175
Epoch 2/10, Batch 40/49, Loss: 0.4030
Epoch 2/10, Train Loss: 0.5511, Valid Loss: 0.4478
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3651
Epoch 3/10, Batch 20/49, Loss: 0.3605
Epoch 3/10, Batch 30/49, Loss: 0.4593
Epoch 3/10, Batch 40/49, Loss: 0.2832
Epoch 3/10, Train Loss: 0.4192, Valid Loss: 0.3927
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3439
Epoch 4/10, Batch 20/49, Loss: 0.4985
Epoch 4/10, Batch 30/49, Loss: 0.2701
Epoch 4/10, Batch 40/49, Loss: 0.3389
Epoch 4/10, Train Loss: 0.3687, Valid Loss: 0.3547
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4266
Epoch 5/10, Batch 20/49, Loss: 0.2865
Epoch 5/10, Batch 30/49, Loss: 0.2531
Epoch 5/10, Batch 40/49, Loss: 0.2710
Epoch 5/10, Train Loss: 0.3270, Valid Loss: 0.3306
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2257
Epoch 6/10, Batch 20/49, Loss: 0.1963
Epoch 6/10, Batch 30/49, Loss: 0.1938
Epoch 6/10, Batch 40/49, Loss: 0.4957
Epoch 6/10, Train Loss: 0.2998, Valid Loss: 0.3132
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2141
Epoch 7/10, Batch 20/49, Loss: 0.1965
Epoch 7/10, Batch 30/49, Loss: 0.2234
Epoch 7/10, Batch 40/49, Loss: 0.3154
Epoch 7/10, Train Loss: 0.2655, Valid Loss: 0.3077
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2881
Epoch 8/10, Batch 20/49, Loss: 0.1597
Epoch 8/10, Batch 30/49, Loss: 0.2174
Epoch 8/10, Batch 40/49, Loss: 0.3277
Epoch 8/10, Train Loss: 0.2500, Valid Loss: 0.3010
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2740
Epoch 9/10, Batch 20/49, Loss: 0.1742
Epoch 9/10, Batch 30/49, Loss: 0.5254
Epoch 9/10, Batch 40/49, Loss: 0.3286
Epoch 9/10, Train Loss: 0.2399, Valid Loss: 0.2889
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2967
Epoch 10/10, Batch 20/49, Loss: 0.1615
Epoch 10/10, Batch 30/49, Loss: 0.1629
Epoch 10/10, Batch 40/49, Loss: 0.2209
Epoch 10/10, Train Loss: 0.2282, Valid Loss: 0.2847
Model saved!
Accuracy: 0.9042
Precision: 0.9010
Recall: 0.9042
F1-score: 0.9020
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2779
Epoch 1/10, Batch 20/49, Loss: 1.2005
Epoch 1/10, Batch 30/49, Loss: 0.9560
Epoch 1/10, Batch 40/49, Loss: 0.7675
Epoch 1/10, Train Loss: 1.0059, Valid Loss: 0.5963
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5311
Epoch 2/10, Batch 20/49, Loss: 0.6561
Epoch 2/10, Batch 30/49, Loss: 0.4692
Epoch 2/10, Batch 40/49, Loss: 0.3572
Epoch 2/10, Train Loss: 0.5499, Valid Loss: 0.4216
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4038
Epoch 3/10, Batch 20/49, Loss: 0.3622
Epoch 3/10, Batch 30/49, Loss: 0.4057
Epoch 3/10, Batch 40/49, Loss: 0.3901
Epoch 3/10, Train Loss: 0.4135, Valid Loss: 0.3682
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4000
Epoch 4/10, Batch 20/49, Loss: 0.3465
Epoch 4/10, Batch 30/49, Loss: 0.2540
Epoch 4/10, Batch 40/49, Loss: 0.4750
Epoch 4/10, Train Loss: 0.3643, Valid Loss: 0.3179
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5327
Epoch 5/10, Batch 20/49, Loss: 0.1723
Epoch 5/10, Batch 30/49, Loss: 0.1977
Epoch 5/10, Batch 40/49, Loss: 0.3415
Epoch 5/10, Train Loss: 0.3178, Valid Loss: 0.2829
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2904
Epoch 6/10, Batch 20/49, Loss: 0.2479
Epoch 6/10, Batch 30/49, Loss: 0.1823
Epoch 6/10, Batch 40/49, Loss: 0.2653
Epoch 6/10, Train Loss: 0.3043, Valid Loss: 0.2798
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1108
Epoch 7/10, Batch 20/49, Loss: 0.2511
Epoch 7/10, Batch 30/49, Loss: 0.1588
Epoch 7/10, Batch 40/49, Loss: 0.1539
Epoch 7/10, Train Loss: 0.2599, Valid Loss: 0.2698
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2299
Epoch 8/10, Batch 20/49, Loss: 0.1622
Epoch 8/10, Batch 30/49, Loss: 0.2581
Epoch 8/10, Batch 40/49, Loss: 0.1352
Epoch 8/10, Train Loss: 0.2485, Valid Loss: 0.2607
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2472
Epoch 9/10, Batch 20/49, Loss: 0.1847
Epoch 9/10, Batch 30/49, Loss: 0.2267
Epoch 9/10, Batch 40/49, Loss: 0.3183
Epoch 9/10, Train Loss: 0.2266, Valid Loss: 0.2493
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2260
Epoch 10/10, Batch 20/49, Loss: 0.2030
Epoch 10/10, Batch 30/49, Loss: 0.2222
Epoch 10/10, Batch 40/49, Loss: 0.2838
Epoch 10/10, Train Loss: 0.2076, Valid Loss: 0.2458
Model saved!
Accuracy: 0.9065
Precision: 0.9048
Recall: 0.9065
F1-score: 0.9017
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2541
Epoch 1/10, Batch 20/49, Loss: 1.1321
Epoch 1/10, Batch 30/49, Loss: 0.7637
Epoch 1/10, Batch 40/49, Loss: 0.7418
Epoch 1/10, Train Loss: 1.0023, Valid Loss: 0.6014
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6275
Epoch 2/10, Batch 20/49, Loss: 0.6017
Epoch 2/10, Batch 30/49, Loss: 0.4264
Epoch 2/10, Batch 40/49, Loss: 0.4276
Epoch 2/10, Train Loss: 0.5312, Valid Loss: 0.4027
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4155
Epoch 3/10, Batch 20/49, Loss: 0.2913
Epoch 3/10, Batch 30/49, Loss: 0.3941
Epoch 3/10, Batch 40/49, Loss: 0.3571
Epoch 3/10, Train Loss: 0.3908, Valid Loss: 0.3572
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3096
Epoch 4/10, Batch 20/49, Loss: 0.2555
Epoch 4/10, Batch 30/49, Loss: 0.3226
Epoch 4/10, Batch 40/49, Loss: 0.3795
Epoch 4/10, Train Loss: 0.3509, Valid Loss: 0.3163
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2430
Epoch 5/10, Batch 20/49, Loss: 0.2545
Epoch 5/10, Batch 30/49, Loss: 0.1561
Epoch 5/10, Batch 40/49, Loss: 0.2441
Epoch 5/10, Train Loss: 0.2964, Valid Loss: 0.2937
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2332
Epoch 6/10, Batch 20/49, Loss: 0.2794
Epoch 6/10, Batch 30/49, Loss: 0.1995
Epoch 6/10, Batch 40/49, Loss: 0.2955
Epoch 6/10, Train Loss: 0.2740, Valid Loss: 0.2806
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1332
Epoch 7/10, Batch 20/49, Loss: 0.2601
Epoch 7/10, Batch 30/49, Loss: 0.1955
Epoch 7/10, Batch 40/49, Loss: 0.1811
Epoch 7/10, Train Loss: 0.2447, Valid Loss: 0.2801
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2371
Epoch 8/10, Batch 20/49, Loss: 0.1828
Epoch 8/10, Batch 30/49, Loss: 0.1456
Epoch 8/10, Batch 40/49, Loss: 0.1950
Epoch 8/10, Train Loss: 0.2451, Valid Loss: 0.2808
Epoch 9/10, Batch 10/49, Loss: 0.1264
Epoch 9/10, Batch 20/49, Loss: 0.1594
Epoch 9/10, Batch 30/49, Loss: 0.2787
Epoch 9/10, Batch 40/49, Loss: 0.3266
Epoch 9/10, Train Loss: 0.2183, Valid Loss: 0.2669
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1917
Epoch 10/10, Batch 20/49, Loss: 0.2765
Epoch 10/10, Batch 30/49, Loss: 0.1400
Epoch 10/10, Batch 40/49, Loss: 0.2058
Epoch 10/10, Train Loss: 0.2064, Valid Loss: 0.2627
Model saved!
Accuracy: 0.9054
Precision: 0.9032
Recall: 0.9054
F1-score: 0.9037
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1962
Epoch 1/10, Batch 20/49, Loss: 1.1602
Epoch 1/10, Batch 30/49, Loss: 0.8824
Epoch 1/10, Batch 40/49, Loss: 0.9226
Epoch 1/10, Train Loss: 1.0192, Valid Loss: 0.6161
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5649
Epoch 2/10, Batch 20/49, Loss: 0.6620
Epoch 2/10, Batch 30/49, Loss: 0.4781
Epoch 2/10, Batch 40/49, Loss: 0.4190
Epoch 2/10, Train Loss: 0.5511, Valid Loss: 0.4340
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4131
Epoch 3/10, Batch 20/49, Loss: 0.2587
Epoch 3/10, Batch 30/49, Loss: 0.4834
Epoch 3/10, Batch 40/49, Loss: 0.3856
Epoch 3/10, Train Loss: 0.4184, Valid Loss: 0.3865
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4073
Epoch 4/10, Batch 20/49, Loss: 0.3318
Epoch 4/10, Batch 30/49, Loss: 0.4901
Epoch 4/10, Batch 40/49, Loss: 0.2791
Epoch 4/10, Train Loss: 0.3742, Valid Loss: 0.3277
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3608
Epoch 5/10, Batch 20/49, Loss: 0.3076
Epoch 5/10, Batch 30/49, Loss: 0.3380
Epoch 5/10, Batch 40/49, Loss: 0.1711
Epoch 5/10, Train Loss: 0.3302, Valid Loss: 0.3088
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2356
Epoch 6/10, Batch 20/49, Loss: 0.1453
Epoch 6/10, Batch 30/49, Loss: 0.2511
Epoch 6/10, Batch 40/49, Loss: 0.3419
Epoch 6/10, Train Loss: 0.3000, Valid Loss: 0.2926
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2891
Epoch 7/10, Batch 20/49, Loss: 0.2328
Epoch 7/10, Batch 30/49, Loss: 0.1826
Epoch 7/10, Batch 40/49, Loss: 0.1428
Epoch 7/10, Train Loss: 0.2653, Valid Loss: 0.2838
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3098
Epoch 8/10, Batch 20/49, Loss: 0.1892
Epoch 8/10, Batch 30/49, Loss: 0.1293
Epoch 8/10, Batch 40/49, Loss: 0.2677
Epoch 8/10, Train Loss: 0.2653, Valid Loss: 0.2785
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2929
Epoch 9/10, Batch 20/49, Loss: 0.2452
Epoch 9/10, Batch 30/49, Loss: 0.3451
Epoch 9/10, Batch 40/49, Loss: 0.2239
Epoch 9/10, Train Loss: 0.2506, Valid Loss: 0.2595
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2797
Epoch 10/10, Batch 20/49, Loss: 0.1872
Epoch 10/10, Batch 30/49, Loss: 0.1397
Epoch 10/10, Batch 40/49, Loss: 0.1638
Epoch 10/10, Train Loss: 0.2178, Valid Loss: 0.2648
Accuracy: 0.9065
Precision: 0.9023
Recall: 0.9065
F1-score: 0.9034
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3156
Epoch 1/10, Batch 20/49, Loss: 1.0887
Epoch 1/10, Batch 30/49, Loss: 0.8097
Epoch 1/10, Batch 40/49, Loss: 0.7556
Epoch 1/10, Train Loss: 1.0189, Valid Loss: 0.6069
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5534
Epoch 2/10, Batch 20/49, Loss: 0.5556
Epoch 2/10, Batch 30/49, Loss: 0.5389
Epoch 2/10, Batch 40/49, Loss: 0.4218
Epoch 2/10, Train Loss: 0.5558, Valid Loss: 0.4276
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4092
Epoch 3/10, Batch 20/49, Loss: 0.4093
Epoch 3/10, Batch 30/49, Loss: 0.4366
Epoch 3/10, Batch 40/49, Loss: 0.3935
Epoch 3/10, Train Loss: 0.4235, Valid Loss: 0.3706
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3153
Epoch 4/10, Batch 20/49, Loss: 0.3853
Epoch 4/10, Batch 30/49, Loss: 0.3897
Epoch 4/10, Batch 40/49, Loss: 0.3702
Epoch 4/10, Train Loss: 0.3709, Valid Loss: 0.3318
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3427
Epoch 5/10, Batch 20/49, Loss: 0.3035
Epoch 5/10, Batch 30/49, Loss: 0.4904
Epoch 5/10, Batch 40/49, Loss: 0.2809
Epoch 5/10, Train Loss: 0.3357, Valid Loss: 0.3131
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2735
Epoch 6/10, Batch 20/49, Loss: 0.3640
Epoch 6/10, Batch 30/49, Loss: 0.3000
Epoch 6/10, Batch 40/49, Loss: 0.3137
Epoch 6/10, Train Loss: 0.2986, Valid Loss: 0.2758
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2597
Epoch 7/10, Batch 20/49, Loss: 0.2895
Epoch 7/10, Batch 30/49, Loss: 0.2760
Epoch 7/10, Batch 40/49, Loss: 0.2700
Epoch 7/10, Train Loss: 0.2624, Valid Loss: 0.2870
Epoch 8/10, Batch 10/49, Loss: 0.2362
Epoch 8/10, Batch 20/49, Loss: 0.1797
Epoch 8/10, Batch 30/49, Loss: 0.1849
Epoch 8/10, Batch 40/49, Loss: 0.2830
Epoch 8/10, Train Loss: 0.2729, Valid Loss: 0.2787
Epoch 9/10, Batch 10/49, Loss: 0.4036
Epoch 9/10, Batch 20/49, Loss: 0.0999
Epoch 9/10, Batch 30/49, Loss: 0.2608
Epoch 9/10, Batch 40/49, Loss: 0.3338
Epoch 9/10, Train Loss: 0.2498, Valid Loss: 0.2704
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2211
Epoch 10/10, Batch 20/49, Loss: 0.1992
Epoch 10/10, Batch 30/49, Loss: 0.3107
Epoch 10/10, Batch 40/49, Loss: 0.2153
Epoch 10/10, Train Loss: 0.2208, Valid Loss: 0.2536
Model saved!
Accuracy: 0.8995
Precision: 0.8971
Recall: 0.8995
F1-score: 0.8970
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2764
Epoch 1/10, Batch 20/49, Loss: 1.0478
Epoch 1/10, Batch 30/49, Loss: 0.7982
Epoch 1/10, Batch 40/49, Loss: 0.8881
Epoch 1/10, Train Loss: 1.0153, Valid Loss: 0.6097
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6556
Epoch 2/10, Batch 20/49, Loss: 0.8223
Epoch 2/10, Batch 30/49, Loss: 0.5553
Epoch 2/10, Batch 40/49, Loss: 0.4318
Epoch 2/10, Train Loss: 0.5627, Valid Loss: 0.4033
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4666
Epoch 3/10, Batch 20/49, Loss: 0.5095
Epoch 3/10, Batch 30/49, Loss: 0.4588
Epoch 3/10, Batch 40/49, Loss: 0.4943
Epoch 3/10, Train Loss: 0.4290, Valid Loss: 0.3408
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4127
Epoch 4/10, Batch 20/49, Loss: 0.5169
Epoch 4/10, Batch 30/49, Loss: 0.3387
Epoch 4/10, Batch 40/49, Loss: 0.3557
Epoch 4/10, Train Loss: 0.3892, Valid Loss: 0.3075
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2879
Epoch 5/10, Batch 20/49, Loss: 0.2378
Epoch 5/10, Batch 30/49, Loss: 0.4387
Epoch 5/10, Batch 40/49, Loss: 0.4977
Epoch 5/10, Train Loss: 0.3375, Valid Loss: 0.2803
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.4054
Epoch 6/10, Batch 20/49, Loss: 0.2245
Epoch 6/10, Batch 30/49, Loss: 0.2250
Epoch 6/10, Batch 40/49, Loss: 0.2288
Epoch 6/10, Train Loss: 0.3013, Valid Loss: 0.2552
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2767
Epoch 7/10, Batch 20/49, Loss: 0.3823
Epoch 7/10, Batch 30/49, Loss: 0.2301
Epoch 7/10, Batch 40/49, Loss: 0.1520
Epoch 7/10, Train Loss: 0.2718, Valid Loss: 0.2531
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.4218
Epoch 8/10, Batch 20/49, Loss: 0.1587
Epoch 8/10, Batch 30/49, Loss: 0.3103
Epoch 8/10, Batch 40/49, Loss: 0.1783
Epoch 8/10, Train Loss: 0.2709, Valid Loss: 0.2409
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2008
Epoch 9/10, Batch 20/49, Loss: 0.1927
Epoch 9/10, Batch 30/49, Loss: 0.3381
Epoch 9/10, Batch 40/49, Loss: 0.3103
Epoch 9/10, Train Loss: 0.2571, Valid Loss: 0.2342
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2148
Epoch 10/10, Batch 20/49, Loss: 0.2013
Epoch 10/10, Batch 30/49, Loss: 0.2170
Epoch 10/10, Batch 40/49, Loss: 0.1962
Epoch 10/10, Train Loss: 0.2338, Valid Loss: 0.2287
Model saved!
Accuracy: 0.9054
Precision: 0.9011
Recall: 0.9054
F1-score: 0.9020
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2263
Epoch 1/10, Batch 20/49, Loss: 1.1622
Epoch 1/10, Batch 30/49, Loss: 0.7265
Epoch 1/10, Batch 40/49, Loss: 0.8317
Epoch 1/10, Train Loss: 1.0190, Valid Loss: 0.6177
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6596
Epoch 2/10, Batch 20/49, Loss: 0.6682
Epoch 2/10, Batch 30/49, Loss: 0.4970
Epoch 2/10, Batch 40/49, Loss: 0.4564
Epoch 2/10, Train Loss: 0.5636, Valid Loss: 0.4386
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3602
Epoch 3/10, Batch 20/49, Loss: 0.3240
Epoch 3/10, Batch 30/49, Loss: 0.4338
Epoch 3/10, Batch 40/49, Loss: 0.4457
Epoch 3/10, Train Loss: 0.4179, Valid Loss: 0.3745
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2490
Epoch 4/10, Batch 20/49, Loss: 0.3381
Epoch 4/10, Batch 30/49, Loss: 0.3289
Epoch 4/10, Batch 40/49, Loss: 0.4455
Epoch 4/10, Train Loss: 0.3816, Valid Loss: 0.3365
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4416
Epoch 5/10, Batch 20/49, Loss: 0.3134
Epoch 5/10, Batch 30/49, Loss: 0.3213
Epoch 5/10, Batch 40/49, Loss: 0.2287
Epoch 5/10, Train Loss: 0.3301, Valid Loss: 0.3077
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2984
Epoch 6/10, Batch 20/49, Loss: 0.2912
Epoch 6/10, Batch 30/49, Loss: 0.2409
Epoch 6/10, Batch 40/49, Loss: 0.3481
Epoch 6/10, Train Loss: 0.3081, Valid Loss: 0.2922
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2746
Epoch 7/10, Batch 20/49, Loss: 0.3111
Epoch 7/10, Batch 30/49, Loss: 0.2997
Epoch 7/10, Batch 40/49, Loss: 0.1235
Epoch 7/10, Train Loss: 0.2723, Valid Loss: 0.2857
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3925
Epoch 8/10, Batch 20/49, Loss: 0.1737
Epoch 8/10, Batch 30/49, Loss: 0.2429
Epoch 8/10, Batch 40/49, Loss: 0.1903
Epoch 8/10, Train Loss: 0.2708, Valid Loss: 0.2768
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3337
Epoch 9/10, Batch 20/49, Loss: 0.2282
Epoch 9/10, Batch 30/49, Loss: 0.2028
Epoch 9/10, Batch 40/49, Loss: 0.3287
Epoch 9/10, Train Loss: 0.2524, Valid Loss: 0.2672
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1873
Epoch 10/10, Batch 20/49, Loss: 0.2119
Epoch 10/10, Batch 30/49, Loss: 0.2938
Epoch 10/10, Batch 40/49, Loss: 0.1781
Epoch 10/10, Train Loss: 0.2297, Valid Loss: 0.2598
Model saved!
Accuracy: 0.8995
Precision: 0.8946
Recall: 0.8995
F1-score: 0.8957
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2068
Epoch 1/10, Batch 20/49, Loss: 1.1108
Epoch 1/10, Batch 30/49, Loss: 0.8840
Epoch 1/10, Batch 40/49, Loss: 0.7207
Epoch 1/10, Train Loss: 1.0207, Valid Loss: 0.5946
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5985
Epoch 2/10, Batch 20/49, Loss: 0.6055
Epoch 2/10, Batch 30/49, Loss: 0.7223
Epoch 2/10, Batch 40/49, Loss: 0.5700
Epoch 2/10, Train Loss: 0.5575, Valid Loss: 0.3964
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4665
Epoch 3/10, Batch 20/49, Loss: 0.3385
Epoch 3/10, Batch 30/49, Loss: 0.4019
Epoch 3/10, Batch 40/49, Loss: 0.3303
Epoch 3/10, Train Loss: 0.4206, Valid Loss: 0.3271
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4292
Epoch 4/10, Batch 20/49, Loss: 0.3309
Epoch 4/10, Batch 30/49, Loss: 0.3931
Epoch 4/10, Batch 40/49, Loss: 0.4220
Epoch 4/10, Train Loss: 0.3674, Valid Loss: 0.2903
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4300
Epoch 5/10, Batch 20/49, Loss: 0.1952
Epoch 5/10, Batch 30/49, Loss: 0.3493
Epoch 5/10, Batch 40/49, Loss: 0.3096
Epoch 5/10, Train Loss: 0.3459, Valid Loss: 0.2703
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3970
Epoch 6/10, Batch 20/49, Loss: 0.2120
Epoch 6/10, Batch 30/49, Loss: 0.2570
Epoch 6/10, Batch 40/49, Loss: 0.3180
Epoch 6/10, Train Loss: 0.3005, Valid Loss: 0.2522
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3079
Epoch 7/10, Batch 20/49, Loss: 0.3844
Epoch 7/10, Batch 30/49, Loss: 0.2157
Epoch 7/10, Batch 40/49, Loss: 0.0924
Epoch 7/10, Train Loss: 0.2677, Valid Loss: 0.2488
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3269
Epoch 8/10, Batch 20/49, Loss: 0.1952
Epoch 8/10, Batch 30/49, Loss: 0.2824
Epoch 8/10, Batch 40/49, Loss: 0.1773
Epoch 8/10, Train Loss: 0.2685, Valid Loss: 0.2375
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2859
Epoch 9/10, Batch 20/49, Loss: 0.1863
Epoch 9/10, Batch 30/49, Loss: 0.2549
Epoch 9/10, Batch 40/49, Loss: 0.3178
Epoch 9/10, Train Loss: 0.2434, Valid Loss: 0.2272
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3175
Epoch 10/10, Batch 20/49, Loss: 0.1978
Epoch 10/10, Batch 30/49, Loss: 0.1646
Epoch 10/10, Batch 40/49, Loss: 0.2422
Epoch 10/10, Train Loss: 0.2247, Valid Loss: 0.2322
Accuracy: 0.9065
Precision: 0.9026
Recall: 0.9065
F1-score: 0.9033
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2676
Epoch 1/10, Batch 20/49, Loss: 1.0606
Epoch 1/10, Batch 30/49, Loss: 0.9019
Epoch 1/10, Batch 40/49, Loss: 0.9292
Epoch 1/10, Train Loss: 1.0228, Valid Loss: 0.6078
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6487
Epoch 2/10, Batch 20/49, Loss: 0.7658
Epoch 2/10, Batch 30/49, Loss: 0.5546
Epoch 2/10, Batch 40/49, Loss: 0.4692
Epoch 2/10, Train Loss: 0.5560, Valid Loss: 0.4124
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4227
Epoch 3/10, Batch 20/49, Loss: 0.4392
Epoch 3/10, Batch 30/49, Loss: 0.4047
Epoch 3/10, Batch 40/49, Loss: 0.3366
Epoch 3/10, Train Loss: 0.4182, Valid Loss: 0.3572
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3517
Epoch 4/10, Batch 20/49, Loss: 0.4238
Epoch 4/10, Batch 30/49, Loss: 0.3817
Epoch 4/10, Batch 40/49, Loss: 0.5781
Epoch 4/10, Train Loss: 0.3813, Valid Loss: 0.3022
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3414
Epoch 5/10, Batch 20/49, Loss: 0.3313
Epoch 5/10, Batch 30/49, Loss: 0.3281
Epoch 5/10, Batch 40/49, Loss: 0.2176
Epoch 5/10, Train Loss: 0.3253, Valid Loss: 0.2672
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.4083
Epoch 6/10, Batch 20/49, Loss: 0.2296
Epoch 6/10, Batch 30/49, Loss: 0.2379
Epoch 6/10, Batch 40/49, Loss: 0.3542
Epoch 6/10, Train Loss: 0.2934, Valid Loss: 0.2534
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3233
Epoch 7/10, Batch 20/49, Loss: 0.3179
Epoch 7/10, Batch 30/49, Loss: 0.2773
Epoch 7/10, Batch 40/49, Loss: 0.1765
Epoch 7/10, Train Loss: 0.2649, Valid Loss: 0.2467
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2931
Epoch 8/10, Batch 20/49, Loss: 0.1012
Epoch 8/10, Batch 30/49, Loss: 0.3208
Epoch 8/10, Batch 40/49, Loss: 0.1997
Epoch 8/10, Train Loss: 0.2555, Valid Loss: 0.2400
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1711
Epoch 9/10, Batch 20/49, Loss: 0.1704
Epoch 9/10, Batch 30/49, Loss: 0.3120
Epoch 9/10, Batch 40/49, Loss: 0.2661
Epoch 9/10, Train Loss: 0.2406, Valid Loss: 0.2163
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2728
Epoch 10/10, Batch 20/49, Loss: 0.2985
Epoch 10/10, Batch 30/49, Loss: 0.2958
Epoch 10/10, Batch 40/49, Loss: 0.1220
Epoch 10/10, Train Loss: 0.2270, Valid Loss: 0.2163
Model saved!
Accuracy: 0.9100
Precision: 0.9068
Recall: 0.9100
F1-score: 0.9074
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2332
Epoch 1/10, Batch 20/49, Loss: 1.1168
Epoch 1/10, Batch 30/49, Loss: 0.9116
Epoch 1/10, Batch 40/49, Loss: 0.8307
Epoch 1/10, Train Loss: 1.0168, Valid Loss: 0.6315
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5465
Epoch 2/10, Batch 20/49, Loss: 0.6544
Epoch 2/10, Batch 30/49, Loss: 0.5802
Epoch 2/10, Batch 40/49, Loss: 0.4126
Epoch 2/10, Train Loss: 0.5556, Valid Loss: 0.4377
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4041
Epoch 3/10, Batch 20/49, Loss: 0.3758
Epoch 3/10, Batch 30/49, Loss: 0.4596
Epoch 3/10, Batch 40/49, Loss: 0.3840
Epoch 3/10, Train Loss: 0.4172, Valid Loss: 0.3695
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3054
Epoch 4/10, Batch 20/49, Loss: 0.5393
Epoch 4/10, Batch 30/49, Loss: 0.3062
Epoch 4/10, Batch 40/49, Loss: 0.3542
Epoch 4/10, Train Loss: 0.3655, Valid Loss: 0.3315
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3987
Epoch 5/10, Batch 20/49, Loss: 0.4072
Epoch 5/10, Batch 30/49, Loss: 0.2045
Epoch 5/10, Batch 40/49, Loss: 0.3884
Epoch 5/10, Train Loss: 0.3206, Valid Loss: 0.3091
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3231
Epoch 6/10, Batch 20/49, Loss: 0.1789
Epoch 6/10, Batch 30/49, Loss: 0.2797
Epoch 6/10, Batch 40/49, Loss: 0.1572
Epoch 6/10, Train Loss: 0.3014, Valid Loss: 0.2922
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1573
Epoch 7/10, Batch 20/49, Loss: 0.2301
Epoch 7/10, Batch 30/49, Loss: 0.3994
Epoch 7/10, Batch 40/49, Loss: 0.2176
Epoch 7/10, Train Loss: 0.2490, Valid Loss: 0.2884
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2404
Epoch 8/10, Batch 20/49, Loss: 0.1296
Epoch 8/10, Batch 30/49, Loss: 0.3864
Epoch 8/10, Batch 40/49, Loss: 0.1599
Epoch 8/10, Train Loss: 0.2666, Valid Loss: 0.2763
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1911
Epoch 9/10, Batch 20/49, Loss: 0.1371
Epoch 9/10, Batch 30/49, Loss: 0.2971
Epoch 9/10, Batch 40/49, Loss: 0.2196
Epoch 9/10, Train Loss: 0.2414, Valid Loss: 0.2607
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2113
Epoch 10/10, Batch 20/49, Loss: 0.2213
Epoch 10/10, Batch 30/49, Loss: 0.1494
Epoch 10/10, Batch 40/49, Loss: 0.2297
Epoch 10/10, Train Loss: 0.2139, Valid Loss: 0.2613
Accuracy: 0.9030
Precision: 0.9000
Recall: 0.9030
F1-score: 0.9008
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2451
Epoch 1/10, Batch 20/49, Loss: 1.1717
Epoch 1/10, Batch 30/49, Loss: 0.8619
Epoch 1/10, Batch 40/49, Loss: 0.8512
Epoch 1/10, Train Loss: 1.0208, Valid Loss: 0.5962
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5434
Epoch 2/10, Batch 20/49, Loss: 0.6291
Epoch 2/10, Batch 30/49, Loss: 0.5535
Epoch 2/10, Batch 40/49, Loss: 0.4616
Epoch 2/10, Train Loss: 0.5654, Valid Loss: 0.4199
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4774
Epoch 3/10, Batch 20/49, Loss: 0.3224
Epoch 3/10, Batch 30/49, Loss: 0.4286
Epoch 3/10, Batch 40/49, Loss: 0.3867
Epoch 3/10, Train Loss: 0.4406, Valid Loss: 0.3593
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3882
Epoch 4/10, Batch 20/49, Loss: 0.3001
Epoch 4/10, Batch 30/49, Loss: 0.4712
Epoch 4/10, Batch 40/49, Loss: 0.4383
Epoch 4/10, Train Loss: 0.3804, Valid Loss: 0.3224
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2729
Epoch 5/10, Batch 20/49, Loss: 0.2328
Epoch 5/10, Batch 30/49, Loss: 0.4142
Epoch 5/10, Batch 40/49, Loss: 0.3537
Epoch 5/10, Train Loss: 0.3398, Valid Loss: 0.2991
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2723
Epoch 6/10, Batch 20/49, Loss: 0.3058
Epoch 6/10, Batch 30/49, Loss: 0.2312
Epoch 6/10, Batch 40/49, Loss: 0.3324
Epoch 6/10, Train Loss: 0.3143, Valid Loss: 0.2888
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2606
Epoch 7/10, Batch 20/49, Loss: 0.3648
Epoch 7/10, Batch 30/49, Loss: 0.2471
Epoch 7/10, Batch 40/49, Loss: 0.3870
Epoch 7/10, Train Loss: 0.2843, Valid Loss: 0.2977
Epoch 8/10, Batch 10/49, Loss: 0.4900
Epoch 8/10, Batch 20/49, Loss: 0.2426
Epoch 8/10, Batch 30/49, Loss: 0.2321
Epoch 8/10, Batch 40/49, Loss: 0.1945
Epoch 8/10, Train Loss: 0.2728, Valid Loss: 0.2798
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2660
Epoch 9/10, Batch 20/49, Loss: 0.1279
Epoch 9/10, Batch 30/49, Loss: 0.4533
Epoch 9/10, Batch 40/49, Loss: 0.3503
Epoch 9/10, Train Loss: 0.2505, Valid Loss: 0.2673
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2391
Epoch 10/10, Batch 20/49, Loss: 0.1756
Epoch 10/10, Batch 30/49, Loss: 0.2379
Epoch 10/10, Batch 40/49, Loss: 0.1722
Epoch 10/10, Train Loss: 0.2214, Valid Loss: 0.2759
Accuracy: 0.9124
Precision: 0.9107
Recall: 0.9124
F1-score: 0.9093
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 19. Fitness: 0.9124
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2508
Epoch 1/10, Batch 20/49, Loss: 1.1093
Epoch 1/10, Batch 30/49, Loss: 0.8545
Epoch 1/10, Batch 40/49, Loss: 0.8294
Epoch 1/10, Train Loss: 1.0230, Valid Loss: 0.6522
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5631
Epoch 2/10, Batch 20/49, Loss: 0.7168
Epoch 2/10, Batch 30/49, Loss: 0.5410
Epoch 2/10, Batch 40/49, Loss: 0.5815
Epoch 2/10, Train Loss: 0.5586, Valid Loss: 0.4457
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4074
Epoch 3/10, Batch 20/49, Loss: 0.2926
Epoch 3/10, Batch 30/49, Loss: 0.2816
Epoch 3/10, Batch 40/49, Loss: 0.2696
Epoch 3/10, Train Loss: 0.4252, Valid Loss: 0.3779
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3465
Epoch 4/10, Batch 20/49, Loss: 0.3698
Epoch 4/10, Batch 30/49, Loss: 0.3095
Epoch 4/10, Batch 40/49, Loss: 0.3752
Epoch 4/10, Train Loss: 0.3782, Valid Loss: 0.3351
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2881
Epoch 5/10, Batch 20/49, Loss: 0.3361
Epoch 5/10, Batch 30/49, Loss: 0.2708
Epoch 5/10, Batch 40/49, Loss: 0.3304
Epoch 5/10, Train Loss: 0.3399, Valid Loss: 0.3043
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2638
Epoch 6/10, Batch 20/49, Loss: 0.2699
Epoch 6/10, Batch 30/49, Loss: 0.2613
Epoch 6/10, Batch 40/49, Loss: 0.3470
Epoch 6/10, Train Loss: 0.3074, Valid Loss: 0.2901
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2798
Epoch 7/10, Batch 20/49, Loss: 0.2766
Epoch 7/10, Batch 30/49, Loss: 0.2835
Epoch 7/10, Batch 40/49, Loss: 0.2615
Epoch 7/10, Train Loss: 0.2727, Valid Loss: 0.2937
Epoch 8/10, Batch 10/49, Loss: 0.3517
Epoch 8/10, Batch 20/49, Loss: 0.1862
Epoch 8/10, Batch 30/49, Loss: 0.2554
Epoch 8/10, Batch 40/49, Loss: 0.3260
Epoch 8/10, Train Loss: 0.2695, Valid Loss: 0.2728
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2991
Epoch 9/10, Batch 20/49, Loss: 0.2892
Epoch 9/10, Batch 30/49, Loss: 0.3581
Epoch 9/10, Batch 40/49, Loss: 0.2556
Epoch 9/10, Train Loss: 0.2432, Valid Loss: 0.2556
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2068
Epoch 10/10, Batch 20/49, Loss: 0.2896
Epoch 10/10, Batch 30/49, Loss: 0.2137
Epoch 10/10, Batch 40/49, Loss: 0.2139
Epoch 10/10, Train Loss: 0.2372, Valid Loss: 0.2504
Model saved!
Accuracy: 0.9019
Precision: 0.8994
Recall: 0.9019
F1-score: 0.8974
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2226
Epoch 1/10, Batch 20/49, Loss: 1.1908
Epoch 1/10, Batch 30/49, Loss: 0.9096
Epoch 1/10, Batch 40/49, Loss: 0.7192
Epoch 1/10, Train Loss: 1.0123, Valid Loss: 0.6246
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5700
Epoch 2/10, Batch 20/49, Loss: 0.5854
Epoch 2/10, Batch 30/49, Loss: 0.4857
Epoch 2/10, Batch 40/49, Loss: 0.5416
Epoch 2/10, Train Loss: 0.5556, Valid Loss: 0.4331
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4670
Epoch 3/10, Batch 20/49, Loss: 0.3097
Epoch 3/10, Batch 30/49, Loss: 0.3838
Epoch 3/10, Batch 40/49, Loss: 0.3609
Epoch 3/10, Train Loss: 0.4287, Valid Loss: 0.3744
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3906
Epoch 4/10, Batch 20/49, Loss: 0.3143
Epoch 4/10, Batch 30/49, Loss: 0.3548
Epoch 4/10, Batch 40/49, Loss: 0.4136
Epoch 4/10, Train Loss: 0.3726, Valid Loss: 0.3303
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3296
Epoch 5/10, Batch 20/49, Loss: 0.2128
Epoch 5/10, Batch 30/49, Loss: 0.1404
Epoch 5/10, Batch 40/49, Loss: 0.2962
Epoch 5/10, Train Loss: 0.3250, Valid Loss: 0.3075
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2461
Epoch 6/10, Batch 20/49, Loss: 0.2661
Epoch 6/10, Batch 30/49, Loss: 0.2127
Epoch 6/10, Batch 40/49, Loss: 0.3376
Epoch 6/10, Train Loss: 0.3087, Valid Loss: 0.2970
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3640
Epoch 7/10, Batch 20/49, Loss: 0.5185
Epoch 7/10, Batch 30/49, Loss: 0.1803
Epoch 7/10, Batch 40/49, Loss: 0.1941
Epoch 7/10, Train Loss: 0.2750, Valid Loss: 0.3010
Epoch 8/10, Batch 10/49, Loss: 0.2088
Epoch 8/10, Batch 20/49, Loss: 0.3809
Epoch 8/10, Batch 30/49, Loss: 0.2001
Epoch 8/10, Batch 40/49, Loss: 0.3022
Epoch 8/10, Train Loss: 0.2579, Valid Loss: 0.2943
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2287
Epoch 9/10, Batch 20/49, Loss: 0.2242
Epoch 9/10, Batch 30/49, Loss: 0.3228
Epoch 9/10, Batch 40/49, Loss: 0.3465
Epoch 9/10, Train Loss: 0.2546, Valid Loss: 0.2696
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2824
Epoch 10/10, Batch 20/49, Loss: 0.2355
Epoch 10/10, Batch 30/49, Loss: 0.2098
Epoch 10/10, Batch 40/49, Loss: 0.3082
Epoch 10/10, Train Loss: 0.2316, Valid Loss: 0.2805
Accuracy: 0.9112
Precision: 0.9078
Recall: 0.9112
F1-score: 0.9081
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3013
Epoch 1/10, Batch 20/49, Loss: 1.1034
Epoch 1/10, Batch 30/49, Loss: 0.8514
Epoch 1/10, Batch 40/49, Loss: 0.8914
Epoch 1/10, Train Loss: 1.0286, Valid Loss: 0.6252
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6437
Epoch 2/10, Batch 20/49, Loss: 0.5715
Epoch 2/10, Batch 30/49, Loss: 0.5436
Epoch 2/10, Batch 40/49, Loss: 0.4214
Epoch 2/10, Train Loss: 0.5685, Valid Loss: 0.4326
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5419
Epoch 3/10, Batch 20/49, Loss: 0.3976
Epoch 3/10, Batch 30/49, Loss: 0.4029
Epoch 3/10, Batch 40/49, Loss: 0.4067
Epoch 3/10, Train Loss: 0.4267, Valid Loss: 0.3799
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2522
Epoch 4/10, Batch 20/49, Loss: 0.4987
Epoch 4/10, Batch 30/49, Loss: 0.4468
Epoch 4/10, Batch 40/49, Loss: 0.3995
Epoch 4/10, Train Loss: 0.3828, Valid Loss: 0.3350
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4833
Epoch 5/10, Batch 20/49, Loss: 0.2786
Epoch 5/10, Batch 30/49, Loss: 0.2328
Epoch 5/10, Batch 40/49, Loss: 0.2721
Epoch 5/10, Train Loss: 0.3314, Valid Loss: 0.3061
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.4126
Epoch 6/10, Batch 20/49, Loss: 0.2800
Epoch 6/10, Batch 30/49, Loss: 0.3031
Epoch 6/10, Batch 40/49, Loss: 0.2634
Epoch 6/10, Train Loss: 0.3021, Valid Loss: 0.2900
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2902
Epoch 7/10, Batch 20/49, Loss: 0.2465
Epoch 7/10, Batch 30/49, Loss: 0.2878
Epoch 7/10, Batch 40/49, Loss: 0.1792
Epoch 7/10, Train Loss: 0.2737, Valid Loss: 0.2923
Epoch 8/10, Batch 10/49, Loss: 0.2126
Epoch 8/10, Batch 20/49, Loss: 0.2333
Epoch 8/10, Batch 30/49, Loss: 0.3146
Epoch 8/10, Batch 40/49, Loss: 0.3077
Epoch 8/10, Train Loss: 0.2726, Valid Loss: 0.2763
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2619
Epoch 9/10, Batch 20/49, Loss: 0.2131
Epoch 9/10, Batch 30/49, Loss: 0.2979
Epoch 9/10, Batch 40/49, Loss: 0.2692
Epoch 9/10, Train Loss: 0.2544, Valid Loss: 0.2606
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1477
Epoch 10/10, Batch 20/49, Loss: 0.1251
Epoch 10/10, Batch 30/49, Loss: 0.1426
Epoch 10/10, Batch 40/49, Loss: 0.1915
Epoch 10/10, Train Loss: 0.2315, Valid Loss: 0.2680
Accuracy: 0.9124
Precision: 0.9085
Recall: 0.9124
F1-score: 0.9098
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2794
Epoch 1/10, Batch 20/49, Loss: 1.1253
Epoch 1/10, Batch 30/49, Loss: 0.8935
Epoch 1/10, Batch 40/49, Loss: 0.7447
Epoch 1/10, Train Loss: 1.0267, Valid Loss: 0.6444
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5680
Epoch 2/10, Batch 20/49, Loss: 0.8357
Epoch 2/10, Batch 30/49, Loss: 0.5365
Epoch 2/10, Batch 40/49, Loss: 0.5677
Epoch 2/10, Train Loss: 0.5495, Valid Loss: 0.4530
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4945
Epoch 3/10, Batch 20/49, Loss: 0.3509
Epoch 3/10, Batch 30/49, Loss: 0.4923
Epoch 3/10, Batch 40/49, Loss: 0.4090
Epoch 3/10, Train Loss: 0.4260, Valid Loss: 0.3908
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3700
Epoch 4/10, Batch 20/49, Loss: 0.3410
Epoch 4/10, Batch 30/49, Loss: 0.3727
Epoch 4/10, Batch 40/49, Loss: 0.3958
Epoch 4/10, Train Loss: 0.3711, Valid Loss: 0.3528
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3924
Epoch 5/10, Batch 20/49, Loss: 0.2479
Epoch 5/10, Batch 30/49, Loss: 0.3195
Epoch 5/10, Batch 40/49, Loss: 0.1901
Epoch 5/10, Train Loss: 0.3192, Valid Loss: 0.3161
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3052
Epoch 6/10, Batch 20/49, Loss: 0.1333
Epoch 6/10, Batch 30/49, Loss: 0.2521
Epoch 6/10, Batch 40/49, Loss: 0.2731
Epoch 6/10, Train Loss: 0.2901, Valid Loss: 0.3075
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2155
Epoch 7/10, Batch 20/49, Loss: 0.2426
Epoch 7/10, Batch 30/49, Loss: 0.2608
Epoch 7/10, Batch 40/49, Loss: 0.1870
Epoch 7/10, Train Loss: 0.2633, Valid Loss: 0.3050
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2742
Epoch 8/10, Batch 20/49, Loss: 0.2129
Epoch 8/10, Batch 30/49, Loss: 0.4076
Epoch 8/10, Batch 40/49, Loss: 0.2299
Epoch 8/10, Train Loss: 0.2640, Valid Loss: 0.2849
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3573
Epoch 9/10, Batch 20/49, Loss: 0.1446
Epoch 9/10, Batch 30/49, Loss: 0.2692
Epoch 9/10, Batch 40/49, Loss: 0.4018
Epoch 9/10, Train Loss: 0.2499, Valid Loss: 0.2818
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1970
Epoch 10/10, Batch 20/49, Loss: 0.2553
Epoch 10/10, Batch 30/49, Loss: 0.2253
Epoch 10/10, Batch 40/49, Loss: 0.2969
Epoch 10/10, Train Loss: 0.2161, Valid Loss: 0.2670
Model saved!
Accuracy: 0.8995
Precision: 0.8967
Recall: 0.8995
F1-score: 0.8966
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2642
Epoch 1/10, Batch 20/49, Loss: 1.1888
Epoch 1/10, Batch 30/49, Loss: 0.7876
Epoch 1/10, Batch 40/49, Loss: 0.7638
Epoch 1/10, Train Loss: 1.0067, Valid Loss: 0.6099
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5647
Epoch 2/10, Batch 20/49, Loss: 0.7042
Epoch 2/10, Batch 30/49, Loss: 0.4531
Epoch 2/10, Batch 40/49, Loss: 0.5407
Epoch 2/10, Train Loss: 0.5445, Valid Loss: 0.4332
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4252
Epoch 3/10, Batch 20/49, Loss: 0.3095
Epoch 3/10, Batch 30/49, Loss: 0.4136
Epoch 3/10, Batch 40/49, Loss: 0.4255
Epoch 3/10, Train Loss: 0.4105, Valid Loss: 0.3719
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3506
Epoch 4/10, Batch 20/49, Loss: 0.2696
Epoch 4/10, Batch 30/49, Loss: 0.4446
Epoch 4/10, Batch 40/49, Loss: 0.5022
Epoch 4/10, Train Loss: 0.3552, Valid Loss: 0.3353
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4449
Epoch 5/10, Batch 20/49, Loss: 0.2758
Epoch 5/10, Batch 30/49, Loss: 0.2517
Epoch 5/10, Batch 40/49, Loss: 0.2772
Epoch 5/10, Train Loss: 0.3134, Valid Loss: 0.3076
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3582
Epoch 6/10, Batch 20/49, Loss: 0.2083
Epoch 6/10, Batch 30/49, Loss: 0.2279
Epoch 6/10, Batch 40/49, Loss: 0.3857
Epoch 6/10, Train Loss: 0.2879, Valid Loss: 0.2955
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3182
Epoch 7/10, Batch 20/49, Loss: 0.2845
Epoch 7/10, Batch 30/49, Loss: 0.2352
Epoch 7/10, Batch 40/49, Loss: 0.1529
Epoch 7/10, Train Loss: 0.2520, Valid Loss: 0.2937
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3261
Epoch 8/10, Batch 20/49, Loss: 0.1799
Epoch 8/10, Batch 30/49, Loss: 0.1849
Epoch 8/10, Batch 40/49, Loss: 0.2357
Epoch 8/10, Train Loss: 0.2531, Valid Loss: 0.2829
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2081
Epoch 9/10, Batch 20/49, Loss: 0.2614
Epoch 9/10, Batch 30/49, Loss: 0.2459
Epoch 9/10, Batch 40/49, Loss: 0.4699
Epoch 9/10, Train Loss: 0.2279, Valid Loss: 0.2711
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2248
Epoch 10/10, Batch 20/49, Loss: 0.2743
Epoch 10/10, Batch 30/49, Loss: 0.1457
Epoch 10/10, Batch 40/49, Loss: 0.1899
Epoch 10/10, Train Loss: 0.2114, Valid Loss: 0.2682
Model saved!
Accuracy: 0.8937
Precision: 0.8900
Recall: 0.8937
F1-score: 0.8892
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2590
Epoch 1/10, Batch 20/49, Loss: 1.1002
Epoch 1/10, Batch 30/49, Loss: 0.8461
Epoch 1/10, Batch 40/49, Loss: 0.8931
Epoch 1/10, Train Loss: 1.0380, Valid Loss: 0.6118
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7147
Epoch 2/10, Batch 20/49, Loss: 0.7377
Epoch 2/10, Batch 30/49, Loss: 0.4381
Epoch 2/10, Batch 40/49, Loss: 0.3566
Epoch 2/10, Train Loss: 0.5832, Valid Loss: 0.4099
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4754
Epoch 3/10, Batch 20/49, Loss: 0.3360
Epoch 3/10, Batch 30/49, Loss: 0.6359
Epoch 3/10, Batch 40/49, Loss: 0.5089
Epoch 3/10, Train Loss: 0.4454, Valid Loss: 0.3536
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.5405
Epoch 4/10, Batch 20/49, Loss: 0.4104
Epoch 4/10, Batch 30/49, Loss: 0.4362
Epoch 4/10, Batch 40/49, Loss: 0.4757
Epoch 4/10, Train Loss: 0.4032, Valid Loss: 0.3137
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3571
Epoch 5/10, Batch 20/49, Loss: 0.2849
Epoch 5/10, Batch 30/49, Loss: 0.3215
Epoch 5/10, Batch 40/49, Loss: 0.3015
Epoch 5/10, Train Loss: 0.3601, Valid Loss: 0.2847
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3539
Epoch 6/10, Batch 20/49, Loss: 0.2078
Epoch 6/10, Batch 30/49, Loss: 0.2166
Epoch 6/10, Batch 40/49, Loss: 0.1740
Epoch 6/10, Train Loss: 0.3190, Valid Loss: 0.2734
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3042
Epoch 7/10, Batch 20/49, Loss: 0.2878
Epoch 7/10, Batch 30/49, Loss: 0.3720
Epoch 7/10, Batch 40/49, Loss: 0.2209
Epoch 7/10, Train Loss: 0.2854, Valid Loss: 0.2744
Epoch 8/10, Batch 10/49, Loss: 0.2583
Epoch 8/10, Batch 20/49, Loss: 0.1973
Epoch 8/10, Batch 30/49, Loss: 0.1607
Epoch 8/10, Batch 40/49, Loss: 0.1673
Epoch 8/10, Train Loss: 0.2716, Valid Loss: 0.2586
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3095
Epoch 9/10, Batch 20/49, Loss: 0.3440
Epoch 9/10, Batch 30/49, Loss: 0.2039
Epoch 9/10, Batch 40/49, Loss: 0.4024
Epoch 9/10, Train Loss: 0.2624, Valid Loss: 0.2431
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3271
Epoch 10/10, Batch 20/49, Loss: 0.2459
Epoch 10/10, Batch 30/49, Loss: 0.2441
Epoch 10/10, Batch 40/49, Loss: 0.2272
Epoch 10/10, Train Loss: 0.2332, Valid Loss: 0.2557
Accuracy: 0.9124
Precision: 0.9086
Recall: 0.9124
F1-score: 0.9088
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2181
Epoch 1/10, Batch 20/49, Loss: 1.1200
Epoch 1/10, Batch 30/49, Loss: 0.7764
Epoch 1/10, Batch 40/49, Loss: 0.8175
Epoch 1/10, Train Loss: 1.0370, Valid Loss: 0.6307
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5777
Epoch 2/10, Batch 20/49, Loss: 0.6500
Epoch 2/10, Batch 30/49, Loss: 0.5141
Epoch 2/10, Batch 40/49, Loss: 0.5107
Epoch 2/10, Train Loss: 0.5728, Valid Loss: 0.4193
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4119
Epoch 3/10, Batch 20/49, Loss: 0.3736
Epoch 3/10, Batch 30/49, Loss: 0.4215
Epoch 3/10, Batch 40/49, Loss: 0.3402
Epoch 3/10, Train Loss: 0.4412, Valid Loss: 0.3526
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2823
Epoch 4/10, Batch 20/49, Loss: 0.3487
Epoch 4/10, Batch 30/49, Loss: 0.5236
Epoch 4/10, Batch 40/49, Loss: 0.4659
Epoch 4/10, Train Loss: 0.3814, Valid Loss: 0.3263
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4718
Epoch 5/10, Batch 20/49, Loss: 0.1572
Epoch 5/10, Batch 30/49, Loss: 0.2622
Epoch 5/10, Batch 40/49, Loss: 0.4147
Epoch 5/10, Train Loss: 0.3399, Valid Loss: 0.2919
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3876
Epoch 6/10, Batch 20/49, Loss: 0.2238
Epoch 6/10, Batch 30/49, Loss: 0.2480
Epoch 6/10, Batch 40/49, Loss: 0.2492
Epoch 6/10, Train Loss: 0.3150, Valid Loss: 0.2781
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2876
Epoch 7/10, Batch 20/49, Loss: 0.2932
Epoch 7/10, Batch 30/49, Loss: 0.2426
Epoch 7/10, Batch 40/49, Loss: 0.2264
Epoch 7/10, Train Loss: 0.2835, Valid Loss: 0.2824
Epoch 8/10, Batch 10/49, Loss: 0.2488
Epoch 8/10, Batch 20/49, Loss: 0.1805
Epoch 8/10, Batch 30/49, Loss: 0.1815
Epoch 8/10, Batch 40/49, Loss: 0.1944
Epoch 8/10, Train Loss: 0.2712, Valid Loss: 0.2710
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2404
Epoch 9/10, Batch 20/49, Loss: 0.1877
Epoch 9/10, Batch 30/49, Loss: 0.3600
Epoch 9/10, Batch 40/49, Loss: 0.2836
Epoch 9/10, Train Loss: 0.2513, Valid Loss: 0.2617
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3085
Epoch 10/10, Batch 20/49, Loss: 0.2075
Epoch 10/10, Batch 30/49, Loss: 0.1638
Epoch 10/10, Batch 40/49, Loss: 0.3070
Epoch 10/10, Train Loss: 0.2323, Valid Loss: 0.2530
Model saved!
Accuracy: 0.9100
Precision: 0.9067
Recall: 0.9100
F1-score: 0.9061
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2226
Epoch 1/10, Batch 20/49, Loss: 1.1500
Epoch 1/10, Batch 30/49, Loss: 0.8226
Epoch 1/10, Batch 40/49, Loss: 0.7780
Epoch 1/10, Train Loss: 1.0261, Valid Loss: 0.6569
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6013
Epoch 2/10, Batch 20/49, Loss: 0.7421
Epoch 2/10, Batch 30/49, Loss: 0.3709
Epoch 2/10, Batch 40/49, Loss: 0.5646
Epoch 2/10, Train Loss: 0.5607, Valid Loss: 0.4455
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4754
Epoch 3/10, Batch 20/49, Loss: 0.2995
Epoch 3/10, Batch 30/49, Loss: 0.2709
Epoch 3/10, Batch 40/49, Loss: 0.3592
Epoch 3/10, Train Loss: 0.4219, Valid Loss: 0.3779
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4778
Epoch 4/10, Batch 20/49, Loss: 0.4487
Epoch 4/10, Batch 30/49, Loss: 0.4530
Epoch 4/10, Batch 40/49, Loss: 0.4193
Epoch 4/10, Train Loss: 0.3805, Valid Loss: 0.3282
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4044
Epoch 5/10, Batch 20/49, Loss: 0.4478
Epoch 5/10, Batch 30/49, Loss: 0.3304
Epoch 5/10, Batch 40/49, Loss: 0.2773
Epoch 5/10, Train Loss: 0.3303, Valid Loss: 0.3004
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.4067
Epoch 6/10, Batch 20/49, Loss: 0.1839
Epoch 6/10, Batch 30/49, Loss: 0.3659
Epoch 6/10, Batch 40/49, Loss: 0.2831
Epoch 6/10, Train Loss: 0.3110, Valid Loss: 0.2741
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3202
Epoch 7/10, Batch 20/49, Loss: 0.2915
Epoch 7/10, Batch 30/49, Loss: 0.3604
Epoch 7/10, Batch 40/49, Loss: 0.2018
Epoch 7/10, Train Loss: 0.2812, Valid Loss: 0.2714
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1817
Epoch 8/10, Batch 20/49, Loss: 0.1817
Epoch 8/10, Batch 30/49, Loss: 0.1992
Epoch 8/10, Batch 40/49, Loss: 0.1797
Epoch 8/10, Train Loss: 0.2701, Valid Loss: 0.2644
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2365
Epoch 9/10, Batch 20/49, Loss: 0.1908
Epoch 9/10, Batch 30/49, Loss: 0.2794
Epoch 9/10, Batch 40/49, Loss: 0.2891
Epoch 9/10, Train Loss: 0.2484, Valid Loss: 0.2490
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2723
Epoch 10/10, Batch 20/49, Loss: 0.2281
Epoch 10/10, Batch 30/49, Loss: 0.1977
Epoch 10/10, Batch 40/49, Loss: 0.2214
Epoch 10/10, Train Loss: 0.2284, Valid Loss: 0.2389
Model saved!
Accuracy: 0.8960
Precision: 0.8913
Recall: 0.8960
F1-score: 0.8911
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2010
Epoch 1/10, Batch 20/49, Loss: 1.0336
Epoch 1/10, Batch 30/49, Loss: 0.9675
Epoch 1/10, Batch 40/49, Loss: 0.7512
Epoch 1/10, Train Loss: 1.0091, Valid Loss: 0.6721
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5748
Epoch 2/10, Batch 20/49, Loss: 0.7932
Epoch 2/10, Batch 30/49, Loss: 0.3770
Epoch 2/10, Batch 40/49, Loss: 0.4003
Epoch 2/10, Train Loss: 0.5528, Valid Loss: 0.4863
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4806
Epoch 3/10, Batch 20/49, Loss: 0.4019
Epoch 3/10, Batch 30/49, Loss: 0.4745
Epoch 3/10, Batch 40/49, Loss: 0.4316
Epoch 3/10, Train Loss: 0.4180, Valid Loss: 0.4233
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4488
Epoch 4/10, Batch 20/49, Loss: 0.3772
Epoch 4/10, Batch 30/49, Loss: 0.2796
Epoch 4/10, Batch 40/49, Loss: 0.4368
Epoch 4/10, Train Loss: 0.3734, Valid Loss: 0.3719
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5133
Epoch 5/10, Batch 20/49, Loss: 0.2415
Epoch 5/10, Batch 30/49, Loss: 0.2155
Epoch 5/10, Batch 40/49, Loss: 0.4518
Epoch 5/10, Train Loss: 0.3226, Valid Loss: 0.3457
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3804
Epoch 6/10, Batch 20/49, Loss: 0.1683
Epoch 6/10, Batch 30/49, Loss: 0.1854
Epoch 6/10, Batch 40/49, Loss: 0.1916
Epoch 6/10, Train Loss: 0.3042, Valid Loss: 0.3292
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3239
Epoch 7/10, Batch 20/49, Loss: 0.3117
Epoch 7/10, Batch 30/49, Loss: 0.1857
Epoch 7/10, Batch 40/49, Loss: 0.2583
Epoch 7/10, Train Loss: 0.2691, Valid Loss: 0.3344
Epoch 8/10, Batch 10/49, Loss: 0.4279
Epoch 8/10, Batch 20/49, Loss: 0.1826
Epoch 8/10, Batch 30/49, Loss: 0.2489
Epoch 8/10, Batch 40/49, Loss: 0.2490
Epoch 8/10, Train Loss: 0.2530, Valid Loss: 0.3183
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3120
Epoch 9/10, Batch 20/49, Loss: 0.2353
Epoch 9/10, Batch 30/49, Loss: 0.2359
Epoch 9/10, Batch 40/49, Loss: 0.4369
Epoch 9/10, Train Loss: 0.2420, Valid Loss: 0.3134
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1807
Epoch 10/10, Batch 20/49, Loss: 0.2241
Epoch 10/10, Batch 30/49, Loss: 0.2793
Epoch 10/10, Batch 40/49, Loss: 0.2660
Epoch 10/10, Train Loss: 0.2255, Valid Loss: 0.3130
Model saved!
Accuracy: 0.9077
Precision: 0.9063
Recall: 0.9077
F1-score: 0.9053
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2693
Epoch 1/10, Batch 20/49, Loss: 1.0534
Epoch 1/10, Batch 30/49, Loss: 0.9258
Epoch 1/10, Batch 40/49, Loss: 0.9423
Epoch 1/10, Train Loss: 1.0168, Valid Loss: 0.6429
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6183
Epoch 2/10, Batch 20/49, Loss: 0.6230
Epoch 2/10, Batch 30/49, Loss: 0.6073
Epoch 2/10, Batch 40/49, Loss: 0.7014
Epoch 2/10, Train Loss: 0.5387, Valid Loss: 0.4722
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4451
Epoch 3/10, Batch 20/49, Loss: 0.3115
Epoch 3/10, Batch 30/49, Loss: 0.3123
Epoch 3/10, Batch 40/49, Loss: 0.5155
Epoch 3/10, Train Loss: 0.4050, Valid Loss: 0.4211
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3225
Epoch 4/10, Batch 20/49, Loss: 0.4105
Epoch 4/10, Batch 30/49, Loss: 0.4968
Epoch 4/10, Batch 40/49, Loss: 0.4702
Epoch 4/10, Train Loss: 0.3602, Valid Loss: 0.3657
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3122
Epoch 5/10, Batch 20/49, Loss: 0.2957
Epoch 5/10, Batch 30/49, Loss: 0.1764
Epoch 5/10, Batch 40/49, Loss: 0.3469
Epoch 5/10, Train Loss: 0.3137, Valid Loss: 0.3467
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2996
Epoch 6/10, Batch 20/49, Loss: 0.1550
Epoch 6/10, Batch 30/49, Loss: 0.2405
Epoch 6/10, Batch 40/49, Loss: 0.3932
Epoch 6/10, Train Loss: 0.2754, Valid Loss: 0.3272
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2869
Epoch 7/10, Batch 20/49, Loss: 0.2949
Epoch 7/10, Batch 30/49, Loss: 0.2989
Epoch 7/10, Batch 40/49, Loss: 0.1364
Epoch 7/10, Train Loss: 0.2480, Valid Loss: 0.3345
Epoch 8/10, Batch 10/49, Loss: 0.1611
Epoch 8/10, Batch 20/49, Loss: 0.2493
Epoch 8/10, Batch 30/49, Loss: 0.1944
Epoch 8/10, Batch 40/49, Loss: 0.3057
Epoch 8/10, Train Loss: 0.2515, Valid Loss: 0.3159
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1593
Epoch 9/10, Batch 20/49, Loss: 0.1847
Epoch 9/10, Batch 30/49, Loss: 0.2650
Epoch 9/10, Batch 40/49, Loss: 0.4179
Epoch 9/10, Train Loss: 0.2250, Valid Loss: 0.3047
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2581
Epoch 10/10, Batch 20/49, Loss: 0.1187
Epoch 10/10, Batch 30/49, Loss: 0.1346
Epoch 10/10, Batch 40/49, Loss: 0.2396
Epoch 10/10, Train Loss: 0.1982, Valid Loss: 0.3036
Model saved!
Accuracy: 0.9065
Precision: 0.9029
Recall: 0.9065
F1-score: 0.9024
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2257
Epoch 1/10, Batch 20/49, Loss: 1.1935
Epoch 1/10, Batch 30/49, Loss: 0.8634
Epoch 1/10, Batch 40/49, Loss: 0.7820
Epoch 1/10, Train Loss: 1.0247, Valid Loss: 0.6146
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5996
Epoch 2/10, Batch 20/49, Loss: 0.7842
Epoch 2/10, Batch 30/49, Loss: 0.5883
Epoch 2/10, Batch 40/49, Loss: 0.5889
Epoch 2/10, Train Loss: 0.5774, Valid Loss: 0.4256
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3400
Epoch 3/10, Batch 20/49, Loss: 0.3664
Epoch 3/10, Batch 30/49, Loss: 0.5323
Epoch 3/10, Batch 40/49, Loss: 0.4974
Epoch 3/10, Train Loss: 0.4339, Valid Loss: 0.3745
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2925
Epoch 4/10, Batch 20/49, Loss: 0.2986
Epoch 4/10, Batch 30/49, Loss: 0.3767
Epoch 4/10, Batch 40/49, Loss: 0.5590
Epoch 4/10, Train Loss: 0.3910, Valid Loss: 0.3274
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5716
Epoch 5/10, Batch 20/49, Loss: 0.2077
Epoch 5/10, Batch 30/49, Loss: 0.2713
Epoch 5/10, Batch 40/49, Loss: 0.3137
Epoch 5/10, Train Loss: 0.3582, Valid Loss: 0.2988
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3607
Epoch 6/10, Batch 20/49, Loss: 0.2567
Epoch 6/10, Batch 30/49, Loss: 0.2478
Epoch 6/10, Batch 40/49, Loss: 0.3500
Epoch 6/10, Train Loss: 0.3066, Valid Loss: 0.2838
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2602
Epoch 7/10, Batch 20/49, Loss: 0.3357
Epoch 7/10, Batch 30/49, Loss: 0.3213
Epoch 7/10, Batch 40/49, Loss: 0.2656
Epoch 7/10, Train Loss: 0.2786, Valid Loss: 0.2913
Epoch 8/10, Batch 10/49, Loss: 0.1896
Epoch 8/10, Batch 20/49, Loss: 0.1499
Epoch 8/10, Batch 30/49, Loss: 0.2628
Epoch 8/10, Batch 40/49, Loss: 0.2950
Epoch 8/10, Train Loss: 0.2819, Valid Loss: 0.2693
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2647
Epoch 9/10, Batch 20/49, Loss: 0.1930
Epoch 9/10, Batch 30/49, Loss: 0.3014
Epoch 9/10, Batch 40/49, Loss: 0.3779
Epoch 9/10, Train Loss: 0.2545, Valid Loss: 0.2519
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2950
Epoch 10/10, Batch 20/49, Loss: 0.2897
Epoch 10/10, Batch 30/49, Loss: 0.2317
Epoch 10/10, Batch 40/49, Loss: 0.2202
Epoch 10/10, Train Loss: 0.2383, Valid Loss: 0.2540
Accuracy: 0.9136
Precision: 0.9120
Recall: 0.9136
F1-score: 0.9103
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 30. Fitness: 0.9136
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2369
Epoch 1/10, Batch 20/49, Loss: 1.1831
Epoch 1/10, Batch 30/49, Loss: 0.8865
Epoch 1/10, Batch 40/49, Loss: 0.7558
Epoch 1/10, Train Loss: 1.0186, Valid Loss: 0.6258
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5838
Epoch 2/10, Batch 20/49, Loss: 0.6367
Epoch 2/10, Batch 30/49, Loss: 0.6417
Epoch 2/10, Batch 40/49, Loss: 0.3954
Epoch 2/10, Train Loss: 0.5520, Valid Loss: 0.4351
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4933
Epoch 3/10, Batch 20/49, Loss: 0.3886
Epoch 3/10, Batch 30/49, Loss: 0.4038
Epoch 3/10, Batch 40/49, Loss: 0.3928
Epoch 3/10, Train Loss: 0.4182, Valid Loss: 0.3615
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4389
Epoch 4/10, Batch 20/49, Loss: 0.3160
Epoch 4/10, Batch 30/49, Loss: 0.4087
Epoch 4/10, Batch 40/49, Loss: 0.3883
Epoch 4/10, Train Loss: 0.3759, Valid Loss: 0.3284
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5048
Epoch 5/10, Batch 20/49, Loss: 0.3295
Epoch 5/10, Batch 30/49, Loss: 0.2031
Epoch 5/10, Batch 40/49, Loss: 0.2381
Epoch 5/10, Train Loss: 0.3432, Valid Loss: 0.3109
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3297
Epoch 6/10, Batch 20/49, Loss: 0.3373
Epoch 6/10, Batch 30/49, Loss: 0.2634
Epoch 6/10, Batch 40/49, Loss: 0.2548
Epoch 6/10, Train Loss: 0.2990, Valid Loss: 0.2862
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3229
Epoch 7/10, Batch 20/49, Loss: 0.2581
Epoch 7/10, Batch 30/49, Loss: 0.2786
Epoch 7/10, Batch 40/49, Loss: 0.1747
Epoch 7/10, Train Loss: 0.2627, Valid Loss: 0.2886
Epoch 8/10, Batch 10/49, Loss: 0.3059
Epoch 8/10, Batch 20/49, Loss: 0.1246
Epoch 8/10, Batch 30/49, Loss: 0.2246
Epoch 8/10, Batch 40/49, Loss: 0.1259
Epoch 8/10, Train Loss: 0.2650, Valid Loss: 0.2887
Epoch 9/10, Batch 10/49, Loss: 0.1924
Epoch 9/10, Batch 20/49, Loss: 0.1515
Epoch 9/10, Batch 30/49, Loss: 0.2227
Epoch 9/10, Batch 40/49, Loss: 0.4079
Epoch 9/10, Train Loss: 0.2526, Valid Loss: 0.2740
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3134
Epoch 10/10, Batch 20/49, Loss: 0.3468
Epoch 10/10, Batch 30/49, Loss: 0.1345
Epoch 10/10, Batch 40/49, Loss: 0.1921
Epoch 10/10, Train Loss: 0.2182, Valid Loss: 0.2705
Model saved!
Accuracy: 0.9089
Precision: 0.9102
Recall: 0.9089
F1-score: 0.9044
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2563
Epoch 1/10, Batch 20/49, Loss: 1.0596
Epoch 1/10, Batch 30/49, Loss: 0.8203
Epoch 1/10, Batch 40/49, Loss: 0.7597
Epoch 1/10, Train Loss: 1.0093, Valid Loss: 0.6077
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6842
Epoch 2/10, Batch 20/49, Loss: 0.7279
Epoch 2/10, Batch 30/49, Loss: 0.3668
Epoch 2/10, Batch 40/49, Loss: 0.4138
Epoch 2/10, Train Loss: 0.5604, Valid Loss: 0.4181
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4274
Epoch 3/10, Batch 20/49, Loss: 0.2814
Epoch 3/10, Batch 30/49, Loss: 0.3633
Epoch 3/10, Batch 40/49, Loss: 0.4565
Epoch 3/10, Train Loss: 0.4218, Valid Loss: 0.3641
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3441
Epoch 4/10, Batch 20/49, Loss: 0.3627
Epoch 4/10, Batch 30/49, Loss: 0.3249
Epoch 4/10, Batch 40/49, Loss: 0.4731
Epoch 4/10, Train Loss: 0.3785, Valid Loss: 0.3157
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5254
Epoch 5/10, Batch 20/49, Loss: 0.2294
Epoch 5/10, Batch 30/49, Loss: 0.3210
Epoch 5/10, Batch 40/49, Loss: 0.3442
Epoch 5/10, Train Loss: 0.3417, Valid Loss: 0.2854
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2551
Epoch 6/10, Batch 20/49, Loss: 0.2160
Epoch 6/10, Batch 30/49, Loss: 0.2197
Epoch 6/10, Batch 40/49, Loss: 0.2810
Epoch 6/10, Train Loss: 0.3022, Valid Loss: 0.2816
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1990
Epoch 7/10, Batch 20/49, Loss: 0.2543
Epoch 7/10, Batch 30/49, Loss: 0.1506
Epoch 7/10, Batch 40/49, Loss: 0.3091
Epoch 7/10, Train Loss: 0.2714, Valid Loss: 0.2672
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3683
Epoch 8/10, Batch 20/49, Loss: 0.2130
Epoch 8/10, Batch 30/49, Loss: 0.1396
Epoch 8/10, Batch 40/49, Loss: 0.2041
Epoch 8/10, Train Loss: 0.2607, Valid Loss: 0.2601
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2810
Epoch 9/10, Batch 20/49, Loss: 0.1911
Epoch 9/10, Batch 30/49, Loss: 0.3890
Epoch 9/10, Batch 40/49, Loss: 0.3026
Epoch 9/10, Train Loss: 0.2444, Valid Loss: 0.2401
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1293
Epoch 10/10, Batch 20/49, Loss: 0.1617
Epoch 10/10, Batch 30/49, Loss: 0.1570
Epoch 10/10, Batch 40/49, Loss: 0.1702
Epoch 10/10, Train Loss: 0.2227, Valid Loss: 0.2457
Accuracy: 0.9112
Precision: 0.9070
Recall: 0.9112
F1-score: 0.9076
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2107
Epoch 1/10, Batch 20/49, Loss: 1.1346
Epoch 1/10, Batch 30/49, Loss: 0.8604
Epoch 1/10, Batch 40/49, Loss: 0.8089
Epoch 1/10, Train Loss: 1.0292, Valid Loss: 0.6474
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5833
Epoch 2/10, Batch 20/49, Loss: 0.6847
Epoch 2/10, Batch 30/49, Loss: 0.5576
Epoch 2/10, Batch 40/49, Loss: 0.3626
Epoch 2/10, Train Loss: 0.5637, Valid Loss: 0.4539
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4904
Epoch 3/10, Batch 20/49, Loss: 0.2645
Epoch 3/10, Batch 30/49, Loss: 0.4548
Epoch 3/10, Batch 40/49, Loss: 0.3963
Epoch 3/10, Train Loss: 0.4402, Valid Loss: 0.3935
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3099
Epoch 4/10, Batch 20/49, Loss: 0.3488
Epoch 4/10, Batch 30/49, Loss: 0.4224
Epoch 4/10, Batch 40/49, Loss: 0.3610
Epoch 4/10, Train Loss: 0.3921, Valid Loss: 0.3328
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3749
Epoch 5/10, Batch 20/49, Loss: 0.2962
Epoch 5/10, Batch 30/49, Loss: 0.2614
Epoch 5/10, Batch 40/49, Loss: 0.3144
Epoch 5/10, Train Loss: 0.3510, Valid Loss: 0.3075
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2707
Epoch 6/10, Batch 20/49, Loss: 0.2371
Epoch 6/10, Batch 30/49, Loss: 0.2062
Epoch 6/10, Batch 40/49, Loss: 0.3147
Epoch 6/10, Train Loss: 0.3091, Valid Loss: 0.2885
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2656
Epoch 7/10, Batch 20/49, Loss: 0.4258
Epoch 7/10, Batch 30/49, Loss: 0.3864
Epoch 7/10, Batch 40/49, Loss: 0.1290
Epoch 7/10, Train Loss: 0.2861, Valid Loss: 0.2836
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3561
Epoch 8/10, Batch 20/49, Loss: 0.1866
Epoch 8/10, Batch 30/49, Loss: 0.2498
Epoch 8/10, Batch 40/49, Loss: 0.2419
Epoch 8/10, Train Loss: 0.2845, Valid Loss: 0.2777
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3542
Epoch 9/10, Batch 20/49, Loss: 0.1794
Epoch 9/10, Batch 30/49, Loss: 0.3778
Epoch 9/10, Batch 40/49, Loss: 0.2653
Epoch 9/10, Train Loss: 0.2662, Valid Loss: 0.2571
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2467
Epoch 10/10, Batch 20/49, Loss: 0.1366
Epoch 10/10, Batch 30/49, Loss: 0.2515
Epoch 10/10, Batch 40/49, Loss: 0.3020
Epoch 10/10, Train Loss: 0.2435, Valid Loss: 0.2707
Accuracy: 0.9089
Precision: 0.9055
Recall: 0.9089
F1-score: 0.9062
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2480
Epoch 1/10, Batch 20/49, Loss: 1.1210
Epoch 1/10, Batch 30/49, Loss: 0.8683
Epoch 1/10, Batch 40/49, Loss: 0.7434
Epoch 1/10, Train Loss: 1.0061, Valid Loss: 0.6168
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5069
Epoch 2/10, Batch 20/49, Loss: 0.6402
Epoch 2/10, Batch 30/49, Loss: 0.5910
Epoch 2/10, Batch 40/49, Loss: 0.5323
Epoch 2/10, Train Loss: 0.5384, Valid Loss: 0.4494
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5953
Epoch 3/10, Batch 20/49, Loss: 0.4371
Epoch 3/10, Batch 30/49, Loss: 0.2938
Epoch 3/10, Batch 40/49, Loss: 0.4020
Epoch 3/10, Train Loss: 0.4138, Valid Loss: 0.3842
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3813
Epoch 4/10, Batch 20/49, Loss: 0.4588
Epoch 4/10, Batch 30/49, Loss: 0.2640
Epoch 4/10, Batch 40/49, Loss: 0.3488
Epoch 4/10, Train Loss: 0.3655, Valid Loss: 0.3438
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4514
Epoch 5/10, Batch 20/49, Loss: 0.3863
Epoch 5/10, Batch 30/49, Loss: 0.2890
Epoch 5/10, Batch 40/49, Loss: 0.4027
Epoch 5/10, Train Loss: 0.3175, Valid Loss: 0.3172
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.5012
Epoch 6/10, Batch 20/49, Loss: 0.2595
Epoch 6/10, Batch 30/49, Loss: 0.2213
Epoch 6/10, Batch 40/49, Loss: 0.2497
Epoch 6/10, Train Loss: 0.2978, Valid Loss: 0.2999
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1735
Epoch 7/10, Batch 20/49, Loss: 0.2026
Epoch 7/10, Batch 30/49, Loss: 0.2851
Epoch 7/10, Batch 40/49, Loss: 0.2081
Epoch 7/10, Train Loss: 0.2568, Valid Loss: 0.3015
Epoch 8/10, Batch 10/49, Loss: 0.2680
Epoch 8/10, Batch 20/49, Loss: 0.2696
Epoch 8/10, Batch 30/49, Loss: 0.2133
Epoch 8/10, Batch 40/49, Loss: 0.2709
Epoch 8/10, Train Loss: 0.2622, Valid Loss: 0.2852
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2396
Epoch 9/10, Batch 20/49, Loss: 0.2175
Epoch 9/10, Batch 30/49, Loss: 0.3429
Epoch 9/10, Batch 40/49, Loss: 0.3018
Epoch 9/10, Train Loss: 0.2359, Valid Loss: 0.2772
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2261
Epoch 10/10, Batch 20/49, Loss: 0.1792
Epoch 10/10, Batch 30/49, Loss: 0.2020
Epoch 10/10, Batch 40/49, Loss: 0.1663
Epoch 10/10, Train Loss: 0.2301, Valid Loss: 0.2702
Model saved!
Accuracy: 0.9019
Precision: 0.8973
Recall: 0.9019
F1-score: 0.8980
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2031
Epoch 1/10, Batch 20/49, Loss: 1.0713
Epoch 1/10, Batch 30/49, Loss: 0.8175
Epoch 1/10, Batch 40/49, Loss: 0.6816
Epoch 1/10, Train Loss: 1.0220, Valid Loss: 0.6389
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6292
Epoch 2/10, Batch 20/49, Loss: 0.6064
Epoch 2/10, Batch 30/49, Loss: 0.4094
Epoch 2/10, Batch 40/49, Loss: 0.4680
Epoch 2/10, Train Loss: 0.5595, Valid Loss: 0.4466
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4728
Epoch 3/10, Batch 20/49, Loss: 0.3366
Epoch 3/10, Batch 30/49, Loss: 0.3689
Epoch 3/10, Batch 40/49, Loss: 0.4767
Epoch 3/10, Train Loss: 0.4202, Valid Loss: 0.3833
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3265
Epoch 4/10, Batch 20/49, Loss: 0.3370
Epoch 4/10, Batch 30/49, Loss: 0.2799
Epoch 4/10, Batch 40/49, Loss: 0.4169
Epoch 4/10, Train Loss: 0.3744, Valid Loss: 0.3333
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4069
Epoch 5/10, Batch 20/49, Loss: 0.3150
Epoch 5/10, Batch 30/49, Loss: 0.2497
Epoch 5/10, Batch 40/49, Loss: 0.2906
Epoch 5/10, Train Loss: 0.3192, Valid Loss: 0.3103
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2739
Epoch 6/10, Batch 20/49, Loss: 0.3611
Epoch 6/10, Batch 30/49, Loss: 0.2509
Epoch 6/10, Batch 40/49, Loss: 0.3196
Epoch 6/10, Train Loss: 0.2937, Valid Loss: 0.2916
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2636
Epoch 7/10, Batch 20/49, Loss: 0.3070
Epoch 7/10, Batch 30/49, Loss: 0.2562
Epoch 7/10, Batch 40/49, Loss: 0.1263
Epoch 7/10, Train Loss: 0.2740, Valid Loss: 0.2921
Epoch 8/10, Batch 10/49, Loss: 0.3486
Epoch 8/10, Batch 20/49, Loss: 0.1942
Epoch 8/10, Batch 30/49, Loss: 0.2406
Epoch 8/10, Batch 40/49, Loss: 0.1238
Epoch 8/10, Train Loss: 0.2687, Valid Loss: 0.2950
Epoch 9/10, Batch 10/49, Loss: 0.3148
Epoch 9/10, Batch 20/49, Loss: 0.1604
Epoch 9/10, Batch 30/49, Loss: 0.2621
Epoch 9/10, Batch 40/49, Loss: 0.2959
Epoch 9/10, Train Loss: 0.2518, Valid Loss: 0.2759
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3090
Epoch 10/10, Batch 20/49, Loss: 0.2017
Epoch 10/10, Batch 30/49, Loss: 0.1922
Epoch 10/10, Batch 40/49, Loss: 0.2072
Epoch 10/10, Train Loss: 0.2221, Valid Loss: 0.2745
Model saved!
Accuracy: 0.9124
Precision: 0.9097
Recall: 0.9124
F1-score: 0.9093
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1816
Epoch 1/10, Batch 20/49, Loss: 1.0760
Epoch 1/10, Batch 30/49, Loss: 0.7620
Epoch 1/10, Batch 40/49, Loss: 0.6468
Epoch 1/10, Train Loss: 1.0145, Valid Loss: 0.6473
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5322
Epoch 2/10, Batch 20/49, Loss: 0.5660
Epoch 2/10, Batch 30/49, Loss: 0.6152
Epoch 2/10, Batch 40/49, Loss: 0.4803
Epoch 2/10, Train Loss: 0.5328, Valid Loss: 0.4762
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4044
Epoch 3/10, Batch 20/49, Loss: 0.3504
Epoch 3/10, Batch 30/49, Loss: 0.3359
Epoch 3/10, Batch 40/49, Loss: 0.4353
Epoch 3/10, Train Loss: 0.4041, Valid Loss: 0.4252
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4850
Epoch 4/10, Batch 20/49, Loss: 0.5352
Epoch 4/10, Batch 30/49, Loss: 0.3400
Epoch 4/10, Batch 40/49, Loss: 0.4179
Epoch 4/10, Train Loss: 0.3520, Valid Loss: 0.3584
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3655
Epoch 5/10, Batch 20/49, Loss: 0.1890
Epoch 5/10, Batch 30/49, Loss: 0.3083
Epoch 5/10, Batch 40/49, Loss: 0.3483
Epoch 5/10, Train Loss: 0.3165, Valid Loss: 0.3366
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3228
Epoch 6/10, Batch 20/49, Loss: 0.1399
Epoch 6/10, Batch 30/49, Loss: 0.2930
Epoch 6/10, Batch 40/49, Loss: 0.2506
Epoch 6/10, Train Loss: 0.2832, Valid Loss: 0.3243
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2861
Epoch 7/10, Batch 20/49, Loss: 0.2798
Epoch 7/10, Batch 30/49, Loss: 0.2237
Epoch 7/10, Batch 40/49, Loss: 0.1732
Epoch 7/10, Train Loss: 0.2511, Valid Loss: 0.3049
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2403
Epoch 8/10, Batch 20/49, Loss: 0.2432
Epoch 8/10, Batch 30/49, Loss: 0.2533
Epoch 8/10, Batch 40/49, Loss: 0.2381
Epoch 8/10, Train Loss: 0.2518, Valid Loss: 0.3180
Epoch 9/10, Batch 10/49, Loss: 0.1174
Epoch 9/10, Batch 20/49, Loss: 0.2393
Epoch 9/10, Batch 30/49, Loss: 0.2554
Epoch 9/10, Batch 40/49, Loss: 0.3607
Epoch 9/10, Train Loss: 0.2199, Valid Loss: 0.3036
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2956
Epoch 10/10, Batch 20/49, Loss: 0.1524
Epoch 10/10, Batch 30/49, Loss: 0.1356
Epoch 10/10, Batch 40/49, Loss: 0.1954
Epoch 10/10, Train Loss: 0.2122, Valid Loss: 0.2991
Model saved!
Accuracy: 0.9054
Precision: 0.9034
Recall: 0.9054
F1-score: 0.9019
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2131
Epoch 1/10, Batch 20/49, Loss: 1.1776
Epoch 1/10, Batch 30/49, Loss: 0.8926
Epoch 1/10, Batch 40/49, Loss: 0.7614
Epoch 1/10, Train Loss: 1.0087, Valid Loss: 0.5986
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6329
Epoch 2/10, Batch 20/49, Loss: 0.6701
Epoch 2/10, Batch 30/49, Loss: 0.5219
Epoch 2/10, Batch 40/49, Loss: 0.5138
Epoch 2/10, Train Loss: 0.5464, Valid Loss: 0.4257
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4333
Epoch 3/10, Batch 20/49, Loss: 0.3504
Epoch 3/10, Batch 30/49, Loss: 0.4128
Epoch 3/10, Batch 40/49, Loss: 0.3929
Epoch 3/10, Train Loss: 0.4190, Valid Loss: 0.3706
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2759
Epoch 4/10, Batch 20/49, Loss: 0.3546
Epoch 4/10, Batch 30/49, Loss: 0.4530
Epoch 4/10, Batch 40/49, Loss: 0.4154
Epoch 4/10, Train Loss: 0.3686, Valid Loss: 0.3223
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3484
Epoch 5/10, Batch 20/49, Loss: 0.2687
Epoch 5/10, Batch 30/49, Loss: 0.2426
Epoch 5/10, Batch 40/49, Loss: 0.3155
Epoch 5/10, Train Loss: 0.3220, Valid Loss: 0.2873
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2694
Epoch 6/10, Batch 20/49, Loss: 0.1791
Epoch 6/10, Batch 30/49, Loss: 0.2699
Epoch 6/10, Batch 40/49, Loss: 0.3108
Epoch 6/10, Train Loss: 0.2980, Valid Loss: 0.2850
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3108
Epoch 7/10, Batch 20/49, Loss: 0.3243
Epoch 7/10, Batch 30/49, Loss: 0.2615
Epoch 7/10, Batch 40/49, Loss: 0.2301
Epoch 7/10, Train Loss: 0.2566, Valid Loss: 0.2893
Epoch 8/10, Batch 10/49, Loss: 0.2462
Epoch 8/10, Batch 20/49, Loss: 0.2006
Epoch 8/10, Batch 30/49, Loss: 0.1570
Epoch 8/10, Batch 40/49, Loss: 0.2121
Epoch 8/10, Train Loss: 0.2499, Valid Loss: 0.2644
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3573
Epoch 9/10, Batch 20/49, Loss: 0.1926
Epoch 9/10, Batch 30/49, Loss: 0.1975
Epoch 9/10, Batch 40/49, Loss: 0.2075
Epoch 9/10, Train Loss: 0.2397, Valid Loss: 0.2530
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2506
Epoch 10/10, Batch 20/49, Loss: 0.1683
Epoch 10/10, Batch 30/49, Loss: 0.1320
Epoch 10/10, Batch 40/49, Loss: 0.1960
Epoch 10/10, Train Loss: 0.2056, Valid Loss: 0.2616
Accuracy: 0.9089
Precision: 0.9064
Recall: 0.9089
F1-score: 0.9053
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2661
Epoch 1/10, Batch 20/49, Loss: 1.1143
Epoch 1/10, Batch 30/49, Loss: 0.7883
Epoch 1/10, Batch 40/49, Loss: 0.7258
Epoch 1/10, Train Loss: 1.0073, Valid Loss: 0.6508
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.8004
Epoch 2/10, Batch 20/49, Loss: 0.6869
Epoch 2/10, Batch 30/49, Loss: 0.4633
Epoch 2/10, Batch 40/49, Loss: 0.4843
Epoch 2/10, Train Loss: 0.5420, Valid Loss: 0.4689
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3753
Epoch 3/10, Batch 20/49, Loss: 0.3503
Epoch 3/10, Batch 30/49, Loss: 0.3950
Epoch 3/10, Batch 40/49, Loss: 0.4666
Epoch 3/10, Train Loss: 0.4157, Valid Loss: 0.4410
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2336
Epoch 4/10, Batch 20/49, Loss: 0.3118
Epoch 4/10, Batch 30/49, Loss: 0.2434
Epoch 4/10, Batch 40/49, Loss: 0.4265
Epoch 4/10, Train Loss: 0.3587, Valid Loss: 0.3693
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2999
Epoch 5/10, Batch 20/49, Loss: 0.1579
Epoch 5/10, Batch 30/49, Loss: 0.2145
Epoch 5/10, Batch 40/49, Loss: 0.2827
Epoch 5/10, Train Loss: 0.3161, Valid Loss: 0.3389
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2532
Epoch 6/10, Batch 20/49, Loss: 0.1775
Epoch 6/10, Batch 30/49, Loss: 0.3172
Epoch 6/10, Batch 40/49, Loss: 0.2478
Epoch 6/10, Train Loss: 0.2924, Valid Loss: 0.3201
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1477
Epoch 7/10, Batch 20/49, Loss: 0.3115
Epoch 7/10, Batch 30/49, Loss: 0.1989
Epoch 7/10, Batch 40/49, Loss: 0.1874
Epoch 7/10, Train Loss: 0.2557, Valid Loss: 0.3217
Epoch 8/10, Batch 10/49, Loss: 0.3898
Epoch 8/10, Batch 20/49, Loss: 0.1509
Epoch 8/10, Batch 30/49, Loss: 0.2759
Epoch 8/10, Batch 40/49, Loss: 0.1655
Epoch 8/10, Train Loss: 0.2547, Valid Loss: 0.3140
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2354
Epoch 9/10, Batch 20/49, Loss: 0.1042
Epoch 9/10, Batch 30/49, Loss: 0.2264
Epoch 9/10, Batch 40/49, Loss: 0.2070
Epoch 9/10, Train Loss: 0.2294, Valid Loss: 0.2958
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2858
Epoch 10/10, Batch 20/49, Loss: 0.1787
Epoch 10/10, Batch 30/49, Loss: 0.1810
Epoch 10/10, Batch 40/49, Loss: 0.1960
Epoch 10/10, Train Loss: 0.2101, Valid Loss: 0.2912
Model saved!
Accuracy: 0.9100
Precision: 0.9066
Recall: 0.9100
F1-score: 0.9075
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2523
Epoch 1/10, Batch 20/49, Loss: 1.1410
Epoch 1/10, Batch 30/49, Loss: 0.8239
Epoch 1/10, Batch 40/49, Loss: 0.7787
Epoch 1/10, Train Loss: 1.0110, Valid Loss: 0.6149
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6252
Epoch 2/10, Batch 20/49, Loss: 0.7637
Epoch 2/10, Batch 30/49, Loss: 0.4801
Epoch 2/10, Batch 40/49, Loss: 0.4355
Epoch 2/10, Train Loss: 0.5407, Valid Loss: 0.4204
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3892
Epoch 3/10, Batch 20/49, Loss: 0.3300
Epoch 3/10, Batch 30/49, Loss: 0.4467
Epoch 3/10, Batch 40/49, Loss: 0.4680
Epoch 3/10, Train Loss: 0.4113, Valid Loss: 0.3605
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3053
Epoch 4/10, Batch 20/49, Loss: 0.3905
Epoch 4/10, Batch 30/49, Loss: 0.3931
Epoch 4/10, Batch 40/49, Loss: 0.4224
Epoch 4/10, Train Loss: 0.3623, Valid Loss: 0.3103
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4158
Epoch 5/10, Batch 20/49, Loss: 0.2219
Epoch 5/10, Batch 30/49, Loss: 0.2939
Epoch 5/10, Batch 40/49, Loss: 0.2823
Epoch 5/10, Train Loss: 0.3178, Valid Loss: 0.2927
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3998
Epoch 6/10, Batch 20/49, Loss: 0.3073
Epoch 6/10, Batch 30/49, Loss: 0.3385
Epoch 6/10, Batch 40/49, Loss: 0.2051
Epoch 6/10, Train Loss: 0.2876, Valid Loss: 0.2767
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.4186
Epoch 7/10, Batch 20/49, Loss: 0.2313
Epoch 7/10, Batch 30/49, Loss: 0.2064
Epoch 7/10, Batch 40/49, Loss: 0.0905
Epoch 7/10, Train Loss: 0.2562, Valid Loss: 0.2697
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2258
Epoch 8/10, Batch 20/49, Loss: 0.1477
Epoch 8/10, Batch 30/49, Loss: 0.1795
Epoch 8/10, Batch 40/49, Loss: 0.1673
Epoch 8/10, Train Loss: 0.2537, Valid Loss: 0.2626
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3315
Epoch 9/10, Batch 20/49, Loss: 0.2607
Epoch 9/10, Batch 30/49, Loss: 0.2558
Epoch 9/10, Batch 40/49, Loss: 0.3792
Epoch 9/10, Train Loss: 0.2267, Valid Loss: 0.2529
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2107
Epoch 10/10, Batch 20/49, Loss: 0.2004
Epoch 10/10, Batch 30/49, Loss: 0.2461
Epoch 10/10, Batch 40/49, Loss: 0.2120
Epoch 10/10, Train Loss: 0.2171, Valid Loss: 0.2476
Model saved!
Accuracy: 0.9077
Precision: 0.9051
Recall: 0.9077
F1-score: 0.9028
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2032
Epoch 1/10, Batch 20/49, Loss: 1.0761
Epoch 1/10, Batch 30/49, Loss: 0.8124
Epoch 1/10, Batch 40/49, Loss: 0.7300
Epoch 1/10, Train Loss: 1.0017, Valid Loss: 0.6283
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6713
Epoch 2/10, Batch 20/49, Loss: 0.6593
Epoch 2/10, Batch 30/49, Loss: 0.4815
Epoch 2/10, Batch 40/49, Loss: 0.4806
Epoch 2/10, Train Loss: 0.5367, Valid Loss: 0.4359
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3555
Epoch 3/10, Batch 20/49, Loss: 0.2549
Epoch 3/10, Batch 30/49, Loss: 0.3542
Epoch 3/10, Batch 40/49, Loss: 0.4147
Epoch 3/10, Train Loss: 0.4143, Valid Loss: 0.3827
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2904
Epoch 4/10, Batch 20/49, Loss: 0.4131
Epoch 4/10, Batch 30/49, Loss: 0.3323
Epoch 4/10, Batch 40/49, Loss: 0.4638
Epoch 4/10, Train Loss: 0.3545, Valid Loss: 0.3419
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3517
Epoch 5/10, Batch 20/49, Loss: 0.2208
Epoch 5/10, Batch 30/49, Loss: 0.2547
Epoch 5/10, Batch 40/49, Loss: 0.2735
Epoch 5/10, Train Loss: 0.3020, Valid Loss: 0.3233
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3682
Epoch 6/10, Batch 20/49, Loss: 0.2021
Epoch 6/10, Batch 30/49, Loss: 0.3712
Epoch 6/10, Batch 40/49, Loss: 0.2948
Epoch 6/10, Train Loss: 0.2806, Valid Loss: 0.2899
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2965
Epoch 7/10, Batch 20/49, Loss: 0.3920
Epoch 7/10, Batch 30/49, Loss: 0.2209
Epoch 7/10, Batch 40/49, Loss: 0.1998
Epoch 7/10, Train Loss: 0.2405, Valid Loss: 0.2949
Epoch 8/10, Batch 10/49, Loss: 0.3227
Epoch 8/10, Batch 20/49, Loss: 0.3577
Epoch 8/10, Batch 30/49, Loss: 0.1773
Epoch 8/10, Batch 40/49, Loss: 0.2120
Epoch 8/10, Train Loss: 0.2444, Valid Loss: 0.2800
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1529
Epoch 9/10, Batch 20/49, Loss: 0.1370
Epoch 9/10, Batch 30/49, Loss: 0.3964
Epoch 9/10, Batch 40/49, Loss: 0.2980
Epoch 9/10, Train Loss: 0.2334, Valid Loss: 0.2684
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3465
Epoch 10/10, Batch 20/49, Loss: 0.2819
Epoch 10/10, Batch 30/49, Loss: 0.1659
Epoch 10/10, Batch 40/49, Loss: 0.1978
Epoch 10/10, Train Loss: 0.2011, Valid Loss: 0.2582
Model saved!
Accuracy: 0.9112
Precision: 0.9082
Recall: 0.9112
F1-score: 0.9093
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1695
Epoch 1/10, Batch 20/49, Loss: 1.1827
Epoch 1/10, Batch 30/49, Loss: 0.8341
Epoch 1/10, Batch 40/49, Loss: 0.8555
Epoch 1/10, Train Loss: 1.0117, Valid Loss: 0.6194
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6874
Epoch 2/10, Batch 20/49, Loss: 0.6603
Epoch 2/10, Batch 30/49, Loss: 0.5576
Epoch 2/10, Batch 40/49, Loss: 0.4695
Epoch 2/10, Train Loss: 0.5602, Valid Loss: 0.4327
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4154
Epoch 3/10, Batch 20/49, Loss: 0.4045
Epoch 3/10, Batch 30/49, Loss: 0.3696
Epoch 3/10, Batch 40/49, Loss: 0.3574
Epoch 3/10, Train Loss: 0.4311, Valid Loss: 0.3734
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3570
Epoch 4/10, Batch 20/49, Loss: 0.3001
Epoch 4/10, Batch 30/49, Loss: 0.3025
Epoch 4/10, Batch 40/49, Loss: 0.3280
Epoch 4/10, Train Loss: 0.3770, Valid Loss: 0.3377
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4068
Epoch 5/10, Batch 20/49, Loss: 0.2901
Epoch 5/10, Batch 30/49, Loss: 0.2715
Epoch 5/10, Batch 40/49, Loss: 0.3324
Epoch 5/10, Train Loss: 0.3392, Valid Loss: 0.3052
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2216
Epoch 6/10, Batch 20/49, Loss: 0.2123
Epoch 6/10, Batch 30/49, Loss: 0.4418
Epoch 6/10, Batch 40/49, Loss: 0.4303
Epoch 6/10, Train Loss: 0.3108, Valid Loss: 0.2945
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2258
Epoch 7/10, Batch 20/49, Loss: 0.4397
Epoch 7/10, Batch 30/49, Loss: 0.2910
Epoch 7/10, Batch 40/49, Loss: 0.2674
Epoch 7/10, Train Loss: 0.2789, Valid Loss: 0.2882
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2324
Epoch 8/10, Batch 20/49, Loss: 0.1565
Epoch 8/10, Batch 30/49, Loss: 0.2655
Epoch 8/10, Batch 40/49, Loss: 0.3209
Epoch 8/10, Train Loss: 0.2571, Valid Loss: 0.2772
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1558
Epoch 9/10, Batch 20/49, Loss: 0.2502
Epoch 9/10, Batch 30/49, Loss: 0.2546
Epoch 9/10, Batch 40/49, Loss: 0.3208
Epoch 9/10, Train Loss: 0.2508, Valid Loss: 0.2805
Epoch 10/10, Batch 10/49, Loss: 0.3348
Epoch 10/10, Batch 20/49, Loss: 0.1927
Epoch 10/10, Batch 30/49, Loss: 0.1127
Epoch 10/10, Batch 40/49, Loss: 0.2020
Epoch 10/10, Train Loss: 0.2298, Valid Loss: 0.2707
Model saved!
Accuracy: 0.9112
Precision: 0.9092
Recall: 0.9112
F1-score: 0.9083
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2508
Epoch 1/10, Batch 20/49, Loss: 1.1628
Epoch 1/10, Batch 30/49, Loss: 0.8198
Epoch 1/10, Batch 40/49, Loss: 0.8310
Epoch 1/10, Train Loss: 1.0184, Valid Loss: 0.6163
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5919
Epoch 2/10, Batch 20/49, Loss: 0.6926
Epoch 2/10, Batch 30/49, Loss: 0.4644
Epoch 2/10, Batch 40/49, Loss: 0.4565
Epoch 2/10, Train Loss: 0.5573, Valid Loss: 0.4184
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4753
Epoch 3/10, Batch 20/49, Loss: 0.3206
Epoch 3/10, Batch 30/49, Loss: 0.3008
Epoch 3/10, Batch 40/49, Loss: 0.4370
Epoch 3/10, Train Loss: 0.4222, Valid Loss: 0.3597
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.6284
Epoch 4/10, Batch 20/49, Loss: 0.3756
Epoch 4/10, Batch 30/49, Loss: 0.3827
Epoch 4/10, Batch 40/49, Loss: 0.4746
Epoch 4/10, Train Loss: 0.3641, Valid Loss: 0.3128
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3879
Epoch 5/10, Batch 20/49, Loss: 0.2460
Epoch 5/10, Batch 30/49, Loss: 0.2739
Epoch 5/10, Batch 40/49, Loss: 0.4292
Epoch 5/10, Train Loss: 0.3285, Valid Loss: 0.2919
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3261
Epoch 6/10, Batch 20/49, Loss: 0.2175
Epoch 6/10, Batch 30/49, Loss: 0.2824
Epoch 6/10, Batch 40/49, Loss: 0.3337
Epoch 6/10, Train Loss: 0.2996, Valid Loss: 0.2644
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3132
Epoch 7/10, Batch 20/49, Loss: 0.2241
Epoch 7/10, Batch 30/49, Loss: 0.3517
Epoch 7/10, Batch 40/49, Loss: 0.1945
Epoch 7/10, Train Loss: 0.2675, Valid Loss: 0.2623
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2888
Epoch 8/10, Batch 20/49, Loss: 0.2021
Epoch 8/10, Batch 30/49, Loss: 0.2806
Epoch 8/10, Batch 40/49, Loss: 0.2553
Epoch 8/10, Train Loss: 0.2586, Valid Loss: 0.2514
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2270
Epoch 9/10, Batch 20/49, Loss: 0.2567
Epoch 9/10, Batch 30/49, Loss: 0.2559
Epoch 9/10, Batch 40/49, Loss: 0.3175
Epoch 9/10, Train Loss: 0.2355, Valid Loss: 0.2391
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2187
Epoch 10/10, Batch 20/49, Loss: 0.2456
Epoch 10/10, Batch 30/49, Loss: 0.1271
Epoch 10/10, Batch 40/49, Loss: 0.1828
Epoch 10/10, Train Loss: 0.2214, Valid Loss: 0.2465
Accuracy: 0.9089
Precision: 0.9058
Recall: 0.9089
F1-score: 0.9048
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2480
Epoch 1/10, Batch 20/49, Loss: 1.0968
Epoch 1/10, Batch 30/49, Loss: 0.8226
Epoch 1/10, Batch 40/49, Loss: 0.7302
Epoch 1/10, Train Loss: 1.0298, Valid Loss: 0.6138
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6507
Epoch 2/10, Batch 20/49, Loss: 0.6373
Epoch 2/10, Batch 30/49, Loss: 0.5749
Epoch 2/10, Batch 40/49, Loss: 0.5602
Epoch 2/10, Train Loss: 0.5569, Valid Loss: 0.4115
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5335
Epoch 3/10, Batch 20/49, Loss: 0.3614
Epoch 3/10, Batch 30/49, Loss: 0.4549
Epoch 3/10, Batch 40/49, Loss: 0.4662
Epoch 3/10, Train Loss: 0.4378, Valid Loss: 0.3527
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4158
Epoch 4/10, Batch 20/49, Loss: 0.4161
Epoch 4/10, Batch 30/49, Loss: 0.4120
Epoch 4/10, Batch 40/49, Loss: 0.3860
Epoch 4/10, Train Loss: 0.3894, Valid Loss: 0.3101
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4464
Epoch 5/10, Batch 20/49, Loss: 0.2044
Epoch 5/10, Batch 30/49, Loss: 0.2693
Epoch 5/10, Batch 40/49, Loss: 0.4167
Epoch 5/10, Train Loss: 0.3317, Valid Loss: 0.2798
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3332
Epoch 6/10, Batch 20/49, Loss: 0.2159
Epoch 6/10, Batch 30/49, Loss: 0.4919
Epoch 6/10, Batch 40/49, Loss: 0.2763
Epoch 6/10, Train Loss: 0.2983, Valid Loss: 0.2641
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3933
Epoch 7/10, Batch 20/49, Loss: 0.4149
Epoch 7/10, Batch 30/49, Loss: 0.2446
Epoch 7/10, Batch 40/49, Loss: 0.1544
Epoch 7/10, Train Loss: 0.2680, Valid Loss: 0.2604
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3461
Epoch 8/10, Batch 20/49, Loss: 0.1325
Epoch 8/10, Batch 30/49, Loss: 0.2149
Epoch 8/10, Batch 40/49, Loss: 0.2562
Epoch 8/10, Train Loss: 0.2615, Valid Loss: 0.2461
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2167
Epoch 9/10, Batch 20/49, Loss: 0.1562
Epoch 9/10, Batch 30/49, Loss: 0.2594
Epoch 9/10, Batch 40/49, Loss: 0.2698
Epoch 9/10, Train Loss: 0.2491, Valid Loss: 0.2339
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.4141
Epoch 10/10, Batch 20/49, Loss: 0.2056
Epoch 10/10, Batch 30/49, Loss: 0.2083
Epoch 10/10, Batch 40/49, Loss: 0.2125
Epoch 10/10, Train Loss: 0.2311, Valid Loss: 0.2344
Accuracy: 0.9124
Precision: 0.9088
Recall: 0.9124
F1-score: 0.9090
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1917
Epoch 1/10, Batch 20/49, Loss: 1.1730
Epoch 1/10, Batch 30/49, Loss: 0.8989
Epoch 1/10, Batch 40/49, Loss: 0.8828
Epoch 1/10, Train Loss: 1.0169, Valid Loss: 0.6418
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5835
Epoch 2/10, Batch 20/49, Loss: 0.6501
Epoch 2/10, Batch 30/49, Loss: 0.5061
Epoch 2/10, Batch 40/49, Loss: 0.4185
Epoch 2/10, Train Loss: 0.5541, Valid Loss: 0.4566
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4803
Epoch 3/10, Batch 20/49, Loss: 0.3870
Epoch 3/10, Batch 30/49, Loss: 0.3941
Epoch 3/10, Batch 40/49, Loss: 0.3568
Epoch 3/10, Train Loss: 0.4254, Valid Loss: 0.4132
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3494
Epoch 4/10, Batch 20/49, Loss: 0.2966
Epoch 4/10, Batch 30/49, Loss: 0.3516
Epoch 4/10, Batch 40/49, Loss: 0.4518
Epoch 4/10, Train Loss: 0.3770, Valid Loss: 0.3478
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3748
Epoch 5/10, Batch 20/49, Loss: 0.2014
Epoch 5/10, Batch 30/49, Loss: 0.1551
Epoch 5/10, Batch 40/49, Loss: 0.2481
Epoch 5/10, Train Loss: 0.3313, Valid Loss: 0.3239
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2222
Epoch 6/10, Batch 20/49, Loss: 0.1970
Epoch 6/10, Batch 30/49, Loss: 0.2576
Epoch 6/10, Batch 40/49, Loss: 0.2682
Epoch 6/10, Train Loss: 0.2915, Valid Loss: 0.3163
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2900
Epoch 7/10, Batch 20/49, Loss: 0.3087
Epoch 7/10, Batch 30/49, Loss: 0.2496
Epoch 7/10, Batch 40/49, Loss: 0.2122
Epoch 7/10, Train Loss: 0.2636, Valid Loss: 0.3182
Epoch 8/10, Batch 10/49, Loss: 0.4253
Epoch 8/10, Batch 20/49, Loss: 0.1876
Epoch 8/10, Batch 30/49, Loss: 0.2690
Epoch 8/10, Batch 40/49, Loss: 0.2351
Epoch 8/10, Train Loss: 0.2740, Valid Loss: 0.3111
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1790
Epoch 9/10, Batch 20/49, Loss: 0.2475
Epoch 9/10, Batch 30/49, Loss: 0.2600
Epoch 9/10, Batch 40/49, Loss: 0.3676
Epoch 9/10, Train Loss: 0.2415, Valid Loss: 0.2968
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1970
Epoch 10/10, Batch 20/49, Loss: 0.1431
Epoch 10/10, Batch 30/49, Loss: 0.1518
Epoch 10/10, Batch 40/49, Loss: 0.2612
Epoch 10/10, Train Loss: 0.2120, Valid Loss: 0.2865
Model saved!
Accuracy: 0.9089
Precision: 0.9069
Recall: 0.9089
F1-score: 0.9054
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2353
Epoch 1/10, Batch 20/49, Loss: 1.1120
Epoch 1/10, Batch 30/49, Loss: 0.7956
Epoch 1/10, Batch 40/49, Loss: 0.8782
Epoch 1/10, Train Loss: 1.0155, Valid Loss: 0.6553
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7032
Epoch 2/10, Batch 20/49, Loss: 0.6034
Epoch 2/10, Batch 30/49, Loss: 0.4215
Epoch 2/10, Batch 40/49, Loss: 0.4357
Epoch 2/10, Train Loss: 0.5573, Valid Loss: 0.4717
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4471
Epoch 3/10, Batch 20/49, Loss: 0.3323
Epoch 3/10, Batch 30/49, Loss: 0.4824
Epoch 3/10, Batch 40/49, Loss: 0.4493
Epoch 3/10, Train Loss: 0.4311, Valid Loss: 0.4091
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4144
Epoch 4/10, Batch 20/49, Loss: 0.3843
Epoch 4/10, Batch 30/49, Loss: 0.4059
Epoch 4/10, Batch 40/49, Loss: 0.4717
Epoch 4/10, Train Loss: 0.3703, Valid Loss: 0.3419
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2933
Epoch 5/10, Batch 20/49, Loss: 0.2907
Epoch 5/10, Batch 30/49, Loss: 0.3542
Epoch 5/10, Batch 40/49, Loss: 0.2741
Epoch 5/10, Train Loss: 0.3335, Valid Loss: 0.3114
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2005
Epoch 6/10, Batch 20/49, Loss: 0.2328
Epoch 6/10, Batch 30/49, Loss: 0.2752
Epoch 6/10, Batch 40/49, Loss: 0.2402
Epoch 6/10, Train Loss: 0.3060, Valid Loss: 0.2999
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3353
Epoch 7/10, Batch 20/49, Loss: 0.3216
Epoch 7/10, Batch 30/49, Loss: 0.1616
Epoch 7/10, Batch 40/49, Loss: 0.2061
Epoch 7/10, Train Loss: 0.2591, Valid Loss: 0.2914
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3682
Epoch 8/10, Batch 20/49, Loss: 0.1704
Epoch 8/10, Batch 30/49, Loss: 0.3038
Epoch 8/10, Batch 40/49, Loss: 0.1501
Epoch 8/10, Train Loss: 0.2652, Valid Loss: 0.2759
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1119
Epoch 9/10, Batch 20/49, Loss: 0.1800
Epoch 9/10, Batch 30/49, Loss: 0.3100
Epoch 9/10, Batch 40/49, Loss: 0.3473
Epoch 9/10, Train Loss: 0.2451, Valid Loss: 0.2655
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2140
Epoch 10/10, Batch 20/49, Loss: 0.2446
Epoch 10/10, Batch 30/49, Loss: 0.2308
Epoch 10/10, Batch 40/49, Loss: 0.2424
Epoch 10/10, Train Loss: 0.2177, Valid Loss: 0.2700
Accuracy: 0.9054
Precision: 0.9018
Recall: 0.9054
F1-score: 0.9010
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2333
Epoch 1/10, Batch 20/49, Loss: 1.1840
Epoch 1/10, Batch 30/49, Loss: 0.7917
Epoch 1/10, Batch 40/49, Loss: 0.7751
Epoch 1/10, Train Loss: 1.0254, Valid Loss: 0.6224
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6957
Epoch 2/10, Batch 20/49, Loss: 0.8540
Epoch 2/10, Batch 30/49, Loss: 0.4686
Epoch 2/10, Batch 40/49, Loss: 0.5199
Epoch 2/10, Train Loss: 0.5632, Valid Loss: 0.4262
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4182
Epoch 3/10, Batch 20/49, Loss: 0.3478
Epoch 3/10, Batch 30/49, Loss: 0.3166
Epoch 3/10, Batch 40/49, Loss: 0.4003
Epoch 3/10, Train Loss: 0.4248, Valid Loss: 0.3596
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4044
Epoch 4/10, Batch 20/49, Loss: 0.4226
Epoch 4/10, Batch 30/49, Loss: 0.4330
Epoch 4/10, Batch 40/49, Loss: 0.3959
Epoch 4/10, Train Loss: 0.3769, Valid Loss: 0.3207
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4520
Epoch 5/10, Batch 20/49, Loss: 0.2452
Epoch 5/10, Batch 30/49, Loss: 0.2768
Epoch 5/10, Batch 40/49, Loss: 0.2908
Epoch 5/10, Train Loss: 0.3373, Valid Loss: 0.3033
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3666
Epoch 6/10, Batch 20/49, Loss: 0.2507
Epoch 6/10, Batch 30/49, Loss: 0.2258
Epoch 6/10, Batch 40/49, Loss: 0.2855
Epoch 6/10, Train Loss: 0.2973, Valid Loss: 0.2807
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2921
Epoch 7/10, Batch 20/49, Loss: 0.3297
Epoch 7/10, Batch 30/49, Loss: 0.2585
Epoch 7/10, Batch 40/49, Loss: 0.1231
Epoch 7/10, Train Loss: 0.2683, Valid Loss: 0.2876
Epoch 8/10, Batch 10/49, Loss: 0.3645
Epoch 8/10, Batch 20/49, Loss: 0.2060
Epoch 8/10, Batch 30/49, Loss: 0.1667
Epoch 8/10, Batch 40/49, Loss: 0.2240
Epoch 8/10, Train Loss: 0.2683, Valid Loss: 0.2674
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1769
Epoch 9/10, Batch 20/49, Loss: 0.1838
Epoch 9/10, Batch 30/49, Loss: 0.3420
Epoch 9/10, Batch 40/49, Loss: 0.2917
Epoch 9/10, Train Loss: 0.2512, Valid Loss: 0.2491
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1629
Epoch 10/10, Batch 20/49, Loss: 0.1812
Epoch 10/10, Batch 30/49, Loss: 0.0988
Epoch 10/10, Batch 40/49, Loss: 0.2289
Epoch 10/10, Train Loss: 0.2211, Valid Loss: 0.2500
Accuracy: 0.9065
Precision: 0.9023
Recall: 0.9065
F1-score: 0.9032
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1853
Epoch 1/10, Batch 20/49, Loss: 1.1469
Epoch 1/10, Batch 30/49, Loss: 0.7951
Epoch 1/10, Batch 40/49, Loss: 0.7753
Epoch 1/10, Train Loss: 1.0291, Valid Loss: 0.6313
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5817
Epoch 2/10, Batch 20/49, Loss: 0.6017
Epoch 2/10, Batch 30/49, Loss: 0.5227
Epoch 2/10, Batch 40/49, Loss: 0.5018
Epoch 2/10, Train Loss: 0.5713, Valid Loss: 0.4397
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3796
Epoch 3/10, Batch 20/49, Loss: 0.3744
Epoch 3/10, Batch 30/49, Loss: 0.5942
Epoch 3/10, Batch 40/49, Loss: 0.2447
Epoch 3/10, Train Loss: 0.4420, Valid Loss: 0.3730
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4153
Epoch 4/10, Batch 20/49, Loss: 0.4911
Epoch 4/10, Batch 30/49, Loss: 0.4434
Epoch 4/10, Batch 40/49, Loss: 0.4142
Epoch 4/10, Train Loss: 0.3856, Valid Loss: 0.3303
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5320
Epoch 5/10, Batch 20/49, Loss: 0.2881
Epoch 5/10, Batch 30/49, Loss: 0.2013
Epoch 5/10, Batch 40/49, Loss: 0.2728
Epoch 5/10, Train Loss: 0.3340, Valid Loss: 0.2942
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2178
Epoch 6/10, Batch 20/49, Loss: 0.2146
Epoch 6/10, Batch 30/49, Loss: 0.3270
Epoch 6/10, Batch 40/49, Loss: 0.3417
Epoch 6/10, Train Loss: 0.3119, Valid Loss: 0.2889
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2938
Epoch 7/10, Batch 20/49, Loss: 0.2969
Epoch 7/10, Batch 30/49, Loss: 0.1650
Epoch 7/10, Batch 40/49, Loss: 0.1726
Epoch 7/10, Train Loss: 0.2612, Valid Loss: 0.2830
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3030
Epoch 8/10, Batch 20/49, Loss: 0.1468
Epoch 8/10, Batch 30/49, Loss: 0.2270
Epoch 8/10, Batch 40/49, Loss: 0.1818
Epoch 8/10, Train Loss: 0.2591, Valid Loss: 0.2660
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2434
Epoch 9/10, Batch 20/49, Loss: 0.2253
Epoch 9/10, Batch 30/49, Loss: 0.3252
Epoch 9/10, Batch 40/49, Loss: 0.3194
Epoch 9/10, Train Loss: 0.2455, Valid Loss: 0.2481
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1318
Epoch 10/10, Batch 20/49, Loss: 0.2806
Epoch 10/10, Batch 30/49, Loss: 0.1767
Epoch 10/10, Batch 40/49, Loss: 0.2041
Epoch 10/10, Train Loss: 0.2363, Valid Loss: 0.2585
Accuracy: 0.9042
Precision: 0.8999
Recall: 0.9042
F1-score: 0.8996
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2472
Epoch 1/10, Batch 20/49, Loss: 1.0462
Epoch 1/10, Batch 30/49, Loss: 0.9218
Epoch 1/10, Batch 40/49, Loss: 0.8162
Epoch 1/10, Train Loss: 1.0189, Valid Loss: 0.6196
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5516
Epoch 2/10, Batch 20/49, Loss: 0.6308
Epoch 2/10, Batch 30/49, Loss: 0.4649
Epoch 2/10, Batch 40/49, Loss: 0.4118
Epoch 2/10, Train Loss: 0.5511, Valid Loss: 0.4311
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3810
Epoch 3/10, Batch 20/49, Loss: 0.3378
Epoch 3/10, Batch 30/49, Loss: 0.3808
Epoch 3/10, Batch 40/49, Loss: 0.3933
Epoch 3/10, Train Loss: 0.4299, Valid Loss: 0.3782
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3278
Epoch 4/10, Batch 20/49, Loss: 0.3093
Epoch 4/10, Batch 30/49, Loss: 0.2776
Epoch 4/10, Batch 40/49, Loss: 0.2989
Epoch 4/10, Train Loss: 0.3674, Valid Loss: 0.3127
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4169
Epoch 5/10, Batch 20/49, Loss: 0.3262
Epoch 5/10, Batch 30/49, Loss: 0.2498
Epoch 5/10, Batch 40/49, Loss: 0.2612
Epoch 5/10, Train Loss: 0.3263, Valid Loss: 0.2859
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2070
Epoch 6/10, Batch 20/49, Loss: 0.2435
Epoch 6/10, Batch 30/49, Loss: 0.2629
Epoch 6/10, Batch 40/49, Loss: 0.4116
Epoch 6/10, Train Loss: 0.2955, Valid Loss: 0.2715
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1804
Epoch 7/10, Batch 20/49, Loss: 0.2933
Epoch 7/10, Batch 30/49, Loss: 0.2709
Epoch 7/10, Batch 40/49, Loss: 0.2568
Epoch 7/10, Train Loss: 0.2611, Valid Loss: 0.2727
Epoch 8/10, Batch 10/49, Loss: 0.3674
Epoch 8/10, Batch 20/49, Loss: 0.2679
Epoch 8/10, Batch 30/49, Loss: 0.3018
Epoch 8/10, Batch 40/49, Loss: 0.2047
Epoch 8/10, Train Loss: 0.2649, Valid Loss: 0.2624
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3770
Epoch 9/10, Batch 20/49, Loss: 0.1729
Epoch 9/10, Batch 30/49, Loss: 0.3394
Epoch 9/10, Batch 40/49, Loss: 0.4086
Epoch 9/10, Train Loss: 0.2424, Valid Loss: 0.2459
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1839
Epoch 10/10, Batch 20/49, Loss: 0.2486
Epoch 10/10, Batch 30/49, Loss: 0.1556
Epoch 10/10, Batch 40/49, Loss: 0.1835
Epoch 10/10, Train Loss: 0.2229, Valid Loss: 0.2479
Accuracy: 0.8972
Precision: 0.8927
Recall: 0.8972
F1-score: 0.8938
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2435
Epoch 1/10, Batch 20/49, Loss: 1.0875
Epoch 1/10, Batch 30/49, Loss: 0.8983
Epoch 1/10, Batch 40/49, Loss: 0.9514
Epoch 1/10, Train Loss: 1.0123, Valid Loss: 0.6611
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6863
Epoch 2/10, Batch 20/49, Loss: 0.7607
Epoch 2/10, Batch 30/49, Loss: 0.4755
Epoch 2/10, Batch 40/49, Loss: 0.4540
Epoch 2/10, Train Loss: 0.5457, Valid Loss: 0.4666
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3243
Epoch 3/10, Batch 20/49, Loss: 0.3161
Epoch 3/10, Batch 30/49, Loss: 0.3754
Epoch 3/10, Batch 40/49, Loss: 0.4774
Epoch 3/10, Train Loss: 0.4103, Valid Loss: 0.4186
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3027
Epoch 4/10, Batch 20/49, Loss: 0.3776
Epoch 4/10, Batch 30/49, Loss: 0.2559
Epoch 4/10, Batch 40/49, Loss: 0.4509
Epoch 4/10, Train Loss: 0.3690, Valid Loss: 0.3628
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3867
Epoch 5/10, Batch 20/49, Loss: 0.2503
Epoch 5/10, Batch 30/49, Loss: 0.2821
Epoch 5/10, Batch 40/49, Loss: 0.1945
Epoch 5/10, Train Loss: 0.3270, Valid Loss: 0.3355
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2357
Epoch 6/10, Batch 20/49, Loss: 0.2225
Epoch 6/10, Batch 30/49, Loss: 0.2186
Epoch 6/10, Batch 40/49, Loss: 0.3097
Epoch 6/10, Train Loss: 0.2964, Valid Loss: 0.3434
Epoch 7/10, Batch 10/49, Loss: 0.2070
Epoch 7/10, Batch 20/49, Loss: 0.2567
Epoch 7/10, Batch 30/49, Loss: 0.1829
Epoch 7/10, Batch 40/49, Loss: 0.1230
Epoch 7/10, Train Loss: 0.2554, Valid Loss: 0.3352
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2539
Epoch 8/10, Batch 20/49, Loss: 0.2014
Epoch 8/10, Batch 30/49, Loss: 0.1576
Epoch 8/10, Batch 40/49, Loss: 0.1000
Epoch 8/10, Train Loss: 0.2526, Valid Loss: 0.3386
Epoch 9/10, Batch 10/49, Loss: 0.1406
Epoch 9/10, Batch 20/49, Loss: 0.1175
Epoch 9/10, Batch 30/49, Loss: 0.3440
Epoch 9/10, Batch 40/49, Loss: 0.4180
Epoch 9/10, Train Loss: 0.2339, Valid Loss: 0.3214
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1889
Epoch 10/10, Batch 20/49, Loss: 0.2647
Epoch 10/10, Batch 30/49, Loss: 0.1340
Epoch 10/10, Batch 40/49, Loss: 0.2133
Epoch 10/10, Train Loss: 0.2137, Valid Loss: 0.3236
Accuracy: 0.9077
Precision: 0.9118
Recall: 0.9077
F1-score: 0.9022
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2011
Epoch 1/10, Batch 20/49, Loss: 1.0872
Epoch 1/10, Batch 30/49, Loss: 0.7838
Epoch 1/10, Batch 40/49, Loss: 0.7722
Epoch 1/10, Train Loss: 1.0183, Valid Loss: 0.6577
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5910
Epoch 2/10, Batch 20/49, Loss: 0.6222
Epoch 2/10, Batch 30/49, Loss: 0.4967
Epoch 2/10, Batch 40/49, Loss: 0.3702
Epoch 2/10, Train Loss: 0.5479, Valid Loss: 0.4641
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3857
Epoch 3/10, Batch 20/49, Loss: 0.3394
Epoch 3/10, Batch 30/49, Loss: 0.4628
Epoch 3/10, Batch 40/49, Loss: 0.3498
Epoch 3/10, Train Loss: 0.4154, Valid Loss: 0.4108
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2400
Epoch 4/10, Batch 20/49, Loss: 0.4608
Epoch 4/10, Batch 30/49, Loss: 0.4505
Epoch 4/10, Batch 40/49, Loss: 0.3561
Epoch 4/10, Train Loss: 0.3688, Valid Loss: 0.3489
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4058
Epoch 5/10, Batch 20/49, Loss: 0.3069
Epoch 5/10, Batch 30/49, Loss: 0.2856
Epoch 5/10, Batch 40/49, Loss: 0.2949
Epoch 5/10, Train Loss: 0.3311, Valid Loss: 0.3258
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1810
Epoch 6/10, Batch 20/49, Loss: 0.2271
Epoch 6/10, Batch 30/49, Loss: 0.3248
Epoch 6/10, Batch 40/49, Loss: 0.2939
Epoch 6/10, Train Loss: 0.2967, Valid Loss: 0.2931
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2598
Epoch 7/10, Batch 20/49, Loss: 0.2665
Epoch 7/10, Batch 30/49, Loss: 0.1773
Epoch 7/10, Batch 40/49, Loss: 0.1938
Epoch 7/10, Train Loss: 0.2646, Valid Loss: 0.2954
Epoch 8/10, Batch 10/49, Loss: 0.2673
Epoch 8/10, Batch 20/49, Loss: 0.1483
Epoch 8/10, Batch 30/49, Loss: 0.2894
Epoch 8/10, Batch 40/49, Loss: 0.2579
Epoch 8/10, Train Loss: 0.2586, Valid Loss: 0.2898
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3334
Epoch 9/10, Batch 20/49, Loss: 0.1560
Epoch 9/10, Batch 30/49, Loss: 0.2621
Epoch 9/10, Batch 40/49, Loss: 0.2559
Epoch 9/10, Train Loss: 0.2436, Valid Loss: 0.2620
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2504
Epoch 10/10, Batch 20/49, Loss: 0.2482
Epoch 10/10, Batch 30/49, Loss: 0.2211
Epoch 10/10, Batch 40/49, Loss: 0.2085
Epoch 10/10, Train Loss: 0.2174, Valid Loss: 0.2776
Accuracy: 0.9077
Precision: 0.9048
Recall: 0.9077
F1-score: 0.9052
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2200
Epoch 1/10, Batch 20/49, Loss: 1.1199
Epoch 1/10, Batch 30/49, Loss: 0.9037
Epoch 1/10, Batch 40/49, Loss: 0.7922
Epoch 1/10, Train Loss: 1.0189, Valid Loss: 0.6034
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7039
Epoch 2/10, Batch 20/49, Loss: 0.7310
Epoch 2/10, Batch 30/49, Loss: 0.5430
Epoch 2/10, Batch 40/49, Loss: 0.4879
Epoch 2/10, Train Loss: 0.5644, Valid Loss: 0.4173
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4457
Epoch 3/10, Batch 20/49, Loss: 0.5308
Epoch 3/10, Batch 30/49, Loss: 0.4206
Epoch 3/10, Batch 40/49, Loss: 0.4987
Epoch 3/10, Train Loss: 0.4271, Valid Loss: 0.3590
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3297
Epoch 4/10, Batch 20/49, Loss: 0.3097
Epoch 4/10, Batch 30/49, Loss: 0.3490
Epoch 4/10, Batch 40/49, Loss: 0.3984
Epoch 4/10, Train Loss: 0.3751, Valid Loss: 0.3181
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4168
Epoch 5/10, Batch 20/49, Loss: 0.4220
Epoch 5/10, Batch 30/49, Loss: 0.2916
Epoch 5/10, Batch 40/49, Loss: 0.3388
Epoch 5/10, Train Loss: 0.3377, Valid Loss: 0.2828
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2823
Epoch 6/10, Batch 20/49, Loss: 0.1684
Epoch 6/10, Batch 30/49, Loss: 0.2543
Epoch 6/10, Batch 40/49, Loss: 0.2955
Epoch 6/10, Train Loss: 0.2979, Valid Loss: 0.2626
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2235
Epoch 7/10, Batch 20/49, Loss: 0.2948
Epoch 7/10, Batch 30/49, Loss: 0.2532
Epoch 7/10, Batch 40/49, Loss: 0.1145
Epoch 7/10, Train Loss: 0.2627, Valid Loss: 0.2660
Epoch 8/10, Batch 10/49, Loss: 0.3300
Epoch 8/10, Batch 20/49, Loss: 0.1344
Epoch 8/10, Batch 30/49, Loss: 0.2094
Epoch 8/10, Batch 40/49, Loss: 0.1338
Epoch 8/10, Train Loss: 0.2576, Valid Loss: 0.2518
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2171
Epoch 9/10, Batch 20/49, Loss: 0.1980
Epoch 9/10, Batch 30/49, Loss: 0.3508
Epoch 9/10, Batch 40/49, Loss: 0.2171
Epoch 9/10, Train Loss: 0.2420, Valid Loss: 0.2372
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2166
Epoch 10/10, Batch 20/49, Loss: 0.2467
Epoch 10/10, Batch 30/49, Loss: 0.1500
Epoch 10/10, Batch 40/49, Loss: 0.2515
Epoch 10/10, Train Loss: 0.2300, Valid Loss: 0.2400
Accuracy: 0.9147
Precision: 0.9122
Recall: 0.9147
F1-score: 0.9115
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 51. Fitness: 0.9147
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2270
Epoch 1/10, Batch 20/49, Loss: 1.1215
Epoch 1/10, Batch 30/49, Loss: 0.9796
Epoch 1/10, Batch 40/49, Loss: 0.7074
Epoch 1/10, Train Loss: 1.0113, Valid Loss: 0.6076
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6544
Epoch 2/10, Batch 20/49, Loss: 0.7948
Epoch 2/10, Batch 30/49, Loss: 0.4580
Epoch 2/10, Batch 40/49, Loss: 0.4165
Epoch 2/10, Train Loss: 0.5504, Valid Loss: 0.4292
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3770
Epoch 3/10, Batch 20/49, Loss: 0.4336
Epoch 3/10, Batch 30/49, Loss: 0.4004
Epoch 3/10, Batch 40/49, Loss: 0.4873
Epoch 3/10, Train Loss: 0.4094, Valid Loss: 0.3753
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3417
Epoch 4/10, Batch 20/49, Loss: 0.3459
Epoch 4/10, Batch 30/49, Loss: 0.2629
Epoch 4/10, Batch 40/49, Loss: 0.4206
Epoch 4/10, Train Loss: 0.3675, Valid Loss: 0.3351
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3720
Epoch 5/10, Batch 20/49, Loss: 0.2463
Epoch 5/10, Batch 30/49, Loss: 0.2428
Epoch 5/10, Batch 40/49, Loss: 0.1913
Epoch 5/10, Train Loss: 0.3287, Valid Loss: 0.3153
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2099
Epoch 6/10, Batch 20/49, Loss: 0.2289
Epoch 6/10, Batch 30/49, Loss: 0.2718
Epoch 6/10, Batch 40/49, Loss: 0.2130
Epoch 6/10, Train Loss: 0.2935, Valid Loss: 0.2986
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2323
Epoch 7/10, Batch 20/49, Loss: 0.2947
Epoch 7/10, Batch 30/49, Loss: 0.1950
Epoch 7/10, Batch 40/49, Loss: 0.1462
Epoch 7/10, Train Loss: 0.2553, Valid Loss: 0.2973
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3527
Epoch 8/10, Batch 20/49, Loss: 0.1868
Epoch 8/10, Batch 30/49, Loss: 0.1947
Epoch 8/10, Batch 40/49, Loss: 0.2189
Epoch 8/10, Train Loss: 0.2597, Valid Loss: 0.2774
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2862
Epoch 9/10, Batch 20/49, Loss: 0.1140
Epoch 9/10, Batch 30/49, Loss: 0.2984
Epoch 9/10, Batch 40/49, Loss: 0.4247
Epoch 9/10, Train Loss: 0.2319, Valid Loss: 0.2751
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2052
Epoch 10/10, Batch 20/49, Loss: 0.1065
Epoch 10/10, Batch 30/49, Loss: 0.0982
Epoch 10/10, Batch 40/49, Loss: 0.3060
Epoch 10/10, Train Loss: 0.2094, Valid Loss: 0.2674
Model saved!
Accuracy: 0.9089
Precision: 0.9058
Recall: 0.9089
F1-score: 0.9065
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2100
Epoch 1/10, Batch 20/49, Loss: 1.1192
Epoch 1/10, Batch 30/49, Loss: 0.8633
Epoch 1/10, Batch 40/49, Loss: 0.8219
Epoch 1/10, Train Loss: 1.0339, Valid Loss: 0.6414
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7136
Epoch 2/10, Batch 20/49, Loss: 0.5877
Epoch 2/10, Batch 30/49, Loss: 0.4072
Epoch 2/10, Batch 40/49, Loss: 0.6175
Epoch 2/10, Train Loss: 0.5634, Valid Loss: 0.4395
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3558
Epoch 3/10, Batch 20/49, Loss: 0.3169
Epoch 3/10, Batch 30/49, Loss: 0.4418
Epoch 3/10, Batch 40/49, Loss: 0.4538
Epoch 3/10, Train Loss: 0.4352, Valid Loss: 0.3628
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3376
Epoch 4/10, Batch 20/49, Loss: 0.2914
Epoch 4/10, Batch 30/49, Loss: 0.3945
Epoch 4/10, Batch 40/49, Loss: 0.5127
Epoch 4/10, Train Loss: 0.3809, Valid Loss: 0.3205
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5525
Epoch 5/10, Batch 20/49, Loss: 0.2864
Epoch 5/10, Batch 30/49, Loss: 0.2482
Epoch 5/10, Batch 40/49, Loss: 0.2919
Epoch 5/10, Train Loss: 0.3299, Valid Loss: 0.2949
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1869
Epoch 6/10, Batch 20/49, Loss: 0.1471
Epoch 6/10, Batch 30/49, Loss: 0.4219
Epoch 6/10, Batch 40/49, Loss: 0.2299
Epoch 6/10, Train Loss: 0.3112, Valid Loss: 0.2756
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2458
Epoch 7/10, Batch 20/49, Loss: 0.3027
Epoch 7/10, Batch 30/49, Loss: 0.2481
Epoch 7/10, Batch 40/49, Loss: 0.2296
Epoch 7/10, Train Loss: 0.2808, Valid Loss: 0.2768
Epoch 8/10, Batch 10/49, Loss: 0.2785
Epoch 8/10, Batch 20/49, Loss: 0.1549
Epoch 8/10, Batch 30/49, Loss: 0.2912
Epoch 8/10, Batch 40/49, Loss: 0.2721
Epoch 8/10, Train Loss: 0.2606, Valid Loss: 0.2587
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2144
Epoch 9/10, Batch 20/49, Loss: 0.2220
Epoch 9/10, Batch 30/49, Loss: 0.2581
Epoch 9/10, Batch 40/49, Loss: 0.2424
Epoch 9/10, Train Loss: 0.2484, Valid Loss: 0.2506
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2050
Epoch 10/10, Batch 20/49, Loss: 0.1931
Epoch 10/10, Batch 30/49, Loss: 0.1659
Epoch 10/10, Batch 40/49, Loss: 0.2597
Epoch 10/10, Train Loss: 0.2337, Valid Loss: 0.2448
Model saved!
Accuracy: 0.9054
Precision: 0.9024
Recall: 0.9054
F1-score: 0.9032
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2736
Epoch 1/10, Batch 20/49, Loss: 1.1907
Epoch 1/10, Batch 30/49, Loss: 0.8216
Epoch 1/10, Batch 40/49, Loss: 0.8382
Epoch 1/10, Train Loss: 1.0197, Valid Loss: 0.6621
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6218
Epoch 2/10, Batch 20/49, Loss: 0.7253
Epoch 2/10, Batch 30/49, Loss: 0.6427
Epoch 2/10, Batch 40/49, Loss: 0.4873
Epoch 2/10, Train Loss: 0.5507, Valid Loss: 0.4612
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4570
Epoch 3/10, Batch 20/49, Loss: 0.2976
Epoch 3/10, Batch 30/49, Loss: 0.3827
Epoch 3/10, Batch 40/49, Loss: 0.3805
Epoch 3/10, Train Loss: 0.4133, Valid Loss: 0.3971
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4800
Epoch 4/10, Batch 20/49, Loss: 0.3638
Epoch 4/10, Batch 30/49, Loss: 0.3841
Epoch 4/10, Batch 40/49, Loss: 0.4157
Epoch 4/10, Train Loss: 0.3659, Valid Loss: 0.3443
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4000
Epoch 5/10, Batch 20/49, Loss: 0.2104
Epoch 5/10, Batch 30/49, Loss: 0.2129
Epoch 5/10, Batch 40/49, Loss: 0.3298
Epoch 5/10, Train Loss: 0.3310, Valid Loss: 0.3140
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2982
Epoch 6/10, Batch 20/49, Loss: 0.1985
Epoch 6/10, Batch 30/49, Loss: 0.2974
Epoch 6/10, Batch 40/49, Loss: 0.3586
Epoch 6/10, Train Loss: 0.3030, Valid Loss: 0.2950
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2794
Epoch 7/10, Batch 20/49, Loss: 0.2836
Epoch 7/10, Batch 30/49, Loss: 0.2365
Epoch 7/10, Batch 40/49, Loss: 0.2017
Epoch 7/10, Train Loss: 0.2535, Valid Loss: 0.2898
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.4486
Epoch 8/10, Batch 20/49, Loss: 0.2452
Epoch 8/10, Batch 30/49, Loss: 0.1851
Epoch 8/10, Batch 40/49, Loss: 0.1933
Epoch 8/10, Train Loss: 0.2483, Valid Loss: 0.2719
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2711
Epoch 9/10, Batch 20/49, Loss: 0.2057
Epoch 9/10, Batch 30/49, Loss: 0.2552
Epoch 9/10, Batch 40/49, Loss: 0.3759
Epoch 9/10, Train Loss: 0.2354, Valid Loss: 0.2578
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2533
Epoch 10/10, Batch 20/49, Loss: 0.1877
Epoch 10/10, Batch 30/49, Loss: 0.1520
Epoch 10/10, Batch 40/49, Loss: 0.2320
Epoch 10/10, Train Loss: 0.2272, Valid Loss: 0.2546
Model saved!
Accuracy: 0.8995
Precision: 0.8960
Recall: 0.8995
F1-score: 0.8952
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2632
Epoch 1/10, Batch 20/49, Loss: 1.1605
Epoch 1/10, Batch 30/49, Loss: 0.9722
Epoch 1/10, Batch 40/49, Loss: 0.8408
Epoch 1/10, Train Loss: 1.0203, Valid Loss: 0.5881
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6374
Epoch 2/10, Batch 20/49, Loss: 0.6168
Epoch 2/10, Batch 30/49, Loss: 0.4739
Epoch 2/10, Batch 40/49, Loss: 0.3978
Epoch 2/10, Train Loss: 0.5506, Valid Loss: 0.4106
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.2955
Epoch 3/10, Batch 20/49, Loss: 0.4031
Epoch 3/10, Batch 30/49, Loss: 0.3777
Epoch 3/10, Batch 40/49, Loss: 0.3164
Epoch 3/10, Train Loss: 0.4277, Valid Loss: 0.3536
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3970
Epoch 4/10, Batch 20/49, Loss: 0.3929
Epoch 4/10, Batch 30/49, Loss: 0.5226
Epoch 4/10, Batch 40/49, Loss: 0.4156
Epoch 4/10, Train Loss: 0.3684, Valid Loss: 0.3201
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4074
Epoch 5/10, Batch 20/49, Loss: 0.1891
Epoch 5/10, Batch 30/49, Loss: 0.2885
Epoch 5/10, Batch 40/49, Loss: 0.4199
Epoch 5/10, Train Loss: 0.3246, Valid Loss: 0.3002
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2887
Epoch 6/10, Batch 20/49, Loss: 0.2543
Epoch 6/10, Batch 30/49, Loss: 0.3228
Epoch 6/10, Batch 40/49, Loss: 0.2057
Epoch 6/10, Train Loss: 0.2994, Valid Loss: 0.2801
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2133
Epoch 7/10, Batch 20/49, Loss: 0.3551
Epoch 7/10, Batch 30/49, Loss: 0.2150
Epoch 7/10, Batch 40/49, Loss: 0.2368
Epoch 7/10, Train Loss: 0.2701, Valid Loss: 0.2935
Epoch 8/10, Batch 10/49, Loss: 0.2636
Epoch 8/10, Batch 20/49, Loss: 0.1098
Epoch 8/10, Batch 30/49, Loss: 0.2182
Epoch 8/10, Batch 40/49, Loss: 0.1516
Epoch 8/10, Train Loss: 0.2596, Valid Loss: 0.2679
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2429
Epoch 9/10, Batch 20/49, Loss: 0.1739
Epoch 9/10, Batch 30/49, Loss: 0.2722
Epoch 9/10, Batch 40/49, Loss: 0.5315
Epoch 9/10, Train Loss: 0.2473, Valid Loss: 0.2714
Epoch 10/10, Batch 10/49, Loss: 0.2206
Epoch 10/10, Batch 20/49, Loss: 0.2625
Epoch 10/10, Batch 30/49, Loss: 0.1733
Epoch 10/10, Batch 40/49, Loss: 0.1467
Epoch 10/10, Train Loss: 0.2227, Valid Loss: 0.2623
Model saved!
Accuracy: 0.8972
Precision: 0.8957
Recall: 0.8972
F1-score: 0.8914
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1979
Epoch 1/10, Batch 20/49, Loss: 1.0694
Epoch 1/10, Batch 30/49, Loss: 0.8113
Epoch 1/10, Batch 40/49, Loss: 0.7972
Epoch 1/10, Train Loss: 1.0108, Valid Loss: 0.6130
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6306
Epoch 2/10, Batch 20/49, Loss: 0.5583
Epoch 2/10, Batch 30/49, Loss: 0.5459
Epoch 2/10, Batch 40/49, Loss: 0.5351
Epoch 2/10, Train Loss: 0.5482, Valid Loss: 0.4179
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4094
Epoch 3/10, Batch 20/49, Loss: 0.5690
Epoch 3/10, Batch 30/49, Loss: 0.5228
Epoch 3/10, Batch 40/49, Loss: 0.3819
Epoch 3/10, Train Loss: 0.4189, Valid Loss: 0.3816
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3413
Epoch 4/10, Batch 20/49, Loss: 0.3902
Epoch 4/10, Batch 30/49, Loss: 0.3833
Epoch 4/10, Batch 40/49, Loss: 0.4060
Epoch 4/10, Train Loss: 0.3704, Valid Loss: 0.3302
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3930
Epoch 5/10, Batch 20/49, Loss: 0.3084
Epoch 5/10, Batch 30/49, Loss: 0.2867
Epoch 5/10, Batch 40/49, Loss: 0.4142
Epoch 5/10, Train Loss: 0.3186, Valid Loss: 0.3007
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2446
Epoch 6/10, Batch 20/49, Loss: 0.1486
Epoch 6/10, Batch 30/49, Loss: 0.3938
Epoch 6/10, Batch 40/49, Loss: 0.3660
Epoch 6/10, Train Loss: 0.2945, Valid Loss: 0.2929
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3487
Epoch 7/10, Batch 20/49, Loss: 0.2181
Epoch 7/10, Batch 30/49, Loss: 0.2966
Epoch 7/10, Batch 40/49, Loss: 0.2630
Epoch 7/10, Train Loss: 0.2673, Valid Loss: 0.2867
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2845
Epoch 8/10, Batch 20/49, Loss: 0.2366
Epoch 8/10, Batch 30/49, Loss: 0.2417
Epoch 8/10, Batch 40/49, Loss: 0.1532
Epoch 8/10, Train Loss: 0.2383, Valid Loss: 0.2824
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2019
Epoch 9/10, Batch 20/49, Loss: 0.2030
Epoch 9/10, Batch 30/49, Loss: 0.2608
Epoch 9/10, Batch 40/49, Loss: 0.2107
Epoch 9/10, Train Loss: 0.2285, Valid Loss: 0.2687
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1767
Epoch 10/10, Batch 20/49, Loss: 0.2579
Epoch 10/10, Batch 30/49, Loss: 0.1338
Epoch 10/10, Batch 40/49, Loss: 0.3175
Epoch 10/10, Train Loss: 0.2226, Valid Loss: 0.2725
Accuracy: 0.9124
Precision: 0.9108
Recall: 0.9124
F1-score: 0.9100
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1226
Epoch 1/10, Batch 20/49, Loss: 1.0648
Epoch 1/10, Batch 30/49, Loss: 0.7953
Epoch 1/10, Batch 40/49, Loss: 0.9500
Epoch 1/10, Train Loss: 1.0095, Valid Loss: 0.6375
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7075
Epoch 2/10, Batch 20/49, Loss: 0.6881
Epoch 2/10, Batch 30/49, Loss: 0.4115
Epoch 2/10, Batch 40/49, Loss: 0.4660
Epoch 2/10, Train Loss: 0.5523, Valid Loss: 0.4496
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4329
Epoch 3/10, Batch 20/49, Loss: 0.3253
Epoch 3/10, Batch 30/49, Loss: 0.4966
Epoch 3/10, Batch 40/49, Loss: 0.3870
Epoch 3/10, Train Loss: 0.4299, Valid Loss: 0.4114
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3645
Epoch 4/10, Batch 20/49, Loss: 0.4091
Epoch 4/10, Batch 30/49, Loss: 0.5135
Epoch 4/10, Batch 40/49, Loss: 0.4878
Epoch 4/10, Train Loss: 0.3764, Valid Loss: 0.3506
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5043
Epoch 5/10, Batch 20/49, Loss: 0.2502
Epoch 5/10, Batch 30/49, Loss: 0.2585
Epoch 5/10, Batch 40/49, Loss: 0.3186
Epoch 5/10, Train Loss: 0.3267, Valid Loss: 0.3333
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3505
Epoch 6/10, Batch 20/49, Loss: 0.3110
Epoch 6/10, Batch 30/49, Loss: 0.2071
Epoch 6/10, Batch 40/49, Loss: 0.2347
Epoch 6/10, Train Loss: 0.3030, Valid Loss: 0.3148
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1622
Epoch 7/10, Batch 20/49, Loss: 0.3960
Epoch 7/10, Batch 30/49, Loss: 0.3739
Epoch 7/10, Batch 40/49, Loss: 0.1785
Epoch 7/10, Train Loss: 0.2714, Valid Loss: 0.3060
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2844
Epoch 8/10, Batch 20/49, Loss: 0.2112
Epoch 8/10, Batch 30/49, Loss: 0.1742
Epoch 8/10, Batch 40/49, Loss: 0.2599
Epoch 8/10, Train Loss: 0.2491, Valid Loss: 0.2988
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2016
Epoch 9/10, Batch 20/49, Loss: 0.3249
Epoch 9/10, Batch 30/49, Loss: 0.2384
Epoch 9/10, Batch 40/49, Loss: 0.3986
Epoch 9/10, Train Loss: 0.2476, Valid Loss: 0.2857
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3127
Epoch 10/10, Batch 20/49, Loss: 0.1885
Epoch 10/10, Batch 30/49, Loss: 0.1307
Epoch 10/10, Batch 40/49, Loss: 0.1866
Epoch 10/10, Train Loss: 0.2308, Valid Loss: 0.2971
Accuracy: 0.9054
Precision: 0.9015
Recall: 0.9054
F1-score: 0.9023
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2678
Epoch 1/10, Batch 20/49, Loss: 1.0892
Epoch 1/10, Batch 30/49, Loss: 0.8983
Epoch 1/10, Batch 40/49, Loss: 0.8003
Epoch 1/10, Train Loss: 1.0066, Valid Loss: 0.6749
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6441
Epoch 2/10, Batch 20/49, Loss: 0.6691
Epoch 2/10, Batch 30/49, Loss: 0.5318
Epoch 2/10, Batch 40/49, Loss: 0.4641
Epoch 2/10, Train Loss: 0.5535, Valid Loss: 0.4712
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4380
Epoch 3/10, Batch 20/49, Loss: 0.2583
Epoch 3/10, Batch 30/49, Loss: 0.4800
Epoch 3/10, Batch 40/49, Loss: 0.4009
Epoch 3/10, Train Loss: 0.4114, Valid Loss: 0.4265
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3305
Epoch 4/10, Batch 20/49, Loss: 0.3039
Epoch 4/10, Batch 30/49, Loss: 0.4201
Epoch 4/10, Batch 40/49, Loss: 0.3492
Epoch 4/10, Train Loss: 0.3624, Valid Loss: 0.3726
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4682
Epoch 5/10, Batch 20/49, Loss: 0.1795
Epoch 5/10, Batch 30/49, Loss: 0.2164
Epoch 5/10, Batch 40/49, Loss: 0.2264
Epoch 5/10, Train Loss: 0.3125, Valid Loss: 0.3229
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.4328
Epoch 6/10, Batch 20/49, Loss: 0.2260
Epoch 6/10, Batch 30/49, Loss: 0.2493
Epoch 6/10, Batch 40/49, Loss: 0.2087
Epoch 6/10, Train Loss: 0.2833, Valid Loss: 0.3226
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2014
Epoch 7/10, Batch 20/49, Loss: 0.2836
Epoch 7/10, Batch 30/49, Loss: 0.1557
Epoch 7/10, Batch 40/49, Loss: 0.2697
Epoch 7/10, Train Loss: 0.2547, Valid Loss: 0.3111
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2483
Epoch 8/10, Batch 20/49, Loss: 0.2436
Epoch 8/10, Batch 30/49, Loss: 0.3086
Epoch 8/10, Batch 40/49, Loss: 0.1505
Epoch 8/10, Train Loss: 0.2612, Valid Loss: 0.3021
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2450
Epoch 9/10, Batch 20/49, Loss: 0.2145
Epoch 9/10, Batch 30/49, Loss: 0.3625
Epoch 9/10, Batch 40/49, Loss: 0.3344
Epoch 9/10, Train Loss: 0.2344, Valid Loss: 0.2934
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3487
Epoch 10/10, Batch 20/49, Loss: 0.1650
Epoch 10/10, Batch 30/49, Loss: 0.2520
Epoch 10/10, Batch 40/49, Loss: 0.2048
Epoch 10/10, Train Loss: 0.2269, Valid Loss: 0.2962
Accuracy: 0.9007
Precision: 0.8966
Recall: 0.9007
F1-score: 0.8972
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2574
Epoch 1/10, Batch 20/49, Loss: 1.1480
Epoch 1/10, Batch 30/49, Loss: 0.8509
Epoch 1/10, Batch 40/49, Loss: 0.8770
Epoch 1/10, Train Loss: 1.0338, Valid Loss: 0.6823
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5908
Epoch 2/10, Batch 20/49, Loss: 0.8251
Epoch 2/10, Batch 30/49, Loss: 0.6642
Epoch 2/10, Batch 40/49, Loss: 0.5699
Epoch 2/10, Train Loss: 0.5652, Valid Loss: 0.4838
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3272
Epoch 3/10, Batch 20/49, Loss: 0.2949
Epoch 3/10, Batch 30/49, Loss: 0.4430
Epoch 3/10, Batch 40/49, Loss: 0.4437
Epoch 3/10, Train Loss: 0.4253, Valid Loss: 0.4172
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3744
Epoch 4/10, Batch 20/49, Loss: 0.3328
Epoch 4/10, Batch 30/49, Loss: 0.4394
Epoch 4/10, Batch 40/49, Loss: 0.2598
Epoch 4/10, Train Loss: 0.3777, Valid Loss: 0.3684
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4889
Epoch 5/10, Batch 20/49, Loss: 0.2201
Epoch 5/10, Batch 30/49, Loss: 0.3890
Epoch 5/10, Batch 40/49, Loss: 0.3019
Epoch 5/10, Train Loss: 0.3430, Valid Loss: 0.3454
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2617
Epoch 6/10, Batch 20/49, Loss: 0.2147
Epoch 6/10, Batch 30/49, Loss: 0.2918
Epoch 6/10, Batch 40/49, Loss: 0.2042
Epoch 6/10, Train Loss: 0.3069, Valid Loss: 0.3250
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2438
Epoch 7/10, Batch 20/49, Loss: 0.3819
Epoch 7/10, Batch 30/49, Loss: 0.2820
Epoch 7/10, Batch 40/49, Loss: 0.1240
Epoch 7/10, Train Loss: 0.2706, Valid Loss: 0.3180
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2589
Epoch 8/10, Batch 20/49, Loss: 0.2014
Epoch 8/10, Batch 30/49, Loss: 0.2409
Epoch 8/10, Batch 40/49, Loss: 0.2983
Epoch 8/10, Train Loss: 0.2766, Valid Loss: 0.2973
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2661
Epoch 9/10, Batch 20/49, Loss: 0.1674
Epoch 9/10, Batch 30/49, Loss: 0.2542
Epoch 9/10, Batch 40/49, Loss: 0.2751
Epoch 9/10, Train Loss: 0.2398, Valid Loss: 0.2857
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2524
Epoch 10/10, Batch 20/49, Loss: 0.2297
Epoch 10/10, Batch 30/49, Loss: 0.1802
Epoch 10/10, Batch 40/49, Loss: 0.2314
Epoch 10/10, Train Loss: 0.2223, Valid Loss: 0.2880
Accuracy: 0.9089
Precision: 0.9061
Recall: 0.9089
F1-score: 0.9051
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2340
Epoch 1/10, Batch 20/49, Loss: 1.1505
Epoch 1/10, Batch 30/49, Loss: 0.7875
Epoch 1/10, Batch 40/49, Loss: 0.8807
Epoch 1/10, Train Loss: 1.0192, Valid Loss: 0.6403
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6586
Epoch 2/10, Batch 20/49, Loss: 0.7072
Epoch 2/10, Batch 30/49, Loss: 0.4835
Epoch 2/10, Batch 40/49, Loss: 0.4845
Epoch 2/10, Train Loss: 0.5687, Valid Loss: 0.4389
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3923
Epoch 3/10, Batch 20/49, Loss: 0.3069
Epoch 3/10, Batch 30/49, Loss: 0.3433
Epoch 3/10, Batch 40/49, Loss: 0.2797
Epoch 3/10, Train Loss: 0.4454, Valid Loss: 0.3876
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4217
Epoch 4/10, Batch 20/49, Loss: 0.3702
Epoch 4/10, Batch 30/49, Loss: 0.3701
Epoch 4/10, Batch 40/49, Loss: 0.4638
Epoch 4/10, Train Loss: 0.3866, Valid Loss: 0.3318
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4246
Epoch 5/10, Batch 20/49, Loss: 0.3174
Epoch 5/10, Batch 30/49, Loss: 0.2181
Epoch 5/10, Batch 40/49, Loss: 0.3515
Epoch 5/10, Train Loss: 0.3489, Valid Loss: 0.3039
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2383
Epoch 6/10, Batch 20/49, Loss: 0.2802
Epoch 6/10, Batch 30/49, Loss: 0.3910
Epoch 6/10, Batch 40/49, Loss: 0.2475
Epoch 6/10, Train Loss: 0.3170, Valid Loss: 0.2925
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2534
Epoch 7/10, Batch 20/49, Loss: 0.3889
Epoch 7/10, Batch 30/49, Loss: 0.2378
Epoch 7/10, Batch 40/49, Loss: 0.2196
Epoch 7/10, Train Loss: 0.2822, Valid Loss: 0.2926
Epoch 8/10, Batch 10/49, Loss: 0.2696
Epoch 8/10, Batch 20/49, Loss: 0.2170
Epoch 8/10, Batch 30/49, Loss: 0.2923
Epoch 8/10, Batch 40/49, Loss: 0.2314
Epoch 8/10, Train Loss: 0.2692, Valid Loss: 0.2708
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1686
Epoch 9/10, Batch 20/49, Loss: 0.1593
Epoch 9/10, Batch 30/49, Loss: 0.4126
Epoch 9/10, Batch 40/49, Loss: 0.3308
Epoch 9/10, Train Loss: 0.2455, Valid Loss: 0.2642
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3129
Epoch 10/10, Batch 20/49, Loss: 0.2131
Epoch 10/10, Batch 30/49, Loss: 0.1796
Epoch 10/10, Batch 40/49, Loss: 0.2597
Epoch 10/10, Train Loss: 0.2374, Valid Loss: 0.2609
Model saved!
Accuracy: 0.9007
Precision: 0.8986
Recall: 0.9007
F1-score: 0.8951
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2424
Epoch 1/10, Batch 20/49, Loss: 1.1318
Epoch 1/10, Batch 30/49, Loss: 0.8253
Epoch 1/10, Batch 40/49, Loss: 0.9239
Epoch 1/10, Train Loss: 1.0143, Valid Loss: 0.6509
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6738
Epoch 2/10, Batch 20/49, Loss: 0.6723
Epoch 2/10, Batch 30/49, Loss: 0.5964
Epoch 2/10, Batch 40/49, Loss: 0.4585
Epoch 2/10, Train Loss: 0.5458, Valid Loss: 0.4494
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5157
Epoch 3/10, Batch 20/49, Loss: 0.2447
Epoch 3/10, Batch 30/49, Loss: 0.3953
Epoch 3/10, Batch 40/49, Loss: 0.3920
Epoch 3/10, Train Loss: 0.4183, Valid Loss: 0.3951
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3782
Epoch 4/10, Batch 20/49, Loss: 0.4838
Epoch 4/10, Batch 30/49, Loss: 0.4671
Epoch 4/10, Batch 40/49, Loss: 0.3196
Epoch 4/10, Train Loss: 0.3739, Valid Loss: 0.3540
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3898
Epoch 5/10, Batch 20/49, Loss: 0.3265
Epoch 5/10, Batch 30/49, Loss: 0.3914
Epoch 5/10, Batch 40/49, Loss: 0.2965
Epoch 5/10, Train Loss: 0.3221, Valid Loss: 0.3220
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2856
Epoch 6/10, Batch 20/49, Loss: 0.3234
Epoch 6/10, Batch 30/49, Loss: 0.2443
Epoch 6/10, Batch 40/49, Loss: 0.3799
Epoch 6/10, Train Loss: 0.2980, Valid Loss: 0.3084
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2337
Epoch 7/10, Batch 20/49, Loss: 0.3076
Epoch 7/10, Batch 30/49, Loss: 0.1539
Epoch 7/10, Batch 40/49, Loss: 0.2432
Epoch 7/10, Train Loss: 0.2612, Valid Loss: 0.2979
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2729
Epoch 8/10, Batch 20/49, Loss: 0.2055
Epoch 8/10, Batch 30/49, Loss: 0.2150
Epoch 8/10, Batch 40/49, Loss: 0.1661
Epoch 8/10, Train Loss: 0.2548, Valid Loss: 0.2996
Epoch 9/10, Batch 10/49, Loss: 0.2260
Epoch 9/10, Batch 20/49, Loss: 0.1224
Epoch 9/10, Batch 30/49, Loss: 0.2025
Epoch 9/10, Batch 40/49, Loss: 0.2402
Epoch 9/10, Train Loss: 0.2416, Valid Loss: 0.2816
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2224
Epoch 10/10, Batch 20/49, Loss: 0.3233
Epoch 10/10, Batch 30/49, Loss: 0.1474
Epoch 10/10, Batch 40/49, Loss: 0.2059
Epoch 10/10, Train Loss: 0.2139, Valid Loss: 0.2784
Model saved!
Accuracy: 0.9089
Precision: 0.9061
Recall: 0.9089
F1-score: 0.9064
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2964
Epoch 1/10, Batch 20/49, Loss: 1.1772
Epoch 1/10, Batch 30/49, Loss: 0.8759
Epoch 1/10, Batch 40/49, Loss: 0.8771
Epoch 1/10, Train Loss: 1.0290, Valid Loss: 0.5881
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6292
Epoch 2/10, Batch 20/49, Loss: 0.6272
Epoch 2/10, Batch 30/49, Loss: 0.5543
Epoch 2/10, Batch 40/49, Loss: 0.4727
Epoch 2/10, Train Loss: 0.5584, Valid Loss: 0.3845
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4254
Epoch 3/10, Batch 20/49, Loss: 0.3707
Epoch 3/10, Batch 30/49, Loss: 0.3710
Epoch 3/10, Batch 40/49, Loss: 0.3627
Epoch 3/10, Train Loss: 0.4309, Valid Loss: 0.3137
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2791
Epoch 4/10, Batch 20/49, Loss: 0.4795
Epoch 4/10, Batch 30/49, Loss: 0.4132
Epoch 4/10, Batch 40/49, Loss: 0.3226
Epoch 4/10, Train Loss: 0.3751, Valid Loss: 0.2758
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3607
Epoch 5/10, Batch 20/49, Loss: 0.3424
Epoch 5/10, Batch 30/49, Loss: 0.2749
Epoch 5/10, Batch 40/49, Loss: 0.2486
Epoch 5/10, Train Loss: 0.3430, Valid Loss: 0.2548
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3124
Epoch 6/10, Batch 20/49, Loss: 0.2363
Epoch 6/10, Batch 30/49, Loss: 0.2598
Epoch 6/10, Batch 40/49, Loss: 0.3513
Epoch 6/10, Train Loss: 0.3056, Valid Loss: 0.2344
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1869
Epoch 7/10, Batch 20/49, Loss: 0.2682
Epoch 7/10, Batch 30/49, Loss: 0.2993
Epoch 7/10, Batch 40/49, Loss: 0.1677
Epoch 7/10, Train Loss: 0.2657, Valid Loss: 0.2365
Epoch 8/10, Batch 10/49, Loss: 0.3433
Epoch 8/10, Batch 20/49, Loss: 0.1701
Epoch 8/10, Batch 30/49, Loss: 0.2983
Epoch 8/10, Batch 40/49, Loss: 0.1562
Epoch 8/10, Train Loss: 0.2619, Valid Loss: 0.2247
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2256
Epoch 9/10, Batch 20/49, Loss: 0.1330
Epoch 9/10, Batch 30/49, Loss: 0.4515
Epoch 9/10, Batch 40/49, Loss: 0.4366
Epoch 9/10, Train Loss: 0.2478, Valid Loss: 0.2149
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3061
Epoch 10/10, Batch 20/49, Loss: 0.1278
Epoch 10/10, Batch 30/49, Loss: 0.1577
Epoch 10/10, Batch 40/49, Loss: 0.2771
Epoch 10/10, Train Loss: 0.2289, Valid Loss: 0.2075
Model saved!
Accuracy: 0.9065
Precision: 0.9037
Recall: 0.9065
F1-score: 0.9025
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2629
Epoch 1/10, Batch 20/49, Loss: 1.1342
Epoch 1/10, Batch 30/49, Loss: 0.8133
Epoch 1/10, Batch 40/49, Loss: 0.7956
Epoch 1/10, Train Loss: 1.0074, Valid Loss: 0.6237
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7056
Epoch 2/10, Batch 20/49, Loss: 0.6665
Epoch 2/10, Batch 30/49, Loss: 0.4897
Epoch 2/10, Batch 40/49, Loss: 0.4156
Epoch 2/10, Train Loss: 0.5438, Valid Loss: 0.4272
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3699
Epoch 3/10, Batch 20/49, Loss: 0.2704
Epoch 3/10, Batch 30/49, Loss: 0.4929
Epoch 3/10, Batch 40/49, Loss: 0.3900
Epoch 3/10, Train Loss: 0.4084, Valid Loss: 0.3632
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4647
Epoch 4/10, Batch 20/49, Loss: 0.3344
Epoch 4/10, Batch 30/49, Loss: 0.3817
Epoch 4/10, Batch 40/49, Loss: 0.3755
Epoch 4/10, Train Loss: 0.3507, Valid Loss: 0.3090
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4222
Epoch 5/10, Batch 20/49, Loss: 0.3106
Epoch 5/10, Batch 30/49, Loss: 0.2976
Epoch 5/10, Batch 40/49, Loss: 0.3085
Epoch 5/10, Train Loss: 0.3115, Valid Loss: 0.2903
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2717
Epoch 6/10, Batch 20/49, Loss: 0.2643
Epoch 6/10, Batch 30/49, Loss: 0.1871
Epoch 6/10, Batch 40/49, Loss: 0.2599
Epoch 6/10, Train Loss: 0.2815, Valid Loss: 0.2733
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1985
Epoch 7/10, Batch 20/49, Loss: 0.3432
Epoch 7/10, Batch 30/49, Loss: 0.2700
Epoch 7/10, Batch 40/49, Loss: 0.2533
Epoch 7/10, Train Loss: 0.2523, Valid Loss: 0.2741
Epoch 8/10, Batch 10/49, Loss: 0.2502
Epoch 8/10, Batch 20/49, Loss: 0.1869
Epoch 8/10, Batch 30/49, Loss: 0.2663
Epoch 8/10, Batch 40/49, Loss: 0.2605
Epoch 8/10, Train Loss: 0.2363, Valid Loss: 0.2695
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2876
Epoch 9/10, Batch 20/49, Loss: 0.1200
Epoch 9/10, Batch 30/49, Loss: 0.2029
Epoch 9/10, Batch 40/49, Loss: 0.3067
Epoch 9/10, Train Loss: 0.2185, Valid Loss: 0.2536
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1876
Epoch 10/10, Batch 20/49, Loss: 0.1679
Epoch 10/10, Batch 30/49, Loss: 0.2063
Epoch 10/10, Batch 40/49, Loss: 0.1307
Epoch 10/10, Train Loss: 0.2095, Valid Loss: 0.2576
Accuracy: 0.9065
Precision: 0.9032
Recall: 0.9065
F1-score: 0.9029
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2452
Epoch 1/10, Batch 20/49, Loss: 1.1072
Epoch 1/10, Batch 30/49, Loss: 0.8676
Epoch 1/10, Batch 40/49, Loss: 0.7768
Epoch 1/10, Train Loss: 1.0029, Valid Loss: 0.6626
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6222
Epoch 2/10, Batch 20/49, Loss: 0.6897
Epoch 2/10, Batch 30/49, Loss: 0.4281
Epoch 2/10, Batch 40/49, Loss: 0.4652
Epoch 2/10, Train Loss: 0.5487, Valid Loss: 0.4767
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5239
Epoch 3/10, Batch 20/49, Loss: 0.3009
Epoch 3/10, Batch 30/49, Loss: 0.4570
Epoch 3/10, Batch 40/49, Loss: 0.4641
Epoch 3/10, Train Loss: 0.4121, Valid Loss: 0.4541
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4105
Epoch 4/10, Batch 20/49, Loss: 0.4594
Epoch 4/10, Batch 30/49, Loss: 0.3659
Epoch 4/10, Batch 40/49, Loss: 0.3931
Epoch 4/10, Train Loss: 0.3686, Valid Loss: 0.3724
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3623
Epoch 5/10, Batch 20/49, Loss: 0.2422
Epoch 5/10, Batch 30/49, Loss: 0.2031
Epoch 5/10, Batch 40/49, Loss: 0.2992
Epoch 5/10, Train Loss: 0.3210, Valid Loss: 0.3596
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2325
Epoch 6/10, Batch 20/49, Loss: 0.2321
Epoch 6/10, Batch 30/49, Loss: 0.2020
Epoch 6/10, Batch 40/49, Loss: 0.3136
Epoch 6/10, Train Loss: 0.2986, Valid Loss: 0.3380
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2312
Epoch 7/10, Batch 20/49, Loss: 0.2962
Epoch 7/10, Batch 30/49, Loss: 0.2033
Epoch 7/10, Batch 40/49, Loss: 0.1364
Epoch 7/10, Train Loss: 0.2607, Valid Loss: 0.3556
Epoch 8/10, Batch 10/49, Loss: 0.2356
Epoch 8/10, Batch 20/49, Loss: 0.1717
Epoch 8/10, Batch 30/49, Loss: 0.2546
Epoch 8/10, Batch 40/49, Loss: 0.3087
Epoch 8/10, Train Loss: 0.2658, Valid Loss: 0.3419
Epoch 9/10, Batch 10/49, Loss: 0.2606
Epoch 9/10, Batch 20/49, Loss: 0.1856
Epoch 9/10, Batch 30/49, Loss: 0.2164
Epoch 9/10, Batch 40/49, Loss: 0.2646
Epoch 9/10, Train Loss: 0.2342, Valid Loss: 0.3185
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3324
Epoch 10/10, Batch 20/49, Loss: 0.1498
Epoch 10/10, Batch 30/49, Loss: 0.1354
Epoch 10/10, Batch 40/49, Loss: 0.1419
Epoch 10/10, Train Loss: 0.2118, Valid Loss: 0.3611
Accuracy: 0.9065
Precision: 0.9027
Recall: 0.9065
F1-score: 0.9037
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2206
Epoch 1/10, Batch 20/49, Loss: 1.1026
Epoch 1/10, Batch 30/49, Loss: 0.7896
Epoch 1/10, Batch 40/49, Loss: 0.8426
Epoch 1/10, Train Loss: 1.0066, Valid Loss: 0.6156
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5782
Epoch 2/10, Batch 20/49, Loss: 0.7011
Epoch 2/10, Batch 30/49, Loss: 0.5935
Epoch 2/10, Batch 40/49, Loss: 0.3762
Epoch 2/10, Train Loss: 0.5570, Valid Loss: 0.4212
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4774
Epoch 3/10, Batch 20/49, Loss: 0.2661
Epoch 3/10, Batch 30/49, Loss: 0.4201
Epoch 3/10, Batch 40/49, Loss: 0.3511
Epoch 3/10, Train Loss: 0.4268, Valid Loss: 0.3746
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4714
Epoch 4/10, Batch 20/49, Loss: 0.4909
Epoch 4/10, Batch 30/49, Loss: 0.3391
Epoch 4/10, Batch 40/49, Loss: 0.3556
Epoch 4/10, Train Loss: 0.3894, Valid Loss: 0.3225
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4965
Epoch 5/10, Batch 20/49, Loss: 0.2551
Epoch 5/10, Batch 30/49, Loss: 0.2701
Epoch 5/10, Batch 40/49, Loss: 0.2464
Epoch 5/10, Train Loss: 0.3374, Valid Loss: 0.2981
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3172
Epoch 6/10, Batch 20/49, Loss: 0.3725
Epoch 6/10, Batch 30/49, Loss: 0.3469
Epoch 6/10, Batch 40/49, Loss: 0.3135
Epoch 6/10, Train Loss: 0.3073, Valid Loss: 0.2829
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2161
Epoch 7/10, Batch 20/49, Loss: 0.4765
Epoch 7/10, Batch 30/49, Loss: 0.2637
Epoch 7/10, Batch 40/49, Loss: 0.1171
Epoch 7/10, Train Loss: 0.2827, Valid Loss: 0.2937
Epoch 8/10, Batch 10/49, Loss: 0.4016
Epoch 8/10, Batch 20/49, Loss: 0.2084
Epoch 8/10, Batch 30/49, Loss: 0.2100
Epoch 8/10, Batch 40/49, Loss: 0.1878
Epoch 8/10, Train Loss: 0.2697, Valid Loss: 0.2702
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2778
Epoch 9/10, Batch 20/49, Loss: 0.1614
Epoch 9/10, Batch 30/49, Loss: 0.3247
Epoch 9/10, Batch 40/49, Loss: 0.3348
Epoch 9/10, Train Loss: 0.2574, Valid Loss: 0.2555
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1734
Epoch 10/10, Batch 20/49, Loss: 0.1932
Epoch 10/10, Batch 30/49, Loss: 0.2693
Epoch 10/10, Batch 40/49, Loss: 0.2597
Epoch 10/10, Train Loss: 0.2253, Valid Loss: 0.2594
Accuracy: 0.9065
Precision: 0.9047
Recall: 0.9065
F1-score: 0.9033
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3161
Epoch 1/10, Batch 20/49, Loss: 1.1103
Epoch 1/10, Batch 30/49, Loss: 0.8519
Epoch 1/10, Batch 40/49, Loss: 0.8624
Epoch 1/10, Train Loss: 1.0363, Valid Loss: 0.6258
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5771
Epoch 2/10, Batch 20/49, Loss: 0.7258
Epoch 2/10, Batch 30/49, Loss: 0.4451
Epoch 2/10, Batch 40/49, Loss: 0.5094
Epoch 2/10, Train Loss: 0.5580, Valid Loss: 0.4278
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3783
Epoch 3/10, Batch 20/49, Loss: 0.3073
Epoch 3/10, Batch 30/49, Loss: 0.4222
Epoch 3/10, Batch 40/49, Loss: 0.3712
Epoch 3/10, Train Loss: 0.4265, Valid Loss: 0.3830
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2969
Epoch 4/10, Batch 20/49, Loss: 0.3208
Epoch 4/10, Batch 30/49, Loss: 0.3124
Epoch 4/10, Batch 40/49, Loss: 0.4469
Epoch 4/10, Train Loss: 0.3697, Valid Loss: 0.3032
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4818
Epoch 5/10, Batch 20/49, Loss: 0.2484
Epoch 5/10, Batch 30/49, Loss: 0.3899
Epoch 5/10, Batch 40/49, Loss: 0.4109
Epoch 5/10, Train Loss: 0.3240, Valid Loss: 0.2773
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2576
Epoch 6/10, Batch 20/49, Loss: 0.2821
Epoch 6/10, Batch 30/49, Loss: 0.2711
Epoch 6/10, Batch 40/49, Loss: 0.2715
Epoch 6/10, Train Loss: 0.2887, Valid Loss: 0.2602
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2128
Epoch 7/10, Batch 20/49, Loss: 0.3636
Epoch 7/10, Batch 30/49, Loss: 0.1680
Epoch 7/10, Batch 40/49, Loss: 0.1722
Epoch 7/10, Train Loss: 0.2563, Valid Loss: 0.2607
Epoch 8/10, Batch 10/49, Loss: 0.3499
Epoch 8/10, Batch 20/49, Loss: 0.1342
Epoch 8/10, Batch 30/49, Loss: 0.2209
Epoch 8/10, Batch 40/49, Loss: 0.2415
Epoch 8/10, Train Loss: 0.2424, Valid Loss: 0.2513
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2749
Epoch 9/10, Batch 20/49, Loss: 0.1156
Epoch 9/10, Batch 30/49, Loss: 0.3544
Epoch 9/10, Batch 40/49, Loss: 0.1962
Epoch 9/10, Train Loss: 0.2361, Valid Loss: 0.2285
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2606
Epoch 10/10, Batch 20/49, Loss: 0.2055
Epoch 10/10, Batch 30/49, Loss: 0.1935
Epoch 10/10, Batch 40/49, Loss: 0.1259
Epoch 10/10, Train Loss: 0.2281, Valid Loss: 0.2360
Accuracy: 0.9065
Precision: 0.9048
Recall: 0.9065
F1-score: 0.9018
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2025
Epoch 1/10, Batch 20/49, Loss: 1.1285
Epoch 1/10, Batch 30/49, Loss: 0.7922
Epoch 1/10, Batch 40/49, Loss: 0.8470
Epoch 1/10, Train Loss: 1.0044, Valid Loss: 0.6013
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5648
Epoch 2/10, Batch 20/49, Loss: 0.6102
Epoch 2/10, Batch 30/49, Loss: 0.4538
Epoch 2/10, Batch 40/49, Loss: 0.3930
Epoch 2/10, Train Loss: 0.5534, Valid Loss: 0.4132
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3853
Epoch 3/10, Batch 20/49, Loss: 0.4126
Epoch 3/10, Batch 30/49, Loss: 0.4215
Epoch 3/10, Batch 40/49, Loss: 0.4251
Epoch 3/10, Train Loss: 0.4231, Valid Loss: 0.3537
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4010
Epoch 4/10, Batch 20/49, Loss: 0.3617
Epoch 4/10, Batch 30/49, Loss: 0.4169
Epoch 4/10, Batch 40/49, Loss: 0.4445
Epoch 4/10, Train Loss: 0.3791, Valid Loss: 0.3233
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4833
Epoch 5/10, Batch 20/49, Loss: 0.2065
Epoch 5/10, Batch 30/49, Loss: 0.2252
Epoch 5/10, Batch 40/49, Loss: 0.3363
Epoch 5/10, Train Loss: 0.3367, Valid Loss: 0.2963
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2755
Epoch 6/10, Batch 20/49, Loss: 0.2588
Epoch 6/10, Batch 30/49, Loss: 0.2441
Epoch 6/10, Batch 40/49, Loss: 0.3793
Epoch 6/10, Train Loss: 0.2948, Valid Loss: 0.2779
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2573
Epoch 7/10, Batch 20/49, Loss: 0.3310
Epoch 7/10, Batch 30/49, Loss: 0.1796
Epoch 7/10, Batch 40/49, Loss: 0.1880
Epoch 7/10, Train Loss: 0.2734, Valid Loss: 0.2862
Epoch 8/10, Batch 10/49, Loss: 0.3167
Epoch 8/10, Batch 20/49, Loss: 0.1964
Epoch 8/10, Batch 30/49, Loss: 0.2407
Epoch 8/10, Batch 40/49, Loss: 0.1551
Epoch 8/10, Train Loss: 0.2613, Valid Loss: 0.2636
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3087
Epoch 9/10, Batch 20/49, Loss: 0.1312
Epoch 9/10, Batch 30/49, Loss: 0.3143
Epoch 9/10, Batch 40/49, Loss: 0.2560
Epoch 9/10, Train Loss: 0.2436, Valid Loss: 0.2534
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2390
Epoch 10/10, Batch 20/49, Loss: 0.1841
Epoch 10/10, Batch 30/49, Loss: 0.1384
Epoch 10/10, Batch 40/49, Loss: 0.1683
Epoch 10/10, Train Loss: 0.2222, Valid Loss: 0.2439
Model saved!
Accuracy: 0.9030
Precision: 0.8992
Recall: 0.9030
F1-score: 0.9000
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2359
Epoch 1/10, Batch 20/49, Loss: 1.1682
Epoch 1/10, Batch 30/49, Loss: 0.9399
Epoch 1/10, Batch 40/49, Loss: 0.7305
Epoch 1/10, Train Loss: 1.0072, Valid Loss: 0.6271
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6578
Epoch 2/10, Batch 20/49, Loss: 0.6091
Epoch 2/10, Batch 30/49, Loss: 0.4242
Epoch 2/10, Batch 40/49, Loss: 0.4563
Epoch 2/10, Train Loss: 0.5492, Valid Loss: 0.4344
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3855
Epoch 3/10, Batch 20/49, Loss: 0.3270
Epoch 3/10, Batch 30/49, Loss: 0.4354
Epoch 3/10, Batch 40/49, Loss: 0.5608
Epoch 3/10, Train Loss: 0.4185, Valid Loss: 0.3689
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3657
Epoch 4/10, Batch 20/49, Loss: 0.3718
Epoch 4/10, Batch 30/49, Loss: 0.3636
Epoch 4/10, Batch 40/49, Loss: 0.4291
Epoch 4/10, Train Loss: 0.3737, Valid Loss: 0.3280
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4517
Epoch 5/10, Batch 20/49, Loss: 0.2691
Epoch 5/10, Batch 30/49, Loss: 0.2339
Epoch 5/10, Batch 40/49, Loss: 0.2574
Epoch 5/10, Train Loss: 0.3269, Valid Loss: 0.3032
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2241
Epoch 6/10, Batch 20/49, Loss: 0.2273
Epoch 6/10, Batch 30/49, Loss: 0.1808
Epoch 6/10, Batch 40/49, Loss: 0.2937
Epoch 6/10, Train Loss: 0.2976, Valid Loss: 0.2831
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3164
Epoch 7/10, Batch 20/49, Loss: 0.2762
Epoch 7/10, Batch 30/49, Loss: 0.4170
Epoch 7/10, Batch 40/49, Loss: 0.1459
Epoch 7/10, Train Loss: 0.2581, Valid Loss: 0.2843
Epoch 8/10, Batch 10/49, Loss: 0.2560
Epoch 8/10, Batch 20/49, Loss: 0.1886
Epoch 8/10, Batch 30/49, Loss: 0.1701
Epoch 8/10, Batch 40/49, Loss: 0.2361
Epoch 8/10, Train Loss: 0.2649, Valid Loss: 0.2660
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3498
Epoch 9/10, Batch 20/49, Loss: 0.1439
Epoch 9/10, Batch 30/49, Loss: 0.2009
Epoch 9/10, Batch 40/49, Loss: 0.2767
Epoch 9/10, Train Loss: 0.2328, Valid Loss: 0.2493
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2257
Epoch 10/10, Batch 20/49, Loss: 0.2537
Epoch 10/10, Batch 30/49, Loss: 0.1388
Epoch 10/10, Batch 40/49, Loss: 0.2572
Epoch 10/10, Train Loss: 0.2190, Valid Loss: 0.2471
Model saved!
Accuracy: 0.9089
Precision: 0.9058
Recall: 0.9089
F1-score: 0.9065
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2577
Epoch 1/10, Batch 20/49, Loss: 1.1213
Epoch 1/10, Batch 30/49, Loss: 0.8637
Epoch 1/10, Batch 40/49, Loss: 0.8279
Epoch 1/10, Train Loss: 1.0064, Valid Loss: 0.6242
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5297
Epoch 2/10, Batch 20/49, Loss: 0.7009
Epoch 2/10, Batch 30/49, Loss: 0.6286
Epoch 2/10, Batch 40/49, Loss: 0.4091
Epoch 2/10, Train Loss: 0.5531, Valid Loss: 0.4308
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4022
Epoch 3/10, Batch 20/49, Loss: 0.3496
Epoch 3/10, Batch 30/49, Loss: 0.3997
Epoch 3/10, Batch 40/49, Loss: 0.5144
Epoch 3/10, Train Loss: 0.4168, Valid Loss: 0.3779
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3641
Epoch 4/10, Batch 20/49, Loss: 0.3222
Epoch 4/10, Batch 30/49, Loss: 0.2959
Epoch 4/10, Batch 40/49, Loss: 0.4068
Epoch 4/10, Train Loss: 0.3743, Valid Loss: 0.3356
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4074
Epoch 5/10, Batch 20/49, Loss: 0.2364
Epoch 5/10, Batch 30/49, Loss: 0.2857
Epoch 5/10, Batch 40/49, Loss: 0.2706
Epoch 5/10, Train Loss: 0.3296, Valid Loss: 0.3016
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3602
Epoch 6/10, Batch 20/49, Loss: 0.2800
Epoch 6/10, Batch 30/49, Loss: 0.2194
Epoch 6/10, Batch 40/49, Loss: 0.2649
Epoch 6/10, Train Loss: 0.2981, Valid Loss: 0.2784
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1759
Epoch 7/10, Batch 20/49, Loss: 0.3945
Epoch 7/10, Batch 30/49, Loss: 0.3343
Epoch 7/10, Batch 40/49, Loss: 0.1733
Epoch 7/10, Train Loss: 0.2658, Valid Loss: 0.2825
Epoch 8/10, Batch 10/49, Loss: 0.3053
Epoch 8/10, Batch 20/49, Loss: 0.2057
Epoch 8/10, Batch 30/49, Loss: 0.2172
Epoch 8/10, Batch 40/49, Loss: 0.1964
Epoch 8/10, Train Loss: 0.2540, Valid Loss: 0.2734
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1572
Epoch 9/10, Batch 20/49, Loss: 0.1926
Epoch 9/10, Batch 30/49, Loss: 0.2732
Epoch 9/10, Batch 40/49, Loss: 0.3310
Epoch 9/10, Train Loss: 0.2327, Valid Loss: 0.2538
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1678
Epoch 10/10, Batch 20/49, Loss: 0.2039
Epoch 10/10, Batch 30/49, Loss: 0.1861
Epoch 10/10, Batch 40/49, Loss: 0.1445
Epoch 10/10, Train Loss: 0.2204, Valid Loss: 0.2643
Accuracy: 0.9089
Precision: 0.9075
Recall: 0.9089
F1-score: 0.9040
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2855
Epoch 1/10, Batch 20/49, Loss: 1.0969
Epoch 1/10, Batch 30/49, Loss: 0.8583
Epoch 1/10, Batch 40/49, Loss: 0.9012
Epoch 1/10, Train Loss: 1.0172, Valid Loss: 0.5686
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5768
Epoch 2/10, Batch 20/49, Loss: 0.7642
Epoch 2/10, Batch 30/49, Loss: 0.4855
Epoch 2/10, Batch 40/49, Loss: 0.5190
Epoch 2/10, Train Loss: 0.5650, Valid Loss: 0.3816
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3594
Epoch 3/10, Batch 20/49, Loss: 0.3493
Epoch 3/10, Batch 30/49, Loss: 0.4901
Epoch 3/10, Batch 40/49, Loss: 0.4406
Epoch 3/10, Train Loss: 0.4299, Valid Loss: 0.3336
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3287
Epoch 4/10, Batch 20/49, Loss: 0.4681
Epoch 4/10, Batch 30/49, Loss: 0.3887
Epoch 4/10, Batch 40/49, Loss: 0.5031
Epoch 4/10, Train Loss: 0.3936, Valid Loss: 0.2782
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3711
Epoch 5/10, Batch 20/49, Loss: 0.2120
Epoch 5/10, Batch 30/49, Loss: 0.2520
Epoch 5/10, Batch 40/49, Loss: 0.2647
Epoch 5/10, Train Loss: 0.3321, Valid Loss: 0.2565
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.4495
Epoch 6/10, Batch 20/49, Loss: 0.2719
Epoch 6/10, Batch 30/49, Loss: 0.2787
Epoch 6/10, Batch 40/49, Loss: 0.3419
Epoch 6/10, Train Loss: 0.3133, Valid Loss: 0.2393
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2942
Epoch 7/10, Batch 20/49, Loss: 0.3004
Epoch 7/10, Batch 30/49, Loss: 0.2137
Epoch 7/10, Batch 40/49, Loss: 0.1434
Epoch 7/10, Train Loss: 0.2742, Valid Loss: 0.2400
Epoch 8/10, Batch 10/49, Loss: 0.2614
Epoch 8/10, Batch 20/49, Loss: 0.1953
Epoch 8/10, Batch 30/49, Loss: 0.2750
Epoch 8/10, Batch 40/49, Loss: 0.2024
Epoch 8/10, Train Loss: 0.2681, Valid Loss: 0.2317
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1742
Epoch 9/10, Batch 20/49, Loss: 0.1689
Epoch 9/10, Batch 30/49, Loss: 0.3107
Epoch 9/10, Batch 40/49, Loss: 0.3247
Epoch 9/10, Train Loss: 0.2462, Valid Loss: 0.2148
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3376
Epoch 10/10, Batch 20/49, Loss: 0.2449
Epoch 10/10, Batch 30/49, Loss: 0.1880
Epoch 10/10, Batch 40/49, Loss: 0.1727
Epoch 10/10, Train Loss: 0.2405, Valid Loss: 0.2131
Model saved!
Accuracy: 0.9065
Precision: 0.9031
Recall: 0.9065
F1-score: 0.9034
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2646
Epoch 1/10, Batch 20/49, Loss: 1.2260
Epoch 1/10, Batch 30/49, Loss: 0.9391
Epoch 1/10, Batch 40/49, Loss: 0.7172
Epoch 1/10, Train Loss: 1.0099, Valid Loss: 0.6320
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6870
Epoch 2/10, Batch 20/49, Loss: 0.6174
Epoch 2/10, Batch 30/49, Loss: 0.4008
Epoch 2/10, Batch 40/49, Loss: 0.5069
Epoch 2/10, Train Loss: 0.5375, Valid Loss: 0.4437
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4398
Epoch 3/10, Batch 20/49, Loss: 0.4630
Epoch 3/10, Batch 30/49, Loss: 0.3924
Epoch 3/10, Batch 40/49, Loss: 0.5107
Epoch 3/10, Train Loss: 0.4191, Valid Loss: 0.3988
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3154
Epoch 4/10, Batch 20/49, Loss: 0.2530
Epoch 4/10, Batch 30/49, Loss: 0.2672
Epoch 4/10, Batch 40/49, Loss: 0.4918
Epoch 4/10, Train Loss: 0.3688, Valid Loss: 0.3496
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5180
Epoch 5/10, Batch 20/49, Loss: 0.1617
Epoch 5/10, Batch 30/49, Loss: 0.1931
Epoch 5/10, Batch 40/49, Loss: 0.3463
Epoch 5/10, Train Loss: 0.3391, Valid Loss: 0.3283
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2861
Epoch 6/10, Batch 20/49, Loss: 0.2509
Epoch 6/10, Batch 30/49, Loss: 0.3309
Epoch 6/10, Batch 40/49, Loss: 0.3964
Epoch 6/10, Train Loss: 0.2941, Valid Loss: 0.3044
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.4125
Epoch 7/10, Batch 20/49, Loss: 0.3494
Epoch 7/10, Batch 30/49, Loss: 0.1793
Epoch 7/10, Batch 40/49, Loss: 0.2215
Epoch 7/10, Train Loss: 0.2642, Valid Loss: 0.3184
Epoch 8/10, Batch 10/49, Loss: 0.3253
Epoch 8/10, Batch 20/49, Loss: 0.1840
Epoch 8/10, Batch 30/49, Loss: 0.2473
Epoch 8/10, Batch 40/49, Loss: 0.1585
Epoch 8/10, Train Loss: 0.2616, Valid Loss: 0.2931
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2925
Epoch 9/10, Batch 20/49, Loss: 0.1613
Epoch 9/10, Batch 30/49, Loss: 0.1966
Epoch 9/10, Batch 40/49, Loss: 0.2916
Epoch 9/10, Train Loss: 0.2332, Valid Loss: 0.2929
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2657
Epoch 10/10, Batch 20/49, Loss: 0.1449
Epoch 10/10, Batch 30/49, Loss: 0.1535
Epoch 10/10, Batch 40/49, Loss: 0.2662
Epoch 10/10, Train Loss: 0.2150, Valid Loss: 0.2893
Model saved!
Accuracy: 0.9065
Precision: 0.9027
Recall: 0.9065
F1-score: 0.9022
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2446
Epoch 1/10, Batch 20/49, Loss: 1.1422
Epoch 1/10, Batch 30/49, Loss: 0.8708
Epoch 1/10, Batch 40/49, Loss: 0.7455
Epoch 1/10, Train Loss: 1.0164, Valid Loss: 0.6565
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6137
Epoch 2/10, Batch 20/49, Loss: 0.6534
Epoch 2/10, Batch 30/49, Loss: 0.4396
Epoch 2/10, Batch 40/49, Loss: 0.4003
Epoch 2/10, Train Loss: 0.5408, Valid Loss: 0.4571
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3378
Epoch 3/10, Batch 20/49, Loss: 0.3515
Epoch 3/10, Batch 30/49, Loss: 0.3387
Epoch 3/10, Batch 40/49, Loss: 0.4626
Epoch 3/10, Train Loss: 0.4148, Valid Loss: 0.4114
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3515
Epoch 4/10, Batch 20/49, Loss: 0.3173
Epoch 4/10, Batch 30/49, Loss: 0.2686
Epoch 4/10, Batch 40/49, Loss: 0.3248
Epoch 4/10, Train Loss: 0.3543, Valid Loss: 0.3655
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3280
Epoch 5/10, Batch 20/49, Loss: 0.2688
Epoch 5/10, Batch 30/49, Loss: 0.2638
Epoch 5/10, Batch 40/49, Loss: 0.2017
Epoch 5/10, Train Loss: 0.3148, Valid Loss: 0.3420
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2549
Epoch 6/10, Batch 20/49, Loss: 0.1379
Epoch 6/10, Batch 30/49, Loss: 0.2769
Epoch 6/10, Batch 40/49, Loss: 0.3104
Epoch 6/10, Train Loss: 0.2835, Valid Loss: 0.3106
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2107
Epoch 7/10, Batch 20/49, Loss: 0.1772
Epoch 7/10, Batch 30/49, Loss: 0.1938
Epoch 7/10, Batch 40/49, Loss: 0.2026
Epoch 7/10, Train Loss: 0.2496, Valid Loss: 0.3252
Epoch 8/10, Batch 10/49, Loss: 0.3850
Epoch 8/10, Batch 20/49, Loss: 0.1382
Epoch 8/10, Batch 30/49, Loss: 0.2416
Epoch 8/10, Batch 40/49, Loss: 0.1728
Epoch 8/10, Train Loss: 0.2408, Valid Loss: 0.3134
Epoch 9/10, Batch 10/49, Loss: 0.1634
Epoch 9/10, Batch 20/49, Loss: 0.1134
Epoch 9/10, Batch 30/49, Loss: 0.2830
Epoch 9/10, Batch 40/49, Loss: 0.2087
Epoch 9/10, Train Loss: 0.2298, Valid Loss: 0.2987
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3420
Epoch 10/10, Batch 20/49, Loss: 0.2505
Epoch 10/10, Batch 30/49, Loss: 0.2382
Epoch 10/10, Batch 40/49, Loss: 0.2304
Epoch 10/10, Train Loss: 0.2075, Valid Loss: 0.2887
Model saved!
Accuracy: 0.9042
Precision: 0.9006
Recall: 0.9042
F1-score: 0.9010
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1918
Epoch 1/10, Batch 20/49, Loss: 1.1494
Epoch 1/10, Batch 30/49, Loss: 0.8747
Epoch 1/10, Batch 40/49, Loss: 0.8832
Epoch 1/10, Train Loss: 1.0242, Valid Loss: 0.6439
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5736
Epoch 2/10, Batch 20/49, Loss: 0.6928
Epoch 2/10, Batch 30/49, Loss: 0.5597
Epoch 2/10, Batch 40/49, Loss: 0.4301
Epoch 2/10, Train Loss: 0.5610, Valid Loss: 0.4499
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3930
Epoch 3/10, Batch 20/49, Loss: 0.3420
Epoch 3/10, Batch 30/49, Loss: 0.4974
Epoch 3/10, Batch 40/49, Loss: 0.4437
Epoch 3/10, Train Loss: 0.4234, Valid Loss: 0.3781
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.5374
Epoch 4/10, Batch 20/49, Loss: 0.2777
Epoch 4/10, Batch 30/49, Loss: 0.4665
Epoch 4/10, Batch 40/49, Loss: 0.4448
Epoch 4/10, Train Loss: 0.3855, Valid Loss: 0.3474
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3584
Epoch 5/10, Batch 20/49, Loss: 0.2118
Epoch 5/10, Batch 30/49, Loss: 0.1886
Epoch 5/10, Batch 40/49, Loss: 0.2579
Epoch 5/10, Train Loss: 0.3404, Valid Loss: 0.3258
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3222
Epoch 6/10, Batch 20/49, Loss: 0.2023
Epoch 6/10, Batch 30/49, Loss: 0.4477
Epoch 6/10, Batch 40/49, Loss: 0.3859
Epoch 6/10, Train Loss: 0.3134, Valid Loss: 0.3238
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2036
Epoch 7/10, Batch 20/49, Loss: 0.4456
Epoch 7/10, Batch 30/49, Loss: 0.1896
Epoch 7/10, Batch 40/49, Loss: 0.1403
Epoch 7/10, Train Loss: 0.2703, Valid Loss: 0.2985
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3261
Epoch 8/10, Batch 20/49, Loss: 0.2051
Epoch 8/10, Batch 30/49, Loss: 0.1979
Epoch 8/10, Batch 40/49, Loss: 0.3927
Epoch 8/10, Train Loss: 0.2613, Valid Loss: 0.2889
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2152
Epoch 9/10, Batch 20/49, Loss: 0.1217
Epoch 9/10, Batch 30/49, Loss: 0.3940
Epoch 9/10, Batch 40/49, Loss: 0.2471
Epoch 9/10, Train Loss: 0.2479, Valid Loss: 0.2753
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2790
Epoch 10/10, Batch 20/49, Loss: 0.3198
Epoch 10/10, Batch 30/49, Loss: 0.2449
Epoch 10/10, Batch 40/49, Loss: 0.2783
Epoch 10/10, Train Loss: 0.2325, Valid Loss: 0.2746
Model saved!
Accuracy: 0.9100
Precision: 0.9074
Recall: 0.9100
F1-score: 0.9077
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3024
Epoch 1/10, Batch 20/49, Loss: 1.0945
Epoch 1/10, Batch 30/49, Loss: 0.8145
Epoch 1/10, Batch 40/49, Loss: 0.9031
Epoch 1/10, Train Loss: 1.0181, Valid Loss: 0.6239
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7197
Epoch 2/10, Batch 20/49, Loss: 0.6337
Epoch 2/10, Batch 30/49, Loss: 0.5918
Epoch 2/10, Batch 40/49, Loss: 0.5253
Epoch 2/10, Train Loss: 0.5568, Valid Loss: 0.4212
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3435
Epoch 3/10, Batch 20/49, Loss: 0.2664
Epoch 3/10, Batch 30/49, Loss: 0.5239
Epoch 3/10, Batch 40/49, Loss: 0.3897
Epoch 3/10, Train Loss: 0.4179, Valid Loss: 0.3629
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3735
Epoch 4/10, Batch 20/49, Loss: 0.4110
Epoch 4/10, Batch 30/49, Loss: 0.4011
Epoch 4/10, Batch 40/49, Loss: 0.5591
Epoch 4/10, Train Loss: 0.3757, Valid Loss: 0.3227
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3296
Epoch 5/10, Batch 20/49, Loss: 0.3959
Epoch 5/10, Batch 30/49, Loss: 0.1591
Epoch 5/10, Batch 40/49, Loss: 0.3712
Epoch 5/10, Train Loss: 0.3232, Valid Loss: 0.3026
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3000
Epoch 6/10, Batch 20/49, Loss: 0.1778
Epoch 6/10, Batch 30/49, Loss: 0.2825
Epoch 6/10, Batch 40/49, Loss: 0.3065
Epoch 6/10, Train Loss: 0.2978, Valid Loss: 0.2868
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2070
Epoch 7/10, Batch 20/49, Loss: 0.3407
Epoch 7/10, Batch 30/49, Loss: 0.2116
Epoch 7/10, Batch 40/49, Loss: 0.2842
Epoch 7/10, Train Loss: 0.2609, Valid Loss: 0.2698
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2830
Epoch 8/10, Batch 20/49, Loss: 0.2344
Epoch 8/10, Batch 30/49, Loss: 0.1791
Epoch 8/10, Batch 40/49, Loss: 0.1668
Epoch 8/10, Train Loss: 0.2476, Valid Loss: 0.2652
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1387
Epoch 9/10, Batch 20/49, Loss: 0.2098
Epoch 9/10, Batch 30/49, Loss: 0.3550
Epoch 9/10, Batch 40/49, Loss: 0.1265
Epoch 9/10, Train Loss: 0.2303, Valid Loss: 0.2564
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2149
Epoch 10/10, Batch 20/49, Loss: 0.3200
Epoch 10/10, Batch 30/49, Loss: 0.1068
Epoch 10/10, Batch 40/49, Loss: 0.1570
Epoch 10/10, Train Loss: 0.2210, Valid Loss: 0.2505
Model saved!
Accuracy: 0.9100
Precision: 0.9074
Recall: 0.9100
F1-score: 0.9076
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2760
Epoch 1/10, Batch 20/49, Loss: 1.1263
Epoch 1/10, Batch 30/49, Loss: 0.9093
Epoch 1/10, Batch 40/49, Loss: 0.8672
Epoch 1/10, Train Loss: 1.0143, Valid Loss: 0.6163
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5704
Epoch 2/10, Batch 20/49, Loss: 0.5216
Epoch 2/10, Batch 30/49, Loss: 0.5346
Epoch 2/10, Batch 40/49, Loss: 0.4489
Epoch 2/10, Train Loss: 0.5467, Valid Loss: 0.4255
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5159
Epoch 3/10, Batch 20/49, Loss: 0.3279
Epoch 3/10, Batch 30/49, Loss: 0.3949
Epoch 3/10, Batch 40/49, Loss: 0.4685
Epoch 3/10, Train Loss: 0.4128, Valid Loss: 0.3497
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3223
Epoch 4/10, Batch 20/49, Loss: 0.4267
Epoch 4/10, Batch 30/49, Loss: 0.3849
Epoch 4/10, Batch 40/49, Loss: 0.3936
Epoch 4/10, Train Loss: 0.3603, Valid Loss: 0.2973
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2873
Epoch 5/10, Batch 20/49, Loss: 0.3431
Epoch 5/10, Batch 30/49, Loss: 0.2846
Epoch 5/10, Batch 40/49, Loss: 0.2421
Epoch 5/10, Train Loss: 0.3176, Valid Loss: 0.2760
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.4220
Epoch 6/10, Batch 20/49, Loss: 0.2853
Epoch 6/10, Batch 30/49, Loss: 0.2282
Epoch 6/10, Batch 40/49, Loss: 0.4315
Epoch 6/10, Train Loss: 0.2971, Valid Loss: 0.2459
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2256
Epoch 7/10, Batch 20/49, Loss: 0.2626
Epoch 7/10, Batch 30/49, Loss: 0.2479
Epoch 7/10, Batch 40/49, Loss: 0.2796
Epoch 7/10, Train Loss: 0.2559, Valid Loss: 0.2630
Epoch 8/10, Batch 10/49, Loss: 0.2132
Epoch 8/10, Batch 20/49, Loss: 0.2489
Epoch 8/10, Batch 30/49, Loss: 0.2184
Epoch 8/10, Batch 40/49, Loss: 0.1562
Epoch 8/10, Train Loss: 0.2520, Valid Loss: 0.2347
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2031
Epoch 9/10, Batch 20/49, Loss: 0.2394
Epoch 9/10, Batch 30/49, Loss: 0.2965
Epoch 9/10, Batch 40/49, Loss: 0.3976
Epoch 9/10, Train Loss: 0.2380, Valid Loss: 0.2207
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2942
Epoch 10/10, Batch 20/49, Loss: 0.2866
Epoch 10/10, Batch 30/49, Loss: 0.2014
Epoch 10/10, Batch 40/49, Loss: 0.2548
Epoch 10/10, Train Loss: 0.2210, Valid Loss: 0.2169
Model saved!
Accuracy: 0.9077
Precision: 0.9052
Recall: 0.9077
F1-score: 0.9046
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1948
Epoch 1/10, Batch 20/49, Loss: 1.0955
Epoch 1/10, Batch 30/49, Loss: 0.7429
Epoch 1/10, Batch 40/49, Loss: 0.8935
Epoch 1/10, Train Loss: 1.0313, Valid Loss: 0.6440
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6152
Epoch 2/10, Batch 20/49, Loss: 0.6850
Epoch 2/10, Batch 30/49, Loss: 0.4232
Epoch 2/10, Batch 40/49, Loss: 0.4346
Epoch 2/10, Train Loss: 0.5517, Valid Loss: 0.4509
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4153
Epoch 3/10, Batch 20/49, Loss: 0.3656
Epoch 3/10, Batch 30/49, Loss: 0.4337
Epoch 3/10, Batch 40/49, Loss: 0.3368
Epoch 3/10, Train Loss: 0.4245, Valid Loss: 0.3819
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3563
Epoch 4/10, Batch 20/49, Loss: 0.4737
Epoch 4/10, Batch 30/49, Loss: 0.4216
Epoch 4/10, Batch 40/49, Loss: 0.4477
Epoch 4/10, Train Loss: 0.3822, Valid Loss: 0.3331
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4166
Epoch 5/10, Batch 20/49, Loss: 0.1938
Epoch 5/10, Batch 30/49, Loss: 0.2415
Epoch 5/10, Batch 40/49, Loss: 0.2578
Epoch 5/10, Train Loss: 0.3305, Valid Loss: 0.3158
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3918
Epoch 6/10, Batch 20/49, Loss: 0.1903
Epoch 6/10, Batch 30/49, Loss: 0.1646
Epoch 6/10, Batch 40/49, Loss: 0.2968
Epoch 6/10, Train Loss: 0.3029, Valid Loss: 0.2843
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2657
Epoch 7/10, Batch 20/49, Loss: 0.3756
Epoch 7/10, Batch 30/49, Loss: 0.3520
Epoch 7/10, Batch 40/49, Loss: 0.2197
Epoch 7/10, Train Loss: 0.2691, Valid Loss: 0.2853
Epoch 8/10, Batch 10/49, Loss: 0.2860
Epoch 8/10, Batch 20/49, Loss: 0.2188
Epoch 8/10, Batch 30/49, Loss: 0.1909
Epoch 8/10, Batch 40/49, Loss: 0.2227
Epoch 8/10, Train Loss: 0.2507, Valid Loss: 0.2789
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1975
Epoch 9/10, Batch 20/49, Loss: 0.1494
Epoch 9/10, Batch 30/49, Loss: 0.1870
Epoch 9/10, Batch 40/49, Loss: 0.2856
Epoch 9/10, Train Loss: 0.2444, Valid Loss: 0.2570
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2375
Epoch 10/10, Batch 20/49, Loss: 0.2826
Epoch 10/10, Batch 30/49, Loss: 0.2372
Epoch 10/10, Batch 40/49, Loss: 0.1855
Epoch 10/10, Train Loss: 0.2255, Valid Loss: 0.2681
Accuracy: 0.9100
Precision: 0.9069
Recall: 0.9100
F1-score: 0.9071
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2657
Epoch 1/10, Batch 20/49, Loss: 1.1891
Epoch 1/10, Batch 30/49, Loss: 0.8806
Epoch 1/10, Batch 40/49, Loss: 0.7846
Epoch 1/10, Train Loss: 1.0190, Valid Loss: 0.6533
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5573
Epoch 2/10, Batch 20/49, Loss: 0.7057
Epoch 2/10, Batch 30/49, Loss: 0.4270
Epoch 2/10, Batch 40/49, Loss: 0.5098
Epoch 2/10, Train Loss: 0.5407, Valid Loss: 0.4650
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4785
Epoch 3/10, Batch 20/49, Loss: 0.3937
Epoch 3/10, Batch 30/49, Loss: 0.4001
Epoch 3/10, Batch 40/49, Loss: 0.3653
Epoch 3/10, Train Loss: 0.4052, Valid Loss: 0.4066
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3361
Epoch 4/10, Batch 20/49, Loss: 0.3505
Epoch 4/10, Batch 30/49, Loss: 0.3533
Epoch 4/10, Batch 40/49, Loss: 0.2886
Epoch 4/10, Train Loss: 0.3560, Valid Loss: 0.3593
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4513
Epoch 5/10, Batch 20/49, Loss: 0.1982
Epoch 5/10, Batch 30/49, Loss: 0.3119
Epoch 5/10, Batch 40/49, Loss: 0.2868
Epoch 5/10, Train Loss: 0.3110, Valid Loss: 0.3320
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2592
Epoch 6/10, Batch 20/49, Loss: 0.1427
Epoch 6/10, Batch 30/49, Loss: 0.2591
Epoch 6/10, Batch 40/49, Loss: 0.1808
Epoch 6/10, Train Loss: 0.2915, Valid Loss: 0.3087
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2057
Epoch 7/10, Batch 20/49, Loss: 0.3387
Epoch 7/10, Batch 30/49, Loss: 0.2346
Epoch 7/10, Batch 40/49, Loss: 0.1293
Epoch 7/10, Train Loss: 0.2485, Valid Loss: 0.3006
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2254
Epoch 8/10, Batch 20/49, Loss: 0.1460
Epoch 8/10, Batch 30/49, Loss: 0.2498
Epoch 8/10, Batch 40/49, Loss: 0.2349
Epoch 8/10, Train Loss: 0.2450, Valid Loss: 0.2965
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2511
Epoch 9/10, Batch 20/49, Loss: 0.1483
Epoch 9/10, Batch 30/49, Loss: 0.3273
Epoch 9/10, Batch 40/49, Loss: 0.3154
Epoch 9/10, Train Loss: 0.2220, Valid Loss: 0.2832
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3229
Epoch 10/10, Batch 20/49, Loss: 0.2234
Epoch 10/10, Batch 30/49, Loss: 0.1175
Epoch 10/10, Batch 40/49, Loss: 0.1105
Epoch 10/10, Train Loss: 0.2060, Valid Loss: 0.2782
Model saved!
Accuracy: 0.9077
Precision: 0.9047
Recall: 0.9077
F1-score: 0.9054
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2569
Epoch 1/10, Batch 20/49, Loss: 1.1857
Epoch 1/10, Batch 30/49, Loss: 0.8616
Epoch 1/10, Batch 40/49, Loss: 0.7615
Epoch 1/10, Train Loss: 1.0176, Valid Loss: 0.6183
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7926
Epoch 2/10, Batch 20/49, Loss: 0.6421
Epoch 2/10, Batch 30/49, Loss: 0.4766
Epoch 2/10, Batch 40/49, Loss: 0.4820
Epoch 2/10, Train Loss: 0.5682, Valid Loss: 0.4458
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5316
Epoch 3/10, Batch 20/49, Loss: 0.3289
Epoch 3/10, Batch 30/49, Loss: 0.4411
Epoch 3/10, Batch 40/49, Loss: 0.2873
Epoch 3/10, Train Loss: 0.4292, Valid Loss: 0.3857
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3727
Epoch 4/10, Batch 20/49, Loss: 0.3814
Epoch 4/10, Batch 30/49, Loss: 0.2953
Epoch 4/10, Batch 40/49, Loss: 0.5791
Epoch 4/10, Train Loss: 0.3872, Valid Loss: 0.3427
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5286
Epoch 5/10, Batch 20/49, Loss: 0.2525
Epoch 5/10, Batch 30/49, Loss: 0.3526
Epoch 5/10, Batch 40/49, Loss: 0.2095
Epoch 5/10, Train Loss: 0.3510, Valid Loss: 0.3125
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3108
Epoch 6/10, Batch 20/49, Loss: 0.2165
Epoch 6/10, Batch 30/49, Loss: 0.2616
Epoch 6/10, Batch 40/49, Loss: 0.3298
Epoch 6/10, Train Loss: 0.3120, Valid Loss: 0.2998
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3032
Epoch 7/10, Batch 20/49, Loss: 0.3210
Epoch 7/10, Batch 30/49, Loss: 0.3185
Epoch 7/10, Batch 40/49, Loss: 0.1658
Epoch 7/10, Train Loss: 0.2734, Valid Loss: 0.3012
Epoch 8/10, Batch 10/49, Loss: 0.2735
Epoch 8/10, Batch 20/49, Loss: 0.1608
Epoch 8/10, Batch 30/49, Loss: 0.3657
Epoch 8/10, Batch 40/49, Loss: 0.2539
Epoch 8/10, Train Loss: 0.2788, Valid Loss: 0.2889
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3007
Epoch 9/10, Batch 20/49, Loss: 0.2604
Epoch 9/10, Batch 30/49, Loss: 0.2665
Epoch 9/10, Batch 40/49, Loss: 0.2874
Epoch 9/10, Train Loss: 0.2557, Valid Loss: 0.2796
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3821
Epoch 10/10, Batch 20/49, Loss: 0.2862
Epoch 10/10, Batch 30/49, Loss: 0.1675
Epoch 10/10, Batch 40/49, Loss: 0.2099
Epoch 10/10, Train Loss: 0.2371, Valid Loss: 0.2789
Model saved!
Accuracy: 0.9136
Precision: 0.9120
Recall: 0.9136
F1-score: 0.9111
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2661
Epoch 1/10, Batch 20/49, Loss: 1.1624
Epoch 1/10, Batch 30/49, Loss: 0.9504
Epoch 1/10, Batch 40/49, Loss: 0.8785
Epoch 1/10, Train Loss: 1.0229, Valid Loss: 0.6375
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5481
Epoch 2/10, Batch 20/49, Loss: 0.5182
Epoch 2/10, Batch 30/49, Loss: 0.4174
Epoch 2/10, Batch 40/49, Loss: 0.5224
Epoch 2/10, Train Loss: 0.5648, Valid Loss: 0.4317
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5497
Epoch 3/10, Batch 20/49, Loss: 0.3097
Epoch 3/10, Batch 30/49, Loss: 0.4359
Epoch 3/10, Batch 40/49, Loss: 0.3565
Epoch 3/10, Train Loss: 0.4336, Valid Loss: 0.3687
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3766
Epoch 4/10, Batch 20/49, Loss: 0.3744
Epoch 4/10, Batch 30/49, Loss: 0.3278
Epoch 4/10, Batch 40/49, Loss: 0.5237
Epoch 4/10, Train Loss: 0.3723, Valid Loss: 0.3319
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3817
Epoch 5/10, Batch 20/49, Loss: 0.2417
Epoch 5/10, Batch 30/49, Loss: 0.2333
Epoch 5/10, Batch 40/49, Loss: 0.2733
Epoch 5/10, Train Loss: 0.3263, Valid Loss: 0.2991
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1767
Epoch 6/10, Batch 20/49, Loss: 0.2616
Epoch 6/10, Batch 30/49, Loss: 0.3403
Epoch 6/10, Batch 40/49, Loss: 0.2601
Epoch 6/10, Train Loss: 0.2996, Valid Loss: 0.2936
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3104
Epoch 7/10, Batch 20/49, Loss: 0.2693
Epoch 7/10, Batch 30/49, Loss: 0.2531
Epoch 7/10, Batch 40/49, Loss: 0.2224
Epoch 7/10, Train Loss: 0.2682, Valid Loss: 0.2751
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.4101
Epoch 8/10, Batch 20/49, Loss: 0.2802
Epoch 8/10, Batch 30/49, Loss: 0.2709
Epoch 8/10, Batch 40/49, Loss: 0.1667
Epoch 8/10, Train Loss: 0.2495, Valid Loss: 0.2616
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3522
Epoch 9/10, Batch 20/49, Loss: 0.1229
Epoch 9/10, Batch 30/49, Loss: 0.3635
Epoch 9/10, Batch 40/49, Loss: 0.3125
Epoch 9/10, Train Loss: 0.2444, Valid Loss: 0.2556
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2550
Epoch 10/10, Batch 20/49, Loss: 0.2227
Epoch 10/10, Batch 30/49, Loss: 0.1589
Epoch 10/10, Batch 40/49, Loss: 0.1694
Epoch 10/10, Train Loss: 0.2146, Valid Loss: 0.2597
Accuracy: 0.9136
Precision: 0.9102
Recall: 0.9136
F1-score: 0.9112
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2679
Epoch 1/10, Batch 20/49, Loss: 1.1254
Epoch 1/10, Batch 30/49, Loss: 0.8023
Epoch 1/10, Batch 40/49, Loss: 0.8180
Epoch 1/10, Train Loss: 1.0131, Valid Loss: 0.6406
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.4854
Epoch 2/10, Batch 20/49, Loss: 0.5593
Epoch 2/10, Batch 30/49, Loss: 0.4685
Epoch 2/10, Batch 40/49, Loss: 0.5461
Epoch 2/10, Train Loss: 0.5543, Valid Loss: 0.4560
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4125
Epoch 3/10, Batch 20/49, Loss: 0.2363
Epoch 3/10, Batch 30/49, Loss: 0.3788
Epoch 3/10, Batch 40/49, Loss: 0.3410
Epoch 3/10, Train Loss: 0.4244, Valid Loss: 0.3784
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3083
Epoch 4/10, Batch 20/49, Loss: 0.3292
Epoch 4/10, Batch 30/49, Loss: 0.3534
Epoch 4/10, Batch 40/49, Loss: 0.3501
Epoch 4/10, Train Loss: 0.3636, Valid Loss: 0.3394
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3418
Epoch 5/10, Batch 20/49, Loss: 0.2289
Epoch 5/10, Batch 30/49, Loss: 0.2408
Epoch 5/10, Batch 40/49, Loss: 0.3184
Epoch 5/10, Train Loss: 0.3273, Valid Loss: 0.3154
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2967
Epoch 6/10, Batch 20/49, Loss: 0.2182
Epoch 6/10, Batch 30/49, Loss: 0.2408
Epoch 6/10, Batch 40/49, Loss: 0.3453
Epoch 6/10, Train Loss: 0.3050, Valid Loss: 0.3032
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2172
Epoch 7/10, Batch 20/49, Loss: 0.3327
Epoch 7/10, Batch 30/49, Loss: 0.2026
Epoch 7/10, Batch 40/49, Loss: 0.1949
Epoch 7/10, Train Loss: 0.2594, Valid Loss: 0.3030
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2597
Epoch 8/10, Batch 20/49, Loss: 0.3436
Epoch 8/10, Batch 30/49, Loss: 0.1724
Epoch 8/10, Batch 40/49, Loss: 0.1335
Epoch 8/10, Train Loss: 0.2610, Valid Loss: 0.2905
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2312
Epoch 9/10, Batch 20/49, Loss: 0.2772
Epoch 9/10, Batch 30/49, Loss: 0.3368
Epoch 9/10, Batch 40/49, Loss: 0.1899
Epoch 9/10, Train Loss: 0.2485, Valid Loss: 0.2745
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3571
Epoch 10/10, Batch 20/49, Loss: 0.2662
Epoch 10/10, Batch 30/49, Loss: 0.2335
Epoch 10/10, Batch 40/49, Loss: 0.1536
Epoch 10/10, Train Loss: 0.2219, Valid Loss: 0.2651
Model saved!
Accuracy: 0.8972
Precision: 0.8943
Recall: 0.8972
F1-score: 0.8912
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2890
Epoch 1/10, Batch 20/49, Loss: 1.1183
Epoch 1/10, Batch 30/49, Loss: 0.9439
Epoch 1/10, Batch 40/49, Loss: 0.7415
Epoch 1/10, Train Loss: 1.0384, Valid Loss: 0.6121
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5980
Epoch 2/10, Batch 20/49, Loss: 0.6752
Epoch 2/10, Batch 30/49, Loss: 0.6153
Epoch 2/10, Batch 40/49, Loss: 0.6758
Epoch 2/10, Train Loss: 0.5663, Valid Loss: 0.4133
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3760
Epoch 3/10, Batch 20/49, Loss: 0.2999
Epoch 3/10, Batch 30/49, Loss: 0.3837
Epoch 3/10, Batch 40/49, Loss: 0.4190
Epoch 3/10, Train Loss: 0.4307, Valid Loss: 0.3467
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4902
Epoch 4/10, Batch 20/49, Loss: 0.3546
Epoch 4/10, Batch 30/49, Loss: 0.3703
Epoch 4/10, Batch 40/49, Loss: 0.3432
Epoch 4/10, Train Loss: 0.3823, Valid Loss: 0.3031
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4442
Epoch 5/10, Batch 20/49, Loss: 0.2872
Epoch 5/10, Batch 30/49, Loss: 0.2199
Epoch 5/10, Batch 40/49, Loss: 0.3288
Epoch 5/10, Train Loss: 0.3338, Valid Loss: 0.2820
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3007
Epoch 6/10, Batch 20/49, Loss: 0.2126
Epoch 6/10, Batch 30/49, Loss: 0.4810
Epoch 6/10, Batch 40/49, Loss: 0.2778
Epoch 6/10, Train Loss: 0.3063, Valid Loss: 0.2639
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.4129
Epoch 7/10, Batch 20/49, Loss: 0.3410
Epoch 7/10, Batch 30/49, Loss: 0.2000
Epoch 7/10, Batch 40/49, Loss: 0.2220
Epoch 7/10, Train Loss: 0.2657, Valid Loss: 0.2655
Epoch 8/10, Batch 10/49, Loss: 0.2213
Epoch 8/10, Batch 20/49, Loss: 0.1986
Epoch 8/10, Batch 30/49, Loss: 0.2955
Epoch 8/10, Batch 40/49, Loss: 0.1909
Epoch 8/10, Train Loss: 0.2754, Valid Loss: 0.2500
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1714
Epoch 9/10, Batch 20/49, Loss: 0.1769
Epoch 9/10, Batch 30/49, Loss: 0.2585
Epoch 9/10, Batch 40/49, Loss: 0.2909
Epoch 9/10, Train Loss: 0.2439, Valid Loss: 0.2453
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.4120
Epoch 10/10, Batch 20/49, Loss: 0.1503
Epoch 10/10, Batch 30/49, Loss: 0.1457
Epoch 10/10, Batch 40/49, Loss: 0.2025
Epoch 10/10, Train Loss: 0.2268, Valid Loss: 0.2381
Model saved!
Accuracy: 0.9042
Precision: 0.9016
Recall: 0.9042
F1-score: 0.9013
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2821
Epoch 1/10, Batch 20/49, Loss: 1.1017
Epoch 1/10, Batch 30/49, Loss: 0.7958
Epoch 1/10, Batch 40/49, Loss: 0.7045
Epoch 1/10, Train Loss: 1.0092, Valid Loss: 0.6501
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5996
Epoch 2/10, Batch 20/49, Loss: 0.6703
Epoch 2/10, Batch 30/49, Loss: 0.4039
Epoch 2/10, Batch 40/49, Loss: 0.4967
Epoch 2/10, Train Loss: 0.5377, Valid Loss: 0.4599
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4237
Epoch 3/10, Batch 20/49, Loss: 0.3156
Epoch 3/10, Batch 30/49, Loss: 0.3813
Epoch 3/10, Batch 40/49, Loss: 0.4073
Epoch 3/10, Train Loss: 0.4162, Valid Loss: 0.3936
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2208
Epoch 4/10, Batch 20/49, Loss: 0.4967
Epoch 4/10, Batch 30/49, Loss: 0.2643
Epoch 4/10, Batch 40/49, Loss: 0.3626
Epoch 4/10, Train Loss: 0.3690, Valid Loss: 0.3521
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4073
Epoch 5/10, Batch 20/49, Loss: 0.2989
Epoch 5/10, Batch 30/49, Loss: 0.2564
Epoch 5/10, Batch 40/49, Loss: 0.1532
Epoch 5/10, Train Loss: 0.3235, Valid Loss: 0.3167
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3126
Epoch 6/10, Batch 20/49, Loss: 0.2356
Epoch 6/10, Batch 30/49, Loss: 0.2440
Epoch 6/10, Batch 40/49, Loss: 0.3234
Epoch 6/10, Train Loss: 0.3020, Valid Loss: 0.3036
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3190
Epoch 7/10, Batch 20/49, Loss: 0.4165
Epoch 7/10, Batch 30/49, Loss: 0.1970
Epoch 7/10, Batch 40/49, Loss: 0.1173
Epoch 7/10, Train Loss: 0.2611, Valid Loss: 0.2935
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2021
Epoch 8/10, Batch 20/49, Loss: 0.2896
Epoch 8/10, Batch 30/49, Loss: 0.2323
Epoch 8/10, Batch 40/49, Loss: 0.1830
Epoch 8/10, Train Loss: 0.2648, Valid Loss: 0.2933
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1687
Epoch 9/10, Batch 20/49, Loss: 0.1534
Epoch 9/10, Batch 30/49, Loss: 0.3444
Epoch 9/10, Batch 40/49, Loss: 0.2402
Epoch 9/10, Train Loss: 0.2491, Valid Loss: 0.2741
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2871
Epoch 10/10, Batch 20/49, Loss: 0.3548
Epoch 10/10, Batch 30/49, Loss: 0.2614
Epoch 10/10, Batch 40/49, Loss: 0.1553
Epoch 10/10, Train Loss: 0.2191, Valid Loss: 0.2770
Accuracy: 0.9065
Precision: 0.9046
Recall: 0.9065
F1-score: 0.9029
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1639
Epoch 1/10, Batch 20/49, Loss: 1.1577
Epoch 1/10, Batch 30/49, Loss: 0.8312
Epoch 1/10, Batch 40/49, Loss: 0.7380
Epoch 1/10, Train Loss: 1.0183, Valid Loss: 0.6474
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5494
Epoch 2/10, Batch 20/49, Loss: 0.6013
Epoch 2/10, Batch 30/49, Loss: 0.4918
Epoch 2/10, Batch 40/49, Loss: 0.4463
Epoch 2/10, Train Loss: 0.5652, Valid Loss: 0.4368
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4075
Epoch 3/10, Batch 20/49, Loss: 0.3289
Epoch 3/10, Batch 30/49, Loss: 0.4171
Epoch 3/10, Batch 40/49, Loss: 0.3004
Epoch 3/10, Train Loss: 0.4306, Valid Loss: 0.3842
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4656
Epoch 4/10, Batch 20/49, Loss: 0.6442
Epoch 4/10, Batch 30/49, Loss: 0.5117
Epoch 4/10, Batch 40/49, Loss: 0.3322
Epoch 4/10, Train Loss: 0.3855, Valid Loss: 0.3389
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2855
Epoch 5/10, Batch 20/49, Loss: 0.2129
Epoch 5/10, Batch 30/49, Loss: 0.2344
Epoch 5/10, Batch 40/49, Loss: 0.2639
Epoch 5/10, Train Loss: 0.3347, Valid Loss: 0.3071
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2472
Epoch 6/10, Batch 20/49, Loss: 0.2659
Epoch 6/10, Batch 30/49, Loss: 0.2505
Epoch 6/10, Batch 40/49, Loss: 0.3143
Epoch 6/10, Train Loss: 0.3078, Valid Loss: 0.2836
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3439
Epoch 7/10, Batch 20/49, Loss: 0.3048
Epoch 7/10, Batch 30/49, Loss: 0.3751
Epoch 7/10, Batch 40/49, Loss: 0.1468
Epoch 7/10, Train Loss: 0.2778, Valid Loss: 0.2702
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2737
Epoch 8/10, Batch 20/49, Loss: 0.2719
Epoch 8/10, Batch 30/49, Loss: 0.1261
Epoch 8/10, Batch 40/49, Loss: 0.2542
Epoch 8/10, Train Loss: 0.2581, Valid Loss: 0.2643
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1941
Epoch 9/10, Batch 20/49, Loss: 0.1283
Epoch 9/10, Batch 30/49, Loss: 0.4068
Epoch 9/10, Batch 40/49, Loss: 0.4665
Epoch 9/10, Train Loss: 0.2515, Valid Loss: 0.2499
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2238
Epoch 10/10, Batch 20/49, Loss: 0.3820
Epoch 10/10, Batch 30/49, Loss: 0.1364
Epoch 10/10, Batch 40/49, Loss: 0.1872
Epoch 10/10, Train Loss: 0.2360, Valid Loss: 0.2484
Model saved!
Accuracy: 0.8995
Precision: 0.8977
Recall: 0.8995
F1-score: 0.8973
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1920
Epoch 1/10, Batch 20/49, Loss: 1.0803
Epoch 1/10, Batch 30/49, Loss: 0.8031
Epoch 1/10, Batch 40/49, Loss: 0.7584
Epoch 1/10, Train Loss: 1.0196, Valid Loss: 0.6227
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6577
Epoch 2/10, Batch 20/49, Loss: 0.7144
Epoch 2/10, Batch 30/49, Loss: 0.6259
Epoch 2/10, Batch 40/49, Loss: 0.4188
Epoch 2/10, Train Loss: 0.5597, Valid Loss: 0.4183
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3717
Epoch 3/10, Batch 20/49, Loss: 0.3517
Epoch 3/10, Batch 30/49, Loss: 0.4253
Epoch 3/10, Batch 40/49, Loss: 0.4079
Epoch 3/10, Train Loss: 0.4293, Valid Loss: 0.3702
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4994
Epoch 4/10, Batch 20/49, Loss: 0.4063
Epoch 4/10, Batch 30/49, Loss: 0.4294
Epoch 4/10, Batch 40/49, Loss: 0.4340
Epoch 4/10, Train Loss: 0.3862, Valid Loss: 0.3266
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5060
Epoch 5/10, Batch 20/49, Loss: 0.3994
Epoch 5/10, Batch 30/49, Loss: 0.3454
Epoch 5/10, Batch 40/49, Loss: 0.2112
Epoch 5/10, Train Loss: 0.3364, Valid Loss: 0.2970
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2970
Epoch 6/10, Batch 20/49, Loss: 0.1762
Epoch 6/10, Batch 30/49, Loss: 0.2732
Epoch 6/10, Batch 40/49, Loss: 0.3254
Epoch 6/10, Train Loss: 0.3037, Valid Loss: 0.2880
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2549
Epoch 7/10, Batch 20/49, Loss: 0.2804
Epoch 7/10, Batch 30/49, Loss: 0.1574
Epoch 7/10, Batch 40/49, Loss: 0.2020
Epoch 7/10, Train Loss: 0.2675, Valid Loss: 0.2865
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2866
Epoch 8/10, Batch 20/49, Loss: 0.2211
Epoch 8/10, Batch 30/49, Loss: 0.1676
Epoch 8/10, Batch 40/49, Loss: 0.1264
Epoch 8/10, Train Loss: 0.2618, Valid Loss: 0.2628
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1886
Epoch 9/10, Batch 20/49, Loss: 0.1538
Epoch 9/10, Batch 30/49, Loss: 0.2673
Epoch 9/10, Batch 40/49, Loss: 0.1927
Epoch 9/10, Train Loss: 0.2447, Valid Loss: 0.2588
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2011
Epoch 10/10, Batch 20/49, Loss: 0.2267
Epoch 10/10, Batch 30/49, Loss: 0.1927
Epoch 10/10, Batch 40/49, Loss: 0.2692
Epoch 10/10, Train Loss: 0.2148, Valid Loss: 0.2508
Model saved!
Accuracy: 0.9136
Precision: 0.9113
Recall: 0.9136
F1-score: 0.9121
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2502
Epoch 1/10, Batch 20/49, Loss: 1.1477
Epoch 1/10, Batch 30/49, Loss: 0.8530
Epoch 1/10, Batch 40/49, Loss: 0.7676
Epoch 1/10, Train Loss: 1.0071, Valid Loss: 0.6151
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6546
Epoch 2/10, Batch 20/49, Loss: 0.6293
Epoch 2/10, Batch 30/49, Loss: 0.4694
Epoch 2/10, Batch 40/49, Loss: 0.4591
Epoch 2/10, Train Loss: 0.5384, Valid Loss: 0.4203
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4258
Epoch 3/10, Batch 20/49, Loss: 0.3156
Epoch 3/10, Batch 30/49, Loss: 0.4220
Epoch 3/10, Batch 40/49, Loss: 0.5114
Epoch 3/10, Train Loss: 0.4126, Valid Loss: 0.3595
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3237
Epoch 4/10, Batch 20/49, Loss: 0.2712
Epoch 4/10, Batch 30/49, Loss: 0.2924
Epoch 4/10, Batch 40/49, Loss: 0.4820
Epoch 4/10, Train Loss: 0.3655, Valid Loss: 0.3109
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4608
Epoch 5/10, Batch 20/49, Loss: 0.3517
Epoch 5/10, Batch 30/49, Loss: 0.3633
Epoch 5/10, Batch 40/49, Loss: 0.2040
Epoch 5/10, Train Loss: 0.3167, Valid Loss: 0.2917
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2085
Epoch 6/10, Batch 20/49, Loss: 0.2110
Epoch 6/10, Batch 30/49, Loss: 0.2261
Epoch 6/10, Batch 40/49, Loss: 0.2692
Epoch 6/10, Train Loss: 0.2890, Valid Loss: 0.2748
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3433
Epoch 7/10, Batch 20/49, Loss: 0.3053
Epoch 7/10, Batch 30/49, Loss: 0.3273
Epoch 7/10, Batch 40/49, Loss: 0.2280
Epoch 7/10, Train Loss: 0.2600, Valid Loss: 0.2784
Epoch 8/10, Batch 10/49, Loss: 0.2482
Epoch 8/10, Batch 20/49, Loss: 0.1413
Epoch 8/10, Batch 30/49, Loss: 0.2505
Epoch 8/10, Batch 40/49, Loss: 0.1913
Epoch 8/10, Train Loss: 0.2455, Valid Loss: 0.2655
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3389
Epoch 9/10, Batch 20/49, Loss: 0.1025
Epoch 9/10, Batch 30/49, Loss: 0.3469
Epoch 9/10, Batch 40/49, Loss: 0.4025
Epoch 9/10, Train Loss: 0.2339, Valid Loss: 0.2572
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1962
Epoch 10/10, Batch 20/49, Loss: 0.2108
Epoch 10/10, Batch 30/49, Loss: 0.2586
Epoch 10/10, Batch 40/49, Loss: 0.1252
Epoch 10/10, Train Loss: 0.2144, Valid Loss: 0.2562
Model saved!
Accuracy: 0.9007
Precision: 0.8970
Recall: 0.9007
F1-score: 0.8962
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1844
Epoch 1/10, Batch 20/49, Loss: 1.0839
Epoch 1/10, Batch 30/49, Loss: 0.7845
Epoch 1/10, Batch 40/49, Loss: 0.8296
Epoch 1/10, Train Loss: 1.0210, Valid Loss: 0.5916
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6632
Epoch 2/10, Batch 20/49, Loss: 0.7589
Epoch 2/10, Batch 30/49, Loss: 0.5038
Epoch 2/10, Batch 40/49, Loss: 0.4473
Epoch 2/10, Train Loss: 0.5597, Valid Loss: 0.4089
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5879
Epoch 3/10, Batch 20/49, Loss: 0.3086
Epoch 3/10, Batch 30/49, Loss: 0.4956
Epoch 3/10, Batch 40/49, Loss: 0.3067
Epoch 3/10, Train Loss: 0.4368, Valid Loss: 0.3590
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3333
Epoch 4/10, Batch 20/49, Loss: 0.4278
Epoch 4/10, Batch 30/49, Loss: 0.4872
Epoch 4/10, Batch 40/49, Loss: 0.4105
Epoch 4/10, Train Loss: 0.3809, Valid Loss: 0.3103
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3717
Epoch 5/10, Batch 20/49, Loss: 0.3900
Epoch 5/10, Batch 30/49, Loss: 0.2219
Epoch 5/10, Batch 40/49, Loss: 0.3283
Epoch 5/10, Train Loss: 0.3477, Valid Loss: 0.2809
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3435
Epoch 6/10, Batch 20/49, Loss: 0.1833
Epoch 6/10, Batch 30/49, Loss: 0.2614
Epoch 6/10, Batch 40/49, Loss: 0.3826
Epoch 6/10, Train Loss: 0.3077, Valid Loss: 0.2621
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3549
Epoch 7/10, Batch 20/49, Loss: 0.2509
Epoch 7/10, Batch 30/49, Loss: 0.3244
Epoch 7/10, Batch 40/49, Loss: 0.1207
Epoch 7/10, Train Loss: 0.2851, Valid Loss: 0.2581
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2470
Epoch 8/10, Batch 20/49, Loss: 0.2511
Epoch 8/10, Batch 30/49, Loss: 0.1960
Epoch 8/10, Batch 40/49, Loss: 0.2500
Epoch 8/10, Train Loss: 0.2572, Valid Loss: 0.2529
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1859
Epoch 9/10, Batch 20/49, Loss: 0.2580
Epoch 9/10, Batch 30/49, Loss: 0.3191
Epoch 9/10, Batch 40/49, Loss: 0.3335
Epoch 9/10, Train Loss: 0.2388, Valid Loss: 0.2338
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2868
Epoch 10/10, Batch 20/49, Loss: 0.2565
Epoch 10/10, Batch 30/49, Loss: 0.2255
Epoch 10/10, Batch 40/49, Loss: 0.2860
Epoch 10/10, Train Loss: 0.2325, Valid Loss: 0.2404
Accuracy: 0.9019
Precision: 0.8979
Recall: 0.9019
F1-score: 0.8992
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1580
Epoch 1/10, Batch 20/49, Loss: 1.0546
Epoch 1/10, Batch 30/49, Loss: 0.8386
Epoch 1/10, Batch 40/49, Loss: 0.8293
Epoch 1/10, Train Loss: 1.0076, Valid Loss: 0.6368
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5694
Epoch 2/10, Batch 20/49, Loss: 0.7345
Epoch 2/10, Batch 30/49, Loss: 0.5264
Epoch 2/10, Batch 40/49, Loss: 0.4718
Epoch 2/10, Train Loss: 0.5395, Valid Loss: 0.4444
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3973
Epoch 3/10, Batch 20/49, Loss: 0.3028
Epoch 3/10, Batch 30/49, Loss: 0.4908
Epoch 3/10, Batch 40/49, Loss: 0.3845
Epoch 3/10, Train Loss: 0.4207, Valid Loss: 0.3850
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4066
Epoch 4/10, Batch 20/49, Loss: 0.6491
Epoch 4/10, Batch 30/49, Loss: 0.5209
Epoch 4/10, Batch 40/49, Loss: 0.5344
Epoch 4/10, Train Loss: 0.3642, Valid Loss: 0.3369
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3896
Epoch 5/10, Batch 20/49, Loss: 0.2247
Epoch 5/10, Batch 30/49, Loss: 0.2671
Epoch 5/10, Batch 40/49, Loss: 0.5667
Epoch 5/10, Train Loss: 0.3182, Valid Loss: 0.2976
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2315
Epoch 6/10, Batch 20/49, Loss: 0.2765
Epoch 6/10, Batch 30/49, Loss: 0.3458
Epoch 6/10, Batch 40/49, Loss: 0.2433
Epoch 6/10, Train Loss: 0.2933, Valid Loss: 0.2859
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2623
Epoch 7/10, Batch 20/49, Loss: 0.3362
Epoch 7/10, Batch 30/49, Loss: 0.1614
Epoch 7/10, Batch 40/49, Loss: 0.1346
Epoch 7/10, Train Loss: 0.2582, Valid Loss: 0.2741
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3032
Epoch 8/10, Batch 20/49, Loss: 0.1761
Epoch 8/10, Batch 30/49, Loss: 0.2041
Epoch 8/10, Batch 40/49, Loss: 0.0966
Epoch 8/10, Train Loss: 0.2469, Valid Loss: 0.2651
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1748
Epoch 9/10, Batch 20/49, Loss: 0.1740
Epoch 9/10, Batch 30/49, Loss: 0.4039
Epoch 9/10, Batch 40/49, Loss: 0.2524
Epoch 9/10, Train Loss: 0.2438, Valid Loss: 0.2521
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.4055
Epoch 10/10, Batch 20/49, Loss: 0.1716
Epoch 10/10, Batch 30/49, Loss: 0.2741
Epoch 10/10, Batch 40/49, Loss: 0.2725
Epoch 10/10, Train Loss: 0.2244, Valid Loss: 0.2548
Accuracy: 0.9065
Precision: 0.9046
Recall: 0.9065
F1-score: 0.9033
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2537
Epoch 1/10, Batch 20/49, Loss: 1.1482
Epoch 1/10, Batch 30/49, Loss: 0.8157
Epoch 1/10, Batch 40/49, Loss: 0.8939
Epoch 1/10, Train Loss: 1.0258, Valid Loss: 0.6315
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5496
Epoch 2/10, Batch 20/49, Loss: 0.7214
Epoch 2/10, Batch 30/49, Loss: 0.5862
Epoch 2/10, Batch 40/49, Loss: 0.3850
Epoch 2/10, Train Loss: 0.5429, Valid Loss: 0.4316
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5062
Epoch 3/10, Batch 20/49, Loss: 0.4068
Epoch 3/10, Batch 30/49, Loss: 0.3480
Epoch 3/10, Batch 40/49, Loss: 0.2989
Epoch 3/10, Train Loss: 0.4227, Valid Loss: 0.3685
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3544
Epoch 4/10, Batch 20/49, Loss: 0.3341
Epoch 4/10, Batch 30/49, Loss: 0.4837
Epoch 4/10, Batch 40/49, Loss: 0.5042
Epoch 4/10, Train Loss: 0.3680, Valid Loss: 0.3318
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3599
Epoch 5/10, Batch 20/49, Loss: 0.4035
Epoch 5/10, Batch 30/49, Loss: 0.2757
Epoch 5/10, Batch 40/49, Loss: 0.3073
Epoch 5/10, Train Loss: 0.3302, Valid Loss: 0.3106
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3045
Epoch 6/10, Batch 20/49, Loss: 0.1848
Epoch 6/10, Batch 30/49, Loss: 0.2540
Epoch 6/10, Batch 40/49, Loss: 0.2971
Epoch 6/10, Train Loss: 0.3036, Valid Loss: 0.2926
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3228
Epoch 7/10, Batch 20/49, Loss: 0.2718
Epoch 7/10, Batch 30/49, Loss: 0.2506
Epoch 7/10, Batch 40/49, Loss: 0.1567
Epoch 7/10, Train Loss: 0.2648, Valid Loss: 0.2950
Epoch 8/10, Batch 10/49, Loss: 0.2225
Epoch 8/10, Batch 20/49, Loss: 0.2226
Epoch 8/10, Batch 30/49, Loss: 0.3571
Epoch 8/10, Batch 40/49, Loss: 0.1869
Epoch 8/10, Train Loss: 0.2659, Valid Loss: 0.2791
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2106
Epoch 9/10, Batch 20/49, Loss: 0.1753
Epoch 9/10, Batch 30/49, Loss: 0.2094
Epoch 9/10, Batch 40/49, Loss: 0.3960
Epoch 9/10, Train Loss: 0.2359, Valid Loss: 0.2750
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3276
Epoch 10/10, Batch 20/49, Loss: 0.1754
Epoch 10/10, Batch 30/49, Loss: 0.2213
Epoch 10/10, Batch 40/49, Loss: 0.1873
Epoch 10/10, Train Loss: 0.2161, Valid Loss: 0.2666
Model saved!
Accuracy: 0.9077
Precision: 0.9065
Recall: 0.9077
F1-score: 0.9036
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2583
Epoch 1/10, Batch 20/49, Loss: 1.1206
Epoch 1/10, Batch 30/49, Loss: 0.8497
Epoch 1/10, Batch 40/49, Loss: 0.7626
Epoch 1/10, Train Loss: 1.0162, Valid Loss: 0.6253
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5244
Epoch 2/10, Batch 20/49, Loss: 0.6783
Epoch 2/10, Batch 30/49, Loss: 0.4568
Epoch 2/10, Batch 40/49, Loss: 0.5555
Epoch 2/10, Train Loss: 0.5459, Valid Loss: 0.4264
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3715
Epoch 3/10, Batch 20/49, Loss: 0.4185
Epoch 3/10, Batch 30/49, Loss: 0.3969
Epoch 3/10, Batch 40/49, Loss: 0.4386
Epoch 3/10, Train Loss: 0.4132, Valid Loss: 0.3644
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3070
Epoch 4/10, Batch 20/49, Loss: 0.4547
Epoch 4/10, Batch 30/49, Loss: 0.4377
Epoch 4/10, Batch 40/49, Loss: 0.4656
Epoch 4/10, Train Loss: 0.3602, Valid Loss: 0.3248
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3519
Epoch 5/10, Batch 20/49, Loss: 0.2670
Epoch 5/10, Batch 30/49, Loss: 0.2107
Epoch 5/10, Batch 40/49, Loss: 0.5009
Epoch 5/10, Train Loss: 0.3223, Valid Loss: 0.2950
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3486
Epoch 6/10, Batch 20/49, Loss: 0.1556
Epoch 6/10, Batch 30/49, Loss: 0.2367
Epoch 6/10, Batch 40/49, Loss: 0.2852
Epoch 6/10, Train Loss: 0.2893, Valid Loss: 0.2756
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1740
Epoch 7/10, Batch 20/49, Loss: 0.3109
Epoch 7/10, Batch 30/49, Loss: 0.2900
Epoch 7/10, Batch 40/49, Loss: 0.1710
Epoch 7/10, Train Loss: 0.2657, Valid Loss: 0.2799
Epoch 8/10, Batch 10/49, Loss: 0.2974
Epoch 8/10, Batch 20/49, Loss: 0.1990
Epoch 8/10, Batch 30/49, Loss: 0.2287
Epoch 8/10, Batch 40/49, Loss: 0.1071
Epoch 8/10, Train Loss: 0.2510, Valid Loss: 0.2637
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1883
Epoch 9/10, Batch 20/49, Loss: 0.2748
Epoch 9/10, Batch 30/49, Loss: 0.2779
Epoch 9/10, Batch 40/49, Loss: 0.2437
Epoch 9/10, Train Loss: 0.2384, Valid Loss: 0.2574
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3278
Epoch 10/10, Batch 20/49, Loss: 0.2378
Epoch 10/10, Batch 30/49, Loss: 0.1298
Epoch 10/10, Batch 40/49, Loss: 0.2367
Epoch 10/10, Train Loss: 0.2165, Valid Loss: 0.2584
Accuracy: 0.9030
Precision: 0.9016
Recall: 0.9030
F1-score: 0.8985
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2396
Epoch 1/10, Batch 20/49, Loss: 1.0448
Epoch 1/10, Batch 30/49, Loss: 0.8023
Epoch 1/10, Batch 40/49, Loss: 0.8385
Epoch 1/10, Train Loss: 1.0082, Valid Loss: 0.6060
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5648
Epoch 2/10, Batch 20/49, Loss: 0.7521
Epoch 2/10, Batch 30/49, Loss: 0.5946
Epoch 2/10, Batch 40/49, Loss: 0.3478
Epoch 2/10, Train Loss: 0.5523, Valid Loss: 0.4106
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3692
Epoch 3/10, Batch 20/49, Loss: 0.3140
Epoch 3/10, Batch 30/49, Loss: 0.3925
Epoch 3/10, Batch 40/49, Loss: 0.3614
Epoch 3/10, Train Loss: 0.4270, Valid Loss: 0.3528
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2851
Epoch 4/10, Batch 20/49, Loss: 0.3022
Epoch 4/10, Batch 30/49, Loss: 0.3093
Epoch 4/10, Batch 40/49, Loss: 0.4292
Epoch 4/10, Train Loss: 0.3773, Valid Loss: 0.3057
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3911
Epoch 5/10, Batch 20/49, Loss: 0.2471
Epoch 5/10, Batch 30/49, Loss: 0.2602
Epoch 5/10, Batch 40/49, Loss: 0.3043
Epoch 5/10, Train Loss: 0.3181, Valid Loss: 0.2832
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2718
Epoch 6/10, Batch 20/49, Loss: 0.1928
Epoch 6/10, Batch 30/49, Loss: 0.3034
Epoch 6/10, Batch 40/49, Loss: 0.3552
Epoch 6/10, Train Loss: 0.3065, Valid Loss: 0.2659
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3457
Epoch 7/10, Batch 20/49, Loss: 0.2045
Epoch 7/10, Batch 30/49, Loss: 0.2500
Epoch 7/10, Batch 40/49, Loss: 0.2015
Epoch 7/10, Train Loss: 0.2643, Valid Loss: 0.2687
Epoch 8/10, Batch 10/49, Loss: 0.3326
Epoch 8/10, Batch 20/49, Loss: 0.2644
Epoch 8/10, Batch 30/49, Loss: 0.1995
Epoch 8/10, Batch 40/49, Loss: 0.2260
Epoch 8/10, Train Loss: 0.2520, Valid Loss: 0.2608
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.3420
Epoch 9/10, Batch 20/49, Loss: 0.2189
Epoch 9/10, Batch 30/49, Loss: 0.1914
Epoch 9/10, Batch 40/49, Loss: 0.2911
Epoch 9/10, Train Loss: 0.2367, Valid Loss: 0.2441
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1846
Epoch 10/10, Batch 20/49, Loss: 0.1984
Epoch 10/10, Batch 30/49, Loss: 0.3062
Epoch 10/10, Batch 40/49, Loss: 0.1907
Epoch 10/10, Train Loss: 0.2324, Valid Loss: 0.2412
Model saved!
Accuracy: 0.9077
Precision: 0.9048
Recall: 0.9077
F1-score: 0.9054
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2271
Epoch 1/10, Batch 20/49, Loss: 1.1337
Epoch 1/10, Batch 30/49, Loss: 0.8318
Epoch 1/10, Batch 40/49, Loss: 0.9209
Epoch 1/10, Train Loss: 1.0188, Valid Loss: 0.6170
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5551
Epoch 2/10, Batch 20/49, Loss: 0.6615
Epoch 2/10, Batch 30/49, Loss: 0.5366
Epoch 2/10, Batch 40/49, Loss: 0.4652
Epoch 2/10, Train Loss: 0.5609, Valid Loss: 0.4244
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3582
Epoch 3/10, Batch 20/49, Loss: 0.3221
Epoch 3/10, Batch 30/49, Loss: 0.4241
Epoch 3/10, Batch 40/49, Loss: 0.3805
Epoch 3/10, Train Loss: 0.4261, Valid Loss: 0.3710
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4036
Epoch 4/10, Batch 20/49, Loss: 0.3826
Epoch 4/10, Batch 30/49, Loss: 0.4470
Epoch 4/10, Batch 40/49, Loss: 0.4563
Epoch 4/10, Train Loss: 0.3746, Valid Loss: 0.3218
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.5436
Epoch 5/10, Batch 20/49, Loss: 0.2004
Epoch 5/10, Batch 30/49, Loss: 0.2201
Epoch 5/10, Batch 40/49, Loss: 0.2129
Epoch 5/10, Train Loss: 0.3277, Valid Loss: 0.3064
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3006
Epoch 6/10, Batch 20/49, Loss: 0.2402
Epoch 6/10, Batch 30/49, Loss: 0.2548
Epoch 6/10, Batch 40/49, Loss: 0.2685
Epoch 6/10, Train Loss: 0.2943, Valid Loss: 0.2912
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2321
Epoch 7/10, Batch 20/49, Loss: 0.4413
Epoch 7/10, Batch 30/49, Loss: 0.2966
Epoch 7/10, Batch 40/49, Loss: 0.1115
Epoch 7/10, Train Loss: 0.2670, Valid Loss: 0.2820
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3877
Epoch 8/10, Batch 20/49, Loss: 0.2032
Epoch 8/10, Batch 30/49, Loss: 0.2114
Epoch 8/10, Batch 40/49, Loss: 0.2205
Epoch 8/10, Train Loss: 0.2572, Valid Loss: 0.2703
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2412
Epoch 9/10, Batch 20/49, Loss: 0.1723
Epoch 9/10, Batch 30/49, Loss: 0.2803
Epoch 9/10, Batch 40/49, Loss: 0.2860
Epoch 9/10, Train Loss: 0.2325, Valid Loss: 0.2629
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3462
Epoch 10/10, Batch 20/49, Loss: 0.2072
Epoch 10/10, Batch 30/49, Loss: 0.1739
Epoch 10/10, Batch 40/49, Loss: 0.2070
Epoch 10/10, Train Loss: 0.2247, Valid Loss: 0.2675
Accuracy: 0.9100
Precision: 0.9058
Recall: 0.9100
F1-score: 0.9065
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2650
Epoch 1/10, Batch 20/49, Loss: 1.1262
Epoch 1/10, Batch 30/49, Loss: 0.8391
Epoch 1/10, Batch 40/49, Loss: 0.8016
Epoch 1/10, Train Loss: 1.0042, Valid Loss: 0.6478
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5302
Epoch 2/10, Batch 20/49, Loss: 0.6582
Epoch 2/10, Batch 30/49, Loss: 0.4660
Epoch 2/10, Batch 40/49, Loss: 0.5682
Epoch 2/10, Train Loss: 0.5551, Valid Loss: 0.4558
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4003
Epoch 3/10, Batch 20/49, Loss: 0.3703
Epoch 3/10, Batch 30/49, Loss: 0.4722
Epoch 3/10, Batch 40/49, Loss: 0.4276
Epoch 3/10, Train Loss: 0.4221, Valid Loss: 0.3971
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2545
Epoch 4/10, Batch 20/49, Loss: 0.4585
Epoch 4/10, Batch 30/49, Loss: 0.4576
Epoch 4/10, Batch 40/49, Loss: 0.4012
Epoch 4/10, Train Loss: 0.3779, Valid Loss: 0.3578
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4812
Epoch 5/10, Batch 20/49, Loss: 0.2355
Epoch 5/10, Batch 30/49, Loss: 0.2387
Epoch 5/10, Batch 40/49, Loss: 0.3158
Epoch 5/10, Train Loss: 0.3394, Valid Loss: 0.3318
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3745
Epoch 6/10, Batch 20/49, Loss: 0.2401
Epoch 6/10, Batch 30/49, Loss: 0.2685
Epoch 6/10, Batch 40/49, Loss: 0.2389
Epoch 6/10, Train Loss: 0.2941, Valid Loss: 0.3134
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1982
Epoch 7/10, Batch 20/49, Loss: 0.3356
Epoch 7/10, Batch 30/49, Loss: 0.1598
Epoch 7/10, Batch 40/49, Loss: 0.1076
Epoch 7/10, Train Loss: 0.2635, Valid Loss: 0.3054
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2327
Epoch 8/10, Batch 20/49, Loss: 0.2319
Epoch 8/10, Batch 30/49, Loss: 0.2115
Epoch 8/10, Batch 40/49, Loss: 0.1939
Epoch 8/10, Train Loss: 0.2616, Valid Loss: 0.3024
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2006
Epoch 9/10, Batch 20/49, Loss: 0.1471
Epoch 9/10, Batch 30/49, Loss: 0.2931
Epoch 9/10, Batch 40/49, Loss: 0.3448
Epoch 9/10, Train Loss: 0.2469, Valid Loss: 0.2854
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2476
Epoch 10/10, Batch 20/49, Loss: 0.2187
Epoch 10/10, Batch 30/49, Loss: 0.2633
Epoch 10/10, Batch 40/49, Loss: 0.2212
Epoch 10/10, Train Loss: 0.2253, Valid Loss: 0.2816
Model saved!
Accuracy: 0.9147
Precision: 0.9128
Recall: 0.9147
F1-score: 0.9127
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2247
Epoch 1/10, Batch 20/49, Loss: 1.1132
Epoch 1/10, Batch 30/49, Loss: 0.6876
Epoch 1/10, Batch 40/49, Loss: 0.8121
Epoch 1/10, Train Loss: 1.0120, Valid Loss: 0.6332
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6857
Epoch 2/10, Batch 20/49, Loss: 0.7846
Epoch 2/10, Batch 30/49, Loss: 0.4420
Epoch 2/10, Batch 40/49, Loss: 0.5212
Epoch 2/10, Train Loss: 0.5389, Valid Loss: 0.4441
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4196
Epoch 3/10, Batch 20/49, Loss: 0.4310
Epoch 3/10, Batch 30/49, Loss: 0.4651
Epoch 3/10, Batch 40/49, Loss: 0.4702
Epoch 3/10, Train Loss: 0.4154, Valid Loss: 0.3774
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2939
Epoch 4/10, Batch 20/49, Loss: 0.2778
Epoch 4/10, Batch 30/49, Loss: 0.3833
Epoch 4/10, Batch 40/49, Loss: 0.3670
Epoch 4/10, Train Loss: 0.3706, Valid Loss: 0.3325
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4015
Epoch 5/10, Batch 20/49, Loss: 0.2990
Epoch 5/10, Batch 30/49, Loss: 0.3111
Epoch 5/10, Batch 40/49, Loss: 0.3408
Epoch 5/10, Train Loss: 0.3206, Valid Loss: 0.3124
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3000
Epoch 6/10, Batch 20/49, Loss: 0.2379
Epoch 6/10, Batch 30/49, Loss: 0.2549
Epoch 6/10, Batch 40/49, Loss: 0.2135
Epoch 6/10, Train Loss: 0.2985, Valid Loss: 0.2969
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2191
Epoch 7/10, Batch 20/49, Loss: 0.4949
Epoch 7/10, Batch 30/49, Loss: 0.1666
Epoch 7/10, Batch 40/49, Loss: 0.1188
Epoch 7/10, Train Loss: 0.2694, Valid Loss: 0.3001
Epoch 8/10, Batch 10/49, Loss: 0.3993
Epoch 8/10, Batch 20/49, Loss: 0.2352
Epoch 8/10, Batch 30/49, Loss: 0.2566
Epoch 8/10, Batch 40/49, Loss: 0.2975
Epoch 8/10, Train Loss: 0.2598, Valid Loss: 0.2845
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1167
Epoch 9/10, Batch 20/49, Loss: 0.1348
Epoch 9/10, Batch 30/49, Loss: 0.2698
Epoch 9/10, Batch 40/49, Loss: 0.3664
Epoch 9/10, Train Loss: 0.2389, Valid Loss: 0.2730
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2968
Epoch 10/10, Batch 20/49, Loss: 0.1949
Epoch 10/10, Batch 30/49, Loss: 0.1249
Epoch 10/10, Batch 40/49, Loss: 0.1149
Epoch 10/10, Train Loss: 0.2177, Valid Loss: 0.2657
Model saved!
Accuracy: 0.9077
Precision: 0.9054
Recall: 0.9077
F1-score: 0.9047
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2302
Epoch 1/10, Batch 20/49, Loss: 1.1305
Epoch 1/10, Batch 30/49, Loss: 0.9083
Epoch 1/10, Batch 40/49, Loss: 0.7756
Epoch 1/10, Train Loss: 1.0123, Valid Loss: 0.6131
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6223
Epoch 2/10, Batch 20/49, Loss: 0.6397
Epoch 2/10, Batch 30/49, Loss: 0.4187
Epoch 2/10, Batch 40/49, Loss: 0.4977
Epoch 2/10, Train Loss: 0.5512, Valid Loss: 0.4192
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3950
Epoch 3/10, Batch 20/49, Loss: 0.3808
Epoch 3/10, Batch 30/49, Loss: 0.4870
Epoch 3/10, Batch 40/49, Loss: 0.3659
Epoch 3/10, Train Loss: 0.4198, Valid Loss: 0.3564
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2858
Epoch 4/10, Batch 20/49, Loss: 0.3719
Epoch 4/10, Batch 30/49, Loss: 0.4165
Epoch 4/10, Batch 40/49, Loss: 0.3513
Epoch 4/10, Train Loss: 0.3653, Valid Loss: 0.3171
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4093
Epoch 5/10, Batch 20/49, Loss: 0.3708
Epoch 5/10, Batch 30/49, Loss: 0.2690
Epoch 5/10, Batch 40/49, Loss: 0.2719
Epoch 5/10, Train Loss: 0.3238, Valid Loss: 0.2906
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2531
Epoch 6/10, Batch 20/49, Loss: 0.2447
Epoch 6/10, Batch 30/49, Loss: 0.1906
Epoch 6/10, Batch 40/49, Loss: 0.3051
Epoch 6/10, Train Loss: 0.2980, Valid Loss: 0.2745
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2335
Epoch 7/10, Batch 20/49, Loss: 0.2768
Epoch 7/10, Batch 30/49, Loss: 0.2556
Epoch 7/10, Batch 40/49, Loss: 0.1712
Epoch 7/10, Train Loss: 0.2483, Valid Loss: 0.2820
Epoch 8/10, Batch 10/49, Loss: 0.3036
Epoch 8/10, Batch 20/49, Loss: 0.1649
Epoch 8/10, Batch 30/49, Loss: 0.2494
Epoch 8/10, Batch 40/49, Loss: 0.2535
Epoch 8/10, Train Loss: 0.2420, Valid Loss: 0.2611
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1389
Epoch 9/10, Batch 20/49, Loss: 0.2349
Epoch 9/10, Batch 30/49, Loss: 0.2667
Epoch 9/10, Batch 40/49, Loss: 0.2101
Epoch 9/10, Train Loss: 0.2328, Valid Loss: 0.2552
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2868
Epoch 10/10, Batch 20/49, Loss: 0.3513
Epoch 10/10, Batch 30/49, Loss: 0.1530
Epoch 10/10, Batch 40/49, Loss: 0.2260
Epoch 10/10, Train Loss: 0.2189, Valid Loss: 0.2516
Model saved!
Accuracy: 0.9065
Precision: 0.9035
Recall: 0.9065
F1-score: 0.9032
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1849
Epoch 1/10, Batch 20/49, Loss: 1.1906
Epoch 1/10, Batch 30/49, Loss: 0.7479
Epoch 1/10, Batch 40/49, Loss: 0.7723
Epoch 1/10, Train Loss: 1.0124, Valid Loss: 0.6448
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6118
Epoch 2/10, Batch 20/49, Loss: 0.7366
Epoch 2/10, Batch 30/49, Loss: 0.5661
Epoch 2/10, Batch 40/49, Loss: 0.4006
Epoch 2/10, Train Loss: 0.5533, Valid Loss: 0.4495
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3935
Epoch 3/10, Batch 20/49, Loss: 0.2775
Epoch 3/10, Batch 30/49, Loss: 0.4629
Epoch 3/10, Batch 40/49, Loss: 0.4906
Epoch 3/10, Train Loss: 0.4132, Valid Loss: 0.4116
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3096
Epoch 4/10, Batch 20/49, Loss: 0.3426
Epoch 4/10, Batch 30/49, Loss: 0.3018
Epoch 4/10, Batch 40/49, Loss: 0.4488
Epoch 4/10, Train Loss: 0.3664, Valid Loss: 0.3426
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4731
Epoch 5/10, Batch 20/49, Loss: 0.2048
Epoch 5/10, Batch 30/49, Loss: 0.1744
Epoch 5/10, Batch 40/49, Loss: 0.3273
Epoch 5/10, Train Loss: 0.3307, Valid Loss: 0.3086
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3340
Epoch 6/10, Batch 20/49, Loss: 0.1587
Epoch 6/10, Batch 30/49, Loss: 0.3544
Epoch 6/10, Batch 40/49, Loss: 0.2563
Epoch 6/10, Train Loss: 0.3013, Valid Loss: 0.3003
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2577
Epoch 7/10, Batch 20/49, Loss: 0.3792
Epoch 7/10, Batch 30/49, Loss: 0.2389
Epoch 7/10, Batch 40/49, Loss: 0.2102
Epoch 7/10, Train Loss: 0.2622, Valid Loss: 0.2960
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.4157
Epoch 8/10, Batch 20/49, Loss: 0.1788
Epoch 8/10, Batch 30/49, Loss: 0.2061
Epoch 8/10, Batch 40/49, Loss: 0.2898
Epoch 8/10, Train Loss: 0.2633, Valid Loss: 0.2768
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2054
Epoch 9/10, Batch 20/49, Loss: 0.1642
Epoch 9/10, Batch 30/49, Loss: 0.3611
Epoch 9/10, Batch 40/49, Loss: 0.3649
Epoch 9/10, Train Loss: 0.2479, Valid Loss: 0.2640
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3843
Epoch 10/10, Batch 20/49, Loss: 0.2459
Epoch 10/10, Batch 30/49, Loss: 0.1431
Epoch 10/10, Batch 40/49, Loss: 0.1928
Epoch 10/10, Train Loss: 0.2191, Valid Loss: 0.2668
Accuracy: 0.9136
Precision: 0.9106
Recall: 0.9136
F1-score: 0.9109
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2197
Epoch 1/10, Batch 20/49, Loss: 1.0930
Epoch 1/10, Batch 30/49, Loss: 0.8281
Epoch 1/10, Batch 40/49, Loss: 0.9662
Epoch 1/10, Train Loss: 1.0174, Valid Loss: 0.6092
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6151
Epoch 2/10, Batch 20/49, Loss: 0.6327
Epoch 2/10, Batch 30/49, Loss: 0.4525
Epoch 2/10, Batch 40/49, Loss: 0.4784
Epoch 2/10, Train Loss: 0.5450, Valid Loss: 0.4377
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3884
Epoch 3/10, Batch 20/49, Loss: 0.2903
Epoch 3/10, Batch 30/49, Loss: 0.4262
Epoch 3/10, Batch 40/49, Loss: 0.3854
Epoch 3/10, Train Loss: 0.4285, Valid Loss: 0.3800
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4696
Epoch 4/10, Batch 20/49, Loss: 0.3086
Epoch 4/10, Batch 30/49, Loss: 0.3576
Epoch 4/10, Batch 40/49, Loss: 0.3578
Epoch 4/10, Train Loss: 0.3632, Valid Loss: 0.3368
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4885
Epoch 5/10, Batch 20/49, Loss: 0.2809
Epoch 5/10, Batch 30/49, Loss: 0.2260
Epoch 5/10, Batch 40/49, Loss: 0.2683
Epoch 5/10, Train Loss: 0.3241, Valid Loss: 0.3071
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3632
Epoch 6/10, Batch 20/49, Loss: 0.3116
Epoch 6/10, Batch 30/49, Loss: 0.2689
Epoch 6/10, Batch 40/49, Loss: 0.2148
Epoch 6/10, Train Loss: 0.3008, Valid Loss: 0.2942
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1741
Epoch 7/10, Batch 20/49, Loss: 0.2507
Epoch 7/10, Batch 30/49, Loss: 0.2253
Epoch 7/10, Batch 40/49, Loss: 0.2142
Epoch 7/10, Train Loss: 0.2715, Valid Loss: 0.2891
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2635
Epoch 8/10, Batch 20/49, Loss: 0.1505
Epoch 8/10, Batch 30/49, Loss: 0.1959
Epoch 8/10, Batch 40/49, Loss: 0.2193
Epoch 8/10, Train Loss: 0.2515, Valid Loss: 0.2709
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2333
Epoch 9/10, Batch 20/49, Loss: 0.1531
Epoch 9/10, Batch 30/49, Loss: 0.2993
Epoch 9/10, Batch 40/49, Loss: 0.3555
Epoch 9/10, Train Loss: 0.2560, Valid Loss: 0.2622
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3105
Epoch 10/10, Batch 20/49, Loss: 0.1526
Epoch 10/10, Batch 30/49, Loss: 0.1818
Epoch 10/10, Batch 40/49, Loss: 0.2503
Epoch 10/10, Train Loss: 0.2230, Valid Loss: 0.2711
Accuracy: 0.9100
Precision: 0.9070
Recall: 0.9100
F1-score: 0.9082
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2521
Epoch 1/10, Batch 20/49, Loss: 1.0791
Epoch 1/10, Batch 30/49, Loss: 0.8650
Epoch 1/10, Batch 40/49, Loss: 0.8241
Epoch 1/10, Train Loss: 1.0001, Valid Loss: 0.6195
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5684
Epoch 2/10, Batch 20/49, Loss: 0.6804
Epoch 2/10, Batch 30/49, Loss: 0.3514
Epoch 2/10, Batch 40/49, Loss: 0.4188
Epoch 2/10, Train Loss: 0.5396, Valid Loss: 0.4349
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4938
Epoch 3/10, Batch 20/49, Loss: 0.4189
Epoch 3/10, Batch 30/49, Loss: 0.4572
Epoch 3/10, Batch 40/49, Loss: 0.4675
Epoch 3/10, Train Loss: 0.4254, Valid Loss: 0.3678
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.5181
Epoch 4/10, Batch 20/49, Loss: 0.3553
Epoch 4/10, Batch 30/49, Loss: 0.3314
Epoch 4/10, Batch 40/49, Loss: 0.5842
Epoch 4/10, Train Loss: 0.3719, Valid Loss: 0.3255
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3733
Epoch 5/10, Batch 20/49, Loss: 0.2178
Epoch 5/10, Batch 30/49, Loss: 0.2517
Epoch 5/10, Batch 40/49, Loss: 0.2859
Epoch 5/10, Train Loss: 0.3309, Valid Loss: 0.3011
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3405
Epoch 6/10, Batch 20/49, Loss: 0.2698
Epoch 6/10, Batch 30/49, Loss: 0.3161
Epoch 6/10, Batch 40/49, Loss: 0.3984
Epoch 6/10, Train Loss: 0.3036, Valid Loss: 0.2778
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.4208
Epoch 7/10, Batch 20/49, Loss: 0.4844
Epoch 7/10, Batch 30/49, Loss: 0.3185
Epoch 7/10, Batch 40/49, Loss: 0.1792
Epoch 7/10, Train Loss: 0.2778, Valid Loss: 0.2762
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2819
Epoch 8/10, Batch 20/49, Loss: 0.2352
Epoch 8/10, Batch 30/49, Loss: 0.2564
Epoch 8/10, Batch 40/49, Loss: 0.2007
Epoch 8/10, Train Loss: 0.2577, Valid Loss: 0.2717
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2871
Epoch 9/10, Batch 20/49, Loss: 0.1834
Epoch 9/10, Batch 30/49, Loss: 0.2212
Epoch 9/10, Batch 40/49, Loss: 0.3020
Epoch 9/10, Train Loss: 0.2408, Valid Loss: 0.2524
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3449
Epoch 10/10, Batch 20/49, Loss: 0.2094
Epoch 10/10, Batch 30/49, Loss: 0.3049
Epoch 10/10, Batch 40/49, Loss: 0.2503
Epoch 10/10, Train Loss: 0.2224, Valid Loss: 0.2614
Accuracy: 0.9100
Precision: 0.9070
Recall: 0.9100
F1-score: 0.9075
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2568
Epoch 1/10, Batch 20/49, Loss: 1.0848
Epoch 1/10, Batch 30/49, Loss: 0.8614
Epoch 1/10, Batch 40/49, Loss: 0.8558
Epoch 1/10, Train Loss: 1.0078, Valid Loss: 0.6174
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6077
Epoch 2/10, Batch 20/49, Loss: 0.6893
Epoch 2/10, Batch 30/49, Loss: 0.5249
Epoch 2/10, Batch 40/49, Loss: 0.4777
Epoch 2/10, Train Loss: 0.5405, Valid Loss: 0.4197
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4115
Epoch 3/10, Batch 20/49, Loss: 0.4129
Epoch 3/10, Batch 30/49, Loss: 0.3999
Epoch 3/10, Batch 40/49, Loss: 0.3905
Epoch 3/10, Train Loss: 0.4227, Valid Loss: 0.3753
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4702
Epoch 4/10, Batch 20/49, Loss: 0.3936
Epoch 4/10, Batch 30/49, Loss: 0.4488
Epoch 4/10, Batch 40/49, Loss: 0.3991
Epoch 4/10, Train Loss: 0.3730, Valid Loss: 0.3370
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3766
Epoch 5/10, Batch 20/49, Loss: 0.3764
Epoch 5/10, Batch 30/49, Loss: 0.2164
Epoch 5/10, Batch 40/49, Loss: 0.3898
Epoch 5/10, Train Loss: 0.3091, Valid Loss: 0.3166
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.4020
Epoch 6/10, Batch 20/49, Loss: 0.3409
Epoch 6/10, Batch 30/49, Loss: 0.1830
Epoch 6/10, Batch 40/49, Loss: 0.2425
Epoch 6/10, Train Loss: 0.2946, Valid Loss: 0.3033
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1806
Epoch 7/10, Batch 20/49, Loss: 0.2861
Epoch 7/10, Batch 30/49, Loss: 0.2636
Epoch 7/10, Batch 40/49, Loss: 0.3208
Epoch 7/10, Train Loss: 0.2509, Valid Loss: 0.2966
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2416
Epoch 8/10, Batch 20/49, Loss: 0.1672
Epoch 8/10, Batch 30/49, Loss: 0.2516
Epoch 8/10, Batch 40/49, Loss: 0.1231
Epoch 8/10, Train Loss: 0.2411, Valid Loss: 0.2835
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2071
Epoch 9/10, Batch 20/49, Loss: 0.1416
Epoch 9/10, Batch 30/49, Loss: 0.2590
Epoch 9/10, Batch 40/49, Loss: 0.3980
Epoch 9/10, Train Loss: 0.2322, Valid Loss: 0.2745
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2063
Epoch 10/10, Batch 20/49, Loss: 0.1996
Epoch 10/10, Batch 30/49, Loss: 0.3413
Epoch 10/10, Batch 40/49, Loss: 0.1986
Epoch 10/10, Train Loss: 0.2110, Valid Loss: 0.2834
Accuracy: 0.9112
Precision: 0.9080
Recall: 0.9112
F1-score: 0.9090
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1848
Epoch 1/10, Batch 20/49, Loss: 1.0915
Epoch 1/10, Batch 30/49, Loss: 0.8938
Epoch 1/10, Batch 40/49, Loss: 0.7337
Epoch 1/10, Train Loss: 1.0297, Valid Loss: 0.6725
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7476
Epoch 2/10, Batch 20/49, Loss: 0.6436
Epoch 2/10, Batch 30/49, Loss: 0.5963
Epoch 2/10, Batch 40/49, Loss: 0.4797
Epoch 2/10, Train Loss: 0.5652, Valid Loss: 0.4933
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4703
Epoch 3/10, Batch 20/49, Loss: 0.3605
Epoch 3/10, Batch 30/49, Loss: 0.3662
Epoch 3/10, Batch 40/49, Loss: 0.3829
Epoch 3/10, Train Loss: 0.4366, Valid Loss: 0.4287
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3213
Epoch 4/10, Batch 20/49, Loss: 0.3726
Epoch 4/10, Batch 30/49, Loss: 0.3124
Epoch 4/10, Batch 40/49, Loss: 0.4768
Epoch 4/10, Train Loss: 0.3747, Valid Loss: 0.3797
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3507
Epoch 5/10, Batch 20/49, Loss: 0.1983
Epoch 5/10, Batch 30/49, Loss: 0.1496
Epoch 5/10, Batch 40/49, Loss: 0.2641
Epoch 5/10, Train Loss: 0.3263, Valid Loss: 0.3465
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2854
Epoch 6/10, Batch 20/49, Loss: 0.2978
Epoch 6/10, Batch 30/49, Loss: 0.2377
Epoch 6/10, Batch 40/49, Loss: 0.3821
Epoch 6/10, Train Loss: 0.3064, Valid Loss: 0.3299
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2127
Epoch 7/10, Batch 20/49, Loss: 0.3925
Epoch 7/10, Batch 30/49, Loss: 0.1919
Epoch 7/10, Batch 40/49, Loss: 0.2658
Epoch 7/10, Train Loss: 0.2675, Valid Loss: 0.3420
Epoch 8/10, Batch 10/49, Loss: 0.3612
Epoch 8/10, Batch 20/49, Loss: 0.1610
Epoch 8/10, Batch 30/49, Loss: 0.2702
Epoch 8/10, Batch 40/49, Loss: 0.1889
Epoch 8/10, Train Loss: 0.2527, Valid Loss: 0.3211
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2190
Epoch 9/10, Batch 20/49, Loss: 0.1729
Epoch 9/10, Batch 30/49, Loss: 0.3156
Epoch 9/10, Batch 40/49, Loss: 0.2828
Epoch 9/10, Train Loss: 0.2519, Valid Loss: 0.3039
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2203
Epoch 10/10, Batch 20/49, Loss: 0.1926
Epoch 10/10, Batch 30/49, Loss: 0.1744
Epoch 10/10, Batch 40/49, Loss: 0.2005
Epoch 10/10, Train Loss: 0.2289, Valid Loss: 0.3131
Accuracy: 0.9054
Precision: 0.9015
Recall: 0.9054
F1-score: 0.9027
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2161
Epoch 1/10, Batch 20/49, Loss: 1.0695
Epoch 1/10, Batch 30/49, Loss: 0.8713
Epoch 1/10, Batch 40/49, Loss: 0.8819
Epoch 1/10, Train Loss: 1.0117, Valid Loss: 0.6203
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5903
Epoch 2/10, Batch 20/49, Loss: 0.5943
Epoch 2/10, Batch 30/49, Loss: 0.5388
Epoch 2/10, Batch 40/49, Loss: 0.5719
Epoch 2/10, Train Loss: 0.5589, Valid Loss: 0.4328
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3490
Epoch 3/10, Batch 20/49, Loss: 0.3354
Epoch 3/10, Batch 30/49, Loss: 0.4401
Epoch 3/10, Batch 40/49, Loss: 0.4253
Epoch 3/10, Train Loss: 0.4207, Valid Loss: 0.3670
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3423
Epoch 4/10, Batch 20/49, Loss: 0.3802
Epoch 4/10, Batch 30/49, Loss: 0.3642
Epoch 4/10, Batch 40/49, Loss: 0.3265
Epoch 4/10, Train Loss: 0.3794, Valid Loss: 0.3172
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3696
Epoch 5/10, Batch 20/49, Loss: 0.2359
Epoch 5/10, Batch 30/49, Loss: 0.3106
Epoch 5/10, Batch 40/49, Loss: 0.3322
Epoch 5/10, Train Loss: 0.3305, Valid Loss: 0.2950
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2806
Epoch 6/10, Batch 20/49, Loss: 0.2655
Epoch 6/10, Batch 30/49, Loss: 0.2596
Epoch 6/10, Batch 40/49, Loss: 0.3369
Epoch 6/10, Train Loss: 0.3064, Valid Loss: 0.2789
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3272
Epoch 7/10, Batch 20/49, Loss: 0.3323
Epoch 7/10, Batch 30/49, Loss: 0.2626
Epoch 7/10, Batch 40/49, Loss: 0.1813
Epoch 7/10, Train Loss: 0.2752, Valid Loss: 0.2889
Epoch 8/10, Batch 10/49, Loss: 0.2573
Epoch 8/10, Batch 20/49, Loss: 0.4328
Epoch 8/10, Batch 30/49, Loss: 0.2415
Epoch 8/10, Batch 40/49, Loss: 0.2266
Epoch 8/10, Train Loss: 0.2617, Valid Loss: 0.2738
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2011
Epoch 9/10, Batch 20/49, Loss: 0.1940
Epoch 9/10, Batch 30/49, Loss: 0.3306
Epoch 9/10, Batch 40/49, Loss: 0.3410
Epoch 9/10, Train Loss: 0.2507, Valid Loss: 0.2637
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3241
Epoch 10/10, Batch 20/49, Loss: 0.1562
Epoch 10/10, Batch 30/49, Loss: 0.2869
Epoch 10/10, Batch 40/49, Loss: 0.1709
Epoch 10/10, Train Loss: 0.2246, Valid Loss: 0.2681
Accuracy: 0.9065
Precision: 0.9030
Recall: 0.9065
F1-score: 0.9029
Memory Allocated after cleanup: 17.76 MB
End time: 2025-02-25 12:21:46.005438
Duration: 3:30:19


Mejor accuracy al acabar el algoritmo: 0.9147


Fitness check:

Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2200
Epoch 1/10, Batch 20/49, Loss: 1.1199
Epoch 1/10, Batch 30/49, Loss: 0.9037
Epoch 1/10, Batch 40/49, Loss: 0.7922
Epoch 1/10, Train Loss: 1.0189, Valid Loss: 0.6034
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7039
Epoch 2/10, Batch 20/49, Loss: 0.7310
Epoch 2/10, Batch 30/49, Loss: 0.5430
Epoch 2/10, Batch 40/49, Loss: 0.4879
Epoch 2/10, Train Loss: 0.5644, Valid Loss: 0.4173
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4457
Epoch 3/10, Batch 20/49, Loss: 0.5308
Epoch 3/10, Batch 30/49, Loss: 0.4206
Epoch 3/10, Batch 40/49, Loss: 0.4987
Epoch 3/10, Train Loss: 0.4271, Valid Loss: 0.3590
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3297
Epoch 4/10, Batch 20/49, Loss: 0.3097
Epoch 4/10, Batch 30/49, Loss: 0.3490
Epoch 4/10, Batch 40/49, Loss: 0.3984
Epoch 4/10, Train Loss: 0.3751, Valid Loss: 0.3181
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4168
Epoch 5/10, Batch 20/49, Loss: 0.4220
Epoch 5/10, Batch 30/49, Loss: 0.2916
Epoch 5/10, Batch 40/49, Loss: 0.3388
Epoch 5/10, Train Loss: 0.3377, Valid Loss: 0.2828
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2823
Epoch 6/10, Batch 20/49, Loss: 0.1684
Epoch 6/10, Batch 30/49, Loss: 0.2543
Epoch 6/10, Batch 40/49, Loss: 0.2955
Epoch 6/10, Train Loss: 0.2979, Valid Loss: 0.2626
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2235
Epoch 7/10, Batch 20/49, Loss: 0.2948
Epoch 7/10, Batch 30/49, Loss: 0.2532
Epoch 7/10, Batch 40/49, Loss: 0.1145
Epoch 7/10, Train Loss: 0.2627, Valid Loss: 0.2660
Epoch 8/10, Batch 10/49, Loss: 0.3300
Epoch 8/10, Batch 20/49, Loss: 0.1344
Epoch 8/10, Batch 30/49, Loss: 0.2094
Epoch 8/10, Batch 40/49, Loss: 0.1338
Epoch 8/10, Train Loss: 0.2576, Valid Loss: 0.2518
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2171
Epoch 9/10, Batch 20/49, Loss: 0.1980
Epoch 9/10, Batch 30/49, Loss: 0.3508
Epoch 9/10, Batch 40/49, Loss: 0.2171
Epoch 9/10, Train Loss: 0.2420, Valid Loss: 0.2372
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2166
Epoch 10/10, Batch 20/49, Loss: 0.2467
Epoch 10/10, Batch 30/49, Loss: 0.1500
Epoch 10/10, Batch 40/49, Loss: 0.2515
Epoch 10/10, Train Loss: 0.2300, Valid Loss: 0.2400
Accuracy: 0.9147
Precision: 0.9122
Recall: 0.9147
F1-score: 0.9115
Memory Allocated after cleanup: 17.76 MB


Mejor accuracy encontrado: 0.9147


--------------------------------------mobilenet  BUSQUEDA LOCAL  50%-------------------------------------------------
Start time: 2025-02-25 12:23:48.325059
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2789
Epoch 1/10, Batch 20/97, Loss: 1.1758
Epoch 1/10, Batch 30/97, Loss: 0.7151
Epoch 1/10, Batch 40/97, Loss: 0.7187
Epoch 1/10, Batch 50/97, Loss: 0.6363
Epoch 1/10, Batch 60/97, Loss: 0.6500
Epoch 1/10, Batch 70/97, Loss: 0.6647
Epoch 1/10, Batch 80/97, Loss: 0.6169
Epoch 1/10, Batch 90/97, Loss: 0.6921
Epoch 1/10, Train Loss: 0.8069, Valid Loss: 0.4314
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5756
Epoch 2/10, Batch 20/97, Loss: 0.4278
Epoch 2/10, Batch 30/97, Loss: 0.3465
Epoch 2/10, Batch 40/97, Loss: 0.3855
Epoch 2/10, Batch 50/97, Loss: 0.3569
Epoch 2/10, Batch 60/97, Loss: 0.4299
Epoch 2/10, Batch 70/97, Loss: 0.4248
Epoch 2/10, Batch 80/97, Loss: 0.3488
Epoch 2/10, Batch 90/97, Loss: 0.3915
Epoch 2/10, Train Loss: 0.4218, Valid Loss: 0.3288
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.5110
Epoch 3/10, Batch 20/97, Loss: 0.3121
Epoch 3/10, Batch 30/97, Loss: 0.4178
Epoch 3/10, Batch 40/97, Loss: 0.2465
Epoch 3/10, Batch 50/97, Loss: 0.4070
Epoch 3/10, Batch 60/97, Loss: 0.3082
Epoch 3/10, Batch 70/97, Loss: 0.3878
Epoch 3/10, Batch 80/97, Loss: 0.3929
Epoch 3/10, Batch 90/97, Loss: 0.2681
Epoch 3/10, Train Loss: 0.3433, Valid Loss: 0.2790
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3707
Epoch 4/10, Batch 20/97, Loss: 0.2366
Epoch 4/10, Batch 30/97, Loss: 0.2457
Epoch 4/10, Batch 40/97, Loss: 0.2459
Epoch 4/10, Batch 50/97, Loss: 0.3668
Epoch 4/10, Batch 60/97, Loss: 0.2690
Epoch 4/10, Batch 70/97, Loss: 0.2746
Epoch 4/10, Batch 80/97, Loss: 0.3024
Epoch 4/10, Batch 90/97, Loss: 0.1820
Epoch 4/10, Train Loss: 0.2945, Valid Loss: 0.2599
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2563
Epoch 5/10, Batch 20/97, Loss: 0.3100
Epoch 5/10, Batch 30/97, Loss: 0.1881
Epoch 5/10, Batch 40/97, Loss: 0.2480
Epoch 5/10, Batch 50/97, Loss: 0.1918
Epoch 5/10, Batch 60/97, Loss: 0.3575
Epoch 5/10, Batch 70/97, Loss: 0.2762
Epoch 5/10, Batch 80/97, Loss: 0.3282
Epoch 5/10, Batch 90/97, Loss: 0.2382
Epoch 5/10, Train Loss: 0.2741, Valid Loss: 0.2470
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1512
Epoch 6/10, Batch 20/97, Loss: 0.2773
Epoch 6/10, Batch 30/97, Loss: 0.1441
Epoch 6/10, Batch 40/97, Loss: 0.2048
Epoch 6/10, Batch 50/97, Loss: 0.2710
Epoch 6/10, Batch 60/97, Loss: 0.3277
Epoch 6/10, Batch 70/97, Loss: 0.2886
Epoch 6/10, Batch 80/97, Loss: 0.3345
Epoch 6/10, Batch 90/97, Loss: 0.2177
Epoch 6/10, Train Loss: 0.2529, Valid Loss: 0.2376
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1554
Epoch 7/10, Batch 20/97, Loss: 0.4749
Epoch 7/10, Batch 30/97, Loss: 0.1602
Epoch 7/10, Batch 40/97, Loss: 0.1300
Epoch 7/10, Batch 50/97, Loss: 0.3067
Epoch 7/10, Batch 60/97, Loss: 0.1030
Epoch 7/10, Batch 70/97, Loss: 0.2908
Epoch 7/10, Batch 80/97, Loss: 0.3194
Epoch 7/10, Batch 90/97, Loss: 0.1374
Epoch 7/10, Train Loss: 0.2341, Valid Loss: 0.2276
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1003
Epoch 8/10, Batch 20/97, Loss: 0.2411
Epoch 8/10, Batch 30/97, Loss: 0.1005
Epoch 8/10, Batch 40/97, Loss: 0.1420
Epoch 8/10, Batch 50/97, Loss: 0.1684
Epoch 8/10, Batch 60/97, Loss: 0.2049
Epoch 8/10, Batch 70/97, Loss: 0.2956
Epoch 8/10, Batch 80/97, Loss: 0.1228
Epoch 8/10, Batch 90/97, Loss: 0.1963
Epoch 8/10, Train Loss: 0.2196, Valid Loss: 0.2309
Epoch 9/10, Batch 10/97, Loss: 0.0926
Epoch 9/10, Batch 20/97, Loss: 0.2847
Epoch 9/10, Batch 30/97, Loss: 0.1541
Epoch 9/10, Batch 40/97, Loss: 0.3346
Epoch 9/10, Batch 50/97, Loss: 0.1631
Epoch 9/10, Batch 60/97, Loss: 0.2140
Epoch 9/10, Batch 70/97, Loss: 0.1770
Epoch 9/10, Batch 80/97, Loss: 0.1077
Epoch 9/10, Batch 90/97, Loss: 0.1944
Epoch 9/10, Train Loss: 0.2145, Valid Loss: 0.2217
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.4044
Epoch 10/10, Batch 20/97, Loss: 0.0695
Epoch 10/10, Batch 30/97, Loss: 0.1738
Epoch 10/10, Batch 40/97, Loss: 0.3422
Epoch 10/10, Batch 50/97, Loss: 0.2580
Epoch 10/10, Batch 60/97, Loss: 0.1266
Epoch 10/10, Batch 70/97, Loss: 0.1723
Epoch 10/10, Batch 80/97, Loss: 0.1509
Epoch 10/10, Batch 90/97, Loss: 0.1856
Epoch 10/10, Train Loss: 0.2086, Valid Loss: 0.2195
Model saved!
Accuracy: 0.9182
Precision: 0.9153
Recall: 0.9182
F1-score: 0.9159
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2245
Epoch 1/10, Batch 20/97, Loss: 1.0549
Epoch 1/10, Batch 30/97, Loss: 0.7407
Epoch 1/10, Batch 40/97, Loss: 0.6346
Epoch 1/10, Batch 50/97, Loss: 0.7767
Epoch 1/10, Batch 60/97, Loss: 0.6701
Epoch 1/10, Batch 70/97, Loss: 0.7147
Epoch 1/10, Batch 80/97, Loss: 0.5622
Epoch 1/10, Batch 90/97, Loss: 0.5699
Epoch 1/10, Train Loss: 0.7962, Valid Loss: 0.4627
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5610
Epoch 2/10, Batch 20/97, Loss: 0.3800
Epoch 2/10, Batch 30/97, Loss: 0.3869
Epoch 2/10, Batch 40/97, Loss: 0.4174
Epoch 2/10, Batch 50/97, Loss: 0.5210
Epoch 2/10, Batch 60/97, Loss: 0.3419
Epoch 2/10, Batch 70/97, Loss: 0.3813
Epoch 2/10, Batch 80/97, Loss: 0.3736
Epoch 2/10, Batch 90/97, Loss: 0.3254
Epoch 2/10, Train Loss: 0.4115, Valid Loss: 0.3567
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3905
Epoch 3/10, Batch 20/97, Loss: 0.2731
Epoch 3/10, Batch 30/97, Loss: 0.3186
Epoch 3/10, Batch 40/97, Loss: 0.2225
Epoch 3/10, Batch 50/97, Loss: 0.2980
Epoch 3/10, Batch 60/97, Loss: 0.1421
Epoch 3/10, Batch 70/97, Loss: 0.3876
Epoch 3/10, Batch 80/97, Loss: 0.3003
Epoch 3/10, Batch 90/97, Loss: 0.2992
Epoch 3/10, Train Loss: 0.3291, Valid Loss: 0.3244
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3414
Epoch 4/10, Batch 20/97, Loss: 0.3353
Epoch 4/10, Batch 30/97, Loss: 0.2020
Epoch 4/10, Batch 40/97, Loss: 0.1977
Epoch 4/10, Batch 50/97, Loss: 0.2474
Epoch 4/10, Batch 60/97, Loss: 0.1698
Epoch 4/10, Batch 70/97, Loss: 0.4193
Epoch 4/10, Batch 80/97, Loss: 0.2060
Epoch 4/10, Batch 90/97, Loss: 0.3309
Epoch 4/10, Train Loss: 0.2848, Valid Loss: 0.2955
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1945
Epoch 5/10, Batch 20/97, Loss: 0.2600
Epoch 5/10, Batch 30/97, Loss: 0.2585
Epoch 5/10, Batch 40/97, Loss: 0.3136
Epoch 5/10, Batch 50/97, Loss: 0.2190
Epoch 5/10, Batch 60/97, Loss: 0.1794
Epoch 5/10, Batch 70/97, Loss: 0.3646
Epoch 5/10, Batch 80/97, Loss: 0.1708
Epoch 5/10, Batch 90/97, Loss: 0.2526
Epoch 5/10, Train Loss: 0.2650, Valid Loss: 0.2865
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3703
Epoch 6/10, Batch 20/97, Loss: 0.3275
Epoch 6/10, Batch 30/97, Loss: 0.1738
Epoch 6/10, Batch 40/97, Loss: 0.1809
Epoch 6/10, Batch 50/97, Loss: 0.2219
Epoch 6/10, Batch 60/97, Loss: 0.2971
Epoch 6/10, Batch 70/97, Loss: 0.3084
Epoch 6/10, Batch 80/97, Loss: 0.2317
Epoch 6/10, Batch 90/97, Loss: 0.1914
Epoch 6/10, Train Loss: 0.2451, Valid Loss: 0.2716
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2104
Epoch 7/10, Batch 20/97, Loss: 0.3405
Epoch 7/10, Batch 30/97, Loss: 0.1797
Epoch 7/10, Batch 40/97, Loss: 0.2566
Epoch 7/10, Batch 50/97, Loss: 0.3090
Epoch 7/10, Batch 60/97, Loss: 0.1375
Epoch 7/10, Batch 70/97, Loss: 0.1646
Epoch 7/10, Batch 80/97, Loss: 0.1146
Epoch 7/10, Batch 90/97, Loss: 0.1956
Epoch 7/10, Train Loss: 0.2260, Valid Loss: 0.2630
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1051
Epoch 8/10, Batch 20/97, Loss: 0.2438
Epoch 8/10, Batch 30/97, Loss: 0.2302
Epoch 8/10, Batch 40/97, Loss: 0.1420
Epoch 8/10, Batch 50/97, Loss: 0.2598
Epoch 8/10, Batch 60/97, Loss: 0.2133
Epoch 8/10, Batch 70/97, Loss: 0.1883
Epoch 8/10, Batch 80/97, Loss: 0.2271
Epoch 8/10, Batch 90/97, Loss: 0.1659
Epoch 8/10, Train Loss: 0.2219, Valid Loss: 0.2678
Epoch 9/10, Batch 10/97, Loss: 0.1702
Epoch 9/10, Batch 20/97, Loss: 0.1442
Epoch 9/10, Batch 30/97, Loss: 0.2081
Epoch 9/10, Batch 40/97, Loss: 0.2720
Epoch 9/10, Batch 50/97, Loss: 0.1653
Epoch 9/10, Batch 60/97, Loss: 0.2366
Epoch 9/10, Batch 70/97, Loss: 0.2188
Epoch 9/10, Batch 80/97, Loss: 0.1750
Epoch 9/10, Batch 90/97, Loss: 0.1392
Epoch 9/10, Train Loss: 0.2057, Valid Loss: 0.2598
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1411
Epoch 10/10, Batch 20/97, Loss: 0.1774
Epoch 10/10, Batch 30/97, Loss: 0.1672
Epoch 10/10, Batch 40/97, Loss: 0.0729
Epoch 10/10, Batch 50/97, Loss: 0.1285
Epoch 10/10, Batch 60/97, Loss: 0.1809
Epoch 10/10, Batch 70/97, Loss: 0.2356
Epoch 10/10, Batch 80/97, Loss: 0.1682
Epoch 10/10, Batch 90/97, Loss: 0.1446
Epoch 10/10, Train Loss: 0.1969, Valid Loss: 0.2578
Model saved!
Accuracy: 0.9171
Precision: 0.9136
Recall: 0.9171
F1-score: 0.9143
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2133
Epoch 1/10, Batch 20/97, Loss: 1.1349
Epoch 1/10, Batch 30/97, Loss: 0.7571
Epoch 1/10, Batch 40/97, Loss: 0.8101
Epoch 1/10, Batch 50/97, Loss: 0.6683
Epoch 1/10, Batch 60/97, Loss: 0.6770
Epoch 1/10, Batch 70/97, Loss: 0.6243
Epoch 1/10, Batch 80/97, Loss: 0.5716
Epoch 1/10, Batch 90/97, Loss: 0.5193
Epoch 1/10, Train Loss: 0.7942, Valid Loss: 0.4453
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5080
Epoch 2/10, Batch 20/97, Loss: 0.4300
Epoch 2/10, Batch 30/97, Loss: 0.3299
Epoch 2/10, Batch 40/97, Loss: 0.4314
Epoch 2/10, Batch 50/97, Loss: 0.4281
Epoch 2/10, Batch 60/97, Loss: 0.3191
Epoch 2/10, Batch 70/97, Loss: 0.5384
Epoch 2/10, Batch 80/97, Loss: 0.3476
Epoch 2/10, Batch 90/97, Loss: 0.3336
Epoch 2/10, Train Loss: 0.4042, Valid Loss: 0.3464
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3558
Epoch 3/10, Batch 20/97, Loss: 0.3171
Epoch 3/10, Batch 30/97, Loss: 0.5067
Epoch 3/10, Batch 40/97, Loss: 0.2870
Epoch 3/10, Batch 50/97, Loss: 0.4164
Epoch 3/10, Batch 60/97, Loss: 0.2241
Epoch 3/10, Batch 70/97, Loss: 0.4099
Epoch 3/10, Batch 80/97, Loss: 0.3061
Epoch 3/10, Batch 90/97, Loss: 0.2130
Epoch 3/10, Train Loss: 0.3294, Valid Loss: 0.3048
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4875
Epoch 4/10, Batch 20/97, Loss: 0.2631
Epoch 4/10, Batch 30/97, Loss: 0.2504
Epoch 4/10, Batch 40/97, Loss: 0.1989
Epoch 4/10, Batch 50/97, Loss: 0.3200
Epoch 4/10, Batch 60/97, Loss: 0.3117
Epoch 4/10, Batch 70/97, Loss: 0.4239
Epoch 4/10, Batch 80/97, Loss: 0.2114
Epoch 4/10, Batch 90/97, Loss: 0.1751
Epoch 4/10, Train Loss: 0.2780, Valid Loss: 0.2907
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2210
Epoch 5/10, Batch 20/97, Loss: 0.4205
Epoch 5/10, Batch 30/97, Loss: 0.1656
Epoch 5/10, Batch 40/97, Loss: 0.2685
Epoch 5/10, Batch 50/97, Loss: 0.2946
Epoch 5/10, Batch 60/97, Loss: 0.2293
Epoch 5/10, Batch 70/97, Loss: 0.1840
Epoch 5/10, Batch 80/97, Loss: 0.2588
Epoch 5/10, Batch 90/97, Loss: 0.1198
Epoch 5/10, Train Loss: 0.2612, Valid Loss: 0.2821
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1965
Epoch 6/10, Batch 20/97, Loss: 0.3556
Epoch 6/10, Batch 30/97, Loss: 0.2156
Epoch 6/10, Batch 40/97, Loss: 0.0592
Epoch 6/10, Batch 50/97, Loss: 0.2910
Epoch 6/10, Batch 60/97, Loss: 0.3042
Epoch 6/10, Batch 70/97, Loss: 0.2399
Epoch 6/10, Batch 80/97, Loss: 0.1849
Epoch 6/10, Batch 90/97, Loss: 0.2174
Epoch 6/10, Train Loss: 0.2344, Valid Loss: 0.2674
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2115
Epoch 7/10, Batch 20/97, Loss: 0.2214
Epoch 7/10, Batch 30/97, Loss: 0.2083
Epoch 7/10, Batch 40/97, Loss: 0.0910
Epoch 7/10, Batch 50/97, Loss: 0.2719
Epoch 7/10, Batch 60/97, Loss: 0.1378
Epoch 7/10, Batch 70/97, Loss: 0.1607
Epoch 7/10, Batch 80/97, Loss: 0.3271
Epoch 7/10, Batch 90/97, Loss: 0.2140
Epoch 7/10, Train Loss: 0.2184, Valid Loss: 0.2630
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1335
Epoch 8/10, Batch 20/97, Loss: 0.1719
Epoch 8/10, Batch 30/97, Loss: 0.1163
Epoch 8/10, Batch 40/97, Loss: 0.1812
Epoch 8/10, Batch 50/97, Loss: 0.1716
Epoch 8/10, Batch 60/97, Loss: 0.2361
Epoch 8/10, Batch 70/97, Loss: 0.1739
Epoch 8/10, Batch 80/97, Loss: 0.1890
Epoch 8/10, Batch 90/97, Loss: 0.1068
Epoch 8/10, Train Loss: 0.2195, Valid Loss: 0.2587
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.3178
Epoch 9/10, Batch 20/97, Loss: 0.2095
Epoch 9/10, Batch 30/97, Loss: 0.2579
Epoch 9/10, Batch 40/97, Loss: 0.2856
Epoch 9/10, Batch 50/97, Loss: 0.2083
Epoch 9/10, Batch 60/97, Loss: 0.2625
Epoch 9/10, Batch 70/97, Loss: 0.1317
Epoch 9/10, Batch 80/97, Loss: 0.1096
Epoch 9/10, Batch 90/97, Loss: 0.2168
Epoch 9/10, Train Loss: 0.1970, Valid Loss: 0.2562
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3264
Epoch 10/10, Batch 20/97, Loss: 0.1364
Epoch 10/10, Batch 30/97, Loss: 0.1731
Epoch 10/10, Batch 40/97, Loss: 0.1413
Epoch 10/10, Batch 50/97, Loss: 0.1372
Epoch 10/10, Batch 60/97, Loss: 0.0780
Epoch 10/10, Batch 70/97, Loss: 0.2912
Epoch 10/10, Batch 80/97, Loss: 0.2793
Epoch 10/10, Batch 90/97, Loss: 0.1503
Epoch 10/10, Train Loss: 0.2039, Valid Loss: 0.2547
Model saved!
Accuracy: 0.9147
Precision: 0.9122
Recall: 0.9147
F1-score: 0.9128
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2702
Epoch 1/10, Batch 20/97, Loss: 1.1317
Epoch 1/10, Batch 30/97, Loss: 0.7316
Epoch 1/10, Batch 40/97, Loss: 0.7825
Epoch 1/10, Batch 50/97, Loss: 0.7230
Epoch 1/10, Batch 60/97, Loss: 0.8216
Epoch 1/10, Batch 70/97, Loss: 0.6698
Epoch 1/10, Batch 80/97, Loss: 0.6495
Epoch 1/10, Batch 90/97, Loss: 0.6990
Epoch 1/10, Train Loss: 0.8039, Valid Loss: 0.4167
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5569
Epoch 2/10, Batch 20/97, Loss: 0.3238
Epoch 2/10, Batch 30/97, Loss: 0.3213
Epoch 2/10, Batch 40/97, Loss: 0.3576
Epoch 2/10, Batch 50/97, Loss: 0.3240
Epoch 2/10, Batch 60/97, Loss: 0.3387
Epoch 2/10, Batch 70/97, Loss: 0.4328
Epoch 2/10, Batch 80/97, Loss: 0.2988
Epoch 2/10, Batch 90/97, Loss: 0.4624
Epoch 2/10, Train Loss: 0.4140, Valid Loss: 0.3037
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4711
Epoch 3/10, Batch 20/97, Loss: 0.4158
Epoch 3/10, Batch 30/97, Loss: 0.4614
Epoch 3/10, Batch 40/97, Loss: 0.3121
Epoch 3/10, Batch 50/97, Loss: 0.2604
Epoch 3/10, Batch 60/97, Loss: 0.2224
Epoch 3/10, Batch 70/97, Loss: 0.2405
Epoch 3/10, Batch 80/97, Loss: 0.2066
Epoch 3/10, Batch 90/97, Loss: 0.3371
Epoch 3/10, Train Loss: 0.3372, Valid Loss: 0.2611
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4796
Epoch 4/10, Batch 20/97, Loss: 0.1672
Epoch 4/10, Batch 30/97, Loss: 0.3003
Epoch 4/10, Batch 40/97, Loss: 0.2414
Epoch 4/10, Batch 50/97, Loss: 0.1973
Epoch 4/10, Batch 60/97, Loss: 0.1614
Epoch 4/10, Batch 70/97, Loss: 0.2189
Epoch 4/10, Batch 80/97, Loss: 0.2441
Epoch 4/10, Batch 90/97, Loss: 0.3564
Epoch 4/10, Train Loss: 0.2880, Valid Loss: 0.2380
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2198
Epoch 5/10, Batch 20/97, Loss: 0.2848
Epoch 5/10, Batch 30/97, Loss: 0.1730
Epoch 5/10, Batch 40/97, Loss: 0.3305
Epoch 5/10, Batch 50/97, Loss: 0.2400
Epoch 5/10, Batch 60/97, Loss: 0.2136
Epoch 5/10, Batch 70/97, Loss: 0.3525
Epoch 5/10, Batch 80/97, Loss: 0.2611
Epoch 5/10, Batch 90/97, Loss: 0.2295
Epoch 5/10, Train Loss: 0.2610, Valid Loss: 0.2320
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2712
Epoch 6/10, Batch 20/97, Loss: 0.2228
Epoch 6/10, Batch 30/97, Loss: 0.1850
Epoch 6/10, Batch 40/97, Loss: 0.1788
Epoch 6/10, Batch 50/97, Loss: 0.2284
Epoch 6/10, Batch 60/97, Loss: 0.2306
Epoch 6/10, Batch 70/97, Loss: 0.2531
Epoch 6/10, Batch 80/97, Loss: 0.2719
Epoch 6/10, Batch 90/97, Loss: 0.2834
Epoch 6/10, Train Loss: 0.2442, Valid Loss: 0.2191
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1229
Epoch 7/10, Batch 20/97, Loss: 0.1926
Epoch 7/10, Batch 30/97, Loss: 0.1516
Epoch 7/10, Batch 40/97, Loss: 0.1532
Epoch 7/10, Batch 50/97, Loss: 0.2509
Epoch 7/10, Batch 60/97, Loss: 0.1919
Epoch 7/10, Batch 70/97, Loss: 0.1744
Epoch 7/10, Batch 80/97, Loss: 0.2941
Epoch 7/10, Batch 90/97, Loss: 0.1700
Epoch 7/10, Train Loss: 0.2283, Valid Loss: 0.2130
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1373
Epoch 8/10, Batch 20/97, Loss: 0.1537
Epoch 8/10, Batch 30/97, Loss: 0.1616
Epoch 8/10, Batch 40/97, Loss: 0.2038
Epoch 8/10, Batch 50/97, Loss: 0.1759
Epoch 8/10, Batch 60/97, Loss: 0.1614
Epoch 8/10, Batch 70/97, Loss: 0.2356
Epoch 8/10, Batch 80/97, Loss: 0.1767
Epoch 8/10, Batch 90/97, Loss: 0.2219
Epoch 8/10, Train Loss: 0.2225, Valid Loss: 0.2080
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1405
Epoch 9/10, Batch 20/97, Loss: 0.1536
Epoch 9/10, Batch 30/97, Loss: 0.2868
Epoch 9/10, Batch 40/97, Loss: 0.2680
Epoch 9/10, Batch 50/97, Loss: 0.1242
Epoch 9/10, Batch 60/97, Loss: 0.1538
Epoch 9/10, Batch 70/97, Loss: 0.1741
Epoch 9/10, Batch 80/97, Loss: 0.2580
Epoch 9/10, Batch 90/97, Loss: 0.1296
Epoch 9/10, Train Loss: 0.2049, Valid Loss: 0.2020
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1396
Epoch 10/10, Batch 20/97, Loss: 0.1429
Epoch 10/10, Batch 30/97, Loss: 0.1434
Epoch 10/10, Batch 40/97, Loss: 0.1692
Epoch 10/10, Batch 50/97, Loss: 0.1709
Epoch 10/10, Batch 60/97, Loss: 0.3140
Epoch 10/10, Batch 70/97, Loss: 0.2808
Epoch 10/10, Batch 80/97, Loss: 0.1657
Epoch 10/10, Batch 90/97, Loss: 0.2180
Epoch 10/10, Train Loss: 0.1940, Valid Loss: 0.1968
Model saved!
Accuracy: 0.9077
Precision: 0.9049
Recall: 0.9077
F1-score: 0.9036
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2321
Epoch 1/10, Batch 20/97, Loss: 1.1516
Epoch 1/10, Batch 30/97, Loss: 0.7727
Epoch 1/10, Batch 40/97, Loss: 0.7252
Epoch 1/10, Batch 50/97, Loss: 0.6382
Epoch 1/10, Batch 60/97, Loss: 0.7046
Epoch 1/10, Batch 70/97, Loss: 0.7615
Epoch 1/10, Batch 80/97, Loss: 0.6966
Epoch 1/10, Batch 90/97, Loss: 0.5975
Epoch 1/10, Train Loss: 0.8068, Valid Loss: 0.4343
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5775
Epoch 2/10, Batch 20/97, Loss: 0.4060
Epoch 2/10, Batch 30/97, Loss: 0.3328
Epoch 2/10, Batch 40/97, Loss: 0.3899
Epoch 2/10, Batch 50/97, Loss: 0.3900
Epoch 2/10, Batch 60/97, Loss: 0.3863
Epoch 2/10, Batch 70/97, Loss: 0.2850
Epoch 2/10, Batch 80/97, Loss: 0.2634
Epoch 2/10, Batch 90/97, Loss: 0.4181
Epoch 2/10, Train Loss: 0.4199, Valid Loss: 0.3252
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4856
Epoch 3/10, Batch 20/97, Loss: 0.4170
Epoch 3/10, Batch 30/97, Loss: 0.2724
Epoch 3/10, Batch 40/97, Loss: 0.3427
Epoch 3/10, Batch 50/97, Loss: 0.2677
Epoch 3/10, Batch 60/97, Loss: 0.2635
Epoch 3/10, Batch 70/97, Loss: 0.3073
Epoch 3/10, Batch 80/97, Loss: 0.3582
Epoch 3/10, Batch 90/97, Loss: 0.2884
Epoch 3/10, Train Loss: 0.3425, Valid Loss: 0.2878
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4085
Epoch 4/10, Batch 20/97, Loss: 0.2958
Epoch 4/10, Batch 30/97, Loss: 0.3307
Epoch 4/10, Batch 40/97, Loss: 0.2801
Epoch 4/10, Batch 50/97, Loss: 0.3602
Epoch 4/10, Batch 60/97, Loss: 0.2178
Epoch 4/10, Batch 70/97, Loss: 0.2268
Epoch 4/10, Batch 80/97, Loss: 0.1661
Epoch 4/10, Batch 90/97, Loss: 0.2358
Epoch 4/10, Train Loss: 0.2922, Valid Loss: 0.2680
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2958
Epoch 5/10, Batch 20/97, Loss: 0.3124
Epoch 5/10, Batch 30/97, Loss: 0.3191
Epoch 5/10, Batch 40/97, Loss: 0.3140
Epoch 5/10, Batch 50/97, Loss: 0.2881
Epoch 5/10, Batch 60/97, Loss: 0.1229
Epoch 5/10, Batch 70/97, Loss: 0.3334
Epoch 5/10, Batch 80/97, Loss: 0.3010
Epoch 5/10, Batch 90/97, Loss: 0.2979
Epoch 5/10, Train Loss: 0.2697, Valid Loss: 0.2619
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3001
Epoch 6/10, Batch 20/97, Loss: 0.3195
Epoch 6/10, Batch 30/97, Loss: 0.1888
Epoch 6/10, Batch 40/97, Loss: 0.2325
Epoch 6/10, Batch 50/97, Loss: 0.2937
Epoch 6/10, Batch 60/97, Loss: 0.2041
Epoch 6/10, Batch 70/97, Loss: 0.2531
Epoch 6/10, Batch 80/97, Loss: 0.3066
Epoch 6/10, Batch 90/97, Loss: 0.3171
Epoch 6/10, Train Loss: 0.2545, Valid Loss: 0.2421
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2853
Epoch 7/10, Batch 20/97, Loss: 0.3571
Epoch 7/10, Batch 30/97, Loss: 0.1049
Epoch 7/10, Batch 40/97, Loss: 0.2278
Epoch 7/10, Batch 50/97, Loss: 0.2991
Epoch 7/10, Batch 60/97, Loss: 0.1184
Epoch 7/10, Batch 70/97, Loss: 0.3184
Epoch 7/10, Batch 80/97, Loss: 0.1836
Epoch 7/10, Batch 90/97, Loss: 0.1975
Epoch 7/10, Train Loss: 0.2299, Valid Loss: 0.2352
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2090
Epoch 8/10, Batch 20/97, Loss: 0.3268
Epoch 8/10, Batch 30/97, Loss: 0.1502
Epoch 8/10, Batch 40/97, Loss: 0.3622
Epoch 8/10, Batch 50/97, Loss: 0.1921
Epoch 8/10, Batch 60/97, Loss: 0.2346
Epoch 8/10, Batch 70/97, Loss: 0.1834
Epoch 8/10, Batch 80/97, Loss: 0.1788
Epoch 8/10, Batch 90/97, Loss: 0.1844
Epoch 8/10, Train Loss: 0.2173, Valid Loss: 0.2391
Epoch 9/10, Batch 10/97, Loss: 0.2069
Epoch 9/10, Batch 20/97, Loss: 0.1358
Epoch 9/10, Batch 30/97, Loss: 0.3621
Epoch 9/10, Batch 40/97, Loss: 0.2557
Epoch 9/10, Batch 50/97, Loss: 0.1046
Epoch 9/10, Batch 60/97, Loss: 0.2167
Epoch 9/10, Batch 70/97, Loss: 0.0920
Epoch 9/10, Batch 80/97, Loss: 0.1484
Epoch 9/10, Batch 90/97, Loss: 0.2062
Epoch 9/10, Train Loss: 0.2155, Valid Loss: 0.2297
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3050
Epoch 10/10, Batch 20/97, Loss: 0.2276
Epoch 10/10, Batch 30/97, Loss: 0.1474
Epoch 10/10, Batch 40/97, Loss: 0.1976
Epoch 10/10, Batch 50/97, Loss: 0.2014
Epoch 10/10, Batch 60/97, Loss: 0.1888
Epoch 10/10, Batch 70/97, Loss: 0.2388
Epoch 10/10, Batch 80/97, Loss: 0.1942
Epoch 10/10, Batch 90/97, Loss: 0.2103
Epoch 10/10, Train Loss: 0.2029, Valid Loss: 0.2365
Accuracy: 0.9229
Precision: 0.9214
Recall: 0.9229
F1-score: 0.9219
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 5. Fitness: 0.9229
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2135
Epoch 1/10, Batch 20/97, Loss: 1.0425
Epoch 1/10, Batch 30/97, Loss: 0.7232
Epoch 1/10, Batch 40/97, Loss: 0.7142
Epoch 1/10, Batch 50/97, Loss: 0.6839
Epoch 1/10, Batch 60/97, Loss: 0.7413
Epoch 1/10, Batch 70/97, Loss: 0.6820
Epoch 1/10, Batch 80/97, Loss: 0.5408
Epoch 1/10, Batch 90/97, Loss: 0.5320
Epoch 1/10, Train Loss: 0.8163, Valid Loss: 0.4381
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4517
Epoch 2/10, Batch 20/97, Loss: 0.4286
Epoch 2/10, Batch 30/97, Loss: 0.3043
Epoch 2/10, Batch 40/97, Loss: 0.4295
Epoch 2/10, Batch 50/97, Loss: 0.3260
Epoch 2/10, Batch 60/97, Loss: 0.4240
Epoch 2/10, Batch 70/97, Loss: 0.3130
Epoch 2/10, Batch 80/97, Loss: 0.2559
Epoch 2/10, Batch 90/97, Loss: 0.4030
Epoch 2/10, Train Loss: 0.4192, Valid Loss: 0.3395
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3710
Epoch 3/10, Batch 20/97, Loss: 0.2689
Epoch 3/10, Batch 30/97, Loss: 0.2678
Epoch 3/10, Batch 40/97, Loss: 0.3103
Epoch 3/10, Batch 50/97, Loss: 0.3349
Epoch 3/10, Batch 60/97, Loss: 0.2063
Epoch 3/10, Batch 70/97, Loss: 0.3325
Epoch 3/10, Batch 80/97, Loss: 0.3016
Epoch 3/10, Batch 90/97, Loss: 0.2477
Epoch 3/10, Train Loss: 0.3507, Valid Loss: 0.2952
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2916
Epoch 4/10, Batch 20/97, Loss: 0.2168
Epoch 4/10, Batch 30/97, Loss: 0.4098
Epoch 4/10, Batch 40/97, Loss: 0.2202
Epoch 4/10, Batch 50/97, Loss: 0.3736
Epoch 4/10, Batch 60/97, Loss: 0.2175
Epoch 4/10, Batch 70/97, Loss: 0.2725
Epoch 4/10, Batch 80/97, Loss: 0.2037
Epoch 4/10, Batch 90/97, Loss: 0.1670
Epoch 4/10, Train Loss: 0.3044, Valid Loss: 0.2808
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2537
Epoch 5/10, Batch 20/97, Loss: 0.5316
Epoch 5/10, Batch 30/97, Loss: 0.1716
Epoch 5/10, Batch 40/97, Loss: 0.2136
Epoch 5/10, Batch 50/97, Loss: 0.1926
Epoch 5/10, Batch 60/97, Loss: 0.2410
Epoch 5/10, Batch 70/97, Loss: 0.4544
Epoch 5/10, Batch 80/97, Loss: 0.2494
Epoch 5/10, Batch 90/97, Loss: 0.2136
Epoch 5/10, Train Loss: 0.2728, Valid Loss: 0.2633
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1564
Epoch 6/10, Batch 20/97, Loss: 0.2809
Epoch 6/10, Batch 30/97, Loss: 0.3972
Epoch 6/10, Batch 40/97, Loss: 0.2307
Epoch 6/10, Batch 50/97, Loss: 0.3993
Epoch 6/10, Batch 60/97, Loss: 0.3373
Epoch 6/10, Batch 70/97, Loss: 0.1888
Epoch 6/10, Batch 80/97, Loss: 0.2699
Epoch 6/10, Batch 90/97, Loss: 0.2429
Epoch 6/10, Train Loss: 0.2570, Valid Loss: 0.2435
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1380
Epoch 7/10, Batch 20/97, Loss: 0.3191
Epoch 7/10, Batch 30/97, Loss: 0.1970
Epoch 7/10, Batch 40/97, Loss: 0.1754
Epoch 7/10, Batch 50/97, Loss: 0.2833
Epoch 7/10, Batch 60/97, Loss: 0.3788
Epoch 7/10, Batch 70/97, Loss: 0.2214
Epoch 7/10, Batch 80/97, Loss: 0.1435
Epoch 7/10, Batch 90/97, Loss: 0.2622
Epoch 7/10, Train Loss: 0.2308, Valid Loss: 0.2398
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1918
Epoch 8/10, Batch 20/97, Loss: 0.1957
Epoch 8/10, Batch 30/97, Loss: 0.2558
Epoch 8/10, Batch 40/97, Loss: 0.2194
Epoch 8/10, Batch 50/97, Loss: 0.2700
Epoch 8/10, Batch 60/97, Loss: 0.2524
Epoch 8/10, Batch 70/97, Loss: 0.3637
Epoch 8/10, Batch 80/97, Loss: 0.1476
Epoch 8/10, Batch 90/97, Loss: 0.2927
Epoch 8/10, Train Loss: 0.2333, Valid Loss: 0.2366
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2314
Epoch 9/10, Batch 20/97, Loss: 0.1877
Epoch 9/10, Batch 30/97, Loss: 0.1543
Epoch 9/10, Batch 40/97, Loss: 0.3842
Epoch 9/10, Batch 50/97, Loss: 0.1483
Epoch 9/10, Batch 60/97, Loss: 0.3278
Epoch 9/10, Batch 70/97, Loss: 0.1035
Epoch 9/10, Batch 80/97, Loss: 0.1970
Epoch 9/10, Batch 90/97, Loss: 0.2573
Epoch 9/10, Train Loss: 0.2131, Valid Loss: 0.2296
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3606
Epoch 10/10, Batch 20/97, Loss: 0.2265
Epoch 10/10, Batch 30/97, Loss: 0.2335
Epoch 10/10, Batch 40/97, Loss: 0.1393
Epoch 10/10, Batch 50/97, Loss: 0.2345
Epoch 10/10, Batch 60/97, Loss: 0.1767
Epoch 10/10, Batch 70/97, Loss: 0.2432
Epoch 10/10, Batch 80/97, Loss: 0.1503
Epoch 10/10, Batch 90/97, Loss: 0.2396
Epoch 10/10, Train Loss: 0.2100, Valid Loss: 0.2280
Model saved!
Accuracy: 0.9136
Precision: 0.9114
Recall: 0.9136
F1-score: 0.9108
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2327
Epoch 1/10, Batch 20/97, Loss: 1.1340
Epoch 1/10, Batch 30/97, Loss: 0.7834
Epoch 1/10, Batch 40/97, Loss: 0.7699
Epoch 1/10, Batch 50/97, Loss: 0.7144
Epoch 1/10, Batch 60/97, Loss: 0.7452
Epoch 1/10, Batch 70/97, Loss: 0.6058
Epoch 1/10, Batch 80/97, Loss: 0.6371
Epoch 1/10, Batch 90/97, Loss: 0.5319
Epoch 1/10, Train Loss: 0.7982, Valid Loss: 0.4494
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3826
Epoch 2/10, Batch 20/97, Loss: 0.4134
Epoch 2/10, Batch 30/97, Loss: 0.4250
Epoch 2/10, Batch 40/97, Loss: 0.5332
Epoch 2/10, Batch 50/97, Loss: 0.4339
Epoch 2/10, Batch 60/97, Loss: 0.4132
Epoch 2/10, Batch 70/97, Loss: 0.3752
Epoch 2/10, Batch 80/97, Loss: 0.3762
Epoch 2/10, Batch 90/97, Loss: 0.5864
Epoch 2/10, Train Loss: 0.4215, Valid Loss: 0.3440
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3044
Epoch 3/10, Batch 20/97, Loss: 0.3519
Epoch 3/10, Batch 30/97, Loss: 0.3262
Epoch 3/10, Batch 40/97, Loss: 0.1908
Epoch 3/10, Batch 50/97, Loss: 0.3662
Epoch 3/10, Batch 60/97, Loss: 0.2847
Epoch 3/10, Batch 70/97, Loss: 0.3533
Epoch 3/10, Batch 80/97, Loss: 0.3572
Epoch 3/10, Batch 90/97, Loss: 0.2927
Epoch 3/10, Train Loss: 0.3349, Valid Loss: 0.3071
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3783
Epoch 4/10, Batch 20/97, Loss: 0.2450
Epoch 4/10, Batch 30/97, Loss: 0.3310
Epoch 4/10, Batch 40/97, Loss: 0.3835
Epoch 4/10, Batch 50/97, Loss: 0.3121
Epoch 4/10, Batch 60/97, Loss: 0.3288
Epoch 4/10, Batch 70/97, Loss: 0.3902
Epoch 4/10, Batch 80/97, Loss: 0.2770
Epoch 4/10, Batch 90/97, Loss: 0.2698
Epoch 4/10, Train Loss: 0.2920, Valid Loss: 0.2841
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2876
Epoch 5/10, Batch 20/97, Loss: 0.1378
Epoch 5/10, Batch 30/97, Loss: 0.1925
Epoch 5/10, Batch 40/97, Loss: 0.2913
Epoch 5/10, Batch 50/97, Loss: 0.2816
Epoch 5/10, Batch 60/97, Loss: 0.2198
Epoch 5/10, Batch 70/97, Loss: 0.3171
Epoch 5/10, Batch 80/97, Loss: 0.3244
Epoch 5/10, Batch 90/97, Loss: 0.2502
Epoch 5/10, Train Loss: 0.2671, Valid Loss: 0.2698
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1697
Epoch 6/10, Batch 20/97, Loss: 0.3897
Epoch 6/10, Batch 30/97, Loss: 0.1824
Epoch 6/10, Batch 40/97, Loss: 0.1763
Epoch 6/10, Batch 50/97, Loss: 0.2955
Epoch 6/10, Batch 60/97, Loss: 0.3315
Epoch 6/10, Batch 70/97, Loss: 0.3180
Epoch 6/10, Batch 80/97, Loss: 0.4208
Epoch 6/10, Batch 90/97, Loss: 0.1990
Epoch 6/10, Train Loss: 0.2492, Valid Loss: 0.2563
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2475
Epoch 7/10, Batch 20/97, Loss: 0.3472
Epoch 7/10, Batch 30/97, Loss: 0.1514
Epoch 7/10, Batch 40/97, Loss: 0.2512
Epoch 7/10, Batch 50/97, Loss: 0.3396
Epoch 7/10, Batch 60/97, Loss: 0.1340
Epoch 7/10, Batch 70/97, Loss: 0.2294
Epoch 7/10, Batch 80/97, Loss: 0.1822
Epoch 7/10, Batch 90/97, Loss: 0.1677
Epoch 7/10, Train Loss: 0.2287, Valid Loss: 0.2516
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2120
Epoch 8/10, Batch 20/97, Loss: 0.1347
Epoch 8/10, Batch 30/97, Loss: 0.1863
Epoch 8/10, Batch 40/97, Loss: 0.1690
Epoch 8/10, Batch 50/97, Loss: 0.3808
Epoch 8/10, Batch 60/97, Loss: 0.2261
Epoch 8/10, Batch 70/97, Loss: 0.2182
Epoch 8/10, Batch 80/97, Loss: 0.2255
Epoch 8/10, Batch 90/97, Loss: 0.3423
Epoch 8/10, Train Loss: 0.2247, Valid Loss: 0.2482
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1717
Epoch 9/10, Batch 20/97, Loss: 0.1573
Epoch 9/10, Batch 30/97, Loss: 0.2433
Epoch 9/10, Batch 40/97, Loss: 0.2771
Epoch 9/10, Batch 50/97, Loss: 0.1977
Epoch 9/10, Batch 60/97, Loss: 0.2936
Epoch 9/10, Batch 70/97, Loss: 0.1696
Epoch 9/10, Batch 80/97, Loss: 0.1397
Epoch 9/10, Batch 90/97, Loss: 0.1443
Epoch 9/10, Train Loss: 0.2055, Valid Loss: 0.2413
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3444
Epoch 10/10, Batch 20/97, Loss: 0.1207
Epoch 10/10, Batch 30/97, Loss: 0.2293
Epoch 10/10, Batch 40/97, Loss: 0.1237
Epoch 10/10, Batch 50/97, Loss: 0.2792
Epoch 10/10, Batch 60/97, Loss: 0.1593
Epoch 10/10, Batch 70/97, Loss: 0.3037
Epoch 10/10, Batch 80/97, Loss: 0.1833
Epoch 10/10, Batch 90/97, Loss: 0.2944
Epoch 10/10, Train Loss: 0.2028, Valid Loss: 0.2433
Accuracy: 0.9206
Precision: 0.9189
Recall: 0.9206
F1-score: 0.9187
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2775
Epoch 1/10, Batch 20/97, Loss: 1.0781
Epoch 1/10, Batch 30/97, Loss: 0.7274
Epoch 1/10, Batch 40/97, Loss: 0.6965
Epoch 1/10, Batch 50/97, Loss: 0.8420
Epoch 1/10, Batch 60/97, Loss: 0.7838
Epoch 1/10, Batch 70/97, Loss: 0.5995
Epoch 1/10, Batch 80/97, Loss: 0.6168
Epoch 1/10, Batch 90/97, Loss: 0.5774
Epoch 1/10, Train Loss: 0.8087, Valid Loss: 0.4714
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5370
Epoch 2/10, Batch 20/97, Loss: 0.3865
Epoch 2/10, Batch 30/97, Loss: 0.3565
Epoch 2/10, Batch 40/97, Loss: 0.4440
Epoch 2/10, Batch 50/97, Loss: 0.4362
Epoch 2/10, Batch 60/97, Loss: 0.3985
Epoch 2/10, Batch 70/97, Loss: 0.3439
Epoch 2/10, Batch 80/97, Loss: 0.5572
Epoch 2/10, Batch 90/97, Loss: 0.4808
Epoch 2/10, Train Loss: 0.4146, Valid Loss: 0.3671
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3285
Epoch 3/10, Batch 20/97, Loss: 0.3291
Epoch 3/10, Batch 30/97, Loss: 0.4154
Epoch 3/10, Batch 40/97, Loss: 0.2341
Epoch 3/10, Batch 50/97, Loss: 0.3878
Epoch 3/10, Batch 60/97, Loss: 0.2130
Epoch 3/10, Batch 70/97, Loss: 0.2602
Epoch 3/10, Batch 80/97, Loss: 0.2696
Epoch 3/10, Batch 90/97, Loss: 0.3230
Epoch 3/10, Train Loss: 0.3356, Valid Loss: 0.3174
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3667
Epoch 4/10, Batch 20/97, Loss: 0.3162
Epoch 4/10, Batch 30/97, Loss: 0.4250
Epoch 4/10, Batch 40/97, Loss: 0.2048
Epoch 4/10, Batch 50/97, Loss: 0.3159
Epoch 4/10, Batch 60/97, Loss: 0.3164
Epoch 4/10, Batch 70/97, Loss: 0.2426
Epoch 4/10, Batch 80/97, Loss: 0.2558
Epoch 4/10, Batch 90/97, Loss: 0.2285
Epoch 4/10, Train Loss: 0.2847, Valid Loss: 0.2950
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2681
Epoch 5/10, Batch 20/97, Loss: 0.2047
Epoch 5/10, Batch 30/97, Loss: 0.2640
Epoch 5/10, Batch 40/97, Loss: 0.1723
Epoch 5/10, Batch 50/97, Loss: 0.2252
Epoch 5/10, Batch 60/97, Loss: 0.2710
Epoch 5/10, Batch 70/97, Loss: 0.3196
Epoch 5/10, Batch 80/97, Loss: 0.2407
Epoch 5/10, Batch 90/97, Loss: 0.2325
Epoch 5/10, Train Loss: 0.2687, Valid Loss: 0.2786
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2173
Epoch 6/10, Batch 20/97, Loss: 0.4036
Epoch 6/10, Batch 30/97, Loss: 0.2222
Epoch 6/10, Batch 40/97, Loss: 0.1854
Epoch 6/10, Batch 50/97, Loss: 0.2612
Epoch 6/10, Batch 60/97, Loss: 0.2622
Epoch 6/10, Batch 70/97, Loss: 0.2736
Epoch 6/10, Batch 80/97, Loss: 0.2762
Epoch 6/10, Batch 90/97, Loss: 0.3247
Epoch 6/10, Train Loss: 0.2475, Valid Loss: 0.2688
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1863
Epoch 7/10, Batch 20/97, Loss: 0.1657
Epoch 7/10, Batch 30/97, Loss: 0.1507
Epoch 7/10, Batch 40/97, Loss: 0.1528
Epoch 7/10, Batch 50/97, Loss: 0.2630
Epoch 7/10, Batch 60/97, Loss: 0.1204
Epoch 7/10, Batch 70/97, Loss: 0.3392
Epoch 7/10, Batch 80/97, Loss: 0.1944
Epoch 7/10, Batch 90/97, Loss: 0.2634
Epoch 7/10, Train Loss: 0.2320, Valid Loss: 0.2658
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2587
Epoch 8/10, Batch 20/97, Loss: 0.1701
Epoch 8/10, Batch 30/97, Loss: 0.2514
Epoch 8/10, Batch 40/97, Loss: 0.3508
Epoch 8/10, Batch 50/97, Loss: 0.2846
Epoch 8/10, Batch 60/97, Loss: 0.1911
Epoch 8/10, Batch 70/97, Loss: 0.1750
Epoch 8/10, Batch 80/97, Loss: 0.2648
Epoch 8/10, Batch 90/97, Loss: 0.2077
Epoch 8/10, Train Loss: 0.2261, Valid Loss: 0.2577
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2868
Epoch 9/10, Batch 20/97, Loss: 0.1279
Epoch 9/10, Batch 30/97, Loss: 0.3256
Epoch 9/10, Batch 40/97, Loss: 0.4226
Epoch 9/10, Batch 50/97, Loss: 0.1944
Epoch 9/10, Batch 60/97, Loss: 0.1839
Epoch 9/10, Batch 70/97, Loss: 0.1342
Epoch 9/10, Batch 80/97, Loss: 0.1114
Epoch 9/10, Batch 90/97, Loss: 0.2694
Epoch 9/10, Train Loss: 0.2025, Valid Loss: 0.2532
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2744
Epoch 10/10, Batch 20/97, Loss: 0.2084
Epoch 10/10, Batch 30/97, Loss: 0.2142
Epoch 10/10, Batch 40/97, Loss: 0.0930
Epoch 10/10, Batch 50/97, Loss: 0.1509
Epoch 10/10, Batch 60/97, Loss: 0.2181
Epoch 10/10, Batch 70/97, Loss: 0.2677
Epoch 10/10, Batch 80/97, Loss: 0.1294
Epoch 10/10, Batch 90/97, Loss: 0.1280
Epoch 10/10, Train Loss: 0.2089, Valid Loss: 0.2488
Model saved!
Accuracy: 0.9159
Precision: 0.9133
Recall: 0.9159
F1-score: 0.9131
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.1851
Epoch 1/10, Batch 20/97, Loss: 1.1904
Epoch 1/10, Batch 30/97, Loss: 0.7453
Epoch 1/10, Batch 40/97, Loss: 0.7928
Epoch 1/10, Batch 50/97, Loss: 0.6602
Epoch 1/10, Batch 60/97, Loss: 0.8333
Epoch 1/10, Batch 70/97, Loss: 0.8976
Epoch 1/10, Batch 80/97, Loss: 0.5872
Epoch 1/10, Batch 90/97, Loss: 0.5004
Epoch 1/10, Train Loss: 0.8126, Valid Loss: 0.4397
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5914
Epoch 2/10, Batch 20/97, Loss: 0.3974
Epoch 2/10, Batch 30/97, Loss: 0.3740
Epoch 2/10, Batch 40/97, Loss: 0.3391
Epoch 2/10, Batch 50/97, Loss: 0.3394
Epoch 2/10, Batch 60/97, Loss: 0.3316
Epoch 2/10, Batch 70/97, Loss: 0.2812
Epoch 2/10, Batch 80/97, Loss: 0.4087
Epoch 2/10, Batch 90/97, Loss: 0.3806
Epoch 2/10, Train Loss: 0.4186, Valid Loss: 0.3360
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3397
Epoch 3/10, Batch 20/97, Loss: 0.3461
Epoch 3/10, Batch 30/97, Loss: 0.3851
Epoch 3/10, Batch 40/97, Loss: 0.2718
Epoch 3/10, Batch 50/97, Loss: 0.5315
Epoch 3/10, Batch 60/97, Loss: 0.3213
Epoch 3/10, Batch 70/97, Loss: 0.3687
Epoch 3/10, Batch 80/97, Loss: 0.3347
Epoch 3/10, Batch 90/97, Loss: 0.1814
Epoch 3/10, Train Loss: 0.3433, Valid Loss: 0.2934
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4264
Epoch 4/10, Batch 20/97, Loss: 0.1725
Epoch 4/10, Batch 30/97, Loss: 0.2899
Epoch 4/10, Batch 40/97, Loss: 0.2173
Epoch 4/10, Batch 50/97, Loss: 0.1897
Epoch 4/10, Batch 60/97, Loss: 0.2617
Epoch 4/10, Batch 70/97, Loss: 0.2026
Epoch 4/10, Batch 80/97, Loss: 0.2788
Epoch 4/10, Batch 90/97, Loss: 0.2226
Epoch 4/10, Train Loss: 0.2919, Valid Loss: 0.2790
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3182
Epoch 5/10, Batch 20/97, Loss: 0.4357
Epoch 5/10, Batch 30/97, Loss: 0.2357
Epoch 5/10, Batch 40/97, Loss: 0.2761
Epoch 5/10, Batch 50/97, Loss: 0.3278
Epoch 5/10, Batch 60/97, Loss: 0.2596
Epoch 5/10, Batch 70/97, Loss: 0.3092
Epoch 5/10, Batch 80/97, Loss: 0.2394
Epoch 5/10, Batch 90/97, Loss: 0.2338
Epoch 5/10, Train Loss: 0.2749, Valid Loss: 0.2653
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1341
Epoch 6/10, Batch 20/97, Loss: 0.2232
Epoch 6/10, Batch 30/97, Loss: 0.2351
Epoch 6/10, Batch 40/97, Loss: 0.2119
Epoch 6/10, Batch 50/97, Loss: 0.1612
Epoch 6/10, Batch 60/97, Loss: 0.2912
Epoch 6/10, Batch 70/97, Loss: 0.2182
Epoch 6/10, Batch 80/97, Loss: 0.2833
Epoch 6/10, Batch 90/97, Loss: 0.1769
Epoch 6/10, Train Loss: 0.2484, Valid Loss: 0.2553
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1932
Epoch 7/10, Batch 20/97, Loss: 0.3241
Epoch 7/10, Batch 30/97, Loss: 0.2179
Epoch 7/10, Batch 40/97, Loss: 0.1492
Epoch 7/10, Batch 50/97, Loss: 0.4801
Epoch 7/10, Batch 60/97, Loss: 0.1774
Epoch 7/10, Batch 70/97, Loss: 0.2661
Epoch 7/10, Batch 80/97, Loss: 0.1276
Epoch 7/10, Batch 90/97, Loss: 0.2434
Epoch 7/10, Train Loss: 0.2337, Valid Loss: 0.2447
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2112
Epoch 8/10, Batch 20/97, Loss: 0.1065
Epoch 8/10, Batch 30/97, Loss: 0.2230
Epoch 8/10, Batch 40/97, Loss: 0.2107
Epoch 8/10, Batch 50/97, Loss: 0.2159
Epoch 8/10, Batch 60/97, Loss: 0.2435
Epoch 8/10, Batch 70/97, Loss: 0.2036
Epoch 8/10, Batch 80/97, Loss: 0.1617
Epoch 8/10, Batch 90/97, Loss: 0.2020
Epoch 8/10, Train Loss: 0.2298, Valid Loss: 0.2425
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1541
Epoch 9/10, Batch 20/97, Loss: 0.1217
Epoch 9/10, Batch 30/97, Loss: 0.2885
Epoch 9/10, Batch 40/97, Loss: 0.4384
Epoch 9/10, Batch 50/97, Loss: 0.1042
Epoch 9/10, Batch 60/97, Loss: 0.2370
Epoch 9/10, Batch 70/97, Loss: 0.2210
Epoch 9/10, Batch 80/97, Loss: 0.2151
Epoch 9/10, Batch 90/97, Loss: 0.1547
Epoch 9/10, Train Loss: 0.2121, Valid Loss: 0.2408
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2588
Epoch 10/10, Batch 20/97, Loss: 0.1409
Epoch 10/10, Batch 30/97, Loss: 0.2007
Epoch 10/10, Batch 40/97, Loss: 0.1162
Epoch 10/10, Batch 50/97, Loss: 0.3025
Epoch 10/10, Batch 60/97, Loss: 0.1471
Epoch 10/10, Batch 70/97, Loss: 0.1662
Epoch 10/10, Batch 80/97, Loss: 0.2810
Epoch 10/10, Batch 90/97, Loss: 0.1416
Epoch 10/10, Train Loss: 0.2113, Valid Loss: 0.2354
Model saved!
Accuracy: 0.9100
Precision: 0.9069
Recall: 0.9100
F1-score: 0.9060
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2153
Epoch 1/10, Batch 20/97, Loss: 1.1234
Epoch 1/10, Batch 30/97, Loss: 0.7383
Epoch 1/10, Batch 40/97, Loss: 0.8226
Epoch 1/10, Batch 50/97, Loss: 0.6395
Epoch 1/10, Batch 60/97, Loss: 0.6502
Epoch 1/10, Batch 70/97, Loss: 0.6408
Epoch 1/10, Batch 80/97, Loss: 0.7137
Epoch 1/10, Batch 90/97, Loss: 0.5711
Epoch 1/10, Train Loss: 0.8128, Valid Loss: 0.4260
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4189
Epoch 2/10, Batch 20/97, Loss: 0.4749
Epoch 2/10, Batch 30/97, Loss: 0.4611
Epoch 2/10, Batch 40/97, Loss: 0.3994
Epoch 2/10, Batch 50/97, Loss: 0.4792
Epoch 2/10, Batch 60/97, Loss: 0.3429
Epoch 2/10, Batch 70/97, Loss: 0.3880
Epoch 2/10, Batch 80/97, Loss: 0.5242
Epoch 2/10, Batch 90/97, Loss: 0.5110
Epoch 2/10, Train Loss: 0.4254, Valid Loss: 0.3129
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3071
Epoch 3/10, Batch 20/97, Loss: 0.3232
Epoch 3/10, Batch 30/97, Loss: 0.3813
Epoch 3/10, Batch 40/97, Loss: 0.3441
Epoch 3/10, Batch 50/97, Loss: 0.3288
Epoch 3/10, Batch 60/97, Loss: 0.1729
Epoch 3/10, Batch 70/97, Loss: 0.4156
Epoch 3/10, Batch 80/97, Loss: 0.2903
Epoch 3/10, Batch 90/97, Loss: 0.3266
Epoch 3/10, Train Loss: 0.3445, Valid Loss: 0.2810
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4459
Epoch 4/10, Batch 20/97, Loss: 0.2764
Epoch 4/10, Batch 30/97, Loss: 0.4434
Epoch 4/10, Batch 40/97, Loss: 0.2106
Epoch 4/10, Batch 50/97, Loss: 0.4445
Epoch 4/10, Batch 60/97, Loss: 0.3940
Epoch 4/10, Batch 70/97, Loss: 0.3503
Epoch 4/10, Batch 80/97, Loss: 0.2180
Epoch 4/10, Batch 90/97, Loss: 0.3883
Epoch 4/10, Train Loss: 0.3012, Valid Loss: 0.2517
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2937
Epoch 5/10, Batch 20/97, Loss: 0.2994
Epoch 5/10, Batch 30/97, Loss: 0.2170
Epoch 5/10, Batch 40/97, Loss: 0.2278
Epoch 5/10, Batch 50/97, Loss: 0.2198
Epoch 5/10, Batch 60/97, Loss: 0.2109
Epoch 5/10, Batch 70/97, Loss: 0.1666
Epoch 5/10, Batch 80/97, Loss: 0.1939
Epoch 5/10, Batch 90/97, Loss: 0.2406
Epoch 5/10, Train Loss: 0.2773, Valid Loss: 0.2350
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1997
Epoch 6/10, Batch 20/97, Loss: 0.3416
Epoch 6/10, Batch 30/97, Loss: 0.1384
Epoch 6/10, Batch 40/97, Loss: 0.3420
Epoch 6/10, Batch 50/97, Loss: 0.1407
Epoch 6/10, Batch 60/97, Loss: 0.3218
Epoch 6/10, Batch 70/97, Loss: 0.2441
Epoch 6/10, Batch 80/97, Loss: 0.2640
Epoch 6/10, Batch 90/97, Loss: 0.2796
Epoch 6/10, Train Loss: 0.2566, Valid Loss: 0.2227
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2766
Epoch 7/10, Batch 20/97, Loss: 0.4211
Epoch 7/10, Batch 30/97, Loss: 0.1276
Epoch 7/10, Batch 40/97, Loss: 0.2508
Epoch 7/10, Batch 50/97, Loss: 0.3459
Epoch 7/10, Batch 60/97, Loss: 0.1183
Epoch 7/10, Batch 70/97, Loss: 0.2095
Epoch 7/10, Batch 80/97, Loss: 0.2431
Epoch 7/10, Batch 90/97, Loss: 0.1372
Epoch 7/10, Train Loss: 0.2399, Valid Loss: 0.2183
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2005
Epoch 8/10, Batch 20/97, Loss: 0.2319
Epoch 8/10, Batch 30/97, Loss: 0.1703
Epoch 8/10, Batch 40/97, Loss: 0.1172
Epoch 8/10, Batch 50/97, Loss: 0.3374
Epoch 8/10, Batch 60/97, Loss: 0.2148
Epoch 8/10, Batch 70/97, Loss: 0.2497
Epoch 8/10, Batch 80/97, Loss: 0.2824
Epoch 8/10, Batch 90/97, Loss: 0.1881
Epoch 8/10, Train Loss: 0.2293, Valid Loss: 0.2165
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0677
Epoch 9/10, Batch 20/97, Loss: 0.0977
Epoch 9/10, Batch 30/97, Loss: 0.2564
Epoch 9/10, Batch 40/97, Loss: 0.2520
Epoch 9/10, Batch 50/97, Loss: 0.1270
Epoch 9/10, Batch 60/97, Loss: 0.1470
Epoch 9/10, Batch 70/97, Loss: 0.1492
Epoch 9/10, Batch 80/97, Loss: 0.1260
Epoch 9/10, Batch 90/97, Loss: 0.2780
Epoch 9/10, Train Loss: 0.2219, Valid Loss: 0.2088
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2475
Epoch 10/10, Batch 20/97, Loss: 0.2093
Epoch 10/10, Batch 30/97, Loss: 0.1360
Epoch 10/10, Batch 40/97, Loss: 0.1072
Epoch 10/10, Batch 50/97, Loss: 0.1574
Epoch 10/10, Batch 60/97, Loss: 0.2994
Epoch 10/10, Batch 70/97, Loss: 0.1640
Epoch 10/10, Batch 80/97, Loss: 0.2272
Epoch 10/10, Batch 90/97, Loss: 0.0925
Epoch 10/10, Train Loss: 0.2119, Valid Loss: 0.2061
Model saved!
Accuracy: 0.9124
Precision: 0.9088
Recall: 0.9124
F1-score: 0.9091
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2019
Epoch 1/10, Batch 20/97, Loss: 1.0789
Epoch 1/10, Batch 30/97, Loss: 0.7319
Epoch 1/10, Batch 40/97, Loss: 0.6823
Epoch 1/10, Batch 50/97, Loss: 0.6983
Epoch 1/10, Batch 60/97, Loss: 0.5860
Epoch 1/10, Batch 70/97, Loss: 0.7213
Epoch 1/10, Batch 80/97, Loss: 0.7760
Epoch 1/10, Batch 90/97, Loss: 0.5548
Epoch 1/10, Train Loss: 0.8069, Valid Loss: 0.4477
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6541
Epoch 2/10, Batch 20/97, Loss: 0.4480
Epoch 2/10, Batch 30/97, Loss: 0.3297
Epoch 2/10, Batch 40/97, Loss: 0.3112
Epoch 2/10, Batch 50/97, Loss: 0.4224
Epoch 2/10, Batch 60/97, Loss: 0.4944
Epoch 2/10, Batch 70/97, Loss: 0.3614
Epoch 2/10, Batch 80/97, Loss: 0.4936
Epoch 2/10, Batch 90/97, Loss: 0.3062
Epoch 2/10, Train Loss: 0.4127, Valid Loss: 0.3462
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3438
Epoch 3/10, Batch 20/97, Loss: 0.2631
Epoch 3/10, Batch 30/97, Loss: 0.3207
Epoch 3/10, Batch 40/97, Loss: 0.3065
Epoch 3/10, Batch 50/97, Loss: 0.4528
Epoch 3/10, Batch 60/97, Loss: 0.2091
Epoch 3/10, Batch 70/97, Loss: 0.5079
Epoch 3/10, Batch 80/97, Loss: 0.1605
Epoch 3/10, Batch 90/97, Loss: 0.3287
Epoch 3/10, Train Loss: 0.3420, Valid Loss: 0.3058
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2658
Epoch 4/10, Batch 20/97, Loss: 0.2548
Epoch 4/10, Batch 30/97, Loss: 0.2418
Epoch 4/10, Batch 40/97, Loss: 0.2697
Epoch 4/10, Batch 50/97, Loss: 0.4889
Epoch 4/10, Batch 60/97, Loss: 0.1686
Epoch 4/10, Batch 70/97, Loss: 0.2268
Epoch 4/10, Batch 80/97, Loss: 0.2964
Epoch 4/10, Batch 90/97, Loss: 0.2126
Epoch 4/10, Train Loss: 0.2919, Valid Loss: 0.2812
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3231
Epoch 5/10, Batch 20/97, Loss: 0.3395
Epoch 5/10, Batch 30/97, Loss: 0.3857
Epoch 5/10, Batch 40/97, Loss: 0.4026
Epoch 5/10, Batch 50/97, Loss: 0.3460
Epoch 5/10, Batch 60/97, Loss: 0.1407
Epoch 5/10, Batch 70/97, Loss: 0.2952
Epoch 5/10, Batch 80/97, Loss: 0.2552
Epoch 5/10, Batch 90/97, Loss: 0.1615
Epoch 5/10, Train Loss: 0.2728, Valid Loss: 0.2664
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.4167
Epoch 6/10, Batch 20/97, Loss: 0.3013
Epoch 6/10, Batch 30/97, Loss: 0.2800
Epoch 6/10, Batch 40/97, Loss: 0.1865
Epoch 6/10, Batch 50/97, Loss: 0.2712
Epoch 6/10, Batch 60/97, Loss: 0.2539
Epoch 6/10, Batch 70/97, Loss: 0.1676
Epoch 6/10, Batch 80/97, Loss: 0.3210
Epoch 6/10, Batch 90/97, Loss: 0.2088
Epoch 6/10, Train Loss: 0.2512, Valid Loss: 0.2562
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1226
Epoch 7/10, Batch 20/97, Loss: 0.1960
Epoch 7/10, Batch 30/97, Loss: 0.1070
Epoch 7/10, Batch 40/97, Loss: 0.1850
Epoch 7/10, Batch 50/97, Loss: 0.1052
Epoch 7/10, Batch 60/97, Loss: 0.3283
Epoch 7/10, Batch 70/97, Loss: 0.2025
Epoch 7/10, Batch 80/97, Loss: 0.3073
Epoch 7/10, Batch 90/97, Loss: 0.3977
Epoch 7/10, Train Loss: 0.2341, Valid Loss: 0.2442
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1862
Epoch 8/10, Batch 20/97, Loss: 0.2332
Epoch 8/10, Batch 30/97, Loss: 0.2550
Epoch 8/10, Batch 40/97, Loss: 0.2925
Epoch 8/10, Batch 50/97, Loss: 0.2048
Epoch 8/10, Batch 60/97, Loss: 0.1581
Epoch 8/10, Batch 70/97, Loss: 0.2721
Epoch 8/10, Batch 80/97, Loss: 0.1386
Epoch 8/10, Batch 90/97, Loss: 0.3379
Epoch 8/10, Train Loss: 0.2206, Valid Loss: 0.2424
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2424
Epoch 9/10, Batch 20/97, Loss: 0.2048
Epoch 9/10, Batch 30/97, Loss: 0.3396
Epoch 9/10, Batch 40/97, Loss: 0.4573
Epoch 9/10, Batch 50/97, Loss: 0.0984
Epoch 9/10, Batch 60/97, Loss: 0.2364
Epoch 9/10, Batch 70/97, Loss: 0.1713
Epoch 9/10, Batch 80/97, Loss: 0.1224
Epoch 9/10, Batch 90/97, Loss: 0.2305
Epoch 9/10, Train Loss: 0.2165, Valid Loss: 0.2419
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2640
Epoch 10/10, Batch 20/97, Loss: 0.1665
Epoch 10/10, Batch 30/97, Loss: 0.2270
Epoch 10/10, Batch 40/97, Loss: 0.0742
Epoch 10/10, Batch 50/97, Loss: 0.1571
Epoch 10/10, Batch 60/97, Loss: 0.2233
Epoch 10/10, Batch 70/97, Loss: 0.2166
Epoch 10/10, Batch 80/97, Loss: 0.1504
Epoch 10/10, Batch 90/97, Loss: 0.1466
Epoch 10/10, Train Loss: 0.2051, Valid Loss: 0.2424
Accuracy: 0.9217
Precision: 0.9205
Recall: 0.9217
F1-score: 0.9206
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2911
Epoch 1/10, Batch 20/97, Loss: 1.0227
Epoch 1/10, Batch 30/97, Loss: 0.8011
Epoch 1/10, Batch 40/97, Loss: 0.8343
Epoch 1/10, Batch 50/97, Loss: 0.6670
Epoch 1/10, Batch 60/97, Loss: 0.6790
Epoch 1/10, Batch 70/97, Loss: 0.5885
Epoch 1/10, Batch 80/97, Loss: 0.7576
Epoch 1/10, Batch 90/97, Loss: 0.4139
Epoch 1/10, Train Loss: 0.8096, Valid Loss: 0.4501
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5771
Epoch 2/10, Batch 20/97, Loss: 0.3871
Epoch 2/10, Batch 30/97, Loss: 0.4679
Epoch 2/10, Batch 40/97, Loss: 0.3935
Epoch 2/10, Batch 50/97, Loss: 0.4556
Epoch 2/10, Batch 60/97, Loss: 0.4935
Epoch 2/10, Batch 70/97, Loss: 0.3247
Epoch 2/10, Batch 80/97, Loss: 0.5842
Epoch 2/10, Batch 90/97, Loss: 0.5243
Epoch 2/10, Train Loss: 0.4222, Valid Loss: 0.3463
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3721
Epoch 3/10, Batch 20/97, Loss: 0.2287
Epoch 3/10, Batch 30/97, Loss: 0.4247
Epoch 3/10, Batch 40/97, Loss: 0.2788
Epoch 3/10, Batch 50/97, Loss: 0.4084
Epoch 3/10, Batch 60/97, Loss: 0.2545
Epoch 3/10, Batch 70/97, Loss: 0.2304
Epoch 3/10, Batch 80/97, Loss: 0.2295
Epoch 3/10, Batch 90/97, Loss: 0.2541
Epoch 3/10, Train Loss: 0.3354, Valid Loss: 0.3004
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3585
Epoch 4/10, Batch 20/97, Loss: 0.2728
Epoch 4/10, Batch 30/97, Loss: 0.2223
Epoch 4/10, Batch 40/97, Loss: 0.2700
Epoch 4/10, Batch 50/97, Loss: 0.4484
Epoch 4/10, Batch 60/97, Loss: 0.3722
Epoch 4/10, Batch 70/97, Loss: 0.3728
Epoch 4/10, Batch 80/97, Loss: 0.2637
Epoch 4/10, Batch 90/97, Loss: 0.3321
Epoch 4/10, Train Loss: 0.2951, Valid Loss: 0.2828
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3044
Epoch 5/10, Batch 20/97, Loss: 0.4647
Epoch 5/10, Batch 30/97, Loss: 0.2755
Epoch 5/10, Batch 40/97, Loss: 0.3224
Epoch 5/10, Batch 50/97, Loss: 0.3944
Epoch 5/10, Batch 60/97, Loss: 0.2658
Epoch 5/10, Batch 70/97, Loss: 0.3350
Epoch 5/10, Batch 80/97, Loss: 0.1800
Epoch 5/10, Batch 90/97, Loss: 0.2857
Epoch 5/10, Train Loss: 0.2710, Valid Loss: 0.2705
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1664
Epoch 6/10, Batch 20/97, Loss: 0.3253
Epoch 6/10, Batch 30/97, Loss: 0.2437
Epoch 6/10, Batch 40/97, Loss: 0.1663
Epoch 6/10, Batch 50/97, Loss: 0.3439
Epoch 6/10, Batch 60/97, Loss: 0.2499
Epoch 6/10, Batch 70/97, Loss: 0.2850
Epoch 6/10, Batch 80/97, Loss: 0.4260
Epoch 6/10, Batch 90/97, Loss: 0.2454
Epoch 6/10, Train Loss: 0.2557, Valid Loss: 0.2559
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2193
Epoch 7/10, Batch 20/97, Loss: 0.4628
Epoch 7/10, Batch 30/97, Loss: 0.1426
Epoch 7/10, Batch 40/97, Loss: 0.1884
Epoch 7/10, Batch 50/97, Loss: 0.1619
Epoch 7/10, Batch 60/97, Loss: 0.1483
Epoch 7/10, Batch 70/97, Loss: 0.4373
Epoch 7/10, Batch 80/97, Loss: 0.2703
Epoch 7/10, Batch 90/97, Loss: 0.3275
Epoch 7/10, Train Loss: 0.2356, Valid Loss: 0.2518
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2208
Epoch 8/10, Batch 20/97, Loss: 0.2221
Epoch 8/10, Batch 30/97, Loss: 0.1956
Epoch 8/10, Batch 40/97, Loss: 0.1769
Epoch 8/10, Batch 50/97, Loss: 0.2273
Epoch 8/10, Batch 60/97, Loss: 0.2632
Epoch 8/10, Batch 70/97, Loss: 0.2742
Epoch 8/10, Batch 80/97, Loss: 0.3192
Epoch 8/10, Batch 90/97, Loss: 0.2525
Epoch 8/10, Train Loss: 0.2291, Valid Loss: 0.2454
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2565
Epoch 9/10, Batch 20/97, Loss: 0.1925
Epoch 9/10, Batch 30/97, Loss: 0.3890
Epoch 9/10, Batch 40/97, Loss: 0.2939
Epoch 9/10, Batch 50/97, Loss: 0.1102
Epoch 9/10, Batch 60/97, Loss: 0.1508
Epoch 9/10, Batch 70/97, Loss: 0.0921
Epoch 9/10, Batch 80/97, Loss: 0.1616
Epoch 9/10, Batch 90/97, Loss: 0.1619
Epoch 9/10, Train Loss: 0.2159, Valid Loss: 0.2417
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3571
Epoch 10/10, Batch 20/97, Loss: 0.1211
Epoch 10/10, Batch 30/97, Loss: 0.2361
Epoch 10/10, Batch 40/97, Loss: 0.2524
Epoch 10/10, Batch 50/97, Loss: 0.2513
Epoch 10/10, Batch 60/97, Loss: 0.2615
Epoch 10/10, Batch 70/97, Loss: 0.3105
Epoch 10/10, Batch 80/97, Loss: 0.1709
Epoch 10/10, Batch 90/97, Loss: 0.2150
Epoch 10/10, Train Loss: 0.2060, Valid Loss: 0.2389
Model saved!
Accuracy: 0.9136
Precision: 0.9113
Recall: 0.9136
F1-score: 0.9117
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2204
Epoch 1/10, Batch 20/97, Loss: 1.0425
Epoch 1/10, Batch 30/97, Loss: 0.7516
Epoch 1/10, Batch 40/97, Loss: 0.7488
Epoch 1/10, Batch 50/97, Loss: 0.5732
Epoch 1/10, Batch 60/97, Loss: 0.7045
Epoch 1/10, Batch 70/97, Loss: 0.6661
Epoch 1/10, Batch 80/97, Loss: 0.6965
Epoch 1/10, Batch 90/97, Loss: 0.6576
Epoch 1/10, Train Loss: 0.7960, Valid Loss: 0.4449
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5953
Epoch 2/10, Batch 20/97, Loss: 0.3540
Epoch 2/10, Batch 30/97, Loss: 0.2549
Epoch 2/10, Batch 40/97, Loss: 0.4873
Epoch 2/10, Batch 50/97, Loss: 0.3171
Epoch 2/10, Batch 60/97, Loss: 0.3993
Epoch 2/10, Batch 70/97, Loss: 0.3371
Epoch 2/10, Batch 80/97, Loss: 0.3188
Epoch 2/10, Batch 90/97, Loss: 0.4230
Epoch 2/10, Train Loss: 0.4069, Valid Loss: 0.3384
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3745
Epoch 3/10, Batch 20/97, Loss: 0.3596
Epoch 3/10, Batch 30/97, Loss: 0.4296
Epoch 3/10, Batch 40/97, Loss: 0.2190
Epoch 3/10, Batch 50/97, Loss: 0.2465
Epoch 3/10, Batch 60/97, Loss: 0.2277
Epoch 3/10, Batch 70/97, Loss: 0.2437
Epoch 3/10, Batch 80/97, Loss: 0.3073
Epoch 3/10, Batch 90/97, Loss: 0.3383
Epoch 3/10, Train Loss: 0.3319, Valid Loss: 0.2965
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3348
Epoch 4/10, Batch 20/97, Loss: 0.2520
Epoch 4/10, Batch 30/97, Loss: 0.3273
Epoch 4/10, Batch 40/97, Loss: 0.2060
Epoch 4/10, Batch 50/97, Loss: 0.2752
Epoch 4/10, Batch 60/97, Loss: 0.3841
Epoch 4/10, Batch 70/97, Loss: 0.2487
Epoch 4/10, Batch 80/97, Loss: 0.4801
Epoch 4/10, Batch 90/97, Loss: 0.2872
Epoch 4/10, Train Loss: 0.2852, Valid Loss: 0.2854
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2520
Epoch 5/10, Batch 20/97, Loss: 0.2895
Epoch 5/10, Batch 30/97, Loss: 0.2053
Epoch 5/10, Batch 40/97, Loss: 0.2053
Epoch 5/10, Batch 50/97, Loss: 0.2865
Epoch 5/10, Batch 60/97, Loss: 0.2901
Epoch 5/10, Batch 70/97, Loss: 0.2583
Epoch 5/10, Batch 80/97, Loss: 0.2547
Epoch 5/10, Batch 90/97, Loss: 0.1845
Epoch 5/10, Train Loss: 0.2604, Valid Loss: 0.2647
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3406
Epoch 6/10, Batch 20/97, Loss: 0.3461
Epoch 6/10, Batch 30/97, Loss: 0.2808
Epoch 6/10, Batch 40/97, Loss: 0.1541
Epoch 6/10, Batch 50/97, Loss: 0.1381
Epoch 6/10, Batch 60/97, Loss: 0.2274
Epoch 6/10, Batch 70/97, Loss: 0.2013
Epoch 6/10, Batch 80/97, Loss: 0.4264
Epoch 6/10, Batch 90/97, Loss: 0.2900
Epoch 6/10, Train Loss: 0.2466, Valid Loss: 0.2522
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1795
Epoch 7/10, Batch 20/97, Loss: 0.2550
Epoch 7/10, Batch 30/97, Loss: 0.3219
Epoch 7/10, Batch 40/97, Loss: 0.1266
Epoch 7/10, Batch 50/97, Loss: 0.2657
Epoch 7/10, Batch 60/97, Loss: 0.1529
Epoch 7/10, Batch 70/97, Loss: 0.1953
Epoch 7/10, Batch 80/97, Loss: 0.1362
Epoch 7/10, Batch 90/97, Loss: 0.2249
Epoch 7/10, Train Loss: 0.2227, Valid Loss: 0.2489
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2321
Epoch 8/10, Batch 20/97, Loss: 0.1934
Epoch 8/10, Batch 30/97, Loss: 0.2036
Epoch 8/10, Batch 40/97, Loss: 0.2359
Epoch 8/10, Batch 50/97, Loss: 0.2878
Epoch 8/10, Batch 60/97, Loss: 0.2173
Epoch 8/10, Batch 70/97, Loss: 0.2095
Epoch 8/10, Batch 80/97, Loss: 0.2138
Epoch 8/10, Batch 90/97, Loss: 0.2681
Epoch 8/10, Train Loss: 0.2178, Valid Loss: 0.2496
Epoch 9/10, Batch 10/97, Loss: 0.1632
Epoch 9/10, Batch 20/97, Loss: 0.1786
Epoch 9/10, Batch 30/97, Loss: 0.1222
Epoch 9/10, Batch 40/97, Loss: 0.2677
Epoch 9/10, Batch 50/97, Loss: 0.0729
Epoch 9/10, Batch 60/97, Loss: 0.1904
Epoch 9/10, Batch 70/97, Loss: 0.1030
Epoch 9/10, Batch 80/97, Loss: 0.2586
Epoch 9/10, Batch 90/97, Loss: 0.1833
Epoch 9/10, Train Loss: 0.2025, Valid Loss: 0.2413
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1780
Epoch 10/10, Batch 20/97, Loss: 0.1818
Epoch 10/10, Batch 30/97, Loss: 0.1699
Epoch 10/10, Batch 40/97, Loss: 0.1285
Epoch 10/10, Batch 50/97, Loss: 0.1459
Epoch 10/10, Batch 60/97, Loss: 0.0809
Epoch 10/10, Batch 70/97, Loss: 0.1299
Epoch 10/10, Batch 80/97, Loss: 0.1889
Epoch 10/10, Batch 90/97, Loss: 0.1154
Epoch 10/10, Train Loss: 0.1934, Valid Loss: 0.2373
Model saved!
Accuracy: 0.9136
Precision: 0.9106
Recall: 0.9136
F1-score: 0.9113
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2264
Epoch 1/10, Batch 20/97, Loss: 1.1257
Epoch 1/10, Batch 30/97, Loss: 0.7862
Epoch 1/10, Batch 40/97, Loss: 0.6652
Epoch 1/10, Batch 50/97, Loss: 0.5618
Epoch 1/10, Batch 60/97, Loss: 0.8376
Epoch 1/10, Batch 70/97, Loss: 0.5824
Epoch 1/10, Batch 80/97, Loss: 0.6559
Epoch 1/10, Batch 90/97, Loss: 0.5156
Epoch 1/10, Train Loss: 0.8097, Valid Loss: 0.4006
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4638
Epoch 2/10, Batch 20/97, Loss: 0.4873
Epoch 2/10, Batch 30/97, Loss: 0.3477
Epoch 2/10, Batch 40/97, Loss: 0.4274
Epoch 2/10, Batch 50/97, Loss: 0.4155
Epoch 2/10, Batch 60/97, Loss: 0.4893
Epoch 2/10, Batch 70/97, Loss: 0.3636
Epoch 2/10, Batch 80/97, Loss: 0.3705
Epoch 2/10, Batch 90/97, Loss: 0.4524
Epoch 2/10, Train Loss: 0.4193, Valid Loss: 0.3045
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4374
Epoch 3/10, Batch 20/97, Loss: 0.2686
Epoch 3/10, Batch 30/97, Loss: 0.2744
Epoch 3/10, Batch 40/97, Loss: 0.2813
Epoch 3/10, Batch 50/97, Loss: 0.4532
Epoch 3/10, Batch 60/97, Loss: 0.3563
Epoch 3/10, Batch 70/97, Loss: 0.3882
Epoch 3/10, Batch 80/97, Loss: 0.2686
Epoch 3/10, Batch 90/97, Loss: 0.1672
Epoch 3/10, Train Loss: 0.3385, Valid Loss: 0.2537
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4623
Epoch 4/10, Batch 20/97, Loss: 0.2359
Epoch 4/10, Batch 30/97, Loss: 0.2715
Epoch 4/10, Batch 40/97, Loss: 0.3497
Epoch 4/10, Batch 50/97, Loss: 0.2344
Epoch 4/10, Batch 60/97, Loss: 0.2041
Epoch 4/10, Batch 70/97, Loss: 0.1729
Epoch 4/10, Batch 80/97, Loss: 0.3985
Epoch 4/10, Batch 90/97, Loss: 0.1749
Epoch 4/10, Train Loss: 0.2910, Valid Loss: 0.2416
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.4289
Epoch 5/10, Batch 20/97, Loss: 0.2886
Epoch 5/10, Batch 30/97, Loss: 0.2620
Epoch 5/10, Batch 40/97, Loss: 0.2688
Epoch 5/10, Batch 50/97, Loss: 0.3345
Epoch 5/10, Batch 60/97, Loss: 0.3912
Epoch 5/10, Batch 70/97, Loss: 0.2573
Epoch 5/10, Batch 80/97, Loss: 0.2511
Epoch 5/10, Batch 90/97, Loss: 0.2962
Epoch 5/10, Train Loss: 0.2641, Valid Loss: 0.2217
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1454
Epoch 6/10, Batch 20/97, Loss: 0.4527
Epoch 6/10, Batch 30/97, Loss: 0.1358
Epoch 6/10, Batch 40/97, Loss: 0.1693
Epoch 6/10, Batch 50/97, Loss: 0.2199
Epoch 6/10, Batch 60/97, Loss: 0.2462
Epoch 6/10, Batch 70/97, Loss: 0.4666
Epoch 6/10, Batch 80/97, Loss: 0.3192
Epoch 6/10, Batch 90/97, Loss: 0.2909
Epoch 6/10, Train Loss: 0.2540, Valid Loss: 0.2041
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2075
Epoch 7/10, Batch 20/97, Loss: 0.3144
Epoch 7/10, Batch 30/97, Loss: 0.2000
Epoch 7/10, Batch 40/97, Loss: 0.1377
Epoch 7/10, Batch 50/97, Loss: 0.4388
Epoch 7/10, Batch 60/97, Loss: 0.2617
Epoch 7/10, Batch 70/97, Loss: 0.3908
Epoch 7/10, Batch 80/97, Loss: 0.2710
Epoch 7/10, Batch 90/97, Loss: 0.1974
Epoch 7/10, Train Loss: 0.2339, Valid Loss: 0.2030
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1846
Epoch 8/10, Batch 20/97, Loss: 0.2216
Epoch 8/10, Batch 30/97, Loss: 0.3016
Epoch 8/10, Batch 40/97, Loss: 0.1608
Epoch 8/10, Batch 50/97, Loss: 0.3063
Epoch 8/10, Batch 60/97, Loss: 0.2604
Epoch 8/10, Batch 70/97, Loss: 0.2463
Epoch 8/10, Batch 80/97, Loss: 0.2576
Epoch 8/10, Batch 90/97, Loss: 0.2978
Epoch 8/10, Train Loss: 0.2254, Valid Loss: 0.1939
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1572
Epoch 9/10, Batch 20/97, Loss: 0.0926
Epoch 9/10, Batch 30/97, Loss: 0.2756
Epoch 9/10, Batch 40/97, Loss: 0.3271
Epoch 9/10, Batch 50/97, Loss: 0.0752
Epoch 9/10, Batch 60/97, Loss: 0.2875
Epoch 9/10, Batch 70/97, Loss: 0.3092
Epoch 9/10, Batch 80/97, Loss: 0.1137
Epoch 9/10, Batch 90/97, Loss: 0.3662
Epoch 9/10, Train Loss: 0.2099, Valid Loss: 0.1875
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1743
Epoch 10/10, Batch 20/97, Loss: 0.1931
Epoch 10/10, Batch 30/97, Loss: 0.1718
Epoch 10/10, Batch 40/97, Loss: 0.2271
Epoch 10/10, Batch 50/97, Loss: 0.2307
Epoch 10/10, Batch 60/97, Loss: 0.1500
Epoch 10/10, Batch 70/97, Loss: 0.2866
Epoch 10/10, Batch 80/97, Loss: 0.1193
Epoch 10/10, Batch 90/97, Loss: 0.3054
Epoch 10/10, Train Loss: 0.2055, Valid Loss: 0.1853
Model saved!
Accuracy: 0.9159
Precision: 0.9127
Recall: 0.9159
F1-score: 0.9131
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2504
Epoch 1/10, Batch 20/97, Loss: 1.1309
Epoch 1/10, Batch 30/97, Loss: 0.6964
Epoch 1/10, Batch 40/97, Loss: 0.7662
Epoch 1/10, Batch 50/97, Loss: 0.7046
Epoch 1/10, Batch 60/97, Loss: 0.6701
Epoch 1/10, Batch 70/97, Loss: 0.5840
Epoch 1/10, Batch 80/97, Loss: 0.6842
Epoch 1/10, Batch 90/97, Loss: 0.6681
Epoch 1/10, Train Loss: 0.8046, Valid Loss: 0.4255
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5340
Epoch 2/10, Batch 20/97, Loss: 0.4775
Epoch 2/10, Batch 30/97, Loss: 0.3598
Epoch 2/10, Batch 40/97, Loss: 0.5162
Epoch 2/10, Batch 50/97, Loss: 0.3601
Epoch 2/10, Batch 60/97, Loss: 0.3829
Epoch 2/10, Batch 70/97, Loss: 0.3228
Epoch 2/10, Batch 80/97, Loss: 0.4904
Epoch 2/10, Batch 90/97, Loss: 0.4819
Epoch 2/10, Train Loss: 0.4190, Valid Loss: 0.3134
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3926
Epoch 3/10, Batch 20/97, Loss: 0.2865
Epoch 3/10, Batch 30/97, Loss: 0.2970
Epoch 3/10, Batch 40/97, Loss: 0.2083
Epoch 3/10, Batch 50/97, Loss: 0.5623
Epoch 3/10, Batch 60/97, Loss: 0.3002
Epoch 3/10, Batch 70/97, Loss: 0.2617
Epoch 3/10, Batch 80/97, Loss: 0.3507
Epoch 3/10, Batch 90/97, Loss: 0.3472
Epoch 3/10, Train Loss: 0.3372, Valid Loss: 0.2691
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4175
Epoch 4/10, Batch 20/97, Loss: 0.2245
Epoch 4/10, Batch 30/97, Loss: 0.3210
Epoch 4/10, Batch 40/97, Loss: 0.2949
Epoch 4/10, Batch 50/97, Loss: 0.2175
Epoch 4/10, Batch 60/97, Loss: 0.2516
Epoch 4/10, Batch 70/97, Loss: 0.2605
Epoch 4/10, Batch 80/97, Loss: 0.1681
Epoch 4/10, Batch 90/97, Loss: 0.3042
Epoch 4/10, Train Loss: 0.2897, Valid Loss: 0.2546
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2475
Epoch 5/10, Batch 20/97, Loss: 0.2936
Epoch 5/10, Batch 30/97, Loss: 0.1728
Epoch 5/10, Batch 40/97, Loss: 0.1457
Epoch 5/10, Batch 50/97, Loss: 0.3599
Epoch 5/10, Batch 60/97, Loss: 0.1972
Epoch 5/10, Batch 70/97, Loss: 0.1417
Epoch 5/10, Batch 80/97, Loss: 0.3786
Epoch 5/10, Batch 90/97, Loss: 0.1635
Epoch 5/10, Train Loss: 0.2695, Valid Loss: 0.2416
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2085
Epoch 6/10, Batch 20/97, Loss: 0.3965
Epoch 6/10, Batch 30/97, Loss: 0.1831
Epoch 6/10, Batch 40/97, Loss: 0.2425
Epoch 6/10, Batch 50/97, Loss: 0.2440
Epoch 6/10, Batch 60/97, Loss: 0.1396
Epoch 6/10, Batch 70/97, Loss: 0.2290
Epoch 6/10, Batch 80/97, Loss: 0.3310
Epoch 6/10, Batch 90/97, Loss: 0.3824
Epoch 6/10, Train Loss: 0.2446, Valid Loss: 0.2230
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1927
Epoch 7/10, Batch 20/97, Loss: 0.3905
Epoch 7/10, Batch 30/97, Loss: 0.1377
Epoch 7/10, Batch 40/97, Loss: 0.1482
Epoch 7/10, Batch 50/97, Loss: 0.1739
Epoch 7/10, Batch 60/97, Loss: 0.2786
Epoch 7/10, Batch 70/97, Loss: 0.2711
Epoch 7/10, Batch 80/97, Loss: 0.2350
Epoch 7/10, Batch 90/97, Loss: 0.1558
Epoch 7/10, Train Loss: 0.2302, Valid Loss: 0.2144
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1224
Epoch 8/10, Batch 20/97, Loss: 0.1662
Epoch 8/10, Batch 30/97, Loss: 0.1670
Epoch 8/10, Batch 40/97, Loss: 0.2855
Epoch 8/10, Batch 50/97, Loss: 0.2448
Epoch 8/10, Batch 60/97, Loss: 0.2830
Epoch 8/10, Batch 70/97, Loss: 0.2621
Epoch 8/10, Batch 80/97, Loss: 0.1245
Epoch 8/10, Batch 90/97, Loss: 0.1405
Epoch 8/10, Train Loss: 0.2214, Valid Loss: 0.2136
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1073
Epoch 9/10, Batch 20/97, Loss: 0.1909
Epoch 9/10, Batch 30/97, Loss: 0.1606
Epoch 9/10, Batch 40/97, Loss: 0.2580
Epoch 9/10, Batch 50/97, Loss: 0.1912
Epoch 9/10, Batch 60/97, Loss: 0.2753
Epoch 9/10, Batch 70/97, Loss: 0.2582
Epoch 9/10, Batch 80/97, Loss: 0.2443
Epoch 9/10, Batch 90/97, Loss: 0.2233
Epoch 9/10, Train Loss: 0.2098, Valid Loss: 0.2120
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1903
Epoch 10/10, Batch 20/97, Loss: 0.1954
Epoch 10/10, Batch 30/97, Loss: 0.1591
Epoch 10/10, Batch 40/97, Loss: 0.1549
Epoch 10/10, Batch 50/97, Loss: 0.1040
Epoch 10/10, Batch 60/97, Loss: 0.1121
Epoch 10/10, Batch 70/97, Loss: 0.1447
Epoch 10/10, Batch 80/97, Loss: 0.2380
Epoch 10/10, Batch 90/97, Loss: 0.2755
Epoch 10/10, Train Loss: 0.2040, Valid Loss: 0.2045
Model saved!
Accuracy: 0.9171
Precision: 0.9138
Recall: 0.9171
F1-score: 0.9144
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2480
Epoch 1/10, Batch 20/97, Loss: 1.0604
Epoch 1/10, Batch 30/97, Loss: 0.7592
Epoch 1/10, Batch 40/97, Loss: 0.6695
Epoch 1/10, Batch 50/97, Loss: 0.6784
Epoch 1/10, Batch 60/97, Loss: 0.6837
Epoch 1/10, Batch 70/97, Loss: 0.7118
Epoch 1/10, Batch 80/97, Loss: 0.8390
Epoch 1/10, Batch 90/97, Loss: 0.5190
Epoch 1/10, Train Loss: 0.8065, Valid Loss: 0.4468
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5862
Epoch 2/10, Batch 20/97, Loss: 0.4333
Epoch 2/10, Batch 30/97, Loss: 0.3795
Epoch 2/10, Batch 40/97, Loss: 0.3293
Epoch 2/10, Batch 50/97, Loss: 0.4671
Epoch 2/10, Batch 60/97, Loss: 0.3997
Epoch 2/10, Batch 70/97, Loss: 0.3455
Epoch 2/10, Batch 80/97, Loss: 0.4863
Epoch 2/10, Batch 90/97, Loss: 0.3359
Epoch 2/10, Train Loss: 0.4195, Valid Loss: 0.3347
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3892
Epoch 3/10, Batch 20/97, Loss: 0.3242
Epoch 3/10, Batch 30/97, Loss: 0.4025
Epoch 3/10, Batch 40/97, Loss: 0.3005
Epoch 3/10, Batch 50/97, Loss: 0.4243
Epoch 3/10, Batch 60/97, Loss: 0.3204
Epoch 3/10, Batch 70/97, Loss: 0.3035
Epoch 3/10, Batch 80/97, Loss: 0.3321
Epoch 3/10, Batch 90/97, Loss: 0.4324
Epoch 3/10, Train Loss: 0.3431, Valid Loss: 0.2884
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2867
Epoch 4/10, Batch 20/97, Loss: 0.2230
Epoch 4/10, Batch 30/97, Loss: 0.3600
Epoch 4/10, Batch 40/97, Loss: 0.3240
Epoch 4/10, Batch 50/97, Loss: 0.4034
Epoch 4/10, Batch 60/97, Loss: 0.1707
Epoch 4/10, Batch 70/97, Loss: 0.2633
Epoch 4/10, Batch 80/97, Loss: 0.4733
Epoch 4/10, Batch 90/97, Loss: 0.5089
Epoch 4/10, Train Loss: 0.2976, Valid Loss: 0.2556
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2128
Epoch 5/10, Batch 20/97, Loss: 0.2781
Epoch 5/10, Batch 30/97, Loss: 0.2905
Epoch 5/10, Batch 40/97, Loss: 0.1784
Epoch 5/10, Batch 50/97, Loss: 0.2475
Epoch 5/10, Batch 60/97, Loss: 0.2617
Epoch 5/10, Batch 70/97, Loss: 0.2338
Epoch 5/10, Batch 80/97, Loss: 0.2491
Epoch 5/10, Batch 90/97, Loss: 0.2384
Epoch 5/10, Train Loss: 0.2776, Valid Loss: 0.2439
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2157
Epoch 6/10, Batch 20/97, Loss: 0.3095
Epoch 6/10, Batch 30/97, Loss: 0.2120
Epoch 6/10, Batch 40/97, Loss: 0.3715
Epoch 6/10, Batch 50/97, Loss: 0.4470
Epoch 6/10, Batch 60/97, Loss: 0.3406
Epoch 6/10, Batch 70/97, Loss: 0.1936
Epoch 6/10, Batch 80/97, Loss: 0.3638
Epoch 6/10, Batch 90/97, Loss: 0.1838
Epoch 6/10, Train Loss: 0.2551, Valid Loss: 0.2306
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2596
Epoch 7/10, Batch 20/97, Loss: 0.3174
Epoch 7/10, Batch 30/97, Loss: 0.2524
Epoch 7/10, Batch 40/97, Loss: 0.1401
Epoch 7/10, Batch 50/97, Loss: 0.2399
Epoch 7/10, Batch 60/97, Loss: 0.2860
Epoch 7/10, Batch 70/97, Loss: 0.1992
Epoch 7/10, Batch 80/97, Loss: 0.2135
Epoch 7/10, Batch 90/97, Loss: 0.1986
Epoch 7/10, Train Loss: 0.2358, Valid Loss: 0.2185
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1771
Epoch 8/10, Batch 20/97, Loss: 0.2460
Epoch 8/10, Batch 30/97, Loss: 0.1950
Epoch 8/10, Batch 40/97, Loss: 0.2273
Epoch 8/10, Batch 50/97, Loss: 0.2010
Epoch 8/10, Batch 60/97, Loss: 0.0797
Epoch 8/10, Batch 70/97, Loss: 0.1783
Epoch 8/10, Batch 80/97, Loss: 0.1944
Epoch 8/10, Batch 90/97, Loss: 0.2329
Epoch 8/10, Train Loss: 0.2306, Valid Loss: 0.2156
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2254
Epoch 9/10, Batch 20/97, Loss: 0.1453
Epoch 9/10, Batch 30/97, Loss: 0.1953
Epoch 9/10, Batch 40/97, Loss: 0.1651
Epoch 9/10, Batch 50/97, Loss: 0.2027
Epoch 9/10, Batch 60/97, Loss: 0.2487
Epoch 9/10, Batch 70/97, Loss: 0.0815
Epoch 9/10, Batch 80/97, Loss: 0.2299
Epoch 9/10, Batch 90/97, Loss: 0.2675
Epoch 9/10, Train Loss: 0.2106, Valid Loss: 0.2045
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2968
Epoch 10/10, Batch 20/97, Loss: 0.0741
Epoch 10/10, Batch 30/97, Loss: 0.2830
Epoch 10/10, Batch 40/97, Loss: 0.0745
Epoch 10/10, Batch 50/97, Loss: 0.1295
Epoch 10/10, Batch 60/97, Loss: 0.2354
Epoch 10/10, Batch 70/97, Loss: 0.2707
Epoch 10/10, Batch 80/97, Loss: 0.2451
Epoch 10/10, Batch 90/97, Loss: 0.1813
Epoch 10/10, Train Loss: 0.2055, Valid Loss: 0.2076
Accuracy: 0.9182
Precision: 0.9170
Recall: 0.9182
F1-score: 0.9171
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.1869
Epoch 1/10, Batch 20/97, Loss: 1.1558
Epoch 1/10, Batch 30/97, Loss: 0.7627
Epoch 1/10, Batch 40/97, Loss: 0.7263
Epoch 1/10, Batch 50/97, Loss: 0.5302
Epoch 1/10, Batch 60/97, Loss: 0.6628
Epoch 1/10, Batch 70/97, Loss: 0.6648
Epoch 1/10, Batch 80/97, Loss: 0.5799
Epoch 1/10, Batch 90/97, Loss: 0.5174
Epoch 1/10, Train Loss: 0.8041, Valid Loss: 0.4629
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5441
Epoch 2/10, Batch 20/97, Loss: 0.4913
Epoch 2/10, Batch 30/97, Loss: 0.3655
Epoch 2/10, Batch 40/97, Loss: 0.5484
Epoch 2/10, Batch 50/97, Loss: 0.4341
Epoch 2/10, Batch 60/97, Loss: 0.4729
Epoch 2/10, Batch 70/97, Loss: 0.3742
Epoch 2/10, Batch 80/97, Loss: 0.4015
Epoch 2/10, Batch 90/97, Loss: 0.5443
Epoch 2/10, Train Loss: 0.4159, Valid Loss: 0.3555
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3616
Epoch 3/10, Batch 20/97, Loss: 0.3549
Epoch 3/10, Batch 30/97, Loss: 0.3320
Epoch 3/10, Batch 40/97, Loss: 0.2224
Epoch 3/10, Batch 50/97, Loss: 0.5015
Epoch 3/10, Batch 60/97, Loss: 0.3108
Epoch 3/10, Batch 70/97, Loss: 0.4610
Epoch 3/10, Batch 80/97, Loss: 0.1556
Epoch 3/10, Batch 90/97, Loss: 0.2684
Epoch 3/10, Train Loss: 0.3299, Valid Loss: 0.3125
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3184
Epoch 4/10, Batch 20/97, Loss: 0.2084
Epoch 4/10, Batch 30/97, Loss: 0.2149
Epoch 4/10, Batch 40/97, Loss: 0.3511
Epoch 4/10, Batch 50/97, Loss: 0.5629
Epoch 4/10, Batch 60/97, Loss: 0.2752
Epoch 4/10, Batch 70/97, Loss: 0.2777
Epoch 4/10, Batch 80/97, Loss: 0.2754
Epoch 4/10, Batch 90/97, Loss: 0.2039
Epoch 4/10, Train Loss: 0.2910, Valid Loss: 0.3004
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2623
Epoch 5/10, Batch 20/97, Loss: 0.3813
Epoch 5/10, Batch 30/97, Loss: 0.2798
Epoch 5/10, Batch 40/97, Loss: 0.3477
Epoch 5/10, Batch 50/97, Loss: 0.3504
Epoch 5/10, Batch 60/97, Loss: 0.3268
Epoch 5/10, Batch 70/97, Loss: 0.2870
Epoch 5/10, Batch 80/97, Loss: 0.3695
Epoch 5/10, Batch 90/97, Loss: 0.1912
Epoch 5/10, Train Loss: 0.2651, Valid Loss: 0.2804
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1556
Epoch 6/10, Batch 20/97, Loss: 0.1833
Epoch 6/10, Batch 30/97, Loss: 0.1745
Epoch 6/10, Batch 40/97, Loss: 0.3507
Epoch 6/10, Batch 50/97, Loss: 0.2636
Epoch 6/10, Batch 60/97, Loss: 0.3947
Epoch 6/10, Batch 70/97, Loss: 0.2769
Epoch 6/10, Batch 80/97, Loss: 0.2571
Epoch 6/10, Batch 90/97, Loss: 0.2262
Epoch 6/10, Train Loss: 0.2460, Valid Loss: 0.2693
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.0952
Epoch 7/10, Batch 20/97, Loss: 0.2526
Epoch 7/10, Batch 30/97, Loss: 0.1768
Epoch 7/10, Batch 40/97, Loss: 0.1529
Epoch 7/10, Batch 50/97, Loss: 0.2415
Epoch 7/10, Batch 60/97, Loss: 0.2312
Epoch 7/10, Batch 70/97, Loss: 0.2901
Epoch 7/10, Batch 80/97, Loss: 0.1914
Epoch 7/10, Batch 90/97, Loss: 0.2361
Epoch 7/10, Train Loss: 0.2262, Valid Loss: 0.2661
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1382
Epoch 8/10, Batch 20/97, Loss: 0.1317
Epoch 8/10, Batch 30/97, Loss: 0.1942
Epoch 8/10, Batch 40/97, Loss: 0.2141
Epoch 8/10, Batch 50/97, Loss: 0.2048
Epoch 8/10, Batch 60/97, Loss: 0.2563
Epoch 8/10, Batch 70/97, Loss: 0.3026
Epoch 8/10, Batch 80/97, Loss: 0.0980
Epoch 8/10, Batch 90/97, Loss: 0.1363
Epoch 8/10, Train Loss: 0.2220, Valid Loss: 0.2599
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1504
Epoch 9/10, Batch 20/97, Loss: 0.1993
Epoch 9/10, Batch 30/97, Loss: 0.3319
Epoch 9/10, Batch 40/97, Loss: 0.2954
Epoch 9/10, Batch 50/97, Loss: 0.0835
Epoch 9/10, Batch 60/97, Loss: 0.0970
Epoch 9/10, Batch 70/97, Loss: 0.1393
Epoch 9/10, Batch 80/97, Loss: 0.1855
Epoch 9/10, Batch 90/97, Loss: 0.3374
Epoch 9/10, Train Loss: 0.2106, Valid Loss: 0.2569
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.4105
Epoch 10/10, Batch 20/97, Loss: 0.0993
Epoch 10/10, Batch 30/97, Loss: 0.1819
Epoch 10/10, Batch 40/97, Loss: 0.2475
Epoch 10/10, Batch 50/97, Loss: 0.1726
Epoch 10/10, Batch 60/97, Loss: 0.1241
Epoch 10/10, Batch 70/97, Loss: 0.3522
Epoch 10/10, Batch 80/97, Loss: 0.1492
Epoch 10/10, Batch 90/97, Loss: 0.2023
Epoch 10/10, Train Loss: 0.2025, Valid Loss: 0.2598
Accuracy: 0.9112
Precision: 0.9088
Recall: 0.9112
F1-score: 0.9095
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2103
Epoch 1/10, Batch 20/97, Loss: 1.0481
Epoch 1/10, Batch 30/97, Loss: 0.6802
Epoch 1/10, Batch 40/97, Loss: 0.7072
Epoch 1/10, Batch 50/97, Loss: 0.6471
Epoch 1/10, Batch 60/97, Loss: 0.8003
Epoch 1/10, Batch 70/97, Loss: 0.6387
Epoch 1/10, Batch 80/97, Loss: 0.5763
Epoch 1/10, Batch 90/97, Loss: 0.5378
Epoch 1/10, Train Loss: 0.7961, Valid Loss: 0.4290
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5410
Epoch 2/10, Batch 20/97, Loss: 0.3517
Epoch 2/10, Batch 30/97, Loss: 0.2577
Epoch 2/10, Batch 40/97, Loss: 0.3083
Epoch 2/10, Batch 50/97, Loss: 0.5958
Epoch 2/10, Batch 60/97, Loss: 0.3710
Epoch 2/10, Batch 70/97, Loss: 0.2931
Epoch 2/10, Batch 80/97, Loss: 0.3544
Epoch 2/10, Batch 90/97, Loss: 0.2482
Epoch 2/10, Train Loss: 0.4101, Valid Loss: 0.3246
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4308
Epoch 3/10, Batch 20/97, Loss: 0.3374
Epoch 3/10, Batch 30/97, Loss: 0.3092
Epoch 3/10, Batch 40/97, Loss: 0.3191
Epoch 3/10, Batch 50/97, Loss: 0.3223
Epoch 3/10, Batch 60/97, Loss: 0.2215
Epoch 3/10, Batch 70/97, Loss: 0.3159
Epoch 3/10, Batch 80/97, Loss: 0.2951
Epoch 3/10, Batch 90/97, Loss: 0.3766
Epoch 3/10, Train Loss: 0.3275, Valid Loss: 0.2810
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4048
Epoch 4/10, Batch 20/97, Loss: 0.2214
Epoch 4/10, Batch 30/97, Loss: 0.4025
Epoch 4/10, Batch 40/97, Loss: 0.3147
Epoch 4/10, Batch 50/97, Loss: 0.1892
Epoch 4/10, Batch 60/97, Loss: 0.2860
Epoch 4/10, Batch 70/97, Loss: 0.1849
Epoch 4/10, Batch 80/97, Loss: 0.2360
Epoch 4/10, Batch 90/97, Loss: 0.2513
Epoch 4/10, Train Loss: 0.2834, Valid Loss: 0.2662
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2178
Epoch 5/10, Batch 20/97, Loss: 0.3329
Epoch 5/10, Batch 30/97, Loss: 0.3280
Epoch 5/10, Batch 40/97, Loss: 0.1853
Epoch 5/10, Batch 50/97, Loss: 0.2039
Epoch 5/10, Batch 60/97, Loss: 0.2330
Epoch 5/10, Batch 70/97, Loss: 0.2303
Epoch 5/10, Batch 80/97, Loss: 0.3944
Epoch 5/10, Batch 90/97, Loss: 0.2515
Epoch 5/10, Train Loss: 0.2640, Valid Loss: 0.2423
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2964
Epoch 6/10, Batch 20/97, Loss: 0.3870
Epoch 6/10, Batch 30/97, Loss: 0.2417
Epoch 6/10, Batch 40/97, Loss: 0.2396
Epoch 6/10, Batch 50/97, Loss: 0.2905
Epoch 6/10, Batch 60/97, Loss: 0.3160
Epoch 6/10, Batch 70/97, Loss: 0.2077
Epoch 6/10, Batch 80/97, Loss: 0.3326
Epoch 6/10, Batch 90/97, Loss: 0.2258
Epoch 6/10, Train Loss: 0.2478, Valid Loss: 0.2284
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2029
Epoch 7/10, Batch 20/97, Loss: 0.3853
Epoch 7/10, Batch 30/97, Loss: 0.1544
Epoch 7/10, Batch 40/97, Loss: 0.2123
Epoch 7/10, Batch 50/97, Loss: 0.1475
Epoch 7/10, Batch 60/97, Loss: 0.2773
Epoch 7/10, Batch 70/97, Loss: 0.2770
Epoch 7/10, Batch 80/97, Loss: 0.1571
Epoch 7/10, Batch 90/97, Loss: 0.3215
Epoch 7/10, Train Loss: 0.2255, Valid Loss: 0.2248
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1678
Epoch 8/10, Batch 20/97, Loss: 0.1619
Epoch 8/10, Batch 30/97, Loss: 0.0825
Epoch 8/10, Batch 40/97, Loss: 0.2841
Epoch 8/10, Batch 50/97, Loss: 0.2032
Epoch 8/10, Batch 60/97, Loss: 0.2541
Epoch 8/10, Batch 70/97, Loss: 0.3259
Epoch 8/10, Batch 80/97, Loss: 0.1689
Epoch 8/10, Batch 90/97, Loss: 0.3344
Epoch 8/10, Train Loss: 0.2133, Valid Loss: 0.2255
Epoch 9/10, Batch 10/97, Loss: 0.2712
Epoch 9/10, Batch 20/97, Loss: 0.1483
Epoch 9/10, Batch 30/97, Loss: 0.2080
Epoch 9/10, Batch 40/97, Loss: 0.1799
Epoch 9/10, Batch 50/97, Loss: 0.1265
Epoch 9/10, Batch 60/97, Loss: 0.2431
Epoch 9/10, Batch 70/97, Loss: 0.1421
Epoch 9/10, Batch 80/97, Loss: 0.1462
Epoch 9/10, Batch 90/97, Loss: 0.1828
Epoch 9/10, Train Loss: 0.2066, Valid Loss: 0.2153
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1835
Epoch 10/10, Batch 20/97, Loss: 0.1077
Epoch 10/10, Batch 30/97, Loss: 0.2736
Epoch 10/10, Batch 40/97, Loss: 0.1280
Epoch 10/10, Batch 50/97, Loss: 0.1277
Epoch 10/10, Batch 60/97, Loss: 0.2407
Epoch 10/10, Batch 70/97, Loss: 0.2258
Epoch 10/10, Batch 80/97, Loss: 0.3202
Epoch 10/10, Batch 90/97, Loss: 0.1903
Epoch 10/10, Train Loss: 0.2006, Valid Loss: 0.2127
Model saved!
Accuracy: 0.9171
Precision: 0.9140
Recall: 0.9171
F1-score: 0.9150
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2739
Epoch 1/10, Batch 20/97, Loss: 1.1131
Epoch 1/10, Batch 30/97, Loss: 0.7915
Epoch 1/10, Batch 40/97, Loss: 0.7716
Epoch 1/10, Batch 50/97, Loss: 0.5169
Epoch 1/10, Batch 60/97, Loss: 0.6712
Epoch 1/10, Batch 70/97, Loss: 0.6438
Epoch 1/10, Batch 80/97, Loss: 0.7302
Epoch 1/10, Batch 90/97, Loss: 0.5293
Epoch 1/10, Train Loss: 0.8090, Valid Loss: 0.4487
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5706
Epoch 2/10, Batch 20/97, Loss: 0.5316
Epoch 2/10, Batch 30/97, Loss: 0.5771
Epoch 2/10, Batch 40/97, Loss: 0.3654
Epoch 2/10, Batch 50/97, Loss: 0.3705
Epoch 2/10, Batch 60/97, Loss: 0.4166
Epoch 2/10, Batch 70/97, Loss: 0.4317
Epoch 2/10, Batch 80/97, Loss: 0.3718
Epoch 2/10, Batch 90/97, Loss: 0.4456
Epoch 2/10, Train Loss: 0.4138, Valid Loss: 0.3435
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3107
Epoch 3/10, Batch 20/97, Loss: 0.3347
Epoch 3/10, Batch 30/97, Loss: 0.2955
Epoch 3/10, Batch 40/97, Loss: 0.1928
Epoch 3/10, Batch 50/97, Loss: 0.4000
Epoch 3/10, Batch 60/97, Loss: 0.2584
Epoch 3/10, Batch 70/97, Loss: 0.4018
Epoch 3/10, Batch 80/97, Loss: 0.2619
Epoch 3/10, Batch 90/97, Loss: 0.2637
Epoch 3/10, Train Loss: 0.3309, Valid Loss: 0.2984
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3362
Epoch 4/10, Batch 20/97, Loss: 0.2018
Epoch 4/10, Batch 30/97, Loss: 0.2081
Epoch 4/10, Batch 40/97, Loss: 0.2012
Epoch 4/10, Batch 50/97, Loss: 0.4539
Epoch 4/10, Batch 60/97, Loss: 0.3644
Epoch 4/10, Batch 70/97, Loss: 0.3525
Epoch 4/10, Batch 80/97, Loss: 0.2249
Epoch 4/10, Batch 90/97, Loss: 0.2015
Epoch 4/10, Train Loss: 0.2901, Valid Loss: 0.2840
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3674
Epoch 5/10, Batch 20/97, Loss: 0.2447
Epoch 5/10, Batch 30/97, Loss: 0.1355
Epoch 5/10, Batch 40/97, Loss: 0.2142
Epoch 5/10, Batch 50/97, Loss: 0.2658
Epoch 5/10, Batch 60/97, Loss: 0.2253
Epoch 5/10, Batch 70/97, Loss: 0.2468
Epoch 5/10, Batch 80/97, Loss: 0.2239
Epoch 5/10, Batch 90/97, Loss: 0.1938
Epoch 5/10, Train Loss: 0.2654, Valid Loss: 0.2683
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1969
Epoch 6/10, Batch 20/97, Loss: 0.3155
Epoch 6/10, Batch 30/97, Loss: 0.2567
Epoch 6/10, Batch 40/97, Loss: 0.2242
Epoch 6/10, Batch 50/97, Loss: 0.2097
Epoch 6/10, Batch 60/97, Loss: 0.2290
Epoch 6/10, Batch 70/97, Loss: 0.2451
Epoch 6/10, Batch 80/97, Loss: 0.3238
Epoch 6/10, Batch 90/97, Loss: 0.4665
Epoch 6/10, Train Loss: 0.2536, Valid Loss: 0.2539
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1961
Epoch 7/10, Batch 20/97, Loss: 0.1854
Epoch 7/10, Batch 30/97, Loss: 0.2173
Epoch 7/10, Batch 40/97, Loss: 0.2969
Epoch 7/10, Batch 50/97, Loss: 0.2378
Epoch 7/10, Batch 60/97, Loss: 0.1487
Epoch 7/10, Batch 70/97, Loss: 0.3367
Epoch 7/10, Batch 80/97, Loss: 0.2039
Epoch 7/10, Batch 90/97, Loss: 0.1947
Epoch 7/10, Train Loss: 0.2296, Valid Loss: 0.2511
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.0657
Epoch 8/10, Batch 20/97, Loss: 0.3214
Epoch 8/10, Batch 30/97, Loss: 0.1463
Epoch 8/10, Batch 40/97, Loss: 0.2355
Epoch 8/10, Batch 50/97, Loss: 0.1523
Epoch 8/10, Batch 60/97, Loss: 0.1810
Epoch 8/10, Batch 70/97, Loss: 0.2222
Epoch 8/10, Batch 80/97, Loss: 0.1652
Epoch 8/10, Batch 90/97, Loss: 0.1402
Epoch 8/10, Train Loss: 0.2180, Valid Loss: 0.2419
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2170
Epoch 9/10, Batch 20/97, Loss: 0.1449
Epoch 9/10, Batch 30/97, Loss: 0.5170
Epoch 9/10, Batch 40/97, Loss: 0.2096
Epoch 9/10, Batch 50/97, Loss: 0.1757
Epoch 9/10, Batch 60/97, Loss: 0.3924
Epoch 9/10, Batch 70/97, Loss: 0.2421
Epoch 9/10, Batch 80/97, Loss: 0.2211
Epoch 9/10, Batch 90/97, Loss: 0.2150
Epoch 9/10, Train Loss: 0.2114, Valid Loss: 0.2320
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2508
Epoch 10/10, Batch 20/97, Loss: 0.1839
Epoch 10/10, Batch 30/97, Loss: 0.3855
Epoch 10/10, Batch 40/97, Loss: 0.0760
Epoch 10/10, Batch 50/97, Loss: 0.1437
Epoch 10/10, Batch 60/97, Loss: 0.1537
Epoch 10/10, Batch 70/97, Loss: 0.4859
Epoch 10/10, Batch 80/97, Loss: 0.2121
Epoch 10/10, Batch 90/97, Loss: 0.1690
Epoch 10/10, Train Loss: 0.2049, Valid Loss: 0.2371
Accuracy: 0.9241
Precision: 0.9212
Recall: 0.9241
F1-score: 0.9220
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 19. Fitness: 0.9241
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2838
Epoch 1/10, Batch 20/97, Loss: 1.0591
Epoch 1/10, Batch 30/97, Loss: 0.7335
Epoch 1/10, Batch 40/97, Loss: 0.6742
Epoch 1/10, Batch 50/97, Loss: 0.6343
Epoch 1/10, Batch 60/97, Loss: 0.6031
Epoch 1/10, Batch 70/97, Loss: 0.5934
Epoch 1/10, Batch 80/97, Loss: 0.6292
Epoch 1/10, Batch 90/97, Loss: 0.4065
Epoch 1/10, Train Loss: 0.7984, Valid Loss: 0.4266
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5465
Epoch 2/10, Batch 20/97, Loss: 0.4482
Epoch 2/10, Batch 30/97, Loss: 0.3426
Epoch 2/10, Batch 40/97, Loss: 0.3264
Epoch 2/10, Batch 50/97, Loss: 0.3785
Epoch 2/10, Batch 60/97, Loss: 0.4119
Epoch 2/10, Batch 70/97, Loss: 0.3311
Epoch 2/10, Batch 80/97, Loss: 0.4698
Epoch 2/10, Batch 90/97, Loss: 0.4285
Epoch 2/10, Train Loss: 0.4085, Valid Loss: 0.3153
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2588
Epoch 3/10, Batch 20/97, Loss: 0.2923
Epoch 3/10, Batch 30/97, Loss: 0.5381
Epoch 3/10, Batch 40/97, Loss: 0.3584
Epoch 3/10, Batch 50/97, Loss: 0.3759
Epoch 3/10, Batch 60/97, Loss: 0.2046
Epoch 3/10, Batch 70/97, Loss: 0.3920
Epoch 3/10, Batch 80/97, Loss: 0.3410
Epoch 3/10, Batch 90/97, Loss: 0.3487
Epoch 3/10, Train Loss: 0.3286, Valid Loss: 0.2710
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3305
Epoch 4/10, Batch 20/97, Loss: 0.3218
Epoch 4/10, Batch 30/97, Loss: 0.2709
Epoch 4/10, Batch 40/97, Loss: 0.2240
Epoch 4/10, Batch 50/97, Loss: 0.3184
Epoch 4/10, Batch 60/97, Loss: 0.2207
Epoch 4/10, Batch 70/97, Loss: 0.2367
Epoch 4/10, Batch 80/97, Loss: 0.2976
Epoch 4/10, Batch 90/97, Loss: 0.2933
Epoch 4/10, Train Loss: 0.2756, Valid Loss: 0.2482
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2644
Epoch 5/10, Batch 20/97, Loss: 0.2634
Epoch 5/10, Batch 30/97, Loss: 0.3207
Epoch 5/10, Batch 40/97, Loss: 0.2123
Epoch 5/10, Batch 50/97, Loss: 0.2496
Epoch 5/10, Batch 60/97, Loss: 0.1797
Epoch 5/10, Batch 70/97, Loss: 0.2155
Epoch 5/10, Batch 80/97, Loss: 0.2133
Epoch 5/10, Batch 90/97, Loss: 0.3017
Epoch 5/10, Train Loss: 0.2648, Valid Loss: 0.2425
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1655
Epoch 6/10, Batch 20/97, Loss: 0.4283
Epoch 6/10, Batch 30/97, Loss: 0.2279
Epoch 6/10, Batch 40/97, Loss: 0.1902
Epoch 6/10, Batch 50/97, Loss: 0.1302
Epoch 6/10, Batch 60/97, Loss: 0.2387
Epoch 6/10, Batch 70/97, Loss: 0.2532
Epoch 6/10, Batch 80/97, Loss: 0.4185
Epoch 6/10, Batch 90/97, Loss: 0.3274
Epoch 6/10, Train Loss: 0.2484, Valid Loss: 0.2290
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1797
Epoch 7/10, Batch 20/97, Loss: 0.2288
Epoch 7/10, Batch 30/97, Loss: 0.2399
Epoch 7/10, Batch 40/97, Loss: 0.1200
Epoch 7/10, Batch 50/97, Loss: 0.1868
Epoch 7/10, Batch 60/97, Loss: 0.2216
Epoch 7/10, Batch 70/97, Loss: 0.3011
Epoch 7/10, Batch 80/97, Loss: 0.4429
Epoch 7/10, Batch 90/97, Loss: 0.2723
Epoch 7/10, Train Loss: 0.2194, Valid Loss: 0.2216
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2006
Epoch 8/10, Batch 20/97, Loss: 0.1151
Epoch 8/10, Batch 30/97, Loss: 0.1573
Epoch 8/10, Batch 40/97, Loss: 0.1551
Epoch 8/10, Batch 50/97, Loss: 0.3181
Epoch 8/10, Batch 60/97, Loss: 0.2419
Epoch 8/10, Batch 70/97, Loss: 0.2774
Epoch 8/10, Batch 80/97, Loss: 0.1788
Epoch 8/10, Batch 90/97, Loss: 0.2707
Epoch 8/10, Train Loss: 0.2141, Valid Loss: 0.2112
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1904
Epoch 9/10, Batch 20/97, Loss: 0.1144
Epoch 9/10, Batch 30/97, Loss: 0.2201
Epoch 9/10, Batch 40/97, Loss: 0.2124
Epoch 9/10, Batch 50/97, Loss: 0.1187
Epoch 9/10, Batch 60/97, Loss: 0.1972
Epoch 9/10, Batch 70/97, Loss: 0.1127
Epoch 9/10, Batch 80/97, Loss: 0.1106
Epoch 9/10, Batch 90/97, Loss: 0.2251
Epoch 9/10, Train Loss: 0.2049, Valid Loss: 0.2183
Epoch 10/10, Batch 10/97, Loss: 0.3794
Epoch 10/10, Batch 20/97, Loss: 0.1355
Epoch 10/10, Batch 30/97, Loss: 0.1470
Epoch 10/10, Batch 40/97, Loss: 0.1738
Epoch 10/10, Batch 50/97, Loss: 0.1535
Epoch 10/10, Batch 60/97, Loss: 0.1407
Epoch 10/10, Batch 70/97, Loss: 0.2261
Epoch 10/10, Batch 80/97, Loss: 0.1740
Epoch 10/10, Batch 90/97, Loss: 0.2169
Epoch 10/10, Train Loss: 0.1999, Valid Loss: 0.2075
Model saved!
Accuracy: 0.9100
Precision: 0.9070
Recall: 0.9100
F1-score: 0.9077
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2889
Epoch 1/10, Batch 20/97, Loss: 1.0686
Epoch 1/10, Batch 30/97, Loss: 0.7479
Epoch 1/10, Batch 40/97, Loss: 0.7316
Epoch 1/10, Batch 50/97, Loss: 0.6801
Epoch 1/10, Batch 60/97, Loss: 0.7151
Epoch 1/10, Batch 70/97, Loss: 0.6562
Epoch 1/10, Batch 80/97, Loss: 0.6981
Epoch 1/10, Batch 90/97, Loss: 0.6781
Epoch 1/10, Train Loss: 0.8036, Valid Loss: 0.4425
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3715
Epoch 2/10, Batch 20/97, Loss: 0.4249
Epoch 2/10, Batch 30/97, Loss: 0.3220
Epoch 2/10, Batch 40/97, Loss: 0.3614
Epoch 2/10, Batch 50/97, Loss: 0.4076
Epoch 2/10, Batch 60/97, Loss: 0.4291
Epoch 2/10, Batch 70/97, Loss: 0.3059
Epoch 2/10, Batch 80/97, Loss: 0.3486
Epoch 2/10, Batch 90/97, Loss: 0.4739
Epoch 2/10, Train Loss: 0.4062, Valid Loss: 0.3391
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2284
Epoch 3/10, Batch 20/97, Loss: 0.3442
Epoch 3/10, Batch 30/97, Loss: 0.4120
Epoch 3/10, Batch 40/97, Loss: 0.2972
Epoch 3/10, Batch 50/97, Loss: 0.3790
Epoch 3/10, Batch 60/97, Loss: 0.3589
Epoch 3/10, Batch 70/97, Loss: 0.3919
Epoch 3/10, Batch 80/97, Loss: 0.3470
Epoch 3/10, Batch 90/97, Loss: 0.3869
Epoch 3/10, Train Loss: 0.3333, Valid Loss: 0.2895
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3496
Epoch 4/10, Batch 20/97, Loss: 0.2018
Epoch 4/10, Batch 30/97, Loss: 0.2097
Epoch 4/10, Batch 40/97, Loss: 0.2503
Epoch 4/10, Batch 50/97, Loss: 0.3508
Epoch 4/10, Batch 60/97, Loss: 0.2882
Epoch 4/10, Batch 70/97, Loss: 0.3583
Epoch 4/10, Batch 80/97, Loss: 0.4243
Epoch 4/10, Batch 90/97, Loss: 0.2742
Epoch 4/10, Train Loss: 0.2838, Valid Loss: 0.2689
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2198
Epoch 5/10, Batch 20/97, Loss: 0.1990
Epoch 5/10, Batch 30/97, Loss: 0.1662
Epoch 5/10, Batch 40/97, Loss: 0.2092
Epoch 5/10, Batch 50/97, Loss: 0.1937
Epoch 5/10, Batch 60/97, Loss: 0.2449
Epoch 5/10, Batch 70/97, Loss: 0.2643
Epoch 5/10, Batch 80/97, Loss: 0.1358
Epoch 5/10, Batch 90/97, Loss: 0.2603
Epoch 5/10, Train Loss: 0.2551, Valid Loss: 0.2516
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1867
Epoch 6/10, Batch 20/97, Loss: 0.3282
Epoch 6/10, Batch 30/97, Loss: 0.2246
Epoch 6/10, Batch 40/97, Loss: 0.1378
Epoch 6/10, Batch 50/97, Loss: 0.1995
Epoch 6/10, Batch 60/97, Loss: 0.2848
Epoch 6/10, Batch 70/97, Loss: 0.2237
Epoch 6/10, Batch 80/97, Loss: 0.2944
Epoch 6/10, Batch 90/97, Loss: 0.5936
Epoch 6/10, Train Loss: 0.2364, Valid Loss: 0.2395
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2974
Epoch 7/10, Batch 20/97, Loss: 0.2020
Epoch 7/10, Batch 30/97, Loss: 0.1537
Epoch 7/10, Batch 40/97, Loss: 0.1332
Epoch 7/10, Batch 50/97, Loss: 0.1970
Epoch 7/10, Batch 60/97, Loss: 0.0772
Epoch 7/10, Batch 70/97, Loss: 0.1802
Epoch 7/10, Batch 80/97, Loss: 0.1126
Epoch 7/10, Batch 90/97, Loss: 0.2047
Epoch 7/10, Train Loss: 0.2185, Valid Loss: 0.2378
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2375
Epoch 8/10, Batch 20/97, Loss: 0.2376
Epoch 8/10, Batch 30/97, Loss: 0.2344
Epoch 8/10, Batch 40/97, Loss: 0.1339
Epoch 8/10, Batch 50/97, Loss: 0.2788
Epoch 8/10, Batch 60/97, Loss: 0.1288
Epoch 8/10, Batch 70/97, Loss: 0.2644
Epoch 8/10, Batch 80/97, Loss: 0.2409
Epoch 8/10, Batch 90/97, Loss: 0.1836
Epoch 8/10, Train Loss: 0.2188, Valid Loss: 0.2349
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2212
Epoch 9/10, Batch 20/97, Loss: 0.1099
Epoch 9/10, Batch 30/97, Loss: 0.1901
Epoch 9/10, Batch 40/97, Loss: 0.2658
Epoch 9/10, Batch 50/97, Loss: 0.1774
Epoch 9/10, Batch 60/97, Loss: 0.1705
Epoch 9/10, Batch 70/97, Loss: 0.1610
Epoch 9/10, Batch 80/97, Loss: 0.2026
Epoch 9/10, Batch 90/97, Loss: 0.2471
Epoch 9/10, Train Loss: 0.2015, Valid Loss: 0.2299
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2333
Epoch 10/10, Batch 20/97, Loss: 0.1836
Epoch 10/10, Batch 30/97, Loss: 0.2189
Epoch 10/10, Batch 40/97, Loss: 0.2172
Epoch 10/10, Batch 50/97, Loss: 0.1311
Epoch 10/10, Batch 60/97, Loss: 0.2001
Epoch 10/10, Batch 70/97, Loss: 0.2096
Epoch 10/10, Batch 80/97, Loss: 0.2088
Epoch 10/10, Batch 90/97, Loss: 0.1797
Epoch 10/10, Train Loss: 0.2053, Valid Loss: 0.2229
Model saved!
Accuracy: 0.9171
Precision: 0.9139
Recall: 0.9171
F1-score: 0.9149
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2447
Epoch 1/10, Batch 20/97, Loss: 1.0591
Epoch 1/10, Batch 30/97, Loss: 0.7742
Epoch 1/10, Batch 40/97, Loss: 0.7837
Epoch 1/10, Batch 50/97, Loss: 0.5927
Epoch 1/10, Batch 60/97, Loss: 0.7081
Epoch 1/10, Batch 70/97, Loss: 0.7112
Epoch 1/10, Batch 80/97, Loss: 0.6657
Epoch 1/10, Batch 90/97, Loss: 0.4435
Epoch 1/10, Train Loss: 0.8048, Valid Loss: 0.4519
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5018
Epoch 2/10, Batch 20/97, Loss: 0.4771
Epoch 2/10, Batch 30/97, Loss: 0.3128
Epoch 2/10, Batch 40/97, Loss: 0.3179
Epoch 2/10, Batch 50/97, Loss: 0.5687
Epoch 2/10, Batch 60/97, Loss: 0.4231
Epoch 2/10, Batch 70/97, Loss: 0.3309
Epoch 2/10, Batch 80/97, Loss: 0.5502
Epoch 2/10, Batch 90/97, Loss: 0.6056
Epoch 2/10, Train Loss: 0.4142, Valid Loss: 0.3511
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3914
Epoch 3/10, Batch 20/97, Loss: 0.3349
Epoch 3/10, Batch 30/97, Loss: 0.2945
Epoch 3/10, Batch 40/97, Loss: 0.3758
Epoch 3/10, Batch 50/97, Loss: 0.3121
Epoch 3/10, Batch 60/97, Loss: 0.1553
Epoch 3/10, Batch 70/97, Loss: 0.4552
Epoch 3/10, Batch 80/97, Loss: 0.3388
Epoch 3/10, Batch 90/97, Loss: 0.2572
Epoch 3/10, Train Loss: 0.3447, Valid Loss: 0.3057
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4394
Epoch 4/10, Batch 20/97, Loss: 0.2282
Epoch 4/10, Batch 30/97, Loss: 0.2887
Epoch 4/10, Batch 40/97, Loss: 0.2178
Epoch 4/10, Batch 50/97, Loss: 0.3386
Epoch 4/10, Batch 60/97, Loss: 0.2253
Epoch 4/10, Batch 70/97, Loss: 0.2053
Epoch 4/10, Batch 80/97, Loss: 0.1712
Epoch 4/10, Batch 90/97, Loss: 0.2154
Epoch 4/10, Train Loss: 0.2883, Valid Loss: 0.2907
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2354
Epoch 5/10, Batch 20/97, Loss: 0.2792
Epoch 5/10, Batch 30/97, Loss: 0.1517
Epoch 5/10, Batch 40/97, Loss: 0.1996
Epoch 5/10, Batch 50/97, Loss: 0.2468
Epoch 5/10, Batch 60/97, Loss: 0.1841
Epoch 5/10, Batch 70/97, Loss: 0.3939
Epoch 5/10, Batch 80/97, Loss: 0.2604
Epoch 5/10, Batch 90/97, Loss: 0.2689
Epoch 5/10, Train Loss: 0.2739, Valid Loss: 0.2724
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1526
Epoch 6/10, Batch 20/97, Loss: 0.2567
Epoch 6/10, Batch 30/97, Loss: 0.1201
Epoch 6/10, Batch 40/97, Loss: 0.1181
Epoch 6/10, Batch 50/97, Loss: 0.2313
Epoch 6/10, Batch 60/97, Loss: 0.1647
Epoch 6/10, Batch 70/97, Loss: 0.2758
Epoch 6/10, Batch 80/97, Loss: 0.1872
Epoch 6/10, Batch 90/97, Loss: 0.1747
Epoch 6/10, Train Loss: 0.2445, Valid Loss: 0.2632
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2610
Epoch 7/10, Batch 20/97, Loss: 0.2363
Epoch 7/10, Batch 30/97, Loss: 0.2158
Epoch 7/10, Batch 40/97, Loss: 0.2378
Epoch 7/10, Batch 50/97, Loss: 0.2995
Epoch 7/10, Batch 60/97, Loss: 0.2237
Epoch 7/10, Batch 70/97, Loss: 0.2692
Epoch 7/10, Batch 80/97, Loss: 0.1614
Epoch 7/10, Batch 90/97, Loss: 0.3618
Epoch 7/10, Train Loss: 0.2277, Valid Loss: 0.2644
Epoch 8/10, Batch 10/97, Loss: 0.1524
Epoch 8/10, Batch 20/97, Loss: 0.1611
Epoch 8/10, Batch 30/97, Loss: 0.3087
Epoch 8/10, Batch 40/97, Loss: 0.2047
Epoch 8/10, Batch 50/97, Loss: 0.2029
Epoch 8/10, Batch 60/97, Loss: 0.1237
Epoch 8/10, Batch 70/97, Loss: 0.1349
Epoch 8/10, Batch 80/97, Loss: 0.3598
Epoch 8/10, Batch 90/97, Loss: 0.2266
Epoch 8/10, Train Loss: 0.2233, Valid Loss: 0.2578
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1534
Epoch 9/10, Batch 20/97, Loss: 0.1244
Epoch 9/10, Batch 30/97, Loss: 0.1951
Epoch 9/10, Batch 40/97, Loss: 0.3107
Epoch 9/10, Batch 50/97, Loss: 0.1662
Epoch 9/10, Batch 60/97, Loss: 0.2033
Epoch 9/10, Batch 70/97, Loss: 0.1477
Epoch 9/10, Batch 80/97, Loss: 0.1150
Epoch 9/10, Batch 90/97, Loss: 0.1526
Epoch 9/10, Train Loss: 0.2048, Valid Loss: 0.2523
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1664
Epoch 10/10, Batch 20/97, Loss: 0.2124
Epoch 10/10, Batch 30/97, Loss: 0.1541
Epoch 10/10, Batch 40/97, Loss: 0.3350
Epoch 10/10, Batch 50/97, Loss: 0.1216
Epoch 10/10, Batch 60/97, Loss: 0.1549
Epoch 10/10, Batch 70/97, Loss: 0.2272
Epoch 10/10, Batch 80/97, Loss: 0.1569
Epoch 10/10, Batch 90/97, Loss: 0.2660
Epoch 10/10, Train Loss: 0.2086, Valid Loss: 0.2460
Model saved!
Accuracy: 0.9089
Precision: 0.9045
Recall: 0.9089
F1-score: 0.9055
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2464
Epoch 1/10, Batch 20/97, Loss: 1.1194
Epoch 1/10, Batch 30/97, Loss: 0.7423
Epoch 1/10, Batch 40/97, Loss: 0.6955
Epoch 1/10, Batch 50/97, Loss: 0.7215
Epoch 1/10, Batch 60/97, Loss: 0.6953
Epoch 1/10, Batch 70/97, Loss: 0.6889
Epoch 1/10, Batch 80/97, Loss: 0.7129
Epoch 1/10, Batch 90/97, Loss: 0.4942
Epoch 1/10, Train Loss: 0.8042, Valid Loss: 0.4366
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4435
Epoch 2/10, Batch 20/97, Loss: 0.3634
Epoch 2/10, Batch 30/97, Loss: 0.3381
Epoch 2/10, Batch 40/97, Loss: 0.4153
Epoch 2/10, Batch 50/97, Loss: 0.4925
Epoch 2/10, Batch 60/97, Loss: 0.4833
Epoch 2/10, Batch 70/97, Loss: 0.3496
Epoch 2/10, Batch 80/97, Loss: 0.5576
Epoch 2/10, Batch 90/97, Loss: 0.4110
Epoch 2/10, Train Loss: 0.4172, Valid Loss: 0.3341
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2712
Epoch 3/10, Batch 20/97, Loss: 0.3661
Epoch 3/10, Batch 30/97, Loss: 0.4304
Epoch 3/10, Batch 40/97, Loss: 0.2595
Epoch 3/10, Batch 50/97, Loss: 0.2724
Epoch 3/10, Batch 60/97, Loss: 0.2335
Epoch 3/10, Batch 70/97, Loss: 0.4265
Epoch 3/10, Batch 80/97, Loss: 0.2264
Epoch 3/10, Batch 90/97, Loss: 0.2435
Epoch 3/10, Train Loss: 0.3384, Valid Loss: 0.2800
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3579
Epoch 4/10, Batch 20/97, Loss: 0.1998
Epoch 4/10, Batch 30/97, Loss: 0.2560
Epoch 4/10, Batch 40/97, Loss: 0.1156
Epoch 4/10, Batch 50/97, Loss: 0.3271
Epoch 4/10, Batch 60/97, Loss: 0.2501
Epoch 4/10, Batch 70/97, Loss: 0.3102
Epoch 4/10, Batch 80/97, Loss: 0.4267
Epoch 4/10, Batch 90/97, Loss: 0.2621
Epoch 4/10, Train Loss: 0.2872, Valid Loss: 0.2579
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3465
Epoch 5/10, Batch 20/97, Loss: 0.3151
Epoch 5/10, Batch 30/97, Loss: 0.3650
Epoch 5/10, Batch 40/97, Loss: 0.3350
Epoch 5/10, Batch 50/97, Loss: 0.2267
Epoch 5/10, Batch 60/97, Loss: 0.2425
Epoch 5/10, Batch 70/97, Loss: 0.1810
Epoch 5/10, Batch 80/97, Loss: 0.4079
Epoch 5/10, Batch 90/97, Loss: 0.2567
Epoch 5/10, Train Loss: 0.2690, Valid Loss: 0.2429
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1903
Epoch 6/10, Batch 20/97, Loss: 0.3510
Epoch 6/10, Batch 30/97, Loss: 0.2204
Epoch 6/10, Batch 40/97, Loss: 0.2982
Epoch 6/10, Batch 50/97, Loss: 0.2448
Epoch 6/10, Batch 60/97, Loss: 0.2472
Epoch 6/10, Batch 70/97, Loss: 0.2925
Epoch 6/10, Batch 80/97, Loss: 0.2919
Epoch 6/10, Batch 90/97, Loss: 0.2386
Epoch 6/10, Train Loss: 0.2385, Valid Loss: 0.2312
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1998
Epoch 7/10, Batch 20/97, Loss: 0.2955
Epoch 7/10, Batch 30/97, Loss: 0.1379
Epoch 7/10, Batch 40/97, Loss: 0.2156
Epoch 7/10, Batch 50/97, Loss: 0.3223
Epoch 7/10, Batch 60/97, Loss: 0.2543
Epoch 7/10, Batch 70/97, Loss: 0.3966
Epoch 7/10, Batch 80/97, Loss: 0.1568
Epoch 7/10, Batch 90/97, Loss: 0.2562
Epoch 7/10, Train Loss: 0.2377, Valid Loss: 0.2193
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2329
Epoch 8/10, Batch 20/97, Loss: 0.1673
Epoch 8/10, Batch 30/97, Loss: 0.1743
Epoch 8/10, Batch 40/97, Loss: 0.2246
Epoch 8/10, Batch 50/97, Loss: 0.3309
Epoch 8/10, Batch 60/97, Loss: 0.0527
Epoch 8/10, Batch 70/97, Loss: 0.2184
Epoch 8/10, Batch 80/97, Loss: 0.2853
Epoch 8/10, Batch 90/97, Loss: 0.1498
Epoch 8/10, Train Loss: 0.2171, Valid Loss: 0.2199
Epoch 9/10, Batch 10/97, Loss: 0.1489
Epoch 9/10, Batch 20/97, Loss: 0.3750
Epoch 9/10, Batch 30/97, Loss: 0.2363
Epoch 9/10, Batch 40/97, Loss: 0.2573
Epoch 9/10, Batch 50/97, Loss: 0.2607
Epoch 9/10, Batch 60/97, Loss: 0.2951
Epoch 9/10, Batch 70/97, Loss: 0.1736
Epoch 9/10, Batch 80/97, Loss: 0.1569
Epoch 9/10, Batch 90/97, Loss: 0.1529
Epoch 9/10, Train Loss: 0.2108, Valid Loss: 0.2137
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2549
Epoch 10/10, Batch 20/97, Loss: 0.2612
Epoch 10/10, Batch 30/97, Loss: 0.1304
Epoch 10/10, Batch 40/97, Loss: 0.1838
Epoch 10/10, Batch 50/97, Loss: 0.1555
Epoch 10/10, Batch 60/97, Loss: 0.1455
Epoch 10/10, Batch 70/97, Loss: 0.0955
Epoch 10/10, Batch 80/97, Loss: 0.2326
Epoch 10/10, Batch 90/97, Loss: 0.2390
Epoch 10/10, Train Loss: 0.1973, Valid Loss: 0.2167
Accuracy: 0.9147
Precision: 0.9112
Recall: 0.9147
F1-score: 0.9118
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2492
Epoch 1/10, Batch 20/97, Loss: 1.0515
Epoch 1/10, Batch 30/97, Loss: 0.6735
Epoch 1/10, Batch 40/97, Loss: 0.7622
Epoch 1/10, Batch 50/97, Loss: 0.5389
Epoch 1/10, Batch 60/97, Loss: 0.6385
Epoch 1/10, Batch 70/97, Loss: 0.6120
Epoch 1/10, Batch 80/97, Loss: 0.6304
Epoch 1/10, Batch 90/97, Loss: 0.6136
Epoch 1/10, Train Loss: 0.8036, Valid Loss: 0.4179
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5787
Epoch 2/10, Batch 20/97, Loss: 0.3951
Epoch 2/10, Batch 30/97, Loss: 0.3250
Epoch 2/10, Batch 40/97, Loss: 0.2968
Epoch 2/10, Batch 50/97, Loss: 0.3866
Epoch 2/10, Batch 60/97, Loss: 0.4354
Epoch 2/10, Batch 70/97, Loss: 0.3267
Epoch 2/10, Batch 80/97, Loss: 0.4176
Epoch 2/10, Batch 90/97, Loss: 0.5411
Epoch 2/10, Train Loss: 0.4109, Valid Loss: 0.3067
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2735
Epoch 3/10, Batch 20/97, Loss: 0.3587
Epoch 3/10, Batch 30/97, Loss: 0.4159
Epoch 3/10, Batch 40/97, Loss: 0.3190
Epoch 3/10, Batch 50/97, Loss: 0.3744
Epoch 3/10, Batch 60/97, Loss: 0.2478
Epoch 3/10, Batch 70/97, Loss: 0.3941
Epoch 3/10, Batch 80/97, Loss: 0.3846
Epoch 3/10, Batch 90/97, Loss: 0.2252
Epoch 3/10, Train Loss: 0.3326, Valid Loss: 0.2642
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3165
Epoch 4/10, Batch 20/97, Loss: 0.2200
Epoch 4/10, Batch 30/97, Loss: 0.5906
Epoch 4/10, Batch 40/97, Loss: 0.2199
Epoch 4/10, Batch 50/97, Loss: 0.3633
Epoch 4/10, Batch 60/97, Loss: 0.1772
Epoch 4/10, Batch 70/97, Loss: 0.4005
Epoch 4/10, Batch 80/97, Loss: 0.3296
Epoch 4/10, Batch 90/97, Loss: 0.2450
Epoch 4/10, Train Loss: 0.2875, Valid Loss: 0.2457
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3332
Epoch 5/10, Batch 20/97, Loss: 0.4494
Epoch 5/10, Batch 30/97, Loss: 0.2838
Epoch 5/10, Batch 40/97, Loss: 0.2419
Epoch 5/10, Batch 50/97, Loss: 0.1344
Epoch 5/10, Batch 60/97, Loss: 0.1824
Epoch 5/10, Batch 70/97, Loss: 0.2911
Epoch 5/10, Batch 80/97, Loss: 0.2585
Epoch 5/10, Batch 90/97, Loss: 0.3266
Epoch 5/10, Train Loss: 0.2603, Valid Loss: 0.2339
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1910
Epoch 6/10, Batch 20/97, Loss: 0.4039
Epoch 6/10, Batch 30/97, Loss: 0.2033
Epoch 6/10, Batch 40/97, Loss: 0.2740
Epoch 6/10, Batch 50/97, Loss: 0.2609
Epoch 6/10, Batch 60/97, Loss: 0.1779
Epoch 6/10, Batch 70/97, Loss: 0.1473
Epoch 6/10, Batch 80/97, Loss: 0.3660
Epoch 6/10, Batch 90/97, Loss: 0.2911
Epoch 6/10, Train Loss: 0.2457, Valid Loss: 0.2254
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1410
Epoch 7/10, Batch 20/97, Loss: 0.1808
Epoch 7/10, Batch 30/97, Loss: 0.2066
Epoch 7/10, Batch 40/97, Loss: 0.1104
Epoch 7/10, Batch 50/97, Loss: 0.2008
Epoch 7/10, Batch 60/97, Loss: 0.0919
Epoch 7/10, Batch 70/97, Loss: 0.2016
Epoch 7/10, Batch 80/97, Loss: 0.2979
Epoch 7/10, Batch 90/97, Loss: 0.2740
Epoch 7/10, Train Loss: 0.2274, Valid Loss: 0.2119
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1676
Epoch 8/10, Batch 20/97, Loss: 0.1700
Epoch 8/10, Batch 30/97, Loss: 0.1429
Epoch 8/10, Batch 40/97, Loss: 0.3454
Epoch 8/10, Batch 50/97, Loss: 0.2251
Epoch 8/10, Batch 60/97, Loss: 0.1097
Epoch 8/10, Batch 70/97, Loss: 0.1989
Epoch 8/10, Batch 80/97, Loss: 0.1849
Epoch 8/10, Batch 90/97, Loss: 0.1676
Epoch 8/10, Train Loss: 0.2211, Valid Loss: 0.2163
Epoch 9/10, Batch 10/97, Loss: 0.1139
Epoch 9/10, Batch 20/97, Loss: 0.2255
Epoch 9/10, Batch 30/97, Loss: 0.2699
Epoch 9/10, Batch 40/97, Loss: 0.2162
Epoch 9/10, Batch 50/97, Loss: 0.1084
Epoch 9/10, Batch 60/97, Loss: 0.2628
Epoch 9/10, Batch 70/97, Loss: 0.2455
Epoch 9/10, Batch 80/97, Loss: 0.1060
Epoch 9/10, Batch 90/97, Loss: 0.0805
Epoch 9/10, Train Loss: 0.2023, Valid Loss: 0.2024
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2463
Epoch 10/10, Batch 20/97, Loss: 0.0796
Epoch 10/10, Batch 30/97, Loss: 0.1375
Epoch 10/10, Batch 40/97, Loss: 0.1073
Epoch 10/10, Batch 50/97, Loss: 0.1906
Epoch 10/10, Batch 60/97, Loss: 0.3063
Epoch 10/10, Batch 70/97, Loss: 0.3110
Epoch 10/10, Batch 80/97, Loss: 0.1005
Epoch 10/10, Batch 90/97, Loss: 0.2650
Epoch 10/10, Train Loss: 0.2011, Valid Loss: 0.2037
Accuracy: 0.9077
Precision: 0.9039
Recall: 0.9077
F1-score: 0.9050
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2652
Epoch 1/10, Batch 20/97, Loss: 1.1067
Epoch 1/10, Batch 30/97, Loss: 0.7118
Epoch 1/10, Batch 40/97, Loss: 0.6613
Epoch 1/10, Batch 50/97, Loss: 0.6373
Epoch 1/10, Batch 60/97, Loss: 0.6367
Epoch 1/10, Batch 70/97, Loss: 0.6590
Epoch 1/10, Batch 80/97, Loss: 0.6415
Epoch 1/10, Batch 90/97, Loss: 0.5314
Epoch 1/10, Train Loss: 0.7876, Valid Loss: 0.4420
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4750
Epoch 2/10, Batch 20/97, Loss: 0.2941
Epoch 2/10, Batch 30/97, Loss: 0.4180
Epoch 2/10, Batch 40/97, Loss: 0.4685
Epoch 2/10, Batch 50/97, Loss: 0.3729
Epoch 2/10, Batch 60/97, Loss: 0.3320
Epoch 2/10, Batch 70/97, Loss: 0.3372
Epoch 2/10, Batch 80/97, Loss: 0.4045
Epoch 2/10, Batch 90/97, Loss: 0.4972
Epoch 2/10, Train Loss: 0.4076, Valid Loss: 0.3341
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3896
Epoch 3/10, Batch 20/97, Loss: 0.3366
Epoch 3/10, Batch 30/97, Loss: 0.4799
Epoch 3/10, Batch 40/97, Loss: 0.3771
Epoch 3/10, Batch 50/97, Loss: 0.4231
Epoch 3/10, Batch 60/97, Loss: 0.3762
Epoch 3/10, Batch 70/97, Loss: 0.3079
Epoch 3/10, Batch 80/97, Loss: 0.3502
Epoch 3/10, Batch 90/97, Loss: 0.1608
Epoch 3/10, Train Loss: 0.3300, Valid Loss: 0.2924
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4075
Epoch 4/10, Batch 20/97, Loss: 0.2951
Epoch 4/10, Batch 30/97, Loss: 0.2352
Epoch 4/10, Batch 40/97, Loss: 0.2768
Epoch 4/10, Batch 50/97, Loss: 0.3008
Epoch 4/10, Batch 60/97, Loss: 0.2840
Epoch 4/10, Batch 70/97, Loss: 0.4438
Epoch 4/10, Batch 80/97, Loss: 0.2720
Epoch 4/10, Batch 90/97, Loss: 0.2107
Epoch 4/10, Train Loss: 0.2813, Valid Loss: 0.2719
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2768
Epoch 5/10, Batch 20/97, Loss: 0.4409
Epoch 5/10, Batch 30/97, Loss: 0.3968
Epoch 5/10, Batch 40/97, Loss: 0.2254
Epoch 5/10, Batch 50/97, Loss: 0.2947
Epoch 5/10, Batch 60/97, Loss: 0.1094
Epoch 5/10, Batch 70/97, Loss: 0.2788
Epoch 5/10, Batch 80/97, Loss: 0.2145
Epoch 5/10, Batch 90/97, Loss: 0.2399
Epoch 5/10, Train Loss: 0.2648, Valid Loss: 0.2485
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2955
Epoch 6/10, Batch 20/97, Loss: 0.4378
Epoch 6/10, Batch 30/97, Loss: 0.1920
Epoch 6/10, Batch 40/97, Loss: 0.1799
Epoch 6/10, Batch 50/97, Loss: 0.2349
Epoch 6/10, Batch 60/97, Loss: 0.2684
Epoch 6/10, Batch 70/97, Loss: 0.2497
Epoch 6/10, Batch 80/97, Loss: 0.3146
Epoch 6/10, Batch 90/97, Loss: 0.3074
Epoch 6/10, Train Loss: 0.2432, Valid Loss: 0.2431
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3070
Epoch 7/10, Batch 20/97, Loss: 0.2862
Epoch 7/10, Batch 30/97, Loss: 0.2430
Epoch 7/10, Batch 40/97, Loss: 0.2458
Epoch 7/10, Batch 50/97, Loss: 0.2473
Epoch 7/10, Batch 60/97, Loss: 0.1798
Epoch 7/10, Batch 70/97, Loss: 0.2209
Epoch 7/10, Batch 80/97, Loss: 0.1572
Epoch 7/10, Batch 90/97, Loss: 0.2584
Epoch 7/10, Train Loss: 0.2272, Valid Loss: 0.2386
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1634
Epoch 8/10, Batch 20/97, Loss: 0.1977
Epoch 8/10, Batch 30/97, Loss: 0.1468
Epoch 8/10, Batch 40/97, Loss: 0.1579
Epoch 8/10, Batch 50/97, Loss: 0.1713
Epoch 8/10, Batch 60/97, Loss: 0.2906
Epoch 8/10, Batch 70/97, Loss: 0.1869
Epoch 8/10, Batch 80/97, Loss: 0.3050
Epoch 8/10, Batch 90/97, Loss: 0.4680
Epoch 8/10, Train Loss: 0.2137, Valid Loss: 0.2313
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2288
Epoch 9/10, Batch 20/97, Loss: 0.0762
Epoch 9/10, Batch 30/97, Loss: 0.2241
Epoch 9/10, Batch 40/97, Loss: 0.2190
Epoch 9/10, Batch 50/97, Loss: 0.1218
Epoch 9/10, Batch 60/97, Loss: 0.3986
Epoch 9/10, Batch 70/97, Loss: 0.2171
Epoch 9/10, Batch 80/97, Loss: 0.1236
Epoch 9/10, Batch 90/97, Loss: 0.1300
Epoch 9/10, Train Loss: 0.2049, Valid Loss: 0.2200
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2248
Epoch 10/10, Batch 20/97, Loss: 0.1172
Epoch 10/10, Batch 30/97, Loss: 0.2844
Epoch 10/10, Batch 40/97, Loss: 0.2174
Epoch 10/10, Batch 50/97, Loss: 0.3030
Epoch 10/10, Batch 60/97, Loss: 0.1410
Epoch 10/10, Batch 70/97, Loss: 0.2105
Epoch 10/10, Batch 80/97, Loss: 0.2543
Epoch 10/10, Batch 90/97, Loss: 0.0833
Epoch 10/10, Train Loss: 0.2043, Valid Loss: 0.2206
Accuracy: 0.9089
Precision: 0.9068
Recall: 0.9089
F1-score: 0.9072
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2965
Epoch 1/10, Batch 20/97, Loss: 1.0427
Epoch 1/10, Batch 30/97, Loss: 0.7660
Epoch 1/10, Batch 40/97, Loss: 0.7676
Epoch 1/10, Batch 50/97, Loss: 0.5774
Epoch 1/10, Batch 60/97, Loss: 0.7527
Epoch 1/10, Batch 70/97, Loss: 0.7501
Epoch 1/10, Batch 80/97, Loss: 0.6808
Epoch 1/10, Batch 90/97, Loss: 0.4727
Epoch 1/10, Train Loss: 0.8167, Valid Loss: 0.4427
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6031
Epoch 2/10, Batch 20/97, Loss: 0.4332
Epoch 2/10, Batch 30/97, Loss: 0.4097
Epoch 2/10, Batch 40/97, Loss: 0.3554
Epoch 2/10, Batch 50/97, Loss: 0.4375
Epoch 2/10, Batch 60/97, Loss: 0.7480
Epoch 2/10, Batch 70/97, Loss: 0.3034
Epoch 2/10, Batch 80/97, Loss: 0.4810
Epoch 2/10, Batch 90/97, Loss: 0.3901
Epoch 2/10, Train Loss: 0.4233, Valid Loss: 0.3289
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3134
Epoch 3/10, Batch 20/97, Loss: 0.3191
Epoch 3/10, Batch 30/97, Loss: 0.3282
Epoch 3/10, Batch 40/97, Loss: 0.3299
Epoch 3/10, Batch 50/97, Loss: 0.3358
Epoch 3/10, Batch 60/97, Loss: 0.3439
Epoch 3/10, Batch 70/97, Loss: 0.4532
Epoch 3/10, Batch 80/97, Loss: 0.3554
Epoch 3/10, Batch 90/97, Loss: 0.2020
Epoch 3/10, Train Loss: 0.3409, Valid Loss: 0.2855
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2750
Epoch 4/10, Batch 20/97, Loss: 0.1222
Epoch 4/10, Batch 30/97, Loss: 0.2324
Epoch 4/10, Batch 40/97, Loss: 0.2365
Epoch 4/10, Batch 50/97, Loss: 0.4339
Epoch 4/10, Batch 60/97, Loss: 0.2349
Epoch 4/10, Batch 70/97, Loss: 0.2337
Epoch 4/10, Batch 80/97, Loss: 0.6126
Epoch 4/10, Batch 90/97, Loss: 0.3124
Epoch 4/10, Train Loss: 0.2968, Valid Loss: 0.2700
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2364
Epoch 5/10, Batch 20/97, Loss: 0.2149
Epoch 5/10, Batch 30/97, Loss: 0.1930
Epoch 5/10, Batch 40/97, Loss: 0.1871
Epoch 5/10, Batch 50/97, Loss: 0.1980
Epoch 5/10, Batch 60/97, Loss: 0.4235
Epoch 5/10, Batch 70/97, Loss: 0.2494
Epoch 5/10, Batch 80/97, Loss: 0.3492
Epoch 5/10, Batch 90/97, Loss: 0.2743
Epoch 5/10, Train Loss: 0.2684, Valid Loss: 0.2570
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1600
Epoch 6/10, Batch 20/97, Loss: 0.3504
Epoch 6/10, Batch 30/97, Loss: 0.2266
Epoch 6/10, Batch 40/97, Loss: 0.2068
Epoch 6/10, Batch 50/97, Loss: 0.3566
Epoch 6/10, Batch 60/97, Loss: 0.2819
Epoch 6/10, Batch 70/97, Loss: 0.2156
Epoch 6/10, Batch 80/97, Loss: 0.2598
Epoch 6/10, Batch 90/97, Loss: 0.2153
Epoch 6/10, Train Loss: 0.2484, Valid Loss: 0.2414
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1896
Epoch 7/10, Batch 20/97, Loss: 0.2129
Epoch 7/10, Batch 30/97, Loss: 0.1441
Epoch 7/10, Batch 40/97, Loss: 0.1564
Epoch 7/10, Batch 50/97, Loss: 0.2267
Epoch 7/10, Batch 60/97, Loss: 0.2302
Epoch 7/10, Batch 70/97, Loss: 0.3063
Epoch 7/10, Batch 80/97, Loss: 0.4827
Epoch 7/10, Batch 90/97, Loss: 0.3195
Epoch 7/10, Train Loss: 0.2333, Valid Loss: 0.2336
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1121
Epoch 8/10, Batch 20/97, Loss: 0.2816
Epoch 8/10, Batch 30/97, Loss: 0.2214
Epoch 8/10, Batch 40/97, Loss: 0.2113
Epoch 8/10, Batch 50/97, Loss: 0.1397
Epoch 8/10, Batch 60/97, Loss: 0.1188
Epoch 8/10, Batch 70/97, Loss: 0.1754
Epoch 8/10, Batch 80/97, Loss: 0.2373
Epoch 8/10, Batch 90/97, Loss: 0.1836
Epoch 8/10, Train Loss: 0.2278, Valid Loss: 0.2329
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1899
Epoch 9/10, Batch 20/97, Loss: 0.2391
Epoch 9/10, Batch 30/97, Loss: 0.2489
Epoch 9/10, Batch 40/97, Loss: 0.1719
Epoch 9/10, Batch 50/97, Loss: 0.2739
Epoch 9/10, Batch 60/97, Loss: 0.1371
Epoch 9/10, Batch 70/97, Loss: 0.1642
Epoch 9/10, Batch 80/97, Loss: 0.0941
Epoch 9/10, Batch 90/97, Loss: 0.1692
Epoch 9/10, Train Loss: 0.2144, Valid Loss: 0.2258
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1966
Epoch 10/10, Batch 20/97, Loss: 0.1780
Epoch 10/10, Batch 30/97, Loss: 0.1884
Epoch 10/10, Batch 40/97, Loss: 0.1453
Epoch 10/10, Batch 50/97, Loss: 0.0977
Epoch 10/10, Batch 60/97, Loss: 0.2587
Epoch 10/10, Batch 70/97, Loss: 0.2449
Epoch 10/10, Batch 80/97, Loss: 0.1198
Epoch 10/10, Batch 90/97, Loss: 0.2354
Epoch 10/10, Train Loss: 0.2065, Valid Loss: 0.2315
Accuracy: 0.9089
Precision: 0.9064
Recall: 0.9089
F1-score: 0.9073
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2355
Epoch 1/10, Batch 20/97, Loss: 1.0355
Epoch 1/10, Batch 30/97, Loss: 0.8516
Epoch 1/10, Batch 40/97, Loss: 0.7218
Epoch 1/10, Batch 50/97, Loss: 0.6520
Epoch 1/10, Batch 60/97, Loss: 0.7158
Epoch 1/10, Batch 70/97, Loss: 0.7141
Epoch 1/10, Batch 80/97, Loss: 0.6374
Epoch 1/10, Batch 90/97, Loss: 0.6001
Epoch 1/10, Train Loss: 0.8031, Valid Loss: 0.4535
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6661
Epoch 2/10, Batch 20/97, Loss: 0.4664
Epoch 2/10, Batch 30/97, Loss: 0.2758
Epoch 2/10, Batch 40/97, Loss: 0.3353
Epoch 2/10, Batch 50/97, Loss: 0.3932
Epoch 2/10, Batch 60/97, Loss: 0.3651
Epoch 2/10, Batch 70/97, Loss: 0.3797
Epoch 2/10, Batch 80/97, Loss: 0.3882
Epoch 2/10, Batch 90/97, Loss: 0.3737
Epoch 2/10, Train Loss: 0.4084, Valid Loss: 0.3518
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3989
Epoch 3/10, Batch 20/97, Loss: 0.1544
Epoch 3/10, Batch 30/97, Loss: 0.4416
Epoch 3/10, Batch 40/97, Loss: 0.4155
Epoch 3/10, Batch 50/97, Loss: 0.3960
Epoch 3/10, Batch 60/97, Loss: 0.2551
Epoch 3/10, Batch 70/97, Loss: 0.2484
Epoch 3/10, Batch 80/97, Loss: 0.3311
Epoch 3/10, Batch 90/97, Loss: 0.3075
Epoch 3/10, Train Loss: 0.3318, Valid Loss: 0.3112
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3767
Epoch 4/10, Batch 20/97, Loss: 0.2749
Epoch 4/10, Batch 30/97, Loss: 0.1818
Epoch 4/10, Batch 40/97, Loss: 0.1698
Epoch 4/10, Batch 50/97, Loss: 0.3063
Epoch 4/10, Batch 60/97, Loss: 0.2852
Epoch 4/10, Batch 70/97, Loss: 0.3530
Epoch 4/10, Batch 80/97, Loss: 0.1718
Epoch 4/10, Batch 90/97, Loss: 0.2614
Epoch 4/10, Train Loss: 0.2840, Valid Loss: 0.2961
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2311
Epoch 5/10, Batch 20/97, Loss: 0.3378
Epoch 5/10, Batch 30/97, Loss: 0.1422
Epoch 5/10, Batch 40/97, Loss: 0.2414
Epoch 5/10, Batch 50/97, Loss: 0.2529
Epoch 5/10, Batch 60/97, Loss: 0.1684
Epoch 5/10, Batch 70/97, Loss: 0.2742
Epoch 5/10, Batch 80/97, Loss: 0.1588
Epoch 5/10, Batch 90/97, Loss: 0.1989
Epoch 5/10, Train Loss: 0.2618, Valid Loss: 0.2802
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2002
Epoch 6/10, Batch 20/97, Loss: 0.1443
Epoch 6/10, Batch 30/97, Loss: 0.1818
Epoch 6/10, Batch 40/97, Loss: 0.2639
Epoch 6/10, Batch 50/97, Loss: 0.3048
Epoch 6/10, Batch 60/97, Loss: 0.3401
Epoch 6/10, Batch 70/97, Loss: 0.3103
Epoch 6/10, Batch 80/97, Loss: 0.4218
Epoch 6/10, Batch 90/97, Loss: 0.2177
Epoch 6/10, Train Loss: 0.2433, Valid Loss: 0.2684
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2216
Epoch 7/10, Batch 20/97, Loss: 0.2423
Epoch 7/10, Batch 30/97, Loss: 0.2496
Epoch 7/10, Batch 40/97, Loss: 0.1564
Epoch 7/10, Batch 50/97, Loss: 0.2972
Epoch 7/10, Batch 60/97, Loss: 0.1554
Epoch 7/10, Batch 70/97, Loss: 0.3249
Epoch 7/10, Batch 80/97, Loss: 0.1482
Epoch 7/10, Batch 90/97, Loss: 0.2145
Epoch 7/10, Train Loss: 0.2278, Valid Loss: 0.2611
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.0915
Epoch 8/10, Batch 20/97, Loss: 0.2068
Epoch 8/10, Batch 30/97, Loss: 0.0805
Epoch 8/10, Batch 40/97, Loss: 0.1523
Epoch 8/10, Batch 50/97, Loss: 0.2337
Epoch 8/10, Batch 60/97, Loss: 0.1506
Epoch 8/10, Batch 70/97, Loss: 0.2443
Epoch 8/10, Batch 80/97, Loss: 0.1534
Epoch 8/10, Batch 90/97, Loss: 0.1984
Epoch 8/10, Train Loss: 0.2206, Valid Loss: 0.2621
Epoch 9/10, Batch 10/97, Loss: 0.1476
Epoch 9/10, Batch 20/97, Loss: 0.1506
Epoch 9/10, Batch 30/97, Loss: 0.2674
Epoch 9/10, Batch 40/97, Loss: 0.3007
Epoch 9/10, Batch 50/97, Loss: 0.1457
Epoch 9/10, Batch 60/97, Loss: 0.1626
Epoch 9/10, Batch 70/97, Loss: 0.1577
Epoch 9/10, Batch 80/97, Loss: 0.1398
Epoch 9/10, Batch 90/97, Loss: 0.1707
Epoch 9/10, Train Loss: 0.1989, Valid Loss: 0.2572
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1340
Epoch 10/10, Batch 20/97, Loss: 0.2015
Epoch 10/10, Batch 30/97, Loss: 0.2003
Epoch 10/10, Batch 40/97, Loss: 0.1206
Epoch 10/10, Batch 50/97, Loss: 0.2302
Epoch 10/10, Batch 60/97, Loss: 0.1556
Epoch 10/10, Batch 70/97, Loss: 0.1112
Epoch 10/10, Batch 80/97, Loss: 0.2057
Epoch 10/10, Batch 90/97, Loss: 0.1608
Epoch 10/10, Train Loss: 0.1941, Valid Loss: 0.2547
Model saved!
Accuracy: 0.9159
Precision: 0.9125
Recall: 0.9159
F1-score: 0.9132
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2738
Epoch 1/10, Batch 20/97, Loss: 1.0783
Epoch 1/10, Batch 30/97, Loss: 0.7950
Epoch 1/10, Batch 40/97, Loss: 0.8707
Epoch 1/10, Batch 50/97, Loss: 0.6884
Epoch 1/10, Batch 60/97, Loss: 0.8063
Epoch 1/10, Batch 70/97, Loss: 0.6136
Epoch 1/10, Batch 80/97, Loss: 0.6005
Epoch 1/10, Batch 90/97, Loss: 0.5626
Epoch 1/10, Train Loss: 0.8084, Valid Loss: 0.4370
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5517
Epoch 2/10, Batch 20/97, Loss: 0.4202
Epoch 2/10, Batch 30/97, Loss: 0.3763
Epoch 2/10, Batch 40/97, Loss: 0.3850
Epoch 2/10, Batch 50/97, Loss: 0.4378
Epoch 2/10, Batch 60/97, Loss: 0.6670
Epoch 2/10, Batch 70/97, Loss: 0.3463
Epoch 2/10, Batch 80/97, Loss: 0.3008
Epoch 2/10, Batch 90/97, Loss: 0.3177
Epoch 2/10, Train Loss: 0.4148, Valid Loss: 0.3368
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3795
Epoch 3/10, Batch 20/97, Loss: 0.3802
Epoch 3/10, Batch 30/97, Loss: 0.3120
Epoch 3/10, Batch 40/97, Loss: 0.2380
Epoch 3/10, Batch 50/97, Loss: 0.5290
Epoch 3/10, Batch 60/97, Loss: 0.4031
Epoch 3/10, Batch 70/97, Loss: 0.2635
Epoch 3/10, Batch 80/97, Loss: 0.2949
Epoch 3/10, Batch 90/97, Loss: 0.2579
Epoch 3/10, Train Loss: 0.3382, Valid Loss: 0.2982
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4053
Epoch 4/10, Batch 20/97, Loss: 0.3061
Epoch 4/10, Batch 30/97, Loss: 0.2903
Epoch 4/10, Batch 40/97, Loss: 0.4253
Epoch 4/10, Batch 50/97, Loss: 0.4101
Epoch 4/10, Batch 60/97, Loss: 0.3003
Epoch 4/10, Batch 70/97, Loss: 0.3395
Epoch 4/10, Batch 80/97, Loss: 0.1915
Epoch 4/10, Batch 90/97, Loss: 0.2065
Epoch 4/10, Train Loss: 0.2911, Valid Loss: 0.2776
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2910
Epoch 5/10, Batch 20/97, Loss: 0.3500
Epoch 5/10, Batch 30/97, Loss: 0.3528
Epoch 5/10, Batch 40/97, Loss: 0.2177
Epoch 5/10, Batch 50/97, Loss: 0.3500
Epoch 5/10, Batch 60/97, Loss: 0.3503
Epoch 5/10, Batch 70/97, Loss: 0.2942
Epoch 5/10, Batch 80/97, Loss: 0.2336
Epoch 5/10, Batch 90/97, Loss: 0.3372
Epoch 5/10, Train Loss: 0.2694, Valid Loss: 0.2681
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2728
Epoch 6/10, Batch 20/97, Loss: 0.3176
Epoch 6/10, Batch 30/97, Loss: 0.2125
Epoch 6/10, Batch 40/97, Loss: 0.1570
Epoch 6/10, Batch 50/97, Loss: 0.1626
Epoch 6/10, Batch 60/97, Loss: 0.2382
Epoch 6/10, Batch 70/97, Loss: 0.1902
Epoch 6/10, Batch 80/97, Loss: 0.2601
Epoch 6/10, Batch 90/97, Loss: 0.1816
Epoch 6/10, Train Loss: 0.2492, Valid Loss: 0.2508
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1992
Epoch 7/10, Batch 20/97, Loss: 0.1999
Epoch 7/10, Batch 30/97, Loss: 0.1466
Epoch 7/10, Batch 40/97, Loss: 0.0930
Epoch 7/10, Batch 50/97, Loss: 0.2605
Epoch 7/10, Batch 60/97, Loss: 0.2993
Epoch 7/10, Batch 70/97, Loss: 0.1906
Epoch 7/10, Batch 80/97, Loss: 0.3111
Epoch 7/10, Batch 90/97, Loss: 0.1408
Epoch 7/10, Train Loss: 0.2369, Valid Loss: 0.2397
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1299
Epoch 8/10, Batch 20/97, Loss: 0.1375
Epoch 8/10, Batch 30/97, Loss: 0.1934
Epoch 8/10, Batch 40/97, Loss: 0.1953
Epoch 8/10, Batch 50/97, Loss: 0.1356
Epoch 8/10, Batch 60/97, Loss: 0.2726
Epoch 8/10, Batch 70/97, Loss: 0.4328
Epoch 8/10, Batch 80/97, Loss: 0.2062
Epoch 8/10, Batch 90/97, Loss: 0.2300
Epoch 8/10, Train Loss: 0.2338, Valid Loss: 0.2440
Epoch 9/10, Batch 10/97, Loss: 0.0921
Epoch 9/10, Batch 20/97, Loss: 0.1835
Epoch 9/10, Batch 30/97, Loss: 0.2564
Epoch 9/10, Batch 40/97, Loss: 0.1261
Epoch 9/10, Batch 50/97, Loss: 0.2759
Epoch 9/10, Batch 60/97, Loss: 0.2380
Epoch 9/10, Batch 70/97, Loss: 0.1848
Epoch 9/10, Batch 80/97, Loss: 0.1563
Epoch 9/10, Batch 90/97, Loss: 0.3025
Epoch 9/10, Train Loss: 0.2111, Valid Loss: 0.2370
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2919
Epoch 10/10, Batch 20/97, Loss: 0.1233
Epoch 10/10, Batch 30/97, Loss: 0.1545
Epoch 10/10, Batch 40/97, Loss: 0.1814
Epoch 10/10, Batch 50/97, Loss: 0.1285
Epoch 10/10, Batch 60/97, Loss: 0.1596
Epoch 10/10, Batch 70/97, Loss: 0.2802
Epoch 10/10, Batch 80/97, Loss: 0.1112
Epoch 10/10, Batch 90/97, Loss: 0.0530
Epoch 10/10, Train Loss: 0.2096, Valid Loss: 0.2375
Accuracy: 0.9124
Precision: 0.9101
Recall: 0.9124
F1-score: 0.9107
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2352
Epoch 1/10, Batch 20/97, Loss: 1.0834
Epoch 1/10, Batch 30/97, Loss: 0.8133
Epoch 1/10, Batch 40/97, Loss: 0.8412
Epoch 1/10, Batch 50/97, Loss: 0.7184
Epoch 1/10, Batch 60/97, Loss: 0.6882
Epoch 1/10, Batch 70/97, Loss: 0.6886
Epoch 1/10, Batch 80/97, Loss: 0.5604
Epoch 1/10, Batch 90/97, Loss: 0.5580
Epoch 1/10, Train Loss: 0.7976, Valid Loss: 0.4448
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5613
Epoch 2/10, Batch 20/97, Loss: 0.4812
Epoch 2/10, Batch 30/97, Loss: 0.2990
Epoch 2/10, Batch 40/97, Loss: 0.3502
Epoch 2/10, Batch 50/97, Loss: 0.3030
Epoch 2/10, Batch 60/97, Loss: 0.5391
Epoch 2/10, Batch 70/97, Loss: 0.2823
Epoch 2/10, Batch 80/97, Loss: 0.3250
Epoch 2/10, Batch 90/97, Loss: 0.4679
Epoch 2/10, Train Loss: 0.4094, Valid Loss: 0.3385
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3157
Epoch 3/10, Batch 20/97, Loss: 0.2632
Epoch 3/10, Batch 30/97, Loss: 0.4167
Epoch 3/10, Batch 40/97, Loss: 0.2980
Epoch 3/10, Batch 50/97, Loss: 0.2716
Epoch 3/10, Batch 60/97, Loss: 0.2151
Epoch 3/10, Batch 70/97, Loss: 0.3362
Epoch 3/10, Batch 80/97, Loss: 0.2215
Epoch 3/10, Batch 90/97, Loss: 0.3015
Epoch 3/10, Train Loss: 0.3365, Valid Loss: 0.3028
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3005
Epoch 4/10, Batch 20/97, Loss: 0.1860
Epoch 4/10, Batch 30/97, Loss: 0.2615
Epoch 4/10, Batch 40/97, Loss: 0.1445
Epoch 4/10, Batch 50/97, Loss: 0.2987
Epoch 4/10, Batch 60/97, Loss: 0.2368
Epoch 4/10, Batch 70/97, Loss: 0.2871
Epoch 4/10, Batch 80/97, Loss: 0.2491
Epoch 4/10, Batch 90/97, Loss: 0.2698
Epoch 4/10, Train Loss: 0.2897, Valid Loss: 0.2844
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2150
Epoch 5/10, Batch 20/97, Loss: 0.2463
Epoch 5/10, Batch 30/97, Loss: 0.1615
Epoch 5/10, Batch 40/97, Loss: 0.2410
Epoch 5/10, Batch 50/97, Loss: 0.3022
Epoch 5/10, Batch 60/97, Loss: 0.1812
Epoch 5/10, Batch 70/97, Loss: 0.3343
Epoch 5/10, Batch 80/97, Loss: 0.2709
Epoch 5/10, Batch 90/97, Loss: 0.2053
Epoch 5/10, Train Loss: 0.2659, Valid Loss: 0.2706
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2151
Epoch 6/10, Batch 20/97, Loss: 0.2527
Epoch 6/10, Batch 30/97, Loss: 0.1944
Epoch 6/10, Batch 40/97, Loss: 0.1309
Epoch 6/10, Batch 50/97, Loss: 0.2327
Epoch 6/10, Batch 60/97, Loss: 0.1872
Epoch 6/10, Batch 70/97, Loss: 0.1623
Epoch 6/10, Batch 80/97, Loss: 0.3070
Epoch 6/10, Batch 90/97, Loss: 0.4175
Epoch 6/10, Train Loss: 0.2513, Valid Loss: 0.2606
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.0949
Epoch 7/10, Batch 20/97, Loss: 0.1805
Epoch 7/10, Batch 30/97, Loss: 0.1603
Epoch 7/10, Batch 40/97, Loss: 0.2750
Epoch 7/10, Batch 50/97, Loss: 0.1480
Epoch 7/10, Batch 60/97, Loss: 0.2807
Epoch 7/10, Batch 70/97, Loss: 0.2397
Epoch 7/10, Batch 80/97, Loss: 0.2059
Epoch 7/10, Batch 90/97, Loss: 0.2203
Epoch 7/10, Train Loss: 0.2252, Valid Loss: 0.2566
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.0602
Epoch 8/10, Batch 20/97, Loss: 0.2188
Epoch 8/10, Batch 30/97, Loss: 0.1559
Epoch 8/10, Batch 40/97, Loss: 0.3250
Epoch 8/10, Batch 50/97, Loss: 0.5143
Epoch 8/10, Batch 60/97, Loss: 0.1315
Epoch 8/10, Batch 70/97, Loss: 0.2522
Epoch 8/10, Batch 80/97, Loss: 0.1306
Epoch 8/10, Batch 90/97, Loss: 0.2026
Epoch 8/10, Train Loss: 0.2155, Valid Loss: 0.2515
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1643
Epoch 9/10, Batch 20/97, Loss: 0.2118
Epoch 9/10, Batch 30/97, Loss: 0.2253
Epoch 9/10, Batch 40/97, Loss: 0.2222
Epoch 9/10, Batch 50/97, Loss: 0.1569
Epoch 9/10, Batch 60/97, Loss: 0.2438
Epoch 9/10, Batch 70/97, Loss: 0.1925
Epoch 9/10, Batch 80/97, Loss: 0.1128
Epoch 9/10, Batch 90/97, Loss: 0.1445
Epoch 9/10, Train Loss: 0.2145, Valid Loss: 0.2499
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3705
Epoch 10/10, Batch 20/97, Loss: 0.1440
Epoch 10/10, Batch 30/97, Loss: 0.1736
Epoch 10/10, Batch 40/97, Loss: 0.1843
Epoch 10/10, Batch 50/97, Loss: 0.2876
Epoch 10/10, Batch 60/97, Loss: 0.2877
Epoch 10/10, Batch 70/97, Loss: 0.2564
Epoch 10/10, Batch 80/97, Loss: 0.2499
Epoch 10/10, Batch 90/97, Loss: 0.2910
Epoch 10/10, Train Loss: 0.2059, Valid Loss: 0.2550
Accuracy: 0.9159
Precision: 0.9145
Recall: 0.9159
F1-score: 0.9146
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2275
Epoch 1/10, Batch 20/97, Loss: 1.0423
Epoch 1/10, Batch 30/97, Loss: 0.8293
Epoch 1/10, Batch 40/97, Loss: 0.7164
Epoch 1/10, Batch 50/97, Loss: 0.5846
Epoch 1/10, Batch 60/97, Loss: 0.7512
Epoch 1/10, Batch 70/97, Loss: 0.5234
Epoch 1/10, Batch 80/97, Loss: 0.4976
Epoch 1/10, Batch 90/97, Loss: 0.5729
Epoch 1/10, Train Loss: 0.7803, Valid Loss: 0.4659
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4107
Epoch 2/10, Batch 20/97, Loss: 0.3629
Epoch 2/10, Batch 30/97, Loss: 0.3820
Epoch 2/10, Batch 40/97, Loss: 0.4223
Epoch 2/10, Batch 50/97, Loss: 0.3452
Epoch 2/10, Batch 60/97, Loss: 0.4061
Epoch 2/10, Batch 70/97, Loss: 0.2922
Epoch 2/10, Batch 80/97, Loss: 0.4102
Epoch 2/10, Batch 90/97, Loss: 0.3507
Epoch 2/10, Train Loss: 0.3980, Valid Loss: 0.3712
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3316
Epoch 3/10, Batch 20/97, Loss: 0.1939
Epoch 3/10, Batch 30/97, Loss: 0.3727
Epoch 3/10, Batch 40/97, Loss: 0.1925
Epoch 3/10, Batch 50/97, Loss: 0.4374
Epoch 3/10, Batch 60/97, Loss: 0.2364
Epoch 3/10, Batch 70/97, Loss: 0.3254
Epoch 3/10, Batch 80/97, Loss: 0.2642
Epoch 3/10, Batch 90/97, Loss: 0.3671
Epoch 3/10, Train Loss: 0.3152, Valid Loss: 0.3334
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.5648
Epoch 4/10, Batch 20/97, Loss: 0.3707
Epoch 4/10, Batch 30/97, Loss: 0.2431
Epoch 4/10, Batch 40/97, Loss: 0.5182
Epoch 4/10, Batch 50/97, Loss: 0.3808
Epoch 4/10, Batch 60/97, Loss: 0.3982
Epoch 4/10, Batch 70/97, Loss: 0.3848
Epoch 4/10, Batch 80/97, Loss: 0.2410
Epoch 4/10, Batch 90/97, Loss: 0.3313
Epoch 4/10, Train Loss: 0.2782, Valid Loss: 0.3242
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2818
Epoch 5/10, Batch 20/97, Loss: 0.2308
Epoch 5/10, Batch 30/97, Loss: 0.1760
Epoch 5/10, Batch 40/97, Loss: 0.3840
Epoch 5/10, Batch 50/97, Loss: 0.1796
Epoch 5/10, Batch 60/97, Loss: 0.1422
Epoch 5/10, Batch 70/97, Loss: 0.2503
Epoch 5/10, Batch 80/97, Loss: 0.2319
Epoch 5/10, Batch 90/97, Loss: 0.1463
Epoch 5/10, Train Loss: 0.2526, Valid Loss: 0.3082
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3426
Epoch 6/10, Batch 20/97, Loss: 0.2209
Epoch 6/10, Batch 30/97, Loss: 0.2466
Epoch 6/10, Batch 40/97, Loss: 0.1341
Epoch 6/10, Batch 50/97, Loss: 0.2480
Epoch 6/10, Batch 60/97, Loss: 0.4006
Epoch 6/10, Batch 70/97, Loss: 0.2722
Epoch 6/10, Batch 80/97, Loss: 0.1918
Epoch 6/10, Batch 90/97, Loss: 0.2078
Epoch 6/10, Train Loss: 0.2321, Valid Loss: 0.2894
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1487
Epoch 7/10, Batch 20/97, Loss: 0.3171
Epoch 7/10, Batch 30/97, Loss: 0.1634
Epoch 7/10, Batch 40/97, Loss: 0.2406
Epoch 7/10, Batch 50/97, Loss: 0.2125
Epoch 7/10, Batch 60/97, Loss: 0.1417
Epoch 7/10, Batch 70/97, Loss: 0.1753
Epoch 7/10, Batch 80/97, Loss: 0.3189
Epoch 7/10, Batch 90/97, Loss: 0.1381
Epoch 7/10, Train Loss: 0.2144, Valid Loss: 0.2842
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1530
Epoch 8/10, Batch 20/97, Loss: 0.2538
Epoch 8/10, Batch 30/97, Loss: 0.2039
Epoch 8/10, Batch 40/97, Loss: 0.1811
Epoch 8/10, Batch 50/97, Loss: 0.2437
Epoch 8/10, Batch 60/97, Loss: 0.1981
Epoch 8/10, Batch 70/97, Loss: 0.1790
Epoch 8/10, Batch 80/97, Loss: 0.2520
Epoch 8/10, Batch 90/97, Loss: 0.2443
Epoch 8/10, Train Loss: 0.2105, Valid Loss: 0.2843
Epoch 9/10, Batch 10/97, Loss: 0.2279
Epoch 9/10, Batch 20/97, Loss: 0.3257
Epoch 9/10, Batch 30/97, Loss: 0.1231
Epoch 9/10, Batch 40/97, Loss: 0.2242
Epoch 9/10, Batch 50/97, Loss: 0.1305
Epoch 9/10, Batch 60/97, Loss: 0.1405
Epoch 9/10, Batch 70/97, Loss: 0.0866
Epoch 9/10, Batch 80/97, Loss: 0.1625
Epoch 9/10, Batch 90/97, Loss: 0.2296
Epoch 9/10, Train Loss: 0.1963, Valid Loss: 0.2749
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1698
Epoch 10/10, Batch 20/97, Loss: 0.1773
Epoch 10/10, Batch 30/97, Loss: 0.1130
Epoch 10/10, Batch 40/97, Loss: 0.2468
Epoch 10/10, Batch 50/97, Loss: 0.2070
Epoch 10/10, Batch 60/97, Loss: 0.1190
Epoch 10/10, Batch 70/97, Loss: 0.1614
Epoch 10/10, Batch 80/97, Loss: 0.1601
Epoch 10/10, Batch 90/97, Loss: 0.2828
Epoch 10/10, Train Loss: 0.1886, Valid Loss: 0.2738
Model saved!
Accuracy: 0.9112
Precision: 0.9081
Recall: 0.9112
F1-score: 0.9082
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2872
Epoch 1/10, Batch 20/97, Loss: 1.0651
Epoch 1/10, Batch 30/97, Loss: 0.7633
Epoch 1/10, Batch 40/97, Loss: 0.7337
Epoch 1/10, Batch 50/97, Loss: 0.5966
Epoch 1/10, Batch 60/97, Loss: 0.7627
Epoch 1/10, Batch 70/97, Loss: 0.6992
Epoch 1/10, Batch 80/97, Loss: 0.5712
Epoch 1/10, Batch 90/97, Loss: 0.5577
Epoch 1/10, Train Loss: 0.8035, Valid Loss: 0.4675
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5320
Epoch 2/10, Batch 20/97, Loss: 0.4450
Epoch 2/10, Batch 30/97, Loss: 0.2414
Epoch 2/10, Batch 40/97, Loss: 0.3731
Epoch 2/10, Batch 50/97, Loss: 0.3499
Epoch 2/10, Batch 60/97, Loss: 0.3624
Epoch 2/10, Batch 70/97, Loss: 0.4927
Epoch 2/10, Batch 80/97, Loss: 0.2877
Epoch 2/10, Batch 90/97, Loss: 0.3520
Epoch 2/10, Train Loss: 0.4126, Valid Loss: 0.3518
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3777
Epoch 3/10, Batch 20/97, Loss: 0.2897
Epoch 3/10, Batch 30/97, Loss: 0.3126
Epoch 3/10, Batch 40/97, Loss: 0.2840
Epoch 3/10, Batch 50/97, Loss: 0.4884
Epoch 3/10, Batch 60/97, Loss: 0.2851
Epoch 3/10, Batch 70/97, Loss: 0.4156
Epoch 3/10, Batch 80/97, Loss: 0.3062
Epoch 3/10, Batch 90/97, Loss: 0.3012
Epoch 3/10, Train Loss: 0.3352, Valid Loss: 0.2999
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3745
Epoch 4/10, Batch 20/97, Loss: 0.1900
Epoch 4/10, Batch 30/97, Loss: 0.3066
Epoch 4/10, Batch 40/97, Loss: 0.2215
Epoch 4/10, Batch 50/97, Loss: 0.2308
Epoch 4/10, Batch 60/97, Loss: 0.2184
Epoch 4/10, Batch 70/97, Loss: 0.1849
Epoch 4/10, Batch 80/97, Loss: 0.2664
Epoch 4/10, Batch 90/97, Loss: 0.2380
Epoch 4/10, Train Loss: 0.2793, Valid Loss: 0.2833
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2369
Epoch 5/10, Batch 20/97, Loss: 0.2833
Epoch 5/10, Batch 30/97, Loss: 0.3282
Epoch 5/10, Batch 40/97, Loss: 0.2336
Epoch 5/10, Batch 50/97, Loss: 0.2670
Epoch 5/10, Batch 60/97, Loss: 0.3739
Epoch 5/10, Batch 70/97, Loss: 0.1560
Epoch 5/10, Batch 80/97, Loss: 0.2413
Epoch 5/10, Batch 90/97, Loss: 0.2594
Epoch 5/10, Train Loss: 0.2632, Valid Loss: 0.2699
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2180
Epoch 6/10, Batch 20/97, Loss: 0.3092
Epoch 6/10, Batch 30/97, Loss: 0.1310
Epoch 6/10, Batch 40/97, Loss: 0.1916
Epoch 6/10, Batch 50/97, Loss: 0.1576
Epoch 6/10, Batch 60/97, Loss: 0.2240
Epoch 6/10, Batch 70/97, Loss: 0.2096
Epoch 6/10, Batch 80/97, Loss: 0.3827
Epoch 6/10, Batch 90/97, Loss: 0.1553
Epoch 6/10, Train Loss: 0.2429, Valid Loss: 0.2572
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2409
Epoch 7/10, Batch 20/97, Loss: 0.3414
Epoch 7/10, Batch 30/97, Loss: 0.2132
Epoch 7/10, Batch 40/97, Loss: 0.1288
Epoch 7/10, Batch 50/97, Loss: 0.2109
Epoch 7/10, Batch 60/97, Loss: 0.1083
Epoch 7/10, Batch 70/97, Loss: 0.3010
Epoch 7/10, Batch 80/97, Loss: 0.1394
Epoch 7/10, Batch 90/97, Loss: 0.1080
Epoch 7/10, Train Loss: 0.2177, Valid Loss: 0.2453
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.0850
Epoch 8/10, Batch 20/97, Loss: 0.2753
Epoch 8/10, Batch 30/97, Loss: 0.1444
Epoch 8/10, Batch 40/97, Loss: 0.1505
Epoch 8/10, Batch 50/97, Loss: 0.2554
Epoch 8/10, Batch 60/97, Loss: 0.2489
Epoch 8/10, Batch 70/97, Loss: 0.2748
Epoch 8/10, Batch 80/97, Loss: 0.2253
Epoch 8/10, Batch 90/97, Loss: 0.3833
Epoch 8/10, Train Loss: 0.2149, Valid Loss: 0.2444
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1517
Epoch 9/10, Batch 20/97, Loss: 0.1482
Epoch 9/10, Batch 30/97, Loss: 0.1868
Epoch 9/10, Batch 40/97, Loss: 0.1775
Epoch 9/10, Batch 50/97, Loss: 0.1369
Epoch 9/10, Batch 60/97, Loss: 0.1768
Epoch 9/10, Batch 70/97, Loss: 0.1274
Epoch 9/10, Batch 80/97, Loss: 0.2347
Epoch 9/10, Batch 90/97, Loss: 0.2339
Epoch 9/10, Train Loss: 0.1978, Valid Loss: 0.2394
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1551
Epoch 10/10, Batch 20/97, Loss: 0.1147
Epoch 10/10, Batch 30/97, Loss: 0.1473
Epoch 10/10, Batch 40/97, Loss: 0.2163
Epoch 10/10, Batch 50/97, Loss: 0.2834
Epoch 10/10, Batch 60/97, Loss: 0.1620
Epoch 10/10, Batch 70/97, Loss: 0.2128
Epoch 10/10, Batch 80/97, Loss: 0.1309
Epoch 10/10, Batch 90/97, Loss: 0.2805
Epoch 10/10, Train Loss: 0.1969, Valid Loss: 0.2413
Accuracy: 0.9100
Precision: 0.9073
Recall: 0.9100
F1-score: 0.9077
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2105
Epoch 1/10, Batch 20/97, Loss: 1.0466
Epoch 1/10, Batch 30/97, Loss: 0.7685
Epoch 1/10, Batch 40/97, Loss: 0.6481
Epoch 1/10, Batch 50/97, Loss: 0.6605
Epoch 1/10, Batch 60/97, Loss: 0.6464
Epoch 1/10, Batch 70/97, Loss: 0.6045
Epoch 1/10, Batch 80/97, Loss: 0.5969
Epoch 1/10, Batch 90/97, Loss: 0.4518
Epoch 1/10, Train Loss: 0.8051, Valid Loss: 0.4590
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5352
Epoch 2/10, Batch 20/97, Loss: 0.3947
Epoch 2/10, Batch 30/97, Loss: 0.2867
Epoch 2/10, Batch 40/97, Loss: 0.3300
Epoch 2/10, Batch 50/97, Loss: 0.6166
Epoch 2/10, Batch 60/97, Loss: 0.4540
Epoch 2/10, Batch 70/97, Loss: 0.4231
Epoch 2/10, Batch 80/97, Loss: 0.4078
Epoch 2/10, Batch 90/97, Loss: 0.4668
Epoch 2/10, Train Loss: 0.4187, Valid Loss: 0.3512
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3773
Epoch 3/10, Batch 20/97, Loss: 0.2631
Epoch 3/10, Batch 30/97, Loss: 0.3138
Epoch 3/10, Batch 40/97, Loss: 0.3091
Epoch 3/10, Batch 50/97, Loss: 0.3065
Epoch 3/10, Batch 60/97, Loss: 0.3095
Epoch 3/10, Batch 70/97, Loss: 0.3289
Epoch 3/10, Batch 80/97, Loss: 0.2365
Epoch 3/10, Batch 90/97, Loss: 0.2782
Epoch 3/10, Train Loss: 0.3394, Valid Loss: 0.3030
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2648
Epoch 4/10, Batch 20/97, Loss: 0.3546
Epoch 4/10, Batch 30/97, Loss: 0.3117
Epoch 4/10, Batch 40/97, Loss: 0.2627
Epoch 4/10, Batch 50/97, Loss: 0.3356
Epoch 4/10, Batch 60/97, Loss: 0.1689
Epoch 4/10, Batch 70/97, Loss: 0.2017
Epoch 4/10, Batch 80/97, Loss: 0.2854
Epoch 4/10, Batch 90/97, Loss: 0.1690
Epoch 4/10, Train Loss: 0.2921, Valid Loss: 0.2885
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1234
Epoch 5/10, Batch 20/97, Loss: 0.2577
Epoch 5/10, Batch 30/97, Loss: 0.2504
Epoch 5/10, Batch 40/97, Loss: 0.3100
Epoch 5/10, Batch 50/97, Loss: 0.1511
Epoch 5/10, Batch 60/97, Loss: 0.2163
Epoch 5/10, Batch 70/97, Loss: 0.1293
Epoch 5/10, Batch 80/97, Loss: 0.2528
Epoch 5/10, Batch 90/97, Loss: 0.2802
Epoch 5/10, Train Loss: 0.2677, Valid Loss: 0.2781
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3346
Epoch 6/10, Batch 20/97, Loss: 0.2411
Epoch 6/10, Batch 30/97, Loss: 0.2352
Epoch 6/10, Batch 40/97, Loss: 0.1416
Epoch 6/10, Batch 50/97, Loss: 0.3703
Epoch 6/10, Batch 60/97, Loss: 0.3824
Epoch 6/10, Batch 70/97, Loss: 0.2544
Epoch 6/10, Batch 80/97, Loss: 0.3270
Epoch 6/10, Batch 90/97, Loss: 0.3002
Epoch 6/10, Train Loss: 0.2492, Valid Loss: 0.2622
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2036
Epoch 7/10, Batch 20/97, Loss: 0.2695
Epoch 7/10, Batch 30/97, Loss: 0.2375
Epoch 7/10, Batch 40/97, Loss: 0.1680
Epoch 7/10, Batch 50/97, Loss: 0.1910
Epoch 7/10, Batch 60/97, Loss: 0.1855
Epoch 7/10, Batch 70/97, Loss: 0.2568
Epoch 7/10, Batch 80/97, Loss: 0.1631
Epoch 7/10, Batch 90/97, Loss: 0.2193
Epoch 7/10, Train Loss: 0.2290, Valid Loss: 0.2580
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2014
Epoch 8/10, Batch 20/97, Loss: 0.2352
Epoch 8/10, Batch 30/97, Loss: 0.1246
Epoch 8/10, Batch 40/97, Loss: 0.2581
Epoch 8/10, Batch 50/97, Loss: 0.2580
Epoch 8/10, Batch 60/97, Loss: 0.1102
Epoch 8/10, Batch 70/97, Loss: 0.2853
Epoch 8/10, Batch 80/97, Loss: 0.2637
Epoch 8/10, Batch 90/97, Loss: 0.2343
Epoch 8/10, Train Loss: 0.2257, Valid Loss: 0.2622
Epoch 9/10, Batch 10/97, Loss: 0.2333
Epoch 9/10, Batch 20/97, Loss: 0.1674
Epoch 9/10, Batch 30/97, Loss: 0.2642
Epoch 9/10, Batch 40/97, Loss: 0.1893
Epoch 9/10, Batch 50/97, Loss: 0.2016
Epoch 9/10, Batch 60/97, Loss: 0.3000
Epoch 9/10, Batch 70/97, Loss: 0.2520
Epoch 9/10, Batch 80/97, Loss: 0.1034
Epoch 9/10, Batch 90/97, Loss: 0.1776
Epoch 9/10, Train Loss: 0.2095, Valid Loss: 0.2500
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1237
Epoch 10/10, Batch 20/97, Loss: 0.0987
Epoch 10/10, Batch 30/97, Loss: 0.2028
Epoch 10/10, Batch 40/97, Loss: 0.0968
Epoch 10/10, Batch 50/97, Loss: 0.5655
Epoch 10/10, Batch 60/97, Loss: 0.1008
Epoch 10/10, Batch 70/97, Loss: 0.1898
Epoch 10/10, Batch 80/97, Loss: 0.1144
Epoch 10/10, Batch 90/97, Loss: 0.2605
Epoch 10/10, Train Loss: 0.2096, Valid Loss: 0.2508
Accuracy: 0.9171
Precision: 0.9141
Recall: 0.9171
F1-score: 0.9147
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2529
Epoch 1/10, Batch 20/97, Loss: 1.1271
Epoch 1/10, Batch 30/97, Loss: 0.8331
Epoch 1/10, Batch 40/97, Loss: 0.6811
Epoch 1/10, Batch 50/97, Loss: 0.5931
Epoch 1/10, Batch 60/97, Loss: 0.6766
Epoch 1/10, Batch 70/97, Loss: 0.6090
Epoch 1/10, Batch 80/97, Loss: 0.7767
Epoch 1/10, Batch 90/97, Loss: 0.5096
Epoch 1/10, Train Loss: 0.8118, Valid Loss: 0.4381
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5554
Epoch 2/10, Batch 20/97, Loss: 0.4393
Epoch 2/10, Batch 30/97, Loss: 0.4219
Epoch 2/10, Batch 40/97, Loss: 0.3950
Epoch 2/10, Batch 50/97, Loss: 0.3289
Epoch 2/10, Batch 60/97, Loss: 0.6005
Epoch 2/10, Batch 70/97, Loss: 0.3698
Epoch 2/10, Batch 80/97, Loss: 0.2475
Epoch 2/10, Batch 90/97, Loss: 0.4208
Epoch 2/10, Train Loss: 0.4179, Valid Loss: 0.3253
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4111
Epoch 3/10, Batch 20/97, Loss: 0.2581
Epoch 3/10, Batch 30/97, Loss: 0.4726
Epoch 3/10, Batch 40/97, Loss: 0.2165
Epoch 3/10, Batch 50/97, Loss: 0.4079
Epoch 3/10, Batch 60/97, Loss: 0.1861
Epoch 3/10, Batch 70/97, Loss: 0.2927
Epoch 3/10, Batch 80/97, Loss: 0.4186
Epoch 3/10, Batch 90/97, Loss: 0.3707
Epoch 3/10, Train Loss: 0.3393, Valid Loss: 0.2847
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3026
Epoch 4/10, Batch 20/97, Loss: 0.2767
Epoch 4/10, Batch 30/97, Loss: 0.2429
Epoch 4/10, Batch 40/97, Loss: 0.3648
Epoch 4/10, Batch 50/97, Loss: 0.4570
Epoch 4/10, Batch 60/97, Loss: 0.3390
Epoch 4/10, Batch 70/97, Loss: 0.3581
Epoch 4/10, Batch 80/97, Loss: 0.2724
Epoch 4/10, Batch 90/97, Loss: 0.2312
Epoch 4/10, Train Loss: 0.2959, Valid Loss: 0.2631
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3820
Epoch 5/10, Batch 20/97, Loss: 0.2779
Epoch 5/10, Batch 30/97, Loss: 0.2778
Epoch 5/10, Batch 40/97, Loss: 0.1862
Epoch 5/10, Batch 50/97, Loss: 0.2109
Epoch 5/10, Batch 60/97, Loss: 0.3275
Epoch 5/10, Batch 70/97, Loss: 0.3520
Epoch 5/10, Batch 80/97, Loss: 0.1973
Epoch 5/10, Batch 90/97, Loss: 0.3236
Epoch 5/10, Train Loss: 0.2636, Valid Loss: 0.2463
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2684
Epoch 6/10, Batch 20/97, Loss: 0.3766
Epoch 6/10, Batch 30/97, Loss: 0.1812
Epoch 6/10, Batch 40/97, Loss: 0.2189
Epoch 6/10, Batch 50/97, Loss: 0.3091
Epoch 6/10, Batch 60/97, Loss: 0.3292
Epoch 6/10, Batch 70/97, Loss: 0.3081
Epoch 6/10, Batch 80/97, Loss: 0.4902
Epoch 6/10, Batch 90/97, Loss: 0.2096
Epoch 6/10, Train Loss: 0.2538, Valid Loss: 0.2315
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2010
Epoch 7/10, Batch 20/97, Loss: 0.2444
Epoch 7/10, Batch 30/97, Loss: 0.2833
Epoch 7/10, Batch 40/97, Loss: 0.1083
Epoch 7/10, Batch 50/97, Loss: 0.3114
Epoch 7/10, Batch 60/97, Loss: 0.1503
Epoch 7/10, Batch 70/97, Loss: 0.3257
Epoch 7/10, Batch 80/97, Loss: 0.1880
Epoch 7/10, Batch 90/97, Loss: 0.1217
Epoch 7/10, Train Loss: 0.2346, Valid Loss: 0.2271
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1963
Epoch 8/10, Batch 20/97, Loss: 0.1812
Epoch 8/10, Batch 30/97, Loss: 0.1424
Epoch 8/10, Batch 40/97, Loss: 0.1642
Epoch 8/10, Batch 50/97, Loss: 0.2012
Epoch 8/10, Batch 60/97, Loss: 0.3291
Epoch 8/10, Batch 70/97, Loss: 0.1827
Epoch 8/10, Batch 80/97, Loss: 0.1459
Epoch 8/10, Batch 90/97, Loss: 0.2202
Epoch 8/10, Train Loss: 0.2252, Valid Loss: 0.2208
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1017
Epoch 9/10, Batch 20/97, Loss: 0.1234
Epoch 9/10, Batch 30/97, Loss: 0.2446
Epoch 9/10, Batch 40/97, Loss: 0.2308
Epoch 9/10, Batch 50/97, Loss: 0.2626
Epoch 9/10, Batch 60/97, Loss: 0.2404
Epoch 9/10, Batch 70/97, Loss: 0.1619
Epoch 9/10, Batch 80/97, Loss: 0.1397
Epoch 9/10, Batch 90/97, Loss: 0.2205
Epoch 9/10, Train Loss: 0.2161, Valid Loss: 0.2222
Epoch 10/10, Batch 10/97, Loss: 0.2057
Epoch 10/10, Batch 20/97, Loss: 0.1566
Epoch 10/10, Batch 30/97, Loss: 0.1725
Epoch 10/10, Batch 40/97, Loss: 0.2464
Epoch 10/10, Batch 50/97, Loss: 0.1397
Epoch 10/10, Batch 60/97, Loss: 0.1506
Epoch 10/10, Batch 70/97, Loss: 0.3110
Epoch 10/10, Batch 80/97, Loss: 0.3103
Epoch 10/10, Batch 90/97, Loss: 0.0867
Epoch 10/10, Train Loss: 0.2074, Valid Loss: 0.2232
Accuracy: 0.9147
Precision: 0.9119
Recall: 0.9147
F1-score: 0.9127
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2722
Epoch 1/10, Batch 20/97, Loss: 1.0610
Epoch 1/10, Batch 30/97, Loss: 0.7370
Epoch 1/10, Batch 40/97, Loss: 0.8041
Epoch 1/10, Batch 50/97, Loss: 0.6119
Epoch 1/10, Batch 60/97, Loss: 0.6626
Epoch 1/10, Batch 70/97, Loss: 0.6963
Epoch 1/10, Batch 80/97, Loss: 0.6381
Epoch 1/10, Batch 90/97, Loss: 0.5263
Epoch 1/10, Train Loss: 0.8045, Valid Loss: 0.4633
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5494
Epoch 2/10, Batch 20/97, Loss: 0.6009
Epoch 2/10, Batch 30/97, Loss: 0.4061
Epoch 2/10, Batch 40/97, Loss: 0.3947
Epoch 2/10, Batch 50/97, Loss: 0.3603
Epoch 2/10, Batch 60/97, Loss: 0.3866
Epoch 2/10, Batch 70/97, Loss: 0.3327
Epoch 2/10, Batch 80/97, Loss: 0.3130
Epoch 2/10, Batch 90/97, Loss: 0.6010
Epoch 2/10, Train Loss: 0.4122, Valid Loss: 0.3473
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3951
Epoch 3/10, Batch 20/97, Loss: 0.2336
Epoch 3/10, Batch 30/97, Loss: 0.4029
Epoch 3/10, Batch 40/97, Loss: 0.4155
Epoch 3/10, Batch 50/97, Loss: 0.2918
Epoch 3/10, Batch 60/97, Loss: 0.2265
Epoch 3/10, Batch 70/97, Loss: 0.3614
Epoch 3/10, Batch 80/97, Loss: 0.2451
Epoch 3/10, Batch 90/97, Loss: 0.3401
Epoch 3/10, Train Loss: 0.3349, Valid Loss: 0.3038
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4191
Epoch 4/10, Batch 20/97, Loss: 0.1673
Epoch 4/10, Batch 30/97, Loss: 0.2851
Epoch 4/10, Batch 40/97, Loss: 0.3803
Epoch 4/10, Batch 50/97, Loss: 0.4020
Epoch 4/10, Batch 60/97, Loss: 0.1873
Epoch 4/10, Batch 70/97, Loss: 0.3095
Epoch 4/10, Batch 80/97, Loss: 0.2628
Epoch 4/10, Batch 90/97, Loss: 0.1817
Epoch 4/10, Train Loss: 0.2925, Valid Loss: 0.2832
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3585
Epoch 5/10, Batch 20/97, Loss: 0.3468
Epoch 5/10, Batch 30/97, Loss: 0.2071
Epoch 5/10, Batch 40/97, Loss: 0.2146
Epoch 5/10, Batch 50/97, Loss: 0.2076
Epoch 5/10, Batch 60/97, Loss: 0.2425
Epoch 5/10, Batch 70/97, Loss: 0.2633
Epoch 5/10, Batch 80/97, Loss: 0.1235
Epoch 5/10, Batch 90/97, Loss: 0.2775
Epoch 5/10, Train Loss: 0.2677, Valid Loss: 0.2751
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1376
Epoch 6/10, Batch 20/97, Loss: 0.4383
Epoch 6/10, Batch 30/97, Loss: 0.3536
Epoch 6/10, Batch 40/97, Loss: 0.2134
Epoch 6/10, Batch 50/97, Loss: 0.2243
Epoch 6/10, Batch 60/97, Loss: 0.2135
Epoch 6/10, Batch 70/97, Loss: 0.1985
Epoch 6/10, Batch 80/97, Loss: 0.3137
Epoch 6/10, Batch 90/97, Loss: 0.3356
Epoch 6/10, Train Loss: 0.2499, Valid Loss: 0.2500
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1211
Epoch 7/10, Batch 20/97, Loss: 0.2439
Epoch 7/10, Batch 30/97, Loss: 0.2060
Epoch 7/10, Batch 40/97, Loss: 0.2103
Epoch 7/10, Batch 50/97, Loss: 0.1547
Epoch 7/10, Batch 60/97, Loss: 0.1813
Epoch 7/10, Batch 70/97, Loss: 0.2079
Epoch 7/10, Batch 80/97, Loss: 0.3091
Epoch 7/10, Batch 90/97, Loss: 0.2179
Epoch 7/10, Train Loss: 0.2344, Valid Loss: 0.2422
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2727
Epoch 8/10, Batch 20/97, Loss: 0.2220
Epoch 8/10, Batch 30/97, Loss: 0.1322
Epoch 8/10, Batch 40/97, Loss: 0.1851
Epoch 8/10, Batch 50/97, Loss: 0.1463
Epoch 8/10, Batch 60/97, Loss: 0.1877
Epoch 8/10, Batch 70/97, Loss: 0.3340
Epoch 8/10, Batch 80/97, Loss: 0.1686
Epoch 8/10, Batch 90/97, Loss: 0.2919
Epoch 8/10, Train Loss: 0.2282, Valid Loss: 0.2383
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0883
Epoch 9/10, Batch 20/97, Loss: 0.1137
Epoch 9/10, Batch 30/97, Loss: 0.2472
Epoch 9/10, Batch 40/97, Loss: 0.3120
Epoch 9/10, Batch 50/97, Loss: 0.1096
Epoch 9/10, Batch 60/97, Loss: 0.2228
Epoch 9/10, Batch 70/97, Loss: 0.2408
Epoch 9/10, Batch 80/97, Loss: 0.1316
Epoch 9/10, Batch 90/97, Loss: 0.1498
Epoch 9/10, Train Loss: 0.2131, Valid Loss: 0.2380
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1545
Epoch 10/10, Batch 20/97, Loss: 0.2471
Epoch 10/10, Batch 30/97, Loss: 0.1444
Epoch 10/10, Batch 40/97, Loss: 0.1822
Epoch 10/10, Batch 50/97, Loss: 0.1086
Epoch 10/10, Batch 60/97, Loss: 0.1231
Epoch 10/10, Batch 70/97, Loss: 0.1398
Epoch 10/10, Batch 80/97, Loss: 0.2113
Epoch 10/10, Batch 90/97, Loss: 0.2685
Epoch 10/10, Train Loss: 0.2041, Valid Loss: 0.2397
Accuracy: 0.9077
Precision: 0.9050
Recall: 0.9077
F1-score: 0.9042
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2890
Epoch 1/10, Batch 20/97, Loss: 1.0820
Epoch 1/10, Batch 30/97, Loss: 0.8281
Epoch 1/10, Batch 40/97, Loss: 0.6617
Epoch 1/10, Batch 50/97, Loss: 0.6199
Epoch 1/10, Batch 60/97, Loss: 0.8278
Epoch 1/10, Batch 70/97, Loss: 0.6219
Epoch 1/10, Batch 80/97, Loss: 0.6611
Epoch 1/10, Batch 90/97, Loss: 0.4742
Epoch 1/10, Train Loss: 0.7973, Valid Loss: 0.4668
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5512
Epoch 2/10, Batch 20/97, Loss: 0.5086
Epoch 2/10, Batch 30/97, Loss: 0.3318
Epoch 2/10, Batch 40/97, Loss: 0.5294
Epoch 2/10, Batch 50/97, Loss: 0.3580
Epoch 2/10, Batch 60/97, Loss: 0.4226
Epoch 2/10, Batch 70/97, Loss: 0.3539
Epoch 2/10, Batch 80/97, Loss: 0.2798
Epoch 2/10, Batch 90/97, Loss: 0.4600
Epoch 2/10, Train Loss: 0.4058, Valid Loss: 0.3548
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3705
Epoch 3/10, Batch 20/97, Loss: 0.2658
Epoch 3/10, Batch 30/97, Loss: 0.3097
Epoch 3/10, Batch 40/97, Loss: 0.2466
Epoch 3/10, Batch 50/97, Loss: 0.3140
Epoch 3/10, Batch 60/97, Loss: 0.2607
Epoch 3/10, Batch 70/97, Loss: 0.3962
Epoch 3/10, Batch 80/97, Loss: 0.2294
Epoch 3/10, Batch 90/97, Loss: 0.2103
Epoch 3/10, Train Loss: 0.3302, Valid Loss: 0.3193
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4006
Epoch 4/10, Batch 20/97, Loss: 0.2166
Epoch 4/10, Batch 30/97, Loss: 0.3199
Epoch 4/10, Batch 40/97, Loss: 0.2529
Epoch 4/10, Batch 50/97, Loss: 0.2952
Epoch 4/10, Batch 60/97, Loss: 0.1911
Epoch 4/10, Batch 70/97, Loss: 0.2564
Epoch 4/10, Batch 80/97, Loss: 0.2454
Epoch 4/10, Batch 90/97, Loss: 0.1990
Epoch 4/10, Train Loss: 0.2772, Valid Loss: 0.2976
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2001
Epoch 5/10, Batch 20/97, Loss: 0.4369
Epoch 5/10, Batch 30/97, Loss: 0.1834
Epoch 5/10, Batch 40/97, Loss: 0.3057
Epoch 5/10, Batch 50/97, Loss: 0.3403
Epoch 5/10, Batch 60/97, Loss: 0.1881
Epoch 5/10, Batch 70/97, Loss: 0.2117
Epoch 5/10, Batch 80/97, Loss: 0.2928
Epoch 5/10, Batch 90/97, Loss: 0.2336
Epoch 5/10, Train Loss: 0.2639, Valid Loss: 0.2816
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3075
Epoch 6/10, Batch 20/97, Loss: 0.3337
Epoch 6/10, Batch 30/97, Loss: 0.1868
Epoch 6/10, Batch 40/97, Loss: 0.2164
Epoch 6/10, Batch 50/97, Loss: 0.2254
Epoch 6/10, Batch 60/97, Loss: 0.2351
Epoch 6/10, Batch 70/97, Loss: 0.1758
Epoch 6/10, Batch 80/97, Loss: 0.2428
Epoch 6/10, Batch 90/97, Loss: 0.2548
Epoch 6/10, Train Loss: 0.2429, Valid Loss: 0.2594
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1722
Epoch 7/10, Batch 20/97, Loss: 0.2032
Epoch 7/10, Batch 30/97, Loss: 0.1447
Epoch 7/10, Batch 40/97, Loss: 0.2227
Epoch 7/10, Batch 50/97, Loss: 0.2569
Epoch 7/10, Batch 60/97, Loss: 0.2357
Epoch 7/10, Batch 70/97, Loss: 0.4504
Epoch 7/10, Batch 80/97, Loss: 0.2488
Epoch 7/10, Batch 90/97, Loss: 0.1493
Epoch 7/10, Train Loss: 0.2227, Valid Loss: 0.2572
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1180
Epoch 8/10, Batch 20/97, Loss: 0.1504
Epoch 8/10, Batch 30/97, Loss: 0.1738
Epoch 8/10, Batch 40/97, Loss: 0.2106
Epoch 8/10, Batch 50/97, Loss: 0.1887
Epoch 8/10, Batch 60/97, Loss: 0.2912
Epoch 8/10, Batch 70/97, Loss: 0.3273
Epoch 8/10, Batch 80/97, Loss: 0.2548
Epoch 8/10, Batch 90/97, Loss: 0.2768
Epoch 8/10, Train Loss: 0.2138, Valid Loss: 0.2580
Epoch 9/10, Batch 10/97, Loss: 0.1301
Epoch 9/10, Batch 20/97, Loss: 0.1725
Epoch 9/10, Batch 30/97, Loss: 0.1964
Epoch 9/10, Batch 40/97, Loss: 0.3292
Epoch 9/10, Batch 50/97, Loss: 0.2346
Epoch 9/10, Batch 60/97, Loss: 0.2242
Epoch 9/10, Batch 70/97, Loss: 0.3989
Epoch 9/10, Batch 80/97, Loss: 0.1437
Epoch 9/10, Batch 90/97, Loss: 0.1666
Epoch 9/10, Train Loss: 0.2020, Valid Loss: 0.2537
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1735
Epoch 10/10, Batch 20/97, Loss: 0.2055
Epoch 10/10, Batch 30/97, Loss: 0.1808
Epoch 10/10, Batch 40/97, Loss: 0.2116
Epoch 10/10, Batch 50/97, Loss: 0.2634
Epoch 10/10, Batch 60/97, Loss: 0.1616
Epoch 10/10, Batch 70/97, Loss: 0.2093
Epoch 10/10, Batch 80/97, Loss: 0.2520
Epoch 10/10, Batch 90/97, Loss: 0.1327
Epoch 10/10, Train Loss: 0.1996, Valid Loss: 0.2483
Model saved!
Accuracy: 0.9217
Precision: 0.9188
Recall: 0.9217
F1-score: 0.9196
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2151
Epoch 1/10, Batch 20/97, Loss: 1.0792
Epoch 1/10, Batch 30/97, Loss: 0.7321
Epoch 1/10, Batch 40/97, Loss: 0.7887
Epoch 1/10, Batch 50/97, Loss: 0.6694
Epoch 1/10, Batch 60/97, Loss: 0.7780
Epoch 1/10, Batch 70/97, Loss: 0.6665
Epoch 1/10, Batch 80/97, Loss: 0.6249
Epoch 1/10, Batch 90/97, Loss: 0.4390
Epoch 1/10, Train Loss: 0.8013, Valid Loss: 0.4498
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4958
Epoch 2/10, Batch 20/97, Loss: 0.4846
Epoch 2/10, Batch 30/97, Loss: 0.3632
Epoch 2/10, Batch 40/97, Loss: 0.2932
Epoch 2/10, Batch 50/97, Loss: 0.4153
Epoch 2/10, Batch 60/97, Loss: 0.2875
Epoch 2/10, Batch 70/97, Loss: 0.2423
Epoch 2/10, Batch 80/97, Loss: 0.4964
Epoch 2/10, Batch 90/97, Loss: 0.3859
Epoch 2/10, Train Loss: 0.4067, Valid Loss: 0.3446
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4907
Epoch 3/10, Batch 20/97, Loss: 0.2803
Epoch 3/10, Batch 30/97, Loss: 0.4031
Epoch 3/10, Batch 40/97, Loss: 0.2798
Epoch 3/10, Batch 50/97, Loss: 0.3773
Epoch 3/10, Batch 60/97, Loss: 0.3630
Epoch 3/10, Batch 70/97, Loss: 0.4321
Epoch 3/10, Batch 80/97, Loss: 0.3911
Epoch 3/10, Batch 90/97, Loss: 0.2824
Epoch 3/10, Train Loss: 0.3274, Valid Loss: 0.3092
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4382
Epoch 4/10, Batch 20/97, Loss: 0.2404
Epoch 4/10, Batch 30/97, Loss: 0.4741
Epoch 4/10, Batch 40/97, Loss: 0.2907
Epoch 4/10, Batch 50/97, Loss: 0.2545
Epoch 4/10, Batch 60/97, Loss: 0.3239
Epoch 4/10, Batch 70/97, Loss: 0.1924
Epoch 4/10, Batch 80/97, Loss: 0.3855
Epoch 4/10, Batch 90/97, Loss: 0.2541
Epoch 4/10, Train Loss: 0.2771, Valid Loss: 0.2844
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2647
Epoch 5/10, Batch 20/97, Loss: 0.3674
Epoch 5/10, Batch 30/97, Loss: 0.2565
Epoch 5/10, Batch 40/97, Loss: 0.2932
Epoch 5/10, Batch 50/97, Loss: 0.2064
Epoch 5/10, Batch 60/97, Loss: 0.2029
Epoch 5/10, Batch 70/97, Loss: 0.2485
Epoch 5/10, Batch 80/97, Loss: 0.3969
Epoch 5/10, Batch 90/97, Loss: 0.1867
Epoch 5/10, Train Loss: 0.2540, Valid Loss: 0.2803
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2818
Epoch 6/10, Batch 20/97, Loss: 0.1999
Epoch 6/10, Batch 30/97, Loss: 0.1467
Epoch 6/10, Batch 40/97, Loss: 0.2656
Epoch 6/10, Batch 50/97, Loss: 0.2265
Epoch 6/10, Batch 60/97, Loss: 0.2591
Epoch 6/10, Batch 70/97, Loss: 0.2782
Epoch 6/10, Batch 80/97, Loss: 0.2966
Epoch 6/10, Batch 90/97, Loss: 0.1792
Epoch 6/10, Train Loss: 0.2401, Valid Loss: 0.2656
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2880
Epoch 7/10, Batch 20/97, Loss: 0.3068
Epoch 7/10, Batch 30/97, Loss: 0.1182
Epoch 7/10, Batch 40/97, Loss: 0.1346
Epoch 7/10, Batch 50/97, Loss: 0.3178
Epoch 7/10, Batch 60/97, Loss: 0.1384
Epoch 7/10, Batch 70/97, Loss: 0.3469
Epoch 7/10, Batch 80/97, Loss: 0.1116
Epoch 7/10, Batch 90/97, Loss: 0.2986
Epoch 7/10, Train Loss: 0.2172, Valid Loss: 0.2605
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1326
Epoch 8/10, Batch 20/97, Loss: 0.1753
Epoch 8/10, Batch 30/97, Loss: 0.1697
Epoch 8/10, Batch 40/97, Loss: 0.2773
Epoch 8/10, Batch 50/97, Loss: 0.2421
Epoch 8/10, Batch 60/97, Loss: 0.2098
Epoch 8/10, Batch 70/97, Loss: 0.2515
Epoch 8/10, Batch 80/97, Loss: 0.2384
Epoch 8/10, Batch 90/97, Loss: 0.2939
Epoch 8/10, Train Loss: 0.2236, Valid Loss: 0.2568
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2138
Epoch 9/10, Batch 20/97, Loss: 0.1083
Epoch 9/10, Batch 30/97, Loss: 0.2550
Epoch 9/10, Batch 40/97, Loss: 0.2216
Epoch 9/10, Batch 50/97, Loss: 0.1225
Epoch 9/10, Batch 60/97, Loss: 0.2563
Epoch 9/10, Batch 70/97, Loss: 0.1505
Epoch 9/10, Batch 80/97, Loss: 0.0894
Epoch 9/10, Batch 90/97, Loss: 0.1690
Epoch 9/10, Train Loss: 0.2083, Valid Loss: 0.2498
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1501
Epoch 10/10, Batch 20/97, Loss: 0.1366
Epoch 10/10, Batch 30/97, Loss: 0.2043
Epoch 10/10, Batch 40/97, Loss: 0.1337
Epoch 10/10, Batch 50/97, Loss: 0.1284
Epoch 10/10, Batch 60/97, Loss: 0.1413
Epoch 10/10, Batch 70/97, Loss: 0.1015
Epoch 10/10, Batch 80/97, Loss: 0.1635
Epoch 10/10, Batch 90/97, Loss: 0.1786
Epoch 10/10, Train Loss: 0.2005, Valid Loss: 0.2425
Model saved!
Accuracy: 0.9182
Precision: 0.9153
Recall: 0.9182
F1-score: 0.9160
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2486
Epoch 1/10, Batch 20/97, Loss: 1.0105
Epoch 1/10, Batch 30/97, Loss: 0.7481
Epoch 1/10, Batch 40/97, Loss: 0.7368
Epoch 1/10, Batch 50/97, Loss: 0.5881
Epoch 1/10, Batch 60/97, Loss: 0.7708
Epoch 1/10, Batch 70/97, Loss: 0.6308
Epoch 1/10, Batch 80/97, Loss: 0.6691
Epoch 1/10, Batch 90/97, Loss: 0.5802
Epoch 1/10, Train Loss: 0.7969, Valid Loss: 0.4374
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5521
Epoch 2/10, Batch 20/97, Loss: 0.3683
Epoch 2/10, Batch 30/97, Loss: 0.3424
Epoch 2/10, Batch 40/97, Loss: 0.4937
Epoch 2/10, Batch 50/97, Loss: 0.4261
Epoch 2/10, Batch 60/97, Loss: 0.4868
Epoch 2/10, Batch 70/97, Loss: 0.3876
Epoch 2/10, Batch 80/97, Loss: 0.4119
Epoch 2/10, Batch 90/97, Loss: 0.4764
Epoch 2/10, Train Loss: 0.4072, Valid Loss: 0.3208
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3776
Epoch 3/10, Batch 20/97, Loss: 0.3465
Epoch 3/10, Batch 30/97, Loss: 0.3810
Epoch 3/10, Batch 40/97, Loss: 0.2132
Epoch 3/10, Batch 50/97, Loss: 0.4206
Epoch 3/10, Batch 60/97, Loss: 0.3135
Epoch 3/10, Batch 70/97, Loss: 0.2575
Epoch 3/10, Batch 80/97, Loss: 0.3211
Epoch 3/10, Batch 90/97, Loss: 0.2432
Epoch 3/10, Train Loss: 0.3300, Valid Loss: 0.2782
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4240
Epoch 4/10, Batch 20/97, Loss: 0.2567
Epoch 4/10, Batch 30/97, Loss: 0.2453
Epoch 4/10, Batch 40/97, Loss: 0.2097
Epoch 4/10, Batch 50/97, Loss: 0.3495
Epoch 4/10, Batch 60/97, Loss: 0.3205
Epoch 4/10, Batch 70/97, Loss: 0.3252
Epoch 4/10, Batch 80/97, Loss: 0.2067
Epoch 4/10, Batch 90/97, Loss: 0.1976
Epoch 4/10, Train Loss: 0.2844, Valid Loss: 0.2651
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2700
Epoch 5/10, Batch 20/97, Loss: 0.2301
Epoch 5/10, Batch 30/97, Loss: 0.2655
Epoch 5/10, Batch 40/97, Loss: 0.3494
Epoch 5/10, Batch 50/97, Loss: 0.2368
Epoch 5/10, Batch 60/97, Loss: 0.3554
Epoch 5/10, Batch 70/97, Loss: 0.2349
Epoch 5/10, Batch 80/97, Loss: 0.3428
Epoch 5/10, Batch 90/97, Loss: 0.2442
Epoch 5/10, Train Loss: 0.2664, Valid Loss: 0.2492
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2443
Epoch 6/10, Batch 20/97, Loss: 0.3087
Epoch 6/10, Batch 30/97, Loss: 0.1324
Epoch 6/10, Batch 40/97, Loss: 0.1368
Epoch 6/10, Batch 50/97, Loss: 0.2051
Epoch 6/10, Batch 60/97, Loss: 0.2550
Epoch 6/10, Batch 70/97, Loss: 0.3300
Epoch 6/10, Batch 80/97, Loss: 0.3532
Epoch 6/10, Batch 90/97, Loss: 0.1940
Epoch 6/10, Train Loss: 0.2442, Valid Loss: 0.2322
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2586
Epoch 7/10, Batch 20/97, Loss: 0.2857
Epoch 7/10, Batch 30/97, Loss: 0.2101
Epoch 7/10, Batch 40/97, Loss: 0.2054
Epoch 7/10, Batch 50/97, Loss: 0.3409
Epoch 7/10, Batch 60/97, Loss: 0.2140
Epoch 7/10, Batch 70/97, Loss: 0.1640
Epoch 7/10, Batch 80/97, Loss: 0.2178
Epoch 7/10, Batch 90/97, Loss: 0.1048
Epoch 7/10, Train Loss: 0.2203, Valid Loss: 0.2230
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1280
Epoch 8/10, Batch 20/97, Loss: 0.2003
Epoch 8/10, Batch 30/97, Loss: 0.2835
Epoch 8/10, Batch 40/97, Loss: 0.3129
Epoch 8/10, Batch 50/97, Loss: 0.2941
Epoch 8/10, Batch 60/97, Loss: 0.1699
Epoch 8/10, Batch 70/97, Loss: 0.2588
Epoch 8/10, Batch 80/97, Loss: 0.1495
Epoch 8/10, Batch 90/97, Loss: 0.2928
Epoch 8/10, Train Loss: 0.2209, Valid Loss: 0.2241
Epoch 9/10, Batch 10/97, Loss: 0.2484
Epoch 9/10, Batch 20/97, Loss: 0.1777
Epoch 9/10, Batch 30/97, Loss: 0.2451
Epoch 9/10, Batch 40/97, Loss: 0.1946
Epoch 9/10, Batch 50/97, Loss: 0.2440
Epoch 9/10, Batch 60/97, Loss: 0.3916
Epoch 9/10, Batch 70/97, Loss: 0.1395
Epoch 9/10, Batch 80/97, Loss: 0.1187
Epoch 9/10, Batch 90/97, Loss: 0.2570
Epoch 9/10, Train Loss: 0.2080, Valid Loss: 0.2131
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2549
Epoch 10/10, Batch 20/97, Loss: 0.3224
Epoch 10/10, Batch 30/97, Loss: 0.2511
Epoch 10/10, Batch 40/97, Loss: 0.2031
Epoch 10/10, Batch 50/97, Loss: 0.1318
Epoch 10/10, Batch 60/97, Loss: 0.1420
Epoch 10/10, Batch 70/97, Loss: 0.2794
Epoch 10/10, Batch 80/97, Loss: 0.2292
Epoch 10/10, Batch 90/97, Loss: 0.1257
Epoch 10/10, Train Loss: 0.2014, Valid Loss: 0.2127
Model saved!
Accuracy: 0.9182
Precision: 0.9162
Recall: 0.9182
F1-score: 0.9158
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.1946
Epoch 1/10, Batch 20/97, Loss: 1.1626
Epoch 1/10, Batch 30/97, Loss: 0.7152
Epoch 1/10, Batch 40/97, Loss: 0.6896
Epoch 1/10, Batch 50/97, Loss: 0.5755
Epoch 1/10, Batch 60/97, Loss: 0.7943
Epoch 1/10, Batch 70/97, Loss: 0.6218
Epoch 1/10, Batch 80/97, Loss: 0.7460
Epoch 1/10, Batch 90/97, Loss: 0.5655
Epoch 1/10, Train Loss: 0.8013, Valid Loss: 0.4343
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4890
Epoch 2/10, Batch 20/97, Loss: 0.5067
Epoch 2/10, Batch 30/97, Loss: 0.3143
Epoch 2/10, Batch 40/97, Loss: 0.5066
Epoch 2/10, Batch 50/97, Loss: 0.4162
Epoch 2/10, Batch 60/97, Loss: 0.5551
Epoch 2/10, Batch 70/97, Loss: 0.3387
Epoch 2/10, Batch 80/97, Loss: 0.3269
Epoch 2/10, Batch 90/97, Loss: 0.4306
Epoch 2/10, Train Loss: 0.4124, Valid Loss: 0.3329
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2870
Epoch 3/10, Batch 20/97, Loss: 0.3572
Epoch 3/10, Batch 30/97, Loss: 0.3353
Epoch 3/10, Batch 40/97, Loss: 0.2614
Epoch 3/10, Batch 50/97, Loss: 0.4043
Epoch 3/10, Batch 60/97, Loss: 0.2083
Epoch 3/10, Batch 70/97, Loss: 0.3929
Epoch 3/10, Batch 80/97, Loss: 0.2948
Epoch 3/10, Batch 90/97, Loss: 0.3009
Epoch 3/10, Train Loss: 0.3328, Valid Loss: 0.2866
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3046
Epoch 4/10, Batch 20/97, Loss: 0.1468
Epoch 4/10, Batch 30/97, Loss: 0.3888
Epoch 4/10, Batch 40/97, Loss: 0.2073
Epoch 4/10, Batch 50/97, Loss: 0.3853
Epoch 4/10, Batch 60/97, Loss: 0.1947
Epoch 4/10, Batch 70/97, Loss: 0.3388
Epoch 4/10, Batch 80/97, Loss: 0.3252
Epoch 4/10, Batch 90/97, Loss: 0.3183
Epoch 4/10, Train Loss: 0.2856, Valid Loss: 0.2735
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2737
Epoch 5/10, Batch 20/97, Loss: 0.2446
Epoch 5/10, Batch 30/97, Loss: 0.2326
Epoch 5/10, Batch 40/97, Loss: 0.2126
Epoch 5/10, Batch 50/97, Loss: 0.1400
Epoch 5/10, Batch 60/97, Loss: 0.3390
Epoch 5/10, Batch 70/97, Loss: 0.2031
Epoch 5/10, Batch 80/97, Loss: 0.1408
Epoch 5/10, Batch 90/97, Loss: 0.2914
Epoch 5/10, Train Loss: 0.2604, Valid Loss: 0.2653
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2114
Epoch 6/10, Batch 20/97, Loss: 0.3031
Epoch 6/10, Batch 30/97, Loss: 0.2652
Epoch 6/10, Batch 40/97, Loss: 0.1820
Epoch 6/10, Batch 50/97, Loss: 0.2266
Epoch 6/10, Batch 60/97, Loss: 0.1861
Epoch 6/10, Batch 70/97, Loss: 0.3248
Epoch 6/10, Batch 80/97, Loss: 0.3189
Epoch 6/10, Batch 90/97, Loss: 0.4689
Epoch 6/10, Train Loss: 0.2437, Valid Loss: 0.2474
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2413
Epoch 7/10, Batch 20/97, Loss: 0.2716
Epoch 7/10, Batch 30/97, Loss: 0.2419
Epoch 7/10, Batch 40/97, Loss: 0.2063
Epoch 7/10, Batch 50/97, Loss: 0.1795
Epoch 7/10, Batch 60/97, Loss: 0.1907
Epoch 7/10, Batch 70/97, Loss: 0.1718
Epoch 7/10, Batch 80/97, Loss: 0.2438
Epoch 7/10, Batch 90/97, Loss: 0.1948
Epoch 7/10, Train Loss: 0.2207, Valid Loss: 0.2459
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1668
Epoch 8/10, Batch 20/97, Loss: 0.1783
Epoch 8/10, Batch 30/97, Loss: 0.1004
Epoch 8/10, Batch 40/97, Loss: 0.1814
Epoch 8/10, Batch 50/97, Loss: 0.1808
Epoch 8/10, Batch 60/97, Loss: 0.1382
Epoch 8/10, Batch 70/97, Loss: 0.5366
Epoch 8/10, Batch 80/97, Loss: 0.1566
Epoch 8/10, Batch 90/97, Loss: 0.2699
Epoch 8/10, Train Loss: 0.2246, Valid Loss: 0.2344
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0931
Epoch 9/10, Batch 20/97, Loss: 0.0816
Epoch 9/10, Batch 30/97, Loss: 0.2167
Epoch 9/10, Batch 40/97, Loss: 0.2050
Epoch 9/10, Batch 50/97, Loss: 0.2013
Epoch 9/10, Batch 60/97, Loss: 0.2378
Epoch 9/10, Batch 70/97, Loss: 0.2496
Epoch 9/10, Batch 80/97, Loss: 0.2910
Epoch 9/10, Batch 90/97, Loss: 0.0812
Epoch 9/10, Train Loss: 0.2065, Valid Loss: 0.2383
Epoch 10/10, Batch 10/97, Loss: 0.1783
Epoch 10/10, Batch 20/97, Loss: 0.2190
Epoch 10/10, Batch 30/97, Loss: 0.1981
Epoch 10/10, Batch 40/97, Loss: 0.1693
Epoch 10/10, Batch 50/97, Loss: 0.1117
Epoch 10/10, Batch 60/97, Loss: 0.2528
Epoch 10/10, Batch 70/97, Loss: 0.1747
Epoch 10/10, Batch 80/97, Loss: 0.2337
Epoch 10/10, Batch 90/97, Loss: 0.2054
Epoch 10/10, Train Loss: 0.2061, Valid Loss: 0.2460
Accuracy: 0.9159
Precision: 0.9122
Recall: 0.9159
F1-score: 0.9131
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.3034
Epoch 1/10, Batch 20/97, Loss: 1.0847
Epoch 1/10, Batch 30/97, Loss: 0.6991
Epoch 1/10, Batch 40/97, Loss: 0.7199
Epoch 1/10, Batch 50/97, Loss: 0.5968
Epoch 1/10, Batch 60/97, Loss: 0.7452
Epoch 1/10, Batch 70/97, Loss: 0.7636
Epoch 1/10, Batch 80/97, Loss: 0.6122
Epoch 1/10, Batch 90/97, Loss: 0.7022
Epoch 1/10, Train Loss: 0.7954, Valid Loss: 0.4359
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4941
Epoch 2/10, Batch 20/97, Loss: 0.4156
Epoch 2/10, Batch 30/97, Loss: 0.4588
Epoch 2/10, Batch 40/97, Loss: 0.3812
Epoch 2/10, Batch 50/97, Loss: 0.6097
Epoch 2/10, Batch 60/97, Loss: 0.3643
Epoch 2/10, Batch 70/97, Loss: 0.3790
Epoch 2/10, Batch 80/97, Loss: 0.3511
Epoch 2/10, Batch 90/97, Loss: 0.4297
Epoch 2/10, Train Loss: 0.4054, Valid Loss: 0.3173
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2697
Epoch 3/10, Batch 20/97, Loss: 0.2967
Epoch 3/10, Batch 30/97, Loss: 0.4323
Epoch 3/10, Batch 40/97, Loss: 0.3598
Epoch 3/10, Batch 50/97, Loss: 0.3931
Epoch 3/10, Batch 60/97, Loss: 0.1839
Epoch 3/10, Batch 70/97, Loss: 0.2609
Epoch 3/10, Batch 80/97, Loss: 0.2819
Epoch 3/10, Batch 90/97, Loss: 0.3345
Epoch 3/10, Train Loss: 0.3246, Valid Loss: 0.2695
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.6152
Epoch 4/10, Batch 20/97, Loss: 0.2156
Epoch 4/10, Batch 30/97, Loss: 0.3000
Epoch 4/10, Batch 40/97, Loss: 0.1435
Epoch 4/10, Batch 50/97, Loss: 0.5635
Epoch 4/10, Batch 60/97, Loss: 0.2231
Epoch 4/10, Batch 70/97, Loss: 0.1884
Epoch 4/10, Batch 80/97, Loss: 0.2787
Epoch 4/10, Batch 90/97, Loss: 0.2488
Epoch 4/10, Train Loss: 0.2804, Valid Loss: 0.2520
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2268
Epoch 5/10, Batch 20/97, Loss: 0.1863
Epoch 5/10, Batch 30/97, Loss: 0.2154
Epoch 5/10, Batch 40/97, Loss: 0.3509
Epoch 5/10, Batch 50/97, Loss: 0.2411
Epoch 5/10, Batch 60/97, Loss: 0.3305
Epoch 5/10, Batch 70/97, Loss: 0.2817
Epoch 5/10, Batch 80/97, Loss: 0.1566
Epoch 5/10, Batch 90/97, Loss: 0.2155
Epoch 5/10, Train Loss: 0.2600, Valid Loss: 0.2476
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2569
Epoch 6/10, Batch 20/97, Loss: 0.2760
Epoch 6/10, Batch 30/97, Loss: 0.1774
Epoch 6/10, Batch 40/97, Loss: 0.1597
Epoch 6/10, Batch 50/97, Loss: 0.2526
Epoch 6/10, Batch 60/97, Loss: 0.3004
Epoch 6/10, Batch 70/97, Loss: 0.2669
Epoch 6/10, Batch 80/97, Loss: 0.1701
Epoch 6/10, Batch 90/97, Loss: 0.4632
Epoch 6/10, Train Loss: 0.2424, Valid Loss: 0.2359
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2129
Epoch 7/10, Batch 20/97, Loss: 0.3773
Epoch 7/10, Batch 30/97, Loss: 0.1289
Epoch 7/10, Batch 40/97, Loss: 0.1203
Epoch 7/10, Batch 50/97, Loss: 0.1266
Epoch 7/10, Batch 60/97, Loss: 0.1792
Epoch 7/10, Batch 70/97, Loss: 0.3033
Epoch 7/10, Batch 80/97, Loss: 0.1463
Epoch 7/10, Batch 90/97, Loss: 0.1472
Epoch 7/10, Train Loss: 0.2208, Valid Loss: 0.2244
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.0951
Epoch 8/10, Batch 20/97, Loss: 0.2876
Epoch 8/10, Batch 30/97, Loss: 0.3129
Epoch 8/10, Batch 40/97, Loss: 0.1860
Epoch 8/10, Batch 50/97, Loss: 0.2399
Epoch 8/10, Batch 60/97, Loss: 0.2468
Epoch 8/10, Batch 70/97, Loss: 0.1769
Epoch 8/10, Batch 80/97, Loss: 0.1589
Epoch 8/10, Batch 90/97, Loss: 0.1349
Epoch 8/10, Train Loss: 0.2177, Valid Loss: 0.2241
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1499
Epoch 9/10, Batch 20/97, Loss: 0.1695
Epoch 9/10, Batch 30/97, Loss: 0.3101
Epoch 9/10, Batch 40/97, Loss: 0.2333
Epoch 9/10, Batch 50/97, Loss: 0.1562
Epoch 9/10, Batch 60/97, Loss: 0.2001
Epoch 9/10, Batch 70/97, Loss: 0.1027
Epoch 9/10, Batch 80/97, Loss: 0.1288
Epoch 9/10, Batch 90/97, Loss: 0.1732
Epoch 9/10, Train Loss: 0.1984, Valid Loss: 0.2211
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2090
Epoch 10/10, Batch 20/97, Loss: 0.0629
Epoch 10/10, Batch 30/97, Loss: 0.1781
Epoch 10/10, Batch 40/97, Loss: 0.1656
Epoch 10/10, Batch 50/97, Loss: 0.1058
Epoch 10/10, Batch 60/97, Loss: 0.1790
Epoch 10/10, Batch 70/97, Loss: 0.1339
Epoch 10/10, Batch 80/97, Loss: 0.1005
Epoch 10/10, Batch 90/97, Loss: 0.1734
Epoch 10/10, Train Loss: 0.1891, Valid Loss: 0.2224
Accuracy: 0.9206
Precision: 0.9184
Recall: 0.9206
F1-score: 0.9190
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2396
Epoch 1/10, Batch 20/97, Loss: 1.0862
Epoch 1/10, Batch 30/97, Loss: 0.8227
Epoch 1/10, Batch 40/97, Loss: 0.7925
Epoch 1/10, Batch 50/97, Loss: 0.6262
Epoch 1/10, Batch 60/97, Loss: 0.7481
Epoch 1/10, Batch 70/97, Loss: 0.6245
Epoch 1/10, Batch 80/97, Loss: 0.7615
Epoch 1/10, Batch 90/97, Loss: 0.5291
Epoch 1/10, Train Loss: 0.7950, Valid Loss: 0.4586
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5026
Epoch 2/10, Batch 20/97, Loss: 0.4642
Epoch 2/10, Batch 30/97, Loss: 0.3723
Epoch 2/10, Batch 40/97, Loss: 0.4222
Epoch 2/10, Batch 50/97, Loss: 0.4050
Epoch 2/10, Batch 60/97, Loss: 0.4751
Epoch 2/10, Batch 70/97, Loss: 0.2824
Epoch 2/10, Batch 80/97, Loss: 0.3612
Epoch 2/10, Batch 90/97, Loss: 0.5006
Epoch 2/10, Train Loss: 0.4122, Valid Loss: 0.3456
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3602
Epoch 3/10, Batch 20/97, Loss: 0.2883
Epoch 3/10, Batch 30/97, Loss: 0.3615
Epoch 3/10, Batch 40/97, Loss: 0.3589
Epoch 3/10, Batch 50/97, Loss: 0.5005
Epoch 3/10, Batch 60/97, Loss: 0.1670
Epoch 3/10, Batch 70/97, Loss: 0.5380
Epoch 3/10, Batch 80/97, Loss: 0.2425
Epoch 3/10, Batch 90/97, Loss: 0.3219
Epoch 3/10, Train Loss: 0.3339, Valid Loss: 0.3077
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3582
Epoch 4/10, Batch 20/97, Loss: 0.3540
Epoch 4/10, Batch 30/97, Loss: 0.2031
Epoch 4/10, Batch 40/97, Loss: 0.3517
Epoch 4/10, Batch 50/97, Loss: 0.3629
Epoch 4/10, Batch 60/97, Loss: 0.1903
Epoch 4/10, Batch 70/97, Loss: 0.2434
Epoch 4/10, Batch 80/97, Loss: 0.2674
Epoch 4/10, Batch 90/97, Loss: 0.3214
Epoch 4/10, Train Loss: 0.2908, Valid Loss: 0.2846
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3017
Epoch 5/10, Batch 20/97, Loss: 0.2582
Epoch 5/10, Batch 30/97, Loss: 0.1995
Epoch 5/10, Batch 40/97, Loss: 0.4963
Epoch 5/10, Batch 50/97, Loss: 0.2287
Epoch 5/10, Batch 60/97, Loss: 0.3614
Epoch 5/10, Batch 70/97, Loss: 0.1456
Epoch 5/10, Batch 80/97, Loss: 0.2915
Epoch 5/10, Batch 90/97, Loss: 0.2158
Epoch 5/10, Train Loss: 0.2666, Valid Loss: 0.2724
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2140
Epoch 6/10, Batch 20/97, Loss: 0.2694
Epoch 6/10, Batch 30/97, Loss: 0.1371
Epoch 6/10, Batch 40/97, Loss: 0.2264
Epoch 6/10, Batch 50/97, Loss: 0.2663
Epoch 6/10, Batch 60/97, Loss: 0.3731
Epoch 6/10, Batch 70/97, Loss: 0.1929
Epoch 6/10, Batch 80/97, Loss: 0.4379
Epoch 6/10, Batch 90/97, Loss: 0.2399
Epoch 6/10, Train Loss: 0.2430, Valid Loss: 0.2516
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3528
Epoch 7/10, Batch 20/97, Loss: 0.1879
Epoch 7/10, Batch 30/97, Loss: 0.2039
Epoch 7/10, Batch 40/97, Loss: 0.1039
Epoch 7/10, Batch 50/97, Loss: 0.2164
Epoch 7/10, Batch 60/97, Loss: 0.2958
Epoch 7/10, Batch 70/97, Loss: 0.3116
Epoch 7/10, Batch 80/97, Loss: 0.2311
Epoch 7/10, Batch 90/97, Loss: 0.1802
Epoch 7/10, Train Loss: 0.2217, Valid Loss: 0.2459
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1799
Epoch 8/10, Batch 20/97, Loss: 0.1994
Epoch 8/10, Batch 30/97, Loss: 0.1595
Epoch 8/10, Batch 40/97, Loss: 0.1633
Epoch 8/10, Batch 50/97, Loss: 0.2486
Epoch 8/10, Batch 60/97, Loss: 0.1155
Epoch 8/10, Batch 70/97, Loss: 0.3202
Epoch 8/10, Batch 80/97, Loss: 0.1387
Epoch 8/10, Batch 90/97, Loss: 0.2329
Epoch 8/10, Train Loss: 0.2162, Valid Loss: 0.2442
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1269
Epoch 9/10, Batch 20/97, Loss: 0.3453
Epoch 9/10, Batch 30/97, Loss: 0.2903
Epoch 9/10, Batch 40/97, Loss: 0.1772
Epoch 9/10, Batch 50/97, Loss: 0.1437
Epoch 9/10, Batch 60/97, Loss: 0.2162
Epoch 9/10, Batch 70/97, Loss: 0.2346
Epoch 9/10, Batch 80/97, Loss: 0.2243
Epoch 9/10, Batch 90/97, Loss: 0.2068
Epoch 9/10, Train Loss: 0.2035, Valid Loss: 0.2359
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1382
Epoch 10/10, Batch 20/97, Loss: 0.1895
Epoch 10/10, Batch 30/97, Loss: 0.0549
Epoch 10/10, Batch 40/97, Loss: 0.0467
Epoch 10/10, Batch 50/97, Loss: 0.2303
Epoch 10/10, Batch 60/97, Loss: 0.1242
Epoch 10/10, Batch 70/97, Loss: 0.3528
Epoch 10/10, Batch 80/97, Loss: 0.1840
Epoch 10/10, Batch 90/97, Loss: 0.1423
Epoch 10/10, Train Loss: 0.2051, Valid Loss: 0.2299
Model saved!
Accuracy: 0.9100
Precision: 0.9059
Recall: 0.9100
F1-score: 0.9067
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.3304
Epoch 1/10, Batch 20/97, Loss: 1.0685
Epoch 1/10, Batch 30/97, Loss: 0.7075
Epoch 1/10, Batch 40/97, Loss: 0.7848
Epoch 1/10, Batch 50/97, Loss: 0.5096
Epoch 1/10, Batch 60/97, Loss: 0.6321
Epoch 1/10, Batch 70/97, Loss: 0.5950
Epoch 1/10, Batch 80/97, Loss: 0.7005
Epoch 1/10, Batch 90/97, Loss: 0.5472
Epoch 1/10, Train Loss: 0.7924, Valid Loss: 0.4447
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5571
Epoch 2/10, Batch 20/97, Loss: 0.3243
Epoch 2/10, Batch 30/97, Loss: 0.3217
Epoch 2/10, Batch 40/97, Loss: 0.3177
Epoch 2/10, Batch 50/97, Loss: 0.5339
Epoch 2/10, Batch 60/97, Loss: 0.3762
Epoch 2/10, Batch 70/97, Loss: 0.2961
Epoch 2/10, Batch 80/97, Loss: 0.4679
Epoch 2/10, Batch 90/97, Loss: 0.3512
Epoch 2/10, Train Loss: 0.4057, Valid Loss: 0.3318
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3295
Epoch 3/10, Batch 20/97, Loss: 0.2510
Epoch 3/10, Batch 30/97, Loss: 0.2991
Epoch 3/10, Batch 40/97, Loss: 0.4635
Epoch 3/10, Batch 50/97, Loss: 0.2627
Epoch 3/10, Batch 60/97, Loss: 0.2392
Epoch 3/10, Batch 70/97, Loss: 0.3894
Epoch 3/10, Batch 80/97, Loss: 0.3874
Epoch 3/10, Batch 90/97, Loss: 0.1808
Epoch 3/10, Train Loss: 0.3253, Valid Loss: 0.2945
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4256
Epoch 4/10, Batch 20/97, Loss: 0.2500
Epoch 4/10, Batch 30/97, Loss: 0.2422
Epoch 4/10, Batch 40/97, Loss: 0.2290
Epoch 4/10, Batch 50/97, Loss: 0.2922
Epoch 4/10, Batch 60/97, Loss: 0.3507
Epoch 4/10, Batch 70/97, Loss: 0.2475
Epoch 4/10, Batch 80/97, Loss: 0.2249
Epoch 4/10, Batch 90/97, Loss: 0.1736
Epoch 4/10, Train Loss: 0.2765, Valid Loss: 0.2709
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2969
Epoch 5/10, Batch 20/97, Loss: 0.2548
Epoch 5/10, Batch 30/97, Loss: 0.3500
Epoch 5/10, Batch 40/97, Loss: 0.3220
Epoch 5/10, Batch 50/97, Loss: 0.1551
Epoch 5/10, Batch 60/97, Loss: 0.2380
Epoch 5/10, Batch 70/97, Loss: 0.2065
Epoch 5/10, Batch 80/97, Loss: 0.1504
Epoch 5/10, Batch 90/97, Loss: 0.2027
Epoch 5/10, Train Loss: 0.2580, Valid Loss: 0.2572
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1814
Epoch 6/10, Batch 20/97, Loss: 0.3920
Epoch 6/10, Batch 30/97, Loss: 0.2050
Epoch 6/10, Batch 40/97, Loss: 0.2833
Epoch 6/10, Batch 50/97, Loss: 0.2030
Epoch 6/10, Batch 60/97, Loss: 0.3273
Epoch 6/10, Batch 70/97, Loss: 0.2623
Epoch 6/10, Batch 80/97, Loss: 0.4198
Epoch 6/10, Batch 90/97, Loss: 0.2524
Epoch 6/10, Train Loss: 0.2400, Valid Loss: 0.2411
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2061
Epoch 7/10, Batch 20/97, Loss: 0.2085
Epoch 7/10, Batch 30/97, Loss: 0.2261
Epoch 7/10, Batch 40/97, Loss: 0.1403
Epoch 7/10, Batch 50/97, Loss: 0.2641
Epoch 7/10, Batch 60/97, Loss: 0.1934
Epoch 7/10, Batch 70/97, Loss: 0.2117
Epoch 7/10, Batch 80/97, Loss: 0.2129
Epoch 7/10, Batch 90/97, Loss: 0.1948
Epoch 7/10, Train Loss: 0.2191, Valid Loss: 0.2385
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1102
Epoch 8/10, Batch 20/97, Loss: 0.2869
Epoch 8/10, Batch 30/97, Loss: 0.2598
Epoch 8/10, Batch 40/97, Loss: 0.2165
Epoch 8/10, Batch 50/97, Loss: 0.2090
Epoch 8/10, Batch 60/97, Loss: 0.2284
Epoch 8/10, Batch 70/97, Loss: 0.2146
Epoch 8/10, Batch 80/97, Loss: 0.2451
Epoch 8/10, Batch 90/97, Loss: 0.1912
Epoch 8/10, Train Loss: 0.2145, Valid Loss: 0.2368
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1189
Epoch 9/10, Batch 20/97, Loss: 0.1125
Epoch 9/10, Batch 30/97, Loss: 0.2659
Epoch 9/10, Batch 40/97, Loss: 0.2650
Epoch 9/10, Batch 50/97, Loss: 0.2206
Epoch 9/10, Batch 60/97, Loss: 0.1947
Epoch 9/10, Batch 70/97, Loss: 0.1512
Epoch 9/10, Batch 80/97, Loss: 0.1654
Epoch 9/10, Batch 90/97, Loss: 0.1427
Epoch 9/10, Train Loss: 0.1996, Valid Loss: 0.2305
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2674
Epoch 10/10, Batch 20/97, Loss: 0.0789
Epoch 10/10, Batch 30/97, Loss: 0.1188
Epoch 10/10, Batch 40/97, Loss: 0.1754
Epoch 10/10, Batch 50/97, Loss: 0.1011
Epoch 10/10, Batch 60/97, Loss: 0.0853
Epoch 10/10, Batch 70/97, Loss: 0.2521
Epoch 10/10, Batch 80/97, Loss: 0.2179
Epoch 10/10, Batch 90/97, Loss: 0.2376
Epoch 10/10, Train Loss: 0.1960, Valid Loss: 0.2351
Accuracy: 0.9159
Precision: 0.9137
Recall: 0.9159
F1-score: 0.9144
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2090
Epoch 1/10, Batch 20/97, Loss: 1.0525
Epoch 1/10, Batch 30/97, Loss: 0.6937
Epoch 1/10, Batch 40/97, Loss: 0.8131
Epoch 1/10, Batch 50/97, Loss: 0.7331
Epoch 1/10, Batch 60/97, Loss: 0.6027
Epoch 1/10, Batch 70/97, Loss: 0.6528
Epoch 1/10, Batch 80/97, Loss: 0.6029
Epoch 1/10, Batch 90/97, Loss: 0.5395
Epoch 1/10, Train Loss: 0.8071, Valid Loss: 0.4430
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5888
Epoch 2/10, Batch 20/97, Loss: 0.5175
Epoch 2/10, Batch 30/97, Loss: 0.4958
Epoch 2/10, Batch 40/97, Loss: 0.4169
Epoch 2/10, Batch 50/97, Loss: 0.3255
Epoch 2/10, Batch 60/97, Loss: 0.3266
Epoch 2/10, Batch 70/97, Loss: 0.2991
Epoch 2/10, Batch 80/97, Loss: 0.3894
Epoch 2/10, Batch 90/97, Loss: 0.4556
Epoch 2/10, Train Loss: 0.4131, Valid Loss: 0.3398
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3123
Epoch 3/10, Batch 20/97, Loss: 0.4209
Epoch 3/10, Batch 30/97, Loss: 0.3767
Epoch 3/10, Batch 40/97, Loss: 0.3152
Epoch 3/10, Batch 50/97, Loss: 0.2945
Epoch 3/10, Batch 60/97, Loss: 0.3072
Epoch 3/10, Batch 70/97, Loss: 0.3881
Epoch 3/10, Batch 80/97, Loss: 0.3154
Epoch 3/10, Batch 90/97, Loss: 0.1513
Epoch 3/10, Train Loss: 0.3399, Valid Loss: 0.3087
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3909
Epoch 4/10, Batch 20/97, Loss: 0.2183
Epoch 4/10, Batch 30/97, Loss: 0.2439
Epoch 4/10, Batch 40/97, Loss: 0.3386
Epoch 4/10, Batch 50/97, Loss: 0.2584
Epoch 4/10, Batch 60/97, Loss: 0.3102
Epoch 4/10, Batch 70/97, Loss: 0.2931
Epoch 4/10, Batch 80/97, Loss: 0.2397
Epoch 4/10, Batch 90/97, Loss: 0.2331
Epoch 4/10, Train Loss: 0.2853, Valid Loss: 0.2794
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3100
Epoch 5/10, Batch 20/97, Loss: 0.4869
Epoch 5/10, Batch 30/97, Loss: 0.1871
Epoch 5/10, Batch 40/97, Loss: 0.2419
Epoch 5/10, Batch 50/97, Loss: 0.2291
Epoch 5/10, Batch 60/97, Loss: 0.1273
Epoch 5/10, Batch 70/97, Loss: 0.2896
Epoch 5/10, Batch 80/97, Loss: 0.3008
Epoch 5/10, Batch 90/97, Loss: 0.2077
Epoch 5/10, Train Loss: 0.2703, Valid Loss: 0.2726
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1695
Epoch 6/10, Batch 20/97, Loss: 0.2796
Epoch 6/10, Batch 30/97, Loss: 0.2282
Epoch 6/10, Batch 40/97, Loss: 0.1868
Epoch 6/10, Batch 50/97, Loss: 0.3126
Epoch 6/10, Batch 60/97, Loss: 0.3401
Epoch 6/10, Batch 70/97, Loss: 0.3555
Epoch 6/10, Batch 80/97, Loss: 0.3283
Epoch 6/10, Batch 90/97, Loss: 0.2406
Epoch 6/10, Train Loss: 0.2556, Valid Loss: 0.2542
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1923
Epoch 7/10, Batch 20/97, Loss: 0.2425
Epoch 7/10, Batch 30/97, Loss: 0.1299
Epoch 7/10, Batch 40/97, Loss: 0.1320
Epoch 7/10, Batch 50/97, Loss: 0.2569
Epoch 7/10, Batch 60/97, Loss: 0.2281
Epoch 7/10, Batch 70/97, Loss: 0.1555
Epoch 7/10, Batch 80/97, Loss: 0.1986
Epoch 7/10, Batch 90/97, Loss: 0.2515
Epoch 7/10, Train Loss: 0.2313, Valid Loss: 0.2459
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1349
Epoch 8/10, Batch 20/97, Loss: 0.1930
Epoch 8/10, Batch 30/97, Loss: 0.1441
Epoch 8/10, Batch 40/97, Loss: 0.2004
Epoch 8/10, Batch 50/97, Loss: 0.2834
Epoch 8/10, Batch 60/97, Loss: 0.1750
Epoch 8/10, Batch 70/97, Loss: 0.2856
Epoch 8/10, Batch 80/97, Loss: 0.2336
Epoch 8/10, Batch 90/97, Loss: 0.2909
Epoch 8/10, Train Loss: 0.2270, Valid Loss: 0.2513
Epoch 9/10, Batch 10/97, Loss: 0.2231
Epoch 9/10, Batch 20/97, Loss: 0.1810
Epoch 9/10, Batch 30/97, Loss: 0.3021
Epoch 9/10, Batch 40/97, Loss: 0.2413
Epoch 9/10, Batch 50/97, Loss: 0.2523
Epoch 9/10, Batch 60/97, Loss: 0.1494
Epoch 9/10, Batch 70/97, Loss: 0.1708
Epoch 9/10, Batch 80/97, Loss: 0.1926
Epoch 9/10, Batch 90/97, Loss: 0.2536
Epoch 9/10, Train Loss: 0.2084, Valid Loss: 0.2402
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1757
Epoch 10/10, Batch 20/97, Loss: 0.1457
Epoch 10/10, Batch 30/97, Loss: 0.2710
Epoch 10/10, Batch 40/97, Loss: 0.2828
Epoch 10/10, Batch 50/97, Loss: 0.1763
Epoch 10/10, Batch 60/97, Loss: 0.0823
Epoch 10/10, Batch 70/97, Loss: 0.2794
Epoch 10/10, Batch 80/97, Loss: 0.1767
Epoch 10/10, Batch 90/97, Loss: 0.2655
Epoch 10/10, Train Loss: 0.2106, Valid Loss: 0.2448
Accuracy: 0.9229
Precision: 0.9216
Recall: 0.9229
F1-score: 0.9219
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2330
Epoch 1/10, Batch 20/97, Loss: 1.1158
Epoch 1/10, Batch 30/97, Loss: 0.7442
Epoch 1/10, Batch 40/97, Loss: 0.8013
Epoch 1/10, Batch 50/97, Loss: 0.6038
Epoch 1/10, Batch 60/97, Loss: 0.7731
Epoch 1/10, Batch 70/97, Loss: 0.6528
Epoch 1/10, Batch 80/97, Loss: 0.8101
Epoch 1/10, Batch 90/97, Loss: 0.5775
Epoch 1/10, Train Loss: 0.8095, Valid Loss: 0.4478
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6660
Epoch 2/10, Batch 20/97, Loss: 0.5453
Epoch 2/10, Batch 30/97, Loss: 0.4223
Epoch 2/10, Batch 40/97, Loss: 0.4120
Epoch 2/10, Batch 50/97, Loss: 0.4583
Epoch 2/10, Batch 60/97, Loss: 0.4690
Epoch 2/10, Batch 70/97, Loss: 0.5449
Epoch 2/10, Batch 80/97, Loss: 0.3129
Epoch 2/10, Batch 90/97, Loss: 0.3207
Epoch 2/10, Train Loss: 0.4214, Valid Loss: 0.3383
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3144
Epoch 3/10, Batch 20/97, Loss: 0.2955
Epoch 3/10, Batch 30/97, Loss: 0.4833
Epoch 3/10, Batch 40/97, Loss: 0.2796
Epoch 3/10, Batch 50/97, Loss: 0.4124
Epoch 3/10, Batch 60/97, Loss: 0.2277
Epoch 3/10, Batch 70/97, Loss: 0.2937
Epoch 3/10, Batch 80/97, Loss: 0.4060
Epoch 3/10, Batch 90/97, Loss: 0.1876
Epoch 3/10, Train Loss: 0.3382, Valid Loss: 0.3016
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3797
Epoch 4/10, Batch 20/97, Loss: 0.2526
Epoch 4/10, Batch 30/97, Loss: 0.2454
Epoch 4/10, Batch 40/97, Loss: 0.2323
Epoch 4/10, Batch 50/97, Loss: 0.3593
Epoch 4/10, Batch 60/97, Loss: 0.3214
Epoch 4/10, Batch 70/97, Loss: 0.3849
Epoch 4/10, Batch 80/97, Loss: 0.2638
Epoch 4/10, Batch 90/97, Loss: 0.2759
Epoch 4/10, Train Loss: 0.2891, Valid Loss: 0.2852
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2557
Epoch 5/10, Batch 20/97, Loss: 0.3058
Epoch 5/10, Batch 30/97, Loss: 0.1936
Epoch 5/10, Batch 40/97, Loss: 0.2598
Epoch 5/10, Batch 50/97, Loss: 0.2500
Epoch 5/10, Batch 60/97, Loss: 0.4047
Epoch 5/10, Batch 70/97, Loss: 0.2947
Epoch 5/10, Batch 80/97, Loss: 0.2655
Epoch 5/10, Batch 90/97, Loss: 0.2995
Epoch 5/10, Train Loss: 0.2653, Valid Loss: 0.2725
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2995
Epoch 6/10, Batch 20/97, Loss: 0.3181
Epoch 6/10, Batch 30/97, Loss: 0.2205
Epoch 6/10, Batch 40/97, Loss: 0.1744
Epoch 6/10, Batch 50/97, Loss: 0.2701
Epoch 6/10, Batch 60/97, Loss: 0.2146
Epoch 6/10, Batch 70/97, Loss: 0.3855
Epoch 6/10, Batch 80/97, Loss: 0.2453
Epoch 6/10, Batch 90/97, Loss: 0.2467
Epoch 6/10, Train Loss: 0.2494, Valid Loss: 0.2612
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1632
Epoch 7/10, Batch 20/97, Loss: 0.1909
Epoch 7/10, Batch 30/97, Loss: 0.2410
Epoch 7/10, Batch 40/97, Loss: 0.1950
Epoch 7/10, Batch 50/97, Loss: 0.2979
Epoch 7/10, Batch 60/97, Loss: 0.2287
Epoch 7/10, Batch 70/97, Loss: 0.2995
Epoch 7/10, Batch 80/97, Loss: 0.3262
Epoch 7/10, Batch 90/97, Loss: 0.2575
Epoch 7/10, Train Loss: 0.2256, Valid Loss: 0.2507
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1541
Epoch 8/10, Batch 20/97, Loss: 0.2196
Epoch 8/10, Batch 30/97, Loss: 0.1627
Epoch 8/10, Batch 40/97, Loss: 0.1879
Epoch 8/10, Batch 50/97, Loss: 0.1832
Epoch 8/10, Batch 60/97, Loss: 0.1973
Epoch 8/10, Batch 70/97, Loss: 0.2940
Epoch 8/10, Batch 80/97, Loss: 0.2662
Epoch 8/10, Batch 90/97, Loss: 0.2469
Epoch 8/10, Train Loss: 0.2207, Valid Loss: 0.2484
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2536
Epoch 9/10, Batch 20/97, Loss: 0.1031
Epoch 9/10, Batch 30/97, Loss: 0.1450
Epoch 9/10, Batch 40/97, Loss: 0.3063
Epoch 9/10, Batch 50/97, Loss: 0.1599
Epoch 9/10, Batch 60/97, Loss: 0.3453
Epoch 9/10, Batch 70/97, Loss: 0.1662
Epoch 9/10, Batch 80/97, Loss: 0.0949
Epoch 9/10, Batch 90/97, Loss: 0.1124
Epoch 9/10, Train Loss: 0.2083, Valid Loss: 0.2479
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3129
Epoch 10/10, Batch 20/97, Loss: 0.2629
Epoch 10/10, Batch 30/97, Loss: 0.3109
Epoch 10/10, Batch 40/97, Loss: 0.1656
Epoch 10/10, Batch 50/97, Loss: 0.2270
Epoch 10/10, Batch 60/97, Loss: 0.1401
Epoch 10/10, Batch 70/97, Loss: 0.2243
Epoch 10/10, Batch 80/97, Loss: 0.2688
Epoch 10/10, Batch 90/97, Loss: 0.1972
Epoch 10/10, Train Loss: 0.2099, Valid Loss: 0.2474
Model saved!
Accuracy: 0.9159
Precision: 0.9149
Recall: 0.9159
F1-score: 0.9118
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2634
Epoch 1/10, Batch 20/97, Loss: 1.0826
Epoch 1/10, Batch 30/97, Loss: 0.7488
Epoch 1/10, Batch 40/97, Loss: 0.7230
Epoch 1/10, Batch 50/97, Loss: 0.5745
Epoch 1/10, Batch 60/97, Loss: 0.7253
Epoch 1/10, Batch 70/97, Loss: 0.6259
Epoch 1/10, Batch 80/97, Loss: 0.6512
Epoch 1/10, Batch 90/97, Loss: 0.5286
Epoch 1/10, Train Loss: 0.8038, Valid Loss: 0.4643
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5821
Epoch 2/10, Batch 20/97, Loss: 0.4738
Epoch 2/10, Batch 30/97, Loss: 0.2427
Epoch 2/10, Batch 40/97, Loss: 0.4038
Epoch 2/10, Batch 50/97, Loss: 0.4003
Epoch 2/10, Batch 60/97, Loss: 0.4299
Epoch 2/10, Batch 70/97, Loss: 0.2700
Epoch 2/10, Batch 80/97, Loss: 0.3516
Epoch 2/10, Batch 90/97, Loss: 0.4732
Epoch 2/10, Train Loss: 0.4164, Valid Loss: 0.3677
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2992
Epoch 3/10, Batch 20/97, Loss: 0.3769
Epoch 3/10, Batch 30/97, Loss: 0.3251
Epoch 3/10, Batch 40/97, Loss: 0.2468
Epoch 3/10, Batch 50/97, Loss: 0.3882
Epoch 3/10, Batch 60/97, Loss: 0.2046
Epoch 3/10, Batch 70/97, Loss: 0.3564
Epoch 3/10, Batch 80/97, Loss: 0.2767
Epoch 3/10, Batch 90/97, Loss: 0.3540
Epoch 3/10, Train Loss: 0.3336, Valid Loss: 0.3262
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4841
Epoch 4/10, Batch 20/97, Loss: 0.1819
Epoch 4/10, Batch 30/97, Loss: 0.2232
Epoch 4/10, Batch 40/97, Loss: 0.3101
Epoch 4/10, Batch 50/97, Loss: 0.4366
Epoch 4/10, Batch 60/97, Loss: 0.2956
Epoch 4/10, Batch 70/97, Loss: 0.1917
Epoch 4/10, Batch 80/97, Loss: 0.2487
Epoch 4/10, Batch 90/97, Loss: 0.2285
Epoch 4/10, Train Loss: 0.2845, Valid Loss: 0.3024
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3437
Epoch 5/10, Batch 20/97, Loss: 0.3596
Epoch 5/10, Batch 30/97, Loss: 0.2742
Epoch 5/10, Batch 40/97, Loss: 0.3196
Epoch 5/10, Batch 50/97, Loss: 0.4484
Epoch 5/10, Batch 60/97, Loss: 0.1441
Epoch 5/10, Batch 70/97, Loss: 0.2749
Epoch 5/10, Batch 80/97, Loss: 0.3166
Epoch 5/10, Batch 90/97, Loss: 0.1306
Epoch 5/10, Train Loss: 0.2619, Valid Loss: 0.2887
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1611
Epoch 6/10, Batch 20/97, Loss: 0.2403
Epoch 6/10, Batch 30/97, Loss: 0.1888
Epoch 6/10, Batch 40/97, Loss: 0.0718
Epoch 6/10, Batch 50/97, Loss: 0.2483
Epoch 6/10, Batch 60/97, Loss: 0.3634
Epoch 6/10, Batch 70/97, Loss: 0.1827
Epoch 6/10, Batch 80/97, Loss: 0.3613
Epoch 6/10, Batch 90/97, Loss: 0.2020
Epoch 6/10, Train Loss: 0.2399, Valid Loss: 0.2753
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1093
Epoch 7/10, Batch 20/97, Loss: 0.4328
Epoch 7/10, Batch 30/97, Loss: 0.1990
Epoch 7/10, Batch 40/97, Loss: 0.1518
Epoch 7/10, Batch 50/97, Loss: 0.2218
Epoch 7/10, Batch 60/97, Loss: 0.1876
Epoch 7/10, Batch 70/97, Loss: 0.4286
Epoch 7/10, Batch 80/97, Loss: 0.2238
Epoch 7/10, Batch 90/97, Loss: 0.2315
Epoch 7/10, Train Loss: 0.2258, Valid Loss: 0.2674
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1231
Epoch 8/10, Batch 20/97, Loss: 0.2613
Epoch 8/10, Batch 30/97, Loss: 0.1316
Epoch 8/10, Batch 40/97, Loss: 0.1226
Epoch 8/10, Batch 50/97, Loss: 0.1588
Epoch 8/10, Batch 60/97, Loss: 0.2895
Epoch 8/10, Batch 70/97, Loss: 0.2225
Epoch 8/10, Batch 80/97, Loss: 0.1428
Epoch 8/10, Batch 90/97, Loss: 0.1889
Epoch 8/10, Train Loss: 0.2200, Valid Loss: 0.2724
Epoch 9/10, Batch 10/97, Loss: 0.1630
Epoch 9/10, Batch 20/97, Loss: 0.1117
Epoch 9/10, Batch 30/97, Loss: 0.3338
Epoch 9/10, Batch 40/97, Loss: 0.1131
Epoch 9/10, Batch 50/97, Loss: 0.2164
Epoch 9/10, Batch 60/97, Loss: 0.2422
Epoch 9/10, Batch 70/97, Loss: 0.1728
Epoch 9/10, Batch 80/97, Loss: 0.1923
Epoch 9/10, Batch 90/97, Loss: 0.1336
Epoch 9/10, Train Loss: 0.2083, Valid Loss: 0.2573
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2472
Epoch 10/10, Batch 20/97, Loss: 0.1027
Epoch 10/10, Batch 30/97, Loss: 0.1821
Epoch 10/10, Batch 40/97, Loss: 0.1932
Epoch 10/10, Batch 50/97, Loss: 0.1875
Epoch 10/10, Batch 60/97, Loss: 0.1254
Epoch 10/10, Batch 70/97, Loss: 0.1205
Epoch 10/10, Batch 80/97, Loss: 0.1365
Epoch 10/10, Batch 90/97, Loss: 0.1889
Epoch 10/10, Train Loss: 0.1962, Valid Loss: 0.2482
Model saved!
Accuracy: 0.9182
Precision: 0.9159
Recall: 0.9182
F1-score: 0.9159
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2618
Epoch 1/10, Batch 20/97, Loss: 1.0874
Epoch 1/10, Batch 30/97, Loss: 0.7887
Epoch 1/10, Batch 40/97, Loss: 0.6734
Epoch 1/10, Batch 50/97, Loss: 0.7343
Epoch 1/10, Batch 60/97, Loss: 0.7497
Epoch 1/10, Batch 70/97, Loss: 0.6557
Epoch 1/10, Batch 80/97, Loss: 0.7147
Epoch 1/10, Batch 90/97, Loss: 0.4625
Epoch 1/10, Train Loss: 0.7973, Valid Loss: 0.4450
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6044
Epoch 2/10, Batch 20/97, Loss: 0.3380
Epoch 2/10, Batch 30/97, Loss: 0.2876
Epoch 2/10, Batch 40/97, Loss: 0.3129
Epoch 2/10, Batch 50/97, Loss: 0.5070
Epoch 2/10, Batch 60/97, Loss: 0.2353
Epoch 2/10, Batch 70/97, Loss: 0.3292
Epoch 2/10, Batch 80/97, Loss: 0.2927
Epoch 2/10, Batch 90/97, Loss: 0.4210
Epoch 2/10, Train Loss: 0.4123, Valid Loss: 0.3304
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3917
Epoch 3/10, Batch 20/97, Loss: 0.1888
Epoch 3/10, Batch 30/97, Loss: 0.3764
Epoch 3/10, Batch 40/97, Loss: 0.3338
Epoch 3/10, Batch 50/97, Loss: 0.2155
Epoch 3/10, Batch 60/97, Loss: 0.1889
Epoch 3/10, Batch 70/97, Loss: 0.3336
Epoch 3/10, Batch 80/97, Loss: 0.3809
Epoch 3/10, Batch 90/97, Loss: 0.2478
Epoch 3/10, Train Loss: 0.3240, Valid Loss: 0.2886
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3718
Epoch 4/10, Batch 20/97, Loss: 0.3078
Epoch 4/10, Batch 30/97, Loss: 0.2622
Epoch 4/10, Batch 40/97, Loss: 0.2774
Epoch 4/10, Batch 50/97, Loss: 0.2142
Epoch 4/10, Batch 60/97, Loss: 0.3301
Epoch 4/10, Batch 70/97, Loss: 0.3119
Epoch 4/10, Batch 80/97, Loss: 0.2449
Epoch 4/10, Batch 90/97, Loss: 0.3348
Epoch 4/10, Train Loss: 0.2815, Valid Loss: 0.2624
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2267
Epoch 5/10, Batch 20/97, Loss: 0.2687
Epoch 5/10, Batch 30/97, Loss: 0.2442
Epoch 5/10, Batch 40/97, Loss: 0.2593
Epoch 5/10, Batch 50/97, Loss: 0.1348
Epoch 5/10, Batch 60/97, Loss: 0.2634
Epoch 5/10, Batch 70/97, Loss: 0.1818
Epoch 5/10, Batch 80/97, Loss: 0.3130
Epoch 5/10, Batch 90/97, Loss: 0.2855
Epoch 5/10, Train Loss: 0.2652, Valid Loss: 0.2551
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2496
Epoch 6/10, Batch 20/97, Loss: 0.3703
Epoch 6/10, Batch 30/97, Loss: 0.1010
Epoch 6/10, Batch 40/97, Loss: 0.1991
Epoch 6/10, Batch 50/97, Loss: 0.1949
Epoch 6/10, Batch 60/97, Loss: 0.3372
Epoch 6/10, Batch 70/97, Loss: 0.1733
Epoch 6/10, Batch 80/97, Loss: 0.3778
Epoch 6/10, Batch 90/97, Loss: 0.3956
Epoch 6/10, Train Loss: 0.2379, Valid Loss: 0.2373
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2278
Epoch 7/10, Batch 20/97, Loss: 0.2306
Epoch 7/10, Batch 30/97, Loss: 0.2141
Epoch 7/10, Batch 40/97, Loss: 0.1957
Epoch 7/10, Batch 50/97, Loss: 0.1443
Epoch 7/10, Batch 60/97, Loss: 0.1171
Epoch 7/10, Batch 70/97, Loss: 0.2261
Epoch 7/10, Batch 80/97, Loss: 0.2052
Epoch 7/10, Batch 90/97, Loss: 0.2895
Epoch 7/10, Train Loss: 0.2219, Valid Loss: 0.2318
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2415
Epoch 8/10, Batch 20/97, Loss: 0.1130
Epoch 8/10, Batch 30/97, Loss: 0.1058
Epoch 8/10, Batch 40/97, Loss: 0.2151
Epoch 8/10, Batch 50/97, Loss: 0.1772
Epoch 8/10, Batch 60/97, Loss: 0.1895
Epoch 8/10, Batch 70/97, Loss: 0.1023
Epoch 8/10, Batch 80/97, Loss: 0.1939
Epoch 8/10, Batch 90/97, Loss: 0.2043
Epoch 8/10, Train Loss: 0.2069, Valid Loss: 0.2302
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2618
Epoch 9/10, Batch 20/97, Loss: 0.1793
Epoch 9/10, Batch 30/97, Loss: 0.2336
Epoch 9/10, Batch 40/97, Loss: 0.3519
Epoch 9/10, Batch 50/97, Loss: 0.0749
Epoch 9/10, Batch 60/97, Loss: 0.2264
Epoch 9/10, Batch 70/97, Loss: 0.1801
Epoch 9/10, Batch 80/97, Loss: 0.0407
Epoch 9/10, Batch 90/97, Loss: 0.1912
Epoch 9/10, Train Loss: 0.1974, Valid Loss: 0.2200
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2648
Epoch 10/10, Batch 20/97, Loss: 0.0770
Epoch 10/10, Batch 30/97, Loss: 0.2024
Epoch 10/10, Batch 40/97, Loss: 0.1350
Epoch 10/10, Batch 50/97, Loss: 0.1278
Epoch 10/10, Batch 60/97, Loss: 0.0961
Epoch 10/10, Batch 70/97, Loss: 0.1251
Epoch 10/10, Batch 80/97, Loss: 0.2266
Epoch 10/10, Batch 90/97, Loss: 0.2032
Epoch 10/10, Train Loss: 0.1940, Valid Loss: 0.2177
Model saved!
Accuracy: 0.9147
Precision: 0.9123
Recall: 0.9147
F1-score: 0.9124
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2284
Epoch 1/10, Batch 20/97, Loss: 1.0046
Epoch 1/10, Batch 30/97, Loss: 0.7959
Epoch 1/10, Batch 40/97, Loss: 0.6329
Epoch 1/10, Batch 50/97, Loss: 0.6135
Epoch 1/10, Batch 60/97, Loss: 0.7120
Epoch 1/10, Batch 70/97, Loss: 0.6076
Epoch 1/10, Batch 80/97, Loss: 0.5018
Epoch 1/10, Batch 90/97, Loss: 0.4848
Epoch 1/10, Train Loss: 0.7984, Valid Loss: 0.4338
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6445
Epoch 2/10, Batch 20/97, Loss: 0.4455
Epoch 2/10, Batch 30/97, Loss: 0.4989
Epoch 2/10, Batch 40/97, Loss: 0.4125
Epoch 2/10, Batch 50/97, Loss: 0.4327
Epoch 2/10, Batch 60/97, Loss: 0.3641
Epoch 2/10, Batch 70/97, Loss: 0.3904
Epoch 2/10, Batch 80/97, Loss: 0.2218
Epoch 2/10, Batch 90/97, Loss: 0.4608
Epoch 2/10, Train Loss: 0.4060, Valid Loss: 0.3222
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2626
Epoch 3/10, Batch 20/97, Loss: 0.3559
Epoch 3/10, Batch 30/97, Loss: 0.1752
Epoch 3/10, Batch 40/97, Loss: 0.2325
Epoch 3/10, Batch 50/97, Loss: 0.4750
Epoch 3/10, Batch 60/97, Loss: 0.2330
Epoch 3/10, Batch 70/97, Loss: 0.2486
Epoch 3/10, Batch 80/97, Loss: 0.3679
Epoch 3/10, Batch 90/97, Loss: 0.1953
Epoch 3/10, Train Loss: 0.3287, Valid Loss: 0.2716
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3198
Epoch 4/10, Batch 20/97, Loss: 0.2723
Epoch 4/10, Batch 30/97, Loss: 0.3886
Epoch 4/10, Batch 40/97, Loss: 0.2720
Epoch 4/10, Batch 50/97, Loss: 0.3620
Epoch 4/10, Batch 60/97, Loss: 0.3669
Epoch 4/10, Batch 70/97, Loss: 0.1647
Epoch 4/10, Batch 80/97, Loss: 0.2248
Epoch 4/10, Batch 90/97, Loss: 0.2825
Epoch 4/10, Train Loss: 0.2865, Valid Loss: 0.2546
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2452
Epoch 5/10, Batch 20/97, Loss: 0.2243
Epoch 5/10, Batch 30/97, Loss: 0.1399
Epoch 5/10, Batch 40/97, Loss: 0.2337
Epoch 5/10, Batch 50/97, Loss: 0.2557
Epoch 5/10, Batch 60/97, Loss: 0.1642
Epoch 5/10, Batch 70/97, Loss: 0.2684
Epoch 5/10, Batch 80/97, Loss: 0.2496
Epoch 5/10, Batch 90/97, Loss: 0.2169
Epoch 5/10, Train Loss: 0.2660, Valid Loss: 0.2433
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2195
Epoch 6/10, Batch 20/97, Loss: 0.3409
Epoch 6/10, Batch 30/97, Loss: 0.1851
Epoch 6/10, Batch 40/97, Loss: 0.3057
Epoch 6/10, Batch 50/97, Loss: 0.3497
Epoch 6/10, Batch 60/97, Loss: 0.2858
Epoch 6/10, Batch 70/97, Loss: 0.2263
Epoch 6/10, Batch 80/97, Loss: 0.2459
Epoch 6/10, Batch 90/97, Loss: 0.4977
Epoch 6/10, Train Loss: 0.2488, Valid Loss: 0.2241
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1946
Epoch 7/10, Batch 20/97, Loss: 0.1458
Epoch 7/10, Batch 30/97, Loss: 0.1702
Epoch 7/10, Batch 40/97, Loss: 0.1912
Epoch 7/10, Batch 50/97, Loss: 0.2695
Epoch 7/10, Batch 60/97, Loss: 0.1740
Epoch 7/10, Batch 70/97, Loss: 0.2189
Epoch 7/10, Batch 80/97, Loss: 0.1890
Epoch 7/10, Batch 90/97, Loss: 0.1499
Epoch 7/10, Train Loss: 0.2262, Valid Loss: 0.2158
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2090
Epoch 8/10, Batch 20/97, Loss: 0.1950
Epoch 8/10, Batch 30/97, Loss: 0.1822
Epoch 8/10, Batch 40/97, Loss: 0.0915
Epoch 8/10, Batch 50/97, Loss: 0.1253
Epoch 8/10, Batch 60/97, Loss: 0.1679
Epoch 8/10, Batch 70/97, Loss: 0.1636
Epoch 8/10, Batch 80/97, Loss: 0.1832
Epoch 8/10, Batch 90/97, Loss: 0.1673
Epoch 8/10, Train Loss: 0.2181, Valid Loss: 0.2135
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0926
Epoch 9/10, Batch 20/97, Loss: 0.1171
Epoch 9/10, Batch 30/97, Loss: 0.3562
Epoch 9/10, Batch 40/97, Loss: 0.1597
Epoch 9/10, Batch 50/97, Loss: 0.1626
Epoch 9/10, Batch 60/97, Loss: 0.1750
Epoch 9/10, Batch 70/97, Loss: 0.2194
Epoch 9/10, Batch 80/97, Loss: 0.1119
Epoch 9/10, Batch 90/97, Loss: 0.1346
Epoch 9/10, Train Loss: 0.2039, Valid Loss: 0.2027
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1532
Epoch 10/10, Batch 20/97, Loss: 0.0828
Epoch 10/10, Batch 30/97, Loss: 0.1816
Epoch 10/10, Batch 40/97, Loss: 0.1334
Epoch 10/10, Batch 50/97, Loss: 0.1420
Epoch 10/10, Batch 60/97, Loss: 0.3085
Epoch 10/10, Batch 70/97, Loss: 0.2521
Epoch 10/10, Batch 80/97, Loss: 0.1742
Epoch 10/10, Batch 90/97, Loss: 0.2689
Epoch 10/10, Train Loss: 0.1975, Valid Loss: 0.2168
Accuracy: 0.9182
Precision: 0.9162
Recall: 0.9182
F1-score: 0.9170
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2453
Epoch 1/10, Batch 20/97, Loss: 1.0488
Epoch 1/10, Batch 30/97, Loss: 0.7097
Epoch 1/10, Batch 40/97, Loss: 0.6523
Epoch 1/10, Batch 50/97, Loss: 0.6274
Epoch 1/10, Batch 60/97, Loss: 0.6850
Epoch 1/10, Batch 70/97, Loss: 0.7076
Epoch 1/10, Batch 80/97, Loss: 0.6495
Epoch 1/10, Batch 90/97, Loss: 0.6796
Epoch 1/10, Train Loss: 0.7891, Valid Loss: 0.4585
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5298
Epoch 2/10, Batch 20/97, Loss: 0.4191
Epoch 2/10, Batch 30/97, Loss: 0.3798
Epoch 2/10, Batch 40/97, Loss: 0.3276
Epoch 2/10, Batch 50/97, Loss: 0.5315
Epoch 2/10, Batch 60/97, Loss: 0.3873
Epoch 2/10, Batch 70/97, Loss: 0.4536
Epoch 2/10, Batch 80/97, Loss: 0.3741
Epoch 2/10, Batch 90/97, Loss: 0.4766
Epoch 2/10, Train Loss: 0.4068, Valid Loss: 0.3580
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2713
Epoch 3/10, Batch 20/97, Loss: 0.3264
Epoch 3/10, Batch 30/97, Loss: 0.3636
Epoch 3/10, Batch 40/97, Loss: 0.2352
Epoch 3/10, Batch 50/97, Loss: 0.3453
Epoch 3/10, Batch 60/97, Loss: 0.2836
Epoch 3/10, Batch 70/97, Loss: 0.3866
Epoch 3/10, Batch 80/97, Loss: 0.2037
Epoch 3/10, Batch 90/97, Loss: 0.2680
Epoch 3/10, Train Loss: 0.3244, Valid Loss: 0.3181
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3607
Epoch 4/10, Batch 20/97, Loss: 0.2568
Epoch 4/10, Batch 30/97, Loss: 0.1728
Epoch 4/10, Batch 40/97, Loss: 0.2573
Epoch 4/10, Batch 50/97, Loss: 0.4793
Epoch 4/10, Batch 60/97, Loss: 0.2207
Epoch 4/10, Batch 70/97, Loss: 0.2532
Epoch 4/10, Batch 80/97, Loss: 0.2786
Epoch 4/10, Batch 90/97, Loss: 0.3194
Epoch 4/10, Train Loss: 0.2806, Valid Loss: 0.3001
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2079
Epoch 5/10, Batch 20/97, Loss: 0.2700
Epoch 5/10, Batch 30/97, Loss: 0.1807
Epoch 5/10, Batch 40/97, Loss: 0.2592
Epoch 5/10, Batch 50/97, Loss: 0.3999
Epoch 5/10, Batch 60/97, Loss: 0.2148
Epoch 5/10, Batch 70/97, Loss: 0.2150
Epoch 5/10, Batch 80/97, Loss: 0.1725
Epoch 5/10, Batch 90/97, Loss: 0.2022
Epoch 5/10, Train Loss: 0.2635, Valid Loss: 0.2846
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3627
Epoch 6/10, Batch 20/97, Loss: 0.2356
Epoch 6/10, Batch 30/97, Loss: 0.2021
Epoch 6/10, Batch 40/97, Loss: 0.2555
Epoch 6/10, Batch 50/97, Loss: 0.2410
Epoch 6/10, Batch 60/97, Loss: 0.1871
Epoch 6/10, Batch 70/97, Loss: 0.1644
Epoch 6/10, Batch 80/97, Loss: 0.2294
Epoch 6/10, Batch 90/97, Loss: 0.3664
Epoch 6/10, Train Loss: 0.2388, Valid Loss: 0.2749
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3038
Epoch 7/10, Batch 20/97, Loss: 0.3194
Epoch 7/10, Batch 30/97, Loss: 0.1104
Epoch 7/10, Batch 40/97, Loss: 0.1327
Epoch 7/10, Batch 50/97, Loss: 0.2934
Epoch 7/10, Batch 60/97, Loss: 0.2765
Epoch 7/10, Batch 70/97, Loss: 0.1865
Epoch 7/10, Batch 80/97, Loss: 0.3110
Epoch 7/10, Batch 90/97, Loss: 0.1740
Epoch 7/10, Train Loss: 0.2184, Valid Loss: 0.2645
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.0900
Epoch 8/10, Batch 20/97, Loss: 0.1929
Epoch 8/10, Batch 30/97, Loss: 0.1644
Epoch 8/10, Batch 40/97, Loss: 0.1842
Epoch 8/10, Batch 50/97, Loss: 0.2898
Epoch 8/10, Batch 60/97, Loss: 0.1955
Epoch 8/10, Batch 70/97, Loss: 0.1777
Epoch 8/10, Batch 80/97, Loss: 0.1108
Epoch 8/10, Batch 90/97, Loss: 0.1346
Epoch 8/10, Train Loss: 0.2168, Valid Loss: 0.2620
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1817
Epoch 9/10, Batch 20/97, Loss: 0.1027
Epoch 9/10, Batch 30/97, Loss: 0.1682
Epoch 9/10, Batch 40/97, Loss: 0.2521
Epoch 9/10, Batch 50/97, Loss: 0.0968
Epoch 9/10, Batch 60/97, Loss: 0.1445
Epoch 9/10, Batch 70/97, Loss: 0.2066
Epoch 9/10, Batch 80/97, Loss: 0.1713
Epoch 9/10, Batch 90/97, Loss: 0.1246
Epoch 9/10, Train Loss: 0.1972, Valid Loss: 0.2599
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2188
Epoch 10/10, Batch 20/97, Loss: 0.1901
Epoch 10/10, Batch 30/97, Loss: 0.1002
Epoch 10/10, Batch 40/97, Loss: 0.2336
Epoch 10/10, Batch 50/97, Loss: 0.1593
Epoch 10/10, Batch 60/97, Loss: 0.1237
Epoch 10/10, Batch 70/97, Loss: 0.2886
Epoch 10/10, Batch 80/97, Loss: 0.1795
Epoch 10/10, Batch 90/97, Loss: 0.1233
Epoch 10/10, Train Loss: 0.1952, Valid Loss: 0.2501
Model saved!
Accuracy: 0.9136
Precision: 0.9106
Recall: 0.9136
F1-score: 0.9117
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.1973
Epoch 1/10, Batch 20/97, Loss: 1.1534
Epoch 1/10, Batch 30/97, Loss: 0.7450
Epoch 1/10, Batch 40/97, Loss: 0.7133
Epoch 1/10, Batch 50/97, Loss: 0.6450
Epoch 1/10, Batch 60/97, Loss: 0.8284
Epoch 1/10, Batch 70/97, Loss: 0.6788
Epoch 1/10, Batch 80/97, Loss: 0.5980
Epoch 1/10, Batch 90/97, Loss: 0.6208
Epoch 1/10, Train Loss: 0.8088, Valid Loss: 0.4420
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6045
Epoch 2/10, Batch 20/97, Loss: 0.4790
Epoch 2/10, Batch 30/97, Loss: 0.3784
Epoch 2/10, Batch 40/97, Loss: 0.4205
Epoch 2/10, Batch 50/97, Loss: 0.4240
Epoch 2/10, Batch 60/97, Loss: 0.3547
Epoch 2/10, Batch 70/97, Loss: 0.2359
Epoch 2/10, Batch 80/97, Loss: 0.3753
Epoch 2/10, Batch 90/97, Loss: 0.4996
Epoch 2/10, Train Loss: 0.4222, Valid Loss: 0.3331
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3338
Epoch 3/10, Batch 20/97, Loss: 0.2800
Epoch 3/10, Batch 30/97, Loss: 0.3744
Epoch 3/10, Batch 40/97, Loss: 0.3475
Epoch 3/10, Batch 50/97, Loss: 0.4014
Epoch 3/10, Batch 60/97, Loss: 0.2124
Epoch 3/10, Batch 70/97, Loss: 0.3856
Epoch 3/10, Batch 80/97, Loss: 0.2706
Epoch 3/10, Batch 90/97, Loss: 0.3004
Epoch 3/10, Train Loss: 0.3352, Valid Loss: 0.2902
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3048
Epoch 4/10, Batch 20/97, Loss: 0.2379
Epoch 4/10, Batch 30/97, Loss: 0.3496
Epoch 4/10, Batch 40/97, Loss: 0.0952
Epoch 4/10, Batch 50/97, Loss: 0.2584
Epoch 4/10, Batch 60/97, Loss: 0.3026
Epoch 4/10, Batch 70/97, Loss: 0.2794
Epoch 4/10, Batch 80/97, Loss: 0.3397
Epoch 4/10, Batch 90/97, Loss: 0.2616
Epoch 4/10, Train Loss: 0.2796, Valid Loss: 0.2874
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1897
Epoch 5/10, Batch 20/97, Loss: 0.3131
Epoch 5/10, Batch 30/97, Loss: 0.3148
Epoch 5/10, Batch 40/97, Loss: 0.2948
Epoch 5/10, Batch 50/97, Loss: 0.1660
Epoch 5/10, Batch 60/97, Loss: 0.2269
Epoch 5/10, Batch 70/97, Loss: 0.2829
Epoch 5/10, Batch 80/97, Loss: 0.3110
Epoch 5/10, Batch 90/97, Loss: 0.1254
Epoch 5/10, Train Loss: 0.2644, Valid Loss: 0.2614
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1901
Epoch 6/10, Batch 20/97, Loss: 0.4168
Epoch 6/10, Batch 30/97, Loss: 0.2176
Epoch 6/10, Batch 40/97, Loss: 0.2249
Epoch 6/10, Batch 50/97, Loss: 0.2437
Epoch 6/10, Batch 60/97, Loss: 0.1947
Epoch 6/10, Batch 70/97, Loss: 0.3344
Epoch 6/10, Batch 80/97, Loss: 0.3909
Epoch 6/10, Batch 90/97, Loss: 0.2669
Epoch 6/10, Train Loss: 0.2468, Valid Loss: 0.2506
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2184
Epoch 7/10, Batch 20/97, Loss: 0.1462
Epoch 7/10, Batch 30/97, Loss: 0.2892
Epoch 7/10, Batch 40/97, Loss: 0.1350
Epoch 7/10, Batch 50/97, Loss: 0.3700
Epoch 7/10, Batch 60/97, Loss: 0.3176
Epoch 7/10, Batch 70/97, Loss: 0.2880
Epoch 7/10, Batch 80/97, Loss: 0.0953
Epoch 7/10, Batch 90/97, Loss: 0.1577
Epoch 7/10, Train Loss: 0.2196, Valid Loss: 0.2497
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.3234
Epoch 8/10, Batch 20/97, Loss: 0.1330
Epoch 8/10, Batch 30/97, Loss: 0.2221
Epoch 8/10, Batch 40/97, Loss: 0.4469
Epoch 8/10, Batch 50/97, Loss: 0.1785
Epoch 8/10, Batch 60/97, Loss: 0.1697
Epoch 8/10, Batch 70/97, Loss: 0.2549
Epoch 8/10, Batch 80/97, Loss: 0.1407
Epoch 8/10, Batch 90/97, Loss: 0.1526
Epoch 8/10, Train Loss: 0.2139, Valid Loss: 0.2443
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1556
Epoch 9/10, Batch 20/97, Loss: 0.2027
Epoch 9/10, Batch 30/97, Loss: 0.1852
Epoch 9/10, Batch 40/97, Loss: 0.3308
Epoch 9/10, Batch 50/97, Loss: 0.2076
Epoch 9/10, Batch 60/97, Loss: 0.1856
Epoch 9/10, Batch 70/97, Loss: 0.1219
Epoch 9/10, Batch 80/97, Loss: 0.1847
Epoch 9/10, Batch 90/97, Loss: 0.2215
Epoch 9/10, Train Loss: 0.2053, Valid Loss: 0.2354
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1832
Epoch 10/10, Batch 20/97, Loss: 0.1321
Epoch 10/10, Batch 30/97, Loss: 0.3034
Epoch 10/10, Batch 40/97, Loss: 0.0940
Epoch 10/10, Batch 50/97, Loss: 0.1741
Epoch 10/10, Batch 60/97, Loss: 0.1299
Epoch 10/10, Batch 70/97, Loss: 0.2470
Epoch 10/10, Batch 80/97, Loss: 0.1950
Epoch 10/10, Batch 90/97, Loss: 0.1295
Epoch 10/10, Train Loss: 0.2011, Valid Loss: 0.2374
Accuracy: 0.9206
Precision: 0.9187
Recall: 0.9206
F1-score: 0.9194
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2969
Epoch 1/10, Batch 20/97, Loss: 1.0615
Epoch 1/10, Batch 30/97, Loss: 0.7823
Epoch 1/10, Batch 40/97, Loss: 0.6982
Epoch 1/10, Batch 50/97, Loss: 0.5166
Epoch 1/10, Batch 60/97, Loss: 0.6632
Epoch 1/10, Batch 70/97, Loss: 0.7988
Epoch 1/10, Batch 80/97, Loss: 0.6656
Epoch 1/10, Batch 90/97, Loss: 0.5219
Epoch 1/10, Train Loss: 0.8100, Valid Loss: 0.4598
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4132
Epoch 2/10, Batch 20/97, Loss: 0.3668
Epoch 2/10, Batch 30/97, Loss: 0.3540
Epoch 2/10, Batch 40/97, Loss: 0.3452
Epoch 2/10, Batch 50/97, Loss: 0.5078
Epoch 2/10, Batch 60/97, Loss: 0.4140
Epoch 2/10, Batch 70/97, Loss: 0.2299
Epoch 2/10, Batch 80/97, Loss: 0.3792
Epoch 2/10, Batch 90/97, Loss: 0.4904
Epoch 2/10, Train Loss: 0.4150, Valid Loss: 0.3460
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3116
Epoch 3/10, Batch 20/97, Loss: 0.3068
Epoch 3/10, Batch 30/97, Loss: 0.3252
Epoch 3/10, Batch 40/97, Loss: 0.2353
Epoch 3/10, Batch 50/97, Loss: 0.4142
Epoch 3/10, Batch 60/97, Loss: 0.2348
Epoch 3/10, Batch 70/97, Loss: 0.3690
Epoch 3/10, Batch 80/97, Loss: 0.3043
Epoch 3/10, Batch 90/97, Loss: 0.4059
Epoch 3/10, Train Loss: 0.3357, Valid Loss: 0.3086
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4396
Epoch 4/10, Batch 20/97, Loss: 0.2447
Epoch 4/10, Batch 30/97, Loss: 0.3207
Epoch 4/10, Batch 40/97, Loss: 0.2192
Epoch 4/10, Batch 50/97, Loss: 0.2857
Epoch 4/10, Batch 60/97, Loss: 0.2368
Epoch 4/10, Batch 70/97, Loss: 0.2898
Epoch 4/10, Batch 80/97, Loss: 0.2195
Epoch 4/10, Batch 90/97, Loss: 0.2876
Epoch 4/10, Train Loss: 0.2858, Valid Loss: 0.2878
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.4137
Epoch 5/10, Batch 20/97, Loss: 0.3104
Epoch 5/10, Batch 30/97, Loss: 0.3026
Epoch 5/10, Batch 40/97, Loss: 0.3422
Epoch 5/10, Batch 50/97, Loss: 0.2040
Epoch 5/10, Batch 60/97, Loss: 0.2613
Epoch 5/10, Batch 70/97, Loss: 0.3080
Epoch 5/10, Batch 80/97, Loss: 0.1344
Epoch 5/10, Batch 90/97, Loss: 0.1365
Epoch 5/10, Train Loss: 0.2590, Valid Loss: 0.2800
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2001
Epoch 6/10, Batch 20/97, Loss: 0.2620
Epoch 6/10, Batch 30/97, Loss: 0.1959
Epoch 6/10, Batch 40/97, Loss: 0.2365
Epoch 6/10, Batch 50/97, Loss: 0.1579
Epoch 6/10, Batch 60/97, Loss: 0.1737
Epoch 6/10, Batch 70/97, Loss: 0.1707
Epoch 6/10, Batch 80/97, Loss: 0.4668
Epoch 6/10, Batch 90/97, Loss: 0.3286
Epoch 6/10, Train Loss: 0.2414, Valid Loss: 0.2663
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2189
Epoch 7/10, Batch 20/97, Loss: 0.3504
Epoch 7/10, Batch 30/97, Loss: 0.1618
Epoch 7/10, Batch 40/97, Loss: 0.2875
Epoch 7/10, Batch 50/97, Loss: 0.1387
Epoch 7/10, Batch 60/97, Loss: 0.1471
Epoch 7/10, Batch 70/97, Loss: 0.3548
Epoch 7/10, Batch 80/97, Loss: 0.2055
Epoch 7/10, Batch 90/97, Loss: 0.2491
Epoch 7/10, Train Loss: 0.2235, Valid Loss: 0.2564
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1354
Epoch 8/10, Batch 20/97, Loss: 0.1747
Epoch 8/10, Batch 30/97, Loss: 0.1356
Epoch 8/10, Batch 40/97, Loss: 0.2174
Epoch 8/10, Batch 50/97, Loss: 0.1887
Epoch 8/10, Batch 60/97, Loss: 0.1675
Epoch 8/10, Batch 70/97, Loss: 0.1573
Epoch 8/10, Batch 80/97, Loss: 0.1609
Epoch 8/10, Batch 90/97, Loss: 0.2359
Epoch 8/10, Train Loss: 0.2208, Valid Loss: 0.2501
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0758
Epoch 9/10, Batch 20/97, Loss: 0.2320
Epoch 9/10, Batch 30/97, Loss: 0.3167
Epoch 9/10, Batch 40/97, Loss: 0.3571
Epoch 9/10, Batch 50/97, Loss: 0.0994
Epoch 9/10, Batch 60/97, Loss: 0.2147
Epoch 9/10, Batch 70/97, Loss: 0.1540
Epoch 9/10, Batch 80/97, Loss: 0.1279
Epoch 9/10, Batch 90/97, Loss: 0.1821
Epoch 9/10, Train Loss: 0.2052, Valid Loss: 0.2496
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1385
Epoch 10/10, Batch 20/97, Loss: 0.2393
Epoch 10/10, Batch 30/97, Loss: 0.2105
Epoch 10/10, Batch 40/97, Loss: 0.1346
Epoch 10/10, Batch 50/97, Loss: 0.1540
Epoch 10/10, Batch 60/97, Loss: 0.1456
Epoch 10/10, Batch 70/97, Loss: 0.3119
Epoch 10/10, Batch 80/97, Loss: 0.1213
Epoch 10/10, Batch 90/97, Loss: 0.1586
Epoch 10/10, Train Loss: 0.2032, Valid Loss: 0.2565
Accuracy: 0.9159
Precision: 0.9129
Recall: 0.9159
F1-score: 0.9137
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.1977
Epoch 1/10, Batch 20/97, Loss: 1.1089
Epoch 1/10, Batch 30/97, Loss: 0.7565
Epoch 1/10, Batch 40/97, Loss: 0.6383
Epoch 1/10, Batch 50/97, Loss: 0.5830
Epoch 1/10, Batch 60/97, Loss: 0.7292
Epoch 1/10, Batch 70/97, Loss: 0.5774
Epoch 1/10, Batch 80/97, Loss: 0.6095
Epoch 1/10, Batch 90/97, Loss: 0.5512
Epoch 1/10, Train Loss: 0.8015, Valid Loss: 0.4386
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4615
Epoch 2/10, Batch 20/97, Loss: 0.4820
Epoch 2/10, Batch 30/97, Loss: 0.4484
Epoch 2/10, Batch 40/97, Loss: 0.4010
Epoch 2/10, Batch 50/97, Loss: 0.4165
Epoch 2/10, Batch 60/97, Loss: 0.3777
Epoch 2/10, Batch 70/97, Loss: 0.3222
Epoch 2/10, Batch 80/97, Loss: 0.3189
Epoch 2/10, Batch 90/97, Loss: 0.5492
Epoch 2/10, Train Loss: 0.4066, Valid Loss: 0.3271
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2690
Epoch 3/10, Batch 20/97, Loss: 0.2239
Epoch 3/10, Batch 30/97, Loss: 0.3424
Epoch 3/10, Batch 40/97, Loss: 0.2585
Epoch 3/10, Batch 50/97, Loss: 0.3641
Epoch 3/10, Batch 60/97, Loss: 0.1985
Epoch 3/10, Batch 70/97, Loss: 0.3935
Epoch 3/10, Batch 80/97, Loss: 0.2929
Epoch 3/10, Batch 90/97, Loss: 0.3460
Epoch 3/10, Train Loss: 0.3388, Valid Loss: 0.2841
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4519
Epoch 4/10, Batch 20/97, Loss: 0.2735
Epoch 4/10, Batch 30/97, Loss: 0.3652
Epoch 4/10, Batch 40/97, Loss: 0.3758
Epoch 4/10, Batch 50/97, Loss: 0.3127
Epoch 4/10, Batch 60/97, Loss: 0.3859
Epoch 4/10, Batch 70/97, Loss: 0.2761
Epoch 4/10, Batch 80/97, Loss: 0.3978
Epoch 4/10, Batch 90/97, Loss: 0.2883
Epoch 4/10, Train Loss: 0.2857, Valid Loss: 0.2680
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3863
Epoch 5/10, Batch 20/97, Loss: 0.2161
Epoch 5/10, Batch 30/97, Loss: 0.1324
Epoch 5/10, Batch 40/97, Loss: 0.1661
Epoch 5/10, Batch 50/97, Loss: 0.1748
Epoch 5/10, Batch 60/97, Loss: 0.2161
Epoch 5/10, Batch 70/97, Loss: 0.3940
Epoch 5/10, Batch 80/97, Loss: 0.1657
Epoch 5/10, Batch 90/97, Loss: 0.2359
Epoch 5/10, Train Loss: 0.2622, Valid Loss: 0.2607
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1604
Epoch 6/10, Batch 20/97, Loss: 0.2154
Epoch 6/10, Batch 30/97, Loss: 0.2224
Epoch 6/10, Batch 40/97, Loss: 0.1807
Epoch 6/10, Batch 50/97, Loss: 0.1801
Epoch 6/10, Batch 60/97, Loss: 0.1655
Epoch 6/10, Batch 70/97, Loss: 0.2482
Epoch 6/10, Batch 80/97, Loss: 0.2076
Epoch 6/10, Batch 90/97, Loss: 0.2548
Epoch 6/10, Train Loss: 0.2480, Valid Loss: 0.2387
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2244
Epoch 7/10, Batch 20/97, Loss: 0.2189
Epoch 7/10, Batch 30/97, Loss: 0.2434
Epoch 7/10, Batch 40/97, Loss: 0.1609
Epoch 7/10, Batch 50/97, Loss: 0.1729
Epoch 7/10, Batch 60/97, Loss: 0.1426
Epoch 7/10, Batch 70/97, Loss: 0.2032
Epoch 7/10, Batch 80/97, Loss: 0.2416
Epoch 7/10, Batch 90/97, Loss: 0.1784
Epoch 7/10, Train Loss: 0.2199, Valid Loss: 0.2329
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.0839
Epoch 8/10, Batch 20/97, Loss: 0.2293
Epoch 8/10, Batch 30/97, Loss: 0.1678
Epoch 8/10, Batch 40/97, Loss: 0.1642
Epoch 8/10, Batch 50/97, Loss: 0.2156
Epoch 8/10, Batch 60/97, Loss: 0.1481
Epoch 8/10, Batch 70/97, Loss: 0.1880
Epoch 8/10, Batch 80/97, Loss: 0.1477
Epoch 8/10, Batch 90/97, Loss: 0.2130
Epoch 8/10, Train Loss: 0.2154, Valid Loss: 0.2300
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1641
Epoch 9/10, Batch 20/97, Loss: 0.1745
Epoch 9/10, Batch 30/97, Loss: 0.1733
Epoch 9/10, Batch 40/97, Loss: 0.2733
Epoch 9/10, Batch 50/97, Loss: 0.2417
Epoch 9/10, Batch 60/97, Loss: 0.2347
Epoch 9/10, Batch 70/97, Loss: 0.2622
Epoch 9/10, Batch 80/97, Loss: 0.0843
Epoch 9/10, Batch 90/97, Loss: 0.1523
Epoch 9/10, Train Loss: 0.2086, Valid Loss: 0.2310
Epoch 10/10, Batch 10/97, Loss: 0.2830
Epoch 10/10, Batch 20/97, Loss: 0.2677
Epoch 10/10, Batch 30/97, Loss: 0.2219
Epoch 10/10, Batch 40/97, Loss: 0.1114
Epoch 10/10, Batch 50/97, Loss: 0.1563
Epoch 10/10, Batch 60/97, Loss: 0.1909
Epoch 10/10, Batch 70/97, Loss: 0.3530
Epoch 10/10, Batch 80/97, Loss: 0.1857
Epoch 10/10, Batch 90/97, Loss: 0.0919
Epoch 10/10, Train Loss: 0.1963, Valid Loss: 0.2275
Model saved!
Accuracy: 0.9182
Precision: 0.9153
Recall: 0.9182
F1-score: 0.9154
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2739
Epoch 1/10, Batch 20/97, Loss: 1.1060
Epoch 1/10, Batch 30/97, Loss: 0.7141
Epoch 1/10, Batch 40/97, Loss: 0.7810
Epoch 1/10, Batch 50/97, Loss: 0.6970
Epoch 1/10, Batch 60/97, Loss: 0.6723
Epoch 1/10, Batch 70/97, Loss: 0.6218
Epoch 1/10, Batch 80/97, Loss: 0.6152
Epoch 1/10, Batch 90/97, Loss: 0.5821
Epoch 1/10, Train Loss: 0.7958, Valid Loss: 0.4605
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5187
Epoch 2/10, Batch 20/97, Loss: 0.4880
Epoch 2/10, Batch 30/97, Loss: 0.3365
Epoch 2/10, Batch 40/97, Loss: 0.2619
Epoch 2/10, Batch 50/97, Loss: 0.3585
Epoch 2/10, Batch 60/97, Loss: 0.4073
Epoch 2/10, Batch 70/97, Loss: 0.3317
Epoch 2/10, Batch 80/97, Loss: 0.4033
Epoch 2/10, Batch 90/97, Loss: 0.2885
Epoch 2/10, Train Loss: 0.4106, Valid Loss: 0.3577
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4120
Epoch 3/10, Batch 20/97, Loss: 0.3287
Epoch 3/10, Batch 30/97, Loss: 0.3292
Epoch 3/10, Batch 40/97, Loss: 0.1935
Epoch 3/10, Batch 50/97, Loss: 0.2979
Epoch 3/10, Batch 60/97, Loss: 0.2500
Epoch 3/10, Batch 70/97, Loss: 0.2123
Epoch 3/10, Batch 80/97, Loss: 0.3239
Epoch 3/10, Batch 90/97, Loss: 0.2464
Epoch 3/10, Train Loss: 0.3332, Valid Loss: 0.3170
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2783
Epoch 4/10, Batch 20/97, Loss: 0.1445
Epoch 4/10, Batch 30/97, Loss: 0.1714
Epoch 4/10, Batch 40/97, Loss: 0.2738
Epoch 4/10, Batch 50/97, Loss: 0.2752
Epoch 4/10, Batch 60/97, Loss: 0.2818
Epoch 4/10, Batch 70/97, Loss: 0.2600
Epoch 4/10, Batch 80/97, Loss: 0.1829
Epoch 4/10, Batch 90/97, Loss: 0.3309
Epoch 4/10, Train Loss: 0.2787, Valid Loss: 0.3053
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3465
Epoch 5/10, Batch 20/97, Loss: 0.2351
Epoch 5/10, Batch 30/97, Loss: 0.1664
Epoch 5/10, Batch 40/97, Loss: 0.3305
Epoch 5/10, Batch 50/97, Loss: 0.2285
Epoch 5/10, Batch 60/97, Loss: 0.2433
Epoch 5/10, Batch 70/97, Loss: 0.2583
Epoch 5/10, Batch 80/97, Loss: 0.1984
Epoch 5/10, Batch 90/97, Loss: 0.3071
Epoch 5/10, Train Loss: 0.2688, Valid Loss: 0.2912
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1124
Epoch 6/10, Batch 20/97, Loss: 0.2554
Epoch 6/10, Batch 30/97, Loss: 0.1476
Epoch 6/10, Batch 40/97, Loss: 0.1506
Epoch 6/10, Batch 50/97, Loss: 0.1141
Epoch 6/10, Batch 60/97, Loss: 0.4217
Epoch 6/10, Batch 70/97, Loss: 0.2797
Epoch 6/10, Batch 80/97, Loss: 0.4069
Epoch 6/10, Batch 90/97, Loss: 0.3488
Epoch 6/10, Train Loss: 0.2470, Valid Loss: 0.2796
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1382
Epoch 7/10, Batch 20/97, Loss: 0.1777
Epoch 7/10, Batch 30/97, Loss: 0.2454
Epoch 7/10, Batch 40/97, Loss: 0.1085
Epoch 7/10, Batch 50/97, Loss: 0.1256
Epoch 7/10, Batch 60/97, Loss: 0.1460
Epoch 7/10, Batch 70/97, Loss: 0.1882
Epoch 7/10, Batch 80/97, Loss: 0.1745
Epoch 7/10, Batch 90/97, Loss: 0.2006
Epoch 7/10, Train Loss: 0.2200, Valid Loss: 0.2625
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1466
Epoch 8/10, Batch 20/97, Loss: 0.0953
Epoch 8/10, Batch 30/97, Loss: 0.2095
Epoch 8/10, Batch 40/97, Loss: 0.1791
Epoch 8/10, Batch 50/97, Loss: 0.3211
Epoch 8/10, Batch 60/97, Loss: 0.1333
Epoch 8/10, Batch 70/97, Loss: 0.2443
Epoch 8/10, Batch 80/97, Loss: 0.1375
Epoch 8/10, Batch 90/97, Loss: 0.1982
Epoch 8/10, Train Loss: 0.2054, Valid Loss: 0.2646
Epoch 9/10, Batch 10/97, Loss: 0.0846
Epoch 9/10, Batch 20/97, Loss: 0.1621
Epoch 9/10, Batch 30/97, Loss: 0.2732
Epoch 9/10, Batch 40/97, Loss: 0.1082
Epoch 9/10, Batch 50/97, Loss: 0.1971
Epoch 9/10, Batch 60/97, Loss: 0.1752
Epoch 9/10, Batch 70/97, Loss: 0.1037
Epoch 9/10, Batch 80/97, Loss: 0.3106
Epoch 9/10, Batch 90/97, Loss: 0.1388
Epoch 9/10, Train Loss: 0.2064, Valid Loss: 0.2615
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1578
Epoch 10/10, Batch 20/97, Loss: 0.1029
Epoch 10/10, Batch 30/97, Loss: 0.2090
Epoch 10/10, Batch 40/97, Loss: 0.1192
Epoch 10/10, Batch 50/97, Loss: 0.2342
Epoch 10/10, Batch 60/97, Loss: 0.1409
Epoch 10/10, Batch 70/97, Loss: 0.3363
Epoch 10/10, Batch 80/97, Loss: 0.1672
Epoch 10/10, Batch 90/97, Loss: 0.1810
Epoch 10/10, Train Loss: 0.1925, Valid Loss: 0.2592
Model saved!
Accuracy: 0.9124
Precision: 0.9090
Recall: 0.9124
F1-score: 0.9091
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2969
Epoch 1/10, Batch 20/97, Loss: 1.0841
Epoch 1/10, Batch 30/97, Loss: 0.7989
Epoch 1/10, Batch 40/97, Loss: 0.7967
Epoch 1/10, Batch 50/97, Loss: 0.7547
Epoch 1/10, Batch 60/97, Loss: 0.7555
Epoch 1/10, Batch 70/97, Loss: 0.6323
Epoch 1/10, Batch 80/97, Loss: 0.6687
Epoch 1/10, Batch 90/97, Loss: 0.5422
Epoch 1/10, Train Loss: 0.8137, Valid Loss: 0.4644
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5164
Epoch 2/10, Batch 20/97, Loss: 0.3887
Epoch 2/10, Batch 30/97, Loss: 0.3275
Epoch 2/10, Batch 40/97, Loss: 0.3173
Epoch 2/10, Batch 50/97, Loss: 0.4008
Epoch 2/10, Batch 60/97, Loss: 0.3181
Epoch 2/10, Batch 70/97, Loss: 0.2816
Epoch 2/10, Batch 80/97, Loss: 0.3725
Epoch 2/10, Batch 90/97, Loss: 0.3883
Epoch 2/10, Train Loss: 0.4250, Valid Loss: 0.3547
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4113
Epoch 3/10, Batch 20/97, Loss: 0.4897
Epoch 3/10, Batch 30/97, Loss: 0.3019
Epoch 3/10, Batch 40/97, Loss: 0.2209
Epoch 3/10, Batch 50/97, Loss: 0.4613
Epoch 3/10, Batch 60/97, Loss: 0.2114
Epoch 3/10, Batch 70/97, Loss: 0.3481
Epoch 3/10, Batch 80/97, Loss: 0.2775
Epoch 3/10, Batch 90/97, Loss: 0.3539
Epoch 3/10, Train Loss: 0.3399, Valid Loss: 0.3101
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3271
Epoch 4/10, Batch 20/97, Loss: 0.2178
Epoch 4/10, Batch 30/97, Loss: 0.2367
Epoch 4/10, Batch 40/97, Loss: 0.2693
Epoch 4/10, Batch 50/97, Loss: 0.3968
Epoch 4/10, Batch 60/97, Loss: 0.3698
Epoch 4/10, Batch 70/97, Loss: 0.4004
Epoch 4/10, Batch 80/97, Loss: 0.3301
Epoch 4/10, Batch 90/97, Loss: 0.2585
Epoch 4/10, Train Loss: 0.2918, Valid Loss: 0.2897
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2888
Epoch 5/10, Batch 20/97, Loss: 0.2593
Epoch 5/10, Batch 30/97, Loss: 0.4314
Epoch 5/10, Batch 40/97, Loss: 0.2005
Epoch 5/10, Batch 50/97, Loss: 0.2484
Epoch 5/10, Batch 60/97, Loss: 0.2498
Epoch 5/10, Batch 70/97, Loss: 0.2301
Epoch 5/10, Batch 80/97, Loss: 0.3597
Epoch 5/10, Batch 90/97, Loss: 0.1956
Epoch 5/10, Train Loss: 0.2751, Valid Loss: 0.2757
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1765
Epoch 6/10, Batch 20/97, Loss: 0.4171
Epoch 6/10, Batch 30/97, Loss: 0.1740
Epoch 6/10, Batch 40/97, Loss: 0.2419
Epoch 6/10, Batch 50/97, Loss: 0.1535
Epoch 6/10, Batch 60/97, Loss: 0.2829
Epoch 6/10, Batch 70/97, Loss: 0.1451
Epoch 6/10, Batch 80/97, Loss: 0.4556
Epoch 6/10, Batch 90/97, Loss: 0.5512
Epoch 6/10, Train Loss: 0.2623, Valid Loss: 0.2632
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1709
Epoch 7/10, Batch 20/97, Loss: 0.2506
Epoch 7/10, Batch 30/97, Loss: 0.1065
Epoch 7/10, Batch 40/97, Loss: 0.2069
Epoch 7/10, Batch 50/97, Loss: 0.2275
Epoch 7/10, Batch 60/97, Loss: 0.1722
Epoch 7/10, Batch 70/97, Loss: 0.2599
Epoch 7/10, Batch 80/97, Loss: 0.1994
Epoch 7/10, Batch 90/97, Loss: 0.2707
Epoch 7/10, Train Loss: 0.2250, Valid Loss: 0.2578
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1629
Epoch 8/10, Batch 20/97, Loss: 0.2638
Epoch 8/10, Batch 30/97, Loss: 0.1722
Epoch 8/10, Batch 40/97, Loss: 0.2939
Epoch 8/10, Batch 50/97, Loss: 0.3079
Epoch 8/10, Batch 60/97, Loss: 0.2727
Epoch 8/10, Batch 70/97, Loss: 0.3080
Epoch 8/10, Batch 80/97, Loss: 0.0748
Epoch 8/10, Batch 90/97, Loss: 0.1152
Epoch 8/10, Train Loss: 0.2297, Valid Loss: 0.2613
Epoch 9/10, Batch 10/97, Loss: 0.0991
Epoch 9/10, Batch 20/97, Loss: 0.1807
Epoch 9/10, Batch 30/97, Loss: 0.2111
Epoch 9/10, Batch 40/97, Loss: 0.1895
Epoch 9/10, Batch 50/97, Loss: 0.2667
Epoch 9/10, Batch 60/97, Loss: 0.2363
Epoch 9/10, Batch 70/97, Loss: 0.1020
Epoch 9/10, Batch 80/97, Loss: 0.1143
Epoch 9/10, Batch 90/97, Loss: 0.1759
Epoch 9/10, Train Loss: 0.2118, Valid Loss: 0.2592
Epoch 10/10, Batch 10/97, Loss: 0.3310
Epoch 10/10, Batch 20/97, Loss: 0.2126
Epoch 10/10, Batch 30/97, Loss: 0.2745
Epoch 10/10, Batch 40/97, Loss: 0.1921
Epoch 10/10, Batch 50/97, Loss: 0.1411
Epoch 10/10, Batch 60/97, Loss: 0.2525
Epoch 10/10, Batch 70/97, Loss: 0.1913
Epoch 10/10, Batch 80/97, Loss: 0.2305
Epoch 10/10, Batch 90/97, Loss: 0.1405
Epoch 10/10, Train Loss: 0.2067, Valid Loss: 0.2500
Model saved!
Accuracy: 0.9182
Precision: 0.9160
Recall: 0.9182
F1-score: 0.9155
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2729
Epoch 1/10, Batch 20/97, Loss: 1.0737
Epoch 1/10, Batch 30/97, Loss: 0.7095
Epoch 1/10, Batch 40/97, Loss: 0.7898
Epoch 1/10, Batch 50/97, Loss: 0.6414
Epoch 1/10, Batch 60/97, Loss: 0.7630
Epoch 1/10, Batch 70/97, Loss: 0.6422
Epoch 1/10, Batch 80/97, Loss: 0.6338
Epoch 1/10, Batch 90/97, Loss: 0.6045
Epoch 1/10, Train Loss: 0.8141, Valid Loss: 0.4449
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5601
Epoch 2/10, Batch 20/97, Loss: 0.4706
Epoch 2/10, Batch 30/97, Loss: 0.4259
Epoch 2/10, Batch 40/97, Loss: 0.3037
Epoch 2/10, Batch 50/97, Loss: 0.4153
Epoch 2/10, Batch 60/97, Loss: 0.4481
Epoch 2/10, Batch 70/97, Loss: 0.3662
Epoch 2/10, Batch 80/97, Loss: 0.4968
Epoch 2/10, Batch 90/97, Loss: 0.3534
Epoch 2/10, Train Loss: 0.4105, Valid Loss: 0.3441
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3852
Epoch 3/10, Batch 20/97, Loss: 0.2349
Epoch 3/10, Batch 30/97, Loss: 0.3397
Epoch 3/10, Batch 40/97, Loss: 0.2530
Epoch 3/10, Batch 50/97, Loss: 0.3391
Epoch 3/10, Batch 60/97, Loss: 0.1885
Epoch 3/10, Batch 70/97, Loss: 0.3553
Epoch 3/10, Batch 80/97, Loss: 0.2585
Epoch 3/10, Batch 90/97, Loss: 0.3596
Epoch 3/10, Train Loss: 0.3308, Valid Loss: 0.3035
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4939
Epoch 4/10, Batch 20/97, Loss: 0.2147
Epoch 4/10, Batch 30/97, Loss: 0.3713
Epoch 4/10, Batch 40/97, Loss: 0.2794
Epoch 4/10, Batch 50/97, Loss: 0.3312
Epoch 4/10, Batch 60/97, Loss: 0.3023
Epoch 4/10, Batch 70/97, Loss: 0.1785
Epoch 4/10, Batch 80/97, Loss: 0.2999
Epoch 4/10, Batch 90/97, Loss: 0.2256
Epoch 4/10, Train Loss: 0.2864, Valid Loss: 0.2873
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2743
Epoch 5/10, Batch 20/97, Loss: 0.1332
Epoch 5/10, Batch 30/97, Loss: 0.1904
Epoch 5/10, Batch 40/97, Loss: 0.2686
Epoch 5/10, Batch 50/97, Loss: 0.2047
Epoch 5/10, Batch 60/97, Loss: 0.3103
Epoch 5/10, Batch 70/97, Loss: 0.3113
Epoch 5/10, Batch 80/97, Loss: 0.2006
Epoch 5/10, Batch 90/97, Loss: 0.2696
Epoch 5/10, Train Loss: 0.2618, Valid Loss: 0.2743
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2305
Epoch 6/10, Batch 20/97, Loss: 0.2977
Epoch 6/10, Batch 30/97, Loss: 0.2103
Epoch 6/10, Batch 40/97, Loss: 0.1877
Epoch 6/10, Batch 50/97, Loss: 0.2557
Epoch 6/10, Batch 60/97, Loss: 0.3275
Epoch 6/10, Batch 70/97, Loss: 0.2720
Epoch 6/10, Batch 80/97, Loss: 0.3499
Epoch 6/10, Batch 90/97, Loss: 0.3568
Epoch 6/10, Train Loss: 0.2470, Valid Loss: 0.2594
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1173
Epoch 7/10, Batch 20/97, Loss: 0.2323
Epoch 7/10, Batch 30/97, Loss: 0.1078
Epoch 7/10, Batch 40/97, Loss: 0.2414
Epoch 7/10, Batch 50/97, Loss: 0.2920
Epoch 7/10, Batch 60/97, Loss: 0.1404
Epoch 7/10, Batch 70/97, Loss: 0.1833
Epoch 7/10, Batch 80/97, Loss: 0.2735
Epoch 7/10, Batch 90/97, Loss: 0.2296
Epoch 7/10, Train Loss: 0.2209, Valid Loss: 0.2489
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1176
Epoch 8/10, Batch 20/97, Loss: 0.0740
Epoch 8/10, Batch 30/97, Loss: 0.1470
Epoch 8/10, Batch 40/97, Loss: 0.1857
Epoch 8/10, Batch 50/97, Loss: 0.2123
Epoch 8/10, Batch 60/97, Loss: 0.2070
Epoch 8/10, Batch 70/97, Loss: 0.2897
Epoch 8/10, Batch 80/97, Loss: 0.1218
Epoch 8/10, Batch 90/97, Loss: 0.3104
Epoch 8/10, Train Loss: 0.2131, Valid Loss: 0.2524
Epoch 9/10, Batch 10/97, Loss: 0.1034
Epoch 9/10, Batch 20/97, Loss: 0.1246
Epoch 9/10, Batch 30/97, Loss: 0.2830
Epoch 9/10, Batch 40/97, Loss: 0.1800
Epoch 9/10, Batch 50/97, Loss: 0.1863
Epoch 9/10, Batch 60/97, Loss: 0.2094
Epoch 9/10, Batch 70/97, Loss: 0.0564
Epoch 9/10, Batch 80/97, Loss: 0.1225
Epoch 9/10, Batch 90/97, Loss: 0.1711
Epoch 9/10, Train Loss: 0.2095, Valid Loss: 0.2447
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1673
Epoch 10/10, Batch 20/97, Loss: 0.0684
Epoch 10/10, Batch 30/97, Loss: 0.2144
Epoch 10/10, Batch 40/97, Loss: 0.0671
Epoch 10/10, Batch 50/97, Loss: 0.1234
Epoch 10/10, Batch 60/97, Loss: 0.1819
Epoch 10/10, Batch 70/97, Loss: 0.2296
Epoch 10/10, Batch 80/97, Loss: 0.2303
Epoch 10/10, Batch 90/97, Loss: 0.3756
Epoch 10/10, Train Loss: 0.2075, Valid Loss: 0.2397
Model saved!
Accuracy: 0.9159
Precision: 0.9137
Recall: 0.9159
F1-score: 0.9142
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2283
Epoch 1/10, Batch 20/97, Loss: 1.0291
Epoch 1/10, Batch 30/97, Loss: 0.7648
Epoch 1/10, Batch 40/97, Loss: 0.6840
Epoch 1/10, Batch 50/97, Loss: 0.5700
Epoch 1/10, Batch 60/97, Loss: 0.7704
Epoch 1/10, Batch 70/97, Loss: 0.6896
Epoch 1/10, Batch 80/97, Loss: 0.7272
Epoch 1/10, Batch 90/97, Loss: 0.5576
Epoch 1/10, Train Loss: 0.8124, Valid Loss: 0.4467
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4954
Epoch 2/10, Batch 20/97, Loss: 0.4479
Epoch 2/10, Batch 30/97, Loss: 0.4228
Epoch 2/10, Batch 40/97, Loss: 0.3224
Epoch 2/10, Batch 50/97, Loss: 0.4280
Epoch 2/10, Batch 60/97, Loss: 0.5332
Epoch 2/10, Batch 70/97, Loss: 0.4898
Epoch 2/10, Batch 80/97, Loss: 0.4764
Epoch 2/10, Batch 90/97, Loss: 0.3018
Epoch 2/10, Train Loss: 0.4212, Valid Loss: 0.3380
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3450
Epoch 3/10, Batch 20/97, Loss: 0.2531
Epoch 3/10, Batch 30/97, Loss: 0.3992
Epoch 3/10, Batch 40/97, Loss: 0.2062
Epoch 3/10, Batch 50/97, Loss: 0.4532
Epoch 3/10, Batch 60/97, Loss: 0.2668
Epoch 3/10, Batch 70/97, Loss: 0.3044
Epoch 3/10, Batch 80/97, Loss: 0.2778
Epoch 3/10, Batch 90/97, Loss: 0.3303
Epoch 3/10, Train Loss: 0.3293, Valid Loss: 0.2998
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4643
Epoch 4/10, Batch 20/97, Loss: 0.2278
Epoch 4/10, Batch 30/97, Loss: 0.1563
Epoch 4/10, Batch 40/97, Loss: 0.4169
Epoch 4/10, Batch 50/97, Loss: 0.3249
Epoch 4/10, Batch 60/97, Loss: 0.2399
Epoch 4/10, Batch 70/97, Loss: 0.1729
Epoch 4/10, Batch 80/97, Loss: 0.3346
Epoch 4/10, Batch 90/97, Loss: 0.2429
Epoch 4/10, Train Loss: 0.2862, Valid Loss: 0.2811
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2495
Epoch 5/10, Batch 20/97, Loss: 0.2955
Epoch 5/10, Batch 30/97, Loss: 0.1930
Epoch 5/10, Batch 40/97, Loss: 0.2717
Epoch 5/10, Batch 50/97, Loss: 0.2900
Epoch 5/10, Batch 60/97, Loss: 0.3271
Epoch 5/10, Batch 70/97, Loss: 0.3430
Epoch 5/10, Batch 80/97, Loss: 0.3281
Epoch 5/10, Batch 90/97, Loss: 0.2085
Epoch 5/10, Train Loss: 0.2642, Valid Loss: 0.2781
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1604
Epoch 6/10, Batch 20/97, Loss: 0.3392
Epoch 6/10, Batch 30/97, Loss: 0.3382
Epoch 6/10, Batch 40/97, Loss: 0.2419
Epoch 6/10, Batch 50/97, Loss: 0.3153
Epoch 6/10, Batch 60/97, Loss: 0.2406
Epoch 6/10, Batch 70/97, Loss: 0.1647
Epoch 6/10, Batch 80/97, Loss: 0.1970
Epoch 6/10, Batch 90/97, Loss: 0.2145
Epoch 6/10, Train Loss: 0.2428, Valid Loss: 0.2544
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3675
Epoch 7/10, Batch 20/97, Loss: 0.1905
Epoch 7/10, Batch 30/97, Loss: 0.1278
Epoch 7/10, Batch 40/97, Loss: 0.1706
Epoch 7/10, Batch 50/97, Loss: 0.2736
Epoch 7/10, Batch 60/97, Loss: 0.1217
Epoch 7/10, Batch 70/97, Loss: 0.2947
Epoch 7/10, Batch 80/97, Loss: 0.2152
Epoch 7/10, Batch 90/97, Loss: 0.3455
Epoch 7/10, Train Loss: 0.2244, Valid Loss: 0.2480
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2246
Epoch 8/10, Batch 20/97, Loss: 0.1866
Epoch 8/10, Batch 30/97, Loss: 0.2401
Epoch 8/10, Batch 40/97, Loss: 0.1817
Epoch 8/10, Batch 50/97, Loss: 0.1373
Epoch 8/10, Batch 60/97, Loss: 0.1684
Epoch 8/10, Batch 70/97, Loss: 0.3105
Epoch 8/10, Batch 80/97, Loss: 0.1866
Epoch 8/10, Batch 90/97, Loss: 0.2561
Epoch 8/10, Train Loss: 0.2162, Valid Loss: 0.2450
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1928
Epoch 9/10, Batch 20/97, Loss: 0.1711
Epoch 9/10, Batch 30/97, Loss: 0.2023
Epoch 9/10, Batch 40/97, Loss: 0.4608
Epoch 9/10, Batch 50/97, Loss: 0.1472
Epoch 9/10, Batch 60/97, Loss: 0.2689
Epoch 9/10, Batch 70/97, Loss: 0.1515
Epoch 9/10, Batch 80/97, Loss: 0.1300
Epoch 9/10, Batch 90/97, Loss: 0.2430
Epoch 9/10, Train Loss: 0.2065, Valid Loss: 0.2427
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2446
Epoch 10/10, Batch 20/97, Loss: 0.0784
Epoch 10/10, Batch 30/97, Loss: 0.1647
Epoch 10/10, Batch 40/97, Loss: 0.2091
Epoch 10/10, Batch 50/97, Loss: 0.2353
Epoch 10/10, Batch 60/97, Loss: 0.0856
Epoch 10/10, Batch 70/97, Loss: 0.2945
Epoch 10/10, Batch 80/97, Loss: 0.1448
Epoch 10/10, Batch 90/97, Loss: 0.1790
Epoch 10/10, Train Loss: 0.1987, Valid Loss: 0.2486
Accuracy: 0.9229
Precision: 0.9213
Recall: 0.9229
F1-score: 0.9218
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2950
Epoch 1/10, Batch 20/97, Loss: 1.0863
Epoch 1/10, Batch 30/97, Loss: 0.6999
Epoch 1/10, Batch 40/97, Loss: 0.7320
Epoch 1/10, Batch 50/97, Loss: 0.7041
Epoch 1/10, Batch 60/97, Loss: 0.6554
Epoch 1/10, Batch 70/97, Loss: 0.6830
Epoch 1/10, Batch 80/97, Loss: 0.7450
Epoch 1/10, Batch 90/97, Loss: 0.6263
Epoch 1/10, Train Loss: 0.7995, Valid Loss: 0.4505
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5748
Epoch 2/10, Batch 20/97, Loss: 0.3503
Epoch 2/10, Batch 30/97, Loss: 0.3565
Epoch 2/10, Batch 40/97, Loss: 0.3158
Epoch 2/10, Batch 50/97, Loss: 0.3417
Epoch 2/10, Batch 60/97, Loss: 0.4145
Epoch 2/10, Batch 70/97, Loss: 0.3080
Epoch 2/10, Batch 80/97, Loss: 0.4662
Epoch 2/10, Batch 90/97, Loss: 0.4333
Epoch 2/10, Train Loss: 0.4157, Valid Loss: 0.3473
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2706
Epoch 3/10, Batch 20/97, Loss: 0.3512
Epoch 3/10, Batch 30/97, Loss: 0.2456
Epoch 3/10, Batch 40/97, Loss: 0.2877
Epoch 3/10, Batch 50/97, Loss: 0.4912
Epoch 3/10, Batch 60/97, Loss: 0.2157
Epoch 3/10, Batch 70/97, Loss: 0.3839
Epoch 3/10, Batch 80/97, Loss: 0.2243
Epoch 3/10, Batch 90/97, Loss: 0.3487
Epoch 3/10, Train Loss: 0.3392, Valid Loss: 0.3067
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4147
Epoch 4/10, Batch 20/97, Loss: 0.2935
Epoch 4/10, Batch 30/97, Loss: 0.2181
Epoch 4/10, Batch 40/97, Loss: 0.2060
Epoch 4/10, Batch 50/97, Loss: 0.2506
Epoch 4/10, Batch 60/97, Loss: 0.2998
Epoch 4/10, Batch 70/97, Loss: 0.2258
Epoch 4/10, Batch 80/97, Loss: 0.2286
Epoch 4/10, Batch 90/97, Loss: 0.2914
Epoch 4/10, Train Loss: 0.2873, Valid Loss: 0.2946
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3769
Epoch 5/10, Batch 20/97, Loss: 0.2993
Epoch 5/10, Batch 30/97, Loss: 0.1367
Epoch 5/10, Batch 40/97, Loss: 0.2203
Epoch 5/10, Batch 50/97, Loss: 0.2737
Epoch 5/10, Batch 60/97, Loss: 0.3523
Epoch 5/10, Batch 70/97, Loss: 0.3699
Epoch 5/10, Batch 80/97, Loss: 0.1223
Epoch 5/10, Batch 90/97, Loss: 0.2198
Epoch 5/10, Train Loss: 0.2727, Valid Loss: 0.2761
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1723
Epoch 6/10, Batch 20/97, Loss: 0.3730
Epoch 6/10, Batch 30/97, Loss: 0.2046
Epoch 6/10, Batch 40/97, Loss: 0.1754
Epoch 6/10, Batch 50/97, Loss: 0.2748
Epoch 6/10, Batch 60/97, Loss: 0.3036
Epoch 6/10, Batch 70/97, Loss: 0.2278
Epoch 6/10, Batch 80/97, Loss: 0.2796
Epoch 6/10, Batch 90/97, Loss: 0.3210
Epoch 6/10, Train Loss: 0.2484, Valid Loss: 0.2569
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2262
Epoch 7/10, Batch 20/97, Loss: 0.1947
Epoch 7/10, Batch 30/97, Loss: 0.1990
Epoch 7/10, Batch 40/97, Loss: 0.1326
Epoch 7/10, Batch 50/97, Loss: 0.2554
Epoch 7/10, Batch 60/97, Loss: 0.2200
Epoch 7/10, Batch 70/97, Loss: 0.2306
Epoch 7/10, Batch 80/97, Loss: 0.1814
Epoch 7/10, Batch 90/97, Loss: 0.1777
Epoch 7/10, Train Loss: 0.2321, Valid Loss: 0.2476
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2091
Epoch 8/10, Batch 20/97, Loss: 0.2517
Epoch 8/10, Batch 30/97, Loss: 0.1983
Epoch 8/10, Batch 40/97, Loss: 0.2170
Epoch 8/10, Batch 50/97, Loss: 0.1632
Epoch 8/10, Batch 60/97, Loss: 0.2059
Epoch 8/10, Batch 70/97, Loss: 0.1616
Epoch 8/10, Batch 80/97, Loss: 0.1173
Epoch 8/10, Batch 90/97, Loss: 0.0990
Epoch 8/10, Train Loss: 0.2241, Valid Loss: 0.2478
Epoch 9/10, Batch 10/97, Loss: 0.1125
Epoch 9/10, Batch 20/97, Loss: 0.1483
Epoch 9/10, Batch 30/97, Loss: 0.2411
Epoch 9/10, Batch 40/97, Loss: 0.1837
Epoch 9/10, Batch 50/97, Loss: 0.2484
Epoch 9/10, Batch 60/97, Loss: 0.1857
Epoch 9/10, Batch 70/97, Loss: 0.1066
Epoch 9/10, Batch 80/97, Loss: 0.0366
Epoch 9/10, Batch 90/97, Loss: 0.2504
Epoch 9/10, Train Loss: 0.2137, Valid Loss: 0.2407
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1731
Epoch 10/10, Batch 20/97, Loss: 0.1610
Epoch 10/10, Batch 30/97, Loss: 0.1904
Epoch 10/10, Batch 40/97, Loss: 0.2239
Epoch 10/10, Batch 50/97, Loss: 0.0712
Epoch 10/10, Batch 60/97, Loss: 0.2460
Epoch 10/10, Batch 70/97, Loss: 0.3139
Epoch 10/10, Batch 80/97, Loss: 0.1060
Epoch 10/10, Batch 90/97, Loss: 0.0867
Epoch 10/10, Train Loss: 0.2056, Valid Loss: 0.2425
Accuracy: 0.9147
Precision: 0.9121
Recall: 0.9147
F1-score: 0.9128
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2172
Epoch 1/10, Batch 20/97, Loss: 1.0255
Epoch 1/10, Batch 30/97, Loss: 0.7274
Epoch 1/10, Batch 40/97, Loss: 0.7416
Epoch 1/10, Batch 50/97, Loss: 0.5966
Epoch 1/10, Batch 60/97, Loss: 0.7350
Epoch 1/10, Batch 70/97, Loss: 0.7369
Epoch 1/10, Batch 80/97, Loss: 0.7286
Epoch 1/10, Batch 90/97, Loss: 0.4775
Epoch 1/10, Train Loss: 0.7985, Valid Loss: 0.4328
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5653
Epoch 2/10, Batch 20/97, Loss: 0.3785
Epoch 2/10, Batch 30/97, Loss: 0.3965
Epoch 2/10, Batch 40/97, Loss: 0.3645
Epoch 2/10, Batch 50/97, Loss: 0.3831
Epoch 2/10, Batch 60/97, Loss: 0.3966
Epoch 2/10, Batch 70/97, Loss: 0.3526
Epoch 2/10, Batch 80/97, Loss: 0.4087
Epoch 2/10, Batch 90/97, Loss: 0.3962
Epoch 2/10, Train Loss: 0.4127, Valid Loss: 0.3303
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4137
Epoch 3/10, Batch 20/97, Loss: 0.3094
Epoch 3/10, Batch 30/97, Loss: 0.3670
Epoch 3/10, Batch 40/97, Loss: 0.2674
Epoch 3/10, Batch 50/97, Loss: 0.5376
Epoch 3/10, Batch 60/97, Loss: 0.2184
Epoch 3/10, Batch 70/97, Loss: 0.4668
Epoch 3/10, Batch 80/97, Loss: 0.3199
Epoch 3/10, Batch 90/97, Loss: 0.3274
Epoch 3/10, Train Loss: 0.3332, Valid Loss: 0.2847
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3596
Epoch 4/10, Batch 20/97, Loss: 0.2768
Epoch 4/10, Batch 30/97, Loss: 0.2283
Epoch 4/10, Batch 40/97, Loss: 0.1915
Epoch 4/10, Batch 50/97, Loss: 0.2940
Epoch 4/10, Batch 60/97, Loss: 0.1791
Epoch 4/10, Batch 70/97, Loss: 0.2568
Epoch 4/10, Batch 80/97, Loss: 0.1982
Epoch 4/10, Batch 90/97, Loss: 0.2699
Epoch 4/10, Train Loss: 0.2825, Valid Loss: 0.2738
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2767
Epoch 5/10, Batch 20/97, Loss: 0.3539
Epoch 5/10, Batch 30/97, Loss: 0.1998
Epoch 5/10, Batch 40/97, Loss: 0.3267
Epoch 5/10, Batch 50/97, Loss: 0.2005
Epoch 5/10, Batch 60/97, Loss: 0.3022
Epoch 5/10, Batch 70/97, Loss: 0.2057
Epoch 5/10, Batch 80/97, Loss: 0.2385
Epoch 5/10, Batch 90/97, Loss: 0.2017
Epoch 5/10, Train Loss: 0.2714, Valid Loss: 0.2578
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1227
Epoch 6/10, Batch 20/97, Loss: 0.2859
Epoch 6/10, Batch 30/97, Loss: 0.1945
Epoch 6/10, Batch 40/97, Loss: 0.1003
Epoch 6/10, Batch 50/97, Loss: 0.2055
Epoch 6/10, Batch 60/97, Loss: 0.2401
Epoch 6/10, Batch 70/97, Loss: 0.1970
Epoch 6/10, Batch 80/97, Loss: 0.3291
Epoch 6/10, Batch 90/97, Loss: 0.4342
Epoch 6/10, Train Loss: 0.2391, Valid Loss: 0.2485
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1344
Epoch 7/10, Batch 20/97, Loss: 0.2051
Epoch 7/10, Batch 30/97, Loss: 0.1335
Epoch 7/10, Batch 40/97, Loss: 0.3315
Epoch 7/10, Batch 50/97, Loss: 0.2605
Epoch 7/10, Batch 60/97, Loss: 0.1501
Epoch 7/10, Batch 70/97, Loss: 0.2542
Epoch 7/10, Batch 80/97, Loss: 0.1922
Epoch 7/10, Batch 90/97, Loss: 0.1368
Epoch 7/10, Train Loss: 0.2363, Valid Loss: 0.2425
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.0765
Epoch 8/10, Batch 20/97, Loss: 0.2658
Epoch 8/10, Batch 30/97, Loss: 0.2682
Epoch 8/10, Batch 40/97, Loss: 0.1897
Epoch 8/10, Batch 50/97, Loss: 0.1801
Epoch 8/10, Batch 60/97, Loss: 0.1757
Epoch 8/10, Batch 70/97, Loss: 0.1327
Epoch 8/10, Batch 80/97, Loss: 0.1964
Epoch 8/10, Batch 90/97, Loss: 0.1125
Epoch 8/10, Train Loss: 0.2163, Valid Loss: 0.2353
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1220
Epoch 9/10, Batch 20/97, Loss: 0.1500
Epoch 9/10, Batch 30/97, Loss: 0.2368
Epoch 9/10, Batch 40/97, Loss: 0.2337
Epoch 9/10, Batch 50/97, Loss: 0.1259
Epoch 9/10, Batch 60/97, Loss: 0.3679
Epoch 9/10, Batch 70/97, Loss: 0.1870
Epoch 9/10, Batch 80/97, Loss: 0.2709
Epoch 9/10, Batch 90/97, Loss: 0.1473
Epoch 9/10, Train Loss: 0.2122, Valid Loss: 0.2335
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1843
Epoch 10/10, Batch 20/97, Loss: 0.0772
Epoch 10/10, Batch 30/97, Loss: 0.1708
Epoch 10/10, Batch 40/97, Loss: 0.0458
Epoch 10/10, Batch 50/97, Loss: 0.1755
Epoch 10/10, Batch 60/97, Loss: 0.2036
Epoch 10/10, Batch 70/97, Loss: 0.3045
Epoch 10/10, Batch 80/97, Loss: 0.2248
Epoch 10/10, Batch 90/97, Loss: 0.2143
Epoch 10/10, Train Loss: 0.1988, Valid Loss: 0.2413
Accuracy: 0.9206
Precision: 0.9177
Recall: 0.9206
F1-score: 0.9183
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2455
Epoch 1/10, Batch 20/97, Loss: 1.0698
Epoch 1/10, Batch 30/97, Loss: 0.8757
Epoch 1/10, Batch 40/97, Loss: 0.7480
Epoch 1/10, Batch 50/97, Loss: 0.6008
Epoch 1/10, Batch 60/97, Loss: 0.8016
Epoch 1/10, Batch 70/97, Loss: 0.6088
Epoch 1/10, Batch 80/97, Loss: 0.6204
Epoch 1/10, Batch 90/97, Loss: 0.5584
Epoch 1/10, Train Loss: 0.8018, Valid Loss: 0.4395
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4309
Epoch 2/10, Batch 20/97, Loss: 0.4451
Epoch 2/10, Batch 30/97, Loss: 0.5568
Epoch 2/10, Batch 40/97, Loss: 0.3795
Epoch 2/10, Batch 50/97, Loss: 0.3617
Epoch 2/10, Batch 60/97, Loss: 0.4284
Epoch 2/10, Batch 70/97, Loss: 0.2974
Epoch 2/10, Batch 80/97, Loss: 0.4155
Epoch 2/10, Batch 90/97, Loss: 0.4955
Epoch 2/10, Train Loss: 0.4146, Valid Loss: 0.3358
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4975
Epoch 3/10, Batch 20/97, Loss: 0.2720
Epoch 3/10, Batch 30/97, Loss: 0.4328
Epoch 3/10, Batch 40/97, Loss: 0.2335
Epoch 3/10, Batch 50/97, Loss: 0.2474
Epoch 3/10, Batch 60/97, Loss: 0.2709
Epoch 3/10, Batch 70/97, Loss: 0.3671
Epoch 3/10, Batch 80/97, Loss: 0.3110
Epoch 3/10, Batch 90/97, Loss: 0.3561
Epoch 3/10, Train Loss: 0.3328, Valid Loss: 0.2952
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.5703
Epoch 4/10, Batch 20/97, Loss: 0.2157
Epoch 4/10, Batch 30/97, Loss: 0.1821
Epoch 4/10, Batch 40/97, Loss: 0.3305
Epoch 4/10, Batch 50/97, Loss: 0.3231
Epoch 4/10, Batch 60/97, Loss: 0.1997
Epoch 4/10, Batch 70/97, Loss: 0.3250
Epoch 4/10, Batch 80/97, Loss: 0.3218
Epoch 4/10, Batch 90/97, Loss: 0.1957
Epoch 4/10, Train Loss: 0.2834, Valid Loss: 0.2856
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3607
Epoch 5/10, Batch 20/97, Loss: 0.2804
Epoch 5/10, Batch 30/97, Loss: 0.2648
Epoch 5/10, Batch 40/97, Loss: 0.1639
Epoch 5/10, Batch 50/97, Loss: 0.2810
Epoch 5/10, Batch 60/97, Loss: 0.2082
Epoch 5/10, Batch 70/97, Loss: 0.3513
Epoch 5/10, Batch 80/97, Loss: 0.1651
Epoch 5/10, Batch 90/97, Loss: 0.2807
Epoch 5/10, Train Loss: 0.2606, Valid Loss: 0.2670
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2424
Epoch 6/10, Batch 20/97, Loss: 0.3489
Epoch 6/10, Batch 30/97, Loss: 0.1946
Epoch 6/10, Batch 40/97, Loss: 0.1321
Epoch 6/10, Batch 50/97, Loss: 0.3223
Epoch 6/10, Batch 60/97, Loss: 0.2898
Epoch 6/10, Batch 70/97, Loss: 0.3358
Epoch 6/10, Batch 80/97, Loss: 0.4256
Epoch 6/10, Batch 90/97, Loss: 0.3006
Epoch 6/10, Train Loss: 0.2484, Valid Loss: 0.2558
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2971
Epoch 7/10, Batch 20/97, Loss: 0.2515
Epoch 7/10, Batch 30/97, Loss: 0.1594
Epoch 7/10, Batch 40/97, Loss: 0.0870
Epoch 7/10, Batch 50/97, Loss: 0.2789
Epoch 7/10, Batch 60/97, Loss: 0.1177
Epoch 7/10, Batch 70/97, Loss: 0.3044
Epoch 7/10, Batch 80/97, Loss: 0.1476
Epoch 7/10, Batch 90/97, Loss: 0.2747
Epoch 7/10, Train Loss: 0.2259, Valid Loss: 0.2454
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2059
Epoch 8/10, Batch 20/97, Loss: 0.1158
Epoch 8/10, Batch 30/97, Loss: 0.1577
Epoch 8/10, Batch 40/97, Loss: 0.1926
Epoch 8/10, Batch 50/97, Loss: 0.2100
Epoch 8/10, Batch 60/97, Loss: 0.1371
Epoch 8/10, Batch 70/97, Loss: 0.3030
Epoch 8/10, Batch 80/97, Loss: 0.1727
Epoch 8/10, Batch 90/97, Loss: 0.2075
Epoch 8/10, Train Loss: 0.2276, Valid Loss: 0.2427
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1192
Epoch 9/10, Batch 20/97, Loss: 0.1067
Epoch 9/10, Batch 30/97, Loss: 0.1724
Epoch 9/10, Batch 40/97, Loss: 0.3810
Epoch 9/10, Batch 50/97, Loss: 0.0783
Epoch 9/10, Batch 60/97, Loss: 0.1540
Epoch 9/10, Batch 70/97, Loss: 0.1579
Epoch 9/10, Batch 80/97, Loss: 0.1679
Epoch 9/10, Batch 90/97, Loss: 0.2273
Epoch 9/10, Train Loss: 0.2141, Valid Loss: 0.2431
Epoch 10/10, Batch 10/97, Loss: 0.1395
Epoch 10/10, Batch 20/97, Loss: 0.1000
Epoch 10/10, Batch 30/97, Loss: 0.3771
Epoch 10/10, Batch 40/97, Loss: 0.1816
Epoch 10/10, Batch 50/97, Loss: 0.2918
Epoch 10/10, Batch 60/97, Loss: 0.2679
Epoch 10/10, Batch 70/97, Loss: 0.3248
Epoch 10/10, Batch 80/97, Loss: 0.1658
Epoch 10/10, Batch 90/97, Loss: 0.1265
Epoch 10/10, Train Loss: 0.2075, Valid Loss: 0.2445
Accuracy: 0.9147
Precision: 0.9112
Recall: 0.9147
F1-score: 0.9121
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2373
Epoch 1/10, Batch 20/97, Loss: 1.0274
Epoch 1/10, Batch 30/97, Loss: 0.7254
Epoch 1/10, Batch 40/97, Loss: 0.5864
Epoch 1/10, Batch 50/97, Loss: 0.6082
Epoch 1/10, Batch 60/97, Loss: 0.6390
Epoch 1/10, Batch 70/97, Loss: 0.5062
Epoch 1/10, Batch 80/97, Loss: 0.4713
Epoch 1/10, Batch 90/97, Loss: 0.5840
Epoch 1/10, Train Loss: 0.7993, Valid Loss: 0.4586
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.7388
Epoch 2/10, Batch 20/97, Loss: 0.3777
Epoch 2/10, Batch 30/97, Loss: 0.3538
Epoch 2/10, Batch 40/97, Loss: 0.2680
Epoch 2/10, Batch 50/97, Loss: 0.3763
Epoch 2/10, Batch 60/97, Loss: 0.3240
Epoch 2/10, Batch 70/97, Loss: 0.4099
Epoch 2/10, Batch 80/97, Loss: 0.2825
Epoch 2/10, Batch 90/97, Loss: 0.4444
Epoch 2/10, Train Loss: 0.4135, Valid Loss: 0.3539
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3252
Epoch 3/10, Batch 20/97, Loss: 0.3611
Epoch 3/10, Batch 30/97, Loss: 0.3339
Epoch 3/10, Batch 40/97, Loss: 0.2252
Epoch 3/10, Batch 50/97, Loss: 0.3960
Epoch 3/10, Batch 60/97, Loss: 0.2861
Epoch 3/10, Batch 70/97, Loss: 0.3209
Epoch 3/10, Batch 80/97, Loss: 0.5010
Epoch 3/10, Batch 90/97, Loss: 0.2409
Epoch 3/10, Train Loss: 0.3325, Valid Loss: 0.3135
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2918
Epoch 4/10, Batch 20/97, Loss: 0.1629
Epoch 4/10, Batch 30/97, Loss: 0.2925
Epoch 4/10, Batch 40/97, Loss: 0.1541
Epoch 4/10, Batch 50/97, Loss: 0.3796
Epoch 4/10, Batch 60/97, Loss: 0.3467
Epoch 4/10, Batch 70/97, Loss: 0.3370
Epoch 4/10, Batch 80/97, Loss: 0.3572
Epoch 4/10, Batch 90/97, Loss: 0.3154
Epoch 4/10, Train Loss: 0.2848, Valid Loss: 0.2918
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3303
Epoch 5/10, Batch 20/97, Loss: 0.3872
Epoch 5/10, Batch 30/97, Loss: 0.1379
Epoch 5/10, Batch 40/97, Loss: 0.2564
Epoch 5/10, Batch 50/97, Loss: 0.1810
Epoch 5/10, Batch 60/97, Loss: 0.2785
Epoch 5/10, Batch 70/97, Loss: 0.2331
Epoch 5/10, Batch 80/97, Loss: 0.1608
Epoch 5/10, Batch 90/97, Loss: 0.3886
Epoch 5/10, Train Loss: 0.2678, Valid Loss: 0.2753
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2214
Epoch 6/10, Batch 20/97, Loss: 0.2720
Epoch 6/10, Batch 30/97, Loss: 0.1600
Epoch 6/10, Batch 40/97, Loss: 0.2920
Epoch 6/10, Batch 50/97, Loss: 0.2795
Epoch 6/10, Batch 60/97, Loss: 0.4953
Epoch 6/10, Batch 70/97, Loss: 0.2161
Epoch 6/10, Batch 80/97, Loss: 0.2422
Epoch 6/10, Batch 90/97, Loss: 0.2081
Epoch 6/10, Train Loss: 0.2428, Valid Loss: 0.2531
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2290
Epoch 7/10, Batch 20/97, Loss: 0.1719
Epoch 7/10, Batch 30/97, Loss: 0.1685
Epoch 7/10, Batch 40/97, Loss: 0.1146
Epoch 7/10, Batch 50/97, Loss: 0.2555
Epoch 7/10, Batch 60/97, Loss: 0.2276
Epoch 7/10, Batch 70/97, Loss: 0.1805
Epoch 7/10, Batch 80/97, Loss: 0.3285
Epoch 7/10, Batch 90/97, Loss: 0.1292
Epoch 7/10, Train Loss: 0.2299, Valid Loss: 0.2485
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1699
Epoch 8/10, Batch 20/97, Loss: 0.2129
Epoch 8/10, Batch 30/97, Loss: 0.2100
Epoch 8/10, Batch 40/97, Loss: 0.3289
Epoch 8/10, Batch 50/97, Loss: 0.2395
Epoch 8/10, Batch 60/97, Loss: 0.1401
Epoch 8/10, Batch 70/97, Loss: 0.2215
Epoch 8/10, Batch 80/97, Loss: 0.1306
Epoch 8/10, Batch 90/97, Loss: 0.1569
Epoch 8/10, Train Loss: 0.2254, Valid Loss: 0.2517
Epoch 9/10, Batch 10/97, Loss: 0.2296
Epoch 9/10, Batch 20/97, Loss: 0.2576
Epoch 9/10, Batch 30/97, Loss: 0.2341
Epoch 9/10, Batch 40/97, Loss: 0.1768
Epoch 9/10, Batch 50/97, Loss: 0.1792
Epoch 9/10, Batch 60/97, Loss: 0.2726
Epoch 9/10, Batch 70/97, Loss: 0.2320
Epoch 9/10, Batch 80/97, Loss: 0.1318
Epoch 9/10, Batch 90/97, Loss: 0.1774
Epoch 9/10, Train Loss: 0.2053, Valid Loss: 0.2372
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1910
Epoch 10/10, Batch 20/97, Loss: 0.1272
Epoch 10/10, Batch 30/97, Loss: 0.1824
Epoch 10/10, Batch 40/97, Loss: 0.1319
Epoch 10/10, Batch 50/97, Loss: 0.0922
Epoch 10/10, Batch 60/97, Loss: 0.1810
Epoch 10/10, Batch 70/97, Loss: 0.1780
Epoch 10/10, Batch 80/97, Loss: 0.2077
Epoch 10/10, Batch 90/97, Loss: 0.0946
Epoch 10/10, Train Loss: 0.2030, Valid Loss: 0.2498
Accuracy: 0.9171
Precision: 0.9157
Recall: 0.9171
F1-score: 0.9162
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2588
Epoch 1/10, Batch 20/97, Loss: 1.1247
Epoch 1/10, Batch 30/97, Loss: 0.7960
Epoch 1/10, Batch 40/97, Loss: 0.7615
Epoch 1/10, Batch 50/97, Loss: 0.5369
Epoch 1/10, Batch 60/97, Loss: 0.5827
Epoch 1/10, Batch 70/97, Loss: 0.7347
Epoch 1/10, Batch 80/97, Loss: 0.7156
Epoch 1/10, Batch 90/97, Loss: 0.5057
Epoch 1/10, Train Loss: 0.8000, Valid Loss: 0.4349
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5620
Epoch 2/10, Batch 20/97, Loss: 0.6250
Epoch 2/10, Batch 30/97, Loss: 0.3033
Epoch 2/10, Batch 40/97, Loss: 0.3770
Epoch 2/10, Batch 50/97, Loss: 0.3853
Epoch 2/10, Batch 60/97, Loss: 0.3663
Epoch 2/10, Batch 70/97, Loss: 0.4285
Epoch 2/10, Batch 80/97, Loss: 0.4184
Epoch 2/10, Batch 90/97, Loss: 0.5136
Epoch 2/10, Train Loss: 0.4050, Valid Loss: 0.3211
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3843
Epoch 3/10, Batch 20/97, Loss: 0.3073
Epoch 3/10, Batch 30/97, Loss: 0.3897
Epoch 3/10, Batch 40/97, Loss: 0.2658
Epoch 3/10, Batch 50/97, Loss: 0.3488
Epoch 3/10, Batch 60/97, Loss: 0.2707
Epoch 3/10, Batch 70/97, Loss: 0.3519
Epoch 3/10, Batch 80/97, Loss: 0.3089
Epoch 3/10, Batch 90/97, Loss: 0.2267
Epoch 3/10, Train Loss: 0.3300, Valid Loss: 0.2773
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3750
Epoch 4/10, Batch 20/97, Loss: 0.1831
Epoch 4/10, Batch 30/97, Loss: 0.3293
Epoch 4/10, Batch 40/97, Loss: 0.1260
Epoch 4/10, Batch 50/97, Loss: 0.5112
Epoch 4/10, Batch 60/97, Loss: 0.2850
Epoch 4/10, Batch 70/97, Loss: 0.2416
Epoch 4/10, Batch 80/97, Loss: 0.5225
Epoch 4/10, Batch 90/97, Loss: 0.1712
Epoch 4/10, Train Loss: 0.2907, Valid Loss: 0.2532
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1903
Epoch 5/10, Batch 20/97, Loss: 0.2090
Epoch 5/10, Batch 30/97, Loss: 0.2789
Epoch 5/10, Batch 40/97, Loss: 0.2773
Epoch 5/10, Batch 50/97, Loss: 0.1416
Epoch 5/10, Batch 60/97, Loss: 0.2261
Epoch 5/10, Batch 70/97, Loss: 0.2429
Epoch 5/10, Batch 80/97, Loss: 0.2278
Epoch 5/10, Batch 90/97, Loss: 0.2886
Epoch 5/10, Train Loss: 0.2623, Valid Loss: 0.2461
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1965
Epoch 6/10, Batch 20/97, Loss: 0.2962
Epoch 6/10, Batch 30/97, Loss: 0.2909
Epoch 6/10, Batch 40/97, Loss: 0.0809
Epoch 6/10, Batch 50/97, Loss: 0.2261
Epoch 6/10, Batch 60/97, Loss: 0.3832
Epoch 6/10, Batch 70/97, Loss: 0.1526
Epoch 6/10, Batch 80/97, Loss: 0.1931
Epoch 6/10, Batch 90/97, Loss: 0.3981
Epoch 6/10, Train Loss: 0.2467, Valid Loss: 0.2274
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1475
Epoch 7/10, Batch 20/97, Loss: 0.1273
Epoch 7/10, Batch 30/97, Loss: 0.1260
Epoch 7/10, Batch 40/97, Loss: 0.1161
Epoch 7/10, Batch 50/97, Loss: 0.2802
Epoch 7/10, Batch 60/97, Loss: 0.1986
Epoch 7/10, Batch 70/97, Loss: 0.2455
Epoch 7/10, Batch 80/97, Loss: 0.2707
Epoch 7/10, Batch 90/97, Loss: 0.1717
Epoch 7/10, Train Loss: 0.2227, Valid Loss: 0.2229
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1399
Epoch 8/10, Batch 20/97, Loss: 0.1875
Epoch 8/10, Batch 30/97, Loss: 0.1494
Epoch 8/10, Batch 40/97, Loss: 0.1941
Epoch 8/10, Batch 50/97, Loss: 0.2520
Epoch 8/10, Batch 60/97, Loss: 0.0727
Epoch 8/10, Batch 70/97, Loss: 0.1733
Epoch 8/10, Batch 80/97, Loss: 0.1633
Epoch 8/10, Batch 90/97, Loss: 0.1669
Epoch 8/10, Train Loss: 0.2162, Valid Loss: 0.2280
Epoch 9/10, Batch 10/97, Loss: 0.1706
Epoch 9/10, Batch 20/97, Loss: 0.3168
Epoch 9/10, Batch 30/97, Loss: 0.1560
Epoch 9/10, Batch 40/97, Loss: 0.4483
Epoch 9/10, Batch 50/97, Loss: 0.1195
Epoch 9/10, Batch 60/97, Loss: 0.1790
Epoch 9/10, Batch 70/97, Loss: 0.3054
Epoch 9/10, Batch 80/97, Loss: 0.2166
Epoch 9/10, Batch 90/97, Loss: 0.1812
Epoch 9/10, Train Loss: 0.2045, Valid Loss: 0.2109
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2968
Epoch 10/10, Batch 20/97, Loss: 0.1607
Epoch 10/10, Batch 30/97, Loss: 0.1542
Epoch 10/10, Batch 40/97, Loss: 0.1084
Epoch 10/10, Batch 50/97, Loss: 0.1755
Epoch 10/10, Batch 60/97, Loss: 0.1254
Epoch 10/10, Batch 70/97, Loss: 0.2474
Epoch 10/10, Batch 80/97, Loss: 0.1313
Epoch 10/10, Batch 90/97, Loss: 0.1943
Epoch 10/10, Train Loss: 0.2005, Valid Loss: 0.2186
Accuracy: 0.9136
Precision: 0.9113
Recall: 0.9136
F1-score: 0.9122
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2058
Epoch 1/10, Batch 20/97, Loss: 1.0628
Epoch 1/10, Batch 30/97, Loss: 0.6797
Epoch 1/10, Batch 40/97, Loss: 0.7608
Epoch 1/10, Batch 50/97, Loss: 0.6154
Epoch 1/10, Batch 60/97, Loss: 0.6732
Epoch 1/10, Batch 70/97, Loss: 0.6526
Epoch 1/10, Batch 80/97, Loss: 0.5491
Epoch 1/10, Batch 90/97, Loss: 0.5739
Epoch 1/10, Train Loss: 0.8040, Valid Loss: 0.4368
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6848
Epoch 2/10, Batch 20/97, Loss: 0.4764
Epoch 2/10, Batch 30/97, Loss: 0.3438
Epoch 2/10, Batch 40/97, Loss: 0.3258
Epoch 2/10, Batch 50/97, Loss: 0.4149
Epoch 2/10, Batch 60/97, Loss: 0.3722
Epoch 2/10, Batch 70/97, Loss: 0.4228
Epoch 2/10, Batch 80/97, Loss: 0.3083
Epoch 2/10, Batch 90/97, Loss: 0.5968
Epoch 2/10, Train Loss: 0.4100, Valid Loss: 0.3243
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2986
Epoch 3/10, Batch 20/97, Loss: 0.3038
Epoch 3/10, Batch 30/97, Loss: 0.3123
Epoch 3/10, Batch 40/97, Loss: 0.2292
Epoch 3/10, Batch 50/97, Loss: 0.4138
Epoch 3/10, Batch 60/97, Loss: 0.3151
Epoch 3/10, Batch 70/97, Loss: 0.2605
Epoch 3/10, Batch 80/97, Loss: 0.2358
Epoch 3/10, Batch 90/97, Loss: 0.1374
Epoch 3/10, Train Loss: 0.3339, Valid Loss: 0.2819
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3574
Epoch 4/10, Batch 20/97, Loss: 0.2404
Epoch 4/10, Batch 30/97, Loss: 0.2432
Epoch 4/10, Batch 40/97, Loss: 0.3004
Epoch 4/10, Batch 50/97, Loss: 0.3872
Epoch 4/10, Batch 60/97, Loss: 0.1827
Epoch 4/10, Batch 70/97, Loss: 0.2070
Epoch 4/10, Batch 80/97, Loss: 0.3874
Epoch 4/10, Batch 90/97, Loss: 0.3121
Epoch 4/10, Train Loss: 0.2924, Valid Loss: 0.2619
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3948
Epoch 5/10, Batch 20/97, Loss: 0.3331
Epoch 5/10, Batch 30/97, Loss: 0.1967
Epoch 5/10, Batch 40/97, Loss: 0.2618
Epoch 5/10, Batch 50/97, Loss: 0.4465
Epoch 5/10, Batch 60/97, Loss: 0.1725
Epoch 5/10, Batch 70/97, Loss: 0.3050
Epoch 5/10, Batch 80/97, Loss: 0.1407
Epoch 5/10, Batch 90/97, Loss: 0.2176
Epoch 5/10, Train Loss: 0.2645, Valid Loss: 0.2527
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3225
Epoch 6/10, Batch 20/97, Loss: 0.3263
Epoch 6/10, Batch 30/97, Loss: 0.1585
Epoch 6/10, Batch 40/97, Loss: 0.1638
Epoch 6/10, Batch 50/97, Loss: 0.3096
Epoch 6/10, Batch 60/97, Loss: 0.3448
Epoch 6/10, Batch 70/97, Loss: 0.2245
Epoch 6/10, Batch 80/97, Loss: 0.2626
Epoch 6/10, Batch 90/97, Loss: 0.2178
Epoch 6/10, Train Loss: 0.2456, Valid Loss: 0.2420
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1978
Epoch 7/10, Batch 20/97, Loss: 0.2124
Epoch 7/10, Batch 30/97, Loss: 0.2417
Epoch 7/10, Batch 40/97, Loss: 0.1510
Epoch 7/10, Batch 50/97, Loss: 0.4003
Epoch 7/10, Batch 60/97, Loss: 0.1072
Epoch 7/10, Batch 70/97, Loss: 0.2187
Epoch 7/10, Batch 80/97, Loss: 0.2593
Epoch 7/10, Batch 90/97, Loss: 0.2718
Epoch 7/10, Train Loss: 0.2299, Valid Loss: 0.2350
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1765
Epoch 8/10, Batch 20/97, Loss: 0.1784
Epoch 8/10, Batch 30/97, Loss: 0.3489
Epoch 8/10, Batch 40/97, Loss: 0.2479
Epoch 8/10, Batch 50/97, Loss: 0.3066
Epoch 8/10, Batch 60/97, Loss: 0.3417
Epoch 8/10, Batch 70/97, Loss: 0.2950
Epoch 8/10, Batch 80/97, Loss: 0.1425
Epoch 8/10, Batch 90/97, Loss: 0.2515
Epoch 8/10, Train Loss: 0.2280, Valid Loss: 0.2337
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1868
Epoch 9/10, Batch 20/97, Loss: 0.0729
Epoch 9/10, Batch 30/97, Loss: 0.2911
Epoch 9/10, Batch 40/97, Loss: 0.1502
Epoch 9/10, Batch 50/97, Loss: 0.3097
Epoch 9/10, Batch 60/97, Loss: 0.1312
Epoch 9/10, Batch 70/97, Loss: 0.1527
Epoch 9/10, Batch 80/97, Loss: 0.1948
Epoch 9/10, Batch 90/97, Loss: 0.2078
Epoch 9/10, Train Loss: 0.2078, Valid Loss: 0.2289
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3093
Epoch 10/10, Batch 20/97, Loss: 0.1151
Epoch 10/10, Batch 30/97, Loss: 0.1757
Epoch 10/10, Batch 40/97, Loss: 0.1766
Epoch 10/10, Batch 50/97, Loss: 0.2511
Epoch 10/10, Batch 60/97, Loss: 0.1797
Epoch 10/10, Batch 70/97, Loss: 0.3084
Epoch 10/10, Batch 80/97, Loss: 0.1394
Epoch 10/10, Batch 90/97, Loss: 0.1079
Epoch 10/10, Train Loss: 0.2046, Valid Loss: 0.2323
Accuracy: 0.9182
Precision: 0.9163
Recall: 0.9182
F1-score: 0.9165
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2427
Epoch 1/10, Batch 20/97, Loss: 1.0516
Epoch 1/10, Batch 30/97, Loss: 0.6331
Epoch 1/10, Batch 40/97, Loss: 0.7930
Epoch 1/10, Batch 50/97, Loss: 0.6050
Epoch 1/10, Batch 60/97, Loss: 0.6172
Epoch 1/10, Batch 70/97, Loss: 0.7041
Epoch 1/10, Batch 80/97, Loss: 0.5812
Epoch 1/10, Batch 90/97, Loss: 0.4940
Epoch 1/10, Train Loss: 0.8092, Valid Loss: 0.4622
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5466
Epoch 2/10, Batch 20/97, Loss: 0.4714
Epoch 2/10, Batch 30/97, Loss: 0.4630
Epoch 2/10, Batch 40/97, Loss: 0.3867
Epoch 2/10, Batch 50/97, Loss: 0.3480
Epoch 2/10, Batch 60/97, Loss: 0.3875
Epoch 2/10, Batch 70/97, Loss: 0.5059
Epoch 2/10, Batch 80/97, Loss: 0.2660
Epoch 2/10, Batch 90/97, Loss: 0.3799
Epoch 2/10, Train Loss: 0.4186, Valid Loss: 0.3493
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4042
Epoch 3/10, Batch 20/97, Loss: 0.2884
Epoch 3/10, Batch 30/97, Loss: 0.3762
Epoch 3/10, Batch 40/97, Loss: 0.3216
Epoch 3/10, Batch 50/97, Loss: 0.4413
Epoch 3/10, Batch 60/97, Loss: 0.2698
Epoch 3/10, Batch 70/97, Loss: 0.2719
Epoch 3/10, Batch 80/97, Loss: 0.2388
Epoch 3/10, Batch 90/97, Loss: 0.4406
Epoch 3/10, Train Loss: 0.3356, Valid Loss: 0.3015
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3824
Epoch 4/10, Batch 20/97, Loss: 0.1976
Epoch 4/10, Batch 30/97, Loss: 0.2385
Epoch 4/10, Batch 40/97, Loss: 0.2090
Epoch 4/10, Batch 50/97, Loss: 0.3105
Epoch 4/10, Batch 60/97, Loss: 0.1768
Epoch 4/10, Batch 70/97, Loss: 0.3006
Epoch 4/10, Batch 80/97, Loss: 0.2034
Epoch 4/10, Batch 90/97, Loss: 0.2597
Epoch 4/10, Train Loss: 0.2884, Valid Loss: 0.2822
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1830
Epoch 5/10, Batch 20/97, Loss: 0.3953
Epoch 5/10, Batch 30/97, Loss: 0.0909
Epoch 5/10, Batch 40/97, Loss: 0.1783
Epoch 5/10, Batch 50/97, Loss: 0.2376
Epoch 5/10, Batch 60/97, Loss: 0.2347
Epoch 5/10, Batch 70/97, Loss: 0.1476
Epoch 5/10, Batch 80/97, Loss: 0.2405
Epoch 5/10, Batch 90/97, Loss: 0.3507
Epoch 5/10, Train Loss: 0.2630, Valid Loss: 0.2608
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3054
Epoch 6/10, Batch 20/97, Loss: 0.2565
Epoch 6/10, Batch 30/97, Loss: 0.4436
Epoch 6/10, Batch 40/97, Loss: 0.2042
Epoch 6/10, Batch 50/97, Loss: 0.3492
Epoch 6/10, Batch 60/97, Loss: 0.3092
Epoch 6/10, Batch 70/97, Loss: 0.2036
Epoch 6/10, Batch 80/97, Loss: 0.4076
Epoch 6/10, Batch 90/97, Loss: 0.4234
Epoch 6/10, Train Loss: 0.2501, Valid Loss: 0.2489
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1311
Epoch 7/10, Batch 20/97, Loss: 0.2888
Epoch 7/10, Batch 30/97, Loss: 0.2298
Epoch 7/10, Batch 40/97, Loss: 0.1043
Epoch 7/10, Batch 50/97, Loss: 0.2065
Epoch 7/10, Batch 60/97, Loss: 0.3141
Epoch 7/10, Batch 70/97, Loss: 0.1474
Epoch 7/10, Batch 80/97, Loss: 0.2622
Epoch 7/10, Batch 90/97, Loss: 0.2071
Epoch 7/10, Train Loss: 0.2247, Valid Loss: 0.2405
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1626
Epoch 8/10, Batch 20/97, Loss: 0.2498
Epoch 8/10, Batch 30/97, Loss: 0.1389
Epoch 8/10, Batch 40/97, Loss: 0.2019
Epoch 8/10, Batch 50/97, Loss: 0.2168
Epoch 8/10, Batch 60/97, Loss: 0.1621
Epoch 8/10, Batch 70/97, Loss: 0.2224
Epoch 8/10, Batch 80/97, Loss: 0.1571
Epoch 8/10, Batch 90/97, Loss: 0.1737
Epoch 8/10, Train Loss: 0.2195, Valid Loss: 0.2393
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0965
Epoch 9/10, Batch 20/97, Loss: 0.1237
Epoch 9/10, Batch 30/97, Loss: 0.2585
Epoch 9/10, Batch 40/97, Loss: 0.1367
Epoch 9/10, Batch 50/97, Loss: 0.1249
Epoch 9/10, Batch 60/97, Loss: 0.2430
Epoch 9/10, Batch 70/97, Loss: 0.2057
Epoch 9/10, Batch 80/97, Loss: 0.2373
Epoch 9/10, Batch 90/97, Loss: 0.1590
Epoch 9/10, Train Loss: 0.2106, Valid Loss: 0.2323
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2303
Epoch 10/10, Batch 20/97, Loss: 0.1407
Epoch 10/10, Batch 30/97, Loss: 0.1699
Epoch 10/10, Batch 40/97, Loss: 0.1444
Epoch 10/10, Batch 50/97, Loss: 0.1283
Epoch 10/10, Batch 60/97, Loss: 0.0937
Epoch 10/10, Batch 70/97, Loss: 0.2531
Epoch 10/10, Batch 80/97, Loss: 0.1528
Epoch 10/10, Batch 90/97, Loss: 0.1808
Epoch 10/10, Train Loss: 0.2036, Valid Loss: 0.2300
Model saved!
Accuracy: 0.9182
Precision: 0.9156
Recall: 0.9182
F1-score: 0.9160
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2509
Epoch 1/10, Batch 20/97, Loss: 1.1064
Epoch 1/10, Batch 30/97, Loss: 0.7988
Epoch 1/10, Batch 40/97, Loss: 0.7004
Epoch 1/10, Batch 50/97, Loss: 0.6911
Epoch 1/10, Batch 60/97, Loss: 0.7872
Epoch 1/10, Batch 70/97, Loss: 0.6429
Epoch 1/10, Batch 80/97, Loss: 0.6614
Epoch 1/10, Batch 90/97, Loss: 0.5576
Epoch 1/10, Train Loss: 0.8056, Valid Loss: 0.4566
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5406
Epoch 2/10, Batch 20/97, Loss: 0.4004
Epoch 2/10, Batch 30/97, Loss: 0.2807
Epoch 2/10, Batch 40/97, Loss: 0.3591
Epoch 2/10, Batch 50/97, Loss: 0.4348
Epoch 2/10, Batch 60/97, Loss: 0.3436
Epoch 2/10, Batch 70/97, Loss: 0.3919
Epoch 2/10, Batch 80/97, Loss: 0.3156
Epoch 2/10, Batch 90/97, Loss: 0.5037
Epoch 2/10, Train Loss: 0.4081, Valid Loss: 0.3527
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3232
Epoch 3/10, Batch 20/97, Loss: 0.1723
Epoch 3/10, Batch 30/97, Loss: 0.4202
Epoch 3/10, Batch 40/97, Loss: 0.1954
Epoch 3/10, Batch 50/97, Loss: 0.3179
Epoch 3/10, Batch 60/97, Loss: 0.1723
Epoch 3/10, Batch 70/97, Loss: 0.3805
Epoch 3/10, Batch 80/97, Loss: 0.4497
Epoch 3/10, Batch 90/97, Loss: 0.1386
Epoch 3/10, Train Loss: 0.3344, Valid Loss: 0.3132
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4779
Epoch 4/10, Batch 20/97, Loss: 0.1682
Epoch 4/10, Batch 30/97, Loss: 0.3995
Epoch 4/10, Batch 40/97, Loss: 0.1345
Epoch 4/10, Batch 50/97, Loss: 0.3285
Epoch 4/10, Batch 60/97, Loss: 0.2816
Epoch 4/10, Batch 70/97, Loss: 0.2096
Epoch 4/10, Batch 80/97, Loss: 0.2166
Epoch 4/10, Batch 90/97, Loss: 0.1875
Epoch 4/10, Train Loss: 0.2858, Valid Loss: 0.2914
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2420
Epoch 5/10, Batch 20/97, Loss: 0.2163
Epoch 5/10, Batch 30/97, Loss: 0.1719
Epoch 5/10, Batch 40/97, Loss: 0.2514
Epoch 5/10, Batch 50/97, Loss: 0.3880
Epoch 5/10, Batch 60/97, Loss: 0.2531
Epoch 5/10, Batch 70/97, Loss: 0.1541
Epoch 5/10, Batch 80/97, Loss: 0.2742
Epoch 5/10, Batch 90/97, Loss: 0.3146
Epoch 5/10, Train Loss: 0.2704, Valid Loss: 0.2761
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2435
Epoch 6/10, Batch 20/97, Loss: 0.3168
Epoch 6/10, Batch 30/97, Loss: 0.1256
Epoch 6/10, Batch 40/97, Loss: 0.1342
Epoch 6/10, Batch 50/97, Loss: 0.1665
Epoch 6/10, Batch 60/97, Loss: 0.2123
Epoch 6/10, Batch 70/97, Loss: 0.1252
Epoch 6/10, Batch 80/97, Loss: 0.2895
Epoch 6/10, Batch 90/97, Loss: 0.2025
Epoch 6/10, Train Loss: 0.2514, Valid Loss: 0.2581
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2789
Epoch 7/10, Batch 20/97, Loss: 0.3449
Epoch 7/10, Batch 30/97, Loss: 0.1322
Epoch 7/10, Batch 40/97, Loss: 0.1265
Epoch 7/10, Batch 50/97, Loss: 0.2891
Epoch 7/10, Batch 60/97, Loss: 0.1165
Epoch 7/10, Batch 70/97, Loss: 0.2086
Epoch 7/10, Batch 80/97, Loss: 0.2516
Epoch 7/10, Batch 90/97, Loss: 0.1532
Epoch 7/10, Train Loss: 0.2205, Valid Loss: 0.2543
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1319
Epoch 8/10, Batch 20/97, Loss: 0.3635
Epoch 8/10, Batch 30/97, Loss: 0.1957
Epoch 8/10, Batch 40/97, Loss: 0.1552
Epoch 8/10, Batch 50/97, Loss: 0.3189
Epoch 8/10, Batch 60/97, Loss: 0.1176
Epoch 8/10, Batch 70/97, Loss: 0.1825
Epoch 8/10, Batch 80/97, Loss: 0.1015
Epoch 8/10, Batch 90/97, Loss: 0.2220
Epoch 8/10, Train Loss: 0.2199, Valid Loss: 0.2498
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1237
Epoch 9/10, Batch 20/97, Loss: 0.1939
Epoch 9/10, Batch 30/97, Loss: 0.1624
Epoch 9/10, Batch 40/97, Loss: 0.2434
Epoch 9/10, Batch 50/97, Loss: 0.1806
Epoch 9/10, Batch 60/97, Loss: 0.1829
Epoch 9/10, Batch 70/97, Loss: 0.1929
Epoch 9/10, Batch 80/97, Loss: 0.1261
Epoch 9/10, Batch 90/97, Loss: 0.1109
Epoch 9/10, Train Loss: 0.2105, Valid Loss: 0.2418
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2612
Epoch 10/10, Batch 20/97, Loss: 0.1437
Epoch 10/10, Batch 30/97, Loss: 0.1765
Epoch 10/10, Batch 40/97, Loss: 0.1195
Epoch 10/10, Batch 50/97, Loss: 0.2751
Epoch 10/10, Batch 60/97, Loss: 0.1944
Epoch 10/10, Batch 70/97, Loss: 0.2526
Epoch 10/10, Batch 80/97, Loss: 0.1955
Epoch 10/10, Batch 90/97, Loss: 0.1038
Epoch 10/10, Train Loss: 0.1949, Valid Loss: 0.2385
Model saved!
Accuracy: 0.9171
Precision: 0.9144
Recall: 0.9171
F1-score: 0.9149
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.1962
Epoch 1/10, Batch 20/97, Loss: 0.9885
Epoch 1/10, Batch 30/97, Loss: 0.7343
Epoch 1/10, Batch 40/97, Loss: 0.7289
Epoch 1/10, Batch 50/97, Loss: 0.5579
Epoch 1/10, Batch 60/97, Loss: 0.8049
Epoch 1/10, Batch 70/97, Loss: 0.6845
Epoch 1/10, Batch 80/97, Loss: 0.5911
Epoch 1/10, Batch 90/97, Loss: 0.5972
Epoch 1/10, Train Loss: 0.8034, Valid Loss: 0.4241
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6690
Epoch 2/10, Batch 20/97, Loss: 0.4276
Epoch 2/10, Batch 30/97, Loss: 0.3411
Epoch 2/10, Batch 40/97, Loss: 0.4536
Epoch 2/10, Batch 50/97, Loss: 0.3564
Epoch 2/10, Batch 60/97, Loss: 0.5287
Epoch 2/10, Batch 70/97, Loss: 0.2920
Epoch 2/10, Batch 80/97, Loss: 0.2526
Epoch 2/10, Batch 90/97, Loss: 0.3847
Epoch 2/10, Train Loss: 0.4192, Valid Loss: 0.3212
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4175
Epoch 3/10, Batch 20/97, Loss: 0.3532
Epoch 3/10, Batch 30/97, Loss: 0.2340
Epoch 3/10, Batch 40/97, Loss: 0.2502
Epoch 3/10, Batch 50/97, Loss: 0.4905
Epoch 3/10, Batch 60/97, Loss: 0.2779
Epoch 3/10, Batch 70/97, Loss: 0.3845
Epoch 3/10, Batch 80/97, Loss: 0.2721
Epoch 3/10, Batch 90/97, Loss: 0.3457
Epoch 3/10, Train Loss: 0.3345, Valid Loss: 0.2834
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3740
Epoch 4/10, Batch 20/97, Loss: 0.1926
Epoch 4/10, Batch 30/97, Loss: 0.2697
Epoch 4/10, Batch 40/97, Loss: 0.2161
Epoch 4/10, Batch 50/97, Loss: 0.4571
Epoch 4/10, Batch 60/97, Loss: 0.3595
Epoch 4/10, Batch 70/97, Loss: 0.2337
Epoch 4/10, Batch 80/97, Loss: 0.2911
Epoch 4/10, Batch 90/97, Loss: 0.1663
Epoch 4/10, Train Loss: 0.2901, Valid Loss: 0.2662
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2392
Epoch 5/10, Batch 20/97, Loss: 0.1866
Epoch 5/10, Batch 30/97, Loss: 0.2981
Epoch 5/10, Batch 40/97, Loss: 0.2468
Epoch 5/10, Batch 50/97, Loss: 0.2214
Epoch 5/10, Batch 60/97, Loss: 0.1836
Epoch 5/10, Batch 70/97, Loss: 0.3084
Epoch 5/10, Batch 80/97, Loss: 0.2198
Epoch 5/10, Batch 90/97, Loss: 0.2563
Epoch 5/10, Train Loss: 0.2619, Valid Loss: 0.2481
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1770
Epoch 6/10, Batch 20/97, Loss: 0.2393
Epoch 6/10, Batch 30/97, Loss: 0.2585
Epoch 6/10, Batch 40/97, Loss: 0.1269
Epoch 6/10, Batch 50/97, Loss: 0.1675
Epoch 6/10, Batch 60/97, Loss: 0.4313
Epoch 6/10, Batch 70/97, Loss: 0.1056
Epoch 6/10, Batch 80/97, Loss: 0.3079
Epoch 6/10, Batch 90/97, Loss: 0.2100
Epoch 6/10, Train Loss: 0.2485, Valid Loss: 0.2330
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1380
Epoch 7/10, Batch 20/97, Loss: 0.1896
Epoch 7/10, Batch 30/97, Loss: 0.1701
Epoch 7/10, Batch 40/97, Loss: 0.1379
Epoch 7/10, Batch 50/97, Loss: 0.2046
Epoch 7/10, Batch 60/97, Loss: 0.2010
Epoch 7/10, Batch 70/97, Loss: 0.2970
Epoch 7/10, Batch 80/97, Loss: 0.1639
Epoch 7/10, Batch 90/97, Loss: 0.2865
Epoch 7/10, Train Loss: 0.2260, Valid Loss: 0.2262
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1243
Epoch 8/10, Batch 20/97, Loss: 0.1875
Epoch 8/10, Batch 30/97, Loss: 0.2059
Epoch 8/10, Batch 40/97, Loss: 0.2442
Epoch 8/10, Batch 50/97, Loss: 0.2738
Epoch 8/10, Batch 60/97, Loss: 0.1906
Epoch 8/10, Batch 70/97, Loss: 0.1962
Epoch 8/10, Batch 80/97, Loss: 0.0880
Epoch 8/10, Batch 90/97, Loss: 0.2152
Epoch 8/10, Train Loss: 0.2201, Valid Loss: 0.2240
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1012
Epoch 9/10, Batch 20/97, Loss: 0.1667
Epoch 9/10, Batch 30/97, Loss: 0.1976
Epoch 9/10, Batch 40/97, Loss: 0.1488
Epoch 9/10, Batch 50/97, Loss: 0.1132
Epoch 9/10, Batch 60/97, Loss: 0.1425
Epoch 9/10, Batch 70/97, Loss: 0.2310
Epoch 9/10, Batch 80/97, Loss: 0.1505
Epoch 9/10, Batch 90/97, Loss: 0.1876
Epoch 9/10, Train Loss: 0.2037, Valid Loss: 0.2184
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1609
Epoch 10/10, Batch 20/97, Loss: 0.2354
Epoch 10/10, Batch 30/97, Loss: 0.2461
Epoch 10/10, Batch 40/97, Loss: 0.1155
Epoch 10/10, Batch 50/97, Loss: 0.0959
Epoch 10/10, Batch 60/97, Loss: 0.1780
Epoch 10/10, Batch 70/97, Loss: 0.2378
Epoch 10/10, Batch 80/97, Loss: 0.1800
Epoch 10/10, Batch 90/97, Loss: 0.2758
Epoch 10/10, Train Loss: 0.1996, Valid Loss: 0.2268
Accuracy: 0.9217
Precision: 0.9206
Recall: 0.9217
F1-score: 0.9211
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2443
Epoch 1/10, Batch 20/97, Loss: 1.0751
Epoch 1/10, Batch 30/97, Loss: 0.7649
Epoch 1/10, Batch 40/97, Loss: 0.7056
Epoch 1/10, Batch 50/97, Loss: 0.5970
Epoch 1/10, Batch 60/97, Loss: 0.8271
Epoch 1/10, Batch 70/97, Loss: 0.5924
Epoch 1/10, Batch 80/97, Loss: 0.7140
Epoch 1/10, Batch 90/97, Loss: 0.4274
Epoch 1/10, Train Loss: 0.7942, Valid Loss: 0.4455
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3895
Epoch 2/10, Batch 20/97, Loss: 0.3570
Epoch 2/10, Batch 30/97, Loss: 0.2977
Epoch 2/10, Batch 40/97, Loss: 0.4245
Epoch 2/10, Batch 50/97, Loss: 0.3576
Epoch 2/10, Batch 60/97, Loss: 0.5639
Epoch 2/10, Batch 70/97, Loss: 0.3432
Epoch 2/10, Batch 80/97, Loss: 0.3949
Epoch 2/10, Batch 90/97, Loss: 0.3689
Epoch 2/10, Train Loss: 0.4048, Valid Loss: 0.3454
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3453
Epoch 3/10, Batch 20/97, Loss: 0.3253
Epoch 3/10, Batch 30/97, Loss: 0.4578
Epoch 3/10, Batch 40/97, Loss: 0.1996
Epoch 3/10, Batch 50/97, Loss: 0.4810
Epoch 3/10, Batch 60/97, Loss: 0.2172
Epoch 3/10, Batch 70/97, Loss: 0.3120
Epoch 3/10, Batch 80/97, Loss: 0.3679
Epoch 3/10, Batch 90/97, Loss: 0.2740
Epoch 3/10, Train Loss: 0.3258, Valid Loss: 0.3047
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3369
Epoch 4/10, Batch 20/97, Loss: 0.1304
Epoch 4/10, Batch 30/97, Loss: 0.2391
Epoch 4/10, Batch 40/97, Loss: 0.2246
Epoch 4/10, Batch 50/97, Loss: 0.4632
Epoch 4/10, Batch 60/97, Loss: 0.2777
Epoch 4/10, Batch 70/97, Loss: 0.2368
Epoch 4/10, Batch 80/97, Loss: 0.2190
Epoch 4/10, Batch 90/97, Loss: 0.3673
Epoch 4/10, Train Loss: 0.2758, Valid Loss: 0.2886
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1752
Epoch 5/10, Batch 20/97, Loss: 0.4037
Epoch 5/10, Batch 30/97, Loss: 0.3373
Epoch 5/10, Batch 40/97, Loss: 0.3320
Epoch 5/10, Batch 50/97, Loss: 0.2020
Epoch 5/10, Batch 60/97, Loss: 0.2727
Epoch 5/10, Batch 70/97, Loss: 0.4935
Epoch 5/10, Batch 80/97, Loss: 0.1731
Epoch 5/10, Batch 90/97, Loss: 0.2100
Epoch 5/10, Train Loss: 0.2622, Valid Loss: 0.2707
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1713
Epoch 6/10, Batch 20/97, Loss: 0.3601
Epoch 6/10, Batch 30/97, Loss: 0.2115
Epoch 6/10, Batch 40/97, Loss: 0.2229
Epoch 6/10, Batch 50/97, Loss: 0.2803
Epoch 6/10, Batch 60/97, Loss: 0.4327
Epoch 6/10, Batch 70/97, Loss: 0.2434
Epoch 6/10, Batch 80/97, Loss: 0.2910
Epoch 6/10, Batch 90/97, Loss: 0.3059
Epoch 6/10, Train Loss: 0.2390, Valid Loss: 0.2632
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1184
Epoch 7/10, Batch 20/97, Loss: 0.1956
Epoch 7/10, Batch 30/97, Loss: 0.1397
Epoch 7/10, Batch 40/97, Loss: 0.1419
Epoch 7/10, Batch 50/97, Loss: 0.1762
Epoch 7/10, Batch 60/97, Loss: 0.0889
Epoch 7/10, Batch 70/97, Loss: 0.1247
Epoch 7/10, Batch 80/97, Loss: 0.1560
Epoch 7/10, Batch 90/97, Loss: 0.1083
Epoch 7/10, Train Loss: 0.2224, Valid Loss: 0.2513
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2165
Epoch 8/10, Batch 20/97, Loss: 0.2097
Epoch 8/10, Batch 30/97, Loss: 0.1155
Epoch 8/10, Batch 40/97, Loss: 0.3338
Epoch 8/10, Batch 50/97, Loss: 0.2615
Epoch 8/10, Batch 60/97, Loss: 0.2301
Epoch 8/10, Batch 70/97, Loss: 0.1913
Epoch 8/10, Batch 80/97, Loss: 0.1906
Epoch 8/10, Batch 90/97, Loss: 0.1982
Epoch 8/10, Train Loss: 0.2129, Valid Loss: 0.2512
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1414
Epoch 9/10, Batch 20/97, Loss: 0.1546
Epoch 9/10, Batch 30/97, Loss: 0.3267
Epoch 9/10, Batch 40/97, Loss: 0.2898
Epoch 9/10, Batch 50/97, Loss: 0.1149
Epoch 9/10, Batch 60/97, Loss: 0.0760
Epoch 9/10, Batch 70/97, Loss: 0.1118
Epoch 9/10, Batch 80/97, Loss: 0.1577
Epoch 9/10, Batch 90/97, Loss: 0.1757
Epoch 9/10, Train Loss: 0.1976, Valid Loss: 0.2471
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3526
Epoch 10/10, Batch 20/97, Loss: 0.2291
Epoch 10/10, Batch 30/97, Loss: 0.2470
Epoch 10/10, Batch 40/97, Loss: 0.1036
Epoch 10/10, Batch 50/97, Loss: 0.2415
Epoch 10/10, Batch 60/97, Loss: 0.1636
Epoch 10/10, Batch 70/97, Loss: 0.2908
Epoch 10/10, Batch 80/97, Loss: 0.2342
Epoch 10/10, Batch 90/97, Loss: 0.1901
Epoch 10/10, Train Loss: 0.1928, Valid Loss: 0.2434
Model saved!
Accuracy: 0.9124
Precision: 0.9098
Recall: 0.9124
F1-score: 0.9106
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2800
Epoch 1/10, Batch 20/97, Loss: 1.0613
Epoch 1/10, Batch 30/97, Loss: 0.6957
Epoch 1/10, Batch 40/97, Loss: 0.8608
Epoch 1/10, Batch 50/97, Loss: 0.5311
Epoch 1/10, Batch 60/97, Loss: 0.7066
Epoch 1/10, Batch 70/97, Loss: 0.5748
Epoch 1/10, Batch 80/97, Loss: 0.6103
Epoch 1/10, Batch 90/97, Loss: 0.6968
Epoch 1/10, Train Loss: 0.8000, Valid Loss: 0.4440
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6455
Epoch 2/10, Batch 20/97, Loss: 0.3373
Epoch 2/10, Batch 30/97, Loss: 0.3465
Epoch 2/10, Batch 40/97, Loss: 0.2946
Epoch 2/10, Batch 50/97, Loss: 0.5791
Epoch 2/10, Batch 60/97, Loss: 0.5017
Epoch 2/10, Batch 70/97, Loss: 0.3825
Epoch 2/10, Batch 80/97, Loss: 0.4296
Epoch 2/10, Batch 90/97, Loss: 0.3513
Epoch 2/10, Train Loss: 0.4197, Valid Loss: 0.3422
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2956
Epoch 3/10, Batch 20/97, Loss: 0.3199
Epoch 3/10, Batch 30/97, Loss: 0.3707
Epoch 3/10, Batch 40/97, Loss: 0.4912
Epoch 3/10, Batch 50/97, Loss: 0.5438
Epoch 3/10, Batch 60/97, Loss: 0.3422
Epoch 3/10, Batch 70/97, Loss: 0.4840
Epoch 3/10, Batch 80/97, Loss: 0.3981
Epoch 3/10, Batch 90/97, Loss: 0.3132
Epoch 3/10, Train Loss: 0.3343, Valid Loss: 0.3082
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3097
Epoch 4/10, Batch 20/97, Loss: 0.3480
Epoch 4/10, Batch 30/97, Loss: 0.2953
Epoch 4/10, Batch 40/97, Loss: 0.2103
Epoch 4/10, Batch 50/97, Loss: 0.2025
Epoch 4/10, Batch 60/97, Loss: 0.1989
Epoch 4/10, Batch 70/97, Loss: 0.4272
Epoch 4/10, Batch 80/97, Loss: 0.2563
Epoch 4/10, Batch 90/97, Loss: 0.2175
Epoch 4/10, Train Loss: 0.2848, Valid Loss: 0.2830
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2010
Epoch 5/10, Batch 20/97, Loss: 0.2752
Epoch 5/10, Batch 30/97, Loss: 0.1533
Epoch 5/10, Batch 40/97, Loss: 0.2431
Epoch 5/10, Batch 50/97, Loss: 0.1012
Epoch 5/10, Batch 60/97, Loss: 0.2246
Epoch 5/10, Batch 70/97, Loss: 0.2351
Epoch 5/10, Batch 80/97, Loss: 0.2265
Epoch 5/10, Batch 90/97, Loss: 0.1648
Epoch 5/10, Train Loss: 0.2697, Valid Loss: 0.2686
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2146
Epoch 6/10, Batch 20/97, Loss: 0.3517
Epoch 6/10, Batch 30/97, Loss: 0.2200
Epoch 6/10, Batch 40/97, Loss: 0.1650
Epoch 6/10, Batch 50/97, Loss: 0.2611
Epoch 6/10, Batch 60/97, Loss: 0.3342
Epoch 6/10, Batch 70/97, Loss: 0.1798
Epoch 6/10, Batch 80/97, Loss: 0.3005
Epoch 6/10, Batch 90/97, Loss: 0.2923
Epoch 6/10, Train Loss: 0.2468, Valid Loss: 0.2550
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1933
Epoch 7/10, Batch 20/97, Loss: 0.3293
Epoch 7/10, Batch 30/97, Loss: 0.1120
Epoch 7/10, Batch 40/97, Loss: 0.1995
Epoch 7/10, Batch 50/97, Loss: 0.1851
Epoch 7/10, Batch 60/97, Loss: 0.3508
Epoch 7/10, Batch 70/97, Loss: 0.1186
Epoch 7/10, Batch 80/97, Loss: 0.2571
Epoch 7/10, Batch 90/97, Loss: 0.1756
Epoch 7/10, Train Loss: 0.2306, Valid Loss: 0.2467
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1570
Epoch 8/10, Batch 20/97, Loss: 0.1599
Epoch 8/10, Batch 30/97, Loss: 0.1795
Epoch 8/10, Batch 40/97, Loss: 0.1953
Epoch 8/10, Batch 50/97, Loss: 0.2612
Epoch 8/10, Batch 60/97, Loss: 0.2376
Epoch 8/10, Batch 70/97, Loss: 0.3365
Epoch 8/10, Batch 80/97, Loss: 0.1559
Epoch 8/10, Batch 90/97, Loss: 0.2654
Epoch 8/10, Train Loss: 0.2131, Valid Loss: 0.2465
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0537
Epoch 9/10, Batch 20/97, Loss: 0.1621
Epoch 9/10, Batch 30/97, Loss: 0.1661
Epoch 9/10, Batch 40/97, Loss: 0.2667
Epoch 9/10, Batch 50/97, Loss: 0.3049
Epoch 9/10, Batch 60/97, Loss: 0.1574
Epoch 9/10, Batch 70/97, Loss: 0.1211
Epoch 9/10, Batch 80/97, Loss: 0.1837
Epoch 9/10, Batch 90/97, Loss: 0.2304
Epoch 9/10, Train Loss: 0.2009, Valid Loss: 0.2486
Epoch 10/10, Batch 10/97, Loss: 0.2087
Epoch 10/10, Batch 20/97, Loss: 0.2210
Epoch 10/10, Batch 30/97, Loss: 0.2497
Epoch 10/10, Batch 40/97, Loss: 0.0653
Epoch 10/10, Batch 50/97, Loss: 0.1899
Epoch 10/10, Batch 60/97, Loss: 0.1267
Epoch 10/10, Batch 70/97, Loss: 0.1621
Epoch 10/10, Batch 80/97, Loss: 0.1053
Epoch 10/10, Batch 90/97, Loss: 0.1721
Epoch 10/10, Train Loss: 0.2046, Valid Loss: 0.2355
Model saved!
Accuracy: 0.9182
Precision: 0.9162
Recall: 0.9182
F1-score: 0.9162
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2501
Epoch 1/10, Batch 20/97, Loss: 1.0779
Epoch 1/10, Batch 30/97, Loss: 0.7663
Epoch 1/10, Batch 40/97, Loss: 0.7152
Epoch 1/10, Batch 50/97, Loss: 0.6782
Epoch 1/10, Batch 60/97, Loss: 0.7227
Epoch 1/10, Batch 70/97, Loss: 0.6941
Epoch 1/10, Batch 80/97, Loss: 0.6826
Epoch 1/10, Batch 90/97, Loss: 0.4722
Epoch 1/10, Train Loss: 0.8064, Valid Loss: 0.4353
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5856
Epoch 2/10, Batch 20/97, Loss: 0.5631
Epoch 2/10, Batch 30/97, Loss: 0.4424
Epoch 2/10, Batch 40/97, Loss: 0.4630
Epoch 2/10, Batch 50/97, Loss: 0.4180
Epoch 2/10, Batch 60/97, Loss: 0.4494
Epoch 2/10, Batch 70/97, Loss: 0.3419
Epoch 2/10, Batch 80/97, Loss: 0.3665
Epoch 2/10, Batch 90/97, Loss: 0.5568
Epoch 2/10, Train Loss: 0.4139, Valid Loss: 0.3269
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4860
Epoch 3/10, Batch 20/97, Loss: 0.3960
Epoch 3/10, Batch 30/97, Loss: 0.4759
Epoch 3/10, Batch 40/97, Loss: 0.2288
Epoch 3/10, Batch 50/97, Loss: 0.4791
Epoch 3/10, Batch 60/97, Loss: 0.2008
Epoch 3/10, Batch 70/97, Loss: 0.3665
Epoch 3/10, Batch 80/97, Loss: 0.2317
Epoch 3/10, Batch 90/97, Loss: 0.2392
Epoch 3/10, Train Loss: 0.3435, Valid Loss: 0.2832
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3575
Epoch 4/10, Batch 20/97, Loss: 0.2538
Epoch 4/10, Batch 30/97, Loss: 0.2326
Epoch 4/10, Batch 40/97, Loss: 0.1753
Epoch 4/10, Batch 50/97, Loss: 0.5045
Epoch 4/10, Batch 60/97, Loss: 0.1656
Epoch 4/10, Batch 70/97, Loss: 0.2941
Epoch 4/10, Batch 80/97, Loss: 0.2852
Epoch 4/10, Batch 90/97, Loss: 0.2170
Epoch 4/10, Train Loss: 0.2876, Valid Loss: 0.2640
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.4288
Epoch 5/10, Batch 20/97, Loss: 0.3678
Epoch 5/10, Batch 30/97, Loss: 0.1497
Epoch 5/10, Batch 40/97, Loss: 0.3079
Epoch 5/10, Batch 50/97, Loss: 0.2331
Epoch 5/10, Batch 60/97, Loss: 0.2300
Epoch 5/10, Batch 70/97, Loss: 0.5102
Epoch 5/10, Batch 80/97, Loss: 0.1371
Epoch 5/10, Batch 90/97, Loss: 0.1461
Epoch 5/10, Train Loss: 0.2674, Valid Loss: 0.2639
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2096
Epoch 6/10, Batch 20/97, Loss: 0.3305
Epoch 6/10, Batch 30/97, Loss: 0.2122
Epoch 6/10, Batch 40/97, Loss: 0.1246
Epoch 6/10, Batch 50/97, Loss: 0.2803
Epoch 6/10, Batch 60/97, Loss: 0.2819
Epoch 6/10, Batch 70/97, Loss: 0.1920
Epoch 6/10, Batch 80/97, Loss: 0.2109
Epoch 6/10, Batch 90/97, Loss: 0.2262
Epoch 6/10, Train Loss: 0.2448, Valid Loss: 0.2342
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.0774
Epoch 7/10, Batch 20/97, Loss: 0.4049
Epoch 7/10, Batch 30/97, Loss: 0.1704
Epoch 7/10, Batch 40/97, Loss: 0.2373
Epoch 7/10, Batch 50/97, Loss: 0.1995
Epoch 7/10, Batch 60/97, Loss: 0.0737
Epoch 7/10, Batch 70/97, Loss: 0.1642
Epoch 7/10, Batch 80/97, Loss: 0.2170
Epoch 7/10, Batch 90/97, Loss: 0.2610
Epoch 7/10, Train Loss: 0.2262, Valid Loss: 0.2335
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2117
Epoch 8/10, Batch 20/97, Loss: 0.2263
Epoch 8/10, Batch 30/97, Loss: 0.1540
Epoch 8/10, Batch 40/97, Loss: 0.1818
Epoch 8/10, Batch 50/97, Loss: 0.1229
Epoch 8/10, Batch 60/97, Loss: 0.1047
Epoch 8/10, Batch 70/97, Loss: 0.1950
Epoch 8/10, Batch 80/97, Loss: 0.4134
Epoch 8/10, Batch 90/97, Loss: 0.3024
Epoch 8/10, Train Loss: 0.2191, Valid Loss: 0.2334
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2603
Epoch 9/10, Batch 20/97, Loss: 0.1265
Epoch 9/10, Batch 30/97, Loss: 0.1616
Epoch 9/10, Batch 40/97, Loss: 0.2870
Epoch 9/10, Batch 50/97, Loss: 0.1443
Epoch 9/10, Batch 60/97, Loss: 0.2103
Epoch 9/10, Batch 70/97, Loss: 0.1852
Epoch 9/10, Batch 80/97, Loss: 0.2313
Epoch 9/10, Batch 90/97, Loss: 0.1151
Epoch 9/10, Train Loss: 0.2124, Valid Loss: 0.2279
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2890
Epoch 10/10, Batch 20/97, Loss: 0.1877
Epoch 10/10, Batch 30/97, Loss: 0.2359
Epoch 10/10, Batch 40/97, Loss: 0.1400
Epoch 10/10, Batch 50/97, Loss: 0.1409
Epoch 10/10, Batch 60/97, Loss: 0.1358
Epoch 10/10, Batch 70/97, Loss: 0.2365
Epoch 10/10, Batch 80/97, Loss: 0.2635
Epoch 10/10, Batch 90/97, Loss: 0.2197
Epoch 10/10, Train Loss: 0.2015, Valid Loss: 0.2330
Accuracy: 0.9217
Precision: 0.9203
Recall: 0.9217
F1-score: 0.9207
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2812
Epoch 1/10, Batch 20/97, Loss: 1.1031
Epoch 1/10, Batch 30/97, Loss: 0.7550
Epoch 1/10, Batch 40/97, Loss: 0.7385
Epoch 1/10, Batch 50/97, Loss: 0.7153
Epoch 1/10, Batch 60/97, Loss: 0.6961
Epoch 1/10, Batch 70/97, Loss: 0.6103
Epoch 1/10, Batch 80/97, Loss: 0.5524
Epoch 1/10, Batch 90/97, Loss: 0.5340
Epoch 1/10, Train Loss: 0.7969, Valid Loss: 0.4473
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4704
Epoch 2/10, Batch 20/97, Loss: 0.5305
Epoch 2/10, Batch 30/97, Loss: 0.2860
Epoch 2/10, Batch 40/97, Loss: 0.2996
Epoch 2/10, Batch 50/97, Loss: 0.3007
Epoch 2/10, Batch 60/97, Loss: 0.3706
Epoch 2/10, Batch 70/97, Loss: 0.3300
Epoch 2/10, Batch 80/97, Loss: 0.2881
Epoch 2/10, Batch 90/97, Loss: 0.4910
Epoch 2/10, Train Loss: 0.4107, Valid Loss: 0.3331
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.5362
Epoch 3/10, Batch 20/97, Loss: 0.3553
Epoch 3/10, Batch 30/97, Loss: 0.3933
Epoch 3/10, Batch 40/97, Loss: 0.2488
Epoch 3/10, Batch 50/97, Loss: 0.2406
Epoch 3/10, Batch 60/97, Loss: 0.2145
Epoch 3/10, Batch 70/97, Loss: 0.4705
Epoch 3/10, Batch 80/97, Loss: 0.3434
Epoch 3/10, Batch 90/97, Loss: 0.3389
Epoch 3/10, Train Loss: 0.3422, Valid Loss: 0.2996
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.6357
Epoch 4/10, Batch 20/97, Loss: 0.2599
Epoch 4/10, Batch 30/97, Loss: 0.2076
Epoch 4/10, Batch 40/97, Loss: 0.4080
Epoch 4/10, Batch 50/97, Loss: 0.2621
Epoch 4/10, Batch 60/97, Loss: 0.2025
Epoch 4/10, Batch 70/97, Loss: 0.2456
Epoch 4/10, Batch 80/97, Loss: 0.2232
Epoch 4/10, Batch 90/97, Loss: 0.2428
Epoch 4/10, Train Loss: 0.2784, Valid Loss: 0.2814
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1500
Epoch 5/10, Batch 20/97, Loss: 0.4164
Epoch 5/10, Batch 30/97, Loss: 0.2542
Epoch 5/10, Batch 40/97, Loss: 0.2557
Epoch 5/10, Batch 50/97, Loss: 0.4531
Epoch 5/10, Batch 60/97, Loss: 0.2259
Epoch 5/10, Batch 70/97, Loss: 0.2657
Epoch 5/10, Batch 80/97, Loss: 0.1030
Epoch 5/10, Batch 90/97, Loss: 0.2548
Epoch 5/10, Train Loss: 0.2651, Valid Loss: 0.2636
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3381
Epoch 6/10, Batch 20/97, Loss: 0.2172
Epoch 6/10, Batch 30/97, Loss: 0.2076
Epoch 6/10, Batch 40/97, Loss: 0.2066
Epoch 6/10, Batch 50/97, Loss: 0.2087
Epoch 6/10, Batch 60/97, Loss: 0.3452
Epoch 6/10, Batch 70/97, Loss: 0.3269
Epoch 6/10, Batch 80/97, Loss: 0.4079
Epoch 6/10, Batch 90/97, Loss: 0.4037
Epoch 6/10, Train Loss: 0.2436, Valid Loss: 0.2534
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2219
Epoch 7/10, Batch 20/97, Loss: 0.3342
Epoch 7/10, Batch 30/97, Loss: 0.1530
Epoch 7/10, Batch 40/97, Loss: 0.1537
Epoch 7/10, Batch 50/97, Loss: 0.1522
Epoch 7/10, Batch 60/97, Loss: 0.1688
Epoch 7/10, Batch 70/97, Loss: 0.2864
Epoch 7/10, Batch 80/97, Loss: 0.1830
Epoch 7/10, Batch 90/97, Loss: 0.2205
Epoch 7/10, Train Loss: 0.2216, Valid Loss: 0.2436
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1088
Epoch 8/10, Batch 20/97, Loss: 0.1877
Epoch 8/10, Batch 30/97, Loss: 0.1812
Epoch 8/10, Batch 40/97, Loss: 0.1927
Epoch 8/10, Batch 50/97, Loss: 0.1853
Epoch 8/10, Batch 60/97, Loss: 0.1426
Epoch 8/10, Batch 70/97, Loss: 0.1853
Epoch 8/10, Batch 80/97, Loss: 0.2482
Epoch 8/10, Batch 90/97, Loss: 0.2679
Epoch 8/10, Train Loss: 0.2197, Valid Loss: 0.2431
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1141
Epoch 9/10, Batch 20/97, Loss: 0.1921
Epoch 9/10, Batch 30/97, Loss: 0.3058
Epoch 9/10, Batch 40/97, Loss: 0.1334
Epoch 9/10, Batch 50/97, Loss: 0.1424
Epoch 9/10, Batch 60/97, Loss: 0.3027
Epoch 9/10, Batch 70/97, Loss: 0.2205
Epoch 9/10, Batch 80/97, Loss: 0.2148
Epoch 9/10, Batch 90/97, Loss: 0.1044
Epoch 9/10, Train Loss: 0.2073, Valid Loss: 0.2400
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3160
Epoch 10/10, Batch 20/97, Loss: 0.2452
Epoch 10/10, Batch 30/97, Loss: 0.3015
Epoch 10/10, Batch 40/97, Loss: 0.1210
Epoch 10/10, Batch 50/97, Loss: 0.1665
Epoch 10/10, Batch 60/97, Loss: 0.0735
Epoch 10/10, Batch 70/97, Loss: 0.3578
Epoch 10/10, Batch 80/97, Loss: 0.2493
Epoch 10/10, Batch 90/97, Loss: 0.1552
Epoch 10/10, Train Loss: 0.2055, Valid Loss: 0.2404
Accuracy: 0.9112
Precision: 0.9092
Recall: 0.9112
F1-score: 0.9096
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2732
Epoch 1/10, Batch 20/97, Loss: 1.0666
Epoch 1/10, Batch 30/97, Loss: 0.7431
Epoch 1/10, Batch 40/97, Loss: 0.7835
Epoch 1/10, Batch 50/97, Loss: 0.5708
Epoch 1/10, Batch 60/97, Loss: 0.7727
Epoch 1/10, Batch 70/97, Loss: 0.7562
Epoch 1/10, Batch 80/97, Loss: 0.6214
Epoch 1/10, Batch 90/97, Loss: 0.4824
Epoch 1/10, Train Loss: 0.8003, Valid Loss: 0.4459
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6409
Epoch 2/10, Batch 20/97, Loss: 0.4173
Epoch 2/10, Batch 30/97, Loss: 0.4467
Epoch 2/10, Batch 40/97, Loss: 0.3870
Epoch 2/10, Batch 50/97, Loss: 0.4527
Epoch 2/10, Batch 60/97, Loss: 0.4019
Epoch 2/10, Batch 70/97, Loss: 0.4353
Epoch 2/10, Batch 80/97, Loss: 0.3622
Epoch 2/10, Batch 90/97, Loss: 0.3849
Epoch 2/10, Train Loss: 0.4141, Valid Loss: 0.3403
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3683
Epoch 3/10, Batch 20/97, Loss: 0.4945
Epoch 3/10, Batch 30/97, Loss: 0.3709
Epoch 3/10, Batch 40/97, Loss: 0.3304
Epoch 3/10, Batch 50/97, Loss: 0.3634
Epoch 3/10, Batch 60/97, Loss: 0.1644
Epoch 3/10, Batch 70/97, Loss: 0.2571
Epoch 3/10, Batch 80/97, Loss: 0.3761
Epoch 3/10, Batch 90/97, Loss: 0.3695
Epoch 3/10, Train Loss: 0.3333, Valid Loss: 0.3002
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3296
Epoch 4/10, Batch 20/97, Loss: 0.3119
Epoch 4/10, Batch 30/97, Loss: 0.3338
Epoch 4/10, Batch 40/97, Loss: 0.2081
Epoch 4/10, Batch 50/97, Loss: 0.3325
Epoch 4/10, Batch 60/97, Loss: 0.2077
Epoch 4/10, Batch 70/97, Loss: 0.2447
Epoch 4/10, Batch 80/97, Loss: 0.2960
Epoch 4/10, Batch 90/97, Loss: 0.2432
Epoch 4/10, Train Loss: 0.2887, Valid Loss: 0.2892
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2845
Epoch 5/10, Batch 20/97, Loss: 0.3273
Epoch 5/10, Batch 30/97, Loss: 0.3655
Epoch 5/10, Batch 40/97, Loss: 0.2565
Epoch 5/10, Batch 50/97, Loss: 0.2140
Epoch 5/10, Batch 60/97, Loss: 0.2854
Epoch 5/10, Batch 70/97, Loss: 0.3179
Epoch 5/10, Batch 80/97, Loss: 0.2407
Epoch 5/10, Batch 90/97, Loss: 0.2859
Epoch 5/10, Train Loss: 0.2710, Valid Loss: 0.2601
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1467
Epoch 6/10, Batch 20/97, Loss: 0.4095
Epoch 6/10, Batch 30/97, Loss: 0.1440
Epoch 6/10, Batch 40/97, Loss: 0.2870
Epoch 6/10, Batch 50/97, Loss: 0.1544
Epoch 6/10, Batch 60/97, Loss: 0.2175
Epoch 6/10, Batch 70/97, Loss: 0.2305
Epoch 6/10, Batch 80/97, Loss: 0.3353
Epoch 6/10, Batch 90/97, Loss: 0.4377
Epoch 6/10, Train Loss: 0.2442, Valid Loss: 0.2490
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1795
Epoch 7/10, Batch 20/97, Loss: 0.1727
Epoch 7/10, Batch 30/97, Loss: 0.2812
Epoch 7/10, Batch 40/97, Loss: 0.2637
Epoch 7/10, Batch 50/97, Loss: 0.2547
Epoch 7/10, Batch 60/97, Loss: 0.2473
Epoch 7/10, Batch 70/97, Loss: 0.2200
Epoch 7/10, Batch 80/97, Loss: 0.2324
Epoch 7/10, Batch 90/97, Loss: 0.2415
Epoch 7/10, Train Loss: 0.2319, Valid Loss: 0.2470
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1568
Epoch 8/10, Batch 20/97, Loss: 0.2060
Epoch 8/10, Batch 30/97, Loss: 0.1114
Epoch 8/10, Batch 40/97, Loss: 0.2167
Epoch 8/10, Batch 50/97, Loss: 0.3422
Epoch 8/10, Batch 60/97, Loss: 0.2097
Epoch 8/10, Batch 70/97, Loss: 0.2004
Epoch 8/10, Batch 80/97, Loss: 0.1911
Epoch 8/10, Batch 90/97, Loss: 0.1354
Epoch 8/10, Train Loss: 0.2255, Valid Loss: 0.2420
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1223
Epoch 9/10, Batch 20/97, Loss: 0.0916
Epoch 9/10, Batch 30/97, Loss: 0.3259
Epoch 9/10, Batch 40/97, Loss: 0.2327
Epoch 9/10, Batch 50/97, Loss: 0.1445
Epoch 9/10, Batch 60/97, Loss: 0.1833
Epoch 9/10, Batch 70/97, Loss: 0.1457
Epoch 9/10, Batch 80/97, Loss: 0.1413
Epoch 9/10, Batch 90/97, Loss: 0.1922
Epoch 9/10, Train Loss: 0.2098, Valid Loss: 0.2369
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2595
Epoch 10/10, Batch 20/97, Loss: 0.1193
Epoch 10/10, Batch 30/97, Loss: 0.1809
Epoch 10/10, Batch 40/97, Loss: 0.1406
Epoch 10/10, Batch 50/97, Loss: 0.0972
Epoch 10/10, Batch 60/97, Loss: 0.0965
Epoch 10/10, Batch 70/97, Loss: 0.2593
Epoch 10/10, Batch 80/97, Loss: 0.1663
Epoch 10/10, Batch 90/97, Loss: 0.1931
Epoch 10/10, Train Loss: 0.2047, Valid Loss: 0.2376
Accuracy: 0.9147
Precision: 0.9123
Recall: 0.9147
F1-score: 0.9130
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2189
Epoch 1/10, Batch 20/97, Loss: 1.0469
Epoch 1/10, Batch 30/97, Loss: 0.7307
Epoch 1/10, Batch 40/97, Loss: 0.7605
Epoch 1/10, Batch 50/97, Loss: 0.6611
Epoch 1/10, Batch 60/97, Loss: 0.7964
Epoch 1/10, Batch 70/97, Loss: 0.6870
Epoch 1/10, Batch 80/97, Loss: 0.6782
Epoch 1/10, Batch 90/97, Loss: 0.5204
Epoch 1/10, Train Loss: 0.8175, Valid Loss: 0.4489
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5033
Epoch 2/10, Batch 20/97, Loss: 0.4220
Epoch 2/10, Batch 30/97, Loss: 0.3410
Epoch 2/10, Batch 40/97, Loss: 0.4410
Epoch 2/10, Batch 50/97, Loss: 0.2716
Epoch 2/10, Batch 60/97, Loss: 0.4190
Epoch 2/10, Batch 70/97, Loss: 0.3117
Epoch 2/10, Batch 80/97, Loss: 0.3400
Epoch 2/10, Batch 90/97, Loss: 0.3221
Epoch 2/10, Train Loss: 0.4240, Valid Loss: 0.3186
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4374
Epoch 3/10, Batch 20/97, Loss: 0.4239
Epoch 3/10, Batch 30/97, Loss: 0.4112
Epoch 3/10, Batch 40/97, Loss: 0.2863
Epoch 3/10, Batch 50/97, Loss: 0.2600
Epoch 3/10, Batch 60/97, Loss: 0.2335
Epoch 3/10, Batch 70/97, Loss: 0.3730
Epoch 3/10, Batch 80/97, Loss: 0.2966
Epoch 3/10, Batch 90/97, Loss: 0.2373
Epoch 3/10, Train Loss: 0.3416, Valid Loss: 0.2759
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4142
Epoch 4/10, Batch 20/97, Loss: 0.1917
Epoch 4/10, Batch 30/97, Loss: 0.2409
Epoch 4/10, Batch 40/97, Loss: 0.3023
Epoch 4/10, Batch 50/97, Loss: 0.4323
Epoch 4/10, Batch 60/97, Loss: 0.2527
Epoch 4/10, Batch 70/97, Loss: 0.1901
Epoch 4/10, Batch 80/97, Loss: 0.2616
Epoch 4/10, Batch 90/97, Loss: 0.3994
Epoch 4/10, Train Loss: 0.3008, Valid Loss: 0.2638
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2298
Epoch 5/10, Batch 20/97, Loss: 0.3145
Epoch 5/10, Batch 30/97, Loss: 0.2150
Epoch 5/10, Batch 40/97, Loss: 0.2316
Epoch 5/10, Batch 50/97, Loss: 0.2807
Epoch 5/10, Batch 60/97, Loss: 0.2189
Epoch 5/10, Batch 70/97, Loss: 0.1999
Epoch 5/10, Batch 80/97, Loss: 0.3580
Epoch 5/10, Batch 90/97, Loss: 0.2524
Epoch 5/10, Train Loss: 0.2787, Valid Loss: 0.2371
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2106
Epoch 6/10, Batch 20/97, Loss: 0.2831
Epoch 6/10, Batch 30/97, Loss: 0.2603
Epoch 6/10, Batch 40/97, Loss: 0.2571
Epoch 6/10, Batch 50/97, Loss: 0.2127
Epoch 6/10, Batch 60/97, Loss: 0.3716
Epoch 6/10, Batch 70/97, Loss: 0.3178
Epoch 6/10, Batch 80/97, Loss: 0.2662
Epoch 6/10, Batch 90/97, Loss: 0.3050
Epoch 6/10, Train Loss: 0.2589, Valid Loss: 0.2268
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1957
Epoch 7/10, Batch 20/97, Loss: 0.3044
Epoch 7/10, Batch 30/97, Loss: 0.1287
Epoch 7/10, Batch 40/97, Loss: 0.1252
Epoch 7/10, Batch 50/97, Loss: 0.1707
Epoch 7/10, Batch 60/97, Loss: 0.2012
Epoch 7/10, Batch 70/97, Loss: 0.4626
Epoch 7/10, Batch 80/97, Loss: 0.1737
Epoch 7/10, Batch 90/97, Loss: 0.2050
Epoch 7/10, Train Loss: 0.2357, Valid Loss: 0.2207
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2432
Epoch 8/10, Batch 20/97, Loss: 0.2034
Epoch 8/10, Batch 30/97, Loss: 0.1927
Epoch 8/10, Batch 40/97, Loss: 0.2199
Epoch 8/10, Batch 50/97, Loss: 0.2368
Epoch 8/10, Batch 60/97, Loss: 0.1962
Epoch 8/10, Batch 70/97, Loss: 0.2189
Epoch 8/10, Batch 80/97, Loss: 0.0924
Epoch 8/10, Batch 90/97, Loss: 0.2351
Epoch 8/10, Train Loss: 0.2324, Valid Loss: 0.2153
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2541
Epoch 9/10, Batch 20/97, Loss: 0.1243
Epoch 9/10, Batch 30/97, Loss: 0.2486
Epoch 9/10, Batch 40/97, Loss: 0.1623
Epoch 9/10, Batch 50/97, Loss: 0.1517
Epoch 9/10, Batch 60/97, Loss: 0.1828
Epoch 9/10, Batch 70/97, Loss: 0.1278
Epoch 9/10, Batch 80/97, Loss: 0.2105
Epoch 9/10, Batch 90/97, Loss: 0.1195
Epoch 9/10, Train Loss: 0.2153, Valid Loss: 0.2146
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3479
Epoch 10/10, Batch 20/97, Loss: 0.1009
Epoch 10/10, Batch 30/97, Loss: 0.1279
Epoch 10/10, Batch 40/97, Loss: 0.1599
Epoch 10/10, Batch 50/97, Loss: 0.2841
Epoch 10/10, Batch 60/97, Loss: 0.1776
Epoch 10/10, Batch 70/97, Loss: 0.3800
Epoch 10/10, Batch 80/97, Loss: 0.2445
Epoch 10/10, Batch 90/97, Loss: 0.2873
Epoch 10/10, Train Loss: 0.2098, Valid Loss: 0.2158
Accuracy: 0.9229
Precision: 0.9205
Recall: 0.9229
F1-score: 0.9207
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2425
Epoch 1/10, Batch 20/97, Loss: 1.0804
Epoch 1/10, Batch 30/97, Loss: 0.8236
Epoch 1/10, Batch 40/97, Loss: 0.6344
Epoch 1/10, Batch 50/97, Loss: 0.7352
Epoch 1/10, Batch 60/97, Loss: 0.6250
Epoch 1/10, Batch 70/97, Loss: 0.6718
Epoch 1/10, Batch 80/97, Loss: 0.6521
Epoch 1/10, Batch 90/97, Loss: 0.5836
Epoch 1/10, Train Loss: 0.8079, Valid Loss: 0.4497
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4278
Epoch 2/10, Batch 20/97, Loss: 0.4912
Epoch 2/10, Batch 30/97, Loss: 0.3405
Epoch 2/10, Batch 40/97, Loss: 0.3404
Epoch 2/10, Batch 50/97, Loss: 0.4015
Epoch 2/10, Batch 60/97, Loss: 0.4364
Epoch 2/10, Batch 70/97, Loss: 0.3549
Epoch 2/10, Batch 80/97, Loss: 0.2582
Epoch 2/10, Batch 90/97, Loss: 0.4352
Epoch 2/10, Train Loss: 0.4122, Valid Loss: 0.3438
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3245
Epoch 3/10, Batch 20/97, Loss: 0.1569
Epoch 3/10, Batch 30/97, Loss: 0.3676
Epoch 3/10, Batch 40/97, Loss: 0.2095
Epoch 3/10, Batch 50/97, Loss: 0.5715
Epoch 3/10, Batch 60/97, Loss: 0.2547
Epoch 3/10, Batch 70/97, Loss: 0.3789
Epoch 3/10, Batch 80/97, Loss: 0.2295
Epoch 3/10, Batch 90/97, Loss: 0.2267
Epoch 3/10, Train Loss: 0.3330, Valid Loss: 0.2940
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2499
Epoch 4/10, Batch 20/97, Loss: 0.2234
Epoch 4/10, Batch 30/97, Loss: 0.2882
Epoch 4/10, Batch 40/97, Loss: 0.1275
Epoch 4/10, Batch 50/97, Loss: 0.2058
Epoch 4/10, Batch 60/97, Loss: 0.2919
Epoch 4/10, Batch 70/97, Loss: 0.2657
Epoch 4/10, Batch 80/97, Loss: 0.1998
Epoch 4/10, Batch 90/97, Loss: 0.3717
Epoch 4/10, Train Loss: 0.2830, Valid Loss: 0.2744
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2187
Epoch 5/10, Batch 20/97, Loss: 0.4112
Epoch 5/10, Batch 30/97, Loss: 0.2014
Epoch 5/10, Batch 40/97, Loss: 0.4026
Epoch 5/10, Batch 50/97, Loss: 0.2032
Epoch 5/10, Batch 60/97, Loss: 0.1706
Epoch 5/10, Batch 70/97, Loss: 0.3311
Epoch 5/10, Batch 80/97, Loss: 0.2247
Epoch 5/10, Batch 90/97, Loss: 0.3023
Epoch 5/10, Train Loss: 0.2696, Valid Loss: 0.2567
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3178
Epoch 6/10, Batch 20/97, Loss: 0.2246
Epoch 6/10, Batch 30/97, Loss: 0.1637
Epoch 6/10, Batch 40/97, Loss: 0.2135
Epoch 6/10, Batch 50/97, Loss: 0.1914
Epoch 6/10, Batch 60/97, Loss: 0.2324
Epoch 6/10, Batch 70/97, Loss: 0.1821
Epoch 6/10, Batch 80/97, Loss: 0.4491
Epoch 6/10, Batch 90/97, Loss: 0.3531
Epoch 6/10, Train Loss: 0.2436, Valid Loss: 0.2493
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1318
Epoch 7/10, Batch 20/97, Loss: 0.1641
Epoch 7/10, Batch 30/97, Loss: 0.2102
Epoch 7/10, Batch 40/97, Loss: 0.1765
Epoch 7/10, Batch 50/97, Loss: 0.4410
Epoch 7/10, Batch 60/97, Loss: 0.3382
Epoch 7/10, Batch 70/97, Loss: 0.2685
Epoch 7/10, Batch 80/97, Loss: 0.2312
Epoch 7/10, Batch 90/97, Loss: 0.2400
Epoch 7/10, Train Loss: 0.2228, Valid Loss: 0.2419
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2872
Epoch 8/10, Batch 20/97, Loss: 0.2323
Epoch 8/10, Batch 30/97, Loss: 0.1949
Epoch 8/10, Batch 40/97, Loss: 0.1914
Epoch 8/10, Batch 50/97, Loss: 0.3023
Epoch 8/10, Batch 60/97, Loss: 0.2269
Epoch 8/10, Batch 70/97, Loss: 0.2011
Epoch 8/10, Batch 80/97, Loss: 0.1029
Epoch 8/10, Batch 90/97, Loss: 0.2164
Epoch 8/10, Train Loss: 0.2183, Valid Loss: 0.2342
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1181
Epoch 9/10, Batch 20/97, Loss: 0.1816
Epoch 9/10, Batch 30/97, Loss: 0.3061
Epoch 9/10, Batch 40/97, Loss: 0.2180
Epoch 9/10, Batch 50/97, Loss: 0.2164
Epoch 9/10, Batch 60/97, Loss: 0.2990
Epoch 9/10, Batch 70/97, Loss: 0.1510
Epoch 9/10, Batch 80/97, Loss: 0.1735
Epoch 9/10, Batch 90/97, Loss: 0.2575
Epoch 9/10, Train Loss: 0.2127, Valid Loss: 0.2267
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2262
Epoch 10/10, Batch 20/97, Loss: 0.1759
Epoch 10/10, Batch 30/97, Loss: 0.1441
Epoch 10/10, Batch 40/97, Loss: 0.2013
Epoch 10/10, Batch 50/97, Loss: 0.1590
Epoch 10/10, Batch 60/97, Loss: 0.1261
Epoch 10/10, Batch 70/97, Loss: 0.2975
Epoch 10/10, Batch 80/97, Loss: 0.1645
Epoch 10/10, Batch 90/97, Loss: 0.1149
Epoch 10/10, Train Loss: 0.1978, Valid Loss: 0.2299
Accuracy: 0.9206
Precision: 0.9182
Recall: 0.9206
F1-score: 0.9189
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2026
Epoch 1/10, Batch 20/97, Loss: 1.0392
Epoch 1/10, Batch 30/97, Loss: 0.7159
Epoch 1/10, Batch 40/97, Loss: 0.7941
Epoch 1/10, Batch 50/97, Loss: 0.7149
Epoch 1/10, Batch 60/97, Loss: 0.7349
Epoch 1/10, Batch 70/97, Loss: 0.7527
Epoch 1/10, Batch 80/97, Loss: 0.6020
Epoch 1/10, Batch 90/97, Loss: 0.6723
Epoch 1/10, Train Loss: 0.8079, Valid Loss: 0.4368
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6453
Epoch 2/10, Batch 20/97, Loss: 0.3833
Epoch 2/10, Batch 30/97, Loss: 0.3024
Epoch 2/10, Batch 40/97, Loss: 0.3408
Epoch 2/10, Batch 50/97, Loss: 0.4878
Epoch 2/10, Batch 60/97, Loss: 0.4751
Epoch 2/10, Batch 70/97, Loss: 0.4279
Epoch 2/10, Batch 80/97, Loss: 0.3848
Epoch 2/10, Batch 90/97, Loss: 0.4468
Epoch 2/10, Train Loss: 0.4231, Valid Loss: 0.3348
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4086
Epoch 3/10, Batch 20/97, Loss: 0.2889
Epoch 3/10, Batch 30/97, Loss: 0.3055
Epoch 3/10, Batch 40/97, Loss: 0.2300
Epoch 3/10, Batch 50/97, Loss: 0.3583
Epoch 3/10, Batch 60/97, Loss: 0.2913
Epoch 3/10, Batch 70/97, Loss: 0.3139
Epoch 3/10, Batch 80/97, Loss: 0.3958
Epoch 3/10, Batch 90/97, Loss: 0.2165
Epoch 3/10, Train Loss: 0.3442, Valid Loss: 0.2920
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3437
Epoch 4/10, Batch 20/97, Loss: 0.2529
Epoch 4/10, Batch 30/97, Loss: 0.2478
Epoch 4/10, Batch 40/97, Loss: 0.3301
Epoch 4/10, Batch 50/97, Loss: 0.4297
Epoch 4/10, Batch 60/97, Loss: 0.2834
Epoch 4/10, Batch 70/97, Loss: 0.2185
Epoch 4/10, Batch 80/97, Loss: 0.3796
Epoch 4/10, Batch 90/97, Loss: 0.2203
Epoch 4/10, Train Loss: 0.2948, Valid Loss: 0.2698
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3366
Epoch 5/10, Batch 20/97, Loss: 0.2193
Epoch 5/10, Batch 30/97, Loss: 0.1879
Epoch 5/10, Batch 40/97, Loss: 0.2482
Epoch 5/10, Batch 50/97, Loss: 0.1926
Epoch 5/10, Batch 60/97, Loss: 0.1596
Epoch 5/10, Batch 70/97, Loss: 0.2190
Epoch 5/10, Batch 80/97, Loss: 0.1331
Epoch 5/10, Batch 90/97, Loss: 0.2879
Epoch 5/10, Train Loss: 0.2702, Valid Loss: 0.2508
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.0920
Epoch 6/10, Batch 20/97, Loss: 0.4331
Epoch 6/10, Batch 30/97, Loss: 0.2368
Epoch 6/10, Batch 40/97, Loss: 0.2195
Epoch 6/10, Batch 50/97, Loss: 0.3605
Epoch 6/10, Batch 60/97, Loss: 0.3731
Epoch 6/10, Batch 70/97, Loss: 0.3973
Epoch 6/10, Batch 80/97, Loss: 0.2044
Epoch 6/10, Batch 90/97, Loss: 0.1991
Epoch 6/10, Train Loss: 0.2506, Valid Loss: 0.2424
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2308
Epoch 7/10, Batch 20/97, Loss: 0.2861
Epoch 7/10, Batch 30/97, Loss: 0.2181
Epoch 7/10, Batch 40/97, Loss: 0.1576
Epoch 7/10, Batch 50/97, Loss: 0.1873
Epoch 7/10, Batch 60/97, Loss: 0.1486
Epoch 7/10, Batch 70/97, Loss: 0.2307
Epoch 7/10, Batch 80/97, Loss: 0.2298
Epoch 7/10, Batch 90/97, Loss: 0.2308
Epoch 7/10, Train Loss: 0.2258, Valid Loss: 0.2348
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2045
Epoch 8/10, Batch 20/97, Loss: 0.2797
Epoch 8/10, Batch 30/97, Loss: 0.1055
Epoch 8/10, Batch 40/97, Loss: 0.2387
Epoch 8/10, Batch 50/97, Loss: 0.2065
Epoch 8/10, Batch 60/97, Loss: 0.1824
Epoch 8/10, Batch 70/97, Loss: 0.1663
Epoch 8/10, Batch 80/97, Loss: 0.1539
Epoch 8/10, Batch 90/97, Loss: 0.1398
Epoch 8/10, Train Loss: 0.2275, Valid Loss: 0.2270
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1021
Epoch 9/10, Batch 20/97, Loss: 0.1176
Epoch 9/10, Batch 30/97, Loss: 0.3017
Epoch 9/10, Batch 40/97, Loss: 0.1529
Epoch 9/10, Batch 50/97, Loss: 0.0753
Epoch 9/10, Batch 60/97, Loss: 0.2209
Epoch 9/10, Batch 70/97, Loss: 0.0883
Epoch 9/10, Batch 80/97, Loss: 0.2467
Epoch 9/10, Batch 90/97, Loss: 0.1578
Epoch 9/10, Train Loss: 0.2123, Valid Loss: 0.2274
Epoch 10/10, Batch 10/97, Loss: 0.1844
Epoch 10/10, Batch 20/97, Loss: 0.1602
Epoch 10/10, Batch 30/97, Loss: 0.3278
Epoch 10/10, Batch 40/97, Loss: 0.2297
Epoch 10/10, Batch 50/97, Loss: 0.2585
Epoch 10/10, Batch 60/97, Loss: 0.1721
Epoch 10/10, Batch 70/97, Loss: 0.2268
Epoch 10/10, Batch 80/97, Loss: 0.2354
Epoch 10/10, Batch 90/97, Loss: 0.1349
Epoch 10/10, Train Loss: 0.2000, Valid Loss: 0.2291
Accuracy: 0.9147
Precision: 0.9111
Recall: 0.9147
F1-score: 0.9122
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.3197
Epoch 1/10, Batch 20/97, Loss: 1.0872
Epoch 1/10, Batch 30/97, Loss: 0.8082
Epoch 1/10, Batch 40/97, Loss: 0.7242
Epoch 1/10, Batch 50/97, Loss: 0.5216
Epoch 1/10, Batch 60/97, Loss: 0.7130
Epoch 1/10, Batch 70/97, Loss: 0.5268
Epoch 1/10, Batch 80/97, Loss: 0.6785
Epoch 1/10, Batch 90/97, Loss: 0.6175
Epoch 1/10, Train Loss: 0.8017, Valid Loss: 0.4394
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6070
Epoch 2/10, Batch 20/97, Loss: 0.5607
Epoch 2/10, Batch 30/97, Loss: 0.4517
Epoch 2/10, Batch 40/97, Loss: 0.3704
Epoch 2/10, Batch 50/97, Loss: 0.4056
Epoch 2/10, Batch 60/97, Loss: 0.3765
Epoch 2/10, Batch 70/97, Loss: 0.3158
Epoch 2/10, Batch 80/97, Loss: 0.1776
Epoch 2/10, Batch 90/97, Loss: 0.3096
Epoch 2/10, Train Loss: 0.4047, Valid Loss: 0.3377
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4545
Epoch 3/10, Batch 20/97, Loss: 0.3467
Epoch 3/10, Batch 30/97, Loss: 0.4709
Epoch 3/10, Batch 40/97, Loss: 0.1982
Epoch 3/10, Batch 50/97, Loss: 0.2970
Epoch 3/10, Batch 60/97, Loss: 0.3158
Epoch 3/10, Batch 70/97, Loss: 0.4760
Epoch 3/10, Batch 80/97, Loss: 0.2444
Epoch 3/10, Batch 90/97, Loss: 0.2728
Epoch 3/10, Train Loss: 0.3278, Valid Loss: 0.2856
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4516
Epoch 4/10, Batch 20/97, Loss: 0.1911
Epoch 4/10, Batch 30/97, Loss: 0.2790
Epoch 4/10, Batch 40/97, Loss: 0.2059
Epoch 4/10, Batch 50/97, Loss: 0.1809
Epoch 4/10, Batch 60/97, Loss: 0.2284
Epoch 4/10, Batch 70/97, Loss: 0.2095
Epoch 4/10, Batch 80/97, Loss: 0.3849
Epoch 4/10, Batch 90/97, Loss: 0.2332
Epoch 4/10, Train Loss: 0.2798, Valid Loss: 0.2737
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1851
Epoch 5/10, Batch 20/97, Loss: 0.2775
Epoch 5/10, Batch 30/97, Loss: 0.2155
Epoch 5/10, Batch 40/97, Loss: 0.2479
Epoch 5/10, Batch 50/97, Loss: 0.2503
Epoch 5/10, Batch 60/97, Loss: 0.1981
Epoch 5/10, Batch 70/97, Loss: 0.2975
Epoch 5/10, Batch 80/97, Loss: 0.2753
Epoch 5/10, Batch 90/97, Loss: 0.1649
Epoch 5/10, Train Loss: 0.2600, Valid Loss: 0.2626
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2184
Epoch 6/10, Batch 20/97, Loss: 0.3216
Epoch 6/10, Batch 30/97, Loss: 0.1336
Epoch 6/10, Batch 40/97, Loss: 0.2064
Epoch 6/10, Batch 50/97, Loss: 0.2736
Epoch 6/10, Batch 60/97, Loss: 0.2820
Epoch 6/10, Batch 70/97, Loss: 0.1619
Epoch 6/10, Batch 80/97, Loss: 0.2028
Epoch 6/10, Batch 90/97, Loss: 0.3197
Epoch 6/10, Train Loss: 0.2365, Valid Loss: 0.2525
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2928
Epoch 7/10, Batch 20/97, Loss: 0.1885
Epoch 7/10, Batch 30/97, Loss: 0.2036
Epoch 7/10, Batch 40/97, Loss: 0.1450
Epoch 7/10, Batch 50/97, Loss: 0.1824
Epoch 7/10, Batch 60/97, Loss: 0.2463
Epoch 7/10, Batch 70/97, Loss: 0.2965
Epoch 7/10, Batch 80/97, Loss: 0.1352
Epoch 7/10, Batch 90/97, Loss: 0.0862
Epoch 7/10, Train Loss: 0.2149, Valid Loss: 0.2410
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2732
Epoch 8/10, Batch 20/97, Loss: 0.2698
Epoch 8/10, Batch 30/97, Loss: 0.1797
Epoch 8/10, Batch 40/97, Loss: 0.3005
Epoch 8/10, Batch 50/97, Loss: 0.3069
Epoch 8/10, Batch 60/97, Loss: 0.1614
Epoch 8/10, Batch 70/97, Loss: 0.1946
Epoch 8/10, Batch 80/97, Loss: 0.1382
Epoch 8/10, Batch 90/97, Loss: 0.1704
Epoch 8/10, Train Loss: 0.2197, Valid Loss: 0.2419
Epoch 9/10, Batch 10/97, Loss: 0.2082
Epoch 9/10, Batch 20/97, Loss: 0.2060
Epoch 9/10, Batch 30/97, Loss: 0.2597
Epoch 9/10, Batch 40/97, Loss: 0.1876
Epoch 9/10, Batch 50/97, Loss: 0.1778
Epoch 9/10, Batch 60/97, Loss: 0.2436
Epoch 9/10, Batch 70/97, Loss: 0.1066
Epoch 9/10, Batch 80/97, Loss: 0.1534
Epoch 9/10, Batch 90/97, Loss: 0.2366
Epoch 9/10, Train Loss: 0.2037, Valid Loss: 0.2391
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1697
Epoch 10/10, Batch 20/97, Loss: 0.2595
Epoch 10/10, Batch 30/97, Loss: 0.1188
Epoch 10/10, Batch 40/97, Loss: 0.1907
Epoch 10/10, Batch 50/97, Loss: 0.1325
Epoch 10/10, Batch 60/97, Loss: 0.1252
Epoch 10/10, Batch 70/97, Loss: 0.1965
Epoch 10/10, Batch 80/97, Loss: 0.1701
Epoch 10/10, Batch 90/97, Loss: 0.1160
Epoch 10/10, Train Loss: 0.1988, Valid Loss: 0.2454
Accuracy: 0.9054
Precision: 0.9032
Recall: 0.9054
F1-score: 0.9033
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2535
Epoch 1/10, Batch 20/97, Loss: 1.0718
Epoch 1/10, Batch 30/97, Loss: 0.7751
Epoch 1/10, Batch 40/97, Loss: 0.8721
Epoch 1/10, Batch 50/97, Loss: 0.6972
Epoch 1/10, Batch 60/97, Loss: 0.7019
Epoch 1/10, Batch 70/97, Loss: 0.6554
Epoch 1/10, Batch 80/97, Loss: 0.5513
Epoch 1/10, Batch 90/97, Loss: 0.6063
Epoch 1/10, Train Loss: 0.8182, Valid Loss: 0.4481
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.7587
Epoch 2/10, Batch 20/97, Loss: 0.4927
Epoch 2/10, Batch 30/97, Loss: 0.2939
Epoch 2/10, Batch 40/97, Loss: 0.4696
Epoch 2/10, Batch 50/97, Loss: 0.3191
Epoch 2/10, Batch 60/97, Loss: 0.3760
Epoch 2/10, Batch 70/97, Loss: 0.2590
Epoch 2/10, Batch 80/97, Loss: 0.5218
Epoch 2/10, Batch 90/97, Loss: 0.5315
Epoch 2/10, Train Loss: 0.4229, Valid Loss: 0.3368
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3957
Epoch 3/10, Batch 20/97, Loss: 0.2449
Epoch 3/10, Batch 30/97, Loss: 0.3600
Epoch 3/10, Batch 40/97, Loss: 0.1593
Epoch 3/10, Batch 50/97, Loss: 0.4831
Epoch 3/10, Batch 60/97, Loss: 0.1793
Epoch 3/10, Batch 70/97, Loss: 0.2957
Epoch 3/10, Batch 80/97, Loss: 0.2927
Epoch 3/10, Batch 90/97, Loss: 0.2665
Epoch 3/10, Train Loss: 0.3446, Valid Loss: 0.2903
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3085
Epoch 4/10, Batch 20/97, Loss: 0.2309
Epoch 4/10, Batch 30/97, Loss: 0.3519
Epoch 4/10, Batch 40/97, Loss: 0.3584
Epoch 4/10, Batch 50/97, Loss: 0.2215
Epoch 4/10, Batch 60/97, Loss: 0.1633
Epoch 4/10, Batch 70/97, Loss: 0.3026
Epoch 4/10, Batch 80/97, Loss: 0.3806
Epoch 4/10, Batch 90/97, Loss: 0.2669
Epoch 4/10, Train Loss: 0.2963, Valid Loss: 0.2717
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2275
Epoch 5/10, Batch 20/97, Loss: 0.1980
Epoch 5/10, Batch 30/97, Loss: 0.1555
Epoch 5/10, Batch 40/97, Loss: 0.2985
Epoch 5/10, Batch 50/97, Loss: 0.3354
Epoch 5/10, Batch 60/97, Loss: 0.1837
Epoch 5/10, Batch 70/97, Loss: 0.2740
Epoch 5/10, Batch 80/97, Loss: 0.1803
Epoch 5/10, Batch 90/97, Loss: 0.1905
Epoch 5/10, Train Loss: 0.2709, Valid Loss: 0.2670
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2149
Epoch 6/10, Batch 20/97, Loss: 0.2499
Epoch 6/10, Batch 30/97, Loss: 0.1743
Epoch 6/10, Batch 40/97, Loss: 0.2065
Epoch 6/10, Batch 50/97, Loss: 0.2694
Epoch 6/10, Batch 60/97, Loss: 0.2132
Epoch 6/10, Batch 70/97, Loss: 0.1658
Epoch 6/10, Batch 80/97, Loss: 0.2855
Epoch 6/10, Batch 90/97, Loss: 0.2251
Epoch 6/10, Train Loss: 0.2526, Valid Loss: 0.2460
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2417
Epoch 7/10, Batch 20/97, Loss: 0.1282
Epoch 7/10, Batch 30/97, Loss: 0.2270
Epoch 7/10, Batch 40/97, Loss: 0.1545
Epoch 7/10, Batch 50/97, Loss: 0.2209
Epoch 7/10, Batch 60/97, Loss: 0.2344
Epoch 7/10, Batch 70/97, Loss: 0.1892
Epoch 7/10, Batch 80/97, Loss: 0.2128
Epoch 7/10, Batch 90/97, Loss: 0.1210
Epoch 7/10, Train Loss: 0.2382, Valid Loss: 0.2362
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2834
Epoch 8/10, Batch 20/97, Loss: 0.1707
Epoch 8/10, Batch 30/97, Loss: 0.1489
Epoch 8/10, Batch 40/97, Loss: 0.1867
Epoch 8/10, Batch 50/97, Loss: 0.2755
Epoch 8/10, Batch 60/97, Loss: 0.2728
Epoch 8/10, Batch 70/97, Loss: 0.1971
Epoch 8/10, Batch 80/97, Loss: 0.1935
Epoch 8/10, Batch 90/97, Loss: 0.2054
Epoch 8/10, Train Loss: 0.2293, Valid Loss: 0.2439
Epoch 9/10, Batch 10/97, Loss: 0.0774
Epoch 9/10, Batch 20/97, Loss: 0.2608
Epoch 9/10, Batch 30/97, Loss: 0.4030
Epoch 9/10, Batch 40/97, Loss: 0.1965
Epoch 9/10, Batch 50/97, Loss: 0.1688
Epoch 9/10, Batch 60/97, Loss: 0.3290
Epoch 9/10, Batch 70/97, Loss: 0.1753
Epoch 9/10, Batch 80/97, Loss: 0.4273
Epoch 9/10, Batch 90/97, Loss: 0.2121
Epoch 9/10, Train Loss: 0.2122, Valid Loss: 0.2403
Epoch 10/10, Batch 10/97, Loss: 0.2091
Epoch 10/10, Batch 20/97, Loss: 0.1975
Epoch 10/10, Batch 30/97, Loss: 0.3480
Epoch 10/10, Batch 40/97, Loss: 0.2163
Epoch 10/10, Batch 50/97, Loss: 0.1853
Epoch 10/10, Batch 60/97, Loss: 0.0961
Epoch 10/10, Batch 70/97, Loss: 0.2424
Epoch 10/10, Batch 80/97, Loss: 0.3020
Epoch 10/10, Batch 90/97, Loss: 0.1859
Epoch 10/10, Train Loss: 0.2109, Valid Loss: 0.2416
Accuracy: 0.9171
Precision: 0.9145
Recall: 0.9171
F1-score: 0.9151
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2553
Epoch 1/10, Batch 20/97, Loss: 1.1070
Epoch 1/10, Batch 30/97, Loss: 0.6722
Epoch 1/10, Batch 40/97, Loss: 0.7977
Epoch 1/10, Batch 50/97, Loss: 0.6541
Epoch 1/10, Batch 60/97, Loss: 0.6863
Epoch 1/10, Batch 70/97, Loss: 0.6940
Epoch 1/10, Batch 80/97, Loss: 0.6483
Epoch 1/10, Batch 90/97, Loss: 0.5514
Epoch 1/10, Train Loss: 0.8069, Valid Loss: 0.4529
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5247
Epoch 2/10, Batch 20/97, Loss: 0.5149
Epoch 2/10, Batch 30/97, Loss: 0.2980
Epoch 2/10, Batch 40/97, Loss: 0.4062
Epoch 2/10, Batch 50/97, Loss: 0.4185
Epoch 2/10, Batch 60/97, Loss: 0.3558
Epoch 2/10, Batch 70/97, Loss: 0.4014
Epoch 2/10, Batch 80/97, Loss: 0.3957
Epoch 2/10, Batch 90/97, Loss: 0.4313
Epoch 2/10, Train Loss: 0.4131, Valid Loss: 0.3392
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3321
Epoch 3/10, Batch 20/97, Loss: 0.3101
Epoch 3/10, Batch 30/97, Loss: 0.3312
Epoch 3/10, Batch 40/97, Loss: 0.1700
Epoch 3/10, Batch 50/97, Loss: 0.1687
Epoch 3/10, Batch 60/97, Loss: 0.2380
Epoch 3/10, Batch 70/97, Loss: 0.3899
Epoch 3/10, Batch 80/97, Loss: 0.3083
Epoch 3/10, Batch 90/97, Loss: 0.2527
Epoch 3/10, Train Loss: 0.3317, Valid Loss: 0.2878
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2742
Epoch 4/10, Batch 20/97, Loss: 0.2164
Epoch 4/10, Batch 30/97, Loss: 0.3127
Epoch 4/10, Batch 40/97, Loss: 0.2555
Epoch 4/10, Batch 50/97, Loss: 0.3855
Epoch 4/10, Batch 60/97, Loss: 0.2199
Epoch 4/10, Batch 70/97, Loss: 0.3227
Epoch 4/10, Batch 80/97, Loss: 0.1961
Epoch 4/10, Batch 90/97, Loss: 0.2099
Epoch 4/10, Train Loss: 0.2885, Valid Loss: 0.2715
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2378
Epoch 5/10, Batch 20/97, Loss: 0.2084
Epoch 5/10, Batch 30/97, Loss: 0.1102
Epoch 5/10, Batch 40/97, Loss: 0.2155
Epoch 5/10, Batch 50/97, Loss: 0.3303
Epoch 5/10, Batch 60/97, Loss: 0.1308
Epoch 5/10, Batch 70/97, Loss: 0.2865
Epoch 5/10, Batch 80/97, Loss: 0.1602
Epoch 5/10, Batch 90/97, Loss: 0.1700
Epoch 5/10, Train Loss: 0.2642, Valid Loss: 0.2558
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2162
Epoch 6/10, Batch 20/97, Loss: 0.3126
Epoch 6/10, Batch 30/97, Loss: 0.1800
Epoch 6/10, Batch 40/97, Loss: 0.1335
Epoch 6/10, Batch 50/97, Loss: 0.2976
Epoch 6/10, Batch 60/97, Loss: 0.1810
Epoch 6/10, Batch 70/97, Loss: 0.2076
Epoch 6/10, Batch 80/97, Loss: 0.2007
Epoch 6/10, Batch 90/97, Loss: 0.1605
Epoch 6/10, Train Loss: 0.2422, Valid Loss: 0.2440
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2772
Epoch 7/10, Batch 20/97, Loss: 0.2842
Epoch 7/10, Batch 30/97, Loss: 0.2831
Epoch 7/10, Batch 40/97, Loss: 0.1684
Epoch 7/10, Batch 50/97, Loss: 0.2947
Epoch 7/10, Batch 60/97, Loss: 0.1101
Epoch 7/10, Batch 70/97, Loss: 0.1812
Epoch 7/10, Batch 80/97, Loss: 0.1653
Epoch 7/10, Batch 90/97, Loss: 0.2383
Epoch 7/10, Train Loss: 0.2302, Valid Loss: 0.2420
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1352
Epoch 8/10, Batch 20/97, Loss: 0.1368
Epoch 8/10, Batch 30/97, Loss: 0.2425
Epoch 8/10, Batch 40/97, Loss: 0.1890
Epoch 8/10, Batch 50/97, Loss: 0.2362
Epoch 8/10, Batch 60/97, Loss: 0.2332
Epoch 8/10, Batch 70/97, Loss: 0.2391
Epoch 8/10, Batch 80/97, Loss: 0.1288
Epoch 8/10, Batch 90/97, Loss: 0.1478
Epoch 8/10, Train Loss: 0.2162, Valid Loss: 0.2327
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1504
Epoch 9/10, Batch 20/97, Loss: 0.0999
Epoch 9/10, Batch 30/97, Loss: 0.3644
Epoch 9/10, Batch 40/97, Loss: 0.3042
Epoch 9/10, Batch 50/97, Loss: 0.1457
Epoch 9/10, Batch 60/97, Loss: 0.2901
Epoch 9/10, Batch 70/97, Loss: 0.0975
Epoch 9/10, Batch 80/97, Loss: 0.1872
Epoch 9/10, Batch 90/97, Loss: 0.1784
Epoch 9/10, Train Loss: 0.2063, Valid Loss: 0.2318
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1618
Epoch 10/10, Batch 20/97, Loss: 0.1525
Epoch 10/10, Batch 30/97, Loss: 0.1886
Epoch 10/10, Batch 40/97, Loss: 0.2366
Epoch 10/10, Batch 50/97, Loss: 0.2047
Epoch 10/10, Batch 60/97, Loss: 0.1949
Epoch 10/10, Batch 70/97, Loss: 0.1689
Epoch 10/10, Batch 80/97, Loss: 0.1029
Epoch 10/10, Batch 90/97, Loss: 0.1674
Epoch 10/10, Train Loss: 0.1987, Valid Loss: 0.2270
Model saved!
Accuracy: 0.9159
Precision: 0.9143
Recall: 0.9159
F1-score: 0.9129
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2232
Epoch 1/10, Batch 20/97, Loss: 1.1939
Epoch 1/10, Batch 30/97, Loss: 0.7968
Epoch 1/10, Batch 40/97, Loss: 0.8462
Epoch 1/10, Batch 50/97, Loss: 0.5604
Epoch 1/10, Batch 60/97, Loss: 0.6515
Epoch 1/10, Batch 70/97, Loss: 0.6255
Epoch 1/10, Batch 80/97, Loss: 0.6198
Epoch 1/10, Batch 90/97, Loss: 0.4980
Epoch 1/10, Train Loss: 0.8025, Valid Loss: 0.4584
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5330
Epoch 2/10, Batch 20/97, Loss: 0.6221
Epoch 2/10, Batch 30/97, Loss: 0.4179
Epoch 2/10, Batch 40/97, Loss: 0.4722
Epoch 2/10, Batch 50/97, Loss: 0.4229
Epoch 2/10, Batch 60/97, Loss: 0.5405
Epoch 2/10, Batch 70/97, Loss: 0.4395
Epoch 2/10, Batch 80/97, Loss: 0.3646
Epoch 2/10, Batch 90/97, Loss: 0.2881
Epoch 2/10, Train Loss: 0.4145, Valid Loss: 0.3486
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4195
Epoch 3/10, Batch 20/97, Loss: 0.3919
Epoch 3/10, Batch 30/97, Loss: 0.4830
Epoch 3/10, Batch 40/97, Loss: 0.2669
Epoch 3/10, Batch 50/97, Loss: 0.3288
Epoch 3/10, Batch 60/97, Loss: 0.2755
Epoch 3/10, Batch 70/97, Loss: 0.4301
Epoch 3/10, Batch 80/97, Loss: 0.2137
Epoch 3/10, Batch 90/97, Loss: 0.2899
Epoch 3/10, Train Loss: 0.3336, Valid Loss: 0.3028
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3209
Epoch 4/10, Batch 20/97, Loss: 0.4016
Epoch 4/10, Batch 30/97, Loss: 0.2425
Epoch 4/10, Batch 40/97, Loss: 0.2446
Epoch 4/10, Batch 50/97, Loss: 0.3436
Epoch 4/10, Batch 60/97, Loss: 0.1563
Epoch 4/10, Batch 70/97, Loss: 0.2862
Epoch 4/10, Batch 80/97, Loss: 0.2748
Epoch 4/10, Batch 90/97, Loss: 0.2648
Epoch 4/10, Train Loss: 0.2921, Valid Loss: 0.2748
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2417
Epoch 5/10, Batch 20/97, Loss: 0.3463
Epoch 5/10, Batch 30/97, Loss: 0.3722
Epoch 5/10, Batch 40/97, Loss: 0.3860
Epoch 5/10, Batch 50/97, Loss: 0.5067
Epoch 5/10, Batch 60/97, Loss: 0.2901
Epoch 5/10, Batch 70/97, Loss: 0.2522
Epoch 5/10, Batch 80/97, Loss: 0.2387
Epoch 5/10, Batch 90/97, Loss: 0.2786
Epoch 5/10, Train Loss: 0.2712, Valid Loss: 0.2724
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1570
Epoch 6/10, Batch 20/97, Loss: 0.4342
Epoch 6/10, Batch 30/97, Loss: 0.2772
Epoch 6/10, Batch 40/97, Loss: 0.1944
Epoch 6/10, Batch 50/97, Loss: 0.3347
Epoch 6/10, Batch 60/97, Loss: 0.3697
Epoch 6/10, Batch 70/97, Loss: 0.3090
Epoch 6/10, Batch 80/97, Loss: 0.3331
Epoch 6/10, Batch 90/97, Loss: 0.3144
Epoch 6/10, Train Loss: 0.2521, Valid Loss: 0.2553
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1430
Epoch 7/10, Batch 20/97, Loss: 0.2508
Epoch 7/10, Batch 30/97, Loss: 0.2020
Epoch 7/10, Batch 40/97, Loss: 0.1100
Epoch 7/10, Batch 50/97, Loss: 0.2206
Epoch 7/10, Batch 60/97, Loss: 0.1876
Epoch 7/10, Batch 70/97, Loss: 0.3188
Epoch 7/10, Batch 80/97, Loss: 0.2365
Epoch 7/10, Batch 90/97, Loss: 0.1718
Epoch 7/10, Train Loss: 0.2269, Valid Loss: 0.2467
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1140
Epoch 8/10, Batch 20/97, Loss: 0.1940
Epoch 8/10, Batch 30/97, Loss: 0.2526
Epoch 8/10, Batch 40/97, Loss: 0.1263
Epoch 8/10, Batch 50/97, Loss: 0.1411
Epoch 8/10, Batch 60/97, Loss: 0.1417
Epoch 8/10, Batch 70/97, Loss: 0.3504
Epoch 8/10, Batch 80/97, Loss: 0.2910
Epoch 8/10, Batch 90/97, Loss: 0.1515
Epoch 8/10, Train Loss: 0.2278, Valid Loss: 0.2465
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0972
Epoch 9/10, Batch 20/97, Loss: 0.1776
Epoch 9/10, Batch 30/97, Loss: 0.2975
Epoch 9/10, Batch 40/97, Loss: 0.3146
Epoch 9/10, Batch 50/97, Loss: 0.0902
Epoch 9/10, Batch 60/97, Loss: 0.3217
Epoch 9/10, Batch 70/97, Loss: 0.1676
Epoch 9/10, Batch 80/97, Loss: 0.1815
Epoch 9/10, Batch 90/97, Loss: 0.1943
Epoch 9/10, Train Loss: 0.2233, Valid Loss: 0.2357
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2351
Epoch 10/10, Batch 20/97, Loss: 0.0994
Epoch 10/10, Batch 30/97, Loss: 0.1578
Epoch 10/10, Batch 40/97, Loss: 0.1271
Epoch 10/10, Batch 50/97, Loss: 0.2423
Epoch 10/10, Batch 60/97, Loss: 0.1125
Epoch 10/10, Batch 70/97, Loss: 0.2353
Epoch 10/10, Batch 80/97, Loss: 0.2222
Epoch 10/10, Batch 90/97, Loss: 0.1928
Epoch 10/10, Train Loss: 0.2112, Valid Loss: 0.2340
Model saved!
Accuracy: 0.9147
Precision: 0.9110
Recall: 0.9147
F1-score: 0.9121
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2434
Epoch 1/10, Batch 20/97, Loss: 1.1314
Epoch 1/10, Batch 30/97, Loss: 0.8241
Epoch 1/10, Batch 40/97, Loss: 0.8152
Epoch 1/10, Batch 50/97, Loss: 0.6271
Epoch 1/10, Batch 60/97, Loss: 0.6788
Epoch 1/10, Batch 70/97, Loss: 0.7433
Epoch 1/10, Batch 80/97, Loss: 0.6585
Epoch 1/10, Batch 90/97, Loss: 0.7607
Epoch 1/10, Train Loss: 0.8060, Valid Loss: 0.4368
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4427
Epoch 2/10, Batch 20/97, Loss: 0.5306
Epoch 2/10, Batch 30/97, Loss: 0.4863
Epoch 2/10, Batch 40/97, Loss: 0.2568
Epoch 2/10, Batch 50/97, Loss: 0.4666
Epoch 2/10, Batch 60/97, Loss: 0.4587
Epoch 2/10, Batch 70/97, Loss: 0.3424
Epoch 2/10, Batch 80/97, Loss: 0.4795
Epoch 2/10, Batch 90/97, Loss: 0.4509
Epoch 2/10, Train Loss: 0.4062, Valid Loss: 0.3247
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3381
Epoch 3/10, Batch 20/97, Loss: 0.3501
Epoch 3/10, Batch 30/97, Loss: 0.3453
Epoch 3/10, Batch 40/97, Loss: 0.2956
Epoch 3/10, Batch 50/97, Loss: 0.3811
Epoch 3/10, Batch 60/97, Loss: 0.2385
Epoch 3/10, Batch 70/97, Loss: 0.4777
Epoch 3/10, Batch 80/97, Loss: 0.2927
Epoch 3/10, Batch 90/97, Loss: 0.4013
Epoch 3/10, Train Loss: 0.3353, Valid Loss: 0.2800
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2976
Epoch 4/10, Batch 20/97, Loss: 0.2656
Epoch 4/10, Batch 30/97, Loss: 0.2600
Epoch 4/10, Batch 40/97, Loss: 0.2342
Epoch 4/10, Batch 50/97, Loss: 0.2182
Epoch 4/10, Batch 60/97, Loss: 0.3034
Epoch 4/10, Batch 70/97, Loss: 0.2905
Epoch 4/10, Batch 80/97, Loss: 0.2311
Epoch 4/10, Batch 90/97, Loss: 0.2383
Epoch 4/10, Train Loss: 0.2821, Valid Loss: 0.2645
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2221
Epoch 5/10, Batch 20/97, Loss: 0.4023
Epoch 5/10, Batch 30/97, Loss: 0.1733
Epoch 5/10, Batch 40/97, Loss: 0.2547
Epoch 5/10, Batch 50/97, Loss: 0.3176
Epoch 5/10, Batch 60/97, Loss: 0.1836
Epoch 5/10, Batch 70/97, Loss: 0.3728
Epoch 5/10, Batch 80/97, Loss: 0.1352
Epoch 5/10, Batch 90/97, Loss: 0.2876
Epoch 5/10, Train Loss: 0.2587, Valid Loss: 0.2483
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2458
Epoch 6/10, Batch 20/97, Loss: 0.3784
Epoch 6/10, Batch 30/97, Loss: 0.3036
Epoch 6/10, Batch 40/97, Loss: 0.1834
Epoch 6/10, Batch 50/97, Loss: 0.2012
Epoch 6/10, Batch 60/97, Loss: 0.2866
Epoch 6/10, Batch 70/97, Loss: 0.1722
Epoch 6/10, Batch 80/97, Loss: 0.3890
Epoch 6/10, Batch 90/97, Loss: 0.2673
Epoch 6/10, Train Loss: 0.2472, Valid Loss: 0.2377
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2969
Epoch 7/10, Batch 20/97, Loss: 0.2773
Epoch 7/10, Batch 30/97, Loss: 0.2139
Epoch 7/10, Batch 40/97, Loss: 0.1458
Epoch 7/10, Batch 50/97, Loss: 0.1793
Epoch 7/10, Batch 60/97, Loss: 0.2216
Epoch 7/10, Batch 70/97, Loss: 0.2006
Epoch 7/10, Batch 80/97, Loss: 0.1732
Epoch 7/10, Batch 90/97, Loss: 0.2787
Epoch 7/10, Train Loss: 0.2258, Valid Loss: 0.2305
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1151
Epoch 8/10, Batch 20/97, Loss: 0.2176
Epoch 8/10, Batch 30/97, Loss: 0.2818
Epoch 8/10, Batch 40/97, Loss: 0.2504
Epoch 8/10, Batch 50/97, Loss: 0.3340
Epoch 8/10, Batch 60/97, Loss: 0.2289
Epoch 8/10, Batch 70/97, Loss: 0.1413
Epoch 8/10, Batch 80/97, Loss: 0.2097
Epoch 8/10, Batch 90/97, Loss: 0.1902
Epoch 8/10, Train Loss: 0.2182, Valid Loss: 0.2241
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1973
Epoch 9/10, Batch 20/97, Loss: 0.1236
Epoch 9/10, Batch 30/97, Loss: 0.3037
Epoch 9/10, Batch 40/97, Loss: 0.3067
Epoch 9/10, Batch 50/97, Loss: 0.1095
Epoch 9/10, Batch 60/97, Loss: 0.2137
Epoch 9/10, Batch 70/97, Loss: 0.1169
Epoch 9/10, Batch 80/97, Loss: 0.1466
Epoch 9/10, Batch 90/97, Loss: 0.0849
Epoch 9/10, Train Loss: 0.1963, Valid Loss: 0.2244
Epoch 10/10, Batch 10/97, Loss: 0.3166
Epoch 10/10, Batch 20/97, Loss: 0.1418
Epoch 10/10, Batch 30/97, Loss: 0.1260
Epoch 10/10, Batch 40/97, Loss: 0.0934
Epoch 10/10, Batch 50/97, Loss: 0.1181
Epoch 10/10, Batch 60/97, Loss: 0.1539
Epoch 10/10, Batch 70/97, Loss: 0.2722
Epoch 10/10, Batch 80/97, Loss: 0.2255
Epoch 10/10, Batch 90/97, Loss: 0.3075
Epoch 10/10, Train Loss: 0.2047, Valid Loss: 0.2216
Model saved!
Accuracy: 0.9159
Precision: 0.9136
Recall: 0.9159
F1-score: 0.9125
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2144
Epoch 1/10, Batch 20/97, Loss: 1.1051
Epoch 1/10, Batch 30/97, Loss: 0.7424
Epoch 1/10, Batch 40/97, Loss: 0.7834
Epoch 1/10, Batch 50/97, Loss: 0.6453
Epoch 1/10, Batch 60/97, Loss: 0.7562
Epoch 1/10, Batch 70/97, Loss: 0.6746
Epoch 1/10, Batch 80/97, Loss: 0.7110
Epoch 1/10, Batch 90/97, Loss: 0.5551
Epoch 1/10, Train Loss: 0.8091, Valid Loss: 0.4342
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5341
Epoch 2/10, Batch 20/97, Loss: 0.5290
Epoch 2/10, Batch 30/97, Loss: 0.2811
Epoch 2/10, Batch 40/97, Loss: 0.3073
Epoch 2/10, Batch 50/97, Loss: 0.5046
Epoch 2/10, Batch 60/97, Loss: 0.3372
Epoch 2/10, Batch 70/97, Loss: 0.2682
Epoch 2/10, Batch 80/97, Loss: 0.3710
Epoch 2/10, Batch 90/97, Loss: 0.4884
Epoch 2/10, Train Loss: 0.4140, Valid Loss: 0.3205
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4163
Epoch 3/10, Batch 20/97, Loss: 0.4287
Epoch 3/10, Batch 30/97, Loss: 0.3703
Epoch 3/10, Batch 40/97, Loss: 0.1614
Epoch 3/10, Batch 50/97, Loss: 0.3497
Epoch 3/10, Batch 60/97, Loss: 0.3935
Epoch 3/10, Batch 70/97, Loss: 0.4834
Epoch 3/10, Batch 80/97, Loss: 0.3500
Epoch 3/10, Batch 90/97, Loss: 0.2984
Epoch 3/10, Train Loss: 0.3392, Valid Loss: 0.2749
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2562
Epoch 4/10, Batch 20/97, Loss: 0.1843
Epoch 4/10, Batch 30/97, Loss: 0.3151
Epoch 4/10, Batch 40/97, Loss: 0.2527
Epoch 4/10, Batch 50/97, Loss: 0.3034
Epoch 4/10, Batch 60/97, Loss: 0.2965
Epoch 4/10, Batch 70/97, Loss: 0.3335
Epoch 4/10, Batch 80/97, Loss: 0.2077
Epoch 4/10, Batch 90/97, Loss: 0.3032
Epoch 4/10, Train Loss: 0.2907, Valid Loss: 0.2622
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1743
Epoch 5/10, Batch 20/97, Loss: 0.3218
Epoch 5/10, Batch 30/97, Loss: 0.2149
Epoch 5/10, Batch 40/97, Loss: 0.2402
Epoch 5/10, Batch 50/97, Loss: 0.1991
Epoch 5/10, Batch 60/97, Loss: 0.2663
Epoch 5/10, Batch 70/97, Loss: 0.3737
Epoch 5/10, Batch 80/97, Loss: 0.2585
Epoch 5/10, Batch 90/97, Loss: 0.1022
Epoch 5/10, Train Loss: 0.2741, Valid Loss: 0.2419
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1961
Epoch 6/10, Batch 20/97, Loss: 0.4139
Epoch 6/10, Batch 30/97, Loss: 0.1987
Epoch 6/10, Batch 40/97, Loss: 0.1983
Epoch 6/10, Batch 50/97, Loss: 0.2000
Epoch 6/10, Batch 60/97, Loss: 0.2424
Epoch 6/10, Batch 70/97, Loss: 0.1828
Epoch 6/10, Batch 80/97, Loss: 0.4030
Epoch 6/10, Batch 90/97, Loss: 0.2237
Epoch 6/10, Train Loss: 0.2465, Valid Loss: 0.2298
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1498
Epoch 7/10, Batch 20/97, Loss: 0.2777
Epoch 7/10, Batch 30/97, Loss: 0.1422
Epoch 7/10, Batch 40/97, Loss: 0.1811
Epoch 7/10, Batch 50/97, Loss: 0.2986
Epoch 7/10, Batch 60/97, Loss: 0.1593
Epoch 7/10, Batch 70/97, Loss: 0.2704
Epoch 7/10, Batch 80/97, Loss: 0.1967
Epoch 7/10, Batch 90/97, Loss: 0.2090
Epoch 7/10, Train Loss: 0.2288, Valid Loss: 0.2320
Epoch 8/10, Batch 10/97, Loss: 0.1165
Epoch 8/10, Batch 20/97, Loss: 0.2299
Epoch 8/10, Batch 30/97, Loss: 0.1399
Epoch 8/10, Batch 40/97, Loss: 0.2167
Epoch 8/10, Batch 50/97, Loss: 0.1536
Epoch 8/10, Batch 60/97, Loss: 0.1915
Epoch 8/10, Batch 70/97, Loss: 0.1119
Epoch 8/10, Batch 80/97, Loss: 0.2057
Epoch 8/10, Batch 90/97, Loss: 0.3016
Epoch 8/10, Train Loss: 0.2278, Valid Loss: 0.2279
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1183
Epoch 9/10, Batch 20/97, Loss: 0.1521
Epoch 9/10, Batch 30/97, Loss: 0.2449
Epoch 9/10, Batch 40/97, Loss: 0.1717
Epoch 9/10, Batch 50/97, Loss: 0.2664
Epoch 9/10, Batch 60/97, Loss: 0.1351
Epoch 9/10, Batch 70/97, Loss: 0.1686
Epoch 9/10, Batch 80/97, Loss: 0.1732
Epoch 9/10, Batch 90/97, Loss: 0.1686
Epoch 9/10, Train Loss: 0.2101, Valid Loss: 0.2241
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2356
Epoch 10/10, Batch 20/97, Loss: 0.1823
Epoch 10/10, Batch 30/97, Loss: 0.3224
Epoch 10/10, Batch 40/97, Loss: 0.1383
Epoch 10/10, Batch 50/97, Loss: 0.1623
Epoch 10/10, Batch 60/97, Loss: 0.2388
Epoch 10/10, Batch 70/97, Loss: 0.2456
Epoch 10/10, Batch 80/97, Loss: 0.1658
Epoch 10/10, Batch 90/97, Loss: 0.1997
Epoch 10/10, Train Loss: 0.2027, Valid Loss: 0.2219
Model saved!
Accuracy: 0.9136
Precision: 0.9104
Recall: 0.9136
F1-score: 0.9105
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2274
Epoch 1/10, Batch 20/97, Loss: 1.0665
Epoch 1/10, Batch 30/97, Loss: 0.7278
Epoch 1/10, Batch 40/97, Loss: 0.6194
Epoch 1/10, Batch 50/97, Loss: 0.7228
Epoch 1/10, Batch 60/97, Loss: 0.6947
Epoch 1/10, Batch 70/97, Loss: 0.6345
Epoch 1/10, Batch 80/97, Loss: 0.5478
Epoch 1/10, Batch 90/97, Loss: 0.5329
Epoch 1/10, Train Loss: 0.7935, Valid Loss: 0.4465
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6196
Epoch 2/10, Batch 20/97, Loss: 0.4629
Epoch 2/10, Batch 30/97, Loss: 0.3044
Epoch 2/10, Batch 40/97, Loss: 0.3373
Epoch 2/10, Batch 50/97, Loss: 0.3492
Epoch 2/10, Batch 60/97, Loss: 0.3478
Epoch 2/10, Batch 70/97, Loss: 0.3679
Epoch 2/10, Batch 80/97, Loss: 0.3501
Epoch 2/10, Batch 90/97, Loss: 0.4217
Epoch 2/10, Train Loss: 0.4055, Valid Loss: 0.3361
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3112
Epoch 3/10, Batch 20/97, Loss: 0.4170
Epoch 3/10, Batch 30/97, Loss: 0.3443
Epoch 3/10, Batch 40/97, Loss: 0.3031
Epoch 3/10, Batch 50/97, Loss: 0.5362
Epoch 3/10, Batch 60/97, Loss: 0.2658
Epoch 3/10, Batch 70/97, Loss: 0.3037
Epoch 3/10, Batch 80/97, Loss: 0.3071
Epoch 3/10, Batch 90/97, Loss: 0.1555
Epoch 3/10, Train Loss: 0.3314, Valid Loss: 0.2983
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2537
Epoch 4/10, Batch 20/97, Loss: 0.3052
Epoch 4/10, Batch 30/97, Loss: 0.1924
Epoch 4/10, Batch 40/97, Loss: 0.3381
Epoch 4/10, Batch 50/97, Loss: 0.2773
Epoch 4/10, Batch 60/97, Loss: 0.2094
Epoch 4/10, Batch 70/97, Loss: 0.2827
Epoch 4/10, Batch 80/97, Loss: 0.3659
Epoch 4/10, Batch 90/97, Loss: 0.2130
Epoch 4/10, Train Loss: 0.2868, Valid Loss: 0.2705
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1580
Epoch 5/10, Batch 20/97, Loss: 0.2463
Epoch 5/10, Batch 30/97, Loss: 0.2319
Epoch 5/10, Batch 40/97, Loss: 0.2897
Epoch 5/10, Batch 50/97, Loss: 0.4504
Epoch 5/10, Batch 60/97, Loss: 0.2265
Epoch 5/10, Batch 70/97, Loss: 0.1782
Epoch 5/10, Batch 80/97, Loss: 0.3406
Epoch 5/10, Batch 90/97, Loss: 0.1716
Epoch 5/10, Train Loss: 0.2621, Valid Loss: 0.2622
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2072
Epoch 6/10, Batch 20/97, Loss: 0.3403
Epoch 6/10, Batch 30/97, Loss: 0.1925
Epoch 6/10, Batch 40/97, Loss: 0.2470
Epoch 6/10, Batch 50/97, Loss: 0.2287
Epoch 6/10, Batch 60/97, Loss: 0.3772
Epoch 6/10, Batch 70/97, Loss: 0.2589
Epoch 6/10, Batch 80/97, Loss: 0.1990
Epoch 6/10, Batch 90/97, Loss: 0.2009
Epoch 6/10, Train Loss: 0.2419, Valid Loss: 0.2451
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1942
Epoch 7/10, Batch 20/97, Loss: 0.1367
Epoch 7/10, Batch 30/97, Loss: 0.3567
Epoch 7/10, Batch 40/97, Loss: 0.1268
Epoch 7/10, Batch 50/97, Loss: 0.2618
Epoch 7/10, Batch 60/97, Loss: 0.2176
Epoch 7/10, Batch 70/97, Loss: 0.1241
Epoch 7/10, Batch 80/97, Loss: 0.1716
Epoch 7/10, Batch 90/97, Loss: 0.2050
Epoch 7/10, Train Loss: 0.2217, Valid Loss: 0.2427
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1174
Epoch 8/10, Batch 20/97, Loss: 0.1586
Epoch 8/10, Batch 30/97, Loss: 0.1040
Epoch 8/10, Batch 40/97, Loss: 0.2648
Epoch 8/10, Batch 50/97, Loss: 0.1976
Epoch 8/10, Batch 60/97, Loss: 0.2706
Epoch 8/10, Batch 70/97, Loss: 0.1866
Epoch 8/10, Batch 80/97, Loss: 0.1091
Epoch 8/10, Batch 90/97, Loss: 0.2134
Epoch 8/10, Train Loss: 0.2180, Valid Loss: 0.2348
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1094
Epoch 9/10, Batch 20/97, Loss: 0.1856
Epoch 9/10, Batch 30/97, Loss: 0.1508
Epoch 9/10, Batch 40/97, Loss: 0.1406
Epoch 9/10, Batch 50/97, Loss: 0.0982
Epoch 9/10, Batch 60/97, Loss: 0.1812
Epoch 9/10, Batch 70/97, Loss: 0.2024
Epoch 9/10, Batch 80/97, Loss: 0.2216
Epoch 9/10, Batch 90/97, Loss: 0.1552
Epoch 9/10, Train Loss: 0.1991, Valid Loss: 0.2310
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1778
Epoch 10/10, Batch 20/97, Loss: 0.2221
Epoch 10/10, Batch 30/97, Loss: 0.2065
Epoch 10/10, Batch 40/97, Loss: 0.1898
Epoch 10/10, Batch 50/97, Loss: 0.2392
Epoch 10/10, Batch 60/97, Loss: 0.1472
Epoch 10/10, Batch 70/97, Loss: 0.3315
Epoch 10/10, Batch 80/97, Loss: 0.1409
Epoch 10/10, Batch 90/97, Loss: 0.1587
Epoch 10/10, Train Loss: 0.1965, Valid Loss: 0.2321
Accuracy: 0.9100
Precision: 0.9072
Recall: 0.9100
F1-score: 0.9079
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2944
Epoch 1/10, Batch 20/97, Loss: 1.0552
Epoch 1/10, Batch 30/97, Loss: 0.7815
Epoch 1/10, Batch 40/97, Loss: 0.7139
Epoch 1/10, Batch 50/97, Loss: 0.5545
Epoch 1/10, Batch 60/97, Loss: 0.6738
Epoch 1/10, Batch 70/97, Loss: 0.7752
Epoch 1/10, Batch 80/97, Loss: 0.6787
Epoch 1/10, Batch 90/97, Loss: 0.5621
Epoch 1/10, Train Loss: 0.8008, Valid Loss: 0.4538
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5907
Epoch 2/10, Batch 20/97, Loss: 0.3797
Epoch 2/10, Batch 30/97, Loss: 0.4354
Epoch 2/10, Batch 40/97, Loss: 0.4738
Epoch 2/10, Batch 50/97, Loss: 0.4717
Epoch 2/10, Batch 60/97, Loss: 0.3087
Epoch 2/10, Batch 70/97, Loss: 0.3270
Epoch 2/10, Batch 80/97, Loss: 0.3062
Epoch 2/10, Batch 90/97, Loss: 0.3594
Epoch 2/10, Train Loss: 0.4132, Valid Loss: 0.3455
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3370
Epoch 3/10, Batch 20/97, Loss: 0.3093
Epoch 3/10, Batch 30/97, Loss: 0.3961
Epoch 3/10, Batch 40/97, Loss: 0.2675
Epoch 3/10, Batch 50/97, Loss: 0.3331
Epoch 3/10, Batch 60/97, Loss: 0.2438
Epoch 3/10, Batch 70/97, Loss: 0.4994
Epoch 3/10, Batch 80/97, Loss: 0.2453
Epoch 3/10, Batch 90/97, Loss: 0.2010
Epoch 3/10, Train Loss: 0.3293, Valid Loss: 0.3116
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3860
Epoch 4/10, Batch 20/97, Loss: 0.2490
Epoch 4/10, Batch 30/97, Loss: 0.1937
Epoch 4/10, Batch 40/97, Loss: 0.2111
Epoch 4/10, Batch 50/97, Loss: 0.2559
Epoch 4/10, Batch 60/97, Loss: 0.1968
Epoch 4/10, Batch 70/97, Loss: 0.2316
Epoch 4/10, Batch 80/97, Loss: 0.3027
Epoch 4/10, Batch 90/97, Loss: 0.1729
Epoch 4/10, Train Loss: 0.2876, Valid Loss: 0.2923
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2685
Epoch 5/10, Batch 20/97, Loss: 0.2696
Epoch 5/10, Batch 30/97, Loss: 0.1836
Epoch 5/10, Batch 40/97, Loss: 0.3838
Epoch 5/10, Batch 50/97, Loss: 0.2240
Epoch 5/10, Batch 60/97, Loss: 0.2278
Epoch 5/10, Batch 70/97, Loss: 0.2771
Epoch 5/10, Batch 80/97, Loss: 0.2588
Epoch 5/10, Batch 90/97, Loss: 0.1346
Epoch 5/10, Train Loss: 0.2644, Valid Loss: 0.2730
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2891
Epoch 6/10, Batch 20/97, Loss: 0.3442
Epoch 6/10, Batch 30/97, Loss: 0.1787
Epoch 6/10, Batch 40/97, Loss: 0.1449
Epoch 6/10, Batch 50/97, Loss: 0.2436
Epoch 6/10, Batch 60/97, Loss: 0.3601
Epoch 6/10, Batch 70/97, Loss: 0.3161
Epoch 6/10, Batch 80/97, Loss: 0.2197
Epoch 6/10, Batch 90/97, Loss: 0.3979
Epoch 6/10, Train Loss: 0.2448, Valid Loss: 0.2593
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2370
Epoch 7/10, Batch 20/97, Loss: 0.1733
Epoch 7/10, Batch 30/97, Loss: 0.0765
Epoch 7/10, Batch 40/97, Loss: 0.1979
Epoch 7/10, Batch 50/97, Loss: 0.2152
Epoch 7/10, Batch 60/97, Loss: 0.2055
Epoch 7/10, Batch 70/97, Loss: 0.2492
Epoch 7/10, Batch 80/97, Loss: 0.1208
Epoch 7/10, Batch 90/97, Loss: 0.1781
Epoch 7/10, Train Loss: 0.2240, Valid Loss: 0.2431
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1450
Epoch 8/10, Batch 20/97, Loss: 0.1615
Epoch 8/10, Batch 30/97, Loss: 0.2006
Epoch 8/10, Batch 40/97, Loss: 0.1736
Epoch 8/10, Batch 50/97, Loss: 0.1660
Epoch 8/10, Batch 60/97, Loss: 0.2823
Epoch 8/10, Batch 70/97, Loss: 0.2035
Epoch 8/10, Batch 80/97, Loss: 0.1401
Epoch 8/10, Batch 90/97, Loss: 0.2491
Epoch 8/10, Train Loss: 0.2146, Valid Loss: 0.2471
Epoch 9/10, Batch 10/97, Loss: 0.1670
Epoch 9/10, Batch 20/97, Loss: 0.3459
Epoch 9/10, Batch 30/97, Loss: 0.2009
Epoch 9/10, Batch 40/97, Loss: 0.1957
Epoch 9/10, Batch 50/97, Loss: 0.1407
Epoch 9/10, Batch 60/97, Loss: 0.1373
Epoch 9/10, Batch 70/97, Loss: 0.1837
Epoch 9/10, Batch 80/97, Loss: 0.2320
Epoch 9/10, Batch 90/97, Loss: 0.2679
Epoch 9/10, Train Loss: 0.2079, Valid Loss: 0.2339
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3530
Epoch 10/10, Batch 20/97, Loss: 0.1910
Epoch 10/10, Batch 30/97, Loss: 0.1583
Epoch 10/10, Batch 40/97, Loss: 0.1277
Epoch 10/10, Batch 50/97, Loss: 0.2727
Epoch 10/10, Batch 60/97, Loss: 0.0949
Epoch 10/10, Batch 70/97, Loss: 0.3241
Epoch 10/10, Batch 80/97, Loss: 0.1237
Epoch 10/10, Batch 90/97, Loss: 0.1653
Epoch 10/10, Train Loss: 0.2055, Valid Loss: 0.2352
Accuracy: 0.9194
Precision: 0.9168
Recall: 0.9194
F1-score: 0.9178
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2090
Epoch 1/10, Batch 20/97, Loss: 1.0168
Epoch 1/10, Batch 30/97, Loss: 0.7617
Epoch 1/10, Batch 40/97, Loss: 0.6727
Epoch 1/10, Batch 50/97, Loss: 0.6655
Epoch 1/10, Batch 60/97, Loss: 0.7607
Epoch 1/10, Batch 70/97, Loss: 0.6108
Epoch 1/10, Batch 80/97, Loss: 0.6488
Epoch 1/10, Batch 90/97, Loss: 0.5894
Epoch 1/10, Train Loss: 0.7883, Valid Loss: 0.4328
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5220
Epoch 2/10, Batch 20/97, Loss: 0.3162
Epoch 2/10, Batch 30/97, Loss: 0.4407
Epoch 2/10, Batch 40/97, Loss: 0.2525
Epoch 2/10, Batch 50/97, Loss: 0.5039
Epoch 2/10, Batch 60/97, Loss: 0.6219
Epoch 2/10, Batch 70/97, Loss: 0.2870
Epoch 2/10, Batch 80/97, Loss: 0.3530
Epoch 2/10, Batch 90/97, Loss: 0.4294
Epoch 2/10, Train Loss: 0.4059, Valid Loss: 0.3294
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3710
Epoch 3/10, Batch 20/97, Loss: 0.4980
Epoch 3/10, Batch 30/97, Loss: 0.4043
Epoch 3/10, Batch 40/97, Loss: 0.3550
Epoch 3/10, Batch 50/97, Loss: 0.4085
Epoch 3/10, Batch 60/97, Loss: 0.5330
Epoch 3/10, Batch 70/97, Loss: 0.3504
Epoch 3/10, Batch 80/97, Loss: 0.2710
Epoch 3/10, Batch 90/97, Loss: 0.4344
Epoch 3/10, Train Loss: 0.3272, Valid Loss: 0.2772
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2689
Epoch 4/10, Batch 20/97, Loss: 0.2237
Epoch 4/10, Batch 30/97, Loss: 0.3730
Epoch 4/10, Batch 40/97, Loss: 0.2052
Epoch 4/10, Batch 50/97, Loss: 0.2613
Epoch 4/10, Batch 60/97, Loss: 0.3039
Epoch 4/10, Batch 70/97, Loss: 0.3084
Epoch 4/10, Batch 80/97, Loss: 0.3153
Epoch 4/10, Batch 90/97, Loss: 0.3006
Epoch 4/10, Train Loss: 0.2805, Valid Loss: 0.2588
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2550
Epoch 5/10, Batch 20/97, Loss: 0.1954
Epoch 5/10, Batch 30/97, Loss: 0.2144
Epoch 5/10, Batch 40/97, Loss: 0.2190
Epoch 5/10, Batch 50/97, Loss: 0.2326
Epoch 5/10, Batch 60/97, Loss: 0.1700
Epoch 5/10, Batch 70/97, Loss: 0.3983
Epoch 5/10, Batch 80/97, Loss: 0.2784
Epoch 5/10, Batch 90/97, Loss: 0.3425
Epoch 5/10, Train Loss: 0.2534, Valid Loss: 0.2474
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2477
Epoch 6/10, Batch 20/97, Loss: 0.3905
Epoch 6/10, Batch 30/97, Loss: 0.1778
Epoch 6/10, Batch 40/97, Loss: 0.1627
Epoch 6/10, Batch 50/97, Loss: 0.2491
Epoch 6/10, Batch 60/97, Loss: 0.2861
Epoch 6/10, Batch 70/97, Loss: 0.2236
Epoch 6/10, Batch 80/97, Loss: 0.2642
Epoch 6/10, Batch 90/97, Loss: 0.2904
Epoch 6/10, Train Loss: 0.2388, Valid Loss: 0.2367
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1856
Epoch 7/10, Batch 20/97, Loss: 0.2480
Epoch 7/10, Batch 30/97, Loss: 0.0914
Epoch 7/10, Batch 40/97, Loss: 0.2452
Epoch 7/10, Batch 50/97, Loss: 0.0726
Epoch 7/10, Batch 60/97, Loss: 0.2065
Epoch 7/10, Batch 70/97, Loss: 0.1507
Epoch 7/10, Batch 80/97, Loss: 0.1553
Epoch 7/10, Batch 90/97, Loss: 0.2034
Epoch 7/10, Train Loss: 0.2165, Valid Loss: 0.2242
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1531
Epoch 8/10, Batch 20/97, Loss: 0.3140
Epoch 8/10, Batch 30/97, Loss: 0.2951
Epoch 8/10, Batch 40/97, Loss: 0.2199
Epoch 8/10, Batch 50/97, Loss: 0.2965
Epoch 8/10, Batch 60/97, Loss: 0.2141
Epoch 8/10, Batch 70/97, Loss: 0.1683
Epoch 8/10, Batch 80/97, Loss: 0.2412
Epoch 8/10, Batch 90/97, Loss: 0.1208
Epoch 8/10, Train Loss: 0.2092, Valid Loss: 0.2210
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1029
Epoch 9/10, Batch 20/97, Loss: 0.1479
Epoch 9/10, Batch 30/97, Loss: 0.1649
Epoch 9/10, Batch 40/97, Loss: 0.1548
Epoch 9/10, Batch 50/97, Loss: 0.1038
Epoch 9/10, Batch 60/97, Loss: 0.3091
Epoch 9/10, Batch 70/97, Loss: 0.1824
Epoch 9/10, Batch 80/97, Loss: 0.1449
Epoch 9/10, Batch 90/97, Loss: 0.1470
Epoch 9/10, Train Loss: 0.1998, Valid Loss: 0.2178
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2809
Epoch 10/10, Batch 20/97, Loss: 0.0965
Epoch 10/10, Batch 30/97, Loss: 0.1317
Epoch 10/10, Batch 40/97, Loss: 0.0900
Epoch 10/10, Batch 50/97, Loss: 0.2463
Epoch 10/10, Batch 60/97, Loss: 0.1110
Epoch 10/10, Batch 70/97, Loss: 0.3273
Epoch 10/10, Batch 80/97, Loss: 0.1972
Epoch 10/10, Batch 90/97, Loss: 0.1636
Epoch 10/10, Train Loss: 0.1935, Valid Loss: 0.2147
Model saved!
Accuracy: 0.9112
Precision: 0.9101
Recall: 0.9112
F1-score: 0.9076
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2751
Epoch 1/10, Batch 20/97, Loss: 1.0817
Epoch 1/10, Batch 30/97, Loss: 0.7835
Epoch 1/10, Batch 40/97, Loss: 0.7722
Epoch 1/10, Batch 50/97, Loss: 0.6439
Epoch 1/10, Batch 60/97, Loss: 0.7386
Epoch 1/10, Batch 70/97, Loss: 0.6942
Epoch 1/10, Batch 80/97, Loss: 0.6132
Epoch 1/10, Batch 90/97, Loss: 0.4804
Epoch 1/10, Train Loss: 0.7999, Valid Loss: 0.4436
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4988
Epoch 2/10, Batch 20/97, Loss: 0.5267
Epoch 2/10, Batch 30/97, Loss: 0.2411
Epoch 2/10, Batch 40/97, Loss: 0.2563
Epoch 2/10, Batch 50/97, Loss: 0.5493
Epoch 2/10, Batch 60/97, Loss: 0.3798
Epoch 2/10, Batch 70/97, Loss: 0.3279
Epoch 2/10, Batch 80/97, Loss: 0.3332
Epoch 2/10, Batch 90/97, Loss: 0.4001
Epoch 2/10, Train Loss: 0.4059, Valid Loss: 0.3377
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4267
Epoch 3/10, Batch 20/97, Loss: 0.3015
Epoch 3/10, Batch 30/97, Loss: 0.4072
Epoch 3/10, Batch 40/97, Loss: 0.2034
Epoch 3/10, Batch 50/97, Loss: 0.4121
Epoch 3/10, Batch 60/97, Loss: 0.1491
Epoch 3/10, Batch 70/97, Loss: 0.3557
Epoch 3/10, Batch 80/97, Loss: 0.2455
Epoch 3/10, Batch 90/97, Loss: 0.2072
Epoch 3/10, Train Loss: 0.3350, Valid Loss: 0.3008
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3335
Epoch 4/10, Batch 20/97, Loss: 0.1737
Epoch 4/10, Batch 30/97, Loss: 0.3150
Epoch 4/10, Batch 40/97, Loss: 0.1800
Epoch 4/10, Batch 50/97, Loss: 0.3169
Epoch 4/10, Batch 60/97, Loss: 0.2034
Epoch 4/10, Batch 70/97, Loss: 0.2802
Epoch 4/10, Batch 80/97, Loss: 0.4300
Epoch 4/10, Batch 90/97, Loss: 0.2772
Epoch 4/10, Train Loss: 0.2839, Valid Loss: 0.2861
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3081
Epoch 5/10, Batch 20/97, Loss: 0.3184
Epoch 5/10, Batch 30/97, Loss: 0.2257
Epoch 5/10, Batch 40/97, Loss: 0.1690
Epoch 5/10, Batch 50/97, Loss: 0.2070
Epoch 5/10, Batch 60/97, Loss: 0.2777
Epoch 5/10, Batch 70/97, Loss: 0.2848
Epoch 5/10, Batch 80/97, Loss: 0.2349
Epoch 5/10, Batch 90/97, Loss: 0.1986
Epoch 5/10, Train Loss: 0.2617, Valid Loss: 0.2648
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2238
Epoch 6/10, Batch 20/97, Loss: 0.2854
Epoch 6/10, Batch 30/97, Loss: 0.2081
Epoch 6/10, Batch 40/97, Loss: 0.2109
Epoch 6/10, Batch 50/97, Loss: 0.3351
Epoch 6/10, Batch 60/97, Loss: 0.3342
Epoch 6/10, Batch 70/97, Loss: 0.1905
Epoch 6/10, Batch 80/97, Loss: 0.3056
Epoch 6/10, Batch 90/97, Loss: 0.2334
Epoch 6/10, Train Loss: 0.2445, Valid Loss: 0.2527
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2177
Epoch 7/10, Batch 20/97, Loss: 0.1760
Epoch 7/10, Batch 30/97, Loss: 0.3045
Epoch 7/10, Batch 40/97, Loss: 0.1852
Epoch 7/10, Batch 50/97, Loss: 0.2396
Epoch 7/10, Batch 60/97, Loss: 0.2268
Epoch 7/10, Batch 70/97, Loss: 0.3048
Epoch 7/10, Batch 80/97, Loss: 0.1129
Epoch 7/10, Batch 90/97, Loss: 0.1703
Epoch 7/10, Train Loss: 0.2298, Valid Loss: 0.2407
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2200
Epoch 8/10, Batch 20/97, Loss: 0.1616
Epoch 8/10, Batch 30/97, Loss: 0.1654
Epoch 8/10, Batch 40/97, Loss: 0.3465
Epoch 8/10, Batch 50/97, Loss: 0.1686
Epoch 8/10, Batch 60/97, Loss: 0.2033
Epoch 8/10, Batch 70/97, Loss: 0.2122
Epoch 8/10, Batch 80/97, Loss: 0.2226
Epoch 8/10, Batch 90/97, Loss: 0.1378
Epoch 8/10, Train Loss: 0.2241, Valid Loss: 0.2453
Epoch 9/10, Batch 10/97, Loss: 0.1812
Epoch 9/10, Batch 20/97, Loss: 0.1010
Epoch 9/10, Batch 30/97, Loss: 0.1661
Epoch 9/10, Batch 40/97, Loss: 0.3161
Epoch 9/10, Batch 50/97, Loss: 0.2432
Epoch 9/10, Batch 60/97, Loss: 0.3395
Epoch 9/10, Batch 70/97, Loss: 0.2598
Epoch 9/10, Batch 80/97, Loss: 0.1433
Epoch 9/10, Batch 90/97, Loss: 0.1344
Epoch 9/10, Train Loss: 0.2067, Valid Loss: 0.2346
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2556
Epoch 10/10, Batch 20/97, Loss: 0.1446
Epoch 10/10, Batch 30/97, Loss: 0.1682
Epoch 10/10, Batch 40/97, Loss: 0.1167
Epoch 10/10, Batch 50/97, Loss: 0.1126
Epoch 10/10, Batch 60/97, Loss: 0.0949
Epoch 10/10, Batch 70/97, Loss: 0.2854
Epoch 10/10, Batch 80/97, Loss: 0.2421
Epoch 10/10, Batch 90/97, Loss: 0.1889
Epoch 10/10, Train Loss: 0.2018, Valid Loss: 0.2310
Model saved!
Accuracy: 0.9159
Precision: 0.9129
Recall: 0.9159
F1-score: 0.9134
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2306
Epoch 1/10, Batch 20/97, Loss: 1.0565
Epoch 1/10, Batch 30/97, Loss: 0.7145
Epoch 1/10, Batch 40/97, Loss: 0.7204
Epoch 1/10, Batch 50/97, Loss: 0.7021
Epoch 1/10, Batch 60/97, Loss: 0.6254
Epoch 1/10, Batch 70/97, Loss: 0.7091
Epoch 1/10, Batch 80/97, Loss: 0.6298
Epoch 1/10, Batch 90/97, Loss: 0.4362
Epoch 1/10, Train Loss: 0.8144, Valid Loss: 0.4548
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5053
Epoch 2/10, Batch 20/97, Loss: 0.5693
Epoch 2/10, Batch 30/97, Loss: 0.3763
Epoch 2/10, Batch 40/97, Loss: 0.3956
Epoch 2/10, Batch 50/97, Loss: 0.4305
Epoch 2/10, Batch 60/97, Loss: 0.4654
Epoch 2/10, Batch 70/97, Loss: 0.4536
Epoch 2/10, Batch 80/97, Loss: 0.3716
Epoch 2/10, Batch 90/97, Loss: 0.3564
Epoch 2/10, Train Loss: 0.4220, Valid Loss: 0.3524
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4307
Epoch 3/10, Batch 20/97, Loss: 0.2976
Epoch 3/10, Batch 30/97, Loss: 0.3906
Epoch 3/10, Batch 40/97, Loss: 0.3376
Epoch 3/10, Batch 50/97, Loss: 0.3662
Epoch 3/10, Batch 60/97, Loss: 0.1130
Epoch 3/10, Batch 70/97, Loss: 0.3057
Epoch 3/10, Batch 80/97, Loss: 0.1907
Epoch 3/10, Batch 90/97, Loss: 0.2498
Epoch 3/10, Train Loss: 0.3441, Valid Loss: 0.3103
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2693
Epoch 4/10, Batch 20/97, Loss: 0.2047
Epoch 4/10, Batch 30/97, Loss: 0.3902
Epoch 4/10, Batch 40/97, Loss: 0.1980
Epoch 4/10, Batch 50/97, Loss: 0.2310
Epoch 4/10, Batch 60/97, Loss: 0.2738
Epoch 4/10, Batch 70/97, Loss: 0.3351
Epoch 4/10, Batch 80/97, Loss: 0.3872
Epoch 4/10, Batch 90/97, Loss: 0.3206
Epoch 4/10, Train Loss: 0.2926, Valid Loss: 0.2995
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3379
Epoch 5/10, Batch 20/97, Loss: 0.3144
Epoch 5/10, Batch 30/97, Loss: 0.1798
Epoch 5/10, Batch 40/97, Loss: 0.3371
Epoch 5/10, Batch 50/97, Loss: 0.2400
Epoch 5/10, Batch 60/97, Loss: 0.2585
Epoch 5/10, Batch 70/97, Loss: 0.3478
Epoch 5/10, Batch 80/97, Loss: 0.2251
Epoch 5/10, Batch 90/97, Loss: 0.2095
Epoch 5/10, Train Loss: 0.2717, Valid Loss: 0.2838
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3150
Epoch 6/10, Batch 20/97, Loss: 0.1959
Epoch 6/10, Batch 30/97, Loss: 0.3341
Epoch 6/10, Batch 40/97, Loss: 0.1840
Epoch 6/10, Batch 50/97, Loss: 0.1467
Epoch 6/10, Batch 60/97, Loss: 0.2468
Epoch 6/10, Batch 70/97, Loss: 0.2862
Epoch 6/10, Batch 80/97, Loss: 0.4001
Epoch 6/10, Batch 90/97, Loss: 0.3603
Epoch 6/10, Train Loss: 0.2505, Valid Loss: 0.2739
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.0883
Epoch 7/10, Batch 20/97, Loss: 0.2139
Epoch 7/10, Batch 30/97, Loss: 0.1321
Epoch 7/10, Batch 40/97, Loss: 0.1991
Epoch 7/10, Batch 50/97, Loss: 0.2202
Epoch 7/10, Batch 60/97, Loss: 0.1444
Epoch 7/10, Batch 70/97, Loss: 0.2786
Epoch 7/10, Batch 80/97, Loss: 0.1843
Epoch 7/10, Batch 90/97, Loss: 0.3060
Epoch 7/10, Train Loss: 0.2261, Valid Loss: 0.2733
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1756
Epoch 8/10, Batch 20/97, Loss: 0.1590
Epoch 8/10, Batch 30/97, Loss: 0.1131
Epoch 8/10, Batch 40/97, Loss: 0.1731
Epoch 8/10, Batch 50/97, Loss: 0.1688
Epoch 8/10, Batch 60/97, Loss: 0.1663
Epoch 8/10, Batch 70/97, Loss: 0.3532
Epoch 8/10, Batch 80/97, Loss: 0.0946
Epoch 8/10, Batch 90/97, Loss: 0.3020
Epoch 8/10, Train Loss: 0.2266, Valid Loss: 0.2732
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1239
Epoch 9/10, Batch 20/97, Loss: 0.1410
Epoch 9/10, Batch 30/97, Loss: 0.2733
Epoch 9/10, Batch 40/97, Loss: 0.2240
Epoch 9/10, Batch 50/97, Loss: 0.1994
Epoch 9/10, Batch 60/97, Loss: 0.1737
Epoch 9/10, Batch 70/97, Loss: 0.1898
Epoch 9/10, Batch 80/97, Loss: 0.0908
Epoch 9/10, Batch 90/97, Loss: 0.1839
Epoch 9/10, Train Loss: 0.2076, Valid Loss: 0.2611
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3619
Epoch 10/10, Batch 20/97, Loss: 0.2499
Epoch 10/10, Batch 30/97, Loss: 0.2099
Epoch 10/10, Batch 40/97, Loss: 0.1584
Epoch 10/10, Batch 50/97, Loss: 0.2190
Epoch 10/10, Batch 60/97, Loss: 0.2011
Epoch 10/10, Batch 70/97, Loss: 0.3698
Epoch 10/10, Batch 80/97, Loss: 0.2027
Epoch 10/10, Batch 90/97, Loss: 0.1848
Epoch 10/10, Train Loss: 0.2059, Valid Loss: 0.2639
Accuracy: 0.9171
Precision: 0.9147
Recall: 0.9171
F1-score: 0.9151
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2823
Epoch 1/10, Batch 20/97, Loss: 1.0082
Epoch 1/10, Batch 30/97, Loss: 0.8081
Epoch 1/10, Batch 40/97, Loss: 0.7583
Epoch 1/10, Batch 50/97, Loss: 0.6369
Epoch 1/10, Batch 60/97, Loss: 0.6185
Epoch 1/10, Batch 70/97, Loss: 0.7079
Epoch 1/10, Batch 80/97, Loss: 0.6259
Epoch 1/10, Batch 90/97, Loss: 0.5002
Epoch 1/10, Train Loss: 0.8059, Valid Loss: 0.4280
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6773
Epoch 2/10, Batch 20/97, Loss: 0.4673
Epoch 2/10, Batch 30/97, Loss: 0.4084
Epoch 2/10, Batch 40/97, Loss: 0.4019
Epoch 2/10, Batch 50/97, Loss: 0.3744
Epoch 2/10, Batch 60/97, Loss: 0.4087
Epoch 2/10, Batch 70/97, Loss: 0.4869
Epoch 2/10, Batch 80/97, Loss: 0.2512
Epoch 2/10, Batch 90/97, Loss: 0.4733
Epoch 2/10, Train Loss: 0.4158, Valid Loss: 0.3227
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4731
Epoch 3/10, Batch 20/97, Loss: 0.2793
Epoch 3/10, Batch 30/97, Loss: 0.3910
Epoch 3/10, Batch 40/97, Loss: 0.2659
Epoch 3/10, Batch 50/97, Loss: 0.4426
Epoch 3/10, Batch 60/97, Loss: 0.2157
Epoch 3/10, Batch 70/97, Loss: 0.1960
Epoch 3/10, Batch 80/97, Loss: 0.3239
Epoch 3/10, Batch 90/97, Loss: 0.3449
Epoch 3/10, Train Loss: 0.3389, Valid Loss: 0.2757
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.5233
Epoch 4/10, Batch 20/97, Loss: 0.2489
Epoch 4/10, Batch 30/97, Loss: 0.2745
Epoch 4/10, Batch 40/97, Loss: 0.3558
Epoch 4/10, Batch 50/97, Loss: 0.4070
Epoch 4/10, Batch 60/97, Loss: 0.2535
Epoch 4/10, Batch 70/97, Loss: 0.3164
Epoch 4/10, Batch 80/97, Loss: 0.2967
Epoch 4/10, Batch 90/97, Loss: 0.1915
Epoch 4/10, Train Loss: 0.2894, Valid Loss: 0.2638
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2103
Epoch 5/10, Batch 20/97, Loss: 0.3950
Epoch 5/10, Batch 30/97, Loss: 0.2505
Epoch 5/10, Batch 40/97, Loss: 0.2944
Epoch 5/10, Batch 50/97, Loss: 0.2376
Epoch 5/10, Batch 60/97, Loss: 0.2217
Epoch 5/10, Batch 70/97, Loss: 0.3991
Epoch 5/10, Batch 80/97, Loss: 0.2502
Epoch 5/10, Batch 90/97, Loss: 0.1088
Epoch 5/10, Train Loss: 0.2706, Valid Loss: 0.2457
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2630
Epoch 6/10, Batch 20/97, Loss: 0.2906
Epoch 6/10, Batch 30/97, Loss: 0.2873
Epoch 6/10, Batch 40/97, Loss: 0.1622
Epoch 6/10, Batch 50/97, Loss: 0.1924
Epoch 6/10, Batch 60/97, Loss: 0.2229
Epoch 6/10, Batch 70/97, Loss: 0.6190
Epoch 6/10, Batch 80/97, Loss: 0.3672
Epoch 6/10, Batch 90/97, Loss: 0.2944
Epoch 6/10, Train Loss: 0.2471, Valid Loss: 0.2256
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1618
Epoch 7/10, Batch 20/97, Loss: 0.2618
Epoch 7/10, Batch 30/97, Loss: 0.1640
Epoch 7/10, Batch 40/97, Loss: 0.2825
Epoch 7/10, Batch 50/97, Loss: 0.2163
Epoch 7/10, Batch 60/97, Loss: 0.1021
Epoch 7/10, Batch 70/97, Loss: 0.3022
Epoch 7/10, Batch 80/97, Loss: 0.2300
Epoch 7/10, Batch 90/97, Loss: 0.1908
Epoch 7/10, Train Loss: 0.2259, Valid Loss: 0.2251
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2110
Epoch 8/10, Batch 20/97, Loss: 0.1342
Epoch 8/10, Batch 30/97, Loss: 0.1973
Epoch 8/10, Batch 40/97, Loss: 0.2219
Epoch 8/10, Batch 50/97, Loss: 0.1508
Epoch 8/10, Batch 60/97, Loss: 0.1935
Epoch 8/10, Batch 70/97, Loss: 0.1969
Epoch 8/10, Batch 80/97, Loss: 0.1244
Epoch 8/10, Batch 90/97, Loss: 0.2214
Epoch 8/10, Train Loss: 0.2207, Valid Loss: 0.2203
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1533
Epoch 9/10, Batch 20/97, Loss: 0.1773
Epoch 9/10, Batch 30/97, Loss: 0.2601
Epoch 9/10, Batch 40/97, Loss: 0.1541
Epoch 9/10, Batch 50/97, Loss: 0.1293
Epoch 9/10, Batch 60/97, Loss: 0.1664
Epoch 9/10, Batch 70/97, Loss: 0.1243
Epoch 9/10, Batch 80/97, Loss: 0.0988
Epoch 9/10, Batch 90/97, Loss: 0.2129
Epoch 9/10, Train Loss: 0.2054, Valid Loss: 0.2234
Epoch 10/10, Batch 10/97, Loss: 0.1863
Epoch 10/10, Batch 20/97, Loss: 0.0788
Epoch 10/10, Batch 30/97, Loss: 0.2051
Epoch 10/10, Batch 40/97, Loss: 0.2277
Epoch 10/10, Batch 50/97, Loss: 0.3530
Epoch 10/10, Batch 60/97, Loss: 0.1390
Epoch 10/10, Batch 70/97, Loss: 0.3025
Epoch 10/10, Batch 80/97, Loss: 0.1540
Epoch 10/10, Batch 90/97, Loss: 0.1547
Epoch 10/10, Train Loss: 0.2020, Valid Loss: 0.2088
Model saved!
Accuracy: 0.9159
Precision: 0.9137
Recall: 0.9159
F1-score: 0.9137
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2587
Epoch 1/10, Batch 20/97, Loss: 1.1174
Epoch 1/10, Batch 30/97, Loss: 0.7348
Epoch 1/10, Batch 40/97, Loss: 0.7946
Epoch 1/10, Batch 50/97, Loss: 0.5935
Epoch 1/10, Batch 60/97, Loss: 0.6572
Epoch 1/10, Batch 70/97, Loss: 0.7383
Epoch 1/10, Batch 80/97, Loss: 0.5809
Epoch 1/10, Batch 90/97, Loss: 0.6628
Epoch 1/10, Train Loss: 0.7943, Valid Loss: 0.4155
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5950
Epoch 2/10, Batch 20/97, Loss: 0.4665
Epoch 2/10, Batch 30/97, Loss: 0.3546
Epoch 2/10, Batch 40/97, Loss: 0.3868
Epoch 2/10, Batch 50/97, Loss: 0.3988
Epoch 2/10, Batch 60/97, Loss: 0.3426
Epoch 2/10, Batch 70/97, Loss: 0.4193
Epoch 2/10, Batch 80/97, Loss: 0.3231
Epoch 2/10, Batch 90/97, Loss: 0.5650
Epoch 2/10, Train Loss: 0.4048, Valid Loss: 0.3085
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3128
Epoch 3/10, Batch 20/97, Loss: 0.3194
Epoch 3/10, Batch 30/97, Loss: 0.4744
Epoch 3/10, Batch 40/97, Loss: 0.1684
Epoch 3/10, Batch 50/97, Loss: 0.3859
Epoch 3/10, Batch 60/97, Loss: 0.2748
Epoch 3/10, Batch 70/97, Loss: 0.3758
Epoch 3/10, Batch 80/97, Loss: 0.3025
Epoch 3/10, Batch 90/97, Loss: 0.2740
Epoch 3/10, Train Loss: 0.3254, Valid Loss: 0.2637
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3188
Epoch 4/10, Batch 20/97, Loss: 0.2846
Epoch 4/10, Batch 30/97, Loss: 0.2283
Epoch 4/10, Batch 40/97, Loss: 0.2952
Epoch 4/10, Batch 50/97, Loss: 0.3523
Epoch 4/10, Batch 60/97, Loss: 0.2048
Epoch 4/10, Batch 70/97, Loss: 0.3956
Epoch 4/10, Batch 80/97, Loss: 0.2671
Epoch 4/10, Batch 90/97, Loss: 0.2142
Epoch 4/10, Train Loss: 0.2820, Valid Loss: 0.2464
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2992
Epoch 5/10, Batch 20/97, Loss: 0.1919
Epoch 5/10, Batch 30/97, Loss: 0.1524
Epoch 5/10, Batch 40/97, Loss: 0.2297
Epoch 5/10, Batch 50/97, Loss: 0.4303
Epoch 5/10, Batch 60/97, Loss: 0.3728
Epoch 5/10, Batch 70/97, Loss: 0.2039
Epoch 5/10, Batch 80/97, Loss: 0.3093
Epoch 5/10, Batch 90/97, Loss: 0.1898
Epoch 5/10, Train Loss: 0.2587, Valid Loss: 0.2352
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1464
Epoch 6/10, Batch 20/97, Loss: 0.3762
Epoch 6/10, Batch 30/97, Loss: 0.1850
Epoch 6/10, Batch 40/97, Loss: 0.2134
Epoch 6/10, Batch 50/97, Loss: 0.2350
Epoch 6/10, Batch 60/97, Loss: 0.3214
Epoch 6/10, Batch 70/97, Loss: 0.2990
Epoch 6/10, Batch 80/97, Loss: 0.3640
Epoch 6/10, Batch 90/97, Loss: 0.2655
Epoch 6/10, Train Loss: 0.2424, Valid Loss: 0.2196
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2650
Epoch 7/10, Batch 20/97, Loss: 0.1628
Epoch 7/10, Batch 30/97, Loss: 0.1596
Epoch 7/10, Batch 40/97, Loss: 0.1158
Epoch 7/10, Batch 50/97, Loss: 0.2763
Epoch 7/10, Batch 60/97, Loss: 0.2524
Epoch 7/10, Batch 70/97, Loss: 0.3811
Epoch 7/10, Batch 80/97, Loss: 0.1981
Epoch 7/10, Batch 90/97, Loss: 0.2056
Epoch 7/10, Train Loss: 0.2241, Valid Loss: 0.2127
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2203
Epoch 8/10, Batch 20/97, Loss: 0.1917
Epoch 8/10, Batch 30/97, Loss: 0.1623
Epoch 8/10, Batch 40/97, Loss: 0.2005
Epoch 8/10, Batch 50/97, Loss: 0.3252
Epoch 8/10, Batch 60/97, Loss: 0.1777
Epoch 8/10, Batch 70/97, Loss: 0.3427
Epoch 8/10, Batch 80/97, Loss: 0.2854
Epoch 8/10, Batch 90/97, Loss: 0.1917
Epoch 8/10, Train Loss: 0.2161, Valid Loss: 0.2092
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1627
Epoch 9/10, Batch 20/97, Loss: 0.0882
Epoch 9/10, Batch 30/97, Loss: 0.2818
Epoch 9/10, Batch 40/97, Loss: 0.2236
Epoch 9/10, Batch 50/97, Loss: 0.1866
Epoch 9/10, Batch 60/97, Loss: 0.2330
Epoch 9/10, Batch 70/97, Loss: 0.1753
Epoch 9/10, Batch 80/97, Loss: 0.2011
Epoch 9/10, Batch 90/97, Loss: 0.1716
Epoch 9/10, Train Loss: 0.2061, Valid Loss: 0.2076
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2937
Epoch 10/10, Batch 20/97, Loss: 0.1790
Epoch 10/10, Batch 30/97, Loss: 0.3405
Epoch 10/10, Batch 40/97, Loss: 0.2743
Epoch 10/10, Batch 50/97, Loss: 0.1504
Epoch 10/10, Batch 60/97, Loss: 0.0957
Epoch 10/10, Batch 70/97, Loss: 0.1663
Epoch 10/10, Batch 80/97, Loss: 0.1470
Epoch 10/10, Batch 90/97, Loss: 0.1770
Epoch 10/10, Train Loss: 0.2053, Valid Loss: 0.2078
Accuracy: 0.9194
Precision: 0.9170
Recall: 0.9194
F1-score: 0.9170
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2707
Epoch 1/10, Batch 20/97, Loss: 1.0889
Epoch 1/10, Batch 30/97, Loss: 0.6862
Epoch 1/10, Batch 40/97, Loss: 0.7427
Epoch 1/10, Batch 50/97, Loss: 0.6359
Epoch 1/10, Batch 60/97, Loss: 0.7252
Epoch 1/10, Batch 70/97, Loss: 0.5824
Epoch 1/10, Batch 80/97, Loss: 0.6487
Epoch 1/10, Batch 90/97, Loss: 0.5203
Epoch 1/10, Train Loss: 0.7985, Valid Loss: 0.4405
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5065
Epoch 2/10, Batch 20/97, Loss: 0.4641
Epoch 2/10, Batch 30/97, Loss: 0.3371
Epoch 2/10, Batch 40/97, Loss: 0.4249
Epoch 2/10, Batch 50/97, Loss: 0.4489
Epoch 2/10, Batch 60/97, Loss: 0.2706
Epoch 2/10, Batch 70/97, Loss: 0.3584
Epoch 2/10, Batch 80/97, Loss: 0.5041
Epoch 2/10, Batch 90/97, Loss: 0.4102
Epoch 2/10, Train Loss: 0.4074, Valid Loss: 0.3228
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4494
Epoch 3/10, Batch 20/97, Loss: 0.4461
Epoch 3/10, Batch 30/97, Loss: 0.4269
Epoch 3/10, Batch 40/97, Loss: 0.3061
Epoch 3/10, Batch 50/97, Loss: 0.3545
Epoch 3/10, Batch 60/97, Loss: 0.3286
Epoch 3/10, Batch 70/97, Loss: 0.2599
Epoch 3/10, Batch 80/97, Loss: 0.3727
Epoch 3/10, Batch 90/97, Loss: 0.3028
Epoch 3/10, Train Loss: 0.3351, Valid Loss: 0.2814
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.5668
Epoch 4/10, Batch 20/97, Loss: 0.2577
Epoch 4/10, Batch 30/97, Loss: 0.3147
Epoch 4/10, Batch 40/97, Loss: 0.3721
Epoch 4/10, Batch 50/97, Loss: 0.2376
Epoch 4/10, Batch 60/97, Loss: 0.3340
Epoch 4/10, Batch 70/97, Loss: 0.3332
Epoch 4/10, Batch 80/97, Loss: 0.4150
Epoch 4/10, Batch 90/97, Loss: 0.2252
Epoch 4/10, Train Loss: 0.2796, Valid Loss: 0.2582
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3085
Epoch 5/10, Batch 20/97, Loss: 0.1882
Epoch 5/10, Batch 30/97, Loss: 0.2834
Epoch 5/10, Batch 40/97, Loss: 0.2069
Epoch 5/10, Batch 50/97, Loss: 0.2510
Epoch 5/10, Batch 60/97, Loss: 0.2137
Epoch 5/10, Batch 70/97, Loss: 0.2166
Epoch 5/10, Batch 80/97, Loss: 0.2564
Epoch 5/10, Batch 90/97, Loss: 0.1520
Epoch 5/10, Train Loss: 0.2659, Valid Loss: 0.2530
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2149
Epoch 6/10, Batch 20/97, Loss: 0.3254
Epoch 6/10, Batch 30/97, Loss: 0.1844
Epoch 6/10, Batch 40/97, Loss: 0.1776
Epoch 6/10, Batch 50/97, Loss: 0.1499
Epoch 6/10, Batch 60/97, Loss: 0.3482
Epoch 6/10, Batch 70/97, Loss: 0.2110
Epoch 6/10, Batch 80/97, Loss: 0.3241
Epoch 6/10, Batch 90/97, Loss: 0.3233
Epoch 6/10, Train Loss: 0.2493, Valid Loss: 0.2312
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1893
Epoch 7/10, Batch 20/97, Loss: 0.3340
Epoch 7/10, Batch 30/97, Loss: 0.2069
Epoch 7/10, Batch 40/97, Loss: 0.1002
Epoch 7/10, Batch 50/97, Loss: 0.2808
Epoch 7/10, Batch 60/97, Loss: 0.1615
Epoch 7/10, Batch 70/97, Loss: 0.2861
Epoch 7/10, Batch 80/97, Loss: 0.1063
Epoch 7/10, Batch 90/97, Loss: 0.2239
Epoch 7/10, Train Loss: 0.2282, Valid Loss: 0.2234
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1955
Epoch 8/10, Batch 20/97, Loss: 0.1080
Epoch 8/10, Batch 30/97, Loss: 0.2745
Epoch 8/10, Batch 40/97, Loss: 0.1844
Epoch 8/10, Batch 50/97, Loss: 0.2921
Epoch 8/10, Batch 60/97, Loss: 0.1700
Epoch 8/10, Batch 70/97, Loss: 0.2392
Epoch 8/10, Batch 80/97, Loss: 0.2869
Epoch 8/10, Batch 90/97, Loss: 0.1656
Epoch 8/10, Train Loss: 0.2157, Valid Loss: 0.2279
Epoch 9/10, Batch 10/97, Loss: 0.1316
Epoch 9/10, Batch 20/97, Loss: 0.1115
Epoch 9/10, Batch 30/97, Loss: 0.1694
Epoch 9/10, Batch 40/97, Loss: 0.3034
Epoch 9/10, Batch 50/97, Loss: 0.1781
Epoch 9/10, Batch 60/97, Loss: 0.0943
Epoch 9/10, Batch 70/97, Loss: 0.1811
Epoch 9/10, Batch 80/97, Loss: 0.1734
Epoch 9/10, Batch 90/97, Loss: 0.1327
Epoch 9/10, Train Loss: 0.2015, Valid Loss: 0.2139
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1848
Epoch 10/10, Batch 20/97, Loss: 0.2501
Epoch 10/10, Batch 30/97, Loss: 0.1828
Epoch 10/10, Batch 40/97, Loss: 0.0944
Epoch 10/10, Batch 50/97, Loss: 0.0974
Epoch 10/10, Batch 60/97, Loss: 0.1218
Epoch 10/10, Batch 70/97, Loss: 0.2597
Epoch 10/10, Batch 80/97, Loss: 0.1877
Epoch 10/10, Batch 90/97, Loss: 0.1061
Epoch 10/10, Train Loss: 0.1958, Valid Loss: 0.2170
Accuracy: 0.9136
Precision: 0.9123
Recall: 0.9136
F1-score: 0.9125
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2080
Epoch 1/10, Batch 20/97, Loss: 1.0719
Epoch 1/10, Batch 30/97, Loss: 0.7182
Epoch 1/10, Batch 40/97, Loss: 0.7075
Epoch 1/10, Batch 50/97, Loss: 0.5845
Epoch 1/10, Batch 60/97, Loss: 0.7484
Epoch 1/10, Batch 70/97, Loss: 0.6059
Epoch 1/10, Batch 80/97, Loss: 0.5387
Epoch 1/10, Batch 90/97, Loss: 0.5319
Epoch 1/10, Train Loss: 0.7959, Valid Loss: 0.4493
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5241
Epoch 2/10, Batch 20/97, Loss: 0.4432
Epoch 2/10, Batch 30/97, Loss: 0.4032
Epoch 2/10, Batch 40/97, Loss: 0.3015
Epoch 2/10, Batch 50/97, Loss: 0.3367
Epoch 2/10, Batch 60/97, Loss: 0.3457
Epoch 2/10, Batch 70/97, Loss: 0.3107
Epoch 2/10, Batch 80/97, Loss: 0.5036
Epoch 2/10, Batch 90/97, Loss: 0.4598
Epoch 2/10, Train Loss: 0.4061, Valid Loss: 0.3496
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2915
Epoch 3/10, Batch 20/97, Loss: 0.2603
Epoch 3/10, Batch 30/97, Loss: 0.3446
Epoch 3/10, Batch 40/97, Loss: 0.2133
Epoch 3/10, Batch 50/97, Loss: 0.4497
Epoch 3/10, Batch 60/97, Loss: 0.2975
Epoch 3/10, Batch 70/97, Loss: 0.3797
Epoch 3/10, Batch 80/97, Loss: 0.3079
Epoch 3/10, Batch 90/97, Loss: 0.2143
Epoch 3/10, Train Loss: 0.3308, Valid Loss: 0.3083
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2991
Epoch 4/10, Batch 20/97, Loss: 0.2017
Epoch 4/10, Batch 30/97, Loss: 0.2814
Epoch 4/10, Batch 40/97, Loss: 0.2102
Epoch 4/10, Batch 50/97, Loss: 0.2969
Epoch 4/10, Batch 60/97, Loss: 0.2456
Epoch 4/10, Batch 70/97, Loss: 0.2958
Epoch 4/10, Batch 80/97, Loss: 0.2783
Epoch 4/10, Batch 90/97, Loss: 0.1871
Epoch 4/10, Train Loss: 0.2791, Valid Loss: 0.2752
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3279
Epoch 5/10, Batch 20/97, Loss: 0.2548
Epoch 5/10, Batch 30/97, Loss: 0.1748
Epoch 5/10, Batch 40/97, Loss: 0.1845
Epoch 5/10, Batch 50/97, Loss: 0.2357
Epoch 5/10, Batch 60/97, Loss: 0.3002
Epoch 5/10, Batch 70/97, Loss: 0.1989
Epoch 5/10, Batch 80/97, Loss: 0.2055
Epoch 5/10, Batch 90/97, Loss: 0.1810
Epoch 5/10, Train Loss: 0.2635, Valid Loss: 0.2696
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2955
Epoch 6/10, Batch 20/97, Loss: 0.2505
Epoch 6/10, Batch 30/97, Loss: 0.1956
Epoch 6/10, Batch 40/97, Loss: 0.1575
Epoch 6/10, Batch 50/97, Loss: 0.2470
Epoch 6/10, Batch 60/97, Loss: 0.4439
Epoch 6/10, Batch 70/97, Loss: 0.1652
Epoch 6/10, Batch 80/97, Loss: 0.1745
Epoch 6/10, Batch 90/97, Loss: 0.3030
Epoch 6/10, Train Loss: 0.2485, Valid Loss: 0.2590
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2717
Epoch 7/10, Batch 20/97, Loss: 0.2342
Epoch 7/10, Batch 30/97, Loss: 0.1255
Epoch 7/10, Batch 40/97, Loss: 0.1796
Epoch 7/10, Batch 50/97, Loss: 0.1643
Epoch 7/10, Batch 60/97, Loss: 0.1291
Epoch 7/10, Batch 70/97, Loss: 0.3257
Epoch 7/10, Batch 80/97, Loss: 0.2726
Epoch 7/10, Batch 90/97, Loss: 0.1299
Epoch 7/10, Train Loss: 0.2220, Valid Loss: 0.2496
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2606
Epoch 8/10, Batch 20/97, Loss: 0.1906
Epoch 8/10, Batch 30/97, Loss: 0.2048
Epoch 8/10, Batch 40/97, Loss: 0.2297
Epoch 8/10, Batch 50/97, Loss: 0.2114
Epoch 8/10, Batch 60/97, Loss: 0.1233
Epoch 8/10, Batch 70/97, Loss: 0.1563
Epoch 8/10, Batch 80/97, Loss: 0.2955
Epoch 8/10, Batch 90/97, Loss: 0.1465
Epoch 8/10, Train Loss: 0.2136, Valid Loss: 0.2429
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2648
Epoch 9/10, Batch 20/97, Loss: 0.2054
Epoch 9/10, Batch 30/97, Loss: 0.1670
Epoch 9/10, Batch 40/97, Loss: 0.1845
Epoch 9/10, Batch 50/97, Loss: 0.1875
Epoch 9/10, Batch 60/97, Loss: 0.2129
Epoch 9/10, Batch 70/97, Loss: 0.0855
Epoch 9/10, Batch 80/97, Loss: 0.1070
Epoch 9/10, Batch 90/97, Loss: 0.0927
Epoch 9/10, Train Loss: 0.2077, Valid Loss: 0.2385
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3609
Epoch 10/10, Batch 20/97, Loss: 0.2130
Epoch 10/10, Batch 30/97, Loss: 0.3034
Epoch 10/10, Batch 40/97, Loss: 0.1496
Epoch 10/10, Batch 50/97, Loss: 0.2042
Epoch 10/10, Batch 60/97, Loss: 0.1685
Epoch 10/10, Batch 70/97, Loss: 0.1475
Epoch 10/10, Batch 80/97, Loss: 0.1324
Epoch 10/10, Batch 90/97, Loss: 0.1911
Epoch 10/10, Train Loss: 0.1987, Valid Loss: 0.2353
Model saved!
Accuracy: 0.9100
Precision: 0.9061
Recall: 0.9100
F1-score: 0.9072
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2388
Epoch 1/10, Batch 20/97, Loss: 1.1235
Epoch 1/10, Batch 30/97, Loss: 0.7794
Epoch 1/10, Batch 40/97, Loss: 0.6933
Epoch 1/10, Batch 50/97, Loss: 0.5798
Epoch 1/10, Batch 60/97, Loss: 0.7117
Epoch 1/10, Batch 70/97, Loss: 0.5731
Epoch 1/10, Batch 80/97, Loss: 0.4495
Epoch 1/10, Batch 90/97, Loss: 0.6236
Epoch 1/10, Train Loss: 0.7958, Valid Loss: 0.4182
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6188
Epoch 2/10, Batch 20/97, Loss: 0.4166
Epoch 2/10, Batch 30/97, Loss: 0.3861
Epoch 2/10, Batch 40/97, Loss: 0.3836
Epoch 2/10, Batch 50/97, Loss: 0.4512
Epoch 2/10, Batch 60/97, Loss: 0.4675
Epoch 2/10, Batch 70/97, Loss: 0.2816
Epoch 2/10, Batch 80/97, Loss: 0.4126
Epoch 2/10, Batch 90/97, Loss: 0.3908
Epoch 2/10, Train Loss: 0.4087, Valid Loss: 0.3099
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2475
Epoch 3/10, Batch 20/97, Loss: 0.2761
Epoch 3/10, Batch 30/97, Loss: 0.4279
Epoch 3/10, Batch 40/97, Loss: 0.2719
Epoch 3/10, Batch 50/97, Loss: 0.3647
Epoch 3/10, Batch 60/97, Loss: 0.2331
Epoch 3/10, Batch 70/97, Loss: 0.3502
Epoch 3/10, Batch 80/97, Loss: 0.2822
Epoch 3/10, Batch 90/97, Loss: 0.2536
Epoch 3/10, Train Loss: 0.3349, Valid Loss: 0.2661
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.5231
Epoch 4/10, Batch 20/97, Loss: 0.2984
Epoch 4/10, Batch 30/97, Loss: 0.2262
Epoch 4/10, Batch 40/97, Loss: 0.2769
Epoch 4/10, Batch 50/97, Loss: 0.2603
Epoch 4/10, Batch 60/97, Loss: 0.3363
Epoch 4/10, Batch 70/97, Loss: 0.2363
Epoch 4/10, Batch 80/97, Loss: 0.3251
Epoch 4/10, Batch 90/97, Loss: 0.2008
Epoch 4/10, Train Loss: 0.2959, Valid Loss: 0.2412
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2652
Epoch 5/10, Batch 20/97, Loss: 0.4751
Epoch 5/10, Batch 30/97, Loss: 0.3148
Epoch 5/10, Batch 40/97, Loss: 0.2690
Epoch 5/10, Batch 50/97, Loss: 0.2984
Epoch 5/10, Batch 60/97, Loss: 0.2796
Epoch 5/10, Batch 70/97, Loss: 0.1923
Epoch 5/10, Batch 80/97, Loss: 0.2929
Epoch 5/10, Batch 90/97, Loss: 0.1824
Epoch 5/10, Train Loss: 0.2760, Valid Loss: 0.2267
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2044
Epoch 6/10, Batch 20/97, Loss: 0.2858
Epoch 6/10, Batch 30/97, Loss: 0.2143
Epoch 6/10, Batch 40/97, Loss: 0.1401
Epoch 6/10, Batch 50/97, Loss: 0.2852
Epoch 6/10, Batch 60/97, Loss: 0.3145
Epoch 6/10, Batch 70/97, Loss: 0.2988
Epoch 6/10, Batch 80/97, Loss: 0.3808
Epoch 6/10, Batch 90/97, Loss: 0.2824
Epoch 6/10, Train Loss: 0.2457, Valid Loss: 0.2125
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2063
Epoch 7/10, Batch 20/97, Loss: 0.3417
Epoch 7/10, Batch 30/97, Loss: 0.1399
Epoch 7/10, Batch 40/97, Loss: 0.1411
Epoch 7/10, Batch 50/97, Loss: 0.2430
Epoch 7/10, Batch 60/97, Loss: 0.1717
Epoch 7/10, Batch 70/97, Loss: 0.3116
Epoch 7/10, Batch 80/97, Loss: 0.2327
Epoch 7/10, Batch 90/97, Loss: 0.2649
Epoch 7/10, Train Loss: 0.2218, Valid Loss: 0.2090
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1478
Epoch 8/10, Batch 20/97, Loss: 0.1854
Epoch 8/10, Batch 30/97, Loss: 0.1468
Epoch 8/10, Batch 40/97, Loss: 0.2268
Epoch 8/10, Batch 50/97, Loss: 0.2069
Epoch 8/10, Batch 60/97, Loss: 0.1718
Epoch 8/10, Batch 70/97, Loss: 0.1164
Epoch 8/10, Batch 80/97, Loss: 0.2796
Epoch 8/10, Batch 90/97, Loss: 0.2496
Epoch 8/10, Train Loss: 0.2203, Valid Loss: 0.2054
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1098
Epoch 9/10, Batch 20/97, Loss: 0.2189
Epoch 9/10, Batch 30/97, Loss: 0.1715
Epoch 9/10, Batch 40/97, Loss: 0.3327
Epoch 9/10, Batch 50/97, Loss: 0.2539
Epoch 9/10, Batch 60/97, Loss: 0.2658
Epoch 9/10, Batch 70/97, Loss: 0.1007
Epoch 9/10, Batch 80/97, Loss: 0.1281
Epoch 9/10, Batch 90/97, Loss: 0.1517
Epoch 9/10, Train Loss: 0.2032, Valid Loss: 0.1964
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1750
Epoch 10/10, Batch 20/97, Loss: 0.1891
Epoch 10/10, Batch 30/97, Loss: 0.1918
Epoch 10/10, Batch 40/97, Loss: 0.1264
Epoch 10/10, Batch 50/97, Loss: 0.2516
Epoch 10/10, Batch 60/97, Loss: 0.2372
Epoch 10/10, Batch 70/97, Loss: 0.3700
Epoch 10/10, Batch 80/97, Loss: 0.2134
Epoch 10/10, Batch 90/97, Loss: 0.2120
Epoch 10/10, Train Loss: 0.2094, Valid Loss: 0.1955
Model saved!
Accuracy: 0.9089
Precision: 0.9060
Recall: 0.9089
F1-score: 0.9064
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2695
Epoch 1/10, Batch 20/97, Loss: 1.0881
Epoch 1/10, Batch 30/97, Loss: 0.7929
Epoch 1/10, Batch 40/97, Loss: 0.7169
Epoch 1/10, Batch 50/97, Loss: 0.6993
Epoch 1/10, Batch 60/97, Loss: 0.6455
Epoch 1/10, Batch 70/97, Loss: 0.6630
Epoch 1/10, Batch 80/97, Loss: 0.5346
Epoch 1/10, Batch 90/97, Loss: 0.5752
Epoch 1/10, Train Loss: 0.7962, Valid Loss: 0.4432
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5872
Epoch 2/10, Batch 20/97, Loss: 0.3951
Epoch 2/10, Batch 30/97, Loss: 0.2739
Epoch 2/10, Batch 40/97, Loss: 0.3146
Epoch 2/10, Batch 50/97, Loss: 0.4155
Epoch 2/10, Batch 60/97, Loss: 0.4248
Epoch 2/10, Batch 70/97, Loss: 0.3453
Epoch 2/10, Batch 80/97, Loss: 0.2621
Epoch 2/10, Batch 90/97, Loss: 0.4455
Epoch 2/10, Train Loss: 0.4040, Valid Loss: 0.3313
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3364
Epoch 3/10, Batch 20/97, Loss: 0.2718
Epoch 3/10, Batch 30/97, Loss: 0.4005
Epoch 3/10, Batch 40/97, Loss: 0.2982
Epoch 3/10, Batch 50/97, Loss: 0.3466
Epoch 3/10, Batch 60/97, Loss: 0.2628
Epoch 3/10, Batch 70/97, Loss: 0.2534
Epoch 3/10, Batch 80/97, Loss: 0.3135
Epoch 3/10, Batch 90/97, Loss: 0.3409
Epoch 3/10, Train Loss: 0.3298, Valid Loss: 0.2941
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3713
Epoch 4/10, Batch 20/97, Loss: 0.2489
Epoch 4/10, Batch 30/97, Loss: 0.2322
Epoch 4/10, Batch 40/97, Loss: 0.1809
Epoch 4/10, Batch 50/97, Loss: 0.5153
Epoch 4/10, Batch 60/97, Loss: 0.2530
Epoch 4/10, Batch 70/97, Loss: 0.2164
Epoch 4/10, Batch 80/97, Loss: 0.2045
Epoch 4/10, Batch 90/97, Loss: 0.1932
Epoch 4/10, Train Loss: 0.2866, Valid Loss: 0.2790
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2814
Epoch 5/10, Batch 20/97, Loss: 0.3571
Epoch 5/10, Batch 30/97, Loss: 0.2669
Epoch 5/10, Batch 40/97, Loss: 0.2918
Epoch 5/10, Batch 50/97, Loss: 0.2498
Epoch 5/10, Batch 60/97, Loss: 0.3270
Epoch 5/10, Batch 70/97, Loss: 0.1624
Epoch 5/10, Batch 80/97, Loss: 0.1616
Epoch 5/10, Batch 90/97, Loss: 0.2745
Epoch 5/10, Train Loss: 0.2594, Valid Loss: 0.2614
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1694
Epoch 6/10, Batch 20/97, Loss: 0.2837
Epoch 6/10, Batch 30/97, Loss: 0.1562
Epoch 6/10, Batch 40/97, Loss: 0.1533
Epoch 6/10, Batch 50/97, Loss: 0.1628
Epoch 6/10, Batch 60/97, Loss: 0.2662
Epoch 6/10, Batch 70/97, Loss: 0.3564
Epoch 6/10, Batch 80/97, Loss: 0.4094
Epoch 6/10, Batch 90/97, Loss: 0.4089
Epoch 6/10, Train Loss: 0.2388, Valid Loss: 0.2499
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1859
Epoch 7/10, Batch 20/97, Loss: 0.2474
Epoch 7/10, Batch 30/97, Loss: 0.1741
Epoch 7/10, Batch 40/97, Loss: 0.2254
Epoch 7/10, Batch 50/97, Loss: 0.2620
Epoch 7/10, Batch 60/97, Loss: 0.1210
Epoch 7/10, Batch 70/97, Loss: 0.3359
Epoch 7/10, Batch 80/97, Loss: 0.4171
Epoch 7/10, Batch 90/97, Loss: 0.1781
Epoch 7/10, Train Loss: 0.2225, Valid Loss: 0.2456
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1337
Epoch 8/10, Batch 20/97, Loss: 0.1542
Epoch 8/10, Batch 30/97, Loss: 0.1897
Epoch 8/10, Batch 40/97, Loss: 0.2153
Epoch 8/10, Batch 50/97, Loss: 0.2108
Epoch 8/10, Batch 60/97, Loss: 0.1830
Epoch 8/10, Batch 70/97, Loss: 0.1385
Epoch 8/10, Batch 80/97, Loss: 0.1722
Epoch 8/10, Batch 90/97, Loss: 0.2126
Epoch 8/10, Train Loss: 0.2186, Valid Loss: 0.2406
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2174
Epoch 9/10, Batch 20/97, Loss: 0.1185
Epoch 9/10, Batch 30/97, Loss: 0.3254
Epoch 9/10, Batch 40/97, Loss: 0.1860
Epoch 9/10, Batch 50/97, Loss: 0.1732
Epoch 9/10, Batch 60/97, Loss: 0.3739
Epoch 9/10, Batch 70/97, Loss: 0.1088
Epoch 9/10, Batch 80/97, Loss: 0.1284
Epoch 9/10, Batch 90/97, Loss: 0.0881
Epoch 9/10, Train Loss: 0.2021, Valid Loss: 0.2371
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1593
Epoch 10/10, Batch 20/97, Loss: 0.2794
Epoch 10/10, Batch 30/97, Loss: 0.2259
Epoch 10/10, Batch 40/97, Loss: 0.1199
Epoch 10/10, Batch 50/97, Loss: 0.4188
Epoch 10/10, Batch 60/97, Loss: 0.1167
Epoch 10/10, Batch 70/97, Loss: 0.2009
Epoch 10/10, Batch 80/97, Loss: 0.2086
Epoch 10/10, Batch 90/97, Loss: 0.1250
Epoch 10/10, Train Loss: 0.1977, Valid Loss: 0.2517
Accuracy: 0.9136
Precision: 0.9116
Recall: 0.9136
F1-score: 0.9119
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2366
Epoch 1/10, Batch 20/97, Loss: 1.0612
Epoch 1/10, Batch 30/97, Loss: 0.7559
Epoch 1/10, Batch 40/97, Loss: 0.7692
Epoch 1/10, Batch 50/97, Loss: 0.5734
Epoch 1/10, Batch 60/97, Loss: 0.6991
Epoch 1/10, Batch 70/97, Loss: 0.6630
Epoch 1/10, Batch 80/97, Loss: 0.6914
Epoch 1/10, Batch 90/97, Loss: 0.5296
Epoch 1/10, Train Loss: 0.8120, Valid Loss: 0.4460
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5877
Epoch 2/10, Batch 20/97, Loss: 0.4561
Epoch 2/10, Batch 30/97, Loss: 0.3995
Epoch 2/10, Batch 40/97, Loss: 0.5160
Epoch 2/10, Batch 50/97, Loss: 0.4084
Epoch 2/10, Batch 60/97, Loss: 0.4410
Epoch 2/10, Batch 70/97, Loss: 0.2731
Epoch 2/10, Batch 80/97, Loss: 0.4527
Epoch 2/10, Batch 90/97, Loss: 0.3535
Epoch 2/10, Train Loss: 0.4129, Valid Loss: 0.3236
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2952
Epoch 3/10, Batch 20/97, Loss: 0.3473
Epoch 3/10, Batch 30/97, Loss: 0.3380
Epoch 3/10, Batch 40/97, Loss: 0.1589
Epoch 3/10, Batch 50/97, Loss: 0.4231
Epoch 3/10, Batch 60/97, Loss: 0.2635
Epoch 3/10, Batch 70/97, Loss: 0.3035
Epoch 3/10, Batch 80/97, Loss: 0.2813
Epoch 3/10, Batch 90/97, Loss: 0.3877
Epoch 3/10, Train Loss: 0.3389, Valid Loss: 0.2773
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4570
Epoch 4/10, Batch 20/97, Loss: 0.2002
Epoch 4/10, Batch 30/97, Loss: 0.3132
Epoch 4/10, Batch 40/97, Loss: 0.1733
Epoch 4/10, Batch 50/97, Loss: 0.4038
Epoch 4/10, Batch 60/97, Loss: 0.1755
Epoch 4/10, Batch 70/97, Loss: 0.3988
Epoch 4/10, Batch 80/97, Loss: 0.3224
Epoch 4/10, Batch 90/97, Loss: 0.1792
Epoch 4/10, Train Loss: 0.2900, Valid Loss: 0.2594
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2542
Epoch 5/10, Batch 20/97, Loss: 0.3588
Epoch 5/10, Batch 30/97, Loss: 0.2693
Epoch 5/10, Batch 40/97, Loss: 0.2228
Epoch 5/10, Batch 50/97, Loss: 0.2998
Epoch 5/10, Batch 60/97, Loss: 0.1645
Epoch 5/10, Batch 70/97, Loss: 0.1644
Epoch 5/10, Batch 80/97, Loss: 0.2462
Epoch 5/10, Batch 90/97, Loss: 0.2179
Epoch 5/10, Train Loss: 0.2682, Valid Loss: 0.2457
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3148
Epoch 6/10, Batch 20/97, Loss: 0.5070
Epoch 6/10, Batch 30/97, Loss: 0.2337
Epoch 6/10, Batch 40/97, Loss: 0.1517
Epoch 6/10, Batch 50/97, Loss: 0.3101
Epoch 6/10, Batch 60/97, Loss: 0.3226
Epoch 6/10, Batch 70/97, Loss: 0.1935
Epoch 6/10, Batch 80/97, Loss: 0.2205
Epoch 6/10, Batch 90/97, Loss: 0.2143
Epoch 6/10, Train Loss: 0.2425, Valid Loss: 0.2289
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1624
Epoch 7/10, Batch 20/97, Loss: 0.3347
Epoch 7/10, Batch 30/97, Loss: 0.2167
Epoch 7/10, Batch 40/97, Loss: 0.1242
Epoch 7/10, Batch 50/97, Loss: 0.1258
Epoch 7/10, Batch 60/97, Loss: 0.2540
Epoch 7/10, Batch 70/97, Loss: 0.2175
Epoch 7/10, Batch 80/97, Loss: 0.2040
Epoch 7/10, Batch 90/97, Loss: 0.3138
Epoch 7/10, Train Loss: 0.2334, Valid Loss: 0.2244
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1670
Epoch 8/10, Batch 20/97, Loss: 0.3018
Epoch 8/10, Batch 30/97, Loss: 0.1861
Epoch 8/10, Batch 40/97, Loss: 0.1569
Epoch 8/10, Batch 50/97, Loss: 0.1992
Epoch 8/10, Batch 60/97, Loss: 0.1936
Epoch 8/10, Batch 70/97, Loss: 0.2785
Epoch 8/10, Batch 80/97, Loss: 0.1161
Epoch 8/10, Batch 90/97, Loss: 0.2974
Epoch 8/10, Train Loss: 0.2255, Valid Loss: 0.2230
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1743
Epoch 9/10, Batch 20/97, Loss: 0.1888
Epoch 9/10, Batch 30/97, Loss: 0.1819
Epoch 9/10, Batch 40/97, Loss: 0.3329
Epoch 9/10, Batch 50/97, Loss: 0.1622
Epoch 9/10, Batch 60/97, Loss: 0.1599
Epoch 9/10, Batch 70/97, Loss: 0.1110
Epoch 9/10, Batch 80/97, Loss: 0.0915
Epoch 9/10, Batch 90/97, Loss: 0.2040
Epoch 9/10, Train Loss: 0.2154, Valid Loss: 0.2214
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2762
Epoch 10/10, Batch 20/97, Loss: 0.1317
Epoch 10/10, Batch 30/97, Loss: 0.1503
Epoch 10/10, Batch 40/97, Loss: 0.1560
Epoch 10/10, Batch 50/97, Loss: 0.1123
Epoch 10/10, Batch 60/97, Loss: 0.1618
Epoch 10/10, Batch 70/97, Loss: 0.3023
Epoch 10/10, Batch 80/97, Loss: 0.2202
Epoch 10/10, Batch 90/97, Loss: 0.0996
Epoch 10/10, Train Loss: 0.2024, Valid Loss: 0.2091
Model saved!
Accuracy: 0.9147
Precision: 0.9131
Recall: 0.9147
F1-score: 0.9132
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2032
Epoch 1/10, Batch 20/97, Loss: 1.0392
Epoch 1/10, Batch 30/97, Loss: 0.7895
Epoch 1/10, Batch 40/97, Loss: 0.7698
Epoch 1/10, Batch 50/97, Loss: 0.8222
Epoch 1/10, Batch 60/97, Loss: 0.8433
Epoch 1/10, Batch 70/97, Loss: 0.6192
Epoch 1/10, Batch 80/97, Loss: 0.6355
Epoch 1/10, Batch 90/97, Loss: 0.4803
Epoch 1/10, Train Loss: 0.8046, Valid Loss: 0.4487
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5474
Epoch 2/10, Batch 20/97, Loss: 0.5134
Epoch 2/10, Batch 30/97, Loss: 0.2927
Epoch 2/10, Batch 40/97, Loss: 0.3068
Epoch 2/10, Batch 50/97, Loss: 0.3687
Epoch 2/10, Batch 60/97, Loss: 0.4379
Epoch 2/10, Batch 70/97, Loss: 0.3776
Epoch 2/10, Batch 80/97, Loss: 0.2782
Epoch 2/10, Batch 90/97, Loss: 0.3983
Epoch 2/10, Train Loss: 0.4169, Valid Loss: 0.3471
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4967
Epoch 3/10, Batch 20/97, Loss: 0.3591
Epoch 3/10, Batch 30/97, Loss: 0.3381
Epoch 3/10, Batch 40/97, Loss: 0.2401
Epoch 3/10, Batch 50/97, Loss: 0.2508
Epoch 3/10, Batch 60/97, Loss: 0.1645
Epoch 3/10, Batch 70/97, Loss: 0.3255
Epoch 3/10, Batch 80/97, Loss: 0.2700
Epoch 3/10, Batch 90/97, Loss: 0.2249
Epoch 3/10, Train Loss: 0.3380, Valid Loss: 0.2997
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4035
Epoch 4/10, Batch 20/97, Loss: 0.2386
Epoch 4/10, Batch 30/97, Loss: 0.2050
Epoch 4/10, Batch 40/97, Loss: 0.2999
Epoch 4/10, Batch 50/97, Loss: 0.2985
Epoch 4/10, Batch 60/97, Loss: 0.1949
Epoch 4/10, Batch 70/97, Loss: 0.4217
Epoch 4/10, Batch 80/97, Loss: 0.2022
Epoch 4/10, Batch 90/97, Loss: 0.1741
Epoch 4/10, Train Loss: 0.2875, Valid Loss: 0.2814
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3050
Epoch 5/10, Batch 20/97, Loss: 0.1728
Epoch 5/10, Batch 30/97, Loss: 0.2441
Epoch 5/10, Batch 40/97, Loss: 0.2569
Epoch 5/10, Batch 50/97, Loss: 0.1726
Epoch 5/10, Batch 60/97, Loss: 0.2015
Epoch 5/10, Batch 70/97, Loss: 0.2387
Epoch 5/10, Batch 80/97, Loss: 0.2005
Epoch 5/10, Batch 90/97, Loss: 0.1762
Epoch 5/10, Train Loss: 0.2675, Valid Loss: 0.2564
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2593
Epoch 6/10, Batch 20/97, Loss: 0.4583
Epoch 6/10, Batch 30/97, Loss: 0.2478
Epoch 6/10, Batch 40/97, Loss: 0.1632
Epoch 6/10, Batch 50/97, Loss: 0.1771
Epoch 6/10, Batch 60/97, Loss: 0.4024
Epoch 6/10, Batch 70/97, Loss: 0.2208
Epoch 6/10, Batch 80/97, Loss: 0.2503
Epoch 6/10, Batch 90/97, Loss: 0.2325
Epoch 6/10, Train Loss: 0.2481, Valid Loss: 0.2491
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1472
Epoch 7/10, Batch 20/97, Loss: 0.2474
Epoch 7/10, Batch 30/97, Loss: 0.1999
Epoch 7/10, Batch 40/97, Loss: 0.1593
Epoch 7/10, Batch 50/97, Loss: 0.2804
Epoch 7/10, Batch 60/97, Loss: 0.1531
Epoch 7/10, Batch 70/97, Loss: 0.1390
Epoch 7/10, Batch 80/97, Loss: 0.1520
Epoch 7/10, Batch 90/97, Loss: 0.2894
Epoch 7/10, Train Loss: 0.2276, Valid Loss: 0.2427
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1049
Epoch 8/10, Batch 20/97, Loss: 0.2221
Epoch 8/10, Batch 30/97, Loss: 0.2584
Epoch 8/10, Batch 40/97, Loss: 0.1688
Epoch 8/10, Batch 50/97, Loss: 0.1317
Epoch 8/10, Batch 60/97, Loss: 0.2125
Epoch 8/10, Batch 70/97, Loss: 0.2886
Epoch 8/10, Batch 80/97, Loss: 0.1615
Epoch 8/10, Batch 90/97, Loss: 0.1543
Epoch 8/10, Train Loss: 0.2252, Valid Loss: 0.2347
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1296
Epoch 9/10, Batch 20/97, Loss: 0.0920
Epoch 9/10, Batch 30/97, Loss: 0.4130
Epoch 9/10, Batch 40/97, Loss: 0.3148
Epoch 9/10, Batch 50/97, Loss: 0.2377
Epoch 9/10, Batch 60/97, Loss: 0.1755
Epoch 9/10, Batch 70/97, Loss: 0.1762
Epoch 9/10, Batch 80/97, Loss: 0.1205
Epoch 9/10, Batch 90/97, Loss: 0.4535
Epoch 9/10, Train Loss: 0.2102, Valid Loss: 0.2239
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2756
Epoch 10/10, Batch 20/97, Loss: 0.2845
Epoch 10/10, Batch 30/97, Loss: 0.2229
Epoch 10/10, Batch 40/97, Loss: 0.1938
Epoch 10/10, Batch 50/97, Loss: 0.1651
Epoch 10/10, Batch 60/97, Loss: 0.2348
Epoch 10/10, Batch 70/97, Loss: 0.2383
Epoch 10/10, Batch 80/97, Loss: 0.1646
Epoch 10/10, Batch 90/97, Loss: 0.1864
Epoch 10/10, Train Loss: 0.2073, Valid Loss: 0.2322
Accuracy: 0.9194
Precision: 0.9175
Recall: 0.9194
F1-score: 0.9180
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2367
Epoch 1/10, Batch 20/97, Loss: 1.2017
Epoch 1/10, Batch 30/97, Loss: 0.8142
Epoch 1/10, Batch 40/97, Loss: 0.7491
Epoch 1/10, Batch 50/97, Loss: 0.6049
Epoch 1/10, Batch 60/97, Loss: 0.5990
Epoch 1/10, Batch 70/97, Loss: 0.8181
Epoch 1/10, Batch 80/97, Loss: 0.5421
Epoch 1/10, Batch 90/97, Loss: 0.6260
Epoch 1/10, Train Loss: 0.8147, Valid Loss: 0.4500
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5072
Epoch 2/10, Batch 20/97, Loss: 0.5035
Epoch 2/10, Batch 30/97, Loss: 0.3619
Epoch 2/10, Batch 40/97, Loss: 0.4507
Epoch 2/10, Batch 50/97, Loss: 0.3176
Epoch 2/10, Batch 60/97, Loss: 0.4531
Epoch 2/10, Batch 70/97, Loss: 0.3423
Epoch 2/10, Batch 80/97, Loss: 0.4198
Epoch 2/10, Batch 90/97, Loss: 0.3314
Epoch 2/10, Train Loss: 0.4156, Valid Loss: 0.3502
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3088
Epoch 3/10, Batch 20/97, Loss: 0.4455
Epoch 3/10, Batch 30/97, Loss: 0.3012
Epoch 3/10, Batch 40/97, Loss: 0.2514
Epoch 3/10, Batch 50/97, Loss: 0.4132
Epoch 3/10, Batch 60/97, Loss: 0.3415
Epoch 3/10, Batch 70/97, Loss: 0.2962
Epoch 3/10, Batch 80/97, Loss: 0.3579
Epoch 3/10, Batch 90/97, Loss: 0.2935
Epoch 3/10, Train Loss: 0.3310, Valid Loss: 0.3123
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3589
Epoch 4/10, Batch 20/97, Loss: 0.2882
Epoch 4/10, Batch 30/97, Loss: 0.2093
Epoch 4/10, Batch 40/97, Loss: 0.1580
Epoch 4/10, Batch 50/97, Loss: 0.3271
Epoch 4/10, Batch 60/97, Loss: 0.2227
Epoch 4/10, Batch 70/97, Loss: 0.2336
Epoch 4/10, Batch 80/97, Loss: 0.2590
Epoch 4/10, Batch 90/97, Loss: 0.2560
Epoch 4/10, Train Loss: 0.2860, Valid Loss: 0.2904
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2590
Epoch 5/10, Batch 20/97, Loss: 0.3169
Epoch 5/10, Batch 30/97, Loss: 0.1919
Epoch 5/10, Batch 40/97, Loss: 0.2190
Epoch 5/10, Batch 50/97, Loss: 0.2756
Epoch 5/10, Batch 60/97, Loss: 0.4197
Epoch 5/10, Batch 70/97, Loss: 0.2274
Epoch 5/10, Batch 80/97, Loss: 0.1541
Epoch 5/10, Batch 90/97, Loss: 0.3070
Epoch 5/10, Train Loss: 0.2674, Valid Loss: 0.2835
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2517
Epoch 6/10, Batch 20/97, Loss: 0.3977
Epoch 6/10, Batch 30/97, Loss: 0.1637
Epoch 6/10, Batch 40/97, Loss: 0.1470
Epoch 6/10, Batch 50/97, Loss: 0.2833
Epoch 6/10, Batch 60/97, Loss: 0.2794
Epoch 6/10, Batch 70/97, Loss: 0.1823
Epoch 6/10, Batch 80/97, Loss: 0.2485
Epoch 6/10, Batch 90/97, Loss: 0.2789
Epoch 6/10, Train Loss: 0.2463, Valid Loss: 0.2662
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1362
Epoch 7/10, Batch 20/97, Loss: 0.2696
Epoch 7/10, Batch 30/97, Loss: 0.2414
Epoch 7/10, Batch 40/97, Loss: 0.1773
Epoch 7/10, Batch 50/97, Loss: 0.2148
Epoch 7/10, Batch 60/97, Loss: 0.1562
Epoch 7/10, Batch 70/97, Loss: 0.4071
Epoch 7/10, Batch 80/97, Loss: 0.2966
Epoch 7/10, Batch 90/97, Loss: 0.2027
Epoch 7/10, Train Loss: 0.2247, Valid Loss: 0.2578
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1625
Epoch 8/10, Batch 20/97, Loss: 0.1552
Epoch 8/10, Batch 30/97, Loss: 0.3383
Epoch 8/10, Batch 40/97, Loss: 0.3107
Epoch 8/10, Batch 50/97, Loss: 0.2176
Epoch 8/10, Batch 60/97, Loss: 0.1967
Epoch 8/10, Batch 70/97, Loss: 0.1610
Epoch 8/10, Batch 80/97, Loss: 0.1294
Epoch 8/10, Batch 90/97, Loss: 0.1220
Epoch 8/10, Train Loss: 0.2188, Valid Loss: 0.2563
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1413
Epoch 9/10, Batch 20/97, Loss: 0.1509
Epoch 9/10, Batch 30/97, Loss: 0.2730
Epoch 9/10, Batch 40/97, Loss: 0.2363
Epoch 9/10, Batch 50/97, Loss: 0.2527
Epoch 9/10, Batch 60/97, Loss: 0.1830
Epoch 9/10, Batch 70/97, Loss: 0.1616
Epoch 9/10, Batch 80/97, Loss: 0.3312
Epoch 9/10, Batch 90/97, Loss: 0.2142
Epoch 9/10, Train Loss: 0.1991, Valid Loss: 0.2538
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2644
Epoch 10/10, Batch 20/97, Loss: 0.2083
Epoch 10/10, Batch 30/97, Loss: 0.2179
Epoch 10/10, Batch 40/97, Loss: 0.1201
Epoch 10/10, Batch 50/97, Loss: 0.1453
Epoch 10/10, Batch 60/97, Loss: 0.1268
Epoch 10/10, Batch 70/97, Loss: 0.1294
Epoch 10/10, Batch 80/97, Loss: 0.1745
Epoch 10/10, Batch 90/97, Loss: 0.1562
Epoch 10/10, Train Loss: 0.1983, Valid Loss: 0.2530
Model saved!
Accuracy: 0.9182
Precision: 0.9156
Recall: 0.9182
F1-score: 0.9158
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2393
Epoch 1/10, Batch 20/97, Loss: 1.1304
Epoch 1/10, Batch 30/97, Loss: 0.8148
Epoch 1/10, Batch 40/97, Loss: 0.7816
Epoch 1/10, Batch 50/97, Loss: 0.5177
Epoch 1/10, Batch 60/97, Loss: 0.7740
Epoch 1/10, Batch 70/97, Loss: 0.6204
Epoch 1/10, Batch 80/97, Loss: 0.5647
Epoch 1/10, Batch 90/97, Loss: 0.4964
Epoch 1/10, Train Loss: 0.7965, Valid Loss: 0.4440
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4978
Epoch 2/10, Batch 20/97, Loss: 0.4147
Epoch 2/10, Batch 30/97, Loss: 0.3711
Epoch 2/10, Batch 40/97, Loss: 0.3206
Epoch 2/10, Batch 50/97, Loss: 0.3801
Epoch 2/10, Batch 60/97, Loss: 0.3434
Epoch 2/10, Batch 70/97, Loss: 0.4395
Epoch 2/10, Batch 80/97, Loss: 0.3172
Epoch 2/10, Batch 90/97, Loss: 0.3224
Epoch 2/10, Train Loss: 0.4096, Valid Loss: 0.3369
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2727
Epoch 3/10, Batch 20/97, Loss: 0.4203
Epoch 3/10, Batch 30/97, Loss: 0.2941
Epoch 3/10, Batch 40/97, Loss: 0.2800
Epoch 3/10, Batch 50/97, Loss: 0.4469
Epoch 3/10, Batch 60/97, Loss: 0.2849
Epoch 3/10, Batch 70/97, Loss: 0.3650
Epoch 3/10, Batch 80/97, Loss: 0.3223
Epoch 3/10, Batch 90/97, Loss: 0.3085
Epoch 3/10, Train Loss: 0.3327, Valid Loss: 0.2992
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3011
Epoch 4/10, Batch 20/97, Loss: 0.2093
Epoch 4/10, Batch 30/97, Loss: 0.2154
Epoch 4/10, Batch 40/97, Loss: 0.2897
Epoch 4/10, Batch 50/97, Loss: 0.3218
Epoch 4/10, Batch 60/97, Loss: 0.3087
Epoch 4/10, Batch 70/97, Loss: 0.3156
Epoch 4/10, Batch 80/97, Loss: 0.4559
Epoch 4/10, Batch 90/97, Loss: 0.1917
Epoch 4/10, Train Loss: 0.2792, Valid Loss: 0.2816
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2109
Epoch 5/10, Batch 20/97, Loss: 0.2680
Epoch 5/10, Batch 30/97, Loss: 0.3124
Epoch 5/10, Batch 40/97, Loss: 0.3078
Epoch 5/10, Batch 50/97, Loss: 0.3184
Epoch 5/10, Batch 60/97, Loss: 0.1889
Epoch 5/10, Batch 70/97, Loss: 0.2408
Epoch 5/10, Batch 80/97, Loss: 0.2916
Epoch 5/10, Batch 90/97, Loss: 0.1767
Epoch 5/10, Train Loss: 0.2684, Valid Loss: 0.2740
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1708
Epoch 6/10, Batch 20/97, Loss: 0.3817
Epoch 6/10, Batch 30/97, Loss: 0.1958
Epoch 6/10, Batch 40/97, Loss: 0.2726
Epoch 6/10, Batch 50/97, Loss: 0.1959
Epoch 6/10, Batch 60/97, Loss: 0.2851
Epoch 6/10, Batch 70/97, Loss: 0.1920
Epoch 6/10, Batch 80/97, Loss: 0.3627
Epoch 6/10, Batch 90/97, Loss: 0.3050
Epoch 6/10, Train Loss: 0.2424, Valid Loss: 0.2552
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3387
Epoch 7/10, Batch 20/97, Loss: 0.2493
Epoch 7/10, Batch 30/97, Loss: 0.2280
Epoch 7/10, Batch 40/97, Loss: 0.1223
Epoch 7/10, Batch 50/97, Loss: 0.2333
Epoch 7/10, Batch 60/97, Loss: 0.1778
Epoch 7/10, Batch 70/97, Loss: 0.3658
Epoch 7/10, Batch 80/97, Loss: 0.2451
Epoch 7/10, Batch 90/97, Loss: 0.2051
Epoch 7/10, Train Loss: 0.2216, Valid Loss: 0.2531
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.0969
Epoch 8/10, Batch 20/97, Loss: 0.2880
Epoch 8/10, Batch 30/97, Loss: 0.1374
Epoch 8/10, Batch 40/97, Loss: 0.2189
Epoch 8/10, Batch 50/97, Loss: 0.2691
Epoch 8/10, Batch 60/97, Loss: 0.2327
Epoch 8/10, Batch 70/97, Loss: 0.4315
Epoch 8/10, Batch 80/97, Loss: 0.1955
Epoch 8/10, Batch 90/97, Loss: 0.2949
Epoch 8/10, Train Loss: 0.2169, Valid Loss: 0.2507
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1531
Epoch 9/10, Batch 20/97, Loss: 0.2884
Epoch 9/10, Batch 30/97, Loss: 0.2873
Epoch 9/10, Batch 40/97, Loss: 0.2166
Epoch 9/10, Batch 50/97, Loss: 0.1672
Epoch 9/10, Batch 60/97, Loss: 0.2304
Epoch 9/10, Batch 70/97, Loss: 0.1773
Epoch 9/10, Batch 80/97, Loss: 0.2028
Epoch 9/10, Batch 90/97, Loss: 0.2035
Epoch 9/10, Train Loss: 0.1941, Valid Loss: 0.2464
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3693
Epoch 10/10, Batch 20/97, Loss: 0.2658
Epoch 10/10, Batch 30/97, Loss: 0.2079
Epoch 10/10, Batch 40/97, Loss: 0.2068
Epoch 10/10, Batch 50/97, Loss: 0.1690
Epoch 10/10, Batch 60/97, Loss: 0.1242
Epoch 10/10, Batch 70/97, Loss: 0.2075
Epoch 10/10, Batch 80/97, Loss: 0.1703
Epoch 10/10, Batch 90/97, Loss: 0.1623
Epoch 10/10, Train Loss: 0.2089, Valid Loss: 0.2462
Model saved!
Accuracy: 0.9124
Precision: 0.9093
Recall: 0.9124
F1-score: 0.9100
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2765
Epoch 1/10, Batch 20/97, Loss: 1.0707
Epoch 1/10, Batch 30/97, Loss: 0.7731
Epoch 1/10, Batch 40/97, Loss: 0.7311
Epoch 1/10, Batch 50/97, Loss: 0.6488
Epoch 1/10, Batch 60/97, Loss: 0.6970
Epoch 1/10, Batch 70/97, Loss: 0.7780
Epoch 1/10, Batch 80/97, Loss: 0.6832
Epoch 1/10, Batch 90/97, Loss: 0.4788
Epoch 1/10, Train Loss: 0.8128, Valid Loss: 0.4372
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5325
Epoch 2/10, Batch 20/97, Loss: 0.4139
Epoch 2/10, Batch 30/97, Loss: 0.6379
Epoch 2/10, Batch 40/97, Loss: 0.4273
Epoch 2/10, Batch 50/97, Loss: 0.4900
Epoch 2/10, Batch 60/97, Loss: 0.4512
Epoch 2/10, Batch 70/97, Loss: 0.3921
Epoch 2/10, Batch 80/97, Loss: 0.3379
Epoch 2/10, Batch 90/97, Loss: 0.6000
Epoch 2/10, Train Loss: 0.4146, Valid Loss: 0.3248
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2884
Epoch 3/10, Batch 20/97, Loss: 0.3822
Epoch 3/10, Batch 30/97, Loss: 0.5628
Epoch 3/10, Batch 40/97, Loss: 0.2615
Epoch 3/10, Batch 50/97, Loss: 0.4293
Epoch 3/10, Batch 60/97, Loss: 0.2831
Epoch 3/10, Batch 70/97, Loss: 0.4371
Epoch 3/10, Batch 80/97, Loss: 0.2868
Epoch 3/10, Batch 90/97, Loss: 0.3227
Epoch 3/10, Train Loss: 0.3423, Valid Loss: 0.2877
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2622
Epoch 4/10, Batch 20/97, Loss: 0.1723
Epoch 4/10, Batch 30/97, Loss: 0.3004
Epoch 4/10, Batch 40/97, Loss: 0.2688
Epoch 4/10, Batch 50/97, Loss: 0.3656
Epoch 4/10, Batch 60/97, Loss: 0.2976
Epoch 4/10, Batch 70/97, Loss: 0.2237
Epoch 4/10, Batch 80/97, Loss: 0.2858
Epoch 4/10, Batch 90/97, Loss: 0.2698
Epoch 4/10, Train Loss: 0.2967, Valid Loss: 0.2625
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1299
Epoch 5/10, Batch 20/97, Loss: 0.3182
Epoch 5/10, Batch 30/97, Loss: 0.0950
Epoch 5/10, Batch 40/97, Loss: 0.2289
Epoch 5/10, Batch 50/97, Loss: 0.4423
Epoch 5/10, Batch 60/97, Loss: 0.4729
Epoch 5/10, Batch 70/97, Loss: 0.2240
Epoch 5/10, Batch 80/97, Loss: 0.3157
Epoch 5/10, Batch 90/97, Loss: 0.2792
Epoch 5/10, Train Loss: 0.2714, Valid Loss: 0.2433
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1533
Epoch 6/10, Batch 20/97, Loss: 0.2946
Epoch 6/10, Batch 30/97, Loss: 0.3377
Epoch 6/10, Batch 40/97, Loss: 0.2366
Epoch 6/10, Batch 50/97, Loss: 0.2791
Epoch 6/10, Batch 60/97, Loss: 0.2280
Epoch 6/10, Batch 70/97, Loss: 0.2862
Epoch 6/10, Batch 80/97, Loss: 0.3019
Epoch 6/10, Batch 90/97, Loss: 0.3977
Epoch 6/10, Train Loss: 0.2532, Valid Loss: 0.2305
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3833
Epoch 7/10, Batch 20/97, Loss: 0.0914
Epoch 7/10, Batch 30/97, Loss: 0.1889
Epoch 7/10, Batch 40/97, Loss: 0.2083
Epoch 7/10, Batch 50/97, Loss: 0.1708
Epoch 7/10, Batch 60/97, Loss: 0.2468
Epoch 7/10, Batch 70/97, Loss: 0.1985
Epoch 7/10, Batch 80/97, Loss: 0.1763
Epoch 7/10, Batch 90/97, Loss: 0.2507
Epoch 7/10, Train Loss: 0.2319, Valid Loss: 0.2270
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1555
Epoch 8/10, Batch 20/97, Loss: 0.3221
Epoch 8/10, Batch 30/97, Loss: 0.1748
Epoch 8/10, Batch 40/97, Loss: 0.1800
Epoch 8/10, Batch 50/97, Loss: 0.1142
Epoch 8/10, Batch 60/97, Loss: 0.2382
Epoch 8/10, Batch 70/97, Loss: 0.1924
Epoch 8/10, Batch 80/97, Loss: 0.1645
Epoch 8/10, Batch 90/97, Loss: 0.1981
Epoch 8/10, Train Loss: 0.2211, Valid Loss: 0.2270
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1089
Epoch 9/10, Batch 20/97, Loss: 0.1131
Epoch 9/10, Batch 30/97, Loss: 0.3765
Epoch 9/10, Batch 40/97, Loss: 0.2653
Epoch 9/10, Batch 50/97, Loss: 0.1726
Epoch 9/10, Batch 60/97, Loss: 0.2457
Epoch 9/10, Batch 70/97, Loss: 0.2887
Epoch 9/10, Batch 80/97, Loss: 0.2328
Epoch 9/10, Batch 90/97, Loss: 0.1042
Epoch 9/10, Train Loss: 0.2148, Valid Loss: 0.2159
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2513
Epoch 10/10, Batch 20/97, Loss: 0.2104
Epoch 10/10, Batch 30/97, Loss: 0.2654
Epoch 10/10, Batch 40/97, Loss: 0.0855
Epoch 10/10, Batch 50/97, Loss: 0.1818
Epoch 10/10, Batch 60/97, Loss: 0.1719
Epoch 10/10, Batch 70/97, Loss: 0.2908
Epoch 10/10, Batch 80/97, Loss: 0.1956
Epoch 10/10, Batch 90/97, Loss: 0.2283
Epoch 10/10, Train Loss: 0.2044, Valid Loss: 0.2124
Model saved!
Accuracy: 0.9217
Precision: 0.9192
Recall: 0.9217
F1-score: 0.9196
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.3144
Epoch 1/10, Batch 20/97, Loss: 1.0989
Epoch 1/10, Batch 30/97, Loss: 0.7455
Epoch 1/10, Batch 40/97, Loss: 0.6821
Epoch 1/10, Batch 50/97, Loss: 0.6733
Epoch 1/10, Batch 60/97, Loss: 0.7361
Epoch 1/10, Batch 70/97, Loss: 0.7265
Epoch 1/10, Batch 80/97, Loss: 0.5503
Epoch 1/10, Batch 90/97, Loss: 0.5492
Epoch 1/10, Train Loss: 0.8118, Valid Loss: 0.4367
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6086
Epoch 2/10, Batch 20/97, Loss: 0.5109
Epoch 2/10, Batch 30/97, Loss: 0.4241
Epoch 2/10, Batch 40/97, Loss: 0.4445
Epoch 2/10, Batch 50/97, Loss: 0.3991
Epoch 2/10, Batch 60/97, Loss: 0.4341
Epoch 2/10, Batch 70/97, Loss: 0.3143
Epoch 2/10, Batch 80/97, Loss: 0.3801
Epoch 2/10, Batch 90/97, Loss: 0.2470
Epoch 2/10, Train Loss: 0.4177, Valid Loss: 0.3236
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2816
Epoch 3/10, Batch 20/97, Loss: 0.4428
Epoch 3/10, Batch 30/97, Loss: 0.4292
Epoch 3/10, Batch 40/97, Loss: 0.1935
Epoch 3/10, Batch 50/97, Loss: 0.3092
Epoch 3/10, Batch 60/97, Loss: 0.2284
Epoch 3/10, Batch 70/97, Loss: 0.3936
Epoch 3/10, Batch 80/97, Loss: 0.3838
Epoch 3/10, Batch 90/97, Loss: 0.3528
Epoch 3/10, Train Loss: 0.3392, Valid Loss: 0.2866
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2754
Epoch 4/10, Batch 20/97, Loss: 0.1696
Epoch 4/10, Batch 30/97, Loss: 0.2981
Epoch 4/10, Batch 40/97, Loss: 0.2248
Epoch 4/10, Batch 50/97, Loss: 0.3475
Epoch 4/10, Batch 60/97, Loss: 0.2982
Epoch 4/10, Batch 70/97, Loss: 0.2938
Epoch 4/10, Batch 80/97, Loss: 0.1489
Epoch 4/10, Batch 90/97, Loss: 0.1885
Epoch 4/10, Train Loss: 0.2901, Valid Loss: 0.2648
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1517
Epoch 5/10, Batch 20/97, Loss: 0.4126
Epoch 5/10, Batch 30/97, Loss: 0.1375
Epoch 5/10, Batch 40/97, Loss: 0.1678
Epoch 5/10, Batch 50/97, Loss: 0.2785
Epoch 5/10, Batch 60/97, Loss: 0.2680
Epoch 5/10, Batch 70/97, Loss: 0.3059
Epoch 5/10, Batch 80/97, Loss: 0.3193
Epoch 5/10, Batch 90/97, Loss: 0.2709
Epoch 5/10, Train Loss: 0.2705, Valid Loss: 0.2474
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1493
Epoch 6/10, Batch 20/97, Loss: 0.3720
Epoch 6/10, Batch 30/97, Loss: 0.1501
Epoch 6/10, Batch 40/97, Loss: 0.1453
Epoch 6/10, Batch 50/97, Loss: 0.2576
Epoch 6/10, Batch 60/97, Loss: 0.3118
Epoch 6/10, Batch 70/97, Loss: 0.3197
Epoch 6/10, Batch 80/97, Loss: 0.3411
Epoch 6/10, Batch 90/97, Loss: 0.3669
Epoch 6/10, Train Loss: 0.2515, Valid Loss: 0.2396
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2466
Epoch 7/10, Batch 20/97, Loss: 0.2147
Epoch 7/10, Batch 30/97, Loss: 0.1014
Epoch 7/10, Batch 40/97, Loss: 0.1692
Epoch 7/10, Batch 50/97, Loss: 0.2242
Epoch 7/10, Batch 60/97, Loss: 0.2174
Epoch 7/10, Batch 70/97, Loss: 0.2439
Epoch 7/10, Batch 80/97, Loss: 0.2240
Epoch 7/10, Batch 90/97, Loss: 0.2482
Epoch 7/10, Train Loss: 0.2304, Valid Loss: 0.2327
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1179
Epoch 8/10, Batch 20/97, Loss: 0.2555
Epoch 8/10, Batch 30/97, Loss: 0.1834
Epoch 8/10, Batch 40/97, Loss: 0.1416
Epoch 8/10, Batch 50/97, Loss: 0.2685
Epoch 8/10, Batch 60/97, Loss: 0.1494
Epoch 8/10, Batch 70/97, Loss: 0.1043
Epoch 8/10, Batch 80/97, Loss: 0.1768
Epoch 8/10, Batch 90/97, Loss: 0.1819
Epoch 8/10, Train Loss: 0.2295, Valid Loss: 0.2296
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1905
Epoch 9/10, Batch 20/97, Loss: 0.2107
Epoch 9/10, Batch 30/97, Loss: 0.2658
Epoch 9/10, Batch 40/97, Loss: 0.2463
Epoch 9/10, Batch 50/97, Loss: 0.2453
Epoch 9/10, Batch 60/97, Loss: 0.2469
Epoch 9/10, Batch 70/97, Loss: 0.1809
Epoch 9/10, Batch 80/97, Loss: 0.1317
Epoch 9/10, Batch 90/97, Loss: 0.1268
Epoch 9/10, Train Loss: 0.2097, Valid Loss: 0.2283
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1593
Epoch 10/10, Batch 20/97, Loss: 0.2488
Epoch 10/10, Batch 30/97, Loss: 0.2176
Epoch 10/10, Batch 40/97, Loss: 0.1371
Epoch 10/10, Batch 50/97, Loss: 0.1955
Epoch 10/10, Batch 60/97, Loss: 0.2104
Epoch 10/10, Batch 70/97, Loss: 0.2357
Epoch 10/10, Batch 80/97, Loss: 0.1739
Epoch 10/10, Batch 90/97, Loss: 0.1790
Epoch 10/10, Train Loss: 0.2074, Valid Loss: 0.2299
Accuracy: 0.9136
Precision: 0.9110
Recall: 0.9136
F1-score: 0.9113
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2708
Epoch 1/10, Batch 20/97, Loss: 1.0459
Epoch 1/10, Batch 30/97, Loss: 0.7505
Epoch 1/10, Batch 40/97, Loss: 0.7779
Epoch 1/10, Batch 50/97, Loss: 0.5445
Epoch 1/10, Batch 60/97, Loss: 0.6084
Epoch 1/10, Batch 70/97, Loss: 0.6830
Epoch 1/10, Batch 80/97, Loss: 0.7132
Epoch 1/10, Batch 90/97, Loss: 0.4977
Epoch 1/10, Train Loss: 0.8083, Valid Loss: 0.4600
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5183
Epoch 2/10, Batch 20/97, Loss: 0.4008
Epoch 2/10, Batch 30/97, Loss: 0.4306
Epoch 2/10, Batch 40/97, Loss: 0.4377
Epoch 2/10, Batch 50/97, Loss: 0.5034
Epoch 2/10, Batch 60/97, Loss: 0.4548
Epoch 2/10, Batch 70/97, Loss: 0.3884
Epoch 2/10, Batch 80/97, Loss: 0.5715
Epoch 2/10, Batch 90/97, Loss: 0.4155
Epoch 2/10, Train Loss: 0.4126, Valid Loss: 0.3461
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2867
Epoch 3/10, Batch 20/97, Loss: 0.3964
Epoch 3/10, Batch 30/97, Loss: 0.4320
Epoch 3/10, Batch 40/97, Loss: 0.1505
Epoch 3/10, Batch 50/97, Loss: 0.4932
Epoch 3/10, Batch 60/97, Loss: 0.3034
Epoch 3/10, Batch 70/97, Loss: 0.4086
Epoch 3/10, Batch 80/97, Loss: 0.2599
Epoch 3/10, Batch 90/97, Loss: 0.3776
Epoch 3/10, Train Loss: 0.3443, Valid Loss: 0.3110
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3724
Epoch 4/10, Batch 20/97, Loss: 0.2818
Epoch 4/10, Batch 30/97, Loss: 0.1881
Epoch 4/10, Batch 40/97, Loss: 0.2888
Epoch 4/10, Batch 50/97, Loss: 0.4693
Epoch 4/10, Batch 60/97, Loss: 0.2323
Epoch 4/10, Batch 70/97, Loss: 0.3193
Epoch 4/10, Batch 80/97, Loss: 0.3320
Epoch 4/10, Batch 90/97, Loss: 0.2085
Epoch 4/10, Train Loss: 0.2927, Valid Loss: 0.2947
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3824
Epoch 5/10, Batch 20/97, Loss: 0.2619
Epoch 5/10, Batch 30/97, Loss: 0.1829
Epoch 5/10, Batch 40/97, Loss: 0.3148
Epoch 5/10, Batch 50/97, Loss: 0.4223
Epoch 5/10, Batch 60/97, Loss: 0.3999
Epoch 5/10, Batch 70/97, Loss: 0.2039
Epoch 5/10, Batch 80/97, Loss: 0.2561
Epoch 5/10, Batch 90/97, Loss: 0.2611
Epoch 5/10, Train Loss: 0.2664, Valid Loss: 0.2799
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1945
Epoch 6/10, Batch 20/97, Loss: 0.2473
Epoch 6/10, Batch 30/97, Loss: 0.0991
Epoch 6/10, Batch 40/97, Loss: 0.3697
Epoch 6/10, Batch 50/97, Loss: 0.2613
Epoch 6/10, Batch 60/97, Loss: 0.1715
Epoch 6/10, Batch 70/97, Loss: 0.1390
Epoch 6/10, Batch 80/97, Loss: 0.2766
Epoch 6/10, Batch 90/97, Loss: 0.3412
Epoch 6/10, Train Loss: 0.2415, Valid Loss: 0.2585
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1956
Epoch 7/10, Batch 20/97, Loss: 0.6434
Epoch 7/10, Batch 30/97, Loss: 0.1569
Epoch 7/10, Batch 40/97, Loss: 0.1391
Epoch 7/10, Batch 50/97, Loss: 0.2294
Epoch 7/10, Batch 60/97, Loss: 0.1479
Epoch 7/10, Batch 70/97, Loss: 0.3617
Epoch 7/10, Batch 80/97, Loss: 0.2452
Epoch 7/10, Batch 90/97, Loss: 0.1725
Epoch 7/10, Train Loss: 0.2369, Valid Loss: 0.2572
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2542
Epoch 8/10, Batch 20/97, Loss: 0.2984
Epoch 8/10, Batch 30/97, Loss: 0.2302
Epoch 8/10, Batch 40/97, Loss: 0.1908
Epoch 8/10, Batch 50/97, Loss: 0.2512
Epoch 8/10, Batch 60/97, Loss: 0.2140
Epoch 8/10, Batch 70/97, Loss: 0.2135
Epoch 8/10, Batch 80/97, Loss: 0.2972
Epoch 8/10, Batch 90/97, Loss: 0.4618
Epoch 8/10, Train Loss: 0.2335, Valid Loss: 0.2533
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1319
Epoch 9/10, Batch 20/97, Loss: 0.2004
Epoch 9/10, Batch 30/97, Loss: 0.3047
Epoch 9/10, Batch 40/97, Loss: 0.2974
Epoch 9/10, Batch 50/97, Loss: 0.1528
Epoch 9/10, Batch 60/97, Loss: 0.2480
Epoch 9/10, Batch 70/97, Loss: 0.2435
Epoch 9/10, Batch 80/97, Loss: 0.1921
Epoch 9/10, Batch 90/97, Loss: 0.2398
Epoch 9/10, Train Loss: 0.2064, Valid Loss: 0.2446
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3635
Epoch 10/10, Batch 20/97, Loss: 0.1696
Epoch 10/10, Batch 30/97, Loss: 0.1872
Epoch 10/10, Batch 40/97, Loss: 0.1616
Epoch 10/10, Batch 50/97, Loss: 0.1508
Epoch 10/10, Batch 60/97, Loss: 0.1282
Epoch 10/10, Batch 70/97, Loss: 0.2319
Epoch 10/10, Batch 80/97, Loss: 0.1153
Epoch 10/10, Batch 90/97, Loss: 0.2117
Epoch 10/10, Train Loss: 0.2029, Valid Loss: 0.2411
Model saved!
Accuracy: 0.9182
Precision: 0.9161
Recall: 0.9182
F1-score: 0.9154
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2197
Epoch 1/10, Batch 20/97, Loss: 1.0310
Epoch 1/10, Batch 30/97, Loss: 0.7646
Epoch 1/10, Batch 40/97, Loss: 0.8174
Epoch 1/10, Batch 50/97, Loss: 0.5774
Epoch 1/10, Batch 60/97, Loss: 0.7157
Epoch 1/10, Batch 70/97, Loss: 0.7926
Epoch 1/10, Batch 80/97, Loss: 0.6511
Epoch 1/10, Batch 90/97, Loss: 0.5503
Epoch 1/10, Train Loss: 0.8024, Valid Loss: 0.4550
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4783
Epoch 2/10, Batch 20/97, Loss: 0.2993
Epoch 2/10, Batch 30/97, Loss: 0.3399
Epoch 2/10, Batch 40/97, Loss: 0.3603
Epoch 2/10, Batch 50/97, Loss: 0.5149
Epoch 2/10, Batch 60/97, Loss: 0.4447
Epoch 2/10, Batch 70/97, Loss: 0.3560
Epoch 2/10, Batch 80/97, Loss: 0.4179
Epoch 2/10, Batch 90/97, Loss: 0.4303
Epoch 2/10, Train Loss: 0.4139, Valid Loss: 0.3463
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3727
Epoch 3/10, Batch 20/97, Loss: 0.3114
Epoch 3/10, Batch 30/97, Loss: 0.4951
Epoch 3/10, Batch 40/97, Loss: 0.2026
Epoch 3/10, Batch 50/97, Loss: 0.4401
Epoch 3/10, Batch 60/97, Loss: 0.4805
Epoch 3/10, Batch 70/97, Loss: 0.4802
Epoch 3/10, Batch 80/97, Loss: 0.3375
Epoch 3/10, Batch 90/97, Loss: 0.2790
Epoch 3/10, Train Loss: 0.3417, Valid Loss: 0.2965
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3097
Epoch 4/10, Batch 20/97, Loss: 0.2524
Epoch 4/10, Batch 30/97, Loss: 0.2899
Epoch 4/10, Batch 40/97, Loss: 0.4839
Epoch 4/10, Batch 50/97, Loss: 0.1841
Epoch 4/10, Batch 60/97, Loss: 0.1801
Epoch 4/10, Batch 70/97, Loss: 0.2639
Epoch 4/10, Batch 80/97, Loss: 0.4070
Epoch 4/10, Batch 90/97, Loss: 0.1998
Epoch 4/10, Train Loss: 0.2837, Valid Loss: 0.2786
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2823
Epoch 5/10, Batch 20/97, Loss: 0.3651
Epoch 5/10, Batch 30/97, Loss: 0.1098
Epoch 5/10, Batch 40/97, Loss: 0.1736
Epoch 5/10, Batch 50/97, Loss: 0.1850
Epoch 5/10, Batch 60/97, Loss: 0.2429
Epoch 5/10, Batch 70/97, Loss: 0.2641
Epoch 5/10, Batch 80/97, Loss: 0.2303
Epoch 5/10, Batch 90/97, Loss: 0.2612
Epoch 5/10, Train Loss: 0.2653, Valid Loss: 0.2591
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3103
Epoch 6/10, Batch 20/97, Loss: 0.3123
Epoch 6/10, Batch 30/97, Loss: 0.1049
Epoch 6/10, Batch 40/97, Loss: 0.2189
Epoch 6/10, Batch 50/97, Loss: 0.1702
Epoch 6/10, Batch 60/97, Loss: 0.2401
Epoch 6/10, Batch 70/97, Loss: 0.2038
Epoch 6/10, Batch 80/97, Loss: 0.2618
Epoch 6/10, Batch 90/97, Loss: 0.3329
Epoch 6/10, Train Loss: 0.2554, Valid Loss: 0.2436
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1668
Epoch 7/10, Batch 20/97, Loss: 0.1785
Epoch 7/10, Batch 30/97, Loss: 0.2156
Epoch 7/10, Batch 40/97, Loss: 0.2482
Epoch 7/10, Batch 50/97, Loss: 0.2406
Epoch 7/10, Batch 60/97, Loss: 0.1425
Epoch 7/10, Batch 70/97, Loss: 0.4112
Epoch 7/10, Batch 80/97, Loss: 0.2680
Epoch 7/10, Batch 90/97, Loss: 0.0779
Epoch 7/10, Train Loss: 0.2264, Valid Loss: 0.2409
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1261
Epoch 8/10, Batch 20/97, Loss: 0.3871
Epoch 8/10, Batch 30/97, Loss: 0.1203
Epoch 8/10, Batch 40/97, Loss: 0.1617
Epoch 8/10, Batch 50/97, Loss: 0.2373
Epoch 8/10, Batch 60/97, Loss: 0.1963
Epoch 8/10, Batch 70/97, Loss: 0.4142
Epoch 8/10, Batch 80/97, Loss: 0.2943
Epoch 8/10, Batch 90/97, Loss: 0.1722
Epoch 8/10, Train Loss: 0.2288, Valid Loss: 0.2280
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1344
Epoch 9/10, Batch 20/97, Loss: 0.1681
Epoch 9/10, Batch 30/97, Loss: 0.2310
Epoch 9/10, Batch 40/97, Loss: 0.1971
Epoch 9/10, Batch 50/97, Loss: 0.3061
Epoch 9/10, Batch 60/97, Loss: 0.2239
Epoch 9/10, Batch 70/97, Loss: 0.1399
Epoch 9/10, Batch 80/97, Loss: 0.1588
Epoch 9/10, Batch 90/97, Loss: 0.1726
Epoch 9/10, Train Loss: 0.2078, Valid Loss: 0.2181
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1616
Epoch 10/10, Batch 20/97, Loss: 0.0822
Epoch 10/10, Batch 30/97, Loss: 0.1962
Epoch 10/10, Batch 40/97, Loss: 0.1426
Epoch 10/10, Batch 50/97, Loss: 0.1733
Epoch 10/10, Batch 60/97, Loss: 0.1814
Epoch 10/10, Batch 70/97, Loss: 0.2757
Epoch 10/10, Batch 80/97, Loss: 0.1746
Epoch 10/10, Batch 90/97, Loss: 0.1696
Epoch 10/10, Train Loss: 0.2077, Valid Loss: 0.2205
Accuracy: 0.9194
Precision: 0.9172
Recall: 0.9194
F1-score: 0.9180
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2046
Epoch 1/10, Batch 20/97, Loss: 1.1110
Epoch 1/10, Batch 30/97, Loss: 0.8188
Epoch 1/10, Batch 40/97, Loss: 0.7186
Epoch 1/10, Batch 50/97, Loss: 0.5675
Epoch 1/10, Batch 60/97, Loss: 0.7414
Epoch 1/10, Batch 70/97, Loss: 0.7459
Epoch 1/10, Batch 80/97, Loss: 0.5579
Epoch 1/10, Batch 90/97, Loss: 0.4765
Epoch 1/10, Train Loss: 0.8118, Valid Loss: 0.4389
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6156
Epoch 2/10, Batch 20/97, Loss: 0.4800
Epoch 2/10, Batch 30/97, Loss: 0.4145
Epoch 2/10, Batch 40/97, Loss: 0.3315
Epoch 2/10, Batch 50/97, Loss: 0.4044
Epoch 2/10, Batch 60/97, Loss: 0.6147
Epoch 2/10, Batch 70/97, Loss: 0.4300
Epoch 2/10, Batch 80/97, Loss: 0.4127
Epoch 2/10, Batch 90/97, Loss: 0.5299
Epoch 2/10, Train Loss: 0.4262, Valid Loss: 0.3264
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4997
Epoch 3/10, Batch 20/97, Loss: 0.3487
Epoch 3/10, Batch 30/97, Loss: 0.3806
Epoch 3/10, Batch 40/97, Loss: 0.2464
Epoch 3/10, Batch 50/97, Loss: 0.3856
Epoch 3/10, Batch 60/97, Loss: 0.2373
Epoch 3/10, Batch 70/97, Loss: 0.3686
Epoch 3/10, Batch 80/97, Loss: 0.2435
Epoch 3/10, Batch 90/97, Loss: 0.2632
Epoch 3/10, Train Loss: 0.3413, Valid Loss: 0.2763
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4577
Epoch 4/10, Batch 20/97, Loss: 0.2171
Epoch 4/10, Batch 30/97, Loss: 0.1913
Epoch 4/10, Batch 40/97, Loss: 0.2504
Epoch 4/10, Batch 50/97, Loss: 0.3961
Epoch 4/10, Batch 60/97, Loss: 0.2610
Epoch 4/10, Batch 70/97, Loss: 0.2800
Epoch 4/10, Batch 80/97, Loss: 0.3229
Epoch 4/10, Batch 90/97, Loss: 0.1494
Epoch 4/10, Train Loss: 0.2887, Valid Loss: 0.2555
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3485
Epoch 5/10, Batch 20/97, Loss: 0.2593
Epoch 5/10, Batch 30/97, Loss: 0.2979
Epoch 5/10, Batch 40/97, Loss: 0.2222
Epoch 5/10, Batch 50/97, Loss: 0.2406
Epoch 5/10, Batch 60/97, Loss: 0.2028
Epoch 5/10, Batch 70/97, Loss: 0.2527
Epoch 5/10, Batch 80/97, Loss: 0.3802
Epoch 5/10, Batch 90/97, Loss: 0.2447
Epoch 5/10, Train Loss: 0.2760, Valid Loss: 0.2399
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.4430
Epoch 6/10, Batch 20/97, Loss: 0.4213
Epoch 6/10, Batch 30/97, Loss: 0.1321
Epoch 6/10, Batch 40/97, Loss: 0.1394
Epoch 6/10, Batch 50/97, Loss: 0.2500
Epoch 6/10, Batch 60/97, Loss: 0.3550
Epoch 6/10, Batch 70/97, Loss: 0.3225
Epoch 6/10, Batch 80/97, Loss: 0.4217
Epoch 6/10, Batch 90/97, Loss: 0.2748
Epoch 6/10, Train Loss: 0.2509, Valid Loss: 0.2230
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2112
Epoch 7/10, Batch 20/97, Loss: 0.2456
Epoch 7/10, Batch 30/97, Loss: 0.1375
Epoch 7/10, Batch 40/97, Loss: 0.1718
Epoch 7/10, Batch 50/97, Loss: 0.1853
Epoch 7/10, Batch 60/97, Loss: 0.3736
Epoch 7/10, Batch 70/97, Loss: 0.2206
Epoch 7/10, Batch 80/97, Loss: 0.2527
Epoch 7/10, Batch 90/97, Loss: 0.1347
Epoch 7/10, Train Loss: 0.2328, Valid Loss: 0.2208
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2323
Epoch 8/10, Batch 20/97, Loss: 0.1935
Epoch 8/10, Batch 30/97, Loss: 0.2238
Epoch 8/10, Batch 40/97, Loss: 0.1108
Epoch 8/10, Batch 50/97, Loss: 0.1413
Epoch 8/10, Batch 60/97, Loss: 0.1540
Epoch 8/10, Batch 70/97, Loss: 0.2267
Epoch 8/10, Batch 80/97, Loss: 0.2057
Epoch 8/10, Batch 90/97, Loss: 0.0811
Epoch 8/10, Train Loss: 0.2243, Valid Loss: 0.2128
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1777
Epoch 9/10, Batch 20/97, Loss: 0.1744
Epoch 9/10, Batch 30/97, Loss: 0.2797
Epoch 9/10, Batch 40/97, Loss: 0.1884
Epoch 9/10, Batch 50/97, Loss: 0.2095
Epoch 9/10, Batch 60/97, Loss: 0.2185
Epoch 9/10, Batch 70/97, Loss: 0.1293
Epoch 9/10, Batch 80/97, Loss: 0.1813
Epoch 9/10, Batch 90/97, Loss: 0.2798
Epoch 9/10, Train Loss: 0.2070, Valid Loss: 0.2086
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2997
Epoch 10/10, Batch 20/97, Loss: 0.1972
Epoch 10/10, Batch 30/97, Loss: 0.2225
Epoch 10/10, Batch 40/97, Loss: 0.1450
Epoch 10/10, Batch 50/97, Loss: 0.2358
Epoch 10/10, Batch 60/97, Loss: 0.1308
Epoch 10/10, Batch 70/97, Loss: 0.1732
Epoch 10/10, Batch 80/97, Loss: 0.1453
Epoch 10/10, Batch 90/97, Loss: 0.2462
Epoch 10/10, Train Loss: 0.2099, Valid Loss: 0.2024
Model saved!
Accuracy: 0.9194
Precision: 0.9180
Recall: 0.9194
F1-score: 0.9174
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2017
Epoch 1/10, Batch 20/97, Loss: 1.1450
Epoch 1/10, Batch 30/97, Loss: 0.7577
Epoch 1/10, Batch 40/97, Loss: 0.7011
Epoch 1/10, Batch 50/97, Loss: 0.6051
Epoch 1/10, Batch 60/97, Loss: 0.6957
Epoch 1/10, Batch 70/97, Loss: 0.6642
Epoch 1/10, Batch 80/97, Loss: 0.5885
Epoch 1/10, Batch 90/97, Loss: 0.5321
Epoch 1/10, Train Loss: 0.7964, Valid Loss: 0.4740
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5238
Epoch 2/10, Batch 20/97, Loss: 0.5657
Epoch 2/10, Batch 30/97, Loss: 0.2702
Epoch 2/10, Batch 40/97, Loss: 0.3656
Epoch 2/10, Batch 50/97, Loss: 0.2983
Epoch 2/10, Batch 60/97, Loss: 0.4262
Epoch 2/10, Batch 70/97, Loss: 0.3529
Epoch 2/10, Batch 80/97, Loss: 0.2707
Epoch 2/10, Batch 90/97, Loss: 0.7791
Epoch 2/10, Train Loss: 0.4127, Valid Loss: 0.3638
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3497
Epoch 3/10, Batch 20/97, Loss: 0.3129
Epoch 3/10, Batch 30/97, Loss: 0.4031
Epoch 3/10, Batch 40/97, Loss: 0.2049
Epoch 3/10, Batch 50/97, Loss: 0.3415
Epoch 3/10, Batch 60/97, Loss: 0.2420
Epoch 3/10, Batch 70/97, Loss: 0.3697
Epoch 3/10, Batch 80/97, Loss: 0.3667
Epoch 3/10, Batch 90/97, Loss: 0.3022
Epoch 3/10, Train Loss: 0.3273, Valid Loss: 0.3186
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3650
Epoch 4/10, Batch 20/97, Loss: 0.2135
Epoch 4/10, Batch 30/97, Loss: 0.3053
Epoch 4/10, Batch 40/97, Loss: 0.2735
Epoch 4/10, Batch 50/97, Loss: 0.3344
Epoch 4/10, Batch 60/97, Loss: 0.3303
Epoch 4/10, Batch 70/97, Loss: 0.2800
Epoch 4/10, Batch 80/97, Loss: 0.2250
Epoch 4/10, Batch 90/97, Loss: 0.1868
Epoch 4/10, Train Loss: 0.2844, Valid Loss: 0.2966
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2389
Epoch 5/10, Batch 20/97, Loss: 0.3566
Epoch 5/10, Batch 30/97, Loss: 0.2367
Epoch 5/10, Batch 40/97, Loss: 0.1770
Epoch 5/10, Batch 50/97, Loss: 0.3130
Epoch 5/10, Batch 60/97, Loss: 0.1677
Epoch 5/10, Batch 70/97, Loss: 0.3925
Epoch 5/10, Batch 80/97, Loss: 0.2205
Epoch 5/10, Batch 90/97, Loss: 0.2487
Epoch 5/10, Train Loss: 0.2615, Valid Loss: 0.2810
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1579
Epoch 6/10, Batch 20/97, Loss: 0.4154
Epoch 6/10, Batch 30/97, Loss: 0.1300
Epoch 6/10, Batch 40/97, Loss: 0.2755
Epoch 6/10, Batch 50/97, Loss: 0.2630
Epoch 6/10, Batch 60/97, Loss: 0.3687
Epoch 6/10, Batch 70/97, Loss: 0.3467
Epoch 6/10, Batch 80/97, Loss: 0.3230
Epoch 6/10, Batch 90/97, Loss: 0.3194
Epoch 6/10, Train Loss: 0.2436, Valid Loss: 0.2601
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1713
Epoch 7/10, Batch 20/97, Loss: 0.3424
Epoch 7/10, Batch 30/97, Loss: 0.2685
Epoch 7/10, Batch 40/97, Loss: 0.1751
Epoch 7/10, Batch 50/97, Loss: 0.1659
Epoch 7/10, Batch 60/97, Loss: 0.1402
Epoch 7/10, Batch 70/97, Loss: 0.2323
Epoch 7/10, Batch 80/97, Loss: 0.2514
Epoch 7/10, Batch 90/97, Loss: 0.0836
Epoch 7/10, Train Loss: 0.2268, Valid Loss: 0.2585
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1727
Epoch 8/10, Batch 20/97, Loss: 0.1910
Epoch 8/10, Batch 30/97, Loss: 0.1540
Epoch 8/10, Batch 40/97, Loss: 0.3055
Epoch 8/10, Batch 50/97, Loss: 0.2066
Epoch 8/10, Batch 60/97, Loss: 0.1957
Epoch 8/10, Batch 70/97, Loss: 0.3306
Epoch 8/10, Batch 80/97, Loss: 0.1066
Epoch 8/10, Batch 90/97, Loss: 0.1504
Epoch 8/10, Train Loss: 0.2203, Valid Loss: 0.2497
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0922
Epoch 9/10, Batch 20/97, Loss: 0.1251
Epoch 9/10, Batch 30/97, Loss: 0.3019
Epoch 9/10, Batch 40/97, Loss: 0.1803
Epoch 9/10, Batch 50/97, Loss: 0.1318
Epoch 9/10, Batch 60/97, Loss: 0.1410
Epoch 9/10, Batch 70/97, Loss: 0.2221
Epoch 9/10, Batch 80/97, Loss: 0.2587
Epoch 9/10, Batch 90/97, Loss: 0.0816
Epoch 9/10, Train Loss: 0.2096, Valid Loss: 0.2484
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2544
Epoch 10/10, Batch 20/97, Loss: 0.2694
Epoch 10/10, Batch 30/97, Loss: 0.2440
Epoch 10/10, Batch 40/97, Loss: 0.1675
Epoch 10/10, Batch 50/97, Loss: 0.1492
Epoch 10/10, Batch 60/97, Loss: 0.1429
Epoch 10/10, Batch 70/97, Loss: 0.2718
Epoch 10/10, Batch 80/97, Loss: 0.2754
Epoch 10/10, Batch 90/97, Loss: 0.1876
Epoch 10/10, Train Loss: 0.2089, Valid Loss: 0.2378
Model saved!
Accuracy: 0.9229
Precision: 0.9215
Recall: 0.9229
F1-score: 0.9211
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.3127
Epoch 1/10, Batch 20/97, Loss: 1.0746
Epoch 1/10, Batch 30/97, Loss: 0.7315
Epoch 1/10, Batch 40/97, Loss: 0.8619
Epoch 1/10, Batch 50/97, Loss: 0.7077
Epoch 1/10, Batch 60/97, Loss: 0.6923
Epoch 1/10, Batch 70/97, Loss: 0.6035
Epoch 1/10, Batch 80/97, Loss: 0.5562
Epoch 1/10, Batch 90/97, Loss: 0.5843
Epoch 1/10, Train Loss: 0.8022, Valid Loss: 0.4398
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3884
Epoch 2/10, Batch 20/97, Loss: 0.3434
Epoch 2/10, Batch 30/97, Loss: 0.5409
Epoch 2/10, Batch 40/97, Loss: 0.4488
Epoch 2/10, Batch 50/97, Loss: 0.3955
Epoch 2/10, Batch 60/97, Loss: 0.3271
Epoch 2/10, Batch 70/97, Loss: 0.3054
Epoch 2/10, Batch 80/97, Loss: 0.4782
Epoch 2/10, Batch 90/97, Loss: 0.4012
Epoch 2/10, Train Loss: 0.4098, Valid Loss: 0.3304
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2799
Epoch 3/10, Batch 20/97, Loss: 0.3315
Epoch 3/10, Batch 30/97, Loss: 0.3251
Epoch 3/10, Batch 40/97, Loss: 0.2905
Epoch 3/10, Batch 50/97, Loss: 0.3098
Epoch 3/10, Batch 60/97, Loss: 0.3669
Epoch 3/10, Batch 70/97, Loss: 0.3502
Epoch 3/10, Batch 80/97, Loss: 0.3740
Epoch 3/10, Batch 90/97, Loss: 0.2814
Epoch 3/10, Train Loss: 0.3342, Valid Loss: 0.2894
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3354
Epoch 4/10, Batch 20/97, Loss: 0.2451
Epoch 4/10, Batch 30/97, Loss: 0.2216
Epoch 4/10, Batch 40/97, Loss: 0.2121
Epoch 4/10, Batch 50/97, Loss: 0.2543
Epoch 4/10, Batch 60/97, Loss: 0.2875
Epoch 4/10, Batch 70/97, Loss: 0.2607
Epoch 4/10, Batch 80/97, Loss: 0.1936
Epoch 4/10, Batch 90/97, Loss: 0.3577
Epoch 4/10, Train Loss: 0.2807, Valid Loss: 0.2652
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2440
Epoch 5/10, Batch 20/97, Loss: 0.4886
Epoch 5/10, Batch 30/97, Loss: 0.2095
Epoch 5/10, Batch 40/97, Loss: 0.2178
Epoch 5/10, Batch 50/97, Loss: 0.1992
Epoch 5/10, Batch 60/97, Loss: 0.3520
Epoch 5/10, Batch 70/97, Loss: 0.3955
Epoch 5/10, Batch 80/97, Loss: 0.4235
Epoch 5/10, Batch 90/97, Loss: 0.1510
Epoch 5/10, Train Loss: 0.2559, Valid Loss: 0.2519
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1796
Epoch 6/10, Batch 20/97, Loss: 0.2152
Epoch 6/10, Batch 30/97, Loss: 0.1824
Epoch 6/10, Batch 40/97, Loss: 0.1866
Epoch 6/10, Batch 50/97, Loss: 0.1225
Epoch 6/10, Batch 60/97, Loss: 0.2513
Epoch 6/10, Batch 70/97, Loss: 0.1967
Epoch 6/10, Batch 80/97, Loss: 0.1749
Epoch 6/10, Batch 90/97, Loss: 0.3672
Epoch 6/10, Train Loss: 0.2436, Valid Loss: 0.2447
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1224
Epoch 7/10, Batch 20/97, Loss: 0.2427
Epoch 7/10, Batch 30/97, Loss: 0.1177
Epoch 7/10, Batch 40/97, Loss: 0.2746
Epoch 7/10, Batch 50/97, Loss: 0.3061
Epoch 7/10, Batch 60/97, Loss: 0.1616
Epoch 7/10, Batch 70/97, Loss: 0.5634
Epoch 7/10, Batch 80/97, Loss: 0.2719
Epoch 7/10, Batch 90/97, Loss: 0.2548
Epoch 7/10, Train Loss: 0.2171, Valid Loss: 0.2378
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2334
Epoch 8/10, Batch 20/97, Loss: 0.1757
Epoch 8/10, Batch 30/97, Loss: 0.2293
Epoch 8/10, Batch 40/97, Loss: 0.2866
Epoch 8/10, Batch 50/97, Loss: 0.1687
Epoch 8/10, Batch 60/97, Loss: 0.2918
Epoch 8/10, Batch 70/97, Loss: 0.2850
Epoch 8/10, Batch 80/97, Loss: 0.3209
Epoch 8/10, Batch 90/97, Loss: 0.1408
Epoch 8/10, Train Loss: 0.2217, Valid Loss: 0.2346
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2718
Epoch 9/10, Batch 20/97, Loss: 0.1170
Epoch 9/10, Batch 30/97, Loss: 0.1854
Epoch 9/10, Batch 40/97, Loss: 0.1589
Epoch 9/10, Batch 50/97, Loss: 0.1397
Epoch 9/10, Batch 60/97, Loss: 0.1613
Epoch 9/10, Batch 70/97, Loss: 0.1767
Epoch 9/10, Batch 80/97, Loss: 0.1983
Epoch 9/10, Batch 90/97, Loss: 0.2839
Epoch 9/10, Train Loss: 0.2023, Valid Loss: 0.2272
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3318
Epoch 10/10, Batch 20/97, Loss: 0.1748
Epoch 10/10, Batch 30/97, Loss: 0.2530
Epoch 10/10, Batch 40/97, Loss: 0.2418
Epoch 10/10, Batch 50/97, Loss: 0.1779
Epoch 10/10, Batch 60/97, Loss: 0.0912
Epoch 10/10, Batch 70/97, Loss: 0.2761
Epoch 10/10, Batch 80/97, Loss: 0.1896
Epoch 10/10, Batch 90/97, Loss: 0.1550
Epoch 10/10, Train Loss: 0.1974, Valid Loss: 0.2264
Model saved!
Accuracy: 0.9171
Precision: 0.9152
Recall: 0.9171
F1-score: 0.9153
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2522
Epoch 1/10, Batch 20/97, Loss: 1.1661
Epoch 1/10, Batch 30/97, Loss: 0.7498
Epoch 1/10, Batch 40/97, Loss: 0.6852
Epoch 1/10, Batch 50/97, Loss: 0.6694
Epoch 1/10, Batch 60/97, Loss: 0.6998
Epoch 1/10, Batch 70/97, Loss: 0.7922
Epoch 1/10, Batch 80/97, Loss: 0.5958
Epoch 1/10, Batch 90/97, Loss: 0.6615
Epoch 1/10, Train Loss: 0.8060, Valid Loss: 0.4488
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4462
Epoch 2/10, Batch 20/97, Loss: 0.3518
Epoch 2/10, Batch 30/97, Loss: 0.3902
Epoch 2/10, Batch 40/97, Loss: 0.3898
Epoch 2/10, Batch 50/97, Loss: 0.3815
Epoch 2/10, Batch 60/97, Loss: 0.5427
Epoch 2/10, Batch 70/97, Loss: 0.3214
Epoch 2/10, Batch 80/97, Loss: 0.2884
Epoch 2/10, Batch 90/97, Loss: 0.5785
Epoch 2/10, Train Loss: 0.4165, Valid Loss: 0.3560
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3103
Epoch 3/10, Batch 20/97, Loss: 0.4660
Epoch 3/10, Batch 30/97, Loss: 0.4156
Epoch 3/10, Batch 40/97, Loss: 0.2964
Epoch 3/10, Batch 50/97, Loss: 0.3199
Epoch 3/10, Batch 60/97, Loss: 0.3358
Epoch 3/10, Batch 70/97, Loss: 0.4019
Epoch 3/10, Batch 80/97, Loss: 0.3755
Epoch 3/10, Batch 90/97, Loss: 0.2089
Epoch 3/10, Train Loss: 0.3353, Valid Loss: 0.3135
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4091
Epoch 4/10, Batch 20/97, Loss: 0.3193
Epoch 4/10, Batch 30/97, Loss: 0.4117
Epoch 4/10, Batch 40/97, Loss: 0.1655
Epoch 4/10, Batch 50/97, Loss: 0.1932
Epoch 4/10, Batch 60/97, Loss: 0.3079
Epoch 4/10, Batch 70/97, Loss: 0.3036
Epoch 4/10, Batch 80/97, Loss: 0.2539
Epoch 4/10, Batch 90/97, Loss: 0.2080
Epoch 4/10, Train Loss: 0.2888, Valid Loss: 0.3011
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2806
Epoch 5/10, Batch 20/97, Loss: 0.3680
Epoch 5/10, Batch 30/97, Loss: 0.2897
Epoch 5/10, Batch 40/97, Loss: 0.3012
Epoch 5/10, Batch 50/97, Loss: 0.2335
Epoch 5/10, Batch 60/97, Loss: 0.2808
Epoch 5/10, Batch 70/97, Loss: 0.2355
Epoch 5/10, Batch 80/97, Loss: 0.2194
Epoch 5/10, Batch 90/97, Loss: 0.3225
Epoch 5/10, Train Loss: 0.2687, Valid Loss: 0.2831
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2802
Epoch 6/10, Batch 20/97, Loss: 0.4478
Epoch 6/10, Batch 30/97, Loss: 0.2050
Epoch 6/10, Batch 40/97, Loss: 0.2239
Epoch 6/10, Batch 50/97, Loss: 0.4915
Epoch 6/10, Batch 60/97, Loss: 0.4270
Epoch 6/10, Batch 70/97, Loss: 0.3018
Epoch 6/10, Batch 80/97, Loss: 0.2649
Epoch 6/10, Batch 90/97, Loss: 0.2817
Epoch 6/10, Train Loss: 0.2557, Valid Loss: 0.2635
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2357
Epoch 7/10, Batch 20/97, Loss: 0.2580
Epoch 7/10, Batch 30/97, Loss: 0.0830
Epoch 7/10, Batch 40/97, Loss: 0.1902
Epoch 7/10, Batch 50/97, Loss: 0.1388
Epoch 7/10, Batch 60/97, Loss: 0.1376
Epoch 7/10, Batch 70/97, Loss: 0.2452
Epoch 7/10, Batch 80/97, Loss: 0.2130
Epoch 7/10, Batch 90/97, Loss: 0.2754
Epoch 7/10, Train Loss: 0.2255, Valid Loss: 0.2631
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2100
Epoch 8/10, Batch 20/97, Loss: 0.1680
Epoch 8/10, Batch 30/97, Loss: 0.2200
Epoch 8/10, Batch 40/97, Loss: 0.2519
Epoch 8/10, Batch 50/97, Loss: 0.2775
Epoch 8/10, Batch 60/97, Loss: 0.2199
Epoch 8/10, Batch 70/97, Loss: 0.2721
Epoch 8/10, Batch 80/97, Loss: 0.1873
Epoch 8/10, Batch 90/97, Loss: 0.1573
Epoch 8/10, Train Loss: 0.2189, Valid Loss: 0.2673
Epoch 9/10, Batch 10/97, Loss: 0.2840
Epoch 9/10, Batch 20/97, Loss: 0.2044
Epoch 9/10, Batch 30/97, Loss: 0.2861
Epoch 9/10, Batch 40/97, Loss: 0.3386
Epoch 9/10, Batch 50/97, Loss: 0.1081
Epoch 9/10, Batch 60/97, Loss: 0.1510
Epoch 9/10, Batch 70/97, Loss: 0.2012
Epoch 9/10, Batch 80/97, Loss: 0.1296
Epoch 9/10, Batch 90/97, Loss: 0.2054
Epoch 9/10, Train Loss: 0.2080, Valid Loss: 0.2566
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2951
Epoch 10/10, Batch 20/97, Loss: 0.1833
Epoch 10/10, Batch 30/97, Loss: 0.1037
Epoch 10/10, Batch 40/97, Loss: 0.1746
Epoch 10/10, Batch 50/97, Loss: 0.1527
Epoch 10/10, Batch 60/97, Loss: 0.0894
Epoch 10/10, Batch 70/97, Loss: 0.2472
Epoch 10/10, Batch 80/97, Loss: 0.1477
Epoch 10/10, Batch 90/97, Loss: 0.2231
Epoch 10/10, Train Loss: 0.2034, Valid Loss: 0.2559
Model saved!
Accuracy: 0.9077
Precision: 0.9057
Recall: 0.9077
F1-score: 0.9052
Memory Allocated after cleanup: 17.76 MB
End time: 2025-02-25 19:02:42.514726
Duration: 6:38:54


Mejor accuracy al acabar el algoritmo: 0.9241


Fitness check:

Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.2739
Epoch 1/10, Batch 20/97, Loss: 1.1131
Epoch 1/10, Batch 30/97, Loss: 0.7915
Epoch 1/10, Batch 40/97, Loss: 0.7716
Epoch 1/10, Batch 50/97, Loss: 0.5169
Epoch 1/10, Batch 60/97, Loss: 0.6712
Epoch 1/10, Batch 70/97, Loss: 0.6438
Epoch 1/10, Batch 80/97, Loss: 0.7302
Epoch 1/10, Batch 90/97, Loss: 0.5293
Epoch 1/10, Train Loss: 0.8090, Valid Loss: 0.4487
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5706
Epoch 2/10, Batch 20/97, Loss: 0.5316
Epoch 2/10, Batch 30/97, Loss: 0.5771
Epoch 2/10, Batch 40/97, Loss: 0.3654
Epoch 2/10, Batch 50/97, Loss: 0.3705
Epoch 2/10, Batch 60/97, Loss: 0.4166
Epoch 2/10, Batch 70/97, Loss: 0.4317
Epoch 2/10, Batch 80/97, Loss: 0.3718
Epoch 2/10, Batch 90/97, Loss: 0.4456
Epoch 2/10, Train Loss: 0.4138, Valid Loss: 0.3435
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3107
Epoch 3/10, Batch 20/97, Loss: 0.3347
Epoch 3/10, Batch 30/97, Loss: 0.2955
Epoch 3/10, Batch 40/97, Loss: 0.1928
Epoch 3/10, Batch 50/97, Loss: 0.4000
Epoch 3/10, Batch 60/97, Loss: 0.2584
Epoch 3/10, Batch 70/97, Loss: 0.4018
Epoch 3/10, Batch 80/97, Loss: 0.2619
Epoch 3/10, Batch 90/97, Loss: 0.2637
Epoch 3/10, Train Loss: 0.3309, Valid Loss: 0.2984
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3362
Epoch 4/10, Batch 20/97, Loss: 0.2018
Epoch 4/10, Batch 30/97, Loss: 0.2081
Epoch 4/10, Batch 40/97, Loss: 0.2012
Epoch 4/10, Batch 50/97, Loss: 0.4539
Epoch 4/10, Batch 60/97, Loss: 0.3644
Epoch 4/10, Batch 70/97, Loss: 0.3525
Epoch 4/10, Batch 80/97, Loss: 0.2249
Epoch 4/10, Batch 90/97, Loss: 0.2015
Epoch 4/10, Train Loss: 0.2901, Valid Loss: 0.2840
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3674
Epoch 5/10, Batch 20/97, Loss: 0.2447
Epoch 5/10, Batch 30/97, Loss: 0.1355
Epoch 5/10, Batch 40/97, Loss: 0.2142
Epoch 5/10, Batch 50/97, Loss: 0.2658
Epoch 5/10, Batch 60/97, Loss: 0.2253
Epoch 5/10, Batch 70/97, Loss: 0.2468
Epoch 5/10, Batch 80/97, Loss: 0.2239
Epoch 5/10, Batch 90/97, Loss: 0.1938
Epoch 5/10, Train Loss: 0.2654, Valid Loss: 0.2683
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1969
Epoch 6/10, Batch 20/97, Loss: 0.3155
Epoch 6/10, Batch 30/97, Loss: 0.2567
Epoch 6/10, Batch 40/97, Loss: 0.2242
Epoch 6/10, Batch 50/97, Loss: 0.2097
Epoch 6/10, Batch 60/97, Loss: 0.2290
Epoch 6/10, Batch 70/97, Loss: 0.2451
Epoch 6/10, Batch 80/97, Loss: 0.3238
Epoch 6/10, Batch 90/97, Loss: 0.4665
Epoch 6/10, Train Loss: 0.2536, Valid Loss: 0.2539
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1961
Epoch 7/10, Batch 20/97, Loss: 0.1854
Epoch 7/10, Batch 30/97, Loss: 0.2173
Epoch 7/10, Batch 40/97, Loss: 0.2969
Epoch 7/10, Batch 50/97, Loss: 0.2378
Epoch 7/10, Batch 60/97, Loss: 0.1487
Epoch 7/10, Batch 70/97, Loss: 0.3367
Epoch 7/10, Batch 80/97, Loss: 0.2039
Epoch 7/10, Batch 90/97, Loss: 0.1947
Epoch 7/10, Train Loss: 0.2296, Valid Loss: 0.2511
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.0657
Epoch 8/10, Batch 20/97, Loss: 0.3214
Epoch 8/10, Batch 30/97, Loss: 0.1463
Epoch 8/10, Batch 40/97, Loss: 0.2355
Epoch 8/10, Batch 50/97, Loss: 0.1523
Epoch 8/10, Batch 60/97, Loss: 0.1810
Epoch 8/10, Batch 70/97, Loss: 0.2222
Epoch 8/10, Batch 80/97, Loss: 0.1652
Epoch 8/10, Batch 90/97, Loss: 0.1402
Epoch 8/10, Train Loss: 0.2180, Valid Loss: 0.2419
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2170
Epoch 9/10, Batch 20/97, Loss: 0.1449
Epoch 9/10, Batch 30/97, Loss: 0.5170
Epoch 9/10, Batch 40/97, Loss: 0.2096
Epoch 9/10, Batch 50/97, Loss: 0.1757
Epoch 9/10, Batch 60/97, Loss: 0.3924
Epoch 9/10, Batch 70/97, Loss: 0.2421
Epoch 9/10, Batch 80/97, Loss: 0.2211
Epoch 9/10, Batch 90/97, Loss: 0.2150
Epoch 9/10, Train Loss: 0.2114, Valid Loss: 0.2320
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2508
Epoch 10/10, Batch 20/97, Loss: 0.1839
Epoch 10/10, Batch 30/97, Loss: 0.3855
Epoch 10/10, Batch 40/97, Loss: 0.0760
Epoch 10/10, Batch 50/97, Loss: 0.1437
Epoch 10/10, Batch 60/97, Loss: 0.1537
Epoch 10/10, Batch 70/97, Loss: 0.4859
Epoch 10/10, Batch 80/97, Loss: 0.2121
Epoch 10/10, Batch 90/97, Loss: 0.1690
Epoch 10/10, Train Loss: 0.2049, Valid Loss: 0.2371
Accuracy: 0.9241
Precision: 0.9212
Recall: 0.9241
F1-score: 0.9220
Memory Allocated after cleanup: 17.76 MB


Mejor accuracy encontrado: 0.9241


--------------------------------------mobilenet  BUSQUEDA LOCAL  75%-------------------------------------------------
Start time: 2025-02-25 19:06:39.965546
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4741
Epoch 1/10, Batch 20/145, Loss: 0.9618
Epoch 1/10, Batch 30/145, Loss: 0.9818
Epoch 1/10, Batch 40/145, Loss: 0.7594
Epoch 1/10, Batch 50/145, Loss: 0.5808
Epoch 1/10, Batch 60/145, Loss: 0.5115
Epoch 1/10, Batch 70/145, Loss: 0.7111
Epoch 1/10, Batch 80/145, Loss: 0.5542
Epoch 1/10, Batch 90/145, Loss: 0.4416
Epoch 1/10, Batch 100/145, Loss: 0.4193
Epoch 1/10, Batch 110/145, Loss: 0.4272
Epoch 1/10, Batch 120/145, Loss: 0.6263
Epoch 1/10, Batch 130/145, Loss: 0.3637
Epoch 1/10, Batch 140/145, Loss: 0.3706
Epoch 1/10, Train Loss: 0.6917, Valid Loss: 0.3787
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2739
Epoch 2/10, Batch 20/145, Loss: 0.4435
Epoch 2/10, Batch 30/145, Loss: 0.3822
Epoch 2/10, Batch 40/145, Loss: 0.4281
Epoch 2/10, Batch 50/145, Loss: 0.3378
Epoch 2/10, Batch 60/145, Loss: 0.3030
Epoch 2/10, Batch 70/145, Loss: 0.4733
Epoch 2/10, Batch 80/145, Loss: 0.2646
Epoch 2/10, Batch 90/145, Loss: 0.2800
Epoch 2/10, Batch 100/145, Loss: 0.4048
Epoch 2/10, Batch 110/145, Loss: 0.2042
Epoch 2/10, Batch 120/145, Loss: 0.3498
Epoch 2/10, Batch 130/145, Loss: 0.3786
Epoch 2/10, Batch 140/145, Loss: 0.3927
Epoch 2/10, Train Loss: 0.3676, Valid Loss: 0.2893
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1726
Epoch 3/10, Batch 20/145, Loss: 0.4103
Epoch 3/10, Batch 30/145, Loss: 0.2272
Epoch 3/10, Batch 40/145, Loss: 0.3520
Epoch 3/10, Batch 50/145, Loss: 0.2249
Epoch 3/10, Batch 60/145, Loss: 0.5011
Epoch 3/10, Batch 70/145, Loss: 0.1553
Epoch 3/10, Batch 80/145, Loss: 0.2734
Epoch 3/10, Batch 90/145, Loss: 0.6773
Epoch 3/10, Batch 100/145, Loss: 0.1727
Epoch 3/10, Batch 110/145, Loss: 0.2354
Epoch 3/10, Batch 120/145, Loss: 0.2646
Epoch 3/10, Batch 130/145, Loss: 0.2219
Epoch 3/10, Batch 140/145, Loss: 0.1643
Epoch 3/10, Train Loss: 0.3097, Valid Loss: 0.2603
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1529
Epoch 4/10, Batch 20/145, Loss: 0.1951
Epoch 4/10, Batch 30/145, Loss: 0.2264
Epoch 4/10, Batch 40/145, Loss: 0.3275
Epoch 4/10, Batch 50/145, Loss: 0.1677
Epoch 4/10, Batch 60/145, Loss: 0.1769
Epoch 4/10, Batch 70/145, Loss: 0.1479
Epoch 4/10, Batch 80/145, Loss: 0.3179
Epoch 4/10, Batch 90/145, Loss: 0.3109
Epoch 4/10, Batch 100/145, Loss: 0.1846
Epoch 4/10, Batch 110/145, Loss: 0.2842
Epoch 4/10, Batch 120/145, Loss: 0.2578
Epoch 4/10, Batch 130/145, Loss: 0.2048
Epoch 4/10, Batch 140/145, Loss: 0.2909
Epoch 4/10, Train Loss: 0.2691, Valid Loss: 0.2466
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1663
Epoch 5/10, Batch 20/145, Loss: 0.3136
Epoch 5/10, Batch 30/145, Loss: 0.1487
Epoch 5/10, Batch 40/145, Loss: 0.2828
Epoch 5/10, Batch 50/145, Loss: 0.2852
Epoch 5/10, Batch 60/145, Loss: 0.1464
Epoch 5/10, Batch 70/145, Loss: 0.2390
Epoch 5/10, Batch 80/145, Loss: 0.4191
Epoch 5/10, Batch 90/145, Loss: 0.1138
Epoch 5/10, Batch 100/145, Loss: 0.2631
Epoch 5/10, Batch 110/145, Loss: 0.2029
Epoch 5/10, Batch 120/145, Loss: 0.2497
Epoch 5/10, Batch 130/145, Loss: 0.3038
Epoch 5/10, Batch 140/145, Loss: 0.3329
Epoch 5/10, Train Loss: 0.2414, Valid Loss: 0.2429
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1381
Epoch 6/10, Batch 20/145, Loss: 0.1711
Epoch 6/10, Batch 30/145, Loss: 0.3103
Epoch 6/10, Batch 40/145, Loss: 0.1351
Epoch 6/10, Batch 50/145, Loss: 0.5066
Epoch 6/10, Batch 60/145, Loss: 0.0954
Epoch 6/10, Batch 70/145, Loss: 0.2054
Epoch 6/10, Batch 80/145, Loss: 0.3873
Epoch 6/10, Batch 90/145, Loss: 0.2101
Epoch 6/10, Batch 100/145, Loss: 0.2540
Epoch 6/10, Batch 110/145, Loss: 0.1968
Epoch 6/10, Batch 120/145, Loss: 0.1953
Epoch 6/10, Batch 130/145, Loss: 0.2194
Epoch 6/10, Batch 140/145, Loss: 0.1905
Epoch 6/10, Train Loss: 0.2327, Valid Loss: 0.2440
Epoch 7/10, Batch 10/145, Loss: 0.3986
Epoch 7/10, Batch 20/145, Loss: 0.1323
Epoch 7/10, Batch 30/145, Loss: 0.1772
Epoch 7/10, Batch 40/145, Loss: 0.5106
Epoch 7/10, Batch 50/145, Loss: 0.2097
Epoch 7/10, Batch 60/145, Loss: 0.1536
Epoch 7/10, Batch 70/145, Loss: 0.2315
Epoch 7/10, Batch 80/145, Loss: 0.0700
Epoch 7/10, Batch 90/145, Loss: 0.2263
Epoch 7/10, Batch 100/145, Loss: 0.2064
Epoch 7/10, Batch 110/145, Loss: 0.1812
Epoch 7/10, Batch 120/145, Loss: 0.1476
Epoch 7/10, Batch 130/145, Loss: 0.2045
Epoch 7/10, Batch 140/145, Loss: 0.2034
Epoch 7/10, Train Loss: 0.2247, Valid Loss: 0.2304
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1985
Epoch 8/10, Batch 20/145, Loss: 0.2256
Epoch 8/10, Batch 30/145, Loss: 0.1466
Epoch 8/10, Batch 40/145, Loss: 0.2980
Epoch 8/10, Batch 50/145, Loss: 0.2974
Epoch 8/10, Batch 60/145, Loss: 0.1954
Epoch 8/10, Batch 70/145, Loss: 0.1308
Epoch 8/10, Batch 80/145, Loss: 0.1886
Epoch 8/10, Batch 90/145, Loss: 0.1262
Epoch 8/10, Batch 100/145, Loss: 0.2907
Epoch 8/10, Batch 110/145, Loss: 0.1463
Epoch 8/10, Batch 120/145, Loss: 0.1156
Epoch 8/10, Batch 130/145, Loss: 0.1147
Epoch 8/10, Batch 140/145, Loss: 0.1830
Epoch 8/10, Train Loss: 0.2159, Valid Loss: 0.2209
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3573
Epoch 9/10, Batch 20/145, Loss: 0.1758
Epoch 9/10, Batch 30/145, Loss: 0.0816
Epoch 9/10, Batch 40/145, Loss: 0.1503
Epoch 9/10, Batch 50/145, Loss: 0.1383
Epoch 9/10, Batch 60/145, Loss: 0.0943
Epoch 9/10, Batch 70/145, Loss: 0.2811
Epoch 9/10, Batch 80/145, Loss: 0.3139
Epoch 9/10, Batch 90/145, Loss: 0.2035
Epoch 9/10, Batch 100/145, Loss: 0.1831
Epoch 9/10, Batch 110/145, Loss: 0.1213
Epoch 9/10, Batch 120/145, Loss: 0.1542
Epoch 9/10, Batch 130/145, Loss: 0.2872
Epoch 9/10, Batch 140/145, Loss: 0.0862
Epoch 9/10, Train Loss: 0.2050, Valid Loss: 0.2230
Epoch 10/10, Batch 10/145, Loss: 0.1440
Epoch 10/10, Batch 20/145, Loss: 0.1416
Epoch 10/10, Batch 30/145, Loss: 0.1436
Epoch 10/10, Batch 40/145, Loss: 0.1538
Epoch 10/10, Batch 50/145, Loss: 0.2821
Epoch 10/10, Batch 60/145, Loss: 0.1895
Epoch 10/10, Batch 70/145, Loss: 0.1538
Epoch 10/10, Batch 80/145, Loss: 0.2595
Epoch 10/10, Batch 90/145, Loss: 0.1640
Epoch 10/10, Batch 100/145, Loss: 0.0884
Epoch 10/10, Batch 110/145, Loss: 0.2981
Epoch 10/10, Batch 120/145, Loss: 0.1916
Epoch 10/10, Batch 130/145, Loss: 0.2503
Epoch 10/10, Batch 140/145, Loss: 0.3418
Epoch 10/10, Train Loss: 0.2012, Valid Loss: 0.2178
Model saved!
Accuracy: 0.9182
Precision: 0.9168
Recall: 0.9182
F1-score: 0.9175
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4582
Epoch 1/10, Batch 20/145, Loss: 0.8872
Epoch 1/10, Batch 30/145, Loss: 0.8160
Epoch 1/10, Batch 40/145, Loss: 0.8500
Epoch 1/10, Batch 50/145, Loss: 0.6429
Epoch 1/10, Batch 60/145, Loss: 0.6851
Epoch 1/10, Batch 70/145, Loss: 0.5872
Epoch 1/10, Batch 80/145, Loss: 0.4573
Epoch 1/10, Batch 90/145, Loss: 0.4805
Epoch 1/10, Batch 100/145, Loss: 0.6240
Epoch 1/10, Batch 110/145, Loss: 0.3533
Epoch 1/10, Batch 120/145, Loss: 0.4711
Epoch 1/10, Batch 130/145, Loss: 0.3180
Epoch 1/10, Batch 140/145, Loss: 0.5047
Epoch 1/10, Train Loss: 0.6920, Valid Loss: 0.3582
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3229
Epoch 2/10, Batch 20/145, Loss: 0.5074
Epoch 2/10, Batch 30/145, Loss: 0.4667
Epoch 2/10, Batch 40/145, Loss: 0.5468
Epoch 2/10, Batch 50/145, Loss: 0.2644
Epoch 2/10, Batch 60/145, Loss: 0.3646
Epoch 2/10, Batch 70/145, Loss: 0.6329
Epoch 2/10, Batch 80/145, Loss: 0.4096
Epoch 2/10, Batch 90/145, Loss: 0.2280
Epoch 2/10, Batch 100/145, Loss: 0.1735
Epoch 2/10, Batch 110/145, Loss: 0.3143
Epoch 2/10, Batch 120/145, Loss: 0.3374
Epoch 2/10, Batch 130/145, Loss: 0.3353
Epoch 2/10, Batch 140/145, Loss: 0.4223
Epoch 2/10, Train Loss: 0.3666, Valid Loss: 0.2790
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2564
Epoch 3/10, Batch 20/145, Loss: 0.3563
Epoch 3/10, Batch 30/145, Loss: 0.3964
Epoch 3/10, Batch 40/145, Loss: 0.2882
Epoch 3/10, Batch 50/145, Loss: 0.2128
Epoch 3/10, Batch 60/145, Loss: 0.3126
Epoch 3/10, Batch 70/145, Loss: 0.1660
Epoch 3/10, Batch 80/145, Loss: 0.3967
Epoch 3/10, Batch 90/145, Loss: 0.6895
Epoch 3/10, Batch 100/145, Loss: 0.2676
Epoch 3/10, Batch 110/145, Loss: 0.3274
Epoch 3/10, Batch 120/145, Loss: 0.2440
Epoch 3/10, Batch 130/145, Loss: 0.2682
Epoch 3/10, Batch 140/145, Loss: 0.2025
Epoch 3/10, Train Loss: 0.3149, Valid Loss: 0.2452
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2718
Epoch 4/10, Batch 20/145, Loss: 0.2198
Epoch 4/10, Batch 30/145, Loss: 0.2364
Epoch 4/10, Batch 40/145, Loss: 0.6079
Epoch 4/10, Batch 50/145, Loss: 0.2577
Epoch 4/10, Batch 60/145, Loss: 0.2435
Epoch 4/10, Batch 70/145, Loss: 0.1335
Epoch 4/10, Batch 80/145, Loss: 0.2885
Epoch 4/10, Batch 90/145, Loss: 0.1692
Epoch 4/10, Batch 100/145, Loss: 0.1671
Epoch 4/10, Batch 110/145, Loss: 0.2150
Epoch 4/10, Batch 120/145, Loss: 0.2589
Epoch 4/10, Batch 130/145, Loss: 0.2781
Epoch 4/10, Batch 140/145, Loss: 0.2516
Epoch 4/10, Train Loss: 0.2687, Valid Loss: 0.2469
Epoch 5/10, Batch 10/145, Loss: 0.2594
Epoch 5/10, Batch 20/145, Loss: 0.2137
Epoch 5/10, Batch 30/145, Loss: 0.1495
Epoch 5/10, Batch 40/145, Loss: 0.2400
Epoch 5/10, Batch 50/145, Loss: 0.1589
Epoch 5/10, Batch 60/145, Loss: 0.1900
Epoch 5/10, Batch 70/145, Loss: 0.2647
Epoch 5/10, Batch 80/145, Loss: 0.3577
Epoch 5/10, Batch 90/145, Loss: 0.2175
Epoch 5/10, Batch 100/145, Loss: 0.1898
Epoch 5/10, Batch 110/145, Loss: 0.1802
Epoch 5/10, Batch 120/145, Loss: 0.1981
Epoch 5/10, Batch 130/145, Loss: 0.1718
Epoch 5/10, Batch 140/145, Loss: 0.2134
Epoch 5/10, Train Loss: 0.2448, Valid Loss: 0.2283
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3575
Epoch 6/10, Batch 20/145, Loss: 0.3450
Epoch 6/10, Batch 30/145, Loss: 0.3840
Epoch 6/10, Batch 40/145, Loss: 0.2107
Epoch 6/10, Batch 50/145, Loss: 0.4552
Epoch 6/10, Batch 60/145, Loss: 0.1734
Epoch 6/10, Batch 70/145, Loss: 0.2844
Epoch 6/10, Batch 80/145, Loss: 0.3613
Epoch 6/10, Batch 90/145, Loss: 0.1595
Epoch 6/10, Batch 100/145, Loss: 0.0772
Epoch 6/10, Batch 110/145, Loss: 0.1890
Epoch 6/10, Batch 120/145, Loss: 0.2756
Epoch 6/10, Batch 130/145, Loss: 0.0944
Epoch 6/10, Batch 140/145, Loss: 0.1581
Epoch 6/10, Train Loss: 0.2337, Valid Loss: 0.2294
Epoch 7/10, Batch 10/145, Loss: 0.3901
Epoch 7/10, Batch 20/145, Loss: 0.1268
Epoch 7/10, Batch 30/145, Loss: 0.2178
Epoch 7/10, Batch 40/145, Loss: 0.4686
Epoch 7/10, Batch 50/145, Loss: 0.1742
Epoch 7/10, Batch 60/145, Loss: 0.1859
Epoch 7/10, Batch 70/145, Loss: 0.4350
Epoch 7/10, Batch 80/145, Loss: 0.1092
Epoch 7/10, Batch 90/145, Loss: 0.2592
Epoch 7/10, Batch 100/145, Loss: 0.2750
Epoch 7/10, Batch 110/145, Loss: 0.1935
Epoch 7/10, Batch 120/145, Loss: 0.1136
Epoch 7/10, Batch 130/145, Loss: 0.2819
Epoch 7/10, Batch 140/145, Loss: 0.0977
Epoch 7/10, Train Loss: 0.2247, Valid Loss: 0.2145
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2686
Epoch 8/10, Batch 20/145, Loss: 0.2686
Epoch 8/10, Batch 30/145, Loss: 0.2224
Epoch 8/10, Batch 40/145, Loss: 0.3300
Epoch 8/10, Batch 50/145, Loss: 0.3027
Epoch 8/10, Batch 60/145, Loss: 0.1605
Epoch 8/10, Batch 70/145, Loss: 0.2910
Epoch 8/10, Batch 80/145, Loss: 0.3728
Epoch 8/10, Batch 90/145, Loss: 0.1720
Epoch 8/10, Batch 100/145, Loss: 0.2032
Epoch 8/10, Batch 110/145, Loss: 0.3308
Epoch 8/10, Batch 120/145, Loss: 0.1103
Epoch 8/10, Batch 130/145, Loss: 0.1207
Epoch 8/10, Batch 140/145, Loss: 0.5062
Epoch 8/10, Train Loss: 0.2134, Valid Loss: 0.2129
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1298
Epoch 9/10, Batch 20/145, Loss: 0.1797
Epoch 9/10, Batch 30/145, Loss: 0.0704
Epoch 9/10, Batch 40/145, Loss: 0.1884
Epoch 9/10, Batch 50/145, Loss: 0.3002
Epoch 9/10, Batch 60/145, Loss: 0.1685
Epoch 9/10, Batch 70/145, Loss: 0.3308
Epoch 9/10, Batch 80/145, Loss: 0.2501
Epoch 9/10, Batch 90/145, Loss: 0.2211
Epoch 9/10, Batch 100/145, Loss: 0.3392
Epoch 9/10, Batch 110/145, Loss: 0.0989
Epoch 9/10, Batch 120/145, Loss: 0.1572
Epoch 9/10, Batch 130/145, Loss: 0.2108
Epoch 9/10, Batch 140/145, Loss: 0.1227
Epoch 9/10, Train Loss: 0.2050, Valid Loss: 0.1993
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.3233
Epoch 10/10, Batch 20/145, Loss: 0.1384
Epoch 10/10, Batch 30/145, Loss: 0.0879
Epoch 10/10, Batch 40/145, Loss: 0.2652
Epoch 10/10, Batch 50/145, Loss: 0.3851
Epoch 10/10, Batch 60/145, Loss: 0.2115
Epoch 10/10, Batch 70/145, Loss: 0.1504
Epoch 10/10, Batch 80/145, Loss: 0.5554
Epoch 10/10, Batch 90/145, Loss: 0.1852
Epoch 10/10, Batch 100/145, Loss: 0.1657
Epoch 10/10, Batch 110/145, Loss: 0.2352
Epoch 10/10, Batch 120/145, Loss: 0.2798
Epoch 10/10, Batch 130/145, Loss: 0.0746
Epoch 10/10, Batch 140/145, Loss: 0.1993
Epoch 10/10, Train Loss: 0.2055, Valid Loss: 0.1974
Model saved!
Accuracy: 0.9229
Precision: 0.9211
Recall: 0.9229
F1-score: 0.9216
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 2. Fitness: 0.9229
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4384
Epoch 1/10, Batch 20/145, Loss: 0.8804
Epoch 1/10, Batch 30/145, Loss: 0.8698
Epoch 1/10, Batch 40/145, Loss: 0.7967
Epoch 1/10, Batch 50/145, Loss: 0.6437
Epoch 1/10, Batch 60/145, Loss: 0.6346
Epoch 1/10, Batch 70/145, Loss: 0.5572
Epoch 1/10, Batch 80/145, Loss: 0.5815
Epoch 1/10, Batch 90/145, Loss: 0.3398
Epoch 1/10, Batch 100/145, Loss: 0.5209
Epoch 1/10, Batch 110/145, Loss: 0.3896
Epoch 1/10, Batch 120/145, Loss: 0.6252
Epoch 1/10, Batch 130/145, Loss: 0.2892
Epoch 1/10, Batch 140/145, Loss: 0.2431
Epoch 1/10, Train Loss: 0.6850, Valid Loss: 0.3947
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4429
Epoch 2/10, Batch 20/145, Loss: 0.5452
Epoch 2/10, Batch 30/145, Loss: 0.3527
Epoch 2/10, Batch 40/145, Loss: 0.4582
Epoch 2/10, Batch 50/145, Loss: 0.1620
Epoch 2/10, Batch 60/145, Loss: 0.3909
Epoch 2/10, Batch 70/145, Loss: 0.3869
Epoch 2/10, Batch 80/145, Loss: 0.3351
Epoch 2/10, Batch 90/145, Loss: 0.3799
Epoch 2/10, Batch 100/145, Loss: 0.1621
Epoch 2/10, Batch 110/145, Loss: 0.2023
Epoch 2/10, Batch 120/145, Loss: 0.4759
Epoch 2/10, Batch 130/145, Loss: 0.3736
Epoch 2/10, Batch 140/145, Loss: 0.3033
Epoch 2/10, Train Loss: 0.3622, Valid Loss: 0.3123
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3681
Epoch 3/10, Batch 20/145, Loss: 0.2106
Epoch 3/10, Batch 30/145, Loss: 0.2422
Epoch 3/10, Batch 40/145, Loss: 0.1784
Epoch 3/10, Batch 50/145, Loss: 0.2302
Epoch 3/10, Batch 60/145, Loss: 0.2573
Epoch 3/10, Batch 70/145, Loss: 0.3501
Epoch 3/10, Batch 80/145, Loss: 0.2272
Epoch 3/10, Batch 90/145, Loss: 0.5835
Epoch 3/10, Batch 100/145, Loss: 0.3888
Epoch 3/10, Batch 110/145, Loss: 0.1955
Epoch 3/10, Batch 120/145, Loss: 0.1321
Epoch 3/10, Batch 130/145, Loss: 0.2666
Epoch 3/10, Batch 140/145, Loss: 0.3977
Epoch 3/10, Train Loss: 0.3099, Valid Loss: 0.2854
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3071
Epoch 4/10, Batch 20/145, Loss: 0.3359
Epoch 4/10, Batch 30/145, Loss: 0.2112
Epoch 4/10, Batch 40/145, Loss: 0.3241
Epoch 4/10, Batch 50/145, Loss: 0.2325
Epoch 4/10, Batch 60/145, Loss: 0.2489
Epoch 4/10, Batch 70/145, Loss: 0.1936
Epoch 4/10, Batch 80/145, Loss: 0.2393
Epoch 4/10, Batch 90/145, Loss: 0.3192
Epoch 4/10, Batch 100/145, Loss: 0.1873
Epoch 4/10, Batch 110/145, Loss: 0.2349
Epoch 4/10, Batch 120/145, Loss: 0.3267
Epoch 4/10, Batch 130/145, Loss: 0.1887
Epoch 4/10, Batch 140/145, Loss: 0.4154
Epoch 4/10, Train Loss: 0.2641, Valid Loss: 0.2743
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1681
Epoch 5/10, Batch 20/145, Loss: 0.2211
Epoch 5/10, Batch 30/145, Loss: 0.1919
Epoch 5/10, Batch 40/145, Loss: 0.2381
Epoch 5/10, Batch 50/145, Loss: 0.1719
Epoch 5/10, Batch 60/145, Loss: 0.2225
Epoch 5/10, Batch 70/145, Loss: 0.2475
Epoch 5/10, Batch 80/145, Loss: 0.2861
Epoch 5/10, Batch 90/145, Loss: 0.2225
Epoch 5/10, Batch 100/145, Loss: 0.1637
Epoch 5/10, Batch 110/145, Loss: 0.1719
Epoch 5/10, Batch 120/145, Loss: 0.1819
Epoch 5/10, Batch 130/145, Loss: 0.2548
Epoch 5/10, Batch 140/145, Loss: 0.1555
Epoch 5/10, Train Loss: 0.2403, Valid Loss: 0.2660
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1982
Epoch 6/10, Batch 20/145, Loss: 0.2100
Epoch 6/10, Batch 30/145, Loss: 0.3098
Epoch 6/10, Batch 40/145, Loss: 0.2770
Epoch 6/10, Batch 50/145, Loss: 0.3356
Epoch 6/10, Batch 60/145, Loss: 0.1489
Epoch 6/10, Batch 70/145, Loss: 0.4337
Epoch 6/10, Batch 80/145, Loss: 0.3017
Epoch 6/10, Batch 90/145, Loss: 0.1282
Epoch 6/10, Batch 100/145, Loss: 0.1628
Epoch 6/10, Batch 110/145, Loss: 0.1985
Epoch 6/10, Batch 120/145, Loss: 0.3487
Epoch 6/10, Batch 130/145, Loss: 0.1470
Epoch 6/10, Batch 140/145, Loss: 0.3504
Epoch 6/10, Train Loss: 0.2294, Valid Loss: 0.2587
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.4405
Epoch 7/10, Batch 20/145, Loss: 0.1731
Epoch 7/10, Batch 30/145, Loss: 0.1317
Epoch 7/10, Batch 40/145, Loss: 0.2312
Epoch 7/10, Batch 50/145, Loss: 0.1959
Epoch 7/10, Batch 60/145, Loss: 0.2250
Epoch 7/10, Batch 70/145, Loss: 0.2099
Epoch 7/10, Batch 80/145, Loss: 0.0812
Epoch 7/10, Batch 90/145, Loss: 0.2504
Epoch 7/10, Batch 100/145, Loss: 0.1456
Epoch 7/10, Batch 110/145, Loss: 0.1544
Epoch 7/10, Batch 120/145, Loss: 0.1342
Epoch 7/10, Batch 130/145, Loss: 0.3004
Epoch 7/10, Batch 140/145, Loss: 0.2025
Epoch 7/10, Train Loss: 0.2143, Valid Loss: 0.2655
Epoch 8/10, Batch 10/145, Loss: 0.1345
Epoch 8/10, Batch 20/145, Loss: 0.1579
Epoch 8/10, Batch 30/145, Loss: 0.1948
Epoch 8/10, Batch 40/145, Loss: 0.3154
Epoch 8/10, Batch 50/145, Loss: 0.2320
Epoch 8/10, Batch 60/145, Loss: 0.1110
Epoch 8/10, Batch 70/145, Loss: 0.1299
Epoch 8/10, Batch 80/145, Loss: 0.2397
Epoch 8/10, Batch 90/145, Loss: 0.1774
Epoch 8/10, Batch 100/145, Loss: 0.1278
Epoch 8/10, Batch 110/145, Loss: 0.2917
Epoch 8/10, Batch 120/145, Loss: 0.1490
Epoch 8/10, Batch 130/145, Loss: 0.1943
Epoch 8/10, Batch 140/145, Loss: 0.1534
Epoch 8/10, Train Loss: 0.2084, Valid Loss: 0.2506
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2351
Epoch 9/10, Batch 20/145, Loss: 0.1274
Epoch 9/10, Batch 30/145, Loss: 0.1599
Epoch 9/10, Batch 40/145, Loss: 0.1699
Epoch 9/10, Batch 50/145, Loss: 0.1642
Epoch 9/10, Batch 60/145, Loss: 0.1243
Epoch 9/10, Batch 70/145, Loss: 0.1487
Epoch 9/10, Batch 80/145, Loss: 0.2327
Epoch 9/10, Batch 90/145, Loss: 0.1214
Epoch 9/10, Batch 100/145, Loss: 0.2739
Epoch 9/10, Batch 110/145, Loss: 0.1275
Epoch 9/10, Batch 120/145, Loss: 0.0685
Epoch 9/10, Batch 130/145, Loss: 0.2763
Epoch 9/10, Batch 140/145, Loss: 0.0927
Epoch 9/10, Train Loss: 0.1990, Valid Loss: 0.2613
Epoch 10/10, Batch 10/145, Loss: 0.1411
Epoch 10/10, Batch 20/145, Loss: 0.1562
Epoch 10/10, Batch 30/145, Loss: 0.0648
Epoch 10/10, Batch 40/145, Loss: 0.2017
Epoch 10/10, Batch 50/145, Loss: 0.1139
Epoch 10/10, Batch 60/145, Loss: 0.2420
Epoch 10/10, Batch 70/145, Loss: 0.1110
Epoch 10/10, Batch 80/145, Loss: 0.3258
Epoch 10/10, Batch 90/145, Loss: 0.1448
Epoch 10/10, Batch 100/145, Loss: 0.2300
Epoch 10/10, Batch 110/145, Loss: 0.4029
Epoch 10/10, Batch 120/145, Loss: 0.2248
Epoch 10/10, Batch 130/145, Loss: 0.2079
Epoch 10/10, Batch 140/145, Loss: 0.1422
Epoch 10/10, Train Loss: 0.1895, Valid Loss: 0.2455
Model saved!
Accuracy: 0.9182
Precision: 0.9161
Recall: 0.9182
F1-score: 0.9168
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5162
Epoch 1/10, Batch 20/145, Loss: 0.9231
Epoch 1/10, Batch 30/145, Loss: 0.8905
Epoch 1/10, Batch 40/145, Loss: 0.7172
Epoch 1/10, Batch 50/145, Loss: 0.7133
Epoch 1/10, Batch 60/145, Loss: 0.5415
Epoch 1/10, Batch 70/145, Loss: 0.6507
Epoch 1/10, Batch 80/145, Loss: 0.4919
Epoch 1/10, Batch 90/145, Loss: 0.5125
Epoch 1/10, Batch 100/145, Loss: 0.5474
Epoch 1/10, Batch 110/145, Loss: 0.3748
Epoch 1/10, Batch 120/145, Loss: 0.6399
Epoch 1/10, Batch 130/145, Loss: 0.2934
Epoch 1/10, Batch 140/145, Loss: 0.2757
Epoch 1/10, Train Loss: 0.6901, Valid Loss: 0.3815
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3115
Epoch 2/10, Batch 20/145, Loss: 0.4692
Epoch 2/10, Batch 30/145, Loss: 0.3414
Epoch 2/10, Batch 40/145, Loss: 0.4659
Epoch 2/10, Batch 50/145, Loss: 0.2958
Epoch 2/10, Batch 60/145, Loss: 0.4658
Epoch 2/10, Batch 70/145, Loss: 0.3673
Epoch 2/10, Batch 80/145, Loss: 0.2546
Epoch 2/10, Batch 90/145, Loss: 0.3363
Epoch 2/10, Batch 100/145, Loss: 0.3081
Epoch 2/10, Batch 110/145, Loss: 0.3120
Epoch 2/10, Batch 120/145, Loss: 0.4398
Epoch 2/10, Batch 130/145, Loss: 0.3178
Epoch 2/10, Batch 140/145, Loss: 0.2479
Epoch 2/10, Train Loss: 0.3648, Valid Loss: 0.2887
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.4467
Epoch 3/10, Batch 20/145, Loss: 0.2128
Epoch 3/10, Batch 30/145, Loss: 0.2331
Epoch 3/10, Batch 40/145, Loss: 0.2960
Epoch 3/10, Batch 50/145, Loss: 0.2446
Epoch 3/10, Batch 60/145, Loss: 0.2275
Epoch 3/10, Batch 70/145, Loss: 0.3065
Epoch 3/10, Batch 80/145, Loss: 0.3234
Epoch 3/10, Batch 90/145, Loss: 0.6147
Epoch 3/10, Batch 100/145, Loss: 0.2779
Epoch 3/10, Batch 110/145, Loss: 0.1891
Epoch 3/10, Batch 120/145, Loss: 0.2762
Epoch 3/10, Batch 130/145, Loss: 0.1652
Epoch 3/10, Batch 140/145, Loss: 0.1992
Epoch 3/10, Train Loss: 0.3092, Valid Loss: 0.2521
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1695
Epoch 4/10, Batch 20/145, Loss: 0.2357
Epoch 4/10, Batch 30/145, Loss: 0.2622
Epoch 4/10, Batch 40/145, Loss: 0.3800
Epoch 4/10, Batch 50/145, Loss: 0.4086
Epoch 4/10, Batch 60/145, Loss: 0.1162
Epoch 4/10, Batch 70/145, Loss: 0.1632
Epoch 4/10, Batch 80/145, Loss: 0.3937
Epoch 4/10, Batch 90/145, Loss: 0.1312
Epoch 4/10, Batch 100/145, Loss: 0.1796
Epoch 4/10, Batch 110/145, Loss: 0.1809
Epoch 4/10, Batch 120/145, Loss: 0.1675
Epoch 4/10, Batch 130/145, Loss: 0.2575
Epoch 4/10, Batch 140/145, Loss: 0.2327
Epoch 4/10, Train Loss: 0.2646, Valid Loss: 0.2342
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2820
Epoch 5/10, Batch 20/145, Loss: 0.2811
Epoch 5/10, Batch 30/145, Loss: 0.1696
Epoch 5/10, Batch 40/145, Loss: 0.1908
Epoch 5/10, Batch 50/145, Loss: 0.1513
Epoch 5/10, Batch 60/145, Loss: 0.2603
Epoch 5/10, Batch 70/145, Loss: 0.3513
Epoch 5/10, Batch 80/145, Loss: 0.2683
Epoch 5/10, Batch 90/145, Loss: 0.2227
Epoch 5/10, Batch 100/145, Loss: 0.1902
Epoch 5/10, Batch 110/145, Loss: 0.2073
Epoch 5/10, Batch 120/145, Loss: 0.1628
Epoch 5/10, Batch 130/145, Loss: 0.1639
Epoch 5/10, Batch 140/145, Loss: 0.2694
Epoch 5/10, Train Loss: 0.2438, Valid Loss: 0.2236
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1327
Epoch 6/10, Batch 20/145, Loss: 0.2201
Epoch 6/10, Batch 30/145, Loss: 0.2708
Epoch 6/10, Batch 40/145, Loss: 0.2345
Epoch 6/10, Batch 50/145, Loss: 0.2645
Epoch 6/10, Batch 60/145, Loss: 0.2445
Epoch 6/10, Batch 70/145, Loss: 0.2528
Epoch 6/10, Batch 80/145, Loss: 0.2501
Epoch 6/10, Batch 90/145, Loss: 0.2323
Epoch 6/10, Batch 100/145, Loss: 0.2514
Epoch 6/10, Batch 110/145, Loss: 0.2426
Epoch 6/10, Batch 120/145, Loss: 0.2563
Epoch 6/10, Batch 130/145, Loss: 0.0885
Epoch 6/10, Batch 140/145, Loss: 0.1782
Epoch 6/10, Train Loss: 0.2302, Valid Loss: 0.2242
Epoch 7/10, Batch 10/145, Loss: 0.4967
Epoch 7/10, Batch 20/145, Loss: 0.1726
Epoch 7/10, Batch 30/145, Loss: 0.1245
Epoch 7/10, Batch 40/145, Loss: 0.3865
Epoch 7/10, Batch 50/145, Loss: 0.1137
Epoch 7/10, Batch 60/145, Loss: 0.2271
Epoch 7/10, Batch 70/145, Loss: 0.2719
Epoch 7/10, Batch 80/145, Loss: 0.1631
Epoch 7/10, Batch 90/145, Loss: 0.2441
Epoch 7/10, Batch 100/145, Loss: 0.2207
Epoch 7/10, Batch 110/145, Loss: 0.2624
Epoch 7/10, Batch 120/145, Loss: 0.1764
Epoch 7/10, Batch 130/145, Loss: 0.2423
Epoch 7/10, Batch 140/145, Loss: 0.0891
Epoch 7/10, Train Loss: 0.2247, Valid Loss: 0.2154
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.3208
Epoch 8/10, Batch 20/145, Loss: 0.2028
Epoch 8/10, Batch 30/145, Loss: 0.0860
Epoch 8/10, Batch 40/145, Loss: 0.2323
Epoch 8/10, Batch 50/145, Loss: 0.1890
Epoch 8/10, Batch 60/145, Loss: 0.1931
Epoch 8/10, Batch 70/145, Loss: 0.1449
Epoch 8/10, Batch 80/145, Loss: 0.2130
Epoch 8/10, Batch 90/145, Loss: 0.1880
Epoch 8/10, Batch 100/145, Loss: 0.2495
Epoch 8/10, Batch 110/145, Loss: 0.2018
Epoch 8/10, Batch 120/145, Loss: 0.3496
Epoch 8/10, Batch 130/145, Loss: 0.1672
Epoch 8/10, Batch 140/145, Loss: 0.2962
Epoch 8/10, Train Loss: 0.2094, Valid Loss: 0.2082
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1988
Epoch 9/10, Batch 20/145, Loss: 0.0911
Epoch 9/10, Batch 30/145, Loss: 0.1238
Epoch 9/10, Batch 40/145, Loss: 0.0968
Epoch 9/10, Batch 50/145, Loss: 0.2405
Epoch 9/10, Batch 60/145, Loss: 0.2222
Epoch 9/10, Batch 70/145, Loss: 0.2459
Epoch 9/10, Batch 80/145, Loss: 0.2278
Epoch 9/10, Batch 90/145, Loss: 0.1488
Epoch 9/10, Batch 100/145, Loss: 0.3046
Epoch 9/10, Batch 110/145, Loss: 0.1203
Epoch 9/10, Batch 120/145, Loss: 0.1013
Epoch 9/10, Batch 130/145, Loss: 0.1561
Epoch 9/10, Batch 140/145, Loss: 0.0994
Epoch 9/10, Train Loss: 0.2083, Valid Loss: 0.2021
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0842
Epoch 10/10, Batch 20/145, Loss: 0.3174
Epoch 10/10, Batch 30/145, Loss: 0.1114
Epoch 10/10, Batch 40/145, Loss: 0.3406
Epoch 10/10, Batch 50/145, Loss: 0.1853
Epoch 10/10, Batch 60/145, Loss: 0.1655
Epoch 10/10, Batch 70/145, Loss: 0.2073
Epoch 10/10, Batch 80/145, Loss: 0.4526
Epoch 10/10, Batch 90/145, Loss: 0.1498
Epoch 10/10, Batch 100/145, Loss: 0.1165
Epoch 10/10, Batch 110/145, Loss: 0.3075
Epoch 10/10, Batch 120/145, Loss: 0.1614
Epoch 10/10, Batch 130/145, Loss: 0.2997
Epoch 10/10, Batch 140/145, Loss: 0.1968
Epoch 10/10, Train Loss: 0.2038, Valid Loss: 0.1958
Model saved!
Accuracy: 0.9276
Precision: 0.9259
Recall: 0.9276
F1-score: 0.9265
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 4. Fitness: 0.9276
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5105
Epoch 1/10, Batch 20/145, Loss: 0.8928
Epoch 1/10, Batch 30/145, Loss: 0.8595
Epoch 1/10, Batch 40/145, Loss: 0.8148
Epoch 1/10, Batch 50/145, Loss: 0.5480
Epoch 1/10, Batch 60/145, Loss: 0.5942
Epoch 1/10, Batch 70/145, Loss: 0.6289
Epoch 1/10, Batch 80/145, Loss: 0.6213
Epoch 1/10, Batch 90/145, Loss: 0.4714
Epoch 1/10, Batch 100/145, Loss: 0.7604
Epoch 1/10, Batch 110/145, Loss: 0.3728
Epoch 1/10, Batch 120/145, Loss: 0.6271
Epoch 1/10, Batch 130/145, Loss: 0.3995
Epoch 1/10, Batch 140/145, Loss: 0.4875
Epoch 1/10, Train Loss: 0.6875, Valid Loss: 0.3813
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3212
Epoch 2/10, Batch 20/145, Loss: 0.4999
Epoch 2/10, Batch 30/145, Loss: 0.3761
Epoch 2/10, Batch 40/145, Loss: 0.4321
Epoch 2/10, Batch 50/145, Loss: 0.3478
Epoch 2/10, Batch 60/145, Loss: 0.4030
Epoch 2/10, Batch 70/145, Loss: 0.3033
Epoch 2/10, Batch 80/145, Loss: 0.3613
Epoch 2/10, Batch 90/145, Loss: 0.2212
Epoch 2/10, Batch 100/145, Loss: 0.2634
Epoch 2/10, Batch 110/145, Loss: 0.2812
Epoch 2/10, Batch 120/145, Loss: 0.3298
Epoch 2/10, Batch 130/145, Loss: 0.3897
Epoch 2/10, Batch 140/145, Loss: 0.2567
Epoch 2/10, Train Loss: 0.3690, Valid Loss: 0.2942
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3879
Epoch 3/10, Batch 20/145, Loss: 0.2498
Epoch 3/10, Batch 30/145, Loss: 0.3237
Epoch 3/10, Batch 40/145, Loss: 0.1679
Epoch 3/10, Batch 50/145, Loss: 0.2242
Epoch 3/10, Batch 60/145, Loss: 0.2758
Epoch 3/10, Batch 70/145, Loss: 0.2195
Epoch 3/10, Batch 80/145, Loss: 0.3081
Epoch 3/10, Batch 90/145, Loss: 0.5370
Epoch 3/10, Batch 100/145, Loss: 0.3095
Epoch 3/10, Batch 110/145, Loss: 0.2496
Epoch 3/10, Batch 120/145, Loss: 0.1111
Epoch 3/10, Batch 130/145, Loss: 0.2091
Epoch 3/10, Batch 140/145, Loss: 0.1672
Epoch 3/10, Train Loss: 0.3086, Valid Loss: 0.2638
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1408
Epoch 4/10, Batch 20/145, Loss: 0.2575
Epoch 4/10, Batch 30/145, Loss: 0.2074
Epoch 4/10, Batch 40/145, Loss: 0.3152
Epoch 4/10, Batch 50/145, Loss: 0.2381
Epoch 4/10, Batch 60/145, Loss: 0.2370
Epoch 4/10, Batch 70/145, Loss: 0.3264
Epoch 4/10, Batch 80/145, Loss: 0.4103
Epoch 4/10, Batch 90/145, Loss: 0.3078
Epoch 4/10, Batch 100/145, Loss: 0.3324
Epoch 4/10, Batch 110/145, Loss: 0.2258
Epoch 4/10, Batch 120/145, Loss: 0.2196
Epoch 4/10, Batch 130/145, Loss: 0.1432
Epoch 4/10, Batch 140/145, Loss: 0.2040
Epoch 4/10, Train Loss: 0.2630, Valid Loss: 0.2565
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1656
Epoch 5/10, Batch 20/145, Loss: 0.3042
Epoch 5/10, Batch 30/145, Loss: 0.1767
Epoch 5/10, Batch 40/145, Loss: 0.2192
Epoch 5/10, Batch 50/145, Loss: 0.1145
Epoch 5/10, Batch 60/145, Loss: 0.1964
Epoch 5/10, Batch 70/145, Loss: 0.3874
Epoch 5/10, Batch 80/145, Loss: 0.2051
Epoch 5/10, Batch 90/145, Loss: 0.2527
Epoch 5/10, Batch 100/145, Loss: 0.1089
Epoch 5/10, Batch 110/145, Loss: 0.1113
Epoch 5/10, Batch 120/145, Loss: 0.1657
Epoch 5/10, Batch 130/145, Loss: 0.1715
Epoch 5/10, Batch 140/145, Loss: 0.2728
Epoch 5/10, Train Loss: 0.2412, Valid Loss: 0.2395
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1922
Epoch 6/10, Batch 20/145, Loss: 0.1764
Epoch 6/10, Batch 30/145, Loss: 0.2462
Epoch 6/10, Batch 40/145, Loss: 0.1508
Epoch 6/10, Batch 50/145, Loss: 0.2262
Epoch 6/10, Batch 60/145, Loss: 0.2065
Epoch 6/10, Batch 70/145, Loss: 0.3793
Epoch 6/10, Batch 80/145, Loss: 0.5524
Epoch 6/10, Batch 90/145, Loss: 0.1996
Epoch 6/10, Batch 100/145, Loss: 0.1469
Epoch 6/10, Batch 110/145, Loss: 0.1570
Epoch 6/10, Batch 120/145, Loss: 0.2929
Epoch 6/10, Batch 130/145, Loss: 0.1408
Epoch 6/10, Batch 140/145, Loss: 0.3005
Epoch 6/10, Train Loss: 0.2244, Valid Loss: 0.2396
Epoch 7/10, Batch 10/145, Loss: 0.2291
Epoch 7/10, Batch 20/145, Loss: 0.1483
Epoch 7/10, Batch 30/145, Loss: 0.2079
Epoch 7/10, Batch 40/145, Loss: 0.2980
Epoch 7/10, Batch 50/145, Loss: 0.1798
Epoch 7/10, Batch 60/145, Loss: 0.1044
Epoch 7/10, Batch 70/145, Loss: 0.2065
Epoch 7/10, Batch 80/145, Loss: 0.1226
Epoch 7/10, Batch 90/145, Loss: 0.2021
Epoch 7/10, Batch 100/145, Loss: 0.2242
Epoch 7/10, Batch 110/145, Loss: 0.2905
Epoch 7/10, Batch 120/145, Loss: 0.2019
Epoch 7/10, Batch 130/145, Loss: 0.3960
Epoch 7/10, Batch 140/145, Loss: 0.1516
Epoch 7/10, Train Loss: 0.2203, Valid Loss: 0.2253
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1071
Epoch 8/10, Batch 20/145, Loss: 0.2575
Epoch 8/10, Batch 30/145, Loss: 0.2494
Epoch 8/10, Batch 40/145, Loss: 0.2771
Epoch 8/10, Batch 50/145, Loss: 0.1838
Epoch 8/10, Batch 60/145, Loss: 0.1883
Epoch 8/10, Batch 70/145, Loss: 0.3028
Epoch 8/10, Batch 80/145, Loss: 0.0964
Epoch 8/10, Batch 90/145, Loss: 0.2106
Epoch 8/10, Batch 100/145, Loss: 0.2757
Epoch 8/10, Batch 110/145, Loss: 0.3501
Epoch 8/10, Batch 120/145, Loss: 0.1559
Epoch 8/10, Batch 130/145, Loss: 0.2281
Epoch 8/10, Batch 140/145, Loss: 0.1868
Epoch 8/10, Train Loss: 0.2111, Valid Loss: 0.2180
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1726
Epoch 9/10, Batch 20/145, Loss: 0.2135
Epoch 9/10, Batch 30/145, Loss: 0.1308
Epoch 9/10, Batch 40/145, Loss: 0.1422
Epoch 9/10, Batch 50/145, Loss: 0.1497
Epoch 9/10, Batch 60/145, Loss: 0.1298
Epoch 9/10, Batch 70/145, Loss: 0.1742
Epoch 9/10, Batch 80/145, Loss: 0.2433
Epoch 9/10, Batch 90/145, Loss: 0.1600
Epoch 9/10, Batch 100/145, Loss: 0.2286
Epoch 9/10, Batch 110/145, Loss: 0.1508
Epoch 9/10, Batch 120/145, Loss: 0.1539
Epoch 9/10, Batch 130/145, Loss: 0.2074
Epoch 9/10, Batch 140/145, Loss: 0.1332
Epoch 9/10, Train Loss: 0.2007, Valid Loss: 0.2166
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1905
Epoch 10/10, Batch 20/145, Loss: 0.1505
Epoch 10/10, Batch 30/145, Loss: 0.0609
Epoch 10/10, Batch 40/145, Loss: 0.1529
Epoch 10/10, Batch 50/145, Loss: 0.2761
Epoch 10/10, Batch 60/145, Loss: 0.3418
Epoch 10/10, Batch 70/145, Loss: 0.1159
Epoch 10/10, Batch 80/145, Loss: 0.4581
Epoch 10/10, Batch 90/145, Loss: 0.0959
Epoch 10/10, Batch 100/145, Loss: 0.1769
Epoch 10/10, Batch 110/145, Loss: 0.1207
Epoch 10/10, Batch 120/145, Loss: 0.2084
Epoch 10/10, Batch 130/145, Loss: 0.3002
Epoch 10/10, Batch 140/145, Loss: 0.2740
Epoch 10/10, Train Loss: 0.1929, Valid Loss: 0.2138
Model saved!
Accuracy: 0.9287
Precision: 0.9279
Recall: 0.9287
F1-score: 0.9283
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 5. Fitness: 0.9287
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4353
Epoch 1/10, Batch 20/145, Loss: 0.8974
Epoch 1/10, Batch 30/145, Loss: 0.8483
Epoch 1/10, Batch 40/145, Loss: 0.7304
Epoch 1/10, Batch 50/145, Loss: 0.5822
Epoch 1/10, Batch 60/145, Loss: 0.6642
Epoch 1/10, Batch 70/145, Loss: 0.5411
Epoch 1/10, Batch 80/145, Loss: 0.5680
Epoch 1/10, Batch 90/145, Loss: 0.5800
Epoch 1/10, Batch 100/145, Loss: 0.5522
Epoch 1/10, Batch 110/145, Loss: 0.5593
Epoch 1/10, Batch 120/145, Loss: 0.5962
Epoch 1/10, Batch 130/145, Loss: 0.3281
Epoch 1/10, Batch 140/145, Loss: 0.4143
Epoch 1/10, Train Loss: 0.6845, Valid Loss: 0.3835
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4501
Epoch 2/10, Batch 20/145, Loss: 0.4879
Epoch 2/10, Batch 30/145, Loss: 0.3625
Epoch 2/10, Batch 40/145, Loss: 0.4004
Epoch 2/10, Batch 50/145, Loss: 0.2315
Epoch 2/10, Batch 60/145, Loss: 0.5175
Epoch 2/10, Batch 70/145, Loss: 0.3502
Epoch 2/10, Batch 80/145, Loss: 0.2968
Epoch 2/10, Batch 90/145, Loss: 0.3736
Epoch 2/10, Batch 100/145, Loss: 0.2394
Epoch 2/10, Batch 110/145, Loss: 0.2025
Epoch 2/10, Batch 120/145, Loss: 0.3290
Epoch 2/10, Batch 130/145, Loss: 0.3547
Epoch 2/10, Batch 140/145, Loss: 0.1437
Epoch 2/10, Train Loss: 0.3559, Valid Loss: 0.2949
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3571
Epoch 3/10, Batch 20/145, Loss: 0.3186
Epoch 3/10, Batch 30/145, Loss: 0.3906
Epoch 3/10, Batch 40/145, Loss: 0.3181
Epoch 3/10, Batch 50/145, Loss: 0.1706
Epoch 3/10, Batch 60/145, Loss: 0.2837
Epoch 3/10, Batch 70/145, Loss: 0.2029
Epoch 3/10, Batch 80/145, Loss: 0.2844
Epoch 3/10, Batch 90/145, Loss: 0.4809
Epoch 3/10, Batch 100/145, Loss: 0.2434
Epoch 3/10, Batch 110/145, Loss: 0.1680
Epoch 3/10, Batch 120/145, Loss: 0.3379
Epoch 3/10, Batch 130/145, Loss: 0.2889
Epoch 3/10, Batch 140/145, Loss: 0.2441
Epoch 3/10, Train Loss: 0.3034, Valid Loss: 0.2611
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1613
Epoch 4/10, Batch 20/145, Loss: 0.1568
Epoch 4/10, Batch 30/145, Loss: 0.3693
Epoch 4/10, Batch 40/145, Loss: 0.4440
Epoch 4/10, Batch 50/145, Loss: 0.4028
Epoch 4/10, Batch 60/145, Loss: 0.2310
Epoch 4/10, Batch 70/145, Loss: 0.2437
Epoch 4/10, Batch 80/145, Loss: 0.3545
Epoch 4/10, Batch 90/145, Loss: 0.1863
Epoch 4/10, Batch 100/145, Loss: 0.2132
Epoch 4/10, Batch 110/145, Loss: 0.1514
Epoch 4/10, Batch 120/145, Loss: 0.3091
Epoch 4/10, Batch 130/145, Loss: 0.1459
Epoch 4/10, Batch 140/145, Loss: 0.2457
Epoch 4/10, Train Loss: 0.2637, Valid Loss: 0.2485
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2726
Epoch 5/10, Batch 20/145, Loss: 0.1996
Epoch 5/10, Batch 30/145, Loss: 0.1697
Epoch 5/10, Batch 40/145, Loss: 0.2881
Epoch 5/10, Batch 50/145, Loss: 0.1361
Epoch 5/10, Batch 60/145, Loss: 0.4181
Epoch 5/10, Batch 70/145, Loss: 0.3051
Epoch 5/10, Batch 80/145, Loss: 0.2626
Epoch 5/10, Batch 90/145, Loss: 0.1945
Epoch 5/10, Batch 100/145, Loss: 0.2647
Epoch 5/10, Batch 110/145, Loss: 0.1205
Epoch 5/10, Batch 120/145, Loss: 0.2812
Epoch 5/10, Batch 130/145, Loss: 0.1773
Epoch 5/10, Batch 140/145, Loss: 0.3092
Epoch 5/10, Train Loss: 0.2424, Valid Loss: 0.2425
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2621
Epoch 6/10, Batch 20/145, Loss: 0.2193
Epoch 6/10, Batch 30/145, Loss: 0.2022
Epoch 6/10, Batch 40/145, Loss: 0.1160
Epoch 6/10, Batch 50/145, Loss: 0.2377
Epoch 6/10, Batch 60/145, Loss: 0.2103
Epoch 6/10, Batch 70/145, Loss: 0.2092
Epoch 6/10, Batch 80/145, Loss: 0.5298
Epoch 6/10, Batch 90/145, Loss: 0.2993
Epoch 6/10, Batch 100/145, Loss: 0.1802
Epoch 6/10, Batch 110/145, Loss: 0.2348
Epoch 6/10, Batch 120/145, Loss: 0.1631
Epoch 6/10, Batch 130/145, Loss: 0.1091
Epoch 6/10, Batch 140/145, Loss: 0.4060
Epoch 6/10, Train Loss: 0.2293, Valid Loss: 0.2242
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1800
Epoch 7/10, Batch 20/145, Loss: 0.1429
Epoch 7/10, Batch 30/145, Loss: 0.1531
Epoch 7/10, Batch 40/145, Loss: 0.6808
Epoch 7/10, Batch 50/145, Loss: 0.1411
Epoch 7/10, Batch 60/145, Loss: 0.2519
Epoch 7/10, Batch 70/145, Loss: 0.2206
Epoch 7/10, Batch 80/145, Loss: 0.2222
Epoch 7/10, Batch 90/145, Loss: 0.2051
Epoch 7/10, Batch 100/145, Loss: 0.2094
Epoch 7/10, Batch 110/145, Loss: 0.1669
Epoch 7/10, Batch 120/145, Loss: 0.1572
Epoch 7/10, Batch 130/145, Loss: 0.1373
Epoch 7/10, Batch 140/145, Loss: 0.1682
Epoch 7/10, Train Loss: 0.2174, Valid Loss: 0.2317
Epoch 8/10, Batch 10/145, Loss: 0.0950
Epoch 8/10, Batch 20/145, Loss: 0.1697
Epoch 8/10, Batch 30/145, Loss: 0.1058
Epoch 8/10, Batch 40/145, Loss: 0.0985
Epoch 8/10, Batch 50/145, Loss: 0.2779
Epoch 8/10, Batch 60/145, Loss: 0.3190
Epoch 8/10, Batch 70/145, Loss: 0.1776
Epoch 8/10, Batch 80/145, Loss: 0.3400
Epoch 8/10, Batch 90/145, Loss: 0.1925
Epoch 8/10, Batch 100/145, Loss: 0.3178
Epoch 8/10, Batch 110/145, Loss: 0.2561
Epoch 8/10, Batch 120/145, Loss: 0.2635
Epoch 8/10, Batch 130/145, Loss: 0.1819
Epoch 8/10, Batch 140/145, Loss: 0.3020
Epoch 8/10, Train Loss: 0.2126, Valid Loss: 0.2202
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3774
Epoch 9/10, Batch 20/145, Loss: 0.2067
Epoch 9/10, Batch 30/145, Loss: 0.1984
Epoch 9/10, Batch 40/145, Loss: 0.1430
Epoch 9/10, Batch 50/145, Loss: 0.3083
Epoch 9/10, Batch 60/145, Loss: 0.2008
Epoch 9/10, Batch 70/145, Loss: 0.2092
Epoch 9/10, Batch 80/145, Loss: 0.2487
Epoch 9/10, Batch 90/145, Loss: 0.3996
Epoch 9/10, Batch 100/145, Loss: 0.2041
Epoch 9/10, Batch 110/145, Loss: 0.0897
Epoch 9/10, Batch 120/145, Loss: 0.2934
Epoch 9/10, Batch 130/145, Loss: 0.2280
Epoch 9/10, Batch 140/145, Loss: 0.1599
Epoch 9/10, Train Loss: 0.2094, Valid Loss: 0.2170
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1501
Epoch 10/10, Batch 20/145, Loss: 0.1074
Epoch 10/10, Batch 30/145, Loss: 0.0755
Epoch 10/10, Batch 40/145, Loss: 0.2969
Epoch 10/10, Batch 50/145, Loss: 0.3177
Epoch 10/10, Batch 60/145, Loss: 0.2047
Epoch 10/10, Batch 70/145, Loss: 0.1496
Epoch 10/10, Batch 80/145, Loss: 0.1876
Epoch 10/10, Batch 90/145, Loss: 0.3731
Epoch 10/10, Batch 100/145, Loss: 0.1967
Epoch 10/10, Batch 110/145, Loss: 0.1727
Epoch 10/10, Batch 120/145, Loss: 0.1507
Epoch 10/10, Batch 130/145, Loss: 0.1671
Epoch 10/10, Batch 140/145, Loss: 0.1768
Epoch 10/10, Train Loss: 0.1976, Valid Loss: 0.2244
Accuracy: 0.9276
Precision: 0.9272
Recall: 0.9276
F1-score: 0.9267
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5469
Epoch 1/10, Batch 20/145, Loss: 0.9923
Epoch 1/10, Batch 30/145, Loss: 0.8589
Epoch 1/10, Batch 40/145, Loss: 0.7980
Epoch 1/10, Batch 50/145, Loss: 0.6335
Epoch 1/10, Batch 60/145, Loss: 0.4670
Epoch 1/10, Batch 70/145, Loss: 0.5145
Epoch 1/10, Batch 80/145, Loss: 0.5613
Epoch 1/10, Batch 90/145, Loss: 0.4770
Epoch 1/10, Batch 100/145, Loss: 0.4860
Epoch 1/10, Batch 110/145, Loss: 0.4301
Epoch 1/10, Batch 120/145, Loss: 0.5397
Epoch 1/10, Batch 130/145, Loss: 0.4622
Epoch 1/10, Batch 140/145, Loss: 0.4087
Epoch 1/10, Train Loss: 0.6825, Valid Loss: 0.3809
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2778
Epoch 2/10, Batch 20/145, Loss: 0.5549
Epoch 2/10, Batch 30/145, Loss: 0.3498
Epoch 2/10, Batch 40/145, Loss: 0.4479
Epoch 2/10, Batch 50/145, Loss: 0.2542
Epoch 2/10, Batch 60/145, Loss: 0.5128
Epoch 2/10, Batch 70/145, Loss: 0.4021
Epoch 2/10, Batch 80/145, Loss: 0.2182
Epoch 2/10, Batch 90/145, Loss: 0.2751
Epoch 2/10, Batch 100/145, Loss: 0.3047
Epoch 2/10, Batch 110/145, Loss: 0.3533
Epoch 2/10, Batch 120/145, Loss: 0.3944
Epoch 2/10, Batch 130/145, Loss: 0.3254
Epoch 2/10, Batch 140/145, Loss: 0.3302
Epoch 2/10, Train Loss: 0.3592, Valid Loss: 0.3054
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2342
Epoch 3/10, Batch 20/145, Loss: 0.2441
Epoch 3/10, Batch 30/145, Loss: 0.2953
Epoch 3/10, Batch 40/145, Loss: 0.3580
Epoch 3/10, Batch 50/145, Loss: 0.1973
Epoch 3/10, Batch 60/145, Loss: 0.2574
Epoch 3/10, Batch 70/145, Loss: 0.3632
Epoch 3/10, Batch 80/145, Loss: 0.2842
Epoch 3/10, Batch 90/145, Loss: 0.5015
Epoch 3/10, Batch 100/145, Loss: 0.2145
Epoch 3/10, Batch 110/145, Loss: 0.2318
Epoch 3/10, Batch 120/145, Loss: 0.2914
Epoch 3/10, Batch 130/145, Loss: 0.3361
Epoch 3/10, Batch 140/145, Loss: 0.1886
Epoch 3/10, Train Loss: 0.3073, Valid Loss: 0.2742
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3135
Epoch 4/10, Batch 20/145, Loss: 0.3048
Epoch 4/10, Batch 30/145, Loss: 0.4562
Epoch 4/10, Batch 40/145, Loss: 0.2672
Epoch 4/10, Batch 50/145, Loss: 0.1974
Epoch 4/10, Batch 60/145, Loss: 0.2757
Epoch 4/10, Batch 70/145, Loss: 0.1931
Epoch 4/10, Batch 80/145, Loss: 0.1957
Epoch 4/10, Batch 90/145, Loss: 0.2754
Epoch 4/10, Batch 100/145, Loss: 0.2515
Epoch 4/10, Batch 110/145, Loss: 0.3117
Epoch 4/10, Batch 120/145, Loss: 0.1236
Epoch 4/10, Batch 130/145, Loss: 0.2561
Epoch 4/10, Batch 140/145, Loss: 0.2242
Epoch 4/10, Train Loss: 0.2591, Valid Loss: 0.2617
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2636
Epoch 5/10, Batch 20/145, Loss: 0.4021
Epoch 5/10, Batch 30/145, Loss: 0.1024
Epoch 5/10, Batch 40/145, Loss: 0.3310
Epoch 5/10, Batch 50/145, Loss: 0.3196
Epoch 5/10, Batch 60/145, Loss: 0.1929
Epoch 5/10, Batch 70/145, Loss: 0.2887
Epoch 5/10, Batch 80/145, Loss: 0.3826
Epoch 5/10, Batch 90/145, Loss: 0.1666
Epoch 5/10, Batch 100/145, Loss: 0.1549
Epoch 5/10, Batch 110/145, Loss: 0.1268
Epoch 5/10, Batch 120/145, Loss: 0.1129
Epoch 5/10, Batch 130/145, Loss: 0.3129
Epoch 5/10, Batch 140/145, Loss: 0.2047
Epoch 5/10, Train Loss: 0.2354, Valid Loss: 0.2513
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1760
Epoch 6/10, Batch 20/145, Loss: 0.1765
Epoch 6/10, Batch 30/145, Loss: 0.1681
Epoch 6/10, Batch 40/145, Loss: 0.2401
Epoch 6/10, Batch 50/145, Loss: 0.2988
Epoch 6/10, Batch 60/145, Loss: 0.2138
Epoch 6/10, Batch 70/145, Loss: 0.2287
Epoch 6/10, Batch 80/145, Loss: 0.2987
Epoch 6/10, Batch 90/145, Loss: 0.1607
Epoch 6/10, Batch 100/145, Loss: 0.1980
Epoch 6/10, Batch 110/145, Loss: 0.1630
Epoch 6/10, Batch 120/145, Loss: 0.2620
Epoch 6/10, Batch 130/145, Loss: 0.1934
Epoch 6/10, Batch 140/145, Loss: 0.2314
Epoch 6/10, Train Loss: 0.2238, Valid Loss: 0.2804
Epoch 7/10, Batch 10/145, Loss: 0.1913
Epoch 7/10, Batch 20/145, Loss: 0.3068
Epoch 7/10, Batch 30/145, Loss: 0.2374
Epoch 7/10, Batch 40/145, Loss: 0.4341
Epoch 7/10, Batch 50/145, Loss: 0.2917
Epoch 7/10, Batch 60/145, Loss: 0.2112
Epoch 7/10, Batch 70/145, Loss: 0.1838
Epoch 7/10, Batch 80/145, Loss: 0.2273
Epoch 7/10, Batch 90/145, Loss: 0.3290
Epoch 7/10, Batch 100/145, Loss: 0.3152
Epoch 7/10, Batch 110/145, Loss: 0.1449
Epoch 7/10, Batch 120/145, Loss: 0.1804
Epoch 7/10, Batch 130/145, Loss: 0.2129
Epoch 7/10, Batch 140/145, Loss: 0.1386
Epoch 7/10, Train Loss: 0.2193, Valid Loss: 0.2501
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1523
Epoch 8/10, Batch 20/145, Loss: 0.1140
Epoch 8/10, Batch 30/145, Loss: 0.1850
Epoch 8/10, Batch 40/145, Loss: 0.2687
Epoch 8/10, Batch 50/145, Loss: 0.2317
Epoch 8/10, Batch 60/145, Loss: 0.2848
Epoch 8/10, Batch 70/145, Loss: 0.1741
Epoch 8/10, Batch 80/145, Loss: 0.1466
Epoch 8/10, Batch 90/145, Loss: 0.2431
Epoch 8/10, Batch 100/145, Loss: 0.2307
Epoch 8/10, Batch 110/145, Loss: 0.2871
Epoch 8/10, Batch 120/145, Loss: 0.1318
Epoch 8/10, Batch 130/145, Loss: 0.2740
Epoch 8/10, Batch 140/145, Loss: 0.2927
Epoch 8/10, Train Loss: 0.2084, Valid Loss: 0.2433
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2080
Epoch 9/10, Batch 20/145, Loss: 0.2863
Epoch 9/10, Batch 30/145, Loss: 0.1015
Epoch 9/10, Batch 40/145, Loss: 0.1901
Epoch 9/10, Batch 50/145, Loss: 0.1852
Epoch 9/10, Batch 60/145, Loss: 0.1358
Epoch 9/10, Batch 70/145, Loss: 0.1456
Epoch 9/10, Batch 80/145, Loss: 0.1897
Epoch 9/10, Batch 90/145, Loss: 0.1704
Epoch 9/10, Batch 100/145, Loss: 0.2008
Epoch 9/10, Batch 110/145, Loss: 0.1227
Epoch 9/10, Batch 120/145, Loss: 0.1567
Epoch 9/10, Batch 130/145, Loss: 0.2001
Epoch 9/10, Batch 140/145, Loss: 0.1784
Epoch 9/10, Train Loss: 0.2006, Valid Loss: 0.2382
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1365
Epoch 10/10, Batch 20/145, Loss: 0.1298
Epoch 10/10, Batch 30/145, Loss: 0.2307
Epoch 10/10, Batch 40/145, Loss: 0.2093
Epoch 10/10, Batch 50/145, Loss: 0.1480
Epoch 10/10, Batch 60/145, Loss: 0.1956
Epoch 10/10, Batch 70/145, Loss: 0.1597
Epoch 10/10, Batch 80/145, Loss: 0.3981
Epoch 10/10, Batch 90/145, Loss: 0.1412
Epoch 10/10, Batch 100/145, Loss: 0.0886
Epoch 10/10, Batch 110/145, Loss: 0.2100
Epoch 10/10, Batch 120/145, Loss: 0.4053
Epoch 10/10, Batch 130/145, Loss: 0.2701
Epoch 10/10, Batch 140/145, Loss: 0.2223
Epoch 10/10, Train Loss: 0.1974, Valid Loss: 0.2260
Model saved!
Accuracy: 0.9241
Precision: 0.9239
Recall: 0.9241
F1-score: 0.9239
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4488
Epoch 1/10, Batch 20/145, Loss: 0.8058
Epoch 1/10, Batch 30/145, Loss: 0.8009
Epoch 1/10, Batch 40/145, Loss: 0.8369
Epoch 1/10, Batch 50/145, Loss: 0.5999
Epoch 1/10, Batch 60/145, Loss: 0.5396
Epoch 1/10, Batch 70/145, Loss: 0.7076
Epoch 1/10, Batch 80/145, Loss: 0.4119
Epoch 1/10, Batch 90/145, Loss: 0.4259
Epoch 1/10, Batch 100/145, Loss: 0.5538
Epoch 1/10, Batch 110/145, Loss: 0.4816
Epoch 1/10, Batch 120/145, Loss: 0.6207
Epoch 1/10, Batch 130/145, Loss: 0.3636
Epoch 1/10, Batch 140/145, Loss: 0.3659
Epoch 1/10, Train Loss: 0.6890, Valid Loss: 0.3742
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2450
Epoch 2/10, Batch 20/145, Loss: 0.5180
Epoch 2/10, Batch 30/145, Loss: 0.2951
Epoch 2/10, Batch 40/145, Loss: 0.6874
Epoch 2/10, Batch 50/145, Loss: 0.2169
Epoch 2/10, Batch 60/145, Loss: 0.3395
Epoch 2/10, Batch 70/145, Loss: 0.4016
Epoch 2/10, Batch 80/145, Loss: 0.4044
Epoch 2/10, Batch 90/145, Loss: 0.4278
Epoch 2/10, Batch 100/145, Loss: 0.3939
Epoch 2/10, Batch 110/145, Loss: 0.3245
Epoch 2/10, Batch 120/145, Loss: 0.3538
Epoch 2/10, Batch 130/145, Loss: 0.4449
Epoch 2/10, Batch 140/145, Loss: 0.1947
Epoch 2/10, Train Loss: 0.3662, Valid Loss: 0.2890
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2471
Epoch 3/10, Batch 20/145, Loss: 0.3597
Epoch 3/10, Batch 30/145, Loss: 0.4384
Epoch 3/10, Batch 40/145, Loss: 0.2820
Epoch 3/10, Batch 50/145, Loss: 0.1280
Epoch 3/10, Batch 60/145, Loss: 0.4204
Epoch 3/10, Batch 70/145, Loss: 0.1257
Epoch 3/10, Batch 80/145, Loss: 0.3071
Epoch 3/10, Batch 90/145, Loss: 0.6977
Epoch 3/10, Batch 100/145, Loss: 0.3710
Epoch 3/10, Batch 110/145, Loss: 0.1740
Epoch 3/10, Batch 120/145, Loss: 0.2522
Epoch 3/10, Batch 130/145, Loss: 0.2380
Epoch 3/10, Batch 140/145, Loss: 0.2337
Epoch 3/10, Train Loss: 0.3097, Valid Loss: 0.2596
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2244
Epoch 4/10, Batch 20/145, Loss: 0.2426
Epoch 4/10, Batch 30/145, Loss: 0.3505
Epoch 4/10, Batch 40/145, Loss: 0.4772
Epoch 4/10, Batch 50/145, Loss: 0.2410
Epoch 4/10, Batch 60/145, Loss: 0.2589
Epoch 4/10, Batch 70/145, Loss: 0.1859
Epoch 4/10, Batch 80/145, Loss: 0.3406
Epoch 4/10, Batch 90/145, Loss: 0.3399
Epoch 4/10, Batch 100/145, Loss: 0.2478
Epoch 4/10, Batch 110/145, Loss: 0.2139
Epoch 4/10, Batch 120/145, Loss: 0.1913
Epoch 4/10, Batch 130/145, Loss: 0.1675
Epoch 4/10, Batch 140/145, Loss: 0.2021
Epoch 4/10, Train Loss: 0.2598, Valid Loss: 0.2501
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3199
Epoch 5/10, Batch 20/145, Loss: 0.2527
Epoch 5/10, Batch 30/145, Loss: 0.3572
Epoch 5/10, Batch 40/145, Loss: 0.3758
Epoch 5/10, Batch 50/145, Loss: 0.0967
Epoch 5/10, Batch 60/145, Loss: 0.3690
Epoch 5/10, Batch 70/145, Loss: 0.1866
Epoch 5/10, Batch 80/145, Loss: 0.2843
Epoch 5/10, Batch 90/145, Loss: 0.1772
Epoch 5/10, Batch 100/145, Loss: 0.1865
Epoch 5/10, Batch 110/145, Loss: 0.1555
Epoch 5/10, Batch 120/145, Loss: 0.2769
Epoch 5/10, Batch 130/145, Loss: 0.2561
Epoch 5/10, Batch 140/145, Loss: 0.2647
Epoch 5/10, Train Loss: 0.2448, Valid Loss: 0.2327
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1879
Epoch 6/10, Batch 20/145, Loss: 0.2607
Epoch 6/10, Batch 30/145, Loss: 0.3394
Epoch 6/10, Batch 40/145, Loss: 0.2069
Epoch 6/10, Batch 50/145, Loss: 0.3203
Epoch 6/10, Batch 60/145, Loss: 0.1929
Epoch 6/10, Batch 70/145, Loss: 0.3137
Epoch 6/10, Batch 80/145, Loss: 0.4579
Epoch 6/10, Batch 90/145, Loss: 0.2114
Epoch 6/10, Batch 100/145, Loss: 0.2924
Epoch 6/10, Batch 110/145, Loss: 0.1850
Epoch 6/10, Batch 120/145, Loss: 0.1319
Epoch 6/10, Batch 130/145, Loss: 0.1912
Epoch 6/10, Batch 140/145, Loss: 0.2248
Epoch 6/10, Train Loss: 0.2257, Valid Loss: 0.2430
Epoch 7/10, Batch 10/145, Loss: 0.3355
Epoch 7/10, Batch 20/145, Loss: 0.3466
Epoch 7/10, Batch 30/145, Loss: 0.1634
Epoch 7/10, Batch 40/145, Loss: 0.3645
Epoch 7/10, Batch 50/145, Loss: 0.1019
Epoch 7/10, Batch 60/145, Loss: 0.1893
Epoch 7/10, Batch 70/145, Loss: 0.2107
Epoch 7/10, Batch 80/145, Loss: 0.1033
Epoch 7/10, Batch 90/145, Loss: 0.1638
Epoch 7/10, Batch 100/145, Loss: 0.2251
Epoch 7/10, Batch 110/145, Loss: 0.2775
Epoch 7/10, Batch 120/145, Loss: 0.1234
Epoch 7/10, Batch 130/145, Loss: 0.3620
Epoch 7/10, Batch 140/145, Loss: 0.1525
Epoch 7/10, Train Loss: 0.2188, Valid Loss: 0.2266
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2145
Epoch 8/10, Batch 20/145, Loss: 0.1680
Epoch 8/10, Batch 30/145, Loss: 0.1804
Epoch 8/10, Batch 40/145, Loss: 0.0919
Epoch 8/10, Batch 50/145, Loss: 0.1077
Epoch 8/10, Batch 60/145, Loss: 0.2241
Epoch 8/10, Batch 70/145, Loss: 0.2206
Epoch 8/10, Batch 80/145, Loss: 0.3196
Epoch 8/10, Batch 90/145, Loss: 0.1776
Epoch 8/10, Batch 100/145, Loss: 0.2057
Epoch 8/10, Batch 110/145, Loss: 0.3699
Epoch 8/10, Batch 120/145, Loss: 0.1606
Epoch 8/10, Batch 130/145, Loss: 0.1407
Epoch 8/10, Batch 140/145, Loss: 0.3770
Epoch 8/10, Train Loss: 0.2056, Valid Loss: 0.2159
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2674
Epoch 9/10, Batch 20/145, Loss: 0.1542
Epoch 9/10, Batch 30/145, Loss: 0.0974
Epoch 9/10, Batch 40/145, Loss: 0.1343
Epoch 9/10, Batch 50/145, Loss: 0.1424
Epoch 9/10, Batch 60/145, Loss: 0.1974
Epoch 9/10, Batch 70/145, Loss: 0.0773
Epoch 9/10, Batch 80/145, Loss: 0.1264
Epoch 9/10, Batch 90/145, Loss: 0.1177
Epoch 9/10, Batch 100/145, Loss: 0.2644
Epoch 9/10, Batch 110/145, Loss: 0.1026
Epoch 9/10, Batch 120/145, Loss: 0.2447
Epoch 9/10, Batch 130/145, Loss: 0.2915
Epoch 9/10, Batch 140/145, Loss: 0.0692
Epoch 9/10, Train Loss: 0.1930, Valid Loss: 0.2063
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0793
Epoch 10/10, Batch 20/145, Loss: 0.1110
Epoch 10/10, Batch 30/145, Loss: 0.1108
Epoch 10/10, Batch 40/145, Loss: 0.2752
Epoch 10/10, Batch 50/145, Loss: 0.3089
Epoch 10/10, Batch 60/145, Loss: 0.1716
Epoch 10/10, Batch 70/145, Loss: 0.1174
Epoch 10/10, Batch 80/145, Loss: 0.3293
Epoch 10/10, Batch 90/145, Loss: 0.1475
Epoch 10/10, Batch 100/145, Loss: 0.2632
Epoch 10/10, Batch 110/145, Loss: 0.1575
Epoch 10/10, Batch 120/145, Loss: 0.2370
Epoch 10/10, Batch 130/145, Loss: 0.1738
Epoch 10/10, Batch 140/145, Loss: 0.2611
Epoch 10/10, Train Loss: 0.1973, Valid Loss: 0.2033
Model saved!
Accuracy: 0.9287
Precision: 0.9276
Recall: 0.9287
F1-score: 0.9280
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4764
Epoch 1/10, Batch 20/145, Loss: 0.8883
Epoch 1/10, Batch 30/145, Loss: 0.8075
Epoch 1/10, Batch 40/145, Loss: 0.6908
Epoch 1/10, Batch 50/145, Loss: 0.6569
Epoch 1/10, Batch 60/145, Loss: 0.5740
Epoch 1/10, Batch 70/145, Loss: 0.7565
Epoch 1/10, Batch 80/145, Loss: 0.4439
Epoch 1/10, Batch 90/145, Loss: 0.5299
Epoch 1/10, Batch 100/145, Loss: 0.4354
Epoch 1/10, Batch 110/145, Loss: 0.4505
Epoch 1/10, Batch 120/145, Loss: 0.5380
Epoch 1/10, Batch 130/145, Loss: 0.4211
Epoch 1/10, Batch 140/145, Loss: 0.3641
Epoch 1/10, Train Loss: 0.6896, Valid Loss: 0.4085
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3531
Epoch 2/10, Batch 20/145, Loss: 0.5590
Epoch 2/10, Batch 30/145, Loss: 0.2533
Epoch 2/10, Batch 40/145, Loss: 0.4276
Epoch 2/10, Batch 50/145, Loss: 0.4352
Epoch 2/10, Batch 60/145, Loss: 0.4501
Epoch 2/10, Batch 70/145, Loss: 0.3399
Epoch 2/10, Batch 80/145, Loss: 0.3355
Epoch 2/10, Batch 90/145, Loss: 0.3592
Epoch 2/10, Batch 100/145, Loss: 0.3122
Epoch 2/10, Batch 110/145, Loss: 0.4312
Epoch 2/10, Batch 120/145, Loss: 0.2904
Epoch 2/10, Batch 130/145, Loss: 0.2847
Epoch 2/10, Batch 140/145, Loss: 0.3240
Epoch 2/10, Train Loss: 0.3546, Valid Loss: 0.3226
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2045
Epoch 3/10, Batch 20/145, Loss: 0.3565
Epoch 3/10, Batch 30/145, Loss: 0.2375
Epoch 3/10, Batch 40/145, Loss: 0.3279
Epoch 3/10, Batch 50/145, Loss: 0.2210
Epoch 3/10, Batch 60/145, Loss: 0.2884
Epoch 3/10, Batch 70/145, Loss: 0.1883
Epoch 3/10, Batch 80/145, Loss: 0.2173
Epoch 3/10, Batch 90/145, Loss: 0.4215
Epoch 3/10, Batch 100/145, Loss: 0.2922
Epoch 3/10, Batch 110/145, Loss: 0.1613
Epoch 3/10, Batch 120/145, Loss: 0.2192
Epoch 3/10, Batch 130/145, Loss: 0.3370
Epoch 3/10, Batch 140/145, Loss: 0.4228
Epoch 3/10, Train Loss: 0.3019, Valid Loss: 0.2909
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2048
Epoch 4/10, Batch 20/145, Loss: 0.3138
Epoch 4/10, Batch 30/145, Loss: 0.2749
Epoch 4/10, Batch 40/145, Loss: 0.2791
Epoch 4/10, Batch 50/145, Loss: 0.1531
Epoch 4/10, Batch 60/145, Loss: 0.1124
Epoch 4/10, Batch 70/145, Loss: 0.2065
Epoch 4/10, Batch 80/145, Loss: 0.1979
Epoch 4/10, Batch 90/145, Loss: 0.1783
Epoch 4/10, Batch 100/145, Loss: 0.2225
Epoch 4/10, Batch 110/145, Loss: 0.2864
Epoch 4/10, Batch 120/145, Loss: 0.2770
Epoch 4/10, Batch 130/145, Loss: 0.3625
Epoch 4/10, Batch 140/145, Loss: 0.4456
Epoch 4/10, Train Loss: 0.2593, Valid Loss: 0.2783
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2149
Epoch 5/10, Batch 20/145, Loss: 0.2159
Epoch 5/10, Batch 30/145, Loss: 0.1479
Epoch 5/10, Batch 40/145, Loss: 0.2001
Epoch 5/10, Batch 50/145, Loss: 0.1156
Epoch 5/10, Batch 60/145, Loss: 0.2206
Epoch 5/10, Batch 70/145, Loss: 0.2941
Epoch 5/10, Batch 80/145, Loss: 0.2856
Epoch 5/10, Batch 90/145, Loss: 0.3069
Epoch 5/10, Batch 100/145, Loss: 0.4018
Epoch 5/10, Batch 110/145, Loss: 0.1456
Epoch 5/10, Batch 120/145, Loss: 0.1253
Epoch 5/10, Batch 130/145, Loss: 0.0962
Epoch 5/10, Batch 140/145, Loss: 0.2614
Epoch 5/10, Train Loss: 0.2379, Valid Loss: 0.2703
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2496
Epoch 6/10, Batch 20/145, Loss: 0.1951
Epoch 6/10, Batch 30/145, Loss: 0.3174
Epoch 6/10, Batch 40/145, Loss: 0.2980
Epoch 6/10, Batch 50/145, Loss: 0.4096
Epoch 6/10, Batch 60/145, Loss: 0.1788
Epoch 6/10, Batch 70/145, Loss: 0.2540
Epoch 6/10, Batch 80/145, Loss: 0.4073
Epoch 6/10, Batch 90/145, Loss: 0.1213
Epoch 6/10, Batch 100/145, Loss: 0.1556
Epoch 6/10, Batch 110/145, Loss: 0.1003
Epoch 6/10, Batch 120/145, Loss: 0.2116
Epoch 6/10, Batch 130/145, Loss: 0.1542
Epoch 6/10, Batch 140/145, Loss: 0.1643
Epoch 6/10, Train Loss: 0.2284, Valid Loss: 0.2636
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2866
Epoch 7/10, Batch 20/145, Loss: 0.2290
Epoch 7/10, Batch 30/145, Loss: 0.1030
Epoch 7/10, Batch 40/145, Loss: 0.5018
Epoch 7/10, Batch 50/145, Loss: 0.1584
Epoch 7/10, Batch 60/145, Loss: 0.2067
Epoch 7/10, Batch 70/145, Loss: 0.2467
Epoch 7/10, Batch 80/145, Loss: 0.2377
Epoch 7/10, Batch 90/145, Loss: 0.2203
Epoch 7/10, Batch 100/145, Loss: 0.1042
Epoch 7/10, Batch 110/145, Loss: 0.2684
Epoch 7/10, Batch 120/145, Loss: 0.2495
Epoch 7/10, Batch 130/145, Loss: 0.1491
Epoch 7/10, Batch 140/145, Loss: 0.1748
Epoch 7/10, Train Loss: 0.2166, Valid Loss: 0.2574
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2146
Epoch 8/10, Batch 20/145, Loss: 0.1399
Epoch 8/10, Batch 30/145, Loss: 0.2295
Epoch 8/10, Batch 40/145, Loss: 0.1042
Epoch 8/10, Batch 50/145, Loss: 0.2169
Epoch 8/10, Batch 60/145, Loss: 0.1825
Epoch 8/10, Batch 70/145, Loss: 0.1131
Epoch 8/10, Batch 80/145, Loss: 0.1439
Epoch 8/10, Batch 90/145, Loss: 0.2027
Epoch 8/10, Batch 100/145, Loss: 0.4339
Epoch 8/10, Batch 110/145, Loss: 0.2701
Epoch 8/10, Batch 120/145, Loss: 0.1178
Epoch 8/10, Batch 130/145, Loss: 0.4903
Epoch 8/10, Batch 140/145, Loss: 0.2368
Epoch 8/10, Train Loss: 0.2091, Valid Loss: 0.2525
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2588
Epoch 9/10, Batch 20/145, Loss: 0.0942
Epoch 9/10, Batch 30/145, Loss: 0.0894
Epoch 9/10, Batch 40/145, Loss: 0.1016
Epoch 9/10, Batch 50/145, Loss: 0.3021
Epoch 9/10, Batch 60/145, Loss: 0.1814
Epoch 9/10, Batch 70/145, Loss: 0.2901
Epoch 9/10, Batch 80/145, Loss: 0.2226
Epoch 9/10, Batch 90/145, Loss: 0.1571
Epoch 9/10, Batch 100/145, Loss: 0.1485
Epoch 9/10, Batch 110/145, Loss: 0.1482
Epoch 9/10, Batch 120/145, Loss: 0.1790
Epoch 9/10, Batch 130/145, Loss: 0.3057
Epoch 9/10, Batch 140/145, Loss: 0.1767
Epoch 9/10, Train Loss: 0.2054, Valid Loss: 0.2511
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1505
Epoch 10/10, Batch 20/145, Loss: 0.2086
Epoch 10/10, Batch 30/145, Loss: 0.1494
Epoch 10/10, Batch 40/145, Loss: 0.1618
Epoch 10/10, Batch 50/145, Loss: 0.2659
Epoch 10/10, Batch 60/145, Loss: 0.2526
Epoch 10/10, Batch 70/145, Loss: 0.1188
Epoch 10/10, Batch 80/145, Loss: 0.4256
Epoch 10/10, Batch 90/145, Loss: 0.1652
Epoch 10/10, Batch 100/145, Loss: 0.1343
Epoch 10/10, Batch 110/145, Loss: 0.1784
Epoch 10/10, Batch 120/145, Loss: 0.1971
Epoch 10/10, Batch 130/145, Loss: 0.1338
Epoch 10/10, Batch 140/145, Loss: 0.1096
Epoch 10/10, Train Loss: 0.1942, Valid Loss: 0.2454
Model saved!
Accuracy: 0.9229
Precision: 0.9230
Recall: 0.9229
F1-score: 0.9229
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5444
Epoch 1/10, Batch 20/145, Loss: 0.9109
Epoch 1/10, Batch 30/145, Loss: 0.8411
Epoch 1/10, Batch 40/145, Loss: 0.8379
Epoch 1/10, Batch 50/145, Loss: 0.6046
Epoch 1/10, Batch 60/145, Loss: 0.5473
Epoch 1/10, Batch 70/145, Loss: 0.7227
Epoch 1/10, Batch 80/145, Loss: 0.5172
Epoch 1/10, Batch 90/145, Loss: 0.5243
Epoch 1/10, Batch 100/145, Loss: 0.6404
Epoch 1/10, Batch 110/145, Loss: 0.3860
Epoch 1/10, Batch 120/145, Loss: 0.5941
Epoch 1/10, Batch 130/145, Loss: 0.5398
Epoch 1/10, Batch 140/145, Loss: 0.4784
Epoch 1/10, Train Loss: 0.6859, Valid Loss: 0.4011
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2907
Epoch 2/10, Batch 20/145, Loss: 0.4310
Epoch 2/10, Batch 30/145, Loss: 0.3058
Epoch 2/10, Batch 40/145, Loss: 0.5633
Epoch 2/10, Batch 50/145, Loss: 0.4085
Epoch 2/10, Batch 60/145, Loss: 0.3593
Epoch 2/10, Batch 70/145, Loss: 0.5048
Epoch 2/10, Batch 80/145, Loss: 0.3629
Epoch 2/10, Batch 90/145, Loss: 0.1592
Epoch 2/10, Batch 100/145, Loss: 0.2656
Epoch 2/10, Batch 110/145, Loss: 0.2503
Epoch 2/10, Batch 120/145, Loss: 0.2745
Epoch 2/10, Batch 130/145, Loss: 0.3162
Epoch 2/10, Batch 140/145, Loss: 0.2303
Epoch 2/10, Train Loss: 0.3545, Valid Loss: 0.3164
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2314
Epoch 3/10, Batch 20/145, Loss: 0.4421
Epoch 3/10, Batch 30/145, Loss: 0.2671
Epoch 3/10, Batch 40/145, Loss: 0.2546
Epoch 3/10, Batch 50/145, Loss: 0.1736
Epoch 3/10, Batch 60/145, Loss: 0.4482
Epoch 3/10, Batch 70/145, Loss: 0.3994
Epoch 3/10, Batch 80/145, Loss: 0.1809
Epoch 3/10, Batch 90/145, Loss: 0.4366
Epoch 3/10, Batch 100/145, Loss: 0.3425
Epoch 3/10, Batch 110/145, Loss: 0.2548
Epoch 3/10, Batch 120/145, Loss: 0.1320
Epoch 3/10, Batch 130/145, Loss: 0.3144
Epoch 3/10, Batch 140/145, Loss: 0.2704
Epoch 3/10, Train Loss: 0.3042, Valid Loss: 0.2971
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1905
Epoch 4/10, Batch 20/145, Loss: 0.2070
Epoch 4/10, Batch 30/145, Loss: 0.2394
Epoch 4/10, Batch 40/145, Loss: 0.3995
Epoch 4/10, Batch 50/145, Loss: 0.2193
Epoch 4/10, Batch 60/145, Loss: 0.3431
Epoch 4/10, Batch 70/145, Loss: 0.1785
Epoch 4/10, Batch 80/145, Loss: 0.2090
Epoch 4/10, Batch 90/145, Loss: 0.2783
Epoch 4/10, Batch 100/145, Loss: 0.1970
Epoch 4/10, Batch 110/145, Loss: 0.2421
Epoch 4/10, Batch 120/145, Loss: 0.3120
Epoch 4/10, Batch 130/145, Loss: 0.2533
Epoch 4/10, Batch 140/145, Loss: 0.2422
Epoch 4/10, Train Loss: 0.2672, Valid Loss: 0.2766
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1790
Epoch 5/10, Batch 20/145, Loss: 0.2164
Epoch 5/10, Batch 30/145, Loss: 0.1818
Epoch 5/10, Batch 40/145, Loss: 0.1351
Epoch 5/10, Batch 50/145, Loss: 0.2180
Epoch 5/10, Batch 60/145, Loss: 0.2427
Epoch 5/10, Batch 70/145, Loss: 0.1495
Epoch 5/10, Batch 80/145, Loss: 0.3291
Epoch 5/10, Batch 90/145, Loss: 0.1138
Epoch 5/10, Batch 100/145, Loss: 0.2316
Epoch 5/10, Batch 110/145, Loss: 0.0661
Epoch 5/10, Batch 120/145, Loss: 0.1910
Epoch 5/10, Batch 130/145, Loss: 0.2527
Epoch 5/10, Batch 140/145, Loss: 0.2172
Epoch 5/10, Train Loss: 0.2327, Valid Loss: 0.2703
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2828
Epoch 6/10, Batch 20/145, Loss: 0.2358
Epoch 6/10, Batch 30/145, Loss: 0.2172
Epoch 6/10, Batch 40/145, Loss: 0.2196
Epoch 6/10, Batch 50/145, Loss: 0.2670
Epoch 6/10, Batch 60/145, Loss: 0.0974
Epoch 6/10, Batch 70/145, Loss: 0.3044
Epoch 6/10, Batch 80/145, Loss: 0.3662
Epoch 6/10, Batch 90/145, Loss: 0.1627
Epoch 6/10, Batch 100/145, Loss: 0.1823
Epoch 6/10, Batch 110/145, Loss: 0.1160
Epoch 6/10, Batch 120/145, Loss: 0.2449
Epoch 6/10, Batch 130/145, Loss: 0.2675
Epoch 6/10, Batch 140/145, Loss: 0.2515
Epoch 6/10, Train Loss: 0.2272, Valid Loss: 0.2699
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.4003
Epoch 7/10, Batch 20/145, Loss: 0.2621
Epoch 7/10, Batch 30/145, Loss: 0.1798
Epoch 7/10, Batch 40/145, Loss: 0.3771
Epoch 7/10, Batch 50/145, Loss: 0.1519
Epoch 7/10, Batch 60/145, Loss: 0.0981
Epoch 7/10, Batch 70/145, Loss: 0.1963
Epoch 7/10, Batch 80/145, Loss: 0.1396
Epoch 7/10, Batch 90/145, Loss: 0.2124
Epoch 7/10, Batch 100/145, Loss: 0.1520
Epoch 7/10, Batch 110/145, Loss: 0.2307
Epoch 7/10, Batch 120/145, Loss: 0.1133
Epoch 7/10, Batch 130/145, Loss: 0.1587
Epoch 7/10, Batch 140/145, Loss: 0.1984
Epoch 7/10, Train Loss: 0.2118, Valid Loss: 0.2573
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1596
Epoch 8/10, Batch 20/145, Loss: 0.1301
Epoch 8/10, Batch 30/145, Loss: 0.1326
Epoch 8/10, Batch 40/145, Loss: 0.3401
Epoch 8/10, Batch 50/145, Loss: 0.1590
Epoch 8/10, Batch 60/145, Loss: 0.1917
Epoch 8/10, Batch 70/145, Loss: 0.2189
Epoch 8/10, Batch 80/145, Loss: 0.2328
Epoch 8/10, Batch 90/145, Loss: 0.1548
Epoch 8/10, Batch 100/145, Loss: 0.4161
Epoch 8/10, Batch 110/145, Loss: 0.4655
Epoch 8/10, Batch 120/145, Loss: 0.1507
Epoch 8/10, Batch 130/145, Loss: 0.2181
Epoch 8/10, Batch 140/145, Loss: 0.2551
Epoch 8/10, Train Loss: 0.2028, Valid Loss: 0.2484
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2384
Epoch 9/10, Batch 20/145, Loss: 0.1150
Epoch 9/10, Batch 30/145, Loss: 0.0713
Epoch 9/10, Batch 40/145, Loss: 0.0948
Epoch 9/10, Batch 50/145, Loss: 0.1307
Epoch 9/10, Batch 60/145, Loss: 0.2841
Epoch 9/10, Batch 70/145, Loss: 0.3370
Epoch 9/10, Batch 80/145, Loss: 0.3085
Epoch 9/10, Batch 90/145, Loss: 0.1291
Epoch 9/10, Batch 100/145, Loss: 0.1645
Epoch 9/10, Batch 110/145, Loss: 0.1076
Epoch 9/10, Batch 120/145, Loss: 0.2110
Epoch 9/10, Batch 130/145, Loss: 0.1850
Epoch 9/10, Batch 140/145, Loss: 0.1243
Epoch 9/10, Train Loss: 0.2026, Valid Loss: 0.2344
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0652
Epoch 10/10, Batch 20/145, Loss: 0.0925
Epoch 10/10, Batch 30/145, Loss: 0.1180
Epoch 10/10, Batch 40/145, Loss: 0.2213
Epoch 10/10, Batch 50/145, Loss: 0.2573
Epoch 10/10, Batch 60/145, Loss: 0.1701
Epoch 10/10, Batch 70/145, Loss: 0.1085
Epoch 10/10, Batch 80/145, Loss: 0.3641
Epoch 10/10, Batch 90/145, Loss: 0.1537
Epoch 10/10, Batch 100/145, Loss: 0.3052
Epoch 10/10, Batch 110/145, Loss: 0.1721
Epoch 10/10, Batch 120/145, Loss: 0.1345
Epoch 10/10, Batch 130/145, Loss: 0.2898
Epoch 10/10, Batch 140/145, Loss: 0.1618
Epoch 10/10, Train Loss: 0.1877, Valid Loss: 0.2349
Accuracy: 0.9287
Precision: 0.9269
Recall: 0.9287
F1-score: 0.9272
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5953
Epoch 1/10, Batch 20/145, Loss: 0.9113
Epoch 1/10, Batch 30/145, Loss: 0.9020
Epoch 1/10, Batch 40/145, Loss: 0.8479
Epoch 1/10, Batch 50/145, Loss: 0.5874
Epoch 1/10, Batch 60/145, Loss: 0.5943
Epoch 1/10, Batch 70/145, Loss: 0.7405
Epoch 1/10, Batch 80/145, Loss: 0.3960
Epoch 1/10, Batch 90/145, Loss: 0.5105
Epoch 1/10, Batch 100/145, Loss: 0.5738
Epoch 1/10, Batch 110/145, Loss: 0.3722
Epoch 1/10, Batch 120/145, Loss: 0.6198
Epoch 1/10, Batch 130/145, Loss: 0.4427
Epoch 1/10, Batch 140/145, Loss: 0.2767
Epoch 1/10, Train Loss: 0.6938, Valid Loss: 0.3687
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3824
Epoch 2/10, Batch 20/145, Loss: 0.3716
Epoch 2/10, Batch 30/145, Loss: 0.3605
Epoch 2/10, Batch 40/145, Loss: 0.6263
Epoch 2/10, Batch 50/145, Loss: 0.3780
Epoch 2/10, Batch 60/145, Loss: 0.4371
Epoch 2/10, Batch 70/145, Loss: 0.3032
Epoch 2/10, Batch 80/145, Loss: 0.3521
Epoch 2/10, Batch 90/145, Loss: 0.2973
Epoch 2/10, Batch 100/145, Loss: 0.4848
Epoch 2/10, Batch 110/145, Loss: 0.2816
Epoch 2/10, Batch 120/145, Loss: 0.4210
Epoch 2/10, Batch 130/145, Loss: 0.4183
Epoch 2/10, Batch 140/145, Loss: 0.2296
Epoch 2/10, Train Loss: 0.3673, Valid Loss: 0.2873
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2218
Epoch 3/10, Batch 20/145, Loss: 0.2409
Epoch 3/10, Batch 30/145, Loss: 0.2038
Epoch 3/10, Batch 40/145, Loss: 0.2909
Epoch 3/10, Batch 50/145, Loss: 0.2872
Epoch 3/10, Batch 60/145, Loss: 0.3284
Epoch 3/10, Batch 70/145, Loss: 0.3074
Epoch 3/10, Batch 80/145, Loss: 0.2545
Epoch 3/10, Batch 90/145, Loss: 0.4657
Epoch 3/10, Batch 100/145, Loss: 0.4441
Epoch 3/10, Batch 110/145, Loss: 0.2445
Epoch 3/10, Batch 120/145, Loss: 0.1674
Epoch 3/10, Batch 130/145, Loss: 0.2833
Epoch 3/10, Batch 140/145, Loss: 0.1864
Epoch 3/10, Train Loss: 0.3119, Valid Loss: 0.2586
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3814
Epoch 4/10, Batch 20/145, Loss: 0.1485
Epoch 4/10, Batch 30/145, Loss: 0.3555
Epoch 4/10, Batch 40/145, Loss: 0.4128
Epoch 4/10, Batch 50/145, Loss: 0.2323
Epoch 4/10, Batch 60/145, Loss: 0.1474
Epoch 4/10, Batch 70/145, Loss: 0.3848
Epoch 4/10, Batch 80/145, Loss: 0.4376
Epoch 4/10, Batch 90/145, Loss: 0.2306
Epoch 4/10, Batch 100/145, Loss: 0.2302
Epoch 4/10, Batch 110/145, Loss: 0.3086
Epoch 4/10, Batch 120/145, Loss: 0.3272
Epoch 4/10, Batch 130/145, Loss: 0.1240
Epoch 4/10, Batch 140/145, Loss: 0.2791
Epoch 4/10, Train Loss: 0.2698, Valid Loss: 0.2448
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2804
Epoch 5/10, Batch 20/145, Loss: 0.2823
Epoch 5/10, Batch 30/145, Loss: 0.1395
Epoch 5/10, Batch 40/145, Loss: 0.2507
Epoch 5/10, Batch 50/145, Loss: 0.2114
Epoch 5/10, Batch 60/145, Loss: 0.2471
Epoch 5/10, Batch 70/145, Loss: 0.1896
Epoch 5/10, Batch 80/145, Loss: 0.2308
Epoch 5/10, Batch 90/145, Loss: 0.1724
Epoch 5/10, Batch 100/145, Loss: 0.1932
Epoch 5/10, Batch 110/145, Loss: 0.1870
Epoch 5/10, Batch 120/145, Loss: 0.1884
Epoch 5/10, Batch 130/145, Loss: 0.2828
Epoch 5/10, Batch 140/145, Loss: 0.1274
Epoch 5/10, Train Loss: 0.2430, Valid Loss: 0.2335
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1512
Epoch 6/10, Batch 20/145, Loss: 0.1673
Epoch 6/10, Batch 30/145, Loss: 0.1711
Epoch 6/10, Batch 40/145, Loss: 0.2132
Epoch 6/10, Batch 50/145, Loss: 0.2566
Epoch 6/10, Batch 60/145, Loss: 0.1376
Epoch 6/10, Batch 70/145, Loss: 0.5076
Epoch 6/10, Batch 80/145, Loss: 0.3080
Epoch 6/10, Batch 90/145, Loss: 0.1073
Epoch 6/10, Batch 100/145, Loss: 0.1573
Epoch 6/10, Batch 110/145, Loss: 0.0741
Epoch 6/10, Batch 120/145, Loss: 0.2297
Epoch 6/10, Batch 130/145, Loss: 0.2518
Epoch 6/10, Batch 140/145, Loss: 0.1538
Epoch 6/10, Train Loss: 0.2320, Valid Loss: 0.2185
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2014
Epoch 7/10, Batch 20/145, Loss: 0.2535
Epoch 7/10, Batch 30/145, Loss: 0.2237
Epoch 7/10, Batch 40/145, Loss: 0.4872
Epoch 7/10, Batch 50/145, Loss: 0.2041
Epoch 7/10, Batch 60/145, Loss: 0.0481
Epoch 7/10, Batch 70/145, Loss: 0.2127
Epoch 7/10, Batch 80/145, Loss: 0.1323
Epoch 7/10, Batch 90/145, Loss: 0.0857
Epoch 7/10, Batch 100/145, Loss: 0.2759
Epoch 7/10, Batch 110/145, Loss: 0.1914
Epoch 7/10, Batch 120/145, Loss: 0.2259
Epoch 7/10, Batch 130/145, Loss: 0.1470
Epoch 7/10, Batch 140/145, Loss: 0.0877
Epoch 7/10, Train Loss: 0.2195, Valid Loss: 0.2123
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1169
Epoch 8/10, Batch 20/145, Loss: 0.1438
Epoch 8/10, Batch 30/145, Loss: 0.2999
Epoch 8/10, Batch 40/145, Loss: 0.1709
Epoch 8/10, Batch 50/145, Loss: 0.2960
Epoch 8/10, Batch 60/145, Loss: 0.1139
Epoch 8/10, Batch 70/145, Loss: 0.2149
Epoch 8/10, Batch 80/145, Loss: 0.1188
Epoch 8/10, Batch 90/145, Loss: 0.3174
Epoch 8/10, Batch 100/145, Loss: 0.1895
Epoch 8/10, Batch 110/145, Loss: 0.1142
Epoch 8/10, Batch 120/145, Loss: 0.1822
Epoch 8/10, Batch 130/145, Loss: 0.2889
Epoch 8/10, Batch 140/145, Loss: 0.3024
Epoch 8/10, Train Loss: 0.2181, Valid Loss: 0.2081
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2087
Epoch 9/10, Batch 20/145, Loss: 0.1153
Epoch 9/10, Batch 30/145, Loss: 0.1995
Epoch 9/10, Batch 40/145, Loss: 0.1499
Epoch 9/10, Batch 50/145, Loss: 0.2640
Epoch 9/10, Batch 60/145, Loss: 0.2642
Epoch 9/10, Batch 70/145, Loss: 0.0878
Epoch 9/10, Batch 80/145, Loss: 0.1909
Epoch 9/10, Batch 90/145, Loss: 0.2213
Epoch 9/10, Batch 100/145, Loss: 0.2105
Epoch 9/10, Batch 110/145, Loss: 0.1886
Epoch 9/10, Batch 120/145, Loss: 0.2128
Epoch 9/10, Batch 130/145, Loss: 0.1742
Epoch 9/10, Batch 140/145, Loss: 0.2356
Epoch 9/10, Train Loss: 0.2128, Valid Loss: 0.1983
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1378
Epoch 10/10, Batch 20/145, Loss: 0.3312
Epoch 10/10, Batch 30/145, Loss: 0.0690
Epoch 10/10, Batch 40/145, Loss: 0.1639
Epoch 10/10, Batch 50/145, Loss: 0.3021
Epoch 10/10, Batch 60/145, Loss: 0.0991
Epoch 10/10, Batch 70/145, Loss: 0.1525
Epoch 10/10, Batch 80/145, Loss: 0.4273
Epoch 10/10, Batch 90/145, Loss: 0.1648
Epoch 10/10, Batch 100/145, Loss: 0.1089
Epoch 10/10, Batch 110/145, Loss: 0.1511
Epoch 10/10, Batch 120/145, Loss: 0.3552
Epoch 10/10, Batch 130/145, Loss: 0.2640
Epoch 10/10, Batch 140/145, Loss: 0.2966
Epoch 10/10, Train Loss: 0.2065, Valid Loss: 0.2008
Accuracy: 0.9264
Precision: 0.9258
Recall: 0.9264
F1-score: 0.9256
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5271
Epoch 1/10, Batch 20/145, Loss: 0.9065
Epoch 1/10, Batch 30/145, Loss: 0.8841
Epoch 1/10, Batch 40/145, Loss: 0.8124
Epoch 1/10, Batch 50/145, Loss: 0.5719
Epoch 1/10, Batch 60/145, Loss: 0.6019
Epoch 1/10, Batch 70/145, Loss: 0.6969
Epoch 1/10, Batch 80/145, Loss: 0.5905
Epoch 1/10, Batch 90/145, Loss: 0.4783
Epoch 1/10, Batch 100/145, Loss: 0.5521
Epoch 1/10, Batch 110/145, Loss: 0.3843
Epoch 1/10, Batch 120/145, Loss: 0.5862
Epoch 1/10, Batch 130/145, Loss: 0.3474
Epoch 1/10, Batch 140/145, Loss: 0.4858
Epoch 1/10, Train Loss: 0.6795, Valid Loss: 0.3752
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2746
Epoch 2/10, Batch 20/145, Loss: 0.4515
Epoch 2/10, Batch 30/145, Loss: 0.3673
Epoch 2/10, Batch 40/145, Loss: 0.4426
Epoch 2/10, Batch 50/145, Loss: 0.3309
Epoch 2/10, Batch 60/145, Loss: 0.3919
Epoch 2/10, Batch 70/145, Loss: 0.4387
Epoch 2/10, Batch 80/145, Loss: 0.1993
Epoch 2/10, Batch 90/145, Loss: 0.2921
Epoch 2/10, Batch 100/145, Loss: 0.1945
Epoch 2/10, Batch 110/145, Loss: 0.2762
Epoch 2/10, Batch 120/145, Loss: 0.3979
Epoch 2/10, Batch 130/145, Loss: 0.2723
Epoch 2/10, Batch 140/145, Loss: 0.3419
Epoch 2/10, Train Loss: 0.3530, Valid Loss: 0.2952
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3087
Epoch 3/10, Batch 20/145, Loss: 0.3119
Epoch 3/10, Batch 30/145, Loss: 0.3184
Epoch 3/10, Batch 40/145, Loss: 0.2120
Epoch 3/10, Batch 50/145, Loss: 0.2060
Epoch 3/10, Batch 60/145, Loss: 0.3417
Epoch 3/10, Batch 70/145, Loss: 0.2253
Epoch 3/10, Batch 80/145, Loss: 0.2039
Epoch 3/10, Batch 90/145, Loss: 0.4933
Epoch 3/10, Batch 100/145, Loss: 0.1773
Epoch 3/10, Batch 110/145, Loss: 0.2339
Epoch 3/10, Batch 120/145, Loss: 0.2320
Epoch 3/10, Batch 130/145, Loss: 0.4350
Epoch 3/10, Batch 140/145, Loss: 0.3008
Epoch 3/10, Train Loss: 0.3008, Valid Loss: 0.2705
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2591
Epoch 4/10, Batch 20/145, Loss: 0.3003
Epoch 4/10, Batch 30/145, Loss: 0.2563
Epoch 4/10, Batch 40/145, Loss: 0.3870
Epoch 4/10, Batch 50/145, Loss: 0.3498
Epoch 4/10, Batch 60/145, Loss: 0.1730
Epoch 4/10, Batch 70/145, Loss: 0.3898
Epoch 4/10, Batch 80/145, Loss: 0.2003
Epoch 4/10, Batch 90/145, Loss: 0.2153
Epoch 4/10, Batch 100/145, Loss: 0.1949
Epoch 4/10, Batch 110/145, Loss: 0.1103
Epoch 4/10, Batch 120/145, Loss: 0.1592
Epoch 4/10, Batch 130/145, Loss: 0.1179
Epoch 4/10, Batch 140/145, Loss: 0.1734
Epoch 4/10, Train Loss: 0.2518, Valid Loss: 0.2544
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1616
Epoch 5/10, Batch 20/145, Loss: 0.1602
Epoch 5/10, Batch 30/145, Loss: 0.2684
Epoch 5/10, Batch 40/145, Loss: 0.1439
Epoch 5/10, Batch 50/145, Loss: 0.1868
Epoch 5/10, Batch 60/145, Loss: 0.2289
Epoch 5/10, Batch 70/145, Loss: 0.2161
Epoch 5/10, Batch 80/145, Loss: 0.2505
Epoch 5/10, Batch 90/145, Loss: 0.2038
Epoch 5/10, Batch 100/145, Loss: 0.2180
Epoch 5/10, Batch 110/145, Loss: 0.2073
Epoch 5/10, Batch 120/145, Loss: 0.2840
Epoch 5/10, Batch 130/145, Loss: 0.4636
Epoch 5/10, Batch 140/145, Loss: 0.1833
Epoch 5/10, Train Loss: 0.2316, Valid Loss: 0.2477
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1818
Epoch 6/10, Batch 20/145, Loss: 0.3123
Epoch 6/10, Batch 30/145, Loss: 0.2466
Epoch 6/10, Batch 40/145, Loss: 0.2114
Epoch 6/10, Batch 50/145, Loss: 0.3326
Epoch 6/10, Batch 60/145, Loss: 0.0649
Epoch 6/10, Batch 70/145, Loss: 0.3018
Epoch 6/10, Batch 80/145, Loss: 0.3100
Epoch 6/10, Batch 90/145, Loss: 0.2101
Epoch 6/10, Batch 100/145, Loss: 0.1768
Epoch 6/10, Batch 110/145, Loss: 0.1448
Epoch 6/10, Batch 120/145, Loss: 0.3565
Epoch 6/10, Batch 130/145, Loss: 0.2466
Epoch 6/10, Batch 140/145, Loss: 0.1449
Epoch 6/10, Train Loss: 0.2209, Valid Loss: 0.2592
Epoch 7/10, Batch 10/145, Loss: 0.4057
Epoch 7/10, Batch 20/145, Loss: 0.2592
Epoch 7/10, Batch 30/145, Loss: 0.1240
Epoch 7/10, Batch 40/145, Loss: 0.2301
Epoch 7/10, Batch 50/145, Loss: 0.1321
Epoch 7/10, Batch 60/145, Loss: 0.1137
Epoch 7/10, Batch 70/145, Loss: 0.1806
Epoch 7/10, Batch 80/145, Loss: 0.1136
Epoch 7/10, Batch 90/145, Loss: 0.2082
Epoch 7/10, Batch 100/145, Loss: 0.0955
Epoch 7/10, Batch 110/145, Loss: 0.1558
Epoch 7/10, Batch 120/145, Loss: 0.1965
Epoch 7/10, Batch 130/145, Loss: 0.1342
Epoch 7/10, Batch 140/145, Loss: 0.1316
Epoch 7/10, Train Loss: 0.2138, Valid Loss: 0.2336
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1217
Epoch 8/10, Batch 20/145, Loss: 0.1262
Epoch 8/10, Batch 30/145, Loss: 0.2395
Epoch 8/10, Batch 40/145, Loss: 0.3126
Epoch 8/10, Batch 50/145, Loss: 0.1993
Epoch 8/10, Batch 60/145, Loss: 0.1694
Epoch 8/10, Batch 70/145, Loss: 0.1008
Epoch 8/10, Batch 80/145, Loss: 0.1770
Epoch 8/10, Batch 90/145, Loss: 0.3709
Epoch 8/10, Batch 100/145, Loss: 0.1964
Epoch 8/10, Batch 110/145, Loss: 0.2281
Epoch 8/10, Batch 120/145, Loss: 0.2631
Epoch 8/10, Batch 130/145, Loss: 0.0959
Epoch 8/10, Batch 140/145, Loss: 0.2350
Epoch 8/10, Train Loss: 0.2057, Valid Loss: 0.2284
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3275
Epoch 9/10, Batch 20/145, Loss: 0.3163
Epoch 9/10, Batch 30/145, Loss: 0.0665
Epoch 9/10, Batch 40/145, Loss: 0.1740
Epoch 9/10, Batch 50/145, Loss: 0.2389
Epoch 9/10, Batch 60/145, Loss: 0.0605
Epoch 9/10, Batch 70/145, Loss: 0.2449
Epoch 9/10, Batch 80/145, Loss: 0.1809
Epoch 9/10, Batch 90/145, Loss: 0.0962
Epoch 9/10, Batch 100/145, Loss: 0.2622
Epoch 9/10, Batch 110/145, Loss: 0.1194
Epoch 9/10, Batch 120/145, Loss: 0.3475
Epoch 9/10, Batch 130/145, Loss: 0.3680
Epoch 9/10, Batch 140/145, Loss: 0.1606
Epoch 9/10, Train Loss: 0.1943, Valid Loss: 0.2127
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1319
Epoch 10/10, Batch 20/145, Loss: 0.2444
Epoch 10/10, Batch 30/145, Loss: 0.0931
Epoch 10/10, Batch 40/145, Loss: 0.1049
Epoch 10/10, Batch 50/145, Loss: 0.1969
Epoch 10/10, Batch 60/145, Loss: 0.3183
Epoch 10/10, Batch 70/145, Loss: 0.1556
Epoch 10/10, Batch 80/145, Loss: 0.3180
Epoch 10/10, Batch 90/145, Loss: 0.0906
Epoch 10/10, Batch 100/145, Loss: 0.1692
Epoch 10/10, Batch 110/145, Loss: 0.1214
Epoch 10/10, Batch 120/145, Loss: 0.1568
Epoch 10/10, Batch 130/145, Loss: 0.1116
Epoch 10/10, Batch 140/145, Loss: 0.1098
Epoch 10/10, Train Loss: 0.1834, Valid Loss: 0.2102
Model saved!
Accuracy: 0.9276
Precision: 0.9268
Recall: 0.9276
F1-score: 0.9271
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4816
Epoch 1/10, Batch 20/145, Loss: 0.8047
Epoch 1/10, Batch 30/145, Loss: 0.8277
Epoch 1/10, Batch 40/145, Loss: 0.8466
Epoch 1/10, Batch 50/145, Loss: 0.7398
Epoch 1/10, Batch 60/145, Loss: 0.6655
Epoch 1/10, Batch 70/145, Loss: 0.5958
Epoch 1/10, Batch 80/145, Loss: 0.5306
Epoch 1/10, Batch 90/145, Loss: 0.3773
Epoch 1/10, Batch 100/145, Loss: 0.6077
Epoch 1/10, Batch 110/145, Loss: 0.4020
Epoch 1/10, Batch 120/145, Loss: 0.5742
Epoch 1/10, Batch 130/145, Loss: 0.3976
Epoch 1/10, Batch 140/145, Loss: 0.5135
Epoch 1/10, Train Loss: 0.6852, Valid Loss: 0.3761
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3217
Epoch 2/10, Batch 20/145, Loss: 0.5062
Epoch 2/10, Batch 30/145, Loss: 0.3006
Epoch 2/10, Batch 40/145, Loss: 0.4095
Epoch 2/10, Batch 50/145, Loss: 0.2885
Epoch 2/10, Batch 60/145, Loss: 0.3693
Epoch 2/10, Batch 70/145, Loss: 0.4340
Epoch 2/10, Batch 80/145, Loss: 0.2498
Epoch 2/10, Batch 90/145, Loss: 0.2829
Epoch 2/10, Batch 100/145, Loss: 0.1966
Epoch 2/10, Batch 110/145, Loss: 0.2345
Epoch 2/10, Batch 120/145, Loss: 0.4621
Epoch 2/10, Batch 130/145, Loss: 0.4352
Epoch 2/10, Batch 140/145, Loss: 0.2344
Epoch 2/10, Train Loss: 0.3580, Valid Loss: 0.2815
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2048
Epoch 3/10, Batch 20/145, Loss: 0.4088
Epoch 3/10, Batch 30/145, Loss: 0.2303
Epoch 3/10, Batch 40/145, Loss: 0.1345
Epoch 3/10, Batch 50/145, Loss: 0.1680
Epoch 3/10, Batch 60/145, Loss: 0.3146
Epoch 3/10, Batch 70/145, Loss: 0.1976
Epoch 3/10, Batch 80/145, Loss: 0.3394
Epoch 3/10, Batch 90/145, Loss: 0.3747
Epoch 3/10, Batch 100/145, Loss: 0.2336
Epoch 3/10, Batch 110/145, Loss: 0.3046
Epoch 3/10, Batch 120/145, Loss: 0.1691
Epoch 3/10, Batch 130/145, Loss: 0.1753
Epoch 3/10, Batch 140/145, Loss: 0.1182
Epoch 3/10, Train Loss: 0.3023, Valid Loss: 0.2593
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2311
Epoch 4/10, Batch 20/145, Loss: 0.1934
Epoch 4/10, Batch 30/145, Loss: 0.2954
Epoch 4/10, Batch 40/145, Loss: 0.3772
Epoch 4/10, Batch 50/145, Loss: 0.3610
Epoch 4/10, Batch 60/145, Loss: 0.2299
Epoch 4/10, Batch 70/145, Loss: 0.4258
Epoch 4/10, Batch 80/145, Loss: 0.3133
Epoch 4/10, Batch 90/145, Loss: 0.4328
Epoch 4/10, Batch 100/145, Loss: 0.1716
Epoch 4/10, Batch 110/145, Loss: 0.3237
Epoch 4/10, Batch 120/145, Loss: 0.2736
Epoch 4/10, Batch 130/145, Loss: 0.1787
Epoch 4/10, Batch 140/145, Loss: 0.1093
Epoch 4/10, Train Loss: 0.2583, Valid Loss: 0.2457
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2117
Epoch 5/10, Batch 20/145, Loss: 0.2345
Epoch 5/10, Batch 30/145, Loss: 0.1561
Epoch 5/10, Batch 40/145, Loss: 0.1196
Epoch 5/10, Batch 50/145, Loss: 0.1423
Epoch 5/10, Batch 60/145, Loss: 0.2539
Epoch 5/10, Batch 70/145, Loss: 0.2743
Epoch 5/10, Batch 80/145, Loss: 0.3088
Epoch 5/10, Batch 90/145, Loss: 0.2683
Epoch 5/10, Batch 100/145, Loss: 0.3139
Epoch 5/10, Batch 110/145, Loss: 0.2815
Epoch 5/10, Batch 120/145, Loss: 0.2616
Epoch 5/10, Batch 130/145, Loss: 0.2464
Epoch 5/10, Batch 140/145, Loss: 0.4502
Epoch 5/10, Train Loss: 0.2410, Valid Loss: 0.2341
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2943
Epoch 6/10, Batch 20/145, Loss: 0.3353
Epoch 6/10, Batch 30/145, Loss: 0.3629
Epoch 6/10, Batch 40/145, Loss: 0.2093
Epoch 6/10, Batch 50/145, Loss: 0.1917
Epoch 6/10, Batch 60/145, Loss: 0.1106
Epoch 6/10, Batch 70/145, Loss: 0.3063
Epoch 6/10, Batch 80/145, Loss: 0.3172
Epoch 6/10, Batch 90/145, Loss: 0.3577
Epoch 6/10, Batch 100/145, Loss: 0.3770
Epoch 6/10, Batch 110/145, Loss: 0.1165
Epoch 6/10, Batch 120/145, Loss: 0.1288
Epoch 6/10, Batch 130/145, Loss: 0.1159
Epoch 6/10, Batch 140/145, Loss: 0.2109
Epoch 6/10, Train Loss: 0.2225, Valid Loss: 0.2267
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3694
Epoch 7/10, Batch 20/145, Loss: 0.1951
Epoch 7/10, Batch 30/145, Loss: 0.2367
Epoch 7/10, Batch 40/145, Loss: 0.5258
Epoch 7/10, Batch 50/145, Loss: 0.1478
Epoch 7/10, Batch 60/145, Loss: 0.1676
Epoch 7/10, Batch 70/145, Loss: 0.2531
Epoch 7/10, Batch 80/145, Loss: 0.0885
Epoch 7/10, Batch 90/145, Loss: 0.2300
Epoch 7/10, Batch 100/145, Loss: 0.1824
Epoch 7/10, Batch 110/145, Loss: 0.2364
Epoch 7/10, Batch 120/145, Loss: 0.2564
Epoch 7/10, Batch 130/145, Loss: 0.1269
Epoch 7/10, Batch 140/145, Loss: 0.0993
Epoch 7/10, Train Loss: 0.2145, Valid Loss: 0.2128
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1621
Epoch 8/10, Batch 20/145, Loss: 0.1873
Epoch 8/10, Batch 30/145, Loss: 0.1533
Epoch 8/10, Batch 40/145, Loss: 0.3236
Epoch 8/10, Batch 50/145, Loss: 0.1774
Epoch 8/10, Batch 60/145, Loss: 0.2122
Epoch 8/10, Batch 70/145, Loss: 0.2022
Epoch 8/10, Batch 80/145, Loss: 0.1036
Epoch 8/10, Batch 90/145, Loss: 0.1270
Epoch 8/10, Batch 100/145, Loss: 0.1868
Epoch 8/10, Batch 110/145, Loss: 0.1913
Epoch 8/10, Batch 120/145, Loss: 0.1505
Epoch 8/10, Batch 130/145, Loss: 0.1806
Epoch 8/10, Batch 140/145, Loss: 0.2663
Epoch 8/10, Train Loss: 0.2115, Valid Loss: 0.2061
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.0960
Epoch 9/10, Batch 20/145, Loss: 0.1733
Epoch 9/10, Batch 30/145, Loss: 0.1279
Epoch 9/10, Batch 40/145, Loss: 0.1239
Epoch 9/10, Batch 50/145, Loss: 0.2514
Epoch 9/10, Batch 60/145, Loss: 0.1786
Epoch 9/10, Batch 70/145, Loss: 0.0640
Epoch 9/10, Batch 80/145, Loss: 0.2423
Epoch 9/10, Batch 90/145, Loss: 0.1060
Epoch 9/10, Batch 100/145, Loss: 0.2473
Epoch 9/10, Batch 110/145, Loss: 0.1782
Epoch 9/10, Batch 120/145, Loss: 0.1647
Epoch 9/10, Batch 130/145, Loss: 0.2802
Epoch 9/10, Batch 140/145, Loss: 0.3378
Epoch 9/10, Train Loss: 0.1974, Valid Loss: 0.2034
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0631
Epoch 10/10, Batch 20/145, Loss: 0.0590
Epoch 10/10, Batch 30/145, Loss: 0.1591
Epoch 10/10, Batch 40/145, Loss: 0.0765
Epoch 10/10, Batch 50/145, Loss: 0.2497
Epoch 10/10, Batch 60/145, Loss: 0.1534
Epoch 10/10, Batch 70/145, Loss: 0.1958
Epoch 10/10, Batch 80/145, Loss: 0.3128
Epoch 10/10, Batch 90/145, Loss: 0.2052
Epoch 10/10, Batch 100/145, Loss: 0.1012
Epoch 10/10, Batch 110/145, Loss: 0.2520
Epoch 10/10, Batch 120/145, Loss: 0.2694
Epoch 10/10, Batch 130/145, Loss: 0.1492
Epoch 10/10, Batch 140/145, Loss: 0.1609
Epoch 10/10, Train Loss: 0.1957, Valid Loss: 0.1969
Model saved!
Accuracy: 0.9241
Precision: 0.9217
Recall: 0.9241
F1-score: 0.9224
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4803
Epoch 1/10, Batch 20/145, Loss: 0.9317
Epoch 1/10, Batch 30/145, Loss: 0.9431
Epoch 1/10, Batch 40/145, Loss: 0.8851
Epoch 1/10, Batch 50/145, Loss: 0.5777
Epoch 1/10, Batch 60/145, Loss: 0.6422
Epoch 1/10, Batch 70/145, Loss: 0.5925
Epoch 1/10, Batch 80/145, Loss: 0.4465
Epoch 1/10, Batch 90/145, Loss: 0.5050
Epoch 1/10, Batch 100/145, Loss: 0.5670
Epoch 1/10, Batch 110/145, Loss: 0.5452
Epoch 1/10, Batch 120/145, Loss: 0.5138
Epoch 1/10, Batch 130/145, Loss: 0.5151
Epoch 1/10, Batch 140/145, Loss: 0.5798
Epoch 1/10, Train Loss: 0.6796, Valid Loss: 0.3779
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.5364
Epoch 2/10, Batch 20/145, Loss: 0.4070
Epoch 2/10, Batch 30/145, Loss: 0.2803
Epoch 2/10, Batch 40/145, Loss: 0.5186
Epoch 2/10, Batch 50/145, Loss: 0.3261
Epoch 2/10, Batch 60/145, Loss: 0.3147
Epoch 2/10, Batch 70/145, Loss: 0.4076
Epoch 2/10, Batch 80/145, Loss: 0.3415
Epoch 2/10, Batch 90/145, Loss: 0.1526
Epoch 2/10, Batch 100/145, Loss: 0.3303
Epoch 2/10, Batch 110/145, Loss: 0.2343
Epoch 2/10, Batch 120/145, Loss: 0.3102
Epoch 2/10, Batch 130/145, Loss: 0.4554
Epoch 2/10, Batch 140/145, Loss: 0.4049
Epoch 2/10, Train Loss: 0.3565, Valid Loss: 0.2973
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3149
Epoch 3/10, Batch 20/145, Loss: 0.2246
Epoch 3/10, Batch 30/145, Loss: 0.2608
Epoch 3/10, Batch 40/145, Loss: 0.2122
Epoch 3/10, Batch 50/145, Loss: 0.1676
Epoch 3/10, Batch 60/145, Loss: 0.4071
Epoch 3/10, Batch 70/145, Loss: 0.3621
Epoch 3/10, Batch 80/145, Loss: 0.2905
Epoch 3/10, Batch 90/145, Loss: 0.4267
Epoch 3/10, Batch 100/145, Loss: 0.2180
Epoch 3/10, Batch 110/145, Loss: 0.1965
Epoch 3/10, Batch 120/145, Loss: 0.2769
Epoch 3/10, Batch 130/145, Loss: 0.1343
Epoch 3/10, Batch 140/145, Loss: 0.2675
Epoch 3/10, Train Loss: 0.2955, Valid Loss: 0.2626
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2339
Epoch 4/10, Batch 20/145, Loss: 0.3882
Epoch 4/10, Batch 30/145, Loss: 0.3360
Epoch 4/10, Batch 40/145, Loss: 0.3137
Epoch 4/10, Batch 50/145, Loss: 0.1540
Epoch 4/10, Batch 60/145, Loss: 0.1728
Epoch 4/10, Batch 70/145, Loss: 0.1882
Epoch 4/10, Batch 80/145, Loss: 0.3537
Epoch 4/10, Batch 90/145, Loss: 0.3203
Epoch 4/10, Batch 100/145, Loss: 0.3082
Epoch 4/10, Batch 110/145, Loss: 0.2435
Epoch 4/10, Batch 120/145, Loss: 0.1647
Epoch 4/10, Batch 130/145, Loss: 0.1599
Epoch 4/10, Batch 140/145, Loss: 0.1773
Epoch 4/10, Train Loss: 0.2627, Valid Loss: 0.2509
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1620
Epoch 5/10, Batch 20/145, Loss: 0.2029
Epoch 5/10, Batch 30/145, Loss: 0.2702
Epoch 5/10, Batch 40/145, Loss: 0.2290
Epoch 5/10, Batch 50/145, Loss: 0.1791
Epoch 5/10, Batch 60/145, Loss: 0.1549
Epoch 5/10, Batch 70/145, Loss: 0.2102
Epoch 5/10, Batch 80/145, Loss: 0.1987
Epoch 5/10, Batch 90/145, Loss: 0.2068
Epoch 5/10, Batch 100/145, Loss: 0.1965
Epoch 5/10, Batch 110/145, Loss: 0.2465
Epoch 5/10, Batch 120/145, Loss: 0.2334
Epoch 5/10, Batch 130/145, Loss: 0.1228
Epoch 5/10, Batch 140/145, Loss: 0.1676
Epoch 5/10, Train Loss: 0.2355, Valid Loss: 0.2323
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1659
Epoch 6/10, Batch 20/145, Loss: 0.1444
Epoch 6/10, Batch 30/145, Loss: 0.2679
Epoch 6/10, Batch 40/145, Loss: 0.1424
Epoch 6/10, Batch 50/145, Loss: 0.2289
Epoch 6/10, Batch 60/145, Loss: 0.2604
Epoch 6/10, Batch 70/145, Loss: 0.3413
Epoch 6/10, Batch 80/145, Loss: 0.2828
Epoch 6/10, Batch 90/145, Loss: 0.2806
Epoch 6/10, Batch 100/145, Loss: 0.2534
Epoch 6/10, Batch 110/145, Loss: 0.1174
Epoch 6/10, Batch 120/145, Loss: 0.2271
Epoch 6/10, Batch 130/145, Loss: 0.2800
Epoch 6/10, Batch 140/145, Loss: 0.3760
Epoch 6/10, Train Loss: 0.2278, Valid Loss: 0.2314
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3916
Epoch 7/10, Batch 20/145, Loss: 0.1857
Epoch 7/10, Batch 30/145, Loss: 0.1391
Epoch 7/10, Batch 40/145, Loss: 0.3429
Epoch 7/10, Batch 50/145, Loss: 0.1337
Epoch 7/10, Batch 60/145, Loss: 0.0532
Epoch 7/10, Batch 70/145, Loss: 0.1377
Epoch 7/10, Batch 80/145, Loss: 0.0894
Epoch 7/10, Batch 90/145, Loss: 0.2908
Epoch 7/10, Batch 100/145, Loss: 0.2016
Epoch 7/10, Batch 110/145, Loss: 0.2439
Epoch 7/10, Batch 120/145, Loss: 0.1838
Epoch 7/10, Batch 130/145, Loss: 0.1156
Epoch 7/10, Batch 140/145, Loss: 0.1960
Epoch 7/10, Train Loss: 0.2102, Valid Loss: 0.2204
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1099
Epoch 8/10, Batch 20/145, Loss: 0.0967
Epoch 8/10, Batch 30/145, Loss: 0.2428
Epoch 8/10, Batch 40/145, Loss: 0.2491
Epoch 8/10, Batch 50/145, Loss: 0.2244
Epoch 8/10, Batch 60/145, Loss: 0.1032
Epoch 8/10, Batch 70/145, Loss: 0.0789
Epoch 8/10, Batch 80/145, Loss: 0.1894
Epoch 8/10, Batch 90/145, Loss: 0.3104
Epoch 8/10, Batch 100/145, Loss: 0.1579
Epoch 8/10, Batch 110/145, Loss: 0.1940
Epoch 8/10, Batch 120/145, Loss: 0.1238
Epoch 8/10, Batch 130/145, Loss: 0.1359
Epoch 8/10, Batch 140/145, Loss: 0.3468
Epoch 8/10, Train Loss: 0.2039, Valid Loss: 0.2155
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2130
Epoch 9/10, Batch 20/145, Loss: 0.0827
Epoch 9/10, Batch 30/145, Loss: 0.1019
Epoch 9/10, Batch 40/145, Loss: 0.1417
Epoch 9/10, Batch 50/145, Loss: 0.2495
Epoch 9/10, Batch 60/145, Loss: 0.1564
Epoch 9/10, Batch 70/145, Loss: 0.1381
Epoch 9/10, Batch 80/145, Loss: 0.2147
Epoch 9/10, Batch 90/145, Loss: 0.0928
Epoch 9/10, Batch 100/145, Loss: 0.3367
Epoch 9/10, Batch 110/145, Loss: 0.1173
Epoch 9/10, Batch 120/145, Loss: 0.2207
Epoch 9/10, Batch 130/145, Loss: 0.1373
Epoch 9/10, Batch 140/145, Loss: 0.0885
Epoch 9/10, Train Loss: 0.1932, Valid Loss: 0.2103
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1439
Epoch 10/10, Batch 20/145, Loss: 0.2708
Epoch 10/10, Batch 30/145, Loss: 0.1678
Epoch 10/10, Batch 40/145, Loss: 0.2341
Epoch 10/10, Batch 50/145, Loss: 0.2305
Epoch 10/10, Batch 60/145, Loss: 0.1909
Epoch 10/10, Batch 70/145, Loss: 0.1582
Epoch 10/10, Batch 80/145, Loss: 0.3120
Epoch 10/10, Batch 90/145, Loss: 0.0911
Epoch 10/10, Batch 100/145, Loss: 0.1735
Epoch 10/10, Batch 110/145, Loss: 0.2995
Epoch 10/10, Batch 120/145, Loss: 0.2073
Epoch 10/10, Batch 130/145, Loss: 0.4911
Epoch 10/10, Batch 140/145, Loss: 0.1610
Epoch 10/10, Train Loss: 0.1936, Valid Loss: 0.2048
Model saved!
Accuracy: 0.9229
Precision: 0.9205
Recall: 0.9229
F1-score: 0.9214
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4887
Epoch 1/10, Batch 20/145, Loss: 0.8941
Epoch 1/10, Batch 30/145, Loss: 0.8851
Epoch 1/10, Batch 40/145, Loss: 0.8419
Epoch 1/10, Batch 50/145, Loss: 0.6668
Epoch 1/10, Batch 60/145, Loss: 0.5292
Epoch 1/10, Batch 70/145, Loss: 0.7366
Epoch 1/10, Batch 80/145, Loss: 0.6819
Epoch 1/10, Batch 90/145, Loss: 0.3911
Epoch 1/10, Batch 100/145, Loss: 0.4435
Epoch 1/10, Batch 110/145, Loss: 0.4850
Epoch 1/10, Batch 120/145, Loss: 0.6233
Epoch 1/10, Batch 130/145, Loss: 0.4326
Epoch 1/10, Batch 140/145, Loss: 0.5190
Epoch 1/10, Train Loss: 0.6844, Valid Loss: 0.3976
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2725
Epoch 2/10, Batch 20/145, Loss: 0.2816
Epoch 2/10, Batch 30/145, Loss: 0.3993
Epoch 2/10, Batch 40/145, Loss: 0.5610
Epoch 2/10, Batch 50/145, Loss: 0.2729
Epoch 2/10, Batch 60/145, Loss: 0.3771
Epoch 2/10, Batch 70/145, Loss: 0.3216
Epoch 2/10, Batch 80/145, Loss: 0.3729
Epoch 2/10, Batch 90/145, Loss: 0.2367
Epoch 2/10, Batch 100/145, Loss: 0.2698
Epoch 2/10, Batch 110/145, Loss: 0.3855
Epoch 2/10, Batch 120/145, Loss: 0.3579
Epoch 2/10, Batch 130/145, Loss: 0.5032
Epoch 2/10, Batch 140/145, Loss: 0.2170
Epoch 2/10, Train Loss: 0.3610, Valid Loss: 0.3105
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1674
Epoch 3/10, Batch 20/145, Loss: 0.2829
Epoch 3/10, Batch 30/145, Loss: 0.4060
Epoch 3/10, Batch 40/145, Loss: 0.2621
Epoch 3/10, Batch 50/145, Loss: 0.2727
Epoch 3/10, Batch 60/145, Loss: 0.2600
Epoch 3/10, Batch 70/145, Loss: 0.2390
Epoch 3/10, Batch 80/145, Loss: 0.4397
Epoch 3/10, Batch 90/145, Loss: 0.6446
Epoch 3/10, Batch 100/145, Loss: 0.3348
Epoch 3/10, Batch 110/145, Loss: 0.2067
Epoch 3/10, Batch 120/145, Loss: 0.2654
Epoch 3/10, Batch 130/145, Loss: 0.1592
Epoch 3/10, Batch 140/145, Loss: 0.2141
Epoch 3/10, Train Loss: 0.2988, Valid Loss: 0.2760
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1596
Epoch 4/10, Batch 20/145, Loss: 0.2007
Epoch 4/10, Batch 30/145, Loss: 0.3595
Epoch 4/10, Batch 40/145, Loss: 0.5447
Epoch 4/10, Batch 50/145, Loss: 0.2885
Epoch 4/10, Batch 60/145, Loss: 0.2689
Epoch 4/10, Batch 70/145, Loss: 0.1643
Epoch 4/10, Batch 80/145, Loss: 0.3513
Epoch 4/10, Batch 90/145, Loss: 0.2382
Epoch 4/10, Batch 100/145, Loss: 0.2505
Epoch 4/10, Batch 110/145, Loss: 0.1728
Epoch 4/10, Batch 120/145, Loss: 0.1472
Epoch 4/10, Batch 130/145, Loss: 0.1888
Epoch 4/10, Batch 140/145, Loss: 0.2146
Epoch 4/10, Train Loss: 0.2586, Valid Loss: 0.2727
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1902
Epoch 5/10, Batch 20/145, Loss: 0.1335
Epoch 5/10, Batch 30/145, Loss: 0.2103
Epoch 5/10, Batch 40/145, Loss: 0.2542
Epoch 5/10, Batch 50/145, Loss: 0.2412
Epoch 5/10, Batch 60/145, Loss: 0.2644
Epoch 5/10, Batch 70/145, Loss: 0.1911
Epoch 5/10, Batch 80/145, Loss: 0.4046
Epoch 5/10, Batch 90/145, Loss: 0.1891
Epoch 5/10, Batch 100/145, Loss: 0.1392
Epoch 5/10, Batch 110/145, Loss: 0.1232
Epoch 5/10, Batch 120/145, Loss: 0.2644
Epoch 5/10, Batch 130/145, Loss: 0.1786
Epoch 5/10, Batch 140/145, Loss: 0.3636
Epoch 5/10, Train Loss: 0.2406, Valid Loss: 0.2541
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1967
Epoch 6/10, Batch 20/145, Loss: 0.1953
Epoch 6/10, Batch 30/145, Loss: 0.3170
Epoch 6/10, Batch 40/145, Loss: 0.0816
Epoch 6/10, Batch 50/145, Loss: 0.1878
Epoch 6/10, Batch 60/145, Loss: 0.1504
Epoch 6/10, Batch 70/145, Loss: 0.3764
Epoch 6/10, Batch 80/145, Loss: 0.1957
Epoch 6/10, Batch 90/145, Loss: 0.2616
Epoch 6/10, Batch 100/145, Loss: 0.1022
Epoch 6/10, Batch 110/145, Loss: 0.1341
Epoch 6/10, Batch 120/145, Loss: 0.2265
Epoch 6/10, Batch 130/145, Loss: 0.1863
Epoch 6/10, Batch 140/145, Loss: 0.2742
Epoch 6/10, Train Loss: 0.2178, Valid Loss: 0.2547
Epoch 7/10, Batch 10/145, Loss: 0.2962
Epoch 7/10, Batch 20/145, Loss: 0.1462
Epoch 7/10, Batch 30/145, Loss: 0.0969
Epoch 7/10, Batch 40/145, Loss: 0.2958
Epoch 7/10, Batch 50/145, Loss: 0.1790
Epoch 7/10, Batch 60/145, Loss: 0.1701
Epoch 7/10, Batch 70/145, Loss: 0.2619
Epoch 7/10, Batch 80/145, Loss: 0.1345
Epoch 7/10, Batch 90/145, Loss: 0.2267
Epoch 7/10, Batch 100/145, Loss: 0.2996
Epoch 7/10, Batch 110/145, Loss: 0.2930
Epoch 7/10, Batch 120/145, Loss: 0.1131
Epoch 7/10, Batch 130/145, Loss: 0.3080
Epoch 7/10, Batch 140/145, Loss: 0.1052
Epoch 7/10, Train Loss: 0.2153, Valid Loss: 0.2513
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1898
Epoch 8/10, Batch 20/145, Loss: 0.3162
Epoch 8/10, Batch 30/145, Loss: 0.1656
Epoch 8/10, Batch 40/145, Loss: 0.3083
Epoch 8/10, Batch 50/145, Loss: 0.1761
Epoch 8/10, Batch 60/145, Loss: 0.2352
Epoch 8/10, Batch 70/145, Loss: 0.1055
Epoch 8/10, Batch 80/145, Loss: 0.1808
Epoch 8/10, Batch 90/145, Loss: 0.2314
Epoch 8/10, Batch 100/145, Loss: 0.3757
Epoch 8/10, Batch 110/145, Loss: 0.3576
Epoch 8/10, Batch 120/145, Loss: 0.2143
Epoch 8/10, Batch 130/145, Loss: 0.1914
Epoch 8/10, Batch 140/145, Loss: 0.2872
Epoch 8/10, Train Loss: 0.2035, Valid Loss: 0.2358
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2840
Epoch 9/10, Batch 20/145, Loss: 0.1606
Epoch 9/10, Batch 30/145, Loss: 0.2073
Epoch 9/10, Batch 40/145, Loss: 0.2467
Epoch 9/10, Batch 50/145, Loss: 0.1647
Epoch 9/10, Batch 60/145, Loss: 0.1589
Epoch 9/10, Batch 70/145, Loss: 0.1428
Epoch 9/10, Batch 80/145, Loss: 0.2550
Epoch 9/10, Batch 90/145, Loss: 0.2276
Epoch 9/10, Batch 100/145, Loss: 0.2699
Epoch 9/10, Batch 110/145, Loss: 0.1040
Epoch 9/10, Batch 120/145, Loss: 0.2879
Epoch 9/10, Batch 130/145, Loss: 0.2324
Epoch 9/10, Batch 140/145, Loss: 0.1824
Epoch 9/10, Train Loss: 0.1987, Valid Loss: 0.2305
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.3071
Epoch 10/10, Batch 20/145, Loss: 0.0925
Epoch 10/10, Batch 30/145, Loss: 0.1019
Epoch 10/10, Batch 40/145, Loss: 0.2334
Epoch 10/10, Batch 50/145, Loss: 0.3027
Epoch 10/10, Batch 60/145, Loss: 0.1667
Epoch 10/10, Batch 70/145, Loss: 0.0964
Epoch 10/10, Batch 80/145, Loss: 0.3730
Epoch 10/10, Batch 90/145, Loss: 0.0822
Epoch 10/10, Batch 100/145, Loss: 0.1532
Epoch 10/10, Batch 110/145, Loss: 0.2607
Epoch 10/10, Batch 120/145, Loss: 0.2291
Epoch 10/10, Batch 130/145, Loss: 0.1394
Epoch 10/10, Batch 140/145, Loss: 0.2007
Epoch 10/10, Train Loss: 0.1896, Valid Loss: 0.2294
Model saved!
Accuracy: 0.9264
Precision: 0.9248
Recall: 0.9264
F1-score: 0.9253
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5324
Epoch 1/10, Batch 20/145, Loss: 0.9282
Epoch 1/10, Batch 30/145, Loss: 0.8395
Epoch 1/10, Batch 40/145, Loss: 0.7943
Epoch 1/10, Batch 50/145, Loss: 0.6226
Epoch 1/10, Batch 60/145, Loss: 0.6639
Epoch 1/10, Batch 70/145, Loss: 0.6056
Epoch 1/10, Batch 80/145, Loss: 0.4907
Epoch 1/10, Batch 90/145, Loss: 0.4612
Epoch 1/10, Batch 100/145, Loss: 0.6265
Epoch 1/10, Batch 110/145, Loss: 0.3445
Epoch 1/10, Batch 120/145, Loss: 0.6093
Epoch 1/10, Batch 130/145, Loss: 0.3421
Epoch 1/10, Batch 140/145, Loss: 0.4723
Epoch 1/10, Train Loss: 0.6858, Valid Loss: 0.3605
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3141
Epoch 2/10, Batch 20/145, Loss: 0.4331
Epoch 2/10, Batch 30/145, Loss: 0.4512
Epoch 2/10, Batch 40/145, Loss: 0.5362
Epoch 2/10, Batch 50/145, Loss: 0.2885
Epoch 2/10, Batch 60/145, Loss: 0.3289
Epoch 2/10, Batch 70/145, Loss: 0.4435
Epoch 2/10, Batch 80/145, Loss: 0.3299
Epoch 2/10, Batch 90/145, Loss: 0.3102
Epoch 2/10, Batch 100/145, Loss: 0.2392
Epoch 2/10, Batch 110/145, Loss: 0.1534
Epoch 2/10, Batch 120/145, Loss: 0.3187
Epoch 2/10, Batch 130/145, Loss: 0.4428
Epoch 2/10, Batch 140/145, Loss: 0.3073
Epoch 2/10, Train Loss: 0.3641, Valid Loss: 0.2745
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.4142
Epoch 3/10, Batch 20/145, Loss: 0.3590
Epoch 3/10, Batch 30/145, Loss: 0.2318
Epoch 3/10, Batch 40/145, Loss: 0.2643
Epoch 3/10, Batch 50/145, Loss: 0.2300
Epoch 3/10, Batch 60/145, Loss: 0.3074
Epoch 3/10, Batch 70/145, Loss: 0.2833
Epoch 3/10, Batch 80/145, Loss: 0.1838
Epoch 3/10, Batch 90/145, Loss: 0.4813
Epoch 3/10, Batch 100/145, Loss: 0.2824
Epoch 3/10, Batch 110/145, Loss: 0.2318
Epoch 3/10, Batch 120/145, Loss: 0.2791
Epoch 3/10, Batch 130/145, Loss: 0.1885
Epoch 3/10, Batch 140/145, Loss: 0.2049
Epoch 3/10, Train Loss: 0.3088, Valid Loss: 0.2480
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2360
Epoch 4/10, Batch 20/145, Loss: 0.1420
Epoch 4/10, Batch 30/145, Loss: 0.3170
Epoch 4/10, Batch 40/145, Loss: 0.1722
Epoch 4/10, Batch 50/145, Loss: 0.2256
Epoch 4/10, Batch 60/145, Loss: 0.2818
Epoch 4/10, Batch 70/145, Loss: 0.1958
Epoch 4/10, Batch 80/145, Loss: 0.2628
Epoch 4/10, Batch 90/145, Loss: 0.2325
Epoch 4/10, Batch 100/145, Loss: 0.1992
Epoch 4/10, Batch 110/145, Loss: 0.3191
Epoch 4/10, Batch 120/145, Loss: 0.3349
Epoch 4/10, Batch 130/145, Loss: 0.2731
Epoch 4/10, Batch 140/145, Loss: 0.2559
Epoch 4/10, Train Loss: 0.2638, Valid Loss: 0.2371
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2623
Epoch 5/10, Batch 20/145, Loss: 0.3003
Epoch 5/10, Batch 30/145, Loss: 0.1900
Epoch 5/10, Batch 40/145, Loss: 0.1925
Epoch 5/10, Batch 50/145, Loss: 0.2152
Epoch 5/10, Batch 60/145, Loss: 0.3058
Epoch 5/10, Batch 70/145, Loss: 0.2562
Epoch 5/10, Batch 80/145, Loss: 0.4839
Epoch 5/10, Batch 90/145, Loss: 0.1034
Epoch 5/10, Batch 100/145, Loss: 0.2839
Epoch 5/10, Batch 110/145, Loss: 0.1781
Epoch 5/10, Batch 120/145, Loss: 0.3468
Epoch 5/10, Batch 130/145, Loss: 0.1772
Epoch 5/10, Batch 140/145, Loss: 0.3416
Epoch 5/10, Train Loss: 0.2402, Valid Loss: 0.2246
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1190
Epoch 6/10, Batch 20/145, Loss: 0.3313
Epoch 6/10, Batch 30/145, Loss: 0.1432
Epoch 6/10, Batch 40/145, Loss: 0.2733
Epoch 6/10, Batch 50/145, Loss: 0.2603
Epoch 6/10, Batch 60/145, Loss: 0.1049
Epoch 6/10, Batch 70/145, Loss: 0.4970
Epoch 6/10, Batch 80/145, Loss: 0.3943
Epoch 6/10, Batch 90/145, Loss: 0.1523
Epoch 6/10, Batch 100/145, Loss: 0.2724
Epoch 6/10, Batch 110/145, Loss: 0.1348
Epoch 6/10, Batch 120/145, Loss: 0.2300
Epoch 6/10, Batch 130/145, Loss: 0.1269
Epoch 6/10, Batch 140/145, Loss: 0.1663
Epoch 6/10, Train Loss: 0.2270, Valid Loss: 0.2142
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3723
Epoch 7/10, Batch 20/145, Loss: 0.1917
Epoch 7/10, Batch 30/145, Loss: 0.3450
Epoch 7/10, Batch 40/145, Loss: 0.3605
Epoch 7/10, Batch 50/145, Loss: 0.1936
Epoch 7/10, Batch 60/145, Loss: 0.1227
Epoch 7/10, Batch 70/145, Loss: 0.1664
Epoch 7/10, Batch 80/145, Loss: 0.1459
Epoch 7/10, Batch 90/145, Loss: 0.2861
Epoch 7/10, Batch 100/145, Loss: 0.1619
Epoch 7/10, Batch 110/145, Loss: 0.2658
Epoch 7/10, Batch 120/145, Loss: 0.1016
Epoch 7/10, Batch 130/145, Loss: 0.2977
Epoch 7/10, Batch 140/145, Loss: 0.0810
Epoch 7/10, Train Loss: 0.2183, Valid Loss: 0.2111
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2082
Epoch 8/10, Batch 20/145, Loss: 0.1177
Epoch 8/10, Batch 30/145, Loss: 0.1731
Epoch 8/10, Batch 40/145, Loss: 0.4719
Epoch 8/10, Batch 50/145, Loss: 0.2535
Epoch 8/10, Batch 60/145, Loss: 0.2236
Epoch 8/10, Batch 70/145, Loss: 0.1190
Epoch 8/10, Batch 80/145, Loss: 0.1659
Epoch 8/10, Batch 90/145, Loss: 0.1148
Epoch 8/10, Batch 100/145, Loss: 0.1641
Epoch 8/10, Batch 110/145, Loss: 0.2214
Epoch 8/10, Batch 120/145, Loss: 0.2133
Epoch 8/10, Batch 130/145, Loss: 0.1475
Epoch 8/10, Batch 140/145, Loss: 0.2421
Epoch 8/10, Train Loss: 0.2101, Valid Loss: 0.2031
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2772
Epoch 9/10, Batch 20/145, Loss: 0.0932
Epoch 9/10, Batch 30/145, Loss: 0.1378
Epoch 9/10, Batch 40/145, Loss: 0.2593
Epoch 9/10, Batch 50/145, Loss: 0.2153
Epoch 9/10, Batch 60/145, Loss: 0.1325
Epoch 9/10, Batch 70/145, Loss: 0.1725
Epoch 9/10, Batch 80/145, Loss: 0.2276
Epoch 9/10, Batch 90/145, Loss: 0.2920
Epoch 9/10, Batch 100/145, Loss: 0.2456
Epoch 9/10, Batch 110/145, Loss: 0.0748
Epoch 9/10, Batch 120/145, Loss: 0.1273
Epoch 9/10, Batch 130/145, Loss: 0.1169
Epoch 9/10, Batch 140/145, Loss: 0.1143
Epoch 9/10, Train Loss: 0.2050, Valid Loss: 0.1984
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2427
Epoch 10/10, Batch 20/145, Loss: 0.2167
Epoch 10/10, Batch 30/145, Loss: 0.0978
Epoch 10/10, Batch 40/145, Loss: 0.2701
Epoch 10/10, Batch 50/145, Loss: 0.2118
Epoch 10/10, Batch 60/145, Loss: 0.2774
Epoch 10/10, Batch 70/145, Loss: 0.1754
Epoch 10/10, Batch 80/145, Loss: 0.4205
Epoch 10/10, Batch 90/145, Loss: 0.2628
Epoch 10/10, Batch 100/145, Loss: 0.1192
Epoch 10/10, Batch 110/145, Loss: 0.2962
Epoch 10/10, Batch 120/145, Loss: 0.1963
Epoch 10/10, Batch 130/145, Loss: 0.2240
Epoch 10/10, Batch 140/145, Loss: 0.2369
Epoch 10/10, Train Loss: 0.1989, Valid Loss: 0.1950
Model saved!
Accuracy: 0.9217
Precision: 0.9203
Recall: 0.9217
F1-score: 0.9209
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5128
Epoch 1/10, Batch 20/145, Loss: 0.9433
Epoch 1/10, Batch 30/145, Loss: 0.8406
Epoch 1/10, Batch 40/145, Loss: 0.7170
Epoch 1/10, Batch 50/145, Loss: 0.6914
Epoch 1/10, Batch 60/145, Loss: 0.5545
Epoch 1/10, Batch 70/145, Loss: 0.6229
Epoch 1/10, Batch 80/145, Loss: 0.4901
Epoch 1/10, Batch 90/145, Loss: 0.5595
Epoch 1/10, Batch 100/145, Loss: 0.6780
Epoch 1/10, Batch 110/145, Loss: 0.3879
Epoch 1/10, Batch 120/145, Loss: 0.5989
Epoch 1/10, Batch 130/145, Loss: 0.6229
Epoch 1/10, Batch 140/145, Loss: 0.4109
Epoch 1/10, Train Loss: 0.6843, Valid Loss: 0.3884
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2854
Epoch 2/10, Batch 20/145, Loss: 0.5022
Epoch 2/10, Batch 30/145, Loss: 0.2593
Epoch 2/10, Batch 40/145, Loss: 0.4563
Epoch 2/10, Batch 50/145, Loss: 0.3774
Epoch 2/10, Batch 60/145, Loss: 0.4868
Epoch 2/10, Batch 70/145, Loss: 0.3398
Epoch 2/10, Batch 80/145, Loss: 0.3344
Epoch 2/10, Batch 90/145, Loss: 0.3478
Epoch 2/10, Batch 100/145, Loss: 0.4713
Epoch 2/10, Batch 110/145, Loss: 0.2035
Epoch 2/10, Batch 120/145, Loss: 0.3956
Epoch 2/10, Batch 130/145, Loss: 0.3060
Epoch 2/10, Batch 140/145, Loss: 0.3116
Epoch 2/10, Train Loss: 0.3587, Valid Loss: 0.3097
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3145
Epoch 3/10, Batch 20/145, Loss: 0.1625
Epoch 3/10, Batch 30/145, Loss: 0.2949
Epoch 3/10, Batch 40/145, Loss: 0.1669
Epoch 3/10, Batch 50/145, Loss: 0.2392
Epoch 3/10, Batch 60/145, Loss: 0.2618
Epoch 3/10, Batch 70/145, Loss: 0.2050
Epoch 3/10, Batch 80/145, Loss: 0.2767
Epoch 3/10, Batch 90/145, Loss: 0.4370
Epoch 3/10, Batch 100/145, Loss: 0.2736
Epoch 3/10, Batch 110/145, Loss: 0.2684
Epoch 3/10, Batch 120/145, Loss: 0.2949
Epoch 3/10, Batch 130/145, Loss: 0.2202
Epoch 3/10, Batch 140/145, Loss: 0.2203
Epoch 3/10, Train Loss: 0.3079, Valid Loss: 0.2693
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1225
Epoch 4/10, Batch 20/145, Loss: 0.2064
Epoch 4/10, Batch 30/145, Loss: 0.2885
Epoch 4/10, Batch 40/145, Loss: 0.2136
Epoch 4/10, Batch 50/145, Loss: 0.2041
Epoch 4/10, Batch 60/145, Loss: 0.2052
Epoch 4/10, Batch 70/145, Loss: 0.1748
Epoch 4/10, Batch 80/145, Loss: 0.3452
Epoch 4/10, Batch 90/145, Loss: 0.2147
Epoch 4/10, Batch 100/145, Loss: 0.2759
Epoch 4/10, Batch 110/145, Loss: 0.1800
Epoch 4/10, Batch 120/145, Loss: 0.3700
Epoch 4/10, Batch 130/145, Loss: 0.1942
Epoch 4/10, Batch 140/145, Loss: 0.2151
Epoch 4/10, Train Loss: 0.2659, Valid Loss: 0.2633
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2918
Epoch 5/10, Batch 20/145, Loss: 0.2917
Epoch 5/10, Batch 30/145, Loss: 0.2544
Epoch 5/10, Batch 40/145, Loss: 0.3379
Epoch 5/10, Batch 50/145, Loss: 0.2103
Epoch 5/10, Batch 60/145, Loss: 0.4430
Epoch 5/10, Batch 70/145, Loss: 0.2895
Epoch 5/10, Batch 80/145, Loss: 0.3481
Epoch 5/10, Batch 90/145, Loss: 0.2755
Epoch 5/10, Batch 100/145, Loss: 0.1347
Epoch 5/10, Batch 110/145, Loss: 0.2618
Epoch 5/10, Batch 120/145, Loss: 0.1278
Epoch 5/10, Batch 130/145, Loss: 0.2185
Epoch 5/10, Batch 140/145, Loss: 0.2254
Epoch 5/10, Train Loss: 0.2434, Valid Loss: 0.2498
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2702
Epoch 6/10, Batch 20/145, Loss: 0.2490
Epoch 6/10, Batch 30/145, Loss: 0.3354
Epoch 6/10, Batch 40/145, Loss: 0.1867
Epoch 6/10, Batch 50/145, Loss: 0.2587
Epoch 6/10, Batch 60/145, Loss: 0.1198
Epoch 6/10, Batch 70/145, Loss: 0.2331
Epoch 6/10, Batch 80/145, Loss: 0.4862
Epoch 6/10, Batch 90/145, Loss: 0.3361
Epoch 6/10, Batch 100/145, Loss: 0.1556
Epoch 6/10, Batch 110/145, Loss: 0.2872
Epoch 6/10, Batch 120/145, Loss: 0.2852
Epoch 6/10, Batch 130/145, Loss: 0.1534
Epoch 6/10, Batch 140/145, Loss: 0.3313
Epoch 6/10, Train Loss: 0.2326, Valid Loss: 0.2579
Epoch 7/10, Batch 10/145, Loss: 0.2481
Epoch 7/10, Batch 20/145, Loss: 0.1491
Epoch 7/10, Batch 30/145, Loss: 0.1322
Epoch 7/10, Batch 40/145, Loss: 0.3819
Epoch 7/10, Batch 50/145, Loss: 0.1672
Epoch 7/10, Batch 60/145, Loss: 0.1088
Epoch 7/10, Batch 70/145, Loss: 0.2411
Epoch 7/10, Batch 80/145, Loss: 0.1438
Epoch 7/10, Batch 90/145, Loss: 0.2681
Epoch 7/10, Batch 100/145, Loss: 0.1481
Epoch 7/10, Batch 110/145, Loss: 0.3182
Epoch 7/10, Batch 120/145, Loss: 0.1109
Epoch 7/10, Batch 130/145, Loss: 0.3228
Epoch 7/10, Batch 140/145, Loss: 0.0879
Epoch 7/10, Train Loss: 0.2224, Valid Loss: 0.2453
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1949
Epoch 8/10, Batch 20/145, Loss: 0.2122
Epoch 8/10, Batch 30/145, Loss: 0.1697
Epoch 8/10, Batch 40/145, Loss: 0.2837
Epoch 8/10, Batch 50/145, Loss: 0.1883
Epoch 8/10, Batch 60/145, Loss: 0.2883
Epoch 8/10, Batch 70/145, Loss: 0.0700
Epoch 8/10, Batch 80/145, Loss: 0.2196
Epoch 8/10, Batch 90/145, Loss: 0.3128
Epoch 8/10, Batch 100/145, Loss: 0.2013
Epoch 8/10, Batch 110/145, Loss: 0.3025
Epoch 8/10, Batch 120/145, Loss: 0.1899
Epoch 8/10, Batch 130/145, Loss: 0.1262
Epoch 8/10, Batch 140/145, Loss: 0.2262
Epoch 8/10, Train Loss: 0.2128, Valid Loss: 0.2324
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1271
Epoch 9/10, Batch 20/145, Loss: 0.1172
Epoch 9/10, Batch 30/145, Loss: 0.0904
Epoch 9/10, Batch 40/145, Loss: 0.1089
Epoch 9/10, Batch 50/145, Loss: 0.3030
Epoch 9/10, Batch 60/145, Loss: 0.1731
Epoch 9/10, Batch 70/145, Loss: 0.1554
Epoch 9/10, Batch 80/145, Loss: 0.1923
Epoch 9/10, Batch 90/145, Loss: 0.1885
Epoch 9/10, Batch 100/145, Loss: 0.2690
Epoch 9/10, Batch 110/145, Loss: 0.1138
Epoch 9/10, Batch 120/145, Loss: 0.1066
Epoch 9/10, Batch 130/145, Loss: 0.1442
Epoch 9/10, Batch 140/145, Loss: 0.1607
Epoch 9/10, Train Loss: 0.2048, Valid Loss: 0.2287
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2257
Epoch 10/10, Batch 20/145, Loss: 0.0761
Epoch 10/10, Batch 30/145, Loss: 0.1885
Epoch 10/10, Batch 40/145, Loss: 0.2430
Epoch 10/10, Batch 50/145, Loss: 0.1603
Epoch 10/10, Batch 60/145, Loss: 0.1814
Epoch 10/10, Batch 70/145, Loss: 0.2834
Epoch 10/10, Batch 80/145, Loss: 0.4647
Epoch 10/10, Batch 90/145, Loss: 0.1703
Epoch 10/10, Batch 100/145, Loss: 0.2881
Epoch 10/10, Batch 110/145, Loss: 0.2305
Epoch 10/10, Batch 120/145, Loss: 0.1358
Epoch 10/10, Batch 130/145, Loss: 0.3552
Epoch 10/10, Batch 140/145, Loss: 0.1510
Epoch 10/10, Train Loss: 0.1973, Valid Loss: 0.2204
Model saved!
Accuracy: 0.9299
Precision: 0.9287
Recall: 0.9299
F1-score: 0.9291
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 17. Fitness: 0.9299
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5061
Epoch 1/10, Batch 20/145, Loss: 0.9438
Epoch 1/10, Batch 30/145, Loss: 0.8301
Epoch 1/10, Batch 40/145, Loss: 0.7974
Epoch 1/10, Batch 50/145, Loss: 0.6223
Epoch 1/10, Batch 60/145, Loss: 0.5803
Epoch 1/10, Batch 70/145, Loss: 0.7153
Epoch 1/10, Batch 80/145, Loss: 0.5507
Epoch 1/10, Batch 90/145, Loss: 0.6541
Epoch 1/10, Batch 100/145, Loss: 0.5798
Epoch 1/10, Batch 110/145, Loss: 0.4238
Epoch 1/10, Batch 120/145, Loss: 0.5940
Epoch 1/10, Batch 130/145, Loss: 0.4091
Epoch 1/10, Batch 140/145, Loss: 0.4998
Epoch 1/10, Train Loss: 0.6893, Valid Loss: 0.3761
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3513
Epoch 2/10, Batch 20/145, Loss: 0.5255
Epoch 2/10, Batch 30/145, Loss: 0.3337
Epoch 2/10, Batch 40/145, Loss: 0.5805
Epoch 2/10, Batch 50/145, Loss: 0.3320
Epoch 2/10, Batch 60/145, Loss: 0.3094
Epoch 2/10, Batch 70/145, Loss: 0.3578
Epoch 2/10, Batch 80/145, Loss: 0.2742
Epoch 2/10, Batch 90/145, Loss: 0.2633
Epoch 2/10, Batch 100/145, Loss: 0.4427
Epoch 2/10, Batch 110/145, Loss: 0.3798
Epoch 2/10, Batch 120/145, Loss: 0.5200
Epoch 2/10, Batch 130/145, Loss: 0.3563
Epoch 2/10, Batch 140/145, Loss: 0.3574
Epoch 2/10, Train Loss: 0.3644, Valid Loss: 0.2975
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3257
Epoch 3/10, Batch 20/145, Loss: 0.2080
Epoch 3/10, Batch 30/145, Loss: 0.1999
Epoch 3/10, Batch 40/145, Loss: 0.2427
Epoch 3/10, Batch 50/145, Loss: 0.1730
Epoch 3/10, Batch 60/145, Loss: 0.3634
Epoch 3/10, Batch 70/145, Loss: 0.2572
Epoch 3/10, Batch 80/145, Loss: 0.2554
Epoch 3/10, Batch 90/145, Loss: 0.3558
Epoch 3/10, Batch 100/145, Loss: 0.3644
Epoch 3/10, Batch 110/145, Loss: 0.1917
Epoch 3/10, Batch 120/145, Loss: 0.4103
Epoch 3/10, Batch 130/145, Loss: 0.2154
Epoch 3/10, Batch 140/145, Loss: 0.2628
Epoch 3/10, Train Loss: 0.3029, Valid Loss: 0.2723
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2653
Epoch 4/10, Batch 20/145, Loss: 0.1769
Epoch 4/10, Batch 30/145, Loss: 0.2331
Epoch 4/10, Batch 40/145, Loss: 0.3745
Epoch 4/10, Batch 50/145, Loss: 0.2360
Epoch 4/10, Batch 60/145, Loss: 0.2181
Epoch 4/10, Batch 70/145, Loss: 0.2013
Epoch 4/10, Batch 80/145, Loss: 0.3539
Epoch 4/10, Batch 90/145, Loss: 0.2669
Epoch 4/10, Batch 100/145, Loss: 0.3041
Epoch 4/10, Batch 110/145, Loss: 0.1950
Epoch 4/10, Batch 120/145, Loss: 0.1051
Epoch 4/10, Batch 130/145, Loss: 0.2295
Epoch 4/10, Batch 140/145, Loss: 0.2526
Epoch 4/10, Train Loss: 0.2618, Valid Loss: 0.2516
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2024
Epoch 5/10, Batch 20/145, Loss: 0.2965
Epoch 5/10, Batch 30/145, Loss: 0.4175
Epoch 5/10, Batch 40/145, Loss: 0.3034
Epoch 5/10, Batch 50/145, Loss: 0.2016
Epoch 5/10, Batch 60/145, Loss: 0.2196
Epoch 5/10, Batch 70/145, Loss: 0.2371
Epoch 5/10, Batch 80/145, Loss: 0.2278
Epoch 5/10, Batch 90/145, Loss: 0.3071
Epoch 5/10, Batch 100/145, Loss: 0.2872
Epoch 5/10, Batch 110/145, Loss: 0.1207
Epoch 5/10, Batch 120/145, Loss: 0.2943
Epoch 5/10, Batch 130/145, Loss: 0.1750
Epoch 5/10, Batch 140/145, Loss: 0.3487
Epoch 5/10, Train Loss: 0.2390, Valid Loss: 0.2406
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2278
Epoch 6/10, Batch 20/145, Loss: 0.1292
Epoch 6/10, Batch 30/145, Loss: 0.4913
Epoch 6/10, Batch 40/145, Loss: 0.1346
Epoch 6/10, Batch 50/145, Loss: 0.1339
Epoch 6/10, Batch 60/145, Loss: 0.2119
Epoch 6/10, Batch 70/145, Loss: 0.3714
Epoch 6/10, Batch 80/145, Loss: 0.2456
Epoch 6/10, Batch 90/145, Loss: 0.3041
Epoch 6/10, Batch 100/145, Loss: 0.3243
Epoch 6/10, Batch 110/145, Loss: 0.1432
Epoch 6/10, Batch 120/145, Loss: 0.1848
Epoch 6/10, Batch 130/145, Loss: 0.2261
Epoch 6/10, Batch 140/145, Loss: 0.3294
Epoch 6/10, Train Loss: 0.2361, Valid Loss: 0.2323
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2270
Epoch 7/10, Batch 20/145, Loss: 0.1286
Epoch 7/10, Batch 30/145, Loss: 0.1528
Epoch 7/10, Batch 40/145, Loss: 0.4559
Epoch 7/10, Batch 50/145, Loss: 0.3527
Epoch 7/10, Batch 60/145, Loss: 0.1902
Epoch 7/10, Batch 70/145, Loss: 0.2214
Epoch 7/10, Batch 80/145, Loss: 0.1409
Epoch 7/10, Batch 90/145, Loss: 0.2196
Epoch 7/10, Batch 100/145, Loss: 0.1744
Epoch 7/10, Batch 110/145, Loss: 0.4400
Epoch 7/10, Batch 120/145, Loss: 0.1588
Epoch 7/10, Batch 130/145, Loss: 0.3230
Epoch 7/10, Batch 140/145, Loss: 0.1684
Epoch 7/10, Train Loss: 0.2221, Valid Loss: 0.2205
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1751
Epoch 8/10, Batch 20/145, Loss: 0.1983
Epoch 8/10, Batch 30/145, Loss: 0.1716
Epoch 8/10, Batch 40/145, Loss: 0.3953
Epoch 8/10, Batch 50/145, Loss: 0.1382
Epoch 8/10, Batch 60/145, Loss: 0.1203
Epoch 8/10, Batch 70/145, Loss: 0.1541
Epoch 8/10, Batch 80/145, Loss: 0.1944
Epoch 8/10, Batch 90/145, Loss: 0.1918
Epoch 8/10, Batch 100/145, Loss: 0.2860
Epoch 8/10, Batch 110/145, Loss: 0.0841
Epoch 8/10, Batch 120/145, Loss: 0.2345
Epoch 8/10, Batch 130/145, Loss: 0.2008
Epoch 8/10, Batch 140/145, Loss: 0.1679
Epoch 8/10, Train Loss: 0.2149, Valid Loss: 0.2216
Epoch 9/10, Batch 10/145, Loss: 0.3373
Epoch 9/10, Batch 20/145, Loss: 0.1446
Epoch 9/10, Batch 30/145, Loss: 0.0749
Epoch 9/10, Batch 40/145, Loss: 0.1528
Epoch 9/10, Batch 50/145, Loss: 0.2416
Epoch 9/10, Batch 60/145, Loss: 0.1291
Epoch 9/10, Batch 70/145, Loss: 0.2100
Epoch 9/10, Batch 80/145, Loss: 0.1809
Epoch 9/10, Batch 90/145, Loss: 0.1997
Epoch 9/10, Batch 100/145, Loss: 0.1600
Epoch 9/10, Batch 110/145, Loss: 0.3260
Epoch 9/10, Batch 120/145, Loss: 0.1924
Epoch 9/10, Batch 130/145, Loss: 0.2035
Epoch 9/10, Batch 140/145, Loss: 0.1216
Epoch 9/10, Train Loss: 0.2121, Valid Loss: 0.2089
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1430
Epoch 10/10, Batch 20/145, Loss: 0.1479
Epoch 10/10, Batch 30/145, Loss: 0.1031
Epoch 10/10, Batch 40/145, Loss: 0.1886
Epoch 10/10, Batch 50/145, Loss: 0.2819
Epoch 10/10, Batch 60/145, Loss: 0.2605
Epoch 10/10, Batch 70/145, Loss: 0.1235
Epoch 10/10, Batch 80/145, Loss: 0.6794
Epoch 10/10, Batch 90/145, Loss: 0.1204
Epoch 10/10, Batch 100/145, Loss: 0.2829
Epoch 10/10, Batch 110/145, Loss: 0.1838
Epoch 10/10, Batch 120/145, Loss: 0.0978
Epoch 10/10, Batch 130/145, Loss: 0.2666
Epoch 10/10, Batch 140/145, Loss: 0.2989
Epoch 10/10, Train Loss: 0.2006, Valid Loss: 0.2114
Accuracy: 0.9171
Precision: 0.9145
Recall: 0.9171
F1-score: 0.9150
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5334
Epoch 1/10, Batch 20/145, Loss: 0.8078
Epoch 1/10, Batch 30/145, Loss: 0.8353
Epoch 1/10, Batch 40/145, Loss: 0.7150
Epoch 1/10, Batch 50/145, Loss: 0.6351
Epoch 1/10, Batch 60/145, Loss: 0.6380
Epoch 1/10, Batch 70/145, Loss: 0.7145
Epoch 1/10, Batch 80/145, Loss: 0.5110
Epoch 1/10, Batch 90/145, Loss: 0.4891
Epoch 1/10, Batch 100/145, Loss: 0.5898
Epoch 1/10, Batch 110/145, Loss: 0.4659
Epoch 1/10, Batch 120/145, Loss: 0.6385
Epoch 1/10, Batch 130/145, Loss: 0.4664
Epoch 1/10, Batch 140/145, Loss: 0.4331
Epoch 1/10, Train Loss: 0.6846, Valid Loss: 0.3954
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3804
Epoch 2/10, Batch 20/145, Loss: 0.5176
Epoch 2/10, Batch 30/145, Loss: 0.4139
Epoch 2/10, Batch 40/145, Loss: 0.2864
Epoch 2/10, Batch 50/145, Loss: 0.4032
Epoch 2/10, Batch 60/145, Loss: 0.2922
Epoch 2/10, Batch 70/145, Loss: 0.3863
Epoch 2/10, Batch 80/145, Loss: 0.2111
Epoch 2/10, Batch 90/145, Loss: 0.3271
Epoch 2/10, Batch 100/145, Loss: 0.2448
Epoch 2/10, Batch 110/145, Loss: 0.2863
Epoch 2/10, Batch 120/145, Loss: 0.3879
Epoch 2/10, Batch 130/145, Loss: 0.3989
Epoch 2/10, Batch 140/145, Loss: 0.2634
Epoch 2/10, Train Loss: 0.3549, Valid Loss: 0.3118
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2231
Epoch 3/10, Batch 20/145, Loss: 0.4610
Epoch 3/10, Batch 30/145, Loss: 0.1068
Epoch 3/10, Batch 40/145, Loss: 0.2366
Epoch 3/10, Batch 50/145, Loss: 0.2321
Epoch 3/10, Batch 60/145, Loss: 0.2215
Epoch 3/10, Batch 70/145, Loss: 0.1502
Epoch 3/10, Batch 80/145, Loss: 0.2878
Epoch 3/10, Batch 90/145, Loss: 0.4481
Epoch 3/10, Batch 100/145, Loss: 0.2032
Epoch 3/10, Batch 110/145, Loss: 0.2426
Epoch 3/10, Batch 120/145, Loss: 0.1844
Epoch 3/10, Batch 130/145, Loss: 0.1737
Epoch 3/10, Batch 140/145, Loss: 0.2620
Epoch 3/10, Train Loss: 0.3029, Valid Loss: 0.2859
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1931
Epoch 4/10, Batch 20/145, Loss: 0.2167
Epoch 4/10, Batch 30/145, Loss: 0.3094
Epoch 4/10, Batch 40/145, Loss: 0.2978
Epoch 4/10, Batch 50/145, Loss: 0.1813
Epoch 4/10, Batch 60/145, Loss: 0.1729
Epoch 4/10, Batch 70/145, Loss: 0.3389
Epoch 4/10, Batch 80/145, Loss: 0.4359
Epoch 4/10, Batch 90/145, Loss: 0.1648
Epoch 4/10, Batch 100/145, Loss: 0.2328
Epoch 4/10, Batch 110/145, Loss: 0.2374
Epoch 4/10, Batch 120/145, Loss: 0.1761
Epoch 4/10, Batch 130/145, Loss: 0.1124
Epoch 4/10, Batch 140/145, Loss: 0.2802
Epoch 4/10, Train Loss: 0.2598, Valid Loss: 0.2746
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2332
Epoch 5/10, Batch 20/145, Loss: 0.1842
Epoch 5/10, Batch 30/145, Loss: 0.1906
Epoch 5/10, Batch 40/145, Loss: 0.1752
Epoch 5/10, Batch 50/145, Loss: 0.1230
Epoch 5/10, Batch 60/145, Loss: 0.2623
Epoch 5/10, Batch 70/145, Loss: 0.2563
Epoch 5/10, Batch 80/145, Loss: 0.3601
Epoch 5/10, Batch 90/145, Loss: 0.2095
Epoch 5/10, Batch 100/145, Loss: 0.1467
Epoch 5/10, Batch 110/145, Loss: 0.2651
Epoch 5/10, Batch 120/145, Loss: 0.1120
Epoch 5/10, Batch 130/145, Loss: 0.1764
Epoch 5/10, Batch 140/145, Loss: 0.2762
Epoch 5/10, Train Loss: 0.2355, Valid Loss: 0.2524
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1965
Epoch 6/10, Batch 20/145, Loss: 0.2121
Epoch 6/10, Batch 30/145, Loss: 0.2656
Epoch 6/10, Batch 40/145, Loss: 0.0849
Epoch 6/10, Batch 50/145, Loss: 0.3216
Epoch 6/10, Batch 60/145, Loss: 0.1520
Epoch 6/10, Batch 70/145, Loss: 0.3296
Epoch 6/10, Batch 80/145, Loss: 0.4117
Epoch 6/10, Batch 90/145, Loss: 0.2710
Epoch 6/10, Batch 100/145, Loss: 0.2939
Epoch 6/10, Batch 110/145, Loss: 0.1698
Epoch 6/10, Batch 120/145, Loss: 0.3245
Epoch 6/10, Batch 130/145, Loss: 0.2207
Epoch 6/10, Batch 140/145, Loss: 0.2117
Epoch 6/10, Train Loss: 0.2247, Valid Loss: 0.2558
Epoch 7/10, Batch 10/145, Loss: 0.3483
Epoch 7/10, Batch 20/145, Loss: 0.1932
Epoch 7/10, Batch 30/145, Loss: 0.1580
Epoch 7/10, Batch 40/145, Loss: 0.4602
Epoch 7/10, Batch 50/145, Loss: 0.1133
Epoch 7/10, Batch 60/145, Loss: 0.3897
Epoch 7/10, Batch 70/145, Loss: 0.2406
Epoch 7/10, Batch 80/145, Loss: 0.1699
Epoch 7/10, Batch 90/145, Loss: 0.3651
Epoch 7/10, Batch 100/145, Loss: 0.3514
Epoch 7/10, Batch 110/145, Loss: 0.3756
Epoch 7/10, Batch 120/145, Loss: 0.1349
Epoch 7/10, Batch 130/145, Loss: 0.1972
Epoch 7/10, Batch 140/145, Loss: 0.2171
Epoch 7/10, Train Loss: 0.2158, Valid Loss: 0.2519
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2406
Epoch 8/10, Batch 20/145, Loss: 0.1326
Epoch 8/10, Batch 30/145, Loss: 0.1910
Epoch 8/10, Batch 40/145, Loss: 0.1467
Epoch 8/10, Batch 50/145, Loss: 0.1515
Epoch 8/10, Batch 60/145, Loss: 0.1967
Epoch 8/10, Batch 70/145, Loss: 0.1134
Epoch 8/10, Batch 80/145, Loss: 0.2204
Epoch 8/10, Batch 90/145, Loss: 0.1747
Epoch 8/10, Batch 100/145, Loss: 0.2401
Epoch 8/10, Batch 110/145, Loss: 0.3494
Epoch 8/10, Batch 120/145, Loss: 0.0907
Epoch 8/10, Batch 130/145, Loss: 0.1318
Epoch 8/10, Batch 140/145, Loss: 0.1338
Epoch 8/10, Train Loss: 0.2066, Valid Loss: 0.2430
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2037
Epoch 9/10, Batch 20/145, Loss: 0.1502
Epoch 9/10, Batch 30/145, Loss: 0.1279
Epoch 9/10, Batch 40/145, Loss: 0.1396
Epoch 9/10, Batch 50/145, Loss: 0.1419
Epoch 9/10, Batch 60/145, Loss: 0.1657
Epoch 9/10, Batch 70/145, Loss: 0.2743
Epoch 9/10, Batch 80/145, Loss: 0.2337
Epoch 9/10, Batch 90/145, Loss: 0.0919
Epoch 9/10, Batch 100/145, Loss: 0.2646
Epoch 9/10, Batch 110/145, Loss: 0.0607
Epoch 9/10, Batch 120/145, Loss: 0.2419
Epoch 9/10, Batch 130/145, Loss: 0.0848
Epoch 9/10, Batch 140/145, Loss: 0.0876
Epoch 9/10, Train Loss: 0.1974, Valid Loss: 0.2382
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1501
Epoch 10/10, Batch 20/145, Loss: 0.1495
Epoch 10/10, Batch 30/145, Loss: 0.0706
Epoch 10/10, Batch 40/145, Loss: 0.1280
Epoch 10/10, Batch 50/145, Loss: 0.2482
Epoch 10/10, Batch 60/145, Loss: 0.1525
Epoch 10/10, Batch 70/145, Loss: 0.2332
Epoch 10/10, Batch 80/145, Loss: 0.4385
Epoch 10/10, Batch 90/145, Loss: 0.2583
Epoch 10/10, Batch 100/145, Loss: 0.1671
Epoch 10/10, Batch 110/145, Loss: 0.2388
Epoch 10/10, Batch 120/145, Loss: 0.3317
Epoch 10/10, Batch 130/145, Loss: 0.3996
Epoch 10/10, Batch 140/145, Loss: 0.3773
Epoch 10/10, Train Loss: 0.1954, Valid Loss: 0.2353
Model saved!
Accuracy: 0.9206
Precision: 0.9186
Recall: 0.9206
F1-score: 0.9193
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4761
Epoch 1/10, Batch 20/145, Loss: 0.9024
Epoch 1/10, Batch 30/145, Loss: 0.7987
Epoch 1/10, Batch 40/145, Loss: 0.8102
Epoch 1/10, Batch 50/145, Loss: 0.6033
Epoch 1/10, Batch 60/145, Loss: 0.4826
Epoch 1/10, Batch 70/145, Loss: 0.6901
Epoch 1/10, Batch 80/145, Loss: 0.4894
Epoch 1/10, Batch 90/145, Loss: 0.4849
Epoch 1/10, Batch 100/145, Loss: 0.6439
Epoch 1/10, Batch 110/145, Loss: 0.3701
Epoch 1/10, Batch 120/145, Loss: 0.5903
Epoch 1/10, Batch 130/145, Loss: 0.3800
Epoch 1/10, Batch 140/145, Loss: 0.4014
Epoch 1/10, Train Loss: 0.7041, Valid Loss: 0.3679
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4545
Epoch 2/10, Batch 20/145, Loss: 0.3728
Epoch 2/10, Batch 30/145, Loss: 0.3566
Epoch 2/10, Batch 40/145, Loss: 0.3917
Epoch 2/10, Batch 50/145, Loss: 0.3808
Epoch 2/10, Batch 60/145, Loss: 0.3537
Epoch 2/10, Batch 70/145, Loss: 0.5835
Epoch 2/10, Batch 80/145, Loss: 0.4011
Epoch 2/10, Batch 90/145, Loss: 0.3179
Epoch 2/10, Batch 100/145, Loss: 0.3060
Epoch 2/10, Batch 110/145, Loss: 0.3354
Epoch 2/10, Batch 120/145, Loss: 0.3605
Epoch 2/10, Batch 130/145, Loss: 0.3023
Epoch 2/10, Batch 140/145, Loss: 0.2208
Epoch 2/10, Train Loss: 0.3710, Valid Loss: 0.2829
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1730
Epoch 3/10, Batch 20/145, Loss: 0.3015
Epoch 3/10, Batch 30/145, Loss: 0.3261
Epoch 3/10, Batch 40/145, Loss: 0.4656
Epoch 3/10, Batch 50/145, Loss: 0.3158
Epoch 3/10, Batch 60/145, Loss: 0.3189
Epoch 3/10, Batch 70/145, Loss: 0.3003
Epoch 3/10, Batch 80/145, Loss: 0.1909
Epoch 3/10, Batch 90/145, Loss: 0.2886
Epoch 3/10, Batch 100/145, Loss: 0.2571
Epoch 3/10, Batch 110/145, Loss: 0.1925
Epoch 3/10, Batch 120/145, Loss: 0.2402
Epoch 3/10, Batch 130/145, Loss: 0.5105
Epoch 3/10, Batch 140/145, Loss: 0.2173
Epoch 3/10, Train Loss: 0.3151, Valid Loss: 0.2568
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2555
Epoch 4/10, Batch 20/145, Loss: 0.3369
Epoch 4/10, Batch 30/145, Loss: 0.2674
Epoch 4/10, Batch 40/145, Loss: 0.3978
Epoch 4/10, Batch 50/145, Loss: 0.2789
Epoch 4/10, Batch 60/145, Loss: 0.2242
Epoch 4/10, Batch 70/145, Loss: 0.2005
Epoch 4/10, Batch 80/145, Loss: 0.2903
Epoch 4/10, Batch 90/145, Loss: 0.2601
Epoch 4/10, Batch 100/145, Loss: 0.2557
Epoch 4/10, Batch 110/145, Loss: 0.1962
Epoch 4/10, Batch 120/145, Loss: 0.2247
Epoch 4/10, Batch 130/145, Loss: 0.1794
Epoch 4/10, Batch 140/145, Loss: 0.1838
Epoch 4/10, Train Loss: 0.2758, Valid Loss: 0.2455
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2709
Epoch 5/10, Batch 20/145, Loss: 0.2056
Epoch 5/10, Batch 30/145, Loss: 0.1988
Epoch 5/10, Batch 40/145, Loss: 0.2196
Epoch 5/10, Batch 50/145, Loss: 0.1938
Epoch 5/10, Batch 60/145, Loss: 0.2322
Epoch 5/10, Batch 70/145, Loss: 0.1550
Epoch 5/10, Batch 80/145, Loss: 0.3966
Epoch 5/10, Batch 90/145, Loss: 0.1250
Epoch 5/10, Batch 100/145, Loss: 0.2577
Epoch 5/10, Batch 110/145, Loss: 0.1437
Epoch 5/10, Batch 120/145, Loss: 0.2164
Epoch 5/10, Batch 130/145, Loss: 0.1522
Epoch 5/10, Batch 140/145, Loss: 0.2134
Epoch 5/10, Train Loss: 0.2442, Valid Loss: 0.2449
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2253
Epoch 6/10, Batch 20/145, Loss: 0.3759
Epoch 6/10, Batch 30/145, Loss: 0.2592
Epoch 6/10, Batch 40/145, Loss: 0.3058
Epoch 6/10, Batch 50/145, Loss: 0.2645
Epoch 6/10, Batch 60/145, Loss: 0.2035
Epoch 6/10, Batch 70/145, Loss: 0.3534
Epoch 6/10, Batch 80/145, Loss: 0.3604
Epoch 6/10, Batch 90/145, Loss: 0.1001
Epoch 6/10, Batch 100/145, Loss: 0.2922
Epoch 6/10, Batch 110/145, Loss: 0.1348
Epoch 6/10, Batch 120/145, Loss: 0.2195
Epoch 6/10, Batch 130/145, Loss: 0.1738
Epoch 6/10, Batch 140/145, Loss: 0.3170
Epoch 6/10, Train Loss: 0.2404, Valid Loss: 0.2141
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3015
Epoch 7/10, Batch 20/145, Loss: 0.3198
Epoch 7/10, Batch 30/145, Loss: 0.0966
Epoch 7/10, Batch 40/145, Loss: 0.3949
Epoch 7/10, Batch 50/145, Loss: 0.1986
Epoch 7/10, Batch 60/145, Loss: 0.1145
Epoch 7/10, Batch 70/145, Loss: 0.2712
Epoch 7/10, Batch 80/145, Loss: 0.0886
Epoch 7/10, Batch 90/145, Loss: 0.3123
Epoch 7/10, Batch 100/145, Loss: 0.1739
Epoch 7/10, Batch 110/145, Loss: 0.1791
Epoch 7/10, Batch 120/145, Loss: 0.2025
Epoch 7/10, Batch 130/145, Loss: 0.2648
Epoch 7/10, Batch 140/145, Loss: 0.1260
Epoch 7/10, Train Loss: 0.2233, Valid Loss: 0.2016
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1530
Epoch 8/10, Batch 20/145, Loss: 0.1763
Epoch 8/10, Batch 30/145, Loss: 0.2478
Epoch 8/10, Batch 40/145, Loss: 0.2898
Epoch 8/10, Batch 50/145, Loss: 0.2280
Epoch 8/10, Batch 60/145, Loss: 0.0952
Epoch 8/10, Batch 70/145, Loss: 0.2275
Epoch 8/10, Batch 80/145, Loss: 0.1537
Epoch 8/10, Batch 90/145, Loss: 0.1759
Epoch 8/10, Batch 100/145, Loss: 0.2329
Epoch 8/10, Batch 110/145, Loss: 0.2412
Epoch 8/10, Batch 120/145, Loss: 0.1870
Epoch 8/10, Batch 130/145, Loss: 0.1556
Epoch 8/10, Batch 140/145, Loss: 0.2226
Epoch 8/10, Train Loss: 0.2213, Valid Loss: 0.2031
Epoch 9/10, Batch 10/145, Loss: 0.2040
Epoch 9/10, Batch 20/145, Loss: 0.1580
Epoch 9/10, Batch 30/145, Loss: 0.1082
Epoch 9/10, Batch 40/145, Loss: 0.1060
Epoch 9/10, Batch 50/145, Loss: 0.1117
Epoch 9/10, Batch 60/145, Loss: 0.1637
Epoch 9/10, Batch 70/145, Loss: 0.1941
Epoch 9/10, Batch 80/145, Loss: 0.1847
Epoch 9/10, Batch 90/145, Loss: 0.2436
Epoch 9/10, Batch 100/145, Loss: 0.1907
Epoch 9/10, Batch 110/145, Loss: 0.1935
Epoch 9/10, Batch 120/145, Loss: 0.1903
Epoch 9/10, Batch 130/145, Loss: 0.2384
Epoch 9/10, Batch 140/145, Loss: 0.1516
Epoch 9/10, Train Loss: 0.2136, Valid Loss: 0.1952
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2545
Epoch 10/10, Batch 20/145, Loss: 0.1384
Epoch 10/10, Batch 30/145, Loss: 0.1115
Epoch 10/10, Batch 40/145, Loss: 0.2142
Epoch 10/10, Batch 50/145, Loss: 0.1651
Epoch 10/10, Batch 60/145, Loss: 0.1269
Epoch 10/10, Batch 70/145, Loss: 0.1598
Epoch 10/10, Batch 80/145, Loss: 0.2969
Epoch 10/10, Batch 90/145, Loss: 0.1424
Epoch 10/10, Batch 100/145, Loss: 0.2352
Epoch 10/10, Batch 110/145, Loss: 0.1303
Epoch 10/10, Batch 120/145, Loss: 0.1765
Epoch 10/10, Batch 130/145, Loss: 0.4407
Epoch 10/10, Batch 140/145, Loss: 0.1740
Epoch 10/10, Train Loss: 0.2041, Valid Loss: 0.1961
Accuracy: 0.9194
Precision: 0.9176
Recall: 0.9194
F1-score: 0.9173
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5058
Epoch 1/10, Batch 20/145, Loss: 0.8764
Epoch 1/10, Batch 30/145, Loss: 0.8652
Epoch 1/10, Batch 40/145, Loss: 0.8853
Epoch 1/10, Batch 50/145, Loss: 0.6592
Epoch 1/10, Batch 60/145, Loss: 0.6139
Epoch 1/10, Batch 70/145, Loss: 0.6453
Epoch 1/10, Batch 80/145, Loss: 0.5121
Epoch 1/10, Batch 90/145, Loss: 0.5789
Epoch 1/10, Batch 100/145, Loss: 0.6098
Epoch 1/10, Batch 110/145, Loss: 0.3836
Epoch 1/10, Batch 120/145, Loss: 0.7358
Epoch 1/10, Batch 130/145, Loss: 0.2996
Epoch 1/10, Batch 140/145, Loss: 0.6676
Epoch 1/10, Train Loss: 0.6930, Valid Loss: 0.3775
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.5637
Epoch 2/10, Batch 20/145, Loss: 0.5019
Epoch 2/10, Batch 30/145, Loss: 0.2844
Epoch 2/10, Batch 40/145, Loss: 0.4786
Epoch 2/10, Batch 50/145, Loss: 0.2467
Epoch 2/10, Batch 60/145, Loss: 0.4167
Epoch 2/10, Batch 70/145, Loss: 0.3747
Epoch 2/10, Batch 80/145, Loss: 0.3516
Epoch 2/10, Batch 90/145, Loss: 0.2649
Epoch 2/10, Batch 100/145, Loss: 0.2363
Epoch 2/10, Batch 110/145, Loss: 0.2842
Epoch 2/10, Batch 120/145, Loss: 0.3966
Epoch 2/10, Batch 130/145, Loss: 0.3354
Epoch 2/10, Batch 140/145, Loss: 0.3564
Epoch 2/10, Train Loss: 0.3613, Valid Loss: 0.2901
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2218
Epoch 3/10, Batch 20/145, Loss: 0.2565
Epoch 3/10, Batch 30/145, Loss: 0.2576
Epoch 3/10, Batch 40/145, Loss: 0.1612
Epoch 3/10, Batch 50/145, Loss: 0.1845
Epoch 3/10, Batch 60/145, Loss: 0.2753
Epoch 3/10, Batch 70/145, Loss: 0.3380
Epoch 3/10, Batch 80/145, Loss: 0.1393
Epoch 3/10, Batch 90/145, Loss: 0.5295
Epoch 3/10, Batch 100/145, Loss: 0.2562
Epoch 3/10, Batch 110/145, Loss: 0.1893
Epoch 3/10, Batch 120/145, Loss: 0.2063
Epoch 3/10, Batch 130/145, Loss: 0.3628
Epoch 3/10, Batch 140/145, Loss: 0.3122
Epoch 3/10, Train Loss: 0.3045, Valid Loss: 0.2614
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1850
Epoch 4/10, Batch 20/145, Loss: 0.2283
Epoch 4/10, Batch 30/145, Loss: 0.4242
Epoch 4/10, Batch 40/145, Loss: 0.2797
Epoch 4/10, Batch 50/145, Loss: 0.2835
Epoch 4/10, Batch 60/145, Loss: 0.1808
Epoch 4/10, Batch 70/145, Loss: 0.3972
Epoch 4/10, Batch 80/145, Loss: 0.2007
Epoch 4/10, Batch 90/145, Loss: 0.3043
Epoch 4/10, Batch 100/145, Loss: 0.2584
Epoch 4/10, Batch 110/145, Loss: 0.3446
Epoch 4/10, Batch 120/145, Loss: 0.2535
Epoch 4/10, Batch 130/145, Loss: 0.1357
Epoch 4/10, Batch 140/145, Loss: 0.2987
Epoch 4/10, Train Loss: 0.2694, Valid Loss: 0.2441
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3070
Epoch 5/10, Batch 20/145, Loss: 0.5659
Epoch 5/10, Batch 30/145, Loss: 0.2733
Epoch 5/10, Batch 40/145, Loss: 0.2357
Epoch 5/10, Batch 50/145, Loss: 0.1707
Epoch 5/10, Batch 60/145, Loss: 0.2855
Epoch 5/10, Batch 70/145, Loss: 0.3321
Epoch 5/10, Batch 80/145, Loss: 0.2075
Epoch 5/10, Batch 90/145, Loss: 0.1965
Epoch 5/10, Batch 100/145, Loss: 0.3172
Epoch 5/10, Batch 110/145, Loss: 0.1066
Epoch 5/10, Batch 120/145, Loss: 0.2298
Epoch 5/10, Batch 130/145, Loss: 0.2071
Epoch 5/10, Batch 140/145, Loss: 0.1700
Epoch 5/10, Train Loss: 0.2436, Valid Loss: 0.2317
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3825
Epoch 6/10, Batch 20/145, Loss: 0.3370
Epoch 6/10, Batch 30/145, Loss: 0.2222
Epoch 6/10, Batch 40/145, Loss: 0.1247
Epoch 6/10, Batch 50/145, Loss: 0.4715
Epoch 6/10, Batch 60/145, Loss: 0.1314
Epoch 6/10, Batch 70/145, Loss: 0.2754
Epoch 6/10, Batch 80/145, Loss: 0.1293
Epoch 6/10, Batch 90/145, Loss: 0.2184
Epoch 6/10, Batch 100/145, Loss: 0.2440
Epoch 6/10, Batch 110/145, Loss: 0.1935
Epoch 6/10, Batch 120/145, Loss: 0.1429
Epoch 6/10, Batch 130/145, Loss: 0.1255
Epoch 6/10, Batch 140/145, Loss: 0.1933
Epoch 6/10, Train Loss: 0.2307, Valid Loss: 0.2386
Epoch 7/10, Batch 10/145, Loss: 0.4244
Epoch 7/10, Batch 20/145, Loss: 0.2465
Epoch 7/10, Batch 30/145, Loss: 0.1944
Epoch 7/10, Batch 40/145, Loss: 0.3447
Epoch 7/10, Batch 50/145, Loss: 0.1927
Epoch 7/10, Batch 60/145, Loss: 0.1596
Epoch 7/10, Batch 70/145, Loss: 0.3247
Epoch 7/10, Batch 80/145, Loss: 0.1664
Epoch 7/10, Batch 90/145, Loss: 0.2873
Epoch 7/10, Batch 100/145, Loss: 0.1160
Epoch 7/10, Batch 110/145, Loss: 0.2668
Epoch 7/10, Batch 120/145, Loss: 0.1766
Epoch 7/10, Batch 130/145, Loss: 0.2401
Epoch 7/10, Batch 140/145, Loss: 0.2181
Epoch 7/10, Train Loss: 0.2187, Valid Loss: 0.2303
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2077
Epoch 8/10, Batch 20/145, Loss: 0.1591
Epoch 8/10, Batch 30/145, Loss: 0.1094
Epoch 8/10, Batch 40/145, Loss: 0.2309
Epoch 8/10, Batch 50/145, Loss: 0.3987
Epoch 8/10, Batch 60/145, Loss: 0.2419
Epoch 8/10, Batch 70/145, Loss: 0.2382
Epoch 8/10, Batch 80/145, Loss: 0.1072
Epoch 8/10, Batch 90/145, Loss: 0.2263
Epoch 8/10, Batch 100/145, Loss: 0.4464
Epoch 8/10, Batch 110/145, Loss: 0.1206
Epoch 8/10, Batch 120/145, Loss: 0.1809
Epoch 8/10, Batch 130/145, Loss: 0.3059
Epoch 8/10, Batch 140/145, Loss: 0.2932
Epoch 8/10, Train Loss: 0.2171, Valid Loss: 0.2188
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2655
Epoch 9/10, Batch 20/145, Loss: 0.1071
Epoch 9/10, Batch 30/145, Loss: 0.2130
Epoch 9/10, Batch 40/145, Loss: 0.1156
Epoch 9/10, Batch 50/145, Loss: 0.2397
Epoch 9/10, Batch 60/145, Loss: 0.3200
Epoch 9/10, Batch 70/145, Loss: 0.0944
Epoch 9/10, Batch 80/145, Loss: 0.2587
Epoch 9/10, Batch 90/145, Loss: 0.1425
Epoch 9/10, Batch 100/145, Loss: 0.1231
Epoch 9/10, Batch 110/145, Loss: 0.1442
Epoch 9/10, Batch 120/145, Loss: 0.1753
Epoch 9/10, Batch 130/145, Loss: 0.2040
Epoch 9/10, Batch 140/145, Loss: 0.1384
Epoch 9/10, Train Loss: 0.2087, Valid Loss: 0.2122
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0612
Epoch 10/10, Batch 20/145, Loss: 0.2101
Epoch 10/10, Batch 30/145, Loss: 0.0765
Epoch 10/10, Batch 40/145, Loss: 0.1570
Epoch 10/10, Batch 50/145, Loss: 0.2624
Epoch 10/10, Batch 60/145, Loss: 0.1326
Epoch 10/10, Batch 70/145, Loss: 0.1259
Epoch 10/10, Batch 80/145, Loss: 0.2931
Epoch 10/10, Batch 90/145, Loss: 0.1356
Epoch 10/10, Batch 100/145, Loss: 0.0750
Epoch 10/10, Batch 110/145, Loss: 0.3674
Epoch 10/10, Batch 120/145, Loss: 0.2833
Epoch 10/10, Batch 130/145, Loss: 0.1839
Epoch 10/10, Batch 140/145, Loss: 0.2164
Epoch 10/10, Train Loss: 0.2001, Valid Loss: 0.2087
Model saved!
Accuracy: 0.9322
Precision: 0.9309
Recall: 0.9322
F1-score: 0.9315
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 21. Fitness: 0.9322
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5010
Epoch 1/10, Batch 20/145, Loss: 0.8633
Epoch 1/10, Batch 30/145, Loss: 0.8575
Epoch 1/10, Batch 40/145, Loss: 0.8937
Epoch 1/10, Batch 50/145, Loss: 0.6082
Epoch 1/10, Batch 60/145, Loss: 0.4999
Epoch 1/10, Batch 70/145, Loss: 0.6532
Epoch 1/10, Batch 80/145, Loss: 0.4205
Epoch 1/10, Batch 90/145, Loss: 0.6467
Epoch 1/10, Batch 100/145, Loss: 0.4081
Epoch 1/10, Batch 110/145, Loss: 0.4283
Epoch 1/10, Batch 120/145, Loss: 0.7182
Epoch 1/10, Batch 130/145, Loss: 0.3937
Epoch 1/10, Batch 140/145, Loss: 0.4005
Epoch 1/10, Train Loss: 0.6830, Valid Loss: 0.3869
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4523
Epoch 2/10, Batch 20/145, Loss: 0.5525
Epoch 2/10, Batch 30/145, Loss: 0.3016
Epoch 2/10, Batch 40/145, Loss: 0.4932
Epoch 2/10, Batch 50/145, Loss: 0.3586
Epoch 2/10, Batch 60/145, Loss: 0.4343
Epoch 2/10, Batch 70/145, Loss: 0.3319
Epoch 2/10, Batch 80/145, Loss: 0.4162
Epoch 2/10, Batch 90/145, Loss: 0.2420
Epoch 2/10, Batch 100/145, Loss: 0.2167
Epoch 2/10, Batch 110/145, Loss: 0.2402
Epoch 2/10, Batch 120/145, Loss: 0.5397
Epoch 2/10, Batch 130/145, Loss: 0.4180
Epoch 2/10, Batch 140/145, Loss: 0.2103
Epoch 2/10, Train Loss: 0.3594, Valid Loss: 0.2897
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2701
Epoch 3/10, Batch 20/145, Loss: 0.2418
Epoch 3/10, Batch 30/145, Loss: 0.2904
Epoch 3/10, Batch 40/145, Loss: 0.2173
Epoch 3/10, Batch 50/145, Loss: 0.2168
Epoch 3/10, Batch 60/145, Loss: 0.2535
Epoch 3/10, Batch 70/145, Loss: 0.3801
Epoch 3/10, Batch 80/145, Loss: 0.2370
Epoch 3/10, Batch 90/145, Loss: 0.5812
Epoch 3/10, Batch 100/145, Loss: 0.2929
Epoch 3/10, Batch 110/145, Loss: 0.2498
Epoch 3/10, Batch 120/145, Loss: 0.1288
Epoch 3/10, Batch 130/145, Loss: 0.3006
Epoch 3/10, Batch 140/145, Loss: 0.2465
Epoch 3/10, Train Loss: 0.3027, Valid Loss: 0.2571
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2249
Epoch 4/10, Batch 20/145, Loss: 0.2529
Epoch 4/10, Batch 30/145, Loss: 0.2120
Epoch 4/10, Batch 40/145, Loss: 0.2425
Epoch 4/10, Batch 50/145, Loss: 0.3086
Epoch 4/10, Batch 60/145, Loss: 0.2616
Epoch 4/10, Batch 70/145, Loss: 0.1999
Epoch 4/10, Batch 80/145, Loss: 0.3619
Epoch 4/10, Batch 90/145, Loss: 0.2207
Epoch 4/10, Batch 100/145, Loss: 0.2438
Epoch 4/10, Batch 110/145, Loss: 0.1779
Epoch 4/10, Batch 120/145, Loss: 0.2001
Epoch 4/10, Batch 130/145, Loss: 0.2341
Epoch 4/10, Batch 140/145, Loss: 0.1396
Epoch 4/10, Train Loss: 0.2637, Valid Loss: 0.2507
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2759
Epoch 5/10, Batch 20/145, Loss: 0.2108
Epoch 5/10, Batch 30/145, Loss: 0.3196
Epoch 5/10, Batch 40/145, Loss: 0.2781
Epoch 5/10, Batch 50/145, Loss: 0.1166
Epoch 5/10, Batch 60/145, Loss: 0.2531
Epoch 5/10, Batch 70/145, Loss: 0.1184
Epoch 5/10, Batch 80/145, Loss: 0.2374
Epoch 5/10, Batch 90/145, Loss: 0.2031
Epoch 5/10, Batch 100/145, Loss: 0.2930
Epoch 5/10, Batch 110/145, Loss: 0.1176
Epoch 5/10, Batch 120/145, Loss: 0.2244
Epoch 5/10, Batch 130/145, Loss: 0.2501
Epoch 5/10, Batch 140/145, Loss: 0.3523
Epoch 5/10, Train Loss: 0.2349, Valid Loss: 0.2337
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3740
Epoch 6/10, Batch 20/145, Loss: 0.3238
Epoch 6/10, Batch 30/145, Loss: 0.2139
Epoch 6/10, Batch 40/145, Loss: 0.0875
Epoch 6/10, Batch 50/145, Loss: 0.2560
Epoch 6/10, Batch 60/145, Loss: 0.2058
Epoch 6/10, Batch 70/145, Loss: 0.2654
Epoch 6/10, Batch 80/145, Loss: 0.2540
Epoch 6/10, Batch 90/145, Loss: 0.3470
Epoch 6/10, Batch 100/145, Loss: 0.4790
Epoch 6/10, Batch 110/145, Loss: 0.2683
Epoch 6/10, Batch 120/145, Loss: 0.2551
Epoch 6/10, Batch 130/145, Loss: 0.0859
Epoch 6/10, Batch 140/145, Loss: 0.1653
Epoch 6/10, Train Loss: 0.2307, Valid Loss: 0.2267
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3062
Epoch 7/10, Batch 20/145, Loss: 0.3142
Epoch 7/10, Batch 30/145, Loss: 0.1928
Epoch 7/10, Batch 40/145, Loss: 0.3543
Epoch 7/10, Batch 50/145, Loss: 0.1821
Epoch 7/10, Batch 60/145, Loss: 0.1177
Epoch 7/10, Batch 70/145, Loss: 0.2770
Epoch 7/10, Batch 80/145, Loss: 0.2030
Epoch 7/10, Batch 90/145, Loss: 0.2546
Epoch 7/10, Batch 100/145, Loss: 0.1274
Epoch 7/10, Batch 110/145, Loss: 0.2788
Epoch 7/10, Batch 120/145, Loss: 0.2271
Epoch 7/10, Batch 130/145, Loss: 0.2473
Epoch 7/10, Batch 140/145, Loss: 0.1334
Epoch 7/10, Train Loss: 0.2136, Valid Loss: 0.2200
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1267
Epoch 8/10, Batch 20/145, Loss: 0.1439
Epoch 8/10, Batch 30/145, Loss: 0.2726
Epoch 8/10, Batch 40/145, Loss: 0.1929
Epoch 8/10, Batch 50/145, Loss: 0.2773
Epoch 8/10, Batch 60/145, Loss: 0.3083
Epoch 8/10, Batch 70/145, Loss: 0.1993
Epoch 8/10, Batch 80/145, Loss: 0.1227
Epoch 8/10, Batch 90/145, Loss: 0.3032
Epoch 8/10, Batch 100/145, Loss: 0.2026
Epoch 8/10, Batch 110/145, Loss: 0.2725
Epoch 8/10, Batch 120/145, Loss: 0.1953
Epoch 8/10, Batch 130/145, Loss: 0.1678
Epoch 8/10, Batch 140/145, Loss: 0.1814
Epoch 8/10, Train Loss: 0.2008, Valid Loss: 0.2160
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.0828
Epoch 9/10, Batch 20/145, Loss: 0.1624
Epoch 9/10, Batch 30/145, Loss: 0.1264
Epoch 9/10, Batch 40/145, Loss: 0.1021
Epoch 9/10, Batch 50/145, Loss: 0.1780
Epoch 9/10, Batch 60/145, Loss: 0.1733
Epoch 9/10, Batch 70/145, Loss: 0.2057
Epoch 9/10, Batch 80/145, Loss: 0.1698
Epoch 9/10, Batch 90/145, Loss: 0.3573
Epoch 9/10, Batch 100/145, Loss: 0.3479
Epoch 9/10, Batch 110/145, Loss: 0.1045
Epoch 9/10, Batch 120/145, Loss: 0.2618
Epoch 9/10, Batch 130/145, Loss: 0.1593
Epoch 9/10, Batch 140/145, Loss: 0.1589
Epoch 9/10, Train Loss: 0.1917, Valid Loss: 0.2038
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2126
Epoch 10/10, Batch 20/145, Loss: 0.1583
Epoch 10/10, Batch 30/145, Loss: 0.1563
Epoch 10/10, Batch 40/145, Loss: 0.1739
Epoch 10/10, Batch 50/145, Loss: 0.2442
Epoch 10/10, Batch 60/145, Loss: 0.1952
Epoch 10/10, Batch 70/145, Loss: 0.1171
Epoch 10/10, Batch 80/145, Loss: 0.2466
Epoch 10/10, Batch 90/145, Loss: 0.0965
Epoch 10/10, Batch 100/145, Loss: 0.0844
Epoch 10/10, Batch 110/145, Loss: 0.3512
Epoch 10/10, Batch 120/145, Loss: 0.1047
Epoch 10/10, Batch 130/145, Loss: 0.1907
Epoch 10/10, Batch 140/145, Loss: 0.1704
Epoch 10/10, Train Loss: 0.1875, Valid Loss: 0.2058
Accuracy: 0.9217
Precision: 0.9197
Recall: 0.9217
F1-score: 0.9200
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5257
Epoch 1/10, Batch 20/145, Loss: 0.9704
Epoch 1/10, Batch 30/145, Loss: 0.9126
Epoch 1/10, Batch 40/145, Loss: 0.7411
Epoch 1/10, Batch 50/145, Loss: 0.6336
Epoch 1/10, Batch 60/145, Loss: 0.5108
Epoch 1/10, Batch 70/145, Loss: 0.6092
Epoch 1/10, Batch 80/145, Loss: 0.6725
Epoch 1/10, Batch 90/145, Loss: 0.5334
Epoch 1/10, Batch 100/145, Loss: 0.5703
Epoch 1/10, Batch 110/145, Loss: 0.4271
Epoch 1/10, Batch 120/145, Loss: 0.6303
Epoch 1/10, Batch 130/145, Loss: 0.3475
Epoch 1/10, Batch 140/145, Loss: 0.4034
Epoch 1/10, Train Loss: 0.6885, Valid Loss: 0.3727
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3740
Epoch 2/10, Batch 20/145, Loss: 0.5254
Epoch 2/10, Batch 30/145, Loss: 0.3300
Epoch 2/10, Batch 40/145, Loss: 0.6080
Epoch 2/10, Batch 50/145, Loss: 0.3495
Epoch 2/10, Batch 60/145, Loss: 0.4261
Epoch 2/10, Batch 70/145, Loss: 0.3447
Epoch 2/10, Batch 80/145, Loss: 0.3823
Epoch 2/10, Batch 90/145, Loss: 0.3135
Epoch 2/10, Batch 100/145, Loss: 0.2605
Epoch 2/10, Batch 110/145, Loss: 0.2635
Epoch 2/10, Batch 120/145, Loss: 0.3881
Epoch 2/10, Batch 130/145, Loss: 0.3464
Epoch 2/10, Batch 140/145, Loss: 0.3163
Epoch 2/10, Train Loss: 0.3663, Valid Loss: 0.2822
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1617
Epoch 3/10, Batch 20/145, Loss: 0.2420
Epoch 3/10, Batch 30/145, Loss: 0.3437
Epoch 3/10, Batch 40/145, Loss: 0.3534
Epoch 3/10, Batch 50/145, Loss: 0.1423
Epoch 3/10, Batch 60/145, Loss: 0.2406
Epoch 3/10, Batch 70/145, Loss: 0.2997
Epoch 3/10, Batch 80/145, Loss: 0.2125
Epoch 3/10, Batch 90/145, Loss: 0.3847
Epoch 3/10, Batch 100/145, Loss: 0.2297
Epoch 3/10, Batch 110/145, Loss: 0.2551
Epoch 3/10, Batch 120/145, Loss: 0.1230
Epoch 3/10, Batch 130/145, Loss: 0.3722
Epoch 3/10, Batch 140/145, Loss: 0.2559
Epoch 3/10, Train Loss: 0.3107, Valid Loss: 0.2547
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4274
Epoch 4/10, Batch 20/145, Loss: 0.2405
Epoch 4/10, Batch 30/145, Loss: 0.2542
Epoch 4/10, Batch 40/145, Loss: 0.2523
Epoch 4/10, Batch 50/145, Loss: 0.2918
Epoch 4/10, Batch 60/145, Loss: 0.1962
Epoch 4/10, Batch 70/145, Loss: 0.2932
Epoch 4/10, Batch 80/145, Loss: 0.1844
Epoch 4/10, Batch 90/145, Loss: 0.2779
Epoch 4/10, Batch 100/145, Loss: 0.2078
Epoch 4/10, Batch 110/145, Loss: 0.1623
Epoch 4/10, Batch 120/145, Loss: 0.2835
Epoch 4/10, Batch 130/145, Loss: 0.1700
Epoch 4/10, Batch 140/145, Loss: 0.1262
Epoch 4/10, Train Loss: 0.2643, Valid Loss: 0.2498
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2569
Epoch 5/10, Batch 20/145, Loss: 0.2109
Epoch 5/10, Batch 30/145, Loss: 0.1920
Epoch 5/10, Batch 40/145, Loss: 0.2883
Epoch 5/10, Batch 50/145, Loss: 0.1725
Epoch 5/10, Batch 60/145, Loss: 0.4315
Epoch 5/10, Batch 70/145, Loss: 0.2022
Epoch 5/10, Batch 80/145, Loss: 0.2500
Epoch 5/10, Batch 90/145, Loss: 0.2327
Epoch 5/10, Batch 100/145, Loss: 0.2256
Epoch 5/10, Batch 110/145, Loss: 0.1284
Epoch 5/10, Batch 120/145, Loss: 0.2278
Epoch 5/10, Batch 130/145, Loss: 0.3304
Epoch 5/10, Batch 140/145, Loss: 0.2955
Epoch 5/10, Train Loss: 0.2376, Valid Loss: 0.2262
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1234
Epoch 6/10, Batch 20/145, Loss: 0.1619
Epoch 6/10, Batch 30/145, Loss: 0.2593
Epoch 6/10, Batch 40/145, Loss: 0.1401
Epoch 6/10, Batch 50/145, Loss: 0.2868
Epoch 6/10, Batch 60/145, Loss: 0.0903
Epoch 6/10, Batch 70/145, Loss: 0.3647
Epoch 6/10, Batch 80/145, Loss: 0.3315
Epoch 6/10, Batch 90/145, Loss: 0.2195
Epoch 6/10, Batch 100/145, Loss: 0.1269
Epoch 6/10, Batch 110/145, Loss: 0.3218
Epoch 6/10, Batch 120/145, Loss: 0.1944
Epoch 6/10, Batch 130/145, Loss: 0.1625
Epoch 6/10, Batch 140/145, Loss: 0.2204
Epoch 6/10, Train Loss: 0.2321, Valid Loss: 0.2290
Epoch 7/10, Batch 10/145, Loss: 0.3716
Epoch 7/10, Batch 20/145, Loss: 0.2190
Epoch 7/10, Batch 30/145, Loss: 0.2729
Epoch 7/10, Batch 40/145, Loss: 0.4842
Epoch 7/10, Batch 50/145, Loss: 0.1618
Epoch 7/10, Batch 60/145, Loss: 0.1617
Epoch 7/10, Batch 70/145, Loss: 0.2967
Epoch 7/10, Batch 80/145, Loss: 0.1639
Epoch 7/10, Batch 90/145, Loss: 0.3228
Epoch 7/10, Batch 100/145, Loss: 0.2510
Epoch 7/10, Batch 110/145, Loss: 0.1971
Epoch 7/10, Batch 120/145, Loss: 0.0932
Epoch 7/10, Batch 130/145, Loss: 0.2930
Epoch 7/10, Batch 140/145, Loss: 0.0930
Epoch 7/10, Train Loss: 0.2237, Valid Loss: 0.2222
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2341
Epoch 8/10, Batch 20/145, Loss: 0.1928
Epoch 8/10, Batch 30/145, Loss: 0.2621
Epoch 8/10, Batch 40/145, Loss: 0.3162
Epoch 8/10, Batch 50/145, Loss: 0.1123
Epoch 8/10, Batch 60/145, Loss: 0.2426
Epoch 8/10, Batch 70/145, Loss: 0.1256
Epoch 8/10, Batch 80/145, Loss: 0.1048
Epoch 8/10, Batch 90/145, Loss: 0.1756
Epoch 8/10, Batch 100/145, Loss: 0.1565
Epoch 8/10, Batch 110/145, Loss: 0.1737
Epoch 8/10, Batch 120/145, Loss: 0.0975
Epoch 8/10, Batch 130/145, Loss: 0.1973
Epoch 8/10, Batch 140/145, Loss: 0.2236
Epoch 8/10, Train Loss: 0.2067, Valid Loss: 0.2096
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3032
Epoch 9/10, Batch 20/145, Loss: 0.2042
Epoch 9/10, Batch 30/145, Loss: 0.0902
Epoch 9/10, Batch 40/145, Loss: 0.2789
Epoch 9/10, Batch 50/145, Loss: 0.2458
Epoch 9/10, Batch 60/145, Loss: 0.0984
Epoch 9/10, Batch 70/145, Loss: 0.2929
Epoch 9/10, Batch 80/145, Loss: 0.2595
Epoch 9/10, Batch 90/145, Loss: 0.0771
Epoch 9/10, Batch 100/145, Loss: 0.1420
Epoch 9/10, Batch 110/145, Loss: 0.1031
Epoch 9/10, Batch 120/145, Loss: 0.3109
Epoch 9/10, Batch 130/145, Loss: 0.1644
Epoch 9/10, Batch 140/145, Loss: 0.2652
Epoch 9/10, Train Loss: 0.2040, Valid Loss: 0.2040
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1151
Epoch 10/10, Batch 20/145, Loss: 0.1277
Epoch 10/10, Batch 30/145, Loss: 0.3501
Epoch 10/10, Batch 40/145, Loss: 0.1192
Epoch 10/10, Batch 50/145, Loss: 0.3971
Epoch 10/10, Batch 60/145, Loss: 0.1694
Epoch 10/10, Batch 70/145, Loss: 0.2184
Epoch 10/10, Batch 80/145, Loss: 0.3666
Epoch 10/10, Batch 90/145, Loss: 0.1404
Epoch 10/10, Batch 100/145, Loss: 0.1364
Epoch 10/10, Batch 110/145, Loss: 0.2135
Epoch 10/10, Batch 120/145, Loss: 0.2175
Epoch 10/10, Batch 130/145, Loss: 0.1567
Epoch 10/10, Batch 140/145, Loss: 0.1345
Epoch 10/10, Train Loss: 0.2015, Valid Loss: 0.2055
Accuracy: 0.9264
Precision: 0.9247
Recall: 0.9264
F1-score: 0.9252
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4499
Epoch 1/10, Batch 20/145, Loss: 0.9389
Epoch 1/10, Batch 30/145, Loss: 0.8660
Epoch 1/10, Batch 40/145, Loss: 0.9799
Epoch 1/10, Batch 50/145, Loss: 0.5333
Epoch 1/10, Batch 60/145, Loss: 0.5613
Epoch 1/10, Batch 70/145, Loss: 0.6216
Epoch 1/10, Batch 80/145, Loss: 0.6008
Epoch 1/10, Batch 90/145, Loss: 0.5175
Epoch 1/10, Batch 100/145, Loss: 0.7201
Epoch 1/10, Batch 110/145, Loss: 0.4034
Epoch 1/10, Batch 120/145, Loss: 0.6345
Epoch 1/10, Batch 130/145, Loss: 0.3276
Epoch 1/10, Batch 140/145, Loss: 0.4564
Epoch 1/10, Train Loss: 0.6915, Valid Loss: 0.3628
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2456
Epoch 2/10, Batch 20/145, Loss: 0.3993
Epoch 2/10, Batch 30/145, Loss: 0.2988
Epoch 2/10, Batch 40/145, Loss: 0.4353
Epoch 2/10, Batch 50/145, Loss: 0.4651
Epoch 2/10, Batch 60/145, Loss: 0.3115
Epoch 2/10, Batch 70/145, Loss: 0.4273
Epoch 2/10, Batch 80/145, Loss: 0.3037
Epoch 2/10, Batch 90/145, Loss: 0.2019
Epoch 2/10, Batch 100/145, Loss: 0.3786
Epoch 2/10, Batch 110/145, Loss: 0.3281
Epoch 2/10, Batch 120/145, Loss: 0.2487
Epoch 2/10, Batch 130/145, Loss: 0.3916
Epoch 2/10, Batch 140/145, Loss: 0.2504
Epoch 2/10, Train Loss: 0.3572, Valid Loss: 0.2737
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2158
Epoch 3/10, Batch 20/145, Loss: 0.2009
Epoch 3/10, Batch 30/145, Loss: 0.2373
Epoch 3/10, Batch 40/145, Loss: 0.2431
Epoch 3/10, Batch 50/145, Loss: 0.1258
Epoch 3/10, Batch 60/145, Loss: 0.2560
Epoch 3/10, Batch 70/145, Loss: 0.2112
Epoch 3/10, Batch 80/145, Loss: 0.1851
Epoch 3/10, Batch 90/145, Loss: 0.4337
Epoch 3/10, Batch 100/145, Loss: 0.2783
Epoch 3/10, Batch 110/145, Loss: 0.2096
Epoch 3/10, Batch 120/145, Loss: 0.3043
Epoch 3/10, Batch 130/145, Loss: 0.2074
Epoch 3/10, Batch 140/145, Loss: 0.3834
Epoch 3/10, Train Loss: 0.3009, Valid Loss: 0.2580
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2098
Epoch 4/10, Batch 20/145, Loss: 0.2205
Epoch 4/10, Batch 30/145, Loss: 0.2632
Epoch 4/10, Batch 40/145, Loss: 0.3081
Epoch 4/10, Batch 50/145, Loss: 0.3569
Epoch 4/10, Batch 60/145, Loss: 0.1217
Epoch 4/10, Batch 70/145, Loss: 0.1883
Epoch 4/10, Batch 80/145, Loss: 0.2845
Epoch 4/10, Batch 90/145, Loss: 0.3486
Epoch 4/10, Batch 100/145, Loss: 0.1278
Epoch 4/10, Batch 110/145, Loss: 0.2535
Epoch 4/10, Batch 120/145, Loss: 0.2967
Epoch 4/10, Batch 130/145, Loss: 0.1927
Epoch 4/10, Batch 140/145, Loss: 0.1752
Epoch 4/10, Train Loss: 0.2629, Valid Loss: 0.2415
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2413
Epoch 5/10, Batch 20/145, Loss: 0.2044
Epoch 5/10, Batch 30/145, Loss: 0.2236
Epoch 5/10, Batch 40/145, Loss: 0.1972
Epoch 5/10, Batch 50/145, Loss: 0.0684
Epoch 5/10, Batch 60/145, Loss: 0.4234
Epoch 5/10, Batch 70/145, Loss: 0.3446
Epoch 5/10, Batch 80/145, Loss: 0.3903
Epoch 5/10, Batch 90/145, Loss: 0.2313
Epoch 5/10, Batch 100/145, Loss: 0.1744
Epoch 5/10, Batch 110/145, Loss: 0.0654
Epoch 5/10, Batch 120/145, Loss: 0.3710
Epoch 5/10, Batch 130/145, Loss: 0.3036
Epoch 5/10, Batch 140/145, Loss: 0.2648
Epoch 5/10, Train Loss: 0.2411, Valid Loss: 0.2331
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2803
Epoch 6/10, Batch 20/145, Loss: 0.2250
Epoch 6/10, Batch 30/145, Loss: 0.4343
Epoch 6/10, Batch 40/145, Loss: 0.1645
Epoch 6/10, Batch 50/145, Loss: 0.3756
Epoch 6/10, Batch 60/145, Loss: 0.2244
Epoch 6/10, Batch 70/145, Loss: 0.3149
Epoch 6/10, Batch 80/145, Loss: 0.2199
Epoch 6/10, Batch 90/145, Loss: 0.3381
Epoch 6/10, Batch 100/145, Loss: 0.2677
Epoch 6/10, Batch 110/145, Loss: 0.2017
Epoch 6/10, Batch 120/145, Loss: 0.2894
Epoch 6/10, Batch 130/145, Loss: 0.1316
Epoch 6/10, Batch 140/145, Loss: 0.2230
Epoch 6/10, Train Loss: 0.2305, Valid Loss: 0.2267
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3534
Epoch 7/10, Batch 20/145, Loss: 0.3236
Epoch 7/10, Batch 30/145, Loss: 0.1060
Epoch 7/10, Batch 40/145, Loss: 0.4555
Epoch 7/10, Batch 50/145, Loss: 0.2280
Epoch 7/10, Batch 60/145, Loss: 0.1406
Epoch 7/10, Batch 70/145, Loss: 0.2894
Epoch 7/10, Batch 80/145, Loss: 0.1815
Epoch 7/10, Batch 90/145, Loss: 0.2173
Epoch 7/10, Batch 100/145, Loss: 0.2026
Epoch 7/10, Batch 110/145, Loss: 0.2202
Epoch 7/10, Batch 120/145, Loss: 0.0566
Epoch 7/10, Batch 130/145, Loss: 0.1553
Epoch 7/10, Batch 140/145, Loss: 0.1163
Epoch 7/10, Train Loss: 0.2132, Valid Loss: 0.2161
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2257
Epoch 8/10, Batch 20/145, Loss: 0.1900
Epoch 8/10, Batch 30/145, Loss: 0.1712
Epoch 8/10, Batch 40/145, Loss: 0.2226
Epoch 8/10, Batch 50/145, Loss: 0.1738
Epoch 8/10, Batch 60/145, Loss: 0.2454
Epoch 8/10, Batch 70/145, Loss: 0.1201
Epoch 8/10, Batch 80/145, Loss: 0.1660
Epoch 8/10, Batch 90/145, Loss: 0.0878
Epoch 8/10, Batch 100/145, Loss: 0.1563
Epoch 8/10, Batch 110/145, Loss: 0.2851
Epoch 8/10, Batch 120/145, Loss: 0.3115
Epoch 8/10, Batch 130/145, Loss: 0.1453
Epoch 8/10, Batch 140/145, Loss: 0.4174
Epoch 8/10, Train Loss: 0.2105, Valid Loss: 0.2146
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1952
Epoch 9/10, Batch 20/145, Loss: 0.0739
Epoch 9/10, Batch 30/145, Loss: 0.0736
Epoch 9/10, Batch 40/145, Loss: 0.1752
Epoch 9/10, Batch 50/145, Loss: 0.1579
Epoch 9/10, Batch 60/145, Loss: 0.1841
Epoch 9/10, Batch 70/145, Loss: 0.2109
Epoch 9/10, Batch 80/145, Loss: 0.2288
Epoch 9/10, Batch 90/145, Loss: 0.1874
Epoch 9/10, Batch 100/145, Loss: 0.1709
Epoch 9/10, Batch 110/145, Loss: 0.2548
Epoch 9/10, Batch 120/145, Loss: 0.1730
Epoch 9/10, Batch 130/145, Loss: 0.1597
Epoch 9/10, Batch 140/145, Loss: 0.1167
Epoch 9/10, Train Loss: 0.2010, Valid Loss: 0.2047
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0968
Epoch 10/10, Batch 20/145, Loss: 0.1059
Epoch 10/10, Batch 30/145, Loss: 0.1301
Epoch 10/10, Batch 40/145, Loss: 0.1618
Epoch 10/10, Batch 50/145, Loss: 0.3907
Epoch 10/10, Batch 60/145, Loss: 0.3335
Epoch 10/10, Batch 70/145, Loss: 0.2851
Epoch 10/10, Batch 80/145, Loss: 0.3753
Epoch 10/10, Batch 90/145, Loss: 0.0846
Epoch 10/10, Batch 100/145, Loss: 0.1719
Epoch 10/10, Batch 110/145, Loss: 0.1355
Epoch 10/10, Batch 120/145, Loss: 0.1515
Epoch 10/10, Batch 130/145, Loss: 0.0975
Epoch 10/10, Batch 140/145, Loss: 0.3172
Epoch 10/10, Train Loss: 0.1954, Valid Loss: 0.2099
Accuracy: 0.9147
Precision: 0.9139
Recall: 0.9147
F1-score: 0.9134
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5440
Epoch 1/10, Batch 20/145, Loss: 0.9498
Epoch 1/10, Batch 30/145, Loss: 0.8172
Epoch 1/10, Batch 40/145, Loss: 0.9362
Epoch 1/10, Batch 50/145, Loss: 0.5728
Epoch 1/10, Batch 60/145, Loss: 0.4983
Epoch 1/10, Batch 70/145, Loss: 0.6190
Epoch 1/10, Batch 80/145, Loss: 0.5134
Epoch 1/10, Batch 90/145, Loss: 0.8297
Epoch 1/10, Batch 100/145, Loss: 0.7510
Epoch 1/10, Batch 110/145, Loss: 0.4172
Epoch 1/10, Batch 120/145, Loss: 0.5902
Epoch 1/10, Batch 130/145, Loss: 0.4051
Epoch 1/10, Batch 140/145, Loss: 0.4807
Epoch 1/10, Train Loss: 0.6896, Valid Loss: 0.3684
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3003
Epoch 2/10, Batch 20/145, Loss: 0.5958
Epoch 2/10, Batch 30/145, Loss: 0.4456
Epoch 2/10, Batch 40/145, Loss: 0.4724
Epoch 2/10, Batch 50/145, Loss: 0.2277
Epoch 2/10, Batch 60/145, Loss: 0.4298
Epoch 2/10, Batch 70/145, Loss: 0.5451
Epoch 2/10, Batch 80/145, Loss: 0.3224
Epoch 2/10, Batch 90/145, Loss: 0.3972
Epoch 2/10, Batch 100/145, Loss: 0.2456
Epoch 2/10, Batch 110/145, Loss: 0.3286
Epoch 2/10, Batch 120/145, Loss: 0.3166
Epoch 2/10, Batch 130/145, Loss: 0.2656
Epoch 2/10, Batch 140/145, Loss: 0.3218
Epoch 2/10, Train Loss: 0.3652, Valid Loss: 0.2835
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3718
Epoch 3/10, Batch 20/145, Loss: 0.1695
Epoch 3/10, Batch 30/145, Loss: 0.2593
Epoch 3/10, Batch 40/145, Loss: 0.2722
Epoch 3/10, Batch 50/145, Loss: 0.2005
Epoch 3/10, Batch 60/145, Loss: 0.2494
Epoch 3/10, Batch 70/145, Loss: 0.1622
Epoch 3/10, Batch 80/145, Loss: 0.3164
Epoch 3/10, Batch 90/145, Loss: 0.5457
Epoch 3/10, Batch 100/145, Loss: 0.3562
Epoch 3/10, Batch 110/145, Loss: 0.2467
Epoch 3/10, Batch 120/145, Loss: 0.2069
Epoch 3/10, Batch 130/145, Loss: 0.1692
Epoch 3/10, Batch 140/145, Loss: 0.2339
Epoch 3/10, Train Loss: 0.3092, Valid Loss: 0.2522
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1531
Epoch 4/10, Batch 20/145, Loss: 0.3368
Epoch 4/10, Batch 30/145, Loss: 0.3311
Epoch 4/10, Batch 40/145, Loss: 0.2745
Epoch 4/10, Batch 50/145, Loss: 0.2193
Epoch 4/10, Batch 60/145, Loss: 0.1768
Epoch 4/10, Batch 70/145, Loss: 0.1554
Epoch 4/10, Batch 80/145, Loss: 0.1996
Epoch 4/10, Batch 90/145, Loss: 0.3913
Epoch 4/10, Batch 100/145, Loss: 0.2313
Epoch 4/10, Batch 110/145, Loss: 0.2730
Epoch 4/10, Batch 120/145, Loss: 0.2227
Epoch 4/10, Batch 130/145, Loss: 0.3398
Epoch 4/10, Batch 140/145, Loss: 0.2279
Epoch 4/10, Train Loss: 0.2681, Valid Loss: 0.2551
Epoch 5/10, Batch 10/145, Loss: 0.3541
Epoch 5/10, Batch 20/145, Loss: 0.3659
Epoch 5/10, Batch 30/145, Loss: 0.1935
Epoch 5/10, Batch 40/145, Loss: 0.2949
Epoch 5/10, Batch 50/145, Loss: 0.2146
Epoch 5/10, Batch 60/145, Loss: 0.2128
Epoch 5/10, Batch 70/145, Loss: 0.3106
Epoch 5/10, Batch 80/145, Loss: 0.2370
Epoch 5/10, Batch 90/145, Loss: 0.0836
Epoch 5/10, Batch 100/145, Loss: 0.1986
Epoch 5/10, Batch 110/145, Loss: 0.1132
Epoch 5/10, Batch 120/145, Loss: 0.1702
Epoch 5/10, Batch 130/145, Loss: 0.2814
Epoch 5/10, Batch 140/145, Loss: 0.3183
Epoch 5/10, Train Loss: 0.2439, Valid Loss: 0.2278
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2952
Epoch 6/10, Batch 20/145, Loss: 0.1556
Epoch 6/10, Batch 30/145, Loss: 0.1679
Epoch 6/10, Batch 40/145, Loss: 0.2321
Epoch 6/10, Batch 50/145, Loss: 0.3447
Epoch 6/10, Batch 60/145, Loss: 0.0944
Epoch 6/10, Batch 70/145, Loss: 0.2312
Epoch 6/10, Batch 80/145, Loss: 0.2665
Epoch 6/10, Batch 90/145, Loss: 0.2599
Epoch 6/10, Batch 100/145, Loss: 0.1370
Epoch 6/10, Batch 110/145, Loss: 0.1389
Epoch 6/10, Batch 120/145, Loss: 0.2550
Epoch 6/10, Batch 130/145, Loss: 0.1398
Epoch 6/10, Batch 140/145, Loss: 0.2163
Epoch 6/10, Train Loss: 0.2332, Valid Loss: 0.2292
Epoch 7/10, Batch 10/145, Loss: 0.2229
Epoch 7/10, Batch 20/145, Loss: 0.1855
Epoch 7/10, Batch 30/145, Loss: 0.3220
Epoch 7/10, Batch 40/145, Loss: 0.6406
Epoch 7/10, Batch 50/145, Loss: 0.2097
Epoch 7/10, Batch 60/145, Loss: 0.0853
Epoch 7/10, Batch 70/145, Loss: 0.2514
Epoch 7/10, Batch 80/145, Loss: 0.1577
Epoch 7/10, Batch 90/145, Loss: 0.2470
Epoch 7/10, Batch 100/145, Loss: 0.1009
Epoch 7/10, Batch 110/145, Loss: 0.2642
Epoch 7/10, Batch 120/145, Loss: 0.2044
Epoch 7/10, Batch 130/145, Loss: 0.2227
Epoch 7/10, Batch 140/145, Loss: 0.2157
Epoch 7/10, Train Loss: 0.2196, Valid Loss: 0.2125
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2429
Epoch 8/10, Batch 20/145, Loss: 0.2198
Epoch 8/10, Batch 30/145, Loss: 0.1966
Epoch 8/10, Batch 40/145, Loss: 0.1750
Epoch 8/10, Batch 50/145, Loss: 0.2893
Epoch 8/10, Batch 60/145, Loss: 0.3123
Epoch 8/10, Batch 70/145, Loss: 0.2976
Epoch 8/10, Batch 80/145, Loss: 0.0685
Epoch 8/10, Batch 90/145, Loss: 0.1406
Epoch 8/10, Batch 100/145, Loss: 0.1741
Epoch 8/10, Batch 110/145, Loss: 0.2862
Epoch 8/10, Batch 120/145, Loss: 0.1874
Epoch 8/10, Batch 130/145, Loss: 0.2031
Epoch 8/10, Batch 140/145, Loss: 0.2306
Epoch 8/10, Train Loss: 0.2101, Valid Loss: 0.2217
Epoch 9/10, Batch 10/145, Loss: 0.2545
Epoch 9/10, Batch 20/145, Loss: 0.1528
Epoch 9/10, Batch 30/145, Loss: 0.0663
Epoch 9/10, Batch 40/145, Loss: 0.2114
Epoch 9/10, Batch 50/145, Loss: 0.2566
Epoch 9/10, Batch 60/145, Loss: 0.1169
Epoch 9/10, Batch 70/145, Loss: 0.2303
Epoch 9/10, Batch 80/145, Loss: 0.1411
Epoch 9/10, Batch 90/145, Loss: 0.1082
Epoch 9/10, Batch 100/145, Loss: 0.3448
Epoch 9/10, Batch 110/145, Loss: 0.0980
Epoch 9/10, Batch 120/145, Loss: 0.1653
Epoch 9/10, Batch 130/145, Loss: 0.2370
Epoch 9/10, Batch 140/145, Loss: 0.1295
Epoch 9/10, Train Loss: 0.1997, Valid Loss: 0.2091
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1567
Epoch 10/10, Batch 20/145, Loss: 0.1023
Epoch 10/10, Batch 30/145, Loss: 0.0544
Epoch 10/10, Batch 40/145, Loss: 0.2383
Epoch 10/10, Batch 50/145, Loss: 0.5020
Epoch 10/10, Batch 60/145, Loss: 0.1305
Epoch 10/10, Batch 70/145, Loss: 0.0703
Epoch 10/10, Batch 80/145, Loss: 0.4171
Epoch 10/10, Batch 90/145, Loss: 0.2544
Epoch 10/10, Batch 100/145, Loss: 0.2731
Epoch 10/10, Batch 110/145, Loss: 0.2677
Epoch 10/10, Batch 120/145, Loss: 0.0865
Epoch 10/10, Batch 130/145, Loss: 0.2461
Epoch 10/10, Batch 140/145, Loss: 0.1165
Epoch 10/10, Train Loss: 0.1972, Valid Loss: 0.2009
Model saved!
Accuracy: 0.9206
Precision: 0.9191
Recall: 0.9206
F1-score: 0.9196
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4681
Epoch 1/10, Batch 20/145, Loss: 0.8706
Epoch 1/10, Batch 30/145, Loss: 0.9801
Epoch 1/10, Batch 40/145, Loss: 0.8777
Epoch 1/10, Batch 50/145, Loss: 0.6263
Epoch 1/10, Batch 60/145, Loss: 0.6123
Epoch 1/10, Batch 70/145, Loss: 0.5877
Epoch 1/10, Batch 80/145, Loss: 0.6014
Epoch 1/10, Batch 90/145, Loss: 0.5596
Epoch 1/10, Batch 100/145, Loss: 0.5221
Epoch 1/10, Batch 110/145, Loss: 0.4955
Epoch 1/10, Batch 120/145, Loss: 0.6135
Epoch 1/10, Batch 130/145, Loss: 0.3018
Epoch 1/10, Batch 140/145, Loss: 0.4325
Epoch 1/10, Train Loss: 0.6891, Valid Loss: 0.3786
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2523
Epoch 2/10, Batch 20/145, Loss: 0.6770
Epoch 2/10, Batch 30/145, Loss: 0.3036
Epoch 2/10, Batch 40/145, Loss: 0.4795
Epoch 2/10, Batch 50/145, Loss: 0.2880
Epoch 2/10, Batch 60/145, Loss: 0.4396
Epoch 2/10, Batch 70/145, Loss: 0.5248
Epoch 2/10, Batch 80/145, Loss: 0.3812
Epoch 2/10, Batch 90/145, Loss: 0.3533
Epoch 2/10, Batch 100/145, Loss: 0.2626
Epoch 2/10, Batch 110/145, Loss: 0.2679
Epoch 2/10, Batch 120/145, Loss: 0.4022
Epoch 2/10, Batch 130/145, Loss: 0.3438
Epoch 2/10, Batch 140/145, Loss: 0.3649
Epoch 2/10, Train Loss: 0.3660, Valid Loss: 0.3003
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2103
Epoch 3/10, Batch 20/145, Loss: 0.3491
Epoch 3/10, Batch 30/145, Loss: 0.2638
Epoch 3/10, Batch 40/145, Loss: 0.2866
Epoch 3/10, Batch 50/145, Loss: 0.2532
Epoch 3/10, Batch 60/145, Loss: 0.3270
Epoch 3/10, Batch 70/145, Loss: 0.2187
Epoch 3/10, Batch 80/145, Loss: 0.1838
Epoch 3/10, Batch 90/145, Loss: 0.3546
Epoch 3/10, Batch 100/145, Loss: 0.2532
Epoch 3/10, Batch 110/145, Loss: 0.3091
Epoch 3/10, Batch 120/145, Loss: 0.1793
Epoch 3/10, Batch 130/145, Loss: 0.2911
Epoch 3/10, Batch 140/145, Loss: 0.2534
Epoch 3/10, Train Loss: 0.3057, Valid Loss: 0.2748
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2417
Epoch 4/10, Batch 20/145, Loss: 0.2550
Epoch 4/10, Batch 30/145, Loss: 0.4159
Epoch 4/10, Batch 40/145, Loss: 0.3667
Epoch 4/10, Batch 50/145, Loss: 0.3310
Epoch 4/10, Batch 60/145, Loss: 0.1864
Epoch 4/10, Batch 70/145, Loss: 0.3451
Epoch 4/10, Batch 80/145, Loss: 0.3349
Epoch 4/10, Batch 90/145, Loss: 0.3214
Epoch 4/10, Batch 100/145, Loss: 0.2283
Epoch 4/10, Batch 110/145, Loss: 0.2888
Epoch 4/10, Batch 120/145, Loss: 0.1064
Epoch 4/10, Batch 130/145, Loss: 0.1707
Epoch 4/10, Batch 140/145, Loss: 0.3400
Epoch 4/10, Train Loss: 0.2689, Valid Loss: 0.2570
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2075
Epoch 5/10, Batch 20/145, Loss: 0.3360
Epoch 5/10, Batch 30/145, Loss: 0.1474
Epoch 5/10, Batch 40/145, Loss: 0.2655
Epoch 5/10, Batch 50/145, Loss: 0.2261
Epoch 5/10, Batch 60/145, Loss: 0.3144
Epoch 5/10, Batch 70/145, Loss: 0.3343
Epoch 5/10, Batch 80/145, Loss: 0.4899
Epoch 5/10, Batch 90/145, Loss: 0.1711
Epoch 5/10, Batch 100/145, Loss: 0.2203
Epoch 5/10, Batch 110/145, Loss: 0.1893
Epoch 5/10, Batch 120/145, Loss: 0.1931
Epoch 5/10, Batch 130/145, Loss: 0.1795
Epoch 5/10, Batch 140/145, Loss: 0.1239
Epoch 5/10, Train Loss: 0.2401, Valid Loss: 0.2407
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1872
Epoch 6/10, Batch 20/145, Loss: 0.2608
Epoch 6/10, Batch 30/145, Loss: 0.1448
Epoch 6/10, Batch 40/145, Loss: 0.2726
Epoch 6/10, Batch 50/145, Loss: 0.2468
Epoch 6/10, Batch 60/145, Loss: 0.1542
Epoch 6/10, Batch 70/145, Loss: 0.2809
Epoch 6/10, Batch 80/145, Loss: 0.2368
Epoch 6/10, Batch 90/145, Loss: 0.2976
Epoch 6/10, Batch 100/145, Loss: 0.1944
Epoch 6/10, Batch 110/145, Loss: 0.1557
Epoch 6/10, Batch 120/145, Loss: 0.3516
Epoch 6/10, Batch 130/145, Loss: 0.0674
Epoch 6/10, Batch 140/145, Loss: 0.2813
Epoch 6/10, Train Loss: 0.2295, Valid Loss: 0.2383
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1860
Epoch 7/10, Batch 20/145, Loss: 0.4059
Epoch 7/10, Batch 30/145, Loss: 0.1601
Epoch 7/10, Batch 40/145, Loss: 0.4133
Epoch 7/10, Batch 50/145, Loss: 0.2706
Epoch 7/10, Batch 60/145, Loss: 0.2370
Epoch 7/10, Batch 70/145, Loss: 0.2162
Epoch 7/10, Batch 80/145, Loss: 0.0956
Epoch 7/10, Batch 90/145, Loss: 0.5822
Epoch 7/10, Batch 100/145, Loss: 0.2738
Epoch 7/10, Batch 110/145, Loss: 0.2920
Epoch 7/10, Batch 120/145, Loss: 0.1658
Epoch 7/10, Batch 130/145, Loss: 0.2553
Epoch 7/10, Batch 140/145, Loss: 0.1495
Epoch 7/10, Train Loss: 0.2222, Valid Loss: 0.2401
Epoch 8/10, Batch 10/145, Loss: 0.1973
Epoch 8/10, Batch 20/145, Loss: 0.1816
Epoch 8/10, Batch 30/145, Loss: 0.1827
Epoch 8/10, Batch 40/145, Loss: 0.2017
Epoch 8/10, Batch 50/145, Loss: 0.3453
Epoch 8/10, Batch 60/145, Loss: 0.2158
Epoch 8/10, Batch 70/145, Loss: 0.1793
Epoch 8/10, Batch 80/145, Loss: 0.2686
Epoch 8/10, Batch 90/145, Loss: 0.1336
Epoch 8/10, Batch 100/145, Loss: 0.1376
Epoch 8/10, Batch 110/145, Loss: 0.2236
Epoch 8/10, Batch 120/145, Loss: 0.3041
Epoch 8/10, Batch 130/145, Loss: 0.1101
Epoch 8/10, Batch 140/145, Loss: 0.2197
Epoch 8/10, Train Loss: 0.2073, Valid Loss: 0.2231
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2525
Epoch 9/10, Batch 20/145, Loss: 0.0872
Epoch 9/10, Batch 30/145, Loss: 0.1463
Epoch 9/10, Batch 40/145, Loss: 0.1807
Epoch 9/10, Batch 50/145, Loss: 0.2700
Epoch 9/10, Batch 60/145, Loss: 0.2498
Epoch 9/10, Batch 70/145, Loss: 0.1401
Epoch 9/10, Batch 80/145, Loss: 0.2946
Epoch 9/10, Batch 90/145, Loss: 0.1027
Epoch 9/10, Batch 100/145, Loss: 0.4147
Epoch 9/10, Batch 110/145, Loss: 0.0952
Epoch 9/10, Batch 120/145, Loss: 0.1271
Epoch 9/10, Batch 130/145, Loss: 0.2990
Epoch 9/10, Batch 140/145, Loss: 0.2347
Epoch 9/10, Train Loss: 0.2087, Valid Loss: 0.2127
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0947
Epoch 10/10, Batch 20/145, Loss: 0.1385
Epoch 10/10, Batch 30/145, Loss: 0.1533
Epoch 10/10, Batch 40/145, Loss: 0.1796
Epoch 10/10, Batch 50/145, Loss: 0.2195
Epoch 10/10, Batch 60/145, Loss: 0.1984
Epoch 10/10, Batch 70/145, Loss: 0.1435
Epoch 10/10, Batch 80/145, Loss: 0.4758
Epoch 10/10, Batch 90/145, Loss: 0.1376
Epoch 10/10, Batch 100/145, Loss: 0.0954
Epoch 10/10, Batch 110/145, Loss: 0.1680
Epoch 10/10, Batch 120/145, Loss: 0.2201
Epoch 10/10, Batch 130/145, Loss: 0.2129
Epoch 10/10, Batch 140/145, Loss: 0.1684
Epoch 10/10, Train Loss: 0.1932, Valid Loss: 0.2205
Accuracy: 0.9159
Precision: 0.9148
Recall: 0.9159
F1-score: 0.9149
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4820
Epoch 1/10, Batch 20/145, Loss: 0.9192
Epoch 1/10, Batch 30/145, Loss: 0.9544
Epoch 1/10, Batch 40/145, Loss: 0.8356
Epoch 1/10, Batch 50/145, Loss: 0.5813
Epoch 1/10, Batch 60/145, Loss: 0.6060
Epoch 1/10, Batch 70/145, Loss: 0.6322
Epoch 1/10, Batch 80/145, Loss: 0.4585
Epoch 1/10, Batch 90/145, Loss: 0.6966
Epoch 1/10, Batch 100/145, Loss: 0.5635
Epoch 1/10, Batch 110/145, Loss: 0.3793
Epoch 1/10, Batch 120/145, Loss: 0.5887
Epoch 1/10, Batch 130/145, Loss: 0.4915
Epoch 1/10, Batch 140/145, Loss: 0.3551
Epoch 1/10, Train Loss: 0.6872, Valid Loss: 0.3771
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3312
Epoch 2/10, Batch 20/145, Loss: 0.6002
Epoch 2/10, Batch 30/145, Loss: 0.4230
Epoch 2/10, Batch 40/145, Loss: 0.4718
Epoch 2/10, Batch 50/145, Loss: 0.2725
Epoch 2/10, Batch 60/145, Loss: 0.4688
Epoch 2/10, Batch 70/145, Loss: 0.5341
Epoch 2/10, Batch 80/145, Loss: 0.3462
Epoch 2/10, Batch 90/145, Loss: 0.3610
Epoch 2/10, Batch 100/145, Loss: 0.2517
Epoch 2/10, Batch 110/145, Loss: 0.3675
Epoch 2/10, Batch 120/145, Loss: 0.6046
Epoch 2/10, Batch 130/145, Loss: 0.4016
Epoch 2/10, Batch 140/145, Loss: 0.2597
Epoch 2/10, Train Loss: 0.3615, Valid Loss: 0.2851
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2449
Epoch 3/10, Batch 20/145, Loss: 0.2557
Epoch 3/10, Batch 30/145, Loss: 0.4398
Epoch 3/10, Batch 40/145, Loss: 0.2104
Epoch 3/10, Batch 50/145, Loss: 0.1533
Epoch 3/10, Batch 60/145, Loss: 0.2997
Epoch 3/10, Batch 70/145, Loss: 0.2162
Epoch 3/10, Batch 80/145, Loss: 0.3929
Epoch 3/10, Batch 90/145, Loss: 0.4977
Epoch 3/10, Batch 100/145, Loss: 0.1718
Epoch 3/10, Batch 110/145, Loss: 0.2588
Epoch 3/10, Batch 120/145, Loss: 0.1930
Epoch 3/10, Batch 130/145, Loss: 0.1520
Epoch 3/10, Batch 140/145, Loss: 0.1570
Epoch 3/10, Train Loss: 0.3101, Valid Loss: 0.2505
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2934
Epoch 4/10, Batch 20/145, Loss: 0.3731
Epoch 4/10, Batch 30/145, Loss: 0.1717
Epoch 4/10, Batch 40/145, Loss: 0.3002
Epoch 4/10, Batch 50/145, Loss: 0.2860
Epoch 4/10, Batch 60/145, Loss: 0.1809
Epoch 4/10, Batch 70/145, Loss: 0.1802
Epoch 4/10, Batch 80/145, Loss: 0.3609
Epoch 4/10, Batch 90/145, Loss: 0.3621
Epoch 4/10, Batch 100/145, Loss: 0.2367
Epoch 4/10, Batch 110/145, Loss: 0.2572
Epoch 4/10, Batch 120/145, Loss: 0.1720
Epoch 4/10, Batch 130/145, Loss: 0.2086
Epoch 4/10, Batch 140/145, Loss: 0.1934
Epoch 4/10, Train Loss: 0.2675, Valid Loss: 0.2361
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1962
Epoch 5/10, Batch 20/145, Loss: 0.1627
Epoch 5/10, Batch 30/145, Loss: 0.2037
Epoch 5/10, Batch 40/145, Loss: 0.2341
Epoch 5/10, Batch 50/145, Loss: 0.1505
Epoch 5/10, Batch 60/145, Loss: 0.2841
Epoch 5/10, Batch 70/145, Loss: 0.1690
Epoch 5/10, Batch 80/145, Loss: 0.1856
Epoch 5/10, Batch 90/145, Loss: 0.1308
Epoch 5/10, Batch 100/145, Loss: 0.3168
Epoch 5/10, Batch 110/145, Loss: 0.1762
Epoch 5/10, Batch 120/145, Loss: 0.1747
Epoch 5/10, Batch 130/145, Loss: 0.1398
Epoch 5/10, Batch 140/145, Loss: 0.2512
Epoch 5/10, Train Loss: 0.2381, Valid Loss: 0.2355
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3687
Epoch 6/10, Batch 20/145, Loss: 0.3317
Epoch 6/10, Batch 30/145, Loss: 0.3041
Epoch 6/10, Batch 40/145, Loss: 0.1448
Epoch 6/10, Batch 50/145, Loss: 0.2448
Epoch 6/10, Batch 60/145, Loss: 0.2404
Epoch 6/10, Batch 70/145, Loss: 0.3862
Epoch 6/10, Batch 80/145, Loss: 0.3732
Epoch 6/10, Batch 90/145, Loss: 0.2454
Epoch 6/10, Batch 100/145, Loss: 0.1447
Epoch 6/10, Batch 110/145, Loss: 0.1262
Epoch 6/10, Batch 120/145, Loss: 0.3113
Epoch 6/10, Batch 130/145, Loss: 0.2291
Epoch 6/10, Batch 140/145, Loss: 0.1294
Epoch 6/10, Train Loss: 0.2281, Valid Loss: 0.2295
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2197
Epoch 7/10, Batch 20/145, Loss: 0.1426
Epoch 7/10, Batch 30/145, Loss: 0.1293
Epoch 7/10, Batch 40/145, Loss: 0.5664
Epoch 7/10, Batch 50/145, Loss: 0.1827
Epoch 7/10, Batch 60/145, Loss: 0.2173
Epoch 7/10, Batch 70/145, Loss: 0.3309
Epoch 7/10, Batch 80/145, Loss: 0.2279
Epoch 7/10, Batch 90/145, Loss: 0.2123
Epoch 7/10, Batch 100/145, Loss: 0.1614
Epoch 7/10, Batch 110/145, Loss: 0.2083
Epoch 7/10, Batch 120/145, Loss: 0.1909
Epoch 7/10, Batch 130/145, Loss: 0.4424
Epoch 7/10, Batch 140/145, Loss: 0.2366
Epoch 7/10, Train Loss: 0.2202, Valid Loss: 0.2177
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2235
Epoch 8/10, Batch 20/145, Loss: 0.2002
Epoch 8/10, Batch 30/145, Loss: 0.1143
Epoch 8/10, Batch 40/145, Loss: 0.2224
Epoch 8/10, Batch 50/145, Loss: 0.2108
Epoch 8/10, Batch 60/145, Loss: 0.0718
Epoch 8/10, Batch 70/145, Loss: 0.1137
Epoch 8/10, Batch 80/145, Loss: 0.2762
Epoch 8/10, Batch 90/145, Loss: 0.1532
Epoch 8/10, Batch 100/145, Loss: 0.3134
Epoch 8/10, Batch 110/145, Loss: 0.2897
Epoch 8/10, Batch 120/145, Loss: 0.1344
Epoch 8/10, Batch 130/145, Loss: 0.1549
Epoch 8/10, Batch 140/145, Loss: 0.3158
Epoch 8/10, Train Loss: 0.2085, Valid Loss: 0.2088
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1662
Epoch 9/10, Batch 20/145, Loss: 0.2667
Epoch 9/10, Batch 30/145, Loss: 0.0542
Epoch 9/10, Batch 40/145, Loss: 0.1473
Epoch 9/10, Batch 50/145, Loss: 0.0955
Epoch 9/10, Batch 60/145, Loss: 0.1217
Epoch 9/10, Batch 70/145, Loss: 0.1385
Epoch 9/10, Batch 80/145, Loss: 0.2754
Epoch 9/10, Batch 90/145, Loss: 0.2241
Epoch 9/10, Batch 100/145, Loss: 0.1710
Epoch 9/10, Batch 110/145, Loss: 0.1378
Epoch 9/10, Batch 120/145, Loss: 0.3709
Epoch 9/10, Batch 130/145, Loss: 0.1891
Epoch 9/10, Batch 140/145, Loss: 0.1277
Epoch 9/10, Train Loss: 0.2016, Valid Loss: 0.2007
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2723
Epoch 10/10, Batch 20/145, Loss: 0.1273
Epoch 10/10, Batch 30/145, Loss: 0.1436
Epoch 10/10, Batch 40/145, Loss: 0.3007
Epoch 10/10, Batch 50/145, Loss: 0.1862
Epoch 10/10, Batch 60/145, Loss: 0.2726
Epoch 10/10, Batch 70/145, Loss: 0.1645
Epoch 10/10, Batch 80/145, Loss: 0.5794
Epoch 10/10, Batch 90/145, Loss: 0.2280
Epoch 10/10, Batch 100/145, Loss: 0.1131
Epoch 10/10, Batch 110/145, Loss: 0.2221
Epoch 10/10, Batch 120/145, Loss: 0.1861
Epoch 10/10, Batch 130/145, Loss: 0.2074
Epoch 10/10, Batch 140/145, Loss: 0.2295
Epoch 10/10, Train Loss: 0.1895, Valid Loss: 0.1990
Model saved!
Accuracy: 0.9252
Precision: 0.9241
Recall: 0.9252
F1-score: 0.9246
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4940
Epoch 1/10, Batch 20/145, Loss: 0.8629
Epoch 1/10, Batch 30/145, Loss: 0.9643
Epoch 1/10, Batch 40/145, Loss: 0.7468
Epoch 1/10, Batch 50/145, Loss: 0.6145
Epoch 1/10, Batch 60/145, Loss: 0.6101
Epoch 1/10, Batch 70/145, Loss: 0.6571
Epoch 1/10, Batch 80/145, Loss: 0.5601
Epoch 1/10, Batch 90/145, Loss: 0.4983
Epoch 1/10, Batch 100/145, Loss: 0.5862
Epoch 1/10, Batch 110/145, Loss: 0.3662
Epoch 1/10, Batch 120/145, Loss: 0.5509
Epoch 1/10, Batch 130/145, Loss: 0.4703
Epoch 1/10, Batch 140/145, Loss: 0.4545
Epoch 1/10, Train Loss: 0.6916, Valid Loss: 0.3692
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3417
Epoch 2/10, Batch 20/145, Loss: 0.5839
Epoch 2/10, Batch 30/145, Loss: 0.2626
Epoch 2/10, Batch 40/145, Loss: 0.3665
Epoch 2/10, Batch 50/145, Loss: 0.3446
Epoch 2/10, Batch 60/145, Loss: 0.4706
Epoch 2/10, Batch 70/145, Loss: 0.3536
Epoch 2/10, Batch 80/145, Loss: 0.2583
Epoch 2/10, Batch 90/145, Loss: 0.2892
Epoch 2/10, Batch 100/145, Loss: 0.2836
Epoch 2/10, Batch 110/145, Loss: 0.2316
Epoch 2/10, Batch 120/145, Loss: 0.3671
Epoch 2/10, Batch 130/145, Loss: 0.3204
Epoch 2/10, Batch 140/145, Loss: 0.3222
Epoch 2/10, Train Loss: 0.3655, Valid Loss: 0.2809
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3353
Epoch 3/10, Batch 20/145, Loss: 0.2491
Epoch 3/10, Batch 30/145, Loss: 0.2905
Epoch 3/10, Batch 40/145, Loss: 0.3885
Epoch 3/10, Batch 50/145, Loss: 0.1770
Epoch 3/10, Batch 60/145, Loss: 0.3573
Epoch 3/10, Batch 70/145, Loss: 0.2902
Epoch 3/10, Batch 80/145, Loss: 0.2404
Epoch 3/10, Batch 90/145, Loss: 0.5039
Epoch 3/10, Batch 100/145, Loss: 0.2321
Epoch 3/10, Batch 110/145, Loss: 0.2377
Epoch 3/10, Batch 120/145, Loss: 0.1884
Epoch 3/10, Batch 130/145, Loss: 0.2601
Epoch 3/10, Batch 140/145, Loss: 0.2102
Epoch 3/10, Train Loss: 0.3083, Valid Loss: 0.2468
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2257
Epoch 4/10, Batch 20/145, Loss: 0.2660
Epoch 4/10, Batch 30/145, Loss: 0.2015
Epoch 4/10, Batch 40/145, Loss: 0.2937
Epoch 4/10, Batch 50/145, Loss: 0.1687
Epoch 4/10, Batch 60/145, Loss: 0.2542
Epoch 4/10, Batch 70/145, Loss: 0.1999
Epoch 4/10, Batch 80/145, Loss: 0.2623
Epoch 4/10, Batch 90/145, Loss: 0.2457
Epoch 4/10, Batch 100/145, Loss: 0.2487
Epoch 4/10, Batch 110/145, Loss: 0.3818
Epoch 4/10, Batch 120/145, Loss: 0.2703
Epoch 4/10, Batch 130/145, Loss: 0.2278
Epoch 4/10, Batch 140/145, Loss: 0.1722
Epoch 4/10, Train Loss: 0.2679, Valid Loss: 0.2362
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2080
Epoch 5/10, Batch 20/145, Loss: 0.1545
Epoch 5/10, Batch 30/145, Loss: 0.1210
Epoch 5/10, Batch 40/145, Loss: 0.1765
Epoch 5/10, Batch 50/145, Loss: 0.1558
Epoch 5/10, Batch 60/145, Loss: 0.2802
Epoch 5/10, Batch 70/145, Loss: 0.2388
Epoch 5/10, Batch 80/145, Loss: 0.3956
Epoch 5/10, Batch 90/145, Loss: 0.3860
Epoch 5/10, Batch 100/145, Loss: 0.2329
Epoch 5/10, Batch 110/145, Loss: 0.1200
Epoch 5/10, Batch 120/145, Loss: 0.1647
Epoch 5/10, Batch 130/145, Loss: 0.2742
Epoch 5/10, Batch 140/145, Loss: 0.3665
Epoch 5/10, Train Loss: 0.2444, Valid Loss: 0.2337
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2971
Epoch 6/10, Batch 20/145, Loss: 0.2853
Epoch 6/10, Batch 30/145, Loss: 0.2504
Epoch 6/10, Batch 40/145, Loss: 0.1758
Epoch 6/10, Batch 50/145, Loss: 0.3672
Epoch 6/10, Batch 60/145, Loss: 0.0711
Epoch 6/10, Batch 70/145, Loss: 0.3331
Epoch 6/10, Batch 80/145, Loss: 0.3940
Epoch 6/10, Batch 90/145, Loss: 0.2102
Epoch 6/10, Batch 100/145, Loss: 0.1404
Epoch 6/10, Batch 110/145, Loss: 0.2243
Epoch 6/10, Batch 120/145, Loss: 0.1713
Epoch 6/10, Batch 130/145, Loss: 0.2124
Epoch 6/10, Batch 140/145, Loss: 0.1446
Epoch 6/10, Train Loss: 0.2327, Valid Loss: 0.2280
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1924
Epoch 7/10, Batch 20/145, Loss: 0.3233
Epoch 7/10, Batch 30/145, Loss: 0.2748
Epoch 7/10, Batch 40/145, Loss: 0.2965
Epoch 7/10, Batch 50/145, Loss: 0.2692
Epoch 7/10, Batch 60/145, Loss: 0.2384
Epoch 7/10, Batch 70/145, Loss: 0.3163
Epoch 7/10, Batch 80/145, Loss: 0.1388
Epoch 7/10, Batch 90/145, Loss: 0.1118
Epoch 7/10, Batch 100/145, Loss: 0.1157
Epoch 7/10, Batch 110/145, Loss: 0.3483
Epoch 7/10, Batch 120/145, Loss: 0.1682
Epoch 7/10, Batch 130/145, Loss: 0.1780
Epoch 7/10, Batch 140/145, Loss: 0.1073
Epoch 7/10, Train Loss: 0.2224, Valid Loss: 0.2227
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2083
Epoch 8/10, Batch 20/145, Loss: 0.1892
Epoch 8/10, Batch 30/145, Loss: 0.2279
Epoch 8/10, Batch 40/145, Loss: 0.2104
Epoch 8/10, Batch 50/145, Loss: 0.1994
Epoch 8/10, Batch 60/145, Loss: 0.1911
Epoch 8/10, Batch 70/145, Loss: 0.1118
Epoch 8/10, Batch 80/145, Loss: 0.1579
Epoch 8/10, Batch 90/145, Loss: 0.1783
Epoch 8/10, Batch 100/145, Loss: 0.3063
Epoch 8/10, Batch 110/145, Loss: 0.2088
Epoch 8/10, Batch 120/145, Loss: 0.2319
Epoch 8/10, Batch 130/145, Loss: 0.1962
Epoch 8/10, Batch 140/145, Loss: 0.2752
Epoch 8/10, Train Loss: 0.2125, Valid Loss: 0.2117
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1895
Epoch 9/10, Batch 20/145, Loss: 0.1195
Epoch 9/10, Batch 30/145, Loss: 0.2533
Epoch 9/10, Batch 40/145, Loss: 0.1959
Epoch 9/10, Batch 50/145, Loss: 0.1042
Epoch 9/10, Batch 60/145, Loss: 0.1337
Epoch 9/10, Batch 70/145, Loss: 0.1709
Epoch 9/10, Batch 80/145, Loss: 0.1422
Epoch 9/10, Batch 90/145, Loss: 0.0949
Epoch 9/10, Batch 100/145, Loss: 0.1995
Epoch 9/10, Batch 110/145, Loss: 0.1763
Epoch 9/10, Batch 120/145, Loss: 0.1227
Epoch 9/10, Batch 130/145, Loss: 0.3050
Epoch 9/10, Batch 140/145, Loss: 0.1188
Epoch 9/10, Train Loss: 0.2038, Valid Loss: 0.2111
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1367
Epoch 10/10, Batch 20/145, Loss: 0.1083
Epoch 10/10, Batch 30/145, Loss: 0.2492
Epoch 10/10, Batch 40/145, Loss: 0.1627
Epoch 10/10, Batch 50/145, Loss: 0.3564
Epoch 10/10, Batch 60/145, Loss: 0.1956
Epoch 10/10, Batch 70/145, Loss: 0.1976
Epoch 10/10, Batch 80/145, Loss: 0.4461
Epoch 10/10, Batch 90/145, Loss: 0.1086
Epoch 10/10, Batch 100/145, Loss: 0.1333
Epoch 10/10, Batch 110/145, Loss: 0.1792
Epoch 10/10, Batch 120/145, Loss: 0.1978
Epoch 10/10, Batch 130/145, Loss: 0.3143
Epoch 10/10, Batch 140/145, Loss: 0.3025
Epoch 10/10, Train Loss: 0.2014, Valid Loss: 0.2077
Model saved!
Accuracy: 0.9229
Precision: 0.9213
Recall: 0.9229
F1-score: 0.9220
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4926
Epoch 1/10, Batch 20/145, Loss: 0.8356
Epoch 1/10, Batch 30/145, Loss: 0.8501
Epoch 1/10, Batch 40/145, Loss: 0.7724
Epoch 1/10, Batch 50/145, Loss: 0.7020
Epoch 1/10, Batch 60/145, Loss: 0.5998
Epoch 1/10, Batch 70/145, Loss: 0.6720
Epoch 1/10, Batch 80/145, Loss: 0.5269
Epoch 1/10, Batch 90/145, Loss: 0.4741
Epoch 1/10, Batch 100/145, Loss: 0.6472
Epoch 1/10, Batch 110/145, Loss: 0.4428
Epoch 1/10, Batch 120/145, Loss: 0.6435
Epoch 1/10, Batch 130/145, Loss: 0.4124
Epoch 1/10, Batch 140/145, Loss: 0.4100
Epoch 1/10, Train Loss: 0.6914, Valid Loss: 0.3518
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4182
Epoch 2/10, Batch 20/145, Loss: 0.4064
Epoch 2/10, Batch 30/145, Loss: 0.2909
Epoch 2/10, Batch 40/145, Loss: 0.3974
Epoch 2/10, Batch 50/145, Loss: 0.2522
Epoch 2/10, Batch 60/145, Loss: 0.5173
Epoch 2/10, Batch 70/145, Loss: 0.2975
Epoch 2/10, Batch 80/145, Loss: 0.3793
Epoch 2/10, Batch 90/145, Loss: 0.5165
Epoch 2/10, Batch 100/145, Loss: 0.3134
Epoch 2/10, Batch 110/145, Loss: 0.2291
Epoch 2/10, Batch 120/145, Loss: 0.2735
Epoch 2/10, Batch 130/145, Loss: 0.2832
Epoch 2/10, Batch 140/145, Loss: 0.2637
Epoch 2/10, Train Loss: 0.3638, Valid Loss: 0.2672
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2694
Epoch 3/10, Batch 20/145, Loss: 0.2209
Epoch 3/10, Batch 30/145, Loss: 0.2471
Epoch 3/10, Batch 40/145, Loss: 0.2191
Epoch 3/10, Batch 50/145, Loss: 0.1771
Epoch 3/10, Batch 60/145, Loss: 0.2782
Epoch 3/10, Batch 70/145, Loss: 0.2588
Epoch 3/10, Batch 80/145, Loss: 0.2548
Epoch 3/10, Batch 90/145, Loss: 0.5061
Epoch 3/10, Batch 100/145, Loss: 0.2656
Epoch 3/10, Batch 110/145, Loss: 0.3411
Epoch 3/10, Batch 120/145, Loss: 0.1584
Epoch 3/10, Batch 130/145, Loss: 0.3959
Epoch 3/10, Batch 140/145, Loss: 0.1214
Epoch 3/10, Train Loss: 0.3120, Valid Loss: 0.2388
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2262
Epoch 4/10, Batch 20/145, Loss: 0.1882
Epoch 4/10, Batch 30/145, Loss: 0.1779
Epoch 4/10, Batch 40/145, Loss: 0.4360
Epoch 4/10, Batch 50/145, Loss: 0.2199
Epoch 4/10, Batch 60/145, Loss: 0.2439
Epoch 4/10, Batch 70/145, Loss: 0.2608
Epoch 4/10, Batch 80/145, Loss: 0.3842
Epoch 4/10, Batch 90/145, Loss: 0.2151
Epoch 4/10, Batch 100/145, Loss: 0.2796
Epoch 4/10, Batch 110/145, Loss: 0.2191
Epoch 4/10, Batch 120/145, Loss: 0.1495
Epoch 4/10, Batch 130/145, Loss: 0.2881
Epoch 4/10, Batch 140/145, Loss: 0.2621
Epoch 4/10, Train Loss: 0.2668, Valid Loss: 0.2299
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1813
Epoch 5/10, Batch 20/145, Loss: 0.2975
Epoch 5/10, Batch 30/145, Loss: 0.2682
Epoch 5/10, Batch 40/145, Loss: 0.1987
Epoch 5/10, Batch 50/145, Loss: 0.1151
Epoch 5/10, Batch 60/145, Loss: 0.3248
Epoch 5/10, Batch 70/145, Loss: 0.3518
Epoch 5/10, Batch 80/145, Loss: 0.3104
Epoch 5/10, Batch 90/145, Loss: 0.2584
Epoch 5/10, Batch 100/145, Loss: 0.3003
Epoch 5/10, Batch 110/145, Loss: 0.1113
Epoch 5/10, Batch 120/145, Loss: 0.2430
Epoch 5/10, Batch 130/145, Loss: 0.3132
Epoch 5/10, Batch 140/145, Loss: 0.1878
Epoch 5/10, Train Loss: 0.2458, Valid Loss: 0.2127
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1975
Epoch 6/10, Batch 20/145, Loss: 0.3216
Epoch 6/10, Batch 30/145, Loss: 0.1847
Epoch 6/10, Batch 40/145, Loss: 0.1215
Epoch 6/10, Batch 50/145, Loss: 0.3565
Epoch 6/10, Batch 60/145, Loss: 0.2117
Epoch 6/10, Batch 70/145, Loss: 0.3230
Epoch 6/10, Batch 80/145, Loss: 0.3440
Epoch 6/10, Batch 90/145, Loss: 0.2948
Epoch 6/10, Batch 100/145, Loss: 0.2006
Epoch 6/10, Batch 110/145, Loss: 0.1039
Epoch 6/10, Batch 120/145, Loss: 0.1974
Epoch 6/10, Batch 130/145, Loss: 0.2094
Epoch 6/10, Batch 140/145, Loss: 0.2001
Epoch 6/10, Train Loss: 0.2330, Valid Loss: 0.2061
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2826
Epoch 7/10, Batch 20/145, Loss: 0.3183
Epoch 7/10, Batch 30/145, Loss: 0.2930
Epoch 7/10, Batch 40/145, Loss: 0.4229
Epoch 7/10, Batch 50/145, Loss: 0.2980
Epoch 7/10, Batch 60/145, Loss: 0.1017
Epoch 7/10, Batch 70/145, Loss: 0.2489
Epoch 7/10, Batch 80/145, Loss: 0.0872
Epoch 7/10, Batch 90/145, Loss: 0.2804
Epoch 7/10, Batch 100/145, Loss: 0.3679
Epoch 7/10, Batch 110/145, Loss: 0.2472
Epoch 7/10, Batch 120/145, Loss: 0.2824
Epoch 7/10, Batch 130/145, Loss: 0.2384
Epoch 7/10, Batch 140/145, Loss: 0.1405
Epoch 7/10, Train Loss: 0.2285, Valid Loss: 0.2020
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2741
Epoch 8/10, Batch 20/145, Loss: 0.1576
Epoch 8/10, Batch 30/145, Loss: 0.1764
Epoch 8/10, Batch 40/145, Loss: 0.2642
Epoch 8/10, Batch 50/145, Loss: 0.2327
Epoch 8/10, Batch 60/145, Loss: 0.0895
Epoch 8/10, Batch 70/145, Loss: 0.0831
Epoch 8/10, Batch 80/145, Loss: 0.1380
Epoch 8/10, Batch 90/145, Loss: 0.1260
Epoch 8/10, Batch 100/145, Loss: 0.2005
Epoch 8/10, Batch 110/145, Loss: 0.2330
Epoch 8/10, Batch 120/145, Loss: 0.1493
Epoch 8/10, Batch 130/145, Loss: 0.1232
Epoch 8/10, Batch 140/145, Loss: 0.3226
Epoch 8/10, Train Loss: 0.2173, Valid Loss: 0.1928
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3518
Epoch 9/10, Batch 20/145, Loss: 0.0926
Epoch 9/10, Batch 30/145, Loss: 0.1636
Epoch 9/10, Batch 40/145, Loss: 0.1398
Epoch 9/10, Batch 50/145, Loss: 0.1820
Epoch 9/10, Batch 60/145, Loss: 0.3389
Epoch 9/10, Batch 70/145, Loss: 0.1835
Epoch 9/10, Batch 80/145, Loss: 0.2140
Epoch 9/10, Batch 90/145, Loss: 0.1444
Epoch 9/10, Batch 100/145, Loss: 0.1779
Epoch 9/10, Batch 110/145, Loss: 0.1869
Epoch 9/10, Batch 120/145, Loss: 0.2585
Epoch 9/10, Batch 130/145, Loss: 0.2083
Epoch 9/10, Batch 140/145, Loss: 0.1243
Epoch 9/10, Train Loss: 0.2046, Valid Loss: 0.1913
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1486
Epoch 10/10, Batch 20/145, Loss: 0.2000
Epoch 10/10, Batch 30/145, Loss: 0.0814
Epoch 10/10, Batch 40/145, Loss: 0.2072
Epoch 10/10, Batch 50/145, Loss: 0.2403
Epoch 10/10, Batch 60/145, Loss: 0.1894
Epoch 10/10, Batch 70/145, Loss: 0.1776
Epoch 10/10, Batch 80/145, Loss: 0.5225
Epoch 10/10, Batch 90/145, Loss: 0.2429
Epoch 10/10, Batch 100/145, Loss: 0.1583
Epoch 10/10, Batch 110/145, Loss: 0.1574
Epoch 10/10, Batch 120/145, Loss: 0.2348
Epoch 10/10, Batch 130/145, Loss: 0.4508
Epoch 10/10, Batch 140/145, Loss: 0.3302
Epoch 10/10, Train Loss: 0.2047, Valid Loss: 0.1844
Model saved!
Accuracy: 0.9311
Precision: 0.9297
Recall: 0.9311
F1-score: 0.9302
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4772
Epoch 1/10, Batch 20/145, Loss: 0.9352
Epoch 1/10, Batch 30/145, Loss: 0.9240
Epoch 1/10, Batch 40/145, Loss: 0.8204
Epoch 1/10, Batch 50/145, Loss: 0.6149
Epoch 1/10, Batch 60/145, Loss: 0.5571
Epoch 1/10, Batch 70/145, Loss: 0.5834
Epoch 1/10, Batch 80/145, Loss: 0.5347
Epoch 1/10, Batch 90/145, Loss: 0.5226
Epoch 1/10, Batch 100/145, Loss: 0.6072
Epoch 1/10, Batch 110/145, Loss: 0.4706
Epoch 1/10, Batch 120/145, Loss: 0.4856
Epoch 1/10, Batch 130/145, Loss: 0.4226
Epoch 1/10, Batch 140/145, Loss: 0.4588
Epoch 1/10, Train Loss: 0.6921, Valid Loss: 0.3592
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4266
Epoch 2/10, Batch 20/145, Loss: 0.4398
Epoch 2/10, Batch 30/145, Loss: 0.3728
Epoch 2/10, Batch 40/145, Loss: 0.4296
Epoch 2/10, Batch 50/145, Loss: 0.5488
Epoch 2/10, Batch 60/145, Loss: 0.3335
Epoch 2/10, Batch 70/145, Loss: 0.2950
Epoch 2/10, Batch 80/145, Loss: 0.3640
Epoch 2/10, Batch 90/145, Loss: 0.2494
Epoch 2/10, Batch 100/145, Loss: 0.1636
Epoch 2/10, Batch 110/145, Loss: 0.4265
Epoch 2/10, Batch 120/145, Loss: 0.3991
Epoch 2/10, Batch 130/145, Loss: 0.3526
Epoch 2/10, Batch 140/145, Loss: 0.3833
Epoch 2/10, Train Loss: 0.3677, Valid Loss: 0.2819
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2968
Epoch 3/10, Batch 20/145, Loss: 0.2717
Epoch 3/10, Batch 30/145, Loss: 0.1879
Epoch 3/10, Batch 40/145, Loss: 0.3036
Epoch 3/10, Batch 50/145, Loss: 0.2626
Epoch 3/10, Batch 60/145, Loss: 0.4010
Epoch 3/10, Batch 70/145, Loss: 0.3052
Epoch 3/10, Batch 80/145, Loss: 0.3825
Epoch 3/10, Batch 90/145, Loss: 0.3909
Epoch 3/10, Batch 100/145, Loss: 0.2259
Epoch 3/10, Batch 110/145, Loss: 0.2043
Epoch 3/10, Batch 120/145, Loss: 0.1520
Epoch 3/10, Batch 130/145, Loss: 0.1963
Epoch 3/10, Batch 140/145, Loss: 0.2474
Epoch 3/10, Train Loss: 0.3065, Valid Loss: 0.2573
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1396
Epoch 4/10, Batch 20/145, Loss: 0.2975
Epoch 4/10, Batch 30/145, Loss: 0.2602
Epoch 4/10, Batch 40/145, Loss: 0.5788
Epoch 4/10, Batch 50/145, Loss: 0.2378
Epoch 4/10, Batch 60/145, Loss: 0.2491
Epoch 4/10, Batch 70/145, Loss: 0.3049
Epoch 4/10, Batch 80/145, Loss: 0.3177
Epoch 4/10, Batch 90/145, Loss: 0.2782
Epoch 4/10, Batch 100/145, Loss: 0.3772
Epoch 4/10, Batch 110/145, Loss: 0.3166
Epoch 4/10, Batch 120/145, Loss: 0.1678
Epoch 4/10, Batch 130/145, Loss: 0.2509
Epoch 4/10, Batch 140/145, Loss: 0.2181
Epoch 4/10, Train Loss: 0.2700, Valid Loss: 0.2440
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1672
Epoch 5/10, Batch 20/145, Loss: 0.3671
Epoch 5/10, Batch 30/145, Loss: 0.1424
Epoch 5/10, Batch 40/145, Loss: 0.1153
Epoch 5/10, Batch 50/145, Loss: 0.2290
Epoch 5/10, Batch 60/145, Loss: 0.3192
Epoch 5/10, Batch 70/145, Loss: 0.2824
Epoch 5/10, Batch 80/145, Loss: 0.2266
Epoch 5/10, Batch 90/145, Loss: 0.2311
Epoch 5/10, Batch 100/145, Loss: 0.2551
Epoch 5/10, Batch 110/145, Loss: 0.1016
Epoch 5/10, Batch 120/145, Loss: 0.2298
Epoch 5/10, Batch 130/145, Loss: 0.1598
Epoch 5/10, Batch 140/145, Loss: 0.2811
Epoch 5/10, Train Loss: 0.2441, Valid Loss: 0.2208
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1207
Epoch 6/10, Batch 20/145, Loss: 0.2100
Epoch 6/10, Batch 30/145, Loss: 0.3312
Epoch 6/10, Batch 40/145, Loss: 0.1660
Epoch 6/10, Batch 50/145, Loss: 0.4636
Epoch 6/10, Batch 60/145, Loss: 0.2638
Epoch 6/10, Batch 70/145, Loss: 0.2737
Epoch 6/10, Batch 80/145, Loss: 0.2574
Epoch 6/10, Batch 90/145, Loss: 0.2323
Epoch 6/10, Batch 100/145, Loss: 0.1549
Epoch 6/10, Batch 110/145, Loss: 0.1188
Epoch 6/10, Batch 120/145, Loss: 0.2886
Epoch 6/10, Batch 130/145, Loss: 0.2158
Epoch 6/10, Batch 140/145, Loss: 0.1621
Epoch 6/10, Train Loss: 0.2288, Valid Loss: 0.2233
Epoch 7/10, Batch 10/145, Loss: 0.2988
Epoch 7/10, Batch 20/145, Loss: 0.1730
Epoch 7/10, Batch 30/145, Loss: 0.2332
Epoch 7/10, Batch 40/145, Loss: 0.3006
Epoch 7/10, Batch 50/145, Loss: 0.2536
Epoch 7/10, Batch 60/145, Loss: 0.1272
Epoch 7/10, Batch 70/145, Loss: 0.1518
Epoch 7/10, Batch 80/145, Loss: 0.1522
Epoch 7/10, Batch 90/145, Loss: 0.3243
Epoch 7/10, Batch 100/145, Loss: 0.3695
Epoch 7/10, Batch 110/145, Loss: 0.2358
Epoch 7/10, Batch 120/145, Loss: 0.1750
Epoch 7/10, Batch 130/145, Loss: 0.2258
Epoch 7/10, Batch 140/145, Loss: 0.1789
Epoch 7/10, Train Loss: 0.2232, Valid Loss: 0.2174
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1856
Epoch 8/10, Batch 20/145, Loss: 0.1309
Epoch 8/10, Batch 30/145, Loss: 0.1749
Epoch 8/10, Batch 40/145, Loss: 0.3491
Epoch 8/10, Batch 50/145, Loss: 0.3286
Epoch 8/10, Batch 60/145, Loss: 0.2531
Epoch 8/10, Batch 70/145, Loss: 0.1008
Epoch 8/10, Batch 80/145, Loss: 0.1830
Epoch 8/10, Batch 90/145, Loss: 0.0927
Epoch 8/10, Batch 100/145, Loss: 0.2381
Epoch 8/10, Batch 110/145, Loss: 0.2811
Epoch 8/10, Batch 120/145, Loss: 0.2622
Epoch 8/10, Batch 130/145, Loss: 0.2064
Epoch 8/10, Batch 140/145, Loss: 0.4073
Epoch 8/10, Train Loss: 0.2179, Valid Loss: 0.2110
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1105
Epoch 9/10, Batch 20/145, Loss: 0.0713
Epoch 9/10, Batch 30/145, Loss: 0.1608
Epoch 9/10, Batch 40/145, Loss: 0.1557
Epoch 9/10, Batch 50/145, Loss: 0.1883
Epoch 9/10, Batch 60/145, Loss: 0.2298
Epoch 9/10, Batch 70/145, Loss: 0.2011
Epoch 9/10, Batch 80/145, Loss: 0.3326
Epoch 9/10, Batch 90/145, Loss: 0.1978
Epoch 9/10, Batch 100/145, Loss: 0.2496
Epoch 9/10, Batch 110/145, Loss: 0.1308
Epoch 9/10, Batch 120/145, Loss: 0.2921
Epoch 9/10, Batch 130/145, Loss: 0.2353
Epoch 9/10, Batch 140/145, Loss: 0.2382
Epoch 9/10, Train Loss: 0.2045, Valid Loss: 0.2041
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2638
Epoch 10/10, Batch 20/145, Loss: 0.0981
Epoch 10/10, Batch 30/145, Loss: 0.0823
Epoch 10/10, Batch 40/145, Loss: 0.0913
Epoch 10/10, Batch 50/145, Loss: 0.1833
Epoch 10/10, Batch 60/145, Loss: 0.3687
Epoch 10/10, Batch 70/145, Loss: 0.2235
Epoch 10/10, Batch 80/145, Loss: 0.3277
Epoch 10/10, Batch 90/145, Loss: 0.1789
Epoch 10/10, Batch 100/145, Loss: 0.1613
Epoch 10/10, Batch 110/145, Loss: 0.3080
Epoch 10/10, Batch 120/145, Loss: 0.1557
Epoch 10/10, Batch 130/145, Loss: 0.1602
Epoch 10/10, Batch 140/145, Loss: 0.1931
Epoch 10/10, Train Loss: 0.1934, Valid Loss: 0.1998
Model saved!
Accuracy: 0.9276
Precision: 0.9266
Recall: 0.9276
F1-score: 0.9270
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5205
Epoch 1/10, Batch 20/145, Loss: 0.7965
Epoch 1/10, Batch 30/145, Loss: 0.8572
Epoch 1/10, Batch 40/145, Loss: 0.9085
Epoch 1/10, Batch 50/145, Loss: 0.5347
Epoch 1/10, Batch 60/145, Loss: 0.5795
Epoch 1/10, Batch 70/145, Loss: 0.5778
Epoch 1/10, Batch 80/145, Loss: 0.5055
Epoch 1/10, Batch 90/145, Loss: 0.6587
Epoch 1/10, Batch 100/145, Loss: 0.5457
Epoch 1/10, Batch 110/145, Loss: 0.3251
Epoch 1/10, Batch 120/145, Loss: 0.4624
Epoch 1/10, Batch 130/145, Loss: 0.4145
Epoch 1/10, Batch 140/145, Loss: 0.4652
Epoch 1/10, Train Loss: 0.6893, Valid Loss: 0.3920
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3122
Epoch 2/10, Batch 20/145, Loss: 0.4903
Epoch 2/10, Batch 30/145, Loss: 0.3210
Epoch 2/10, Batch 40/145, Loss: 0.5191
Epoch 2/10, Batch 50/145, Loss: 0.2881
Epoch 2/10, Batch 60/145, Loss: 0.2696
Epoch 2/10, Batch 70/145, Loss: 0.4131
Epoch 2/10, Batch 80/145, Loss: 0.2198
Epoch 2/10, Batch 90/145, Loss: 0.3317
Epoch 2/10, Batch 100/145, Loss: 0.2967
Epoch 2/10, Batch 110/145, Loss: 0.2514
Epoch 2/10, Batch 120/145, Loss: 0.3838
Epoch 2/10, Batch 130/145, Loss: 0.2906
Epoch 2/10, Batch 140/145, Loss: 0.3571
Epoch 2/10, Train Loss: 0.3618, Valid Loss: 0.3028
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2666
Epoch 3/10, Batch 20/145, Loss: 0.1812
Epoch 3/10, Batch 30/145, Loss: 0.3235
Epoch 3/10, Batch 40/145, Loss: 0.2761
Epoch 3/10, Batch 50/145, Loss: 0.2467
Epoch 3/10, Batch 60/145, Loss: 0.3578
Epoch 3/10, Batch 70/145, Loss: 0.2124
Epoch 3/10, Batch 80/145, Loss: 0.2973
Epoch 3/10, Batch 90/145, Loss: 0.3654
Epoch 3/10, Batch 100/145, Loss: 0.2343
Epoch 3/10, Batch 110/145, Loss: 0.1941
Epoch 3/10, Batch 120/145, Loss: 0.1587
Epoch 3/10, Batch 130/145, Loss: 0.1965
Epoch 3/10, Batch 140/145, Loss: 0.1800
Epoch 3/10, Train Loss: 0.3057, Valid Loss: 0.2725
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2085
Epoch 4/10, Batch 20/145, Loss: 0.3834
Epoch 4/10, Batch 30/145, Loss: 0.3286
Epoch 4/10, Batch 40/145, Loss: 0.2884
Epoch 4/10, Batch 50/145, Loss: 0.1432
Epoch 4/10, Batch 60/145, Loss: 0.2048
Epoch 4/10, Batch 70/145, Loss: 0.1900
Epoch 4/10, Batch 80/145, Loss: 0.2573
Epoch 4/10, Batch 90/145, Loss: 0.2679
Epoch 4/10, Batch 100/145, Loss: 0.1407
Epoch 4/10, Batch 110/145, Loss: 0.2451
Epoch 4/10, Batch 120/145, Loss: 0.1894
Epoch 4/10, Batch 130/145, Loss: 0.1791
Epoch 4/10, Batch 140/145, Loss: 0.1549
Epoch 4/10, Train Loss: 0.2659, Valid Loss: 0.2646
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1564
Epoch 5/10, Batch 20/145, Loss: 0.1676
Epoch 5/10, Batch 30/145, Loss: 0.2631
Epoch 5/10, Batch 40/145, Loss: 0.1519
Epoch 5/10, Batch 50/145, Loss: 0.1674
Epoch 5/10, Batch 60/145, Loss: 0.2228
Epoch 5/10, Batch 70/145, Loss: 0.1367
Epoch 5/10, Batch 80/145, Loss: 0.2694
Epoch 5/10, Batch 90/145, Loss: 0.2229
Epoch 5/10, Batch 100/145, Loss: 0.2954
Epoch 5/10, Batch 110/145, Loss: 0.2253
Epoch 5/10, Batch 120/145, Loss: 0.2074
Epoch 5/10, Batch 130/145, Loss: 0.1198
Epoch 5/10, Batch 140/145, Loss: 0.2876
Epoch 5/10, Train Loss: 0.2354, Valid Loss: 0.2492
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1940
Epoch 6/10, Batch 20/145, Loss: 0.2164
Epoch 6/10, Batch 30/145, Loss: 0.1497
Epoch 6/10, Batch 40/145, Loss: 0.2127
Epoch 6/10, Batch 50/145, Loss: 0.3792
Epoch 6/10, Batch 60/145, Loss: 0.1456
Epoch 6/10, Batch 70/145, Loss: 0.2035
Epoch 6/10, Batch 80/145, Loss: 0.2936
Epoch 6/10, Batch 90/145, Loss: 0.1998
Epoch 6/10, Batch 100/145, Loss: 0.1809
Epoch 6/10, Batch 110/145, Loss: 0.1476
Epoch 6/10, Batch 120/145, Loss: 0.1971
Epoch 6/10, Batch 130/145, Loss: 0.1074
Epoch 6/10, Batch 140/145, Loss: 0.2173
Epoch 6/10, Train Loss: 0.2240, Valid Loss: 0.2415
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1506
Epoch 7/10, Batch 20/145, Loss: 0.1772
Epoch 7/10, Batch 30/145, Loss: 0.1684
Epoch 7/10, Batch 40/145, Loss: 0.3292
Epoch 7/10, Batch 50/145, Loss: 0.2274
Epoch 7/10, Batch 60/145, Loss: 0.1980
Epoch 7/10, Batch 70/145, Loss: 0.3635
Epoch 7/10, Batch 80/145, Loss: 0.1167
Epoch 7/10, Batch 90/145, Loss: 0.2260
Epoch 7/10, Batch 100/145, Loss: 0.1772
Epoch 7/10, Batch 110/145, Loss: 0.1753
Epoch 7/10, Batch 120/145, Loss: 0.0505
Epoch 7/10, Batch 130/145, Loss: 0.1237
Epoch 7/10, Batch 140/145, Loss: 0.1370
Epoch 7/10, Train Loss: 0.2171, Valid Loss: 0.2450
Epoch 8/10, Batch 10/145, Loss: 0.0762
Epoch 8/10, Batch 20/145, Loss: 0.1225
Epoch 8/10, Batch 30/145, Loss: 0.1923
Epoch 8/10, Batch 40/145, Loss: 0.1738
Epoch 8/10, Batch 50/145, Loss: 0.2142
Epoch 8/10, Batch 60/145, Loss: 0.2906
Epoch 8/10, Batch 70/145, Loss: 0.1425
Epoch 8/10, Batch 80/145, Loss: 0.2351
Epoch 8/10, Batch 90/145, Loss: 0.1771
Epoch 8/10, Batch 100/145, Loss: 0.3533
Epoch 8/10, Batch 110/145, Loss: 0.2886
Epoch 8/10, Batch 120/145, Loss: 0.0529
Epoch 8/10, Batch 130/145, Loss: 0.1412
Epoch 8/10, Batch 140/145, Loss: 0.1932
Epoch 8/10, Train Loss: 0.2127, Valid Loss: 0.2381
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1153
Epoch 9/10, Batch 20/145, Loss: 0.1370
Epoch 9/10, Batch 30/145, Loss: 0.1324
Epoch 9/10, Batch 40/145, Loss: 0.1721
Epoch 9/10, Batch 50/145, Loss: 0.3104
Epoch 9/10, Batch 60/145, Loss: 0.1676
Epoch 9/10, Batch 70/145, Loss: 0.2308
Epoch 9/10, Batch 80/145, Loss: 0.2565
Epoch 9/10, Batch 90/145, Loss: 0.1122
Epoch 9/10, Batch 100/145, Loss: 0.1195
Epoch 9/10, Batch 110/145, Loss: 0.0539
Epoch 9/10, Batch 120/145, Loss: 0.2173
Epoch 9/10, Batch 130/145, Loss: 0.2709
Epoch 9/10, Batch 140/145, Loss: 0.2157
Epoch 9/10, Train Loss: 0.1953, Valid Loss: 0.2365
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1518
Epoch 10/10, Batch 20/145, Loss: 0.1786
Epoch 10/10, Batch 30/145, Loss: 0.0413
Epoch 10/10, Batch 40/145, Loss: 0.1587
Epoch 10/10, Batch 50/145, Loss: 0.2546
Epoch 10/10, Batch 60/145, Loss: 0.3476
Epoch 10/10, Batch 70/145, Loss: 0.2111
Epoch 10/10, Batch 80/145, Loss: 0.2779
Epoch 10/10, Batch 90/145, Loss: 0.2214
Epoch 10/10, Batch 100/145, Loss: 0.1615
Epoch 10/10, Batch 110/145, Loss: 0.2876
Epoch 10/10, Batch 120/145, Loss: 0.1678
Epoch 10/10, Batch 130/145, Loss: 0.2194
Epoch 10/10, Batch 140/145, Loss: 0.1561
Epoch 10/10, Train Loss: 0.1925, Valid Loss: 0.2348
Model saved!
Accuracy: 0.9299
Precision: 0.9285
Recall: 0.9299
F1-score: 0.9289
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5372
Epoch 1/10, Batch 20/145, Loss: 0.9073
Epoch 1/10, Batch 30/145, Loss: 0.8372
Epoch 1/10, Batch 40/145, Loss: 0.8302
Epoch 1/10, Batch 50/145, Loss: 0.6279
Epoch 1/10, Batch 60/145, Loss: 0.5820
Epoch 1/10, Batch 70/145, Loss: 0.7318
Epoch 1/10, Batch 80/145, Loss: 0.5142
Epoch 1/10, Batch 90/145, Loss: 0.6000
Epoch 1/10, Batch 100/145, Loss: 0.7095
Epoch 1/10, Batch 110/145, Loss: 0.3823
Epoch 1/10, Batch 120/145, Loss: 0.4914
Epoch 1/10, Batch 130/145, Loss: 0.4288
Epoch 1/10, Batch 140/145, Loss: 0.4624
Epoch 1/10, Train Loss: 0.6955, Valid Loss: 0.3766
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4092
Epoch 2/10, Batch 20/145, Loss: 0.5571
Epoch 2/10, Batch 30/145, Loss: 0.2480
Epoch 2/10, Batch 40/145, Loss: 0.3921
Epoch 2/10, Batch 50/145, Loss: 0.3434
Epoch 2/10, Batch 60/145, Loss: 0.4245
Epoch 2/10, Batch 70/145, Loss: 0.4432
Epoch 2/10, Batch 80/145, Loss: 0.2730
Epoch 2/10, Batch 90/145, Loss: 0.3499
Epoch 2/10, Batch 100/145, Loss: 0.3853
Epoch 2/10, Batch 110/145, Loss: 0.3511
Epoch 2/10, Batch 120/145, Loss: 0.4066
Epoch 2/10, Batch 130/145, Loss: 0.3920
Epoch 2/10, Batch 140/145, Loss: 0.5470
Epoch 2/10, Train Loss: 0.3607, Valid Loss: 0.2899
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2287
Epoch 3/10, Batch 20/145, Loss: 0.2412
Epoch 3/10, Batch 30/145, Loss: 0.2185
Epoch 3/10, Batch 40/145, Loss: 0.1979
Epoch 3/10, Batch 50/145, Loss: 0.2378
Epoch 3/10, Batch 60/145, Loss: 0.2295
Epoch 3/10, Batch 70/145, Loss: 0.2203
Epoch 3/10, Batch 80/145, Loss: 0.3321
Epoch 3/10, Batch 90/145, Loss: 0.4505
Epoch 3/10, Batch 100/145, Loss: 0.1712
Epoch 3/10, Batch 110/145, Loss: 0.2495
Epoch 3/10, Batch 120/145, Loss: 0.3265
Epoch 3/10, Batch 130/145, Loss: 0.3095
Epoch 3/10, Batch 140/145, Loss: 0.3076
Epoch 3/10, Train Loss: 0.3102, Valid Loss: 0.2577
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1790
Epoch 4/10, Batch 20/145, Loss: 0.2698
Epoch 4/10, Batch 30/145, Loss: 0.3138
Epoch 4/10, Batch 40/145, Loss: 0.3365
Epoch 4/10, Batch 50/145, Loss: 0.2315
Epoch 4/10, Batch 60/145, Loss: 0.3272
Epoch 4/10, Batch 70/145, Loss: 0.2774
Epoch 4/10, Batch 80/145, Loss: 0.4933
Epoch 4/10, Batch 90/145, Loss: 0.2828
Epoch 4/10, Batch 100/145, Loss: 0.1238
Epoch 4/10, Batch 110/145, Loss: 0.1955
Epoch 4/10, Batch 120/145, Loss: 0.1527
Epoch 4/10, Batch 130/145, Loss: 0.2147
Epoch 4/10, Batch 140/145, Loss: 0.3052
Epoch 4/10, Train Loss: 0.2703, Valid Loss: 0.2555
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2730
Epoch 5/10, Batch 20/145, Loss: 0.2039
Epoch 5/10, Batch 30/145, Loss: 0.1775
Epoch 5/10, Batch 40/145, Loss: 0.1168
Epoch 5/10, Batch 50/145, Loss: 0.1436
Epoch 5/10, Batch 60/145, Loss: 0.3227
Epoch 5/10, Batch 70/145, Loss: 0.2603
Epoch 5/10, Batch 80/145, Loss: 0.3114
Epoch 5/10, Batch 90/145, Loss: 0.1605
Epoch 5/10, Batch 100/145, Loss: 0.1571
Epoch 5/10, Batch 110/145, Loss: 0.2657
Epoch 5/10, Batch 120/145, Loss: 0.1802
Epoch 5/10, Batch 130/145, Loss: 0.2488
Epoch 5/10, Batch 140/145, Loss: 0.4906
Epoch 5/10, Train Loss: 0.2436, Valid Loss: 0.2421
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1893
Epoch 6/10, Batch 20/145, Loss: 0.3957
Epoch 6/10, Batch 30/145, Loss: 0.2787
Epoch 6/10, Batch 40/145, Loss: 0.1893
Epoch 6/10, Batch 50/145, Loss: 0.3165
Epoch 6/10, Batch 60/145, Loss: 0.0650
Epoch 6/10, Batch 70/145, Loss: 0.5355
Epoch 6/10, Batch 80/145, Loss: 0.2351
Epoch 6/10, Batch 90/145, Loss: 0.2034
Epoch 6/10, Batch 100/145, Loss: 0.1493
Epoch 6/10, Batch 110/145, Loss: 0.1791
Epoch 6/10, Batch 120/145, Loss: 0.1638
Epoch 6/10, Batch 130/145, Loss: 0.1481
Epoch 6/10, Batch 140/145, Loss: 0.1827
Epoch 6/10, Train Loss: 0.2374, Valid Loss: 0.2314
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2004
Epoch 7/10, Batch 20/145, Loss: 0.1298
Epoch 7/10, Batch 30/145, Loss: 0.0958
Epoch 7/10, Batch 40/145, Loss: 0.3181
Epoch 7/10, Batch 50/145, Loss: 0.1851
Epoch 7/10, Batch 60/145, Loss: 0.1200
Epoch 7/10, Batch 70/145, Loss: 0.1352
Epoch 7/10, Batch 80/145, Loss: 0.1942
Epoch 7/10, Batch 90/145, Loss: 0.3125
Epoch 7/10, Batch 100/145, Loss: 0.2103
Epoch 7/10, Batch 110/145, Loss: 0.2581
Epoch 7/10, Batch 120/145, Loss: 0.2077
Epoch 7/10, Batch 130/145, Loss: 0.2464
Epoch 7/10, Batch 140/145, Loss: 0.2255
Epoch 7/10, Train Loss: 0.2161, Valid Loss: 0.2217
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1510
Epoch 8/10, Batch 20/145, Loss: 0.1173
Epoch 8/10, Batch 30/145, Loss: 0.4129
Epoch 8/10, Batch 40/145, Loss: 0.4391
Epoch 8/10, Batch 50/145, Loss: 0.2115
Epoch 8/10, Batch 60/145, Loss: 0.1281
Epoch 8/10, Batch 70/145, Loss: 0.1235
Epoch 8/10, Batch 80/145, Loss: 0.1958
Epoch 8/10, Batch 90/145, Loss: 0.1976
Epoch 8/10, Batch 100/145, Loss: 0.1633
Epoch 8/10, Batch 110/145, Loss: 0.1152
Epoch 8/10, Batch 120/145, Loss: 0.2597
Epoch 8/10, Batch 130/145, Loss: 0.2214
Epoch 8/10, Batch 140/145, Loss: 0.1159
Epoch 8/10, Train Loss: 0.2203, Valid Loss: 0.2300
Epoch 9/10, Batch 10/145, Loss: 0.1778
Epoch 9/10, Batch 20/145, Loss: 0.2155
Epoch 9/10, Batch 30/145, Loss: 0.0826
Epoch 9/10, Batch 40/145, Loss: 0.2550
Epoch 9/10, Batch 50/145, Loss: 0.0869
Epoch 9/10, Batch 60/145, Loss: 0.1790
Epoch 9/10, Batch 70/145, Loss: 0.0710
Epoch 9/10, Batch 80/145, Loss: 0.1805
Epoch 9/10, Batch 90/145, Loss: 0.1171
Epoch 9/10, Batch 100/145, Loss: 0.1912
Epoch 9/10, Batch 110/145, Loss: 0.1169
Epoch 9/10, Batch 120/145, Loss: 0.2738
Epoch 9/10, Batch 130/145, Loss: 0.3682
Epoch 9/10, Batch 140/145, Loss: 0.1791
Epoch 9/10, Train Loss: 0.2083, Valid Loss: 0.2089
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0914
Epoch 10/10, Batch 20/145, Loss: 0.1119
Epoch 10/10, Batch 30/145, Loss: 0.0952
Epoch 10/10, Batch 40/145, Loss: 0.1414
Epoch 10/10, Batch 50/145, Loss: 0.2624
Epoch 10/10, Batch 60/145, Loss: 0.0734
Epoch 10/10, Batch 70/145, Loss: 0.1598
Epoch 10/10, Batch 80/145, Loss: 0.2984
Epoch 10/10, Batch 90/145, Loss: 0.0784
Epoch 10/10, Batch 100/145, Loss: 0.2801
Epoch 10/10, Batch 110/145, Loss: 0.4076
Epoch 10/10, Batch 120/145, Loss: 0.2866
Epoch 10/10, Batch 130/145, Loss: 0.3382
Epoch 10/10, Batch 140/145, Loss: 0.3793
Epoch 10/10, Train Loss: 0.2001, Valid Loss: 0.2155
Accuracy: 0.9264
Precision: 0.9246
Recall: 0.9264
F1-score: 0.9250
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4470
Epoch 1/10, Batch 20/145, Loss: 0.8404
Epoch 1/10, Batch 30/145, Loss: 0.8145
Epoch 1/10, Batch 40/145, Loss: 0.8635
Epoch 1/10, Batch 50/145, Loss: 0.5881
Epoch 1/10, Batch 60/145, Loss: 0.5719
Epoch 1/10, Batch 70/145, Loss: 0.5573
Epoch 1/10, Batch 80/145, Loss: 0.5371
Epoch 1/10, Batch 90/145, Loss: 0.5046
Epoch 1/10, Batch 100/145, Loss: 0.6931
Epoch 1/10, Batch 110/145, Loss: 0.4326
Epoch 1/10, Batch 120/145, Loss: 0.5539
Epoch 1/10, Batch 130/145, Loss: 0.3351
Epoch 1/10, Batch 140/145, Loss: 0.2497
Epoch 1/10, Train Loss: 0.6881, Valid Loss: 0.3734
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3388
Epoch 2/10, Batch 20/145, Loss: 0.5293
Epoch 2/10, Batch 30/145, Loss: 0.3753
Epoch 2/10, Batch 40/145, Loss: 0.4837
Epoch 2/10, Batch 50/145, Loss: 0.3383
Epoch 2/10, Batch 60/145, Loss: 0.4197
Epoch 2/10, Batch 70/145, Loss: 0.3497
Epoch 2/10, Batch 80/145, Loss: 0.2330
Epoch 2/10, Batch 90/145, Loss: 0.4010
Epoch 2/10, Batch 100/145, Loss: 0.3103
Epoch 2/10, Batch 110/145, Loss: 0.4234
Epoch 2/10, Batch 120/145, Loss: 0.4689
Epoch 2/10, Batch 130/145, Loss: 0.3016
Epoch 2/10, Batch 140/145, Loss: 0.1616
Epoch 2/10, Train Loss: 0.3574, Valid Loss: 0.3040
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2133
Epoch 3/10, Batch 20/145, Loss: 0.2823
Epoch 3/10, Batch 30/145, Loss: 0.2004
Epoch 3/10, Batch 40/145, Loss: 0.2763
Epoch 3/10, Batch 50/145, Loss: 0.1192
Epoch 3/10, Batch 60/145, Loss: 0.4139
Epoch 3/10, Batch 70/145, Loss: 0.2512
Epoch 3/10, Batch 80/145, Loss: 0.3473
Epoch 3/10, Batch 90/145, Loss: 0.6349
Epoch 3/10, Batch 100/145, Loss: 0.3982
Epoch 3/10, Batch 110/145, Loss: 0.2385
Epoch 3/10, Batch 120/145, Loss: 0.1584
Epoch 3/10, Batch 130/145, Loss: 0.2690
Epoch 3/10, Batch 140/145, Loss: 0.2383
Epoch 3/10, Train Loss: 0.3000, Valid Loss: 0.2722
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1913
Epoch 4/10, Batch 20/145, Loss: 0.1620
Epoch 4/10, Batch 30/145, Loss: 0.2223
Epoch 4/10, Batch 40/145, Loss: 0.2768
Epoch 4/10, Batch 50/145, Loss: 0.1634
Epoch 4/10, Batch 60/145, Loss: 0.3121
Epoch 4/10, Batch 70/145, Loss: 0.3392
Epoch 4/10, Batch 80/145, Loss: 0.1560
Epoch 4/10, Batch 90/145, Loss: 0.2987
Epoch 4/10, Batch 100/145, Loss: 0.1279
Epoch 4/10, Batch 110/145, Loss: 0.1907
Epoch 4/10, Batch 120/145, Loss: 0.2850
Epoch 4/10, Batch 130/145, Loss: 0.2237
Epoch 4/10, Batch 140/145, Loss: 0.1328
Epoch 4/10, Train Loss: 0.2612, Valid Loss: 0.2605
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3457
Epoch 5/10, Batch 20/145, Loss: 0.1610
Epoch 5/10, Batch 30/145, Loss: 0.2362
Epoch 5/10, Batch 40/145, Loss: 0.1931
Epoch 5/10, Batch 50/145, Loss: 0.1335
Epoch 5/10, Batch 60/145, Loss: 0.2279
Epoch 5/10, Batch 70/145, Loss: 0.2873
Epoch 5/10, Batch 80/145, Loss: 0.4366
Epoch 5/10, Batch 90/145, Loss: 0.2074
Epoch 5/10, Batch 100/145, Loss: 0.2021
Epoch 5/10, Batch 110/145, Loss: 0.1963
Epoch 5/10, Batch 120/145, Loss: 0.1964
Epoch 5/10, Batch 130/145, Loss: 0.1974
Epoch 5/10, Batch 140/145, Loss: 0.2893
Epoch 5/10, Train Loss: 0.2297, Valid Loss: 0.2437
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1964
Epoch 6/10, Batch 20/145, Loss: 0.1432
Epoch 6/10, Batch 30/145, Loss: 0.1908
Epoch 6/10, Batch 40/145, Loss: 0.1868
Epoch 6/10, Batch 50/145, Loss: 0.2400
Epoch 6/10, Batch 60/145, Loss: 0.1995
Epoch 6/10, Batch 70/145, Loss: 0.3321
Epoch 6/10, Batch 80/145, Loss: 0.3192
Epoch 6/10, Batch 90/145, Loss: 0.2455
Epoch 6/10, Batch 100/145, Loss: 0.1946
Epoch 6/10, Batch 110/145, Loss: 0.2036
Epoch 6/10, Batch 120/145, Loss: 0.2449
Epoch 6/10, Batch 130/145, Loss: 0.2175
Epoch 6/10, Batch 140/145, Loss: 0.1858
Epoch 6/10, Train Loss: 0.2185, Valid Loss: 0.2284
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3660
Epoch 7/10, Batch 20/145, Loss: 0.2104
Epoch 7/10, Batch 30/145, Loss: 0.1468
Epoch 7/10, Batch 40/145, Loss: 0.3520
Epoch 7/10, Batch 50/145, Loss: 0.1564
Epoch 7/10, Batch 60/145, Loss: 0.1356
Epoch 7/10, Batch 70/145, Loss: 0.2351
Epoch 7/10, Batch 80/145, Loss: 0.1857
Epoch 7/10, Batch 90/145, Loss: 0.2557
Epoch 7/10, Batch 100/145, Loss: 0.1864
Epoch 7/10, Batch 110/145, Loss: 0.3991
Epoch 7/10, Batch 120/145, Loss: 0.2225
Epoch 7/10, Batch 130/145, Loss: 0.2744
Epoch 7/10, Batch 140/145, Loss: 0.1963
Epoch 7/10, Train Loss: 0.2163, Valid Loss: 0.2296
Epoch 8/10, Batch 10/145, Loss: 0.1710
Epoch 8/10, Batch 20/145, Loss: 0.1704
Epoch 8/10, Batch 30/145, Loss: 0.2842
Epoch 8/10, Batch 40/145, Loss: 0.1456
Epoch 8/10, Batch 50/145, Loss: 0.1350
Epoch 8/10, Batch 60/145, Loss: 0.4232
Epoch 8/10, Batch 70/145, Loss: 0.1707
Epoch 8/10, Batch 80/145, Loss: 0.2546
Epoch 8/10, Batch 90/145, Loss: 0.1153
Epoch 8/10, Batch 100/145, Loss: 0.2688
Epoch 8/10, Batch 110/145, Loss: 0.2578
Epoch 8/10, Batch 120/145, Loss: 0.3155
Epoch 8/10, Batch 130/145, Loss: 0.1391
Epoch 8/10, Batch 140/145, Loss: 0.2978
Epoch 8/10, Train Loss: 0.2043, Valid Loss: 0.2333
Epoch 9/10, Batch 10/145, Loss: 0.1955
Epoch 9/10, Batch 20/145, Loss: 0.1168
Epoch 9/10, Batch 30/145, Loss: 0.0809
Epoch 9/10, Batch 40/145, Loss: 0.1232
Epoch 9/10, Batch 50/145, Loss: 0.0815
Epoch 9/10, Batch 60/145, Loss: 0.1185
Epoch 9/10, Batch 70/145, Loss: 0.2607
Epoch 9/10, Batch 80/145, Loss: 0.1675
Epoch 9/10, Batch 90/145, Loss: 0.1225
Epoch 9/10, Batch 100/145, Loss: 0.2522
Epoch 9/10, Batch 110/145, Loss: 0.2161
Epoch 9/10, Batch 120/145, Loss: 0.1901
Epoch 9/10, Batch 130/145, Loss: 0.1677
Epoch 9/10, Batch 140/145, Loss: 0.1737
Epoch 9/10, Train Loss: 0.1963, Valid Loss: 0.2181
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2524
Epoch 10/10, Batch 20/145, Loss: 0.1468
Epoch 10/10, Batch 30/145, Loss: 0.0885
Epoch 10/10, Batch 40/145, Loss: 0.4031
Epoch 10/10, Batch 50/145, Loss: 0.0951
Epoch 10/10, Batch 60/145, Loss: 0.2693
Epoch 10/10, Batch 70/145, Loss: 0.2247
Epoch 10/10, Batch 80/145, Loss: 0.5065
Epoch 10/10, Batch 90/145, Loss: 0.0713
Epoch 10/10, Batch 100/145, Loss: 0.3149
Epoch 10/10, Batch 110/145, Loss: 0.1858
Epoch 10/10, Batch 120/145, Loss: 0.3395
Epoch 10/10, Batch 130/145, Loss: 0.1511
Epoch 10/10, Batch 140/145, Loss: 0.1329
Epoch 10/10, Train Loss: 0.1903, Valid Loss: 0.2223
Accuracy: 0.9136
Precision: 0.9110
Recall: 0.9136
F1-score: 0.9114
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5098
Epoch 1/10, Batch 20/145, Loss: 0.8691
Epoch 1/10, Batch 30/145, Loss: 0.8265
Epoch 1/10, Batch 40/145, Loss: 0.8961
Epoch 1/10, Batch 50/145, Loss: 0.5805
Epoch 1/10, Batch 60/145, Loss: 0.5833
Epoch 1/10, Batch 70/145, Loss: 0.6191
Epoch 1/10, Batch 80/145, Loss: 0.4065
Epoch 1/10, Batch 90/145, Loss: 0.5853
Epoch 1/10, Batch 100/145, Loss: 0.5488
Epoch 1/10, Batch 110/145, Loss: 0.3718
Epoch 1/10, Batch 120/145, Loss: 0.4759
Epoch 1/10, Batch 130/145, Loss: 0.4108
Epoch 1/10, Batch 140/145, Loss: 0.3804
Epoch 1/10, Train Loss: 0.6859, Valid Loss: 0.3728
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4139
Epoch 2/10, Batch 20/145, Loss: 0.4808
Epoch 2/10, Batch 30/145, Loss: 0.4105
Epoch 2/10, Batch 40/145, Loss: 0.3781
Epoch 2/10, Batch 50/145, Loss: 0.3310
Epoch 2/10, Batch 60/145, Loss: 0.4120
Epoch 2/10, Batch 70/145, Loss: 0.3648
Epoch 2/10, Batch 80/145, Loss: 0.2770
Epoch 2/10, Batch 90/145, Loss: 0.3073
Epoch 2/10, Batch 100/145, Loss: 0.3715
Epoch 2/10, Batch 110/145, Loss: 0.3424
Epoch 2/10, Batch 120/145, Loss: 0.4180
Epoch 2/10, Batch 130/145, Loss: 0.5498
Epoch 2/10, Batch 140/145, Loss: 0.3284
Epoch 2/10, Train Loss: 0.3685, Valid Loss: 0.2883
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2113
Epoch 3/10, Batch 20/145, Loss: 0.3506
Epoch 3/10, Batch 30/145, Loss: 0.3567
Epoch 3/10, Batch 40/145, Loss: 0.2707
Epoch 3/10, Batch 50/145, Loss: 0.1873
Epoch 3/10, Batch 60/145, Loss: 0.2397
Epoch 3/10, Batch 70/145, Loss: 0.2422
Epoch 3/10, Batch 80/145, Loss: 0.2346
Epoch 3/10, Batch 90/145, Loss: 0.6194
Epoch 3/10, Batch 100/145, Loss: 0.2478
Epoch 3/10, Batch 110/145, Loss: 0.2205
Epoch 3/10, Batch 120/145, Loss: 0.1911
Epoch 3/10, Batch 130/145, Loss: 0.1703
Epoch 3/10, Batch 140/145, Loss: 0.1835
Epoch 3/10, Train Loss: 0.3146, Valid Loss: 0.2561
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1387
Epoch 4/10, Batch 20/145, Loss: 0.2246
Epoch 4/10, Batch 30/145, Loss: 0.4333
Epoch 4/10, Batch 40/145, Loss: 0.3192
Epoch 4/10, Batch 50/145, Loss: 0.2178
Epoch 4/10, Batch 60/145, Loss: 0.1792
Epoch 4/10, Batch 70/145, Loss: 0.1712
Epoch 4/10, Batch 80/145, Loss: 0.1920
Epoch 4/10, Batch 90/145, Loss: 0.2492
Epoch 4/10, Batch 100/145, Loss: 0.1821
Epoch 4/10, Batch 110/145, Loss: 0.3064
Epoch 4/10, Batch 120/145, Loss: 0.2798
Epoch 4/10, Batch 130/145, Loss: 0.2312
Epoch 4/10, Batch 140/145, Loss: 0.0800
Epoch 4/10, Train Loss: 0.2652, Valid Loss: 0.2507
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2313
Epoch 5/10, Batch 20/145, Loss: 0.2547
Epoch 5/10, Batch 30/145, Loss: 0.1286
Epoch 5/10, Batch 40/145, Loss: 0.2222
Epoch 5/10, Batch 50/145, Loss: 0.1568
Epoch 5/10, Batch 60/145, Loss: 0.2873
Epoch 5/10, Batch 70/145, Loss: 0.3032
Epoch 5/10, Batch 80/145, Loss: 0.3134
Epoch 5/10, Batch 90/145, Loss: 0.1468
Epoch 5/10, Batch 100/145, Loss: 0.2497
Epoch 5/10, Batch 110/145, Loss: 0.1324
Epoch 5/10, Batch 120/145, Loss: 0.3646
Epoch 5/10, Batch 130/145, Loss: 0.2615
Epoch 5/10, Batch 140/145, Loss: 0.2811
Epoch 5/10, Train Loss: 0.2428, Valid Loss: 0.2283
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3696
Epoch 6/10, Batch 20/145, Loss: 0.3925
Epoch 6/10, Batch 30/145, Loss: 0.3214
Epoch 6/10, Batch 40/145, Loss: 0.1075
Epoch 6/10, Batch 50/145, Loss: 0.2555
Epoch 6/10, Batch 60/145, Loss: 0.1514
Epoch 6/10, Batch 70/145, Loss: 0.3718
Epoch 6/10, Batch 80/145, Loss: 0.5144
Epoch 6/10, Batch 90/145, Loss: 0.1759
Epoch 6/10, Batch 100/145, Loss: 0.0912
Epoch 6/10, Batch 110/145, Loss: 0.3532
Epoch 6/10, Batch 120/145, Loss: 0.0933
Epoch 6/10, Batch 130/145, Loss: 0.3517
Epoch 6/10, Batch 140/145, Loss: 0.3342
Epoch 6/10, Train Loss: 0.2324, Valid Loss: 0.2309
Epoch 7/10, Batch 10/145, Loss: 0.1473
Epoch 7/10, Batch 20/145, Loss: 0.2977
Epoch 7/10, Batch 30/145, Loss: 0.1505
Epoch 7/10, Batch 40/145, Loss: 0.3188
Epoch 7/10, Batch 50/145, Loss: 0.1539
Epoch 7/10, Batch 60/145, Loss: 0.2662
Epoch 7/10, Batch 70/145, Loss: 0.2394
Epoch 7/10, Batch 80/145, Loss: 0.0877
Epoch 7/10, Batch 90/145, Loss: 0.1976
Epoch 7/10, Batch 100/145, Loss: 0.1752
Epoch 7/10, Batch 110/145, Loss: 0.1400
Epoch 7/10, Batch 120/145, Loss: 0.2594
Epoch 7/10, Batch 130/145, Loss: 0.2421
Epoch 7/10, Batch 140/145, Loss: 0.1332
Epoch 7/10, Train Loss: 0.2197, Valid Loss: 0.2167
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1115
Epoch 8/10, Batch 20/145, Loss: 0.1408
Epoch 8/10, Batch 30/145, Loss: 0.1266
Epoch 8/10, Batch 40/145, Loss: 0.1406
Epoch 8/10, Batch 50/145, Loss: 0.2147
Epoch 8/10, Batch 60/145, Loss: 0.1099
Epoch 8/10, Batch 70/145, Loss: 0.1926
Epoch 8/10, Batch 80/145, Loss: 0.1889
Epoch 8/10, Batch 90/145, Loss: 0.1643
Epoch 8/10, Batch 100/145, Loss: 0.1492
Epoch 8/10, Batch 110/145, Loss: 0.2836
Epoch 8/10, Batch 120/145, Loss: 0.3063
Epoch 8/10, Batch 130/145, Loss: 0.2061
Epoch 8/10, Batch 140/145, Loss: 0.0909
Epoch 8/10, Train Loss: 0.2099, Valid Loss: 0.2173
Epoch 9/10, Batch 10/145, Loss: 0.1570
Epoch 9/10, Batch 20/145, Loss: 0.1480
Epoch 9/10, Batch 30/145, Loss: 0.1588
Epoch 9/10, Batch 40/145, Loss: 0.1518
Epoch 9/10, Batch 50/145, Loss: 0.2053
Epoch 9/10, Batch 60/145, Loss: 0.2045
Epoch 9/10, Batch 70/145, Loss: 0.4327
Epoch 9/10, Batch 80/145, Loss: 0.2389
Epoch 9/10, Batch 90/145, Loss: 0.1117
Epoch 9/10, Batch 100/145, Loss: 0.3723
Epoch 9/10, Batch 110/145, Loss: 0.1692
Epoch 9/10, Batch 120/145, Loss: 0.2353
Epoch 9/10, Batch 130/145, Loss: 0.2125
Epoch 9/10, Batch 140/145, Loss: 0.1939
Epoch 9/10, Train Loss: 0.2015, Valid Loss: 0.2062
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1757
Epoch 10/10, Batch 20/145, Loss: 0.2034
Epoch 10/10, Batch 30/145, Loss: 0.1032
Epoch 10/10, Batch 40/145, Loss: 0.1636
Epoch 10/10, Batch 50/145, Loss: 0.2125
Epoch 10/10, Batch 60/145, Loss: 0.0741
Epoch 10/10, Batch 70/145, Loss: 0.1619
Epoch 10/10, Batch 80/145, Loss: 0.2237
Epoch 10/10, Batch 90/145, Loss: 0.0866
Epoch 10/10, Batch 100/145, Loss: 0.1420
Epoch 10/10, Batch 110/145, Loss: 0.1636
Epoch 10/10, Batch 120/145, Loss: 0.1135
Epoch 10/10, Batch 130/145, Loss: 0.2631
Epoch 10/10, Batch 140/145, Loss: 0.2851
Epoch 10/10, Train Loss: 0.1969, Valid Loss: 0.2049
Model saved!
Accuracy: 0.9252
Precision: 0.9237
Recall: 0.9252
F1-score: 0.9243
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4958
Epoch 1/10, Batch 20/145, Loss: 0.9188
Epoch 1/10, Batch 30/145, Loss: 0.8821
Epoch 1/10, Batch 40/145, Loss: 0.7926
Epoch 1/10, Batch 50/145, Loss: 0.7270
Epoch 1/10, Batch 60/145, Loss: 0.5133
Epoch 1/10, Batch 70/145, Loss: 0.6171
Epoch 1/10, Batch 80/145, Loss: 0.5010
Epoch 1/10, Batch 90/145, Loss: 0.4972
Epoch 1/10, Batch 100/145, Loss: 0.5874
Epoch 1/10, Batch 110/145, Loss: 0.3580
Epoch 1/10, Batch 120/145, Loss: 0.5750
Epoch 1/10, Batch 130/145, Loss: 0.4959
Epoch 1/10, Batch 140/145, Loss: 0.5175
Epoch 1/10, Train Loss: 0.6918, Valid Loss: 0.3928
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3127
Epoch 2/10, Batch 20/145, Loss: 0.5802
Epoch 2/10, Batch 30/145, Loss: 0.2747
Epoch 2/10, Batch 40/145, Loss: 0.4936
Epoch 2/10, Batch 50/145, Loss: 0.2937
Epoch 2/10, Batch 60/145, Loss: 0.4684
Epoch 2/10, Batch 70/145, Loss: 0.3267
Epoch 2/10, Batch 80/145, Loss: 0.2311
Epoch 2/10, Batch 90/145, Loss: 0.2084
Epoch 2/10, Batch 100/145, Loss: 0.2413
Epoch 2/10, Batch 110/145, Loss: 0.2329
Epoch 2/10, Batch 120/145, Loss: 0.3481
Epoch 2/10, Batch 130/145, Loss: 0.2145
Epoch 2/10, Batch 140/145, Loss: 0.2804
Epoch 2/10, Train Loss: 0.3614, Valid Loss: 0.3083
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3032
Epoch 3/10, Batch 20/145, Loss: 0.3773
Epoch 3/10, Batch 30/145, Loss: 0.2277
Epoch 3/10, Batch 40/145, Loss: 0.2237
Epoch 3/10, Batch 50/145, Loss: 0.2109
Epoch 3/10, Batch 60/145, Loss: 0.3191
Epoch 3/10, Batch 70/145, Loss: 0.1638
Epoch 3/10, Batch 80/145, Loss: 0.2862
Epoch 3/10, Batch 90/145, Loss: 0.5564
Epoch 3/10, Batch 100/145, Loss: 0.2471
Epoch 3/10, Batch 110/145, Loss: 0.3498
Epoch 3/10, Batch 120/145, Loss: 0.2397
Epoch 3/10, Batch 130/145, Loss: 0.2332
Epoch 3/10, Batch 140/145, Loss: 0.2205
Epoch 3/10, Train Loss: 0.3065, Valid Loss: 0.2733
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2158
Epoch 4/10, Batch 20/145, Loss: 0.2605
Epoch 4/10, Batch 30/145, Loss: 0.3043
Epoch 4/10, Batch 40/145, Loss: 0.5804
Epoch 4/10, Batch 50/145, Loss: 0.1614
Epoch 4/10, Batch 60/145, Loss: 0.2435
Epoch 4/10, Batch 70/145, Loss: 0.1340
Epoch 4/10, Batch 80/145, Loss: 0.2530
Epoch 4/10, Batch 90/145, Loss: 0.2770
Epoch 4/10, Batch 100/145, Loss: 0.2281
Epoch 4/10, Batch 110/145, Loss: 0.3587
Epoch 4/10, Batch 120/145, Loss: 0.1286
Epoch 4/10, Batch 130/145, Loss: 0.1932
Epoch 4/10, Batch 140/145, Loss: 0.3135
Epoch 4/10, Train Loss: 0.2659, Valid Loss: 0.2788
Epoch 5/10, Batch 10/145, Loss: 0.3672
Epoch 5/10, Batch 20/145, Loss: 0.2246
Epoch 5/10, Batch 30/145, Loss: 0.1708
Epoch 5/10, Batch 40/145, Loss: 0.2020
Epoch 5/10, Batch 50/145, Loss: 0.1386
Epoch 5/10, Batch 60/145, Loss: 0.2284
Epoch 5/10, Batch 70/145, Loss: 0.3136
Epoch 5/10, Batch 80/145, Loss: 0.1738
Epoch 5/10, Batch 90/145, Loss: 0.3433
Epoch 5/10, Batch 100/145, Loss: 0.1107
Epoch 5/10, Batch 110/145, Loss: 0.1837
Epoch 5/10, Batch 120/145, Loss: 0.1775
Epoch 5/10, Batch 130/145, Loss: 0.1414
Epoch 5/10, Batch 140/145, Loss: 0.2048
Epoch 5/10, Train Loss: 0.2417, Valid Loss: 0.2444
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1324
Epoch 6/10, Batch 20/145, Loss: 0.4140
Epoch 6/10, Batch 30/145, Loss: 0.2220
Epoch 6/10, Batch 40/145, Loss: 0.1631
Epoch 6/10, Batch 50/145, Loss: 0.3383
Epoch 6/10, Batch 60/145, Loss: 0.0953
Epoch 6/10, Batch 70/145, Loss: 0.2730
Epoch 6/10, Batch 80/145, Loss: 0.2224
Epoch 6/10, Batch 90/145, Loss: 0.2581
Epoch 6/10, Batch 100/145, Loss: 0.1535
Epoch 6/10, Batch 110/145, Loss: 0.2144
Epoch 6/10, Batch 120/145, Loss: 0.2352
Epoch 6/10, Batch 130/145, Loss: 0.3144
Epoch 6/10, Batch 140/145, Loss: 0.2128
Epoch 6/10, Train Loss: 0.2275, Valid Loss: 0.2382
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1921
Epoch 7/10, Batch 20/145, Loss: 0.1632
Epoch 7/10, Batch 30/145, Loss: 0.2677
Epoch 7/10, Batch 40/145, Loss: 0.4245
Epoch 7/10, Batch 50/145, Loss: 0.2332
Epoch 7/10, Batch 60/145, Loss: 0.1603
Epoch 7/10, Batch 70/145, Loss: 0.1349
Epoch 7/10, Batch 80/145, Loss: 0.2083
Epoch 7/10, Batch 90/145, Loss: 0.3214
Epoch 7/10, Batch 100/145, Loss: 0.2333
Epoch 7/10, Batch 110/145, Loss: 0.3210
Epoch 7/10, Batch 120/145, Loss: 0.1177
Epoch 7/10, Batch 130/145, Loss: 0.1404
Epoch 7/10, Batch 140/145, Loss: 0.1825
Epoch 7/10, Train Loss: 0.2195, Valid Loss: 0.2381
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1465
Epoch 8/10, Batch 20/145, Loss: 0.1141
Epoch 8/10, Batch 30/145, Loss: 0.0714
Epoch 8/10, Batch 40/145, Loss: 0.1933
Epoch 8/10, Batch 50/145, Loss: 0.2677
Epoch 8/10, Batch 60/145, Loss: 0.1870
Epoch 8/10, Batch 70/145, Loss: 0.0468
Epoch 8/10, Batch 80/145, Loss: 0.2127
Epoch 8/10, Batch 90/145, Loss: 0.1486
Epoch 8/10, Batch 100/145, Loss: 0.2173
Epoch 8/10, Batch 110/145, Loss: 0.2823
Epoch 8/10, Batch 120/145, Loss: 0.1196
Epoch 8/10, Batch 130/145, Loss: 0.1942
Epoch 8/10, Batch 140/145, Loss: 0.1395
Epoch 8/10, Train Loss: 0.2069, Valid Loss: 0.2314
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1658
Epoch 9/10, Batch 20/145, Loss: 0.1329
Epoch 9/10, Batch 30/145, Loss: 0.1692
Epoch 9/10, Batch 40/145, Loss: 0.1560
Epoch 9/10, Batch 50/145, Loss: 0.1482
Epoch 9/10, Batch 60/145, Loss: 0.2329
Epoch 9/10, Batch 70/145, Loss: 0.2287
Epoch 9/10, Batch 80/145, Loss: 0.1973
Epoch 9/10, Batch 90/145, Loss: 0.3070
Epoch 9/10, Batch 100/145, Loss: 0.5220
Epoch 9/10, Batch 110/145, Loss: 0.0553
Epoch 9/10, Batch 120/145, Loss: 0.1162
Epoch 9/10, Batch 130/145, Loss: 0.3389
Epoch 9/10, Batch 140/145, Loss: 0.2180
Epoch 9/10, Train Loss: 0.2068, Valid Loss: 0.2152
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1523
Epoch 10/10, Batch 20/145, Loss: 0.2293
Epoch 10/10, Batch 30/145, Loss: 0.0610
Epoch 10/10, Batch 40/145, Loss: 0.1196
Epoch 10/10, Batch 50/145, Loss: 0.2103
Epoch 10/10, Batch 60/145, Loss: 0.1810
Epoch 10/10, Batch 70/145, Loss: 0.2118
Epoch 10/10, Batch 80/145, Loss: 0.5692
Epoch 10/10, Batch 90/145, Loss: 0.1206
Epoch 10/10, Batch 100/145, Loss: 0.1583
Epoch 10/10, Batch 110/145, Loss: 0.1313
Epoch 10/10, Batch 120/145, Loss: 0.2582
Epoch 10/10, Batch 130/145, Loss: 0.2837
Epoch 10/10, Batch 140/145, Loss: 0.2325
Epoch 10/10, Train Loss: 0.2030, Valid Loss: 0.2159
Accuracy: 0.9252
Precision: 0.9243
Recall: 0.9252
F1-score: 0.9241
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4645
Epoch 1/10, Batch 20/145, Loss: 1.0065
Epoch 1/10, Batch 30/145, Loss: 1.0068
Epoch 1/10, Batch 40/145, Loss: 0.8581
Epoch 1/10, Batch 50/145, Loss: 0.6627
Epoch 1/10, Batch 60/145, Loss: 0.5763
Epoch 1/10, Batch 70/145, Loss: 0.7692
Epoch 1/10, Batch 80/145, Loss: 0.5632
Epoch 1/10, Batch 90/145, Loss: 0.6384
Epoch 1/10, Batch 100/145, Loss: 0.5969
Epoch 1/10, Batch 110/145, Loss: 0.4152
Epoch 1/10, Batch 120/145, Loss: 0.5651
Epoch 1/10, Batch 130/145, Loss: 0.4747
Epoch 1/10, Batch 140/145, Loss: 0.4102
Epoch 1/10, Train Loss: 0.6939, Valid Loss: 0.3739
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2379
Epoch 2/10, Batch 20/145, Loss: 0.4244
Epoch 2/10, Batch 30/145, Loss: 0.3637
Epoch 2/10, Batch 40/145, Loss: 0.4315
Epoch 2/10, Batch 50/145, Loss: 0.2953
Epoch 2/10, Batch 60/145, Loss: 0.4720
Epoch 2/10, Batch 70/145, Loss: 0.3587
Epoch 2/10, Batch 80/145, Loss: 0.4435
Epoch 2/10, Batch 90/145, Loss: 0.1919
Epoch 2/10, Batch 100/145, Loss: 0.3765
Epoch 2/10, Batch 110/145, Loss: 0.3745
Epoch 2/10, Batch 120/145, Loss: 0.3666
Epoch 2/10, Batch 130/145, Loss: 0.4515
Epoch 2/10, Batch 140/145, Loss: 0.1834
Epoch 2/10, Train Loss: 0.3653, Valid Loss: 0.2881
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1899
Epoch 3/10, Batch 20/145, Loss: 0.3028
Epoch 3/10, Batch 30/145, Loss: 0.2356
Epoch 3/10, Batch 40/145, Loss: 0.2352
Epoch 3/10, Batch 50/145, Loss: 0.2580
Epoch 3/10, Batch 60/145, Loss: 0.2842
Epoch 3/10, Batch 70/145, Loss: 0.2576
Epoch 3/10, Batch 80/145, Loss: 0.2319
Epoch 3/10, Batch 90/145, Loss: 0.5198
Epoch 3/10, Batch 100/145, Loss: 0.2868
Epoch 3/10, Batch 110/145, Loss: 0.3618
Epoch 3/10, Batch 120/145, Loss: 0.3207
Epoch 3/10, Batch 130/145, Loss: 0.3487
Epoch 3/10, Batch 140/145, Loss: 0.1481
Epoch 3/10, Train Loss: 0.3089, Valid Loss: 0.2652
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2605
Epoch 4/10, Batch 20/145, Loss: 0.2315
Epoch 4/10, Batch 30/145, Loss: 0.3902
Epoch 4/10, Batch 40/145, Loss: 0.2483
Epoch 4/10, Batch 50/145, Loss: 0.2070
Epoch 4/10, Batch 60/145, Loss: 0.1862
Epoch 4/10, Batch 70/145, Loss: 0.2156
Epoch 4/10, Batch 80/145, Loss: 0.2269
Epoch 4/10, Batch 90/145, Loss: 0.2266
Epoch 4/10, Batch 100/145, Loss: 0.2771
Epoch 4/10, Batch 110/145, Loss: 0.1928
Epoch 4/10, Batch 120/145, Loss: 0.2311
Epoch 4/10, Batch 130/145, Loss: 0.1798
Epoch 4/10, Batch 140/145, Loss: 0.2408
Epoch 4/10, Train Loss: 0.2697, Valid Loss: 0.2493
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2180
Epoch 5/10, Batch 20/145, Loss: 0.2035
Epoch 5/10, Batch 30/145, Loss: 0.1634
Epoch 5/10, Batch 40/145, Loss: 0.1625
Epoch 5/10, Batch 50/145, Loss: 0.2273
Epoch 5/10, Batch 60/145, Loss: 0.2042
Epoch 5/10, Batch 70/145, Loss: 0.2774
Epoch 5/10, Batch 80/145, Loss: 0.2666
Epoch 5/10, Batch 90/145, Loss: 0.2288
Epoch 5/10, Batch 100/145, Loss: 0.2071
Epoch 5/10, Batch 110/145, Loss: 0.1903
Epoch 5/10, Batch 120/145, Loss: 0.1146
Epoch 5/10, Batch 130/145, Loss: 0.1841
Epoch 5/10, Batch 140/145, Loss: 0.1968
Epoch 5/10, Train Loss: 0.2406, Valid Loss: 0.2326
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1602
Epoch 6/10, Batch 20/145, Loss: 0.2519
Epoch 6/10, Batch 30/145, Loss: 0.2303
Epoch 6/10, Batch 40/145, Loss: 0.1087
Epoch 6/10, Batch 50/145, Loss: 0.2460
Epoch 6/10, Batch 60/145, Loss: 0.1178
Epoch 6/10, Batch 70/145, Loss: 0.2776
Epoch 6/10, Batch 80/145, Loss: 0.3124
Epoch 6/10, Batch 90/145, Loss: 0.3145
Epoch 6/10, Batch 100/145, Loss: 0.2643
Epoch 6/10, Batch 110/145, Loss: 0.1236
Epoch 6/10, Batch 120/145, Loss: 0.2443
Epoch 6/10, Batch 130/145, Loss: 0.2305
Epoch 6/10, Batch 140/145, Loss: 0.1299
Epoch 6/10, Train Loss: 0.2284, Valid Loss: 0.2299
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2082
Epoch 7/10, Batch 20/145, Loss: 0.1600
Epoch 7/10, Batch 30/145, Loss: 0.0983
Epoch 7/10, Batch 40/145, Loss: 0.6052
Epoch 7/10, Batch 50/145, Loss: 0.4033
Epoch 7/10, Batch 60/145, Loss: 0.1771
Epoch 7/10, Batch 70/145, Loss: 0.1994
Epoch 7/10, Batch 80/145, Loss: 0.2491
Epoch 7/10, Batch 90/145, Loss: 0.1976
Epoch 7/10, Batch 100/145, Loss: 0.1479
Epoch 7/10, Batch 110/145, Loss: 0.2589
Epoch 7/10, Batch 120/145, Loss: 0.1920
Epoch 7/10, Batch 130/145, Loss: 0.1764
Epoch 7/10, Batch 140/145, Loss: 0.0634
Epoch 7/10, Train Loss: 0.2274, Valid Loss: 0.2157
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2989
Epoch 8/10, Batch 20/145, Loss: 0.3871
Epoch 8/10, Batch 30/145, Loss: 0.1274
Epoch 8/10, Batch 40/145, Loss: 0.3379
Epoch 8/10, Batch 50/145, Loss: 0.2490
Epoch 8/10, Batch 60/145, Loss: 0.1775
Epoch 8/10, Batch 70/145, Loss: 0.1782
Epoch 8/10, Batch 80/145, Loss: 0.3157
Epoch 8/10, Batch 90/145, Loss: 0.2306
Epoch 8/10, Batch 100/145, Loss: 0.3536
Epoch 8/10, Batch 110/145, Loss: 0.1279
Epoch 8/10, Batch 120/145, Loss: 0.1718
Epoch 8/10, Batch 130/145, Loss: 0.2755
Epoch 8/10, Batch 140/145, Loss: 0.2320
Epoch 8/10, Train Loss: 0.2145, Valid Loss: 0.2166
Epoch 9/10, Batch 10/145, Loss: 0.2638
Epoch 9/10, Batch 20/145, Loss: 0.1171
Epoch 9/10, Batch 30/145, Loss: 0.1410
Epoch 9/10, Batch 40/145, Loss: 0.2524
Epoch 9/10, Batch 50/145, Loss: 0.1606
Epoch 9/10, Batch 60/145, Loss: 0.2348
Epoch 9/10, Batch 70/145, Loss: 0.1353
Epoch 9/10, Batch 80/145, Loss: 0.2368
Epoch 9/10, Batch 90/145, Loss: 0.2899
Epoch 9/10, Batch 100/145, Loss: 0.3092
Epoch 9/10, Batch 110/145, Loss: 0.0263
Epoch 9/10, Batch 120/145, Loss: 0.1972
Epoch 9/10, Batch 130/145, Loss: 0.3445
Epoch 9/10, Batch 140/145, Loss: 0.1041
Epoch 9/10, Train Loss: 0.2010, Valid Loss: 0.2100
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0756
Epoch 10/10, Batch 20/145, Loss: 0.1531
Epoch 10/10, Batch 30/145, Loss: 0.0998
Epoch 10/10, Batch 40/145, Loss: 0.2289
Epoch 10/10, Batch 50/145, Loss: 0.2255
Epoch 10/10, Batch 60/145, Loss: 0.2249
Epoch 10/10, Batch 70/145, Loss: 0.1040
Epoch 10/10, Batch 80/145, Loss: 0.4075
Epoch 10/10, Batch 90/145, Loss: 0.1189
Epoch 10/10, Batch 100/145, Loss: 0.1984
Epoch 10/10, Batch 110/145, Loss: 0.3016
Epoch 10/10, Batch 120/145, Loss: 0.2929
Epoch 10/10, Batch 130/145, Loss: 0.1221
Epoch 10/10, Batch 140/145, Loss: 0.2809
Epoch 10/10, Train Loss: 0.2001, Valid Loss: 0.2064
Model saved!
Accuracy: 0.9194
Precision: 0.9173
Recall: 0.9194
F1-score: 0.9178
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4929
Epoch 1/10, Batch 20/145, Loss: 0.9298
Epoch 1/10, Batch 30/145, Loss: 0.8636
Epoch 1/10, Batch 40/145, Loss: 0.9364
Epoch 1/10, Batch 50/145, Loss: 0.5951
Epoch 1/10, Batch 60/145, Loss: 0.6072
Epoch 1/10, Batch 70/145, Loss: 0.5656
Epoch 1/10, Batch 80/145, Loss: 0.5030
Epoch 1/10, Batch 90/145, Loss: 0.6641
Epoch 1/10, Batch 100/145, Loss: 0.5574
Epoch 1/10, Batch 110/145, Loss: 0.4523
Epoch 1/10, Batch 120/145, Loss: 0.6511
Epoch 1/10, Batch 130/145, Loss: 0.6041
Epoch 1/10, Batch 140/145, Loss: 0.2696
Epoch 1/10, Train Loss: 0.6895, Valid Loss: 0.3604
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4233
Epoch 2/10, Batch 20/145, Loss: 0.4710
Epoch 2/10, Batch 30/145, Loss: 0.3200
Epoch 2/10, Batch 40/145, Loss: 0.5104
Epoch 2/10, Batch 50/145, Loss: 0.3277
Epoch 2/10, Batch 60/145, Loss: 0.5020
Epoch 2/10, Batch 70/145, Loss: 0.3508
Epoch 2/10, Batch 80/145, Loss: 0.3310
Epoch 2/10, Batch 90/145, Loss: 0.3170
Epoch 2/10, Batch 100/145, Loss: 0.3061
Epoch 2/10, Batch 110/145, Loss: 0.3114
Epoch 2/10, Batch 120/145, Loss: 0.4408
Epoch 2/10, Batch 130/145, Loss: 0.3349
Epoch 2/10, Batch 140/145, Loss: 0.2925
Epoch 2/10, Train Loss: 0.3674, Valid Loss: 0.2807
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1601
Epoch 3/10, Batch 20/145, Loss: 0.1889
Epoch 3/10, Batch 30/145, Loss: 0.2129
Epoch 3/10, Batch 40/145, Loss: 0.1478
Epoch 3/10, Batch 50/145, Loss: 0.1260
Epoch 3/10, Batch 60/145, Loss: 0.2575
Epoch 3/10, Batch 70/145, Loss: 0.2348
Epoch 3/10, Batch 80/145, Loss: 0.2233
Epoch 3/10, Batch 90/145, Loss: 0.4527
Epoch 3/10, Batch 100/145, Loss: 0.1827
Epoch 3/10, Batch 110/145, Loss: 0.2373
Epoch 3/10, Batch 120/145, Loss: 0.2299
Epoch 3/10, Batch 130/145, Loss: 0.3627
Epoch 3/10, Batch 140/145, Loss: 0.1816
Epoch 3/10, Train Loss: 0.3073, Valid Loss: 0.2524
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2409
Epoch 4/10, Batch 20/145, Loss: 0.2525
Epoch 4/10, Batch 30/145, Loss: 0.2840
Epoch 4/10, Batch 40/145, Loss: 0.3631
Epoch 4/10, Batch 50/145, Loss: 0.5087
Epoch 4/10, Batch 60/145, Loss: 0.2636
Epoch 4/10, Batch 70/145, Loss: 0.2089
Epoch 4/10, Batch 80/145, Loss: 0.3702
Epoch 4/10, Batch 90/145, Loss: 0.2402
Epoch 4/10, Batch 100/145, Loss: 0.2467
Epoch 4/10, Batch 110/145, Loss: 0.2543
Epoch 4/10, Batch 120/145, Loss: 0.1988
Epoch 4/10, Batch 130/145, Loss: 0.2171
Epoch 4/10, Batch 140/145, Loss: 0.2986
Epoch 4/10, Train Loss: 0.2690, Valid Loss: 0.2421
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1218
Epoch 5/10, Batch 20/145, Loss: 0.2289
Epoch 5/10, Batch 30/145, Loss: 0.2690
Epoch 5/10, Batch 40/145, Loss: 0.2532
Epoch 5/10, Batch 50/145, Loss: 0.1024
Epoch 5/10, Batch 60/145, Loss: 0.2566
Epoch 5/10, Batch 70/145, Loss: 0.3986
Epoch 5/10, Batch 80/145, Loss: 0.3195
Epoch 5/10, Batch 90/145, Loss: 0.1162
Epoch 5/10, Batch 100/145, Loss: 0.2198
Epoch 5/10, Batch 110/145, Loss: 0.1014
Epoch 5/10, Batch 120/145, Loss: 0.4147
Epoch 5/10, Batch 130/145, Loss: 0.2356
Epoch 5/10, Batch 140/145, Loss: 0.2516
Epoch 5/10, Train Loss: 0.2435, Valid Loss: 0.2396
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3100
Epoch 6/10, Batch 20/145, Loss: 0.1720
Epoch 6/10, Batch 30/145, Loss: 0.3028
Epoch 6/10, Batch 40/145, Loss: 0.2058
Epoch 6/10, Batch 50/145, Loss: 0.3822
Epoch 6/10, Batch 60/145, Loss: 0.1401
Epoch 6/10, Batch 70/145, Loss: 0.2945
Epoch 6/10, Batch 80/145, Loss: 0.4872
Epoch 6/10, Batch 90/145, Loss: 0.1839
Epoch 6/10, Batch 100/145, Loss: 0.1161
Epoch 6/10, Batch 110/145, Loss: 0.1822
Epoch 6/10, Batch 120/145, Loss: 0.1532
Epoch 6/10, Batch 130/145, Loss: 0.2298
Epoch 6/10, Batch 140/145, Loss: 0.3734
Epoch 6/10, Train Loss: 0.2359, Valid Loss: 0.2468
Epoch 7/10, Batch 10/145, Loss: 0.3287
Epoch 7/10, Batch 20/145, Loss: 0.2523
Epoch 7/10, Batch 30/145, Loss: 0.2099
Epoch 7/10, Batch 40/145, Loss: 0.4812
Epoch 7/10, Batch 50/145, Loss: 0.1632
Epoch 7/10, Batch 60/145, Loss: 0.2861
Epoch 7/10, Batch 70/145, Loss: 0.1360
Epoch 7/10, Batch 80/145, Loss: 0.1892
Epoch 7/10, Batch 90/145, Loss: 0.1992
Epoch 7/10, Batch 100/145, Loss: 0.1410
Epoch 7/10, Batch 110/145, Loss: 0.1963
Epoch 7/10, Batch 120/145, Loss: 0.1178
Epoch 7/10, Batch 130/145, Loss: 0.2644
Epoch 7/10, Batch 140/145, Loss: 0.1116
Epoch 7/10, Train Loss: 0.2259, Valid Loss: 0.2238
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1524
Epoch 8/10, Batch 20/145, Loss: 0.1630
Epoch 8/10, Batch 30/145, Loss: 0.2523
Epoch 8/10, Batch 40/145, Loss: 0.2535
Epoch 8/10, Batch 50/145, Loss: 0.2233
Epoch 8/10, Batch 60/145, Loss: 0.2378
Epoch 8/10, Batch 70/145, Loss: 0.1150
Epoch 8/10, Batch 80/145, Loss: 0.1061
Epoch 8/10, Batch 90/145, Loss: 0.1557
Epoch 8/10, Batch 100/145, Loss: 0.2297
Epoch 8/10, Batch 110/145, Loss: 0.1225
Epoch 8/10, Batch 120/145, Loss: 0.0805
Epoch 8/10, Batch 130/145, Loss: 0.1260
Epoch 8/10, Batch 140/145, Loss: 0.2661
Epoch 8/10, Train Loss: 0.2074, Valid Loss: 0.2206
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1517
Epoch 9/10, Batch 20/145, Loss: 0.0778
Epoch 9/10, Batch 30/145, Loss: 0.0819
Epoch 9/10, Batch 40/145, Loss: 0.2375
Epoch 9/10, Batch 50/145, Loss: 0.2055
Epoch 9/10, Batch 60/145, Loss: 0.2139
Epoch 9/10, Batch 70/145, Loss: 0.1067
Epoch 9/10, Batch 80/145, Loss: 0.2152
Epoch 9/10, Batch 90/145, Loss: 0.1284
Epoch 9/10, Batch 100/145, Loss: 0.2820
Epoch 9/10, Batch 110/145, Loss: 0.1150
Epoch 9/10, Batch 120/145, Loss: 0.1331
Epoch 9/10, Batch 130/145, Loss: 0.1282
Epoch 9/10, Batch 140/145, Loss: 0.2176
Epoch 9/10, Train Loss: 0.2073, Valid Loss: 0.2108
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2966
Epoch 10/10, Batch 20/145, Loss: 0.0577
Epoch 10/10, Batch 30/145, Loss: 0.0973
Epoch 10/10, Batch 40/145, Loss: 0.2447
Epoch 10/10, Batch 50/145, Loss: 0.1806
Epoch 10/10, Batch 60/145, Loss: 0.3339
Epoch 10/10, Batch 70/145, Loss: 0.1030
Epoch 10/10, Batch 80/145, Loss: 0.4457
Epoch 10/10, Batch 90/145, Loss: 0.1996
Epoch 10/10, Batch 100/145, Loss: 0.0949
Epoch 10/10, Batch 110/145, Loss: 0.2655
Epoch 10/10, Batch 120/145, Loss: 0.1788
Epoch 10/10, Batch 130/145, Loss: 0.1256
Epoch 10/10, Batch 140/145, Loss: 0.0965
Epoch 10/10, Train Loss: 0.1996, Valid Loss: 0.2105
Model saved!
Accuracy: 0.9182
Precision: 0.9173
Recall: 0.9182
F1-score: 0.9177
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4402
Epoch 1/10, Batch 20/145, Loss: 0.9044
Epoch 1/10, Batch 30/145, Loss: 0.9027
Epoch 1/10, Batch 40/145, Loss: 0.8346
Epoch 1/10, Batch 50/145, Loss: 0.6497
Epoch 1/10, Batch 60/145, Loss: 0.5953
Epoch 1/10, Batch 70/145, Loss: 0.6536
Epoch 1/10, Batch 80/145, Loss: 0.4399
Epoch 1/10, Batch 90/145, Loss: 0.5527
Epoch 1/10, Batch 100/145, Loss: 0.6782
Epoch 1/10, Batch 110/145, Loss: 0.4221
Epoch 1/10, Batch 120/145, Loss: 0.5574
Epoch 1/10, Batch 130/145, Loss: 0.3243
Epoch 1/10, Batch 140/145, Loss: 0.3338
Epoch 1/10, Train Loss: 0.6849, Valid Loss: 0.3844
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3449
Epoch 2/10, Batch 20/145, Loss: 0.4076
Epoch 2/10, Batch 30/145, Loss: 0.2332
Epoch 2/10, Batch 40/145, Loss: 0.5139
Epoch 2/10, Batch 50/145, Loss: 0.2880
Epoch 2/10, Batch 60/145, Loss: 0.4342
Epoch 2/10, Batch 70/145, Loss: 0.3612
Epoch 2/10, Batch 80/145, Loss: 0.2512
Epoch 2/10, Batch 90/145, Loss: 0.3251
Epoch 2/10, Batch 100/145, Loss: 0.3726
Epoch 2/10, Batch 110/145, Loss: 0.2832
Epoch 2/10, Batch 120/145, Loss: 0.4094
Epoch 2/10, Batch 130/145, Loss: 0.2765
Epoch 2/10, Batch 140/145, Loss: 0.2825
Epoch 2/10, Train Loss: 0.3581, Valid Loss: 0.2952
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2369
Epoch 3/10, Batch 20/145, Loss: 0.3232
Epoch 3/10, Batch 30/145, Loss: 0.3738
Epoch 3/10, Batch 40/145, Loss: 0.3474
Epoch 3/10, Batch 50/145, Loss: 0.1541
Epoch 3/10, Batch 60/145, Loss: 0.3457
Epoch 3/10, Batch 70/145, Loss: 0.2997
Epoch 3/10, Batch 80/145, Loss: 0.2027
Epoch 3/10, Batch 90/145, Loss: 0.4731
Epoch 3/10, Batch 100/145, Loss: 0.2990
Epoch 3/10, Batch 110/145, Loss: 0.2850
Epoch 3/10, Batch 120/145, Loss: 0.2525
Epoch 3/10, Batch 130/145, Loss: 0.1926
Epoch 3/10, Batch 140/145, Loss: 0.3799
Epoch 3/10, Train Loss: 0.3131, Valid Loss: 0.2644
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1226
Epoch 4/10, Batch 20/145, Loss: 0.2508
Epoch 4/10, Batch 30/145, Loss: 0.3249
Epoch 4/10, Batch 40/145, Loss: 0.3218
Epoch 4/10, Batch 50/145, Loss: 0.2784
Epoch 4/10, Batch 60/145, Loss: 0.2659
Epoch 4/10, Batch 70/145, Loss: 0.4287
Epoch 4/10, Batch 80/145, Loss: 0.3704
Epoch 4/10, Batch 90/145, Loss: 0.2029
Epoch 4/10, Batch 100/145, Loss: 0.2336
Epoch 4/10, Batch 110/145, Loss: 0.2290
Epoch 4/10, Batch 120/145, Loss: 0.2374
Epoch 4/10, Batch 130/145, Loss: 0.3029
Epoch 4/10, Batch 140/145, Loss: 0.2297
Epoch 4/10, Train Loss: 0.2654, Valid Loss: 0.2659
Epoch 5/10, Batch 10/145, Loss: 0.2925
Epoch 5/10, Batch 20/145, Loss: 0.1635
Epoch 5/10, Batch 30/145, Loss: 0.2306
Epoch 5/10, Batch 40/145, Loss: 0.1843
Epoch 5/10, Batch 50/145, Loss: 0.2345
Epoch 5/10, Batch 60/145, Loss: 0.1866
Epoch 5/10, Batch 70/145, Loss: 0.2301
Epoch 5/10, Batch 80/145, Loss: 0.2480
Epoch 5/10, Batch 90/145, Loss: 0.2110
Epoch 5/10, Batch 100/145, Loss: 0.1537
Epoch 5/10, Batch 110/145, Loss: 0.1061
Epoch 5/10, Batch 120/145, Loss: 0.2410
Epoch 5/10, Batch 130/145, Loss: 0.2242
Epoch 5/10, Batch 140/145, Loss: 0.4299
Epoch 5/10, Train Loss: 0.2412, Valid Loss: 0.2385
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3768
Epoch 6/10, Batch 20/145, Loss: 0.1736
Epoch 6/10, Batch 30/145, Loss: 0.2234
Epoch 6/10, Batch 40/145, Loss: 0.1501
Epoch 6/10, Batch 50/145, Loss: 0.2251
Epoch 6/10, Batch 60/145, Loss: 0.2434
Epoch 6/10, Batch 70/145, Loss: 0.2544
Epoch 6/10, Batch 80/145, Loss: 0.3772
Epoch 6/10, Batch 90/145, Loss: 0.2104
Epoch 6/10, Batch 100/145, Loss: 0.1291
Epoch 6/10, Batch 110/145, Loss: 0.1992
Epoch 6/10, Batch 120/145, Loss: 0.2698
Epoch 6/10, Batch 130/145, Loss: 0.0567
Epoch 6/10, Batch 140/145, Loss: 0.2222
Epoch 6/10, Train Loss: 0.2233, Valid Loss: 0.2281
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3190
Epoch 7/10, Batch 20/145, Loss: 0.2835
Epoch 7/10, Batch 30/145, Loss: 0.2870
Epoch 7/10, Batch 40/145, Loss: 0.3378
Epoch 7/10, Batch 50/145, Loss: 0.1491
Epoch 7/10, Batch 60/145, Loss: 0.2305
Epoch 7/10, Batch 70/145, Loss: 0.2469
Epoch 7/10, Batch 80/145, Loss: 0.0990
Epoch 7/10, Batch 90/145, Loss: 0.2190
Epoch 7/10, Batch 100/145, Loss: 0.2208
Epoch 7/10, Batch 110/145, Loss: 0.3783
Epoch 7/10, Batch 120/145, Loss: 0.3322
Epoch 7/10, Batch 130/145, Loss: 0.1820
Epoch 7/10, Batch 140/145, Loss: 0.1453
Epoch 7/10, Train Loss: 0.2177, Valid Loss: 0.2172
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1831
Epoch 8/10, Batch 20/145, Loss: 0.2678
Epoch 8/10, Batch 30/145, Loss: 0.1480
Epoch 8/10, Batch 40/145, Loss: 0.2040
Epoch 8/10, Batch 50/145, Loss: 0.1391
Epoch 8/10, Batch 60/145, Loss: 0.1588
Epoch 8/10, Batch 70/145, Loss: 0.1530
Epoch 8/10, Batch 80/145, Loss: 0.2985
Epoch 8/10, Batch 90/145, Loss: 0.0879
Epoch 8/10, Batch 100/145, Loss: 0.1740
Epoch 8/10, Batch 110/145, Loss: 0.3324
Epoch 8/10, Batch 120/145, Loss: 0.2917
Epoch 8/10, Batch 130/145, Loss: 0.2020
Epoch 8/10, Batch 140/145, Loss: 0.3564
Epoch 8/10, Train Loss: 0.2115, Valid Loss: 0.2146
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3151
Epoch 9/10, Batch 20/145, Loss: 0.2511
Epoch 9/10, Batch 30/145, Loss: 0.1561
Epoch 9/10, Batch 40/145, Loss: 0.1632
Epoch 9/10, Batch 50/145, Loss: 0.2763
Epoch 9/10, Batch 60/145, Loss: 0.1943
Epoch 9/10, Batch 70/145, Loss: 0.0984
Epoch 9/10, Batch 80/145, Loss: 0.2575
Epoch 9/10, Batch 90/145, Loss: 0.1068
Epoch 9/10, Batch 100/145, Loss: 0.2504
Epoch 9/10, Batch 110/145, Loss: 0.2604
Epoch 9/10, Batch 120/145, Loss: 0.2096
Epoch 9/10, Batch 130/145, Loss: 0.2429
Epoch 9/10, Batch 140/145, Loss: 0.0678
Epoch 9/10, Train Loss: 0.2074, Valid Loss: 0.2022
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2362
Epoch 10/10, Batch 20/145, Loss: 0.1260
Epoch 10/10, Batch 30/145, Loss: 0.1228
Epoch 10/10, Batch 40/145, Loss: 0.2290
Epoch 10/10, Batch 50/145, Loss: 0.2779
Epoch 10/10, Batch 60/145, Loss: 0.1129
Epoch 10/10, Batch 70/145, Loss: 0.0925
Epoch 10/10, Batch 80/145, Loss: 0.2355
Epoch 10/10, Batch 90/145, Loss: 0.4127
Epoch 10/10, Batch 100/145, Loss: 0.1867
Epoch 10/10, Batch 110/145, Loss: 0.1932
Epoch 10/10, Batch 120/145, Loss: 0.2374
Epoch 10/10, Batch 130/145, Loss: 0.2597
Epoch 10/10, Batch 140/145, Loss: 0.3632
Epoch 10/10, Train Loss: 0.2002, Valid Loss: 0.2017
Model saved!
Accuracy: 0.9229
Precision: 0.9211
Recall: 0.9229
F1-score: 0.9217
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5061
Epoch 1/10, Batch 20/145, Loss: 0.9557
Epoch 1/10, Batch 30/145, Loss: 0.8706
Epoch 1/10, Batch 40/145, Loss: 0.8377
Epoch 1/10, Batch 50/145, Loss: 0.6359
Epoch 1/10, Batch 60/145, Loss: 0.4886
Epoch 1/10, Batch 70/145, Loss: 0.6845
Epoch 1/10, Batch 80/145, Loss: 0.5143
Epoch 1/10, Batch 90/145, Loss: 0.5349
Epoch 1/10, Batch 100/145, Loss: 0.6647
Epoch 1/10, Batch 110/145, Loss: 0.4366
Epoch 1/10, Batch 120/145, Loss: 0.5651
Epoch 1/10, Batch 130/145, Loss: 0.4071
Epoch 1/10, Batch 140/145, Loss: 0.3639
Epoch 1/10, Train Loss: 0.6885, Valid Loss: 0.3607
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3183
Epoch 2/10, Batch 20/145, Loss: 0.5414
Epoch 2/10, Batch 30/145, Loss: 0.2701
Epoch 2/10, Batch 40/145, Loss: 0.4985
Epoch 2/10, Batch 50/145, Loss: 0.2919
Epoch 2/10, Batch 60/145, Loss: 0.3172
Epoch 2/10, Batch 70/145, Loss: 0.4013
Epoch 2/10, Batch 80/145, Loss: 0.2226
Epoch 2/10, Batch 90/145, Loss: 0.3010
Epoch 2/10, Batch 100/145, Loss: 0.2107
Epoch 2/10, Batch 110/145, Loss: 0.3463
Epoch 2/10, Batch 120/145, Loss: 0.5012
Epoch 2/10, Batch 130/145, Loss: 0.3651
Epoch 2/10, Batch 140/145, Loss: 0.2331
Epoch 2/10, Train Loss: 0.3653, Valid Loss: 0.2850
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2590
Epoch 3/10, Batch 20/145, Loss: 0.2721
Epoch 3/10, Batch 30/145, Loss: 0.2669
Epoch 3/10, Batch 40/145, Loss: 0.2819
Epoch 3/10, Batch 50/145, Loss: 0.2065
Epoch 3/10, Batch 60/145, Loss: 0.2469
Epoch 3/10, Batch 70/145, Loss: 0.2021
Epoch 3/10, Batch 80/145, Loss: 0.3464
Epoch 3/10, Batch 90/145, Loss: 0.7821
Epoch 3/10, Batch 100/145, Loss: 0.2784
Epoch 3/10, Batch 110/145, Loss: 0.3066
Epoch 3/10, Batch 120/145, Loss: 0.2495
Epoch 3/10, Batch 130/145, Loss: 0.1424
Epoch 3/10, Batch 140/145, Loss: 0.2473
Epoch 3/10, Train Loss: 0.3109, Valid Loss: 0.2581
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1205
Epoch 4/10, Batch 20/145, Loss: 0.2334
Epoch 4/10, Batch 30/145, Loss: 0.2850
Epoch 4/10, Batch 40/145, Loss: 0.2693
Epoch 4/10, Batch 50/145, Loss: 0.3372
Epoch 4/10, Batch 60/145, Loss: 0.2636
Epoch 4/10, Batch 70/145, Loss: 0.1366
Epoch 4/10, Batch 80/145, Loss: 0.1917
Epoch 4/10, Batch 90/145, Loss: 0.2937
Epoch 4/10, Batch 100/145, Loss: 0.3811
Epoch 4/10, Batch 110/145, Loss: 0.3029
Epoch 4/10, Batch 120/145, Loss: 0.1648
Epoch 4/10, Batch 130/145, Loss: 0.2870
Epoch 4/10, Batch 140/145, Loss: 0.1623
Epoch 4/10, Train Loss: 0.2655, Valid Loss: 0.2537
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2713
Epoch 5/10, Batch 20/145, Loss: 0.2927
Epoch 5/10, Batch 30/145, Loss: 0.1544
Epoch 5/10, Batch 40/145, Loss: 0.3598
Epoch 5/10, Batch 50/145, Loss: 0.1802
Epoch 5/10, Batch 60/145, Loss: 0.2484
Epoch 5/10, Batch 70/145, Loss: 0.3235
Epoch 5/10, Batch 80/145, Loss: 0.3758
Epoch 5/10, Batch 90/145, Loss: 0.1039
Epoch 5/10, Batch 100/145, Loss: 0.2568
Epoch 5/10, Batch 110/145, Loss: 0.1481
Epoch 5/10, Batch 120/145, Loss: 0.2063
Epoch 5/10, Batch 130/145, Loss: 0.2380
Epoch 5/10, Batch 140/145, Loss: 0.1074
Epoch 5/10, Train Loss: 0.2407, Valid Loss: 0.2314
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2012
Epoch 6/10, Batch 20/145, Loss: 0.1803
Epoch 6/10, Batch 30/145, Loss: 0.3581
Epoch 6/10, Batch 40/145, Loss: 0.1506
Epoch 6/10, Batch 50/145, Loss: 0.4741
Epoch 6/10, Batch 60/145, Loss: 0.2564
Epoch 6/10, Batch 70/145, Loss: 0.2019
Epoch 6/10, Batch 80/145, Loss: 0.4125
Epoch 6/10, Batch 90/145, Loss: 0.0799
Epoch 6/10, Batch 100/145, Loss: 0.1795
Epoch 6/10, Batch 110/145, Loss: 0.0973
Epoch 6/10, Batch 120/145, Loss: 0.2378
Epoch 6/10, Batch 130/145, Loss: 0.2189
Epoch 6/10, Batch 140/145, Loss: 0.2635
Epoch 6/10, Train Loss: 0.2308, Valid Loss: 0.2370
Epoch 7/10, Batch 10/145, Loss: 0.3431
Epoch 7/10, Batch 20/145, Loss: 0.2319
Epoch 7/10, Batch 30/145, Loss: 0.1663
Epoch 7/10, Batch 40/145, Loss: 0.4751
Epoch 7/10, Batch 50/145, Loss: 0.2187
Epoch 7/10, Batch 60/145, Loss: 0.2339
Epoch 7/10, Batch 70/145, Loss: 0.2101
Epoch 7/10, Batch 80/145, Loss: 0.1758
Epoch 7/10, Batch 90/145, Loss: 0.1794
Epoch 7/10, Batch 100/145, Loss: 0.1435
Epoch 7/10, Batch 110/145, Loss: 0.2846
Epoch 7/10, Batch 120/145, Loss: 0.1991
Epoch 7/10, Batch 130/145, Loss: 0.2902
Epoch 7/10, Batch 140/145, Loss: 0.1478
Epoch 7/10, Train Loss: 0.2174, Valid Loss: 0.2263
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2239
Epoch 8/10, Batch 20/145, Loss: 0.1697
Epoch 8/10, Batch 30/145, Loss: 0.1667
Epoch 8/10, Batch 40/145, Loss: 0.1763
Epoch 8/10, Batch 50/145, Loss: 0.2484
Epoch 8/10, Batch 60/145, Loss: 0.1360
Epoch 8/10, Batch 70/145, Loss: 0.0702
Epoch 8/10, Batch 80/145, Loss: 0.1015
Epoch 8/10, Batch 90/145, Loss: 0.1446
Epoch 8/10, Batch 100/145, Loss: 0.2620
Epoch 8/10, Batch 110/145, Loss: 0.2304
Epoch 8/10, Batch 120/145, Loss: 0.1144
Epoch 8/10, Batch 130/145, Loss: 0.1927
Epoch 8/10, Batch 140/145, Loss: 0.1793
Epoch 8/10, Train Loss: 0.2117, Valid Loss: 0.2321
Epoch 9/10, Batch 10/145, Loss: 0.1398
Epoch 9/10, Batch 20/145, Loss: 0.1364
Epoch 9/10, Batch 30/145, Loss: 0.1072
Epoch 9/10, Batch 40/145, Loss: 0.2475
Epoch 9/10, Batch 50/145, Loss: 0.1838
Epoch 9/10, Batch 60/145, Loss: 0.1638
Epoch 9/10, Batch 70/145, Loss: 0.3153
Epoch 9/10, Batch 80/145, Loss: 0.2299
Epoch 9/10, Batch 90/145, Loss: 0.1849
Epoch 9/10, Batch 100/145, Loss: 0.2343
Epoch 9/10, Batch 110/145, Loss: 0.0760
Epoch 9/10, Batch 120/145, Loss: 0.4098
Epoch 9/10, Batch 130/145, Loss: 0.1874
Epoch 9/10, Batch 140/145, Loss: 0.0934
Epoch 9/10, Train Loss: 0.2039, Valid Loss: 0.2198
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1417
Epoch 10/10, Batch 20/145, Loss: 0.1820
Epoch 10/10, Batch 30/145, Loss: 0.1218
Epoch 10/10, Batch 40/145, Loss: 0.2155
Epoch 10/10, Batch 50/145, Loss: 0.2499
Epoch 10/10, Batch 60/145, Loss: 0.1254
Epoch 10/10, Batch 70/145, Loss: 0.1041
Epoch 10/10, Batch 80/145, Loss: 0.5200
Epoch 10/10, Batch 90/145, Loss: 0.0961
Epoch 10/10, Batch 100/145, Loss: 0.0916
Epoch 10/10, Batch 110/145, Loss: 0.2085
Epoch 10/10, Batch 120/145, Loss: 0.1022
Epoch 10/10, Batch 130/145, Loss: 0.2491
Epoch 10/10, Batch 140/145, Loss: 0.1908
Epoch 10/10, Train Loss: 0.1980, Valid Loss: 0.2212
Accuracy: 0.9229
Precision: 0.9216
Recall: 0.9229
F1-score: 0.9220
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4780
Epoch 1/10, Batch 20/145, Loss: 0.9567
Epoch 1/10, Batch 30/145, Loss: 0.7584
Epoch 1/10, Batch 40/145, Loss: 0.8657
Epoch 1/10, Batch 50/145, Loss: 0.6075
Epoch 1/10, Batch 60/145, Loss: 0.5387
Epoch 1/10, Batch 70/145, Loss: 0.6511
Epoch 1/10, Batch 80/145, Loss: 0.5598
Epoch 1/10, Batch 90/145, Loss: 0.5368
Epoch 1/10, Batch 100/145, Loss: 0.6565
Epoch 1/10, Batch 110/145, Loss: 0.3808
Epoch 1/10, Batch 120/145, Loss: 0.5921
Epoch 1/10, Batch 130/145, Loss: 0.5163
Epoch 1/10, Batch 140/145, Loss: 0.4324
Epoch 1/10, Train Loss: 0.6853, Valid Loss: 0.3820
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3438
Epoch 2/10, Batch 20/145, Loss: 0.4866
Epoch 2/10, Batch 30/145, Loss: 0.3643
Epoch 2/10, Batch 40/145, Loss: 0.4401
Epoch 2/10, Batch 50/145, Loss: 0.2603
Epoch 2/10, Batch 60/145, Loss: 0.4558
Epoch 2/10, Batch 70/145, Loss: 0.4439
Epoch 2/10, Batch 80/145, Loss: 0.3053
Epoch 2/10, Batch 90/145, Loss: 0.1807
Epoch 2/10, Batch 100/145, Loss: 0.1935
Epoch 2/10, Batch 110/145, Loss: 0.3320
Epoch 2/10, Batch 120/145, Loss: 0.4289
Epoch 2/10, Batch 130/145, Loss: 0.3824
Epoch 2/10, Batch 140/145, Loss: 0.2572
Epoch 2/10, Train Loss: 0.3641, Valid Loss: 0.3024
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.4065
Epoch 3/10, Batch 20/145, Loss: 0.2214
Epoch 3/10, Batch 30/145, Loss: 0.2813
Epoch 3/10, Batch 40/145, Loss: 0.2769
Epoch 3/10, Batch 50/145, Loss: 0.1936
Epoch 3/10, Batch 60/145, Loss: 0.2686
Epoch 3/10, Batch 70/145, Loss: 0.2699
Epoch 3/10, Batch 80/145, Loss: 0.3345
Epoch 3/10, Batch 90/145, Loss: 0.5442
Epoch 3/10, Batch 100/145, Loss: 0.2610
Epoch 3/10, Batch 110/145, Loss: 0.2057
Epoch 3/10, Batch 120/145, Loss: 0.1985
Epoch 3/10, Batch 130/145, Loss: 0.3402
Epoch 3/10, Batch 140/145, Loss: 0.2237
Epoch 3/10, Train Loss: 0.3015, Valid Loss: 0.2724
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1876
Epoch 4/10, Batch 20/145, Loss: 0.1899
Epoch 4/10, Batch 30/145, Loss: 0.2748
Epoch 4/10, Batch 40/145, Loss: 0.2923
Epoch 4/10, Batch 50/145, Loss: 0.1080
Epoch 4/10, Batch 60/145, Loss: 0.1944
Epoch 4/10, Batch 70/145, Loss: 0.1746
Epoch 4/10, Batch 80/145, Loss: 0.2233
Epoch 4/10, Batch 90/145, Loss: 0.3686
Epoch 4/10, Batch 100/145, Loss: 0.2570
Epoch 4/10, Batch 110/145, Loss: 0.1248
Epoch 4/10, Batch 120/145, Loss: 0.2752
Epoch 4/10, Batch 130/145, Loss: 0.2403
Epoch 4/10, Batch 140/145, Loss: 0.1703
Epoch 4/10, Train Loss: 0.2657, Valid Loss: 0.2606
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2427
Epoch 5/10, Batch 20/145, Loss: 0.2412
Epoch 5/10, Batch 30/145, Loss: 0.1904
Epoch 5/10, Batch 40/145, Loss: 0.1758
Epoch 5/10, Batch 50/145, Loss: 0.1729
Epoch 5/10, Batch 60/145, Loss: 0.2662
Epoch 5/10, Batch 70/145, Loss: 0.4856
Epoch 5/10, Batch 80/145, Loss: 0.2353
Epoch 5/10, Batch 90/145, Loss: 0.2344
Epoch 5/10, Batch 100/145, Loss: 0.3281
Epoch 5/10, Batch 110/145, Loss: 0.1407
Epoch 5/10, Batch 120/145, Loss: 0.1265
Epoch 5/10, Batch 130/145, Loss: 0.1438
Epoch 5/10, Batch 140/145, Loss: 0.1331
Epoch 5/10, Train Loss: 0.2325, Valid Loss: 0.2487
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2952
Epoch 6/10, Batch 20/145, Loss: 0.3052
Epoch 6/10, Batch 30/145, Loss: 0.2229
Epoch 6/10, Batch 40/145, Loss: 0.1575
Epoch 6/10, Batch 50/145, Loss: 0.3687
Epoch 6/10, Batch 60/145, Loss: 0.1956
Epoch 6/10, Batch 70/145, Loss: 0.3443
Epoch 6/10, Batch 80/145, Loss: 0.1711
Epoch 6/10, Batch 90/145, Loss: 0.1419
Epoch 6/10, Batch 100/145, Loss: 0.2646
Epoch 6/10, Batch 110/145, Loss: 0.1572
Epoch 6/10, Batch 120/145, Loss: 0.1985
Epoch 6/10, Batch 130/145, Loss: 0.2179
Epoch 6/10, Batch 140/145, Loss: 0.2808
Epoch 6/10, Train Loss: 0.2291, Valid Loss: 0.2446
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3016
Epoch 7/10, Batch 20/145, Loss: 0.2915
Epoch 7/10, Batch 30/145, Loss: 0.4155
Epoch 7/10, Batch 40/145, Loss: 0.4675
Epoch 7/10, Batch 50/145, Loss: 0.2416
Epoch 7/10, Batch 60/145, Loss: 0.2287
Epoch 7/10, Batch 70/145, Loss: 0.1280
Epoch 7/10, Batch 80/145, Loss: 0.0958
Epoch 7/10, Batch 90/145, Loss: 0.1652
Epoch 7/10, Batch 100/145, Loss: 0.1801
Epoch 7/10, Batch 110/145, Loss: 0.2374
Epoch 7/10, Batch 120/145, Loss: 0.3198
Epoch 7/10, Batch 130/145, Loss: 0.3230
Epoch 7/10, Batch 140/145, Loss: 0.1452
Epoch 7/10, Train Loss: 0.2128, Valid Loss: 0.2296
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1653
Epoch 8/10, Batch 20/145, Loss: 0.1854
Epoch 8/10, Batch 30/145, Loss: 0.2056
Epoch 8/10, Batch 40/145, Loss: 0.2263
Epoch 8/10, Batch 50/145, Loss: 0.2298
Epoch 8/10, Batch 60/145, Loss: 0.2631
Epoch 8/10, Batch 70/145, Loss: 0.2530
Epoch 8/10, Batch 80/145, Loss: 0.2235
Epoch 8/10, Batch 90/145, Loss: 0.0988
Epoch 8/10, Batch 100/145, Loss: 0.3913
Epoch 8/10, Batch 110/145, Loss: 0.2389
Epoch 8/10, Batch 120/145, Loss: 0.2472
Epoch 8/10, Batch 130/145, Loss: 0.2029
Epoch 8/10, Batch 140/145, Loss: 0.2239
Epoch 8/10, Train Loss: 0.2020, Valid Loss: 0.2428
Epoch 9/10, Batch 10/145, Loss: 0.2974
Epoch 9/10, Batch 20/145, Loss: 0.3133
Epoch 9/10, Batch 30/145, Loss: 0.2591
Epoch 9/10, Batch 40/145, Loss: 0.1745
Epoch 9/10, Batch 50/145, Loss: 0.1282
Epoch 9/10, Batch 60/145, Loss: 0.1267
Epoch 9/10, Batch 70/145, Loss: 0.2467
Epoch 9/10, Batch 80/145, Loss: 0.1136
Epoch 9/10, Batch 90/145, Loss: 0.1468
Epoch 9/10, Batch 100/145, Loss: 0.3424
Epoch 9/10, Batch 110/145, Loss: 0.1053
Epoch 9/10, Batch 120/145, Loss: 0.1168
Epoch 9/10, Batch 130/145, Loss: 0.0740
Epoch 9/10, Batch 140/145, Loss: 0.0569
Epoch 9/10, Train Loss: 0.2035, Valid Loss: 0.2196
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0989
Epoch 10/10, Batch 20/145, Loss: 0.0779
Epoch 10/10, Batch 30/145, Loss: 0.1176
Epoch 10/10, Batch 40/145, Loss: 0.2378
Epoch 10/10, Batch 50/145, Loss: 0.1793
Epoch 10/10, Batch 60/145, Loss: 0.2302
Epoch 10/10, Batch 70/145, Loss: 0.3067
Epoch 10/10, Batch 80/145, Loss: 0.3485
Epoch 10/10, Batch 90/145, Loss: 0.1560
Epoch 10/10, Batch 100/145, Loss: 0.0817
Epoch 10/10, Batch 110/145, Loss: 0.4881
Epoch 10/10, Batch 120/145, Loss: 0.3713
Epoch 10/10, Batch 130/145, Loss: 0.2322
Epoch 10/10, Batch 140/145, Loss: 0.1774
Epoch 10/10, Train Loss: 0.1887, Valid Loss: 0.2234
Accuracy: 0.9217
Precision: 0.9193
Recall: 0.9217
F1-score: 0.9197
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4587
Epoch 1/10, Batch 20/145, Loss: 0.9003
Epoch 1/10, Batch 30/145, Loss: 0.8882
Epoch 1/10, Batch 40/145, Loss: 0.8038
Epoch 1/10, Batch 50/145, Loss: 0.6063
Epoch 1/10, Batch 60/145, Loss: 0.5499
Epoch 1/10, Batch 70/145, Loss: 0.5449
Epoch 1/10, Batch 80/145, Loss: 0.5539
Epoch 1/10, Batch 90/145, Loss: 0.4259
Epoch 1/10, Batch 100/145, Loss: 0.5322
Epoch 1/10, Batch 110/145, Loss: 0.4178
Epoch 1/10, Batch 120/145, Loss: 0.6750
Epoch 1/10, Batch 130/145, Loss: 0.4000
Epoch 1/10, Batch 140/145, Loss: 0.4909
Epoch 1/10, Train Loss: 0.6848, Valid Loss: 0.3840
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2885
Epoch 2/10, Batch 20/145, Loss: 0.6103
Epoch 2/10, Batch 30/145, Loss: 0.3472
Epoch 2/10, Batch 40/145, Loss: 0.3829
Epoch 2/10, Batch 50/145, Loss: 0.2479
Epoch 2/10, Batch 60/145, Loss: 0.4769
Epoch 2/10, Batch 70/145, Loss: 0.3324
Epoch 2/10, Batch 80/145, Loss: 0.2777
Epoch 2/10, Batch 90/145, Loss: 0.2910
Epoch 2/10, Batch 100/145, Loss: 0.2231
Epoch 2/10, Batch 110/145, Loss: 0.1730
Epoch 2/10, Batch 120/145, Loss: 0.4726
Epoch 2/10, Batch 130/145, Loss: 0.3611
Epoch 2/10, Batch 140/145, Loss: 0.2728
Epoch 2/10, Train Loss: 0.3580, Valid Loss: 0.3005
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2798
Epoch 3/10, Batch 20/145, Loss: 0.3946
Epoch 3/10, Batch 30/145, Loss: 0.2257
Epoch 3/10, Batch 40/145, Loss: 0.3433
Epoch 3/10, Batch 50/145, Loss: 0.2236
Epoch 3/10, Batch 60/145, Loss: 0.1817
Epoch 3/10, Batch 70/145, Loss: 0.2758
Epoch 3/10, Batch 80/145, Loss: 0.2945
Epoch 3/10, Batch 90/145, Loss: 0.5339
Epoch 3/10, Batch 100/145, Loss: 0.3057
Epoch 3/10, Batch 110/145, Loss: 0.1945
Epoch 3/10, Batch 120/145, Loss: 0.1580
Epoch 3/10, Batch 130/145, Loss: 0.2414
Epoch 3/10, Batch 140/145, Loss: 0.1805
Epoch 3/10, Train Loss: 0.3094, Valid Loss: 0.2673
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2294
Epoch 4/10, Batch 20/145, Loss: 0.2472
Epoch 4/10, Batch 30/145, Loss: 0.2244
Epoch 4/10, Batch 40/145, Loss: 0.2326
Epoch 4/10, Batch 50/145, Loss: 0.1950
Epoch 4/10, Batch 60/145, Loss: 0.2159
Epoch 4/10, Batch 70/145, Loss: 0.2782
Epoch 4/10, Batch 80/145, Loss: 0.4114
Epoch 4/10, Batch 90/145, Loss: 0.2225
Epoch 4/10, Batch 100/145, Loss: 0.2566
Epoch 4/10, Batch 110/145, Loss: 0.3365
Epoch 4/10, Batch 120/145, Loss: 0.2254
Epoch 4/10, Batch 130/145, Loss: 0.1499
Epoch 4/10, Batch 140/145, Loss: 0.2142
Epoch 4/10, Train Loss: 0.2611, Valid Loss: 0.2639
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1612
Epoch 5/10, Batch 20/145, Loss: 0.2536
Epoch 5/10, Batch 30/145, Loss: 0.1926
Epoch 5/10, Batch 40/145, Loss: 0.3042
Epoch 5/10, Batch 50/145, Loss: 0.2694
Epoch 5/10, Batch 60/145, Loss: 0.1415
Epoch 5/10, Batch 70/145, Loss: 0.3406
Epoch 5/10, Batch 80/145, Loss: 0.3845
Epoch 5/10, Batch 90/145, Loss: 0.1627
Epoch 5/10, Batch 100/145, Loss: 0.3086
Epoch 5/10, Batch 110/145, Loss: 0.1762
Epoch 5/10, Batch 120/145, Loss: 0.1301
Epoch 5/10, Batch 130/145, Loss: 0.1924
Epoch 5/10, Batch 140/145, Loss: 0.3689
Epoch 5/10, Train Loss: 0.2388, Valid Loss: 0.2435
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2971
Epoch 6/10, Batch 20/145, Loss: 0.1891
Epoch 6/10, Batch 30/145, Loss: 0.4968
Epoch 6/10, Batch 40/145, Loss: 0.1439
Epoch 6/10, Batch 50/145, Loss: 0.2899
Epoch 6/10, Batch 60/145, Loss: 0.1606
Epoch 6/10, Batch 70/145, Loss: 0.3638
Epoch 6/10, Batch 80/145, Loss: 0.3803
Epoch 6/10, Batch 90/145, Loss: 0.3374
Epoch 6/10, Batch 100/145, Loss: 0.2229
Epoch 6/10, Batch 110/145, Loss: 0.1789
Epoch 6/10, Batch 120/145, Loss: 0.4771
Epoch 6/10, Batch 130/145, Loss: 0.1852
Epoch 6/10, Batch 140/145, Loss: 0.1798
Epoch 6/10, Train Loss: 0.2265, Valid Loss: 0.2459
Epoch 7/10, Batch 10/145, Loss: 0.3479
Epoch 7/10, Batch 20/145, Loss: 0.1632
Epoch 7/10, Batch 30/145, Loss: 0.1467
Epoch 7/10, Batch 40/145, Loss: 0.4572
Epoch 7/10, Batch 50/145, Loss: 0.2733
Epoch 7/10, Batch 60/145, Loss: 0.1212
Epoch 7/10, Batch 70/145, Loss: 0.4219
Epoch 7/10, Batch 80/145, Loss: 0.1288
Epoch 7/10, Batch 90/145, Loss: 0.1861
Epoch 7/10, Batch 100/145, Loss: 0.3183
Epoch 7/10, Batch 110/145, Loss: 0.2891
Epoch 7/10, Batch 120/145, Loss: 0.2880
Epoch 7/10, Batch 130/145, Loss: 0.2389
Epoch 7/10, Batch 140/145, Loss: 0.1052
Epoch 7/10, Train Loss: 0.2173, Valid Loss: 0.2351
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2732
Epoch 8/10, Batch 20/145, Loss: 0.1417
Epoch 8/10, Batch 30/145, Loss: 0.1902
Epoch 8/10, Batch 40/145, Loss: 0.2506
Epoch 8/10, Batch 50/145, Loss: 0.1971
Epoch 8/10, Batch 60/145, Loss: 0.1983
Epoch 8/10, Batch 70/145, Loss: 0.1629
Epoch 8/10, Batch 80/145, Loss: 0.1696
Epoch 8/10, Batch 90/145, Loss: 0.1784
Epoch 8/10, Batch 100/145, Loss: 0.3602
Epoch 8/10, Batch 110/145, Loss: 0.1730
Epoch 8/10, Batch 120/145, Loss: 0.1228
Epoch 8/10, Batch 130/145, Loss: 0.1103
Epoch 8/10, Batch 140/145, Loss: 0.3587
Epoch 8/10, Train Loss: 0.2090, Valid Loss: 0.2303
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1858
Epoch 9/10, Batch 20/145, Loss: 0.2777
Epoch 9/10, Batch 30/145, Loss: 0.2331
Epoch 9/10, Batch 40/145, Loss: 0.2608
Epoch 9/10, Batch 50/145, Loss: 0.0892
Epoch 9/10, Batch 60/145, Loss: 0.1941
Epoch 9/10, Batch 70/145, Loss: 0.1527
Epoch 9/10, Batch 80/145, Loss: 0.2806
Epoch 9/10, Batch 90/145, Loss: 0.1358
Epoch 9/10, Batch 100/145, Loss: 0.2966
Epoch 9/10, Batch 110/145, Loss: 0.1144
Epoch 9/10, Batch 120/145, Loss: 0.1995
Epoch 9/10, Batch 130/145, Loss: 0.2703
Epoch 9/10, Batch 140/145, Loss: 0.1122
Epoch 9/10, Train Loss: 0.2009, Valid Loss: 0.2228
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1933
Epoch 10/10, Batch 20/145, Loss: 0.1324
Epoch 10/10, Batch 30/145, Loss: 0.0566
Epoch 10/10, Batch 40/145, Loss: 0.1582
Epoch 10/10, Batch 50/145, Loss: 0.1934
Epoch 10/10, Batch 60/145, Loss: 0.1627
Epoch 10/10, Batch 70/145, Loss: 0.1079
Epoch 10/10, Batch 80/145, Loss: 0.3374
Epoch 10/10, Batch 90/145, Loss: 0.0976
Epoch 10/10, Batch 100/145, Loss: 0.1053
Epoch 10/10, Batch 110/145, Loss: 0.2777
Epoch 10/10, Batch 120/145, Loss: 0.1677
Epoch 10/10, Batch 130/145, Loss: 0.2887
Epoch 10/10, Batch 140/145, Loss: 0.1526
Epoch 10/10, Train Loss: 0.1957, Valid Loss: 0.2208
Model saved!
Accuracy: 0.9252
Precision: 0.9256
Recall: 0.9252
F1-score: 0.9248
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5241
Epoch 1/10, Batch 20/145, Loss: 0.8248
Epoch 1/10, Batch 30/145, Loss: 0.9588
Epoch 1/10, Batch 40/145, Loss: 0.6733
Epoch 1/10, Batch 50/145, Loss: 0.6377
Epoch 1/10, Batch 60/145, Loss: 0.7980
Epoch 1/10, Batch 70/145, Loss: 0.6345
Epoch 1/10, Batch 80/145, Loss: 0.6127
Epoch 1/10, Batch 90/145, Loss: 0.5968
Epoch 1/10, Batch 100/145, Loss: 0.6009
Epoch 1/10, Batch 110/145, Loss: 0.3383
Epoch 1/10, Batch 120/145, Loss: 0.5772
Epoch 1/10, Batch 130/145, Loss: 0.3876
Epoch 1/10, Batch 140/145, Loss: 0.3096
Epoch 1/10, Train Loss: 0.6903, Valid Loss: 0.3903
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3932
Epoch 2/10, Batch 20/145, Loss: 0.3789
Epoch 2/10, Batch 30/145, Loss: 0.2552
Epoch 2/10, Batch 40/145, Loss: 0.6371
Epoch 2/10, Batch 50/145, Loss: 0.3713
Epoch 2/10, Batch 60/145, Loss: 0.3479
Epoch 2/10, Batch 70/145, Loss: 0.4397
Epoch 2/10, Batch 80/145, Loss: 0.3670
Epoch 2/10, Batch 90/145, Loss: 0.2716
Epoch 2/10, Batch 100/145, Loss: 0.2795
Epoch 2/10, Batch 110/145, Loss: 0.3647
Epoch 2/10, Batch 120/145, Loss: 0.3560
Epoch 2/10, Batch 130/145, Loss: 0.4006
Epoch 2/10, Batch 140/145, Loss: 0.2764
Epoch 2/10, Train Loss: 0.3693, Valid Loss: 0.3036
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2410
Epoch 3/10, Batch 20/145, Loss: 0.2275
Epoch 3/10, Batch 30/145, Loss: 0.2104
Epoch 3/10, Batch 40/145, Loss: 0.3140
Epoch 3/10, Batch 50/145, Loss: 0.1358
Epoch 3/10, Batch 60/145, Loss: 0.1660
Epoch 3/10, Batch 70/145, Loss: 0.3144
Epoch 3/10, Batch 80/145, Loss: 0.2001
Epoch 3/10, Batch 90/145, Loss: 0.6432
Epoch 3/10, Batch 100/145, Loss: 0.2957
Epoch 3/10, Batch 110/145, Loss: 0.2205
Epoch 3/10, Batch 120/145, Loss: 0.1788
Epoch 3/10, Batch 130/145, Loss: 0.1938
Epoch 3/10, Batch 140/145, Loss: 0.1607
Epoch 3/10, Train Loss: 0.3122, Valid Loss: 0.2672
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2129
Epoch 4/10, Batch 20/145, Loss: 0.2007
Epoch 4/10, Batch 30/145, Loss: 0.2968
Epoch 4/10, Batch 40/145, Loss: 0.2713
Epoch 4/10, Batch 50/145, Loss: 0.2308
Epoch 4/10, Batch 60/145, Loss: 0.1760
Epoch 4/10, Batch 70/145, Loss: 0.2156
Epoch 4/10, Batch 80/145, Loss: 0.2969
Epoch 4/10, Batch 90/145, Loss: 0.2702
Epoch 4/10, Batch 100/145, Loss: 0.2430
Epoch 4/10, Batch 110/145, Loss: 0.2400
Epoch 4/10, Batch 120/145, Loss: 0.3178
Epoch 4/10, Batch 130/145, Loss: 0.2068
Epoch 4/10, Batch 140/145, Loss: 0.1770
Epoch 4/10, Train Loss: 0.2731, Valid Loss: 0.2648
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1886
Epoch 5/10, Batch 20/145, Loss: 0.1606
Epoch 5/10, Batch 30/145, Loss: 0.2005
Epoch 5/10, Batch 40/145, Loss: 0.1556
Epoch 5/10, Batch 50/145, Loss: 0.1519
Epoch 5/10, Batch 60/145, Loss: 0.1737
Epoch 5/10, Batch 70/145, Loss: 0.2419
Epoch 5/10, Batch 80/145, Loss: 0.3054
Epoch 5/10, Batch 90/145, Loss: 0.3640
Epoch 5/10, Batch 100/145, Loss: 0.1620
Epoch 5/10, Batch 110/145, Loss: 0.1002
Epoch 5/10, Batch 120/145, Loss: 0.2200
Epoch 5/10, Batch 130/145, Loss: 0.2290
Epoch 5/10, Batch 140/145, Loss: 0.2635
Epoch 5/10, Train Loss: 0.2455, Valid Loss: 0.2424
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1966
Epoch 6/10, Batch 20/145, Loss: 0.1791
Epoch 6/10, Batch 30/145, Loss: 0.2162
Epoch 6/10, Batch 40/145, Loss: 0.1051
Epoch 6/10, Batch 50/145, Loss: 0.2362
Epoch 6/10, Batch 60/145, Loss: 0.2783
Epoch 6/10, Batch 70/145, Loss: 0.3312
Epoch 6/10, Batch 80/145, Loss: 0.2644
Epoch 6/10, Batch 90/145, Loss: 0.1017
Epoch 6/10, Batch 100/145, Loss: 0.1315
Epoch 6/10, Batch 110/145, Loss: 0.2258
Epoch 6/10, Batch 120/145, Loss: 0.2669
Epoch 6/10, Batch 130/145, Loss: 0.2000
Epoch 6/10, Batch 140/145, Loss: 0.2135
Epoch 6/10, Train Loss: 0.2296, Valid Loss: 0.2428
Epoch 7/10, Batch 10/145, Loss: 0.3030
Epoch 7/10, Batch 20/145, Loss: 0.2770
Epoch 7/10, Batch 30/145, Loss: 0.2032
Epoch 7/10, Batch 40/145, Loss: 0.5067
Epoch 7/10, Batch 50/145, Loss: 0.1786
Epoch 7/10, Batch 60/145, Loss: 0.2011
Epoch 7/10, Batch 70/145, Loss: 0.1981
Epoch 7/10, Batch 80/145, Loss: 0.0922
Epoch 7/10, Batch 90/145, Loss: 0.1772
Epoch 7/10, Batch 100/145, Loss: 0.1633
Epoch 7/10, Batch 110/145, Loss: 0.2146
Epoch 7/10, Batch 120/145, Loss: 0.2089
Epoch 7/10, Batch 130/145, Loss: 0.1688
Epoch 7/10, Batch 140/145, Loss: 0.1467
Epoch 7/10, Train Loss: 0.2224, Valid Loss: 0.2278
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1555
Epoch 8/10, Batch 20/145, Loss: 0.1255
Epoch 8/10, Batch 30/145, Loss: 0.2685
Epoch 8/10, Batch 40/145, Loss: 0.4127
Epoch 8/10, Batch 50/145, Loss: 0.2828
Epoch 8/10, Batch 60/145, Loss: 0.1820
Epoch 8/10, Batch 70/145, Loss: 0.1562
Epoch 8/10, Batch 80/145, Loss: 0.2642
Epoch 8/10, Batch 90/145, Loss: 0.1901
Epoch 8/10, Batch 100/145, Loss: 0.2850
Epoch 8/10, Batch 110/145, Loss: 0.1471
Epoch 8/10, Batch 120/145, Loss: 0.2148
Epoch 8/10, Batch 130/145, Loss: 0.1864
Epoch 8/10, Batch 140/145, Loss: 0.2130
Epoch 8/10, Train Loss: 0.2123, Valid Loss: 0.2322
Epoch 9/10, Batch 10/145, Loss: 0.2718
Epoch 9/10, Batch 20/145, Loss: 0.0974
Epoch 9/10, Batch 30/145, Loss: 0.1310
Epoch 9/10, Batch 40/145, Loss: 0.1020
Epoch 9/10, Batch 50/145, Loss: 0.2459
Epoch 9/10, Batch 60/145, Loss: 0.1108
Epoch 9/10, Batch 70/145, Loss: 0.1538
Epoch 9/10, Batch 80/145, Loss: 0.2622
Epoch 9/10, Batch 90/145, Loss: 0.1808
Epoch 9/10, Batch 100/145, Loss: 0.3529
Epoch 9/10, Batch 110/145, Loss: 0.1160
Epoch 9/10, Batch 120/145, Loss: 0.1826
Epoch 9/10, Batch 130/145, Loss: 0.1164
Epoch 9/10, Batch 140/145, Loss: 0.2358
Epoch 9/10, Train Loss: 0.2089, Valid Loss: 0.2202
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1023
Epoch 10/10, Batch 20/145, Loss: 0.2179
Epoch 10/10, Batch 30/145, Loss: 0.1212
Epoch 10/10, Batch 40/145, Loss: 0.2241
Epoch 10/10, Batch 50/145, Loss: 0.3068
Epoch 10/10, Batch 60/145, Loss: 0.3176
Epoch 10/10, Batch 70/145, Loss: 0.1194
Epoch 10/10, Batch 80/145, Loss: 0.4542
Epoch 10/10, Batch 90/145, Loss: 0.1391
Epoch 10/10, Batch 100/145, Loss: 0.1699
Epoch 10/10, Batch 110/145, Loss: 0.2208
Epoch 10/10, Batch 120/145, Loss: 0.3298
Epoch 10/10, Batch 130/145, Loss: 0.2499
Epoch 10/10, Batch 140/145, Loss: 0.1162
Epoch 10/10, Train Loss: 0.2026, Valid Loss: 0.2165
Model saved!
Accuracy: 0.9229
Precision: 0.9208
Recall: 0.9229
F1-score: 0.9213
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5174
Epoch 1/10, Batch 20/145, Loss: 0.8272
Epoch 1/10, Batch 30/145, Loss: 0.8291
Epoch 1/10, Batch 40/145, Loss: 0.8455
Epoch 1/10, Batch 50/145, Loss: 0.5619
Epoch 1/10, Batch 60/145, Loss: 0.6007
Epoch 1/10, Batch 70/145, Loss: 0.6757
Epoch 1/10, Batch 80/145, Loss: 0.4277
Epoch 1/10, Batch 90/145, Loss: 0.4552
Epoch 1/10, Batch 100/145, Loss: 0.5694
Epoch 1/10, Batch 110/145, Loss: 0.3595
Epoch 1/10, Batch 120/145, Loss: 0.5391
Epoch 1/10, Batch 130/145, Loss: 0.3532
Epoch 1/10, Batch 140/145, Loss: 0.5118
Epoch 1/10, Train Loss: 0.6888, Valid Loss: 0.3647
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3905
Epoch 2/10, Batch 20/145, Loss: 0.4932
Epoch 2/10, Batch 30/145, Loss: 0.3022
Epoch 2/10, Batch 40/145, Loss: 0.5057
Epoch 2/10, Batch 50/145, Loss: 0.3141
Epoch 2/10, Batch 60/145, Loss: 0.4297
Epoch 2/10, Batch 70/145, Loss: 0.3923
Epoch 2/10, Batch 80/145, Loss: 0.5684
Epoch 2/10, Batch 90/145, Loss: 0.3213
Epoch 2/10, Batch 100/145, Loss: 0.3306
Epoch 2/10, Batch 110/145, Loss: 0.2835
Epoch 2/10, Batch 120/145, Loss: 0.2071
Epoch 2/10, Batch 130/145, Loss: 0.4265
Epoch 2/10, Batch 140/145, Loss: 0.2973
Epoch 2/10, Train Loss: 0.3648, Valid Loss: 0.2775
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2454
Epoch 3/10, Batch 20/145, Loss: 0.2589
Epoch 3/10, Batch 30/145, Loss: 0.2002
Epoch 3/10, Batch 40/145, Loss: 0.3305
Epoch 3/10, Batch 50/145, Loss: 0.2190
Epoch 3/10, Batch 60/145, Loss: 0.2692
Epoch 3/10, Batch 70/145, Loss: 0.1841
Epoch 3/10, Batch 80/145, Loss: 0.2453
Epoch 3/10, Batch 90/145, Loss: 0.3875
Epoch 3/10, Batch 100/145, Loss: 0.3449
Epoch 3/10, Batch 110/145, Loss: 0.4291
Epoch 3/10, Batch 120/145, Loss: 0.2349
Epoch 3/10, Batch 130/145, Loss: 0.2376
Epoch 3/10, Batch 140/145, Loss: 0.1186
Epoch 3/10, Train Loss: 0.3047, Valid Loss: 0.2517
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2577
Epoch 4/10, Batch 20/145, Loss: 0.2780
Epoch 4/10, Batch 30/145, Loss: 0.3046
Epoch 4/10, Batch 40/145, Loss: 0.3957
Epoch 4/10, Batch 50/145, Loss: 0.1497
Epoch 4/10, Batch 60/145, Loss: 0.3255
Epoch 4/10, Batch 70/145, Loss: 0.1342
Epoch 4/10, Batch 80/145, Loss: 0.2288
Epoch 4/10, Batch 90/145, Loss: 0.2585
Epoch 4/10, Batch 100/145, Loss: 0.1866
Epoch 4/10, Batch 110/145, Loss: 0.1491
Epoch 4/10, Batch 120/145, Loss: 0.1775
Epoch 4/10, Batch 130/145, Loss: 0.1591
Epoch 4/10, Batch 140/145, Loss: 0.3373
Epoch 4/10, Train Loss: 0.2663, Valid Loss: 0.2315
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2122
Epoch 5/10, Batch 20/145, Loss: 0.3408
Epoch 5/10, Batch 30/145, Loss: 0.1552
Epoch 5/10, Batch 40/145, Loss: 0.2417
Epoch 5/10, Batch 50/145, Loss: 0.1489
Epoch 5/10, Batch 60/145, Loss: 0.2035
Epoch 5/10, Batch 70/145, Loss: 0.2603
Epoch 5/10, Batch 80/145, Loss: 0.2688
Epoch 5/10, Batch 90/145, Loss: 0.1112
Epoch 5/10, Batch 100/145, Loss: 0.2080
Epoch 5/10, Batch 110/145, Loss: 0.1268
Epoch 5/10, Batch 120/145, Loss: 0.2092
Epoch 5/10, Batch 130/145, Loss: 0.2149
Epoch 5/10, Batch 140/145, Loss: 0.2057
Epoch 5/10, Train Loss: 0.2442, Valid Loss: 0.2181
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2061
Epoch 6/10, Batch 20/145, Loss: 0.2347
Epoch 6/10, Batch 30/145, Loss: 0.2279
Epoch 6/10, Batch 40/145, Loss: 0.1624
Epoch 6/10, Batch 50/145, Loss: 0.5693
Epoch 6/10, Batch 60/145, Loss: 0.1995
Epoch 6/10, Batch 70/145, Loss: 0.2372
Epoch 6/10, Batch 80/145, Loss: 0.3308
Epoch 6/10, Batch 90/145, Loss: 0.1787
Epoch 6/10, Batch 100/145, Loss: 0.1844
Epoch 6/10, Batch 110/145, Loss: 0.1119
Epoch 6/10, Batch 120/145, Loss: 0.1871
Epoch 6/10, Batch 130/145, Loss: 0.1810
Epoch 6/10, Batch 140/145, Loss: 0.2760
Epoch 6/10, Train Loss: 0.2284, Valid Loss: 0.2166
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1946
Epoch 7/10, Batch 20/145, Loss: 0.3309
Epoch 7/10, Batch 30/145, Loss: 0.1580
Epoch 7/10, Batch 40/145, Loss: 0.4810
Epoch 7/10, Batch 50/145, Loss: 0.1836
Epoch 7/10, Batch 60/145, Loss: 0.1074
Epoch 7/10, Batch 70/145, Loss: 0.2837
Epoch 7/10, Batch 80/145, Loss: 0.1338
Epoch 7/10, Batch 90/145, Loss: 0.3024
Epoch 7/10, Batch 100/145, Loss: 0.1896
Epoch 7/10, Batch 110/145, Loss: 0.2079
Epoch 7/10, Batch 120/145, Loss: 0.2307
Epoch 7/10, Batch 130/145, Loss: 0.2147
Epoch 7/10, Batch 140/145, Loss: 0.1776
Epoch 7/10, Train Loss: 0.2138, Valid Loss: 0.2022
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1020
Epoch 8/10, Batch 20/145, Loss: 0.1020
Epoch 8/10, Batch 30/145, Loss: 0.1414
Epoch 8/10, Batch 40/145, Loss: 0.2434
Epoch 8/10, Batch 50/145, Loss: 0.2746
Epoch 8/10, Batch 60/145, Loss: 0.1914
Epoch 8/10, Batch 70/145, Loss: 0.1223
Epoch 8/10, Batch 80/145, Loss: 0.1348
Epoch 8/10, Batch 90/145, Loss: 0.1164
Epoch 8/10, Batch 100/145, Loss: 0.1517
Epoch 8/10, Batch 110/145, Loss: 0.3658
Epoch 8/10, Batch 120/145, Loss: 0.0840
Epoch 8/10, Batch 130/145, Loss: 0.1233
Epoch 8/10, Batch 140/145, Loss: 0.2272
Epoch 8/10, Train Loss: 0.2085, Valid Loss: 0.2105
Epoch 9/10, Batch 10/145, Loss: 0.0982
Epoch 9/10, Batch 20/145, Loss: 0.1389
Epoch 9/10, Batch 30/145, Loss: 0.0905
Epoch 9/10, Batch 40/145, Loss: 0.1417
Epoch 9/10, Batch 50/145, Loss: 0.2001
Epoch 9/10, Batch 60/145, Loss: 0.2571
Epoch 9/10, Batch 70/145, Loss: 0.2049
Epoch 9/10, Batch 80/145, Loss: 0.1987
Epoch 9/10, Batch 90/145, Loss: 0.2160
Epoch 9/10, Batch 100/145, Loss: 0.1524
Epoch 9/10, Batch 110/145, Loss: 0.1033
Epoch 9/10, Batch 120/145, Loss: 0.1331
Epoch 9/10, Batch 130/145, Loss: 0.4185
Epoch 9/10, Batch 140/145, Loss: 0.0865
Epoch 9/10, Train Loss: 0.2092, Valid Loss: 0.1896
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1455
Epoch 10/10, Batch 20/145, Loss: 0.1087
Epoch 10/10, Batch 30/145, Loss: 0.0988
Epoch 10/10, Batch 40/145, Loss: 0.2964
Epoch 10/10, Batch 50/145, Loss: 0.1767
Epoch 10/10, Batch 60/145, Loss: 0.1301
Epoch 10/10, Batch 70/145, Loss: 0.1113
Epoch 10/10, Batch 80/145, Loss: 0.3435
Epoch 10/10, Batch 90/145, Loss: 0.2676
Epoch 10/10, Batch 100/145, Loss: 0.1073
Epoch 10/10, Batch 110/145, Loss: 0.3061
Epoch 10/10, Batch 120/145, Loss: 0.3150
Epoch 10/10, Batch 130/145, Loss: 0.1899
Epoch 10/10, Batch 140/145, Loss: 0.1007
Epoch 10/10, Train Loss: 0.1907, Valid Loss: 0.1963
Accuracy: 0.9217
Precision: 0.9213
Recall: 0.9217
F1-score: 0.9204
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4795
Epoch 1/10, Batch 20/145, Loss: 0.8327
Epoch 1/10, Batch 30/145, Loss: 0.8083
Epoch 1/10, Batch 40/145, Loss: 0.7673
Epoch 1/10, Batch 50/145, Loss: 0.7030
Epoch 1/10, Batch 60/145, Loss: 0.4327
Epoch 1/10, Batch 70/145, Loss: 0.7197
Epoch 1/10, Batch 80/145, Loss: 0.5935
Epoch 1/10, Batch 90/145, Loss: 0.5112
Epoch 1/10, Batch 100/145, Loss: 0.6374
Epoch 1/10, Batch 110/145, Loss: 0.4501
Epoch 1/10, Batch 120/145, Loss: 0.5751
Epoch 1/10, Batch 130/145, Loss: 0.3103
Epoch 1/10, Batch 140/145, Loss: 0.4244
Epoch 1/10, Train Loss: 0.6972, Valid Loss: 0.3478
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2996
Epoch 2/10, Batch 20/145, Loss: 0.4599
Epoch 2/10, Batch 30/145, Loss: 0.4034
Epoch 2/10, Batch 40/145, Loss: 0.4758
Epoch 2/10, Batch 50/145, Loss: 0.3405
Epoch 2/10, Batch 60/145, Loss: 0.4293
Epoch 2/10, Batch 70/145, Loss: 0.4844
Epoch 2/10, Batch 80/145, Loss: 0.3185
Epoch 2/10, Batch 90/145, Loss: 0.3241
Epoch 2/10, Batch 100/145, Loss: 0.1876
Epoch 2/10, Batch 110/145, Loss: 0.2377
Epoch 2/10, Batch 120/145, Loss: 0.4347
Epoch 2/10, Batch 130/145, Loss: 0.2907
Epoch 2/10, Batch 140/145, Loss: 0.2430
Epoch 2/10, Train Loss: 0.3753, Valid Loss: 0.2580
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2544
Epoch 3/10, Batch 20/145, Loss: 0.4105
Epoch 3/10, Batch 30/145, Loss: 0.3698
Epoch 3/10, Batch 40/145, Loss: 0.2572
Epoch 3/10, Batch 50/145, Loss: 0.1639
Epoch 3/10, Batch 60/145, Loss: 0.3119
Epoch 3/10, Batch 70/145, Loss: 0.2497
Epoch 3/10, Batch 80/145, Loss: 0.2382
Epoch 3/10, Batch 90/145, Loss: 0.4354
Epoch 3/10, Batch 100/145, Loss: 0.2024
Epoch 3/10, Batch 110/145, Loss: 0.2725
Epoch 3/10, Batch 120/145, Loss: 0.4848
Epoch 3/10, Batch 130/145, Loss: 0.2280
Epoch 3/10, Batch 140/145, Loss: 0.1907
Epoch 3/10, Train Loss: 0.3128, Valid Loss: 0.2264
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2374
Epoch 4/10, Batch 20/145, Loss: 0.3884
Epoch 4/10, Batch 30/145, Loss: 0.2276
Epoch 4/10, Batch 40/145, Loss: 0.4413
Epoch 4/10, Batch 50/145, Loss: 0.2960
Epoch 4/10, Batch 60/145, Loss: 0.2612
Epoch 4/10, Batch 70/145, Loss: 0.1383
Epoch 4/10, Batch 80/145, Loss: 0.2630
Epoch 4/10, Batch 90/145, Loss: 0.1900
Epoch 4/10, Batch 100/145, Loss: 0.2546
Epoch 4/10, Batch 110/145, Loss: 0.2597
Epoch 4/10, Batch 120/145, Loss: 0.1660
Epoch 4/10, Batch 130/145, Loss: 0.3144
Epoch 4/10, Batch 140/145, Loss: 0.2256
Epoch 4/10, Train Loss: 0.2716, Valid Loss: 0.2185
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2195
Epoch 5/10, Batch 20/145, Loss: 0.2257
Epoch 5/10, Batch 30/145, Loss: 0.1272
Epoch 5/10, Batch 40/145, Loss: 0.3753
Epoch 5/10, Batch 50/145, Loss: 0.1932
Epoch 5/10, Batch 60/145, Loss: 0.2380
Epoch 5/10, Batch 70/145, Loss: 0.3281
Epoch 5/10, Batch 80/145, Loss: 0.3385
Epoch 5/10, Batch 90/145, Loss: 0.3202
Epoch 5/10, Batch 100/145, Loss: 0.2603
Epoch 5/10, Batch 110/145, Loss: 0.0755
Epoch 5/10, Batch 120/145, Loss: 0.2219
Epoch 5/10, Batch 130/145, Loss: 0.1943
Epoch 5/10, Batch 140/145, Loss: 0.1453
Epoch 5/10, Train Loss: 0.2500, Valid Loss: 0.2040
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2252
Epoch 6/10, Batch 20/145, Loss: 0.2150
Epoch 6/10, Batch 30/145, Loss: 0.4026
Epoch 6/10, Batch 40/145, Loss: 0.3052
Epoch 6/10, Batch 50/145, Loss: 0.2121
Epoch 6/10, Batch 60/145, Loss: 0.2968
Epoch 6/10, Batch 70/145, Loss: 0.1886
Epoch 6/10, Batch 80/145, Loss: 0.1738
Epoch 6/10, Batch 90/145, Loss: 0.3238
Epoch 6/10, Batch 100/145, Loss: 0.2478
Epoch 6/10, Batch 110/145, Loss: 0.1175
Epoch 6/10, Batch 120/145, Loss: 0.2344
Epoch 6/10, Batch 130/145, Loss: 0.1495
Epoch 6/10, Batch 140/145, Loss: 0.2388
Epoch 6/10, Train Loss: 0.2327, Valid Loss: 0.2026
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3459
Epoch 7/10, Batch 20/145, Loss: 0.2655
Epoch 7/10, Batch 30/145, Loss: 0.1054
Epoch 7/10, Batch 40/145, Loss: 0.3232
Epoch 7/10, Batch 50/145, Loss: 0.2022
Epoch 7/10, Batch 60/145, Loss: 0.1875
Epoch 7/10, Batch 70/145, Loss: 0.2049
Epoch 7/10, Batch 80/145, Loss: 0.0703
Epoch 7/10, Batch 90/145, Loss: 0.3822
Epoch 7/10, Batch 100/145, Loss: 0.1639
Epoch 7/10, Batch 110/145, Loss: 0.3579
Epoch 7/10, Batch 120/145, Loss: 0.1909
Epoch 7/10, Batch 130/145, Loss: 0.1891
Epoch 7/10, Batch 140/145, Loss: 0.1512
Epoch 7/10, Train Loss: 0.2225, Valid Loss: 0.1941
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2071
Epoch 8/10, Batch 20/145, Loss: 0.1939
Epoch 8/10, Batch 30/145, Loss: 0.1797
Epoch 8/10, Batch 40/145, Loss: 0.1659
Epoch 8/10, Batch 50/145, Loss: 0.1683
Epoch 8/10, Batch 60/145, Loss: 0.1347
Epoch 8/10, Batch 70/145, Loss: 0.1828
Epoch 8/10, Batch 80/145, Loss: 0.3146
Epoch 8/10, Batch 90/145, Loss: 0.1276
Epoch 8/10, Batch 100/145, Loss: 0.1305
Epoch 8/10, Batch 110/145, Loss: 0.2449
Epoch 8/10, Batch 120/145, Loss: 0.0801
Epoch 8/10, Batch 130/145, Loss: 0.2374
Epoch 8/10, Batch 140/145, Loss: 0.2264
Epoch 8/10, Train Loss: 0.2178, Valid Loss: 0.1916
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1579
Epoch 9/10, Batch 20/145, Loss: 0.0864
Epoch 9/10, Batch 30/145, Loss: 0.0927
Epoch 9/10, Batch 40/145, Loss: 0.3063
Epoch 9/10, Batch 50/145, Loss: 0.2967
Epoch 9/10, Batch 60/145, Loss: 0.1578
Epoch 9/10, Batch 70/145, Loss: 0.3826
Epoch 9/10, Batch 80/145, Loss: 0.3927
Epoch 9/10, Batch 90/145, Loss: 0.1933
Epoch 9/10, Batch 100/145, Loss: 0.1624
Epoch 9/10, Batch 110/145, Loss: 0.0848
Epoch 9/10, Batch 120/145, Loss: 0.2143
Epoch 9/10, Batch 130/145, Loss: 0.2250
Epoch 9/10, Batch 140/145, Loss: 0.2428
Epoch 9/10, Train Loss: 0.2097, Valid Loss: 0.1811
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1494
Epoch 10/10, Batch 20/145, Loss: 0.0982
Epoch 10/10, Batch 30/145, Loss: 0.0705
Epoch 10/10, Batch 40/145, Loss: 0.1284
Epoch 10/10, Batch 50/145, Loss: 0.2224
Epoch 10/10, Batch 60/145, Loss: 0.1292
Epoch 10/10, Batch 70/145, Loss: 0.1420
Epoch 10/10, Batch 80/145, Loss: 0.3686
Epoch 10/10, Batch 90/145, Loss: 0.3138
Epoch 10/10, Batch 100/145, Loss: 0.2404
Epoch 10/10, Batch 110/145, Loss: 0.3075
Epoch 10/10, Batch 120/145, Loss: 0.1848
Epoch 10/10, Batch 130/145, Loss: 0.2492
Epoch 10/10, Batch 140/145, Loss: 0.3624
Epoch 10/10, Train Loss: 0.2046, Valid Loss: 0.1810
Model saved!
Accuracy: 0.9217
Precision: 0.9196
Recall: 0.9217
F1-score: 0.9203
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4544
Epoch 1/10, Batch 20/145, Loss: 0.9517
Epoch 1/10, Batch 30/145, Loss: 0.9490
Epoch 1/10, Batch 40/145, Loss: 0.7741
Epoch 1/10, Batch 50/145, Loss: 0.7183
Epoch 1/10, Batch 60/145, Loss: 0.4882
Epoch 1/10, Batch 70/145, Loss: 0.5854
Epoch 1/10, Batch 80/145, Loss: 0.5546
Epoch 1/10, Batch 90/145, Loss: 0.6556
Epoch 1/10, Batch 100/145, Loss: 0.5787
Epoch 1/10, Batch 110/145, Loss: 0.4370
Epoch 1/10, Batch 120/145, Loss: 0.6141
Epoch 1/10, Batch 130/145, Loss: 0.3425
Epoch 1/10, Batch 140/145, Loss: 0.4691
Epoch 1/10, Train Loss: 0.6875, Valid Loss: 0.3797
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2677
Epoch 2/10, Batch 20/145, Loss: 0.5967
Epoch 2/10, Batch 30/145, Loss: 0.2581
Epoch 2/10, Batch 40/145, Loss: 0.4430
Epoch 2/10, Batch 50/145, Loss: 0.2963
Epoch 2/10, Batch 60/145, Loss: 0.4801
Epoch 2/10, Batch 70/145, Loss: 0.6054
Epoch 2/10, Batch 80/145, Loss: 0.4544
Epoch 2/10, Batch 90/145, Loss: 0.3155
Epoch 2/10, Batch 100/145, Loss: 0.3866
Epoch 2/10, Batch 110/145, Loss: 0.2388
Epoch 2/10, Batch 120/145, Loss: 0.4053
Epoch 2/10, Batch 130/145, Loss: 0.4976
Epoch 2/10, Batch 140/145, Loss: 0.3040
Epoch 2/10, Train Loss: 0.3605, Valid Loss: 0.2996
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2208
Epoch 3/10, Batch 20/145, Loss: 0.3889
Epoch 3/10, Batch 30/145, Loss: 0.3054
Epoch 3/10, Batch 40/145, Loss: 0.2753
Epoch 3/10, Batch 50/145, Loss: 0.1810
Epoch 3/10, Batch 60/145, Loss: 0.4482
Epoch 3/10, Batch 70/145, Loss: 0.2543
Epoch 3/10, Batch 80/145, Loss: 0.2446
Epoch 3/10, Batch 90/145, Loss: 0.4475
Epoch 3/10, Batch 100/145, Loss: 0.5193
Epoch 3/10, Batch 110/145, Loss: 0.3049
Epoch 3/10, Batch 120/145, Loss: 0.1425
Epoch 3/10, Batch 130/145, Loss: 0.2554
Epoch 3/10, Batch 140/145, Loss: 0.3160
Epoch 3/10, Train Loss: 0.3148, Valid Loss: 0.2721
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2413
Epoch 4/10, Batch 20/145, Loss: 0.3247
Epoch 4/10, Batch 30/145, Loss: 0.4397
Epoch 4/10, Batch 40/145, Loss: 0.4664
Epoch 4/10, Batch 50/145, Loss: 0.1988
Epoch 4/10, Batch 60/145, Loss: 0.1248
Epoch 4/10, Batch 70/145, Loss: 0.2441
Epoch 4/10, Batch 80/145, Loss: 0.2130
Epoch 4/10, Batch 90/145, Loss: 0.2801
Epoch 4/10, Batch 100/145, Loss: 0.2193
Epoch 4/10, Batch 110/145, Loss: 0.2610
Epoch 4/10, Batch 120/145, Loss: 0.1506
Epoch 4/10, Batch 130/145, Loss: 0.1429
Epoch 4/10, Batch 140/145, Loss: 0.2276
Epoch 4/10, Train Loss: 0.2646, Valid Loss: 0.2612
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2754
Epoch 5/10, Batch 20/145, Loss: 0.4635
Epoch 5/10, Batch 30/145, Loss: 0.1666
Epoch 5/10, Batch 40/145, Loss: 0.3001
Epoch 5/10, Batch 50/145, Loss: 0.1975
Epoch 5/10, Batch 60/145, Loss: 0.2134
Epoch 5/10, Batch 70/145, Loss: 0.5008
Epoch 5/10, Batch 80/145, Loss: 0.3077
Epoch 5/10, Batch 90/145, Loss: 0.2002
Epoch 5/10, Batch 100/145, Loss: 0.4123
Epoch 5/10, Batch 110/145, Loss: 0.1076
Epoch 5/10, Batch 120/145, Loss: 0.1724
Epoch 5/10, Batch 130/145, Loss: 0.3140
Epoch 5/10, Batch 140/145, Loss: 0.4564
Epoch 5/10, Train Loss: 0.2370, Valid Loss: 0.2518
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3279
Epoch 6/10, Batch 20/145, Loss: 0.3004
Epoch 6/10, Batch 30/145, Loss: 0.2235
Epoch 6/10, Batch 40/145, Loss: 0.2150
Epoch 6/10, Batch 50/145, Loss: 0.3671
Epoch 6/10, Batch 60/145, Loss: 0.2140
Epoch 6/10, Batch 70/145, Loss: 0.2525
Epoch 6/10, Batch 80/145, Loss: 0.2650
Epoch 6/10, Batch 90/145, Loss: 0.2258
Epoch 6/10, Batch 100/145, Loss: 0.1988
Epoch 6/10, Batch 110/145, Loss: 0.2906
Epoch 6/10, Batch 120/145, Loss: 0.3032
Epoch 6/10, Batch 130/145, Loss: 0.0789
Epoch 6/10, Batch 140/145, Loss: 0.1810
Epoch 6/10, Train Loss: 0.2295, Valid Loss: 0.2502
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.6091
Epoch 7/10, Batch 20/145, Loss: 0.2123
Epoch 7/10, Batch 30/145, Loss: 0.1989
Epoch 7/10, Batch 40/145, Loss: 0.5814
Epoch 7/10, Batch 50/145, Loss: 0.1778
Epoch 7/10, Batch 60/145, Loss: 0.0920
Epoch 7/10, Batch 70/145, Loss: 0.2167
Epoch 7/10, Batch 80/145, Loss: 0.1884
Epoch 7/10, Batch 90/145, Loss: 0.2399
Epoch 7/10, Batch 100/145, Loss: 0.2887
Epoch 7/10, Batch 110/145, Loss: 0.2639
Epoch 7/10, Batch 120/145, Loss: 0.1402
Epoch 7/10, Batch 130/145, Loss: 0.2322
Epoch 7/10, Batch 140/145, Loss: 0.1231
Epoch 7/10, Train Loss: 0.2206, Valid Loss: 0.2379
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1938
Epoch 8/10, Batch 20/145, Loss: 0.1695
Epoch 8/10, Batch 30/145, Loss: 0.1031
Epoch 8/10, Batch 40/145, Loss: 0.2659
Epoch 8/10, Batch 50/145, Loss: 0.0920
Epoch 8/10, Batch 60/145, Loss: 0.2069
Epoch 8/10, Batch 70/145, Loss: 0.2578
Epoch 8/10, Batch 80/145, Loss: 0.1653
Epoch 8/10, Batch 90/145, Loss: 0.1336
Epoch 8/10, Batch 100/145, Loss: 0.2019
Epoch 8/10, Batch 110/145, Loss: 0.1893
Epoch 8/10, Batch 120/145, Loss: 0.4005
Epoch 8/10, Batch 130/145, Loss: 0.1009
Epoch 8/10, Batch 140/145, Loss: 0.2879
Epoch 8/10, Train Loss: 0.2134, Valid Loss: 0.2360
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1861
Epoch 9/10, Batch 20/145, Loss: 0.0983
Epoch 9/10, Batch 30/145, Loss: 0.2831
Epoch 9/10, Batch 40/145, Loss: 0.1519
Epoch 9/10, Batch 50/145, Loss: 0.1467
Epoch 9/10, Batch 60/145, Loss: 0.0940
Epoch 9/10, Batch 70/145, Loss: 0.2307
Epoch 9/10, Batch 80/145, Loss: 0.2805
Epoch 9/10, Batch 90/145, Loss: 0.3314
Epoch 9/10, Batch 100/145, Loss: 0.2499
Epoch 9/10, Batch 110/145, Loss: 0.1999
Epoch 9/10, Batch 120/145, Loss: 0.1210
Epoch 9/10, Batch 130/145, Loss: 0.2344
Epoch 9/10, Batch 140/145, Loss: 0.0627
Epoch 9/10, Train Loss: 0.2040, Valid Loss: 0.2285
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1565
Epoch 10/10, Batch 20/145, Loss: 0.1384
Epoch 10/10, Batch 30/145, Loss: 0.0912
Epoch 10/10, Batch 40/145, Loss: 0.2230
Epoch 10/10, Batch 50/145, Loss: 0.2200
Epoch 10/10, Batch 60/145, Loss: 0.3364
Epoch 10/10, Batch 70/145, Loss: 0.2175
Epoch 10/10, Batch 80/145, Loss: 0.3298
Epoch 10/10, Batch 90/145, Loss: 0.1331
Epoch 10/10, Batch 100/145, Loss: 0.1231
Epoch 10/10, Batch 110/145, Loss: 0.1194
Epoch 10/10, Batch 120/145, Loss: 0.1415
Epoch 10/10, Batch 130/145, Loss: 0.1481
Epoch 10/10, Batch 140/145, Loss: 0.2358
Epoch 10/10, Train Loss: 0.1959, Valid Loss: 0.2288
Accuracy: 0.9182
Precision: 0.9160
Recall: 0.9182
F1-score: 0.9166
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5525
Epoch 1/10, Batch 20/145, Loss: 0.8639
Epoch 1/10, Batch 30/145, Loss: 0.9430
Epoch 1/10, Batch 40/145, Loss: 0.8110
Epoch 1/10, Batch 50/145, Loss: 0.7265
Epoch 1/10, Batch 60/145, Loss: 0.5652
Epoch 1/10, Batch 70/145, Loss: 0.6246
Epoch 1/10, Batch 80/145, Loss: 0.4790
Epoch 1/10, Batch 90/145, Loss: 0.6848
Epoch 1/10, Batch 100/145, Loss: 0.6006
Epoch 1/10, Batch 110/145, Loss: 0.3611
Epoch 1/10, Batch 120/145, Loss: 0.6731
Epoch 1/10, Batch 130/145, Loss: 0.4390
Epoch 1/10, Batch 140/145, Loss: 0.5326
Epoch 1/10, Train Loss: 0.6797, Valid Loss: 0.3842
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3022
Epoch 2/10, Batch 20/145, Loss: 0.5704
Epoch 2/10, Batch 30/145, Loss: 0.2330
Epoch 2/10, Batch 40/145, Loss: 0.4536
Epoch 2/10, Batch 50/145, Loss: 0.3045
Epoch 2/10, Batch 60/145, Loss: 0.4520
Epoch 2/10, Batch 70/145, Loss: 0.3164
Epoch 2/10, Batch 80/145, Loss: 0.2445
Epoch 2/10, Batch 90/145, Loss: 0.3029
Epoch 2/10, Batch 100/145, Loss: 0.2247
Epoch 2/10, Batch 110/145, Loss: 0.2317
Epoch 2/10, Batch 120/145, Loss: 0.4339
Epoch 2/10, Batch 130/145, Loss: 0.3340
Epoch 2/10, Batch 140/145, Loss: 0.3014
Epoch 2/10, Train Loss: 0.3581, Valid Loss: 0.2967
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2916
Epoch 3/10, Batch 20/145, Loss: 0.3273
Epoch 3/10, Batch 30/145, Loss: 0.3647
Epoch 3/10, Batch 40/145, Loss: 0.3436
Epoch 3/10, Batch 50/145, Loss: 0.3478
Epoch 3/10, Batch 60/145, Loss: 0.2750
Epoch 3/10, Batch 70/145, Loss: 0.2596
Epoch 3/10, Batch 80/145, Loss: 0.2368
Epoch 3/10, Batch 90/145, Loss: 0.5969
Epoch 3/10, Batch 100/145, Loss: 0.1667
Epoch 3/10, Batch 110/145, Loss: 0.2873
Epoch 3/10, Batch 120/145, Loss: 0.3288
Epoch 3/10, Batch 130/145, Loss: 0.3460
Epoch 3/10, Batch 140/145, Loss: 0.2527
Epoch 3/10, Train Loss: 0.3000, Valid Loss: 0.2749
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2303
Epoch 4/10, Batch 20/145, Loss: 0.1362
Epoch 4/10, Batch 30/145, Loss: 0.1953
Epoch 4/10, Batch 40/145, Loss: 0.3574
Epoch 4/10, Batch 50/145, Loss: 0.1443
Epoch 4/10, Batch 60/145, Loss: 0.2512
Epoch 4/10, Batch 70/145, Loss: 0.1930
Epoch 4/10, Batch 80/145, Loss: 0.3481
Epoch 4/10, Batch 90/145, Loss: 0.2410
Epoch 4/10, Batch 100/145, Loss: 0.3277
Epoch 4/10, Batch 110/145, Loss: 0.2851
Epoch 4/10, Batch 120/145, Loss: 0.2276
Epoch 4/10, Batch 130/145, Loss: 0.2199
Epoch 4/10, Batch 140/145, Loss: 0.2680
Epoch 4/10, Train Loss: 0.2605, Valid Loss: 0.2555
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3172
Epoch 5/10, Batch 20/145, Loss: 0.0899
Epoch 5/10, Batch 30/145, Loss: 0.1707
Epoch 5/10, Batch 40/145, Loss: 0.1231
Epoch 5/10, Batch 50/145, Loss: 0.2010
Epoch 5/10, Batch 60/145, Loss: 0.2478
Epoch 5/10, Batch 70/145, Loss: 0.3978
Epoch 5/10, Batch 80/145, Loss: 0.3423
Epoch 5/10, Batch 90/145, Loss: 0.1146
Epoch 5/10, Batch 100/145, Loss: 0.1627
Epoch 5/10, Batch 110/145, Loss: 0.1110
Epoch 5/10, Batch 120/145, Loss: 0.1873
Epoch 5/10, Batch 130/145, Loss: 0.1927
Epoch 5/10, Batch 140/145, Loss: 0.2830
Epoch 5/10, Train Loss: 0.2376, Valid Loss: 0.2489
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2271
Epoch 6/10, Batch 20/145, Loss: 0.2612
Epoch 6/10, Batch 30/145, Loss: 0.2000
Epoch 6/10, Batch 40/145, Loss: 0.1765
Epoch 6/10, Batch 50/145, Loss: 0.2434
Epoch 6/10, Batch 60/145, Loss: 0.1784
Epoch 6/10, Batch 70/145, Loss: 0.3516
Epoch 6/10, Batch 80/145, Loss: 0.4702
Epoch 6/10, Batch 90/145, Loss: 0.1508
Epoch 6/10, Batch 100/145, Loss: 0.2249
Epoch 6/10, Batch 110/145, Loss: 0.4092
Epoch 6/10, Batch 120/145, Loss: 0.1840
Epoch 6/10, Batch 130/145, Loss: 0.1911
Epoch 6/10, Batch 140/145, Loss: 0.2218
Epoch 6/10, Train Loss: 0.2279, Valid Loss: 0.2369
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1822
Epoch 7/10, Batch 20/145, Loss: 0.2649
Epoch 7/10, Batch 30/145, Loss: 0.0655
Epoch 7/10, Batch 40/145, Loss: 0.4886
Epoch 7/10, Batch 50/145, Loss: 0.1786
Epoch 7/10, Batch 60/145, Loss: 0.1290
Epoch 7/10, Batch 70/145, Loss: 0.3891
Epoch 7/10, Batch 80/145, Loss: 0.1992
Epoch 7/10, Batch 90/145, Loss: 0.2503
Epoch 7/10, Batch 100/145, Loss: 0.2771
Epoch 7/10, Batch 110/145, Loss: 0.2230
Epoch 7/10, Batch 120/145, Loss: 0.2071
Epoch 7/10, Batch 130/145, Loss: 0.1429
Epoch 7/10, Batch 140/145, Loss: 0.0841
Epoch 7/10, Train Loss: 0.2095, Valid Loss: 0.2249
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1532
Epoch 8/10, Batch 20/145, Loss: 0.3001
Epoch 8/10, Batch 30/145, Loss: 0.1767
Epoch 8/10, Batch 40/145, Loss: 0.1878
Epoch 8/10, Batch 50/145, Loss: 0.1408
Epoch 8/10, Batch 60/145, Loss: 0.3323
Epoch 8/10, Batch 70/145, Loss: 0.0599
Epoch 8/10, Batch 80/145, Loss: 0.1214
Epoch 8/10, Batch 90/145, Loss: 0.2484
Epoch 8/10, Batch 100/145, Loss: 0.1677
Epoch 8/10, Batch 110/145, Loss: 0.2026
Epoch 8/10, Batch 120/145, Loss: 0.1357
Epoch 8/10, Batch 130/145, Loss: 0.3104
Epoch 8/10, Batch 140/145, Loss: 0.1735
Epoch 8/10, Train Loss: 0.2088, Valid Loss: 0.2217
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2326
Epoch 9/10, Batch 20/145, Loss: 0.0818
Epoch 9/10, Batch 30/145, Loss: 0.2378
Epoch 9/10, Batch 40/145, Loss: 0.2311
Epoch 9/10, Batch 50/145, Loss: 0.1552
Epoch 9/10, Batch 60/145, Loss: 0.1611
Epoch 9/10, Batch 70/145, Loss: 0.0863
Epoch 9/10, Batch 80/145, Loss: 0.1399
Epoch 9/10, Batch 90/145, Loss: 0.1038
Epoch 9/10, Batch 100/145, Loss: 0.2192
Epoch 9/10, Batch 110/145, Loss: 0.2187
Epoch 9/10, Batch 120/145, Loss: 0.2401
Epoch 9/10, Batch 130/145, Loss: 0.1970
Epoch 9/10, Batch 140/145, Loss: 0.1049
Epoch 9/10, Train Loss: 0.2004, Valid Loss: 0.2175
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0671
Epoch 10/10, Batch 20/145, Loss: 0.1539
Epoch 10/10, Batch 30/145, Loss: 0.1524
Epoch 10/10, Batch 40/145, Loss: 0.1855
Epoch 10/10, Batch 50/145, Loss: 0.1428
Epoch 10/10, Batch 60/145, Loss: 0.2318
Epoch 10/10, Batch 70/145, Loss: 0.0634
Epoch 10/10, Batch 80/145, Loss: 0.4757
Epoch 10/10, Batch 90/145, Loss: 0.1496
Epoch 10/10, Batch 100/145, Loss: 0.1055
Epoch 10/10, Batch 110/145, Loss: 0.3835
Epoch 10/10, Batch 120/145, Loss: 0.1783
Epoch 10/10, Batch 130/145, Loss: 0.2756
Epoch 10/10, Batch 140/145, Loss: 0.1826
Epoch 10/10, Train Loss: 0.1913, Valid Loss: 0.2159
Model saved!
Accuracy: 0.9159
Precision: 0.9141
Recall: 0.9159
F1-score: 0.9147
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5675
Epoch 1/10, Batch 20/145, Loss: 0.8733
Epoch 1/10, Batch 30/145, Loss: 0.8900
Epoch 1/10, Batch 40/145, Loss: 0.7831
Epoch 1/10, Batch 50/145, Loss: 0.5752
Epoch 1/10, Batch 60/145, Loss: 0.6314
Epoch 1/10, Batch 70/145, Loss: 0.7581
Epoch 1/10, Batch 80/145, Loss: 0.4536
Epoch 1/10, Batch 90/145, Loss: 0.7381
Epoch 1/10, Batch 100/145, Loss: 0.4519
Epoch 1/10, Batch 110/145, Loss: 0.4207
Epoch 1/10, Batch 120/145, Loss: 0.6113
Epoch 1/10, Batch 130/145, Loss: 0.2987
Epoch 1/10, Batch 140/145, Loss: 0.4479
Epoch 1/10, Train Loss: 0.6799, Valid Loss: 0.3842
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2365
Epoch 2/10, Batch 20/145, Loss: 0.4134
Epoch 2/10, Batch 30/145, Loss: 0.3137
Epoch 2/10, Batch 40/145, Loss: 0.4880
Epoch 2/10, Batch 50/145, Loss: 0.2592
Epoch 2/10, Batch 60/145, Loss: 0.4788
Epoch 2/10, Batch 70/145, Loss: 0.4026
Epoch 2/10, Batch 80/145, Loss: 0.3439
Epoch 2/10, Batch 90/145, Loss: 0.2742
Epoch 2/10, Batch 100/145, Loss: 0.2168
Epoch 2/10, Batch 110/145, Loss: 0.2373
Epoch 2/10, Batch 120/145, Loss: 0.4270
Epoch 2/10, Batch 130/145, Loss: 0.4121
Epoch 2/10, Batch 140/145, Loss: 0.2511
Epoch 2/10, Train Loss: 0.3552, Valid Loss: 0.3041
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2122
Epoch 3/10, Batch 20/145, Loss: 0.2771
Epoch 3/10, Batch 30/145, Loss: 0.1766
Epoch 3/10, Batch 40/145, Loss: 0.4010
Epoch 3/10, Batch 50/145, Loss: 0.2567
Epoch 3/10, Batch 60/145, Loss: 0.3306
Epoch 3/10, Batch 70/145, Loss: 0.2148
Epoch 3/10, Batch 80/145, Loss: 0.2447
Epoch 3/10, Batch 90/145, Loss: 0.5773
Epoch 3/10, Batch 100/145, Loss: 0.3500
Epoch 3/10, Batch 110/145, Loss: 0.2274
Epoch 3/10, Batch 120/145, Loss: 0.1664
Epoch 3/10, Batch 130/145, Loss: 0.1963
Epoch 3/10, Batch 140/145, Loss: 0.2429
Epoch 3/10, Train Loss: 0.2965, Valid Loss: 0.2767
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3124
Epoch 4/10, Batch 20/145, Loss: 0.3272
Epoch 4/10, Batch 30/145, Loss: 0.2195
Epoch 4/10, Batch 40/145, Loss: 0.4285
Epoch 4/10, Batch 50/145, Loss: 0.2469
Epoch 4/10, Batch 60/145, Loss: 0.2090
Epoch 4/10, Batch 70/145, Loss: 0.1416
Epoch 4/10, Batch 80/145, Loss: 0.2212
Epoch 4/10, Batch 90/145, Loss: 0.2263
Epoch 4/10, Batch 100/145, Loss: 0.1532
Epoch 4/10, Batch 110/145, Loss: 0.1031
Epoch 4/10, Batch 120/145, Loss: 0.0981
Epoch 4/10, Batch 130/145, Loss: 0.1207
Epoch 4/10, Batch 140/145, Loss: 0.3268
Epoch 4/10, Train Loss: 0.2595, Valid Loss: 0.2687
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2194
Epoch 5/10, Batch 20/145, Loss: 0.1962
Epoch 5/10, Batch 30/145, Loss: 0.2389
Epoch 5/10, Batch 40/145, Loss: 0.3335
Epoch 5/10, Batch 50/145, Loss: 0.1786
Epoch 5/10, Batch 60/145, Loss: 0.4125
Epoch 5/10, Batch 70/145, Loss: 0.3976
Epoch 5/10, Batch 80/145, Loss: 0.1655
Epoch 5/10, Batch 90/145, Loss: 0.1855
Epoch 5/10, Batch 100/145, Loss: 0.2346
Epoch 5/10, Batch 110/145, Loss: 0.0860
Epoch 5/10, Batch 120/145, Loss: 0.3585
Epoch 5/10, Batch 130/145, Loss: 0.1453
Epoch 5/10, Batch 140/145, Loss: 0.3462
Epoch 5/10, Train Loss: 0.2374, Valid Loss: 0.2584
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2185
Epoch 6/10, Batch 20/145, Loss: 0.2547
Epoch 6/10, Batch 30/145, Loss: 0.2274
Epoch 6/10, Batch 40/145, Loss: 0.2744
Epoch 6/10, Batch 50/145, Loss: 0.3137
Epoch 6/10, Batch 60/145, Loss: 0.1182
Epoch 6/10, Batch 70/145, Loss: 0.2020
Epoch 6/10, Batch 80/145, Loss: 0.1679
Epoch 6/10, Batch 90/145, Loss: 0.2427
Epoch 6/10, Batch 100/145, Loss: 0.3889
Epoch 6/10, Batch 110/145, Loss: 0.0881
Epoch 6/10, Batch 120/145, Loss: 0.1867
Epoch 6/10, Batch 130/145, Loss: 0.2028
Epoch 6/10, Batch 140/145, Loss: 0.1747
Epoch 6/10, Train Loss: 0.2223, Valid Loss: 0.2594
Epoch 7/10, Batch 10/145, Loss: 0.1684
Epoch 7/10, Batch 20/145, Loss: 0.2570
Epoch 7/10, Batch 30/145, Loss: 0.2106
Epoch 7/10, Batch 40/145, Loss: 0.2944
Epoch 7/10, Batch 50/145, Loss: 0.1551
Epoch 7/10, Batch 60/145, Loss: 0.1808
Epoch 7/10, Batch 70/145, Loss: 0.1715
Epoch 7/10, Batch 80/145, Loss: 0.1628
Epoch 7/10, Batch 90/145, Loss: 0.1788
Epoch 7/10, Batch 100/145, Loss: 0.1716
Epoch 7/10, Batch 110/145, Loss: 0.1773
Epoch 7/10, Batch 120/145, Loss: 0.1549
Epoch 7/10, Batch 130/145, Loss: 0.2711
Epoch 7/10, Batch 140/145, Loss: 0.2394
Epoch 7/10, Train Loss: 0.2165, Valid Loss: 0.2400
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1115
Epoch 8/10, Batch 20/145, Loss: 0.1256
Epoch 8/10, Batch 30/145, Loss: 0.2087
Epoch 8/10, Batch 40/145, Loss: 0.2063
Epoch 8/10, Batch 50/145, Loss: 0.2454
Epoch 8/10, Batch 60/145, Loss: 0.1282
Epoch 8/10, Batch 70/145, Loss: 0.1062
Epoch 8/10, Batch 80/145, Loss: 0.1227
Epoch 8/10, Batch 90/145, Loss: 0.1289
Epoch 8/10, Batch 100/145, Loss: 0.3120
Epoch 8/10, Batch 110/145, Loss: 0.1729
Epoch 8/10, Batch 120/145, Loss: 0.1359
Epoch 8/10, Batch 130/145, Loss: 0.1726
Epoch 8/10, Batch 140/145, Loss: 0.1682
Epoch 8/10, Train Loss: 0.1980, Valid Loss: 0.2377
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1463
Epoch 9/10, Batch 20/145, Loss: 0.1625
Epoch 9/10, Batch 30/145, Loss: 0.1476
Epoch 9/10, Batch 40/145, Loss: 0.0974
Epoch 9/10, Batch 50/145, Loss: 0.2002
Epoch 9/10, Batch 60/145, Loss: 0.2935
Epoch 9/10, Batch 70/145, Loss: 0.1636
Epoch 9/10, Batch 80/145, Loss: 0.1827
Epoch 9/10, Batch 90/145, Loss: 0.2636
Epoch 9/10, Batch 100/145, Loss: 0.1957
Epoch 9/10, Batch 110/145, Loss: 0.2017
Epoch 9/10, Batch 120/145, Loss: 0.1709
Epoch 9/10, Batch 130/145, Loss: 0.2637
Epoch 9/10, Batch 140/145, Loss: 0.1184
Epoch 9/10, Train Loss: 0.2010, Valid Loss: 0.2361
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1725
Epoch 10/10, Batch 20/145, Loss: 0.2834
Epoch 10/10, Batch 30/145, Loss: 0.1930
Epoch 10/10, Batch 40/145, Loss: 0.1958
Epoch 10/10, Batch 50/145, Loss: 0.2307
Epoch 10/10, Batch 60/145, Loss: 0.3199
Epoch 10/10, Batch 70/145, Loss: 0.1938
Epoch 10/10, Batch 80/145, Loss: 0.3307
Epoch 10/10, Batch 90/145, Loss: 0.1112
Epoch 10/10, Batch 100/145, Loss: 0.1116
Epoch 10/10, Batch 110/145, Loss: 0.2609
Epoch 10/10, Batch 120/145, Loss: 0.4246
Epoch 10/10, Batch 130/145, Loss: 0.1540
Epoch 10/10, Batch 140/145, Loss: 0.1788
Epoch 10/10, Train Loss: 0.1953, Valid Loss: 0.2320
Model saved!
Accuracy: 0.9229
Precision: 0.9210
Recall: 0.9229
F1-score: 0.9217
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5613
Epoch 1/10, Batch 20/145, Loss: 0.8637
Epoch 1/10, Batch 30/145, Loss: 0.8818
Epoch 1/10, Batch 40/145, Loss: 0.8851
Epoch 1/10, Batch 50/145, Loss: 0.6716
Epoch 1/10, Batch 60/145, Loss: 0.6974
Epoch 1/10, Batch 70/145, Loss: 0.6326
Epoch 1/10, Batch 80/145, Loss: 0.5198
Epoch 1/10, Batch 90/145, Loss: 0.5893
Epoch 1/10, Batch 100/145, Loss: 0.5791
Epoch 1/10, Batch 110/145, Loss: 0.4684
Epoch 1/10, Batch 120/145, Loss: 0.6798
Epoch 1/10, Batch 130/145, Loss: 0.4030
Epoch 1/10, Batch 140/145, Loss: 0.6286
Epoch 1/10, Train Loss: 0.6857, Valid Loss: 0.3969
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2994
Epoch 2/10, Batch 20/145, Loss: 0.3897
Epoch 2/10, Batch 30/145, Loss: 0.3580
Epoch 2/10, Batch 40/145, Loss: 0.3717
Epoch 2/10, Batch 50/145, Loss: 0.3986
Epoch 2/10, Batch 60/145, Loss: 0.3750
Epoch 2/10, Batch 70/145, Loss: 0.6177
Epoch 2/10, Batch 80/145, Loss: 0.3488
Epoch 2/10, Batch 90/145, Loss: 0.3545
Epoch 2/10, Batch 100/145, Loss: 0.2298
Epoch 2/10, Batch 110/145, Loss: 0.3665
Epoch 2/10, Batch 120/145, Loss: 0.4925
Epoch 2/10, Batch 130/145, Loss: 0.3356
Epoch 2/10, Batch 140/145, Loss: 0.1756
Epoch 2/10, Train Loss: 0.3637, Valid Loss: 0.3111
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2565
Epoch 3/10, Batch 20/145, Loss: 0.4056
Epoch 3/10, Batch 30/145, Loss: 0.2044
Epoch 3/10, Batch 40/145, Loss: 0.3225
Epoch 3/10, Batch 50/145, Loss: 0.1151
Epoch 3/10, Batch 60/145, Loss: 0.4371
Epoch 3/10, Batch 70/145, Loss: 0.1919
Epoch 3/10, Batch 80/145, Loss: 0.2763
Epoch 3/10, Batch 90/145, Loss: 0.6588
Epoch 3/10, Batch 100/145, Loss: 0.1912
Epoch 3/10, Batch 110/145, Loss: 0.1917
Epoch 3/10, Batch 120/145, Loss: 0.2070
Epoch 3/10, Batch 130/145, Loss: 0.2618
Epoch 3/10, Batch 140/145, Loss: 0.2520
Epoch 3/10, Train Loss: 0.3078, Valid Loss: 0.2803
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1713
Epoch 4/10, Batch 20/145, Loss: 0.2630
Epoch 4/10, Batch 30/145, Loss: 0.3324
Epoch 4/10, Batch 40/145, Loss: 0.3169
Epoch 4/10, Batch 50/145, Loss: 0.2269
Epoch 4/10, Batch 60/145, Loss: 0.3049
Epoch 4/10, Batch 70/145, Loss: 0.2503
Epoch 4/10, Batch 80/145, Loss: 0.3306
Epoch 4/10, Batch 90/145, Loss: 0.2986
Epoch 4/10, Batch 100/145, Loss: 0.3118
Epoch 4/10, Batch 110/145, Loss: 0.2579
Epoch 4/10, Batch 120/145, Loss: 0.1513
Epoch 4/10, Batch 130/145, Loss: 0.1709
Epoch 4/10, Batch 140/145, Loss: 0.1908
Epoch 4/10, Train Loss: 0.2650, Valid Loss: 0.2852
Epoch 5/10, Batch 10/145, Loss: 0.1862
Epoch 5/10, Batch 20/145, Loss: 0.1012
Epoch 5/10, Batch 30/145, Loss: 0.1212
Epoch 5/10, Batch 40/145, Loss: 0.2155
Epoch 5/10, Batch 50/145, Loss: 0.1176
Epoch 5/10, Batch 60/145, Loss: 0.2425
Epoch 5/10, Batch 70/145, Loss: 0.2403
Epoch 5/10, Batch 80/145, Loss: 0.1814
Epoch 5/10, Batch 90/145, Loss: 0.2054
Epoch 5/10, Batch 100/145, Loss: 0.1653
Epoch 5/10, Batch 110/145, Loss: 0.1853
Epoch 5/10, Batch 120/145, Loss: 0.2138
Epoch 5/10, Batch 130/145, Loss: 0.0878
Epoch 5/10, Batch 140/145, Loss: 0.2841
Epoch 5/10, Train Loss: 0.2410, Valid Loss: 0.2483
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2577
Epoch 6/10, Batch 20/145, Loss: 0.2620
Epoch 6/10, Batch 30/145, Loss: 0.2423
Epoch 6/10, Batch 40/145, Loss: 0.1954
Epoch 6/10, Batch 50/145, Loss: 0.2026
Epoch 6/10, Batch 60/145, Loss: 0.1808
Epoch 6/10, Batch 70/145, Loss: 0.2663
Epoch 6/10, Batch 80/145, Loss: 0.3852
Epoch 6/10, Batch 90/145, Loss: 0.2357
Epoch 6/10, Batch 100/145, Loss: 0.2222
Epoch 6/10, Batch 110/145, Loss: 0.1674
Epoch 6/10, Batch 120/145, Loss: 0.2366
Epoch 6/10, Batch 130/145, Loss: 0.3177
Epoch 6/10, Batch 140/145, Loss: 0.1296
Epoch 6/10, Train Loss: 0.2302, Valid Loss: 0.2436
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2229
Epoch 7/10, Batch 20/145, Loss: 0.2341
Epoch 7/10, Batch 30/145, Loss: 0.1241
Epoch 7/10, Batch 40/145, Loss: 0.3744
Epoch 7/10, Batch 50/145, Loss: 0.2059
Epoch 7/10, Batch 60/145, Loss: 0.1037
Epoch 7/10, Batch 70/145, Loss: 0.2956
Epoch 7/10, Batch 80/145, Loss: 0.1591
Epoch 7/10, Batch 90/145, Loss: 0.2864
Epoch 7/10, Batch 100/145, Loss: 0.1851
Epoch 7/10, Batch 110/145, Loss: 0.1495
Epoch 7/10, Batch 120/145, Loss: 0.1061
Epoch 7/10, Batch 130/145, Loss: 0.2235
Epoch 7/10, Batch 140/145, Loss: 0.1178
Epoch 7/10, Train Loss: 0.2207, Valid Loss: 0.2426
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1176
Epoch 8/10, Batch 20/145, Loss: 0.0951
Epoch 8/10, Batch 30/145, Loss: 0.1583
Epoch 8/10, Batch 40/145, Loss: 0.2894
Epoch 8/10, Batch 50/145, Loss: 0.2495
Epoch 8/10, Batch 60/145, Loss: 0.1613
Epoch 8/10, Batch 70/145, Loss: 0.0762
Epoch 8/10, Batch 80/145, Loss: 0.1979
Epoch 8/10, Batch 90/145, Loss: 0.1723
Epoch 8/10, Batch 100/145, Loss: 0.2917
Epoch 8/10, Batch 110/145, Loss: 0.1511
Epoch 8/10, Batch 120/145, Loss: 0.3311
Epoch 8/10, Batch 130/145, Loss: 0.2276
Epoch 8/10, Batch 140/145, Loss: 0.2278
Epoch 8/10, Train Loss: 0.2006, Valid Loss: 0.2308
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.0788
Epoch 9/10, Batch 20/145, Loss: 0.1304
Epoch 9/10, Batch 30/145, Loss: 0.1749
Epoch 9/10, Batch 40/145, Loss: 0.1157
Epoch 9/10, Batch 50/145, Loss: 0.2600
Epoch 9/10, Batch 60/145, Loss: 0.2142
Epoch 9/10, Batch 70/145, Loss: 0.1132
Epoch 9/10, Batch 80/145, Loss: 0.2743
Epoch 9/10, Batch 90/145, Loss: 0.2633
Epoch 9/10, Batch 100/145, Loss: 0.1904
Epoch 9/10, Batch 110/145, Loss: 0.1936
Epoch 9/10, Batch 120/145, Loss: 0.1155
Epoch 9/10, Batch 130/145, Loss: 0.1883
Epoch 9/10, Batch 140/145, Loss: 0.1223
Epoch 9/10, Train Loss: 0.2035, Valid Loss: 0.2201
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2934
Epoch 10/10, Batch 20/145, Loss: 0.2143
Epoch 10/10, Batch 30/145, Loss: 0.1772
Epoch 10/10, Batch 40/145, Loss: 0.2544
Epoch 10/10, Batch 50/145, Loss: 0.3018
Epoch 10/10, Batch 60/145, Loss: 0.1917
Epoch 10/10, Batch 70/145, Loss: 0.1704
Epoch 10/10, Batch 80/145, Loss: 0.3085
Epoch 10/10, Batch 90/145, Loss: 0.1889
Epoch 10/10, Batch 100/145, Loss: 0.1409
Epoch 10/10, Batch 110/145, Loss: 0.1748
Epoch 10/10, Batch 120/145, Loss: 0.3751
Epoch 10/10, Batch 130/145, Loss: 0.1891
Epoch 10/10, Batch 140/145, Loss: 0.3943
Epoch 10/10, Train Loss: 0.1976, Valid Loss: 0.2204
Accuracy: 0.9241
Precision: 0.9218
Recall: 0.9241
F1-score: 0.9225
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5772
Epoch 1/10, Batch 20/145, Loss: 0.8905
Epoch 1/10, Batch 30/145, Loss: 0.8645
Epoch 1/10, Batch 40/145, Loss: 0.8292
Epoch 1/10, Batch 50/145, Loss: 0.6172
Epoch 1/10, Batch 60/145, Loss: 0.5881
Epoch 1/10, Batch 70/145, Loss: 0.6243
Epoch 1/10, Batch 80/145, Loss: 0.6405
Epoch 1/10, Batch 90/145, Loss: 0.5692
Epoch 1/10, Batch 100/145, Loss: 0.4918
Epoch 1/10, Batch 110/145, Loss: 0.4054
Epoch 1/10, Batch 120/145, Loss: 0.5356
Epoch 1/10, Batch 130/145, Loss: 0.4811
Epoch 1/10, Batch 140/145, Loss: 0.2867
Epoch 1/10, Train Loss: 0.6879, Valid Loss: 0.4034
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2747
Epoch 2/10, Batch 20/145, Loss: 0.6743
Epoch 2/10, Batch 30/145, Loss: 0.3142
Epoch 2/10, Batch 40/145, Loss: 0.5131
Epoch 2/10, Batch 50/145, Loss: 0.4486
Epoch 2/10, Batch 60/145, Loss: 0.3823
Epoch 2/10, Batch 70/145, Loss: 0.4378
Epoch 2/10, Batch 80/145, Loss: 0.6997
Epoch 2/10, Batch 90/145, Loss: 0.3409
Epoch 2/10, Batch 100/145, Loss: 0.1734
Epoch 2/10, Batch 110/145, Loss: 0.2456
Epoch 2/10, Batch 120/145, Loss: 0.3353
Epoch 2/10, Batch 130/145, Loss: 0.3490
Epoch 2/10, Batch 140/145, Loss: 0.3579
Epoch 2/10, Train Loss: 0.3588, Valid Loss: 0.3198
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2613
Epoch 3/10, Batch 20/145, Loss: 0.1846
Epoch 3/10, Batch 30/145, Loss: 0.2853
Epoch 3/10, Batch 40/145, Loss: 0.3534
Epoch 3/10, Batch 50/145, Loss: 0.1851
Epoch 3/10, Batch 60/145, Loss: 0.2192
Epoch 3/10, Batch 70/145, Loss: 0.1941
Epoch 3/10, Batch 80/145, Loss: 0.2971
Epoch 3/10, Batch 90/145, Loss: 0.4474
Epoch 3/10, Batch 100/145, Loss: 0.2757
Epoch 3/10, Batch 110/145, Loss: 0.2384
Epoch 3/10, Batch 120/145, Loss: 0.1362
Epoch 3/10, Batch 130/145, Loss: 0.3146
Epoch 3/10, Batch 140/145, Loss: 0.1983
Epoch 3/10, Train Loss: 0.3077, Valid Loss: 0.2865
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3210
Epoch 4/10, Batch 20/145, Loss: 0.2805
Epoch 4/10, Batch 30/145, Loss: 0.3692
Epoch 4/10, Batch 40/145, Loss: 0.4183
Epoch 4/10, Batch 50/145, Loss: 0.1824
Epoch 4/10, Batch 60/145, Loss: 0.1609
Epoch 4/10, Batch 70/145, Loss: 0.2141
Epoch 4/10, Batch 80/145, Loss: 0.1499
Epoch 4/10, Batch 90/145, Loss: 0.3769
Epoch 4/10, Batch 100/145, Loss: 0.4387
Epoch 4/10, Batch 110/145, Loss: 0.1620
Epoch 4/10, Batch 120/145, Loss: 0.3171
Epoch 4/10, Batch 130/145, Loss: 0.1404
Epoch 4/10, Batch 140/145, Loss: 0.2773
Epoch 4/10, Train Loss: 0.2615, Valid Loss: 0.2823
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2043
Epoch 5/10, Batch 20/145, Loss: 0.1758
Epoch 5/10, Batch 30/145, Loss: 0.2562
Epoch 5/10, Batch 40/145, Loss: 0.2526
Epoch 5/10, Batch 50/145, Loss: 0.1208
Epoch 5/10, Batch 60/145, Loss: 0.2346
Epoch 5/10, Batch 70/145, Loss: 0.2011
Epoch 5/10, Batch 80/145, Loss: 0.3109
Epoch 5/10, Batch 90/145, Loss: 0.2053
Epoch 5/10, Batch 100/145, Loss: 0.2104
Epoch 5/10, Batch 110/145, Loss: 0.2135
Epoch 5/10, Batch 120/145, Loss: 0.2144
Epoch 5/10, Batch 130/145, Loss: 0.2309
Epoch 5/10, Batch 140/145, Loss: 0.2432
Epoch 5/10, Train Loss: 0.2369, Valid Loss: 0.2668
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2029
Epoch 6/10, Batch 20/145, Loss: 0.1498
Epoch 6/10, Batch 30/145, Loss: 0.2055
Epoch 6/10, Batch 40/145, Loss: 0.2007
Epoch 6/10, Batch 50/145, Loss: 0.2938
Epoch 6/10, Batch 60/145, Loss: 0.3638
Epoch 6/10, Batch 70/145, Loss: 0.3746
Epoch 6/10, Batch 80/145, Loss: 0.3135
Epoch 6/10, Batch 90/145, Loss: 0.2333
Epoch 6/10, Batch 100/145, Loss: 0.4099
Epoch 6/10, Batch 110/145, Loss: 0.1118
Epoch 6/10, Batch 120/145, Loss: 0.3389
Epoch 6/10, Batch 130/145, Loss: 0.1437
Epoch 6/10, Batch 140/145, Loss: 0.2884
Epoch 6/10, Train Loss: 0.2338, Valid Loss: 0.2698
Epoch 7/10, Batch 10/145, Loss: 0.4051
Epoch 7/10, Batch 20/145, Loss: 0.2409
Epoch 7/10, Batch 30/145, Loss: 0.1562
Epoch 7/10, Batch 40/145, Loss: 0.3872
Epoch 7/10, Batch 50/145, Loss: 0.3018
Epoch 7/10, Batch 60/145, Loss: 0.1640
Epoch 7/10, Batch 70/145, Loss: 0.1943
Epoch 7/10, Batch 80/145, Loss: 0.1196
Epoch 7/10, Batch 90/145, Loss: 0.4799
Epoch 7/10, Batch 100/145, Loss: 0.1157
Epoch 7/10, Batch 110/145, Loss: 0.2986
Epoch 7/10, Batch 120/145, Loss: 0.1729
Epoch 7/10, Batch 130/145, Loss: 0.3862
Epoch 7/10, Batch 140/145, Loss: 0.1096
Epoch 7/10, Train Loss: 0.2200, Valid Loss: 0.2703
Epoch 8/10, Batch 10/145, Loss: 0.1161
Epoch 8/10, Batch 20/145, Loss: 0.2048
Epoch 8/10, Batch 30/145, Loss: 0.1337
Epoch 8/10, Batch 40/145, Loss: 0.2793
Epoch 8/10, Batch 50/145, Loss: 0.1158
Epoch 8/10, Batch 60/145, Loss: 0.1597
Epoch 8/10, Batch 70/145, Loss: 0.2078
Epoch 8/10, Batch 80/145, Loss: 0.3008
Epoch 8/10, Batch 90/145, Loss: 0.1781
Epoch 8/10, Batch 100/145, Loss: 0.2494
Epoch 8/10, Batch 110/145, Loss: 0.2679
Epoch 8/10, Batch 120/145, Loss: 0.0996
Epoch 8/10, Batch 130/145, Loss: 0.2689
Epoch 8/10, Batch 140/145, Loss: 0.2692
Epoch 8/10, Train Loss: 0.2098, Valid Loss: 0.2518
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.4804
Epoch 9/10, Batch 20/145, Loss: 0.0997
Epoch 9/10, Batch 30/145, Loss: 0.0845
Epoch 9/10, Batch 40/145, Loss: 0.1883
Epoch 9/10, Batch 50/145, Loss: 0.1328
Epoch 9/10, Batch 60/145, Loss: 0.1483
Epoch 9/10, Batch 70/145, Loss: 0.2172
Epoch 9/10, Batch 80/145, Loss: 0.1770
Epoch 9/10, Batch 90/145, Loss: 0.3049
Epoch 9/10, Batch 100/145, Loss: 0.2369
Epoch 9/10, Batch 110/145, Loss: 0.1244
Epoch 9/10, Batch 120/145, Loss: 0.1925
Epoch 9/10, Batch 130/145, Loss: 0.3919
Epoch 9/10, Batch 140/145, Loss: 0.1325
Epoch 9/10, Train Loss: 0.1965, Valid Loss: 0.2447
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1546
Epoch 10/10, Batch 20/145, Loss: 0.1897
Epoch 10/10, Batch 30/145, Loss: 0.2400
Epoch 10/10, Batch 40/145, Loss: 0.2528
Epoch 10/10, Batch 50/145, Loss: 0.3741
Epoch 10/10, Batch 60/145, Loss: 0.2972
Epoch 10/10, Batch 70/145, Loss: 0.2048
Epoch 10/10, Batch 80/145, Loss: 0.4351
Epoch 10/10, Batch 90/145, Loss: 0.1209
Epoch 10/10, Batch 100/145, Loss: 0.1382
Epoch 10/10, Batch 110/145, Loss: 0.2881
Epoch 10/10, Batch 120/145, Loss: 0.2319
Epoch 10/10, Batch 130/145, Loss: 0.2990
Epoch 10/10, Batch 140/145, Loss: 0.2535
Epoch 10/10, Train Loss: 0.1937, Valid Loss: 0.2454
Accuracy: 0.9252
Precision: 0.9243
Recall: 0.9252
F1-score: 0.9240
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3984
Epoch 1/10, Batch 20/145, Loss: 0.9147
Epoch 1/10, Batch 30/145, Loss: 0.7948
Epoch 1/10, Batch 40/145, Loss: 0.8193
Epoch 1/10, Batch 50/145, Loss: 0.6570
Epoch 1/10, Batch 60/145, Loss: 0.5703
Epoch 1/10, Batch 70/145, Loss: 0.5660
Epoch 1/10, Batch 80/145, Loss: 0.6875
Epoch 1/10, Batch 90/145, Loss: 0.6884
Epoch 1/10, Batch 100/145, Loss: 0.4869
Epoch 1/10, Batch 110/145, Loss: 0.3833
Epoch 1/10, Batch 120/145, Loss: 0.5635
Epoch 1/10, Batch 130/145, Loss: 0.3810
Epoch 1/10, Batch 140/145, Loss: 0.4995
Epoch 1/10, Train Loss: 0.6845, Valid Loss: 0.3938
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2569
Epoch 2/10, Batch 20/145, Loss: 0.5980
Epoch 2/10, Batch 30/145, Loss: 0.3338
Epoch 2/10, Batch 40/145, Loss: 0.5735
Epoch 2/10, Batch 50/145, Loss: 0.2293
Epoch 2/10, Batch 60/145, Loss: 0.3473
Epoch 2/10, Batch 70/145, Loss: 0.3794
Epoch 2/10, Batch 80/145, Loss: 0.3276
Epoch 2/10, Batch 90/145, Loss: 0.2999
Epoch 2/10, Batch 100/145, Loss: 0.2978
Epoch 2/10, Batch 110/145, Loss: 0.2108
Epoch 2/10, Batch 120/145, Loss: 0.2979
Epoch 2/10, Batch 130/145, Loss: 0.3998
Epoch 2/10, Batch 140/145, Loss: 0.3447
Epoch 2/10, Train Loss: 0.3601, Valid Loss: 0.3095
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2225
Epoch 3/10, Batch 20/145, Loss: 0.1580
Epoch 3/10, Batch 30/145, Loss: 0.1844
Epoch 3/10, Batch 40/145, Loss: 0.3967
Epoch 3/10, Batch 50/145, Loss: 0.1950
Epoch 3/10, Batch 60/145, Loss: 0.5460
Epoch 3/10, Batch 70/145, Loss: 0.1927
Epoch 3/10, Batch 80/145, Loss: 0.1525
Epoch 3/10, Batch 90/145, Loss: 0.5158
Epoch 3/10, Batch 100/145, Loss: 0.2613
Epoch 3/10, Batch 110/145, Loss: 0.1412
Epoch 3/10, Batch 120/145, Loss: 0.2317
Epoch 3/10, Batch 130/145, Loss: 0.3048
Epoch 3/10, Batch 140/145, Loss: 0.2041
Epoch 3/10, Train Loss: 0.3003, Valid Loss: 0.2821
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2378
Epoch 4/10, Batch 20/145, Loss: 0.2311
Epoch 4/10, Batch 30/145, Loss: 0.2763
Epoch 4/10, Batch 40/145, Loss: 0.5311
Epoch 4/10, Batch 50/145, Loss: 0.2220
Epoch 4/10, Batch 60/145, Loss: 0.1816
Epoch 4/10, Batch 70/145, Loss: 0.2402
Epoch 4/10, Batch 80/145, Loss: 0.2700
Epoch 4/10, Batch 90/145, Loss: 0.3009
Epoch 4/10, Batch 100/145, Loss: 0.1872
Epoch 4/10, Batch 110/145, Loss: 0.2179
Epoch 4/10, Batch 120/145, Loss: 0.2264
Epoch 4/10, Batch 130/145, Loss: 0.1835
Epoch 4/10, Batch 140/145, Loss: 0.3135
Epoch 4/10, Train Loss: 0.2613, Valid Loss: 0.2730
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2919
Epoch 5/10, Batch 20/145, Loss: 0.3361
Epoch 5/10, Batch 30/145, Loss: 0.2219
Epoch 5/10, Batch 40/145, Loss: 0.3360
Epoch 5/10, Batch 50/145, Loss: 0.1718
Epoch 5/10, Batch 60/145, Loss: 0.2095
Epoch 5/10, Batch 70/145, Loss: 0.3296
Epoch 5/10, Batch 80/145, Loss: 0.3107
Epoch 5/10, Batch 90/145, Loss: 0.1853
Epoch 5/10, Batch 100/145, Loss: 0.4043
Epoch 5/10, Batch 110/145, Loss: 0.2265
Epoch 5/10, Batch 120/145, Loss: 0.3297
Epoch 5/10, Batch 130/145, Loss: 0.2488
Epoch 5/10, Batch 140/145, Loss: 0.4679
Epoch 5/10, Train Loss: 0.2378, Valid Loss: 0.2596
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1216
Epoch 6/10, Batch 20/145, Loss: 0.2673
Epoch 6/10, Batch 30/145, Loss: 0.2461
Epoch 6/10, Batch 40/145, Loss: 0.2211
Epoch 6/10, Batch 50/145, Loss: 0.2568
Epoch 6/10, Batch 60/145, Loss: 0.1149
Epoch 6/10, Batch 70/145, Loss: 0.3001
Epoch 6/10, Batch 80/145, Loss: 0.2113
Epoch 6/10, Batch 90/145, Loss: 0.1791
Epoch 6/10, Batch 100/145, Loss: 0.3280
Epoch 6/10, Batch 110/145, Loss: 0.1913
Epoch 6/10, Batch 120/145, Loss: 0.2611
Epoch 6/10, Batch 130/145, Loss: 0.2349
Epoch 6/10, Batch 140/145, Loss: 0.2611
Epoch 6/10, Train Loss: 0.2249, Valid Loss: 0.2639
Epoch 7/10, Batch 10/145, Loss: 0.3473
Epoch 7/10, Batch 20/145, Loss: 0.1786
Epoch 7/10, Batch 30/145, Loss: 0.2791
Epoch 7/10, Batch 40/145, Loss: 0.4600
Epoch 7/10, Batch 50/145, Loss: 0.2409
Epoch 7/10, Batch 60/145, Loss: 0.1019
Epoch 7/10, Batch 70/145, Loss: 0.1679
Epoch 7/10, Batch 80/145, Loss: 0.2047
Epoch 7/10, Batch 90/145, Loss: 0.3527
Epoch 7/10, Batch 100/145, Loss: 0.1358
Epoch 7/10, Batch 110/145, Loss: 0.1472
Epoch 7/10, Batch 120/145, Loss: 0.2409
Epoch 7/10, Batch 130/145, Loss: 0.3123
Epoch 7/10, Batch 140/145, Loss: 0.1766
Epoch 7/10, Train Loss: 0.2158, Valid Loss: 0.2538
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1240
Epoch 8/10, Batch 20/145, Loss: 0.1380
Epoch 8/10, Batch 30/145, Loss: 0.1655
Epoch 8/10, Batch 40/145, Loss: 0.2146
Epoch 8/10, Batch 50/145, Loss: 0.2518
Epoch 8/10, Batch 60/145, Loss: 0.1445
Epoch 8/10, Batch 70/145, Loss: 0.2590
Epoch 8/10, Batch 80/145, Loss: 0.1258
Epoch 8/10, Batch 90/145, Loss: 0.1468
Epoch 8/10, Batch 100/145, Loss: 0.2343
Epoch 8/10, Batch 110/145, Loss: 0.2030
Epoch 8/10, Batch 120/145, Loss: 0.0858
Epoch 8/10, Batch 130/145, Loss: 0.1094
Epoch 8/10, Batch 140/145, Loss: 0.2167
Epoch 8/10, Train Loss: 0.2071, Valid Loss: 0.2440
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2999
Epoch 9/10, Batch 20/145, Loss: 0.2746
Epoch 9/10, Batch 30/145, Loss: 0.3716
Epoch 9/10, Batch 40/145, Loss: 0.1261
Epoch 9/10, Batch 50/145, Loss: 0.1613
Epoch 9/10, Batch 60/145, Loss: 0.0952
Epoch 9/10, Batch 70/145, Loss: 0.1010
Epoch 9/10, Batch 80/145, Loss: 0.2428
Epoch 9/10, Batch 90/145, Loss: 0.1491
Epoch 9/10, Batch 100/145, Loss: 0.2626
Epoch 9/10, Batch 110/145, Loss: 0.1335
Epoch 9/10, Batch 120/145, Loss: 0.2950
Epoch 9/10, Batch 130/145, Loss: 0.2304
Epoch 9/10, Batch 140/145, Loss: 0.2942
Epoch 9/10, Train Loss: 0.2064, Valid Loss: 0.2402
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2505
Epoch 10/10, Batch 20/145, Loss: 0.1428
Epoch 10/10, Batch 30/145, Loss: 0.1471
Epoch 10/10, Batch 40/145, Loss: 0.1996
Epoch 10/10, Batch 50/145, Loss: 0.2132
Epoch 10/10, Batch 60/145, Loss: 0.2682
Epoch 10/10, Batch 70/145, Loss: 0.1195
Epoch 10/10, Batch 80/145, Loss: 0.2948
Epoch 10/10, Batch 90/145, Loss: 0.1350
Epoch 10/10, Batch 100/145, Loss: 0.2151
Epoch 10/10, Batch 110/145, Loss: 0.4605
Epoch 10/10, Batch 120/145, Loss: 0.0757
Epoch 10/10, Batch 130/145, Loss: 0.1835
Epoch 10/10, Batch 140/145, Loss: 0.1146
Epoch 10/10, Train Loss: 0.1931, Valid Loss: 0.2365
Model saved!
Accuracy: 0.9136
Precision: 0.9109
Recall: 0.9136
F1-score: 0.9115
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5452
Epoch 1/10, Batch 20/145, Loss: 0.8724
Epoch 1/10, Batch 30/145, Loss: 0.8515
Epoch 1/10, Batch 40/145, Loss: 0.8003
Epoch 1/10, Batch 50/145, Loss: 0.5047
Epoch 1/10, Batch 60/145, Loss: 0.5481
Epoch 1/10, Batch 70/145, Loss: 0.6925
Epoch 1/10, Batch 80/145, Loss: 0.5591
Epoch 1/10, Batch 90/145, Loss: 0.6319
Epoch 1/10, Batch 100/145, Loss: 0.5748
Epoch 1/10, Batch 110/145, Loss: 0.3557
Epoch 1/10, Batch 120/145, Loss: 0.6897
Epoch 1/10, Batch 130/145, Loss: 0.5400
Epoch 1/10, Batch 140/145, Loss: 0.3937
Epoch 1/10, Train Loss: 0.6929, Valid Loss: 0.3682
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4020
Epoch 2/10, Batch 20/145, Loss: 0.4187
Epoch 2/10, Batch 30/145, Loss: 0.2441
Epoch 2/10, Batch 40/145, Loss: 0.3648
Epoch 2/10, Batch 50/145, Loss: 0.2873
Epoch 2/10, Batch 60/145, Loss: 0.3677
Epoch 2/10, Batch 70/145, Loss: 0.4947
Epoch 2/10, Batch 80/145, Loss: 0.3944
Epoch 2/10, Batch 90/145, Loss: 0.3279
Epoch 2/10, Batch 100/145, Loss: 0.2758
Epoch 2/10, Batch 110/145, Loss: 0.3284
Epoch 2/10, Batch 120/145, Loss: 0.3753
Epoch 2/10, Batch 130/145, Loss: 0.3455
Epoch 2/10, Batch 140/145, Loss: 0.1850
Epoch 2/10, Train Loss: 0.3637, Valid Loss: 0.2875
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2542
Epoch 3/10, Batch 20/145, Loss: 0.2647
Epoch 3/10, Batch 30/145, Loss: 0.2374
Epoch 3/10, Batch 40/145, Loss: 0.2615
Epoch 3/10, Batch 50/145, Loss: 0.1781
Epoch 3/10, Batch 60/145, Loss: 0.2430
Epoch 3/10, Batch 70/145, Loss: 0.2062
Epoch 3/10, Batch 80/145, Loss: 0.2606
Epoch 3/10, Batch 90/145, Loss: 0.4762
Epoch 3/10, Batch 100/145, Loss: 0.2423
Epoch 3/10, Batch 110/145, Loss: 0.3262
Epoch 3/10, Batch 120/145, Loss: 0.1973
Epoch 3/10, Batch 130/145, Loss: 0.2561
Epoch 3/10, Batch 140/145, Loss: 0.2371
Epoch 3/10, Train Loss: 0.3063, Valid Loss: 0.2501
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3521
Epoch 4/10, Batch 20/145, Loss: 0.2432
Epoch 4/10, Batch 30/145, Loss: 0.3034
Epoch 4/10, Batch 40/145, Loss: 0.4648
Epoch 4/10, Batch 50/145, Loss: 0.1643
Epoch 4/10, Batch 60/145, Loss: 0.2172
Epoch 4/10, Batch 70/145, Loss: 0.2839
Epoch 4/10, Batch 80/145, Loss: 0.2988
Epoch 4/10, Batch 90/145, Loss: 0.2777
Epoch 4/10, Batch 100/145, Loss: 0.2070
Epoch 4/10, Batch 110/145, Loss: 0.2242
Epoch 4/10, Batch 120/145, Loss: 0.1689
Epoch 4/10, Batch 130/145, Loss: 0.2163
Epoch 4/10, Batch 140/145, Loss: 0.1771
Epoch 4/10, Train Loss: 0.2647, Valid Loss: 0.2346
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1416
Epoch 5/10, Batch 20/145, Loss: 0.3286
Epoch 5/10, Batch 30/145, Loss: 0.1731
Epoch 5/10, Batch 40/145, Loss: 0.2958
Epoch 5/10, Batch 50/145, Loss: 0.0625
Epoch 5/10, Batch 60/145, Loss: 0.2602
Epoch 5/10, Batch 70/145, Loss: 0.2174
Epoch 5/10, Batch 80/145, Loss: 0.2874
Epoch 5/10, Batch 90/145, Loss: 0.2913
Epoch 5/10, Batch 100/145, Loss: 0.3326
Epoch 5/10, Batch 110/145, Loss: 0.1380
Epoch 5/10, Batch 120/145, Loss: 0.1366
Epoch 5/10, Batch 130/145, Loss: 0.2817
Epoch 5/10, Batch 140/145, Loss: 0.2704
Epoch 5/10, Train Loss: 0.2358, Valid Loss: 0.2237
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2131
Epoch 6/10, Batch 20/145, Loss: 0.1943
Epoch 6/10, Batch 30/145, Loss: 0.2658
Epoch 6/10, Batch 40/145, Loss: 0.3733
Epoch 6/10, Batch 50/145, Loss: 0.3265
Epoch 6/10, Batch 60/145, Loss: 0.1337
Epoch 6/10, Batch 70/145, Loss: 0.3331
Epoch 6/10, Batch 80/145, Loss: 0.3856
Epoch 6/10, Batch 90/145, Loss: 0.2465
Epoch 6/10, Batch 100/145, Loss: 0.1221
Epoch 6/10, Batch 110/145, Loss: 0.1650
Epoch 6/10, Batch 120/145, Loss: 0.1780
Epoch 6/10, Batch 130/145, Loss: 0.1784
Epoch 6/10, Batch 140/145, Loss: 0.4314
Epoch 6/10, Train Loss: 0.2331, Valid Loss: 0.2282
Epoch 7/10, Batch 10/145, Loss: 0.2212
Epoch 7/10, Batch 20/145, Loss: 0.1227
Epoch 7/10, Batch 30/145, Loss: 0.2009
Epoch 7/10, Batch 40/145, Loss: 0.3897
Epoch 7/10, Batch 50/145, Loss: 0.2340
Epoch 7/10, Batch 60/145, Loss: 0.2807
Epoch 7/10, Batch 70/145, Loss: 0.2616
Epoch 7/10, Batch 80/145, Loss: 0.1002
Epoch 7/10, Batch 90/145, Loss: 0.4145
Epoch 7/10, Batch 100/145, Loss: 0.3449
Epoch 7/10, Batch 110/145, Loss: 0.4737
Epoch 7/10, Batch 120/145, Loss: 0.1273
Epoch 7/10, Batch 130/145, Loss: 0.2335
Epoch 7/10, Batch 140/145, Loss: 0.0876
Epoch 7/10, Train Loss: 0.2210, Valid Loss: 0.2145
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0835
Epoch 8/10, Batch 20/145, Loss: 0.1050
Epoch 8/10, Batch 30/145, Loss: 0.2465
Epoch 8/10, Batch 40/145, Loss: 0.3296
Epoch 8/10, Batch 50/145, Loss: 0.3615
Epoch 8/10, Batch 60/145, Loss: 0.2097
Epoch 8/10, Batch 70/145, Loss: 0.1569
Epoch 8/10, Batch 80/145, Loss: 0.2525
Epoch 8/10, Batch 90/145, Loss: 0.1951
Epoch 8/10, Batch 100/145, Loss: 0.2632
Epoch 8/10, Batch 110/145, Loss: 0.2220
Epoch 8/10, Batch 120/145, Loss: 0.2019
Epoch 8/10, Batch 130/145, Loss: 0.1684
Epoch 8/10, Batch 140/145, Loss: 0.3836
Epoch 8/10, Train Loss: 0.2114, Valid Loss: 0.2057
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2554
Epoch 9/10, Batch 20/145, Loss: 0.2751
Epoch 9/10, Batch 30/145, Loss: 0.0936
Epoch 9/10, Batch 40/145, Loss: 0.3339
Epoch 9/10, Batch 50/145, Loss: 0.1132
Epoch 9/10, Batch 60/145, Loss: 0.1659
Epoch 9/10, Batch 70/145, Loss: 0.2581
Epoch 9/10, Batch 80/145, Loss: 0.2723
Epoch 9/10, Batch 90/145, Loss: 0.1611
Epoch 9/10, Batch 100/145, Loss: 0.2073
Epoch 9/10, Batch 110/145, Loss: 0.1628
Epoch 9/10, Batch 120/145, Loss: 0.3152
Epoch 9/10, Batch 130/145, Loss: 0.2584
Epoch 9/10, Batch 140/145, Loss: 0.0943
Epoch 9/10, Train Loss: 0.2065, Valid Loss: 0.2002
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1923
Epoch 10/10, Batch 20/145, Loss: 0.1224
Epoch 10/10, Batch 30/145, Loss: 0.1526
Epoch 10/10, Batch 40/145, Loss: 0.1430
Epoch 10/10, Batch 50/145, Loss: 0.1880
Epoch 10/10, Batch 60/145, Loss: 0.1928
Epoch 10/10, Batch 70/145, Loss: 0.1345
Epoch 10/10, Batch 80/145, Loss: 0.4049
Epoch 10/10, Batch 90/145, Loss: 0.1607
Epoch 10/10, Batch 100/145, Loss: 0.0949
Epoch 10/10, Batch 110/145, Loss: 0.3450
Epoch 10/10, Batch 120/145, Loss: 0.1802
Epoch 10/10, Batch 130/145, Loss: 0.3920
Epoch 10/10, Batch 140/145, Loss: 0.1718
Epoch 10/10, Train Loss: 0.1969, Valid Loss: 0.1936
Model saved!
Accuracy: 0.9264
Precision: 0.9243
Recall: 0.9264
F1-score: 0.9249
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4737
Epoch 1/10, Batch 20/145, Loss: 0.8596
Epoch 1/10, Batch 30/145, Loss: 0.8317
Epoch 1/10, Batch 40/145, Loss: 0.7774
Epoch 1/10, Batch 50/145, Loss: 0.7247
Epoch 1/10, Batch 60/145, Loss: 0.7138
Epoch 1/10, Batch 70/145, Loss: 0.7877
Epoch 1/10, Batch 80/145, Loss: 0.5392
Epoch 1/10, Batch 90/145, Loss: 0.4477
Epoch 1/10, Batch 100/145, Loss: 0.5172
Epoch 1/10, Batch 110/145, Loss: 0.4426
Epoch 1/10, Batch 120/145, Loss: 0.6766
Epoch 1/10, Batch 130/145, Loss: 0.3235
Epoch 1/10, Batch 140/145, Loss: 0.4451
Epoch 1/10, Train Loss: 0.6800, Valid Loss: 0.3809
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4219
Epoch 2/10, Batch 20/145, Loss: 0.4298
Epoch 2/10, Batch 30/145, Loss: 0.3406
Epoch 2/10, Batch 40/145, Loss: 0.4760
Epoch 2/10, Batch 50/145, Loss: 0.2950
Epoch 2/10, Batch 60/145, Loss: 0.3700
Epoch 2/10, Batch 70/145, Loss: 0.4056
Epoch 2/10, Batch 80/145, Loss: 0.3104
Epoch 2/10, Batch 90/145, Loss: 0.3134
Epoch 2/10, Batch 100/145, Loss: 0.2721
Epoch 2/10, Batch 110/145, Loss: 0.2531
Epoch 2/10, Batch 120/145, Loss: 0.4318
Epoch 2/10, Batch 130/145, Loss: 0.3381
Epoch 2/10, Batch 140/145, Loss: 0.2789
Epoch 2/10, Train Loss: 0.3560, Valid Loss: 0.2987
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3086
Epoch 3/10, Batch 20/145, Loss: 0.2924
Epoch 3/10, Batch 30/145, Loss: 0.2397
Epoch 3/10, Batch 40/145, Loss: 0.3009
Epoch 3/10, Batch 50/145, Loss: 0.3421
Epoch 3/10, Batch 60/145, Loss: 0.1857
Epoch 3/10, Batch 70/145, Loss: 0.1408
Epoch 3/10, Batch 80/145, Loss: 0.3664
Epoch 3/10, Batch 90/145, Loss: 0.4681
Epoch 3/10, Batch 100/145, Loss: 0.3226
Epoch 3/10, Batch 110/145, Loss: 0.3104
Epoch 3/10, Batch 120/145, Loss: 0.2039
Epoch 3/10, Batch 130/145, Loss: 0.2752
Epoch 3/10, Batch 140/145, Loss: 0.1762
Epoch 3/10, Train Loss: 0.3041, Valid Loss: 0.2772
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2243
Epoch 4/10, Batch 20/145, Loss: 0.4024
Epoch 4/10, Batch 30/145, Loss: 0.3415
Epoch 4/10, Batch 40/145, Loss: 0.2513
Epoch 4/10, Batch 50/145, Loss: 0.2298
Epoch 4/10, Batch 60/145, Loss: 0.2064
Epoch 4/10, Batch 70/145, Loss: 0.2877
Epoch 4/10, Batch 80/145, Loss: 0.1776
Epoch 4/10, Batch 90/145, Loss: 0.2798
Epoch 4/10, Batch 100/145, Loss: 0.1649
Epoch 4/10, Batch 110/145, Loss: 0.2980
Epoch 4/10, Batch 120/145, Loss: 0.2338
Epoch 4/10, Batch 130/145, Loss: 0.1946
Epoch 4/10, Batch 140/145, Loss: 0.2716
Epoch 4/10, Train Loss: 0.2604, Valid Loss: 0.2733
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2672
Epoch 5/10, Batch 20/145, Loss: 0.2326
Epoch 5/10, Batch 30/145, Loss: 0.3035
Epoch 5/10, Batch 40/145, Loss: 0.2809
Epoch 5/10, Batch 50/145, Loss: 0.1428
Epoch 5/10, Batch 60/145, Loss: 0.2749
Epoch 5/10, Batch 70/145, Loss: 0.2475
Epoch 5/10, Batch 80/145, Loss: 0.1688
Epoch 5/10, Batch 90/145, Loss: 0.1996
Epoch 5/10, Batch 100/145, Loss: 0.2840
Epoch 5/10, Batch 110/145, Loss: 0.2257
Epoch 5/10, Batch 120/145, Loss: 0.1155
Epoch 5/10, Batch 130/145, Loss: 0.1075
Epoch 5/10, Batch 140/145, Loss: 0.3428
Epoch 5/10, Train Loss: 0.2369, Valid Loss: 0.2422
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2825
Epoch 6/10, Batch 20/145, Loss: 0.1864
Epoch 6/10, Batch 30/145, Loss: 0.2594
Epoch 6/10, Batch 40/145, Loss: 0.0826
Epoch 6/10, Batch 50/145, Loss: 0.4135
Epoch 6/10, Batch 60/145, Loss: 0.0968
Epoch 6/10, Batch 70/145, Loss: 0.1083
Epoch 6/10, Batch 80/145, Loss: 0.2582
Epoch 6/10, Batch 90/145, Loss: 0.2006
Epoch 6/10, Batch 100/145, Loss: 0.1838
Epoch 6/10, Batch 110/145, Loss: 0.1345
Epoch 6/10, Batch 120/145, Loss: 0.1690
Epoch 6/10, Batch 130/145, Loss: 0.1371
Epoch 6/10, Batch 140/145, Loss: 0.2528
Epoch 6/10, Train Loss: 0.2284, Valid Loss: 0.2382
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2328
Epoch 7/10, Batch 20/145, Loss: 0.1778
Epoch 7/10, Batch 30/145, Loss: 0.1406
Epoch 7/10, Batch 40/145, Loss: 0.3014
Epoch 7/10, Batch 50/145, Loss: 0.1866
Epoch 7/10, Batch 60/145, Loss: 0.1769
Epoch 7/10, Batch 70/145, Loss: 0.3391
Epoch 7/10, Batch 80/145, Loss: 0.2746
Epoch 7/10, Batch 90/145, Loss: 0.2332
Epoch 7/10, Batch 100/145, Loss: 0.1522
Epoch 7/10, Batch 110/145, Loss: 0.2876
Epoch 7/10, Batch 120/145, Loss: 0.2962
Epoch 7/10, Batch 130/145, Loss: 0.1961
Epoch 7/10, Batch 140/145, Loss: 0.1653
Epoch 7/10, Train Loss: 0.2134, Valid Loss: 0.2244
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0969
Epoch 8/10, Batch 20/145, Loss: 0.1010
Epoch 8/10, Batch 30/145, Loss: 0.2119
Epoch 8/10, Batch 40/145, Loss: 0.1728
Epoch 8/10, Batch 50/145, Loss: 0.3291
Epoch 8/10, Batch 60/145, Loss: 0.1008
Epoch 8/10, Batch 70/145, Loss: 0.1038
Epoch 8/10, Batch 80/145, Loss: 0.4314
Epoch 8/10, Batch 90/145, Loss: 0.1777
Epoch 8/10, Batch 100/145, Loss: 0.2941
Epoch 8/10, Batch 110/145, Loss: 0.1572
Epoch 8/10, Batch 120/145, Loss: 0.1615
Epoch 8/10, Batch 130/145, Loss: 0.2045
Epoch 8/10, Batch 140/145, Loss: 0.2770
Epoch 8/10, Train Loss: 0.2056, Valid Loss: 0.2321
Epoch 9/10, Batch 10/145, Loss: 0.2215
Epoch 9/10, Batch 20/145, Loss: 0.1879
Epoch 9/10, Batch 30/145, Loss: 0.1528
Epoch 9/10, Batch 40/145, Loss: 0.1178
Epoch 9/10, Batch 50/145, Loss: 0.2213
Epoch 9/10, Batch 60/145, Loss: 0.2536
Epoch 9/10, Batch 70/145, Loss: 0.0976
Epoch 9/10, Batch 80/145, Loss: 0.1624
Epoch 9/10, Batch 90/145, Loss: 0.2310
Epoch 9/10, Batch 100/145, Loss: 0.2487
Epoch 9/10, Batch 110/145, Loss: 0.0669
Epoch 9/10, Batch 120/145, Loss: 0.3211
Epoch 9/10, Batch 130/145, Loss: 0.2002
Epoch 9/10, Batch 140/145, Loss: 0.0779
Epoch 9/10, Train Loss: 0.2004, Valid Loss: 0.2192
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1348
Epoch 10/10, Batch 20/145, Loss: 0.1964
Epoch 10/10, Batch 30/145, Loss: 0.1586
Epoch 10/10, Batch 40/145, Loss: 0.1989
Epoch 10/10, Batch 50/145, Loss: 0.2660
Epoch 10/10, Batch 60/145, Loss: 0.1508
Epoch 10/10, Batch 70/145, Loss: 0.1985
Epoch 10/10, Batch 80/145, Loss: 0.4246
Epoch 10/10, Batch 90/145, Loss: 0.1586
Epoch 10/10, Batch 100/145, Loss: 0.1136
Epoch 10/10, Batch 110/145, Loss: 0.2099
Epoch 10/10, Batch 120/145, Loss: 0.1221
Epoch 10/10, Batch 130/145, Loss: 0.2520
Epoch 10/10, Batch 140/145, Loss: 0.1758
Epoch 10/10, Train Loss: 0.1945, Valid Loss: 0.2243
Accuracy: 0.9171
Precision: 0.9143
Recall: 0.9171
F1-score: 0.9151
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4756
Epoch 1/10, Batch 20/145, Loss: 0.8203
Epoch 1/10, Batch 30/145, Loss: 0.8641
Epoch 1/10, Batch 40/145, Loss: 0.8330
Epoch 1/10, Batch 50/145, Loss: 0.6823
Epoch 1/10, Batch 60/145, Loss: 0.4990
Epoch 1/10, Batch 70/145, Loss: 0.5652
Epoch 1/10, Batch 80/145, Loss: 0.5541
Epoch 1/10, Batch 90/145, Loss: 0.3549
Epoch 1/10, Batch 100/145, Loss: 0.7140
Epoch 1/10, Batch 110/145, Loss: 0.4771
Epoch 1/10, Batch 120/145, Loss: 0.5051
Epoch 1/10, Batch 130/145, Loss: 0.3551
Epoch 1/10, Batch 140/145, Loss: 0.3913
Epoch 1/10, Train Loss: 0.6838, Valid Loss: 0.3913
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3286
Epoch 2/10, Batch 20/145, Loss: 0.4074
Epoch 2/10, Batch 30/145, Loss: 0.2715
Epoch 2/10, Batch 40/145, Loss: 0.4300
Epoch 2/10, Batch 50/145, Loss: 0.3259
Epoch 2/10, Batch 60/145, Loss: 0.3567
Epoch 2/10, Batch 70/145, Loss: 0.2536
Epoch 2/10, Batch 80/145, Loss: 0.2314
Epoch 2/10, Batch 90/145, Loss: 0.2422
Epoch 2/10, Batch 100/145, Loss: 0.4055
Epoch 2/10, Batch 110/145, Loss: 0.2731
Epoch 2/10, Batch 120/145, Loss: 0.3841
Epoch 2/10, Batch 130/145, Loss: 0.3320
Epoch 2/10, Batch 140/145, Loss: 0.1651
Epoch 2/10, Train Loss: 0.3614, Valid Loss: 0.3134
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2218
Epoch 3/10, Batch 20/145, Loss: 0.2399
Epoch 3/10, Batch 30/145, Loss: 0.2695
Epoch 3/10, Batch 40/145, Loss: 0.2599
Epoch 3/10, Batch 50/145, Loss: 0.2058
Epoch 3/10, Batch 60/145, Loss: 0.2835
Epoch 3/10, Batch 70/145, Loss: 0.1758
Epoch 3/10, Batch 80/145, Loss: 0.3020
Epoch 3/10, Batch 90/145, Loss: 0.5815
Epoch 3/10, Batch 100/145, Loss: 0.2085
Epoch 3/10, Batch 110/145, Loss: 0.3006
Epoch 3/10, Batch 120/145, Loss: 0.1468
Epoch 3/10, Batch 130/145, Loss: 0.3924
Epoch 3/10, Batch 140/145, Loss: 0.2262
Epoch 3/10, Train Loss: 0.3033, Valid Loss: 0.2821
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3541
Epoch 4/10, Batch 20/145, Loss: 0.2530
Epoch 4/10, Batch 30/145, Loss: 0.3709
Epoch 4/10, Batch 40/145, Loss: 0.2729
Epoch 4/10, Batch 50/145, Loss: 0.3389
Epoch 4/10, Batch 60/145, Loss: 0.3203
Epoch 4/10, Batch 70/145, Loss: 0.2754
Epoch 4/10, Batch 80/145, Loss: 0.1718
Epoch 4/10, Batch 90/145, Loss: 0.2543
Epoch 4/10, Batch 100/145, Loss: 0.3187
Epoch 4/10, Batch 110/145, Loss: 0.2933
Epoch 4/10, Batch 120/145, Loss: 0.1834
Epoch 4/10, Batch 130/145, Loss: 0.1908
Epoch 4/10, Batch 140/145, Loss: 0.2932
Epoch 4/10, Train Loss: 0.2677, Valid Loss: 0.2793
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1510
Epoch 5/10, Batch 20/145, Loss: 0.1283
Epoch 5/10, Batch 30/145, Loss: 0.2407
Epoch 5/10, Batch 40/145, Loss: 0.1882
Epoch 5/10, Batch 50/145, Loss: 0.2297
Epoch 5/10, Batch 60/145, Loss: 0.2582
Epoch 5/10, Batch 70/145, Loss: 0.4325
Epoch 5/10, Batch 80/145, Loss: 0.3039
Epoch 5/10, Batch 90/145, Loss: 0.3002
Epoch 5/10, Batch 100/145, Loss: 0.2451
Epoch 5/10, Batch 110/145, Loss: 0.1734
Epoch 5/10, Batch 120/145, Loss: 0.2827
Epoch 5/10, Batch 130/145, Loss: 0.2568
Epoch 5/10, Batch 140/145, Loss: 0.3119
Epoch 5/10, Train Loss: 0.2418, Valid Loss: 0.2671
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2876
Epoch 6/10, Batch 20/145, Loss: 0.2762
Epoch 6/10, Batch 30/145, Loss: 0.3013
Epoch 6/10, Batch 40/145, Loss: 0.1965
Epoch 6/10, Batch 50/145, Loss: 0.3102
Epoch 6/10, Batch 60/145, Loss: 0.1679
Epoch 6/10, Batch 70/145, Loss: 0.3726
Epoch 6/10, Batch 80/145, Loss: 0.2419
Epoch 6/10, Batch 90/145, Loss: 0.2751
Epoch 6/10, Batch 100/145, Loss: 0.1674
Epoch 6/10, Batch 110/145, Loss: 0.2296
Epoch 6/10, Batch 120/145, Loss: 0.2786
Epoch 6/10, Batch 130/145, Loss: 0.1251
Epoch 6/10, Batch 140/145, Loss: 0.1688
Epoch 6/10, Train Loss: 0.2335, Valid Loss: 0.2671
Epoch 7/10, Batch 10/145, Loss: 0.3510
Epoch 7/10, Batch 20/145, Loss: 0.1251
Epoch 7/10, Batch 30/145, Loss: 0.2041
Epoch 7/10, Batch 40/145, Loss: 0.4346
Epoch 7/10, Batch 50/145, Loss: 0.1673
Epoch 7/10, Batch 60/145, Loss: 0.1780
Epoch 7/10, Batch 70/145, Loss: 0.1472
Epoch 7/10, Batch 80/145, Loss: 0.1434
Epoch 7/10, Batch 90/145, Loss: 0.2284
Epoch 7/10, Batch 100/145, Loss: 0.1075
Epoch 7/10, Batch 110/145, Loss: 0.1818
Epoch 7/10, Batch 120/145, Loss: 0.2282
Epoch 7/10, Batch 130/145, Loss: 0.1863
Epoch 7/10, Batch 140/145, Loss: 0.1517
Epoch 7/10, Train Loss: 0.2137, Valid Loss: 0.2508
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1807
Epoch 8/10, Batch 20/145, Loss: 0.1411
Epoch 8/10, Batch 30/145, Loss: 0.1487
Epoch 8/10, Batch 40/145, Loss: 0.1214
Epoch 8/10, Batch 50/145, Loss: 0.0774
Epoch 8/10, Batch 60/145, Loss: 0.2848
Epoch 8/10, Batch 70/145, Loss: 0.1738
Epoch 8/10, Batch 80/145, Loss: 0.2046
Epoch 8/10, Batch 90/145, Loss: 0.1479
Epoch 8/10, Batch 100/145, Loss: 0.1997
Epoch 8/10, Batch 110/145, Loss: 0.3530
Epoch 8/10, Batch 120/145, Loss: 0.2219
Epoch 8/10, Batch 130/145, Loss: 0.2881
Epoch 8/10, Batch 140/145, Loss: 0.1615
Epoch 8/10, Train Loss: 0.2126, Valid Loss: 0.2501
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2592
Epoch 9/10, Batch 20/145, Loss: 0.0509
Epoch 9/10, Batch 30/145, Loss: 0.1445
Epoch 9/10, Batch 40/145, Loss: 0.2023
Epoch 9/10, Batch 50/145, Loss: 0.1339
Epoch 9/10, Batch 60/145, Loss: 0.1560
Epoch 9/10, Batch 70/145, Loss: 0.2254
Epoch 9/10, Batch 80/145, Loss: 0.1992
Epoch 9/10, Batch 90/145, Loss: 0.2909
Epoch 9/10, Batch 100/145, Loss: 0.3839
Epoch 9/10, Batch 110/145, Loss: 0.1169
Epoch 9/10, Batch 120/145, Loss: 0.1460
Epoch 9/10, Batch 130/145, Loss: 0.2937
Epoch 9/10, Batch 140/145, Loss: 0.1076
Epoch 9/10, Train Loss: 0.2053, Valid Loss: 0.2466
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.3066
Epoch 10/10, Batch 20/145, Loss: 0.0508
Epoch 10/10, Batch 30/145, Loss: 0.1035
Epoch 10/10, Batch 40/145, Loss: 0.3496
Epoch 10/10, Batch 50/145, Loss: 0.3227
Epoch 10/10, Batch 60/145, Loss: 0.1916
Epoch 10/10, Batch 70/145, Loss: 0.1063
Epoch 10/10, Batch 80/145, Loss: 0.2792
Epoch 10/10, Batch 90/145, Loss: 0.1137
Epoch 10/10, Batch 100/145, Loss: 0.0905
Epoch 10/10, Batch 110/145, Loss: 0.2021
Epoch 10/10, Batch 120/145, Loss: 0.1137
Epoch 10/10, Batch 130/145, Loss: 0.1866
Epoch 10/10, Batch 140/145, Loss: 0.2548
Epoch 10/10, Train Loss: 0.1952, Valid Loss: 0.2406
Model saved!
Accuracy: 0.9252
Precision: 0.9239
Recall: 0.9252
F1-score: 0.9240
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5046
Epoch 1/10, Batch 20/145, Loss: 0.8754
Epoch 1/10, Batch 30/145, Loss: 0.8266
Epoch 1/10, Batch 40/145, Loss: 0.8776
Epoch 1/10, Batch 50/145, Loss: 0.5060
Epoch 1/10, Batch 60/145, Loss: 0.6279
Epoch 1/10, Batch 70/145, Loss: 0.6686
Epoch 1/10, Batch 80/145, Loss: 0.4822
Epoch 1/10, Batch 90/145, Loss: 0.4205
Epoch 1/10, Batch 100/145, Loss: 0.6043
Epoch 1/10, Batch 110/145, Loss: 0.4490
Epoch 1/10, Batch 120/145, Loss: 0.5576
Epoch 1/10, Batch 130/145, Loss: 0.4098
Epoch 1/10, Batch 140/145, Loss: 0.5632
Epoch 1/10, Train Loss: 0.6871, Valid Loss: 0.3901
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3494
Epoch 2/10, Batch 20/145, Loss: 0.3836
Epoch 2/10, Batch 30/145, Loss: 0.3026
Epoch 2/10, Batch 40/145, Loss: 0.4665
Epoch 2/10, Batch 50/145, Loss: 0.2340
Epoch 2/10, Batch 60/145, Loss: 0.3995
Epoch 2/10, Batch 70/145, Loss: 0.3773
Epoch 2/10, Batch 80/145, Loss: 0.4276
Epoch 2/10, Batch 90/145, Loss: 0.4922
Epoch 2/10, Batch 100/145, Loss: 0.3209
Epoch 2/10, Batch 110/145, Loss: 0.3172
Epoch 2/10, Batch 120/145, Loss: 0.4732
Epoch 2/10, Batch 130/145, Loss: 0.2624
Epoch 2/10, Batch 140/145, Loss: 0.2862
Epoch 2/10, Train Loss: 0.3669, Valid Loss: 0.3012
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3456
Epoch 3/10, Batch 20/145, Loss: 0.4629
Epoch 3/10, Batch 30/145, Loss: 0.2593
Epoch 3/10, Batch 40/145, Loss: 0.2589
Epoch 3/10, Batch 50/145, Loss: 0.2294
Epoch 3/10, Batch 60/145, Loss: 0.2609
Epoch 3/10, Batch 70/145, Loss: 0.1959
Epoch 3/10, Batch 80/145, Loss: 0.3109
Epoch 3/10, Batch 90/145, Loss: 0.5851
Epoch 3/10, Batch 100/145, Loss: 0.2540
Epoch 3/10, Batch 110/145, Loss: 0.2497
Epoch 3/10, Batch 120/145, Loss: 0.2761
Epoch 3/10, Batch 130/145, Loss: 0.2178
Epoch 3/10, Batch 140/145, Loss: 0.1642
Epoch 3/10, Train Loss: 0.3074, Valid Loss: 0.2702
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1705
Epoch 4/10, Batch 20/145, Loss: 0.2611
Epoch 4/10, Batch 30/145, Loss: 0.2792
Epoch 4/10, Batch 40/145, Loss: 0.3717
Epoch 4/10, Batch 50/145, Loss: 0.2314
Epoch 4/10, Batch 60/145, Loss: 0.2207
Epoch 4/10, Batch 70/145, Loss: 0.1224
Epoch 4/10, Batch 80/145, Loss: 0.2724
Epoch 4/10, Batch 90/145, Loss: 0.1778
Epoch 4/10, Batch 100/145, Loss: 0.3451
Epoch 4/10, Batch 110/145, Loss: 0.2789
Epoch 4/10, Batch 120/145, Loss: 0.0951
Epoch 4/10, Batch 130/145, Loss: 0.1769
Epoch 4/10, Batch 140/145, Loss: 0.1947
Epoch 4/10, Train Loss: 0.2642, Valid Loss: 0.2527
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2200
Epoch 5/10, Batch 20/145, Loss: 0.2735
Epoch 5/10, Batch 30/145, Loss: 0.1447
Epoch 5/10, Batch 40/145, Loss: 0.3983
Epoch 5/10, Batch 50/145, Loss: 0.0732
Epoch 5/10, Batch 60/145, Loss: 0.0999
Epoch 5/10, Batch 70/145, Loss: 0.3586
Epoch 5/10, Batch 80/145, Loss: 0.3705
Epoch 5/10, Batch 90/145, Loss: 0.2367
Epoch 5/10, Batch 100/145, Loss: 0.4026
Epoch 5/10, Batch 110/145, Loss: 0.3188
Epoch 5/10, Batch 120/145, Loss: 0.1885
Epoch 5/10, Batch 130/145, Loss: 0.3325
Epoch 5/10, Batch 140/145, Loss: 0.2400
Epoch 5/10, Train Loss: 0.2419, Valid Loss: 0.2448
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2618
Epoch 6/10, Batch 20/145, Loss: 0.2760
Epoch 6/10, Batch 30/145, Loss: 0.3653
Epoch 6/10, Batch 40/145, Loss: 0.1140
Epoch 6/10, Batch 50/145, Loss: 0.2338
Epoch 6/10, Batch 60/145, Loss: 0.2019
Epoch 6/10, Batch 70/145, Loss: 0.2829
Epoch 6/10, Batch 80/145, Loss: 0.2122
Epoch 6/10, Batch 90/145, Loss: 0.3702
Epoch 6/10, Batch 100/145, Loss: 0.1748
Epoch 6/10, Batch 110/145, Loss: 0.2487
Epoch 6/10, Batch 120/145, Loss: 0.2699
Epoch 6/10, Batch 130/145, Loss: 0.1969
Epoch 6/10, Batch 140/145, Loss: 0.2065
Epoch 6/10, Train Loss: 0.2294, Valid Loss: 0.2434
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.4581
Epoch 7/10, Batch 20/145, Loss: 0.2742
Epoch 7/10, Batch 30/145, Loss: 0.2061
Epoch 7/10, Batch 40/145, Loss: 0.4650
Epoch 7/10, Batch 50/145, Loss: 0.3899
Epoch 7/10, Batch 60/145, Loss: 0.2813
Epoch 7/10, Batch 70/145, Loss: 0.2225
Epoch 7/10, Batch 80/145, Loss: 0.2004
Epoch 7/10, Batch 90/145, Loss: 0.1675
Epoch 7/10, Batch 100/145, Loss: 0.2109
Epoch 7/10, Batch 110/145, Loss: 0.2105
Epoch 7/10, Batch 120/145, Loss: 0.1453
Epoch 7/10, Batch 130/145, Loss: 0.2898
Epoch 7/10, Batch 140/145, Loss: 0.2272
Epoch 7/10, Train Loss: 0.2211, Valid Loss: 0.2440
Epoch 8/10, Batch 10/145, Loss: 0.1831
Epoch 8/10, Batch 20/145, Loss: 0.1866
Epoch 8/10, Batch 30/145, Loss: 0.1656
Epoch 8/10, Batch 40/145, Loss: 0.3684
Epoch 8/10, Batch 50/145, Loss: 0.2429
Epoch 8/10, Batch 60/145, Loss: 0.1323
Epoch 8/10, Batch 70/145, Loss: 0.1180
Epoch 8/10, Batch 80/145, Loss: 0.1382
Epoch 8/10, Batch 90/145, Loss: 0.3636
Epoch 8/10, Batch 100/145, Loss: 0.2326
Epoch 8/10, Batch 110/145, Loss: 0.2682
Epoch 8/10, Batch 120/145, Loss: 0.1830
Epoch 8/10, Batch 130/145, Loss: 0.1027
Epoch 8/10, Batch 140/145, Loss: 0.2557
Epoch 8/10, Train Loss: 0.2162, Valid Loss: 0.2253
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1202
Epoch 9/10, Batch 20/145, Loss: 0.1280
Epoch 9/10, Batch 30/145, Loss: 0.1734
Epoch 9/10, Batch 40/145, Loss: 0.2159
Epoch 9/10, Batch 50/145, Loss: 0.1404
Epoch 9/10, Batch 60/145, Loss: 0.1507
Epoch 9/10, Batch 70/145, Loss: 0.4761
Epoch 9/10, Batch 80/145, Loss: 0.2752
Epoch 9/10, Batch 90/145, Loss: 0.0829
Epoch 9/10, Batch 100/145, Loss: 0.2304
Epoch 9/10, Batch 110/145, Loss: 0.2164
Epoch 9/10, Batch 120/145, Loss: 0.3225
Epoch 9/10, Batch 130/145, Loss: 0.1854
Epoch 9/10, Batch 140/145, Loss: 0.0859
Epoch 9/10, Train Loss: 0.2094, Valid Loss: 0.2191
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1864
Epoch 10/10, Batch 20/145, Loss: 0.1064
Epoch 10/10, Batch 30/145, Loss: 0.1534
Epoch 10/10, Batch 40/145, Loss: 0.2784
Epoch 10/10, Batch 50/145, Loss: 0.1161
Epoch 10/10, Batch 60/145, Loss: 0.1477
Epoch 10/10, Batch 70/145, Loss: 0.1928
Epoch 10/10, Batch 80/145, Loss: 0.3372
Epoch 10/10, Batch 90/145, Loss: 0.1026
Epoch 10/10, Batch 100/145, Loss: 0.1802
Epoch 10/10, Batch 110/145, Loss: 0.2647
Epoch 10/10, Batch 120/145, Loss: 0.2725
Epoch 10/10, Batch 130/145, Loss: 0.3576
Epoch 10/10, Batch 140/145, Loss: 0.2467
Epoch 10/10, Train Loss: 0.1968, Valid Loss: 0.2177
Model saved!
Accuracy: 0.9159
Precision: 0.9132
Recall: 0.9159
F1-score: 0.9142
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4047
Epoch 1/10, Batch 20/145, Loss: 0.8469
Epoch 1/10, Batch 30/145, Loss: 0.8518
Epoch 1/10, Batch 40/145, Loss: 0.8858
Epoch 1/10, Batch 50/145, Loss: 0.5705
Epoch 1/10, Batch 60/145, Loss: 0.5913
Epoch 1/10, Batch 70/145, Loss: 0.7582
Epoch 1/10, Batch 80/145, Loss: 0.6212
Epoch 1/10, Batch 90/145, Loss: 0.5432
Epoch 1/10, Batch 100/145, Loss: 0.5052
Epoch 1/10, Batch 110/145, Loss: 0.3932
Epoch 1/10, Batch 120/145, Loss: 0.5651
Epoch 1/10, Batch 130/145, Loss: 0.3563
Epoch 1/10, Batch 140/145, Loss: 0.2599
Epoch 1/10, Train Loss: 0.6859, Valid Loss: 0.3860
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3695
Epoch 2/10, Batch 20/145, Loss: 0.4923
Epoch 2/10, Batch 30/145, Loss: 0.3540
Epoch 2/10, Batch 40/145, Loss: 0.3919
Epoch 2/10, Batch 50/145, Loss: 0.3240
Epoch 2/10, Batch 60/145, Loss: 0.4362
Epoch 2/10, Batch 70/145, Loss: 0.4720
Epoch 2/10, Batch 80/145, Loss: 0.4783
Epoch 2/10, Batch 90/145, Loss: 0.1619
Epoch 2/10, Batch 100/145, Loss: 0.2356
Epoch 2/10, Batch 110/145, Loss: 0.2001
Epoch 2/10, Batch 120/145, Loss: 0.4675
Epoch 2/10, Batch 130/145, Loss: 0.2515
Epoch 2/10, Batch 140/145, Loss: 0.2260
Epoch 2/10, Train Loss: 0.3603, Valid Loss: 0.2890
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1727
Epoch 3/10, Batch 20/145, Loss: 0.3279
Epoch 3/10, Batch 30/145, Loss: 0.1869
Epoch 3/10, Batch 40/145, Loss: 0.4755
Epoch 3/10, Batch 50/145, Loss: 0.1960
Epoch 3/10, Batch 60/145, Loss: 0.3171
Epoch 3/10, Batch 70/145, Loss: 0.1277
Epoch 3/10, Batch 80/145, Loss: 0.2190
Epoch 3/10, Batch 90/145, Loss: 0.5722
Epoch 3/10, Batch 100/145, Loss: 0.4898
Epoch 3/10, Batch 110/145, Loss: 0.2677
Epoch 3/10, Batch 120/145, Loss: 0.2026
Epoch 3/10, Batch 130/145, Loss: 0.2177
Epoch 3/10, Batch 140/145, Loss: 0.2826
Epoch 3/10, Train Loss: 0.3028, Valid Loss: 0.2632
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2309
Epoch 4/10, Batch 20/145, Loss: 0.1571
Epoch 4/10, Batch 30/145, Loss: 0.3342
Epoch 4/10, Batch 40/145, Loss: 0.3155
Epoch 4/10, Batch 50/145, Loss: 0.2004
Epoch 4/10, Batch 60/145, Loss: 0.2152
Epoch 4/10, Batch 70/145, Loss: 0.1917
Epoch 4/10, Batch 80/145, Loss: 0.2942
Epoch 4/10, Batch 90/145, Loss: 0.2959
Epoch 4/10, Batch 100/145, Loss: 0.1790
Epoch 4/10, Batch 110/145, Loss: 0.1500
Epoch 4/10, Batch 120/145, Loss: 0.1652
Epoch 4/10, Batch 130/145, Loss: 0.2222
Epoch 4/10, Batch 140/145, Loss: 0.3312
Epoch 4/10, Train Loss: 0.2621, Valid Loss: 0.2480
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1608
Epoch 5/10, Batch 20/145, Loss: 0.3419
Epoch 5/10, Batch 30/145, Loss: 0.1220
Epoch 5/10, Batch 40/145, Loss: 0.1922
Epoch 5/10, Batch 50/145, Loss: 0.1153
Epoch 5/10, Batch 60/145, Loss: 0.2473
Epoch 5/10, Batch 70/145, Loss: 0.4653
Epoch 5/10, Batch 80/145, Loss: 0.4748
Epoch 5/10, Batch 90/145, Loss: 0.1385
Epoch 5/10, Batch 100/145, Loss: 0.3940
Epoch 5/10, Batch 110/145, Loss: 0.1141
Epoch 5/10, Batch 120/145, Loss: 0.2490
Epoch 5/10, Batch 130/145, Loss: 0.1591
Epoch 5/10, Batch 140/145, Loss: 0.2982
Epoch 5/10, Train Loss: 0.2329, Valid Loss: 0.2355
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2281
Epoch 6/10, Batch 20/145, Loss: 0.3686
Epoch 6/10, Batch 30/145, Loss: 0.3040
Epoch 6/10, Batch 40/145, Loss: 0.1169
Epoch 6/10, Batch 50/145, Loss: 0.3192
Epoch 6/10, Batch 60/145, Loss: 0.1462
Epoch 6/10, Batch 70/145, Loss: 0.3533
Epoch 6/10, Batch 80/145, Loss: 0.3132
Epoch 6/10, Batch 90/145, Loss: 0.2721
Epoch 6/10, Batch 100/145, Loss: 0.1212
Epoch 6/10, Batch 110/145, Loss: 0.1022
Epoch 6/10, Batch 120/145, Loss: 0.1387
Epoch 6/10, Batch 130/145, Loss: 0.0796
Epoch 6/10, Batch 140/145, Loss: 0.4189
Epoch 6/10, Train Loss: 0.2238, Valid Loss: 0.2368
Epoch 7/10, Batch 10/145, Loss: 0.3155
Epoch 7/10, Batch 20/145, Loss: 0.1871
Epoch 7/10, Batch 30/145, Loss: 0.1901
Epoch 7/10, Batch 40/145, Loss: 0.2817
Epoch 7/10, Batch 50/145, Loss: 0.1136
Epoch 7/10, Batch 60/145, Loss: 0.2823
Epoch 7/10, Batch 70/145, Loss: 0.2304
Epoch 7/10, Batch 80/145, Loss: 0.1533
Epoch 7/10, Batch 90/145, Loss: 0.3538
Epoch 7/10, Batch 100/145, Loss: 0.1435
Epoch 7/10, Batch 110/145, Loss: 0.3756
Epoch 7/10, Batch 120/145, Loss: 0.2660
Epoch 7/10, Batch 130/145, Loss: 0.1937
Epoch 7/10, Batch 140/145, Loss: 0.1517
Epoch 7/10, Train Loss: 0.2135, Valid Loss: 0.2243
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1579
Epoch 8/10, Batch 20/145, Loss: 0.1463
Epoch 8/10, Batch 30/145, Loss: 0.1829
Epoch 8/10, Batch 40/145, Loss: 0.2107
Epoch 8/10, Batch 50/145, Loss: 0.2784
Epoch 8/10, Batch 60/145, Loss: 0.1101
Epoch 8/10, Batch 70/145, Loss: 0.1308
Epoch 8/10, Batch 80/145, Loss: 0.2078
Epoch 8/10, Batch 90/145, Loss: 0.0999
Epoch 8/10, Batch 100/145, Loss: 0.2613
Epoch 8/10, Batch 110/145, Loss: 0.2454
Epoch 8/10, Batch 120/145, Loss: 0.1314
Epoch 8/10, Batch 130/145, Loss: 0.2258
Epoch 8/10, Batch 140/145, Loss: 0.1491
Epoch 8/10, Train Loss: 0.2068, Valid Loss: 0.2243
Epoch 9/10, Batch 10/145, Loss: 0.3597
Epoch 9/10, Batch 20/145, Loss: 0.1845
Epoch 9/10, Batch 30/145, Loss: 0.0983
Epoch 9/10, Batch 40/145, Loss: 0.1652
Epoch 9/10, Batch 50/145, Loss: 0.2541
Epoch 9/10, Batch 60/145, Loss: 0.1539
Epoch 9/10, Batch 70/145, Loss: 0.1543
Epoch 9/10, Batch 80/145, Loss: 0.1576
Epoch 9/10, Batch 90/145, Loss: 0.2564
Epoch 9/10, Batch 100/145, Loss: 0.2074
Epoch 9/10, Batch 110/145, Loss: 0.1898
Epoch 9/10, Batch 120/145, Loss: 0.1972
Epoch 9/10, Batch 130/145, Loss: 0.3513
Epoch 9/10, Batch 140/145, Loss: 0.2235
Epoch 9/10, Train Loss: 0.2065, Valid Loss: 0.2154
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1800
Epoch 10/10, Batch 20/145, Loss: 0.1685
Epoch 10/10, Batch 30/145, Loss: 0.0856
Epoch 10/10, Batch 40/145, Loss: 0.1062
Epoch 10/10, Batch 50/145, Loss: 0.1818
Epoch 10/10, Batch 60/145, Loss: 0.1315
Epoch 10/10, Batch 70/145, Loss: 0.1020
Epoch 10/10, Batch 80/145, Loss: 0.4474
Epoch 10/10, Batch 90/145, Loss: 0.1655
Epoch 10/10, Batch 100/145, Loss: 0.0883
Epoch 10/10, Batch 110/145, Loss: 0.2923
Epoch 10/10, Batch 120/145, Loss: 0.2619
Epoch 10/10, Batch 130/145, Loss: 0.1526
Epoch 10/10, Batch 140/145, Loss: 0.2016
Epoch 10/10, Train Loss: 0.1940, Valid Loss: 0.2110
Model saved!
Accuracy: 0.9241
Precision: 0.9235
Recall: 0.9241
F1-score: 0.9236
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4856
Epoch 1/10, Batch 20/145, Loss: 0.9218
Epoch 1/10, Batch 30/145, Loss: 0.8139
Epoch 1/10, Batch 40/145, Loss: 0.8543
Epoch 1/10, Batch 50/145, Loss: 0.6257
Epoch 1/10, Batch 60/145, Loss: 0.5105
Epoch 1/10, Batch 70/145, Loss: 0.7235
Epoch 1/10, Batch 80/145, Loss: 0.6043
Epoch 1/10, Batch 90/145, Loss: 0.7262
Epoch 1/10, Batch 100/145, Loss: 0.6395
Epoch 1/10, Batch 110/145, Loss: 0.3958
Epoch 1/10, Batch 120/145, Loss: 0.7376
Epoch 1/10, Batch 130/145, Loss: 0.3718
Epoch 1/10, Batch 140/145, Loss: 0.3879
Epoch 1/10, Train Loss: 0.6927, Valid Loss: 0.3683
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2498
Epoch 2/10, Batch 20/145, Loss: 0.5400
Epoch 2/10, Batch 30/145, Loss: 0.4530
Epoch 2/10, Batch 40/145, Loss: 0.3516
Epoch 2/10, Batch 50/145, Loss: 0.3719
Epoch 2/10, Batch 60/145, Loss: 0.3915
Epoch 2/10, Batch 70/145, Loss: 0.2571
Epoch 2/10, Batch 80/145, Loss: 0.3775
Epoch 2/10, Batch 90/145, Loss: 0.2552
Epoch 2/10, Batch 100/145, Loss: 0.2590
Epoch 2/10, Batch 110/145, Loss: 0.4055
Epoch 2/10, Batch 120/145, Loss: 0.3374
Epoch 2/10, Batch 130/145, Loss: 0.3950
Epoch 2/10, Batch 140/145, Loss: 0.1985
Epoch 2/10, Train Loss: 0.3664, Valid Loss: 0.2791
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2002
Epoch 3/10, Batch 20/145, Loss: 0.2367
Epoch 3/10, Batch 30/145, Loss: 0.2601
Epoch 3/10, Batch 40/145, Loss: 0.3355
Epoch 3/10, Batch 50/145, Loss: 0.2370
Epoch 3/10, Batch 60/145, Loss: 0.2750
Epoch 3/10, Batch 70/145, Loss: 0.2353
Epoch 3/10, Batch 80/145, Loss: 0.1777
Epoch 3/10, Batch 90/145, Loss: 0.3705
Epoch 3/10, Batch 100/145, Loss: 0.4277
Epoch 3/10, Batch 110/145, Loss: 0.2571
Epoch 3/10, Batch 120/145, Loss: 0.1602
Epoch 3/10, Batch 130/145, Loss: 0.1225
Epoch 3/10, Batch 140/145, Loss: 0.1771
Epoch 3/10, Train Loss: 0.3095, Valid Loss: 0.2609
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1827
Epoch 4/10, Batch 20/145, Loss: 0.1942
Epoch 4/10, Batch 30/145, Loss: 0.3219
Epoch 4/10, Batch 40/145, Loss: 0.2618
Epoch 4/10, Batch 50/145, Loss: 0.2487
Epoch 4/10, Batch 60/145, Loss: 0.1943
Epoch 4/10, Batch 70/145, Loss: 0.2686
Epoch 4/10, Batch 80/145, Loss: 0.2345
Epoch 4/10, Batch 90/145, Loss: 0.3764
Epoch 4/10, Batch 100/145, Loss: 0.1894
Epoch 4/10, Batch 110/145, Loss: 0.2670
Epoch 4/10, Batch 120/145, Loss: 0.1660
Epoch 4/10, Batch 130/145, Loss: 0.2052
Epoch 4/10, Batch 140/145, Loss: 0.1855
Epoch 4/10, Train Loss: 0.2698, Valid Loss: 0.2419
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3803
Epoch 5/10, Batch 20/145, Loss: 0.3437
Epoch 5/10, Batch 30/145, Loss: 0.1266
Epoch 5/10, Batch 40/145, Loss: 0.2019
Epoch 5/10, Batch 50/145, Loss: 0.2402
Epoch 5/10, Batch 60/145, Loss: 0.2188
Epoch 5/10, Batch 70/145, Loss: 0.3102
Epoch 5/10, Batch 80/145, Loss: 0.3297
Epoch 5/10, Batch 90/145, Loss: 0.1717
Epoch 5/10, Batch 100/145, Loss: 0.2740
Epoch 5/10, Batch 110/145, Loss: 0.1624
Epoch 5/10, Batch 120/145, Loss: 0.2791
Epoch 5/10, Batch 130/145, Loss: 0.3214
Epoch 5/10, Batch 140/145, Loss: 0.3077
Epoch 5/10, Train Loss: 0.2395, Valid Loss: 0.2378
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1799
Epoch 6/10, Batch 20/145, Loss: 0.2186
Epoch 6/10, Batch 30/145, Loss: 0.2263
Epoch 6/10, Batch 40/145, Loss: 0.2011
Epoch 6/10, Batch 50/145, Loss: 0.2744
Epoch 6/10, Batch 60/145, Loss: 0.1460
Epoch 6/10, Batch 70/145, Loss: 0.4997
Epoch 6/10, Batch 80/145, Loss: 0.2176
Epoch 6/10, Batch 90/145, Loss: 0.2451
Epoch 6/10, Batch 100/145, Loss: 0.2586
Epoch 6/10, Batch 110/145, Loss: 0.2233
Epoch 6/10, Batch 120/145, Loss: 0.1760
Epoch 6/10, Batch 130/145, Loss: 0.1480
Epoch 6/10, Batch 140/145, Loss: 0.2397
Epoch 6/10, Train Loss: 0.2291, Valid Loss: 0.2330
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.4623
Epoch 7/10, Batch 20/145, Loss: 0.2161
Epoch 7/10, Batch 30/145, Loss: 0.1177
Epoch 7/10, Batch 40/145, Loss: 0.4189
Epoch 7/10, Batch 50/145, Loss: 0.1591
Epoch 7/10, Batch 60/145, Loss: 0.1680
Epoch 7/10, Batch 70/145, Loss: 0.3820
Epoch 7/10, Batch 80/145, Loss: 0.1022
Epoch 7/10, Batch 90/145, Loss: 0.2650
Epoch 7/10, Batch 100/145, Loss: 0.1103
Epoch 7/10, Batch 110/145, Loss: 0.2041
Epoch 7/10, Batch 120/145, Loss: 0.1451
Epoch 7/10, Batch 130/145, Loss: 0.2386
Epoch 7/10, Batch 140/145, Loss: 0.2268
Epoch 7/10, Train Loss: 0.2257, Valid Loss: 0.2367
Epoch 8/10, Batch 10/145, Loss: 0.1971
Epoch 8/10, Batch 20/145, Loss: 0.1583
Epoch 8/10, Batch 30/145, Loss: 0.1391
Epoch 8/10, Batch 40/145, Loss: 0.2313
Epoch 8/10, Batch 50/145, Loss: 0.2213
Epoch 8/10, Batch 60/145, Loss: 0.2005
Epoch 8/10, Batch 70/145, Loss: 0.1039
Epoch 8/10, Batch 80/145, Loss: 0.2162
Epoch 8/10, Batch 90/145, Loss: 0.1276
Epoch 8/10, Batch 100/145, Loss: 0.1527
Epoch 8/10, Batch 110/145, Loss: 0.2657
Epoch 8/10, Batch 120/145, Loss: 0.2327
Epoch 8/10, Batch 130/145, Loss: 0.1352
Epoch 8/10, Batch 140/145, Loss: 0.1924
Epoch 8/10, Train Loss: 0.2116, Valid Loss: 0.2064
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3220
Epoch 9/10, Batch 20/145, Loss: 0.1537
Epoch 9/10, Batch 30/145, Loss: 0.0937
Epoch 9/10, Batch 40/145, Loss: 0.0769
Epoch 9/10, Batch 50/145, Loss: 0.1053
Epoch 9/10, Batch 60/145, Loss: 0.2355
Epoch 9/10, Batch 70/145, Loss: 0.3218
Epoch 9/10, Batch 80/145, Loss: 0.2608
Epoch 9/10, Batch 90/145, Loss: 0.1662
Epoch 9/10, Batch 100/145, Loss: 0.1760
Epoch 9/10, Batch 110/145, Loss: 0.0741
Epoch 9/10, Batch 120/145, Loss: 0.1209
Epoch 9/10, Batch 130/145, Loss: 0.2815
Epoch 9/10, Batch 140/145, Loss: 0.1901
Epoch 9/10, Train Loss: 0.2009, Valid Loss: 0.2017
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1262
Epoch 10/10, Batch 20/145, Loss: 0.1139
Epoch 10/10, Batch 30/145, Loss: 0.0542
Epoch 10/10, Batch 40/145, Loss: 0.1602
Epoch 10/10, Batch 50/145, Loss: 0.1921
Epoch 10/10, Batch 60/145, Loss: 0.1747
Epoch 10/10, Batch 70/145, Loss: 0.1644
Epoch 10/10, Batch 80/145, Loss: 0.6893
Epoch 10/10, Batch 90/145, Loss: 0.1657
Epoch 10/10, Batch 100/145, Loss: 0.0908
Epoch 10/10, Batch 110/145, Loss: 0.1224
Epoch 10/10, Batch 120/145, Loss: 0.2698
Epoch 10/10, Batch 130/145, Loss: 0.1806
Epoch 10/10, Batch 140/145, Loss: 0.2938
Epoch 10/10, Train Loss: 0.1985, Valid Loss: 0.2117
Accuracy: 0.9217
Precision: 0.9198
Recall: 0.9217
F1-score: 0.9203
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4810
Epoch 1/10, Batch 20/145, Loss: 0.9012
Epoch 1/10, Batch 30/145, Loss: 0.9258
Epoch 1/10, Batch 40/145, Loss: 0.8049
Epoch 1/10, Batch 50/145, Loss: 0.5487
Epoch 1/10, Batch 60/145, Loss: 0.4838
Epoch 1/10, Batch 70/145, Loss: 0.7530
Epoch 1/10, Batch 80/145, Loss: 0.6121
Epoch 1/10, Batch 90/145, Loss: 0.4981
Epoch 1/10, Batch 100/145, Loss: 0.7012
Epoch 1/10, Batch 110/145, Loss: 0.3536
Epoch 1/10, Batch 120/145, Loss: 0.4625
Epoch 1/10, Batch 130/145, Loss: 0.4940
Epoch 1/10, Batch 140/145, Loss: 0.4662
Epoch 1/10, Train Loss: 0.6869, Valid Loss: 0.3774
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3923
Epoch 2/10, Batch 20/145, Loss: 0.4621
Epoch 2/10, Batch 30/145, Loss: 0.3574
Epoch 2/10, Batch 40/145, Loss: 0.3663
Epoch 2/10, Batch 50/145, Loss: 0.3505
Epoch 2/10, Batch 60/145, Loss: 0.3816
Epoch 2/10, Batch 70/145, Loss: 0.5291
Epoch 2/10, Batch 80/145, Loss: 0.2442
Epoch 2/10, Batch 90/145, Loss: 0.1791
Epoch 2/10, Batch 100/145, Loss: 0.2575
Epoch 2/10, Batch 110/145, Loss: 0.2675
Epoch 2/10, Batch 120/145, Loss: 0.4957
Epoch 2/10, Batch 130/145, Loss: 0.3279
Epoch 2/10, Batch 140/145, Loss: 0.3148
Epoch 2/10, Train Loss: 0.3580, Valid Loss: 0.2878
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3209
Epoch 3/10, Batch 20/145, Loss: 0.2253
Epoch 3/10, Batch 30/145, Loss: 0.2551
Epoch 3/10, Batch 40/145, Loss: 0.3503
Epoch 3/10, Batch 50/145, Loss: 0.2101
Epoch 3/10, Batch 60/145, Loss: 0.2435
Epoch 3/10, Batch 70/145, Loss: 0.2415
Epoch 3/10, Batch 80/145, Loss: 0.2468
Epoch 3/10, Batch 90/145, Loss: 0.4443
Epoch 3/10, Batch 100/145, Loss: 0.3578
Epoch 3/10, Batch 110/145, Loss: 0.1827
Epoch 3/10, Batch 120/145, Loss: 0.1024
Epoch 3/10, Batch 130/145, Loss: 0.1619
Epoch 3/10, Batch 140/145, Loss: 0.1995
Epoch 3/10, Train Loss: 0.3061, Valid Loss: 0.2603
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2812
Epoch 4/10, Batch 20/145, Loss: 0.2939
Epoch 4/10, Batch 30/145, Loss: 0.2889
Epoch 4/10, Batch 40/145, Loss: 0.3960
Epoch 4/10, Batch 50/145, Loss: 0.1600
Epoch 4/10, Batch 60/145, Loss: 0.2641
Epoch 4/10, Batch 70/145, Loss: 0.3080
Epoch 4/10, Batch 80/145, Loss: 0.2783
Epoch 4/10, Batch 90/145, Loss: 0.2126
Epoch 4/10, Batch 100/145, Loss: 0.2726
Epoch 4/10, Batch 110/145, Loss: 0.2541
Epoch 4/10, Batch 120/145, Loss: 0.2172
Epoch 4/10, Batch 130/145, Loss: 0.1520
Epoch 4/10, Batch 140/145, Loss: 0.1890
Epoch 4/10, Train Loss: 0.2600, Valid Loss: 0.2479
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2141
Epoch 5/10, Batch 20/145, Loss: 0.2126
Epoch 5/10, Batch 30/145, Loss: 0.2216
Epoch 5/10, Batch 40/145, Loss: 0.2319
Epoch 5/10, Batch 50/145, Loss: 0.2127
Epoch 5/10, Batch 60/145, Loss: 0.3145
Epoch 5/10, Batch 70/145, Loss: 0.2359
Epoch 5/10, Batch 80/145, Loss: 0.2412
Epoch 5/10, Batch 90/145, Loss: 0.1700
Epoch 5/10, Batch 100/145, Loss: 0.3517
Epoch 5/10, Batch 110/145, Loss: 0.0906
Epoch 5/10, Batch 120/145, Loss: 0.3078
Epoch 5/10, Batch 130/145, Loss: 0.1736
Epoch 5/10, Batch 140/145, Loss: 0.1756
Epoch 5/10, Train Loss: 0.2408, Valid Loss: 0.2388
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1701
Epoch 6/10, Batch 20/145, Loss: 0.1540
Epoch 6/10, Batch 30/145, Loss: 0.1595
Epoch 6/10, Batch 40/145, Loss: 0.2415
Epoch 6/10, Batch 50/145, Loss: 0.2547
Epoch 6/10, Batch 60/145, Loss: 0.1742
Epoch 6/10, Batch 70/145, Loss: 0.2181
Epoch 6/10, Batch 80/145, Loss: 0.1113
Epoch 6/10, Batch 90/145, Loss: 0.1604
Epoch 6/10, Batch 100/145, Loss: 0.1669
Epoch 6/10, Batch 110/145, Loss: 0.0922
Epoch 6/10, Batch 120/145, Loss: 0.1852
Epoch 6/10, Batch 130/145, Loss: 0.1441
Epoch 6/10, Batch 140/145, Loss: 0.2759
Epoch 6/10, Train Loss: 0.2258, Valid Loss: 0.2301
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2238
Epoch 7/10, Batch 20/145, Loss: 0.1000
Epoch 7/10, Batch 30/145, Loss: 0.1590
Epoch 7/10, Batch 40/145, Loss: 0.4475
Epoch 7/10, Batch 50/145, Loss: 0.2389
Epoch 7/10, Batch 60/145, Loss: 0.1736
Epoch 7/10, Batch 70/145, Loss: 0.1749
Epoch 7/10, Batch 80/145, Loss: 0.1875
Epoch 7/10, Batch 90/145, Loss: 0.2214
Epoch 7/10, Batch 100/145, Loss: 0.1090
Epoch 7/10, Batch 110/145, Loss: 0.4122
Epoch 7/10, Batch 120/145, Loss: 0.1869
Epoch 7/10, Batch 130/145, Loss: 0.2211
Epoch 7/10, Batch 140/145, Loss: 0.1642
Epoch 7/10, Train Loss: 0.2176, Valid Loss: 0.2262
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1695
Epoch 8/10, Batch 20/145, Loss: 0.2221
Epoch 8/10, Batch 30/145, Loss: 0.1133
Epoch 8/10, Batch 40/145, Loss: 0.1936
Epoch 8/10, Batch 50/145, Loss: 0.2781
Epoch 8/10, Batch 60/145, Loss: 0.2190
Epoch 8/10, Batch 70/145, Loss: 0.1354
Epoch 8/10, Batch 80/145, Loss: 0.1160
Epoch 8/10, Batch 90/145, Loss: 0.0929
Epoch 8/10, Batch 100/145, Loss: 0.2412
Epoch 8/10, Batch 110/145, Loss: 0.2720
Epoch 8/10, Batch 120/145, Loss: 0.3801
Epoch 8/10, Batch 130/145, Loss: 0.1930
Epoch 8/10, Batch 140/145, Loss: 0.2489
Epoch 8/10, Train Loss: 0.2100, Valid Loss: 0.2257
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2358
Epoch 9/10, Batch 20/145, Loss: 0.1843
Epoch 9/10, Batch 30/145, Loss: 0.0641
Epoch 9/10, Batch 40/145, Loss: 0.2800
Epoch 9/10, Batch 50/145, Loss: 0.0994
Epoch 9/10, Batch 60/145, Loss: 0.1537
Epoch 9/10, Batch 70/145, Loss: 0.1848
Epoch 9/10, Batch 80/145, Loss: 0.2999
Epoch 9/10, Batch 90/145, Loss: 0.1376
Epoch 9/10, Batch 100/145, Loss: 0.1938
Epoch 9/10, Batch 110/145, Loss: 0.1137
Epoch 9/10, Batch 120/145, Loss: 0.2460
Epoch 9/10, Batch 130/145, Loss: 0.3205
Epoch 9/10, Batch 140/145, Loss: 0.2834
Epoch 9/10, Train Loss: 0.2020, Valid Loss: 0.2183
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2504
Epoch 10/10, Batch 20/145, Loss: 0.1832
Epoch 10/10, Batch 30/145, Loss: 0.1370
Epoch 10/10, Batch 40/145, Loss: 0.1670
Epoch 10/10, Batch 50/145, Loss: 0.2098
Epoch 10/10, Batch 60/145, Loss: 0.2278
Epoch 10/10, Batch 70/145, Loss: 0.1875
Epoch 10/10, Batch 80/145, Loss: 0.2197
Epoch 10/10, Batch 90/145, Loss: 0.1521
Epoch 10/10, Batch 100/145, Loss: 0.1171
Epoch 10/10, Batch 110/145, Loss: 0.3126
Epoch 10/10, Batch 120/145, Loss: 0.3812
Epoch 10/10, Batch 130/145, Loss: 0.2792
Epoch 10/10, Batch 140/145, Loss: 0.1082
Epoch 10/10, Train Loss: 0.1974, Valid Loss: 0.2138
Model saved!
Accuracy: 0.9171
Precision: 0.9153
Recall: 0.9171
F1-score: 0.9154
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4904
Epoch 1/10, Batch 20/145, Loss: 0.8411
Epoch 1/10, Batch 30/145, Loss: 0.8819
Epoch 1/10, Batch 40/145, Loss: 0.8147
Epoch 1/10, Batch 50/145, Loss: 0.5762
Epoch 1/10, Batch 60/145, Loss: 0.5692
Epoch 1/10, Batch 70/145, Loss: 0.5384
Epoch 1/10, Batch 80/145, Loss: 0.5433
Epoch 1/10, Batch 90/145, Loss: 0.5388
Epoch 1/10, Batch 100/145, Loss: 0.5274
Epoch 1/10, Batch 110/145, Loss: 0.4354
Epoch 1/10, Batch 120/145, Loss: 0.6546
Epoch 1/10, Batch 130/145, Loss: 0.3991
Epoch 1/10, Batch 140/145, Loss: 0.4184
Epoch 1/10, Train Loss: 0.6803, Valid Loss: 0.3747
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4316
Epoch 2/10, Batch 20/145, Loss: 0.6212
Epoch 2/10, Batch 30/145, Loss: 0.3382
Epoch 2/10, Batch 40/145, Loss: 0.5855
Epoch 2/10, Batch 50/145, Loss: 0.3241
Epoch 2/10, Batch 60/145, Loss: 0.4398
Epoch 2/10, Batch 70/145, Loss: 0.3553
Epoch 2/10, Batch 80/145, Loss: 0.1841
Epoch 2/10, Batch 90/145, Loss: 0.3331
Epoch 2/10, Batch 100/145, Loss: 0.2539
Epoch 2/10, Batch 110/145, Loss: 0.3023
Epoch 2/10, Batch 120/145, Loss: 0.2850
Epoch 2/10, Batch 130/145, Loss: 0.3037
Epoch 2/10, Batch 140/145, Loss: 0.1845
Epoch 2/10, Train Loss: 0.3630, Valid Loss: 0.3006
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2332
Epoch 3/10, Batch 20/145, Loss: 0.2957
Epoch 3/10, Batch 30/145, Loss: 0.1921
Epoch 3/10, Batch 40/145, Loss: 0.2762
Epoch 3/10, Batch 50/145, Loss: 0.2198
Epoch 3/10, Batch 60/145, Loss: 0.4018
Epoch 3/10, Batch 70/145, Loss: 0.2174
Epoch 3/10, Batch 80/145, Loss: 0.3574
Epoch 3/10, Batch 90/145, Loss: 0.2956
Epoch 3/10, Batch 100/145, Loss: 0.1997
Epoch 3/10, Batch 110/145, Loss: 0.1869
Epoch 3/10, Batch 120/145, Loss: 0.1822
Epoch 3/10, Batch 130/145, Loss: 0.2547
Epoch 3/10, Batch 140/145, Loss: 0.2550
Epoch 3/10, Train Loss: 0.2991, Valid Loss: 0.2579
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1838
Epoch 4/10, Batch 20/145, Loss: 0.2735
Epoch 4/10, Batch 30/145, Loss: 0.2417
Epoch 4/10, Batch 40/145, Loss: 0.3820
Epoch 4/10, Batch 50/145, Loss: 0.1931
Epoch 4/10, Batch 60/145, Loss: 0.2743
Epoch 4/10, Batch 70/145, Loss: 0.2410
Epoch 4/10, Batch 80/145, Loss: 0.2186
Epoch 4/10, Batch 90/145, Loss: 0.2012
Epoch 4/10, Batch 100/145, Loss: 0.2836
Epoch 4/10, Batch 110/145, Loss: 0.1376
Epoch 4/10, Batch 120/145, Loss: 0.3637
Epoch 4/10, Batch 130/145, Loss: 0.1629
Epoch 4/10, Batch 140/145, Loss: 0.2287
Epoch 4/10, Train Loss: 0.2578, Valid Loss: 0.2492
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3605
Epoch 5/10, Batch 20/145, Loss: 0.3198
Epoch 5/10, Batch 30/145, Loss: 0.1443
Epoch 5/10, Batch 40/145, Loss: 0.2628
Epoch 5/10, Batch 50/145, Loss: 0.0722
Epoch 5/10, Batch 60/145, Loss: 0.2083
Epoch 5/10, Batch 70/145, Loss: 0.2007
Epoch 5/10, Batch 80/145, Loss: 0.1541
Epoch 5/10, Batch 90/145, Loss: 0.1282
Epoch 5/10, Batch 100/145, Loss: 0.1891
Epoch 5/10, Batch 110/145, Loss: 0.0661
Epoch 5/10, Batch 120/145, Loss: 0.1861
Epoch 5/10, Batch 130/145, Loss: 0.3430
Epoch 5/10, Batch 140/145, Loss: 0.4105
Epoch 5/10, Train Loss: 0.2296, Valid Loss: 0.2300
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2416
Epoch 6/10, Batch 20/145, Loss: 0.3401
Epoch 6/10, Batch 30/145, Loss: 0.2582
Epoch 6/10, Batch 40/145, Loss: 0.1720
Epoch 6/10, Batch 50/145, Loss: 0.2772
Epoch 6/10, Batch 60/145, Loss: 0.1187
Epoch 6/10, Batch 70/145, Loss: 0.2814
Epoch 6/10, Batch 80/145, Loss: 0.2607
Epoch 6/10, Batch 90/145, Loss: 0.3184
Epoch 6/10, Batch 100/145, Loss: 0.2532
Epoch 6/10, Batch 110/145, Loss: 0.3131
Epoch 6/10, Batch 120/145, Loss: 0.3411
Epoch 6/10, Batch 130/145, Loss: 0.1811
Epoch 6/10, Batch 140/145, Loss: 0.2784
Epoch 6/10, Train Loss: 0.2239, Valid Loss: 0.2219
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2387
Epoch 7/10, Batch 20/145, Loss: 0.2133
Epoch 7/10, Batch 30/145, Loss: 0.1587
Epoch 7/10, Batch 40/145, Loss: 0.4938
Epoch 7/10, Batch 50/145, Loss: 0.1013
Epoch 7/10, Batch 60/145, Loss: 0.2058
Epoch 7/10, Batch 70/145, Loss: 0.1550
Epoch 7/10, Batch 80/145, Loss: 0.0797
Epoch 7/10, Batch 90/145, Loss: 0.2151
Epoch 7/10, Batch 100/145, Loss: 0.1362
Epoch 7/10, Batch 110/145, Loss: 0.3814
Epoch 7/10, Batch 120/145, Loss: 0.1311
Epoch 7/10, Batch 130/145, Loss: 0.3477
Epoch 7/10, Batch 140/145, Loss: 0.1121
Epoch 7/10, Train Loss: 0.2135, Valid Loss: 0.2245
Epoch 8/10, Batch 10/145, Loss: 0.1201
Epoch 8/10, Batch 20/145, Loss: 0.1064
Epoch 8/10, Batch 30/145, Loss: 0.2798
Epoch 8/10, Batch 40/145, Loss: 0.1616
Epoch 8/10, Batch 50/145, Loss: 0.2322
Epoch 8/10, Batch 60/145, Loss: 0.2162
Epoch 8/10, Batch 70/145, Loss: 0.2107
Epoch 8/10, Batch 80/145, Loss: 0.1770
Epoch 8/10, Batch 90/145, Loss: 0.0761
Epoch 8/10, Batch 100/145, Loss: 0.3126
Epoch 8/10, Batch 110/145, Loss: 0.3656
Epoch 8/10, Batch 120/145, Loss: 0.1157
Epoch 8/10, Batch 130/145, Loss: 0.1762
Epoch 8/10, Batch 140/145, Loss: 0.1805
Epoch 8/10, Train Loss: 0.2076, Valid Loss: 0.2215
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2310
Epoch 9/10, Batch 20/145, Loss: 0.0711
Epoch 9/10, Batch 30/145, Loss: 0.1301
Epoch 9/10, Batch 40/145, Loss: 0.3039
Epoch 9/10, Batch 50/145, Loss: 0.1047
Epoch 9/10, Batch 60/145, Loss: 0.1281
Epoch 9/10, Batch 70/145, Loss: 0.1654
Epoch 9/10, Batch 80/145, Loss: 0.2789
Epoch 9/10, Batch 90/145, Loss: 0.0757
Epoch 9/10, Batch 100/145, Loss: 0.2837
Epoch 9/10, Batch 110/145, Loss: 0.1201
Epoch 9/10, Batch 120/145, Loss: 0.2550
Epoch 9/10, Batch 130/145, Loss: 0.2259
Epoch 9/10, Batch 140/145, Loss: 0.1718
Epoch 9/10, Train Loss: 0.1960, Valid Loss: 0.2153
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1360
Epoch 10/10, Batch 20/145, Loss: 0.1244
Epoch 10/10, Batch 30/145, Loss: 0.1856
Epoch 10/10, Batch 40/145, Loss: 0.1710
Epoch 10/10, Batch 50/145, Loss: 0.2300
Epoch 10/10, Batch 60/145, Loss: 0.1620
Epoch 10/10, Batch 70/145, Loss: 0.1106
Epoch 10/10, Batch 80/145, Loss: 0.3667
Epoch 10/10, Batch 90/145, Loss: 0.1617
Epoch 10/10, Batch 100/145, Loss: 0.1099
Epoch 10/10, Batch 110/145, Loss: 0.4034
Epoch 10/10, Batch 120/145, Loss: 0.2056
Epoch 10/10, Batch 130/145, Loss: 0.2250
Epoch 10/10, Batch 140/145, Loss: 0.2723
Epoch 10/10, Train Loss: 0.1880, Valid Loss: 0.2111
Model saved!
Accuracy: 0.9229
Precision: 0.9211
Recall: 0.9229
F1-score: 0.9216
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5577
Epoch 1/10, Batch 20/145, Loss: 0.9989
Epoch 1/10, Batch 30/145, Loss: 0.8848
Epoch 1/10, Batch 40/145, Loss: 0.8387
Epoch 1/10, Batch 50/145, Loss: 0.5950
Epoch 1/10, Batch 60/145, Loss: 0.6101
Epoch 1/10, Batch 70/145, Loss: 0.5135
Epoch 1/10, Batch 80/145, Loss: 0.4764
Epoch 1/10, Batch 90/145, Loss: 0.6058
Epoch 1/10, Batch 100/145, Loss: 0.5604
Epoch 1/10, Batch 110/145, Loss: 0.3723
Epoch 1/10, Batch 120/145, Loss: 0.6342
Epoch 1/10, Batch 130/145, Loss: 0.3515
Epoch 1/10, Batch 140/145, Loss: 0.6067
Epoch 1/10, Train Loss: 0.6815, Valid Loss: 0.3707
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3081
Epoch 2/10, Batch 20/145, Loss: 0.5961
Epoch 2/10, Batch 30/145, Loss: 0.4077
Epoch 2/10, Batch 40/145, Loss: 0.6340
Epoch 2/10, Batch 50/145, Loss: 0.3107
Epoch 2/10, Batch 60/145, Loss: 0.5281
Epoch 2/10, Batch 70/145, Loss: 0.4268
Epoch 2/10, Batch 80/145, Loss: 0.3704
Epoch 2/10, Batch 90/145, Loss: 0.3762
Epoch 2/10, Batch 100/145, Loss: 0.2313
Epoch 2/10, Batch 110/145, Loss: 0.1854
Epoch 2/10, Batch 120/145, Loss: 0.3178
Epoch 2/10, Batch 130/145, Loss: 0.2457
Epoch 2/10, Batch 140/145, Loss: 0.2746
Epoch 2/10, Train Loss: 0.3542, Valid Loss: 0.2884
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2300
Epoch 3/10, Batch 20/145, Loss: 0.5342
Epoch 3/10, Batch 30/145, Loss: 0.2982
Epoch 3/10, Batch 40/145, Loss: 0.2254
Epoch 3/10, Batch 50/145, Loss: 0.2487
Epoch 3/10, Batch 60/145, Loss: 0.2878
Epoch 3/10, Batch 70/145, Loss: 0.1813
Epoch 3/10, Batch 80/145, Loss: 0.2638
Epoch 3/10, Batch 90/145, Loss: 0.5166
Epoch 3/10, Batch 100/145, Loss: 0.2173
Epoch 3/10, Batch 110/145, Loss: 0.1824
Epoch 3/10, Batch 120/145, Loss: 0.1292
Epoch 3/10, Batch 130/145, Loss: 0.1405
Epoch 3/10, Batch 140/145, Loss: 0.1999
Epoch 3/10, Train Loss: 0.3026, Valid Loss: 0.2557
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1545
Epoch 4/10, Batch 20/145, Loss: 0.2744
Epoch 4/10, Batch 30/145, Loss: 0.3152
Epoch 4/10, Batch 40/145, Loss: 0.3000
Epoch 4/10, Batch 50/145, Loss: 0.2313
Epoch 4/10, Batch 60/145, Loss: 0.2686
Epoch 4/10, Batch 70/145, Loss: 0.2693
Epoch 4/10, Batch 80/145, Loss: 0.2344
Epoch 4/10, Batch 90/145, Loss: 0.2963
Epoch 4/10, Batch 100/145, Loss: 0.2188
Epoch 4/10, Batch 110/145, Loss: 0.2474
Epoch 4/10, Batch 120/145, Loss: 0.1661
Epoch 4/10, Batch 130/145, Loss: 0.2870
Epoch 4/10, Batch 140/145, Loss: 0.1802
Epoch 4/10, Train Loss: 0.2638, Valid Loss: 0.2441
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2572
Epoch 5/10, Batch 20/145, Loss: 0.2327
Epoch 5/10, Batch 30/145, Loss: 0.1630
Epoch 5/10, Batch 40/145, Loss: 0.2535
Epoch 5/10, Batch 50/145, Loss: 0.2449
Epoch 5/10, Batch 60/145, Loss: 0.1245
Epoch 5/10, Batch 70/145, Loss: 0.2493
Epoch 5/10, Batch 80/145, Loss: 0.1983
Epoch 5/10, Batch 90/145, Loss: 0.1191
Epoch 5/10, Batch 100/145, Loss: 0.2506
Epoch 5/10, Batch 110/145, Loss: 0.1155
Epoch 5/10, Batch 120/145, Loss: 0.1807
Epoch 5/10, Batch 130/145, Loss: 0.3088
Epoch 5/10, Batch 140/145, Loss: 0.1852
Epoch 5/10, Train Loss: 0.2430, Valid Loss: 0.2299
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1421
Epoch 6/10, Batch 20/145, Loss: 0.2070
Epoch 6/10, Batch 30/145, Loss: 0.3123
Epoch 6/10, Batch 40/145, Loss: 0.2589
Epoch 6/10, Batch 50/145, Loss: 0.2731
Epoch 6/10, Batch 60/145, Loss: 0.1972
Epoch 6/10, Batch 70/145, Loss: 0.2959
Epoch 6/10, Batch 80/145, Loss: 0.2882
Epoch 6/10, Batch 90/145, Loss: 0.1559
Epoch 6/10, Batch 100/145, Loss: 0.2244
Epoch 6/10, Batch 110/145, Loss: 0.1889
Epoch 6/10, Batch 120/145, Loss: 0.2921
Epoch 6/10, Batch 130/145, Loss: 0.2196
Epoch 6/10, Batch 140/145, Loss: 0.2573
Epoch 6/10, Train Loss: 0.2280, Valid Loss: 0.2340
Epoch 7/10, Batch 10/145, Loss: 0.2656
Epoch 7/10, Batch 20/145, Loss: 0.2936
Epoch 7/10, Batch 30/145, Loss: 0.1482
Epoch 7/10, Batch 40/145, Loss: 0.4440
Epoch 7/10, Batch 50/145, Loss: 0.1602
Epoch 7/10, Batch 60/145, Loss: 0.0857
Epoch 7/10, Batch 70/145, Loss: 0.1332
Epoch 7/10, Batch 80/145, Loss: 0.3172
Epoch 7/10, Batch 90/145, Loss: 0.2785
Epoch 7/10, Batch 100/145, Loss: 0.1630
Epoch 7/10, Batch 110/145, Loss: 0.2242
Epoch 7/10, Batch 120/145, Loss: 0.1378
Epoch 7/10, Batch 130/145, Loss: 0.2688
Epoch 7/10, Batch 140/145, Loss: 0.2167
Epoch 7/10, Train Loss: 0.2161, Valid Loss: 0.2288
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1268
Epoch 8/10, Batch 20/145, Loss: 0.1861
Epoch 8/10, Batch 30/145, Loss: 0.0969
Epoch 8/10, Batch 40/145, Loss: 0.2699
Epoch 8/10, Batch 50/145, Loss: 0.2729
Epoch 8/10, Batch 60/145, Loss: 0.1625
Epoch 8/10, Batch 70/145, Loss: 0.2267
Epoch 8/10, Batch 80/145, Loss: 0.3137
Epoch 8/10, Batch 90/145, Loss: 0.1522
Epoch 8/10, Batch 100/145, Loss: 0.2401
Epoch 8/10, Batch 110/145, Loss: 0.2268
Epoch 8/10, Batch 120/145, Loss: 0.3040
Epoch 8/10, Batch 130/145, Loss: 0.0932
Epoch 8/10, Batch 140/145, Loss: 0.2877
Epoch 8/10, Train Loss: 0.2062, Valid Loss: 0.2232
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2816
Epoch 9/10, Batch 20/145, Loss: 0.1063
Epoch 9/10, Batch 30/145, Loss: 0.1488
Epoch 9/10, Batch 40/145, Loss: 0.1698
Epoch 9/10, Batch 50/145, Loss: 0.2153
Epoch 9/10, Batch 60/145, Loss: 0.2258
Epoch 9/10, Batch 70/145, Loss: 0.2002
Epoch 9/10, Batch 80/145, Loss: 0.3582
Epoch 9/10, Batch 90/145, Loss: 0.2124
Epoch 9/10, Batch 100/145, Loss: 0.1473
Epoch 9/10, Batch 110/145, Loss: 0.0721
Epoch 9/10, Batch 120/145, Loss: 0.2677
Epoch 9/10, Batch 130/145, Loss: 0.3561
Epoch 9/10, Batch 140/145, Loss: 0.2302
Epoch 9/10, Train Loss: 0.2012, Valid Loss: 0.2105
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0820
Epoch 10/10, Batch 20/145, Loss: 0.1757
Epoch 10/10, Batch 30/145, Loss: 0.1945
Epoch 10/10, Batch 40/145, Loss: 0.2632
Epoch 10/10, Batch 50/145, Loss: 0.1209
Epoch 10/10, Batch 60/145, Loss: 0.3429
Epoch 10/10, Batch 70/145, Loss: 0.0991
Epoch 10/10, Batch 80/145, Loss: 0.4579
Epoch 10/10, Batch 90/145, Loss: 0.2827
Epoch 10/10, Batch 100/145, Loss: 0.3083
Epoch 10/10, Batch 110/145, Loss: 0.2524
Epoch 10/10, Batch 120/145, Loss: 0.2312
Epoch 10/10, Batch 130/145, Loss: 0.1574
Epoch 10/10, Batch 140/145, Loss: 0.1871
Epoch 10/10, Train Loss: 0.1959, Valid Loss: 0.2105
Accuracy: 0.9194
Precision: 0.9168
Recall: 0.9194
F1-score: 0.9176
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5104
Epoch 1/10, Batch 20/145, Loss: 0.8825
Epoch 1/10, Batch 30/145, Loss: 0.9122
Epoch 1/10, Batch 40/145, Loss: 0.8251
Epoch 1/10, Batch 50/145, Loss: 0.6286
Epoch 1/10, Batch 60/145, Loss: 0.5342
Epoch 1/10, Batch 70/145, Loss: 0.6498
Epoch 1/10, Batch 80/145, Loss: 0.4142
Epoch 1/10, Batch 90/145, Loss: 0.5635
Epoch 1/10, Batch 100/145, Loss: 0.6366
Epoch 1/10, Batch 110/145, Loss: 0.3902
Epoch 1/10, Batch 120/145, Loss: 0.6199
Epoch 1/10, Batch 130/145, Loss: 0.4105
Epoch 1/10, Batch 140/145, Loss: 0.4094
Epoch 1/10, Train Loss: 0.6846, Valid Loss: 0.3778
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2580
Epoch 2/10, Batch 20/145, Loss: 0.5050
Epoch 2/10, Batch 30/145, Loss: 0.4534
Epoch 2/10, Batch 40/145, Loss: 0.5104
Epoch 2/10, Batch 50/145, Loss: 0.5558
Epoch 2/10, Batch 60/145, Loss: 0.4384
Epoch 2/10, Batch 70/145, Loss: 0.3755
Epoch 2/10, Batch 80/145, Loss: 0.2957
Epoch 2/10, Batch 90/145, Loss: 0.2147
Epoch 2/10, Batch 100/145, Loss: 0.2171
Epoch 2/10, Batch 110/145, Loss: 0.1873
Epoch 2/10, Batch 120/145, Loss: 0.3012
Epoch 2/10, Batch 130/145, Loss: 0.3689
Epoch 2/10, Batch 140/145, Loss: 0.2302
Epoch 2/10, Train Loss: 0.3590, Valid Loss: 0.3026
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3978
Epoch 3/10, Batch 20/145, Loss: 0.1909
Epoch 3/10, Batch 30/145, Loss: 0.2358
Epoch 3/10, Batch 40/145, Loss: 0.1795
Epoch 3/10, Batch 50/145, Loss: 0.3214
Epoch 3/10, Batch 60/145, Loss: 0.2786
Epoch 3/10, Batch 70/145, Loss: 0.2799
Epoch 3/10, Batch 80/145, Loss: 0.1180
Epoch 3/10, Batch 90/145, Loss: 0.3192
Epoch 3/10, Batch 100/145, Loss: 0.2699
Epoch 3/10, Batch 110/145, Loss: 0.2554
Epoch 3/10, Batch 120/145, Loss: 0.1128
Epoch 3/10, Batch 130/145, Loss: 0.2555
Epoch 3/10, Batch 140/145, Loss: 0.1132
Epoch 3/10, Train Loss: 0.3033, Valid Loss: 0.2682
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1553
Epoch 4/10, Batch 20/145, Loss: 0.2399
Epoch 4/10, Batch 30/145, Loss: 0.3065
Epoch 4/10, Batch 40/145, Loss: 0.3970
Epoch 4/10, Batch 50/145, Loss: 0.1782
Epoch 4/10, Batch 60/145, Loss: 0.3342
Epoch 4/10, Batch 70/145, Loss: 0.3452
Epoch 4/10, Batch 80/145, Loss: 0.2865
Epoch 4/10, Batch 90/145, Loss: 0.2596
Epoch 4/10, Batch 100/145, Loss: 0.2497
Epoch 4/10, Batch 110/145, Loss: 0.2380
Epoch 4/10, Batch 120/145, Loss: 0.1376
Epoch 4/10, Batch 130/145, Loss: 0.1313
Epoch 4/10, Batch 140/145, Loss: 0.1286
Epoch 4/10, Train Loss: 0.2647, Valid Loss: 0.2733
Epoch 5/10, Batch 10/145, Loss: 0.2034
Epoch 5/10, Batch 20/145, Loss: 0.1879
Epoch 5/10, Batch 30/145, Loss: 0.1977
Epoch 5/10, Batch 40/145, Loss: 0.3742
Epoch 5/10, Batch 50/145, Loss: 0.1922
Epoch 5/10, Batch 60/145, Loss: 0.2175
Epoch 5/10, Batch 70/145, Loss: 0.2735
Epoch 5/10, Batch 80/145, Loss: 0.3101
Epoch 5/10, Batch 90/145, Loss: 0.1973
Epoch 5/10, Batch 100/145, Loss: 0.2418
Epoch 5/10, Batch 110/145, Loss: 0.1732
Epoch 5/10, Batch 120/145, Loss: 0.1770
Epoch 5/10, Batch 130/145, Loss: 0.1734
Epoch 5/10, Batch 140/145, Loss: 0.2483
Epoch 5/10, Train Loss: 0.2393, Valid Loss: 0.2532
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1177
Epoch 6/10, Batch 20/145, Loss: 0.1697
Epoch 6/10, Batch 30/145, Loss: 0.2616
Epoch 6/10, Batch 40/145, Loss: 0.2388
Epoch 6/10, Batch 50/145, Loss: 0.2656
Epoch 6/10, Batch 60/145, Loss: 0.2027
Epoch 6/10, Batch 70/145, Loss: 0.2332
Epoch 6/10, Batch 80/145, Loss: 0.2700
Epoch 6/10, Batch 90/145, Loss: 0.1919
Epoch 6/10, Batch 100/145, Loss: 0.1419
Epoch 6/10, Batch 110/145, Loss: 0.1680
Epoch 6/10, Batch 120/145, Loss: 0.1437
Epoch 6/10, Batch 130/145, Loss: 0.1526
Epoch 6/10, Batch 140/145, Loss: 0.2154
Epoch 6/10, Train Loss: 0.2257, Valid Loss: 0.2444
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2486
Epoch 7/10, Batch 20/145, Loss: 0.2805
Epoch 7/10, Batch 30/145, Loss: 0.0782
Epoch 7/10, Batch 40/145, Loss: 0.4435
Epoch 7/10, Batch 50/145, Loss: 0.2060
Epoch 7/10, Batch 60/145, Loss: 0.1415
Epoch 7/10, Batch 70/145, Loss: 0.2007
Epoch 7/10, Batch 80/145, Loss: 0.1639
Epoch 7/10, Batch 90/145, Loss: 0.2385
Epoch 7/10, Batch 100/145, Loss: 0.1324
Epoch 7/10, Batch 110/145, Loss: 0.1491
Epoch 7/10, Batch 120/145, Loss: 0.1887
Epoch 7/10, Batch 130/145, Loss: 0.0932
Epoch 7/10, Batch 140/145, Loss: 0.0702
Epoch 7/10, Train Loss: 0.2111, Valid Loss: 0.2390
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0670
Epoch 8/10, Batch 20/145, Loss: 0.2940
Epoch 8/10, Batch 30/145, Loss: 0.1668
Epoch 8/10, Batch 40/145, Loss: 0.2285
Epoch 8/10, Batch 50/145, Loss: 0.2983
Epoch 8/10, Batch 60/145, Loss: 0.1939
Epoch 8/10, Batch 70/145, Loss: 0.0556
Epoch 8/10, Batch 80/145, Loss: 0.1321
Epoch 8/10, Batch 90/145, Loss: 0.3117
Epoch 8/10, Batch 100/145, Loss: 0.1852
Epoch 8/10, Batch 110/145, Loss: 0.2596
Epoch 8/10, Batch 120/145, Loss: 0.2149
Epoch 8/10, Batch 130/145, Loss: 0.1370
Epoch 8/10, Batch 140/145, Loss: 0.2815
Epoch 8/10, Train Loss: 0.2086, Valid Loss: 0.2431
Epoch 9/10, Batch 10/145, Loss: 0.3124
Epoch 9/10, Batch 20/145, Loss: 0.1651
Epoch 9/10, Batch 30/145, Loss: 0.1143
Epoch 9/10, Batch 40/145, Loss: 0.1085
Epoch 9/10, Batch 50/145, Loss: 0.2112
Epoch 9/10, Batch 60/145, Loss: 0.1307
Epoch 9/10, Batch 70/145, Loss: 0.1617
Epoch 9/10, Batch 80/145, Loss: 0.1275
Epoch 9/10, Batch 90/145, Loss: 0.2490
Epoch 9/10, Batch 100/145, Loss: 0.2220
Epoch 9/10, Batch 110/145, Loss: 0.1032
Epoch 9/10, Batch 120/145, Loss: 0.2695
Epoch 9/10, Batch 130/145, Loss: 0.1955
Epoch 9/10, Batch 140/145, Loss: 0.3128
Epoch 9/10, Train Loss: 0.2004, Valid Loss: 0.2299
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0843
Epoch 10/10, Batch 20/145, Loss: 0.1955
Epoch 10/10, Batch 30/145, Loss: 0.1340
Epoch 10/10, Batch 40/145, Loss: 0.2443
Epoch 10/10, Batch 50/145, Loss: 0.2628
Epoch 10/10, Batch 60/145, Loss: 0.1358
Epoch 10/10, Batch 70/145, Loss: 0.1999
Epoch 10/10, Batch 80/145, Loss: 0.3632
Epoch 10/10, Batch 90/145, Loss: 0.1884
Epoch 10/10, Batch 100/145, Loss: 0.0818
Epoch 10/10, Batch 110/145, Loss: 0.1984
Epoch 10/10, Batch 120/145, Loss: 0.1956
Epoch 10/10, Batch 130/145, Loss: 0.1469
Epoch 10/10, Batch 140/145, Loss: 0.1866
Epoch 10/10, Train Loss: 0.1943, Valid Loss: 0.2310
Accuracy: 0.9171
Precision: 0.9146
Recall: 0.9171
F1-score: 0.9148
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5092
Epoch 1/10, Batch 20/145, Loss: 0.8809
Epoch 1/10, Batch 30/145, Loss: 0.8754
Epoch 1/10, Batch 40/145, Loss: 0.7985
Epoch 1/10, Batch 50/145, Loss: 0.5381
Epoch 1/10, Batch 60/145, Loss: 0.5129
Epoch 1/10, Batch 70/145, Loss: 0.5657
Epoch 1/10, Batch 80/145, Loss: 0.5196
Epoch 1/10, Batch 90/145, Loss: 0.4338
Epoch 1/10, Batch 100/145, Loss: 0.5065
Epoch 1/10, Batch 110/145, Loss: 0.3784
Epoch 1/10, Batch 120/145, Loss: 0.6221
Epoch 1/10, Batch 130/145, Loss: 0.4346
Epoch 1/10, Batch 140/145, Loss: 0.4339
Epoch 1/10, Train Loss: 0.6881, Valid Loss: 0.3749
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3777
Epoch 2/10, Batch 20/145, Loss: 0.5445
Epoch 2/10, Batch 30/145, Loss: 0.3073
Epoch 2/10, Batch 40/145, Loss: 0.5627
Epoch 2/10, Batch 50/145, Loss: 0.2508
Epoch 2/10, Batch 60/145, Loss: 0.3953
Epoch 2/10, Batch 70/145, Loss: 0.3588
Epoch 2/10, Batch 80/145, Loss: 0.5807
Epoch 2/10, Batch 90/145, Loss: 0.2393
Epoch 2/10, Batch 100/145, Loss: 0.3659
Epoch 2/10, Batch 110/145, Loss: 0.2711
Epoch 2/10, Batch 120/145, Loss: 0.3065
Epoch 2/10, Batch 130/145, Loss: 0.2726
Epoch 2/10, Batch 140/145, Loss: 0.2578
Epoch 2/10, Train Loss: 0.3644, Valid Loss: 0.2875
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2419
Epoch 3/10, Batch 20/145, Loss: 0.3118
Epoch 3/10, Batch 30/145, Loss: 0.3303
Epoch 3/10, Batch 40/145, Loss: 0.2282
Epoch 3/10, Batch 50/145, Loss: 0.2135
Epoch 3/10, Batch 60/145, Loss: 0.3660
Epoch 3/10, Batch 70/145, Loss: 0.3020
Epoch 3/10, Batch 80/145, Loss: 0.3631
Epoch 3/10, Batch 90/145, Loss: 0.5425
Epoch 3/10, Batch 100/145, Loss: 0.2224
Epoch 3/10, Batch 110/145, Loss: 0.2875
Epoch 3/10, Batch 120/145, Loss: 0.2256
Epoch 3/10, Batch 130/145, Loss: 0.1779
Epoch 3/10, Batch 140/145, Loss: 0.1907
Epoch 3/10, Train Loss: 0.3076, Valid Loss: 0.2580
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1375
Epoch 4/10, Batch 20/145, Loss: 0.2188
Epoch 4/10, Batch 30/145, Loss: 0.1887
Epoch 4/10, Batch 40/145, Loss: 0.2922
Epoch 4/10, Batch 50/145, Loss: 0.1850
Epoch 4/10, Batch 60/145, Loss: 0.2945
Epoch 4/10, Batch 70/145, Loss: 0.1876
Epoch 4/10, Batch 80/145, Loss: 0.1724
Epoch 4/10, Batch 90/145, Loss: 0.2704
Epoch 4/10, Batch 100/145, Loss: 0.3636
Epoch 4/10, Batch 110/145, Loss: 0.2169
Epoch 4/10, Batch 120/145, Loss: 0.2804
Epoch 4/10, Batch 130/145, Loss: 0.3060
Epoch 4/10, Batch 140/145, Loss: 0.1751
Epoch 4/10, Train Loss: 0.2663, Valid Loss: 0.2495
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2284
Epoch 5/10, Batch 20/145, Loss: 0.2765
Epoch 5/10, Batch 30/145, Loss: 0.2204
Epoch 5/10, Batch 40/145, Loss: 0.3470
Epoch 5/10, Batch 50/145, Loss: 0.1277
Epoch 5/10, Batch 60/145, Loss: 0.1587
Epoch 5/10, Batch 70/145, Loss: 0.1734
Epoch 5/10, Batch 80/145, Loss: 0.2531
Epoch 5/10, Batch 90/145, Loss: 0.1578
Epoch 5/10, Batch 100/145, Loss: 0.2572
Epoch 5/10, Batch 110/145, Loss: 0.1872
Epoch 5/10, Batch 120/145, Loss: 0.1067
Epoch 5/10, Batch 130/145, Loss: 0.0928
Epoch 5/10, Batch 140/145, Loss: 0.3322
Epoch 5/10, Train Loss: 0.2376, Valid Loss: 0.2288
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1565
Epoch 6/10, Batch 20/145, Loss: 0.1764
Epoch 6/10, Batch 30/145, Loss: 0.2981
Epoch 6/10, Batch 40/145, Loss: 0.1274
Epoch 6/10, Batch 50/145, Loss: 0.3601
Epoch 6/10, Batch 60/145, Loss: 0.2457
Epoch 6/10, Batch 70/145, Loss: 0.2724
Epoch 6/10, Batch 80/145, Loss: 0.2644
Epoch 6/10, Batch 90/145, Loss: 0.1988
Epoch 6/10, Batch 100/145, Loss: 0.0762
Epoch 6/10, Batch 110/145, Loss: 0.3074
Epoch 6/10, Batch 120/145, Loss: 0.1375
Epoch 6/10, Batch 130/145, Loss: 0.2003
Epoch 6/10, Batch 140/145, Loss: 0.2707
Epoch 6/10, Train Loss: 0.2307, Valid Loss: 0.2210
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1962
Epoch 7/10, Batch 20/145, Loss: 0.1757
Epoch 7/10, Batch 30/145, Loss: 0.2000
Epoch 7/10, Batch 40/145, Loss: 0.4425
Epoch 7/10, Batch 50/145, Loss: 0.1682
Epoch 7/10, Batch 60/145, Loss: 0.1513
Epoch 7/10, Batch 70/145, Loss: 0.3777
Epoch 7/10, Batch 80/145, Loss: 0.0704
Epoch 7/10, Batch 90/145, Loss: 0.3250
Epoch 7/10, Batch 100/145, Loss: 0.1199
Epoch 7/10, Batch 110/145, Loss: 0.4110
Epoch 7/10, Batch 120/145, Loss: 0.2212
Epoch 7/10, Batch 130/145, Loss: 0.1065
Epoch 7/10, Batch 140/145, Loss: 0.1200
Epoch 7/10, Train Loss: 0.2203, Valid Loss: 0.2121
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2259
Epoch 8/10, Batch 20/145, Loss: 0.1857
Epoch 8/10, Batch 30/145, Loss: 0.1299
Epoch 8/10, Batch 40/145, Loss: 0.2651
Epoch 8/10, Batch 50/145, Loss: 0.2214
Epoch 8/10, Batch 60/145, Loss: 0.1094
Epoch 8/10, Batch 70/145, Loss: 0.2257
Epoch 8/10, Batch 80/145, Loss: 0.0785
Epoch 8/10, Batch 90/145, Loss: 0.2218
Epoch 8/10, Batch 100/145, Loss: 0.1928
Epoch 8/10, Batch 110/145, Loss: 0.1233
Epoch 8/10, Batch 120/145, Loss: 0.1083
Epoch 8/10, Batch 130/145, Loss: 0.2258
Epoch 8/10, Batch 140/145, Loss: 0.1813
Epoch 8/10, Train Loss: 0.2104, Valid Loss: 0.2106
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2876
Epoch 9/10, Batch 20/145, Loss: 0.0859
Epoch 9/10, Batch 30/145, Loss: 0.1110
Epoch 9/10, Batch 40/145, Loss: 0.1864
Epoch 9/10, Batch 50/145, Loss: 0.2530
Epoch 9/10, Batch 60/145, Loss: 0.0982
Epoch 9/10, Batch 70/145, Loss: 0.1954
Epoch 9/10, Batch 80/145, Loss: 0.1672
Epoch 9/10, Batch 90/145, Loss: 0.0716
Epoch 9/10, Batch 100/145, Loss: 0.1171
Epoch 9/10, Batch 110/145, Loss: 0.0883
Epoch 9/10, Batch 120/145, Loss: 0.1442
Epoch 9/10, Batch 130/145, Loss: 0.1174
Epoch 9/10, Batch 140/145, Loss: 0.0815
Epoch 9/10, Train Loss: 0.1990, Valid Loss: 0.2083
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1341
Epoch 10/10, Batch 20/145, Loss: 0.1670
Epoch 10/10, Batch 30/145, Loss: 0.1461
Epoch 10/10, Batch 40/145, Loss: 0.1326
Epoch 10/10, Batch 50/145, Loss: 0.4043
Epoch 10/10, Batch 60/145, Loss: 0.1648
Epoch 10/10, Batch 70/145, Loss: 0.1143
Epoch 10/10, Batch 80/145, Loss: 0.3656
Epoch 10/10, Batch 90/145, Loss: 0.1971
Epoch 10/10, Batch 100/145, Loss: 0.1374
Epoch 10/10, Batch 110/145, Loss: 0.2090
Epoch 10/10, Batch 120/145, Loss: 0.0947
Epoch 10/10, Batch 130/145, Loss: 0.2378
Epoch 10/10, Batch 140/145, Loss: 0.1394
Epoch 10/10, Train Loss: 0.1917, Valid Loss: 0.2043
Model saved!
Accuracy: 0.9241
Precision: 0.9225
Recall: 0.9241
F1-score: 0.9231
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4970
Epoch 1/10, Batch 20/145, Loss: 0.9067
Epoch 1/10, Batch 30/145, Loss: 0.9141
Epoch 1/10, Batch 40/145, Loss: 0.7919
Epoch 1/10, Batch 50/145, Loss: 0.5680
Epoch 1/10, Batch 60/145, Loss: 0.5506
Epoch 1/10, Batch 70/145, Loss: 0.5635
Epoch 1/10, Batch 80/145, Loss: 0.5591
Epoch 1/10, Batch 90/145, Loss: 0.5202
Epoch 1/10, Batch 100/145, Loss: 0.5596
Epoch 1/10, Batch 110/145, Loss: 0.4163
Epoch 1/10, Batch 120/145, Loss: 0.6325
Epoch 1/10, Batch 130/145, Loss: 0.3933
Epoch 1/10, Batch 140/145, Loss: 0.7214
Epoch 1/10, Train Loss: 0.6918, Valid Loss: 0.3634
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3502
Epoch 2/10, Batch 20/145, Loss: 0.4648
Epoch 2/10, Batch 30/145, Loss: 0.3249
Epoch 2/10, Batch 40/145, Loss: 0.4722
Epoch 2/10, Batch 50/145, Loss: 0.2152
Epoch 2/10, Batch 60/145, Loss: 0.4058
Epoch 2/10, Batch 70/145, Loss: 0.5901
Epoch 2/10, Batch 80/145, Loss: 0.5427
Epoch 2/10, Batch 90/145, Loss: 0.2052
Epoch 2/10, Batch 100/145, Loss: 0.2832
Epoch 2/10, Batch 110/145, Loss: 0.3599
Epoch 2/10, Batch 120/145, Loss: 0.3122
Epoch 2/10, Batch 130/145, Loss: 0.3527
Epoch 2/10, Batch 140/145, Loss: 0.2912
Epoch 2/10, Train Loss: 0.3652, Valid Loss: 0.2781
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2017
Epoch 3/10, Batch 20/145, Loss: 0.3055
Epoch 3/10, Batch 30/145, Loss: 0.1811
Epoch 3/10, Batch 40/145, Loss: 0.2454
Epoch 3/10, Batch 50/145, Loss: 0.2297
Epoch 3/10, Batch 60/145, Loss: 0.3832
Epoch 3/10, Batch 70/145, Loss: 0.2147
Epoch 3/10, Batch 80/145, Loss: 0.2561
Epoch 3/10, Batch 90/145, Loss: 0.5172
Epoch 3/10, Batch 100/145, Loss: 0.3215
Epoch 3/10, Batch 110/145, Loss: 0.2189
Epoch 3/10, Batch 120/145, Loss: 0.2384
Epoch 3/10, Batch 130/145, Loss: 0.2022
Epoch 3/10, Batch 140/145, Loss: 0.1651
Epoch 3/10, Train Loss: 0.3154, Valid Loss: 0.2426
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2064
Epoch 4/10, Batch 20/145, Loss: 0.3436
Epoch 4/10, Batch 30/145, Loss: 0.2593
Epoch 4/10, Batch 40/145, Loss: 0.4576
Epoch 4/10, Batch 50/145, Loss: 0.1765
Epoch 4/10, Batch 60/145, Loss: 0.2334
Epoch 4/10, Batch 70/145, Loss: 0.2086
Epoch 4/10, Batch 80/145, Loss: 0.2880
Epoch 4/10, Batch 90/145, Loss: 0.2207
Epoch 4/10, Batch 100/145, Loss: 0.2687
Epoch 4/10, Batch 110/145, Loss: 0.3672
Epoch 4/10, Batch 120/145, Loss: 0.1381
Epoch 4/10, Batch 130/145, Loss: 0.2593
Epoch 4/10, Batch 140/145, Loss: 0.2046
Epoch 4/10, Train Loss: 0.2725, Valid Loss: 0.2424
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1960
Epoch 5/10, Batch 20/145, Loss: 0.2721
Epoch 5/10, Batch 30/145, Loss: 0.2223
Epoch 5/10, Batch 40/145, Loss: 0.2606
Epoch 5/10, Batch 50/145, Loss: 0.2193
Epoch 5/10, Batch 60/145, Loss: 0.1661
Epoch 5/10, Batch 70/145, Loss: 0.2823
Epoch 5/10, Batch 80/145, Loss: 0.2118
Epoch 5/10, Batch 90/145, Loss: 0.3056
Epoch 5/10, Batch 100/145, Loss: 0.2187
Epoch 5/10, Batch 110/145, Loss: 0.2203
Epoch 5/10, Batch 120/145, Loss: 0.1490
Epoch 5/10, Batch 130/145, Loss: 0.1633
Epoch 5/10, Batch 140/145, Loss: 0.3245
Epoch 5/10, Train Loss: 0.2447, Valid Loss: 0.2244
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1754
Epoch 6/10, Batch 20/145, Loss: 0.1735
Epoch 6/10, Batch 30/145, Loss: 0.2678
Epoch 6/10, Batch 40/145, Loss: 0.2119
Epoch 6/10, Batch 50/145, Loss: 0.3508
Epoch 6/10, Batch 60/145, Loss: 0.1724
Epoch 6/10, Batch 70/145, Loss: 0.1919
Epoch 6/10, Batch 80/145, Loss: 0.2832
Epoch 6/10, Batch 90/145, Loss: 0.3375
Epoch 6/10, Batch 100/145, Loss: 0.1892
Epoch 6/10, Batch 110/145, Loss: 0.0607
Epoch 6/10, Batch 120/145, Loss: 0.3416
Epoch 6/10, Batch 130/145, Loss: 0.1075
Epoch 6/10, Batch 140/145, Loss: 0.1739
Epoch 6/10, Train Loss: 0.2393, Valid Loss: 0.2298
Epoch 7/10, Batch 10/145, Loss: 0.1308
Epoch 7/10, Batch 20/145, Loss: 0.1505
Epoch 7/10, Batch 30/145, Loss: 0.1987
Epoch 7/10, Batch 40/145, Loss: 0.3833
Epoch 7/10, Batch 50/145, Loss: 0.2846
Epoch 7/10, Batch 60/145, Loss: 0.2616
Epoch 7/10, Batch 70/145, Loss: 0.1471
Epoch 7/10, Batch 80/145, Loss: 0.1274
Epoch 7/10, Batch 90/145, Loss: 0.2905
Epoch 7/10, Batch 100/145, Loss: 0.1830
Epoch 7/10, Batch 110/145, Loss: 0.2976
Epoch 7/10, Batch 120/145, Loss: 0.1313
Epoch 7/10, Batch 130/145, Loss: 0.2131
Epoch 7/10, Batch 140/145, Loss: 0.1862
Epoch 7/10, Train Loss: 0.2203, Valid Loss: 0.2184
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2940
Epoch 8/10, Batch 20/145, Loss: 0.1859
Epoch 8/10, Batch 30/145, Loss: 0.1479
Epoch 8/10, Batch 40/145, Loss: 0.1182
Epoch 8/10, Batch 50/145, Loss: 0.2620
Epoch 8/10, Batch 60/145, Loss: 0.1458
Epoch 8/10, Batch 70/145, Loss: 0.1740
Epoch 8/10, Batch 80/145, Loss: 0.1952
Epoch 8/10, Batch 90/145, Loss: 0.1879
Epoch 8/10, Batch 100/145, Loss: 0.2823
Epoch 8/10, Batch 110/145, Loss: 0.2447
Epoch 8/10, Batch 120/145, Loss: 0.1450
Epoch 8/10, Batch 130/145, Loss: 0.0793
Epoch 8/10, Batch 140/145, Loss: 0.2337
Epoch 8/10, Train Loss: 0.2146, Valid Loss: 0.2187
Epoch 9/10, Batch 10/145, Loss: 0.1609
Epoch 9/10, Batch 20/145, Loss: 0.1511
Epoch 9/10, Batch 30/145, Loss: 0.2765
Epoch 9/10, Batch 40/145, Loss: 0.1286
Epoch 9/10, Batch 50/145, Loss: 0.2342
Epoch 9/10, Batch 60/145, Loss: 0.2668
Epoch 9/10, Batch 70/145, Loss: 0.1857
Epoch 9/10, Batch 80/145, Loss: 0.2364
Epoch 9/10, Batch 90/145, Loss: 0.1590
Epoch 9/10, Batch 100/145, Loss: 0.5015
Epoch 9/10, Batch 110/145, Loss: 0.1011
Epoch 9/10, Batch 120/145, Loss: 0.3983
Epoch 9/10, Batch 130/145, Loss: 0.2381
Epoch 9/10, Batch 140/145, Loss: 0.1682
Epoch 9/10, Train Loss: 0.2099, Valid Loss: 0.2018
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2621
Epoch 10/10, Batch 20/145, Loss: 0.0772
Epoch 10/10, Batch 30/145, Loss: 0.1739
Epoch 10/10, Batch 40/145, Loss: 0.1545
Epoch 10/10, Batch 50/145, Loss: 0.2044
Epoch 10/10, Batch 60/145, Loss: 0.1972
Epoch 10/10, Batch 70/145, Loss: 0.1154
Epoch 10/10, Batch 80/145, Loss: 0.3089
Epoch 10/10, Batch 90/145, Loss: 0.2952
Epoch 10/10, Batch 100/145, Loss: 0.0670
Epoch 10/10, Batch 110/145, Loss: 0.1569
Epoch 10/10, Batch 120/145, Loss: 0.2551
Epoch 10/10, Batch 130/145, Loss: 0.1926
Epoch 10/10, Batch 140/145, Loss: 0.1813
Epoch 10/10, Train Loss: 0.2027, Valid Loss: 0.2017
Model saved!
Accuracy: 0.9182
Precision: 0.9159
Recall: 0.9182
F1-score: 0.9166
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4870
Epoch 1/10, Batch 20/145, Loss: 0.8998
Epoch 1/10, Batch 30/145, Loss: 0.8347
Epoch 1/10, Batch 40/145, Loss: 0.8454
Epoch 1/10, Batch 50/145, Loss: 0.6572
Epoch 1/10, Batch 60/145, Loss: 0.5965
Epoch 1/10, Batch 70/145, Loss: 0.6566
Epoch 1/10, Batch 80/145, Loss: 0.6309
Epoch 1/10, Batch 90/145, Loss: 0.5525
Epoch 1/10, Batch 100/145, Loss: 0.6195
Epoch 1/10, Batch 110/145, Loss: 0.4377
Epoch 1/10, Batch 120/145, Loss: 0.7151
Epoch 1/10, Batch 130/145, Loss: 0.5091
Epoch 1/10, Batch 140/145, Loss: 0.5108
Epoch 1/10, Train Loss: 0.6927, Valid Loss: 0.3702
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3325
Epoch 2/10, Batch 20/145, Loss: 0.4153
Epoch 2/10, Batch 30/145, Loss: 0.5152
Epoch 2/10, Batch 40/145, Loss: 0.4187
Epoch 2/10, Batch 50/145, Loss: 0.2876
Epoch 2/10, Batch 60/145, Loss: 0.4494
Epoch 2/10, Batch 70/145, Loss: 0.4031
Epoch 2/10, Batch 80/145, Loss: 0.3426
Epoch 2/10, Batch 90/145, Loss: 0.2768
Epoch 2/10, Batch 100/145, Loss: 0.1995
Epoch 2/10, Batch 110/145, Loss: 0.4356
Epoch 2/10, Batch 120/145, Loss: 0.2296
Epoch 2/10, Batch 130/145, Loss: 0.3005
Epoch 2/10, Batch 140/145, Loss: 0.2480
Epoch 2/10, Train Loss: 0.3593, Valid Loss: 0.2784
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1455
Epoch 3/10, Batch 20/145, Loss: 0.3569
Epoch 3/10, Batch 30/145, Loss: 0.2908
Epoch 3/10, Batch 40/145, Loss: 0.2288
Epoch 3/10, Batch 50/145, Loss: 0.2361
Epoch 3/10, Batch 60/145, Loss: 0.1884
Epoch 3/10, Batch 70/145, Loss: 0.2701
Epoch 3/10, Batch 80/145, Loss: 0.3087
Epoch 3/10, Batch 90/145, Loss: 0.6344
Epoch 3/10, Batch 100/145, Loss: 0.2216
Epoch 3/10, Batch 110/145, Loss: 0.2561
Epoch 3/10, Batch 120/145, Loss: 0.2718
Epoch 3/10, Batch 130/145, Loss: 0.2395
Epoch 3/10, Batch 140/145, Loss: 0.2311
Epoch 3/10, Train Loss: 0.3091, Valid Loss: 0.2427
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2576
Epoch 4/10, Batch 20/145, Loss: 0.2485
Epoch 4/10, Batch 30/145, Loss: 0.1785
Epoch 4/10, Batch 40/145, Loss: 0.2341
Epoch 4/10, Batch 50/145, Loss: 0.2657
Epoch 4/10, Batch 60/145, Loss: 0.1803
Epoch 4/10, Batch 70/145, Loss: 0.2045
Epoch 4/10, Batch 80/145, Loss: 0.1696
Epoch 4/10, Batch 90/145, Loss: 0.2631
Epoch 4/10, Batch 100/145, Loss: 0.2345
Epoch 4/10, Batch 110/145, Loss: 0.2190
Epoch 4/10, Batch 120/145, Loss: 0.1697
Epoch 4/10, Batch 130/145, Loss: 0.2299
Epoch 4/10, Batch 140/145, Loss: 0.3034
Epoch 4/10, Train Loss: 0.2608, Valid Loss: 0.2266
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3546
Epoch 5/10, Batch 20/145, Loss: 0.1397
Epoch 5/10, Batch 30/145, Loss: 0.1833
Epoch 5/10, Batch 40/145, Loss: 0.1517
Epoch 5/10, Batch 50/145, Loss: 0.1402
Epoch 5/10, Batch 60/145, Loss: 0.2535
Epoch 5/10, Batch 70/145, Loss: 0.1442
Epoch 5/10, Batch 80/145, Loss: 0.4960
Epoch 5/10, Batch 90/145, Loss: 0.3683
Epoch 5/10, Batch 100/145, Loss: 0.1435
Epoch 5/10, Batch 110/145, Loss: 0.1205
Epoch 5/10, Batch 120/145, Loss: 0.2317
Epoch 5/10, Batch 130/145, Loss: 0.3333
Epoch 5/10, Batch 140/145, Loss: 0.3120
Epoch 5/10, Train Loss: 0.2391, Valid Loss: 0.2185
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1590
Epoch 6/10, Batch 20/145, Loss: 0.2023
Epoch 6/10, Batch 30/145, Loss: 0.2797
Epoch 6/10, Batch 40/145, Loss: 0.1695
Epoch 6/10, Batch 50/145, Loss: 0.3959
Epoch 6/10, Batch 60/145, Loss: 0.2470
Epoch 6/10, Batch 70/145, Loss: 0.2508
Epoch 6/10, Batch 80/145, Loss: 0.3447
Epoch 6/10, Batch 90/145, Loss: 0.1624
Epoch 6/10, Batch 100/145, Loss: 0.1868
Epoch 6/10, Batch 110/145, Loss: 0.2313
Epoch 6/10, Batch 120/145, Loss: 0.1695
Epoch 6/10, Batch 130/145, Loss: 0.3058
Epoch 6/10, Batch 140/145, Loss: 0.1788
Epoch 6/10, Train Loss: 0.2231, Valid Loss: 0.2162
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3798
Epoch 7/10, Batch 20/145, Loss: 0.1841
Epoch 7/10, Batch 30/145, Loss: 0.1491
Epoch 7/10, Batch 40/145, Loss: 0.5110
Epoch 7/10, Batch 50/145, Loss: 0.1987
Epoch 7/10, Batch 60/145, Loss: 0.1032
Epoch 7/10, Batch 70/145, Loss: 0.3517
Epoch 7/10, Batch 80/145, Loss: 0.1176
Epoch 7/10, Batch 90/145, Loss: 0.1928
Epoch 7/10, Batch 100/145, Loss: 0.1618
Epoch 7/10, Batch 110/145, Loss: 0.3194
Epoch 7/10, Batch 120/145, Loss: 0.1387
Epoch 7/10, Batch 130/145, Loss: 0.3119
Epoch 7/10, Batch 140/145, Loss: 0.1618
Epoch 7/10, Train Loss: 0.2145, Valid Loss: 0.2151
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1409
Epoch 8/10, Batch 20/145, Loss: 0.2200
Epoch 8/10, Batch 30/145, Loss: 0.1599
Epoch 8/10, Batch 40/145, Loss: 0.1770
Epoch 8/10, Batch 50/145, Loss: 0.1726
Epoch 8/10, Batch 60/145, Loss: 0.1131
Epoch 8/10, Batch 70/145, Loss: 0.1063
Epoch 8/10, Batch 80/145, Loss: 0.1720
Epoch 8/10, Batch 90/145, Loss: 0.1462
Epoch 8/10, Batch 100/145, Loss: 0.1465
Epoch 8/10, Batch 110/145, Loss: 0.1975
Epoch 8/10, Batch 120/145, Loss: 0.1309
Epoch 8/10, Batch 130/145, Loss: 0.1174
Epoch 8/10, Batch 140/145, Loss: 0.1907
Epoch 8/10, Train Loss: 0.2044, Valid Loss: 0.2068
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2041
Epoch 9/10, Batch 20/145, Loss: 0.1343
Epoch 9/10, Batch 30/145, Loss: 0.0819
Epoch 9/10, Batch 40/145, Loss: 0.2164
Epoch 9/10, Batch 50/145, Loss: 0.1980
Epoch 9/10, Batch 60/145, Loss: 0.0877
Epoch 9/10, Batch 70/145, Loss: 0.3300
Epoch 9/10, Batch 80/145, Loss: 0.3582
Epoch 9/10, Batch 90/145, Loss: 0.1733
Epoch 9/10, Batch 100/145, Loss: 0.2235
Epoch 9/10, Batch 110/145, Loss: 0.1363
Epoch 9/10, Batch 120/145, Loss: 0.2344
Epoch 9/10, Batch 130/145, Loss: 0.0965
Epoch 9/10, Batch 140/145, Loss: 0.2845
Epoch 9/10, Train Loss: 0.1969, Valid Loss: 0.1994
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0783
Epoch 10/10, Batch 20/145, Loss: 0.1679
Epoch 10/10, Batch 30/145, Loss: 0.2770
Epoch 10/10, Batch 40/145, Loss: 0.1198
Epoch 10/10, Batch 50/145, Loss: 0.3872
Epoch 10/10, Batch 60/145, Loss: 0.2419
Epoch 10/10, Batch 70/145, Loss: 0.1357
Epoch 10/10, Batch 80/145, Loss: 0.3833
Epoch 10/10, Batch 90/145, Loss: 0.1491
Epoch 10/10, Batch 100/145, Loss: 0.2196
Epoch 10/10, Batch 110/145, Loss: 0.3759
Epoch 10/10, Batch 120/145, Loss: 0.1469
Epoch 10/10, Batch 130/145, Loss: 0.1635
Epoch 10/10, Batch 140/145, Loss: 0.2470
Epoch 10/10, Train Loss: 0.1995, Valid Loss: 0.1984
Model saved!
Accuracy: 0.9217
Precision: 0.9194
Recall: 0.9217
F1-score: 0.9194
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5205
Epoch 1/10, Batch 20/145, Loss: 0.9081
Epoch 1/10, Batch 30/145, Loss: 0.9035
Epoch 1/10, Batch 40/145, Loss: 0.9100
Epoch 1/10, Batch 50/145, Loss: 0.5886
Epoch 1/10, Batch 60/145, Loss: 0.5593
Epoch 1/10, Batch 70/145, Loss: 0.6137
Epoch 1/10, Batch 80/145, Loss: 0.5694
Epoch 1/10, Batch 90/145, Loss: 0.5091
Epoch 1/10, Batch 100/145, Loss: 0.6331
Epoch 1/10, Batch 110/145, Loss: 0.4329
Epoch 1/10, Batch 120/145, Loss: 0.6310
Epoch 1/10, Batch 130/145, Loss: 0.4173
Epoch 1/10, Batch 140/145, Loss: 0.4542
Epoch 1/10, Train Loss: 0.6937, Valid Loss: 0.3662
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3083
Epoch 2/10, Batch 20/145, Loss: 0.5547
Epoch 2/10, Batch 30/145, Loss: 0.2817
Epoch 2/10, Batch 40/145, Loss: 0.4474
Epoch 2/10, Batch 50/145, Loss: 0.3622
Epoch 2/10, Batch 60/145, Loss: 0.5550
Epoch 2/10, Batch 70/145, Loss: 0.4704
Epoch 2/10, Batch 80/145, Loss: 0.4413
Epoch 2/10, Batch 90/145, Loss: 0.3647
Epoch 2/10, Batch 100/145, Loss: 0.4421
Epoch 2/10, Batch 110/145, Loss: 0.2675
Epoch 2/10, Batch 120/145, Loss: 0.5064
Epoch 2/10, Batch 130/145, Loss: 0.3371
Epoch 2/10, Batch 140/145, Loss: 0.2350
Epoch 2/10, Train Loss: 0.3652, Valid Loss: 0.2817
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2795
Epoch 3/10, Batch 20/145, Loss: 0.4104
Epoch 3/10, Batch 30/145, Loss: 0.2654
Epoch 3/10, Batch 40/145, Loss: 0.2138
Epoch 3/10, Batch 50/145, Loss: 0.1956
Epoch 3/10, Batch 60/145, Loss: 0.3916
Epoch 3/10, Batch 70/145, Loss: 0.1669
Epoch 3/10, Batch 80/145, Loss: 0.2074
Epoch 3/10, Batch 90/145, Loss: 0.6234
Epoch 3/10, Batch 100/145, Loss: 0.3583
Epoch 3/10, Batch 110/145, Loss: 0.3370
Epoch 3/10, Batch 120/145, Loss: 0.2051
Epoch 3/10, Batch 130/145, Loss: 0.3608
Epoch 3/10, Batch 140/145, Loss: 0.2361
Epoch 3/10, Train Loss: 0.3077, Valid Loss: 0.2558
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3076
Epoch 4/10, Batch 20/145, Loss: 0.2221
Epoch 4/10, Batch 30/145, Loss: 0.3012
Epoch 4/10, Batch 40/145, Loss: 0.4456
Epoch 4/10, Batch 50/145, Loss: 0.2781
Epoch 4/10, Batch 60/145, Loss: 0.2951
Epoch 4/10, Batch 70/145, Loss: 0.2143
Epoch 4/10, Batch 80/145, Loss: 0.2534
Epoch 4/10, Batch 90/145, Loss: 0.2977
Epoch 4/10, Batch 100/145, Loss: 0.2471
Epoch 4/10, Batch 110/145, Loss: 0.3057
Epoch 4/10, Batch 120/145, Loss: 0.2739
Epoch 4/10, Batch 130/145, Loss: 0.1963
Epoch 4/10, Batch 140/145, Loss: 0.3407
Epoch 4/10, Train Loss: 0.2690, Valid Loss: 0.2428
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2049
Epoch 5/10, Batch 20/145, Loss: 0.2360
Epoch 5/10, Batch 30/145, Loss: 0.2015
Epoch 5/10, Batch 40/145, Loss: 0.2540
Epoch 5/10, Batch 50/145, Loss: 0.2843
Epoch 5/10, Batch 60/145, Loss: 0.3518
Epoch 5/10, Batch 70/145, Loss: 0.4629
Epoch 5/10, Batch 80/145, Loss: 0.1705
Epoch 5/10, Batch 90/145, Loss: 0.1500
Epoch 5/10, Batch 100/145, Loss: 0.2725
Epoch 5/10, Batch 110/145, Loss: 0.2158
Epoch 5/10, Batch 120/145, Loss: 0.2366
Epoch 5/10, Batch 130/145, Loss: 0.2960
Epoch 5/10, Batch 140/145, Loss: 0.2047
Epoch 5/10, Train Loss: 0.2474, Valid Loss: 0.2337
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1164
Epoch 6/10, Batch 20/145, Loss: 0.3018
Epoch 6/10, Batch 30/145, Loss: 0.2316
Epoch 6/10, Batch 40/145, Loss: 0.1992
Epoch 6/10, Batch 50/145, Loss: 0.3482
Epoch 6/10, Batch 60/145, Loss: 0.1275
Epoch 6/10, Batch 70/145, Loss: 0.4584
Epoch 6/10, Batch 80/145, Loss: 0.3616
Epoch 6/10, Batch 90/145, Loss: 0.1871
Epoch 6/10, Batch 100/145, Loss: 0.1255
Epoch 6/10, Batch 110/145, Loss: 0.2572
Epoch 6/10, Batch 120/145, Loss: 0.3516
Epoch 6/10, Batch 130/145, Loss: 0.1997
Epoch 6/10, Batch 140/145, Loss: 0.2650
Epoch 6/10, Train Loss: 0.2347, Valid Loss: 0.2322
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2771
Epoch 7/10, Batch 20/145, Loss: 0.2750
Epoch 7/10, Batch 30/145, Loss: 0.2299
Epoch 7/10, Batch 40/145, Loss: 0.3311
Epoch 7/10, Batch 50/145, Loss: 0.1719
Epoch 7/10, Batch 60/145, Loss: 0.1905
Epoch 7/10, Batch 70/145, Loss: 0.3671
Epoch 7/10, Batch 80/145, Loss: 0.2733
Epoch 7/10, Batch 90/145, Loss: 0.3686
Epoch 7/10, Batch 100/145, Loss: 0.2522
Epoch 7/10, Batch 110/145, Loss: 0.1883
Epoch 7/10, Batch 120/145, Loss: 0.0753
Epoch 7/10, Batch 130/145, Loss: 0.3039
Epoch 7/10, Batch 140/145, Loss: 0.1763
Epoch 7/10, Train Loss: 0.2218, Valid Loss: 0.2241
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1555
Epoch 8/10, Batch 20/145, Loss: 0.2362
Epoch 8/10, Batch 30/145, Loss: 0.1974
Epoch 8/10, Batch 40/145, Loss: 0.3507
Epoch 8/10, Batch 50/145, Loss: 0.3833
Epoch 8/10, Batch 60/145, Loss: 0.1305
Epoch 8/10, Batch 70/145, Loss: 0.1288
Epoch 8/10, Batch 80/145, Loss: 0.1124
Epoch 8/10, Batch 90/145, Loss: 0.2477
Epoch 8/10, Batch 100/145, Loss: 0.2115
Epoch 8/10, Batch 110/145, Loss: 0.3474
Epoch 8/10, Batch 120/145, Loss: 0.1359
Epoch 8/10, Batch 130/145, Loss: 0.0967
Epoch 8/10, Batch 140/145, Loss: 0.3870
Epoch 8/10, Train Loss: 0.2097, Valid Loss: 0.2153
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3613
Epoch 9/10, Batch 20/145, Loss: 0.1300
Epoch 9/10, Batch 30/145, Loss: 0.1183
Epoch 9/10, Batch 40/145, Loss: 0.3045
Epoch 9/10, Batch 50/145, Loss: 0.1418
Epoch 9/10, Batch 60/145, Loss: 0.2045
Epoch 9/10, Batch 70/145, Loss: 0.2005
Epoch 9/10, Batch 80/145, Loss: 0.1578
Epoch 9/10, Batch 90/145, Loss: 0.0886
Epoch 9/10, Batch 100/145, Loss: 0.2615
Epoch 9/10, Batch 110/145, Loss: 0.2026
Epoch 9/10, Batch 120/145, Loss: 0.1955
Epoch 9/10, Batch 130/145, Loss: 0.1936
Epoch 9/10, Batch 140/145, Loss: 0.0982
Epoch 9/10, Train Loss: 0.2065, Valid Loss: 0.2131
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1341
Epoch 10/10, Batch 20/145, Loss: 0.2393
Epoch 10/10, Batch 30/145, Loss: 0.1067
Epoch 10/10, Batch 40/145, Loss: 0.3234
Epoch 10/10, Batch 50/145, Loss: 0.2266
Epoch 10/10, Batch 60/145, Loss: 0.1152
Epoch 10/10, Batch 70/145, Loss: 0.1416
Epoch 10/10, Batch 80/145, Loss: 0.3146
Epoch 10/10, Batch 90/145, Loss: 0.0915
Epoch 10/10, Batch 100/145, Loss: 0.1177
Epoch 10/10, Batch 110/145, Loss: 0.2820
Epoch 10/10, Batch 120/145, Loss: 0.1686
Epoch 10/10, Batch 130/145, Loss: 0.2585
Epoch 10/10, Batch 140/145, Loss: 0.1685
Epoch 10/10, Train Loss: 0.2034, Valid Loss: 0.2110
Model saved!
Accuracy: 0.9159
Precision: 0.9140
Recall: 0.9159
F1-score: 0.9148
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4506
Epoch 1/10, Batch 20/145, Loss: 0.9062
Epoch 1/10, Batch 30/145, Loss: 0.8812
Epoch 1/10, Batch 40/145, Loss: 0.7815
Epoch 1/10, Batch 50/145, Loss: 0.6261
Epoch 1/10, Batch 60/145, Loss: 0.5706
Epoch 1/10, Batch 70/145, Loss: 0.7130
Epoch 1/10, Batch 80/145, Loss: 0.6011
Epoch 1/10, Batch 90/145, Loss: 0.5226
Epoch 1/10, Batch 100/145, Loss: 0.5897
Epoch 1/10, Batch 110/145, Loss: 0.4277
Epoch 1/10, Batch 120/145, Loss: 0.5315
Epoch 1/10, Batch 130/145, Loss: 0.4502
Epoch 1/10, Batch 140/145, Loss: 0.5120
Epoch 1/10, Train Loss: 0.6915, Valid Loss: 0.3654
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3216
Epoch 2/10, Batch 20/145, Loss: 0.3964
Epoch 2/10, Batch 30/145, Loss: 0.3476
Epoch 2/10, Batch 40/145, Loss: 0.5393
Epoch 2/10, Batch 50/145, Loss: 0.3045
Epoch 2/10, Batch 60/145, Loss: 0.4886
Epoch 2/10, Batch 70/145, Loss: 0.5040
Epoch 2/10, Batch 80/145, Loss: 0.3329
Epoch 2/10, Batch 90/145, Loss: 0.3548
Epoch 2/10, Batch 100/145, Loss: 0.3583
Epoch 2/10, Batch 110/145, Loss: 0.2997
Epoch 2/10, Batch 120/145, Loss: 0.3926
Epoch 2/10, Batch 130/145, Loss: 0.4474
Epoch 2/10, Batch 140/145, Loss: 0.2255
Epoch 2/10, Train Loss: 0.3611, Valid Loss: 0.2737
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2086
Epoch 3/10, Batch 20/145, Loss: 0.1946
Epoch 3/10, Batch 30/145, Loss: 0.1896
Epoch 3/10, Batch 40/145, Loss: 0.5357
Epoch 3/10, Batch 50/145, Loss: 0.1976
Epoch 3/10, Batch 60/145, Loss: 0.2531
Epoch 3/10, Batch 70/145, Loss: 0.2464
Epoch 3/10, Batch 80/145, Loss: 0.2366
Epoch 3/10, Batch 90/145, Loss: 0.4080
Epoch 3/10, Batch 100/145, Loss: 0.3422
Epoch 3/10, Batch 110/145, Loss: 0.1825
Epoch 3/10, Batch 120/145, Loss: 0.3114
Epoch 3/10, Batch 130/145, Loss: 0.2838
Epoch 3/10, Batch 140/145, Loss: 0.2924
Epoch 3/10, Train Loss: 0.3045, Valid Loss: 0.2491
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2092
Epoch 4/10, Batch 20/145, Loss: 0.2461
Epoch 4/10, Batch 30/145, Loss: 0.1854
Epoch 4/10, Batch 40/145, Loss: 0.3772
Epoch 4/10, Batch 50/145, Loss: 0.1697
Epoch 4/10, Batch 60/145, Loss: 0.2795
Epoch 4/10, Batch 70/145, Loss: 0.2412
Epoch 4/10, Batch 80/145, Loss: 0.3007
Epoch 4/10, Batch 90/145, Loss: 0.2914
Epoch 4/10, Batch 100/145, Loss: 0.2230
Epoch 4/10, Batch 110/145, Loss: 0.2276
Epoch 4/10, Batch 120/145, Loss: 0.2533
Epoch 4/10, Batch 130/145, Loss: 0.1825
Epoch 4/10, Batch 140/145, Loss: 0.2888
Epoch 4/10, Train Loss: 0.2645, Valid Loss: 0.2402
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2272
Epoch 5/10, Batch 20/145, Loss: 0.3449
Epoch 5/10, Batch 30/145, Loss: 0.1465
Epoch 5/10, Batch 40/145, Loss: 0.2675
Epoch 5/10, Batch 50/145, Loss: 0.2466
Epoch 5/10, Batch 60/145, Loss: 0.3403
Epoch 5/10, Batch 70/145, Loss: 0.2987
Epoch 5/10, Batch 80/145, Loss: 0.2175
Epoch 5/10, Batch 90/145, Loss: 0.3520
Epoch 5/10, Batch 100/145, Loss: 0.2020
Epoch 5/10, Batch 110/145, Loss: 0.1979
Epoch 5/10, Batch 120/145, Loss: 0.2324
Epoch 5/10, Batch 130/145, Loss: 0.3428
Epoch 5/10, Batch 140/145, Loss: 0.1889
Epoch 5/10, Train Loss: 0.2431, Valid Loss: 0.2217
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3594
Epoch 6/10, Batch 20/145, Loss: 0.2002
Epoch 6/10, Batch 30/145, Loss: 0.2243
Epoch 6/10, Batch 40/145, Loss: 0.2218
Epoch 6/10, Batch 50/145, Loss: 0.3313
Epoch 6/10, Batch 60/145, Loss: 0.1509
Epoch 6/10, Batch 70/145, Loss: 0.2341
Epoch 6/10, Batch 80/145, Loss: 0.3072
Epoch 6/10, Batch 90/145, Loss: 0.3047
Epoch 6/10, Batch 100/145, Loss: 0.2484
Epoch 6/10, Batch 110/145, Loss: 0.1313
Epoch 6/10, Batch 120/145, Loss: 0.2366
Epoch 6/10, Batch 130/145, Loss: 0.1791
Epoch 6/10, Batch 140/145, Loss: 0.1618
Epoch 6/10, Train Loss: 0.2256, Valid Loss: 0.2282
Epoch 7/10, Batch 10/145, Loss: 0.2111
Epoch 7/10, Batch 20/145, Loss: 0.2752
Epoch 7/10, Batch 30/145, Loss: 0.0860
Epoch 7/10, Batch 40/145, Loss: 0.4327
Epoch 7/10, Batch 50/145, Loss: 0.1799
Epoch 7/10, Batch 60/145, Loss: 0.1052
Epoch 7/10, Batch 70/145, Loss: 0.2060
Epoch 7/10, Batch 80/145, Loss: 0.1943
Epoch 7/10, Batch 90/145, Loss: 0.2146
Epoch 7/10, Batch 100/145, Loss: 0.2343
Epoch 7/10, Batch 110/145, Loss: 0.2092
Epoch 7/10, Batch 120/145, Loss: 0.2461
Epoch 7/10, Batch 130/145, Loss: 0.3267
Epoch 7/10, Batch 140/145, Loss: 0.2092
Epoch 7/10, Train Loss: 0.2213, Valid Loss: 0.2062
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2407
Epoch 8/10, Batch 20/145, Loss: 0.1060
Epoch 8/10, Batch 30/145, Loss: 0.1149
Epoch 8/10, Batch 40/145, Loss: 0.2704
Epoch 8/10, Batch 50/145, Loss: 0.2103
Epoch 8/10, Batch 60/145, Loss: 0.2038
Epoch 8/10, Batch 70/145, Loss: 0.1612
Epoch 8/10, Batch 80/145, Loss: 0.1038
Epoch 8/10, Batch 90/145, Loss: 0.0929
Epoch 8/10, Batch 100/145, Loss: 0.1146
Epoch 8/10, Batch 110/145, Loss: 0.2854
Epoch 8/10, Batch 120/145, Loss: 0.1681
Epoch 8/10, Batch 130/145, Loss: 0.2100
Epoch 8/10, Batch 140/145, Loss: 0.4864
Epoch 8/10, Train Loss: 0.2116, Valid Loss: 0.2026
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1649
Epoch 9/10, Batch 20/145, Loss: 0.1494
Epoch 9/10, Batch 30/145, Loss: 0.0962
Epoch 9/10, Batch 40/145, Loss: 0.3747
Epoch 9/10, Batch 50/145, Loss: 0.1334
Epoch 9/10, Batch 60/145, Loss: 0.1939
Epoch 9/10, Batch 70/145, Loss: 0.0892
Epoch 9/10, Batch 80/145, Loss: 0.1749
Epoch 9/10, Batch 90/145, Loss: 0.0924
Epoch 9/10, Batch 100/145, Loss: 0.2216
Epoch 9/10, Batch 110/145, Loss: 0.0725
Epoch 9/10, Batch 120/145, Loss: 0.2059
Epoch 9/10, Batch 130/145, Loss: 0.2415
Epoch 9/10, Batch 140/145, Loss: 0.1853
Epoch 9/10, Train Loss: 0.2009, Valid Loss: 0.2008
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0941
Epoch 10/10, Batch 20/145, Loss: 0.1586
Epoch 10/10, Batch 30/145, Loss: 0.1055
Epoch 10/10, Batch 40/145, Loss: 0.1788
Epoch 10/10, Batch 50/145, Loss: 0.3641
Epoch 10/10, Batch 60/145, Loss: 0.2845
Epoch 10/10, Batch 70/145, Loss: 0.2017
Epoch 10/10, Batch 80/145, Loss: 0.4160
Epoch 10/10, Batch 90/145, Loss: 0.1481
Epoch 10/10, Batch 100/145, Loss: 0.1694
Epoch 10/10, Batch 110/145, Loss: 0.2511
Epoch 10/10, Batch 120/145, Loss: 0.2908
Epoch 10/10, Batch 130/145, Loss: 0.2428
Epoch 10/10, Batch 140/145, Loss: 0.5039
Epoch 10/10, Train Loss: 0.1918, Valid Loss: 0.1942
Model saved!
Accuracy: 0.9264
Precision: 0.9263
Recall: 0.9264
F1-score: 0.9259
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5352
Epoch 1/10, Batch 20/145, Loss: 0.9220
Epoch 1/10, Batch 30/145, Loss: 0.8696
Epoch 1/10, Batch 40/145, Loss: 0.8731
Epoch 1/10, Batch 50/145, Loss: 0.6125
Epoch 1/10, Batch 60/145, Loss: 0.5180
Epoch 1/10, Batch 70/145, Loss: 0.5316
Epoch 1/10, Batch 80/145, Loss: 0.4968
Epoch 1/10, Batch 90/145, Loss: 0.4800
Epoch 1/10, Batch 100/145, Loss: 0.4507
Epoch 1/10, Batch 110/145, Loss: 0.3917
Epoch 1/10, Batch 120/145, Loss: 0.5143
Epoch 1/10, Batch 130/145, Loss: 0.4686
Epoch 1/10, Batch 140/145, Loss: 0.4650
Epoch 1/10, Train Loss: 0.6897, Valid Loss: 0.3860
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3018
Epoch 2/10, Batch 20/145, Loss: 0.4227
Epoch 2/10, Batch 30/145, Loss: 0.2640
Epoch 2/10, Batch 40/145, Loss: 0.4921
Epoch 2/10, Batch 50/145, Loss: 0.3135
Epoch 2/10, Batch 60/145, Loss: 0.4282
Epoch 2/10, Batch 70/145, Loss: 0.4007
Epoch 2/10, Batch 80/145, Loss: 0.3206
Epoch 2/10, Batch 90/145, Loss: 0.2827
Epoch 2/10, Batch 100/145, Loss: 0.2424
Epoch 2/10, Batch 110/145, Loss: 0.3135
Epoch 2/10, Batch 120/145, Loss: 0.4111
Epoch 2/10, Batch 130/145, Loss: 0.3588
Epoch 2/10, Batch 140/145, Loss: 0.3017
Epoch 2/10, Train Loss: 0.3653, Valid Loss: 0.2898
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2307
Epoch 3/10, Batch 20/145, Loss: 0.5831
Epoch 3/10, Batch 30/145, Loss: 0.2263
Epoch 3/10, Batch 40/145, Loss: 0.2677
Epoch 3/10, Batch 50/145, Loss: 0.2162
Epoch 3/10, Batch 60/145, Loss: 0.3540
Epoch 3/10, Batch 70/145, Loss: 0.1842
Epoch 3/10, Batch 80/145, Loss: 0.3548
Epoch 3/10, Batch 90/145, Loss: 0.5599
Epoch 3/10, Batch 100/145, Loss: 0.2485
Epoch 3/10, Batch 110/145, Loss: 0.1862
Epoch 3/10, Batch 120/145, Loss: 0.2383
Epoch 3/10, Batch 130/145, Loss: 0.2486
Epoch 3/10, Batch 140/145, Loss: 0.1878
Epoch 3/10, Train Loss: 0.3143, Valid Loss: 0.2523
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1898
Epoch 4/10, Batch 20/145, Loss: 0.2734
Epoch 4/10, Batch 30/145, Loss: 0.2646
Epoch 4/10, Batch 40/145, Loss: 0.3868
Epoch 4/10, Batch 50/145, Loss: 0.1341
Epoch 4/10, Batch 60/145, Loss: 0.1896
Epoch 4/10, Batch 70/145, Loss: 0.3339
Epoch 4/10, Batch 80/145, Loss: 0.2847
Epoch 4/10, Batch 90/145, Loss: 0.3248
Epoch 4/10, Batch 100/145, Loss: 0.2657
Epoch 4/10, Batch 110/145, Loss: 0.1201
Epoch 4/10, Batch 120/145, Loss: 0.2493
Epoch 4/10, Batch 130/145, Loss: 0.1958
Epoch 4/10, Batch 140/145, Loss: 0.1375
Epoch 4/10, Train Loss: 0.2632, Valid Loss: 0.2480
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1716
Epoch 5/10, Batch 20/145, Loss: 0.4715
Epoch 5/10, Batch 30/145, Loss: 0.1818
Epoch 5/10, Batch 40/145, Loss: 0.2578
Epoch 5/10, Batch 50/145, Loss: 0.1298
Epoch 5/10, Batch 60/145, Loss: 0.2379
Epoch 5/10, Batch 70/145, Loss: 0.4245
Epoch 5/10, Batch 80/145, Loss: 0.2318
Epoch 5/10, Batch 90/145, Loss: 0.1447
Epoch 5/10, Batch 100/145, Loss: 0.2646
Epoch 5/10, Batch 110/145, Loss: 0.1236
Epoch 5/10, Batch 120/145, Loss: 0.1883
Epoch 5/10, Batch 130/145, Loss: 0.2334
Epoch 5/10, Batch 140/145, Loss: 0.4430
Epoch 5/10, Train Loss: 0.2433, Valid Loss: 0.2282
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1657
Epoch 6/10, Batch 20/145, Loss: 0.4761
Epoch 6/10, Batch 30/145, Loss: 0.2843
Epoch 6/10, Batch 40/145, Loss: 0.2578
Epoch 6/10, Batch 50/145, Loss: 0.3375
Epoch 6/10, Batch 60/145, Loss: 0.1672
Epoch 6/10, Batch 70/145, Loss: 0.3358
Epoch 6/10, Batch 80/145, Loss: 0.2969
Epoch 6/10, Batch 90/145, Loss: 0.2918
Epoch 6/10, Batch 100/145, Loss: 0.2648
Epoch 6/10, Batch 110/145, Loss: 0.1793
Epoch 6/10, Batch 120/145, Loss: 0.2390
Epoch 6/10, Batch 130/145, Loss: 0.0833
Epoch 6/10, Batch 140/145, Loss: 0.4490
Epoch 6/10, Train Loss: 0.2361, Valid Loss: 0.2211
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1752
Epoch 7/10, Batch 20/145, Loss: 0.1361
Epoch 7/10, Batch 30/145, Loss: 0.2072
Epoch 7/10, Batch 40/145, Loss: 0.4797
Epoch 7/10, Batch 50/145, Loss: 0.1570
Epoch 7/10, Batch 60/145, Loss: 0.2401
Epoch 7/10, Batch 70/145, Loss: 0.2638
Epoch 7/10, Batch 80/145, Loss: 0.1918
Epoch 7/10, Batch 90/145, Loss: 0.4210
Epoch 7/10, Batch 100/145, Loss: 0.1658
Epoch 7/10, Batch 110/145, Loss: 0.3108
Epoch 7/10, Batch 120/145, Loss: 0.1356
Epoch 7/10, Batch 130/145, Loss: 0.2680
Epoch 7/10, Batch 140/145, Loss: 0.2132
Epoch 7/10, Train Loss: 0.2241, Valid Loss: 0.2129
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1233
Epoch 8/10, Batch 20/145, Loss: 0.1720
Epoch 8/10, Batch 30/145, Loss: 0.2010
Epoch 8/10, Batch 40/145, Loss: 0.2442
Epoch 8/10, Batch 50/145, Loss: 0.5431
Epoch 8/10, Batch 60/145, Loss: 0.1684
Epoch 8/10, Batch 70/145, Loss: 0.1685
Epoch 8/10, Batch 80/145, Loss: 0.1695
Epoch 8/10, Batch 90/145, Loss: 0.1693
Epoch 8/10, Batch 100/145, Loss: 0.2896
Epoch 8/10, Batch 110/145, Loss: 0.1391
Epoch 8/10, Batch 120/145, Loss: 0.1078
Epoch 8/10, Batch 130/145, Loss: 0.1995
Epoch 8/10, Batch 140/145, Loss: 0.1291
Epoch 8/10, Train Loss: 0.2119, Valid Loss: 0.2094
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1823
Epoch 9/10, Batch 20/145, Loss: 0.1173
Epoch 9/10, Batch 30/145, Loss: 0.0770
Epoch 9/10, Batch 40/145, Loss: 0.1289
Epoch 9/10, Batch 50/145, Loss: 0.2771
Epoch 9/10, Batch 60/145, Loss: 0.1133
Epoch 9/10, Batch 70/145, Loss: 0.2167
Epoch 9/10, Batch 80/145, Loss: 0.1671
Epoch 9/10, Batch 90/145, Loss: 0.2224
Epoch 9/10, Batch 100/145, Loss: 0.2387
Epoch 9/10, Batch 110/145, Loss: 0.0560
Epoch 9/10, Batch 120/145, Loss: 0.2471
Epoch 9/10, Batch 130/145, Loss: 0.2280
Epoch 9/10, Batch 140/145, Loss: 0.1518
Epoch 9/10, Train Loss: 0.2063, Valid Loss: 0.2078
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1771
Epoch 10/10, Batch 20/145, Loss: 0.3134
Epoch 10/10, Batch 30/145, Loss: 0.0822
Epoch 10/10, Batch 40/145, Loss: 0.2334
Epoch 10/10, Batch 50/145, Loss: 0.3389
Epoch 10/10, Batch 60/145, Loss: 0.1804
Epoch 10/10, Batch 70/145, Loss: 0.0717
Epoch 10/10, Batch 80/145, Loss: 0.4498
Epoch 10/10, Batch 90/145, Loss: 0.0897
Epoch 10/10, Batch 100/145, Loss: 0.1148
Epoch 10/10, Batch 110/145, Loss: 0.3052
Epoch 10/10, Batch 120/145, Loss: 0.2246
Epoch 10/10, Batch 130/145, Loss: 0.1568
Epoch 10/10, Batch 140/145, Loss: 0.3431
Epoch 10/10, Train Loss: 0.2032, Valid Loss: 0.2006
Model saved!
Accuracy: 0.9334
Precision: 0.9325
Recall: 0.9334
F1-score: 0.9328
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 66. Fitness: 0.9334
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4959
Epoch 1/10, Batch 20/145, Loss: 0.8649
Epoch 1/10, Batch 30/145, Loss: 0.8938
Epoch 1/10, Batch 40/145, Loss: 0.7900
Epoch 1/10, Batch 50/145, Loss: 0.6892
Epoch 1/10, Batch 60/145, Loss: 0.6285
Epoch 1/10, Batch 70/145, Loss: 0.6312
Epoch 1/10, Batch 80/145, Loss: 0.5302
Epoch 1/10, Batch 90/145, Loss: 0.6248
Epoch 1/10, Batch 100/145, Loss: 0.6195
Epoch 1/10, Batch 110/145, Loss: 0.4090
Epoch 1/10, Batch 120/145, Loss: 0.5900
Epoch 1/10, Batch 130/145, Loss: 0.5183
Epoch 1/10, Batch 140/145, Loss: 0.4447
Epoch 1/10, Train Loss: 0.6905, Valid Loss: 0.3742
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2591
Epoch 2/10, Batch 20/145, Loss: 0.4845
Epoch 2/10, Batch 30/145, Loss: 0.3995
Epoch 2/10, Batch 40/145, Loss: 0.4208
Epoch 2/10, Batch 50/145, Loss: 0.2143
Epoch 2/10, Batch 60/145, Loss: 0.5461
Epoch 2/10, Batch 70/145, Loss: 0.4252
Epoch 2/10, Batch 80/145, Loss: 0.1515
Epoch 2/10, Batch 90/145, Loss: 0.3074
Epoch 2/10, Batch 100/145, Loss: 0.2325
Epoch 2/10, Batch 110/145, Loss: 0.3570
Epoch 2/10, Batch 120/145, Loss: 0.5757
Epoch 2/10, Batch 130/145, Loss: 0.2205
Epoch 2/10, Batch 140/145, Loss: 0.2314
Epoch 2/10, Train Loss: 0.3617, Valid Loss: 0.2899
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2860
Epoch 3/10, Batch 20/145, Loss: 0.3175
Epoch 3/10, Batch 30/145, Loss: 0.2431
Epoch 3/10, Batch 40/145, Loss: 0.2689
Epoch 3/10, Batch 50/145, Loss: 0.1761
Epoch 3/10, Batch 60/145, Loss: 0.2824
Epoch 3/10, Batch 70/145, Loss: 0.1744
Epoch 3/10, Batch 80/145, Loss: 0.2026
Epoch 3/10, Batch 90/145, Loss: 0.4134
Epoch 3/10, Batch 100/145, Loss: 0.3327
Epoch 3/10, Batch 110/145, Loss: 0.2435
Epoch 3/10, Batch 120/145, Loss: 0.2204
Epoch 3/10, Batch 130/145, Loss: 0.3346
Epoch 3/10, Batch 140/145, Loss: 0.2191
Epoch 3/10, Train Loss: 0.3117, Valid Loss: 0.2535
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2207
Epoch 4/10, Batch 20/145, Loss: 0.1438
Epoch 4/10, Batch 30/145, Loss: 0.3491
Epoch 4/10, Batch 40/145, Loss: 0.2744
Epoch 4/10, Batch 50/145, Loss: 0.2845
Epoch 4/10, Batch 60/145, Loss: 0.2034
Epoch 4/10, Batch 70/145, Loss: 0.2856
Epoch 4/10, Batch 80/145, Loss: 0.3264
Epoch 4/10, Batch 90/145, Loss: 0.2324
Epoch 4/10, Batch 100/145, Loss: 0.3325
Epoch 4/10, Batch 110/145, Loss: 0.2077
Epoch 4/10, Batch 120/145, Loss: 0.2031
Epoch 4/10, Batch 130/145, Loss: 0.3492
Epoch 4/10, Batch 140/145, Loss: 0.2589
Epoch 4/10, Train Loss: 0.2667, Valid Loss: 0.2470
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2215
Epoch 5/10, Batch 20/145, Loss: 0.2851
Epoch 5/10, Batch 30/145, Loss: 0.2006
Epoch 5/10, Batch 40/145, Loss: 0.1989
Epoch 5/10, Batch 50/145, Loss: 0.1685
Epoch 5/10, Batch 60/145, Loss: 0.2757
Epoch 5/10, Batch 70/145, Loss: 0.2431
Epoch 5/10, Batch 80/145, Loss: 0.2493
Epoch 5/10, Batch 90/145, Loss: 0.2439
Epoch 5/10, Batch 100/145, Loss: 0.2185
Epoch 5/10, Batch 110/145, Loss: 0.2341
Epoch 5/10, Batch 120/145, Loss: 0.1980
Epoch 5/10, Batch 130/145, Loss: 0.1980
Epoch 5/10, Batch 140/145, Loss: 0.2510
Epoch 5/10, Train Loss: 0.2422, Valid Loss: 0.2304
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2578
Epoch 6/10, Batch 20/145, Loss: 0.4177
Epoch 6/10, Batch 30/145, Loss: 0.2669
Epoch 6/10, Batch 40/145, Loss: 0.1269
Epoch 6/10, Batch 50/145, Loss: 0.2211
Epoch 6/10, Batch 60/145, Loss: 0.1668
Epoch 6/10, Batch 70/145, Loss: 0.1700
Epoch 6/10, Batch 80/145, Loss: 0.2320
Epoch 6/10, Batch 90/145, Loss: 0.2468
Epoch 6/10, Batch 100/145, Loss: 0.2129
Epoch 6/10, Batch 110/145, Loss: 0.2351
Epoch 6/10, Batch 120/145, Loss: 0.1662
Epoch 6/10, Batch 130/145, Loss: 0.1575
Epoch 6/10, Batch 140/145, Loss: 0.2407
Epoch 6/10, Train Loss: 0.2291, Valid Loss: 0.2292
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.4686
Epoch 7/10, Batch 20/145, Loss: 0.2792
Epoch 7/10, Batch 30/145, Loss: 0.2399
Epoch 7/10, Batch 40/145, Loss: 0.4977
Epoch 7/10, Batch 50/145, Loss: 0.2701
Epoch 7/10, Batch 60/145, Loss: 0.1552
Epoch 7/10, Batch 70/145, Loss: 0.1818
Epoch 7/10, Batch 80/145, Loss: 0.1416
Epoch 7/10, Batch 90/145, Loss: 0.2556
Epoch 7/10, Batch 100/145, Loss: 0.2428
Epoch 7/10, Batch 110/145, Loss: 0.2212
Epoch 7/10, Batch 120/145, Loss: 0.2345
Epoch 7/10, Batch 130/145, Loss: 0.2400
Epoch 7/10, Batch 140/145, Loss: 0.1449
Epoch 7/10, Train Loss: 0.2208, Valid Loss: 0.2176
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2834
Epoch 8/10, Batch 20/145, Loss: 0.2085
Epoch 8/10, Batch 30/145, Loss: 0.2629
Epoch 8/10, Batch 40/145, Loss: 0.2051
Epoch 8/10, Batch 50/145, Loss: 0.4339
Epoch 8/10, Batch 60/145, Loss: 0.1926
Epoch 8/10, Batch 70/145, Loss: 0.1436
Epoch 8/10, Batch 80/145, Loss: 0.2439
Epoch 8/10, Batch 90/145, Loss: 0.1607
Epoch 8/10, Batch 100/145, Loss: 0.1490
Epoch 8/10, Batch 110/145, Loss: 0.4695
Epoch 8/10, Batch 120/145, Loss: 0.1664
Epoch 8/10, Batch 130/145, Loss: 0.1194
Epoch 8/10, Batch 140/145, Loss: 0.3850
Epoch 8/10, Train Loss: 0.2229, Valid Loss: 0.2098
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2296
Epoch 9/10, Batch 20/145, Loss: 0.2398
Epoch 9/10, Batch 30/145, Loss: 0.1494
Epoch 9/10, Batch 40/145, Loss: 0.1586
Epoch 9/10, Batch 50/145, Loss: 0.3081
Epoch 9/10, Batch 60/145, Loss: 0.1071
Epoch 9/10, Batch 70/145, Loss: 0.1374
Epoch 9/10, Batch 80/145, Loss: 0.1614
Epoch 9/10, Batch 90/145, Loss: 0.1166
Epoch 9/10, Batch 100/145, Loss: 0.2475
Epoch 9/10, Batch 110/145, Loss: 0.1581
Epoch 9/10, Batch 120/145, Loss: 0.1083
Epoch 9/10, Batch 130/145, Loss: 0.2022
Epoch 9/10, Batch 140/145, Loss: 0.2312
Epoch 9/10, Train Loss: 0.2089, Valid Loss: 0.2022
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2989
Epoch 10/10, Batch 20/145, Loss: 0.1733
Epoch 10/10, Batch 30/145, Loss: 0.1031
Epoch 10/10, Batch 40/145, Loss: 0.2139
Epoch 10/10, Batch 50/145, Loss: 0.1774
Epoch 10/10, Batch 60/145, Loss: 0.1869
Epoch 10/10, Batch 70/145, Loss: 0.2094
Epoch 10/10, Batch 80/145, Loss: 0.2315
Epoch 10/10, Batch 90/145, Loss: 0.1107
Epoch 10/10, Batch 100/145, Loss: 0.2398
Epoch 10/10, Batch 110/145, Loss: 0.1784
Epoch 10/10, Batch 120/145, Loss: 0.2620
Epoch 10/10, Batch 130/145, Loss: 0.2008
Epoch 10/10, Batch 140/145, Loss: 0.1980
Epoch 10/10, Train Loss: 0.1974, Valid Loss: 0.1997
Model saved!
Accuracy: 0.9252
Precision: 0.9242
Recall: 0.9252
F1-score: 0.9245
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4975
Epoch 1/10, Batch 20/145, Loss: 0.9480
Epoch 1/10, Batch 30/145, Loss: 0.8998
Epoch 1/10, Batch 40/145, Loss: 0.8145
Epoch 1/10, Batch 50/145, Loss: 0.6834
Epoch 1/10, Batch 60/145, Loss: 0.4685
Epoch 1/10, Batch 70/145, Loss: 0.7328
Epoch 1/10, Batch 80/145, Loss: 0.4686
Epoch 1/10, Batch 90/145, Loss: 0.4379
Epoch 1/10, Batch 100/145, Loss: 0.6004
Epoch 1/10, Batch 110/145, Loss: 0.3952
Epoch 1/10, Batch 120/145, Loss: 0.6322
Epoch 1/10, Batch 130/145, Loss: 0.3121
Epoch 1/10, Batch 140/145, Loss: 0.3472
Epoch 1/10, Train Loss: 0.6877, Valid Loss: 0.3860
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3915
Epoch 2/10, Batch 20/145, Loss: 0.5184
Epoch 2/10, Batch 30/145, Loss: 0.4997
Epoch 2/10, Batch 40/145, Loss: 0.2997
Epoch 2/10, Batch 50/145, Loss: 0.3933
Epoch 2/10, Batch 60/145, Loss: 0.3887
Epoch 2/10, Batch 70/145, Loss: 0.3934
Epoch 2/10, Batch 80/145, Loss: 0.5693
Epoch 2/10, Batch 90/145, Loss: 0.4257
Epoch 2/10, Batch 100/145, Loss: 0.3344
Epoch 2/10, Batch 110/145, Loss: 0.3521
Epoch 2/10, Batch 120/145, Loss: 0.4844
Epoch 2/10, Batch 130/145, Loss: 0.2666
Epoch 2/10, Batch 140/145, Loss: 0.3121
Epoch 2/10, Train Loss: 0.3638, Valid Loss: 0.3009
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2477
Epoch 3/10, Batch 20/145, Loss: 0.1930
Epoch 3/10, Batch 30/145, Loss: 0.3417
Epoch 3/10, Batch 40/145, Loss: 0.1432
Epoch 3/10, Batch 50/145, Loss: 0.1355
Epoch 3/10, Batch 60/145, Loss: 0.3093
Epoch 3/10, Batch 70/145, Loss: 0.3493
Epoch 3/10, Batch 80/145, Loss: 0.3174
Epoch 3/10, Batch 90/145, Loss: 0.5158
Epoch 3/10, Batch 100/145, Loss: 0.2578
Epoch 3/10, Batch 110/145, Loss: 0.2319
Epoch 3/10, Batch 120/145, Loss: 0.2252
Epoch 3/10, Batch 130/145, Loss: 0.3100
Epoch 3/10, Batch 140/145, Loss: 0.1761
Epoch 3/10, Train Loss: 0.3092, Valid Loss: 0.2675
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1855
Epoch 4/10, Batch 20/145, Loss: 0.2437
Epoch 4/10, Batch 30/145, Loss: 0.3318
Epoch 4/10, Batch 40/145, Loss: 0.3687
Epoch 4/10, Batch 50/145, Loss: 0.2554
Epoch 4/10, Batch 60/145, Loss: 0.2453
Epoch 4/10, Batch 70/145, Loss: 0.1917
Epoch 4/10, Batch 80/145, Loss: 0.3442
Epoch 4/10, Batch 90/145, Loss: 0.2249
Epoch 4/10, Batch 100/145, Loss: 0.2550
Epoch 4/10, Batch 110/145, Loss: 0.1788
Epoch 4/10, Batch 120/145, Loss: 0.1781
Epoch 4/10, Batch 130/145, Loss: 0.1833
Epoch 4/10, Batch 140/145, Loss: 0.2219
Epoch 4/10, Train Loss: 0.2625, Valid Loss: 0.2598
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2334
Epoch 5/10, Batch 20/145, Loss: 0.2131
Epoch 5/10, Batch 30/145, Loss: 0.1952
Epoch 5/10, Batch 40/145, Loss: 0.2977
Epoch 5/10, Batch 50/145, Loss: 0.1907
Epoch 5/10, Batch 60/145, Loss: 0.1297
Epoch 5/10, Batch 70/145, Loss: 0.4704
Epoch 5/10, Batch 80/145, Loss: 0.2378
Epoch 5/10, Batch 90/145, Loss: 0.2557
Epoch 5/10, Batch 100/145, Loss: 0.1234
Epoch 5/10, Batch 110/145, Loss: 0.1191
Epoch 5/10, Batch 120/145, Loss: 0.2059
Epoch 5/10, Batch 130/145, Loss: 0.1919
Epoch 5/10, Batch 140/145, Loss: 0.2770
Epoch 5/10, Train Loss: 0.2395, Valid Loss: 0.2532
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1171
Epoch 6/10, Batch 20/145, Loss: 0.1589
Epoch 6/10, Batch 30/145, Loss: 0.2582
Epoch 6/10, Batch 40/145, Loss: 0.1739
Epoch 6/10, Batch 50/145, Loss: 0.3387
Epoch 6/10, Batch 60/145, Loss: 0.1994
Epoch 6/10, Batch 70/145, Loss: 0.4106
Epoch 6/10, Batch 80/145, Loss: 0.4392
Epoch 6/10, Batch 90/145, Loss: 0.1564
Epoch 6/10, Batch 100/145, Loss: 0.3185
Epoch 6/10, Batch 110/145, Loss: 0.2833
Epoch 6/10, Batch 120/145, Loss: 0.1488
Epoch 6/10, Batch 130/145, Loss: 0.1754
Epoch 6/10, Batch 140/145, Loss: 0.2518
Epoch 6/10, Train Loss: 0.2265, Valid Loss: 0.2508
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3405
Epoch 7/10, Batch 20/145, Loss: 0.3638
Epoch 7/10, Batch 30/145, Loss: 0.1512
Epoch 7/10, Batch 40/145, Loss: 0.4453
Epoch 7/10, Batch 50/145, Loss: 0.2632
Epoch 7/10, Batch 60/145, Loss: 0.2668
Epoch 7/10, Batch 70/145, Loss: 0.1751
Epoch 7/10, Batch 80/145, Loss: 0.1281
Epoch 7/10, Batch 90/145, Loss: 0.2669
Epoch 7/10, Batch 100/145, Loss: 0.1618
Epoch 7/10, Batch 110/145, Loss: 0.2580
Epoch 7/10, Batch 120/145, Loss: 0.2169
Epoch 7/10, Batch 130/145, Loss: 0.2185
Epoch 7/10, Batch 140/145, Loss: 0.2341
Epoch 7/10, Train Loss: 0.2224, Valid Loss: 0.2455
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1267
Epoch 8/10, Batch 20/145, Loss: 0.2071
Epoch 8/10, Batch 30/145, Loss: 0.0981
Epoch 8/10, Batch 40/145, Loss: 0.3122
Epoch 8/10, Batch 50/145, Loss: 0.1472
Epoch 8/10, Batch 60/145, Loss: 0.2616
Epoch 8/10, Batch 70/145, Loss: 0.1543
Epoch 8/10, Batch 80/145, Loss: 0.1331
Epoch 8/10, Batch 90/145, Loss: 0.2585
Epoch 8/10, Batch 100/145, Loss: 0.2114
Epoch 8/10, Batch 110/145, Loss: 0.2927
Epoch 8/10, Batch 120/145, Loss: 0.0965
Epoch 8/10, Batch 130/145, Loss: 0.1892
Epoch 8/10, Batch 140/145, Loss: 0.2898
Epoch 8/10, Train Loss: 0.2110, Valid Loss: 0.2347
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1349
Epoch 9/10, Batch 20/145, Loss: 0.0749
Epoch 9/10, Batch 30/145, Loss: 0.2237
Epoch 9/10, Batch 40/145, Loss: 0.1471
Epoch 9/10, Batch 50/145, Loss: 0.2122
Epoch 9/10, Batch 60/145, Loss: 0.1202
Epoch 9/10, Batch 70/145, Loss: 0.1249
Epoch 9/10, Batch 80/145, Loss: 0.1886
Epoch 9/10, Batch 90/145, Loss: 0.2036
Epoch 9/10, Batch 100/145, Loss: 0.2926
Epoch 9/10, Batch 110/145, Loss: 0.0735
Epoch 9/10, Batch 120/145, Loss: 0.3199
Epoch 9/10, Batch 130/145, Loss: 0.2074
Epoch 9/10, Batch 140/145, Loss: 0.0844
Epoch 9/10, Train Loss: 0.1964, Valid Loss: 0.2260
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1786
Epoch 10/10, Batch 20/145, Loss: 0.0943
Epoch 10/10, Batch 30/145, Loss: 0.0804
Epoch 10/10, Batch 40/145, Loss: 0.3016
Epoch 10/10, Batch 50/145, Loss: 0.1983
Epoch 10/10, Batch 60/145, Loss: 0.1410
Epoch 10/10, Batch 70/145, Loss: 0.0940
Epoch 10/10, Batch 80/145, Loss: 0.3887
Epoch 10/10, Batch 90/145, Loss: 0.1189
Epoch 10/10, Batch 100/145, Loss: 0.1406
Epoch 10/10, Batch 110/145, Loss: 0.2620
Epoch 10/10, Batch 120/145, Loss: 0.2339
Epoch 10/10, Batch 130/145, Loss: 0.1661
Epoch 10/10, Batch 140/145, Loss: 0.2623
Epoch 10/10, Train Loss: 0.1978, Valid Loss: 0.2287
Accuracy: 0.9241
Precision: 0.9222
Recall: 0.9241
F1-score: 0.9227
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4297
Epoch 1/10, Batch 20/145, Loss: 0.9078
Epoch 1/10, Batch 30/145, Loss: 0.8803
Epoch 1/10, Batch 40/145, Loss: 0.9377
Epoch 1/10, Batch 50/145, Loss: 0.6406
Epoch 1/10, Batch 60/145, Loss: 0.6746
Epoch 1/10, Batch 70/145, Loss: 0.5439
Epoch 1/10, Batch 80/145, Loss: 0.4995
Epoch 1/10, Batch 90/145, Loss: 0.4444
Epoch 1/10, Batch 100/145, Loss: 0.6793
Epoch 1/10, Batch 110/145, Loss: 0.4238
Epoch 1/10, Batch 120/145, Loss: 0.6839
Epoch 1/10, Batch 130/145, Loss: 0.3925
Epoch 1/10, Batch 140/145, Loss: 0.3957
Epoch 1/10, Train Loss: 0.6929, Valid Loss: 0.3943
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4265
Epoch 2/10, Batch 20/145, Loss: 0.5770
Epoch 2/10, Batch 30/145, Loss: 0.3198
Epoch 2/10, Batch 40/145, Loss: 0.3250
Epoch 2/10, Batch 50/145, Loss: 0.3436
Epoch 2/10, Batch 60/145, Loss: 0.3706
Epoch 2/10, Batch 70/145, Loss: 0.3662
Epoch 2/10, Batch 80/145, Loss: 0.1802
Epoch 2/10, Batch 90/145, Loss: 0.3098
Epoch 2/10, Batch 100/145, Loss: 0.3316
Epoch 2/10, Batch 110/145, Loss: 0.2451
Epoch 2/10, Batch 120/145, Loss: 0.4657
Epoch 2/10, Batch 130/145, Loss: 0.4325
Epoch 2/10, Batch 140/145, Loss: 0.3467
Epoch 2/10, Train Loss: 0.3690, Valid Loss: 0.3089
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3131
Epoch 3/10, Batch 20/145, Loss: 0.1595
Epoch 3/10, Batch 30/145, Loss: 0.2737
Epoch 3/10, Batch 40/145, Loss: 0.3122
Epoch 3/10, Batch 50/145, Loss: 0.1902
Epoch 3/10, Batch 60/145, Loss: 0.3227
Epoch 3/10, Batch 70/145, Loss: 0.2891
Epoch 3/10, Batch 80/145, Loss: 0.2474
Epoch 3/10, Batch 90/145, Loss: 0.6315
Epoch 3/10, Batch 100/145, Loss: 0.2201
Epoch 3/10, Batch 110/145, Loss: 0.1959
Epoch 3/10, Batch 120/145, Loss: 0.1638
Epoch 3/10, Batch 130/145, Loss: 0.2267
Epoch 3/10, Batch 140/145, Loss: 0.3391
Epoch 3/10, Train Loss: 0.3073, Valid Loss: 0.2868
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2160
Epoch 4/10, Batch 20/145, Loss: 0.2142
Epoch 4/10, Batch 30/145, Loss: 0.2434
Epoch 4/10, Batch 40/145, Loss: 0.3199
Epoch 4/10, Batch 50/145, Loss: 0.1434
Epoch 4/10, Batch 60/145, Loss: 0.2834
Epoch 4/10, Batch 70/145, Loss: 0.2275
Epoch 4/10, Batch 80/145, Loss: 0.2209
Epoch 4/10, Batch 90/145, Loss: 0.2449
Epoch 4/10, Batch 100/145, Loss: 0.1755
Epoch 4/10, Batch 110/145, Loss: 0.2045
Epoch 4/10, Batch 120/145, Loss: 0.2088
Epoch 4/10, Batch 130/145, Loss: 0.1911
Epoch 4/10, Batch 140/145, Loss: 0.3605
Epoch 4/10, Train Loss: 0.2709, Valid Loss: 0.2740
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1678
Epoch 5/10, Batch 20/145, Loss: 0.2201
Epoch 5/10, Batch 30/145, Loss: 0.2926
Epoch 5/10, Batch 40/145, Loss: 0.1879
Epoch 5/10, Batch 50/145, Loss: 0.0863
Epoch 5/10, Batch 60/145, Loss: 0.2938
Epoch 5/10, Batch 70/145, Loss: 0.1496
Epoch 5/10, Batch 80/145, Loss: 0.2067
Epoch 5/10, Batch 90/145, Loss: 0.1549
Epoch 5/10, Batch 100/145, Loss: 0.1676
Epoch 5/10, Batch 110/145, Loss: 0.0790
Epoch 5/10, Batch 120/145, Loss: 0.2646
Epoch 5/10, Batch 130/145, Loss: 0.2013
Epoch 5/10, Batch 140/145, Loss: 0.1843
Epoch 5/10, Train Loss: 0.2469, Valid Loss: 0.2542
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3026
Epoch 6/10, Batch 20/145, Loss: 0.1833
Epoch 6/10, Batch 30/145, Loss: 0.0708
Epoch 6/10, Batch 40/145, Loss: 0.1723
Epoch 6/10, Batch 50/145, Loss: 0.2463
Epoch 6/10, Batch 60/145, Loss: 0.1548
Epoch 6/10, Batch 70/145, Loss: 0.2541
Epoch 6/10, Batch 80/145, Loss: 0.2746
Epoch 6/10, Batch 90/145, Loss: 0.3926
Epoch 6/10, Batch 100/145, Loss: 0.1863
Epoch 6/10, Batch 110/145, Loss: 0.2755
Epoch 6/10, Batch 120/145, Loss: 0.2326
Epoch 6/10, Batch 130/145, Loss: 0.2249
Epoch 6/10, Batch 140/145, Loss: 0.1798
Epoch 6/10, Train Loss: 0.2297, Valid Loss: 0.2434
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3781
Epoch 7/10, Batch 20/145, Loss: 0.2926
Epoch 7/10, Batch 30/145, Loss: 0.1374
Epoch 7/10, Batch 40/145, Loss: 0.4495
Epoch 7/10, Batch 50/145, Loss: 0.1946
Epoch 7/10, Batch 60/145, Loss: 0.2324
Epoch 7/10, Batch 70/145, Loss: 0.2749
Epoch 7/10, Batch 80/145, Loss: 0.2187
Epoch 7/10, Batch 90/145, Loss: 0.1671
Epoch 7/10, Batch 100/145, Loss: 0.2214
Epoch 7/10, Batch 110/145, Loss: 0.1860
Epoch 7/10, Batch 120/145, Loss: 0.3439
Epoch 7/10, Batch 130/145, Loss: 0.2627
Epoch 7/10, Batch 140/145, Loss: 0.1071
Epoch 7/10, Train Loss: 0.2190, Valid Loss: 0.2327
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2838
Epoch 8/10, Batch 20/145, Loss: 0.1059
Epoch 8/10, Batch 30/145, Loss: 0.1862
Epoch 8/10, Batch 40/145, Loss: 0.1146
Epoch 8/10, Batch 50/145, Loss: 0.3713
Epoch 8/10, Batch 60/145, Loss: 0.2943
Epoch 8/10, Batch 70/145, Loss: 0.1155
Epoch 8/10, Batch 80/145, Loss: 0.2800
Epoch 8/10, Batch 90/145, Loss: 0.1242
Epoch 8/10, Batch 100/145, Loss: 0.3437
Epoch 8/10, Batch 110/145, Loss: 0.1758
Epoch 8/10, Batch 120/145, Loss: 0.3423
Epoch 8/10, Batch 130/145, Loss: 0.1776
Epoch 8/10, Batch 140/145, Loss: 0.4605
Epoch 8/10, Train Loss: 0.2105, Valid Loss: 0.2293
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2287
Epoch 9/10, Batch 20/145, Loss: 0.1726
Epoch 9/10, Batch 30/145, Loss: 0.0948
Epoch 9/10, Batch 40/145, Loss: 0.0925
Epoch 9/10, Batch 50/145, Loss: 0.1065
Epoch 9/10, Batch 60/145, Loss: 0.1975
Epoch 9/10, Batch 70/145, Loss: 0.2346
Epoch 9/10, Batch 80/145, Loss: 0.2099
Epoch 9/10, Batch 90/145, Loss: 0.2604
Epoch 9/10, Batch 100/145, Loss: 0.3599
Epoch 9/10, Batch 110/145, Loss: 0.1055
Epoch 9/10, Batch 120/145, Loss: 0.1665
Epoch 9/10, Batch 130/145, Loss: 0.2266
Epoch 9/10, Batch 140/145, Loss: 0.0978
Epoch 9/10, Train Loss: 0.2091, Valid Loss: 0.2254
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2923
Epoch 10/10, Batch 20/145, Loss: 0.0783
Epoch 10/10, Batch 30/145, Loss: 0.1569
Epoch 10/10, Batch 40/145, Loss: 0.1817
Epoch 10/10, Batch 50/145, Loss: 0.3966
Epoch 10/10, Batch 60/145, Loss: 0.0996
Epoch 10/10, Batch 70/145, Loss: 0.1955
Epoch 10/10, Batch 80/145, Loss: 0.2929
Epoch 10/10, Batch 90/145, Loss: 0.1650
Epoch 10/10, Batch 100/145, Loss: 0.2145
Epoch 10/10, Batch 110/145, Loss: 0.1069
Epoch 10/10, Batch 120/145, Loss: 0.1790
Epoch 10/10, Batch 130/145, Loss: 0.0931
Epoch 10/10, Batch 140/145, Loss: 0.2140
Epoch 10/10, Train Loss: 0.1994, Valid Loss: 0.2314
Accuracy: 0.9252
Precision: 0.9239
Recall: 0.9252
F1-score: 0.9242
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4515
Epoch 1/10, Batch 20/145, Loss: 0.8607
Epoch 1/10, Batch 30/145, Loss: 0.8291
Epoch 1/10, Batch 40/145, Loss: 0.7901
Epoch 1/10, Batch 50/145, Loss: 0.5837
Epoch 1/10, Batch 60/145, Loss: 0.6012
Epoch 1/10, Batch 70/145, Loss: 0.6170
Epoch 1/10, Batch 80/145, Loss: 0.4503
Epoch 1/10, Batch 90/145, Loss: 0.6133
Epoch 1/10, Batch 100/145, Loss: 0.6307
Epoch 1/10, Batch 110/145, Loss: 0.4550
Epoch 1/10, Batch 120/145, Loss: 0.5728
Epoch 1/10, Batch 130/145, Loss: 0.4430
Epoch 1/10, Batch 140/145, Loss: 0.3658
Epoch 1/10, Train Loss: 0.6876, Valid Loss: 0.3781
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2664
Epoch 2/10, Batch 20/145, Loss: 0.4000
Epoch 2/10, Batch 30/145, Loss: 0.3594
Epoch 2/10, Batch 40/145, Loss: 0.4767
Epoch 2/10, Batch 50/145, Loss: 0.2983
Epoch 2/10, Batch 60/145, Loss: 0.3427
Epoch 2/10, Batch 70/145, Loss: 0.3939
Epoch 2/10, Batch 80/145, Loss: 0.3193
Epoch 2/10, Batch 90/145, Loss: 0.3530
Epoch 2/10, Batch 100/145, Loss: 0.3209
Epoch 2/10, Batch 110/145, Loss: 0.3997
Epoch 2/10, Batch 120/145, Loss: 0.5493
Epoch 2/10, Batch 130/145, Loss: 0.1956
Epoch 2/10, Batch 140/145, Loss: 0.3077
Epoch 2/10, Train Loss: 0.3701, Valid Loss: 0.2899
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2576
Epoch 3/10, Batch 20/145, Loss: 0.2460
Epoch 3/10, Batch 30/145, Loss: 0.3253
Epoch 3/10, Batch 40/145, Loss: 0.2900
Epoch 3/10, Batch 50/145, Loss: 0.1637
Epoch 3/10, Batch 60/145, Loss: 0.2887
Epoch 3/10, Batch 70/145, Loss: 0.1548
Epoch 3/10, Batch 80/145, Loss: 0.2429
Epoch 3/10, Batch 90/145, Loss: 0.5056
Epoch 3/10, Batch 100/145, Loss: 0.3024
Epoch 3/10, Batch 110/145, Loss: 0.2793
Epoch 3/10, Batch 120/145, Loss: 0.2642
Epoch 3/10, Batch 130/145, Loss: 0.2009
Epoch 3/10, Batch 140/145, Loss: 0.3259
Epoch 3/10, Train Loss: 0.3118, Valid Loss: 0.2649
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2049
Epoch 4/10, Batch 20/145, Loss: 0.3324
Epoch 4/10, Batch 30/145, Loss: 0.2255
Epoch 4/10, Batch 40/145, Loss: 0.1773
Epoch 4/10, Batch 50/145, Loss: 0.1974
Epoch 4/10, Batch 60/145, Loss: 0.1940
Epoch 4/10, Batch 70/145, Loss: 0.3604
Epoch 4/10, Batch 80/145, Loss: 0.4723
Epoch 4/10, Batch 90/145, Loss: 0.2359
Epoch 4/10, Batch 100/145, Loss: 0.2867
Epoch 4/10, Batch 110/145, Loss: 0.2417
Epoch 4/10, Batch 120/145, Loss: 0.1429
Epoch 4/10, Batch 130/145, Loss: 0.2242
Epoch 4/10, Batch 140/145, Loss: 0.2010
Epoch 4/10, Train Loss: 0.2659, Valid Loss: 0.2568
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1637
Epoch 5/10, Batch 20/145, Loss: 0.2222
Epoch 5/10, Batch 30/145, Loss: 0.1422
Epoch 5/10, Batch 40/145, Loss: 0.1375
Epoch 5/10, Batch 50/145, Loss: 0.1481
Epoch 5/10, Batch 60/145, Loss: 0.2449
Epoch 5/10, Batch 70/145, Loss: 0.4556
Epoch 5/10, Batch 80/145, Loss: 0.2842
Epoch 5/10, Batch 90/145, Loss: 0.1380
Epoch 5/10, Batch 100/145, Loss: 0.2442
Epoch 5/10, Batch 110/145, Loss: 0.1017
Epoch 5/10, Batch 120/145, Loss: 0.2205
Epoch 5/10, Batch 130/145, Loss: 0.2111
Epoch 5/10, Batch 140/145, Loss: 0.3600
Epoch 5/10, Train Loss: 0.2424, Valid Loss: 0.2320
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2292
Epoch 6/10, Batch 20/145, Loss: 0.2424
Epoch 6/10, Batch 30/145, Loss: 0.2571
Epoch 6/10, Batch 40/145, Loss: 0.2232
Epoch 6/10, Batch 50/145, Loss: 0.2920
Epoch 6/10, Batch 60/145, Loss: 0.2071
Epoch 6/10, Batch 70/145, Loss: 0.3442
Epoch 6/10, Batch 80/145, Loss: 0.4662
Epoch 6/10, Batch 90/145, Loss: 0.3389
Epoch 6/10, Batch 100/145, Loss: 0.1180
Epoch 6/10, Batch 110/145, Loss: 0.1544
Epoch 6/10, Batch 120/145, Loss: 0.2877
Epoch 6/10, Batch 130/145, Loss: 0.2049
Epoch 6/10, Batch 140/145, Loss: 0.1184
Epoch 6/10, Train Loss: 0.2327, Valid Loss: 0.2353
Epoch 7/10, Batch 10/145, Loss: 0.2451
Epoch 7/10, Batch 20/145, Loss: 0.1941
Epoch 7/10, Batch 30/145, Loss: 0.2588
Epoch 7/10, Batch 40/145, Loss: 0.2050
Epoch 7/10, Batch 50/145, Loss: 0.1861
Epoch 7/10, Batch 60/145, Loss: 0.1561
Epoch 7/10, Batch 70/145, Loss: 0.1560
Epoch 7/10, Batch 80/145, Loss: 0.0892
Epoch 7/10, Batch 90/145, Loss: 0.3206
Epoch 7/10, Batch 100/145, Loss: 0.1181
Epoch 7/10, Batch 110/145, Loss: 0.3674
Epoch 7/10, Batch 120/145, Loss: 0.1928
Epoch 7/10, Batch 130/145, Loss: 0.3541
Epoch 7/10, Batch 140/145, Loss: 0.1495
Epoch 7/10, Train Loss: 0.2190, Valid Loss: 0.2206
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1162
Epoch 8/10, Batch 20/145, Loss: 0.1284
Epoch 8/10, Batch 30/145, Loss: 0.2052
Epoch 8/10, Batch 40/145, Loss: 0.1360
Epoch 8/10, Batch 50/145, Loss: 0.1797
Epoch 8/10, Batch 60/145, Loss: 0.0975
Epoch 8/10, Batch 70/145, Loss: 0.1375
Epoch 8/10, Batch 80/145, Loss: 0.1273
Epoch 8/10, Batch 90/145, Loss: 0.2343
Epoch 8/10, Batch 100/145, Loss: 0.2325
Epoch 8/10, Batch 110/145, Loss: 0.2646
Epoch 8/10, Batch 120/145, Loss: 0.2427
Epoch 8/10, Batch 130/145, Loss: 0.3533
Epoch 8/10, Batch 140/145, Loss: 0.3496
Epoch 8/10, Train Loss: 0.2093, Valid Loss: 0.2220
Epoch 9/10, Batch 10/145, Loss: 0.1829
Epoch 9/10, Batch 20/145, Loss: 0.1924
Epoch 9/10, Batch 30/145, Loss: 0.1067
Epoch 9/10, Batch 40/145, Loss: 0.1342
Epoch 9/10, Batch 50/145, Loss: 0.0911
Epoch 9/10, Batch 60/145, Loss: 0.2535
Epoch 9/10, Batch 70/145, Loss: 0.3262
Epoch 9/10, Batch 80/145, Loss: 0.1338
Epoch 9/10, Batch 90/145, Loss: 0.1198
Epoch 9/10, Batch 100/145, Loss: 0.2064
Epoch 9/10, Batch 110/145, Loss: 0.0784
Epoch 9/10, Batch 120/145, Loss: 0.1320
Epoch 9/10, Batch 130/145, Loss: 0.2532
Epoch 9/10, Batch 140/145, Loss: 0.0579
Epoch 9/10, Train Loss: 0.1974, Valid Loss: 0.2140
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1268
Epoch 10/10, Batch 20/145, Loss: 0.0985
Epoch 10/10, Batch 30/145, Loss: 0.1037
Epoch 10/10, Batch 40/145, Loss: 0.2613
Epoch 10/10, Batch 50/145, Loss: 0.2686
Epoch 10/10, Batch 60/145, Loss: 0.2423
Epoch 10/10, Batch 70/145, Loss: 0.1803
Epoch 10/10, Batch 80/145, Loss: 0.2388
Epoch 10/10, Batch 90/145, Loss: 0.1570
Epoch 10/10, Batch 100/145, Loss: 0.0677
Epoch 10/10, Batch 110/145, Loss: 0.2637
Epoch 10/10, Batch 120/145, Loss: 0.2367
Epoch 10/10, Batch 130/145, Loss: 0.3600
Epoch 10/10, Batch 140/145, Loss: 0.4457
Epoch 10/10, Train Loss: 0.2010, Valid Loss: 0.2163
Accuracy: 0.9241
Precision: 0.9222
Recall: 0.9241
F1-score: 0.9228
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5002
Epoch 1/10, Batch 20/145, Loss: 0.8654
Epoch 1/10, Batch 30/145, Loss: 0.8313
Epoch 1/10, Batch 40/145, Loss: 0.7232
Epoch 1/10, Batch 50/145, Loss: 0.5086
Epoch 1/10, Batch 60/145, Loss: 0.5315
Epoch 1/10, Batch 70/145, Loss: 0.6359
Epoch 1/10, Batch 80/145, Loss: 0.6582
Epoch 1/10, Batch 90/145, Loss: 0.6872
Epoch 1/10, Batch 100/145, Loss: 0.6734
Epoch 1/10, Batch 110/145, Loss: 0.4282
Epoch 1/10, Batch 120/145, Loss: 0.5898
Epoch 1/10, Batch 130/145, Loss: 0.5435
Epoch 1/10, Batch 140/145, Loss: 0.4362
Epoch 1/10, Train Loss: 0.6872, Valid Loss: 0.3777
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2204
Epoch 2/10, Batch 20/145, Loss: 0.4520
Epoch 2/10, Batch 30/145, Loss: 0.3772
Epoch 2/10, Batch 40/145, Loss: 0.2982
Epoch 2/10, Batch 50/145, Loss: 0.3099
Epoch 2/10, Batch 60/145, Loss: 0.5695
Epoch 2/10, Batch 70/145, Loss: 0.4410
Epoch 2/10, Batch 80/145, Loss: 0.3596
Epoch 2/10, Batch 90/145, Loss: 0.2493
Epoch 2/10, Batch 100/145, Loss: 0.4581
Epoch 2/10, Batch 110/145, Loss: 0.2458
Epoch 2/10, Batch 120/145, Loss: 0.4612
Epoch 2/10, Batch 130/145, Loss: 0.3867
Epoch 2/10, Batch 140/145, Loss: 0.3080
Epoch 2/10, Train Loss: 0.3587, Valid Loss: 0.3011
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3104
Epoch 3/10, Batch 20/145, Loss: 0.2828
Epoch 3/10, Batch 30/145, Loss: 0.2249
Epoch 3/10, Batch 40/145, Loss: 0.3172
Epoch 3/10, Batch 50/145, Loss: 0.1980
Epoch 3/10, Batch 60/145, Loss: 0.3641
Epoch 3/10, Batch 70/145, Loss: 0.1827
Epoch 3/10, Batch 80/145, Loss: 0.2853
Epoch 3/10, Batch 90/145, Loss: 0.3876
Epoch 3/10, Batch 100/145, Loss: 0.4038
Epoch 3/10, Batch 110/145, Loss: 0.3400
Epoch 3/10, Batch 120/145, Loss: 0.3653
Epoch 3/10, Batch 130/145, Loss: 0.2042
Epoch 3/10, Batch 140/145, Loss: 0.2178
Epoch 3/10, Train Loss: 0.3057, Valid Loss: 0.2636
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1810
Epoch 4/10, Batch 20/145, Loss: 0.1236
Epoch 4/10, Batch 30/145, Loss: 0.1948
Epoch 4/10, Batch 40/145, Loss: 0.3899
Epoch 4/10, Batch 50/145, Loss: 0.1113
Epoch 4/10, Batch 60/145, Loss: 0.1789
Epoch 4/10, Batch 70/145, Loss: 0.1903
Epoch 4/10, Batch 80/145, Loss: 0.4730
Epoch 4/10, Batch 90/145, Loss: 0.2980
Epoch 4/10, Batch 100/145, Loss: 0.2292
Epoch 4/10, Batch 110/145, Loss: 0.2623
Epoch 4/10, Batch 120/145, Loss: 0.1749
Epoch 4/10, Batch 130/145, Loss: 0.2031
Epoch 4/10, Batch 140/145, Loss: 0.3895
Epoch 4/10, Train Loss: 0.2643, Valid Loss: 0.2568
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1968
Epoch 5/10, Batch 20/145, Loss: 0.3199
Epoch 5/10, Batch 30/145, Loss: 0.3665
Epoch 5/10, Batch 40/145, Loss: 0.1891
Epoch 5/10, Batch 50/145, Loss: 0.1335
Epoch 5/10, Batch 60/145, Loss: 0.1375
Epoch 5/10, Batch 70/145, Loss: 0.2913
Epoch 5/10, Batch 80/145, Loss: 0.3192
Epoch 5/10, Batch 90/145, Loss: 0.2692
Epoch 5/10, Batch 100/145, Loss: 0.2666
Epoch 5/10, Batch 110/145, Loss: 0.1991
Epoch 5/10, Batch 120/145, Loss: 0.1864
Epoch 5/10, Batch 130/145, Loss: 0.1237
Epoch 5/10, Batch 140/145, Loss: 0.2813
Epoch 5/10, Train Loss: 0.2363, Valid Loss: 0.2403
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1604
Epoch 6/10, Batch 20/145, Loss: 0.2931
Epoch 6/10, Batch 30/145, Loss: 0.1486
Epoch 6/10, Batch 40/145, Loss: 0.1154
Epoch 6/10, Batch 50/145, Loss: 0.3525
Epoch 6/10, Batch 60/145, Loss: 0.1671
Epoch 6/10, Batch 70/145, Loss: 0.4416
Epoch 6/10, Batch 80/145, Loss: 0.3198
Epoch 6/10, Batch 90/145, Loss: 0.2343
Epoch 6/10, Batch 100/145, Loss: 0.1991
Epoch 6/10, Batch 110/145, Loss: 0.2305
Epoch 6/10, Batch 120/145, Loss: 0.2322
Epoch 6/10, Batch 130/145, Loss: 0.2300
Epoch 6/10, Batch 140/145, Loss: 0.3266
Epoch 6/10, Train Loss: 0.2319, Valid Loss: 0.2323
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2684
Epoch 7/10, Batch 20/145, Loss: 0.1567
Epoch 7/10, Batch 30/145, Loss: 0.1505
Epoch 7/10, Batch 40/145, Loss: 0.3796
Epoch 7/10, Batch 50/145, Loss: 0.1857
Epoch 7/10, Batch 60/145, Loss: 0.0879
Epoch 7/10, Batch 70/145, Loss: 0.3345
Epoch 7/10, Batch 80/145, Loss: 0.1412
Epoch 7/10, Batch 90/145, Loss: 0.3518
Epoch 7/10, Batch 100/145, Loss: 0.2226
Epoch 7/10, Batch 110/145, Loss: 0.2365
Epoch 7/10, Batch 120/145, Loss: 0.1973
Epoch 7/10, Batch 130/145, Loss: 0.2515
Epoch 7/10, Batch 140/145, Loss: 0.2411
Epoch 7/10, Train Loss: 0.2235, Valid Loss: 0.2342
Epoch 8/10, Batch 10/145, Loss: 0.2712
Epoch 8/10, Batch 20/145, Loss: 0.1470
Epoch 8/10, Batch 30/145, Loss: 0.1192
Epoch 8/10, Batch 40/145, Loss: 0.1472
Epoch 8/10, Batch 50/145, Loss: 0.2622
Epoch 8/10, Batch 60/145, Loss: 0.1571
Epoch 8/10, Batch 70/145, Loss: 0.0823
Epoch 8/10, Batch 80/145, Loss: 0.2271
Epoch 8/10, Batch 90/145, Loss: 0.1231
Epoch 8/10, Batch 100/145, Loss: 0.1691
Epoch 8/10, Batch 110/145, Loss: 0.4621
Epoch 8/10, Batch 120/145, Loss: 0.1541
Epoch 8/10, Batch 130/145, Loss: 0.1786
Epoch 8/10, Batch 140/145, Loss: 0.2772
Epoch 8/10, Train Loss: 0.2128, Valid Loss: 0.2234
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1667
Epoch 9/10, Batch 20/145, Loss: 0.1080
Epoch 9/10, Batch 30/145, Loss: 0.0852
Epoch 9/10, Batch 40/145, Loss: 0.2301
Epoch 9/10, Batch 50/145, Loss: 0.1691
Epoch 9/10, Batch 60/145, Loss: 0.1629
Epoch 9/10, Batch 70/145, Loss: 0.1437
Epoch 9/10, Batch 80/145, Loss: 0.2191
Epoch 9/10, Batch 90/145, Loss: 0.1756
Epoch 9/10, Batch 100/145, Loss: 0.1116
Epoch 9/10, Batch 110/145, Loss: 0.2495
Epoch 9/10, Batch 120/145, Loss: 0.1688
Epoch 9/10, Batch 130/145, Loss: 0.1909
Epoch 9/10, Batch 140/145, Loss: 0.1277
Epoch 9/10, Train Loss: 0.2093, Valid Loss: 0.2178
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1420
Epoch 10/10, Batch 20/145, Loss: 0.2048
Epoch 10/10, Batch 30/145, Loss: 0.0666
Epoch 10/10, Batch 40/145, Loss: 0.1978
Epoch 10/10, Batch 50/145, Loss: 0.2848
Epoch 10/10, Batch 60/145, Loss: 0.1745
Epoch 10/10, Batch 70/145, Loss: 0.1632
Epoch 10/10, Batch 80/145, Loss: 0.4162
Epoch 10/10, Batch 90/145, Loss: 0.2664
Epoch 10/10, Batch 100/145, Loss: 0.2137
Epoch 10/10, Batch 110/145, Loss: 0.2119
Epoch 10/10, Batch 120/145, Loss: 0.2265
Epoch 10/10, Batch 130/145, Loss: 0.2756
Epoch 10/10, Batch 140/145, Loss: 0.2172
Epoch 10/10, Train Loss: 0.1928, Valid Loss: 0.2107
Model saved!
Accuracy: 0.9241
Precision: 0.9228
Recall: 0.9241
F1-score: 0.9233
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5382
Epoch 1/10, Batch 20/145, Loss: 0.9186
Epoch 1/10, Batch 30/145, Loss: 0.8657
Epoch 1/10, Batch 40/145, Loss: 0.8285
Epoch 1/10, Batch 50/145, Loss: 0.5844
Epoch 1/10, Batch 60/145, Loss: 0.5992
Epoch 1/10, Batch 70/145, Loss: 0.5926
Epoch 1/10, Batch 80/145, Loss: 0.4487
Epoch 1/10, Batch 90/145, Loss: 0.6129
Epoch 1/10, Batch 100/145, Loss: 0.7018
Epoch 1/10, Batch 110/145, Loss: 0.4326
Epoch 1/10, Batch 120/145, Loss: 0.5124
Epoch 1/10, Batch 130/145, Loss: 0.5676
Epoch 1/10, Batch 140/145, Loss: 0.3709
Epoch 1/10, Train Loss: 0.6815, Valid Loss: 0.3982
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2574
Epoch 2/10, Batch 20/145, Loss: 0.4188
Epoch 2/10, Batch 30/145, Loss: 0.2665
Epoch 2/10, Batch 40/145, Loss: 0.5167
Epoch 2/10, Batch 50/145, Loss: 0.2221
Epoch 2/10, Batch 60/145, Loss: 0.4498
Epoch 2/10, Batch 70/145, Loss: 0.3928
Epoch 2/10, Batch 80/145, Loss: 0.3393
Epoch 2/10, Batch 90/145, Loss: 0.3395
Epoch 2/10, Batch 100/145, Loss: 0.3419
Epoch 2/10, Batch 110/145, Loss: 0.1947
Epoch 2/10, Batch 120/145, Loss: 0.3973
Epoch 2/10, Batch 130/145, Loss: 0.4317
Epoch 2/10, Batch 140/145, Loss: 0.2081
Epoch 2/10, Train Loss: 0.3565, Valid Loss: 0.3195
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1869
Epoch 3/10, Batch 20/145, Loss: 0.3270
Epoch 3/10, Batch 30/145, Loss: 0.2167
Epoch 3/10, Batch 40/145, Loss: 0.3848
Epoch 3/10, Batch 50/145, Loss: 0.1595
Epoch 3/10, Batch 60/145, Loss: 0.3827
Epoch 3/10, Batch 70/145, Loss: 0.1558
Epoch 3/10, Batch 80/145, Loss: 0.3463
Epoch 3/10, Batch 90/145, Loss: 0.4194
Epoch 3/10, Batch 100/145, Loss: 0.2813
Epoch 3/10, Batch 110/145, Loss: 0.1928
Epoch 3/10, Batch 120/145, Loss: 0.2985
Epoch 3/10, Batch 130/145, Loss: 0.2426
Epoch 3/10, Batch 140/145, Loss: 0.2235
Epoch 3/10, Train Loss: 0.3038, Valid Loss: 0.2855
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1975
Epoch 4/10, Batch 20/145, Loss: 0.2028
Epoch 4/10, Batch 30/145, Loss: 0.2685
Epoch 4/10, Batch 40/145, Loss: 0.4157
Epoch 4/10, Batch 50/145, Loss: 0.3116
Epoch 4/10, Batch 60/145, Loss: 0.1310
Epoch 4/10, Batch 70/145, Loss: 0.2730
Epoch 4/10, Batch 80/145, Loss: 0.2512
Epoch 4/10, Batch 90/145, Loss: 0.4444
Epoch 4/10, Batch 100/145, Loss: 0.2286
Epoch 4/10, Batch 110/145, Loss: 0.2660
Epoch 4/10, Batch 120/145, Loss: 0.1672
Epoch 4/10, Batch 130/145, Loss: 0.2645
Epoch 4/10, Batch 140/145, Loss: 0.3070
Epoch 4/10, Train Loss: 0.2526, Valid Loss: 0.2722
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3691
Epoch 5/10, Batch 20/145, Loss: 0.3066
Epoch 5/10, Batch 30/145, Loss: 0.2295
Epoch 5/10, Batch 40/145, Loss: 0.2023
Epoch 5/10, Batch 50/145, Loss: 0.1509
Epoch 5/10, Batch 60/145, Loss: 0.2567
Epoch 5/10, Batch 70/145, Loss: 0.2609
Epoch 5/10, Batch 80/145, Loss: 0.2884
Epoch 5/10, Batch 90/145, Loss: 0.2799
Epoch 5/10, Batch 100/145, Loss: 0.3463
Epoch 5/10, Batch 110/145, Loss: 0.3348
Epoch 5/10, Batch 120/145, Loss: 0.1326
Epoch 5/10, Batch 130/145, Loss: 0.2898
Epoch 5/10, Batch 140/145, Loss: 0.2766
Epoch 5/10, Train Loss: 0.2387, Valid Loss: 0.2593
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3148
Epoch 6/10, Batch 20/145, Loss: 0.0844
Epoch 6/10, Batch 30/145, Loss: 0.1839
Epoch 6/10, Batch 40/145, Loss: 0.3075
Epoch 6/10, Batch 50/145, Loss: 0.2724
Epoch 6/10, Batch 60/145, Loss: 0.1322
Epoch 6/10, Batch 70/145, Loss: 0.2847
Epoch 6/10, Batch 80/145, Loss: 0.2861
Epoch 6/10, Batch 90/145, Loss: 0.3084
Epoch 6/10, Batch 100/145, Loss: 0.1105
Epoch 6/10, Batch 110/145, Loss: 0.1745
Epoch 6/10, Batch 120/145, Loss: 0.3208
Epoch 6/10, Batch 130/145, Loss: 0.1879
Epoch 6/10, Batch 140/145, Loss: 0.2843
Epoch 6/10, Train Loss: 0.2274, Valid Loss: 0.2707
Epoch 7/10, Batch 10/145, Loss: 0.3970
Epoch 7/10, Batch 20/145, Loss: 0.2292
Epoch 7/10, Batch 30/145, Loss: 0.2259
Epoch 7/10, Batch 40/145, Loss: 0.4374
Epoch 7/10, Batch 50/145, Loss: 0.2616
Epoch 7/10, Batch 60/145, Loss: 0.1759
Epoch 7/10, Batch 70/145, Loss: 0.5044
Epoch 7/10, Batch 80/145, Loss: 0.1227
Epoch 7/10, Batch 90/145, Loss: 0.2373
Epoch 7/10, Batch 100/145, Loss: 0.1750
Epoch 7/10, Batch 110/145, Loss: 0.1382
Epoch 7/10, Batch 120/145, Loss: 0.0914
Epoch 7/10, Batch 130/145, Loss: 0.2766
Epoch 7/10, Batch 140/145, Loss: 0.2476
Epoch 7/10, Train Loss: 0.2189, Valid Loss: 0.2527
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1224
Epoch 8/10, Batch 20/145, Loss: 0.1432
Epoch 8/10, Batch 30/145, Loss: 0.1739
Epoch 8/10, Batch 40/145, Loss: 0.2014
Epoch 8/10, Batch 50/145, Loss: 0.0794
Epoch 8/10, Batch 60/145, Loss: 0.2134
Epoch 8/10, Batch 70/145, Loss: 0.1810
Epoch 8/10, Batch 80/145, Loss: 0.3666
Epoch 8/10, Batch 90/145, Loss: 0.0812
Epoch 8/10, Batch 100/145, Loss: 0.2482
Epoch 8/10, Batch 110/145, Loss: 0.2196
Epoch 8/10, Batch 120/145, Loss: 0.1647
Epoch 8/10, Batch 130/145, Loss: 0.0926
Epoch 8/10, Batch 140/145, Loss: 0.2336
Epoch 8/10, Train Loss: 0.2058, Valid Loss: 0.2461
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1349
Epoch 9/10, Batch 20/145, Loss: 0.0632
Epoch 9/10, Batch 30/145, Loss: 0.0910
Epoch 9/10, Batch 40/145, Loss: 0.3762
Epoch 9/10, Batch 50/145, Loss: 0.1232
Epoch 9/10, Batch 60/145, Loss: 0.1757
Epoch 9/10, Batch 70/145, Loss: 0.2956
Epoch 9/10, Batch 80/145, Loss: 0.2609
Epoch 9/10, Batch 90/145, Loss: 0.0678
Epoch 9/10, Batch 100/145, Loss: 0.1620
Epoch 9/10, Batch 110/145, Loss: 0.1529
Epoch 9/10, Batch 120/145, Loss: 0.2412
Epoch 9/10, Batch 130/145, Loss: 0.0973
Epoch 9/10, Batch 140/145, Loss: 0.0799
Epoch 9/10, Train Loss: 0.2035, Valid Loss: 0.2422
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1475
Epoch 10/10, Batch 20/145, Loss: 0.2373
Epoch 10/10, Batch 30/145, Loss: 0.1359
Epoch 10/10, Batch 40/145, Loss: 0.1343
Epoch 10/10, Batch 50/145, Loss: 0.3367
Epoch 10/10, Batch 60/145, Loss: 0.2340
Epoch 10/10, Batch 70/145, Loss: 0.1138
Epoch 10/10, Batch 80/145, Loss: 0.3840
Epoch 10/10, Batch 90/145, Loss: 0.1428
Epoch 10/10, Batch 100/145, Loss: 0.2156
Epoch 10/10, Batch 110/145, Loss: 0.1894
Epoch 10/10, Batch 120/145, Loss: 0.1649
Epoch 10/10, Batch 130/145, Loss: 0.3087
Epoch 10/10, Batch 140/145, Loss: 0.1664
Epoch 10/10, Train Loss: 0.1920, Valid Loss: 0.2372
Model saved!
Accuracy: 0.9206
Precision: 0.9183
Recall: 0.9206
F1-score: 0.9190
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4479
Epoch 1/10, Batch 20/145, Loss: 0.8939
Epoch 1/10, Batch 30/145, Loss: 0.8435
Epoch 1/10, Batch 40/145, Loss: 0.7068
Epoch 1/10, Batch 50/145, Loss: 0.5578
Epoch 1/10, Batch 60/145, Loss: 0.5421
Epoch 1/10, Batch 70/145, Loss: 0.6740
Epoch 1/10, Batch 80/145, Loss: 0.5687
Epoch 1/10, Batch 90/145, Loss: 0.4128
Epoch 1/10, Batch 100/145, Loss: 0.7033
Epoch 1/10, Batch 110/145, Loss: 0.4081
Epoch 1/10, Batch 120/145, Loss: 0.6122
Epoch 1/10, Batch 130/145, Loss: 0.5010
Epoch 1/10, Batch 140/145, Loss: 0.4225
Epoch 1/10, Train Loss: 0.6917, Valid Loss: 0.3871
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3199
Epoch 2/10, Batch 20/145, Loss: 0.4838
Epoch 2/10, Batch 30/145, Loss: 0.2964
Epoch 2/10, Batch 40/145, Loss: 0.3764
Epoch 2/10, Batch 50/145, Loss: 0.3555
Epoch 2/10, Batch 60/145, Loss: 0.5085
Epoch 2/10, Batch 70/145, Loss: 0.3968
Epoch 2/10, Batch 80/145, Loss: 0.2549
Epoch 2/10, Batch 90/145, Loss: 0.4096
Epoch 2/10, Batch 100/145, Loss: 0.2839
Epoch 2/10, Batch 110/145, Loss: 0.3794
Epoch 2/10, Batch 120/145, Loss: 0.3868
Epoch 2/10, Batch 130/145, Loss: 0.3393
Epoch 2/10, Batch 140/145, Loss: 0.2580
Epoch 2/10, Train Loss: 0.3652, Valid Loss: 0.2950
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3144
Epoch 3/10, Batch 20/145, Loss: 0.4002
Epoch 3/10, Batch 30/145, Loss: 0.3438
Epoch 3/10, Batch 40/145, Loss: 0.2471
Epoch 3/10, Batch 50/145, Loss: 0.2062
Epoch 3/10, Batch 60/145, Loss: 0.4773
Epoch 3/10, Batch 70/145, Loss: 0.1970
Epoch 3/10, Batch 80/145, Loss: 0.1973
Epoch 3/10, Batch 90/145, Loss: 0.5586
Epoch 3/10, Batch 100/145, Loss: 0.3803
Epoch 3/10, Batch 110/145, Loss: 0.2436
Epoch 3/10, Batch 120/145, Loss: 0.2405
Epoch 3/10, Batch 130/145, Loss: 0.3002
Epoch 3/10, Batch 140/145, Loss: 0.2077
Epoch 3/10, Train Loss: 0.3084, Valid Loss: 0.2672
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2366
Epoch 4/10, Batch 20/145, Loss: 0.3086
Epoch 4/10, Batch 30/145, Loss: 0.2546
Epoch 4/10, Batch 40/145, Loss: 0.2944
Epoch 4/10, Batch 50/145, Loss: 0.1784
Epoch 4/10, Batch 60/145, Loss: 0.2160
Epoch 4/10, Batch 70/145, Loss: 0.2307
Epoch 4/10, Batch 80/145, Loss: 0.2431
Epoch 4/10, Batch 90/145, Loss: 0.2522
Epoch 4/10, Batch 100/145, Loss: 0.1555
Epoch 4/10, Batch 110/145, Loss: 0.1969
Epoch 4/10, Batch 120/145, Loss: 0.1593
Epoch 4/10, Batch 130/145, Loss: 0.2643
Epoch 4/10, Batch 140/145, Loss: 0.2521
Epoch 4/10, Train Loss: 0.2610, Valid Loss: 0.2477
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1914
Epoch 5/10, Batch 20/145, Loss: 0.2125
Epoch 5/10, Batch 30/145, Loss: 0.2402
Epoch 5/10, Batch 40/145, Loss: 0.2770
Epoch 5/10, Batch 50/145, Loss: 0.1175
Epoch 5/10, Batch 60/145, Loss: 0.1358
Epoch 5/10, Batch 70/145, Loss: 0.1508
Epoch 5/10, Batch 80/145, Loss: 0.3768
Epoch 5/10, Batch 90/145, Loss: 0.2362
Epoch 5/10, Batch 100/145, Loss: 0.2363
Epoch 5/10, Batch 110/145, Loss: 0.1443
Epoch 5/10, Batch 120/145, Loss: 0.2761
Epoch 5/10, Batch 130/145, Loss: 0.2712
Epoch 5/10, Batch 140/145, Loss: 0.3083
Epoch 5/10, Train Loss: 0.2408, Valid Loss: 0.2323
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3728
Epoch 6/10, Batch 20/145, Loss: 0.1227
Epoch 6/10, Batch 30/145, Loss: 0.1282
Epoch 6/10, Batch 40/145, Loss: 0.0799
Epoch 6/10, Batch 50/145, Loss: 0.1754
Epoch 6/10, Batch 60/145, Loss: 0.2289
Epoch 6/10, Batch 70/145, Loss: 0.1654
Epoch 6/10, Batch 80/145, Loss: 0.3110
Epoch 6/10, Batch 90/145, Loss: 0.2805
Epoch 6/10, Batch 100/145, Loss: 0.1526
Epoch 6/10, Batch 110/145, Loss: 0.1949
Epoch 6/10, Batch 120/145, Loss: 0.2856
Epoch 6/10, Batch 130/145, Loss: 0.2138
Epoch 6/10, Batch 140/145, Loss: 0.2087
Epoch 6/10, Train Loss: 0.2317, Valid Loss: 0.2145
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2337
Epoch 7/10, Batch 20/145, Loss: 0.2104
Epoch 7/10, Batch 30/145, Loss: 0.1872
Epoch 7/10, Batch 40/145, Loss: 0.3736
Epoch 7/10, Batch 50/145, Loss: 0.3086
Epoch 7/10, Batch 60/145, Loss: 0.1477
Epoch 7/10, Batch 70/145, Loss: 0.1399
Epoch 7/10, Batch 80/145, Loss: 0.3964
Epoch 7/10, Batch 90/145, Loss: 0.2263
Epoch 7/10, Batch 100/145, Loss: 0.1965
Epoch 7/10, Batch 110/145, Loss: 0.1879
Epoch 7/10, Batch 120/145, Loss: 0.3316
Epoch 7/10, Batch 130/145, Loss: 0.1432
Epoch 7/10, Batch 140/145, Loss: 0.1421
Epoch 7/10, Train Loss: 0.2200, Valid Loss: 0.2102
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1703
Epoch 8/10, Batch 20/145, Loss: 0.1872
Epoch 8/10, Batch 30/145, Loss: 0.1751
Epoch 8/10, Batch 40/145, Loss: 0.2198
Epoch 8/10, Batch 50/145, Loss: 0.2260
Epoch 8/10, Batch 60/145, Loss: 0.1785
Epoch 8/10, Batch 70/145, Loss: 0.2263
Epoch 8/10, Batch 80/145, Loss: 0.2386
Epoch 8/10, Batch 90/145, Loss: 0.0890
Epoch 8/10, Batch 100/145, Loss: 0.2927
Epoch 8/10, Batch 110/145, Loss: 0.1739
Epoch 8/10, Batch 120/145, Loss: 0.2373
Epoch 8/10, Batch 130/145, Loss: 0.1764
Epoch 8/10, Batch 140/145, Loss: 0.2505
Epoch 8/10, Train Loss: 0.2075, Valid Loss: 0.2094
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1696
Epoch 9/10, Batch 20/145, Loss: 0.1706
Epoch 9/10, Batch 30/145, Loss: 0.1377
Epoch 9/10, Batch 40/145, Loss: 0.1814
Epoch 9/10, Batch 50/145, Loss: 0.2274
Epoch 9/10, Batch 60/145, Loss: 0.2526
Epoch 9/10, Batch 70/145, Loss: 0.1645
Epoch 9/10, Batch 80/145, Loss: 0.1598
Epoch 9/10, Batch 90/145, Loss: 0.1566
Epoch 9/10, Batch 100/145, Loss: 0.2523
Epoch 9/10, Batch 110/145, Loss: 0.0812
Epoch 9/10, Batch 120/145, Loss: 0.2728
Epoch 9/10, Batch 130/145, Loss: 0.2216
Epoch 9/10, Batch 140/145, Loss: 0.1631
Epoch 9/10, Train Loss: 0.2011, Valid Loss: 0.2025
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1630
Epoch 10/10, Batch 20/145, Loss: 0.0719
Epoch 10/10, Batch 30/145, Loss: 0.0879
Epoch 10/10, Batch 40/145, Loss: 0.1564
Epoch 10/10, Batch 50/145, Loss: 0.2376
Epoch 10/10, Batch 60/145, Loss: 0.0962
Epoch 10/10, Batch 70/145, Loss: 0.2157
Epoch 10/10, Batch 80/145, Loss: 0.2801
Epoch 10/10, Batch 90/145, Loss: 0.2588
Epoch 10/10, Batch 100/145, Loss: 0.0642
Epoch 10/10, Batch 110/145, Loss: 0.1867
Epoch 10/10, Batch 120/145, Loss: 0.1923
Epoch 10/10, Batch 130/145, Loss: 0.1924
Epoch 10/10, Batch 140/145, Loss: 0.2673
Epoch 10/10, Train Loss: 0.1891, Valid Loss: 0.2100
Accuracy: 0.9276
Precision: 0.9262
Recall: 0.9276
F1-score: 0.9265
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4866
Epoch 1/10, Batch 20/145, Loss: 0.9403
Epoch 1/10, Batch 30/145, Loss: 0.8666
Epoch 1/10, Batch 40/145, Loss: 0.7114
Epoch 1/10, Batch 50/145, Loss: 0.5544
Epoch 1/10, Batch 60/145, Loss: 0.6368
Epoch 1/10, Batch 70/145, Loss: 0.5836
Epoch 1/10, Batch 80/145, Loss: 0.4954
Epoch 1/10, Batch 90/145, Loss: 0.6995
Epoch 1/10, Batch 100/145, Loss: 0.6902
Epoch 1/10, Batch 110/145, Loss: 0.4452
Epoch 1/10, Batch 120/145, Loss: 0.5375
Epoch 1/10, Batch 130/145, Loss: 0.4405
Epoch 1/10, Batch 140/145, Loss: 0.3974
Epoch 1/10, Train Loss: 0.6877, Valid Loss: 0.3689
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3898
Epoch 2/10, Batch 20/145, Loss: 0.4935
Epoch 2/10, Batch 30/145, Loss: 0.4276
Epoch 2/10, Batch 40/145, Loss: 0.4442
Epoch 2/10, Batch 50/145, Loss: 0.3419
Epoch 2/10, Batch 60/145, Loss: 0.5326
Epoch 2/10, Batch 70/145, Loss: 0.4849
Epoch 2/10, Batch 80/145, Loss: 0.3956
Epoch 2/10, Batch 90/145, Loss: 0.3848
Epoch 2/10, Batch 100/145, Loss: 0.1972
Epoch 2/10, Batch 110/145, Loss: 0.1930
Epoch 2/10, Batch 120/145, Loss: 0.4128
Epoch 2/10, Batch 130/145, Loss: 0.5274
Epoch 2/10, Batch 140/145, Loss: 0.2422
Epoch 2/10, Train Loss: 0.3642, Valid Loss: 0.2803
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2452
Epoch 3/10, Batch 20/145, Loss: 0.2502
Epoch 3/10, Batch 30/145, Loss: 0.3570
Epoch 3/10, Batch 40/145, Loss: 0.3326
Epoch 3/10, Batch 50/145, Loss: 0.1691
Epoch 3/10, Batch 60/145, Loss: 0.2888
Epoch 3/10, Batch 70/145, Loss: 0.2072
Epoch 3/10, Batch 80/145, Loss: 0.2313
Epoch 3/10, Batch 90/145, Loss: 0.5132
Epoch 3/10, Batch 100/145, Loss: 0.2691
Epoch 3/10, Batch 110/145, Loss: 0.1852
Epoch 3/10, Batch 120/145, Loss: 0.1489
Epoch 3/10, Batch 130/145, Loss: 0.2765
Epoch 3/10, Batch 140/145, Loss: 0.2246
Epoch 3/10, Train Loss: 0.3031, Valid Loss: 0.2453
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1463
Epoch 4/10, Batch 20/145, Loss: 0.3281
Epoch 4/10, Batch 30/145, Loss: 0.4049
Epoch 4/10, Batch 40/145, Loss: 0.3572
Epoch 4/10, Batch 50/145, Loss: 0.3302
Epoch 4/10, Batch 60/145, Loss: 0.2733
Epoch 4/10, Batch 70/145, Loss: 0.2258
Epoch 4/10, Batch 80/145, Loss: 0.2051
Epoch 4/10, Batch 90/145, Loss: 0.2084
Epoch 4/10, Batch 100/145, Loss: 0.2166
Epoch 4/10, Batch 110/145, Loss: 0.1868
Epoch 4/10, Batch 120/145, Loss: 0.2072
Epoch 4/10, Batch 130/145, Loss: 0.2526
Epoch 4/10, Batch 140/145, Loss: 0.2688
Epoch 4/10, Train Loss: 0.2735, Valid Loss: 0.2409
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2636
Epoch 5/10, Batch 20/145, Loss: 0.2463
Epoch 5/10, Batch 30/145, Loss: 0.3008
Epoch 5/10, Batch 40/145, Loss: 0.1780
Epoch 5/10, Batch 50/145, Loss: 0.1684
Epoch 5/10, Batch 60/145, Loss: 0.4018
Epoch 5/10, Batch 70/145, Loss: 0.3069
Epoch 5/10, Batch 80/145, Loss: 0.3774
Epoch 5/10, Batch 90/145, Loss: 0.1886
Epoch 5/10, Batch 100/145, Loss: 0.2371
Epoch 5/10, Batch 110/145, Loss: 0.1783
Epoch 5/10, Batch 120/145, Loss: 0.1223
Epoch 5/10, Batch 130/145, Loss: 0.1884
Epoch 5/10, Batch 140/145, Loss: 0.2148
Epoch 5/10, Train Loss: 0.2404, Valid Loss: 0.2242
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3119
Epoch 6/10, Batch 20/145, Loss: 0.3267
Epoch 6/10, Batch 30/145, Loss: 0.1490
Epoch 6/10, Batch 40/145, Loss: 0.0870
Epoch 6/10, Batch 50/145, Loss: 0.4382
Epoch 6/10, Batch 60/145, Loss: 0.1745
Epoch 6/10, Batch 70/145, Loss: 0.2529
Epoch 6/10, Batch 80/145, Loss: 0.1865
Epoch 6/10, Batch 90/145, Loss: 0.2341
Epoch 6/10, Batch 100/145, Loss: 0.1669
Epoch 6/10, Batch 110/145, Loss: 0.1186
Epoch 6/10, Batch 120/145, Loss: 0.1793
Epoch 6/10, Batch 130/145, Loss: 0.1375
Epoch 6/10, Batch 140/145, Loss: 0.2588
Epoch 6/10, Train Loss: 0.2258, Valid Loss: 0.2119
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1871
Epoch 7/10, Batch 20/145, Loss: 0.2276
Epoch 7/10, Batch 30/145, Loss: 0.2076
Epoch 7/10, Batch 40/145, Loss: 0.3418
Epoch 7/10, Batch 50/145, Loss: 0.1350
Epoch 7/10, Batch 60/145, Loss: 0.2477
Epoch 7/10, Batch 70/145, Loss: 0.1642
Epoch 7/10, Batch 80/145, Loss: 0.2947
Epoch 7/10, Batch 90/145, Loss: 0.2999
Epoch 7/10, Batch 100/145, Loss: 0.1723
Epoch 7/10, Batch 110/145, Loss: 0.1577
Epoch 7/10, Batch 120/145, Loss: 0.1975
Epoch 7/10, Batch 130/145, Loss: 0.3304
Epoch 7/10, Batch 140/145, Loss: 0.1558
Epoch 7/10, Train Loss: 0.2145, Valid Loss: 0.2119
Epoch 8/10, Batch 10/145, Loss: 0.2535
Epoch 8/10, Batch 20/145, Loss: 0.1415
Epoch 8/10, Batch 30/145, Loss: 0.1269
Epoch 8/10, Batch 40/145, Loss: 0.2044
Epoch 8/10, Batch 50/145, Loss: 0.3986
Epoch 8/10, Batch 60/145, Loss: 0.1363
Epoch 8/10, Batch 70/145, Loss: 0.1806
Epoch 8/10, Batch 80/145, Loss: 0.1162
Epoch 8/10, Batch 90/145, Loss: 0.2503
Epoch 8/10, Batch 100/145, Loss: 0.2277
Epoch 8/10, Batch 110/145, Loss: 0.2604
Epoch 8/10, Batch 120/145, Loss: 0.1165
Epoch 8/10, Batch 130/145, Loss: 0.1863
Epoch 8/10, Batch 140/145, Loss: 0.3905
Epoch 8/10, Train Loss: 0.2142, Valid Loss: 0.1965
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1979
Epoch 9/10, Batch 20/145, Loss: 0.1500
Epoch 9/10, Batch 30/145, Loss: 0.1591
Epoch 9/10, Batch 40/145, Loss: 0.1580
Epoch 9/10, Batch 50/145, Loss: 0.2484
Epoch 9/10, Batch 60/145, Loss: 0.2158
Epoch 9/10, Batch 70/145, Loss: 0.1587
Epoch 9/10, Batch 80/145, Loss: 0.2054
Epoch 9/10, Batch 90/145, Loss: 0.1305
Epoch 9/10, Batch 100/145, Loss: 0.1687
Epoch 9/10, Batch 110/145, Loss: 0.1334
Epoch 9/10, Batch 120/145, Loss: 0.1453
Epoch 9/10, Batch 130/145, Loss: 0.1753
Epoch 9/10, Batch 140/145, Loss: 0.1701
Epoch 9/10, Train Loss: 0.2003, Valid Loss: 0.1988
Epoch 10/10, Batch 10/145, Loss: 0.1819
Epoch 10/10, Batch 20/145, Loss: 0.2205
Epoch 10/10, Batch 30/145, Loss: 0.1534
Epoch 10/10, Batch 40/145, Loss: 0.2885
Epoch 10/10, Batch 50/145, Loss: 0.2809
Epoch 10/10, Batch 60/145, Loss: 0.1874
Epoch 10/10, Batch 70/145, Loss: 0.1659
Epoch 10/10, Batch 80/145, Loss: 0.4483
Epoch 10/10, Batch 90/145, Loss: 0.2214
Epoch 10/10, Batch 100/145, Loss: 0.2258
Epoch 10/10, Batch 110/145, Loss: 0.2307
Epoch 10/10, Batch 120/145, Loss: 0.3540
Epoch 10/10, Batch 130/145, Loss: 0.1163
Epoch 10/10, Batch 140/145, Loss: 0.3061
Epoch 10/10, Train Loss: 0.1999, Valid Loss: 0.2070
Accuracy: 0.9194
Precision: 0.9167
Recall: 0.9194
F1-score: 0.9175
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4860
Epoch 1/10, Batch 20/145, Loss: 0.9274
Epoch 1/10, Batch 30/145, Loss: 0.8686
Epoch 1/10, Batch 40/145, Loss: 0.8162
Epoch 1/10, Batch 50/145, Loss: 0.6870
Epoch 1/10, Batch 60/145, Loss: 0.5645
Epoch 1/10, Batch 70/145, Loss: 0.6509
Epoch 1/10, Batch 80/145, Loss: 0.5486
Epoch 1/10, Batch 90/145, Loss: 0.5196
Epoch 1/10, Batch 100/145, Loss: 0.6316
Epoch 1/10, Batch 110/145, Loss: 0.4013
Epoch 1/10, Batch 120/145, Loss: 0.4899
Epoch 1/10, Batch 130/145, Loss: 0.4355
Epoch 1/10, Batch 140/145, Loss: 0.4032
Epoch 1/10, Train Loss: 0.6881, Valid Loss: 0.3765
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2973
Epoch 2/10, Batch 20/145, Loss: 0.5116
Epoch 2/10, Batch 30/145, Loss: 0.3340
Epoch 2/10, Batch 40/145, Loss: 0.4686
Epoch 2/10, Batch 50/145, Loss: 0.3507
Epoch 2/10, Batch 60/145, Loss: 0.4352
Epoch 2/10, Batch 70/145, Loss: 0.3802
Epoch 2/10, Batch 80/145, Loss: 0.4790
Epoch 2/10, Batch 90/145, Loss: 0.3131
Epoch 2/10, Batch 100/145, Loss: 0.5467
Epoch 2/10, Batch 110/145, Loss: 0.2627
Epoch 2/10, Batch 120/145, Loss: 0.5163
Epoch 2/10, Batch 130/145, Loss: 0.4123
Epoch 2/10, Batch 140/145, Loss: 0.3962
Epoch 2/10, Train Loss: 0.3598, Valid Loss: 0.2904
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2505
Epoch 3/10, Batch 20/145, Loss: 0.2321
Epoch 3/10, Batch 30/145, Loss: 0.2225
Epoch 3/10, Batch 40/145, Loss: 0.2775
Epoch 3/10, Batch 50/145, Loss: 0.1765
Epoch 3/10, Batch 60/145, Loss: 0.2609
Epoch 3/10, Batch 70/145, Loss: 0.2425
Epoch 3/10, Batch 80/145, Loss: 0.2019
Epoch 3/10, Batch 90/145, Loss: 0.5907
Epoch 3/10, Batch 100/145, Loss: 0.4575
Epoch 3/10, Batch 110/145, Loss: 0.2097
Epoch 3/10, Batch 120/145, Loss: 0.2047
Epoch 3/10, Batch 130/145, Loss: 0.3473
Epoch 3/10, Batch 140/145, Loss: 0.1430
Epoch 3/10, Train Loss: 0.3061, Valid Loss: 0.2578
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1845
Epoch 4/10, Batch 20/145, Loss: 0.3024
Epoch 4/10, Batch 30/145, Loss: 0.2706
Epoch 4/10, Batch 40/145, Loss: 0.2424
Epoch 4/10, Batch 50/145, Loss: 0.2124
Epoch 4/10, Batch 60/145, Loss: 0.3500
Epoch 4/10, Batch 70/145, Loss: 0.3030
Epoch 4/10, Batch 80/145, Loss: 0.3210
Epoch 4/10, Batch 90/145, Loss: 0.2442
Epoch 4/10, Batch 100/145, Loss: 0.2095
Epoch 4/10, Batch 110/145, Loss: 0.2513
Epoch 4/10, Batch 120/145, Loss: 0.2302
Epoch 4/10, Batch 130/145, Loss: 0.1562
Epoch 4/10, Batch 140/145, Loss: 0.2065
Epoch 4/10, Train Loss: 0.2655, Valid Loss: 0.2479
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2089
Epoch 5/10, Batch 20/145, Loss: 0.3753
Epoch 5/10, Batch 30/145, Loss: 0.1802
Epoch 5/10, Batch 40/145, Loss: 0.2667
Epoch 5/10, Batch 50/145, Loss: 0.1380
Epoch 5/10, Batch 60/145, Loss: 0.2478
Epoch 5/10, Batch 70/145, Loss: 0.3828
Epoch 5/10, Batch 80/145, Loss: 0.2518
Epoch 5/10, Batch 90/145, Loss: 0.2001
Epoch 5/10, Batch 100/145, Loss: 0.2112
Epoch 5/10, Batch 110/145, Loss: 0.1131
Epoch 5/10, Batch 120/145, Loss: 0.2324
Epoch 5/10, Batch 130/145, Loss: 0.1622
Epoch 5/10, Batch 140/145, Loss: 0.2385
Epoch 5/10, Train Loss: 0.2370, Valid Loss: 0.2276
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1921
Epoch 6/10, Batch 20/145, Loss: 0.2865
Epoch 6/10, Batch 30/145, Loss: 0.1485
Epoch 6/10, Batch 40/145, Loss: 0.1416
Epoch 6/10, Batch 50/145, Loss: 0.3256
Epoch 6/10, Batch 60/145, Loss: 0.2356
Epoch 6/10, Batch 70/145, Loss: 0.3170
Epoch 6/10, Batch 80/145, Loss: 0.4274
Epoch 6/10, Batch 90/145, Loss: 0.2480
Epoch 6/10, Batch 100/145, Loss: 0.1982
Epoch 6/10, Batch 110/145, Loss: 0.1138
Epoch 6/10, Batch 120/145, Loss: 0.2449
Epoch 6/10, Batch 130/145, Loss: 0.1731
Epoch 6/10, Batch 140/145, Loss: 0.0753
Epoch 6/10, Train Loss: 0.2293, Valid Loss: 0.2177
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1963
Epoch 7/10, Batch 20/145, Loss: 0.1763
Epoch 7/10, Batch 30/145, Loss: 0.1953
Epoch 7/10, Batch 40/145, Loss: 0.3929
Epoch 7/10, Batch 50/145, Loss: 0.1389
Epoch 7/10, Batch 60/145, Loss: 0.1531
Epoch 7/10, Batch 70/145, Loss: 0.1719
Epoch 7/10, Batch 80/145, Loss: 0.3035
Epoch 7/10, Batch 90/145, Loss: 0.4261
Epoch 7/10, Batch 100/145, Loss: 0.3844
Epoch 7/10, Batch 110/145, Loss: 0.1993
Epoch 7/10, Batch 120/145, Loss: 0.2654
Epoch 7/10, Batch 130/145, Loss: 0.1645
Epoch 7/10, Batch 140/145, Loss: 0.1897
Epoch 7/10, Train Loss: 0.2167, Valid Loss: 0.2145
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2594
Epoch 8/10, Batch 20/145, Loss: 0.2129
Epoch 8/10, Batch 30/145, Loss: 0.1210
Epoch 8/10, Batch 40/145, Loss: 0.3784
Epoch 8/10, Batch 50/145, Loss: 0.2944
Epoch 8/10, Batch 60/145, Loss: 0.2073
Epoch 8/10, Batch 70/145, Loss: 0.1201
Epoch 8/10, Batch 80/145, Loss: 0.1294
Epoch 8/10, Batch 90/145, Loss: 0.2202
Epoch 8/10, Batch 100/145, Loss: 0.1717
Epoch 8/10, Batch 110/145, Loss: 0.2469
Epoch 8/10, Batch 120/145, Loss: 0.1546
Epoch 8/10, Batch 130/145, Loss: 0.1081
Epoch 8/10, Batch 140/145, Loss: 0.3032
Epoch 8/10, Train Loss: 0.2095, Valid Loss: 0.2025
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1859
Epoch 9/10, Batch 20/145, Loss: 0.1755
Epoch 9/10, Batch 30/145, Loss: 0.1866
Epoch 9/10, Batch 40/145, Loss: 0.2084
Epoch 9/10, Batch 50/145, Loss: 0.1808
Epoch 9/10, Batch 60/145, Loss: 0.1200
Epoch 9/10, Batch 70/145, Loss: 0.3276
Epoch 9/10, Batch 80/145, Loss: 0.2422
Epoch 9/10, Batch 90/145, Loss: 0.1226
Epoch 9/10, Batch 100/145, Loss: 0.3495
Epoch 9/10, Batch 110/145, Loss: 0.0409
Epoch 9/10, Batch 120/145, Loss: 0.2872
Epoch 9/10, Batch 130/145, Loss: 0.2203
Epoch 9/10, Batch 140/145, Loss: 0.2150
Epoch 9/10, Train Loss: 0.2055, Valid Loss: 0.1995
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1806
Epoch 10/10, Batch 20/145, Loss: 0.2014
Epoch 10/10, Batch 30/145, Loss: 0.2185
Epoch 10/10, Batch 40/145, Loss: 0.1796
Epoch 10/10, Batch 50/145, Loss: 0.2287
Epoch 10/10, Batch 60/145, Loss: 0.2042
Epoch 10/10, Batch 70/145, Loss: 0.1212
Epoch 10/10, Batch 80/145, Loss: 0.3228
Epoch 10/10, Batch 90/145, Loss: 0.1515
Epoch 10/10, Batch 100/145, Loss: 0.1283
Epoch 10/10, Batch 110/145, Loss: 0.2258
Epoch 10/10, Batch 120/145, Loss: 0.2034
Epoch 10/10, Batch 130/145, Loss: 0.3342
Epoch 10/10, Batch 140/145, Loss: 0.2695
Epoch 10/10, Train Loss: 0.1930, Valid Loss: 0.2031
Accuracy: 0.9182
Precision: 0.9171
Recall: 0.9182
F1-score: 0.9171
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5029
Epoch 1/10, Batch 20/145, Loss: 0.9621
Epoch 1/10, Batch 30/145, Loss: 0.8231
Epoch 1/10, Batch 40/145, Loss: 0.8896
Epoch 1/10, Batch 50/145, Loss: 0.5590
Epoch 1/10, Batch 60/145, Loss: 0.5593
Epoch 1/10, Batch 70/145, Loss: 0.6578
Epoch 1/10, Batch 80/145, Loss: 0.5057
Epoch 1/10, Batch 90/145, Loss: 0.6376
Epoch 1/10, Batch 100/145, Loss: 0.5518
Epoch 1/10, Batch 110/145, Loss: 0.3416
Epoch 1/10, Batch 120/145, Loss: 0.4615
Epoch 1/10, Batch 130/145, Loss: 0.4282
Epoch 1/10, Batch 140/145, Loss: 0.5606
Epoch 1/10, Train Loss: 0.6896, Valid Loss: 0.3625
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4544
Epoch 2/10, Batch 20/145, Loss: 0.3875
Epoch 2/10, Batch 30/145, Loss: 0.3321
Epoch 2/10, Batch 40/145, Loss: 0.5179
Epoch 2/10, Batch 50/145, Loss: 0.3348
Epoch 2/10, Batch 60/145, Loss: 0.3837
Epoch 2/10, Batch 70/145, Loss: 0.4387
Epoch 2/10, Batch 80/145, Loss: 0.3612
Epoch 2/10, Batch 90/145, Loss: 0.2480
Epoch 2/10, Batch 100/145, Loss: 0.2348
Epoch 2/10, Batch 110/145, Loss: 0.3347
Epoch 2/10, Batch 120/145, Loss: 0.5260
Epoch 2/10, Batch 130/145, Loss: 0.2914
Epoch 2/10, Batch 140/145, Loss: 0.2959
Epoch 2/10, Train Loss: 0.3601, Valid Loss: 0.2831
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2113
Epoch 3/10, Batch 20/145, Loss: 0.2874
Epoch 3/10, Batch 30/145, Loss: 0.1847
Epoch 3/10, Batch 40/145, Loss: 0.2331
Epoch 3/10, Batch 50/145, Loss: 0.1945
Epoch 3/10, Batch 60/145, Loss: 0.3221
Epoch 3/10, Batch 70/145, Loss: 0.4417
Epoch 3/10, Batch 80/145, Loss: 0.3533
Epoch 3/10, Batch 90/145, Loss: 0.7956
Epoch 3/10, Batch 100/145, Loss: 0.2286
Epoch 3/10, Batch 110/145, Loss: 0.1920
Epoch 3/10, Batch 120/145, Loss: 0.2213
Epoch 3/10, Batch 130/145, Loss: 0.2772
Epoch 3/10, Batch 140/145, Loss: 0.2806
Epoch 3/10, Train Loss: 0.3031, Valid Loss: 0.2495
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2615
Epoch 4/10, Batch 20/145, Loss: 0.2842
Epoch 4/10, Batch 30/145, Loss: 0.2344
Epoch 4/10, Batch 40/145, Loss: 0.4272
Epoch 4/10, Batch 50/145, Loss: 0.1403
Epoch 4/10, Batch 60/145, Loss: 0.1987
Epoch 4/10, Batch 70/145, Loss: 0.1273
Epoch 4/10, Batch 80/145, Loss: 0.2352
Epoch 4/10, Batch 90/145, Loss: 0.2097
Epoch 4/10, Batch 100/145, Loss: 0.1380
Epoch 4/10, Batch 110/145, Loss: 0.2427
Epoch 4/10, Batch 120/145, Loss: 0.1193
Epoch 4/10, Batch 130/145, Loss: 0.1651
Epoch 4/10, Batch 140/145, Loss: 0.2079
Epoch 4/10, Train Loss: 0.2581, Valid Loss: 0.2418
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2628
Epoch 5/10, Batch 20/145, Loss: 0.1950
Epoch 5/10, Batch 30/145, Loss: 0.2537
Epoch 5/10, Batch 40/145, Loss: 0.2804
Epoch 5/10, Batch 50/145, Loss: 0.1196
Epoch 5/10, Batch 60/145, Loss: 0.1859
Epoch 5/10, Batch 70/145, Loss: 0.4453
Epoch 5/10, Batch 80/145, Loss: 0.2580
Epoch 5/10, Batch 90/145, Loss: 0.0875
Epoch 5/10, Batch 100/145, Loss: 0.2307
Epoch 5/10, Batch 110/145, Loss: 0.1119
Epoch 5/10, Batch 120/145, Loss: 0.2141
Epoch 5/10, Batch 130/145, Loss: 0.2763
Epoch 5/10, Batch 140/145, Loss: 0.2949
Epoch 5/10, Train Loss: 0.2422, Valid Loss: 0.2340
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2959
Epoch 6/10, Batch 20/145, Loss: 0.2159
Epoch 6/10, Batch 30/145, Loss: 0.3987
Epoch 6/10, Batch 40/145, Loss: 0.2045
Epoch 6/10, Batch 50/145, Loss: 0.2938
Epoch 6/10, Batch 60/145, Loss: 0.1082
Epoch 6/10, Batch 70/145, Loss: 0.2765
Epoch 6/10, Batch 80/145, Loss: 0.2151
Epoch 6/10, Batch 90/145, Loss: 0.2051
Epoch 6/10, Batch 100/145, Loss: 0.2002
Epoch 6/10, Batch 110/145, Loss: 0.2183
Epoch 6/10, Batch 120/145, Loss: 0.2619
Epoch 6/10, Batch 130/145, Loss: 0.2037
Epoch 6/10, Batch 140/145, Loss: 0.3444
Epoch 6/10, Train Loss: 0.2242, Valid Loss: 0.2344
Epoch 7/10, Batch 10/145, Loss: 0.1187
Epoch 7/10, Batch 20/145, Loss: 0.2637
Epoch 7/10, Batch 30/145, Loss: 0.0866
Epoch 7/10, Batch 40/145, Loss: 0.4094
Epoch 7/10, Batch 50/145, Loss: 0.2061
Epoch 7/10, Batch 60/145, Loss: 0.1730
Epoch 7/10, Batch 70/145, Loss: 0.2327
Epoch 7/10, Batch 80/145, Loss: 0.2104
Epoch 7/10, Batch 90/145, Loss: 0.2553
Epoch 7/10, Batch 100/145, Loss: 0.1434
Epoch 7/10, Batch 110/145, Loss: 0.2403
Epoch 7/10, Batch 120/145, Loss: 0.1601
Epoch 7/10, Batch 130/145, Loss: 0.2407
Epoch 7/10, Batch 140/145, Loss: 0.1165
Epoch 7/10, Train Loss: 0.2179, Valid Loss: 0.2224
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1899
Epoch 8/10, Batch 20/145, Loss: 0.1049
Epoch 8/10, Batch 30/145, Loss: 0.1450
Epoch 8/10, Batch 40/145, Loss: 0.1928
Epoch 8/10, Batch 50/145, Loss: 0.1654
Epoch 8/10, Batch 60/145, Loss: 0.1180
Epoch 8/10, Batch 70/145, Loss: 0.2625
Epoch 8/10, Batch 80/145, Loss: 0.1100
Epoch 8/10, Batch 90/145, Loss: 0.1321
Epoch 8/10, Batch 100/145, Loss: 0.2893
Epoch 8/10, Batch 110/145, Loss: 0.1593
Epoch 8/10, Batch 120/145, Loss: 0.1558
Epoch 8/10, Batch 130/145, Loss: 0.1952
Epoch 8/10, Batch 140/145, Loss: 0.2096
Epoch 8/10, Train Loss: 0.2060, Valid Loss: 0.2171
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2682
Epoch 9/10, Batch 20/145, Loss: 0.2329
Epoch 9/10, Batch 30/145, Loss: 0.0504
Epoch 9/10, Batch 40/145, Loss: 0.1068
Epoch 9/10, Batch 50/145, Loss: 0.1656
Epoch 9/10, Batch 60/145, Loss: 0.2771
Epoch 9/10, Batch 70/145, Loss: 0.1172
Epoch 9/10, Batch 80/145, Loss: 0.1745
Epoch 9/10, Batch 90/145, Loss: 0.1162
Epoch 9/10, Batch 100/145, Loss: 0.1659
Epoch 9/10, Batch 110/145, Loss: 0.1585
Epoch 9/10, Batch 120/145, Loss: 0.1837
Epoch 9/10, Batch 130/145, Loss: 0.1015
Epoch 9/10, Batch 140/145, Loss: 0.2292
Epoch 9/10, Train Loss: 0.1941, Valid Loss: 0.2109
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1983
Epoch 10/10, Batch 20/145, Loss: 0.1998
Epoch 10/10, Batch 30/145, Loss: 0.0962
Epoch 10/10, Batch 40/145, Loss: 0.2502
Epoch 10/10, Batch 50/145, Loss: 0.1236
Epoch 10/10, Batch 60/145, Loss: 0.1696
Epoch 10/10, Batch 70/145, Loss: 0.2744
Epoch 10/10, Batch 80/145, Loss: 0.3837
Epoch 10/10, Batch 90/145, Loss: 0.2678
Epoch 10/10, Batch 100/145, Loss: 0.1904
Epoch 10/10, Batch 110/145, Loss: 0.1635
Epoch 10/10, Batch 120/145, Loss: 0.3428
Epoch 10/10, Batch 130/145, Loss: 0.3276
Epoch 10/10, Batch 140/145, Loss: 0.1292
Epoch 10/10, Train Loss: 0.1938, Valid Loss: 0.2056
Model saved!
Accuracy: 0.9264
Precision: 0.9244
Recall: 0.9264
F1-score: 0.9250
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5099
Epoch 1/10, Batch 20/145, Loss: 0.9044
Epoch 1/10, Batch 30/145, Loss: 0.8687
Epoch 1/10, Batch 40/145, Loss: 0.8415
Epoch 1/10, Batch 50/145, Loss: 0.5211
Epoch 1/10, Batch 60/145, Loss: 0.6133
Epoch 1/10, Batch 70/145, Loss: 0.7398
Epoch 1/10, Batch 80/145, Loss: 0.4220
Epoch 1/10, Batch 90/145, Loss: 0.6714
Epoch 1/10, Batch 100/145, Loss: 0.6329
Epoch 1/10, Batch 110/145, Loss: 0.3570
Epoch 1/10, Batch 120/145, Loss: 0.4362
Epoch 1/10, Batch 130/145, Loss: 0.4697
Epoch 1/10, Batch 140/145, Loss: 0.3849
Epoch 1/10, Train Loss: 0.6929, Valid Loss: 0.3699
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3533
Epoch 2/10, Batch 20/145, Loss: 0.4538
Epoch 2/10, Batch 30/145, Loss: 0.2358
Epoch 2/10, Batch 40/145, Loss: 0.5866
Epoch 2/10, Batch 50/145, Loss: 0.3365
Epoch 2/10, Batch 60/145, Loss: 0.4077
Epoch 2/10, Batch 70/145, Loss: 0.4033
Epoch 2/10, Batch 80/145, Loss: 0.2552
Epoch 2/10, Batch 90/145, Loss: 0.3416
Epoch 2/10, Batch 100/145, Loss: 0.3369
Epoch 2/10, Batch 110/145, Loss: 0.2584
Epoch 2/10, Batch 120/145, Loss: 0.3474
Epoch 2/10, Batch 130/145, Loss: 0.3996
Epoch 2/10, Batch 140/145, Loss: 0.3361
Epoch 2/10, Train Loss: 0.3632, Valid Loss: 0.2876
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1936
Epoch 3/10, Batch 20/145, Loss: 0.1494
Epoch 3/10, Batch 30/145, Loss: 0.2287
Epoch 3/10, Batch 40/145, Loss: 0.2186
Epoch 3/10, Batch 50/145, Loss: 0.1944
Epoch 3/10, Batch 60/145, Loss: 0.3078
Epoch 3/10, Batch 70/145, Loss: 0.2560
Epoch 3/10, Batch 80/145, Loss: 0.2703
Epoch 3/10, Batch 90/145, Loss: 0.6644
Epoch 3/10, Batch 100/145, Loss: 0.2709
Epoch 3/10, Batch 110/145, Loss: 0.2758
Epoch 3/10, Batch 120/145, Loss: 0.2317
Epoch 3/10, Batch 130/145, Loss: 0.3991
Epoch 3/10, Batch 140/145, Loss: 0.1560
Epoch 3/10, Train Loss: 0.3067, Valid Loss: 0.2557
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1267
Epoch 4/10, Batch 20/145, Loss: 0.3217
Epoch 4/10, Batch 30/145, Loss: 0.3147
Epoch 4/10, Batch 40/145, Loss: 0.4357
Epoch 4/10, Batch 50/145, Loss: 0.1143
Epoch 4/10, Batch 60/145, Loss: 0.2312
Epoch 4/10, Batch 70/145, Loss: 0.3387
Epoch 4/10, Batch 80/145, Loss: 0.2056
Epoch 4/10, Batch 90/145, Loss: 0.4448
Epoch 4/10, Batch 100/145, Loss: 0.3173
Epoch 4/10, Batch 110/145, Loss: 0.2316
Epoch 4/10, Batch 120/145, Loss: 0.1308
Epoch 4/10, Batch 130/145, Loss: 0.1398
Epoch 4/10, Batch 140/145, Loss: 0.1827
Epoch 4/10, Train Loss: 0.2644, Valid Loss: 0.2404
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2731
Epoch 5/10, Batch 20/145, Loss: 0.0735
Epoch 5/10, Batch 30/145, Loss: 0.1832
Epoch 5/10, Batch 40/145, Loss: 0.2036
Epoch 5/10, Batch 50/145, Loss: 0.1537
Epoch 5/10, Batch 60/145, Loss: 0.1979
Epoch 5/10, Batch 70/145, Loss: 0.2986
Epoch 5/10, Batch 80/145, Loss: 0.2387
Epoch 5/10, Batch 90/145, Loss: 0.2502
Epoch 5/10, Batch 100/145, Loss: 0.2982
Epoch 5/10, Batch 110/145, Loss: 0.2214
Epoch 5/10, Batch 120/145, Loss: 0.1497
Epoch 5/10, Batch 130/145, Loss: 0.2738
Epoch 5/10, Batch 140/145, Loss: 0.4422
Epoch 5/10, Train Loss: 0.2465, Valid Loss: 0.2278
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3738
Epoch 6/10, Batch 20/145, Loss: 0.4376
Epoch 6/10, Batch 30/145, Loss: 0.3167
Epoch 6/10, Batch 40/145, Loss: 0.1573
Epoch 6/10, Batch 50/145, Loss: 0.2659
Epoch 6/10, Batch 60/145, Loss: 0.2005
Epoch 6/10, Batch 70/145, Loss: 0.3787
Epoch 6/10, Batch 80/145, Loss: 0.3112
Epoch 6/10, Batch 90/145, Loss: 0.1522
Epoch 6/10, Batch 100/145, Loss: 0.2270
Epoch 6/10, Batch 110/145, Loss: 0.2586
Epoch 6/10, Batch 120/145, Loss: 0.2207
Epoch 6/10, Batch 130/145, Loss: 0.2454
Epoch 6/10, Batch 140/145, Loss: 0.2677
Epoch 6/10, Train Loss: 0.2257, Valid Loss: 0.2234
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2051
Epoch 7/10, Batch 20/145, Loss: 0.4762
Epoch 7/10, Batch 30/145, Loss: 0.2993
Epoch 7/10, Batch 40/145, Loss: 0.3856
Epoch 7/10, Batch 50/145, Loss: 0.2386
Epoch 7/10, Batch 60/145, Loss: 0.2278
Epoch 7/10, Batch 70/145, Loss: 0.2179
Epoch 7/10, Batch 80/145, Loss: 0.0786
Epoch 7/10, Batch 90/145, Loss: 0.2508
Epoch 7/10, Batch 100/145, Loss: 0.0858
Epoch 7/10, Batch 110/145, Loss: 0.3419
Epoch 7/10, Batch 120/145, Loss: 0.1206
Epoch 7/10, Batch 130/145, Loss: 0.1635
Epoch 7/10, Batch 140/145, Loss: 0.1798
Epoch 7/10, Train Loss: 0.2155, Valid Loss: 0.2186
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2430
Epoch 8/10, Batch 20/145, Loss: 0.1422
Epoch 8/10, Batch 30/145, Loss: 0.1422
Epoch 8/10, Batch 40/145, Loss: 0.1903
Epoch 8/10, Batch 50/145, Loss: 0.2095
Epoch 8/10, Batch 60/145, Loss: 0.0901
Epoch 8/10, Batch 70/145, Loss: 0.0863
Epoch 8/10, Batch 80/145, Loss: 0.1275
Epoch 8/10, Batch 90/145, Loss: 0.0586
Epoch 8/10, Batch 100/145, Loss: 0.1960
Epoch 8/10, Batch 110/145, Loss: 0.2943
Epoch 8/10, Batch 120/145, Loss: 0.2266
Epoch 8/10, Batch 130/145, Loss: 0.0880
Epoch 8/10, Batch 140/145, Loss: 0.1671
Epoch 8/10, Train Loss: 0.2111, Valid Loss: 0.2158
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1968
Epoch 9/10, Batch 20/145, Loss: 0.1831
Epoch 9/10, Batch 30/145, Loss: 0.1486
Epoch 9/10, Batch 40/145, Loss: 0.1330
Epoch 9/10, Batch 50/145, Loss: 0.1835
Epoch 9/10, Batch 60/145, Loss: 0.0878
Epoch 9/10, Batch 70/145, Loss: 0.2989
Epoch 9/10, Batch 80/145, Loss: 0.2779
Epoch 9/10, Batch 90/145, Loss: 0.2196
Epoch 9/10, Batch 100/145, Loss: 0.2149
Epoch 9/10, Batch 110/145, Loss: 0.1851
Epoch 9/10, Batch 120/145, Loss: 0.0776
Epoch 9/10, Batch 130/145, Loss: 0.2940
Epoch 9/10, Batch 140/145, Loss: 0.1802
Epoch 9/10, Train Loss: 0.2038, Valid Loss: 0.2125
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2362
Epoch 10/10, Batch 20/145, Loss: 0.1284
Epoch 10/10, Batch 30/145, Loss: 0.1331
Epoch 10/10, Batch 40/145, Loss: 0.2628
Epoch 10/10, Batch 50/145, Loss: 0.4771
Epoch 10/10, Batch 60/145, Loss: 0.1180
Epoch 10/10, Batch 70/145, Loss: 0.1405
Epoch 10/10, Batch 80/145, Loss: 0.4584
Epoch 10/10, Batch 90/145, Loss: 0.1696
Epoch 10/10, Batch 100/145, Loss: 0.2047
Epoch 10/10, Batch 110/145, Loss: 0.1913
Epoch 10/10, Batch 120/145, Loss: 0.2351
Epoch 10/10, Batch 130/145, Loss: 0.2420
Epoch 10/10, Batch 140/145, Loss: 0.2624
Epoch 10/10, Train Loss: 0.1999, Valid Loss: 0.2077
Model saved!
Accuracy: 0.9206
Precision: 0.9186
Recall: 0.9206
F1-score: 0.9193
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4902
Epoch 1/10, Batch 20/145, Loss: 0.9320
Epoch 1/10, Batch 30/145, Loss: 0.8230
Epoch 1/10, Batch 40/145, Loss: 0.9021
Epoch 1/10, Batch 50/145, Loss: 0.6596
Epoch 1/10, Batch 60/145, Loss: 0.5654
Epoch 1/10, Batch 70/145, Loss: 0.6040
Epoch 1/10, Batch 80/145, Loss: 0.4908
Epoch 1/10, Batch 90/145, Loss: 0.6932
Epoch 1/10, Batch 100/145, Loss: 0.4682
Epoch 1/10, Batch 110/145, Loss: 0.4025
Epoch 1/10, Batch 120/145, Loss: 0.8385
Epoch 1/10, Batch 130/145, Loss: 0.3780
Epoch 1/10, Batch 140/145, Loss: 0.3988
Epoch 1/10, Train Loss: 0.6863, Valid Loss: 0.3760
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2879
Epoch 2/10, Batch 20/145, Loss: 0.4936
Epoch 2/10, Batch 30/145, Loss: 0.4505
Epoch 2/10, Batch 40/145, Loss: 0.4891
Epoch 2/10, Batch 50/145, Loss: 0.2691
Epoch 2/10, Batch 60/145, Loss: 0.3611
Epoch 2/10, Batch 70/145, Loss: 0.3549
Epoch 2/10, Batch 80/145, Loss: 0.2764
Epoch 2/10, Batch 90/145, Loss: 0.3763
Epoch 2/10, Batch 100/145, Loss: 0.2708
Epoch 2/10, Batch 110/145, Loss: 0.3203
Epoch 2/10, Batch 120/145, Loss: 0.4159
Epoch 2/10, Batch 130/145, Loss: 0.4377
Epoch 2/10, Batch 140/145, Loss: 0.4226
Epoch 2/10, Train Loss: 0.3674, Valid Loss: 0.2886
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2498
Epoch 3/10, Batch 20/145, Loss: 0.2372
Epoch 3/10, Batch 30/145, Loss: 0.2221
Epoch 3/10, Batch 40/145, Loss: 0.3181
Epoch 3/10, Batch 50/145, Loss: 0.2073
Epoch 3/10, Batch 60/145, Loss: 0.2285
Epoch 3/10, Batch 70/145, Loss: 0.1963
Epoch 3/10, Batch 80/145, Loss: 0.3081
Epoch 3/10, Batch 90/145, Loss: 0.5736
Epoch 3/10, Batch 100/145, Loss: 0.1850
Epoch 3/10, Batch 110/145, Loss: 0.2257
Epoch 3/10, Batch 120/145, Loss: 0.2590
Epoch 3/10, Batch 130/145, Loss: 0.2998
Epoch 3/10, Batch 140/145, Loss: 0.1752
Epoch 3/10, Train Loss: 0.3048, Valid Loss: 0.2602
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2528
Epoch 4/10, Batch 20/145, Loss: 0.2803
Epoch 4/10, Batch 30/145, Loss: 0.3688
Epoch 4/10, Batch 40/145, Loss: 0.4378
Epoch 4/10, Batch 50/145, Loss: 0.1911
Epoch 4/10, Batch 60/145, Loss: 0.3133
Epoch 4/10, Batch 70/145, Loss: 0.3608
Epoch 4/10, Batch 80/145, Loss: 0.1243
Epoch 4/10, Batch 90/145, Loss: 0.3302
Epoch 4/10, Batch 100/145, Loss: 0.2326
Epoch 4/10, Batch 110/145, Loss: 0.3544
Epoch 4/10, Batch 120/145, Loss: 0.1874
Epoch 4/10, Batch 130/145, Loss: 0.2031
Epoch 4/10, Batch 140/145, Loss: 0.3008
Epoch 4/10, Train Loss: 0.2664, Valid Loss: 0.2519
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2008
Epoch 5/10, Batch 20/145, Loss: 0.2120
Epoch 5/10, Batch 30/145, Loss: 0.1923
Epoch 5/10, Batch 40/145, Loss: 0.2284
Epoch 5/10, Batch 50/145, Loss: 0.1448
Epoch 5/10, Batch 60/145, Loss: 0.2365
Epoch 5/10, Batch 70/145, Loss: 0.2065
Epoch 5/10, Batch 80/145, Loss: 0.4403
Epoch 5/10, Batch 90/145, Loss: 0.2882
Epoch 5/10, Batch 100/145, Loss: 0.4246
Epoch 5/10, Batch 110/145, Loss: 0.1631
Epoch 5/10, Batch 120/145, Loss: 0.2362
Epoch 5/10, Batch 130/145, Loss: 0.2753
Epoch 5/10, Batch 140/145, Loss: 0.2829
Epoch 5/10, Train Loss: 0.2406, Valid Loss: 0.2322
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2908
Epoch 6/10, Batch 20/145, Loss: 0.2115
Epoch 6/10, Batch 30/145, Loss: 0.1398
Epoch 6/10, Batch 40/145, Loss: 0.1751
Epoch 6/10, Batch 50/145, Loss: 0.3959
Epoch 6/10, Batch 60/145, Loss: 0.2780
Epoch 6/10, Batch 70/145, Loss: 0.4496
Epoch 6/10, Batch 80/145, Loss: 0.3068
Epoch 6/10, Batch 90/145, Loss: 0.1921
Epoch 6/10, Batch 100/145, Loss: 0.2806
Epoch 6/10, Batch 110/145, Loss: 0.1825
Epoch 6/10, Batch 120/145, Loss: 0.3063
Epoch 6/10, Batch 130/145, Loss: 0.1400
Epoch 6/10, Batch 140/145, Loss: 0.2071
Epoch 6/10, Train Loss: 0.2300, Valid Loss: 0.2260
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2914
Epoch 7/10, Batch 20/145, Loss: 0.2170
Epoch 7/10, Batch 30/145, Loss: 0.1865
Epoch 7/10, Batch 40/145, Loss: 0.5829
Epoch 7/10, Batch 50/145, Loss: 0.2871
Epoch 7/10, Batch 60/145, Loss: 0.2006
Epoch 7/10, Batch 70/145, Loss: 0.1656
Epoch 7/10, Batch 80/145, Loss: 0.2269
Epoch 7/10, Batch 90/145, Loss: 0.2080
Epoch 7/10, Batch 100/145, Loss: 0.1129
Epoch 7/10, Batch 110/145, Loss: 0.3075
Epoch 7/10, Batch 120/145, Loss: 0.1789
Epoch 7/10, Batch 130/145, Loss: 0.1443
Epoch 7/10, Batch 140/145, Loss: 0.1061
Epoch 7/10, Train Loss: 0.2158, Valid Loss: 0.2204
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2005
Epoch 8/10, Batch 20/145, Loss: 0.1231
Epoch 8/10, Batch 30/145, Loss: 0.1852
Epoch 8/10, Batch 40/145, Loss: 0.3194
Epoch 8/10, Batch 50/145, Loss: 0.1987
Epoch 8/10, Batch 60/145, Loss: 0.1593
Epoch 8/10, Batch 70/145, Loss: 0.2440
Epoch 8/10, Batch 80/145, Loss: 0.1494
Epoch 8/10, Batch 90/145, Loss: 0.2567
Epoch 8/10, Batch 100/145, Loss: 0.2780
Epoch 8/10, Batch 110/145, Loss: 0.2083
Epoch 8/10, Batch 120/145, Loss: 0.1690
Epoch 8/10, Batch 130/145, Loss: 0.1324
Epoch 8/10, Batch 140/145, Loss: 0.2683
Epoch 8/10, Train Loss: 0.2124, Valid Loss: 0.2192
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2079
Epoch 9/10, Batch 20/145, Loss: 0.1617
Epoch 9/10, Batch 30/145, Loss: 0.1547
Epoch 9/10, Batch 40/145, Loss: 0.1122
Epoch 9/10, Batch 50/145, Loss: 0.1882
Epoch 9/10, Batch 60/145, Loss: 0.1315
Epoch 9/10, Batch 70/145, Loss: 0.1207
Epoch 9/10, Batch 80/145, Loss: 0.3249
Epoch 9/10, Batch 90/145, Loss: 0.3055
Epoch 9/10, Batch 100/145, Loss: 0.2905
Epoch 9/10, Batch 110/145, Loss: 0.1432
Epoch 9/10, Batch 120/145, Loss: 0.1713
Epoch 9/10, Batch 130/145, Loss: 0.1386
Epoch 9/10, Batch 140/145, Loss: 0.1765
Epoch 9/10, Train Loss: 0.2008, Valid Loss: 0.2068
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1939
Epoch 10/10, Batch 20/145, Loss: 0.0969
Epoch 10/10, Batch 30/145, Loss: 0.0739
Epoch 10/10, Batch 40/145, Loss: 0.1982
Epoch 10/10, Batch 50/145, Loss: 0.1434
Epoch 10/10, Batch 60/145, Loss: 0.1297
Epoch 10/10, Batch 70/145, Loss: 0.0998
Epoch 10/10, Batch 80/145, Loss: 0.3577
Epoch 10/10, Batch 90/145, Loss: 0.1137
Epoch 10/10, Batch 100/145, Loss: 0.2183
Epoch 10/10, Batch 110/145, Loss: 0.1584
Epoch 10/10, Batch 120/145, Loss: 0.0963
Epoch 10/10, Batch 130/145, Loss: 0.0637
Epoch 10/10, Batch 140/145, Loss: 0.2449
Epoch 10/10, Train Loss: 0.1971, Valid Loss: 0.2032
Model saved!
Accuracy: 0.9206
Precision: 0.9209
Recall: 0.9206
F1-score: 0.9203
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4481
Epoch 1/10, Batch 20/145, Loss: 0.8978
Epoch 1/10, Batch 30/145, Loss: 0.8523
Epoch 1/10, Batch 40/145, Loss: 0.8774
Epoch 1/10, Batch 50/145, Loss: 0.6634
Epoch 1/10, Batch 60/145, Loss: 0.5164
Epoch 1/10, Batch 70/145, Loss: 0.6429
Epoch 1/10, Batch 80/145, Loss: 0.4999
Epoch 1/10, Batch 90/145, Loss: 0.5259
Epoch 1/10, Batch 100/145, Loss: 0.8359
Epoch 1/10, Batch 110/145, Loss: 0.4063
Epoch 1/10, Batch 120/145, Loss: 0.6506
Epoch 1/10, Batch 130/145, Loss: 0.4342
Epoch 1/10, Batch 140/145, Loss: 0.3866
Epoch 1/10, Train Loss: 0.6926, Valid Loss: 0.3716
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4861
Epoch 2/10, Batch 20/145, Loss: 0.7335
Epoch 2/10, Batch 30/145, Loss: 0.4678
Epoch 2/10, Batch 40/145, Loss: 0.4408
Epoch 2/10, Batch 50/145, Loss: 0.3558
Epoch 2/10, Batch 60/145, Loss: 0.3736
Epoch 2/10, Batch 70/145, Loss: 0.3013
Epoch 2/10, Batch 80/145, Loss: 0.2324
Epoch 2/10, Batch 90/145, Loss: 0.2502
Epoch 2/10, Batch 100/145, Loss: 0.3723
Epoch 2/10, Batch 110/145, Loss: 0.2954
Epoch 2/10, Batch 120/145, Loss: 0.3053
Epoch 2/10, Batch 130/145, Loss: 0.4214
Epoch 2/10, Batch 140/145, Loss: 0.4716
Epoch 2/10, Train Loss: 0.3675, Valid Loss: 0.2805
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2111
Epoch 3/10, Batch 20/145, Loss: 0.2630
Epoch 3/10, Batch 30/145, Loss: 0.3494
Epoch 3/10, Batch 40/145, Loss: 0.3364
Epoch 3/10, Batch 50/145, Loss: 0.2498
Epoch 3/10, Batch 60/145, Loss: 0.3598
Epoch 3/10, Batch 70/145, Loss: 0.2865
Epoch 3/10, Batch 80/145, Loss: 0.2329
Epoch 3/10, Batch 90/145, Loss: 0.5626
Epoch 3/10, Batch 100/145, Loss: 0.4882
Epoch 3/10, Batch 110/145, Loss: 0.2165
Epoch 3/10, Batch 120/145, Loss: 0.1985
Epoch 3/10, Batch 130/145, Loss: 0.2383
Epoch 3/10, Batch 140/145, Loss: 0.1123
Epoch 3/10, Train Loss: 0.3084, Valid Loss: 0.2553
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1286
Epoch 4/10, Batch 20/145, Loss: 0.2081
Epoch 4/10, Batch 30/145, Loss: 0.2932
Epoch 4/10, Batch 40/145, Loss: 0.4032
Epoch 4/10, Batch 50/145, Loss: 0.2611
Epoch 4/10, Batch 60/145, Loss: 0.2638
Epoch 4/10, Batch 70/145, Loss: 0.2690
Epoch 4/10, Batch 80/145, Loss: 0.2954
Epoch 4/10, Batch 90/145, Loss: 0.2452
Epoch 4/10, Batch 100/145, Loss: 0.2335
Epoch 4/10, Batch 110/145, Loss: 0.2769
Epoch 4/10, Batch 120/145, Loss: 0.2454
Epoch 4/10, Batch 130/145, Loss: 0.1877
Epoch 4/10, Batch 140/145, Loss: 0.1803
Epoch 4/10, Train Loss: 0.2669, Valid Loss: 0.2487
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2216
Epoch 5/10, Batch 20/145, Loss: 0.1505
Epoch 5/10, Batch 30/145, Loss: 0.3259
Epoch 5/10, Batch 40/145, Loss: 0.1622
Epoch 5/10, Batch 50/145, Loss: 0.1594
Epoch 5/10, Batch 60/145, Loss: 0.2180
Epoch 5/10, Batch 70/145, Loss: 0.3205
Epoch 5/10, Batch 80/145, Loss: 0.3437
Epoch 5/10, Batch 90/145, Loss: 0.4391
Epoch 5/10, Batch 100/145, Loss: 0.2713
Epoch 5/10, Batch 110/145, Loss: 0.1052
Epoch 5/10, Batch 120/145, Loss: 0.1207
Epoch 5/10, Batch 130/145, Loss: 0.2153
Epoch 5/10, Batch 140/145, Loss: 0.1160
Epoch 5/10, Train Loss: 0.2496, Valid Loss: 0.2206
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1837
Epoch 6/10, Batch 20/145, Loss: 0.0952
Epoch 6/10, Batch 30/145, Loss: 0.2063
Epoch 6/10, Batch 40/145, Loss: 0.1088
Epoch 6/10, Batch 50/145, Loss: 0.4070
Epoch 6/10, Batch 60/145, Loss: 0.1595
Epoch 6/10, Batch 70/145, Loss: 0.4005
Epoch 6/10, Batch 80/145, Loss: 0.3599
Epoch 6/10, Batch 90/145, Loss: 0.3189
Epoch 6/10, Batch 100/145, Loss: 0.2706
Epoch 6/10, Batch 110/145, Loss: 0.1807
Epoch 6/10, Batch 120/145, Loss: 0.1756
Epoch 6/10, Batch 130/145, Loss: 0.0812
Epoch 6/10, Batch 140/145, Loss: 0.2355
Epoch 6/10, Train Loss: 0.2330, Valid Loss: 0.2138
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3742
Epoch 7/10, Batch 20/145, Loss: 0.1761
Epoch 7/10, Batch 30/145, Loss: 0.1188
Epoch 7/10, Batch 40/145, Loss: 0.5062
Epoch 7/10, Batch 50/145, Loss: 0.2241
Epoch 7/10, Batch 60/145, Loss: 0.1381
Epoch 7/10, Batch 70/145, Loss: 0.1108
Epoch 7/10, Batch 80/145, Loss: 0.2107
Epoch 7/10, Batch 90/145, Loss: 0.3089
Epoch 7/10, Batch 100/145, Loss: 0.2723
Epoch 7/10, Batch 110/145, Loss: 0.3090
Epoch 7/10, Batch 120/145, Loss: 0.1959
Epoch 7/10, Batch 130/145, Loss: 0.1719
Epoch 7/10, Batch 140/145, Loss: 0.2210
Epoch 7/10, Train Loss: 0.2221, Valid Loss: 0.2055
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.3705
Epoch 8/10, Batch 20/145, Loss: 0.2695
Epoch 8/10, Batch 30/145, Loss: 0.1893
Epoch 8/10, Batch 40/145, Loss: 0.3123
Epoch 8/10, Batch 50/145, Loss: 0.4025
Epoch 8/10, Batch 60/145, Loss: 0.2361
Epoch 8/10, Batch 70/145, Loss: 0.1098
Epoch 8/10, Batch 80/145, Loss: 0.2258
Epoch 8/10, Batch 90/145, Loss: 0.1004
Epoch 8/10, Batch 100/145, Loss: 0.3473
Epoch 8/10, Batch 110/145, Loss: 0.1831
Epoch 8/10, Batch 120/145, Loss: 0.1168
Epoch 8/10, Batch 130/145, Loss: 0.2319
Epoch 8/10, Batch 140/145, Loss: 0.1876
Epoch 8/10, Train Loss: 0.2165, Valid Loss: 0.2076
Epoch 9/10, Batch 10/145, Loss: 0.1420
Epoch 9/10, Batch 20/145, Loss: 0.1942
Epoch 9/10, Batch 30/145, Loss: 0.2527
Epoch 9/10, Batch 40/145, Loss: 0.2362
Epoch 9/10, Batch 50/145, Loss: 0.1573
Epoch 9/10, Batch 60/145, Loss: 0.1953
Epoch 9/10, Batch 70/145, Loss: 0.2440
Epoch 9/10, Batch 80/145, Loss: 0.1902
Epoch 9/10, Batch 90/145, Loss: 0.1425
Epoch 9/10, Batch 100/145, Loss: 0.2687
Epoch 9/10, Batch 110/145, Loss: 0.0745
Epoch 9/10, Batch 120/145, Loss: 0.3065
Epoch 9/10, Batch 130/145, Loss: 0.1501
Epoch 9/10, Batch 140/145, Loss: 0.1416
Epoch 9/10, Train Loss: 0.2075, Valid Loss: 0.1925
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1494
Epoch 10/10, Batch 20/145, Loss: 0.1880
Epoch 10/10, Batch 30/145, Loss: 0.1513
Epoch 10/10, Batch 40/145, Loss: 0.2002
Epoch 10/10, Batch 50/145, Loss: 0.2822
Epoch 10/10, Batch 60/145, Loss: 0.1604
Epoch 10/10, Batch 70/145, Loss: 0.0566
Epoch 10/10, Batch 80/145, Loss: 0.3669
Epoch 10/10, Batch 90/145, Loss: 0.2951
Epoch 10/10, Batch 100/145, Loss: 0.1445
Epoch 10/10, Batch 110/145, Loss: 0.1246
Epoch 10/10, Batch 120/145, Loss: 0.1689
Epoch 10/10, Batch 130/145, Loss: 0.2131
Epoch 10/10, Batch 140/145, Loss: 0.2284
Epoch 10/10, Train Loss: 0.2020, Valid Loss: 0.1899
Model saved!
Accuracy: 0.9252
Precision: 0.9242
Recall: 0.9252
F1-score: 0.9246
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4940
Epoch 1/10, Batch 20/145, Loss: 0.8271
Epoch 1/10, Batch 30/145, Loss: 0.8738
Epoch 1/10, Batch 40/145, Loss: 0.7640
Epoch 1/10, Batch 50/145, Loss: 0.5364
Epoch 1/10, Batch 60/145, Loss: 0.5913
Epoch 1/10, Batch 70/145, Loss: 0.7180
Epoch 1/10, Batch 80/145, Loss: 0.4795
Epoch 1/10, Batch 90/145, Loss: 0.4970
Epoch 1/10, Batch 100/145, Loss: 0.4115
Epoch 1/10, Batch 110/145, Loss: 0.3950
Epoch 1/10, Batch 120/145, Loss: 0.5426
Epoch 1/10, Batch 130/145, Loss: 0.3518
Epoch 1/10, Batch 140/145, Loss: 0.4980
Epoch 1/10, Train Loss: 0.6794, Valid Loss: 0.3785
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3365
Epoch 2/10, Batch 20/145, Loss: 0.4975
Epoch 2/10, Batch 30/145, Loss: 0.2724
Epoch 2/10, Batch 40/145, Loss: 0.6012
Epoch 2/10, Batch 50/145, Loss: 0.2405
Epoch 2/10, Batch 60/145, Loss: 0.3215
Epoch 2/10, Batch 70/145, Loss: 0.3797
Epoch 2/10, Batch 80/145, Loss: 0.3878
Epoch 2/10, Batch 90/145, Loss: 0.3391
Epoch 2/10, Batch 100/145, Loss: 0.3531
Epoch 2/10, Batch 110/145, Loss: 0.2825
Epoch 2/10, Batch 120/145, Loss: 0.3952
Epoch 2/10, Batch 130/145, Loss: 0.3148
Epoch 2/10, Batch 140/145, Loss: 0.1952
Epoch 2/10, Train Loss: 0.3508, Valid Loss: 0.2923
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1994
Epoch 3/10, Batch 20/145, Loss: 0.2967
Epoch 3/10, Batch 30/145, Loss: 0.2514
Epoch 3/10, Batch 40/145, Loss: 0.2909
Epoch 3/10, Batch 50/145, Loss: 0.1601
Epoch 3/10, Batch 60/145, Loss: 0.2913
Epoch 3/10, Batch 70/145, Loss: 0.2607
Epoch 3/10, Batch 80/145, Loss: 0.2171
Epoch 3/10, Batch 90/145, Loss: 0.5307
Epoch 3/10, Batch 100/145, Loss: 0.1779
Epoch 3/10, Batch 110/145, Loss: 0.2897
Epoch 3/10, Batch 120/145, Loss: 0.2281
Epoch 3/10, Batch 130/145, Loss: 0.2757
Epoch 3/10, Batch 140/145, Loss: 0.1324
Epoch 3/10, Train Loss: 0.3011, Valid Loss: 0.2639
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2413
Epoch 4/10, Batch 20/145, Loss: 0.1820
Epoch 4/10, Batch 30/145, Loss: 0.3742
Epoch 4/10, Batch 40/145, Loss: 0.2368
Epoch 4/10, Batch 50/145, Loss: 0.2233
Epoch 4/10, Batch 60/145, Loss: 0.1609
Epoch 4/10, Batch 70/145, Loss: 0.2039
Epoch 4/10, Batch 80/145, Loss: 0.2129
Epoch 4/10, Batch 90/145, Loss: 0.4061
Epoch 4/10, Batch 100/145, Loss: 0.2230
Epoch 4/10, Batch 110/145, Loss: 0.2387
Epoch 4/10, Batch 120/145, Loss: 0.3116
Epoch 4/10, Batch 130/145, Loss: 0.2252
Epoch 4/10, Batch 140/145, Loss: 0.2103
Epoch 4/10, Train Loss: 0.2545, Valid Loss: 0.2538
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1706
Epoch 5/10, Batch 20/145, Loss: 0.2470
Epoch 5/10, Batch 30/145, Loss: 0.1915
Epoch 5/10, Batch 40/145, Loss: 0.2876
Epoch 5/10, Batch 50/145, Loss: 0.2159
Epoch 5/10, Batch 60/145, Loss: 0.1870
Epoch 5/10, Batch 70/145, Loss: 0.2374
Epoch 5/10, Batch 80/145, Loss: 0.3883
Epoch 5/10, Batch 90/145, Loss: 0.1622
Epoch 5/10, Batch 100/145, Loss: 0.1501
Epoch 5/10, Batch 110/145, Loss: 0.2590
Epoch 5/10, Batch 120/145, Loss: 0.2972
Epoch 5/10, Batch 130/145, Loss: 0.2526
Epoch 5/10, Batch 140/145, Loss: 0.3166
Epoch 5/10, Train Loss: 0.2352, Valid Loss: 0.2429
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2781
Epoch 6/10, Batch 20/145, Loss: 0.1891
Epoch 6/10, Batch 30/145, Loss: 0.2721
Epoch 6/10, Batch 40/145, Loss: 0.2179
Epoch 6/10, Batch 50/145, Loss: 0.3030
Epoch 6/10, Batch 60/145, Loss: 0.1416
Epoch 6/10, Batch 70/145, Loss: 0.3070
Epoch 6/10, Batch 80/145, Loss: 0.2708
Epoch 6/10, Batch 90/145, Loss: 0.2120
Epoch 6/10, Batch 100/145, Loss: 0.2357
Epoch 6/10, Batch 110/145, Loss: 0.1578
Epoch 6/10, Batch 120/145, Loss: 0.1965
Epoch 6/10, Batch 130/145, Loss: 0.0957
Epoch 6/10, Batch 140/145, Loss: 0.1713
Epoch 6/10, Train Loss: 0.2213, Valid Loss: 0.2359
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.4661
Epoch 7/10, Batch 20/145, Loss: 0.3404
Epoch 7/10, Batch 30/145, Loss: 0.1843
Epoch 7/10, Batch 40/145, Loss: 0.4109
Epoch 7/10, Batch 50/145, Loss: 0.1859
Epoch 7/10, Batch 60/145, Loss: 0.2250
Epoch 7/10, Batch 70/145, Loss: 0.2388
Epoch 7/10, Batch 80/145, Loss: 0.2117
Epoch 7/10, Batch 90/145, Loss: 0.2738
Epoch 7/10, Batch 100/145, Loss: 0.1113
Epoch 7/10, Batch 110/145, Loss: 0.1732
Epoch 7/10, Batch 120/145, Loss: 0.1101
Epoch 7/10, Batch 130/145, Loss: 0.2253
Epoch 7/10, Batch 140/145, Loss: 0.0932
Epoch 7/10, Train Loss: 0.2094, Valid Loss: 0.2257
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0674
Epoch 8/10, Batch 20/145, Loss: 0.0675
Epoch 8/10, Batch 30/145, Loss: 0.1412
Epoch 8/10, Batch 40/145, Loss: 0.2366
Epoch 8/10, Batch 50/145, Loss: 0.1338
Epoch 8/10, Batch 60/145, Loss: 0.2162
Epoch 8/10, Batch 70/145, Loss: 0.1425
Epoch 8/10, Batch 80/145, Loss: 0.2622
Epoch 8/10, Batch 90/145, Loss: 0.1642
Epoch 8/10, Batch 100/145, Loss: 0.2244
Epoch 8/10, Batch 110/145, Loss: 0.3496
Epoch 8/10, Batch 120/145, Loss: 0.3029
Epoch 8/10, Batch 130/145, Loss: 0.1029
Epoch 8/10, Batch 140/145, Loss: 0.2340
Epoch 8/10, Train Loss: 0.2001, Valid Loss: 0.2221
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3108
Epoch 9/10, Batch 20/145, Loss: 0.1032
Epoch 9/10, Batch 30/145, Loss: 0.1032
Epoch 9/10, Batch 40/145, Loss: 0.1613
Epoch 9/10, Batch 50/145, Loss: 0.1206
Epoch 9/10, Batch 60/145, Loss: 0.1362
Epoch 9/10, Batch 70/145, Loss: 0.1487
Epoch 9/10, Batch 80/145, Loss: 0.2061
Epoch 9/10, Batch 90/145, Loss: 0.0638
Epoch 9/10, Batch 100/145, Loss: 0.2750
Epoch 9/10, Batch 110/145, Loss: 0.0876
Epoch 9/10, Batch 120/145, Loss: 0.1294
Epoch 9/10, Batch 130/145, Loss: 0.1238
Epoch 9/10, Batch 140/145, Loss: 0.2368
Epoch 9/10, Train Loss: 0.1921, Valid Loss: 0.2147
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1033
Epoch 10/10, Batch 20/145, Loss: 0.1917
Epoch 10/10, Batch 30/145, Loss: 0.1537
Epoch 10/10, Batch 40/145, Loss: 0.1460
Epoch 10/10, Batch 50/145, Loss: 0.2679
Epoch 10/10, Batch 60/145, Loss: 0.2380
Epoch 10/10, Batch 70/145, Loss: 0.2086
Epoch 10/10, Batch 80/145, Loss: 0.3436
Epoch 10/10, Batch 90/145, Loss: 0.2277
Epoch 10/10, Batch 100/145, Loss: 0.0971
Epoch 10/10, Batch 110/145, Loss: 0.1729
Epoch 10/10, Batch 120/145, Loss: 0.1456
Epoch 10/10, Batch 130/145, Loss: 0.3047
Epoch 10/10, Batch 140/145, Loss: 0.2693
Epoch 10/10, Train Loss: 0.1920, Valid Loss: 0.2153
Accuracy: 0.9206
Precision: 0.9180
Recall: 0.9206
F1-score: 0.9182
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5121
Epoch 1/10, Batch 20/145, Loss: 0.9175
Epoch 1/10, Batch 30/145, Loss: 0.9031
Epoch 1/10, Batch 40/145, Loss: 0.9436
Epoch 1/10, Batch 50/145, Loss: 0.5596
Epoch 1/10, Batch 60/145, Loss: 0.5343
Epoch 1/10, Batch 70/145, Loss: 0.6034
Epoch 1/10, Batch 80/145, Loss: 0.5379
Epoch 1/10, Batch 90/145, Loss: 0.5158
Epoch 1/10, Batch 100/145, Loss: 0.7005
Epoch 1/10, Batch 110/145, Loss: 0.4207
Epoch 1/10, Batch 120/145, Loss: 0.6448
Epoch 1/10, Batch 130/145, Loss: 0.3465
Epoch 1/10, Batch 140/145, Loss: 0.4284
Epoch 1/10, Train Loss: 0.6858, Valid Loss: 0.3903
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4248
Epoch 2/10, Batch 20/145, Loss: 0.4207
Epoch 2/10, Batch 30/145, Loss: 0.2705
Epoch 2/10, Batch 40/145, Loss: 0.3398
Epoch 2/10, Batch 50/145, Loss: 0.4565
Epoch 2/10, Batch 60/145, Loss: 0.3635
Epoch 2/10, Batch 70/145, Loss: 0.2873
Epoch 2/10, Batch 80/145, Loss: 0.4120
Epoch 2/10, Batch 90/145, Loss: 0.2369
Epoch 2/10, Batch 100/145, Loss: 0.2870
Epoch 2/10, Batch 110/145, Loss: 0.2296
Epoch 2/10, Batch 120/145, Loss: 0.3904
Epoch 2/10, Batch 130/145, Loss: 0.4024
Epoch 2/10, Batch 140/145, Loss: 0.2901
Epoch 2/10, Train Loss: 0.3642, Valid Loss: 0.2940
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2069
Epoch 3/10, Batch 20/145, Loss: 0.2150
Epoch 3/10, Batch 30/145, Loss: 0.2333
Epoch 3/10, Batch 40/145, Loss: 0.3903
Epoch 3/10, Batch 50/145, Loss: 0.1531
Epoch 3/10, Batch 60/145, Loss: 0.3273
Epoch 3/10, Batch 70/145, Loss: 0.2735
Epoch 3/10, Batch 80/145, Loss: 0.2011
Epoch 3/10, Batch 90/145, Loss: 0.3760
Epoch 3/10, Batch 100/145, Loss: 0.3156
Epoch 3/10, Batch 110/145, Loss: 0.1778
Epoch 3/10, Batch 120/145, Loss: 0.1897
Epoch 3/10, Batch 130/145, Loss: 0.2232
Epoch 3/10, Batch 140/145, Loss: 0.2352
Epoch 3/10, Train Loss: 0.3053, Valid Loss: 0.2709
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1848
Epoch 4/10, Batch 20/145, Loss: 0.2342
Epoch 4/10, Batch 30/145, Loss: 0.1761
Epoch 4/10, Batch 40/145, Loss: 0.3611
Epoch 4/10, Batch 50/145, Loss: 0.2068
Epoch 4/10, Batch 60/145, Loss: 0.1433
Epoch 4/10, Batch 70/145, Loss: 0.2968
Epoch 4/10, Batch 80/145, Loss: 0.2673
Epoch 4/10, Batch 90/145, Loss: 0.4275
Epoch 4/10, Batch 100/145, Loss: 0.2954
Epoch 4/10, Batch 110/145, Loss: 0.2327
Epoch 4/10, Batch 120/145, Loss: 0.1270
Epoch 4/10, Batch 130/145, Loss: 0.2521
Epoch 4/10, Batch 140/145, Loss: 0.1672
Epoch 4/10, Train Loss: 0.2651, Valid Loss: 0.2596
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2122
Epoch 5/10, Batch 20/145, Loss: 0.2116
Epoch 5/10, Batch 30/145, Loss: 0.2704
Epoch 5/10, Batch 40/145, Loss: 0.3151
Epoch 5/10, Batch 50/145, Loss: 0.1360
Epoch 5/10, Batch 60/145, Loss: 0.2332
Epoch 5/10, Batch 70/145, Loss: 0.2779
Epoch 5/10, Batch 80/145, Loss: 0.3519
Epoch 5/10, Batch 90/145, Loss: 0.2128
Epoch 5/10, Batch 100/145, Loss: 0.2658
Epoch 5/10, Batch 110/145, Loss: 0.0915
Epoch 5/10, Batch 120/145, Loss: 0.2421
Epoch 5/10, Batch 130/145, Loss: 0.2119
Epoch 5/10, Batch 140/145, Loss: 0.2887
Epoch 5/10, Train Loss: 0.2388, Valid Loss: 0.2464
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2018
Epoch 6/10, Batch 20/145, Loss: 0.3236
Epoch 6/10, Batch 30/145, Loss: 0.1906
Epoch 6/10, Batch 40/145, Loss: 0.2807
Epoch 6/10, Batch 50/145, Loss: 0.3058
Epoch 6/10, Batch 60/145, Loss: 0.1994
Epoch 6/10, Batch 70/145, Loss: 0.2165
Epoch 6/10, Batch 80/145, Loss: 0.3155
Epoch 6/10, Batch 90/145, Loss: 0.2181
Epoch 6/10, Batch 100/145, Loss: 0.2651
Epoch 6/10, Batch 110/145, Loss: 0.1986
Epoch 6/10, Batch 120/145, Loss: 0.2385
Epoch 6/10, Batch 130/145, Loss: 0.0610
Epoch 6/10, Batch 140/145, Loss: 0.4405
Epoch 6/10, Train Loss: 0.2323, Valid Loss: 0.2454
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3057
Epoch 7/10, Batch 20/145, Loss: 0.1595
Epoch 7/10, Batch 30/145, Loss: 0.1749
Epoch 7/10, Batch 40/145, Loss: 0.4864
Epoch 7/10, Batch 50/145, Loss: 0.1319
Epoch 7/10, Batch 60/145, Loss: 0.1015
Epoch 7/10, Batch 70/145, Loss: 0.1278
Epoch 7/10, Batch 80/145, Loss: 0.0965
Epoch 7/10, Batch 90/145, Loss: 0.2532
Epoch 7/10, Batch 100/145, Loss: 0.1337
Epoch 7/10, Batch 110/145, Loss: 0.1935
Epoch 7/10, Batch 120/145, Loss: 0.1885
Epoch 7/10, Batch 130/145, Loss: 0.3019
Epoch 7/10, Batch 140/145, Loss: 0.2780
Epoch 7/10, Train Loss: 0.2184, Valid Loss: 0.2411
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1488
Epoch 8/10, Batch 20/145, Loss: 0.2046
Epoch 8/10, Batch 30/145, Loss: 0.2047
Epoch 8/10, Batch 40/145, Loss: 0.2200
Epoch 8/10, Batch 50/145, Loss: 0.3691
Epoch 8/10, Batch 60/145, Loss: 0.0895
Epoch 8/10, Batch 70/145, Loss: 0.0979
Epoch 8/10, Batch 80/145, Loss: 0.0993
Epoch 8/10, Batch 90/145, Loss: 0.1625
Epoch 8/10, Batch 100/145, Loss: 0.3564
Epoch 8/10, Batch 110/145, Loss: 0.1856
Epoch 8/10, Batch 120/145, Loss: 0.1731
Epoch 8/10, Batch 130/145, Loss: 0.2512
Epoch 8/10, Batch 140/145, Loss: 0.2878
Epoch 8/10, Train Loss: 0.2108, Valid Loss: 0.2297
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2172
Epoch 9/10, Batch 20/145, Loss: 0.2233
Epoch 9/10, Batch 30/145, Loss: 0.1615
Epoch 9/10, Batch 40/145, Loss: 0.2910
Epoch 9/10, Batch 50/145, Loss: 0.1440
Epoch 9/10, Batch 60/145, Loss: 0.1015
Epoch 9/10, Batch 70/145, Loss: 0.1333
Epoch 9/10, Batch 80/145, Loss: 0.2479
Epoch 9/10, Batch 90/145, Loss: 0.1553
Epoch 9/10, Batch 100/145, Loss: 0.1618
Epoch 9/10, Batch 110/145, Loss: 0.1946
Epoch 9/10, Batch 120/145, Loss: 0.2653
Epoch 9/10, Batch 130/145, Loss: 0.1713
Epoch 9/10, Batch 140/145, Loss: 0.1452
Epoch 9/10, Train Loss: 0.2010, Valid Loss: 0.2352
Epoch 10/10, Batch 10/145, Loss: 0.0776
Epoch 10/10, Batch 20/145, Loss: 0.1643
Epoch 10/10, Batch 30/145, Loss: 0.1384
Epoch 10/10, Batch 40/145, Loss: 0.1769
Epoch 10/10, Batch 50/145, Loss: 0.2058
Epoch 10/10, Batch 60/145, Loss: 0.1368
Epoch 10/10, Batch 70/145, Loss: 0.2843
Epoch 10/10, Batch 80/145, Loss: 0.5833
Epoch 10/10, Batch 90/145, Loss: 0.2134
Epoch 10/10, Batch 100/145, Loss: 0.1380
Epoch 10/10, Batch 110/145, Loss: 0.3884
Epoch 10/10, Batch 120/145, Loss: 0.2301
Epoch 10/10, Batch 130/145, Loss: 0.1607
Epoch 10/10, Batch 140/145, Loss: 0.2263
Epoch 10/10, Train Loss: 0.2013, Valid Loss: 0.2293
Model saved!
Accuracy: 0.9206
Precision: 0.9186
Recall: 0.9206
F1-score: 0.9192
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5051
Epoch 1/10, Batch 20/145, Loss: 0.9519
Epoch 1/10, Batch 30/145, Loss: 0.8436
Epoch 1/10, Batch 40/145, Loss: 0.8011
Epoch 1/10, Batch 50/145, Loss: 0.6316
Epoch 1/10, Batch 60/145, Loss: 0.5496
Epoch 1/10, Batch 70/145, Loss: 0.5753
Epoch 1/10, Batch 80/145, Loss: 0.5026
Epoch 1/10, Batch 90/145, Loss: 0.6281
Epoch 1/10, Batch 100/145, Loss: 0.6604
Epoch 1/10, Batch 110/145, Loss: 0.4999
Epoch 1/10, Batch 120/145, Loss: 0.5963
Epoch 1/10, Batch 130/145, Loss: 0.4819
Epoch 1/10, Batch 140/145, Loss: 0.4647
Epoch 1/10, Train Loss: 0.6853, Valid Loss: 0.3778
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3073
Epoch 2/10, Batch 20/145, Loss: 0.5794
Epoch 2/10, Batch 30/145, Loss: 0.3315
Epoch 2/10, Batch 40/145, Loss: 0.3957
Epoch 2/10, Batch 50/145, Loss: 0.3320
Epoch 2/10, Batch 60/145, Loss: 0.3063
Epoch 2/10, Batch 70/145, Loss: 0.4590
Epoch 2/10, Batch 80/145, Loss: 0.3515
Epoch 2/10, Batch 90/145, Loss: 0.3940
Epoch 2/10, Batch 100/145, Loss: 0.3105
Epoch 2/10, Batch 110/145, Loss: 0.3378
Epoch 2/10, Batch 120/145, Loss: 0.4248
Epoch 2/10, Batch 130/145, Loss: 0.4168
Epoch 2/10, Batch 140/145, Loss: 0.3175
Epoch 2/10, Train Loss: 0.3590, Valid Loss: 0.2932
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3021
Epoch 3/10, Batch 20/145, Loss: 0.2472
Epoch 3/10, Batch 30/145, Loss: 0.1935
Epoch 3/10, Batch 40/145, Loss: 0.3275
Epoch 3/10, Batch 50/145, Loss: 0.2779
Epoch 3/10, Batch 60/145, Loss: 0.4108
Epoch 3/10, Batch 70/145, Loss: 0.2179
Epoch 3/10, Batch 80/145, Loss: 0.2873
Epoch 3/10, Batch 90/145, Loss: 0.6021
Epoch 3/10, Batch 100/145, Loss: 0.2623
Epoch 3/10, Batch 110/145, Loss: 0.2187
Epoch 3/10, Batch 120/145, Loss: 0.2298
Epoch 3/10, Batch 130/145, Loss: 0.1930
Epoch 3/10, Batch 140/145, Loss: 0.2944
Epoch 3/10, Train Loss: 0.3068, Valid Loss: 0.2671
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2505
Epoch 4/10, Batch 20/145, Loss: 0.2802
Epoch 4/10, Batch 30/145, Loss: 0.2986
Epoch 4/10, Batch 40/145, Loss: 0.2180
Epoch 4/10, Batch 50/145, Loss: 0.2112
Epoch 4/10, Batch 60/145, Loss: 0.1469
Epoch 4/10, Batch 70/145, Loss: 0.2140
Epoch 4/10, Batch 80/145, Loss: 0.2993
Epoch 4/10, Batch 90/145, Loss: 0.2189
Epoch 4/10, Batch 100/145, Loss: 0.1257
Epoch 4/10, Batch 110/145, Loss: 0.3687
Epoch 4/10, Batch 120/145, Loss: 0.2482
Epoch 4/10, Batch 130/145, Loss: 0.1949
Epoch 4/10, Batch 140/145, Loss: 0.2074
Epoch 4/10, Train Loss: 0.2652, Valid Loss: 0.2580
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2109
Epoch 5/10, Batch 20/145, Loss: 0.3988
Epoch 5/10, Batch 30/145, Loss: 0.1539
Epoch 5/10, Batch 40/145, Loss: 0.3037
Epoch 5/10, Batch 50/145, Loss: 0.1335
Epoch 5/10, Batch 60/145, Loss: 0.2303
Epoch 5/10, Batch 70/145, Loss: 0.2664
Epoch 5/10, Batch 80/145, Loss: 0.2639
Epoch 5/10, Batch 90/145, Loss: 0.1796
Epoch 5/10, Batch 100/145, Loss: 0.3127
Epoch 5/10, Batch 110/145, Loss: 0.1840
Epoch 5/10, Batch 120/145, Loss: 0.2618
Epoch 5/10, Batch 130/145, Loss: 0.1419
Epoch 5/10, Batch 140/145, Loss: 0.3453
Epoch 5/10, Train Loss: 0.2410, Valid Loss: 0.2437
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1115
Epoch 6/10, Batch 20/145, Loss: 0.2382
Epoch 6/10, Batch 30/145, Loss: 0.2258
Epoch 6/10, Batch 40/145, Loss: 0.2838
Epoch 6/10, Batch 50/145, Loss: 0.2563
Epoch 6/10, Batch 60/145, Loss: 0.2491
Epoch 6/10, Batch 70/145, Loss: 0.3609
Epoch 6/10, Batch 80/145, Loss: 0.2546
Epoch 6/10, Batch 90/145, Loss: 0.2122
Epoch 6/10, Batch 100/145, Loss: 0.3345
Epoch 6/10, Batch 110/145, Loss: 0.1366
Epoch 6/10, Batch 120/145, Loss: 0.1648
Epoch 6/10, Batch 130/145, Loss: 0.0964
Epoch 6/10, Batch 140/145, Loss: 0.2394
Epoch 6/10, Train Loss: 0.2279, Valid Loss: 0.2357
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2809
Epoch 7/10, Batch 20/145, Loss: 0.2501
Epoch 7/10, Batch 30/145, Loss: 0.1265
Epoch 7/10, Batch 40/145, Loss: 0.5163
Epoch 7/10, Batch 50/145, Loss: 0.1024
Epoch 7/10, Batch 60/145, Loss: 0.1888
Epoch 7/10, Batch 70/145, Loss: 0.1692
Epoch 7/10, Batch 80/145, Loss: 0.1962
Epoch 7/10, Batch 90/145, Loss: 0.5022
Epoch 7/10, Batch 100/145, Loss: 0.1612
Epoch 7/10, Batch 110/145, Loss: 0.2025
Epoch 7/10, Batch 120/145, Loss: 0.1960
Epoch 7/10, Batch 130/145, Loss: 0.2287
Epoch 7/10, Batch 140/145, Loss: 0.1016
Epoch 7/10, Train Loss: 0.2158, Valid Loss: 0.2256
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1302
Epoch 8/10, Batch 20/145, Loss: 0.2012
Epoch 8/10, Batch 30/145, Loss: 0.1924
Epoch 8/10, Batch 40/145, Loss: 0.2304
Epoch 8/10, Batch 50/145, Loss: 0.1530
Epoch 8/10, Batch 60/145, Loss: 0.1597
Epoch 8/10, Batch 70/145, Loss: 0.1311
Epoch 8/10, Batch 80/145, Loss: 0.1277
Epoch 8/10, Batch 90/145, Loss: 0.1601
Epoch 8/10, Batch 100/145, Loss: 0.2301
Epoch 8/10, Batch 110/145, Loss: 0.2820
Epoch 8/10, Batch 120/145, Loss: 0.1723
Epoch 8/10, Batch 130/145, Loss: 0.1228
Epoch 8/10, Batch 140/145, Loss: 0.2835
Epoch 8/10, Train Loss: 0.2032, Valid Loss: 0.2282
Epoch 9/10, Batch 10/145, Loss: 0.2464
Epoch 9/10, Batch 20/145, Loss: 0.2240
Epoch 9/10, Batch 30/145, Loss: 0.0909
Epoch 9/10, Batch 40/145, Loss: 0.1675
Epoch 9/10, Batch 50/145, Loss: 0.2695
Epoch 9/10, Batch 60/145, Loss: 0.3293
Epoch 9/10, Batch 70/145, Loss: 0.0551
Epoch 9/10, Batch 80/145, Loss: 0.2318
Epoch 9/10, Batch 90/145, Loss: 0.1703
Epoch 9/10, Batch 100/145, Loss: 0.3292
Epoch 9/10, Batch 110/145, Loss: 0.1121
Epoch 9/10, Batch 120/145, Loss: 0.1946
Epoch 9/10, Batch 130/145, Loss: 0.2437
Epoch 9/10, Batch 140/145, Loss: 0.1010
Epoch 9/10, Train Loss: 0.2078, Valid Loss: 0.2166
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2106
Epoch 10/10, Batch 20/145, Loss: 0.1274
Epoch 10/10, Batch 30/145, Loss: 0.0553
Epoch 10/10, Batch 40/145, Loss: 0.2149
Epoch 10/10, Batch 50/145, Loss: 0.2309
Epoch 10/10, Batch 60/145, Loss: 0.1936
Epoch 10/10, Batch 70/145, Loss: 0.1391
Epoch 10/10, Batch 80/145, Loss: 0.2814
Epoch 10/10, Batch 90/145, Loss: 0.0875
Epoch 10/10, Batch 100/145, Loss: 0.3445
Epoch 10/10, Batch 110/145, Loss: 0.4098
Epoch 10/10, Batch 120/145, Loss: 0.2359
Epoch 10/10, Batch 130/145, Loss: 0.1762
Epoch 10/10, Batch 140/145, Loss: 0.1868
Epoch 10/10, Train Loss: 0.1874, Valid Loss: 0.2199
Accuracy: 0.9206
Precision: 0.9184
Recall: 0.9206
F1-score: 0.9190
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5224
Epoch 1/10, Batch 20/145, Loss: 0.8934
Epoch 1/10, Batch 30/145, Loss: 0.8186
Epoch 1/10, Batch 40/145, Loss: 0.8701
Epoch 1/10, Batch 50/145, Loss: 0.7174
Epoch 1/10, Batch 60/145, Loss: 0.5530
Epoch 1/10, Batch 70/145, Loss: 0.7430
Epoch 1/10, Batch 80/145, Loss: 0.5505
Epoch 1/10, Batch 90/145, Loss: 0.6517
Epoch 1/10, Batch 100/145, Loss: 0.5601
Epoch 1/10, Batch 110/145, Loss: 0.4525
Epoch 1/10, Batch 120/145, Loss: 0.7111
Epoch 1/10, Batch 130/145, Loss: 0.3600
Epoch 1/10, Batch 140/145, Loss: 0.3588
Epoch 1/10, Train Loss: 0.6958, Valid Loss: 0.3757
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4975
Epoch 2/10, Batch 20/145, Loss: 0.5495
Epoch 2/10, Batch 30/145, Loss: 0.3683
Epoch 2/10, Batch 40/145, Loss: 0.5393
Epoch 2/10, Batch 50/145, Loss: 0.4676
Epoch 2/10, Batch 60/145, Loss: 0.4467
Epoch 2/10, Batch 70/145, Loss: 0.4551
Epoch 2/10, Batch 80/145, Loss: 0.2985
Epoch 2/10, Batch 90/145, Loss: 0.1895
Epoch 2/10, Batch 100/145, Loss: 0.3633
Epoch 2/10, Batch 110/145, Loss: 0.2951
Epoch 2/10, Batch 120/145, Loss: 0.2767
Epoch 2/10, Batch 130/145, Loss: 0.4701
Epoch 2/10, Batch 140/145, Loss: 0.2152
Epoch 2/10, Train Loss: 0.3737, Valid Loss: 0.2913
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2680
Epoch 3/10, Batch 20/145, Loss: 0.1945
Epoch 3/10, Batch 30/145, Loss: 0.2284
Epoch 3/10, Batch 40/145, Loss: 0.3067
Epoch 3/10, Batch 50/145, Loss: 0.2626
Epoch 3/10, Batch 60/145, Loss: 0.4441
Epoch 3/10, Batch 70/145, Loss: 0.3597
Epoch 3/10, Batch 80/145, Loss: 0.3391
Epoch 3/10, Batch 90/145, Loss: 0.5404
Epoch 3/10, Batch 100/145, Loss: 0.4539
Epoch 3/10, Batch 110/145, Loss: 0.2425
Epoch 3/10, Batch 120/145, Loss: 0.1856
Epoch 3/10, Batch 130/145, Loss: 0.2628
Epoch 3/10, Batch 140/145, Loss: 0.2060
Epoch 3/10, Train Loss: 0.3228, Valid Loss: 0.2651
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2615
Epoch 4/10, Batch 20/145, Loss: 0.3233
Epoch 4/10, Batch 30/145, Loss: 0.1964
Epoch 4/10, Batch 40/145, Loss: 0.2643
Epoch 4/10, Batch 50/145, Loss: 0.2944
Epoch 4/10, Batch 60/145, Loss: 0.1818
Epoch 4/10, Batch 70/145, Loss: 0.2868
Epoch 4/10, Batch 80/145, Loss: 0.2481
Epoch 4/10, Batch 90/145, Loss: 0.2047
Epoch 4/10, Batch 100/145, Loss: 0.2828
Epoch 4/10, Batch 110/145, Loss: 0.3133
Epoch 4/10, Batch 120/145, Loss: 0.1910
Epoch 4/10, Batch 130/145, Loss: 0.1461
Epoch 4/10, Batch 140/145, Loss: 0.2451
Epoch 4/10, Train Loss: 0.2714, Valid Loss: 0.2510
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1958
Epoch 5/10, Batch 20/145, Loss: 0.1569
Epoch 5/10, Batch 30/145, Loss: 0.2100
Epoch 5/10, Batch 40/145, Loss: 0.2873
Epoch 5/10, Batch 50/145, Loss: 0.1026
Epoch 5/10, Batch 60/145, Loss: 0.2770
Epoch 5/10, Batch 70/145, Loss: 0.2547
Epoch 5/10, Batch 80/145, Loss: 0.2757
Epoch 5/10, Batch 90/145, Loss: 0.2660
Epoch 5/10, Batch 100/145, Loss: 0.2634
Epoch 5/10, Batch 110/145, Loss: 0.1279
Epoch 5/10, Batch 120/145, Loss: 0.1532
Epoch 5/10, Batch 130/145, Loss: 0.1756
Epoch 5/10, Batch 140/145, Loss: 0.3203
Epoch 5/10, Train Loss: 0.2469, Valid Loss: 0.2426
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2878
Epoch 6/10, Batch 20/145, Loss: 0.3195
Epoch 6/10, Batch 30/145, Loss: 0.2190
Epoch 6/10, Batch 40/145, Loss: 0.3288
Epoch 6/10, Batch 50/145, Loss: 0.4299
Epoch 6/10, Batch 60/145, Loss: 0.1476
Epoch 6/10, Batch 70/145, Loss: 0.1839
Epoch 6/10, Batch 80/145, Loss: 0.4451
Epoch 6/10, Batch 90/145, Loss: 0.1780
Epoch 6/10, Batch 100/145, Loss: 0.0849
Epoch 6/10, Batch 110/145, Loss: 0.1532
Epoch 6/10, Batch 120/145, Loss: 0.2340
Epoch 6/10, Batch 130/145, Loss: 0.1680
Epoch 6/10, Batch 140/145, Loss: 0.2799
Epoch 6/10, Train Loss: 0.2405, Valid Loss: 0.2387
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3301
Epoch 7/10, Batch 20/145, Loss: 0.2358
Epoch 7/10, Batch 30/145, Loss: 0.1965
Epoch 7/10, Batch 40/145, Loss: 0.5226
Epoch 7/10, Batch 50/145, Loss: 0.1256
Epoch 7/10, Batch 60/145, Loss: 0.1212
Epoch 7/10, Batch 70/145, Loss: 0.1523
Epoch 7/10, Batch 80/145, Loss: 0.1484
Epoch 7/10, Batch 90/145, Loss: 0.2464
Epoch 7/10, Batch 100/145, Loss: 0.1827
Epoch 7/10, Batch 110/145, Loss: 0.2288
Epoch 7/10, Batch 120/145, Loss: 0.2020
Epoch 7/10, Batch 130/145, Loss: 0.2225
Epoch 7/10, Batch 140/145, Loss: 0.2219
Epoch 7/10, Train Loss: 0.2296, Valid Loss: 0.2184
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2637
Epoch 8/10, Batch 20/145, Loss: 0.1162
Epoch 8/10, Batch 30/145, Loss: 0.2314
Epoch 8/10, Batch 40/145, Loss: 0.2516
Epoch 8/10, Batch 50/145, Loss: 0.1262
Epoch 8/10, Batch 60/145, Loss: 0.1601
Epoch 8/10, Batch 70/145, Loss: 0.0558
Epoch 8/10, Batch 80/145, Loss: 0.2482
Epoch 8/10, Batch 90/145, Loss: 0.1766
Epoch 8/10, Batch 100/145, Loss: 0.3582
Epoch 8/10, Batch 110/145, Loss: 0.2008
Epoch 8/10, Batch 120/145, Loss: 0.1612
Epoch 8/10, Batch 130/145, Loss: 0.0960
Epoch 8/10, Batch 140/145, Loss: 0.2746
Epoch 8/10, Train Loss: 0.2204, Valid Loss: 0.2165
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1269
Epoch 9/10, Batch 20/145, Loss: 0.1510
Epoch 9/10, Batch 30/145, Loss: 0.1888
Epoch 9/10, Batch 40/145, Loss: 0.1012
Epoch 9/10, Batch 50/145, Loss: 0.1167
Epoch 9/10, Batch 60/145, Loss: 0.1578
Epoch 9/10, Batch 70/145, Loss: 0.3901
Epoch 9/10, Batch 80/145, Loss: 0.2344
Epoch 9/10, Batch 90/145, Loss: 0.2236
Epoch 9/10, Batch 100/145, Loss: 0.2471
Epoch 9/10, Batch 110/145, Loss: 0.1718
Epoch 9/10, Batch 120/145, Loss: 0.1341
Epoch 9/10, Batch 130/145, Loss: 0.1194
Epoch 9/10, Batch 140/145, Loss: 0.1613
Epoch 9/10, Train Loss: 0.2119, Valid Loss: 0.2108
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1064
Epoch 10/10, Batch 20/145, Loss: 0.0985
Epoch 10/10, Batch 30/145, Loss: 0.0660
Epoch 10/10, Batch 40/145, Loss: 0.2225
Epoch 10/10, Batch 50/145, Loss: 0.1852
Epoch 10/10, Batch 60/145, Loss: 0.3712
Epoch 10/10, Batch 70/145, Loss: 0.2666
Epoch 10/10, Batch 80/145, Loss: 0.3802
Epoch 10/10, Batch 90/145, Loss: 0.1886
Epoch 10/10, Batch 100/145, Loss: 0.1463
Epoch 10/10, Batch 110/145, Loss: 0.1711
Epoch 10/10, Batch 120/145, Loss: 0.2322
Epoch 10/10, Batch 130/145, Loss: 0.1812
Epoch 10/10, Batch 140/145, Loss: 0.3547
Epoch 10/10, Train Loss: 0.2117, Valid Loss: 0.2107
Model saved!
Accuracy: 0.9276
Precision: 0.9273
Recall: 0.9276
F1-score: 0.9269
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4969
Epoch 1/10, Batch 20/145, Loss: 0.8606
Epoch 1/10, Batch 30/145, Loss: 0.8832
Epoch 1/10, Batch 40/145, Loss: 0.8893
Epoch 1/10, Batch 50/145, Loss: 0.5894
Epoch 1/10, Batch 60/145, Loss: 0.5213
Epoch 1/10, Batch 70/145, Loss: 0.6975
Epoch 1/10, Batch 80/145, Loss: 0.4784
Epoch 1/10, Batch 90/145, Loss: 0.5091
Epoch 1/10, Batch 100/145, Loss: 0.5112
Epoch 1/10, Batch 110/145, Loss: 0.4866
Epoch 1/10, Batch 120/145, Loss: 0.8414
Epoch 1/10, Batch 130/145, Loss: 0.3723
Epoch 1/10, Batch 140/145, Loss: 0.4077
Epoch 1/10, Train Loss: 0.6843, Valid Loss: 0.3567
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3586
Epoch 2/10, Batch 20/145, Loss: 0.5569
Epoch 2/10, Batch 30/145, Loss: 0.2960
Epoch 2/10, Batch 40/145, Loss: 0.5089
Epoch 2/10, Batch 50/145, Loss: 0.3310
Epoch 2/10, Batch 60/145, Loss: 0.5546
Epoch 2/10, Batch 70/145, Loss: 0.3181
Epoch 2/10, Batch 80/145, Loss: 0.2577
Epoch 2/10, Batch 90/145, Loss: 0.3069
Epoch 2/10, Batch 100/145, Loss: 0.3230
Epoch 2/10, Batch 110/145, Loss: 0.2369
Epoch 2/10, Batch 120/145, Loss: 0.3372
Epoch 2/10, Batch 130/145, Loss: 0.3976
Epoch 2/10, Batch 140/145, Loss: 0.2222
Epoch 2/10, Train Loss: 0.3627, Valid Loss: 0.2724
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2700
Epoch 3/10, Batch 20/145, Loss: 0.4022
Epoch 3/10, Batch 30/145, Loss: 0.2648
Epoch 3/10, Batch 40/145, Loss: 0.3159
Epoch 3/10, Batch 50/145, Loss: 0.2748
Epoch 3/10, Batch 60/145, Loss: 0.2211
Epoch 3/10, Batch 70/145, Loss: 0.3022
Epoch 3/10, Batch 80/145, Loss: 0.4277
Epoch 3/10, Batch 90/145, Loss: 0.4952
Epoch 3/10, Batch 100/145, Loss: 0.3243
Epoch 3/10, Batch 110/145, Loss: 0.2956
Epoch 3/10, Batch 120/145, Loss: 0.1792
Epoch 3/10, Batch 130/145, Loss: 0.3291
Epoch 3/10, Batch 140/145, Loss: 0.3233
Epoch 3/10, Train Loss: 0.3103, Valid Loss: 0.2396
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1821
Epoch 4/10, Batch 20/145, Loss: 0.2498
Epoch 4/10, Batch 30/145, Loss: 0.4660
Epoch 4/10, Batch 40/145, Loss: 0.3384
Epoch 4/10, Batch 50/145, Loss: 0.2128
Epoch 4/10, Batch 60/145, Loss: 0.2003
Epoch 4/10, Batch 70/145, Loss: 0.1610
Epoch 4/10, Batch 80/145, Loss: 0.2036
Epoch 4/10, Batch 90/145, Loss: 0.3186
Epoch 4/10, Batch 100/145, Loss: 0.1990
Epoch 4/10, Batch 110/145, Loss: 0.2510
Epoch 4/10, Batch 120/145, Loss: 0.2130
Epoch 4/10, Batch 130/145, Loss: 0.2368
Epoch 4/10, Batch 140/145, Loss: 0.3164
Epoch 4/10, Train Loss: 0.2666, Valid Loss: 0.2319
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1772
Epoch 5/10, Batch 20/145, Loss: 0.3066
Epoch 5/10, Batch 30/145, Loss: 0.2394
Epoch 5/10, Batch 40/145, Loss: 0.1859
Epoch 5/10, Batch 50/145, Loss: 0.1155
Epoch 5/10, Batch 60/145, Loss: 0.2935
Epoch 5/10, Batch 70/145, Loss: 0.2314
Epoch 5/10, Batch 80/145, Loss: 0.2506
Epoch 5/10, Batch 90/145, Loss: 0.2173
Epoch 5/10, Batch 100/145, Loss: 0.2056
Epoch 5/10, Batch 110/145, Loss: 0.1728
Epoch 5/10, Batch 120/145, Loss: 0.1524
Epoch 5/10, Batch 130/145, Loss: 0.4328
Epoch 5/10, Batch 140/145, Loss: 0.3085
Epoch 5/10, Train Loss: 0.2432, Valid Loss: 0.2103
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2935
Epoch 6/10, Batch 20/145, Loss: 0.1137
Epoch 6/10, Batch 30/145, Loss: 0.2351
Epoch 6/10, Batch 40/145, Loss: 0.2714
Epoch 6/10, Batch 50/145, Loss: 0.2432
Epoch 6/10, Batch 60/145, Loss: 0.1461
Epoch 6/10, Batch 70/145, Loss: 0.1344
Epoch 6/10, Batch 80/145, Loss: 0.2400
Epoch 6/10, Batch 90/145, Loss: 0.2209
Epoch 6/10, Batch 100/145, Loss: 0.2891
Epoch 6/10, Batch 110/145, Loss: 0.1770
Epoch 6/10, Batch 120/145, Loss: 0.3852
Epoch 6/10, Batch 130/145, Loss: 0.2310
Epoch 6/10, Batch 140/145, Loss: 0.1563
Epoch 6/10, Train Loss: 0.2296, Valid Loss: 0.2097
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1769
Epoch 7/10, Batch 20/145, Loss: 0.2110
Epoch 7/10, Batch 30/145, Loss: 0.1198
Epoch 7/10, Batch 40/145, Loss: 0.2714
Epoch 7/10, Batch 50/145, Loss: 0.2935
Epoch 7/10, Batch 60/145, Loss: 0.1941
Epoch 7/10, Batch 70/145, Loss: 0.2517
Epoch 7/10, Batch 80/145, Loss: 0.2062
Epoch 7/10, Batch 90/145, Loss: 0.3108
Epoch 7/10, Batch 100/145, Loss: 0.1111
Epoch 7/10, Batch 110/145, Loss: 0.3365
Epoch 7/10, Batch 120/145, Loss: 0.1673
Epoch 7/10, Batch 130/145, Loss: 0.1712
Epoch 7/10, Batch 140/145, Loss: 0.1394
Epoch 7/10, Train Loss: 0.2162, Valid Loss: 0.1984
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1655
Epoch 8/10, Batch 20/145, Loss: 0.2385
Epoch 8/10, Batch 30/145, Loss: 0.1424
Epoch 8/10, Batch 40/145, Loss: 0.2641
Epoch 8/10, Batch 50/145, Loss: 0.1620
Epoch 8/10, Batch 60/145, Loss: 0.2403
Epoch 8/10, Batch 70/145, Loss: 0.2466
Epoch 8/10, Batch 80/145, Loss: 0.1797
Epoch 8/10, Batch 90/145, Loss: 0.1746
Epoch 8/10, Batch 100/145, Loss: 0.1525
Epoch 8/10, Batch 110/145, Loss: 0.2696
Epoch 8/10, Batch 120/145, Loss: 0.1208
Epoch 8/10, Batch 130/145, Loss: 0.1348
Epoch 8/10, Batch 140/145, Loss: 0.5764
Epoch 8/10, Train Loss: 0.2107, Valid Loss: 0.1929
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3441
Epoch 9/10, Batch 20/145, Loss: 0.1146
Epoch 9/10, Batch 30/145, Loss: 0.1195
Epoch 9/10, Batch 40/145, Loss: 0.1184
Epoch 9/10, Batch 50/145, Loss: 0.1210
Epoch 9/10, Batch 60/145, Loss: 0.2007
Epoch 9/10, Batch 70/145, Loss: 0.1303
Epoch 9/10, Batch 80/145, Loss: 0.2651
Epoch 9/10, Batch 90/145, Loss: 0.1559
Epoch 9/10, Batch 100/145, Loss: 0.3060
Epoch 9/10, Batch 110/145, Loss: 0.0254
Epoch 9/10, Batch 120/145, Loss: 0.3606
Epoch 9/10, Batch 130/145, Loss: 0.2136
Epoch 9/10, Batch 140/145, Loss: 0.2386
Epoch 9/10, Train Loss: 0.2033, Valid Loss: 0.1864
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2011
Epoch 10/10, Batch 20/145, Loss: 0.0821
Epoch 10/10, Batch 30/145, Loss: 0.1749
Epoch 10/10, Batch 40/145, Loss: 0.2844
Epoch 10/10, Batch 50/145, Loss: 0.2247
Epoch 10/10, Batch 60/145, Loss: 0.1582
Epoch 10/10, Batch 70/145, Loss: 0.0961
Epoch 10/10, Batch 80/145, Loss: 0.4563
Epoch 10/10, Batch 90/145, Loss: 0.0877
Epoch 10/10, Batch 100/145, Loss: 0.1464
Epoch 10/10, Batch 110/145, Loss: 0.1476
Epoch 10/10, Batch 120/145, Loss: 0.1911
Epoch 10/10, Batch 130/145, Loss: 0.2778
Epoch 10/10, Batch 140/145, Loss: 0.3465
Epoch 10/10, Train Loss: 0.1994, Valid Loss: 0.1867
Accuracy: 0.9206
Precision: 0.9184
Recall: 0.9206
F1-score: 0.9186
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5338
Epoch 1/10, Batch 20/145, Loss: 0.9025
Epoch 1/10, Batch 30/145, Loss: 0.8902
Epoch 1/10, Batch 40/145, Loss: 0.7293
Epoch 1/10, Batch 50/145, Loss: 0.8268
Epoch 1/10, Batch 60/145, Loss: 0.6301
Epoch 1/10, Batch 70/145, Loss: 0.6218
Epoch 1/10, Batch 80/145, Loss: 0.4958
Epoch 1/10, Batch 90/145, Loss: 0.5086
Epoch 1/10, Batch 100/145, Loss: 0.7798
Epoch 1/10, Batch 110/145, Loss: 0.2993
Epoch 1/10, Batch 120/145, Loss: 0.6441
Epoch 1/10, Batch 130/145, Loss: 0.4771
Epoch 1/10, Batch 140/145, Loss: 0.4144
Epoch 1/10, Train Loss: 0.6855, Valid Loss: 0.3943
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2830
Epoch 2/10, Batch 20/145, Loss: 0.4683
Epoch 2/10, Batch 30/145, Loss: 0.2843
Epoch 2/10, Batch 40/145, Loss: 0.3397
Epoch 2/10, Batch 50/145, Loss: 0.2061
Epoch 2/10, Batch 60/145, Loss: 0.5914
Epoch 2/10, Batch 70/145, Loss: 0.3805
Epoch 2/10, Batch 80/145, Loss: 0.3972
Epoch 2/10, Batch 90/145, Loss: 0.2046
Epoch 2/10, Batch 100/145, Loss: 0.2582
Epoch 2/10, Batch 110/145, Loss: 0.3122
Epoch 2/10, Batch 120/145, Loss: 0.5228
Epoch 2/10, Batch 130/145, Loss: 0.3749
Epoch 2/10, Batch 140/145, Loss: 0.1893
Epoch 2/10, Train Loss: 0.3641, Valid Loss: 0.2996
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2836
Epoch 3/10, Batch 20/145, Loss: 0.1532
Epoch 3/10, Batch 30/145, Loss: 0.2178
Epoch 3/10, Batch 40/145, Loss: 0.1881
Epoch 3/10, Batch 50/145, Loss: 0.2751
Epoch 3/10, Batch 60/145, Loss: 0.2390
Epoch 3/10, Batch 70/145, Loss: 0.2655
Epoch 3/10, Batch 80/145, Loss: 0.2531
Epoch 3/10, Batch 90/145, Loss: 0.6885
Epoch 3/10, Batch 100/145, Loss: 0.2248
Epoch 3/10, Batch 110/145, Loss: 0.2533
Epoch 3/10, Batch 120/145, Loss: 0.1868
Epoch 3/10, Batch 130/145, Loss: 0.2370
Epoch 3/10, Batch 140/145, Loss: 0.2101
Epoch 3/10, Train Loss: 0.3094, Valid Loss: 0.2650
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2213
Epoch 4/10, Batch 20/145, Loss: 0.1389
Epoch 4/10, Batch 30/145, Loss: 0.3542
Epoch 4/10, Batch 40/145, Loss: 0.2397
Epoch 4/10, Batch 50/145, Loss: 0.1461
Epoch 4/10, Batch 60/145, Loss: 0.2170
Epoch 4/10, Batch 70/145, Loss: 0.2616
Epoch 4/10, Batch 80/145, Loss: 0.2134
Epoch 4/10, Batch 90/145, Loss: 0.2764
Epoch 4/10, Batch 100/145, Loss: 0.3237
Epoch 4/10, Batch 110/145, Loss: 0.2426
Epoch 4/10, Batch 120/145, Loss: 0.2248
Epoch 4/10, Batch 130/145, Loss: 0.1908
Epoch 4/10, Batch 140/145, Loss: 0.1574
Epoch 4/10, Train Loss: 0.2642, Valid Loss: 0.2565
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2312
Epoch 5/10, Batch 20/145, Loss: 0.1702
Epoch 5/10, Batch 30/145, Loss: 0.1151
Epoch 5/10, Batch 40/145, Loss: 0.2247
Epoch 5/10, Batch 50/145, Loss: 0.1109
Epoch 5/10, Batch 60/145, Loss: 0.1754
Epoch 5/10, Batch 70/145, Loss: 0.2708
Epoch 5/10, Batch 80/145, Loss: 0.2926
Epoch 5/10, Batch 90/145, Loss: 0.2505
Epoch 5/10, Batch 100/145, Loss: 0.2722
Epoch 5/10, Batch 110/145, Loss: 0.1327
Epoch 5/10, Batch 120/145, Loss: 0.1525
Epoch 5/10, Batch 130/145, Loss: 0.2246
Epoch 5/10, Batch 140/145, Loss: 0.1867
Epoch 5/10, Train Loss: 0.2373, Valid Loss: 0.2399
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3503
Epoch 6/10, Batch 20/145, Loss: 0.1872
Epoch 6/10, Batch 30/145, Loss: 0.2590
Epoch 6/10, Batch 40/145, Loss: 0.1916
Epoch 6/10, Batch 50/145, Loss: 0.2792
Epoch 6/10, Batch 60/145, Loss: 0.1511
Epoch 6/10, Batch 70/145, Loss: 0.1740
Epoch 6/10, Batch 80/145, Loss: 0.1806
Epoch 6/10, Batch 90/145, Loss: 0.2061
Epoch 6/10, Batch 100/145, Loss: 0.1587
Epoch 6/10, Batch 110/145, Loss: 0.1869
Epoch 6/10, Batch 120/145, Loss: 0.2505
Epoch 6/10, Batch 130/145, Loss: 0.1129
Epoch 6/10, Batch 140/145, Loss: 0.2811
Epoch 6/10, Train Loss: 0.2314, Valid Loss: 0.2343
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1772
Epoch 7/10, Batch 20/145, Loss: 0.2430
Epoch 7/10, Batch 30/145, Loss: 0.1479
Epoch 7/10, Batch 40/145, Loss: 0.3624
Epoch 7/10, Batch 50/145, Loss: 0.2446
Epoch 7/10, Batch 60/145, Loss: 0.1565
Epoch 7/10, Batch 70/145, Loss: 0.2643
Epoch 7/10, Batch 80/145, Loss: 0.1601
Epoch 7/10, Batch 90/145, Loss: 0.1451
Epoch 7/10, Batch 100/145, Loss: 0.2861
Epoch 7/10, Batch 110/145, Loss: 0.3650
Epoch 7/10, Batch 120/145, Loss: 0.2121
Epoch 7/10, Batch 130/145, Loss: 0.2228
Epoch 7/10, Batch 140/145, Loss: 0.3265
Epoch 7/10, Train Loss: 0.2256, Valid Loss: 0.2264
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1897
Epoch 8/10, Batch 20/145, Loss: 0.1006
Epoch 8/10, Batch 30/145, Loss: 0.0866
Epoch 8/10, Batch 40/145, Loss: 0.2172
Epoch 8/10, Batch 50/145, Loss: 0.3628
Epoch 8/10, Batch 60/145, Loss: 0.1624
Epoch 8/10, Batch 70/145, Loss: 0.1797
Epoch 8/10, Batch 80/145, Loss: 0.1309
Epoch 8/10, Batch 90/145, Loss: 0.1773
Epoch 8/10, Batch 100/145, Loss: 0.2052
Epoch 8/10, Batch 110/145, Loss: 0.2384
Epoch 8/10, Batch 120/145, Loss: 0.2764
Epoch 8/10, Batch 130/145, Loss: 0.1409
Epoch 8/10, Batch 140/145, Loss: 0.2545
Epoch 8/10, Train Loss: 0.2121, Valid Loss: 0.2237
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1557
Epoch 9/10, Batch 20/145, Loss: 0.1528
Epoch 9/10, Batch 30/145, Loss: 0.0787
Epoch 9/10, Batch 40/145, Loss: 0.2544
Epoch 9/10, Batch 50/145, Loss: 0.1709
Epoch 9/10, Batch 60/145, Loss: 0.2369
Epoch 9/10, Batch 70/145, Loss: 0.1277
Epoch 9/10, Batch 80/145, Loss: 0.2561
Epoch 9/10, Batch 90/145, Loss: 0.3483
Epoch 9/10, Batch 100/145, Loss: 0.2413
Epoch 9/10, Batch 110/145, Loss: 0.0643
Epoch 9/10, Batch 120/145, Loss: 0.2418
Epoch 9/10, Batch 130/145, Loss: 0.2703
Epoch 9/10, Batch 140/145, Loss: 0.1567
Epoch 9/10, Train Loss: 0.2013, Valid Loss: 0.2209
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1300
Epoch 10/10, Batch 20/145, Loss: 0.1722
Epoch 10/10, Batch 30/145, Loss: 0.1011
Epoch 10/10, Batch 40/145, Loss: 0.1170
Epoch 10/10, Batch 50/145, Loss: 0.2751
Epoch 10/10, Batch 60/145, Loss: 0.1095
Epoch 10/10, Batch 70/145, Loss: 0.1053
Epoch 10/10, Batch 80/145, Loss: 0.4090
Epoch 10/10, Batch 90/145, Loss: 0.0882
Epoch 10/10, Batch 100/145, Loss: 0.1340
Epoch 10/10, Batch 110/145, Loss: 0.2058
Epoch 10/10, Batch 120/145, Loss: 0.2547
Epoch 10/10, Batch 130/145, Loss: 0.2261
Epoch 10/10, Batch 140/145, Loss: 0.2672
Epoch 10/10, Train Loss: 0.2002, Valid Loss: 0.2170
Model saved!
Accuracy: 0.9229
Precision: 0.9210
Recall: 0.9229
F1-score: 0.9213
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5036
Epoch 1/10, Batch 20/145, Loss: 0.8710
Epoch 1/10, Batch 30/145, Loss: 0.9411
Epoch 1/10, Batch 40/145, Loss: 0.8324
Epoch 1/10, Batch 50/145, Loss: 0.5866
Epoch 1/10, Batch 60/145, Loss: 0.5462
Epoch 1/10, Batch 70/145, Loss: 0.6188
Epoch 1/10, Batch 80/145, Loss: 0.4860
Epoch 1/10, Batch 90/145, Loss: 0.4061
Epoch 1/10, Batch 100/145, Loss: 0.5546
Epoch 1/10, Batch 110/145, Loss: 0.5573
Epoch 1/10, Batch 120/145, Loss: 0.5110
Epoch 1/10, Batch 130/145, Loss: 0.4348
Epoch 1/10, Batch 140/145, Loss: 0.4387
Epoch 1/10, Train Loss: 0.6806, Valid Loss: 0.3756
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3569
Epoch 2/10, Batch 20/145, Loss: 0.5657
Epoch 2/10, Batch 30/145, Loss: 0.3217
Epoch 2/10, Batch 40/145, Loss: 0.4443
Epoch 2/10, Batch 50/145, Loss: 0.3352
Epoch 2/10, Batch 60/145, Loss: 0.4896
Epoch 2/10, Batch 70/145, Loss: 0.4592
Epoch 2/10, Batch 80/145, Loss: 0.4430
Epoch 2/10, Batch 90/145, Loss: 0.2540
Epoch 2/10, Batch 100/145, Loss: 0.2663
Epoch 2/10, Batch 110/145, Loss: 0.2990
Epoch 2/10, Batch 120/145, Loss: 0.3354
Epoch 2/10, Batch 130/145, Loss: 0.3203
Epoch 2/10, Batch 140/145, Loss: 0.2189
Epoch 2/10, Train Loss: 0.3555, Valid Loss: 0.2920
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2150
Epoch 3/10, Batch 20/145, Loss: 0.2402
Epoch 3/10, Batch 30/145, Loss: 0.2207
Epoch 3/10, Batch 40/145, Loss: 0.2697
Epoch 3/10, Batch 50/145, Loss: 0.2367
Epoch 3/10, Batch 60/145, Loss: 0.3786
Epoch 3/10, Batch 70/145, Loss: 0.1519
Epoch 3/10, Batch 80/145, Loss: 0.2751
Epoch 3/10, Batch 90/145, Loss: 0.4931
Epoch 3/10, Batch 100/145, Loss: 0.2748
Epoch 3/10, Batch 110/145, Loss: 0.3621
Epoch 3/10, Batch 120/145, Loss: 0.1384
Epoch 3/10, Batch 130/145, Loss: 0.3199
Epoch 3/10, Batch 140/145, Loss: 0.1809
Epoch 3/10, Train Loss: 0.3020, Valid Loss: 0.2615
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2271
Epoch 4/10, Batch 20/145, Loss: 0.3845
Epoch 4/10, Batch 30/145, Loss: 0.2334
Epoch 4/10, Batch 40/145, Loss: 0.2965
Epoch 4/10, Batch 50/145, Loss: 0.1561
Epoch 4/10, Batch 60/145, Loss: 0.2347
Epoch 4/10, Batch 70/145, Loss: 0.2039
Epoch 4/10, Batch 80/145, Loss: 0.3551
Epoch 4/10, Batch 90/145, Loss: 0.2598
Epoch 4/10, Batch 100/145, Loss: 0.1907
Epoch 4/10, Batch 110/145, Loss: 0.2854
Epoch 4/10, Batch 120/145, Loss: 0.2215
Epoch 4/10, Batch 130/145, Loss: 0.1366
Epoch 4/10, Batch 140/145, Loss: 0.3957
Epoch 4/10, Train Loss: 0.2608, Valid Loss: 0.2599
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2867
Epoch 5/10, Batch 20/145, Loss: 0.3554
Epoch 5/10, Batch 30/145, Loss: 0.2487
Epoch 5/10, Batch 40/145, Loss: 0.3557
Epoch 5/10, Batch 50/145, Loss: 0.1489
Epoch 5/10, Batch 60/145, Loss: 0.1392
Epoch 5/10, Batch 70/145, Loss: 0.2117
Epoch 5/10, Batch 80/145, Loss: 0.2815
Epoch 5/10, Batch 90/145, Loss: 0.1401
Epoch 5/10, Batch 100/145, Loss: 0.2092
Epoch 5/10, Batch 110/145, Loss: 0.1088
Epoch 5/10, Batch 120/145, Loss: 0.2567
Epoch 5/10, Batch 130/145, Loss: 0.2722
Epoch 5/10, Batch 140/145, Loss: 0.2326
Epoch 5/10, Train Loss: 0.2359, Valid Loss: 0.2391
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2652
Epoch 6/10, Batch 20/145, Loss: 0.2117
Epoch 6/10, Batch 30/145, Loss: 0.2961
Epoch 6/10, Batch 40/145, Loss: 0.1761
Epoch 6/10, Batch 50/145, Loss: 0.2452
Epoch 6/10, Batch 60/145, Loss: 0.1370
Epoch 6/10, Batch 70/145, Loss: 0.2978
Epoch 6/10, Batch 80/145, Loss: 0.1644
Epoch 6/10, Batch 90/145, Loss: 0.1821
Epoch 6/10, Batch 100/145, Loss: 0.2383
Epoch 6/10, Batch 110/145, Loss: 0.1486
Epoch 6/10, Batch 120/145, Loss: 0.3323
Epoch 6/10, Batch 130/145, Loss: 0.2711
Epoch 6/10, Batch 140/145, Loss: 0.1254
Epoch 6/10, Train Loss: 0.2183, Valid Loss: 0.2398
Epoch 7/10, Batch 10/145, Loss: 0.2009
Epoch 7/10, Batch 20/145, Loss: 0.0931
Epoch 7/10, Batch 30/145, Loss: 0.2349
Epoch 7/10, Batch 40/145, Loss: 0.5573
Epoch 7/10, Batch 50/145, Loss: 0.1757
Epoch 7/10, Batch 60/145, Loss: 0.1194
Epoch 7/10, Batch 70/145, Loss: 0.2426
Epoch 7/10, Batch 80/145, Loss: 0.1841
Epoch 7/10, Batch 90/145, Loss: 0.2763
Epoch 7/10, Batch 100/145, Loss: 0.3369
Epoch 7/10, Batch 110/145, Loss: 0.2425
Epoch 7/10, Batch 120/145, Loss: 0.1271
Epoch 7/10, Batch 130/145, Loss: 0.2575
Epoch 7/10, Batch 140/145, Loss: 0.1366
Epoch 7/10, Train Loss: 0.2145, Valid Loss: 0.2177
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1641
Epoch 8/10, Batch 20/145, Loss: 0.2580
Epoch 8/10, Batch 30/145, Loss: 0.2122
Epoch 8/10, Batch 40/145, Loss: 0.2586
Epoch 8/10, Batch 50/145, Loss: 0.2173
Epoch 8/10, Batch 60/145, Loss: 0.1487
Epoch 8/10, Batch 70/145, Loss: 0.1366
Epoch 8/10, Batch 80/145, Loss: 0.1637
Epoch 8/10, Batch 90/145, Loss: 0.1678
Epoch 8/10, Batch 100/145, Loss: 0.3474
Epoch 8/10, Batch 110/145, Loss: 0.3883
Epoch 8/10, Batch 120/145, Loss: 0.2275
Epoch 8/10, Batch 130/145, Loss: 0.2956
Epoch 8/10, Batch 140/145, Loss: 0.1557
Epoch 8/10, Train Loss: 0.2084, Valid Loss: 0.2211
Epoch 9/10, Batch 10/145, Loss: 0.2214
Epoch 9/10, Batch 20/145, Loss: 0.1120
Epoch 9/10, Batch 30/145, Loss: 0.1083
Epoch 9/10, Batch 40/145, Loss: 0.0896
Epoch 9/10, Batch 50/145, Loss: 0.1768
Epoch 9/10, Batch 60/145, Loss: 0.2013
Epoch 9/10, Batch 70/145, Loss: 0.1154
Epoch 9/10, Batch 80/145, Loss: 0.1998
Epoch 9/10, Batch 90/145, Loss: 0.2004
Epoch 9/10, Batch 100/145, Loss: 0.1904
Epoch 9/10, Batch 110/145, Loss: 0.2285
Epoch 9/10, Batch 120/145, Loss: 0.1906
Epoch 9/10, Batch 130/145, Loss: 0.2056
Epoch 9/10, Batch 140/145, Loss: 0.2313
Epoch 9/10, Train Loss: 0.1982, Valid Loss: 0.2091
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1900
Epoch 10/10, Batch 20/145, Loss: 0.1041
Epoch 10/10, Batch 30/145, Loss: 0.0643
Epoch 10/10, Batch 40/145, Loss: 0.3347
Epoch 10/10, Batch 50/145, Loss: 0.2303
Epoch 10/10, Batch 60/145, Loss: 0.1421
Epoch 10/10, Batch 70/145, Loss: 0.1316
Epoch 10/10, Batch 80/145, Loss: 0.2303
Epoch 10/10, Batch 90/145, Loss: 0.2096
Epoch 10/10, Batch 100/145, Loss: 0.3542
Epoch 10/10, Batch 110/145, Loss: 0.2682
Epoch 10/10, Batch 120/145, Loss: 0.2265
Epoch 10/10, Batch 130/145, Loss: 0.2282
Epoch 10/10, Batch 140/145, Loss: 0.2635
Epoch 10/10, Train Loss: 0.1863, Valid Loss: 0.2110
Accuracy: 0.9229
Precision: 0.9207
Recall: 0.9229
F1-score: 0.9211
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4942
Epoch 1/10, Batch 20/145, Loss: 0.9057
Epoch 1/10, Batch 30/145, Loss: 0.8228
Epoch 1/10, Batch 40/145, Loss: 0.8338
Epoch 1/10, Batch 50/145, Loss: 0.5067
Epoch 1/10, Batch 60/145, Loss: 0.6473
Epoch 1/10, Batch 70/145, Loss: 0.5210
Epoch 1/10, Batch 80/145, Loss: 0.5067
Epoch 1/10, Batch 90/145, Loss: 0.6906
Epoch 1/10, Batch 100/145, Loss: 0.6825
Epoch 1/10, Batch 110/145, Loss: 0.3789
Epoch 1/10, Batch 120/145, Loss: 0.7017
Epoch 1/10, Batch 130/145, Loss: 0.3659
Epoch 1/10, Batch 140/145, Loss: 0.4654
Epoch 1/10, Train Loss: 0.6913, Valid Loss: 0.3733
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4373
Epoch 2/10, Batch 20/145, Loss: 0.4689
Epoch 2/10, Batch 30/145, Loss: 0.3249
Epoch 2/10, Batch 40/145, Loss: 0.6006
Epoch 2/10, Batch 50/145, Loss: 0.2637
Epoch 2/10, Batch 60/145, Loss: 0.4082
Epoch 2/10, Batch 70/145, Loss: 0.3778
Epoch 2/10, Batch 80/145, Loss: 0.3925
Epoch 2/10, Batch 90/145, Loss: 0.2276
Epoch 2/10, Batch 100/145, Loss: 0.3755
Epoch 2/10, Batch 110/145, Loss: 0.2798
Epoch 2/10, Batch 120/145, Loss: 0.3546
Epoch 2/10, Batch 130/145, Loss: 0.2995
Epoch 2/10, Batch 140/145, Loss: 0.1906
Epoch 2/10, Train Loss: 0.3568, Valid Loss: 0.2829
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2666
Epoch 3/10, Batch 20/145, Loss: 0.3229
Epoch 3/10, Batch 30/145, Loss: 0.3084
Epoch 3/10, Batch 40/145, Loss: 0.2456
Epoch 3/10, Batch 50/145, Loss: 0.2090
Epoch 3/10, Batch 60/145, Loss: 0.2747
Epoch 3/10, Batch 70/145, Loss: 0.1630
Epoch 3/10, Batch 80/145, Loss: 0.2023
Epoch 3/10, Batch 90/145, Loss: 0.4472
Epoch 3/10, Batch 100/145, Loss: 0.2286
Epoch 3/10, Batch 110/145, Loss: 0.3207
Epoch 3/10, Batch 120/145, Loss: 0.1544
Epoch 3/10, Batch 130/145, Loss: 0.3466
Epoch 3/10, Batch 140/145, Loss: 0.1744
Epoch 3/10, Train Loss: 0.3018, Valid Loss: 0.2536
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2121
Epoch 4/10, Batch 20/145, Loss: 0.1871
Epoch 4/10, Batch 30/145, Loss: 0.1878
Epoch 4/10, Batch 40/145, Loss: 0.2167
Epoch 4/10, Batch 50/145, Loss: 0.3284
Epoch 4/10, Batch 60/145, Loss: 0.2095
Epoch 4/10, Batch 70/145, Loss: 0.1379
Epoch 4/10, Batch 80/145, Loss: 0.3389
Epoch 4/10, Batch 90/145, Loss: 0.3878
Epoch 4/10, Batch 100/145, Loss: 0.2035
Epoch 4/10, Batch 110/145, Loss: 0.2726
Epoch 4/10, Batch 120/145, Loss: 0.1538
Epoch 4/10, Batch 130/145, Loss: 0.2781
Epoch 4/10, Batch 140/145, Loss: 0.3910
Epoch 4/10, Train Loss: 0.2615, Valid Loss: 0.2446
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3449
Epoch 5/10, Batch 20/145, Loss: 0.1478
Epoch 5/10, Batch 30/145, Loss: 0.2275
Epoch 5/10, Batch 40/145, Loss: 0.3326
Epoch 5/10, Batch 50/145, Loss: 0.1399
Epoch 5/10, Batch 60/145, Loss: 0.2351
Epoch 5/10, Batch 70/145, Loss: 0.1866
Epoch 5/10, Batch 80/145, Loss: 0.2656
Epoch 5/10, Batch 90/145, Loss: 0.1145
Epoch 5/10, Batch 100/145, Loss: 0.2703
Epoch 5/10, Batch 110/145, Loss: 0.2695
Epoch 5/10, Batch 120/145, Loss: 0.1537
Epoch 5/10, Batch 130/145, Loss: 0.1690
Epoch 5/10, Batch 140/145, Loss: 0.2741
Epoch 5/10, Train Loss: 0.2337, Valid Loss: 0.2373
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1303
Epoch 6/10, Batch 20/145, Loss: 0.2667
Epoch 6/10, Batch 30/145, Loss: 0.3544
Epoch 6/10, Batch 40/145, Loss: 0.1465
Epoch 6/10, Batch 50/145, Loss: 0.2021
Epoch 6/10, Batch 60/145, Loss: 0.2800
Epoch 6/10, Batch 70/145, Loss: 0.2804
Epoch 6/10, Batch 80/145, Loss: 0.4085
Epoch 6/10, Batch 90/145, Loss: 0.2763
Epoch 6/10, Batch 100/145, Loss: 0.1799
Epoch 6/10, Batch 110/145, Loss: 0.2606
Epoch 6/10, Batch 120/145, Loss: 0.2096
Epoch 6/10, Batch 130/145, Loss: 0.1009
Epoch 6/10, Batch 140/145, Loss: 0.1670
Epoch 6/10, Train Loss: 0.2207, Valid Loss: 0.2325
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2333
Epoch 7/10, Batch 20/145, Loss: 0.1612
Epoch 7/10, Batch 30/145, Loss: 0.2124
Epoch 7/10, Batch 40/145, Loss: 0.4137
Epoch 7/10, Batch 50/145, Loss: 0.1539
Epoch 7/10, Batch 60/145, Loss: 0.2151
Epoch 7/10, Batch 70/145, Loss: 0.1968
Epoch 7/10, Batch 80/145, Loss: 0.1063
Epoch 7/10, Batch 90/145, Loss: 0.0833
Epoch 7/10, Batch 100/145, Loss: 0.1030
Epoch 7/10, Batch 110/145, Loss: 0.2537
Epoch 7/10, Batch 120/145, Loss: 0.0935
Epoch 7/10, Batch 130/145, Loss: 0.3794
Epoch 7/10, Batch 140/145, Loss: 0.1904
Epoch 7/10, Train Loss: 0.2109, Valid Loss: 0.2277
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1153
Epoch 8/10, Batch 20/145, Loss: 0.2601
Epoch 8/10, Batch 30/145, Loss: 0.2599
Epoch 8/10, Batch 40/145, Loss: 0.4219
Epoch 8/10, Batch 50/145, Loss: 0.2183
Epoch 8/10, Batch 60/145, Loss: 0.2952
Epoch 8/10, Batch 70/145, Loss: 0.2025
Epoch 8/10, Batch 80/145, Loss: 0.2338
Epoch 8/10, Batch 90/145, Loss: 0.1677
Epoch 8/10, Batch 100/145, Loss: 0.2078
Epoch 8/10, Batch 110/145, Loss: 0.2031
Epoch 8/10, Batch 120/145, Loss: 0.0372
Epoch 8/10, Batch 130/145, Loss: 0.0894
Epoch 8/10, Batch 140/145, Loss: 0.2300
Epoch 8/10, Train Loss: 0.2078, Valid Loss: 0.2138
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1517
Epoch 9/10, Batch 20/145, Loss: 0.1645
Epoch 9/10, Batch 30/145, Loss: 0.0895
Epoch 9/10, Batch 40/145, Loss: 0.1961
Epoch 9/10, Batch 50/145, Loss: 0.1836
Epoch 9/10, Batch 60/145, Loss: 0.1441
Epoch 9/10, Batch 70/145, Loss: 0.1857
Epoch 9/10, Batch 80/145, Loss: 0.2093
Epoch 9/10, Batch 90/145, Loss: 0.1441
Epoch 9/10, Batch 100/145, Loss: 0.1832
Epoch 9/10, Batch 110/145, Loss: 0.2278
Epoch 9/10, Batch 120/145, Loss: 0.1999
Epoch 9/10, Batch 130/145, Loss: 0.2134
Epoch 9/10, Batch 140/145, Loss: 0.0736
Epoch 9/10, Train Loss: 0.1923, Valid Loss: 0.2117
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0957
Epoch 10/10, Batch 20/145, Loss: 0.1095
Epoch 10/10, Batch 30/145, Loss: 0.1879
Epoch 10/10, Batch 40/145, Loss: 0.1818
Epoch 10/10, Batch 50/145, Loss: 0.2224
Epoch 10/10, Batch 60/145, Loss: 0.1069
Epoch 10/10, Batch 70/145, Loss: 0.1550
Epoch 10/10, Batch 80/145, Loss: 0.4256
Epoch 10/10, Batch 90/145, Loss: 0.1409
Epoch 10/10, Batch 100/145, Loss: 0.0817
Epoch 10/10, Batch 110/145, Loss: 0.2990
Epoch 10/10, Batch 120/145, Loss: 0.3034
Epoch 10/10, Batch 130/145, Loss: 0.1272
Epoch 10/10, Batch 140/145, Loss: 0.1537
Epoch 10/10, Train Loss: 0.1900, Valid Loss: 0.2262
Accuracy: 0.9194
Precision: 0.9166
Recall: 0.9194
F1-score: 0.9174
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4652
Epoch 1/10, Batch 20/145, Loss: 0.9879
Epoch 1/10, Batch 30/145, Loss: 0.8194
Epoch 1/10, Batch 40/145, Loss: 0.7196
Epoch 1/10, Batch 50/145, Loss: 0.6250
Epoch 1/10, Batch 60/145, Loss: 0.5869
Epoch 1/10, Batch 70/145, Loss: 0.5187
Epoch 1/10, Batch 80/145, Loss: 0.5566
Epoch 1/10, Batch 90/145, Loss: 0.4535
Epoch 1/10, Batch 100/145, Loss: 0.5394
Epoch 1/10, Batch 110/145, Loss: 0.4909
Epoch 1/10, Batch 120/145, Loss: 0.6286
Epoch 1/10, Batch 130/145, Loss: 0.4305
Epoch 1/10, Batch 140/145, Loss: 0.5920
Epoch 1/10, Train Loss: 0.6852, Valid Loss: 0.4048
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3757
Epoch 2/10, Batch 20/145, Loss: 0.5226
Epoch 2/10, Batch 30/145, Loss: 0.2680
Epoch 2/10, Batch 40/145, Loss: 0.4538
Epoch 2/10, Batch 50/145, Loss: 0.3568
Epoch 2/10, Batch 60/145, Loss: 0.3614
Epoch 2/10, Batch 70/145, Loss: 0.3811
Epoch 2/10, Batch 80/145, Loss: 0.2269
Epoch 2/10, Batch 90/145, Loss: 0.3692
Epoch 2/10, Batch 100/145, Loss: 0.2806
Epoch 2/10, Batch 110/145, Loss: 0.3005
Epoch 2/10, Batch 120/145, Loss: 0.3608
Epoch 2/10, Batch 130/145, Loss: 0.3182
Epoch 2/10, Batch 140/145, Loss: 0.2011
Epoch 2/10, Train Loss: 0.3578, Valid Loss: 0.3192
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.4717
Epoch 3/10, Batch 20/145, Loss: 0.3247
Epoch 3/10, Batch 30/145, Loss: 0.3576
Epoch 3/10, Batch 40/145, Loss: 0.2319
Epoch 3/10, Batch 50/145, Loss: 0.1765
Epoch 3/10, Batch 60/145, Loss: 0.3736
Epoch 3/10, Batch 70/145, Loss: 0.3185
Epoch 3/10, Batch 80/145, Loss: 0.3394
Epoch 3/10, Batch 90/145, Loss: 0.4174
Epoch 3/10, Batch 100/145, Loss: 0.4136
Epoch 3/10, Batch 110/145, Loss: 0.1739
Epoch 3/10, Batch 120/145, Loss: 0.1461
Epoch 3/10, Batch 130/145, Loss: 0.2653
Epoch 3/10, Batch 140/145, Loss: 0.3210
Epoch 3/10, Train Loss: 0.3014, Valid Loss: 0.2922
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1493
Epoch 4/10, Batch 20/145, Loss: 0.1902
Epoch 4/10, Batch 30/145, Loss: 0.2981
Epoch 4/10, Batch 40/145, Loss: 0.3718
Epoch 4/10, Batch 50/145, Loss: 0.2137
Epoch 4/10, Batch 60/145, Loss: 0.2010
Epoch 4/10, Batch 70/145, Loss: 0.2035
Epoch 4/10, Batch 80/145, Loss: 0.3036
Epoch 4/10, Batch 90/145, Loss: 0.3087
Epoch 4/10, Batch 100/145, Loss: 0.2561
Epoch 4/10, Batch 110/145, Loss: 0.2314
Epoch 4/10, Batch 120/145, Loss: 0.0967
Epoch 4/10, Batch 130/145, Loss: 0.2365
Epoch 4/10, Batch 140/145, Loss: 0.2118
Epoch 4/10, Train Loss: 0.2642, Valid Loss: 0.2866
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1337
Epoch 5/10, Batch 20/145, Loss: 0.1967
Epoch 5/10, Batch 30/145, Loss: 0.2121
Epoch 5/10, Batch 40/145, Loss: 0.1514
Epoch 5/10, Batch 50/145, Loss: 0.1079
Epoch 5/10, Batch 60/145, Loss: 0.2467
Epoch 5/10, Batch 70/145, Loss: 0.2468
Epoch 5/10, Batch 80/145, Loss: 0.2945
Epoch 5/10, Batch 90/145, Loss: 0.1275
Epoch 5/10, Batch 100/145, Loss: 0.2099
Epoch 5/10, Batch 110/145, Loss: 0.2403
Epoch 5/10, Batch 120/145, Loss: 0.2521
Epoch 5/10, Batch 130/145, Loss: 0.1549
Epoch 5/10, Batch 140/145, Loss: 0.0918
Epoch 5/10, Train Loss: 0.2333, Valid Loss: 0.2664
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3061
Epoch 6/10, Batch 20/145, Loss: 0.2563
Epoch 6/10, Batch 30/145, Loss: 0.2084
Epoch 6/10, Batch 40/145, Loss: 0.1298
Epoch 6/10, Batch 50/145, Loss: 0.3405
Epoch 6/10, Batch 60/145, Loss: 0.0981
Epoch 6/10, Batch 70/145, Loss: 0.3697
Epoch 6/10, Batch 80/145, Loss: 0.3098
Epoch 6/10, Batch 90/145, Loss: 0.3488
Epoch 6/10, Batch 100/145, Loss: 0.3316
Epoch 6/10, Batch 110/145, Loss: 0.2363
Epoch 6/10, Batch 120/145, Loss: 0.2914
Epoch 6/10, Batch 130/145, Loss: 0.1750
Epoch 6/10, Batch 140/145, Loss: 0.3008
Epoch 6/10, Train Loss: 0.2228, Valid Loss: 0.2586
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3534
Epoch 7/10, Batch 20/145, Loss: 0.1438
Epoch 7/10, Batch 30/145, Loss: 0.1554
Epoch 7/10, Batch 40/145, Loss: 0.3212
Epoch 7/10, Batch 50/145, Loss: 0.2766
Epoch 7/10, Batch 60/145, Loss: 0.2821
Epoch 7/10, Batch 70/145, Loss: 0.2036
Epoch 7/10, Batch 80/145, Loss: 0.0825
Epoch 7/10, Batch 90/145, Loss: 0.2338
Epoch 7/10, Batch 100/145, Loss: 0.2654
Epoch 7/10, Batch 110/145, Loss: 0.2229
Epoch 7/10, Batch 120/145, Loss: 0.1129
Epoch 7/10, Batch 130/145, Loss: 0.2061
Epoch 7/10, Batch 140/145, Loss: 0.1163
Epoch 7/10, Train Loss: 0.2110, Valid Loss: 0.2565
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1895
Epoch 8/10, Batch 20/145, Loss: 0.0922
Epoch 8/10, Batch 30/145, Loss: 0.1767
Epoch 8/10, Batch 40/145, Loss: 0.1403
Epoch 8/10, Batch 50/145, Loss: 0.1226
Epoch 8/10, Batch 60/145, Loss: 0.2185
Epoch 8/10, Batch 70/145, Loss: 0.0911
Epoch 8/10, Batch 80/145, Loss: 0.1087
Epoch 8/10, Batch 90/145, Loss: 0.1480
Epoch 8/10, Batch 100/145, Loss: 0.3364
Epoch 8/10, Batch 110/145, Loss: 0.2359
Epoch 8/10, Batch 120/145, Loss: 0.1612
Epoch 8/10, Batch 130/145, Loss: 0.1498
Epoch 8/10, Batch 140/145, Loss: 0.2325
Epoch 8/10, Train Loss: 0.2046, Valid Loss: 0.2526
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3019
Epoch 9/10, Batch 20/145, Loss: 0.0618
Epoch 9/10, Batch 30/145, Loss: 0.0916
Epoch 9/10, Batch 40/145, Loss: 0.1884
Epoch 9/10, Batch 50/145, Loss: 0.1085
Epoch 9/10, Batch 60/145, Loss: 0.1641
Epoch 9/10, Batch 70/145, Loss: 0.2362
Epoch 9/10, Batch 80/145, Loss: 0.2949
Epoch 9/10, Batch 90/145, Loss: 0.1153
Epoch 9/10, Batch 100/145, Loss: 0.1208
Epoch 9/10, Batch 110/145, Loss: 0.1228
Epoch 9/10, Batch 120/145, Loss: 0.2247
Epoch 9/10, Batch 130/145, Loss: 0.1629
Epoch 9/10, Batch 140/145, Loss: 0.1046
Epoch 9/10, Train Loss: 0.2032, Valid Loss: 0.2454
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2082
Epoch 10/10, Batch 20/145, Loss: 0.1246
Epoch 10/10, Batch 30/145, Loss: 0.1293
Epoch 10/10, Batch 40/145, Loss: 0.1231
Epoch 10/10, Batch 50/145, Loss: 0.2199
Epoch 10/10, Batch 60/145, Loss: 0.1065
Epoch 10/10, Batch 70/145, Loss: 0.2402
Epoch 10/10, Batch 80/145, Loss: 0.3341
Epoch 10/10, Batch 90/145, Loss: 0.1064
Epoch 10/10, Batch 100/145, Loss: 0.0603
Epoch 10/10, Batch 110/145, Loss: 0.1076
Epoch 10/10, Batch 120/145, Loss: 0.1668
Epoch 10/10, Batch 130/145, Loss: 0.2878
Epoch 10/10, Batch 140/145, Loss: 0.2287
Epoch 10/10, Train Loss: 0.1915, Valid Loss: 0.2378
Model saved!
Accuracy: 0.9276
Precision: 0.9264
Recall: 0.9276
F1-score: 0.9268
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5903
Epoch 1/10, Batch 20/145, Loss: 0.9767
Epoch 1/10, Batch 30/145, Loss: 0.9061
Epoch 1/10, Batch 40/145, Loss: 0.7436
Epoch 1/10, Batch 50/145, Loss: 0.6598
Epoch 1/10, Batch 60/145, Loss: 0.6169
Epoch 1/10, Batch 70/145, Loss: 0.5731
Epoch 1/10, Batch 80/145, Loss: 0.4724
Epoch 1/10, Batch 90/145, Loss: 0.5090
Epoch 1/10, Batch 100/145, Loss: 0.4933
Epoch 1/10, Batch 110/145, Loss: 0.4564
Epoch 1/10, Batch 120/145, Loss: 0.6833
Epoch 1/10, Batch 130/145, Loss: 0.4947
Epoch 1/10, Batch 140/145, Loss: 0.4501
Epoch 1/10, Train Loss: 0.6892, Valid Loss: 0.3583
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2903
Epoch 2/10, Batch 20/145, Loss: 0.6690
Epoch 2/10, Batch 30/145, Loss: 0.3255
Epoch 2/10, Batch 40/145, Loss: 0.4694
Epoch 2/10, Batch 50/145, Loss: 0.2394
Epoch 2/10, Batch 60/145, Loss: 0.4404
Epoch 2/10, Batch 70/145, Loss: 0.2350
Epoch 2/10, Batch 80/145, Loss: 0.3510
Epoch 2/10, Batch 90/145, Loss: 0.2789
Epoch 2/10, Batch 100/145, Loss: 0.2320
Epoch 2/10, Batch 110/145, Loss: 0.3091
Epoch 2/10, Batch 120/145, Loss: 0.4457
Epoch 2/10, Batch 130/145, Loss: 0.2726
Epoch 2/10, Batch 140/145, Loss: 0.4278
Epoch 2/10, Train Loss: 0.3652, Valid Loss: 0.2715
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2135
Epoch 3/10, Batch 20/145, Loss: 0.1967
Epoch 3/10, Batch 30/145, Loss: 0.3178
Epoch 3/10, Batch 40/145, Loss: 0.2907
Epoch 3/10, Batch 50/145, Loss: 0.1845
Epoch 3/10, Batch 60/145, Loss: 0.2026
Epoch 3/10, Batch 70/145, Loss: 0.4027
Epoch 3/10, Batch 80/145, Loss: 0.2548
Epoch 3/10, Batch 90/145, Loss: 0.4245
Epoch 3/10, Batch 100/145, Loss: 0.2968
Epoch 3/10, Batch 110/145, Loss: 0.2939
Epoch 3/10, Batch 120/145, Loss: 0.2063
Epoch 3/10, Batch 130/145, Loss: 0.4440
Epoch 3/10, Batch 140/145, Loss: 0.1984
Epoch 3/10, Train Loss: 0.3070, Valid Loss: 0.2418
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1569
Epoch 4/10, Batch 20/145, Loss: 0.2161
Epoch 4/10, Batch 30/145, Loss: 0.1495
Epoch 4/10, Batch 40/145, Loss: 0.2916
Epoch 4/10, Batch 50/145, Loss: 0.2860
Epoch 4/10, Batch 60/145, Loss: 0.2182
Epoch 4/10, Batch 70/145, Loss: 0.2587
Epoch 4/10, Batch 80/145, Loss: 0.2447
Epoch 4/10, Batch 90/145, Loss: 0.1650
Epoch 4/10, Batch 100/145, Loss: 0.1593
Epoch 4/10, Batch 110/145, Loss: 0.1404
Epoch 4/10, Batch 120/145, Loss: 0.2711
Epoch 4/10, Batch 130/145, Loss: 0.1580
Epoch 4/10, Batch 140/145, Loss: 0.2059
Epoch 4/10, Train Loss: 0.2655, Valid Loss: 0.2273
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1952
Epoch 5/10, Batch 20/145, Loss: 0.3036
Epoch 5/10, Batch 30/145, Loss: 0.2007
Epoch 5/10, Batch 40/145, Loss: 0.2645
Epoch 5/10, Batch 50/145, Loss: 0.1276
Epoch 5/10, Batch 60/145, Loss: 0.2534
Epoch 5/10, Batch 70/145, Loss: 0.3914
Epoch 5/10, Batch 80/145, Loss: 0.2019
Epoch 5/10, Batch 90/145, Loss: 0.3136
Epoch 5/10, Batch 100/145, Loss: 0.1520
Epoch 5/10, Batch 110/145, Loss: 0.1036
Epoch 5/10, Batch 120/145, Loss: 0.1605
Epoch 5/10, Batch 130/145, Loss: 0.2854
Epoch 5/10, Batch 140/145, Loss: 0.1670
Epoch 5/10, Train Loss: 0.2439, Valid Loss: 0.2173
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2431
Epoch 6/10, Batch 20/145, Loss: 0.1599
Epoch 6/10, Batch 30/145, Loss: 0.2999
Epoch 6/10, Batch 40/145, Loss: 0.2149
Epoch 6/10, Batch 50/145, Loss: 0.1658
Epoch 6/10, Batch 60/145, Loss: 0.1568
Epoch 6/10, Batch 70/145, Loss: 0.2795
Epoch 6/10, Batch 80/145, Loss: 0.3573
Epoch 6/10, Batch 90/145, Loss: 0.1795
Epoch 6/10, Batch 100/145, Loss: 0.1394
Epoch 6/10, Batch 110/145, Loss: 0.1274
Epoch 6/10, Batch 120/145, Loss: 0.2780
Epoch 6/10, Batch 130/145, Loss: 0.1527
Epoch 6/10, Batch 140/145, Loss: 0.2924
Epoch 6/10, Train Loss: 0.2308, Valid Loss: 0.2180
Epoch 7/10, Batch 10/145, Loss: 0.2576
Epoch 7/10, Batch 20/145, Loss: 0.1665
Epoch 7/10, Batch 30/145, Loss: 0.1087
Epoch 7/10, Batch 40/145, Loss: 0.3419
Epoch 7/10, Batch 50/145, Loss: 0.1109
Epoch 7/10, Batch 60/145, Loss: 0.2056
Epoch 7/10, Batch 70/145, Loss: 0.1693
Epoch 7/10, Batch 80/145, Loss: 0.2685
Epoch 7/10, Batch 90/145, Loss: 0.2418
Epoch 7/10, Batch 100/145, Loss: 0.1616
Epoch 7/10, Batch 110/145, Loss: 0.2066
Epoch 7/10, Batch 120/145, Loss: 0.1175
Epoch 7/10, Batch 130/145, Loss: 0.2670
Epoch 7/10, Batch 140/145, Loss: 0.2561
Epoch 7/10, Train Loss: 0.2225, Valid Loss: 0.2041
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1706
Epoch 8/10, Batch 20/145, Loss: 0.2395
Epoch 8/10, Batch 30/145, Loss: 0.2025
Epoch 8/10, Batch 40/145, Loss: 0.2311
Epoch 8/10, Batch 50/145, Loss: 0.2721
Epoch 8/10, Batch 60/145, Loss: 0.2020
Epoch 8/10, Batch 70/145, Loss: 0.0656
Epoch 8/10, Batch 80/145, Loss: 0.0773
Epoch 8/10, Batch 90/145, Loss: 0.3313
Epoch 8/10, Batch 100/145, Loss: 0.1957
Epoch 8/10, Batch 110/145, Loss: 0.1462
Epoch 8/10, Batch 120/145, Loss: 0.1421
Epoch 8/10, Batch 130/145, Loss: 0.1832
Epoch 8/10, Batch 140/145, Loss: 0.2131
Epoch 8/10, Train Loss: 0.2126, Valid Loss: 0.1972
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2418
Epoch 9/10, Batch 20/145, Loss: 0.2034
Epoch 9/10, Batch 30/145, Loss: 0.1758
Epoch 9/10, Batch 40/145, Loss: 0.1611
Epoch 9/10, Batch 50/145, Loss: 0.1509
Epoch 9/10, Batch 60/145, Loss: 0.1962
Epoch 9/10, Batch 70/145, Loss: 0.2198
Epoch 9/10, Batch 80/145, Loss: 0.2168
Epoch 9/10, Batch 90/145, Loss: 0.1199
Epoch 9/10, Batch 100/145, Loss: 0.2425
Epoch 9/10, Batch 110/145, Loss: 0.1076
Epoch 9/10, Batch 120/145, Loss: 0.1417
Epoch 9/10, Batch 130/145, Loss: 0.2073
Epoch 9/10, Batch 140/145, Loss: 0.1009
Epoch 9/10, Train Loss: 0.2115, Valid Loss: 0.1931
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2468
Epoch 10/10, Batch 20/145, Loss: 0.0896
Epoch 10/10, Batch 30/145, Loss: 0.1249
Epoch 10/10, Batch 40/145, Loss: 0.3014
Epoch 10/10, Batch 50/145, Loss: 0.2504
Epoch 10/10, Batch 60/145, Loss: 0.1724
Epoch 10/10, Batch 70/145, Loss: 0.1295
Epoch 10/10, Batch 80/145, Loss: 0.5349
Epoch 10/10, Batch 90/145, Loss: 0.1370
Epoch 10/10, Batch 100/145, Loss: 0.1363
Epoch 10/10, Batch 110/145, Loss: 0.1369
Epoch 10/10, Batch 120/145, Loss: 0.1571
Epoch 10/10, Batch 130/145, Loss: 0.2384
Epoch 10/10, Batch 140/145, Loss: 0.2869
Epoch 10/10, Train Loss: 0.1980, Valid Loss: 0.1928
Model saved!
Accuracy: 0.9229
Precision: 0.9221
Recall: 0.9229
F1-score: 0.9225
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5265
Epoch 1/10, Batch 20/145, Loss: 0.8243
Epoch 1/10, Batch 30/145, Loss: 0.9751
Epoch 1/10, Batch 40/145, Loss: 0.7803
Epoch 1/10, Batch 50/145, Loss: 0.7139
Epoch 1/10, Batch 60/145, Loss: 0.4906
Epoch 1/10, Batch 70/145, Loss: 0.6380
Epoch 1/10, Batch 80/145, Loss: 0.4734
Epoch 1/10, Batch 90/145, Loss: 0.4026
Epoch 1/10, Batch 100/145, Loss: 0.7117
Epoch 1/10, Batch 110/145, Loss: 0.3627
Epoch 1/10, Batch 120/145, Loss: 0.6838
Epoch 1/10, Batch 130/145, Loss: 0.3912
Epoch 1/10, Batch 140/145, Loss: 0.3984
Epoch 1/10, Train Loss: 0.6786, Valid Loss: 0.3867
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3246
Epoch 2/10, Batch 20/145, Loss: 0.4466
Epoch 2/10, Batch 30/145, Loss: 0.3079
Epoch 2/10, Batch 40/145, Loss: 0.4304
Epoch 2/10, Batch 50/145, Loss: 0.4165
Epoch 2/10, Batch 60/145, Loss: 0.3795
Epoch 2/10, Batch 70/145, Loss: 0.4138
Epoch 2/10, Batch 80/145, Loss: 0.2761
Epoch 2/10, Batch 90/145, Loss: 0.3486
Epoch 2/10, Batch 100/145, Loss: 0.2678
Epoch 2/10, Batch 110/145, Loss: 0.5289
Epoch 2/10, Batch 120/145, Loss: 0.3774
Epoch 2/10, Batch 130/145, Loss: 0.4335
Epoch 2/10, Batch 140/145, Loss: 0.2312
Epoch 2/10, Train Loss: 0.3588, Valid Loss: 0.2938
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2419
Epoch 3/10, Batch 20/145, Loss: 0.2513
Epoch 3/10, Batch 30/145, Loss: 0.1899
Epoch 3/10, Batch 40/145, Loss: 0.3191
Epoch 3/10, Batch 50/145, Loss: 0.2600
Epoch 3/10, Batch 60/145, Loss: 0.3539
Epoch 3/10, Batch 70/145, Loss: 0.1618
Epoch 3/10, Batch 80/145, Loss: 0.1930
Epoch 3/10, Batch 90/145, Loss: 0.3217
Epoch 3/10, Batch 100/145, Loss: 0.4075
Epoch 3/10, Batch 110/145, Loss: 0.3420
Epoch 3/10, Batch 120/145, Loss: 0.3329
Epoch 3/10, Batch 130/145, Loss: 0.2459
Epoch 3/10, Batch 140/145, Loss: 0.2522
Epoch 3/10, Train Loss: 0.2976, Valid Loss: 0.2636
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1576
Epoch 4/10, Batch 20/145, Loss: 0.1541
Epoch 4/10, Batch 30/145, Loss: 0.2331
Epoch 4/10, Batch 40/145, Loss: 0.3759
Epoch 4/10, Batch 50/145, Loss: 0.1887
Epoch 4/10, Batch 60/145, Loss: 0.2525
Epoch 4/10, Batch 70/145, Loss: 0.1760
Epoch 4/10, Batch 80/145, Loss: 0.4159
Epoch 4/10, Batch 90/145, Loss: 0.2121
Epoch 4/10, Batch 100/145, Loss: 0.1808
Epoch 4/10, Batch 110/145, Loss: 0.2229
Epoch 4/10, Batch 120/145, Loss: 0.3824
Epoch 4/10, Batch 130/145, Loss: 0.3008
Epoch 4/10, Batch 140/145, Loss: 0.1231
Epoch 4/10, Train Loss: 0.2575, Valid Loss: 0.2533
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1870
Epoch 5/10, Batch 20/145, Loss: 0.2795
Epoch 5/10, Batch 30/145, Loss: 0.2604
Epoch 5/10, Batch 40/145, Loss: 0.2447
Epoch 5/10, Batch 50/145, Loss: 0.1331
Epoch 5/10, Batch 60/145, Loss: 0.2665
Epoch 5/10, Batch 70/145, Loss: 0.2029
Epoch 5/10, Batch 80/145, Loss: 0.2800
Epoch 5/10, Batch 90/145, Loss: 0.1457
Epoch 5/10, Batch 100/145, Loss: 0.1473
Epoch 5/10, Batch 110/145, Loss: 0.0940
Epoch 5/10, Batch 120/145, Loss: 0.2364
Epoch 5/10, Batch 130/145, Loss: 0.1787
Epoch 5/10, Batch 140/145, Loss: 0.3543
Epoch 5/10, Train Loss: 0.2258, Valid Loss: 0.2451
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1339
Epoch 6/10, Batch 20/145, Loss: 0.2560
Epoch 6/10, Batch 30/145, Loss: 0.1188
Epoch 6/10, Batch 40/145, Loss: 0.1252
Epoch 6/10, Batch 50/145, Loss: 0.2893
Epoch 6/10, Batch 60/145, Loss: 0.1991
Epoch 6/10, Batch 70/145, Loss: 0.2508
Epoch 6/10, Batch 80/145, Loss: 0.2620
Epoch 6/10, Batch 90/145, Loss: 0.2521
Epoch 6/10, Batch 100/145, Loss: 0.3207
Epoch 6/10, Batch 110/145, Loss: 0.1668
Epoch 6/10, Batch 120/145, Loss: 0.2991
Epoch 6/10, Batch 130/145, Loss: 0.1693
Epoch 6/10, Batch 140/145, Loss: 0.4133
Epoch 6/10, Train Loss: 0.2192, Valid Loss: 0.2512
Epoch 7/10, Batch 10/145, Loss: 0.2058
Epoch 7/10, Batch 20/145, Loss: 0.2708
Epoch 7/10, Batch 30/145, Loss: 0.2862
Epoch 7/10, Batch 40/145, Loss: 0.4471
Epoch 7/10, Batch 50/145, Loss: 0.0854
Epoch 7/10, Batch 60/145, Loss: 0.1888
Epoch 7/10, Batch 70/145, Loss: 0.1869
Epoch 7/10, Batch 80/145, Loss: 0.2066
Epoch 7/10, Batch 90/145, Loss: 0.3357
Epoch 7/10, Batch 100/145, Loss: 0.1302
Epoch 7/10, Batch 110/145, Loss: 0.1780
Epoch 7/10, Batch 120/145, Loss: 0.1332
Epoch 7/10, Batch 130/145, Loss: 0.1351
Epoch 7/10, Batch 140/145, Loss: 0.1344
Epoch 7/10, Train Loss: 0.2024, Valid Loss: 0.2300
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2409
Epoch 8/10, Batch 20/145, Loss: 0.1359
Epoch 8/10, Batch 30/145, Loss: 0.1594
Epoch 8/10, Batch 40/145, Loss: 0.3320
Epoch 8/10, Batch 50/145, Loss: 0.2126
Epoch 8/10, Batch 60/145, Loss: 0.2400
Epoch 8/10, Batch 70/145, Loss: 0.2256
Epoch 8/10, Batch 80/145, Loss: 0.1667
Epoch 8/10, Batch 90/145, Loss: 0.2582
Epoch 8/10, Batch 100/145, Loss: 0.1174
Epoch 8/10, Batch 110/145, Loss: 0.4931
Epoch 8/10, Batch 120/145, Loss: 0.1147
Epoch 8/10, Batch 130/145, Loss: 0.1428
Epoch 8/10, Batch 140/145, Loss: 0.3508
Epoch 8/10, Train Loss: 0.1988, Valid Loss: 0.2241
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1499
Epoch 9/10, Batch 20/145, Loss: 0.1637
Epoch 9/10, Batch 30/145, Loss: 0.0409
Epoch 9/10, Batch 40/145, Loss: 0.2385
Epoch 9/10, Batch 50/145, Loss: 0.1614
Epoch 9/10, Batch 60/145, Loss: 0.1454
Epoch 9/10, Batch 70/145, Loss: 0.1670
Epoch 9/10, Batch 80/145, Loss: 0.2535
Epoch 9/10, Batch 90/145, Loss: 0.1148
Epoch 9/10, Batch 100/145, Loss: 0.2459
Epoch 9/10, Batch 110/145, Loss: 0.2901
Epoch 9/10, Batch 120/145, Loss: 0.2071
Epoch 9/10, Batch 130/145, Loss: 0.2430
Epoch 9/10, Batch 140/145, Loss: 0.2375
Epoch 9/10, Train Loss: 0.1929, Valid Loss: 0.2142
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1938
Epoch 10/10, Batch 20/145, Loss: 0.0849
Epoch 10/10, Batch 30/145, Loss: 0.1176
Epoch 10/10, Batch 40/145, Loss: 0.2291
Epoch 10/10, Batch 50/145, Loss: 0.1311
Epoch 10/10, Batch 60/145, Loss: 0.1422
Epoch 10/10, Batch 70/145, Loss: 0.1877
Epoch 10/10, Batch 80/145, Loss: 0.4179
Epoch 10/10, Batch 90/145, Loss: 0.1417
Epoch 10/10, Batch 100/145, Loss: 0.0775
Epoch 10/10, Batch 110/145, Loss: 0.3349
Epoch 10/10, Batch 120/145, Loss: 0.3385
Epoch 10/10, Batch 130/145, Loss: 0.1726
Epoch 10/10, Batch 140/145, Loss: 0.2990
Epoch 10/10, Train Loss: 0.1872, Valid Loss: 0.2106
Model saved!
Accuracy: 0.9206
Precision: 0.9191
Recall: 0.9206
F1-score: 0.9197
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5514
Epoch 1/10, Batch 20/145, Loss: 0.8825
Epoch 1/10, Batch 30/145, Loss: 0.8619
Epoch 1/10, Batch 40/145, Loss: 0.8551
Epoch 1/10, Batch 50/145, Loss: 0.6283
Epoch 1/10, Batch 60/145, Loss: 0.6424
Epoch 1/10, Batch 70/145, Loss: 0.6327
Epoch 1/10, Batch 80/145, Loss: 0.5258
Epoch 1/10, Batch 90/145, Loss: 0.6202
Epoch 1/10, Batch 100/145, Loss: 0.6572
Epoch 1/10, Batch 110/145, Loss: 0.4981
Epoch 1/10, Batch 120/145, Loss: 0.8072
Epoch 1/10, Batch 130/145, Loss: 0.4932
Epoch 1/10, Batch 140/145, Loss: 0.4090
Epoch 1/10, Train Loss: 0.6877, Valid Loss: 0.3743
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3072
Epoch 2/10, Batch 20/145, Loss: 0.4541
Epoch 2/10, Batch 30/145, Loss: 0.3919
Epoch 2/10, Batch 40/145, Loss: 0.4600
Epoch 2/10, Batch 50/145, Loss: 0.3029
Epoch 2/10, Batch 60/145, Loss: 0.4592
Epoch 2/10, Batch 70/145, Loss: 0.3876
Epoch 2/10, Batch 80/145, Loss: 0.3918
Epoch 2/10, Batch 90/145, Loss: 0.2962
Epoch 2/10, Batch 100/145, Loss: 0.2077
Epoch 2/10, Batch 110/145, Loss: 0.3061
Epoch 2/10, Batch 120/145, Loss: 0.3135
Epoch 2/10, Batch 130/145, Loss: 0.2842
Epoch 2/10, Batch 140/145, Loss: 0.3775
Epoch 2/10, Train Loss: 0.3669, Valid Loss: 0.2871
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2449
Epoch 3/10, Batch 20/145, Loss: 0.1640
Epoch 3/10, Batch 30/145, Loss: 0.1992
Epoch 3/10, Batch 40/145, Loss: 0.2699
Epoch 3/10, Batch 50/145, Loss: 0.2444
Epoch 3/10, Batch 60/145, Loss: 0.2494
Epoch 3/10, Batch 70/145, Loss: 0.2428
Epoch 3/10, Batch 80/145, Loss: 0.2150
Epoch 3/10, Batch 90/145, Loss: 0.7177
Epoch 3/10, Batch 100/145, Loss: 0.2322
Epoch 3/10, Batch 110/145, Loss: 0.2130
Epoch 3/10, Batch 120/145, Loss: 0.1464
Epoch 3/10, Batch 130/145, Loss: 0.1924
Epoch 3/10, Batch 140/145, Loss: 0.1227
Epoch 3/10, Train Loss: 0.3129, Valid Loss: 0.2571
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1606
Epoch 4/10, Batch 20/145, Loss: 0.1554
Epoch 4/10, Batch 30/145, Loss: 0.1734
Epoch 4/10, Batch 40/145, Loss: 0.3201
Epoch 4/10, Batch 50/145, Loss: 0.1975
Epoch 4/10, Batch 60/145, Loss: 0.2842
Epoch 4/10, Batch 70/145, Loss: 0.1969
Epoch 4/10, Batch 80/145, Loss: 0.2166
Epoch 4/10, Batch 90/145, Loss: 0.2689
Epoch 4/10, Batch 100/145, Loss: 0.2405
Epoch 4/10, Batch 110/145, Loss: 0.2889
Epoch 4/10, Batch 120/145, Loss: 0.1776
Epoch 4/10, Batch 130/145, Loss: 0.2408
Epoch 4/10, Batch 140/145, Loss: 0.4165
Epoch 4/10, Train Loss: 0.2695, Valid Loss: 0.2453
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2545
Epoch 5/10, Batch 20/145, Loss: 0.2007
Epoch 5/10, Batch 30/145, Loss: 0.1933
Epoch 5/10, Batch 40/145, Loss: 0.2538
Epoch 5/10, Batch 50/145, Loss: 0.2323
Epoch 5/10, Batch 60/145, Loss: 0.1936
Epoch 5/10, Batch 70/145, Loss: 0.2714
Epoch 5/10, Batch 80/145, Loss: 0.3237
Epoch 5/10, Batch 90/145, Loss: 0.1231
Epoch 5/10, Batch 100/145, Loss: 0.3299
Epoch 5/10, Batch 110/145, Loss: 0.2129
Epoch 5/10, Batch 120/145, Loss: 0.2461
Epoch 5/10, Batch 130/145, Loss: 0.2325
Epoch 5/10, Batch 140/145, Loss: 0.2838
Epoch 5/10, Train Loss: 0.2408, Valid Loss: 0.2263
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3086
Epoch 6/10, Batch 20/145, Loss: 0.3025
Epoch 6/10, Batch 30/145, Loss: 0.2140
Epoch 6/10, Batch 40/145, Loss: 0.1103
Epoch 6/10, Batch 50/145, Loss: 0.2705
Epoch 6/10, Batch 60/145, Loss: 0.1127
Epoch 6/10, Batch 70/145, Loss: 0.2162
Epoch 6/10, Batch 80/145, Loss: 0.4391
Epoch 6/10, Batch 90/145, Loss: 0.2366
Epoch 6/10, Batch 100/145, Loss: 0.2356
Epoch 6/10, Batch 110/145, Loss: 0.1222
Epoch 6/10, Batch 120/145, Loss: 0.3636
Epoch 6/10, Batch 130/145, Loss: 0.1573
Epoch 6/10, Batch 140/145, Loss: 0.1950
Epoch 6/10, Train Loss: 0.2353, Valid Loss: 0.2281
Epoch 7/10, Batch 10/145, Loss: 0.3835
Epoch 7/10, Batch 20/145, Loss: 0.3053
Epoch 7/10, Batch 30/145, Loss: 0.1321
Epoch 7/10, Batch 40/145, Loss: 0.2571
Epoch 7/10, Batch 50/145, Loss: 0.2182
Epoch 7/10, Batch 60/145, Loss: 0.1666
Epoch 7/10, Batch 70/145, Loss: 0.2676
Epoch 7/10, Batch 80/145, Loss: 0.1536
Epoch 7/10, Batch 90/145, Loss: 0.1951
Epoch 7/10, Batch 100/145, Loss: 0.1486
Epoch 7/10, Batch 110/145, Loss: 0.2120
Epoch 7/10, Batch 120/145, Loss: 0.1854
Epoch 7/10, Batch 130/145, Loss: 0.2933
Epoch 7/10, Batch 140/145, Loss: 0.1997
Epoch 7/10, Train Loss: 0.2276, Valid Loss: 0.2174
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2484
Epoch 8/10, Batch 20/145, Loss: 0.1678
Epoch 8/10, Batch 30/145, Loss: 0.1731
Epoch 8/10, Batch 40/145, Loss: 0.1503
Epoch 8/10, Batch 50/145, Loss: 0.2545
Epoch 8/10, Batch 60/145, Loss: 0.1357
Epoch 8/10, Batch 70/145, Loss: 0.1426
Epoch 8/10, Batch 80/145, Loss: 0.4146
Epoch 8/10, Batch 90/145, Loss: 0.1359
Epoch 8/10, Batch 100/145, Loss: 0.4307
Epoch 8/10, Batch 110/145, Loss: 0.2563
Epoch 8/10, Batch 120/145, Loss: 0.2987
Epoch 8/10, Batch 130/145, Loss: 0.1159
Epoch 8/10, Batch 140/145, Loss: 0.3757
Epoch 8/10, Train Loss: 0.2163, Valid Loss: 0.2165
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1316
Epoch 9/10, Batch 20/145, Loss: 0.0896
Epoch 9/10, Batch 30/145, Loss: 0.1254
Epoch 9/10, Batch 40/145, Loss: 0.1915
Epoch 9/10, Batch 50/145, Loss: 0.2593
Epoch 9/10, Batch 60/145, Loss: 0.1742
Epoch 9/10, Batch 70/145, Loss: 0.1796
Epoch 9/10, Batch 80/145, Loss: 0.3943
Epoch 9/10, Batch 90/145, Loss: 0.1349
Epoch 9/10, Batch 100/145, Loss: 0.4213
Epoch 9/10, Batch 110/145, Loss: 0.0859
Epoch 9/10, Batch 120/145, Loss: 0.3307
Epoch 9/10, Batch 130/145, Loss: 0.1877
Epoch 9/10, Batch 140/145, Loss: 0.1743
Epoch 9/10, Train Loss: 0.2038, Valid Loss: 0.2114
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2420
Epoch 10/10, Batch 20/145, Loss: 0.0851
Epoch 10/10, Batch 30/145, Loss: 0.1504
Epoch 10/10, Batch 40/145, Loss: 0.1668
Epoch 10/10, Batch 50/145, Loss: 0.3475
Epoch 10/10, Batch 60/145, Loss: 0.2281
Epoch 10/10, Batch 70/145, Loss: 0.1713
Epoch 10/10, Batch 80/145, Loss: 0.5467
Epoch 10/10, Batch 90/145, Loss: 0.1656
Epoch 10/10, Batch 100/145, Loss: 0.0662
Epoch 10/10, Batch 110/145, Loss: 0.4016
Epoch 10/10, Batch 120/145, Loss: 0.1943
Epoch 10/10, Batch 130/145, Loss: 0.3966
Epoch 10/10, Batch 140/145, Loss: 0.2606
Epoch 10/10, Train Loss: 0.2024, Valid Loss: 0.2113
Model saved!
Accuracy: 0.9264
Precision: 0.9254
Recall: 0.9264
F1-score: 0.9251
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4821
Epoch 1/10, Batch 20/145, Loss: 0.8297
Epoch 1/10, Batch 30/145, Loss: 0.7424
Epoch 1/10, Batch 40/145, Loss: 0.8839
Epoch 1/10, Batch 50/145, Loss: 0.6401
Epoch 1/10, Batch 60/145, Loss: 0.5029
Epoch 1/10, Batch 70/145, Loss: 0.6769
Epoch 1/10, Batch 80/145, Loss: 0.4166
Epoch 1/10, Batch 90/145, Loss: 0.4475
Epoch 1/10, Batch 100/145, Loss: 0.7655
Epoch 1/10, Batch 110/145, Loss: 0.5380
Epoch 1/10, Batch 120/145, Loss: 0.6843
Epoch 1/10, Batch 130/145, Loss: 0.4527
Epoch 1/10, Batch 140/145, Loss: 0.2803
Epoch 1/10, Train Loss: 0.6943, Valid Loss: 0.3601
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3032
Epoch 2/10, Batch 20/145, Loss: 0.3873
Epoch 2/10, Batch 30/145, Loss: 0.3551
Epoch 2/10, Batch 40/145, Loss: 0.5199
Epoch 2/10, Batch 50/145, Loss: 0.2189
Epoch 2/10, Batch 60/145, Loss: 0.4162
Epoch 2/10, Batch 70/145, Loss: 0.3000
Epoch 2/10, Batch 80/145, Loss: 0.3095
Epoch 2/10, Batch 90/145, Loss: 0.3446
Epoch 2/10, Batch 100/145, Loss: 0.3280
Epoch 2/10, Batch 110/145, Loss: 0.2000
Epoch 2/10, Batch 120/145, Loss: 0.4580
Epoch 2/10, Batch 130/145, Loss: 0.3956
Epoch 2/10, Batch 140/145, Loss: 0.1567
Epoch 2/10, Train Loss: 0.3652, Valid Loss: 0.2739
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3186
Epoch 3/10, Batch 20/145, Loss: 0.3682
Epoch 3/10, Batch 30/145, Loss: 0.1939
Epoch 3/10, Batch 40/145, Loss: 0.1847
Epoch 3/10, Batch 50/145, Loss: 0.1650
Epoch 3/10, Batch 60/145, Loss: 0.5716
Epoch 3/10, Batch 70/145, Loss: 0.1189
Epoch 3/10, Batch 80/145, Loss: 0.1915
Epoch 3/10, Batch 90/145, Loss: 0.4354
Epoch 3/10, Batch 100/145, Loss: 0.2641
Epoch 3/10, Batch 110/145, Loss: 0.1596
Epoch 3/10, Batch 120/145, Loss: 0.0963
Epoch 3/10, Batch 130/145, Loss: 0.2842
Epoch 3/10, Batch 140/145, Loss: 0.1302
Epoch 3/10, Train Loss: 0.3123, Valid Loss: 0.2471
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1481
Epoch 4/10, Batch 20/145, Loss: 0.3029
Epoch 4/10, Batch 30/145, Loss: 0.1914
Epoch 4/10, Batch 40/145, Loss: 0.4467
Epoch 4/10, Batch 50/145, Loss: 0.2171
Epoch 4/10, Batch 60/145, Loss: 0.3072
Epoch 4/10, Batch 70/145, Loss: 0.2394
Epoch 4/10, Batch 80/145, Loss: 0.2086
Epoch 4/10, Batch 90/145, Loss: 0.3341
Epoch 4/10, Batch 100/145, Loss: 0.2473
Epoch 4/10, Batch 110/145, Loss: 0.2089
Epoch 4/10, Batch 120/145, Loss: 0.2133
Epoch 4/10, Batch 130/145, Loss: 0.1550
Epoch 4/10, Batch 140/145, Loss: 0.1847
Epoch 4/10, Train Loss: 0.2792, Valid Loss: 0.2322
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1953
Epoch 5/10, Batch 20/145, Loss: 0.2592
Epoch 5/10, Batch 30/145, Loss: 0.1697
Epoch 5/10, Batch 40/145, Loss: 0.1311
Epoch 5/10, Batch 50/145, Loss: 0.1088
Epoch 5/10, Batch 60/145, Loss: 0.3232
Epoch 5/10, Batch 70/145, Loss: 0.2548
Epoch 5/10, Batch 80/145, Loss: 0.4165
Epoch 5/10, Batch 90/145, Loss: 0.2953
Epoch 5/10, Batch 100/145, Loss: 0.3032
Epoch 5/10, Batch 110/145, Loss: 0.1730
Epoch 5/10, Batch 120/145, Loss: 0.2732
Epoch 5/10, Batch 130/145, Loss: 0.1784
Epoch 5/10, Batch 140/145, Loss: 0.2735
Epoch 5/10, Train Loss: 0.2540, Valid Loss: 0.2198
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2495
Epoch 6/10, Batch 20/145, Loss: 0.2505
Epoch 6/10, Batch 30/145, Loss: 0.2346
Epoch 6/10, Batch 40/145, Loss: 0.1268
Epoch 6/10, Batch 50/145, Loss: 0.3302
Epoch 6/10, Batch 60/145, Loss: 0.1797
Epoch 6/10, Batch 70/145, Loss: 0.5383
Epoch 6/10, Batch 80/145, Loss: 0.3062
Epoch 6/10, Batch 90/145, Loss: 0.2327
Epoch 6/10, Batch 100/145, Loss: 0.1173
Epoch 6/10, Batch 110/145, Loss: 0.1457
Epoch 6/10, Batch 120/145, Loss: 0.2327
Epoch 6/10, Batch 130/145, Loss: 0.1284
Epoch 6/10, Batch 140/145, Loss: 0.3038
Epoch 6/10, Train Loss: 0.2402, Valid Loss: 0.2214
Epoch 7/10, Batch 10/145, Loss: 0.3536
Epoch 7/10, Batch 20/145, Loss: 0.3544
Epoch 7/10, Batch 30/145, Loss: 0.2971
Epoch 7/10, Batch 40/145, Loss: 0.4622
Epoch 7/10, Batch 50/145, Loss: 0.1818
Epoch 7/10, Batch 60/145, Loss: 0.2054
Epoch 7/10, Batch 70/145, Loss: 0.2376
Epoch 7/10, Batch 80/145, Loss: 0.2043
Epoch 7/10, Batch 90/145, Loss: 0.3287
Epoch 7/10, Batch 100/145, Loss: 0.1573
Epoch 7/10, Batch 110/145, Loss: 0.2376
Epoch 7/10, Batch 120/145, Loss: 0.1636
Epoch 7/10, Batch 130/145, Loss: 0.2107
Epoch 7/10, Batch 140/145, Loss: 0.1722
Epoch 7/10, Train Loss: 0.2275, Valid Loss: 0.2028
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2036
Epoch 8/10, Batch 20/145, Loss: 0.1668
Epoch 8/10, Batch 30/145, Loss: 0.2661
Epoch 8/10, Batch 40/145, Loss: 0.1908
Epoch 8/10, Batch 50/145, Loss: 0.0860
Epoch 8/10, Batch 60/145, Loss: 0.1914
Epoch 8/10, Batch 70/145, Loss: 0.1517
Epoch 8/10, Batch 80/145, Loss: 0.2796
Epoch 8/10, Batch 90/145, Loss: 0.0903
Epoch 8/10, Batch 100/145, Loss: 0.2120
Epoch 8/10, Batch 110/145, Loss: 0.2602
Epoch 8/10, Batch 120/145, Loss: 0.2043
Epoch 8/10, Batch 130/145, Loss: 0.1261
Epoch 8/10, Batch 140/145, Loss: 0.2137
Epoch 8/10, Train Loss: 0.2168, Valid Loss: 0.2107
Epoch 9/10, Batch 10/145, Loss: 0.4647
Epoch 9/10, Batch 20/145, Loss: 0.2230
Epoch 9/10, Batch 30/145, Loss: 0.1338
Epoch 9/10, Batch 40/145, Loss: 0.2228
Epoch 9/10, Batch 50/145, Loss: 0.2196
Epoch 9/10, Batch 60/145, Loss: 0.2512
Epoch 9/10, Batch 70/145, Loss: 0.2704
Epoch 9/10, Batch 80/145, Loss: 0.2226
Epoch 9/10, Batch 90/145, Loss: 0.1486
Epoch 9/10, Batch 100/145, Loss: 0.2739
Epoch 9/10, Batch 110/145, Loss: 0.1820
Epoch 9/10, Batch 120/145, Loss: 0.1795
Epoch 9/10, Batch 130/145, Loss: 0.2026
Epoch 9/10, Batch 140/145, Loss: 0.0993
Epoch 9/10, Train Loss: 0.2112, Valid Loss: 0.1943
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.3270
Epoch 10/10, Batch 20/145, Loss: 0.1752
Epoch 10/10, Batch 30/145, Loss: 0.0716
Epoch 10/10, Batch 40/145, Loss: 0.2603
Epoch 10/10, Batch 50/145, Loss: 0.3627
Epoch 10/10, Batch 60/145, Loss: 0.3415
Epoch 10/10, Batch 70/145, Loss: 0.1661
Epoch 10/10, Batch 80/145, Loss: 0.4206
Epoch 10/10, Batch 90/145, Loss: 0.2214
Epoch 10/10, Batch 100/145, Loss: 0.1775
Epoch 10/10, Batch 110/145, Loss: 0.4491
Epoch 10/10, Batch 120/145, Loss: 0.2217
Epoch 10/10, Batch 130/145, Loss: 0.1535
Epoch 10/10, Batch 140/145, Loss: 0.2717
Epoch 10/10, Train Loss: 0.2097, Valid Loss: 0.1917
Model saved!
Accuracy: 0.9287
Precision: 0.9269
Recall: 0.9287
F1-score: 0.9276
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5256
Epoch 1/10, Batch 20/145, Loss: 0.9809
Epoch 1/10, Batch 30/145, Loss: 0.8533
Epoch 1/10, Batch 40/145, Loss: 0.8610
Epoch 1/10, Batch 50/145, Loss: 0.5793
Epoch 1/10, Batch 60/145, Loss: 0.5444
Epoch 1/10, Batch 70/145, Loss: 0.6965
Epoch 1/10, Batch 80/145, Loss: 0.5273
Epoch 1/10, Batch 90/145, Loss: 0.5951
Epoch 1/10, Batch 100/145, Loss: 0.6237
Epoch 1/10, Batch 110/145, Loss: 0.4449
Epoch 1/10, Batch 120/145, Loss: 0.6961
Epoch 1/10, Batch 130/145, Loss: 0.3988
Epoch 1/10, Batch 140/145, Loss: 0.3513
Epoch 1/10, Train Loss: 0.6846, Valid Loss: 0.3748
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3054
Epoch 2/10, Batch 20/145, Loss: 0.4635
Epoch 2/10, Batch 30/145, Loss: 0.3136
Epoch 2/10, Batch 40/145, Loss: 0.4872
Epoch 2/10, Batch 50/145, Loss: 0.3875
Epoch 2/10, Batch 60/145, Loss: 0.4500
Epoch 2/10, Batch 70/145, Loss: 0.3859
Epoch 2/10, Batch 80/145, Loss: 0.6977
Epoch 2/10, Batch 90/145, Loss: 0.4158
Epoch 2/10, Batch 100/145, Loss: 0.2949
Epoch 2/10, Batch 110/145, Loss: 0.2958
Epoch 2/10, Batch 120/145, Loss: 0.2806
Epoch 2/10, Batch 130/145, Loss: 0.3910
Epoch 2/10, Batch 140/145, Loss: 0.2203
Epoch 2/10, Train Loss: 0.3629, Valid Loss: 0.2944
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3047
Epoch 3/10, Batch 20/145, Loss: 0.3910
Epoch 3/10, Batch 30/145, Loss: 0.1519
Epoch 3/10, Batch 40/145, Loss: 0.1824
Epoch 3/10, Batch 50/145, Loss: 0.1410
Epoch 3/10, Batch 60/145, Loss: 0.2813
Epoch 3/10, Batch 70/145, Loss: 0.2565
Epoch 3/10, Batch 80/145, Loss: 0.1731
Epoch 3/10, Batch 90/145, Loss: 0.4235
Epoch 3/10, Batch 100/145, Loss: 0.2574
Epoch 3/10, Batch 110/145, Loss: 0.2947
Epoch 3/10, Batch 120/145, Loss: 0.3435
Epoch 3/10, Batch 130/145, Loss: 0.2341
Epoch 3/10, Batch 140/145, Loss: 0.1738
Epoch 3/10, Train Loss: 0.3076, Valid Loss: 0.2613
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2363
Epoch 4/10, Batch 20/145, Loss: 0.2386
Epoch 4/10, Batch 30/145, Loss: 0.3118
Epoch 4/10, Batch 40/145, Loss: 0.3613
Epoch 4/10, Batch 50/145, Loss: 0.1971
Epoch 4/10, Batch 60/145, Loss: 0.1650
Epoch 4/10, Batch 70/145, Loss: 0.3711
Epoch 4/10, Batch 80/145, Loss: 0.3964
Epoch 4/10, Batch 90/145, Loss: 0.2297
Epoch 4/10, Batch 100/145, Loss: 0.2013
Epoch 4/10, Batch 110/145, Loss: 0.2686
Epoch 4/10, Batch 120/145, Loss: 0.1387
Epoch 4/10, Batch 130/145, Loss: 0.1768
Epoch 4/10, Batch 140/145, Loss: 0.1383
Epoch 4/10, Train Loss: 0.2710, Valid Loss: 0.2535
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1990
Epoch 5/10, Batch 20/145, Loss: 0.1164
Epoch 5/10, Batch 30/145, Loss: 0.3145
Epoch 5/10, Batch 40/145, Loss: 0.2309
Epoch 5/10, Batch 50/145, Loss: 0.2157
Epoch 5/10, Batch 60/145, Loss: 0.2218
Epoch 5/10, Batch 70/145, Loss: 0.2050
Epoch 5/10, Batch 80/145, Loss: 0.2477
Epoch 5/10, Batch 90/145, Loss: 0.1310
Epoch 5/10, Batch 100/145, Loss: 0.2305
Epoch 5/10, Batch 110/145, Loss: 0.1001
Epoch 5/10, Batch 120/145, Loss: 0.3191
Epoch 5/10, Batch 130/145, Loss: 0.2671
Epoch 5/10, Batch 140/145, Loss: 0.2291
Epoch 5/10, Train Loss: 0.2371, Valid Loss: 0.2424
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3799
Epoch 6/10, Batch 20/145, Loss: 0.2336
Epoch 6/10, Batch 30/145, Loss: 0.3882
Epoch 6/10, Batch 40/145, Loss: 0.2084
Epoch 6/10, Batch 50/145, Loss: 0.2689
Epoch 6/10, Batch 60/145, Loss: 0.1341
Epoch 6/10, Batch 70/145, Loss: 0.1519
Epoch 6/10, Batch 80/145, Loss: 0.1733
Epoch 6/10, Batch 90/145, Loss: 0.2793
Epoch 6/10, Batch 100/145, Loss: 0.1043
Epoch 6/10, Batch 110/145, Loss: 0.2832
Epoch 6/10, Batch 120/145, Loss: 0.3256
Epoch 6/10, Batch 130/145, Loss: 0.1393
Epoch 6/10, Batch 140/145, Loss: 0.3218
Epoch 6/10, Train Loss: 0.2298, Valid Loss: 0.2387
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2251
Epoch 7/10, Batch 20/145, Loss: 0.2631
Epoch 7/10, Batch 30/145, Loss: 0.1903
Epoch 7/10, Batch 40/145, Loss: 0.2958
Epoch 7/10, Batch 50/145, Loss: 0.1740
Epoch 7/10, Batch 60/145, Loss: 0.1429
Epoch 7/10, Batch 70/145, Loss: 0.2823
Epoch 7/10, Batch 80/145, Loss: 0.1579
Epoch 7/10, Batch 90/145, Loss: 0.2999
Epoch 7/10, Batch 100/145, Loss: 0.4072
Epoch 7/10, Batch 110/145, Loss: 0.2413
Epoch 7/10, Batch 120/145, Loss: 0.1241
Epoch 7/10, Batch 130/145, Loss: 0.2241
Epoch 7/10, Batch 140/145, Loss: 0.1921
Epoch 7/10, Train Loss: 0.2193, Valid Loss: 0.2265
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1925
Epoch 8/10, Batch 20/145, Loss: 0.1328
Epoch 8/10, Batch 30/145, Loss: 0.1657
Epoch 8/10, Batch 40/145, Loss: 0.2647
Epoch 8/10, Batch 50/145, Loss: 0.1473
Epoch 8/10, Batch 60/145, Loss: 0.1052
Epoch 8/10, Batch 70/145, Loss: 0.1388
Epoch 8/10, Batch 80/145, Loss: 0.1822
Epoch 8/10, Batch 90/145, Loss: 0.1639
Epoch 8/10, Batch 100/145, Loss: 0.4456
Epoch 8/10, Batch 110/145, Loss: 0.4339
Epoch 8/10, Batch 120/145, Loss: 0.2792
Epoch 8/10, Batch 130/145, Loss: 0.1416
Epoch 8/10, Batch 140/145, Loss: 0.2288
Epoch 8/10, Train Loss: 0.2073, Valid Loss: 0.2150
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2895
Epoch 9/10, Batch 20/145, Loss: 0.1678
Epoch 9/10, Batch 30/145, Loss: 0.0896
Epoch 9/10, Batch 40/145, Loss: 0.1323
Epoch 9/10, Batch 50/145, Loss: 0.1765
Epoch 9/10, Batch 60/145, Loss: 0.2765
Epoch 9/10, Batch 70/145, Loss: 0.1662
Epoch 9/10, Batch 80/145, Loss: 0.2246
Epoch 9/10, Batch 90/145, Loss: 0.1154
Epoch 9/10, Batch 100/145, Loss: 0.1718
Epoch 9/10, Batch 110/145, Loss: 0.1324
Epoch 9/10, Batch 120/145, Loss: 0.2033
Epoch 9/10, Batch 130/145, Loss: 0.2584
Epoch 9/10, Batch 140/145, Loss: 0.1087
Epoch 9/10, Train Loss: 0.2029, Valid Loss: 0.2086
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2182
Epoch 10/10, Batch 20/145, Loss: 0.2420
Epoch 10/10, Batch 30/145, Loss: 0.1797
Epoch 10/10, Batch 40/145, Loss: 0.1656
Epoch 10/10, Batch 50/145, Loss: 0.4216
Epoch 10/10, Batch 60/145, Loss: 0.2172
Epoch 10/10, Batch 70/145, Loss: 0.1923
Epoch 10/10, Batch 80/145, Loss: 0.3338
Epoch 10/10, Batch 90/145, Loss: 0.1214
Epoch 10/10, Batch 100/145, Loss: 0.1696
Epoch 10/10, Batch 110/145, Loss: 0.1986
Epoch 10/10, Batch 120/145, Loss: 0.4346
Epoch 10/10, Batch 130/145, Loss: 0.1547
Epoch 10/10, Batch 140/145, Loss: 0.3582
Epoch 10/10, Train Loss: 0.1903, Valid Loss: 0.2128
Accuracy: 0.9159
Precision: 0.9174
Recall: 0.9159
F1-score: 0.9142
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4422
Epoch 1/10, Batch 20/145, Loss: 0.9003
Epoch 1/10, Batch 30/145, Loss: 0.8994
Epoch 1/10, Batch 40/145, Loss: 0.8667
Epoch 1/10, Batch 50/145, Loss: 0.6568
Epoch 1/10, Batch 60/145, Loss: 0.5425
Epoch 1/10, Batch 70/145, Loss: 0.7583
Epoch 1/10, Batch 80/145, Loss: 0.5152
Epoch 1/10, Batch 90/145, Loss: 0.6492
Epoch 1/10, Batch 100/145, Loss: 0.7563
Epoch 1/10, Batch 110/145, Loss: 0.3996
Epoch 1/10, Batch 120/145, Loss: 0.5194
Epoch 1/10, Batch 130/145, Loss: 0.3343
Epoch 1/10, Batch 140/145, Loss: 0.5284
Epoch 1/10, Train Loss: 0.6916, Valid Loss: 0.3663
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3663
Epoch 2/10, Batch 20/145, Loss: 0.5407
Epoch 2/10, Batch 30/145, Loss: 0.3245
Epoch 2/10, Batch 40/145, Loss: 0.4394
Epoch 2/10, Batch 50/145, Loss: 0.4434
Epoch 2/10, Batch 60/145, Loss: 0.3734
Epoch 2/10, Batch 70/145, Loss: 0.4126
Epoch 2/10, Batch 80/145, Loss: 0.2159
Epoch 2/10, Batch 90/145, Loss: 0.3070
Epoch 2/10, Batch 100/145, Loss: 0.2165
Epoch 2/10, Batch 110/145, Loss: 0.3698
Epoch 2/10, Batch 120/145, Loss: 0.4060
Epoch 2/10, Batch 130/145, Loss: 0.3936
Epoch 2/10, Batch 140/145, Loss: 0.2748
Epoch 2/10, Train Loss: 0.3659, Valid Loss: 0.2804
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2197
Epoch 3/10, Batch 20/145, Loss: 0.3605
Epoch 3/10, Batch 30/145, Loss: 0.2381
Epoch 3/10, Batch 40/145, Loss: 0.3372
Epoch 3/10, Batch 50/145, Loss: 0.1910
Epoch 3/10, Batch 60/145, Loss: 0.3202
Epoch 3/10, Batch 70/145, Loss: 0.2240
Epoch 3/10, Batch 80/145, Loss: 0.3362
Epoch 3/10, Batch 90/145, Loss: 0.4452
Epoch 3/10, Batch 100/145, Loss: 0.2716
Epoch 3/10, Batch 110/145, Loss: 0.2374
Epoch 3/10, Batch 120/145, Loss: 0.2594
Epoch 3/10, Batch 130/145, Loss: 0.2314
Epoch 3/10, Batch 140/145, Loss: 0.1363
Epoch 3/10, Train Loss: 0.3154, Valid Loss: 0.2568
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2715
Epoch 4/10, Batch 20/145, Loss: 0.1296
Epoch 4/10, Batch 30/145, Loss: 0.2909
Epoch 4/10, Batch 40/145, Loss: 0.4793
Epoch 4/10, Batch 50/145, Loss: 0.3270
Epoch 4/10, Batch 60/145, Loss: 0.3262
Epoch 4/10, Batch 70/145, Loss: 0.2024
Epoch 4/10, Batch 80/145, Loss: 0.3665
Epoch 4/10, Batch 90/145, Loss: 0.2016
Epoch 4/10, Batch 100/145, Loss: 0.2277
Epoch 4/10, Batch 110/145, Loss: 0.1267
Epoch 4/10, Batch 120/145, Loss: 0.1993
Epoch 4/10, Batch 130/145, Loss: 0.1923
Epoch 4/10, Batch 140/145, Loss: 0.1690
Epoch 4/10, Train Loss: 0.2682, Valid Loss: 0.2381
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2680
Epoch 5/10, Batch 20/145, Loss: 0.1544
Epoch 5/10, Batch 30/145, Loss: 0.2434
Epoch 5/10, Batch 40/145, Loss: 0.1755
Epoch 5/10, Batch 50/145, Loss: 0.1836
Epoch 5/10, Batch 60/145, Loss: 0.3401
Epoch 5/10, Batch 70/145, Loss: 0.4689
Epoch 5/10, Batch 80/145, Loss: 0.2892
Epoch 5/10, Batch 90/145, Loss: 0.1702
Epoch 5/10, Batch 100/145, Loss: 0.2941
Epoch 5/10, Batch 110/145, Loss: 0.1630
Epoch 5/10, Batch 120/145, Loss: 0.3462
Epoch 5/10, Batch 130/145, Loss: 0.2890
Epoch 5/10, Batch 140/145, Loss: 0.4482
Epoch 5/10, Train Loss: 0.2519, Valid Loss: 0.2300
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2209
Epoch 6/10, Batch 20/145, Loss: 0.1714
Epoch 6/10, Batch 30/145, Loss: 0.2087
Epoch 6/10, Batch 40/145, Loss: 0.0694
Epoch 6/10, Batch 50/145, Loss: 0.3795
Epoch 6/10, Batch 60/145, Loss: 0.2179
Epoch 6/10, Batch 70/145, Loss: 0.1439
Epoch 6/10, Batch 80/145, Loss: 0.2741
Epoch 6/10, Batch 90/145, Loss: 0.2156
Epoch 6/10, Batch 100/145, Loss: 0.1595
Epoch 6/10, Batch 110/145, Loss: 0.1349
Epoch 6/10, Batch 120/145, Loss: 0.2120
Epoch 6/10, Batch 130/145, Loss: 0.0517
Epoch 6/10, Batch 140/145, Loss: 0.2784
Epoch 6/10, Train Loss: 0.2296, Valid Loss: 0.2267
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3416
Epoch 7/10, Batch 20/145, Loss: 0.1722
Epoch 7/10, Batch 30/145, Loss: 0.1313
Epoch 7/10, Batch 40/145, Loss: 0.5346
Epoch 7/10, Batch 50/145, Loss: 0.2541
Epoch 7/10, Batch 60/145, Loss: 0.2693
Epoch 7/10, Batch 70/145, Loss: 0.1608
Epoch 7/10, Batch 80/145, Loss: 0.1771
Epoch 7/10, Batch 90/145, Loss: 0.2819
Epoch 7/10, Batch 100/145, Loss: 0.2832
Epoch 7/10, Batch 110/145, Loss: 0.2114
Epoch 7/10, Batch 120/145, Loss: 0.3024
Epoch 7/10, Batch 130/145, Loss: 0.1444
Epoch 7/10, Batch 140/145, Loss: 0.2199
Epoch 7/10, Train Loss: 0.2217, Valid Loss: 0.2172
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1537
Epoch 8/10, Batch 20/145, Loss: 0.1268
Epoch 8/10, Batch 30/145, Loss: 0.2755
Epoch 8/10, Batch 40/145, Loss: 0.3330
Epoch 8/10, Batch 50/145, Loss: 0.4163
Epoch 8/10, Batch 60/145, Loss: 0.2507
Epoch 8/10, Batch 70/145, Loss: 0.1863
Epoch 8/10, Batch 80/145, Loss: 0.2361
Epoch 8/10, Batch 90/145, Loss: 0.2403
Epoch 8/10, Batch 100/145, Loss: 0.2040
Epoch 8/10, Batch 110/145, Loss: 0.2683
Epoch 8/10, Batch 120/145, Loss: 0.2165
Epoch 8/10, Batch 130/145, Loss: 0.3011
Epoch 8/10, Batch 140/145, Loss: 0.3335
Epoch 8/10, Train Loss: 0.2238, Valid Loss: 0.2172
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2124
Epoch 9/10, Batch 20/145, Loss: 0.1757
Epoch 9/10, Batch 30/145, Loss: 0.1518
Epoch 9/10, Batch 40/145, Loss: 0.1049
Epoch 9/10, Batch 50/145, Loss: 0.0743
Epoch 9/10, Batch 60/145, Loss: 0.1550
Epoch 9/10, Batch 70/145, Loss: 0.1486
Epoch 9/10, Batch 80/145, Loss: 0.2934
Epoch 9/10, Batch 90/145, Loss: 0.1753
Epoch 9/10, Batch 100/145, Loss: 0.1224
Epoch 9/10, Batch 110/145, Loss: 0.1423
Epoch 9/10, Batch 120/145, Loss: 0.2457
Epoch 9/10, Batch 130/145, Loss: 0.2839
Epoch 9/10, Batch 140/145, Loss: 0.0863
Epoch 9/10, Train Loss: 0.2089, Valid Loss: 0.2075
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2085
Epoch 10/10, Batch 20/145, Loss: 0.1927
Epoch 10/10, Batch 30/145, Loss: 0.2140
Epoch 10/10, Batch 40/145, Loss: 0.2072
Epoch 10/10, Batch 50/145, Loss: 0.3416
Epoch 10/10, Batch 60/145, Loss: 0.0724
Epoch 10/10, Batch 70/145, Loss: 0.1832
Epoch 10/10, Batch 80/145, Loss: 0.3415
Epoch 10/10, Batch 90/145, Loss: 0.1189
Epoch 10/10, Batch 100/145, Loss: 0.1662
Epoch 10/10, Batch 110/145, Loss: 0.1503
Epoch 10/10, Batch 120/145, Loss: 0.0995
Epoch 10/10, Batch 130/145, Loss: 0.1832
Epoch 10/10, Batch 140/145, Loss: 0.2426
Epoch 10/10, Train Loss: 0.1974, Valid Loss: 0.2026
Model saved!
Accuracy: 0.9182
Precision: 0.9168
Recall: 0.9182
F1-score: 0.9170
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4674
Epoch 1/10, Batch 20/145, Loss: 1.0000
Epoch 1/10, Batch 30/145, Loss: 0.8507
Epoch 1/10, Batch 40/145, Loss: 0.7951
Epoch 1/10, Batch 50/145, Loss: 0.6584
Epoch 1/10, Batch 60/145, Loss: 0.5729
Epoch 1/10, Batch 70/145, Loss: 0.5838
Epoch 1/10, Batch 80/145, Loss: 0.5196
Epoch 1/10, Batch 90/145, Loss: 0.6545
Epoch 1/10, Batch 100/145, Loss: 0.4949
Epoch 1/10, Batch 110/145, Loss: 0.4352
Epoch 1/10, Batch 120/145, Loss: 0.4718
Epoch 1/10, Batch 130/145, Loss: 0.4116
Epoch 1/10, Batch 140/145, Loss: 0.3798
Epoch 1/10, Train Loss: 0.6851, Valid Loss: 0.3823
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3374
Epoch 2/10, Batch 20/145, Loss: 0.4416
Epoch 2/10, Batch 30/145, Loss: 0.2412
Epoch 2/10, Batch 40/145, Loss: 0.4346
Epoch 2/10, Batch 50/145, Loss: 0.3648
Epoch 2/10, Batch 60/145, Loss: 0.4164
Epoch 2/10, Batch 70/145, Loss: 0.5474
Epoch 2/10, Batch 80/145, Loss: 0.2490
Epoch 2/10, Batch 90/145, Loss: 0.4104
Epoch 2/10, Batch 100/145, Loss: 0.2265
Epoch 2/10, Batch 110/145, Loss: 0.1937
Epoch 2/10, Batch 120/145, Loss: 0.3660
Epoch 2/10, Batch 130/145, Loss: 0.3407
Epoch 2/10, Batch 140/145, Loss: 0.2940
Epoch 2/10, Train Loss: 0.3609, Valid Loss: 0.2921
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1423
Epoch 3/10, Batch 20/145, Loss: 0.2118
Epoch 3/10, Batch 30/145, Loss: 0.1944
Epoch 3/10, Batch 40/145, Loss: 0.5995
Epoch 3/10, Batch 50/145, Loss: 0.1965
Epoch 3/10, Batch 60/145, Loss: 0.2351
Epoch 3/10, Batch 70/145, Loss: 0.0972
Epoch 3/10, Batch 80/145, Loss: 0.3206
Epoch 3/10, Batch 90/145, Loss: 0.4472
Epoch 3/10, Batch 100/145, Loss: 0.2627
Epoch 3/10, Batch 110/145, Loss: 0.2362
Epoch 3/10, Batch 120/145, Loss: 0.3095
Epoch 3/10, Batch 130/145, Loss: 0.3362
Epoch 3/10, Batch 140/145, Loss: 0.1582
Epoch 3/10, Train Loss: 0.3101, Valid Loss: 0.2662
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3058
Epoch 4/10, Batch 20/145, Loss: 0.3349
Epoch 4/10, Batch 30/145, Loss: 0.3769
Epoch 4/10, Batch 40/145, Loss: 0.3238
Epoch 4/10, Batch 50/145, Loss: 0.3702
Epoch 4/10, Batch 60/145, Loss: 0.1192
Epoch 4/10, Batch 70/145, Loss: 0.4680
Epoch 4/10, Batch 80/145, Loss: 0.2312
Epoch 4/10, Batch 90/145, Loss: 0.2633
Epoch 4/10, Batch 100/145, Loss: 0.2094
Epoch 4/10, Batch 110/145, Loss: 0.2236
Epoch 4/10, Batch 120/145, Loss: 0.2250
Epoch 4/10, Batch 130/145, Loss: 0.2009
Epoch 4/10, Batch 140/145, Loss: 0.2683
Epoch 4/10, Train Loss: 0.2623, Valid Loss: 0.2586
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2408
Epoch 5/10, Batch 20/145, Loss: 0.2196
Epoch 5/10, Batch 30/145, Loss: 0.2059
Epoch 5/10, Batch 40/145, Loss: 0.3528
Epoch 5/10, Batch 50/145, Loss: 0.2238
Epoch 5/10, Batch 60/145, Loss: 0.2045
Epoch 5/10, Batch 70/145, Loss: 0.2133
Epoch 5/10, Batch 80/145, Loss: 0.4409
Epoch 5/10, Batch 90/145, Loss: 0.2189
Epoch 5/10, Batch 100/145, Loss: 0.1555
Epoch 5/10, Batch 110/145, Loss: 0.1400
Epoch 5/10, Batch 120/145, Loss: 0.2734
Epoch 5/10, Batch 130/145, Loss: 0.1769
Epoch 5/10, Batch 140/145, Loss: 0.2400
Epoch 5/10, Train Loss: 0.2417, Valid Loss: 0.2406
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3070
Epoch 6/10, Batch 20/145, Loss: 0.2636
Epoch 6/10, Batch 30/145, Loss: 0.2443
Epoch 6/10, Batch 40/145, Loss: 0.3027
Epoch 6/10, Batch 50/145, Loss: 0.4112
Epoch 6/10, Batch 60/145, Loss: 0.1685
Epoch 6/10, Batch 70/145, Loss: 0.3219
Epoch 6/10, Batch 80/145, Loss: 0.2300
Epoch 6/10, Batch 90/145, Loss: 0.2108
Epoch 6/10, Batch 100/145, Loss: 0.4286
Epoch 6/10, Batch 110/145, Loss: 0.1898
Epoch 6/10, Batch 120/145, Loss: 0.2507
Epoch 6/10, Batch 130/145, Loss: 0.1522
Epoch 6/10, Batch 140/145, Loss: 0.2476
Epoch 6/10, Train Loss: 0.2274, Valid Loss: 0.2356
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2541
Epoch 7/10, Batch 20/145, Loss: 0.1547
Epoch 7/10, Batch 30/145, Loss: 0.1553
Epoch 7/10, Batch 40/145, Loss: 0.3706
Epoch 7/10, Batch 50/145, Loss: 0.1810
Epoch 7/10, Batch 60/145, Loss: 0.1608
Epoch 7/10, Batch 70/145, Loss: 0.2111
Epoch 7/10, Batch 80/145, Loss: 0.2737
Epoch 7/10, Batch 90/145, Loss: 0.1327
Epoch 7/10, Batch 100/145, Loss: 0.2460
Epoch 7/10, Batch 110/145, Loss: 0.3241
Epoch 7/10, Batch 120/145, Loss: 0.2083
Epoch 7/10, Batch 130/145, Loss: 0.2873
Epoch 7/10, Batch 140/145, Loss: 0.1780
Epoch 7/10, Train Loss: 0.2176, Valid Loss: 0.2353
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1927
Epoch 8/10, Batch 20/145, Loss: 0.1233
Epoch 8/10, Batch 30/145, Loss: 0.2110
Epoch 8/10, Batch 40/145, Loss: 0.2250
Epoch 8/10, Batch 50/145, Loss: 0.1489
Epoch 8/10, Batch 60/145, Loss: 0.1814
Epoch 8/10, Batch 70/145, Loss: 0.1658
Epoch 8/10, Batch 80/145, Loss: 0.2021
Epoch 8/10, Batch 90/145, Loss: 0.1751
Epoch 8/10, Batch 100/145, Loss: 0.2287
Epoch 8/10, Batch 110/145, Loss: 0.2684
Epoch 8/10, Batch 120/145, Loss: 0.1379
Epoch 8/10, Batch 130/145, Loss: 0.1836
Epoch 8/10, Batch 140/145, Loss: 0.3339
Epoch 8/10, Train Loss: 0.2033, Valid Loss: 0.2280
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1836
Epoch 9/10, Batch 20/145, Loss: 0.2368
Epoch 9/10, Batch 30/145, Loss: 0.1754
Epoch 9/10, Batch 40/145, Loss: 0.2333
Epoch 9/10, Batch 50/145, Loss: 0.2325
Epoch 9/10, Batch 60/145, Loss: 0.2148
Epoch 9/10, Batch 70/145, Loss: 0.1899
Epoch 9/10, Batch 80/145, Loss: 0.3287
Epoch 9/10, Batch 90/145, Loss: 0.2406
Epoch 9/10, Batch 100/145, Loss: 0.1696
Epoch 9/10, Batch 110/145, Loss: 0.0704
Epoch 9/10, Batch 120/145, Loss: 0.2166
Epoch 9/10, Batch 130/145, Loss: 0.2011
Epoch 9/10, Batch 140/145, Loss: 0.2987
Epoch 9/10, Train Loss: 0.2063, Valid Loss: 0.2241
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1640
Epoch 10/10, Batch 20/145, Loss: 0.2075
Epoch 10/10, Batch 30/145, Loss: 0.2447
Epoch 10/10, Batch 40/145, Loss: 0.2364
Epoch 10/10, Batch 50/145, Loss: 0.2746
Epoch 10/10, Batch 60/145, Loss: 0.2222
Epoch 10/10, Batch 70/145, Loss: 0.2603
Epoch 10/10, Batch 80/145, Loss: 0.3329
Epoch 10/10, Batch 90/145, Loss: 0.1470
Epoch 10/10, Batch 100/145, Loss: 0.1033
Epoch 10/10, Batch 110/145, Loss: 0.1490
Epoch 10/10, Batch 120/145, Loss: 0.1956
Epoch 10/10, Batch 130/145, Loss: 0.1915
Epoch 10/10, Batch 140/145, Loss: 0.2482
Epoch 10/10, Train Loss: 0.1884, Valid Loss: 0.2220
Model saved!
Accuracy: 0.9264
Precision: 0.9259
Recall: 0.9264
F1-score: 0.9258
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4688
Epoch 1/10, Batch 20/145, Loss: 0.9744
Epoch 1/10, Batch 30/145, Loss: 0.7740
Epoch 1/10, Batch 40/145, Loss: 0.9411
Epoch 1/10, Batch 50/145, Loss: 0.6567
Epoch 1/10, Batch 60/145, Loss: 0.6200
Epoch 1/10, Batch 70/145, Loss: 0.7021
Epoch 1/10, Batch 80/145, Loss: 0.4944
Epoch 1/10, Batch 90/145, Loss: 0.5777
Epoch 1/10, Batch 100/145, Loss: 0.6807
Epoch 1/10, Batch 110/145, Loss: 0.3949
Epoch 1/10, Batch 120/145, Loss: 0.4858
Epoch 1/10, Batch 130/145, Loss: 0.4561
Epoch 1/10, Batch 140/145, Loss: 0.4382
Epoch 1/10, Train Loss: 0.6966, Valid Loss: 0.3763
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.5184
Epoch 2/10, Batch 20/145, Loss: 0.3537
Epoch 2/10, Batch 30/145, Loss: 0.5163
Epoch 2/10, Batch 40/145, Loss: 0.4410
Epoch 2/10, Batch 50/145, Loss: 0.3172
Epoch 2/10, Batch 60/145, Loss: 0.4777
Epoch 2/10, Batch 70/145, Loss: 0.2794
Epoch 2/10, Batch 80/145, Loss: 0.4065
Epoch 2/10, Batch 90/145, Loss: 0.3351
Epoch 2/10, Batch 100/145, Loss: 0.3416
Epoch 2/10, Batch 110/145, Loss: 0.2143
Epoch 2/10, Batch 120/145, Loss: 0.3668
Epoch 2/10, Batch 130/145, Loss: 0.4183
Epoch 2/10, Batch 140/145, Loss: 0.3231
Epoch 2/10, Train Loss: 0.3683, Valid Loss: 0.2862
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2512
Epoch 3/10, Batch 20/145, Loss: 0.3657
Epoch 3/10, Batch 30/145, Loss: 0.2061
Epoch 3/10, Batch 40/145, Loss: 0.4527
Epoch 3/10, Batch 50/145, Loss: 0.2058
Epoch 3/10, Batch 60/145, Loss: 0.3633
Epoch 3/10, Batch 70/145, Loss: 0.1593
Epoch 3/10, Batch 80/145, Loss: 0.3082
Epoch 3/10, Batch 90/145, Loss: 0.5729
Epoch 3/10, Batch 100/145, Loss: 0.4650
Epoch 3/10, Batch 110/145, Loss: 0.1711
Epoch 3/10, Batch 120/145, Loss: 0.1426
Epoch 3/10, Batch 130/145, Loss: 0.4533
Epoch 3/10, Batch 140/145, Loss: 0.1422
Epoch 3/10, Train Loss: 0.3136, Valid Loss: 0.2523
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3682
Epoch 4/10, Batch 20/145, Loss: 0.2415
Epoch 4/10, Batch 30/145, Loss: 0.1040
Epoch 4/10, Batch 40/145, Loss: 0.3740
Epoch 4/10, Batch 50/145, Loss: 0.1952
Epoch 4/10, Batch 60/145, Loss: 0.2313
Epoch 4/10, Batch 70/145, Loss: 0.1803
Epoch 4/10, Batch 80/145, Loss: 0.2873
Epoch 4/10, Batch 90/145, Loss: 0.2267
Epoch 4/10, Batch 100/145, Loss: 0.2972
Epoch 4/10, Batch 110/145, Loss: 0.1880
Epoch 4/10, Batch 120/145, Loss: 0.1432
Epoch 4/10, Batch 130/145, Loss: 0.1336
Epoch 4/10, Batch 140/145, Loss: 0.2333
Epoch 4/10, Train Loss: 0.2693, Valid Loss: 0.2480
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1461
Epoch 5/10, Batch 20/145, Loss: 0.2838
Epoch 5/10, Batch 30/145, Loss: 0.2077
Epoch 5/10, Batch 40/145, Loss: 0.3139
Epoch 5/10, Batch 50/145, Loss: 0.2577
Epoch 5/10, Batch 60/145, Loss: 0.2539
Epoch 5/10, Batch 70/145, Loss: 0.1538
Epoch 5/10, Batch 80/145, Loss: 0.3301
Epoch 5/10, Batch 90/145, Loss: 0.2056
Epoch 5/10, Batch 100/145, Loss: 0.2066
Epoch 5/10, Batch 110/145, Loss: 0.1652
Epoch 5/10, Batch 120/145, Loss: 0.1565
Epoch 5/10, Batch 130/145, Loss: 0.3245
Epoch 5/10, Batch 140/145, Loss: 0.2210
Epoch 5/10, Train Loss: 0.2425, Valid Loss: 0.2330
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1539
Epoch 6/10, Batch 20/145, Loss: 0.2416
Epoch 6/10, Batch 30/145, Loss: 0.4219
Epoch 6/10, Batch 40/145, Loss: 0.1995
Epoch 6/10, Batch 50/145, Loss: 0.2520
Epoch 6/10, Batch 60/145, Loss: 0.1446
Epoch 6/10, Batch 70/145, Loss: 0.2405
Epoch 6/10, Batch 80/145, Loss: 0.2467
Epoch 6/10, Batch 90/145, Loss: 0.1655
Epoch 6/10, Batch 100/145, Loss: 0.3089
Epoch 6/10, Batch 110/145, Loss: 0.2297
Epoch 6/10, Batch 120/145, Loss: 0.3144
Epoch 6/10, Batch 130/145, Loss: 0.2287
Epoch 6/10, Batch 140/145, Loss: 0.1966
Epoch 6/10, Train Loss: 0.2333, Valid Loss: 0.2148
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2253
Epoch 7/10, Batch 20/145, Loss: 0.2680
Epoch 7/10, Batch 30/145, Loss: 0.1933
Epoch 7/10, Batch 40/145, Loss: 0.4881
Epoch 7/10, Batch 50/145, Loss: 0.2383
Epoch 7/10, Batch 60/145, Loss: 0.1182
Epoch 7/10, Batch 70/145, Loss: 0.2083
Epoch 7/10, Batch 80/145, Loss: 0.1520
Epoch 7/10, Batch 90/145, Loss: 0.3178
Epoch 7/10, Batch 100/145, Loss: 0.1226
Epoch 7/10, Batch 110/145, Loss: 0.2692
Epoch 7/10, Batch 120/145, Loss: 0.1719
Epoch 7/10, Batch 130/145, Loss: 0.1851
Epoch 7/10, Batch 140/145, Loss: 0.1714
Epoch 7/10, Train Loss: 0.2240, Valid Loss: 0.2160
Epoch 8/10, Batch 10/145, Loss: 0.1896
Epoch 8/10, Batch 20/145, Loss: 0.1649
Epoch 8/10, Batch 30/145, Loss: 0.2522
Epoch 8/10, Batch 40/145, Loss: 0.2792
Epoch 8/10, Batch 50/145, Loss: 0.3926
Epoch 8/10, Batch 60/145, Loss: 0.1038
Epoch 8/10, Batch 70/145, Loss: 0.1888
Epoch 8/10, Batch 80/145, Loss: 0.1025
Epoch 8/10, Batch 90/145, Loss: 0.1398
Epoch 8/10, Batch 100/145, Loss: 0.4008
Epoch 8/10, Batch 110/145, Loss: 0.3697
Epoch 8/10, Batch 120/145, Loss: 0.2606
Epoch 8/10, Batch 130/145, Loss: 0.1225
Epoch 8/10, Batch 140/145, Loss: 0.3556
Epoch 8/10, Train Loss: 0.2172, Valid Loss: 0.2150
Epoch 9/10, Batch 10/145, Loss: 0.2129
Epoch 9/10, Batch 20/145, Loss: 0.2337
Epoch 9/10, Batch 30/145, Loss: 0.0846
Epoch 9/10, Batch 40/145, Loss: 0.2372
Epoch 9/10, Batch 50/145, Loss: 0.1531
Epoch 9/10, Batch 60/145, Loss: 0.2250
Epoch 9/10, Batch 70/145, Loss: 0.1536
Epoch 9/10, Batch 80/145, Loss: 0.2478
Epoch 9/10, Batch 90/145, Loss: 0.1753
Epoch 9/10, Batch 100/145, Loss: 0.2114
Epoch 9/10, Batch 110/145, Loss: 0.2224
Epoch 9/10, Batch 120/145, Loss: 0.1193
Epoch 9/10, Batch 130/145, Loss: 0.1427
Epoch 9/10, Batch 140/145, Loss: 0.0991
Epoch 9/10, Train Loss: 0.2034, Valid Loss: 0.2045
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1803
Epoch 10/10, Batch 20/145, Loss: 0.1940
Epoch 10/10, Batch 30/145, Loss: 0.0542
Epoch 10/10, Batch 40/145, Loss: 0.2639
Epoch 10/10, Batch 50/145, Loss: 0.1649
Epoch 10/10, Batch 60/145, Loss: 0.3305
Epoch 10/10, Batch 70/145, Loss: 0.1910
Epoch 10/10, Batch 80/145, Loss: 0.4398
Epoch 10/10, Batch 90/145, Loss: 0.2298
Epoch 10/10, Batch 100/145, Loss: 0.2265
Epoch 10/10, Batch 110/145, Loss: 0.2363
Epoch 10/10, Batch 120/145, Loss: 0.2331
Epoch 10/10, Batch 130/145, Loss: 0.2956
Epoch 10/10, Batch 140/145, Loss: 0.2829
Epoch 10/10, Train Loss: 0.2003, Valid Loss: 0.2048
Accuracy: 0.9276
Precision: 0.9254
Recall: 0.9276
F1-score: 0.9263
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5342
Epoch 1/10, Batch 20/145, Loss: 0.8700
Epoch 1/10, Batch 30/145, Loss: 0.8697
Epoch 1/10, Batch 40/145, Loss: 0.7857
Epoch 1/10, Batch 50/145, Loss: 0.6239
Epoch 1/10, Batch 60/145, Loss: 0.6056
Epoch 1/10, Batch 70/145, Loss: 0.5860
Epoch 1/10, Batch 80/145, Loss: 0.5092
Epoch 1/10, Batch 90/145, Loss: 0.5322
Epoch 1/10, Batch 100/145, Loss: 0.5580
Epoch 1/10, Batch 110/145, Loss: 0.4220
Epoch 1/10, Batch 120/145, Loss: 0.5659
Epoch 1/10, Batch 130/145, Loss: 0.3965
Epoch 1/10, Batch 140/145, Loss: 0.5411
Epoch 1/10, Train Loss: 0.6844, Valid Loss: 0.3925
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2569
Epoch 2/10, Batch 20/145, Loss: 0.5911
Epoch 2/10, Batch 30/145, Loss: 0.3679
Epoch 2/10, Batch 40/145, Loss: 0.5011
Epoch 2/10, Batch 50/145, Loss: 0.3809
Epoch 2/10, Batch 60/145, Loss: 0.3496
Epoch 2/10, Batch 70/145, Loss: 0.3509
Epoch 2/10, Batch 80/145, Loss: 0.2082
Epoch 2/10, Batch 90/145, Loss: 0.3553
Epoch 2/10, Batch 100/145, Loss: 0.4392
Epoch 2/10, Batch 110/145, Loss: 0.4036
Epoch 2/10, Batch 120/145, Loss: 0.4159
Epoch 2/10, Batch 130/145, Loss: 0.3016
Epoch 2/10, Batch 140/145, Loss: 0.2284
Epoch 2/10, Train Loss: 0.3625, Valid Loss: 0.3127
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3141
Epoch 3/10, Batch 20/145, Loss: 0.3106
Epoch 3/10, Batch 30/145, Loss: 0.1986
Epoch 3/10, Batch 40/145, Loss: 0.2830
Epoch 3/10, Batch 50/145, Loss: 0.3070
Epoch 3/10, Batch 60/145, Loss: 0.3007
Epoch 3/10, Batch 70/145, Loss: 0.3203
Epoch 3/10, Batch 80/145, Loss: 0.3180
Epoch 3/10, Batch 90/145, Loss: 0.5428
Epoch 3/10, Batch 100/145, Loss: 0.2112
Epoch 3/10, Batch 110/145, Loss: 0.2047
Epoch 3/10, Batch 120/145, Loss: 0.1925
Epoch 3/10, Batch 130/145, Loss: 0.1928
Epoch 3/10, Batch 140/145, Loss: 0.1840
Epoch 3/10, Train Loss: 0.3037, Valid Loss: 0.2703
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3918
Epoch 4/10, Batch 20/145, Loss: 0.2972
Epoch 4/10, Batch 30/145, Loss: 0.2238
Epoch 4/10, Batch 40/145, Loss: 0.3685
Epoch 4/10, Batch 50/145, Loss: 0.2655
Epoch 4/10, Batch 60/145, Loss: 0.2293
Epoch 4/10, Batch 70/145, Loss: 0.1625
Epoch 4/10, Batch 80/145, Loss: 0.2373
Epoch 4/10, Batch 90/145, Loss: 0.2791
Epoch 4/10, Batch 100/145, Loss: 0.1964
Epoch 4/10, Batch 110/145, Loss: 0.2497
Epoch 4/10, Batch 120/145, Loss: 0.3165
Epoch 4/10, Batch 130/145, Loss: 0.1986
Epoch 4/10, Batch 140/145, Loss: 0.2320
Epoch 4/10, Train Loss: 0.2656, Valid Loss: 0.2662
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2576
Epoch 5/10, Batch 20/145, Loss: 0.2411
Epoch 5/10, Batch 30/145, Loss: 0.2226
Epoch 5/10, Batch 40/145, Loss: 0.2502
Epoch 5/10, Batch 50/145, Loss: 0.1639
Epoch 5/10, Batch 60/145, Loss: 0.4679
Epoch 5/10, Batch 70/145, Loss: 0.2266
Epoch 5/10, Batch 80/145, Loss: 0.2264
Epoch 5/10, Batch 90/145, Loss: 0.1460
Epoch 5/10, Batch 100/145, Loss: 0.3699
Epoch 5/10, Batch 110/145, Loss: 0.1599
Epoch 5/10, Batch 120/145, Loss: 0.1129
Epoch 5/10, Batch 130/145, Loss: 0.1341
Epoch 5/10, Batch 140/145, Loss: 0.4032
Epoch 5/10, Train Loss: 0.2455, Valid Loss: 0.2523
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2052
Epoch 6/10, Batch 20/145, Loss: 0.1409
Epoch 6/10, Batch 30/145, Loss: 0.2319
Epoch 6/10, Batch 40/145, Loss: 0.0886
Epoch 6/10, Batch 50/145, Loss: 0.3444
Epoch 6/10, Batch 60/145, Loss: 0.1903
Epoch 6/10, Batch 70/145, Loss: 0.2043
Epoch 6/10, Batch 80/145, Loss: 0.4148
Epoch 6/10, Batch 90/145, Loss: 0.3547
Epoch 6/10, Batch 100/145, Loss: 0.1427
Epoch 6/10, Batch 110/145, Loss: 0.1677
Epoch 6/10, Batch 120/145, Loss: 0.2444
Epoch 6/10, Batch 130/145, Loss: 0.1423
Epoch 6/10, Batch 140/145, Loss: 0.1504
Epoch 6/10, Train Loss: 0.2284, Valid Loss: 0.2335
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2184
Epoch 7/10, Batch 20/145, Loss: 0.1724
Epoch 7/10, Batch 30/145, Loss: 0.1217
Epoch 7/10, Batch 40/145, Loss: 0.4330
Epoch 7/10, Batch 50/145, Loss: 0.2860
Epoch 7/10, Batch 60/145, Loss: 0.0925
Epoch 7/10, Batch 70/145, Loss: 0.2582
Epoch 7/10, Batch 80/145, Loss: 0.2462
Epoch 7/10, Batch 90/145, Loss: 0.2234
Epoch 7/10, Batch 100/145, Loss: 0.3042
Epoch 7/10, Batch 110/145, Loss: 0.2336
Epoch 7/10, Batch 120/145, Loss: 0.1883
Epoch 7/10, Batch 130/145, Loss: 0.1941
Epoch 7/10, Batch 140/145, Loss: 0.1248
Epoch 7/10, Train Loss: 0.2197, Valid Loss: 0.2260
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1852
Epoch 8/10, Batch 20/145, Loss: 0.0892
Epoch 8/10, Batch 30/145, Loss: 0.1243
Epoch 8/10, Batch 40/145, Loss: 0.1527
Epoch 8/10, Batch 50/145, Loss: 0.1911
Epoch 8/10, Batch 60/145, Loss: 0.1665
Epoch 8/10, Batch 70/145, Loss: 0.1522
Epoch 8/10, Batch 80/145, Loss: 0.2860
Epoch 8/10, Batch 90/145, Loss: 0.1587
Epoch 8/10, Batch 100/145, Loss: 0.2320
Epoch 8/10, Batch 110/145, Loss: 0.1884
Epoch 8/10, Batch 120/145, Loss: 0.4107
Epoch 8/10, Batch 130/145, Loss: 0.0699
Epoch 8/10, Batch 140/145, Loss: 0.2707
Epoch 8/10, Train Loss: 0.2077, Valid Loss: 0.2243
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1903
Epoch 9/10, Batch 20/145, Loss: 0.2031
Epoch 9/10, Batch 30/145, Loss: 0.1281
Epoch 9/10, Batch 40/145, Loss: 0.2184
Epoch 9/10, Batch 50/145, Loss: 0.1039
Epoch 9/10, Batch 60/145, Loss: 0.1437
Epoch 9/10, Batch 70/145, Loss: 0.3201
Epoch 9/10, Batch 80/145, Loss: 0.3458
Epoch 9/10, Batch 90/145, Loss: 0.1630
Epoch 9/10, Batch 100/145, Loss: 0.2822
Epoch 9/10, Batch 110/145, Loss: 0.1679
Epoch 9/10, Batch 120/145, Loss: 0.1813
Epoch 9/10, Batch 130/145, Loss: 0.2663
Epoch 9/10, Batch 140/145, Loss: 0.1196
Epoch 9/10, Train Loss: 0.2009, Valid Loss: 0.2167
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2292
Epoch 10/10, Batch 20/145, Loss: 0.1333
Epoch 10/10, Batch 30/145, Loss: 0.1702
Epoch 10/10, Batch 40/145, Loss: 0.1190
Epoch 10/10, Batch 50/145, Loss: 0.3466
Epoch 10/10, Batch 60/145, Loss: 0.1989
Epoch 10/10, Batch 70/145, Loss: 0.0937
Epoch 10/10, Batch 80/145, Loss: 0.4749
Epoch 10/10, Batch 90/145, Loss: 0.2865
Epoch 10/10, Batch 100/145, Loss: 0.0909
Epoch 10/10, Batch 110/145, Loss: 0.2534
Epoch 10/10, Batch 120/145, Loss: 0.1719
Epoch 10/10, Batch 130/145, Loss: 0.2688
Epoch 10/10, Batch 140/145, Loss: 0.2781
Epoch 10/10, Train Loss: 0.1968, Valid Loss: 0.2132
Model saved!
Accuracy: 0.9252
Precision: 0.9238
Recall: 0.9252
F1-score: 0.9240
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5611
Epoch 1/10, Batch 20/145, Loss: 1.0254
Epoch 1/10, Batch 30/145, Loss: 0.8579
Epoch 1/10, Batch 40/145, Loss: 0.8009
Epoch 1/10, Batch 50/145, Loss: 0.6583
Epoch 1/10, Batch 60/145, Loss: 0.5336
Epoch 1/10, Batch 70/145, Loss: 0.5836
Epoch 1/10, Batch 80/145, Loss: 0.5168
Epoch 1/10, Batch 90/145, Loss: 0.4364
Epoch 1/10, Batch 100/145, Loss: 0.8341
Epoch 1/10, Batch 110/145, Loss: 0.3813
Epoch 1/10, Batch 120/145, Loss: 0.6273
Epoch 1/10, Batch 130/145, Loss: 0.6131
Epoch 1/10, Batch 140/145, Loss: 0.3420
Epoch 1/10, Train Loss: 0.6870, Valid Loss: 0.3615
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3481
Epoch 2/10, Batch 20/145, Loss: 0.5875
Epoch 2/10, Batch 30/145, Loss: 0.5052
Epoch 2/10, Batch 40/145, Loss: 0.3750
Epoch 2/10, Batch 50/145, Loss: 0.2997
Epoch 2/10, Batch 60/145, Loss: 0.5104
Epoch 2/10, Batch 70/145, Loss: 0.4565
Epoch 2/10, Batch 80/145, Loss: 0.2266
Epoch 2/10, Batch 90/145, Loss: 0.3321
Epoch 2/10, Batch 100/145, Loss: 0.2336
Epoch 2/10, Batch 110/145, Loss: 0.2266
Epoch 2/10, Batch 120/145, Loss: 0.3885
Epoch 2/10, Batch 130/145, Loss: 0.4173
Epoch 2/10, Batch 140/145, Loss: 0.2803
Epoch 2/10, Train Loss: 0.3635, Valid Loss: 0.2860
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1847
Epoch 3/10, Batch 20/145, Loss: 0.3676
Epoch 3/10, Batch 30/145, Loss: 0.1945
Epoch 3/10, Batch 40/145, Loss: 0.2126
Epoch 3/10, Batch 50/145, Loss: 0.3279
Epoch 3/10, Batch 60/145, Loss: 0.2593
Epoch 3/10, Batch 70/145, Loss: 0.2038
Epoch 3/10, Batch 80/145, Loss: 0.2655
Epoch 3/10, Batch 90/145, Loss: 0.3256
Epoch 3/10, Batch 100/145, Loss: 0.3009
Epoch 3/10, Batch 110/145, Loss: 0.3481
Epoch 3/10, Batch 120/145, Loss: 0.1472
Epoch 3/10, Batch 130/145, Loss: 0.2991
Epoch 3/10, Batch 140/145, Loss: 0.3421
Epoch 3/10, Train Loss: 0.3084, Valid Loss: 0.2509
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3004
Epoch 4/10, Batch 20/145, Loss: 0.2923
Epoch 4/10, Batch 30/145, Loss: 0.2051
Epoch 4/10, Batch 40/145, Loss: 0.2926
Epoch 4/10, Batch 50/145, Loss: 0.2680
Epoch 4/10, Batch 60/145, Loss: 0.1966
Epoch 4/10, Batch 70/145, Loss: 0.2087
Epoch 4/10, Batch 80/145, Loss: 0.3423
Epoch 4/10, Batch 90/145, Loss: 0.3794
Epoch 4/10, Batch 100/145, Loss: 0.1755
Epoch 4/10, Batch 110/145, Loss: 0.1829
Epoch 4/10, Batch 120/145, Loss: 0.1831
Epoch 4/10, Batch 130/145, Loss: 0.1488
Epoch 4/10, Batch 140/145, Loss: 0.2162
Epoch 4/10, Train Loss: 0.2619, Valid Loss: 0.2531
Epoch 5/10, Batch 10/145, Loss: 0.1522
Epoch 5/10, Batch 20/145, Loss: 0.2884
Epoch 5/10, Batch 30/145, Loss: 0.1440
Epoch 5/10, Batch 40/145, Loss: 0.2242
Epoch 5/10, Batch 50/145, Loss: 0.1452
Epoch 5/10, Batch 60/145, Loss: 0.2223
Epoch 5/10, Batch 70/145, Loss: 0.3145
Epoch 5/10, Batch 80/145, Loss: 0.3198
Epoch 5/10, Batch 90/145, Loss: 0.3387
Epoch 5/10, Batch 100/145, Loss: 0.2262
Epoch 5/10, Batch 110/145, Loss: 0.2173
Epoch 5/10, Batch 120/145, Loss: 0.1377
Epoch 5/10, Batch 130/145, Loss: 0.1658
Epoch 5/10, Batch 140/145, Loss: 0.3578
Epoch 5/10, Train Loss: 0.2416, Valid Loss: 0.2312
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2431
Epoch 6/10, Batch 20/145, Loss: 0.2585
Epoch 6/10, Batch 30/145, Loss: 0.2089
Epoch 6/10, Batch 40/145, Loss: 0.1627
Epoch 6/10, Batch 50/145, Loss: 0.3449
Epoch 6/10, Batch 60/145, Loss: 0.3261
Epoch 6/10, Batch 70/145, Loss: 0.2056
Epoch 6/10, Batch 80/145, Loss: 0.3999
Epoch 6/10, Batch 90/145, Loss: 0.2830
Epoch 6/10, Batch 100/145, Loss: 0.0982
Epoch 6/10, Batch 110/145, Loss: 0.1277
Epoch 6/10, Batch 120/145, Loss: 0.1738
Epoch 6/10, Batch 130/145, Loss: 0.1774
Epoch 6/10, Batch 140/145, Loss: 0.3625
Epoch 6/10, Train Loss: 0.2252, Valid Loss: 0.2212
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3076
Epoch 7/10, Batch 20/145, Loss: 0.2692
Epoch 7/10, Batch 30/145, Loss: 0.2421
Epoch 7/10, Batch 40/145, Loss: 0.3615
Epoch 7/10, Batch 50/145, Loss: 0.1848
Epoch 7/10, Batch 60/145, Loss: 0.1533
Epoch 7/10, Batch 70/145, Loss: 0.2913
Epoch 7/10, Batch 80/145, Loss: 0.0953
Epoch 7/10, Batch 90/145, Loss: 0.4082
Epoch 7/10, Batch 100/145, Loss: 0.1470
Epoch 7/10, Batch 110/145, Loss: 0.1498
Epoch 7/10, Batch 120/145, Loss: 0.0960
Epoch 7/10, Batch 130/145, Loss: 0.2243
Epoch 7/10, Batch 140/145, Loss: 0.1307
Epoch 7/10, Train Loss: 0.2174, Valid Loss: 0.2154
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1499
Epoch 8/10, Batch 20/145, Loss: 0.1180
Epoch 8/10, Batch 30/145, Loss: 0.2832
Epoch 8/10, Batch 40/145, Loss: 0.2006
Epoch 8/10, Batch 50/145, Loss: 0.1274
Epoch 8/10, Batch 60/145, Loss: 0.2384
Epoch 8/10, Batch 70/145, Loss: 0.1363
Epoch 8/10, Batch 80/145, Loss: 0.2056
Epoch 8/10, Batch 90/145, Loss: 0.1690
Epoch 8/10, Batch 100/145, Loss: 0.3966
Epoch 8/10, Batch 110/145, Loss: 0.2207
Epoch 8/10, Batch 120/145, Loss: 0.2970
Epoch 8/10, Batch 130/145, Loss: 0.1929
Epoch 8/10, Batch 140/145, Loss: 0.4743
Epoch 8/10, Train Loss: 0.2101, Valid Loss: 0.2146
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3258
Epoch 9/10, Batch 20/145, Loss: 0.1014
Epoch 9/10, Batch 30/145, Loss: 0.2947
Epoch 9/10, Batch 40/145, Loss: 0.2571
Epoch 9/10, Batch 50/145, Loss: 0.1227
Epoch 9/10, Batch 60/145, Loss: 0.1179
Epoch 9/10, Batch 70/145, Loss: 0.2767
Epoch 9/10, Batch 80/145, Loss: 0.2621
Epoch 9/10, Batch 90/145, Loss: 0.1843
Epoch 9/10, Batch 100/145, Loss: 0.2611
Epoch 9/10, Batch 110/145, Loss: 0.2165
Epoch 9/10, Batch 120/145, Loss: 0.0990
Epoch 9/10, Batch 130/145, Loss: 0.1513
Epoch 9/10, Batch 140/145, Loss: 0.1153
Epoch 9/10, Train Loss: 0.2040, Valid Loss: 0.1984
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.3340
Epoch 10/10, Batch 20/145, Loss: 0.1062
Epoch 10/10, Batch 30/145, Loss: 0.1296
Epoch 10/10, Batch 40/145, Loss: 0.1919
Epoch 10/10, Batch 50/145, Loss: 0.2750
Epoch 10/10, Batch 60/145, Loss: 0.2428
Epoch 10/10, Batch 70/145, Loss: 0.2923
Epoch 10/10, Batch 80/145, Loss: 0.3179
Epoch 10/10, Batch 90/145, Loss: 0.0702
Epoch 10/10, Batch 100/145, Loss: 0.1818
Epoch 10/10, Batch 110/145, Loss: 0.2761
Epoch 10/10, Batch 120/145, Loss: 0.1757
Epoch 10/10, Batch 130/145, Loss: 0.1378
Epoch 10/10, Batch 140/145, Loss: 0.2958
Epoch 10/10, Train Loss: 0.2021, Valid Loss: 0.2037
Accuracy: 0.9217
Precision: 0.9200
Recall: 0.9217
F1-score: 0.9205
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5465
Epoch 1/10, Batch 20/145, Loss: 0.9415
Epoch 1/10, Batch 30/145, Loss: 0.9423
Epoch 1/10, Batch 40/145, Loss: 0.7885
Epoch 1/10, Batch 50/145, Loss: 0.6737
Epoch 1/10, Batch 60/145, Loss: 0.5434
Epoch 1/10, Batch 70/145, Loss: 0.6585
Epoch 1/10, Batch 80/145, Loss: 0.5347
Epoch 1/10, Batch 90/145, Loss: 0.5482
Epoch 1/10, Batch 100/145, Loss: 0.5497
Epoch 1/10, Batch 110/145, Loss: 0.3865
Epoch 1/10, Batch 120/145, Loss: 0.4741
Epoch 1/10, Batch 130/145, Loss: 0.5098
Epoch 1/10, Batch 140/145, Loss: 0.2842
Epoch 1/10, Train Loss: 0.6856, Valid Loss: 0.3682
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3744
Epoch 2/10, Batch 20/145, Loss: 0.5403
Epoch 2/10, Batch 30/145, Loss: 0.3517
Epoch 2/10, Batch 40/145, Loss: 0.4515
Epoch 2/10, Batch 50/145, Loss: 0.2038
Epoch 2/10, Batch 60/145, Loss: 0.4117
Epoch 2/10, Batch 70/145, Loss: 0.4918
Epoch 2/10, Batch 80/145, Loss: 0.3706
Epoch 2/10, Batch 90/145, Loss: 0.4143
Epoch 2/10, Batch 100/145, Loss: 0.1704
Epoch 2/10, Batch 110/145, Loss: 0.3344
Epoch 2/10, Batch 120/145, Loss: 0.3165
Epoch 2/10, Batch 130/145, Loss: 0.3236
Epoch 2/10, Batch 140/145, Loss: 0.2215
Epoch 2/10, Train Loss: 0.3575, Valid Loss: 0.2857
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2423
Epoch 3/10, Batch 20/145, Loss: 0.2836
Epoch 3/10, Batch 30/145, Loss: 0.2098
Epoch 3/10, Batch 40/145, Loss: 0.3917
Epoch 3/10, Batch 50/145, Loss: 0.1671
Epoch 3/10, Batch 60/145, Loss: 0.2241
Epoch 3/10, Batch 70/145, Loss: 0.3565
Epoch 3/10, Batch 80/145, Loss: 0.2792
Epoch 3/10, Batch 90/145, Loss: 0.4661
Epoch 3/10, Batch 100/145, Loss: 0.2062
Epoch 3/10, Batch 110/145, Loss: 0.1528
Epoch 3/10, Batch 120/145, Loss: 0.1375
Epoch 3/10, Batch 130/145, Loss: 0.2282
Epoch 3/10, Batch 140/145, Loss: 0.3145
Epoch 3/10, Train Loss: 0.3015, Valid Loss: 0.2527
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1367
Epoch 4/10, Batch 20/145, Loss: 0.1569
Epoch 4/10, Batch 30/145, Loss: 0.2125
Epoch 4/10, Batch 40/145, Loss: 0.3230
Epoch 4/10, Batch 50/145, Loss: 0.1555
Epoch 4/10, Batch 60/145, Loss: 0.3634
Epoch 4/10, Batch 70/145, Loss: 0.2700
Epoch 4/10, Batch 80/145, Loss: 0.2421
Epoch 4/10, Batch 90/145, Loss: 0.2834
Epoch 4/10, Batch 100/145, Loss: 0.1573
Epoch 4/10, Batch 110/145, Loss: 0.1711
Epoch 4/10, Batch 120/145, Loss: 0.2119
Epoch 4/10, Batch 130/145, Loss: 0.2621
Epoch 4/10, Batch 140/145, Loss: 0.1776
Epoch 4/10, Train Loss: 0.2630, Valid Loss: 0.2349
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3546
Epoch 5/10, Batch 20/145, Loss: 0.2379
Epoch 5/10, Batch 30/145, Loss: 0.1612
Epoch 5/10, Batch 40/145, Loss: 0.3005
Epoch 5/10, Batch 50/145, Loss: 0.2224
Epoch 5/10, Batch 60/145, Loss: 0.1499
Epoch 5/10, Batch 70/145, Loss: 0.4174
Epoch 5/10, Batch 80/145, Loss: 0.2737
Epoch 5/10, Batch 90/145, Loss: 0.1992
Epoch 5/10, Batch 100/145, Loss: 0.2249
Epoch 5/10, Batch 110/145, Loss: 0.2361
Epoch 5/10, Batch 120/145, Loss: 0.1865
Epoch 5/10, Batch 130/145, Loss: 0.2197
Epoch 5/10, Batch 140/145, Loss: 0.2146
Epoch 5/10, Train Loss: 0.2410, Valid Loss: 0.2200
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2733
Epoch 6/10, Batch 20/145, Loss: 0.2705
Epoch 6/10, Batch 30/145, Loss: 0.2258
Epoch 6/10, Batch 40/145, Loss: 0.1972
Epoch 6/10, Batch 50/145, Loss: 0.4391
Epoch 6/10, Batch 60/145, Loss: 0.1715
Epoch 6/10, Batch 70/145, Loss: 0.3419
Epoch 6/10, Batch 80/145, Loss: 0.3066
Epoch 6/10, Batch 90/145, Loss: 0.2737
Epoch 6/10, Batch 100/145, Loss: 0.1692
Epoch 6/10, Batch 110/145, Loss: 0.1365
Epoch 6/10, Batch 120/145, Loss: 0.2653
Epoch 6/10, Batch 130/145, Loss: 0.1578
Epoch 6/10, Batch 140/145, Loss: 0.1652
Epoch 6/10, Train Loss: 0.2311, Valid Loss: 0.2163
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2935
Epoch 7/10, Batch 20/145, Loss: 0.3293
Epoch 7/10, Batch 30/145, Loss: 0.0814
Epoch 7/10, Batch 40/145, Loss: 0.3801
Epoch 7/10, Batch 50/145, Loss: 0.1961
Epoch 7/10, Batch 60/145, Loss: 0.1218
Epoch 7/10, Batch 70/145, Loss: 0.3576
Epoch 7/10, Batch 80/145, Loss: 0.0678
Epoch 7/10, Batch 90/145, Loss: 0.1680
Epoch 7/10, Batch 100/145, Loss: 0.1621
Epoch 7/10, Batch 110/145, Loss: 0.1583
Epoch 7/10, Batch 120/145, Loss: 0.2230
Epoch 7/10, Batch 130/145, Loss: 0.1940
Epoch 7/10, Batch 140/145, Loss: 0.1144
Epoch 7/10, Train Loss: 0.2148, Valid Loss: 0.2075
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1506
Epoch 8/10, Batch 20/145, Loss: 0.1739
Epoch 8/10, Batch 30/145, Loss: 0.0729
Epoch 8/10, Batch 40/145, Loss: 0.1633
Epoch 8/10, Batch 50/145, Loss: 0.1887
Epoch 8/10, Batch 60/145, Loss: 0.1799
Epoch 8/10, Batch 70/145, Loss: 0.1094
Epoch 8/10, Batch 80/145, Loss: 0.1616
Epoch 8/10, Batch 90/145, Loss: 0.0824
Epoch 8/10, Batch 100/145, Loss: 0.2694
Epoch 8/10, Batch 110/145, Loss: 0.2669
Epoch 8/10, Batch 120/145, Loss: 0.2588
Epoch 8/10, Batch 130/145, Loss: 0.1699
Epoch 8/10, Batch 140/145, Loss: 0.3515
Epoch 8/10, Train Loss: 0.2065, Valid Loss: 0.2080
Epoch 9/10, Batch 10/145, Loss: 0.2479
Epoch 9/10, Batch 20/145, Loss: 0.1792
Epoch 9/10, Batch 30/145, Loss: 0.1238
Epoch 9/10, Batch 40/145, Loss: 0.1902
Epoch 9/10, Batch 50/145, Loss: 0.2056
Epoch 9/10, Batch 60/145, Loss: 0.1326
Epoch 9/10, Batch 70/145, Loss: 0.1531
Epoch 9/10, Batch 80/145, Loss: 0.3702
Epoch 9/10, Batch 90/145, Loss: 0.2012
Epoch 9/10, Batch 100/145, Loss: 0.1865
Epoch 9/10, Batch 110/145, Loss: 0.0960
Epoch 9/10, Batch 120/145, Loss: 0.1852
Epoch 9/10, Batch 130/145, Loss: 0.1924
Epoch 9/10, Batch 140/145, Loss: 0.1391
Epoch 9/10, Train Loss: 0.2003, Valid Loss: 0.1964
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2805
Epoch 10/10, Batch 20/145, Loss: 0.1097
Epoch 10/10, Batch 30/145, Loss: 0.0833
Epoch 10/10, Batch 40/145, Loss: 0.2981
Epoch 10/10, Batch 50/145, Loss: 0.3189
Epoch 10/10, Batch 60/145, Loss: 0.3230
Epoch 10/10, Batch 70/145, Loss: 0.2862
Epoch 10/10, Batch 80/145, Loss: 0.4025
Epoch 10/10, Batch 90/145, Loss: 0.2283
Epoch 10/10, Batch 100/145, Loss: 0.1157
Epoch 10/10, Batch 110/145, Loss: 0.3095
Epoch 10/10, Batch 120/145, Loss: 0.3224
Epoch 10/10, Batch 130/145, Loss: 0.1494
Epoch 10/10, Batch 140/145, Loss: 0.1232
Epoch 10/10, Train Loss: 0.1997, Valid Loss: 0.1942
Model saved!
Accuracy: 0.9194
Precision: 0.9182
Recall: 0.9194
F1-score: 0.9187
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4422
Epoch 1/10, Batch 20/145, Loss: 0.9425
Epoch 1/10, Batch 30/145, Loss: 0.8995
Epoch 1/10, Batch 40/145, Loss: 0.7822
Epoch 1/10, Batch 50/145, Loss: 0.5142
Epoch 1/10, Batch 60/145, Loss: 0.5570
Epoch 1/10, Batch 70/145, Loss: 0.5588
Epoch 1/10, Batch 80/145, Loss: 0.3798
Epoch 1/10, Batch 90/145, Loss: 0.6000
Epoch 1/10, Batch 100/145, Loss: 0.6894
Epoch 1/10, Batch 110/145, Loss: 0.4777
Epoch 1/10, Batch 120/145, Loss: 0.6796
Epoch 1/10, Batch 130/145, Loss: 0.5137
Epoch 1/10, Batch 140/145, Loss: 0.3762
Epoch 1/10, Train Loss: 0.6846, Valid Loss: 0.3861
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2829
Epoch 2/10, Batch 20/145, Loss: 0.4537
Epoch 2/10, Batch 30/145, Loss: 0.3601
Epoch 2/10, Batch 40/145, Loss: 0.4168
Epoch 2/10, Batch 50/145, Loss: 0.2837
Epoch 2/10, Batch 60/145, Loss: 0.3970
Epoch 2/10, Batch 70/145, Loss: 0.4214
Epoch 2/10, Batch 80/145, Loss: 0.3244
Epoch 2/10, Batch 90/145, Loss: 0.3221
Epoch 2/10, Batch 100/145, Loss: 0.2406
Epoch 2/10, Batch 110/145, Loss: 0.1964
Epoch 2/10, Batch 120/145, Loss: 0.5204
Epoch 2/10, Batch 130/145, Loss: 0.3301
Epoch 2/10, Batch 140/145, Loss: 0.2580
Epoch 2/10, Train Loss: 0.3602, Valid Loss: 0.2959
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1798
Epoch 3/10, Batch 20/145, Loss: 0.3012
Epoch 3/10, Batch 30/145, Loss: 0.2248
Epoch 3/10, Batch 40/145, Loss: 0.3320
Epoch 3/10, Batch 50/145, Loss: 0.1889
Epoch 3/10, Batch 60/145, Loss: 0.3811
Epoch 3/10, Batch 70/145, Loss: 0.3941
Epoch 3/10, Batch 80/145, Loss: 0.2342
Epoch 3/10, Batch 90/145, Loss: 0.5100
Epoch 3/10, Batch 100/145, Loss: 0.2531
Epoch 3/10, Batch 110/145, Loss: 0.1748
Epoch 3/10, Batch 120/145, Loss: 0.2643
Epoch 3/10, Batch 130/145, Loss: 0.3076
Epoch 3/10, Batch 140/145, Loss: 0.2291
Epoch 3/10, Train Loss: 0.3020, Valid Loss: 0.2645
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1897
Epoch 4/10, Batch 20/145, Loss: 0.1749
Epoch 4/10, Batch 30/145, Loss: 0.3971
Epoch 4/10, Batch 40/145, Loss: 0.4403
Epoch 4/10, Batch 50/145, Loss: 0.2257
Epoch 4/10, Batch 60/145, Loss: 0.3127
Epoch 4/10, Batch 70/145, Loss: 0.1387
Epoch 4/10, Batch 80/145, Loss: 0.3977
Epoch 4/10, Batch 90/145, Loss: 0.3016
Epoch 4/10, Batch 100/145, Loss: 0.1893
Epoch 4/10, Batch 110/145, Loss: 0.3016
Epoch 4/10, Batch 120/145, Loss: 0.1146
Epoch 4/10, Batch 130/145, Loss: 0.3860
Epoch 4/10, Batch 140/145, Loss: 0.2646
Epoch 4/10, Train Loss: 0.2642, Valid Loss: 0.2424
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3268
Epoch 5/10, Batch 20/145, Loss: 0.1814
Epoch 5/10, Batch 30/145, Loss: 0.2294
Epoch 5/10, Batch 40/145, Loss: 0.1826
Epoch 5/10, Batch 50/145, Loss: 0.2612
Epoch 5/10, Batch 60/145, Loss: 0.2059
Epoch 5/10, Batch 70/145, Loss: 0.3248
Epoch 5/10, Batch 80/145, Loss: 0.3432
Epoch 5/10, Batch 90/145, Loss: 0.1323
Epoch 5/10, Batch 100/145, Loss: 0.1988
Epoch 5/10, Batch 110/145, Loss: 0.1710
Epoch 5/10, Batch 120/145, Loss: 0.2008
Epoch 5/10, Batch 130/145, Loss: 0.2729
Epoch 5/10, Batch 140/145, Loss: 0.3228
Epoch 5/10, Train Loss: 0.2377, Valid Loss: 0.2380
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1864
Epoch 6/10, Batch 20/145, Loss: 0.1527
Epoch 6/10, Batch 30/145, Loss: 0.4139
Epoch 6/10, Batch 40/145, Loss: 0.1401
Epoch 6/10, Batch 50/145, Loss: 0.3969
Epoch 6/10, Batch 60/145, Loss: 0.1456
Epoch 6/10, Batch 70/145, Loss: 0.2072
Epoch 6/10, Batch 80/145, Loss: 0.2385
Epoch 6/10, Batch 90/145, Loss: 0.2099
Epoch 6/10, Batch 100/145, Loss: 0.1836
Epoch 6/10, Batch 110/145, Loss: 0.0814
Epoch 6/10, Batch 120/145, Loss: 0.2650
Epoch 6/10, Batch 130/145, Loss: 0.1315
Epoch 6/10, Batch 140/145, Loss: 0.2485
Epoch 6/10, Train Loss: 0.2295, Valid Loss: 0.2347
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2936
Epoch 7/10, Batch 20/145, Loss: 0.1928
Epoch 7/10, Batch 30/145, Loss: 0.2852
Epoch 7/10, Batch 40/145, Loss: 0.2650
Epoch 7/10, Batch 50/145, Loss: 0.2901
Epoch 7/10, Batch 60/145, Loss: 0.1535
Epoch 7/10, Batch 70/145, Loss: 0.2815
Epoch 7/10, Batch 80/145, Loss: 0.1327
Epoch 7/10, Batch 90/145, Loss: 0.2361
Epoch 7/10, Batch 100/145, Loss: 0.2929
Epoch 7/10, Batch 110/145, Loss: 0.3228
Epoch 7/10, Batch 120/145, Loss: 0.2405
Epoch 7/10, Batch 130/145, Loss: 0.1222
Epoch 7/10, Batch 140/145, Loss: 0.1059
Epoch 7/10, Train Loss: 0.2178, Valid Loss: 0.2311
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0930
Epoch 8/10, Batch 20/145, Loss: 0.1526
Epoch 8/10, Batch 30/145, Loss: 0.1606
Epoch 8/10, Batch 40/145, Loss: 0.2243
Epoch 8/10, Batch 50/145, Loss: 0.1281
Epoch 8/10, Batch 60/145, Loss: 0.3380
Epoch 8/10, Batch 70/145, Loss: 0.1758
Epoch 8/10, Batch 80/145, Loss: 0.1070
Epoch 8/10, Batch 90/145, Loss: 0.1285
Epoch 8/10, Batch 100/145, Loss: 0.2873
Epoch 8/10, Batch 110/145, Loss: 0.1817
Epoch 8/10, Batch 120/145, Loss: 0.2524
Epoch 8/10, Batch 130/145, Loss: 0.1345
Epoch 8/10, Batch 140/145, Loss: 0.1620
Epoch 8/10, Train Loss: 0.2090, Valid Loss: 0.2131
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2251
Epoch 9/10, Batch 20/145, Loss: 0.1415
Epoch 9/10, Batch 30/145, Loss: 0.1236
Epoch 9/10, Batch 40/145, Loss: 0.2144
Epoch 9/10, Batch 50/145, Loss: 0.1699
Epoch 9/10, Batch 60/145, Loss: 0.1810
Epoch 9/10, Batch 70/145, Loss: 0.2316
Epoch 9/10, Batch 80/145, Loss: 0.3608
Epoch 9/10, Batch 90/145, Loss: 0.1175
Epoch 9/10, Batch 100/145, Loss: 0.2002
Epoch 9/10, Batch 110/145, Loss: 0.1116
Epoch 9/10, Batch 120/145, Loss: 0.1934
Epoch 9/10, Batch 130/145, Loss: 0.1112
Epoch 9/10, Batch 140/145, Loss: 0.0627
Epoch 9/10, Train Loss: 0.2068, Valid Loss: 0.2112
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1147
Epoch 10/10, Batch 20/145, Loss: 0.0959
Epoch 10/10, Batch 30/145, Loss: 0.1246
Epoch 10/10, Batch 40/145, Loss: 0.1440
Epoch 10/10, Batch 50/145, Loss: 0.2580
Epoch 10/10, Batch 60/145, Loss: 0.2201
Epoch 10/10, Batch 70/145, Loss: 0.1557
Epoch 10/10, Batch 80/145, Loss: 0.3612
Epoch 10/10, Batch 90/145, Loss: 0.2944
Epoch 10/10, Batch 100/145, Loss: 0.1528
Epoch 10/10, Batch 110/145, Loss: 0.1928
Epoch 10/10, Batch 120/145, Loss: 0.1458
Epoch 10/10, Batch 130/145, Loss: 0.2727
Epoch 10/10, Batch 140/145, Loss: 0.1768
Epoch 10/10, Train Loss: 0.1940, Valid Loss: 0.2045
Model saved!
Accuracy: 0.9264
Precision: 0.9249
Recall: 0.9264
F1-score: 0.9254
Memory Allocated after cleanup: 17.76 MB
End time: 2025-02-26 04:51:29.009569
Duration: 9:44:49


Mejor accuracy al acabar el algoritmo: 0.9334


Fitness check:

Using device: cuda
GPU: NVIDIA TITAN RTX
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.5352
Epoch 1/10, Batch 20/145, Loss: 0.9220
Epoch 1/10, Batch 30/145, Loss: 0.8696
Epoch 1/10, Batch 40/145, Loss: 0.8731
Epoch 1/10, Batch 50/145, Loss: 0.6125
Epoch 1/10, Batch 60/145, Loss: 0.5180
Epoch 1/10, Batch 70/145, Loss: 0.5316
Epoch 1/10, Batch 80/145, Loss: 0.4968
Epoch 1/10, Batch 90/145, Loss: 0.4800
Epoch 1/10, Batch 100/145, Loss: 0.4507
Epoch 1/10, Batch 110/145, Loss: 0.3917
Epoch 1/10, Batch 120/145, Loss: 0.5143
Epoch 1/10, Batch 130/145, Loss: 0.4686
Epoch 1/10, Batch 140/145, Loss: 0.4650
Epoch 1/10, Train Loss: 0.6897, Valid Loss: 0.3860
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3018
Epoch 2/10, Batch 20/145, Loss: 0.4227
Epoch 2/10, Batch 30/145, Loss: 0.2640
Epoch 2/10, Batch 40/145, Loss: 0.4921
Epoch 2/10, Batch 50/145, Loss: 0.3135
Epoch 2/10, Batch 60/145, Loss: 0.4282
Epoch 2/10, Batch 70/145, Loss: 0.4007
Epoch 2/10, Batch 80/145, Loss: 0.3206
Epoch 2/10, Batch 90/145, Loss: 0.2827
Epoch 2/10, Batch 100/145, Loss: 0.2424
Epoch 2/10, Batch 110/145, Loss: 0.3135
Epoch 2/10, Batch 120/145, Loss: 0.4111
Epoch 2/10, Batch 130/145, Loss: 0.3588
Epoch 2/10, Batch 140/145, Loss: 0.3017
Epoch 2/10, Train Loss: 0.3653, Valid Loss: 0.2898
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2307
Epoch 3/10, Batch 20/145, Loss: 0.5831
Epoch 3/10, Batch 30/145, Loss: 0.2263
Epoch 3/10, Batch 40/145, Loss: 0.2677
Epoch 3/10, Batch 50/145, Loss: 0.2162
Epoch 3/10, Batch 60/145, Loss: 0.3540
Epoch 3/10, Batch 70/145, Loss: 0.1842
Epoch 3/10, Batch 80/145, Loss: 0.3548
Epoch 3/10, Batch 90/145, Loss: 0.5599
Epoch 3/10, Batch 100/145, Loss: 0.2485
Epoch 3/10, Batch 110/145, Loss: 0.1862
Epoch 3/10, Batch 120/145, Loss: 0.2383
Epoch 3/10, Batch 130/145, Loss: 0.2486
Epoch 3/10, Batch 140/145, Loss: 0.1878
Epoch 3/10, Train Loss: 0.3143, Valid Loss: 0.2523
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1898
Epoch 4/10, Batch 20/145, Loss: 0.2734
Epoch 4/10, Batch 30/145, Loss: 0.2646
Epoch 4/10, Batch 40/145, Loss: 0.3868
Epoch 4/10, Batch 50/145, Loss: 0.1341
Epoch 4/10, Batch 60/145, Loss: 0.1896
Epoch 4/10, Batch 70/145, Loss: 0.3339
Epoch 4/10, Batch 80/145, Loss: 0.2847
Epoch 4/10, Batch 90/145, Loss: 0.3248
Epoch 4/10, Batch 100/145, Loss: 0.2657
Epoch 4/10, Batch 110/145, Loss: 0.1201
Epoch 4/10, Batch 120/145, Loss: 0.2493
Epoch 4/10, Batch 130/145, Loss: 0.1958
Epoch 4/10, Batch 140/145, Loss: 0.1375
Epoch 4/10, Train Loss: 0.2632, Valid Loss: 0.2480
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1716
Epoch 5/10, Batch 20/145, Loss: 0.4715
Epoch 5/10, Batch 30/145, Loss: 0.1818
Epoch 5/10, Batch 40/145, Loss: 0.2578
Epoch 5/10, Batch 50/145, Loss: 0.1298
Epoch 5/10, Batch 60/145, Loss: 0.2379
Epoch 5/10, Batch 70/145, Loss: 0.4245
Epoch 5/10, Batch 80/145, Loss: 0.2318
Epoch 5/10, Batch 90/145, Loss: 0.1447
Epoch 5/10, Batch 100/145, Loss: 0.2646
Epoch 5/10, Batch 110/145, Loss: 0.1236
Epoch 5/10, Batch 120/145, Loss: 0.1883
Epoch 5/10, Batch 130/145, Loss: 0.2334
Epoch 5/10, Batch 140/145, Loss: 0.4430
Epoch 5/10, Train Loss: 0.2433, Valid Loss: 0.2282
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1657
Epoch 6/10, Batch 20/145, Loss: 0.4761
Epoch 6/10, Batch 30/145, Loss: 0.2843
Epoch 6/10, Batch 40/145, Loss: 0.2578
Epoch 6/10, Batch 50/145, Loss: 0.3375
Epoch 6/10, Batch 60/145, Loss: 0.1672
Epoch 6/10, Batch 70/145, Loss: 0.3358
Epoch 6/10, Batch 80/145, Loss: 0.2969
Epoch 6/10, Batch 90/145, Loss: 0.2918
Epoch 6/10, Batch 100/145, Loss: 0.2648
Epoch 6/10, Batch 110/145, Loss: 0.1793
Epoch 6/10, Batch 120/145, Loss: 0.2390
Epoch 6/10, Batch 130/145, Loss: 0.0833
Epoch 6/10, Batch 140/145, Loss: 0.4490
Epoch 6/10, Train Loss: 0.2361, Valid Loss: 0.2211
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1752
Epoch 7/10, Batch 20/145, Loss: 0.1361
Epoch 7/10, Batch 30/145, Loss: 0.2072
Epoch 7/10, Batch 40/145, Loss: 0.4797
Epoch 7/10, Batch 50/145, Loss: 0.1570
Epoch 7/10, Batch 60/145, Loss: 0.2401
Epoch 7/10, Batch 70/145, Loss: 0.2638
Epoch 7/10, Batch 80/145, Loss: 0.1918
Epoch 7/10, Batch 90/145, Loss: 0.4210
Epoch 7/10, Batch 100/145, Loss: 0.1658
Epoch 7/10, Batch 110/145, Loss: 0.3108
Epoch 7/10, Batch 120/145, Loss: 0.1356
Epoch 7/10, Batch 130/145, Loss: 0.2680
Epoch 7/10, Batch 140/145, Loss: 0.2132
Epoch 7/10, Train Loss: 0.2241, Valid Loss: 0.2129
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1233
Epoch 8/10, Batch 20/145, Loss: 0.1720
Epoch 8/10, Batch 30/145, Loss: 0.2010
Epoch 8/10, Batch 40/145, Loss: 0.2442
Epoch 8/10, Batch 50/145, Loss: 0.5431
Epoch 8/10, Batch 60/145, Loss: 0.1684
Epoch 8/10, Batch 70/145, Loss: 0.1685
Epoch 8/10, Batch 80/145, Loss: 0.1695
Epoch 8/10, Batch 90/145, Loss: 0.1693
Epoch 8/10, Batch 100/145, Loss: 0.2896
Epoch 8/10, Batch 110/145, Loss: 0.1391
Epoch 8/10, Batch 120/145, Loss: 0.1078
Epoch 8/10, Batch 130/145, Loss: 0.1995
Epoch 8/10, Batch 140/145, Loss: 0.1291
Epoch 8/10, Train Loss: 0.2119, Valid Loss: 0.2094
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1823
Epoch 9/10, Batch 20/145, Loss: 0.1173
Epoch 9/10, Batch 30/145, Loss: 0.0770
Epoch 9/10, Batch 40/145, Loss: 0.1289
Epoch 9/10, Batch 50/145, Loss: 0.2771
Epoch 9/10, Batch 60/145, Loss: 0.1133
Epoch 9/10, Batch 70/145, Loss: 0.2167
Epoch 9/10, Batch 80/145, Loss: 0.1671
Epoch 9/10, Batch 90/145, Loss: 0.2224
Epoch 9/10, Batch 100/145, Loss: 0.2387
Epoch 9/10, Batch 110/145, Loss: 0.0560
Epoch 9/10, Batch 120/145, Loss: 0.2471
Epoch 9/10, Batch 130/145, Loss: 0.2280
Epoch 9/10, Batch 140/145, Loss: 0.1518
Epoch 9/10, Train Loss: 0.2063, Valid Loss: 0.2078
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1771
Epoch 10/10, Batch 20/145, Loss: 0.3134
Epoch 10/10, Batch 30/145, Loss: 0.0822
Epoch 10/10, Batch 40/145, Loss: 0.2334
Epoch 10/10, Batch 50/145, Loss: 0.3389
Epoch 10/10, Batch 60/145, Loss: 0.1804
Epoch 10/10, Batch 70/145, Loss: 0.0717
Epoch 10/10, Batch 80/145, Loss: 0.4498
Epoch 10/10, Batch 90/145, Loss: 0.0897
Epoch 10/10, Batch 100/145, Loss: 0.1148
Epoch 10/10, Batch 110/145, Loss: 0.3052
Epoch 10/10, Batch 120/145, Loss: 0.2246
Epoch 10/10, Batch 130/145, Loss: 0.1568
Epoch 10/10, Batch 140/145, Loss: 0.3431
Epoch 10/10, Train Loss: 0.2032, Valid Loss: 0.2006
Model saved!
Accuracy: 0.9334
Precision: 0.9325
Recall: 0.9334
F1-score: 0.9328
Memory Allocated after cleanup: 17.76 MB


Mejor accuracy encontrado: 0.9334
Se han generado los boxplots y guardado los resultados correctamente.
