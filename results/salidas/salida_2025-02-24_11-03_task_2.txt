Task ID recibido: 2
GPU: True


--------------------------------------mobilenet  ALEATORIO  10%-------------------------------------------------
Start time: 2025-02-24 09:04:57.201112
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.00 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2236
Epoch 1/10, Batch 20/20, Loss: 1.1540
Epoch 1/10, Train Loss: 1.3028, Valid Loss: 0.9503
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8083
Epoch 2/10, Batch 20/20, Loss: 0.9378
Epoch 2/10, Train Loss: 0.8865, Valid Loss: 0.6755
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6640
Epoch 3/10, Batch 20/20, Loss: 0.7956
Epoch 3/10, Train Loss: 0.6715, Valid Loss: 0.5556
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7553
Epoch 4/10, Batch 20/20, Loss: 0.4010
Epoch 4/10, Train Loss: 0.5465, Valid Loss: 0.4788
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4686
Epoch 5/10, Batch 20/20, Loss: 0.4579
Epoch 5/10, Train Loss: 0.4752, Valid Loss: 0.4291
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5622
Epoch 6/10, Batch 20/20, Loss: 0.9023
Epoch 6/10, Train Loss: 0.4775, Valid Loss: 0.3940
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4852
Epoch 7/10, Batch 20/20, Loss: 0.4387
Epoch 7/10, Train Loss: 0.4010, Valid Loss: 0.3741
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2853
Epoch 8/10, Batch 20/20, Loss: 0.1734
Epoch 8/10, Train Loss: 0.3627, Valid Loss: 0.3527
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5397
Epoch 9/10, Batch 20/20, Loss: 0.6046
Epoch 9/10, Train Loss: 0.3536, Valid Loss: 0.3349
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2193
Epoch 10/10, Batch 20/20, Loss: 0.5169
Epoch 10/10, Train Loss: 0.3158, Valid Loss: 0.3213
Model saved!
Accuracy: 0.8890
Precision: 0.8835
Recall: 0.8890
F1-score: 0.8848
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 1. Fitness: 0.8890
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1967
Epoch 1/10, Batch 20/20, Loss: 1.1718
Epoch 1/10, Train Loss: 1.2998, Valid Loss: 0.9336
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8898
Epoch 2/10, Batch 20/20, Loss: 0.8890
Epoch 2/10, Train Loss: 0.8635, Valid Loss: 0.6594
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6032
Epoch 3/10, Batch 20/20, Loss: 0.9130
Epoch 3/10, Train Loss: 0.6570, Valid Loss: 0.5310
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6695
Epoch 4/10, Batch 20/20, Loss: 0.3218
Epoch 4/10, Train Loss: 0.5309, Valid Loss: 0.4720
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5595
Epoch 5/10, Batch 20/20, Loss: 0.6313
Epoch 5/10, Train Loss: 0.4679, Valid Loss: 0.4155
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5863
Epoch 6/10, Batch 20/20, Loss: 0.5664
Epoch 6/10, Train Loss: 0.4245, Valid Loss: 0.3870
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3930
Epoch 7/10, Batch 20/20, Loss: 0.4549
Epoch 7/10, Train Loss: 0.3775, Valid Loss: 0.3677
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2984
Epoch 8/10, Batch 20/20, Loss: 0.4390
Epoch 8/10, Train Loss: 0.3426, Valid Loss: 0.3422
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4799
Epoch 9/10, Batch 20/20, Loss: 0.5625
Epoch 9/10, Train Loss: 0.3243, Valid Loss: 0.3379
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2695
Epoch 10/10, Batch 20/20, Loss: 0.5033
Epoch 10/10, Train Loss: 0.2912, Valid Loss: 0.3245
Model saved!
Accuracy: 0.8808
Precision: 0.8755
Recall: 0.8808
F1-score: 0.8772
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2566
Epoch 1/10, Batch 20/20, Loss: 1.2441
Epoch 1/10, Train Loss: 1.3165, Valid Loss: 0.9380
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8251
Epoch 2/10, Batch 20/20, Loss: 0.9408
Epoch 2/10, Train Loss: 0.8582, Valid Loss: 0.6492
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5192
Epoch 3/10, Batch 20/20, Loss: 0.7558
Epoch 3/10, Train Loss: 0.6435, Valid Loss: 0.5180
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6194
Epoch 4/10, Batch 20/20, Loss: 0.4514
Epoch 4/10, Train Loss: 0.5234, Valid Loss: 0.4391
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4361
Epoch 5/10, Batch 20/20, Loss: 0.4593
Epoch 5/10, Train Loss: 0.4418, Valid Loss: 0.3947
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5470
Epoch 6/10, Batch 20/20, Loss: 0.7448
Epoch 6/10, Train Loss: 0.4169, Valid Loss: 0.3629
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3227
Epoch 7/10, Batch 20/20, Loss: 0.4678
Epoch 7/10, Train Loss: 0.3671, Valid Loss: 0.3377
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3002
Epoch 8/10, Batch 20/20, Loss: 0.5456
Epoch 8/10, Train Loss: 0.3424, Valid Loss: 0.3303
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4231
Epoch 9/10, Batch 20/20, Loss: 0.6541
Epoch 9/10, Train Loss: 0.3373, Valid Loss: 0.3199
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3104
Epoch 10/10, Batch 20/20, Loss: 0.3671
Epoch 10/10, Train Loss: 0.2848, Valid Loss: 0.3006
Model saved!
Accuracy: 0.8879
Precision: 0.8848
Recall: 0.8879
F1-score: 0.8860
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2383
Epoch 1/10, Batch 20/20, Loss: 1.0499
Epoch 1/10, Train Loss: 1.2830, Valid Loss: 0.9977
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8792
Epoch 2/10, Batch 20/20, Loss: 0.9945
Epoch 2/10, Train Loss: 0.8321, Valid Loss: 0.7179
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5418
Epoch 3/10, Batch 20/20, Loss: 0.7696
Epoch 3/10, Train Loss: 0.5861, Valid Loss: 0.6044
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5746
Epoch 4/10, Batch 20/20, Loss: 0.3763
Epoch 4/10, Train Loss: 0.4863, Valid Loss: 0.5376
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4938
Epoch 5/10, Batch 20/20, Loss: 0.5341
Epoch 5/10, Train Loss: 0.4097, Valid Loss: 0.4895
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4317
Epoch 6/10, Batch 20/20, Loss: 0.4690
Epoch 6/10, Train Loss: 0.3901, Valid Loss: 0.4500
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3455
Epoch 7/10, Batch 20/20, Loss: 0.3712
Epoch 7/10, Train Loss: 0.3360, Valid Loss: 0.4272
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2535
Epoch 8/10, Batch 20/20, Loss: 0.5593
Epoch 8/10, Train Loss: 0.3106, Valid Loss: 0.4019
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3898
Epoch 9/10, Batch 20/20, Loss: 0.3703
Epoch 9/10, Train Loss: 0.2885, Valid Loss: 0.3928
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3056
Epoch 10/10, Batch 20/20, Loss: 0.5162
Epoch 10/10, Train Loss: 0.2637, Valid Loss: 0.3751
Model saved!
Accuracy: 0.8820
Precision: 0.8752
Recall: 0.8820
F1-score: 0.8755
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2433
Epoch 1/10, Batch 20/20, Loss: 1.1935
Epoch 1/10, Train Loss: 1.3090, Valid Loss: 0.9319
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9097
Epoch 2/10, Batch 20/20, Loss: 1.0045
Epoch 2/10, Train Loss: 0.8706, Valid Loss: 0.6432
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6053
Epoch 3/10, Batch 20/20, Loss: 0.6124
Epoch 3/10, Train Loss: 0.6428, Valid Loss: 0.5148
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6866
Epoch 4/10, Batch 20/20, Loss: 0.4058
Epoch 4/10, Train Loss: 0.5326, Valid Loss: 0.4425
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4229
Epoch 5/10, Batch 20/20, Loss: 0.3510
Epoch 5/10, Train Loss: 0.4581, Valid Loss: 0.4049
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5695
Epoch 6/10, Batch 20/20, Loss: 0.2976
Epoch 6/10, Train Loss: 0.4249, Valid Loss: 0.3683
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4351
Epoch 7/10, Batch 20/20, Loss: 0.8448
Epoch 7/10, Train Loss: 0.4047, Valid Loss: 0.3483
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2948
Epoch 8/10, Batch 20/20, Loss: 0.5108
Epoch 8/10, Train Loss: 0.3490, Valid Loss: 0.3263
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4674
Epoch 9/10, Batch 20/20, Loss: 0.4431
Epoch 9/10, Train Loss: 0.3403, Valid Loss: 0.3082
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2886
Epoch 10/10, Batch 20/20, Loss: 0.3303
Epoch 10/10, Train Loss: 0.2853, Valid Loss: 0.3015
Model saved!
Accuracy: 0.8762
Precision: 0.8710
Recall: 0.8762
F1-score: 0.8720
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2953
Epoch 1/10, Batch 20/20, Loss: 1.2631
Epoch 1/10, Train Loss: 1.3212, Valid Loss: 0.9394
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8452
Epoch 2/10, Batch 20/20, Loss: 0.7898
Epoch 2/10, Train Loss: 0.8720, Valid Loss: 0.6606
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5733
Epoch 3/10, Batch 20/20, Loss: 0.5155
Epoch 3/10, Train Loss: 0.6418, Valid Loss: 0.5354
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7374
Epoch 4/10, Batch 20/20, Loss: 0.4641
Epoch 4/10, Train Loss: 0.5381, Valid Loss: 0.4708
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4034
Epoch 5/10, Batch 20/20, Loss: 0.3154
Epoch 5/10, Train Loss: 0.4334, Valid Loss: 0.4220
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.7442
Epoch 6/10, Batch 20/20, Loss: 0.6532
Epoch 6/10, Train Loss: 0.4383, Valid Loss: 0.3939
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.5468
Epoch 7/10, Batch 20/20, Loss: 0.2661
Epoch 7/10, Train Loss: 0.3793, Valid Loss: 0.3677
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3194
Epoch 8/10, Batch 20/20, Loss: 0.4392
Epoch 8/10, Train Loss: 0.3421, Valid Loss: 0.3565
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3981
Epoch 9/10, Batch 20/20, Loss: 0.5645
Epoch 9/10, Train Loss: 0.3313, Valid Loss: 0.3447
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2472
Epoch 10/10, Batch 20/20, Loss: 0.3223
Epoch 10/10, Train Loss: 0.2902, Valid Loss: 0.3383
Model saved!
Accuracy: 0.9030
Precision: 0.8988
Recall: 0.9030
F1-score: 0.8994
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 6. Fitness: 0.9030
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2633
Epoch 1/10, Batch 20/20, Loss: 1.1246
Epoch 1/10, Train Loss: 1.3084, Valid Loss: 0.9046
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8198
Epoch 2/10, Batch 20/20, Loss: 0.8244
Epoch 2/10, Train Loss: 0.8582, Valid Loss: 0.6203
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5379
Epoch 3/10, Batch 20/20, Loss: 0.5962
Epoch 3/10, Train Loss: 0.6143, Valid Loss: 0.4822
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6504
Epoch 4/10, Batch 20/20, Loss: 0.3640
Epoch 4/10, Train Loss: 0.5114, Valid Loss: 0.4022
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5257
Epoch 5/10, Batch 20/20, Loss: 0.4962
Epoch 5/10, Train Loss: 0.4407, Valid Loss: 0.3634
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5151
Epoch 6/10, Batch 20/20, Loss: 0.4254
Epoch 6/10, Train Loss: 0.3947, Valid Loss: 0.3313
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3910
Epoch 7/10, Batch 20/20, Loss: 0.1949
Epoch 7/10, Train Loss: 0.3502, Valid Loss: 0.3111
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2444
Epoch 8/10, Batch 20/20, Loss: 0.2881
Epoch 8/10, Train Loss: 0.3096, Valid Loss: 0.2925
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4103
Epoch 9/10, Batch 20/20, Loss: 0.4684
Epoch 9/10, Train Loss: 0.3124, Valid Loss: 0.2856
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2600
Epoch 10/10, Batch 20/20, Loss: 0.2341
Epoch 10/10, Train Loss: 0.2662, Valid Loss: 0.2719
Model saved!
Accuracy: 0.8867
Precision: 0.8811
Recall: 0.8867
F1-score: 0.8828
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1551
Epoch 1/10, Batch 20/20, Loss: 1.2623
Epoch 1/10, Train Loss: 1.3012, Valid Loss: 0.9067
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8224
Epoch 2/10, Batch 20/20, Loss: 0.8842
Epoch 2/10, Train Loss: 0.8452, Valid Loss: 0.6558
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4830
Epoch 3/10, Batch 20/20, Loss: 0.8514
Epoch 3/10, Train Loss: 0.6381, Valid Loss: 0.5362
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7251
Epoch 4/10, Batch 20/20, Loss: 0.4699
Epoch 4/10, Train Loss: 0.5184, Valid Loss: 0.4567
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3934
Epoch 5/10, Batch 20/20, Loss: 0.5294
Epoch 5/10, Train Loss: 0.4434, Valid Loss: 0.4106
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4736
Epoch 6/10, Batch 20/20, Loss: 0.6251
Epoch 6/10, Train Loss: 0.4367, Valid Loss: 0.3791
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3954
Epoch 7/10, Batch 20/20, Loss: 0.4608
Epoch 7/10, Train Loss: 0.3670, Valid Loss: 0.3624
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3447
Epoch 8/10, Batch 20/20, Loss: 0.4346
Epoch 8/10, Train Loss: 0.3442, Valid Loss: 0.3315
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3811
Epoch 9/10, Batch 20/20, Loss: 0.7365
Epoch 9/10, Train Loss: 0.3341, Valid Loss: 0.3260
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2736
Epoch 10/10, Batch 20/20, Loss: 0.4330
Epoch 10/10, Train Loss: 0.2784, Valid Loss: 0.3202
Model saved!
Accuracy: 0.8914
Precision: 0.8858
Recall: 0.8914
F1-score: 0.8864
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2213
Epoch 1/10, Batch 20/20, Loss: 1.1596
Epoch 1/10, Train Loss: 1.2917, Valid Loss: 0.9313
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8027
Epoch 2/10, Batch 20/20, Loss: 0.6965
Epoch 2/10, Train Loss: 0.8328, Valid Loss: 0.6536
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5345
Epoch 3/10, Batch 20/20, Loss: 0.6560
Epoch 3/10, Train Loss: 0.6104, Valid Loss: 0.5244
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6273
Epoch 4/10, Batch 20/20, Loss: 0.4408
Epoch 4/10, Train Loss: 0.5079, Valid Loss: 0.4634
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4853
Epoch 5/10, Batch 20/20, Loss: 0.6659
Epoch 5/10, Train Loss: 0.4403, Valid Loss: 0.4165
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5166
Epoch 6/10, Batch 20/20, Loss: 0.6590
Epoch 6/10, Train Loss: 0.3985, Valid Loss: 0.3837
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3799
Epoch 7/10, Batch 20/20, Loss: 0.4366
Epoch 7/10, Train Loss: 0.3539, Valid Loss: 0.3705
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2872
Epoch 8/10, Batch 20/20, Loss: 0.2139
Epoch 8/10, Train Loss: 0.3066, Valid Loss: 0.3542
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.6546
Epoch 9/10, Batch 20/20, Loss: 0.3588
Epoch 9/10, Train Loss: 0.3039, Valid Loss: 0.3519
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2205
Epoch 10/10, Batch 20/20, Loss: 0.3307
Epoch 10/10, Train Loss: 0.2664, Valid Loss: 0.3330
Model saved!
Accuracy: 0.8914
Precision: 0.8863
Recall: 0.8914
F1-score: 0.8861
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1983
Epoch 1/10, Batch 20/20, Loss: 1.1611
Epoch 1/10, Train Loss: 1.2741, Valid Loss: 0.9607
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8517
Epoch 2/10, Batch 20/20, Loss: 0.9716
Epoch 2/10, Train Loss: 0.8243, Valid Loss: 0.7012
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6090
Epoch 3/10, Batch 20/20, Loss: 0.7715
Epoch 3/10, Train Loss: 0.6124, Valid Loss: 0.5749
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6201
Epoch 4/10, Batch 20/20, Loss: 0.4653
Epoch 4/10, Train Loss: 0.4916, Valid Loss: 0.4998
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4250
Epoch 5/10, Batch 20/20, Loss: 0.3458
Epoch 5/10, Train Loss: 0.4046, Valid Loss: 0.4477
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5011
Epoch 6/10, Batch 20/20, Loss: 0.6618
Epoch 6/10, Train Loss: 0.3936, Valid Loss: 0.4239
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4479
Epoch 7/10, Batch 20/20, Loss: 0.3595
Epoch 7/10, Train Loss: 0.3413, Valid Loss: 0.3935
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3039
Epoch 8/10, Batch 20/20, Loss: 0.2439
Epoch 8/10, Train Loss: 0.2937, Valid Loss: 0.3815
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4800
Epoch 9/10, Batch 20/20, Loss: 0.3218
Epoch 9/10, Train Loss: 0.2961, Valid Loss: 0.3671
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2694
Epoch 10/10, Batch 20/20, Loss: 0.2486
Epoch 10/10, Train Loss: 0.2477, Valid Loss: 0.3595
Model saved!
Accuracy: 0.8808
Precision: 0.8754
Recall: 0.8808
F1-score: 0.8769
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3029
Epoch 1/10, Batch 20/20, Loss: 1.2762
Epoch 1/10, Train Loss: 1.3154, Valid Loss: 0.9433
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8255
Epoch 2/10, Batch 20/20, Loss: 0.9481
Epoch 2/10, Train Loss: 0.8644, Valid Loss: 0.6864
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5826
Epoch 3/10, Batch 20/20, Loss: 0.6858
Epoch 3/10, Train Loss: 0.6273, Valid Loss: 0.5473
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5427
Epoch 4/10, Batch 20/20, Loss: 0.5588
Epoch 4/10, Train Loss: 0.5173, Valid Loss: 0.4709
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5035
Epoch 5/10, Batch 20/20, Loss: 0.2950
Epoch 5/10, Train Loss: 0.4299, Valid Loss: 0.4343
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5701
Epoch 6/10, Batch 20/20, Loss: 0.4134
Epoch 6/10, Train Loss: 0.4136, Valid Loss: 0.3910
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3257
Epoch 7/10, Batch 20/20, Loss: 0.5319
Epoch 7/10, Train Loss: 0.3801, Valid Loss: 0.3725
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3013
Epoch 8/10, Batch 20/20, Loss: 0.3577
Epoch 8/10, Train Loss: 0.3332, Valid Loss: 0.3512
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5485
Epoch 9/10, Batch 20/20, Loss: 0.4055
Epoch 9/10, Train Loss: 0.3140, Valid Loss: 0.3370
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1850
Epoch 10/10, Batch 20/20, Loss: 0.4530
Epoch 10/10, Train Loss: 0.2708, Valid Loss: 0.3282
Model saved!
Accuracy: 0.8867
Precision: 0.8815
Recall: 0.8867
F1-score: 0.8825
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3121
Epoch 1/10, Batch 20/20, Loss: 1.1567
Epoch 1/10, Train Loss: 1.3141, Valid Loss: 0.9608
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8043
Epoch 2/10, Batch 20/20, Loss: 0.7874
Epoch 2/10, Train Loss: 0.8776, Valid Loss: 0.6953
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5809
Epoch 3/10, Batch 20/20, Loss: 0.6462
Epoch 3/10, Train Loss: 0.6716, Valid Loss: 0.5643
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6751
Epoch 4/10, Batch 20/20, Loss: 0.4293
Epoch 4/10, Train Loss: 0.5642, Valid Loss: 0.4933
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4812
Epoch 5/10, Batch 20/20, Loss: 0.6552
Epoch 5/10, Train Loss: 0.4913, Valid Loss: 0.4518
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5655
Epoch 6/10, Batch 20/20, Loss: 0.5527
Epoch 6/10, Train Loss: 0.4641, Valid Loss: 0.4078
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4264
Epoch 7/10, Batch 20/20, Loss: 0.4407
Epoch 7/10, Train Loss: 0.4085, Valid Loss: 0.3896
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2658
Epoch 8/10, Batch 20/20, Loss: 0.2919
Epoch 8/10, Train Loss: 0.3732, Valid Loss: 0.3674
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5871
Epoch 9/10, Batch 20/20, Loss: 0.5379
Epoch 9/10, Train Loss: 0.3735, Valid Loss: 0.3601
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2774
Epoch 10/10, Batch 20/20, Loss: 0.1366
Epoch 10/10, Train Loss: 0.3259, Valid Loss: 0.3521
Model saved!
Accuracy: 0.8879
Precision: 0.8827
Recall: 0.8879
F1-score: 0.8836
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2679
Epoch 1/10, Batch 20/20, Loss: 1.2259
Epoch 1/10, Train Loss: 1.3019, Valid Loss: 0.9196
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8464
Epoch 2/10, Batch 20/20, Loss: 0.7449
Epoch 2/10, Train Loss: 0.8375, Valid Loss: 0.6561
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5752
Epoch 3/10, Batch 20/20, Loss: 0.5091
Epoch 3/10, Train Loss: 0.6174, Valid Loss: 0.5168
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5823
Epoch 4/10, Batch 20/20, Loss: 0.4391
Epoch 4/10, Train Loss: 0.5004, Valid Loss: 0.4412
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3587
Epoch 5/10, Batch 20/20, Loss: 0.7127
Epoch 5/10, Train Loss: 0.4330, Valid Loss: 0.3928
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4636
Epoch 6/10, Batch 20/20, Loss: 0.6837
Epoch 6/10, Train Loss: 0.4073, Valid Loss: 0.3549
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3621
Epoch 7/10, Batch 20/20, Loss: 0.3387
Epoch 7/10, Train Loss: 0.3597, Valid Loss: 0.3441
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3267
Epoch 8/10, Batch 20/20, Loss: 0.2988
Epoch 8/10, Train Loss: 0.3193, Valid Loss: 0.3091
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3788
Epoch 9/10, Batch 20/20, Loss: 0.4257
Epoch 9/10, Train Loss: 0.3056, Valid Loss: 0.3031
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2345
Epoch 10/10, Batch 20/20, Loss: 0.3180
Epoch 10/10, Train Loss: 0.2637, Valid Loss: 0.2829
Model saved!
Accuracy: 0.8750
Precision: 0.8685
Recall: 0.8750
F1-score: 0.8705
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2301
Epoch 1/10, Batch 20/20, Loss: 1.1372
Epoch 1/10, Train Loss: 1.2885, Valid Loss: 0.9568
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8720
Epoch 2/10, Batch 20/20, Loss: 0.9933
Epoch 2/10, Train Loss: 0.8253, Valid Loss: 0.6970
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4933
Epoch 3/10, Batch 20/20, Loss: 0.8647
Epoch 3/10, Train Loss: 0.6151, Valid Loss: 0.5663
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7181
Epoch 4/10, Batch 20/20, Loss: 0.6436
Epoch 4/10, Train Loss: 0.5056, Valid Loss: 0.4875
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4080
Epoch 5/10, Batch 20/20, Loss: 0.4796
Epoch 5/10, Train Loss: 0.4206, Valid Loss: 0.4390
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4953
Epoch 6/10, Batch 20/20, Loss: 0.4096
Epoch 6/10, Train Loss: 0.4007, Valid Loss: 0.3946
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4105
Epoch 7/10, Batch 20/20, Loss: 0.4785
Epoch 7/10, Train Loss: 0.3463, Valid Loss: 0.3745
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2969
Epoch 8/10, Batch 20/20, Loss: 0.2915
Epoch 8/10, Train Loss: 0.3136, Valid Loss: 0.3727
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4383
Epoch 9/10, Batch 20/20, Loss: 0.6391
Epoch 9/10, Train Loss: 0.3187, Valid Loss: 0.3453
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2705
Epoch 10/10, Batch 20/20, Loss: 0.2549
Epoch 10/10, Train Loss: 0.2642, Valid Loss: 0.3420
Model saved!
Accuracy: 0.8785
Precision: 0.8721
Recall: 0.8785
F1-score: 0.8733
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2931
Epoch 1/10, Batch 20/20, Loss: 1.2795
Epoch 1/10, Train Loss: 1.2953, Valid Loss: 0.9492
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8635
Epoch 2/10, Batch 20/20, Loss: 0.6950
Epoch 2/10, Train Loss: 0.8408, Valid Loss: 0.6708
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5689
Epoch 3/10, Batch 20/20, Loss: 0.8477
Epoch 3/10, Train Loss: 0.6362, Valid Loss: 0.5559
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7127
Epoch 4/10, Batch 20/20, Loss: 0.5179
Epoch 4/10, Train Loss: 0.5209, Valid Loss: 0.4787
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4580
Epoch 5/10, Batch 20/20, Loss: 0.4302
Epoch 5/10, Train Loss: 0.4411, Valid Loss: 0.4415
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5797
Epoch 6/10, Batch 20/20, Loss: 0.6499
Epoch 6/10, Train Loss: 0.4301, Valid Loss: 0.4014
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4947
Epoch 7/10, Batch 20/20, Loss: 0.4291
Epoch 7/10, Train Loss: 0.3668, Valid Loss: 0.3849
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3148
Epoch 8/10, Batch 20/20, Loss: 0.3231
Epoch 8/10, Train Loss: 0.3393, Valid Loss: 0.3709
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4179
Epoch 9/10, Batch 20/20, Loss: 0.5070
Epoch 9/10, Train Loss: 0.3302, Valid Loss: 0.3639
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3424
Epoch 10/10, Batch 20/20, Loss: 0.2152
Epoch 10/10, Train Loss: 0.2717, Valid Loss: 0.3450
Model saved!
Accuracy: 0.8738
Precision: 0.8714
Recall: 0.8738
F1-score: 0.8710
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2020
Epoch 1/10, Batch 20/20, Loss: 1.3131
Epoch 1/10, Train Loss: 1.3027, Valid Loss: 0.9713
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8110
Epoch 2/10, Batch 20/20, Loss: 0.8598
Epoch 2/10, Train Loss: 0.8467, Valid Loss: 0.7137
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6155
Epoch 3/10, Batch 20/20, Loss: 0.7704
Epoch 3/10, Train Loss: 0.6381, Valid Loss: 0.5854
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6497
Epoch 4/10, Batch 20/20, Loss: 0.3647
Epoch 4/10, Train Loss: 0.5142, Valid Loss: 0.5227
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3962
Epoch 5/10, Batch 20/20, Loss: 0.2854
Epoch 5/10, Train Loss: 0.4239, Valid Loss: 0.4714
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4657
Epoch 6/10, Batch 20/20, Loss: 0.6751
Epoch 6/10, Train Loss: 0.4211, Valid Loss: 0.4274
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3699
Epoch 7/10, Batch 20/20, Loss: 0.3372
Epoch 7/10, Train Loss: 0.3482, Valid Loss: 0.3986
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3464
Epoch 8/10, Batch 20/20, Loss: 0.3736
Epoch 8/10, Train Loss: 0.3295, Valid Loss: 0.3909
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4557
Epoch 9/10, Batch 20/20, Loss: 0.5160
Epoch 9/10, Train Loss: 0.3081, Valid Loss: 0.3735
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2809
Epoch 10/10, Batch 20/20, Loss: 0.2214
Epoch 10/10, Train Loss: 0.2701, Valid Loss: 0.3587
Model saved!
Accuracy: 0.8820
Precision: 0.8760
Recall: 0.8820
F1-score: 0.8774
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2405
Epoch 1/10, Batch 20/20, Loss: 1.2817
Epoch 1/10, Train Loss: 1.3162, Valid Loss: 0.9759
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8279
Epoch 2/10, Batch 20/20, Loss: 0.8997
Epoch 2/10, Train Loss: 0.8407, Valid Loss: 0.7195
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5459
Epoch 3/10, Batch 20/20, Loss: 0.7182
Epoch 3/10, Train Loss: 0.6194, Valid Loss: 0.5910
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6328
Epoch 4/10, Batch 20/20, Loss: 0.4407
Epoch 4/10, Train Loss: 0.5179, Valid Loss: 0.5186
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5061
Epoch 5/10, Batch 20/20, Loss: 0.3428
Epoch 5/10, Train Loss: 0.4205, Valid Loss: 0.4841
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5778
Epoch 6/10, Batch 20/20, Loss: 0.7142
Epoch 6/10, Train Loss: 0.4103, Valid Loss: 0.4497
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3843
Epoch 7/10, Batch 20/20, Loss: 0.3331
Epoch 7/10, Train Loss: 0.3526, Valid Loss: 0.4306
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3451
Epoch 8/10, Batch 20/20, Loss: 0.2479
Epoch 8/10, Train Loss: 0.3184, Valid Loss: 0.4178
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.6401
Epoch 9/10, Batch 20/20, Loss: 0.8767
Epoch 9/10, Train Loss: 0.3387, Valid Loss: 0.3993
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2969
Epoch 10/10, Batch 20/20, Loss: 0.2567
Epoch 10/10, Train Loss: 0.2580, Valid Loss: 0.3914
Model saved!
Accuracy: 0.8750
Precision: 0.8713
Recall: 0.8750
F1-score: 0.8724
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2271
Epoch 1/10, Batch 20/20, Loss: 1.3453
Epoch 1/10, Train Loss: 1.3051, Valid Loss: 0.9327
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8210
Epoch 2/10, Batch 20/20, Loss: 0.8107
Epoch 2/10, Train Loss: 0.8464, Valid Loss: 0.6598
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4972
Epoch 3/10, Batch 20/20, Loss: 0.9119
Epoch 3/10, Train Loss: 0.6403, Valid Loss: 0.5282
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6469
Epoch 4/10, Batch 20/20, Loss: 0.4047
Epoch 4/10, Train Loss: 0.5185, Valid Loss: 0.4565
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4458
Epoch 5/10, Batch 20/20, Loss: 0.5213
Epoch 5/10, Train Loss: 0.4503, Valid Loss: 0.4127
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4975
Epoch 6/10, Batch 20/20, Loss: 0.5918
Epoch 6/10, Train Loss: 0.4268, Valid Loss: 0.3736
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4142
Epoch 7/10, Batch 20/20, Loss: 0.3419
Epoch 7/10, Train Loss: 0.3675, Valid Loss: 0.3614
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2744
Epoch 8/10, Batch 20/20, Loss: 0.2934
Epoch 8/10, Train Loss: 0.3352, Valid Loss: 0.3356
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4360
Epoch 9/10, Batch 20/20, Loss: 0.7030
Epoch 9/10, Train Loss: 0.3334, Valid Loss: 0.3259
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2535
Epoch 10/10, Batch 20/20, Loss: 0.2457
Epoch 10/10, Train Loss: 0.2713, Valid Loss: 0.3045
Model saved!
Accuracy: 0.8773
Precision: 0.8702
Recall: 0.8773
F1-score: 0.8718
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1861
Epoch 1/10, Batch 20/20, Loss: 1.0441
Epoch 1/10, Train Loss: 1.2748, Valid Loss: 0.9312
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7878
Epoch 2/10, Batch 20/20, Loss: 0.7230
Epoch 2/10, Train Loss: 0.8106, Valid Loss: 0.6809
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5094
Epoch 3/10, Batch 20/20, Loss: 0.8165
Epoch 3/10, Train Loss: 0.6047, Valid Loss: 0.5448
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7359
Epoch 4/10, Batch 20/20, Loss: 0.5665
Epoch 4/10, Train Loss: 0.4893, Valid Loss: 0.4666
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4570
Epoch 5/10, Batch 20/20, Loss: 0.3002
Epoch 5/10, Train Loss: 0.4139, Valid Loss: 0.4147
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6332
Epoch 6/10, Batch 20/20, Loss: 0.3624
Epoch 6/10, Train Loss: 0.3926, Valid Loss: 0.3902
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4048
Epoch 7/10, Batch 20/20, Loss: 0.5454
Epoch 7/10, Train Loss: 0.3606, Valid Loss: 0.3625
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2664
Epoch 8/10, Batch 20/20, Loss: 0.1642
Epoch 8/10, Train Loss: 0.3178, Valid Loss: 0.3497
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4857
Epoch 9/10, Batch 20/20, Loss: 0.6936
Epoch 9/10, Train Loss: 0.3090, Valid Loss: 0.3286
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2146
Epoch 10/10, Batch 20/20, Loss: 0.2436
Epoch 10/10, Train Loss: 0.2505, Valid Loss: 0.3216
Model saved!
Accuracy: 0.8715
Precision: 0.8638
Recall: 0.8715
F1-score: 0.8644
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2008
Epoch 1/10, Batch 20/20, Loss: 1.1710
Epoch 1/10, Train Loss: 1.2892, Valid Loss: 0.9525
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8392
Epoch 2/10, Batch 20/20, Loss: 0.7326
Epoch 2/10, Train Loss: 0.8488, Valid Loss: 0.6775
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6802
Epoch 3/10, Batch 20/20, Loss: 0.8172
Epoch 3/10, Train Loss: 0.6442, Valid Loss: 0.5557
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7335
Epoch 4/10, Batch 20/20, Loss: 0.7198
Epoch 4/10, Train Loss: 0.5443, Valid Loss: 0.4907
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5592
Epoch 5/10, Batch 20/20, Loss: 0.3141
Epoch 5/10, Train Loss: 0.4389, Valid Loss: 0.4513
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5371
Epoch 6/10, Batch 20/20, Loss: 0.5194
Epoch 6/10, Train Loss: 0.4281, Valid Loss: 0.4195
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3409
Epoch 7/10, Batch 20/20, Loss: 0.2784
Epoch 7/10, Train Loss: 0.3714, Valid Loss: 0.4017
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3476
Epoch 8/10, Batch 20/20, Loss: 0.2551
Epoch 8/10, Train Loss: 0.3457, Valid Loss: 0.3847
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4717
Epoch 9/10, Batch 20/20, Loss: 0.5915
Epoch 9/10, Train Loss: 0.3338, Valid Loss: 0.3790
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2023
Epoch 10/10, Batch 20/20, Loss: 0.1731
Epoch 10/10, Train Loss: 0.2711, Valid Loss: 0.3620
Model saved!
Accuracy: 0.8867
Precision: 0.8808
Recall: 0.8867
F1-score: 0.8828
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2454
Epoch 1/10, Batch 20/20, Loss: 1.1348
Epoch 1/10, Train Loss: 1.3067, Valid Loss: 0.9734
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8106
Epoch 2/10, Batch 20/20, Loss: 0.8451
Epoch 2/10, Train Loss: 0.8515, Valid Loss: 0.7012
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6578
Epoch 3/10, Batch 20/20, Loss: 0.9893
Epoch 3/10, Train Loss: 0.6445, Valid Loss: 0.5674
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6950
Epoch 4/10, Batch 20/20, Loss: 0.5224
Epoch 4/10, Train Loss: 0.5214, Valid Loss: 0.5033
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4336
Epoch 5/10, Batch 20/20, Loss: 0.4384
Epoch 5/10, Train Loss: 0.4344, Valid Loss: 0.4458
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5230
Epoch 6/10, Batch 20/20, Loss: 0.6761
Epoch 6/10, Train Loss: 0.4359, Valid Loss: 0.4172
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4156
Epoch 7/10, Batch 20/20, Loss: 0.2987
Epoch 7/10, Train Loss: 0.3663, Valid Loss: 0.3997
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2935
Epoch 8/10, Batch 20/20, Loss: 0.1983
Epoch 8/10, Train Loss: 0.3303, Valid Loss: 0.3768
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3448
Epoch 9/10, Batch 20/20, Loss: 0.4380
Epoch 9/10, Train Loss: 0.3223, Valid Loss: 0.3630
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2442
Epoch 10/10, Batch 20/20, Loss: 0.2723
Epoch 10/10, Train Loss: 0.2752, Valid Loss: 0.3526
Model saved!
Accuracy: 0.8832
Precision: 0.8780
Recall: 0.8832
F1-score: 0.8798
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2567
Epoch 1/10, Batch 20/20, Loss: 1.2496
Epoch 1/10, Train Loss: 1.3122, Valid Loss: 0.9237
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9282
Epoch 2/10, Batch 20/20, Loss: 0.9363
Epoch 2/10, Train Loss: 0.8720, Valid Loss: 0.6484
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5616
Epoch 3/10, Batch 20/20, Loss: 0.6235
Epoch 3/10, Train Loss: 0.6440, Valid Loss: 0.5118
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7171
Epoch 4/10, Batch 20/20, Loss: 0.5114
Epoch 4/10, Train Loss: 0.5637, Valid Loss: 0.4411
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4777
Epoch 5/10, Batch 20/20, Loss: 0.3964
Epoch 5/10, Train Loss: 0.4685, Valid Loss: 0.3948
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4903
Epoch 6/10, Batch 20/20, Loss: 0.7414
Epoch 6/10, Train Loss: 0.4552, Valid Loss: 0.3515
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4985
Epoch 7/10, Batch 20/20, Loss: 0.6305
Epoch 7/10, Train Loss: 0.4120, Valid Loss: 0.3298
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2214
Epoch 8/10, Batch 20/20, Loss: 0.3877
Epoch 8/10, Train Loss: 0.3651, Valid Loss: 0.3114
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4802
Epoch 9/10, Batch 20/20, Loss: 0.4774
Epoch 9/10, Train Loss: 0.3475, Valid Loss: 0.2971
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3026
Epoch 10/10, Batch 20/20, Loss: 0.1873
Epoch 10/10, Train Loss: 0.3034, Valid Loss: 0.2844
Model saved!
Accuracy: 0.9007
Precision: 0.8979
Recall: 0.9007
F1-score: 0.8990
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2122
Epoch 1/10, Batch 20/20, Loss: 1.3670
Epoch 1/10, Train Loss: 1.3168, Valid Loss: 0.9190
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8588
Epoch 2/10, Batch 20/20, Loss: 0.9251
Epoch 2/10, Train Loss: 0.8470, Valid Loss: 0.6413
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5641
Epoch 3/10, Batch 20/20, Loss: 0.6920
Epoch 3/10, Train Loss: 0.6251, Valid Loss: 0.5162
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6880
Epoch 4/10, Batch 20/20, Loss: 0.2657
Epoch 4/10, Train Loss: 0.5006, Valid Loss: 0.4466
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4118
Epoch 5/10, Batch 20/20, Loss: 0.4581
Epoch 5/10, Train Loss: 0.4295, Valid Loss: 0.4043
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6515
Epoch 6/10, Batch 20/20, Loss: 0.3795
Epoch 6/10, Train Loss: 0.4105, Valid Loss: 0.3744
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4385
Epoch 7/10, Batch 20/20, Loss: 0.3114
Epoch 7/10, Train Loss: 0.3529, Valid Loss: 0.3574
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3099
Epoch 8/10, Batch 20/20, Loss: 0.2972
Epoch 8/10, Train Loss: 0.3094, Valid Loss: 0.3391
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5954
Epoch 9/10, Batch 20/20, Loss: 0.4453
Epoch 9/10, Train Loss: 0.3088, Valid Loss: 0.3302
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2330
Epoch 10/10, Batch 20/20, Loss: 0.3870
Epoch 10/10, Train Loss: 0.2686, Valid Loss: 0.3118
Model saved!
Accuracy: 0.8937
Precision: 0.8876
Recall: 0.8937
F1-score: 0.8894
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2521
Epoch 1/10, Batch 20/20, Loss: 1.1799
Epoch 1/10, Train Loss: 1.3072, Valid Loss: 0.9303
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8782
Epoch 2/10, Batch 20/20, Loss: 0.8730
Epoch 2/10, Train Loss: 0.8571, Valid Loss: 0.6437
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5843
Epoch 3/10, Batch 20/20, Loss: 0.7937
Epoch 3/10, Train Loss: 0.6478, Valid Loss: 0.5033
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6286
Epoch 4/10, Batch 20/20, Loss: 0.4535
Epoch 4/10, Train Loss: 0.5233, Valid Loss: 0.4262
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4722
Epoch 5/10, Batch 20/20, Loss: 0.4268
Epoch 5/10, Train Loss: 0.4583, Valid Loss: 0.3817
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4744
Epoch 6/10, Batch 20/20, Loss: 0.7312
Epoch 6/10, Train Loss: 0.4407, Valid Loss: 0.3415
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4106
Epoch 7/10, Batch 20/20, Loss: 0.2787
Epoch 7/10, Train Loss: 0.3799, Valid Loss: 0.3197
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3806
Epoch 8/10, Batch 20/20, Loss: 0.5914
Epoch 8/10, Train Loss: 0.3575, Valid Loss: 0.2983
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4009
Epoch 9/10, Batch 20/20, Loss: 0.7791
Epoch 9/10, Train Loss: 0.3442, Valid Loss: 0.2801
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2044
Epoch 10/10, Batch 20/20, Loss: 0.4037
Epoch 10/10, Train Loss: 0.2909, Valid Loss: 0.2706
Model saved!
Accuracy: 0.8879
Precision: 0.8809
Recall: 0.8879
F1-score: 0.8826
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2327
Epoch 1/10, Batch 20/20, Loss: 1.2677
Epoch 1/10, Train Loss: 1.2887, Valid Loss: 0.9116
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7990
Epoch 2/10, Batch 20/20, Loss: 1.1447
Epoch 2/10, Train Loss: 0.8351, Valid Loss: 0.6400
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4917
Epoch 3/10, Batch 20/20, Loss: 0.8575
Epoch 3/10, Train Loss: 0.6190, Valid Loss: 0.5193
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6489
Epoch 4/10, Batch 20/20, Loss: 0.5278
Epoch 4/10, Train Loss: 0.5165, Valid Loss: 0.4496
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3672
Epoch 5/10, Batch 20/20, Loss: 0.3980
Epoch 5/10, Train Loss: 0.4362, Valid Loss: 0.3988
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4432
Epoch 6/10, Batch 20/20, Loss: 0.5233
Epoch 6/10, Train Loss: 0.4163, Valid Loss: 0.3672
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4084
Epoch 7/10, Batch 20/20, Loss: 0.5120
Epoch 7/10, Train Loss: 0.3812, Valid Loss: 0.3346
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2762
Epoch 8/10, Batch 20/20, Loss: 0.1707
Epoch 8/10, Train Loss: 0.3414, Valid Loss: 0.3157
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4122
Epoch 9/10, Batch 20/20, Loss: 0.5694
Epoch 9/10, Train Loss: 0.3278, Valid Loss: 0.3031
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3064
Epoch 10/10, Batch 20/20, Loss: 0.2741
Epoch 10/10, Train Loss: 0.2786, Valid Loss: 0.2967
Model saved!
Accuracy: 0.8949
Precision: 0.8910
Recall: 0.8949
F1-score: 0.8920
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3254
Epoch 1/10, Batch 20/20, Loss: 1.0985
Epoch 1/10, Train Loss: 1.3033, Valid Loss: 0.9947
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8922
Epoch 2/10, Batch 20/20, Loss: 0.7212
Epoch 2/10, Train Loss: 0.8701, Valid Loss: 0.7369
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5611
Epoch 3/10, Batch 20/20, Loss: 0.8474
Epoch 3/10, Train Loss: 0.6632, Valid Loss: 0.6178
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7882
Epoch 4/10, Batch 20/20, Loss: 0.6028
Epoch 4/10, Train Loss: 0.5462, Valid Loss: 0.5453
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3612
Epoch 5/10, Batch 20/20, Loss: 0.5517
Epoch 5/10, Train Loss: 0.4667, Valid Loss: 0.5024
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6336
Epoch 6/10, Batch 20/20, Loss: 0.6094
Epoch 6/10, Train Loss: 0.4460, Valid Loss: 0.4585
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.5225
Epoch 7/10, Batch 20/20, Loss: 0.4679
Epoch 7/10, Train Loss: 0.3860, Valid Loss: 0.4420
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3762
Epoch 8/10, Batch 20/20, Loss: 0.4154
Epoch 8/10, Train Loss: 0.3610, Valid Loss: 0.4279
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4494
Epoch 9/10, Batch 20/20, Loss: 0.6723
Epoch 9/10, Train Loss: 0.3557, Valid Loss: 0.4092
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3569
Epoch 10/10, Batch 20/20, Loss: 0.2500
Epoch 10/10, Train Loss: 0.3074, Valid Loss: 0.3966
Model saved!
Accuracy: 0.8867
Precision: 0.8836
Recall: 0.8867
F1-score: 0.8849
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2483
Epoch 1/10, Batch 20/20, Loss: 1.1517
Epoch 1/10, Train Loss: 1.2964, Valid Loss: 0.9564
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9047
Epoch 2/10, Batch 20/20, Loss: 0.9570
Epoch 2/10, Train Loss: 0.8589, Valid Loss: 0.6898
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5452
Epoch 3/10, Batch 20/20, Loss: 0.8018
Epoch 3/10, Train Loss: 0.6410, Valid Loss: 0.5398
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6660
Epoch 4/10, Batch 20/20, Loss: 0.5563
Epoch 4/10, Train Loss: 0.5338, Valid Loss: 0.4594
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4282
Epoch 5/10, Batch 20/20, Loss: 0.4665
Epoch 5/10, Train Loss: 0.4412, Valid Loss: 0.4062
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4588
Epoch 6/10, Batch 20/20, Loss: 0.6363
Epoch 6/10, Train Loss: 0.4268, Valid Loss: 0.3715
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3553
Epoch 7/10, Batch 20/20, Loss: 0.4996
Epoch 7/10, Train Loss: 0.3713, Valid Loss: 0.3499
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2975
Epoch 8/10, Batch 20/20, Loss: 0.4355
Epoch 8/10, Train Loss: 0.3335, Valid Loss: 0.3240
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.7134
Epoch 9/10, Batch 20/20, Loss: 0.4059
Epoch 9/10, Train Loss: 0.3280, Valid Loss: 0.3228
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2720
Epoch 10/10, Batch 20/20, Loss: 0.3707
Epoch 10/10, Train Loss: 0.2896, Valid Loss: 0.3065
Model saved!
Accuracy: 0.8867
Precision: 0.8811
Recall: 0.8867
F1-score: 0.8827
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1847
Epoch 1/10, Batch 20/20, Loss: 1.1454
Epoch 1/10, Train Loss: 1.2975, Valid Loss: 1.0064
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8702
Epoch 2/10, Batch 20/20, Loss: 0.9706
Epoch 2/10, Train Loss: 0.8590, Valid Loss: 0.7465
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5253
Epoch 3/10, Batch 20/20, Loss: 0.6814
Epoch 3/10, Train Loss: 0.6264, Valid Loss: 0.6094
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6846
Epoch 4/10, Batch 20/20, Loss: 0.4045
Epoch 4/10, Train Loss: 0.5114, Valid Loss: 0.5333
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4635
Epoch 5/10, Batch 20/20, Loss: 0.5090
Epoch 5/10, Train Loss: 0.4361, Valid Loss: 0.4869
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6947
Epoch 6/10, Batch 20/20, Loss: 0.5818
Epoch 6/10, Train Loss: 0.4272, Valid Loss: 0.4489
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3437
Epoch 7/10, Batch 20/20, Loss: 0.3060
Epoch 7/10, Train Loss: 0.3727, Valid Loss: 0.4198
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2208
Epoch 8/10, Batch 20/20, Loss: 0.3817
Epoch 8/10, Train Loss: 0.3275, Valid Loss: 0.4055
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5585
Epoch 9/10, Batch 20/20, Loss: 1.1651
Epoch 9/10, Train Loss: 0.3458, Valid Loss: 0.3883
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2382
Epoch 10/10, Batch 20/20, Loss: 0.2592
Epoch 10/10, Train Loss: 0.2846, Valid Loss: 0.3791
Model saved!
Accuracy: 0.8832
Precision: 0.8773
Recall: 0.8832
F1-score: 0.8783
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2884
Epoch 1/10, Batch 20/20, Loss: 1.1996
Epoch 1/10, Train Loss: 1.2972, Valid Loss: 0.9498
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8364
Epoch 2/10, Batch 20/20, Loss: 1.1695
Epoch 2/10, Train Loss: 0.8584, Valid Loss: 0.6888
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5459
Epoch 3/10, Batch 20/20, Loss: 0.9939
Epoch 3/10, Train Loss: 0.6532, Valid Loss: 0.5673
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6455
Epoch 4/10, Batch 20/20, Loss: 0.5424
Epoch 4/10, Train Loss: 0.5406, Valid Loss: 0.5033
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4341
Epoch 5/10, Batch 20/20, Loss: 0.3575
Epoch 5/10, Train Loss: 0.4466, Valid Loss: 0.4520
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6337
Epoch 6/10, Batch 20/20, Loss: 0.6006
Epoch 6/10, Train Loss: 0.4457, Valid Loss: 0.4181
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.5952
Epoch 7/10, Batch 20/20, Loss: 0.3617
Epoch 7/10, Train Loss: 0.3792, Valid Loss: 0.3996
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3835
Epoch 8/10, Batch 20/20, Loss: 0.3847
Epoch 8/10, Train Loss: 0.3535, Valid Loss: 0.3802
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3233
Epoch 9/10, Batch 20/20, Loss: 0.5860
Epoch 9/10, Train Loss: 0.3408, Valid Loss: 0.3704
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1792
Epoch 10/10, Batch 20/20, Loss: 0.3920
Epoch 10/10, Train Loss: 0.3013, Valid Loss: 0.3493
Model saved!
Accuracy: 0.8902
Precision: 0.8845
Recall: 0.8902
F1-score: 0.8863
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1783
Epoch 1/10, Batch 20/20, Loss: 1.1099
Epoch 1/10, Train Loss: 1.2857, Valid Loss: 0.9039
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8122
Epoch 2/10, Batch 20/20, Loss: 0.7766
Epoch 2/10, Train Loss: 0.8177, Valid Loss: 0.6120
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5881
Epoch 3/10, Batch 20/20, Loss: 0.5360
Epoch 3/10, Train Loss: 0.6024, Valid Loss: 0.4803
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6363
Epoch 4/10, Batch 20/20, Loss: 0.4809
Epoch 4/10, Train Loss: 0.4830, Valid Loss: 0.4055
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4336
Epoch 5/10, Batch 20/20, Loss: 0.4575
Epoch 5/10, Train Loss: 0.4134, Valid Loss: 0.3652
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4671
Epoch 6/10, Batch 20/20, Loss: 0.7906
Epoch 6/10, Train Loss: 0.4030, Valid Loss: 0.3305
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3227
Epoch 7/10, Batch 20/20, Loss: 0.4172
Epoch 7/10, Train Loss: 0.3470, Valid Loss: 0.3046
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2795
Epoch 8/10, Batch 20/20, Loss: 0.2164
Epoch 8/10, Train Loss: 0.3056, Valid Loss: 0.2954
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4957
Epoch 9/10, Batch 20/20, Loss: 0.6575
Epoch 9/10, Train Loss: 0.3176, Valid Loss: 0.2754
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3017
Epoch 10/10, Batch 20/20, Loss: 0.1217
Epoch 10/10, Train Loss: 0.2550, Valid Loss: 0.2747
Model saved!
Accuracy: 0.8925
Precision: 0.8865
Recall: 0.8925
F1-score: 0.8875
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2779
Epoch 1/10, Batch 20/20, Loss: 1.3049
Epoch 1/10, Train Loss: 1.3011, Valid Loss: 1.0074
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8058
Epoch 2/10, Batch 20/20, Loss: 0.9638
Epoch 2/10, Train Loss: 0.8442, Valid Loss: 0.7515
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4507
Epoch 3/10, Batch 20/20, Loss: 0.6460
Epoch 3/10, Train Loss: 0.6221, Valid Loss: 0.6325
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7450
Epoch 4/10, Batch 20/20, Loss: 0.6116
Epoch 4/10, Train Loss: 0.5334, Valid Loss: 0.5661
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3813
Epoch 5/10, Batch 20/20, Loss: 0.4020
Epoch 5/10, Train Loss: 0.4470, Valid Loss: 0.5201
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5190
Epoch 6/10, Batch 20/20, Loss: 0.5330
Epoch 6/10, Train Loss: 0.4140, Valid Loss: 0.4838
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4085
Epoch 7/10, Batch 20/20, Loss: 0.6001
Epoch 7/10, Train Loss: 0.3793, Valid Loss: 0.4582
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3062
Epoch 8/10, Batch 20/20, Loss: 0.5165
Epoch 8/10, Train Loss: 0.3502, Valid Loss: 0.4376
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3976
Epoch 9/10, Batch 20/20, Loss: 0.6775
Epoch 9/10, Train Loss: 0.3329, Valid Loss: 0.4240
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2424
Epoch 10/10, Batch 20/20, Loss: 0.1703
Epoch 10/10, Train Loss: 0.2755, Valid Loss: 0.4104
Model saved!
Accuracy: 0.8890
Precision: 0.8851
Recall: 0.8890
F1-score: 0.8863
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1931
Epoch 1/10, Batch 20/20, Loss: 1.3847
Epoch 1/10, Train Loss: 1.3141, Valid Loss: 0.9545
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8103
Epoch 2/10, Batch 20/20, Loss: 1.0652
Epoch 2/10, Train Loss: 0.8484, Valid Loss: 0.6983
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5813
Epoch 3/10, Batch 20/20, Loss: 0.8270
Epoch 3/10, Train Loss: 0.6320, Valid Loss: 0.5701
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7548
Epoch 4/10, Batch 20/20, Loss: 0.3853
Epoch 4/10, Train Loss: 0.5165, Valid Loss: 0.5086
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4048
Epoch 5/10, Batch 20/20, Loss: 0.4496
Epoch 5/10, Train Loss: 0.4269, Valid Loss: 0.4547
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6199
Epoch 6/10, Batch 20/20, Loss: 0.6549
Epoch 6/10, Train Loss: 0.4228, Valid Loss: 0.4154
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3949
Epoch 7/10, Batch 20/20, Loss: 0.4791
Epoch 7/10, Train Loss: 0.3615, Valid Loss: 0.3889
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2516
Epoch 8/10, Batch 20/20, Loss: 0.4201
Epoch 8/10, Train Loss: 0.3371, Valid Loss: 0.3793
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4168
Epoch 9/10, Batch 20/20, Loss: 0.4458
Epoch 9/10, Train Loss: 0.3153, Valid Loss: 0.3606
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3393
Epoch 10/10, Batch 20/20, Loss: 0.2749
Epoch 10/10, Train Loss: 0.2655, Valid Loss: 0.3413
Model saved!
Accuracy: 0.8727
Precision: 0.8651
Recall: 0.8727
F1-score: 0.8679
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2577
Epoch 1/10, Batch 20/20, Loss: 1.1005
Epoch 1/10, Train Loss: 1.3015, Valid Loss: 0.9812
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8599
Epoch 2/10, Batch 20/20, Loss: 1.0933
Epoch 2/10, Train Loss: 0.8632, Valid Loss: 0.6935
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5153
Epoch 3/10, Batch 20/20, Loss: 0.8713
Epoch 3/10, Train Loss: 0.6253, Valid Loss: 0.5632
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6191
Epoch 4/10, Batch 20/20, Loss: 0.6335
Epoch 4/10, Train Loss: 0.5045, Valid Loss: 0.4927
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3976
Epoch 5/10, Batch 20/20, Loss: 0.5069
Epoch 5/10, Train Loss: 0.4253, Valid Loss: 0.4428
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4030
Epoch 6/10, Batch 20/20, Loss: 0.5686
Epoch 6/10, Train Loss: 0.3990, Valid Loss: 0.4098
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3988
Epoch 7/10, Batch 20/20, Loss: 0.5255
Epoch 7/10, Train Loss: 0.3490, Valid Loss: 0.3867
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3169
Epoch 8/10, Batch 20/20, Loss: 0.2795
Epoch 8/10, Train Loss: 0.3170, Valid Loss: 0.3762
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4007
Epoch 9/10, Batch 20/20, Loss: 0.5941
Epoch 9/10, Train Loss: 0.3124, Valid Loss: 0.3584
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2660
Epoch 10/10, Batch 20/20, Loss: 0.2364
Epoch 10/10, Train Loss: 0.2612, Valid Loss: 0.3542
Model saved!
Accuracy: 0.8843
Precision: 0.8794
Recall: 0.8843
F1-score: 0.8793
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1846
Epoch 1/10, Batch 20/20, Loss: 1.3592
Epoch 1/10, Train Loss: 1.2887, Valid Loss: 0.9416
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7956
Epoch 2/10, Batch 20/20, Loss: 0.8540
Epoch 2/10, Train Loss: 0.8432, Valid Loss: 0.6779
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5112
Epoch 3/10, Batch 20/20, Loss: 0.6729
Epoch 3/10, Train Loss: 0.6267, Valid Loss: 0.5501
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6229
Epoch 4/10, Batch 20/20, Loss: 0.4973
Epoch 4/10, Train Loss: 0.5099, Valid Loss: 0.4663
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4184
Epoch 5/10, Batch 20/20, Loss: 0.5286
Epoch 5/10, Train Loss: 0.4450, Valid Loss: 0.4236
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5602
Epoch 6/10, Batch 20/20, Loss: 0.3907
Epoch 6/10, Train Loss: 0.4107, Valid Loss: 0.3825
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3875
Epoch 7/10, Batch 20/20, Loss: 0.3058
Epoch 7/10, Train Loss: 0.3780, Valid Loss: 0.3565
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2739
Epoch 8/10, Batch 20/20, Loss: 0.3240
Epoch 8/10, Train Loss: 0.3290, Valid Loss: 0.3333
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4366
Epoch 9/10, Batch 20/20, Loss: 0.4632
Epoch 9/10, Train Loss: 0.3177, Valid Loss: 0.3242
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2529
Epoch 10/10, Batch 20/20, Loss: 0.1595
Epoch 10/10, Train Loss: 0.2658, Valid Loss: 0.3091
Model saved!
Accuracy: 0.8832
Precision: 0.8767
Recall: 0.8832
F1-score: 0.8787
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2231
Epoch 1/10, Batch 20/20, Loss: 1.3121
Epoch 1/10, Train Loss: 1.2930, Valid Loss: 0.9232
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8586
Epoch 2/10, Batch 20/20, Loss: 0.9034
Epoch 2/10, Train Loss: 0.8272, Valid Loss: 0.6547
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5266
Epoch 3/10, Batch 20/20, Loss: 0.5410
Epoch 3/10, Train Loss: 0.6053, Valid Loss: 0.5350
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7487
Epoch 4/10, Batch 20/20, Loss: 0.4966
Epoch 4/10, Train Loss: 0.5034, Valid Loss: 0.4587
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3997
Epoch 5/10, Batch 20/20, Loss: 0.3069
Epoch 5/10, Train Loss: 0.4195, Valid Loss: 0.4218
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4187
Epoch 6/10, Batch 20/20, Loss: 0.6672
Epoch 6/10, Train Loss: 0.4047, Valid Loss: 0.3740
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.5440
Epoch 7/10, Batch 20/20, Loss: 0.3859
Epoch 7/10, Train Loss: 0.3589, Valid Loss: 0.3702
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3310
Epoch 8/10, Batch 20/20, Loss: 0.5445
Epoch 8/10, Train Loss: 0.3398, Valid Loss: 0.3410
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3461
Epoch 9/10, Batch 20/20, Loss: 0.5095
Epoch 9/10, Train Loss: 0.3076, Valid Loss: 0.3564
Epoch 10/10, Batch 10/20, Loss: 0.2625
Epoch 10/10, Batch 20/20, Loss: 0.2169
Epoch 10/10, Train Loss: 0.2627, Valid Loss: 0.3216
Model saved!
Accuracy: 0.8843
Precision: 0.8775
Recall: 0.8843
F1-score: 0.8788
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2418
Epoch 1/10, Batch 20/20, Loss: 1.2036
Epoch 1/10, Train Loss: 1.3086, Valid Loss: 0.9392
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8396
Epoch 2/10, Batch 20/20, Loss: 0.9149
Epoch 2/10, Train Loss: 0.8585, Valid Loss: 0.6571
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6386
Epoch 3/10, Batch 20/20, Loss: 0.7810
Epoch 3/10, Train Loss: 0.6380, Valid Loss: 0.5251
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5452
Epoch 4/10, Batch 20/20, Loss: 0.4153
Epoch 4/10, Train Loss: 0.5103, Valid Loss: 0.4563
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4041
Epoch 5/10, Batch 20/20, Loss: 0.4558
Epoch 5/10, Train Loss: 0.4440, Valid Loss: 0.4140
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4811
Epoch 6/10, Batch 20/20, Loss: 0.5040
Epoch 6/10, Train Loss: 0.4050, Valid Loss: 0.3731
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4298
Epoch 7/10, Batch 20/20, Loss: 0.3890
Epoch 7/10, Train Loss: 0.3736, Valid Loss: 0.3498
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3359
Epoch 8/10, Batch 20/20, Loss: 0.3378
Epoch 8/10, Train Loss: 0.3417, Valid Loss: 0.3284
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4859
Epoch 9/10, Batch 20/20, Loss: 0.7415
Epoch 9/10, Train Loss: 0.3397, Valid Loss: 0.3134
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1521
Epoch 10/10, Batch 20/20, Loss: 0.3550
Epoch 10/10, Train Loss: 0.2853, Valid Loss: 0.3145
Accuracy: 0.8808
Precision: 0.8749
Recall: 0.8808
F1-score: 0.8768
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3105
Epoch 1/10, Batch 20/20, Loss: 1.1983
Epoch 1/10, Train Loss: 1.3279, Valid Loss: 0.9416
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8711
Epoch 2/10, Batch 20/20, Loss: 0.9123
Epoch 2/10, Train Loss: 0.8720, Valid Loss: 0.6603
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6282
Epoch 3/10, Batch 20/20, Loss: 0.7638
Epoch 3/10, Train Loss: 0.6526, Valid Loss: 0.5438
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7370
Epoch 4/10, Batch 20/20, Loss: 0.7127
Epoch 4/10, Train Loss: 0.5654, Valid Loss: 0.4682
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4085
Epoch 5/10, Batch 20/20, Loss: 0.2971
Epoch 5/10, Train Loss: 0.4629, Valid Loss: 0.4280
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5662
Epoch 6/10, Batch 20/20, Loss: 0.4209
Epoch 6/10, Train Loss: 0.4388, Valid Loss: 0.3951
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4193
Epoch 7/10, Batch 20/20, Loss: 0.5198
Epoch 7/10, Train Loss: 0.3959, Valid Loss: 0.3773
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2574
Epoch 8/10, Batch 20/20, Loss: 0.4239
Epoch 8/10, Train Loss: 0.3718, Valid Loss: 0.3508
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.6795
Epoch 9/10, Batch 20/20, Loss: 0.7712
Epoch 9/10, Train Loss: 0.3621, Valid Loss: 0.3493
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2729
Epoch 10/10, Batch 20/20, Loss: 0.5233
Epoch 10/10, Train Loss: 0.3044, Valid Loss: 0.3246
Model saved!
Accuracy: 0.8808
Precision: 0.8771
Recall: 0.8808
F1-score: 0.8744
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2271
Epoch 1/10, Batch 20/20, Loss: 1.1558
Epoch 1/10, Train Loss: 1.3002, Valid Loss: 0.9989
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9249
Epoch 2/10, Batch 20/20, Loss: 0.8432
Epoch 2/10, Train Loss: 0.8489, Valid Loss: 0.7252
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5268
Epoch 3/10, Batch 20/20, Loss: 0.7036
Epoch 3/10, Train Loss: 0.6342, Valid Loss: 0.6035
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7766
Epoch 4/10, Batch 20/20, Loss: 0.4401
Epoch 4/10, Train Loss: 0.5394, Valid Loss: 0.5219
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5454
Epoch 5/10, Batch 20/20, Loss: 0.4208
Epoch 5/10, Train Loss: 0.4457, Valid Loss: 0.4681
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5416
Epoch 6/10, Batch 20/20, Loss: 0.8099
Epoch 6/10, Train Loss: 0.4291, Valid Loss: 0.4292
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4028
Epoch 7/10, Batch 20/20, Loss: 0.4042
Epoch 7/10, Train Loss: 0.3721, Valid Loss: 0.4130
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3285
Epoch 8/10, Batch 20/20, Loss: 0.2913
Epoch 8/10, Train Loss: 0.3217, Valid Loss: 0.3852
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4470
Epoch 9/10, Batch 20/20, Loss: 0.4168
Epoch 9/10, Train Loss: 0.3321, Valid Loss: 0.3752
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2583
Epoch 10/10, Batch 20/20, Loss: 0.4345
Epoch 10/10, Train Loss: 0.2839, Valid Loss: 0.3603
Model saved!
Accuracy: 0.8879
Precision: 0.8822
Recall: 0.8879
F1-score: 0.8839
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2564
Epoch 1/10, Batch 20/20, Loss: 1.1953
Epoch 1/10, Train Loss: 1.3073, Valid Loss: 0.9841
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8296
Epoch 2/10, Batch 20/20, Loss: 0.9326
Epoch 2/10, Train Loss: 0.8633, Valid Loss: 0.7016
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6483
Epoch 3/10, Batch 20/20, Loss: 0.6081
Epoch 3/10, Train Loss: 0.6438, Valid Loss: 0.5786
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6663
Epoch 4/10, Batch 20/20, Loss: 0.3734
Epoch 4/10, Train Loss: 0.5319, Valid Loss: 0.5072
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4325
Epoch 5/10, Batch 20/20, Loss: 0.6242
Epoch 5/10, Train Loss: 0.4577, Valid Loss: 0.4640
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5182
Epoch 6/10, Batch 20/20, Loss: 0.9088
Epoch 6/10, Train Loss: 0.4369, Valid Loss: 0.4270
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3756
Epoch 7/10, Batch 20/20, Loss: 0.3376
Epoch 7/10, Train Loss: 0.3720, Valid Loss: 0.4075
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3225
Epoch 8/10, Batch 20/20, Loss: 0.3760
Epoch 8/10, Train Loss: 0.3323, Valid Loss: 0.3953
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4518
Epoch 9/10, Batch 20/20, Loss: 0.3082
Epoch 9/10, Train Loss: 0.3080, Valid Loss: 0.3766
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1840
Epoch 10/10, Batch 20/20, Loss: 0.2603
Epoch 10/10, Train Loss: 0.2681, Valid Loss: 0.3605
Model saved!
Accuracy: 0.8855
Precision: 0.8801
Recall: 0.8855
F1-score: 0.8810
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2382
Epoch 1/10, Batch 20/20, Loss: 1.2603
Epoch 1/10, Train Loss: 1.2905, Valid Loss: 0.9659
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8812
Epoch 2/10, Batch 20/20, Loss: 0.7769
Epoch 2/10, Train Loss: 0.8420, Valid Loss: 0.7032
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5338
Epoch 3/10, Batch 20/20, Loss: 0.5138
Epoch 3/10, Train Loss: 0.6117, Valid Loss: 0.5756
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6557
Epoch 4/10, Batch 20/20, Loss: 0.4474
Epoch 4/10, Train Loss: 0.5094, Valid Loss: 0.5138
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4333
Epoch 5/10, Batch 20/20, Loss: 0.2580
Epoch 5/10, Train Loss: 0.4165, Valid Loss: 0.4661
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4391
Epoch 6/10, Batch 20/20, Loss: 0.5392
Epoch 6/10, Train Loss: 0.4134, Valid Loss: 0.4286
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3194
Epoch 7/10, Batch 20/20, Loss: 0.3994
Epoch 7/10, Train Loss: 0.3654, Valid Loss: 0.4085
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.1815
Epoch 8/10, Batch 20/20, Loss: 0.3062
Epoch 8/10, Train Loss: 0.3216, Valid Loss: 0.3822
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4256
Epoch 9/10, Batch 20/20, Loss: 0.7456
Epoch 9/10, Train Loss: 0.3268, Valid Loss: 0.3788
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3158
Epoch 10/10, Batch 20/20, Loss: 0.2972
Epoch 10/10, Train Loss: 0.2684, Valid Loss: 0.3593
Model saved!
Accuracy: 0.8727
Precision: 0.8686
Recall: 0.8727
F1-score: 0.8702
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2801
Epoch 1/10, Batch 20/20, Loss: 1.0839
Epoch 1/10, Train Loss: 1.3142, Valid Loss: 0.9480
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8705
Epoch 2/10, Batch 20/20, Loss: 0.8660
Epoch 2/10, Train Loss: 0.8562, Valid Loss: 0.6623
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5063
Epoch 3/10, Batch 20/20, Loss: 0.6411
Epoch 3/10, Train Loss: 0.6374, Valid Loss: 0.5240
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6226
Epoch 4/10, Batch 20/20, Loss: 0.4718
Epoch 4/10, Train Loss: 0.5107, Valid Loss: 0.4702
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4840
Epoch 5/10, Batch 20/20, Loss: 0.4474
Epoch 5/10, Train Loss: 0.4269, Valid Loss: 0.4209
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5695
Epoch 6/10, Batch 20/20, Loss: 0.6015
Epoch 6/10, Train Loss: 0.4153, Valid Loss: 0.3901
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3864
Epoch 7/10, Batch 20/20, Loss: 0.4660
Epoch 7/10, Train Loss: 0.3742, Valid Loss: 0.3703
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.1999
Epoch 8/10, Batch 20/20, Loss: 0.4032
Epoch 8/10, Train Loss: 0.3302, Valid Loss: 0.3560
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4889
Epoch 9/10, Batch 20/20, Loss: 0.4485
Epoch 9/10, Train Loss: 0.3143, Valid Loss: 0.3371
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2011
Epoch 10/10, Batch 20/20, Loss: 0.2172
Epoch 10/10, Train Loss: 0.2646, Valid Loss: 0.3325
Model saved!
Accuracy: 0.8820
Precision: 0.8766
Recall: 0.8820
F1-score: 0.8764
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2139
Epoch 1/10, Batch 20/20, Loss: 1.1990
Epoch 1/10, Train Loss: 1.2937, Valid Loss: 0.9338
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8400
Epoch 2/10, Batch 20/20, Loss: 0.8119
Epoch 2/10, Train Loss: 0.8363, Valid Loss: 0.6982
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5410
Epoch 3/10, Batch 20/20, Loss: 0.7012
Epoch 3/10, Train Loss: 0.6221, Valid Loss: 0.5623
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6811
Epoch 4/10, Batch 20/20, Loss: 0.4051
Epoch 4/10, Train Loss: 0.5048, Valid Loss: 0.5041
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3817
Epoch 5/10, Batch 20/20, Loss: 0.2314
Epoch 5/10, Train Loss: 0.4275, Valid Loss: 0.4541
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.3894
Epoch 6/10, Batch 20/20, Loss: 0.4687
Epoch 6/10, Train Loss: 0.4042, Valid Loss: 0.4196
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4446
Epoch 7/10, Batch 20/20, Loss: 0.6107
Epoch 7/10, Train Loss: 0.3756, Valid Loss: 0.4000
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3027
Epoch 8/10, Batch 20/20, Loss: 0.2047
Epoch 8/10, Train Loss: 0.3214, Valid Loss: 0.3901
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5631
Epoch 9/10, Batch 20/20, Loss: 0.6874
Epoch 9/10, Train Loss: 0.3332, Valid Loss: 0.3729
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2378
Epoch 10/10, Batch 20/20, Loss: 0.3628
Epoch 10/10, Train Loss: 0.2794, Valid Loss: 0.3554
Model saved!
Accuracy: 0.8867
Precision: 0.8816
Recall: 0.8867
F1-score: 0.8817
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2748
Epoch 1/10, Batch 20/20, Loss: 1.2208
Epoch 1/10, Train Loss: 1.3094, Valid Loss: 0.9987
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8438
Epoch 2/10, Batch 20/20, Loss: 0.8807
Epoch 2/10, Train Loss: 0.8844, Valid Loss: 0.7352
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6780
Epoch 3/10, Batch 20/20, Loss: 0.6803
Epoch 3/10, Train Loss: 0.6604, Valid Loss: 0.6069
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6529
Epoch 4/10, Batch 20/20, Loss: 0.3737
Epoch 4/10, Train Loss: 0.5426, Valid Loss: 0.5431
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4519
Epoch 5/10, Batch 20/20, Loss: 0.7144
Epoch 5/10, Train Loss: 0.4771, Valid Loss: 0.4996
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6853
Epoch 6/10, Batch 20/20, Loss: 0.7664
Epoch 6/10, Train Loss: 0.4624, Valid Loss: 0.4479
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.5005
Epoch 7/10, Batch 20/20, Loss: 0.3690
Epoch 7/10, Train Loss: 0.3902, Valid Loss: 0.4292
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4130
Epoch 8/10, Batch 20/20, Loss: 0.6349
Epoch 8/10, Train Loss: 0.3815, Valid Loss: 0.4149
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5158
Epoch 9/10, Batch 20/20, Loss: 0.5293
Epoch 9/10, Train Loss: 0.3523, Valid Loss: 0.4009
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3418
Epoch 10/10, Batch 20/20, Loss: 0.6310
Epoch 10/10, Train Loss: 0.3207, Valid Loss: 0.3954
Model saved!
Accuracy: 0.8960
Precision: 0.8924
Recall: 0.8960
F1-score: 0.8934
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1852
Epoch 1/10, Batch 20/20, Loss: 1.2315
Epoch 1/10, Train Loss: 1.2965, Valid Loss: 0.9249
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7385
Epoch 2/10, Batch 20/20, Loss: 0.9195
Epoch 2/10, Train Loss: 0.8349, Valid Loss: 0.6591
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5750
Epoch 3/10, Batch 20/20, Loss: 0.7834
Epoch 3/10, Train Loss: 0.6155, Valid Loss: 0.5404
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7338
Epoch 4/10, Batch 20/20, Loss: 0.3622
Epoch 4/10, Train Loss: 0.4919, Valid Loss: 0.4689
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3939
Epoch 5/10, Batch 20/20, Loss: 0.4255
Epoch 5/10, Train Loss: 0.4190, Valid Loss: 0.4305
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5485
Epoch 6/10, Batch 20/20, Loss: 0.6303
Epoch 6/10, Train Loss: 0.4114, Valid Loss: 0.3794
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4056
Epoch 7/10, Batch 20/20, Loss: 0.3219
Epoch 7/10, Train Loss: 0.3532, Valid Loss: 0.3584
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3189
Epoch 8/10, Batch 20/20, Loss: 0.4378
Epoch 8/10, Train Loss: 0.3189, Valid Loss: 0.3493
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.6741
Epoch 9/10, Batch 20/20, Loss: 0.4215
Epoch 9/10, Train Loss: 0.3102, Valid Loss: 0.3266
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2593
Epoch 10/10, Batch 20/20, Loss: 0.2339
Epoch 10/10, Train Loss: 0.2644, Valid Loss: 0.3173
Model saved!
Accuracy: 0.8855
Precision: 0.8803
Recall: 0.8855
F1-score: 0.8816
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1749
Epoch 1/10, Batch 20/20, Loss: 1.1197
Epoch 1/10, Train Loss: 1.2832, Valid Loss: 0.9765
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8225
Epoch 2/10, Batch 20/20, Loss: 0.8796
Epoch 2/10, Train Loss: 0.8243, Valid Loss: 0.7168
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6501
Epoch 3/10, Batch 20/20, Loss: 0.8124
Epoch 3/10, Train Loss: 0.6145, Valid Loss: 0.5807
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6194
Epoch 4/10, Batch 20/20, Loss: 0.3832
Epoch 4/10, Train Loss: 0.4937, Valid Loss: 0.5159
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3354
Epoch 5/10, Batch 20/20, Loss: 0.3752
Epoch 5/10, Train Loss: 0.4129, Valid Loss: 0.4772
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5462
Epoch 6/10, Batch 20/20, Loss: 0.6511
Epoch 6/10, Train Loss: 0.4100, Valid Loss: 0.4349
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4381
Epoch 7/10, Batch 20/20, Loss: 0.1832
Epoch 7/10, Train Loss: 0.3440, Valid Loss: 0.4158
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2954
Epoch 8/10, Batch 20/20, Loss: 0.1850
Epoch 8/10, Train Loss: 0.3072, Valid Loss: 0.4061
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5414
Epoch 9/10, Batch 20/20, Loss: 0.5706
Epoch 9/10, Train Loss: 0.3279, Valid Loss: 0.3734
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2048
Epoch 10/10, Batch 20/20, Loss: 0.2261
Epoch 10/10, Train Loss: 0.2715, Valid Loss: 0.3816
Accuracy: 0.8727
Precision: 0.8654
Recall: 0.8727
F1-score: 0.8675
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2600
Epoch 1/10, Batch 20/20, Loss: 1.1702
Epoch 1/10, Train Loss: 1.2822, Valid Loss: 0.9414
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8403
Epoch 2/10, Batch 20/20, Loss: 0.8983
Epoch 2/10, Train Loss: 0.8175, Valid Loss: 0.6782
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5491
Epoch 3/10, Batch 20/20, Loss: 0.4955
Epoch 3/10, Train Loss: 0.5949, Valid Loss: 0.5459
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7141
Epoch 4/10, Batch 20/20, Loss: 0.4297
Epoch 4/10, Train Loss: 0.4805, Valid Loss: 0.4836
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4027
Epoch 5/10, Batch 20/20, Loss: 0.4592
Epoch 5/10, Train Loss: 0.4114, Valid Loss: 0.4435
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4996
Epoch 6/10, Batch 20/20, Loss: 0.5838
Epoch 6/10, Train Loss: 0.4019, Valid Loss: 0.3994
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3276
Epoch 7/10, Batch 20/20, Loss: 0.2498
Epoch 7/10, Train Loss: 0.3477, Valid Loss: 0.3812
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2124
Epoch 8/10, Batch 20/20, Loss: 0.4509
Epoch 8/10, Train Loss: 0.3229, Valid Loss: 0.3574
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4356
Epoch 9/10, Batch 20/20, Loss: 0.3777
Epoch 9/10, Train Loss: 0.3003, Valid Loss: 0.3476
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2130
Epoch 10/10, Batch 20/20, Loss: 0.2959
Epoch 10/10, Train Loss: 0.2670, Valid Loss: 0.3320
Model saved!
Accuracy: 0.8820
Precision: 0.8762
Recall: 0.8820
F1-score: 0.8777
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2334
Epoch 1/10, Batch 20/20, Loss: 1.1315
Epoch 1/10, Train Loss: 1.3046, Valid Loss: 0.9107
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7879
Epoch 2/10, Batch 20/20, Loss: 0.8839
Epoch 2/10, Train Loss: 0.8538, Valid Loss: 0.6282
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5919
Epoch 3/10, Batch 20/20, Loss: 0.6982
Epoch 3/10, Train Loss: 0.6294, Valid Loss: 0.4892
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6366
Epoch 4/10, Batch 20/20, Loss: 0.5793
Epoch 4/10, Train Loss: 0.5263, Valid Loss: 0.4278
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5241
Epoch 5/10, Batch 20/20, Loss: 0.4421
Epoch 5/10, Train Loss: 0.4366, Valid Loss: 0.3807
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5229
Epoch 6/10, Batch 20/20, Loss: 0.5087
Epoch 6/10, Train Loss: 0.4095, Valid Loss: 0.3411
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3647
Epoch 7/10, Batch 20/20, Loss: 0.3942
Epoch 7/10, Train Loss: 0.3683, Valid Loss: 0.3245
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3450
Epoch 8/10, Batch 20/20, Loss: 0.2064
Epoch 8/10, Train Loss: 0.3183, Valid Loss: 0.3080
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5188
Epoch 9/10, Batch 20/20, Loss: 0.6461
Epoch 9/10, Train Loss: 0.3256, Valid Loss: 0.2906
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2037
Epoch 10/10, Batch 20/20, Loss: 0.3213
Epoch 10/10, Train Loss: 0.2836, Valid Loss: 0.2776
Model saved!
Accuracy: 0.8902
Precision: 0.8877
Recall: 0.8902
F1-score: 0.8873
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2316
Epoch 1/10, Batch 20/20, Loss: 1.1736
Epoch 1/10, Train Loss: 1.3272, Valid Loss: 1.0185
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9211
Epoch 2/10, Batch 20/20, Loss: 1.1111
Epoch 2/10, Train Loss: 0.8738, Valid Loss: 0.7610
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5904
Epoch 3/10, Batch 20/20, Loss: 0.6754
Epoch 3/10, Train Loss: 0.6519, Valid Loss: 0.6338
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6431
Epoch 4/10, Batch 20/20, Loss: 0.6012
Epoch 4/10, Train Loss: 0.5464, Valid Loss: 0.5691
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4380
Epoch 5/10, Batch 20/20, Loss: 0.8224
Epoch 5/10, Train Loss: 0.4741, Valid Loss: 0.5109
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.7037
Epoch 6/10, Batch 20/20, Loss: 0.6087
Epoch 6/10, Train Loss: 0.4565, Valid Loss: 0.4645
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4895
Epoch 7/10, Batch 20/20, Loss: 0.4467
Epoch 7/10, Train Loss: 0.3915, Valid Loss: 0.4453
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3182
Epoch 8/10, Batch 20/20, Loss: 0.3151
Epoch 8/10, Train Loss: 0.3514, Valid Loss: 0.4285
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4183
Epoch 9/10, Batch 20/20, Loss: 0.2894
Epoch 9/10, Train Loss: 0.3391, Valid Loss: 0.4240
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2245
Epoch 10/10, Batch 20/20, Loss: 0.4621
Epoch 10/10, Train Loss: 0.3027, Valid Loss: 0.3952
Model saved!
Accuracy: 0.8879
Precision: 0.8827
Recall: 0.8879
F1-score: 0.8830
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2666
Epoch 1/10, Batch 20/20, Loss: 1.2308
Epoch 1/10, Train Loss: 1.3225, Valid Loss: 0.9595
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9131
Epoch 2/10, Batch 20/20, Loss: 0.9204
Epoch 2/10, Train Loss: 0.8717, Valid Loss: 0.6701
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5484
Epoch 3/10, Batch 20/20, Loss: 0.5551
Epoch 3/10, Train Loss: 0.6512, Valid Loss: 0.5390
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6118
Epoch 4/10, Batch 20/20, Loss: 0.4634
Epoch 4/10, Train Loss: 0.5456, Valid Loss: 0.4590
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5654
Epoch 5/10, Batch 20/20, Loss: 0.5076
Epoch 5/10, Train Loss: 0.4663, Valid Loss: 0.4085
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5590
Epoch 6/10, Batch 20/20, Loss: 0.3680
Epoch 6/10, Train Loss: 0.4464, Valid Loss: 0.3521
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3407
Epoch 7/10, Batch 20/20, Loss: 0.3466
Epoch 7/10, Train Loss: 0.3994, Valid Loss: 0.3462
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4087
Epoch 8/10, Batch 20/20, Loss: 0.2353
Epoch 8/10, Train Loss: 0.3614, Valid Loss: 0.3160
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4347
Epoch 9/10, Batch 20/20, Loss: 0.4817
Epoch 9/10, Train Loss: 0.3515, Valid Loss: 0.3103
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2615
Epoch 10/10, Batch 20/20, Loss: 0.3303
Epoch 10/10, Train Loss: 0.3024, Valid Loss: 0.2886
Model saved!
Accuracy: 0.8925
Precision: 0.8882
Recall: 0.8925
F1-score: 0.8895
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2663
Epoch 1/10, Batch 20/20, Loss: 1.1856
Epoch 1/10, Train Loss: 1.3168, Valid Loss: 0.9803
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9459
Epoch 2/10, Batch 20/20, Loss: 0.9601
Epoch 2/10, Train Loss: 0.8743, Valid Loss: 0.7039
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7036
Epoch 3/10, Batch 20/20, Loss: 0.7563
Epoch 3/10, Train Loss: 0.6474, Valid Loss: 0.5800
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7492
Epoch 4/10, Batch 20/20, Loss: 0.6128
Epoch 4/10, Train Loss: 0.5420, Valid Loss: 0.5086
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4358
Epoch 5/10, Batch 20/20, Loss: 0.5258
Epoch 5/10, Train Loss: 0.4484, Valid Loss: 0.4723
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4244
Epoch 6/10, Batch 20/20, Loss: 0.6246
Epoch 6/10, Train Loss: 0.4391, Valid Loss: 0.4236
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3886
Epoch 7/10, Batch 20/20, Loss: 0.4904
Epoch 7/10, Train Loss: 0.3723, Valid Loss: 0.4151
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3110
Epoch 8/10, Batch 20/20, Loss: 0.3261
Epoch 8/10, Train Loss: 0.3507, Valid Loss: 0.3899
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4836
Epoch 9/10, Batch 20/20, Loss: 0.6621
Epoch 9/10, Train Loss: 0.3461, Valid Loss: 0.3928
Epoch 10/10, Batch 10/20, Loss: 0.2589
Epoch 10/10, Batch 20/20, Loss: 0.2934
Epoch 10/10, Train Loss: 0.2947, Valid Loss: 0.3636
Model saved!
Accuracy: 0.8820
Precision: 0.8775
Recall: 0.8820
F1-score: 0.8782
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2469
Epoch 1/10, Batch 20/20, Loss: 1.1346
Epoch 1/10, Train Loss: 1.3084, Valid Loss: 0.9691
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0018
Epoch 2/10, Batch 20/20, Loss: 1.0490
Epoch 2/10, Train Loss: 0.8735, Valid Loss: 0.7191
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5552
Epoch 3/10, Batch 20/20, Loss: 0.9016
Epoch 3/10, Train Loss: 0.6570, Valid Loss: 0.6011
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6167
Epoch 4/10, Batch 20/20, Loss: 0.4546
Epoch 4/10, Train Loss: 0.5354, Valid Loss: 0.5297
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3693
Epoch 5/10, Batch 20/20, Loss: 0.4254
Epoch 5/10, Train Loss: 0.4525, Valid Loss: 0.4738
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4847
Epoch 6/10, Batch 20/20, Loss: 0.5323
Epoch 6/10, Train Loss: 0.4322, Valid Loss: 0.4345
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3813
Epoch 7/10, Batch 20/20, Loss: 0.5616
Epoch 7/10, Train Loss: 0.3892, Valid Loss: 0.4195
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3890
Epoch 8/10, Batch 20/20, Loss: 0.3744
Epoch 8/10, Train Loss: 0.3531, Valid Loss: 0.4002
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.6478
Epoch 9/10, Batch 20/20, Loss: 0.5141
Epoch 9/10, Train Loss: 0.3440, Valid Loss: 0.3962
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2936
Epoch 10/10, Batch 20/20, Loss: 0.2910
Epoch 10/10, Train Loss: 0.2987, Valid Loss: 0.3811
Model saved!
Accuracy: 0.8855
Precision: 0.8820
Recall: 0.8855
F1-score: 0.8820
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2131
Epoch 1/10, Batch 20/20, Loss: 1.1239
Epoch 1/10, Train Loss: 1.2809, Valid Loss: 0.9836
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8122
Epoch 2/10, Batch 20/20, Loss: 0.9858
Epoch 2/10, Train Loss: 0.8310, Valid Loss: 0.7300
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6072
Epoch 3/10, Batch 20/20, Loss: 0.7071
Epoch 3/10, Train Loss: 0.5994, Valid Loss: 0.6188
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7189
Epoch 4/10, Batch 20/20, Loss: 0.4105
Epoch 4/10, Train Loss: 0.4983, Valid Loss: 0.5533
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4453
Epoch 5/10, Batch 20/20, Loss: 0.4665
Epoch 5/10, Train Loss: 0.4035, Valid Loss: 0.5155
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4897
Epoch 6/10, Batch 20/20, Loss: 0.8127
Epoch 6/10, Train Loss: 0.4014, Valid Loss: 0.4861
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4080
Epoch 7/10, Batch 20/20, Loss: 0.4221
Epoch 7/10, Train Loss: 0.3474, Valid Loss: 0.4707
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3852
Epoch 8/10, Batch 20/20, Loss: 0.2796
Epoch 8/10, Train Loss: 0.3073, Valid Loss: 0.4558
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4285
Epoch 9/10, Batch 20/20, Loss: 0.7110
Epoch 9/10, Train Loss: 0.3109, Valid Loss: 0.4373
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2211
Epoch 10/10, Batch 20/20, Loss: 0.1587
Epoch 10/10, Train Loss: 0.2429, Valid Loss: 0.4385
Accuracy: 0.8914
Precision: 0.8856
Recall: 0.8914
F1-score: 0.8875
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2457
Epoch 1/10, Batch 20/20, Loss: 1.0487
Epoch 1/10, Train Loss: 1.2969, Valid Loss: 0.9331
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8363
Epoch 2/10, Batch 20/20, Loss: 0.7987
Epoch 2/10, Train Loss: 0.8444, Valid Loss: 0.6627
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5385
Epoch 3/10, Batch 20/20, Loss: 0.5850
Epoch 3/10, Train Loss: 0.6179, Valid Loss: 0.5328
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6830
Epoch 4/10, Batch 20/20, Loss: 0.4103
Epoch 4/10, Train Loss: 0.5100, Valid Loss: 0.4612
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4208
Epoch 5/10, Batch 20/20, Loss: 0.4047
Epoch 5/10, Train Loss: 0.4404, Valid Loss: 0.4143
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5885
Epoch 6/10, Batch 20/20, Loss: 0.6106
Epoch 6/10, Train Loss: 0.4157, Valid Loss: 0.3833
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4336
Epoch 7/10, Batch 20/20, Loss: 0.3612
Epoch 7/10, Train Loss: 0.3851, Valid Loss: 0.3629
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2749
Epoch 8/10, Batch 20/20, Loss: 0.3026
Epoch 8/10, Train Loss: 0.3410, Valid Loss: 0.3422
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5642
Epoch 9/10, Batch 20/20, Loss: 0.6763
Epoch 9/10, Train Loss: 0.3322, Valid Loss: 0.3266
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2976
Epoch 10/10, Batch 20/20, Loss: 0.2357
Epoch 10/10, Train Loss: 0.2765, Valid Loss: 0.3122
Model saved!
Accuracy: 0.8902
Precision: 0.8873
Recall: 0.8902
F1-score: 0.8872
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2878
Epoch 1/10, Batch 20/20, Loss: 1.1765
Epoch 1/10, Train Loss: 1.3181, Valid Loss: 0.9861
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8997
Epoch 2/10, Batch 20/20, Loss: 0.8024
Epoch 2/10, Train Loss: 0.8723, Valid Loss: 0.6963
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6226
Epoch 3/10, Batch 20/20, Loss: 0.6183
Epoch 3/10, Train Loss: 0.6495, Valid Loss: 0.5748
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7596
Epoch 4/10, Batch 20/20, Loss: 0.5264
Epoch 4/10, Train Loss: 0.5528, Valid Loss: 0.4885
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5731
Epoch 5/10, Batch 20/20, Loss: 0.6513
Epoch 5/10, Train Loss: 0.4706, Valid Loss: 0.4384
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5457
Epoch 6/10, Batch 20/20, Loss: 0.6021
Epoch 6/10, Train Loss: 0.4441, Valid Loss: 0.4010
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4642
Epoch 7/10, Batch 20/20, Loss: 0.5554
Epoch 7/10, Train Loss: 0.3964, Valid Loss: 0.3668
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3837
Epoch 8/10, Batch 20/20, Loss: 0.3772
Epoch 8/10, Train Loss: 0.3571, Valid Loss: 0.3566
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4375
Epoch 9/10, Batch 20/20, Loss: 0.4341
Epoch 9/10, Train Loss: 0.3382, Valid Loss: 0.3383
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2511
Epoch 10/10, Batch 20/20, Loss: 0.4187
Epoch 10/10, Train Loss: 0.3043, Valid Loss: 0.3239
Model saved!
Accuracy: 0.8902
Precision: 0.8882
Recall: 0.8902
F1-score: 0.8852
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2813
Epoch 1/10, Batch 20/20, Loss: 1.1347
Epoch 1/10, Train Loss: 1.3036, Valid Loss: 0.9870
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9530
Epoch 2/10, Batch 20/20, Loss: 0.7320
Epoch 2/10, Train Loss: 0.8547, Valid Loss: 0.7282
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6354
Epoch 3/10, Batch 20/20, Loss: 0.7234
Epoch 3/10, Train Loss: 0.6346, Valid Loss: 0.6148
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7550
Epoch 4/10, Batch 20/20, Loss: 0.6075
Epoch 4/10, Train Loss: 0.5369, Valid Loss: 0.5446
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4655
Epoch 5/10, Batch 20/20, Loss: 0.5811
Epoch 5/10, Train Loss: 0.4524, Valid Loss: 0.5149
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4802
Epoch 6/10, Batch 20/20, Loss: 0.7887
Epoch 6/10, Train Loss: 0.4342, Valid Loss: 0.4809
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3674
Epoch 7/10, Batch 20/20, Loss: 0.5806
Epoch 7/10, Train Loss: 0.3891, Valid Loss: 0.4633
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3324
Epoch 8/10, Batch 20/20, Loss: 0.3660
Epoch 8/10, Train Loss: 0.3384, Valid Loss: 0.4479
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4903
Epoch 9/10, Batch 20/20, Loss: 0.3963
Epoch 9/10, Train Loss: 0.3281, Valid Loss: 0.4559
Epoch 10/10, Batch 10/20, Loss: 0.3057
Epoch 10/10, Batch 20/20, Loss: 0.3819
Epoch 10/10, Train Loss: 0.2993, Valid Loss: 0.4329
Model saved!
Accuracy: 0.8843
Precision: 0.8787
Recall: 0.8843
F1-score: 0.8802
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2191
Epoch 1/10, Batch 20/20, Loss: 1.0745
Epoch 1/10, Train Loss: 1.2906, Valid Loss: 0.9557
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7470
Epoch 2/10, Batch 20/20, Loss: 0.9727
Epoch 2/10, Train Loss: 0.8374, Valid Loss: 0.6947
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5809
Epoch 3/10, Batch 20/20, Loss: 0.8069
Epoch 3/10, Train Loss: 0.6141, Valid Loss: 0.5687
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7164
Epoch 4/10, Batch 20/20, Loss: 0.4147
Epoch 4/10, Train Loss: 0.4936, Valid Loss: 0.4916
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4656
Epoch 5/10, Batch 20/20, Loss: 0.3723
Epoch 5/10, Train Loss: 0.4095, Valid Loss: 0.4371
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4840
Epoch 6/10, Batch 20/20, Loss: 0.6224
Epoch 6/10, Train Loss: 0.3898, Valid Loss: 0.4006
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3872
Epoch 7/10, Batch 20/20, Loss: 0.4179
Epoch 7/10, Train Loss: 0.3468, Valid Loss: 0.3823
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3452
Epoch 8/10, Batch 20/20, Loss: 0.3596
Epoch 8/10, Train Loss: 0.3092, Valid Loss: 0.3604
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5039
Epoch 9/10, Batch 20/20, Loss: 0.8466
Epoch 9/10, Train Loss: 0.3127, Valid Loss: 0.3614
Epoch 10/10, Batch 10/20, Loss: 0.1207
Epoch 10/10, Batch 20/20, Loss: 0.1721
Epoch 10/10, Train Loss: 0.2463, Valid Loss: 0.3343
Model saved!
Accuracy: 0.8925
Precision: 0.8870
Recall: 0.8925
F1-score: 0.8891
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2181
Epoch 1/10, Batch 20/20, Loss: 1.2011
Epoch 1/10, Train Loss: 1.3099, Valid Loss: 0.9675
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8524
Epoch 2/10, Batch 20/20, Loss: 0.9565
Epoch 2/10, Train Loss: 0.8513, Valid Loss: 0.7143
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5484
Epoch 3/10, Batch 20/20, Loss: 0.6673
Epoch 3/10, Train Loss: 0.6264, Valid Loss: 0.5930
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7132
Epoch 4/10, Batch 20/20, Loss: 0.3494
Epoch 4/10, Train Loss: 0.5028, Valid Loss: 0.5263
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3723
Epoch 5/10, Batch 20/20, Loss: 0.5468
Epoch 5/10, Train Loss: 0.4365, Valid Loss: 0.4836
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4675
Epoch 6/10, Batch 20/20, Loss: 0.5716
Epoch 6/10, Train Loss: 0.4151, Valid Loss: 0.4499
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4403
Epoch 7/10, Batch 20/20, Loss: 0.6025
Epoch 7/10, Train Loss: 0.3661, Valid Loss: 0.4288
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2689
Epoch 8/10, Batch 20/20, Loss: 0.1747
Epoch 8/10, Train Loss: 0.3250, Valid Loss: 0.4036
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3951
Epoch 9/10, Batch 20/20, Loss: 0.4894
Epoch 9/10, Train Loss: 0.3317, Valid Loss: 0.3936
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2351
Epoch 10/10, Batch 20/20, Loss: 0.3004
Epoch 10/10, Train Loss: 0.2677, Valid Loss: 0.3743
Model saved!
Accuracy: 0.8867
Precision: 0.8805
Recall: 0.8867
F1-score: 0.8806
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2850
Epoch 1/10, Batch 20/20, Loss: 1.1793
Epoch 1/10, Train Loss: 1.3036, Valid Loss: 0.9620
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9191
Epoch 2/10, Batch 20/20, Loss: 0.7504
Epoch 2/10, Train Loss: 0.8503, Valid Loss: 0.6970
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5564
Epoch 3/10, Batch 20/20, Loss: 0.7883
Epoch 3/10, Train Loss: 0.6475, Valid Loss: 0.5805
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6499
Epoch 4/10, Batch 20/20, Loss: 0.4665
Epoch 4/10, Train Loss: 0.5358, Valid Loss: 0.5171
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4172
Epoch 5/10, Batch 20/20, Loss: 0.4367
Epoch 5/10, Train Loss: 0.4508, Valid Loss: 0.4855
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5268
Epoch 6/10, Batch 20/20, Loss: 0.4939
Epoch 6/10, Train Loss: 0.4225, Valid Loss: 0.4448
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4329
Epoch 7/10, Batch 20/20, Loss: 0.2730
Epoch 7/10, Train Loss: 0.3632, Valid Loss: 0.4302
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2552
Epoch 8/10, Batch 20/20, Loss: 0.3044
Epoch 8/10, Train Loss: 0.3445, Valid Loss: 0.4176
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5725
Epoch 9/10, Batch 20/20, Loss: 0.5691
Epoch 9/10, Train Loss: 0.3399, Valid Loss: 0.4083
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2777
Epoch 10/10, Batch 20/20, Loss: 0.0867
Epoch 10/10, Train Loss: 0.2851, Valid Loss: 0.3934
Model saved!
Accuracy: 0.8914
Precision: 0.8884
Recall: 0.8914
F1-score: 0.8889
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1680
Epoch 1/10, Batch 20/20, Loss: 1.1039
Epoch 1/10, Train Loss: 1.3012, Valid Loss: 0.9464
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8652
Epoch 2/10, Batch 20/20, Loss: 0.9248
Epoch 2/10, Train Loss: 0.8625, Valid Loss: 0.6658
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5576
Epoch 3/10, Batch 20/20, Loss: 0.5745
Epoch 3/10, Train Loss: 0.6205, Valid Loss: 0.5240
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.8136
Epoch 4/10, Batch 20/20, Loss: 0.4141
Epoch 4/10, Train Loss: 0.5140, Valid Loss: 0.4370
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4172
Epoch 5/10, Batch 20/20, Loss: 0.4740
Epoch 5/10, Train Loss: 0.4484, Valid Loss: 0.3999
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5220
Epoch 6/10, Batch 20/20, Loss: 0.5209
Epoch 6/10, Train Loss: 0.4206, Valid Loss: 0.3558
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3330
Epoch 7/10, Batch 20/20, Loss: 0.4347
Epoch 7/10, Train Loss: 0.3751, Valid Loss: 0.3355
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3102
Epoch 8/10, Batch 20/20, Loss: 0.2324
Epoch 8/10, Train Loss: 0.3264, Valid Loss: 0.3117
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5478
Epoch 9/10, Batch 20/20, Loss: 0.6004
Epoch 9/10, Train Loss: 0.3301, Valid Loss: 0.2993
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2081
Epoch 10/10, Batch 20/20, Loss: 0.3423
Epoch 10/10, Train Loss: 0.2780, Valid Loss: 0.2922
Model saved!
Accuracy: 0.8867
Precision: 0.8790
Recall: 0.8867
F1-score: 0.8801
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2387
Epoch 1/10, Batch 20/20, Loss: 1.3121
Epoch 1/10, Train Loss: 1.3098, Valid Loss: 0.9496
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8558
Epoch 2/10, Batch 20/20, Loss: 0.9595
Epoch 2/10, Train Loss: 0.8409, Valid Loss: 0.6727
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5971
Epoch 3/10, Batch 20/20, Loss: 0.7007
Epoch 3/10, Train Loss: 0.6318, Valid Loss: 0.5457
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6838
Epoch 4/10, Batch 20/20, Loss: 0.5545
Epoch 4/10, Train Loss: 0.5181, Valid Loss: 0.4790
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4719
Epoch 5/10, Batch 20/20, Loss: 0.4054
Epoch 5/10, Train Loss: 0.4382, Valid Loss: 0.4253
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4649
Epoch 6/10, Batch 20/20, Loss: 0.5116
Epoch 6/10, Train Loss: 0.4101, Valid Loss: 0.4013
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3829
Epoch 7/10, Batch 20/20, Loss: 0.4396
Epoch 7/10, Train Loss: 0.3651, Valid Loss: 0.3771
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2989
Epoch 8/10, Batch 20/20, Loss: 0.3078
Epoch 8/10, Train Loss: 0.3282, Valid Loss: 0.3650
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5207
Epoch 9/10, Batch 20/20, Loss: 0.5914
Epoch 9/10, Train Loss: 0.3157, Valid Loss: 0.3435
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2280
Epoch 10/10, Batch 20/20, Loss: 0.2293
Epoch 10/10, Train Loss: 0.2567, Valid Loss: 0.3344
Model saved!
Accuracy: 0.8902
Precision: 0.8842
Recall: 0.8902
F1-score: 0.8843
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2975
Epoch 1/10, Batch 20/20, Loss: 1.2440
Epoch 1/10, Train Loss: 1.2941, Valid Loss: 0.9882
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8223
Epoch 2/10, Batch 20/20, Loss: 1.0153
Epoch 2/10, Train Loss: 0.8578, Valid Loss: 0.6899
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6182
Epoch 3/10, Batch 20/20, Loss: 0.6349
Epoch 3/10, Train Loss: 0.6437, Valid Loss: 0.5701
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7916
Epoch 4/10, Batch 20/20, Loss: 0.4758
Epoch 4/10, Train Loss: 0.5413, Valid Loss: 0.4970
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4970
Epoch 5/10, Batch 20/20, Loss: 0.5133
Epoch 5/10, Train Loss: 0.4535, Valid Loss: 0.4580
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5910
Epoch 6/10, Batch 20/20, Loss: 0.7647
Epoch 6/10, Train Loss: 0.4430, Valid Loss: 0.4201
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3272
Epoch 7/10, Batch 20/20, Loss: 0.2449
Epoch 7/10, Train Loss: 0.3644, Valid Loss: 0.4004
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4163
Epoch 8/10, Batch 20/20, Loss: 0.2074
Epoch 8/10, Train Loss: 0.3549, Valid Loss: 0.3757
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5008
Epoch 9/10, Batch 20/20, Loss: 0.7853
Epoch 9/10, Train Loss: 0.3588, Valid Loss: 0.3712
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3349
Epoch 10/10, Batch 20/20, Loss: 0.3079
Epoch 10/10, Train Loss: 0.2912, Valid Loss: 0.3439
Model saved!
Accuracy: 0.8890
Precision: 0.8830
Recall: 0.8890
F1-score: 0.8833
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2850
Epoch 1/10, Batch 20/20, Loss: 1.1076
Epoch 1/10, Train Loss: 1.3044, Valid Loss: 0.9920
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0078
Epoch 2/10, Batch 20/20, Loss: 0.7235
Epoch 2/10, Train Loss: 0.8649, Valid Loss: 0.7132
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5692
Epoch 3/10, Batch 20/20, Loss: 0.9637
Epoch 3/10, Train Loss: 0.6661, Valid Loss: 0.5845
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5846
Epoch 4/10, Batch 20/20, Loss: 0.5627
Epoch 4/10, Train Loss: 0.5348, Valid Loss: 0.5044
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5228
Epoch 5/10, Batch 20/20, Loss: 0.5140
Epoch 5/10, Train Loss: 0.4597, Valid Loss: 0.4635
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5685
Epoch 6/10, Batch 20/20, Loss: 0.4832
Epoch 6/10, Train Loss: 0.4431, Valid Loss: 0.4280
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4181
Epoch 7/10, Batch 20/20, Loss: 0.5127
Epoch 7/10, Train Loss: 0.3732, Valid Loss: 0.4075
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2948
Epoch 8/10, Batch 20/20, Loss: 0.4335
Epoch 8/10, Train Loss: 0.3449, Valid Loss: 0.3791
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4864
Epoch 9/10, Batch 20/20, Loss: 0.5482
Epoch 9/10, Train Loss: 0.3467, Valid Loss: 0.3767
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3199
Epoch 10/10, Batch 20/20, Loss: 0.2444
Epoch 10/10, Train Loss: 0.2856, Valid Loss: 0.3594
Model saved!
Accuracy: 0.8843
Precision: 0.8761
Recall: 0.8843
F1-score: 0.8784
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2957
Epoch 1/10, Batch 20/20, Loss: 1.3597
Epoch 1/10, Train Loss: 1.3182, Valid Loss: 0.9479
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9466
Epoch 2/10, Batch 20/20, Loss: 0.9222
Epoch 2/10, Train Loss: 0.8722, Valid Loss: 0.6823
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5148
Epoch 3/10, Batch 20/20, Loss: 0.7974
Epoch 3/10, Train Loss: 0.6626, Valid Loss: 0.5405
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7249
Epoch 4/10, Batch 20/20, Loss: 0.5502
Epoch 4/10, Train Loss: 0.5510, Valid Loss: 0.4635
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4411
Epoch 5/10, Batch 20/20, Loss: 0.6221
Epoch 5/10, Train Loss: 0.4708, Valid Loss: 0.4100
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4863
Epoch 6/10, Batch 20/20, Loss: 0.5762
Epoch 6/10, Train Loss: 0.4468, Valid Loss: 0.3705
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4239
Epoch 7/10, Batch 20/20, Loss: 0.6152
Epoch 7/10, Train Loss: 0.4008, Valid Loss: 0.3397
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3113
Epoch 8/10, Batch 20/20, Loss: 0.2659
Epoch 8/10, Train Loss: 0.3619, Valid Loss: 0.3222
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5849
Epoch 9/10, Batch 20/20, Loss: 0.6671
Epoch 9/10, Train Loss: 0.3540, Valid Loss: 0.3035
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3037
Epoch 10/10, Batch 20/20, Loss: 0.2356
Epoch 10/10, Train Loss: 0.2974, Valid Loss: 0.2917
Model saved!
Accuracy: 0.8867
Precision: 0.8881
Recall: 0.8867
F1-score: 0.8821
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2673
Epoch 1/10, Batch 20/20, Loss: 1.3966
Epoch 1/10, Train Loss: 1.3187, Valid Loss: 0.9463
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8519
Epoch 2/10, Batch 20/20, Loss: 0.8083
Epoch 2/10, Train Loss: 0.8590, Valid Loss: 0.6688
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5380
Epoch 3/10, Batch 20/20, Loss: 0.6015
Epoch 3/10, Train Loss: 0.6354, Valid Loss: 0.5522
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6383
Epoch 4/10, Batch 20/20, Loss: 0.4211
Epoch 4/10, Train Loss: 0.5229, Valid Loss: 0.4733
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4734
Epoch 5/10, Batch 20/20, Loss: 0.4398
Epoch 5/10, Train Loss: 0.4299, Valid Loss: 0.4348
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5269
Epoch 6/10, Batch 20/20, Loss: 0.9727
Epoch 6/10, Train Loss: 0.4402, Valid Loss: 0.3979
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4225
Epoch 7/10, Batch 20/20, Loss: 0.2798
Epoch 7/10, Train Loss: 0.3664, Valid Loss: 0.3839
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2659
Epoch 8/10, Batch 20/20, Loss: 0.1473
Epoch 8/10, Train Loss: 0.3272, Valid Loss: 0.3653
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5586
Epoch 9/10, Batch 20/20, Loss: 0.5693
Epoch 9/10, Train Loss: 0.3224, Valid Loss: 0.3658
Epoch 10/10, Batch 10/20, Loss: 0.1931
Epoch 10/10, Batch 20/20, Loss: 0.4603
Epoch 10/10, Train Loss: 0.2724, Valid Loss: 0.3451
Model saved!
Accuracy: 0.8832
Precision: 0.8795
Recall: 0.8832
F1-score: 0.8780
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3492
Epoch 1/10, Batch 20/20, Loss: 1.1952
Epoch 1/10, Train Loss: 1.2971, Valid Loss: 0.9835
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9370
Epoch 2/10, Batch 20/20, Loss: 0.7076
Epoch 2/10, Train Loss: 0.8483, Valid Loss: 0.7206
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5062
Epoch 3/10, Batch 20/20, Loss: 0.9441
Epoch 3/10, Train Loss: 0.6670, Valid Loss: 0.6045
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6121
Epoch 4/10, Batch 20/20, Loss: 0.4001
Epoch 4/10, Train Loss: 0.5259, Valid Loss: 0.5349
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5013
Epoch 5/10, Batch 20/20, Loss: 0.5282
Epoch 5/10, Train Loss: 0.4465, Valid Loss: 0.4888
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5434
Epoch 6/10, Batch 20/20, Loss: 0.6066
Epoch 6/10, Train Loss: 0.4383, Valid Loss: 0.4548
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3742
Epoch 7/10, Batch 20/20, Loss: 0.4766
Epoch 7/10, Train Loss: 0.3727, Valid Loss: 0.4296
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3018
Epoch 8/10, Batch 20/20, Loss: 0.2933
Epoch 8/10, Train Loss: 0.3489, Valid Loss: 0.4141
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5283
Epoch 9/10, Batch 20/20, Loss: 0.9113
Epoch 9/10, Train Loss: 0.3534, Valid Loss: 0.3949
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1778
Epoch 10/10, Batch 20/20, Loss: 0.2059
Epoch 10/10, Train Loss: 0.2792, Valid Loss: 0.3788
Model saved!
Accuracy: 0.8879
Precision: 0.8843
Recall: 0.8879
F1-score: 0.8855
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2879
Epoch 1/10, Batch 20/20, Loss: 1.1401
Epoch 1/10, Train Loss: 1.2922, Valid Loss: 0.9490
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8219
Epoch 2/10, Batch 20/20, Loss: 0.8369
Epoch 2/10, Train Loss: 0.8404, Valid Loss: 0.6615
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6241
Epoch 3/10, Batch 20/20, Loss: 0.5406
Epoch 3/10, Train Loss: 0.6004, Valid Loss: 0.5133
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5868
Epoch 4/10, Batch 20/20, Loss: 0.5713
Epoch 4/10, Train Loss: 0.5074, Valid Loss: 0.4464
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3955
Epoch 5/10, Batch 20/20, Loss: 0.6410
Epoch 5/10, Train Loss: 0.4305, Valid Loss: 0.3990
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6358
Epoch 6/10, Batch 20/20, Loss: 0.5546
Epoch 6/10, Train Loss: 0.4060, Valid Loss: 0.3679
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3384
Epoch 7/10, Batch 20/20, Loss: 0.4535
Epoch 7/10, Train Loss: 0.3501, Valid Loss: 0.3476
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2365
Epoch 8/10, Batch 20/20, Loss: 0.2948
Epoch 8/10, Train Loss: 0.3147, Valid Loss: 0.3275
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4035
Epoch 9/10, Batch 20/20, Loss: 0.5848
Epoch 9/10, Train Loss: 0.3072, Valid Loss: 0.3129
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2464
Epoch 10/10, Batch 20/20, Loss: 0.4370
Epoch 10/10, Train Loss: 0.2681, Valid Loss: 0.3006
Model saved!
Accuracy: 0.8762
Precision: 0.8709
Recall: 0.8762
F1-score: 0.8727
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1947
Epoch 1/10, Batch 20/20, Loss: 1.0676
Epoch 1/10, Train Loss: 1.3043, Valid Loss: 0.9712
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8490
Epoch 2/10, Batch 20/20, Loss: 0.8498
Epoch 2/10, Train Loss: 0.8514, Valid Loss: 0.6846
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5579
Epoch 3/10, Batch 20/20, Loss: 0.8268
Epoch 3/10, Train Loss: 0.6456, Valid Loss: 0.5642
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5806
Epoch 4/10, Batch 20/20, Loss: 0.8331
Epoch 4/10, Train Loss: 0.5296, Valid Loss: 0.4845
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4651
Epoch 5/10, Batch 20/20, Loss: 0.3680
Epoch 5/10, Train Loss: 0.4420, Valid Loss: 0.4470
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6260
Epoch 6/10, Batch 20/20, Loss: 0.4679
Epoch 6/10, Train Loss: 0.4127, Valid Loss: 0.4035
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3959
Epoch 7/10, Batch 20/20, Loss: 0.4217
Epoch 7/10, Train Loss: 0.3720, Valid Loss: 0.3868
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2527
Epoch 8/10, Batch 20/20, Loss: 0.2285
Epoch 8/10, Train Loss: 0.3418, Valid Loss: 0.3604
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4177
Epoch 9/10, Batch 20/20, Loss: 0.4227
Epoch 9/10, Train Loss: 0.3288, Valid Loss: 0.3515
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2678
Epoch 10/10, Batch 20/20, Loss: 0.1616
Epoch 10/10, Train Loss: 0.2669, Valid Loss: 0.3282
Model saved!
Accuracy: 0.8855
Precision: 0.8795
Recall: 0.8855
F1-score: 0.8813
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2722
Epoch 1/10, Batch 20/20, Loss: 1.2564
Epoch 1/10, Train Loss: 1.3096, Valid Loss: 0.9701
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8535
Epoch 2/10, Batch 20/20, Loss: 0.8256
Epoch 2/10, Train Loss: 0.8442, Valid Loss: 0.6875
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6067
Epoch 3/10, Batch 20/20, Loss: 0.6272
Epoch 3/10, Train Loss: 0.6179, Valid Loss: 0.5581
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5294
Epoch 4/10, Batch 20/20, Loss: 0.4725
Epoch 4/10, Train Loss: 0.5041, Valid Loss: 0.4950
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4624
Epoch 5/10, Batch 20/20, Loss: 0.5921
Epoch 5/10, Train Loss: 0.4333, Valid Loss: 0.4522
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5763
Epoch 6/10, Batch 20/20, Loss: 0.4863
Epoch 6/10, Train Loss: 0.3980, Valid Loss: 0.4168
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3455
Epoch 7/10, Batch 20/20, Loss: 0.1837
Epoch 7/10, Train Loss: 0.3562, Valid Loss: 0.3958
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2817
Epoch 8/10, Batch 20/20, Loss: 0.2395
Epoch 8/10, Train Loss: 0.3212, Valid Loss: 0.3718
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3661
Epoch 9/10, Batch 20/20, Loss: 0.5854
Epoch 9/10, Train Loss: 0.3148, Valid Loss: 0.3675
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2587
Epoch 10/10, Batch 20/20, Loss: 0.1801
Epoch 10/10, Train Loss: 0.2696, Valid Loss: 0.3550
Model saved!
Accuracy: 0.8867
Precision: 0.8813
Recall: 0.8867
F1-score: 0.8831
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3242
Epoch 1/10, Batch 20/20, Loss: 1.0880
Epoch 1/10, Train Loss: 1.2956, Valid Loss: 0.9579
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9808
Epoch 2/10, Batch 20/20, Loss: 1.1006
Epoch 2/10, Train Loss: 0.8632, Valid Loss: 0.6821
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5158
Epoch 3/10, Batch 20/20, Loss: 0.6652
Epoch 3/10, Train Loss: 0.6204, Valid Loss: 0.5531
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6161
Epoch 4/10, Batch 20/20, Loss: 0.4586
Epoch 4/10, Train Loss: 0.5166, Valid Loss: 0.4885
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4718
Epoch 5/10, Batch 20/20, Loss: 0.2507
Epoch 5/10, Train Loss: 0.4364, Valid Loss: 0.4396
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5112
Epoch 6/10, Batch 20/20, Loss: 0.4856
Epoch 6/10, Train Loss: 0.4208, Valid Loss: 0.4072
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3561
Epoch 7/10, Batch 20/20, Loss: 0.4780
Epoch 7/10, Train Loss: 0.3833, Valid Loss: 0.3879
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3482
Epoch 8/10, Batch 20/20, Loss: 0.2474
Epoch 8/10, Train Loss: 0.3418, Valid Loss: 0.3653
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4819
Epoch 9/10, Batch 20/20, Loss: 0.6805
Epoch 9/10, Train Loss: 0.3443, Valid Loss: 0.3527
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3770
Epoch 10/10, Batch 20/20, Loss: 0.4757
Epoch 10/10, Train Loss: 0.2992, Valid Loss: 0.3471
Model saved!
Accuracy: 0.8855
Precision: 0.8854
Recall: 0.8855
F1-score: 0.8835
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3308
Epoch 1/10, Batch 20/20, Loss: 1.1573
Epoch 1/10, Train Loss: 1.3104, Valid Loss: 0.9589
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9138
Epoch 2/10, Batch 20/20, Loss: 0.9308
Epoch 2/10, Train Loss: 0.8813, Valid Loss: 0.6835
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5892
Epoch 3/10, Batch 20/20, Loss: 1.0030
Epoch 3/10, Train Loss: 0.6818, Valid Loss: 0.5477
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.8625
Epoch 4/10, Batch 20/20, Loss: 0.6179
Epoch 4/10, Train Loss: 0.5579, Valid Loss: 0.4846
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5428
Epoch 5/10, Batch 20/20, Loss: 0.3659
Epoch 5/10, Train Loss: 0.4722, Valid Loss: 0.4321
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4876
Epoch 6/10, Batch 20/20, Loss: 0.6661
Epoch 6/10, Train Loss: 0.4502, Valid Loss: 0.3936
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4181
Epoch 7/10, Batch 20/20, Loss: 0.3980
Epoch 7/10, Train Loss: 0.3862, Valid Loss: 0.3690
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3971
Epoch 8/10, Batch 20/20, Loss: 0.2267
Epoch 8/10, Train Loss: 0.3529, Valid Loss: 0.3514
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4471
Epoch 9/10, Batch 20/20, Loss: 0.9656
Epoch 9/10, Train Loss: 0.3623, Valid Loss: 0.3425
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3267
Epoch 10/10, Batch 20/20, Loss: 0.1973
Epoch 10/10, Train Loss: 0.2944, Valid Loss: 0.3206
Model saved!
Accuracy: 0.8843
Precision: 0.8806
Recall: 0.8843
F1-score: 0.8821
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2007
Epoch 1/10, Batch 20/20, Loss: 1.1386
Epoch 1/10, Train Loss: 1.3045, Valid Loss: 0.9404
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8963
Epoch 2/10, Batch 20/20, Loss: 0.9649
Epoch 2/10, Train Loss: 0.8612, Valid Loss: 0.6592
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6834
Epoch 3/10, Batch 20/20, Loss: 0.5999
Epoch 3/10, Train Loss: 0.6354, Valid Loss: 0.5236
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7780
Epoch 4/10, Batch 20/20, Loss: 0.3714
Epoch 4/10, Train Loss: 0.5186, Valid Loss: 0.4438
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4052
Epoch 5/10, Batch 20/20, Loss: 0.3701
Epoch 5/10, Train Loss: 0.4368, Valid Loss: 0.3947
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5482
Epoch 6/10, Batch 20/20, Loss: 0.5834
Epoch 6/10, Train Loss: 0.4123, Valid Loss: 0.3475
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4349
Epoch 7/10, Batch 20/20, Loss: 0.3995
Epoch 7/10, Train Loss: 0.3726, Valid Loss: 0.3379
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2176
Epoch 8/10, Batch 20/20, Loss: 0.3493
Epoch 8/10, Train Loss: 0.3283, Valid Loss: 0.3160
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4634
Epoch 9/10, Batch 20/20, Loss: 0.4833
Epoch 9/10, Train Loss: 0.3339, Valid Loss: 0.3054
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2525
Epoch 10/10, Batch 20/20, Loss: 0.2014
Epoch 10/10, Train Loss: 0.2665, Valid Loss: 0.2860
Model saved!
Accuracy: 0.8832
Precision: 0.8775
Recall: 0.8832
F1-score: 0.8779
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2778
Epoch 1/10, Batch 20/20, Loss: 1.1157
Epoch 1/10, Train Loss: 1.3057, Valid Loss: 0.9479
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8106
Epoch 2/10, Batch 20/20, Loss: 0.7810
Epoch 2/10, Train Loss: 0.8496, Valid Loss: 0.6642
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5909
Epoch 3/10, Batch 20/20, Loss: 0.8609
Epoch 3/10, Train Loss: 0.6448, Valid Loss: 0.5297
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6507
Epoch 4/10, Batch 20/20, Loss: 0.6029
Epoch 4/10, Train Loss: 0.5205, Valid Loss: 0.4667
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4646
Epoch 5/10, Batch 20/20, Loss: 0.2997
Epoch 5/10, Train Loss: 0.4394, Valid Loss: 0.4271
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4506
Epoch 6/10, Batch 20/20, Loss: 0.4983
Epoch 6/10, Train Loss: 0.4115, Valid Loss: 0.3929
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3369
Epoch 7/10, Batch 20/20, Loss: 0.6826
Epoch 7/10, Train Loss: 0.3699, Valid Loss: 0.3786
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2342
Epoch 8/10, Batch 20/20, Loss: 0.1956
Epoch 8/10, Train Loss: 0.3346, Valid Loss: 0.3710
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5107
Epoch 9/10, Batch 20/20, Loss: 0.5088
Epoch 9/10, Train Loss: 0.3279, Valid Loss: 0.3548
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2308
Epoch 10/10, Batch 20/20, Loss: 0.1646
Epoch 10/10, Train Loss: 0.2771, Valid Loss: 0.3554
Accuracy: 0.8890
Precision: 0.8827
Recall: 0.8890
F1-score: 0.8845
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1952
Epoch 1/10, Batch 20/20, Loss: 1.3950
Epoch 1/10, Train Loss: 1.2992, Valid Loss: 0.9121
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7669
Epoch 2/10, Batch 20/20, Loss: 0.9053
Epoch 2/10, Train Loss: 0.8475, Valid Loss: 0.6449
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5421
Epoch 3/10, Batch 20/20, Loss: 0.7863
Epoch 3/10, Train Loss: 0.6324, Valid Loss: 0.5176
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7556
Epoch 4/10, Batch 20/20, Loss: 0.3809
Epoch 4/10, Train Loss: 0.5085, Valid Loss: 0.4519
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4620
Epoch 5/10, Batch 20/20, Loss: 0.3842
Epoch 5/10, Train Loss: 0.4362, Valid Loss: 0.4013
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6085
Epoch 6/10, Batch 20/20, Loss: 0.8405
Epoch 6/10, Train Loss: 0.4411, Valid Loss: 0.3678
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4143
Epoch 7/10, Batch 20/20, Loss: 0.3831
Epoch 7/10, Train Loss: 0.3763, Valid Loss: 0.3570
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3050
Epoch 8/10, Batch 20/20, Loss: 0.2641
Epoch 8/10, Train Loss: 0.3250, Valid Loss: 0.3349
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4456
Epoch 9/10, Batch 20/20, Loss: 0.6747
Epoch 9/10, Train Loss: 0.3273, Valid Loss: 0.3261
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2418
Epoch 10/10, Batch 20/20, Loss: 0.2808
Epoch 10/10, Train Loss: 0.2695, Valid Loss: 0.3172
Model saved!
Accuracy: 0.8832
Precision: 0.8827
Recall: 0.8832
F1-score: 0.8780
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3493
Epoch 1/10, Batch 20/20, Loss: 1.0065
Epoch 1/10, Train Loss: 1.2843, Valid Loss: 0.9584
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8031
Epoch 2/10, Batch 20/20, Loss: 0.8725
Epoch 2/10, Train Loss: 0.8417, Valid Loss: 0.6732
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5921
Epoch 3/10, Batch 20/20, Loss: 1.2532
Epoch 3/10, Train Loss: 0.6573, Valid Loss: 0.5464
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6703
Epoch 4/10, Batch 20/20, Loss: 0.4542
Epoch 4/10, Train Loss: 0.5174, Valid Loss: 0.4665
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3602
Epoch 5/10, Batch 20/20, Loss: 0.3055
Epoch 5/10, Train Loss: 0.4407, Valid Loss: 0.4205
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4818
Epoch 6/10, Batch 20/20, Loss: 0.7147
Epoch 6/10, Train Loss: 0.4176, Valid Loss: 0.3897
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.5383
Epoch 7/10, Batch 20/20, Loss: 0.4399
Epoch 7/10, Train Loss: 0.3600, Valid Loss: 0.3712
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2928
Epoch 8/10, Batch 20/20, Loss: 0.5071
Epoch 8/10, Train Loss: 0.3389, Valid Loss: 0.3439
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5191
Epoch 9/10, Batch 20/20, Loss: 0.7320
Epoch 9/10, Train Loss: 0.3341, Valid Loss: 0.3394
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3227
Epoch 10/10, Batch 20/20, Loss: 0.6218
Epoch 10/10, Train Loss: 0.2965, Valid Loss: 0.3242
Model saved!
Accuracy: 0.8867
Precision: 0.8860
Recall: 0.8867
F1-score: 0.8833
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3188
Epoch 1/10, Batch 20/20, Loss: 1.0367
Epoch 1/10, Train Loss: 1.3053, Valid Loss: 0.9742
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9243
Epoch 2/10, Batch 20/20, Loss: 0.9412
Epoch 2/10, Train Loss: 0.8711, Valid Loss: 0.6964
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5327
Epoch 3/10, Batch 20/20, Loss: 1.0420
Epoch 3/10, Train Loss: 0.6524, Valid Loss: 0.5667
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6832
Epoch 4/10, Batch 20/20, Loss: 0.3898
Epoch 4/10, Train Loss: 0.5308, Valid Loss: 0.4940
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4344
Epoch 5/10, Batch 20/20, Loss: 0.3242
Epoch 5/10, Train Loss: 0.4372, Valid Loss: 0.4413
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.3911
Epoch 6/10, Batch 20/20, Loss: 0.4966
Epoch 6/10, Train Loss: 0.4315, Valid Loss: 0.4074
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4805
Epoch 7/10, Batch 20/20, Loss: 0.5205
Epoch 7/10, Train Loss: 0.3687, Valid Loss: 0.3888
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2927
Epoch 8/10, Batch 20/20, Loss: 0.2618
Epoch 8/10, Train Loss: 0.3330, Valid Loss: 0.3669
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3883
Epoch 9/10, Batch 20/20, Loss: 0.4058
Epoch 9/10, Train Loss: 0.3297, Valid Loss: 0.3484
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2280
Epoch 10/10, Batch 20/20, Loss: 0.2892
Epoch 10/10, Train Loss: 0.2772, Valid Loss: 0.3447
Model saved!
Accuracy: 0.8984
Precision: 0.8955
Recall: 0.8984
F1-score: 0.8964
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3126
Epoch 1/10, Batch 20/20, Loss: 1.2998
Epoch 1/10, Train Loss: 1.3191, Valid Loss: 0.9729
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9319
Epoch 2/10, Batch 20/20, Loss: 0.9207
Epoch 2/10, Train Loss: 0.8695, Valid Loss: 0.6909
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5687
Epoch 3/10, Batch 20/20, Loss: 0.6693
Epoch 3/10, Train Loss: 0.6363, Valid Loss: 0.5462
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5872
Epoch 4/10, Batch 20/20, Loss: 0.6100
Epoch 4/10, Train Loss: 0.5252, Valid Loss: 0.4668
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4785
Epoch 5/10, Batch 20/20, Loss: 0.3989
Epoch 5/10, Train Loss: 0.4349, Valid Loss: 0.4120
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4613
Epoch 6/10, Batch 20/20, Loss: 0.6606
Epoch 6/10, Train Loss: 0.4195, Valid Loss: 0.3682
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4144
Epoch 7/10, Batch 20/20, Loss: 0.3947
Epoch 7/10, Train Loss: 0.3553, Valid Loss: 0.3442
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2522
Epoch 8/10, Batch 20/20, Loss: 0.3172
Epoch 8/10, Train Loss: 0.3215, Valid Loss: 0.3218
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3803
Epoch 9/10, Batch 20/20, Loss: 0.4856
Epoch 9/10, Train Loss: 0.3135, Valid Loss: 0.3066
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2770
Epoch 10/10, Batch 20/20, Loss: 0.2499
Epoch 10/10, Train Loss: 0.2644, Valid Loss: 0.2883
Model saved!
Accuracy: 0.8867
Precision: 0.8825
Recall: 0.8867
F1-score: 0.8807
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2817
Epoch 1/10, Batch 20/20, Loss: 1.2170
Epoch 1/10, Train Loss: 1.3067, Valid Loss: 0.9180
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8450
Epoch 2/10, Batch 20/20, Loss: 0.8691
Epoch 2/10, Train Loss: 0.8443, Valid Loss: 0.6404
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5544
Epoch 3/10, Batch 20/20, Loss: 0.6743
Epoch 3/10, Train Loss: 0.6226, Valid Loss: 0.5100
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6616
Epoch 4/10, Batch 20/20, Loss: 0.3935
Epoch 4/10, Train Loss: 0.5193, Valid Loss: 0.4404
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5313
Epoch 5/10, Batch 20/20, Loss: 0.3984
Epoch 5/10, Train Loss: 0.4294, Valid Loss: 0.3941
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5143
Epoch 6/10, Batch 20/20, Loss: 0.3890
Epoch 6/10, Train Loss: 0.4151, Valid Loss: 0.3487
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4620
Epoch 7/10, Batch 20/20, Loss: 0.2489
Epoch 7/10, Train Loss: 0.3712, Valid Loss: 0.3320
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3026
Epoch 8/10, Batch 20/20, Loss: 0.2481
Epoch 8/10, Train Loss: 0.3315, Valid Loss: 0.3047
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4812
Epoch 9/10, Batch 20/20, Loss: 0.7675
Epoch 9/10, Train Loss: 0.3308, Valid Loss: 0.3108
Epoch 10/10, Batch 10/20, Loss: 0.2888
Epoch 10/10, Batch 20/20, Loss: 0.3322
Epoch 10/10, Train Loss: 0.2679, Valid Loss: 0.2845
Model saved!
Accuracy: 0.8843
Precision: 0.8793
Recall: 0.8843
F1-score: 0.8797
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2271
Epoch 1/10, Batch 20/20, Loss: 1.2251
Epoch 1/10, Train Loss: 1.3004, Valid Loss: 0.9203
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8443
Epoch 2/10, Batch 20/20, Loss: 1.0590
Epoch 2/10, Train Loss: 0.8696, Valid Loss: 0.6388
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5501
Epoch 3/10, Batch 20/20, Loss: 0.5134
Epoch 3/10, Train Loss: 0.6519, Valid Loss: 0.5022
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7320
Epoch 4/10, Batch 20/20, Loss: 0.5133
Epoch 4/10, Train Loss: 0.5454, Valid Loss: 0.4306
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5422
Epoch 5/10, Batch 20/20, Loss: 0.3246
Epoch 5/10, Train Loss: 0.4512, Valid Loss: 0.3837
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5117
Epoch 6/10, Batch 20/20, Loss: 0.5962
Epoch 6/10, Train Loss: 0.4400, Valid Loss: 0.3461
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4054
Epoch 7/10, Batch 20/20, Loss: 0.6066
Epoch 7/10, Train Loss: 0.4066, Valid Loss: 0.3227
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3305
Epoch 8/10, Batch 20/20, Loss: 0.2505
Epoch 8/10, Train Loss: 0.3566, Valid Loss: 0.3106
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5245
Epoch 9/10, Batch 20/20, Loss: 0.5607
Epoch 9/10, Train Loss: 0.3342, Valid Loss: 0.2970
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3271
Epoch 10/10, Batch 20/20, Loss: 0.2791
Epoch 10/10, Train Loss: 0.2864, Valid Loss: 0.2869
Model saved!
Accuracy: 0.8890
Precision: 0.8831
Recall: 0.8890
F1-score: 0.8845
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2240
Epoch 1/10, Batch 20/20, Loss: 1.3218
Epoch 1/10, Train Loss: 1.3111, Valid Loss: 0.9812
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8393
Epoch 2/10, Batch 20/20, Loss: 0.7688
Epoch 2/10, Train Loss: 0.8556, Valid Loss: 0.7223
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5847
Epoch 3/10, Batch 20/20, Loss: 0.6412
Epoch 3/10, Train Loss: 0.6332, Valid Loss: 0.5827
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6667
Epoch 4/10, Batch 20/20, Loss: 0.5037
Epoch 4/10, Train Loss: 0.5303, Valid Loss: 0.5189
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4734
Epoch 5/10, Batch 20/20, Loss: 0.3892
Epoch 5/10, Train Loss: 0.4472, Valid Loss: 0.4665
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5583
Epoch 6/10, Batch 20/20, Loss: 0.5610
Epoch 6/10, Train Loss: 0.4255, Valid Loss: 0.4275
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3270
Epoch 7/10, Batch 20/20, Loss: 0.4949
Epoch 7/10, Train Loss: 0.3758, Valid Loss: 0.4067
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3156
Epoch 8/10, Batch 20/20, Loss: 0.3584
Epoch 8/10, Train Loss: 0.3317, Valid Loss: 0.3888
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4442
Epoch 9/10, Batch 20/20, Loss: 0.5852
Epoch 9/10, Train Loss: 0.3367, Valid Loss: 0.3646
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2123
Epoch 10/10, Batch 20/20, Loss: 0.2447
Epoch 10/10, Train Loss: 0.2824, Valid Loss: 0.3698
Accuracy: 0.8808
Precision: 0.8740
Recall: 0.8808
F1-score: 0.8758
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2122
Epoch 1/10, Batch 20/20, Loss: 1.1789
Epoch 1/10, Train Loss: 1.3238, Valid Loss: 0.9418
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9282
Epoch 2/10, Batch 20/20, Loss: 0.9470
Epoch 2/10, Train Loss: 0.8754, Valid Loss: 0.6775
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5431
Epoch 3/10, Batch 20/20, Loss: 0.7909
Epoch 3/10, Train Loss: 0.6530, Valid Loss: 0.5302
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6293
Epoch 4/10, Batch 20/20, Loss: 0.4181
Epoch 4/10, Train Loss: 0.5324, Valid Loss: 0.4650
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4381
Epoch 5/10, Batch 20/20, Loss: 0.6625
Epoch 5/10, Train Loss: 0.4647, Valid Loss: 0.4070
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5940
Epoch 6/10, Batch 20/20, Loss: 0.6401
Epoch 6/10, Train Loss: 0.4363, Valid Loss: 0.3767
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3660
Epoch 7/10, Batch 20/20, Loss: 0.5466
Epoch 7/10, Train Loss: 0.3891, Valid Loss: 0.3518
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4345
Epoch 8/10, Batch 20/20, Loss: 0.3585
Epoch 8/10, Train Loss: 0.3609, Valid Loss: 0.3335
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5921
Epoch 9/10, Batch 20/20, Loss: 0.3277
Epoch 9/10, Train Loss: 0.3305, Valid Loss: 0.3064
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2641
Epoch 10/10, Batch 20/20, Loss: 0.6929
Epoch 10/10, Train Loss: 0.3089, Valid Loss: 0.3054
Model saved!
Accuracy: 0.8843
Precision: 0.8769
Recall: 0.8843
F1-score: 0.8783
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1897
Epoch 1/10, Batch 20/20, Loss: 1.2238
Epoch 1/10, Train Loss: 1.2975, Valid Loss: 0.9618
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8943
Epoch 2/10, Batch 20/20, Loss: 0.9216
Epoch 2/10, Train Loss: 0.8546, Valid Loss: 0.6898
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6437
Epoch 3/10, Batch 20/20, Loss: 0.7752
Epoch 3/10, Train Loss: 0.6440, Valid Loss: 0.5560
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7268
Epoch 4/10, Batch 20/20, Loss: 0.5089
Epoch 4/10, Train Loss: 0.5242, Valid Loss: 0.4737
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4929
Epoch 5/10, Batch 20/20, Loss: 0.4249
Epoch 5/10, Train Loss: 0.4551, Valid Loss: 0.4330
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5106
Epoch 6/10, Batch 20/20, Loss: 0.7081
Epoch 6/10, Train Loss: 0.4351, Valid Loss: 0.3922
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4067
Epoch 7/10, Batch 20/20, Loss: 0.5876
Epoch 7/10, Train Loss: 0.3851, Valid Loss: 0.3643
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3491
Epoch 8/10, Batch 20/20, Loss: 0.5073
Epoch 8/10, Train Loss: 0.3503, Valid Loss: 0.3420
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4421
Epoch 9/10, Batch 20/20, Loss: 0.8439
Epoch 9/10, Train Loss: 0.3513, Valid Loss: 0.3365
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2343
Epoch 10/10, Batch 20/20, Loss: 0.3909
Epoch 10/10, Train Loss: 0.2785, Valid Loss: 0.3127
Model saved!
Accuracy: 0.8949
Precision: 0.8894
Recall: 0.8949
F1-score: 0.8902
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2043
Epoch 1/10, Batch 20/20, Loss: 1.2520
Epoch 1/10, Train Loss: 1.3091, Valid Loss: 0.9256
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8180
Epoch 2/10, Batch 20/20, Loss: 0.9175
Epoch 2/10, Train Loss: 0.8637, Valid Loss: 0.6505
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5632
Epoch 3/10, Batch 20/20, Loss: 1.0519
Epoch 3/10, Train Loss: 0.6564, Valid Loss: 0.5108
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6773
Epoch 4/10, Batch 20/20, Loss: 0.3090
Epoch 4/10, Train Loss: 0.5314, Valid Loss: 0.4479
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4921
Epoch 5/10, Batch 20/20, Loss: 0.3928
Epoch 5/10, Train Loss: 0.4421, Valid Loss: 0.3924
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6743
Epoch 6/10, Batch 20/20, Loss: 0.5337
Epoch 6/10, Train Loss: 0.4308, Valid Loss: 0.3611
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4790
Epoch 7/10, Batch 20/20, Loss: 0.2518
Epoch 7/10, Train Loss: 0.3835, Valid Loss: 0.3437
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2779
Epoch 8/10, Batch 20/20, Loss: 0.2448
Epoch 8/10, Train Loss: 0.3364, Valid Loss: 0.3183
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5820
Epoch 9/10, Batch 20/20, Loss: 0.8244
Epoch 9/10, Train Loss: 0.3471, Valid Loss: 0.3109
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2390
Epoch 10/10, Batch 20/20, Loss: 0.2928
Epoch 10/10, Train Loss: 0.2856, Valid Loss: 0.2909
Model saved!
Accuracy: 0.8832
Precision: 0.8773
Recall: 0.8832
F1-score: 0.8795
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1987
Epoch 1/10, Batch 20/20, Loss: 1.1869
Epoch 1/10, Train Loss: 1.2796, Valid Loss: 0.9436
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7475
Epoch 2/10, Batch 20/20, Loss: 0.9373
Epoch 2/10, Train Loss: 0.8357, Valid Loss: 0.6819
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6277
Epoch 3/10, Batch 20/20, Loss: 0.7181
Epoch 3/10, Train Loss: 0.6112, Valid Loss: 0.5464
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7056
Epoch 4/10, Batch 20/20, Loss: 0.4639
Epoch 4/10, Train Loss: 0.4991, Valid Loss: 0.4715
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4374
Epoch 5/10, Batch 20/20, Loss: 0.2465
Epoch 5/10, Train Loss: 0.4132, Valid Loss: 0.4209
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4382
Epoch 6/10, Batch 20/20, Loss: 0.7242
Epoch 6/10, Train Loss: 0.4123, Valid Loss: 0.3899
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3470
Epoch 7/10, Batch 20/20, Loss: 0.4291
Epoch 7/10, Train Loss: 0.3426, Valid Loss: 0.3614
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3001
Epoch 8/10, Batch 20/20, Loss: 0.3317
Epoch 8/10, Train Loss: 0.3091, Valid Loss: 0.3492
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3133
Epoch 9/10, Batch 20/20, Loss: 0.3948
Epoch 9/10, Train Loss: 0.3018, Valid Loss: 0.3325
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1975
Epoch 10/10, Batch 20/20, Loss: 0.1656
Epoch 10/10, Train Loss: 0.2622, Valid Loss: 0.3199
Model saved!
Accuracy: 0.8914
Precision: 0.8859
Recall: 0.8914
F1-score: 0.8855
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2813
Epoch 1/10, Batch 20/20, Loss: 1.1671
Epoch 1/10, Train Loss: 1.2989, Valid Loss: 0.9645
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8622
Epoch 2/10, Batch 20/20, Loss: 0.9682
Epoch 2/10, Train Loss: 0.8395, Valid Loss: 0.7094
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5116
Epoch 3/10, Batch 20/20, Loss: 0.6079
Epoch 3/10, Train Loss: 0.6215, Valid Loss: 0.5843
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7530
Epoch 4/10, Batch 20/20, Loss: 0.3651
Epoch 4/10, Train Loss: 0.5042, Valid Loss: 0.5130
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4206
Epoch 5/10, Batch 20/20, Loss: 0.4655
Epoch 5/10, Train Loss: 0.4251, Valid Loss: 0.4730
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4129
Epoch 6/10, Batch 20/20, Loss: 0.5568
Epoch 6/10, Train Loss: 0.4039, Valid Loss: 0.4237
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4229
Epoch 7/10, Batch 20/20, Loss: 0.4944
Epoch 7/10, Train Loss: 0.3609, Valid Loss: 0.4071
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2282
Epoch 8/10, Batch 20/20, Loss: 0.2751
Epoch 8/10, Train Loss: 0.3121, Valid Loss: 0.3821
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5669
Epoch 9/10, Batch 20/20, Loss: 0.4255
Epoch 9/10, Train Loss: 0.2986, Valid Loss: 0.3711
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2476
Epoch 10/10, Batch 20/20, Loss: 0.3301
Epoch 10/10, Train Loss: 0.2606, Valid Loss: 0.3524
Model saved!
Accuracy: 0.8820
Precision: 0.8766
Recall: 0.8820
F1-score: 0.8784
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2517
Epoch 1/10, Batch 20/20, Loss: 1.1751
Epoch 1/10, Train Loss: 1.3003, Valid Loss: 0.9408
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8728
Epoch 2/10, Batch 20/20, Loss: 0.8676
Epoch 2/10, Train Loss: 0.8473, Valid Loss: 0.6768
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6228
Epoch 3/10, Batch 20/20, Loss: 0.7044
Epoch 3/10, Train Loss: 0.6383, Valid Loss: 0.5515
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.4845
Epoch 4/10, Batch 20/20, Loss: 0.3746
Epoch 4/10, Train Loss: 0.5267, Valid Loss: 0.4791
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5319
Epoch 5/10, Batch 20/20, Loss: 0.4656
Epoch 5/10, Train Loss: 0.4423, Valid Loss: 0.4300
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4464
Epoch 6/10, Batch 20/20, Loss: 0.7362
Epoch 6/10, Train Loss: 0.4324, Valid Loss: 0.3928
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4066
Epoch 7/10, Batch 20/20, Loss: 0.3118
Epoch 7/10, Train Loss: 0.3770, Valid Loss: 0.3726
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3556
Epoch 8/10, Batch 20/20, Loss: 0.5486
Epoch 8/10, Train Loss: 0.3432, Valid Loss: 0.3474
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4037
Epoch 9/10, Batch 20/20, Loss: 0.6176
Epoch 9/10, Train Loss: 0.3306, Valid Loss: 0.3360
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1721
Epoch 10/10, Batch 20/20, Loss: 0.4309
Epoch 10/10, Train Loss: 0.2980, Valid Loss: 0.3230
Model saved!
Accuracy: 0.8937
Precision: 0.8907
Recall: 0.8937
F1-score: 0.8913
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3110
Epoch 1/10, Batch 20/20, Loss: 1.1540
Epoch 1/10, Train Loss: 1.2913, Valid Loss: 0.9621
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8669
Epoch 2/10, Batch 20/20, Loss: 0.6385
Epoch 2/10, Train Loss: 0.8252, Valid Loss: 0.6932
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4480
Epoch 3/10, Batch 20/20, Loss: 0.9811
Epoch 3/10, Train Loss: 0.6329, Valid Loss: 0.5691
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6585
Epoch 4/10, Batch 20/20, Loss: 0.4883
Epoch 4/10, Train Loss: 0.5072, Valid Loss: 0.4941
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5127
Epoch 5/10, Batch 20/20, Loss: 0.6132
Epoch 5/10, Train Loss: 0.4244, Valid Loss: 0.4528
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4561
Epoch 6/10, Batch 20/20, Loss: 0.4651
Epoch 6/10, Train Loss: 0.4013, Valid Loss: 0.4144
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3355
Epoch 7/10, Batch 20/20, Loss: 0.5336
Epoch 7/10, Train Loss: 0.3606, Valid Loss: 0.3969
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3161
Epoch 8/10, Batch 20/20, Loss: 0.4596
Epoch 8/10, Train Loss: 0.3223, Valid Loss: 0.3722
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4029
Epoch 9/10, Batch 20/20, Loss: 0.5867
Epoch 9/10, Train Loss: 0.3066, Valid Loss: 0.3622
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2947
Epoch 10/10, Batch 20/20, Loss: 0.1373
Epoch 10/10, Train Loss: 0.2673, Valid Loss: 0.3475
Model saved!
Accuracy: 0.8808
Precision: 0.8788
Recall: 0.8808
F1-score: 0.8794
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2896
Epoch 1/10, Batch 20/20, Loss: 1.1828
Epoch 1/10, Train Loss: 1.3048, Valid Loss: 1.0465
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9376
Epoch 2/10, Batch 20/20, Loss: 0.9909
Epoch 2/10, Train Loss: 0.8658, Valid Loss: 0.8121
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5644
Epoch 3/10, Batch 20/20, Loss: 0.6470
Epoch 3/10, Train Loss: 0.6345, Valid Loss: 0.7046
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6475
Epoch 4/10, Batch 20/20, Loss: 0.2932
Epoch 4/10, Train Loss: 0.5188, Valid Loss: 0.6380
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4891
Epoch 5/10, Batch 20/20, Loss: 0.3680
Epoch 5/10, Train Loss: 0.4488, Valid Loss: 0.5873
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5994
Epoch 6/10, Batch 20/20, Loss: 0.4357
Epoch 6/10, Train Loss: 0.4161, Valid Loss: 0.5415
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4009
Epoch 7/10, Batch 20/20, Loss: 0.3284
Epoch 7/10, Train Loss: 0.3764, Valid Loss: 0.5196
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3532
Epoch 8/10, Batch 20/20, Loss: 0.2770
Epoch 8/10, Train Loss: 0.3378, Valid Loss: 0.4992
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3582
Epoch 9/10, Batch 20/20, Loss: 0.5369
Epoch 9/10, Train Loss: 0.3196, Valid Loss: 0.4931
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2017
Epoch 10/10, Batch 20/20, Loss: 0.2824
Epoch 10/10, Train Loss: 0.2793, Valid Loss: 0.4698
Model saved!
Accuracy: 0.8914
Precision: 0.8892
Recall: 0.8914
F1-score: 0.8891
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2854
Epoch 1/10, Batch 20/20, Loss: 1.2816
Epoch 1/10, Train Loss: 1.3035, Valid Loss: 0.9441
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8497
Epoch 2/10, Batch 20/20, Loss: 0.9410
Epoch 2/10, Train Loss: 0.8582, Valid Loss: 0.6849
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5636
Epoch 3/10, Batch 20/20, Loss: 0.9440
Epoch 3/10, Train Loss: 0.6440, Valid Loss: 0.5661
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6431
Epoch 4/10, Batch 20/20, Loss: 0.3705
Epoch 4/10, Train Loss: 0.5397, Valid Loss: 0.4961
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4072
Epoch 5/10, Batch 20/20, Loss: 0.4821
Epoch 5/10, Train Loss: 0.4527, Valid Loss: 0.4470
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5702
Epoch 6/10, Batch 20/20, Loss: 0.7720
Epoch 6/10, Train Loss: 0.4597, Valid Loss: 0.4190
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4336
Epoch 7/10, Batch 20/20, Loss: 0.4493
Epoch 7/10, Train Loss: 0.3826, Valid Loss: 0.3939
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3413
Epoch 8/10, Batch 20/20, Loss: 0.3563
Epoch 8/10, Train Loss: 0.3607, Valid Loss: 0.3748
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4289
Epoch 9/10, Batch 20/20, Loss: 0.6285
Epoch 9/10, Train Loss: 0.3560, Valid Loss: 0.3624
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1827
Epoch 10/10, Batch 20/20, Loss: 0.4499
Epoch 10/10, Train Loss: 0.2895, Valid Loss: 0.3564
Model saved!
Accuracy: 0.8797
Precision: 0.8733
Recall: 0.8797
F1-score: 0.8741
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1906
Epoch 1/10, Batch 20/20, Loss: 1.1378
Epoch 1/10, Train Loss: 1.2838, Valid Loss: 0.9406
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8324
Epoch 2/10, Batch 20/20, Loss: 0.7464
Epoch 2/10, Train Loss: 0.8316, Valid Loss: 0.6700
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6495
Epoch 3/10, Batch 20/20, Loss: 0.7360
Epoch 3/10, Train Loss: 0.6240, Valid Loss: 0.5453
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6163
Epoch 4/10, Batch 20/20, Loss: 0.4322
Epoch 4/10, Train Loss: 0.4998, Valid Loss: 0.4689
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3722
Epoch 5/10, Batch 20/20, Loss: 0.2607
Epoch 5/10, Train Loss: 0.4110, Valid Loss: 0.4234
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4513
Epoch 6/10, Batch 20/20, Loss: 0.5591
Epoch 6/10, Train Loss: 0.4135, Valid Loss: 0.3911
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3601
Epoch 7/10, Batch 20/20, Loss: 0.3520
Epoch 7/10, Train Loss: 0.3450, Valid Loss: 0.3714
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3645
Epoch 8/10, Batch 20/20, Loss: 0.1922
Epoch 8/10, Train Loss: 0.3164, Valid Loss: 0.3579
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4887
Epoch 9/10, Batch 20/20, Loss: 0.6338
Epoch 9/10, Train Loss: 0.3148, Valid Loss: 0.3364
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2723
Epoch 10/10, Batch 20/20, Loss: 0.5103
Epoch 10/10, Train Loss: 0.2733, Valid Loss: 0.3307
Model saved!
Accuracy: 0.8843
Precision: 0.8803
Recall: 0.8843
F1-score: 0.8816
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3021
Epoch 1/10, Batch 20/20, Loss: 1.2414
Epoch 1/10, Train Loss: 1.3075, Valid Loss: 0.9731
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9417
Epoch 2/10, Batch 20/20, Loss: 0.9323
Epoch 2/10, Train Loss: 0.8683, Valid Loss: 0.6934
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5147
Epoch 3/10, Batch 20/20, Loss: 0.9075
Epoch 3/10, Train Loss: 0.6617, Valid Loss: 0.5649
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6607
Epoch 4/10, Batch 20/20, Loss: 0.5485
Epoch 4/10, Train Loss: 0.5370, Valid Loss: 0.4848
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4406
Epoch 5/10, Batch 20/20, Loss: 0.3393
Epoch 5/10, Train Loss: 0.4465, Valid Loss: 0.4433
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4517
Epoch 6/10, Batch 20/20, Loss: 0.5390
Epoch 6/10, Train Loss: 0.4456, Valid Loss: 0.3972
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.6098
Epoch 7/10, Batch 20/20, Loss: 0.3324
Epoch 7/10, Train Loss: 0.3794, Valid Loss: 0.3718
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3023
Epoch 8/10, Batch 20/20, Loss: 0.2665
Epoch 8/10, Train Loss: 0.3372, Valid Loss: 0.3500
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.6267
Epoch 9/10, Batch 20/20, Loss: 0.5008
Epoch 9/10, Train Loss: 0.3342, Valid Loss: 0.3344
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2400
Epoch 10/10, Batch 20/20, Loss: 0.3780
Epoch 10/10, Train Loss: 0.2929, Valid Loss: 0.3256
Model saved!
Accuracy: 0.9007
Precision: 0.8964
Recall: 0.9007
F1-score: 0.8968
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3143
Epoch 1/10, Batch 20/20, Loss: 1.2037
Epoch 1/10, Train Loss: 1.2997, Valid Loss: 0.9754
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8742
Epoch 2/10, Batch 20/20, Loss: 0.8908
Epoch 2/10, Train Loss: 0.8380, Valid Loss: 0.7183
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5624
Epoch 3/10, Batch 20/20, Loss: 0.7016
Epoch 3/10, Train Loss: 0.6319, Valid Loss: 0.6047
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6807
Epoch 4/10, Batch 20/20, Loss: 0.6084
Epoch 4/10, Train Loss: 0.5152, Valid Loss: 0.5363
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3565
Epoch 5/10, Batch 20/20, Loss: 0.5525
Epoch 5/10, Train Loss: 0.4445, Valid Loss: 0.4874
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5569
Epoch 6/10, Batch 20/20, Loss: 0.8410
Epoch 6/10, Train Loss: 0.4177, Valid Loss: 0.4521
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4217
Epoch 7/10, Batch 20/20, Loss: 0.2874
Epoch 7/10, Train Loss: 0.3621, Valid Loss: 0.4303
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2745
Epoch 8/10, Batch 20/20, Loss: 0.2704
Epoch 8/10, Train Loss: 0.3206, Valid Loss: 0.4078
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4486
Epoch 9/10, Batch 20/20, Loss: 0.5766
Epoch 9/10, Train Loss: 0.3122, Valid Loss: 0.3949
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2166
Epoch 10/10, Batch 20/20, Loss: 0.3111
Epoch 10/10, Train Loss: 0.2757, Valid Loss: 0.3896
Model saved!
Accuracy: 0.8820
Precision: 0.8796
Recall: 0.8820
F1-score: 0.8803
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2551
Epoch 1/10, Batch 20/20, Loss: 1.2213
Epoch 1/10, Train Loss: 1.3069, Valid Loss: 0.9673
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8749
Epoch 2/10, Batch 20/20, Loss: 0.9978
Epoch 2/10, Train Loss: 0.8776, Valid Loss: 0.6794
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5916
Epoch 3/10, Batch 20/20, Loss: 0.7342
Epoch 3/10, Train Loss: 0.6505, Valid Loss: 0.5445
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7703
Epoch 4/10, Batch 20/20, Loss: 0.4613
Epoch 4/10, Train Loss: 0.5385, Valid Loss: 0.4607
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4095
Epoch 5/10, Batch 20/20, Loss: 0.3751
Epoch 5/10, Train Loss: 0.4499, Valid Loss: 0.4090
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5657
Epoch 6/10, Batch 20/20, Loss: 0.4018
Epoch 6/10, Train Loss: 0.4291, Valid Loss: 0.3688
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.5502
Epoch 7/10, Batch 20/20, Loss: 0.3066
Epoch 7/10, Train Loss: 0.3804, Valid Loss: 0.3470
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2874
Epoch 8/10, Batch 20/20, Loss: 0.3126
Epoch 8/10, Train Loss: 0.3409, Valid Loss: 0.3183
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4356
Epoch 9/10, Batch 20/20, Loss: 0.5594
Epoch 9/10, Train Loss: 0.3321, Valid Loss: 0.3078
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1969
Epoch 10/10, Batch 20/20, Loss: 0.3210
Epoch 10/10, Train Loss: 0.2895, Valid Loss: 0.2795
Model saved!
Accuracy: 0.9007
Precision: 0.8969
Recall: 0.9007
F1-score: 0.8976
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1635
Epoch 1/10, Batch 20/20, Loss: 1.3861
Epoch 1/10, Train Loss: 1.3118, Valid Loss: 0.9064
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9972
Epoch 2/10, Batch 20/20, Loss: 0.8125
Epoch 2/10, Train Loss: 0.8475, Valid Loss: 0.6377
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5271
Epoch 3/10, Batch 20/20, Loss: 0.7032
Epoch 3/10, Train Loss: 0.6374, Valid Loss: 0.5057
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6382
Epoch 4/10, Batch 20/20, Loss: 0.5274
Epoch 4/10, Train Loss: 0.5333, Valid Loss: 0.4369
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4471
Epoch 5/10, Batch 20/20, Loss: 0.5718
Epoch 5/10, Train Loss: 0.4448, Valid Loss: 0.3873
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4709
Epoch 6/10, Batch 20/20, Loss: 0.4402
Epoch 6/10, Train Loss: 0.4198, Valid Loss: 0.3543
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2649
Epoch 7/10, Batch 20/20, Loss: 0.4387
Epoch 7/10, Train Loss: 0.3673, Valid Loss: 0.3288
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2355
Epoch 8/10, Batch 20/20, Loss: 0.5154
Epoch 8/10, Train Loss: 0.3421, Valid Loss: 0.3125
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5694
Epoch 9/10, Batch 20/20, Loss: 0.4869
Epoch 9/10, Train Loss: 0.3251, Valid Loss: 0.2995
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3791
Epoch 10/10, Batch 20/20, Loss: 0.4382
Epoch 10/10, Train Loss: 0.2850, Valid Loss: 0.2910
Model saved!
Accuracy: 0.8832
Precision: 0.8770
Recall: 0.8832
F1-score: 0.8791
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2537
Epoch 1/10, Batch 20/20, Loss: 1.1373
Epoch 1/10, Train Loss: 1.2988, Valid Loss: 0.9583
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8298
Epoch 2/10, Batch 20/20, Loss: 0.7696
Epoch 2/10, Train Loss: 0.8530, Valid Loss: 0.6861
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5435
Epoch 3/10, Batch 20/20, Loss: 0.9996
Epoch 3/10, Train Loss: 0.6632, Valid Loss: 0.5600
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7360
Epoch 4/10, Batch 20/20, Loss: 0.4953
Epoch 4/10, Train Loss: 0.5385, Valid Loss: 0.4994
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.6007
Epoch 5/10, Batch 20/20, Loss: 0.5490
Epoch 5/10, Train Loss: 0.4649, Valid Loss: 0.4394
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6055
Epoch 6/10, Batch 20/20, Loss: 0.8035
Epoch 6/10, Train Loss: 0.4679, Valid Loss: 0.4072
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4402
Epoch 7/10, Batch 20/20, Loss: 0.4658
Epoch 7/10, Train Loss: 0.4048, Valid Loss: 0.3760
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2702
Epoch 8/10, Batch 20/20, Loss: 0.2506
Epoch 8/10, Train Loss: 0.3491, Valid Loss: 0.3637
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4981
Epoch 9/10, Batch 20/20, Loss: 0.3047
Epoch 9/10, Train Loss: 0.3345, Valid Loss: 0.3427
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.4323
Epoch 10/10, Batch 20/20, Loss: 0.2453
Epoch 10/10, Train Loss: 0.3000, Valid Loss: 0.3300
Model saved!
Accuracy: 0.8949
Precision: 0.8900
Recall: 0.8949
F1-score: 0.8919
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2727
Epoch 1/10, Batch 20/20, Loss: 1.2393
Epoch 1/10, Train Loss: 1.3108, Valid Loss: 0.9881
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8776
Epoch 2/10, Batch 20/20, Loss: 0.8461
Epoch 2/10, Train Loss: 0.8477, Valid Loss: 0.7092
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5227
Epoch 3/10, Batch 20/20, Loss: 0.9162
Epoch 3/10, Train Loss: 0.6352, Valid Loss: 0.5744
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6736
Epoch 4/10, Batch 20/20, Loss: 0.4106
Epoch 4/10, Train Loss: 0.5101, Valid Loss: 0.5018
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5237
Epoch 5/10, Batch 20/20, Loss: 0.7298
Epoch 5/10, Train Loss: 0.4416, Valid Loss: 0.4550
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4662
Epoch 6/10, Batch 20/20, Loss: 0.6843
Epoch 6/10, Train Loss: 0.4109, Valid Loss: 0.4050
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3308
Epoch 7/10, Batch 20/20, Loss: 0.4400
Epoch 7/10, Train Loss: 0.3648, Valid Loss: 0.3848
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3241
Epoch 8/10, Batch 20/20, Loss: 0.2613
Epoch 8/10, Train Loss: 0.3284, Valid Loss: 0.3690
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4718
Epoch 9/10, Batch 20/20, Loss: 0.7961
Epoch 9/10, Train Loss: 0.3264, Valid Loss: 0.3581
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3070
Epoch 10/10, Batch 20/20, Loss: 0.2861
Epoch 10/10, Train Loss: 0.2686, Valid Loss: 0.3352
Model saved!
Accuracy: 0.8949
Precision: 0.8900
Recall: 0.8949
F1-score: 0.8916
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2415
Epoch 1/10, Batch 20/20, Loss: 1.3629
Epoch 1/10, Train Loss: 1.3266, Valid Loss: 0.9463
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8907
Epoch 2/10, Batch 20/20, Loss: 0.8235
Epoch 2/10, Train Loss: 0.8689, Valid Loss: 0.6728
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5869
Epoch 3/10, Batch 20/20, Loss: 0.7797
Epoch 3/10, Train Loss: 0.6565, Valid Loss: 0.5442
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6473
Epoch 4/10, Batch 20/20, Loss: 0.3624
Epoch 4/10, Train Loss: 0.5378, Valid Loss: 0.4657
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5191
Epoch 5/10, Batch 20/20, Loss: 0.5017
Epoch 5/10, Train Loss: 0.4591, Valid Loss: 0.4253
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5563
Epoch 6/10, Batch 20/20, Loss: 0.6395
Epoch 6/10, Train Loss: 0.4384, Valid Loss: 0.3911
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3580
Epoch 7/10, Batch 20/20, Loss: 0.4954
Epoch 7/10, Train Loss: 0.3859, Valid Loss: 0.3600
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3597
Epoch 8/10, Batch 20/20, Loss: 0.4643
Epoch 8/10, Train Loss: 0.3524, Valid Loss: 0.3466
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3688
Epoch 9/10, Batch 20/20, Loss: 0.4321
Epoch 9/10, Train Loss: 0.3344, Valid Loss: 0.3266
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1978
Epoch 10/10, Batch 20/20, Loss: 0.1641
Epoch 10/10, Train Loss: 0.2717, Valid Loss: 0.3157
Model saved!
Accuracy: 0.8843
Precision: 0.8787
Recall: 0.8843
F1-score: 0.8798
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2563
Epoch 1/10, Batch 20/20, Loss: 1.1292
Epoch 1/10, Train Loss: 1.3046, Valid Loss: 0.9269
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9333
Epoch 2/10, Batch 20/20, Loss: 0.7277
Epoch 2/10, Train Loss: 0.8714, Valid Loss: 0.6658
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6310
Epoch 3/10, Batch 20/20, Loss: 0.9011
Epoch 3/10, Train Loss: 0.6736, Valid Loss: 0.5235
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6502
Epoch 4/10, Batch 20/20, Loss: 0.6622
Epoch 4/10, Train Loss: 0.5641, Valid Loss: 0.4499
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4346
Epoch 5/10, Batch 20/20, Loss: 0.3774
Epoch 5/10, Train Loss: 0.4687, Valid Loss: 0.3991
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4309
Epoch 6/10, Batch 20/20, Loss: 0.4970
Epoch 6/10, Train Loss: 0.4381, Valid Loss: 0.3552
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3823
Epoch 7/10, Batch 20/20, Loss: 0.4536
Epoch 7/10, Train Loss: 0.3975, Valid Loss: 0.3298
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3871
Epoch 8/10, Batch 20/20, Loss: 0.3178
Epoch 8/10, Train Loss: 0.3534, Valid Loss: 0.3144
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5729
Epoch 9/10, Batch 20/20, Loss: 0.5013
Epoch 9/10, Train Loss: 0.3563, Valid Loss: 0.2876
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2947
Epoch 10/10, Batch 20/20, Loss: 0.2681
Epoch 10/10, Train Loss: 0.3049, Valid Loss: 0.2828
Model saved!
Accuracy: 0.8937
Precision: 0.8895
Recall: 0.8937
F1-score: 0.8909
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2392
Epoch 1/10, Batch 20/20, Loss: 1.2000
Epoch 1/10, Train Loss: 1.3053, Valid Loss: 0.9343
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8600
Epoch 2/10, Batch 20/20, Loss: 0.8487
Epoch 2/10, Train Loss: 0.8579, Valid Loss: 0.6465
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5136
Epoch 3/10, Batch 20/20, Loss: 0.8164
Epoch 3/10, Train Loss: 0.6406, Valid Loss: 0.5119
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6620
Epoch 4/10, Batch 20/20, Loss: 0.4301
Epoch 4/10, Train Loss: 0.5288, Valid Loss: 0.4349
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3865
Epoch 5/10, Batch 20/20, Loss: 0.4304
Epoch 5/10, Train Loss: 0.4363, Valid Loss: 0.3876
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5720
Epoch 6/10, Batch 20/20, Loss: 0.7559
Epoch 6/10, Train Loss: 0.4311, Valid Loss: 0.3563
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4115
Epoch 7/10, Batch 20/20, Loss: 0.7236
Epoch 7/10, Train Loss: 0.3811, Valid Loss: 0.3462
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3505
Epoch 8/10, Batch 20/20, Loss: 0.4874
Epoch 8/10, Train Loss: 0.3411, Valid Loss: 0.3231
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4904
Epoch 9/10, Batch 20/20, Loss: 0.3882
Epoch 9/10, Train Loss: 0.3123, Valid Loss: 0.3073
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2649
Epoch 10/10, Batch 20/20, Loss: 0.3127
Epoch 10/10, Train Loss: 0.2693, Valid Loss: 0.2904
Model saved!
Accuracy: 0.8820
Precision: 0.8766
Recall: 0.8820
F1-score: 0.8785
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2532
Epoch 1/10, Batch 20/20, Loss: 1.1233
Epoch 1/10, Train Loss: 1.3072, Valid Loss: 0.9897
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0132
Epoch 2/10, Batch 20/20, Loss: 0.8543
Epoch 2/10, Train Loss: 0.8549, Valid Loss: 0.7225
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5991
Epoch 3/10, Batch 20/20, Loss: 0.7689
Epoch 3/10, Train Loss: 0.6426, Valid Loss: 0.6081
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6978
Epoch 4/10, Batch 20/20, Loss: 0.5166
Epoch 4/10, Train Loss: 0.5265, Valid Loss: 0.5341
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5184
Epoch 5/10, Batch 20/20, Loss: 0.5672
Epoch 5/10, Train Loss: 0.4383, Valid Loss: 0.4973
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5693
Epoch 6/10, Batch 20/20, Loss: 0.5865
Epoch 6/10, Train Loss: 0.4189, Valid Loss: 0.4515
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3478
Epoch 7/10, Batch 20/20, Loss: 0.4471
Epoch 7/10, Train Loss: 0.3607, Valid Loss: 0.4382
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2414
Epoch 8/10, Batch 20/20, Loss: 0.3705
Epoch 8/10, Train Loss: 0.3333, Valid Loss: 0.4169
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4182
Epoch 9/10, Batch 20/20, Loss: 0.9519
Epoch 9/10, Train Loss: 0.3473, Valid Loss: 0.4196
Epoch 10/10, Batch 10/20, Loss: 0.1883
Epoch 10/10, Batch 20/20, Loss: 0.2027
Epoch 10/10, Train Loss: 0.2773, Valid Loss: 0.3866
Model saved!
Accuracy: 0.8914
Precision: 0.8869
Recall: 0.8914
F1-score: 0.8873
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2456
Epoch 1/10, Batch 20/20, Loss: 1.2776
Epoch 1/10, Train Loss: 1.3146, Valid Loss: 0.9408
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9287
Epoch 2/10, Batch 20/20, Loss: 0.8884
Epoch 2/10, Train Loss: 0.8746, Valid Loss: 0.6784
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6214
Epoch 3/10, Batch 20/20, Loss: 0.8084
Epoch 3/10, Train Loss: 0.6441, Valid Loss: 0.5470
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7227
Epoch 4/10, Batch 20/20, Loss: 0.4859
Epoch 4/10, Train Loss: 0.5270, Valid Loss: 0.4695
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4927
Epoch 5/10, Batch 20/20, Loss: 0.3721
Epoch 5/10, Train Loss: 0.4356, Valid Loss: 0.4113
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5961
Epoch 6/10, Batch 20/20, Loss: 0.4776
Epoch 6/10, Train Loss: 0.4089, Valid Loss: 0.3837
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3905
Epoch 7/10, Batch 20/20, Loss: 0.5516
Epoch 7/10, Train Loss: 0.3676, Valid Loss: 0.3573
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2503
Epoch 8/10, Batch 20/20, Loss: 0.2212
Epoch 8/10, Train Loss: 0.3217, Valid Loss: 0.3478
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5035
Epoch 9/10, Batch 20/20, Loss: 0.3969
Epoch 9/10, Train Loss: 0.3157, Valid Loss: 0.3298
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2285
Epoch 10/10, Batch 20/20, Loss: 0.2770
Epoch 10/10, Train Loss: 0.2737, Valid Loss: 0.3210
Model saved!
Accuracy: 0.8902
Precision: 0.8844
Recall: 0.8902
F1-score: 0.8858
Memory Allocated after cleanup: 17.76 MB
End time: 2025-02-24 11:02:57.118070
Duration: 1:57:59


Mejor accuracy al acabar el algoritmo: 0.9030


Fitness check:

Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2953
Epoch 1/10, Batch 20/20, Loss: 1.2631
Epoch 1/10, Train Loss: 1.3212, Valid Loss: 0.9394
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8452
Epoch 2/10, Batch 20/20, Loss: 0.7898
Epoch 2/10, Train Loss: 0.8720, Valid Loss: 0.6606
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5733
Epoch 3/10, Batch 20/20, Loss: 0.5155
Epoch 3/10, Train Loss: 0.6418, Valid Loss: 0.5354
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7374
Epoch 4/10, Batch 20/20, Loss: 0.4641
Epoch 4/10, Train Loss: 0.5381, Valid Loss: 0.4708
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4034
Epoch 5/10, Batch 20/20, Loss: 0.3154
Epoch 5/10, Train Loss: 0.4334, Valid Loss: 0.4220
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.7442
Epoch 6/10, Batch 20/20, Loss: 0.6532
Epoch 6/10, Train Loss: 0.4383, Valid Loss: 0.3939
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.5468
Epoch 7/10, Batch 20/20, Loss: 0.2661
Epoch 7/10, Train Loss: 0.3793, Valid Loss: 0.3677
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3194
Epoch 8/10, Batch 20/20, Loss: 0.4392
Epoch 8/10, Train Loss: 0.3421, Valid Loss: 0.3565
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3981
Epoch 9/10, Batch 20/20, Loss: 0.5645
Epoch 9/10, Train Loss: 0.3313, Valid Loss: 0.3447
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2472
Epoch 10/10, Batch 20/20, Loss: 0.3223
Epoch 10/10, Train Loss: 0.2902, Valid Loss: 0.3383
Model saved!
Accuracy: 0.9030
Precision: 0.8988
Recall: 0.9030
F1-score: 0.8994
Memory Allocated after cleanup: 17.76 MB


Mejor accuracy encontrado: 0.9030


--------------------------------------mobilenet  ALEATORIO  25%-------------------------------------------------
Start time: 2025-02-24 11:04:08.301774
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2846
Epoch 1/10, Batch 20/49, Loss: 1.0402
Epoch 1/10, Batch 30/49, Loss: 0.7902
Epoch 1/10, Batch 40/49, Loss: 0.7678
Epoch 1/10, Train Loss: 1.0089, Valid Loss: 0.6946
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6741
Epoch 2/10, Batch 20/49, Loss: 0.4570
Epoch 2/10, Batch 30/49, Loss: 0.4402
Epoch 2/10, Batch 40/49, Loss: 0.4394
Epoch 2/10, Train Loss: 0.5490, Valid Loss: 0.5365
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4854
Epoch 3/10, Batch 20/49, Loss: 0.3769
Epoch 3/10, Batch 30/49, Loss: 0.4415
Epoch 3/10, Batch 40/49, Loss: 0.3373
Epoch 3/10, Train Loss: 0.4359, Valid Loss: 0.4908
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3874
Epoch 4/10, Batch 20/49, Loss: 0.4391
Epoch 4/10, Batch 30/49, Loss: 0.2011
Epoch 4/10, Batch 40/49, Loss: 0.2791
Epoch 4/10, Train Loss: 0.3698, Valid Loss: 0.4449
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2163
Epoch 5/10, Batch 20/49, Loss: 0.3228
Epoch 5/10, Batch 30/49, Loss: 0.2761
Epoch 5/10, Batch 40/49, Loss: 0.3403
Epoch 5/10, Train Loss: 0.3186, Valid Loss: 0.4265
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3395
Epoch 6/10, Batch 20/49, Loss: 0.3042
Epoch 6/10, Batch 30/49, Loss: 0.2601
Epoch 6/10, Batch 40/49, Loss: 0.3355
Epoch 6/10, Train Loss: 0.2958, Valid Loss: 0.4317
Epoch 7/10, Batch 10/49, Loss: 0.1866
Epoch 7/10, Batch 20/49, Loss: 0.1695
Epoch 7/10, Batch 30/49, Loss: 0.2288
Epoch 7/10, Batch 40/49, Loss: 0.1825
Epoch 7/10, Train Loss: 0.2673, Valid Loss: 0.4431
Epoch 8/10, Batch 10/49, Loss: 0.2310
Epoch 8/10, Batch 20/49, Loss: 0.2198
Epoch 8/10, Batch 30/49, Loss: 0.3365
Epoch 8/10, Batch 40/49, Loss: 0.1728
Epoch 8/10, Train Loss: 0.2638, Valid Loss: 0.4135
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2377
Epoch 9/10, Batch 20/49, Loss: 0.1761
Epoch 9/10, Batch 30/49, Loss: 0.5047
Epoch 9/10, Batch 40/49, Loss: 0.2196
Epoch 9/10, Train Loss: 0.2377, Valid Loss: 0.4023
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3032
Epoch 10/10, Batch 20/49, Loss: 0.1962
Epoch 10/10, Batch 30/49, Loss: 0.1886
Epoch 10/10, Batch 40/49, Loss: 0.1836
Epoch 10/10, Train Loss: 0.2168, Valid Loss: 0.3952
Model saved!
Accuracy: 0.9065
Precision: 0.9040
Recall: 0.9065
F1-score: 0.9050
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 1. Fitness: 0.9065
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3018
Epoch 1/10, Batch 20/49, Loss: 1.0256
Epoch 1/10, Batch 30/49, Loss: 0.8712
Epoch 1/10, Batch 40/49, Loss: 0.7744
Epoch 1/10, Train Loss: 1.0115, Valid Loss: 0.6588
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6973
Epoch 2/10, Batch 20/49, Loss: 0.5562
Epoch 2/10, Batch 30/49, Loss: 0.5564
Epoch 2/10, Batch 40/49, Loss: 0.4988
Epoch 2/10, Train Loss: 0.5433, Valid Loss: 0.4822
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4714
Epoch 3/10, Batch 20/49, Loss: 0.3931
Epoch 3/10, Batch 30/49, Loss: 0.3455
Epoch 3/10, Batch 40/49, Loss: 0.3094
Epoch 3/10, Train Loss: 0.4230, Valid Loss: 0.4110
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2535
Epoch 4/10, Batch 20/49, Loss: 0.4247
Epoch 4/10, Batch 30/49, Loss: 0.3690
Epoch 4/10, Batch 40/49, Loss: 0.2804
Epoch 4/10, Train Loss: 0.3597, Valid Loss: 0.3518
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3320
Epoch 5/10, Batch 20/49, Loss: 0.2269
Epoch 5/10, Batch 30/49, Loss: 0.1893
Epoch 5/10, Batch 40/49, Loss: 0.1881
Epoch 5/10, Train Loss: 0.3076, Valid Loss: 0.3343
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3288
Epoch 6/10, Batch 20/49, Loss: 0.2888
Epoch 6/10, Batch 30/49, Loss: 0.3958
Epoch 6/10, Batch 40/49, Loss: 0.2176
Epoch 6/10, Train Loss: 0.2944, Valid Loss: 0.3229
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2272
Epoch 7/10, Batch 20/49, Loss: 0.2440
Epoch 7/10, Batch 30/49, Loss: 0.2819
Epoch 7/10, Batch 40/49, Loss: 0.2528
Epoch 7/10, Train Loss: 0.2667, Valid Loss: 0.3285
Epoch 8/10, Batch 10/49, Loss: 0.1588
Epoch 8/10, Batch 20/49, Loss: 0.2022
Epoch 8/10, Batch 30/49, Loss: 0.3173
Epoch 8/10, Batch 40/49, Loss: 0.2524
Epoch 8/10, Train Loss: 0.2442, Valid Loss: 0.3024
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1211
Epoch 9/10, Batch 20/49, Loss: 0.2638
Epoch 9/10, Batch 30/49, Loss: 0.6437
Epoch 9/10, Batch 40/49, Loss: 0.1591
Epoch 9/10, Train Loss: 0.2424, Valid Loss: 0.2877
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1562
Epoch 10/10, Batch 20/49, Loss: 0.2613
Epoch 10/10, Batch 30/49, Loss: 0.3308
Epoch 10/10, Batch 40/49, Loss: 0.1623
Epoch 10/10, Train Loss: 0.2089, Valid Loss: 0.2749
Model saved!
Accuracy: 0.9112
Precision: 0.9080
Recall: 0.9112
F1-score: 0.9093
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 2. Fitness: 0.9112
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2948
Epoch 1/10, Batch 20/49, Loss: 1.0843
Epoch 1/10, Batch 30/49, Loss: 0.7336
Epoch 1/10, Batch 40/49, Loss: 0.7260
Epoch 1/10, Train Loss: 0.9970, Valid Loss: 0.6982
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7469
Epoch 2/10, Batch 20/49, Loss: 0.3970
Epoch 2/10, Batch 30/49, Loss: 0.5382
Epoch 2/10, Batch 40/49, Loss: 0.5281
Epoch 2/10, Train Loss: 0.5344, Valid Loss: 0.5301
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.2801
Epoch 3/10, Batch 20/49, Loss: 0.4698
Epoch 3/10, Batch 30/49, Loss: 0.4729
Epoch 3/10, Batch 40/49, Loss: 0.3239
Epoch 3/10, Train Loss: 0.4263, Valid Loss: 0.4629
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2546
Epoch 4/10, Batch 20/49, Loss: 0.3811
Epoch 4/10, Batch 30/49, Loss: 0.4577
Epoch 4/10, Batch 40/49, Loss: 0.2736
Epoch 4/10, Train Loss: 0.3613, Valid Loss: 0.4119
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3626
Epoch 5/10, Batch 20/49, Loss: 0.2560
Epoch 5/10, Batch 30/49, Loss: 0.4778
Epoch 5/10, Batch 40/49, Loss: 0.1983
Epoch 5/10, Train Loss: 0.3111, Valid Loss: 0.4058
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3043
Epoch 6/10, Batch 20/49, Loss: 0.4751
Epoch 6/10, Batch 30/49, Loss: 0.3295
Epoch 6/10, Batch 40/49, Loss: 0.3176
Epoch 6/10, Train Loss: 0.2925, Valid Loss: 0.3793
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3047
Epoch 7/10, Batch 20/49, Loss: 0.2738
Epoch 7/10, Batch 30/49, Loss: 0.3495
Epoch 7/10, Batch 40/49, Loss: 0.2801
Epoch 7/10, Train Loss: 0.2785, Valid Loss: 0.3943
Epoch 8/10, Batch 10/49, Loss: 0.2866
Epoch 8/10, Batch 20/49, Loss: 0.2937
Epoch 8/10, Batch 30/49, Loss: 0.2779
Epoch 8/10, Batch 40/49, Loss: 0.2397
Epoch 8/10, Train Loss: 0.2570, Valid Loss: 0.3615
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2122
Epoch 9/10, Batch 20/49, Loss: 0.1258
Epoch 9/10, Batch 30/49, Loss: 0.3664
Epoch 9/10, Batch 40/49, Loss: 0.2068
Epoch 9/10, Train Loss: 0.2276, Valid Loss: 0.3584
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3495
Epoch 10/10, Batch 20/49, Loss: 0.1726
Epoch 10/10, Batch 30/49, Loss: 0.3172
Epoch 10/10, Batch 40/49, Loss: 0.2460
Epoch 10/10, Train Loss: 0.2139, Valid Loss: 0.3388
Model saved!
Accuracy: 0.9030
Precision: 0.8985
Recall: 0.9030
F1-score: 0.8989
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2794
Epoch 1/10, Batch 20/49, Loss: 1.0211
Epoch 1/10, Batch 30/49, Loss: 0.7867
Epoch 1/10, Batch 40/49, Loss: 0.7757
Epoch 1/10, Train Loss: 0.9915, Valid Loss: 0.6190
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5355
Epoch 2/10, Batch 20/49, Loss: 0.4071
Epoch 2/10, Batch 30/49, Loss: 0.5313
Epoch 2/10, Batch 40/49, Loss: 0.5477
Epoch 2/10, Train Loss: 0.5269, Valid Loss: 0.4259
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5347
Epoch 3/10, Batch 20/49, Loss: 0.4502
Epoch 3/10, Batch 30/49, Loss: 0.2908
Epoch 3/10, Batch 40/49, Loss: 0.4848
Epoch 3/10, Train Loss: 0.4005, Valid Loss: 0.3605
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2190
Epoch 4/10, Batch 20/49, Loss: 0.3463
Epoch 4/10, Batch 30/49, Loss: 0.3218
Epoch 4/10, Batch 40/49, Loss: 0.2399
Epoch 4/10, Train Loss: 0.3583, Valid Loss: 0.3001
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2500
Epoch 5/10, Batch 20/49, Loss: 0.2849
Epoch 5/10, Batch 30/49, Loss: 0.2023
Epoch 5/10, Batch 40/49, Loss: 0.3286
Epoch 5/10, Train Loss: 0.2920, Valid Loss: 0.2866
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2051
Epoch 6/10, Batch 20/49, Loss: 0.2090
Epoch 6/10, Batch 30/49, Loss: 0.4062
Epoch 6/10, Batch 40/49, Loss: 0.2191
Epoch 6/10, Train Loss: 0.2696, Valid Loss: 0.2609
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1903
Epoch 7/10, Batch 20/49, Loss: 0.1807
Epoch 7/10, Batch 30/49, Loss: 0.2812
Epoch 7/10, Batch 40/49, Loss: 0.1338
Epoch 7/10, Train Loss: 0.2500, Valid Loss: 0.2605
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1597
Epoch 8/10, Batch 20/49, Loss: 0.2297
Epoch 8/10, Batch 30/49, Loss: 0.3168
Epoch 8/10, Batch 40/49, Loss: 0.1850
Epoch 8/10, Train Loss: 0.2365, Valid Loss: 0.2389
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1697
Epoch 9/10, Batch 20/49, Loss: 0.2695
Epoch 9/10, Batch 30/49, Loss: 0.4029
Epoch 9/10, Batch 40/49, Loss: 0.0844
Epoch 9/10, Train Loss: 0.2200, Valid Loss: 0.2261
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2415
Epoch 10/10, Batch 20/49, Loss: 0.2057
Epoch 10/10, Batch 30/49, Loss: 0.2243
Epoch 10/10, Batch 40/49, Loss: 0.3351
Epoch 10/10, Train Loss: 0.2025, Valid Loss: 0.2188
Model saved!
Accuracy: 0.9007
Precision: 0.8961
Recall: 0.9007
F1-score: 0.8963
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2983
Epoch 1/10, Batch 20/49, Loss: 1.0790
Epoch 1/10, Batch 30/49, Loss: 0.8078
Epoch 1/10, Batch 40/49, Loss: 0.7996
Epoch 1/10, Train Loss: 0.9913, Valid Loss: 0.6965
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6804
Epoch 2/10, Batch 20/49, Loss: 0.4681
Epoch 2/10, Batch 30/49, Loss: 0.5781
Epoch 2/10, Batch 40/49, Loss: 0.4112
Epoch 2/10, Train Loss: 0.5466, Valid Loss: 0.5323
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4052
Epoch 3/10, Batch 20/49, Loss: 0.4723
Epoch 3/10, Batch 30/49, Loss: 0.3742
Epoch 3/10, Batch 40/49, Loss: 0.3179
Epoch 3/10, Train Loss: 0.4297, Valid Loss: 0.4691
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2903
Epoch 4/10, Batch 20/49, Loss: 0.3848
Epoch 4/10, Batch 30/49, Loss: 0.3394
Epoch 4/10, Batch 40/49, Loss: 0.4113
Epoch 4/10, Train Loss: 0.3614, Valid Loss: 0.4072
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2984
Epoch 5/10, Batch 20/49, Loss: 0.3234
Epoch 5/10, Batch 30/49, Loss: 0.2590
Epoch 5/10, Batch 40/49, Loss: 0.2418
Epoch 5/10, Train Loss: 0.3127, Valid Loss: 0.3839
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2628
Epoch 6/10, Batch 20/49, Loss: 0.2948
Epoch 6/10, Batch 30/49, Loss: 0.3173
Epoch 6/10, Batch 40/49, Loss: 0.3707
Epoch 6/10, Train Loss: 0.2894, Valid Loss: 0.3845
Epoch 7/10, Batch 10/49, Loss: 0.2270
Epoch 7/10, Batch 20/49, Loss: 0.2741
Epoch 7/10, Batch 30/49, Loss: 0.3097
Epoch 7/10, Batch 40/49, Loss: 0.2376
Epoch 7/10, Train Loss: 0.2725, Valid Loss: 0.3836
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1765
Epoch 8/10, Batch 20/49, Loss: 0.2877
Epoch 8/10, Batch 30/49, Loss: 0.1515
Epoch 8/10, Batch 40/49, Loss: 0.2458
Epoch 8/10, Train Loss: 0.2647, Valid Loss: 0.3536
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1619
Epoch 9/10, Batch 20/49, Loss: 0.1969
Epoch 9/10, Batch 30/49, Loss: 0.3172
Epoch 9/10, Batch 40/49, Loss: 0.2225
Epoch 9/10, Train Loss: 0.2338, Valid Loss: 0.3352
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2003
Epoch 10/10, Batch 20/49, Loss: 0.1482
Epoch 10/10, Batch 30/49, Loss: 0.2675
Epoch 10/10, Batch 40/49, Loss: 0.2053
Epoch 10/10, Train Loss: 0.2110, Valid Loss: 0.3196
Model saved!
Accuracy: 0.9054
Precision: 0.9014
Recall: 0.9054
F1-score: 0.9013
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3381
Epoch 1/10, Batch 20/49, Loss: 1.0476
Epoch 1/10, Batch 30/49, Loss: 0.8589
Epoch 1/10, Batch 40/49, Loss: 0.8632
Epoch 1/10, Train Loss: 1.0079, Valid Loss: 0.6358
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5691
Epoch 2/10, Batch 20/49, Loss: 0.4359
Epoch 2/10, Batch 30/49, Loss: 0.4537
Epoch 2/10, Batch 40/49, Loss: 0.6094
Epoch 2/10, Train Loss: 0.5530, Valid Loss: 0.4662
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4914
Epoch 3/10, Batch 20/49, Loss: 0.4283
Epoch 3/10, Batch 30/49, Loss: 0.3298
Epoch 3/10, Batch 40/49, Loss: 0.3671
Epoch 3/10, Train Loss: 0.4283, Valid Loss: 0.3972
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4606
Epoch 4/10, Batch 20/49, Loss: 0.3719
Epoch 4/10, Batch 30/49, Loss: 0.2711
Epoch 4/10, Batch 40/49, Loss: 0.3311
Epoch 4/10, Train Loss: 0.3681, Valid Loss: 0.3471
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4010
Epoch 5/10, Batch 20/49, Loss: 0.2689
Epoch 5/10, Batch 30/49, Loss: 0.2206
Epoch 5/10, Batch 40/49, Loss: 0.2975
Epoch 5/10, Train Loss: 0.3154, Valid Loss: 0.3210
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2546
Epoch 6/10, Batch 20/49, Loss: 0.4096
Epoch 6/10, Batch 30/49, Loss: 0.3914
Epoch 6/10, Batch 40/49, Loss: 0.3235
Epoch 6/10, Train Loss: 0.2958, Valid Loss: 0.3127
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1352
Epoch 7/10, Batch 20/49, Loss: 0.2285
Epoch 7/10, Batch 30/49, Loss: 0.5248
Epoch 7/10, Batch 40/49, Loss: 0.3186
Epoch 7/10, Train Loss: 0.2720, Valid Loss: 0.3022
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2830
Epoch 8/10, Batch 20/49, Loss: 0.2825
Epoch 8/10, Batch 30/49, Loss: 0.3010
Epoch 8/10, Batch 40/49, Loss: 0.3216
Epoch 8/10, Train Loss: 0.2476, Valid Loss: 0.2937
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1199
Epoch 9/10, Batch 20/49, Loss: 0.1745
Epoch 9/10, Batch 30/49, Loss: 0.5658
Epoch 9/10, Batch 40/49, Loss: 0.1906
Epoch 9/10, Train Loss: 0.2451, Valid Loss: 0.2833
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3057
Epoch 10/10, Batch 20/49, Loss: 0.1286
Epoch 10/10, Batch 30/49, Loss: 0.2439
Epoch 10/10, Batch 40/49, Loss: 0.2528
Epoch 10/10, Train Loss: 0.2173, Valid Loss: 0.2788
Model saved!
Accuracy: 0.9077
Precision: 0.9038
Recall: 0.9077
F1-score: 0.9050
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3177
Epoch 1/10, Batch 20/49, Loss: 1.1016
Epoch 1/10, Batch 30/49, Loss: 0.7986
Epoch 1/10, Batch 40/49, Loss: 0.7672
Epoch 1/10, Train Loss: 1.0050, Valid Loss: 0.6746
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5840
Epoch 2/10, Batch 20/49, Loss: 0.5188
Epoch 2/10, Batch 30/49, Loss: 0.5571
Epoch 2/10, Batch 40/49, Loss: 0.5897
Epoch 2/10, Train Loss: 0.5293, Valid Loss: 0.5068
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5383
Epoch 3/10, Batch 20/49, Loss: 0.4382
Epoch 3/10, Batch 30/49, Loss: 0.3940
Epoch 3/10, Batch 40/49, Loss: 0.4009
Epoch 3/10, Train Loss: 0.4036, Valid Loss: 0.4553
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2476
Epoch 4/10, Batch 20/49, Loss: 0.4829
Epoch 4/10, Batch 30/49, Loss: 0.2411
Epoch 4/10, Batch 40/49, Loss: 0.4176
Epoch 4/10, Train Loss: 0.3560, Valid Loss: 0.3980
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2826
Epoch 5/10, Batch 20/49, Loss: 0.2919
Epoch 5/10, Batch 30/49, Loss: 0.2605
Epoch 5/10, Batch 40/49, Loss: 0.2122
Epoch 5/10, Train Loss: 0.2971, Valid Loss: 0.3760
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2286
Epoch 6/10, Batch 20/49, Loss: 0.2962
Epoch 6/10, Batch 30/49, Loss: 0.2743
Epoch 6/10, Batch 40/49, Loss: 0.2867
Epoch 6/10, Train Loss: 0.2718, Valid Loss: 0.3550
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3340
Epoch 7/10, Batch 20/49, Loss: 0.1429
Epoch 7/10, Batch 30/49, Loss: 0.3312
Epoch 7/10, Batch 40/49, Loss: 0.2089
Epoch 7/10, Train Loss: 0.2576, Valid Loss: 0.3545
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1545
Epoch 8/10, Batch 20/49, Loss: 0.2358
Epoch 8/10, Batch 30/49, Loss: 0.3828
Epoch 8/10, Batch 40/49, Loss: 0.1761
Epoch 8/10, Train Loss: 0.2406, Valid Loss: 0.3477
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2214
Epoch 9/10, Batch 20/49, Loss: 0.3194
Epoch 9/10, Batch 30/49, Loss: 0.4903
Epoch 9/10, Batch 40/49, Loss: 0.2348
Epoch 9/10, Train Loss: 0.2278, Valid Loss: 0.3290
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1719
Epoch 10/10, Batch 20/49, Loss: 0.1391
Epoch 10/10, Batch 30/49, Loss: 0.2336
Epoch 10/10, Batch 40/49, Loss: 0.2310
Epoch 10/10, Train Loss: 0.1972, Valid Loss: 0.3224
Model saved!
Accuracy: 0.9007
Precision: 0.8957
Recall: 0.9007
F1-score: 0.8973
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2950
Epoch 1/10, Batch 20/49, Loss: 1.0760
Epoch 1/10, Batch 30/49, Loss: 0.7245
Epoch 1/10, Batch 40/49, Loss: 0.7663
Epoch 1/10, Train Loss: 0.9852, Valid Loss: 0.6306
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6355
Epoch 2/10, Batch 20/49, Loss: 0.4506
Epoch 2/10, Batch 30/49, Loss: 0.5475
Epoch 2/10, Batch 40/49, Loss: 0.3885
Epoch 2/10, Train Loss: 0.5218, Valid Loss: 0.4727
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5000
Epoch 3/10, Batch 20/49, Loss: 0.3986
Epoch 3/10, Batch 30/49, Loss: 0.3781
Epoch 3/10, Batch 40/49, Loss: 0.3090
Epoch 3/10, Train Loss: 0.4034, Valid Loss: 0.4094
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3361
Epoch 4/10, Batch 20/49, Loss: 0.4068
Epoch 4/10, Batch 30/49, Loss: 0.2499
Epoch 4/10, Batch 40/49, Loss: 0.2757
Epoch 4/10, Train Loss: 0.3399, Valid Loss: 0.3561
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3939
Epoch 5/10, Batch 20/49, Loss: 0.2860
Epoch 5/10, Batch 30/49, Loss: 0.2951
Epoch 5/10, Batch 40/49, Loss: 0.1766
Epoch 5/10, Train Loss: 0.2911, Valid Loss: 0.3334
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2956
Epoch 6/10, Batch 20/49, Loss: 0.2310
Epoch 6/10, Batch 30/49, Loss: 0.2318
Epoch 6/10, Batch 40/49, Loss: 0.1748
Epoch 6/10, Train Loss: 0.2622, Valid Loss: 0.3254
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2200
Epoch 7/10, Batch 20/49, Loss: 0.2042
Epoch 7/10, Batch 30/49, Loss: 0.3829
Epoch 7/10, Batch 40/49, Loss: 0.2788
Epoch 7/10, Train Loss: 0.2433, Valid Loss: 0.3201
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3150
Epoch 8/10, Batch 20/49, Loss: 0.1771
Epoch 8/10, Batch 30/49, Loss: 0.1789
Epoch 8/10, Batch 40/49, Loss: 0.1763
Epoch 8/10, Train Loss: 0.2250, Valid Loss: 0.3059
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1775
Epoch 9/10, Batch 20/49, Loss: 0.1539
Epoch 9/10, Batch 30/49, Loss: 0.5124
Epoch 9/10, Batch 40/49, Loss: 0.1483
Epoch 9/10, Train Loss: 0.2154, Valid Loss: 0.2990
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2378
Epoch 10/10, Batch 20/49, Loss: 0.1602
Epoch 10/10, Batch 30/49, Loss: 0.2133
Epoch 10/10, Batch 40/49, Loss: 0.1575
Epoch 10/10, Train Loss: 0.1940, Valid Loss: 0.2807
Model saved!
Accuracy: 0.9019
Precision: 0.8994
Recall: 0.9019
F1-score: 0.8977
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3406
Epoch 1/10, Batch 20/49, Loss: 1.0671
Epoch 1/10, Batch 30/49, Loss: 0.8446
Epoch 1/10, Batch 40/49, Loss: 0.6808
Epoch 1/10, Train Loss: 0.9891, Valid Loss: 0.6682
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7238
Epoch 2/10, Batch 20/49, Loss: 0.3530
Epoch 2/10, Batch 30/49, Loss: 0.5744
Epoch 2/10, Batch 40/49, Loss: 0.5600
Epoch 2/10, Train Loss: 0.5326, Valid Loss: 0.5040
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3904
Epoch 3/10, Batch 20/49, Loss: 0.4664
Epoch 3/10, Batch 30/49, Loss: 0.3585
Epoch 3/10, Batch 40/49, Loss: 0.3764
Epoch 3/10, Train Loss: 0.4176, Valid Loss: 0.4305
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2551
Epoch 4/10, Batch 20/49, Loss: 0.3330
Epoch 4/10, Batch 30/49, Loss: 0.2705
Epoch 4/10, Batch 40/49, Loss: 0.2898
Epoch 4/10, Train Loss: 0.3515, Valid Loss: 0.3803
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3709
Epoch 5/10, Batch 20/49, Loss: 0.2185
Epoch 5/10, Batch 30/49, Loss: 0.3282
Epoch 5/10, Batch 40/49, Loss: 0.2013
Epoch 5/10, Train Loss: 0.3049, Valid Loss: 0.3467
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2431
Epoch 6/10, Batch 20/49, Loss: 0.2849
Epoch 6/10, Batch 30/49, Loss: 0.3865
Epoch 6/10, Batch 40/49, Loss: 0.3241
Epoch 6/10, Train Loss: 0.2775, Valid Loss: 0.3306
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2431
Epoch 7/10, Batch 20/49, Loss: 0.2067
Epoch 7/10, Batch 30/49, Loss: 0.3021
Epoch 7/10, Batch 40/49, Loss: 0.2370
Epoch 7/10, Train Loss: 0.2579, Valid Loss: 0.3239
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2018
Epoch 8/10, Batch 20/49, Loss: 0.1675
Epoch 8/10, Batch 30/49, Loss: 0.3591
Epoch 8/10, Batch 40/49, Loss: 0.1639
Epoch 8/10, Train Loss: 0.2502, Valid Loss: 0.3048
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2038
Epoch 9/10, Batch 20/49, Loss: 0.3647
Epoch 9/10, Batch 30/49, Loss: 0.3495
Epoch 9/10, Batch 40/49, Loss: 0.1208
Epoch 9/10, Train Loss: 0.2290, Valid Loss: 0.2897
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1702
Epoch 10/10, Batch 20/49, Loss: 0.2336
Epoch 10/10, Batch 30/49, Loss: 0.2921
Epoch 10/10, Batch 40/49, Loss: 0.1540
Epoch 10/10, Train Loss: 0.2090, Valid Loss: 0.2773
Model saved!
Accuracy: 0.9019
Precision: 0.9004
Recall: 0.9019
F1-score: 0.8972
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2279
Epoch 1/10, Batch 20/49, Loss: 1.0275
Epoch 1/10, Batch 30/49, Loss: 0.7796
Epoch 1/10, Batch 40/49, Loss: 0.7261
Epoch 1/10, Train Loss: 1.0108, Valid Loss: 0.6381
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6319
Epoch 2/10, Batch 20/49, Loss: 0.4980
Epoch 2/10, Batch 30/49, Loss: 0.5007
Epoch 2/10, Batch 40/49, Loss: 0.5993
Epoch 2/10, Train Loss: 0.5434, Valid Loss: 0.4568
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5130
Epoch 3/10, Batch 20/49, Loss: 0.4728
Epoch 3/10, Batch 30/49, Loss: 0.4406
Epoch 3/10, Batch 40/49, Loss: 0.5005
Epoch 3/10, Train Loss: 0.4260, Valid Loss: 0.3928
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3525
Epoch 4/10, Batch 20/49, Loss: 0.3168
Epoch 4/10, Batch 30/49, Loss: 0.2693
Epoch 4/10, Batch 40/49, Loss: 0.2490
Epoch 4/10, Train Loss: 0.3698, Valid Loss: 0.3434
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3076
Epoch 5/10, Batch 20/49, Loss: 0.3280
Epoch 5/10, Batch 30/49, Loss: 0.2835
Epoch 5/10, Batch 40/49, Loss: 0.2646
Epoch 5/10, Train Loss: 0.3146, Valid Loss: 0.3325
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2411
Epoch 6/10, Batch 20/49, Loss: 0.2973
Epoch 6/10, Batch 30/49, Loss: 0.3141
Epoch 6/10, Batch 40/49, Loss: 0.2778
Epoch 6/10, Train Loss: 0.2925, Valid Loss: 0.3264
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2748
Epoch 7/10, Batch 20/49, Loss: 0.1799
Epoch 7/10, Batch 30/49, Loss: 0.2630
Epoch 7/10, Batch 40/49, Loss: 0.3630
Epoch 7/10, Train Loss: 0.2690, Valid Loss: 0.3249
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2036
Epoch 8/10, Batch 20/49, Loss: 0.2361
Epoch 8/10, Batch 30/49, Loss: 0.2586
Epoch 8/10, Batch 40/49, Loss: 0.2070
Epoch 8/10, Train Loss: 0.2429, Valid Loss: 0.2924
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1501
Epoch 9/10, Batch 20/49, Loss: 0.3492
Epoch 9/10, Batch 30/49, Loss: 0.5125
Epoch 9/10, Batch 40/49, Loss: 0.1769
Epoch 9/10, Train Loss: 0.2380, Valid Loss: 0.2794
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2930
Epoch 10/10, Batch 20/49, Loss: 0.1370
Epoch 10/10, Batch 30/49, Loss: 0.2879
Epoch 10/10, Batch 40/49, Loss: 0.3529
Epoch 10/10, Train Loss: 0.2154, Valid Loss: 0.2818
Accuracy: 0.9112
Precision: 0.9078
Recall: 0.9112
F1-score: 0.9089
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2995
Epoch 1/10, Batch 20/49, Loss: 1.0524
Epoch 1/10, Batch 30/49, Loss: 0.8796
Epoch 1/10, Batch 40/49, Loss: 0.6504
Epoch 1/10, Train Loss: 0.9977, Valid Loss: 0.6439
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6441
Epoch 2/10, Batch 20/49, Loss: 0.3900
Epoch 2/10, Batch 30/49, Loss: 0.4704
Epoch 2/10, Batch 40/49, Loss: 0.6567
Epoch 2/10, Train Loss: 0.5309, Valid Loss: 0.4864
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4608
Epoch 3/10, Batch 20/49, Loss: 0.3710
Epoch 3/10, Batch 30/49, Loss: 0.4621
Epoch 3/10, Batch 40/49, Loss: 0.2643
Epoch 3/10, Train Loss: 0.4116, Valid Loss: 0.4509
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2813
Epoch 4/10, Batch 20/49, Loss: 0.3745
Epoch 4/10, Batch 30/49, Loss: 0.2619
Epoch 4/10, Batch 40/49, Loss: 0.4028
Epoch 4/10, Train Loss: 0.3526, Valid Loss: 0.3868
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2171
Epoch 5/10, Batch 20/49, Loss: 0.2267
Epoch 5/10, Batch 30/49, Loss: 0.2808
Epoch 5/10, Batch 40/49, Loss: 0.1084
Epoch 5/10, Train Loss: 0.3087, Valid Loss: 0.3767
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2262
Epoch 6/10, Batch 20/49, Loss: 0.3271
Epoch 6/10, Batch 30/49, Loss: 0.2753
Epoch 6/10, Batch 40/49, Loss: 0.5182
Epoch 6/10, Train Loss: 0.2847, Valid Loss: 0.3829
Epoch 7/10, Batch 10/49, Loss: 0.2481
Epoch 7/10, Batch 20/49, Loss: 0.1396
Epoch 7/10, Batch 30/49, Loss: 0.3101
Epoch 7/10, Batch 40/49, Loss: 0.2105
Epoch 7/10, Train Loss: 0.2543, Valid Loss: 0.3884
Epoch 8/10, Batch 10/49, Loss: 0.1981
Epoch 8/10, Batch 20/49, Loss: 0.3092
Epoch 8/10, Batch 30/49, Loss: 0.3305
Epoch 8/10, Batch 40/49, Loss: 0.1710
Epoch 8/10, Train Loss: 0.2507, Valid Loss: 0.3683
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2793
Epoch 9/10, Batch 20/49, Loss: 0.2718
Epoch 9/10, Batch 30/49, Loss: 0.4115
Epoch 9/10, Batch 40/49, Loss: 0.2522
Epoch 9/10, Train Loss: 0.2365, Valid Loss: 0.3512
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2389
Epoch 10/10, Batch 20/49, Loss: 0.1336
Epoch 10/10, Batch 30/49, Loss: 0.1771
Epoch 10/10, Batch 40/49, Loss: 0.3258
Epoch 10/10, Train Loss: 0.2062, Valid Loss: 0.3532
Accuracy: 0.9042
Precision: 0.9004
Recall: 0.9042
F1-score: 0.9016
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2663
Epoch 1/10, Batch 20/49, Loss: 1.0945
Epoch 1/10, Batch 30/49, Loss: 0.9047
Epoch 1/10, Batch 40/49, Loss: 0.7798
Epoch 1/10, Train Loss: 1.0169, Valid Loss: 0.7090
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5921
Epoch 2/10, Batch 20/49, Loss: 0.4404
Epoch 2/10, Batch 30/49, Loss: 0.5725
Epoch 2/10, Batch 40/49, Loss: 0.5037
Epoch 2/10, Train Loss: 0.5565, Valid Loss: 0.5265
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4418
Epoch 3/10, Batch 20/49, Loss: 0.5281
Epoch 3/10, Batch 30/49, Loss: 0.4292
Epoch 3/10, Batch 40/49, Loss: 0.3642
Epoch 3/10, Train Loss: 0.4392, Valid Loss: 0.4708
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3845
Epoch 4/10, Batch 20/49, Loss: 0.5369
Epoch 4/10, Batch 30/49, Loss: 0.2559
Epoch 4/10, Batch 40/49, Loss: 0.3212
Epoch 4/10, Train Loss: 0.3755, Valid Loss: 0.4081
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2839
Epoch 5/10, Batch 20/49, Loss: 0.1942
Epoch 5/10, Batch 30/49, Loss: 0.2904
Epoch 5/10, Batch 40/49, Loss: 0.2749
Epoch 5/10, Train Loss: 0.3194, Valid Loss: 0.3964
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1908
Epoch 6/10, Batch 20/49, Loss: 0.3617
Epoch 6/10, Batch 30/49, Loss: 0.2750
Epoch 6/10, Batch 40/49, Loss: 0.2012
Epoch 6/10, Train Loss: 0.2995, Valid Loss: 0.3749
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2961
Epoch 7/10, Batch 20/49, Loss: 0.2123
Epoch 7/10, Batch 30/49, Loss: 0.3735
Epoch 7/10, Batch 40/49, Loss: 0.2188
Epoch 7/10, Train Loss: 0.2853, Valid Loss: 0.3966
Epoch 8/10, Batch 10/49, Loss: 0.1990
Epoch 8/10, Batch 20/49, Loss: 0.3108
Epoch 8/10, Batch 30/49, Loss: 0.2060
Epoch 8/10, Batch 40/49, Loss: 0.1602
Epoch 8/10, Train Loss: 0.2709, Valid Loss: 0.3592
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1384
Epoch 9/10, Batch 20/49, Loss: 0.3451
Epoch 9/10, Batch 30/49, Loss: 0.6058
Epoch 9/10, Batch 40/49, Loss: 0.1413
Epoch 9/10, Train Loss: 0.2504, Valid Loss: 0.3587
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2182
Epoch 10/10, Batch 20/49, Loss: 0.1584
Epoch 10/10, Batch 30/49, Loss: 0.3672
Epoch 10/10, Batch 40/49, Loss: 0.2726
Epoch 10/10, Train Loss: 0.2259, Valid Loss: 0.3280
Model saved!
Accuracy: 0.9077
Precision: 0.9047
Recall: 0.9077
F1-score: 0.9059
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2690
Epoch 1/10, Batch 20/49, Loss: 1.0540
Epoch 1/10, Batch 30/49, Loss: 0.8646
Epoch 1/10, Batch 40/49, Loss: 0.7914
Epoch 1/10, Train Loss: 1.0026, Valid Loss: 0.6396
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6398
Epoch 2/10, Batch 20/49, Loss: 0.3769
Epoch 2/10, Batch 30/49, Loss: 0.4222
Epoch 2/10, Batch 40/49, Loss: 0.4743
Epoch 2/10, Train Loss: 0.5376, Valid Loss: 0.4528
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4852
Epoch 3/10, Batch 20/49, Loss: 0.4226
Epoch 3/10, Batch 30/49, Loss: 0.4448
Epoch 3/10, Batch 40/49, Loss: 0.2931
Epoch 3/10, Train Loss: 0.4166, Valid Loss: 0.3856
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2389
Epoch 4/10, Batch 20/49, Loss: 0.3032
Epoch 4/10, Batch 30/49, Loss: 0.3107
Epoch 4/10, Batch 40/49, Loss: 0.3099
Epoch 4/10, Train Loss: 0.3494, Valid Loss: 0.3280
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2300
Epoch 5/10, Batch 20/49, Loss: 0.3879
Epoch 5/10, Batch 30/49, Loss: 0.2686
Epoch 5/10, Batch 40/49, Loss: 0.1851
Epoch 5/10, Train Loss: 0.3056, Valid Loss: 0.3180
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2938
Epoch 6/10, Batch 20/49, Loss: 0.1542
Epoch 6/10, Batch 30/49, Loss: 0.2564
Epoch 6/10, Batch 40/49, Loss: 0.3370
Epoch 6/10, Train Loss: 0.2882, Valid Loss: 0.2877
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2953
Epoch 7/10, Batch 20/49, Loss: 0.2304
Epoch 7/10, Batch 30/49, Loss: 0.3332
Epoch 7/10, Batch 40/49, Loss: 0.1988
Epoch 7/10, Train Loss: 0.2598, Valid Loss: 0.2803
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2129
Epoch 8/10, Batch 20/49, Loss: 0.3295
Epoch 8/10, Batch 30/49, Loss: 0.3401
Epoch 8/10, Batch 40/49, Loss: 0.2036
Epoch 8/10, Train Loss: 0.2527, Valid Loss: 0.2659
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2139
Epoch 9/10, Batch 20/49, Loss: 0.3788
Epoch 9/10, Batch 30/49, Loss: 0.3115
Epoch 9/10, Batch 40/49, Loss: 0.1847
Epoch 9/10, Train Loss: 0.2405, Valid Loss: 0.2607
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2273
Epoch 10/10, Batch 20/49, Loss: 0.1743
Epoch 10/10, Batch 30/49, Loss: 0.1649
Epoch 10/10, Batch 40/49, Loss: 0.1643
Epoch 10/10, Train Loss: 0.2104, Valid Loss: 0.2598
Model saved!
Accuracy: 0.9030
Precision: 0.9014
Recall: 0.9030
F1-score: 0.8981
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3477
Epoch 1/10, Batch 20/49, Loss: 1.0538
Epoch 1/10, Batch 30/49, Loss: 0.8536
Epoch 1/10, Batch 40/49, Loss: 0.7997
Epoch 1/10, Train Loss: 1.0000, Valid Loss: 0.6403
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5934
Epoch 2/10, Batch 20/49, Loss: 0.4577
Epoch 2/10, Batch 30/49, Loss: 0.5173
Epoch 2/10, Batch 40/49, Loss: 0.5317
Epoch 2/10, Train Loss: 0.5278, Valid Loss: 0.4681
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5431
Epoch 3/10, Batch 20/49, Loss: 0.5068
Epoch 3/10, Batch 30/49, Loss: 0.3765
Epoch 3/10, Batch 40/49, Loss: 0.3257
Epoch 3/10, Train Loss: 0.4182, Valid Loss: 0.3962
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2266
Epoch 4/10, Batch 20/49, Loss: 0.4784
Epoch 4/10, Batch 30/49, Loss: 0.2759
Epoch 4/10, Batch 40/49, Loss: 0.3325
Epoch 4/10, Train Loss: 0.3479, Valid Loss: 0.3487
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2739
Epoch 5/10, Batch 20/49, Loss: 0.2140
Epoch 5/10, Batch 30/49, Loss: 0.1987
Epoch 5/10, Batch 40/49, Loss: 0.1869
Epoch 5/10, Train Loss: 0.2964, Valid Loss: 0.3291
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1541
Epoch 6/10, Batch 20/49, Loss: 0.2568
Epoch 6/10, Batch 30/49, Loss: 0.3605
Epoch 6/10, Batch 40/49, Loss: 0.2647
Epoch 6/10, Train Loss: 0.2749, Valid Loss: 0.3202
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3436
Epoch 7/10, Batch 20/49, Loss: 0.2269
Epoch 7/10, Batch 30/49, Loss: 0.3684
Epoch 7/10, Batch 40/49, Loss: 0.2283
Epoch 7/10, Train Loss: 0.2746, Valid Loss: 0.3235
Epoch 8/10, Batch 10/49, Loss: 0.3172
Epoch 8/10, Batch 20/49, Loss: 0.2564
Epoch 8/10, Batch 30/49, Loss: 0.2220
Epoch 8/10, Batch 40/49, Loss: 0.3729
Epoch 8/10, Train Loss: 0.2412, Valid Loss: 0.2996
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1792
Epoch 9/10, Batch 20/49, Loss: 0.2369
Epoch 9/10, Batch 30/49, Loss: 0.5225
Epoch 9/10, Batch 40/49, Loss: 0.2326
Epoch 9/10, Train Loss: 0.2228, Valid Loss: 0.2888
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2549
Epoch 10/10, Batch 20/49, Loss: 0.1237
Epoch 10/10, Batch 30/49, Loss: 0.1933
Epoch 10/10, Batch 40/49, Loss: 0.2152
Epoch 10/10, Train Loss: 0.2090, Valid Loss: 0.2857
Model saved!
Accuracy: 0.9054
Precision: 0.9018
Recall: 0.9054
F1-score: 0.9026
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2141
Epoch 1/10, Batch 20/49, Loss: 1.0095
Epoch 1/10, Batch 30/49, Loss: 0.8136
Epoch 1/10, Batch 40/49, Loss: 0.6859
Epoch 1/10, Train Loss: 0.9915, Valid Loss: 0.6501
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5779
Epoch 2/10, Batch 20/49, Loss: 0.5131
Epoch 2/10, Batch 30/49, Loss: 0.5258
Epoch 2/10, Batch 40/49, Loss: 0.4000
Epoch 2/10, Train Loss: 0.5421, Valid Loss: 0.4832
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5265
Epoch 3/10, Batch 20/49, Loss: 0.3769
Epoch 3/10, Batch 30/49, Loss: 0.4926
Epoch 3/10, Batch 40/49, Loss: 0.3522
Epoch 3/10, Train Loss: 0.4186, Valid Loss: 0.4201
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2359
Epoch 4/10, Batch 20/49, Loss: 0.3934
Epoch 4/10, Batch 30/49, Loss: 0.2644
Epoch 4/10, Batch 40/49, Loss: 0.2720
Epoch 4/10, Train Loss: 0.3573, Valid Loss: 0.3652
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3228
Epoch 5/10, Batch 20/49, Loss: 0.2059
Epoch 5/10, Batch 30/49, Loss: 0.2707
Epoch 5/10, Batch 40/49, Loss: 0.1724
Epoch 5/10, Train Loss: 0.3182, Valid Loss: 0.3453
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1916
Epoch 6/10, Batch 20/49, Loss: 0.3221
Epoch 6/10, Batch 30/49, Loss: 0.1825
Epoch 6/10, Batch 40/49, Loss: 0.3728
Epoch 6/10, Train Loss: 0.2975, Valid Loss: 0.3275
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1689
Epoch 7/10, Batch 20/49, Loss: 0.2616
Epoch 7/10, Batch 30/49, Loss: 0.3079
Epoch 7/10, Batch 40/49, Loss: 0.1571
Epoch 7/10, Train Loss: 0.2548, Valid Loss: 0.3249
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1866
Epoch 8/10, Batch 20/49, Loss: 0.2221
Epoch 8/10, Batch 30/49, Loss: 0.2607
Epoch 8/10, Batch 40/49, Loss: 0.2134
Epoch 8/10, Train Loss: 0.2476, Valid Loss: 0.3073
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1633
Epoch 9/10, Batch 20/49, Loss: 0.2120
Epoch 9/10, Batch 30/49, Loss: 0.6286
Epoch 9/10, Batch 40/49, Loss: 0.1682
Epoch 9/10, Train Loss: 0.2408, Valid Loss: 0.2832
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3140
Epoch 10/10, Batch 20/49, Loss: 0.1801
Epoch 10/10, Batch 30/49, Loss: 0.3565
Epoch 10/10, Batch 40/49, Loss: 0.2153
Epoch 10/10, Train Loss: 0.2119, Valid Loss: 0.2800
Model saved!
Accuracy: 0.9030
Precision: 0.8988
Recall: 0.9030
F1-score: 0.8992
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2105
Epoch 1/10, Batch 20/49, Loss: 1.0735
Epoch 1/10, Batch 30/49, Loss: 0.7838
Epoch 1/10, Batch 40/49, Loss: 0.6878
Epoch 1/10, Train Loss: 1.0132, Valid Loss: 0.6386
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6536
Epoch 2/10, Batch 20/49, Loss: 0.4904
Epoch 2/10, Batch 30/49, Loss: 0.5438
Epoch 2/10, Batch 40/49, Loss: 0.5306
Epoch 2/10, Train Loss: 0.5463, Valid Loss: 0.4673
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5655
Epoch 3/10, Batch 20/49, Loss: 0.6066
Epoch 3/10, Batch 30/49, Loss: 0.2878
Epoch 3/10, Batch 40/49, Loss: 0.4933
Epoch 3/10, Train Loss: 0.4173, Valid Loss: 0.3850
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3096
Epoch 4/10, Batch 20/49, Loss: 0.4033
Epoch 4/10, Batch 30/49, Loss: 0.3617
Epoch 4/10, Batch 40/49, Loss: 0.2510
Epoch 4/10, Train Loss: 0.3760, Valid Loss: 0.3387
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2635
Epoch 5/10, Batch 20/49, Loss: 0.2607
Epoch 5/10, Batch 30/49, Loss: 0.1744
Epoch 5/10, Batch 40/49, Loss: 0.2368
Epoch 5/10, Train Loss: 0.3075, Valid Loss: 0.3240
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2720
Epoch 6/10, Batch 20/49, Loss: 0.3012
Epoch 6/10, Batch 30/49, Loss: 0.3610
Epoch 6/10, Batch 40/49, Loss: 0.2093
Epoch 6/10, Train Loss: 0.2965, Valid Loss: 0.3100
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3551
Epoch 7/10, Batch 20/49, Loss: 0.1824
Epoch 7/10, Batch 30/49, Loss: 0.4424
Epoch 7/10, Batch 40/49, Loss: 0.3419
Epoch 7/10, Train Loss: 0.2673, Valid Loss: 0.3115
Epoch 8/10, Batch 10/49, Loss: 0.1794
Epoch 8/10, Batch 20/49, Loss: 0.2581
Epoch 8/10, Batch 30/49, Loss: 0.1318
Epoch 8/10, Batch 40/49, Loss: 0.1815
Epoch 8/10, Train Loss: 0.2599, Valid Loss: 0.2820
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1966
Epoch 9/10, Batch 20/49, Loss: 0.3230
Epoch 9/10, Batch 30/49, Loss: 0.4278
Epoch 9/10, Batch 40/49, Loss: 0.1467
Epoch 9/10, Train Loss: 0.2382, Valid Loss: 0.2754
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2188
Epoch 10/10, Batch 20/49, Loss: 0.1750
Epoch 10/10, Batch 30/49, Loss: 0.2551
Epoch 10/10, Batch 40/49, Loss: 0.1598
Epoch 10/10, Train Loss: 0.2129, Valid Loss: 0.2612
Model saved!
Accuracy: 0.9065
Precision: 0.9033
Recall: 0.9065
F1-score: 0.9029
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2881
Epoch 1/10, Batch 20/49, Loss: 1.0487
Epoch 1/10, Batch 30/49, Loss: 0.7776
Epoch 1/10, Batch 40/49, Loss: 0.7771
Epoch 1/10, Train Loss: 0.9944, Valid Loss: 0.6711
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6438
Epoch 2/10, Batch 20/49, Loss: 0.4488
Epoch 2/10, Batch 30/49, Loss: 0.5173
Epoch 2/10, Batch 40/49, Loss: 0.4159
Epoch 2/10, Train Loss: 0.5424, Valid Loss: 0.5007
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4388
Epoch 3/10, Batch 20/49, Loss: 0.4238
Epoch 3/10, Batch 30/49, Loss: 0.3939
Epoch 3/10, Batch 40/49, Loss: 0.3598
Epoch 3/10, Train Loss: 0.4137, Valid Loss: 0.4361
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2529
Epoch 4/10, Batch 20/49, Loss: 0.4071
Epoch 4/10, Batch 30/49, Loss: 0.3940
Epoch 4/10, Batch 40/49, Loss: 0.3049
Epoch 4/10, Train Loss: 0.3624, Valid Loss: 0.3934
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2697
Epoch 5/10, Batch 20/49, Loss: 0.1795
Epoch 5/10, Batch 30/49, Loss: 0.2703
Epoch 5/10, Batch 40/49, Loss: 0.2022
Epoch 5/10, Train Loss: 0.3083, Valid Loss: 0.3578
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2035
Epoch 6/10, Batch 20/49, Loss: 0.2716
Epoch 6/10, Batch 30/49, Loss: 0.3965
Epoch 6/10, Batch 40/49, Loss: 0.2611
Epoch 6/10, Train Loss: 0.2768, Valid Loss: 0.3298
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3399
Epoch 7/10, Batch 20/49, Loss: 0.1974
Epoch 7/10, Batch 30/49, Loss: 0.4231
Epoch 7/10, Batch 40/49, Loss: 0.1907
Epoch 7/10, Train Loss: 0.2856, Valid Loss: 0.3267
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2535
Epoch 8/10, Batch 20/49, Loss: 0.4405
Epoch 8/10, Batch 30/49, Loss: 0.2751
Epoch 8/10, Batch 40/49, Loss: 0.1821
Epoch 8/10, Train Loss: 0.2563, Valid Loss: 0.3161
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1515
Epoch 9/10, Batch 20/49, Loss: 0.2516
Epoch 9/10, Batch 30/49, Loss: 0.5004
Epoch 9/10, Batch 40/49, Loss: 0.1828
Epoch 9/10, Train Loss: 0.2442, Valid Loss: 0.3097
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1842
Epoch 10/10, Batch 20/49, Loss: 0.1220
Epoch 10/10, Batch 30/49, Loss: 0.2592
Epoch 10/10, Batch 40/49, Loss: 0.3614
Epoch 10/10, Train Loss: 0.2178, Valid Loss: 0.3053
Model saved!
Accuracy: 0.8984
Precision: 0.8950
Recall: 0.8984
F1-score: 0.8938
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3340
Epoch 1/10, Batch 20/49, Loss: 1.0581
Epoch 1/10, Batch 30/49, Loss: 0.7966
Epoch 1/10, Batch 40/49, Loss: 0.8039
Epoch 1/10, Train Loss: 0.9975, Valid Loss: 0.6246
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.8395
Epoch 2/10, Batch 20/49, Loss: 0.4620
Epoch 2/10, Batch 30/49, Loss: 0.5719
Epoch 2/10, Batch 40/49, Loss: 0.4870
Epoch 2/10, Train Loss: 0.5314, Valid Loss: 0.4355
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3537
Epoch 3/10, Batch 20/49, Loss: 0.4712
Epoch 3/10, Batch 30/49, Loss: 0.3566
Epoch 3/10, Batch 40/49, Loss: 0.2253
Epoch 3/10, Train Loss: 0.4132, Valid Loss: 0.3569
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3004
Epoch 4/10, Batch 20/49, Loss: 0.4495
Epoch 4/10, Batch 30/49, Loss: 0.1899
Epoch 4/10, Batch 40/49, Loss: 0.3173
Epoch 4/10, Train Loss: 0.3490, Valid Loss: 0.2867
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3067
Epoch 5/10, Batch 20/49, Loss: 0.1992
Epoch 5/10, Batch 30/49, Loss: 0.2276
Epoch 5/10, Batch 40/49, Loss: 0.2601
Epoch 5/10, Train Loss: 0.2966, Valid Loss: 0.2825
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1615
Epoch 6/10, Batch 20/49, Loss: 0.2709
Epoch 6/10, Batch 30/49, Loss: 0.6462
Epoch 6/10, Batch 40/49, Loss: 0.2830
Epoch 6/10, Train Loss: 0.2845, Valid Loss: 0.2524
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2585
Epoch 7/10, Batch 20/49, Loss: 0.1763
Epoch 7/10, Batch 30/49, Loss: 0.3814
Epoch 7/10, Batch 40/49, Loss: 0.2711
Epoch 7/10, Train Loss: 0.2752, Valid Loss: 0.2460
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2180
Epoch 8/10, Batch 20/49, Loss: 0.2524
Epoch 8/10, Batch 30/49, Loss: 0.1817
Epoch 8/10, Batch 40/49, Loss: 0.1556
Epoch 8/10, Train Loss: 0.2422, Valid Loss: 0.2253
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2038
Epoch 9/10, Batch 20/49, Loss: 0.2631
Epoch 9/10, Batch 30/49, Loss: 0.3980
Epoch 9/10, Batch 40/49, Loss: 0.2530
Epoch 9/10, Train Loss: 0.2280, Valid Loss: 0.2200
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1889
Epoch 10/10, Batch 20/49, Loss: 0.0985
Epoch 10/10, Batch 30/49, Loss: 0.2922
Epoch 10/10, Batch 40/49, Loss: 0.2963
Epoch 10/10, Train Loss: 0.1979, Valid Loss: 0.2142
Model saved!
Accuracy: 0.9019
Precision: 0.8989
Recall: 0.9019
F1-score: 0.8992
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3054
Epoch 1/10, Batch 20/49, Loss: 1.0915
Epoch 1/10, Batch 30/49, Loss: 0.8370
Epoch 1/10, Batch 40/49, Loss: 0.7052
Epoch 1/10, Train Loss: 0.9998, Valid Loss: 0.6310
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6798
Epoch 2/10, Batch 20/49, Loss: 0.4480
Epoch 2/10, Batch 30/49, Loss: 0.4941
Epoch 2/10, Batch 40/49, Loss: 0.6897
Epoch 2/10, Train Loss: 0.5316, Valid Loss: 0.4556
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3835
Epoch 3/10, Batch 20/49, Loss: 0.5162
Epoch 3/10, Batch 30/49, Loss: 0.2952
Epoch 3/10, Batch 40/49, Loss: 0.2617
Epoch 3/10, Train Loss: 0.4215, Valid Loss: 0.3939
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3798
Epoch 4/10, Batch 20/49, Loss: 0.3936
Epoch 4/10, Batch 30/49, Loss: 0.3038
Epoch 4/10, Batch 40/49, Loss: 0.3859
Epoch 4/10, Train Loss: 0.3667, Valid Loss: 0.3558
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.1910
Epoch 5/10, Batch 20/49, Loss: 0.2764
Epoch 5/10, Batch 30/49, Loss: 0.2914
Epoch 5/10, Batch 40/49, Loss: 0.3270
Epoch 5/10, Train Loss: 0.3037, Valid Loss: 0.3332
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2778
Epoch 6/10, Batch 20/49, Loss: 0.3408
Epoch 6/10, Batch 30/49, Loss: 0.3310
Epoch 6/10, Batch 40/49, Loss: 0.1493
Epoch 6/10, Train Loss: 0.2879, Valid Loss: 0.3076
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2425
Epoch 7/10, Batch 20/49, Loss: 0.1480
Epoch 7/10, Batch 30/49, Loss: 0.3688
Epoch 7/10, Batch 40/49, Loss: 0.1750
Epoch 7/10, Train Loss: 0.2593, Valid Loss: 0.3063
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2083
Epoch 8/10, Batch 20/49, Loss: 0.3295
Epoch 8/10, Batch 30/49, Loss: 0.2915
Epoch 8/10, Batch 40/49, Loss: 0.2139
Epoch 8/10, Train Loss: 0.2536, Valid Loss: 0.2876
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1081
Epoch 9/10, Batch 20/49, Loss: 0.4354
Epoch 9/10, Batch 30/49, Loss: 0.3726
Epoch 9/10, Batch 40/49, Loss: 0.1357
Epoch 9/10, Train Loss: 0.2238, Valid Loss: 0.2969
Epoch 10/10, Batch 10/49, Loss: 0.3874
Epoch 10/10, Batch 20/49, Loss: 0.1369
Epoch 10/10, Batch 30/49, Loss: 0.3103
Epoch 10/10, Batch 40/49, Loss: 0.1530
Epoch 10/10, Train Loss: 0.2207, Valid Loss: 0.2812
Model saved!
Accuracy: 0.9054
Precision: 0.9018
Recall: 0.9054
F1-score: 0.9016
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2548
Epoch 1/10, Batch 20/49, Loss: 1.0214
Epoch 1/10, Batch 30/49, Loss: 0.7687
Epoch 1/10, Batch 40/49, Loss: 0.7397
Epoch 1/10, Train Loss: 0.9999, Valid Loss: 0.6867
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7122
Epoch 2/10, Batch 20/49, Loss: 0.4412
Epoch 2/10, Batch 30/49, Loss: 0.6312
Epoch 2/10, Batch 40/49, Loss: 0.3963
Epoch 2/10, Train Loss: 0.5421, Valid Loss: 0.5140
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3446
Epoch 3/10, Batch 20/49, Loss: 0.3268
Epoch 3/10, Batch 30/49, Loss: 0.4292
Epoch 3/10, Batch 40/49, Loss: 0.3579
Epoch 3/10, Train Loss: 0.4298, Valid Loss: 0.4371
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2367
Epoch 4/10, Batch 20/49, Loss: 0.3663
Epoch 4/10, Batch 30/49, Loss: 0.1830
Epoch 4/10, Batch 40/49, Loss: 0.2892
Epoch 4/10, Train Loss: 0.3638, Valid Loss: 0.3842
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2608
Epoch 5/10, Batch 20/49, Loss: 0.1861
Epoch 5/10, Batch 30/49, Loss: 0.2610
Epoch 5/10, Batch 40/49, Loss: 0.1916
Epoch 5/10, Train Loss: 0.3186, Valid Loss: 0.3528
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1852
Epoch 6/10, Batch 20/49, Loss: 0.2876
Epoch 6/10, Batch 30/49, Loss: 0.3127
Epoch 6/10, Batch 40/49, Loss: 0.2820
Epoch 6/10, Train Loss: 0.2912, Valid Loss: 0.3331
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2502
Epoch 7/10, Batch 20/49, Loss: 0.2191
Epoch 7/10, Batch 30/49, Loss: 0.4163
Epoch 7/10, Batch 40/49, Loss: 0.1569
Epoch 7/10, Train Loss: 0.2675, Valid Loss: 0.3274
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2240
Epoch 8/10, Batch 20/49, Loss: 0.2534
Epoch 8/10, Batch 30/49, Loss: 0.3079
Epoch 8/10, Batch 40/49, Loss: 0.1956
Epoch 8/10, Train Loss: 0.2475, Valid Loss: 0.3126
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1700
Epoch 9/10, Batch 20/49, Loss: 0.2289
Epoch 9/10, Batch 30/49, Loss: 0.5171
Epoch 9/10, Batch 40/49, Loss: 0.1530
Epoch 9/10, Train Loss: 0.2573, Valid Loss: 0.3087
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2423
Epoch 10/10, Batch 20/49, Loss: 0.1880
Epoch 10/10, Batch 30/49, Loss: 0.3611
Epoch 10/10, Batch 40/49, Loss: 0.2621
Epoch 10/10, Train Loss: 0.2216, Valid Loss: 0.2967
Model saved!
Accuracy: 0.9007
Precision: 0.8974
Recall: 0.9007
F1-score: 0.8954
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1822
Epoch 1/10, Batch 20/49, Loss: 1.0239
Epoch 1/10, Batch 30/49, Loss: 0.8254
Epoch 1/10, Batch 40/49, Loss: 0.7479
Epoch 1/10, Train Loss: 0.9927, Valid Loss: 0.6223
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5936
Epoch 2/10, Batch 20/49, Loss: 0.5483
Epoch 2/10, Batch 30/49, Loss: 0.4794
Epoch 2/10, Batch 40/49, Loss: 0.4792
Epoch 2/10, Train Loss: 0.5423, Valid Loss: 0.4480
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4330
Epoch 3/10, Batch 20/49, Loss: 0.3882
Epoch 3/10, Batch 30/49, Loss: 0.3610
Epoch 3/10, Batch 40/49, Loss: 0.5257
Epoch 3/10, Train Loss: 0.4124, Valid Loss: 0.3949
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2867
Epoch 4/10, Batch 20/49, Loss: 0.3395
Epoch 4/10, Batch 30/49, Loss: 0.2037
Epoch 4/10, Batch 40/49, Loss: 0.2906
Epoch 4/10, Train Loss: 0.3632, Valid Loss: 0.3388
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2246
Epoch 5/10, Batch 20/49, Loss: 0.2241
Epoch 5/10, Batch 30/49, Loss: 0.3323
Epoch 5/10, Batch 40/49, Loss: 0.2511
Epoch 5/10, Train Loss: 0.3121, Valid Loss: 0.3167
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2457
Epoch 6/10, Batch 20/49, Loss: 0.3031
Epoch 6/10, Batch 30/49, Loss: 0.3202
Epoch 6/10, Batch 40/49, Loss: 0.1816
Epoch 6/10, Train Loss: 0.2780, Valid Loss: 0.3054
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1513
Epoch 7/10, Batch 20/49, Loss: 0.2084
Epoch 7/10, Batch 30/49, Loss: 0.4201
Epoch 7/10, Batch 40/49, Loss: 0.1830
Epoch 7/10, Train Loss: 0.2610, Valid Loss: 0.2977
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1838
Epoch 8/10, Batch 20/49, Loss: 0.3290
Epoch 8/10, Batch 30/49, Loss: 0.2637
Epoch 8/10, Batch 40/49, Loss: 0.2061
Epoch 8/10, Train Loss: 0.2553, Valid Loss: 0.2868
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1338
Epoch 9/10, Batch 20/49, Loss: 0.3966
Epoch 9/10, Batch 30/49, Loss: 0.3333
Epoch 9/10, Batch 40/49, Loss: 0.1530
Epoch 9/10, Train Loss: 0.2283, Valid Loss: 0.2775
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2376
Epoch 10/10, Batch 20/49, Loss: 0.1030
Epoch 10/10, Batch 30/49, Loss: 0.3393
Epoch 10/10, Batch 40/49, Loss: 0.1572
Epoch 10/10, Train Loss: 0.2098, Valid Loss: 0.2695
Model saved!
Accuracy: 0.9065
Precision: 0.9036
Recall: 0.9065
F1-score: 0.9036
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2760
Epoch 1/10, Batch 20/49, Loss: 1.0971
Epoch 1/10, Batch 30/49, Loss: 0.7758
Epoch 1/10, Batch 40/49, Loss: 0.7297
Epoch 1/10, Train Loss: 0.9997, Valid Loss: 0.6734
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7278
Epoch 2/10, Batch 20/49, Loss: 0.3268
Epoch 2/10, Batch 30/49, Loss: 0.7136
Epoch 2/10, Batch 40/49, Loss: 0.3784
Epoch 2/10, Train Loss: 0.5330, Valid Loss: 0.4891
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5936
Epoch 3/10, Batch 20/49, Loss: 0.4943
Epoch 3/10, Batch 30/49, Loss: 0.4243
Epoch 3/10, Batch 40/49, Loss: 0.4304
Epoch 3/10, Train Loss: 0.4182, Valid Loss: 0.4335
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2317
Epoch 4/10, Batch 20/49, Loss: 0.4629
Epoch 4/10, Batch 30/49, Loss: 0.2251
Epoch 4/10, Batch 40/49, Loss: 0.3471
Epoch 4/10, Train Loss: 0.3746, Valid Loss: 0.3878
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2485
Epoch 5/10, Batch 20/49, Loss: 0.2010
Epoch 5/10, Batch 30/49, Loss: 0.3455
Epoch 5/10, Batch 40/49, Loss: 0.2577
Epoch 5/10, Train Loss: 0.3119, Valid Loss: 0.3614
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3848
Epoch 6/10, Batch 20/49, Loss: 0.3862
Epoch 6/10, Batch 30/49, Loss: 0.3463
Epoch 6/10, Batch 40/49, Loss: 0.2017
Epoch 6/10, Train Loss: 0.2943, Valid Loss: 0.3333
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2523
Epoch 7/10, Batch 20/49, Loss: 0.1789
Epoch 7/10, Batch 30/49, Loss: 0.3325
Epoch 7/10, Batch 40/49, Loss: 0.2231
Epoch 7/10, Train Loss: 0.2597, Valid Loss: 0.3264
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1418
Epoch 8/10, Batch 20/49, Loss: 0.4887
Epoch 8/10, Batch 30/49, Loss: 0.2657
Epoch 8/10, Batch 40/49, Loss: 0.1630
Epoch 8/10, Train Loss: 0.2628, Valid Loss: 0.3197
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1962
Epoch 9/10, Batch 20/49, Loss: 0.2389
Epoch 9/10, Batch 30/49, Loss: 0.4541
Epoch 9/10, Batch 40/49, Loss: 0.3566
Epoch 9/10, Train Loss: 0.2424, Valid Loss: 0.3085
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2444
Epoch 10/10, Batch 20/49, Loss: 0.1757
Epoch 10/10, Batch 30/49, Loss: 0.2672
Epoch 10/10, Batch 40/49, Loss: 0.1757
Epoch 10/10, Train Loss: 0.2171, Valid Loss: 0.3089
Accuracy: 0.9159
Precision: 0.9129
Recall: 0.9159
F1-score: 0.9139
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 22. Fitness: 0.9159
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2507
Epoch 1/10, Batch 20/49, Loss: 1.0641
Epoch 1/10, Batch 30/49, Loss: 0.8419
Epoch 1/10, Batch 40/49, Loss: 0.8205
Epoch 1/10, Train Loss: 0.9925, Valid Loss: 0.6097
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6085
Epoch 2/10, Batch 20/49, Loss: 0.4199
Epoch 2/10, Batch 30/49, Loss: 0.6359
Epoch 2/10, Batch 40/49, Loss: 0.5450
Epoch 2/10, Train Loss: 0.5353, Valid Loss: 0.4385
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3604
Epoch 3/10, Batch 20/49, Loss: 0.5450
Epoch 3/10, Batch 30/49, Loss: 0.4498
Epoch 3/10, Batch 40/49, Loss: 0.4231
Epoch 3/10, Train Loss: 0.4142, Valid Loss: 0.3786
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3485
Epoch 4/10, Batch 20/49, Loss: 0.3808
Epoch 4/10, Batch 30/49, Loss: 0.3050
Epoch 4/10, Batch 40/49, Loss: 0.2958
Epoch 4/10, Train Loss: 0.3543, Valid Loss: 0.3310
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3723
Epoch 5/10, Batch 20/49, Loss: 0.2961
Epoch 5/10, Batch 30/49, Loss: 0.2749
Epoch 5/10, Batch 40/49, Loss: 0.1906
Epoch 5/10, Train Loss: 0.3096, Valid Loss: 0.3000
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3170
Epoch 6/10, Batch 20/49, Loss: 0.3637
Epoch 6/10, Batch 30/49, Loss: 0.2470
Epoch 6/10, Batch 40/49, Loss: 0.3194
Epoch 6/10, Train Loss: 0.2816, Valid Loss: 0.2880
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2559
Epoch 7/10, Batch 20/49, Loss: 0.2670
Epoch 7/10, Batch 30/49, Loss: 0.3477
Epoch 7/10, Batch 40/49, Loss: 0.2126
Epoch 7/10, Train Loss: 0.2564, Valid Loss: 0.2764
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2801
Epoch 8/10, Batch 20/49, Loss: 0.2282
Epoch 8/10, Batch 30/49, Loss: 0.3955
Epoch 8/10, Batch 40/49, Loss: 0.1439
Epoch 8/10, Train Loss: 0.2435, Valid Loss: 0.2636
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1158
Epoch 9/10, Batch 20/49, Loss: 0.2511
Epoch 9/10, Batch 30/49, Loss: 0.4627
Epoch 9/10, Batch 40/49, Loss: 0.1708
Epoch 9/10, Train Loss: 0.2299, Valid Loss: 0.2663
Epoch 10/10, Batch 10/49, Loss: 0.1903
Epoch 10/10, Batch 20/49, Loss: 0.2576
Epoch 10/10, Batch 30/49, Loss: 0.2846
Epoch 10/10, Batch 40/49, Loss: 0.1751
Epoch 10/10, Train Loss: 0.2095, Valid Loss: 0.2577
Model saved!
Accuracy: 0.9042
Precision: 0.9012
Recall: 0.9042
F1-score: 0.8983
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2958
Epoch 1/10, Batch 20/49, Loss: 1.0128
Epoch 1/10, Batch 30/49, Loss: 0.7832
Epoch 1/10, Batch 40/49, Loss: 0.7153
Epoch 1/10, Train Loss: 1.0056, Valid Loss: 0.6438
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6488
Epoch 2/10, Batch 20/49, Loss: 0.4719
Epoch 2/10, Batch 30/49, Loss: 0.4854
Epoch 2/10, Batch 40/49, Loss: 0.4984
Epoch 2/10, Train Loss: 0.5316, Valid Loss: 0.4566
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4000
Epoch 3/10, Batch 20/49, Loss: 0.3574
Epoch 3/10, Batch 30/49, Loss: 0.4369
Epoch 3/10, Batch 40/49, Loss: 0.4515
Epoch 3/10, Train Loss: 0.4209, Valid Loss: 0.3825
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2764
Epoch 4/10, Batch 20/49, Loss: 0.4304
Epoch 4/10, Batch 30/49, Loss: 0.2574
Epoch 4/10, Batch 40/49, Loss: 0.3572
Epoch 4/10, Train Loss: 0.3640, Valid Loss: 0.3315
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2321
Epoch 5/10, Batch 20/49, Loss: 0.2604
Epoch 5/10, Batch 30/49, Loss: 0.2208
Epoch 5/10, Batch 40/49, Loss: 0.2392
Epoch 5/10, Train Loss: 0.3198, Valid Loss: 0.3077
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2291
Epoch 6/10, Batch 20/49, Loss: 0.2266
Epoch 6/10, Batch 30/49, Loss: 0.3709
Epoch 6/10, Batch 40/49, Loss: 0.2228
Epoch 6/10, Train Loss: 0.2862, Valid Loss: 0.2967
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3134
Epoch 7/10, Batch 20/49, Loss: 0.1859
Epoch 7/10, Batch 30/49, Loss: 0.3558
Epoch 7/10, Batch 40/49, Loss: 0.1729
Epoch 7/10, Train Loss: 0.2735, Valid Loss: 0.2879
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3309
Epoch 8/10, Batch 20/49, Loss: 0.1857
Epoch 8/10, Batch 30/49, Loss: 0.2196
Epoch 8/10, Batch 40/49, Loss: 0.2431
Epoch 8/10, Train Loss: 0.2570, Valid Loss: 0.2708
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1196
Epoch 9/10, Batch 20/49, Loss: 0.2680
Epoch 9/10, Batch 30/49, Loss: 0.5309
Epoch 9/10, Batch 40/49, Loss: 0.1993
Epoch 9/10, Train Loss: 0.2383, Valid Loss: 0.2571
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2402
Epoch 10/10, Batch 20/49, Loss: 0.2111
Epoch 10/10, Batch 30/49, Loss: 0.3564
Epoch 10/10, Batch 40/49, Loss: 0.2451
Epoch 10/10, Train Loss: 0.2179, Valid Loss: 0.2519
Model saved!
Accuracy: 0.9065
Precision: 0.9032
Recall: 0.9065
F1-score: 0.9038
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3300
Epoch 1/10, Batch 20/49, Loss: 1.0913
Epoch 1/10, Batch 30/49, Loss: 0.8872
Epoch 1/10, Batch 40/49, Loss: 0.7653
Epoch 1/10, Train Loss: 1.0038, Valid Loss: 0.6574
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6725
Epoch 2/10, Batch 20/49, Loss: 0.3639
Epoch 2/10, Batch 30/49, Loss: 0.5643
Epoch 2/10, Batch 40/49, Loss: 0.4437
Epoch 2/10, Train Loss: 0.5303, Valid Loss: 0.4648
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4357
Epoch 3/10, Batch 20/49, Loss: 0.4607
Epoch 3/10, Batch 30/49, Loss: 0.3467
Epoch 3/10, Batch 40/49, Loss: 0.3642
Epoch 3/10, Train Loss: 0.4222, Valid Loss: 0.3885
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2661
Epoch 4/10, Batch 20/49, Loss: 0.3392
Epoch 4/10, Batch 30/49, Loss: 0.2850
Epoch 4/10, Batch 40/49, Loss: 0.2244
Epoch 4/10, Train Loss: 0.3642, Valid Loss: 0.3388
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4542
Epoch 5/10, Batch 20/49, Loss: 0.1977
Epoch 5/10, Batch 30/49, Loss: 0.2292
Epoch 5/10, Batch 40/49, Loss: 0.2837
Epoch 5/10, Train Loss: 0.3062, Valid Loss: 0.3232
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1837
Epoch 6/10, Batch 20/49, Loss: 0.3541
Epoch 6/10, Batch 30/49, Loss: 0.3042
Epoch 6/10, Batch 40/49, Loss: 0.3105
Epoch 6/10, Train Loss: 0.2794, Valid Loss: 0.3105
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2280
Epoch 7/10, Batch 20/49, Loss: 0.2017
Epoch 7/10, Batch 30/49, Loss: 0.3089
Epoch 7/10, Batch 40/49, Loss: 0.1978
Epoch 7/10, Train Loss: 0.2681, Valid Loss: 0.2991
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2198
Epoch 8/10, Batch 20/49, Loss: 0.3627
Epoch 8/10, Batch 30/49, Loss: 0.1752
Epoch 8/10, Batch 40/49, Loss: 0.2435
Epoch 8/10, Train Loss: 0.2525, Valid Loss: 0.2803
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2403
Epoch 9/10, Batch 20/49, Loss: 0.1534
Epoch 9/10, Batch 30/49, Loss: 0.5114
Epoch 9/10, Batch 40/49, Loss: 0.1659
Epoch 9/10, Train Loss: 0.2491, Valid Loss: 0.2701
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2965
Epoch 10/10, Batch 20/49, Loss: 0.1677
Epoch 10/10, Batch 30/49, Loss: 0.2428
Epoch 10/10, Batch 40/49, Loss: 0.2628
Epoch 10/10, Train Loss: 0.2080, Valid Loss: 0.2635
Model saved!
Accuracy: 0.9007
Precision: 0.8968
Recall: 0.9007
F1-score: 0.8973
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3484
Epoch 1/10, Batch 20/49, Loss: 1.0164
Epoch 1/10, Batch 30/49, Loss: 0.7764
Epoch 1/10, Batch 40/49, Loss: 0.9128
Epoch 1/10, Train Loss: 1.0021, Valid Loss: 0.6078
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7226
Epoch 2/10, Batch 20/49, Loss: 0.4338
Epoch 2/10, Batch 30/49, Loss: 0.5311
Epoch 2/10, Batch 40/49, Loss: 0.4831
Epoch 2/10, Train Loss: 0.5477, Valid Loss: 0.4299
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5682
Epoch 3/10, Batch 20/49, Loss: 0.4419
Epoch 3/10, Batch 30/49, Loss: 0.4529
Epoch 3/10, Batch 40/49, Loss: 0.3127
Epoch 3/10, Train Loss: 0.4284, Valid Loss: 0.3585
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2517
Epoch 4/10, Batch 20/49, Loss: 0.6117
Epoch 4/10, Batch 30/49, Loss: 0.2833
Epoch 4/10, Batch 40/49, Loss: 0.3179
Epoch 4/10, Train Loss: 0.3623, Valid Loss: 0.3149
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4008
Epoch 5/10, Batch 20/49, Loss: 0.1919
Epoch 5/10, Batch 30/49, Loss: 0.2963
Epoch 5/10, Batch 40/49, Loss: 0.2917
Epoch 5/10, Train Loss: 0.3071, Valid Loss: 0.2892
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1840
Epoch 6/10, Batch 20/49, Loss: 0.3222
Epoch 6/10, Batch 30/49, Loss: 0.3637
Epoch 6/10, Batch 40/49, Loss: 0.1944
Epoch 6/10, Train Loss: 0.2968, Valid Loss: 0.2767
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2874
Epoch 7/10, Batch 20/49, Loss: 0.1977
Epoch 7/10, Batch 30/49, Loss: 0.3272
Epoch 7/10, Batch 40/49, Loss: 0.1904
Epoch 7/10, Train Loss: 0.2762, Valid Loss: 0.2830
Epoch 8/10, Batch 10/49, Loss: 0.2242
Epoch 8/10, Batch 20/49, Loss: 0.1837
Epoch 8/10, Batch 30/49, Loss: 0.2296
Epoch 8/10, Batch 40/49, Loss: 0.2798
Epoch 8/10, Train Loss: 0.2655, Valid Loss: 0.2576
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1770
Epoch 9/10, Batch 20/49, Loss: 0.2201
Epoch 9/10, Batch 30/49, Loss: 0.4695
Epoch 9/10, Batch 40/49, Loss: 0.2238
Epoch 9/10, Train Loss: 0.2488, Valid Loss: 0.2484
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2585
Epoch 10/10, Batch 20/49, Loss: 0.1915
Epoch 10/10, Batch 30/49, Loss: 0.2041
Epoch 10/10, Batch 40/49, Loss: 0.1628
Epoch 10/10, Train Loss: 0.2257, Valid Loss: 0.2462
Model saved!
Accuracy: 0.8972
Precision: 0.8926
Recall: 0.8972
F1-score: 0.8930
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3186
Epoch 1/10, Batch 20/49, Loss: 1.0391
Epoch 1/10, Batch 30/49, Loss: 0.8812
Epoch 1/10, Batch 40/49, Loss: 0.7410
Epoch 1/10, Train Loss: 1.0090, Valid Loss: 0.6254
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6777
Epoch 2/10, Batch 20/49, Loss: 0.4705
Epoch 2/10, Batch 30/49, Loss: 0.4779
Epoch 2/10, Batch 40/49, Loss: 0.6021
Epoch 2/10, Train Loss: 0.5570, Valid Loss: 0.4572
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4472
Epoch 3/10, Batch 20/49, Loss: 0.4855
Epoch 3/10, Batch 30/49, Loss: 0.4146
Epoch 3/10, Batch 40/49, Loss: 0.3313
Epoch 3/10, Train Loss: 0.4454, Valid Loss: 0.3747
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2351
Epoch 4/10, Batch 20/49, Loss: 0.5805
Epoch 4/10, Batch 30/49, Loss: 0.3647
Epoch 4/10, Batch 40/49, Loss: 0.2281
Epoch 4/10, Train Loss: 0.3757, Valid Loss: 0.3418
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2907
Epoch 5/10, Batch 20/49, Loss: 0.2399
Epoch 5/10, Batch 30/49, Loss: 0.2523
Epoch 5/10, Batch 40/49, Loss: 0.1666
Epoch 5/10, Train Loss: 0.3244, Valid Loss: 0.3105
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1815
Epoch 6/10, Batch 20/49, Loss: 0.4525
Epoch 6/10, Batch 30/49, Loss: 0.2791
Epoch 6/10, Batch 40/49, Loss: 0.2472
Epoch 6/10, Train Loss: 0.2951, Valid Loss: 0.2966
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3286
Epoch 7/10, Batch 20/49, Loss: 0.1822
Epoch 7/10, Batch 30/49, Loss: 0.3891
Epoch 7/10, Batch 40/49, Loss: 0.3091
Epoch 7/10, Train Loss: 0.2729, Valid Loss: 0.2983
Epoch 8/10, Batch 10/49, Loss: 0.2005
Epoch 8/10, Batch 20/49, Loss: 0.3991
Epoch 8/10, Batch 30/49, Loss: 0.1833
Epoch 8/10, Batch 40/49, Loss: 0.1946
Epoch 8/10, Train Loss: 0.2539, Valid Loss: 0.2817
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1567
Epoch 9/10, Batch 20/49, Loss: 0.3389
Epoch 9/10, Batch 30/49, Loss: 0.4509
Epoch 9/10, Batch 40/49, Loss: 0.1954
Epoch 9/10, Train Loss: 0.2435, Valid Loss: 0.2749
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2413
Epoch 10/10, Batch 20/49, Loss: 0.1140
Epoch 10/10, Batch 30/49, Loss: 0.3491
Epoch 10/10, Batch 40/49, Loss: 0.1856
Epoch 10/10, Train Loss: 0.2263, Valid Loss: 0.2801
Accuracy: 0.8995
Precision: 0.8945
Recall: 0.8995
F1-score: 0.8960
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2386
Epoch 1/10, Batch 20/49, Loss: 1.0157
Epoch 1/10, Batch 30/49, Loss: 0.9037
Epoch 1/10, Batch 40/49, Loss: 0.7502
Epoch 1/10, Train Loss: 1.0094, Valid Loss: 0.6866
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6644
Epoch 2/10, Batch 20/49, Loss: 0.4394
Epoch 2/10, Batch 30/49, Loss: 0.4316
Epoch 2/10, Batch 40/49, Loss: 0.5196
Epoch 2/10, Train Loss: 0.5358, Valid Loss: 0.5108
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4971
Epoch 3/10, Batch 20/49, Loss: 0.3722
Epoch 3/10, Batch 30/49, Loss: 0.2875
Epoch 3/10, Batch 40/49, Loss: 0.4387
Epoch 3/10, Train Loss: 0.4216, Valid Loss: 0.4320
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2898
Epoch 4/10, Batch 20/49, Loss: 0.4280
Epoch 4/10, Batch 30/49, Loss: 0.2594
Epoch 4/10, Batch 40/49, Loss: 0.2592
Epoch 4/10, Train Loss: 0.3575, Valid Loss: 0.3921
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2932
Epoch 5/10, Batch 20/49, Loss: 0.2454
Epoch 5/10, Batch 30/49, Loss: 0.2403
Epoch 5/10, Batch 40/49, Loss: 0.3510
Epoch 5/10, Train Loss: 0.3115, Valid Loss: 0.3728
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2546
Epoch 6/10, Batch 20/49, Loss: 0.2846
Epoch 6/10, Batch 30/49, Loss: 0.3776
Epoch 6/10, Batch 40/49, Loss: 0.2480
Epoch 6/10, Train Loss: 0.2821, Valid Loss: 0.3583
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2695
Epoch 7/10, Batch 20/49, Loss: 0.2296
Epoch 7/10, Batch 30/49, Loss: 0.4034
Epoch 7/10, Batch 40/49, Loss: 0.1109
Epoch 7/10, Train Loss: 0.2593, Valid Loss: 0.3368
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2521
Epoch 8/10, Batch 20/49, Loss: 0.1622
Epoch 8/10, Batch 30/49, Loss: 0.3432
Epoch 8/10, Batch 40/49, Loss: 0.1874
Epoch 8/10, Train Loss: 0.2452, Valid Loss: 0.3232
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1578
Epoch 9/10, Batch 20/49, Loss: 0.2544
Epoch 9/10, Batch 30/49, Loss: 0.3851
Epoch 9/10, Batch 40/49, Loss: 0.2384
Epoch 9/10, Train Loss: 0.2346, Valid Loss: 0.3167
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1051
Epoch 10/10, Batch 20/49, Loss: 0.1466
Epoch 10/10, Batch 30/49, Loss: 0.3387
Epoch 10/10, Batch 40/49, Loss: 0.2346
Epoch 10/10, Train Loss: 0.2178, Valid Loss: 0.3025
Model saved!
Accuracy: 0.8984
Precision: 0.8934
Recall: 0.8984
F1-score: 0.8928
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3280
Epoch 1/10, Batch 20/49, Loss: 1.0877
Epoch 1/10, Batch 30/49, Loss: 0.7574
Epoch 1/10, Batch 40/49, Loss: 0.6935
Epoch 1/10, Train Loss: 1.0065, Valid Loss: 0.6688
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6381
Epoch 2/10, Batch 20/49, Loss: 0.3796
Epoch 2/10, Batch 30/49, Loss: 0.4858
Epoch 2/10, Batch 40/49, Loss: 0.6038
Epoch 2/10, Train Loss: 0.5473, Valid Loss: 0.5161
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5216
Epoch 3/10, Batch 20/49, Loss: 0.5520
Epoch 3/10, Batch 30/49, Loss: 0.2247
Epoch 3/10, Batch 40/49, Loss: 0.2879
Epoch 3/10, Train Loss: 0.4212, Valid Loss: 0.4373
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2387
Epoch 4/10, Batch 20/49, Loss: 0.3086
Epoch 4/10, Batch 30/49, Loss: 0.2816
Epoch 4/10, Batch 40/49, Loss: 0.3637
Epoch 4/10, Train Loss: 0.3680, Valid Loss: 0.3743
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2629
Epoch 5/10, Batch 20/49, Loss: 0.2398
Epoch 5/10, Batch 30/49, Loss: 0.2306
Epoch 5/10, Batch 40/49, Loss: 0.1535
Epoch 5/10, Train Loss: 0.3060, Valid Loss: 0.3686
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2156
Epoch 6/10, Batch 20/49, Loss: 0.3024
Epoch 6/10, Batch 30/49, Loss: 0.2795
Epoch 6/10, Batch 40/49, Loss: 0.2351
Epoch 6/10, Train Loss: 0.2824, Valid Loss: 0.3609
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2181
Epoch 7/10, Batch 20/49, Loss: 0.2403
Epoch 7/10, Batch 30/49, Loss: 0.2138
Epoch 7/10, Batch 40/49, Loss: 0.2952
Epoch 7/10, Train Loss: 0.2578, Valid Loss: 0.3404
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2926
Epoch 8/10, Batch 20/49, Loss: 0.2993
Epoch 8/10, Batch 30/49, Loss: 0.2666
Epoch 8/10, Batch 40/49, Loss: 0.1404
Epoch 8/10, Train Loss: 0.2430, Valid Loss: 0.3296
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1621
Epoch 9/10, Batch 20/49, Loss: 0.2560
Epoch 9/10, Batch 30/49, Loss: 0.4772
Epoch 9/10, Batch 40/49, Loss: 0.1640
Epoch 9/10, Train Loss: 0.2335, Valid Loss: 0.3171
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2103
Epoch 10/10, Batch 20/49, Loss: 0.2058
Epoch 10/10, Batch 30/49, Loss: 0.1459
Epoch 10/10, Batch 40/49, Loss: 0.1359
Epoch 10/10, Train Loss: 0.2043, Valid Loss: 0.2949
Model saved!
Accuracy: 0.9019
Precision: 0.8974
Recall: 0.9019
F1-score: 0.8987
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2811
Epoch 1/10, Batch 20/49, Loss: 1.0952
Epoch 1/10, Batch 30/49, Loss: 0.7555
Epoch 1/10, Batch 40/49, Loss: 0.8015
Epoch 1/10, Train Loss: 0.9788, Valid Loss: 0.5951
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7030
Epoch 2/10, Batch 20/49, Loss: 0.4562
Epoch 2/10, Batch 30/49, Loss: 0.5253
Epoch 2/10, Batch 40/49, Loss: 0.4992
Epoch 2/10, Train Loss: 0.5181, Valid Loss: 0.4144
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3892
Epoch 3/10, Batch 20/49, Loss: 0.4383
Epoch 3/10, Batch 30/49, Loss: 0.3710
Epoch 3/10, Batch 40/49, Loss: 0.4090
Epoch 3/10, Train Loss: 0.4024, Valid Loss: 0.3474
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3733
Epoch 4/10, Batch 20/49, Loss: 0.4199
Epoch 4/10, Batch 30/49, Loss: 0.1995
Epoch 4/10, Batch 40/49, Loss: 0.3004
Epoch 4/10, Train Loss: 0.3444, Valid Loss: 0.3018
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2623
Epoch 5/10, Batch 20/49, Loss: 0.2613
Epoch 5/10, Batch 30/49, Loss: 0.2622
Epoch 5/10, Batch 40/49, Loss: 0.2483
Epoch 5/10, Train Loss: 0.3017, Valid Loss: 0.2727
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2210
Epoch 6/10, Batch 20/49, Loss: 0.3750
Epoch 6/10, Batch 30/49, Loss: 0.1890
Epoch 6/10, Batch 40/49, Loss: 0.2746
Epoch 6/10, Train Loss: 0.2746, Valid Loss: 0.2675
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1947
Epoch 7/10, Batch 20/49, Loss: 0.1680
Epoch 7/10, Batch 30/49, Loss: 0.2825
Epoch 7/10, Batch 40/49, Loss: 0.1674
Epoch 7/10, Train Loss: 0.2491, Valid Loss: 0.2614
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2255
Epoch 8/10, Batch 20/49, Loss: 0.3529
Epoch 8/10, Batch 30/49, Loss: 0.2068
Epoch 8/10, Batch 40/49, Loss: 0.2951
Epoch 8/10, Train Loss: 0.2544, Valid Loss: 0.2507
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1288
Epoch 9/10, Batch 20/49, Loss: 0.1611
Epoch 9/10, Batch 30/49, Loss: 0.4060
Epoch 9/10, Batch 40/49, Loss: 0.1800
Epoch 9/10, Train Loss: 0.2256, Valid Loss: 0.2368
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1875
Epoch 10/10, Batch 20/49, Loss: 0.1242
Epoch 10/10, Batch 30/49, Loss: 0.2663
Epoch 10/10, Batch 40/49, Loss: 0.2826
Epoch 10/10, Train Loss: 0.2149, Valid Loss: 0.2348
Model saved!
Accuracy: 0.9136
Precision: 0.9126
Recall: 0.9136
F1-score: 0.9100
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2294
Epoch 1/10, Batch 20/49, Loss: 1.0874
Epoch 1/10, Batch 30/49, Loss: 0.8689
Epoch 1/10, Batch 40/49, Loss: 0.6635
Epoch 1/10, Train Loss: 0.9899, Valid Loss: 0.6683
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6942
Epoch 2/10, Batch 20/49, Loss: 0.3495
Epoch 2/10, Batch 30/49, Loss: 0.4503
Epoch 2/10, Batch 40/49, Loss: 0.5789
Epoch 2/10, Train Loss: 0.5428, Valid Loss: 0.4944
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4397
Epoch 3/10, Batch 20/49, Loss: 0.4180
Epoch 3/10, Batch 30/49, Loss: 0.3534
Epoch 3/10, Batch 40/49, Loss: 0.5086
Epoch 3/10, Train Loss: 0.4151, Valid Loss: 0.4196
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2685
Epoch 4/10, Batch 20/49, Loss: 0.2918
Epoch 4/10, Batch 30/49, Loss: 0.1865
Epoch 4/10, Batch 40/49, Loss: 0.2951
Epoch 4/10, Train Loss: 0.3756, Valid Loss: 0.3875
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3464
Epoch 5/10, Batch 20/49, Loss: 0.2864
Epoch 5/10, Batch 30/49, Loss: 0.3072
Epoch 5/10, Batch 40/49, Loss: 0.3837
Epoch 5/10, Train Loss: 0.3102, Valid Loss: 0.3640
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2391
Epoch 6/10, Batch 20/49, Loss: 0.2951
Epoch 6/10, Batch 30/49, Loss: 0.3247
Epoch 6/10, Batch 40/49, Loss: 0.2273
Epoch 6/10, Train Loss: 0.2916, Valid Loss: 0.3494
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1631
Epoch 7/10, Batch 20/49, Loss: 0.2400
Epoch 7/10, Batch 30/49, Loss: 0.4791
Epoch 7/10, Batch 40/49, Loss: 0.1872
Epoch 7/10, Train Loss: 0.2739, Valid Loss: 0.3466
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1445
Epoch 8/10, Batch 20/49, Loss: 0.2872
Epoch 8/10, Batch 30/49, Loss: 0.2217
Epoch 8/10, Batch 40/49, Loss: 0.2175
Epoch 8/10, Train Loss: 0.2564, Valid Loss: 0.3307
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2066
Epoch 9/10, Batch 20/49, Loss: 0.2390
Epoch 9/10, Batch 30/49, Loss: 0.5356
Epoch 9/10, Batch 40/49, Loss: 0.1316
Epoch 9/10, Train Loss: 0.2402, Valid Loss: 0.3110
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2741
Epoch 10/10, Batch 20/49, Loss: 0.1801
Epoch 10/10, Batch 30/49, Loss: 0.1942
Epoch 10/10, Batch 40/49, Loss: 0.2179
Epoch 10/10, Train Loss: 0.2114, Valid Loss: 0.3145
Accuracy: 0.9065
Precision: 0.9032
Recall: 0.9065
F1-score: 0.9044
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3204
Epoch 1/10, Batch 20/49, Loss: 0.9986
Epoch 1/10, Batch 30/49, Loss: 0.7103
Epoch 1/10, Batch 40/49, Loss: 0.7335
Epoch 1/10, Train Loss: 0.9897, Valid Loss: 0.6834
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6100
Epoch 2/10, Batch 20/49, Loss: 0.3981
Epoch 2/10, Batch 30/49, Loss: 0.5530
Epoch 2/10, Batch 40/49, Loss: 0.6275
Epoch 2/10, Train Loss: 0.5346, Valid Loss: 0.5470
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3767
Epoch 3/10, Batch 20/49, Loss: 0.3818
Epoch 3/10, Batch 30/49, Loss: 0.4452
Epoch 3/10, Batch 40/49, Loss: 0.2493
Epoch 3/10, Train Loss: 0.4119, Valid Loss: 0.4834
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2537
Epoch 4/10, Batch 20/49, Loss: 0.4605
Epoch 4/10, Batch 30/49, Loss: 0.2918
Epoch 4/10, Batch 40/49, Loss: 0.3453
Epoch 4/10, Train Loss: 0.3582, Valid Loss: 0.4244
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3298
Epoch 5/10, Batch 20/49, Loss: 0.2298
Epoch 5/10, Batch 30/49, Loss: 0.2301
Epoch 5/10, Batch 40/49, Loss: 0.2156
Epoch 5/10, Train Loss: 0.3126, Valid Loss: 0.4222
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2430
Epoch 6/10, Batch 20/49, Loss: 0.4263
Epoch 6/10, Batch 30/49, Loss: 0.4028
Epoch 6/10, Batch 40/49, Loss: 0.3411
Epoch 6/10, Train Loss: 0.2838, Valid Loss: 0.3996
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2867
Epoch 7/10, Batch 20/49, Loss: 0.2027
Epoch 7/10, Batch 30/49, Loss: 0.2728
Epoch 7/10, Batch 40/49, Loss: 0.1006
Epoch 7/10, Train Loss: 0.2547, Valid Loss: 0.4328
Epoch 8/10, Batch 10/49, Loss: 0.1640
Epoch 8/10, Batch 20/49, Loss: 0.2789
Epoch 8/10, Batch 30/49, Loss: 0.3387
Epoch 8/10, Batch 40/49, Loss: 0.1774
Epoch 8/10, Train Loss: 0.2589, Valid Loss: 0.3977
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2276
Epoch 9/10, Batch 20/49, Loss: 0.3316
Epoch 9/10, Batch 30/49, Loss: 0.4711
Epoch 9/10, Batch 40/49, Loss: 0.1520
Epoch 9/10, Train Loss: 0.2313, Valid Loss: 0.3855
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2117
Epoch 10/10, Batch 20/49, Loss: 0.1725
Epoch 10/10, Batch 30/49, Loss: 0.4540
Epoch 10/10, Batch 40/49, Loss: 0.1810
Epoch 10/10, Train Loss: 0.2158, Valid Loss: 0.3523
Model saved!
Accuracy: 0.9019
Precision: 0.9001
Recall: 0.9019
F1-score: 0.8964
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2877
Epoch 1/10, Batch 20/49, Loss: 1.0053
Epoch 1/10, Batch 30/49, Loss: 0.8522
Epoch 1/10, Batch 40/49, Loss: 0.8327
Epoch 1/10, Train Loss: 1.0095, Valid Loss: 0.6366
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6521
Epoch 2/10, Batch 20/49, Loss: 0.4946
Epoch 2/10, Batch 30/49, Loss: 0.6044
Epoch 2/10, Batch 40/49, Loss: 0.5670
Epoch 2/10, Train Loss: 0.5365, Valid Loss: 0.4482
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4835
Epoch 3/10, Batch 20/49, Loss: 0.4722
Epoch 3/10, Batch 30/49, Loss: 0.3420
Epoch 3/10, Batch 40/49, Loss: 0.3858
Epoch 3/10, Train Loss: 0.4198, Valid Loss: 0.3824
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3491
Epoch 4/10, Batch 20/49, Loss: 0.3729
Epoch 4/10, Batch 30/49, Loss: 0.2813
Epoch 4/10, Batch 40/49, Loss: 0.3175
Epoch 4/10, Train Loss: 0.3553, Valid Loss: 0.3177
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2271
Epoch 5/10, Batch 20/49, Loss: 0.3709
Epoch 5/10, Batch 30/49, Loss: 0.3579
Epoch 5/10, Batch 40/49, Loss: 0.2335
Epoch 5/10, Train Loss: 0.2996, Valid Loss: 0.2998
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2023
Epoch 6/10, Batch 20/49, Loss: 0.1741
Epoch 6/10, Batch 30/49, Loss: 0.3122
Epoch 6/10, Batch 40/49, Loss: 0.2268
Epoch 6/10, Train Loss: 0.2856, Valid Loss: 0.2928
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2681
Epoch 7/10, Batch 20/49, Loss: 0.2430
Epoch 7/10, Batch 30/49, Loss: 0.3631
Epoch 7/10, Batch 40/49, Loss: 0.1329
Epoch 7/10, Train Loss: 0.2818, Valid Loss: 0.2802
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1714
Epoch 8/10, Batch 20/49, Loss: 0.2729
Epoch 8/10, Batch 30/49, Loss: 0.3050
Epoch 8/10, Batch 40/49, Loss: 0.1919
Epoch 8/10, Train Loss: 0.2473, Valid Loss: 0.2529
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2277
Epoch 9/10, Batch 20/49, Loss: 0.1764
Epoch 9/10, Batch 30/49, Loss: 0.2370
Epoch 9/10, Batch 40/49, Loss: 0.2018
Epoch 9/10, Train Loss: 0.2299, Valid Loss: 0.2408
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1897
Epoch 10/10, Batch 20/49, Loss: 0.1953
Epoch 10/10, Batch 30/49, Loss: 0.3442
Epoch 10/10, Batch 40/49, Loss: 0.2497
Epoch 10/10, Train Loss: 0.2064, Valid Loss: 0.2329
Model saved!
Accuracy: 0.9030
Precision: 0.9003
Recall: 0.9030
F1-score: 0.8992
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3318
Epoch 1/10, Batch 20/49, Loss: 1.0290
Epoch 1/10, Batch 30/49, Loss: 0.8442
Epoch 1/10, Batch 40/49, Loss: 0.7028
Epoch 1/10, Train Loss: 1.0024, Valid Loss: 0.6572
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5990
Epoch 2/10, Batch 20/49, Loss: 0.4843
Epoch 2/10, Batch 30/49, Loss: 0.5939
Epoch 2/10, Batch 40/49, Loss: 0.3819
Epoch 2/10, Train Loss: 0.5362, Valid Loss: 0.4770
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3925
Epoch 3/10, Batch 20/49, Loss: 0.5036
Epoch 3/10, Batch 30/49, Loss: 0.3262
Epoch 3/10, Batch 40/49, Loss: 0.3351
Epoch 3/10, Train Loss: 0.4223, Valid Loss: 0.4085
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3035
Epoch 4/10, Batch 20/49, Loss: 0.3584
Epoch 4/10, Batch 30/49, Loss: 0.2949
Epoch 4/10, Batch 40/49, Loss: 0.3140
Epoch 4/10, Train Loss: 0.3650, Valid Loss: 0.3606
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2176
Epoch 5/10, Batch 20/49, Loss: 0.2271
Epoch 5/10, Batch 30/49, Loss: 0.4133
Epoch 5/10, Batch 40/49, Loss: 0.2636
Epoch 5/10, Train Loss: 0.3183, Valid Loss: 0.3371
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1993
Epoch 6/10, Batch 20/49, Loss: 0.3755
Epoch 6/10, Batch 30/49, Loss: 0.3381
Epoch 6/10, Batch 40/49, Loss: 0.3317
Epoch 6/10, Train Loss: 0.2912, Valid Loss: 0.3185
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2819
Epoch 7/10, Batch 20/49, Loss: 0.2209
Epoch 7/10, Batch 30/49, Loss: 0.2238
Epoch 7/10, Batch 40/49, Loss: 0.2208
Epoch 7/10, Train Loss: 0.2662, Valid Loss: 0.3100
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3283
Epoch 8/10, Batch 20/49, Loss: 0.3210
Epoch 8/10, Batch 30/49, Loss: 0.2227
Epoch 8/10, Batch 40/49, Loss: 0.3458
Epoch 8/10, Train Loss: 0.2476, Valid Loss: 0.2925
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1456
Epoch 9/10, Batch 20/49, Loss: 0.1179
Epoch 9/10, Batch 30/49, Loss: 0.4199
Epoch 9/10, Batch 40/49, Loss: 0.1403
Epoch 9/10, Train Loss: 0.2340, Valid Loss: 0.2855
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1785
Epoch 10/10, Batch 20/49, Loss: 0.1439
Epoch 10/10, Batch 30/49, Loss: 0.2134
Epoch 10/10, Batch 40/49, Loss: 0.1945
Epoch 10/10, Train Loss: 0.2272, Valid Loss: 0.2828
Model saved!
Accuracy: 0.9136
Precision: 0.9106
Recall: 0.9136
F1-score: 0.9106
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2881
Epoch 1/10, Batch 20/49, Loss: 1.0450
Epoch 1/10, Batch 30/49, Loss: 0.8112
Epoch 1/10, Batch 40/49, Loss: 0.7060
Epoch 1/10, Train Loss: 0.9975, Valid Loss: 0.6235
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6293
Epoch 2/10, Batch 20/49, Loss: 0.4709
Epoch 2/10, Batch 30/49, Loss: 0.5073
Epoch 2/10, Batch 40/49, Loss: 0.4541
Epoch 2/10, Train Loss: 0.5362, Valid Loss: 0.4453
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4508
Epoch 3/10, Batch 20/49, Loss: 0.3700
Epoch 3/10, Batch 30/49, Loss: 0.3239
Epoch 3/10, Batch 40/49, Loss: 0.3735
Epoch 3/10, Train Loss: 0.4151, Valid Loss: 0.3760
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3713
Epoch 4/10, Batch 20/49, Loss: 0.4536
Epoch 4/10, Batch 30/49, Loss: 0.3265
Epoch 4/10, Batch 40/49, Loss: 0.2446
Epoch 4/10, Train Loss: 0.3497, Valid Loss: 0.3305
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2225
Epoch 5/10, Batch 20/49, Loss: 0.2822
Epoch 5/10, Batch 30/49, Loss: 0.3264
Epoch 5/10, Batch 40/49, Loss: 0.2315
Epoch 5/10, Train Loss: 0.3050, Valid Loss: 0.3024
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3195
Epoch 6/10, Batch 20/49, Loss: 0.2490
Epoch 6/10, Batch 30/49, Loss: 0.3191
Epoch 6/10, Batch 40/49, Loss: 0.3670
Epoch 6/10, Train Loss: 0.2832, Valid Loss: 0.2959
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2902
Epoch 7/10, Batch 20/49, Loss: 0.2257
Epoch 7/10, Batch 30/49, Loss: 0.2942
Epoch 7/10, Batch 40/49, Loss: 0.3176
Epoch 7/10, Train Loss: 0.2644, Valid Loss: 0.2845
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3735
Epoch 8/10, Batch 20/49, Loss: 0.2010
Epoch 8/10, Batch 30/49, Loss: 0.1915
Epoch 8/10, Batch 40/49, Loss: 0.1684
Epoch 8/10, Train Loss: 0.2472, Valid Loss: 0.2678
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1412
Epoch 9/10, Batch 20/49, Loss: 0.2906
Epoch 9/10, Batch 30/49, Loss: 0.4684
Epoch 9/10, Batch 40/49, Loss: 0.1898
Epoch 9/10, Train Loss: 0.2369, Valid Loss: 0.2693
Epoch 10/10, Batch 10/49, Loss: 0.1845
Epoch 10/10, Batch 20/49, Loss: 0.0925
Epoch 10/10, Batch 30/49, Loss: 0.2718
Epoch 10/10, Batch 40/49, Loss: 0.2869
Epoch 10/10, Train Loss: 0.2197, Valid Loss: 0.2717
Accuracy: 0.9030
Precision: 0.8984
Recall: 0.9030
F1-score: 0.8995
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3382
Epoch 1/10, Batch 20/49, Loss: 1.0052
Epoch 1/10, Batch 30/49, Loss: 0.8777
Epoch 1/10, Batch 40/49, Loss: 0.7048
Epoch 1/10, Train Loss: 0.9910, Valid Loss: 0.6670
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6452
Epoch 2/10, Batch 20/49, Loss: 0.5870
Epoch 2/10, Batch 30/49, Loss: 0.6337
Epoch 2/10, Batch 40/49, Loss: 0.5408
Epoch 2/10, Train Loss: 0.5498, Valid Loss: 0.4998
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4886
Epoch 3/10, Batch 20/49, Loss: 0.4854
Epoch 3/10, Batch 30/49, Loss: 0.5446
Epoch 3/10, Batch 40/49, Loss: 0.2793
Epoch 3/10, Train Loss: 0.4280, Valid Loss: 0.4487
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3700
Epoch 4/10, Batch 20/49, Loss: 0.3652
Epoch 4/10, Batch 30/49, Loss: 0.2523
Epoch 4/10, Batch 40/49, Loss: 0.3574
Epoch 4/10, Train Loss: 0.3711, Valid Loss: 0.3795
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3417
Epoch 5/10, Batch 20/49, Loss: 0.1872
Epoch 5/10, Batch 30/49, Loss: 0.2835
Epoch 5/10, Batch 40/49, Loss: 0.1545
Epoch 5/10, Train Loss: 0.3129, Valid Loss: 0.3625
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1897
Epoch 6/10, Batch 20/49, Loss: 0.3180
Epoch 6/10, Batch 30/49, Loss: 0.3889
Epoch 6/10, Batch 40/49, Loss: 0.3653
Epoch 6/10, Train Loss: 0.2958, Valid Loss: 0.3515
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2634
Epoch 7/10, Batch 20/49, Loss: 0.2971
Epoch 7/10, Batch 30/49, Loss: 0.4139
Epoch 7/10, Batch 40/49, Loss: 0.1637
Epoch 7/10, Train Loss: 0.2685, Valid Loss: 0.3492
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3414
Epoch 8/10, Batch 20/49, Loss: 0.1647
Epoch 8/10, Batch 30/49, Loss: 0.1696
Epoch 8/10, Batch 40/49, Loss: 0.2166
Epoch 8/10, Train Loss: 0.2510, Valid Loss: 0.3259
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1498
Epoch 9/10, Batch 20/49, Loss: 0.2739
Epoch 9/10, Batch 30/49, Loss: 0.3847
Epoch 9/10, Batch 40/49, Loss: 0.2990
Epoch 9/10, Train Loss: 0.2444, Valid Loss: 0.3145
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2546
Epoch 10/10, Batch 20/49, Loss: 0.1552
Epoch 10/10, Batch 30/49, Loss: 0.3434
Epoch 10/10, Batch 40/49, Loss: 0.2985
Epoch 10/10, Train Loss: 0.2183, Valid Loss: 0.3062
Model saved!
Accuracy: 0.9065
Precision: 0.9039
Recall: 0.9065
F1-score: 0.9021
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2935
Epoch 1/10, Batch 20/49, Loss: 1.0885
Epoch 1/10, Batch 30/49, Loss: 0.9179
Epoch 1/10, Batch 40/49, Loss: 0.6706
Epoch 1/10, Train Loss: 1.0111, Valid Loss: 0.6518
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6788
Epoch 2/10, Batch 20/49, Loss: 0.5220
Epoch 2/10, Batch 30/49, Loss: 0.4841
Epoch 2/10, Batch 40/49, Loss: 0.5891
Epoch 2/10, Train Loss: 0.5568, Valid Loss: 0.4709
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4580
Epoch 3/10, Batch 20/49, Loss: 0.3431
Epoch 3/10, Batch 30/49, Loss: 0.3051
Epoch 3/10, Batch 40/49, Loss: 0.3551
Epoch 3/10, Train Loss: 0.4466, Valid Loss: 0.3956
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2434
Epoch 4/10, Batch 20/49, Loss: 0.4758
Epoch 4/10, Batch 30/49, Loss: 0.2614
Epoch 4/10, Batch 40/49, Loss: 0.2563
Epoch 4/10, Train Loss: 0.3803, Valid Loss: 0.3420
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3005
Epoch 5/10, Batch 20/49, Loss: 0.2878
Epoch 5/10, Batch 30/49, Loss: 0.2801
Epoch 5/10, Batch 40/49, Loss: 0.2543
Epoch 5/10, Train Loss: 0.3291, Valid Loss: 0.3198
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2636
Epoch 6/10, Batch 20/49, Loss: 0.3627
Epoch 6/10, Batch 30/49, Loss: 0.3029
Epoch 6/10, Batch 40/49, Loss: 0.3074
Epoch 6/10, Train Loss: 0.3042, Valid Loss: 0.3215
Epoch 7/10, Batch 10/49, Loss: 0.4215
Epoch 7/10, Batch 20/49, Loss: 0.2255
Epoch 7/10, Batch 30/49, Loss: 0.4160
Epoch 7/10, Batch 40/49, Loss: 0.1851
Epoch 7/10, Train Loss: 0.2946, Valid Loss: 0.2972
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2897
Epoch 8/10, Batch 20/49, Loss: 0.4371
Epoch 8/10, Batch 30/49, Loss: 0.1808
Epoch 8/10, Batch 40/49, Loss: 0.3864
Epoch 8/10, Train Loss: 0.2876, Valid Loss: 0.2872
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2377
Epoch 9/10, Batch 20/49, Loss: 0.2224
Epoch 9/10, Batch 30/49, Loss: 0.4986
Epoch 9/10, Batch 40/49, Loss: 0.1765
Epoch 9/10, Train Loss: 0.2629, Valid Loss: 0.2693
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2373
Epoch 10/10, Batch 20/49, Loss: 0.0991
Epoch 10/10, Batch 30/49, Loss: 0.2660
Epoch 10/10, Batch 40/49, Loss: 0.2233
Epoch 10/10, Train Loss: 0.2429, Valid Loss: 0.2572
Model saved!
Accuracy: 0.8995
Precision: 0.8972
Recall: 0.8995
F1-score: 0.8950
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3046
Epoch 1/10, Batch 20/49, Loss: 1.1184
Epoch 1/10, Batch 30/49, Loss: 0.8468
Epoch 1/10, Batch 40/49, Loss: 0.7154
Epoch 1/10, Train Loss: 0.9925, Valid Loss: 0.6523
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6028
Epoch 2/10, Batch 20/49, Loss: 0.4905
Epoch 2/10, Batch 30/49, Loss: 0.5565
Epoch 2/10, Batch 40/49, Loss: 0.6236
Epoch 2/10, Train Loss: 0.5256, Valid Loss: 0.4743
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3920
Epoch 3/10, Batch 20/49, Loss: 0.4019
Epoch 3/10, Batch 30/49, Loss: 0.4649
Epoch 3/10, Batch 40/49, Loss: 0.3986
Epoch 3/10, Train Loss: 0.4075, Valid Loss: 0.4109
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3387
Epoch 4/10, Batch 20/49, Loss: 0.4808
Epoch 4/10, Batch 30/49, Loss: 0.2571
Epoch 4/10, Batch 40/49, Loss: 0.2768
Epoch 4/10, Train Loss: 0.3578, Valid Loss: 0.3644
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2448
Epoch 5/10, Batch 20/49, Loss: 0.1770
Epoch 5/10, Batch 30/49, Loss: 0.2318
Epoch 5/10, Batch 40/49, Loss: 0.1950
Epoch 5/10, Train Loss: 0.3003, Valid Loss: 0.3443
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2478
Epoch 6/10, Batch 20/49, Loss: 0.3096
Epoch 6/10, Batch 30/49, Loss: 0.2476
Epoch 6/10, Batch 40/49, Loss: 0.2055
Epoch 6/10, Train Loss: 0.2776, Valid Loss: 0.3445
Epoch 7/10, Batch 10/49, Loss: 0.1031
Epoch 7/10, Batch 20/49, Loss: 0.1785
Epoch 7/10, Batch 30/49, Loss: 0.3469
Epoch 7/10, Batch 40/49, Loss: 0.2217
Epoch 7/10, Train Loss: 0.2540, Valid Loss: 0.3431
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2514
Epoch 8/10, Batch 20/49, Loss: 0.2302
Epoch 8/10, Batch 30/49, Loss: 0.2576
Epoch 8/10, Batch 40/49, Loss: 0.1946
Epoch 8/10, Train Loss: 0.2471, Valid Loss: 0.3367
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1763
Epoch 9/10, Batch 20/49, Loss: 0.1788
Epoch 9/10, Batch 30/49, Loss: 0.4633
Epoch 9/10, Batch 40/49, Loss: 0.1870
Epoch 9/10, Train Loss: 0.2282, Valid Loss: 0.3029
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1838
Epoch 10/10, Batch 20/49, Loss: 0.1318
Epoch 10/10, Batch 30/49, Loss: 0.1794
Epoch 10/10, Batch 40/49, Loss: 0.1188
Epoch 10/10, Train Loss: 0.2047, Valid Loss: 0.2996
Model saved!
Accuracy: 0.9054
Precision: 0.9010
Recall: 0.9054
F1-score: 0.9011
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2728
Epoch 1/10, Batch 20/49, Loss: 1.0777
Epoch 1/10, Batch 30/49, Loss: 0.8434
Epoch 1/10, Batch 40/49, Loss: 0.7312
Epoch 1/10, Train Loss: 1.0055, Valid Loss: 0.6762
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5910
Epoch 2/10, Batch 20/49, Loss: 0.5146
Epoch 2/10, Batch 30/49, Loss: 0.5364
Epoch 2/10, Batch 40/49, Loss: 0.5663
Epoch 2/10, Train Loss: 0.5385, Valid Loss: 0.5182
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4083
Epoch 3/10, Batch 20/49, Loss: 0.4356
Epoch 3/10, Batch 30/49, Loss: 0.3929
Epoch 3/10, Batch 40/49, Loss: 0.2862
Epoch 3/10, Train Loss: 0.4277, Valid Loss: 0.4703
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3053
Epoch 4/10, Batch 20/49, Loss: 0.2814
Epoch 4/10, Batch 30/49, Loss: 0.2813
Epoch 4/10, Batch 40/49, Loss: 0.3105
Epoch 4/10, Train Loss: 0.3565, Valid Loss: 0.4279
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4036
Epoch 5/10, Batch 20/49, Loss: 0.2543
Epoch 5/10, Batch 30/49, Loss: 0.2186
Epoch 5/10, Batch 40/49, Loss: 0.3233
Epoch 5/10, Train Loss: 0.3087, Valid Loss: 0.4278
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1714
Epoch 6/10, Batch 20/49, Loss: 0.2643
Epoch 6/10, Batch 30/49, Loss: 0.2900
Epoch 6/10, Batch 40/49, Loss: 0.3435
Epoch 6/10, Train Loss: 0.2912, Valid Loss: 0.4198
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3257
Epoch 7/10, Batch 20/49, Loss: 0.2199
Epoch 7/10, Batch 30/49, Loss: 0.3434
Epoch 7/10, Batch 40/49, Loss: 0.1738
Epoch 7/10, Train Loss: 0.2669, Valid Loss: 0.4224
Epoch 8/10, Batch 10/49, Loss: 0.2215
Epoch 8/10, Batch 20/49, Loss: 0.2485
Epoch 8/10, Batch 30/49, Loss: 0.2514
Epoch 8/10, Batch 40/49, Loss: 0.2571
Epoch 8/10, Train Loss: 0.2556, Valid Loss: 0.4155
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2532
Epoch 9/10, Batch 20/49, Loss: 0.2207
Epoch 9/10, Batch 30/49, Loss: 0.3552
Epoch 9/10, Batch 40/49, Loss: 0.1916
Epoch 9/10, Train Loss: 0.2335, Valid Loss: 0.4210
Epoch 10/10, Batch 10/49, Loss: 0.2012
Epoch 10/10, Batch 20/49, Loss: 0.1448
Epoch 10/10, Batch 30/49, Loss: 0.2725
Epoch 10/10, Batch 40/49, Loss: 0.1916
Epoch 10/10, Train Loss: 0.2073, Valid Loss: 0.4052
Model saved!
Accuracy: 0.9054
Precision: 0.9015
Recall: 0.9054
F1-score: 0.9008
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2928
Epoch 1/10, Batch 20/49, Loss: 0.9245
Epoch 1/10, Batch 30/49, Loss: 0.8838
Epoch 1/10, Batch 40/49, Loss: 0.7441
Epoch 1/10, Train Loss: 0.9920, Valid Loss: 0.6568
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6028
Epoch 2/10, Batch 20/49, Loss: 0.4820
Epoch 2/10, Batch 30/49, Loss: 0.6823
Epoch 2/10, Batch 40/49, Loss: 0.5098
Epoch 2/10, Train Loss: 0.5330, Valid Loss: 0.4552
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3834
Epoch 3/10, Batch 20/49, Loss: 0.4346
Epoch 3/10, Batch 30/49, Loss: 0.3297
Epoch 3/10, Batch 40/49, Loss: 0.3536
Epoch 3/10, Train Loss: 0.4133, Valid Loss: 0.3944
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2820
Epoch 4/10, Batch 20/49, Loss: 0.4250
Epoch 4/10, Batch 30/49, Loss: 0.1718
Epoch 4/10, Batch 40/49, Loss: 0.3444
Epoch 4/10, Train Loss: 0.3503, Valid Loss: 0.3394
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2556
Epoch 5/10, Batch 20/49, Loss: 0.1819
Epoch 5/10, Batch 30/49, Loss: 0.2629
Epoch 5/10, Batch 40/49, Loss: 0.2418
Epoch 5/10, Train Loss: 0.3081, Valid Loss: 0.3136
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2202
Epoch 6/10, Batch 20/49, Loss: 0.2640
Epoch 6/10, Batch 30/49, Loss: 0.2771
Epoch 6/10, Batch 40/49, Loss: 0.2425
Epoch 6/10, Train Loss: 0.2777, Valid Loss: 0.2992
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3025
Epoch 7/10, Batch 20/49, Loss: 0.2346
Epoch 7/10, Batch 30/49, Loss: 0.3068
Epoch 7/10, Batch 40/49, Loss: 0.2512
Epoch 7/10, Train Loss: 0.2675, Valid Loss: 0.2936
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2283
Epoch 8/10, Batch 20/49, Loss: 0.2805
Epoch 8/10, Batch 30/49, Loss: 0.2695
Epoch 8/10, Batch 40/49, Loss: 0.2131
Epoch 8/10, Train Loss: 0.2538, Valid Loss: 0.2795
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1450
Epoch 9/10, Batch 20/49, Loss: 0.2128
Epoch 9/10, Batch 30/49, Loss: 0.3110
Epoch 9/10, Batch 40/49, Loss: 0.3154
Epoch 9/10, Train Loss: 0.2407, Valid Loss: 0.2636
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2019
Epoch 10/10, Batch 20/49, Loss: 0.2132
Epoch 10/10, Batch 30/49, Loss: 0.1733
Epoch 10/10, Batch 40/49, Loss: 0.2126
Epoch 10/10, Train Loss: 0.2160, Valid Loss: 0.2502
Model saved!
Accuracy: 0.9089
Precision: 0.9062
Recall: 0.9089
F1-score: 0.9055
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3447
Epoch 1/10, Batch 20/49, Loss: 1.0213
Epoch 1/10, Batch 30/49, Loss: 0.7898
Epoch 1/10, Batch 40/49, Loss: 0.8714
Epoch 1/10, Train Loss: 0.9979, Valid Loss: 0.6426
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5958
Epoch 2/10, Batch 20/49, Loss: 0.3811
Epoch 2/10, Batch 30/49, Loss: 0.6062
Epoch 2/10, Batch 40/49, Loss: 0.3867
Epoch 2/10, Train Loss: 0.5451, Valid Loss: 0.4640
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4654
Epoch 3/10, Batch 20/49, Loss: 0.3591
Epoch 3/10, Batch 30/49, Loss: 0.3643
Epoch 3/10, Batch 40/49, Loss: 0.2347
Epoch 3/10, Train Loss: 0.4286, Valid Loss: 0.3950
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2642
Epoch 4/10, Batch 20/49, Loss: 0.4052
Epoch 4/10, Batch 30/49, Loss: 0.2483
Epoch 4/10, Batch 40/49, Loss: 0.3744
Epoch 4/10, Train Loss: 0.3618, Valid Loss: 0.3427
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3786
Epoch 5/10, Batch 20/49, Loss: 0.3359
Epoch 5/10, Batch 30/49, Loss: 0.2269
Epoch 5/10, Batch 40/49, Loss: 0.2442
Epoch 5/10, Train Loss: 0.3120, Valid Loss: 0.3307
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3487
Epoch 6/10, Batch 20/49, Loss: 0.3854
Epoch 6/10, Batch 30/49, Loss: 0.3349
Epoch 6/10, Batch 40/49, Loss: 0.2271
Epoch 6/10, Train Loss: 0.2908, Valid Loss: 0.3077
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2765
Epoch 7/10, Batch 20/49, Loss: 0.1722
Epoch 7/10, Batch 30/49, Loss: 0.6110
Epoch 7/10, Batch 40/49, Loss: 0.1583
Epoch 7/10, Train Loss: 0.2641, Valid Loss: 0.2980
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2051
Epoch 8/10, Batch 20/49, Loss: 0.2342
Epoch 8/10, Batch 30/49, Loss: 0.2744
Epoch 8/10, Batch 40/49, Loss: 0.1766
Epoch 8/10, Train Loss: 0.2401, Valid Loss: 0.2952
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2202
Epoch 9/10, Batch 20/49, Loss: 0.1826
Epoch 9/10, Batch 30/49, Loss: 0.4092
Epoch 9/10, Batch 40/49, Loss: 0.1432
Epoch 9/10, Train Loss: 0.2335, Valid Loss: 0.2831
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2246
Epoch 10/10, Batch 20/49, Loss: 0.1619
Epoch 10/10, Batch 30/49, Loss: 0.2343
Epoch 10/10, Batch 40/49, Loss: 0.3004
Epoch 10/10, Train Loss: 0.2197, Valid Loss: 0.2844
Accuracy: 0.9030
Precision: 0.8980
Recall: 0.9030
F1-score: 0.8980
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2551
Epoch 1/10, Batch 20/49, Loss: 1.0728
Epoch 1/10, Batch 30/49, Loss: 0.7897
Epoch 1/10, Batch 40/49, Loss: 0.7538
Epoch 1/10, Train Loss: 0.9845, Valid Loss: 0.6988
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5871
Epoch 2/10, Batch 20/49, Loss: 0.3944
Epoch 2/10, Batch 30/49, Loss: 0.4589
Epoch 2/10, Batch 40/49, Loss: 0.4302
Epoch 2/10, Train Loss: 0.5218, Valid Loss: 0.5555
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4646
Epoch 3/10, Batch 20/49, Loss: 0.6985
Epoch 3/10, Batch 30/49, Loss: 0.4001
Epoch 3/10, Batch 40/49, Loss: 0.3184
Epoch 3/10, Train Loss: 0.4082, Valid Loss: 0.4995
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2527
Epoch 4/10, Batch 20/49, Loss: 0.4727
Epoch 4/10, Batch 30/49, Loss: 0.1979
Epoch 4/10, Batch 40/49, Loss: 0.3427
Epoch 4/10, Train Loss: 0.3493, Valid Loss: 0.4435
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.1662
Epoch 5/10, Batch 20/49, Loss: 0.3060
Epoch 5/10, Batch 30/49, Loss: 0.2828
Epoch 5/10, Batch 40/49, Loss: 0.1939
Epoch 5/10, Train Loss: 0.3028, Valid Loss: 0.4315
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3412
Epoch 6/10, Batch 20/49, Loss: 0.3125
Epoch 6/10, Batch 30/49, Loss: 0.3333
Epoch 6/10, Batch 40/49, Loss: 0.2556
Epoch 6/10, Train Loss: 0.2725, Valid Loss: 0.4408
Epoch 7/10, Batch 10/49, Loss: 0.2611
Epoch 7/10, Batch 20/49, Loss: 0.1520
Epoch 7/10, Batch 30/49, Loss: 0.3969
Epoch 7/10, Batch 40/49, Loss: 0.2216
Epoch 7/10, Train Loss: 0.2571, Valid Loss: 0.4358
Epoch 8/10, Batch 10/49, Loss: 0.2974
Epoch 8/10, Batch 20/49, Loss: 0.2585
Epoch 8/10, Batch 30/49, Loss: 0.2808
Epoch 8/10, Batch 40/49, Loss: 0.2656
Epoch 8/10, Train Loss: 0.2449, Valid Loss: 0.4191
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1744
Epoch 9/10, Batch 20/49, Loss: 0.3093
Epoch 9/10, Batch 30/49, Loss: 0.5180
Epoch 9/10, Batch 40/49, Loss: 0.1919
Epoch 9/10, Train Loss: 0.2205, Valid Loss: 0.3979
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1583
Epoch 10/10, Batch 20/49, Loss: 0.1451
Epoch 10/10, Batch 30/49, Loss: 0.3840
Epoch 10/10, Batch 40/49, Loss: 0.2151
Epoch 10/10, Train Loss: 0.2038, Valid Loss: 0.3889
Model saved!
Accuracy: 0.8984
Precision: 0.8940
Recall: 0.8984
F1-score: 0.8951
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2465
Epoch 1/10, Batch 20/49, Loss: 1.0129
Epoch 1/10, Batch 30/49, Loss: 0.7731
Epoch 1/10, Batch 40/49, Loss: 0.6899
Epoch 1/10, Train Loss: 1.0076, Valid Loss: 0.6770
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7594
Epoch 2/10, Batch 20/49, Loss: 0.4482
Epoch 2/10, Batch 30/49, Loss: 0.6121
Epoch 2/10, Batch 40/49, Loss: 0.4901
Epoch 2/10, Train Loss: 0.5481, Valid Loss: 0.5071
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4766
Epoch 3/10, Batch 20/49, Loss: 0.3684
Epoch 3/10, Batch 30/49, Loss: 0.3260
Epoch 3/10, Batch 40/49, Loss: 0.3242
Epoch 3/10, Train Loss: 0.4303, Valid Loss: 0.4441
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2363
Epoch 4/10, Batch 20/49, Loss: 0.4424
Epoch 4/10, Batch 30/49, Loss: 0.2812
Epoch 4/10, Batch 40/49, Loss: 0.2618
Epoch 4/10, Train Loss: 0.3666, Valid Loss: 0.3846
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3521
Epoch 5/10, Batch 20/49, Loss: 0.3560
Epoch 5/10, Batch 30/49, Loss: 0.5173
Epoch 5/10, Batch 40/49, Loss: 0.1972
Epoch 5/10, Train Loss: 0.3175, Valid Loss: 0.3602
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2520
Epoch 6/10, Batch 20/49, Loss: 0.2722
Epoch 6/10, Batch 30/49, Loss: 0.3392
Epoch 6/10, Batch 40/49, Loss: 0.2640
Epoch 6/10, Train Loss: 0.2965, Valid Loss: 0.3560
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2111
Epoch 7/10, Batch 20/49, Loss: 0.1929
Epoch 7/10, Batch 30/49, Loss: 0.3215
Epoch 7/10, Batch 40/49, Loss: 0.2305
Epoch 7/10, Train Loss: 0.2835, Valid Loss: 0.3585
Epoch 8/10, Batch 10/49, Loss: 0.2740
Epoch 8/10, Batch 20/49, Loss: 0.2435
Epoch 8/10, Batch 30/49, Loss: 0.2103
Epoch 8/10, Batch 40/49, Loss: 0.2223
Epoch 8/10, Train Loss: 0.2607, Valid Loss: 0.3295
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2034
Epoch 9/10, Batch 20/49, Loss: 0.1886
Epoch 9/10, Batch 30/49, Loss: 0.2820
Epoch 9/10, Batch 40/49, Loss: 0.2025
Epoch 9/10, Train Loss: 0.2510, Valid Loss: 0.3300
Epoch 10/10, Batch 10/49, Loss: 0.2447
Epoch 10/10, Batch 20/49, Loss: 0.2608
Epoch 10/10, Batch 30/49, Loss: 0.2545
Epoch 10/10, Batch 40/49, Loss: 0.2382
Epoch 10/10, Train Loss: 0.2260, Valid Loss: 0.3169
Model saved!
Accuracy: 0.8995
Precision: 0.8951
Recall: 0.8995
F1-score: 0.8954
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2259
Epoch 1/10, Batch 20/49, Loss: 1.1118
Epoch 1/10, Batch 30/49, Loss: 0.7702
Epoch 1/10, Batch 40/49, Loss: 0.7662
Epoch 1/10, Train Loss: 0.9902, Valid Loss: 0.6181
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6055
Epoch 2/10, Batch 20/49, Loss: 0.4325
Epoch 2/10, Batch 30/49, Loss: 0.4322
Epoch 2/10, Batch 40/49, Loss: 0.4328
Epoch 2/10, Train Loss: 0.5170, Valid Loss: 0.4306
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3792
Epoch 3/10, Batch 20/49, Loss: 0.4716
Epoch 3/10, Batch 30/49, Loss: 0.3073
Epoch 3/10, Batch 40/49, Loss: 0.2535
Epoch 3/10, Train Loss: 0.4032, Valid Loss: 0.3530
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3876
Epoch 4/10, Batch 20/49, Loss: 0.3097
Epoch 4/10, Batch 30/49, Loss: 0.2775
Epoch 4/10, Batch 40/49, Loss: 0.3804
Epoch 4/10, Train Loss: 0.3335, Valid Loss: 0.3088
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2269
Epoch 5/10, Batch 20/49, Loss: 0.2081
Epoch 5/10, Batch 30/49, Loss: 0.1593
Epoch 5/10, Batch 40/49, Loss: 0.2244
Epoch 5/10, Train Loss: 0.2967, Valid Loss: 0.2802
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2594
Epoch 6/10, Batch 20/49, Loss: 0.2697
Epoch 6/10, Batch 30/49, Loss: 0.2763
Epoch 6/10, Batch 40/49, Loss: 0.2177
Epoch 6/10, Train Loss: 0.2716, Valid Loss: 0.2739
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1752
Epoch 7/10, Batch 20/49, Loss: 0.1826
Epoch 7/10, Batch 30/49, Loss: 0.2908
Epoch 7/10, Batch 40/49, Loss: 0.1904
Epoch 7/10, Train Loss: 0.2448, Valid Loss: 0.2578
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2636
Epoch 8/10, Batch 20/49, Loss: 0.1724
Epoch 8/10, Batch 30/49, Loss: 0.2958
Epoch 8/10, Batch 40/49, Loss: 0.1776
Epoch 8/10, Train Loss: 0.2326, Valid Loss: 0.2543
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2504
Epoch 9/10, Batch 20/49, Loss: 0.2533
Epoch 9/10, Batch 30/49, Loss: 0.4106
Epoch 9/10, Batch 40/49, Loss: 0.1974
Epoch 9/10, Train Loss: 0.2121, Valid Loss: 0.2380
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1874
Epoch 10/10, Batch 20/49, Loss: 0.0816
Epoch 10/10, Batch 30/49, Loss: 0.2590
Epoch 10/10, Batch 40/49, Loss: 0.2970
Epoch 10/10, Train Loss: 0.1923, Valid Loss: 0.2298
Model saved!
Accuracy: 0.8984
Precision: 0.8940
Recall: 0.8984
F1-score: 0.8945
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3030
Epoch 1/10, Batch 20/49, Loss: 1.0449
Epoch 1/10, Batch 30/49, Loss: 0.7119
Epoch 1/10, Batch 40/49, Loss: 0.6726
Epoch 1/10, Train Loss: 0.9821, Valid Loss: 0.6559
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6278
Epoch 2/10, Batch 20/49, Loss: 0.5614
Epoch 2/10, Batch 30/49, Loss: 0.4093
Epoch 2/10, Batch 40/49, Loss: 0.4719
Epoch 2/10, Train Loss: 0.5238, Valid Loss: 0.4871
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3703
Epoch 3/10, Batch 20/49, Loss: 0.3228
Epoch 3/10, Batch 30/49, Loss: 0.4354
Epoch 3/10, Batch 40/49, Loss: 0.2788
Epoch 3/10, Train Loss: 0.4029, Valid Loss: 0.4228
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3449
Epoch 4/10, Batch 20/49, Loss: 0.3458
Epoch 4/10, Batch 30/49, Loss: 0.2892
Epoch 4/10, Batch 40/49, Loss: 0.2890
Epoch 4/10, Train Loss: 0.3425, Valid Loss: 0.3793
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3729
Epoch 5/10, Batch 20/49, Loss: 0.2696
Epoch 5/10, Batch 30/49, Loss: 0.3828
Epoch 5/10, Batch 40/49, Loss: 0.2686
Epoch 5/10, Train Loss: 0.2900, Valid Loss: 0.3655
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1725
Epoch 6/10, Batch 20/49, Loss: 0.3126
Epoch 6/10, Batch 30/49, Loss: 0.2976
Epoch 6/10, Batch 40/49, Loss: 0.2947
Epoch 6/10, Train Loss: 0.2660, Valid Loss: 0.3474
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1173
Epoch 7/10, Batch 20/49, Loss: 0.1659
Epoch 7/10, Batch 30/49, Loss: 0.3911
Epoch 7/10, Batch 40/49, Loss: 0.1289
Epoch 7/10, Train Loss: 0.2450, Valid Loss: 0.3445
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3068
Epoch 8/10, Batch 20/49, Loss: 0.2613
Epoch 8/10, Batch 30/49, Loss: 0.2268
Epoch 8/10, Batch 40/49, Loss: 0.2425
Epoch 8/10, Train Loss: 0.2412, Valid Loss: 0.3288
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1495
Epoch 9/10, Batch 20/49, Loss: 0.1787
Epoch 9/10, Batch 30/49, Loss: 0.4054
Epoch 9/10, Batch 40/49, Loss: 0.2303
Epoch 9/10, Train Loss: 0.2215, Valid Loss: 0.3160
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2048
Epoch 10/10, Batch 20/49, Loss: 0.2233
Epoch 10/10, Batch 30/49, Loss: 0.2469
Epoch 10/10, Batch 40/49, Loss: 0.0773
Epoch 10/10, Train Loss: 0.1924, Valid Loss: 0.3063
Model saved!
Accuracy: 0.9089
Precision: 0.9045
Recall: 0.9089
F1-score: 0.9048
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2081
Epoch 1/10, Batch 20/49, Loss: 0.9974
Epoch 1/10, Batch 30/49, Loss: 0.7652
Epoch 1/10, Batch 40/49, Loss: 0.8166
Epoch 1/10, Train Loss: 0.9815, Valid Loss: 0.6182
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6723
Epoch 2/10, Batch 20/49, Loss: 0.5005
Epoch 2/10, Batch 30/49, Loss: 0.6207
Epoch 2/10, Batch 40/49, Loss: 0.4739
Epoch 2/10, Train Loss: 0.5224, Valid Loss: 0.4404
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4218
Epoch 3/10, Batch 20/49, Loss: 0.3705
Epoch 3/10, Batch 30/49, Loss: 0.3024
Epoch 3/10, Batch 40/49, Loss: 0.3024
Epoch 3/10, Train Loss: 0.4032, Valid Loss: 0.3739
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2585
Epoch 4/10, Batch 20/49, Loss: 0.4555
Epoch 4/10, Batch 30/49, Loss: 0.2241
Epoch 4/10, Batch 40/49, Loss: 0.2842
Epoch 4/10, Train Loss: 0.3571, Valid Loss: 0.3268
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3123
Epoch 5/10, Batch 20/49, Loss: 0.2702
Epoch 5/10, Batch 30/49, Loss: 0.2147
Epoch 5/10, Batch 40/49, Loss: 0.2194
Epoch 5/10, Train Loss: 0.2976, Valid Loss: 0.2994
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1820
Epoch 6/10, Batch 20/49, Loss: 0.2053
Epoch 6/10, Batch 30/49, Loss: 0.2972
Epoch 6/10, Batch 40/49, Loss: 0.2874
Epoch 6/10, Train Loss: 0.2765, Valid Loss: 0.2925
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2070
Epoch 7/10, Batch 20/49, Loss: 0.2869
Epoch 7/10, Batch 30/49, Loss: 0.3707
Epoch 7/10, Batch 40/49, Loss: 0.1150
Epoch 7/10, Train Loss: 0.2569, Valid Loss: 0.2894
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1970
Epoch 8/10, Batch 20/49, Loss: 0.2384
Epoch 8/10, Batch 30/49, Loss: 0.1754
Epoch 8/10, Batch 40/49, Loss: 0.2099
Epoch 8/10, Train Loss: 0.2514, Valid Loss: 0.2760
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2299
Epoch 9/10, Batch 20/49, Loss: 0.2676
Epoch 9/10, Batch 30/49, Loss: 0.5534
Epoch 9/10, Batch 40/49, Loss: 0.2021
Epoch 9/10, Train Loss: 0.2335, Valid Loss: 0.2624
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3785
Epoch 10/10, Batch 20/49, Loss: 0.1876
Epoch 10/10, Batch 30/49, Loss: 0.1396
Epoch 10/10, Batch 40/49, Loss: 0.2517
Epoch 10/10, Train Loss: 0.2007, Valid Loss: 0.2550
Model saved!
Accuracy: 0.8995
Precision: 0.8942
Recall: 0.8995
F1-score: 0.8955
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3000
Epoch 1/10, Batch 20/49, Loss: 1.0104
Epoch 1/10, Batch 30/49, Loss: 0.7505
Epoch 1/10, Batch 40/49, Loss: 0.8095
Epoch 1/10, Train Loss: 0.9893, Valid Loss: 0.6624
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7006
Epoch 2/10, Batch 20/49, Loss: 0.4661
Epoch 2/10, Batch 30/49, Loss: 0.4017
Epoch 2/10, Batch 40/49, Loss: 0.5597
Epoch 2/10, Train Loss: 0.5270, Valid Loss: 0.5029
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3149
Epoch 3/10, Batch 20/49, Loss: 0.3331
Epoch 3/10, Batch 30/49, Loss: 0.4033
Epoch 3/10, Batch 40/49, Loss: 0.4248
Epoch 3/10, Train Loss: 0.4136, Valid Loss: 0.4409
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2229
Epoch 4/10, Batch 20/49, Loss: 0.4903
Epoch 4/10, Batch 30/49, Loss: 0.1932
Epoch 4/10, Batch 40/49, Loss: 0.2619
Epoch 4/10, Train Loss: 0.3552, Valid Loss: 0.3746
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3122
Epoch 5/10, Batch 20/49, Loss: 0.3148
Epoch 5/10, Batch 30/49, Loss: 0.2683
Epoch 5/10, Batch 40/49, Loss: 0.2487
Epoch 5/10, Train Loss: 0.2892, Valid Loss: 0.3548
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2946
Epoch 6/10, Batch 20/49, Loss: 0.3240
Epoch 6/10, Batch 30/49, Loss: 0.3419
Epoch 6/10, Batch 40/49, Loss: 0.3043
Epoch 6/10, Train Loss: 0.2762, Valid Loss: 0.3607
Epoch 7/10, Batch 10/49, Loss: 0.3007
Epoch 7/10, Batch 20/49, Loss: 0.2253
Epoch 7/10, Batch 30/49, Loss: 0.3574
Epoch 7/10, Batch 40/49, Loss: 0.1670
Epoch 7/10, Train Loss: 0.2554, Valid Loss: 0.3339
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2650
Epoch 8/10, Batch 20/49, Loss: 0.3316
Epoch 8/10, Batch 30/49, Loss: 0.2165
Epoch 8/10, Batch 40/49, Loss: 0.1913
Epoch 8/10, Train Loss: 0.2438, Valid Loss: 0.3348
Epoch 9/10, Batch 10/49, Loss: 0.2816
Epoch 9/10, Batch 20/49, Loss: 0.1471
Epoch 9/10, Batch 30/49, Loss: 0.3313
Epoch 9/10, Batch 40/49, Loss: 0.2391
Epoch 9/10, Train Loss: 0.2193, Valid Loss: 0.3123
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3358
Epoch 10/10, Batch 20/49, Loss: 0.1966
Epoch 10/10, Batch 30/49, Loss: 0.1799
Epoch 10/10, Batch 40/49, Loss: 0.3056
Epoch 10/10, Train Loss: 0.2021, Valid Loss: 0.3150
Accuracy: 0.8972
Precision: 0.8923
Recall: 0.8972
F1-score: 0.8939
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2830
Epoch 1/10, Batch 20/49, Loss: 1.0512
Epoch 1/10, Batch 30/49, Loss: 0.8326
Epoch 1/10, Batch 40/49, Loss: 0.7231
Epoch 1/10, Train Loss: 1.0111, Valid Loss: 0.6335
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5746
Epoch 2/10, Batch 20/49, Loss: 0.5455
Epoch 2/10, Batch 30/49, Loss: 0.6613
Epoch 2/10, Batch 40/49, Loss: 0.5359
Epoch 2/10, Train Loss: 0.5564, Valid Loss: 0.4640
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3608
Epoch 3/10, Batch 20/49, Loss: 0.5733
Epoch 3/10, Batch 30/49, Loss: 0.4297
Epoch 3/10, Batch 40/49, Loss: 0.3926
Epoch 3/10, Train Loss: 0.4439, Valid Loss: 0.3813
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3380
Epoch 4/10, Batch 20/49, Loss: 0.3937
Epoch 4/10, Batch 30/49, Loss: 0.2683
Epoch 4/10, Batch 40/49, Loss: 0.3040
Epoch 4/10, Train Loss: 0.3789, Valid Loss: 0.3329
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2194
Epoch 5/10, Batch 20/49, Loss: 0.2904
Epoch 5/10, Batch 30/49, Loss: 0.2554
Epoch 5/10, Batch 40/49, Loss: 0.2691
Epoch 5/10, Train Loss: 0.3236, Valid Loss: 0.3041
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2127
Epoch 6/10, Batch 20/49, Loss: 0.1895
Epoch 6/10, Batch 30/49, Loss: 0.3009
Epoch 6/10, Batch 40/49, Loss: 0.3071
Epoch 6/10, Train Loss: 0.3070, Valid Loss: 0.2936
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1787
Epoch 7/10, Batch 20/49, Loss: 0.2405
Epoch 7/10, Batch 30/49, Loss: 0.2437
Epoch 7/10, Batch 40/49, Loss: 0.2355
Epoch 7/10, Train Loss: 0.2870, Valid Loss: 0.2867
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1831
Epoch 8/10, Batch 20/49, Loss: 0.4369
Epoch 8/10, Batch 30/49, Loss: 0.3355
Epoch 8/10, Batch 40/49, Loss: 0.2234
Epoch 8/10, Train Loss: 0.2743, Valid Loss: 0.2719
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1584
Epoch 9/10, Batch 20/49, Loss: 0.2534
Epoch 9/10, Batch 30/49, Loss: 0.4412
Epoch 9/10, Batch 40/49, Loss: 0.2203
Epoch 9/10, Train Loss: 0.2479, Valid Loss: 0.2637
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1956
Epoch 10/10, Batch 20/49, Loss: 0.1271
Epoch 10/10, Batch 30/49, Loss: 0.2741
Epoch 10/10, Batch 40/49, Loss: 0.1454
Epoch 10/10, Train Loss: 0.2197, Valid Loss: 0.2582
Model saved!
Accuracy: 0.8972
Precision: 0.8950
Recall: 0.8972
F1-score: 0.8904
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2935
Epoch 1/10, Batch 20/49, Loss: 1.0034
Epoch 1/10, Batch 30/49, Loss: 0.7948
Epoch 1/10, Batch 40/49, Loss: 0.8456
Epoch 1/10, Train Loss: 0.9918, Valid Loss: 0.6382
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6948
Epoch 2/10, Batch 20/49, Loss: 0.5332
Epoch 2/10, Batch 30/49, Loss: 0.5182
Epoch 2/10, Batch 40/49, Loss: 0.7037
Epoch 2/10, Train Loss: 0.5348, Valid Loss: 0.4824
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4045
Epoch 3/10, Batch 20/49, Loss: 0.4350
Epoch 3/10, Batch 30/49, Loss: 0.3998
Epoch 3/10, Batch 40/49, Loss: 0.3142
Epoch 3/10, Train Loss: 0.4159, Valid Loss: 0.4278
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3020
Epoch 4/10, Batch 20/49, Loss: 0.3743
Epoch 4/10, Batch 30/49, Loss: 0.2768
Epoch 4/10, Batch 40/49, Loss: 0.3013
Epoch 4/10, Train Loss: 0.3568, Valid Loss: 0.3890
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3330
Epoch 5/10, Batch 20/49, Loss: 0.2537
Epoch 5/10, Batch 30/49, Loss: 0.3110
Epoch 5/10, Batch 40/49, Loss: 0.2039
Epoch 5/10, Train Loss: 0.3023, Valid Loss: 0.3601
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2150
Epoch 6/10, Batch 20/49, Loss: 0.2631
Epoch 6/10, Batch 30/49, Loss: 0.3047
Epoch 6/10, Batch 40/49, Loss: 0.2846
Epoch 6/10, Train Loss: 0.2813, Valid Loss: 0.3716
Epoch 7/10, Batch 10/49, Loss: 0.2634
Epoch 7/10, Batch 20/49, Loss: 0.2478
Epoch 7/10, Batch 30/49, Loss: 0.3953
Epoch 7/10, Batch 40/49, Loss: 0.1804
Epoch 7/10, Train Loss: 0.2607, Valid Loss: 0.3693
Epoch 8/10, Batch 10/49, Loss: 0.2166
Epoch 8/10, Batch 20/49, Loss: 0.1628
Epoch 8/10, Batch 30/49, Loss: 0.2449
Epoch 8/10, Batch 40/49, Loss: 0.1470
Epoch 8/10, Train Loss: 0.2589, Valid Loss: 0.3551
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1217
Epoch 9/10, Batch 20/49, Loss: 0.2051
Epoch 9/10, Batch 30/49, Loss: 0.3210
Epoch 9/10, Batch 40/49, Loss: 0.1888
Epoch 9/10, Train Loss: 0.2264, Valid Loss: 0.3265
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1748
Epoch 10/10, Batch 20/49, Loss: 0.1536
Epoch 10/10, Batch 30/49, Loss: 0.3395
Epoch 10/10, Batch 40/49, Loss: 0.1388
Epoch 10/10, Train Loss: 0.2109, Valid Loss: 0.3283
Accuracy: 0.9065
Precision: 0.9032
Recall: 0.9065
F1-score: 0.9039
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3137
Epoch 1/10, Batch 20/49, Loss: 1.0143
Epoch 1/10, Batch 30/49, Loss: 0.9126
Epoch 1/10, Batch 40/49, Loss: 0.7844
Epoch 1/10, Train Loss: 1.0076, Valid Loss: 0.6040
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7374
Epoch 2/10, Batch 20/49, Loss: 0.4626
Epoch 2/10, Batch 30/49, Loss: 0.5562
Epoch 2/10, Batch 40/49, Loss: 0.7020
Epoch 2/10, Train Loss: 0.5578, Valid Loss: 0.4444
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4545
Epoch 3/10, Batch 20/49, Loss: 0.5500
Epoch 3/10, Batch 30/49, Loss: 0.3709
Epoch 3/10, Batch 40/49, Loss: 0.3853
Epoch 3/10, Train Loss: 0.4401, Valid Loss: 0.3566
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3469
Epoch 4/10, Batch 20/49, Loss: 0.4181
Epoch 4/10, Batch 30/49, Loss: 0.2482
Epoch 4/10, Batch 40/49, Loss: 0.3310
Epoch 4/10, Train Loss: 0.3728, Valid Loss: 0.3081
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4201
Epoch 5/10, Batch 20/49, Loss: 0.2621
Epoch 5/10, Batch 30/49, Loss: 0.3346
Epoch 5/10, Batch 40/49, Loss: 0.3139
Epoch 5/10, Train Loss: 0.3227, Valid Loss: 0.2820
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2705
Epoch 6/10, Batch 20/49, Loss: 0.3754
Epoch 6/10, Batch 30/49, Loss: 0.4133
Epoch 6/10, Batch 40/49, Loss: 0.2454
Epoch 6/10, Train Loss: 0.2937, Valid Loss: 0.2815
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3003
Epoch 7/10, Batch 20/49, Loss: 0.2346
Epoch 7/10, Batch 30/49, Loss: 0.4037
Epoch 7/10, Batch 40/49, Loss: 0.3251
Epoch 7/10, Train Loss: 0.2743, Valid Loss: 0.2684
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1685
Epoch 8/10, Batch 20/49, Loss: 0.2200
Epoch 8/10, Batch 30/49, Loss: 0.3600
Epoch 8/10, Batch 40/49, Loss: 0.2420
Epoch 8/10, Train Loss: 0.2585, Valid Loss: 0.2430
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1604
Epoch 9/10, Batch 20/49, Loss: 0.2393
Epoch 9/10, Batch 30/49, Loss: 0.5145
Epoch 9/10, Batch 40/49, Loss: 0.1582
Epoch 9/10, Train Loss: 0.2479, Valid Loss: 0.2310
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2502
Epoch 10/10, Batch 20/49, Loss: 0.1307
Epoch 10/10, Batch 30/49, Loss: 0.2252
Epoch 10/10, Batch 40/49, Loss: 0.3202
Epoch 10/10, Train Loss: 0.2215, Valid Loss: 0.2133
Model saved!
Accuracy: 0.9100
Precision: 0.9083
Recall: 0.9100
F1-score: 0.9065
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3347
Epoch 1/10, Batch 20/49, Loss: 1.0608
Epoch 1/10, Batch 30/49, Loss: 0.8523
Epoch 1/10, Batch 40/49, Loss: 0.8324
Epoch 1/10, Train Loss: 1.0038, Valid Loss: 0.6903
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6606
Epoch 2/10, Batch 20/49, Loss: 0.4452
Epoch 2/10, Batch 30/49, Loss: 0.5132
Epoch 2/10, Batch 40/49, Loss: 0.5603
Epoch 2/10, Train Loss: 0.5370, Valid Loss: 0.5102
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4548
Epoch 3/10, Batch 20/49, Loss: 0.4892
Epoch 3/10, Batch 30/49, Loss: 0.3807
Epoch 3/10, Batch 40/49, Loss: 0.5157
Epoch 3/10, Train Loss: 0.4202, Valid Loss: 0.4267
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2686
Epoch 4/10, Batch 20/49, Loss: 0.4394
Epoch 4/10, Batch 30/49, Loss: 0.3695
Epoch 4/10, Batch 40/49, Loss: 0.2006
Epoch 4/10, Train Loss: 0.3555, Valid Loss: 0.3775
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.1745
Epoch 5/10, Batch 20/49, Loss: 0.1496
Epoch 5/10, Batch 30/49, Loss: 0.2419
Epoch 5/10, Batch 40/49, Loss: 0.2451
Epoch 5/10, Train Loss: 0.3060, Valid Loss: 0.3518
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2445
Epoch 6/10, Batch 20/49, Loss: 0.2514
Epoch 6/10, Batch 30/49, Loss: 0.3068
Epoch 6/10, Batch 40/49, Loss: 0.1295
Epoch 6/10, Train Loss: 0.2859, Valid Loss: 0.3357
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2807
Epoch 7/10, Batch 20/49, Loss: 0.3298
Epoch 7/10, Batch 30/49, Loss: 0.3863
Epoch 7/10, Batch 40/49, Loss: 0.1785
Epoch 7/10, Train Loss: 0.2672, Valid Loss: 0.3325
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1642
Epoch 8/10, Batch 20/49, Loss: 0.2178
Epoch 8/10, Batch 30/49, Loss: 0.1507
Epoch 8/10, Batch 40/49, Loss: 0.1500
Epoch 8/10, Train Loss: 0.2504, Valid Loss: 0.3124
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2100
Epoch 9/10, Batch 20/49, Loss: 0.2563
Epoch 9/10, Batch 30/49, Loss: 0.4347
Epoch 9/10, Batch 40/49, Loss: 0.2045
Epoch 9/10, Train Loss: 0.2299, Valid Loss: 0.3037
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1840
Epoch 10/10, Batch 20/49, Loss: 0.1546
Epoch 10/10, Batch 30/49, Loss: 0.1341
Epoch 10/10, Batch 40/49, Loss: 0.1109
Epoch 10/10, Train Loss: 0.2101, Valid Loss: 0.2918
Model saved!
Accuracy: 0.8995
Precision: 0.8956
Recall: 0.8995
F1-score: 0.8966
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2032
Epoch 1/10, Batch 20/49, Loss: 1.0543
Epoch 1/10, Batch 30/49, Loss: 0.7655
Epoch 1/10, Batch 40/49, Loss: 0.7010
Epoch 1/10, Train Loss: 0.9907, Valid Loss: 0.7170
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6824
Epoch 2/10, Batch 20/49, Loss: 0.3671
Epoch 2/10, Batch 30/49, Loss: 0.4668
Epoch 2/10, Batch 40/49, Loss: 0.4606
Epoch 2/10, Train Loss: 0.5341, Valid Loss: 0.5733
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4562
Epoch 3/10, Batch 20/49, Loss: 0.4569
Epoch 3/10, Batch 30/49, Loss: 0.3412
Epoch 3/10, Batch 40/49, Loss: 0.4956
Epoch 3/10, Train Loss: 0.4132, Valid Loss: 0.5364
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2503
Epoch 4/10, Batch 20/49, Loss: 0.4128
Epoch 4/10, Batch 30/49, Loss: 0.2752
Epoch 4/10, Batch 40/49, Loss: 0.2960
Epoch 4/10, Train Loss: 0.3622, Valid Loss: 0.4750
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2877
Epoch 5/10, Batch 20/49, Loss: 0.1951
Epoch 5/10, Batch 30/49, Loss: 0.2495
Epoch 5/10, Batch 40/49, Loss: 0.2111
Epoch 5/10, Train Loss: 0.3027, Valid Loss: 0.4648
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2553
Epoch 6/10, Batch 20/49, Loss: 0.1929
Epoch 6/10, Batch 30/49, Loss: 0.3411
Epoch 6/10, Batch 40/49, Loss: 0.3094
Epoch 6/10, Train Loss: 0.2835, Valid Loss: 0.4663
Epoch 7/10, Batch 10/49, Loss: 0.3092
Epoch 7/10, Batch 20/49, Loss: 0.1894
Epoch 7/10, Batch 30/49, Loss: 0.2578
Epoch 7/10, Batch 40/49, Loss: 0.2071
Epoch 7/10, Train Loss: 0.2509, Valid Loss: 0.4617
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2135
Epoch 8/10, Batch 20/49, Loss: 0.2969
Epoch 8/10, Batch 30/49, Loss: 0.2160
Epoch 8/10, Batch 40/49, Loss: 0.2186
Epoch 8/10, Train Loss: 0.2431, Valid Loss: 0.4327
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2234
Epoch 9/10, Batch 20/49, Loss: 0.1985
Epoch 9/10, Batch 30/49, Loss: 0.5643
Epoch 9/10, Batch 40/49, Loss: 0.2179
Epoch 9/10, Train Loss: 0.2266, Valid Loss: 0.4365
Epoch 10/10, Batch 10/49, Loss: 0.1937
Epoch 10/10, Batch 20/49, Loss: 0.1364
Epoch 10/10, Batch 30/49, Loss: 0.1762
Epoch 10/10, Batch 40/49, Loss: 0.1017
Epoch 10/10, Train Loss: 0.2039, Valid Loss: 0.4136
Model saved!
Accuracy: 0.9100
Precision: 0.9081
Recall: 0.9100
F1-score: 0.9058
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2162
Epoch 1/10, Batch 20/49, Loss: 1.0729
Epoch 1/10, Batch 30/49, Loss: 0.8248
Epoch 1/10, Batch 40/49, Loss: 0.7302
Epoch 1/10, Train Loss: 0.9920, Valid Loss: 0.6899
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6978
Epoch 2/10, Batch 20/49, Loss: 0.5473
Epoch 2/10, Batch 30/49, Loss: 0.5457
Epoch 2/10, Batch 40/49, Loss: 0.4361
Epoch 2/10, Train Loss: 0.5330, Valid Loss: 0.5198
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4703
Epoch 3/10, Batch 20/49, Loss: 0.4116
Epoch 3/10, Batch 30/49, Loss: 0.2513
Epoch 3/10, Batch 40/49, Loss: 0.2929
Epoch 3/10, Train Loss: 0.4086, Valid Loss: 0.4650
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3177
Epoch 4/10, Batch 20/49, Loss: 0.4856
Epoch 4/10, Batch 30/49, Loss: 0.2316
Epoch 4/10, Batch 40/49, Loss: 0.1766
Epoch 4/10, Train Loss: 0.3564, Valid Loss: 0.4208
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2684
Epoch 5/10, Batch 20/49, Loss: 0.1860
Epoch 5/10, Batch 30/49, Loss: 0.2876
Epoch 5/10, Batch 40/49, Loss: 0.3116
Epoch 5/10, Train Loss: 0.3081, Valid Loss: 0.4013
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2713
Epoch 6/10, Batch 20/49, Loss: 0.2715
Epoch 6/10, Batch 30/49, Loss: 0.2525
Epoch 6/10, Batch 40/49, Loss: 0.2122
Epoch 6/10, Train Loss: 0.2753, Valid Loss: 0.3876
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2253
Epoch 7/10, Batch 20/49, Loss: 0.1477
Epoch 7/10, Batch 30/49, Loss: 0.2779
Epoch 7/10, Batch 40/49, Loss: 0.1920
Epoch 7/10, Train Loss: 0.2463, Valid Loss: 0.3922
Epoch 8/10, Batch 10/49, Loss: 0.2920
Epoch 8/10, Batch 20/49, Loss: 0.2473
Epoch 8/10, Batch 30/49, Loss: 0.2118
Epoch 8/10, Batch 40/49, Loss: 0.2105
Epoch 8/10, Train Loss: 0.2506, Valid Loss: 0.3835
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.0899
Epoch 9/10, Batch 20/49, Loss: 0.1417
Epoch 9/10, Batch 30/49, Loss: 0.3640
Epoch 9/10, Batch 40/49, Loss: 0.1450
Epoch 9/10, Train Loss: 0.2254, Valid Loss: 0.3625
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1519
Epoch 10/10, Batch 20/49, Loss: 0.1750
Epoch 10/10, Batch 30/49, Loss: 0.1597
Epoch 10/10, Batch 40/49, Loss: 0.2325
Epoch 10/10, Train Loss: 0.2125, Valid Loss: 0.3509
Model saved!
Accuracy: 0.9100
Precision: 0.9069
Recall: 0.9100
F1-score: 0.9081
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1834
Epoch 1/10, Batch 20/49, Loss: 1.0180
Epoch 1/10, Batch 30/49, Loss: 0.9006
Epoch 1/10, Batch 40/49, Loss: 0.8066
Epoch 1/10, Train Loss: 1.0066, Valid Loss: 0.6556
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6812
Epoch 2/10, Batch 20/49, Loss: 0.5130
Epoch 2/10, Batch 30/49, Loss: 0.4165
Epoch 2/10, Batch 40/49, Loss: 0.5781
Epoch 2/10, Train Loss: 0.5383, Valid Loss: 0.4765
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4373
Epoch 3/10, Batch 20/49, Loss: 0.4659
Epoch 3/10, Batch 30/49, Loss: 0.3906
Epoch 3/10, Batch 40/49, Loss: 0.4278
Epoch 3/10, Train Loss: 0.4149, Valid Loss: 0.4159
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2143
Epoch 4/10, Batch 20/49, Loss: 0.4775
Epoch 4/10, Batch 30/49, Loss: 0.2239
Epoch 4/10, Batch 40/49, Loss: 0.2516
Epoch 4/10, Train Loss: 0.3664, Valid Loss: 0.3664
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2289
Epoch 5/10, Batch 20/49, Loss: 0.2162
Epoch 5/10, Batch 30/49, Loss: 0.3169
Epoch 5/10, Batch 40/49, Loss: 0.2239
Epoch 5/10, Train Loss: 0.3036, Valid Loss: 0.3470
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2131
Epoch 6/10, Batch 20/49, Loss: 0.4317
Epoch 6/10, Batch 30/49, Loss: 0.3738
Epoch 6/10, Batch 40/49, Loss: 0.1825
Epoch 6/10, Train Loss: 0.2799, Valid Loss: 0.3380
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2889
Epoch 7/10, Batch 20/49, Loss: 0.2929
Epoch 7/10, Batch 30/49, Loss: 0.3207
Epoch 7/10, Batch 40/49, Loss: 0.2470
Epoch 7/10, Train Loss: 0.2570, Valid Loss: 0.3299
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2389
Epoch 8/10, Batch 20/49, Loss: 0.2438
Epoch 8/10, Batch 30/49, Loss: 0.2416
Epoch 8/10, Batch 40/49, Loss: 0.2948
Epoch 8/10, Train Loss: 0.2555, Valid Loss: 0.3097
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1963
Epoch 9/10, Batch 20/49, Loss: 0.2452
Epoch 9/10, Batch 30/49, Loss: 0.3142
Epoch 9/10, Batch 40/49, Loss: 0.1499
Epoch 9/10, Train Loss: 0.2361, Valid Loss: 0.3041
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1994
Epoch 10/10, Batch 20/49, Loss: 0.1528
Epoch 10/10, Batch 30/49, Loss: 0.1645
Epoch 10/10, Batch 40/49, Loss: 0.1674
Epoch 10/10, Train Loss: 0.2071, Valid Loss: 0.2944
Model saved!
Accuracy: 0.9065
Precision: 0.9035
Recall: 0.9065
F1-score: 0.9042
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2510
Epoch 1/10, Batch 20/49, Loss: 0.9568
Epoch 1/10, Batch 30/49, Loss: 0.8166
Epoch 1/10, Batch 40/49, Loss: 0.8659
Epoch 1/10, Train Loss: 1.0087, Valid Loss: 0.7082
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6540
Epoch 2/10, Batch 20/49, Loss: 0.5027
Epoch 2/10, Batch 30/49, Loss: 0.5470
Epoch 2/10, Batch 40/49, Loss: 0.4089
Epoch 2/10, Train Loss: 0.5436, Valid Loss: 0.5519
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.6094
Epoch 3/10, Batch 20/49, Loss: 0.3732
Epoch 3/10, Batch 30/49, Loss: 0.3785
Epoch 3/10, Batch 40/49, Loss: 0.3981
Epoch 3/10, Train Loss: 0.4323, Valid Loss: 0.4919
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3482
Epoch 4/10, Batch 20/49, Loss: 0.6113
Epoch 4/10, Batch 30/49, Loss: 0.3123
Epoch 4/10, Batch 40/49, Loss: 0.2452
Epoch 4/10, Train Loss: 0.3776, Valid Loss: 0.4460
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4418
Epoch 5/10, Batch 20/49, Loss: 0.3365
Epoch 5/10, Batch 30/49, Loss: 0.2631
Epoch 5/10, Batch 40/49, Loss: 0.2443
Epoch 5/10, Train Loss: 0.3221, Valid Loss: 0.4340
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2456
Epoch 6/10, Batch 20/49, Loss: 0.3003
Epoch 6/10, Batch 30/49, Loss: 0.4290
Epoch 6/10, Batch 40/49, Loss: 0.2963
Epoch 6/10, Train Loss: 0.2975, Valid Loss: 0.4324
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2710
Epoch 7/10, Batch 20/49, Loss: 0.1326
Epoch 7/10, Batch 30/49, Loss: 0.4366
Epoch 7/10, Batch 40/49, Loss: 0.4256
Epoch 7/10, Train Loss: 0.2764, Valid Loss: 0.4169
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2683
Epoch 8/10, Batch 20/49, Loss: 0.1600
Epoch 8/10, Batch 30/49, Loss: 0.1617
Epoch 8/10, Batch 40/49, Loss: 0.2349
Epoch 8/10, Train Loss: 0.2792, Valid Loss: 0.4013
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2086
Epoch 9/10, Batch 20/49, Loss: 0.1836
Epoch 9/10, Batch 30/49, Loss: 0.4338
Epoch 9/10, Batch 40/49, Loss: 0.1507
Epoch 9/10, Train Loss: 0.2460, Valid Loss: 0.3984
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2470
Epoch 10/10, Batch 20/49, Loss: 0.1561
Epoch 10/10, Batch 30/49, Loss: 0.1752
Epoch 10/10, Batch 40/49, Loss: 0.2776
Epoch 10/10, Train Loss: 0.2302, Valid Loss: 0.3749
Model saved!
Accuracy: 0.9065
Precision: 0.9032
Recall: 0.9065
F1-score: 0.9044
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3050
Epoch 1/10, Batch 20/49, Loss: 1.0698
Epoch 1/10, Batch 30/49, Loss: 0.7979
Epoch 1/10, Batch 40/49, Loss: 0.8964
Epoch 1/10, Train Loss: 1.0017, Valid Loss: 0.5891
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6466
Epoch 2/10, Batch 20/49, Loss: 0.4913
Epoch 2/10, Batch 30/49, Loss: 0.6777
Epoch 2/10, Batch 40/49, Loss: 0.5979
Epoch 2/10, Train Loss: 0.5398, Valid Loss: 0.4298
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5143
Epoch 3/10, Batch 20/49, Loss: 0.3918
Epoch 3/10, Batch 30/49, Loss: 0.4381
Epoch 3/10, Batch 40/49, Loss: 0.2220
Epoch 3/10, Train Loss: 0.4133, Valid Loss: 0.3567
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2384
Epoch 4/10, Batch 20/49, Loss: 0.4110
Epoch 4/10, Batch 30/49, Loss: 0.2215
Epoch 4/10, Batch 40/49, Loss: 0.2466
Epoch 4/10, Train Loss: 0.3598, Valid Loss: 0.3200
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3151
Epoch 5/10, Batch 20/49, Loss: 0.1690
Epoch 5/10, Batch 30/49, Loss: 0.3069
Epoch 5/10, Batch 40/49, Loss: 0.1980
Epoch 5/10, Train Loss: 0.3113, Valid Loss: 0.2955
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2452
Epoch 6/10, Batch 20/49, Loss: 0.1781
Epoch 6/10, Batch 30/49, Loss: 0.2263
Epoch 6/10, Batch 40/49, Loss: 0.1618
Epoch 6/10, Train Loss: 0.2801, Valid Loss: 0.2792
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2003
Epoch 7/10, Batch 20/49, Loss: 0.2242
Epoch 7/10, Batch 30/49, Loss: 0.2721
Epoch 7/10, Batch 40/49, Loss: 0.2613
Epoch 7/10, Train Loss: 0.2747, Valid Loss: 0.2717
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1827
Epoch 8/10, Batch 20/49, Loss: 0.3190
Epoch 8/10, Batch 30/49, Loss: 0.2547
Epoch 8/10, Batch 40/49, Loss: 0.2244
Epoch 8/10, Train Loss: 0.2477, Valid Loss: 0.2622
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1438
Epoch 9/10, Batch 20/49, Loss: 0.1357
Epoch 9/10, Batch 30/49, Loss: 0.3585
Epoch 9/10, Batch 40/49, Loss: 0.1626
Epoch 9/10, Train Loss: 0.2319, Valid Loss: 0.2478
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3016
Epoch 10/10, Batch 20/49, Loss: 0.1917
Epoch 10/10, Batch 30/49, Loss: 0.2512
Epoch 10/10, Batch 40/49, Loss: 0.2406
Epoch 10/10, Train Loss: 0.2209, Valid Loss: 0.2467
Model saved!
Accuracy: 0.8960
Precision: 0.8915
Recall: 0.8960
F1-score: 0.8910
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3022
Epoch 1/10, Batch 20/49, Loss: 0.9983
Epoch 1/10, Batch 30/49, Loss: 0.8130
Epoch 1/10, Batch 40/49, Loss: 0.8166
Epoch 1/10, Train Loss: 1.0040, Valid Loss: 0.6409
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7087
Epoch 2/10, Batch 20/49, Loss: 0.4970
Epoch 2/10, Batch 30/49, Loss: 0.5125
Epoch 2/10, Batch 40/49, Loss: 0.5487
Epoch 2/10, Train Loss: 0.5387, Valid Loss: 0.4808
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3945
Epoch 3/10, Batch 20/49, Loss: 0.3334
Epoch 3/10, Batch 30/49, Loss: 0.2976
Epoch 3/10, Batch 40/49, Loss: 0.4257
Epoch 3/10, Train Loss: 0.4193, Valid Loss: 0.4096
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2895
Epoch 4/10, Batch 20/49, Loss: 0.4945
Epoch 4/10, Batch 30/49, Loss: 0.3555
Epoch 4/10, Batch 40/49, Loss: 0.4953
Epoch 4/10, Train Loss: 0.3538, Valid Loss: 0.3721
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3301
Epoch 5/10, Batch 20/49, Loss: 0.2670
Epoch 5/10, Batch 30/49, Loss: 0.3171
Epoch 5/10, Batch 40/49, Loss: 0.2181
Epoch 5/10, Train Loss: 0.3100, Valid Loss: 0.3424
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2411
Epoch 6/10, Batch 20/49, Loss: 0.2311
Epoch 6/10, Batch 30/49, Loss: 0.2960
Epoch 6/10, Batch 40/49, Loss: 0.3337
Epoch 6/10, Train Loss: 0.2824, Valid Loss: 0.3312
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1997
Epoch 7/10, Batch 20/49, Loss: 0.1369
Epoch 7/10, Batch 30/49, Loss: 0.2715
Epoch 7/10, Batch 40/49, Loss: 0.3008
Epoch 7/10, Train Loss: 0.2631, Valid Loss: 0.3312
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3505
Epoch 8/10, Batch 20/49, Loss: 0.1499
Epoch 8/10, Batch 30/49, Loss: 0.2955
Epoch 8/10, Batch 40/49, Loss: 0.2091
Epoch 8/10, Train Loss: 0.2505, Valid Loss: 0.3093
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2348
Epoch 9/10, Batch 20/49, Loss: 0.2529
Epoch 9/10, Batch 30/49, Loss: 0.5544
Epoch 9/10, Batch 40/49, Loss: 0.2342
Epoch 9/10, Train Loss: 0.2347, Valid Loss: 0.2948
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2449
Epoch 10/10, Batch 20/49, Loss: 0.1604
Epoch 10/10, Batch 30/49, Loss: 0.1307
Epoch 10/10, Batch 40/49, Loss: 0.2227
Epoch 10/10, Train Loss: 0.2092, Valid Loss: 0.2882
Model saved!
Accuracy: 0.9042
Precision: 0.9015
Recall: 0.9042
F1-score: 0.8997
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2285
Epoch 1/10, Batch 20/49, Loss: 1.0420
Epoch 1/10, Batch 30/49, Loss: 0.8677
Epoch 1/10, Batch 40/49, Loss: 0.7912
Epoch 1/10, Train Loss: 0.9927, Valid Loss: 0.6864
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5824
Epoch 2/10, Batch 20/49, Loss: 0.4809
Epoch 2/10, Batch 30/49, Loss: 0.4831
Epoch 2/10, Batch 40/49, Loss: 0.3841
Epoch 2/10, Train Loss: 0.5329, Valid Loss: 0.5178
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4986
Epoch 3/10, Batch 20/49, Loss: 0.5559
Epoch 3/10, Batch 30/49, Loss: 0.3394
Epoch 3/10, Batch 40/49, Loss: 0.4222
Epoch 3/10, Train Loss: 0.4154, Valid Loss: 0.4670
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3862
Epoch 4/10, Batch 20/49, Loss: 0.3837
Epoch 4/10, Batch 30/49, Loss: 0.3238
Epoch 4/10, Batch 40/49, Loss: 0.2321
Epoch 4/10, Train Loss: 0.3585, Valid Loss: 0.4112
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4636
Epoch 5/10, Batch 20/49, Loss: 0.2911
Epoch 5/10, Batch 30/49, Loss: 0.2503
Epoch 5/10, Batch 40/49, Loss: 0.1812
Epoch 5/10, Train Loss: 0.2998, Valid Loss: 0.3902
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1729
Epoch 6/10, Batch 20/49, Loss: 0.2570
Epoch 6/10, Batch 30/49, Loss: 0.3957
Epoch 6/10, Batch 40/49, Loss: 0.3226
Epoch 6/10, Train Loss: 0.2853, Valid Loss: 0.3985
Epoch 7/10, Batch 10/49, Loss: 0.2683
Epoch 7/10, Batch 20/49, Loss: 0.2741
Epoch 7/10, Batch 30/49, Loss: 0.3171
Epoch 7/10, Batch 40/49, Loss: 0.2740
Epoch 7/10, Train Loss: 0.2695, Valid Loss: 0.3874
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1947
Epoch 8/10, Batch 20/49, Loss: 0.3252
Epoch 8/10, Batch 30/49, Loss: 0.1508
Epoch 8/10, Batch 40/49, Loss: 0.1557
Epoch 8/10, Train Loss: 0.2509, Valid Loss: 0.3541
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1218
Epoch 9/10, Batch 20/49, Loss: 0.1683
Epoch 9/10, Batch 30/49, Loss: 0.3909
Epoch 9/10, Batch 40/49, Loss: 0.1443
Epoch 9/10, Train Loss: 0.2391, Valid Loss: 0.3588
Epoch 10/10, Batch 10/49, Loss: 0.1790
Epoch 10/10, Batch 20/49, Loss: 0.2012
Epoch 10/10, Batch 30/49, Loss: 0.2413
Epoch 10/10, Batch 40/49, Loss: 0.2243
Epoch 10/10, Train Loss: 0.2134, Valid Loss: 0.3358
Model saved!
Accuracy: 0.9065
Precision: 0.9037
Recall: 0.9065
F1-score: 0.9045
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2071
Epoch 1/10, Batch 20/49, Loss: 1.0509
Epoch 1/10, Batch 30/49, Loss: 0.7624
Epoch 1/10, Batch 40/49, Loss: 0.7528
Epoch 1/10, Train Loss: 0.9856, Valid Loss: 0.6548
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6938
Epoch 2/10, Batch 20/49, Loss: 0.4852
Epoch 2/10, Batch 30/49, Loss: 0.4642
Epoch 2/10, Batch 40/49, Loss: 0.4972
Epoch 2/10, Train Loss: 0.5166, Valid Loss: 0.4916
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3860
Epoch 3/10, Batch 20/49, Loss: 0.3082
Epoch 3/10, Batch 30/49, Loss: 0.3281
Epoch 3/10, Batch 40/49, Loss: 0.3688
Epoch 3/10, Train Loss: 0.3977, Valid Loss: 0.4179
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2928
Epoch 4/10, Batch 20/49, Loss: 0.3493
Epoch 4/10, Batch 30/49, Loss: 0.2851
Epoch 4/10, Batch 40/49, Loss: 0.2842
Epoch 4/10, Train Loss: 0.3474, Valid Loss: 0.3728
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2833
Epoch 5/10, Batch 20/49, Loss: 0.1597
Epoch 5/10, Batch 30/49, Loss: 0.3447
Epoch 5/10, Batch 40/49, Loss: 0.2383
Epoch 5/10, Train Loss: 0.3016, Valid Loss: 0.3475
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2438
Epoch 6/10, Batch 20/49, Loss: 0.3272
Epoch 6/10, Batch 30/49, Loss: 0.2613
Epoch 6/10, Batch 40/49, Loss: 0.2576
Epoch 6/10, Train Loss: 0.2712, Valid Loss: 0.3489
Epoch 7/10, Batch 10/49, Loss: 0.2044
Epoch 7/10, Batch 20/49, Loss: 0.1577
Epoch 7/10, Batch 30/49, Loss: 0.3401
Epoch 7/10, Batch 40/49, Loss: 0.2042
Epoch 7/10, Train Loss: 0.2532, Valid Loss: 0.3350
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1802
Epoch 8/10, Batch 20/49, Loss: 0.2269
Epoch 8/10, Batch 30/49, Loss: 0.1459
Epoch 8/10, Batch 40/49, Loss: 0.2252
Epoch 8/10, Train Loss: 0.2425, Valid Loss: 0.3252
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1786
Epoch 9/10, Batch 20/49, Loss: 0.1032
Epoch 9/10, Batch 30/49, Loss: 0.2732
Epoch 9/10, Batch 40/49, Loss: 0.1345
Epoch 9/10, Train Loss: 0.2353, Valid Loss: 0.3120
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1755
Epoch 10/10, Batch 20/49, Loss: 0.1425
Epoch 10/10, Batch 30/49, Loss: 0.2603
Epoch 10/10, Batch 40/49, Loss: 0.2333
Epoch 10/10, Train Loss: 0.2012, Valid Loss: 0.3035
Model saved!
Accuracy: 0.9136
Precision: 0.9110
Recall: 0.9136
F1-score: 0.9104
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2831
Epoch 1/10, Batch 20/49, Loss: 1.0368
Epoch 1/10, Batch 30/49, Loss: 0.9451
Epoch 1/10, Batch 40/49, Loss: 0.8078
Epoch 1/10, Train Loss: 1.0056, Valid Loss: 0.6541
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6245
Epoch 2/10, Batch 20/49, Loss: 0.5016
Epoch 2/10, Batch 30/49, Loss: 0.5083
Epoch 2/10, Batch 40/49, Loss: 0.5381
Epoch 2/10, Train Loss: 0.5470, Valid Loss: 0.4784
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4954
Epoch 3/10, Batch 20/49, Loss: 0.4186
Epoch 3/10, Batch 30/49, Loss: 0.5480
Epoch 3/10, Batch 40/49, Loss: 0.3910
Epoch 3/10, Train Loss: 0.4183, Valid Loss: 0.4174
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3398
Epoch 4/10, Batch 20/49, Loss: 0.3565
Epoch 4/10, Batch 30/49, Loss: 0.3224
Epoch 4/10, Batch 40/49, Loss: 0.3763
Epoch 4/10, Train Loss: 0.3704, Valid Loss: 0.3614
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3506
Epoch 5/10, Batch 20/49, Loss: 0.2080
Epoch 5/10, Batch 30/49, Loss: 0.1837
Epoch 5/10, Batch 40/49, Loss: 0.1702
Epoch 5/10, Train Loss: 0.3074, Valid Loss: 0.3642
Epoch 6/10, Batch 10/49, Loss: 0.3843
Epoch 6/10, Batch 20/49, Loss: 0.2555
Epoch 6/10, Batch 30/49, Loss: 0.4046
Epoch 6/10, Batch 40/49, Loss: 0.2331
Epoch 6/10, Train Loss: 0.2976, Valid Loss: 0.3379
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2881
Epoch 7/10, Batch 20/49, Loss: 0.2489
Epoch 7/10, Batch 30/49, Loss: 0.3392
Epoch 7/10, Batch 40/49, Loss: 0.2459
Epoch 7/10, Train Loss: 0.2658, Valid Loss: 0.3513
Epoch 8/10, Batch 10/49, Loss: 0.1640
Epoch 8/10, Batch 20/49, Loss: 0.3106
Epoch 8/10, Batch 30/49, Loss: 0.2410
Epoch 8/10, Batch 40/49, Loss: 0.1711
Epoch 8/10, Train Loss: 0.2639, Valid Loss: 0.3317
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1563
Epoch 9/10, Batch 20/49, Loss: 0.2880
Epoch 9/10, Batch 30/49, Loss: 0.4632
Epoch 9/10, Batch 40/49, Loss: 0.1563
Epoch 9/10, Train Loss: 0.2357, Valid Loss: 0.3286
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1988
Epoch 10/10, Batch 20/49, Loss: 0.1538
Epoch 10/10, Batch 30/49, Loss: 0.2792
Epoch 10/10, Batch 40/49, Loss: 0.2226
Epoch 10/10, Train Loss: 0.2038, Valid Loss: 0.3111
Model saved!
Accuracy: 0.9030
Precision: 0.8995
Recall: 0.9030
F1-score: 0.8980
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2911
Epoch 1/10, Batch 20/49, Loss: 0.9714
Epoch 1/10, Batch 30/49, Loss: 0.8329
Epoch 1/10, Batch 40/49, Loss: 0.7616
Epoch 1/10, Train Loss: 0.9939, Valid Loss: 0.6530
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6754
Epoch 2/10, Batch 20/49, Loss: 0.4520
Epoch 2/10, Batch 30/49, Loss: 0.6331
Epoch 2/10, Batch 40/49, Loss: 0.4705
Epoch 2/10, Train Loss: 0.5403, Valid Loss: 0.4735
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5242
Epoch 3/10, Batch 20/49, Loss: 0.4943
Epoch 3/10, Batch 30/49, Loss: 0.4254
Epoch 3/10, Batch 40/49, Loss: 0.4343
Epoch 3/10, Train Loss: 0.4251, Valid Loss: 0.4073
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2655
Epoch 4/10, Batch 20/49, Loss: 0.4293
Epoch 4/10, Batch 30/49, Loss: 0.3486
Epoch 4/10, Batch 40/49, Loss: 0.2356
Epoch 4/10, Train Loss: 0.3652, Valid Loss: 0.3638
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2040
Epoch 5/10, Batch 20/49, Loss: 0.1746
Epoch 5/10, Batch 30/49, Loss: 0.2846
Epoch 5/10, Batch 40/49, Loss: 0.2246
Epoch 5/10, Train Loss: 0.3061, Valid Loss: 0.3401
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2520
Epoch 6/10, Batch 20/49, Loss: 0.2850
Epoch 6/10, Batch 30/49, Loss: 0.2681
Epoch 6/10, Batch 40/49, Loss: 0.1918
Epoch 6/10, Train Loss: 0.2863, Valid Loss: 0.3238
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1971
Epoch 7/10, Batch 20/49, Loss: 0.3499
Epoch 7/10, Batch 30/49, Loss: 0.2676
Epoch 7/10, Batch 40/49, Loss: 0.2170
Epoch 7/10, Train Loss: 0.2757, Valid Loss: 0.3207
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2075
Epoch 8/10, Batch 20/49, Loss: 0.2544
Epoch 8/10, Batch 30/49, Loss: 0.1814
Epoch 8/10, Batch 40/49, Loss: 0.2752
Epoch 8/10, Train Loss: 0.2562, Valid Loss: 0.3050
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2267
Epoch 9/10, Batch 20/49, Loss: 0.1507
Epoch 9/10, Batch 30/49, Loss: 0.4514
Epoch 9/10, Batch 40/49, Loss: 0.1512
Epoch 9/10, Train Loss: 0.2550, Valid Loss: 0.2929
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2320
Epoch 10/10, Batch 20/49, Loss: 0.1291
Epoch 10/10, Batch 30/49, Loss: 0.1838
Epoch 10/10, Batch 40/49, Loss: 0.2176
Epoch 10/10, Train Loss: 0.2157, Valid Loss: 0.2867
Model saved!
Accuracy: 0.9100
Precision: 0.9064
Recall: 0.9100
F1-score: 0.9069
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3055
Epoch 1/10, Batch 20/49, Loss: 0.9811
Epoch 1/10, Batch 30/49, Loss: 0.9325
Epoch 1/10, Batch 40/49, Loss: 0.7120
Epoch 1/10, Train Loss: 1.0206, Valid Loss: 0.6657
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6132
Epoch 2/10, Batch 20/49, Loss: 0.5612
Epoch 2/10, Batch 30/49, Loss: 0.4987
Epoch 2/10, Batch 40/49, Loss: 0.4103
Epoch 2/10, Train Loss: 0.5581, Valid Loss: 0.4781
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4486
Epoch 3/10, Batch 20/49, Loss: 0.5158
Epoch 3/10, Batch 30/49, Loss: 0.5081
Epoch 3/10, Batch 40/49, Loss: 0.4256
Epoch 3/10, Train Loss: 0.4299, Valid Loss: 0.3974
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3160
Epoch 4/10, Batch 20/49, Loss: 0.4810
Epoch 4/10, Batch 30/49, Loss: 0.3670
Epoch 4/10, Batch 40/49, Loss: 0.3131
Epoch 4/10, Train Loss: 0.3760, Valid Loss: 0.3413
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3548
Epoch 5/10, Batch 20/49, Loss: 0.2910
Epoch 5/10, Batch 30/49, Loss: 0.3217
Epoch 5/10, Batch 40/49, Loss: 0.2295
Epoch 5/10, Train Loss: 0.3230, Valid Loss: 0.3157
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3319
Epoch 6/10, Batch 20/49, Loss: 0.3946
Epoch 6/10, Batch 30/49, Loss: 0.2727
Epoch 6/10, Batch 40/49, Loss: 0.2775
Epoch 6/10, Train Loss: 0.2956, Valid Loss: 0.2996
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2659
Epoch 7/10, Batch 20/49, Loss: 0.3376
Epoch 7/10, Batch 30/49, Loss: 0.3446
Epoch 7/10, Batch 40/49, Loss: 0.2247
Epoch 7/10, Train Loss: 0.2812, Valid Loss: 0.2906
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3275
Epoch 8/10, Batch 20/49, Loss: 0.2444
Epoch 8/10, Batch 30/49, Loss: 0.2945
Epoch 8/10, Batch 40/49, Loss: 0.2430
Epoch 8/10, Train Loss: 0.2687, Valid Loss: 0.2738
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1714
Epoch 9/10, Batch 20/49, Loss: 0.2593
Epoch 9/10, Batch 30/49, Loss: 0.3947
Epoch 9/10, Batch 40/49, Loss: 0.1778
Epoch 9/10, Train Loss: 0.2421, Valid Loss: 0.2617
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2136
Epoch 10/10, Batch 20/49, Loss: 0.2071
Epoch 10/10, Batch 30/49, Loss: 0.2442
Epoch 10/10, Batch 40/49, Loss: 0.2088
Epoch 10/10, Train Loss: 0.2316, Valid Loss: 0.2606
Model saved!
Accuracy: 0.9065
Precision: 0.9042
Recall: 0.9065
F1-score: 0.9017
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2728
Epoch 1/10, Batch 20/49, Loss: 1.0346
Epoch 1/10, Batch 30/49, Loss: 0.9616
Epoch 1/10, Batch 40/49, Loss: 0.7656
Epoch 1/10, Train Loss: 1.0007, Valid Loss: 0.6766
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6290
Epoch 2/10, Batch 20/49, Loss: 0.4963
Epoch 2/10, Batch 30/49, Loss: 0.4695
Epoch 2/10, Batch 40/49, Loss: 0.6946
Epoch 2/10, Train Loss: 0.5473, Valid Loss: 0.4992
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4524
Epoch 3/10, Batch 20/49, Loss: 0.3781
Epoch 3/10, Batch 30/49, Loss: 0.2837
Epoch 3/10, Batch 40/49, Loss: 0.3785
Epoch 3/10, Train Loss: 0.4283, Valid Loss: 0.4279
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2624
Epoch 4/10, Batch 20/49, Loss: 0.3350
Epoch 4/10, Batch 30/49, Loss: 0.3258
Epoch 4/10, Batch 40/49, Loss: 0.2918
Epoch 4/10, Train Loss: 0.3700, Valid Loss: 0.3738
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2017
Epoch 5/10, Batch 20/49, Loss: 0.3853
Epoch 5/10, Batch 30/49, Loss: 0.3802
Epoch 5/10, Batch 40/49, Loss: 0.3625
Epoch 5/10, Train Loss: 0.3143, Valid Loss: 0.3664
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2869
Epoch 6/10, Batch 20/49, Loss: 0.5811
Epoch 6/10, Batch 30/49, Loss: 0.3913
Epoch 6/10, Batch 40/49, Loss: 0.2571
Epoch 6/10, Train Loss: 0.2910, Valid Loss: 0.3375
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2404
Epoch 7/10, Batch 20/49, Loss: 0.2807
Epoch 7/10, Batch 30/49, Loss: 0.4709
Epoch 7/10, Batch 40/49, Loss: 0.1980
Epoch 7/10, Train Loss: 0.2665, Valid Loss: 0.3437
Epoch 8/10, Batch 10/49, Loss: 0.4101
Epoch 8/10, Batch 20/49, Loss: 0.2444
Epoch 8/10, Batch 30/49, Loss: 0.2415
Epoch 8/10, Batch 40/49, Loss: 0.1813
Epoch 8/10, Train Loss: 0.2559, Valid Loss: 0.3322
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1829
Epoch 9/10, Batch 20/49, Loss: 0.4188
Epoch 9/10, Batch 30/49, Loss: 0.5018
Epoch 9/10, Batch 40/49, Loss: 0.1633
Epoch 9/10, Train Loss: 0.2421, Valid Loss: 0.3071
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1162
Epoch 10/10, Batch 20/49, Loss: 0.2437
Epoch 10/10, Batch 30/49, Loss: 0.2296
Epoch 10/10, Batch 40/49, Loss: 0.2224
Epoch 10/10, Train Loss: 0.2224, Valid Loss: 0.2995
Model saved!
Accuracy: 0.9136
Precision: 0.9095
Recall: 0.9136
F1-score: 0.9102
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2690
Epoch 1/10, Batch 20/49, Loss: 1.0647
Epoch 1/10, Batch 30/49, Loss: 0.8913
Epoch 1/10, Batch 40/49, Loss: 0.8047
Epoch 1/10, Train Loss: 1.0050, Valid Loss: 0.6130
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7144
Epoch 2/10, Batch 20/49, Loss: 0.4798
Epoch 2/10, Batch 30/49, Loss: 0.5893
Epoch 2/10, Batch 40/49, Loss: 0.4840
Epoch 2/10, Train Loss: 0.5370, Valid Loss: 0.4451
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5735
Epoch 3/10, Batch 20/49, Loss: 0.4383
Epoch 3/10, Batch 30/49, Loss: 0.3432
Epoch 3/10, Batch 40/49, Loss: 0.3695
Epoch 3/10, Train Loss: 0.4140, Valid Loss: 0.3764
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3744
Epoch 4/10, Batch 20/49, Loss: 0.5315
Epoch 4/10, Batch 30/49, Loss: 0.2556
Epoch 4/10, Batch 40/49, Loss: 0.2362
Epoch 4/10, Train Loss: 0.3426, Valid Loss: 0.3297
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4110
Epoch 5/10, Batch 20/49, Loss: 0.2261
Epoch 5/10, Batch 30/49, Loss: 0.2510
Epoch 5/10, Batch 40/49, Loss: 0.1771
Epoch 5/10, Train Loss: 0.3072, Valid Loss: 0.3269
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2684
Epoch 6/10, Batch 20/49, Loss: 0.3585
Epoch 6/10, Batch 30/49, Loss: 0.2728
Epoch 6/10, Batch 40/49, Loss: 0.1788
Epoch 6/10, Train Loss: 0.2813, Valid Loss: 0.3110
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2913
Epoch 7/10, Batch 20/49, Loss: 0.3096
Epoch 7/10, Batch 30/49, Loss: 0.3065
Epoch 7/10, Batch 40/49, Loss: 0.2802
Epoch 7/10, Train Loss: 0.2732, Valid Loss: 0.3017
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2275
Epoch 8/10, Batch 20/49, Loss: 0.1558
Epoch 8/10, Batch 30/49, Loss: 0.2320
Epoch 8/10, Batch 40/49, Loss: 0.2591
Epoch 8/10, Train Loss: 0.2553, Valid Loss: 0.2870
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2190
Epoch 9/10, Batch 20/49, Loss: 0.1754
Epoch 9/10, Batch 30/49, Loss: 0.3340
Epoch 9/10, Batch 40/49, Loss: 0.1098
Epoch 9/10, Train Loss: 0.2260, Valid Loss: 0.2974
Epoch 10/10, Batch 10/49, Loss: 0.2112
Epoch 10/10, Batch 20/49, Loss: 0.1990
Epoch 10/10, Batch 30/49, Loss: 0.3101
Epoch 10/10, Batch 40/49, Loss: 0.2413
Epoch 10/10, Train Loss: 0.2138, Valid Loss: 0.2828
Model saved!
Accuracy: 0.8995
Precision: 0.8995
Recall: 0.8995
F1-score: 0.8948
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2627
Epoch 1/10, Batch 20/49, Loss: 1.0259
Epoch 1/10, Batch 30/49, Loss: 0.8355
Epoch 1/10, Batch 40/49, Loss: 0.7467
Epoch 1/10, Train Loss: 1.0028, Valid Loss: 0.6631
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7802
Epoch 2/10, Batch 20/49, Loss: 0.4574
Epoch 2/10, Batch 30/49, Loss: 0.5362
Epoch 2/10, Batch 40/49, Loss: 0.5158
Epoch 2/10, Train Loss: 0.5572, Valid Loss: 0.4870
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4434
Epoch 3/10, Batch 20/49, Loss: 0.3907
Epoch 3/10, Batch 30/49, Loss: 0.4704
Epoch 3/10, Batch 40/49, Loss: 0.3961
Epoch 3/10, Train Loss: 0.4364, Valid Loss: 0.4136
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3274
Epoch 4/10, Batch 20/49, Loss: 0.4013
Epoch 4/10, Batch 30/49, Loss: 0.2425
Epoch 4/10, Batch 40/49, Loss: 0.3156
Epoch 4/10, Train Loss: 0.3798, Valid Loss: 0.3556
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4177
Epoch 5/10, Batch 20/49, Loss: 0.2755
Epoch 5/10, Batch 30/49, Loss: 0.2719
Epoch 5/10, Batch 40/49, Loss: 0.2291
Epoch 5/10, Train Loss: 0.3141, Valid Loss: 0.3327
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2446
Epoch 6/10, Batch 20/49, Loss: 0.2814
Epoch 6/10, Batch 30/49, Loss: 0.3009
Epoch 6/10, Batch 40/49, Loss: 0.3502
Epoch 6/10, Train Loss: 0.3031, Valid Loss: 0.3287
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2048
Epoch 7/10, Batch 20/49, Loss: 0.1443
Epoch 7/10, Batch 30/49, Loss: 0.2774
Epoch 7/10, Batch 40/49, Loss: 0.2228
Epoch 7/10, Train Loss: 0.2795, Valid Loss: 0.3150
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1723
Epoch 8/10, Batch 20/49, Loss: 0.2675
Epoch 8/10, Batch 30/49, Loss: 0.3036
Epoch 8/10, Batch 40/49, Loss: 0.3146
Epoch 8/10, Train Loss: 0.2678, Valid Loss: 0.3070
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1349
Epoch 9/10, Batch 20/49, Loss: 0.2376
Epoch 9/10, Batch 30/49, Loss: 0.5062
Epoch 9/10, Batch 40/49, Loss: 0.3223
Epoch 9/10, Train Loss: 0.2559, Valid Loss: 0.2848
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1835
Epoch 10/10, Batch 20/49, Loss: 0.1981
Epoch 10/10, Batch 30/49, Loss: 0.2356
Epoch 10/10, Batch 40/49, Loss: 0.2638
Epoch 10/10, Train Loss: 0.2310, Valid Loss: 0.2761
Model saved!
Accuracy: 0.9019
Precision: 0.8995
Recall: 0.9019
F1-score: 0.9001
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2227
Epoch 1/10, Batch 20/49, Loss: 1.0554
Epoch 1/10, Batch 30/49, Loss: 0.8575
Epoch 1/10, Batch 40/49, Loss: 0.7733
Epoch 1/10, Train Loss: 0.9992, Valid Loss: 0.6199
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6966
Epoch 2/10, Batch 20/49, Loss: 0.4659
Epoch 2/10, Batch 30/49, Loss: 0.6236
Epoch 2/10, Batch 40/49, Loss: 0.5656
Epoch 2/10, Train Loss: 0.5510, Valid Loss: 0.4385
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.6090
Epoch 3/10, Batch 20/49, Loss: 0.5200
Epoch 3/10, Batch 30/49, Loss: 0.3944
Epoch 3/10, Batch 40/49, Loss: 0.3515
Epoch 3/10, Train Loss: 0.4350, Valid Loss: 0.3712
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2201
Epoch 4/10, Batch 20/49, Loss: 0.3838
Epoch 4/10, Batch 30/49, Loss: 0.2527
Epoch 4/10, Batch 40/49, Loss: 0.2582
Epoch 4/10, Train Loss: 0.3658, Valid Loss: 0.3237
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3619
Epoch 5/10, Batch 20/49, Loss: 0.2342
Epoch 5/10, Batch 30/49, Loss: 0.2415
Epoch 5/10, Batch 40/49, Loss: 0.2743
Epoch 5/10, Train Loss: 0.3172, Valid Loss: 0.2891
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3120
Epoch 6/10, Batch 20/49, Loss: 0.2326
Epoch 6/10, Batch 30/49, Loss: 0.3583
Epoch 6/10, Batch 40/49, Loss: 0.1660
Epoch 6/10, Train Loss: 0.2948, Valid Loss: 0.2854
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2782
Epoch 7/10, Batch 20/49, Loss: 0.2692
Epoch 7/10, Batch 30/49, Loss: 0.2788
Epoch 7/10, Batch 40/49, Loss: 0.2015
Epoch 7/10, Train Loss: 0.2723, Valid Loss: 0.2715
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2951
Epoch 8/10, Batch 20/49, Loss: 0.2343
Epoch 8/10, Batch 30/49, Loss: 0.2646
Epoch 8/10, Batch 40/49, Loss: 0.1678
Epoch 8/10, Train Loss: 0.2602, Valid Loss: 0.2628
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1236
Epoch 9/10, Batch 20/49, Loss: 0.1533
Epoch 9/10, Batch 30/49, Loss: 0.3698
Epoch 9/10, Batch 40/49, Loss: 0.3344
Epoch 9/10, Train Loss: 0.2552, Valid Loss: 0.2468
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2285
Epoch 10/10, Batch 20/49, Loss: 0.1348
Epoch 10/10, Batch 30/49, Loss: 0.1656
Epoch 10/10, Batch 40/49, Loss: 0.2930
Epoch 10/10, Train Loss: 0.2193, Valid Loss: 0.2422
Model saved!
Accuracy: 0.8995
Precision: 0.8953
Recall: 0.8995
F1-score: 0.8955
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2447
Epoch 1/10, Batch 20/49, Loss: 1.0782
Epoch 1/10, Batch 30/49, Loss: 0.7771
Epoch 1/10, Batch 40/49, Loss: 0.6991
Epoch 1/10, Train Loss: 1.0055, Valid Loss: 0.6690
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7715
Epoch 2/10, Batch 20/49, Loss: 0.5935
Epoch 2/10, Batch 30/49, Loss: 0.5072
Epoch 2/10, Batch 40/49, Loss: 0.5187
Epoch 2/10, Train Loss: 0.5531, Valid Loss: 0.5078
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4584
Epoch 3/10, Batch 20/49, Loss: 0.4239
Epoch 3/10, Batch 30/49, Loss: 0.3739
Epoch 3/10, Batch 40/49, Loss: 0.3732
Epoch 3/10, Train Loss: 0.4378, Valid Loss: 0.4243
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3293
Epoch 4/10, Batch 20/49, Loss: 0.4169
Epoch 4/10, Batch 30/49, Loss: 0.2849
Epoch 4/10, Batch 40/49, Loss: 0.3117
Epoch 4/10, Train Loss: 0.3767, Valid Loss: 0.3700
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4353
Epoch 5/10, Batch 20/49, Loss: 0.1817
Epoch 5/10, Batch 30/49, Loss: 0.2529
Epoch 5/10, Batch 40/49, Loss: 0.2269
Epoch 5/10, Train Loss: 0.3273, Valid Loss: 0.3478
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2242
Epoch 6/10, Batch 20/49, Loss: 0.2868
Epoch 6/10, Batch 30/49, Loss: 0.4626
Epoch 6/10, Batch 40/49, Loss: 0.2748
Epoch 6/10, Train Loss: 0.3091, Valid Loss: 0.3467
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2240
Epoch 7/10, Batch 20/49, Loss: 0.4188
Epoch 7/10, Batch 30/49, Loss: 0.3674
Epoch 7/10, Batch 40/49, Loss: 0.2157
Epoch 7/10, Train Loss: 0.2894, Valid Loss: 0.3428
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1653
Epoch 8/10, Batch 20/49, Loss: 0.3765
Epoch 8/10, Batch 30/49, Loss: 0.2094
Epoch 8/10, Batch 40/49, Loss: 0.1413
Epoch 8/10, Train Loss: 0.2756, Valid Loss: 0.3062
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1490
Epoch 9/10, Batch 20/49, Loss: 0.2263
Epoch 9/10, Batch 30/49, Loss: 0.3215
Epoch 9/10, Batch 40/49, Loss: 0.2328
Epoch 9/10, Train Loss: 0.2581, Valid Loss: 0.2942
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2373
Epoch 10/10, Batch 20/49, Loss: 0.1396
Epoch 10/10, Batch 30/49, Loss: 0.2270
Epoch 10/10, Batch 40/49, Loss: 0.3198
Epoch 10/10, Train Loss: 0.2346, Valid Loss: 0.2762
Model saved!
Accuracy: 0.8984
Precision: 0.8943
Recall: 0.8984
F1-score: 0.8935
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2479
Epoch 1/10, Batch 20/49, Loss: 1.0625
Epoch 1/10, Batch 30/49, Loss: 0.8382
Epoch 1/10, Batch 40/49, Loss: 0.8616
Epoch 1/10, Train Loss: 1.0136, Valid Loss: 0.6188
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6247
Epoch 2/10, Batch 20/49, Loss: 0.4995
Epoch 2/10, Batch 30/49, Loss: 0.5947
Epoch 2/10, Batch 40/49, Loss: 0.5598
Epoch 2/10, Train Loss: 0.5482, Valid Loss: 0.4506
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5016
Epoch 3/10, Batch 20/49, Loss: 0.4037
Epoch 3/10, Batch 30/49, Loss: 0.4806
Epoch 3/10, Batch 40/49, Loss: 0.5730
Epoch 3/10, Train Loss: 0.4413, Valid Loss: 0.3713
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2600
Epoch 4/10, Batch 20/49, Loss: 0.3965
Epoch 4/10, Batch 30/49, Loss: 0.3120
Epoch 4/10, Batch 40/49, Loss: 0.2481
Epoch 4/10, Train Loss: 0.3677, Valid Loss: 0.3333
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3022
Epoch 5/10, Batch 20/49, Loss: 0.2082
Epoch 5/10, Batch 30/49, Loss: 0.2598
Epoch 5/10, Batch 40/49, Loss: 0.2636
Epoch 5/10, Train Loss: 0.3277, Valid Loss: 0.3101
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3153
Epoch 6/10, Batch 20/49, Loss: 0.3300
Epoch 6/10, Batch 30/49, Loss: 0.3420
Epoch 6/10, Batch 40/49, Loss: 0.2434
Epoch 6/10, Train Loss: 0.2982, Valid Loss: 0.2985
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2430
Epoch 7/10, Batch 20/49, Loss: 0.1713
Epoch 7/10, Batch 30/49, Loss: 0.4589
Epoch 7/10, Batch 40/49, Loss: 0.3321
Epoch 7/10, Train Loss: 0.2777, Valid Loss: 0.2825
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3323
Epoch 8/10, Batch 20/49, Loss: 0.4517
Epoch 8/10, Batch 30/49, Loss: 0.2428
Epoch 8/10, Batch 40/49, Loss: 0.1985
Epoch 8/10, Train Loss: 0.2704, Valid Loss: 0.2749
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1550
Epoch 9/10, Batch 20/49, Loss: 0.2325
Epoch 9/10, Batch 30/49, Loss: 0.4813
Epoch 9/10, Batch 40/49, Loss: 0.1817
Epoch 9/10, Train Loss: 0.2360, Valid Loss: 0.2653
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2814
Epoch 10/10, Batch 20/49, Loss: 0.1701
Epoch 10/10, Batch 30/49, Loss: 0.2260
Epoch 10/10, Batch 40/49, Loss: 0.3114
Epoch 10/10, Train Loss: 0.2193, Valid Loss: 0.2691
Accuracy: 0.9089
Precision: 0.9062
Recall: 0.9089
F1-score: 0.9073
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3325
Epoch 1/10, Batch 20/49, Loss: 1.0238
Epoch 1/10, Batch 30/49, Loss: 0.8321
Epoch 1/10, Batch 40/49, Loss: 0.7699
Epoch 1/10, Train Loss: 1.0040, Valid Loss: 0.6372
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6062
Epoch 2/10, Batch 20/49, Loss: 0.4670
Epoch 2/10, Batch 30/49, Loss: 0.4370
Epoch 2/10, Batch 40/49, Loss: 0.5310
Epoch 2/10, Train Loss: 0.5346, Valid Loss: 0.4712
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3548
Epoch 3/10, Batch 20/49, Loss: 0.3678
Epoch 3/10, Batch 30/49, Loss: 0.3634
Epoch 3/10, Batch 40/49, Loss: 0.3695
Epoch 3/10, Train Loss: 0.4146, Valid Loss: 0.4078
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3484
Epoch 4/10, Batch 20/49, Loss: 0.4156
Epoch 4/10, Batch 30/49, Loss: 0.2595
Epoch 4/10, Batch 40/49, Loss: 0.2692
Epoch 4/10, Train Loss: 0.3643, Valid Loss: 0.3632
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4138
Epoch 5/10, Batch 20/49, Loss: 0.2577
Epoch 5/10, Batch 30/49, Loss: 0.2880
Epoch 5/10, Batch 40/49, Loss: 0.1805
Epoch 5/10, Train Loss: 0.3139, Valid Loss: 0.3396
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2070
Epoch 6/10, Batch 20/49, Loss: 0.2767
Epoch 6/10, Batch 30/49, Loss: 0.3951
Epoch 6/10, Batch 40/49, Loss: 0.3128
Epoch 6/10, Train Loss: 0.2741, Valid Loss: 0.3314
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2639
Epoch 7/10, Batch 20/49, Loss: 0.5227
Epoch 7/10, Batch 30/49, Loss: 0.2882
Epoch 7/10, Batch 40/49, Loss: 0.4207
Epoch 7/10, Train Loss: 0.2697, Valid Loss: 0.3314
Epoch 8/10, Batch 10/49, Loss: 0.3369
Epoch 8/10, Batch 20/49, Loss: 0.3103
Epoch 8/10, Batch 30/49, Loss: 0.2491
Epoch 8/10, Batch 40/49, Loss: 0.1752
Epoch 8/10, Train Loss: 0.2486, Valid Loss: 0.3142
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1892
Epoch 9/10, Batch 20/49, Loss: 0.2030
Epoch 9/10, Batch 30/49, Loss: 0.6200
Epoch 9/10, Batch 40/49, Loss: 0.2317
Epoch 9/10, Train Loss: 0.2324, Valid Loss: 0.3084
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3573
Epoch 10/10, Batch 20/49, Loss: 0.1408
Epoch 10/10, Batch 30/49, Loss: 0.2211
Epoch 10/10, Batch 40/49, Loss: 0.1906
Epoch 10/10, Train Loss: 0.2049, Valid Loss: 0.3074
Model saved!
Accuracy: 0.9042
Precision: 0.9016
Recall: 0.9042
F1-score: 0.9018
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2246
Epoch 1/10, Batch 20/49, Loss: 1.0183
Epoch 1/10, Batch 30/49, Loss: 0.7786
Epoch 1/10, Batch 40/49, Loss: 0.7493
Epoch 1/10, Train Loss: 0.9995, Valid Loss: 0.6332
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6713
Epoch 2/10, Batch 20/49, Loss: 0.4511
Epoch 2/10, Batch 30/49, Loss: 0.6397
Epoch 2/10, Batch 40/49, Loss: 0.5985
Epoch 2/10, Train Loss: 0.5276, Valid Loss: 0.4516
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4395
Epoch 3/10, Batch 20/49, Loss: 0.3881
Epoch 3/10, Batch 30/49, Loss: 0.4286
Epoch 3/10, Batch 40/49, Loss: 0.4265
Epoch 3/10, Train Loss: 0.4144, Valid Loss: 0.3888
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2220
Epoch 4/10, Batch 20/49, Loss: 0.3533
Epoch 4/10, Batch 30/49, Loss: 0.2153
Epoch 4/10, Batch 40/49, Loss: 0.3911
Epoch 4/10, Train Loss: 0.3582, Valid Loss: 0.3444
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4402
Epoch 5/10, Batch 20/49, Loss: 0.1585
Epoch 5/10, Batch 30/49, Loss: 0.3320
Epoch 5/10, Batch 40/49, Loss: 0.2359
Epoch 5/10, Train Loss: 0.2948, Valid Loss: 0.3229
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1977
Epoch 6/10, Batch 20/49, Loss: 0.3502
Epoch 6/10, Batch 30/49, Loss: 0.2586
Epoch 6/10, Batch 40/49, Loss: 0.1654
Epoch 6/10, Train Loss: 0.2742, Valid Loss: 0.3120
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2473
Epoch 7/10, Batch 20/49, Loss: 0.3649
Epoch 7/10, Batch 30/49, Loss: 0.2639
Epoch 7/10, Batch 40/49, Loss: 0.1853
Epoch 7/10, Train Loss: 0.2619, Valid Loss: 0.3035
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2348
Epoch 8/10, Batch 20/49, Loss: 0.2551
Epoch 8/10, Batch 30/49, Loss: 0.2943
Epoch 8/10, Batch 40/49, Loss: 0.2315
Epoch 8/10, Train Loss: 0.2489, Valid Loss: 0.2908
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1375
Epoch 9/10, Batch 20/49, Loss: 0.2942
Epoch 9/10, Batch 30/49, Loss: 0.3124
Epoch 9/10, Batch 40/49, Loss: 0.2544
Epoch 9/10, Train Loss: 0.2295, Valid Loss: 0.2753
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1981
Epoch 10/10, Batch 20/49, Loss: 0.1131
Epoch 10/10, Batch 30/49, Loss: 0.2437
Epoch 10/10, Batch 40/49, Loss: 0.1314
Epoch 10/10, Train Loss: 0.2038, Valid Loss: 0.2698
Model saved!
Accuracy: 0.9019
Precision: 0.8986
Recall: 0.9019
F1-score: 0.8984
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2826
Epoch 1/10, Batch 20/49, Loss: 1.0742
Epoch 1/10, Batch 30/49, Loss: 0.7838
Epoch 1/10, Batch 40/49, Loss: 0.7734
Epoch 1/10, Train Loss: 0.9963, Valid Loss: 0.6571
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7360
Epoch 2/10, Batch 20/49, Loss: 0.4473
Epoch 2/10, Batch 30/49, Loss: 0.5892
Epoch 2/10, Batch 40/49, Loss: 0.4929
Epoch 2/10, Train Loss: 0.5373, Valid Loss: 0.4812
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4342
Epoch 3/10, Batch 20/49, Loss: 0.4338
Epoch 3/10, Batch 30/49, Loss: 0.3875
Epoch 3/10, Batch 40/49, Loss: 0.3559
Epoch 3/10, Train Loss: 0.4093, Valid Loss: 0.4165
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2115
Epoch 4/10, Batch 20/49, Loss: 0.3063
Epoch 4/10, Batch 30/49, Loss: 0.2224
Epoch 4/10, Batch 40/49, Loss: 0.2189
Epoch 4/10, Train Loss: 0.3514, Valid Loss: 0.3664
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2215
Epoch 5/10, Batch 20/49, Loss: 0.2142
Epoch 5/10, Batch 30/49, Loss: 0.2789
Epoch 5/10, Batch 40/49, Loss: 0.2156
Epoch 5/10, Train Loss: 0.3050, Valid Loss: 0.3415
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2496
Epoch 6/10, Batch 20/49, Loss: 0.2773
Epoch 6/10, Batch 30/49, Loss: 0.4411
Epoch 6/10, Batch 40/49, Loss: 0.3008
Epoch 6/10, Train Loss: 0.2788, Valid Loss: 0.3385
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2259
Epoch 7/10, Batch 20/49, Loss: 0.2536
Epoch 7/10, Batch 30/49, Loss: 0.3919
Epoch 7/10, Batch 40/49, Loss: 0.1796
Epoch 7/10, Train Loss: 0.2553, Valid Loss: 0.3283
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1703
Epoch 8/10, Batch 20/49, Loss: 0.1946
Epoch 8/10, Batch 30/49, Loss: 0.2236
Epoch 8/10, Batch 40/49, Loss: 0.2230
Epoch 8/10, Train Loss: 0.2470, Valid Loss: 0.3126
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1638
Epoch 9/10, Batch 20/49, Loss: 0.2229
Epoch 9/10, Batch 30/49, Loss: 0.4226
Epoch 9/10, Batch 40/49, Loss: 0.1398
Epoch 9/10, Train Loss: 0.2309, Valid Loss: 0.3086
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1868
Epoch 10/10, Batch 20/49, Loss: 0.1742
Epoch 10/10, Batch 30/49, Loss: 0.1429
Epoch 10/10, Batch 40/49, Loss: 0.2368
Epoch 10/10, Train Loss: 0.2075, Valid Loss: 0.2874
Model saved!
Accuracy: 0.8960
Precision: 0.8908
Recall: 0.8960
F1-score: 0.8915
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2473
Epoch 1/10, Batch 20/49, Loss: 1.1188
Epoch 1/10, Batch 30/49, Loss: 0.8164
Epoch 1/10, Batch 40/49, Loss: 0.7830
Epoch 1/10, Train Loss: 0.9952, Valid Loss: 0.6595
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6893
Epoch 2/10, Batch 20/49, Loss: 0.6331
Epoch 2/10, Batch 30/49, Loss: 0.5854
Epoch 2/10, Batch 40/49, Loss: 0.5751
Epoch 2/10, Train Loss: 0.5385, Valid Loss: 0.4832
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4421
Epoch 3/10, Batch 20/49, Loss: 0.4350
Epoch 3/10, Batch 30/49, Loss: 0.3347
Epoch 3/10, Batch 40/49, Loss: 0.4057
Epoch 3/10, Train Loss: 0.4148, Valid Loss: 0.4111
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4380
Epoch 4/10, Batch 20/49, Loss: 0.3505
Epoch 4/10, Batch 30/49, Loss: 0.3208
Epoch 4/10, Batch 40/49, Loss: 0.3054
Epoch 4/10, Train Loss: 0.3651, Valid Loss: 0.3513
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3501
Epoch 5/10, Batch 20/49, Loss: 0.2473
Epoch 5/10, Batch 30/49, Loss: 0.2447
Epoch 5/10, Batch 40/49, Loss: 0.1869
Epoch 5/10, Train Loss: 0.3105, Valid Loss: 0.3302
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3856
Epoch 6/10, Batch 20/49, Loss: 0.3527
Epoch 6/10, Batch 30/49, Loss: 0.2794
Epoch 6/10, Batch 40/49, Loss: 0.2850
Epoch 6/10, Train Loss: 0.2914, Valid Loss: 0.3225
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3232
Epoch 7/10, Batch 20/49, Loss: 0.2607
Epoch 7/10, Batch 30/49, Loss: 0.4374
Epoch 7/10, Batch 40/49, Loss: 0.2810
Epoch 7/10, Train Loss: 0.2848, Valid Loss: 0.3130
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1155
Epoch 8/10, Batch 20/49, Loss: 0.3620
Epoch 8/10, Batch 30/49, Loss: 0.2468
Epoch 8/10, Batch 40/49, Loss: 0.2043
Epoch 8/10, Train Loss: 0.2628, Valid Loss: 0.2892
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1392
Epoch 9/10, Batch 20/49, Loss: 0.2245
Epoch 9/10, Batch 30/49, Loss: 0.4070
Epoch 9/10, Batch 40/49, Loss: 0.1953
Epoch 9/10, Train Loss: 0.2497, Valid Loss: 0.2821
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2659
Epoch 10/10, Batch 20/49, Loss: 0.2210
Epoch 10/10, Batch 30/49, Loss: 0.1726
Epoch 10/10, Batch 40/49, Loss: 0.1964
Epoch 10/10, Train Loss: 0.2192, Valid Loss: 0.2757
Model saved!
Accuracy: 0.8984
Precision: 0.8934
Recall: 0.8984
F1-score: 0.8942
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2258
Epoch 1/10, Batch 20/49, Loss: 1.0981
Epoch 1/10, Batch 30/49, Loss: 0.8565
Epoch 1/10, Batch 40/49, Loss: 0.8133
Epoch 1/10, Train Loss: 0.9838, Valid Loss: 0.6759
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5366
Epoch 2/10, Batch 20/49, Loss: 0.4502
Epoch 2/10, Batch 30/49, Loss: 0.4670
Epoch 2/10, Batch 40/49, Loss: 0.5394
Epoch 2/10, Train Loss: 0.5350, Valid Loss: 0.4991
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4352
Epoch 3/10, Batch 20/49, Loss: 0.4810
Epoch 3/10, Batch 30/49, Loss: 0.2792
Epoch 3/10, Batch 40/49, Loss: 0.3691
Epoch 3/10, Train Loss: 0.4121, Valid Loss: 0.4396
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3185
Epoch 4/10, Batch 20/49, Loss: 0.3431
Epoch 4/10, Batch 30/49, Loss: 0.2783
Epoch 4/10, Batch 40/49, Loss: 0.3544
Epoch 4/10, Train Loss: 0.3539, Valid Loss: 0.3686
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3367
Epoch 5/10, Batch 20/49, Loss: 0.2452
Epoch 5/10, Batch 30/49, Loss: 0.3424
Epoch 5/10, Batch 40/49, Loss: 0.2226
Epoch 5/10, Train Loss: 0.3128, Valid Loss: 0.3595
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1958
Epoch 6/10, Batch 20/49, Loss: 0.3138
Epoch 6/10, Batch 30/49, Loss: 0.3900
Epoch 6/10, Batch 40/49, Loss: 0.3152
Epoch 6/10, Train Loss: 0.2864, Valid Loss: 0.3344
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2468
Epoch 7/10, Batch 20/49, Loss: 0.2066
Epoch 7/10, Batch 30/49, Loss: 0.3070
Epoch 7/10, Batch 40/49, Loss: 0.2614
Epoch 7/10, Train Loss: 0.2655, Valid Loss: 0.3443
Epoch 8/10, Batch 10/49, Loss: 0.2233
Epoch 8/10, Batch 20/49, Loss: 0.2119
Epoch 8/10, Batch 30/49, Loss: 0.1838
Epoch 8/10, Batch 40/49, Loss: 0.3039
Epoch 8/10, Train Loss: 0.2527, Valid Loss: 0.3171
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2368
Epoch 9/10, Batch 20/49, Loss: 0.2725
Epoch 9/10, Batch 30/49, Loss: 0.4208
Epoch 9/10, Batch 40/49, Loss: 0.1880
Epoch 9/10, Train Loss: 0.2321, Valid Loss: 0.3046
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2918
Epoch 10/10, Batch 20/49, Loss: 0.1149
Epoch 10/10, Batch 30/49, Loss: 0.1860
Epoch 10/10, Batch 40/49, Loss: 0.2186
Epoch 10/10, Train Loss: 0.2099, Valid Loss: 0.2760
Model saved!
Accuracy: 0.9030
Precision: 0.8992
Recall: 0.9030
F1-score: 0.8991
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2698
Epoch 1/10, Batch 20/49, Loss: 1.0220
Epoch 1/10, Batch 30/49, Loss: 0.8346
Epoch 1/10, Batch 40/49, Loss: 0.7300
Epoch 1/10, Train Loss: 0.9865, Valid Loss: 0.6326
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7021
Epoch 2/10, Batch 20/49, Loss: 0.4164
Epoch 2/10, Batch 30/49, Loss: 0.5371
Epoch 2/10, Batch 40/49, Loss: 0.5246
Epoch 2/10, Train Loss: 0.5234, Valid Loss: 0.4499
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3693
Epoch 3/10, Batch 20/49, Loss: 0.3845
Epoch 3/10, Batch 30/49, Loss: 0.3737
Epoch 3/10, Batch 40/49, Loss: 0.2990
Epoch 3/10, Train Loss: 0.4040, Valid Loss: 0.3796
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2669
Epoch 4/10, Batch 20/49, Loss: 0.4042
Epoch 4/10, Batch 30/49, Loss: 0.2907
Epoch 4/10, Batch 40/49, Loss: 0.4052
Epoch 4/10, Train Loss: 0.3435, Valid Loss: 0.3373
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2341
Epoch 5/10, Batch 20/49, Loss: 0.1705
Epoch 5/10, Batch 30/49, Loss: 0.3350
Epoch 5/10, Batch 40/49, Loss: 0.2516
Epoch 5/10, Train Loss: 0.2965, Valid Loss: 0.3145
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2633
Epoch 6/10, Batch 20/49, Loss: 0.3027
Epoch 6/10, Batch 30/49, Loss: 0.3121
Epoch 6/10, Batch 40/49, Loss: 0.1223
Epoch 6/10, Train Loss: 0.2670, Valid Loss: 0.3019
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2047
Epoch 7/10, Batch 20/49, Loss: 0.3176
Epoch 7/10, Batch 30/49, Loss: 0.2748
Epoch 7/10, Batch 40/49, Loss: 0.2199
Epoch 7/10, Train Loss: 0.2541, Valid Loss: 0.2868
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1429
Epoch 8/10, Batch 20/49, Loss: 0.1601
Epoch 8/10, Batch 30/49, Loss: 0.2099
Epoch 8/10, Batch 40/49, Loss: 0.1225
Epoch 8/10, Train Loss: 0.2405, Valid Loss: 0.2752
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1267
Epoch 9/10, Batch 20/49, Loss: 0.2478
Epoch 9/10, Batch 30/49, Loss: 0.4281
Epoch 9/10, Batch 40/49, Loss: 0.1870
Epoch 9/10, Train Loss: 0.2255, Valid Loss: 0.2790
Epoch 10/10, Batch 10/49, Loss: 0.3326
Epoch 10/10, Batch 20/49, Loss: 0.1661
Epoch 10/10, Batch 30/49, Loss: 0.2081
Epoch 10/10, Batch 40/49, Loss: 0.1978
Epoch 10/10, Train Loss: 0.1988, Valid Loss: 0.2582
Model saved!
Accuracy: 0.9042
Precision: 0.9014
Recall: 0.9042
F1-score: 0.9011
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2822
Epoch 1/10, Batch 20/49, Loss: 0.9391
Epoch 1/10, Batch 30/49, Loss: 0.8472
Epoch 1/10, Batch 40/49, Loss: 0.7633
Epoch 1/10, Train Loss: 0.9906, Valid Loss: 0.6192
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6854
Epoch 2/10, Batch 20/49, Loss: 0.4627
Epoch 2/10, Batch 30/49, Loss: 0.5597
Epoch 2/10, Batch 40/49, Loss: 0.3613
Epoch 2/10, Train Loss: 0.5342, Valid Loss: 0.4505
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3832
Epoch 3/10, Batch 20/49, Loss: 0.4832
Epoch 3/10, Batch 30/49, Loss: 0.3550
Epoch 3/10, Batch 40/49, Loss: 0.4914
Epoch 3/10, Train Loss: 0.4062, Valid Loss: 0.3766
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2858
Epoch 4/10, Batch 20/49, Loss: 0.3969
Epoch 4/10, Batch 30/49, Loss: 0.2732
Epoch 4/10, Batch 40/49, Loss: 0.2787
Epoch 4/10, Train Loss: 0.3555, Valid Loss: 0.3455
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4004
Epoch 5/10, Batch 20/49, Loss: 0.2784
Epoch 5/10, Batch 30/49, Loss: 0.2455
Epoch 5/10, Batch 40/49, Loss: 0.2256
Epoch 5/10, Train Loss: 0.2997, Valid Loss: 0.3264
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1669
Epoch 6/10, Batch 20/49, Loss: 0.2808
Epoch 6/10, Batch 30/49, Loss: 0.2642
Epoch 6/10, Batch 40/49, Loss: 0.3121
Epoch 6/10, Train Loss: 0.2749, Valid Loss: 0.3152
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2435
Epoch 7/10, Batch 20/49, Loss: 0.1908
Epoch 7/10, Batch 30/49, Loss: 0.4278
Epoch 7/10, Batch 40/49, Loss: 0.1921
Epoch 7/10, Train Loss: 0.2497, Valid Loss: 0.3095
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1446
Epoch 8/10, Batch 20/49, Loss: 0.1806
Epoch 8/10, Batch 30/49, Loss: 0.1515
Epoch 8/10, Batch 40/49, Loss: 0.2195
Epoch 8/10, Train Loss: 0.2418, Valid Loss: 0.2904
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1236
Epoch 9/10, Batch 20/49, Loss: 0.1263
Epoch 9/10, Batch 30/49, Loss: 0.4184
Epoch 9/10, Batch 40/49, Loss: 0.1791
Epoch 9/10, Train Loss: 0.2179, Valid Loss: 0.2915
Epoch 10/10, Batch 10/49, Loss: 0.2048
Epoch 10/10, Batch 20/49, Loss: 0.1292
Epoch 10/10, Batch 30/49, Loss: 0.2165
Epoch 10/10, Batch 40/49, Loss: 0.1659
Epoch 10/10, Train Loss: 0.2088, Valid Loss: 0.2802
Model saved!
Accuracy: 0.9054
Precision: 0.9023
Recall: 0.9054
F1-score: 0.9013
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2860
Epoch 1/10, Batch 20/49, Loss: 1.0645
Epoch 1/10, Batch 30/49, Loss: 0.8945
Epoch 1/10, Batch 40/49, Loss: 0.8330
Epoch 1/10, Train Loss: 0.9985, Valid Loss: 0.6508
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5358
Epoch 2/10, Batch 20/49, Loss: 0.4321
Epoch 2/10, Batch 30/49, Loss: 0.6641
Epoch 2/10, Batch 40/49, Loss: 0.6331
Epoch 2/10, Train Loss: 0.5298, Valid Loss: 0.4686
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5020
Epoch 3/10, Batch 20/49, Loss: 0.4314
Epoch 3/10, Batch 30/49, Loss: 0.2949
Epoch 3/10, Batch 40/49, Loss: 0.2925
Epoch 3/10, Train Loss: 0.4002, Valid Loss: 0.4034
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3620
Epoch 4/10, Batch 20/49, Loss: 0.3363
Epoch 4/10, Batch 30/49, Loss: 0.2865
Epoch 4/10, Batch 40/49, Loss: 0.3045
Epoch 4/10, Train Loss: 0.3459, Valid Loss: 0.3594
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2202
Epoch 5/10, Batch 20/49, Loss: 0.3010
Epoch 5/10, Batch 30/49, Loss: 0.2572
Epoch 5/10, Batch 40/49, Loss: 0.2294
Epoch 5/10, Train Loss: 0.2923, Valid Loss: 0.3367
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2168
Epoch 6/10, Batch 20/49, Loss: 0.2068
Epoch 6/10, Batch 30/49, Loss: 0.3392
Epoch 6/10, Batch 40/49, Loss: 0.2112
Epoch 6/10, Train Loss: 0.2677, Valid Loss: 0.3109
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1854
Epoch 7/10, Batch 20/49, Loss: 0.2310
Epoch 7/10, Batch 30/49, Loss: 0.2920
Epoch 7/10, Batch 40/49, Loss: 0.2056
Epoch 7/10, Train Loss: 0.2509, Valid Loss: 0.3108
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1821
Epoch 8/10, Batch 20/49, Loss: 0.3891
Epoch 8/10, Batch 30/49, Loss: 0.2814
Epoch 8/10, Batch 40/49, Loss: 0.2416
Epoch 8/10, Train Loss: 0.2410, Valid Loss: 0.2874
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1789
Epoch 9/10, Batch 20/49, Loss: 0.1704
Epoch 9/10, Batch 30/49, Loss: 0.3665
Epoch 9/10, Batch 40/49, Loss: 0.2453
Epoch 9/10, Train Loss: 0.2219, Valid Loss: 0.2770
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1252
Epoch 10/10, Batch 20/49, Loss: 0.0879
Epoch 10/10, Batch 30/49, Loss: 0.2047
Epoch 10/10, Batch 40/49, Loss: 0.1988
Epoch 10/10, Train Loss: 0.2067, Valid Loss: 0.2655
Model saved!
Accuracy: 0.9077
Precision: 0.9029
Recall: 0.9077
F1-score: 0.9035
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2792
Epoch 1/10, Batch 20/49, Loss: 1.1413
Epoch 1/10, Batch 30/49, Loss: 0.8022
Epoch 1/10, Batch 40/49, Loss: 0.7833
Epoch 1/10, Train Loss: 0.9997, Valid Loss: 0.6534
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6298
Epoch 2/10, Batch 20/49, Loss: 0.5704
Epoch 2/10, Batch 30/49, Loss: 0.6162
Epoch 2/10, Batch 40/49, Loss: 0.5214
Epoch 2/10, Train Loss: 0.5363, Valid Loss: 0.4956
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3892
Epoch 3/10, Batch 20/49, Loss: 0.4050
Epoch 3/10, Batch 30/49, Loss: 0.3450
Epoch 3/10, Batch 40/49, Loss: 0.3086
Epoch 3/10, Train Loss: 0.4099, Valid Loss: 0.4301
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3277
Epoch 4/10, Batch 20/49, Loss: 0.4930
Epoch 4/10, Batch 30/49, Loss: 0.2925
Epoch 4/10, Batch 40/49, Loss: 0.2690
Epoch 4/10, Train Loss: 0.3560, Valid Loss: 0.3798
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2974
Epoch 5/10, Batch 20/49, Loss: 0.1991
Epoch 5/10, Batch 30/49, Loss: 0.2830
Epoch 5/10, Batch 40/49, Loss: 0.1878
Epoch 5/10, Train Loss: 0.3071, Valid Loss: 0.3570
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3227
Epoch 6/10, Batch 20/49, Loss: 0.2711
Epoch 6/10, Batch 30/49, Loss: 0.3636
Epoch 6/10, Batch 40/49, Loss: 0.1385
Epoch 6/10, Train Loss: 0.2900, Valid Loss: 0.3577
Epoch 7/10, Batch 10/49, Loss: 0.2221
Epoch 7/10, Batch 20/49, Loss: 0.1466
Epoch 7/10, Batch 30/49, Loss: 0.4213
Epoch 7/10, Batch 40/49, Loss: 0.1400
Epoch 7/10, Train Loss: 0.2575, Valid Loss: 0.3398
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3130
Epoch 8/10, Batch 20/49, Loss: 0.2780
Epoch 8/10, Batch 30/49, Loss: 0.2269
Epoch 8/10, Batch 40/49, Loss: 0.3390
Epoch 8/10, Train Loss: 0.2624, Valid Loss: 0.3211
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1561
Epoch 9/10, Batch 20/49, Loss: 0.2227
Epoch 9/10, Batch 30/49, Loss: 0.6337
Epoch 9/10, Batch 40/49, Loss: 0.1755
Epoch 9/10, Train Loss: 0.2343, Valid Loss: 0.3101
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2902
Epoch 10/10, Batch 20/49, Loss: 0.1341
Epoch 10/10, Batch 30/49, Loss: 0.2900
Epoch 10/10, Batch 40/49, Loss: 0.1547
Epoch 10/10, Train Loss: 0.2132, Valid Loss: 0.3052
Model saved!
Accuracy: 0.9065
Precision: 0.9036
Recall: 0.9065
F1-score: 0.9044
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2182
Epoch 1/10, Batch 20/49, Loss: 1.0268
Epoch 1/10, Batch 30/49, Loss: 0.8862
Epoch 1/10, Batch 40/49, Loss: 0.7377
Epoch 1/10, Train Loss: 0.9974, Valid Loss: 0.6543
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6372
Epoch 2/10, Batch 20/49, Loss: 0.5190
Epoch 2/10, Batch 30/49, Loss: 0.4672
Epoch 2/10, Batch 40/49, Loss: 0.4490
Epoch 2/10, Train Loss: 0.5355, Valid Loss: 0.4808
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5580
Epoch 3/10, Batch 20/49, Loss: 0.3983
Epoch 3/10, Batch 30/49, Loss: 0.3230
Epoch 3/10, Batch 40/49, Loss: 0.4466
Epoch 3/10, Train Loss: 0.4142, Valid Loss: 0.3977
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2685
Epoch 4/10, Batch 20/49, Loss: 0.5572
Epoch 4/10, Batch 30/49, Loss: 0.3152
Epoch 4/10, Batch 40/49, Loss: 0.3013
Epoch 4/10, Train Loss: 0.3625, Valid Loss: 0.3367
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2213
Epoch 5/10, Batch 20/49, Loss: 0.2917
Epoch 5/10, Batch 30/49, Loss: 0.3440
Epoch 5/10, Batch 40/49, Loss: 0.2364
Epoch 5/10, Train Loss: 0.3138, Valid Loss: 0.3276
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2429
Epoch 6/10, Batch 20/49, Loss: 0.2691
Epoch 6/10, Batch 30/49, Loss: 0.2710
Epoch 6/10, Batch 40/49, Loss: 0.2998
Epoch 6/10, Train Loss: 0.2959, Valid Loss: 0.3104
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2915
Epoch 7/10, Batch 20/49, Loss: 0.2172
Epoch 7/10, Batch 30/49, Loss: 0.2233
Epoch 7/10, Batch 40/49, Loss: 0.1808
Epoch 7/10, Train Loss: 0.2733, Valid Loss: 0.3157
Epoch 8/10, Batch 10/49, Loss: 0.1760
Epoch 8/10, Batch 20/49, Loss: 0.2149
Epoch 8/10, Batch 30/49, Loss: 0.1632
Epoch 8/10, Batch 40/49, Loss: 0.1958
Epoch 8/10, Train Loss: 0.2587, Valid Loss: 0.2901
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1975
Epoch 9/10, Batch 20/49, Loss: 0.2230
Epoch 9/10, Batch 30/49, Loss: 0.3987
Epoch 9/10, Batch 40/49, Loss: 0.1622
Epoch 9/10, Train Loss: 0.2325, Valid Loss: 0.2705
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3604
Epoch 10/10, Batch 20/49, Loss: 0.1409
Epoch 10/10, Batch 30/49, Loss: 0.1621
Epoch 10/10, Batch 40/49, Loss: 0.1684
Epoch 10/10, Train Loss: 0.2176, Valid Loss: 0.2652
Model saved!
Accuracy: 0.9077
Precision: 0.9036
Recall: 0.9077
F1-score: 0.9045
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2814
Epoch 1/10, Batch 20/49, Loss: 1.0583
Epoch 1/10, Batch 30/49, Loss: 0.8864
Epoch 1/10, Batch 40/49, Loss: 0.7033
Epoch 1/10, Train Loss: 0.9870, Valid Loss: 0.6740
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6002
Epoch 2/10, Batch 20/49, Loss: 0.3491
Epoch 2/10, Batch 30/49, Loss: 0.5493
Epoch 2/10, Batch 40/49, Loss: 0.6245
Epoch 2/10, Train Loss: 0.5311, Valid Loss: 0.4889
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5085
Epoch 3/10, Batch 20/49, Loss: 0.4753
Epoch 3/10, Batch 30/49, Loss: 0.4728
Epoch 3/10, Batch 40/49, Loss: 0.4358
Epoch 3/10, Train Loss: 0.4220, Valid Loss: 0.4179
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2803
Epoch 4/10, Batch 20/49, Loss: 0.4624
Epoch 4/10, Batch 30/49, Loss: 0.2142
Epoch 4/10, Batch 40/49, Loss: 0.2019
Epoch 4/10, Train Loss: 0.3624, Valid Loss: 0.3685
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3169
Epoch 5/10, Batch 20/49, Loss: 0.4462
Epoch 5/10, Batch 30/49, Loss: 0.3188
Epoch 5/10, Batch 40/49, Loss: 0.1978
Epoch 5/10, Train Loss: 0.3038, Valid Loss: 0.3471
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2220
Epoch 6/10, Batch 20/49, Loss: 0.2627
Epoch 6/10, Batch 30/49, Loss: 0.3371
Epoch 6/10, Batch 40/49, Loss: 0.3463
Epoch 6/10, Train Loss: 0.2815, Valid Loss: 0.3391
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3135
Epoch 7/10, Batch 20/49, Loss: 0.2146
Epoch 7/10, Batch 30/49, Loss: 0.3174
Epoch 7/10, Batch 40/49, Loss: 0.1195
Epoch 7/10, Train Loss: 0.2765, Valid Loss: 0.3292
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2136
Epoch 8/10, Batch 20/49, Loss: 0.2565
Epoch 8/10, Batch 30/49, Loss: 0.3254
Epoch 8/10, Batch 40/49, Loss: 0.2560
Epoch 8/10, Train Loss: 0.2560, Valid Loss: 0.3076
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2902
Epoch 9/10, Batch 20/49, Loss: 0.1597
Epoch 9/10, Batch 30/49, Loss: 0.5694
Epoch 9/10, Batch 40/49, Loss: 0.1739
Epoch 9/10, Train Loss: 0.2417, Valid Loss: 0.3033
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2066
Epoch 10/10, Batch 20/49, Loss: 0.1597
Epoch 10/10, Batch 30/49, Loss: 0.3950
Epoch 10/10, Batch 40/49, Loss: 0.1498
Epoch 10/10, Train Loss: 0.2079, Valid Loss: 0.2932
Model saved!
Accuracy: 0.9030
Precision: 0.8973
Recall: 0.9030
F1-score: 0.8987
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2811
Epoch 1/10, Batch 20/49, Loss: 1.1108
Epoch 1/10, Batch 30/49, Loss: 0.9065
Epoch 1/10, Batch 40/49, Loss: 0.8265
Epoch 1/10, Train Loss: 0.9987, Valid Loss: 0.6373
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7387
Epoch 2/10, Batch 20/49, Loss: 0.4981
Epoch 2/10, Batch 30/49, Loss: 0.5899
Epoch 2/10, Batch 40/49, Loss: 0.5439
Epoch 2/10, Train Loss: 0.5435, Valid Loss: 0.4671
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4120
Epoch 3/10, Batch 20/49, Loss: 0.3860
Epoch 3/10, Batch 30/49, Loss: 0.3315
Epoch 3/10, Batch 40/49, Loss: 0.5159
Epoch 3/10, Train Loss: 0.4190, Valid Loss: 0.3887
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2211
Epoch 4/10, Batch 20/49, Loss: 0.3764
Epoch 4/10, Batch 30/49, Loss: 0.2434
Epoch 4/10, Batch 40/49, Loss: 0.2953
Epoch 4/10, Train Loss: 0.3711, Valid Loss: 0.3458
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2400
Epoch 5/10, Batch 20/49, Loss: 0.2068
Epoch 5/10, Batch 30/49, Loss: 0.3002
Epoch 5/10, Batch 40/49, Loss: 0.2966
Epoch 5/10, Train Loss: 0.3228, Valid Loss: 0.3126
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2572
Epoch 6/10, Batch 20/49, Loss: 0.2998
Epoch 6/10, Batch 30/49, Loss: 0.2766
Epoch 6/10, Batch 40/49, Loss: 0.2884
Epoch 6/10, Train Loss: 0.2920, Valid Loss: 0.3011
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2071
Epoch 7/10, Batch 20/49, Loss: 0.1360
Epoch 7/10, Batch 30/49, Loss: 0.4023
Epoch 7/10, Batch 40/49, Loss: 0.2964
Epoch 7/10, Train Loss: 0.2701, Valid Loss: 0.2915
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3924
Epoch 8/10, Batch 20/49, Loss: 0.2599
Epoch 8/10, Batch 30/49, Loss: 0.2016
Epoch 8/10, Batch 40/49, Loss: 0.1380
Epoch 8/10, Train Loss: 0.2676, Valid Loss: 0.2751
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2298
Epoch 9/10, Batch 20/49, Loss: 0.2466
Epoch 9/10, Batch 30/49, Loss: 0.3774
Epoch 9/10, Batch 40/49, Loss: 0.1729
Epoch 9/10, Train Loss: 0.2382, Valid Loss: 0.2581
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2312
Epoch 10/10, Batch 20/49, Loss: 0.2723
Epoch 10/10, Batch 30/49, Loss: 0.2749
Epoch 10/10, Batch 40/49, Loss: 0.3870
Epoch 10/10, Train Loss: 0.2288, Valid Loss: 0.2576
Model saved!
Accuracy: 0.8995
Precision: 0.8955
Recall: 0.8995
F1-score: 0.8932
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2293
Epoch 1/10, Batch 20/49, Loss: 1.1097
Epoch 1/10, Batch 30/49, Loss: 0.8266
Epoch 1/10, Batch 40/49, Loss: 0.6990
Epoch 1/10, Train Loss: 1.0031, Valid Loss: 0.6867
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6984
Epoch 2/10, Batch 20/49, Loss: 0.4054
Epoch 2/10, Batch 30/49, Loss: 0.3986
Epoch 2/10, Batch 40/49, Loss: 0.5625
Epoch 2/10, Train Loss: 0.5432, Valid Loss: 0.5064
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5361
Epoch 3/10, Batch 20/49, Loss: 0.4195
Epoch 3/10, Batch 30/49, Loss: 0.4577
Epoch 3/10, Batch 40/49, Loss: 0.4934
Epoch 3/10, Train Loss: 0.4280, Valid Loss: 0.4466
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3997
Epoch 4/10, Batch 20/49, Loss: 0.3195
Epoch 4/10, Batch 30/49, Loss: 0.2780
Epoch 4/10, Batch 40/49, Loss: 0.2680
Epoch 4/10, Train Loss: 0.3655, Valid Loss: 0.3936
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3807
Epoch 5/10, Batch 20/49, Loss: 0.1786
Epoch 5/10, Batch 30/49, Loss: 0.2607
Epoch 5/10, Batch 40/49, Loss: 0.1861
Epoch 5/10, Train Loss: 0.3173, Valid Loss: 0.3697
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3436
Epoch 6/10, Batch 20/49, Loss: 0.2979
Epoch 6/10, Batch 30/49, Loss: 0.2441
Epoch 6/10, Batch 40/49, Loss: 0.3255
Epoch 6/10, Train Loss: 0.3079, Valid Loss: 0.3689
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2543
Epoch 7/10, Batch 20/49, Loss: 0.4808
Epoch 7/10, Batch 30/49, Loss: 0.4914
Epoch 7/10, Batch 40/49, Loss: 0.2223
Epoch 7/10, Train Loss: 0.2883, Valid Loss: 0.3550
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2617
Epoch 8/10, Batch 20/49, Loss: 0.2013
Epoch 8/10, Batch 30/49, Loss: 0.2790
Epoch 8/10, Batch 40/49, Loss: 0.1828
Epoch 8/10, Train Loss: 0.2673, Valid Loss: 0.3360
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2176
Epoch 9/10, Batch 20/49, Loss: 0.1961
Epoch 9/10, Batch 30/49, Loss: 0.4013
Epoch 9/10, Batch 40/49, Loss: 0.1976
Epoch 9/10, Train Loss: 0.2561, Valid Loss: 0.3135
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1456
Epoch 10/10, Batch 20/49, Loss: 0.3116
Epoch 10/10, Batch 30/49, Loss: 0.3377
Epoch 10/10, Batch 40/49, Loss: 0.2706
Epoch 10/10, Train Loss: 0.2214, Valid Loss: 0.3167
Accuracy: 0.9065
Precision: 0.9031
Recall: 0.9065
F1-score: 0.9043
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3057
Epoch 1/10, Batch 20/49, Loss: 1.0373
Epoch 1/10, Batch 30/49, Loss: 0.8475
Epoch 1/10, Batch 40/49, Loss: 0.8424
Epoch 1/10, Train Loss: 0.9993, Valid Loss: 0.6544
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5762
Epoch 2/10, Batch 20/49, Loss: 0.3850
Epoch 2/10, Batch 30/49, Loss: 0.4995
Epoch 2/10, Batch 40/49, Loss: 0.4843
Epoch 2/10, Train Loss: 0.5289, Valid Loss: 0.4904
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5600
Epoch 3/10, Batch 20/49, Loss: 0.4544
Epoch 3/10, Batch 30/49, Loss: 0.4166
Epoch 3/10, Batch 40/49, Loss: 0.3798
Epoch 3/10, Train Loss: 0.4050, Valid Loss: 0.4181
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2647
Epoch 4/10, Batch 20/49, Loss: 0.2134
Epoch 4/10, Batch 30/49, Loss: 0.3541
Epoch 4/10, Batch 40/49, Loss: 0.3896
Epoch 4/10, Train Loss: 0.3505, Valid Loss: 0.3779
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2842
Epoch 5/10, Batch 20/49, Loss: 0.2202
Epoch 5/10, Batch 30/49, Loss: 0.2282
Epoch 5/10, Batch 40/49, Loss: 0.2058
Epoch 5/10, Train Loss: 0.2891, Valid Loss: 0.3552
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2921
Epoch 6/10, Batch 20/49, Loss: 0.2436
Epoch 6/10, Batch 30/49, Loss: 0.3083
Epoch 6/10, Batch 40/49, Loss: 0.2785
Epoch 6/10, Train Loss: 0.2662, Valid Loss: 0.3470
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3084
Epoch 7/10, Batch 20/49, Loss: 0.2272
Epoch 7/10, Batch 30/49, Loss: 0.2550
Epoch 7/10, Batch 40/49, Loss: 0.1401
Epoch 7/10, Train Loss: 0.2497, Valid Loss: 0.3343
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1313
Epoch 8/10, Batch 20/49, Loss: 0.2063
Epoch 8/10, Batch 30/49, Loss: 0.2272
Epoch 8/10, Batch 40/49, Loss: 0.2464
Epoch 8/10, Train Loss: 0.2385, Valid Loss: 0.3301
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1193
Epoch 9/10, Batch 20/49, Loss: 0.1196
Epoch 9/10, Batch 30/49, Loss: 0.4031
Epoch 9/10, Batch 40/49, Loss: 0.2031
Epoch 9/10, Train Loss: 0.2223, Valid Loss: 0.3114
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1764
Epoch 10/10, Batch 20/49, Loss: 0.1146
Epoch 10/10, Batch 30/49, Loss: 0.2455
Epoch 10/10, Batch 40/49, Loss: 0.2352
Epoch 10/10, Train Loss: 0.2037, Valid Loss: 0.3092
Model saved!
Accuracy: 0.8972
Precision: 0.8931
Recall: 0.8972
F1-score: 0.8947
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2695
Epoch 1/10, Batch 20/49, Loss: 1.0079
Epoch 1/10, Batch 30/49, Loss: 0.7881
Epoch 1/10, Batch 40/49, Loss: 0.7831
Epoch 1/10, Train Loss: 0.9878, Valid Loss: 0.6605
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6332
Epoch 2/10, Batch 20/49, Loss: 0.4096
Epoch 2/10, Batch 30/49, Loss: 0.4683
Epoch 2/10, Batch 40/49, Loss: 0.5884
Epoch 2/10, Train Loss: 0.5172, Valid Loss: 0.4767
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3346
Epoch 3/10, Batch 20/49, Loss: 0.3573
Epoch 3/10, Batch 30/49, Loss: 0.3912
Epoch 3/10, Batch 40/49, Loss: 0.2680
Epoch 3/10, Train Loss: 0.4028, Valid Loss: 0.4139
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.1844
Epoch 4/10, Batch 20/49, Loss: 0.5173
Epoch 4/10, Batch 30/49, Loss: 0.2478
Epoch 4/10, Batch 40/49, Loss: 0.2701
Epoch 4/10, Train Loss: 0.3525, Valid Loss: 0.3720
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3370
Epoch 5/10, Batch 20/49, Loss: 0.2027
Epoch 5/10, Batch 30/49, Loss: 0.2358
Epoch 5/10, Batch 40/49, Loss: 0.2534
Epoch 5/10, Train Loss: 0.2959, Valid Loss: 0.3563
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2081
Epoch 6/10, Batch 20/49, Loss: 0.2844
Epoch 6/10, Batch 30/49, Loss: 0.2447
Epoch 6/10, Batch 40/49, Loss: 0.2250
Epoch 6/10, Train Loss: 0.2690, Valid Loss: 0.3279
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2459
Epoch 7/10, Batch 20/49, Loss: 0.1607
Epoch 7/10, Batch 30/49, Loss: 0.4110
Epoch 7/10, Batch 40/49, Loss: 0.1897
Epoch 7/10, Train Loss: 0.2456, Valid Loss: 0.3281
Epoch 8/10, Batch 10/49, Loss: 0.2911
Epoch 8/10, Batch 20/49, Loss: 0.2374
Epoch 8/10, Batch 30/49, Loss: 0.1704
Epoch 8/10, Batch 40/49, Loss: 0.1821
Epoch 8/10, Train Loss: 0.2465, Valid Loss: 0.3275
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1692
Epoch 9/10, Batch 20/49, Loss: 0.1763
Epoch 9/10, Batch 30/49, Loss: 0.4306
Epoch 9/10, Batch 40/49, Loss: 0.1313
Epoch 9/10, Train Loss: 0.2083, Valid Loss: 0.3229
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1823
Epoch 10/10, Batch 20/49, Loss: 0.1025
Epoch 10/10, Batch 30/49, Loss: 0.2430
Epoch 10/10, Batch 40/49, Loss: 0.2051
Epoch 10/10, Train Loss: 0.1967, Valid Loss: 0.3135
Model saved!
Accuracy: 0.9054
Precision: 0.9021
Recall: 0.9054
F1-score: 0.9027
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2555
Epoch 1/10, Batch 20/49, Loss: 1.0383
Epoch 1/10, Batch 30/49, Loss: 0.9053
Epoch 1/10, Batch 40/49, Loss: 0.7971
Epoch 1/10, Train Loss: 0.9932, Valid Loss: 0.6417
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5981
Epoch 2/10, Batch 20/49, Loss: 0.4820
Epoch 2/10, Batch 30/49, Loss: 0.6003
Epoch 2/10, Batch 40/49, Loss: 0.4671
Epoch 2/10, Train Loss: 0.5307, Valid Loss: 0.4544
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4210
Epoch 3/10, Batch 20/49, Loss: 0.5486
Epoch 3/10, Batch 30/49, Loss: 0.3991
Epoch 3/10, Batch 40/49, Loss: 0.2742
Epoch 3/10, Train Loss: 0.4188, Valid Loss: 0.3875
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2543
Epoch 4/10, Batch 20/49, Loss: 0.3265
Epoch 4/10, Batch 30/49, Loss: 0.2696
Epoch 4/10, Batch 40/49, Loss: 0.2853
Epoch 4/10, Train Loss: 0.3544, Valid Loss: 0.3516
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3674
Epoch 5/10, Batch 20/49, Loss: 0.2812
Epoch 5/10, Batch 30/49, Loss: 0.2903
Epoch 5/10, Batch 40/49, Loss: 0.2272
Epoch 5/10, Train Loss: 0.2971, Valid Loss: 0.3185
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2226
Epoch 6/10, Batch 20/49, Loss: 0.2979
Epoch 6/10, Batch 30/49, Loss: 0.3566
Epoch 6/10, Batch 40/49, Loss: 0.2971
Epoch 6/10, Train Loss: 0.2733, Valid Loss: 0.3099
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2647
Epoch 7/10, Batch 20/49, Loss: 0.2368
Epoch 7/10, Batch 30/49, Loss: 0.3618
Epoch 7/10, Batch 40/49, Loss: 0.1222
Epoch 7/10, Train Loss: 0.2643, Valid Loss: 0.2921
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1573
Epoch 8/10, Batch 20/49, Loss: 0.1794
Epoch 8/10, Batch 30/49, Loss: 0.2619
Epoch 8/10, Batch 40/49, Loss: 0.1803
Epoch 8/10, Train Loss: 0.2437, Valid Loss: 0.2871
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2152
Epoch 9/10, Batch 20/49, Loss: 0.1393
Epoch 9/10, Batch 30/49, Loss: 0.4831
Epoch 9/10, Batch 40/49, Loss: 0.1814
Epoch 9/10, Train Loss: 0.2310, Valid Loss: 0.2865
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3026
Epoch 10/10, Batch 20/49, Loss: 0.1556
Epoch 10/10, Batch 30/49, Loss: 0.2219
Epoch 10/10, Batch 40/49, Loss: 0.2991
Epoch 10/10, Train Loss: 0.2049, Valid Loss: 0.2755
Model saved!
Accuracy: 0.8995
Precision: 0.8950
Recall: 0.8995
F1-score: 0.8948
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3250
Epoch 1/10, Batch 20/49, Loss: 1.0795
Epoch 1/10, Batch 30/49, Loss: 0.8693
Epoch 1/10, Batch 40/49, Loss: 0.7347
Epoch 1/10, Train Loss: 0.9945, Valid Loss: 0.6401
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7345
Epoch 2/10, Batch 20/49, Loss: 0.4150
Epoch 2/10, Batch 30/49, Loss: 0.5550
Epoch 2/10, Batch 40/49, Loss: 0.4009
Epoch 2/10, Train Loss: 0.5259, Valid Loss: 0.4803
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4725
Epoch 3/10, Batch 20/49, Loss: 0.3650
Epoch 3/10, Batch 30/49, Loss: 0.4185
Epoch 3/10, Batch 40/49, Loss: 0.3500
Epoch 3/10, Train Loss: 0.4217, Valid Loss: 0.4270
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2876
Epoch 4/10, Batch 20/49, Loss: 0.4108
Epoch 4/10, Batch 30/49, Loss: 0.2048
Epoch 4/10, Batch 40/49, Loss: 0.3150
Epoch 4/10, Train Loss: 0.3571, Valid Loss: 0.3796
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2748
Epoch 5/10, Batch 20/49, Loss: 0.1789
Epoch 5/10, Batch 30/49, Loss: 0.3176
Epoch 5/10, Batch 40/49, Loss: 0.4156
Epoch 5/10, Train Loss: 0.3055, Valid Loss: 0.3684
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3065
Epoch 6/10, Batch 20/49, Loss: 0.3568
Epoch 6/10, Batch 30/49, Loss: 0.3091
Epoch 6/10, Batch 40/49, Loss: 0.2453
Epoch 6/10, Train Loss: 0.2863, Valid Loss: 0.3567
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2782
Epoch 7/10, Batch 20/49, Loss: 0.1982
Epoch 7/10, Batch 30/49, Loss: 0.3190
Epoch 7/10, Batch 40/49, Loss: 0.1776
Epoch 7/10, Train Loss: 0.2634, Valid Loss: 0.3641
Epoch 8/10, Batch 10/49, Loss: 0.2630
Epoch 8/10, Batch 20/49, Loss: 0.1792
Epoch 8/10, Batch 30/49, Loss: 0.2426
Epoch 8/10, Batch 40/49, Loss: 0.2067
Epoch 8/10, Train Loss: 0.2475, Valid Loss: 0.3452
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2529
Epoch 9/10, Batch 20/49, Loss: 0.1718
Epoch 9/10, Batch 30/49, Loss: 0.6448
Epoch 9/10, Batch 40/49, Loss: 0.1450
Epoch 9/10, Train Loss: 0.2320, Valid Loss: 0.3278
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3672
Epoch 10/10, Batch 20/49, Loss: 0.1035
Epoch 10/10, Batch 30/49, Loss: 0.1657
Epoch 10/10, Batch 40/49, Loss: 0.1805
Epoch 10/10, Train Loss: 0.2179, Valid Loss: 0.3218
Model saved!
Accuracy: 0.8995
Precision: 0.8963
Recall: 0.8995
F1-score: 0.8951
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2620
Epoch 1/10, Batch 20/49, Loss: 1.0670
Epoch 1/10, Batch 30/49, Loss: 0.7654
Epoch 1/10, Batch 40/49, Loss: 0.8350
Epoch 1/10, Train Loss: 1.0053, Valid Loss: 0.6256
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6559
Epoch 2/10, Batch 20/49, Loss: 0.4491
Epoch 2/10, Batch 30/49, Loss: 0.5010
Epoch 2/10, Batch 40/49, Loss: 0.5277
Epoch 2/10, Train Loss: 0.5360, Valid Loss: 0.4447
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4633
Epoch 3/10, Batch 20/49, Loss: 0.4240
Epoch 3/10, Batch 30/49, Loss: 0.3516
Epoch 3/10, Batch 40/49, Loss: 0.4035
Epoch 3/10, Train Loss: 0.4198, Valid Loss: 0.3769
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3533
Epoch 4/10, Batch 20/49, Loss: 0.3548
Epoch 4/10, Batch 30/49, Loss: 0.2488
Epoch 4/10, Batch 40/49, Loss: 0.3527
Epoch 4/10, Train Loss: 0.3620, Valid Loss: 0.3321
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.1773
Epoch 5/10, Batch 20/49, Loss: 0.1520
Epoch 5/10, Batch 30/49, Loss: 0.2338
Epoch 5/10, Batch 40/49, Loss: 0.3041
Epoch 5/10, Train Loss: 0.3035, Valid Loss: 0.3152
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2382
Epoch 6/10, Batch 20/49, Loss: 0.3259
Epoch 6/10, Batch 30/49, Loss: 0.2446
Epoch 6/10, Batch 40/49, Loss: 0.3414
Epoch 6/10, Train Loss: 0.2768, Valid Loss: 0.3097
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2791
Epoch 7/10, Batch 20/49, Loss: 0.2591
Epoch 7/10, Batch 30/49, Loss: 0.3859
Epoch 7/10, Batch 40/49, Loss: 0.2584
Epoch 7/10, Train Loss: 0.2605, Valid Loss: 0.2979
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2183
Epoch 8/10, Batch 20/49, Loss: 0.2292
Epoch 8/10, Batch 30/49, Loss: 0.2711
Epoch 8/10, Batch 40/49, Loss: 0.2474
Epoch 8/10, Train Loss: 0.2414, Valid Loss: 0.2773
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1488
Epoch 9/10, Batch 20/49, Loss: 0.2770
Epoch 9/10, Batch 30/49, Loss: 0.3375
Epoch 9/10, Batch 40/49, Loss: 0.2093
Epoch 9/10, Train Loss: 0.2291, Valid Loss: 0.2673
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2269
Epoch 10/10, Batch 20/49, Loss: 0.0771
Epoch 10/10, Batch 30/49, Loss: 0.2709
Epoch 10/10, Batch 40/49, Loss: 0.2749
Epoch 10/10, Train Loss: 0.2046, Valid Loss: 0.2622
Model saved!
Accuracy: 0.9065
Precision: 0.9048
Recall: 0.9065
F1-score: 0.9035
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2331
Epoch 1/10, Batch 20/49, Loss: 1.0118
Epoch 1/10, Batch 30/49, Loss: 0.7536
Epoch 1/10, Batch 40/49, Loss: 0.8061
Epoch 1/10, Train Loss: 0.9956, Valid Loss: 0.6715
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5675
Epoch 2/10, Batch 20/49, Loss: 0.4725
Epoch 2/10, Batch 30/49, Loss: 0.5966
Epoch 2/10, Batch 40/49, Loss: 0.5348
Epoch 2/10, Train Loss: 0.5348, Valid Loss: 0.5093
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4760
Epoch 3/10, Batch 20/49, Loss: 0.4243
Epoch 3/10, Batch 30/49, Loss: 0.3494
Epoch 3/10, Batch 40/49, Loss: 0.3853
Epoch 3/10, Train Loss: 0.4097, Valid Loss: 0.4496
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3469
Epoch 4/10, Batch 20/49, Loss: 0.4159
Epoch 4/10, Batch 30/49, Loss: 0.2269
Epoch 4/10, Batch 40/49, Loss: 0.2081
Epoch 4/10, Train Loss: 0.3586, Valid Loss: 0.3985
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3300
Epoch 5/10, Batch 20/49, Loss: 0.2089
Epoch 5/10, Batch 30/49, Loss: 0.2317
Epoch 5/10, Batch 40/49, Loss: 0.1343
Epoch 5/10, Train Loss: 0.3095, Valid Loss: 0.3720
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1595
Epoch 6/10, Batch 20/49, Loss: 0.2254
Epoch 6/10, Batch 30/49, Loss: 0.3473
Epoch 6/10, Batch 40/49, Loss: 0.2937
Epoch 6/10, Train Loss: 0.2846, Valid Loss: 0.3665
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2506
Epoch 7/10, Batch 20/49, Loss: 0.1910
Epoch 7/10, Batch 30/49, Loss: 0.3849
Epoch 7/10, Batch 40/49, Loss: 0.1661
Epoch 7/10, Train Loss: 0.2625, Valid Loss: 0.3649
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2411
Epoch 8/10, Batch 20/49, Loss: 0.1990
Epoch 8/10, Batch 30/49, Loss: 0.1924
Epoch 8/10, Batch 40/49, Loss: 0.1982
Epoch 8/10, Train Loss: 0.2449, Valid Loss: 0.3383
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2710
Epoch 9/10, Batch 20/49, Loss: 0.1813
Epoch 9/10, Batch 30/49, Loss: 0.5868
Epoch 9/10, Batch 40/49, Loss: 0.2348
Epoch 9/10, Train Loss: 0.2411, Valid Loss: 0.3379
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2037
Epoch 10/10, Batch 20/49, Loss: 0.2360
Epoch 10/10, Batch 30/49, Loss: 0.1655
Epoch 10/10, Batch 40/49, Loss: 0.2272
Epoch 10/10, Train Loss: 0.2012, Valid Loss: 0.3273
Model saved!
Accuracy: 0.9042
Precision: 0.9013
Recall: 0.9042
F1-score: 0.9015
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2398
Epoch 1/10, Batch 20/49, Loss: 1.0408
Epoch 1/10, Batch 30/49, Loss: 0.8281
Epoch 1/10, Batch 40/49, Loss: 0.8058
Epoch 1/10, Train Loss: 1.0026, Valid Loss: 0.6233
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6052
Epoch 2/10, Batch 20/49, Loss: 0.5141
Epoch 2/10, Batch 30/49, Loss: 0.4771
Epoch 2/10, Batch 40/49, Loss: 0.3470
Epoch 2/10, Train Loss: 0.5376, Valid Loss: 0.4664
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4856
Epoch 3/10, Batch 20/49, Loss: 0.3962
Epoch 3/10, Batch 30/49, Loss: 0.3180
Epoch 3/10, Batch 40/49, Loss: 0.3996
Epoch 3/10, Train Loss: 0.4227, Valid Loss: 0.3796
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3263
Epoch 4/10, Batch 20/49, Loss: 0.3814
Epoch 4/10, Batch 30/49, Loss: 0.2361
Epoch 4/10, Batch 40/49, Loss: 0.2382
Epoch 4/10, Train Loss: 0.3733, Valid Loss: 0.3300
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3193
Epoch 5/10, Batch 20/49, Loss: 0.1854
Epoch 5/10, Batch 30/49, Loss: 0.2583
Epoch 5/10, Batch 40/49, Loss: 0.2273
Epoch 5/10, Train Loss: 0.3176, Valid Loss: 0.3061
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2264
Epoch 6/10, Batch 20/49, Loss: 0.2927
Epoch 6/10, Batch 30/49, Loss: 0.3179
Epoch 6/10, Batch 40/49, Loss: 0.2253
Epoch 6/10, Train Loss: 0.2904, Valid Loss: 0.3006
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3863
Epoch 7/10, Batch 20/49, Loss: 0.2628
Epoch 7/10, Batch 30/49, Loss: 0.4262
Epoch 7/10, Batch 40/49, Loss: 0.1343
Epoch 7/10, Train Loss: 0.2696, Valid Loss: 0.3014
Epoch 8/10, Batch 10/49, Loss: 0.2059
Epoch 8/10, Batch 20/49, Loss: 0.2154
Epoch 8/10, Batch 30/49, Loss: 0.2614
Epoch 8/10, Batch 40/49, Loss: 0.1794
Epoch 8/10, Train Loss: 0.2479, Valid Loss: 0.2771
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1660
Epoch 9/10, Batch 20/49, Loss: 0.3168
Epoch 9/10, Batch 30/49, Loss: 0.4131
Epoch 9/10, Batch 40/49, Loss: 0.1692
Epoch 9/10, Train Loss: 0.2450, Valid Loss: 0.2650
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3598
Epoch 10/10, Batch 20/49, Loss: 0.2097
Epoch 10/10, Batch 30/49, Loss: 0.2714
Epoch 10/10, Batch 40/49, Loss: 0.1708
Epoch 10/10, Train Loss: 0.2140, Valid Loss: 0.2559
Model saved!
Accuracy: 0.8995
Precision: 0.8972
Recall: 0.8995
F1-score: 0.8944
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3027
Epoch 1/10, Batch 20/49, Loss: 1.0515
Epoch 1/10, Batch 30/49, Loss: 0.8069
Epoch 1/10, Batch 40/49, Loss: 0.7569
Epoch 1/10, Train Loss: 1.0002, Valid Loss: 0.6925
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6996
Epoch 2/10, Batch 20/49, Loss: 0.4172
Epoch 2/10, Batch 30/49, Loss: 0.5388
Epoch 2/10, Batch 40/49, Loss: 0.5469
Epoch 2/10, Train Loss: 0.5352, Valid Loss: 0.5208
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3432
Epoch 3/10, Batch 20/49, Loss: 0.4153
Epoch 3/10, Batch 30/49, Loss: 0.3883
Epoch 3/10, Batch 40/49, Loss: 0.2258
Epoch 3/10, Train Loss: 0.4141, Valid Loss: 0.4459
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2672
Epoch 4/10, Batch 20/49, Loss: 0.3508
Epoch 4/10, Batch 30/49, Loss: 0.3511
Epoch 4/10, Batch 40/49, Loss: 0.3952
Epoch 4/10, Train Loss: 0.3658, Valid Loss: 0.3958
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2765
Epoch 5/10, Batch 20/49, Loss: 0.1660
Epoch 5/10, Batch 30/49, Loss: 0.3373
Epoch 5/10, Batch 40/49, Loss: 0.2008
Epoch 5/10, Train Loss: 0.2962, Valid Loss: 0.3741
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1728
Epoch 6/10, Batch 20/49, Loss: 0.2725
Epoch 6/10, Batch 30/49, Loss: 0.2973
Epoch 6/10, Batch 40/49, Loss: 0.2652
Epoch 6/10, Train Loss: 0.2724, Valid Loss: 0.3624
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1939
Epoch 7/10, Batch 20/49, Loss: 0.2434
Epoch 7/10, Batch 30/49, Loss: 0.4675
Epoch 7/10, Batch 40/49, Loss: 0.1883
Epoch 7/10, Train Loss: 0.2658, Valid Loss: 0.3571
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2797
Epoch 8/10, Batch 20/49, Loss: 0.3511
Epoch 8/10, Batch 30/49, Loss: 0.2341
Epoch 8/10, Batch 40/49, Loss: 0.2536
Epoch 8/10, Train Loss: 0.2546, Valid Loss: 0.3488
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1566
Epoch 9/10, Batch 20/49, Loss: 0.1594
Epoch 9/10, Batch 30/49, Loss: 0.4647
Epoch 9/10, Batch 40/49, Loss: 0.1399
Epoch 9/10, Train Loss: 0.2254, Valid Loss: 0.3225
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2015
Epoch 10/10, Batch 20/49, Loss: 0.1232
Epoch 10/10, Batch 30/49, Loss: 0.2514
Epoch 10/10, Batch 40/49, Loss: 0.3212
Epoch 10/10, Train Loss: 0.2100, Valid Loss: 0.3215
Model saved!
Accuracy: 0.9112
Precision: 0.9079
Recall: 0.9112
F1-score: 0.9082
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2562
Epoch 1/10, Batch 20/49, Loss: 0.9964
Epoch 1/10, Batch 30/49, Loss: 0.8376
Epoch 1/10, Batch 40/49, Loss: 0.6910
Epoch 1/10, Train Loss: 1.0048, Valid Loss: 0.6602
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6565
Epoch 2/10, Batch 20/49, Loss: 0.4321
Epoch 2/10, Batch 30/49, Loss: 0.6033
Epoch 2/10, Batch 40/49, Loss: 0.4711
Epoch 2/10, Train Loss: 0.5395, Valid Loss: 0.4945
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4730
Epoch 3/10, Batch 20/49, Loss: 0.4977
Epoch 3/10, Batch 30/49, Loss: 0.3148
Epoch 3/10, Batch 40/49, Loss: 0.4210
Epoch 3/10, Train Loss: 0.4224, Valid Loss: 0.4431
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3512
Epoch 4/10, Batch 20/49, Loss: 0.3458
Epoch 4/10, Batch 30/49, Loss: 0.3599
Epoch 4/10, Batch 40/49, Loss: 0.2546
Epoch 4/10, Train Loss: 0.3647, Valid Loss: 0.3863
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3241
Epoch 5/10, Batch 20/49, Loss: 0.2421
Epoch 5/10, Batch 30/49, Loss: 0.2669
Epoch 5/10, Batch 40/49, Loss: 0.2039
Epoch 5/10, Train Loss: 0.3101, Valid Loss: 0.3679
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2688
Epoch 6/10, Batch 20/49, Loss: 0.2999
Epoch 6/10, Batch 30/49, Loss: 0.3305
Epoch 6/10, Batch 40/49, Loss: 0.1549
Epoch 6/10, Train Loss: 0.2929, Valid Loss: 0.3736
Epoch 7/10, Batch 10/49, Loss: 0.3262
Epoch 7/10, Batch 20/49, Loss: 0.1703
Epoch 7/10, Batch 30/49, Loss: 0.2827
Epoch 7/10, Batch 40/49, Loss: 0.2263
Epoch 7/10, Train Loss: 0.2704, Valid Loss: 0.3622
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2729
Epoch 8/10, Batch 20/49, Loss: 0.2011
Epoch 8/10, Batch 30/49, Loss: 0.2504
Epoch 8/10, Batch 40/49, Loss: 0.2436
Epoch 8/10, Train Loss: 0.2438, Valid Loss: 0.3252
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1481
Epoch 9/10, Batch 20/49, Loss: 0.1972
Epoch 9/10, Batch 30/49, Loss: 0.3323
Epoch 9/10, Batch 40/49, Loss: 0.3147
Epoch 9/10, Train Loss: 0.2390, Valid Loss: 0.3315
Epoch 10/10, Batch 10/49, Loss: 0.2501
Epoch 10/10, Batch 20/49, Loss: 0.1796
Epoch 10/10, Batch 30/49, Loss: 0.2044
Epoch 10/10, Batch 40/49, Loss: 0.2671
Epoch 10/10, Train Loss: 0.2151, Valid Loss: 0.3076
Model saved!
Accuracy: 0.9100
Precision: 0.9070
Recall: 0.9100
F1-score: 0.9062
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2455
Epoch 1/10, Batch 20/49, Loss: 1.0876
Epoch 1/10, Batch 30/49, Loss: 0.8722
Epoch 1/10, Batch 40/49, Loss: 0.6138
Epoch 1/10, Train Loss: 1.0202, Valid Loss: 0.5924
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7188
Epoch 2/10, Batch 20/49, Loss: 0.4418
Epoch 2/10, Batch 30/49, Loss: 0.5830
Epoch 2/10, Batch 40/49, Loss: 0.4983
Epoch 2/10, Train Loss: 0.5454, Valid Loss: 0.4196
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5443
Epoch 3/10, Batch 20/49, Loss: 0.3751
Epoch 3/10, Batch 30/49, Loss: 0.4328
Epoch 3/10, Batch 40/49, Loss: 0.3213
Epoch 3/10, Train Loss: 0.4279, Valid Loss: 0.3508
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3030
Epoch 4/10, Batch 20/49, Loss: 0.4600
Epoch 4/10, Batch 30/49, Loss: 0.2940
Epoch 4/10, Batch 40/49, Loss: 0.2524
Epoch 4/10, Train Loss: 0.3738, Valid Loss: 0.3080
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2199
Epoch 5/10, Batch 20/49, Loss: 0.3347
Epoch 5/10, Batch 30/49, Loss: 0.3281
Epoch 5/10, Batch 40/49, Loss: 0.2793
Epoch 5/10, Train Loss: 0.3163, Valid Loss: 0.2924
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2798
Epoch 6/10, Batch 20/49, Loss: 0.3381
Epoch 6/10, Batch 30/49, Loss: 0.3189
Epoch 6/10, Batch 40/49, Loss: 0.2969
Epoch 6/10, Train Loss: 0.2857, Valid Loss: 0.2799
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2119
Epoch 7/10, Batch 20/49, Loss: 0.1619
Epoch 7/10, Batch 30/49, Loss: 0.4377
Epoch 7/10, Batch 40/49, Loss: 0.1718
Epoch 7/10, Train Loss: 0.2676, Valid Loss: 0.2786
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2562
Epoch 8/10, Batch 20/49, Loss: 0.1652
Epoch 8/10, Batch 30/49, Loss: 0.1797
Epoch 8/10, Batch 40/49, Loss: 0.2874
Epoch 8/10, Train Loss: 0.2606, Valid Loss: 0.2613
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2056
Epoch 9/10, Batch 20/49, Loss: 0.2063
Epoch 9/10, Batch 30/49, Loss: 0.4696
Epoch 9/10, Batch 40/49, Loss: 0.1883
Epoch 9/10, Train Loss: 0.2398, Valid Loss: 0.2549
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1917
Epoch 10/10, Batch 20/49, Loss: 0.1454
Epoch 10/10, Batch 30/49, Loss: 0.2499
Epoch 10/10, Batch 40/49, Loss: 0.2536
Epoch 10/10, Train Loss: 0.2183, Valid Loss: 0.2502
Model saved!
Accuracy: 0.9065
Precision: 0.9041
Recall: 0.9065
F1-score: 0.9027
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2333
Epoch 1/10, Batch 20/49, Loss: 1.0604
Epoch 1/10, Batch 30/49, Loss: 0.8446
Epoch 1/10, Batch 40/49, Loss: 0.7317
Epoch 1/10, Train Loss: 1.0049, Valid Loss: 0.6885
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6549
Epoch 2/10, Batch 20/49, Loss: 0.6363
Epoch 2/10, Batch 30/49, Loss: 0.5647
Epoch 2/10, Batch 40/49, Loss: 0.4464
Epoch 2/10, Train Loss: 0.5508, Valid Loss: 0.5312
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4978
Epoch 3/10, Batch 20/49, Loss: 0.4108
Epoch 3/10, Batch 30/49, Loss: 0.4749
Epoch 3/10, Batch 40/49, Loss: 0.4095
Epoch 3/10, Train Loss: 0.4328, Valid Loss: 0.4859
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3074
Epoch 4/10, Batch 20/49, Loss: 0.4638
Epoch 4/10, Batch 30/49, Loss: 0.3813
Epoch 4/10, Batch 40/49, Loss: 0.2859
Epoch 4/10, Train Loss: 0.3764, Valid Loss: 0.4265
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2521
Epoch 5/10, Batch 20/49, Loss: 0.2472
Epoch 5/10, Batch 30/49, Loss: 0.1987
Epoch 5/10, Batch 40/49, Loss: 0.2469
Epoch 5/10, Train Loss: 0.3110, Valid Loss: 0.4316
Epoch 6/10, Batch 10/49, Loss: 0.2193
Epoch 6/10, Batch 20/49, Loss: 0.2135
Epoch 6/10, Batch 30/49, Loss: 0.3667
Epoch 6/10, Batch 40/49, Loss: 0.3224
Epoch 6/10, Train Loss: 0.3016, Valid Loss: 0.4181
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1811
Epoch 7/10, Batch 20/49, Loss: 0.2311
Epoch 7/10, Batch 30/49, Loss: 0.2451
Epoch 7/10, Batch 40/49, Loss: 0.1658
Epoch 7/10, Train Loss: 0.2942, Valid Loss: 0.4268
Epoch 8/10, Batch 10/49, Loss: 0.1911
Epoch 8/10, Batch 20/49, Loss: 0.3171
Epoch 8/10, Batch 30/49, Loss: 0.3035
Epoch 8/10, Batch 40/49, Loss: 0.2503
Epoch 8/10, Train Loss: 0.2643, Valid Loss: 0.3956
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.0883
Epoch 9/10, Batch 20/49, Loss: 0.2086
Epoch 9/10, Batch 30/49, Loss: 0.3098
Epoch 9/10, Batch 40/49, Loss: 0.1572
Epoch 9/10, Train Loss: 0.2434, Valid Loss: 0.4095
Epoch 10/10, Batch 10/49, Loss: 0.1779
Epoch 10/10, Batch 20/49, Loss: 0.0954
Epoch 10/10, Batch 30/49, Loss: 0.3570
Epoch 10/10, Batch 40/49, Loss: 0.2743
Epoch 10/10, Train Loss: 0.2273, Valid Loss: 0.3902
Model saved!
Accuracy: 0.9089
Precision: 0.9051
Recall: 0.9089
F1-score: 0.9061
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2276
Epoch 1/10, Batch 20/49, Loss: 1.1224
Epoch 1/10, Batch 30/49, Loss: 0.7951
Epoch 1/10, Batch 40/49, Loss: 0.7277
Epoch 1/10, Train Loss: 0.9929, Valid Loss: 0.6328
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5878
Epoch 2/10, Batch 20/49, Loss: 0.4175
Epoch 2/10, Batch 30/49, Loss: 0.5530
Epoch 2/10, Batch 40/49, Loss: 0.5133
Epoch 2/10, Train Loss: 0.5349, Valid Loss: 0.4644
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3931
Epoch 3/10, Batch 20/49, Loss: 0.4834
Epoch 3/10, Batch 30/49, Loss: 0.2973
Epoch 3/10, Batch 40/49, Loss: 0.2229
Epoch 3/10, Train Loss: 0.4164, Valid Loss: 0.3921
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2927
Epoch 4/10, Batch 20/49, Loss: 0.2865
Epoch 4/10, Batch 30/49, Loss: 0.3309
Epoch 4/10, Batch 40/49, Loss: 0.3408
Epoch 4/10, Train Loss: 0.3624, Valid Loss: 0.3630
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.1943
Epoch 5/10, Batch 20/49, Loss: 0.2853
Epoch 5/10, Batch 30/49, Loss: 0.2704
Epoch 5/10, Batch 40/49, Loss: 0.2175
Epoch 5/10, Train Loss: 0.3051, Valid Loss: 0.3314
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1963
Epoch 6/10, Batch 20/49, Loss: 0.3320
Epoch 6/10, Batch 30/49, Loss: 0.1992
Epoch 6/10, Batch 40/49, Loss: 0.2938
Epoch 6/10, Train Loss: 0.2838, Valid Loss: 0.3284
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2039
Epoch 7/10, Batch 20/49, Loss: 0.1740
Epoch 7/10, Batch 30/49, Loss: 0.4848
Epoch 7/10, Batch 40/49, Loss: 0.2159
Epoch 7/10, Train Loss: 0.2540, Valid Loss: 0.3133
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3047
Epoch 8/10, Batch 20/49, Loss: 0.2306
Epoch 8/10, Batch 30/49, Loss: 0.1687
Epoch 8/10, Batch 40/49, Loss: 0.2720
Epoch 8/10, Train Loss: 0.2451, Valid Loss: 0.3076
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1530
Epoch 9/10, Batch 20/49, Loss: 0.1537
Epoch 9/10, Batch 30/49, Loss: 0.3689
Epoch 9/10, Batch 40/49, Loss: 0.2690
Epoch 9/10, Train Loss: 0.2276, Valid Loss: 0.2966
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2036
Epoch 10/10, Batch 20/49, Loss: 0.0874
Epoch 10/10, Batch 30/49, Loss: 0.1551
Epoch 10/10, Batch 40/49, Loss: 0.1895
Epoch 10/10, Train Loss: 0.2141, Valid Loss: 0.3067
Accuracy: 0.9019
Precision: 0.8983
Recall: 0.9019
F1-score: 0.8993
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3031
Epoch 1/10, Batch 20/49, Loss: 1.0958
Epoch 1/10, Batch 30/49, Loss: 0.7761
Epoch 1/10, Batch 40/49, Loss: 0.8081
Epoch 1/10, Train Loss: 1.0088, Valid Loss: 0.6801
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6457
Epoch 2/10, Batch 20/49, Loss: 0.4636
Epoch 2/10, Batch 30/49, Loss: 0.6610
Epoch 2/10, Batch 40/49, Loss: 0.6095
Epoch 2/10, Train Loss: 0.5501, Valid Loss: 0.4951
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4236
Epoch 3/10, Batch 20/49, Loss: 0.4146
Epoch 3/10, Batch 30/49, Loss: 0.4717
Epoch 3/10, Batch 40/49, Loss: 0.4371
Epoch 3/10, Train Loss: 0.4224, Valid Loss: 0.4149
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3280
Epoch 4/10, Batch 20/49, Loss: 0.4218
Epoch 4/10, Batch 30/49, Loss: 0.2307
Epoch 4/10, Batch 40/49, Loss: 0.2621
Epoch 4/10, Train Loss: 0.3730, Valid Loss: 0.3697
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3364
Epoch 5/10, Batch 20/49, Loss: 0.2596
Epoch 5/10, Batch 30/49, Loss: 0.2358
Epoch 5/10, Batch 40/49, Loss: 0.2547
Epoch 5/10, Train Loss: 0.3198, Valid Loss: 0.3429
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2277
Epoch 6/10, Batch 20/49, Loss: 0.3378
Epoch 6/10, Batch 30/49, Loss: 0.3247
Epoch 6/10, Batch 40/49, Loss: 0.2724
Epoch 6/10, Train Loss: 0.3018, Valid Loss: 0.3359
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3247
Epoch 7/10, Batch 20/49, Loss: 0.2554
Epoch 7/10, Batch 30/49, Loss: 0.2886
Epoch 7/10, Batch 40/49, Loss: 0.2651
Epoch 7/10, Train Loss: 0.2744, Valid Loss: 0.3260
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1575
Epoch 8/10, Batch 20/49, Loss: 0.2966
Epoch 8/10, Batch 30/49, Loss: 0.2052
Epoch 8/10, Batch 40/49, Loss: 0.2196
Epoch 8/10, Train Loss: 0.2566, Valid Loss: 0.2998
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1107
Epoch 9/10, Batch 20/49, Loss: 0.3401
Epoch 9/10, Batch 30/49, Loss: 0.4589
Epoch 9/10, Batch 40/49, Loss: 0.2470
Epoch 9/10, Train Loss: 0.2523, Valid Loss: 0.2925
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2254
Epoch 10/10, Batch 20/49, Loss: 0.3539
Epoch 10/10, Batch 30/49, Loss: 0.2677
Epoch 10/10, Batch 40/49, Loss: 0.1448
Epoch 10/10, Train Loss: 0.2213, Valid Loss: 0.2826
Model saved!
Accuracy: 0.8972
Precision: 0.8937
Recall: 0.8972
F1-score: 0.8940
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2663
Epoch 1/10, Batch 20/49, Loss: 1.1312
Epoch 1/10, Batch 30/49, Loss: 0.8192
Epoch 1/10, Batch 40/49, Loss: 0.7950
Epoch 1/10, Train Loss: 0.9902, Valid Loss: 0.6392
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7533
Epoch 2/10, Batch 20/49, Loss: 0.4439
Epoch 2/10, Batch 30/49, Loss: 0.5012
Epoch 2/10, Batch 40/49, Loss: 0.3548
Epoch 2/10, Train Loss: 0.5237, Valid Loss: 0.4537
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5790
Epoch 3/10, Batch 20/49, Loss: 0.3733
Epoch 3/10, Batch 30/49, Loss: 0.3803
Epoch 3/10, Batch 40/49, Loss: 0.3125
Epoch 3/10, Train Loss: 0.4058, Valid Loss: 0.3927
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2368
Epoch 4/10, Batch 20/49, Loss: 0.4536
Epoch 4/10, Batch 30/49, Loss: 0.3188
Epoch 4/10, Batch 40/49, Loss: 0.3390
Epoch 4/10, Train Loss: 0.3432, Valid Loss: 0.3476
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3882
Epoch 5/10, Batch 20/49, Loss: 0.2673
Epoch 5/10, Batch 30/49, Loss: 0.2582
Epoch 5/10, Batch 40/49, Loss: 0.3440
Epoch 5/10, Train Loss: 0.2879, Valid Loss: 0.3280
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2440
Epoch 6/10, Batch 20/49, Loss: 0.2212
Epoch 6/10, Batch 30/49, Loss: 0.2384
Epoch 6/10, Batch 40/49, Loss: 0.2610
Epoch 6/10, Train Loss: 0.2705, Valid Loss: 0.3222
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3146
Epoch 7/10, Batch 20/49, Loss: 0.3015
Epoch 7/10, Batch 30/49, Loss: 0.2397
Epoch 7/10, Batch 40/49, Loss: 0.3631
Epoch 7/10, Train Loss: 0.2554, Valid Loss: 0.3133
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2481
Epoch 8/10, Batch 20/49, Loss: 0.2403
Epoch 8/10, Batch 30/49, Loss: 0.4309
Epoch 8/10, Batch 40/49, Loss: 0.1819
Epoch 8/10, Train Loss: 0.2387, Valid Loss: 0.3031
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.0914
Epoch 9/10, Batch 20/49, Loss: 0.1548
Epoch 9/10, Batch 30/49, Loss: 0.4192
Epoch 9/10, Batch 40/49, Loss: 0.2361
Epoch 9/10, Train Loss: 0.2148, Valid Loss: 0.2940
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1745
Epoch 10/10, Batch 20/49, Loss: 0.0791
Epoch 10/10, Batch 30/49, Loss: 0.2567
Epoch 10/10, Batch 40/49, Loss: 0.1165
Epoch 10/10, Train Loss: 0.1956, Valid Loss: 0.2826
Model saved!
Accuracy: 0.9054
Precision: 0.9022
Recall: 0.9054
F1-score: 0.9026
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2743
Epoch 1/10, Batch 20/49, Loss: 1.0369
Epoch 1/10, Batch 30/49, Loss: 0.8648
Epoch 1/10, Batch 40/49, Loss: 0.8259
Epoch 1/10, Train Loss: 1.0046, Valid Loss: 0.6340
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6517
Epoch 2/10, Batch 20/49, Loss: 0.4968
Epoch 2/10, Batch 30/49, Loss: 0.5790
Epoch 2/10, Batch 40/49, Loss: 0.5586
Epoch 2/10, Train Loss: 0.5402, Valid Loss: 0.4584
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3240
Epoch 3/10, Batch 20/49, Loss: 0.4183
Epoch 3/10, Batch 30/49, Loss: 0.4797
Epoch 3/10, Batch 40/49, Loss: 0.3617
Epoch 3/10, Train Loss: 0.4066, Valid Loss: 0.3975
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3413
Epoch 4/10, Batch 20/49, Loss: 0.3502
Epoch 4/10, Batch 30/49, Loss: 0.2765
Epoch 4/10, Batch 40/49, Loss: 0.2609
Epoch 4/10, Train Loss: 0.3599, Valid Loss: 0.3580
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2833
Epoch 5/10, Batch 20/49, Loss: 0.2816
Epoch 5/10, Batch 30/49, Loss: 0.2421
Epoch 5/10, Batch 40/49, Loss: 0.1984
Epoch 5/10, Train Loss: 0.3103, Valid Loss: 0.3350
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2706
Epoch 6/10, Batch 20/49, Loss: 0.3023
Epoch 6/10, Batch 30/49, Loss: 0.3171
Epoch 6/10, Batch 40/49, Loss: 0.2311
Epoch 6/10, Train Loss: 0.2814, Valid Loss: 0.3221
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2616
Epoch 7/10, Batch 20/49, Loss: 0.2067
Epoch 7/10, Batch 30/49, Loss: 0.3731
Epoch 7/10, Batch 40/49, Loss: 0.1921
Epoch 7/10, Train Loss: 0.2552, Valid Loss: 0.3106
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2044
Epoch 8/10, Batch 20/49, Loss: 0.2334
Epoch 8/10, Batch 30/49, Loss: 0.2587
Epoch 8/10, Batch 40/49, Loss: 0.2671
Epoch 8/10, Train Loss: 0.2538, Valid Loss: 0.3005
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1134
Epoch 9/10, Batch 20/49, Loss: 0.2758
Epoch 9/10, Batch 30/49, Loss: 0.5056
Epoch 9/10, Batch 40/49, Loss: 0.2546
Epoch 9/10, Train Loss: 0.2388, Valid Loss: 0.2939
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1868
Epoch 10/10, Batch 20/49, Loss: 0.1135
Epoch 10/10, Batch 30/49, Loss: 0.2781
Epoch 10/10, Batch 40/49, Loss: 0.2892
Epoch 10/10, Train Loss: 0.2075, Valid Loss: 0.2892
Model saved!
Accuracy: 0.9042
Precision: 0.9035
Recall: 0.9042
F1-score: 0.9000
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2887
Epoch 1/10, Batch 20/49, Loss: 1.0885
Epoch 1/10, Batch 30/49, Loss: 0.8164
Epoch 1/10, Batch 40/49, Loss: 0.7669
Epoch 1/10, Train Loss: 0.9887, Valid Loss: 0.6326
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6322
Epoch 2/10, Batch 20/49, Loss: 0.5552
Epoch 2/10, Batch 30/49, Loss: 0.5501
Epoch 2/10, Batch 40/49, Loss: 0.4985
Epoch 2/10, Train Loss: 0.5249, Valid Loss: 0.4580
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5310
Epoch 3/10, Batch 20/49, Loss: 0.4027
Epoch 3/10, Batch 30/49, Loss: 0.3373
Epoch 3/10, Batch 40/49, Loss: 0.4403
Epoch 3/10, Train Loss: 0.4002, Valid Loss: 0.3961
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2268
Epoch 4/10, Batch 20/49, Loss: 0.3663
Epoch 4/10, Batch 30/49, Loss: 0.1758
Epoch 4/10, Batch 40/49, Loss: 0.2636
Epoch 4/10, Train Loss: 0.3458, Valid Loss: 0.3559
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4362
Epoch 5/10, Batch 20/49, Loss: 0.2943
Epoch 5/10, Batch 30/49, Loss: 0.2711
Epoch 5/10, Batch 40/49, Loss: 0.1078
Epoch 5/10, Train Loss: 0.2957, Valid Loss: 0.3265
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1310
Epoch 6/10, Batch 20/49, Loss: 0.2707
Epoch 6/10, Batch 30/49, Loss: 0.2619
Epoch 6/10, Batch 40/49, Loss: 0.2405
Epoch 6/10, Train Loss: 0.2712, Valid Loss: 0.3120
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1871
Epoch 7/10, Batch 20/49, Loss: 0.3426
Epoch 7/10, Batch 30/49, Loss: 0.3313
Epoch 7/10, Batch 40/49, Loss: 0.2288
Epoch 7/10, Train Loss: 0.2455, Valid Loss: 0.3011
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2711
Epoch 8/10, Batch 20/49, Loss: 0.2213
Epoch 8/10, Batch 30/49, Loss: 0.1623
Epoch 8/10, Batch 40/49, Loss: 0.1732
Epoch 8/10, Train Loss: 0.2243, Valid Loss: 0.2999
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1482
Epoch 9/10, Batch 20/49, Loss: 0.2516
Epoch 9/10, Batch 30/49, Loss: 0.5607
Epoch 9/10, Batch 40/49, Loss: 0.2622
Epoch 9/10, Train Loss: 0.2186, Valid Loss: 0.2900
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2302
Epoch 10/10, Batch 20/49, Loss: 0.1368
Epoch 10/10, Batch 30/49, Loss: 0.2310
Epoch 10/10, Batch 40/49, Loss: 0.2323
Epoch 10/10, Train Loss: 0.1981, Valid Loss: 0.2818
Model saved!
Accuracy: 0.9054
Precision: 0.9004
Recall: 0.9054
F1-score: 0.9016
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2489
Epoch 1/10, Batch 20/49, Loss: 1.0417
Epoch 1/10, Batch 30/49, Loss: 0.8870
Epoch 1/10, Batch 40/49, Loss: 0.7923
Epoch 1/10, Train Loss: 1.0020, Valid Loss: 0.6724
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5990
Epoch 2/10, Batch 20/49, Loss: 0.5800
Epoch 2/10, Batch 30/49, Loss: 0.6581
Epoch 2/10, Batch 40/49, Loss: 0.6692
Epoch 2/10, Train Loss: 0.5394, Valid Loss: 0.4801
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4284
Epoch 3/10, Batch 20/49, Loss: 0.3931
Epoch 3/10, Batch 30/49, Loss: 0.3522
Epoch 3/10, Batch 40/49, Loss: 0.3260
Epoch 3/10, Train Loss: 0.4235, Valid Loss: 0.4161
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3086
Epoch 4/10, Batch 20/49, Loss: 0.3929
Epoch 4/10, Batch 30/49, Loss: 0.3177
Epoch 4/10, Batch 40/49, Loss: 0.3215
Epoch 4/10, Train Loss: 0.3717, Valid Loss: 0.3627
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3956
Epoch 5/10, Batch 20/49, Loss: 0.2190
Epoch 5/10, Batch 30/49, Loss: 0.3465
Epoch 5/10, Batch 40/49, Loss: 0.2512
Epoch 5/10, Train Loss: 0.3161, Valid Loss: 0.3343
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3332
Epoch 6/10, Batch 20/49, Loss: 0.2742
Epoch 6/10, Batch 30/49, Loss: 0.3716
Epoch 6/10, Batch 40/49, Loss: 0.3726
Epoch 6/10, Train Loss: 0.2886, Valid Loss: 0.3145
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2784
Epoch 7/10, Batch 20/49, Loss: 0.2042
Epoch 7/10, Batch 30/49, Loss: 0.4063
Epoch 7/10, Batch 40/49, Loss: 0.1501
Epoch 7/10, Train Loss: 0.2671, Valid Loss: 0.3071
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2469
Epoch 8/10, Batch 20/49, Loss: 0.3554
Epoch 8/10, Batch 30/49, Loss: 0.2755
Epoch 8/10, Batch 40/49, Loss: 0.1961
Epoch 8/10, Train Loss: 0.2521, Valid Loss: 0.2795
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1748
Epoch 9/10, Batch 20/49, Loss: 0.2683
Epoch 9/10, Batch 30/49, Loss: 0.5497
Epoch 9/10, Batch 40/49, Loss: 0.1453
Epoch 9/10, Train Loss: 0.2512, Valid Loss: 0.2771
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2606
Epoch 10/10, Batch 20/49, Loss: 0.1374
Epoch 10/10, Batch 30/49, Loss: 0.2571
Epoch 10/10, Batch 40/49, Loss: 0.1873
Epoch 10/10, Train Loss: 0.2218, Valid Loss: 0.2751
Model saved!
Accuracy: 0.8925
Precision: 0.8909
Recall: 0.8925
F1-score: 0.8899
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3117
Epoch 1/10, Batch 20/49, Loss: 1.0126
Epoch 1/10, Batch 30/49, Loss: 0.7966
Epoch 1/10, Batch 40/49, Loss: 0.8121
Epoch 1/10, Train Loss: 1.0221, Valid Loss: 0.6384
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7112
Epoch 2/10, Batch 20/49, Loss: 0.4990
Epoch 2/10, Batch 30/49, Loss: 0.6038
Epoch 2/10, Batch 40/49, Loss: 0.5328
Epoch 2/10, Train Loss: 0.5522, Valid Loss: 0.4566
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5310
Epoch 3/10, Batch 20/49, Loss: 0.3853
Epoch 3/10, Batch 30/49, Loss: 0.4420
Epoch 3/10, Batch 40/49, Loss: 0.4688
Epoch 3/10, Train Loss: 0.4279, Valid Loss: 0.3840
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2957
Epoch 4/10, Batch 20/49, Loss: 0.3608
Epoch 4/10, Batch 30/49, Loss: 0.3591
Epoch 4/10, Batch 40/49, Loss: 0.3690
Epoch 4/10, Train Loss: 0.3709, Valid Loss: 0.3238
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3451
Epoch 5/10, Batch 20/49, Loss: 0.1962
Epoch 5/10, Batch 30/49, Loss: 0.2939
Epoch 5/10, Batch 40/49, Loss: 0.2388
Epoch 5/10, Train Loss: 0.3124, Valid Loss: 0.2943
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2785
Epoch 6/10, Batch 20/49, Loss: 0.3628
Epoch 6/10, Batch 30/49, Loss: 0.4033
Epoch 6/10, Batch 40/49, Loss: 0.2559
Epoch 6/10, Train Loss: 0.3067, Valid Loss: 0.2866
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3080
Epoch 7/10, Batch 20/49, Loss: 0.2612
Epoch 7/10, Batch 30/49, Loss: 0.3472
Epoch 7/10, Batch 40/49, Loss: 0.2423
Epoch 7/10, Train Loss: 0.2838, Valid Loss: 0.2785
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1870
Epoch 8/10, Batch 20/49, Loss: 0.1821
Epoch 8/10, Batch 30/49, Loss: 0.1575
Epoch 8/10, Batch 40/49, Loss: 0.3706
Epoch 8/10, Train Loss: 0.2691, Valid Loss: 0.2580
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.0842
Epoch 9/10, Batch 20/49, Loss: 0.1845
Epoch 9/10, Batch 30/49, Loss: 0.4112
Epoch 9/10, Batch 40/49, Loss: 0.2068
Epoch 9/10, Train Loss: 0.2585, Valid Loss: 0.2445
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3032
Epoch 10/10, Batch 20/49, Loss: 0.2492
Epoch 10/10, Batch 30/49, Loss: 0.1848
Epoch 10/10, Batch 40/49, Loss: 0.2289
Epoch 10/10, Train Loss: 0.2294, Valid Loss: 0.2400
Model saved!
Accuracy: 0.8995
Precision: 0.8947
Recall: 0.8995
F1-score: 0.8957
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2754
Epoch 1/10, Batch 20/49, Loss: 1.0590
Epoch 1/10, Batch 30/49, Loss: 0.8687
Epoch 1/10, Batch 40/49, Loss: 0.8696
Epoch 1/10, Train Loss: 1.0202, Valid Loss: 0.6812
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6605
Epoch 2/10, Batch 20/49, Loss: 0.4450
Epoch 2/10, Batch 30/49, Loss: 0.5369
Epoch 2/10, Batch 40/49, Loss: 0.3851
Epoch 2/10, Train Loss: 0.5593, Valid Loss: 0.5254
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5223
Epoch 3/10, Batch 20/49, Loss: 0.3979
Epoch 3/10, Batch 30/49, Loss: 0.4548
Epoch 3/10, Batch 40/49, Loss: 0.3520
Epoch 3/10, Train Loss: 0.4379, Valid Loss: 0.4452
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2604
Epoch 4/10, Batch 20/49, Loss: 0.3344
Epoch 4/10, Batch 30/49, Loss: 0.3824
Epoch 4/10, Batch 40/49, Loss: 0.2142
Epoch 4/10, Train Loss: 0.3770, Valid Loss: 0.3941
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2928
Epoch 5/10, Batch 20/49, Loss: 0.2354
Epoch 5/10, Batch 30/49, Loss: 0.2780
Epoch 5/10, Batch 40/49, Loss: 0.3269
Epoch 5/10, Train Loss: 0.3293, Valid Loss: 0.3659
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3037
Epoch 6/10, Batch 20/49, Loss: 0.2687
Epoch 6/10, Batch 30/49, Loss: 0.3616
Epoch 6/10, Batch 40/49, Loss: 0.1449
Epoch 6/10, Train Loss: 0.3048, Valid Loss: 0.3554
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1912
Epoch 7/10, Batch 20/49, Loss: 0.1777
Epoch 7/10, Batch 30/49, Loss: 0.3449
Epoch 7/10, Batch 40/49, Loss: 0.3008
Epoch 7/10, Train Loss: 0.2802, Valid Loss: 0.3540
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3962
Epoch 8/10, Batch 20/49, Loss: 0.2187
Epoch 8/10, Batch 30/49, Loss: 0.3176
Epoch 8/10, Batch 40/49, Loss: 0.2262
Epoch 8/10, Train Loss: 0.2668, Valid Loss: 0.3297
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2677
Epoch 9/10, Batch 20/49, Loss: 0.1886
Epoch 9/10, Batch 30/49, Loss: 0.4367
Epoch 9/10, Batch 40/49, Loss: 0.2004
Epoch 9/10, Train Loss: 0.2549, Valid Loss: 0.3191
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2924
Epoch 10/10, Batch 20/49, Loss: 0.1575
Epoch 10/10, Batch 30/49, Loss: 0.1964
Epoch 10/10, Batch 40/49, Loss: 0.3865
Epoch 10/10, Train Loss: 0.2270, Valid Loss: 0.3076
Model saved!
Accuracy: 0.9206
Precision: 0.9172
Recall: 0.9206
F1-score: 0.9180
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 100. Fitness: 0.9206
End time: 2025-02-24 15:34:26.828714
Duration: 4:30:18


Mejor accuracy al acabar el algoritmo: 0.9206


Fitness check:

Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2754
Epoch 1/10, Batch 20/49, Loss: 1.0590
Epoch 1/10, Batch 30/49, Loss: 0.8687
Epoch 1/10, Batch 40/49, Loss: 0.8696
Epoch 1/10, Train Loss: 1.0202, Valid Loss: 0.6812
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6605
Epoch 2/10, Batch 20/49, Loss: 0.4450
Epoch 2/10, Batch 30/49, Loss: 0.5369
Epoch 2/10, Batch 40/49, Loss: 0.3851
Epoch 2/10, Train Loss: 0.5593, Valid Loss: 0.5254
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5223
Epoch 3/10, Batch 20/49, Loss: 0.3979
Epoch 3/10, Batch 30/49, Loss: 0.4548
Epoch 3/10, Batch 40/49, Loss: 0.3520
Epoch 3/10, Train Loss: 0.4379, Valid Loss: 0.4452
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2604
Epoch 4/10, Batch 20/49, Loss: 0.3344
Epoch 4/10, Batch 30/49, Loss: 0.3824
Epoch 4/10, Batch 40/49, Loss: 0.2142
Epoch 4/10, Train Loss: 0.3770, Valid Loss: 0.3941
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2928
Epoch 5/10, Batch 20/49, Loss: 0.2354
Epoch 5/10, Batch 30/49, Loss: 0.2780
Epoch 5/10, Batch 40/49, Loss: 0.3269
Epoch 5/10, Train Loss: 0.3293, Valid Loss: 0.3659
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3037
Epoch 6/10, Batch 20/49, Loss: 0.2687
Epoch 6/10, Batch 30/49, Loss: 0.3616
Epoch 6/10, Batch 40/49, Loss: 0.1449
Epoch 6/10, Train Loss: 0.3048, Valid Loss: 0.3554
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1912
Epoch 7/10, Batch 20/49, Loss: 0.1777
Epoch 7/10, Batch 30/49, Loss: 0.3449
Epoch 7/10, Batch 40/49, Loss: 0.3008
Epoch 7/10, Train Loss: 0.2802, Valid Loss: 0.3540
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3962
Epoch 8/10, Batch 20/49, Loss: 0.2187
Epoch 8/10, Batch 30/49, Loss: 0.3176
Epoch 8/10, Batch 40/49, Loss: 0.2262
Epoch 8/10, Train Loss: 0.2668, Valid Loss: 0.3297
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2677
Epoch 9/10, Batch 20/49, Loss: 0.1886
Epoch 9/10, Batch 30/49, Loss: 0.4367
Epoch 9/10, Batch 40/49, Loss: 0.2004
Epoch 9/10, Train Loss: 0.2549, Valid Loss: 0.3191
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2924
Epoch 10/10, Batch 20/49, Loss: 0.1575
Epoch 10/10, Batch 30/49, Loss: 0.1964
Epoch 10/10, Batch 40/49, Loss: 0.3865
Epoch 10/10, Train Loss: 0.2270, Valid Loss: 0.3076
Model saved!
Accuracy: 0.9206
Precision: 0.9172
Recall: 0.9206
F1-score: 0.9180
Memory Allocated after cleanup: 17.76 MB


Mejor accuracy encontrado: 0.9206


--------------------------------------mobilenet  ALEATORIO  50%-------------------------------------------------
Start time: 2025-02-24 15:37:14.391465
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4518
Epoch 1/10, Batch 20/97, Loss: 0.9353
Epoch 1/10, Batch 30/97, Loss: 0.8851
Epoch 1/10, Batch 40/97, Loss: 0.7571
Epoch 1/10, Batch 50/97, Loss: 0.6339
Epoch 1/10, Batch 60/97, Loss: 0.5984
Epoch 1/10, Batch 70/97, Loss: 0.6678
Epoch 1/10, Batch 80/97, Loss: 0.4635
Epoch 1/10, Batch 90/97, Loss: 0.5123
Epoch 1/10, Train Loss: 0.7820, Valid Loss: 0.4497
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4706
Epoch 2/10, Batch 20/97, Loss: 0.4052
Epoch 2/10, Batch 30/97, Loss: 0.3695
Epoch 2/10, Batch 40/97, Loss: 0.3808
Epoch 2/10, Batch 50/97, Loss: 0.4643
Epoch 2/10, Batch 60/97, Loss: 0.4259
Epoch 2/10, Batch 70/97, Loss: 0.2600
Epoch 2/10, Batch 80/97, Loss: 0.5268
Epoch 2/10, Batch 90/97, Loss: 0.4278
Epoch 2/10, Train Loss: 0.3990, Valid Loss: 0.3522
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3822
Epoch 3/10, Batch 20/97, Loss: 0.3441
Epoch 3/10, Batch 30/97, Loss: 0.2863
Epoch 3/10, Batch 40/97, Loss: 0.3339
Epoch 3/10, Batch 50/97, Loss: 0.2133
Epoch 3/10, Batch 60/97, Loss: 0.2377
Epoch 3/10, Batch 70/97, Loss: 0.2434
Epoch 3/10, Batch 80/97, Loss: 0.2360
Epoch 3/10, Batch 90/97, Loss: 0.1914
Epoch 3/10, Train Loss: 0.3316, Valid Loss: 0.2963
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3470
Epoch 4/10, Batch 20/97, Loss: 0.2143
Epoch 4/10, Batch 30/97, Loss: 0.5408
Epoch 4/10, Batch 40/97, Loss: 0.2316
Epoch 4/10, Batch 50/97, Loss: 0.2607
Epoch 4/10, Batch 60/97, Loss: 0.2506
Epoch 4/10, Batch 70/97, Loss: 0.1870
Epoch 4/10, Batch 80/97, Loss: 0.2427
Epoch 4/10, Batch 90/97, Loss: 0.3094
Epoch 4/10, Train Loss: 0.2953, Valid Loss: 0.2677
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2221
Epoch 5/10, Batch 20/97, Loss: 0.1416
Epoch 5/10, Batch 30/97, Loss: 0.2242
Epoch 5/10, Batch 40/97, Loss: 0.1370
Epoch 5/10, Batch 50/97, Loss: 0.2545
Epoch 5/10, Batch 60/97, Loss: 0.3426
Epoch 5/10, Batch 70/97, Loss: 0.1819
Epoch 5/10, Batch 80/97, Loss: 0.3086
Epoch 5/10, Batch 90/97, Loss: 0.4024
Epoch 5/10, Train Loss: 0.2641, Valid Loss: 0.2580
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3173
Epoch 6/10, Batch 20/97, Loss: 0.2600
Epoch 6/10, Batch 30/97, Loss: 0.1912
Epoch 6/10, Batch 40/97, Loss: 0.3124
Epoch 6/10, Batch 50/97, Loss: 0.2209
Epoch 6/10, Batch 60/97, Loss: 0.2164
Epoch 6/10, Batch 70/97, Loss: 0.2673
Epoch 6/10, Batch 80/97, Loss: 0.2096
Epoch 6/10, Batch 90/97, Loss: 0.2174
Epoch 6/10, Train Loss: 0.2498, Valid Loss: 0.2467
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2285
Epoch 7/10, Batch 20/97, Loss: 0.1512
Epoch 7/10, Batch 30/97, Loss: 0.1535
Epoch 7/10, Batch 40/97, Loss: 0.1240
Epoch 7/10, Batch 50/97, Loss: 0.2169
Epoch 7/10, Batch 60/97, Loss: 0.4316
Epoch 7/10, Batch 70/97, Loss: 0.1177
Epoch 7/10, Batch 80/97, Loss: 0.2054
Epoch 7/10, Batch 90/97, Loss: 0.3124
Epoch 7/10, Train Loss: 0.2547, Valid Loss: 0.2380
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1273
Epoch 8/10, Batch 20/97, Loss: 0.1509
Epoch 8/10, Batch 30/97, Loss: 0.0729
Epoch 8/10, Batch 40/97, Loss: 0.0690
Epoch 8/10, Batch 50/97, Loss: 0.1631
Epoch 8/10, Batch 60/97, Loss: 0.3090
Epoch 8/10, Batch 70/97, Loss: 0.2214
Epoch 8/10, Batch 80/97, Loss: 0.2234
Epoch 8/10, Batch 90/97, Loss: 0.1890
Epoch 8/10, Train Loss: 0.2264, Valid Loss: 0.2284
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2036
Epoch 9/10, Batch 20/97, Loss: 0.1513
Epoch 9/10, Batch 30/97, Loss: 0.1392
Epoch 9/10, Batch 40/97, Loss: 0.1699
Epoch 9/10, Batch 50/97, Loss: 0.2091
Epoch 9/10, Batch 60/97, Loss: 0.2330
Epoch 9/10, Batch 70/97, Loss: 0.1331
Epoch 9/10, Batch 80/97, Loss: 0.1622
Epoch 9/10, Batch 90/97, Loss: 0.2287
Epoch 9/10, Train Loss: 0.2155, Valid Loss: 0.2306
Epoch 10/10, Batch 10/97, Loss: 0.2543
Epoch 10/10, Batch 20/97, Loss: 0.2197
Epoch 10/10, Batch 30/97, Loss: 0.1148
Epoch 10/10, Batch 40/97, Loss: 0.1696
Epoch 10/10, Batch 50/97, Loss: 0.3632
Epoch 10/10, Batch 60/97, Loss: 0.1021
Epoch 10/10, Batch 70/97, Loss: 0.3314
Epoch 10/10, Batch 80/97, Loss: 0.1518
Epoch 10/10, Batch 90/97, Loss: 0.1222
Epoch 10/10, Train Loss: 0.2082, Valid Loss: 0.2188
Model saved!
Accuracy: 0.9159
Precision: 0.9151
Recall: 0.9159
F1-score: 0.9149
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 1. Fitness: 0.9159
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4046
Epoch 1/10, Batch 20/97, Loss: 0.9644
Epoch 1/10, Batch 30/97, Loss: 0.8070
Epoch 1/10, Batch 40/97, Loss: 0.6652
Epoch 1/10, Batch 50/97, Loss: 0.5874
Epoch 1/10, Batch 60/97, Loss: 0.5519
Epoch 1/10, Batch 70/97, Loss: 0.4574
Epoch 1/10, Batch 80/97, Loss: 0.4112
Epoch 1/10, Batch 90/97, Loss: 0.5568
Epoch 1/10, Train Loss: 0.7696, Valid Loss: 0.4077
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4148
Epoch 2/10, Batch 20/97, Loss: 0.5269
Epoch 2/10, Batch 30/97, Loss: 0.3540
Epoch 2/10, Batch 40/97, Loss: 0.4046
Epoch 2/10, Batch 50/97, Loss: 0.5280
Epoch 2/10, Batch 60/97, Loss: 0.4959
Epoch 2/10, Batch 70/97, Loss: 0.3556
Epoch 2/10, Batch 80/97, Loss: 0.3231
Epoch 2/10, Batch 90/97, Loss: 0.2182
Epoch 2/10, Train Loss: 0.3904, Valid Loss: 0.3030
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.1929
Epoch 3/10, Batch 20/97, Loss: 0.3662
Epoch 3/10, Batch 30/97, Loss: 0.1839
Epoch 3/10, Batch 40/97, Loss: 0.4069
Epoch 3/10, Batch 50/97, Loss: 0.2162
Epoch 3/10, Batch 60/97, Loss: 0.1857
Epoch 3/10, Batch 70/97, Loss: 0.3326
Epoch 3/10, Batch 80/97, Loss: 0.3271
Epoch 3/10, Batch 90/97, Loss: 0.3115
Epoch 3/10, Train Loss: 0.3167, Valid Loss: 0.2560
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3084
Epoch 4/10, Batch 20/97, Loss: 0.2608
Epoch 4/10, Batch 30/97, Loss: 0.2151
Epoch 4/10, Batch 40/97, Loss: 0.3220
Epoch 4/10, Batch 50/97, Loss: 0.2290
Epoch 4/10, Batch 60/97, Loss: 0.1357
Epoch 4/10, Batch 70/97, Loss: 0.2918
Epoch 4/10, Batch 80/97, Loss: 0.1561
Epoch 4/10, Batch 90/97, Loss: 0.2544
Epoch 4/10, Train Loss: 0.2771, Valid Loss: 0.2354
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1702
Epoch 5/10, Batch 20/97, Loss: 0.2098
Epoch 5/10, Batch 30/97, Loss: 0.1353
Epoch 5/10, Batch 40/97, Loss: 0.1169
Epoch 5/10, Batch 50/97, Loss: 0.2197
Epoch 5/10, Batch 60/97, Loss: 0.1506
Epoch 5/10, Batch 70/97, Loss: 0.1171
Epoch 5/10, Batch 80/97, Loss: 0.3252
Epoch 5/10, Batch 90/97, Loss: 0.2159
Epoch 5/10, Train Loss: 0.2500, Valid Loss: 0.2264
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2143
Epoch 6/10, Batch 20/97, Loss: 0.1868
Epoch 6/10, Batch 30/97, Loss: 0.2479
Epoch 6/10, Batch 40/97, Loss: 0.3081
Epoch 6/10, Batch 50/97, Loss: 0.1955
Epoch 6/10, Batch 60/97, Loss: 0.2180
Epoch 6/10, Batch 70/97, Loss: 0.2259
Epoch 6/10, Batch 80/97, Loss: 0.2312
Epoch 6/10, Batch 90/97, Loss: 0.2329
Epoch 6/10, Train Loss: 0.2288, Valid Loss: 0.2220
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2827
Epoch 7/10, Batch 20/97, Loss: 0.1890
Epoch 7/10, Batch 30/97, Loss: 0.1515
Epoch 7/10, Batch 40/97, Loss: 0.2083
Epoch 7/10, Batch 50/97, Loss: 0.2315
Epoch 7/10, Batch 60/97, Loss: 0.2407
Epoch 7/10, Batch 70/97, Loss: 0.1609
Epoch 7/10, Batch 80/97, Loss: 0.2585
Epoch 7/10, Batch 90/97, Loss: 0.1958
Epoch 7/10, Train Loss: 0.2303, Valid Loss: 0.2067
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2167
Epoch 8/10, Batch 20/97, Loss: 0.2217
Epoch 8/10, Batch 30/97, Loss: 0.1432
Epoch 8/10, Batch 40/97, Loss: 0.2037
Epoch 8/10, Batch 50/97, Loss: 0.1081
Epoch 8/10, Batch 60/97, Loss: 0.2315
Epoch 8/10, Batch 70/97, Loss: 0.2671
Epoch 8/10, Batch 80/97, Loss: 0.1008
Epoch 8/10, Batch 90/97, Loss: 0.1162
Epoch 8/10, Train Loss: 0.2066, Valid Loss: 0.2061
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1290
Epoch 9/10, Batch 20/97, Loss: 0.1729
Epoch 9/10, Batch 30/97, Loss: 0.3366
Epoch 9/10, Batch 40/97, Loss: 0.0917
Epoch 9/10, Batch 50/97, Loss: 0.1881
Epoch 9/10, Batch 60/97, Loss: 0.1188
Epoch 9/10, Batch 70/97, Loss: 0.2045
Epoch 9/10, Batch 80/97, Loss: 0.2444
Epoch 9/10, Batch 90/97, Loss: 0.2790
Epoch 9/10, Train Loss: 0.2050, Valid Loss: 0.2001
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1813
Epoch 10/10, Batch 20/97, Loss: 0.0898
Epoch 10/10, Batch 30/97, Loss: 0.1880
Epoch 10/10, Batch 40/97, Loss: 0.2081
Epoch 10/10, Batch 50/97, Loss: 0.3827
Epoch 10/10, Batch 60/97, Loss: 0.1429
Epoch 10/10, Batch 70/97, Loss: 0.1430
Epoch 10/10, Batch 80/97, Loss: 0.2585
Epoch 10/10, Batch 90/97, Loss: 0.1240
Epoch 10/10, Train Loss: 0.1954, Valid Loss: 0.1952
Model saved!
Accuracy: 0.9124
Precision: 0.9120
Recall: 0.9124
F1-score: 0.9117
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5136
Epoch 1/10, Batch 20/97, Loss: 1.0864
Epoch 1/10, Batch 30/97, Loss: 0.9304
Epoch 1/10, Batch 40/97, Loss: 0.7591
Epoch 1/10, Batch 50/97, Loss: 0.5787
Epoch 1/10, Batch 60/97, Loss: 0.5672
Epoch 1/10, Batch 70/97, Loss: 0.5266
Epoch 1/10, Batch 80/97, Loss: 0.4491
Epoch 1/10, Batch 90/97, Loss: 0.5768
Epoch 1/10, Train Loss: 0.7674, Valid Loss: 0.4479
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5061
Epoch 2/10, Batch 20/97, Loss: 0.5778
Epoch 2/10, Batch 30/97, Loss: 0.3304
Epoch 2/10, Batch 40/97, Loss: 0.4610
Epoch 2/10, Batch 50/97, Loss: 0.6220
Epoch 2/10, Batch 60/97, Loss: 0.3931
Epoch 2/10, Batch 70/97, Loss: 0.2347
Epoch 2/10, Batch 80/97, Loss: 0.2633
Epoch 2/10, Batch 90/97, Loss: 0.3201
Epoch 2/10, Train Loss: 0.3906, Valid Loss: 0.3424
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3396
Epoch 3/10, Batch 20/97, Loss: 0.3440
Epoch 3/10, Batch 30/97, Loss: 0.2463
Epoch 3/10, Batch 40/97, Loss: 0.2760
Epoch 3/10, Batch 50/97, Loss: 0.2767
Epoch 3/10, Batch 60/97, Loss: 0.3179
Epoch 3/10, Batch 70/97, Loss: 0.3621
Epoch 3/10, Batch 80/97, Loss: 0.1917
Epoch 3/10, Batch 90/97, Loss: 0.3176
Epoch 3/10, Train Loss: 0.3153, Valid Loss: 0.3129
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2399
Epoch 4/10, Batch 20/97, Loss: 0.1630
Epoch 4/10, Batch 30/97, Loss: 0.3819
Epoch 4/10, Batch 40/97, Loss: 0.4501
Epoch 4/10, Batch 50/97, Loss: 0.1719
Epoch 4/10, Batch 60/97, Loss: 0.1251
Epoch 4/10, Batch 70/97, Loss: 0.2529
Epoch 4/10, Batch 80/97, Loss: 0.2383
Epoch 4/10, Batch 90/97, Loss: 0.3332
Epoch 4/10, Train Loss: 0.2875, Valid Loss: 0.2892
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2313
Epoch 5/10, Batch 20/97, Loss: 0.2246
Epoch 5/10, Batch 30/97, Loss: 0.2079
Epoch 5/10, Batch 40/97, Loss: 0.1924
Epoch 5/10, Batch 50/97, Loss: 0.2258
Epoch 5/10, Batch 60/97, Loss: 0.1837
Epoch 5/10, Batch 70/97, Loss: 0.3006
Epoch 5/10, Batch 80/97, Loss: 0.3469
Epoch 5/10, Batch 90/97, Loss: 0.2475
Epoch 5/10, Train Loss: 0.2517, Valid Loss: 0.2769
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3002
Epoch 6/10, Batch 20/97, Loss: 0.2229
Epoch 6/10, Batch 30/97, Loss: 0.2131
Epoch 6/10, Batch 40/97, Loss: 0.2849
Epoch 6/10, Batch 50/97, Loss: 0.2560
Epoch 6/10, Batch 60/97, Loss: 0.3473
Epoch 6/10, Batch 70/97, Loss: 0.2891
Epoch 6/10, Batch 80/97, Loss: 0.1796
Epoch 6/10, Batch 90/97, Loss: 0.1367
Epoch 6/10, Train Loss: 0.2364, Valid Loss: 0.2661
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4670
Epoch 7/10, Batch 20/97, Loss: 0.1784
Epoch 7/10, Batch 30/97, Loss: 0.1449
Epoch 7/10, Batch 40/97, Loss: 0.2171
Epoch 7/10, Batch 50/97, Loss: 0.2613
Epoch 7/10, Batch 60/97, Loss: 0.1981
Epoch 7/10, Batch 70/97, Loss: 0.2249
Epoch 7/10, Batch 80/97, Loss: 0.2010
Epoch 7/10, Batch 90/97, Loss: 0.2122
Epoch 7/10, Train Loss: 0.2467, Valid Loss: 0.2623
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2145
Epoch 8/10, Batch 20/97, Loss: 0.2279
Epoch 8/10, Batch 30/97, Loss: 0.1863
Epoch 8/10, Batch 40/97, Loss: 0.2394
Epoch 8/10, Batch 50/97, Loss: 0.2945
Epoch 8/10, Batch 60/97, Loss: 0.1094
Epoch 8/10, Batch 70/97, Loss: 0.2942
Epoch 8/10, Batch 80/97, Loss: 0.2147
Epoch 8/10, Batch 90/97, Loss: 0.2813
Epoch 8/10, Train Loss: 0.2130, Valid Loss: 0.2533
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1496
Epoch 9/10, Batch 20/97, Loss: 0.1324
Epoch 9/10, Batch 30/97, Loss: 0.2654
Epoch 9/10, Batch 40/97, Loss: 0.1335
Epoch 9/10, Batch 50/97, Loss: 0.1381
Epoch 9/10, Batch 60/97, Loss: 0.3832
Epoch 9/10, Batch 70/97, Loss: 0.2088
Epoch 9/10, Batch 80/97, Loss: 0.1901
Epoch 9/10, Batch 90/97, Loss: 0.2841
Epoch 9/10, Train Loss: 0.2069, Valid Loss: 0.2538
Epoch 10/10, Batch 10/97, Loss: 0.1219
Epoch 10/10, Batch 20/97, Loss: 0.0736
Epoch 10/10, Batch 30/97, Loss: 0.2070
Epoch 10/10, Batch 40/97, Loss: 0.2029
Epoch 10/10, Batch 50/97, Loss: 0.2985
Epoch 10/10, Batch 60/97, Loss: 0.1612
Epoch 10/10, Batch 70/97, Loss: 0.1137
Epoch 10/10, Batch 80/97, Loss: 0.1375
Epoch 10/10, Batch 90/97, Loss: 0.3520
Epoch 10/10, Train Loss: 0.1974, Valid Loss: 0.2622
Accuracy: 0.9124
Precision: 0.9100
Recall: 0.9124
F1-score: 0.9097
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4746
Epoch 1/10, Batch 20/97, Loss: 1.0301
Epoch 1/10, Batch 30/97, Loss: 0.9680
Epoch 1/10, Batch 40/97, Loss: 0.7878
Epoch 1/10, Batch 50/97, Loss: 0.7387
Epoch 1/10, Batch 60/97, Loss: 0.5145
Epoch 1/10, Batch 70/97, Loss: 0.5363
Epoch 1/10, Batch 80/97, Loss: 0.5729
Epoch 1/10, Batch 90/97, Loss: 0.5363
Epoch 1/10, Train Loss: 0.7601, Valid Loss: 0.4135
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4225
Epoch 2/10, Batch 20/97, Loss: 0.5654
Epoch 2/10, Batch 30/97, Loss: 0.3795
Epoch 2/10, Batch 40/97, Loss: 0.3982
Epoch 2/10, Batch 50/97, Loss: 0.5078
Epoch 2/10, Batch 60/97, Loss: 0.3509
Epoch 2/10, Batch 70/97, Loss: 0.3154
Epoch 2/10, Batch 80/97, Loss: 0.2267
Epoch 2/10, Batch 90/97, Loss: 0.3363
Epoch 2/10, Train Loss: 0.3791, Valid Loss: 0.3087
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2798
Epoch 3/10, Batch 20/97, Loss: 0.3855
Epoch 3/10, Batch 30/97, Loss: 0.3927
Epoch 3/10, Batch 40/97, Loss: 0.2940
Epoch 3/10, Batch 50/97, Loss: 0.1977
Epoch 3/10, Batch 60/97, Loss: 0.3169
Epoch 3/10, Batch 70/97, Loss: 0.2215
Epoch 3/10, Batch 80/97, Loss: 0.3546
Epoch 3/10, Batch 90/97, Loss: 0.1853
Epoch 3/10, Train Loss: 0.3050, Valid Loss: 0.2745
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2729
Epoch 4/10, Batch 20/97, Loss: 0.1620
Epoch 4/10, Batch 30/97, Loss: 0.2824
Epoch 4/10, Batch 40/97, Loss: 0.2787
Epoch 4/10, Batch 50/97, Loss: 0.2334
Epoch 4/10, Batch 60/97, Loss: 0.1731
Epoch 4/10, Batch 70/97, Loss: 0.2380
Epoch 4/10, Batch 80/97, Loss: 0.1611
Epoch 4/10, Batch 90/97, Loss: 0.1067
Epoch 4/10, Train Loss: 0.2677, Valid Loss: 0.2489
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2427
Epoch 5/10, Batch 20/97, Loss: 0.1763
Epoch 5/10, Batch 30/97, Loss: 0.2539
Epoch 5/10, Batch 40/97, Loss: 0.2245
Epoch 5/10, Batch 50/97, Loss: 0.2282
Epoch 5/10, Batch 60/97, Loss: 0.2741
Epoch 5/10, Batch 70/97, Loss: 0.1829
Epoch 5/10, Batch 80/97, Loss: 0.2667
Epoch 5/10, Batch 90/97, Loss: 0.3588
Epoch 5/10, Train Loss: 0.2446, Valid Loss: 0.2386
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2471
Epoch 6/10, Batch 20/97, Loss: 0.2910
Epoch 6/10, Batch 30/97, Loss: 0.2413
Epoch 6/10, Batch 40/97, Loss: 0.2237
Epoch 6/10, Batch 50/97, Loss: 0.1890
Epoch 6/10, Batch 60/97, Loss: 0.3133
Epoch 6/10, Batch 70/97, Loss: 0.1234
Epoch 6/10, Batch 80/97, Loss: 0.2130
Epoch 6/10, Batch 90/97, Loss: 0.1823
Epoch 6/10, Train Loss: 0.2243, Valid Loss: 0.2241
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2845
Epoch 7/10, Batch 20/97, Loss: 0.0690
Epoch 7/10, Batch 30/97, Loss: 0.1984
Epoch 7/10, Batch 40/97, Loss: 0.2629
Epoch 7/10, Batch 50/97, Loss: 0.2326
Epoch 7/10, Batch 60/97, Loss: 0.3187
Epoch 7/10, Batch 70/97, Loss: 0.1854
Epoch 7/10, Batch 80/97, Loss: 0.1777
Epoch 7/10, Batch 90/97, Loss: 0.2719
Epoch 7/10, Train Loss: 0.2304, Valid Loss: 0.2202
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2060
Epoch 8/10, Batch 20/97, Loss: 0.1338
Epoch 8/10, Batch 30/97, Loss: 0.1284
Epoch 8/10, Batch 40/97, Loss: 0.1831
Epoch 8/10, Batch 50/97, Loss: 0.2577
Epoch 8/10, Batch 60/97, Loss: 0.1258
Epoch 8/10, Batch 70/97, Loss: 0.3885
Epoch 8/10, Batch 80/97, Loss: 0.3545
Epoch 8/10, Batch 90/97, Loss: 0.2628
Epoch 8/10, Train Loss: 0.2064, Valid Loss: 0.2162
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2068
Epoch 9/10, Batch 20/97, Loss: 0.1399
Epoch 9/10, Batch 30/97, Loss: 0.3272
Epoch 9/10, Batch 40/97, Loss: 0.0742
Epoch 9/10, Batch 50/97, Loss: 0.2148
Epoch 9/10, Batch 60/97, Loss: 0.0874
Epoch 9/10, Batch 70/97, Loss: 0.1550
Epoch 9/10, Batch 80/97, Loss: 0.1660
Epoch 9/10, Batch 90/97, Loss: 0.1379
Epoch 9/10, Train Loss: 0.1922, Valid Loss: 0.2113
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1904
Epoch 10/10, Batch 20/97, Loss: 0.1399
Epoch 10/10, Batch 30/97, Loss: 0.0767
Epoch 10/10, Batch 40/97, Loss: 0.1758
Epoch 10/10, Batch 50/97, Loss: 0.2119
Epoch 10/10, Batch 60/97, Loss: 0.1283
Epoch 10/10, Batch 70/97, Loss: 0.2202
Epoch 10/10, Batch 80/97, Loss: 0.1502
Epoch 10/10, Batch 90/97, Loss: 0.1134
Epoch 10/10, Train Loss: 0.1798, Valid Loss: 0.2079
Model saved!
Accuracy: 0.9159
Precision: 0.9132
Recall: 0.9159
F1-score: 0.9141
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4910
Epoch 1/10, Batch 20/97, Loss: 0.9910
Epoch 1/10, Batch 30/97, Loss: 0.8696
Epoch 1/10, Batch 40/97, Loss: 0.6792
Epoch 1/10, Batch 50/97, Loss: 0.6155
Epoch 1/10, Batch 60/97, Loss: 0.5247
Epoch 1/10, Batch 70/97, Loss: 0.5546
Epoch 1/10, Batch 80/97, Loss: 0.4052
Epoch 1/10, Batch 90/97, Loss: 0.4318
Epoch 1/10, Train Loss: 0.7738, Valid Loss: 0.4559
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3739
Epoch 2/10, Batch 20/97, Loss: 0.5225
Epoch 2/10, Batch 30/97, Loss: 0.3949
Epoch 2/10, Batch 40/97, Loss: 0.3871
Epoch 2/10, Batch 50/97, Loss: 0.6819
Epoch 2/10, Batch 60/97, Loss: 0.3422
Epoch 2/10, Batch 70/97, Loss: 0.2632
Epoch 2/10, Batch 80/97, Loss: 0.1693
Epoch 2/10, Batch 90/97, Loss: 0.3475
Epoch 2/10, Train Loss: 0.3912, Valid Loss: 0.3611
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4058
Epoch 3/10, Batch 20/97, Loss: 0.3942
Epoch 3/10, Batch 30/97, Loss: 0.2075
Epoch 3/10, Batch 40/97, Loss: 0.3048
Epoch 3/10, Batch 50/97, Loss: 0.5420
Epoch 3/10, Batch 60/97, Loss: 0.2522
Epoch 3/10, Batch 70/97, Loss: 0.2447
Epoch 3/10, Batch 80/97, Loss: 0.2198
Epoch 3/10, Batch 90/97, Loss: 0.3055
Epoch 3/10, Train Loss: 0.3238, Valid Loss: 0.3229
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2753
Epoch 4/10, Batch 20/97, Loss: 0.2379
Epoch 4/10, Batch 30/97, Loss: 0.2415
Epoch 4/10, Batch 40/97, Loss: 0.2537
Epoch 4/10, Batch 50/97, Loss: 0.2384
Epoch 4/10, Batch 60/97, Loss: 0.2170
Epoch 4/10, Batch 70/97, Loss: 0.2252
Epoch 4/10, Batch 80/97, Loss: 0.2890
Epoch 4/10, Batch 90/97, Loss: 0.2821
Epoch 4/10, Train Loss: 0.2852, Valid Loss: 0.3093
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3469
Epoch 5/10, Batch 20/97, Loss: 0.2471
Epoch 5/10, Batch 30/97, Loss: 0.1713
Epoch 5/10, Batch 40/97, Loss: 0.1189
Epoch 5/10, Batch 50/97, Loss: 0.1607
Epoch 5/10, Batch 60/97, Loss: 0.4054
Epoch 5/10, Batch 70/97, Loss: 0.1956
Epoch 5/10, Batch 80/97, Loss: 0.4846
Epoch 5/10, Batch 90/97, Loss: 0.4855
Epoch 5/10, Train Loss: 0.2551, Valid Loss: 0.2969
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2416
Epoch 6/10, Batch 20/97, Loss: 0.2769
Epoch 6/10, Batch 30/97, Loss: 0.2470
Epoch 6/10, Batch 40/97, Loss: 0.3808
Epoch 6/10, Batch 50/97, Loss: 0.1370
Epoch 6/10, Batch 60/97, Loss: 0.3262
Epoch 6/10, Batch 70/97, Loss: 0.1703
Epoch 6/10, Batch 80/97, Loss: 0.2770
Epoch 6/10, Batch 90/97, Loss: 0.2540
Epoch 6/10, Train Loss: 0.2369, Valid Loss: 0.2947
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4042
Epoch 7/10, Batch 20/97, Loss: 0.1710
Epoch 7/10, Batch 30/97, Loss: 0.1448
Epoch 7/10, Batch 40/97, Loss: 0.2400
Epoch 7/10, Batch 50/97, Loss: 0.1959
Epoch 7/10, Batch 60/97, Loss: 0.3534
Epoch 7/10, Batch 70/97, Loss: 0.3244
Epoch 7/10, Batch 80/97, Loss: 0.1824
Epoch 7/10, Batch 90/97, Loss: 0.4687
Epoch 7/10, Train Loss: 0.2374, Valid Loss: 0.2810
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1558
Epoch 8/10, Batch 20/97, Loss: 0.2663
Epoch 8/10, Batch 30/97, Loss: 0.1387
Epoch 8/10, Batch 40/97, Loss: 0.3237
Epoch 8/10, Batch 50/97, Loss: 0.2561
Epoch 8/10, Batch 60/97, Loss: 0.1887
Epoch 8/10, Batch 70/97, Loss: 0.3457
Epoch 8/10, Batch 80/97, Loss: 0.1751
Epoch 8/10, Batch 90/97, Loss: 0.0925
Epoch 8/10, Train Loss: 0.2158, Valid Loss: 0.2778
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1998
Epoch 9/10, Batch 20/97, Loss: 0.0977
Epoch 9/10, Batch 30/97, Loss: 0.3273
Epoch 9/10, Batch 40/97, Loss: 0.1603
Epoch 9/10, Batch 50/97, Loss: 0.1919
Epoch 9/10, Batch 60/97, Loss: 0.1295
Epoch 9/10, Batch 70/97, Loss: 0.2070
Epoch 9/10, Batch 80/97, Loss: 0.1683
Epoch 9/10, Batch 90/97, Loss: 0.1889
Epoch 9/10, Train Loss: 0.2075, Valid Loss: 0.2850
Epoch 10/10, Batch 10/97, Loss: 0.1300
Epoch 10/10, Batch 20/97, Loss: 0.2887
Epoch 10/10, Batch 30/97, Loss: 0.1905
Epoch 10/10, Batch 40/97, Loss: 0.2426
Epoch 10/10, Batch 50/97, Loss: 0.3158
Epoch 10/10, Batch 60/97, Loss: 0.2203
Epoch 10/10, Batch 70/97, Loss: 0.2319
Epoch 10/10, Batch 80/97, Loss: 0.1526
Epoch 10/10, Batch 90/97, Loss: 0.1157
Epoch 10/10, Train Loss: 0.2044, Valid Loss: 0.2799
Accuracy: 0.9089
Precision: 0.9070
Recall: 0.9089
F1-score: 0.9055
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4619
Epoch 1/10, Batch 20/97, Loss: 1.0940
Epoch 1/10, Batch 30/97, Loss: 0.8157
Epoch 1/10, Batch 40/97, Loss: 0.7336
Epoch 1/10, Batch 50/97, Loss: 0.5721
Epoch 1/10, Batch 60/97, Loss: 0.5476
Epoch 1/10, Batch 70/97, Loss: 0.6024
Epoch 1/10, Batch 80/97, Loss: 0.4125
Epoch 1/10, Batch 90/97, Loss: 0.5689
Epoch 1/10, Train Loss: 0.7768, Valid Loss: 0.4412
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3369
Epoch 2/10, Batch 20/97, Loss: 0.3791
Epoch 2/10, Batch 30/97, Loss: 0.3963
Epoch 2/10, Batch 40/97, Loss: 0.4803
Epoch 2/10, Batch 50/97, Loss: 0.5726
Epoch 2/10, Batch 60/97, Loss: 0.3316
Epoch 2/10, Batch 70/97, Loss: 0.4523
Epoch 2/10, Batch 80/97, Loss: 0.3288
Epoch 2/10, Batch 90/97, Loss: 0.3471
Epoch 2/10, Train Loss: 0.3932, Valid Loss: 0.3261
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3067
Epoch 3/10, Batch 20/97, Loss: 0.3240
Epoch 3/10, Batch 30/97, Loss: 0.3297
Epoch 3/10, Batch 40/97, Loss: 0.3126
Epoch 3/10, Batch 50/97, Loss: 0.4006
Epoch 3/10, Batch 60/97, Loss: 0.2177
Epoch 3/10, Batch 70/97, Loss: 0.2436
Epoch 3/10, Batch 80/97, Loss: 0.2932
Epoch 3/10, Batch 90/97, Loss: 0.2246
Epoch 3/10, Train Loss: 0.3275, Valid Loss: 0.2891
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2361
Epoch 4/10, Batch 20/97, Loss: 0.2022
Epoch 4/10, Batch 30/97, Loss: 0.2211
Epoch 4/10, Batch 40/97, Loss: 0.1917
Epoch 4/10, Batch 50/97, Loss: 0.3276
Epoch 4/10, Batch 60/97, Loss: 0.1954
Epoch 4/10, Batch 70/97, Loss: 0.2900
Epoch 4/10, Batch 80/97, Loss: 0.2179
Epoch 4/10, Batch 90/97, Loss: 0.2174
Epoch 4/10, Train Loss: 0.2865, Valid Loss: 0.2634
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1352
Epoch 5/10, Batch 20/97, Loss: 0.1866
Epoch 5/10, Batch 30/97, Loss: 0.1946
Epoch 5/10, Batch 40/97, Loss: 0.3440
Epoch 5/10, Batch 50/97, Loss: 0.2013
Epoch 5/10, Batch 60/97, Loss: 0.2000
Epoch 5/10, Batch 70/97, Loss: 0.2296
Epoch 5/10, Batch 80/97, Loss: 0.3190
Epoch 5/10, Batch 90/97, Loss: 0.2125
Epoch 5/10, Train Loss: 0.2633, Valid Loss: 0.2516
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3040
Epoch 6/10, Batch 20/97, Loss: 0.2570
Epoch 6/10, Batch 30/97, Loss: 0.0937
Epoch 6/10, Batch 40/97, Loss: 0.1803
Epoch 6/10, Batch 50/97, Loss: 0.2075
Epoch 6/10, Batch 60/97, Loss: 0.2177
Epoch 6/10, Batch 70/97, Loss: 0.1833
Epoch 6/10, Batch 80/97, Loss: 0.1516
Epoch 6/10, Batch 90/97, Loss: 0.2301
Epoch 6/10, Train Loss: 0.2384, Valid Loss: 0.2477
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2913
Epoch 7/10, Batch 20/97, Loss: 0.1411
Epoch 7/10, Batch 30/97, Loss: 0.2076
Epoch 7/10, Batch 40/97, Loss: 0.1869
Epoch 7/10, Batch 50/97, Loss: 0.2484
Epoch 7/10, Batch 60/97, Loss: 0.2002
Epoch 7/10, Batch 70/97, Loss: 0.1444
Epoch 7/10, Batch 80/97, Loss: 0.2164
Epoch 7/10, Batch 90/97, Loss: 0.2927
Epoch 7/10, Train Loss: 0.2383, Valid Loss: 0.2289
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2887
Epoch 8/10, Batch 20/97, Loss: 0.2221
Epoch 8/10, Batch 30/97, Loss: 0.1839
Epoch 8/10, Batch 40/97, Loss: 0.1834
Epoch 8/10, Batch 50/97, Loss: 0.2242
Epoch 8/10, Batch 60/97, Loss: 0.2106
Epoch 8/10, Batch 70/97, Loss: 0.2078
Epoch 8/10, Batch 80/97, Loss: 0.1716
Epoch 8/10, Batch 90/97, Loss: 0.2327
Epoch 8/10, Train Loss: 0.2173, Valid Loss: 0.2329
Epoch 9/10, Batch 10/97, Loss: 0.1042
Epoch 9/10, Batch 20/97, Loss: 0.0880
Epoch 9/10, Batch 30/97, Loss: 0.3847
Epoch 9/10, Batch 40/97, Loss: 0.1260
Epoch 9/10, Batch 50/97, Loss: 0.3205
Epoch 9/10, Batch 60/97, Loss: 0.2628
Epoch 9/10, Batch 70/97, Loss: 0.1973
Epoch 9/10, Batch 80/97, Loss: 0.1877
Epoch 9/10, Batch 90/97, Loss: 0.2678
Epoch 9/10, Train Loss: 0.2060, Valid Loss: 0.2319
Epoch 10/10, Batch 10/97, Loss: 0.3038
Epoch 10/10, Batch 20/97, Loss: 0.1433
Epoch 10/10, Batch 30/97, Loss: 0.0998
Epoch 10/10, Batch 40/97, Loss: 0.2108
Epoch 10/10, Batch 50/97, Loss: 0.2799
Epoch 10/10, Batch 60/97, Loss: 0.1132
Epoch 10/10, Batch 70/97, Loss: 0.1634
Epoch 10/10, Batch 80/97, Loss: 0.2051
Epoch 10/10, Batch 90/97, Loss: 0.3629
Epoch 10/10, Train Loss: 0.1936, Valid Loss: 0.2252
Model saved!
Accuracy: 0.9124
Precision: 0.9095
Recall: 0.9124
F1-score: 0.9101
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4360
Epoch 1/10, Batch 20/97, Loss: 1.0441
Epoch 1/10, Batch 30/97, Loss: 0.8712
Epoch 1/10, Batch 40/97, Loss: 0.7763
Epoch 1/10, Batch 50/97, Loss: 0.6095
Epoch 1/10, Batch 60/97, Loss: 0.6665
Epoch 1/10, Batch 70/97, Loss: 0.5732
Epoch 1/10, Batch 80/97, Loss: 0.3869
Epoch 1/10, Batch 90/97, Loss: 0.4649
Epoch 1/10, Train Loss: 0.7856, Valid Loss: 0.4264
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3872
Epoch 2/10, Batch 20/97, Loss: 0.6424
Epoch 2/10, Batch 30/97, Loss: 0.2960
Epoch 2/10, Batch 40/97, Loss: 0.4817
Epoch 2/10, Batch 50/97, Loss: 0.5935
Epoch 2/10, Batch 60/97, Loss: 0.3363
Epoch 2/10, Batch 70/97, Loss: 0.3936
Epoch 2/10, Batch 80/97, Loss: 0.4793
Epoch 2/10, Batch 90/97, Loss: 0.2686
Epoch 2/10, Train Loss: 0.4069, Valid Loss: 0.3239
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3503
Epoch 3/10, Batch 20/97, Loss: 0.2693
Epoch 3/10, Batch 30/97, Loss: 0.2758
Epoch 3/10, Batch 40/97, Loss: 0.3377
Epoch 3/10, Batch 50/97, Loss: 0.3361
Epoch 3/10, Batch 60/97, Loss: 0.1979
Epoch 3/10, Batch 70/97, Loss: 0.3811
Epoch 3/10, Batch 80/97, Loss: 0.3408
Epoch 3/10, Batch 90/97, Loss: 0.2406
Epoch 3/10, Train Loss: 0.3323, Valid Loss: 0.2855
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1619
Epoch 4/10, Batch 20/97, Loss: 0.2787
Epoch 4/10, Batch 30/97, Loss: 0.4719
Epoch 4/10, Batch 40/97, Loss: 0.3256
Epoch 4/10, Batch 50/97, Loss: 0.1362
Epoch 4/10, Batch 60/97, Loss: 0.2085
Epoch 4/10, Batch 70/97, Loss: 0.2544
Epoch 4/10, Batch 80/97, Loss: 0.3014
Epoch 4/10, Batch 90/97, Loss: 0.2972
Epoch 4/10, Train Loss: 0.2917, Valid Loss: 0.2637
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1787
Epoch 5/10, Batch 20/97, Loss: 0.2834
Epoch 5/10, Batch 30/97, Loss: 0.2215
Epoch 5/10, Batch 40/97, Loss: 0.1642
Epoch 5/10, Batch 50/97, Loss: 0.1708
Epoch 5/10, Batch 60/97, Loss: 0.1627
Epoch 5/10, Batch 70/97, Loss: 0.1637
Epoch 5/10, Batch 80/97, Loss: 0.1582
Epoch 5/10, Batch 90/97, Loss: 0.2335
Epoch 5/10, Train Loss: 0.2617, Valid Loss: 0.2484
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2135
Epoch 6/10, Batch 20/97, Loss: 0.2832
Epoch 6/10, Batch 30/97, Loss: 0.1866
Epoch 6/10, Batch 40/97, Loss: 0.2341
Epoch 6/10, Batch 50/97, Loss: 0.1793
Epoch 6/10, Batch 60/97, Loss: 0.2528
Epoch 6/10, Batch 70/97, Loss: 0.2316
Epoch 6/10, Batch 80/97, Loss: 0.1688
Epoch 6/10, Batch 90/97, Loss: 0.1891
Epoch 6/10, Train Loss: 0.2509, Valid Loss: 0.2385
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3026
Epoch 7/10, Batch 20/97, Loss: 0.2751
Epoch 7/10, Batch 30/97, Loss: 0.2551
Epoch 7/10, Batch 40/97, Loss: 0.3285
Epoch 7/10, Batch 50/97, Loss: 0.2664
Epoch 7/10, Batch 60/97, Loss: 0.2591
Epoch 7/10, Batch 70/97, Loss: 0.2702
Epoch 7/10, Batch 80/97, Loss: 0.1636
Epoch 7/10, Batch 90/97, Loss: 0.3289
Epoch 7/10, Train Loss: 0.2534, Valid Loss: 0.2334
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1784
Epoch 8/10, Batch 20/97, Loss: 0.1452
Epoch 8/10, Batch 30/97, Loss: 0.1204
Epoch 8/10, Batch 40/97, Loss: 0.1260
Epoch 8/10, Batch 50/97, Loss: 0.3142
Epoch 8/10, Batch 60/97, Loss: 0.2171
Epoch 8/10, Batch 70/97, Loss: 0.3220
Epoch 8/10, Batch 80/97, Loss: 0.1623
Epoch 8/10, Batch 90/97, Loss: 0.2559
Epoch 8/10, Train Loss: 0.2272, Valid Loss: 0.2332
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1482
Epoch 9/10, Batch 20/97, Loss: 0.1586
Epoch 9/10, Batch 30/97, Loss: 0.1746
Epoch 9/10, Batch 40/97, Loss: 0.1320
Epoch 9/10, Batch 50/97, Loss: 0.1593
Epoch 9/10, Batch 60/97, Loss: 0.1525
Epoch 9/10, Batch 70/97, Loss: 0.1621
Epoch 9/10, Batch 80/97, Loss: 0.0985
Epoch 9/10, Batch 90/97, Loss: 0.1567
Epoch 9/10, Train Loss: 0.2046, Valid Loss: 0.2280
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2793
Epoch 10/10, Batch 20/97, Loss: 0.1971
Epoch 10/10, Batch 30/97, Loss: 0.1450
Epoch 10/10, Batch 40/97, Loss: 0.1715
Epoch 10/10, Batch 50/97, Loss: 0.4426
Epoch 10/10, Batch 60/97, Loss: 0.1509
Epoch 10/10, Batch 70/97, Loss: 0.2128
Epoch 10/10, Batch 80/97, Loss: 0.2195
Epoch 10/10, Batch 90/97, Loss: 0.3739
Epoch 10/10, Train Loss: 0.2078, Valid Loss: 0.2227
Model saved!
Accuracy: 0.9100
Precision: 0.9084
Recall: 0.9100
F1-score: 0.9088
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5169
Epoch 1/10, Batch 20/97, Loss: 0.9541
Epoch 1/10, Batch 30/97, Loss: 0.8487
Epoch 1/10, Batch 40/97, Loss: 0.6815
Epoch 1/10, Batch 50/97, Loss: 0.5742
Epoch 1/10, Batch 60/97, Loss: 0.5873
Epoch 1/10, Batch 70/97, Loss: 0.4422
Epoch 1/10, Batch 80/97, Loss: 0.3570
Epoch 1/10, Batch 90/97, Loss: 0.3833
Epoch 1/10, Train Loss: 0.7667, Valid Loss: 0.4650
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4066
Epoch 2/10, Batch 20/97, Loss: 0.4319
Epoch 2/10, Batch 30/97, Loss: 0.4693
Epoch 2/10, Batch 40/97, Loss: 0.4423
Epoch 2/10, Batch 50/97, Loss: 0.6944
Epoch 2/10, Batch 60/97, Loss: 0.2720
Epoch 2/10, Batch 70/97, Loss: 0.3959
Epoch 2/10, Batch 80/97, Loss: 0.2165
Epoch 2/10, Batch 90/97, Loss: 0.3838
Epoch 2/10, Train Loss: 0.3926, Valid Loss: 0.3601
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2371
Epoch 3/10, Batch 20/97, Loss: 0.2195
Epoch 3/10, Batch 30/97, Loss: 0.2924
Epoch 3/10, Batch 40/97, Loss: 0.3000
Epoch 3/10, Batch 50/97, Loss: 0.3166
Epoch 3/10, Batch 60/97, Loss: 0.2751
Epoch 3/10, Batch 70/97, Loss: 0.2505
Epoch 3/10, Batch 80/97, Loss: 0.3599
Epoch 3/10, Batch 90/97, Loss: 0.3898
Epoch 3/10, Train Loss: 0.3105, Valid Loss: 0.3145
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3649
Epoch 4/10, Batch 20/97, Loss: 0.2510
Epoch 4/10, Batch 30/97, Loss: 0.4144
Epoch 4/10, Batch 40/97, Loss: 0.2900
Epoch 4/10, Batch 50/97, Loss: 0.2266
Epoch 4/10, Batch 60/97, Loss: 0.3550
Epoch 4/10, Batch 70/97, Loss: 0.2090
Epoch 4/10, Batch 80/97, Loss: 0.1812
Epoch 4/10, Batch 90/97, Loss: 0.3562
Epoch 4/10, Train Loss: 0.2809, Valid Loss: 0.2974
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1541
Epoch 5/10, Batch 20/97, Loss: 0.2865
Epoch 5/10, Batch 30/97, Loss: 0.1800
Epoch 5/10, Batch 40/97, Loss: 0.2841
Epoch 5/10, Batch 50/97, Loss: 0.2294
Epoch 5/10, Batch 60/97, Loss: 0.2338
Epoch 5/10, Batch 70/97, Loss: 0.3954
Epoch 5/10, Batch 80/97, Loss: 0.2431
Epoch 5/10, Batch 90/97, Loss: 0.2138
Epoch 5/10, Train Loss: 0.2530, Valid Loss: 0.2818
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1858
Epoch 6/10, Batch 20/97, Loss: 0.2852
Epoch 6/10, Batch 30/97, Loss: 0.1146
Epoch 6/10, Batch 40/97, Loss: 0.4685
Epoch 6/10, Batch 50/97, Loss: 0.1391
Epoch 6/10, Batch 60/97, Loss: 0.4684
Epoch 6/10, Batch 70/97, Loss: 0.2265
Epoch 6/10, Batch 80/97, Loss: 0.1657
Epoch 6/10, Batch 90/97, Loss: 0.3336
Epoch 6/10, Train Loss: 0.2346, Valid Loss: 0.2663
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3401
Epoch 7/10, Batch 20/97, Loss: 0.1218
Epoch 7/10, Batch 30/97, Loss: 0.1808
Epoch 7/10, Batch 40/97, Loss: 0.1695
Epoch 7/10, Batch 50/97, Loss: 0.1115
Epoch 7/10, Batch 60/97, Loss: 0.3455
Epoch 7/10, Batch 70/97, Loss: 0.2386
Epoch 7/10, Batch 80/97, Loss: 0.1008
Epoch 7/10, Batch 90/97, Loss: 0.2055
Epoch 7/10, Train Loss: 0.2444, Valid Loss: 0.2595
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2116
Epoch 8/10, Batch 20/97, Loss: 0.1311
Epoch 8/10, Batch 30/97, Loss: 0.1819
Epoch 8/10, Batch 40/97, Loss: 0.2029
Epoch 8/10, Batch 50/97, Loss: 0.1706
Epoch 8/10, Batch 60/97, Loss: 0.1249
Epoch 8/10, Batch 70/97, Loss: 0.2414
Epoch 8/10, Batch 80/97, Loss: 0.1164
Epoch 8/10, Batch 90/97, Loss: 0.3520
Epoch 8/10, Train Loss: 0.2127, Valid Loss: 0.2570
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1483
Epoch 9/10, Batch 20/97, Loss: 0.0868
Epoch 9/10, Batch 30/97, Loss: 0.3042
Epoch 9/10, Batch 40/97, Loss: 0.1411
Epoch 9/10, Batch 50/97, Loss: 0.1858
Epoch 9/10, Batch 60/97, Loss: 0.2287
Epoch 9/10, Batch 70/97, Loss: 0.2345
Epoch 9/10, Batch 80/97, Loss: 0.1867
Epoch 9/10, Batch 90/97, Loss: 0.2441
Epoch 9/10, Train Loss: 0.1985, Valid Loss: 0.2544
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2618
Epoch 10/10, Batch 20/97, Loss: 0.1260
Epoch 10/10, Batch 30/97, Loss: 0.2171
Epoch 10/10, Batch 40/97, Loss: 0.1895
Epoch 10/10, Batch 50/97, Loss: 0.2689
Epoch 10/10, Batch 60/97, Loss: 0.1303
Epoch 10/10, Batch 70/97, Loss: 0.3443
Epoch 10/10, Batch 80/97, Loss: 0.1195
Epoch 10/10, Batch 90/97, Loss: 0.1337
Epoch 10/10, Train Loss: 0.1885, Valid Loss: 0.2492
Model saved!
Accuracy: 0.9147
Precision: 0.9122
Recall: 0.9147
F1-score: 0.9129
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5286
Epoch 1/10, Batch 20/97, Loss: 1.0195
Epoch 1/10, Batch 30/97, Loss: 0.8605
Epoch 1/10, Batch 40/97, Loss: 0.6803
Epoch 1/10, Batch 50/97, Loss: 0.6754
Epoch 1/10, Batch 60/97, Loss: 0.5720
Epoch 1/10, Batch 70/97, Loss: 0.4689
Epoch 1/10, Batch 80/97, Loss: 0.4505
Epoch 1/10, Batch 90/97, Loss: 0.3753
Epoch 1/10, Train Loss: 0.7701, Valid Loss: 0.4673
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3692
Epoch 2/10, Batch 20/97, Loss: 0.5073
Epoch 2/10, Batch 30/97, Loss: 0.3311
Epoch 2/10, Batch 40/97, Loss: 0.4334
Epoch 2/10, Batch 50/97, Loss: 0.5292
Epoch 2/10, Batch 60/97, Loss: 0.3128
Epoch 2/10, Batch 70/97, Loss: 0.3193
Epoch 2/10, Batch 80/97, Loss: 0.3025
Epoch 2/10, Batch 90/97, Loss: 0.2481
Epoch 2/10, Train Loss: 0.3928, Valid Loss: 0.3515
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2788
Epoch 3/10, Batch 20/97, Loss: 0.2793
Epoch 3/10, Batch 30/97, Loss: 0.3164
Epoch 3/10, Batch 40/97, Loss: 0.3778
Epoch 3/10, Batch 50/97, Loss: 0.2041
Epoch 3/10, Batch 60/97, Loss: 0.2819
Epoch 3/10, Batch 70/97, Loss: 0.1890
Epoch 3/10, Batch 80/97, Loss: 0.2501
Epoch 3/10, Batch 90/97, Loss: 0.2066
Epoch 3/10, Train Loss: 0.3201, Valid Loss: 0.3059
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4771
Epoch 4/10, Batch 20/97, Loss: 0.1277
Epoch 4/10, Batch 30/97, Loss: 0.4844
Epoch 4/10, Batch 40/97, Loss: 0.2373
Epoch 4/10, Batch 50/97, Loss: 0.2191
Epoch 4/10, Batch 60/97, Loss: 0.2077
Epoch 4/10, Batch 70/97, Loss: 0.2228
Epoch 4/10, Batch 80/97, Loss: 0.3128
Epoch 4/10, Batch 90/97, Loss: 0.2487
Epoch 4/10, Train Loss: 0.2833, Valid Loss: 0.2811
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3304
Epoch 5/10, Batch 20/97, Loss: 0.1437
Epoch 5/10, Batch 30/97, Loss: 0.1832
Epoch 5/10, Batch 40/97, Loss: 0.1765
Epoch 5/10, Batch 50/97, Loss: 0.1663
Epoch 5/10, Batch 60/97, Loss: 0.2530
Epoch 5/10, Batch 70/97, Loss: 0.1917
Epoch 5/10, Batch 80/97, Loss: 0.2113
Epoch 5/10, Batch 90/97, Loss: 0.2895
Epoch 5/10, Train Loss: 0.2582, Valid Loss: 0.2634
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1818
Epoch 6/10, Batch 20/97, Loss: 0.2603
Epoch 6/10, Batch 30/97, Loss: 0.2618
Epoch 6/10, Batch 40/97, Loss: 0.1886
Epoch 6/10, Batch 50/97, Loss: 0.2093
Epoch 6/10, Batch 60/97, Loss: 0.2827
Epoch 6/10, Batch 70/97, Loss: 0.2518
Epoch 6/10, Batch 80/97, Loss: 0.3010
Epoch 6/10, Batch 90/97, Loss: 0.2434
Epoch 6/10, Train Loss: 0.2426, Valid Loss: 0.2532
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2064
Epoch 7/10, Batch 20/97, Loss: 0.0688
Epoch 7/10, Batch 30/97, Loss: 0.1941
Epoch 7/10, Batch 40/97, Loss: 0.2202
Epoch 7/10, Batch 50/97, Loss: 0.3400
Epoch 7/10, Batch 60/97, Loss: 0.2769
Epoch 7/10, Batch 70/97, Loss: 0.1637
Epoch 7/10, Batch 80/97, Loss: 0.1952
Epoch 7/10, Batch 90/97, Loss: 0.2987
Epoch 7/10, Train Loss: 0.2389, Valid Loss: 0.2460
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1411
Epoch 8/10, Batch 20/97, Loss: 0.1929
Epoch 8/10, Batch 30/97, Loss: 0.1966
Epoch 8/10, Batch 40/97, Loss: 0.1292
Epoch 8/10, Batch 50/97, Loss: 0.1813
Epoch 8/10, Batch 60/97, Loss: 0.2108
Epoch 8/10, Batch 70/97, Loss: 0.2601
Epoch 8/10, Batch 80/97, Loss: 0.1596
Epoch 8/10, Batch 90/97, Loss: 0.2943
Epoch 8/10, Train Loss: 0.2182, Valid Loss: 0.2406
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1640
Epoch 9/10, Batch 20/97, Loss: 0.0977
Epoch 9/10, Batch 30/97, Loss: 0.2330
Epoch 9/10, Batch 40/97, Loss: 0.1140
Epoch 9/10, Batch 50/97, Loss: 0.1567
Epoch 9/10, Batch 60/97, Loss: 0.2285
Epoch 9/10, Batch 70/97, Loss: 0.1852
Epoch 9/10, Batch 80/97, Loss: 0.2634
Epoch 9/10, Batch 90/97, Loss: 0.2116
Epoch 9/10, Train Loss: 0.2115, Valid Loss: 0.2319
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2942
Epoch 10/10, Batch 20/97, Loss: 0.1386
Epoch 10/10, Batch 30/97, Loss: 0.1210
Epoch 10/10, Batch 40/97, Loss: 0.1310
Epoch 10/10, Batch 50/97, Loss: 0.2704
Epoch 10/10, Batch 60/97, Loss: 0.1331
Epoch 10/10, Batch 70/97, Loss: 0.2019
Epoch 10/10, Batch 80/97, Loss: 0.1852
Epoch 10/10, Batch 90/97, Loss: 0.1835
Epoch 10/10, Train Loss: 0.1842, Valid Loss: 0.2228
Model saved!
Accuracy: 0.9159
Precision: 0.9137
Recall: 0.9159
F1-score: 0.9145
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.3855
Epoch 1/10, Batch 20/97, Loss: 1.0508
Epoch 1/10, Batch 30/97, Loss: 0.8772
Epoch 1/10, Batch 40/97, Loss: 0.7251
Epoch 1/10, Batch 50/97, Loss: 0.5579
Epoch 1/10, Batch 60/97, Loss: 0.5795
Epoch 1/10, Batch 70/97, Loss: 0.4705
Epoch 1/10, Batch 80/97, Loss: 0.4816
Epoch 1/10, Batch 90/97, Loss: 0.5392
Epoch 1/10, Train Loss: 0.7746, Valid Loss: 0.4475
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4448
Epoch 2/10, Batch 20/97, Loss: 0.4019
Epoch 2/10, Batch 30/97, Loss: 0.4128
Epoch 2/10, Batch 40/97, Loss: 0.3578
Epoch 2/10, Batch 50/97, Loss: 0.5394
Epoch 2/10, Batch 60/97, Loss: 0.4114
Epoch 2/10, Batch 70/97, Loss: 0.3567
Epoch 2/10, Batch 80/97, Loss: 0.3878
Epoch 2/10, Batch 90/97, Loss: 0.3502
Epoch 2/10, Train Loss: 0.3934, Valid Loss: 0.3449
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3708
Epoch 3/10, Batch 20/97, Loss: 0.3292
Epoch 3/10, Batch 30/97, Loss: 0.2575
Epoch 3/10, Batch 40/97, Loss: 0.2971
Epoch 3/10, Batch 50/97, Loss: 0.2797
Epoch 3/10, Batch 60/97, Loss: 0.3419
Epoch 3/10, Batch 70/97, Loss: 0.1647
Epoch 3/10, Batch 80/97, Loss: 0.2795
Epoch 3/10, Batch 90/97, Loss: 0.2076
Epoch 3/10, Train Loss: 0.3269, Valid Loss: 0.3083
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2617
Epoch 4/10, Batch 20/97, Loss: 0.1958
Epoch 4/10, Batch 30/97, Loss: 0.4740
Epoch 4/10, Batch 40/97, Loss: 0.2940
Epoch 4/10, Batch 50/97, Loss: 0.1052
Epoch 4/10, Batch 60/97, Loss: 0.3027
Epoch 4/10, Batch 70/97, Loss: 0.2693
Epoch 4/10, Batch 80/97, Loss: 0.3765
Epoch 4/10, Batch 90/97, Loss: 0.2390
Epoch 4/10, Train Loss: 0.2856, Valid Loss: 0.2904
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2658
Epoch 5/10, Batch 20/97, Loss: 0.2464
Epoch 5/10, Batch 30/97, Loss: 0.1636
Epoch 5/10, Batch 40/97, Loss: 0.1432
Epoch 5/10, Batch 50/97, Loss: 0.2357
Epoch 5/10, Batch 60/97, Loss: 0.2214
Epoch 5/10, Batch 70/97, Loss: 0.2053
Epoch 5/10, Batch 80/97, Loss: 0.3304
Epoch 5/10, Batch 90/97, Loss: 0.2883
Epoch 5/10, Train Loss: 0.2570, Valid Loss: 0.2825
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2196
Epoch 6/10, Batch 20/97, Loss: 0.1646
Epoch 6/10, Batch 30/97, Loss: 0.2008
Epoch 6/10, Batch 40/97, Loss: 0.3827
Epoch 6/10, Batch 50/97, Loss: 0.2160
Epoch 6/10, Batch 60/97, Loss: 0.3053
Epoch 6/10, Batch 70/97, Loss: 0.1438
Epoch 6/10, Batch 80/97, Loss: 0.1195
Epoch 6/10, Batch 90/97, Loss: 0.1672
Epoch 6/10, Train Loss: 0.2408, Valid Loss: 0.2793
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3792
Epoch 7/10, Batch 20/97, Loss: 0.1650
Epoch 7/10, Batch 30/97, Loss: 0.2206
Epoch 7/10, Batch 40/97, Loss: 0.1924
Epoch 7/10, Batch 50/97, Loss: 0.2895
Epoch 7/10, Batch 60/97, Loss: 0.4332
Epoch 7/10, Batch 70/97, Loss: 0.1818
Epoch 7/10, Batch 80/97, Loss: 0.2963
Epoch 7/10, Batch 90/97, Loss: 0.3043
Epoch 7/10, Train Loss: 0.2387, Valid Loss: 0.2606
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1543
Epoch 8/10, Batch 20/97, Loss: 0.2063
Epoch 8/10, Batch 30/97, Loss: 0.1511
Epoch 8/10, Batch 40/97, Loss: 0.1110
Epoch 8/10, Batch 50/97, Loss: 0.1752
Epoch 8/10, Batch 60/97, Loss: 0.1829
Epoch 8/10, Batch 70/97, Loss: 0.1684
Epoch 8/10, Batch 80/97, Loss: 0.1260
Epoch 8/10, Batch 90/97, Loss: 0.2078
Epoch 8/10, Train Loss: 0.2172, Valid Loss: 0.2683
Epoch 9/10, Batch 10/97, Loss: 0.1478
Epoch 9/10, Batch 20/97, Loss: 0.1246
Epoch 9/10, Batch 30/97, Loss: 0.3493
Epoch 9/10, Batch 40/97, Loss: 0.1277
Epoch 9/10, Batch 50/97, Loss: 0.2985
Epoch 9/10, Batch 60/97, Loss: 0.1110
Epoch 9/10, Batch 70/97, Loss: 0.2635
Epoch 9/10, Batch 80/97, Loss: 0.2104
Epoch 9/10, Batch 90/97, Loss: 0.2187
Epoch 9/10, Train Loss: 0.2089, Valid Loss: 0.2576
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2807
Epoch 10/10, Batch 20/97, Loss: 0.1506
Epoch 10/10, Batch 30/97, Loss: 0.1274
Epoch 10/10, Batch 40/97, Loss: 0.2850
Epoch 10/10, Batch 50/97, Loss: 0.2309
Epoch 10/10, Batch 60/97, Loss: 0.0834
Epoch 10/10, Batch 70/97, Loss: 0.0934
Epoch 10/10, Batch 80/97, Loss: 0.2535
Epoch 10/10, Batch 90/97, Loss: 0.2632
Epoch 10/10, Train Loss: 0.1982, Valid Loss: 0.2540
Model saved!
Accuracy: 0.9182
Precision: 0.9158
Recall: 0.9182
F1-score: 0.9164
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 10. Fitness: 0.9182
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5379
Epoch 1/10, Batch 20/97, Loss: 0.9635
Epoch 1/10, Batch 30/97, Loss: 0.8967
Epoch 1/10, Batch 40/97, Loss: 0.8431
Epoch 1/10, Batch 50/97, Loss: 0.6824
Epoch 1/10, Batch 60/97, Loss: 0.6282
Epoch 1/10, Batch 70/97, Loss: 0.4233
Epoch 1/10, Batch 80/97, Loss: 0.5697
Epoch 1/10, Batch 90/97, Loss: 0.5614
Epoch 1/10, Train Loss: 0.7710, Valid Loss: 0.4258
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4866
Epoch 2/10, Batch 20/97, Loss: 0.4846
Epoch 2/10, Batch 30/97, Loss: 0.3538
Epoch 2/10, Batch 40/97, Loss: 0.5292
Epoch 2/10, Batch 50/97, Loss: 0.6035
Epoch 2/10, Batch 60/97, Loss: 0.3900
Epoch 2/10, Batch 70/97, Loss: 0.2526
Epoch 2/10, Batch 80/97, Loss: 0.2990
Epoch 2/10, Batch 90/97, Loss: 0.3945
Epoch 2/10, Train Loss: 0.3890, Valid Loss: 0.3132
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3859
Epoch 3/10, Batch 20/97, Loss: 0.3405
Epoch 3/10, Batch 30/97, Loss: 0.1386
Epoch 3/10, Batch 40/97, Loss: 0.3307
Epoch 3/10, Batch 50/97, Loss: 0.3593
Epoch 3/10, Batch 60/97, Loss: 0.3082
Epoch 3/10, Batch 70/97, Loss: 0.2219
Epoch 3/10, Batch 80/97, Loss: 0.4196
Epoch 3/10, Batch 90/97, Loss: 0.2409
Epoch 3/10, Train Loss: 0.3187, Valid Loss: 0.2722
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2383
Epoch 4/10, Batch 20/97, Loss: 0.2288
Epoch 4/10, Batch 30/97, Loss: 0.3816
Epoch 4/10, Batch 40/97, Loss: 0.4318
Epoch 4/10, Batch 50/97, Loss: 0.2987
Epoch 4/10, Batch 60/97, Loss: 0.2743
Epoch 4/10, Batch 70/97, Loss: 0.3401
Epoch 4/10, Batch 80/97, Loss: 0.3601
Epoch 4/10, Batch 90/97, Loss: 0.2366
Epoch 4/10, Train Loss: 0.2839, Valid Loss: 0.2503
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1429
Epoch 5/10, Batch 20/97, Loss: 0.1741
Epoch 5/10, Batch 30/97, Loss: 0.3166
Epoch 5/10, Batch 40/97, Loss: 0.1477
Epoch 5/10, Batch 50/97, Loss: 0.2084
Epoch 5/10, Batch 60/97, Loss: 0.2674
Epoch 5/10, Batch 70/97, Loss: 0.2700
Epoch 5/10, Batch 80/97, Loss: 0.3687
Epoch 5/10, Batch 90/97, Loss: 0.2337
Epoch 5/10, Train Loss: 0.2600, Valid Loss: 0.2383
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2534
Epoch 6/10, Batch 20/97, Loss: 0.1890
Epoch 6/10, Batch 30/97, Loss: 0.2009
Epoch 6/10, Batch 40/97, Loss: 0.3381
Epoch 6/10, Batch 50/97, Loss: 0.3170
Epoch 6/10, Batch 60/97, Loss: 0.3098
Epoch 6/10, Batch 70/97, Loss: 0.1406
Epoch 6/10, Batch 80/97, Loss: 0.1360
Epoch 6/10, Batch 90/97, Loss: 0.1336
Epoch 6/10, Train Loss: 0.2476, Valid Loss: 0.2356
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3795
Epoch 7/10, Batch 20/97, Loss: 0.1372
Epoch 7/10, Batch 30/97, Loss: 0.2420
Epoch 7/10, Batch 40/97, Loss: 0.1826
Epoch 7/10, Batch 50/97, Loss: 0.2371
Epoch 7/10, Batch 60/97, Loss: 0.3576
Epoch 7/10, Batch 70/97, Loss: 0.3117
Epoch 7/10, Batch 80/97, Loss: 0.2136
Epoch 7/10, Batch 90/97, Loss: 0.2417
Epoch 7/10, Train Loss: 0.2427, Valid Loss: 0.2270
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2011
Epoch 8/10, Batch 20/97, Loss: 0.1597
Epoch 8/10, Batch 30/97, Loss: 0.1720
Epoch 8/10, Batch 40/97, Loss: 0.2322
Epoch 8/10, Batch 50/97, Loss: 0.1568
Epoch 8/10, Batch 60/97, Loss: 0.0955
Epoch 8/10, Batch 70/97, Loss: 0.2378
Epoch 8/10, Batch 80/97, Loss: 0.2979
Epoch 8/10, Batch 90/97, Loss: 0.2105
Epoch 8/10, Train Loss: 0.2194, Valid Loss: 0.2107
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0631
Epoch 9/10, Batch 20/97, Loss: 0.1030
Epoch 9/10, Batch 30/97, Loss: 0.1611
Epoch 9/10, Batch 40/97, Loss: 0.2863
Epoch 9/10, Batch 50/97, Loss: 0.1399
Epoch 9/10, Batch 60/97, Loss: 0.1296
Epoch 9/10, Batch 70/97, Loss: 0.2992
Epoch 9/10, Batch 80/97, Loss: 0.2568
Epoch 9/10, Batch 90/97, Loss: 0.2361
Epoch 9/10, Train Loss: 0.2074, Valid Loss: 0.2101
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1214
Epoch 10/10, Batch 20/97, Loss: 0.2088
Epoch 10/10, Batch 30/97, Loss: 0.1540
Epoch 10/10, Batch 40/97, Loss: 0.2149
Epoch 10/10, Batch 50/97, Loss: 0.3662
Epoch 10/10, Batch 60/97, Loss: 0.0816
Epoch 10/10, Batch 70/97, Loss: 0.1479
Epoch 10/10, Batch 80/97, Loss: 0.1842
Epoch 10/10, Batch 90/97, Loss: 0.2371
Epoch 10/10, Train Loss: 0.1929, Valid Loss: 0.2057
Model saved!
Accuracy: 0.9077
Precision: 0.9058
Recall: 0.9077
F1-score: 0.9060
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5111
Epoch 1/10, Batch 20/97, Loss: 0.9946
Epoch 1/10, Batch 30/97, Loss: 0.8856
Epoch 1/10, Batch 40/97, Loss: 0.8310
Epoch 1/10, Batch 50/97, Loss: 0.6156
Epoch 1/10, Batch 60/97, Loss: 0.5702
Epoch 1/10, Batch 70/97, Loss: 0.4813
Epoch 1/10, Batch 80/97, Loss: 0.4867
Epoch 1/10, Batch 90/97, Loss: 0.5787
Epoch 1/10, Train Loss: 0.7913, Valid Loss: 0.4232
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3784
Epoch 2/10, Batch 20/97, Loss: 0.4592
Epoch 2/10, Batch 30/97, Loss: 0.4220
Epoch 2/10, Batch 40/97, Loss: 0.4163
Epoch 2/10, Batch 50/97, Loss: 0.4965
Epoch 2/10, Batch 60/97, Loss: 0.2762
Epoch 2/10, Batch 70/97, Loss: 0.2778
Epoch 2/10, Batch 80/97, Loss: 0.3419
Epoch 2/10, Batch 90/97, Loss: 0.4502
Epoch 2/10, Train Loss: 0.4073, Valid Loss: 0.3146
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3322
Epoch 3/10, Batch 20/97, Loss: 0.2539
Epoch 3/10, Batch 30/97, Loss: 0.2591
Epoch 3/10, Batch 40/97, Loss: 0.2897
Epoch 3/10, Batch 50/97, Loss: 0.3854
Epoch 3/10, Batch 60/97, Loss: 0.2135
Epoch 3/10, Batch 70/97, Loss: 0.2677
Epoch 3/10, Batch 80/97, Loss: 0.3857
Epoch 3/10, Batch 90/97, Loss: 0.2806
Epoch 3/10, Train Loss: 0.3330, Valid Loss: 0.2732
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3426
Epoch 4/10, Batch 20/97, Loss: 0.3636
Epoch 4/10, Batch 30/97, Loss: 0.3366
Epoch 4/10, Batch 40/97, Loss: 0.4777
Epoch 4/10, Batch 50/97, Loss: 0.2621
Epoch 4/10, Batch 60/97, Loss: 0.2751
Epoch 4/10, Batch 70/97, Loss: 0.1701
Epoch 4/10, Batch 80/97, Loss: 0.3120
Epoch 4/10, Batch 90/97, Loss: 0.3152
Epoch 4/10, Train Loss: 0.2948, Valid Loss: 0.2566
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3756
Epoch 5/10, Batch 20/97, Loss: 0.1106
Epoch 5/10, Batch 30/97, Loss: 0.1676
Epoch 5/10, Batch 40/97, Loss: 0.2452
Epoch 5/10, Batch 50/97, Loss: 0.2529
Epoch 5/10, Batch 60/97, Loss: 0.3771
Epoch 5/10, Batch 70/97, Loss: 0.1505
Epoch 5/10, Batch 80/97, Loss: 0.3436
Epoch 5/10, Batch 90/97, Loss: 0.3822
Epoch 5/10, Train Loss: 0.2727, Valid Loss: 0.2378
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2452
Epoch 6/10, Batch 20/97, Loss: 0.2178
Epoch 6/10, Batch 30/97, Loss: 0.1548
Epoch 6/10, Batch 40/97, Loss: 0.2093
Epoch 6/10, Batch 50/97, Loss: 0.1556
Epoch 6/10, Batch 60/97, Loss: 0.2772
Epoch 6/10, Batch 70/97, Loss: 0.2085
Epoch 6/10, Batch 80/97, Loss: 0.2068
Epoch 6/10, Batch 90/97, Loss: 0.2499
Epoch 6/10, Train Loss: 0.2511, Valid Loss: 0.2358
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3469
Epoch 7/10, Batch 20/97, Loss: 0.0952
Epoch 7/10, Batch 30/97, Loss: 0.1138
Epoch 7/10, Batch 40/97, Loss: 0.2356
Epoch 7/10, Batch 50/97, Loss: 0.1717
Epoch 7/10, Batch 60/97, Loss: 0.4578
Epoch 7/10, Batch 70/97, Loss: 0.2118
Epoch 7/10, Batch 80/97, Loss: 0.2456
Epoch 7/10, Batch 90/97, Loss: 0.3393
Epoch 7/10, Train Loss: 0.2500, Valid Loss: 0.2251
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2103
Epoch 8/10, Batch 20/97, Loss: 0.1723
Epoch 8/10, Batch 30/97, Loss: 0.2574
Epoch 8/10, Batch 40/97, Loss: 0.2406
Epoch 8/10, Batch 50/97, Loss: 0.1577
Epoch 8/10, Batch 60/97, Loss: 0.0728
Epoch 8/10, Batch 70/97, Loss: 0.2776
Epoch 8/10, Batch 80/97, Loss: 0.1549
Epoch 8/10, Batch 90/97, Loss: 0.2510
Epoch 8/10, Train Loss: 0.2260, Valid Loss: 0.2131
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1183
Epoch 9/10, Batch 20/97, Loss: 0.0969
Epoch 9/10, Batch 30/97, Loss: 0.1889
Epoch 9/10, Batch 40/97, Loss: 0.0841
Epoch 9/10, Batch 50/97, Loss: 0.2002
Epoch 9/10, Batch 60/97, Loss: 0.1523
Epoch 9/10, Batch 70/97, Loss: 0.2384
Epoch 9/10, Batch 80/97, Loss: 0.1069
Epoch 9/10, Batch 90/97, Loss: 0.4402
Epoch 9/10, Train Loss: 0.2141, Valid Loss: 0.2201
Epoch 10/10, Batch 10/97, Loss: 0.4325
Epoch 10/10, Batch 20/97, Loss: 0.2401
Epoch 10/10, Batch 30/97, Loss: 0.1899
Epoch 10/10, Batch 40/97, Loss: 0.1853
Epoch 10/10, Batch 50/97, Loss: 0.4494
Epoch 10/10, Batch 60/97, Loss: 0.1227
Epoch 10/10, Batch 70/97, Loss: 0.1582
Epoch 10/10, Batch 80/97, Loss: 0.1364
Epoch 10/10, Batch 90/97, Loss: 0.1837
Epoch 10/10, Train Loss: 0.2067, Valid Loss: 0.2093
Model saved!
Accuracy: 0.9124
Precision: 0.9116
Recall: 0.9124
F1-score: 0.9113
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4749
Epoch 1/10, Batch 20/97, Loss: 0.9525
Epoch 1/10, Batch 30/97, Loss: 0.9218
Epoch 1/10, Batch 40/97, Loss: 0.6626
Epoch 1/10, Batch 50/97, Loss: 0.5690
Epoch 1/10, Batch 60/97, Loss: 0.5433
Epoch 1/10, Batch 70/97, Loss: 0.4783
Epoch 1/10, Batch 80/97, Loss: 0.4993
Epoch 1/10, Batch 90/97, Loss: 0.5186
Epoch 1/10, Train Loss: 0.7800, Valid Loss: 0.4565
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4826
Epoch 2/10, Batch 20/97, Loss: 0.5068
Epoch 2/10, Batch 30/97, Loss: 0.3489
Epoch 2/10, Batch 40/97, Loss: 0.4209
Epoch 2/10, Batch 50/97, Loss: 0.4203
Epoch 2/10, Batch 60/97, Loss: 0.2772
Epoch 2/10, Batch 70/97, Loss: 0.3000
Epoch 2/10, Batch 80/97, Loss: 0.2290
Epoch 2/10, Batch 90/97, Loss: 0.4250
Epoch 2/10, Train Loss: 0.3992, Valid Loss: 0.3450
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4701
Epoch 3/10, Batch 20/97, Loss: 0.2872
Epoch 3/10, Batch 30/97, Loss: 0.3468
Epoch 3/10, Batch 40/97, Loss: 0.4125
Epoch 3/10, Batch 50/97, Loss: 0.3298
Epoch 3/10, Batch 60/97, Loss: 0.2183
Epoch 3/10, Batch 70/97, Loss: 0.2061
Epoch 3/10, Batch 80/97, Loss: 0.2687
Epoch 3/10, Batch 90/97, Loss: 0.2252
Epoch 3/10, Train Loss: 0.3263, Valid Loss: 0.2980
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3919
Epoch 4/10, Batch 20/97, Loss: 0.3156
Epoch 4/10, Batch 30/97, Loss: 0.2525
Epoch 4/10, Batch 40/97, Loss: 0.3482
Epoch 4/10, Batch 50/97, Loss: 0.1854
Epoch 4/10, Batch 60/97, Loss: 0.2016
Epoch 4/10, Batch 70/97, Loss: 0.2081
Epoch 4/10, Batch 80/97, Loss: 0.2782
Epoch 4/10, Batch 90/97, Loss: 0.2476
Epoch 4/10, Train Loss: 0.2909, Valid Loss: 0.2776
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1924
Epoch 5/10, Batch 20/97, Loss: 0.2021
Epoch 5/10, Batch 30/97, Loss: 0.3191
Epoch 5/10, Batch 40/97, Loss: 0.2348
Epoch 5/10, Batch 50/97, Loss: 0.3108
Epoch 5/10, Batch 60/97, Loss: 0.2445
Epoch 5/10, Batch 70/97, Loss: 0.3493
Epoch 5/10, Batch 80/97, Loss: 0.2824
Epoch 5/10, Batch 90/97, Loss: 0.3224
Epoch 5/10, Train Loss: 0.2641, Valid Loss: 0.2612
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3959
Epoch 6/10, Batch 20/97, Loss: 0.1909
Epoch 6/10, Batch 30/97, Loss: 0.2499
Epoch 6/10, Batch 40/97, Loss: 0.2792
Epoch 6/10, Batch 50/97, Loss: 0.3020
Epoch 6/10, Batch 60/97, Loss: 0.1719
Epoch 6/10, Batch 70/97, Loss: 0.3136
Epoch 6/10, Batch 80/97, Loss: 0.1590
Epoch 6/10, Batch 90/97, Loss: 0.2567
Epoch 6/10, Train Loss: 0.2384, Valid Loss: 0.2526
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3378
Epoch 7/10, Batch 20/97, Loss: 0.1148
Epoch 7/10, Batch 30/97, Loss: 0.1549
Epoch 7/10, Batch 40/97, Loss: 0.1421
Epoch 7/10, Batch 50/97, Loss: 0.3399
Epoch 7/10, Batch 60/97, Loss: 0.3028
Epoch 7/10, Batch 70/97, Loss: 0.1872
Epoch 7/10, Batch 80/97, Loss: 0.1322
Epoch 7/10, Batch 90/97, Loss: 0.1682
Epoch 7/10, Train Loss: 0.2416, Valid Loss: 0.2410
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2594
Epoch 8/10, Batch 20/97, Loss: 0.1867
Epoch 8/10, Batch 30/97, Loss: 0.1260
Epoch 8/10, Batch 40/97, Loss: 0.1440
Epoch 8/10, Batch 50/97, Loss: 0.2283
Epoch 8/10, Batch 60/97, Loss: 0.1802
Epoch 8/10, Batch 70/97, Loss: 0.3213
Epoch 8/10, Batch 80/97, Loss: 0.1537
Epoch 8/10, Batch 90/97, Loss: 0.1566
Epoch 8/10, Train Loss: 0.2240, Valid Loss: 0.2427
Epoch 9/10, Batch 10/97, Loss: 0.1100
Epoch 9/10, Batch 20/97, Loss: 0.0830
Epoch 9/10, Batch 30/97, Loss: 0.2878
Epoch 9/10, Batch 40/97, Loss: 0.1954
Epoch 9/10, Batch 50/97, Loss: 0.3030
Epoch 9/10, Batch 60/97, Loss: 0.1963
Epoch 9/10, Batch 70/97, Loss: 0.1663
Epoch 9/10, Batch 80/97, Loss: 0.2159
Epoch 9/10, Batch 90/97, Loss: 0.2144
Epoch 9/10, Train Loss: 0.2127, Valid Loss: 0.2379
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2457
Epoch 10/10, Batch 20/97, Loss: 0.0993
Epoch 10/10, Batch 30/97, Loss: 0.2387
Epoch 10/10, Batch 40/97, Loss: 0.2890
Epoch 10/10, Batch 50/97, Loss: 0.2765
Epoch 10/10, Batch 60/97, Loss: 0.2697
Epoch 10/10, Batch 70/97, Loss: 0.2029
Epoch 10/10, Batch 80/97, Loss: 0.2046
Epoch 10/10, Batch 90/97, Loss: 0.1457
Epoch 10/10, Train Loss: 0.2015, Valid Loss: 0.2291
Model saved!
Accuracy: 0.9112
Precision: 0.9092
Recall: 0.9112
F1-score: 0.9098
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5272
Epoch 1/10, Batch 20/97, Loss: 1.0053
Epoch 1/10, Batch 30/97, Loss: 0.8266
Epoch 1/10, Batch 40/97, Loss: 0.7456
Epoch 1/10, Batch 50/97, Loss: 0.5224
Epoch 1/10, Batch 60/97, Loss: 0.6207
Epoch 1/10, Batch 70/97, Loss: 0.4883
Epoch 1/10, Batch 80/97, Loss: 0.4145
Epoch 1/10, Batch 90/97, Loss: 0.5368
Epoch 1/10, Train Loss: 0.7696, Valid Loss: 0.4473
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4050
Epoch 2/10, Batch 20/97, Loss: 0.4496
Epoch 2/10, Batch 30/97, Loss: 0.4384
Epoch 2/10, Batch 40/97, Loss: 0.4044
Epoch 2/10, Batch 50/97, Loss: 0.5630
Epoch 2/10, Batch 60/97, Loss: 0.2656
Epoch 2/10, Batch 70/97, Loss: 0.3938
Epoch 2/10, Batch 80/97, Loss: 0.2490
Epoch 2/10, Batch 90/97, Loss: 0.2299
Epoch 2/10, Train Loss: 0.3874, Valid Loss: 0.3443
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2491
Epoch 3/10, Batch 20/97, Loss: 0.3080
Epoch 3/10, Batch 30/97, Loss: 0.1430
Epoch 3/10, Batch 40/97, Loss: 0.1773
Epoch 3/10, Batch 50/97, Loss: 0.2288
Epoch 3/10, Batch 60/97, Loss: 0.3766
Epoch 3/10, Batch 70/97, Loss: 0.2716
Epoch 3/10, Batch 80/97, Loss: 0.3257
Epoch 3/10, Batch 90/97, Loss: 0.1548
Epoch 3/10, Train Loss: 0.3077, Valid Loss: 0.3108
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1463
Epoch 4/10, Batch 20/97, Loss: 0.1970
Epoch 4/10, Batch 30/97, Loss: 0.3613
Epoch 4/10, Batch 40/97, Loss: 0.2454
Epoch 4/10, Batch 50/97, Loss: 0.3164
Epoch 4/10, Batch 60/97, Loss: 0.2528
Epoch 4/10, Batch 70/97, Loss: 0.1876
Epoch 4/10, Batch 80/97, Loss: 0.3618
Epoch 4/10, Batch 90/97, Loss: 0.2043
Epoch 4/10, Train Loss: 0.2718, Valid Loss: 0.2843
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3357
Epoch 5/10, Batch 20/97, Loss: 0.1217
Epoch 5/10, Batch 30/97, Loss: 0.1565
Epoch 5/10, Batch 40/97, Loss: 0.3212
Epoch 5/10, Batch 50/97, Loss: 0.1618
Epoch 5/10, Batch 60/97, Loss: 0.2954
Epoch 5/10, Batch 70/97, Loss: 0.1676
Epoch 5/10, Batch 80/97, Loss: 0.4857
Epoch 5/10, Batch 90/97, Loss: 0.3359
Epoch 5/10, Train Loss: 0.2503, Valid Loss: 0.2677
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3175
Epoch 6/10, Batch 20/97, Loss: 0.3282
Epoch 6/10, Batch 30/97, Loss: 0.2241
Epoch 6/10, Batch 40/97, Loss: 0.2993
Epoch 6/10, Batch 50/97, Loss: 0.1681
Epoch 6/10, Batch 60/97, Loss: 0.1695
Epoch 6/10, Batch 70/97, Loss: 0.3450
Epoch 6/10, Batch 80/97, Loss: 0.1566
Epoch 6/10, Batch 90/97, Loss: 0.3339
Epoch 6/10, Train Loss: 0.2246, Valid Loss: 0.2592
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1694
Epoch 7/10, Batch 20/97, Loss: 0.1386
Epoch 7/10, Batch 30/97, Loss: 0.1636
Epoch 7/10, Batch 40/97, Loss: 0.1238
Epoch 7/10, Batch 50/97, Loss: 0.3155
Epoch 7/10, Batch 60/97, Loss: 0.4121
Epoch 7/10, Batch 70/97, Loss: 0.1971
Epoch 7/10, Batch 80/97, Loss: 0.1712
Epoch 7/10, Batch 90/97, Loss: 0.2211
Epoch 7/10, Train Loss: 0.2273, Valid Loss: 0.2589
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1603
Epoch 8/10, Batch 20/97, Loss: 0.1156
Epoch 8/10, Batch 30/97, Loss: 0.1335
Epoch 8/10, Batch 40/97, Loss: 0.2704
Epoch 8/10, Batch 50/97, Loss: 0.1973
Epoch 8/10, Batch 60/97, Loss: 0.2624
Epoch 8/10, Batch 70/97, Loss: 0.2704
Epoch 8/10, Batch 80/97, Loss: 0.3242
Epoch 8/10, Batch 90/97, Loss: 0.1002
Epoch 8/10, Train Loss: 0.2100, Valid Loss: 0.2462
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2171
Epoch 9/10, Batch 20/97, Loss: 0.1468
Epoch 9/10, Batch 30/97, Loss: 0.3143
Epoch 9/10, Batch 40/97, Loss: 0.1485
Epoch 9/10, Batch 50/97, Loss: 0.1961
Epoch 9/10, Batch 60/97, Loss: 0.1201
Epoch 9/10, Batch 70/97, Loss: 0.2865
Epoch 9/10, Batch 80/97, Loss: 0.1306
Epoch 9/10, Batch 90/97, Loss: 0.2526
Epoch 9/10, Train Loss: 0.1994, Valid Loss: 0.2427
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1445
Epoch 10/10, Batch 20/97, Loss: 0.1062
Epoch 10/10, Batch 30/97, Loss: 0.0870
Epoch 10/10, Batch 40/97, Loss: 0.1137
Epoch 10/10, Batch 50/97, Loss: 0.2392
Epoch 10/10, Batch 60/97, Loss: 0.1513
Epoch 10/10, Batch 70/97, Loss: 0.1260
Epoch 10/10, Batch 80/97, Loss: 0.2549
Epoch 10/10, Batch 90/97, Loss: 0.2233
Epoch 10/10, Train Loss: 0.1898, Valid Loss: 0.2442
Accuracy: 0.9206
Precision: 0.9192
Recall: 0.9206
F1-score: 0.9197
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 14. Fitness: 0.9206
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4949
Epoch 1/10, Batch 20/97, Loss: 0.9719
Epoch 1/10, Batch 30/97, Loss: 0.9145
Epoch 1/10, Batch 40/97, Loss: 0.6481
Epoch 1/10, Batch 50/97, Loss: 0.5852
Epoch 1/10, Batch 60/97, Loss: 0.5546
Epoch 1/10, Batch 70/97, Loss: 0.5348
Epoch 1/10, Batch 80/97, Loss: 0.4415
Epoch 1/10, Batch 90/97, Loss: 0.4183
Epoch 1/10, Train Loss: 0.7697, Valid Loss: 0.4514
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4131
Epoch 2/10, Batch 20/97, Loss: 0.4819
Epoch 2/10, Batch 30/97, Loss: 0.3079
Epoch 2/10, Batch 40/97, Loss: 0.5455
Epoch 2/10, Batch 50/97, Loss: 0.5372
Epoch 2/10, Batch 60/97, Loss: 0.1883
Epoch 2/10, Batch 70/97, Loss: 0.2946
Epoch 2/10, Batch 80/97, Loss: 0.3484
Epoch 2/10, Batch 90/97, Loss: 0.2816
Epoch 2/10, Train Loss: 0.3920, Valid Loss: 0.3554
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2926
Epoch 3/10, Batch 20/97, Loss: 0.3224
Epoch 3/10, Batch 30/97, Loss: 0.2649
Epoch 3/10, Batch 40/97, Loss: 0.2518
Epoch 3/10, Batch 50/97, Loss: 0.3233
Epoch 3/10, Batch 60/97, Loss: 0.3171
Epoch 3/10, Batch 70/97, Loss: 0.1349
Epoch 3/10, Batch 80/97, Loss: 0.2534
Epoch 3/10, Batch 90/97, Loss: 0.2905
Epoch 3/10, Train Loss: 0.3175, Valid Loss: 0.3137
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2110
Epoch 4/10, Batch 20/97, Loss: 0.2013
Epoch 4/10, Batch 30/97, Loss: 0.3291
Epoch 4/10, Batch 40/97, Loss: 0.2483
Epoch 4/10, Batch 50/97, Loss: 0.2142
Epoch 4/10, Batch 60/97, Loss: 0.2457
Epoch 4/10, Batch 70/97, Loss: 0.2911
Epoch 4/10, Batch 80/97, Loss: 0.1862
Epoch 4/10, Batch 90/97, Loss: 0.2943
Epoch 4/10, Train Loss: 0.2838, Valid Loss: 0.2963
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1523
Epoch 5/10, Batch 20/97, Loss: 0.1873
Epoch 5/10, Batch 30/97, Loss: 0.1930
Epoch 5/10, Batch 40/97, Loss: 0.1206
Epoch 5/10, Batch 50/97, Loss: 0.2993
Epoch 5/10, Batch 60/97, Loss: 0.2182
Epoch 5/10, Batch 70/97, Loss: 0.1555
Epoch 5/10, Batch 80/97, Loss: 0.2481
Epoch 5/10, Batch 90/97, Loss: 0.2959
Epoch 5/10, Train Loss: 0.2501, Valid Loss: 0.2846
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2167
Epoch 6/10, Batch 20/97, Loss: 0.2269
Epoch 6/10, Batch 30/97, Loss: 0.1326
Epoch 6/10, Batch 40/97, Loss: 0.2589
Epoch 6/10, Batch 50/97, Loss: 0.2977
Epoch 6/10, Batch 60/97, Loss: 0.3718
Epoch 6/10, Batch 70/97, Loss: 0.1673
Epoch 6/10, Batch 80/97, Loss: 0.2239
Epoch 6/10, Batch 90/97, Loss: 0.2284
Epoch 6/10, Train Loss: 0.2391, Valid Loss: 0.2755
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4608
Epoch 7/10, Batch 20/97, Loss: 0.1971
Epoch 7/10, Batch 30/97, Loss: 0.2274
Epoch 7/10, Batch 40/97, Loss: 0.2775
Epoch 7/10, Batch 50/97, Loss: 0.1809
Epoch 7/10, Batch 60/97, Loss: 0.3304
Epoch 7/10, Batch 70/97, Loss: 0.2157
Epoch 7/10, Batch 80/97, Loss: 0.1606
Epoch 7/10, Batch 90/97, Loss: 0.2108
Epoch 7/10, Train Loss: 0.2451, Valid Loss: 0.2590
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1365
Epoch 8/10, Batch 20/97, Loss: 0.2307
Epoch 8/10, Batch 30/97, Loss: 0.0937
Epoch 8/10, Batch 40/97, Loss: 0.2563
Epoch 8/10, Batch 50/97, Loss: 0.1724
Epoch 8/10, Batch 60/97, Loss: 0.1277
Epoch 8/10, Batch 70/97, Loss: 0.2967
Epoch 8/10, Batch 80/97, Loss: 0.2744
Epoch 8/10, Batch 90/97, Loss: 0.1099
Epoch 8/10, Train Loss: 0.2180, Valid Loss: 0.2639
Epoch 9/10, Batch 10/97, Loss: 0.1436
Epoch 9/10, Batch 20/97, Loss: 0.0714
Epoch 9/10, Batch 30/97, Loss: 0.1822
Epoch 9/10, Batch 40/97, Loss: 0.1835
Epoch 9/10, Batch 50/97, Loss: 0.1628
Epoch 9/10, Batch 60/97, Loss: 0.2231
Epoch 9/10, Batch 70/97, Loss: 0.2370
Epoch 9/10, Batch 80/97, Loss: 0.2156
Epoch 9/10, Batch 90/97, Loss: 0.2809
Epoch 9/10, Train Loss: 0.2029, Valid Loss: 0.2550
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2474
Epoch 10/10, Batch 20/97, Loss: 0.1553
Epoch 10/10, Batch 30/97, Loss: 0.3268
Epoch 10/10, Batch 40/97, Loss: 0.3343
Epoch 10/10, Batch 50/97, Loss: 0.2970
Epoch 10/10, Batch 60/97, Loss: 0.1151
Epoch 10/10, Batch 70/97, Loss: 0.1895
Epoch 10/10, Batch 80/97, Loss: 0.1612
Epoch 10/10, Batch 90/97, Loss: 0.1402
Epoch 10/10, Train Loss: 0.1915, Valid Loss: 0.2507
Model saved!
Accuracy: 0.9159
Precision: 0.9135
Recall: 0.9159
F1-score: 0.9135
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4590
Epoch 1/10, Batch 20/97, Loss: 1.0198
Epoch 1/10, Batch 30/97, Loss: 0.8887
Epoch 1/10, Batch 40/97, Loss: 0.7463
Epoch 1/10, Batch 50/97, Loss: 0.6508
Epoch 1/10, Batch 60/97, Loss: 0.5913
Epoch 1/10, Batch 70/97, Loss: 0.6208
Epoch 1/10, Batch 80/97, Loss: 0.4948
Epoch 1/10, Batch 90/97, Loss: 0.5479
Epoch 1/10, Train Loss: 0.7763, Valid Loss: 0.4341
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3279
Epoch 2/10, Batch 20/97, Loss: 0.5568
Epoch 2/10, Batch 30/97, Loss: 0.3143
Epoch 2/10, Batch 40/97, Loss: 0.4214
Epoch 2/10, Batch 50/97, Loss: 0.4853
Epoch 2/10, Batch 60/97, Loss: 0.2985
Epoch 2/10, Batch 70/97, Loss: 0.3330
Epoch 2/10, Batch 80/97, Loss: 0.2676
Epoch 2/10, Batch 90/97, Loss: 0.3104
Epoch 2/10, Train Loss: 0.4017, Valid Loss: 0.3211
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3563
Epoch 3/10, Batch 20/97, Loss: 0.3879
Epoch 3/10, Batch 30/97, Loss: 0.2638
Epoch 3/10, Batch 40/97, Loss: 0.3431
Epoch 3/10, Batch 50/97, Loss: 0.3451
Epoch 3/10, Batch 60/97, Loss: 0.2105
Epoch 3/10, Batch 70/97, Loss: 0.3137
Epoch 3/10, Batch 80/97, Loss: 0.3644
Epoch 3/10, Batch 90/97, Loss: 0.2458
Epoch 3/10, Train Loss: 0.3291, Valid Loss: 0.2728
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3381
Epoch 4/10, Batch 20/97, Loss: 0.2741
Epoch 4/10, Batch 30/97, Loss: 0.4244
Epoch 4/10, Batch 40/97, Loss: 0.1898
Epoch 4/10, Batch 50/97, Loss: 0.2802
Epoch 4/10, Batch 60/97, Loss: 0.1899
Epoch 4/10, Batch 70/97, Loss: 0.2793
Epoch 4/10, Batch 80/97, Loss: 0.1936
Epoch 4/10, Batch 90/97, Loss: 0.2857
Epoch 4/10, Train Loss: 0.2901, Valid Loss: 0.2481
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2407
Epoch 5/10, Batch 20/97, Loss: 0.1775
Epoch 5/10, Batch 30/97, Loss: 0.2009
Epoch 5/10, Batch 40/97, Loss: 0.1629
Epoch 5/10, Batch 50/97, Loss: 0.2294
Epoch 5/10, Batch 60/97, Loss: 0.2718
Epoch 5/10, Batch 70/97, Loss: 0.2141
Epoch 5/10, Batch 80/97, Loss: 0.4420
Epoch 5/10, Batch 90/97, Loss: 0.3525
Epoch 5/10, Train Loss: 0.2666, Valid Loss: 0.2352
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2163
Epoch 6/10, Batch 20/97, Loss: 0.1475
Epoch 6/10, Batch 30/97, Loss: 0.1807
Epoch 6/10, Batch 40/97, Loss: 0.2533
Epoch 6/10, Batch 50/97, Loss: 0.1892
Epoch 6/10, Batch 60/97, Loss: 0.1906
Epoch 6/10, Batch 70/97, Loss: 0.2818
Epoch 6/10, Batch 80/97, Loss: 0.1690
Epoch 6/10, Batch 90/97, Loss: 0.2269
Epoch 6/10, Train Loss: 0.2454, Valid Loss: 0.2265
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3487
Epoch 7/10, Batch 20/97, Loss: 0.1608
Epoch 7/10, Batch 30/97, Loss: 0.1492
Epoch 7/10, Batch 40/97, Loss: 0.1302
Epoch 7/10, Batch 50/97, Loss: 0.3034
Epoch 7/10, Batch 60/97, Loss: 0.2573
Epoch 7/10, Batch 70/97, Loss: 0.1708
Epoch 7/10, Batch 80/97, Loss: 0.0682
Epoch 7/10, Batch 90/97, Loss: 0.2597
Epoch 7/10, Train Loss: 0.2544, Valid Loss: 0.2138
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1373
Epoch 8/10, Batch 20/97, Loss: 0.1171
Epoch 8/10, Batch 30/97, Loss: 0.1993
Epoch 8/10, Batch 40/97, Loss: 0.1625
Epoch 8/10, Batch 50/97, Loss: 0.2737
Epoch 8/10, Batch 60/97, Loss: 0.1101
Epoch 8/10, Batch 70/97, Loss: 0.2661
Epoch 8/10, Batch 80/97, Loss: 0.1117
Epoch 8/10, Batch 90/97, Loss: 0.1082
Epoch 8/10, Train Loss: 0.2195, Valid Loss: 0.2203
Epoch 9/10, Batch 10/97, Loss: 0.1942
Epoch 9/10, Batch 20/97, Loss: 0.1873
Epoch 9/10, Batch 30/97, Loss: 0.2892
Epoch 9/10, Batch 40/97, Loss: 0.2221
Epoch 9/10, Batch 50/97, Loss: 0.1777
Epoch 9/10, Batch 60/97, Loss: 0.0801
Epoch 9/10, Batch 70/97, Loss: 0.1660
Epoch 9/10, Batch 80/97, Loss: 0.0847
Epoch 9/10, Batch 90/97, Loss: 0.1935
Epoch 9/10, Train Loss: 0.2104, Valid Loss: 0.2137
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3497
Epoch 10/10, Batch 20/97, Loss: 0.1275
Epoch 10/10, Batch 30/97, Loss: 0.1017
Epoch 10/10, Batch 40/97, Loss: 0.1812
Epoch 10/10, Batch 50/97, Loss: 0.1958
Epoch 10/10, Batch 60/97, Loss: 0.1854
Epoch 10/10, Batch 70/97, Loss: 0.1466
Epoch 10/10, Batch 80/97, Loss: 0.2408
Epoch 10/10, Batch 90/97, Loss: 0.1371
Epoch 10/10, Train Loss: 0.2009, Valid Loss: 0.2004
Model saved!
Accuracy: 0.9171
Precision: 0.9149
Recall: 0.9171
F1-score: 0.9156
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4820
Epoch 1/10, Batch 20/97, Loss: 1.0133
Epoch 1/10, Batch 30/97, Loss: 0.9085
Epoch 1/10, Batch 40/97, Loss: 0.7090
Epoch 1/10, Batch 50/97, Loss: 0.6501
Epoch 1/10, Batch 60/97, Loss: 0.6088
Epoch 1/10, Batch 70/97, Loss: 0.6100
Epoch 1/10, Batch 80/97, Loss: 0.5159
Epoch 1/10, Batch 90/97, Loss: 0.6279
Epoch 1/10, Train Loss: 0.7678, Valid Loss: 0.4284
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4642
Epoch 2/10, Batch 20/97, Loss: 0.3807
Epoch 2/10, Batch 30/97, Loss: 0.4197
Epoch 2/10, Batch 40/97, Loss: 0.4654
Epoch 2/10, Batch 50/97, Loss: 0.7892
Epoch 2/10, Batch 60/97, Loss: 0.2687
Epoch 2/10, Batch 70/97, Loss: 0.2736
Epoch 2/10, Batch 80/97, Loss: 0.3649
Epoch 2/10, Batch 90/97, Loss: 0.4304
Epoch 2/10, Train Loss: 0.3976, Valid Loss: 0.3390
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3150
Epoch 3/10, Batch 20/97, Loss: 0.3907
Epoch 3/10, Batch 30/97, Loss: 0.3004
Epoch 3/10, Batch 40/97, Loss: 0.3438
Epoch 3/10, Batch 50/97, Loss: 0.2854
Epoch 3/10, Batch 60/97, Loss: 0.2023
Epoch 3/10, Batch 70/97, Loss: 0.2666
Epoch 3/10, Batch 80/97, Loss: 0.2558
Epoch 3/10, Batch 90/97, Loss: 0.3235
Epoch 3/10, Train Loss: 0.3167, Valid Loss: 0.3008
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2735
Epoch 4/10, Batch 20/97, Loss: 0.2832
Epoch 4/10, Batch 30/97, Loss: 0.2840
Epoch 4/10, Batch 40/97, Loss: 0.1811
Epoch 4/10, Batch 50/97, Loss: 0.1654
Epoch 4/10, Batch 60/97, Loss: 0.1303
Epoch 4/10, Batch 70/97, Loss: 0.2072
Epoch 4/10, Batch 80/97, Loss: 0.2332
Epoch 4/10, Batch 90/97, Loss: 0.4043
Epoch 4/10, Train Loss: 0.2753, Valid Loss: 0.2774
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1275
Epoch 5/10, Batch 20/97, Loss: 0.1520
Epoch 5/10, Batch 30/97, Loss: 0.1810
Epoch 5/10, Batch 40/97, Loss: 0.1557
Epoch 5/10, Batch 50/97, Loss: 0.2073
Epoch 5/10, Batch 60/97, Loss: 0.2195
Epoch 5/10, Batch 70/97, Loss: 0.1631
Epoch 5/10, Batch 80/97, Loss: 0.2449
Epoch 5/10, Batch 90/97, Loss: 0.1558
Epoch 5/10, Train Loss: 0.2440, Valid Loss: 0.2703
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1413
Epoch 6/10, Batch 20/97, Loss: 0.1973
Epoch 6/10, Batch 30/97, Loss: 0.1078
Epoch 6/10, Batch 40/97, Loss: 0.2062
Epoch 6/10, Batch 50/97, Loss: 0.3383
Epoch 6/10, Batch 60/97, Loss: 0.1491
Epoch 6/10, Batch 70/97, Loss: 0.2559
Epoch 6/10, Batch 80/97, Loss: 0.1515
Epoch 6/10, Batch 90/97, Loss: 0.1819
Epoch 6/10, Train Loss: 0.2371, Valid Loss: 0.2653
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2285
Epoch 7/10, Batch 20/97, Loss: 0.1435
Epoch 7/10, Batch 30/97, Loss: 0.2431
Epoch 7/10, Batch 40/97, Loss: 0.2511
Epoch 7/10, Batch 50/97, Loss: 0.3355
Epoch 7/10, Batch 60/97, Loss: 0.2664
Epoch 7/10, Batch 70/97, Loss: 0.1028
Epoch 7/10, Batch 80/97, Loss: 0.3257
Epoch 7/10, Batch 90/97, Loss: 0.3177
Epoch 7/10, Train Loss: 0.2403, Valid Loss: 0.2597
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1690
Epoch 8/10, Batch 20/97, Loss: 0.2326
Epoch 8/10, Batch 30/97, Loss: 0.1669
Epoch 8/10, Batch 40/97, Loss: 0.1653
Epoch 8/10, Batch 50/97, Loss: 0.3401
Epoch 8/10, Batch 60/97, Loss: 0.1365
Epoch 8/10, Batch 70/97, Loss: 0.2226
Epoch 8/10, Batch 80/97, Loss: 0.2157
Epoch 8/10, Batch 90/97, Loss: 0.1306
Epoch 8/10, Train Loss: 0.2191, Valid Loss: 0.2568
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2091
Epoch 9/10, Batch 20/97, Loss: 0.1162
Epoch 9/10, Batch 30/97, Loss: 0.3072
Epoch 9/10, Batch 40/97, Loss: 0.1256
Epoch 9/10, Batch 50/97, Loss: 0.2365
Epoch 9/10, Batch 60/97, Loss: 0.2176
Epoch 9/10, Batch 70/97, Loss: 0.1132
Epoch 9/10, Batch 80/97, Loss: 0.1350
Epoch 9/10, Batch 90/97, Loss: 0.1342
Epoch 9/10, Train Loss: 0.2043, Valid Loss: 0.2555
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2733
Epoch 10/10, Batch 20/97, Loss: 0.1089
Epoch 10/10, Batch 30/97, Loss: 0.1247
Epoch 10/10, Batch 40/97, Loss: 0.1498
Epoch 10/10, Batch 50/97, Loss: 0.3695
Epoch 10/10, Batch 60/97, Loss: 0.1050
Epoch 10/10, Batch 70/97, Loss: 0.1319
Epoch 10/10, Batch 80/97, Loss: 0.1952
Epoch 10/10, Batch 90/97, Loss: 0.0936
Epoch 10/10, Train Loss: 0.1949, Valid Loss: 0.2505
Model saved!
Accuracy: 0.9217
Precision: 0.9205
Recall: 0.9217
F1-score: 0.9208
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 17. Fitness: 0.9217
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5475
Epoch 1/10, Batch 20/97, Loss: 1.0187
Epoch 1/10, Batch 30/97, Loss: 0.8572
Epoch 1/10, Batch 40/97, Loss: 0.8085
Epoch 1/10, Batch 50/97, Loss: 0.7136
Epoch 1/10, Batch 60/97, Loss: 0.5984
Epoch 1/10, Batch 70/97, Loss: 0.4492
Epoch 1/10, Batch 80/97, Loss: 0.6317
Epoch 1/10, Batch 90/97, Loss: 0.6031
Epoch 1/10, Train Loss: 0.7799, Valid Loss: 0.4460
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4314
Epoch 2/10, Batch 20/97, Loss: 0.4579
Epoch 2/10, Batch 30/97, Loss: 0.4307
Epoch 2/10, Batch 40/97, Loss: 0.3700
Epoch 2/10, Batch 50/97, Loss: 0.6613
Epoch 2/10, Batch 60/97, Loss: 0.4056
Epoch 2/10, Batch 70/97, Loss: 0.3029
Epoch 2/10, Batch 80/97, Loss: 0.3479
Epoch 2/10, Batch 90/97, Loss: 0.3148
Epoch 2/10, Train Loss: 0.3959, Valid Loss: 0.3417
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2789
Epoch 3/10, Batch 20/97, Loss: 0.3157
Epoch 3/10, Batch 30/97, Loss: 0.1920
Epoch 3/10, Batch 40/97, Loss: 0.1926
Epoch 3/10, Batch 50/97, Loss: 0.2244
Epoch 3/10, Batch 60/97, Loss: 0.3322
Epoch 3/10, Batch 70/97, Loss: 0.2846
Epoch 3/10, Batch 80/97, Loss: 0.2188
Epoch 3/10, Batch 90/97, Loss: 0.2320
Epoch 3/10, Train Loss: 0.3233, Valid Loss: 0.3082
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1632
Epoch 4/10, Batch 20/97, Loss: 0.2084
Epoch 4/10, Batch 30/97, Loss: 0.2450
Epoch 4/10, Batch 40/97, Loss: 0.3044
Epoch 4/10, Batch 50/97, Loss: 0.2270
Epoch 4/10, Batch 60/97, Loss: 0.2259
Epoch 4/10, Batch 70/97, Loss: 0.2303
Epoch 4/10, Batch 80/97, Loss: 0.2310
Epoch 4/10, Batch 90/97, Loss: 0.2080
Epoch 4/10, Train Loss: 0.2812, Valid Loss: 0.2807
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2989
Epoch 5/10, Batch 20/97, Loss: 0.1985
Epoch 5/10, Batch 30/97, Loss: 0.1604
Epoch 5/10, Batch 40/97, Loss: 0.1362
Epoch 5/10, Batch 50/97, Loss: 0.2365
Epoch 5/10, Batch 60/97, Loss: 0.3423
Epoch 5/10, Batch 70/97, Loss: 0.2317
Epoch 5/10, Batch 80/97, Loss: 0.2859
Epoch 5/10, Batch 90/97, Loss: 0.3894
Epoch 5/10, Train Loss: 0.2560, Valid Loss: 0.2740
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1984
Epoch 6/10, Batch 20/97, Loss: 0.2347
Epoch 6/10, Batch 30/97, Loss: 0.2618
Epoch 6/10, Batch 40/97, Loss: 0.3412
Epoch 6/10, Batch 50/97, Loss: 0.0970
Epoch 6/10, Batch 60/97, Loss: 0.3999
Epoch 6/10, Batch 70/97, Loss: 0.4085
Epoch 6/10, Batch 80/97, Loss: 0.2376
Epoch 6/10, Batch 90/97, Loss: 0.2146
Epoch 6/10, Train Loss: 0.2353, Valid Loss: 0.2653
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3067
Epoch 7/10, Batch 20/97, Loss: 0.1076
Epoch 7/10, Batch 30/97, Loss: 0.2512
Epoch 7/10, Batch 40/97, Loss: 0.3417
Epoch 7/10, Batch 50/97, Loss: 0.2700
Epoch 7/10, Batch 60/97, Loss: 0.3556
Epoch 7/10, Batch 70/97, Loss: 0.2126
Epoch 7/10, Batch 80/97, Loss: 0.3762
Epoch 7/10, Batch 90/97, Loss: 0.1595
Epoch 7/10, Train Loss: 0.2342, Valid Loss: 0.2641
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.0715
Epoch 8/10, Batch 20/97, Loss: 0.2314
Epoch 8/10, Batch 30/97, Loss: 0.1250
Epoch 8/10, Batch 40/97, Loss: 0.1945
Epoch 8/10, Batch 50/97, Loss: 0.2133
Epoch 8/10, Batch 60/97, Loss: 0.2326
Epoch 8/10, Batch 70/97, Loss: 0.2926
Epoch 8/10, Batch 80/97, Loss: 0.1795
Epoch 8/10, Batch 90/97, Loss: 0.2938
Epoch 8/10, Train Loss: 0.2146, Valid Loss: 0.2520
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1057
Epoch 9/10, Batch 20/97, Loss: 0.1410
Epoch 9/10, Batch 30/97, Loss: 0.2175
Epoch 9/10, Batch 40/97, Loss: 0.0702
Epoch 9/10, Batch 50/97, Loss: 0.1142
Epoch 9/10, Batch 60/97, Loss: 0.1542
Epoch 9/10, Batch 70/97, Loss: 0.1666
Epoch 9/10, Batch 80/97, Loss: 0.1972
Epoch 9/10, Batch 90/97, Loss: 0.1661
Epoch 9/10, Train Loss: 0.2047, Valid Loss: 0.2573
Epoch 10/10, Batch 10/97, Loss: 0.2385
Epoch 10/10, Batch 20/97, Loss: 0.1272
Epoch 10/10, Batch 30/97, Loss: 0.1813
Epoch 10/10, Batch 40/97, Loss: 0.2545
Epoch 10/10, Batch 50/97, Loss: 0.3840
Epoch 10/10, Batch 60/97, Loss: 0.1090
Epoch 10/10, Batch 70/97, Loss: 0.1755
Epoch 10/10, Batch 80/97, Loss: 0.2395
Epoch 10/10, Batch 90/97, Loss: 0.3871
Epoch 10/10, Train Loss: 0.1982, Valid Loss: 0.2425
Model saved!
Accuracy: 0.9136
Precision: 0.9119
Recall: 0.9136
F1-score: 0.9125
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5256
Epoch 1/10, Batch 20/97, Loss: 0.9996
Epoch 1/10, Batch 30/97, Loss: 0.7914
Epoch 1/10, Batch 40/97, Loss: 0.7274
Epoch 1/10, Batch 50/97, Loss: 0.6367
Epoch 1/10, Batch 60/97, Loss: 0.6123
Epoch 1/10, Batch 70/97, Loss: 0.4189
Epoch 1/10, Batch 80/97, Loss: 0.4333
Epoch 1/10, Batch 90/97, Loss: 0.5356
Epoch 1/10, Train Loss: 0.7649, Valid Loss: 0.4460
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4126
Epoch 2/10, Batch 20/97, Loss: 0.5801
Epoch 2/10, Batch 30/97, Loss: 0.2971
Epoch 2/10, Batch 40/97, Loss: 0.4937
Epoch 2/10, Batch 50/97, Loss: 0.6660
Epoch 2/10, Batch 60/97, Loss: 0.4476
Epoch 2/10, Batch 70/97, Loss: 0.3239
Epoch 2/10, Batch 80/97, Loss: 0.3246
Epoch 2/10, Batch 90/97, Loss: 0.1812
Epoch 2/10, Train Loss: 0.3938, Valid Loss: 0.3413
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2984
Epoch 3/10, Batch 20/97, Loss: 0.2838
Epoch 3/10, Batch 30/97, Loss: 0.2544
Epoch 3/10, Batch 40/97, Loss: 0.2805
Epoch 3/10, Batch 50/97, Loss: 0.3140
Epoch 3/10, Batch 60/97, Loss: 0.3665
Epoch 3/10, Batch 70/97, Loss: 0.2880
Epoch 3/10, Batch 80/97, Loss: 0.2396
Epoch 3/10, Batch 90/97, Loss: 0.3733
Epoch 3/10, Train Loss: 0.3200, Valid Loss: 0.2993
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3938
Epoch 4/10, Batch 20/97, Loss: 0.2301
Epoch 4/10, Batch 30/97, Loss: 0.3909
Epoch 4/10, Batch 40/97, Loss: 0.3013
Epoch 4/10, Batch 50/97, Loss: 0.2583
Epoch 4/10, Batch 60/97, Loss: 0.1773
Epoch 4/10, Batch 70/97, Loss: 0.1669
Epoch 4/10, Batch 80/97, Loss: 0.3082
Epoch 4/10, Batch 90/97, Loss: 0.2161
Epoch 4/10, Train Loss: 0.2851, Valid Loss: 0.2794
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1920
Epoch 5/10, Batch 20/97, Loss: 0.2107
Epoch 5/10, Batch 30/97, Loss: 0.4479
Epoch 5/10, Batch 40/97, Loss: 0.2373
Epoch 5/10, Batch 50/97, Loss: 0.1150
Epoch 5/10, Batch 60/97, Loss: 0.2184
Epoch 5/10, Batch 70/97, Loss: 0.2207
Epoch 5/10, Batch 80/97, Loss: 0.2603
Epoch 5/10, Batch 90/97, Loss: 0.2906
Epoch 5/10, Train Loss: 0.2569, Valid Loss: 0.2635
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2616
Epoch 6/10, Batch 20/97, Loss: 0.2197
Epoch 6/10, Batch 30/97, Loss: 0.1064
Epoch 6/10, Batch 40/97, Loss: 0.3856
Epoch 6/10, Batch 50/97, Loss: 0.1810
Epoch 6/10, Batch 60/97, Loss: 0.2115
Epoch 6/10, Batch 70/97, Loss: 0.1690
Epoch 6/10, Batch 80/97, Loss: 0.2111
Epoch 6/10, Batch 90/97, Loss: 0.2750
Epoch 6/10, Train Loss: 0.2396, Valid Loss: 0.2626
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2753
Epoch 7/10, Batch 20/97, Loss: 0.1774
Epoch 7/10, Batch 30/97, Loss: 0.1645
Epoch 7/10, Batch 40/97, Loss: 0.2736
Epoch 7/10, Batch 50/97, Loss: 0.3050
Epoch 7/10, Batch 60/97, Loss: 0.2285
Epoch 7/10, Batch 70/97, Loss: 0.2474
Epoch 7/10, Batch 80/97, Loss: 0.1728
Epoch 7/10, Batch 90/97, Loss: 0.2964
Epoch 7/10, Train Loss: 0.2425, Valid Loss: 0.2494
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1318
Epoch 8/10, Batch 20/97, Loss: 0.2148
Epoch 8/10, Batch 30/97, Loss: 0.1401
Epoch 8/10, Batch 40/97, Loss: 0.1518
Epoch 8/10, Batch 50/97, Loss: 0.3763
Epoch 8/10, Batch 60/97, Loss: 0.1372
Epoch 8/10, Batch 70/97, Loss: 0.4656
Epoch 8/10, Batch 80/97, Loss: 0.2590
Epoch 8/10, Batch 90/97, Loss: 0.2267
Epoch 8/10, Train Loss: 0.2171, Valid Loss: 0.2452
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1170
Epoch 9/10, Batch 20/97, Loss: 0.0774
Epoch 9/10, Batch 30/97, Loss: 0.3136
Epoch 9/10, Batch 40/97, Loss: 0.2022
Epoch 9/10, Batch 50/97, Loss: 0.2979
Epoch 9/10, Batch 60/97, Loss: 0.1941
Epoch 9/10, Batch 70/97, Loss: 0.1342
Epoch 9/10, Batch 80/97, Loss: 0.0626
Epoch 9/10, Batch 90/97, Loss: 0.3664
Epoch 9/10, Train Loss: 0.2025, Valid Loss: 0.2526
Epoch 10/10, Batch 10/97, Loss: 0.1666
Epoch 10/10, Batch 20/97, Loss: 0.0921
Epoch 10/10, Batch 30/97, Loss: 0.1293
Epoch 10/10, Batch 40/97, Loss: 0.2509
Epoch 10/10, Batch 50/97, Loss: 0.2533
Epoch 10/10, Batch 60/97, Loss: 0.2107
Epoch 10/10, Batch 70/97, Loss: 0.1056
Epoch 10/10, Batch 80/97, Loss: 0.1677
Epoch 10/10, Batch 90/97, Loss: 0.2615
Epoch 10/10, Train Loss: 0.1970, Valid Loss: 0.2439
Model saved!
Accuracy: 0.9136
Precision: 0.9116
Recall: 0.9136
F1-score: 0.9119
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5861
Epoch 1/10, Batch 20/97, Loss: 1.0474
Epoch 1/10, Batch 30/97, Loss: 0.8912
Epoch 1/10, Batch 40/97, Loss: 0.7824
Epoch 1/10, Batch 50/97, Loss: 0.5279
Epoch 1/10, Batch 60/97, Loss: 0.6284
Epoch 1/10, Batch 70/97, Loss: 0.4649
Epoch 1/10, Batch 80/97, Loss: 0.4316
Epoch 1/10, Batch 90/97, Loss: 0.4944
Epoch 1/10, Train Loss: 0.7786, Valid Loss: 0.4506
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4359
Epoch 2/10, Batch 20/97, Loss: 0.3813
Epoch 2/10, Batch 30/97, Loss: 0.3321
Epoch 2/10, Batch 40/97, Loss: 0.3341
Epoch 2/10, Batch 50/97, Loss: 0.4078
Epoch 2/10, Batch 60/97, Loss: 0.4187
Epoch 2/10, Batch 70/97, Loss: 0.3746
Epoch 2/10, Batch 80/97, Loss: 0.4479
Epoch 2/10, Batch 90/97, Loss: 0.2665
Epoch 2/10, Train Loss: 0.3889, Valid Loss: 0.3464
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2688
Epoch 3/10, Batch 20/97, Loss: 0.3116
Epoch 3/10, Batch 30/97, Loss: 0.3208
Epoch 3/10, Batch 40/97, Loss: 0.3508
Epoch 3/10, Batch 50/97, Loss: 0.3670
Epoch 3/10, Batch 60/97, Loss: 0.2102
Epoch 3/10, Batch 70/97, Loss: 0.1795
Epoch 3/10, Batch 80/97, Loss: 0.2003
Epoch 3/10, Batch 90/97, Loss: 0.2252
Epoch 3/10, Train Loss: 0.3187, Valid Loss: 0.3033
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2409
Epoch 4/10, Batch 20/97, Loss: 0.3643
Epoch 4/10, Batch 30/97, Loss: 0.2593
Epoch 4/10, Batch 40/97, Loss: 0.1888
Epoch 4/10, Batch 50/97, Loss: 0.1973
Epoch 4/10, Batch 60/97, Loss: 0.1525
Epoch 4/10, Batch 70/97, Loss: 0.2425
Epoch 4/10, Batch 80/97, Loss: 0.1785
Epoch 4/10, Batch 90/97, Loss: 0.3109
Epoch 4/10, Train Loss: 0.2767, Valid Loss: 0.2868
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1629
Epoch 5/10, Batch 20/97, Loss: 0.2642
Epoch 5/10, Batch 30/97, Loss: 0.1086
Epoch 5/10, Batch 40/97, Loss: 0.2626
Epoch 5/10, Batch 50/97, Loss: 0.1506
Epoch 5/10, Batch 60/97, Loss: 0.3521
Epoch 5/10, Batch 70/97, Loss: 0.2193
Epoch 5/10, Batch 80/97, Loss: 0.4496
Epoch 5/10, Batch 90/97, Loss: 0.2765
Epoch 5/10, Train Loss: 0.2545, Valid Loss: 0.2756
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2425
Epoch 6/10, Batch 20/97, Loss: 0.2979
Epoch 6/10, Batch 30/97, Loss: 0.2174
Epoch 6/10, Batch 40/97, Loss: 0.2399
Epoch 6/10, Batch 50/97, Loss: 0.1854
Epoch 6/10, Batch 60/97, Loss: 0.1684
Epoch 6/10, Batch 70/97, Loss: 0.2087
Epoch 6/10, Batch 80/97, Loss: 0.1938
Epoch 6/10, Batch 90/97, Loss: 0.2640
Epoch 6/10, Train Loss: 0.2331, Valid Loss: 0.2737
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2101
Epoch 7/10, Batch 20/97, Loss: 0.0964
Epoch 7/10, Batch 30/97, Loss: 0.2569
Epoch 7/10, Batch 40/97, Loss: 0.2153
Epoch 7/10, Batch 50/97, Loss: 0.2047
Epoch 7/10, Batch 60/97, Loss: 0.2646
Epoch 7/10, Batch 70/97, Loss: 0.1659
Epoch 7/10, Batch 80/97, Loss: 0.2454
Epoch 7/10, Batch 90/97, Loss: 0.2278
Epoch 7/10, Train Loss: 0.2343, Valid Loss: 0.2555
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.0807
Epoch 8/10, Batch 20/97, Loss: 0.1454
Epoch 8/10, Batch 30/97, Loss: 0.1483
Epoch 8/10, Batch 40/97, Loss: 0.2003
Epoch 8/10, Batch 50/97, Loss: 0.1706
Epoch 8/10, Batch 60/97, Loss: 0.2351
Epoch 8/10, Batch 70/97, Loss: 0.3324
Epoch 8/10, Batch 80/97, Loss: 0.0869
Epoch 8/10, Batch 90/97, Loss: 0.2860
Epoch 8/10, Train Loss: 0.2106, Valid Loss: 0.2589
Epoch 9/10, Batch 10/97, Loss: 0.1472
Epoch 9/10, Batch 20/97, Loss: 0.0914
Epoch 9/10, Batch 30/97, Loss: 0.3286
Epoch 9/10, Batch 40/97, Loss: 0.1732
Epoch 9/10, Batch 50/97, Loss: 0.2196
Epoch 9/10, Batch 60/97, Loss: 0.1214
Epoch 9/10, Batch 70/97, Loss: 0.1818
Epoch 9/10, Batch 80/97, Loss: 0.1738
Epoch 9/10, Batch 90/97, Loss: 0.2744
Epoch 9/10, Train Loss: 0.2012, Valid Loss: 0.2560
Epoch 10/10, Batch 10/97, Loss: 0.2845
Epoch 10/10, Batch 20/97, Loss: 0.1675
Epoch 10/10, Batch 30/97, Loss: 0.0981
Epoch 10/10, Batch 40/97, Loss: 0.1905
Epoch 10/10, Batch 50/97, Loss: 0.2970
Epoch 10/10, Batch 60/97, Loss: 0.1129
Epoch 10/10, Batch 70/97, Loss: 0.1007
Epoch 10/10, Batch 80/97, Loss: 0.2404
Epoch 10/10, Batch 90/97, Loss: 0.1102
Epoch 10/10, Train Loss: 0.1826, Valid Loss: 0.2623
Accuracy: 0.9089
Precision: 0.9061
Recall: 0.9089
F1-score: 0.9065
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4289
Epoch 1/10, Batch 20/97, Loss: 0.9600
Epoch 1/10, Batch 30/97, Loss: 0.8249
Epoch 1/10, Batch 40/97, Loss: 0.7626
Epoch 1/10, Batch 50/97, Loss: 0.6737
Epoch 1/10, Batch 60/97, Loss: 0.5429
Epoch 1/10, Batch 70/97, Loss: 0.4862
Epoch 1/10, Batch 80/97, Loss: 0.4933
Epoch 1/10, Batch 90/97, Loss: 0.6005
Epoch 1/10, Train Loss: 0.7768, Valid Loss: 0.4370
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4315
Epoch 2/10, Batch 20/97, Loss: 0.5199
Epoch 2/10, Batch 30/97, Loss: 0.2957
Epoch 2/10, Batch 40/97, Loss: 0.2866
Epoch 2/10, Batch 50/97, Loss: 0.5132
Epoch 2/10, Batch 60/97, Loss: 0.2891
Epoch 2/10, Batch 70/97, Loss: 0.2799
Epoch 2/10, Batch 80/97, Loss: 0.3177
Epoch 2/10, Batch 90/97, Loss: 0.2885
Epoch 2/10, Train Loss: 0.4004, Valid Loss: 0.3420
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2674
Epoch 3/10, Batch 20/97, Loss: 0.2453
Epoch 3/10, Batch 30/97, Loss: 0.5104
Epoch 3/10, Batch 40/97, Loss: 0.1941
Epoch 3/10, Batch 50/97, Loss: 0.4222
Epoch 3/10, Batch 60/97, Loss: 0.3202
Epoch 3/10, Batch 70/97, Loss: 0.2098
Epoch 3/10, Batch 80/97, Loss: 0.2941
Epoch 3/10, Batch 90/97, Loss: 0.3317
Epoch 3/10, Train Loss: 0.3267, Valid Loss: 0.2999
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3573
Epoch 4/10, Batch 20/97, Loss: 0.2862
Epoch 4/10, Batch 30/97, Loss: 0.3162
Epoch 4/10, Batch 40/97, Loss: 0.3167
Epoch 4/10, Batch 50/97, Loss: 0.1318
Epoch 4/10, Batch 60/97, Loss: 0.1122
Epoch 4/10, Batch 70/97, Loss: 0.1958
Epoch 4/10, Batch 80/97, Loss: 0.3212
Epoch 4/10, Batch 90/97, Loss: 0.4773
Epoch 4/10, Train Loss: 0.2844, Valid Loss: 0.2776
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2837
Epoch 5/10, Batch 20/97, Loss: 0.2737
Epoch 5/10, Batch 30/97, Loss: 0.2024
Epoch 5/10, Batch 40/97, Loss: 0.2537
Epoch 5/10, Batch 50/97, Loss: 0.2028
Epoch 5/10, Batch 60/97, Loss: 0.2319
Epoch 5/10, Batch 70/97, Loss: 0.1810
Epoch 5/10, Batch 80/97, Loss: 0.2805
Epoch 5/10, Batch 90/97, Loss: 0.5006
Epoch 5/10, Train Loss: 0.2618, Valid Loss: 0.2622
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1012
Epoch 6/10, Batch 20/97, Loss: 0.2826
Epoch 6/10, Batch 30/97, Loss: 0.1986
Epoch 6/10, Batch 40/97, Loss: 0.3178
Epoch 6/10, Batch 50/97, Loss: 0.2409
Epoch 6/10, Batch 60/97, Loss: 0.3141
Epoch 6/10, Batch 70/97, Loss: 0.2694
Epoch 6/10, Batch 80/97, Loss: 0.1745
Epoch 6/10, Batch 90/97, Loss: 0.4138
Epoch 6/10, Train Loss: 0.2403, Valid Loss: 0.2549
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2993
Epoch 7/10, Batch 20/97, Loss: 0.2340
Epoch 7/10, Batch 30/97, Loss: 0.1454
Epoch 7/10, Batch 40/97, Loss: 0.1705
Epoch 7/10, Batch 50/97, Loss: 0.1425
Epoch 7/10, Batch 60/97, Loss: 0.3231
Epoch 7/10, Batch 70/97, Loss: 0.2998
Epoch 7/10, Batch 80/97, Loss: 0.1308
Epoch 7/10, Batch 90/97, Loss: 0.1449
Epoch 7/10, Train Loss: 0.2385, Valid Loss: 0.2508
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2139
Epoch 8/10, Batch 20/97, Loss: 0.1935
Epoch 8/10, Batch 30/97, Loss: 0.2013
Epoch 8/10, Batch 40/97, Loss: 0.2809
Epoch 8/10, Batch 50/97, Loss: 0.1931
Epoch 8/10, Batch 60/97, Loss: 0.1919
Epoch 8/10, Batch 70/97, Loss: 0.1730
Epoch 8/10, Batch 80/97, Loss: 0.1619
Epoch 8/10, Batch 90/97, Loss: 0.1578
Epoch 8/10, Train Loss: 0.2197, Valid Loss: 0.2441
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1753
Epoch 9/10, Batch 20/97, Loss: 0.0999
Epoch 9/10, Batch 30/97, Loss: 0.3719
Epoch 9/10, Batch 40/97, Loss: 0.1361
Epoch 9/10, Batch 50/97, Loss: 0.3124
Epoch 9/10, Batch 60/97, Loss: 0.1960
Epoch 9/10, Batch 70/97, Loss: 0.1423
Epoch 9/10, Batch 80/97, Loss: 0.1656
Epoch 9/10, Batch 90/97, Loss: 0.0800
Epoch 9/10, Train Loss: 0.2091, Valid Loss: 0.2386
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3695
Epoch 10/10, Batch 20/97, Loss: 0.1776
Epoch 10/10, Batch 30/97, Loss: 0.1942
Epoch 10/10, Batch 40/97, Loss: 0.2088
Epoch 10/10, Batch 50/97, Loss: 0.3450
Epoch 10/10, Batch 60/97, Loss: 0.1508
Epoch 10/10, Batch 70/97, Loss: 0.1861
Epoch 10/10, Batch 80/97, Loss: 0.2117
Epoch 10/10, Batch 90/97, Loss: 0.1068
Epoch 10/10, Train Loss: 0.2006, Valid Loss: 0.2392
Accuracy: 0.9182
Precision: 0.9162
Recall: 0.9182
F1-score: 0.9169
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4742
Epoch 1/10, Batch 20/97, Loss: 1.0514
Epoch 1/10, Batch 30/97, Loss: 0.8200
Epoch 1/10, Batch 40/97, Loss: 0.7802
Epoch 1/10, Batch 50/97, Loss: 0.7760
Epoch 1/10, Batch 60/97, Loss: 0.6662
Epoch 1/10, Batch 70/97, Loss: 0.4282
Epoch 1/10, Batch 80/97, Loss: 0.5169
Epoch 1/10, Batch 90/97, Loss: 0.4944
Epoch 1/10, Train Loss: 0.7749, Valid Loss: 0.4222
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4263
Epoch 2/10, Batch 20/97, Loss: 0.4822
Epoch 2/10, Batch 30/97, Loss: 0.3147
Epoch 2/10, Batch 40/97, Loss: 0.4771
Epoch 2/10, Batch 50/97, Loss: 0.6373
Epoch 2/10, Batch 60/97, Loss: 0.3031
Epoch 2/10, Batch 70/97, Loss: 0.4377
Epoch 2/10, Batch 80/97, Loss: 0.4506
Epoch 2/10, Batch 90/97, Loss: 0.2072
Epoch 2/10, Train Loss: 0.3972, Valid Loss: 0.3181
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3192
Epoch 3/10, Batch 20/97, Loss: 0.2965
Epoch 3/10, Batch 30/97, Loss: 0.2286
Epoch 3/10, Batch 40/97, Loss: 0.2303
Epoch 3/10, Batch 50/97, Loss: 0.3776
Epoch 3/10, Batch 60/97, Loss: 0.1814
Epoch 3/10, Batch 70/97, Loss: 0.2379
Epoch 3/10, Batch 80/97, Loss: 0.2861
Epoch 3/10, Batch 90/97, Loss: 0.3154
Epoch 3/10, Train Loss: 0.3224, Valid Loss: 0.2760
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2709
Epoch 4/10, Batch 20/97, Loss: 0.2023
Epoch 4/10, Batch 30/97, Loss: 0.3236
Epoch 4/10, Batch 40/97, Loss: 0.2647
Epoch 4/10, Batch 50/97, Loss: 0.1561
Epoch 4/10, Batch 60/97, Loss: 0.1642
Epoch 4/10, Batch 70/97, Loss: 0.2545
Epoch 4/10, Batch 80/97, Loss: 0.1771
Epoch 4/10, Batch 90/97, Loss: 0.1864
Epoch 4/10, Train Loss: 0.2901, Valid Loss: 0.2513
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1856
Epoch 5/10, Batch 20/97, Loss: 0.2719
Epoch 5/10, Batch 30/97, Loss: 0.1567
Epoch 5/10, Batch 40/97, Loss: 0.2453
Epoch 5/10, Batch 50/97, Loss: 0.1790
Epoch 5/10, Batch 60/97, Loss: 0.1703
Epoch 5/10, Batch 70/97, Loss: 0.1597
Epoch 5/10, Batch 80/97, Loss: 0.2407
Epoch 5/10, Batch 90/97, Loss: 0.7465
Epoch 5/10, Train Loss: 0.2641, Valid Loss: 0.2399
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1452
Epoch 6/10, Batch 20/97, Loss: 0.2715
Epoch 6/10, Batch 30/97, Loss: 0.1620
Epoch 6/10, Batch 40/97, Loss: 0.3077
Epoch 6/10, Batch 50/97, Loss: 0.1795
Epoch 6/10, Batch 60/97, Loss: 0.2007
Epoch 6/10, Batch 70/97, Loss: 0.2800
Epoch 6/10, Batch 80/97, Loss: 0.1717
Epoch 6/10, Batch 90/97, Loss: 0.1530
Epoch 6/10, Train Loss: 0.2356, Valid Loss: 0.2389
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3493
Epoch 7/10, Batch 20/97, Loss: 0.1889
Epoch 7/10, Batch 30/97, Loss: 0.2387
Epoch 7/10, Batch 40/97, Loss: 0.2646
Epoch 7/10, Batch 50/97, Loss: 0.2309
Epoch 7/10, Batch 60/97, Loss: 0.3416
Epoch 7/10, Batch 70/97, Loss: 0.2738
Epoch 7/10, Batch 80/97, Loss: 0.2146
Epoch 7/10, Batch 90/97, Loss: 0.3128
Epoch 7/10, Train Loss: 0.2514, Valid Loss: 0.2267
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1823
Epoch 8/10, Batch 20/97, Loss: 0.2113
Epoch 8/10, Batch 30/97, Loss: 0.1887
Epoch 8/10, Batch 40/97, Loss: 0.3367
Epoch 8/10, Batch 50/97, Loss: 0.2884
Epoch 8/10, Batch 60/97, Loss: 0.1198
Epoch 8/10, Batch 70/97, Loss: 0.2415
Epoch 8/10, Batch 80/97, Loss: 0.2196
Epoch 8/10, Batch 90/97, Loss: 0.1036
Epoch 8/10, Train Loss: 0.2231, Valid Loss: 0.2255
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2059
Epoch 9/10, Batch 20/97, Loss: 0.1693
Epoch 9/10, Batch 30/97, Loss: 0.2114
Epoch 9/10, Batch 40/97, Loss: 0.1880
Epoch 9/10, Batch 50/97, Loss: 0.1581
Epoch 9/10, Batch 60/97, Loss: 0.2627
Epoch 9/10, Batch 70/97, Loss: 0.1220
Epoch 9/10, Batch 80/97, Loss: 0.2247
Epoch 9/10, Batch 90/97, Loss: 0.1792
Epoch 9/10, Train Loss: 0.2100, Valid Loss: 0.2144
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2519
Epoch 10/10, Batch 20/97, Loss: 0.2642
Epoch 10/10, Batch 30/97, Loss: 0.2229
Epoch 10/10, Batch 40/97, Loss: 0.2141
Epoch 10/10, Batch 50/97, Loss: 0.2954
Epoch 10/10, Batch 60/97, Loss: 0.1718
Epoch 10/10, Batch 70/97, Loss: 0.2053
Epoch 10/10, Batch 80/97, Loss: 0.2093
Epoch 10/10, Batch 90/97, Loss: 0.1193
Epoch 10/10, Train Loss: 0.2023, Valid Loss: 0.2101
Model saved!
Accuracy: 0.9159
Precision: 0.9127
Recall: 0.9159
F1-score: 0.9130
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5639
Epoch 1/10, Batch 20/97, Loss: 1.0595
Epoch 1/10, Batch 30/97, Loss: 0.7638
Epoch 1/10, Batch 40/97, Loss: 0.6169
Epoch 1/10, Batch 50/97, Loss: 0.6463
Epoch 1/10, Batch 60/97, Loss: 0.5829
Epoch 1/10, Batch 70/97, Loss: 0.4276
Epoch 1/10, Batch 80/97, Loss: 0.5174
Epoch 1/10, Batch 90/97, Loss: 0.6144
Epoch 1/10, Train Loss: 0.7718, Valid Loss: 0.4439
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4598
Epoch 2/10, Batch 20/97, Loss: 0.4272
Epoch 2/10, Batch 30/97, Loss: 0.5454
Epoch 2/10, Batch 40/97, Loss: 0.5326
Epoch 2/10, Batch 50/97, Loss: 0.5027
Epoch 2/10, Batch 60/97, Loss: 0.2804
Epoch 2/10, Batch 70/97, Loss: 0.3393
Epoch 2/10, Batch 80/97, Loss: 0.2475
Epoch 2/10, Batch 90/97, Loss: 0.3288
Epoch 2/10, Train Loss: 0.3926, Valid Loss: 0.3434
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3189
Epoch 3/10, Batch 20/97, Loss: 0.3587
Epoch 3/10, Batch 30/97, Loss: 0.3184
Epoch 3/10, Batch 40/97, Loss: 0.4381
Epoch 3/10, Batch 50/97, Loss: 0.2941
Epoch 3/10, Batch 60/97, Loss: 0.3039
Epoch 3/10, Batch 70/97, Loss: 0.2465
Epoch 3/10, Batch 80/97, Loss: 0.2424
Epoch 3/10, Batch 90/97, Loss: 0.3433
Epoch 3/10, Train Loss: 0.3209, Valid Loss: 0.3106
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1671
Epoch 4/10, Batch 20/97, Loss: 0.1928
Epoch 4/10, Batch 30/97, Loss: 0.4531
Epoch 4/10, Batch 40/97, Loss: 0.2421
Epoch 4/10, Batch 50/97, Loss: 0.1674
Epoch 4/10, Batch 60/97, Loss: 0.1808
Epoch 4/10, Batch 70/97, Loss: 0.1941
Epoch 4/10, Batch 80/97, Loss: 0.2472
Epoch 4/10, Batch 90/97, Loss: 0.2902
Epoch 4/10, Train Loss: 0.2769, Valid Loss: 0.2854
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1798
Epoch 5/10, Batch 20/97, Loss: 0.2930
Epoch 5/10, Batch 30/97, Loss: 0.1846
Epoch 5/10, Batch 40/97, Loss: 0.1632
Epoch 5/10, Batch 50/97, Loss: 0.1887
Epoch 5/10, Batch 60/97, Loss: 0.1664
Epoch 5/10, Batch 70/97, Loss: 0.1976
Epoch 5/10, Batch 80/97, Loss: 0.2587
Epoch 5/10, Batch 90/97, Loss: 0.4140
Epoch 5/10, Train Loss: 0.2492, Valid Loss: 0.2808
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2504
Epoch 6/10, Batch 20/97, Loss: 0.1921
Epoch 6/10, Batch 30/97, Loss: 0.1057
Epoch 6/10, Batch 40/97, Loss: 0.3228
Epoch 6/10, Batch 50/97, Loss: 0.1800
Epoch 6/10, Batch 60/97, Loss: 0.3600
Epoch 6/10, Batch 70/97, Loss: 0.2947
Epoch 6/10, Batch 80/97, Loss: 0.2188
Epoch 6/10, Batch 90/97, Loss: 0.2679
Epoch 6/10, Train Loss: 0.2398, Valid Loss: 0.2720
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2812
Epoch 7/10, Batch 20/97, Loss: 0.2605
Epoch 7/10, Batch 30/97, Loss: 0.1492
Epoch 7/10, Batch 40/97, Loss: 0.2460
Epoch 7/10, Batch 50/97, Loss: 0.2617
Epoch 7/10, Batch 60/97, Loss: 0.2223
Epoch 7/10, Batch 70/97, Loss: 0.2692
Epoch 7/10, Batch 80/97, Loss: 0.1891
Epoch 7/10, Batch 90/97, Loss: 0.1811
Epoch 7/10, Train Loss: 0.2352, Valid Loss: 0.2661
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1942
Epoch 8/10, Batch 20/97, Loss: 0.1756
Epoch 8/10, Batch 30/97, Loss: 0.1147
Epoch 8/10, Batch 40/97, Loss: 0.1714
Epoch 8/10, Batch 50/97, Loss: 0.2472
Epoch 8/10, Batch 60/97, Loss: 0.1635
Epoch 8/10, Batch 70/97, Loss: 0.2710
Epoch 8/10, Batch 80/97, Loss: 0.1308
Epoch 8/10, Batch 90/97, Loss: 0.1116
Epoch 8/10, Train Loss: 0.2164, Valid Loss: 0.2603
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.3945
Epoch 9/10, Batch 20/97, Loss: 0.1306
Epoch 9/10, Batch 30/97, Loss: 0.2530
Epoch 9/10, Batch 40/97, Loss: 0.1958
Epoch 9/10, Batch 50/97, Loss: 0.1998
Epoch 9/10, Batch 60/97, Loss: 0.1888
Epoch 9/10, Batch 70/97, Loss: 0.0926
Epoch 9/10, Batch 80/97, Loss: 0.1218
Epoch 9/10, Batch 90/97, Loss: 0.2352
Epoch 9/10, Train Loss: 0.2051, Valid Loss: 0.2650
Epoch 10/10, Batch 10/97, Loss: 0.1814
Epoch 10/10, Batch 20/97, Loss: 0.2169
Epoch 10/10, Batch 30/97, Loss: 0.1697
Epoch 10/10, Batch 40/97, Loss: 0.1863
Epoch 10/10, Batch 50/97, Loss: 0.2560
Epoch 10/10, Batch 60/97, Loss: 0.2141
Epoch 10/10, Batch 70/97, Loss: 0.2623
Epoch 10/10, Batch 80/97, Loss: 0.1404
Epoch 10/10, Batch 90/97, Loss: 0.1514
Epoch 10/10, Train Loss: 0.1912, Valid Loss: 0.2543
Model saved!
Accuracy: 0.9100
Precision: 0.9077
Recall: 0.9100
F1-score: 0.9083
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4114
Epoch 1/10, Batch 20/97, Loss: 1.0640
Epoch 1/10, Batch 30/97, Loss: 0.8299
Epoch 1/10, Batch 40/97, Loss: 0.6948
Epoch 1/10, Batch 50/97, Loss: 0.6016
Epoch 1/10, Batch 60/97, Loss: 0.6325
Epoch 1/10, Batch 70/97, Loss: 0.5148
Epoch 1/10, Batch 80/97, Loss: 0.4416
Epoch 1/10, Batch 90/97, Loss: 0.4693
Epoch 1/10, Train Loss: 0.7731, Valid Loss: 0.4289
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3742
Epoch 2/10, Batch 20/97, Loss: 0.4013
Epoch 2/10, Batch 30/97, Loss: 0.4260
Epoch 2/10, Batch 40/97, Loss: 0.4872
Epoch 2/10, Batch 50/97, Loss: 0.5623
Epoch 2/10, Batch 60/97, Loss: 0.4427
Epoch 2/10, Batch 70/97, Loss: 0.2182
Epoch 2/10, Batch 80/97, Loss: 0.3745
Epoch 2/10, Batch 90/97, Loss: 0.2887
Epoch 2/10, Train Loss: 0.3976, Valid Loss: 0.3327
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2889
Epoch 3/10, Batch 20/97, Loss: 0.2732
Epoch 3/10, Batch 30/97, Loss: 0.2687
Epoch 3/10, Batch 40/97, Loss: 0.2880
Epoch 3/10, Batch 50/97, Loss: 0.3577
Epoch 3/10, Batch 60/97, Loss: 0.3550
Epoch 3/10, Batch 70/97, Loss: 0.3237
Epoch 3/10, Batch 80/97, Loss: 0.2613
Epoch 3/10, Batch 90/97, Loss: 0.2492
Epoch 3/10, Train Loss: 0.3230, Valid Loss: 0.2948
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2590
Epoch 4/10, Batch 20/97, Loss: 0.1694
Epoch 4/10, Batch 30/97, Loss: 0.3479
Epoch 4/10, Batch 40/97, Loss: 0.1835
Epoch 4/10, Batch 50/97, Loss: 0.1665
Epoch 4/10, Batch 60/97, Loss: 0.1286
Epoch 4/10, Batch 70/97, Loss: 0.2849
Epoch 4/10, Batch 80/97, Loss: 0.3161
Epoch 4/10, Batch 90/97, Loss: 0.4015
Epoch 4/10, Train Loss: 0.2904, Valid Loss: 0.2710
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3145
Epoch 5/10, Batch 20/97, Loss: 0.1787
Epoch 5/10, Batch 30/97, Loss: 0.2199
Epoch 5/10, Batch 40/97, Loss: 0.1475
Epoch 5/10, Batch 50/97, Loss: 0.2950
Epoch 5/10, Batch 60/97, Loss: 0.2029
Epoch 5/10, Batch 70/97, Loss: 0.1744
Epoch 5/10, Batch 80/97, Loss: 0.2593
Epoch 5/10, Batch 90/97, Loss: 0.4756
Epoch 5/10, Train Loss: 0.2559, Valid Loss: 0.2597
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2225
Epoch 6/10, Batch 20/97, Loss: 0.1367
Epoch 6/10, Batch 30/97, Loss: 0.2147
Epoch 6/10, Batch 40/97, Loss: 0.2991
Epoch 6/10, Batch 50/97, Loss: 0.3262
Epoch 6/10, Batch 60/97, Loss: 0.2937
Epoch 6/10, Batch 70/97, Loss: 0.2853
Epoch 6/10, Batch 80/97, Loss: 0.2281
Epoch 6/10, Batch 90/97, Loss: 0.2738
Epoch 6/10, Train Loss: 0.2402, Valid Loss: 0.2589
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3060
Epoch 7/10, Batch 20/97, Loss: 0.1410
Epoch 7/10, Batch 30/97, Loss: 0.2636
Epoch 7/10, Batch 40/97, Loss: 0.2862
Epoch 7/10, Batch 50/97, Loss: 0.1394
Epoch 7/10, Batch 60/97, Loss: 0.1355
Epoch 7/10, Batch 70/97, Loss: 0.3192
Epoch 7/10, Batch 80/97, Loss: 0.1094
Epoch 7/10, Batch 90/97, Loss: 0.6033
Epoch 7/10, Train Loss: 0.2402, Valid Loss: 0.2568
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1338
Epoch 8/10, Batch 20/97, Loss: 0.1420
Epoch 8/10, Batch 30/97, Loss: 0.1506
Epoch 8/10, Batch 40/97, Loss: 0.1313
Epoch 8/10, Batch 50/97, Loss: 0.2953
Epoch 8/10, Batch 60/97, Loss: 0.1923
Epoch 8/10, Batch 70/97, Loss: 0.3163
Epoch 8/10, Batch 80/97, Loss: 0.0986
Epoch 8/10, Batch 90/97, Loss: 0.2270
Epoch 8/10, Train Loss: 0.2253, Valid Loss: 0.2418
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2408
Epoch 9/10, Batch 20/97, Loss: 0.1684
Epoch 9/10, Batch 30/97, Loss: 0.3026
Epoch 9/10, Batch 40/97, Loss: 0.1132
Epoch 9/10, Batch 50/97, Loss: 0.1582
Epoch 9/10, Batch 60/97, Loss: 0.1686
Epoch 9/10, Batch 70/97, Loss: 0.1707
Epoch 9/10, Batch 80/97, Loss: 0.1666
Epoch 9/10, Batch 90/97, Loss: 0.3072
Epoch 9/10, Train Loss: 0.2094, Valid Loss: 0.2381
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3110
Epoch 10/10, Batch 20/97, Loss: 0.1965
Epoch 10/10, Batch 30/97, Loss: 0.1685
Epoch 10/10, Batch 40/97, Loss: 0.2719
Epoch 10/10, Batch 50/97, Loss: 0.4519
Epoch 10/10, Batch 60/97, Loss: 0.3377
Epoch 10/10, Batch 70/97, Loss: 0.1869
Epoch 10/10, Batch 80/97, Loss: 0.1015
Epoch 10/10, Batch 90/97, Loss: 0.1405
Epoch 10/10, Train Loss: 0.1948, Valid Loss: 0.2387
Accuracy: 0.9065
Precision: 0.9049
Recall: 0.9065
F1-score: 0.9046
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4738
Epoch 1/10, Batch 20/97, Loss: 0.9495
Epoch 1/10, Batch 30/97, Loss: 0.8438
Epoch 1/10, Batch 40/97, Loss: 0.7210
Epoch 1/10, Batch 50/97, Loss: 0.5528
Epoch 1/10, Batch 60/97, Loss: 0.7022
Epoch 1/10, Batch 70/97, Loss: 0.5232
Epoch 1/10, Batch 80/97, Loss: 0.5211
Epoch 1/10, Batch 90/97, Loss: 0.5619
Epoch 1/10, Train Loss: 0.7714, Valid Loss: 0.4512
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5018
Epoch 2/10, Batch 20/97, Loss: 0.3674
Epoch 2/10, Batch 30/97, Loss: 0.3048
Epoch 2/10, Batch 40/97, Loss: 0.4450
Epoch 2/10, Batch 50/97, Loss: 0.5289
Epoch 2/10, Batch 60/97, Loss: 0.3397
Epoch 2/10, Batch 70/97, Loss: 0.3301
Epoch 2/10, Batch 80/97, Loss: 0.4025
Epoch 2/10, Batch 90/97, Loss: 0.4778
Epoch 2/10, Train Loss: 0.3988, Valid Loss: 0.3463
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2216
Epoch 3/10, Batch 20/97, Loss: 0.2954
Epoch 3/10, Batch 30/97, Loss: 0.2251
Epoch 3/10, Batch 40/97, Loss: 0.2696
Epoch 3/10, Batch 50/97, Loss: 0.2950
Epoch 3/10, Batch 60/97, Loss: 0.2202
Epoch 3/10, Batch 70/97, Loss: 0.2573
Epoch 3/10, Batch 80/97, Loss: 0.4963
Epoch 3/10, Batch 90/97, Loss: 0.3067
Epoch 3/10, Train Loss: 0.3241, Valid Loss: 0.3073
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1735
Epoch 4/10, Batch 20/97, Loss: 0.2722
Epoch 4/10, Batch 30/97, Loss: 0.3427
Epoch 4/10, Batch 40/97, Loss: 0.2703
Epoch 4/10, Batch 50/97, Loss: 0.2166
Epoch 4/10, Batch 60/97, Loss: 0.2620
Epoch 4/10, Batch 70/97, Loss: 0.2445
Epoch 4/10, Batch 80/97, Loss: 0.1970
Epoch 4/10, Batch 90/97, Loss: 0.2543
Epoch 4/10, Train Loss: 0.2834, Valid Loss: 0.2807
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3132
Epoch 5/10, Batch 20/97, Loss: 0.1848
Epoch 5/10, Batch 30/97, Loss: 0.1607
Epoch 5/10, Batch 40/97, Loss: 0.2986
Epoch 5/10, Batch 50/97, Loss: 0.2391
Epoch 5/10, Batch 60/97, Loss: 0.2651
Epoch 5/10, Batch 70/97, Loss: 0.1748
Epoch 5/10, Batch 80/97, Loss: 0.1692
Epoch 5/10, Batch 90/97, Loss: 0.2923
Epoch 5/10, Train Loss: 0.2594, Valid Loss: 0.2641
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2054
Epoch 6/10, Batch 20/97, Loss: 0.4240
Epoch 6/10, Batch 30/97, Loss: 0.2135
Epoch 6/10, Batch 40/97, Loss: 0.2712
Epoch 6/10, Batch 50/97, Loss: 0.1821
Epoch 6/10, Batch 60/97, Loss: 0.2490
Epoch 6/10, Batch 70/97, Loss: 0.1603
Epoch 6/10, Batch 80/97, Loss: 0.1352
Epoch 6/10, Batch 90/97, Loss: 0.1632
Epoch 6/10, Train Loss: 0.2369, Valid Loss: 0.2524
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2576
Epoch 7/10, Batch 20/97, Loss: 0.1487
Epoch 7/10, Batch 30/97, Loss: 0.1241
Epoch 7/10, Batch 40/97, Loss: 0.1175
Epoch 7/10, Batch 50/97, Loss: 0.1959
Epoch 7/10, Batch 60/97, Loss: 0.3194
Epoch 7/10, Batch 70/97, Loss: 0.1733
Epoch 7/10, Batch 80/97, Loss: 0.3542
Epoch 7/10, Batch 90/97, Loss: 0.2263
Epoch 7/10, Train Loss: 0.2433, Valid Loss: 0.2489
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2890
Epoch 8/10, Batch 20/97, Loss: 0.3332
Epoch 8/10, Batch 30/97, Loss: 0.0801
Epoch 8/10, Batch 40/97, Loss: 0.2260
Epoch 8/10, Batch 50/97, Loss: 0.3677
Epoch 8/10, Batch 60/97, Loss: 0.1418
Epoch 8/10, Batch 70/97, Loss: 0.2696
Epoch 8/10, Batch 80/97, Loss: 0.1865
Epoch 8/10, Batch 90/97, Loss: 0.2061
Epoch 8/10, Train Loss: 0.2143, Valid Loss: 0.2441
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1369
Epoch 9/10, Batch 20/97, Loss: 0.1102
Epoch 9/10, Batch 30/97, Loss: 0.1780
Epoch 9/10, Batch 40/97, Loss: 0.1281
Epoch 9/10, Batch 50/97, Loss: 0.1887
Epoch 9/10, Batch 60/97, Loss: 0.2316
Epoch 9/10, Batch 70/97, Loss: 0.2389
Epoch 9/10, Batch 80/97, Loss: 0.2073
Epoch 9/10, Batch 90/97, Loss: 0.1866
Epoch 9/10, Train Loss: 0.2109, Valid Loss: 0.2405
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2487
Epoch 10/10, Batch 20/97, Loss: 0.1856
Epoch 10/10, Batch 30/97, Loss: 0.1453
Epoch 10/10, Batch 40/97, Loss: 0.2798
Epoch 10/10, Batch 50/97, Loss: 0.2032
Epoch 10/10, Batch 60/97, Loss: 0.2288
Epoch 10/10, Batch 70/97, Loss: 0.1694
Epoch 10/10, Batch 80/97, Loss: 0.1510
Epoch 10/10, Batch 90/97, Loss: 0.1330
Epoch 10/10, Train Loss: 0.2025, Valid Loss: 0.2362
Model saved!
Accuracy: 0.9124
Precision: 0.9104
Recall: 0.9124
F1-score: 0.9111
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4959
Epoch 1/10, Batch 20/97, Loss: 0.9459
Epoch 1/10, Batch 30/97, Loss: 0.7907
Epoch 1/10, Batch 40/97, Loss: 0.7864
Epoch 1/10, Batch 50/97, Loss: 0.6684
Epoch 1/10, Batch 60/97, Loss: 0.6585
Epoch 1/10, Batch 70/97, Loss: 0.5015
Epoch 1/10, Batch 80/97, Loss: 0.4920
Epoch 1/10, Batch 90/97, Loss: 0.4611
Epoch 1/10, Train Loss: 0.7729, Valid Loss: 0.4405
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4339
Epoch 2/10, Batch 20/97, Loss: 0.4126
Epoch 2/10, Batch 30/97, Loss: 0.4236
Epoch 2/10, Batch 40/97, Loss: 0.4848
Epoch 2/10, Batch 50/97, Loss: 0.5251
Epoch 2/10, Batch 60/97, Loss: 0.2222
Epoch 2/10, Batch 70/97, Loss: 0.2641
Epoch 2/10, Batch 80/97, Loss: 0.3725
Epoch 2/10, Batch 90/97, Loss: 0.2576
Epoch 2/10, Train Loss: 0.3947, Valid Loss: 0.3432
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3110
Epoch 3/10, Batch 20/97, Loss: 0.3380
Epoch 3/10, Batch 30/97, Loss: 0.2654
Epoch 3/10, Batch 40/97, Loss: 0.2492
Epoch 3/10, Batch 50/97, Loss: 0.2882
Epoch 3/10, Batch 60/97, Loss: 0.2326
Epoch 3/10, Batch 70/97, Loss: 0.2966
Epoch 3/10, Batch 80/97, Loss: 0.4041
Epoch 3/10, Batch 90/97, Loss: 0.4165
Epoch 3/10, Train Loss: 0.3273, Valid Loss: 0.3080
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2313
Epoch 4/10, Batch 20/97, Loss: 0.1918
Epoch 4/10, Batch 30/97, Loss: 0.3480
Epoch 4/10, Batch 40/97, Loss: 0.2494
Epoch 4/10, Batch 50/97, Loss: 0.1433
Epoch 4/10, Batch 60/97, Loss: 0.3029
Epoch 4/10, Batch 70/97, Loss: 0.3269
Epoch 4/10, Batch 80/97, Loss: 0.2250
Epoch 4/10, Batch 90/97, Loss: 0.3697
Epoch 4/10, Train Loss: 0.2857, Valid Loss: 0.2830
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1193
Epoch 5/10, Batch 20/97, Loss: 0.1692
Epoch 5/10, Batch 30/97, Loss: 0.1353
Epoch 5/10, Batch 40/97, Loss: 0.1719
Epoch 5/10, Batch 50/97, Loss: 0.3233
Epoch 5/10, Batch 60/97, Loss: 0.2783
Epoch 5/10, Batch 70/97, Loss: 0.1947
Epoch 5/10, Batch 80/97, Loss: 0.3925
Epoch 5/10, Batch 90/97, Loss: 0.4688
Epoch 5/10, Train Loss: 0.2509, Valid Loss: 0.2712
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2215
Epoch 6/10, Batch 20/97, Loss: 0.3509
Epoch 6/10, Batch 30/97, Loss: 0.2482
Epoch 6/10, Batch 40/97, Loss: 0.5375
Epoch 6/10, Batch 50/97, Loss: 0.1605
Epoch 6/10, Batch 60/97, Loss: 0.2311
Epoch 6/10, Batch 70/97, Loss: 0.1955
Epoch 6/10, Batch 80/97, Loss: 0.2075
Epoch 6/10, Batch 90/97, Loss: 0.1979
Epoch 6/10, Train Loss: 0.2443, Valid Loss: 0.2644
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1698
Epoch 7/10, Batch 20/97, Loss: 0.3567
Epoch 7/10, Batch 30/97, Loss: 0.1218
Epoch 7/10, Batch 40/97, Loss: 0.1867
Epoch 7/10, Batch 50/97, Loss: 0.2106
Epoch 7/10, Batch 60/97, Loss: 0.3838
Epoch 7/10, Batch 70/97, Loss: 0.1149
Epoch 7/10, Batch 80/97, Loss: 0.1790
Epoch 7/10, Batch 90/97, Loss: 0.2438
Epoch 7/10, Train Loss: 0.2372, Valid Loss: 0.2598
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2395
Epoch 8/10, Batch 20/97, Loss: 0.1416
Epoch 8/10, Batch 30/97, Loss: 0.0778
Epoch 8/10, Batch 40/97, Loss: 0.3106
Epoch 8/10, Batch 50/97, Loss: 0.2264
Epoch 8/10, Batch 60/97, Loss: 0.2821
Epoch 8/10, Batch 70/97, Loss: 0.3298
Epoch 8/10, Batch 80/97, Loss: 0.3872
Epoch 8/10, Batch 90/97, Loss: 0.2504
Epoch 8/10, Train Loss: 0.2175, Valid Loss: 0.2518
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1604
Epoch 9/10, Batch 20/97, Loss: 0.1440
Epoch 9/10, Batch 30/97, Loss: 0.1208
Epoch 9/10, Batch 40/97, Loss: 0.1641
Epoch 9/10, Batch 50/97, Loss: 0.2658
Epoch 9/10, Batch 60/97, Loss: 0.1021
Epoch 9/10, Batch 70/97, Loss: 0.1375
Epoch 9/10, Batch 80/97, Loss: 0.1723
Epoch 9/10, Batch 90/97, Loss: 0.3590
Epoch 9/10, Train Loss: 0.2088, Valid Loss: 0.2503
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3627
Epoch 10/10, Batch 20/97, Loss: 0.0852
Epoch 10/10, Batch 30/97, Loss: 0.1160
Epoch 10/10, Batch 40/97, Loss: 0.1544
Epoch 10/10, Batch 50/97, Loss: 0.3827
Epoch 10/10, Batch 60/97, Loss: 0.1427
Epoch 10/10, Batch 70/97, Loss: 0.1601
Epoch 10/10, Batch 80/97, Loss: 0.3787
Epoch 10/10, Batch 90/97, Loss: 0.1729
Epoch 10/10, Train Loss: 0.1920, Valid Loss: 0.2449
Model saved!
Accuracy: 0.9182
Precision: 0.9180
Recall: 0.9182
F1-score: 0.9177
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4011
Epoch 1/10, Batch 20/97, Loss: 0.9784
Epoch 1/10, Batch 30/97, Loss: 0.9226
Epoch 1/10, Batch 40/97, Loss: 0.8025
Epoch 1/10, Batch 50/97, Loss: 0.6146
Epoch 1/10, Batch 60/97, Loss: 0.6127
Epoch 1/10, Batch 70/97, Loss: 0.4983
Epoch 1/10, Batch 80/97, Loss: 0.5658
Epoch 1/10, Batch 90/97, Loss: 0.5633
Epoch 1/10, Train Loss: 0.7768, Valid Loss: 0.4531
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5249
Epoch 2/10, Batch 20/97, Loss: 0.5568
Epoch 2/10, Batch 30/97, Loss: 0.2855
Epoch 2/10, Batch 40/97, Loss: 0.4008
Epoch 2/10, Batch 50/97, Loss: 0.5958
Epoch 2/10, Batch 60/97, Loss: 0.3455
Epoch 2/10, Batch 70/97, Loss: 0.2962
Epoch 2/10, Batch 80/97, Loss: 0.2581
Epoch 2/10, Batch 90/97, Loss: 0.2794
Epoch 2/10, Train Loss: 0.4020, Valid Loss: 0.3464
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2749
Epoch 3/10, Batch 20/97, Loss: 0.3319
Epoch 3/10, Batch 30/97, Loss: 0.2700
Epoch 3/10, Batch 40/97, Loss: 0.3709
Epoch 3/10, Batch 50/97, Loss: 0.1685
Epoch 3/10, Batch 60/97, Loss: 0.2628
Epoch 3/10, Batch 70/97, Loss: 0.2526
Epoch 3/10, Batch 80/97, Loss: 0.3548
Epoch 3/10, Batch 90/97, Loss: 0.3476
Epoch 3/10, Train Loss: 0.3326, Valid Loss: 0.3042
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3626
Epoch 4/10, Batch 20/97, Loss: 0.2884
Epoch 4/10, Batch 30/97, Loss: 0.3048
Epoch 4/10, Batch 40/97, Loss: 0.4565
Epoch 4/10, Batch 50/97, Loss: 0.2394
Epoch 4/10, Batch 60/97, Loss: 0.1003
Epoch 4/10, Batch 70/97, Loss: 0.1291
Epoch 4/10, Batch 80/97, Loss: 0.2762
Epoch 4/10, Batch 90/97, Loss: 0.2530
Epoch 4/10, Train Loss: 0.2871, Valid Loss: 0.2816
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2550
Epoch 5/10, Batch 20/97, Loss: 0.1206
Epoch 5/10, Batch 30/97, Loss: 0.1460
Epoch 5/10, Batch 40/97, Loss: 0.1680
Epoch 5/10, Batch 50/97, Loss: 0.1953
Epoch 5/10, Batch 60/97, Loss: 0.2478
Epoch 5/10, Batch 70/97, Loss: 0.3075
Epoch 5/10, Batch 80/97, Loss: 0.3175
Epoch 5/10, Batch 90/97, Loss: 0.2464
Epoch 5/10, Train Loss: 0.2673, Valid Loss: 0.2764
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1836
Epoch 6/10, Batch 20/97, Loss: 0.2228
Epoch 6/10, Batch 30/97, Loss: 0.1734
Epoch 6/10, Batch 40/97, Loss: 0.3898
Epoch 6/10, Batch 50/97, Loss: 0.1835
Epoch 6/10, Batch 60/97, Loss: 0.2151
Epoch 6/10, Batch 70/97, Loss: 0.1605
Epoch 6/10, Batch 80/97, Loss: 0.2425
Epoch 6/10, Batch 90/97, Loss: 0.3541
Epoch 6/10, Train Loss: 0.2438, Valid Loss: 0.2626
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3244
Epoch 7/10, Batch 20/97, Loss: 0.2191
Epoch 7/10, Batch 30/97, Loss: 0.3535
Epoch 7/10, Batch 40/97, Loss: 0.1261
Epoch 7/10, Batch 50/97, Loss: 0.2281
Epoch 7/10, Batch 60/97, Loss: 0.2978
Epoch 7/10, Batch 70/97, Loss: 0.0862
Epoch 7/10, Batch 80/97, Loss: 0.3143
Epoch 7/10, Batch 90/97, Loss: 0.1569
Epoch 7/10, Train Loss: 0.2419, Valid Loss: 0.2635
Epoch 8/10, Batch 10/97, Loss: 0.2708
Epoch 8/10, Batch 20/97, Loss: 0.2181
Epoch 8/10, Batch 30/97, Loss: 0.1283
Epoch 8/10, Batch 40/97, Loss: 0.3831
Epoch 8/10, Batch 50/97, Loss: 0.1492
Epoch 8/10, Batch 60/97, Loss: 0.1515
Epoch 8/10, Batch 70/97, Loss: 0.3280
Epoch 8/10, Batch 80/97, Loss: 0.1829
Epoch 8/10, Batch 90/97, Loss: 0.1375
Epoch 8/10, Train Loss: 0.2240, Valid Loss: 0.2581
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1618
Epoch 9/10, Batch 20/97, Loss: 0.1014
Epoch 9/10, Batch 30/97, Loss: 0.2408
Epoch 9/10, Batch 40/97, Loss: 0.1555
Epoch 9/10, Batch 50/97, Loss: 0.1774
Epoch 9/10, Batch 60/97, Loss: 0.1517
Epoch 9/10, Batch 70/97, Loss: 0.1891
Epoch 9/10, Batch 80/97, Loss: 0.1789
Epoch 9/10, Batch 90/97, Loss: 0.3611
Epoch 9/10, Train Loss: 0.2157, Valid Loss: 0.2527
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2136
Epoch 10/10, Batch 20/97, Loss: 0.1397
Epoch 10/10, Batch 30/97, Loss: 0.2430
Epoch 10/10, Batch 40/97, Loss: 0.2796
Epoch 10/10, Batch 50/97, Loss: 0.3002
Epoch 10/10, Batch 60/97, Loss: 0.0978
Epoch 10/10, Batch 70/97, Loss: 0.2152
Epoch 10/10, Batch 80/97, Loss: 0.1228
Epoch 10/10, Batch 90/97, Loss: 0.1637
Epoch 10/10, Train Loss: 0.2084, Valid Loss: 0.2451
Model saved!
Accuracy: 0.9217
Precision: 0.9201
Recall: 0.9217
F1-score: 0.9206
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5092
Epoch 1/10, Batch 20/97, Loss: 0.9861
Epoch 1/10, Batch 30/97, Loss: 0.9353
Epoch 1/10, Batch 40/97, Loss: 0.6780
Epoch 1/10, Batch 50/97, Loss: 0.5781
Epoch 1/10, Batch 60/97, Loss: 0.6254
Epoch 1/10, Batch 70/97, Loss: 0.4751
Epoch 1/10, Batch 80/97, Loss: 0.4398
Epoch 1/10, Batch 90/97, Loss: 0.4750
Epoch 1/10, Train Loss: 0.7705, Valid Loss: 0.4405
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4804
Epoch 2/10, Batch 20/97, Loss: 0.5736
Epoch 2/10, Batch 30/97, Loss: 0.4221
Epoch 2/10, Batch 40/97, Loss: 0.3968
Epoch 2/10, Batch 50/97, Loss: 0.5032
Epoch 2/10, Batch 60/97, Loss: 0.3700
Epoch 2/10, Batch 70/97, Loss: 0.2739
Epoch 2/10, Batch 80/97, Loss: 0.2965
Epoch 2/10, Batch 90/97, Loss: 0.3386
Epoch 2/10, Train Loss: 0.3887, Valid Loss: 0.3369
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3303
Epoch 3/10, Batch 20/97, Loss: 0.2764
Epoch 3/10, Batch 30/97, Loss: 0.2751
Epoch 3/10, Batch 40/97, Loss: 0.3070
Epoch 3/10, Batch 50/97, Loss: 0.2630
Epoch 3/10, Batch 60/97, Loss: 0.2762
Epoch 3/10, Batch 70/97, Loss: 0.2962
Epoch 3/10, Batch 80/97, Loss: 0.3213
Epoch 3/10, Batch 90/97, Loss: 0.2148
Epoch 3/10, Train Loss: 0.3191, Valid Loss: 0.2948
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2476
Epoch 4/10, Batch 20/97, Loss: 0.2019
Epoch 4/10, Batch 30/97, Loss: 0.2761
Epoch 4/10, Batch 40/97, Loss: 0.2043
Epoch 4/10, Batch 50/97, Loss: 0.1249
Epoch 4/10, Batch 60/97, Loss: 0.2063
Epoch 4/10, Batch 70/97, Loss: 0.1869
Epoch 4/10, Batch 80/97, Loss: 0.1880
Epoch 4/10, Batch 90/97, Loss: 0.3767
Epoch 4/10, Train Loss: 0.2829, Valid Loss: 0.2679
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2073
Epoch 5/10, Batch 20/97, Loss: 0.1562
Epoch 5/10, Batch 30/97, Loss: 0.1248
Epoch 5/10, Batch 40/97, Loss: 0.1432
Epoch 5/10, Batch 50/97, Loss: 0.1686
Epoch 5/10, Batch 60/97, Loss: 0.2988
Epoch 5/10, Batch 70/97, Loss: 0.1777
Epoch 5/10, Batch 80/97, Loss: 0.4465
Epoch 5/10, Batch 90/97, Loss: 0.3941
Epoch 5/10, Train Loss: 0.2607, Valid Loss: 0.2586
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1730
Epoch 6/10, Batch 20/97, Loss: 0.2449
Epoch 6/10, Batch 30/97, Loss: 0.1865
Epoch 6/10, Batch 40/97, Loss: 0.2447
Epoch 6/10, Batch 50/97, Loss: 0.1447
Epoch 6/10, Batch 60/97, Loss: 0.2599
Epoch 6/10, Batch 70/97, Loss: 0.3020
Epoch 6/10, Batch 80/97, Loss: 0.1877
Epoch 6/10, Batch 90/97, Loss: 0.2498
Epoch 6/10, Train Loss: 0.2428, Valid Loss: 0.2384
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2941
Epoch 7/10, Batch 20/97, Loss: 0.1471
Epoch 7/10, Batch 30/97, Loss: 0.2041
Epoch 7/10, Batch 40/97, Loss: 0.1784
Epoch 7/10, Batch 50/97, Loss: 0.3788
Epoch 7/10, Batch 60/97, Loss: 0.2332
Epoch 7/10, Batch 70/97, Loss: 0.1602
Epoch 7/10, Batch 80/97, Loss: 0.2038
Epoch 7/10, Batch 90/97, Loss: 0.3219
Epoch 7/10, Train Loss: 0.2389, Valid Loss: 0.2385
Epoch 8/10, Batch 10/97, Loss: 0.3589
Epoch 8/10, Batch 20/97, Loss: 0.2043
Epoch 8/10, Batch 30/97, Loss: 0.1811
Epoch 8/10, Batch 40/97, Loss: 0.2293
Epoch 8/10, Batch 50/97, Loss: 0.2367
Epoch 8/10, Batch 60/97, Loss: 0.2075
Epoch 8/10, Batch 70/97, Loss: 0.3808
Epoch 8/10, Batch 80/97, Loss: 0.1894
Epoch 8/10, Batch 90/97, Loss: 0.1465
Epoch 8/10, Train Loss: 0.2222, Valid Loss: 0.2352
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1440
Epoch 9/10, Batch 20/97, Loss: 0.1974
Epoch 9/10, Batch 30/97, Loss: 0.1532
Epoch 9/10, Batch 40/97, Loss: 0.1394
Epoch 9/10, Batch 50/97, Loss: 0.2682
Epoch 9/10, Batch 60/97, Loss: 0.1390
Epoch 9/10, Batch 70/97, Loss: 0.3403
Epoch 9/10, Batch 80/97, Loss: 0.1880
Epoch 9/10, Batch 90/97, Loss: 0.3266
Epoch 9/10, Train Loss: 0.1981, Valid Loss: 0.2232
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2928
Epoch 10/10, Batch 20/97, Loss: 0.1513
Epoch 10/10, Batch 30/97, Loss: 0.2371
Epoch 10/10, Batch 40/97, Loss: 0.1379
Epoch 10/10, Batch 50/97, Loss: 0.2937
Epoch 10/10, Batch 60/97, Loss: 0.1702
Epoch 10/10, Batch 70/97, Loss: 0.1872
Epoch 10/10, Batch 80/97, Loss: 0.2564
Epoch 10/10, Batch 90/97, Loss: 0.1004
Epoch 10/10, Train Loss: 0.1917, Valid Loss: 0.2230
Model saved!
Accuracy: 0.9159
Precision: 0.9139
Recall: 0.9159
F1-score: 0.9145
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.3992
Epoch 1/10, Batch 20/97, Loss: 0.9465
Epoch 1/10, Batch 30/97, Loss: 0.8344
Epoch 1/10, Batch 40/97, Loss: 0.6683
Epoch 1/10, Batch 50/97, Loss: 0.5673
Epoch 1/10, Batch 60/97, Loss: 0.6472
Epoch 1/10, Batch 70/97, Loss: 0.5664
Epoch 1/10, Batch 80/97, Loss: 0.4057
Epoch 1/10, Batch 90/97, Loss: 0.5480
Epoch 1/10, Train Loss: 0.7656, Valid Loss: 0.4442
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3632
Epoch 2/10, Batch 20/97, Loss: 0.5257
Epoch 2/10, Batch 30/97, Loss: 0.4445
Epoch 2/10, Batch 40/97, Loss: 0.3949
Epoch 2/10, Batch 50/97, Loss: 0.4632
Epoch 2/10, Batch 60/97, Loss: 0.3476
Epoch 2/10, Batch 70/97, Loss: 0.2806
Epoch 2/10, Batch 80/97, Loss: 0.3285
Epoch 2/10, Batch 90/97, Loss: 0.3477
Epoch 2/10, Train Loss: 0.3840, Valid Loss: 0.3458
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3025
Epoch 3/10, Batch 20/97, Loss: 0.3638
Epoch 3/10, Batch 30/97, Loss: 0.2357
Epoch 3/10, Batch 40/97, Loss: 0.2274
Epoch 3/10, Batch 50/97, Loss: 0.1968
Epoch 3/10, Batch 60/97, Loss: 0.3291
Epoch 3/10, Batch 70/97, Loss: 0.2023
Epoch 3/10, Batch 80/97, Loss: 0.3871
Epoch 3/10, Batch 90/97, Loss: 0.4272
Epoch 3/10, Train Loss: 0.3148, Valid Loss: 0.3014
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3468
Epoch 4/10, Batch 20/97, Loss: 0.2622
Epoch 4/10, Batch 30/97, Loss: 0.2904
Epoch 4/10, Batch 40/97, Loss: 0.2491
Epoch 4/10, Batch 50/97, Loss: 0.1585
Epoch 4/10, Batch 60/97, Loss: 0.2617
Epoch 4/10, Batch 70/97, Loss: 0.3204
Epoch 4/10, Batch 80/97, Loss: 0.3419
Epoch 4/10, Batch 90/97, Loss: 0.2391
Epoch 4/10, Train Loss: 0.2785, Valid Loss: 0.2748
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2163
Epoch 5/10, Batch 20/97, Loss: 0.1556
Epoch 5/10, Batch 30/97, Loss: 0.1701
Epoch 5/10, Batch 40/97, Loss: 0.2004
Epoch 5/10, Batch 50/97, Loss: 0.2606
Epoch 5/10, Batch 60/97, Loss: 0.3225
Epoch 5/10, Batch 70/97, Loss: 0.2514
Epoch 5/10, Batch 80/97, Loss: 0.3838
Epoch 5/10, Batch 90/97, Loss: 0.3109
Epoch 5/10, Train Loss: 0.2455, Valid Loss: 0.2599
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1630
Epoch 6/10, Batch 20/97, Loss: 0.2781
Epoch 6/10, Batch 30/97, Loss: 0.1936
Epoch 6/10, Batch 40/97, Loss: 0.2094
Epoch 6/10, Batch 50/97, Loss: 0.1976
Epoch 6/10, Batch 60/97, Loss: 0.2498
Epoch 6/10, Batch 70/97, Loss: 0.3253
Epoch 6/10, Batch 80/97, Loss: 0.2053
Epoch 6/10, Batch 90/97, Loss: 0.3079
Epoch 6/10, Train Loss: 0.2357, Valid Loss: 0.2629
Epoch 7/10, Batch 10/97, Loss: 0.3098
Epoch 7/10, Batch 20/97, Loss: 0.1622
Epoch 7/10, Batch 30/97, Loss: 0.1955
Epoch 7/10, Batch 40/97, Loss: 0.2101
Epoch 7/10, Batch 50/97, Loss: 0.3572
Epoch 7/10, Batch 60/97, Loss: 0.2084
Epoch 7/10, Batch 70/97, Loss: 0.1333
Epoch 7/10, Batch 80/97, Loss: 0.2061
Epoch 7/10, Batch 90/97, Loss: 0.2226
Epoch 7/10, Train Loss: 0.2291, Valid Loss: 0.2475
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2549
Epoch 8/10, Batch 20/97, Loss: 0.2817
Epoch 8/10, Batch 30/97, Loss: 0.0685
Epoch 8/10, Batch 40/97, Loss: 0.1174
Epoch 8/10, Batch 50/97, Loss: 0.1276
Epoch 8/10, Batch 60/97, Loss: 0.0854
Epoch 8/10, Batch 70/97, Loss: 0.3190
Epoch 8/10, Batch 80/97, Loss: 0.1904
Epoch 8/10, Batch 90/97, Loss: 0.1723
Epoch 8/10, Train Loss: 0.2145, Valid Loss: 0.2407
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1316
Epoch 9/10, Batch 20/97, Loss: 0.0956
Epoch 9/10, Batch 30/97, Loss: 0.3120
Epoch 9/10, Batch 40/97, Loss: 0.0679
Epoch 9/10, Batch 50/97, Loss: 0.1164
Epoch 9/10, Batch 60/97, Loss: 0.2585
Epoch 9/10, Batch 70/97, Loss: 0.4577
Epoch 9/10, Batch 80/97, Loss: 0.1056
Epoch 9/10, Batch 90/97, Loss: 0.1158
Epoch 9/10, Train Loss: 0.1949, Valid Loss: 0.2425
Epoch 10/10, Batch 10/97, Loss: 0.1266
Epoch 10/10, Batch 20/97, Loss: 0.1252
Epoch 10/10, Batch 30/97, Loss: 0.1757
Epoch 10/10, Batch 40/97, Loss: 0.1319
Epoch 10/10, Batch 50/97, Loss: 0.2573
Epoch 10/10, Batch 60/97, Loss: 0.1814
Epoch 10/10, Batch 70/97, Loss: 0.1653
Epoch 10/10, Batch 80/97, Loss: 0.1587
Epoch 10/10, Batch 90/97, Loss: 0.2388
Epoch 10/10, Train Loss: 0.1893, Valid Loss: 0.2320
Model saved!
Accuracy: 0.9112
Precision: 0.9087
Recall: 0.9112
F1-score: 0.9092
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4951
Epoch 1/10, Batch 20/97, Loss: 1.0496
Epoch 1/10, Batch 30/97, Loss: 0.8558
Epoch 1/10, Batch 40/97, Loss: 0.7522
Epoch 1/10, Batch 50/97, Loss: 0.6625
Epoch 1/10, Batch 60/97, Loss: 0.7244
Epoch 1/10, Batch 70/97, Loss: 0.4271
Epoch 1/10, Batch 80/97, Loss: 0.4690
Epoch 1/10, Batch 90/97, Loss: 0.4412
Epoch 1/10, Train Loss: 0.7790, Valid Loss: 0.4143
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5537
Epoch 2/10, Batch 20/97, Loss: 0.5605
Epoch 2/10, Batch 30/97, Loss: 0.3769
Epoch 2/10, Batch 40/97, Loss: 0.4371
Epoch 2/10, Batch 50/97, Loss: 0.4503
Epoch 2/10, Batch 60/97, Loss: 0.3191
Epoch 2/10, Batch 70/97, Loss: 0.4470
Epoch 2/10, Batch 80/97, Loss: 0.3803
Epoch 2/10, Batch 90/97, Loss: 0.2820
Epoch 2/10, Train Loss: 0.3967, Valid Loss: 0.3131
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2227
Epoch 3/10, Batch 20/97, Loss: 0.4611
Epoch 3/10, Batch 30/97, Loss: 0.2109
Epoch 3/10, Batch 40/97, Loss: 0.2316
Epoch 3/10, Batch 50/97, Loss: 0.3573
Epoch 3/10, Batch 60/97, Loss: 0.2389
Epoch 3/10, Batch 70/97, Loss: 0.1967
Epoch 3/10, Batch 80/97, Loss: 0.3834
Epoch 3/10, Batch 90/97, Loss: 0.3048
Epoch 3/10, Train Loss: 0.3281, Valid Loss: 0.2705
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3901
Epoch 4/10, Batch 20/97, Loss: 0.2817
Epoch 4/10, Batch 30/97, Loss: 0.4455
Epoch 4/10, Batch 40/97, Loss: 0.3196
Epoch 4/10, Batch 50/97, Loss: 0.2993
Epoch 4/10, Batch 60/97, Loss: 0.1401
Epoch 4/10, Batch 70/97, Loss: 0.3273
Epoch 4/10, Batch 80/97, Loss: 0.2427
Epoch 4/10, Batch 90/97, Loss: 0.4371
Epoch 4/10, Train Loss: 0.2911, Valid Loss: 0.2493
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3044
Epoch 5/10, Batch 20/97, Loss: 0.2362
Epoch 5/10, Batch 30/97, Loss: 0.2136
Epoch 5/10, Batch 40/97, Loss: 0.1450
Epoch 5/10, Batch 50/97, Loss: 0.1368
Epoch 5/10, Batch 60/97, Loss: 0.2219
Epoch 5/10, Batch 70/97, Loss: 0.4305
Epoch 5/10, Batch 80/97, Loss: 0.3179
Epoch 5/10, Batch 90/97, Loss: 0.3900
Epoch 5/10, Train Loss: 0.2683, Valid Loss: 0.2351
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2492
Epoch 6/10, Batch 20/97, Loss: 0.2483
Epoch 6/10, Batch 30/97, Loss: 0.3332
Epoch 6/10, Batch 40/97, Loss: 0.2750
Epoch 6/10, Batch 50/97, Loss: 0.1943
Epoch 6/10, Batch 60/97, Loss: 0.2431
Epoch 6/10, Batch 70/97, Loss: 0.2691
Epoch 6/10, Batch 80/97, Loss: 0.2888
Epoch 6/10, Batch 90/97, Loss: 0.3424
Epoch 6/10, Train Loss: 0.2483, Valid Loss: 0.2288
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1498
Epoch 7/10, Batch 20/97, Loss: 0.2131
Epoch 7/10, Batch 30/97, Loss: 0.1530
Epoch 7/10, Batch 40/97, Loss: 0.1367
Epoch 7/10, Batch 50/97, Loss: 0.1827
Epoch 7/10, Batch 60/97, Loss: 0.2858
Epoch 7/10, Batch 70/97, Loss: 0.1074
Epoch 7/10, Batch 80/97, Loss: 0.2332
Epoch 7/10, Batch 90/97, Loss: 0.2414
Epoch 7/10, Train Loss: 0.2464, Valid Loss: 0.2225
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2864
Epoch 8/10, Batch 20/97, Loss: 0.1851
Epoch 8/10, Batch 30/97, Loss: 0.3941
Epoch 8/10, Batch 40/97, Loss: 0.2058
Epoch 8/10, Batch 50/97, Loss: 0.1883
Epoch 8/10, Batch 60/97, Loss: 0.0948
Epoch 8/10, Batch 70/97, Loss: 0.2423
Epoch 8/10, Batch 80/97, Loss: 0.1126
Epoch 8/10, Batch 90/97, Loss: 0.2116
Epoch 8/10, Train Loss: 0.2322, Valid Loss: 0.2145
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1780
Epoch 9/10, Batch 20/97, Loss: 0.1076
Epoch 9/10, Batch 30/97, Loss: 0.4563
Epoch 9/10, Batch 40/97, Loss: 0.1451
Epoch 9/10, Batch 50/97, Loss: 0.1839
Epoch 9/10, Batch 60/97, Loss: 0.1388
Epoch 9/10, Batch 70/97, Loss: 0.2083
Epoch 9/10, Batch 80/97, Loss: 0.1856
Epoch 9/10, Batch 90/97, Loss: 0.2528
Epoch 9/10, Train Loss: 0.2221, Valid Loss: 0.2107
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3269
Epoch 10/10, Batch 20/97, Loss: 0.1671
Epoch 10/10, Batch 30/97, Loss: 0.2661
Epoch 10/10, Batch 40/97, Loss: 0.2687
Epoch 10/10, Batch 50/97, Loss: 0.2547
Epoch 10/10, Batch 60/97, Loss: 0.2101
Epoch 10/10, Batch 70/97, Loss: 0.2408
Epoch 10/10, Batch 80/97, Loss: 0.0885
Epoch 10/10, Batch 90/97, Loss: 0.2217
Epoch 10/10, Train Loss: 0.2053, Valid Loss: 0.1983
Model saved!
Accuracy: 0.9171
Precision: 0.9147
Recall: 0.9171
F1-score: 0.9152
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4124
Epoch 1/10, Batch 20/97, Loss: 1.0729
Epoch 1/10, Batch 30/97, Loss: 0.8391
Epoch 1/10, Batch 40/97, Loss: 0.7750
Epoch 1/10, Batch 50/97, Loss: 0.5436
Epoch 1/10, Batch 60/97, Loss: 0.5735
Epoch 1/10, Batch 70/97, Loss: 0.5397
Epoch 1/10, Batch 80/97, Loss: 0.4872
Epoch 1/10, Batch 90/97, Loss: 0.5436
Epoch 1/10, Train Loss: 0.7826, Valid Loss: 0.4458
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4246
Epoch 2/10, Batch 20/97, Loss: 0.3916
Epoch 2/10, Batch 30/97, Loss: 0.3234
Epoch 2/10, Batch 40/97, Loss: 0.3414
Epoch 2/10, Batch 50/97, Loss: 0.4066
Epoch 2/10, Batch 60/97, Loss: 0.3152
Epoch 2/10, Batch 70/97, Loss: 0.3706
Epoch 2/10, Batch 80/97, Loss: 0.4707
Epoch 2/10, Batch 90/97, Loss: 0.4010
Epoch 2/10, Train Loss: 0.4132, Valid Loss: 0.3379
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3134
Epoch 3/10, Batch 20/97, Loss: 0.2789
Epoch 3/10, Batch 30/97, Loss: 0.2294
Epoch 3/10, Batch 40/97, Loss: 0.3858
Epoch 3/10, Batch 50/97, Loss: 0.4343
Epoch 3/10, Batch 60/97, Loss: 0.3102
Epoch 3/10, Batch 70/97, Loss: 0.2005
Epoch 3/10, Batch 80/97, Loss: 0.4026
Epoch 3/10, Batch 90/97, Loss: 0.3601
Epoch 3/10, Train Loss: 0.3405, Valid Loss: 0.2938
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2311
Epoch 4/10, Batch 20/97, Loss: 0.2523
Epoch 4/10, Batch 30/97, Loss: 0.3913
Epoch 4/10, Batch 40/97, Loss: 0.2552
Epoch 4/10, Batch 50/97, Loss: 0.1047
Epoch 4/10, Batch 60/97, Loss: 0.1888
Epoch 4/10, Batch 70/97, Loss: 0.3540
Epoch 4/10, Batch 80/97, Loss: 0.2517
Epoch 4/10, Batch 90/97, Loss: 0.3095
Epoch 4/10, Train Loss: 0.2975, Valid Loss: 0.2729
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2021
Epoch 5/10, Batch 20/97, Loss: 0.1879
Epoch 5/10, Batch 30/97, Loss: 0.2948
Epoch 5/10, Batch 40/97, Loss: 0.1212
Epoch 5/10, Batch 50/97, Loss: 0.1750
Epoch 5/10, Batch 60/97, Loss: 0.4248
Epoch 5/10, Batch 70/97, Loss: 0.2075
Epoch 5/10, Batch 80/97, Loss: 0.4791
Epoch 5/10, Batch 90/97, Loss: 0.3385
Epoch 5/10, Train Loss: 0.2737, Valid Loss: 0.2551
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2969
Epoch 6/10, Batch 20/97, Loss: 0.2025
Epoch 6/10, Batch 30/97, Loss: 0.2318
Epoch 6/10, Batch 40/97, Loss: 0.3429
Epoch 6/10, Batch 50/97, Loss: 0.2178
Epoch 6/10, Batch 60/97, Loss: 0.1808
Epoch 6/10, Batch 70/97, Loss: 0.1436
Epoch 6/10, Batch 80/97, Loss: 0.1940
Epoch 6/10, Batch 90/97, Loss: 0.2073
Epoch 6/10, Train Loss: 0.2505, Valid Loss: 0.2485
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2580
Epoch 7/10, Batch 20/97, Loss: 0.1359
Epoch 7/10, Batch 30/97, Loss: 0.1688
Epoch 7/10, Batch 40/97, Loss: 0.2066
Epoch 7/10, Batch 50/97, Loss: 0.2285
Epoch 7/10, Batch 60/97, Loss: 0.1892
Epoch 7/10, Batch 70/97, Loss: 0.2492
Epoch 7/10, Batch 80/97, Loss: 0.2020
Epoch 7/10, Batch 90/97, Loss: 0.3154
Epoch 7/10, Train Loss: 0.2550, Valid Loss: 0.2395
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1554
Epoch 8/10, Batch 20/97, Loss: 0.3236
Epoch 8/10, Batch 30/97, Loss: 0.1091
Epoch 8/10, Batch 40/97, Loss: 0.1626
Epoch 8/10, Batch 50/97, Loss: 0.2383
Epoch 8/10, Batch 60/97, Loss: 0.2491
Epoch 8/10, Batch 70/97, Loss: 0.2229
Epoch 8/10, Batch 80/97, Loss: 0.0912
Epoch 8/10, Batch 90/97, Loss: 0.1553
Epoch 8/10, Train Loss: 0.2329, Valid Loss: 0.2369
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1150
Epoch 9/10, Batch 20/97, Loss: 0.1432
Epoch 9/10, Batch 30/97, Loss: 0.2474
Epoch 9/10, Batch 40/97, Loss: 0.2629
Epoch 9/10, Batch 50/97, Loss: 0.4164
Epoch 9/10, Batch 60/97, Loss: 0.1067
Epoch 9/10, Batch 70/97, Loss: 0.1280
Epoch 9/10, Batch 80/97, Loss: 0.1577
Epoch 9/10, Batch 90/97, Loss: 0.1574
Epoch 9/10, Train Loss: 0.2223, Valid Loss: 0.2328
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2388
Epoch 10/10, Batch 20/97, Loss: 0.1285
Epoch 10/10, Batch 30/97, Loss: 0.2232
Epoch 10/10, Batch 40/97, Loss: 0.2143
Epoch 10/10, Batch 50/97, Loss: 0.3106
Epoch 10/10, Batch 60/97, Loss: 0.2769
Epoch 10/10, Batch 70/97, Loss: 0.1816
Epoch 10/10, Batch 80/97, Loss: 0.3367
Epoch 10/10, Batch 90/97, Loss: 0.3315
Epoch 10/10, Train Loss: 0.2096, Valid Loss: 0.2229
Model saved!
Accuracy: 0.9182
Precision: 0.9162
Recall: 0.9182
F1-score: 0.9166
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5419
Epoch 1/10, Batch 20/97, Loss: 0.9939
Epoch 1/10, Batch 30/97, Loss: 0.8199
Epoch 1/10, Batch 40/97, Loss: 0.7756
Epoch 1/10, Batch 50/97, Loss: 0.6116
Epoch 1/10, Batch 60/97, Loss: 0.5956
Epoch 1/10, Batch 70/97, Loss: 0.5620
Epoch 1/10, Batch 80/97, Loss: 0.4582
Epoch 1/10, Batch 90/97, Loss: 0.5017
Epoch 1/10, Train Loss: 0.7823, Valid Loss: 0.4364
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4091
Epoch 2/10, Batch 20/97, Loss: 0.5967
Epoch 2/10, Batch 30/97, Loss: 0.3987
Epoch 2/10, Batch 40/97, Loss: 0.3529
Epoch 2/10, Batch 50/97, Loss: 0.5823
Epoch 2/10, Batch 60/97, Loss: 0.3816
Epoch 2/10, Batch 70/97, Loss: 0.2162
Epoch 2/10, Batch 80/97, Loss: 0.3204
Epoch 2/10, Batch 90/97, Loss: 0.3259
Epoch 2/10, Train Loss: 0.3999, Valid Loss: 0.3361
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3115
Epoch 3/10, Batch 20/97, Loss: 0.2970
Epoch 3/10, Batch 30/97, Loss: 0.2635
Epoch 3/10, Batch 40/97, Loss: 0.3248
Epoch 3/10, Batch 50/97, Loss: 0.2984
Epoch 3/10, Batch 60/97, Loss: 0.2291
Epoch 3/10, Batch 70/97, Loss: 0.2421
Epoch 3/10, Batch 80/97, Loss: 0.3142
Epoch 3/10, Batch 90/97, Loss: 0.2915
Epoch 3/10, Train Loss: 0.3233, Valid Loss: 0.2981
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1785
Epoch 4/10, Batch 20/97, Loss: 0.4289
Epoch 4/10, Batch 30/97, Loss: 0.3757
Epoch 4/10, Batch 40/97, Loss: 0.3637
Epoch 4/10, Batch 50/97, Loss: 0.2267
Epoch 4/10, Batch 60/97, Loss: 0.2186
Epoch 4/10, Batch 70/97, Loss: 0.3234
Epoch 4/10, Batch 80/97, Loss: 0.2162
Epoch 4/10, Batch 90/97, Loss: 0.2543
Epoch 4/10, Train Loss: 0.2913, Valid Loss: 0.2739
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2140
Epoch 5/10, Batch 20/97, Loss: 0.1213
Epoch 5/10, Batch 30/97, Loss: 0.1285
Epoch 5/10, Batch 40/97, Loss: 0.2508
Epoch 5/10, Batch 50/97, Loss: 0.2184
Epoch 5/10, Batch 60/97, Loss: 0.1807
Epoch 5/10, Batch 70/97, Loss: 0.2100
Epoch 5/10, Batch 80/97, Loss: 0.2857
Epoch 5/10, Batch 90/97, Loss: 0.2652
Epoch 5/10, Train Loss: 0.2589, Valid Loss: 0.2666
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1424
Epoch 6/10, Batch 20/97, Loss: 0.2352
Epoch 6/10, Batch 30/97, Loss: 0.0827
Epoch 6/10, Batch 40/97, Loss: 0.2780
Epoch 6/10, Batch 50/97, Loss: 0.2151
Epoch 6/10, Batch 60/97, Loss: 0.2047
Epoch 6/10, Batch 70/97, Loss: 0.2250
Epoch 6/10, Batch 80/97, Loss: 0.1519
Epoch 6/10, Batch 90/97, Loss: 0.2301
Epoch 6/10, Train Loss: 0.2391, Valid Loss: 0.2505
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3186
Epoch 7/10, Batch 20/97, Loss: 0.1476
Epoch 7/10, Batch 30/97, Loss: 0.1508
Epoch 7/10, Batch 40/97, Loss: 0.1204
Epoch 7/10, Batch 50/97, Loss: 0.2295
Epoch 7/10, Batch 60/97, Loss: 0.2705
Epoch 7/10, Batch 70/97, Loss: 0.0850
Epoch 7/10, Batch 80/97, Loss: 0.2698
Epoch 7/10, Batch 90/97, Loss: 0.3010
Epoch 7/10, Train Loss: 0.2373, Valid Loss: 0.2385
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1161
Epoch 8/10, Batch 20/97, Loss: 0.2727
Epoch 8/10, Batch 30/97, Loss: 0.2091
Epoch 8/10, Batch 40/97, Loss: 0.1255
Epoch 8/10, Batch 50/97, Loss: 0.2360
Epoch 8/10, Batch 60/97, Loss: 0.2818
Epoch 8/10, Batch 70/97, Loss: 0.3496
Epoch 8/10, Batch 80/97, Loss: 0.0803
Epoch 8/10, Batch 90/97, Loss: 0.1907
Epoch 8/10, Train Loss: 0.2194, Valid Loss: 0.2354
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1851
Epoch 9/10, Batch 20/97, Loss: 0.0686
Epoch 9/10, Batch 30/97, Loss: 0.3354
Epoch 9/10, Batch 40/97, Loss: 0.1320
Epoch 9/10, Batch 50/97, Loss: 0.3000
Epoch 9/10, Batch 60/97, Loss: 0.2531
Epoch 9/10, Batch 70/97, Loss: 0.1576
Epoch 9/10, Batch 80/97, Loss: 0.2481
Epoch 9/10, Batch 90/97, Loss: 0.1662
Epoch 9/10, Train Loss: 0.2090, Valid Loss: 0.2363
Epoch 10/10, Batch 10/97, Loss: 0.3623
Epoch 10/10, Batch 20/97, Loss: 0.2020
Epoch 10/10, Batch 30/97, Loss: 0.1925
Epoch 10/10, Batch 40/97, Loss: 0.2423
Epoch 10/10, Batch 50/97, Loss: 0.2427
Epoch 10/10, Batch 60/97, Loss: 0.1825
Epoch 10/10, Batch 70/97, Loss: 0.2371
Epoch 10/10, Batch 80/97, Loss: 0.1243
Epoch 10/10, Batch 90/97, Loss: 0.1003
Epoch 10/10, Train Loss: 0.1928, Valid Loss: 0.2319
Model saved!
Accuracy: 0.9147
Precision: 0.9115
Recall: 0.9147
F1-score: 0.9125
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5806
Epoch 1/10, Batch 20/97, Loss: 1.0303
Epoch 1/10, Batch 30/97, Loss: 0.8439
Epoch 1/10, Batch 40/97, Loss: 0.8323
Epoch 1/10, Batch 50/97, Loss: 0.6607
Epoch 1/10, Batch 60/97, Loss: 0.5016
Epoch 1/10, Batch 70/97, Loss: 0.5316
Epoch 1/10, Batch 80/97, Loss: 0.4617
Epoch 1/10, Batch 90/97, Loss: 0.5008
Epoch 1/10, Train Loss: 0.7670, Valid Loss: 0.4264
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3670
Epoch 2/10, Batch 20/97, Loss: 0.4734
Epoch 2/10, Batch 30/97, Loss: 0.4244
Epoch 2/10, Batch 40/97, Loss: 0.5721
Epoch 2/10, Batch 50/97, Loss: 0.5372
Epoch 2/10, Batch 60/97, Loss: 0.3713
Epoch 2/10, Batch 70/97, Loss: 0.3125
Epoch 2/10, Batch 80/97, Loss: 0.4596
Epoch 2/10, Batch 90/97, Loss: 0.2384
Epoch 2/10, Train Loss: 0.3892, Valid Loss: 0.3173
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2547
Epoch 3/10, Batch 20/97, Loss: 0.2839
Epoch 3/10, Batch 30/97, Loss: 0.2428
Epoch 3/10, Batch 40/97, Loss: 0.3926
Epoch 3/10, Batch 50/97, Loss: 0.3515
Epoch 3/10, Batch 60/97, Loss: 0.2876
Epoch 3/10, Batch 70/97, Loss: 0.2180
Epoch 3/10, Batch 80/97, Loss: 0.3326
Epoch 3/10, Batch 90/97, Loss: 0.2974
Epoch 3/10, Train Loss: 0.3128, Valid Loss: 0.2756
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3212
Epoch 4/10, Batch 20/97, Loss: 0.2964
Epoch 4/10, Batch 30/97, Loss: 0.4670
Epoch 4/10, Batch 40/97, Loss: 0.4177
Epoch 4/10, Batch 50/97, Loss: 0.2874
Epoch 4/10, Batch 60/97, Loss: 0.1741
Epoch 4/10, Batch 70/97, Loss: 0.2185
Epoch 4/10, Batch 80/97, Loss: 0.3189
Epoch 4/10, Batch 90/97, Loss: 0.1838
Epoch 4/10, Train Loss: 0.2802, Valid Loss: 0.2527
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2012
Epoch 5/10, Batch 20/97, Loss: 0.2427
Epoch 5/10, Batch 30/97, Loss: 0.2294
Epoch 5/10, Batch 40/97, Loss: 0.1497
Epoch 5/10, Batch 50/97, Loss: 0.1853
Epoch 5/10, Batch 60/97, Loss: 0.3043
Epoch 5/10, Batch 70/97, Loss: 0.1922
Epoch 5/10, Batch 80/97, Loss: 0.1590
Epoch 5/10, Batch 90/97, Loss: 0.3604
Epoch 5/10, Train Loss: 0.2511, Valid Loss: 0.2410
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1094
Epoch 6/10, Batch 20/97, Loss: 0.2012
Epoch 6/10, Batch 30/97, Loss: 0.1098
Epoch 6/10, Batch 40/97, Loss: 0.1766
Epoch 6/10, Batch 50/97, Loss: 0.1686
Epoch 6/10, Batch 60/97, Loss: 0.2186
Epoch 6/10, Batch 70/97, Loss: 0.4241
Epoch 6/10, Batch 80/97, Loss: 0.1610
Epoch 6/10, Batch 90/97, Loss: 0.1166
Epoch 6/10, Train Loss: 0.2281, Valid Loss: 0.2357
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3855
Epoch 7/10, Batch 20/97, Loss: 0.1814
Epoch 7/10, Batch 30/97, Loss: 0.2273
Epoch 7/10, Batch 40/97, Loss: 0.2055
Epoch 7/10, Batch 50/97, Loss: 0.3169
Epoch 7/10, Batch 60/97, Loss: 0.5124
Epoch 7/10, Batch 70/97, Loss: 0.1987
Epoch 7/10, Batch 80/97, Loss: 0.1688
Epoch 7/10, Batch 90/97, Loss: 0.2275
Epoch 7/10, Train Loss: 0.2323, Valid Loss: 0.2166
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2133
Epoch 8/10, Batch 20/97, Loss: 0.1662
Epoch 8/10, Batch 30/97, Loss: 0.1326
Epoch 8/10, Batch 40/97, Loss: 0.1814
Epoch 8/10, Batch 50/97, Loss: 0.2074
Epoch 8/10, Batch 60/97, Loss: 0.1611
Epoch 8/10, Batch 70/97, Loss: 0.2294
Epoch 8/10, Batch 80/97, Loss: 0.1317
Epoch 8/10, Batch 90/97, Loss: 0.1058
Epoch 8/10, Train Loss: 0.2190, Valid Loss: 0.2221
Epoch 9/10, Batch 10/97, Loss: 0.1833
Epoch 9/10, Batch 20/97, Loss: 0.0958
Epoch 9/10, Batch 30/97, Loss: 0.3437
Epoch 9/10, Batch 40/97, Loss: 0.1492
Epoch 9/10, Batch 50/97, Loss: 0.2376
Epoch 9/10, Batch 60/97, Loss: 0.1432
Epoch 9/10, Batch 70/97, Loss: 0.1824
Epoch 9/10, Batch 80/97, Loss: 0.1977
Epoch 9/10, Batch 90/97, Loss: 0.1376
Epoch 9/10, Train Loss: 0.2011, Valid Loss: 0.2262
Epoch 10/10, Batch 10/97, Loss: 0.3403
Epoch 10/10, Batch 20/97, Loss: 0.2335
Epoch 10/10, Batch 30/97, Loss: 0.2273
Epoch 10/10, Batch 40/97, Loss: 0.2694
Epoch 10/10, Batch 50/97, Loss: 0.1174
Epoch 10/10, Batch 60/97, Loss: 0.1483
Epoch 10/10, Batch 70/97, Loss: 0.1213
Epoch 10/10, Batch 80/97, Loss: 0.1170
Epoch 10/10, Batch 90/97, Loss: 0.2175
Epoch 10/10, Train Loss: 0.1926, Valid Loss: 0.2096
Model saved!
Accuracy: 0.9100
Precision: 0.9067
Recall: 0.9100
F1-score: 0.9077
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5191
Epoch 1/10, Batch 20/97, Loss: 1.0584
Epoch 1/10, Batch 30/97, Loss: 0.9221
Epoch 1/10, Batch 40/97, Loss: 0.7273
Epoch 1/10, Batch 50/97, Loss: 0.7010
Epoch 1/10, Batch 60/97, Loss: 0.5690
Epoch 1/10, Batch 70/97, Loss: 0.6410
Epoch 1/10, Batch 80/97, Loss: 0.4483
Epoch 1/10, Batch 90/97, Loss: 0.5344
Epoch 1/10, Train Loss: 0.7813, Valid Loss: 0.4528
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4777
Epoch 2/10, Batch 20/97, Loss: 0.4274
Epoch 2/10, Batch 30/97, Loss: 0.4838
Epoch 2/10, Batch 40/97, Loss: 0.4217
Epoch 2/10, Batch 50/97, Loss: 0.8135
Epoch 2/10, Batch 60/97, Loss: 0.3443
Epoch 2/10, Batch 70/97, Loss: 0.3231
Epoch 2/10, Batch 80/97, Loss: 0.4162
Epoch 2/10, Batch 90/97, Loss: 0.3491
Epoch 2/10, Train Loss: 0.4010, Valid Loss: 0.3360
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3052
Epoch 3/10, Batch 20/97, Loss: 0.2077
Epoch 3/10, Batch 30/97, Loss: 0.2566
Epoch 3/10, Batch 40/97, Loss: 0.4537
Epoch 3/10, Batch 50/97, Loss: 0.3258
Epoch 3/10, Batch 60/97, Loss: 0.3409
Epoch 3/10, Batch 70/97, Loss: 0.2071
Epoch 3/10, Batch 80/97, Loss: 0.2951
Epoch 3/10, Batch 90/97, Loss: 0.2657
Epoch 3/10, Train Loss: 0.3267, Valid Loss: 0.2890
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1789
Epoch 4/10, Batch 20/97, Loss: 0.3728
Epoch 4/10, Batch 30/97, Loss: 0.3449
Epoch 4/10, Batch 40/97, Loss: 0.3165
Epoch 4/10, Batch 50/97, Loss: 0.1977
Epoch 4/10, Batch 60/97, Loss: 0.2258
Epoch 4/10, Batch 70/97, Loss: 0.3675
Epoch 4/10, Batch 80/97, Loss: 0.1820
Epoch 4/10, Batch 90/97, Loss: 0.2846
Epoch 4/10, Train Loss: 0.2892, Valid Loss: 0.2670
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2003
Epoch 5/10, Batch 20/97, Loss: 0.2391
Epoch 5/10, Batch 30/97, Loss: 0.1988
Epoch 5/10, Batch 40/97, Loss: 0.2672
Epoch 5/10, Batch 50/97, Loss: 0.2154
Epoch 5/10, Batch 60/97, Loss: 0.2656
Epoch 5/10, Batch 70/97, Loss: 0.2739
Epoch 5/10, Batch 80/97, Loss: 0.3835
Epoch 5/10, Batch 90/97, Loss: 0.3301
Epoch 5/10, Train Loss: 0.2656, Valid Loss: 0.2438
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1457
Epoch 6/10, Batch 20/97, Loss: 0.2955
Epoch 6/10, Batch 30/97, Loss: 0.1361
Epoch 6/10, Batch 40/97, Loss: 0.2162
Epoch 6/10, Batch 50/97, Loss: 0.1648
Epoch 6/10, Batch 60/97, Loss: 0.2481
Epoch 6/10, Batch 70/97, Loss: 0.2964
Epoch 6/10, Batch 80/97, Loss: 0.1072
Epoch 6/10, Batch 90/97, Loss: 0.3446
Epoch 6/10, Train Loss: 0.2443, Valid Loss: 0.2342
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2339
Epoch 7/10, Batch 20/97, Loss: 0.1849
Epoch 7/10, Batch 30/97, Loss: 0.1276
Epoch 7/10, Batch 40/97, Loss: 0.1783
Epoch 7/10, Batch 50/97, Loss: 0.1955
Epoch 7/10, Batch 60/97, Loss: 0.2847
Epoch 7/10, Batch 70/97, Loss: 0.1486
Epoch 7/10, Batch 80/97, Loss: 0.2335
Epoch 7/10, Batch 90/97, Loss: 0.2364
Epoch 7/10, Train Loss: 0.2437, Valid Loss: 0.2274
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1415
Epoch 8/10, Batch 20/97, Loss: 0.3042
Epoch 8/10, Batch 30/97, Loss: 0.4713
Epoch 8/10, Batch 40/97, Loss: 0.2997
Epoch 8/10, Batch 50/97, Loss: 0.2056
Epoch 8/10, Batch 60/97, Loss: 0.1862
Epoch 8/10, Batch 70/97, Loss: 0.4629
Epoch 8/10, Batch 80/97, Loss: 0.0822
Epoch 8/10, Batch 90/97, Loss: 0.2093
Epoch 8/10, Train Loss: 0.2344, Valid Loss: 0.2259
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1092
Epoch 9/10, Batch 20/97, Loss: 0.1420
Epoch 9/10, Batch 30/97, Loss: 0.2755
Epoch 9/10, Batch 40/97, Loss: 0.1499
Epoch 9/10, Batch 50/97, Loss: 0.2942
Epoch 9/10, Batch 60/97, Loss: 0.2285
Epoch 9/10, Batch 70/97, Loss: 0.3506
Epoch 9/10, Batch 80/97, Loss: 0.1956
Epoch 9/10, Batch 90/97, Loss: 0.1844
Epoch 9/10, Train Loss: 0.2204, Valid Loss: 0.2215
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3084
Epoch 10/10, Batch 20/97, Loss: 0.2131
Epoch 10/10, Batch 30/97, Loss: 0.2347
Epoch 10/10, Batch 40/97, Loss: 0.2716
Epoch 10/10, Batch 50/97, Loss: 0.2586
Epoch 10/10, Batch 60/97, Loss: 0.1378
Epoch 10/10, Batch 70/97, Loss: 0.1908
Epoch 10/10, Batch 80/97, Loss: 0.2107
Epoch 10/10, Batch 90/97, Loss: 0.1903
Epoch 10/10, Train Loss: 0.2033, Valid Loss: 0.2124
Model saved!
Accuracy: 0.9206
Precision: 0.9188
Recall: 0.9206
F1-score: 0.9195
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4581
Epoch 1/10, Batch 20/97, Loss: 0.9741
Epoch 1/10, Batch 30/97, Loss: 0.8690
Epoch 1/10, Batch 40/97, Loss: 0.6529
Epoch 1/10, Batch 50/97, Loss: 0.6432
Epoch 1/10, Batch 60/97, Loss: 0.6661
Epoch 1/10, Batch 70/97, Loss: 0.5734
Epoch 1/10, Batch 80/97, Loss: 0.5072
Epoch 1/10, Batch 90/97, Loss: 0.5775
Epoch 1/10, Train Loss: 0.7793, Valid Loss: 0.4285
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3250
Epoch 2/10, Batch 20/97, Loss: 0.4566
Epoch 2/10, Batch 30/97, Loss: 0.4094
Epoch 2/10, Batch 40/97, Loss: 0.5347
Epoch 2/10, Batch 50/97, Loss: 0.5661
Epoch 2/10, Batch 60/97, Loss: 0.3511
Epoch 2/10, Batch 70/97, Loss: 0.3080
Epoch 2/10, Batch 80/97, Loss: 0.3715
Epoch 2/10, Batch 90/97, Loss: 0.2939
Epoch 2/10, Train Loss: 0.4028, Valid Loss: 0.3285
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4154
Epoch 3/10, Batch 20/97, Loss: 0.3363
Epoch 3/10, Batch 30/97, Loss: 0.2835
Epoch 3/10, Batch 40/97, Loss: 0.3450
Epoch 3/10, Batch 50/97, Loss: 0.2713
Epoch 3/10, Batch 60/97, Loss: 0.2397
Epoch 3/10, Batch 70/97, Loss: 0.1553
Epoch 3/10, Batch 80/97, Loss: 0.2886
Epoch 3/10, Batch 90/97, Loss: 0.3170
Epoch 3/10, Train Loss: 0.3267, Valid Loss: 0.2840
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3688
Epoch 4/10, Batch 20/97, Loss: 0.2454
Epoch 4/10, Batch 30/97, Loss: 0.4100
Epoch 4/10, Batch 40/97, Loss: 0.1800
Epoch 4/10, Batch 50/97, Loss: 0.1851
Epoch 4/10, Batch 60/97, Loss: 0.1027
Epoch 4/10, Batch 70/97, Loss: 0.3249
Epoch 4/10, Batch 80/97, Loss: 0.2328
Epoch 4/10, Batch 90/97, Loss: 0.3964
Epoch 4/10, Train Loss: 0.2893, Valid Loss: 0.2600
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2080
Epoch 5/10, Batch 20/97, Loss: 0.3096
Epoch 5/10, Batch 30/97, Loss: 0.2141
Epoch 5/10, Batch 40/97, Loss: 0.1424
Epoch 5/10, Batch 50/97, Loss: 0.2281
Epoch 5/10, Batch 60/97, Loss: 0.2110
Epoch 5/10, Batch 70/97, Loss: 0.2740
Epoch 5/10, Batch 80/97, Loss: 0.2287
Epoch 5/10, Batch 90/97, Loss: 0.3186
Epoch 5/10, Train Loss: 0.2685, Valid Loss: 0.2481
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1980
Epoch 6/10, Batch 20/97, Loss: 0.3321
Epoch 6/10, Batch 30/97, Loss: 0.2279
Epoch 6/10, Batch 40/97, Loss: 0.2629
Epoch 6/10, Batch 50/97, Loss: 0.2342
Epoch 6/10, Batch 60/97, Loss: 0.3812
Epoch 6/10, Batch 70/97, Loss: 0.1960
Epoch 6/10, Batch 80/97, Loss: 0.2458
Epoch 6/10, Batch 90/97, Loss: 0.2759
Epoch 6/10, Train Loss: 0.2480, Valid Loss: 0.2490
Epoch 7/10, Batch 10/97, Loss: 0.1700
Epoch 7/10, Batch 20/97, Loss: 0.1764
Epoch 7/10, Batch 30/97, Loss: 0.1861
Epoch 7/10, Batch 40/97, Loss: 0.2403
Epoch 7/10, Batch 50/97, Loss: 0.2351
Epoch 7/10, Batch 60/97, Loss: 0.1977
Epoch 7/10, Batch 70/97, Loss: 0.3888
Epoch 7/10, Batch 80/97, Loss: 0.2786
Epoch 7/10, Batch 90/97, Loss: 0.2328
Epoch 7/10, Train Loss: 0.2487, Valid Loss: 0.2349
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2339
Epoch 8/10, Batch 20/97, Loss: 0.1820
Epoch 8/10, Batch 30/97, Loss: 0.1259
Epoch 8/10, Batch 40/97, Loss: 0.3332
Epoch 8/10, Batch 50/97, Loss: 0.2235
Epoch 8/10, Batch 60/97, Loss: 0.1088
Epoch 8/10, Batch 70/97, Loss: 0.2014
Epoch 8/10, Batch 80/97, Loss: 0.1347
Epoch 8/10, Batch 90/97, Loss: 0.2042
Epoch 8/10, Train Loss: 0.2272, Valid Loss: 0.2395
Epoch 9/10, Batch 10/97, Loss: 0.1482
Epoch 9/10, Batch 20/97, Loss: 0.2544
Epoch 9/10, Batch 30/97, Loss: 0.3208
Epoch 9/10, Batch 40/97, Loss: 0.1958
Epoch 9/10, Batch 50/97, Loss: 0.2432
Epoch 9/10, Batch 60/97, Loss: 0.1149
Epoch 9/10, Batch 70/97, Loss: 0.1899
Epoch 9/10, Batch 80/97, Loss: 0.0966
Epoch 9/10, Batch 90/97, Loss: 0.1798
Epoch 9/10, Train Loss: 0.2058, Valid Loss: 0.2305
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.4001
Epoch 10/10, Batch 20/97, Loss: 0.1291
Epoch 10/10, Batch 30/97, Loss: 0.1748
Epoch 10/10, Batch 40/97, Loss: 0.0871
Epoch 10/10, Batch 50/97, Loss: 0.2279
Epoch 10/10, Batch 60/97, Loss: 0.1797
Epoch 10/10, Batch 70/97, Loss: 0.1346
Epoch 10/10, Batch 80/97, Loss: 0.1708
Epoch 10/10, Batch 90/97, Loss: 0.1886
Epoch 10/10, Train Loss: 0.1953, Valid Loss: 0.2223
Model saved!
Accuracy: 0.9147
Precision: 0.9122
Recall: 0.9147
F1-score: 0.9127
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4658
Epoch 1/10, Batch 20/97, Loss: 1.0231
Epoch 1/10, Batch 30/97, Loss: 0.8277
Epoch 1/10, Batch 40/97, Loss: 0.7229
Epoch 1/10, Batch 50/97, Loss: 0.6135
Epoch 1/10, Batch 60/97, Loss: 0.7237
Epoch 1/10, Batch 70/97, Loss: 0.4956
Epoch 1/10, Batch 80/97, Loss: 0.5262
Epoch 1/10, Batch 90/97, Loss: 0.6308
Epoch 1/10, Train Loss: 0.7735, Valid Loss: 0.4312
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3312
Epoch 2/10, Batch 20/97, Loss: 0.5727
Epoch 2/10, Batch 30/97, Loss: 0.4866
Epoch 2/10, Batch 40/97, Loss: 0.4893
Epoch 2/10, Batch 50/97, Loss: 0.4964
Epoch 2/10, Batch 60/97, Loss: 0.3741
Epoch 2/10, Batch 70/97, Loss: 0.4454
Epoch 2/10, Batch 80/97, Loss: 0.3037
Epoch 2/10, Batch 90/97, Loss: 0.2399
Epoch 2/10, Train Loss: 0.3902, Valid Loss: 0.3318
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3240
Epoch 3/10, Batch 20/97, Loss: 0.3830
Epoch 3/10, Batch 30/97, Loss: 0.2506
Epoch 3/10, Batch 40/97, Loss: 0.3088
Epoch 3/10, Batch 50/97, Loss: 0.5078
Epoch 3/10, Batch 60/97, Loss: 0.2348
Epoch 3/10, Batch 70/97, Loss: 0.1913
Epoch 3/10, Batch 80/97, Loss: 0.2396
Epoch 3/10, Batch 90/97, Loss: 0.3984
Epoch 3/10, Train Loss: 0.3162, Valid Loss: 0.2905
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2106
Epoch 4/10, Batch 20/97, Loss: 0.1416
Epoch 4/10, Batch 30/97, Loss: 0.3934
Epoch 4/10, Batch 40/97, Loss: 0.2183
Epoch 4/10, Batch 50/97, Loss: 0.2350
Epoch 4/10, Batch 60/97, Loss: 0.2257
Epoch 4/10, Batch 70/97, Loss: 0.2134
Epoch 4/10, Batch 80/97, Loss: 0.2489
Epoch 4/10, Batch 90/97, Loss: 0.1958
Epoch 4/10, Train Loss: 0.2788, Valid Loss: 0.2766
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2198
Epoch 5/10, Batch 20/97, Loss: 0.2503
Epoch 5/10, Batch 30/97, Loss: 0.1711
Epoch 5/10, Batch 40/97, Loss: 0.1346
Epoch 5/10, Batch 50/97, Loss: 0.2124
Epoch 5/10, Batch 60/97, Loss: 0.2212
Epoch 5/10, Batch 70/97, Loss: 0.3112
Epoch 5/10, Batch 80/97, Loss: 0.4449
Epoch 5/10, Batch 90/97, Loss: 0.3372
Epoch 5/10, Train Loss: 0.2497, Valid Loss: 0.2598
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1529
Epoch 6/10, Batch 20/97, Loss: 0.3467
Epoch 6/10, Batch 30/97, Loss: 0.1660
Epoch 6/10, Batch 40/97, Loss: 0.3224
Epoch 6/10, Batch 50/97, Loss: 0.1654
Epoch 6/10, Batch 60/97, Loss: 0.1983
Epoch 6/10, Batch 70/97, Loss: 0.2565
Epoch 6/10, Batch 80/97, Loss: 0.1634
Epoch 6/10, Batch 90/97, Loss: 0.1848
Epoch 6/10, Train Loss: 0.2390, Valid Loss: 0.2597
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3484
Epoch 7/10, Batch 20/97, Loss: 0.2064
Epoch 7/10, Batch 30/97, Loss: 0.2053
Epoch 7/10, Batch 40/97, Loss: 0.1491
Epoch 7/10, Batch 50/97, Loss: 0.1265
Epoch 7/10, Batch 60/97, Loss: 0.2960
Epoch 7/10, Batch 70/97, Loss: 0.1786
Epoch 7/10, Batch 80/97, Loss: 0.1132
Epoch 7/10, Batch 90/97, Loss: 0.2307
Epoch 7/10, Train Loss: 0.2401, Valid Loss: 0.2404
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1401
Epoch 8/10, Batch 20/97, Loss: 0.1455
Epoch 8/10, Batch 30/97, Loss: 0.1946
Epoch 8/10, Batch 40/97, Loss: 0.1146
Epoch 8/10, Batch 50/97, Loss: 0.1649
Epoch 8/10, Batch 60/97, Loss: 0.1534
Epoch 8/10, Batch 70/97, Loss: 0.2395
Epoch 8/10, Batch 80/97, Loss: 0.0767
Epoch 8/10, Batch 90/97, Loss: 0.1119
Epoch 8/10, Train Loss: 0.2081, Valid Loss: 0.2543
Epoch 9/10, Batch 10/97, Loss: 0.1535
Epoch 9/10, Batch 20/97, Loss: 0.0994
Epoch 9/10, Batch 30/97, Loss: 0.2234
Epoch 9/10, Batch 40/97, Loss: 0.1413
Epoch 9/10, Batch 50/97, Loss: 0.1679
Epoch 9/10, Batch 60/97, Loss: 0.2647
Epoch 9/10, Batch 70/97, Loss: 0.1485
Epoch 9/10, Batch 80/97, Loss: 0.1730
Epoch 9/10, Batch 90/97, Loss: 0.2645
Epoch 9/10, Train Loss: 0.1937, Valid Loss: 0.2463
Epoch 10/10, Batch 10/97, Loss: 0.2181
Epoch 10/10, Batch 20/97, Loss: 0.2533
Epoch 10/10, Batch 30/97, Loss: 0.1330
Epoch 10/10, Batch 40/97, Loss: 0.2392
Epoch 10/10, Batch 50/97, Loss: 0.2320
Epoch 10/10, Batch 60/97, Loss: 0.1798
Epoch 10/10, Batch 70/97, Loss: 0.1118
Epoch 10/10, Batch 80/97, Loss: 0.2586
Epoch 10/10, Batch 90/97, Loss: 0.2155
Epoch 10/10, Train Loss: 0.2005, Valid Loss: 0.2381
Model saved!
Accuracy: 0.9182
Precision: 0.9153
Recall: 0.9182
F1-score: 0.9163
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4587
Epoch 1/10, Batch 20/97, Loss: 0.9889
Epoch 1/10, Batch 30/97, Loss: 0.8238
Epoch 1/10, Batch 40/97, Loss: 0.8618
Epoch 1/10, Batch 50/97, Loss: 0.6589
Epoch 1/10, Batch 60/97, Loss: 0.6485
Epoch 1/10, Batch 70/97, Loss: 0.5788
Epoch 1/10, Batch 80/97, Loss: 0.4515
Epoch 1/10, Batch 90/97, Loss: 0.6401
Epoch 1/10, Train Loss: 0.7803, Valid Loss: 0.4482
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4009
Epoch 2/10, Batch 20/97, Loss: 0.5638
Epoch 2/10, Batch 30/97, Loss: 0.5650
Epoch 2/10, Batch 40/97, Loss: 0.3284
Epoch 2/10, Batch 50/97, Loss: 0.4960
Epoch 2/10, Batch 60/97, Loss: 0.3463
Epoch 2/10, Batch 70/97, Loss: 0.2583
Epoch 2/10, Batch 80/97, Loss: 0.3265
Epoch 2/10, Batch 90/97, Loss: 0.4636
Epoch 2/10, Train Loss: 0.4053, Valid Loss: 0.3417
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3286
Epoch 3/10, Batch 20/97, Loss: 0.2740
Epoch 3/10, Batch 30/97, Loss: 0.2084
Epoch 3/10, Batch 40/97, Loss: 0.2889
Epoch 3/10, Batch 50/97, Loss: 0.2990
Epoch 3/10, Batch 60/97, Loss: 0.3313
Epoch 3/10, Batch 70/97, Loss: 0.2385
Epoch 3/10, Batch 80/97, Loss: 0.3254
Epoch 3/10, Batch 90/97, Loss: 0.2394
Epoch 3/10, Train Loss: 0.3296, Valid Loss: 0.3004
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1779
Epoch 4/10, Batch 20/97, Loss: 0.2776
Epoch 4/10, Batch 30/97, Loss: 0.2974
Epoch 4/10, Batch 40/97, Loss: 0.2617
Epoch 4/10, Batch 50/97, Loss: 0.1315
Epoch 4/10, Batch 60/97, Loss: 0.1384
Epoch 4/10, Batch 70/97, Loss: 0.2040
Epoch 4/10, Batch 80/97, Loss: 0.1942
Epoch 4/10, Batch 90/97, Loss: 0.2577
Epoch 4/10, Train Loss: 0.2927, Valid Loss: 0.2867
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2541
Epoch 5/10, Batch 20/97, Loss: 0.1904
Epoch 5/10, Batch 30/97, Loss: 0.1822
Epoch 5/10, Batch 40/97, Loss: 0.3311
Epoch 5/10, Batch 50/97, Loss: 0.1273
Epoch 5/10, Batch 60/97, Loss: 0.1534
Epoch 5/10, Batch 70/97, Loss: 0.3179
Epoch 5/10, Batch 80/97, Loss: 0.2516
Epoch 5/10, Batch 90/97, Loss: 0.2757
Epoch 5/10, Train Loss: 0.2591, Valid Loss: 0.2783
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1746
Epoch 6/10, Batch 20/97, Loss: 0.1061
Epoch 6/10, Batch 30/97, Loss: 0.1547
Epoch 6/10, Batch 40/97, Loss: 0.3161
Epoch 6/10, Batch 50/97, Loss: 0.2178
Epoch 6/10, Batch 60/97, Loss: 0.2774
Epoch 6/10, Batch 70/97, Loss: 0.2137
Epoch 6/10, Batch 80/97, Loss: 0.2441
Epoch 6/10, Batch 90/97, Loss: 0.3506
Epoch 6/10, Train Loss: 0.2466, Valid Loss: 0.2651
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2824
Epoch 7/10, Batch 20/97, Loss: 0.0894
Epoch 7/10, Batch 30/97, Loss: 0.2597
Epoch 7/10, Batch 40/97, Loss: 0.1378
Epoch 7/10, Batch 50/97, Loss: 0.1593
Epoch 7/10, Batch 60/97, Loss: 0.1917
Epoch 7/10, Batch 70/97, Loss: 0.2342
Epoch 7/10, Batch 80/97, Loss: 0.2968
Epoch 7/10, Batch 90/97, Loss: 0.2527
Epoch 7/10, Train Loss: 0.2514, Valid Loss: 0.2608
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1110
Epoch 8/10, Batch 20/97, Loss: 0.1808
Epoch 8/10, Batch 30/97, Loss: 0.0988
Epoch 8/10, Batch 40/97, Loss: 0.1890
Epoch 8/10, Batch 50/97, Loss: 0.3018
Epoch 8/10, Batch 60/97, Loss: 0.2194
Epoch 8/10, Batch 70/97, Loss: 0.2470
Epoch 8/10, Batch 80/97, Loss: 0.1954
Epoch 8/10, Batch 90/97, Loss: 0.2406
Epoch 8/10, Train Loss: 0.2223, Valid Loss: 0.2544
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1546
Epoch 9/10, Batch 20/97, Loss: 0.2383
Epoch 9/10, Batch 30/97, Loss: 0.5562
Epoch 9/10, Batch 40/97, Loss: 0.1556
Epoch 9/10, Batch 50/97, Loss: 0.1879
Epoch 9/10, Batch 60/97, Loss: 0.0580
Epoch 9/10, Batch 70/97, Loss: 0.2279
Epoch 9/10, Batch 80/97, Loss: 0.1654
Epoch 9/10, Batch 90/97, Loss: 0.2650
Epoch 9/10, Train Loss: 0.2139, Valid Loss: 0.2494
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3005
Epoch 10/10, Batch 20/97, Loss: 0.1512
Epoch 10/10, Batch 30/97, Loss: 0.2478
Epoch 10/10, Batch 40/97, Loss: 0.2193
Epoch 10/10, Batch 50/97, Loss: 0.2041
Epoch 10/10, Batch 60/97, Loss: 0.0818
Epoch 10/10, Batch 70/97, Loss: 0.1047
Epoch 10/10, Batch 80/97, Loss: 0.1792
Epoch 10/10, Batch 90/97, Loss: 0.0869
Epoch 10/10, Train Loss: 0.2048, Valid Loss: 0.2431
Model saved!
Accuracy: 0.9159
Precision: 0.9136
Recall: 0.9159
F1-score: 0.9142
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4879
Epoch 1/10, Batch 20/97, Loss: 1.0351
Epoch 1/10, Batch 30/97, Loss: 0.8422
Epoch 1/10, Batch 40/97, Loss: 0.7153
Epoch 1/10, Batch 50/97, Loss: 0.5842
Epoch 1/10, Batch 60/97, Loss: 0.5781
Epoch 1/10, Batch 70/97, Loss: 0.5280
Epoch 1/10, Batch 80/97, Loss: 0.4620
Epoch 1/10, Batch 90/97, Loss: 0.4591
Epoch 1/10, Train Loss: 0.7857, Valid Loss: 0.4424
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4176
Epoch 2/10, Batch 20/97, Loss: 0.4575
Epoch 2/10, Batch 30/97, Loss: 0.5023
Epoch 2/10, Batch 40/97, Loss: 0.4676
Epoch 2/10, Batch 50/97, Loss: 0.4945
Epoch 2/10, Batch 60/97, Loss: 0.3175
Epoch 2/10, Batch 70/97, Loss: 0.3903
Epoch 2/10, Batch 80/97, Loss: 0.2747
Epoch 2/10, Batch 90/97, Loss: 0.3396
Epoch 2/10, Train Loss: 0.4097, Valid Loss: 0.3298
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3072
Epoch 3/10, Batch 20/97, Loss: 0.3888
Epoch 3/10, Batch 30/97, Loss: 0.3345
Epoch 3/10, Batch 40/97, Loss: 0.3418
Epoch 3/10, Batch 50/97, Loss: 0.2686
Epoch 3/10, Batch 60/97, Loss: 0.3903
Epoch 3/10, Batch 70/97, Loss: 0.2803
Epoch 3/10, Batch 80/97, Loss: 0.2374
Epoch 3/10, Batch 90/97, Loss: 0.2655
Epoch 3/10, Train Loss: 0.3341, Valid Loss: 0.2955
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2221
Epoch 4/10, Batch 20/97, Loss: 0.3444
Epoch 4/10, Batch 30/97, Loss: 0.3169
Epoch 4/10, Batch 40/97, Loss: 0.3708
Epoch 4/10, Batch 50/97, Loss: 0.2627
Epoch 4/10, Batch 60/97, Loss: 0.1490
Epoch 4/10, Batch 70/97, Loss: 0.2730
Epoch 4/10, Batch 80/97, Loss: 0.4296
Epoch 4/10, Batch 90/97, Loss: 0.1919
Epoch 4/10, Train Loss: 0.2903, Valid Loss: 0.2738
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3520
Epoch 5/10, Batch 20/97, Loss: 0.2759
Epoch 5/10, Batch 30/97, Loss: 0.2853
Epoch 5/10, Batch 40/97, Loss: 0.2608
Epoch 5/10, Batch 50/97, Loss: 0.3013
Epoch 5/10, Batch 60/97, Loss: 0.2188
Epoch 5/10, Batch 70/97, Loss: 0.2585
Epoch 5/10, Batch 80/97, Loss: 0.4194
Epoch 5/10, Batch 90/97, Loss: 0.7679
Epoch 5/10, Train Loss: 0.2734, Valid Loss: 0.2656
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2420
Epoch 6/10, Batch 20/97, Loss: 0.2199
Epoch 6/10, Batch 30/97, Loss: 0.2332
Epoch 6/10, Batch 40/97, Loss: 0.4108
Epoch 6/10, Batch 50/97, Loss: 0.2224
Epoch 6/10, Batch 60/97, Loss: 0.2355
Epoch 6/10, Batch 70/97, Loss: 0.1283
Epoch 6/10, Batch 80/97, Loss: 0.3160
Epoch 6/10, Batch 90/97, Loss: 0.1711
Epoch 6/10, Train Loss: 0.2508, Valid Loss: 0.2487
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3802
Epoch 7/10, Batch 20/97, Loss: 0.1159
Epoch 7/10, Batch 30/97, Loss: 0.2189
Epoch 7/10, Batch 40/97, Loss: 0.1454
Epoch 7/10, Batch 50/97, Loss: 0.2377
Epoch 7/10, Batch 60/97, Loss: 0.3495
Epoch 7/10, Batch 70/97, Loss: 0.1717
Epoch 7/10, Batch 80/97, Loss: 0.1862
Epoch 7/10, Batch 90/97, Loss: 0.3040
Epoch 7/10, Train Loss: 0.2590, Valid Loss: 0.2446
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.3014
Epoch 8/10, Batch 20/97, Loss: 0.1874
Epoch 8/10, Batch 30/97, Loss: 0.1545
Epoch 8/10, Batch 40/97, Loss: 0.1438
Epoch 8/10, Batch 50/97, Loss: 0.3136
Epoch 8/10, Batch 60/97, Loss: 0.1099
Epoch 8/10, Batch 70/97, Loss: 0.4167
Epoch 8/10, Batch 80/97, Loss: 0.2268
Epoch 8/10, Batch 90/97, Loss: 0.1913
Epoch 8/10, Train Loss: 0.2255, Valid Loss: 0.2334
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2220
Epoch 9/10, Batch 20/97, Loss: 0.1878
Epoch 9/10, Batch 30/97, Loss: 0.3252
Epoch 9/10, Batch 40/97, Loss: 0.1016
Epoch 9/10, Batch 50/97, Loss: 0.3161
Epoch 9/10, Batch 60/97, Loss: 0.1820
Epoch 9/10, Batch 70/97, Loss: 0.1978
Epoch 9/10, Batch 80/97, Loss: 0.0840
Epoch 9/10, Batch 90/97, Loss: 0.5489
Epoch 9/10, Train Loss: 0.2208, Valid Loss: 0.2283
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1104
Epoch 10/10, Batch 20/97, Loss: 0.2358
Epoch 10/10, Batch 30/97, Loss: 0.1992
Epoch 10/10, Batch 40/97, Loss: 0.1282
Epoch 10/10, Batch 50/97, Loss: 0.1871
Epoch 10/10, Batch 60/97, Loss: 0.1524
Epoch 10/10, Batch 70/97, Loss: 0.3430
Epoch 10/10, Batch 80/97, Loss: 0.1429
Epoch 10/10, Batch 90/97, Loss: 0.1972
Epoch 10/10, Train Loss: 0.2056, Valid Loss: 0.2186
Model saved!
Accuracy: 0.9159
Precision: 0.9131
Recall: 0.9159
F1-score: 0.9137
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5058
Epoch 1/10, Batch 20/97, Loss: 0.9918
Epoch 1/10, Batch 30/97, Loss: 0.9524
Epoch 1/10, Batch 40/97, Loss: 0.7674
Epoch 1/10, Batch 50/97, Loss: 0.6617
Epoch 1/10, Batch 60/97, Loss: 0.7049
Epoch 1/10, Batch 70/97, Loss: 0.5042
Epoch 1/10, Batch 80/97, Loss: 0.4257
Epoch 1/10, Batch 90/97, Loss: 0.4750
Epoch 1/10, Train Loss: 0.7821, Valid Loss: 0.4248
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4293
Epoch 2/10, Batch 20/97, Loss: 0.6056
Epoch 2/10, Batch 30/97, Loss: 0.4957
Epoch 2/10, Batch 40/97, Loss: 0.4221
Epoch 2/10, Batch 50/97, Loss: 0.5407
Epoch 2/10, Batch 60/97, Loss: 0.3763
Epoch 2/10, Batch 70/97, Loss: 0.3252
Epoch 2/10, Batch 80/97, Loss: 0.3489
Epoch 2/10, Batch 90/97, Loss: 0.2496
Epoch 2/10, Train Loss: 0.3959, Valid Loss: 0.3144
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3936
Epoch 3/10, Batch 20/97, Loss: 0.3382
Epoch 3/10, Batch 30/97, Loss: 0.2272
Epoch 3/10, Batch 40/97, Loss: 0.3470
Epoch 3/10, Batch 50/97, Loss: 0.2638
Epoch 3/10, Batch 60/97, Loss: 0.3250
Epoch 3/10, Batch 70/97, Loss: 0.1038
Epoch 3/10, Batch 80/97, Loss: 0.4434
Epoch 3/10, Batch 90/97, Loss: 0.4189
Epoch 3/10, Train Loss: 0.3219, Valid Loss: 0.2807
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2829
Epoch 4/10, Batch 20/97, Loss: 0.4828
Epoch 4/10, Batch 30/97, Loss: 0.2453
Epoch 4/10, Batch 40/97, Loss: 0.3268
Epoch 4/10, Batch 50/97, Loss: 0.2130
Epoch 4/10, Batch 60/97, Loss: 0.1714
Epoch 4/10, Batch 70/97, Loss: 0.2769
Epoch 4/10, Batch 80/97, Loss: 0.2293
Epoch 4/10, Batch 90/97, Loss: 0.1975
Epoch 4/10, Train Loss: 0.2854, Valid Loss: 0.2528
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1877
Epoch 5/10, Batch 20/97, Loss: 0.2037
Epoch 5/10, Batch 30/97, Loss: 0.2126
Epoch 5/10, Batch 40/97, Loss: 0.2073
Epoch 5/10, Batch 50/97, Loss: 0.2014
Epoch 5/10, Batch 60/97, Loss: 0.2398
Epoch 5/10, Batch 70/97, Loss: 0.3092
Epoch 5/10, Batch 80/97, Loss: 0.2224
Epoch 5/10, Batch 90/97, Loss: 0.2854
Epoch 5/10, Train Loss: 0.2606, Valid Loss: 0.2443
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1280
Epoch 6/10, Batch 20/97, Loss: 0.1859
Epoch 6/10, Batch 30/97, Loss: 0.1887
Epoch 6/10, Batch 40/97, Loss: 0.2914
Epoch 6/10, Batch 50/97, Loss: 0.3049
Epoch 6/10, Batch 60/97, Loss: 0.2724
Epoch 6/10, Batch 70/97, Loss: 0.2433
Epoch 6/10, Batch 80/97, Loss: 0.1809
Epoch 6/10, Batch 90/97, Loss: 0.2831
Epoch 6/10, Train Loss: 0.2368, Valid Loss: 0.2336
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3275
Epoch 7/10, Batch 20/97, Loss: 0.1321
Epoch 7/10, Batch 30/97, Loss: 0.2424
Epoch 7/10, Batch 40/97, Loss: 0.1586
Epoch 7/10, Batch 50/97, Loss: 0.1810
Epoch 7/10, Batch 60/97, Loss: 0.2155
Epoch 7/10, Batch 70/97, Loss: 0.2096
Epoch 7/10, Batch 80/97, Loss: 0.2590
Epoch 7/10, Batch 90/97, Loss: 0.2737
Epoch 7/10, Train Loss: 0.2401, Valid Loss: 0.2247
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1953
Epoch 8/10, Batch 20/97, Loss: 0.1652
Epoch 8/10, Batch 30/97, Loss: 0.1887
Epoch 8/10, Batch 40/97, Loss: 0.1483
Epoch 8/10, Batch 50/97, Loss: 0.1595
Epoch 8/10, Batch 60/97, Loss: 0.0961
Epoch 8/10, Batch 70/97, Loss: 0.3158
Epoch 8/10, Batch 80/97, Loss: 0.1265
Epoch 8/10, Batch 90/97, Loss: 0.1789
Epoch 8/10, Train Loss: 0.2225, Valid Loss: 0.2121
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0986
Epoch 9/10, Batch 20/97, Loss: 0.1976
Epoch 9/10, Batch 30/97, Loss: 0.3670
Epoch 9/10, Batch 40/97, Loss: 0.1042
Epoch 9/10, Batch 50/97, Loss: 0.1618
Epoch 9/10, Batch 60/97, Loss: 0.2038
Epoch 9/10, Batch 70/97, Loss: 0.2645
Epoch 9/10, Batch 80/97, Loss: 0.1883
Epoch 9/10, Batch 90/97, Loss: 0.1758
Epoch 9/10, Train Loss: 0.2048, Valid Loss: 0.2180
Epoch 10/10, Batch 10/97, Loss: 0.1820
Epoch 10/10, Batch 20/97, Loss: 0.1771
Epoch 10/10, Batch 30/97, Loss: 0.2299
Epoch 10/10, Batch 40/97, Loss: 0.1978
Epoch 10/10, Batch 50/97, Loss: 0.2364
Epoch 10/10, Batch 60/97, Loss: 0.1052
Epoch 10/10, Batch 70/97, Loss: 0.2160
Epoch 10/10, Batch 80/97, Loss: 0.1154
Epoch 10/10, Batch 90/97, Loss: 0.1668
Epoch 10/10, Train Loss: 0.1922, Valid Loss: 0.2133
Accuracy: 0.9159
Precision: 0.9132
Recall: 0.9159
F1-score: 0.9137
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4302
Epoch 1/10, Batch 20/97, Loss: 0.9849
Epoch 1/10, Batch 30/97, Loss: 0.9310
Epoch 1/10, Batch 40/97, Loss: 0.6453
Epoch 1/10, Batch 50/97, Loss: 0.5421
Epoch 1/10, Batch 60/97, Loss: 0.5629
Epoch 1/10, Batch 70/97, Loss: 0.4261
Epoch 1/10, Batch 80/97, Loss: 0.5473
Epoch 1/10, Batch 90/97, Loss: 0.5113
Epoch 1/10, Train Loss: 0.7698, Valid Loss: 0.4196
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4995
Epoch 2/10, Batch 20/97, Loss: 0.4243
Epoch 2/10, Batch 30/97, Loss: 0.4137
Epoch 2/10, Batch 40/97, Loss: 0.4326
Epoch 2/10, Batch 50/97, Loss: 0.5018
Epoch 2/10, Batch 60/97, Loss: 0.2740
Epoch 2/10, Batch 70/97, Loss: 0.1981
Epoch 2/10, Batch 80/97, Loss: 0.3524
Epoch 2/10, Batch 90/97, Loss: 0.3235
Epoch 2/10, Train Loss: 0.3888, Valid Loss: 0.3158
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3308
Epoch 3/10, Batch 20/97, Loss: 0.3341
Epoch 3/10, Batch 30/97, Loss: 0.3271
Epoch 3/10, Batch 40/97, Loss: 0.2736
Epoch 3/10, Batch 50/97, Loss: 0.1964
Epoch 3/10, Batch 60/97, Loss: 0.1985
Epoch 3/10, Batch 70/97, Loss: 0.2795
Epoch 3/10, Batch 80/97, Loss: 0.2736
Epoch 3/10, Batch 90/97, Loss: 0.2651
Epoch 3/10, Train Loss: 0.3203, Valid Loss: 0.2827
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2519
Epoch 4/10, Batch 20/97, Loss: 0.2008
Epoch 4/10, Batch 30/97, Loss: 0.4133
Epoch 4/10, Batch 40/97, Loss: 0.4703
Epoch 4/10, Batch 50/97, Loss: 0.2123
Epoch 4/10, Batch 60/97, Loss: 0.1763
Epoch 4/10, Batch 70/97, Loss: 0.3211
Epoch 4/10, Batch 80/97, Loss: 0.1897
Epoch 4/10, Batch 90/97, Loss: 0.2776
Epoch 4/10, Train Loss: 0.2807, Valid Loss: 0.2620
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2993
Epoch 5/10, Batch 20/97, Loss: 0.1968
Epoch 5/10, Batch 30/97, Loss: 0.2254
Epoch 5/10, Batch 40/97, Loss: 0.1093
Epoch 5/10, Batch 50/97, Loss: 0.1851
Epoch 5/10, Batch 60/97, Loss: 0.2236
Epoch 5/10, Batch 70/97, Loss: 0.2477
Epoch 5/10, Batch 80/97, Loss: 0.2629
Epoch 5/10, Batch 90/97, Loss: 0.3011
Epoch 5/10, Train Loss: 0.2540, Valid Loss: 0.2490
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2708
Epoch 6/10, Batch 20/97, Loss: 0.1656
Epoch 6/10, Batch 30/97, Loss: 0.2159
Epoch 6/10, Batch 40/97, Loss: 0.3142
Epoch 6/10, Batch 50/97, Loss: 0.1819
Epoch 6/10, Batch 60/97, Loss: 0.2576
Epoch 6/10, Batch 70/97, Loss: 0.1712
Epoch 6/10, Batch 80/97, Loss: 0.1940
Epoch 6/10, Batch 90/97, Loss: 0.1765
Epoch 6/10, Train Loss: 0.2329, Valid Loss: 0.2481
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2568
Epoch 7/10, Batch 20/97, Loss: 0.1106
Epoch 7/10, Batch 30/97, Loss: 0.1961
Epoch 7/10, Batch 40/97, Loss: 0.1454
Epoch 7/10, Batch 50/97, Loss: 0.2148
Epoch 7/10, Batch 60/97, Loss: 0.3740
Epoch 7/10, Batch 70/97, Loss: 0.2323
Epoch 7/10, Batch 80/97, Loss: 0.2115
Epoch 7/10, Batch 90/97, Loss: 0.1788
Epoch 7/10, Train Loss: 0.2369, Valid Loss: 0.2369
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2327
Epoch 8/10, Batch 20/97, Loss: 0.2212
Epoch 8/10, Batch 30/97, Loss: 0.0947
Epoch 8/10, Batch 40/97, Loss: 0.1302
Epoch 8/10, Batch 50/97, Loss: 0.1478
Epoch 8/10, Batch 60/97, Loss: 0.1982
Epoch 8/10, Batch 70/97, Loss: 0.3251
Epoch 8/10, Batch 80/97, Loss: 0.1404
Epoch 8/10, Batch 90/97, Loss: 0.2189
Epoch 8/10, Train Loss: 0.2135, Valid Loss: 0.2337
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1702
Epoch 9/10, Batch 20/97, Loss: 0.1117
Epoch 9/10, Batch 30/97, Loss: 0.2493
Epoch 9/10, Batch 40/97, Loss: 0.1157
Epoch 9/10, Batch 50/97, Loss: 0.2922
Epoch 9/10, Batch 60/97, Loss: 0.1986
Epoch 9/10, Batch 70/97, Loss: 0.2095
Epoch 9/10, Batch 80/97, Loss: 0.1052
Epoch 9/10, Batch 90/97, Loss: 0.1335
Epoch 9/10, Train Loss: 0.2013, Valid Loss: 0.2318
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3498
Epoch 10/10, Batch 20/97, Loss: 0.1440
Epoch 10/10, Batch 30/97, Loss: 0.1815
Epoch 10/10, Batch 40/97, Loss: 0.2300
Epoch 10/10, Batch 50/97, Loss: 0.3128
Epoch 10/10, Batch 60/97, Loss: 0.0748
Epoch 10/10, Batch 70/97, Loss: 0.1468
Epoch 10/10, Batch 80/97, Loss: 0.2631
Epoch 10/10, Batch 90/97, Loss: 0.2081
Epoch 10/10, Train Loss: 0.1919, Valid Loss: 0.2302
Model saved!
Accuracy: 0.9159
Precision: 0.9139
Recall: 0.9159
F1-score: 0.9147
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5004
Epoch 1/10, Batch 20/97, Loss: 1.0547
Epoch 1/10, Batch 30/97, Loss: 0.8921
Epoch 1/10, Batch 40/97, Loss: 0.8121
Epoch 1/10, Batch 50/97, Loss: 0.6342
Epoch 1/10, Batch 60/97, Loss: 0.7068
Epoch 1/10, Batch 70/97, Loss: 0.5874
Epoch 1/10, Batch 80/97, Loss: 0.5175
Epoch 1/10, Batch 90/97, Loss: 0.6143
Epoch 1/10, Train Loss: 0.7740, Valid Loss: 0.4623
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3985
Epoch 2/10, Batch 20/97, Loss: 0.4704
Epoch 2/10, Batch 30/97, Loss: 0.4082
Epoch 2/10, Batch 40/97, Loss: 0.4001
Epoch 2/10, Batch 50/97, Loss: 0.5177
Epoch 2/10, Batch 60/97, Loss: 0.3766
Epoch 2/10, Batch 70/97, Loss: 0.2712
Epoch 2/10, Batch 80/97, Loss: 0.3079
Epoch 2/10, Batch 90/97, Loss: 0.3199
Epoch 2/10, Train Loss: 0.3958, Valid Loss: 0.3535
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3068
Epoch 3/10, Batch 20/97, Loss: 0.3417
Epoch 3/10, Batch 30/97, Loss: 0.1937
Epoch 3/10, Batch 40/97, Loss: 0.2056
Epoch 3/10, Batch 50/97, Loss: 0.4253
Epoch 3/10, Batch 60/97, Loss: 0.3254
Epoch 3/10, Batch 70/97, Loss: 0.2051
Epoch 3/10, Batch 80/97, Loss: 0.3433
Epoch 3/10, Batch 90/97, Loss: 0.2505
Epoch 3/10, Train Loss: 0.3218, Valid Loss: 0.3136
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2142
Epoch 4/10, Batch 20/97, Loss: 0.2010
Epoch 4/10, Batch 30/97, Loss: 0.3539
Epoch 4/10, Batch 40/97, Loss: 0.1401
Epoch 4/10, Batch 50/97, Loss: 0.1413
Epoch 4/10, Batch 60/97, Loss: 0.1964
Epoch 4/10, Batch 70/97, Loss: 0.2563
Epoch 4/10, Batch 80/97, Loss: 0.2486
Epoch 4/10, Batch 90/97, Loss: 0.2712
Epoch 4/10, Train Loss: 0.2874, Valid Loss: 0.2917
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2238
Epoch 5/10, Batch 20/97, Loss: 0.0932
Epoch 5/10, Batch 30/97, Loss: 0.1857
Epoch 5/10, Batch 40/97, Loss: 0.1768
Epoch 5/10, Batch 50/97, Loss: 0.3697
Epoch 5/10, Batch 60/97, Loss: 0.2131
Epoch 5/10, Batch 70/97, Loss: 0.1177
Epoch 5/10, Batch 80/97, Loss: 0.2922
Epoch 5/10, Batch 90/97, Loss: 0.2846
Epoch 5/10, Train Loss: 0.2602, Valid Loss: 0.2691
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1562
Epoch 6/10, Batch 20/97, Loss: 0.2324
Epoch 6/10, Batch 30/97, Loss: 0.1994
Epoch 6/10, Batch 40/97, Loss: 0.2942
Epoch 6/10, Batch 50/97, Loss: 0.1735
Epoch 6/10, Batch 60/97, Loss: 0.3312
Epoch 6/10, Batch 70/97, Loss: 0.4247
Epoch 6/10, Batch 80/97, Loss: 0.0763
Epoch 6/10, Batch 90/97, Loss: 0.1743
Epoch 6/10, Train Loss: 0.2464, Valid Loss: 0.2595
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3440
Epoch 7/10, Batch 20/97, Loss: 0.1810
Epoch 7/10, Batch 30/97, Loss: 0.2820
Epoch 7/10, Batch 40/97, Loss: 0.2404
Epoch 7/10, Batch 50/97, Loss: 0.2856
Epoch 7/10, Batch 60/97, Loss: 0.3999
Epoch 7/10, Batch 70/97, Loss: 0.2724
Epoch 7/10, Batch 80/97, Loss: 0.2917
Epoch 7/10, Batch 90/97, Loss: 0.1340
Epoch 7/10, Train Loss: 0.2411, Valid Loss: 0.2539
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1675
Epoch 8/10, Batch 20/97, Loss: 0.2948
Epoch 8/10, Batch 30/97, Loss: 0.1995
Epoch 8/10, Batch 40/97, Loss: 0.2670
Epoch 8/10, Batch 50/97, Loss: 0.2413
Epoch 8/10, Batch 60/97, Loss: 0.2125
Epoch 8/10, Batch 70/97, Loss: 0.2383
Epoch 8/10, Batch 80/97, Loss: 0.2646
Epoch 8/10, Batch 90/97, Loss: 0.1638
Epoch 8/10, Train Loss: 0.2256, Valid Loss: 0.2525
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1533
Epoch 9/10, Batch 20/97, Loss: 0.1352
Epoch 9/10, Batch 30/97, Loss: 0.2148
Epoch 9/10, Batch 40/97, Loss: 0.2576
Epoch 9/10, Batch 50/97, Loss: 0.2772
Epoch 9/10, Batch 60/97, Loss: 0.0893
Epoch 9/10, Batch 70/97, Loss: 0.1873
Epoch 9/10, Batch 80/97, Loss: 0.1994
Epoch 9/10, Batch 90/97, Loss: 0.2527
Epoch 9/10, Train Loss: 0.2095, Valid Loss: 0.2461
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1529
Epoch 10/10, Batch 20/97, Loss: 0.0875
Epoch 10/10, Batch 30/97, Loss: 0.3679
Epoch 10/10, Batch 40/97, Loss: 0.1758
Epoch 10/10, Batch 50/97, Loss: 0.2521
Epoch 10/10, Batch 60/97, Loss: 0.1750
Epoch 10/10, Batch 70/97, Loss: 0.2912
Epoch 10/10, Batch 80/97, Loss: 0.0855
Epoch 10/10, Batch 90/97, Loss: 0.1758
Epoch 10/10, Train Loss: 0.1960, Valid Loss: 0.2394
Model saved!
Accuracy: 0.9112
Precision: 0.9086
Recall: 0.9112
F1-score: 0.9084
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5022
Epoch 1/10, Batch 20/97, Loss: 1.0028
Epoch 1/10, Batch 30/97, Loss: 0.8441
Epoch 1/10, Batch 40/97, Loss: 0.7334
Epoch 1/10, Batch 50/97, Loss: 0.5972
Epoch 1/10, Batch 60/97, Loss: 0.5585
Epoch 1/10, Batch 70/97, Loss: 0.4410
Epoch 1/10, Batch 80/97, Loss: 0.4648
Epoch 1/10, Batch 90/97, Loss: 0.5185
Epoch 1/10, Train Loss: 0.7800, Valid Loss: 0.4278
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4561
Epoch 2/10, Batch 20/97, Loss: 0.4849
Epoch 2/10, Batch 30/97, Loss: 0.3768
Epoch 2/10, Batch 40/97, Loss: 0.3913
Epoch 2/10, Batch 50/97, Loss: 0.6188
Epoch 2/10, Batch 60/97, Loss: 0.3340
Epoch 2/10, Batch 70/97, Loss: 0.3941
Epoch 2/10, Batch 80/97, Loss: 0.4305
Epoch 2/10, Batch 90/97, Loss: 0.3592
Epoch 2/10, Train Loss: 0.3949, Valid Loss: 0.3181
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4063
Epoch 3/10, Batch 20/97, Loss: 0.2611
Epoch 3/10, Batch 30/97, Loss: 0.2716
Epoch 3/10, Batch 40/97, Loss: 0.2631
Epoch 3/10, Batch 50/97, Loss: 0.3810
Epoch 3/10, Batch 60/97, Loss: 0.1667
Epoch 3/10, Batch 70/97, Loss: 0.1569
Epoch 3/10, Batch 80/97, Loss: 0.2792
Epoch 3/10, Batch 90/97, Loss: 0.2276
Epoch 3/10, Train Loss: 0.3245, Valid Loss: 0.2728
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2665
Epoch 4/10, Batch 20/97, Loss: 0.2552
Epoch 4/10, Batch 30/97, Loss: 0.5145
Epoch 4/10, Batch 40/97, Loss: 0.3258
Epoch 4/10, Batch 50/97, Loss: 0.1239
Epoch 4/10, Batch 60/97, Loss: 0.1530
Epoch 4/10, Batch 70/97, Loss: 0.3229
Epoch 4/10, Batch 80/97, Loss: 0.2422
Epoch 4/10, Batch 90/97, Loss: 0.2401
Epoch 4/10, Train Loss: 0.2799, Valid Loss: 0.2531
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2828
Epoch 5/10, Batch 20/97, Loss: 0.1974
Epoch 5/10, Batch 30/97, Loss: 0.1787
Epoch 5/10, Batch 40/97, Loss: 0.1534
Epoch 5/10, Batch 50/97, Loss: 0.1475
Epoch 5/10, Batch 60/97, Loss: 0.1959
Epoch 5/10, Batch 70/97, Loss: 0.2495
Epoch 5/10, Batch 80/97, Loss: 0.3726
Epoch 5/10, Batch 90/97, Loss: 0.3769
Epoch 5/10, Train Loss: 0.2535, Valid Loss: 0.2334
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3006
Epoch 6/10, Batch 20/97, Loss: 0.1401
Epoch 6/10, Batch 30/97, Loss: 0.1737
Epoch 6/10, Batch 40/97, Loss: 0.2352
Epoch 6/10, Batch 50/97, Loss: 0.1882
Epoch 6/10, Batch 60/97, Loss: 0.2263
Epoch 6/10, Batch 70/97, Loss: 0.1427
Epoch 6/10, Batch 80/97, Loss: 0.2036
Epoch 6/10, Batch 90/97, Loss: 0.2460
Epoch 6/10, Train Loss: 0.2334, Valid Loss: 0.2301
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3036
Epoch 7/10, Batch 20/97, Loss: 0.1374
Epoch 7/10, Batch 30/97, Loss: 0.2199
Epoch 7/10, Batch 40/97, Loss: 0.1651
Epoch 7/10, Batch 50/97, Loss: 0.2376
Epoch 7/10, Batch 60/97, Loss: 0.2568
Epoch 7/10, Batch 70/97, Loss: 0.1808
Epoch 7/10, Batch 80/97, Loss: 0.1455
Epoch 7/10, Batch 90/97, Loss: 0.3498
Epoch 7/10, Train Loss: 0.2363, Valid Loss: 0.2101
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2328
Epoch 8/10, Batch 20/97, Loss: 0.1498
Epoch 8/10, Batch 30/97, Loss: 0.0677
Epoch 8/10, Batch 40/97, Loss: 0.1416
Epoch 8/10, Batch 50/97, Loss: 0.3016
Epoch 8/10, Batch 60/97, Loss: 0.0827
Epoch 8/10, Batch 70/97, Loss: 0.2914
Epoch 8/10, Batch 80/97, Loss: 0.2479
Epoch 8/10, Batch 90/97, Loss: 0.1327
Epoch 8/10, Train Loss: 0.2236, Valid Loss: 0.2141
Epoch 9/10, Batch 10/97, Loss: 0.1632
Epoch 9/10, Batch 20/97, Loss: 0.0590
Epoch 9/10, Batch 30/97, Loss: 0.2272
Epoch 9/10, Batch 40/97, Loss: 0.3004
Epoch 9/10, Batch 50/97, Loss: 0.1587
Epoch 9/10, Batch 60/97, Loss: 0.1135
Epoch 9/10, Batch 70/97, Loss: 0.2065
Epoch 9/10, Batch 80/97, Loss: 0.2361
Epoch 9/10, Batch 90/97, Loss: 0.2136
Epoch 9/10, Train Loss: 0.2024, Valid Loss: 0.2131
Epoch 10/10, Batch 10/97, Loss: 0.1438
Epoch 10/10, Batch 20/97, Loss: 0.2821
Epoch 10/10, Batch 30/97, Loss: 0.1358
Epoch 10/10, Batch 40/97, Loss: 0.1474
Epoch 10/10, Batch 50/97, Loss: 0.2905
Epoch 10/10, Batch 60/97, Loss: 0.1917
Epoch 10/10, Batch 70/97, Loss: 0.1792
Epoch 10/10, Batch 80/97, Loss: 0.1394
Epoch 10/10, Batch 90/97, Loss: 0.1298
Epoch 10/10, Train Loss: 0.1978, Valid Loss: 0.2041
Model saved!
Accuracy: 0.9147
Precision: 0.9116
Recall: 0.9147
F1-score: 0.9123
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5105
Epoch 1/10, Batch 20/97, Loss: 1.0043
Epoch 1/10, Batch 30/97, Loss: 0.8920
Epoch 1/10, Batch 40/97, Loss: 0.7349
Epoch 1/10, Batch 50/97, Loss: 0.5560
Epoch 1/10, Batch 60/97, Loss: 0.6421
Epoch 1/10, Batch 70/97, Loss: 0.4698
Epoch 1/10, Batch 80/97, Loss: 0.4660
Epoch 1/10, Batch 90/97, Loss: 0.5203
Epoch 1/10, Train Loss: 0.7747, Valid Loss: 0.4131
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4307
Epoch 2/10, Batch 20/97, Loss: 0.7660
Epoch 2/10, Batch 30/97, Loss: 0.3139
Epoch 2/10, Batch 40/97, Loss: 0.3769
Epoch 2/10, Batch 50/97, Loss: 0.4461
Epoch 2/10, Batch 60/97, Loss: 0.4409
Epoch 2/10, Batch 70/97, Loss: 0.2555
Epoch 2/10, Batch 80/97, Loss: 0.3193
Epoch 2/10, Batch 90/97, Loss: 0.2900
Epoch 2/10, Train Loss: 0.3914, Valid Loss: 0.3023
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2742
Epoch 3/10, Batch 20/97, Loss: 0.3015
Epoch 3/10, Batch 30/97, Loss: 0.2102
Epoch 3/10, Batch 40/97, Loss: 0.2380
Epoch 3/10, Batch 50/97, Loss: 0.2927
Epoch 3/10, Batch 60/97, Loss: 0.3402
Epoch 3/10, Batch 70/97, Loss: 0.1489
Epoch 3/10, Batch 80/97, Loss: 0.3546
Epoch 3/10, Batch 90/97, Loss: 0.2995
Epoch 3/10, Train Loss: 0.3214, Valid Loss: 0.2633
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2183
Epoch 4/10, Batch 20/97, Loss: 0.3882
Epoch 4/10, Batch 30/97, Loss: 0.3215
Epoch 4/10, Batch 40/97, Loss: 0.1777
Epoch 4/10, Batch 50/97, Loss: 0.2935
Epoch 4/10, Batch 60/97, Loss: 0.1790
Epoch 4/10, Batch 70/97, Loss: 0.1405
Epoch 4/10, Batch 80/97, Loss: 0.2340
Epoch 4/10, Batch 90/97, Loss: 0.1941
Epoch 4/10, Train Loss: 0.2801, Valid Loss: 0.2427
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2407
Epoch 5/10, Batch 20/97, Loss: 0.1841
Epoch 5/10, Batch 30/97, Loss: 0.2861
Epoch 5/10, Batch 40/97, Loss: 0.2554
Epoch 5/10, Batch 50/97, Loss: 0.2766
Epoch 5/10, Batch 60/97, Loss: 0.1624
Epoch 5/10, Batch 70/97, Loss: 0.2239
Epoch 5/10, Batch 80/97, Loss: 0.2693
Epoch 5/10, Batch 90/97, Loss: 0.3930
Epoch 5/10, Train Loss: 0.2595, Valid Loss: 0.2320
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3919
Epoch 6/10, Batch 20/97, Loss: 0.2897
Epoch 6/10, Batch 30/97, Loss: 0.3451
Epoch 6/10, Batch 40/97, Loss: 0.2659
Epoch 6/10, Batch 50/97, Loss: 0.1184
Epoch 6/10, Batch 60/97, Loss: 0.3336
Epoch 6/10, Batch 70/97, Loss: 0.1639
Epoch 6/10, Batch 80/97, Loss: 0.2158
Epoch 6/10, Batch 90/97, Loss: 0.2320
Epoch 6/10, Train Loss: 0.2411, Valid Loss: 0.2243
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4214
Epoch 7/10, Batch 20/97, Loss: 0.1350
Epoch 7/10, Batch 30/97, Loss: 0.1239
Epoch 7/10, Batch 40/97, Loss: 0.1604
Epoch 7/10, Batch 50/97, Loss: 0.1760
Epoch 7/10, Batch 60/97, Loss: 0.4188
Epoch 7/10, Batch 70/97, Loss: 0.1436
Epoch 7/10, Batch 80/97, Loss: 0.1983
Epoch 7/10, Batch 90/97, Loss: 0.1726
Epoch 7/10, Train Loss: 0.2381, Valid Loss: 0.2179
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1998
Epoch 8/10, Batch 20/97, Loss: 0.1678
Epoch 8/10, Batch 30/97, Loss: 0.2462
Epoch 8/10, Batch 40/97, Loss: 0.2554
Epoch 8/10, Batch 50/97, Loss: 0.2057
Epoch 8/10, Batch 60/97, Loss: 0.0758
Epoch 8/10, Batch 70/97, Loss: 0.2031
Epoch 8/10, Batch 80/97, Loss: 0.2741
Epoch 8/10, Batch 90/97, Loss: 0.2470
Epoch 8/10, Train Loss: 0.2203, Valid Loss: 0.2130
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2171
Epoch 9/10, Batch 20/97, Loss: 0.0538
Epoch 9/10, Batch 30/97, Loss: 0.2379
Epoch 9/10, Batch 40/97, Loss: 0.1517
Epoch 9/10, Batch 50/97, Loss: 0.3344
Epoch 9/10, Batch 60/97, Loss: 0.2289
Epoch 9/10, Batch 70/97, Loss: 0.1659
Epoch 9/10, Batch 80/97, Loss: 0.3857
Epoch 9/10, Batch 90/97, Loss: 0.4329
Epoch 9/10, Train Loss: 0.2110, Valid Loss: 0.2094
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2803
Epoch 10/10, Batch 20/97, Loss: 0.2556
Epoch 10/10, Batch 30/97, Loss: 0.1538
Epoch 10/10, Batch 40/97, Loss: 0.3352
Epoch 10/10, Batch 50/97, Loss: 0.3652
Epoch 10/10, Batch 60/97, Loss: 0.1264
Epoch 10/10, Batch 70/97, Loss: 0.1679
Epoch 10/10, Batch 80/97, Loss: 0.0830
Epoch 10/10, Batch 90/97, Loss: 0.0986
Epoch 10/10, Train Loss: 0.1908, Valid Loss: 0.2028
Model saved!
Accuracy: 0.9147
Precision: 0.9118
Recall: 0.9147
F1-score: 0.9124
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4565
Epoch 1/10, Batch 20/97, Loss: 1.0637
Epoch 1/10, Batch 30/97, Loss: 0.8877
Epoch 1/10, Batch 40/97, Loss: 0.7291
Epoch 1/10, Batch 50/97, Loss: 0.6153
Epoch 1/10, Batch 60/97, Loss: 0.6442
Epoch 1/10, Batch 70/97, Loss: 0.4377
Epoch 1/10, Batch 80/97, Loss: 0.4658
Epoch 1/10, Batch 90/97, Loss: 0.5019
Epoch 1/10, Train Loss: 0.7583, Valid Loss: 0.4239
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5332
Epoch 2/10, Batch 20/97, Loss: 0.4092
Epoch 2/10, Batch 30/97, Loss: 0.3681
Epoch 2/10, Batch 40/97, Loss: 0.4002
Epoch 2/10, Batch 50/97, Loss: 0.5462
Epoch 2/10, Batch 60/97, Loss: 0.2794
Epoch 2/10, Batch 70/97, Loss: 0.5346
Epoch 2/10, Batch 80/97, Loss: 0.2315
Epoch 2/10, Batch 90/97, Loss: 0.3709
Epoch 2/10, Train Loss: 0.3804, Valid Loss: 0.3349
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3171
Epoch 3/10, Batch 20/97, Loss: 0.2589
Epoch 3/10, Batch 30/97, Loss: 0.2516
Epoch 3/10, Batch 40/97, Loss: 0.3119
Epoch 3/10, Batch 50/97, Loss: 0.1932
Epoch 3/10, Batch 60/97, Loss: 0.3455
Epoch 3/10, Batch 70/97, Loss: 0.1832
Epoch 3/10, Batch 80/97, Loss: 0.2695
Epoch 3/10, Batch 90/97, Loss: 0.2621
Epoch 3/10, Train Loss: 0.3095, Valid Loss: 0.2982
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3572
Epoch 4/10, Batch 20/97, Loss: 0.2083
Epoch 4/10, Batch 30/97, Loss: 0.4877
Epoch 4/10, Batch 40/97, Loss: 0.2111
Epoch 4/10, Batch 50/97, Loss: 0.1847
Epoch 4/10, Batch 60/97, Loss: 0.2205
Epoch 4/10, Batch 70/97, Loss: 0.2013
Epoch 4/10, Batch 80/97, Loss: 0.1515
Epoch 4/10, Batch 90/97, Loss: 0.2073
Epoch 4/10, Train Loss: 0.2755, Valid Loss: 0.2771
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1893
Epoch 5/10, Batch 20/97, Loss: 0.2748
Epoch 5/10, Batch 30/97, Loss: 0.2828
Epoch 5/10, Batch 40/97, Loss: 0.1286
Epoch 5/10, Batch 50/97, Loss: 0.2077
Epoch 5/10, Batch 60/97, Loss: 0.1861
Epoch 5/10, Batch 70/97, Loss: 0.2970
Epoch 5/10, Batch 80/97, Loss: 0.3687
Epoch 5/10, Batch 90/97, Loss: 0.2590
Epoch 5/10, Train Loss: 0.2558, Valid Loss: 0.2576
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2418
Epoch 6/10, Batch 20/97, Loss: 0.1447
Epoch 6/10, Batch 30/97, Loss: 0.2700
Epoch 6/10, Batch 40/97, Loss: 0.2330
Epoch 6/10, Batch 50/97, Loss: 0.1745
Epoch 6/10, Batch 60/97, Loss: 0.2482
Epoch 6/10, Batch 70/97, Loss: 0.1678
Epoch 6/10, Batch 80/97, Loss: 0.1488
Epoch 6/10, Batch 90/97, Loss: 0.2964
Epoch 6/10, Train Loss: 0.2365, Valid Loss: 0.2613
Epoch 7/10, Batch 10/97, Loss: 0.3164
Epoch 7/10, Batch 20/97, Loss: 0.1029
Epoch 7/10, Batch 30/97, Loss: 0.1210
Epoch 7/10, Batch 40/97, Loss: 0.0869
Epoch 7/10, Batch 50/97, Loss: 0.1273
Epoch 7/10, Batch 60/97, Loss: 0.2479
Epoch 7/10, Batch 70/97, Loss: 0.1336
Epoch 7/10, Batch 80/97, Loss: 0.2416
Epoch 7/10, Batch 90/97, Loss: 0.2003
Epoch 7/10, Train Loss: 0.2437, Valid Loss: 0.2440
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2472
Epoch 8/10, Batch 20/97, Loss: 0.1568
Epoch 8/10, Batch 30/97, Loss: 0.1490
Epoch 8/10, Batch 40/97, Loss: 0.1410
Epoch 8/10, Batch 50/97, Loss: 0.2145
Epoch 8/10, Batch 60/97, Loss: 0.0706
Epoch 8/10, Batch 70/97, Loss: 0.2312
Epoch 8/10, Batch 80/97, Loss: 0.1563
Epoch 8/10, Batch 90/97, Loss: 0.1705
Epoch 8/10, Train Loss: 0.2126, Valid Loss: 0.2339
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1496
Epoch 9/10, Batch 20/97, Loss: 0.1086
Epoch 9/10, Batch 30/97, Loss: 0.2942
Epoch 9/10, Batch 40/97, Loss: 0.1334
Epoch 9/10, Batch 50/97, Loss: 0.1409
Epoch 9/10, Batch 60/97, Loss: 0.1162
Epoch 9/10, Batch 70/97, Loss: 0.1683
Epoch 9/10, Batch 80/97, Loss: 0.1548
Epoch 9/10, Batch 90/97, Loss: 0.2053
Epoch 9/10, Train Loss: 0.1996, Valid Loss: 0.2391
Epoch 10/10, Batch 10/97, Loss: 0.2439
Epoch 10/10, Batch 20/97, Loss: 0.1228
Epoch 10/10, Batch 30/97, Loss: 0.1293
Epoch 10/10, Batch 40/97, Loss: 0.1744
Epoch 10/10, Batch 50/97, Loss: 0.2002
Epoch 10/10, Batch 60/97, Loss: 0.1122
Epoch 10/10, Batch 70/97, Loss: 0.3220
Epoch 10/10, Batch 80/97, Loss: 0.1475
Epoch 10/10, Batch 90/97, Loss: 0.0698
Epoch 10/10, Train Loss: 0.1949, Valid Loss: 0.2304
Model saved!
Accuracy: 0.9124
Precision: 0.9097
Recall: 0.9124
F1-score: 0.9098
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4240
Epoch 1/10, Batch 20/97, Loss: 0.9467
Epoch 1/10, Batch 30/97, Loss: 0.8569
Epoch 1/10, Batch 40/97, Loss: 0.7970
Epoch 1/10, Batch 50/97, Loss: 0.5763
Epoch 1/10, Batch 60/97, Loss: 0.5475
Epoch 1/10, Batch 70/97, Loss: 0.4555
Epoch 1/10, Batch 80/97, Loss: 0.4289
Epoch 1/10, Batch 90/97, Loss: 0.4997
Epoch 1/10, Train Loss: 0.7658, Valid Loss: 0.4240
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3681
Epoch 2/10, Batch 20/97, Loss: 0.4952
Epoch 2/10, Batch 30/97, Loss: 0.3408
Epoch 2/10, Batch 40/97, Loss: 0.4683
Epoch 2/10, Batch 50/97, Loss: 0.5951
Epoch 2/10, Batch 60/97, Loss: 0.3456
Epoch 2/10, Batch 70/97, Loss: 0.2683
Epoch 2/10, Batch 80/97, Loss: 0.2752
Epoch 2/10, Batch 90/97, Loss: 0.3218
Epoch 2/10, Train Loss: 0.3941, Valid Loss: 0.3124
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.1796
Epoch 3/10, Batch 20/97, Loss: 0.2541
Epoch 3/10, Batch 30/97, Loss: 0.4411
Epoch 3/10, Batch 40/97, Loss: 0.2605
Epoch 3/10, Batch 50/97, Loss: 0.3596
Epoch 3/10, Batch 60/97, Loss: 0.3450
Epoch 3/10, Batch 70/97, Loss: 0.2576
Epoch 3/10, Batch 80/97, Loss: 0.2721
Epoch 3/10, Batch 90/97, Loss: 0.2664
Epoch 3/10, Train Loss: 0.3225, Valid Loss: 0.2728
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3503
Epoch 4/10, Batch 20/97, Loss: 0.2724
Epoch 4/10, Batch 30/97, Loss: 0.3982
Epoch 4/10, Batch 40/97, Loss: 0.2902
Epoch 4/10, Batch 50/97, Loss: 0.3023
Epoch 4/10, Batch 60/97, Loss: 0.1751
Epoch 4/10, Batch 70/97, Loss: 0.1388
Epoch 4/10, Batch 80/97, Loss: 0.4468
Epoch 4/10, Batch 90/97, Loss: 0.1903
Epoch 4/10, Train Loss: 0.2881, Valid Loss: 0.2471
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2059
Epoch 5/10, Batch 20/97, Loss: 0.2118
Epoch 5/10, Batch 30/97, Loss: 0.2169
Epoch 5/10, Batch 40/97, Loss: 0.3330
Epoch 5/10, Batch 50/97, Loss: 0.1912
Epoch 5/10, Batch 60/97, Loss: 0.3557
Epoch 5/10, Batch 70/97, Loss: 0.2075
Epoch 5/10, Batch 80/97, Loss: 0.2435
Epoch 5/10, Batch 90/97, Loss: 0.3091
Epoch 5/10, Train Loss: 0.2630, Valid Loss: 0.2395
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2111
Epoch 6/10, Batch 20/97, Loss: 0.2623
Epoch 6/10, Batch 30/97, Loss: 0.1772
Epoch 6/10, Batch 40/97, Loss: 0.2324
Epoch 6/10, Batch 50/97, Loss: 0.1351
Epoch 6/10, Batch 60/97, Loss: 0.2210
Epoch 6/10, Batch 70/97, Loss: 0.2360
Epoch 6/10, Batch 80/97, Loss: 0.1158
Epoch 6/10, Batch 90/97, Loss: 0.2393
Epoch 6/10, Train Loss: 0.2415, Valid Loss: 0.2267
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3547
Epoch 7/10, Batch 20/97, Loss: 0.1382
Epoch 7/10, Batch 30/97, Loss: 0.2267
Epoch 7/10, Batch 40/97, Loss: 0.2360
Epoch 7/10, Batch 50/97, Loss: 0.1366
Epoch 7/10, Batch 60/97, Loss: 0.2906
Epoch 7/10, Batch 70/97, Loss: 0.2681
Epoch 7/10, Batch 80/97, Loss: 0.2296
Epoch 7/10, Batch 90/97, Loss: 0.1449
Epoch 7/10, Train Loss: 0.2443, Valid Loss: 0.2107
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1623
Epoch 8/10, Batch 20/97, Loss: 0.1975
Epoch 8/10, Batch 30/97, Loss: 0.4562
Epoch 8/10, Batch 40/97, Loss: 0.2676
Epoch 8/10, Batch 50/97, Loss: 0.1550
Epoch 8/10, Batch 60/97, Loss: 0.2347
Epoch 8/10, Batch 70/97, Loss: 0.2640
Epoch 8/10, Batch 80/97, Loss: 0.1937
Epoch 8/10, Batch 90/97, Loss: 0.1635
Epoch 8/10, Train Loss: 0.2296, Valid Loss: 0.2139
Epoch 9/10, Batch 10/97, Loss: 0.1953
Epoch 9/10, Batch 20/97, Loss: 0.2261
Epoch 9/10, Batch 30/97, Loss: 0.2751
Epoch 9/10, Batch 40/97, Loss: 0.1656
Epoch 9/10, Batch 50/97, Loss: 0.3124
Epoch 9/10, Batch 60/97, Loss: 0.1926
Epoch 9/10, Batch 70/97, Loss: 0.2338
Epoch 9/10, Batch 80/97, Loss: 0.3461
Epoch 9/10, Batch 90/97, Loss: 0.2437
Epoch 9/10, Train Loss: 0.2099, Valid Loss: 0.2105
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3527
Epoch 10/10, Batch 20/97, Loss: 0.2812
Epoch 10/10, Batch 30/97, Loss: 0.1878
Epoch 10/10, Batch 40/97, Loss: 0.1442
Epoch 10/10, Batch 50/97, Loss: 0.2220
Epoch 10/10, Batch 60/97, Loss: 0.1660
Epoch 10/10, Batch 70/97, Loss: 0.2855
Epoch 10/10, Batch 80/97, Loss: 0.2597
Epoch 10/10, Batch 90/97, Loss: 0.2044
Epoch 10/10, Train Loss: 0.1992, Valid Loss: 0.1998
Model saved!
Accuracy: 0.9159
Precision: 0.9134
Recall: 0.9159
F1-score: 0.9142
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4586
Epoch 1/10, Batch 20/97, Loss: 1.0243
Epoch 1/10, Batch 30/97, Loss: 0.8261
Epoch 1/10, Batch 40/97, Loss: 0.5880
Epoch 1/10, Batch 50/97, Loss: 0.5222
Epoch 1/10, Batch 60/97, Loss: 0.5516
Epoch 1/10, Batch 70/97, Loss: 0.5704
Epoch 1/10, Batch 80/97, Loss: 0.4571
Epoch 1/10, Batch 90/97, Loss: 0.5309
Epoch 1/10, Train Loss: 0.7599, Valid Loss: 0.4651
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3378
Epoch 2/10, Batch 20/97, Loss: 0.5333
Epoch 2/10, Batch 30/97, Loss: 0.3577
Epoch 2/10, Batch 40/97, Loss: 0.5166
Epoch 2/10, Batch 50/97, Loss: 0.4914
Epoch 2/10, Batch 60/97, Loss: 0.3973
Epoch 2/10, Batch 70/97, Loss: 0.3425
Epoch 2/10, Batch 80/97, Loss: 0.2438
Epoch 2/10, Batch 90/97, Loss: 0.2653
Epoch 2/10, Train Loss: 0.3837, Valid Loss: 0.3635
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2601
Epoch 3/10, Batch 20/97, Loss: 0.4210
Epoch 3/10, Batch 30/97, Loss: 0.3614
Epoch 3/10, Batch 40/97, Loss: 0.3071
Epoch 3/10, Batch 50/97, Loss: 0.2438
Epoch 3/10, Batch 60/97, Loss: 0.2801
Epoch 3/10, Batch 70/97, Loss: 0.2268
Epoch 3/10, Batch 80/97, Loss: 0.2645
Epoch 3/10, Batch 90/97, Loss: 0.2350
Epoch 3/10, Train Loss: 0.3136, Valid Loss: 0.3318
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3516
Epoch 4/10, Batch 20/97, Loss: 0.1950
Epoch 4/10, Batch 30/97, Loss: 0.2597
Epoch 4/10, Batch 40/97, Loss: 0.2339
Epoch 4/10, Batch 50/97, Loss: 0.3370
Epoch 4/10, Batch 60/97, Loss: 0.1888
Epoch 4/10, Batch 70/97, Loss: 0.2784
Epoch 4/10, Batch 80/97, Loss: 0.2508
Epoch 4/10, Batch 90/97, Loss: 0.2958
Epoch 4/10, Train Loss: 0.2747, Valid Loss: 0.3029
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1220
Epoch 5/10, Batch 20/97, Loss: 0.2974
Epoch 5/10, Batch 30/97, Loss: 0.1468
Epoch 5/10, Batch 40/97, Loss: 0.1030
Epoch 5/10, Batch 50/97, Loss: 0.1407
Epoch 5/10, Batch 60/97, Loss: 0.3270
Epoch 5/10, Batch 70/97, Loss: 0.1896
Epoch 5/10, Batch 80/97, Loss: 0.3921
Epoch 5/10, Batch 90/97, Loss: 0.2817
Epoch 5/10, Train Loss: 0.2577, Valid Loss: 0.2941
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1930
Epoch 6/10, Batch 20/97, Loss: 0.1373
Epoch 6/10, Batch 30/97, Loss: 0.0881
Epoch 6/10, Batch 40/97, Loss: 0.2575
Epoch 6/10, Batch 50/97, Loss: 0.3334
Epoch 6/10, Batch 60/97, Loss: 0.1133
Epoch 6/10, Batch 70/97, Loss: 0.4137
Epoch 6/10, Batch 80/97, Loss: 0.1481
Epoch 6/10, Batch 90/97, Loss: 0.3180
Epoch 6/10, Train Loss: 0.2358, Valid Loss: 0.2984
Epoch 7/10, Batch 10/97, Loss: 0.1575
Epoch 7/10, Batch 20/97, Loss: 0.1522
Epoch 7/10, Batch 30/97, Loss: 0.2358
Epoch 7/10, Batch 40/97, Loss: 0.1396
Epoch 7/10, Batch 50/97, Loss: 0.3105
Epoch 7/10, Batch 60/97, Loss: 0.3661
Epoch 7/10, Batch 70/97, Loss: 0.1746
Epoch 7/10, Batch 80/97, Loss: 0.2104
Epoch 7/10, Batch 90/97, Loss: 0.4142
Epoch 7/10, Train Loss: 0.2348, Valid Loss: 0.2831
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1725
Epoch 8/10, Batch 20/97, Loss: 0.1414
Epoch 8/10, Batch 30/97, Loss: 0.2373
Epoch 8/10, Batch 40/97, Loss: 0.2628
Epoch 8/10, Batch 50/97, Loss: 0.2901
Epoch 8/10, Batch 60/97, Loss: 0.1328
Epoch 8/10, Batch 70/97, Loss: 0.2640
Epoch 8/10, Batch 80/97, Loss: 0.1675
Epoch 8/10, Batch 90/97, Loss: 0.1207
Epoch 8/10, Train Loss: 0.2098, Valid Loss: 0.2808
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1113
Epoch 9/10, Batch 20/97, Loss: 0.1058
Epoch 9/10, Batch 30/97, Loss: 0.3431
Epoch 9/10, Batch 40/97, Loss: 0.0523
Epoch 9/10, Batch 50/97, Loss: 0.2690
Epoch 9/10, Batch 60/97, Loss: 0.3819
Epoch 9/10, Batch 70/97, Loss: 0.2012
Epoch 9/10, Batch 80/97, Loss: 0.1321
Epoch 9/10, Batch 90/97, Loss: 0.2298
Epoch 9/10, Train Loss: 0.2051, Valid Loss: 0.2864
Epoch 10/10, Batch 10/97, Loss: 0.2468
Epoch 10/10, Batch 20/97, Loss: 0.1798
Epoch 10/10, Batch 30/97, Loss: 0.1226
Epoch 10/10, Batch 40/97, Loss: 0.2083
Epoch 10/10, Batch 50/97, Loss: 0.1791
Epoch 10/10, Batch 60/97, Loss: 0.2336
Epoch 10/10, Batch 70/97, Loss: 0.2560
Epoch 10/10, Batch 80/97, Loss: 0.2570
Epoch 10/10, Batch 90/97, Loss: 0.2068
Epoch 10/10, Train Loss: 0.1879, Valid Loss: 0.2697
Model saved!
Accuracy: 0.9124
Precision: 0.9088
Recall: 0.9124
F1-score: 0.9096
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5240
Epoch 1/10, Batch 20/97, Loss: 0.9667
Epoch 1/10, Batch 30/97, Loss: 0.8821
Epoch 1/10, Batch 40/97, Loss: 0.7524
Epoch 1/10, Batch 50/97, Loss: 0.6439
Epoch 1/10, Batch 60/97, Loss: 0.5622
Epoch 1/10, Batch 70/97, Loss: 0.4875
Epoch 1/10, Batch 80/97, Loss: 0.4821
Epoch 1/10, Batch 90/97, Loss: 0.4891
Epoch 1/10, Train Loss: 0.7731, Valid Loss: 0.4662
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4402
Epoch 2/10, Batch 20/97, Loss: 0.4078
Epoch 2/10, Batch 30/97, Loss: 0.3506
Epoch 2/10, Batch 40/97, Loss: 0.4323
Epoch 2/10, Batch 50/97, Loss: 0.6572
Epoch 2/10, Batch 60/97, Loss: 0.2965
Epoch 2/10, Batch 70/97, Loss: 0.2517
Epoch 2/10, Batch 80/97, Loss: 0.3856
Epoch 2/10, Batch 90/97, Loss: 0.4966
Epoch 2/10, Train Loss: 0.3960, Valid Loss: 0.3704
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3300
Epoch 3/10, Batch 20/97, Loss: 0.3380
Epoch 3/10, Batch 30/97, Loss: 0.2229
Epoch 3/10, Batch 40/97, Loss: 0.4085
Epoch 3/10, Batch 50/97, Loss: 0.2203
Epoch 3/10, Batch 60/97, Loss: 0.3460
Epoch 3/10, Batch 70/97, Loss: 0.1856
Epoch 3/10, Batch 80/97, Loss: 0.4416
Epoch 3/10, Batch 90/97, Loss: 0.2530
Epoch 3/10, Train Loss: 0.3234, Valid Loss: 0.3159
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2653
Epoch 4/10, Batch 20/97, Loss: 0.2684
Epoch 4/10, Batch 30/97, Loss: 0.3527
Epoch 4/10, Batch 40/97, Loss: 0.1978
Epoch 4/10, Batch 50/97, Loss: 0.2130
Epoch 4/10, Batch 60/97, Loss: 0.1798
Epoch 4/10, Batch 70/97, Loss: 0.2534
Epoch 4/10, Batch 80/97, Loss: 0.2000
Epoch 4/10, Batch 90/97, Loss: 0.3023
Epoch 4/10, Train Loss: 0.2845, Valid Loss: 0.2998
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3035
Epoch 5/10, Batch 20/97, Loss: 0.1462
Epoch 5/10, Batch 30/97, Loss: 0.1920
Epoch 5/10, Batch 40/97, Loss: 0.1400
Epoch 5/10, Batch 50/97, Loss: 0.2838
Epoch 5/10, Batch 60/97, Loss: 0.1377
Epoch 5/10, Batch 70/97, Loss: 0.1288
Epoch 5/10, Batch 80/97, Loss: 0.3590
Epoch 5/10, Batch 90/97, Loss: 0.3749
Epoch 5/10, Train Loss: 0.2557, Valid Loss: 0.2861
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3085
Epoch 6/10, Batch 20/97, Loss: 0.5147
Epoch 6/10, Batch 30/97, Loss: 0.2560
Epoch 6/10, Batch 40/97, Loss: 0.2355
Epoch 6/10, Batch 50/97, Loss: 0.2071
Epoch 6/10, Batch 60/97, Loss: 0.3126
Epoch 6/10, Batch 70/97, Loss: 0.1997
Epoch 6/10, Batch 80/97, Loss: 0.1782
Epoch 6/10, Batch 90/97, Loss: 0.2082
Epoch 6/10, Train Loss: 0.2383, Valid Loss: 0.2811
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2584
Epoch 7/10, Batch 20/97, Loss: 0.1180
Epoch 7/10, Batch 30/97, Loss: 0.1203
Epoch 7/10, Batch 40/97, Loss: 0.1307
Epoch 7/10, Batch 50/97, Loss: 0.2319
Epoch 7/10, Batch 60/97, Loss: 0.1773
Epoch 7/10, Batch 70/97, Loss: 0.1492
Epoch 7/10, Batch 80/97, Loss: 0.2110
Epoch 7/10, Batch 90/97, Loss: 0.1754
Epoch 7/10, Train Loss: 0.2408, Valid Loss: 0.2614
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1849
Epoch 8/10, Batch 20/97, Loss: 0.1635
Epoch 8/10, Batch 30/97, Loss: 0.1486
Epoch 8/10, Batch 40/97, Loss: 0.1067
Epoch 8/10, Batch 50/97, Loss: 0.2450
Epoch 8/10, Batch 60/97, Loss: 0.1115
Epoch 8/10, Batch 70/97, Loss: 0.2296
Epoch 8/10, Batch 80/97, Loss: 0.0367
Epoch 8/10, Batch 90/97, Loss: 0.2125
Epoch 8/10, Train Loss: 0.2198, Valid Loss: 0.2574
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1528
Epoch 9/10, Batch 20/97, Loss: 0.2223
Epoch 9/10, Batch 30/97, Loss: 0.1947
Epoch 9/10, Batch 40/97, Loss: 0.1622
Epoch 9/10, Batch 50/97, Loss: 0.1684
Epoch 9/10, Batch 60/97, Loss: 0.1818
Epoch 9/10, Batch 70/97, Loss: 0.1309
Epoch 9/10, Batch 80/97, Loss: 0.1979
Epoch 9/10, Batch 90/97, Loss: 0.1153
Epoch 9/10, Train Loss: 0.2090, Valid Loss: 0.2652
Epoch 10/10, Batch 10/97, Loss: 0.2347
Epoch 10/10, Batch 20/97, Loss: 0.0732
Epoch 10/10, Batch 30/97, Loss: 0.1151
Epoch 10/10, Batch 40/97, Loss: 0.1980
Epoch 10/10, Batch 50/97, Loss: 0.3544
Epoch 10/10, Batch 60/97, Loss: 0.1363
Epoch 10/10, Batch 70/97, Loss: 0.1596
Epoch 10/10, Batch 80/97, Loss: 0.2640
Epoch 10/10, Batch 90/97, Loss: 0.1420
Epoch 10/10, Train Loss: 0.1960, Valid Loss: 0.2561
Model saved!
Accuracy: 0.9171
Precision: 0.9158
Recall: 0.9171
F1-score: 0.9156
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4574
Epoch 1/10, Batch 20/97, Loss: 0.9971
Epoch 1/10, Batch 30/97, Loss: 0.9503
Epoch 1/10, Batch 40/97, Loss: 0.5879
Epoch 1/10, Batch 50/97, Loss: 0.7636
Epoch 1/10, Batch 60/97, Loss: 0.8185
Epoch 1/10, Batch 70/97, Loss: 0.5240
Epoch 1/10, Batch 80/97, Loss: 0.4311
Epoch 1/10, Batch 90/97, Loss: 0.5360
Epoch 1/10, Train Loss: 0.7780, Valid Loss: 0.4365
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4089
Epoch 2/10, Batch 20/97, Loss: 0.4743
Epoch 2/10, Batch 30/97, Loss: 0.3289
Epoch 2/10, Batch 40/97, Loss: 0.5025
Epoch 2/10, Batch 50/97, Loss: 0.5887
Epoch 2/10, Batch 60/97, Loss: 0.3740
Epoch 2/10, Batch 70/97, Loss: 0.2781
Epoch 2/10, Batch 80/97, Loss: 0.2625
Epoch 2/10, Batch 90/97, Loss: 0.3794
Epoch 2/10, Train Loss: 0.3908, Valid Loss: 0.3385
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3940
Epoch 3/10, Batch 20/97, Loss: 0.2704
Epoch 3/10, Batch 30/97, Loss: 0.2691
Epoch 3/10, Batch 40/97, Loss: 0.3846
Epoch 3/10, Batch 50/97, Loss: 0.3005
Epoch 3/10, Batch 60/97, Loss: 0.3165
Epoch 3/10, Batch 70/97, Loss: 0.2619
Epoch 3/10, Batch 80/97, Loss: 0.2238
Epoch 3/10, Batch 90/97, Loss: 0.2623
Epoch 3/10, Train Loss: 0.3191, Valid Loss: 0.3001
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3651
Epoch 4/10, Batch 20/97, Loss: 0.1952
Epoch 4/10, Batch 30/97, Loss: 0.3290
Epoch 4/10, Batch 40/97, Loss: 0.2406
Epoch 4/10, Batch 50/97, Loss: 0.1886
Epoch 4/10, Batch 60/97, Loss: 0.1366
Epoch 4/10, Batch 70/97, Loss: 0.1432
Epoch 4/10, Batch 80/97, Loss: 0.1996
Epoch 4/10, Batch 90/97, Loss: 0.3554
Epoch 4/10, Train Loss: 0.2843, Valid Loss: 0.2798
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2279
Epoch 5/10, Batch 20/97, Loss: 0.2001
Epoch 5/10, Batch 30/97, Loss: 0.1778
Epoch 5/10, Batch 40/97, Loss: 0.1552
Epoch 5/10, Batch 50/97, Loss: 0.2971
Epoch 5/10, Batch 60/97, Loss: 0.2153
Epoch 5/10, Batch 70/97, Loss: 0.2162
Epoch 5/10, Batch 80/97, Loss: 0.2391
Epoch 5/10, Batch 90/97, Loss: 0.2120
Epoch 5/10, Train Loss: 0.2616, Valid Loss: 0.2716
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2419
Epoch 6/10, Batch 20/97, Loss: 0.2867
Epoch 6/10, Batch 30/97, Loss: 0.1888
Epoch 6/10, Batch 40/97, Loss: 0.2452
Epoch 6/10, Batch 50/97, Loss: 0.2211
Epoch 6/10, Batch 60/97, Loss: 0.2209
Epoch 6/10, Batch 70/97, Loss: 0.2381
Epoch 6/10, Batch 80/97, Loss: 0.2497
Epoch 6/10, Batch 90/97, Loss: 0.2860
Epoch 6/10, Train Loss: 0.2440, Valid Loss: 0.2583
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2440
Epoch 7/10, Batch 20/97, Loss: 0.1109
Epoch 7/10, Batch 30/97, Loss: 0.4514
Epoch 7/10, Batch 40/97, Loss: 0.2333
Epoch 7/10, Batch 50/97, Loss: 0.2776
Epoch 7/10, Batch 60/97, Loss: 0.2636
Epoch 7/10, Batch 70/97, Loss: 0.1863
Epoch 7/10, Batch 80/97, Loss: 0.3375
Epoch 7/10, Batch 90/97, Loss: 0.2016
Epoch 7/10, Train Loss: 0.2470, Valid Loss: 0.2496
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1741
Epoch 8/10, Batch 20/97, Loss: 0.2049
Epoch 8/10, Batch 30/97, Loss: 0.1266
Epoch 8/10, Batch 40/97, Loss: 0.1447
Epoch 8/10, Batch 50/97, Loss: 0.1677
Epoch 8/10, Batch 60/97, Loss: 0.2134
Epoch 8/10, Batch 70/97, Loss: 0.3379
Epoch 8/10, Batch 80/97, Loss: 0.1625
Epoch 8/10, Batch 90/97, Loss: 0.1646
Epoch 8/10, Train Loss: 0.2270, Valid Loss: 0.2648
Epoch 9/10, Batch 10/97, Loss: 0.1811
Epoch 9/10, Batch 20/97, Loss: 0.0678
Epoch 9/10, Batch 30/97, Loss: 0.2488
Epoch 9/10, Batch 40/97, Loss: 0.1966
Epoch 9/10, Batch 50/97, Loss: 0.1820
Epoch 9/10, Batch 60/97, Loss: 0.1724
Epoch 9/10, Batch 70/97, Loss: 0.0930
Epoch 9/10, Batch 80/97, Loss: 0.1438
Epoch 9/10, Batch 90/97, Loss: 0.3837
Epoch 9/10, Train Loss: 0.2126, Valid Loss: 0.2519
Epoch 10/10, Batch 10/97, Loss: 0.1687
Epoch 10/10, Batch 20/97, Loss: 0.1286
Epoch 10/10, Batch 30/97, Loss: 0.2406
Epoch 10/10, Batch 40/97, Loss: 0.2415
Epoch 10/10, Batch 50/97, Loss: 0.3719
Epoch 10/10, Batch 60/97, Loss: 0.1619
Epoch 10/10, Batch 70/97, Loss: 0.2684
Epoch 10/10, Batch 80/97, Loss: 0.2314
Epoch 10/10, Batch 90/97, Loss: 0.0765
Epoch 10/10, Train Loss: 0.2009, Valid Loss: 0.2388
Model saved!
Accuracy: 0.9159
Precision: 0.9133
Recall: 0.9159
F1-score: 0.9138
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5399
Epoch 1/10, Batch 20/97, Loss: 1.0270
Epoch 1/10, Batch 30/97, Loss: 0.8419
Epoch 1/10, Batch 40/97, Loss: 0.7155
Epoch 1/10, Batch 50/97, Loss: 0.5055
Epoch 1/10, Batch 60/97, Loss: 0.5516
Epoch 1/10, Batch 70/97, Loss: 0.6050
Epoch 1/10, Batch 80/97, Loss: 0.4286
Epoch 1/10, Batch 90/97, Loss: 0.4463
Epoch 1/10, Train Loss: 0.7686, Valid Loss: 0.4347
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4141
Epoch 2/10, Batch 20/97, Loss: 0.5512
Epoch 2/10, Batch 30/97, Loss: 0.4369
Epoch 2/10, Batch 40/97, Loss: 0.5787
Epoch 2/10, Batch 50/97, Loss: 0.5436
Epoch 2/10, Batch 60/97, Loss: 0.3985
Epoch 2/10, Batch 70/97, Loss: 0.3148
Epoch 2/10, Batch 80/97, Loss: 0.2968
Epoch 2/10, Batch 90/97, Loss: 0.3439
Epoch 2/10, Train Loss: 0.3838, Valid Loss: 0.3335
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3791
Epoch 3/10, Batch 20/97, Loss: 0.2967
Epoch 3/10, Batch 30/97, Loss: 0.2962
Epoch 3/10, Batch 40/97, Loss: 0.2072
Epoch 3/10, Batch 50/97, Loss: 0.2728
Epoch 3/10, Batch 60/97, Loss: 0.3104
Epoch 3/10, Batch 70/97, Loss: 0.2075
Epoch 3/10, Batch 80/97, Loss: 0.2824
Epoch 3/10, Batch 90/97, Loss: 0.2215
Epoch 3/10, Train Loss: 0.3177, Valid Loss: 0.2845
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1735
Epoch 4/10, Batch 20/97, Loss: 0.1750
Epoch 4/10, Batch 30/97, Loss: 0.2501
Epoch 4/10, Batch 40/97, Loss: 0.2486
Epoch 4/10, Batch 50/97, Loss: 0.2389
Epoch 4/10, Batch 60/97, Loss: 0.2098
Epoch 4/10, Batch 70/97, Loss: 0.3349
Epoch 4/10, Batch 80/97, Loss: 0.4550
Epoch 4/10, Batch 90/97, Loss: 0.3125
Epoch 4/10, Train Loss: 0.2831, Valid Loss: 0.2650
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3100
Epoch 5/10, Batch 20/97, Loss: 0.1629
Epoch 5/10, Batch 30/97, Loss: 0.1980
Epoch 5/10, Batch 40/97, Loss: 0.1959
Epoch 5/10, Batch 50/97, Loss: 0.1685
Epoch 5/10, Batch 60/97, Loss: 0.2509
Epoch 5/10, Batch 70/97, Loss: 0.2472
Epoch 5/10, Batch 80/97, Loss: 0.1764
Epoch 5/10, Batch 90/97, Loss: 0.4237
Epoch 5/10, Train Loss: 0.2540, Valid Loss: 0.2512
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2805
Epoch 6/10, Batch 20/97, Loss: 0.2948
Epoch 6/10, Batch 30/97, Loss: 0.1803
Epoch 6/10, Batch 40/97, Loss: 0.2630
Epoch 6/10, Batch 50/97, Loss: 0.1412
Epoch 6/10, Batch 60/97, Loss: 0.1948
Epoch 6/10, Batch 70/97, Loss: 0.1644
Epoch 6/10, Batch 80/97, Loss: 0.2096
Epoch 6/10, Batch 90/97, Loss: 0.1734
Epoch 6/10, Train Loss: 0.2366, Valid Loss: 0.2436
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3296
Epoch 7/10, Batch 20/97, Loss: 0.1914
Epoch 7/10, Batch 30/97, Loss: 0.2313
Epoch 7/10, Batch 40/97, Loss: 0.2892
Epoch 7/10, Batch 50/97, Loss: 0.2882
Epoch 7/10, Batch 60/97, Loss: 0.3387
Epoch 7/10, Batch 70/97, Loss: 0.1543
Epoch 7/10, Batch 80/97, Loss: 0.1566
Epoch 7/10, Batch 90/97, Loss: 0.2395
Epoch 7/10, Train Loss: 0.2396, Valid Loss: 0.2383
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1533
Epoch 8/10, Batch 20/97, Loss: 0.1440
Epoch 8/10, Batch 30/97, Loss: 0.1728
Epoch 8/10, Batch 40/97, Loss: 0.1683
Epoch 8/10, Batch 50/97, Loss: 0.1838
Epoch 8/10, Batch 60/97, Loss: 0.1254
Epoch 8/10, Batch 70/97, Loss: 0.2487
Epoch 8/10, Batch 80/97, Loss: 0.2053
Epoch 8/10, Batch 90/97, Loss: 0.1130
Epoch 8/10, Train Loss: 0.2150, Valid Loss: 0.2276
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.3189
Epoch 9/10, Batch 20/97, Loss: 0.1315
Epoch 9/10, Batch 30/97, Loss: 0.2192
Epoch 9/10, Batch 40/97, Loss: 0.2165
Epoch 9/10, Batch 50/97, Loss: 0.2972
Epoch 9/10, Batch 60/97, Loss: 0.1965
Epoch 9/10, Batch 70/97, Loss: 0.1472
Epoch 9/10, Batch 80/97, Loss: 0.2287
Epoch 9/10, Batch 90/97, Loss: 0.2484
Epoch 9/10, Train Loss: 0.2008, Valid Loss: 0.2294
Epoch 10/10, Batch 10/97, Loss: 0.1655
Epoch 10/10, Batch 20/97, Loss: 0.1253
Epoch 10/10, Batch 30/97, Loss: 0.3483
Epoch 10/10, Batch 40/97, Loss: 0.1437
Epoch 10/10, Batch 50/97, Loss: 0.3369
Epoch 10/10, Batch 60/97, Loss: 0.1960
Epoch 10/10, Batch 70/97, Loss: 0.2454
Epoch 10/10, Batch 80/97, Loss: 0.1685
Epoch 10/10, Batch 90/97, Loss: 0.1615
Epoch 10/10, Train Loss: 0.1905, Valid Loss: 0.2194
Model saved!
Accuracy: 0.9100
Precision: 0.9064
Recall: 0.9100
F1-score: 0.9074
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5086
Epoch 1/10, Batch 20/97, Loss: 1.0132
Epoch 1/10, Batch 30/97, Loss: 0.8330
Epoch 1/10, Batch 40/97, Loss: 0.7861
Epoch 1/10, Batch 50/97, Loss: 0.6283
Epoch 1/10, Batch 60/97, Loss: 0.7768
Epoch 1/10, Batch 70/97, Loss: 0.4840
Epoch 1/10, Batch 80/97, Loss: 0.4150
Epoch 1/10, Batch 90/97, Loss: 0.5576
Epoch 1/10, Train Loss: 0.7681, Valid Loss: 0.4364
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3362
Epoch 2/10, Batch 20/97, Loss: 0.5121
Epoch 2/10, Batch 30/97, Loss: 0.3502
Epoch 2/10, Batch 40/97, Loss: 0.4642
Epoch 2/10, Batch 50/97, Loss: 0.5276
Epoch 2/10, Batch 60/97, Loss: 0.4620
Epoch 2/10, Batch 70/97, Loss: 0.2689
Epoch 2/10, Batch 80/97, Loss: 0.3369
Epoch 2/10, Batch 90/97, Loss: 0.3795
Epoch 2/10, Train Loss: 0.3928, Valid Loss: 0.3348
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3430
Epoch 3/10, Batch 20/97, Loss: 0.2838
Epoch 3/10, Batch 30/97, Loss: 0.1933
Epoch 3/10, Batch 40/97, Loss: 0.1928
Epoch 3/10, Batch 50/97, Loss: 0.2890
Epoch 3/10, Batch 60/97, Loss: 0.3287
Epoch 3/10, Batch 70/97, Loss: 0.2759
Epoch 3/10, Batch 80/97, Loss: 0.2108
Epoch 3/10, Batch 90/97, Loss: 0.2524
Epoch 3/10, Train Loss: 0.3158, Valid Loss: 0.2884
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3066
Epoch 4/10, Batch 20/97, Loss: 0.1517
Epoch 4/10, Batch 30/97, Loss: 0.4053
Epoch 4/10, Batch 40/97, Loss: 0.2495
Epoch 4/10, Batch 50/97, Loss: 0.3113
Epoch 4/10, Batch 60/97, Loss: 0.1447
Epoch 4/10, Batch 70/97, Loss: 0.1605
Epoch 4/10, Batch 80/97, Loss: 0.3157
Epoch 4/10, Batch 90/97, Loss: 0.2966
Epoch 4/10, Train Loss: 0.2852, Valid Loss: 0.2686
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2866
Epoch 5/10, Batch 20/97, Loss: 0.1361
Epoch 5/10, Batch 30/97, Loss: 0.1604
Epoch 5/10, Batch 40/97, Loss: 0.1916
Epoch 5/10, Batch 50/97, Loss: 0.1531
Epoch 5/10, Batch 60/97, Loss: 0.1975
Epoch 5/10, Batch 70/97, Loss: 0.2706
Epoch 5/10, Batch 80/97, Loss: 0.2801
Epoch 5/10, Batch 90/97, Loss: 0.3340
Epoch 5/10, Train Loss: 0.2559, Valid Loss: 0.2545
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2270
Epoch 6/10, Batch 20/97, Loss: 0.2576
Epoch 6/10, Batch 30/97, Loss: 0.1982
Epoch 6/10, Batch 40/97, Loss: 0.2365
Epoch 6/10, Batch 50/97, Loss: 0.2375
Epoch 6/10, Batch 60/97, Loss: 0.2371
Epoch 6/10, Batch 70/97, Loss: 0.2411
Epoch 6/10, Batch 80/97, Loss: 0.2846
Epoch 6/10, Batch 90/97, Loss: 0.1986
Epoch 6/10, Train Loss: 0.2370, Valid Loss: 0.2490
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2720
Epoch 7/10, Batch 20/97, Loss: 0.1284
Epoch 7/10, Batch 30/97, Loss: 0.1424
Epoch 7/10, Batch 40/97, Loss: 0.3169
Epoch 7/10, Batch 50/97, Loss: 0.2826
Epoch 7/10, Batch 60/97, Loss: 0.3340
Epoch 7/10, Batch 70/97, Loss: 0.1671
Epoch 7/10, Batch 80/97, Loss: 0.1846
Epoch 7/10, Batch 90/97, Loss: 0.2271
Epoch 7/10, Train Loss: 0.2460, Valid Loss: 0.2365
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.3042
Epoch 8/10, Batch 20/97, Loss: 0.2296
Epoch 8/10, Batch 30/97, Loss: 0.1300
Epoch 8/10, Batch 40/97, Loss: 0.1515
Epoch 8/10, Batch 50/97, Loss: 0.2001
Epoch 8/10, Batch 60/97, Loss: 0.1821
Epoch 8/10, Batch 70/97, Loss: 0.2181
Epoch 8/10, Batch 80/97, Loss: 0.0929
Epoch 8/10, Batch 90/97, Loss: 0.1751
Epoch 8/10, Train Loss: 0.2218, Valid Loss: 0.2367
Epoch 9/10, Batch 10/97, Loss: 0.0946
Epoch 9/10, Batch 20/97, Loss: 0.2382
Epoch 9/10, Batch 30/97, Loss: 0.3159
Epoch 9/10, Batch 40/97, Loss: 0.1556
Epoch 9/10, Batch 50/97, Loss: 0.1659
Epoch 9/10, Batch 60/97, Loss: 0.1351
Epoch 9/10, Batch 70/97, Loss: 0.1793
Epoch 9/10, Batch 80/97, Loss: 0.1380
Epoch 9/10, Batch 90/97, Loss: 0.1574
Epoch 9/10, Train Loss: 0.1991, Valid Loss: 0.2299
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3936
Epoch 10/10, Batch 20/97, Loss: 0.1800
Epoch 10/10, Batch 30/97, Loss: 0.2415
Epoch 10/10, Batch 40/97, Loss: 0.3169
Epoch 10/10, Batch 50/97, Loss: 0.3065
Epoch 10/10, Batch 60/97, Loss: 0.1809
Epoch 10/10, Batch 70/97, Loss: 0.2196
Epoch 10/10, Batch 80/97, Loss: 0.1228
Epoch 10/10, Batch 90/97, Loss: 0.3090
Epoch 10/10, Train Loss: 0.1989, Valid Loss: 0.2196
Model saved!
Accuracy: 0.9147
Precision: 0.9120
Recall: 0.9147
F1-score: 0.9127
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4736
Epoch 1/10, Batch 20/97, Loss: 1.0167
Epoch 1/10, Batch 30/97, Loss: 0.8455
Epoch 1/10, Batch 40/97, Loss: 0.7770
Epoch 1/10, Batch 50/97, Loss: 0.5431
Epoch 1/10, Batch 60/97, Loss: 0.7127
Epoch 1/10, Batch 70/97, Loss: 0.5635
Epoch 1/10, Batch 80/97, Loss: 0.4070
Epoch 1/10, Batch 90/97, Loss: 0.5333
Epoch 1/10, Train Loss: 0.7735, Valid Loss: 0.4188
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4051
Epoch 2/10, Batch 20/97, Loss: 0.3951
Epoch 2/10, Batch 30/97, Loss: 0.3429
Epoch 2/10, Batch 40/97, Loss: 0.3167
Epoch 2/10, Batch 50/97, Loss: 0.6058
Epoch 2/10, Batch 60/97, Loss: 0.3252
Epoch 2/10, Batch 70/97, Loss: 0.4238
Epoch 2/10, Batch 80/97, Loss: 0.3832
Epoch 2/10, Batch 90/97, Loss: 0.3727
Epoch 2/10, Train Loss: 0.3952, Valid Loss: 0.3075
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2914
Epoch 3/10, Batch 20/97, Loss: 0.3905
Epoch 3/10, Batch 30/97, Loss: 0.3585
Epoch 3/10, Batch 40/97, Loss: 0.2060
Epoch 3/10, Batch 50/97, Loss: 0.3444
Epoch 3/10, Batch 60/97, Loss: 0.2322
Epoch 3/10, Batch 70/97, Loss: 0.2526
Epoch 3/10, Batch 80/97, Loss: 0.2788
Epoch 3/10, Batch 90/97, Loss: 0.3197
Epoch 3/10, Train Loss: 0.3275, Valid Loss: 0.2710
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3661
Epoch 4/10, Batch 20/97, Loss: 0.2598
Epoch 4/10, Batch 30/97, Loss: 0.3156
Epoch 4/10, Batch 40/97, Loss: 0.2829
Epoch 4/10, Batch 50/97, Loss: 0.3120
Epoch 4/10, Batch 60/97, Loss: 0.1896
Epoch 4/10, Batch 70/97, Loss: 0.3486
Epoch 4/10, Batch 80/97, Loss: 0.2748
Epoch 4/10, Batch 90/97, Loss: 0.3482
Epoch 4/10, Train Loss: 0.2854, Valid Loss: 0.2504
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1678
Epoch 5/10, Batch 20/97, Loss: 0.3471
Epoch 5/10, Batch 30/97, Loss: 0.1229
Epoch 5/10, Batch 40/97, Loss: 0.0924
Epoch 5/10, Batch 50/97, Loss: 0.2049
Epoch 5/10, Batch 60/97, Loss: 0.3177
Epoch 5/10, Batch 70/97, Loss: 0.1852
Epoch 5/10, Batch 80/97, Loss: 0.2756
Epoch 5/10, Batch 90/97, Loss: 0.3071
Epoch 5/10, Train Loss: 0.2632, Valid Loss: 0.2356
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1939
Epoch 6/10, Batch 20/97, Loss: 0.2899
Epoch 6/10, Batch 30/97, Loss: 0.2189
Epoch 6/10, Batch 40/97, Loss: 0.2825
Epoch 6/10, Batch 50/97, Loss: 0.1866
Epoch 6/10, Batch 60/97, Loss: 0.2924
Epoch 6/10, Batch 70/97, Loss: 0.3058
Epoch 6/10, Batch 80/97, Loss: 0.2298
Epoch 6/10, Batch 90/97, Loss: 0.1888
Epoch 6/10, Train Loss: 0.2421, Valid Loss: 0.2270
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3602
Epoch 7/10, Batch 20/97, Loss: 0.1999
Epoch 7/10, Batch 30/97, Loss: 0.1851
Epoch 7/10, Batch 40/97, Loss: 0.2448
Epoch 7/10, Batch 50/97, Loss: 0.1869
Epoch 7/10, Batch 60/97, Loss: 0.2737
Epoch 7/10, Batch 70/97, Loss: 0.2252
Epoch 7/10, Batch 80/97, Loss: 0.2669
Epoch 7/10, Batch 90/97, Loss: 0.2585
Epoch 7/10, Train Loss: 0.2441, Valid Loss: 0.2151
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1698
Epoch 8/10, Batch 20/97, Loss: 0.2038
Epoch 8/10, Batch 30/97, Loss: 0.0874
Epoch 8/10, Batch 40/97, Loss: 0.2122
Epoch 8/10, Batch 50/97, Loss: 0.2972
Epoch 8/10, Batch 60/97, Loss: 0.0974
Epoch 8/10, Batch 70/97, Loss: 0.2229
Epoch 8/10, Batch 80/97, Loss: 0.2593
Epoch 8/10, Batch 90/97, Loss: 0.1209
Epoch 8/10, Train Loss: 0.2217, Valid Loss: 0.2091
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0938
Epoch 9/10, Batch 20/97, Loss: 0.0870
Epoch 9/10, Batch 30/97, Loss: 0.2667
Epoch 9/10, Batch 40/97, Loss: 0.1301
Epoch 9/10, Batch 50/97, Loss: 0.2234
Epoch 9/10, Batch 60/97, Loss: 0.1994
Epoch 9/10, Batch 70/97, Loss: 0.3281
Epoch 9/10, Batch 80/97, Loss: 0.1706
Epoch 9/10, Batch 90/97, Loss: 0.1899
Epoch 9/10, Train Loss: 0.2132, Valid Loss: 0.2134
Epoch 10/10, Batch 10/97, Loss: 0.2384
Epoch 10/10, Batch 20/97, Loss: 0.1942
Epoch 10/10, Batch 30/97, Loss: 0.3206
Epoch 10/10, Batch 40/97, Loss: 0.2495
Epoch 10/10, Batch 50/97, Loss: 0.1822
Epoch 10/10, Batch 60/97, Loss: 0.1495
Epoch 10/10, Batch 70/97, Loss: 0.1633
Epoch 10/10, Batch 80/97, Loss: 0.2312
Epoch 10/10, Batch 90/97, Loss: 0.2356
Epoch 10/10, Train Loss: 0.1989, Valid Loss: 0.2012
Model saved!
Accuracy: 0.9194
Precision: 0.9170
Recall: 0.9194
F1-score: 0.9173
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4639
Epoch 1/10, Batch 20/97, Loss: 1.0355
Epoch 1/10, Batch 30/97, Loss: 0.8432
Epoch 1/10, Batch 40/97, Loss: 0.7657
Epoch 1/10, Batch 50/97, Loss: 0.6828
Epoch 1/10, Batch 60/97, Loss: 0.5048
Epoch 1/10, Batch 70/97, Loss: 0.5535
Epoch 1/10, Batch 80/97, Loss: 0.4938
Epoch 1/10, Batch 90/97, Loss: 0.4943
Epoch 1/10, Train Loss: 0.7838, Valid Loss: 0.4221
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.6002
Epoch 2/10, Batch 20/97, Loss: 0.5210
Epoch 2/10, Batch 30/97, Loss: 0.3125
Epoch 2/10, Batch 40/97, Loss: 0.4122
Epoch 2/10, Batch 50/97, Loss: 0.6178
Epoch 2/10, Batch 60/97, Loss: 0.3864
Epoch 2/10, Batch 70/97, Loss: 0.2946
Epoch 2/10, Batch 80/97, Loss: 0.3489
Epoch 2/10, Batch 90/97, Loss: 0.4332
Epoch 2/10, Train Loss: 0.4025, Valid Loss: 0.3260
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3539
Epoch 3/10, Batch 20/97, Loss: 0.3075
Epoch 3/10, Batch 30/97, Loss: 0.2267
Epoch 3/10, Batch 40/97, Loss: 0.3279
Epoch 3/10, Batch 50/97, Loss: 0.2654
Epoch 3/10, Batch 60/97, Loss: 0.2365
Epoch 3/10, Batch 70/97, Loss: 0.2453
Epoch 3/10, Batch 80/97, Loss: 0.4572
Epoch 3/10, Batch 90/97, Loss: 0.2219
Epoch 3/10, Train Loss: 0.3186, Valid Loss: 0.2866
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2895
Epoch 4/10, Batch 20/97, Loss: 0.3067
Epoch 4/10, Batch 30/97, Loss: 0.3138
Epoch 4/10, Batch 40/97, Loss: 0.3505
Epoch 4/10, Batch 50/97, Loss: 0.2077
Epoch 4/10, Batch 60/97, Loss: 0.2420
Epoch 4/10, Batch 70/97, Loss: 0.2035
Epoch 4/10, Batch 80/97, Loss: 0.3422
Epoch 4/10, Batch 90/97, Loss: 0.2656
Epoch 4/10, Train Loss: 0.2926, Valid Loss: 0.2685
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2568
Epoch 5/10, Batch 20/97, Loss: 0.2063
Epoch 5/10, Batch 30/97, Loss: 0.1933
Epoch 5/10, Batch 40/97, Loss: 0.1129
Epoch 5/10, Batch 50/97, Loss: 0.2262
Epoch 5/10, Batch 60/97, Loss: 0.4377
Epoch 5/10, Batch 70/97, Loss: 0.2166
Epoch 5/10, Batch 80/97, Loss: 0.1860
Epoch 5/10, Batch 90/97, Loss: 0.3880
Epoch 5/10, Train Loss: 0.2547, Valid Loss: 0.2541
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2141
Epoch 6/10, Batch 20/97, Loss: 0.1743
Epoch 6/10, Batch 30/97, Loss: 0.2056
Epoch 6/10, Batch 40/97, Loss: 0.3593
Epoch 6/10, Batch 50/97, Loss: 0.1906
Epoch 6/10, Batch 60/97, Loss: 0.4555
Epoch 6/10, Batch 70/97, Loss: 0.2891
Epoch 6/10, Batch 80/97, Loss: 0.2594
Epoch 6/10, Batch 90/97, Loss: 0.1841
Epoch 6/10, Train Loss: 0.2454, Valid Loss: 0.2433
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3090
Epoch 7/10, Batch 20/97, Loss: 0.1283
Epoch 7/10, Batch 30/97, Loss: 0.1278
Epoch 7/10, Batch 40/97, Loss: 0.2060
Epoch 7/10, Batch 50/97, Loss: 0.1099
Epoch 7/10, Batch 60/97, Loss: 0.2315
Epoch 7/10, Batch 70/97, Loss: 0.1657
Epoch 7/10, Batch 80/97, Loss: 0.2809
Epoch 7/10, Batch 90/97, Loss: 0.2940
Epoch 7/10, Train Loss: 0.2434, Valid Loss: 0.2375
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1600
Epoch 8/10, Batch 20/97, Loss: 0.1597
Epoch 8/10, Batch 30/97, Loss: 0.2284
Epoch 8/10, Batch 40/97, Loss: 0.1388
Epoch 8/10, Batch 50/97, Loss: 0.1682
Epoch 8/10, Batch 60/97, Loss: 0.1240
Epoch 8/10, Batch 70/97, Loss: 0.2856
Epoch 8/10, Batch 80/97, Loss: 0.1154
Epoch 8/10, Batch 90/97, Loss: 0.2055
Epoch 8/10, Train Loss: 0.2205, Valid Loss: 0.2341
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1418
Epoch 9/10, Batch 20/97, Loss: 0.1661
Epoch 9/10, Batch 30/97, Loss: 0.2930
Epoch 9/10, Batch 40/97, Loss: 0.1003
Epoch 9/10, Batch 50/97, Loss: 0.3111
Epoch 9/10, Batch 60/97, Loss: 0.1982
Epoch 9/10, Batch 70/97, Loss: 0.0985
Epoch 9/10, Batch 80/97, Loss: 0.2164
Epoch 9/10, Batch 90/97, Loss: 0.3022
Epoch 9/10, Train Loss: 0.2079, Valid Loss: 0.2334
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2660
Epoch 10/10, Batch 20/97, Loss: 0.1312
Epoch 10/10, Batch 30/97, Loss: 0.1370
Epoch 10/10, Batch 40/97, Loss: 0.2442
Epoch 10/10, Batch 50/97, Loss: 0.2425
Epoch 10/10, Batch 60/97, Loss: 0.1726
Epoch 10/10, Batch 70/97, Loss: 0.2553
Epoch 10/10, Batch 80/97, Loss: 0.0876
Epoch 10/10, Batch 90/97, Loss: 0.0949
Epoch 10/10, Train Loss: 0.1980, Valid Loss: 0.2279
Model saved!
Accuracy: 0.9206
Precision: 0.9178
Recall: 0.9206
F1-score: 0.9188
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4618
Epoch 1/10, Batch 20/97, Loss: 1.0006
Epoch 1/10, Batch 30/97, Loss: 0.8916
Epoch 1/10, Batch 40/97, Loss: 0.7452
Epoch 1/10, Batch 50/97, Loss: 0.5943
Epoch 1/10, Batch 60/97, Loss: 0.5485
Epoch 1/10, Batch 70/97, Loss: 0.4904
Epoch 1/10, Batch 80/97, Loss: 0.4299
Epoch 1/10, Batch 90/97, Loss: 0.5722
Epoch 1/10, Train Loss: 0.7738, Valid Loss: 0.4238
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4124
Epoch 2/10, Batch 20/97, Loss: 0.5358
Epoch 2/10, Batch 30/97, Loss: 0.3141
Epoch 2/10, Batch 40/97, Loss: 0.3790
Epoch 2/10, Batch 50/97, Loss: 0.5653
Epoch 2/10, Batch 60/97, Loss: 0.3855
Epoch 2/10, Batch 70/97, Loss: 0.3812
Epoch 2/10, Batch 80/97, Loss: 0.2906
Epoch 2/10, Batch 90/97, Loss: 0.3505
Epoch 2/10, Train Loss: 0.3947, Valid Loss: 0.3171
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3534
Epoch 3/10, Batch 20/97, Loss: 0.4383
Epoch 3/10, Batch 30/97, Loss: 0.3232
Epoch 3/10, Batch 40/97, Loss: 0.3830
Epoch 3/10, Batch 50/97, Loss: 0.4617
Epoch 3/10, Batch 60/97, Loss: 0.3341
Epoch 3/10, Batch 70/97, Loss: 0.2754
Epoch 3/10, Batch 80/97, Loss: 0.1872
Epoch 3/10, Batch 90/97, Loss: 0.1687
Epoch 3/10, Train Loss: 0.3309, Valid Loss: 0.2715
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3701
Epoch 4/10, Batch 20/97, Loss: 0.3416
Epoch 4/10, Batch 30/97, Loss: 0.3448
Epoch 4/10, Batch 40/97, Loss: 0.2499
Epoch 4/10, Batch 50/97, Loss: 0.2215
Epoch 4/10, Batch 60/97, Loss: 0.1228
Epoch 4/10, Batch 70/97, Loss: 0.2135
Epoch 4/10, Batch 80/97, Loss: 0.1654
Epoch 4/10, Batch 90/97, Loss: 0.2899
Epoch 4/10, Train Loss: 0.2940, Valid Loss: 0.2531
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3806
Epoch 5/10, Batch 20/97, Loss: 0.1703
Epoch 5/10, Batch 30/97, Loss: 0.1890
Epoch 5/10, Batch 40/97, Loss: 0.1840
Epoch 5/10, Batch 50/97, Loss: 0.2403
Epoch 5/10, Batch 60/97, Loss: 0.1209
Epoch 5/10, Batch 70/97, Loss: 0.2535
Epoch 5/10, Batch 80/97, Loss: 0.2425
Epoch 5/10, Batch 90/97, Loss: 0.2241
Epoch 5/10, Train Loss: 0.2696, Valid Loss: 0.2409
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3371
Epoch 6/10, Batch 20/97, Loss: 0.2269
Epoch 6/10, Batch 30/97, Loss: 0.2346
Epoch 6/10, Batch 40/97, Loss: 0.2313
Epoch 6/10, Batch 50/97, Loss: 0.1575
Epoch 6/10, Batch 60/97, Loss: 0.2422
Epoch 6/10, Batch 70/97, Loss: 0.1735
Epoch 6/10, Batch 80/97, Loss: 0.2763
Epoch 6/10, Batch 90/97, Loss: 0.1884
Epoch 6/10, Train Loss: 0.2506, Valid Loss: 0.2277
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2470
Epoch 7/10, Batch 20/97, Loss: 0.0952
Epoch 7/10, Batch 30/97, Loss: 0.2953
Epoch 7/10, Batch 40/97, Loss: 0.2844
Epoch 7/10, Batch 50/97, Loss: 0.1959
Epoch 7/10, Batch 60/97, Loss: 0.2814
Epoch 7/10, Batch 70/97, Loss: 0.2261
Epoch 7/10, Batch 80/97, Loss: 0.1170
Epoch 7/10, Batch 90/97, Loss: 0.3494
Epoch 7/10, Train Loss: 0.2503, Valid Loss: 0.2223
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1073
Epoch 8/10, Batch 20/97, Loss: 0.2529
Epoch 8/10, Batch 30/97, Loss: 0.1514
Epoch 8/10, Batch 40/97, Loss: 0.2017
Epoch 8/10, Batch 50/97, Loss: 0.2231
Epoch 8/10, Batch 60/97, Loss: 0.1156
Epoch 8/10, Batch 70/97, Loss: 0.2555
Epoch 8/10, Batch 80/97, Loss: 0.2317
Epoch 8/10, Batch 90/97, Loss: 0.1858
Epoch 8/10, Train Loss: 0.2300, Valid Loss: 0.2190
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1224
Epoch 9/10, Batch 20/97, Loss: 0.1887
Epoch 9/10, Batch 30/97, Loss: 0.3305
Epoch 9/10, Batch 40/97, Loss: 0.1168
Epoch 9/10, Batch 50/97, Loss: 0.1862
Epoch 9/10, Batch 60/97, Loss: 0.1669
Epoch 9/10, Batch 70/97, Loss: 0.1312
Epoch 9/10, Batch 80/97, Loss: 0.0912
Epoch 9/10, Batch 90/97, Loss: 0.1644
Epoch 9/10, Train Loss: 0.2055, Valid Loss: 0.2099
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2492
Epoch 10/10, Batch 20/97, Loss: 0.1015
Epoch 10/10, Batch 30/97, Loss: 0.1436
Epoch 10/10, Batch 40/97, Loss: 0.1388
Epoch 10/10, Batch 50/97, Loss: 0.1324
Epoch 10/10, Batch 60/97, Loss: 0.1554
Epoch 10/10, Batch 70/97, Loss: 0.1381
Epoch 10/10, Batch 80/97, Loss: 0.1687
Epoch 10/10, Batch 90/97, Loss: 0.1990
Epoch 10/10, Train Loss: 0.2005, Valid Loss: 0.2070
Model saved!
Accuracy: 0.9171
Precision: 0.9151
Recall: 0.9171
F1-score: 0.9152
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4363
Epoch 1/10, Batch 20/97, Loss: 1.0283
Epoch 1/10, Batch 30/97, Loss: 0.9014
Epoch 1/10, Batch 40/97, Loss: 0.6761
Epoch 1/10, Batch 50/97, Loss: 0.6731
Epoch 1/10, Batch 60/97, Loss: 0.5900
Epoch 1/10, Batch 70/97, Loss: 0.4525
Epoch 1/10, Batch 80/97, Loss: 0.6149
Epoch 1/10, Batch 90/97, Loss: 0.6124
Epoch 1/10, Train Loss: 0.7654, Valid Loss: 0.4523
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4271
Epoch 2/10, Batch 20/97, Loss: 0.5130
Epoch 2/10, Batch 30/97, Loss: 0.2654
Epoch 2/10, Batch 40/97, Loss: 0.4617
Epoch 2/10, Batch 50/97, Loss: 0.6373
Epoch 2/10, Batch 60/97, Loss: 0.2977
Epoch 2/10, Batch 70/97, Loss: 0.2513
Epoch 2/10, Batch 80/97, Loss: 0.3750
Epoch 2/10, Batch 90/97, Loss: 0.2777
Epoch 2/10, Train Loss: 0.3930, Valid Loss: 0.3381
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4746
Epoch 3/10, Batch 20/97, Loss: 0.2871
Epoch 3/10, Batch 30/97, Loss: 0.2662
Epoch 3/10, Batch 40/97, Loss: 0.4083
Epoch 3/10, Batch 50/97, Loss: 0.2599
Epoch 3/10, Batch 60/97, Loss: 0.1944
Epoch 3/10, Batch 70/97, Loss: 0.3461
Epoch 3/10, Batch 80/97, Loss: 0.3234
Epoch 3/10, Batch 90/97, Loss: 0.2225
Epoch 3/10, Train Loss: 0.3225, Valid Loss: 0.2985
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2456
Epoch 4/10, Batch 20/97, Loss: 0.3715
Epoch 4/10, Batch 30/97, Loss: 0.3024
Epoch 4/10, Batch 40/97, Loss: 0.3326
Epoch 4/10, Batch 50/97, Loss: 0.2298
Epoch 4/10, Batch 60/97, Loss: 0.3058
Epoch 4/10, Batch 70/97, Loss: 0.2210
Epoch 4/10, Batch 80/97, Loss: 0.3621
Epoch 4/10, Batch 90/97, Loss: 0.2114
Epoch 4/10, Train Loss: 0.2788, Valid Loss: 0.2735
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2375
Epoch 5/10, Batch 20/97, Loss: 0.1545
Epoch 5/10, Batch 30/97, Loss: 0.1564
Epoch 5/10, Batch 40/97, Loss: 0.2162
Epoch 5/10, Batch 50/97, Loss: 0.2517
Epoch 5/10, Batch 60/97, Loss: 0.1114
Epoch 5/10, Batch 70/97, Loss: 0.2700
Epoch 5/10, Batch 80/97, Loss: 0.2193
Epoch 5/10, Batch 90/97, Loss: 0.4388
Epoch 5/10, Train Loss: 0.2470, Valid Loss: 0.2637
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2500
Epoch 6/10, Batch 20/97, Loss: 0.2000
Epoch 6/10, Batch 30/97, Loss: 0.0844
Epoch 6/10, Batch 40/97, Loss: 0.3735
Epoch 6/10, Batch 50/97, Loss: 0.2962
Epoch 6/10, Batch 60/97, Loss: 0.2421
Epoch 6/10, Batch 70/97, Loss: 0.2694
Epoch 6/10, Batch 80/97, Loss: 0.2119
Epoch 6/10, Batch 90/97, Loss: 0.2477
Epoch 6/10, Train Loss: 0.2407, Valid Loss: 0.2526
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3659
Epoch 7/10, Batch 20/97, Loss: 0.1330
Epoch 7/10, Batch 30/97, Loss: 0.1789
Epoch 7/10, Batch 40/97, Loss: 0.1529
Epoch 7/10, Batch 50/97, Loss: 0.1563
Epoch 7/10, Batch 60/97, Loss: 0.2550
Epoch 7/10, Batch 70/97, Loss: 0.2692
Epoch 7/10, Batch 80/97, Loss: 0.2672
Epoch 7/10, Batch 90/97, Loss: 0.2344
Epoch 7/10, Train Loss: 0.2396, Valid Loss: 0.2372
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2519
Epoch 8/10, Batch 20/97, Loss: 0.2142
Epoch 8/10, Batch 30/97, Loss: 0.1135
Epoch 8/10, Batch 40/97, Loss: 0.2490
Epoch 8/10, Batch 50/97, Loss: 0.3433
Epoch 8/10, Batch 60/97, Loss: 0.1432
Epoch 8/10, Batch 70/97, Loss: 0.2287
Epoch 8/10, Batch 80/97, Loss: 0.3220
Epoch 8/10, Batch 90/97, Loss: 0.2564
Epoch 8/10, Train Loss: 0.2159, Valid Loss: 0.2383
Epoch 9/10, Batch 10/97, Loss: 0.1324
Epoch 9/10, Batch 20/97, Loss: 0.1901
Epoch 9/10, Batch 30/97, Loss: 0.2039
Epoch 9/10, Batch 40/97, Loss: 0.0887
Epoch 9/10, Batch 50/97, Loss: 0.2275
Epoch 9/10, Batch 60/97, Loss: 0.1460
Epoch 9/10, Batch 70/97, Loss: 0.1918
Epoch 9/10, Batch 80/97, Loss: 0.1414
Epoch 9/10, Batch 90/97, Loss: 0.1048
Epoch 9/10, Train Loss: 0.2011, Valid Loss: 0.2359
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1510
Epoch 10/10, Batch 20/97, Loss: 0.1683
Epoch 10/10, Batch 30/97, Loss: 0.1153
Epoch 10/10, Batch 40/97, Loss: 0.1586
Epoch 10/10, Batch 50/97, Loss: 0.5580
Epoch 10/10, Batch 60/97, Loss: 0.0770
Epoch 10/10, Batch 70/97, Loss: 0.1842
Epoch 10/10, Batch 80/97, Loss: 0.2292
Epoch 10/10, Batch 90/97, Loss: 0.2258
Epoch 10/10, Train Loss: 0.1890, Valid Loss: 0.2275
Model saved!
Accuracy: 0.9182
Precision: 0.9155
Recall: 0.9182
F1-score: 0.9159
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4243
Epoch 1/10, Batch 20/97, Loss: 1.0754
Epoch 1/10, Batch 30/97, Loss: 0.9214
Epoch 1/10, Batch 40/97, Loss: 0.8373
Epoch 1/10, Batch 50/97, Loss: 0.6245
Epoch 1/10, Batch 60/97, Loss: 0.5421
Epoch 1/10, Batch 70/97, Loss: 0.4843
Epoch 1/10, Batch 80/97, Loss: 0.5540
Epoch 1/10, Batch 90/97, Loss: 0.6360
Epoch 1/10, Train Loss: 0.7926, Valid Loss: 0.4534
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3613
Epoch 2/10, Batch 20/97, Loss: 0.6316
Epoch 2/10, Batch 30/97, Loss: 0.3771
Epoch 2/10, Batch 40/97, Loss: 0.3435
Epoch 2/10, Batch 50/97, Loss: 0.6284
Epoch 2/10, Batch 60/97, Loss: 0.3482
Epoch 2/10, Batch 70/97, Loss: 0.3858
Epoch 2/10, Batch 80/97, Loss: 0.2082
Epoch 2/10, Batch 90/97, Loss: 0.3853
Epoch 2/10, Train Loss: 0.4138, Valid Loss: 0.3411
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3153
Epoch 3/10, Batch 20/97, Loss: 0.2957
Epoch 3/10, Batch 30/97, Loss: 0.2063
Epoch 3/10, Batch 40/97, Loss: 0.3476
Epoch 3/10, Batch 50/97, Loss: 0.2964
Epoch 3/10, Batch 60/97, Loss: 0.1754
Epoch 3/10, Batch 70/97, Loss: 0.3181
Epoch 3/10, Batch 80/97, Loss: 0.2448
Epoch 3/10, Batch 90/97, Loss: 0.1684
Epoch 3/10, Train Loss: 0.3281, Valid Loss: 0.3013
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2428
Epoch 4/10, Batch 20/97, Loss: 0.2360
Epoch 4/10, Batch 30/97, Loss: 0.3866
Epoch 4/10, Batch 40/97, Loss: 0.3523
Epoch 4/10, Batch 50/97, Loss: 0.2761
Epoch 4/10, Batch 60/97, Loss: 0.2212
Epoch 4/10, Batch 70/97, Loss: 0.1567
Epoch 4/10, Batch 80/97, Loss: 0.2672
Epoch 4/10, Batch 90/97, Loss: 0.2674
Epoch 4/10, Train Loss: 0.2916, Valid Loss: 0.2804
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1878
Epoch 5/10, Batch 20/97, Loss: 0.1886
Epoch 5/10, Batch 30/97, Loss: 0.1252
Epoch 5/10, Batch 40/97, Loss: 0.2514
Epoch 5/10, Batch 50/97, Loss: 0.1878
Epoch 5/10, Batch 60/97, Loss: 0.2440
Epoch 5/10, Batch 70/97, Loss: 0.1289
Epoch 5/10, Batch 80/97, Loss: 0.4032
Epoch 5/10, Batch 90/97, Loss: 0.3425
Epoch 5/10, Train Loss: 0.2656, Valid Loss: 0.2718
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2423
Epoch 6/10, Batch 20/97, Loss: 0.3386
Epoch 6/10, Batch 30/97, Loss: 0.1351
Epoch 6/10, Batch 40/97, Loss: 0.2409
Epoch 6/10, Batch 50/97, Loss: 0.2199
Epoch 6/10, Batch 60/97, Loss: 0.1800
Epoch 6/10, Batch 70/97, Loss: 0.2027
Epoch 6/10, Batch 80/97, Loss: 0.2875
Epoch 6/10, Batch 90/97, Loss: 0.2394
Epoch 6/10, Train Loss: 0.2545, Valid Loss: 0.2611
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1925
Epoch 7/10, Batch 20/97, Loss: 0.2319
Epoch 7/10, Batch 30/97, Loss: 0.2687
Epoch 7/10, Batch 40/97, Loss: 0.2453
Epoch 7/10, Batch 50/97, Loss: 0.2034
Epoch 7/10, Batch 60/97, Loss: 0.2416
Epoch 7/10, Batch 70/97, Loss: 0.2195
Epoch 7/10, Batch 80/97, Loss: 0.2842
Epoch 7/10, Batch 90/97, Loss: 0.2737
Epoch 7/10, Train Loss: 0.2586, Valid Loss: 0.2538
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2122
Epoch 8/10, Batch 20/97, Loss: 0.2723
Epoch 8/10, Batch 30/97, Loss: 0.1420
Epoch 8/10, Batch 40/97, Loss: 0.1420
Epoch 8/10, Batch 50/97, Loss: 0.3643
Epoch 8/10, Batch 60/97, Loss: 0.4075
Epoch 8/10, Batch 70/97, Loss: 0.1441
Epoch 8/10, Batch 80/97, Loss: 0.2526
Epoch 8/10, Batch 90/97, Loss: 0.1881
Epoch 8/10, Train Loss: 0.2316, Valid Loss: 0.2472
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0996
Epoch 9/10, Batch 20/97, Loss: 0.1630
Epoch 9/10, Batch 30/97, Loss: 0.2745
Epoch 9/10, Batch 40/97, Loss: 0.1814
Epoch 9/10, Batch 50/97, Loss: 0.1983
Epoch 9/10, Batch 60/97, Loss: 0.1852
Epoch 9/10, Batch 70/97, Loss: 0.1759
Epoch 9/10, Batch 80/97, Loss: 0.3213
Epoch 9/10, Batch 90/97, Loss: 0.1867
Epoch 9/10, Train Loss: 0.2209, Valid Loss: 0.2460
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2622
Epoch 10/10, Batch 20/97, Loss: 0.0786
Epoch 10/10, Batch 30/97, Loss: 0.1971
Epoch 10/10, Batch 40/97, Loss: 0.3359
Epoch 10/10, Batch 50/97, Loss: 0.3608
Epoch 10/10, Batch 60/97, Loss: 0.1603
Epoch 10/10, Batch 70/97, Loss: 0.2082
Epoch 10/10, Batch 80/97, Loss: 0.2149
Epoch 10/10, Batch 90/97, Loss: 0.2596
Epoch 10/10, Train Loss: 0.2036, Valid Loss: 0.2425
Model saved!
Accuracy: 0.9147
Precision: 0.9143
Recall: 0.9147
F1-score: 0.9139
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4505
Epoch 1/10, Batch 20/97, Loss: 0.9401
Epoch 1/10, Batch 30/97, Loss: 0.8245
Epoch 1/10, Batch 40/97, Loss: 0.7362
Epoch 1/10, Batch 50/97, Loss: 0.6840
Epoch 1/10, Batch 60/97, Loss: 0.6230
Epoch 1/10, Batch 70/97, Loss: 0.5226
Epoch 1/10, Batch 80/97, Loss: 0.3877
Epoch 1/10, Batch 90/97, Loss: 0.5247
Epoch 1/10, Train Loss: 0.7707, Valid Loss: 0.4472
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3909
Epoch 2/10, Batch 20/97, Loss: 0.5382
Epoch 2/10, Batch 30/97, Loss: 0.3498
Epoch 2/10, Batch 40/97, Loss: 0.4429
Epoch 2/10, Batch 50/97, Loss: 0.4265
Epoch 2/10, Batch 60/97, Loss: 0.3245
Epoch 2/10, Batch 70/97, Loss: 0.2862
Epoch 2/10, Batch 80/97, Loss: 0.4254
Epoch 2/10, Batch 90/97, Loss: 0.4087
Epoch 2/10, Train Loss: 0.3961, Valid Loss: 0.3394
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4196
Epoch 3/10, Batch 20/97, Loss: 0.2505
Epoch 3/10, Batch 30/97, Loss: 0.2765
Epoch 3/10, Batch 40/97, Loss: 0.2737
Epoch 3/10, Batch 50/97, Loss: 0.2793
Epoch 3/10, Batch 60/97, Loss: 0.2030
Epoch 3/10, Batch 70/97, Loss: 0.2135
Epoch 3/10, Batch 80/97, Loss: 0.2288
Epoch 3/10, Batch 90/97, Loss: 0.3559
Epoch 3/10, Train Loss: 0.3219, Valid Loss: 0.2998
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3627
Epoch 4/10, Batch 20/97, Loss: 0.3135
Epoch 4/10, Batch 30/97, Loss: 0.2680
Epoch 4/10, Batch 40/97, Loss: 0.3545
Epoch 4/10, Batch 50/97, Loss: 0.2794
Epoch 4/10, Batch 60/97, Loss: 0.2212
Epoch 4/10, Batch 70/97, Loss: 0.2430
Epoch 4/10, Batch 80/97, Loss: 0.3339
Epoch 4/10, Batch 90/97, Loss: 0.4101
Epoch 4/10, Train Loss: 0.2896, Valid Loss: 0.2752
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2329
Epoch 5/10, Batch 20/97, Loss: 0.1725
Epoch 5/10, Batch 30/97, Loss: 0.1579
Epoch 5/10, Batch 40/97, Loss: 0.1741
Epoch 5/10, Batch 50/97, Loss: 0.3603
Epoch 5/10, Batch 60/97, Loss: 0.3487
Epoch 5/10, Batch 70/97, Loss: 0.1622
Epoch 5/10, Batch 80/97, Loss: 0.2130
Epoch 5/10, Batch 90/97, Loss: 0.4954
Epoch 5/10, Train Loss: 0.2635, Valid Loss: 0.2671
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3034
Epoch 6/10, Batch 20/97, Loss: 0.1614
Epoch 6/10, Batch 30/97, Loss: 0.2778
Epoch 6/10, Batch 40/97, Loss: 0.2022
Epoch 6/10, Batch 50/97, Loss: 0.2059
Epoch 6/10, Batch 60/97, Loss: 0.3110
Epoch 6/10, Batch 70/97, Loss: 0.2704
Epoch 6/10, Batch 80/97, Loss: 0.1847
Epoch 6/10, Batch 90/97, Loss: 0.2161
Epoch 6/10, Train Loss: 0.2440, Valid Loss: 0.2465
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1675
Epoch 7/10, Batch 20/97, Loss: 0.1429
Epoch 7/10, Batch 30/97, Loss: 0.2520
Epoch 7/10, Batch 40/97, Loss: 0.1698
Epoch 7/10, Batch 50/97, Loss: 0.2080
Epoch 7/10, Batch 60/97, Loss: 0.2436
Epoch 7/10, Batch 70/97, Loss: 0.3887
Epoch 7/10, Batch 80/97, Loss: 0.1378
Epoch 7/10, Batch 90/97, Loss: 0.3114
Epoch 7/10, Train Loss: 0.2404, Valid Loss: 0.2467
Epoch 8/10, Batch 10/97, Loss: 0.2288
Epoch 8/10, Batch 20/97, Loss: 0.2232
Epoch 8/10, Batch 30/97, Loss: 0.1828
Epoch 8/10, Batch 40/97, Loss: 0.1571
Epoch 8/10, Batch 50/97, Loss: 0.2373
Epoch 8/10, Batch 60/97, Loss: 0.2997
Epoch 8/10, Batch 70/97, Loss: 0.2097
Epoch 8/10, Batch 80/97, Loss: 0.1067
Epoch 8/10, Batch 90/97, Loss: 0.1594
Epoch 8/10, Train Loss: 0.2232, Valid Loss: 0.2410
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2065
Epoch 9/10, Batch 20/97, Loss: 0.1143
Epoch 9/10, Batch 30/97, Loss: 0.3282
Epoch 9/10, Batch 40/97, Loss: 0.2103
Epoch 9/10, Batch 50/97, Loss: 0.2535
Epoch 9/10, Batch 60/97, Loss: 0.3353
Epoch 9/10, Batch 70/97, Loss: 0.1564
Epoch 9/10, Batch 80/97, Loss: 0.1428
Epoch 9/10, Batch 90/97, Loss: 0.2337
Epoch 9/10, Train Loss: 0.2076, Valid Loss: 0.2413
Epoch 10/10, Batch 10/97, Loss: 0.2049
Epoch 10/10, Batch 20/97, Loss: 0.1381
Epoch 10/10, Batch 30/97, Loss: 0.1143
Epoch 10/10, Batch 40/97, Loss: 0.1781
Epoch 10/10, Batch 50/97, Loss: 0.3309
Epoch 10/10, Batch 60/97, Loss: 0.1499
Epoch 10/10, Batch 70/97, Loss: 0.2128
Epoch 10/10, Batch 80/97, Loss: 0.2896
Epoch 10/10, Batch 90/97, Loss: 0.1335
Epoch 10/10, Train Loss: 0.2004, Valid Loss: 0.2362
Model saved!
Accuracy: 0.9147
Precision: 0.9130
Recall: 0.9147
F1-score: 0.9126
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5004
Epoch 1/10, Batch 20/97, Loss: 1.0326
Epoch 1/10, Batch 30/97, Loss: 0.8753
Epoch 1/10, Batch 40/97, Loss: 0.7952
Epoch 1/10, Batch 50/97, Loss: 0.5624
Epoch 1/10, Batch 60/97, Loss: 0.6845
Epoch 1/10, Batch 70/97, Loss: 0.6545
Epoch 1/10, Batch 80/97, Loss: 0.3984
Epoch 1/10, Batch 90/97, Loss: 0.6466
Epoch 1/10, Train Loss: 0.7801, Valid Loss: 0.4136
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4481
Epoch 2/10, Batch 20/97, Loss: 0.6907
Epoch 2/10, Batch 30/97, Loss: 0.3820
Epoch 2/10, Batch 40/97, Loss: 0.5025
Epoch 2/10, Batch 50/97, Loss: 0.6120
Epoch 2/10, Batch 60/97, Loss: 0.3223
Epoch 2/10, Batch 70/97, Loss: 0.3361
Epoch 2/10, Batch 80/97, Loss: 0.2620
Epoch 2/10, Batch 90/97, Loss: 0.2762
Epoch 2/10, Train Loss: 0.3959, Valid Loss: 0.3079
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2129
Epoch 3/10, Batch 20/97, Loss: 0.2608
Epoch 3/10, Batch 30/97, Loss: 0.2152
Epoch 3/10, Batch 40/97, Loss: 0.3548
Epoch 3/10, Batch 50/97, Loss: 0.3125
Epoch 3/10, Batch 60/97, Loss: 0.2989
Epoch 3/10, Batch 70/97, Loss: 0.2147
Epoch 3/10, Batch 80/97, Loss: 0.3292
Epoch 3/10, Batch 90/97, Loss: 0.2703
Epoch 3/10, Train Loss: 0.3250, Valid Loss: 0.2739
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3422
Epoch 4/10, Batch 20/97, Loss: 0.1584
Epoch 4/10, Batch 30/97, Loss: 0.4156
Epoch 4/10, Batch 40/97, Loss: 0.3476
Epoch 4/10, Batch 50/97, Loss: 0.3185
Epoch 4/10, Batch 60/97, Loss: 0.2291
Epoch 4/10, Batch 70/97, Loss: 0.3736
Epoch 4/10, Batch 80/97, Loss: 0.2354
Epoch 4/10, Batch 90/97, Loss: 0.3689
Epoch 4/10, Train Loss: 0.2866, Valid Loss: 0.2549
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2418
Epoch 5/10, Batch 20/97, Loss: 0.1821
Epoch 5/10, Batch 30/97, Loss: 0.1415
Epoch 5/10, Batch 40/97, Loss: 0.2778
Epoch 5/10, Batch 50/97, Loss: 0.1889
Epoch 5/10, Batch 60/97, Loss: 0.3193
Epoch 5/10, Batch 70/97, Loss: 0.2446
Epoch 5/10, Batch 80/97, Loss: 0.2241
Epoch 5/10, Batch 90/97, Loss: 0.2999
Epoch 5/10, Train Loss: 0.2633, Valid Loss: 0.2350
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2068
Epoch 6/10, Batch 20/97, Loss: 0.1447
Epoch 6/10, Batch 30/97, Loss: 0.2982
Epoch 6/10, Batch 40/97, Loss: 0.2778
Epoch 6/10, Batch 50/97, Loss: 0.1938
Epoch 6/10, Batch 60/97, Loss: 0.2357
Epoch 6/10, Batch 70/97, Loss: 0.1727
Epoch 6/10, Batch 80/97, Loss: 0.1655
Epoch 6/10, Batch 90/97, Loss: 0.2882
Epoch 6/10, Train Loss: 0.2418, Valid Loss: 0.2335
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2731
Epoch 7/10, Batch 20/97, Loss: 0.0933
Epoch 7/10, Batch 30/97, Loss: 0.1116
Epoch 7/10, Batch 40/97, Loss: 0.1896
Epoch 7/10, Batch 50/97, Loss: 0.2500
Epoch 7/10, Batch 60/97, Loss: 0.2226
Epoch 7/10, Batch 70/97, Loss: 0.3304
Epoch 7/10, Batch 80/97, Loss: 0.1836
Epoch 7/10, Batch 90/97, Loss: 0.2548
Epoch 7/10, Train Loss: 0.2472, Valid Loss: 0.2196
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1871
Epoch 8/10, Batch 20/97, Loss: 0.3069
Epoch 8/10, Batch 30/97, Loss: 0.1418
Epoch 8/10, Batch 40/97, Loss: 0.1326
Epoch 8/10, Batch 50/97, Loss: 0.1670
Epoch 8/10, Batch 60/97, Loss: 0.1799
Epoch 8/10, Batch 70/97, Loss: 0.2088
Epoch 8/10, Batch 80/97, Loss: 0.1921
Epoch 8/10, Batch 90/97, Loss: 0.1140
Epoch 8/10, Train Loss: 0.2147, Valid Loss: 0.2221
Epoch 9/10, Batch 10/97, Loss: 0.0880
Epoch 9/10, Batch 20/97, Loss: 0.1273
Epoch 9/10, Batch 30/97, Loss: 0.3061
Epoch 9/10, Batch 40/97, Loss: 0.1070
Epoch 9/10, Batch 50/97, Loss: 0.2484
Epoch 9/10, Batch 60/97, Loss: 0.2755
Epoch 9/10, Batch 70/97, Loss: 0.3854
Epoch 9/10, Batch 80/97, Loss: 0.1972
Epoch 9/10, Batch 90/97, Loss: 0.1621
Epoch 9/10, Train Loss: 0.2159, Valid Loss: 0.2142
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3306
Epoch 10/10, Batch 20/97, Loss: 0.2113
Epoch 10/10, Batch 30/97, Loss: 0.1187
Epoch 10/10, Batch 40/97, Loss: 0.2385
Epoch 10/10, Batch 50/97, Loss: 0.2935
Epoch 10/10, Batch 60/97, Loss: 0.1623
Epoch 10/10, Batch 70/97, Loss: 0.2141
Epoch 10/10, Batch 80/97, Loss: 0.2773
Epoch 10/10, Batch 90/97, Loss: 0.1946
Epoch 10/10, Train Loss: 0.2006, Valid Loss: 0.2129
Model saved!
Accuracy: 0.9159
Precision: 0.9122
Recall: 0.9159
F1-score: 0.9132
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5073
Epoch 1/10, Batch 20/97, Loss: 0.9862
Epoch 1/10, Batch 30/97, Loss: 0.9559
Epoch 1/10, Batch 40/97, Loss: 0.7340
Epoch 1/10, Batch 50/97, Loss: 0.6598
Epoch 1/10, Batch 60/97, Loss: 0.6184
Epoch 1/10, Batch 70/97, Loss: 0.4714
Epoch 1/10, Batch 80/97, Loss: 0.5597
Epoch 1/10, Batch 90/97, Loss: 0.5326
Epoch 1/10, Train Loss: 0.7828, Valid Loss: 0.4445
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3243
Epoch 2/10, Batch 20/97, Loss: 0.4968
Epoch 2/10, Batch 30/97, Loss: 0.4289
Epoch 2/10, Batch 40/97, Loss: 0.4223
Epoch 2/10, Batch 50/97, Loss: 0.5136
Epoch 2/10, Batch 60/97, Loss: 0.2580
Epoch 2/10, Batch 70/97, Loss: 0.2346
Epoch 2/10, Batch 80/97, Loss: 0.2682
Epoch 2/10, Batch 90/97, Loss: 0.4067
Epoch 2/10, Train Loss: 0.3999, Valid Loss: 0.3534
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3818
Epoch 3/10, Batch 20/97, Loss: 0.2543
Epoch 3/10, Batch 30/97, Loss: 0.2471
Epoch 3/10, Batch 40/97, Loss: 0.2653
Epoch 3/10, Batch 50/97, Loss: 0.3070
Epoch 3/10, Batch 60/97, Loss: 0.2605
Epoch 3/10, Batch 70/97, Loss: 0.3297
Epoch 3/10, Batch 80/97, Loss: 0.2147
Epoch 3/10, Batch 90/97, Loss: 0.2245
Epoch 3/10, Train Loss: 0.3279, Valid Loss: 0.3220
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3593
Epoch 4/10, Batch 20/97, Loss: 0.3120
Epoch 4/10, Batch 30/97, Loss: 0.1908
Epoch 4/10, Batch 40/97, Loss: 0.2178
Epoch 4/10, Batch 50/97, Loss: 0.2367
Epoch 4/10, Batch 60/97, Loss: 0.1893
Epoch 4/10, Batch 70/97, Loss: 0.3155
Epoch 4/10, Batch 80/97, Loss: 0.3667
Epoch 4/10, Batch 90/97, Loss: 0.2223
Epoch 4/10, Train Loss: 0.2900, Valid Loss: 0.2995
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.4064
Epoch 5/10, Batch 20/97, Loss: 0.2746
Epoch 5/10, Batch 30/97, Loss: 0.1836
Epoch 5/10, Batch 40/97, Loss: 0.2275
Epoch 5/10, Batch 50/97, Loss: 0.2039
Epoch 5/10, Batch 60/97, Loss: 0.1461
Epoch 5/10, Batch 70/97, Loss: 0.2950
Epoch 5/10, Batch 80/97, Loss: 0.2226
Epoch 5/10, Batch 90/97, Loss: 0.3187
Epoch 5/10, Train Loss: 0.2583, Valid Loss: 0.2884
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1699
Epoch 6/10, Batch 20/97, Loss: 0.1999
Epoch 6/10, Batch 30/97, Loss: 0.1024
Epoch 6/10, Batch 40/97, Loss: 0.3820
Epoch 6/10, Batch 50/97, Loss: 0.2256
Epoch 6/10, Batch 60/97, Loss: 0.1869
Epoch 6/10, Batch 70/97, Loss: 0.2851
Epoch 6/10, Batch 80/97, Loss: 0.1797
Epoch 6/10, Batch 90/97, Loss: 0.3718
Epoch 6/10, Train Loss: 0.2427, Valid Loss: 0.2766
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3225
Epoch 7/10, Batch 20/97, Loss: 0.1783
Epoch 7/10, Batch 30/97, Loss: 0.2023
Epoch 7/10, Batch 40/97, Loss: 0.2191
Epoch 7/10, Batch 50/97, Loss: 0.2872
Epoch 7/10, Batch 60/97, Loss: 0.2735
Epoch 7/10, Batch 70/97, Loss: 0.2843
Epoch 7/10, Batch 80/97, Loss: 0.3004
Epoch 7/10, Batch 90/97, Loss: 0.2829
Epoch 7/10, Train Loss: 0.2472, Valid Loss: 0.2785
Epoch 8/10, Batch 10/97, Loss: 0.1789
Epoch 8/10, Batch 20/97, Loss: 0.2473
Epoch 8/10, Batch 30/97, Loss: 0.0844
Epoch 8/10, Batch 40/97, Loss: 0.2023
Epoch 8/10, Batch 50/97, Loss: 0.2767
Epoch 8/10, Batch 60/97, Loss: 0.1793
Epoch 8/10, Batch 70/97, Loss: 0.1633
Epoch 8/10, Batch 80/97, Loss: 0.3218
Epoch 8/10, Batch 90/97, Loss: 0.1243
Epoch 8/10, Train Loss: 0.2248, Valid Loss: 0.2750
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0964
Epoch 9/10, Batch 20/97, Loss: 0.1935
Epoch 9/10, Batch 30/97, Loss: 0.3761
Epoch 9/10, Batch 40/97, Loss: 0.1384
Epoch 9/10, Batch 50/97, Loss: 0.1176
Epoch 9/10, Batch 60/97, Loss: 0.1847
Epoch 9/10, Batch 70/97, Loss: 0.3104
Epoch 9/10, Batch 80/97, Loss: 0.1713
Epoch 9/10, Batch 90/97, Loss: 0.2930
Epoch 9/10, Train Loss: 0.2107, Valid Loss: 0.2669
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2328
Epoch 10/10, Batch 20/97, Loss: 0.0794
Epoch 10/10, Batch 30/97, Loss: 0.2132
Epoch 10/10, Batch 40/97, Loss: 0.3165
Epoch 10/10, Batch 50/97, Loss: 0.2137
Epoch 10/10, Batch 60/97, Loss: 0.1955
Epoch 10/10, Batch 70/97, Loss: 0.2457
Epoch 10/10, Batch 80/97, Loss: 0.2068
Epoch 10/10, Batch 90/97, Loss: 0.1401
Epoch 10/10, Train Loss: 0.1928, Valid Loss: 0.2626
Model saved!
Accuracy: 0.9264
Precision: 0.9253
Recall: 0.9264
F1-score: 0.9255
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 58. Fitness: 0.9264
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4704
Epoch 1/10, Batch 20/97, Loss: 1.0083
Epoch 1/10, Batch 30/97, Loss: 0.9147
Epoch 1/10, Batch 40/97, Loss: 0.6792
Epoch 1/10, Batch 50/97, Loss: 0.6461
Epoch 1/10, Batch 60/97, Loss: 0.4503
Epoch 1/10, Batch 70/97, Loss: 0.4724
Epoch 1/10, Batch 80/97, Loss: 0.4931
Epoch 1/10, Batch 90/97, Loss: 0.4321
Epoch 1/10, Train Loss: 0.7733, Valid Loss: 0.4874
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4338
Epoch 2/10, Batch 20/97, Loss: 0.3937
Epoch 2/10, Batch 30/97, Loss: 0.3858
Epoch 2/10, Batch 40/97, Loss: 0.3861
Epoch 2/10, Batch 50/97, Loss: 0.7033
Epoch 2/10, Batch 60/97, Loss: 0.3268
Epoch 2/10, Batch 70/97, Loss: 0.3800
Epoch 2/10, Batch 80/97, Loss: 0.3571
Epoch 2/10, Batch 90/97, Loss: 0.3149
Epoch 2/10, Train Loss: 0.3898, Valid Loss: 0.3918
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3033
Epoch 3/10, Batch 20/97, Loss: 0.2465
Epoch 3/10, Batch 30/97, Loss: 0.3522
Epoch 3/10, Batch 40/97, Loss: 0.2469
Epoch 3/10, Batch 50/97, Loss: 0.2413
Epoch 3/10, Batch 60/97, Loss: 0.2750
Epoch 3/10, Batch 70/97, Loss: 0.2029
Epoch 3/10, Batch 80/97, Loss: 0.4068
Epoch 3/10, Batch 90/97, Loss: 0.2680
Epoch 3/10, Train Loss: 0.3125, Valid Loss: 0.3531
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3243
Epoch 4/10, Batch 20/97, Loss: 0.3712
Epoch 4/10, Batch 30/97, Loss: 0.3361
Epoch 4/10, Batch 40/97, Loss: 0.2275
Epoch 4/10, Batch 50/97, Loss: 0.1619
Epoch 4/10, Batch 60/97, Loss: 0.1357
Epoch 4/10, Batch 70/97, Loss: 0.2242
Epoch 4/10, Batch 80/97, Loss: 0.2908
Epoch 4/10, Batch 90/97, Loss: 0.2732
Epoch 4/10, Train Loss: 0.2712, Valid Loss: 0.3191
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1814
Epoch 5/10, Batch 20/97, Loss: 0.2146
Epoch 5/10, Batch 30/97, Loss: 0.1191
Epoch 5/10, Batch 40/97, Loss: 0.1522
Epoch 5/10, Batch 50/97, Loss: 0.2348
Epoch 5/10, Batch 60/97, Loss: 0.1534
Epoch 5/10, Batch 70/97, Loss: 0.2724
Epoch 5/10, Batch 80/97, Loss: 0.2126
Epoch 5/10, Batch 90/97, Loss: 0.2775
Epoch 5/10, Train Loss: 0.2506, Valid Loss: 0.3141
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1529
Epoch 6/10, Batch 20/97, Loss: 0.1343
Epoch 6/10, Batch 30/97, Loss: 0.2885
Epoch 6/10, Batch 40/97, Loss: 0.1866
Epoch 6/10, Batch 50/97, Loss: 0.2189
Epoch 6/10, Batch 60/97, Loss: 0.1732
Epoch 6/10, Batch 70/97, Loss: 0.3592
Epoch 6/10, Batch 80/97, Loss: 0.2519
Epoch 6/10, Batch 90/97, Loss: 0.2646
Epoch 6/10, Train Loss: 0.2292, Valid Loss: 0.3012
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2392
Epoch 7/10, Batch 20/97, Loss: 0.2013
Epoch 7/10, Batch 30/97, Loss: 0.1666
Epoch 7/10, Batch 40/97, Loss: 0.2040
Epoch 7/10, Batch 50/97, Loss: 0.3382
Epoch 7/10, Batch 60/97, Loss: 0.2802
Epoch 7/10, Batch 70/97, Loss: 0.2778
Epoch 7/10, Batch 80/97, Loss: 0.1658
Epoch 7/10, Batch 90/97, Loss: 0.2563
Epoch 7/10, Train Loss: 0.2320, Valid Loss: 0.2975
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2016
Epoch 8/10, Batch 20/97, Loss: 0.2479
Epoch 8/10, Batch 30/97, Loss: 0.1658
Epoch 8/10, Batch 40/97, Loss: 0.1039
Epoch 8/10, Batch 50/97, Loss: 0.3115
Epoch 8/10, Batch 60/97, Loss: 0.1822
Epoch 8/10, Batch 70/97, Loss: 0.2063
Epoch 8/10, Batch 80/97, Loss: 0.0945
Epoch 8/10, Batch 90/97, Loss: 0.1665
Epoch 8/10, Train Loss: 0.2095, Valid Loss: 0.2802
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1271
Epoch 9/10, Batch 20/97, Loss: 0.1559
Epoch 9/10, Batch 30/97, Loss: 0.2902
Epoch 9/10, Batch 40/97, Loss: 0.1353
Epoch 9/10, Batch 50/97, Loss: 0.2114
Epoch 9/10, Batch 60/97, Loss: 0.1800
Epoch 9/10, Batch 70/97, Loss: 0.1304
Epoch 9/10, Batch 80/97, Loss: 0.1826
Epoch 9/10, Batch 90/97, Loss: 0.2834
Epoch 9/10, Train Loss: 0.1931, Valid Loss: 0.2843
Epoch 10/10, Batch 10/97, Loss: 0.2145
Epoch 10/10, Batch 20/97, Loss: 0.1157
Epoch 10/10, Batch 30/97, Loss: 0.1440
Epoch 10/10, Batch 40/97, Loss: 0.1158
Epoch 10/10, Batch 50/97, Loss: 0.2801
Epoch 10/10, Batch 60/97, Loss: 0.2316
Epoch 10/10, Batch 70/97, Loss: 0.1469
Epoch 10/10, Batch 80/97, Loss: 0.1197
Epoch 10/10, Batch 90/97, Loss: 0.1488
Epoch 10/10, Train Loss: 0.1837, Valid Loss: 0.2856
Accuracy: 0.9112
Precision: 0.9082
Recall: 0.9112
F1-score: 0.9085
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4757
Epoch 1/10, Batch 20/97, Loss: 0.9185
Epoch 1/10, Batch 30/97, Loss: 0.8397
Epoch 1/10, Batch 40/97, Loss: 0.8423
Epoch 1/10, Batch 50/97, Loss: 0.6955
Epoch 1/10, Batch 60/97, Loss: 0.5815
Epoch 1/10, Batch 70/97, Loss: 0.5954
Epoch 1/10, Batch 80/97, Loss: 0.4448
Epoch 1/10, Batch 90/97, Loss: 0.4196
Epoch 1/10, Train Loss: 0.7726, Valid Loss: 0.4305
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4392
Epoch 2/10, Batch 20/97, Loss: 0.5252
Epoch 2/10, Batch 30/97, Loss: 0.3643
Epoch 2/10, Batch 40/97, Loss: 0.3367
Epoch 2/10, Batch 50/97, Loss: 0.5929
Epoch 2/10, Batch 60/97, Loss: 0.4336
Epoch 2/10, Batch 70/97, Loss: 0.3935
Epoch 2/10, Batch 80/97, Loss: 0.3499
Epoch 2/10, Batch 90/97, Loss: 0.3543
Epoch 2/10, Train Loss: 0.3976, Valid Loss: 0.3265
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3629
Epoch 3/10, Batch 20/97, Loss: 0.1725
Epoch 3/10, Batch 30/97, Loss: 0.2836
Epoch 3/10, Batch 40/97, Loss: 0.2324
Epoch 3/10, Batch 50/97, Loss: 0.2421
Epoch 3/10, Batch 60/97, Loss: 0.2162
Epoch 3/10, Batch 70/97, Loss: 0.1973
Epoch 3/10, Batch 80/97, Loss: 0.4003
Epoch 3/10, Batch 90/97, Loss: 0.1807
Epoch 3/10, Train Loss: 0.3232, Valid Loss: 0.2872
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2396
Epoch 4/10, Batch 20/97, Loss: 0.3062
Epoch 4/10, Batch 30/97, Loss: 0.3834
Epoch 4/10, Batch 40/97, Loss: 0.2030
Epoch 4/10, Batch 50/97, Loss: 0.1884
Epoch 4/10, Batch 60/97, Loss: 0.1582
Epoch 4/10, Batch 70/97, Loss: 0.1797
Epoch 4/10, Batch 80/97, Loss: 0.2377
Epoch 4/10, Batch 90/97, Loss: 0.1990
Epoch 4/10, Train Loss: 0.2894, Valid Loss: 0.2663
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2205
Epoch 5/10, Batch 20/97, Loss: 0.1450
Epoch 5/10, Batch 30/97, Loss: 0.2063
Epoch 5/10, Batch 40/97, Loss: 0.1389
Epoch 5/10, Batch 50/97, Loss: 0.2309
Epoch 5/10, Batch 60/97, Loss: 0.3415
Epoch 5/10, Batch 70/97, Loss: 0.1879
Epoch 5/10, Batch 80/97, Loss: 0.2346
Epoch 5/10, Batch 90/97, Loss: 0.3698
Epoch 5/10, Train Loss: 0.2609, Valid Loss: 0.2534
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2354
Epoch 6/10, Batch 20/97, Loss: 0.2182
Epoch 6/10, Batch 30/97, Loss: 0.1711
Epoch 6/10, Batch 40/97, Loss: 0.2860
Epoch 6/10, Batch 50/97, Loss: 0.2152
Epoch 6/10, Batch 60/97, Loss: 0.2060
Epoch 6/10, Batch 70/97, Loss: 0.2626
Epoch 6/10, Batch 80/97, Loss: 0.0943
Epoch 6/10, Batch 90/97, Loss: 0.1984
Epoch 6/10, Train Loss: 0.2334, Valid Loss: 0.2575
Epoch 7/10, Batch 10/97, Loss: 0.3528
Epoch 7/10, Batch 20/97, Loss: 0.1812
Epoch 7/10, Batch 30/97, Loss: 0.2054
Epoch 7/10, Batch 40/97, Loss: 0.2396
Epoch 7/10, Batch 50/97, Loss: 0.2483
Epoch 7/10, Batch 60/97, Loss: 0.2940
Epoch 7/10, Batch 70/97, Loss: 0.2254
Epoch 7/10, Batch 80/97, Loss: 0.2853
Epoch 7/10, Batch 90/97, Loss: 0.2145
Epoch 7/10, Train Loss: 0.2445, Valid Loss: 0.2387
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1112
Epoch 8/10, Batch 20/97, Loss: 0.2143
Epoch 8/10, Batch 30/97, Loss: 0.2990
Epoch 8/10, Batch 40/97, Loss: 0.1769
Epoch 8/10, Batch 50/97, Loss: 0.2319
Epoch 8/10, Batch 60/97, Loss: 0.1421
Epoch 8/10, Batch 70/97, Loss: 0.1881
Epoch 8/10, Batch 80/97, Loss: 0.1656
Epoch 8/10, Batch 90/97, Loss: 0.1879
Epoch 8/10, Train Loss: 0.2184, Valid Loss: 0.2377
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1433
Epoch 9/10, Batch 20/97, Loss: 0.0668
Epoch 9/10, Batch 30/97, Loss: 0.2571
Epoch 9/10, Batch 40/97, Loss: 0.0829
Epoch 9/10, Batch 50/97, Loss: 0.2725
Epoch 9/10, Batch 60/97, Loss: 0.1590
Epoch 9/10, Batch 70/97, Loss: 0.2828
Epoch 9/10, Batch 80/97, Loss: 0.1966
Epoch 9/10, Batch 90/97, Loss: 0.1930
Epoch 9/10, Train Loss: 0.2103, Valid Loss: 0.2402
Epoch 10/10, Batch 10/97, Loss: 0.2286
Epoch 10/10, Batch 20/97, Loss: 0.1137
Epoch 10/10, Batch 30/97, Loss: 0.1802
Epoch 10/10, Batch 40/97, Loss: 0.2652
Epoch 10/10, Batch 50/97, Loss: 0.1825
Epoch 10/10, Batch 60/97, Loss: 0.2647
Epoch 10/10, Batch 70/97, Loss: 0.2039
Epoch 10/10, Batch 80/97, Loss: 0.3014
Epoch 10/10, Batch 90/97, Loss: 0.2941
Epoch 10/10, Train Loss: 0.1980, Valid Loss: 0.2294
Model saved!
Accuracy: 0.9136
Precision: 0.9113
Recall: 0.9136
F1-score: 0.9121
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4598
Epoch 1/10, Batch 20/97, Loss: 1.0396
Epoch 1/10, Batch 30/97, Loss: 0.8458
Epoch 1/10, Batch 40/97, Loss: 0.6539
Epoch 1/10, Batch 50/97, Loss: 0.5202
Epoch 1/10, Batch 60/97, Loss: 0.6332
Epoch 1/10, Batch 70/97, Loss: 0.4800
Epoch 1/10, Batch 80/97, Loss: 0.4919
Epoch 1/10, Batch 90/97, Loss: 0.5838
Epoch 1/10, Train Loss: 0.7710, Valid Loss: 0.4170
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3647
Epoch 2/10, Batch 20/97, Loss: 0.4397
Epoch 2/10, Batch 30/97, Loss: 0.3210
Epoch 2/10, Batch 40/97, Loss: 0.4535
Epoch 2/10, Batch 50/97, Loss: 0.5757
Epoch 2/10, Batch 60/97, Loss: 0.2837
Epoch 2/10, Batch 70/97, Loss: 0.2994
Epoch 2/10, Batch 80/97, Loss: 0.3058
Epoch 2/10, Batch 90/97, Loss: 0.4660
Epoch 2/10, Train Loss: 0.3924, Valid Loss: 0.3169
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2747
Epoch 3/10, Batch 20/97, Loss: 0.3711
Epoch 3/10, Batch 30/97, Loss: 0.3358
Epoch 3/10, Batch 40/97, Loss: 0.3460
Epoch 3/10, Batch 50/97, Loss: 0.2506
Epoch 3/10, Batch 60/97, Loss: 0.2295
Epoch 3/10, Batch 70/97, Loss: 0.2990
Epoch 3/10, Batch 80/97, Loss: 0.2579
Epoch 3/10, Batch 90/97, Loss: 0.2206
Epoch 3/10, Train Loss: 0.3173, Valid Loss: 0.2835
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3548
Epoch 4/10, Batch 20/97, Loss: 0.3587
Epoch 4/10, Batch 30/97, Loss: 0.2131
Epoch 4/10, Batch 40/97, Loss: 0.3367
Epoch 4/10, Batch 50/97, Loss: 0.2456
Epoch 4/10, Batch 60/97, Loss: 0.3004
Epoch 4/10, Batch 70/97, Loss: 0.1401
Epoch 4/10, Batch 80/97, Loss: 0.3570
Epoch 4/10, Batch 90/97, Loss: 0.3610
Epoch 4/10, Train Loss: 0.2837, Valid Loss: 0.2586
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2596
Epoch 5/10, Batch 20/97, Loss: 0.2353
Epoch 5/10, Batch 30/97, Loss: 0.1790
Epoch 5/10, Batch 40/97, Loss: 0.1474
Epoch 5/10, Batch 50/97, Loss: 0.1514
Epoch 5/10, Batch 60/97, Loss: 0.2082
Epoch 5/10, Batch 70/97, Loss: 0.1877
Epoch 5/10, Batch 80/97, Loss: 0.3010
Epoch 5/10, Batch 90/97, Loss: 0.2901
Epoch 5/10, Train Loss: 0.2523, Valid Loss: 0.2477
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2464
Epoch 6/10, Batch 20/97, Loss: 0.1226
Epoch 6/10, Batch 30/97, Loss: 0.0569
Epoch 6/10, Batch 40/97, Loss: 0.3495
Epoch 6/10, Batch 50/97, Loss: 0.2042
Epoch 6/10, Batch 60/97, Loss: 0.4243
Epoch 6/10, Batch 70/97, Loss: 0.3058
Epoch 6/10, Batch 80/97, Loss: 0.1993
Epoch 6/10, Batch 90/97, Loss: 0.2242
Epoch 6/10, Train Loss: 0.2422, Valid Loss: 0.2424
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3629
Epoch 7/10, Batch 20/97, Loss: 0.1845
Epoch 7/10, Batch 30/97, Loss: 0.1689
Epoch 7/10, Batch 40/97, Loss: 0.1859
Epoch 7/10, Batch 50/97, Loss: 0.3459
Epoch 7/10, Batch 60/97, Loss: 0.3629
Epoch 7/10, Batch 70/97, Loss: 0.3076
Epoch 7/10, Batch 80/97, Loss: 0.1698
Epoch 7/10, Batch 90/97, Loss: 0.1895
Epoch 7/10, Train Loss: 0.2486, Valid Loss: 0.2265
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1084
Epoch 8/10, Batch 20/97, Loss: 0.2556
Epoch 8/10, Batch 30/97, Loss: 0.1318
Epoch 8/10, Batch 40/97, Loss: 0.1953
Epoch 8/10, Batch 50/97, Loss: 0.3015
Epoch 8/10, Batch 60/97, Loss: 0.2436
Epoch 8/10, Batch 70/97, Loss: 0.3619
Epoch 8/10, Batch 80/97, Loss: 0.1785
Epoch 8/10, Batch 90/97, Loss: 0.1721
Epoch 8/10, Train Loss: 0.2136, Valid Loss: 0.2306
Epoch 9/10, Batch 10/97, Loss: 0.1554
Epoch 9/10, Batch 20/97, Loss: 0.0567
Epoch 9/10, Batch 30/97, Loss: 0.2176
Epoch 9/10, Batch 40/97, Loss: 0.1011
Epoch 9/10, Batch 50/97, Loss: 0.3380
Epoch 9/10, Batch 60/97, Loss: 0.1724
Epoch 9/10, Batch 70/97, Loss: 0.2415
Epoch 9/10, Batch 80/97, Loss: 0.2185
Epoch 9/10, Batch 90/97, Loss: 0.1884
Epoch 9/10, Train Loss: 0.2081, Valid Loss: 0.2313
Epoch 10/10, Batch 10/97, Loss: 0.2044
Epoch 10/10, Batch 20/97, Loss: 0.1381
Epoch 10/10, Batch 30/97, Loss: 0.2565
Epoch 10/10, Batch 40/97, Loss: 0.2084
Epoch 10/10, Batch 50/97, Loss: 0.2335
Epoch 10/10, Batch 60/97, Loss: 0.2042
Epoch 10/10, Batch 70/97, Loss: 0.2642
Epoch 10/10, Batch 80/97, Loss: 0.1416
Epoch 10/10, Batch 90/97, Loss: 0.1957
Epoch 10/10, Train Loss: 0.1931, Valid Loss: 0.2261
Model saved!
Accuracy: 0.9276
Precision: 0.9255
Recall: 0.9276
F1-score: 0.9260
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 61. Fitness: 0.9276
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4480
Epoch 1/10, Batch 20/97, Loss: 0.9770
Epoch 1/10, Batch 30/97, Loss: 0.7981
Epoch 1/10, Batch 40/97, Loss: 0.7390
Epoch 1/10, Batch 50/97, Loss: 0.5895
Epoch 1/10, Batch 60/97, Loss: 0.6035
Epoch 1/10, Batch 70/97, Loss: 0.4777
Epoch 1/10, Batch 80/97, Loss: 0.5573
Epoch 1/10, Batch 90/97, Loss: 0.4837
Epoch 1/10, Train Loss: 0.7797, Valid Loss: 0.4460
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3980
Epoch 2/10, Batch 20/97, Loss: 0.5574
Epoch 2/10, Batch 30/97, Loss: 0.3417
Epoch 2/10, Batch 40/97, Loss: 0.4815
Epoch 2/10, Batch 50/97, Loss: 0.6028
Epoch 2/10, Batch 60/97, Loss: 0.3379
Epoch 2/10, Batch 70/97, Loss: 0.2731
Epoch 2/10, Batch 80/97, Loss: 0.2551
Epoch 2/10, Batch 90/97, Loss: 0.3603
Epoch 2/10, Train Loss: 0.3875, Valid Loss: 0.3403
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3219
Epoch 3/10, Batch 20/97, Loss: 0.2715
Epoch 3/10, Batch 30/97, Loss: 0.3307
Epoch 3/10, Batch 40/97, Loss: 0.3387
Epoch 3/10, Batch 50/97, Loss: 0.3036
Epoch 3/10, Batch 60/97, Loss: 0.3031
Epoch 3/10, Batch 70/97, Loss: 0.3107
Epoch 3/10, Batch 80/97, Loss: 0.3051
Epoch 3/10, Batch 90/97, Loss: 0.2350
Epoch 3/10, Train Loss: 0.3253, Valid Loss: 0.3022
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2392
Epoch 4/10, Batch 20/97, Loss: 0.3724
Epoch 4/10, Batch 30/97, Loss: 0.3951
Epoch 4/10, Batch 40/97, Loss: 0.2841
Epoch 4/10, Batch 50/97, Loss: 0.3452
Epoch 4/10, Batch 60/97, Loss: 0.1525
Epoch 4/10, Batch 70/97, Loss: 0.1434
Epoch 4/10, Batch 80/97, Loss: 0.3179
Epoch 4/10, Batch 90/97, Loss: 0.4133
Epoch 4/10, Train Loss: 0.2836, Valid Loss: 0.2769
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2148
Epoch 5/10, Batch 20/97, Loss: 0.0956
Epoch 5/10, Batch 30/97, Loss: 0.2618
Epoch 5/10, Batch 40/97, Loss: 0.3033
Epoch 5/10, Batch 50/97, Loss: 0.2936
Epoch 5/10, Batch 60/97, Loss: 0.2395
Epoch 5/10, Batch 70/97, Loss: 0.3769
Epoch 5/10, Batch 80/97, Loss: 0.2185
Epoch 5/10, Batch 90/97, Loss: 0.2462
Epoch 5/10, Train Loss: 0.2577, Valid Loss: 0.2656
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1901
Epoch 6/10, Batch 20/97, Loss: 0.2411
Epoch 6/10, Batch 30/97, Loss: 0.1274
Epoch 6/10, Batch 40/97, Loss: 0.3062
Epoch 6/10, Batch 50/97, Loss: 0.2135
Epoch 6/10, Batch 60/97, Loss: 0.2553
Epoch 6/10, Batch 70/97, Loss: 0.2899
Epoch 6/10, Batch 80/97, Loss: 0.1392
Epoch 6/10, Batch 90/97, Loss: 0.2523
Epoch 6/10, Train Loss: 0.2429, Valid Loss: 0.2495
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3722
Epoch 7/10, Batch 20/97, Loss: 0.1458
Epoch 7/10, Batch 30/97, Loss: 0.1158
Epoch 7/10, Batch 40/97, Loss: 0.1452
Epoch 7/10, Batch 50/97, Loss: 0.2446
Epoch 7/10, Batch 60/97, Loss: 0.2975
Epoch 7/10, Batch 70/97, Loss: 0.2620
Epoch 7/10, Batch 80/97, Loss: 0.2628
Epoch 7/10, Batch 90/97, Loss: 0.2832
Epoch 7/10, Train Loss: 0.2426, Valid Loss: 0.2429
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2486
Epoch 8/10, Batch 20/97, Loss: 0.2111
Epoch 8/10, Batch 30/97, Loss: 0.1303
Epoch 8/10, Batch 40/97, Loss: 0.1611
Epoch 8/10, Batch 50/97, Loss: 0.2849
Epoch 8/10, Batch 60/97, Loss: 0.1130
Epoch 8/10, Batch 70/97, Loss: 0.1536
Epoch 8/10, Batch 80/97, Loss: 0.3154
Epoch 8/10, Batch 90/97, Loss: 0.0667
Epoch 8/10, Train Loss: 0.2239, Valid Loss: 0.2401
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0955
Epoch 9/10, Batch 20/97, Loss: 0.0946
Epoch 9/10, Batch 30/97, Loss: 0.2609
Epoch 9/10, Batch 40/97, Loss: 0.0948
Epoch 9/10, Batch 50/97, Loss: 0.1585
Epoch 9/10, Batch 60/97, Loss: 0.2951
Epoch 9/10, Batch 70/97, Loss: 0.1811
Epoch 9/10, Batch 80/97, Loss: 0.3678
Epoch 9/10, Batch 90/97, Loss: 0.3748
Epoch 9/10, Train Loss: 0.2111, Valid Loss: 0.2392
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2763
Epoch 10/10, Batch 20/97, Loss: 0.2283
Epoch 10/10, Batch 30/97, Loss: 0.1539
Epoch 10/10, Batch 40/97, Loss: 0.2030
Epoch 10/10, Batch 50/97, Loss: 0.1871
Epoch 10/10, Batch 60/97, Loss: 0.1528
Epoch 10/10, Batch 70/97, Loss: 0.1524
Epoch 10/10, Batch 80/97, Loss: 0.2480
Epoch 10/10, Batch 90/97, Loss: 0.1678
Epoch 10/10, Train Loss: 0.1968, Valid Loss: 0.2284
Model saved!
Accuracy: 0.9171
Precision: 0.9147
Recall: 0.9171
F1-score: 0.9155
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5293
Epoch 1/10, Batch 20/97, Loss: 1.0091
Epoch 1/10, Batch 30/97, Loss: 0.8788
Epoch 1/10, Batch 40/97, Loss: 0.8173
Epoch 1/10, Batch 50/97, Loss: 0.5825
Epoch 1/10, Batch 60/97, Loss: 0.5645
Epoch 1/10, Batch 70/97, Loss: 0.4569
Epoch 1/10, Batch 80/97, Loss: 0.4406
Epoch 1/10, Batch 90/97, Loss: 0.5345
Epoch 1/10, Train Loss: 0.7802, Valid Loss: 0.4394
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4435
Epoch 2/10, Batch 20/97, Loss: 0.6270
Epoch 2/10, Batch 30/97, Loss: 0.4196
Epoch 2/10, Batch 40/97, Loss: 0.3333
Epoch 2/10, Batch 50/97, Loss: 0.6543
Epoch 2/10, Batch 60/97, Loss: 0.2460
Epoch 2/10, Batch 70/97, Loss: 0.1775
Epoch 2/10, Batch 80/97, Loss: 0.1940
Epoch 2/10, Batch 90/97, Loss: 0.3498
Epoch 2/10, Train Loss: 0.3952, Valid Loss: 0.3408
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2644
Epoch 3/10, Batch 20/97, Loss: 0.3566
Epoch 3/10, Batch 30/97, Loss: 0.2037
Epoch 3/10, Batch 40/97, Loss: 0.3508
Epoch 3/10, Batch 50/97, Loss: 0.3539
Epoch 3/10, Batch 60/97, Loss: 0.2380
Epoch 3/10, Batch 70/97, Loss: 0.1814
Epoch 3/10, Batch 80/97, Loss: 0.2830
Epoch 3/10, Batch 90/97, Loss: 0.2364
Epoch 3/10, Train Loss: 0.3311, Valid Loss: 0.3030
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2622
Epoch 4/10, Batch 20/97, Loss: 0.2682
Epoch 4/10, Batch 30/97, Loss: 0.2999
Epoch 4/10, Batch 40/97, Loss: 0.2499
Epoch 4/10, Batch 50/97, Loss: 0.1247
Epoch 4/10, Batch 60/97, Loss: 0.1762
Epoch 4/10, Batch 70/97, Loss: 0.2567
Epoch 4/10, Batch 80/97, Loss: 0.2578
Epoch 4/10, Batch 90/97, Loss: 0.2789
Epoch 4/10, Train Loss: 0.2879, Valid Loss: 0.2870
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2730
Epoch 5/10, Batch 20/97, Loss: 0.2226
Epoch 5/10, Batch 30/97, Loss: 0.1968
Epoch 5/10, Batch 40/97, Loss: 0.1240
Epoch 5/10, Batch 50/97, Loss: 0.2278
Epoch 5/10, Batch 60/97, Loss: 0.1778
Epoch 5/10, Batch 70/97, Loss: 0.3387
Epoch 5/10, Batch 80/97, Loss: 0.3103
Epoch 5/10, Batch 90/97, Loss: 0.4813
Epoch 5/10, Train Loss: 0.2565, Valid Loss: 0.2741
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2065
Epoch 6/10, Batch 20/97, Loss: 0.2526
Epoch 6/10, Batch 30/97, Loss: 0.1216
Epoch 6/10, Batch 40/97, Loss: 0.3024
Epoch 6/10, Batch 50/97, Loss: 0.1706
Epoch 6/10, Batch 60/97, Loss: 0.2297
Epoch 6/10, Batch 70/97, Loss: 0.4336
Epoch 6/10, Batch 80/97, Loss: 0.1173
Epoch 6/10, Batch 90/97, Loss: 0.2990
Epoch 6/10, Train Loss: 0.2458, Valid Loss: 0.2755
Epoch 7/10, Batch 10/97, Loss: 0.2365
Epoch 7/10, Batch 20/97, Loss: 0.1427
Epoch 7/10, Batch 30/97, Loss: 0.2502
Epoch 7/10, Batch 40/97, Loss: 0.1602
Epoch 7/10, Batch 50/97, Loss: 0.2733
Epoch 7/10, Batch 60/97, Loss: 0.3453
Epoch 7/10, Batch 70/97, Loss: 0.1718
Epoch 7/10, Batch 80/97, Loss: 0.1762
Epoch 7/10, Batch 90/97, Loss: 0.2762
Epoch 7/10, Train Loss: 0.2486, Valid Loss: 0.2581
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1753
Epoch 8/10, Batch 20/97, Loss: 0.3322
Epoch 8/10, Batch 30/97, Loss: 0.3208
Epoch 8/10, Batch 40/97, Loss: 0.2196
Epoch 8/10, Batch 50/97, Loss: 0.2634
Epoch 8/10, Batch 60/97, Loss: 0.1581
Epoch 8/10, Batch 70/97, Loss: 0.2703
Epoch 8/10, Batch 80/97, Loss: 0.1442
Epoch 8/10, Batch 90/97, Loss: 0.1873
Epoch 8/10, Train Loss: 0.2229, Valid Loss: 0.2615
Epoch 9/10, Batch 10/97, Loss: 0.2402
Epoch 9/10, Batch 20/97, Loss: 0.1184
Epoch 9/10, Batch 30/97, Loss: 0.3570
Epoch 9/10, Batch 40/97, Loss: 0.1423
Epoch 9/10, Batch 50/97, Loss: 0.1518
Epoch 9/10, Batch 60/97, Loss: 0.3004
Epoch 9/10, Batch 70/97, Loss: 0.2206
Epoch 9/10, Batch 80/97, Loss: 0.2579
Epoch 9/10, Batch 90/97, Loss: 0.2601
Epoch 9/10, Train Loss: 0.2056, Valid Loss: 0.2612
Epoch 10/10, Batch 10/97, Loss: 0.3052
Epoch 10/10, Batch 20/97, Loss: 0.1126
Epoch 10/10, Batch 30/97, Loss: 0.4570
Epoch 10/10, Batch 40/97, Loss: 0.1347
Epoch 10/10, Batch 50/97, Loss: 0.2633
Epoch 10/10, Batch 60/97, Loss: 0.1475
Epoch 10/10, Batch 70/97, Loss: 0.1528
Epoch 10/10, Batch 80/97, Loss: 0.3662
Epoch 10/10, Batch 90/97, Loss: 0.1666
Epoch 10/10, Train Loss: 0.1945, Valid Loss: 0.2543
Model saved!
Accuracy: 0.9206
Precision: 0.9180
Recall: 0.9206
F1-score: 0.9187
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4932
Epoch 1/10, Batch 20/97, Loss: 1.0082
Epoch 1/10, Batch 30/97, Loss: 0.9405
Epoch 1/10, Batch 40/97, Loss: 0.7212
Epoch 1/10, Batch 50/97, Loss: 0.5695
Epoch 1/10, Batch 60/97, Loss: 0.6013
Epoch 1/10, Batch 70/97, Loss: 0.5214
Epoch 1/10, Batch 80/97, Loss: 0.4776
Epoch 1/10, Batch 90/97, Loss: 0.6130
Epoch 1/10, Train Loss: 0.7832, Valid Loss: 0.4229
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3192
Epoch 2/10, Batch 20/97, Loss: 0.4901
Epoch 2/10, Batch 30/97, Loss: 0.3812
Epoch 2/10, Batch 40/97, Loss: 0.4174
Epoch 2/10, Batch 50/97, Loss: 0.4545
Epoch 2/10, Batch 60/97, Loss: 0.3763
Epoch 2/10, Batch 70/97, Loss: 0.2700
Epoch 2/10, Batch 80/97, Loss: 0.2360
Epoch 2/10, Batch 90/97, Loss: 0.4072
Epoch 2/10, Train Loss: 0.3987, Valid Loss: 0.3190
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3310
Epoch 3/10, Batch 20/97, Loss: 0.2864
Epoch 3/10, Batch 30/97, Loss: 0.4367
Epoch 3/10, Batch 40/97, Loss: 0.1940
Epoch 3/10, Batch 50/97, Loss: 0.2370
Epoch 3/10, Batch 60/97, Loss: 0.1812
Epoch 3/10, Batch 70/97, Loss: 0.1561
Epoch 3/10, Batch 80/97, Loss: 0.2733
Epoch 3/10, Batch 90/97, Loss: 0.3581
Epoch 3/10, Train Loss: 0.3261, Valid Loss: 0.2739
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3294
Epoch 4/10, Batch 20/97, Loss: 0.2901
Epoch 4/10, Batch 30/97, Loss: 0.5316
Epoch 4/10, Batch 40/97, Loss: 0.2988
Epoch 4/10, Batch 50/97, Loss: 0.1659
Epoch 4/10, Batch 60/97, Loss: 0.1311
Epoch 4/10, Batch 70/97, Loss: 0.2281
Epoch 4/10, Batch 80/97, Loss: 0.3050
Epoch 4/10, Batch 90/97, Loss: 0.3502
Epoch 4/10, Train Loss: 0.2897, Valid Loss: 0.2552
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1314
Epoch 5/10, Batch 20/97, Loss: 0.2456
Epoch 5/10, Batch 30/97, Loss: 0.1434
Epoch 5/10, Batch 40/97, Loss: 0.1330
Epoch 5/10, Batch 50/97, Loss: 0.1817
Epoch 5/10, Batch 60/97, Loss: 0.2159
Epoch 5/10, Batch 70/97, Loss: 0.2837
Epoch 5/10, Batch 80/97, Loss: 0.2065
Epoch 5/10, Batch 90/97, Loss: 0.5546
Epoch 5/10, Train Loss: 0.2628, Valid Loss: 0.2392
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1969
Epoch 6/10, Batch 20/97, Loss: 0.2754
Epoch 6/10, Batch 30/97, Loss: 0.1448
Epoch 6/10, Batch 40/97, Loss: 0.3015
Epoch 6/10, Batch 50/97, Loss: 0.1950
Epoch 6/10, Batch 60/97, Loss: 0.2045
Epoch 6/10, Batch 70/97, Loss: 0.2660
Epoch 6/10, Batch 80/97, Loss: 0.2516
Epoch 6/10, Batch 90/97, Loss: 0.2306
Epoch 6/10, Train Loss: 0.2466, Valid Loss: 0.2333
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2874
Epoch 7/10, Batch 20/97, Loss: 0.2572
Epoch 7/10, Batch 30/97, Loss: 0.2223
Epoch 7/10, Batch 40/97, Loss: 0.1490
Epoch 7/10, Batch 50/97, Loss: 0.1750
Epoch 7/10, Batch 60/97, Loss: 0.2197
Epoch 7/10, Batch 70/97, Loss: 0.3501
Epoch 7/10, Batch 80/97, Loss: 0.2679
Epoch 7/10, Batch 90/97, Loss: 0.1970
Epoch 7/10, Train Loss: 0.2413, Valid Loss: 0.2177
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2426
Epoch 8/10, Batch 20/97, Loss: 0.2259
Epoch 8/10, Batch 30/97, Loss: 0.1340
Epoch 8/10, Batch 40/97, Loss: 0.0947
Epoch 8/10, Batch 50/97, Loss: 0.1724
Epoch 8/10, Batch 60/97, Loss: 0.1762
Epoch 8/10, Batch 70/97, Loss: 0.2217
Epoch 8/10, Batch 80/97, Loss: 0.1282
Epoch 8/10, Batch 90/97, Loss: 0.2531
Epoch 8/10, Train Loss: 0.2225, Valid Loss: 0.2118
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0798
Epoch 9/10, Batch 20/97, Loss: 0.2041
Epoch 9/10, Batch 30/97, Loss: 0.3020
Epoch 9/10, Batch 40/97, Loss: 0.1079
Epoch 9/10, Batch 50/97, Loss: 0.3685
Epoch 9/10, Batch 60/97, Loss: 0.2953
Epoch 9/10, Batch 70/97, Loss: 0.2010
Epoch 9/10, Batch 80/97, Loss: 0.1288
Epoch 9/10, Batch 90/97, Loss: 0.2502
Epoch 9/10, Train Loss: 0.2098, Valid Loss: 0.2165
Epoch 10/10, Batch 10/97, Loss: 0.1836
Epoch 10/10, Batch 20/97, Loss: 0.1661
Epoch 10/10, Batch 30/97, Loss: 0.1895
Epoch 10/10, Batch 40/97, Loss: 0.3408
Epoch 10/10, Batch 50/97, Loss: 0.3521
Epoch 10/10, Batch 60/97, Loss: 0.1265
Epoch 10/10, Batch 70/97, Loss: 0.1485
Epoch 10/10, Batch 80/97, Loss: 0.2503
Epoch 10/10, Batch 90/97, Loss: 0.1581
Epoch 10/10, Train Loss: 0.2042, Valid Loss: 0.2054
Model saved!
Accuracy: 0.9206
Precision: 0.9187
Recall: 0.9206
F1-score: 0.9192
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5226
Epoch 1/10, Batch 20/97, Loss: 0.9909
Epoch 1/10, Batch 30/97, Loss: 0.9706
Epoch 1/10, Batch 40/97, Loss: 0.6450
Epoch 1/10, Batch 50/97, Loss: 0.6069
Epoch 1/10, Batch 60/97, Loss: 0.5324
Epoch 1/10, Batch 70/97, Loss: 0.4590
Epoch 1/10, Batch 80/97, Loss: 0.4899
Epoch 1/10, Batch 90/97, Loss: 0.5248
Epoch 1/10, Train Loss: 0.7716, Valid Loss: 0.4505
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3364
Epoch 2/10, Batch 20/97, Loss: 0.6340
Epoch 2/10, Batch 30/97, Loss: 0.4312
Epoch 2/10, Batch 40/97, Loss: 0.4103
Epoch 2/10, Batch 50/97, Loss: 0.4261
Epoch 2/10, Batch 60/97, Loss: 0.2471
Epoch 2/10, Batch 70/97, Loss: 0.4822
Epoch 2/10, Batch 80/97, Loss: 0.2680
Epoch 2/10, Batch 90/97, Loss: 0.2307
Epoch 2/10, Train Loss: 0.3988, Valid Loss: 0.3577
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3091
Epoch 3/10, Batch 20/97, Loss: 0.2664
Epoch 3/10, Batch 30/97, Loss: 0.2737
Epoch 3/10, Batch 40/97, Loss: 0.2176
Epoch 3/10, Batch 50/97, Loss: 0.2832
Epoch 3/10, Batch 60/97, Loss: 0.3519
Epoch 3/10, Batch 70/97, Loss: 0.1870
Epoch 3/10, Batch 80/97, Loss: 0.3132
Epoch 3/10, Batch 90/97, Loss: 0.2710
Epoch 3/10, Train Loss: 0.3228, Valid Loss: 0.3178
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3130
Epoch 4/10, Batch 20/97, Loss: 0.1811
Epoch 4/10, Batch 30/97, Loss: 0.4716
Epoch 4/10, Batch 40/97, Loss: 0.2607
Epoch 4/10, Batch 50/97, Loss: 0.2160
Epoch 4/10, Batch 60/97, Loss: 0.1684
Epoch 4/10, Batch 70/97, Loss: 0.2568
Epoch 4/10, Batch 80/97, Loss: 0.2841
Epoch 4/10, Batch 90/97, Loss: 0.2304
Epoch 4/10, Train Loss: 0.2802, Valid Loss: 0.2975
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1468
Epoch 5/10, Batch 20/97, Loss: 0.2163
Epoch 5/10, Batch 30/97, Loss: 0.2484
Epoch 5/10, Batch 40/97, Loss: 0.2025
Epoch 5/10, Batch 50/97, Loss: 0.3577
Epoch 5/10, Batch 60/97, Loss: 0.2260
Epoch 5/10, Batch 70/97, Loss: 0.1934
Epoch 5/10, Batch 80/97, Loss: 0.2517
Epoch 5/10, Batch 90/97, Loss: 0.4087
Epoch 5/10, Train Loss: 0.2537, Valid Loss: 0.2810
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1928
Epoch 6/10, Batch 20/97, Loss: 0.1944
Epoch 6/10, Batch 30/97, Loss: 0.1562
Epoch 6/10, Batch 40/97, Loss: 0.2008
Epoch 6/10, Batch 50/97, Loss: 0.1588
Epoch 6/10, Batch 60/97, Loss: 0.3582
Epoch 6/10, Batch 70/97, Loss: 0.2736
Epoch 6/10, Batch 80/97, Loss: 0.1902
Epoch 6/10, Batch 90/97, Loss: 0.1577
Epoch 6/10, Train Loss: 0.2343, Valid Loss: 0.2807
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3649
Epoch 7/10, Batch 20/97, Loss: 0.2118
Epoch 7/10, Batch 30/97, Loss: 0.2304
Epoch 7/10, Batch 40/97, Loss: 0.1858
Epoch 7/10, Batch 50/97, Loss: 0.2269
Epoch 7/10, Batch 60/97, Loss: 0.2382
Epoch 7/10, Batch 70/97, Loss: 0.1546
Epoch 7/10, Batch 80/97, Loss: 0.1779
Epoch 7/10, Batch 90/97, Loss: 0.2841
Epoch 7/10, Train Loss: 0.2443, Valid Loss: 0.2739
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2232
Epoch 8/10, Batch 20/97, Loss: 0.2064
Epoch 8/10, Batch 30/97, Loss: 0.1580
Epoch 8/10, Batch 40/97, Loss: 0.0896
Epoch 8/10, Batch 50/97, Loss: 0.3065
Epoch 8/10, Batch 60/97, Loss: 0.1570
Epoch 8/10, Batch 70/97, Loss: 0.2783
Epoch 8/10, Batch 80/97, Loss: 0.1059
Epoch 8/10, Batch 90/97, Loss: 0.2136
Epoch 8/10, Train Loss: 0.2186, Valid Loss: 0.2696
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1900
Epoch 9/10, Batch 20/97, Loss: 0.0753
Epoch 9/10, Batch 30/97, Loss: 0.3389
Epoch 9/10, Batch 40/97, Loss: 0.1195
Epoch 9/10, Batch 50/97, Loss: 0.1754
Epoch 9/10, Batch 60/97, Loss: 0.1725
Epoch 9/10, Batch 70/97, Loss: 0.1309
Epoch 9/10, Batch 80/97, Loss: 0.1782
Epoch 9/10, Batch 90/97, Loss: 0.3609
Epoch 9/10, Train Loss: 0.2097, Valid Loss: 0.2716
Epoch 10/10, Batch 10/97, Loss: 0.2632
Epoch 10/10, Batch 20/97, Loss: 0.0792
Epoch 10/10, Batch 30/97, Loss: 0.1114
Epoch 10/10, Batch 40/97, Loss: 0.3541
Epoch 10/10, Batch 50/97, Loss: 0.3150
Epoch 10/10, Batch 60/97, Loss: 0.1366
Epoch 10/10, Batch 70/97, Loss: 0.2137
Epoch 10/10, Batch 80/97, Loss: 0.1267
Epoch 10/10, Batch 90/97, Loss: 0.2348
Epoch 10/10, Train Loss: 0.1977, Valid Loss: 0.2664
Model saved!
Accuracy: 0.9136
Precision: 0.9107
Recall: 0.9136
F1-score: 0.9116
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4703
Epoch 1/10, Batch 20/97, Loss: 0.9666
Epoch 1/10, Batch 30/97, Loss: 0.8241
Epoch 1/10, Batch 40/97, Loss: 0.8731
Epoch 1/10, Batch 50/97, Loss: 0.6623
Epoch 1/10, Batch 60/97, Loss: 0.6340
Epoch 1/10, Batch 70/97, Loss: 0.4245
Epoch 1/10, Batch 80/97, Loss: 0.4143
Epoch 1/10, Batch 90/97, Loss: 0.6015
Epoch 1/10, Train Loss: 0.7811, Valid Loss: 0.4309
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4835
Epoch 2/10, Batch 20/97, Loss: 0.6807
Epoch 2/10, Batch 30/97, Loss: 0.4359
Epoch 2/10, Batch 40/97, Loss: 0.3885
Epoch 2/10, Batch 50/97, Loss: 0.7825
Epoch 2/10, Batch 60/97, Loss: 0.3264
Epoch 2/10, Batch 70/97, Loss: 0.4169
Epoch 2/10, Batch 80/97, Loss: 0.3098
Epoch 2/10, Batch 90/97, Loss: 0.3903
Epoch 2/10, Train Loss: 0.4025, Valid Loss: 0.3230
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2703
Epoch 3/10, Batch 20/97, Loss: 0.2490
Epoch 3/10, Batch 30/97, Loss: 0.3138
Epoch 3/10, Batch 40/97, Loss: 0.2142
Epoch 3/10, Batch 50/97, Loss: 0.2473
Epoch 3/10, Batch 60/97, Loss: 0.2929
Epoch 3/10, Batch 70/97, Loss: 0.1869
Epoch 3/10, Batch 80/97, Loss: 0.4255
Epoch 3/10, Batch 90/97, Loss: 0.3408
Epoch 3/10, Train Loss: 0.3321, Valid Loss: 0.2824
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3247
Epoch 4/10, Batch 20/97, Loss: 0.2605
Epoch 4/10, Batch 30/97, Loss: 0.4044
Epoch 4/10, Batch 40/97, Loss: 0.2912
Epoch 4/10, Batch 50/97, Loss: 0.2060
Epoch 4/10, Batch 60/97, Loss: 0.1500
Epoch 4/10, Batch 70/97, Loss: 0.3099
Epoch 4/10, Batch 80/97, Loss: 0.2881
Epoch 4/10, Batch 90/97, Loss: 0.1812
Epoch 4/10, Train Loss: 0.2938, Valid Loss: 0.2522
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3475
Epoch 5/10, Batch 20/97, Loss: 0.1827
Epoch 5/10, Batch 30/97, Loss: 0.2173
Epoch 5/10, Batch 40/97, Loss: 0.2015
Epoch 5/10, Batch 50/97, Loss: 0.1621
Epoch 5/10, Batch 60/97, Loss: 0.2167
Epoch 5/10, Batch 70/97, Loss: 0.2577
Epoch 5/10, Batch 80/97, Loss: 0.2085
Epoch 5/10, Batch 90/97, Loss: 0.3269
Epoch 5/10, Train Loss: 0.2705, Valid Loss: 0.2458
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2147
Epoch 6/10, Batch 20/97, Loss: 0.2308
Epoch 6/10, Batch 30/97, Loss: 0.5338
Epoch 6/10, Batch 40/97, Loss: 0.2873
Epoch 6/10, Batch 50/97, Loss: 0.1413
Epoch 6/10, Batch 60/97, Loss: 0.2419
Epoch 6/10, Batch 70/97, Loss: 0.2240
Epoch 6/10, Batch 80/97, Loss: 0.1147
Epoch 6/10, Batch 90/97, Loss: 0.2680
Epoch 6/10, Train Loss: 0.2487, Valid Loss: 0.2397
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4846
Epoch 7/10, Batch 20/97, Loss: 0.1096
Epoch 7/10, Batch 30/97, Loss: 0.2859
Epoch 7/10, Batch 40/97, Loss: 0.1683
Epoch 7/10, Batch 50/97, Loss: 0.2041
Epoch 7/10, Batch 60/97, Loss: 0.2073
Epoch 7/10, Batch 70/97, Loss: 0.2497
Epoch 7/10, Batch 80/97, Loss: 0.3268
Epoch 7/10, Batch 90/97, Loss: 0.2713
Epoch 7/10, Train Loss: 0.2536, Valid Loss: 0.2283
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1301
Epoch 8/10, Batch 20/97, Loss: 0.1453
Epoch 8/10, Batch 30/97, Loss: 0.3122
Epoch 8/10, Batch 40/97, Loss: 0.1686
Epoch 8/10, Batch 50/97, Loss: 0.1325
Epoch 8/10, Batch 60/97, Loss: 0.2411
Epoch 8/10, Batch 70/97, Loss: 0.2791
Epoch 8/10, Batch 80/97, Loss: 0.2065
Epoch 8/10, Batch 90/97, Loss: 0.3161
Epoch 8/10, Train Loss: 0.2269, Valid Loss: 0.2233
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2754
Epoch 9/10, Batch 20/97, Loss: 0.1235
Epoch 9/10, Batch 30/97, Loss: 0.2419
Epoch 9/10, Batch 40/97, Loss: 0.1042
Epoch 9/10, Batch 50/97, Loss: 0.2251
Epoch 9/10, Batch 60/97, Loss: 0.1286
Epoch 9/10, Batch 70/97, Loss: 0.1966
Epoch 9/10, Batch 80/97, Loss: 0.1874
Epoch 9/10, Batch 90/97, Loss: 0.2847
Epoch 9/10, Train Loss: 0.2203, Valid Loss: 0.2183
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1144
Epoch 10/10, Batch 20/97, Loss: 0.2068
Epoch 10/10, Batch 30/97, Loss: 0.1820
Epoch 10/10, Batch 40/97, Loss: 0.3169
Epoch 10/10, Batch 50/97, Loss: 0.1767
Epoch 10/10, Batch 60/97, Loss: 0.1292
Epoch 10/10, Batch 70/97, Loss: 0.1721
Epoch 10/10, Batch 80/97, Loss: 0.1520
Epoch 10/10, Batch 90/97, Loss: 0.1184
Epoch 10/10, Train Loss: 0.2083, Valid Loss: 0.2128
Model saved!
Accuracy: 0.9147
Precision: 0.9158
Recall: 0.9147
F1-score: 0.9142
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5179
Epoch 1/10, Batch 20/97, Loss: 0.9605
Epoch 1/10, Batch 30/97, Loss: 0.9548
Epoch 1/10, Batch 40/97, Loss: 0.7642
Epoch 1/10, Batch 50/97, Loss: 0.6176
Epoch 1/10, Batch 60/97, Loss: 0.5197
Epoch 1/10, Batch 70/97, Loss: 0.5718
Epoch 1/10, Batch 80/97, Loss: 0.4008
Epoch 1/10, Batch 90/97, Loss: 0.5754
Epoch 1/10, Train Loss: 0.7858, Valid Loss: 0.4532
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4211
Epoch 2/10, Batch 20/97, Loss: 0.4840
Epoch 2/10, Batch 30/97, Loss: 0.3507
Epoch 2/10, Batch 40/97, Loss: 0.3574
Epoch 2/10, Batch 50/97, Loss: 0.5028
Epoch 2/10, Batch 60/97, Loss: 0.3743
Epoch 2/10, Batch 70/97, Loss: 0.3362
Epoch 2/10, Batch 80/97, Loss: 0.3442
Epoch 2/10, Batch 90/97, Loss: 0.2583
Epoch 2/10, Train Loss: 0.4004, Valid Loss: 0.3661
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2627
Epoch 3/10, Batch 20/97, Loss: 0.3901
Epoch 3/10, Batch 30/97, Loss: 0.2756
Epoch 3/10, Batch 40/97, Loss: 0.2510
Epoch 3/10, Batch 50/97, Loss: 0.6221
Epoch 3/10, Batch 60/97, Loss: 0.2433
Epoch 3/10, Batch 70/97, Loss: 0.2624
Epoch 3/10, Batch 80/97, Loss: 0.4312
Epoch 3/10, Batch 90/97, Loss: 0.2903
Epoch 3/10, Train Loss: 0.3343, Valid Loss: 0.3412
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1651
Epoch 4/10, Batch 20/97, Loss: 0.1870
Epoch 4/10, Batch 30/97, Loss: 0.2586
Epoch 4/10, Batch 40/97, Loss: 0.3162
Epoch 4/10, Batch 50/97, Loss: 0.2350
Epoch 4/10, Batch 60/97, Loss: 0.2057
Epoch 4/10, Batch 70/97, Loss: 0.3884
Epoch 4/10, Batch 80/97, Loss: 0.2243
Epoch 4/10, Batch 90/97, Loss: 0.2852
Epoch 4/10, Train Loss: 0.2938, Valid Loss: 0.3298
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2202
Epoch 5/10, Batch 20/97, Loss: 0.1725
Epoch 5/10, Batch 30/97, Loss: 0.1616
Epoch 5/10, Batch 40/97, Loss: 0.1050
Epoch 5/10, Batch 50/97, Loss: 0.3713
Epoch 5/10, Batch 60/97, Loss: 0.3403
Epoch 5/10, Batch 70/97, Loss: 0.1676
Epoch 5/10, Batch 80/97, Loss: 0.5194
Epoch 5/10, Batch 90/97, Loss: 0.3536
Epoch 5/10, Train Loss: 0.2601, Valid Loss: 0.3253
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3428
Epoch 6/10, Batch 20/97, Loss: 0.2459
Epoch 6/10, Batch 30/97, Loss: 0.2166
Epoch 6/10, Batch 40/97, Loss: 0.2065
Epoch 6/10, Batch 50/97, Loss: 0.3012
Epoch 6/10, Batch 60/97, Loss: 0.2901
Epoch 6/10, Batch 70/97, Loss: 0.3232
Epoch 6/10, Batch 80/97, Loss: 0.1261
Epoch 6/10, Batch 90/97, Loss: 0.2958
Epoch 6/10, Train Loss: 0.2443, Valid Loss: 0.3172
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4431
Epoch 7/10, Batch 20/97, Loss: 0.1677
Epoch 7/10, Batch 30/97, Loss: 0.2799
Epoch 7/10, Batch 40/97, Loss: 0.2662
Epoch 7/10, Batch 50/97, Loss: 0.3720
Epoch 7/10, Batch 60/97, Loss: 0.2523
Epoch 7/10, Batch 70/97, Loss: 0.2398
Epoch 7/10, Batch 80/97, Loss: 0.1511
Epoch 7/10, Batch 90/97, Loss: 0.3328
Epoch 7/10, Train Loss: 0.2485, Valid Loss: 0.3220
Epoch 8/10, Batch 10/97, Loss: 0.2159
Epoch 8/10, Batch 20/97, Loss: 0.3079
Epoch 8/10, Batch 30/97, Loss: 0.1954
Epoch 8/10, Batch 40/97, Loss: 0.0543
Epoch 8/10, Batch 50/97, Loss: 0.3191
Epoch 8/10, Batch 60/97, Loss: 0.1530
Epoch 8/10, Batch 70/97, Loss: 0.3077
Epoch 8/10, Batch 80/97, Loss: 0.1152
Epoch 8/10, Batch 90/97, Loss: 0.0979
Epoch 8/10, Train Loss: 0.2218, Valid Loss: 0.3102
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1416
Epoch 9/10, Batch 20/97, Loss: 0.0880
Epoch 9/10, Batch 30/97, Loss: 0.1841
Epoch 9/10, Batch 40/97, Loss: 0.1277
Epoch 9/10, Batch 50/97, Loss: 0.1748
Epoch 9/10, Batch 60/97, Loss: 0.1052
Epoch 9/10, Batch 70/97, Loss: 0.2421
Epoch 9/10, Batch 80/97, Loss: 0.1895
Epoch 9/10, Batch 90/97, Loss: 0.1558
Epoch 9/10, Train Loss: 0.2150, Valid Loss: 0.3252
Epoch 10/10, Batch 10/97, Loss: 0.2627
Epoch 10/10, Batch 20/97, Loss: 0.1272
Epoch 10/10, Batch 30/97, Loss: 0.2074
Epoch 10/10, Batch 40/97, Loss: 0.3418
Epoch 10/10, Batch 50/97, Loss: 0.2240
Epoch 10/10, Batch 60/97, Loss: 0.1105
Epoch 10/10, Batch 70/97, Loss: 0.3189
Epoch 10/10, Batch 80/97, Loss: 0.1368
Epoch 10/10, Batch 90/97, Loss: 0.1138
Epoch 10/10, Train Loss: 0.2010, Valid Loss: 0.3244
Accuracy: 0.9124
Precision: 0.9095
Recall: 0.9124
F1-score: 0.9102
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4574
Epoch 1/10, Batch 20/97, Loss: 0.9959
Epoch 1/10, Batch 30/97, Loss: 0.8882
Epoch 1/10, Batch 40/97, Loss: 0.7912
Epoch 1/10, Batch 50/97, Loss: 0.7541
Epoch 1/10, Batch 60/97, Loss: 0.6868
Epoch 1/10, Batch 70/97, Loss: 0.5703
Epoch 1/10, Batch 80/97, Loss: 0.4845
Epoch 1/10, Batch 90/97, Loss: 0.4423
Epoch 1/10, Train Loss: 0.7818, Valid Loss: 0.4215
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3838
Epoch 2/10, Batch 20/97, Loss: 0.4156
Epoch 2/10, Batch 30/97, Loss: 0.4224
Epoch 2/10, Batch 40/97, Loss: 0.4068
Epoch 2/10, Batch 50/97, Loss: 0.7126
Epoch 2/10, Batch 60/97, Loss: 0.2857
Epoch 2/10, Batch 70/97, Loss: 0.2536
Epoch 2/10, Batch 80/97, Loss: 0.3728
Epoch 2/10, Batch 90/97, Loss: 0.3576
Epoch 2/10, Train Loss: 0.4028, Valid Loss: 0.3203
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2796
Epoch 3/10, Batch 20/97, Loss: 0.3581
Epoch 3/10, Batch 30/97, Loss: 0.2520
Epoch 3/10, Batch 40/97, Loss: 0.2399
Epoch 3/10, Batch 50/97, Loss: 0.2812
Epoch 3/10, Batch 60/97, Loss: 0.2190
Epoch 3/10, Batch 70/97, Loss: 0.2661
Epoch 3/10, Batch 80/97, Loss: 0.2603
Epoch 3/10, Batch 90/97, Loss: 0.3121
Epoch 3/10, Train Loss: 0.3258, Valid Loss: 0.2823
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3028
Epoch 4/10, Batch 20/97, Loss: 0.2579
Epoch 4/10, Batch 30/97, Loss: 0.3352
Epoch 4/10, Batch 40/97, Loss: 0.2213
Epoch 4/10, Batch 50/97, Loss: 0.1374
Epoch 4/10, Batch 60/97, Loss: 0.2286
Epoch 4/10, Batch 70/97, Loss: 0.1847
Epoch 4/10, Batch 80/97, Loss: 0.2960
Epoch 4/10, Batch 90/97, Loss: 0.1389
Epoch 4/10, Train Loss: 0.2906, Valid Loss: 0.2611
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1469
Epoch 5/10, Batch 20/97, Loss: 0.1807
Epoch 5/10, Batch 30/97, Loss: 0.1964
Epoch 5/10, Batch 40/97, Loss: 0.2427
Epoch 5/10, Batch 50/97, Loss: 0.3415
Epoch 5/10, Batch 60/97, Loss: 0.2324
Epoch 5/10, Batch 70/97, Loss: 0.2691
Epoch 5/10, Batch 80/97, Loss: 0.1774
Epoch 5/10, Batch 90/97, Loss: 0.1924
Epoch 5/10, Train Loss: 0.2652, Valid Loss: 0.2436
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2230
Epoch 6/10, Batch 20/97, Loss: 0.3609
Epoch 6/10, Batch 30/97, Loss: 0.2410
Epoch 6/10, Batch 40/97, Loss: 0.2774
Epoch 6/10, Batch 50/97, Loss: 0.1983
Epoch 6/10, Batch 60/97, Loss: 0.4514
Epoch 6/10, Batch 70/97, Loss: 0.1946
Epoch 6/10, Batch 80/97, Loss: 0.3063
Epoch 6/10, Batch 90/97, Loss: 0.2987
Epoch 6/10, Train Loss: 0.2517, Valid Loss: 0.2421
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2599
Epoch 7/10, Batch 20/97, Loss: 0.1132
Epoch 7/10, Batch 30/97, Loss: 0.1614
Epoch 7/10, Batch 40/97, Loss: 0.1411
Epoch 7/10, Batch 50/97, Loss: 0.2468
Epoch 7/10, Batch 60/97, Loss: 0.3035
Epoch 7/10, Batch 70/97, Loss: 0.2657
Epoch 7/10, Batch 80/97, Loss: 0.2134
Epoch 7/10, Batch 90/97, Loss: 0.2778
Epoch 7/10, Train Loss: 0.2462, Valid Loss: 0.2318
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1829
Epoch 8/10, Batch 20/97, Loss: 0.2572
Epoch 8/10, Batch 30/97, Loss: 0.1378
Epoch 8/10, Batch 40/97, Loss: 0.2912
Epoch 8/10, Batch 50/97, Loss: 0.2798
Epoch 8/10, Batch 60/97, Loss: 0.1101
Epoch 8/10, Batch 70/97, Loss: 0.1915
Epoch 8/10, Batch 80/97, Loss: 0.1649
Epoch 8/10, Batch 90/97, Loss: 0.1931
Epoch 8/10, Train Loss: 0.2214, Valid Loss: 0.2273
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1518
Epoch 9/10, Batch 20/97, Loss: 0.1283
Epoch 9/10, Batch 30/97, Loss: 0.2262
Epoch 9/10, Batch 40/97, Loss: 0.2119
Epoch 9/10, Batch 50/97, Loss: 0.1608
Epoch 9/10, Batch 60/97, Loss: 0.1782
Epoch 9/10, Batch 70/97, Loss: 0.2265
Epoch 9/10, Batch 80/97, Loss: 0.0976
Epoch 9/10, Batch 90/97, Loss: 0.3078
Epoch 9/10, Train Loss: 0.2232, Valid Loss: 0.2258
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2894
Epoch 10/10, Batch 20/97, Loss: 0.1056
Epoch 10/10, Batch 30/97, Loss: 0.2035
Epoch 10/10, Batch 40/97, Loss: 0.3203
Epoch 10/10, Batch 50/97, Loss: 0.2627
Epoch 10/10, Batch 60/97, Loss: 0.1543
Epoch 10/10, Batch 70/97, Loss: 0.1089
Epoch 10/10, Batch 80/97, Loss: 0.1684
Epoch 10/10, Batch 90/97, Loss: 0.1575
Epoch 10/10, Train Loss: 0.2003, Valid Loss: 0.2232
Model saved!
Accuracy: 0.9112
Precision: 0.9083
Recall: 0.9112
F1-score: 0.9092
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4670
Epoch 1/10, Batch 20/97, Loss: 1.0207
Epoch 1/10, Batch 30/97, Loss: 0.9017
Epoch 1/10, Batch 40/97, Loss: 0.8179
Epoch 1/10, Batch 50/97, Loss: 0.5701
Epoch 1/10, Batch 60/97, Loss: 0.5857
Epoch 1/10, Batch 70/97, Loss: 0.4401
Epoch 1/10, Batch 80/97, Loss: 0.4258
Epoch 1/10, Batch 90/97, Loss: 0.4728
Epoch 1/10, Train Loss: 0.7750, Valid Loss: 0.4315
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3364
Epoch 2/10, Batch 20/97, Loss: 0.4829
Epoch 2/10, Batch 30/97, Loss: 0.3942
Epoch 2/10, Batch 40/97, Loss: 0.4029
Epoch 2/10, Batch 50/97, Loss: 0.3981
Epoch 2/10, Batch 60/97, Loss: 0.4293
Epoch 2/10, Batch 70/97, Loss: 0.3960
Epoch 2/10, Batch 80/97, Loss: 0.2956
Epoch 2/10, Batch 90/97, Loss: 0.5234
Epoch 2/10, Train Loss: 0.4040, Valid Loss: 0.3403
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.5033
Epoch 3/10, Batch 20/97, Loss: 0.2930
Epoch 3/10, Batch 30/97, Loss: 0.2533
Epoch 3/10, Batch 40/97, Loss: 0.2479
Epoch 3/10, Batch 50/97, Loss: 0.2301
Epoch 3/10, Batch 60/97, Loss: 0.1334
Epoch 3/10, Batch 70/97, Loss: 0.1412
Epoch 3/10, Batch 80/97, Loss: 0.5578
Epoch 3/10, Batch 90/97, Loss: 0.4316
Epoch 3/10, Train Loss: 0.3284, Valid Loss: 0.2944
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2787
Epoch 4/10, Batch 20/97, Loss: 0.2046
Epoch 4/10, Batch 30/97, Loss: 0.3040
Epoch 4/10, Batch 40/97, Loss: 0.3126
Epoch 4/10, Batch 50/97, Loss: 0.1598
Epoch 4/10, Batch 60/97, Loss: 0.2785
Epoch 4/10, Batch 70/97, Loss: 0.2423
Epoch 4/10, Batch 80/97, Loss: 0.2966
Epoch 4/10, Batch 90/97, Loss: 0.2907
Epoch 4/10, Train Loss: 0.2926, Valid Loss: 0.2759
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1986
Epoch 5/10, Batch 20/97, Loss: 0.2593
Epoch 5/10, Batch 30/97, Loss: 0.2162
Epoch 5/10, Batch 40/97, Loss: 0.3116
Epoch 5/10, Batch 50/97, Loss: 0.1218
Epoch 5/10, Batch 60/97, Loss: 0.2721
Epoch 5/10, Batch 70/97, Loss: 0.2844
Epoch 5/10, Batch 80/97, Loss: 0.3668
Epoch 5/10, Batch 90/97, Loss: 0.2807
Epoch 5/10, Train Loss: 0.2680, Valid Loss: 0.2661
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2025
Epoch 6/10, Batch 20/97, Loss: 0.2979
Epoch 6/10, Batch 30/97, Loss: 0.2480
Epoch 6/10, Batch 40/97, Loss: 0.5180
Epoch 6/10, Batch 50/97, Loss: 0.2689
Epoch 6/10, Batch 60/97, Loss: 0.2065
Epoch 6/10, Batch 70/97, Loss: 0.2121
Epoch 6/10, Batch 80/97, Loss: 0.2252
Epoch 6/10, Batch 90/97, Loss: 0.1418
Epoch 6/10, Train Loss: 0.2464, Valid Loss: 0.2584
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2567
Epoch 7/10, Batch 20/97, Loss: 0.1761
Epoch 7/10, Batch 30/97, Loss: 0.2287
Epoch 7/10, Batch 40/97, Loss: 0.1665
Epoch 7/10, Batch 50/97, Loss: 0.1808
Epoch 7/10, Batch 60/97, Loss: 0.2967
Epoch 7/10, Batch 70/97, Loss: 0.1531
Epoch 7/10, Batch 80/97, Loss: 0.4160
Epoch 7/10, Batch 90/97, Loss: 0.2910
Epoch 7/10, Train Loss: 0.2445, Valid Loss: 0.2548
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.3172
Epoch 8/10, Batch 20/97, Loss: 0.2928
Epoch 8/10, Batch 30/97, Loss: 0.1141
Epoch 8/10, Batch 40/97, Loss: 0.1736
Epoch 8/10, Batch 50/97, Loss: 0.2699
Epoch 8/10, Batch 60/97, Loss: 0.1015
Epoch 8/10, Batch 70/97, Loss: 0.2410
Epoch 8/10, Batch 80/97, Loss: 0.3612
Epoch 8/10, Batch 90/97, Loss: 0.1420
Epoch 8/10, Train Loss: 0.2294, Valid Loss: 0.2508
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1087
Epoch 9/10, Batch 20/97, Loss: 0.1172
Epoch 9/10, Batch 30/97, Loss: 0.3255
Epoch 9/10, Batch 40/97, Loss: 0.1272
Epoch 9/10, Batch 50/97, Loss: 0.2147
Epoch 9/10, Batch 60/97, Loss: 0.0945
Epoch 9/10, Batch 70/97, Loss: 0.2073
Epoch 9/10, Batch 80/97, Loss: 0.1499
Epoch 9/10, Batch 90/97, Loss: 0.2049
Epoch 9/10, Train Loss: 0.2113, Valid Loss: 0.2522
Epoch 10/10, Batch 10/97, Loss: 0.2556
Epoch 10/10, Batch 20/97, Loss: 0.1736
Epoch 10/10, Batch 30/97, Loss: 0.1441
Epoch 10/10, Batch 40/97, Loss: 0.3022
Epoch 10/10, Batch 50/97, Loss: 0.2908
Epoch 10/10, Batch 60/97, Loss: 0.1915
Epoch 10/10, Batch 70/97, Loss: 0.2503
Epoch 10/10, Batch 80/97, Loss: 0.1486
Epoch 10/10, Batch 90/97, Loss: 0.2335
Epoch 10/10, Train Loss: 0.2004, Valid Loss: 0.2337
Model saved!
Accuracy: 0.9089
Precision: 0.9064
Recall: 0.9089
F1-score: 0.9069
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4593
Epoch 1/10, Batch 20/97, Loss: 1.0023
Epoch 1/10, Batch 30/97, Loss: 0.8268
Epoch 1/10, Batch 40/97, Loss: 0.6474
Epoch 1/10, Batch 50/97, Loss: 0.5798
Epoch 1/10, Batch 60/97, Loss: 0.5675
Epoch 1/10, Batch 70/97, Loss: 0.4964
Epoch 1/10, Batch 80/97, Loss: 0.4299
Epoch 1/10, Batch 90/97, Loss: 0.5509
Epoch 1/10, Train Loss: 0.7725, Valid Loss: 0.4501
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4242
Epoch 2/10, Batch 20/97, Loss: 0.6137
Epoch 2/10, Batch 30/97, Loss: 0.3609
Epoch 2/10, Batch 40/97, Loss: 0.4604
Epoch 2/10, Batch 50/97, Loss: 0.5345
Epoch 2/10, Batch 60/97, Loss: 0.3833
Epoch 2/10, Batch 70/97, Loss: 0.2864
Epoch 2/10, Batch 80/97, Loss: 0.3359
Epoch 2/10, Batch 90/97, Loss: 0.2007
Epoch 2/10, Train Loss: 0.3894, Valid Loss: 0.3557
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4074
Epoch 3/10, Batch 20/97, Loss: 0.2660
Epoch 3/10, Batch 30/97, Loss: 0.3138
Epoch 3/10, Batch 40/97, Loss: 0.2675
Epoch 3/10, Batch 50/97, Loss: 0.2419
Epoch 3/10, Batch 60/97, Loss: 0.2721
Epoch 3/10, Batch 70/97, Loss: 0.1742
Epoch 3/10, Batch 80/97, Loss: 0.2640
Epoch 3/10, Batch 90/97, Loss: 0.4506
Epoch 3/10, Train Loss: 0.3143, Valid Loss: 0.3152
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2793
Epoch 4/10, Batch 20/97, Loss: 0.2986
Epoch 4/10, Batch 30/97, Loss: 0.3492
Epoch 4/10, Batch 40/97, Loss: 0.2686
Epoch 4/10, Batch 50/97, Loss: 0.1382
Epoch 4/10, Batch 60/97, Loss: 0.1918
Epoch 4/10, Batch 70/97, Loss: 0.3380
Epoch 4/10, Batch 80/97, Loss: 0.2441
Epoch 4/10, Batch 90/97, Loss: 0.1861
Epoch 4/10, Train Loss: 0.2777, Valid Loss: 0.2964
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1260
Epoch 5/10, Batch 20/97, Loss: 0.1998
Epoch 5/10, Batch 30/97, Loss: 0.1340
Epoch 5/10, Batch 40/97, Loss: 0.1456
Epoch 5/10, Batch 50/97, Loss: 0.2698
Epoch 5/10, Batch 60/97, Loss: 0.2747
Epoch 5/10, Batch 70/97, Loss: 0.2154
Epoch 5/10, Batch 80/97, Loss: 0.2066
Epoch 5/10, Batch 90/97, Loss: 0.5596
Epoch 5/10, Train Loss: 0.2509, Valid Loss: 0.2855
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2318
Epoch 6/10, Batch 20/97, Loss: 0.1546
Epoch 6/10, Batch 30/97, Loss: 0.1542
Epoch 6/10, Batch 40/97, Loss: 0.2497
Epoch 6/10, Batch 50/97, Loss: 0.1992
Epoch 6/10, Batch 60/97, Loss: 0.2428
Epoch 6/10, Batch 70/97, Loss: 0.1739
Epoch 6/10, Batch 80/97, Loss: 0.1453
Epoch 6/10, Batch 90/97, Loss: 0.2996
Epoch 6/10, Train Loss: 0.2336, Valid Loss: 0.2797
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3215
Epoch 7/10, Batch 20/97, Loss: 0.1288
Epoch 7/10, Batch 30/97, Loss: 0.1323
Epoch 7/10, Batch 40/97, Loss: 0.1446
Epoch 7/10, Batch 50/97, Loss: 0.1780
Epoch 7/10, Batch 60/97, Loss: 0.3024
Epoch 7/10, Batch 70/97, Loss: 0.1787
Epoch 7/10, Batch 80/97, Loss: 0.2879
Epoch 7/10, Batch 90/97, Loss: 0.2636
Epoch 7/10, Train Loss: 0.2387, Valid Loss: 0.2763
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1446
Epoch 8/10, Batch 20/97, Loss: 0.1607
Epoch 8/10, Batch 30/97, Loss: 0.0839
Epoch 8/10, Batch 40/97, Loss: 0.2916
Epoch 8/10, Batch 50/97, Loss: 0.3369
Epoch 8/10, Batch 60/97, Loss: 0.3418
Epoch 8/10, Batch 70/97, Loss: 0.4472
Epoch 8/10, Batch 80/97, Loss: 0.1856
Epoch 8/10, Batch 90/97, Loss: 0.2460
Epoch 8/10, Train Loss: 0.2086, Valid Loss: 0.2648
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0972
Epoch 9/10, Batch 20/97, Loss: 0.0720
Epoch 9/10, Batch 30/97, Loss: 0.2699
Epoch 9/10, Batch 40/97, Loss: 0.1534
Epoch 9/10, Batch 50/97, Loss: 0.3298
Epoch 9/10, Batch 60/97, Loss: 0.1881
Epoch 9/10, Batch 70/97, Loss: 0.1803
Epoch 9/10, Batch 80/97, Loss: 0.1074
Epoch 9/10, Batch 90/97, Loss: 0.2389
Epoch 9/10, Train Loss: 0.1973, Valid Loss: 0.2606
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2441
Epoch 10/10, Batch 20/97, Loss: 0.1019
Epoch 10/10, Batch 30/97, Loss: 0.3022
Epoch 10/10, Batch 40/97, Loss: 0.0967
Epoch 10/10, Batch 50/97, Loss: 0.1801
Epoch 10/10, Batch 60/97, Loss: 0.2690
Epoch 10/10, Batch 70/97, Loss: 0.1736
Epoch 10/10, Batch 80/97, Loss: 0.3344
Epoch 10/10, Batch 90/97, Loss: 0.1903
Epoch 10/10, Train Loss: 0.1898, Valid Loss: 0.2618
Accuracy: 0.9159
Precision: 0.9132
Recall: 0.9159
F1-score: 0.9137
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4494
Epoch 1/10, Batch 20/97, Loss: 1.0185
Epoch 1/10, Batch 30/97, Loss: 0.9460
Epoch 1/10, Batch 40/97, Loss: 0.7213
Epoch 1/10, Batch 50/97, Loss: 0.6107
Epoch 1/10, Batch 60/97, Loss: 0.5211
Epoch 1/10, Batch 70/97, Loss: 0.5578
Epoch 1/10, Batch 80/97, Loss: 0.4234
Epoch 1/10, Batch 90/97, Loss: 0.5946
Epoch 1/10, Train Loss: 0.7768, Valid Loss: 0.4249
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4100
Epoch 2/10, Batch 20/97, Loss: 0.5573
Epoch 2/10, Batch 30/97, Loss: 0.4031
Epoch 2/10, Batch 40/97, Loss: 0.3447
Epoch 2/10, Batch 50/97, Loss: 0.6372
Epoch 2/10, Batch 60/97, Loss: 0.4364
Epoch 2/10, Batch 70/97, Loss: 0.2814
Epoch 2/10, Batch 80/97, Loss: 0.2967
Epoch 2/10, Batch 90/97, Loss: 0.3084
Epoch 2/10, Train Loss: 0.3937, Valid Loss: 0.3245
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3108
Epoch 3/10, Batch 20/97, Loss: 0.3367
Epoch 3/10, Batch 30/97, Loss: 0.3421
Epoch 3/10, Batch 40/97, Loss: 0.2553
Epoch 3/10, Batch 50/97, Loss: 0.2663
Epoch 3/10, Batch 60/97, Loss: 0.2321
Epoch 3/10, Batch 70/97, Loss: 0.2141
Epoch 3/10, Batch 80/97, Loss: 0.3528
Epoch 3/10, Batch 90/97, Loss: 0.3129
Epoch 3/10, Train Loss: 0.3227, Valid Loss: 0.2894
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3907
Epoch 4/10, Batch 20/97, Loss: 0.2082
Epoch 4/10, Batch 30/97, Loss: 0.4642
Epoch 4/10, Batch 40/97, Loss: 0.2159
Epoch 4/10, Batch 50/97, Loss: 0.1324
Epoch 4/10, Batch 60/97, Loss: 0.3758
Epoch 4/10, Batch 70/97, Loss: 0.2628
Epoch 4/10, Batch 80/97, Loss: 0.2449
Epoch 4/10, Batch 90/97, Loss: 0.1878
Epoch 4/10, Train Loss: 0.2879, Valid Loss: 0.2695
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2686
Epoch 5/10, Batch 20/97, Loss: 0.2835
Epoch 5/10, Batch 30/97, Loss: 0.2228
Epoch 5/10, Batch 40/97, Loss: 0.1581
Epoch 5/10, Batch 50/97, Loss: 0.2190
Epoch 5/10, Batch 60/97, Loss: 0.3163
Epoch 5/10, Batch 70/97, Loss: 0.2672
Epoch 5/10, Batch 80/97, Loss: 0.3941
Epoch 5/10, Batch 90/97, Loss: 0.4132
Epoch 5/10, Train Loss: 0.2609, Valid Loss: 0.2595
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3521
Epoch 6/10, Batch 20/97, Loss: 0.2699
Epoch 6/10, Batch 30/97, Loss: 0.1013
Epoch 6/10, Batch 40/97, Loss: 0.3211
Epoch 6/10, Batch 50/97, Loss: 0.2218
Epoch 6/10, Batch 60/97, Loss: 0.3053
Epoch 6/10, Batch 70/97, Loss: 0.2794
Epoch 6/10, Batch 80/97, Loss: 0.1340
Epoch 6/10, Batch 90/97, Loss: 0.1492
Epoch 6/10, Train Loss: 0.2447, Valid Loss: 0.2506
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2514
Epoch 7/10, Batch 20/97, Loss: 0.1673
Epoch 7/10, Batch 30/97, Loss: 0.2390
Epoch 7/10, Batch 40/97, Loss: 0.2270
Epoch 7/10, Batch 50/97, Loss: 0.1885
Epoch 7/10, Batch 60/97, Loss: 0.2577
Epoch 7/10, Batch 70/97, Loss: 0.1315
Epoch 7/10, Batch 80/97, Loss: 0.1898
Epoch 7/10, Batch 90/97, Loss: 0.2028
Epoch 7/10, Train Loss: 0.2372, Valid Loss: 0.2528
Epoch 8/10, Batch 10/97, Loss: 0.1983
Epoch 8/10, Batch 20/97, Loss: 0.2392
Epoch 8/10, Batch 30/97, Loss: 0.1244
Epoch 8/10, Batch 40/97, Loss: 0.1608
Epoch 8/10, Batch 50/97, Loss: 0.1944
Epoch 8/10, Batch 60/97, Loss: 0.1691
Epoch 8/10, Batch 70/97, Loss: 0.2757
Epoch 8/10, Batch 80/97, Loss: 0.1787
Epoch 8/10, Batch 90/97, Loss: 0.1205
Epoch 8/10, Train Loss: 0.2277, Valid Loss: 0.2429
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1512
Epoch 9/10, Batch 20/97, Loss: 0.2101
Epoch 9/10, Batch 30/97, Loss: 0.4141
Epoch 9/10, Batch 40/97, Loss: 0.1413
Epoch 9/10, Batch 50/97, Loss: 0.1197
Epoch 9/10, Batch 60/97, Loss: 0.1394
Epoch 9/10, Batch 70/97, Loss: 0.2514
Epoch 9/10, Batch 80/97, Loss: 0.2698
Epoch 9/10, Batch 90/97, Loss: 0.2767
Epoch 9/10, Train Loss: 0.2131, Valid Loss: 0.2399
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2913
Epoch 10/10, Batch 20/97, Loss: 0.1900
Epoch 10/10, Batch 30/97, Loss: 0.1846
Epoch 10/10, Batch 40/97, Loss: 0.1843
Epoch 10/10, Batch 50/97, Loss: 0.1603
Epoch 10/10, Batch 60/97, Loss: 0.1388
Epoch 10/10, Batch 70/97, Loss: 0.1913
Epoch 10/10, Batch 80/97, Loss: 0.2863
Epoch 10/10, Batch 90/97, Loss: 0.1670
Epoch 10/10, Train Loss: 0.1955, Valid Loss: 0.2320
Model saved!
Accuracy: 0.9136
Precision: 0.9103
Recall: 0.9136
F1-score: 0.9111
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4955
Epoch 1/10, Batch 20/97, Loss: 0.9854
Epoch 1/10, Batch 30/97, Loss: 0.8135
Epoch 1/10, Batch 40/97, Loss: 0.6202
Epoch 1/10, Batch 50/97, Loss: 0.6984
Epoch 1/10, Batch 60/97, Loss: 0.6253
Epoch 1/10, Batch 70/97, Loss: 0.4462
Epoch 1/10, Batch 80/97, Loss: 0.5010
Epoch 1/10, Batch 90/97, Loss: 0.5746
Epoch 1/10, Train Loss: 0.7743, Valid Loss: 0.4354
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4770
Epoch 2/10, Batch 20/97, Loss: 0.6499
Epoch 2/10, Batch 30/97, Loss: 0.3835
Epoch 2/10, Batch 40/97, Loss: 0.5094
Epoch 2/10, Batch 50/97, Loss: 0.6965
Epoch 2/10, Batch 60/97, Loss: 0.3082
Epoch 2/10, Batch 70/97, Loss: 0.3658
Epoch 2/10, Batch 80/97, Loss: 0.2970
Epoch 2/10, Batch 90/97, Loss: 0.2127
Epoch 2/10, Train Loss: 0.4074, Valid Loss: 0.3290
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4071
Epoch 3/10, Batch 20/97, Loss: 0.3075
Epoch 3/10, Batch 30/97, Loss: 0.3825
Epoch 3/10, Batch 40/97, Loss: 0.3556
Epoch 3/10, Batch 50/97, Loss: 0.2895
Epoch 3/10, Batch 60/97, Loss: 0.4237
Epoch 3/10, Batch 70/97, Loss: 0.2166
Epoch 3/10, Batch 80/97, Loss: 0.2894
Epoch 3/10, Batch 90/97, Loss: 0.3621
Epoch 3/10, Train Loss: 0.3316, Valid Loss: 0.2927
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3696
Epoch 4/10, Batch 20/97, Loss: 0.3760
Epoch 4/10, Batch 30/97, Loss: 0.4073
Epoch 4/10, Batch 40/97, Loss: 0.2072
Epoch 4/10, Batch 50/97, Loss: 0.1632
Epoch 4/10, Batch 60/97, Loss: 0.1389
Epoch 4/10, Batch 70/97, Loss: 0.2106
Epoch 4/10, Batch 80/97, Loss: 0.2214
Epoch 4/10, Batch 90/97, Loss: 0.2600
Epoch 4/10, Train Loss: 0.2884, Valid Loss: 0.2698
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1982
Epoch 5/10, Batch 20/97, Loss: 0.1998
Epoch 5/10, Batch 30/97, Loss: 0.2897
Epoch 5/10, Batch 40/97, Loss: 0.1791
Epoch 5/10, Batch 50/97, Loss: 0.4022
Epoch 5/10, Batch 60/97, Loss: 0.1581
Epoch 5/10, Batch 70/97, Loss: 0.1932
Epoch 5/10, Batch 80/97, Loss: 0.3708
Epoch 5/10, Batch 90/97, Loss: 0.3079
Epoch 5/10, Train Loss: 0.2732, Valid Loss: 0.2569
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1614
Epoch 6/10, Batch 20/97, Loss: 0.2468
Epoch 6/10, Batch 30/97, Loss: 0.2304
Epoch 6/10, Batch 40/97, Loss: 0.3152
Epoch 6/10, Batch 50/97, Loss: 0.1801
Epoch 6/10, Batch 60/97, Loss: 0.2349
Epoch 6/10, Batch 70/97, Loss: 0.2438
Epoch 6/10, Batch 80/97, Loss: 0.2102
Epoch 6/10, Batch 90/97, Loss: 0.2836
Epoch 6/10, Train Loss: 0.2434, Valid Loss: 0.2366
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3692
Epoch 7/10, Batch 20/97, Loss: 0.1993
Epoch 7/10, Batch 30/97, Loss: 0.2255
Epoch 7/10, Batch 40/97, Loss: 0.0899
Epoch 7/10, Batch 50/97, Loss: 0.1549
Epoch 7/10, Batch 60/97, Loss: 0.3142
Epoch 7/10, Batch 70/97, Loss: 0.2780
Epoch 7/10, Batch 80/97, Loss: 0.1942
Epoch 7/10, Batch 90/97, Loss: 0.2342
Epoch 7/10, Train Loss: 0.2545, Valid Loss: 0.2336
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1395
Epoch 8/10, Batch 20/97, Loss: 0.1587
Epoch 8/10, Batch 30/97, Loss: 0.1662
Epoch 8/10, Batch 40/97, Loss: 0.2652
Epoch 8/10, Batch 50/97, Loss: 0.3726
Epoch 8/10, Batch 60/97, Loss: 0.1142
Epoch 8/10, Batch 70/97, Loss: 0.4127
Epoch 8/10, Batch 80/97, Loss: 0.2080
Epoch 8/10, Batch 90/97, Loss: 0.2333
Epoch 8/10, Train Loss: 0.2303, Valid Loss: 0.2322
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1524
Epoch 9/10, Batch 20/97, Loss: 0.0961
Epoch 9/10, Batch 30/97, Loss: 0.2706
Epoch 9/10, Batch 40/97, Loss: 0.1667
Epoch 9/10, Batch 50/97, Loss: 0.3249
Epoch 9/10, Batch 60/97, Loss: 0.3284
Epoch 9/10, Batch 70/97, Loss: 0.0834
Epoch 9/10, Batch 80/97, Loss: 0.1555
Epoch 9/10, Batch 90/97, Loss: 0.1724
Epoch 9/10, Train Loss: 0.2164, Valid Loss: 0.2300
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1416
Epoch 10/10, Batch 20/97, Loss: 0.1143
Epoch 10/10, Batch 30/97, Loss: 0.1655
Epoch 10/10, Batch 40/97, Loss: 0.2140
Epoch 10/10, Batch 50/97, Loss: 0.3101
Epoch 10/10, Batch 60/97, Loss: 0.2208
Epoch 10/10, Batch 70/97, Loss: 0.1891
Epoch 10/10, Batch 80/97, Loss: 0.1541
Epoch 10/10, Batch 90/97, Loss: 0.1756
Epoch 10/10, Train Loss: 0.2042, Valid Loss: 0.2246
Model saved!
Accuracy: 0.9182
Precision: 0.9167
Recall: 0.9182
F1-score: 0.9172
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5120
Epoch 1/10, Batch 20/97, Loss: 0.9975
Epoch 1/10, Batch 30/97, Loss: 0.8717
Epoch 1/10, Batch 40/97, Loss: 0.6368
Epoch 1/10, Batch 50/97, Loss: 0.5600
Epoch 1/10, Batch 60/97, Loss: 0.5349
Epoch 1/10, Batch 70/97, Loss: 0.5705
Epoch 1/10, Batch 80/97, Loss: 0.4271
Epoch 1/10, Batch 90/97, Loss: 0.6087
Epoch 1/10, Train Loss: 0.7781, Valid Loss: 0.4492
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3834
Epoch 2/10, Batch 20/97, Loss: 0.4472
Epoch 2/10, Batch 30/97, Loss: 0.3591
Epoch 2/10, Batch 40/97, Loss: 0.5379
Epoch 2/10, Batch 50/97, Loss: 0.5785
Epoch 2/10, Batch 60/97, Loss: 0.2970
Epoch 2/10, Batch 70/97, Loss: 0.2467
Epoch 2/10, Batch 80/97, Loss: 0.2227
Epoch 2/10, Batch 90/97, Loss: 0.3754
Epoch 2/10, Train Loss: 0.3902, Valid Loss: 0.3589
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2654
Epoch 3/10, Batch 20/97, Loss: 0.2454
Epoch 3/10, Batch 30/97, Loss: 0.2263
Epoch 3/10, Batch 40/97, Loss: 0.2481
Epoch 3/10, Batch 50/97, Loss: 0.3468
Epoch 3/10, Batch 60/97, Loss: 0.2811
Epoch 3/10, Batch 70/97, Loss: 0.1810
Epoch 3/10, Batch 80/97, Loss: 0.2982
Epoch 3/10, Batch 90/97, Loss: 0.1997
Epoch 3/10, Train Loss: 0.3191, Valid Loss: 0.3283
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3468
Epoch 4/10, Batch 20/97, Loss: 0.2777
Epoch 4/10, Batch 30/97, Loss: 0.2761
Epoch 4/10, Batch 40/97, Loss: 0.2063
Epoch 4/10, Batch 50/97, Loss: 0.3053
Epoch 4/10, Batch 60/97, Loss: 0.2086
Epoch 4/10, Batch 70/97, Loss: 0.3154
Epoch 4/10, Batch 80/97, Loss: 0.2587
Epoch 4/10, Batch 90/97, Loss: 0.2058
Epoch 4/10, Train Loss: 0.2787, Valid Loss: 0.3191
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2747
Epoch 5/10, Batch 20/97, Loss: 0.1654
Epoch 5/10, Batch 30/97, Loss: 0.1314
Epoch 5/10, Batch 40/97, Loss: 0.1488
Epoch 5/10, Batch 50/97, Loss: 0.2838
Epoch 5/10, Batch 60/97, Loss: 0.1742
Epoch 5/10, Batch 70/97, Loss: 0.1356
Epoch 5/10, Batch 80/97, Loss: 0.3458
Epoch 5/10, Batch 90/97, Loss: 0.4884
Epoch 5/10, Train Loss: 0.2512, Valid Loss: 0.3068
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2751
Epoch 6/10, Batch 20/97, Loss: 0.1945
Epoch 6/10, Batch 30/97, Loss: 0.3003
Epoch 6/10, Batch 40/97, Loss: 0.3309
Epoch 6/10, Batch 50/97, Loss: 0.2453
Epoch 6/10, Batch 60/97, Loss: 0.2375
Epoch 6/10, Batch 70/97, Loss: 0.1036
Epoch 6/10, Batch 80/97, Loss: 0.2084
Epoch 6/10, Batch 90/97, Loss: 0.1497
Epoch 6/10, Train Loss: 0.2325, Valid Loss: 0.2977
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2715
Epoch 7/10, Batch 20/97, Loss: 0.1377
Epoch 7/10, Batch 30/97, Loss: 0.1339
Epoch 7/10, Batch 40/97, Loss: 0.1896
Epoch 7/10, Batch 50/97, Loss: 0.1834
Epoch 7/10, Batch 60/97, Loss: 0.3818
Epoch 7/10, Batch 70/97, Loss: 0.1895
Epoch 7/10, Batch 80/97, Loss: 0.2642
Epoch 7/10, Batch 90/97, Loss: 0.1831
Epoch 7/10, Train Loss: 0.2410, Valid Loss: 0.2933
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1812
Epoch 8/10, Batch 20/97, Loss: 0.1350
Epoch 8/10, Batch 30/97, Loss: 0.1060
Epoch 8/10, Batch 40/97, Loss: 0.1902
Epoch 8/10, Batch 50/97, Loss: 0.1845
Epoch 8/10, Batch 60/97, Loss: 0.1432
Epoch 8/10, Batch 70/97, Loss: 0.1586
Epoch 8/10, Batch 80/97, Loss: 0.1884
Epoch 8/10, Batch 90/97, Loss: 0.1454
Epoch 8/10, Train Loss: 0.2144, Valid Loss: 0.2932
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1171
Epoch 9/10, Batch 20/97, Loss: 0.1447
Epoch 9/10, Batch 30/97, Loss: 0.2484
Epoch 9/10, Batch 40/97, Loss: 0.1791
Epoch 9/10, Batch 50/97, Loss: 0.2552
Epoch 9/10, Batch 60/97, Loss: 0.1758
Epoch 9/10, Batch 70/97, Loss: 0.3556
Epoch 9/10, Batch 80/97, Loss: 0.2204
Epoch 9/10, Batch 90/97, Loss: 0.2296
Epoch 9/10, Train Loss: 0.2117, Valid Loss: 0.2833
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1765
Epoch 10/10, Batch 20/97, Loss: 0.1594
Epoch 10/10, Batch 30/97, Loss: 0.0954
Epoch 10/10, Batch 40/97, Loss: 0.1424
Epoch 10/10, Batch 50/97, Loss: 0.2199
Epoch 10/10, Batch 60/97, Loss: 0.1003
Epoch 10/10, Batch 70/97, Loss: 0.2582
Epoch 10/10, Batch 80/97, Loss: 0.1460
Epoch 10/10, Batch 90/97, Loss: 0.1624
Epoch 10/10, Train Loss: 0.1977, Valid Loss: 0.2876
Accuracy: 0.9065
Precision: 0.9028
Recall: 0.9065
F1-score: 0.9039
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4566
Epoch 1/10, Batch 20/97, Loss: 0.9881
Epoch 1/10, Batch 30/97, Loss: 0.8763
Epoch 1/10, Batch 40/97, Loss: 0.6811
Epoch 1/10, Batch 50/97, Loss: 0.6446
Epoch 1/10, Batch 60/97, Loss: 0.6992
Epoch 1/10, Batch 70/97, Loss: 0.3936
Epoch 1/10, Batch 80/97, Loss: 0.5235
Epoch 1/10, Batch 90/97, Loss: 0.4279
Epoch 1/10, Train Loss: 0.7630, Valid Loss: 0.4522
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4119
Epoch 2/10, Batch 20/97, Loss: 0.4516
Epoch 2/10, Batch 30/97, Loss: 0.4456
Epoch 2/10, Batch 40/97, Loss: 0.4680
Epoch 2/10, Batch 50/97, Loss: 0.5237
Epoch 2/10, Batch 60/97, Loss: 0.3937
Epoch 2/10, Batch 70/97, Loss: 0.2840
Epoch 2/10, Batch 80/97, Loss: 0.3270
Epoch 2/10, Batch 90/97, Loss: 0.3610
Epoch 2/10, Train Loss: 0.3887, Valid Loss: 0.3400
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2692
Epoch 3/10, Batch 20/97, Loss: 0.4216
Epoch 3/10, Batch 30/97, Loss: 0.2908
Epoch 3/10, Batch 40/97, Loss: 0.2806
Epoch 3/10, Batch 50/97, Loss: 0.2623
Epoch 3/10, Batch 60/97, Loss: 0.3383
Epoch 3/10, Batch 70/97, Loss: 0.2329
Epoch 3/10, Batch 80/97, Loss: 0.2496
Epoch 3/10, Batch 90/97, Loss: 0.2500
Epoch 3/10, Train Loss: 0.3142, Valid Loss: 0.2938
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2450
Epoch 4/10, Batch 20/97, Loss: 0.3330
Epoch 4/10, Batch 30/97, Loss: 0.2744
Epoch 4/10, Batch 40/97, Loss: 0.2630
Epoch 4/10, Batch 50/97, Loss: 0.1508
Epoch 4/10, Batch 60/97, Loss: 0.1267
Epoch 4/10, Batch 70/97, Loss: 0.1603
Epoch 4/10, Batch 80/97, Loss: 0.3574
Epoch 4/10, Batch 90/97, Loss: 0.1959
Epoch 4/10, Train Loss: 0.2752, Valid Loss: 0.2704
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1920
Epoch 5/10, Batch 20/97, Loss: 0.1857
Epoch 5/10, Batch 30/97, Loss: 0.2566
Epoch 5/10, Batch 40/97, Loss: 0.0887
Epoch 5/10, Batch 50/97, Loss: 0.2174
Epoch 5/10, Batch 60/97, Loss: 0.1849
Epoch 5/10, Batch 70/97, Loss: 0.2928
Epoch 5/10, Batch 80/97, Loss: 0.3642
Epoch 5/10, Batch 90/97, Loss: 0.2704
Epoch 5/10, Train Loss: 0.2491, Valid Loss: 0.2573
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2020
Epoch 6/10, Batch 20/97, Loss: 0.2146
Epoch 6/10, Batch 30/97, Loss: 0.1754
Epoch 6/10, Batch 40/97, Loss: 0.1505
Epoch 6/10, Batch 50/97, Loss: 0.1275
Epoch 6/10, Batch 60/97, Loss: 0.2729
Epoch 6/10, Batch 70/97, Loss: 0.2053
Epoch 6/10, Batch 80/97, Loss: 0.1975
Epoch 6/10, Batch 90/97, Loss: 0.2176
Epoch 6/10, Train Loss: 0.2403, Valid Loss: 0.2530
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1685
Epoch 7/10, Batch 20/97, Loss: 0.0888
Epoch 7/10, Batch 30/97, Loss: 0.2614
Epoch 7/10, Batch 40/97, Loss: 0.1989
Epoch 7/10, Batch 50/97, Loss: 0.1536
Epoch 7/10, Batch 60/97, Loss: 0.3337
Epoch 7/10, Batch 70/97, Loss: 0.1268
Epoch 7/10, Batch 80/97, Loss: 0.1403
Epoch 7/10, Batch 90/97, Loss: 0.1800
Epoch 7/10, Train Loss: 0.2451, Valid Loss: 0.2362
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1856
Epoch 8/10, Batch 20/97, Loss: 0.1846
Epoch 8/10, Batch 30/97, Loss: 0.1258
Epoch 8/10, Batch 40/97, Loss: 0.1646
Epoch 8/10, Batch 50/97, Loss: 0.1330
Epoch 8/10, Batch 60/97, Loss: 0.1103
Epoch 8/10, Batch 70/97, Loss: 0.2763
Epoch 8/10, Batch 80/97, Loss: 0.1303
Epoch 8/10, Batch 90/97, Loss: 0.1340
Epoch 8/10, Train Loss: 0.2115, Valid Loss: 0.2321
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1387
Epoch 9/10, Batch 20/97, Loss: 0.0820
Epoch 9/10, Batch 30/97, Loss: 0.3193
Epoch 9/10, Batch 40/97, Loss: 0.1180
Epoch 9/10, Batch 50/97, Loss: 0.2559
Epoch 9/10, Batch 60/97, Loss: 0.2115
Epoch 9/10, Batch 70/97, Loss: 0.1284
Epoch 9/10, Batch 80/97, Loss: 0.2279
Epoch 9/10, Batch 90/97, Loss: 0.1295
Epoch 9/10, Train Loss: 0.1961, Valid Loss: 0.2299
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2270
Epoch 10/10, Batch 20/97, Loss: 0.0611
Epoch 10/10, Batch 30/97, Loss: 0.2416
Epoch 10/10, Batch 40/97, Loss: 0.1153
Epoch 10/10, Batch 50/97, Loss: 0.1985
Epoch 10/10, Batch 60/97, Loss: 0.1000
Epoch 10/10, Batch 70/97, Loss: 0.1187
Epoch 10/10, Batch 80/97, Loss: 0.1879
Epoch 10/10, Batch 90/97, Loss: 0.3754
Epoch 10/10, Train Loss: 0.1944, Valid Loss: 0.2214
Model saved!
Accuracy: 0.9206
Precision: 0.9193
Recall: 0.9206
F1-score: 0.9198
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5040
Epoch 1/10, Batch 20/97, Loss: 1.0742
Epoch 1/10, Batch 30/97, Loss: 0.8399
Epoch 1/10, Batch 40/97, Loss: 0.6735
Epoch 1/10, Batch 50/97, Loss: 0.6864
Epoch 1/10, Batch 60/97, Loss: 0.6480
Epoch 1/10, Batch 70/97, Loss: 0.5210
Epoch 1/10, Batch 80/97, Loss: 0.5809
Epoch 1/10, Batch 90/97, Loss: 0.6241
Epoch 1/10, Train Loss: 0.7759, Valid Loss: 0.4288
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.2934
Epoch 2/10, Batch 20/97, Loss: 0.2823
Epoch 2/10, Batch 30/97, Loss: 0.3465
Epoch 2/10, Batch 40/97, Loss: 0.3857
Epoch 2/10, Batch 50/97, Loss: 0.6409
Epoch 2/10, Batch 60/97, Loss: 0.4483
Epoch 2/10, Batch 70/97, Loss: 0.2995
Epoch 2/10, Batch 80/97, Loss: 0.3225
Epoch 2/10, Batch 90/97, Loss: 0.2367
Epoch 2/10, Train Loss: 0.3903, Valid Loss: 0.3159
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3055
Epoch 3/10, Batch 20/97, Loss: 0.2605
Epoch 3/10, Batch 30/97, Loss: 0.3155
Epoch 3/10, Batch 40/97, Loss: 0.2940
Epoch 3/10, Batch 50/97, Loss: 0.2511
Epoch 3/10, Batch 60/97, Loss: 0.1935
Epoch 3/10, Batch 70/97, Loss: 0.2269
Epoch 3/10, Batch 80/97, Loss: 0.2134
Epoch 3/10, Batch 90/97, Loss: 0.3942
Epoch 3/10, Train Loss: 0.3232, Valid Loss: 0.2826
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3541
Epoch 4/10, Batch 20/97, Loss: 0.2772
Epoch 4/10, Batch 30/97, Loss: 0.2293
Epoch 4/10, Batch 40/97, Loss: 0.2010
Epoch 4/10, Batch 50/97, Loss: 0.2068
Epoch 4/10, Batch 60/97, Loss: 0.1391
Epoch 4/10, Batch 70/97, Loss: 0.2943
Epoch 4/10, Batch 80/97, Loss: 0.2565
Epoch 4/10, Batch 90/97, Loss: 0.4160
Epoch 4/10, Train Loss: 0.2827, Valid Loss: 0.2601
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3014
Epoch 5/10, Batch 20/97, Loss: 0.3278
Epoch 5/10, Batch 30/97, Loss: 0.1672
Epoch 5/10, Batch 40/97, Loss: 0.1966
Epoch 5/10, Batch 50/97, Loss: 0.2516
Epoch 5/10, Batch 60/97, Loss: 0.2031
Epoch 5/10, Batch 70/97, Loss: 0.1987
Epoch 5/10, Batch 80/97, Loss: 0.2761
Epoch 5/10, Batch 90/97, Loss: 0.3788
Epoch 5/10, Train Loss: 0.2522, Valid Loss: 0.2462
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1882
Epoch 6/10, Batch 20/97, Loss: 0.1401
Epoch 6/10, Batch 30/97, Loss: 0.2002
Epoch 6/10, Batch 40/97, Loss: 0.3083
Epoch 6/10, Batch 50/97, Loss: 0.2039
Epoch 6/10, Batch 60/97, Loss: 0.2635
Epoch 6/10, Batch 70/97, Loss: 0.2490
Epoch 6/10, Batch 80/97, Loss: 0.1933
Epoch 6/10, Batch 90/97, Loss: 0.1743
Epoch 6/10, Train Loss: 0.2313, Valid Loss: 0.2386
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2414
Epoch 7/10, Batch 20/97, Loss: 0.1312
Epoch 7/10, Batch 30/97, Loss: 0.1767
Epoch 7/10, Batch 40/97, Loss: 0.1679
Epoch 7/10, Batch 50/97, Loss: 0.2567
Epoch 7/10, Batch 60/97, Loss: 0.2131
Epoch 7/10, Batch 70/97, Loss: 0.0960
Epoch 7/10, Batch 80/97, Loss: 0.2309
Epoch 7/10, Batch 90/97, Loss: 0.1896
Epoch 7/10, Train Loss: 0.2372, Valid Loss: 0.2281
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1902
Epoch 8/10, Batch 20/97, Loss: 0.1811
Epoch 8/10, Batch 30/97, Loss: 0.0980
Epoch 8/10, Batch 40/97, Loss: 0.1814
Epoch 8/10, Batch 50/97, Loss: 0.2697
Epoch 8/10, Batch 60/97, Loss: 0.0629
Epoch 8/10, Batch 70/97, Loss: 0.3428
Epoch 8/10, Batch 80/97, Loss: 0.2871
Epoch 8/10, Batch 90/97, Loss: 0.2739
Epoch 8/10, Train Loss: 0.2191, Valid Loss: 0.2215
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1799
Epoch 9/10, Batch 20/97, Loss: 0.2242
Epoch 9/10, Batch 30/97, Loss: 0.2377
Epoch 9/10, Batch 40/97, Loss: 0.2016
Epoch 9/10, Batch 50/97, Loss: 0.3293
Epoch 9/10, Batch 60/97, Loss: 0.1431
Epoch 9/10, Batch 70/97, Loss: 0.1555
Epoch 9/10, Batch 80/97, Loss: 0.1979
Epoch 9/10, Batch 90/97, Loss: 0.4557
Epoch 9/10, Train Loss: 0.2124, Valid Loss: 0.2271
Epoch 10/10, Batch 10/97, Loss: 0.1919
Epoch 10/10, Batch 20/97, Loss: 0.1519
Epoch 10/10, Batch 30/97, Loss: 0.1465
Epoch 10/10, Batch 40/97, Loss: 0.1950
Epoch 10/10, Batch 50/97, Loss: 0.3472
Epoch 10/10, Batch 60/97, Loss: 0.1352
Epoch 10/10, Batch 70/97, Loss: 0.2348
Epoch 10/10, Batch 80/97, Loss: 0.2609
Epoch 10/10, Batch 90/97, Loss: 0.1987
Epoch 10/10, Train Loss: 0.1954, Valid Loss: 0.2221
Accuracy: 0.9112
Precision: 0.9092
Recall: 0.9112
F1-score: 0.9082
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4296
Epoch 1/10, Batch 20/97, Loss: 0.9561
Epoch 1/10, Batch 30/97, Loss: 0.8160
Epoch 1/10, Batch 40/97, Loss: 0.6770
Epoch 1/10, Batch 50/97, Loss: 0.5960
Epoch 1/10, Batch 60/97, Loss: 0.5934
Epoch 1/10, Batch 70/97, Loss: 0.4497
Epoch 1/10, Batch 80/97, Loss: 0.6352
Epoch 1/10, Batch 90/97, Loss: 0.5786
Epoch 1/10, Train Loss: 0.7738, Valid Loss: 0.4544
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4850
Epoch 2/10, Batch 20/97, Loss: 0.6674
Epoch 2/10, Batch 30/97, Loss: 0.3226
Epoch 2/10, Batch 40/97, Loss: 0.4189
Epoch 2/10, Batch 50/97, Loss: 0.4083
Epoch 2/10, Batch 60/97, Loss: 0.2028
Epoch 2/10, Batch 70/97, Loss: 0.3230
Epoch 2/10, Batch 80/97, Loss: 0.2528
Epoch 2/10, Batch 90/97, Loss: 0.3532
Epoch 2/10, Train Loss: 0.3895, Valid Loss: 0.3564
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4175
Epoch 3/10, Batch 20/97, Loss: 0.2787
Epoch 3/10, Batch 30/97, Loss: 0.2589
Epoch 3/10, Batch 40/97, Loss: 0.2794
Epoch 3/10, Batch 50/97, Loss: 0.2855
Epoch 3/10, Batch 60/97, Loss: 0.3035
Epoch 3/10, Batch 70/97, Loss: 0.1546
Epoch 3/10, Batch 80/97, Loss: 0.3852
Epoch 3/10, Batch 90/97, Loss: 0.2464
Epoch 3/10, Train Loss: 0.3193, Valid Loss: 0.3230
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3766
Epoch 4/10, Batch 20/97, Loss: 0.3154
Epoch 4/10, Batch 30/97, Loss: 0.3266
Epoch 4/10, Batch 40/97, Loss: 0.2515
Epoch 4/10, Batch 50/97, Loss: 0.1277
Epoch 4/10, Batch 60/97, Loss: 0.2317
Epoch 4/10, Batch 70/97, Loss: 0.2467
Epoch 4/10, Batch 80/97, Loss: 0.2587
Epoch 4/10, Batch 90/97, Loss: 0.1878
Epoch 4/10, Train Loss: 0.2860, Valid Loss: 0.3008
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1830
Epoch 5/10, Batch 20/97, Loss: 0.1161
Epoch 5/10, Batch 30/97, Loss: 0.2538
Epoch 5/10, Batch 40/97, Loss: 0.2528
Epoch 5/10, Batch 50/97, Loss: 0.1750
Epoch 5/10, Batch 60/97, Loss: 0.2488
Epoch 5/10, Batch 70/97, Loss: 0.3399
Epoch 5/10, Batch 80/97, Loss: 0.2488
Epoch 5/10, Batch 90/97, Loss: 0.2695
Epoch 5/10, Train Loss: 0.2570, Valid Loss: 0.2905
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1473
Epoch 6/10, Batch 20/97, Loss: 0.2234
Epoch 6/10, Batch 30/97, Loss: 0.1198
Epoch 6/10, Batch 40/97, Loss: 0.2712
Epoch 6/10, Batch 50/97, Loss: 0.1741
Epoch 6/10, Batch 60/97, Loss: 0.3441
Epoch 6/10, Batch 70/97, Loss: 0.2212
Epoch 6/10, Batch 80/97, Loss: 0.1751
Epoch 6/10, Batch 90/97, Loss: 0.2260
Epoch 6/10, Train Loss: 0.2381, Valid Loss: 0.2739
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3223
Epoch 7/10, Batch 20/97, Loss: 0.1662
Epoch 7/10, Batch 30/97, Loss: 0.1255
Epoch 7/10, Batch 40/97, Loss: 0.2040
Epoch 7/10, Batch 50/97, Loss: 0.1182
Epoch 7/10, Batch 60/97, Loss: 0.2995
Epoch 7/10, Batch 70/97, Loss: 0.2441
Epoch 7/10, Batch 80/97, Loss: 0.2142
Epoch 7/10, Batch 90/97, Loss: 0.3657
Epoch 7/10, Train Loss: 0.2417, Valid Loss: 0.2688
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.3231
Epoch 8/10, Batch 20/97, Loss: 0.1087
Epoch 8/10, Batch 30/97, Loss: 0.1764
Epoch 8/10, Batch 40/97, Loss: 0.1567
Epoch 8/10, Batch 50/97, Loss: 0.1668
Epoch 8/10, Batch 60/97, Loss: 0.1212
Epoch 8/10, Batch 70/97, Loss: 0.3473
Epoch 8/10, Batch 80/97, Loss: 0.2193
Epoch 8/10, Batch 90/97, Loss: 0.2603
Epoch 8/10, Train Loss: 0.2168, Valid Loss: 0.2850
Epoch 9/10, Batch 10/97, Loss: 0.0569
Epoch 9/10, Batch 20/97, Loss: 0.1213
Epoch 9/10, Batch 30/97, Loss: 0.2478
Epoch 9/10, Batch 40/97, Loss: 0.1133
Epoch 9/10, Batch 50/97, Loss: 0.3117
Epoch 9/10, Batch 60/97, Loss: 0.1533
Epoch 9/10, Batch 70/97, Loss: 0.1841
Epoch 9/10, Batch 80/97, Loss: 0.1502
Epoch 9/10, Batch 90/97, Loss: 0.1593
Epoch 9/10, Train Loss: 0.2098, Valid Loss: 0.2648
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1973
Epoch 10/10, Batch 20/97, Loss: 0.1508
Epoch 10/10, Batch 30/97, Loss: 0.0941
Epoch 10/10, Batch 40/97, Loss: 0.1771
Epoch 10/10, Batch 50/97, Loss: 0.2833
Epoch 10/10, Batch 60/97, Loss: 0.0853
Epoch 10/10, Batch 70/97, Loss: 0.2298
Epoch 10/10, Batch 80/97, Loss: 0.3318
Epoch 10/10, Batch 90/97, Loss: 0.1570
Epoch 10/10, Train Loss: 0.1988, Valid Loss: 0.2701
Accuracy: 0.9124
Precision: 0.9093
Recall: 0.9124
F1-score: 0.9104
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5146
Epoch 1/10, Batch 20/97, Loss: 0.9816
Epoch 1/10, Batch 30/97, Loss: 0.8539
Epoch 1/10, Batch 40/97, Loss: 0.6225
Epoch 1/10, Batch 50/97, Loss: 0.5831
Epoch 1/10, Batch 60/97, Loss: 0.5052
Epoch 1/10, Batch 70/97, Loss: 0.5148
Epoch 1/10, Batch 80/97, Loss: 0.3707
Epoch 1/10, Batch 90/97, Loss: 0.7055
Epoch 1/10, Train Loss: 0.7695, Valid Loss: 0.4238
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3837
Epoch 2/10, Batch 20/97, Loss: 0.6315
Epoch 2/10, Batch 30/97, Loss: 0.3793
Epoch 2/10, Batch 40/97, Loss: 0.3997
Epoch 2/10, Batch 50/97, Loss: 0.4141
Epoch 2/10, Batch 60/97, Loss: 0.3239
Epoch 2/10, Batch 70/97, Loss: 0.3649
Epoch 2/10, Batch 80/97, Loss: 0.2946
Epoch 2/10, Batch 90/97, Loss: 0.3600
Epoch 2/10, Train Loss: 0.3986, Valid Loss: 0.3144
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3401
Epoch 3/10, Batch 20/97, Loss: 0.2606
Epoch 3/10, Batch 30/97, Loss: 0.3211
Epoch 3/10, Batch 40/97, Loss: 0.2445
Epoch 3/10, Batch 50/97, Loss: 0.3435
Epoch 3/10, Batch 60/97, Loss: 0.5102
Epoch 3/10, Batch 70/97, Loss: 0.3140
Epoch 3/10, Batch 80/97, Loss: 0.2966
Epoch 3/10, Batch 90/97, Loss: 0.2457
Epoch 3/10, Train Loss: 0.3256, Valid Loss: 0.2767
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1710
Epoch 4/10, Batch 20/97, Loss: 0.3740
Epoch 4/10, Batch 30/97, Loss: 0.3301
Epoch 4/10, Batch 40/97, Loss: 0.2705
Epoch 4/10, Batch 50/97, Loss: 0.1322
Epoch 4/10, Batch 60/97, Loss: 0.2025
Epoch 4/10, Batch 70/97, Loss: 0.1437
Epoch 4/10, Batch 80/97, Loss: 0.6183
Epoch 4/10, Batch 90/97, Loss: 0.3140
Epoch 4/10, Train Loss: 0.2866, Valid Loss: 0.2598
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2117
Epoch 5/10, Batch 20/97, Loss: 0.1832
Epoch 5/10, Batch 30/97, Loss: 0.1086
Epoch 5/10, Batch 40/97, Loss: 0.1422
Epoch 5/10, Batch 50/97, Loss: 0.1278
Epoch 5/10, Batch 60/97, Loss: 0.3351
Epoch 5/10, Batch 70/97, Loss: 0.2339
Epoch 5/10, Batch 80/97, Loss: 0.2161
Epoch 5/10, Batch 90/97, Loss: 0.1965
Epoch 5/10, Train Loss: 0.2655, Valid Loss: 0.2471
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1546
Epoch 6/10, Batch 20/97, Loss: 0.2832
Epoch 6/10, Batch 30/97, Loss: 0.2068
Epoch 6/10, Batch 40/97, Loss: 0.2354
Epoch 6/10, Batch 50/97, Loss: 0.1488
Epoch 6/10, Batch 60/97, Loss: 0.3024
Epoch 6/10, Batch 70/97, Loss: 0.1187
Epoch 6/10, Batch 80/97, Loss: 0.2006
Epoch 6/10, Batch 90/97, Loss: 0.2075
Epoch 6/10, Train Loss: 0.2373, Valid Loss: 0.2309
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3347
Epoch 7/10, Batch 20/97, Loss: 0.1726
Epoch 7/10, Batch 30/97, Loss: 0.1226
Epoch 7/10, Batch 40/97, Loss: 0.2183
Epoch 7/10, Batch 50/97, Loss: 0.1721
Epoch 7/10, Batch 60/97, Loss: 0.3117
Epoch 7/10, Batch 70/97, Loss: 0.2792
Epoch 7/10, Batch 80/97, Loss: 0.1930
Epoch 7/10, Batch 90/97, Loss: 0.3071
Epoch 7/10, Train Loss: 0.2369, Valid Loss: 0.2276
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1059
Epoch 8/10, Batch 20/97, Loss: 0.1805
Epoch 8/10, Batch 30/97, Loss: 0.1936
Epoch 8/10, Batch 40/97, Loss: 0.2404
Epoch 8/10, Batch 50/97, Loss: 0.2860
Epoch 8/10, Batch 60/97, Loss: 0.1582
Epoch 8/10, Batch 70/97, Loss: 0.2290
Epoch 8/10, Batch 80/97, Loss: 0.1492
Epoch 8/10, Batch 90/97, Loss: 0.2429
Epoch 8/10, Train Loss: 0.2203, Valid Loss: 0.2253
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1210
Epoch 9/10, Batch 20/97, Loss: 0.1365
Epoch 9/10, Batch 30/97, Loss: 0.3529
Epoch 9/10, Batch 40/97, Loss: 0.1194
Epoch 9/10, Batch 50/97, Loss: 0.2147
Epoch 9/10, Batch 60/97, Loss: 0.1658
Epoch 9/10, Batch 70/97, Loss: 0.1872
Epoch 9/10, Batch 80/97, Loss: 0.1224
Epoch 9/10, Batch 90/97, Loss: 0.2198
Epoch 9/10, Train Loss: 0.2080, Valid Loss: 0.2230
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2818
Epoch 10/10, Batch 20/97, Loss: 0.1819
Epoch 10/10, Batch 30/97, Loss: 0.1424
Epoch 10/10, Batch 40/97, Loss: 0.2571
Epoch 10/10, Batch 50/97, Loss: 0.1630
Epoch 10/10, Batch 60/97, Loss: 0.1250
Epoch 10/10, Batch 70/97, Loss: 0.2292
Epoch 10/10, Batch 80/97, Loss: 0.2963
Epoch 10/10, Batch 90/97, Loss: 0.1665
Epoch 10/10, Train Loss: 0.1981, Valid Loss: 0.2198
Model saved!
Accuracy: 0.9206
Precision: 0.9183
Recall: 0.9206
F1-score: 0.9191
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4799
Epoch 1/10, Batch 20/97, Loss: 1.0650
Epoch 1/10, Batch 30/97, Loss: 0.8256
Epoch 1/10, Batch 40/97, Loss: 0.6683
Epoch 1/10, Batch 50/97, Loss: 0.5447
Epoch 1/10, Batch 60/97, Loss: 0.6571
Epoch 1/10, Batch 70/97, Loss: 0.4446
Epoch 1/10, Batch 80/97, Loss: 0.5224
Epoch 1/10, Batch 90/97, Loss: 0.3970
Epoch 1/10, Train Loss: 0.7675, Valid Loss: 0.4359
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3401
Epoch 2/10, Batch 20/97, Loss: 0.5292
Epoch 2/10, Batch 30/97, Loss: 0.5452
Epoch 2/10, Batch 40/97, Loss: 0.3720
Epoch 2/10, Batch 50/97, Loss: 0.5024
Epoch 2/10, Batch 60/97, Loss: 0.3313
Epoch 2/10, Batch 70/97, Loss: 0.2917
Epoch 2/10, Batch 80/97, Loss: 0.3128
Epoch 2/10, Batch 90/97, Loss: 0.3359
Epoch 2/10, Train Loss: 0.3903, Valid Loss: 0.3389
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3924
Epoch 3/10, Batch 20/97, Loss: 0.3503
Epoch 3/10, Batch 30/97, Loss: 0.2654
Epoch 3/10, Batch 40/97, Loss: 0.2961
Epoch 3/10, Batch 50/97, Loss: 0.2136
Epoch 3/10, Batch 60/97, Loss: 0.2551
Epoch 3/10, Batch 70/97, Loss: 0.3841
Epoch 3/10, Batch 80/97, Loss: 0.2480
Epoch 3/10, Batch 90/97, Loss: 0.2261
Epoch 3/10, Train Loss: 0.3287, Valid Loss: 0.2967
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2787
Epoch 4/10, Batch 20/97, Loss: 0.3543
Epoch 4/10, Batch 30/97, Loss: 0.2776
Epoch 4/10, Batch 40/97, Loss: 0.3759
Epoch 4/10, Batch 50/97, Loss: 0.2215
Epoch 4/10, Batch 60/97, Loss: 0.2065
Epoch 4/10, Batch 70/97, Loss: 0.2520
Epoch 4/10, Batch 80/97, Loss: 0.1805
Epoch 4/10, Batch 90/97, Loss: 0.2922
Epoch 4/10, Train Loss: 0.2858, Valid Loss: 0.2754
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2955
Epoch 5/10, Batch 20/97, Loss: 0.2059
Epoch 5/10, Batch 30/97, Loss: 0.1672
Epoch 5/10, Batch 40/97, Loss: 0.2248
Epoch 5/10, Batch 50/97, Loss: 0.3361
Epoch 5/10, Batch 60/97, Loss: 0.4105
Epoch 5/10, Batch 70/97, Loss: 0.1677
Epoch 5/10, Batch 80/97, Loss: 0.3366
Epoch 5/10, Batch 90/97, Loss: 0.3199
Epoch 5/10, Train Loss: 0.2663, Valid Loss: 0.2585
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2256
Epoch 6/10, Batch 20/97, Loss: 0.2267
Epoch 6/10, Batch 30/97, Loss: 0.2189
Epoch 6/10, Batch 40/97, Loss: 0.3330
Epoch 6/10, Batch 50/97, Loss: 0.3780
Epoch 6/10, Batch 60/97, Loss: 0.1924
Epoch 6/10, Batch 70/97, Loss: 0.2852
Epoch 6/10, Batch 80/97, Loss: 0.1717
Epoch 6/10, Batch 90/97, Loss: 0.2098
Epoch 6/10, Train Loss: 0.2465, Valid Loss: 0.2466
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2544
Epoch 7/10, Batch 20/97, Loss: 0.1484
Epoch 7/10, Batch 30/97, Loss: 0.2219
Epoch 7/10, Batch 40/97, Loss: 0.1738
Epoch 7/10, Batch 50/97, Loss: 0.3047
Epoch 7/10, Batch 60/97, Loss: 0.2203
Epoch 7/10, Batch 70/97, Loss: 0.1428
Epoch 7/10, Batch 80/97, Loss: 0.2092
Epoch 7/10, Batch 90/97, Loss: 0.3118
Epoch 7/10, Train Loss: 0.2446, Valid Loss: 0.2355
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2588
Epoch 8/10, Batch 20/97, Loss: 0.1642
Epoch 8/10, Batch 30/97, Loss: 0.1590
Epoch 8/10, Batch 40/97, Loss: 0.1250
Epoch 8/10, Batch 50/97, Loss: 0.2959
Epoch 8/10, Batch 60/97, Loss: 0.0857
Epoch 8/10, Batch 70/97, Loss: 0.2470
Epoch 8/10, Batch 80/97, Loss: 0.1791
Epoch 8/10, Batch 90/97, Loss: 0.2068
Epoch 8/10, Train Loss: 0.2314, Valid Loss: 0.2357
Epoch 9/10, Batch 10/97, Loss: 0.1271
Epoch 9/10, Batch 20/97, Loss: 0.0599
Epoch 9/10, Batch 30/97, Loss: 0.2718
Epoch 9/10, Batch 40/97, Loss: 0.1709
Epoch 9/10, Batch 50/97, Loss: 0.3290
Epoch 9/10, Batch 60/97, Loss: 0.1553
Epoch 9/10, Batch 70/97, Loss: 0.1297
Epoch 9/10, Batch 80/97, Loss: 0.1911
Epoch 9/10, Batch 90/97, Loss: 0.2680
Epoch 9/10, Train Loss: 0.2057, Valid Loss: 0.2297
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2420
Epoch 10/10, Batch 20/97, Loss: 0.0998
Epoch 10/10, Batch 30/97, Loss: 0.1591
Epoch 10/10, Batch 40/97, Loss: 0.2684
Epoch 10/10, Batch 50/97, Loss: 0.2647
Epoch 10/10, Batch 60/97, Loss: 0.2171
Epoch 10/10, Batch 70/97, Loss: 0.1515
Epoch 10/10, Batch 80/97, Loss: 0.2514
Epoch 10/10, Batch 90/97, Loss: 0.2539
Epoch 10/10, Train Loss: 0.1951, Valid Loss: 0.2266
Model saved!
Accuracy: 0.9077
Precision: 0.9053
Recall: 0.9077
F1-score: 0.9048
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4985
Epoch 1/10, Batch 20/97, Loss: 0.9834
Epoch 1/10, Batch 30/97, Loss: 0.9288
Epoch 1/10, Batch 40/97, Loss: 0.7305
Epoch 1/10, Batch 50/97, Loss: 0.5791
Epoch 1/10, Batch 60/97, Loss: 0.5332
Epoch 1/10, Batch 70/97, Loss: 0.4455
Epoch 1/10, Batch 80/97, Loss: 0.5576
Epoch 1/10, Batch 90/97, Loss: 0.5619
Epoch 1/10, Train Loss: 0.7701, Valid Loss: 0.4275
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4598
Epoch 2/10, Batch 20/97, Loss: 0.5408
Epoch 2/10, Batch 30/97, Loss: 0.4170
Epoch 2/10, Batch 40/97, Loss: 0.4652
Epoch 2/10, Batch 50/97, Loss: 0.4522
Epoch 2/10, Batch 60/97, Loss: 0.3967
Epoch 2/10, Batch 70/97, Loss: 0.2607
Epoch 2/10, Batch 80/97, Loss: 0.3884
Epoch 2/10, Batch 90/97, Loss: 0.3125
Epoch 2/10, Train Loss: 0.3960, Valid Loss: 0.3250
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2863
Epoch 3/10, Batch 20/97, Loss: 0.2793
Epoch 3/10, Batch 30/97, Loss: 0.1597
Epoch 3/10, Batch 40/97, Loss: 0.3789
Epoch 3/10, Batch 50/97, Loss: 0.3185
Epoch 3/10, Batch 60/97, Loss: 0.3295
Epoch 3/10, Batch 70/97, Loss: 0.1190
Epoch 3/10, Batch 80/97, Loss: 0.2616
Epoch 3/10, Batch 90/97, Loss: 0.2229
Epoch 3/10, Train Loss: 0.3216, Valid Loss: 0.2848
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3281
Epoch 4/10, Batch 20/97, Loss: 0.2338
Epoch 4/10, Batch 30/97, Loss: 0.3750
Epoch 4/10, Batch 40/97, Loss: 0.3128
Epoch 4/10, Batch 50/97, Loss: 0.2096
Epoch 4/10, Batch 60/97, Loss: 0.1669
Epoch 4/10, Batch 70/97, Loss: 0.4113
Epoch 4/10, Batch 80/97, Loss: 0.2827
Epoch 4/10, Batch 90/97, Loss: 0.2275
Epoch 4/10, Train Loss: 0.2830, Valid Loss: 0.2684
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2683
Epoch 5/10, Batch 20/97, Loss: 0.2328
Epoch 5/10, Batch 30/97, Loss: 0.1923
Epoch 5/10, Batch 40/97, Loss: 0.1277
Epoch 5/10, Batch 50/97, Loss: 0.1925
Epoch 5/10, Batch 60/97, Loss: 0.2401
Epoch 5/10, Batch 70/97, Loss: 0.2333
Epoch 5/10, Batch 80/97, Loss: 0.2875
Epoch 5/10, Batch 90/97, Loss: 0.3165
Epoch 5/10, Train Loss: 0.2574, Valid Loss: 0.2510
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1860
Epoch 6/10, Batch 20/97, Loss: 0.1812
Epoch 6/10, Batch 30/97, Loss: 0.1170
Epoch 6/10, Batch 40/97, Loss: 0.2726
Epoch 6/10, Batch 50/97, Loss: 0.2649
Epoch 6/10, Batch 60/97, Loss: 0.2803
Epoch 6/10, Batch 70/97, Loss: 0.2240
Epoch 6/10, Batch 80/97, Loss: 0.1635
Epoch 6/10, Batch 90/97, Loss: 0.2598
Epoch 6/10, Train Loss: 0.2386, Valid Loss: 0.2455
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3860
Epoch 7/10, Batch 20/97, Loss: 0.2235
Epoch 7/10, Batch 30/97, Loss: 0.1345
Epoch 7/10, Batch 40/97, Loss: 0.1491
Epoch 7/10, Batch 50/97, Loss: 0.3407
Epoch 7/10, Batch 60/97, Loss: 0.3120
Epoch 7/10, Batch 70/97, Loss: 0.1954
Epoch 7/10, Batch 80/97, Loss: 0.1420
Epoch 7/10, Batch 90/97, Loss: 0.4060
Epoch 7/10, Train Loss: 0.2449, Valid Loss: 0.2370
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1672
Epoch 8/10, Batch 20/97, Loss: 0.1713
Epoch 8/10, Batch 30/97, Loss: 0.1899
Epoch 8/10, Batch 40/97, Loss: 0.2698
Epoch 8/10, Batch 50/97, Loss: 0.1824
Epoch 8/10, Batch 60/97, Loss: 0.2405
Epoch 8/10, Batch 70/97, Loss: 0.3729
Epoch 8/10, Batch 80/97, Loss: 0.1260
Epoch 8/10, Batch 90/97, Loss: 0.1043
Epoch 8/10, Train Loss: 0.2200, Valid Loss: 0.2291
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1187
Epoch 9/10, Batch 20/97, Loss: 0.2130
Epoch 9/10, Batch 30/97, Loss: 0.2666
Epoch 9/10, Batch 40/97, Loss: 0.1445
Epoch 9/10, Batch 50/97, Loss: 0.1658
Epoch 9/10, Batch 60/97, Loss: 0.2560
Epoch 9/10, Batch 70/97, Loss: 0.2396
Epoch 9/10, Batch 80/97, Loss: 0.1503
Epoch 9/10, Batch 90/97, Loss: 0.2675
Epoch 9/10, Train Loss: 0.2123, Valid Loss: 0.2328
Epoch 10/10, Batch 10/97, Loss: 0.1665
Epoch 10/10, Batch 20/97, Loss: 0.1481
Epoch 10/10, Batch 30/97, Loss: 0.0994
Epoch 10/10, Batch 40/97, Loss: 0.1632
Epoch 10/10, Batch 50/97, Loss: 0.2899
Epoch 10/10, Batch 60/97, Loss: 0.2080
Epoch 10/10, Batch 70/97, Loss: 0.1220
Epoch 10/10, Batch 80/97, Loss: 0.1348
Epoch 10/10, Batch 90/97, Loss: 0.1122
Epoch 10/10, Train Loss: 0.2020, Valid Loss: 0.2194
Model saved!
Accuracy: 0.9194
Precision: 0.9161
Recall: 0.9194
F1-score: 0.9169
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5561
Epoch 1/10, Batch 20/97, Loss: 1.1091
Epoch 1/10, Batch 30/97, Loss: 0.8206
Epoch 1/10, Batch 40/97, Loss: 0.6817
Epoch 1/10, Batch 50/97, Loss: 0.6572
Epoch 1/10, Batch 60/97, Loss: 0.6150
Epoch 1/10, Batch 70/97, Loss: 0.3809
Epoch 1/10, Batch 80/97, Loss: 0.4500
Epoch 1/10, Batch 90/97, Loss: 0.6296
Epoch 1/10, Train Loss: 0.7766, Valid Loss: 0.4542
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3581
Epoch 2/10, Batch 20/97, Loss: 0.6684
Epoch 2/10, Batch 30/97, Loss: 0.3905
Epoch 2/10, Batch 40/97, Loss: 0.5107
Epoch 2/10, Batch 50/97, Loss: 0.5789
Epoch 2/10, Batch 60/97, Loss: 0.3667
Epoch 2/10, Batch 70/97, Loss: 0.2641
Epoch 2/10, Batch 80/97, Loss: 0.2994
Epoch 2/10, Batch 90/97, Loss: 0.4157
Epoch 2/10, Train Loss: 0.3952, Valid Loss: 0.3527
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2681
Epoch 3/10, Batch 20/97, Loss: 0.2454
Epoch 3/10, Batch 30/97, Loss: 0.3190
Epoch 3/10, Batch 40/97, Loss: 0.2690
Epoch 3/10, Batch 50/97, Loss: 0.3930
Epoch 3/10, Batch 60/97, Loss: 0.1951
Epoch 3/10, Batch 70/97, Loss: 0.2201
Epoch 3/10, Batch 80/97, Loss: 0.2419
Epoch 3/10, Batch 90/97, Loss: 0.3217
Epoch 3/10, Train Loss: 0.3205, Valid Loss: 0.3071
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2375
Epoch 4/10, Batch 20/97, Loss: 0.2508
Epoch 4/10, Batch 30/97, Loss: 0.4252
Epoch 4/10, Batch 40/97, Loss: 0.3452
Epoch 4/10, Batch 50/97, Loss: 0.3036
Epoch 4/10, Batch 60/97, Loss: 0.1474
Epoch 4/10, Batch 70/97, Loss: 0.1523
Epoch 4/10, Batch 80/97, Loss: 0.3306
Epoch 4/10, Batch 90/97, Loss: 0.2378
Epoch 4/10, Train Loss: 0.2898, Valid Loss: 0.2882
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2462
Epoch 5/10, Batch 20/97, Loss: 0.1619
Epoch 5/10, Batch 30/97, Loss: 0.1942
Epoch 5/10, Batch 40/97, Loss: 0.1517
Epoch 5/10, Batch 50/97, Loss: 0.3177
Epoch 5/10, Batch 60/97, Loss: 0.3261
Epoch 5/10, Batch 70/97, Loss: 0.1950
Epoch 5/10, Batch 80/97, Loss: 0.2158
Epoch 5/10, Batch 90/97, Loss: 0.2203
Epoch 5/10, Train Loss: 0.2585, Valid Loss: 0.2753
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3114
Epoch 6/10, Batch 20/97, Loss: 0.3051
Epoch 6/10, Batch 30/97, Loss: 0.2251
Epoch 6/10, Batch 40/97, Loss: 0.1424
Epoch 6/10, Batch 50/97, Loss: 0.2025
Epoch 6/10, Batch 60/97, Loss: 0.1595
Epoch 6/10, Batch 70/97, Loss: 0.2147
Epoch 6/10, Batch 80/97, Loss: 0.2135
Epoch 6/10, Batch 90/97, Loss: 0.1915
Epoch 6/10, Train Loss: 0.2450, Valid Loss: 0.2651
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2873
Epoch 7/10, Batch 20/97, Loss: 0.2005
Epoch 7/10, Batch 30/97, Loss: 0.1689
Epoch 7/10, Batch 40/97, Loss: 0.1136
Epoch 7/10, Batch 50/97, Loss: 0.3654
Epoch 7/10, Batch 60/97, Loss: 0.3195
Epoch 7/10, Batch 70/97, Loss: 0.1891
Epoch 7/10, Batch 80/97, Loss: 0.2603
Epoch 7/10, Batch 90/97, Loss: 0.4323
Epoch 7/10, Train Loss: 0.2453, Valid Loss: 0.2532
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2582
Epoch 8/10, Batch 20/97, Loss: 0.1513
Epoch 8/10, Batch 30/97, Loss: 0.1027
Epoch 8/10, Batch 40/97, Loss: 0.1601
Epoch 8/10, Batch 50/97, Loss: 0.1012
Epoch 8/10, Batch 60/97, Loss: 0.2375
Epoch 8/10, Batch 70/97, Loss: 0.2835
Epoch 8/10, Batch 80/97, Loss: 0.1260
Epoch 8/10, Batch 90/97, Loss: 0.1132
Epoch 8/10, Train Loss: 0.2180, Valid Loss: 0.2445
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0962
Epoch 9/10, Batch 20/97, Loss: 0.1159
Epoch 9/10, Batch 30/97, Loss: 0.3184
Epoch 9/10, Batch 40/97, Loss: 0.1549
Epoch 9/10, Batch 50/97, Loss: 0.2109
Epoch 9/10, Batch 60/97, Loss: 0.2633
Epoch 9/10, Batch 70/97, Loss: 0.1199
Epoch 9/10, Batch 80/97, Loss: 0.0784
Epoch 9/10, Batch 90/97, Loss: 0.1632
Epoch 9/10, Train Loss: 0.2081, Valid Loss: 0.2440
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2068
Epoch 10/10, Batch 20/97, Loss: 0.1091
Epoch 10/10, Batch 30/97, Loss: 0.2510
Epoch 10/10, Batch 40/97, Loss: 0.2037
Epoch 10/10, Batch 50/97, Loss: 0.3117
Epoch 10/10, Batch 60/97, Loss: 0.1249
Epoch 10/10, Batch 70/97, Loss: 0.1332
Epoch 10/10, Batch 80/97, Loss: 0.1059
Epoch 10/10, Batch 90/97, Loss: 0.1794
Epoch 10/10, Train Loss: 0.2062, Valid Loss: 0.2407
Model saved!
Accuracy: 0.9147
Precision: 0.9127
Recall: 0.9147
F1-score: 0.9128
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5079
Epoch 1/10, Batch 20/97, Loss: 1.1354
Epoch 1/10, Batch 30/97, Loss: 0.9092
Epoch 1/10, Batch 40/97, Loss: 0.6848
Epoch 1/10, Batch 50/97, Loss: 0.5111
Epoch 1/10, Batch 60/97, Loss: 0.6304
Epoch 1/10, Batch 70/97, Loss: 0.5005
Epoch 1/10, Batch 80/97, Loss: 0.5381
Epoch 1/10, Batch 90/97, Loss: 0.5245
Epoch 1/10, Train Loss: 0.7761, Valid Loss: 0.4505
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3291
Epoch 2/10, Batch 20/97, Loss: 0.5210
Epoch 2/10, Batch 30/97, Loss: 0.3483
Epoch 2/10, Batch 40/97, Loss: 0.6371
Epoch 2/10, Batch 50/97, Loss: 0.5161
Epoch 2/10, Batch 60/97, Loss: 0.3212
Epoch 2/10, Batch 70/97, Loss: 0.2538
Epoch 2/10, Batch 80/97, Loss: 0.1786
Epoch 2/10, Batch 90/97, Loss: 0.3205
Epoch 2/10, Train Loss: 0.3927, Valid Loss: 0.3473
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3300
Epoch 3/10, Batch 20/97, Loss: 0.3267
Epoch 3/10, Batch 30/97, Loss: 0.2549
Epoch 3/10, Batch 40/97, Loss: 0.2674
Epoch 3/10, Batch 50/97, Loss: 0.4388
Epoch 3/10, Batch 60/97, Loss: 0.3163
Epoch 3/10, Batch 70/97, Loss: 0.1619
Epoch 3/10, Batch 80/97, Loss: 0.2812
Epoch 3/10, Batch 90/97, Loss: 0.3198
Epoch 3/10, Train Loss: 0.3223, Valid Loss: 0.3117
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1720
Epoch 4/10, Batch 20/97, Loss: 0.2437
Epoch 4/10, Batch 30/97, Loss: 0.4010
Epoch 4/10, Batch 40/97, Loss: 0.1934
Epoch 4/10, Batch 50/97, Loss: 0.3015
Epoch 4/10, Batch 60/97, Loss: 0.3756
Epoch 4/10, Batch 70/97, Loss: 0.2466
Epoch 4/10, Batch 80/97, Loss: 0.2039
Epoch 4/10, Batch 90/97, Loss: 0.3030
Epoch 4/10, Train Loss: 0.2908, Valid Loss: 0.2901
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1870
Epoch 5/10, Batch 20/97, Loss: 0.1678
Epoch 5/10, Batch 30/97, Loss: 0.3188
Epoch 5/10, Batch 40/97, Loss: 0.2103
Epoch 5/10, Batch 50/97, Loss: 0.3245
Epoch 5/10, Batch 60/97, Loss: 0.2022
Epoch 5/10, Batch 70/97, Loss: 0.2518
Epoch 5/10, Batch 80/97, Loss: 0.2653
Epoch 5/10, Batch 90/97, Loss: 0.3458
Epoch 5/10, Train Loss: 0.2615, Valid Loss: 0.2747
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1908
Epoch 6/10, Batch 20/97, Loss: 0.2595
Epoch 6/10, Batch 30/97, Loss: 0.2034
Epoch 6/10, Batch 40/97, Loss: 0.1917
Epoch 6/10, Batch 50/97, Loss: 0.1448
Epoch 6/10, Batch 60/97, Loss: 0.3022
Epoch 6/10, Batch 70/97, Loss: 0.1824
Epoch 6/10, Batch 80/97, Loss: 0.1834
Epoch 6/10, Batch 90/97, Loss: 0.2393
Epoch 6/10, Train Loss: 0.2340, Valid Loss: 0.2601
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1852
Epoch 7/10, Batch 20/97, Loss: 0.1644
Epoch 7/10, Batch 30/97, Loss: 0.1293
Epoch 7/10, Batch 40/97, Loss: 0.2082
Epoch 7/10, Batch 50/97, Loss: 0.2978
Epoch 7/10, Batch 60/97, Loss: 0.2211
Epoch 7/10, Batch 70/97, Loss: 0.2356
Epoch 7/10, Batch 80/97, Loss: 0.3233
Epoch 7/10, Batch 90/97, Loss: 0.2213
Epoch 7/10, Train Loss: 0.2504, Valid Loss: 0.2554
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.0937
Epoch 8/10, Batch 20/97, Loss: 0.1929
Epoch 8/10, Batch 30/97, Loss: 0.1185
Epoch 8/10, Batch 40/97, Loss: 0.4707
Epoch 8/10, Batch 50/97, Loss: 0.2183
Epoch 8/10, Batch 60/97, Loss: 0.1838
Epoch 8/10, Batch 70/97, Loss: 0.3425
Epoch 8/10, Batch 80/97, Loss: 0.1586
Epoch 8/10, Batch 90/97, Loss: 0.1420
Epoch 8/10, Train Loss: 0.2223, Valid Loss: 0.2454
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1328
Epoch 9/10, Batch 20/97, Loss: 0.1699
Epoch 9/10, Batch 30/97, Loss: 0.3317
Epoch 9/10, Batch 40/97, Loss: 0.1766
Epoch 9/10, Batch 50/97, Loss: 0.2214
Epoch 9/10, Batch 60/97, Loss: 0.1848
Epoch 9/10, Batch 70/97, Loss: 0.1813
Epoch 9/10, Batch 80/97, Loss: 0.0882
Epoch 9/10, Batch 90/97, Loss: 0.2627
Epoch 9/10, Train Loss: 0.2062, Valid Loss: 0.2442
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3295
Epoch 10/10, Batch 20/97, Loss: 0.0734
Epoch 10/10, Batch 30/97, Loss: 0.0887
Epoch 10/10, Batch 40/97, Loss: 0.3187
Epoch 10/10, Batch 50/97, Loss: 0.2256
Epoch 10/10, Batch 60/97, Loss: 0.2190
Epoch 10/10, Batch 70/97, Loss: 0.1826
Epoch 10/10, Batch 80/97, Loss: 0.2878
Epoch 10/10, Batch 90/97, Loss: 0.3090
Epoch 10/10, Train Loss: 0.2006, Valid Loss: 0.2485
Accuracy: 0.9182
Precision: 0.9158
Recall: 0.9182
F1-score: 0.9165
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4614
Epoch 1/10, Batch 20/97, Loss: 0.9325
Epoch 1/10, Batch 30/97, Loss: 0.8507
Epoch 1/10, Batch 40/97, Loss: 0.7384
Epoch 1/10, Batch 50/97, Loss: 0.6636
Epoch 1/10, Batch 60/97, Loss: 0.4861
Epoch 1/10, Batch 70/97, Loss: 0.4512
Epoch 1/10, Batch 80/97, Loss: 0.4583
Epoch 1/10, Batch 90/97, Loss: 0.5666
Epoch 1/10, Train Loss: 0.7719, Valid Loss: 0.4269
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3669
Epoch 2/10, Batch 20/97, Loss: 0.5877
Epoch 2/10, Batch 30/97, Loss: 0.2625
Epoch 2/10, Batch 40/97, Loss: 0.3597
Epoch 2/10, Batch 50/97, Loss: 0.4956
Epoch 2/10, Batch 60/97, Loss: 0.4720
Epoch 2/10, Batch 70/97, Loss: 0.3189
Epoch 2/10, Batch 80/97, Loss: 0.3371
Epoch 2/10, Batch 90/97, Loss: 0.3546
Epoch 2/10, Train Loss: 0.3937, Valid Loss: 0.3206
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3091
Epoch 3/10, Batch 20/97, Loss: 0.3420
Epoch 3/10, Batch 30/97, Loss: 0.2999
Epoch 3/10, Batch 40/97, Loss: 0.2224
Epoch 3/10, Batch 50/97, Loss: 0.4069
Epoch 3/10, Batch 60/97, Loss: 0.3534
Epoch 3/10, Batch 70/97, Loss: 0.2108
Epoch 3/10, Batch 80/97, Loss: 0.3689
Epoch 3/10, Batch 90/97, Loss: 0.1829
Epoch 3/10, Train Loss: 0.3201, Valid Loss: 0.2817
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2059
Epoch 4/10, Batch 20/97, Loss: 0.1930
Epoch 4/10, Batch 30/97, Loss: 0.3404
Epoch 4/10, Batch 40/97, Loss: 0.3713
Epoch 4/10, Batch 50/97, Loss: 0.3321
Epoch 4/10, Batch 60/97, Loss: 0.1173
Epoch 4/10, Batch 70/97, Loss: 0.2190
Epoch 4/10, Batch 80/97, Loss: 0.2779
Epoch 4/10, Batch 90/97, Loss: 0.4325
Epoch 4/10, Train Loss: 0.2825, Valid Loss: 0.2647
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2142
Epoch 5/10, Batch 20/97, Loss: 0.2397
Epoch 5/10, Batch 30/97, Loss: 0.1744
Epoch 5/10, Batch 40/97, Loss: 0.2057
Epoch 5/10, Batch 50/97, Loss: 0.2425
Epoch 5/10, Batch 60/97, Loss: 0.3124
Epoch 5/10, Batch 70/97, Loss: 0.1844
Epoch 5/10, Batch 80/97, Loss: 0.1685
Epoch 5/10, Batch 90/97, Loss: 0.2678
Epoch 5/10, Train Loss: 0.2533, Valid Loss: 0.2482
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3537
Epoch 6/10, Batch 20/97, Loss: 0.1616
Epoch 6/10, Batch 30/97, Loss: 0.2365
Epoch 6/10, Batch 40/97, Loss: 0.2313
Epoch 6/10, Batch 50/97, Loss: 0.3170
Epoch 6/10, Batch 60/97, Loss: 0.2484
Epoch 6/10, Batch 70/97, Loss: 0.2022
Epoch 6/10, Batch 80/97, Loss: 0.2161
Epoch 6/10, Batch 90/97, Loss: 0.2565
Epoch 6/10, Train Loss: 0.2410, Valid Loss: 0.2506
Epoch 7/10, Batch 10/97, Loss: 0.2586
Epoch 7/10, Batch 20/97, Loss: 0.1948
Epoch 7/10, Batch 30/97, Loss: 0.2131
Epoch 7/10, Batch 40/97, Loss: 0.1487
Epoch 7/10, Batch 50/97, Loss: 0.1873
Epoch 7/10, Batch 60/97, Loss: 0.2787
Epoch 7/10, Batch 70/97, Loss: 0.2999
Epoch 7/10, Batch 80/97, Loss: 0.3220
Epoch 7/10, Batch 90/97, Loss: 0.2150
Epoch 7/10, Train Loss: 0.2392, Valid Loss: 0.2437
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1518
Epoch 8/10, Batch 20/97, Loss: 0.1772
Epoch 8/10, Batch 30/97, Loss: 0.1505
Epoch 8/10, Batch 40/97, Loss: 0.3565
Epoch 8/10, Batch 50/97, Loss: 0.1482
Epoch 8/10, Batch 60/97, Loss: 0.1491
Epoch 8/10, Batch 70/97, Loss: 0.2576
Epoch 8/10, Batch 80/97, Loss: 0.1996
Epoch 8/10, Batch 90/97, Loss: 0.1474
Epoch 8/10, Train Loss: 0.2173, Valid Loss: 0.2423
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1099
Epoch 9/10, Batch 20/97, Loss: 0.1222
Epoch 9/10, Batch 30/97, Loss: 0.2665
Epoch 9/10, Batch 40/97, Loss: 0.2093
Epoch 9/10, Batch 50/97, Loss: 0.2313
Epoch 9/10, Batch 60/97, Loss: 0.2159
Epoch 9/10, Batch 70/97, Loss: 0.2611
Epoch 9/10, Batch 80/97, Loss: 0.2397
Epoch 9/10, Batch 90/97, Loss: 0.1482
Epoch 9/10, Train Loss: 0.2047, Valid Loss: 0.2400
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2915
Epoch 10/10, Batch 20/97, Loss: 0.1779
Epoch 10/10, Batch 30/97, Loss: 0.0642
Epoch 10/10, Batch 40/97, Loss: 0.1918
Epoch 10/10, Batch 50/97, Loss: 0.4751
Epoch 10/10, Batch 60/97, Loss: 0.1993
Epoch 10/10, Batch 70/97, Loss: 0.1787
Epoch 10/10, Batch 80/97, Loss: 0.2972
Epoch 10/10, Batch 90/97, Loss: 0.2097
Epoch 10/10, Train Loss: 0.1952, Valid Loss: 0.2346
Model saved!
Accuracy: 0.9147
Precision: 0.9127
Recall: 0.9147
F1-score: 0.9133
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4763
Epoch 1/10, Batch 20/97, Loss: 0.9693
Epoch 1/10, Batch 30/97, Loss: 0.8793
Epoch 1/10, Batch 40/97, Loss: 0.7577
Epoch 1/10, Batch 50/97, Loss: 0.6100
Epoch 1/10, Batch 60/97, Loss: 0.4784
Epoch 1/10, Batch 70/97, Loss: 0.3947
Epoch 1/10, Batch 80/97, Loss: 0.5385
Epoch 1/10, Batch 90/97, Loss: 0.5526
Epoch 1/10, Train Loss: 0.7600, Valid Loss: 0.4197
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3885
Epoch 2/10, Batch 20/97, Loss: 0.6105
Epoch 2/10, Batch 30/97, Loss: 0.4343
Epoch 2/10, Batch 40/97, Loss: 0.4538
Epoch 2/10, Batch 50/97, Loss: 0.4939
Epoch 2/10, Batch 60/97, Loss: 0.3861
Epoch 2/10, Batch 70/97, Loss: 0.2674
Epoch 2/10, Batch 80/97, Loss: 0.2324
Epoch 2/10, Batch 90/97, Loss: 0.5770
Epoch 2/10, Train Loss: 0.3840, Valid Loss: 0.3118
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3224
Epoch 3/10, Batch 20/97, Loss: 0.2935
Epoch 3/10, Batch 30/97, Loss: 0.3691
Epoch 3/10, Batch 40/97, Loss: 0.2931
Epoch 3/10, Batch 50/97, Loss: 0.1742
Epoch 3/10, Batch 60/97, Loss: 0.2911
Epoch 3/10, Batch 70/97, Loss: 0.1696
Epoch 3/10, Batch 80/97, Loss: 0.3917
Epoch 3/10, Batch 90/97, Loss: 0.3299
Epoch 3/10, Train Loss: 0.3113, Valid Loss: 0.2766
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2115
Epoch 4/10, Batch 20/97, Loss: 0.3232
Epoch 4/10, Batch 30/97, Loss: 0.2740
Epoch 4/10, Batch 40/97, Loss: 0.1442
Epoch 4/10, Batch 50/97, Loss: 0.2397
Epoch 4/10, Batch 60/97, Loss: 0.1438
Epoch 4/10, Batch 70/97, Loss: 0.2994
Epoch 4/10, Batch 80/97, Loss: 0.2518
Epoch 4/10, Batch 90/97, Loss: 0.1814
Epoch 4/10, Train Loss: 0.2707, Valid Loss: 0.2566
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2583
Epoch 5/10, Batch 20/97, Loss: 0.1005
Epoch 5/10, Batch 30/97, Loss: 0.1259
Epoch 5/10, Batch 40/97, Loss: 0.3605
Epoch 5/10, Batch 50/97, Loss: 0.1735
Epoch 5/10, Batch 60/97, Loss: 0.2073
Epoch 5/10, Batch 70/97, Loss: 0.1806
Epoch 5/10, Batch 80/97, Loss: 0.2366
Epoch 5/10, Batch 90/97, Loss: 0.4177
Epoch 5/10, Train Loss: 0.2493, Valid Loss: 0.2370
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2268
Epoch 6/10, Batch 20/97, Loss: 0.2591
Epoch 6/10, Batch 30/97, Loss: 0.2364
Epoch 6/10, Batch 40/97, Loss: 0.2780
Epoch 6/10, Batch 50/97, Loss: 0.1439
Epoch 6/10, Batch 60/97, Loss: 0.2328
Epoch 6/10, Batch 70/97, Loss: 0.0874
Epoch 6/10, Batch 80/97, Loss: 0.1631
Epoch 6/10, Batch 90/97, Loss: 0.2685
Epoch 6/10, Train Loss: 0.2351, Valid Loss: 0.2284
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3408
Epoch 7/10, Batch 20/97, Loss: 0.0987
Epoch 7/10, Batch 30/97, Loss: 0.1390
Epoch 7/10, Batch 40/97, Loss: 0.1109
Epoch 7/10, Batch 50/97, Loss: 0.2081
Epoch 7/10, Batch 60/97, Loss: 0.1825
Epoch 7/10, Batch 70/97, Loss: 0.1956
Epoch 7/10, Batch 80/97, Loss: 0.1743
Epoch 7/10, Batch 90/97, Loss: 0.1430
Epoch 7/10, Train Loss: 0.2325, Valid Loss: 0.2258
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1188
Epoch 8/10, Batch 20/97, Loss: 0.1811
Epoch 8/10, Batch 30/97, Loss: 0.1589
Epoch 8/10, Batch 40/97, Loss: 0.1921
Epoch 8/10, Batch 50/97, Loss: 0.2545
Epoch 8/10, Batch 60/97, Loss: 0.2609
Epoch 8/10, Batch 70/97, Loss: 0.2382
Epoch 8/10, Batch 80/97, Loss: 0.0883
Epoch 8/10, Batch 90/97, Loss: 0.2085
Epoch 8/10, Train Loss: 0.2095, Valid Loss: 0.2090
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1539
Epoch 9/10, Batch 20/97, Loss: 0.1965
Epoch 9/10, Batch 30/97, Loss: 0.2940
Epoch 9/10, Batch 40/97, Loss: 0.2316
Epoch 9/10, Batch 50/97, Loss: 0.2198
Epoch 9/10, Batch 60/97, Loss: 0.1149
Epoch 9/10, Batch 70/97, Loss: 0.1077
Epoch 9/10, Batch 80/97, Loss: 0.1929
Epoch 9/10, Batch 90/97, Loss: 0.1690
Epoch 9/10, Train Loss: 0.2010, Valid Loss: 0.2081
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2342
Epoch 10/10, Batch 20/97, Loss: 0.1692
Epoch 10/10, Batch 30/97, Loss: 0.1631
Epoch 10/10, Batch 40/97, Loss: 0.2228
Epoch 10/10, Batch 50/97, Loss: 0.2347
Epoch 10/10, Batch 60/97, Loss: 0.1035
Epoch 10/10, Batch 70/97, Loss: 0.1163
Epoch 10/10, Batch 80/97, Loss: 0.1589
Epoch 10/10, Batch 90/97, Loss: 0.1254
Epoch 10/10, Train Loss: 0.1862, Valid Loss: 0.2017
Model saved!
Accuracy: 0.9136
Precision: 0.9107
Recall: 0.9136
F1-score: 0.9114
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4363
Epoch 1/10, Batch 20/97, Loss: 1.0418
Epoch 1/10, Batch 30/97, Loss: 0.7678
Epoch 1/10, Batch 40/97, Loss: 0.7761
Epoch 1/10, Batch 50/97, Loss: 0.5662
Epoch 1/10, Batch 60/97, Loss: 0.6191
Epoch 1/10, Batch 70/97, Loss: 0.6350
Epoch 1/10, Batch 80/97, Loss: 0.4539
Epoch 1/10, Batch 90/97, Loss: 0.4545
Epoch 1/10, Train Loss: 0.7701, Valid Loss: 0.4623
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3531
Epoch 2/10, Batch 20/97, Loss: 0.4804
Epoch 2/10, Batch 30/97, Loss: 0.3980
Epoch 2/10, Batch 40/97, Loss: 0.5684
Epoch 2/10, Batch 50/97, Loss: 0.5246
Epoch 2/10, Batch 60/97, Loss: 0.3797
Epoch 2/10, Batch 70/97, Loss: 0.3059
Epoch 2/10, Batch 80/97, Loss: 0.4763
Epoch 2/10, Batch 90/97, Loss: 0.3761
Epoch 2/10, Train Loss: 0.3922, Valid Loss: 0.3626
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2896
Epoch 3/10, Batch 20/97, Loss: 0.3396
Epoch 3/10, Batch 30/97, Loss: 0.2506
Epoch 3/10, Batch 40/97, Loss: 0.3689
Epoch 3/10, Batch 50/97, Loss: 0.2431
Epoch 3/10, Batch 60/97, Loss: 0.2439
Epoch 3/10, Batch 70/97, Loss: 0.2540
Epoch 3/10, Batch 80/97, Loss: 0.3121
Epoch 3/10, Batch 90/97, Loss: 0.2420
Epoch 3/10, Train Loss: 0.3191, Valid Loss: 0.3171
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2371
Epoch 4/10, Batch 20/97, Loss: 0.1991
Epoch 4/10, Batch 30/97, Loss: 0.3124
Epoch 4/10, Batch 40/97, Loss: 0.2688
Epoch 4/10, Batch 50/97, Loss: 0.1993
Epoch 4/10, Batch 60/97, Loss: 0.2337
Epoch 4/10, Batch 70/97, Loss: 0.1475
Epoch 4/10, Batch 80/97, Loss: 0.1682
Epoch 4/10, Batch 90/97, Loss: 0.2458
Epoch 4/10, Train Loss: 0.2850, Valid Loss: 0.2939
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2466
Epoch 5/10, Batch 20/97, Loss: 0.1783
Epoch 5/10, Batch 30/97, Loss: 0.2387
Epoch 5/10, Batch 40/97, Loss: 0.2011
Epoch 5/10, Batch 50/97, Loss: 0.2554
Epoch 5/10, Batch 60/97, Loss: 0.1505
Epoch 5/10, Batch 70/97, Loss: 0.1988
Epoch 5/10, Batch 80/97, Loss: 0.1548
Epoch 5/10, Batch 90/97, Loss: 0.2575
Epoch 5/10, Train Loss: 0.2633, Valid Loss: 0.2838
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2360
Epoch 6/10, Batch 20/97, Loss: 0.2530
Epoch 6/10, Batch 30/97, Loss: 0.2607
Epoch 6/10, Batch 40/97, Loss: 0.3816
Epoch 6/10, Batch 50/97, Loss: 0.3250
Epoch 6/10, Batch 60/97, Loss: 0.2330
Epoch 6/10, Batch 70/97, Loss: 0.1387
Epoch 6/10, Batch 80/97, Loss: 0.1556
Epoch 6/10, Batch 90/97, Loss: 0.3078
Epoch 6/10, Train Loss: 0.2361, Valid Loss: 0.2837
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1915
Epoch 7/10, Batch 20/97, Loss: 0.1406
Epoch 7/10, Batch 30/97, Loss: 0.1997
Epoch 7/10, Batch 40/97, Loss: 0.1998
Epoch 7/10, Batch 50/97, Loss: 0.3308
Epoch 7/10, Batch 60/97, Loss: 0.3415
Epoch 7/10, Batch 70/97, Loss: 0.1610
Epoch 7/10, Batch 80/97, Loss: 0.2697
Epoch 7/10, Batch 90/97, Loss: 0.1929
Epoch 7/10, Train Loss: 0.2350, Valid Loss: 0.2735
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2341
Epoch 8/10, Batch 20/97, Loss: 0.1658
Epoch 8/10, Batch 30/97, Loss: 0.1988
Epoch 8/10, Batch 40/97, Loss: 0.1366
Epoch 8/10, Batch 50/97, Loss: 0.1396
Epoch 8/10, Batch 60/97, Loss: 0.1334
Epoch 8/10, Batch 70/97, Loss: 0.1226
Epoch 8/10, Batch 80/97, Loss: 0.2416
Epoch 8/10, Batch 90/97, Loss: 0.1550
Epoch 8/10, Train Loss: 0.2090, Valid Loss: 0.2700
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1151
Epoch 9/10, Batch 20/97, Loss: 0.0849
Epoch 9/10, Batch 30/97, Loss: 0.1906
Epoch 9/10, Batch 40/97, Loss: 0.2028
Epoch 9/10, Batch 50/97, Loss: 0.3780
Epoch 9/10, Batch 60/97, Loss: 0.2729
Epoch 9/10, Batch 70/97, Loss: 0.1752
Epoch 9/10, Batch 80/97, Loss: 0.1639
Epoch 9/10, Batch 90/97, Loss: 0.3188
Epoch 9/10, Train Loss: 0.2053, Valid Loss: 0.2586
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2129
Epoch 10/10, Batch 20/97, Loss: 0.1440
Epoch 10/10, Batch 30/97, Loss: 0.1419
Epoch 10/10, Batch 40/97, Loss: 0.1919
Epoch 10/10, Batch 50/97, Loss: 0.2136
Epoch 10/10, Batch 60/97, Loss: 0.1073
Epoch 10/10, Batch 70/97, Loss: 0.1022
Epoch 10/10, Batch 80/97, Loss: 0.2298
Epoch 10/10, Batch 90/97, Loss: 0.1738
Epoch 10/10, Train Loss: 0.1953, Valid Loss: 0.2553
Model saved!
Accuracy: 0.9089
Precision: 0.9066
Recall: 0.9089
F1-score: 0.9057
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4785
Epoch 1/10, Batch 20/97, Loss: 1.0231
Epoch 1/10, Batch 30/97, Loss: 0.8588
Epoch 1/10, Batch 40/97, Loss: 0.8160
Epoch 1/10, Batch 50/97, Loss: 0.6678
Epoch 1/10, Batch 60/97, Loss: 0.5832
Epoch 1/10, Batch 70/97, Loss: 0.4728
Epoch 1/10, Batch 80/97, Loss: 0.4699
Epoch 1/10, Batch 90/97, Loss: 0.5132
Epoch 1/10, Train Loss: 0.7733, Valid Loss: 0.4279
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3385
Epoch 2/10, Batch 20/97, Loss: 0.6746
Epoch 2/10, Batch 30/97, Loss: 0.4114
Epoch 2/10, Batch 40/97, Loss: 0.3186
Epoch 2/10, Batch 50/97, Loss: 0.6093
Epoch 2/10, Batch 60/97, Loss: 0.3189
Epoch 2/10, Batch 70/97, Loss: 0.2927
Epoch 2/10, Batch 80/97, Loss: 0.2338
Epoch 2/10, Batch 90/97, Loss: 0.3850
Epoch 2/10, Train Loss: 0.3949, Valid Loss: 0.3141
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3001
Epoch 3/10, Batch 20/97, Loss: 0.3022
Epoch 3/10, Batch 30/97, Loss: 0.2056
Epoch 3/10, Batch 40/97, Loss: 0.1790
Epoch 3/10, Batch 50/97, Loss: 0.1912
Epoch 3/10, Batch 60/97, Loss: 0.2008
Epoch 3/10, Batch 70/97, Loss: 0.2201
Epoch 3/10, Batch 80/97, Loss: 0.4229
Epoch 3/10, Batch 90/97, Loss: 0.2550
Epoch 3/10, Train Loss: 0.3222, Valid Loss: 0.2729
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3420
Epoch 4/10, Batch 20/97, Loss: 0.1970
Epoch 4/10, Batch 30/97, Loss: 0.4057
Epoch 4/10, Batch 40/97, Loss: 0.2876
Epoch 4/10, Batch 50/97, Loss: 0.2007
Epoch 4/10, Batch 60/97, Loss: 0.2216
Epoch 4/10, Batch 70/97, Loss: 0.2738
Epoch 4/10, Batch 80/97, Loss: 0.3898
Epoch 4/10, Batch 90/97, Loss: 0.2966
Epoch 4/10, Train Loss: 0.2840, Valid Loss: 0.2492
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2566
Epoch 5/10, Batch 20/97, Loss: 0.1042
Epoch 5/10, Batch 30/97, Loss: 0.2163
Epoch 5/10, Batch 40/97, Loss: 0.1177
Epoch 5/10, Batch 50/97, Loss: 0.2798
Epoch 5/10, Batch 60/97, Loss: 0.2656
Epoch 5/10, Batch 70/97, Loss: 0.2225
Epoch 5/10, Batch 80/97, Loss: 0.3152
Epoch 5/10, Batch 90/97, Loss: 0.3776
Epoch 5/10, Train Loss: 0.2571, Valid Loss: 0.2349
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2696
Epoch 6/10, Batch 20/97, Loss: 0.2038
Epoch 6/10, Batch 30/97, Loss: 0.2091
Epoch 6/10, Batch 40/97, Loss: 0.2597
Epoch 6/10, Batch 50/97, Loss: 0.1621
Epoch 6/10, Batch 60/97, Loss: 0.2529
Epoch 6/10, Batch 70/97, Loss: 0.3523
Epoch 6/10, Batch 80/97, Loss: 0.2381
Epoch 6/10, Batch 90/97, Loss: 0.1438
Epoch 6/10, Train Loss: 0.2430, Valid Loss: 0.2295
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2336
Epoch 7/10, Batch 20/97, Loss: 0.1387
Epoch 7/10, Batch 30/97, Loss: 0.1871
Epoch 7/10, Batch 40/97, Loss: 0.1513
Epoch 7/10, Batch 50/97, Loss: 0.2191
Epoch 7/10, Batch 60/97, Loss: 0.2151
Epoch 7/10, Batch 70/97, Loss: 0.3422
Epoch 7/10, Batch 80/97, Loss: 0.1958
Epoch 7/10, Batch 90/97, Loss: 0.2381
Epoch 7/10, Train Loss: 0.2421, Valid Loss: 0.2135
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1405
Epoch 8/10, Batch 20/97, Loss: 0.2214
Epoch 8/10, Batch 30/97, Loss: 0.1487
Epoch 8/10, Batch 40/97, Loss: 0.0828
Epoch 8/10, Batch 50/97, Loss: 0.2971
Epoch 8/10, Batch 60/97, Loss: 0.1267
Epoch 8/10, Batch 70/97, Loss: 0.3595
Epoch 8/10, Batch 80/97, Loss: 0.2866
Epoch 8/10, Batch 90/97, Loss: 0.1831
Epoch 8/10, Train Loss: 0.2183, Valid Loss: 0.2091
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0747
Epoch 9/10, Batch 20/97, Loss: 0.0948
Epoch 9/10, Batch 30/97, Loss: 0.3043
Epoch 9/10, Batch 40/97, Loss: 0.2350
Epoch 9/10, Batch 50/97, Loss: 0.1824
Epoch 9/10, Batch 60/97, Loss: 0.2282
Epoch 9/10, Batch 70/97, Loss: 0.1813
Epoch 9/10, Batch 80/97, Loss: 0.1101
Epoch 9/10, Batch 90/97, Loss: 0.2068
Epoch 9/10, Train Loss: 0.2053, Valid Loss: 0.2101
Epoch 10/10, Batch 10/97, Loss: 0.2496
Epoch 10/10, Batch 20/97, Loss: 0.1654
Epoch 10/10, Batch 30/97, Loss: 0.2770
Epoch 10/10, Batch 40/97, Loss: 0.1750
Epoch 10/10, Batch 50/97, Loss: 0.4159
Epoch 10/10, Batch 60/97, Loss: 0.1544
Epoch 10/10, Batch 70/97, Loss: 0.2381
Epoch 10/10, Batch 80/97, Loss: 0.1452
Epoch 10/10, Batch 90/97, Loss: 0.1923
Epoch 10/10, Train Loss: 0.1952, Valid Loss: 0.1996
Model saved!
Accuracy: 0.9194
Precision: 0.9171
Recall: 0.9194
F1-score: 0.9177
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4866
Epoch 1/10, Batch 20/97, Loss: 0.9802
Epoch 1/10, Batch 30/97, Loss: 0.9075
Epoch 1/10, Batch 40/97, Loss: 0.6819
Epoch 1/10, Batch 50/97, Loss: 0.5813
Epoch 1/10, Batch 60/97, Loss: 0.5169
Epoch 1/10, Batch 70/97, Loss: 0.4757
Epoch 1/10, Batch 80/97, Loss: 0.4458
Epoch 1/10, Batch 90/97, Loss: 0.5686
Epoch 1/10, Train Loss: 0.7738, Valid Loss: 0.4392
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4538
Epoch 2/10, Batch 20/97, Loss: 0.6028
Epoch 2/10, Batch 30/97, Loss: 0.3853
Epoch 2/10, Batch 40/97, Loss: 0.4511
Epoch 2/10, Batch 50/97, Loss: 0.4797
Epoch 2/10, Batch 60/97, Loss: 0.2835
Epoch 2/10, Batch 70/97, Loss: 0.3213
Epoch 2/10, Batch 80/97, Loss: 0.3277
Epoch 2/10, Batch 90/97, Loss: 0.2765
Epoch 2/10, Train Loss: 0.3882, Valid Loss: 0.3374
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2903
Epoch 3/10, Batch 20/97, Loss: 0.2972
Epoch 3/10, Batch 30/97, Loss: 0.2667
Epoch 3/10, Batch 40/97, Loss: 0.2518
Epoch 3/10, Batch 50/97, Loss: 0.3664
Epoch 3/10, Batch 60/97, Loss: 0.2833
Epoch 3/10, Batch 70/97, Loss: 0.2167
Epoch 3/10, Batch 80/97, Loss: 0.2448
Epoch 3/10, Batch 90/97, Loss: 0.3884
Epoch 3/10, Train Loss: 0.3156, Valid Loss: 0.2915
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2231
Epoch 4/10, Batch 20/97, Loss: 0.2426
Epoch 4/10, Batch 30/97, Loss: 0.3257
Epoch 4/10, Batch 40/97, Loss: 0.2844
Epoch 4/10, Batch 50/97, Loss: 0.1927
Epoch 4/10, Batch 60/97, Loss: 0.2191
Epoch 4/10, Batch 70/97, Loss: 0.2122
Epoch 4/10, Batch 80/97, Loss: 0.2170
Epoch 4/10, Batch 90/97, Loss: 0.2656
Epoch 4/10, Train Loss: 0.2790, Valid Loss: 0.2739
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3477
Epoch 5/10, Batch 20/97, Loss: 0.2306
Epoch 5/10, Batch 30/97, Loss: 0.1592
Epoch 5/10, Batch 40/97, Loss: 0.1702
Epoch 5/10, Batch 50/97, Loss: 0.2456
Epoch 5/10, Batch 60/97, Loss: 0.1723
Epoch 5/10, Batch 70/97, Loss: 0.1610
Epoch 5/10, Batch 80/97, Loss: 0.2199
Epoch 5/10, Batch 90/97, Loss: 0.3164
Epoch 5/10, Train Loss: 0.2507, Valid Loss: 0.2532
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3201
Epoch 6/10, Batch 20/97, Loss: 0.1374
Epoch 6/10, Batch 30/97, Loss: 0.2440
Epoch 6/10, Batch 40/97, Loss: 0.2883
Epoch 6/10, Batch 50/97, Loss: 0.2294
Epoch 6/10, Batch 60/97, Loss: 0.2497
Epoch 6/10, Batch 70/97, Loss: 0.2307
Epoch 6/10, Batch 80/97, Loss: 0.2033
Epoch 6/10, Batch 90/97, Loss: 0.2559
Epoch 6/10, Train Loss: 0.2304, Valid Loss: 0.2548
Epoch 7/10, Batch 10/97, Loss: 0.2586
Epoch 7/10, Batch 20/97, Loss: 0.2095
Epoch 7/10, Batch 30/97, Loss: 0.2360
Epoch 7/10, Batch 40/97, Loss: 0.2142
Epoch 7/10, Batch 50/97, Loss: 0.3674
Epoch 7/10, Batch 60/97, Loss: 0.3198
Epoch 7/10, Batch 70/97, Loss: 0.1756
Epoch 7/10, Batch 80/97, Loss: 0.2038
Epoch 7/10, Batch 90/97, Loss: 0.1667
Epoch 7/10, Train Loss: 0.2349, Valid Loss: 0.2487
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1589
Epoch 8/10, Batch 20/97, Loss: 0.1460
Epoch 8/10, Batch 30/97, Loss: 0.1337
Epoch 8/10, Batch 40/97, Loss: 0.1794
Epoch 8/10, Batch 50/97, Loss: 0.0973
Epoch 8/10, Batch 60/97, Loss: 0.1042
Epoch 8/10, Batch 70/97, Loss: 0.2400
Epoch 8/10, Batch 80/97, Loss: 0.1860
Epoch 8/10, Batch 90/97, Loss: 0.0969
Epoch 8/10, Train Loss: 0.2104, Valid Loss: 0.2397
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0660
Epoch 9/10, Batch 20/97, Loss: 0.1863
Epoch 9/10, Batch 30/97, Loss: 0.1729
Epoch 9/10, Batch 40/97, Loss: 0.2282
Epoch 9/10, Batch 50/97, Loss: 0.2716
Epoch 9/10, Batch 60/97, Loss: 0.2231
Epoch 9/10, Batch 70/97, Loss: 0.2036
Epoch 9/10, Batch 80/97, Loss: 0.3419
Epoch 9/10, Batch 90/97, Loss: 0.1042
Epoch 9/10, Train Loss: 0.2088, Valid Loss: 0.2441
Epoch 10/10, Batch 10/97, Loss: 0.3129
Epoch 10/10, Batch 20/97, Loss: 0.2195
Epoch 10/10, Batch 30/97, Loss: 0.1896
Epoch 10/10, Batch 40/97, Loss: 0.2098
Epoch 10/10, Batch 50/97, Loss: 0.3145
Epoch 10/10, Batch 60/97, Loss: 0.1325
Epoch 10/10, Batch 70/97, Loss: 0.1361
Epoch 10/10, Batch 80/97, Loss: 0.1844
Epoch 10/10, Batch 90/97, Loss: 0.2026
Epoch 10/10, Train Loss: 0.1974, Valid Loss: 0.2344
Model saved!
Accuracy: 0.9194
Precision: 0.9171
Recall: 0.9194
F1-score: 0.9178
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4651
Epoch 1/10, Batch 20/97, Loss: 0.9812
Epoch 1/10, Batch 30/97, Loss: 0.8552
Epoch 1/10, Batch 40/97, Loss: 0.7255
Epoch 1/10, Batch 50/97, Loss: 0.5544
Epoch 1/10, Batch 60/97, Loss: 0.6147
Epoch 1/10, Batch 70/97, Loss: 0.4835
Epoch 1/10, Batch 80/97, Loss: 0.4878
Epoch 1/10, Batch 90/97, Loss: 0.5047
Epoch 1/10, Train Loss: 0.7717, Valid Loss: 0.4544
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3914
Epoch 2/10, Batch 20/97, Loss: 0.5813
Epoch 2/10, Batch 30/97, Loss: 0.4354
Epoch 2/10, Batch 40/97, Loss: 0.4928
Epoch 2/10, Batch 50/97, Loss: 0.5327
Epoch 2/10, Batch 60/97, Loss: 0.4013
Epoch 2/10, Batch 70/97, Loss: 0.3193
Epoch 2/10, Batch 80/97, Loss: 0.3761
Epoch 2/10, Batch 90/97, Loss: 0.3948
Epoch 2/10, Train Loss: 0.3929, Valid Loss: 0.3670
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2302
Epoch 3/10, Batch 20/97, Loss: 0.2933
Epoch 3/10, Batch 30/97, Loss: 0.1384
Epoch 3/10, Batch 40/97, Loss: 0.2891
Epoch 3/10, Batch 50/97, Loss: 0.3393
Epoch 3/10, Batch 60/97, Loss: 0.2926
Epoch 3/10, Batch 70/97, Loss: 0.3165
Epoch 3/10, Batch 80/97, Loss: 0.2341
Epoch 3/10, Batch 90/97, Loss: 0.3217
Epoch 3/10, Train Loss: 0.3236, Valid Loss: 0.3288
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3047
Epoch 4/10, Batch 20/97, Loss: 0.3563
Epoch 4/10, Batch 30/97, Loss: 0.3222
Epoch 4/10, Batch 40/97, Loss: 0.2430
Epoch 4/10, Batch 50/97, Loss: 0.1489
Epoch 4/10, Batch 60/97, Loss: 0.1649
Epoch 4/10, Batch 70/97, Loss: 0.2031
Epoch 4/10, Batch 80/97, Loss: 0.3372
Epoch 4/10, Batch 90/97, Loss: 0.2249
Epoch 4/10, Train Loss: 0.2869, Valid Loss: 0.3140
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1842
Epoch 5/10, Batch 20/97, Loss: 0.1469
Epoch 5/10, Batch 30/97, Loss: 0.1080
Epoch 5/10, Batch 40/97, Loss: 0.2180
Epoch 5/10, Batch 50/97, Loss: 0.2023
Epoch 5/10, Batch 60/97, Loss: 0.3393
Epoch 5/10, Batch 70/97, Loss: 0.1670
Epoch 5/10, Batch 80/97, Loss: 0.3561
Epoch 5/10, Batch 90/97, Loss: 0.5232
Epoch 5/10, Train Loss: 0.2625, Valid Loss: 0.3037
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2901
Epoch 6/10, Batch 20/97, Loss: 0.2540
Epoch 6/10, Batch 30/97, Loss: 0.2010
Epoch 6/10, Batch 40/97, Loss: 0.2136
Epoch 6/10, Batch 50/97, Loss: 0.1629
Epoch 6/10, Batch 60/97, Loss: 0.3327
Epoch 6/10, Batch 70/97, Loss: 0.2344
Epoch 6/10, Batch 80/97, Loss: 0.2024
Epoch 6/10, Batch 90/97, Loss: 0.2032
Epoch 6/10, Train Loss: 0.2444, Valid Loss: 0.2973
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2728
Epoch 7/10, Batch 20/97, Loss: 0.1598
Epoch 7/10, Batch 30/97, Loss: 0.1492
Epoch 7/10, Batch 40/97, Loss: 0.1162
Epoch 7/10, Batch 50/97, Loss: 0.2643
Epoch 7/10, Batch 60/97, Loss: 0.2200
Epoch 7/10, Batch 70/97, Loss: 0.2091
Epoch 7/10, Batch 80/97, Loss: 0.1991
Epoch 7/10, Batch 90/97, Loss: 0.2075
Epoch 7/10, Train Loss: 0.2464, Valid Loss: 0.2908
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2116
Epoch 8/10, Batch 20/97, Loss: 0.2435
Epoch 8/10, Batch 30/97, Loss: 0.1224
Epoch 8/10, Batch 40/97, Loss: 0.2731
Epoch 8/10, Batch 50/97, Loss: 0.1484
Epoch 8/10, Batch 60/97, Loss: 0.0802
Epoch 8/10, Batch 70/97, Loss: 0.2688
Epoch 8/10, Batch 80/97, Loss: 0.1091
Epoch 8/10, Batch 90/97, Loss: 0.1715
Epoch 8/10, Train Loss: 0.2145, Valid Loss: 0.2786
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0875
Epoch 9/10, Batch 20/97, Loss: 0.1884
Epoch 9/10, Batch 30/97, Loss: 0.2900
Epoch 9/10, Batch 40/97, Loss: 0.2604
Epoch 9/10, Batch 50/97, Loss: 0.2429
Epoch 9/10, Batch 60/97, Loss: 0.2104
Epoch 9/10, Batch 70/97, Loss: 0.1680
Epoch 9/10, Batch 80/97, Loss: 0.1310
Epoch 9/10, Batch 90/97, Loss: 0.2287
Epoch 9/10, Train Loss: 0.2073, Valid Loss: 0.2836
Epoch 10/10, Batch 10/97, Loss: 0.2801
Epoch 10/10, Batch 20/97, Loss: 0.0953
Epoch 10/10, Batch 30/97, Loss: 0.1136
Epoch 10/10, Batch 40/97, Loss: 0.3232
Epoch 10/10, Batch 50/97, Loss: 0.2492
Epoch 10/10, Batch 60/97, Loss: 0.0992
Epoch 10/10, Batch 70/97, Loss: 0.1539
Epoch 10/10, Batch 80/97, Loss: 0.2997
Epoch 10/10, Batch 90/97, Loss: 0.2043
Epoch 10/10, Train Loss: 0.1961, Valid Loss: 0.2791
Accuracy: 0.9206
Precision: 0.9181
Recall: 0.9206
F1-score: 0.9187
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4995
Epoch 1/10, Batch 20/97, Loss: 0.9625
Epoch 1/10, Batch 30/97, Loss: 0.9098
Epoch 1/10, Batch 40/97, Loss: 0.6467
Epoch 1/10, Batch 50/97, Loss: 0.5418
Epoch 1/10, Batch 60/97, Loss: 0.6699
Epoch 1/10, Batch 70/97, Loss: 0.4138
Epoch 1/10, Batch 80/97, Loss: 0.6512
Epoch 1/10, Batch 90/97, Loss: 0.6257
Epoch 1/10, Train Loss: 0.7671, Valid Loss: 0.4433
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4691
Epoch 2/10, Batch 20/97, Loss: 0.4928
Epoch 2/10, Batch 30/97, Loss: 0.3755
Epoch 2/10, Batch 40/97, Loss: 0.3699
Epoch 2/10, Batch 50/97, Loss: 0.6073
Epoch 2/10, Batch 60/97, Loss: 0.4304
Epoch 2/10, Batch 70/97, Loss: 0.2983
Epoch 2/10, Batch 80/97, Loss: 0.3384
Epoch 2/10, Batch 90/97, Loss: 0.2910
Epoch 2/10, Train Loss: 0.3845, Valid Loss: 0.3470
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3304
Epoch 3/10, Batch 20/97, Loss: 0.2455
Epoch 3/10, Batch 30/97, Loss: 0.2343
Epoch 3/10, Batch 40/97, Loss: 0.2797
Epoch 3/10, Batch 50/97, Loss: 0.2503
Epoch 3/10, Batch 60/97, Loss: 0.2267
Epoch 3/10, Batch 70/97, Loss: 0.2885
Epoch 3/10, Batch 80/97, Loss: 0.2684
Epoch 3/10, Batch 90/97, Loss: 0.3220
Epoch 3/10, Train Loss: 0.3118, Valid Loss: 0.3027
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2635
Epoch 4/10, Batch 20/97, Loss: 0.1841
Epoch 4/10, Batch 30/97, Loss: 0.4041
Epoch 4/10, Batch 40/97, Loss: 0.1568
Epoch 4/10, Batch 50/97, Loss: 0.2985
Epoch 4/10, Batch 60/97, Loss: 0.2571
Epoch 4/10, Batch 70/97, Loss: 0.3212
Epoch 4/10, Batch 80/97, Loss: 0.2370
Epoch 4/10, Batch 90/97, Loss: 0.2686
Epoch 4/10, Train Loss: 0.2899, Valid Loss: 0.2885
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2267
Epoch 5/10, Batch 20/97, Loss: 0.1635
Epoch 5/10, Batch 30/97, Loss: 0.2720
Epoch 5/10, Batch 40/97, Loss: 0.1486
Epoch 5/10, Batch 50/97, Loss: 0.1819
Epoch 5/10, Batch 60/97, Loss: 0.1874
Epoch 5/10, Batch 70/97, Loss: 0.1776
Epoch 5/10, Batch 80/97, Loss: 0.1673
Epoch 5/10, Batch 90/97, Loss: 0.2417
Epoch 5/10, Train Loss: 0.2504, Valid Loss: 0.2775
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2067
Epoch 6/10, Batch 20/97, Loss: 0.4104
Epoch 6/10, Batch 30/97, Loss: 0.1656
Epoch 6/10, Batch 40/97, Loss: 0.5209
Epoch 6/10, Batch 50/97, Loss: 0.2564
Epoch 6/10, Batch 60/97, Loss: 0.1516
Epoch 6/10, Batch 70/97, Loss: 0.2827
Epoch 6/10, Batch 80/97, Loss: 0.2292
Epoch 6/10, Batch 90/97, Loss: 0.2488
Epoch 6/10, Train Loss: 0.2392, Valid Loss: 0.2762
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4333
Epoch 7/10, Batch 20/97, Loss: 0.0893
Epoch 7/10, Batch 30/97, Loss: 0.2005
Epoch 7/10, Batch 40/97, Loss: 0.2569
Epoch 7/10, Batch 50/97, Loss: 0.2253
Epoch 7/10, Batch 60/97, Loss: 0.2356
Epoch 7/10, Batch 70/97, Loss: 0.2276
Epoch 7/10, Batch 80/97, Loss: 0.1169
Epoch 7/10, Batch 90/97, Loss: 0.3247
Epoch 7/10, Train Loss: 0.2364, Valid Loss: 0.2623
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1477
Epoch 8/10, Batch 20/97, Loss: 0.2412
Epoch 8/10, Batch 30/97, Loss: 0.2062
Epoch 8/10, Batch 40/97, Loss: 0.1156
Epoch 8/10, Batch 50/97, Loss: 0.2174
Epoch 8/10, Batch 60/97, Loss: 0.2142
Epoch 8/10, Batch 70/97, Loss: 0.4567
Epoch 8/10, Batch 80/97, Loss: 0.0914
Epoch 8/10, Batch 90/97, Loss: 0.2099
Epoch 8/10, Train Loss: 0.2163, Valid Loss: 0.2547
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1686
Epoch 9/10, Batch 20/97, Loss: 0.0980
Epoch 9/10, Batch 30/97, Loss: 0.2578
Epoch 9/10, Batch 40/97, Loss: 0.1822
Epoch 9/10, Batch 50/97, Loss: 0.1815
Epoch 9/10, Batch 60/97, Loss: 0.2024
Epoch 9/10, Batch 70/97, Loss: 0.3032
Epoch 9/10, Batch 80/97, Loss: 0.1883
Epoch 9/10, Batch 90/97, Loss: 0.0953
Epoch 9/10, Train Loss: 0.2046, Valid Loss: 0.2548
Epoch 10/10, Batch 10/97, Loss: 0.2440
Epoch 10/10, Batch 20/97, Loss: 0.0676
Epoch 10/10, Batch 30/97, Loss: 0.2316
Epoch 10/10, Batch 40/97, Loss: 0.2865
Epoch 10/10, Batch 50/97, Loss: 0.4116
Epoch 10/10, Batch 60/97, Loss: 0.1938
Epoch 10/10, Batch 70/97, Loss: 0.0742
Epoch 10/10, Batch 80/97, Loss: 0.1167
Epoch 10/10, Batch 90/97, Loss: 0.1683
Epoch 10/10, Train Loss: 0.1917, Valid Loss: 0.2527
Model saved!
Accuracy: 0.9077
Precision: 0.9047
Recall: 0.9077
F1-score: 0.9051
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5187
Epoch 1/10, Batch 20/97, Loss: 1.0070
Epoch 1/10, Batch 30/97, Loss: 0.9142
Epoch 1/10, Batch 40/97, Loss: 0.7482
Epoch 1/10, Batch 50/97, Loss: 0.5789
Epoch 1/10, Batch 60/97, Loss: 0.6994
Epoch 1/10, Batch 70/97, Loss: 0.4425
Epoch 1/10, Batch 80/97, Loss: 0.4747
Epoch 1/10, Batch 90/97, Loss: 0.6341
Epoch 1/10, Train Loss: 0.7783, Valid Loss: 0.4238
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3163
Epoch 2/10, Batch 20/97, Loss: 0.4946
Epoch 2/10, Batch 30/97, Loss: 0.4591
Epoch 2/10, Batch 40/97, Loss: 0.3948
Epoch 2/10, Batch 50/97, Loss: 0.5356
Epoch 2/10, Batch 60/97, Loss: 0.4402
Epoch 2/10, Batch 70/97, Loss: 0.3180
Epoch 2/10, Batch 80/97, Loss: 0.3422
Epoch 2/10, Batch 90/97, Loss: 0.3105
Epoch 2/10, Train Loss: 0.3973, Valid Loss: 0.3207
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2896
Epoch 3/10, Batch 20/97, Loss: 0.3139
Epoch 3/10, Batch 30/97, Loss: 0.2811
Epoch 3/10, Batch 40/97, Loss: 0.2211
Epoch 3/10, Batch 50/97, Loss: 0.3147
Epoch 3/10, Batch 60/97, Loss: 0.1736
Epoch 3/10, Batch 70/97, Loss: 0.1692
Epoch 3/10, Batch 80/97, Loss: 0.2349
Epoch 3/10, Batch 90/97, Loss: 0.3831
Epoch 3/10, Train Loss: 0.3212, Valid Loss: 0.2751
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4265
Epoch 4/10, Batch 20/97, Loss: 0.3251
Epoch 4/10, Batch 30/97, Loss: 0.3532
Epoch 4/10, Batch 40/97, Loss: 0.3023
Epoch 4/10, Batch 50/97, Loss: 0.2279
Epoch 4/10, Batch 60/97, Loss: 0.1274
Epoch 4/10, Batch 70/97, Loss: 0.2277
Epoch 4/10, Batch 80/97, Loss: 0.2465
Epoch 4/10, Batch 90/97, Loss: 0.2419
Epoch 4/10, Train Loss: 0.2828, Valid Loss: 0.2464
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2684
Epoch 5/10, Batch 20/97, Loss: 0.3701
Epoch 5/10, Batch 30/97, Loss: 0.1211
Epoch 5/10, Batch 40/97, Loss: 0.1526
Epoch 5/10, Batch 50/97, Loss: 0.1731
Epoch 5/10, Batch 60/97, Loss: 0.2423
Epoch 5/10, Batch 70/97, Loss: 0.3724
Epoch 5/10, Batch 80/97, Loss: 0.2401
Epoch 5/10, Batch 90/97, Loss: 0.2740
Epoch 5/10, Train Loss: 0.2605, Valid Loss: 0.2331
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2105
Epoch 6/10, Batch 20/97, Loss: 0.1589
Epoch 6/10, Batch 30/97, Loss: 0.1648
Epoch 6/10, Batch 40/97, Loss: 0.3675
Epoch 6/10, Batch 50/97, Loss: 0.2610
Epoch 6/10, Batch 60/97, Loss: 0.3579
Epoch 6/10, Batch 70/97, Loss: 0.1727
Epoch 6/10, Batch 80/97, Loss: 0.1894
Epoch 6/10, Batch 90/97, Loss: 0.3556
Epoch 6/10, Train Loss: 0.2354, Valid Loss: 0.2274
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3500
Epoch 7/10, Batch 20/97, Loss: 0.2542
Epoch 7/10, Batch 30/97, Loss: 0.2302
Epoch 7/10, Batch 40/97, Loss: 0.1200
Epoch 7/10, Batch 50/97, Loss: 0.2883
Epoch 7/10, Batch 60/97, Loss: 0.3177
Epoch 7/10, Batch 70/97, Loss: 0.2335
Epoch 7/10, Batch 80/97, Loss: 0.1019
Epoch 7/10, Batch 90/97, Loss: 0.1954
Epoch 7/10, Train Loss: 0.2421, Valid Loss: 0.2212
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1544
Epoch 8/10, Batch 20/97, Loss: 0.1584
Epoch 8/10, Batch 30/97, Loss: 0.1229
Epoch 8/10, Batch 40/97, Loss: 0.1676
Epoch 8/10, Batch 50/97, Loss: 0.2214
Epoch 8/10, Batch 60/97, Loss: 0.1326
Epoch 8/10, Batch 70/97, Loss: 0.4412
Epoch 8/10, Batch 80/97, Loss: 0.1238
Epoch 8/10, Batch 90/97, Loss: 0.2394
Epoch 8/10, Train Loss: 0.2186, Valid Loss: 0.2206
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0525
Epoch 9/10, Batch 20/97, Loss: 0.1292
Epoch 9/10, Batch 30/97, Loss: 0.2907
Epoch 9/10, Batch 40/97, Loss: 0.1535
Epoch 9/10, Batch 50/97, Loss: 0.3531
Epoch 9/10, Batch 60/97, Loss: 0.2889
Epoch 9/10, Batch 70/97, Loss: 0.2129
Epoch 9/10, Batch 80/97, Loss: 0.1787
Epoch 9/10, Batch 90/97, Loss: 0.1763
Epoch 9/10, Train Loss: 0.2071, Valid Loss: 0.2108
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2328
Epoch 10/10, Batch 20/97, Loss: 0.1161
Epoch 10/10, Batch 30/97, Loss: 0.2289
Epoch 10/10, Batch 40/97, Loss: 0.2269
Epoch 10/10, Batch 50/97, Loss: 0.4382
Epoch 10/10, Batch 60/97, Loss: 0.0967
Epoch 10/10, Batch 70/97, Loss: 0.2199
Epoch 10/10, Batch 80/97, Loss: 0.1820
Epoch 10/10, Batch 90/97, Loss: 0.0972
Epoch 10/10, Train Loss: 0.1946, Valid Loss: 0.2039
Model saved!
Accuracy: 0.9182
Precision: 0.9166
Recall: 0.9182
F1-score: 0.9171
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4329
Epoch 1/10, Batch 20/97, Loss: 0.9933
Epoch 1/10, Batch 30/97, Loss: 0.8504
Epoch 1/10, Batch 40/97, Loss: 0.7452
Epoch 1/10, Batch 50/97, Loss: 0.7844
Epoch 1/10, Batch 60/97, Loss: 0.6556
Epoch 1/10, Batch 70/97, Loss: 0.5682
Epoch 1/10, Batch 80/97, Loss: 0.5998
Epoch 1/10, Batch 90/97, Loss: 0.5450
Epoch 1/10, Train Loss: 0.7894, Valid Loss: 0.4432
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4153
Epoch 2/10, Batch 20/97, Loss: 0.7442
Epoch 2/10, Batch 30/97, Loss: 0.4825
Epoch 2/10, Batch 40/97, Loss: 0.3840
Epoch 2/10, Batch 50/97, Loss: 0.6680
Epoch 2/10, Batch 60/97, Loss: 0.4596
Epoch 2/10, Batch 70/97, Loss: 0.2749
Epoch 2/10, Batch 80/97, Loss: 0.2981
Epoch 2/10, Batch 90/97, Loss: 0.3187
Epoch 2/10, Train Loss: 0.4093, Valid Loss: 0.3462
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3235
Epoch 3/10, Batch 20/97, Loss: 0.3008
Epoch 3/10, Batch 30/97, Loss: 0.4171
Epoch 3/10, Batch 40/97, Loss: 0.2950
Epoch 3/10, Batch 50/97, Loss: 0.4866
Epoch 3/10, Batch 60/97, Loss: 0.1912
Epoch 3/10, Batch 70/97, Loss: 0.2577
Epoch 3/10, Batch 80/97, Loss: 0.3935
Epoch 3/10, Batch 90/97, Loss: 0.1718
Epoch 3/10, Train Loss: 0.3394, Valid Loss: 0.3188
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3230
Epoch 4/10, Batch 20/97, Loss: 0.3411
Epoch 4/10, Batch 30/97, Loss: 0.3211
Epoch 4/10, Batch 40/97, Loss: 0.2576
Epoch 4/10, Batch 50/97, Loss: 0.2503
Epoch 4/10, Batch 60/97, Loss: 0.1625
Epoch 4/10, Batch 70/97, Loss: 0.2246
Epoch 4/10, Batch 80/97, Loss: 0.2221
Epoch 4/10, Batch 90/97, Loss: 0.2846
Epoch 4/10, Train Loss: 0.2994, Valid Loss: 0.2961
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3302
Epoch 5/10, Batch 20/97, Loss: 0.1620
Epoch 5/10, Batch 30/97, Loss: 0.0827
Epoch 5/10, Batch 40/97, Loss: 0.1909
Epoch 5/10, Batch 50/97, Loss: 0.2748
Epoch 5/10, Batch 60/97, Loss: 0.3180
Epoch 5/10, Batch 70/97, Loss: 0.2006
Epoch 5/10, Batch 80/97, Loss: 0.3312
Epoch 5/10, Batch 90/97, Loss: 0.4212
Epoch 5/10, Train Loss: 0.2740, Valid Loss: 0.2863
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3241
Epoch 6/10, Batch 20/97, Loss: 0.2251
Epoch 6/10, Batch 30/97, Loss: 0.2353
Epoch 6/10, Batch 40/97, Loss: 0.3973
Epoch 6/10, Batch 50/97, Loss: 0.2028
Epoch 6/10, Batch 60/97, Loss: 0.2935
Epoch 6/10, Batch 70/97, Loss: 0.2873
Epoch 6/10, Batch 80/97, Loss: 0.1601
Epoch 6/10, Batch 90/97, Loss: 0.2408
Epoch 6/10, Train Loss: 0.2521, Valid Loss: 0.2810
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3560
Epoch 7/10, Batch 20/97, Loss: 0.1206
Epoch 7/10, Batch 30/97, Loss: 0.2444
Epoch 7/10, Batch 40/97, Loss: 0.1346
Epoch 7/10, Batch 50/97, Loss: 0.2265
Epoch 7/10, Batch 60/97, Loss: 0.3732
Epoch 7/10, Batch 70/97, Loss: 0.1774
Epoch 7/10, Batch 80/97, Loss: 0.3256
Epoch 7/10, Batch 90/97, Loss: 0.2694
Epoch 7/10, Train Loss: 0.2570, Valid Loss: 0.2749
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2238
Epoch 8/10, Batch 20/97, Loss: 0.2583
Epoch 8/10, Batch 30/97, Loss: 0.1752
Epoch 8/10, Batch 40/97, Loss: 0.2254
Epoch 8/10, Batch 50/97, Loss: 0.1412
Epoch 8/10, Batch 60/97, Loss: 0.2159
Epoch 8/10, Batch 70/97, Loss: 0.4276
Epoch 8/10, Batch 80/97, Loss: 0.2194
Epoch 8/10, Batch 90/97, Loss: 0.0950
Epoch 8/10, Train Loss: 0.2322, Valid Loss: 0.2609
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0910
Epoch 9/10, Batch 20/97, Loss: 0.1153
Epoch 9/10, Batch 30/97, Loss: 0.5264
Epoch 9/10, Batch 40/97, Loss: 0.1973
Epoch 9/10, Batch 50/97, Loss: 0.2207
Epoch 9/10, Batch 60/97, Loss: 0.1662
Epoch 9/10, Batch 70/97, Loss: 0.2296
Epoch 9/10, Batch 80/97, Loss: 0.1585
Epoch 9/10, Batch 90/97, Loss: 0.3503
Epoch 9/10, Train Loss: 0.2095, Valid Loss: 0.2648
Epoch 10/10, Batch 10/97, Loss: 0.2299
Epoch 10/10, Batch 20/97, Loss: 0.1180
Epoch 10/10, Batch 30/97, Loss: 0.2105
Epoch 10/10, Batch 40/97, Loss: 0.5445
Epoch 10/10, Batch 50/97, Loss: 0.2588
Epoch 10/10, Batch 60/97, Loss: 0.1444
Epoch 10/10, Batch 70/97, Loss: 0.2292
Epoch 10/10, Batch 80/97, Loss: 0.1391
Epoch 10/10, Batch 90/97, Loss: 0.1369
Epoch 10/10, Train Loss: 0.2013, Valid Loss: 0.2649
Accuracy: 0.9124
Precision: 0.9094
Recall: 0.9124
F1-score: 0.9091
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4059
Epoch 1/10, Batch 20/97, Loss: 1.0442
Epoch 1/10, Batch 30/97, Loss: 0.9068
Epoch 1/10, Batch 40/97, Loss: 0.6417
Epoch 1/10, Batch 50/97, Loss: 0.5336
Epoch 1/10, Batch 60/97, Loss: 0.6116
Epoch 1/10, Batch 70/97, Loss: 0.5660
Epoch 1/10, Batch 80/97, Loss: 0.4850
Epoch 1/10, Batch 90/97, Loss: 0.4597
Epoch 1/10, Train Loss: 0.7740, Valid Loss: 0.4571
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4073
Epoch 2/10, Batch 20/97, Loss: 0.4724
Epoch 2/10, Batch 30/97, Loss: 0.4289
Epoch 2/10, Batch 40/97, Loss: 0.3622
Epoch 2/10, Batch 50/97, Loss: 0.5841
Epoch 2/10, Batch 60/97, Loss: 0.2821
Epoch 2/10, Batch 70/97, Loss: 0.3598
Epoch 2/10, Batch 80/97, Loss: 0.2851
Epoch 2/10, Batch 90/97, Loss: 0.2904
Epoch 2/10, Train Loss: 0.3996, Valid Loss: 0.3666
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2456
Epoch 3/10, Batch 20/97, Loss: 0.2820
Epoch 3/10, Batch 30/97, Loss: 0.2935
Epoch 3/10, Batch 40/97, Loss: 0.2804
Epoch 3/10, Batch 50/97, Loss: 0.3394
Epoch 3/10, Batch 60/97, Loss: 0.3517
Epoch 3/10, Batch 70/97, Loss: 0.4048
Epoch 3/10, Batch 80/97, Loss: 0.3503
Epoch 3/10, Batch 90/97, Loss: 0.3174
Epoch 3/10, Train Loss: 0.3309, Valid Loss: 0.3314
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3099
Epoch 4/10, Batch 20/97, Loss: 0.2131
Epoch 4/10, Batch 30/97, Loss: 0.4545
Epoch 4/10, Batch 40/97, Loss: 0.2154
Epoch 4/10, Batch 50/97, Loss: 0.2345
Epoch 4/10, Batch 60/97, Loss: 0.1014
Epoch 4/10, Batch 70/97, Loss: 0.3161
Epoch 4/10, Batch 80/97, Loss: 0.3368
Epoch 4/10, Batch 90/97, Loss: 0.3505
Epoch 4/10, Train Loss: 0.2879, Valid Loss: 0.3119
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2482
Epoch 5/10, Batch 20/97, Loss: 0.1535
Epoch 5/10, Batch 30/97, Loss: 0.2056
Epoch 5/10, Batch 40/97, Loss: 0.2582
Epoch 5/10, Batch 50/97, Loss: 0.2183
Epoch 5/10, Batch 60/97, Loss: 0.1799
Epoch 5/10, Batch 70/97, Loss: 0.1752
Epoch 5/10, Batch 80/97, Loss: 0.2869
Epoch 5/10, Batch 90/97, Loss: 0.3149
Epoch 5/10, Train Loss: 0.2605, Valid Loss: 0.3005
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1621
Epoch 6/10, Batch 20/97, Loss: 0.2472
Epoch 6/10, Batch 30/97, Loss: 0.0925
Epoch 6/10, Batch 40/97, Loss: 0.2762
Epoch 6/10, Batch 50/97, Loss: 0.2147
Epoch 6/10, Batch 60/97, Loss: 0.2797
Epoch 6/10, Batch 70/97, Loss: 0.5630
Epoch 6/10, Batch 80/97, Loss: 0.0942
Epoch 6/10, Batch 90/97, Loss: 0.3363
Epoch 6/10, Train Loss: 0.2539, Valid Loss: 0.2914
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4851
Epoch 7/10, Batch 20/97, Loss: 0.1574
Epoch 7/10, Batch 30/97, Loss: 0.2025
Epoch 7/10, Batch 40/97, Loss: 0.1932
Epoch 7/10, Batch 50/97, Loss: 0.2880
Epoch 7/10, Batch 60/97, Loss: 0.1931
Epoch 7/10, Batch 70/97, Loss: 0.2603
Epoch 7/10, Batch 80/97, Loss: 0.4211
Epoch 7/10, Batch 90/97, Loss: 0.3036
Epoch 7/10, Train Loss: 0.2469, Valid Loss: 0.2896
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1066
Epoch 8/10, Batch 20/97, Loss: 0.1391
Epoch 8/10, Batch 30/97, Loss: 0.2153
Epoch 8/10, Batch 40/97, Loss: 0.2995
Epoch 8/10, Batch 50/97, Loss: 0.3505
Epoch 8/10, Batch 60/97, Loss: 0.2069
Epoch 8/10, Batch 70/97, Loss: 0.1395
Epoch 8/10, Batch 80/97, Loss: 0.2604
Epoch 8/10, Batch 90/97, Loss: 0.1830
Epoch 8/10, Train Loss: 0.2213, Valid Loss: 0.2831
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2001
Epoch 9/10, Batch 20/97, Loss: 0.1313
Epoch 9/10, Batch 30/97, Loss: 0.3263
Epoch 9/10, Batch 40/97, Loss: 0.1596
Epoch 9/10, Batch 50/97, Loss: 0.2500
Epoch 9/10, Batch 60/97, Loss: 0.1721
Epoch 9/10, Batch 70/97, Loss: 0.1668
Epoch 9/10, Batch 80/97, Loss: 0.1802
Epoch 9/10, Batch 90/97, Loss: 0.2832
Epoch 9/10, Train Loss: 0.2099, Valid Loss: 0.2790
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1367
Epoch 10/10, Batch 20/97, Loss: 0.0624
Epoch 10/10, Batch 30/97, Loss: 0.2007
Epoch 10/10, Batch 40/97, Loss: 0.2218
Epoch 10/10, Batch 50/97, Loss: 0.3225
Epoch 10/10, Batch 60/97, Loss: 0.1659
Epoch 10/10, Batch 70/97, Loss: 0.1568
Epoch 10/10, Batch 80/97, Loss: 0.1168
Epoch 10/10, Batch 90/97, Loss: 0.1158
Epoch 10/10, Train Loss: 0.2010, Valid Loss: 0.2773
Model saved!
Accuracy: 0.9217
Precision: 0.9210
Recall: 0.9217
F1-score: 0.9212
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4740
Epoch 1/10, Batch 20/97, Loss: 0.9254
Epoch 1/10, Batch 30/97, Loss: 0.9449
Epoch 1/10, Batch 40/97, Loss: 0.7639
Epoch 1/10, Batch 50/97, Loss: 0.5439
Epoch 1/10, Batch 60/97, Loss: 0.5979
Epoch 1/10, Batch 70/97, Loss: 0.5246
Epoch 1/10, Batch 80/97, Loss: 0.5026
Epoch 1/10, Batch 90/97, Loss: 0.4291
Epoch 1/10, Train Loss: 0.7887, Valid Loss: 0.3983
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5441
Epoch 2/10, Batch 20/97, Loss: 0.6036
Epoch 2/10, Batch 30/97, Loss: 0.3624
Epoch 2/10, Batch 40/97, Loss: 0.2021
Epoch 2/10, Batch 50/97, Loss: 0.6851
Epoch 2/10, Batch 60/97, Loss: 0.3918
Epoch 2/10, Batch 70/97, Loss: 0.2966
Epoch 2/10, Batch 80/97, Loss: 0.2128
Epoch 2/10, Batch 90/97, Loss: 0.3985
Epoch 2/10, Train Loss: 0.4015, Valid Loss: 0.2934
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2536
Epoch 3/10, Batch 20/97, Loss: 0.2984
Epoch 3/10, Batch 30/97, Loss: 0.2655
Epoch 3/10, Batch 40/97, Loss: 0.3524
Epoch 3/10, Batch 50/97, Loss: 0.3070
Epoch 3/10, Batch 60/97, Loss: 0.2369
Epoch 3/10, Batch 70/97, Loss: 0.2031
Epoch 3/10, Batch 80/97, Loss: 0.1927
Epoch 3/10, Batch 90/97, Loss: 0.2500
Epoch 3/10, Train Loss: 0.3249, Valid Loss: 0.2510
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2408
Epoch 4/10, Batch 20/97, Loss: 0.1975
Epoch 4/10, Batch 30/97, Loss: 0.4014
Epoch 4/10, Batch 40/97, Loss: 0.2181
Epoch 4/10, Batch 50/97, Loss: 0.1376
Epoch 4/10, Batch 60/97, Loss: 0.2448
Epoch 4/10, Batch 70/97, Loss: 0.2135
Epoch 4/10, Batch 80/97, Loss: 0.2435
Epoch 4/10, Batch 90/97, Loss: 0.2073
Epoch 4/10, Train Loss: 0.2869, Valid Loss: 0.2277
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2407
Epoch 5/10, Batch 20/97, Loss: 0.1608
Epoch 5/10, Batch 30/97, Loss: 0.1699
Epoch 5/10, Batch 40/97, Loss: 0.1663
Epoch 5/10, Batch 50/97, Loss: 0.4082
Epoch 5/10, Batch 60/97, Loss: 0.3102
Epoch 5/10, Batch 70/97, Loss: 0.2399
Epoch 5/10, Batch 80/97, Loss: 0.4534
Epoch 5/10, Batch 90/97, Loss: 0.3995
Epoch 5/10, Train Loss: 0.2713, Valid Loss: 0.2167
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2553
Epoch 6/10, Batch 20/97, Loss: 0.4522
Epoch 6/10, Batch 30/97, Loss: 0.1667
Epoch 6/10, Batch 40/97, Loss: 0.1668
Epoch 6/10, Batch 50/97, Loss: 0.3012
Epoch 6/10, Batch 60/97, Loss: 0.4458
Epoch 6/10, Batch 70/97, Loss: 0.1958
Epoch 6/10, Batch 80/97, Loss: 0.1629
Epoch 6/10, Batch 90/97, Loss: 0.1661
Epoch 6/10, Train Loss: 0.2433, Valid Loss: 0.2099
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2738
Epoch 7/10, Batch 20/97, Loss: 0.1071
Epoch 7/10, Batch 30/97, Loss: 0.1459
Epoch 7/10, Batch 40/97, Loss: 0.1414
Epoch 7/10, Batch 50/97, Loss: 0.3719
Epoch 7/10, Batch 60/97, Loss: 0.1797
Epoch 7/10, Batch 70/97, Loss: 0.1505
Epoch 7/10, Batch 80/97, Loss: 0.2459
Epoch 7/10, Batch 90/97, Loss: 0.3401
Epoch 7/10, Train Loss: 0.2454, Valid Loss: 0.2005
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2299
Epoch 8/10, Batch 20/97, Loss: 0.2052
Epoch 8/10, Batch 30/97, Loss: 0.2347
Epoch 8/10, Batch 40/97, Loss: 0.2050
Epoch 8/10, Batch 50/97, Loss: 0.1476
Epoch 8/10, Batch 60/97, Loss: 0.1297
Epoch 8/10, Batch 70/97, Loss: 0.2728
Epoch 8/10, Batch 80/97, Loss: 0.1451
Epoch 8/10, Batch 90/97, Loss: 0.1531
Epoch 8/10, Train Loss: 0.2202, Valid Loss: 0.1946
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1190
Epoch 9/10, Batch 20/97, Loss: 0.1029
Epoch 9/10, Batch 30/97, Loss: 0.5254
Epoch 9/10, Batch 40/97, Loss: 0.2427
Epoch 9/10, Batch 50/97, Loss: 0.3966
Epoch 9/10, Batch 60/97, Loss: 0.2012
Epoch 9/10, Batch 70/97, Loss: 0.1138
Epoch 9/10, Batch 80/97, Loss: 0.1809
Epoch 9/10, Batch 90/97, Loss: 0.2756
Epoch 9/10, Train Loss: 0.2210, Valid Loss: 0.1963
Epoch 10/10, Batch 10/97, Loss: 0.2662
Epoch 10/10, Batch 20/97, Loss: 0.1266
Epoch 10/10, Batch 30/97, Loss: 0.1753
Epoch 10/10, Batch 40/97, Loss: 0.2924
Epoch 10/10, Batch 50/97, Loss: 0.2696
Epoch 10/10, Batch 60/97, Loss: 0.1738
Epoch 10/10, Batch 70/97, Loss: 0.1151
Epoch 10/10, Batch 80/97, Loss: 0.1892
Epoch 10/10, Batch 90/97, Loss: 0.2142
Epoch 10/10, Train Loss: 0.2029, Valid Loss: 0.1862
Model saved!
Accuracy: 0.9124
Precision: 0.9106
Recall: 0.9124
F1-score: 0.9112
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4151
Epoch 1/10, Batch 20/97, Loss: 0.9619
Epoch 1/10, Batch 30/97, Loss: 0.8643
Epoch 1/10, Batch 40/97, Loss: 0.6641
Epoch 1/10, Batch 50/97, Loss: 0.5875
Epoch 1/10, Batch 60/97, Loss: 0.5565
Epoch 1/10, Batch 70/97, Loss: 0.3949
Epoch 1/10, Batch 80/97, Loss: 0.5462
Epoch 1/10, Batch 90/97, Loss: 0.6072
Epoch 1/10, Train Loss: 0.7760, Valid Loss: 0.4211
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3557
Epoch 2/10, Batch 20/97, Loss: 0.4265
Epoch 2/10, Batch 30/97, Loss: 0.2950
Epoch 2/10, Batch 40/97, Loss: 0.3988
Epoch 2/10, Batch 50/97, Loss: 0.5818
Epoch 2/10, Batch 60/97, Loss: 0.2219
Epoch 2/10, Batch 70/97, Loss: 0.4536
Epoch 2/10, Batch 80/97, Loss: 0.2938
Epoch 2/10, Batch 90/97, Loss: 0.3261
Epoch 2/10, Train Loss: 0.3934, Valid Loss: 0.3138
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3220
Epoch 3/10, Batch 20/97, Loss: 0.3423
Epoch 3/10, Batch 30/97, Loss: 0.2248
Epoch 3/10, Batch 40/97, Loss: 0.3187
Epoch 3/10, Batch 50/97, Loss: 0.3741
Epoch 3/10, Batch 60/97, Loss: 0.2353
Epoch 3/10, Batch 70/97, Loss: 0.3285
Epoch 3/10, Batch 80/97, Loss: 0.3425
Epoch 3/10, Batch 90/97, Loss: 0.3496
Epoch 3/10, Train Loss: 0.3242, Valid Loss: 0.2754
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3467
Epoch 4/10, Batch 20/97, Loss: 0.2401
Epoch 4/10, Batch 30/97, Loss: 0.3513
Epoch 4/10, Batch 40/97, Loss: 0.2831
Epoch 4/10, Batch 50/97, Loss: 0.2485
Epoch 4/10, Batch 60/97, Loss: 0.0913
Epoch 4/10, Batch 70/97, Loss: 0.2748
Epoch 4/10, Batch 80/97, Loss: 0.3335
Epoch 4/10, Batch 90/97, Loss: 0.2337
Epoch 4/10, Train Loss: 0.2828, Valid Loss: 0.2539
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2438
Epoch 5/10, Batch 20/97, Loss: 0.2659
Epoch 5/10, Batch 30/97, Loss: 0.1374
Epoch 5/10, Batch 40/97, Loss: 0.1530
Epoch 5/10, Batch 50/97, Loss: 0.1855
Epoch 5/10, Batch 60/97, Loss: 0.2548
Epoch 5/10, Batch 70/97, Loss: 0.3833
Epoch 5/10, Batch 80/97, Loss: 0.2753
Epoch 5/10, Batch 90/97, Loss: 0.2012
Epoch 5/10, Train Loss: 0.2558, Valid Loss: 0.2404
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2485
Epoch 6/10, Batch 20/97, Loss: 0.2359
Epoch 6/10, Batch 30/97, Loss: 0.2658
Epoch 6/10, Batch 40/97, Loss: 0.2834
Epoch 6/10, Batch 50/97, Loss: 0.2247
Epoch 6/10, Batch 60/97, Loss: 0.2650
Epoch 6/10, Batch 70/97, Loss: 0.1241
Epoch 6/10, Batch 80/97, Loss: 0.2571
Epoch 6/10, Batch 90/97, Loss: 0.2179
Epoch 6/10, Train Loss: 0.2399, Valid Loss: 0.2339
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1918
Epoch 7/10, Batch 20/97, Loss: 0.1710
Epoch 7/10, Batch 30/97, Loss: 0.2405
Epoch 7/10, Batch 40/97, Loss: 0.1419
Epoch 7/10, Batch 50/97, Loss: 0.3655
Epoch 7/10, Batch 60/97, Loss: 0.2149
Epoch 7/10, Batch 70/97, Loss: 0.3504
Epoch 7/10, Batch 80/97, Loss: 0.2967
Epoch 7/10, Batch 90/97, Loss: 0.2508
Epoch 7/10, Train Loss: 0.2447, Valid Loss: 0.2287
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1559
Epoch 8/10, Batch 20/97, Loss: 0.1108
Epoch 8/10, Batch 30/97, Loss: 0.0679
Epoch 8/10, Batch 40/97, Loss: 0.1561
Epoch 8/10, Batch 50/97, Loss: 0.2118
Epoch 8/10, Batch 60/97, Loss: 0.2286
Epoch 8/10, Batch 70/97, Loss: 0.3352
Epoch 8/10, Batch 80/97, Loss: 0.2226
Epoch 8/10, Batch 90/97, Loss: 0.3716
Epoch 8/10, Train Loss: 0.2229, Valid Loss: 0.2242
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0508
Epoch 9/10, Batch 20/97, Loss: 0.0794
Epoch 9/10, Batch 30/97, Loss: 0.3551
Epoch 9/10, Batch 40/97, Loss: 0.1958
Epoch 9/10, Batch 50/97, Loss: 0.2138
Epoch 9/10, Batch 60/97, Loss: 0.2490
Epoch 9/10, Batch 70/97, Loss: 0.1613
Epoch 9/10, Batch 80/97, Loss: 0.1504
Epoch 9/10, Batch 90/97, Loss: 0.2797
Epoch 9/10, Train Loss: 0.2125, Valid Loss: 0.2217
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2827
Epoch 10/10, Batch 20/97, Loss: 0.1654
Epoch 10/10, Batch 30/97, Loss: 0.1469
Epoch 10/10, Batch 40/97, Loss: 0.1886
Epoch 10/10, Batch 50/97, Loss: 0.2396
Epoch 10/10, Batch 60/97, Loss: 0.0741
Epoch 10/10, Batch 70/97, Loss: 0.1230
Epoch 10/10, Batch 80/97, Loss: 0.2376
Epoch 10/10, Batch 90/97, Loss: 0.2013
Epoch 10/10, Train Loss: 0.1995, Valid Loss: 0.2127
Model saved!
Accuracy: 0.9136
Precision: 0.9112
Recall: 0.9136
F1-score: 0.9119
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5186
Epoch 1/10, Batch 20/97, Loss: 0.9868
Epoch 1/10, Batch 30/97, Loss: 0.9098
Epoch 1/10, Batch 40/97, Loss: 0.8281
Epoch 1/10, Batch 50/97, Loss: 0.5600
Epoch 1/10, Batch 60/97, Loss: 0.6530
Epoch 1/10, Batch 70/97, Loss: 0.5449
Epoch 1/10, Batch 80/97, Loss: 0.4948
Epoch 1/10, Batch 90/97, Loss: 0.5751
Epoch 1/10, Train Loss: 0.7836, Valid Loss: 0.4421
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5083
Epoch 2/10, Batch 20/97, Loss: 0.5065
Epoch 2/10, Batch 30/97, Loss: 0.3695
Epoch 2/10, Batch 40/97, Loss: 0.4062
Epoch 2/10, Batch 50/97, Loss: 0.4982
Epoch 2/10, Batch 60/97, Loss: 0.4243
Epoch 2/10, Batch 70/97, Loss: 0.4079
Epoch 2/10, Batch 80/97, Loss: 0.2948
Epoch 2/10, Batch 90/97, Loss: 0.2904
Epoch 2/10, Train Loss: 0.4059, Valid Loss: 0.3280
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2988
Epoch 3/10, Batch 20/97, Loss: 0.2981
Epoch 3/10, Batch 30/97, Loss: 0.4566
Epoch 3/10, Batch 40/97, Loss: 0.3039
Epoch 3/10, Batch 50/97, Loss: 0.4186
Epoch 3/10, Batch 60/97, Loss: 0.1605
Epoch 3/10, Batch 70/97, Loss: 0.3471
Epoch 3/10, Batch 80/97, Loss: 0.2498
Epoch 3/10, Batch 90/97, Loss: 0.3150
Epoch 3/10, Train Loss: 0.3352, Valid Loss: 0.2924
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3005
Epoch 4/10, Batch 20/97, Loss: 0.2603
Epoch 4/10, Batch 30/97, Loss: 0.3530
Epoch 4/10, Batch 40/97, Loss: 0.2403
Epoch 4/10, Batch 50/97, Loss: 0.1780
Epoch 4/10, Batch 60/97, Loss: 0.2854
Epoch 4/10, Batch 70/97, Loss: 0.3176
Epoch 4/10, Batch 80/97, Loss: 0.2695
Epoch 4/10, Batch 90/97, Loss: 0.2940
Epoch 4/10, Train Loss: 0.2950, Valid Loss: 0.2696
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1682
Epoch 5/10, Batch 20/97, Loss: 0.1632
Epoch 5/10, Batch 30/97, Loss: 0.2538
Epoch 5/10, Batch 40/97, Loss: 0.2235
Epoch 5/10, Batch 50/97, Loss: 0.2943
Epoch 5/10, Batch 60/97, Loss: 0.3113
Epoch 5/10, Batch 70/97, Loss: 0.3035
Epoch 5/10, Batch 80/97, Loss: 0.2827
Epoch 5/10, Batch 90/97, Loss: 0.2464
Epoch 5/10, Train Loss: 0.2591, Valid Loss: 0.2593
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3766
Epoch 6/10, Batch 20/97, Loss: 0.3501
Epoch 6/10, Batch 30/97, Loss: 0.2285
Epoch 6/10, Batch 40/97, Loss: 0.3685
Epoch 6/10, Batch 50/97, Loss: 0.3047
Epoch 6/10, Batch 60/97, Loss: 0.3213
Epoch 6/10, Batch 70/97, Loss: 0.2077
Epoch 6/10, Batch 80/97, Loss: 0.2989
Epoch 6/10, Batch 90/97, Loss: 0.2193
Epoch 6/10, Train Loss: 0.2524, Valid Loss: 0.2437
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2794
Epoch 7/10, Batch 20/97, Loss: 0.1771
Epoch 7/10, Batch 30/97, Loss: 0.1232
Epoch 7/10, Batch 40/97, Loss: 0.2049
Epoch 7/10, Batch 50/97, Loss: 0.1982
Epoch 7/10, Batch 60/97, Loss: 0.0952
Epoch 7/10, Batch 70/97, Loss: 0.2287
Epoch 7/10, Batch 80/97, Loss: 0.1744
Epoch 7/10, Batch 90/97, Loss: 0.2269
Epoch 7/10, Train Loss: 0.2461, Valid Loss: 0.2306
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1271
Epoch 8/10, Batch 20/97, Loss: 0.2225
Epoch 8/10, Batch 30/97, Loss: 0.1818
Epoch 8/10, Batch 40/97, Loss: 0.2283
Epoch 8/10, Batch 50/97, Loss: 0.1605
Epoch 8/10, Batch 60/97, Loss: 0.1301
Epoch 8/10, Batch 70/97, Loss: 0.1336
Epoch 8/10, Batch 80/97, Loss: 0.1790
Epoch 8/10, Batch 90/97, Loss: 0.1214
Epoch 8/10, Train Loss: 0.2317, Valid Loss: 0.2315
Epoch 9/10, Batch 10/97, Loss: 0.1419
Epoch 9/10, Batch 20/97, Loss: 0.1864
Epoch 9/10, Batch 30/97, Loss: 0.2724
Epoch 9/10, Batch 40/97, Loss: 0.1374
Epoch 9/10, Batch 50/97, Loss: 0.2236
Epoch 9/10, Batch 60/97, Loss: 0.1617
Epoch 9/10, Batch 70/97, Loss: 0.1454
Epoch 9/10, Batch 80/97, Loss: 0.2191
Epoch 9/10, Batch 90/97, Loss: 0.2049
Epoch 9/10, Train Loss: 0.2196, Valid Loss: 0.2263
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2644
Epoch 10/10, Batch 20/97, Loss: 0.1041
Epoch 10/10, Batch 30/97, Loss: 0.2189
Epoch 10/10, Batch 40/97, Loss: 0.4143
Epoch 10/10, Batch 50/97, Loss: 0.3250
Epoch 10/10, Batch 60/97, Loss: 0.2090
Epoch 10/10, Batch 70/97, Loss: 0.1746
Epoch 10/10, Batch 80/97, Loss: 0.1838
Epoch 10/10, Batch 90/97, Loss: 0.1400
Epoch 10/10, Train Loss: 0.2078, Valid Loss: 0.2206
Model saved!
Accuracy: 0.9147
Precision: 0.9123
Recall: 0.9147
F1-score: 0.9128
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4777
Epoch 1/10, Batch 20/97, Loss: 0.9578
Epoch 1/10, Batch 30/97, Loss: 0.9459
Epoch 1/10, Batch 40/97, Loss: 0.6771
Epoch 1/10, Batch 50/97, Loss: 0.6186
Epoch 1/10, Batch 60/97, Loss: 0.6041
Epoch 1/10, Batch 70/97, Loss: 0.4726
Epoch 1/10, Batch 80/97, Loss: 0.5444
Epoch 1/10, Batch 90/97, Loss: 0.4387
Epoch 1/10, Train Loss: 0.7707, Valid Loss: 0.4467
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4134
Epoch 2/10, Batch 20/97, Loss: 0.3357
Epoch 2/10, Batch 30/97, Loss: 0.4136
Epoch 2/10, Batch 40/97, Loss: 0.5131
Epoch 2/10, Batch 50/97, Loss: 0.4742
Epoch 2/10, Batch 60/97, Loss: 0.2838
Epoch 2/10, Batch 70/97, Loss: 0.3188
Epoch 2/10, Batch 80/97, Loss: 0.4168
Epoch 2/10, Batch 90/97, Loss: 0.4015
Epoch 2/10, Train Loss: 0.3866, Valid Loss: 0.3448
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3883
Epoch 3/10, Batch 20/97, Loss: 0.2592
Epoch 3/10, Batch 30/97, Loss: 0.2316
Epoch 3/10, Batch 40/97, Loss: 0.2912
Epoch 3/10, Batch 50/97, Loss: 0.2968
Epoch 3/10, Batch 60/97, Loss: 0.3481
Epoch 3/10, Batch 70/97, Loss: 0.2241
Epoch 3/10, Batch 80/97, Loss: 0.3327
Epoch 3/10, Batch 90/97, Loss: 0.1623
Epoch 3/10, Train Loss: 0.3173, Valid Loss: 0.2991
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1863
Epoch 4/10, Batch 20/97, Loss: 0.1171
Epoch 4/10, Batch 30/97, Loss: 0.2998
Epoch 4/10, Batch 40/97, Loss: 0.2838
Epoch 4/10, Batch 50/97, Loss: 0.2635
Epoch 4/10, Batch 60/97, Loss: 0.3317
Epoch 4/10, Batch 70/97, Loss: 0.2402
Epoch 4/10, Batch 80/97, Loss: 0.2304
Epoch 4/10, Batch 90/97, Loss: 0.1839
Epoch 4/10, Train Loss: 0.2771, Valid Loss: 0.2850
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3242
Epoch 5/10, Batch 20/97, Loss: 0.1887
Epoch 5/10, Batch 30/97, Loss: 0.1440
Epoch 5/10, Batch 40/97, Loss: 0.2116
Epoch 5/10, Batch 50/97, Loss: 0.1894
Epoch 5/10, Batch 60/97, Loss: 0.2329
Epoch 5/10, Batch 70/97, Loss: 0.2093
Epoch 5/10, Batch 80/97, Loss: 0.1801
Epoch 5/10, Batch 90/97, Loss: 0.2586
Epoch 5/10, Train Loss: 0.2455, Valid Loss: 0.2662
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2743
Epoch 6/10, Batch 20/97, Loss: 0.2495
Epoch 6/10, Batch 30/97, Loss: 0.1201
Epoch 6/10, Batch 40/97, Loss: 0.2731
Epoch 6/10, Batch 50/97, Loss: 0.1764
Epoch 6/10, Batch 60/97, Loss: 0.2390
Epoch 6/10, Batch 70/97, Loss: 0.2673
Epoch 6/10, Batch 80/97, Loss: 0.1295
Epoch 6/10, Batch 90/97, Loss: 0.1449
Epoch 6/10, Train Loss: 0.2338, Valid Loss: 0.2655
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2824
Epoch 7/10, Batch 20/97, Loss: 0.1438
Epoch 7/10, Batch 30/97, Loss: 0.1585
Epoch 7/10, Batch 40/97, Loss: 0.2539
Epoch 7/10, Batch 50/97, Loss: 0.2772
Epoch 7/10, Batch 60/97, Loss: 0.3121
Epoch 7/10, Batch 70/97, Loss: 0.0926
Epoch 7/10, Batch 80/97, Loss: 0.1734
Epoch 7/10, Batch 90/97, Loss: 0.2083
Epoch 7/10, Train Loss: 0.2343, Valid Loss: 0.2553
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2539
Epoch 8/10, Batch 20/97, Loss: 0.1936
Epoch 8/10, Batch 30/97, Loss: 0.2144
Epoch 8/10, Batch 40/97, Loss: 0.1606
Epoch 8/10, Batch 50/97, Loss: 0.2735
Epoch 8/10, Batch 60/97, Loss: 0.1627
Epoch 8/10, Batch 70/97, Loss: 0.2424
Epoch 8/10, Batch 80/97, Loss: 0.1258
Epoch 8/10, Batch 90/97, Loss: 0.1647
Epoch 8/10, Train Loss: 0.2187, Valid Loss: 0.2463
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1018
Epoch 9/10, Batch 20/97, Loss: 0.0630
Epoch 9/10, Batch 30/97, Loss: 0.1740
Epoch 9/10, Batch 40/97, Loss: 0.0976
Epoch 9/10, Batch 50/97, Loss: 0.2300
Epoch 9/10, Batch 60/97, Loss: 0.3180
Epoch 9/10, Batch 70/97, Loss: 0.2166
Epoch 9/10, Batch 80/97, Loss: 0.1370
Epoch 9/10, Batch 90/97, Loss: 0.1833
Epoch 9/10, Train Loss: 0.2037, Valid Loss: 0.2407
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3656
Epoch 10/10, Batch 20/97, Loss: 0.2205
Epoch 10/10, Batch 30/97, Loss: 0.2152
Epoch 10/10, Batch 40/97, Loss: 0.1938
Epoch 10/10, Batch 50/97, Loss: 0.3164
Epoch 10/10, Batch 60/97, Loss: 0.2961
Epoch 10/10, Batch 70/97, Loss: 0.1471
Epoch 10/10, Batch 80/97, Loss: 0.2320
Epoch 10/10, Batch 90/97, Loss: 0.2629
Epoch 10/10, Train Loss: 0.1936, Valid Loss: 0.2380
Model saved!
Accuracy: 0.9147
Precision: 0.9123
Recall: 0.9147
F1-score: 0.9133
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5000
Epoch 1/10, Batch 20/97, Loss: 1.0871
Epoch 1/10, Batch 30/97, Loss: 0.9242
Epoch 1/10, Batch 40/97, Loss: 0.6835
Epoch 1/10, Batch 50/97, Loss: 0.6168
Epoch 1/10, Batch 60/97, Loss: 0.5472
Epoch 1/10, Batch 70/97, Loss: 0.4565
Epoch 1/10, Batch 80/97, Loss: 0.5341
Epoch 1/10, Batch 90/97, Loss: 0.5519
Epoch 1/10, Train Loss: 0.7739, Valid Loss: 0.4318
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3759
Epoch 2/10, Batch 20/97, Loss: 0.4144
Epoch 2/10, Batch 30/97, Loss: 0.5176
Epoch 2/10, Batch 40/97, Loss: 0.4607
Epoch 2/10, Batch 50/97, Loss: 0.7354
Epoch 2/10, Batch 60/97, Loss: 0.2790
Epoch 2/10, Batch 70/97, Loss: 0.3859
Epoch 2/10, Batch 80/97, Loss: 0.2527
Epoch 2/10, Batch 90/97, Loss: 0.2910
Epoch 2/10, Train Loss: 0.3972, Valid Loss: 0.3221
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3293
Epoch 3/10, Batch 20/97, Loss: 0.3267
Epoch 3/10, Batch 30/97, Loss: 0.3033
Epoch 3/10, Batch 40/97, Loss: 0.2119
Epoch 3/10, Batch 50/97, Loss: 0.3137
Epoch 3/10, Batch 60/97, Loss: 0.2558
Epoch 3/10, Batch 70/97, Loss: 0.2272
Epoch 3/10, Batch 80/97, Loss: 0.2058
Epoch 3/10, Batch 90/97, Loss: 0.2734
Epoch 3/10, Train Loss: 0.3233, Valid Loss: 0.2829
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2912
Epoch 4/10, Batch 20/97, Loss: 0.4231
Epoch 4/10, Batch 30/97, Loss: 0.3520
Epoch 4/10, Batch 40/97, Loss: 0.2409
Epoch 4/10, Batch 50/97, Loss: 0.1989
Epoch 4/10, Batch 60/97, Loss: 0.2030
Epoch 4/10, Batch 70/97, Loss: 0.2763
Epoch 4/10, Batch 80/97, Loss: 0.4622
Epoch 4/10, Batch 90/97, Loss: 0.3253
Epoch 4/10, Train Loss: 0.2942, Valid Loss: 0.2691
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2296
Epoch 5/10, Batch 20/97, Loss: 0.2452
Epoch 5/10, Batch 30/97, Loss: 0.1892
Epoch 5/10, Batch 40/97, Loss: 0.1848
Epoch 5/10, Batch 50/97, Loss: 0.1614
Epoch 5/10, Batch 60/97, Loss: 0.2721
Epoch 5/10, Batch 70/97, Loss: 0.3432
Epoch 5/10, Batch 80/97, Loss: 0.2647
Epoch 5/10, Batch 90/97, Loss: 0.4328
Epoch 5/10, Train Loss: 0.2653, Valid Loss: 0.2507
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2528
Epoch 6/10, Batch 20/97, Loss: 0.1905
Epoch 6/10, Batch 30/97, Loss: 0.2542
Epoch 6/10, Batch 40/97, Loss: 0.1964
Epoch 6/10, Batch 50/97, Loss: 0.1137
Epoch 6/10, Batch 60/97, Loss: 0.2537
Epoch 6/10, Batch 70/97, Loss: 0.1817
Epoch 6/10, Batch 80/97, Loss: 0.1423
Epoch 6/10, Batch 90/97, Loss: 0.2042
Epoch 6/10, Train Loss: 0.2411, Valid Loss: 0.2440
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2759
Epoch 7/10, Batch 20/97, Loss: 0.1319
Epoch 7/10, Batch 30/97, Loss: 0.2071
Epoch 7/10, Batch 40/97, Loss: 0.3040
Epoch 7/10, Batch 50/97, Loss: 0.2839
Epoch 7/10, Batch 60/97, Loss: 0.2837
Epoch 7/10, Batch 70/97, Loss: 0.3367
Epoch 7/10, Batch 80/97, Loss: 0.1612
Epoch 7/10, Batch 90/97, Loss: 0.3537
Epoch 7/10, Train Loss: 0.2501, Valid Loss: 0.2383
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1884
Epoch 8/10, Batch 20/97, Loss: 0.2666
Epoch 8/10, Batch 30/97, Loss: 0.1666
Epoch 8/10, Batch 40/97, Loss: 0.1607
Epoch 8/10, Batch 50/97, Loss: 0.2198
Epoch 8/10, Batch 60/97, Loss: 0.1214
Epoch 8/10, Batch 70/97, Loss: 0.3299
Epoch 8/10, Batch 80/97, Loss: 0.1081
Epoch 8/10, Batch 90/97, Loss: 0.1305
Epoch 8/10, Train Loss: 0.2227, Valid Loss: 0.2309
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1879
Epoch 9/10, Batch 20/97, Loss: 0.1851
Epoch 9/10, Batch 30/97, Loss: 0.3743
Epoch 9/10, Batch 40/97, Loss: 0.1682
Epoch 9/10, Batch 50/97, Loss: 0.1617
Epoch 9/10, Batch 60/97, Loss: 0.1525
Epoch 9/10, Batch 70/97, Loss: 0.2292
Epoch 9/10, Batch 80/97, Loss: 0.1901
Epoch 9/10, Batch 90/97, Loss: 0.1513
Epoch 9/10, Train Loss: 0.2104, Valid Loss: 0.2277
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2799
Epoch 10/10, Batch 20/97, Loss: 0.1736
Epoch 10/10, Batch 30/97, Loss: 0.1418
Epoch 10/10, Batch 40/97, Loss: 0.2215
Epoch 10/10, Batch 50/97, Loss: 0.2852
Epoch 10/10, Batch 60/97, Loss: 0.3430
Epoch 10/10, Batch 70/97, Loss: 0.2029
Epoch 10/10, Batch 80/97, Loss: 0.1833
Epoch 10/10, Batch 90/97, Loss: 0.2817
Epoch 10/10, Train Loss: 0.2015, Valid Loss: 0.2239
Model saved!
Accuracy: 0.9100
Precision: 0.9070
Recall: 0.9100
F1-score: 0.9078
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4099
Epoch 1/10, Batch 20/97, Loss: 1.0230
Epoch 1/10, Batch 30/97, Loss: 0.9146
Epoch 1/10, Batch 40/97, Loss: 0.7839
Epoch 1/10, Batch 50/97, Loss: 0.5985
Epoch 1/10, Batch 60/97, Loss: 0.5777
Epoch 1/10, Batch 70/97, Loss: 0.4302
Epoch 1/10, Batch 80/97, Loss: 0.4112
Epoch 1/10, Batch 90/97, Loss: 0.5407
Epoch 1/10, Train Loss: 0.7744, Valid Loss: 0.4325
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3804
Epoch 2/10, Batch 20/97, Loss: 0.4399
Epoch 2/10, Batch 30/97, Loss: 0.2900
Epoch 2/10, Batch 40/97, Loss: 0.3802
Epoch 2/10, Batch 50/97, Loss: 0.5199
Epoch 2/10, Batch 60/97, Loss: 0.4331
Epoch 2/10, Batch 70/97, Loss: 0.3079
Epoch 2/10, Batch 80/97, Loss: 0.3347
Epoch 2/10, Batch 90/97, Loss: 0.3317
Epoch 2/10, Train Loss: 0.3919, Valid Loss: 0.3188
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2328
Epoch 3/10, Batch 20/97, Loss: 0.2872
Epoch 3/10, Batch 30/97, Loss: 0.4467
Epoch 3/10, Batch 40/97, Loss: 0.3152
Epoch 3/10, Batch 50/97, Loss: 0.4061
Epoch 3/10, Batch 60/97, Loss: 0.2584
Epoch 3/10, Batch 70/97, Loss: 0.1790
Epoch 3/10, Batch 80/97, Loss: 0.2215
Epoch 3/10, Batch 90/97, Loss: 0.1934
Epoch 3/10, Train Loss: 0.3283, Valid Loss: 0.2838
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4510
Epoch 4/10, Batch 20/97, Loss: 0.3816
Epoch 4/10, Batch 30/97, Loss: 0.4102
Epoch 4/10, Batch 40/97, Loss: 0.3170
Epoch 4/10, Batch 50/97, Loss: 0.1627
Epoch 4/10, Batch 60/97, Loss: 0.1454
Epoch 4/10, Batch 70/97, Loss: 0.1798
Epoch 4/10, Batch 80/97, Loss: 0.1828
Epoch 4/10, Batch 90/97, Loss: 0.3677
Epoch 4/10, Train Loss: 0.2921, Valid Loss: 0.2592
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2160
Epoch 5/10, Batch 20/97, Loss: 0.2482
Epoch 5/10, Batch 30/97, Loss: 0.1571
Epoch 5/10, Batch 40/97, Loss: 0.1946
Epoch 5/10, Batch 50/97, Loss: 0.3273
Epoch 5/10, Batch 60/97, Loss: 0.2622
Epoch 5/10, Batch 70/97, Loss: 0.0826
Epoch 5/10, Batch 80/97, Loss: 0.2793
Epoch 5/10, Batch 90/97, Loss: 0.3926
Epoch 5/10, Train Loss: 0.2613, Valid Loss: 0.2369
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.0963
Epoch 6/10, Batch 20/97, Loss: 0.2966
Epoch 6/10, Batch 30/97, Loss: 0.2667
Epoch 6/10, Batch 40/97, Loss: 0.3415
Epoch 6/10, Batch 50/97, Loss: 0.3129
Epoch 6/10, Batch 60/97, Loss: 0.1214
Epoch 6/10, Batch 70/97, Loss: 0.2169
Epoch 6/10, Batch 80/97, Loss: 0.2260
Epoch 6/10, Batch 90/97, Loss: 0.2475
Epoch 6/10, Train Loss: 0.2387, Valid Loss: 0.2324
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3810
Epoch 7/10, Batch 20/97, Loss: 0.2042
Epoch 7/10, Batch 30/97, Loss: 0.2884
Epoch 7/10, Batch 40/97, Loss: 0.1934
Epoch 7/10, Batch 50/97, Loss: 0.1768
Epoch 7/10, Batch 60/97, Loss: 0.3111
Epoch 7/10, Batch 70/97, Loss: 0.1582
Epoch 7/10, Batch 80/97, Loss: 0.1190
Epoch 7/10, Batch 90/97, Loss: 0.2695
Epoch 7/10, Train Loss: 0.2473, Valid Loss: 0.2184
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2385
Epoch 8/10, Batch 20/97, Loss: 0.1795
Epoch 8/10, Batch 30/97, Loss: 0.1284
Epoch 8/10, Batch 40/97, Loss: 0.2116
Epoch 8/10, Batch 50/97, Loss: 0.2250
Epoch 8/10, Batch 60/97, Loss: 0.2165
Epoch 8/10, Batch 70/97, Loss: 0.2660
Epoch 8/10, Batch 80/97, Loss: 0.2250
Epoch 8/10, Batch 90/97, Loss: 0.1481
Epoch 8/10, Train Loss: 0.2235, Valid Loss: 0.2110
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0852
Epoch 9/10, Batch 20/97, Loss: 0.1538
Epoch 9/10, Batch 30/97, Loss: 0.3164
Epoch 9/10, Batch 40/97, Loss: 0.1071
Epoch 9/10, Batch 50/97, Loss: 0.2276
Epoch 9/10, Batch 60/97, Loss: 0.1701
Epoch 9/10, Batch 70/97, Loss: 0.1798
Epoch 9/10, Batch 80/97, Loss: 0.2549
Epoch 9/10, Batch 90/97, Loss: 0.1951
Epoch 9/10, Train Loss: 0.2031, Valid Loss: 0.2031
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3481
Epoch 10/10, Batch 20/97, Loss: 0.0633
Epoch 10/10, Batch 30/97, Loss: 0.3009
Epoch 10/10, Batch 40/97, Loss: 0.1931
Epoch 10/10, Batch 50/97, Loss: 0.3945
Epoch 10/10, Batch 60/97, Loss: 0.3427
Epoch 10/10, Batch 70/97, Loss: 0.1861
Epoch 10/10, Batch 80/97, Loss: 0.1850
Epoch 10/10, Batch 90/97, Loss: 0.1924
Epoch 10/10, Train Loss: 0.2028, Valid Loss: 0.2024
Model saved!
Accuracy: 0.9124
Precision: 0.9115
Recall: 0.9124
F1-score: 0.9116
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5240
Epoch 1/10, Batch 20/97, Loss: 0.9902
Epoch 1/10, Batch 30/97, Loss: 0.8636
Epoch 1/10, Batch 40/97, Loss: 0.6394
Epoch 1/10, Batch 50/97, Loss: 0.6558
Epoch 1/10, Batch 60/97, Loss: 0.7325
Epoch 1/10, Batch 70/97, Loss: 0.5095
Epoch 1/10, Batch 80/97, Loss: 0.4837
Epoch 1/10, Batch 90/97, Loss: 0.7131
Epoch 1/10, Train Loss: 0.7720, Valid Loss: 0.4655
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3964
Epoch 2/10, Batch 20/97, Loss: 0.5398
Epoch 2/10, Batch 30/97, Loss: 0.4183
Epoch 2/10, Batch 40/97, Loss: 0.4707
Epoch 2/10, Batch 50/97, Loss: 0.4213
Epoch 2/10, Batch 60/97, Loss: 0.3105
Epoch 2/10, Batch 70/97, Loss: 0.2393
Epoch 2/10, Batch 80/97, Loss: 0.2551
Epoch 2/10, Batch 90/97, Loss: 0.3847
Epoch 2/10, Train Loss: 0.3913, Valid Loss: 0.3663
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3186
Epoch 3/10, Batch 20/97, Loss: 0.2557
Epoch 3/10, Batch 30/97, Loss: 0.1940
Epoch 3/10, Batch 40/97, Loss: 0.3293
Epoch 3/10, Batch 50/97, Loss: 0.3927
Epoch 3/10, Batch 60/97, Loss: 0.3178
Epoch 3/10, Batch 70/97, Loss: 0.2966
Epoch 3/10, Batch 80/97, Loss: 0.2783
Epoch 3/10, Batch 90/97, Loss: 0.3170
Epoch 3/10, Train Loss: 0.3233, Valid Loss: 0.3257
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2502
Epoch 4/10, Batch 20/97, Loss: 0.3365
Epoch 4/10, Batch 30/97, Loss: 0.2971
Epoch 4/10, Batch 40/97, Loss: 0.2845
Epoch 4/10, Batch 50/97, Loss: 0.3372
Epoch 4/10, Batch 60/97, Loss: 0.1907
Epoch 4/10, Batch 70/97, Loss: 0.2599
Epoch 4/10, Batch 80/97, Loss: 0.2373
Epoch 4/10, Batch 90/97, Loss: 0.3570
Epoch 4/10, Train Loss: 0.2853, Valid Loss: 0.3041
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2406
Epoch 5/10, Batch 20/97, Loss: 0.1936
Epoch 5/10, Batch 30/97, Loss: 0.2831
Epoch 5/10, Batch 40/97, Loss: 0.1727
Epoch 5/10, Batch 50/97, Loss: 0.1164
Epoch 5/10, Batch 60/97, Loss: 0.1273
Epoch 5/10, Batch 70/97, Loss: 0.1802
Epoch 5/10, Batch 80/97, Loss: 0.4505
Epoch 5/10, Batch 90/97, Loss: 0.2541
Epoch 5/10, Train Loss: 0.2569, Valid Loss: 0.2946
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1770
Epoch 6/10, Batch 20/97, Loss: 0.3211
Epoch 6/10, Batch 30/97, Loss: 0.1938
Epoch 6/10, Batch 40/97, Loss: 0.3097
Epoch 6/10, Batch 50/97, Loss: 0.1892
Epoch 6/10, Batch 60/97, Loss: 0.2155
Epoch 6/10, Batch 70/97, Loss: 0.1784
Epoch 6/10, Batch 80/97, Loss: 0.1670
Epoch 6/10, Batch 90/97, Loss: 0.3326
Epoch 6/10, Train Loss: 0.2412, Valid Loss: 0.2852
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2138
Epoch 7/10, Batch 20/97, Loss: 0.2051
Epoch 7/10, Batch 30/97, Loss: 0.2511
Epoch 7/10, Batch 40/97, Loss: 0.2036
Epoch 7/10, Batch 50/97, Loss: 0.2194
Epoch 7/10, Batch 60/97, Loss: 0.3733
Epoch 7/10, Batch 70/97, Loss: 0.1228
Epoch 7/10, Batch 80/97, Loss: 0.1689
Epoch 7/10, Batch 90/97, Loss: 0.1859
Epoch 7/10, Train Loss: 0.2453, Valid Loss: 0.2796
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.3514
Epoch 8/10, Batch 20/97, Loss: 0.1721
Epoch 8/10, Batch 30/97, Loss: 0.1149
Epoch 8/10, Batch 40/97, Loss: 0.0776
Epoch 8/10, Batch 50/97, Loss: 0.2122
Epoch 8/10, Batch 60/97, Loss: 0.2081
Epoch 8/10, Batch 70/97, Loss: 0.4357
Epoch 8/10, Batch 80/97, Loss: 0.1793
Epoch 8/10, Batch 90/97, Loss: 0.3053
Epoch 8/10, Train Loss: 0.2241, Valid Loss: 0.2835
Epoch 9/10, Batch 10/97, Loss: 0.1270
Epoch 9/10, Batch 20/97, Loss: 0.0635
Epoch 9/10, Batch 30/97, Loss: 0.1574
Epoch 9/10, Batch 40/97, Loss: 0.1157
Epoch 9/10, Batch 50/97, Loss: 0.1300
Epoch 9/10, Batch 60/97, Loss: 0.2118
Epoch 9/10, Batch 70/97, Loss: 0.3225
Epoch 9/10, Batch 80/97, Loss: 0.1147
Epoch 9/10, Batch 90/97, Loss: 0.4487
Epoch 9/10, Train Loss: 0.2048, Valid Loss: 0.2725
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1235
Epoch 10/10, Batch 20/97, Loss: 0.2489
Epoch 10/10, Batch 30/97, Loss: 0.1614
Epoch 10/10, Batch 40/97, Loss: 0.3165
Epoch 10/10, Batch 50/97, Loss: 0.2356
Epoch 10/10, Batch 60/97, Loss: 0.2336
Epoch 10/10, Batch 70/97, Loss: 0.2104
Epoch 10/10, Batch 80/97, Loss: 0.1122
Epoch 10/10, Batch 90/97, Loss: 0.2077
Epoch 10/10, Train Loss: 0.2023, Valid Loss: 0.2615
Model saved!
Accuracy: 0.9112
Precision: 0.9086
Recall: 0.9112
F1-score: 0.9096
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4742
Epoch 1/10, Batch 20/97, Loss: 1.0115
Epoch 1/10, Batch 30/97, Loss: 0.9539
Epoch 1/10, Batch 40/97, Loss: 0.7912
Epoch 1/10, Batch 50/97, Loss: 0.6220
Epoch 1/10, Batch 60/97, Loss: 0.5453
Epoch 1/10, Batch 70/97, Loss: 0.4404
Epoch 1/10, Batch 80/97, Loss: 0.5270
Epoch 1/10, Batch 90/97, Loss: 0.4420
Epoch 1/10, Train Loss: 0.7797, Valid Loss: 0.4197
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4189
Epoch 2/10, Batch 20/97, Loss: 0.4514
Epoch 2/10, Batch 30/97, Loss: 0.3365
Epoch 2/10, Batch 40/97, Loss: 0.3115
Epoch 2/10, Batch 50/97, Loss: 0.4829
Epoch 2/10, Batch 60/97, Loss: 0.3156
Epoch 2/10, Batch 70/97, Loss: 0.3429
Epoch 2/10, Batch 80/97, Loss: 0.2822
Epoch 2/10, Batch 90/97, Loss: 0.4291
Epoch 2/10, Train Loss: 0.3991, Valid Loss: 0.3266
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2265
Epoch 3/10, Batch 20/97, Loss: 0.2644
Epoch 3/10, Batch 30/97, Loss: 0.2969
Epoch 3/10, Batch 40/97, Loss: 0.2340
Epoch 3/10, Batch 50/97, Loss: 0.3038
Epoch 3/10, Batch 60/97, Loss: 0.1893
Epoch 3/10, Batch 70/97, Loss: 0.2634
Epoch 3/10, Batch 80/97, Loss: 0.2394
Epoch 3/10, Batch 90/97, Loss: 0.2797
Epoch 3/10, Train Loss: 0.3253, Valid Loss: 0.2865
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3234
Epoch 4/10, Batch 20/97, Loss: 0.3143
Epoch 4/10, Batch 30/97, Loss: 0.2617
Epoch 4/10, Batch 40/97, Loss: 0.2514
Epoch 4/10, Batch 50/97, Loss: 0.1375
Epoch 4/10, Batch 60/97, Loss: 0.2545
Epoch 4/10, Batch 70/97, Loss: 0.3397
Epoch 4/10, Batch 80/97, Loss: 0.4226
Epoch 4/10, Batch 90/97, Loss: 0.2809
Epoch 4/10, Train Loss: 0.2891, Valid Loss: 0.2704
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2886
Epoch 5/10, Batch 20/97, Loss: 0.2247
Epoch 5/10, Batch 30/97, Loss: 0.2162
Epoch 5/10, Batch 40/97, Loss: 0.2029
Epoch 5/10, Batch 50/97, Loss: 0.2760
Epoch 5/10, Batch 60/97, Loss: 0.3369
Epoch 5/10, Batch 70/97, Loss: 0.2499
Epoch 5/10, Batch 80/97, Loss: 0.3119
Epoch 5/10, Batch 90/97, Loss: 0.4950
Epoch 5/10, Train Loss: 0.2650, Valid Loss: 0.2582
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2288
Epoch 6/10, Batch 20/97, Loss: 0.2967
Epoch 6/10, Batch 30/97, Loss: 0.2017
Epoch 6/10, Batch 40/97, Loss: 0.1877
Epoch 6/10, Batch 50/97, Loss: 0.1189
Epoch 6/10, Batch 60/97, Loss: 0.4326
Epoch 6/10, Batch 70/97, Loss: 0.1966
Epoch 6/10, Batch 80/97, Loss: 0.2749
Epoch 6/10, Batch 90/97, Loss: 0.2388
Epoch 6/10, Train Loss: 0.2413, Valid Loss: 0.2449
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4491
Epoch 7/10, Batch 20/97, Loss: 0.2954
Epoch 7/10, Batch 30/97, Loss: 0.1417
Epoch 7/10, Batch 40/97, Loss: 0.1455
Epoch 7/10, Batch 50/97, Loss: 0.2623
Epoch 7/10, Batch 60/97, Loss: 0.2996
Epoch 7/10, Batch 70/97, Loss: 0.2412
Epoch 7/10, Batch 80/97, Loss: 0.2292
Epoch 7/10, Batch 90/97, Loss: 0.2134
Epoch 7/10, Train Loss: 0.2410, Valid Loss: 0.2371
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2026
Epoch 8/10, Batch 20/97, Loss: 0.1876
Epoch 8/10, Batch 30/97, Loss: 0.1114
Epoch 8/10, Batch 40/97, Loss: 0.1203
Epoch 8/10, Batch 50/97, Loss: 0.1332
Epoch 8/10, Batch 60/97, Loss: 0.1351
Epoch 8/10, Batch 70/97, Loss: 0.3624
Epoch 8/10, Batch 80/97, Loss: 0.1223
Epoch 8/10, Batch 90/97, Loss: 0.2616
Epoch 8/10, Train Loss: 0.2167, Valid Loss: 0.2463
Epoch 9/10, Batch 10/97, Loss: 0.1396
Epoch 9/10, Batch 20/97, Loss: 0.1319
Epoch 9/10, Batch 30/97, Loss: 0.2579
Epoch 9/10, Batch 40/97, Loss: 0.1635
Epoch 9/10, Batch 50/97, Loss: 0.2889
Epoch 9/10, Batch 60/97, Loss: 0.1142
Epoch 9/10, Batch 70/97, Loss: 0.1395
Epoch 9/10, Batch 80/97, Loss: 0.2836
Epoch 9/10, Batch 90/97, Loss: 0.1441
Epoch 9/10, Train Loss: 0.2066, Valid Loss: 0.2403
Epoch 10/10, Batch 10/97, Loss: 0.1616
Epoch 10/10, Batch 20/97, Loss: 0.1832
Epoch 10/10, Batch 30/97, Loss: 0.2272
Epoch 10/10, Batch 40/97, Loss: 0.1752
Epoch 10/10, Batch 50/97, Loss: 0.1940
Epoch 10/10, Batch 60/97, Loss: 0.0940
Epoch 10/10, Batch 70/97, Loss: 0.1726
Epoch 10/10, Batch 80/97, Loss: 0.1559
Epoch 10/10, Batch 90/97, Loss: 0.1444
Epoch 10/10, Train Loss: 0.2009, Valid Loss: 0.2276
Model saved!
Accuracy: 0.9171
Precision: 0.9148
Recall: 0.9171
F1-score: 0.9156
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5103
Epoch 1/10, Batch 20/97, Loss: 1.0183
Epoch 1/10, Batch 30/97, Loss: 0.8262
Epoch 1/10, Batch 40/97, Loss: 0.7590
Epoch 1/10, Batch 50/97, Loss: 0.5873
Epoch 1/10, Batch 60/97, Loss: 0.6355
Epoch 1/10, Batch 70/97, Loss: 0.6229
Epoch 1/10, Batch 80/97, Loss: 0.5800
Epoch 1/10, Batch 90/97, Loss: 0.5248
Epoch 1/10, Train Loss: 0.7807, Valid Loss: 0.4655
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3672
Epoch 2/10, Batch 20/97, Loss: 0.4343
Epoch 2/10, Batch 30/97, Loss: 0.4117
Epoch 2/10, Batch 40/97, Loss: 0.4821
Epoch 2/10, Batch 50/97, Loss: 0.5753
Epoch 2/10, Batch 60/97, Loss: 0.3476
Epoch 2/10, Batch 70/97, Loss: 0.3377
Epoch 2/10, Batch 80/97, Loss: 0.3193
Epoch 2/10, Batch 90/97, Loss: 0.4191
Epoch 2/10, Train Loss: 0.3995, Valid Loss: 0.3644
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2645
Epoch 3/10, Batch 20/97, Loss: 0.2779
Epoch 3/10, Batch 30/97, Loss: 0.2034
Epoch 3/10, Batch 40/97, Loss: 0.3670
Epoch 3/10, Batch 50/97, Loss: 0.2950
Epoch 3/10, Batch 60/97, Loss: 0.2023
Epoch 3/10, Batch 70/97, Loss: 0.1855
Epoch 3/10, Batch 80/97, Loss: 0.3505
Epoch 3/10, Batch 90/97, Loss: 0.2694
Epoch 3/10, Train Loss: 0.3342, Valid Loss: 0.3206
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3166
Epoch 4/10, Batch 20/97, Loss: 0.4210
Epoch 4/10, Batch 30/97, Loss: 0.3425
Epoch 4/10, Batch 40/97, Loss: 0.3015
Epoch 4/10, Batch 50/97, Loss: 0.1791
Epoch 4/10, Batch 60/97, Loss: 0.1883
Epoch 4/10, Batch 70/97, Loss: 0.2035
Epoch 4/10, Batch 80/97, Loss: 0.1824
Epoch 4/10, Batch 90/97, Loss: 0.1969
Epoch 4/10, Train Loss: 0.2898, Valid Loss: 0.3022
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2097
Epoch 5/10, Batch 20/97, Loss: 0.1569
Epoch 5/10, Batch 30/97, Loss: 0.2164
Epoch 5/10, Batch 40/97, Loss: 0.3236
Epoch 5/10, Batch 50/97, Loss: 0.1853
Epoch 5/10, Batch 60/97, Loss: 0.2595
Epoch 5/10, Batch 70/97, Loss: 0.1989
Epoch 5/10, Batch 80/97, Loss: 0.2788
Epoch 5/10, Batch 90/97, Loss: 0.3857
Epoch 5/10, Train Loss: 0.2673, Valid Loss: 0.2826
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2236
Epoch 6/10, Batch 20/97, Loss: 0.3131
Epoch 6/10, Batch 30/97, Loss: 0.2537
Epoch 6/10, Batch 40/97, Loss: 0.3943
Epoch 6/10, Batch 50/97, Loss: 0.2811
Epoch 6/10, Batch 60/97, Loss: 0.4102
Epoch 6/10, Batch 70/97, Loss: 0.2300
Epoch 6/10, Batch 80/97, Loss: 0.2187
Epoch 6/10, Batch 90/97, Loss: 0.2501
Epoch 6/10, Train Loss: 0.2531, Valid Loss: 0.2704
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2953
Epoch 7/10, Batch 20/97, Loss: 0.1538
Epoch 7/10, Batch 30/97, Loss: 0.2399
Epoch 7/10, Batch 40/97, Loss: 0.2976
Epoch 7/10, Batch 50/97, Loss: 0.2289
Epoch 7/10, Batch 60/97, Loss: 0.2180
Epoch 7/10, Batch 70/97, Loss: 0.2034
Epoch 7/10, Batch 80/97, Loss: 0.2356
Epoch 7/10, Batch 90/97, Loss: 0.3229
Epoch 7/10, Train Loss: 0.2518, Valid Loss: 0.2624
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1475
Epoch 8/10, Batch 20/97, Loss: 0.2719
Epoch 8/10, Batch 30/97, Loss: 0.1615
Epoch 8/10, Batch 40/97, Loss: 0.1705
Epoch 8/10, Batch 50/97, Loss: 0.3212
Epoch 8/10, Batch 60/97, Loss: 0.3649
Epoch 8/10, Batch 70/97, Loss: 0.1324
Epoch 8/10, Batch 80/97, Loss: 0.2026
Epoch 8/10, Batch 90/97, Loss: 0.2001
Epoch 8/10, Train Loss: 0.2250, Valid Loss: 0.2667
Epoch 9/10, Batch 10/97, Loss: 0.2013
Epoch 9/10, Batch 20/97, Loss: 0.1624
Epoch 9/10, Batch 30/97, Loss: 0.3353
Epoch 9/10, Batch 40/97, Loss: 0.2058
Epoch 9/10, Batch 50/97, Loss: 0.2289
Epoch 9/10, Batch 60/97, Loss: 0.1827
Epoch 9/10, Batch 70/97, Loss: 0.1098
Epoch 9/10, Batch 80/97, Loss: 0.2574
Epoch 9/10, Batch 90/97, Loss: 0.2573
Epoch 9/10, Train Loss: 0.2188, Valid Loss: 0.2594
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3061
Epoch 10/10, Batch 20/97, Loss: 0.1488
Epoch 10/10, Batch 30/97, Loss: 0.2273
Epoch 10/10, Batch 40/97, Loss: 0.1875
Epoch 10/10, Batch 50/97, Loss: 0.1968
Epoch 10/10, Batch 60/97, Loss: 0.1070
Epoch 10/10, Batch 70/97, Loss: 0.1658
Epoch 10/10, Batch 80/97, Loss: 0.2284
Epoch 10/10, Batch 90/97, Loss: 0.1337
Epoch 10/10, Train Loss: 0.2025, Valid Loss: 0.2592
Model saved!
Accuracy: 0.9054
Precision: 0.9027
Recall: 0.9054
F1-score: 0.9035
Memory Allocated after cleanup: 17.76 MB
End time: 2025-02-25 00:16:19.926565
Duration: 8:39:05


Mejor accuracy al acabar el algoritmo: 0.9276


Fitness check:

Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4598
Epoch 1/10, Batch 20/97, Loss: 1.0396
Epoch 1/10, Batch 30/97, Loss: 0.8458
Epoch 1/10, Batch 40/97, Loss: 0.6539
Epoch 1/10, Batch 50/97, Loss: 0.5202
Epoch 1/10, Batch 60/97, Loss: 0.6332
Epoch 1/10, Batch 70/97, Loss: 0.4800
Epoch 1/10, Batch 80/97, Loss: 0.4919
Epoch 1/10, Batch 90/97, Loss: 0.5838
Epoch 1/10, Train Loss: 0.7710, Valid Loss: 0.4170
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3647
Epoch 2/10, Batch 20/97, Loss: 0.4397
Epoch 2/10, Batch 30/97, Loss: 0.3210
Epoch 2/10, Batch 40/97, Loss: 0.4535
Epoch 2/10, Batch 50/97, Loss: 0.5757
Epoch 2/10, Batch 60/97, Loss: 0.2837
Epoch 2/10, Batch 70/97, Loss: 0.2994
Epoch 2/10, Batch 80/97, Loss: 0.3058
Epoch 2/10, Batch 90/97, Loss: 0.4660
Epoch 2/10, Train Loss: 0.3924, Valid Loss: 0.3169
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2747
Epoch 3/10, Batch 20/97, Loss: 0.3711
Epoch 3/10, Batch 30/97, Loss: 0.3358
Epoch 3/10, Batch 40/97, Loss: 0.3460
Epoch 3/10, Batch 50/97, Loss: 0.2506
Epoch 3/10, Batch 60/97, Loss: 0.2295
Epoch 3/10, Batch 70/97, Loss: 0.2990
Epoch 3/10, Batch 80/97, Loss: 0.2579
Epoch 3/10, Batch 90/97, Loss: 0.2206
Epoch 3/10, Train Loss: 0.3173, Valid Loss: 0.2835
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3548
Epoch 4/10, Batch 20/97, Loss: 0.3587
Epoch 4/10, Batch 30/97, Loss: 0.2131
Epoch 4/10, Batch 40/97, Loss: 0.3367
Epoch 4/10, Batch 50/97, Loss: 0.2456
Epoch 4/10, Batch 60/97, Loss: 0.3004
Epoch 4/10, Batch 70/97, Loss: 0.1401
Epoch 4/10, Batch 80/97, Loss: 0.3570
Epoch 4/10, Batch 90/97, Loss: 0.3610
Epoch 4/10, Train Loss: 0.2837, Valid Loss: 0.2586
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2596
Epoch 5/10, Batch 20/97, Loss: 0.2353
Epoch 5/10, Batch 30/97, Loss: 0.1790
Epoch 5/10, Batch 40/97, Loss: 0.1474
Epoch 5/10, Batch 50/97, Loss: 0.1514
Epoch 5/10, Batch 60/97, Loss: 0.2082
Epoch 5/10, Batch 70/97, Loss: 0.1877
Epoch 5/10, Batch 80/97, Loss: 0.3010
Epoch 5/10, Batch 90/97, Loss: 0.2901
Epoch 5/10, Train Loss: 0.2523, Valid Loss: 0.2477
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2464
Epoch 6/10, Batch 20/97, Loss: 0.1226
Epoch 6/10, Batch 30/97, Loss: 0.0569
Epoch 6/10, Batch 40/97, Loss: 0.3495
Epoch 6/10, Batch 50/97, Loss: 0.2042
Epoch 6/10, Batch 60/97, Loss: 0.4243
Epoch 6/10, Batch 70/97, Loss: 0.3058
Epoch 6/10, Batch 80/97, Loss: 0.1993
Epoch 6/10, Batch 90/97, Loss: 0.2242
Epoch 6/10, Train Loss: 0.2422, Valid Loss: 0.2424
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3629
Epoch 7/10, Batch 20/97, Loss: 0.1845
Epoch 7/10, Batch 30/97, Loss: 0.1689
Epoch 7/10, Batch 40/97, Loss: 0.1859
Epoch 7/10, Batch 50/97, Loss: 0.3459
Epoch 7/10, Batch 60/97, Loss: 0.3629
Epoch 7/10, Batch 70/97, Loss: 0.3076
Epoch 7/10, Batch 80/97, Loss: 0.1698
Epoch 7/10, Batch 90/97, Loss: 0.1895
Epoch 7/10, Train Loss: 0.2486, Valid Loss: 0.2265
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1084
Epoch 8/10, Batch 20/97, Loss: 0.2556
Epoch 8/10, Batch 30/97, Loss: 0.1318
Epoch 8/10, Batch 40/97, Loss: 0.1953
Epoch 8/10, Batch 50/97, Loss: 0.3015
Epoch 8/10, Batch 60/97, Loss: 0.2436
Epoch 8/10, Batch 70/97, Loss: 0.3619
Epoch 8/10, Batch 80/97, Loss: 0.1785
Epoch 8/10, Batch 90/97, Loss: 0.1721
Epoch 8/10, Train Loss: 0.2136, Valid Loss: 0.2306
Epoch 9/10, Batch 10/97, Loss: 0.1554
Epoch 9/10, Batch 20/97, Loss: 0.0567
Epoch 9/10, Batch 30/97, Loss: 0.2176
Epoch 9/10, Batch 40/97, Loss: 0.1011
Epoch 9/10, Batch 50/97, Loss: 0.3380
Epoch 9/10, Batch 60/97, Loss: 0.1724
Epoch 9/10, Batch 70/97, Loss: 0.2415
Epoch 9/10, Batch 80/97, Loss: 0.2185
Epoch 9/10, Batch 90/97, Loss: 0.1884
Epoch 9/10, Train Loss: 0.2081, Valid Loss: 0.2313
Epoch 10/10, Batch 10/97, Loss: 0.2044
Epoch 10/10, Batch 20/97, Loss: 0.1381
Epoch 10/10, Batch 30/97, Loss: 0.2565
Epoch 10/10, Batch 40/97, Loss: 0.2084
Epoch 10/10, Batch 50/97, Loss: 0.2335
Epoch 10/10, Batch 60/97, Loss: 0.2042
Epoch 10/10, Batch 70/97, Loss: 0.2642
Epoch 10/10, Batch 80/97, Loss: 0.1416
Epoch 10/10, Batch 90/97, Loss: 0.1957
Epoch 10/10, Train Loss: 0.1931, Valid Loss: 0.2261
Model saved!
Accuracy: 0.9276
Precision: 0.9255
Recall: 0.9276
F1-score: 0.9260
Memory Allocated after cleanup: 17.76 MB


Mejor accuracy encontrado: 0.9276


--------------------------------------mobilenet  ALEATORIO  75%-------------------------------------------------
Start time: 2025-02-25 00:21:26.141918
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3545
Epoch 1/10, Batch 20/145, Loss: 0.9193
Epoch 1/10, Batch 30/145, Loss: 0.8653
Epoch 1/10, Batch 40/145, Loss: 0.8330
Epoch 1/10, Batch 50/145, Loss: 0.6957
Epoch 1/10, Batch 60/145, Loss: 0.6106
Epoch 1/10, Batch 70/145, Loss: 0.5735
Epoch 1/10, Batch 80/145, Loss: 0.5733
Epoch 1/10, Batch 90/145, Loss: 0.3887
Epoch 1/10, Batch 100/145, Loss: 0.5454
Epoch 1/10, Batch 110/145, Loss: 0.3599
Epoch 1/10, Batch 120/145, Loss: 0.5295
Epoch 1/10, Batch 130/145, Loss: 0.5119
Epoch 1/10, Batch 140/145, Loss: 0.4275
Epoch 1/10, Train Loss: 0.6762, Valid Loss: 0.3756
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3725
Epoch 2/10, Batch 20/145, Loss: 0.2775
Epoch 2/10, Batch 30/145, Loss: 0.4544
Epoch 2/10, Batch 40/145, Loss: 0.5660
Epoch 2/10, Batch 50/145, Loss: 0.3010
Epoch 2/10, Batch 60/145, Loss: 0.3518
Epoch 2/10, Batch 70/145, Loss: 0.3099
Epoch 2/10, Batch 80/145, Loss: 0.4757
Epoch 2/10, Batch 90/145, Loss: 0.3720
Epoch 2/10, Batch 100/145, Loss: 0.2222
Epoch 2/10, Batch 110/145, Loss: 0.3655
Epoch 2/10, Batch 120/145, Loss: 0.4086
Epoch 2/10, Batch 130/145, Loss: 0.3277
Epoch 2/10, Batch 140/145, Loss: 0.3230
Epoch 2/10, Train Loss: 0.3528, Valid Loss: 0.3004
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1938
Epoch 3/10, Batch 20/145, Loss: 0.2190
Epoch 3/10, Batch 30/145, Loss: 0.4096
Epoch 3/10, Batch 40/145, Loss: 0.1597
Epoch 3/10, Batch 50/145, Loss: 0.1574
Epoch 3/10, Batch 60/145, Loss: 0.5587
Epoch 3/10, Batch 70/145, Loss: 0.2660
Epoch 3/10, Batch 80/145, Loss: 0.2646
Epoch 3/10, Batch 90/145, Loss: 0.2170
Epoch 3/10, Batch 100/145, Loss: 0.2392
Epoch 3/10, Batch 110/145, Loss: 0.3025
Epoch 3/10, Batch 120/145, Loss: 0.3623
Epoch 3/10, Batch 130/145, Loss: 0.3043
Epoch 3/10, Batch 140/145, Loss: 0.2376
Epoch 3/10, Train Loss: 0.2970, Valid Loss: 0.2718
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2325
Epoch 4/10, Batch 20/145, Loss: 0.2937
Epoch 4/10, Batch 30/145, Loss: 0.2937
Epoch 4/10, Batch 40/145, Loss: 0.1683
Epoch 4/10, Batch 50/145, Loss: 0.3266
Epoch 4/10, Batch 60/145, Loss: 0.3411
Epoch 4/10, Batch 70/145, Loss: 0.2845
Epoch 4/10, Batch 80/145, Loss: 0.2623
Epoch 4/10, Batch 90/145, Loss: 0.2855
Epoch 4/10, Batch 100/145, Loss: 0.4074
Epoch 4/10, Batch 110/145, Loss: 0.2024
Epoch 4/10, Batch 120/145, Loss: 0.2727
Epoch 4/10, Batch 130/145, Loss: 0.1450
Epoch 4/10, Batch 140/145, Loss: 0.1748
Epoch 4/10, Train Loss: 0.2571, Valid Loss: 0.2575
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3366
Epoch 5/10, Batch 20/145, Loss: 0.1528
Epoch 5/10, Batch 30/145, Loss: 0.3742
Epoch 5/10, Batch 40/145, Loss: 0.0990
Epoch 5/10, Batch 50/145, Loss: 0.2145
Epoch 5/10, Batch 60/145, Loss: 0.1616
Epoch 5/10, Batch 70/145, Loss: 0.2471
Epoch 5/10, Batch 80/145, Loss: 0.2162
Epoch 5/10, Batch 90/145, Loss: 0.1624
Epoch 5/10, Batch 100/145, Loss: 0.1899
Epoch 5/10, Batch 110/145, Loss: 0.1925
Epoch 5/10, Batch 120/145, Loss: 0.3574
Epoch 5/10, Batch 130/145, Loss: 0.1641
Epoch 5/10, Batch 140/145, Loss: 0.1935
Epoch 5/10, Train Loss: 0.2482, Valid Loss: 0.2447
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1102
Epoch 6/10, Batch 20/145, Loss: 0.3923
Epoch 6/10, Batch 30/145, Loss: 0.3341
Epoch 6/10, Batch 40/145, Loss: 0.1967
Epoch 6/10, Batch 50/145, Loss: 0.3943
Epoch 6/10, Batch 60/145, Loss: 0.1342
Epoch 6/10, Batch 70/145, Loss: 0.1507
Epoch 6/10, Batch 80/145, Loss: 0.1583
Epoch 6/10, Batch 90/145, Loss: 0.3802
Epoch 6/10, Batch 100/145, Loss: 0.2094
Epoch 6/10, Batch 110/145, Loss: 0.2159
Epoch 6/10, Batch 120/145, Loss: 0.3169
Epoch 6/10, Batch 130/145, Loss: 0.2278
Epoch 6/10, Batch 140/145, Loss: 0.1892
Epoch 6/10, Train Loss: 0.2264, Valid Loss: 0.2339
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1357
Epoch 7/10, Batch 20/145, Loss: 0.3730
Epoch 7/10, Batch 30/145, Loss: 0.3426
Epoch 7/10, Batch 40/145, Loss: 0.2676
Epoch 7/10, Batch 50/145, Loss: 0.2661
Epoch 7/10, Batch 60/145, Loss: 0.3774
Epoch 7/10, Batch 70/145, Loss: 0.2349
Epoch 7/10, Batch 80/145, Loss: 0.3721
Epoch 7/10, Batch 90/145, Loss: 0.1293
Epoch 7/10, Batch 100/145, Loss: 0.1519
Epoch 7/10, Batch 110/145, Loss: 0.1317
Epoch 7/10, Batch 120/145, Loss: 0.1508
Epoch 7/10, Batch 130/145, Loss: 0.1345
Epoch 7/10, Batch 140/145, Loss: 0.2248
Epoch 7/10, Train Loss: 0.2170, Valid Loss: 0.2333
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1885
Epoch 8/10, Batch 20/145, Loss: 0.5501
Epoch 8/10, Batch 30/145, Loss: 0.1882
Epoch 8/10, Batch 40/145, Loss: 0.2537
Epoch 8/10, Batch 50/145, Loss: 0.4333
Epoch 8/10, Batch 60/145, Loss: 0.2433
Epoch 8/10, Batch 70/145, Loss: 0.2698
Epoch 8/10, Batch 80/145, Loss: 0.2141
Epoch 8/10, Batch 90/145, Loss: 0.2120
Epoch 8/10, Batch 100/145, Loss: 0.2659
Epoch 8/10, Batch 110/145, Loss: 0.1279
Epoch 8/10, Batch 120/145, Loss: 0.1338
Epoch 8/10, Batch 130/145, Loss: 0.2703
Epoch 8/10, Batch 140/145, Loss: 0.2531
Epoch 8/10, Train Loss: 0.2031, Valid Loss: 0.2223
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2665
Epoch 9/10, Batch 20/145, Loss: 0.2005
Epoch 9/10, Batch 30/145, Loss: 0.1547
Epoch 9/10, Batch 40/145, Loss: 0.1598
Epoch 9/10, Batch 50/145, Loss: 0.2211
Epoch 9/10, Batch 60/145, Loss: 0.2101
Epoch 9/10, Batch 70/145, Loss: 0.2518
Epoch 9/10, Batch 80/145, Loss: 0.2457
Epoch 9/10, Batch 90/145, Loss: 0.4095
Epoch 9/10, Batch 100/145, Loss: 0.1593
Epoch 9/10, Batch 110/145, Loss: 0.2245
Epoch 9/10, Batch 120/145, Loss: 0.1295
Epoch 9/10, Batch 130/145, Loss: 0.1440
Epoch 9/10, Batch 140/145, Loss: 0.1208
Epoch 9/10, Train Loss: 0.1965, Valid Loss: 0.2234
Epoch 10/10, Batch 10/145, Loss: 0.1051
Epoch 10/10, Batch 20/145, Loss: 0.2110
Epoch 10/10, Batch 30/145, Loss: 0.0826
Epoch 10/10, Batch 40/145, Loss: 0.1095
Epoch 10/10, Batch 50/145, Loss: 0.1923
Epoch 10/10, Batch 60/145, Loss: 0.1032
Epoch 10/10, Batch 70/145, Loss: 0.3006
Epoch 10/10, Batch 80/145, Loss: 0.2502
Epoch 10/10, Batch 90/145, Loss: 0.1182
Epoch 10/10, Batch 100/145, Loss: 0.1661
Epoch 10/10, Batch 110/145, Loss: 0.1892
Epoch 10/10, Batch 120/145, Loss: 0.1682
Epoch 10/10, Batch 130/145, Loss: 0.1184
Epoch 10/10, Batch 140/145, Loss: 0.1985
Epoch 10/10, Train Loss: 0.1878, Valid Loss: 0.2239
Accuracy: 0.9136
Precision: 0.9113
Recall: 0.9136
F1-score: 0.9119
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 1. Fitness: 0.9136
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3550
Epoch 1/10, Batch 20/145, Loss: 0.9021
Epoch 1/10, Batch 30/145, Loss: 0.8678
Epoch 1/10, Batch 40/145, Loss: 0.8312
Epoch 1/10, Batch 50/145, Loss: 0.8031
Epoch 1/10, Batch 60/145, Loss: 0.6031
Epoch 1/10, Batch 70/145, Loss: 0.4641
Epoch 1/10, Batch 80/145, Loss: 0.6211
Epoch 1/10, Batch 90/145, Loss: 0.3594
Epoch 1/10, Batch 100/145, Loss: 0.6198
Epoch 1/10, Batch 110/145, Loss: 0.4962
Epoch 1/10, Batch 120/145, Loss: 0.5617
Epoch 1/10, Batch 130/145, Loss: 0.5190
Epoch 1/10, Batch 140/145, Loss: 0.3020
Epoch 1/10, Train Loss: 0.6733, Valid Loss: 0.3840
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3466
Epoch 2/10, Batch 20/145, Loss: 0.3308
Epoch 2/10, Batch 30/145, Loss: 0.3729
Epoch 2/10, Batch 40/145, Loss: 0.3934
Epoch 2/10, Batch 50/145, Loss: 0.2875
Epoch 2/10, Batch 60/145, Loss: 0.7234
Epoch 2/10, Batch 70/145, Loss: 0.4506
Epoch 2/10, Batch 80/145, Loss: 0.2649
Epoch 2/10, Batch 90/145, Loss: 0.4194
Epoch 2/10, Batch 100/145, Loss: 0.2881
Epoch 2/10, Batch 110/145, Loss: 0.4642
Epoch 2/10, Batch 120/145, Loss: 0.3141
Epoch 2/10, Batch 130/145, Loss: 0.2534
Epoch 2/10, Batch 140/145, Loss: 0.4053
Epoch 2/10, Train Loss: 0.3500, Valid Loss: 0.3016
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2207
Epoch 3/10, Batch 20/145, Loss: 0.2788
Epoch 3/10, Batch 30/145, Loss: 0.3638
Epoch 3/10, Batch 40/145, Loss: 0.2077
Epoch 3/10, Batch 50/145, Loss: 0.1750
Epoch 3/10, Batch 60/145, Loss: 0.3534
Epoch 3/10, Batch 70/145, Loss: 0.3891
Epoch 3/10, Batch 80/145, Loss: 0.1802
Epoch 3/10, Batch 90/145, Loss: 0.2321
Epoch 3/10, Batch 100/145, Loss: 0.2199
Epoch 3/10, Batch 110/145, Loss: 0.2881
Epoch 3/10, Batch 120/145, Loss: 0.3878
Epoch 3/10, Batch 130/145, Loss: 0.3098
Epoch 3/10, Batch 140/145, Loss: 0.2778
Epoch 3/10, Train Loss: 0.2847, Valid Loss: 0.2660
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3039
Epoch 4/10, Batch 20/145, Loss: 0.2911
Epoch 4/10, Batch 30/145, Loss: 0.2838
Epoch 4/10, Batch 40/145, Loss: 0.1563
Epoch 4/10, Batch 50/145, Loss: 0.1837
Epoch 4/10, Batch 60/145, Loss: 0.1904
Epoch 4/10, Batch 70/145, Loss: 0.2170
Epoch 4/10, Batch 80/145, Loss: 0.1666
Epoch 4/10, Batch 90/145, Loss: 0.2713
Epoch 4/10, Batch 100/145, Loss: 0.2121
Epoch 4/10, Batch 110/145, Loss: 0.1205
Epoch 4/10, Batch 120/145, Loss: 0.3043
Epoch 4/10, Batch 130/145, Loss: 0.1268
Epoch 4/10, Batch 140/145, Loss: 0.1469
Epoch 4/10, Train Loss: 0.2493, Valid Loss: 0.2582
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1264
Epoch 5/10, Batch 20/145, Loss: 0.2157
Epoch 5/10, Batch 30/145, Loss: 0.2438
Epoch 5/10, Batch 40/145, Loss: 0.1820
Epoch 5/10, Batch 50/145, Loss: 0.1030
Epoch 5/10, Batch 60/145, Loss: 0.2142
Epoch 5/10, Batch 70/145, Loss: 0.1606
Epoch 5/10, Batch 80/145, Loss: 0.3233
Epoch 5/10, Batch 90/145, Loss: 0.3092
Epoch 5/10, Batch 100/145, Loss: 0.1704
Epoch 5/10, Batch 110/145, Loss: 0.0957
Epoch 5/10, Batch 120/145, Loss: 0.4463
Epoch 5/10, Batch 130/145, Loss: 0.2060
Epoch 5/10, Batch 140/145, Loss: 0.2936
Epoch 5/10, Train Loss: 0.2375, Valid Loss: 0.2427
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2129
Epoch 6/10, Batch 20/145, Loss: 0.4775
Epoch 6/10, Batch 30/145, Loss: 0.3610
Epoch 6/10, Batch 40/145, Loss: 0.2383
Epoch 6/10, Batch 50/145, Loss: 0.2686
Epoch 6/10, Batch 60/145, Loss: 0.1705
Epoch 6/10, Batch 70/145, Loss: 0.3042
Epoch 6/10, Batch 80/145, Loss: 0.3562
Epoch 6/10, Batch 90/145, Loss: 0.2296
Epoch 6/10, Batch 100/145, Loss: 0.2596
Epoch 6/10, Batch 110/145, Loss: 0.2374
Epoch 6/10, Batch 120/145, Loss: 0.2142
Epoch 6/10, Batch 130/145, Loss: 0.1127
Epoch 6/10, Batch 140/145, Loss: 0.2232
Epoch 6/10, Train Loss: 0.2188, Valid Loss: 0.2369
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3396
Epoch 7/10, Batch 20/145, Loss: 0.2194
Epoch 7/10, Batch 30/145, Loss: 0.2283
Epoch 7/10, Batch 40/145, Loss: 0.3950
Epoch 7/10, Batch 50/145, Loss: 0.1032
Epoch 7/10, Batch 60/145, Loss: 0.1603
Epoch 7/10, Batch 70/145, Loss: 0.2196
Epoch 7/10, Batch 80/145, Loss: 0.5606
Epoch 7/10, Batch 90/145, Loss: 0.1307
Epoch 7/10, Batch 100/145, Loss: 0.2204
Epoch 7/10, Batch 110/145, Loss: 0.1430
Epoch 7/10, Batch 120/145, Loss: 0.2149
Epoch 7/10, Batch 130/145, Loss: 0.1196
Epoch 7/10, Batch 140/145, Loss: 0.1135
Epoch 7/10, Train Loss: 0.2062, Valid Loss: 0.2310
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.3298
Epoch 8/10, Batch 20/145, Loss: 0.1587
Epoch 8/10, Batch 30/145, Loss: 0.1137
Epoch 8/10, Batch 40/145, Loss: 0.1605
Epoch 8/10, Batch 50/145, Loss: 0.3464
Epoch 8/10, Batch 60/145, Loss: 0.1130
Epoch 8/10, Batch 70/145, Loss: 0.2051
Epoch 8/10, Batch 80/145, Loss: 0.2419
Epoch 8/10, Batch 90/145, Loss: 0.2843
Epoch 8/10, Batch 100/145, Loss: 0.1678
Epoch 8/10, Batch 110/145, Loss: 0.1497
Epoch 8/10, Batch 120/145, Loss: 0.3241
Epoch 8/10, Batch 130/145, Loss: 0.0934
Epoch 8/10, Batch 140/145, Loss: 0.1805
Epoch 8/10, Train Loss: 0.1994, Valid Loss: 0.2312
Epoch 9/10, Batch 10/145, Loss: 0.3456
Epoch 9/10, Batch 20/145, Loss: 0.2427
Epoch 9/10, Batch 30/145, Loss: 0.1342
Epoch 9/10, Batch 40/145, Loss: 0.3281
Epoch 9/10, Batch 50/145, Loss: 0.1441
Epoch 9/10, Batch 60/145, Loss: 0.2221
Epoch 9/10, Batch 70/145, Loss: 0.1287
Epoch 9/10, Batch 80/145, Loss: 0.1415
Epoch 9/10, Batch 90/145, Loss: 0.1837
Epoch 9/10, Batch 100/145, Loss: 0.1337
Epoch 9/10, Batch 110/145, Loss: 0.1824
Epoch 9/10, Batch 120/145, Loss: 0.0815
Epoch 9/10, Batch 130/145, Loss: 0.2342
Epoch 9/10, Batch 140/145, Loss: 0.3397
Epoch 9/10, Train Loss: 0.1974, Valid Loss: 0.2296
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0882
Epoch 10/10, Batch 20/145, Loss: 0.1466
Epoch 10/10, Batch 30/145, Loss: 0.1377
Epoch 10/10, Batch 40/145, Loss: 0.2155
Epoch 10/10, Batch 50/145, Loss: 0.2057
Epoch 10/10, Batch 60/145, Loss: 0.0733
Epoch 10/10, Batch 70/145, Loss: 0.2859
Epoch 10/10, Batch 80/145, Loss: 0.1753
Epoch 10/10, Batch 90/145, Loss: 0.0796
Epoch 10/10, Batch 100/145, Loss: 0.1044
Epoch 10/10, Batch 110/145, Loss: 0.0985
Epoch 10/10, Batch 120/145, Loss: 0.2092
Epoch 10/10, Batch 130/145, Loss: 0.3734
Epoch 10/10, Batch 140/145, Loss: 0.2031
Epoch 10/10, Train Loss: 0.1841, Valid Loss: 0.2204
Model saved!
Accuracy: 0.9241
Precision: 0.9224
Recall: 0.9241
F1-score: 0.9229
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 2. Fitness: 0.9241
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3574
Epoch 1/10, Batch 20/145, Loss: 0.9572
Epoch 1/10, Batch 30/145, Loss: 0.8954
Epoch 1/10, Batch 40/145, Loss: 0.8716
Epoch 1/10, Batch 50/145, Loss: 0.6515
Epoch 1/10, Batch 60/145, Loss: 0.5461
Epoch 1/10, Batch 70/145, Loss: 0.4348
Epoch 1/10, Batch 80/145, Loss: 0.6863
Epoch 1/10, Batch 90/145, Loss: 0.4587
Epoch 1/10, Batch 100/145, Loss: 0.4100
Epoch 1/10, Batch 110/145, Loss: 0.3872
Epoch 1/10, Batch 120/145, Loss: 0.6459
Epoch 1/10, Batch 130/145, Loss: 0.6034
Epoch 1/10, Batch 140/145, Loss: 0.3694
Epoch 1/10, Train Loss: 0.6770, Valid Loss: 0.3787
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4013
Epoch 2/10, Batch 20/145, Loss: 0.2831
Epoch 2/10, Batch 30/145, Loss: 0.2994
Epoch 2/10, Batch 40/145, Loss: 0.4659
Epoch 2/10, Batch 50/145, Loss: 0.2861
Epoch 2/10, Batch 60/145, Loss: 0.3802
Epoch 2/10, Batch 70/145, Loss: 0.4069
Epoch 2/10, Batch 80/145, Loss: 0.3448
Epoch 2/10, Batch 90/145, Loss: 0.2813
Epoch 2/10, Batch 100/145, Loss: 0.4754
Epoch 2/10, Batch 110/145, Loss: 0.3113
Epoch 2/10, Batch 120/145, Loss: 0.4501
Epoch 2/10, Batch 130/145, Loss: 0.2942
Epoch 2/10, Batch 140/145, Loss: 0.4300
Epoch 2/10, Train Loss: 0.3511, Valid Loss: 0.2916
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2669
Epoch 3/10, Batch 20/145, Loss: 0.1925
Epoch 3/10, Batch 30/145, Loss: 0.3228
Epoch 3/10, Batch 40/145, Loss: 0.2989
Epoch 3/10, Batch 50/145, Loss: 0.2222
Epoch 3/10, Batch 60/145, Loss: 0.4341
Epoch 3/10, Batch 70/145, Loss: 0.3488
Epoch 3/10, Batch 80/145, Loss: 0.1951
Epoch 3/10, Batch 90/145, Loss: 0.1505
Epoch 3/10, Batch 100/145, Loss: 0.1821
Epoch 3/10, Batch 110/145, Loss: 0.1839
Epoch 3/10, Batch 120/145, Loss: 0.3452
Epoch 3/10, Batch 130/145, Loss: 0.5846
Epoch 3/10, Batch 140/145, Loss: 0.2727
Epoch 3/10, Train Loss: 0.2966, Valid Loss: 0.2575
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4187
Epoch 4/10, Batch 20/145, Loss: 0.1952
Epoch 4/10, Batch 30/145, Loss: 0.2279
Epoch 4/10, Batch 40/145, Loss: 0.1866
Epoch 4/10, Batch 50/145, Loss: 0.1719
Epoch 4/10, Batch 60/145, Loss: 0.4654
Epoch 4/10, Batch 70/145, Loss: 0.2302
Epoch 4/10, Batch 80/145, Loss: 0.2458
Epoch 4/10, Batch 90/145, Loss: 0.2299
Epoch 4/10, Batch 100/145, Loss: 0.2238
Epoch 4/10, Batch 110/145, Loss: 0.1320
Epoch 4/10, Batch 120/145, Loss: 0.4014
Epoch 4/10, Batch 130/145, Loss: 0.2369
Epoch 4/10, Batch 140/145, Loss: 0.1410
Epoch 4/10, Train Loss: 0.2611, Valid Loss: 0.2414
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3307
Epoch 5/10, Batch 20/145, Loss: 0.1637
Epoch 5/10, Batch 30/145, Loss: 0.2412
Epoch 5/10, Batch 40/145, Loss: 0.2509
Epoch 5/10, Batch 50/145, Loss: 0.1210
Epoch 5/10, Batch 60/145, Loss: 0.1614
Epoch 5/10, Batch 70/145, Loss: 0.1915
Epoch 5/10, Batch 80/145, Loss: 0.2974
Epoch 5/10, Batch 90/145, Loss: 0.3295
Epoch 5/10, Batch 100/145, Loss: 0.4274
Epoch 5/10, Batch 110/145, Loss: 0.1892
Epoch 5/10, Batch 120/145, Loss: 0.2762
Epoch 5/10, Batch 130/145, Loss: 0.1860
Epoch 5/10, Batch 140/145, Loss: 0.2039
Epoch 5/10, Train Loss: 0.2466, Valid Loss: 0.2311
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3199
Epoch 6/10, Batch 20/145, Loss: 0.5583
Epoch 6/10, Batch 30/145, Loss: 0.2355
Epoch 6/10, Batch 40/145, Loss: 0.0814
Epoch 6/10, Batch 50/145, Loss: 0.3363
Epoch 6/10, Batch 60/145, Loss: 0.2926
Epoch 6/10, Batch 70/145, Loss: 0.1284
Epoch 6/10, Batch 80/145, Loss: 0.2601
Epoch 6/10, Batch 90/145, Loss: 0.2942
Epoch 6/10, Batch 100/145, Loss: 0.2721
Epoch 6/10, Batch 110/145, Loss: 0.2080
Epoch 6/10, Batch 120/145, Loss: 0.2003
Epoch 6/10, Batch 130/145, Loss: 0.2190
Epoch 6/10, Batch 140/145, Loss: 0.1758
Epoch 6/10, Train Loss: 0.2326, Valid Loss: 0.2236
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2058
Epoch 7/10, Batch 20/145, Loss: 0.3312
Epoch 7/10, Batch 30/145, Loss: 0.2031
Epoch 7/10, Batch 40/145, Loss: 0.4286
Epoch 7/10, Batch 50/145, Loss: 0.1693
Epoch 7/10, Batch 60/145, Loss: 0.1580
Epoch 7/10, Batch 70/145, Loss: 0.1556
Epoch 7/10, Batch 80/145, Loss: 0.4164
Epoch 7/10, Batch 90/145, Loss: 0.0747
Epoch 7/10, Batch 100/145, Loss: 0.1278
Epoch 7/10, Batch 110/145, Loss: 0.2139
Epoch 7/10, Batch 120/145, Loss: 0.2340
Epoch 7/10, Batch 130/145, Loss: 0.0891
Epoch 7/10, Batch 140/145, Loss: 0.2380
Epoch 7/10, Train Loss: 0.2114, Valid Loss: 0.2143
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.3471
Epoch 8/10, Batch 20/145, Loss: 0.3541
Epoch 8/10, Batch 30/145, Loss: 0.1827
Epoch 8/10, Batch 40/145, Loss: 0.1935
Epoch 8/10, Batch 50/145, Loss: 0.2139
Epoch 8/10, Batch 60/145, Loss: 0.1156
Epoch 8/10, Batch 70/145, Loss: 0.3819
Epoch 8/10, Batch 80/145, Loss: 0.2511
Epoch 8/10, Batch 90/145, Loss: 0.1968
Epoch 8/10, Batch 100/145, Loss: 0.1487
Epoch 8/10, Batch 110/145, Loss: 0.1080
Epoch 8/10, Batch 120/145, Loss: 0.4053
Epoch 8/10, Batch 130/145, Loss: 0.1169
Epoch 8/10, Batch 140/145, Loss: 0.1357
Epoch 8/10, Train Loss: 0.2065, Valid Loss: 0.2072
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3839
Epoch 9/10, Batch 20/145, Loss: 0.2377
Epoch 9/10, Batch 30/145, Loss: 0.1629
Epoch 9/10, Batch 40/145, Loss: 0.1096
Epoch 9/10, Batch 50/145, Loss: 0.1782
Epoch 9/10, Batch 60/145, Loss: 0.2822
Epoch 9/10, Batch 70/145, Loss: 0.2488
Epoch 9/10, Batch 80/145, Loss: 0.2069
Epoch 9/10, Batch 90/145, Loss: 0.2527
Epoch 9/10, Batch 100/145, Loss: 0.1942
Epoch 9/10, Batch 110/145, Loss: 0.2302
Epoch 9/10, Batch 120/145, Loss: 0.0997
Epoch 9/10, Batch 130/145, Loss: 0.2071
Epoch 9/10, Batch 140/145, Loss: 0.1506
Epoch 9/10, Train Loss: 0.2039, Valid Loss: 0.2063
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1237
Epoch 10/10, Batch 20/145, Loss: 0.1496
Epoch 10/10, Batch 30/145, Loss: 0.1669
Epoch 10/10, Batch 40/145, Loss: 0.1919
Epoch 10/10, Batch 50/145, Loss: 0.2543
Epoch 10/10, Batch 60/145, Loss: 0.1341
Epoch 10/10, Batch 70/145, Loss: 0.4129
Epoch 10/10, Batch 80/145, Loss: 0.1212
Epoch 10/10, Batch 90/145, Loss: 0.0632
Epoch 10/10, Batch 100/145, Loss: 0.1357
Epoch 10/10, Batch 110/145, Loss: 0.2748
Epoch 10/10, Batch 120/145, Loss: 0.1489
Epoch 10/10, Batch 130/145, Loss: 0.1331
Epoch 10/10, Batch 140/145, Loss: 0.2406
Epoch 10/10, Train Loss: 0.1924, Valid Loss: 0.2004
Model saved!
Accuracy: 0.9194
Precision: 0.9166
Recall: 0.9194
F1-score: 0.9172
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3844
Epoch 1/10, Batch 20/145, Loss: 0.9736
Epoch 1/10, Batch 30/145, Loss: 0.9369
Epoch 1/10, Batch 40/145, Loss: 0.8165
Epoch 1/10, Batch 50/145, Loss: 0.6691
Epoch 1/10, Batch 60/145, Loss: 0.7525
Epoch 1/10, Batch 70/145, Loss: 0.4225
Epoch 1/10, Batch 80/145, Loss: 0.5330
Epoch 1/10, Batch 90/145, Loss: 0.3393
Epoch 1/10, Batch 100/145, Loss: 0.4196
Epoch 1/10, Batch 110/145, Loss: 0.4377
Epoch 1/10, Batch 120/145, Loss: 0.5193
Epoch 1/10, Batch 130/145, Loss: 0.4034
Epoch 1/10, Batch 140/145, Loss: 0.5073
Epoch 1/10, Train Loss: 0.6723, Valid Loss: 0.3953
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3877
Epoch 2/10, Batch 20/145, Loss: 0.2689
Epoch 2/10, Batch 30/145, Loss: 0.3341
Epoch 2/10, Batch 40/145, Loss: 0.4624
Epoch 2/10, Batch 50/145, Loss: 0.3000
Epoch 2/10, Batch 60/145, Loss: 0.4468
Epoch 2/10, Batch 70/145, Loss: 0.3402
Epoch 2/10, Batch 80/145, Loss: 0.2419
Epoch 2/10, Batch 90/145, Loss: 0.2582
Epoch 2/10, Batch 100/145, Loss: 0.3001
Epoch 2/10, Batch 110/145, Loss: 0.4625
Epoch 2/10, Batch 120/145, Loss: 0.3292
Epoch 2/10, Batch 130/145, Loss: 0.3362
Epoch 2/10, Batch 140/145, Loss: 0.4626
Epoch 2/10, Train Loss: 0.3426, Valid Loss: 0.3199
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3456
Epoch 3/10, Batch 20/145, Loss: 0.2715
Epoch 3/10, Batch 30/145, Loss: 0.4645
Epoch 3/10, Batch 40/145, Loss: 0.2047
Epoch 3/10, Batch 50/145, Loss: 0.1654
Epoch 3/10, Batch 60/145, Loss: 0.3823
Epoch 3/10, Batch 70/145, Loss: 0.1890
Epoch 3/10, Batch 80/145, Loss: 0.2045
Epoch 3/10, Batch 90/145, Loss: 0.4244
Epoch 3/10, Batch 100/145, Loss: 0.2192
Epoch 3/10, Batch 110/145, Loss: 0.2703
Epoch 3/10, Batch 120/145, Loss: 0.2020
Epoch 3/10, Batch 130/145, Loss: 0.3066
Epoch 3/10, Batch 140/145, Loss: 0.1815
Epoch 3/10, Train Loss: 0.2819, Valid Loss: 0.2946
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2735
Epoch 4/10, Batch 20/145, Loss: 0.3785
Epoch 4/10, Batch 30/145, Loss: 0.1739
Epoch 4/10, Batch 40/145, Loss: 0.1920
Epoch 4/10, Batch 50/145, Loss: 0.2084
Epoch 4/10, Batch 60/145, Loss: 0.2181
Epoch 4/10, Batch 70/145, Loss: 0.2592
Epoch 4/10, Batch 80/145, Loss: 0.1591
Epoch 4/10, Batch 90/145, Loss: 0.2717
Epoch 4/10, Batch 100/145, Loss: 0.3498
Epoch 4/10, Batch 110/145, Loss: 0.1779
Epoch 4/10, Batch 120/145, Loss: 0.3925
Epoch 4/10, Batch 130/145, Loss: 0.1778
Epoch 4/10, Batch 140/145, Loss: 0.1282
Epoch 4/10, Train Loss: 0.2449, Valid Loss: 0.2832
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2554
Epoch 5/10, Batch 20/145, Loss: 0.1111
Epoch 5/10, Batch 30/145, Loss: 0.1848
Epoch 5/10, Batch 40/145, Loss: 0.1604
Epoch 5/10, Batch 50/145, Loss: 0.1101
Epoch 5/10, Batch 60/145, Loss: 0.2038
Epoch 5/10, Batch 70/145, Loss: 0.2244
Epoch 5/10, Batch 80/145, Loss: 0.1876
Epoch 5/10, Batch 90/145, Loss: 0.4165
Epoch 5/10, Batch 100/145, Loss: 0.2815
Epoch 5/10, Batch 110/145, Loss: 0.1732
Epoch 5/10, Batch 120/145, Loss: 0.1602
Epoch 5/10, Batch 130/145, Loss: 0.1801
Epoch 5/10, Batch 140/145, Loss: 0.1999
Epoch 5/10, Train Loss: 0.2307, Valid Loss: 0.2710
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2083
Epoch 6/10, Batch 20/145, Loss: 0.2483
Epoch 6/10, Batch 30/145, Loss: 0.3764
Epoch 6/10, Batch 40/145, Loss: 0.1312
Epoch 6/10, Batch 50/145, Loss: 0.2866
Epoch 6/10, Batch 60/145, Loss: 0.1935
Epoch 6/10, Batch 70/145, Loss: 0.2061
Epoch 6/10, Batch 80/145, Loss: 0.2225
Epoch 6/10, Batch 90/145, Loss: 0.3565
Epoch 6/10, Batch 100/145, Loss: 0.2881
Epoch 6/10, Batch 110/145, Loss: 0.2358
Epoch 6/10, Batch 120/145, Loss: 0.2736
Epoch 6/10, Batch 130/145, Loss: 0.1460
Epoch 6/10, Batch 140/145, Loss: 0.1640
Epoch 6/10, Train Loss: 0.2181, Valid Loss: 0.2620
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2563
Epoch 7/10, Batch 20/145, Loss: 0.3645
Epoch 7/10, Batch 30/145, Loss: 0.2440
Epoch 7/10, Batch 40/145, Loss: 0.2950
Epoch 7/10, Batch 50/145, Loss: 0.2280
Epoch 7/10, Batch 60/145, Loss: 0.1793
Epoch 7/10, Batch 70/145, Loss: 0.2201
Epoch 7/10, Batch 80/145, Loss: 0.3487
Epoch 7/10, Batch 90/145, Loss: 0.1807
Epoch 7/10, Batch 100/145, Loss: 0.1047
Epoch 7/10, Batch 110/145, Loss: 0.1211
Epoch 7/10, Batch 120/145, Loss: 0.1956
Epoch 7/10, Batch 130/145, Loss: 0.1230
Epoch 7/10, Batch 140/145, Loss: 0.2109
Epoch 7/10, Train Loss: 0.2062, Valid Loss: 0.2568
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1526
Epoch 8/10, Batch 20/145, Loss: 0.1840
Epoch 8/10, Batch 30/145, Loss: 0.2205
Epoch 8/10, Batch 40/145, Loss: 0.1383
Epoch 8/10, Batch 50/145, Loss: 0.3641
Epoch 8/10, Batch 60/145, Loss: 0.3019
Epoch 8/10, Batch 70/145, Loss: 0.1687
Epoch 8/10, Batch 80/145, Loss: 0.1272
Epoch 8/10, Batch 90/145, Loss: 0.2520
Epoch 8/10, Batch 100/145, Loss: 0.1153
Epoch 8/10, Batch 110/145, Loss: 0.3078
Epoch 8/10, Batch 120/145, Loss: 0.1910
Epoch 8/10, Batch 130/145, Loss: 0.2031
Epoch 8/10, Batch 140/145, Loss: 0.1995
Epoch 8/10, Train Loss: 0.1953, Valid Loss: 0.2487
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2417
Epoch 9/10, Batch 20/145, Loss: 0.1066
Epoch 9/10, Batch 30/145, Loss: 0.1535
Epoch 9/10, Batch 40/145, Loss: 0.1773
Epoch 9/10, Batch 50/145, Loss: 0.1442
Epoch 9/10, Batch 60/145, Loss: 0.1495
Epoch 9/10, Batch 70/145, Loss: 0.2108
Epoch 9/10, Batch 80/145, Loss: 0.0928
Epoch 9/10, Batch 90/145, Loss: 0.1523
Epoch 9/10, Batch 100/145, Loss: 0.1495
Epoch 9/10, Batch 110/145, Loss: 0.2225
Epoch 9/10, Batch 120/145, Loss: 0.0615
Epoch 9/10, Batch 130/145, Loss: 0.1515
Epoch 9/10, Batch 140/145, Loss: 0.1431
Epoch 9/10, Train Loss: 0.1906, Valid Loss: 0.2447
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1847
Epoch 10/10, Batch 20/145, Loss: 0.0942
Epoch 10/10, Batch 30/145, Loss: 0.1193
Epoch 10/10, Batch 40/145, Loss: 0.2294
Epoch 10/10, Batch 50/145, Loss: 0.3046
Epoch 10/10, Batch 60/145, Loss: 0.2428
Epoch 10/10, Batch 70/145, Loss: 0.2906
Epoch 10/10, Batch 80/145, Loss: 0.0731
Epoch 10/10, Batch 90/145, Loss: 0.1982
Epoch 10/10, Batch 100/145, Loss: 0.1777
Epoch 10/10, Batch 110/145, Loss: 0.1665
Epoch 10/10, Batch 120/145, Loss: 0.2569
Epoch 10/10, Batch 130/145, Loss: 0.2114
Epoch 10/10, Batch 140/145, Loss: 0.2817
Epoch 10/10, Train Loss: 0.1831, Valid Loss: 0.2562
Accuracy: 0.9147
Precision: 0.9130
Recall: 0.9147
F1-score: 0.9136
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4311
Epoch 1/10, Batch 20/145, Loss: 0.9232
Epoch 1/10, Batch 30/145, Loss: 0.9147
Epoch 1/10, Batch 40/145, Loss: 0.7229
Epoch 1/10, Batch 50/145, Loss: 0.6586
Epoch 1/10, Batch 60/145, Loss: 0.6162
Epoch 1/10, Batch 70/145, Loss: 0.4798
Epoch 1/10, Batch 80/145, Loss: 0.5193
Epoch 1/10, Batch 90/145, Loss: 0.4131
Epoch 1/10, Batch 100/145, Loss: 0.5262
Epoch 1/10, Batch 110/145, Loss: 0.5128
Epoch 1/10, Batch 120/145, Loss: 0.6268
Epoch 1/10, Batch 130/145, Loss: 0.6956
Epoch 1/10, Batch 140/145, Loss: 0.3553
Epoch 1/10, Train Loss: 0.6797, Valid Loss: 0.3800
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3073
Epoch 2/10, Batch 20/145, Loss: 0.3593
Epoch 2/10, Batch 30/145, Loss: 0.2581
Epoch 2/10, Batch 40/145, Loss: 0.4097
Epoch 2/10, Batch 50/145, Loss: 0.4995
Epoch 2/10, Batch 60/145, Loss: 0.4362
Epoch 2/10, Batch 70/145, Loss: 0.4036
Epoch 2/10, Batch 80/145, Loss: 0.3185
Epoch 2/10, Batch 90/145, Loss: 0.3540
Epoch 2/10, Batch 100/145, Loss: 0.2588
Epoch 2/10, Batch 110/145, Loss: 0.4876
Epoch 2/10, Batch 120/145, Loss: 0.3493
Epoch 2/10, Batch 130/145, Loss: 0.2890
Epoch 2/10, Batch 140/145, Loss: 0.2497
Epoch 2/10, Train Loss: 0.3521, Valid Loss: 0.2989
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2939
Epoch 3/10, Batch 20/145, Loss: 0.1398
Epoch 3/10, Batch 30/145, Loss: 0.5248
Epoch 3/10, Batch 40/145, Loss: 0.1905
Epoch 3/10, Batch 50/145, Loss: 0.1607
Epoch 3/10, Batch 60/145, Loss: 0.4581
Epoch 3/10, Batch 70/145, Loss: 0.3484
Epoch 3/10, Batch 80/145, Loss: 0.1852
Epoch 3/10, Batch 90/145, Loss: 0.2837
Epoch 3/10, Batch 100/145, Loss: 0.5071
Epoch 3/10, Batch 110/145, Loss: 0.2231
Epoch 3/10, Batch 120/145, Loss: 0.3472
Epoch 3/10, Batch 130/145, Loss: 0.2456
Epoch 3/10, Batch 140/145, Loss: 0.2538
Epoch 3/10, Train Loss: 0.2959, Valid Loss: 0.2675
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2651
Epoch 4/10, Batch 20/145, Loss: 0.4102
Epoch 4/10, Batch 30/145, Loss: 0.3146
Epoch 4/10, Batch 40/145, Loss: 0.1937
Epoch 4/10, Batch 50/145, Loss: 0.2378
Epoch 4/10, Batch 60/145, Loss: 0.3195
Epoch 4/10, Batch 70/145, Loss: 0.2180
Epoch 4/10, Batch 80/145, Loss: 0.2281
Epoch 4/10, Batch 90/145, Loss: 0.2032
Epoch 4/10, Batch 100/145, Loss: 0.2518
Epoch 4/10, Batch 110/145, Loss: 0.1953
Epoch 4/10, Batch 120/145, Loss: 0.2583
Epoch 4/10, Batch 130/145, Loss: 0.2771
Epoch 4/10, Batch 140/145, Loss: 0.2371
Epoch 4/10, Train Loss: 0.2582, Valid Loss: 0.2505
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1159
Epoch 5/10, Batch 20/145, Loss: 0.2589
Epoch 5/10, Batch 30/145, Loss: 0.1889
Epoch 5/10, Batch 40/145, Loss: 0.1177
Epoch 5/10, Batch 50/145, Loss: 0.1617
Epoch 5/10, Batch 60/145, Loss: 0.1492
Epoch 5/10, Batch 70/145, Loss: 0.1430
Epoch 5/10, Batch 80/145, Loss: 0.3238
Epoch 5/10, Batch 90/145, Loss: 0.4014
Epoch 5/10, Batch 100/145, Loss: 0.1334
Epoch 5/10, Batch 110/145, Loss: 0.2705
Epoch 5/10, Batch 120/145, Loss: 0.2837
Epoch 5/10, Batch 130/145, Loss: 0.1974
Epoch 5/10, Batch 140/145, Loss: 0.3692
Epoch 5/10, Train Loss: 0.2491, Valid Loss: 0.2452
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2152
Epoch 6/10, Batch 20/145, Loss: 0.4152
Epoch 6/10, Batch 30/145, Loss: 0.2495
Epoch 6/10, Batch 40/145, Loss: 0.1135
Epoch 6/10, Batch 50/145, Loss: 0.2897
Epoch 6/10, Batch 60/145, Loss: 0.2672
Epoch 6/10, Batch 70/145, Loss: 0.1140
Epoch 6/10, Batch 80/145, Loss: 0.3702
Epoch 6/10, Batch 90/145, Loss: 0.2958
Epoch 6/10, Batch 100/145, Loss: 0.2610
Epoch 6/10, Batch 110/145, Loss: 0.2252
Epoch 6/10, Batch 120/145, Loss: 0.2529
Epoch 6/10, Batch 130/145, Loss: 0.1780
Epoch 6/10, Batch 140/145, Loss: 0.2283
Epoch 6/10, Train Loss: 0.2289, Valid Loss: 0.2299
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3183
Epoch 7/10, Batch 20/145, Loss: 0.2478
Epoch 7/10, Batch 30/145, Loss: 0.3553
Epoch 7/10, Batch 40/145, Loss: 0.3435
Epoch 7/10, Batch 50/145, Loss: 0.2314
Epoch 7/10, Batch 60/145, Loss: 0.2308
Epoch 7/10, Batch 70/145, Loss: 0.0846
Epoch 7/10, Batch 80/145, Loss: 0.2841
Epoch 7/10, Batch 90/145, Loss: 0.1047
Epoch 7/10, Batch 100/145, Loss: 0.3509
Epoch 7/10, Batch 110/145, Loss: 0.1673
Epoch 7/10, Batch 120/145, Loss: 0.2576
Epoch 7/10, Batch 130/145, Loss: 0.1532
Epoch 7/10, Batch 140/145, Loss: 0.2668
Epoch 7/10, Train Loss: 0.2139, Valid Loss: 0.2292
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1519
Epoch 8/10, Batch 20/145, Loss: 0.2854
Epoch 8/10, Batch 30/145, Loss: 0.1883
Epoch 8/10, Batch 40/145, Loss: 0.1955
Epoch 8/10, Batch 50/145, Loss: 0.1893
Epoch 8/10, Batch 60/145, Loss: 0.1547
Epoch 8/10, Batch 70/145, Loss: 0.3638
Epoch 8/10, Batch 80/145, Loss: 0.1269
Epoch 8/10, Batch 90/145, Loss: 0.2519
Epoch 8/10, Batch 100/145, Loss: 0.1270
Epoch 8/10, Batch 110/145, Loss: 0.1274
Epoch 8/10, Batch 120/145, Loss: 0.2101
Epoch 8/10, Batch 130/145, Loss: 0.1298
Epoch 8/10, Batch 140/145, Loss: 0.1798
Epoch 8/10, Train Loss: 0.2132, Valid Loss: 0.2240
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3188
Epoch 9/10, Batch 20/145, Loss: 0.1809
Epoch 9/10, Batch 30/145, Loss: 0.1928
Epoch 9/10, Batch 40/145, Loss: 0.1159
Epoch 9/10, Batch 50/145, Loss: 0.0848
Epoch 9/10, Batch 60/145, Loss: 0.1645
Epoch 9/10, Batch 70/145, Loss: 0.1070
Epoch 9/10, Batch 80/145, Loss: 0.2188
Epoch 9/10, Batch 90/145, Loss: 0.1920
Epoch 9/10, Batch 100/145, Loss: 0.1696
Epoch 9/10, Batch 110/145, Loss: 0.2608
Epoch 9/10, Batch 120/145, Loss: 0.1074
Epoch 9/10, Batch 130/145, Loss: 0.3019
Epoch 9/10, Batch 140/145, Loss: 0.3084
Epoch 9/10, Train Loss: 0.1989, Valid Loss: 0.2174
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0809
Epoch 10/10, Batch 20/145, Loss: 0.1029
Epoch 10/10, Batch 30/145, Loss: 0.1225
Epoch 10/10, Batch 40/145, Loss: 0.1306
Epoch 10/10, Batch 50/145, Loss: 0.2097
Epoch 10/10, Batch 60/145, Loss: 0.2484
Epoch 10/10, Batch 70/145, Loss: 0.3070
Epoch 10/10, Batch 80/145, Loss: 0.2895
Epoch 10/10, Batch 90/145, Loss: 0.1616
Epoch 10/10, Batch 100/145, Loss: 0.3017
Epoch 10/10, Batch 110/145, Loss: 0.1592
Epoch 10/10, Batch 120/145, Loss: 0.1643
Epoch 10/10, Batch 130/145, Loss: 0.1405
Epoch 10/10, Batch 140/145, Loss: 0.2655
Epoch 10/10, Train Loss: 0.1972, Valid Loss: 0.2198
Accuracy: 0.9194
Precision: 0.9189
Recall: 0.9194
F1-score: 0.9189
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3951
Epoch 1/10, Batch 20/145, Loss: 0.9496
Epoch 1/10, Batch 30/145, Loss: 0.9282
Epoch 1/10, Batch 40/145, Loss: 0.7196
Epoch 1/10, Batch 50/145, Loss: 0.7229
Epoch 1/10, Batch 60/145, Loss: 0.6978
Epoch 1/10, Batch 70/145, Loss: 0.4723
Epoch 1/10, Batch 80/145, Loss: 0.6113
Epoch 1/10, Batch 90/145, Loss: 0.3829
Epoch 1/10, Batch 100/145, Loss: 0.4057
Epoch 1/10, Batch 110/145, Loss: 0.4671
Epoch 1/10, Batch 120/145, Loss: 0.6246
Epoch 1/10, Batch 130/145, Loss: 0.4754
Epoch 1/10, Batch 140/145, Loss: 0.3482
Epoch 1/10, Train Loss: 0.6713, Valid Loss: 0.3828
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2989
Epoch 2/10, Batch 20/145, Loss: 0.3184
Epoch 2/10, Batch 30/145, Loss: 0.3171
Epoch 2/10, Batch 40/145, Loss: 0.3750
Epoch 2/10, Batch 50/145, Loss: 0.2177
Epoch 2/10, Batch 60/145, Loss: 0.3789
Epoch 2/10, Batch 70/145, Loss: 0.3344
Epoch 2/10, Batch 80/145, Loss: 0.2366
Epoch 2/10, Batch 90/145, Loss: 0.2680
Epoch 2/10, Batch 100/145, Loss: 0.3892
Epoch 2/10, Batch 110/145, Loss: 0.2852
Epoch 2/10, Batch 120/145, Loss: 0.3583
Epoch 2/10, Batch 130/145, Loss: 0.2540
Epoch 2/10, Batch 140/145, Loss: 0.2596
Epoch 2/10, Train Loss: 0.3475, Valid Loss: 0.3055
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2614
Epoch 3/10, Batch 20/145, Loss: 0.3464
Epoch 3/10, Batch 30/145, Loss: 0.3597
Epoch 3/10, Batch 40/145, Loss: 0.2713
Epoch 3/10, Batch 50/145, Loss: 0.2866
Epoch 3/10, Batch 60/145, Loss: 0.3997
Epoch 3/10, Batch 70/145, Loss: 0.5228
Epoch 3/10, Batch 80/145, Loss: 0.2214
Epoch 3/10, Batch 90/145, Loss: 0.4705
Epoch 3/10, Batch 100/145, Loss: 0.4095
Epoch 3/10, Batch 110/145, Loss: 0.2451
Epoch 3/10, Batch 120/145, Loss: 0.2116
Epoch 3/10, Batch 130/145, Loss: 0.6590
Epoch 3/10, Batch 140/145, Loss: 0.3571
Epoch 3/10, Train Loss: 0.2895, Valid Loss: 0.2786
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2914
Epoch 4/10, Batch 20/145, Loss: 0.4705
Epoch 4/10, Batch 30/145, Loss: 0.3271
Epoch 4/10, Batch 40/145, Loss: 0.2261
Epoch 4/10, Batch 50/145, Loss: 0.1537
Epoch 4/10, Batch 60/145, Loss: 0.3215
Epoch 4/10, Batch 70/145, Loss: 0.3108
Epoch 4/10, Batch 80/145, Loss: 0.2269
Epoch 4/10, Batch 90/145, Loss: 0.2275
Epoch 4/10, Batch 100/145, Loss: 0.2112
Epoch 4/10, Batch 110/145, Loss: 0.1315
Epoch 4/10, Batch 120/145, Loss: 0.2068
Epoch 4/10, Batch 130/145, Loss: 0.2401
Epoch 4/10, Batch 140/145, Loss: 0.1317
Epoch 4/10, Train Loss: 0.2513, Valid Loss: 0.2664
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1965
Epoch 5/10, Batch 20/145, Loss: 0.2197
Epoch 5/10, Batch 30/145, Loss: 0.2483
Epoch 5/10, Batch 40/145, Loss: 0.1244
Epoch 5/10, Batch 50/145, Loss: 0.2409
Epoch 5/10, Batch 60/145, Loss: 0.2005
Epoch 5/10, Batch 70/145, Loss: 0.1895
Epoch 5/10, Batch 80/145, Loss: 0.2335
Epoch 5/10, Batch 90/145, Loss: 0.2628
Epoch 5/10, Batch 100/145, Loss: 0.2923
Epoch 5/10, Batch 110/145, Loss: 0.1328
Epoch 5/10, Batch 120/145, Loss: 0.3477
Epoch 5/10, Batch 130/145, Loss: 0.1845
Epoch 5/10, Batch 140/145, Loss: 0.1409
Epoch 5/10, Train Loss: 0.2315, Valid Loss: 0.2590
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2064
Epoch 6/10, Batch 20/145, Loss: 0.4097
Epoch 6/10, Batch 30/145, Loss: 0.2868
Epoch 6/10, Batch 40/145, Loss: 0.1281
Epoch 6/10, Batch 50/145, Loss: 0.3306
Epoch 6/10, Batch 60/145, Loss: 0.2178
Epoch 6/10, Batch 70/145, Loss: 0.1129
Epoch 6/10, Batch 80/145, Loss: 0.1397
Epoch 6/10, Batch 90/145, Loss: 0.2175
Epoch 6/10, Batch 100/145, Loss: 0.2365
Epoch 6/10, Batch 110/145, Loss: 0.1864
Epoch 6/10, Batch 120/145, Loss: 0.2909
Epoch 6/10, Batch 130/145, Loss: 0.1876
Epoch 6/10, Batch 140/145, Loss: 0.0705
Epoch 6/10, Train Loss: 0.2168, Valid Loss: 0.2494
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2711
Epoch 7/10, Batch 20/145, Loss: 0.4246
Epoch 7/10, Batch 30/145, Loss: 0.3534
Epoch 7/10, Batch 40/145, Loss: 0.4640
Epoch 7/10, Batch 50/145, Loss: 0.1781
Epoch 7/10, Batch 60/145, Loss: 0.1620
Epoch 7/10, Batch 70/145, Loss: 0.2808
Epoch 7/10, Batch 80/145, Loss: 0.5142
Epoch 7/10, Batch 90/145, Loss: 0.1872
Epoch 7/10, Batch 100/145, Loss: 0.1584
Epoch 7/10, Batch 110/145, Loss: 0.1256
Epoch 7/10, Batch 120/145, Loss: 0.1287
Epoch 7/10, Batch 130/145, Loss: 0.1584
Epoch 7/10, Batch 140/145, Loss: 0.4389
Epoch 7/10, Train Loss: 0.2178, Valid Loss: 0.2504
Epoch 8/10, Batch 10/145, Loss: 0.2180
Epoch 8/10, Batch 20/145, Loss: 0.2395
Epoch 8/10, Batch 30/145, Loss: 0.2609
Epoch 8/10, Batch 40/145, Loss: 0.1742
Epoch 8/10, Batch 50/145, Loss: 0.1947
Epoch 8/10, Batch 60/145, Loss: 0.3197
Epoch 8/10, Batch 70/145, Loss: 0.2422
Epoch 8/10, Batch 80/145, Loss: 0.1955
Epoch 8/10, Batch 90/145, Loss: 0.2298
Epoch 8/10, Batch 100/145, Loss: 0.2210
Epoch 8/10, Batch 110/145, Loss: 0.1457
Epoch 8/10, Batch 120/145, Loss: 0.2785
Epoch 8/10, Batch 130/145, Loss: 0.2014
Epoch 8/10, Batch 140/145, Loss: 0.2473
Epoch 8/10, Train Loss: 0.2100, Valid Loss: 0.2395
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2219
Epoch 9/10, Batch 20/145, Loss: 0.1267
Epoch 9/10, Batch 30/145, Loss: 0.1476
Epoch 9/10, Batch 40/145, Loss: 0.1303
Epoch 9/10, Batch 50/145, Loss: 0.2969
Epoch 9/10, Batch 60/145, Loss: 0.1674
Epoch 9/10, Batch 70/145, Loss: 0.3309
Epoch 9/10, Batch 80/145, Loss: 0.1256
Epoch 9/10, Batch 90/145, Loss: 0.1542
Epoch 9/10, Batch 100/145, Loss: 0.1784
Epoch 9/10, Batch 110/145, Loss: 0.2905
Epoch 9/10, Batch 120/145, Loss: 0.0793
Epoch 9/10, Batch 130/145, Loss: 0.3299
Epoch 9/10, Batch 140/145, Loss: 0.2139
Epoch 9/10, Train Loss: 0.1899, Valid Loss: 0.2388
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1632
Epoch 10/10, Batch 20/145, Loss: 0.0807
Epoch 10/10, Batch 30/145, Loss: 0.1197
Epoch 10/10, Batch 40/145, Loss: 0.0871
Epoch 10/10, Batch 50/145, Loss: 0.1727
Epoch 10/10, Batch 60/145, Loss: 0.1058
Epoch 10/10, Batch 70/145, Loss: 0.3649
Epoch 10/10, Batch 80/145, Loss: 0.2736
Epoch 10/10, Batch 90/145, Loss: 0.1884
Epoch 10/10, Batch 100/145, Loss: 0.1308
Epoch 10/10, Batch 110/145, Loss: 0.1303
Epoch 10/10, Batch 120/145, Loss: 0.1324
Epoch 10/10, Batch 130/145, Loss: 0.1015
Epoch 10/10, Batch 140/145, Loss: 0.2062
Epoch 10/10, Train Loss: 0.1869, Valid Loss: 0.2459
Accuracy: 0.9206
Precision: 0.9191
Recall: 0.9206
F1-score: 0.9196
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3307
Epoch 1/10, Batch 20/145, Loss: 0.9797
Epoch 1/10, Batch 30/145, Loss: 0.8391
Epoch 1/10, Batch 40/145, Loss: 0.9003
Epoch 1/10, Batch 50/145, Loss: 0.7047
Epoch 1/10, Batch 60/145, Loss: 0.6207
Epoch 1/10, Batch 70/145, Loss: 0.5497
Epoch 1/10, Batch 80/145, Loss: 0.6186
Epoch 1/10, Batch 90/145, Loss: 0.3436
Epoch 1/10, Batch 100/145, Loss: 0.4268
Epoch 1/10, Batch 110/145, Loss: 0.4634
Epoch 1/10, Batch 120/145, Loss: 0.7625
Epoch 1/10, Batch 130/145, Loss: 0.5420
Epoch 1/10, Batch 140/145, Loss: 0.4171
Epoch 1/10, Train Loss: 0.6780, Valid Loss: 0.3845
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3393
Epoch 2/10, Batch 20/145, Loss: 0.4250
Epoch 2/10, Batch 30/145, Loss: 0.2104
Epoch 2/10, Batch 40/145, Loss: 0.5418
Epoch 2/10, Batch 50/145, Loss: 0.2616
Epoch 2/10, Batch 60/145, Loss: 0.3365
Epoch 2/10, Batch 70/145, Loss: 0.3258
Epoch 2/10, Batch 80/145, Loss: 0.4150
Epoch 2/10, Batch 90/145, Loss: 0.4491
Epoch 2/10, Batch 100/145, Loss: 0.3455
Epoch 2/10, Batch 110/145, Loss: 0.3541
Epoch 2/10, Batch 120/145, Loss: 0.4179
Epoch 2/10, Batch 130/145, Loss: 0.3326
Epoch 2/10, Batch 140/145, Loss: 0.3081
Epoch 2/10, Train Loss: 0.3559, Valid Loss: 0.3022
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3121
Epoch 3/10, Batch 20/145, Loss: 0.2436
Epoch 3/10, Batch 30/145, Loss: 0.4602
Epoch 3/10, Batch 40/145, Loss: 0.1875
Epoch 3/10, Batch 50/145, Loss: 0.2845
Epoch 3/10, Batch 60/145, Loss: 0.3232
Epoch 3/10, Batch 70/145, Loss: 0.4058
Epoch 3/10, Batch 80/145, Loss: 0.2617
Epoch 3/10, Batch 90/145, Loss: 0.2609
Epoch 3/10, Batch 100/145, Loss: 0.1902
Epoch 3/10, Batch 110/145, Loss: 0.2072
Epoch 3/10, Batch 120/145, Loss: 0.2035
Epoch 3/10, Batch 130/145, Loss: 0.3182
Epoch 3/10, Batch 140/145, Loss: 0.2532
Epoch 3/10, Train Loss: 0.2966, Valid Loss: 0.2677
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2146
Epoch 4/10, Batch 20/145, Loss: 0.3260
Epoch 4/10, Batch 30/145, Loss: 0.2444
Epoch 4/10, Batch 40/145, Loss: 0.2443
Epoch 4/10, Batch 50/145, Loss: 0.2654
Epoch 4/10, Batch 60/145, Loss: 0.2741
Epoch 4/10, Batch 70/145, Loss: 0.2559
Epoch 4/10, Batch 80/145, Loss: 0.2130
Epoch 4/10, Batch 90/145, Loss: 0.2061
Epoch 4/10, Batch 100/145, Loss: 0.2855
Epoch 4/10, Batch 110/145, Loss: 0.1325
Epoch 4/10, Batch 120/145, Loss: 0.4220
Epoch 4/10, Batch 130/145, Loss: 0.1981
Epoch 4/10, Batch 140/145, Loss: 0.1091
Epoch 4/10, Train Loss: 0.2586, Valid Loss: 0.2496
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1777
Epoch 5/10, Batch 20/145, Loss: 0.0620
Epoch 5/10, Batch 30/145, Loss: 0.2316
Epoch 5/10, Batch 40/145, Loss: 0.3432
Epoch 5/10, Batch 50/145, Loss: 0.2076
Epoch 5/10, Batch 60/145, Loss: 0.3659
Epoch 5/10, Batch 70/145, Loss: 0.1490
Epoch 5/10, Batch 80/145, Loss: 0.2284
Epoch 5/10, Batch 90/145, Loss: 0.2421
Epoch 5/10, Batch 100/145, Loss: 0.3437
Epoch 5/10, Batch 110/145, Loss: 0.1435
Epoch 5/10, Batch 120/145, Loss: 0.4055
Epoch 5/10, Batch 130/145, Loss: 0.1383
Epoch 5/10, Batch 140/145, Loss: 0.2127
Epoch 5/10, Train Loss: 0.2425, Valid Loss: 0.2488
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1643
Epoch 6/10, Batch 20/145, Loss: 0.3559
Epoch 6/10, Batch 30/145, Loss: 0.2362
Epoch 6/10, Batch 40/145, Loss: 0.1629
Epoch 6/10, Batch 50/145, Loss: 0.2639
Epoch 6/10, Batch 60/145, Loss: 0.1726
Epoch 6/10, Batch 70/145, Loss: 0.1304
Epoch 6/10, Batch 80/145, Loss: 0.2289
Epoch 6/10, Batch 90/145, Loss: 0.2307
Epoch 6/10, Batch 100/145, Loss: 0.2138
Epoch 6/10, Batch 110/145, Loss: 0.1506
Epoch 6/10, Batch 120/145, Loss: 0.2130
Epoch 6/10, Batch 130/145, Loss: 0.1102
Epoch 6/10, Batch 140/145, Loss: 0.2258
Epoch 6/10, Train Loss: 0.2410, Valid Loss: 0.2485
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3509
Epoch 7/10, Batch 20/145, Loss: 0.3673
Epoch 7/10, Batch 30/145, Loss: 0.1600
Epoch 7/10, Batch 40/145, Loss: 0.5351
Epoch 7/10, Batch 50/145, Loss: 0.1564
Epoch 7/10, Batch 60/145, Loss: 0.1288
Epoch 7/10, Batch 70/145, Loss: 0.1815
Epoch 7/10, Batch 80/145, Loss: 0.4400
Epoch 7/10, Batch 90/145, Loss: 0.2548
Epoch 7/10, Batch 100/145, Loss: 0.2158
Epoch 7/10, Batch 110/145, Loss: 0.1467
Epoch 7/10, Batch 120/145, Loss: 0.2218
Epoch 7/10, Batch 130/145, Loss: 0.1051
Epoch 7/10, Batch 140/145, Loss: 0.3291
Epoch 7/10, Train Loss: 0.2133, Valid Loss: 0.2269
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2398
Epoch 8/10, Batch 20/145, Loss: 0.2386
Epoch 8/10, Batch 30/145, Loss: 0.3118
Epoch 8/10, Batch 40/145, Loss: 0.2761
Epoch 8/10, Batch 50/145, Loss: 0.2028
Epoch 8/10, Batch 60/145, Loss: 0.2409
Epoch 8/10, Batch 70/145, Loss: 0.2055
Epoch 8/10, Batch 80/145, Loss: 0.1087
Epoch 8/10, Batch 90/145, Loss: 0.1801
Epoch 8/10, Batch 100/145, Loss: 0.2634
Epoch 8/10, Batch 110/145, Loss: 0.3392
Epoch 8/10, Batch 120/145, Loss: 0.2162
Epoch 8/10, Batch 130/145, Loss: 0.1648
Epoch 8/10, Batch 140/145, Loss: 0.1420
Epoch 8/10, Train Loss: 0.2103, Valid Loss: 0.2220
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3493
Epoch 9/10, Batch 20/145, Loss: 0.1023
Epoch 9/10, Batch 30/145, Loss: 0.0814
Epoch 9/10, Batch 40/145, Loss: 0.3354
Epoch 9/10, Batch 50/145, Loss: 0.1516
Epoch 9/10, Batch 60/145, Loss: 0.1792
Epoch 9/10, Batch 70/145, Loss: 0.1799
Epoch 9/10, Batch 80/145, Loss: 0.1213
Epoch 9/10, Batch 90/145, Loss: 0.1567
Epoch 9/10, Batch 100/145, Loss: 0.1962
Epoch 9/10, Batch 110/145, Loss: 0.1801
Epoch 9/10, Batch 120/145, Loss: 0.1920
Epoch 9/10, Batch 130/145, Loss: 0.1937
Epoch 9/10, Batch 140/145, Loss: 0.1339
Epoch 9/10, Train Loss: 0.1985, Valid Loss: 0.2204
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1979
Epoch 10/10, Batch 20/145, Loss: 0.1635
Epoch 10/10, Batch 30/145, Loss: 0.4014
Epoch 10/10, Batch 40/145, Loss: 0.0874
Epoch 10/10, Batch 50/145, Loss: 0.2701
Epoch 10/10, Batch 60/145, Loss: 0.0859
Epoch 10/10, Batch 70/145, Loss: 0.2065
Epoch 10/10, Batch 80/145, Loss: 0.2150
Epoch 10/10, Batch 90/145, Loss: 0.0824
Epoch 10/10, Batch 100/145, Loss: 0.2642
Epoch 10/10, Batch 110/145, Loss: 0.2164
Epoch 10/10, Batch 120/145, Loss: 0.1942
Epoch 10/10, Batch 130/145, Loss: 0.1097
Epoch 10/10, Batch 140/145, Loss: 0.2102
Epoch 10/10, Train Loss: 0.1970, Valid Loss: 0.2142
Model saved!
Accuracy: 0.9264
Precision: 0.9244
Recall: 0.9264
F1-score: 0.9250
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 7. Fitness: 0.9264
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4259
Epoch 1/10, Batch 20/145, Loss: 0.9219
Epoch 1/10, Batch 30/145, Loss: 0.9044
Epoch 1/10, Batch 40/145, Loss: 0.7625
Epoch 1/10, Batch 50/145, Loss: 0.7775
Epoch 1/10, Batch 60/145, Loss: 0.5040
Epoch 1/10, Batch 70/145, Loss: 0.4906
Epoch 1/10, Batch 80/145, Loss: 0.5027
Epoch 1/10, Batch 90/145, Loss: 0.3272
Epoch 1/10, Batch 100/145, Loss: 0.4695
Epoch 1/10, Batch 110/145, Loss: 0.6121
Epoch 1/10, Batch 120/145, Loss: 0.6497
Epoch 1/10, Batch 130/145, Loss: 0.5465
Epoch 1/10, Batch 140/145, Loss: 0.3662
Epoch 1/10, Train Loss: 0.6762, Valid Loss: 0.3918
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2375
Epoch 2/10, Batch 20/145, Loss: 0.4643
Epoch 2/10, Batch 30/145, Loss: 0.3846
Epoch 2/10, Batch 40/145, Loss: 0.6394
Epoch 2/10, Batch 50/145, Loss: 0.3803
Epoch 2/10, Batch 60/145, Loss: 0.2988
Epoch 2/10, Batch 70/145, Loss: 0.3739
Epoch 2/10, Batch 80/145, Loss: 0.2520
Epoch 2/10, Batch 90/145, Loss: 0.2894
Epoch 2/10, Batch 100/145, Loss: 0.4017
Epoch 2/10, Batch 110/145, Loss: 0.3947
Epoch 2/10, Batch 120/145, Loss: 0.3634
Epoch 2/10, Batch 130/145, Loss: 0.3588
Epoch 2/10, Batch 140/145, Loss: 0.4312
Epoch 2/10, Train Loss: 0.3484, Valid Loss: 0.3087
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2934
Epoch 3/10, Batch 20/145, Loss: 0.4391
Epoch 3/10, Batch 30/145, Loss: 0.2315
Epoch 3/10, Batch 40/145, Loss: 0.2396
Epoch 3/10, Batch 50/145, Loss: 0.2750
Epoch 3/10, Batch 60/145, Loss: 0.3300
Epoch 3/10, Batch 70/145, Loss: 0.4224
Epoch 3/10, Batch 80/145, Loss: 0.2660
Epoch 3/10, Batch 90/145, Loss: 0.1980
Epoch 3/10, Batch 100/145, Loss: 0.1752
Epoch 3/10, Batch 110/145, Loss: 0.1860
Epoch 3/10, Batch 120/145, Loss: 0.2961
Epoch 3/10, Batch 130/145, Loss: 0.5756
Epoch 3/10, Batch 140/145, Loss: 0.1693
Epoch 3/10, Train Loss: 0.2893, Valid Loss: 0.2713
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2955
Epoch 4/10, Batch 20/145, Loss: 0.3298
Epoch 4/10, Batch 30/145, Loss: 0.2740
Epoch 4/10, Batch 40/145, Loss: 0.2367
Epoch 4/10, Batch 50/145, Loss: 0.1852
Epoch 4/10, Batch 60/145, Loss: 0.4606
Epoch 4/10, Batch 70/145, Loss: 0.2171
Epoch 4/10, Batch 80/145, Loss: 0.2155
Epoch 4/10, Batch 90/145, Loss: 0.2601
Epoch 4/10, Batch 100/145, Loss: 0.3017
Epoch 4/10, Batch 110/145, Loss: 0.1906
Epoch 4/10, Batch 120/145, Loss: 0.2303
Epoch 4/10, Batch 130/145, Loss: 0.1508
Epoch 4/10, Batch 140/145, Loss: 0.2783
Epoch 4/10, Train Loss: 0.2549, Valid Loss: 0.2585
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2007
Epoch 5/10, Batch 20/145, Loss: 0.1319
Epoch 5/10, Batch 30/145, Loss: 0.2498
Epoch 5/10, Batch 40/145, Loss: 0.1694
Epoch 5/10, Batch 50/145, Loss: 0.2775
Epoch 5/10, Batch 60/145, Loss: 0.3406
Epoch 5/10, Batch 70/145, Loss: 0.3502
Epoch 5/10, Batch 80/145, Loss: 0.1640
Epoch 5/10, Batch 90/145, Loss: 0.3904
Epoch 5/10, Batch 100/145, Loss: 0.2773
Epoch 5/10, Batch 110/145, Loss: 0.0953
Epoch 5/10, Batch 120/145, Loss: 0.4283
Epoch 5/10, Batch 130/145, Loss: 0.2935
Epoch 5/10, Batch 140/145, Loss: 0.2771
Epoch 5/10, Train Loss: 0.2420, Valid Loss: 0.2456
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1105
Epoch 6/10, Batch 20/145, Loss: 0.4248
Epoch 6/10, Batch 30/145, Loss: 0.2432
Epoch 6/10, Batch 40/145, Loss: 0.1057
Epoch 6/10, Batch 50/145, Loss: 0.2774
Epoch 6/10, Batch 60/145, Loss: 0.1617
Epoch 6/10, Batch 70/145, Loss: 0.2493
Epoch 6/10, Batch 80/145, Loss: 0.1724
Epoch 6/10, Batch 90/145, Loss: 0.3293
Epoch 6/10, Batch 100/145, Loss: 0.3262
Epoch 6/10, Batch 110/145, Loss: 0.1794
Epoch 6/10, Batch 120/145, Loss: 0.3808
Epoch 6/10, Batch 130/145, Loss: 0.2815
Epoch 6/10, Batch 140/145, Loss: 0.1488
Epoch 6/10, Train Loss: 0.2209, Valid Loss: 0.2416
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1367
Epoch 7/10, Batch 20/145, Loss: 0.3109
Epoch 7/10, Batch 30/145, Loss: 0.1779
Epoch 7/10, Batch 40/145, Loss: 0.3458
Epoch 7/10, Batch 50/145, Loss: 0.1477
Epoch 7/10, Batch 60/145, Loss: 0.2104
Epoch 7/10, Batch 70/145, Loss: 0.1860
Epoch 7/10, Batch 80/145, Loss: 0.4750
Epoch 7/10, Batch 90/145, Loss: 0.1914
Epoch 7/10, Batch 100/145, Loss: 0.1667
Epoch 7/10, Batch 110/145, Loss: 0.1447
Epoch 7/10, Batch 120/145, Loss: 0.3210
Epoch 7/10, Batch 130/145, Loss: 0.1855
Epoch 7/10, Batch 140/145, Loss: 0.1936
Epoch 7/10, Train Loss: 0.2173, Valid Loss: 0.2312
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2019
Epoch 8/10, Batch 20/145, Loss: 0.2175
Epoch 8/10, Batch 30/145, Loss: 0.1984
Epoch 8/10, Batch 40/145, Loss: 0.1655
Epoch 8/10, Batch 50/145, Loss: 0.2998
Epoch 8/10, Batch 60/145, Loss: 0.2104
Epoch 8/10, Batch 70/145, Loss: 0.3888
Epoch 8/10, Batch 80/145, Loss: 0.1605
Epoch 8/10, Batch 90/145, Loss: 0.2112
Epoch 8/10, Batch 100/145, Loss: 0.2893
Epoch 8/10, Batch 110/145, Loss: 0.1682
Epoch 8/10, Batch 120/145, Loss: 0.1422
Epoch 8/10, Batch 130/145, Loss: 0.1100
Epoch 8/10, Batch 140/145, Loss: 0.0714
Epoch 8/10, Train Loss: 0.2121, Valid Loss: 0.2270
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2198
Epoch 9/10, Batch 20/145, Loss: 0.1704
Epoch 9/10, Batch 30/145, Loss: 0.1121
Epoch 9/10, Batch 40/145, Loss: 0.2086
Epoch 9/10, Batch 50/145, Loss: 0.2253
Epoch 9/10, Batch 60/145, Loss: 0.2450
Epoch 9/10, Batch 70/145, Loss: 0.1629
Epoch 9/10, Batch 80/145, Loss: 0.1408
Epoch 9/10, Batch 90/145, Loss: 0.2120
Epoch 9/10, Batch 100/145, Loss: 0.1458
Epoch 9/10, Batch 110/145, Loss: 0.2471
Epoch 9/10, Batch 120/145, Loss: 0.1169
Epoch 9/10, Batch 130/145, Loss: 0.2699
Epoch 9/10, Batch 140/145, Loss: 0.1817
Epoch 9/10, Train Loss: 0.1978, Valid Loss: 0.2274
Epoch 10/10, Batch 10/145, Loss: 0.0687
Epoch 10/10, Batch 20/145, Loss: 0.1465
Epoch 10/10, Batch 30/145, Loss: 0.0953
Epoch 10/10, Batch 40/145, Loss: 0.2836
Epoch 10/10, Batch 50/145, Loss: 0.0951
Epoch 10/10, Batch 60/145, Loss: 0.2058
Epoch 10/10, Batch 70/145, Loss: 0.2560
Epoch 10/10, Batch 80/145, Loss: 0.1281
Epoch 10/10, Batch 90/145, Loss: 0.1660
Epoch 10/10, Batch 100/145, Loss: 0.2616
Epoch 10/10, Batch 110/145, Loss: 0.2573
Epoch 10/10, Batch 120/145, Loss: 0.2568
Epoch 10/10, Batch 130/145, Loss: 0.1555
Epoch 10/10, Batch 140/145, Loss: 0.2258
Epoch 10/10, Train Loss: 0.1954, Valid Loss: 0.2208
Model saved!
Accuracy: 0.9217
Precision: 0.9193
Recall: 0.9217
F1-score: 0.9198
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3719
Epoch 1/10, Batch 20/145, Loss: 0.8943
Epoch 1/10, Batch 30/145, Loss: 0.9352
Epoch 1/10, Batch 40/145, Loss: 0.7864
Epoch 1/10, Batch 50/145, Loss: 0.7071
Epoch 1/10, Batch 60/145, Loss: 0.8229
Epoch 1/10, Batch 70/145, Loss: 0.5351
Epoch 1/10, Batch 80/145, Loss: 0.7041
Epoch 1/10, Batch 90/145, Loss: 0.4992
Epoch 1/10, Batch 100/145, Loss: 0.4790
Epoch 1/10, Batch 110/145, Loss: 0.4756
Epoch 1/10, Batch 120/145, Loss: 0.5196
Epoch 1/10, Batch 130/145, Loss: 0.4941
Epoch 1/10, Batch 140/145, Loss: 0.3669
Epoch 1/10, Train Loss: 0.6812, Valid Loss: 0.3819
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3123
Epoch 2/10, Batch 20/145, Loss: 0.2776
Epoch 2/10, Batch 30/145, Loss: 0.2738
Epoch 2/10, Batch 40/145, Loss: 0.3754
Epoch 2/10, Batch 50/145, Loss: 0.3874
Epoch 2/10, Batch 60/145, Loss: 0.4600
Epoch 2/10, Batch 70/145, Loss: 0.4063
Epoch 2/10, Batch 80/145, Loss: 0.2843
Epoch 2/10, Batch 90/145, Loss: 0.2445
Epoch 2/10, Batch 100/145, Loss: 0.2066
Epoch 2/10, Batch 110/145, Loss: 0.3568
Epoch 2/10, Batch 120/145, Loss: 0.2208
Epoch 2/10, Batch 130/145, Loss: 0.3293
Epoch 2/10, Batch 140/145, Loss: 0.4169
Epoch 2/10, Train Loss: 0.3536, Valid Loss: 0.2956
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3689
Epoch 3/10, Batch 20/145, Loss: 0.2758
Epoch 3/10, Batch 30/145, Loss: 0.3008
Epoch 3/10, Batch 40/145, Loss: 0.2271
Epoch 3/10, Batch 50/145, Loss: 0.2357
Epoch 3/10, Batch 60/145, Loss: 0.3210
Epoch 3/10, Batch 70/145, Loss: 0.2899
Epoch 3/10, Batch 80/145, Loss: 0.2812
Epoch 3/10, Batch 90/145, Loss: 0.3146
Epoch 3/10, Batch 100/145, Loss: 0.2192
Epoch 3/10, Batch 110/145, Loss: 0.1973
Epoch 3/10, Batch 120/145, Loss: 0.2291
Epoch 3/10, Batch 130/145, Loss: 0.2303
Epoch 3/10, Batch 140/145, Loss: 0.2660
Epoch 3/10, Train Loss: 0.2949, Valid Loss: 0.2658
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4122
Epoch 4/10, Batch 20/145, Loss: 0.2902
Epoch 4/10, Batch 30/145, Loss: 0.4052
Epoch 4/10, Batch 40/145, Loss: 0.1579
Epoch 4/10, Batch 50/145, Loss: 0.2002
Epoch 4/10, Batch 60/145, Loss: 0.1958
Epoch 4/10, Batch 70/145, Loss: 0.2014
Epoch 4/10, Batch 80/145, Loss: 0.0704
Epoch 4/10, Batch 90/145, Loss: 0.2949
Epoch 4/10, Batch 100/145, Loss: 0.1820
Epoch 4/10, Batch 110/145, Loss: 0.2530
Epoch 4/10, Batch 120/145, Loss: 0.2425
Epoch 4/10, Batch 130/145, Loss: 0.2084
Epoch 4/10, Batch 140/145, Loss: 0.1587
Epoch 4/10, Train Loss: 0.2574, Valid Loss: 0.2458
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2463
Epoch 5/10, Batch 20/145, Loss: 0.1760
Epoch 5/10, Batch 30/145, Loss: 0.2518
Epoch 5/10, Batch 40/145, Loss: 0.1691
Epoch 5/10, Batch 50/145, Loss: 0.1540
Epoch 5/10, Batch 60/145, Loss: 0.1837
Epoch 5/10, Batch 70/145, Loss: 0.2757
Epoch 5/10, Batch 80/145, Loss: 0.3087
Epoch 5/10, Batch 90/145, Loss: 0.1919
Epoch 5/10, Batch 100/145, Loss: 0.5376
Epoch 5/10, Batch 110/145, Loss: 0.3210
Epoch 5/10, Batch 120/145, Loss: 0.4306
Epoch 5/10, Batch 130/145, Loss: 0.1663
Epoch 5/10, Batch 140/145, Loss: 0.2560
Epoch 5/10, Train Loss: 0.2397, Valid Loss: 0.2394
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1151
Epoch 6/10, Batch 20/145, Loss: 0.4804
Epoch 6/10, Batch 30/145, Loss: 0.2525
Epoch 6/10, Batch 40/145, Loss: 0.0982
Epoch 6/10, Batch 50/145, Loss: 0.3624
Epoch 6/10, Batch 60/145, Loss: 0.2131
Epoch 6/10, Batch 70/145, Loss: 0.2758
Epoch 6/10, Batch 80/145, Loss: 0.1629
Epoch 6/10, Batch 90/145, Loss: 0.1163
Epoch 6/10, Batch 100/145, Loss: 0.2712
Epoch 6/10, Batch 110/145, Loss: 0.3365
Epoch 6/10, Batch 120/145, Loss: 0.4736
Epoch 6/10, Batch 130/145, Loss: 0.1732
Epoch 6/10, Batch 140/145, Loss: 0.1606
Epoch 6/10, Train Loss: 0.2316, Valid Loss: 0.2308
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1797
Epoch 7/10, Batch 20/145, Loss: 0.2079
Epoch 7/10, Batch 30/145, Loss: 0.2316
Epoch 7/10, Batch 40/145, Loss: 0.3137
Epoch 7/10, Batch 50/145, Loss: 0.1668
Epoch 7/10, Batch 60/145, Loss: 0.1967
Epoch 7/10, Batch 70/145, Loss: 0.1394
Epoch 7/10, Batch 80/145, Loss: 0.3738
Epoch 7/10, Batch 90/145, Loss: 0.1097
Epoch 7/10, Batch 100/145, Loss: 0.1490
Epoch 7/10, Batch 110/145, Loss: 0.2089
Epoch 7/10, Batch 120/145, Loss: 0.1406
Epoch 7/10, Batch 130/145, Loss: 0.2304
Epoch 7/10, Batch 140/145, Loss: 0.1936
Epoch 7/10, Train Loss: 0.2173, Valid Loss: 0.2191
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.3897
Epoch 8/10, Batch 20/145, Loss: 0.0556
Epoch 8/10, Batch 30/145, Loss: 0.1493
Epoch 8/10, Batch 40/145, Loss: 0.1559
Epoch 8/10, Batch 50/145, Loss: 0.3720
Epoch 8/10, Batch 60/145, Loss: 0.1474
Epoch 8/10, Batch 70/145, Loss: 0.2825
Epoch 8/10, Batch 80/145, Loss: 0.3814
Epoch 8/10, Batch 90/145, Loss: 0.3312
Epoch 8/10, Batch 100/145, Loss: 0.2917
Epoch 8/10, Batch 110/145, Loss: 0.1335
Epoch 8/10, Batch 120/145, Loss: 0.0962
Epoch 8/10, Batch 130/145, Loss: 0.1886
Epoch 8/10, Batch 140/145, Loss: 0.2923
Epoch 8/10, Train Loss: 0.2032, Valid Loss: 0.2263
Epoch 9/10, Batch 10/145, Loss: 0.2548
Epoch 9/10, Batch 20/145, Loss: 0.2686
Epoch 9/10, Batch 30/145, Loss: 0.2885
Epoch 9/10, Batch 40/145, Loss: 0.2789
Epoch 9/10, Batch 50/145, Loss: 0.1237
Epoch 9/10, Batch 60/145, Loss: 0.2215
Epoch 9/10, Batch 70/145, Loss: 0.1406
Epoch 9/10, Batch 80/145, Loss: 0.2133
Epoch 9/10, Batch 90/145, Loss: 0.1951
Epoch 9/10, Batch 100/145, Loss: 0.2738
Epoch 9/10, Batch 110/145, Loss: 0.3216
Epoch 9/10, Batch 120/145, Loss: 0.1382
Epoch 9/10, Batch 130/145, Loss: 0.1806
Epoch 9/10, Batch 140/145, Loss: 0.3737
Epoch 9/10, Train Loss: 0.2008, Valid Loss: 0.2160
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1307
Epoch 10/10, Batch 20/145, Loss: 0.1167
Epoch 10/10, Batch 30/145, Loss: 0.0641
Epoch 10/10, Batch 40/145, Loss: 0.1588
Epoch 10/10, Batch 50/145, Loss: 0.2000
Epoch 10/10, Batch 60/145, Loss: 0.1519
Epoch 10/10, Batch 70/145, Loss: 0.2373
Epoch 10/10, Batch 80/145, Loss: 0.1278
Epoch 10/10, Batch 90/145, Loss: 0.1508
Epoch 10/10, Batch 100/145, Loss: 0.1872
Epoch 10/10, Batch 110/145, Loss: 0.2283
Epoch 10/10, Batch 120/145, Loss: 0.0921
Epoch 10/10, Batch 130/145, Loss: 0.1836
Epoch 10/10, Batch 140/145, Loss: 0.2456
Epoch 10/10, Train Loss: 0.1963, Valid Loss: 0.2214
Accuracy: 0.9241
Precision: 0.9232
Recall: 0.9241
F1-score: 0.9235
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4028
Epoch 1/10, Batch 20/145, Loss: 0.8269
Epoch 1/10, Batch 30/145, Loss: 0.8963
Epoch 1/10, Batch 40/145, Loss: 0.8094
Epoch 1/10, Batch 50/145, Loss: 0.6674
Epoch 1/10, Batch 60/145, Loss: 0.5800
Epoch 1/10, Batch 70/145, Loss: 0.5210
Epoch 1/10, Batch 80/145, Loss: 0.6834
Epoch 1/10, Batch 90/145, Loss: 0.3725
Epoch 1/10, Batch 100/145, Loss: 0.4221
Epoch 1/10, Batch 110/145, Loss: 0.5262
Epoch 1/10, Batch 120/145, Loss: 0.5371
Epoch 1/10, Batch 130/145, Loss: 0.4826
Epoch 1/10, Batch 140/145, Loss: 0.4247
Epoch 1/10, Train Loss: 0.6796, Valid Loss: 0.3893
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3082
Epoch 2/10, Batch 20/145, Loss: 0.2867
Epoch 2/10, Batch 30/145, Loss: 0.3328
Epoch 2/10, Batch 40/145, Loss: 0.3605
Epoch 2/10, Batch 50/145, Loss: 0.2949
Epoch 2/10, Batch 60/145, Loss: 0.4115
Epoch 2/10, Batch 70/145, Loss: 0.2018
Epoch 2/10, Batch 80/145, Loss: 0.2052
Epoch 2/10, Batch 90/145, Loss: 0.3433
Epoch 2/10, Batch 100/145, Loss: 0.2983
Epoch 2/10, Batch 110/145, Loss: 0.2736
Epoch 2/10, Batch 120/145, Loss: 0.4591
Epoch 2/10, Batch 130/145, Loss: 0.3196
Epoch 2/10, Batch 140/145, Loss: 0.3198
Epoch 2/10, Train Loss: 0.3572, Valid Loss: 0.3030
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2559
Epoch 3/10, Batch 20/145, Loss: 0.1921
Epoch 3/10, Batch 30/145, Loss: 0.2862
Epoch 3/10, Batch 40/145, Loss: 0.2374
Epoch 3/10, Batch 50/145, Loss: 0.2232
Epoch 3/10, Batch 60/145, Loss: 0.3344
Epoch 3/10, Batch 70/145, Loss: 0.3543
Epoch 3/10, Batch 80/145, Loss: 0.3601
Epoch 3/10, Batch 90/145, Loss: 0.3394
Epoch 3/10, Batch 100/145, Loss: 0.3821
Epoch 3/10, Batch 110/145, Loss: 0.1623
Epoch 3/10, Batch 120/145, Loss: 0.1854
Epoch 3/10, Batch 130/145, Loss: 0.2841
Epoch 3/10, Batch 140/145, Loss: 0.2128
Epoch 3/10, Train Loss: 0.2952, Valid Loss: 0.2653
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3325
Epoch 4/10, Batch 20/145, Loss: 0.3261
Epoch 4/10, Batch 30/145, Loss: 0.2169
Epoch 4/10, Batch 40/145, Loss: 0.1934
Epoch 4/10, Batch 50/145, Loss: 0.1851
Epoch 4/10, Batch 60/145, Loss: 0.3347
Epoch 4/10, Batch 70/145, Loss: 0.2336
Epoch 4/10, Batch 80/145, Loss: 0.1302
Epoch 4/10, Batch 90/145, Loss: 0.2232
Epoch 4/10, Batch 100/145, Loss: 0.5376
Epoch 4/10, Batch 110/145, Loss: 0.1003
Epoch 4/10, Batch 120/145, Loss: 0.3453
Epoch 4/10, Batch 130/145, Loss: 0.1384
Epoch 4/10, Batch 140/145, Loss: 0.2047
Epoch 4/10, Train Loss: 0.2596, Valid Loss: 0.2486
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1542
Epoch 5/10, Batch 20/145, Loss: 0.0696
Epoch 5/10, Batch 30/145, Loss: 0.2368
Epoch 5/10, Batch 40/145, Loss: 0.1818
Epoch 5/10, Batch 50/145, Loss: 0.1956
Epoch 5/10, Batch 60/145, Loss: 0.4162
Epoch 5/10, Batch 70/145, Loss: 0.3660
Epoch 5/10, Batch 80/145, Loss: 0.2496
Epoch 5/10, Batch 90/145, Loss: 0.3323
Epoch 5/10, Batch 100/145, Loss: 0.1881
Epoch 5/10, Batch 110/145, Loss: 0.2932
Epoch 5/10, Batch 120/145, Loss: 0.2583
Epoch 5/10, Batch 130/145, Loss: 0.2720
Epoch 5/10, Batch 140/145, Loss: 0.4054
Epoch 5/10, Train Loss: 0.2450, Valid Loss: 0.2369
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2108
Epoch 6/10, Batch 20/145, Loss: 0.4120
Epoch 6/10, Batch 30/145, Loss: 0.2018
Epoch 6/10, Batch 40/145, Loss: 0.1352
Epoch 6/10, Batch 50/145, Loss: 0.2839
Epoch 6/10, Batch 60/145, Loss: 0.1666
Epoch 6/10, Batch 70/145, Loss: 0.1676
Epoch 6/10, Batch 80/145, Loss: 0.1783
Epoch 6/10, Batch 90/145, Loss: 0.2212
Epoch 6/10, Batch 100/145, Loss: 0.2755
Epoch 6/10, Batch 110/145, Loss: 0.1242
Epoch 6/10, Batch 120/145, Loss: 0.4377
Epoch 6/10, Batch 130/145, Loss: 0.2124
Epoch 6/10, Batch 140/145, Loss: 0.3417
Epoch 6/10, Train Loss: 0.2261, Valid Loss: 0.2290
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2898
Epoch 7/10, Batch 20/145, Loss: 0.2188
Epoch 7/10, Batch 30/145, Loss: 0.1009
Epoch 7/10, Batch 40/145, Loss: 0.3816
Epoch 7/10, Batch 50/145, Loss: 0.3198
Epoch 7/10, Batch 60/145, Loss: 0.1601
Epoch 7/10, Batch 70/145, Loss: 0.1936
Epoch 7/10, Batch 80/145, Loss: 0.5273
Epoch 7/10, Batch 90/145, Loss: 0.1262
Epoch 7/10, Batch 100/145, Loss: 0.1739
Epoch 7/10, Batch 110/145, Loss: 0.1480
Epoch 7/10, Batch 120/145, Loss: 0.2166
Epoch 7/10, Batch 130/145, Loss: 0.1323
Epoch 7/10, Batch 140/145, Loss: 0.2517
Epoch 7/10, Train Loss: 0.2180, Valid Loss: 0.2264
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1435
Epoch 8/10, Batch 20/145, Loss: 0.1488
Epoch 8/10, Batch 30/145, Loss: 0.2880
Epoch 8/10, Batch 40/145, Loss: 0.1028
Epoch 8/10, Batch 50/145, Loss: 0.2355
Epoch 8/10, Batch 60/145, Loss: 0.1800
Epoch 8/10, Batch 70/145, Loss: 0.2130
Epoch 8/10, Batch 80/145, Loss: 0.2427
Epoch 8/10, Batch 90/145, Loss: 0.2047
Epoch 8/10, Batch 100/145, Loss: 0.2784
Epoch 8/10, Batch 110/145, Loss: 0.1999
Epoch 8/10, Batch 120/145, Loss: 0.2543
Epoch 8/10, Batch 130/145, Loss: 0.1084
Epoch 8/10, Batch 140/145, Loss: 0.1590
Epoch 8/10, Train Loss: 0.2058, Valid Loss: 0.2113
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2664
Epoch 9/10, Batch 20/145, Loss: 0.1049
Epoch 9/10, Batch 30/145, Loss: 0.1930
Epoch 9/10, Batch 40/145, Loss: 0.2051
Epoch 9/10, Batch 50/145, Loss: 0.1548
Epoch 9/10, Batch 60/145, Loss: 0.3892
Epoch 9/10, Batch 70/145, Loss: 0.1893
Epoch 9/10, Batch 80/145, Loss: 0.1815
Epoch 9/10, Batch 90/145, Loss: 0.2302
Epoch 9/10, Batch 100/145, Loss: 0.0951
Epoch 9/10, Batch 110/145, Loss: 0.2267
Epoch 9/10, Batch 120/145, Loss: 0.3203
Epoch 9/10, Batch 130/145, Loss: 0.3168
Epoch 9/10, Batch 140/145, Loss: 0.2259
Epoch 9/10, Train Loss: 0.2063, Valid Loss: 0.2100
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0666
Epoch 10/10, Batch 20/145, Loss: 0.1887
Epoch 10/10, Batch 30/145, Loss: 0.1804
Epoch 10/10, Batch 40/145, Loss: 0.2113
Epoch 10/10, Batch 50/145, Loss: 0.1641
Epoch 10/10, Batch 60/145, Loss: 0.2278
Epoch 10/10, Batch 70/145, Loss: 0.1990
Epoch 10/10, Batch 80/145, Loss: 0.3310
Epoch 10/10, Batch 90/145, Loss: 0.0700
Epoch 10/10, Batch 100/145, Loss: 0.2649
Epoch 10/10, Batch 110/145, Loss: 0.1596
Epoch 10/10, Batch 120/145, Loss: 0.1527
Epoch 10/10, Batch 130/145, Loss: 0.1690
Epoch 10/10, Batch 140/145, Loss: 0.1153
Epoch 10/10, Train Loss: 0.1938, Valid Loss: 0.2156
Accuracy: 0.9206
Precision: 0.9182
Recall: 0.9206
F1-score: 0.9191
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3942
Epoch 1/10, Batch 20/145, Loss: 0.9422
Epoch 1/10, Batch 30/145, Loss: 0.8149
Epoch 1/10, Batch 40/145, Loss: 0.7820
Epoch 1/10, Batch 50/145, Loss: 0.6258
Epoch 1/10, Batch 60/145, Loss: 0.6398
Epoch 1/10, Batch 70/145, Loss: 0.4076
Epoch 1/10, Batch 80/145, Loss: 0.6068
Epoch 1/10, Batch 90/145, Loss: 0.3693
Epoch 1/10, Batch 100/145, Loss: 0.4969
Epoch 1/10, Batch 110/145, Loss: 0.4736
Epoch 1/10, Batch 120/145, Loss: 0.4743
Epoch 1/10, Batch 130/145, Loss: 0.5032
Epoch 1/10, Batch 140/145, Loss: 0.3137
Epoch 1/10, Train Loss: 0.6808, Valid Loss: 0.3691
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3388
Epoch 2/10, Batch 20/145, Loss: 0.3537
Epoch 2/10, Batch 30/145, Loss: 0.4260
Epoch 2/10, Batch 40/145, Loss: 0.5391
Epoch 2/10, Batch 50/145, Loss: 0.3878
Epoch 2/10, Batch 60/145, Loss: 0.2182
Epoch 2/10, Batch 70/145, Loss: 0.3944
Epoch 2/10, Batch 80/145, Loss: 0.3853
Epoch 2/10, Batch 90/145, Loss: 0.3451
Epoch 2/10, Batch 100/145, Loss: 0.2524
Epoch 2/10, Batch 110/145, Loss: 0.2659
Epoch 2/10, Batch 120/145, Loss: 0.2945
Epoch 2/10, Batch 130/145, Loss: 0.2185
Epoch 2/10, Batch 140/145, Loss: 0.3931
Epoch 2/10, Train Loss: 0.3515, Valid Loss: 0.2874
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2061
Epoch 3/10, Batch 20/145, Loss: 0.2164
Epoch 3/10, Batch 30/145, Loss: 0.4162
Epoch 3/10, Batch 40/145, Loss: 0.2753
Epoch 3/10, Batch 50/145, Loss: 0.2247
Epoch 3/10, Batch 60/145, Loss: 0.4288
Epoch 3/10, Batch 70/145, Loss: 0.3262
Epoch 3/10, Batch 80/145, Loss: 0.3486
Epoch 3/10, Batch 90/145, Loss: 0.2967
Epoch 3/10, Batch 100/145, Loss: 0.2243
Epoch 3/10, Batch 110/145, Loss: 0.2183
Epoch 3/10, Batch 120/145, Loss: 0.3220
Epoch 3/10, Batch 130/145, Loss: 0.1842
Epoch 3/10, Batch 140/145, Loss: 0.2738
Epoch 3/10, Train Loss: 0.2934, Valid Loss: 0.2529
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4088
Epoch 4/10, Batch 20/145, Loss: 0.3503
Epoch 4/10, Batch 30/145, Loss: 0.2503
Epoch 4/10, Batch 40/145, Loss: 0.1143
Epoch 4/10, Batch 50/145, Loss: 0.1352
Epoch 4/10, Batch 60/145, Loss: 0.2590
Epoch 4/10, Batch 70/145, Loss: 0.2699
Epoch 4/10, Batch 80/145, Loss: 0.1678
Epoch 4/10, Batch 90/145, Loss: 0.2863
Epoch 4/10, Batch 100/145, Loss: 0.3360
Epoch 4/10, Batch 110/145, Loss: 0.1355
Epoch 4/10, Batch 120/145, Loss: 0.1877
Epoch 4/10, Batch 130/145, Loss: 0.1284
Epoch 4/10, Batch 140/145, Loss: 0.1568
Epoch 4/10, Train Loss: 0.2544, Valid Loss: 0.2425
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1905
Epoch 5/10, Batch 20/145, Loss: 0.1706
Epoch 5/10, Batch 30/145, Loss: 0.3125
Epoch 5/10, Batch 40/145, Loss: 0.1893
Epoch 5/10, Batch 50/145, Loss: 0.2561
Epoch 5/10, Batch 60/145, Loss: 0.1786
Epoch 5/10, Batch 70/145, Loss: 0.2435
Epoch 5/10, Batch 80/145, Loss: 0.2797
Epoch 5/10, Batch 90/145, Loss: 0.2945
Epoch 5/10, Batch 100/145, Loss: 0.1462
Epoch 5/10, Batch 110/145, Loss: 0.1955
Epoch 5/10, Batch 120/145, Loss: 0.1901
Epoch 5/10, Batch 130/145, Loss: 0.1583
Epoch 5/10, Batch 140/145, Loss: 0.2326
Epoch 5/10, Train Loss: 0.2401, Valid Loss: 0.2326
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.0870
Epoch 6/10, Batch 20/145, Loss: 0.4254
Epoch 6/10, Batch 30/145, Loss: 0.3300
Epoch 6/10, Batch 40/145, Loss: 0.1573
Epoch 6/10, Batch 50/145, Loss: 0.2769
Epoch 6/10, Batch 60/145, Loss: 0.2651
Epoch 6/10, Batch 70/145, Loss: 0.2074
Epoch 6/10, Batch 80/145, Loss: 0.1714
Epoch 6/10, Batch 90/145, Loss: 0.2805
Epoch 6/10, Batch 100/145, Loss: 0.3420
Epoch 6/10, Batch 110/145, Loss: 0.3420
Epoch 6/10, Batch 120/145, Loss: 0.3222
Epoch 6/10, Batch 130/145, Loss: 0.1652
Epoch 6/10, Batch 140/145, Loss: 0.1671
Epoch 6/10, Train Loss: 0.2205, Valid Loss: 0.2230
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1547
Epoch 7/10, Batch 20/145, Loss: 0.2980
Epoch 7/10, Batch 30/145, Loss: 0.2635
Epoch 7/10, Batch 40/145, Loss: 0.2696
Epoch 7/10, Batch 50/145, Loss: 0.2395
Epoch 7/10, Batch 60/145, Loss: 0.1889
Epoch 7/10, Batch 70/145, Loss: 0.0943
Epoch 7/10, Batch 80/145, Loss: 0.3293
Epoch 7/10, Batch 90/145, Loss: 0.2398
Epoch 7/10, Batch 100/145, Loss: 0.1224
Epoch 7/10, Batch 110/145, Loss: 0.2353
Epoch 7/10, Batch 120/145, Loss: 0.1815
Epoch 7/10, Batch 130/145, Loss: 0.1787
Epoch 7/10, Batch 140/145, Loss: 0.1729
Epoch 7/10, Train Loss: 0.2054, Valid Loss: 0.2171
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1913
Epoch 8/10, Batch 20/145, Loss: 0.1896
Epoch 8/10, Batch 30/145, Loss: 0.1291
Epoch 8/10, Batch 40/145, Loss: 0.2820
Epoch 8/10, Batch 50/145, Loss: 0.3124
Epoch 8/10, Batch 60/145, Loss: 0.2677
Epoch 8/10, Batch 70/145, Loss: 0.2255
Epoch 8/10, Batch 80/145, Loss: 0.1586
Epoch 8/10, Batch 90/145, Loss: 0.2142
Epoch 8/10, Batch 100/145, Loss: 0.1750
Epoch 8/10, Batch 110/145, Loss: 0.2997
Epoch 8/10, Batch 120/145, Loss: 0.3594
Epoch 8/10, Batch 130/145, Loss: 0.2030
Epoch 8/10, Batch 140/145, Loss: 0.1779
Epoch 8/10, Train Loss: 0.2053, Valid Loss: 0.2211
Epoch 9/10, Batch 10/145, Loss: 0.2729
Epoch 9/10, Batch 20/145, Loss: 0.1497
Epoch 9/10, Batch 30/145, Loss: 0.1870
Epoch 9/10, Batch 40/145, Loss: 0.4256
Epoch 9/10, Batch 50/145, Loss: 0.0716
Epoch 9/10, Batch 60/145, Loss: 0.1745
Epoch 9/10, Batch 70/145, Loss: 0.2537
Epoch 9/10, Batch 80/145, Loss: 0.0868
Epoch 9/10, Batch 90/145, Loss: 0.1639
Epoch 9/10, Batch 100/145, Loss: 0.2255
Epoch 9/10, Batch 110/145, Loss: 0.2578
Epoch 9/10, Batch 120/145, Loss: 0.2022
Epoch 9/10, Batch 130/145, Loss: 0.1745
Epoch 9/10, Batch 140/145, Loss: 0.1622
Epoch 9/10, Train Loss: 0.1900, Valid Loss: 0.2139
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0760
Epoch 10/10, Batch 20/145, Loss: 0.1300
Epoch 10/10, Batch 30/145, Loss: 0.1621
Epoch 10/10, Batch 40/145, Loss: 0.1570
Epoch 10/10, Batch 50/145, Loss: 0.1957
Epoch 10/10, Batch 60/145, Loss: 0.1198
Epoch 10/10, Batch 70/145, Loss: 0.2157
Epoch 10/10, Batch 80/145, Loss: 0.4095
Epoch 10/10, Batch 90/145, Loss: 0.1808
Epoch 10/10, Batch 100/145, Loss: 0.1680
Epoch 10/10, Batch 110/145, Loss: 0.2051
Epoch 10/10, Batch 120/145, Loss: 0.3394
Epoch 10/10, Batch 130/145, Loss: 0.1146
Epoch 10/10, Batch 140/145, Loss: 0.1878
Epoch 10/10, Train Loss: 0.1943, Valid Loss: 0.2086
Model saved!
Accuracy: 0.9206
Precision: 0.9180
Recall: 0.9206
F1-score: 0.9188
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4311
Epoch 1/10, Batch 20/145, Loss: 0.9616
Epoch 1/10, Batch 30/145, Loss: 0.9228
Epoch 1/10, Batch 40/145, Loss: 0.8104
Epoch 1/10, Batch 50/145, Loss: 0.7674
Epoch 1/10, Batch 60/145, Loss: 0.6743
Epoch 1/10, Batch 70/145, Loss: 0.5267
Epoch 1/10, Batch 80/145, Loss: 0.4838
Epoch 1/10, Batch 90/145, Loss: 0.4161
Epoch 1/10, Batch 100/145, Loss: 0.4915
Epoch 1/10, Batch 110/145, Loss: 0.5302
Epoch 1/10, Batch 120/145, Loss: 0.4526
Epoch 1/10, Batch 130/145, Loss: 0.4489
Epoch 1/10, Batch 140/145, Loss: 0.3330
Epoch 1/10, Train Loss: 0.6757, Valid Loss: 0.3925
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3254
Epoch 2/10, Batch 20/145, Loss: 0.3657
Epoch 2/10, Batch 30/145, Loss: 0.3225
Epoch 2/10, Batch 40/145, Loss: 0.5074
Epoch 2/10, Batch 50/145, Loss: 0.4052
Epoch 2/10, Batch 60/145, Loss: 0.3869
Epoch 2/10, Batch 70/145, Loss: 0.1491
Epoch 2/10, Batch 80/145, Loss: 0.1983
Epoch 2/10, Batch 90/145, Loss: 0.2995
Epoch 2/10, Batch 100/145, Loss: 0.5211
Epoch 2/10, Batch 110/145, Loss: 0.3784
Epoch 2/10, Batch 120/145, Loss: 0.3262
Epoch 2/10, Batch 130/145, Loss: 0.3424
Epoch 2/10, Batch 140/145, Loss: 0.3523
Epoch 2/10, Train Loss: 0.3463, Valid Loss: 0.3048
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1783
Epoch 3/10, Batch 20/145, Loss: 0.3113
Epoch 3/10, Batch 30/145, Loss: 0.3218
Epoch 3/10, Batch 40/145, Loss: 0.1774
Epoch 3/10, Batch 50/145, Loss: 0.2810
Epoch 3/10, Batch 60/145, Loss: 0.4806
Epoch 3/10, Batch 70/145, Loss: 0.4032
Epoch 3/10, Batch 80/145, Loss: 0.3846
Epoch 3/10, Batch 90/145, Loss: 0.1837
Epoch 3/10, Batch 100/145, Loss: 0.1875
Epoch 3/10, Batch 110/145, Loss: 0.1858
Epoch 3/10, Batch 120/145, Loss: 0.2611
Epoch 3/10, Batch 130/145, Loss: 0.2033
Epoch 3/10, Batch 140/145, Loss: 0.2345
Epoch 3/10, Train Loss: 0.2906, Valid Loss: 0.2679
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2839
Epoch 4/10, Batch 20/145, Loss: 0.2532
Epoch 4/10, Batch 30/145, Loss: 0.4785
Epoch 4/10, Batch 40/145, Loss: 0.1256
Epoch 4/10, Batch 50/145, Loss: 0.1632
Epoch 4/10, Batch 60/145, Loss: 0.1995
Epoch 4/10, Batch 70/145, Loss: 0.1293
Epoch 4/10, Batch 80/145, Loss: 0.1949
Epoch 4/10, Batch 90/145, Loss: 0.2685
Epoch 4/10, Batch 100/145, Loss: 0.2774
Epoch 4/10, Batch 110/145, Loss: 0.1412
Epoch 4/10, Batch 120/145, Loss: 0.2706
Epoch 4/10, Batch 130/145, Loss: 0.2322
Epoch 4/10, Batch 140/145, Loss: 0.3093
Epoch 4/10, Train Loss: 0.2557, Valid Loss: 0.2555
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2054
Epoch 5/10, Batch 20/145, Loss: 0.1637
Epoch 5/10, Batch 30/145, Loss: 0.1686
Epoch 5/10, Batch 40/145, Loss: 0.1929
Epoch 5/10, Batch 50/145, Loss: 0.2520
Epoch 5/10, Batch 60/145, Loss: 0.1706
Epoch 5/10, Batch 70/145, Loss: 0.1976
Epoch 5/10, Batch 80/145, Loss: 0.1647
Epoch 5/10, Batch 90/145, Loss: 0.2430
Epoch 5/10, Batch 100/145, Loss: 0.2068
Epoch 5/10, Batch 110/145, Loss: 0.1814
Epoch 5/10, Batch 120/145, Loss: 0.4700
Epoch 5/10, Batch 130/145, Loss: 0.1892
Epoch 5/10, Batch 140/145, Loss: 0.2479
Epoch 5/10, Train Loss: 0.2391, Valid Loss: 0.2442
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2076
Epoch 6/10, Batch 20/145, Loss: 0.3134
Epoch 6/10, Batch 30/145, Loss: 0.3248
Epoch 6/10, Batch 40/145, Loss: 0.1981
Epoch 6/10, Batch 50/145, Loss: 0.3375
Epoch 6/10, Batch 60/145, Loss: 0.1895
Epoch 6/10, Batch 70/145, Loss: 0.2050
Epoch 6/10, Batch 80/145, Loss: 0.2170
Epoch 6/10, Batch 90/145, Loss: 0.2125
Epoch 6/10, Batch 100/145, Loss: 0.2354
Epoch 6/10, Batch 110/145, Loss: 0.3546
Epoch 6/10, Batch 120/145, Loss: 0.3845
Epoch 6/10, Batch 130/145, Loss: 0.2488
Epoch 6/10, Batch 140/145, Loss: 0.1860
Epoch 6/10, Train Loss: 0.2267, Valid Loss: 0.2378
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1839
Epoch 7/10, Batch 20/145, Loss: 0.3663
Epoch 7/10, Batch 30/145, Loss: 0.2244
Epoch 7/10, Batch 40/145, Loss: 0.4811
Epoch 7/10, Batch 50/145, Loss: 0.1690
Epoch 7/10, Batch 60/145, Loss: 0.2454
Epoch 7/10, Batch 70/145, Loss: 0.1544
Epoch 7/10, Batch 80/145, Loss: 0.3918
Epoch 7/10, Batch 90/145, Loss: 0.1616
Epoch 7/10, Batch 100/145, Loss: 0.0836
Epoch 7/10, Batch 110/145, Loss: 0.1671
Epoch 7/10, Batch 120/145, Loss: 0.1705
Epoch 7/10, Batch 130/145, Loss: 0.0796
Epoch 7/10, Batch 140/145, Loss: 0.3510
Epoch 7/10, Train Loss: 0.2088, Valid Loss: 0.2276
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2412
Epoch 8/10, Batch 20/145, Loss: 0.2948
Epoch 8/10, Batch 30/145, Loss: 0.1081
Epoch 8/10, Batch 40/145, Loss: 0.1333
Epoch 8/10, Batch 50/145, Loss: 0.2011
Epoch 8/10, Batch 60/145, Loss: 0.2563
Epoch 8/10, Batch 70/145, Loss: 0.2360
Epoch 8/10, Batch 80/145, Loss: 0.1806
Epoch 8/10, Batch 90/145, Loss: 0.4012
Epoch 8/10, Batch 100/145, Loss: 0.0794
Epoch 8/10, Batch 110/145, Loss: 0.2269
Epoch 8/10, Batch 120/145, Loss: 0.2529
Epoch 8/10, Batch 130/145, Loss: 0.1519
Epoch 8/10, Batch 140/145, Loss: 0.1779
Epoch 8/10, Train Loss: 0.2061, Valid Loss: 0.2292
Epoch 9/10, Batch 10/145, Loss: 0.4017
Epoch 9/10, Batch 20/145, Loss: 0.3095
Epoch 9/10, Batch 30/145, Loss: 0.1702
Epoch 9/10, Batch 40/145, Loss: 0.2115
Epoch 9/10, Batch 50/145, Loss: 0.1576
Epoch 9/10, Batch 60/145, Loss: 0.4660
Epoch 9/10, Batch 70/145, Loss: 0.2070
Epoch 9/10, Batch 80/145, Loss: 0.1350
Epoch 9/10, Batch 90/145, Loss: 0.3264
Epoch 9/10, Batch 100/145, Loss: 0.1031
Epoch 9/10, Batch 110/145, Loss: 0.1399
Epoch 9/10, Batch 120/145, Loss: 0.0907
Epoch 9/10, Batch 130/145, Loss: 0.1275
Epoch 9/10, Batch 140/145, Loss: 0.2377
Epoch 9/10, Train Loss: 0.1961, Valid Loss: 0.2230
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0776
Epoch 10/10, Batch 20/145, Loss: 0.1394
Epoch 10/10, Batch 30/145, Loss: 0.1394
Epoch 10/10, Batch 40/145, Loss: 0.2013
Epoch 10/10, Batch 50/145, Loss: 0.2641
Epoch 10/10, Batch 60/145, Loss: 0.2311
Epoch 10/10, Batch 70/145, Loss: 0.2708
Epoch 10/10, Batch 80/145, Loss: 0.1011
Epoch 10/10, Batch 90/145, Loss: 0.1243
Epoch 10/10, Batch 100/145, Loss: 0.1640
Epoch 10/10, Batch 110/145, Loss: 0.2337
Epoch 10/10, Batch 120/145, Loss: 0.1586
Epoch 10/10, Batch 130/145, Loss: 0.2499
Epoch 10/10, Batch 140/145, Loss: 0.2567
Epoch 10/10, Train Loss: 0.1899, Valid Loss: 0.2189
Model saved!
Accuracy: 0.9287
Precision: 0.9268
Recall: 0.9287
F1-score: 0.9269
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 12. Fitness: 0.9287
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4328
Epoch 1/10, Batch 20/145, Loss: 1.0139
Epoch 1/10, Batch 30/145, Loss: 0.8306
Epoch 1/10, Batch 40/145, Loss: 0.8544
Epoch 1/10, Batch 50/145, Loss: 0.8366
Epoch 1/10, Batch 60/145, Loss: 0.6403
Epoch 1/10, Batch 70/145, Loss: 0.4511
Epoch 1/10, Batch 80/145, Loss: 0.5290
Epoch 1/10, Batch 90/145, Loss: 0.2718
Epoch 1/10, Batch 100/145, Loss: 0.4903
Epoch 1/10, Batch 110/145, Loss: 0.3203
Epoch 1/10, Batch 120/145, Loss: 0.6039
Epoch 1/10, Batch 130/145, Loss: 0.5954
Epoch 1/10, Batch 140/145, Loss: 0.3537
Epoch 1/10, Train Loss: 0.6748, Valid Loss: 0.3787
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3761
Epoch 2/10, Batch 20/145, Loss: 0.3369
Epoch 2/10, Batch 30/145, Loss: 0.3717
Epoch 2/10, Batch 40/145, Loss: 0.3854
Epoch 2/10, Batch 50/145, Loss: 0.3275
Epoch 2/10, Batch 60/145, Loss: 0.4437
Epoch 2/10, Batch 70/145, Loss: 0.5457
Epoch 2/10, Batch 80/145, Loss: 0.2848
Epoch 2/10, Batch 90/145, Loss: 0.1924
Epoch 2/10, Batch 100/145, Loss: 0.2649
Epoch 2/10, Batch 110/145, Loss: 0.4090
Epoch 2/10, Batch 120/145, Loss: 0.3807
Epoch 2/10, Batch 130/145, Loss: 0.2600
Epoch 2/10, Batch 140/145, Loss: 0.3473
Epoch 2/10, Train Loss: 0.3510, Valid Loss: 0.3017
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2585
Epoch 3/10, Batch 20/145, Loss: 0.2040
Epoch 3/10, Batch 30/145, Loss: 0.4625
Epoch 3/10, Batch 40/145, Loss: 0.2873
Epoch 3/10, Batch 50/145, Loss: 0.2827
Epoch 3/10, Batch 60/145, Loss: 0.5111
Epoch 3/10, Batch 70/145, Loss: 0.2434
Epoch 3/10, Batch 80/145, Loss: 0.3116
Epoch 3/10, Batch 90/145, Loss: 0.2301
Epoch 3/10, Batch 100/145, Loss: 0.2236
Epoch 3/10, Batch 110/145, Loss: 0.1546
Epoch 3/10, Batch 120/145, Loss: 0.2979
Epoch 3/10, Batch 130/145, Loss: 0.3570
Epoch 3/10, Batch 140/145, Loss: 0.4244
Epoch 3/10, Train Loss: 0.2879, Valid Loss: 0.2703
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4058
Epoch 4/10, Batch 20/145, Loss: 0.2468
Epoch 4/10, Batch 30/145, Loss: 0.2943
Epoch 4/10, Batch 40/145, Loss: 0.2869
Epoch 4/10, Batch 50/145, Loss: 0.1840
Epoch 4/10, Batch 60/145, Loss: 0.2743
Epoch 4/10, Batch 70/145, Loss: 0.0970
Epoch 4/10, Batch 80/145, Loss: 0.1803
Epoch 4/10, Batch 90/145, Loss: 0.2344
Epoch 4/10, Batch 100/145, Loss: 0.2944
Epoch 4/10, Batch 110/145, Loss: 0.1046
Epoch 4/10, Batch 120/145, Loss: 0.1701
Epoch 4/10, Batch 130/145, Loss: 0.1685
Epoch 4/10, Batch 140/145, Loss: 0.0942
Epoch 4/10, Train Loss: 0.2592, Valid Loss: 0.2589
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3068
Epoch 5/10, Batch 20/145, Loss: 0.0882
Epoch 5/10, Batch 30/145, Loss: 0.2753
Epoch 5/10, Batch 40/145, Loss: 0.1214
Epoch 5/10, Batch 50/145, Loss: 0.1932
Epoch 5/10, Batch 60/145, Loss: 0.1731
Epoch 5/10, Batch 70/145, Loss: 0.3266
Epoch 5/10, Batch 80/145, Loss: 0.2216
Epoch 5/10, Batch 90/145, Loss: 0.3209
Epoch 5/10, Batch 100/145, Loss: 0.2487
Epoch 5/10, Batch 110/145, Loss: 0.1974
Epoch 5/10, Batch 120/145, Loss: 0.3526
Epoch 5/10, Batch 130/145, Loss: 0.1938
Epoch 5/10, Batch 140/145, Loss: 0.1896
Epoch 5/10, Train Loss: 0.2401, Valid Loss: 0.2455
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1525
Epoch 6/10, Batch 20/145, Loss: 0.3655
Epoch 6/10, Batch 30/145, Loss: 0.3676
Epoch 6/10, Batch 40/145, Loss: 0.1465
Epoch 6/10, Batch 50/145, Loss: 0.3865
Epoch 6/10, Batch 60/145, Loss: 0.0968
Epoch 6/10, Batch 70/145, Loss: 0.1525
Epoch 6/10, Batch 80/145, Loss: 0.2423
Epoch 6/10, Batch 90/145, Loss: 0.3190
Epoch 6/10, Batch 100/145, Loss: 0.2189
Epoch 6/10, Batch 110/145, Loss: 0.2456
Epoch 6/10, Batch 120/145, Loss: 0.2816
Epoch 6/10, Batch 130/145, Loss: 0.0995
Epoch 6/10, Batch 140/145, Loss: 0.2031
Epoch 6/10, Train Loss: 0.2237, Valid Loss: 0.2416
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1523
Epoch 7/10, Batch 20/145, Loss: 0.3274
Epoch 7/10, Batch 30/145, Loss: 0.3606
Epoch 7/10, Batch 40/145, Loss: 0.2810
Epoch 7/10, Batch 50/145, Loss: 0.2378
Epoch 7/10, Batch 60/145, Loss: 0.1079
Epoch 7/10, Batch 70/145, Loss: 0.1881
Epoch 7/10, Batch 80/145, Loss: 0.4270
Epoch 7/10, Batch 90/145, Loss: 0.1162
Epoch 7/10, Batch 100/145, Loss: 0.1760
Epoch 7/10, Batch 110/145, Loss: 0.0887
Epoch 7/10, Batch 120/145, Loss: 0.2346
Epoch 7/10, Batch 130/145, Loss: 0.1074
Epoch 7/10, Batch 140/145, Loss: 0.1722
Epoch 7/10, Train Loss: 0.2131, Valid Loss: 0.2342
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1459
Epoch 8/10, Batch 20/145, Loss: 0.2184
Epoch 8/10, Batch 30/145, Loss: 0.2190
Epoch 8/10, Batch 40/145, Loss: 0.1497
Epoch 8/10, Batch 50/145, Loss: 0.1331
Epoch 8/10, Batch 60/145, Loss: 0.1935
Epoch 8/10, Batch 70/145, Loss: 0.4293
Epoch 8/10, Batch 80/145, Loss: 0.1951
Epoch 8/10, Batch 90/145, Loss: 0.1759
Epoch 8/10, Batch 100/145, Loss: 0.2746
Epoch 8/10, Batch 110/145, Loss: 0.1303
Epoch 8/10, Batch 120/145, Loss: 0.3332
Epoch 8/10, Batch 130/145, Loss: 0.2816
Epoch 8/10, Batch 140/145, Loss: 0.2419
Epoch 8/10, Train Loss: 0.2036, Valid Loss: 0.2262
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2980
Epoch 9/10, Batch 20/145, Loss: 0.1946
Epoch 9/10, Batch 30/145, Loss: 0.1623
Epoch 9/10, Batch 40/145, Loss: 0.1579
Epoch 9/10, Batch 50/145, Loss: 0.1376
Epoch 9/10, Batch 60/145, Loss: 0.3599
Epoch 9/10, Batch 70/145, Loss: 0.1416
Epoch 9/10, Batch 80/145, Loss: 0.0748
Epoch 9/10, Batch 90/145, Loss: 0.3637
Epoch 9/10, Batch 100/145, Loss: 0.1674
Epoch 9/10, Batch 110/145, Loss: 0.2493
Epoch 9/10, Batch 120/145, Loss: 0.1114
Epoch 9/10, Batch 130/145, Loss: 0.1861
Epoch 9/10, Batch 140/145, Loss: 0.2771
Epoch 9/10, Train Loss: 0.1982, Valid Loss: 0.2246
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2164
Epoch 10/10, Batch 20/145, Loss: 0.1746
Epoch 10/10, Batch 30/145, Loss: 0.1915
Epoch 10/10, Batch 40/145, Loss: 0.1504
Epoch 10/10, Batch 50/145, Loss: 0.2576
Epoch 10/10, Batch 60/145, Loss: 0.1341
Epoch 10/10, Batch 70/145, Loss: 0.2197
Epoch 10/10, Batch 80/145, Loss: 0.3121
Epoch 10/10, Batch 90/145, Loss: 0.0923
Epoch 10/10, Batch 100/145, Loss: 0.1978
Epoch 10/10, Batch 110/145, Loss: 0.1443
Epoch 10/10, Batch 120/145, Loss: 0.1315
Epoch 10/10, Batch 130/145, Loss: 0.1986
Epoch 10/10, Batch 140/145, Loss: 0.1548
Epoch 10/10, Train Loss: 0.1944, Valid Loss: 0.2290
Accuracy: 0.9100
Precision: 0.9086
Recall: 0.9100
F1-score: 0.9090
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3400
Epoch 1/10, Batch 20/145, Loss: 0.9527
Epoch 1/10, Batch 30/145, Loss: 0.9380
Epoch 1/10, Batch 40/145, Loss: 0.8440
Epoch 1/10, Batch 50/145, Loss: 0.7043
Epoch 1/10, Batch 60/145, Loss: 0.6617
Epoch 1/10, Batch 70/145, Loss: 0.4950
Epoch 1/10, Batch 80/145, Loss: 0.5010
Epoch 1/10, Batch 90/145, Loss: 0.3586
Epoch 1/10, Batch 100/145, Loss: 0.3806
Epoch 1/10, Batch 110/145, Loss: 0.3638
Epoch 1/10, Batch 120/145, Loss: 0.5532
Epoch 1/10, Batch 130/145, Loss: 0.5561
Epoch 1/10, Batch 140/145, Loss: 0.4844
Epoch 1/10, Train Loss: 0.6720, Valid Loss: 0.3803
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2558
Epoch 2/10, Batch 20/145, Loss: 0.3470
Epoch 2/10, Batch 30/145, Loss: 0.3450
Epoch 2/10, Batch 40/145, Loss: 0.3910
Epoch 2/10, Batch 50/145, Loss: 0.4105
Epoch 2/10, Batch 60/145, Loss: 0.3550
Epoch 2/10, Batch 70/145, Loss: 0.3224
Epoch 2/10, Batch 80/145, Loss: 0.2548
Epoch 2/10, Batch 90/145, Loss: 0.3543
Epoch 2/10, Batch 100/145, Loss: 0.3086
Epoch 2/10, Batch 110/145, Loss: 0.2759
Epoch 2/10, Batch 120/145, Loss: 0.4071
Epoch 2/10, Batch 130/145, Loss: 0.2262
Epoch 2/10, Batch 140/145, Loss: 0.4025
Epoch 2/10, Train Loss: 0.3432, Valid Loss: 0.2951
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2846
Epoch 3/10, Batch 20/145, Loss: 0.2931
Epoch 3/10, Batch 30/145, Loss: 0.3907
Epoch 3/10, Batch 40/145, Loss: 0.3146
Epoch 3/10, Batch 50/145, Loss: 0.4356
Epoch 3/10, Batch 60/145, Loss: 0.5120
Epoch 3/10, Batch 70/145, Loss: 0.2805
Epoch 3/10, Batch 80/145, Loss: 0.3272
Epoch 3/10, Batch 90/145, Loss: 0.3107
Epoch 3/10, Batch 100/145, Loss: 0.3022
Epoch 3/10, Batch 110/145, Loss: 0.1399
Epoch 3/10, Batch 120/145, Loss: 0.2830
Epoch 3/10, Batch 130/145, Loss: 0.4090
Epoch 3/10, Batch 140/145, Loss: 0.2090
Epoch 3/10, Train Loss: 0.2837, Valid Loss: 0.2690
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4504
Epoch 4/10, Batch 20/145, Loss: 0.1975
Epoch 4/10, Batch 30/145, Loss: 0.2392
Epoch 4/10, Batch 40/145, Loss: 0.1019
Epoch 4/10, Batch 50/145, Loss: 0.2350
Epoch 4/10, Batch 60/145, Loss: 0.4260
Epoch 4/10, Batch 70/145, Loss: 0.1854
Epoch 4/10, Batch 80/145, Loss: 0.2607
Epoch 4/10, Batch 90/145, Loss: 0.1807
Epoch 4/10, Batch 100/145, Loss: 0.2534
Epoch 4/10, Batch 110/145, Loss: 0.2500
Epoch 4/10, Batch 120/145, Loss: 0.2389
Epoch 4/10, Batch 130/145, Loss: 0.2210
Epoch 4/10, Batch 140/145, Loss: 0.1225
Epoch 4/10, Train Loss: 0.2532, Valid Loss: 0.2506
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1633
Epoch 5/10, Batch 20/145, Loss: 0.1552
Epoch 5/10, Batch 30/145, Loss: 0.2711
Epoch 5/10, Batch 40/145, Loss: 0.1554
Epoch 5/10, Batch 50/145, Loss: 0.1709
Epoch 5/10, Batch 60/145, Loss: 0.3704
Epoch 5/10, Batch 70/145, Loss: 0.2335
Epoch 5/10, Batch 80/145, Loss: 0.2272
Epoch 5/10, Batch 90/145, Loss: 0.3082
Epoch 5/10, Batch 100/145, Loss: 0.1964
Epoch 5/10, Batch 110/145, Loss: 0.1322
Epoch 5/10, Batch 120/145, Loss: 0.2274
Epoch 5/10, Batch 130/145, Loss: 0.1733
Epoch 5/10, Batch 140/145, Loss: 0.2921
Epoch 5/10, Train Loss: 0.2324, Valid Loss: 0.2393
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1727
Epoch 6/10, Batch 20/145, Loss: 0.4147
Epoch 6/10, Batch 30/145, Loss: 0.2407
Epoch 6/10, Batch 40/145, Loss: 0.1429
Epoch 6/10, Batch 50/145, Loss: 0.2407
Epoch 6/10, Batch 60/145, Loss: 0.2483
Epoch 6/10, Batch 70/145, Loss: 0.1832
Epoch 6/10, Batch 80/145, Loss: 0.2877
Epoch 6/10, Batch 90/145, Loss: 0.1779
Epoch 6/10, Batch 100/145, Loss: 0.3799
Epoch 6/10, Batch 110/145, Loss: 0.2091
Epoch 6/10, Batch 120/145, Loss: 0.1585
Epoch 6/10, Batch 130/145, Loss: 0.2728
Epoch 6/10, Batch 140/145, Loss: 0.2154
Epoch 6/10, Train Loss: 0.2229, Valid Loss: 0.2330
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1080
Epoch 7/10, Batch 20/145, Loss: 0.2813
Epoch 7/10, Batch 30/145, Loss: 0.1418
Epoch 7/10, Batch 40/145, Loss: 0.1776
Epoch 7/10, Batch 50/145, Loss: 0.1444
Epoch 7/10, Batch 60/145, Loss: 0.1869
Epoch 7/10, Batch 70/145, Loss: 0.2378
Epoch 7/10, Batch 80/145, Loss: 0.2520
Epoch 7/10, Batch 90/145, Loss: 0.2067
Epoch 7/10, Batch 100/145, Loss: 0.3711
Epoch 7/10, Batch 110/145, Loss: 0.2224
Epoch 7/10, Batch 120/145, Loss: 0.1310
Epoch 7/10, Batch 130/145, Loss: 0.2124
Epoch 7/10, Batch 140/145, Loss: 0.4641
Epoch 7/10, Train Loss: 0.2118, Valid Loss: 0.2284
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1001
Epoch 8/10, Batch 20/145, Loss: 0.1914
Epoch 8/10, Batch 30/145, Loss: 0.2585
Epoch 8/10, Batch 40/145, Loss: 0.1521
Epoch 8/10, Batch 50/145, Loss: 0.1729
Epoch 8/10, Batch 60/145, Loss: 0.2367
Epoch 8/10, Batch 70/145, Loss: 0.3148
Epoch 8/10, Batch 80/145, Loss: 0.1242
Epoch 8/10, Batch 90/145, Loss: 0.2837
Epoch 8/10, Batch 100/145, Loss: 0.2664
Epoch 8/10, Batch 110/145, Loss: 0.1714
Epoch 8/10, Batch 120/145, Loss: 0.1191
Epoch 8/10, Batch 130/145, Loss: 0.2361
Epoch 8/10, Batch 140/145, Loss: 0.0861
Epoch 8/10, Train Loss: 0.1996, Valid Loss: 0.2186
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3282
Epoch 9/10, Batch 20/145, Loss: 0.3241
Epoch 9/10, Batch 30/145, Loss: 0.1847
Epoch 9/10, Batch 40/145, Loss: 0.1244
Epoch 9/10, Batch 50/145, Loss: 0.0680
Epoch 9/10, Batch 60/145, Loss: 0.1497
Epoch 9/10, Batch 70/145, Loss: 0.1670
Epoch 9/10, Batch 80/145, Loss: 0.1353
Epoch 9/10, Batch 90/145, Loss: 0.2157
Epoch 9/10, Batch 100/145, Loss: 0.2044
Epoch 9/10, Batch 110/145, Loss: 0.4758
Epoch 9/10, Batch 120/145, Loss: 0.1392
Epoch 9/10, Batch 130/145, Loss: 0.2628
Epoch 9/10, Batch 140/145, Loss: 0.1116
Epoch 9/10, Train Loss: 0.1951, Valid Loss: 0.2216
Epoch 10/10, Batch 10/145, Loss: 0.1401
Epoch 10/10, Batch 20/145, Loss: 0.1775
Epoch 10/10, Batch 30/145, Loss: 0.1165
Epoch 10/10, Batch 40/145, Loss: 0.1351
Epoch 10/10, Batch 50/145, Loss: 0.2025
Epoch 10/10, Batch 60/145, Loss: 0.2514
Epoch 10/10, Batch 70/145, Loss: 0.3076
Epoch 10/10, Batch 80/145, Loss: 0.0918
Epoch 10/10, Batch 90/145, Loss: 0.0822
Epoch 10/10, Batch 100/145, Loss: 0.1395
Epoch 10/10, Batch 110/145, Loss: 0.1948
Epoch 10/10, Batch 120/145, Loss: 0.3065
Epoch 10/10, Batch 130/145, Loss: 0.1270
Epoch 10/10, Batch 140/145, Loss: 0.2674
Epoch 10/10, Train Loss: 0.1957, Valid Loss: 0.2183
Model saved!
Accuracy: 0.9159
Precision: 0.9134
Recall: 0.9159
F1-score: 0.9131
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4050
Epoch 1/10, Batch 20/145, Loss: 0.9854
Epoch 1/10, Batch 30/145, Loss: 0.9047
Epoch 1/10, Batch 40/145, Loss: 0.7479
Epoch 1/10, Batch 50/145, Loss: 0.7431
Epoch 1/10, Batch 60/145, Loss: 0.5898
Epoch 1/10, Batch 70/145, Loss: 0.4524
Epoch 1/10, Batch 80/145, Loss: 0.4904
Epoch 1/10, Batch 90/145, Loss: 0.3627
Epoch 1/10, Batch 100/145, Loss: 0.5088
Epoch 1/10, Batch 110/145, Loss: 0.5070
Epoch 1/10, Batch 120/145, Loss: 0.6658
Epoch 1/10, Batch 130/145, Loss: 0.4609
Epoch 1/10, Batch 140/145, Loss: 0.5029
Epoch 1/10, Train Loss: 0.6772, Valid Loss: 0.3834
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3929
Epoch 2/10, Batch 20/145, Loss: 0.3159
Epoch 2/10, Batch 30/145, Loss: 0.3794
Epoch 2/10, Batch 40/145, Loss: 0.4499
Epoch 2/10, Batch 50/145, Loss: 0.6125
Epoch 2/10, Batch 60/145, Loss: 0.4820
Epoch 2/10, Batch 70/145, Loss: 0.3354
Epoch 2/10, Batch 80/145, Loss: 0.3187
Epoch 2/10, Batch 90/145, Loss: 0.4145
Epoch 2/10, Batch 100/145, Loss: 0.3952
Epoch 2/10, Batch 110/145, Loss: 0.3862
Epoch 2/10, Batch 120/145, Loss: 0.4000
Epoch 2/10, Batch 130/145, Loss: 0.2373
Epoch 2/10, Batch 140/145, Loss: 0.3681
Epoch 2/10, Train Loss: 0.3547, Valid Loss: 0.2934
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1690
Epoch 3/10, Batch 20/145, Loss: 0.3133
Epoch 3/10, Batch 30/145, Loss: 0.3123
Epoch 3/10, Batch 40/145, Loss: 0.3016
Epoch 3/10, Batch 50/145, Loss: 0.1741
Epoch 3/10, Batch 60/145, Loss: 0.4598
Epoch 3/10, Batch 70/145, Loss: 0.3437
Epoch 3/10, Batch 80/145, Loss: 0.1750
Epoch 3/10, Batch 90/145, Loss: 0.2824
Epoch 3/10, Batch 100/145, Loss: 0.2791
Epoch 3/10, Batch 110/145, Loss: 0.2562
Epoch 3/10, Batch 120/145, Loss: 0.4372
Epoch 3/10, Batch 130/145, Loss: 0.2215
Epoch 3/10, Batch 140/145, Loss: 0.2555
Epoch 3/10, Train Loss: 0.2963, Valid Loss: 0.2664
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3131
Epoch 4/10, Batch 20/145, Loss: 0.3407
Epoch 4/10, Batch 30/145, Loss: 0.3880
Epoch 4/10, Batch 40/145, Loss: 0.2004
Epoch 4/10, Batch 50/145, Loss: 0.1603
Epoch 4/10, Batch 60/145, Loss: 0.3021
Epoch 4/10, Batch 70/145, Loss: 0.2293
Epoch 4/10, Batch 80/145, Loss: 0.2150
Epoch 4/10, Batch 90/145, Loss: 0.5376
Epoch 4/10, Batch 100/145, Loss: 0.2997
Epoch 4/10, Batch 110/145, Loss: 0.1069
Epoch 4/10, Batch 120/145, Loss: 0.2782
Epoch 4/10, Batch 130/145, Loss: 0.2442
Epoch 4/10, Batch 140/145, Loss: 0.1280
Epoch 4/10, Train Loss: 0.2625, Valid Loss: 0.2452
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2002
Epoch 5/10, Batch 20/145, Loss: 0.1662
Epoch 5/10, Batch 30/145, Loss: 0.3275
Epoch 5/10, Batch 40/145, Loss: 0.1584
Epoch 5/10, Batch 50/145, Loss: 0.1866
Epoch 5/10, Batch 60/145, Loss: 0.2335
Epoch 5/10, Batch 70/145, Loss: 0.2701
Epoch 5/10, Batch 80/145, Loss: 0.3228
Epoch 5/10, Batch 90/145, Loss: 0.3644
Epoch 5/10, Batch 100/145, Loss: 0.2598
Epoch 5/10, Batch 110/145, Loss: 0.2172
Epoch 5/10, Batch 120/145, Loss: 0.3101
Epoch 5/10, Batch 130/145, Loss: 0.1362
Epoch 5/10, Batch 140/145, Loss: 0.2172
Epoch 5/10, Train Loss: 0.2456, Valid Loss: 0.2404
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2571
Epoch 6/10, Batch 20/145, Loss: 0.3852
Epoch 6/10, Batch 30/145, Loss: 0.2298
Epoch 6/10, Batch 40/145, Loss: 0.1041
Epoch 6/10, Batch 50/145, Loss: 0.2696
Epoch 6/10, Batch 60/145, Loss: 0.2138
Epoch 6/10, Batch 70/145, Loss: 0.0695
Epoch 6/10, Batch 80/145, Loss: 0.2244
Epoch 6/10, Batch 90/145, Loss: 0.4113
Epoch 6/10, Batch 100/145, Loss: 0.3281
Epoch 6/10, Batch 110/145, Loss: 0.1296
Epoch 6/10, Batch 120/145, Loss: 0.3419
Epoch 6/10, Batch 130/145, Loss: 0.1822
Epoch 6/10, Batch 140/145, Loss: 0.1982
Epoch 6/10, Train Loss: 0.2390, Valid Loss: 0.2358
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1259
Epoch 7/10, Batch 20/145, Loss: 0.2998
Epoch 7/10, Batch 30/145, Loss: 0.1171
Epoch 7/10, Batch 40/145, Loss: 0.5763
Epoch 7/10, Batch 50/145, Loss: 0.1218
Epoch 7/10, Batch 60/145, Loss: 0.1706
Epoch 7/10, Batch 70/145, Loss: 0.1914
Epoch 7/10, Batch 80/145, Loss: 0.2837
Epoch 7/10, Batch 90/145, Loss: 0.2210
Epoch 7/10, Batch 100/145, Loss: 0.2121
Epoch 7/10, Batch 110/145, Loss: 0.2028
Epoch 7/10, Batch 120/145, Loss: 0.1622
Epoch 7/10, Batch 130/145, Loss: 0.0925
Epoch 7/10, Batch 140/145, Loss: 0.4018
Epoch 7/10, Train Loss: 0.2166, Valid Loss: 0.2269
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2208
Epoch 8/10, Batch 20/145, Loss: 0.1667
Epoch 8/10, Batch 30/145, Loss: 0.2257
Epoch 8/10, Batch 40/145, Loss: 0.1346
Epoch 8/10, Batch 50/145, Loss: 0.2219
Epoch 8/10, Batch 60/145, Loss: 0.2657
Epoch 8/10, Batch 70/145, Loss: 0.2416
Epoch 8/10, Batch 80/145, Loss: 0.1905
Epoch 8/10, Batch 90/145, Loss: 0.4201
Epoch 8/10, Batch 100/145, Loss: 0.1885
Epoch 8/10, Batch 110/145, Loss: 0.2133
Epoch 8/10, Batch 120/145, Loss: 0.2389
Epoch 8/10, Batch 130/145, Loss: 0.1204
Epoch 8/10, Batch 140/145, Loss: 0.1722
Epoch 8/10, Train Loss: 0.2081, Valid Loss: 0.2206
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2642
Epoch 9/10, Batch 20/145, Loss: 0.2493
Epoch 9/10, Batch 30/145, Loss: 0.1081
Epoch 9/10, Batch 40/145, Loss: 0.2166
Epoch 9/10, Batch 50/145, Loss: 0.1069
Epoch 9/10, Batch 60/145, Loss: 0.2726
Epoch 9/10, Batch 70/145, Loss: 0.1634
Epoch 9/10, Batch 80/145, Loss: 0.1399
Epoch 9/10, Batch 90/145, Loss: 0.2054
Epoch 9/10, Batch 100/145, Loss: 0.1354
Epoch 9/10, Batch 110/145, Loss: 0.3089
Epoch 9/10, Batch 120/145, Loss: 0.1075
Epoch 9/10, Batch 130/145, Loss: 0.1303
Epoch 9/10, Batch 140/145, Loss: 0.4021
Epoch 9/10, Train Loss: 0.2085, Valid Loss: 0.2209
Epoch 10/10, Batch 10/145, Loss: 0.1275
Epoch 10/10, Batch 20/145, Loss: 0.2727
Epoch 10/10, Batch 30/145, Loss: 0.1337
Epoch 10/10, Batch 40/145, Loss: 0.3378
Epoch 10/10, Batch 50/145, Loss: 0.2951
Epoch 10/10, Batch 60/145, Loss: 0.2114
Epoch 10/10, Batch 70/145, Loss: 0.4126
Epoch 10/10, Batch 80/145, Loss: 0.2231
Epoch 10/10, Batch 90/145, Loss: 0.1255
Epoch 10/10, Batch 100/145, Loss: 0.2699
Epoch 10/10, Batch 110/145, Loss: 0.1120
Epoch 10/10, Batch 120/145, Loss: 0.1918
Epoch 10/10, Batch 130/145, Loss: 0.2003
Epoch 10/10, Batch 140/145, Loss: 0.2441
Epoch 10/10, Train Loss: 0.1963, Valid Loss: 0.2157
Model saved!
Accuracy: 0.9171
Precision: 0.9146
Recall: 0.9171
F1-score: 0.9153
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4596
Epoch 1/10, Batch 20/145, Loss: 0.9302
Epoch 1/10, Batch 30/145, Loss: 0.8598
Epoch 1/10, Batch 40/145, Loss: 0.8066
Epoch 1/10, Batch 50/145, Loss: 0.6996
Epoch 1/10, Batch 60/145, Loss: 0.6882
Epoch 1/10, Batch 70/145, Loss: 0.3554
Epoch 1/10, Batch 80/145, Loss: 0.6169
Epoch 1/10, Batch 90/145, Loss: 0.3351
Epoch 1/10, Batch 100/145, Loss: 0.4981
Epoch 1/10, Batch 110/145, Loss: 0.3182
Epoch 1/10, Batch 120/145, Loss: 0.5529
Epoch 1/10, Batch 130/145, Loss: 0.6091
Epoch 1/10, Batch 140/145, Loss: 0.3274
Epoch 1/10, Train Loss: 0.6848, Valid Loss: 0.3776
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3050
Epoch 2/10, Batch 20/145, Loss: 0.3589
Epoch 2/10, Batch 30/145, Loss: 0.3078
Epoch 2/10, Batch 40/145, Loss: 0.4128
Epoch 2/10, Batch 50/145, Loss: 0.3703
Epoch 2/10, Batch 60/145, Loss: 0.4739
Epoch 2/10, Batch 70/145, Loss: 0.3576
Epoch 2/10, Batch 80/145, Loss: 0.2655
Epoch 2/10, Batch 90/145, Loss: 0.2712
Epoch 2/10, Batch 100/145, Loss: 0.3909
Epoch 2/10, Batch 110/145, Loss: 0.3503
Epoch 2/10, Batch 120/145, Loss: 0.3243
Epoch 2/10, Batch 130/145, Loss: 0.3610
Epoch 2/10, Batch 140/145, Loss: 0.2646
Epoch 2/10, Train Loss: 0.3484, Valid Loss: 0.2967
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3059
Epoch 3/10, Batch 20/145, Loss: 0.1725
Epoch 3/10, Batch 30/145, Loss: 0.3239
Epoch 3/10, Batch 40/145, Loss: 0.1635
Epoch 3/10, Batch 50/145, Loss: 0.2756
Epoch 3/10, Batch 60/145, Loss: 0.5184
Epoch 3/10, Batch 70/145, Loss: 0.4199
Epoch 3/10, Batch 80/145, Loss: 0.3020
Epoch 3/10, Batch 90/145, Loss: 0.2343
Epoch 3/10, Batch 100/145, Loss: 0.3137
Epoch 3/10, Batch 110/145, Loss: 0.1655
Epoch 3/10, Batch 120/145, Loss: 0.1524
Epoch 3/10, Batch 130/145, Loss: 0.4592
Epoch 3/10, Batch 140/145, Loss: 0.3296
Epoch 3/10, Train Loss: 0.2887, Valid Loss: 0.2693
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.5086
Epoch 4/10, Batch 20/145, Loss: 0.2912
Epoch 4/10, Batch 30/145, Loss: 0.2349
Epoch 4/10, Batch 40/145, Loss: 0.1312
Epoch 4/10, Batch 50/145, Loss: 0.2118
Epoch 4/10, Batch 60/145, Loss: 0.3003
Epoch 4/10, Batch 70/145, Loss: 0.2276
Epoch 4/10, Batch 80/145, Loss: 0.2329
Epoch 4/10, Batch 90/145, Loss: 0.4287
Epoch 4/10, Batch 100/145, Loss: 0.3787
Epoch 4/10, Batch 110/145, Loss: 0.0562
Epoch 4/10, Batch 120/145, Loss: 0.1492
Epoch 4/10, Batch 130/145, Loss: 0.2459
Epoch 4/10, Batch 140/145, Loss: 0.1866
Epoch 4/10, Train Loss: 0.2527, Valid Loss: 0.2618
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2397
Epoch 5/10, Batch 20/145, Loss: 0.1242
Epoch 5/10, Batch 30/145, Loss: 0.1597
Epoch 5/10, Batch 40/145, Loss: 0.4092
Epoch 5/10, Batch 50/145, Loss: 0.1720
Epoch 5/10, Batch 60/145, Loss: 0.1705
Epoch 5/10, Batch 70/145, Loss: 0.2713
Epoch 5/10, Batch 80/145, Loss: 0.1960
Epoch 5/10, Batch 90/145, Loss: 0.3489
Epoch 5/10, Batch 100/145, Loss: 0.2243
Epoch 5/10, Batch 110/145, Loss: 0.1677
Epoch 5/10, Batch 120/145, Loss: 0.3347
Epoch 5/10, Batch 130/145, Loss: 0.1454
Epoch 5/10, Batch 140/145, Loss: 0.1826
Epoch 5/10, Train Loss: 0.2416, Valid Loss: 0.2484
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2770
Epoch 6/10, Batch 20/145, Loss: 0.4836
Epoch 6/10, Batch 30/145, Loss: 0.3757
Epoch 6/10, Batch 40/145, Loss: 0.1280
Epoch 6/10, Batch 50/145, Loss: 0.3321
Epoch 6/10, Batch 60/145, Loss: 0.1954
Epoch 6/10, Batch 70/145, Loss: 0.2707
Epoch 6/10, Batch 80/145, Loss: 0.2654
Epoch 6/10, Batch 90/145, Loss: 0.2867
Epoch 6/10, Batch 100/145, Loss: 0.4351
Epoch 6/10, Batch 110/145, Loss: 0.2104
Epoch 6/10, Batch 120/145, Loss: 0.3044
Epoch 6/10, Batch 130/145, Loss: 0.0891
Epoch 6/10, Batch 140/145, Loss: 0.1298
Epoch 6/10, Train Loss: 0.2240, Valid Loss: 0.2421
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2501
Epoch 7/10, Batch 20/145, Loss: 0.2799
Epoch 7/10, Batch 30/145, Loss: 0.2084
Epoch 7/10, Batch 40/145, Loss: 0.4200
Epoch 7/10, Batch 50/145, Loss: 0.1538
Epoch 7/10, Batch 60/145, Loss: 0.1982
Epoch 7/10, Batch 70/145, Loss: 0.1440
Epoch 7/10, Batch 80/145, Loss: 0.3848
Epoch 7/10, Batch 90/145, Loss: 0.2789
Epoch 7/10, Batch 100/145, Loss: 0.1168
Epoch 7/10, Batch 110/145, Loss: 0.0986
Epoch 7/10, Batch 120/145, Loss: 0.3235
Epoch 7/10, Batch 130/145, Loss: 0.2378
Epoch 7/10, Batch 140/145, Loss: 0.2634
Epoch 7/10, Train Loss: 0.2089, Valid Loss: 0.2393
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1530
Epoch 8/10, Batch 20/145, Loss: 0.1643
Epoch 8/10, Batch 30/145, Loss: 0.2158
Epoch 8/10, Batch 40/145, Loss: 0.3416
Epoch 8/10, Batch 50/145, Loss: 0.1190
Epoch 8/10, Batch 60/145, Loss: 0.2490
Epoch 8/10, Batch 70/145, Loss: 0.1867
Epoch 8/10, Batch 80/145, Loss: 0.1726
Epoch 8/10, Batch 90/145, Loss: 0.2890
Epoch 8/10, Batch 100/145, Loss: 0.1185
Epoch 8/10, Batch 110/145, Loss: 0.2692
Epoch 8/10, Batch 120/145, Loss: 0.0998
Epoch 8/10, Batch 130/145, Loss: 0.1638
Epoch 8/10, Batch 140/145, Loss: 0.1162
Epoch 8/10, Train Loss: 0.1920, Valid Loss: 0.2318
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3538
Epoch 9/10, Batch 20/145, Loss: 0.1433
Epoch 9/10, Batch 30/145, Loss: 0.1069
Epoch 9/10, Batch 40/145, Loss: 0.1263
Epoch 9/10, Batch 50/145, Loss: 0.2258
Epoch 9/10, Batch 60/145, Loss: 0.1431
Epoch 9/10, Batch 70/145, Loss: 0.1780
Epoch 9/10, Batch 80/145, Loss: 0.0633
Epoch 9/10, Batch 90/145, Loss: 0.2928
Epoch 9/10, Batch 100/145, Loss: 0.2034
Epoch 9/10, Batch 110/145, Loss: 0.1712
Epoch 9/10, Batch 120/145, Loss: 0.1313
Epoch 9/10, Batch 130/145, Loss: 0.1814
Epoch 9/10, Batch 140/145, Loss: 0.2480
Epoch 9/10, Train Loss: 0.1979, Valid Loss: 0.2355
Epoch 10/10, Batch 10/145, Loss: 0.0936
Epoch 10/10, Batch 20/145, Loss: 0.1690
Epoch 10/10, Batch 30/145, Loss: 0.0910
Epoch 10/10, Batch 40/145, Loss: 0.0700
Epoch 10/10, Batch 50/145, Loss: 0.2950
Epoch 10/10, Batch 60/145, Loss: 0.2796
Epoch 10/10, Batch 70/145, Loss: 0.1465
Epoch 10/10, Batch 80/145, Loss: 0.1606
Epoch 10/10, Batch 90/145, Loss: 0.1546
Epoch 10/10, Batch 100/145, Loss: 0.1158
Epoch 10/10, Batch 110/145, Loss: 0.1734
Epoch 10/10, Batch 120/145, Loss: 0.2296
Epoch 10/10, Batch 130/145, Loss: 0.1746
Epoch 10/10, Batch 140/145, Loss: 0.1510
Epoch 10/10, Train Loss: 0.1916, Valid Loss: 0.2370
Accuracy: 0.9287
Precision: 0.9274
Recall: 0.9287
F1-score: 0.9277
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3777
Epoch 1/10, Batch 20/145, Loss: 0.9731
Epoch 1/10, Batch 30/145, Loss: 0.9340
Epoch 1/10, Batch 40/145, Loss: 0.7168
Epoch 1/10, Batch 50/145, Loss: 0.7641
Epoch 1/10, Batch 60/145, Loss: 0.7993
Epoch 1/10, Batch 70/145, Loss: 0.4961
Epoch 1/10, Batch 80/145, Loss: 0.6103
Epoch 1/10, Batch 90/145, Loss: 0.5359
Epoch 1/10, Batch 100/145, Loss: 0.5559
Epoch 1/10, Batch 110/145, Loss: 0.4048
Epoch 1/10, Batch 120/145, Loss: 0.6143
Epoch 1/10, Batch 130/145, Loss: 0.4905
Epoch 1/10, Batch 140/145, Loss: 0.3609
Epoch 1/10, Train Loss: 0.6783, Valid Loss: 0.3777
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3403
Epoch 2/10, Batch 20/145, Loss: 0.3296
Epoch 2/10, Batch 30/145, Loss: 0.3276
Epoch 2/10, Batch 40/145, Loss: 0.4394
Epoch 2/10, Batch 50/145, Loss: 0.3590
Epoch 2/10, Batch 60/145, Loss: 0.3331
Epoch 2/10, Batch 70/145, Loss: 0.5409
Epoch 2/10, Batch 80/145, Loss: 0.3513
Epoch 2/10, Batch 90/145, Loss: 0.4102
Epoch 2/10, Batch 100/145, Loss: 0.2144
Epoch 2/10, Batch 110/145, Loss: 0.3789
Epoch 2/10, Batch 120/145, Loss: 0.3236
Epoch 2/10, Batch 130/145, Loss: 0.3758
Epoch 2/10, Batch 140/145, Loss: 0.3394
Epoch 2/10, Train Loss: 0.3549, Valid Loss: 0.2881
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3226
Epoch 3/10, Batch 20/145, Loss: 0.2667
Epoch 3/10, Batch 30/145, Loss: 0.3556
Epoch 3/10, Batch 40/145, Loss: 0.3265
Epoch 3/10, Batch 50/145, Loss: 0.1697
Epoch 3/10, Batch 60/145, Loss: 0.3226
Epoch 3/10, Batch 70/145, Loss: 0.2327
Epoch 3/10, Batch 80/145, Loss: 0.3884
Epoch 3/10, Batch 90/145, Loss: 0.3526
Epoch 3/10, Batch 100/145, Loss: 0.2765
Epoch 3/10, Batch 110/145, Loss: 0.3523
Epoch 3/10, Batch 120/145, Loss: 0.1726
Epoch 3/10, Batch 130/145, Loss: 0.5208
Epoch 3/10, Batch 140/145, Loss: 0.2043
Epoch 3/10, Train Loss: 0.2935, Valid Loss: 0.2637
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3097
Epoch 4/10, Batch 20/145, Loss: 0.3485
Epoch 4/10, Batch 30/145, Loss: 0.2784
Epoch 4/10, Batch 40/145, Loss: 0.2058
Epoch 4/10, Batch 50/145, Loss: 0.2128
Epoch 4/10, Batch 60/145, Loss: 0.2192
Epoch 4/10, Batch 70/145, Loss: 0.2238
Epoch 4/10, Batch 80/145, Loss: 0.2105
Epoch 4/10, Batch 90/145, Loss: 0.2661
Epoch 4/10, Batch 100/145, Loss: 0.4596
Epoch 4/10, Batch 110/145, Loss: 0.2151
Epoch 4/10, Batch 120/145, Loss: 0.3822
Epoch 4/10, Batch 130/145, Loss: 0.1824
Epoch 4/10, Batch 140/145, Loss: 0.2225
Epoch 4/10, Train Loss: 0.2623, Valid Loss: 0.2496
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1419
Epoch 5/10, Batch 20/145, Loss: 0.1661
Epoch 5/10, Batch 30/145, Loss: 0.2848
Epoch 5/10, Batch 40/145, Loss: 0.1502
Epoch 5/10, Batch 50/145, Loss: 0.1591
Epoch 5/10, Batch 60/145, Loss: 0.1915
Epoch 5/10, Batch 70/145, Loss: 0.2130
Epoch 5/10, Batch 80/145, Loss: 0.2702
Epoch 5/10, Batch 90/145, Loss: 0.3640
Epoch 5/10, Batch 100/145, Loss: 0.3296
Epoch 5/10, Batch 110/145, Loss: 0.1865
Epoch 5/10, Batch 120/145, Loss: 0.2550
Epoch 5/10, Batch 130/145, Loss: 0.1050
Epoch 5/10, Batch 140/145, Loss: 0.3017
Epoch 5/10, Train Loss: 0.2427, Valid Loss: 0.2353
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1480
Epoch 6/10, Batch 20/145, Loss: 0.4679
Epoch 6/10, Batch 30/145, Loss: 0.4380
Epoch 6/10, Batch 40/145, Loss: 0.2919
Epoch 6/10, Batch 50/145, Loss: 0.3943
Epoch 6/10, Batch 60/145, Loss: 0.2901
Epoch 6/10, Batch 70/145, Loss: 0.3146
Epoch 6/10, Batch 80/145, Loss: 0.2220
Epoch 6/10, Batch 90/145, Loss: 0.2346
Epoch 6/10, Batch 100/145, Loss: 0.2190
Epoch 6/10, Batch 110/145, Loss: 0.2134
Epoch 6/10, Batch 120/145, Loss: 0.4157
Epoch 6/10, Batch 130/145, Loss: 0.2025
Epoch 6/10, Batch 140/145, Loss: 0.1572
Epoch 6/10, Train Loss: 0.2302, Valid Loss: 0.2251
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1884
Epoch 7/10, Batch 20/145, Loss: 0.3899
Epoch 7/10, Batch 30/145, Loss: 0.2071
Epoch 7/10, Batch 40/145, Loss: 0.2875
Epoch 7/10, Batch 50/145, Loss: 0.2395
Epoch 7/10, Batch 60/145, Loss: 0.2537
Epoch 7/10, Batch 70/145, Loss: 0.2988
Epoch 7/10, Batch 80/145, Loss: 0.3724
Epoch 7/10, Batch 90/145, Loss: 0.2710
Epoch 7/10, Batch 100/145, Loss: 0.1526
Epoch 7/10, Batch 110/145, Loss: 0.2153
Epoch 7/10, Batch 120/145, Loss: 0.1424
Epoch 7/10, Batch 130/145, Loss: 0.1945
Epoch 7/10, Batch 140/145, Loss: 0.3452
Epoch 7/10, Train Loss: 0.2221, Valid Loss: 0.2240
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1898
Epoch 8/10, Batch 20/145, Loss: 0.1235
Epoch 8/10, Batch 30/145, Loss: 0.3000
Epoch 8/10, Batch 40/145, Loss: 0.3299
Epoch 8/10, Batch 50/145, Loss: 0.2634
Epoch 8/10, Batch 60/145, Loss: 0.1325
Epoch 8/10, Batch 70/145, Loss: 0.1594
Epoch 8/10, Batch 80/145, Loss: 0.2296
Epoch 8/10, Batch 90/145, Loss: 0.4516
Epoch 8/10, Batch 100/145, Loss: 0.3789
Epoch 8/10, Batch 110/145, Loss: 0.2507
Epoch 8/10, Batch 120/145, Loss: 0.1487
Epoch 8/10, Batch 130/145, Loss: 0.1011
Epoch 8/10, Batch 140/145, Loss: 0.1612
Epoch 8/10, Train Loss: 0.2028, Valid Loss: 0.2135
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.4170
Epoch 9/10, Batch 20/145, Loss: 0.1344
Epoch 9/10, Batch 30/145, Loss: 0.1089
Epoch 9/10, Batch 40/145, Loss: 0.2165
Epoch 9/10, Batch 50/145, Loss: 0.0693
Epoch 9/10, Batch 60/145, Loss: 0.3603
Epoch 9/10, Batch 70/145, Loss: 0.1087
Epoch 9/10, Batch 80/145, Loss: 0.1327
Epoch 9/10, Batch 90/145, Loss: 0.1841
Epoch 9/10, Batch 100/145, Loss: 0.1522
Epoch 9/10, Batch 110/145, Loss: 0.2365
Epoch 9/10, Batch 120/145, Loss: 0.1391
Epoch 9/10, Batch 130/145, Loss: 0.2756
Epoch 9/10, Batch 140/145, Loss: 0.2588
Epoch 9/10, Train Loss: 0.1968, Valid Loss: 0.2117
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1278
Epoch 10/10, Batch 20/145, Loss: 0.1829
Epoch 10/10, Batch 30/145, Loss: 0.1118
Epoch 10/10, Batch 40/145, Loss: 0.0563
Epoch 10/10, Batch 50/145, Loss: 0.2032
Epoch 10/10, Batch 60/145, Loss: 0.0830
Epoch 10/10, Batch 70/145, Loss: 0.2609
Epoch 10/10, Batch 80/145, Loss: 0.1829
Epoch 10/10, Batch 90/145, Loss: 0.2385
Epoch 10/10, Batch 100/145, Loss: 0.3143
Epoch 10/10, Batch 110/145, Loss: 0.0942
Epoch 10/10, Batch 120/145, Loss: 0.2545
Epoch 10/10, Batch 130/145, Loss: 0.1740
Epoch 10/10, Batch 140/145, Loss: 0.1944
Epoch 10/10, Train Loss: 0.1984, Valid Loss: 0.2104
Model saved!
Accuracy: 0.9159
Precision: 0.9129
Recall: 0.9159
F1-score: 0.9130
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3587
Epoch 1/10, Batch 20/145, Loss: 0.9121
Epoch 1/10, Batch 30/145, Loss: 0.9274
Epoch 1/10, Batch 40/145, Loss: 0.6899
Epoch 1/10, Batch 50/145, Loss: 0.6975
Epoch 1/10, Batch 60/145, Loss: 0.6023
Epoch 1/10, Batch 70/145, Loss: 0.3598
Epoch 1/10, Batch 80/145, Loss: 0.4787
Epoch 1/10, Batch 90/145, Loss: 0.4263
Epoch 1/10, Batch 100/145, Loss: 0.5547
Epoch 1/10, Batch 110/145, Loss: 0.5144
Epoch 1/10, Batch 120/145, Loss: 0.5248
Epoch 1/10, Batch 130/145, Loss: 0.5080
Epoch 1/10, Batch 140/145, Loss: 0.3761
Epoch 1/10, Train Loss: 0.6743, Valid Loss: 0.3878
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2742
Epoch 2/10, Batch 20/145, Loss: 0.1845
Epoch 2/10, Batch 30/145, Loss: 0.2370
Epoch 2/10, Batch 40/145, Loss: 0.3719
Epoch 2/10, Batch 50/145, Loss: 0.2947
Epoch 2/10, Batch 60/145, Loss: 0.3601
Epoch 2/10, Batch 70/145, Loss: 0.2625
Epoch 2/10, Batch 80/145, Loss: 0.3221
Epoch 2/10, Batch 90/145, Loss: 0.2899
Epoch 2/10, Batch 100/145, Loss: 0.3081
Epoch 2/10, Batch 110/145, Loss: 0.2775
Epoch 2/10, Batch 120/145, Loss: 0.3218
Epoch 2/10, Batch 130/145, Loss: 0.3445
Epoch 2/10, Batch 140/145, Loss: 0.2152
Epoch 2/10, Train Loss: 0.3473, Valid Loss: 0.3041
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2520
Epoch 3/10, Batch 20/145, Loss: 0.3721
Epoch 3/10, Batch 30/145, Loss: 0.4216
Epoch 3/10, Batch 40/145, Loss: 0.3229
Epoch 3/10, Batch 50/145, Loss: 0.2418
Epoch 3/10, Batch 60/145, Loss: 0.2213
Epoch 3/10, Batch 70/145, Loss: 0.3323
Epoch 3/10, Batch 80/145, Loss: 0.2214
Epoch 3/10, Batch 90/145, Loss: 0.4491
Epoch 3/10, Batch 100/145, Loss: 0.2272
Epoch 3/10, Batch 110/145, Loss: 0.3028
Epoch 3/10, Batch 120/145, Loss: 0.3137
Epoch 3/10, Batch 130/145, Loss: 0.4563
Epoch 3/10, Batch 140/145, Loss: 0.1984
Epoch 3/10, Train Loss: 0.2902, Valid Loss: 0.2674
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1442
Epoch 4/10, Batch 20/145, Loss: 0.2684
Epoch 4/10, Batch 30/145, Loss: 0.3979
Epoch 4/10, Batch 40/145, Loss: 0.2246
Epoch 4/10, Batch 50/145, Loss: 0.1198
Epoch 4/10, Batch 60/145, Loss: 0.2189
Epoch 4/10, Batch 70/145, Loss: 0.1902
Epoch 4/10, Batch 80/145, Loss: 0.1678
Epoch 4/10, Batch 90/145, Loss: 0.1943
Epoch 4/10, Batch 100/145, Loss: 0.6132
Epoch 4/10, Batch 110/145, Loss: 0.1329
Epoch 4/10, Batch 120/145, Loss: 0.2277
Epoch 4/10, Batch 130/145, Loss: 0.2463
Epoch 4/10, Batch 140/145, Loss: 0.2142
Epoch 4/10, Train Loss: 0.2557, Valid Loss: 0.2532
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1809
Epoch 5/10, Batch 20/145, Loss: 0.1435
Epoch 5/10, Batch 30/145, Loss: 0.1190
Epoch 5/10, Batch 40/145, Loss: 0.1122
Epoch 5/10, Batch 50/145, Loss: 0.2667
Epoch 5/10, Batch 60/145, Loss: 0.1489
Epoch 5/10, Batch 70/145, Loss: 0.2156
Epoch 5/10, Batch 80/145, Loss: 0.2562
Epoch 5/10, Batch 90/145, Loss: 0.3082
Epoch 5/10, Batch 100/145, Loss: 0.2836
Epoch 5/10, Batch 110/145, Loss: 0.2288
Epoch 5/10, Batch 120/145, Loss: 0.2835
Epoch 5/10, Batch 130/145, Loss: 0.2306
Epoch 5/10, Batch 140/145, Loss: 0.1972
Epoch 5/10, Train Loss: 0.2450, Valid Loss: 0.2455
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1619
Epoch 6/10, Batch 20/145, Loss: 0.4434
Epoch 6/10, Batch 30/145, Loss: 0.2966
Epoch 6/10, Batch 40/145, Loss: 0.1279
Epoch 6/10, Batch 50/145, Loss: 0.3152
Epoch 6/10, Batch 60/145, Loss: 0.1516
Epoch 6/10, Batch 70/145, Loss: 0.1431
Epoch 6/10, Batch 80/145, Loss: 0.2035
Epoch 6/10, Batch 90/145, Loss: 0.2039
Epoch 6/10, Batch 100/145, Loss: 0.2299
Epoch 6/10, Batch 110/145, Loss: 0.2038
Epoch 6/10, Batch 120/145, Loss: 0.2443
Epoch 6/10, Batch 130/145, Loss: 0.1713
Epoch 6/10, Batch 140/145, Loss: 0.2713
Epoch 6/10, Train Loss: 0.2284, Valid Loss: 0.2366
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2108
Epoch 7/10, Batch 20/145, Loss: 0.2695
Epoch 7/10, Batch 30/145, Loss: 0.2982
Epoch 7/10, Batch 40/145, Loss: 0.2508
Epoch 7/10, Batch 50/145, Loss: 0.3221
Epoch 7/10, Batch 60/145, Loss: 0.1961
Epoch 7/10, Batch 70/145, Loss: 0.1863
Epoch 7/10, Batch 80/145, Loss: 0.3951
Epoch 7/10, Batch 90/145, Loss: 0.2308
Epoch 7/10, Batch 100/145, Loss: 0.1354
Epoch 7/10, Batch 110/145, Loss: 0.0964
Epoch 7/10, Batch 120/145, Loss: 0.2837
Epoch 7/10, Batch 130/145, Loss: 0.2158
Epoch 7/10, Batch 140/145, Loss: 0.2056
Epoch 7/10, Train Loss: 0.2133, Valid Loss: 0.2257
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2427
Epoch 8/10, Batch 20/145, Loss: 0.2397
Epoch 8/10, Batch 30/145, Loss: 0.4274
Epoch 8/10, Batch 40/145, Loss: 0.1500
Epoch 8/10, Batch 50/145, Loss: 0.2421
Epoch 8/10, Batch 60/145, Loss: 0.2301
Epoch 8/10, Batch 70/145, Loss: 0.1886
Epoch 8/10, Batch 80/145, Loss: 0.3116
Epoch 8/10, Batch 90/145, Loss: 0.5507
Epoch 8/10, Batch 100/145, Loss: 0.1207
Epoch 8/10, Batch 110/145, Loss: 0.1773
Epoch 8/10, Batch 120/145, Loss: 0.2031
Epoch 8/10, Batch 130/145, Loss: 0.0857
Epoch 8/10, Batch 140/145, Loss: 0.3107
Epoch 8/10, Train Loss: 0.2079, Valid Loss: 0.2254
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2465
Epoch 9/10, Batch 20/145, Loss: 0.1434
Epoch 9/10, Batch 30/145, Loss: 0.3338
Epoch 9/10, Batch 40/145, Loss: 0.1823
Epoch 9/10, Batch 50/145, Loss: 0.1756
Epoch 9/10, Batch 60/145, Loss: 0.1567
Epoch 9/10, Batch 70/145, Loss: 0.1812
Epoch 9/10, Batch 80/145, Loss: 0.0835
Epoch 9/10, Batch 90/145, Loss: 0.2386
Epoch 9/10, Batch 100/145, Loss: 0.1137
Epoch 9/10, Batch 110/145, Loss: 0.2091
Epoch 9/10, Batch 120/145, Loss: 0.0813
Epoch 9/10, Batch 130/145, Loss: 0.1921
Epoch 9/10, Batch 140/145, Loss: 0.2478
Epoch 9/10, Train Loss: 0.2014, Valid Loss: 0.2233
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0791
Epoch 10/10, Batch 20/145, Loss: 0.2133
Epoch 10/10, Batch 30/145, Loss: 0.0871
Epoch 10/10, Batch 40/145, Loss: 0.1473
Epoch 10/10, Batch 50/145, Loss: 0.1781
Epoch 10/10, Batch 60/145, Loss: 0.1241
Epoch 10/10, Batch 70/145, Loss: 0.2913
Epoch 10/10, Batch 80/145, Loss: 0.1145
Epoch 10/10, Batch 90/145, Loss: 0.1028
Epoch 10/10, Batch 100/145, Loss: 0.2592
Epoch 10/10, Batch 110/145, Loss: 0.2043
Epoch 10/10, Batch 120/145, Loss: 0.2636
Epoch 10/10, Batch 130/145, Loss: 0.1114
Epoch 10/10, Batch 140/145, Loss: 0.1704
Epoch 10/10, Train Loss: 0.1935, Valid Loss: 0.2171
Model saved!
Accuracy: 0.9194
Precision: 0.9165
Recall: 0.9194
F1-score: 0.9170
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3565
Epoch 1/10, Batch 20/145, Loss: 0.9821
Epoch 1/10, Batch 30/145, Loss: 0.8710
Epoch 1/10, Batch 40/145, Loss: 0.7360
Epoch 1/10, Batch 50/145, Loss: 0.7381
Epoch 1/10, Batch 60/145, Loss: 0.6348
Epoch 1/10, Batch 70/145, Loss: 0.4440
Epoch 1/10, Batch 80/145, Loss: 0.6367
Epoch 1/10, Batch 90/145, Loss: 0.4093
Epoch 1/10, Batch 100/145, Loss: 0.4561
Epoch 1/10, Batch 110/145, Loss: 0.3057
Epoch 1/10, Batch 120/145, Loss: 0.6418
Epoch 1/10, Batch 130/145, Loss: 0.5052
Epoch 1/10, Batch 140/145, Loss: 0.3299
Epoch 1/10, Train Loss: 0.6717, Valid Loss: 0.3703
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4549
Epoch 2/10, Batch 20/145, Loss: 0.3763
Epoch 2/10, Batch 30/145, Loss: 0.3238
Epoch 2/10, Batch 40/145, Loss: 0.4114
Epoch 2/10, Batch 50/145, Loss: 0.2769
Epoch 2/10, Batch 60/145, Loss: 0.3439
Epoch 2/10, Batch 70/145, Loss: 0.3019
Epoch 2/10, Batch 80/145, Loss: 0.3243
Epoch 2/10, Batch 90/145, Loss: 0.2642
Epoch 2/10, Batch 100/145, Loss: 0.3122
Epoch 2/10, Batch 110/145, Loss: 0.2784
Epoch 2/10, Batch 120/145, Loss: 0.4095
Epoch 2/10, Batch 130/145, Loss: 0.4506
Epoch 2/10, Batch 140/145, Loss: 0.3685
Epoch 2/10, Train Loss: 0.3430, Valid Loss: 0.2948
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3360
Epoch 3/10, Batch 20/145, Loss: 0.1744
Epoch 3/10, Batch 30/145, Loss: 0.4000
Epoch 3/10, Batch 40/145, Loss: 0.2178
Epoch 3/10, Batch 50/145, Loss: 0.1831
Epoch 3/10, Batch 60/145, Loss: 0.2565
Epoch 3/10, Batch 70/145, Loss: 0.1706
Epoch 3/10, Batch 80/145, Loss: 0.3126
Epoch 3/10, Batch 90/145, Loss: 0.2004
Epoch 3/10, Batch 100/145, Loss: 0.2208
Epoch 3/10, Batch 110/145, Loss: 0.1720
Epoch 3/10, Batch 120/145, Loss: 0.1958
Epoch 3/10, Batch 130/145, Loss: 0.2128
Epoch 3/10, Batch 140/145, Loss: 0.2188
Epoch 3/10, Train Loss: 0.2867, Valid Loss: 0.2608
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1922
Epoch 4/10, Batch 20/145, Loss: 0.2246
Epoch 4/10, Batch 30/145, Loss: 0.2243
Epoch 4/10, Batch 40/145, Loss: 0.1857
Epoch 4/10, Batch 50/145, Loss: 0.2408
Epoch 4/10, Batch 60/145, Loss: 0.2610
Epoch 4/10, Batch 70/145, Loss: 0.2609
Epoch 4/10, Batch 80/145, Loss: 0.1740
Epoch 4/10, Batch 90/145, Loss: 0.3476
Epoch 4/10, Batch 100/145, Loss: 0.5055
Epoch 4/10, Batch 110/145, Loss: 0.2005
Epoch 4/10, Batch 120/145, Loss: 0.2113
Epoch 4/10, Batch 130/145, Loss: 0.1674
Epoch 4/10, Batch 140/145, Loss: 0.1893
Epoch 4/10, Train Loss: 0.2511, Valid Loss: 0.2533
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2456
Epoch 5/10, Batch 20/145, Loss: 0.0931
Epoch 5/10, Batch 30/145, Loss: 0.2960
Epoch 5/10, Batch 40/145, Loss: 0.1979
Epoch 5/10, Batch 50/145, Loss: 0.2474
Epoch 5/10, Batch 60/145, Loss: 0.2409
Epoch 5/10, Batch 70/145, Loss: 0.3277
Epoch 5/10, Batch 80/145, Loss: 0.3926
Epoch 5/10, Batch 90/145, Loss: 0.2711
Epoch 5/10, Batch 100/145, Loss: 0.3373
Epoch 5/10, Batch 110/145, Loss: 0.1416
Epoch 5/10, Batch 120/145, Loss: 0.2855
Epoch 5/10, Batch 130/145, Loss: 0.1984
Epoch 5/10, Batch 140/145, Loss: 0.1470
Epoch 5/10, Train Loss: 0.2372, Valid Loss: 0.2378
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1216
Epoch 6/10, Batch 20/145, Loss: 0.3455
Epoch 6/10, Batch 30/145, Loss: 0.2666
Epoch 6/10, Batch 40/145, Loss: 0.2363
Epoch 6/10, Batch 50/145, Loss: 0.3303
Epoch 6/10, Batch 60/145, Loss: 0.1383
Epoch 6/10, Batch 70/145, Loss: 0.1002
Epoch 6/10, Batch 80/145, Loss: 0.1209
Epoch 6/10, Batch 90/145, Loss: 0.1375
Epoch 6/10, Batch 100/145, Loss: 0.3447
Epoch 6/10, Batch 110/145, Loss: 0.2623
Epoch 6/10, Batch 120/145, Loss: 0.3112
Epoch 6/10, Batch 130/145, Loss: 0.1130
Epoch 6/10, Batch 140/145, Loss: 0.1232
Epoch 6/10, Train Loss: 0.2251, Valid Loss: 0.2314
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2402
Epoch 7/10, Batch 20/145, Loss: 0.1832
Epoch 7/10, Batch 30/145, Loss: 0.2348
Epoch 7/10, Batch 40/145, Loss: 0.2532
Epoch 7/10, Batch 50/145, Loss: 0.1362
Epoch 7/10, Batch 60/145, Loss: 0.1623
Epoch 7/10, Batch 70/145, Loss: 0.2338
Epoch 7/10, Batch 80/145, Loss: 0.4577
Epoch 7/10, Batch 90/145, Loss: 0.1664
Epoch 7/10, Batch 100/145, Loss: 0.1406
Epoch 7/10, Batch 110/145, Loss: 0.2171
Epoch 7/10, Batch 120/145, Loss: 0.2561
Epoch 7/10, Batch 130/145, Loss: 0.1317
Epoch 7/10, Batch 140/145, Loss: 0.3724
Epoch 7/10, Train Loss: 0.2020, Valid Loss: 0.2326
Epoch 8/10, Batch 10/145, Loss: 0.1786
Epoch 8/10, Batch 20/145, Loss: 0.2054
Epoch 8/10, Batch 30/145, Loss: 0.2195
Epoch 8/10, Batch 40/145, Loss: 0.3029
Epoch 8/10, Batch 50/145, Loss: 0.1969
Epoch 8/10, Batch 60/145, Loss: 0.2411
Epoch 8/10, Batch 70/145, Loss: 0.3017
Epoch 8/10, Batch 80/145, Loss: 0.1166
Epoch 8/10, Batch 90/145, Loss: 0.2950
Epoch 8/10, Batch 100/145, Loss: 0.1619
Epoch 8/10, Batch 110/145, Loss: 0.2063
Epoch 8/10, Batch 120/145, Loss: 0.2095
Epoch 8/10, Batch 130/145, Loss: 0.2110
Epoch 8/10, Batch 140/145, Loss: 0.2869
Epoch 8/10, Train Loss: 0.1995, Valid Loss: 0.2189
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2578
Epoch 9/10, Batch 20/145, Loss: 0.1846
Epoch 9/10, Batch 30/145, Loss: 0.0715
Epoch 9/10, Batch 40/145, Loss: 0.1850
Epoch 9/10, Batch 50/145, Loss: 0.1057
Epoch 9/10, Batch 60/145, Loss: 0.1996
Epoch 9/10, Batch 70/145, Loss: 0.0754
Epoch 9/10, Batch 80/145, Loss: 0.2284
Epoch 9/10, Batch 90/145, Loss: 0.3184
Epoch 9/10, Batch 100/145, Loss: 0.1144
Epoch 9/10, Batch 110/145, Loss: 0.3674
Epoch 9/10, Batch 120/145, Loss: 0.1347
Epoch 9/10, Batch 130/145, Loss: 0.2169
Epoch 9/10, Batch 140/145, Loss: 0.1586
Epoch 9/10, Train Loss: 0.1972, Valid Loss: 0.2264
Epoch 10/10, Batch 10/145, Loss: 0.1900
Epoch 10/10, Batch 20/145, Loss: 0.1463
Epoch 10/10, Batch 30/145, Loss: 0.1823
Epoch 10/10, Batch 40/145, Loss: 0.0897
Epoch 10/10, Batch 50/145, Loss: 0.2435
Epoch 10/10, Batch 60/145, Loss: 0.0673
Epoch 10/10, Batch 70/145, Loss: 0.1465
Epoch 10/10, Batch 80/145, Loss: 0.1731
Epoch 10/10, Batch 90/145, Loss: 0.1320
Epoch 10/10, Batch 100/145, Loss: 0.1663
Epoch 10/10, Batch 110/145, Loss: 0.1413
Epoch 10/10, Batch 120/145, Loss: 0.1927
Epoch 10/10, Batch 130/145, Loss: 0.1076
Epoch 10/10, Batch 140/145, Loss: 0.1159
Epoch 10/10, Train Loss: 0.1851, Valid Loss: 0.2181
Model saved!
Accuracy: 0.9182
Precision: 0.9149
Recall: 0.9182
F1-score: 0.9158
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3959
Epoch 1/10, Batch 20/145, Loss: 0.9341
Epoch 1/10, Batch 30/145, Loss: 0.8956
Epoch 1/10, Batch 40/145, Loss: 0.7489
Epoch 1/10, Batch 50/145, Loss: 0.8791
Epoch 1/10, Batch 60/145, Loss: 0.6250
Epoch 1/10, Batch 70/145, Loss: 0.5443
Epoch 1/10, Batch 80/145, Loss: 0.5009
Epoch 1/10, Batch 90/145, Loss: 0.3708
Epoch 1/10, Batch 100/145, Loss: 0.4760
Epoch 1/10, Batch 110/145, Loss: 0.4973
Epoch 1/10, Batch 120/145, Loss: 0.5838
Epoch 1/10, Batch 130/145, Loss: 0.4971
Epoch 1/10, Batch 140/145, Loss: 0.4046
Epoch 1/10, Train Loss: 0.6752, Valid Loss: 0.3854
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3365
Epoch 2/10, Batch 20/145, Loss: 0.3261
Epoch 2/10, Batch 30/145, Loss: 0.4582
Epoch 2/10, Batch 40/145, Loss: 0.4047
Epoch 2/10, Batch 50/145, Loss: 0.2036
Epoch 2/10, Batch 60/145, Loss: 0.3302
Epoch 2/10, Batch 70/145, Loss: 0.2753
Epoch 2/10, Batch 80/145, Loss: 0.2280
Epoch 2/10, Batch 90/145, Loss: 0.3153
Epoch 2/10, Batch 100/145, Loss: 0.2628
Epoch 2/10, Batch 110/145, Loss: 0.3480
Epoch 2/10, Batch 120/145, Loss: 0.4828
Epoch 2/10, Batch 130/145, Loss: 0.2446
Epoch 2/10, Batch 140/145, Loss: 0.2836
Epoch 2/10, Train Loss: 0.3518, Valid Loss: 0.2956
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2551
Epoch 3/10, Batch 20/145, Loss: 0.2339
Epoch 3/10, Batch 30/145, Loss: 0.3592
Epoch 3/10, Batch 40/145, Loss: 0.2583
Epoch 3/10, Batch 50/145, Loss: 0.2902
Epoch 3/10, Batch 60/145, Loss: 0.5626
Epoch 3/10, Batch 70/145, Loss: 0.2944
Epoch 3/10, Batch 80/145, Loss: 0.2292
Epoch 3/10, Batch 90/145, Loss: 0.1446
Epoch 3/10, Batch 100/145, Loss: 0.2470
Epoch 3/10, Batch 110/145, Loss: 0.1544
Epoch 3/10, Batch 120/145, Loss: 0.2726
Epoch 3/10, Batch 130/145, Loss: 0.2727
Epoch 3/10, Batch 140/145, Loss: 0.3116
Epoch 3/10, Train Loss: 0.2905, Valid Loss: 0.2705
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2336
Epoch 4/10, Batch 20/145, Loss: 0.3237
Epoch 4/10, Batch 30/145, Loss: 0.4813
Epoch 4/10, Batch 40/145, Loss: 0.2384
Epoch 4/10, Batch 50/145, Loss: 0.1839
Epoch 4/10, Batch 60/145, Loss: 0.2604
Epoch 4/10, Batch 70/145, Loss: 0.1736
Epoch 4/10, Batch 80/145, Loss: 0.1580
Epoch 4/10, Batch 90/145, Loss: 0.1602
Epoch 4/10, Batch 100/145, Loss: 0.1957
Epoch 4/10, Batch 110/145, Loss: 0.1529
Epoch 4/10, Batch 120/145, Loss: 0.2232
Epoch 4/10, Batch 130/145, Loss: 0.1687
Epoch 4/10, Batch 140/145, Loss: 0.0867
Epoch 4/10, Train Loss: 0.2526, Valid Loss: 0.2566
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1811
Epoch 5/10, Batch 20/145, Loss: 0.1789
Epoch 5/10, Batch 30/145, Loss: 0.1451
Epoch 5/10, Batch 40/145, Loss: 0.1562
Epoch 5/10, Batch 50/145, Loss: 0.2795
Epoch 5/10, Batch 60/145, Loss: 0.1859
Epoch 5/10, Batch 70/145, Loss: 0.1998
Epoch 5/10, Batch 80/145, Loss: 0.2158
Epoch 5/10, Batch 90/145, Loss: 0.2846
Epoch 5/10, Batch 100/145, Loss: 0.1977
Epoch 5/10, Batch 110/145, Loss: 0.2468
Epoch 5/10, Batch 120/145, Loss: 0.2823
Epoch 5/10, Batch 130/145, Loss: 0.1838
Epoch 5/10, Batch 140/145, Loss: 0.2020
Epoch 5/10, Train Loss: 0.2400, Valid Loss: 0.2503
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2140
Epoch 6/10, Batch 20/145, Loss: 0.3433
Epoch 6/10, Batch 30/145, Loss: 0.2879
Epoch 6/10, Batch 40/145, Loss: 0.1333
Epoch 6/10, Batch 50/145, Loss: 0.2721
Epoch 6/10, Batch 60/145, Loss: 0.2167
Epoch 6/10, Batch 70/145, Loss: 0.1119
Epoch 6/10, Batch 80/145, Loss: 0.1793
Epoch 6/10, Batch 90/145, Loss: 0.3900
Epoch 6/10, Batch 100/145, Loss: 0.2400
Epoch 6/10, Batch 110/145, Loss: 0.1136
Epoch 6/10, Batch 120/145, Loss: 0.2832
Epoch 6/10, Batch 130/145, Loss: 0.1589
Epoch 6/10, Batch 140/145, Loss: 0.2515
Epoch 6/10, Train Loss: 0.2199, Valid Loss: 0.2402
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2638
Epoch 7/10, Batch 20/145, Loss: 0.2981
Epoch 7/10, Batch 30/145, Loss: 0.3434
Epoch 7/10, Batch 40/145, Loss: 0.4398
Epoch 7/10, Batch 50/145, Loss: 0.1306
Epoch 7/10, Batch 60/145, Loss: 0.1822
Epoch 7/10, Batch 70/145, Loss: 0.1214
Epoch 7/10, Batch 80/145, Loss: 0.4334
Epoch 7/10, Batch 90/145, Loss: 0.1703
Epoch 7/10, Batch 100/145, Loss: 0.2277
Epoch 7/10, Batch 110/145, Loss: 0.1305
Epoch 7/10, Batch 120/145, Loss: 0.1827
Epoch 7/10, Batch 130/145, Loss: 0.1736
Epoch 7/10, Batch 140/145, Loss: 0.1822
Epoch 7/10, Train Loss: 0.2150, Valid Loss: 0.2379
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2737
Epoch 8/10, Batch 20/145, Loss: 0.2610
Epoch 8/10, Batch 30/145, Loss: 0.2123
Epoch 8/10, Batch 40/145, Loss: 0.2119
Epoch 8/10, Batch 50/145, Loss: 0.2773
Epoch 8/10, Batch 60/145, Loss: 0.2565
Epoch 8/10, Batch 70/145, Loss: 0.2413
Epoch 8/10, Batch 80/145, Loss: 0.2598
Epoch 8/10, Batch 90/145, Loss: 0.2750
Epoch 8/10, Batch 100/145, Loss: 0.2760
Epoch 8/10, Batch 110/145, Loss: 0.1417
Epoch 8/10, Batch 120/145, Loss: 0.3098
Epoch 8/10, Batch 130/145, Loss: 0.1802
Epoch 8/10, Batch 140/145, Loss: 0.2077
Epoch 8/10, Train Loss: 0.2068, Valid Loss: 0.2296
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2081
Epoch 9/10, Batch 20/145, Loss: 0.1205
Epoch 9/10, Batch 30/145, Loss: 0.1395
Epoch 9/10, Batch 40/145, Loss: 0.2625
Epoch 9/10, Batch 50/145, Loss: 0.2984
Epoch 9/10, Batch 60/145, Loss: 0.3113
Epoch 9/10, Batch 70/145, Loss: 0.1264
Epoch 9/10, Batch 80/145, Loss: 0.1656
Epoch 9/10, Batch 90/145, Loss: 0.3332
Epoch 9/10, Batch 100/145, Loss: 0.1624
Epoch 9/10, Batch 110/145, Loss: 0.2051
Epoch 9/10, Batch 120/145, Loss: 0.1039
Epoch 9/10, Batch 130/145, Loss: 0.1700
Epoch 9/10, Batch 140/145, Loss: 0.1598
Epoch 9/10, Train Loss: 0.1962, Valid Loss: 0.2264
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1462
Epoch 10/10, Batch 20/145, Loss: 0.1790
Epoch 10/10, Batch 30/145, Loss: 0.0605
Epoch 10/10, Batch 40/145, Loss: 0.1272
Epoch 10/10, Batch 50/145, Loss: 0.2208
Epoch 10/10, Batch 60/145, Loss: 0.1809
Epoch 10/10, Batch 70/145, Loss: 0.3918
Epoch 10/10, Batch 80/145, Loss: 0.2125
Epoch 10/10, Batch 90/145, Loss: 0.1527
Epoch 10/10, Batch 100/145, Loss: 0.1747
Epoch 10/10, Batch 110/145, Loss: 0.2336
Epoch 10/10, Batch 120/145, Loss: 0.1505
Epoch 10/10, Batch 130/145, Loss: 0.2150
Epoch 10/10, Batch 140/145, Loss: 0.1234
Epoch 10/10, Train Loss: 0.1885, Valid Loss: 0.2301
Accuracy: 0.9159
Precision: 0.9145
Recall: 0.9159
F1-score: 0.9147
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3462
Epoch 1/10, Batch 20/145, Loss: 0.9050
Epoch 1/10, Batch 30/145, Loss: 0.8765
Epoch 1/10, Batch 40/145, Loss: 0.7781
Epoch 1/10, Batch 50/145, Loss: 0.7472
Epoch 1/10, Batch 60/145, Loss: 0.5809
Epoch 1/10, Batch 70/145, Loss: 0.4658
Epoch 1/10, Batch 80/145, Loss: 0.5532
Epoch 1/10, Batch 90/145, Loss: 0.5095
Epoch 1/10, Batch 100/145, Loss: 0.4538
Epoch 1/10, Batch 110/145, Loss: 0.4444
Epoch 1/10, Batch 120/145, Loss: 0.4022
Epoch 1/10, Batch 130/145, Loss: 0.4663
Epoch 1/10, Batch 140/145, Loss: 0.3318
Epoch 1/10, Train Loss: 0.6729, Valid Loss: 0.3865
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3500
Epoch 2/10, Batch 20/145, Loss: 0.3573
Epoch 2/10, Batch 30/145, Loss: 0.2693
Epoch 2/10, Batch 40/145, Loss: 0.4199
Epoch 2/10, Batch 50/145, Loss: 0.3976
Epoch 2/10, Batch 60/145, Loss: 0.3927
Epoch 2/10, Batch 70/145, Loss: 0.2730
Epoch 2/10, Batch 80/145, Loss: 0.3367
Epoch 2/10, Batch 90/145, Loss: 0.2703
Epoch 2/10, Batch 100/145, Loss: 0.2847
Epoch 2/10, Batch 110/145, Loss: 0.2605
Epoch 2/10, Batch 120/145, Loss: 0.3721
Epoch 2/10, Batch 130/145, Loss: 0.3057
Epoch 2/10, Batch 140/145, Loss: 0.3520
Epoch 2/10, Train Loss: 0.3470, Valid Loss: 0.2994
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3030
Epoch 3/10, Batch 20/145, Loss: 0.3401
Epoch 3/10, Batch 30/145, Loss: 0.3072
Epoch 3/10, Batch 40/145, Loss: 0.1202
Epoch 3/10, Batch 50/145, Loss: 0.2025
Epoch 3/10, Batch 60/145, Loss: 0.4993
Epoch 3/10, Batch 70/145, Loss: 0.3063
Epoch 3/10, Batch 80/145, Loss: 0.2726
Epoch 3/10, Batch 90/145, Loss: 0.2454
Epoch 3/10, Batch 100/145, Loss: 0.1461
Epoch 3/10, Batch 110/145, Loss: 0.2499
Epoch 3/10, Batch 120/145, Loss: 0.4228
Epoch 3/10, Batch 130/145, Loss: 0.2860
Epoch 3/10, Batch 140/145, Loss: 0.2351
Epoch 3/10, Train Loss: 0.2839, Valid Loss: 0.2710
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3976
Epoch 4/10, Batch 20/145, Loss: 0.2642
Epoch 4/10, Batch 30/145, Loss: 0.2950
Epoch 4/10, Batch 40/145, Loss: 0.3321
Epoch 4/10, Batch 50/145, Loss: 0.2060
Epoch 4/10, Batch 60/145, Loss: 0.3094
Epoch 4/10, Batch 70/145, Loss: 0.1256
Epoch 4/10, Batch 80/145, Loss: 0.1293
Epoch 4/10, Batch 90/145, Loss: 0.2037
Epoch 4/10, Batch 100/145, Loss: 0.4213
Epoch 4/10, Batch 110/145, Loss: 0.2496
Epoch 4/10, Batch 120/145, Loss: 0.1546
Epoch 4/10, Batch 130/145, Loss: 0.2032
Epoch 4/10, Batch 140/145, Loss: 0.1987
Epoch 4/10, Train Loss: 0.2463, Valid Loss: 0.2592
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2517
Epoch 5/10, Batch 20/145, Loss: 0.2839
Epoch 5/10, Batch 30/145, Loss: 0.3509
Epoch 5/10, Batch 40/145, Loss: 0.1435
Epoch 5/10, Batch 50/145, Loss: 0.2659
Epoch 5/10, Batch 60/145, Loss: 0.2754
Epoch 5/10, Batch 70/145, Loss: 0.3956
Epoch 5/10, Batch 80/145, Loss: 0.2187
Epoch 5/10, Batch 90/145, Loss: 0.1789
Epoch 5/10, Batch 100/145, Loss: 0.1223
Epoch 5/10, Batch 110/145, Loss: 0.2141
Epoch 5/10, Batch 120/145, Loss: 0.2989
Epoch 5/10, Batch 130/145, Loss: 0.1089
Epoch 5/10, Batch 140/145, Loss: 0.1564
Epoch 5/10, Train Loss: 0.2364, Valid Loss: 0.2462
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2454
Epoch 6/10, Batch 20/145, Loss: 0.6517
Epoch 6/10, Batch 30/145, Loss: 0.4708
Epoch 6/10, Batch 40/145, Loss: 0.1097
Epoch 6/10, Batch 50/145, Loss: 0.2822
Epoch 6/10, Batch 60/145, Loss: 0.2442
Epoch 6/10, Batch 70/145, Loss: 0.1320
Epoch 6/10, Batch 80/145, Loss: 0.1248
Epoch 6/10, Batch 90/145, Loss: 0.3036
Epoch 6/10, Batch 100/145, Loss: 0.2635
Epoch 6/10, Batch 110/145, Loss: 0.1357
Epoch 6/10, Batch 120/145, Loss: 0.3369
Epoch 6/10, Batch 130/145, Loss: 0.1413
Epoch 6/10, Batch 140/145, Loss: 0.2752
Epoch 6/10, Train Loss: 0.2218, Valid Loss: 0.2502
Epoch 7/10, Batch 10/145, Loss: 0.2762
Epoch 7/10, Batch 20/145, Loss: 0.4676
Epoch 7/10, Batch 30/145, Loss: 0.1882
Epoch 7/10, Batch 40/145, Loss: 0.5244
Epoch 7/10, Batch 50/145, Loss: 0.1474
Epoch 7/10, Batch 60/145, Loss: 0.1568
Epoch 7/10, Batch 70/145, Loss: 0.1163
Epoch 7/10, Batch 80/145, Loss: 0.3886
Epoch 7/10, Batch 90/145, Loss: 0.1650
Epoch 7/10, Batch 100/145, Loss: 0.1288
Epoch 7/10, Batch 110/145, Loss: 0.2862
Epoch 7/10, Batch 120/145, Loss: 0.2921
Epoch 7/10, Batch 130/145, Loss: 0.1425
Epoch 7/10, Batch 140/145, Loss: 0.2579
Epoch 7/10, Train Loss: 0.2080, Valid Loss: 0.2391
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2418
Epoch 8/10, Batch 20/145, Loss: 0.1328
Epoch 8/10, Batch 30/145, Loss: 0.3272
Epoch 8/10, Batch 40/145, Loss: 0.3115
Epoch 8/10, Batch 50/145, Loss: 0.2885
Epoch 8/10, Batch 60/145, Loss: 0.2353
Epoch 8/10, Batch 70/145, Loss: 0.2717
Epoch 8/10, Batch 80/145, Loss: 0.1561
Epoch 8/10, Batch 90/145, Loss: 0.3516
Epoch 8/10, Batch 100/145, Loss: 0.1183
Epoch 8/10, Batch 110/145, Loss: 0.1126
Epoch 8/10, Batch 120/145, Loss: 0.1735
Epoch 8/10, Batch 130/145, Loss: 0.1728
Epoch 8/10, Batch 140/145, Loss: 0.1403
Epoch 8/10, Train Loss: 0.1966, Valid Loss: 0.2275
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2312
Epoch 9/10, Batch 20/145, Loss: 0.1204
Epoch 9/10, Batch 30/145, Loss: 0.1157
Epoch 9/10, Batch 40/145, Loss: 0.2439
Epoch 9/10, Batch 50/145, Loss: 0.1882
Epoch 9/10, Batch 60/145, Loss: 0.1340
Epoch 9/10, Batch 70/145, Loss: 0.1414
Epoch 9/10, Batch 80/145, Loss: 0.1236
Epoch 9/10, Batch 90/145, Loss: 0.2311
Epoch 9/10, Batch 100/145, Loss: 0.1686
Epoch 9/10, Batch 110/145, Loss: 0.2657
Epoch 9/10, Batch 120/145, Loss: 0.0394
Epoch 9/10, Batch 130/145, Loss: 0.3676
Epoch 9/10, Batch 140/145, Loss: 0.2365
Epoch 9/10, Train Loss: 0.1921, Valid Loss: 0.2334
Epoch 10/10, Batch 10/145, Loss: 0.1297
Epoch 10/10, Batch 20/145, Loss: 0.1515
Epoch 10/10, Batch 30/145, Loss: 0.1183
Epoch 10/10, Batch 40/145, Loss: 0.0968
Epoch 10/10, Batch 50/145, Loss: 0.2035
Epoch 10/10, Batch 60/145, Loss: 0.1029
Epoch 10/10, Batch 70/145, Loss: 0.3085
Epoch 10/10, Batch 80/145, Loss: 0.2602
Epoch 10/10, Batch 90/145, Loss: 0.1309
Epoch 10/10, Batch 100/145, Loss: 0.1633
Epoch 10/10, Batch 110/145, Loss: 0.0721
Epoch 10/10, Batch 120/145, Loss: 0.1982
Epoch 10/10, Batch 130/145, Loss: 0.1581
Epoch 10/10, Batch 140/145, Loss: 0.2669
Epoch 10/10, Train Loss: 0.1851, Valid Loss: 0.2227
Model saved!
Accuracy: 0.9194
Precision: 0.9173
Recall: 0.9194
F1-score: 0.9180
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3788
Epoch 1/10, Batch 20/145, Loss: 0.9336
Epoch 1/10, Batch 30/145, Loss: 0.9539
Epoch 1/10, Batch 40/145, Loss: 0.8091
Epoch 1/10, Batch 50/145, Loss: 0.7134
Epoch 1/10, Batch 60/145, Loss: 0.6095
Epoch 1/10, Batch 70/145, Loss: 0.6204
Epoch 1/10, Batch 80/145, Loss: 0.6217
Epoch 1/10, Batch 90/145, Loss: 0.4069
Epoch 1/10, Batch 100/145, Loss: 0.5007
Epoch 1/10, Batch 110/145, Loss: 0.4491
Epoch 1/10, Batch 120/145, Loss: 0.6225
Epoch 1/10, Batch 130/145, Loss: 0.5162
Epoch 1/10, Batch 140/145, Loss: 0.2526
Epoch 1/10, Train Loss: 0.6763, Valid Loss: 0.3785
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2739
Epoch 2/10, Batch 20/145, Loss: 0.3840
Epoch 2/10, Batch 30/145, Loss: 0.2626
Epoch 2/10, Batch 40/145, Loss: 0.5167
Epoch 2/10, Batch 50/145, Loss: 0.3137
Epoch 2/10, Batch 60/145, Loss: 0.3739
Epoch 2/10, Batch 70/145, Loss: 0.3879
Epoch 2/10, Batch 80/145, Loss: 0.2297
Epoch 2/10, Batch 90/145, Loss: 0.2988
Epoch 2/10, Batch 100/145, Loss: 0.3555
Epoch 2/10, Batch 110/145, Loss: 0.3686
Epoch 2/10, Batch 120/145, Loss: 0.3701
Epoch 2/10, Batch 130/145, Loss: 0.3059
Epoch 2/10, Batch 140/145, Loss: 0.2375
Epoch 2/10, Train Loss: 0.3548, Valid Loss: 0.2930
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2010
Epoch 3/10, Batch 20/145, Loss: 0.2437
Epoch 3/10, Batch 30/145, Loss: 0.3856
Epoch 3/10, Batch 40/145, Loss: 0.2462
Epoch 3/10, Batch 50/145, Loss: 0.2667
Epoch 3/10, Batch 60/145, Loss: 0.3182
Epoch 3/10, Batch 70/145, Loss: 0.2986
Epoch 3/10, Batch 80/145, Loss: 0.3113
Epoch 3/10, Batch 90/145, Loss: 0.2964
Epoch 3/10, Batch 100/145, Loss: 0.2259
Epoch 3/10, Batch 110/145, Loss: 0.3577
Epoch 3/10, Batch 120/145, Loss: 0.2968
Epoch 3/10, Batch 130/145, Loss: 0.3112
Epoch 3/10, Batch 140/145, Loss: 0.2497
Epoch 3/10, Train Loss: 0.2905, Valid Loss: 0.2602
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3129
Epoch 4/10, Batch 20/145, Loss: 0.1965
Epoch 4/10, Batch 30/145, Loss: 0.1979
Epoch 4/10, Batch 40/145, Loss: 0.1200
Epoch 4/10, Batch 50/145, Loss: 0.2303
Epoch 4/10, Batch 60/145, Loss: 0.2406
Epoch 4/10, Batch 70/145, Loss: 0.1804
Epoch 4/10, Batch 80/145, Loss: 0.1686
Epoch 4/10, Batch 90/145, Loss: 0.2412
Epoch 4/10, Batch 100/145, Loss: 0.3523
Epoch 4/10, Batch 110/145, Loss: 0.1529
Epoch 4/10, Batch 120/145, Loss: 0.2852
Epoch 4/10, Batch 130/145, Loss: 0.1915
Epoch 4/10, Batch 140/145, Loss: 0.1296
Epoch 4/10, Train Loss: 0.2566, Valid Loss: 0.2478
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1953
Epoch 5/10, Batch 20/145, Loss: 0.1390
Epoch 5/10, Batch 30/145, Loss: 0.2071
Epoch 5/10, Batch 40/145, Loss: 0.1580
Epoch 5/10, Batch 50/145, Loss: 0.1433
Epoch 5/10, Batch 60/145, Loss: 0.1025
Epoch 5/10, Batch 70/145, Loss: 0.1933
Epoch 5/10, Batch 80/145, Loss: 0.3517
Epoch 5/10, Batch 90/145, Loss: 0.3668
Epoch 5/10, Batch 100/145, Loss: 0.1130
Epoch 5/10, Batch 110/145, Loss: 0.3025
Epoch 5/10, Batch 120/145, Loss: 0.4962
Epoch 5/10, Batch 130/145, Loss: 0.2211
Epoch 5/10, Batch 140/145, Loss: 0.2246
Epoch 5/10, Train Loss: 0.2405, Valid Loss: 0.2351
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2341
Epoch 6/10, Batch 20/145, Loss: 0.4410
Epoch 6/10, Batch 30/145, Loss: 0.3155
Epoch 6/10, Batch 40/145, Loss: 0.1154
Epoch 6/10, Batch 50/145, Loss: 0.3139
Epoch 6/10, Batch 60/145, Loss: 0.2042
Epoch 6/10, Batch 70/145, Loss: 0.0636
Epoch 6/10, Batch 80/145, Loss: 0.1840
Epoch 6/10, Batch 90/145, Loss: 0.2465
Epoch 6/10, Batch 100/145, Loss: 0.3228
Epoch 6/10, Batch 110/145, Loss: 0.2272
Epoch 6/10, Batch 120/145, Loss: 0.2390
Epoch 6/10, Batch 130/145, Loss: 0.0966
Epoch 6/10, Batch 140/145, Loss: 0.2885
Epoch 6/10, Train Loss: 0.2350, Valid Loss: 0.2219
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1804
Epoch 7/10, Batch 20/145, Loss: 0.3768
Epoch 7/10, Batch 30/145, Loss: 0.2122
Epoch 7/10, Batch 40/145, Loss: 0.6434
Epoch 7/10, Batch 50/145, Loss: 0.2660
Epoch 7/10, Batch 60/145, Loss: 0.0873
Epoch 7/10, Batch 70/145, Loss: 0.2005
Epoch 7/10, Batch 80/145, Loss: 0.5187
Epoch 7/10, Batch 90/145, Loss: 0.1574
Epoch 7/10, Batch 100/145, Loss: 0.2047
Epoch 7/10, Batch 110/145, Loss: 0.1240
Epoch 7/10, Batch 120/145, Loss: 0.2771
Epoch 7/10, Batch 130/145, Loss: 0.1130
Epoch 7/10, Batch 140/145, Loss: 0.5011
Epoch 7/10, Train Loss: 0.2201, Valid Loss: 0.2179
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1169
Epoch 8/10, Batch 20/145, Loss: 0.2774
Epoch 8/10, Batch 30/145, Loss: 0.1884
Epoch 8/10, Batch 40/145, Loss: 0.1547
Epoch 8/10, Batch 50/145, Loss: 0.1265
Epoch 8/10, Batch 60/145, Loss: 0.2310
Epoch 8/10, Batch 70/145, Loss: 0.2100
Epoch 8/10, Batch 80/145, Loss: 0.2181
Epoch 8/10, Batch 90/145, Loss: 0.2066
Epoch 8/10, Batch 100/145, Loss: 0.1514
Epoch 8/10, Batch 110/145, Loss: 0.2585
Epoch 8/10, Batch 120/145, Loss: 0.2678
Epoch 8/10, Batch 130/145, Loss: 0.1635
Epoch 8/10, Batch 140/145, Loss: 0.1904
Epoch 8/10, Train Loss: 0.2081, Valid Loss: 0.2124
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2704
Epoch 9/10, Batch 20/145, Loss: 0.1720
Epoch 9/10, Batch 30/145, Loss: 0.3819
Epoch 9/10, Batch 40/145, Loss: 0.1842
Epoch 9/10, Batch 50/145, Loss: 0.1485
Epoch 9/10, Batch 60/145, Loss: 0.3215
Epoch 9/10, Batch 70/145, Loss: 0.1930
Epoch 9/10, Batch 80/145, Loss: 0.1283
Epoch 9/10, Batch 90/145, Loss: 0.2305
Epoch 9/10, Batch 100/145, Loss: 0.1823
Epoch 9/10, Batch 110/145, Loss: 0.2125
Epoch 9/10, Batch 120/145, Loss: 0.1488
Epoch 9/10, Batch 130/145, Loss: 0.1137
Epoch 9/10, Batch 140/145, Loss: 0.3150
Epoch 9/10, Train Loss: 0.2062, Valid Loss: 0.2090
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0703
Epoch 10/10, Batch 20/145, Loss: 0.1092
Epoch 10/10, Batch 30/145, Loss: 0.1607
Epoch 10/10, Batch 40/145, Loss: 0.2193
Epoch 10/10, Batch 50/145, Loss: 0.1954
Epoch 10/10, Batch 60/145, Loss: 0.1612
Epoch 10/10, Batch 70/145, Loss: 0.2017
Epoch 10/10, Batch 80/145, Loss: 0.1489
Epoch 10/10, Batch 90/145, Loss: 0.0718
Epoch 10/10, Batch 100/145, Loss: 0.3141
Epoch 10/10, Batch 110/145, Loss: 0.2226
Epoch 10/10, Batch 120/145, Loss: 0.2986
Epoch 10/10, Batch 130/145, Loss: 0.0779
Epoch 10/10, Batch 140/145, Loss: 0.1133
Epoch 10/10, Train Loss: 0.1927, Valid Loss: 0.2111
Accuracy: 0.9241
Precision: 0.9230
Recall: 0.9241
F1-score: 0.9234
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3629
Epoch 1/10, Batch 20/145, Loss: 0.9320
Epoch 1/10, Batch 30/145, Loss: 0.8698
Epoch 1/10, Batch 40/145, Loss: 0.6499
Epoch 1/10, Batch 50/145, Loss: 0.7512
Epoch 1/10, Batch 60/145, Loss: 0.6455
Epoch 1/10, Batch 70/145, Loss: 0.5523
Epoch 1/10, Batch 80/145, Loss: 0.6103
Epoch 1/10, Batch 90/145, Loss: 0.5772
Epoch 1/10, Batch 100/145, Loss: 0.4227
Epoch 1/10, Batch 110/145, Loss: 0.3930
Epoch 1/10, Batch 120/145, Loss: 0.5628
Epoch 1/10, Batch 130/145, Loss: 0.5719
Epoch 1/10, Batch 140/145, Loss: 0.3130
Epoch 1/10, Train Loss: 0.6742, Valid Loss: 0.3769
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3598
Epoch 2/10, Batch 20/145, Loss: 0.2805
Epoch 2/10, Batch 30/145, Loss: 0.2765
Epoch 2/10, Batch 40/145, Loss: 0.4308
Epoch 2/10, Batch 50/145, Loss: 0.3210
Epoch 2/10, Batch 60/145, Loss: 0.2330
Epoch 2/10, Batch 70/145, Loss: 0.3783
Epoch 2/10, Batch 80/145, Loss: 0.3691
Epoch 2/10, Batch 90/145, Loss: 0.2904
Epoch 2/10, Batch 100/145, Loss: 0.4973
Epoch 2/10, Batch 110/145, Loss: 0.2675
Epoch 2/10, Batch 120/145, Loss: 0.5395
Epoch 2/10, Batch 130/145, Loss: 0.2577
Epoch 2/10, Batch 140/145, Loss: 0.2354
Epoch 2/10, Train Loss: 0.3482, Valid Loss: 0.2943
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2994
Epoch 3/10, Batch 20/145, Loss: 0.1917
Epoch 3/10, Batch 30/145, Loss: 0.4998
Epoch 3/10, Batch 40/145, Loss: 0.1893
Epoch 3/10, Batch 50/145, Loss: 0.2928
Epoch 3/10, Batch 60/145, Loss: 0.3978
Epoch 3/10, Batch 70/145, Loss: 0.4355
Epoch 3/10, Batch 80/145, Loss: 0.2020
Epoch 3/10, Batch 90/145, Loss: 0.2035
Epoch 3/10, Batch 100/145, Loss: 0.1860
Epoch 3/10, Batch 110/145, Loss: 0.2050
Epoch 3/10, Batch 120/145, Loss: 0.1952
Epoch 3/10, Batch 130/145, Loss: 0.2714
Epoch 3/10, Batch 140/145, Loss: 0.2781
Epoch 3/10, Train Loss: 0.2873, Valid Loss: 0.2623
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4140
Epoch 4/10, Batch 20/145, Loss: 0.3797
Epoch 4/10, Batch 30/145, Loss: 0.3003
Epoch 4/10, Batch 40/145, Loss: 0.2411
Epoch 4/10, Batch 50/145, Loss: 0.1720
Epoch 4/10, Batch 60/145, Loss: 0.3333
Epoch 4/10, Batch 70/145, Loss: 0.1608
Epoch 4/10, Batch 80/145, Loss: 0.1915
Epoch 4/10, Batch 90/145, Loss: 0.1332
Epoch 4/10, Batch 100/145, Loss: 0.3214
Epoch 4/10, Batch 110/145, Loss: 0.1367
Epoch 4/10, Batch 120/145, Loss: 0.3463
Epoch 4/10, Batch 130/145, Loss: 0.1782
Epoch 4/10, Batch 140/145, Loss: 0.1792
Epoch 4/10, Train Loss: 0.2529, Valid Loss: 0.2480
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1601
Epoch 5/10, Batch 20/145, Loss: 0.1060
Epoch 5/10, Batch 30/145, Loss: 0.2117
Epoch 5/10, Batch 40/145, Loss: 0.1526
Epoch 5/10, Batch 50/145, Loss: 0.2292
Epoch 5/10, Batch 60/145, Loss: 0.2579
Epoch 5/10, Batch 70/145, Loss: 0.2921
Epoch 5/10, Batch 80/145, Loss: 0.2427
Epoch 5/10, Batch 90/145, Loss: 0.2054
Epoch 5/10, Batch 100/145, Loss: 0.2262
Epoch 5/10, Batch 110/145, Loss: 0.2319
Epoch 5/10, Batch 120/145, Loss: 0.3644
Epoch 5/10, Batch 130/145, Loss: 0.1919
Epoch 5/10, Batch 140/145, Loss: 0.1938
Epoch 5/10, Train Loss: 0.2447, Valid Loss: 0.2407
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2819
Epoch 6/10, Batch 20/145, Loss: 0.3379
Epoch 6/10, Batch 30/145, Loss: 0.3349
Epoch 6/10, Batch 40/145, Loss: 0.3614
Epoch 6/10, Batch 50/145, Loss: 0.4257
Epoch 6/10, Batch 60/145, Loss: 0.2399
Epoch 6/10, Batch 70/145, Loss: 0.1590
Epoch 6/10, Batch 80/145, Loss: 0.1035
Epoch 6/10, Batch 90/145, Loss: 0.3484
Epoch 6/10, Batch 100/145, Loss: 0.4344
Epoch 6/10, Batch 110/145, Loss: 0.2343
Epoch 6/10, Batch 120/145, Loss: 0.2582
Epoch 6/10, Batch 130/145, Loss: 0.2763
Epoch 6/10, Batch 140/145, Loss: 0.1162
Epoch 6/10, Train Loss: 0.2169, Valid Loss: 0.2272
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1391
Epoch 7/10, Batch 20/145, Loss: 0.3444
Epoch 7/10, Batch 30/145, Loss: 0.1598
Epoch 7/10, Batch 40/145, Loss: 0.2643
Epoch 7/10, Batch 50/145, Loss: 0.1792
Epoch 7/10, Batch 60/145, Loss: 0.1676
Epoch 7/10, Batch 70/145, Loss: 0.1524
Epoch 7/10, Batch 80/145, Loss: 0.4339
Epoch 7/10, Batch 90/145, Loss: 0.0997
Epoch 7/10, Batch 100/145, Loss: 0.1643
Epoch 7/10, Batch 110/145, Loss: 0.1879
Epoch 7/10, Batch 120/145, Loss: 0.3146
Epoch 7/10, Batch 130/145, Loss: 0.1457
Epoch 7/10, Batch 140/145, Loss: 0.1461
Epoch 7/10, Train Loss: 0.2040, Valid Loss: 0.2246
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1608
Epoch 8/10, Batch 20/145, Loss: 0.2626
Epoch 8/10, Batch 30/145, Loss: 0.2199
Epoch 8/10, Batch 40/145, Loss: 0.1576
Epoch 8/10, Batch 50/145, Loss: 0.1665
Epoch 8/10, Batch 60/145, Loss: 0.2489
Epoch 8/10, Batch 70/145, Loss: 0.2782
Epoch 8/10, Batch 80/145, Loss: 0.1914
Epoch 8/10, Batch 90/145, Loss: 0.2986
Epoch 8/10, Batch 100/145, Loss: 0.1528
Epoch 8/10, Batch 110/145, Loss: 0.1848
Epoch 8/10, Batch 120/145, Loss: 0.2332
Epoch 8/10, Batch 130/145, Loss: 0.1592
Epoch 8/10, Batch 140/145, Loss: 0.2443
Epoch 8/10, Train Loss: 0.2067, Valid Loss: 0.2219
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3106
Epoch 9/10, Batch 20/145, Loss: 0.1468
Epoch 9/10, Batch 30/145, Loss: 0.1654
Epoch 9/10, Batch 40/145, Loss: 0.2050
Epoch 9/10, Batch 50/145, Loss: 0.1758
Epoch 9/10, Batch 60/145, Loss: 0.1668
Epoch 9/10, Batch 70/145, Loss: 0.2022
Epoch 9/10, Batch 80/145, Loss: 0.0647
Epoch 9/10, Batch 90/145, Loss: 0.1372
Epoch 9/10, Batch 100/145, Loss: 0.2093
Epoch 9/10, Batch 110/145, Loss: 0.2009
Epoch 9/10, Batch 120/145, Loss: 0.0708
Epoch 9/10, Batch 130/145, Loss: 0.0968
Epoch 9/10, Batch 140/145, Loss: 0.2979
Epoch 9/10, Train Loss: 0.2001, Valid Loss: 0.2267
Epoch 10/10, Batch 10/145, Loss: 0.1821
Epoch 10/10, Batch 20/145, Loss: 0.2414
Epoch 10/10, Batch 30/145, Loss: 0.1838
Epoch 10/10, Batch 40/145, Loss: 0.2084
Epoch 10/10, Batch 50/145, Loss: 0.3141
Epoch 10/10, Batch 60/145, Loss: 0.1166
Epoch 10/10, Batch 70/145, Loss: 0.2664
Epoch 10/10, Batch 80/145, Loss: 0.1963
Epoch 10/10, Batch 90/145, Loss: 0.1121
Epoch 10/10, Batch 100/145, Loss: 0.2167
Epoch 10/10, Batch 110/145, Loss: 0.4350
Epoch 10/10, Batch 120/145, Loss: 0.1964
Epoch 10/10, Batch 130/145, Loss: 0.1699
Epoch 10/10, Batch 140/145, Loss: 0.1609
Epoch 10/10, Train Loss: 0.1989, Valid Loss: 0.2214
Model saved!
Accuracy: 0.9100
Precision: 0.9066
Recall: 0.9100
F1-score: 0.9061
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4887
Epoch 1/10, Batch 20/145, Loss: 0.9449
Epoch 1/10, Batch 30/145, Loss: 0.9067
Epoch 1/10, Batch 40/145, Loss: 0.7581
Epoch 1/10, Batch 50/145, Loss: 0.6841
Epoch 1/10, Batch 60/145, Loss: 0.6312
Epoch 1/10, Batch 70/145, Loss: 0.4867
Epoch 1/10, Batch 80/145, Loss: 0.5333
Epoch 1/10, Batch 90/145, Loss: 0.4637
Epoch 1/10, Batch 100/145, Loss: 0.4806
Epoch 1/10, Batch 110/145, Loss: 0.5081
Epoch 1/10, Batch 120/145, Loss: 0.4704
Epoch 1/10, Batch 130/145, Loss: 0.5357
Epoch 1/10, Batch 140/145, Loss: 0.4381
Epoch 1/10, Train Loss: 0.6835, Valid Loss: 0.3881
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3131
Epoch 2/10, Batch 20/145, Loss: 0.3342
Epoch 2/10, Batch 30/145, Loss: 0.2561
Epoch 2/10, Batch 40/145, Loss: 0.5111
Epoch 2/10, Batch 50/145, Loss: 0.3564
Epoch 2/10, Batch 60/145, Loss: 0.4059
Epoch 2/10, Batch 70/145, Loss: 0.3280
Epoch 2/10, Batch 80/145, Loss: 0.2900
Epoch 2/10, Batch 90/145, Loss: 0.5009
Epoch 2/10, Batch 100/145, Loss: 0.2631
Epoch 2/10, Batch 110/145, Loss: 0.2642
Epoch 2/10, Batch 120/145, Loss: 0.4246
Epoch 2/10, Batch 130/145, Loss: 0.2136
Epoch 2/10, Batch 140/145, Loss: 0.2463
Epoch 2/10, Train Loss: 0.3634, Valid Loss: 0.3009
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3671
Epoch 3/10, Batch 20/145, Loss: 0.3803
Epoch 3/10, Batch 30/145, Loss: 0.5142
Epoch 3/10, Batch 40/145, Loss: 0.2404
Epoch 3/10, Batch 50/145, Loss: 0.1727
Epoch 3/10, Batch 60/145, Loss: 0.3857
Epoch 3/10, Batch 70/145, Loss: 0.4134
Epoch 3/10, Batch 80/145, Loss: 0.3695
Epoch 3/10, Batch 90/145, Loss: 0.2442
Epoch 3/10, Batch 100/145, Loss: 0.2519
Epoch 3/10, Batch 110/145, Loss: 0.3514
Epoch 3/10, Batch 120/145, Loss: 0.2778
Epoch 3/10, Batch 130/145, Loss: 0.4064
Epoch 3/10, Batch 140/145, Loss: 0.2302
Epoch 3/10, Train Loss: 0.3003, Valid Loss: 0.2642
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4300
Epoch 4/10, Batch 20/145, Loss: 0.2749
Epoch 4/10, Batch 30/145, Loss: 0.2548
Epoch 4/10, Batch 40/145, Loss: 0.1690
Epoch 4/10, Batch 50/145, Loss: 0.2097
Epoch 4/10, Batch 60/145, Loss: 0.5053
Epoch 4/10, Batch 70/145, Loss: 0.2372
Epoch 4/10, Batch 80/145, Loss: 0.2034
Epoch 4/10, Batch 90/145, Loss: 0.2076
Epoch 4/10, Batch 100/145, Loss: 0.3883
Epoch 4/10, Batch 110/145, Loss: 0.1573
Epoch 4/10, Batch 120/145, Loss: 0.2501
Epoch 4/10, Batch 130/145, Loss: 0.1571
Epoch 4/10, Batch 140/145, Loss: 0.1740
Epoch 4/10, Train Loss: 0.2596, Valid Loss: 0.2554
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2435
Epoch 5/10, Batch 20/145, Loss: 0.2283
Epoch 5/10, Batch 30/145, Loss: 0.1798
Epoch 5/10, Batch 40/145, Loss: 0.0930
Epoch 5/10, Batch 50/145, Loss: 0.1811
Epoch 5/10, Batch 60/145, Loss: 0.1843
Epoch 5/10, Batch 70/145, Loss: 0.2131
Epoch 5/10, Batch 80/145, Loss: 0.2035
Epoch 5/10, Batch 90/145, Loss: 0.2511
Epoch 5/10, Batch 100/145, Loss: 0.2976
Epoch 5/10, Batch 110/145, Loss: 0.3318
Epoch 5/10, Batch 120/145, Loss: 0.2699
Epoch 5/10, Batch 130/145, Loss: 0.2903
Epoch 5/10, Batch 140/145, Loss: 0.1869
Epoch 5/10, Train Loss: 0.2465, Valid Loss: 0.2400
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.0804
Epoch 6/10, Batch 20/145, Loss: 0.3247
Epoch 6/10, Batch 30/145, Loss: 0.2145
Epoch 6/10, Batch 40/145, Loss: 0.1212
Epoch 6/10, Batch 50/145, Loss: 0.2086
Epoch 6/10, Batch 60/145, Loss: 0.2197
Epoch 6/10, Batch 70/145, Loss: 0.3262
Epoch 6/10, Batch 80/145, Loss: 0.1590
Epoch 6/10, Batch 90/145, Loss: 0.1025
Epoch 6/10, Batch 100/145, Loss: 0.2710
Epoch 6/10, Batch 110/145, Loss: 0.1951
Epoch 6/10, Batch 120/145, Loss: 0.3028
Epoch 6/10, Batch 130/145, Loss: 0.1233
Epoch 6/10, Batch 140/145, Loss: 0.1940
Epoch 6/10, Train Loss: 0.2338, Valid Loss: 0.2308
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2518
Epoch 7/10, Batch 20/145, Loss: 0.1708
Epoch 7/10, Batch 30/145, Loss: 0.3009
Epoch 7/10, Batch 40/145, Loss: 0.2897
Epoch 7/10, Batch 50/145, Loss: 0.1366
Epoch 7/10, Batch 60/145, Loss: 0.1917
Epoch 7/10, Batch 70/145, Loss: 0.0888
Epoch 7/10, Batch 80/145, Loss: 0.3778
Epoch 7/10, Batch 90/145, Loss: 0.1374
Epoch 7/10, Batch 100/145, Loss: 0.1897
Epoch 7/10, Batch 110/145, Loss: 0.1938
Epoch 7/10, Batch 120/145, Loss: 0.2958
Epoch 7/10, Batch 130/145, Loss: 0.1212
Epoch 7/10, Batch 140/145, Loss: 0.1577
Epoch 7/10, Train Loss: 0.2240, Valid Loss: 0.2219
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1887
Epoch 8/10, Batch 20/145, Loss: 0.3461
Epoch 8/10, Batch 30/145, Loss: 0.3932
Epoch 8/10, Batch 40/145, Loss: 0.1997
Epoch 8/10, Batch 50/145, Loss: 0.1537
Epoch 8/10, Batch 60/145, Loss: 0.1750
Epoch 8/10, Batch 70/145, Loss: 0.3717
Epoch 8/10, Batch 80/145, Loss: 0.1208
Epoch 8/10, Batch 90/145, Loss: 0.3167
Epoch 8/10, Batch 100/145, Loss: 0.3527
Epoch 8/10, Batch 110/145, Loss: 0.1961
Epoch 8/10, Batch 120/145, Loss: 0.1938
Epoch 8/10, Batch 130/145, Loss: 0.1470
Epoch 8/10, Batch 140/145, Loss: 0.2054
Epoch 8/10, Train Loss: 0.2132, Valid Loss: 0.2224
Epoch 9/10, Batch 10/145, Loss: 0.2401
Epoch 9/10, Batch 20/145, Loss: 0.1654
Epoch 9/10, Batch 30/145, Loss: 0.1141
Epoch 9/10, Batch 40/145, Loss: 0.1534
Epoch 9/10, Batch 50/145, Loss: 0.2036
Epoch 9/10, Batch 60/145, Loss: 0.3905
Epoch 9/10, Batch 70/145, Loss: 0.1301
Epoch 9/10, Batch 80/145, Loss: 0.0817
Epoch 9/10, Batch 90/145, Loss: 0.2142
Epoch 9/10, Batch 100/145, Loss: 0.2350
Epoch 9/10, Batch 110/145, Loss: 0.1433
Epoch 9/10, Batch 120/145, Loss: 0.1177
Epoch 9/10, Batch 130/145, Loss: 0.1649
Epoch 9/10, Batch 140/145, Loss: 0.1743
Epoch 9/10, Train Loss: 0.2132, Valid Loss: 0.2234
Epoch 10/10, Batch 10/145, Loss: 0.1446
Epoch 10/10, Batch 20/145, Loss: 0.1765
Epoch 10/10, Batch 30/145, Loss: 0.1466
Epoch 10/10, Batch 40/145, Loss: 0.1045
Epoch 10/10, Batch 50/145, Loss: 0.1870
Epoch 10/10, Batch 60/145, Loss: 0.1107
Epoch 10/10, Batch 70/145, Loss: 0.2548
Epoch 10/10, Batch 80/145, Loss: 0.2008
Epoch 10/10, Batch 90/145, Loss: 0.1970
Epoch 10/10, Batch 100/145, Loss: 0.3021
Epoch 10/10, Batch 110/145, Loss: 0.1859
Epoch 10/10, Batch 120/145, Loss: 0.2597
Epoch 10/10, Batch 130/145, Loss: 0.2650
Epoch 10/10, Batch 140/145, Loss: 0.2168
Epoch 10/10, Train Loss: 0.2060, Valid Loss: 0.2149
Model saved!
Accuracy: 0.9217
Precision: 0.9196
Recall: 0.9217
F1-score: 0.9202
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4448
Epoch 1/10, Batch 20/145, Loss: 0.9258
Epoch 1/10, Batch 30/145, Loss: 0.9802
Epoch 1/10, Batch 40/145, Loss: 0.8022
Epoch 1/10, Batch 50/145, Loss: 0.7888
Epoch 1/10, Batch 60/145, Loss: 0.5895
Epoch 1/10, Batch 70/145, Loss: 0.4421
Epoch 1/10, Batch 80/145, Loss: 0.5470
Epoch 1/10, Batch 90/145, Loss: 0.4765
Epoch 1/10, Batch 100/145, Loss: 0.4867
Epoch 1/10, Batch 110/145, Loss: 0.3057
Epoch 1/10, Batch 120/145, Loss: 0.5626
Epoch 1/10, Batch 130/145, Loss: 0.5731
Epoch 1/10, Batch 140/145, Loss: 0.3994
Epoch 1/10, Train Loss: 0.6833, Valid Loss: 0.4050
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3407
Epoch 2/10, Batch 20/145, Loss: 0.3586
Epoch 2/10, Batch 30/145, Loss: 0.2596
Epoch 2/10, Batch 40/145, Loss: 0.6023
Epoch 2/10, Batch 50/145, Loss: 0.3269
Epoch 2/10, Batch 60/145, Loss: 0.3585
Epoch 2/10, Batch 70/145, Loss: 0.3886
Epoch 2/10, Batch 80/145, Loss: 0.3405
Epoch 2/10, Batch 90/145, Loss: 0.2127
Epoch 2/10, Batch 100/145, Loss: 0.2955
Epoch 2/10, Batch 110/145, Loss: 0.2554
Epoch 2/10, Batch 120/145, Loss: 0.3075
Epoch 2/10, Batch 130/145, Loss: 0.3050
Epoch 2/10, Batch 140/145, Loss: 0.2703
Epoch 2/10, Train Loss: 0.3587, Valid Loss: 0.3175
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3477
Epoch 3/10, Batch 20/145, Loss: 0.2537
Epoch 3/10, Batch 30/145, Loss: 0.4628
Epoch 3/10, Batch 40/145, Loss: 0.1914
Epoch 3/10, Batch 50/145, Loss: 0.1921
Epoch 3/10, Batch 60/145, Loss: 0.3099
Epoch 3/10, Batch 70/145, Loss: 0.4052
Epoch 3/10, Batch 80/145, Loss: 0.2363
Epoch 3/10, Batch 90/145, Loss: 0.3288
Epoch 3/10, Batch 100/145, Loss: 0.2779
Epoch 3/10, Batch 110/145, Loss: 0.2726
Epoch 3/10, Batch 120/145, Loss: 0.2739
Epoch 3/10, Batch 130/145, Loss: 0.2960
Epoch 3/10, Batch 140/145, Loss: 0.1974
Epoch 3/10, Train Loss: 0.2994, Valid Loss: 0.2794
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4368
Epoch 4/10, Batch 20/145, Loss: 0.4109
Epoch 4/10, Batch 30/145, Loss: 0.3820
Epoch 4/10, Batch 40/145, Loss: 0.1188
Epoch 4/10, Batch 50/145, Loss: 0.1756
Epoch 4/10, Batch 60/145, Loss: 0.5085
Epoch 4/10, Batch 70/145, Loss: 0.1608
Epoch 4/10, Batch 80/145, Loss: 0.2114
Epoch 4/10, Batch 90/145, Loss: 0.2405
Epoch 4/10, Batch 100/145, Loss: 0.2297
Epoch 4/10, Batch 110/145, Loss: 0.0973
Epoch 4/10, Batch 120/145, Loss: 0.1865
Epoch 4/10, Batch 130/145, Loss: 0.1746
Epoch 4/10, Batch 140/145, Loss: 0.0999
Epoch 4/10, Train Loss: 0.2575, Valid Loss: 0.2640
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1762
Epoch 5/10, Batch 20/145, Loss: 0.1209
Epoch 5/10, Batch 30/145, Loss: 0.3271
Epoch 5/10, Batch 40/145, Loss: 0.1777
Epoch 5/10, Batch 50/145, Loss: 0.2756
Epoch 5/10, Batch 60/145, Loss: 0.3086
Epoch 5/10, Batch 70/145, Loss: 0.2873
Epoch 5/10, Batch 80/145, Loss: 0.3602
Epoch 5/10, Batch 90/145, Loss: 0.1652
Epoch 5/10, Batch 100/145, Loss: 0.3209
Epoch 5/10, Batch 110/145, Loss: 0.3603
Epoch 5/10, Batch 120/145, Loss: 0.4351
Epoch 5/10, Batch 130/145, Loss: 0.2646
Epoch 5/10, Batch 140/145, Loss: 0.2911
Epoch 5/10, Train Loss: 0.2447, Valid Loss: 0.2543
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2897
Epoch 6/10, Batch 20/145, Loss: 0.3761
Epoch 6/10, Batch 30/145, Loss: 0.2112
Epoch 6/10, Batch 40/145, Loss: 0.1112
Epoch 6/10, Batch 50/145, Loss: 0.2360
Epoch 6/10, Batch 60/145, Loss: 0.2229
Epoch 6/10, Batch 70/145, Loss: 0.1029
Epoch 6/10, Batch 80/145, Loss: 0.1504
Epoch 6/10, Batch 90/145, Loss: 0.1471
Epoch 6/10, Batch 100/145, Loss: 0.3093
Epoch 6/10, Batch 110/145, Loss: 0.1592
Epoch 6/10, Batch 120/145, Loss: 0.1996
Epoch 6/10, Batch 130/145, Loss: 0.3247
Epoch 6/10, Batch 140/145, Loss: 0.1978
Epoch 6/10, Train Loss: 0.2316, Valid Loss: 0.2441
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1794
Epoch 7/10, Batch 20/145, Loss: 0.3419
Epoch 7/10, Batch 30/145, Loss: 0.1915
Epoch 7/10, Batch 40/145, Loss: 0.3113
Epoch 7/10, Batch 50/145, Loss: 0.2130
Epoch 7/10, Batch 60/145, Loss: 0.1707
Epoch 7/10, Batch 70/145, Loss: 0.1581
Epoch 7/10, Batch 80/145, Loss: 0.3424
Epoch 7/10, Batch 90/145, Loss: 0.2822
Epoch 7/10, Batch 100/145, Loss: 0.1759
Epoch 7/10, Batch 110/145, Loss: 0.1525
Epoch 7/10, Batch 120/145, Loss: 0.1757
Epoch 7/10, Batch 130/145, Loss: 0.2339
Epoch 7/10, Batch 140/145, Loss: 0.3125
Epoch 7/10, Train Loss: 0.2129, Valid Loss: 0.2359
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1407
Epoch 8/10, Batch 20/145, Loss: 0.3246
Epoch 8/10, Batch 30/145, Loss: 0.2620
Epoch 8/10, Batch 40/145, Loss: 0.2725
Epoch 8/10, Batch 50/145, Loss: 0.1947
Epoch 8/10, Batch 60/145, Loss: 0.2573
Epoch 8/10, Batch 70/145, Loss: 0.3943
Epoch 8/10, Batch 80/145, Loss: 0.3602
Epoch 8/10, Batch 90/145, Loss: 0.2995
Epoch 8/10, Batch 100/145, Loss: 0.3013
Epoch 8/10, Batch 110/145, Loss: 0.1927
Epoch 8/10, Batch 120/145, Loss: 0.1614
Epoch 8/10, Batch 130/145, Loss: 0.2564
Epoch 8/10, Batch 140/145, Loss: 0.2261
Epoch 8/10, Train Loss: 0.2178, Valid Loss: 0.2319
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1964
Epoch 9/10, Batch 20/145, Loss: 0.2226
Epoch 9/10, Batch 30/145, Loss: 0.2463
Epoch 9/10, Batch 40/145, Loss: 0.1173
Epoch 9/10, Batch 50/145, Loss: 0.3068
Epoch 9/10, Batch 60/145, Loss: 0.3994
Epoch 9/10, Batch 70/145, Loss: 0.2198
Epoch 9/10, Batch 80/145, Loss: 0.1577
Epoch 9/10, Batch 90/145, Loss: 0.1343
Epoch 9/10, Batch 100/145, Loss: 0.1258
Epoch 9/10, Batch 110/145, Loss: 0.1848
Epoch 9/10, Batch 120/145, Loss: 0.1085
Epoch 9/10, Batch 130/145, Loss: 0.1177
Epoch 9/10, Batch 140/145, Loss: 0.2149
Epoch 9/10, Train Loss: 0.2060, Valid Loss: 0.2307
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1750
Epoch 10/10, Batch 20/145, Loss: 0.2093
Epoch 10/10, Batch 30/145, Loss: 0.1560
Epoch 10/10, Batch 40/145, Loss: 0.2243
Epoch 10/10, Batch 50/145, Loss: 0.1298
Epoch 10/10, Batch 60/145, Loss: 0.3199
Epoch 10/10, Batch 70/145, Loss: 0.1873
Epoch 10/10, Batch 80/145, Loss: 0.2170
Epoch 10/10, Batch 90/145, Loss: 0.0927
Epoch 10/10, Batch 100/145, Loss: 0.2335
Epoch 10/10, Batch 110/145, Loss: 0.2714
Epoch 10/10, Batch 120/145, Loss: 0.1822
Epoch 10/10, Batch 130/145, Loss: 0.1409
Epoch 10/10, Batch 140/145, Loss: 0.2838
Epoch 10/10, Train Loss: 0.1983, Valid Loss: 0.2281
Model saved!
Accuracy: 0.9229
Precision: 0.9210
Recall: 0.9229
F1-score: 0.9217
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4036
Epoch 1/10, Batch 20/145, Loss: 0.9268
Epoch 1/10, Batch 30/145, Loss: 0.9074
Epoch 1/10, Batch 40/145, Loss: 0.7983
Epoch 1/10, Batch 50/145, Loss: 0.7033
Epoch 1/10, Batch 60/145, Loss: 0.6142
Epoch 1/10, Batch 70/145, Loss: 0.4280
Epoch 1/10, Batch 80/145, Loss: 0.5472
Epoch 1/10, Batch 90/145, Loss: 0.3455
Epoch 1/10, Batch 100/145, Loss: 0.4571
Epoch 1/10, Batch 110/145, Loss: 0.4038
Epoch 1/10, Batch 120/145, Loss: 0.4766
Epoch 1/10, Batch 130/145, Loss: 0.6296
Epoch 1/10, Batch 140/145, Loss: 0.2684
Epoch 1/10, Train Loss: 0.6790, Valid Loss: 0.3812
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4689
Epoch 2/10, Batch 20/145, Loss: 0.2929
Epoch 2/10, Batch 30/145, Loss: 0.3338
Epoch 2/10, Batch 40/145, Loss: 0.3840
Epoch 2/10, Batch 50/145, Loss: 0.3493
Epoch 2/10, Batch 60/145, Loss: 0.3796
Epoch 2/10, Batch 70/145, Loss: 0.3604
Epoch 2/10, Batch 80/145, Loss: 0.3398
Epoch 2/10, Batch 90/145, Loss: 0.2275
Epoch 2/10, Batch 100/145, Loss: 0.4077
Epoch 2/10, Batch 110/145, Loss: 0.3462
Epoch 2/10, Batch 120/145, Loss: 0.4623
Epoch 2/10, Batch 130/145, Loss: 0.5773
Epoch 2/10, Batch 140/145, Loss: 0.4458
Epoch 2/10, Train Loss: 0.3489, Valid Loss: 0.3100
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2491
Epoch 3/10, Batch 20/145, Loss: 0.3771
Epoch 3/10, Batch 30/145, Loss: 0.3393
Epoch 3/10, Batch 40/145, Loss: 0.3322
Epoch 3/10, Batch 50/145, Loss: 0.3026
Epoch 3/10, Batch 60/145, Loss: 0.2410
Epoch 3/10, Batch 70/145, Loss: 0.3872
Epoch 3/10, Batch 80/145, Loss: 0.3130
Epoch 3/10, Batch 90/145, Loss: 0.1426
Epoch 3/10, Batch 100/145, Loss: 0.1998
Epoch 3/10, Batch 110/145, Loss: 0.1452
Epoch 3/10, Batch 120/145, Loss: 0.2693
Epoch 3/10, Batch 130/145, Loss: 0.3122
Epoch 3/10, Batch 140/145, Loss: 0.3161
Epoch 3/10, Train Loss: 0.2928, Valid Loss: 0.2820
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3680
Epoch 4/10, Batch 20/145, Loss: 0.2700
Epoch 4/10, Batch 30/145, Loss: 0.3313
Epoch 4/10, Batch 40/145, Loss: 0.1522
Epoch 4/10, Batch 50/145, Loss: 0.1803
Epoch 4/10, Batch 60/145, Loss: 0.0934
Epoch 4/10, Batch 70/145, Loss: 0.3548
Epoch 4/10, Batch 80/145, Loss: 0.2893
Epoch 4/10, Batch 90/145, Loss: 0.1954
Epoch 4/10, Batch 100/145, Loss: 0.5295
Epoch 4/10, Batch 110/145, Loss: 0.1775
Epoch 4/10, Batch 120/145, Loss: 0.1876
Epoch 4/10, Batch 130/145, Loss: 0.1200
Epoch 4/10, Batch 140/145, Loss: 0.1607
Epoch 4/10, Train Loss: 0.2588, Valid Loss: 0.2781
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1992
Epoch 5/10, Batch 20/145, Loss: 0.0824
Epoch 5/10, Batch 30/145, Loss: 0.2201
Epoch 5/10, Batch 40/145, Loss: 0.2226
Epoch 5/10, Batch 50/145, Loss: 0.2449
Epoch 5/10, Batch 60/145, Loss: 0.2749
Epoch 5/10, Batch 70/145, Loss: 0.2028
Epoch 5/10, Batch 80/145, Loss: 0.1747
Epoch 5/10, Batch 90/145, Loss: 0.3967
Epoch 5/10, Batch 100/145, Loss: 0.3050
Epoch 5/10, Batch 110/145, Loss: 0.2316
Epoch 5/10, Batch 120/145, Loss: 0.4379
Epoch 5/10, Batch 130/145, Loss: 0.1946
Epoch 5/10, Batch 140/145, Loss: 0.2600
Epoch 5/10, Train Loss: 0.2444, Valid Loss: 0.2675
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2697
Epoch 6/10, Batch 20/145, Loss: 0.4054
Epoch 6/10, Batch 30/145, Loss: 0.2926
Epoch 6/10, Batch 40/145, Loss: 0.1405
Epoch 6/10, Batch 50/145, Loss: 0.3095
Epoch 6/10, Batch 60/145, Loss: 0.3091
Epoch 6/10, Batch 70/145, Loss: 0.1920
Epoch 6/10, Batch 80/145, Loss: 0.1292
Epoch 6/10, Batch 90/145, Loss: 0.2420
Epoch 6/10, Batch 100/145, Loss: 0.3073
Epoch 6/10, Batch 110/145, Loss: 0.4629
Epoch 6/10, Batch 120/145, Loss: 0.3582
Epoch 6/10, Batch 130/145, Loss: 0.1344
Epoch 6/10, Batch 140/145, Loss: 0.1026
Epoch 6/10, Train Loss: 0.2262, Valid Loss: 0.2672
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2424
Epoch 7/10, Batch 20/145, Loss: 0.2237
Epoch 7/10, Batch 30/145, Loss: 0.2109
Epoch 7/10, Batch 40/145, Loss: 0.2870
Epoch 7/10, Batch 50/145, Loss: 0.1844
Epoch 7/10, Batch 60/145, Loss: 0.1083
Epoch 7/10, Batch 70/145, Loss: 0.1782
Epoch 7/10, Batch 80/145, Loss: 0.4813
Epoch 7/10, Batch 90/145, Loss: 0.2421
Epoch 7/10, Batch 100/145, Loss: 0.1989
Epoch 7/10, Batch 110/145, Loss: 0.3259
Epoch 7/10, Batch 120/145, Loss: 0.1301
Epoch 7/10, Batch 130/145, Loss: 0.1360
Epoch 7/10, Batch 140/145, Loss: 0.2180
Epoch 7/10, Train Loss: 0.2122, Valid Loss: 0.2533
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2079
Epoch 8/10, Batch 20/145, Loss: 0.1731
Epoch 8/10, Batch 30/145, Loss: 0.2136
Epoch 8/10, Batch 40/145, Loss: 0.2407
Epoch 8/10, Batch 50/145, Loss: 0.2601
Epoch 8/10, Batch 60/145, Loss: 0.2127
Epoch 8/10, Batch 70/145, Loss: 0.3034
Epoch 8/10, Batch 80/145, Loss: 0.0502
Epoch 8/10, Batch 90/145, Loss: 0.2811
Epoch 8/10, Batch 100/145, Loss: 0.1484
Epoch 8/10, Batch 110/145, Loss: 0.2339
Epoch 8/10, Batch 120/145, Loss: 0.1368
Epoch 8/10, Batch 130/145, Loss: 0.1275
Epoch 8/10, Batch 140/145, Loss: 0.2822
Epoch 8/10, Train Loss: 0.2072, Valid Loss: 0.2516
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3020
Epoch 9/10, Batch 20/145, Loss: 0.1868
Epoch 9/10, Batch 30/145, Loss: 0.1772
Epoch 9/10, Batch 40/145, Loss: 0.1810
Epoch 9/10, Batch 50/145, Loss: 0.1623
Epoch 9/10, Batch 60/145, Loss: 0.2301
Epoch 9/10, Batch 70/145, Loss: 0.3481
Epoch 9/10, Batch 80/145, Loss: 0.1418
Epoch 9/10, Batch 90/145, Loss: 0.3596
Epoch 9/10, Batch 100/145, Loss: 0.1552
Epoch 9/10, Batch 110/145, Loss: 0.1981
Epoch 9/10, Batch 120/145, Loss: 0.1313
Epoch 9/10, Batch 130/145, Loss: 0.2777
Epoch 9/10, Batch 140/145, Loss: 0.2111
Epoch 9/10, Train Loss: 0.1982, Valid Loss: 0.2529
Epoch 10/10, Batch 10/145, Loss: 0.0567
Epoch 10/10, Batch 20/145, Loss: 0.2058
Epoch 10/10, Batch 30/145, Loss: 0.1556
Epoch 10/10, Batch 40/145, Loss: 0.2229
Epoch 10/10, Batch 50/145, Loss: 0.3431
Epoch 10/10, Batch 60/145, Loss: 0.1362
Epoch 10/10, Batch 70/145, Loss: 0.2188
Epoch 10/10, Batch 80/145, Loss: 0.2151
Epoch 10/10, Batch 90/145, Loss: 0.1454
Epoch 10/10, Batch 100/145, Loss: 0.0877
Epoch 10/10, Batch 110/145, Loss: 0.1076
Epoch 10/10, Batch 120/145, Loss: 0.2712
Epoch 10/10, Batch 130/145, Loss: 0.2172
Epoch 10/10, Batch 140/145, Loss: 0.2166
Epoch 10/10, Train Loss: 0.1911, Valid Loss: 0.2465
Model saved!
Accuracy: 0.9252
Precision: 0.9226
Recall: 0.9252
F1-score: 0.9231
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3864
Epoch 1/10, Batch 20/145, Loss: 1.0146
Epoch 1/10, Batch 30/145, Loss: 0.9443
Epoch 1/10, Batch 40/145, Loss: 0.6889
Epoch 1/10, Batch 50/145, Loss: 0.6688
Epoch 1/10, Batch 60/145, Loss: 0.7413
Epoch 1/10, Batch 70/145, Loss: 0.4202
Epoch 1/10, Batch 80/145, Loss: 0.5207
Epoch 1/10, Batch 90/145, Loss: 0.4668
Epoch 1/10, Batch 100/145, Loss: 0.5583
Epoch 1/10, Batch 110/145, Loss: 0.4090
Epoch 1/10, Batch 120/145, Loss: 0.6021
Epoch 1/10, Batch 130/145, Loss: 0.3819
Epoch 1/10, Batch 140/145, Loss: 0.3398
Epoch 1/10, Train Loss: 0.6814, Valid Loss: 0.3766
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4268
Epoch 2/10, Batch 20/145, Loss: 0.3183
Epoch 2/10, Batch 30/145, Loss: 0.2050
Epoch 2/10, Batch 40/145, Loss: 0.4157
Epoch 2/10, Batch 50/145, Loss: 0.4613
Epoch 2/10, Batch 60/145, Loss: 0.4800
Epoch 2/10, Batch 70/145, Loss: 0.3678
Epoch 2/10, Batch 80/145, Loss: 0.2649
Epoch 2/10, Batch 90/145, Loss: 0.2999
Epoch 2/10, Batch 100/145, Loss: 0.2079
Epoch 2/10, Batch 110/145, Loss: 0.4538
Epoch 2/10, Batch 120/145, Loss: 0.3129
Epoch 2/10, Batch 130/145, Loss: 0.2118
Epoch 2/10, Batch 140/145, Loss: 0.2495
Epoch 2/10, Train Loss: 0.3619, Valid Loss: 0.2887
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3479
Epoch 3/10, Batch 20/145, Loss: 0.2481
Epoch 3/10, Batch 30/145, Loss: 0.3160
Epoch 3/10, Batch 40/145, Loss: 0.1114
Epoch 3/10, Batch 50/145, Loss: 0.3097
Epoch 3/10, Batch 60/145, Loss: 0.4773
Epoch 3/10, Batch 70/145, Loss: 0.3854
Epoch 3/10, Batch 80/145, Loss: 0.2440
Epoch 3/10, Batch 90/145, Loss: 0.3812
Epoch 3/10, Batch 100/145, Loss: 0.2872
Epoch 3/10, Batch 110/145, Loss: 0.2992
Epoch 3/10, Batch 120/145, Loss: 0.3683
Epoch 3/10, Batch 130/145, Loss: 0.6740
Epoch 3/10, Batch 140/145, Loss: 0.1948
Epoch 3/10, Train Loss: 0.3017, Valid Loss: 0.2522
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3710
Epoch 4/10, Batch 20/145, Loss: 0.3987
Epoch 4/10, Batch 30/145, Loss: 0.3852
Epoch 4/10, Batch 40/145, Loss: 0.0701
Epoch 4/10, Batch 50/145, Loss: 0.1591
Epoch 4/10, Batch 60/145, Loss: 0.1819
Epoch 4/10, Batch 70/145, Loss: 0.1554
Epoch 4/10, Batch 80/145, Loss: 0.2660
Epoch 4/10, Batch 90/145, Loss: 0.3337
Epoch 4/10, Batch 100/145, Loss: 0.1975
Epoch 4/10, Batch 110/145, Loss: 0.1490
Epoch 4/10, Batch 120/145, Loss: 0.2213
Epoch 4/10, Batch 130/145, Loss: 0.1567
Epoch 4/10, Batch 140/145, Loss: 0.1234
Epoch 4/10, Train Loss: 0.2633, Valid Loss: 0.2449
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2585
Epoch 5/10, Batch 20/145, Loss: 0.1333
Epoch 5/10, Batch 30/145, Loss: 0.3566
Epoch 5/10, Batch 40/145, Loss: 0.2128
Epoch 5/10, Batch 50/145, Loss: 0.1177
Epoch 5/10, Batch 60/145, Loss: 0.1503
Epoch 5/10, Batch 70/145, Loss: 0.3466
Epoch 5/10, Batch 80/145, Loss: 0.1592
Epoch 5/10, Batch 90/145, Loss: 0.1516
Epoch 5/10, Batch 100/145, Loss: 0.3431
Epoch 5/10, Batch 110/145, Loss: 0.3072
Epoch 5/10, Batch 120/145, Loss: 0.2812
Epoch 5/10, Batch 130/145, Loss: 0.2097
Epoch 5/10, Batch 140/145, Loss: 0.2149
Epoch 5/10, Train Loss: 0.2523, Valid Loss: 0.2246
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1441
Epoch 6/10, Batch 20/145, Loss: 0.3518
Epoch 6/10, Batch 30/145, Loss: 0.3177
Epoch 6/10, Batch 40/145, Loss: 0.0648
Epoch 6/10, Batch 50/145, Loss: 0.3676
Epoch 6/10, Batch 60/145, Loss: 0.1672
Epoch 6/10, Batch 70/145, Loss: 0.1414
Epoch 6/10, Batch 80/145, Loss: 0.1646
Epoch 6/10, Batch 90/145, Loss: 0.3012
Epoch 6/10, Batch 100/145, Loss: 0.3476
Epoch 6/10, Batch 110/145, Loss: 0.2362
Epoch 6/10, Batch 120/145, Loss: 0.4305
Epoch 6/10, Batch 130/145, Loss: 0.2734
Epoch 6/10, Batch 140/145, Loss: 0.2005
Epoch 6/10, Train Loss: 0.2345, Valid Loss: 0.2142
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2818
Epoch 7/10, Batch 20/145, Loss: 0.2743
Epoch 7/10, Batch 30/145, Loss: 0.2284
Epoch 7/10, Batch 40/145, Loss: 0.3249
Epoch 7/10, Batch 50/145, Loss: 0.4115
Epoch 7/10, Batch 60/145, Loss: 0.2010
Epoch 7/10, Batch 70/145, Loss: 0.1340
Epoch 7/10, Batch 80/145, Loss: 0.2865
Epoch 7/10, Batch 90/145, Loss: 0.1233
Epoch 7/10, Batch 100/145, Loss: 0.2371
Epoch 7/10, Batch 110/145, Loss: 0.2050
Epoch 7/10, Batch 120/145, Loss: 0.2545
Epoch 7/10, Batch 130/145, Loss: 0.1437
Epoch 7/10, Batch 140/145, Loss: 0.3112
Epoch 7/10, Train Loss: 0.2176, Valid Loss: 0.2117
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1772
Epoch 8/10, Batch 20/145, Loss: 0.1836
Epoch 8/10, Batch 30/145, Loss: 0.2910
Epoch 8/10, Batch 40/145, Loss: 0.2037
Epoch 8/10, Batch 50/145, Loss: 0.3482
Epoch 8/10, Batch 60/145, Loss: 0.2259
Epoch 8/10, Batch 70/145, Loss: 0.3701
Epoch 8/10, Batch 80/145, Loss: 0.1543
Epoch 8/10, Batch 90/145, Loss: 0.2777
Epoch 8/10, Batch 100/145, Loss: 0.0995
Epoch 8/10, Batch 110/145, Loss: 0.1805
Epoch 8/10, Batch 120/145, Loss: 0.2096
Epoch 8/10, Batch 130/145, Loss: 0.1473
Epoch 8/10, Batch 140/145, Loss: 0.4383
Epoch 8/10, Train Loss: 0.2116, Valid Loss: 0.2097
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3628
Epoch 9/10, Batch 20/145, Loss: 0.2473
Epoch 9/10, Batch 30/145, Loss: 0.0811
Epoch 9/10, Batch 40/145, Loss: 0.2908
Epoch 9/10, Batch 50/145, Loss: 0.2045
Epoch 9/10, Batch 60/145, Loss: 0.2414
Epoch 9/10, Batch 70/145, Loss: 0.1604
Epoch 9/10, Batch 80/145, Loss: 0.1798
Epoch 9/10, Batch 90/145, Loss: 0.2008
Epoch 9/10, Batch 100/145, Loss: 0.0648
Epoch 9/10, Batch 110/145, Loss: 0.1674
Epoch 9/10, Batch 120/145, Loss: 0.3503
Epoch 9/10, Batch 130/145, Loss: 0.1602
Epoch 9/10, Batch 140/145, Loss: 0.2400
Epoch 9/10, Train Loss: 0.2034, Valid Loss: 0.2032
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1669
Epoch 10/10, Batch 20/145, Loss: 0.2029
Epoch 10/10, Batch 30/145, Loss: 0.1411
Epoch 10/10, Batch 40/145, Loss: 0.2513
Epoch 10/10, Batch 50/145, Loss: 0.1729
Epoch 10/10, Batch 60/145, Loss: 0.3493
Epoch 10/10, Batch 70/145, Loss: 0.3475
Epoch 10/10, Batch 80/145, Loss: 0.2366
Epoch 10/10, Batch 90/145, Loss: 0.2145
Epoch 10/10, Batch 100/145, Loss: 0.1794
Epoch 10/10, Batch 110/145, Loss: 0.1069
Epoch 10/10, Batch 120/145, Loss: 0.2552
Epoch 10/10, Batch 130/145, Loss: 0.2147
Epoch 10/10, Batch 140/145, Loss: 0.1759
Epoch 10/10, Train Loss: 0.1983, Valid Loss: 0.2003
Model saved!
Accuracy: 0.9171
Precision: 0.9147
Recall: 0.9171
F1-score: 0.9153
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3635
Epoch 1/10, Batch 20/145, Loss: 1.0344
Epoch 1/10, Batch 30/145, Loss: 0.9381
Epoch 1/10, Batch 40/145, Loss: 0.8047
Epoch 1/10, Batch 50/145, Loss: 0.6903
Epoch 1/10, Batch 60/145, Loss: 0.6943
Epoch 1/10, Batch 70/145, Loss: 0.5163
Epoch 1/10, Batch 80/145, Loss: 0.6550
Epoch 1/10, Batch 90/145, Loss: 0.4204
Epoch 1/10, Batch 100/145, Loss: 0.5767
Epoch 1/10, Batch 110/145, Loss: 0.4656
Epoch 1/10, Batch 120/145, Loss: 0.5339
Epoch 1/10, Batch 130/145, Loss: 0.5145
Epoch 1/10, Batch 140/145, Loss: 0.2713
Epoch 1/10, Train Loss: 0.6823, Valid Loss: 0.3687
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3408
Epoch 2/10, Batch 20/145, Loss: 0.3553
Epoch 2/10, Batch 30/145, Loss: 0.2956
Epoch 2/10, Batch 40/145, Loss: 0.3843
Epoch 2/10, Batch 50/145, Loss: 0.3913
Epoch 2/10, Batch 60/145, Loss: 0.5351
Epoch 2/10, Batch 70/145, Loss: 0.3582
Epoch 2/10, Batch 80/145, Loss: 0.2636
Epoch 2/10, Batch 90/145, Loss: 0.3753
Epoch 2/10, Batch 100/145, Loss: 0.3590
Epoch 2/10, Batch 110/145, Loss: 0.3813
Epoch 2/10, Batch 120/145, Loss: 0.3582
Epoch 2/10, Batch 130/145, Loss: 0.2228
Epoch 2/10, Batch 140/145, Loss: 0.2994
Epoch 2/10, Train Loss: 0.3589, Valid Loss: 0.2828
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2991
Epoch 3/10, Batch 20/145, Loss: 0.3668
Epoch 3/10, Batch 30/145, Loss: 0.2180
Epoch 3/10, Batch 40/145, Loss: 0.1692
Epoch 3/10, Batch 50/145, Loss: 0.2115
Epoch 3/10, Batch 60/145, Loss: 0.3513
Epoch 3/10, Batch 70/145, Loss: 0.5081
Epoch 3/10, Batch 80/145, Loss: 0.1920
Epoch 3/10, Batch 90/145, Loss: 0.2992
Epoch 3/10, Batch 100/145, Loss: 0.2318
Epoch 3/10, Batch 110/145, Loss: 0.2197
Epoch 3/10, Batch 120/145, Loss: 0.2414
Epoch 3/10, Batch 130/145, Loss: 0.4012
Epoch 3/10, Batch 140/145, Loss: 0.2944
Epoch 3/10, Train Loss: 0.3009, Valid Loss: 0.2462
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4415
Epoch 4/10, Batch 20/145, Loss: 0.2585
Epoch 4/10, Batch 30/145, Loss: 0.3729
Epoch 4/10, Batch 40/145, Loss: 0.1391
Epoch 4/10, Batch 50/145, Loss: 0.2888
Epoch 4/10, Batch 60/145, Loss: 0.2002
Epoch 4/10, Batch 70/145, Loss: 0.3045
Epoch 4/10, Batch 80/145, Loss: 0.1698
Epoch 4/10, Batch 90/145, Loss: 0.1830
Epoch 4/10, Batch 100/145, Loss: 0.3637
Epoch 4/10, Batch 110/145, Loss: 0.0621
Epoch 4/10, Batch 120/145, Loss: 0.2736
Epoch 4/10, Batch 130/145, Loss: 0.0761
Epoch 4/10, Batch 140/145, Loss: 0.1689
Epoch 4/10, Train Loss: 0.2644, Valid Loss: 0.2363
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1702
Epoch 5/10, Batch 20/145, Loss: 0.1677
Epoch 5/10, Batch 30/145, Loss: 0.2450
Epoch 5/10, Batch 40/145, Loss: 0.1334
Epoch 5/10, Batch 50/145, Loss: 0.1715
Epoch 5/10, Batch 60/145, Loss: 0.1770
Epoch 5/10, Batch 70/145, Loss: 0.2440
Epoch 5/10, Batch 80/145, Loss: 0.1600
Epoch 5/10, Batch 90/145, Loss: 0.2000
Epoch 5/10, Batch 100/145, Loss: 0.1337
Epoch 5/10, Batch 110/145, Loss: 0.2797
Epoch 5/10, Batch 120/145, Loss: 0.2373
Epoch 5/10, Batch 130/145, Loss: 0.3847
Epoch 5/10, Batch 140/145, Loss: 0.2027
Epoch 5/10, Train Loss: 0.2543, Valid Loss: 0.2245
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1270
Epoch 6/10, Batch 20/145, Loss: 0.4292
Epoch 6/10, Batch 30/145, Loss: 0.2989
Epoch 6/10, Batch 40/145, Loss: 0.2534
Epoch 6/10, Batch 50/145, Loss: 0.3412
Epoch 6/10, Batch 60/145, Loss: 0.2099
Epoch 6/10, Batch 70/145, Loss: 0.2602
Epoch 6/10, Batch 80/145, Loss: 0.2035
Epoch 6/10, Batch 90/145, Loss: 0.3688
Epoch 6/10, Batch 100/145, Loss: 0.1956
Epoch 6/10, Batch 110/145, Loss: 0.3093
Epoch 6/10, Batch 120/145, Loss: 0.3064
Epoch 6/10, Batch 130/145, Loss: 0.1149
Epoch 6/10, Batch 140/145, Loss: 0.2268
Epoch 6/10, Train Loss: 0.2307, Valid Loss: 0.2149
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2545
Epoch 7/10, Batch 20/145, Loss: 0.1206
Epoch 7/10, Batch 30/145, Loss: 0.4928
Epoch 7/10, Batch 40/145, Loss: 0.3270
Epoch 7/10, Batch 50/145, Loss: 0.1579
Epoch 7/10, Batch 60/145, Loss: 0.2469
Epoch 7/10, Batch 70/145, Loss: 0.0980
Epoch 7/10, Batch 80/145, Loss: 0.3851
Epoch 7/10, Batch 90/145, Loss: 0.1773
Epoch 7/10, Batch 100/145, Loss: 0.2682
Epoch 7/10, Batch 110/145, Loss: 0.0733
Epoch 7/10, Batch 120/145, Loss: 0.1870
Epoch 7/10, Batch 130/145, Loss: 0.1425
Epoch 7/10, Batch 140/145, Loss: 0.2882
Epoch 7/10, Train Loss: 0.2154, Valid Loss: 0.2140
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1437
Epoch 8/10, Batch 20/145, Loss: 0.1960
Epoch 8/10, Batch 30/145, Loss: 0.2464
Epoch 8/10, Batch 40/145, Loss: 0.2683
Epoch 8/10, Batch 50/145, Loss: 0.2308
Epoch 8/10, Batch 60/145, Loss: 0.2421
Epoch 8/10, Batch 70/145, Loss: 0.2786
Epoch 8/10, Batch 80/145, Loss: 0.0943
Epoch 8/10, Batch 90/145, Loss: 0.3065
Epoch 8/10, Batch 100/145, Loss: 0.4335
Epoch 8/10, Batch 110/145, Loss: 0.2030
Epoch 8/10, Batch 120/145, Loss: 0.2272
Epoch 8/10, Batch 130/145, Loss: 0.1199
Epoch 8/10, Batch 140/145, Loss: 0.3138
Epoch 8/10, Train Loss: 0.2091, Valid Loss: 0.2068
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3202
Epoch 9/10, Batch 20/145, Loss: 0.1748
Epoch 9/10, Batch 30/145, Loss: 0.1772
Epoch 9/10, Batch 40/145, Loss: 0.3115
Epoch 9/10, Batch 50/145, Loss: 0.2102
Epoch 9/10, Batch 60/145, Loss: 0.2089
Epoch 9/10, Batch 70/145, Loss: 0.3452
Epoch 9/10, Batch 80/145, Loss: 0.1146
Epoch 9/10, Batch 90/145, Loss: 0.1617
Epoch 9/10, Batch 100/145, Loss: 0.0797
Epoch 9/10, Batch 110/145, Loss: 0.2363
Epoch 9/10, Batch 120/145, Loss: 0.2349
Epoch 9/10, Batch 130/145, Loss: 0.1599
Epoch 9/10, Batch 140/145, Loss: 0.1879
Epoch 9/10, Train Loss: 0.2134, Valid Loss: 0.2045
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2773
Epoch 10/10, Batch 20/145, Loss: 0.1464
Epoch 10/10, Batch 30/145, Loss: 0.1344
Epoch 10/10, Batch 40/145, Loss: 0.0786
Epoch 10/10, Batch 50/145, Loss: 0.1975
Epoch 10/10, Batch 60/145, Loss: 0.1429
Epoch 10/10, Batch 70/145, Loss: 0.2562
Epoch 10/10, Batch 80/145, Loss: 0.1371
Epoch 10/10, Batch 90/145, Loss: 0.1778
Epoch 10/10, Batch 100/145, Loss: 0.1118
Epoch 10/10, Batch 110/145, Loss: 0.1542
Epoch 10/10, Batch 120/145, Loss: 0.2357
Epoch 10/10, Batch 130/145, Loss: 0.1886
Epoch 10/10, Batch 140/145, Loss: 0.1662
Epoch 10/10, Train Loss: 0.1946, Valid Loss: 0.2071
Accuracy: 0.9171
Precision: 0.9150
Recall: 0.9171
F1-score: 0.9157
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4578
Epoch 1/10, Batch 20/145, Loss: 0.8689
Epoch 1/10, Batch 30/145, Loss: 0.9633
Epoch 1/10, Batch 40/145, Loss: 0.9047
Epoch 1/10, Batch 50/145, Loss: 0.7984
Epoch 1/10, Batch 60/145, Loss: 0.7095
Epoch 1/10, Batch 70/145, Loss: 0.4406
Epoch 1/10, Batch 80/145, Loss: 0.7397
Epoch 1/10, Batch 90/145, Loss: 0.3516
Epoch 1/10, Batch 100/145, Loss: 0.3800
Epoch 1/10, Batch 110/145, Loss: 0.3233
Epoch 1/10, Batch 120/145, Loss: 0.6032
Epoch 1/10, Batch 130/145, Loss: 0.5697
Epoch 1/10, Batch 140/145, Loss: 0.2533
Epoch 1/10, Train Loss: 0.6702, Valid Loss: 0.3961
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3589
Epoch 2/10, Batch 20/145, Loss: 0.2755
Epoch 2/10, Batch 30/145, Loss: 0.2423
Epoch 2/10, Batch 40/145, Loss: 0.4857
Epoch 2/10, Batch 50/145, Loss: 0.3887
Epoch 2/10, Batch 60/145, Loss: 0.3543
Epoch 2/10, Batch 70/145, Loss: 0.2558
Epoch 2/10, Batch 80/145, Loss: 0.3992
Epoch 2/10, Batch 90/145, Loss: 0.4450
Epoch 2/10, Batch 100/145, Loss: 0.3194
Epoch 2/10, Batch 110/145, Loss: 0.4263
Epoch 2/10, Batch 120/145, Loss: 0.2682
Epoch 2/10, Batch 130/145, Loss: 0.3003
Epoch 2/10, Batch 140/145, Loss: 0.4090
Epoch 2/10, Train Loss: 0.3429, Valid Loss: 0.3205
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1434
Epoch 3/10, Batch 20/145, Loss: 0.2761
Epoch 3/10, Batch 30/145, Loss: 0.4296
Epoch 3/10, Batch 40/145, Loss: 0.2488
Epoch 3/10, Batch 50/145, Loss: 0.2198
Epoch 3/10, Batch 60/145, Loss: 0.2347
Epoch 3/10, Batch 70/145, Loss: 0.3357
Epoch 3/10, Batch 80/145, Loss: 0.1845
Epoch 3/10, Batch 90/145, Loss: 0.4371
Epoch 3/10, Batch 100/145, Loss: 0.2351
Epoch 3/10, Batch 110/145, Loss: 0.2015
Epoch 3/10, Batch 120/145, Loss: 0.2280
Epoch 3/10, Batch 130/145, Loss: 0.2318
Epoch 3/10, Batch 140/145, Loss: 0.3254
Epoch 3/10, Train Loss: 0.2797, Valid Loss: 0.2853
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3815
Epoch 4/10, Batch 20/145, Loss: 0.2307
Epoch 4/10, Batch 30/145, Loss: 0.2873
Epoch 4/10, Batch 40/145, Loss: 0.1581
Epoch 4/10, Batch 50/145, Loss: 0.2058
Epoch 4/10, Batch 60/145, Loss: 0.2923
Epoch 4/10, Batch 70/145, Loss: 0.2369
Epoch 4/10, Batch 80/145, Loss: 0.2356
Epoch 4/10, Batch 90/145, Loss: 0.3464
Epoch 4/10, Batch 100/145, Loss: 0.2291
Epoch 4/10, Batch 110/145, Loss: 0.1302
Epoch 4/10, Batch 120/145, Loss: 0.1612
Epoch 4/10, Batch 130/145, Loss: 0.1552
Epoch 4/10, Batch 140/145, Loss: 0.0959
Epoch 4/10, Train Loss: 0.2445, Valid Loss: 0.2719
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1763
Epoch 5/10, Batch 20/145, Loss: 0.1145
Epoch 5/10, Batch 30/145, Loss: 0.2092
Epoch 5/10, Batch 40/145, Loss: 0.1685
Epoch 5/10, Batch 50/145, Loss: 0.2748
Epoch 5/10, Batch 60/145, Loss: 0.1768
Epoch 5/10, Batch 70/145, Loss: 0.2565
Epoch 5/10, Batch 80/145, Loss: 0.4507
Epoch 5/10, Batch 90/145, Loss: 0.2705
Epoch 5/10, Batch 100/145, Loss: 0.1869
Epoch 5/10, Batch 110/145, Loss: 0.2980
Epoch 5/10, Batch 120/145, Loss: 0.2844
Epoch 5/10, Batch 130/145, Loss: 0.2287
Epoch 5/10, Batch 140/145, Loss: 0.1591
Epoch 5/10, Train Loss: 0.2353, Valid Loss: 0.2601
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1591
Epoch 6/10, Batch 20/145, Loss: 0.3016
Epoch 6/10, Batch 30/145, Loss: 0.2598
Epoch 6/10, Batch 40/145, Loss: 0.1186
Epoch 6/10, Batch 50/145, Loss: 0.2180
Epoch 6/10, Batch 60/145, Loss: 0.2505
Epoch 6/10, Batch 70/145, Loss: 0.0682
Epoch 6/10, Batch 80/145, Loss: 0.2065
Epoch 6/10, Batch 90/145, Loss: 0.2201
Epoch 6/10, Batch 100/145, Loss: 0.2157
Epoch 6/10, Batch 110/145, Loss: 0.1895
Epoch 6/10, Batch 120/145, Loss: 0.2268
Epoch 6/10, Batch 130/145, Loss: 0.2928
Epoch 6/10, Batch 140/145, Loss: 0.1669
Epoch 6/10, Train Loss: 0.2153, Valid Loss: 0.2536
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2816
Epoch 7/10, Batch 20/145, Loss: 0.3616
Epoch 7/10, Batch 30/145, Loss: 0.2678
Epoch 7/10, Batch 40/145, Loss: 0.1990
Epoch 7/10, Batch 50/145, Loss: 0.1152
Epoch 7/10, Batch 60/145, Loss: 0.1779
Epoch 7/10, Batch 70/145, Loss: 0.1815
Epoch 7/10, Batch 80/145, Loss: 0.3010
Epoch 7/10, Batch 90/145, Loss: 0.1615
Epoch 7/10, Batch 100/145, Loss: 0.2110
Epoch 7/10, Batch 110/145, Loss: 0.1934
Epoch 7/10, Batch 120/145, Loss: 0.2653
Epoch 7/10, Batch 130/145, Loss: 0.1944
Epoch 7/10, Batch 140/145, Loss: 0.1594
Epoch 7/10, Train Loss: 0.2069, Valid Loss: 0.2460
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1574
Epoch 8/10, Batch 20/145, Loss: 0.1443
Epoch 8/10, Batch 30/145, Loss: 0.1305
Epoch 8/10, Batch 40/145, Loss: 0.2019
Epoch 8/10, Batch 50/145, Loss: 0.2210
Epoch 8/10, Batch 60/145, Loss: 0.2481
Epoch 8/10, Batch 70/145, Loss: 0.1288
Epoch 8/10, Batch 80/145, Loss: 0.1805
Epoch 8/10, Batch 90/145, Loss: 0.2512
Epoch 8/10, Batch 100/145, Loss: 0.2127
Epoch 8/10, Batch 110/145, Loss: 0.1636
Epoch 8/10, Batch 120/145, Loss: 0.2476
Epoch 8/10, Batch 130/145, Loss: 0.2060
Epoch 8/10, Batch 140/145, Loss: 0.2670
Epoch 8/10, Train Loss: 0.1950, Valid Loss: 0.2392
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3755
Epoch 9/10, Batch 20/145, Loss: 0.2127
Epoch 9/10, Batch 30/145, Loss: 0.1502
Epoch 9/10, Batch 40/145, Loss: 0.0983
Epoch 9/10, Batch 50/145, Loss: 0.2084
Epoch 9/10, Batch 60/145, Loss: 0.1534
Epoch 9/10, Batch 70/145, Loss: 0.2442
Epoch 9/10, Batch 80/145, Loss: 0.1065
Epoch 9/10, Batch 90/145, Loss: 0.0764
Epoch 9/10, Batch 100/145, Loss: 0.1397
Epoch 9/10, Batch 110/145, Loss: 0.3649
Epoch 9/10, Batch 120/145, Loss: 0.1090
Epoch 9/10, Batch 130/145, Loss: 0.2763
Epoch 9/10, Batch 140/145, Loss: 0.3141
Epoch 9/10, Train Loss: 0.1923, Valid Loss: 0.2436
Epoch 10/10, Batch 10/145, Loss: 0.1247
Epoch 10/10, Batch 20/145, Loss: 0.1566
Epoch 10/10, Batch 30/145, Loss: 0.2181
Epoch 10/10, Batch 40/145, Loss: 0.1533
Epoch 10/10, Batch 50/145, Loss: 0.2620
Epoch 10/10, Batch 60/145, Loss: 0.1535
Epoch 10/10, Batch 70/145, Loss: 0.3444
Epoch 10/10, Batch 80/145, Loss: 0.2428
Epoch 10/10, Batch 90/145, Loss: 0.1957
Epoch 10/10, Batch 100/145, Loss: 0.1564
Epoch 10/10, Batch 110/145, Loss: 0.1068
Epoch 10/10, Batch 120/145, Loss: 0.2901
Epoch 10/10, Batch 130/145, Loss: 0.1555
Epoch 10/10, Batch 140/145, Loss: 0.0988
Epoch 10/10, Train Loss: 0.1855, Valid Loss: 0.2362
Model saved!
Accuracy: 0.9100
Precision: 0.9069
Recall: 0.9100
F1-score: 0.9066
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3399
Epoch 1/10, Batch 20/145, Loss: 0.8696
Epoch 1/10, Batch 30/145, Loss: 0.9224
Epoch 1/10, Batch 40/145, Loss: 0.9073
Epoch 1/10, Batch 50/145, Loss: 0.6807
Epoch 1/10, Batch 60/145, Loss: 0.6414
Epoch 1/10, Batch 70/145, Loss: 0.4265
Epoch 1/10, Batch 80/145, Loss: 0.4785
Epoch 1/10, Batch 90/145, Loss: 0.5471
Epoch 1/10, Batch 100/145, Loss: 0.4637
Epoch 1/10, Batch 110/145, Loss: 0.4860
Epoch 1/10, Batch 120/145, Loss: 0.5581
Epoch 1/10, Batch 130/145, Loss: 0.7223
Epoch 1/10, Batch 140/145, Loss: 0.4106
Epoch 1/10, Train Loss: 0.6688, Valid Loss: 0.3657
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2143
Epoch 2/10, Batch 20/145, Loss: 0.3200
Epoch 2/10, Batch 30/145, Loss: 0.3162
Epoch 2/10, Batch 40/145, Loss: 0.4787
Epoch 2/10, Batch 50/145, Loss: 0.2988
Epoch 2/10, Batch 60/145, Loss: 0.3087
Epoch 2/10, Batch 70/145, Loss: 0.4436
Epoch 2/10, Batch 80/145, Loss: 0.2277
Epoch 2/10, Batch 90/145, Loss: 0.3374
Epoch 2/10, Batch 100/145, Loss: 0.2793
Epoch 2/10, Batch 110/145, Loss: 0.2652
Epoch 2/10, Batch 120/145, Loss: 0.3849
Epoch 2/10, Batch 130/145, Loss: 0.2712
Epoch 2/10, Batch 140/145, Loss: 0.3800
Epoch 2/10, Train Loss: 0.3455, Valid Loss: 0.2914
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3115
Epoch 3/10, Batch 20/145, Loss: 0.2749
Epoch 3/10, Batch 30/145, Loss: 0.3257
Epoch 3/10, Batch 40/145, Loss: 0.2625
Epoch 3/10, Batch 50/145, Loss: 0.2783
Epoch 3/10, Batch 60/145, Loss: 0.4220
Epoch 3/10, Batch 70/145, Loss: 0.3150
Epoch 3/10, Batch 80/145, Loss: 0.2106
Epoch 3/10, Batch 90/145, Loss: 0.3483
Epoch 3/10, Batch 100/145, Loss: 0.2411
Epoch 3/10, Batch 110/145, Loss: 0.2423
Epoch 3/10, Batch 120/145, Loss: 0.1213
Epoch 3/10, Batch 130/145, Loss: 0.2396
Epoch 3/10, Batch 140/145, Loss: 0.2934
Epoch 3/10, Train Loss: 0.2925, Valid Loss: 0.2621
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3444
Epoch 4/10, Batch 20/145, Loss: 0.4087
Epoch 4/10, Batch 30/145, Loss: 0.2016
Epoch 4/10, Batch 40/145, Loss: 0.3706
Epoch 4/10, Batch 50/145, Loss: 0.2241
Epoch 4/10, Batch 60/145, Loss: 0.2528
Epoch 4/10, Batch 70/145, Loss: 0.1222
Epoch 4/10, Batch 80/145, Loss: 0.1325
Epoch 4/10, Batch 90/145, Loss: 0.2455
Epoch 4/10, Batch 100/145, Loss: 0.4084
Epoch 4/10, Batch 110/145, Loss: 0.1473
Epoch 4/10, Batch 120/145, Loss: 0.4063
Epoch 4/10, Batch 130/145, Loss: 0.2055
Epoch 4/10, Batch 140/145, Loss: 0.1892
Epoch 4/10, Train Loss: 0.2556, Valid Loss: 0.2435
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2492
Epoch 5/10, Batch 20/145, Loss: 0.0951
Epoch 5/10, Batch 30/145, Loss: 0.2085
Epoch 5/10, Batch 40/145, Loss: 0.2867
Epoch 5/10, Batch 50/145, Loss: 0.1246
Epoch 5/10, Batch 60/145, Loss: 0.1813
Epoch 5/10, Batch 70/145, Loss: 0.2375
Epoch 5/10, Batch 80/145, Loss: 0.1706
Epoch 5/10, Batch 90/145, Loss: 0.3302
Epoch 5/10, Batch 100/145, Loss: 0.1710
Epoch 5/10, Batch 110/145, Loss: 0.2085
Epoch 5/10, Batch 120/145, Loss: 0.2386
Epoch 5/10, Batch 130/145, Loss: 0.2421
Epoch 5/10, Batch 140/145, Loss: 0.2031
Epoch 5/10, Train Loss: 0.2361, Valid Loss: 0.2416
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1625
Epoch 6/10, Batch 20/145, Loss: 0.2660
Epoch 6/10, Batch 30/145, Loss: 0.3354
Epoch 6/10, Batch 40/145, Loss: 0.2389
Epoch 6/10, Batch 50/145, Loss: 0.2908
Epoch 6/10, Batch 60/145, Loss: 0.1628
Epoch 6/10, Batch 70/145, Loss: 0.1396
Epoch 6/10, Batch 80/145, Loss: 0.3707
Epoch 6/10, Batch 90/145, Loss: 0.3002
Epoch 6/10, Batch 100/145, Loss: 0.3164
Epoch 6/10, Batch 110/145, Loss: 0.2925
Epoch 6/10, Batch 120/145, Loss: 0.2576
Epoch 6/10, Batch 130/145, Loss: 0.2338
Epoch 6/10, Batch 140/145, Loss: 0.1636
Epoch 6/10, Train Loss: 0.2255, Valid Loss: 0.2327
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1723
Epoch 7/10, Batch 20/145, Loss: 0.3687
Epoch 7/10, Batch 30/145, Loss: 0.2729
Epoch 7/10, Batch 40/145, Loss: 0.3632
Epoch 7/10, Batch 50/145, Loss: 0.1211
Epoch 7/10, Batch 60/145, Loss: 0.1990
Epoch 7/10, Batch 70/145, Loss: 0.1571
Epoch 7/10, Batch 80/145, Loss: 0.5622
Epoch 7/10, Batch 90/145, Loss: 0.2047
Epoch 7/10, Batch 100/145, Loss: 0.1848
Epoch 7/10, Batch 110/145, Loss: 0.1572
Epoch 7/10, Batch 120/145, Loss: 0.1917
Epoch 7/10, Batch 130/145, Loss: 0.1142
Epoch 7/10, Batch 140/145, Loss: 0.1242
Epoch 7/10, Train Loss: 0.2137, Valid Loss: 0.2204
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1401
Epoch 8/10, Batch 20/145, Loss: 0.3185
Epoch 8/10, Batch 30/145, Loss: 0.2672
Epoch 8/10, Batch 40/145, Loss: 0.2833
Epoch 8/10, Batch 50/145, Loss: 0.3558
Epoch 8/10, Batch 60/145, Loss: 0.1949
Epoch 8/10, Batch 70/145, Loss: 0.2653
Epoch 8/10, Batch 80/145, Loss: 0.2782
Epoch 8/10, Batch 90/145, Loss: 0.1459
Epoch 8/10, Batch 100/145, Loss: 0.1494
Epoch 8/10, Batch 110/145, Loss: 0.3344
Epoch 8/10, Batch 120/145, Loss: 0.1497
Epoch 8/10, Batch 130/145, Loss: 0.2515
Epoch 8/10, Batch 140/145, Loss: 0.2843
Epoch 8/10, Train Loss: 0.2048, Valid Loss: 0.2198
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3068
Epoch 9/10, Batch 20/145, Loss: 0.1577
Epoch 9/10, Batch 30/145, Loss: 0.2164
Epoch 9/10, Batch 40/145, Loss: 0.3176
Epoch 9/10, Batch 50/145, Loss: 0.1729
Epoch 9/10, Batch 60/145, Loss: 0.2836
Epoch 9/10, Batch 70/145, Loss: 0.1355
Epoch 9/10, Batch 80/145, Loss: 0.0780
Epoch 9/10, Batch 90/145, Loss: 0.2474
Epoch 9/10, Batch 100/145, Loss: 0.1334
Epoch 9/10, Batch 110/145, Loss: 0.3331
Epoch 9/10, Batch 120/145, Loss: 0.1416
Epoch 9/10, Batch 130/145, Loss: 0.0952
Epoch 9/10, Batch 140/145, Loss: 0.1472
Epoch 9/10, Train Loss: 0.1978, Valid Loss: 0.2133
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0756
Epoch 10/10, Batch 20/145, Loss: 0.1828
Epoch 10/10, Batch 30/145, Loss: 0.2272
Epoch 10/10, Batch 40/145, Loss: 0.1267
Epoch 10/10, Batch 50/145, Loss: 0.1149
Epoch 10/10, Batch 60/145, Loss: 0.1329
Epoch 10/10, Batch 70/145, Loss: 0.4342
Epoch 10/10, Batch 80/145, Loss: 0.1670
Epoch 10/10, Batch 90/145, Loss: 0.2142
Epoch 10/10, Batch 100/145, Loss: 0.1478
Epoch 10/10, Batch 110/145, Loss: 0.3064
Epoch 10/10, Batch 120/145, Loss: 0.1503
Epoch 10/10, Batch 130/145, Loss: 0.1138
Epoch 10/10, Batch 140/145, Loss: 0.2668
Epoch 10/10, Train Loss: 0.1937, Valid Loss: 0.2161
Accuracy: 0.9147
Precision: 0.9116
Recall: 0.9147
F1-score: 0.9125
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4362
Epoch 1/10, Batch 20/145, Loss: 0.9413
Epoch 1/10, Batch 30/145, Loss: 0.8652
Epoch 1/10, Batch 40/145, Loss: 0.7403
Epoch 1/10, Batch 50/145, Loss: 0.8282
Epoch 1/10, Batch 60/145, Loss: 0.5203
Epoch 1/10, Batch 70/145, Loss: 0.5137
Epoch 1/10, Batch 80/145, Loss: 0.5336
Epoch 1/10, Batch 90/145, Loss: 0.3337
Epoch 1/10, Batch 100/145, Loss: 0.5760
Epoch 1/10, Batch 110/145, Loss: 0.5061
Epoch 1/10, Batch 120/145, Loss: 0.5537
Epoch 1/10, Batch 130/145, Loss: 0.5112
Epoch 1/10, Batch 140/145, Loss: 0.3314
Epoch 1/10, Train Loss: 0.6843, Valid Loss: 0.3811
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4200
Epoch 2/10, Batch 20/145, Loss: 0.2430
Epoch 2/10, Batch 30/145, Loss: 0.2142
Epoch 2/10, Batch 40/145, Loss: 0.3341
Epoch 2/10, Batch 50/145, Loss: 0.4129
Epoch 2/10, Batch 60/145, Loss: 0.3871
Epoch 2/10, Batch 70/145, Loss: 0.3964
Epoch 2/10, Batch 80/145, Loss: 0.3249
Epoch 2/10, Batch 90/145, Loss: 0.2072
Epoch 2/10, Batch 100/145, Loss: 0.3446
Epoch 2/10, Batch 110/145, Loss: 0.2911
Epoch 2/10, Batch 120/145, Loss: 0.4322
Epoch 2/10, Batch 130/145, Loss: 0.3298
Epoch 2/10, Batch 140/145, Loss: 0.4789
Epoch 2/10, Train Loss: 0.3599, Valid Loss: 0.2973
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2108
Epoch 3/10, Batch 20/145, Loss: 0.2854
Epoch 3/10, Batch 30/145, Loss: 0.4508
Epoch 3/10, Batch 40/145, Loss: 0.2336
Epoch 3/10, Batch 50/145, Loss: 0.3505
Epoch 3/10, Batch 60/145, Loss: 0.3195
Epoch 3/10, Batch 70/145, Loss: 0.3202
Epoch 3/10, Batch 80/145, Loss: 0.3472
Epoch 3/10, Batch 90/145, Loss: 0.2694
Epoch 3/10, Batch 100/145, Loss: 0.2337
Epoch 3/10, Batch 110/145, Loss: 0.2344
Epoch 3/10, Batch 120/145, Loss: 0.2145
Epoch 3/10, Batch 130/145, Loss: 0.4237
Epoch 3/10, Batch 140/145, Loss: 0.2238
Epoch 3/10, Train Loss: 0.3003, Valid Loss: 0.2701
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1719
Epoch 4/10, Batch 20/145, Loss: 0.2431
Epoch 4/10, Batch 30/145, Loss: 0.1753
Epoch 4/10, Batch 40/145, Loss: 0.1751
Epoch 4/10, Batch 50/145, Loss: 0.1346
Epoch 4/10, Batch 60/145, Loss: 0.3097
Epoch 4/10, Batch 70/145, Loss: 0.3277
Epoch 4/10, Batch 80/145, Loss: 0.1274
Epoch 4/10, Batch 90/145, Loss: 0.2058
Epoch 4/10, Batch 100/145, Loss: 0.2432
Epoch 4/10, Batch 110/145, Loss: 0.2393
Epoch 4/10, Batch 120/145, Loss: 0.2246
Epoch 4/10, Batch 130/145, Loss: 0.1596
Epoch 4/10, Batch 140/145, Loss: 0.1650
Epoch 4/10, Train Loss: 0.2630, Valid Loss: 0.2522
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1733
Epoch 5/10, Batch 20/145, Loss: 0.1124
Epoch 5/10, Batch 30/145, Loss: 0.2642
Epoch 5/10, Batch 40/145, Loss: 0.1288
Epoch 5/10, Batch 50/145, Loss: 0.2049
Epoch 5/10, Batch 60/145, Loss: 0.2416
Epoch 5/10, Batch 70/145, Loss: 0.2254
Epoch 5/10, Batch 80/145, Loss: 0.2458
Epoch 5/10, Batch 90/145, Loss: 0.2286
Epoch 5/10, Batch 100/145, Loss: 0.3646
Epoch 5/10, Batch 110/145, Loss: 0.2011
Epoch 5/10, Batch 120/145, Loss: 0.2672
Epoch 5/10, Batch 130/145, Loss: 0.2862
Epoch 5/10, Batch 140/145, Loss: 0.2005
Epoch 5/10, Train Loss: 0.2484, Valid Loss: 0.2383
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1919
Epoch 6/10, Batch 20/145, Loss: 0.3498
Epoch 6/10, Batch 30/145, Loss: 0.4575
Epoch 6/10, Batch 40/145, Loss: 0.1278
Epoch 6/10, Batch 50/145, Loss: 0.3933
Epoch 6/10, Batch 60/145, Loss: 0.2029
Epoch 6/10, Batch 70/145, Loss: 0.0952
Epoch 6/10, Batch 80/145, Loss: 0.2440
Epoch 6/10, Batch 90/145, Loss: 0.3449
Epoch 6/10, Batch 100/145, Loss: 0.4754
Epoch 6/10, Batch 110/145, Loss: 0.1960
Epoch 6/10, Batch 120/145, Loss: 0.2824
Epoch 6/10, Batch 130/145, Loss: 0.2199
Epoch 6/10, Batch 140/145, Loss: 0.1721
Epoch 6/10, Train Loss: 0.2358, Valid Loss: 0.2305
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2254
Epoch 7/10, Batch 20/145, Loss: 0.3700
Epoch 7/10, Batch 30/145, Loss: 0.3661
Epoch 7/10, Batch 40/145, Loss: 0.3785
Epoch 7/10, Batch 50/145, Loss: 0.1795
Epoch 7/10, Batch 60/145, Loss: 0.1352
Epoch 7/10, Batch 70/145, Loss: 0.1874
Epoch 7/10, Batch 80/145, Loss: 0.4709
Epoch 7/10, Batch 90/145, Loss: 0.1042
Epoch 7/10, Batch 100/145, Loss: 0.2766
Epoch 7/10, Batch 110/145, Loss: 0.1325
Epoch 7/10, Batch 120/145, Loss: 0.2809
Epoch 7/10, Batch 130/145, Loss: 0.2481
Epoch 7/10, Batch 140/145, Loss: 0.2604
Epoch 7/10, Train Loss: 0.2176, Valid Loss: 0.2285
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1368
Epoch 8/10, Batch 20/145, Loss: 0.3278
Epoch 8/10, Batch 30/145, Loss: 0.2245
Epoch 8/10, Batch 40/145, Loss: 0.1436
Epoch 8/10, Batch 50/145, Loss: 0.1725
Epoch 8/10, Batch 60/145, Loss: 0.1868
Epoch 8/10, Batch 70/145, Loss: 0.4306
Epoch 8/10, Batch 80/145, Loss: 0.2521
Epoch 8/10, Batch 90/145, Loss: 0.2779
Epoch 8/10, Batch 100/145, Loss: 0.3044
Epoch 8/10, Batch 110/145, Loss: 0.1129
Epoch 8/10, Batch 120/145, Loss: 0.2776
Epoch 8/10, Batch 130/145, Loss: 0.2636
Epoch 8/10, Batch 140/145, Loss: 0.1563
Epoch 8/10, Train Loss: 0.2075, Valid Loss: 0.2268
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2350
Epoch 9/10, Batch 20/145, Loss: 0.1916
Epoch 9/10, Batch 30/145, Loss: 0.1602
Epoch 9/10, Batch 40/145, Loss: 0.1359
Epoch 9/10, Batch 50/145, Loss: 0.1602
Epoch 9/10, Batch 60/145, Loss: 0.2824
Epoch 9/10, Batch 70/145, Loss: 0.1692
Epoch 9/10, Batch 80/145, Loss: 0.1882
Epoch 9/10, Batch 90/145, Loss: 0.2893
Epoch 9/10, Batch 100/145, Loss: 0.1080
Epoch 9/10, Batch 110/145, Loss: 0.1483
Epoch 9/10, Batch 120/145, Loss: 0.0627
Epoch 9/10, Batch 130/145, Loss: 0.3091
Epoch 9/10, Batch 140/145, Loss: 0.2876
Epoch 9/10, Train Loss: 0.2038, Valid Loss: 0.2188
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1615
Epoch 10/10, Batch 20/145, Loss: 0.2259
Epoch 10/10, Batch 30/145, Loss: 0.0848
Epoch 10/10, Batch 40/145, Loss: 0.1804
Epoch 10/10, Batch 50/145, Loss: 0.1947
Epoch 10/10, Batch 60/145, Loss: 0.2062
Epoch 10/10, Batch 70/145, Loss: 0.2846
Epoch 10/10, Batch 80/145, Loss: 0.2653
Epoch 10/10, Batch 90/145, Loss: 0.2013
Epoch 10/10, Batch 100/145, Loss: 0.1283
Epoch 10/10, Batch 110/145, Loss: 0.2663
Epoch 10/10, Batch 120/145, Loss: 0.2737
Epoch 10/10, Batch 130/145, Loss: 0.1773
Epoch 10/10, Batch 140/145, Loss: 0.2415
Epoch 10/10, Train Loss: 0.1963, Valid Loss: 0.2212
Accuracy: 0.9217
Precision: 0.9214
Recall: 0.9217
F1-score: 0.9214
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4179
Epoch 1/10, Batch 20/145, Loss: 0.8893
Epoch 1/10, Batch 30/145, Loss: 0.9550
Epoch 1/10, Batch 40/145, Loss: 0.7518
Epoch 1/10, Batch 50/145, Loss: 0.7315
Epoch 1/10, Batch 60/145, Loss: 0.6722
Epoch 1/10, Batch 70/145, Loss: 0.4272
Epoch 1/10, Batch 80/145, Loss: 0.5955
Epoch 1/10, Batch 90/145, Loss: 0.3984
Epoch 1/10, Batch 100/145, Loss: 0.4170
Epoch 1/10, Batch 110/145, Loss: 0.5529
Epoch 1/10, Batch 120/145, Loss: 0.4368
Epoch 1/10, Batch 130/145, Loss: 0.6188
Epoch 1/10, Batch 140/145, Loss: 0.4104
Epoch 1/10, Train Loss: 0.6821, Valid Loss: 0.3812
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4080
Epoch 2/10, Batch 20/145, Loss: 0.3405
Epoch 2/10, Batch 30/145, Loss: 0.2650
Epoch 2/10, Batch 40/145, Loss: 0.3767
Epoch 2/10, Batch 50/145, Loss: 0.2486
Epoch 2/10, Batch 60/145, Loss: 0.4647
Epoch 2/10, Batch 70/145, Loss: 0.3560
Epoch 2/10, Batch 80/145, Loss: 0.2455
Epoch 2/10, Batch 90/145, Loss: 0.4089
Epoch 2/10, Batch 100/145, Loss: 0.3274
Epoch 2/10, Batch 110/145, Loss: 0.3140
Epoch 2/10, Batch 120/145, Loss: 0.2986
Epoch 2/10, Batch 130/145, Loss: 0.3551
Epoch 2/10, Batch 140/145, Loss: 0.3152
Epoch 2/10, Train Loss: 0.3573, Valid Loss: 0.3015
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2212
Epoch 3/10, Batch 20/145, Loss: 0.3662
Epoch 3/10, Batch 30/145, Loss: 0.3473
Epoch 3/10, Batch 40/145, Loss: 0.1623
Epoch 3/10, Batch 50/145, Loss: 0.2034
Epoch 3/10, Batch 60/145, Loss: 0.3565
Epoch 3/10, Batch 70/145, Loss: 0.4202
Epoch 3/10, Batch 80/145, Loss: 0.2469
Epoch 3/10, Batch 90/145, Loss: 0.2526
Epoch 3/10, Batch 100/145, Loss: 0.3536
Epoch 3/10, Batch 110/145, Loss: 0.2200
Epoch 3/10, Batch 120/145, Loss: 0.4457
Epoch 3/10, Batch 130/145, Loss: 0.2955
Epoch 3/10, Batch 140/145, Loss: 0.2038
Epoch 3/10, Train Loss: 0.2924, Valid Loss: 0.2690
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2290
Epoch 4/10, Batch 20/145, Loss: 0.3725
Epoch 4/10, Batch 30/145, Loss: 0.2517
Epoch 4/10, Batch 40/145, Loss: 0.2145
Epoch 4/10, Batch 50/145, Loss: 0.1708
Epoch 4/10, Batch 60/145, Loss: 0.2451
Epoch 4/10, Batch 70/145, Loss: 0.2344
Epoch 4/10, Batch 80/145, Loss: 0.2057
Epoch 4/10, Batch 90/145, Loss: 0.2223
Epoch 4/10, Batch 100/145, Loss: 0.4370
Epoch 4/10, Batch 110/145, Loss: 0.1476
Epoch 4/10, Batch 120/145, Loss: 0.2114
Epoch 4/10, Batch 130/145, Loss: 0.1789
Epoch 4/10, Batch 140/145, Loss: 0.1341
Epoch 4/10, Train Loss: 0.2664, Valid Loss: 0.2614
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1739
Epoch 5/10, Batch 20/145, Loss: 0.2885
Epoch 5/10, Batch 30/145, Loss: 0.3515
Epoch 5/10, Batch 40/145, Loss: 0.1785
Epoch 5/10, Batch 50/145, Loss: 0.1307
Epoch 5/10, Batch 60/145, Loss: 0.2272
Epoch 5/10, Batch 70/145, Loss: 0.2092
Epoch 5/10, Batch 80/145, Loss: 0.2744
Epoch 5/10, Batch 90/145, Loss: 0.2262
Epoch 5/10, Batch 100/145, Loss: 0.2625
Epoch 5/10, Batch 110/145, Loss: 0.1370
Epoch 5/10, Batch 120/145, Loss: 0.3073
Epoch 5/10, Batch 130/145, Loss: 0.1892
Epoch 5/10, Batch 140/145, Loss: 0.1687
Epoch 5/10, Train Loss: 0.2444, Valid Loss: 0.2499
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2008
Epoch 6/10, Batch 20/145, Loss: 0.5715
Epoch 6/10, Batch 30/145, Loss: 0.3545
Epoch 6/10, Batch 40/145, Loss: 0.0807
Epoch 6/10, Batch 50/145, Loss: 0.1923
Epoch 6/10, Batch 60/145, Loss: 0.1453
Epoch 6/10, Batch 70/145, Loss: 0.0996
Epoch 6/10, Batch 80/145, Loss: 0.1715
Epoch 6/10, Batch 90/145, Loss: 0.2618
Epoch 6/10, Batch 100/145, Loss: 0.2792
Epoch 6/10, Batch 110/145, Loss: 0.2850
Epoch 6/10, Batch 120/145, Loss: 0.2753
Epoch 6/10, Batch 130/145, Loss: 0.0793
Epoch 6/10, Batch 140/145, Loss: 0.2941
Epoch 6/10, Train Loss: 0.2310, Valid Loss: 0.2432
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2186
Epoch 7/10, Batch 20/145, Loss: 0.2046
Epoch 7/10, Batch 30/145, Loss: 0.1577
Epoch 7/10, Batch 40/145, Loss: 0.3314
Epoch 7/10, Batch 50/145, Loss: 0.1133
Epoch 7/10, Batch 60/145, Loss: 0.0744
Epoch 7/10, Batch 70/145, Loss: 0.2309
Epoch 7/10, Batch 80/145, Loss: 0.5501
Epoch 7/10, Batch 90/145, Loss: 0.1112
Epoch 7/10, Batch 100/145, Loss: 0.0730
Epoch 7/10, Batch 110/145, Loss: 0.0972
Epoch 7/10, Batch 120/145, Loss: 0.1909
Epoch 7/10, Batch 130/145, Loss: 0.1328
Epoch 7/10, Batch 140/145, Loss: 0.3430
Epoch 7/10, Train Loss: 0.2161, Valid Loss: 0.2321
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1070
Epoch 8/10, Batch 20/145, Loss: 0.3373
Epoch 8/10, Batch 30/145, Loss: 0.3531
Epoch 8/10, Batch 40/145, Loss: 0.2466
Epoch 8/10, Batch 50/145, Loss: 0.5734
Epoch 8/10, Batch 60/145, Loss: 0.4274
Epoch 8/10, Batch 70/145, Loss: 0.2485
Epoch 8/10, Batch 80/145, Loss: 0.3044
Epoch 8/10, Batch 90/145, Loss: 0.4635
Epoch 8/10, Batch 100/145, Loss: 0.1886
Epoch 8/10, Batch 110/145, Loss: 0.1606
Epoch 8/10, Batch 120/145, Loss: 0.1649
Epoch 8/10, Batch 130/145, Loss: 0.1388
Epoch 8/10, Batch 140/145, Loss: 0.2705
Epoch 8/10, Train Loss: 0.2101, Valid Loss: 0.2300
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3365
Epoch 9/10, Batch 20/145, Loss: 0.2331
Epoch 9/10, Batch 30/145, Loss: 0.1533
Epoch 9/10, Batch 40/145, Loss: 0.1492
Epoch 9/10, Batch 50/145, Loss: 0.3058
Epoch 9/10, Batch 60/145, Loss: 0.2176
Epoch 9/10, Batch 70/145, Loss: 0.2104
Epoch 9/10, Batch 80/145, Loss: 0.2018
Epoch 9/10, Batch 90/145, Loss: 0.2911
Epoch 9/10, Batch 100/145, Loss: 0.1742
Epoch 9/10, Batch 110/145, Loss: 0.2304
Epoch 9/10, Batch 120/145, Loss: 0.1278
Epoch 9/10, Batch 130/145, Loss: 0.1634
Epoch 9/10, Batch 140/145, Loss: 0.1638
Epoch 9/10, Train Loss: 0.2030, Valid Loss: 0.2296
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0798
Epoch 10/10, Batch 20/145, Loss: 0.1897
Epoch 10/10, Batch 30/145, Loss: 0.1621
Epoch 10/10, Batch 40/145, Loss: 0.0792
Epoch 10/10, Batch 50/145, Loss: 0.2714
Epoch 10/10, Batch 60/145, Loss: 0.1849
Epoch 10/10, Batch 70/145, Loss: 0.3235
Epoch 10/10, Batch 80/145, Loss: 0.1348
Epoch 10/10, Batch 90/145, Loss: 0.1774
Epoch 10/10, Batch 100/145, Loss: 0.2342
Epoch 10/10, Batch 110/145, Loss: 0.1488
Epoch 10/10, Batch 120/145, Loss: 0.1978
Epoch 10/10, Batch 130/145, Loss: 0.2800
Epoch 10/10, Batch 140/145, Loss: 0.1336
Epoch 10/10, Train Loss: 0.1927, Valid Loss: 0.2256
Model saved!
Accuracy: 0.9229
Precision: 0.9205
Recall: 0.9229
F1-score: 0.9212
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3313
Epoch 1/10, Batch 20/145, Loss: 0.9184
Epoch 1/10, Batch 30/145, Loss: 0.9229
Epoch 1/10, Batch 40/145, Loss: 0.8263
Epoch 1/10, Batch 50/145, Loss: 0.6067
Epoch 1/10, Batch 60/145, Loss: 0.5461
Epoch 1/10, Batch 70/145, Loss: 0.4139
Epoch 1/10, Batch 80/145, Loss: 0.6315
Epoch 1/10, Batch 90/145, Loss: 0.3688
Epoch 1/10, Batch 100/145, Loss: 0.5543
Epoch 1/10, Batch 110/145, Loss: 0.4226
Epoch 1/10, Batch 120/145, Loss: 0.4857
Epoch 1/10, Batch 130/145, Loss: 0.4992
Epoch 1/10, Batch 140/145, Loss: 0.4013
Epoch 1/10, Train Loss: 0.6751, Valid Loss: 0.3847
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3219
Epoch 2/10, Batch 20/145, Loss: 0.4566
Epoch 2/10, Batch 30/145, Loss: 0.2858
Epoch 2/10, Batch 40/145, Loss: 0.3209
Epoch 2/10, Batch 50/145, Loss: 0.3227
Epoch 2/10, Batch 60/145, Loss: 0.4321
Epoch 2/10, Batch 70/145, Loss: 0.3325
Epoch 2/10, Batch 80/145, Loss: 0.3579
Epoch 2/10, Batch 90/145, Loss: 0.2321
Epoch 2/10, Batch 100/145, Loss: 0.3245
Epoch 2/10, Batch 110/145, Loss: 0.4247
Epoch 2/10, Batch 120/145, Loss: 0.2976
Epoch 2/10, Batch 130/145, Loss: 0.3129
Epoch 2/10, Batch 140/145, Loss: 0.2624
Epoch 2/10, Train Loss: 0.3520, Valid Loss: 0.3016
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2261
Epoch 3/10, Batch 20/145, Loss: 0.3025
Epoch 3/10, Batch 30/145, Loss: 0.4117
Epoch 3/10, Batch 40/145, Loss: 0.1063
Epoch 3/10, Batch 50/145, Loss: 0.2505
Epoch 3/10, Batch 60/145, Loss: 0.3639
Epoch 3/10, Batch 70/145, Loss: 0.2838
Epoch 3/10, Batch 80/145, Loss: 0.2598
Epoch 3/10, Batch 90/145, Loss: 0.2207
Epoch 3/10, Batch 100/145, Loss: 0.3301
Epoch 3/10, Batch 110/145, Loss: 0.1884
Epoch 3/10, Batch 120/145, Loss: 0.2458
Epoch 3/10, Batch 130/145, Loss: 0.4208
Epoch 3/10, Batch 140/145, Loss: 0.1798
Epoch 3/10, Train Loss: 0.2934, Valid Loss: 0.2748
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3385
Epoch 4/10, Batch 20/145, Loss: 0.3428
Epoch 4/10, Batch 30/145, Loss: 0.3347
Epoch 4/10, Batch 40/145, Loss: 0.1721
Epoch 4/10, Batch 50/145, Loss: 0.1865
Epoch 4/10, Batch 60/145, Loss: 0.1629
Epoch 4/10, Batch 70/145, Loss: 0.3065
Epoch 4/10, Batch 80/145, Loss: 0.1553
Epoch 4/10, Batch 90/145, Loss: 0.1729
Epoch 4/10, Batch 100/145, Loss: 0.3150
Epoch 4/10, Batch 110/145, Loss: 0.1862
Epoch 4/10, Batch 120/145, Loss: 0.1948
Epoch 4/10, Batch 130/145, Loss: 0.2250
Epoch 4/10, Batch 140/145, Loss: 0.1290
Epoch 4/10, Train Loss: 0.2515, Valid Loss: 0.2603
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2515
Epoch 5/10, Batch 20/145, Loss: 0.0886
Epoch 5/10, Batch 30/145, Loss: 0.2363
Epoch 5/10, Batch 40/145, Loss: 0.1805
Epoch 5/10, Batch 50/145, Loss: 0.1046
Epoch 5/10, Batch 60/145, Loss: 0.1856
Epoch 5/10, Batch 70/145, Loss: 0.1658
Epoch 5/10, Batch 80/145, Loss: 0.1402
Epoch 5/10, Batch 90/145, Loss: 0.2522
Epoch 5/10, Batch 100/145, Loss: 0.2842
Epoch 5/10, Batch 110/145, Loss: 0.2979
Epoch 5/10, Batch 120/145, Loss: 0.1678
Epoch 5/10, Batch 130/145, Loss: 0.2538
Epoch 5/10, Batch 140/145, Loss: 0.2522
Epoch 5/10, Train Loss: 0.2375, Valid Loss: 0.2448
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1304
Epoch 6/10, Batch 20/145, Loss: 0.4424
Epoch 6/10, Batch 30/145, Loss: 0.5542
Epoch 6/10, Batch 40/145, Loss: 0.2346
Epoch 6/10, Batch 50/145, Loss: 0.4461
Epoch 6/10, Batch 60/145, Loss: 0.1666
Epoch 6/10, Batch 70/145, Loss: 0.1820
Epoch 6/10, Batch 80/145, Loss: 0.1620
Epoch 6/10, Batch 90/145, Loss: 0.4382
Epoch 6/10, Batch 100/145, Loss: 0.2502
Epoch 6/10, Batch 110/145, Loss: 0.1730
Epoch 6/10, Batch 120/145, Loss: 0.3078
Epoch 6/10, Batch 130/145, Loss: 0.2137
Epoch 6/10, Batch 140/145, Loss: 0.0877
Epoch 6/10, Train Loss: 0.2290, Valid Loss: 0.2425
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1783
Epoch 7/10, Batch 20/145, Loss: 0.1842
Epoch 7/10, Batch 30/145, Loss: 0.3971
Epoch 7/10, Batch 40/145, Loss: 0.2369
Epoch 7/10, Batch 50/145, Loss: 0.1257
Epoch 7/10, Batch 60/145, Loss: 0.2432
Epoch 7/10, Batch 70/145, Loss: 0.2358
Epoch 7/10, Batch 80/145, Loss: 0.4381
Epoch 7/10, Batch 90/145, Loss: 0.0769
Epoch 7/10, Batch 100/145, Loss: 0.3319
Epoch 7/10, Batch 110/145, Loss: 0.1569
Epoch 7/10, Batch 120/145, Loss: 0.1742
Epoch 7/10, Batch 130/145, Loss: 0.1205
Epoch 7/10, Batch 140/145, Loss: 0.2269
Epoch 7/10, Train Loss: 0.2111, Valid Loss: 0.2350
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1539
Epoch 8/10, Batch 20/145, Loss: 0.2385
Epoch 8/10, Batch 30/145, Loss: 0.3348
Epoch 8/10, Batch 40/145, Loss: 0.1872
Epoch 8/10, Batch 50/145, Loss: 0.2637
Epoch 8/10, Batch 60/145, Loss: 0.2962
Epoch 8/10, Batch 70/145, Loss: 0.1553
Epoch 8/10, Batch 80/145, Loss: 0.2003
Epoch 8/10, Batch 90/145, Loss: 0.3478
Epoch 8/10, Batch 100/145, Loss: 0.0978
Epoch 8/10, Batch 110/145, Loss: 0.1933
Epoch 8/10, Batch 120/145, Loss: 0.2126
Epoch 8/10, Batch 130/145, Loss: 0.1083
Epoch 8/10, Batch 140/145, Loss: 0.1672
Epoch 8/10, Train Loss: 0.2070, Valid Loss: 0.2336
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2765
Epoch 9/10, Batch 20/145, Loss: 0.1552
Epoch 9/10, Batch 30/145, Loss: 0.1135
Epoch 9/10, Batch 40/145, Loss: 0.2844
Epoch 9/10, Batch 50/145, Loss: 0.1994
Epoch 9/10, Batch 60/145, Loss: 0.2390
Epoch 9/10, Batch 70/145, Loss: 0.1318
Epoch 9/10, Batch 80/145, Loss: 0.1896
Epoch 9/10, Batch 90/145, Loss: 0.2948
Epoch 9/10, Batch 100/145, Loss: 0.1690
Epoch 9/10, Batch 110/145, Loss: 0.1020
Epoch 9/10, Batch 120/145, Loss: 0.0361
Epoch 9/10, Batch 130/145, Loss: 0.0898
Epoch 9/10, Batch 140/145, Loss: 0.1335
Epoch 9/10, Train Loss: 0.1982, Valid Loss: 0.2276
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2043
Epoch 10/10, Batch 20/145, Loss: 0.0991
Epoch 10/10, Batch 30/145, Loss: 0.1572
Epoch 10/10, Batch 40/145, Loss: 0.1670
Epoch 10/10, Batch 50/145, Loss: 0.1761
Epoch 10/10, Batch 60/145, Loss: 0.0955
Epoch 10/10, Batch 70/145, Loss: 0.3100
Epoch 10/10, Batch 80/145, Loss: 0.2349
Epoch 10/10, Batch 90/145, Loss: 0.1503
Epoch 10/10, Batch 100/145, Loss: 0.1668
Epoch 10/10, Batch 110/145, Loss: 0.3173
Epoch 10/10, Batch 120/145, Loss: 0.2972
Epoch 10/10, Batch 130/145, Loss: 0.0533
Epoch 10/10, Batch 140/145, Loss: 0.2010
Epoch 10/10, Train Loss: 0.1839, Valid Loss: 0.2241
Model saved!
Accuracy: 0.9206
Precision: 0.9184
Recall: 0.9206
F1-score: 0.9184
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4632
Epoch 1/10, Batch 20/145, Loss: 0.9739
Epoch 1/10, Batch 30/145, Loss: 0.9049
Epoch 1/10, Batch 40/145, Loss: 0.8180
Epoch 1/10, Batch 50/145, Loss: 0.7346
Epoch 1/10, Batch 60/145, Loss: 0.5574
Epoch 1/10, Batch 70/145, Loss: 0.6158
Epoch 1/10, Batch 80/145, Loss: 0.5862
Epoch 1/10, Batch 90/145, Loss: 0.3169
Epoch 1/10, Batch 100/145, Loss: 0.4706
Epoch 1/10, Batch 110/145, Loss: 0.5209
Epoch 1/10, Batch 120/145, Loss: 0.6041
Epoch 1/10, Batch 130/145, Loss: 0.5583
Epoch 1/10, Batch 140/145, Loss: 0.4216
Epoch 1/10, Train Loss: 0.6867, Valid Loss: 0.3750
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2449
Epoch 2/10, Batch 20/145, Loss: 0.3284
Epoch 2/10, Batch 30/145, Loss: 0.3328
Epoch 2/10, Batch 40/145, Loss: 0.3544
Epoch 2/10, Batch 50/145, Loss: 0.3835
Epoch 2/10, Batch 60/145, Loss: 0.3828
Epoch 2/10, Batch 70/145, Loss: 0.4654
Epoch 2/10, Batch 80/145, Loss: 0.4046
Epoch 2/10, Batch 90/145, Loss: 0.2940
Epoch 2/10, Batch 100/145, Loss: 0.2809
Epoch 2/10, Batch 110/145, Loss: 0.2762
Epoch 2/10, Batch 120/145, Loss: 0.3223
Epoch 2/10, Batch 130/145, Loss: 0.1563
Epoch 2/10, Batch 140/145, Loss: 0.3314
Epoch 2/10, Train Loss: 0.3622, Valid Loss: 0.2932
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2297
Epoch 3/10, Batch 20/145, Loss: 0.2904
Epoch 3/10, Batch 30/145, Loss: 0.4274
Epoch 3/10, Batch 40/145, Loss: 0.2443
Epoch 3/10, Batch 50/145, Loss: 0.3828
Epoch 3/10, Batch 60/145, Loss: 0.3705
Epoch 3/10, Batch 70/145, Loss: 0.4238
Epoch 3/10, Batch 80/145, Loss: 0.3663
Epoch 3/10, Batch 90/145, Loss: 0.2962
Epoch 3/10, Batch 100/145, Loss: 0.2712
Epoch 3/10, Batch 110/145, Loss: 0.1782
Epoch 3/10, Batch 120/145, Loss: 0.3112
Epoch 3/10, Batch 130/145, Loss: 0.3387
Epoch 3/10, Batch 140/145, Loss: 0.2968
Epoch 3/10, Train Loss: 0.3025, Valid Loss: 0.2606
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2153
Epoch 4/10, Batch 20/145, Loss: 0.2893
Epoch 4/10, Batch 30/145, Loss: 0.2350
Epoch 4/10, Batch 40/145, Loss: 0.3782
Epoch 4/10, Batch 50/145, Loss: 0.2703
Epoch 4/10, Batch 60/145, Loss: 0.2338
Epoch 4/10, Batch 70/145, Loss: 0.2338
Epoch 4/10, Batch 80/145, Loss: 0.2533
Epoch 4/10, Batch 90/145, Loss: 0.3510
Epoch 4/10, Batch 100/145, Loss: 0.2943
Epoch 4/10, Batch 110/145, Loss: 0.1627
Epoch 4/10, Batch 120/145, Loss: 0.3472
Epoch 4/10, Batch 130/145, Loss: 0.2645
Epoch 4/10, Batch 140/145, Loss: 0.1649
Epoch 4/10, Train Loss: 0.2697, Valid Loss: 0.2447
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2157
Epoch 5/10, Batch 20/145, Loss: 0.1056
Epoch 5/10, Batch 30/145, Loss: 0.4318
Epoch 5/10, Batch 40/145, Loss: 0.1094
Epoch 5/10, Batch 50/145, Loss: 0.1476
Epoch 5/10, Batch 60/145, Loss: 0.2081
Epoch 5/10, Batch 70/145, Loss: 0.3291
Epoch 5/10, Batch 80/145, Loss: 0.2477
Epoch 5/10, Batch 90/145, Loss: 0.3540
Epoch 5/10, Batch 100/145, Loss: 0.3462
Epoch 5/10, Batch 110/145, Loss: 0.2034
Epoch 5/10, Batch 120/145, Loss: 0.2025
Epoch 5/10, Batch 130/145, Loss: 0.3245
Epoch 5/10, Batch 140/145, Loss: 0.2060
Epoch 5/10, Train Loss: 0.2536, Valid Loss: 0.2363
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1727
Epoch 6/10, Batch 20/145, Loss: 0.7399
Epoch 6/10, Batch 30/145, Loss: 0.2728
Epoch 6/10, Batch 40/145, Loss: 0.0900
Epoch 6/10, Batch 50/145, Loss: 0.3980
Epoch 6/10, Batch 60/145, Loss: 0.3063
Epoch 6/10, Batch 70/145, Loss: 0.1519
Epoch 6/10, Batch 80/145, Loss: 0.1809
Epoch 6/10, Batch 90/145, Loss: 0.3454
Epoch 6/10, Batch 100/145, Loss: 0.2605
Epoch 6/10, Batch 110/145, Loss: 0.1916
Epoch 6/10, Batch 120/145, Loss: 0.2906
Epoch 6/10, Batch 130/145, Loss: 0.2623
Epoch 6/10, Batch 140/145, Loss: 0.2236
Epoch 6/10, Train Loss: 0.2416, Valid Loss: 0.2221
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3529
Epoch 7/10, Batch 20/145, Loss: 0.2097
Epoch 7/10, Batch 30/145, Loss: 0.0734
Epoch 7/10, Batch 40/145, Loss: 0.2949
Epoch 7/10, Batch 50/145, Loss: 0.2553
Epoch 7/10, Batch 60/145, Loss: 0.1357
Epoch 7/10, Batch 70/145, Loss: 0.1588
Epoch 7/10, Batch 80/145, Loss: 0.3734
Epoch 7/10, Batch 90/145, Loss: 0.1554
Epoch 7/10, Batch 100/145, Loss: 0.1572
Epoch 7/10, Batch 110/145, Loss: 0.1344
Epoch 7/10, Batch 120/145, Loss: 0.2604
Epoch 7/10, Batch 130/145, Loss: 0.0860
Epoch 7/10, Batch 140/145, Loss: 0.4477
Epoch 7/10, Train Loss: 0.2241, Valid Loss: 0.2102
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2684
Epoch 8/10, Batch 20/145, Loss: 0.0874
Epoch 8/10, Batch 30/145, Loss: 0.2426
Epoch 8/10, Batch 40/145, Loss: 0.2273
Epoch 8/10, Batch 50/145, Loss: 0.2070
Epoch 8/10, Batch 60/145, Loss: 0.2364
Epoch 8/10, Batch 70/145, Loss: 0.3264
Epoch 8/10, Batch 80/145, Loss: 0.3025
Epoch 8/10, Batch 90/145, Loss: 0.3126
Epoch 8/10, Batch 100/145, Loss: 0.1903
Epoch 8/10, Batch 110/145, Loss: 0.1823
Epoch 8/10, Batch 120/145, Loss: 0.1651
Epoch 8/10, Batch 130/145, Loss: 0.1934
Epoch 8/10, Batch 140/145, Loss: 0.2544
Epoch 8/10, Train Loss: 0.2194, Valid Loss: 0.2032
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3090
Epoch 9/10, Batch 20/145, Loss: 0.1904
Epoch 9/10, Batch 30/145, Loss: 0.0500
Epoch 9/10, Batch 40/145, Loss: 0.1919
Epoch 9/10, Batch 50/145, Loss: 0.2325
Epoch 9/10, Batch 60/145, Loss: 0.3531
Epoch 9/10, Batch 70/145, Loss: 0.2398
Epoch 9/10, Batch 80/145, Loss: 0.1524
Epoch 9/10, Batch 90/145, Loss: 0.1685
Epoch 9/10, Batch 100/145, Loss: 0.1515
Epoch 9/10, Batch 110/145, Loss: 0.3052
Epoch 9/10, Batch 120/145, Loss: 0.1079
Epoch 9/10, Batch 130/145, Loss: 0.0645
Epoch 9/10, Batch 140/145, Loss: 0.2809
Epoch 9/10, Train Loss: 0.2062, Valid Loss: 0.2022
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1581
Epoch 10/10, Batch 20/145, Loss: 0.2039
Epoch 10/10, Batch 30/145, Loss: 0.1184
Epoch 10/10, Batch 40/145, Loss: 0.1333
Epoch 10/10, Batch 50/145, Loss: 0.2974
Epoch 10/10, Batch 60/145, Loss: 0.2733
Epoch 10/10, Batch 70/145, Loss: 0.3265
Epoch 10/10, Batch 80/145, Loss: 0.0560
Epoch 10/10, Batch 90/145, Loss: 0.1465
Epoch 10/10, Batch 100/145, Loss: 0.2838
Epoch 10/10, Batch 110/145, Loss: 0.1776
Epoch 10/10, Batch 120/145, Loss: 0.1874
Epoch 10/10, Batch 130/145, Loss: 0.2032
Epoch 10/10, Batch 140/145, Loss: 0.2289
Epoch 10/10, Train Loss: 0.1986, Valid Loss: 0.2053
Accuracy: 0.9217
Precision: 0.9209
Recall: 0.9217
F1-score: 0.9213
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4116
Epoch 1/10, Batch 20/145, Loss: 0.9329
Epoch 1/10, Batch 30/145, Loss: 0.8894
Epoch 1/10, Batch 40/145, Loss: 0.7946
Epoch 1/10, Batch 50/145, Loss: 0.7530
Epoch 1/10, Batch 60/145, Loss: 0.5260
Epoch 1/10, Batch 70/145, Loss: 0.4927
Epoch 1/10, Batch 80/145, Loss: 0.5581
Epoch 1/10, Batch 90/145, Loss: 0.4378
Epoch 1/10, Batch 100/145, Loss: 0.5302
Epoch 1/10, Batch 110/145, Loss: 0.2927
Epoch 1/10, Batch 120/145, Loss: 0.5613
Epoch 1/10, Batch 130/145, Loss: 0.4734
Epoch 1/10, Batch 140/145, Loss: 0.4188
Epoch 1/10, Train Loss: 0.6723, Valid Loss: 0.3719
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2806
Epoch 2/10, Batch 20/145, Loss: 0.2387
Epoch 2/10, Batch 30/145, Loss: 0.2312
Epoch 2/10, Batch 40/145, Loss: 0.4229
Epoch 2/10, Batch 50/145, Loss: 0.3416
Epoch 2/10, Batch 60/145, Loss: 0.6828
Epoch 2/10, Batch 70/145, Loss: 0.4644
Epoch 2/10, Batch 80/145, Loss: 0.2691
Epoch 2/10, Batch 90/145, Loss: 0.3564
Epoch 2/10, Batch 100/145, Loss: 0.2488
Epoch 2/10, Batch 110/145, Loss: 0.3336
Epoch 2/10, Batch 120/145, Loss: 0.3073
Epoch 2/10, Batch 130/145, Loss: 0.4122
Epoch 2/10, Batch 140/145, Loss: 0.2026
Epoch 2/10, Train Loss: 0.3465, Valid Loss: 0.2921
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2992
Epoch 3/10, Batch 20/145, Loss: 0.2093
Epoch 3/10, Batch 30/145, Loss: 0.3529
Epoch 3/10, Batch 40/145, Loss: 0.3589
Epoch 3/10, Batch 50/145, Loss: 0.2541
Epoch 3/10, Batch 60/145, Loss: 0.2131
Epoch 3/10, Batch 70/145, Loss: 0.2652
Epoch 3/10, Batch 80/145, Loss: 0.1837
Epoch 3/10, Batch 90/145, Loss: 0.2026
Epoch 3/10, Batch 100/145, Loss: 0.1741
Epoch 3/10, Batch 110/145, Loss: 0.2254
Epoch 3/10, Batch 120/145, Loss: 0.1472
Epoch 3/10, Batch 130/145, Loss: 0.3028
Epoch 3/10, Batch 140/145, Loss: 0.1705
Epoch 3/10, Train Loss: 0.2860, Valid Loss: 0.2651
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2566
Epoch 4/10, Batch 20/145, Loss: 0.4127
Epoch 4/10, Batch 30/145, Loss: 0.2669
Epoch 4/10, Batch 40/145, Loss: 0.1980
Epoch 4/10, Batch 50/145, Loss: 0.2026
Epoch 4/10, Batch 60/145, Loss: 0.3166
Epoch 4/10, Batch 70/145, Loss: 0.1908
Epoch 4/10, Batch 80/145, Loss: 0.1700
Epoch 4/10, Batch 90/145, Loss: 0.1991
Epoch 4/10, Batch 100/145, Loss: 0.2509
Epoch 4/10, Batch 110/145, Loss: 0.2465
Epoch 4/10, Batch 120/145, Loss: 0.2114
Epoch 4/10, Batch 130/145, Loss: 0.1152
Epoch 4/10, Batch 140/145, Loss: 0.1884
Epoch 4/10, Train Loss: 0.2505, Valid Loss: 0.2505
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2024
Epoch 5/10, Batch 20/145, Loss: 0.2758
Epoch 5/10, Batch 30/145, Loss: 0.3605
Epoch 5/10, Batch 40/145, Loss: 0.1043
Epoch 5/10, Batch 50/145, Loss: 0.3259
Epoch 5/10, Batch 60/145, Loss: 0.2533
Epoch 5/10, Batch 70/145, Loss: 0.1309
Epoch 5/10, Batch 80/145, Loss: 0.2049
Epoch 5/10, Batch 90/145, Loss: 0.4977
Epoch 5/10, Batch 100/145, Loss: 0.1089
Epoch 5/10, Batch 110/145, Loss: 0.1864
Epoch 5/10, Batch 120/145, Loss: 0.2538
Epoch 5/10, Batch 130/145, Loss: 0.0969
Epoch 5/10, Batch 140/145, Loss: 0.1395
Epoch 5/10, Train Loss: 0.2363, Valid Loss: 0.2551
Epoch 6/10, Batch 10/145, Loss: 0.1853
Epoch 6/10, Batch 20/145, Loss: 0.4127
Epoch 6/10, Batch 30/145, Loss: 0.3713
Epoch 6/10, Batch 40/145, Loss: 0.1808
Epoch 6/10, Batch 50/145, Loss: 0.3170
Epoch 6/10, Batch 60/145, Loss: 0.2176
Epoch 6/10, Batch 70/145, Loss: 0.3595
Epoch 6/10, Batch 80/145, Loss: 0.0963
Epoch 6/10, Batch 90/145, Loss: 0.3266
Epoch 6/10, Batch 100/145, Loss: 0.3153
Epoch 6/10, Batch 110/145, Loss: 0.2870
Epoch 6/10, Batch 120/145, Loss: 0.2077
Epoch 6/10, Batch 130/145, Loss: 0.1127
Epoch 6/10, Batch 140/145, Loss: 0.2415
Epoch 6/10, Train Loss: 0.2217, Valid Loss: 0.2345
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1676
Epoch 7/10, Batch 20/145, Loss: 0.3160
Epoch 7/10, Batch 30/145, Loss: 0.1153
Epoch 7/10, Batch 40/145, Loss: 0.3047
Epoch 7/10, Batch 50/145, Loss: 0.1017
Epoch 7/10, Batch 60/145, Loss: 0.2092
Epoch 7/10, Batch 70/145, Loss: 0.2319
Epoch 7/10, Batch 80/145, Loss: 0.2868
Epoch 7/10, Batch 90/145, Loss: 0.3340
Epoch 7/10, Batch 100/145, Loss: 0.2192
Epoch 7/10, Batch 110/145, Loss: 0.3393
Epoch 7/10, Batch 120/145, Loss: 0.1233
Epoch 7/10, Batch 130/145, Loss: 0.0708
Epoch 7/10, Batch 140/145, Loss: 0.3283
Epoch 7/10, Train Loss: 0.2134, Valid Loss: 0.2288
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1693
Epoch 8/10, Batch 20/145, Loss: 0.2643
Epoch 8/10, Batch 30/145, Loss: 0.1627
Epoch 8/10, Batch 40/145, Loss: 0.1472
Epoch 8/10, Batch 50/145, Loss: 0.1902
Epoch 8/10, Batch 60/145, Loss: 0.1724
Epoch 8/10, Batch 70/145, Loss: 0.2096
Epoch 8/10, Batch 80/145, Loss: 0.3115
Epoch 8/10, Batch 90/145, Loss: 0.2386
Epoch 8/10, Batch 100/145, Loss: 0.2556
Epoch 8/10, Batch 110/145, Loss: 0.1582
Epoch 8/10, Batch 120/145, Loss: 0.1229
Epoch 8/10, Batch 130/145, Loss: 0.1171
Epoch 8/10, Batch 140/145, Loss: 0.3245
Epoch 8/10, Train Loss: 0.1986, Valid Loss: 0.2354
Epoch 9/10, Batch 10/145, Loss: 0.4035
Epoch 9/10, Batch 20/145, Loss: 0.0898
Epoch 9/10, Batch 30/145, Loss: 0.0645
Epoch 9/10, Batch 40/145, Loss: 0.1541
Epoch 9/10, Batch 50/145, Loss: 0.1198
Epoch 9/10, Batch 60/145, Loss: 0.2690
Epoch 9/10, Batch 70/145, Loss: 0.3777
Epoch 9/10, Batch 80/145, Loss: 0.1961
Epoch 9/10, Batch 90/145, Loss: 0.1245
Epoch 9/10, Batch 100/145, Loss: 0.1612
Epoch 9/10, Batch 110/145, Loss: 0.3028
Epoch 9/10, Batch 120/145, Loss: 0.0989
Epoch 9/10, Batch 130/145, Loss: 0.2112
Epoch 9/10, Batch 140/145, Loss: 0.1347
Epoch 9/10, Train Loss: 0.2007, Valid Loss: 0.2225
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1240
Epoch 10/10, Batch 20/145, Loss: 0.3206
Epoch 10/10, Batch 30/145, Loss: 0.1484
Epoch 10/10, Batch 40/145, Loss: 0.1717
Epoch 10/10, Batch 50/145, Loss: 0.1880
Epoch 10/10, Batch 60/145, Loss: 0.2176
Epoch 10/10, Batch 70/145, Loss: 0.2633
Epoch 10/10, Batch 80/145, Loss: 0.2272
Epoch 10/10, Batch 90/145, Loss: 0.2032
Epoch 10/10, Batch 100/145, Loss: 0.1609
Epoch 10/10, Batch 110/145, Loss: 0.2574
Epoch 10/10, Batch 120/145, Loss: 0.1876
Epoch 10/10, Batch 130/145, Loss: 0.1440
Epoch 10/10, Batch 140/145, Loss: 0.1681
Epoch 10/10, Train Loss: 0.1887, Valid Loss: 0.2200
Model saved!
Accuracy: 0.9241
Precision: 0.9216
Recall: 0.9241
F1-score: 0.9221
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3877
Epoch 1/10, Batch 20/145, Loss: 0.9759
Epoch 1/10, Batch 30/145, Loss: 0.9124
Epoch 1/10, Batch 40/145, Loss: 0.8026
Epoch 1/10, Batch 50/145, Loss: 0.6647
Epoch 1/10, Batch 60/145, Loss: 0.6271
Epoch 1/10, Batch 70/145, Loss: 0.4553
Epoch 1/10, Batch 80/145, Loss: 0.4051
Epoch 1/10, Batch 90/145, Loss: 0.3990
Epoch 1/10, Batch 100/145, Loss: 0.4435
Epoch 1/10, Batch 110/145, Loss: 0.3967
Epoch 1/10, Batch 120/145, Loss: 0.5395
Epoch 1/10, Batch 130/145, Loss: 0.5001
Epoch 1/10, Batch 140/145, Loss: 0.4825
Epoch 1/10, Train Loss: 0.6712, Valid Loss: 0.3859
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3074
Epoch 2/10, Batch 20/145, Loss: 0.2832
Epoch 2/10, Batch 30/145, Loss: 0.2703
Epoch 2/10, Batch 40/145, Loss: 0.4773
Epoch 2/10, Batch 50/145, Loss: 0.2328
Epoch 2/10, Batch 60/145, Loss: 0.3406
Epoch 2/10, Batch 70/145, Loss: 0.2855
Epoch 2/10, Batch 80/145, Loss: 0.3042
Epoch 2/10, Batch 90/145, Loss: 0.2684
Epoch 2/10, Batch 100/145, Loss: 0.5209
Epoch 2/10, Batch 110/145, Loss: 0.4082
Epoch 2/10, Batch 120/145, Loss: 0.2649
Epoch 2/10, Batch 130/145, Loss: 0.2452
Epoch 2/10, Batch 140/145, Loss: 0.3040
Epoch 2/10, Train Loss: 0.3432, Valid Loss: 0.3074
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2231
Epoch 3/10, Batch 20/145, Loss: 0.1752
Epoch 3/10, Batch 30/145, Loss: 0.3281
Epoch 3/10, Batch 40/145, Loss: 0.2960
Epoch 3/10, Batch 50/145, Loss: 0.1684
Epoch 3/10, Batch 60/145, Loss: 0.2380
Epoch 3/10, Batch 70/145, Loss: 0.3673
Epoch 3/10, Batch 80/145, Loss: 0.1440
Epoch 3/10, Batch 90/145, Loss: 0.2248
Epoch 3/10, Batch 100/145, Loss: 0.2314
Epoch 3/10, Batch 110/145, Loss: 0.3185
Epoch 3/10, Batch 120/145, Loss: 0.1944
Epoch 3/10, Batch 130/145, Loss: 0.4476
Epoch 3/10, Batch 140/145, Loss: 0.2976
Epoch 3/10, Train Loss: 0.2878, Valid Loss: 0.2749
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2776
Epoch 4/10, Batch 20/145, Loss: 0.1755
Epoch 4/10, Batch 30/145, Loss: 0.3657
Epoch 4/10, Batch 40/145, Loss: 0.1490
Epoch 4/10, Batch 50/145, Loss: 0.1276
Epoch 4/10, Batch 60/145, Loss: 0.2769
Epoch 4/10, Batch 70/145, Loss: 0.3014
Epoch 4/10, Batch 80/145, Loss: 0.1402
Epoch 4/10, Batch 90/145, Loss: 0.2770
Epoch 4/10, Batch 100/145, Loss: 0.2469
Epoch 4/10, Batch 110/145, Loss: 0.0916
Epoch 4/10, Batch 120/145, Loss: 0.2627
Epoch 4/10, Batch 130/145, Loss: 0.1826
Epoch 4/10, Batch 140/145, Loss: 0.1171
Epoch 4/10, Train Loss: 0.2471, Valid Loss: 0.2615
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1753
Epoch 5/10, Batch 20/145, Loss: 0.2668
Epoch 5/10, Batch 30/145, Loss: 0.3403
Epoch 5/10, Batch 40/145, Loss: 0.2012
Epoch 5/10, Batch 50/145, Loss: 0.2651
Epoch 5/10, Batch 60/145, Loss: 0.2280
Epoch 5/10, Batch 70/145, Loss: 0.1684
Epoch 5/10, Batch 80/145, Loss: 0.2691
Epoch 5/10, Batch 90/145, Loss: 0.3432
Epoch 5/10, Batch 100/145, Loss: 0.2336
Epoch 5/10, Batch 110/145, Loss: 0.2569
Epoch 5/10, Batch 120/145, Loss: 0.2603
Epoch 5/10, Batch 130/145, Loss: 0.1211
Epoch 5/10, Batch 140/145, Loss: 0.1708
Epoch 5/10, Train Loss: 0.2347, Valid Loss: 0.2499
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.0978
Epoch 6/10, Batch 20/145, Loss: 0.3547
Epoch 6/10, Batch 30/145, Loss: 0.3784
Epoch 6/10, Batch 40/145, Loss: 0.1274
Epoch 6/10, Batch 50/145, Loss: 0.4901
Epoch 6/10, Batch 60/145, Loss: 0.2606
Epoch 6/10, Batch 70/145, Loss: 0.1690
Epoch 6/10, Batch 80/145, Loss: 0.2036
Epoch 6/10, Batch 90/145, Loss: 0.2805
Epoch 6/10, Batch 100/145, Loss: 0.2774
Epoch 6/10, Batch 110/145, Loss: 0.2713
Epoch 6/10, Batch 120/145, Loss: 0.3380
Epoch 6/10, Batch 130/145, Loss: 0.2037
Epoch 6/10, Batch 140/145, Loss: 0.1373
Epoch 6/10, Train Loss: 0.2184, Valid Loss: 0.2432
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1590
Epoch 7/10, Batch 20/145, Loss: 0.2307
Epoch 7/10, Batch 30/145, Loss: 0.2991
Epoch 7/10, Batch 40/145, Loss: 0.2713
Epoch 7/10, Batch 50/145, Loss: 0.1952
Epoch 7/10, Batch 60/145, Loss: 0.2918
Epoch 7/10, Batch 70/145, Loss: 0.1053
Epoch 7/10, Batch 80/145, Loss: 0.3463
Epoch 7/10, Batch 90/145, Loss: 0.1994
Epoch 7/10, Batch 100/145, Loss: 0.0982
Epoch 7/10, Batch 110/145, Loss: 0.1500
Epoch 7/10, Batch 120/145, Loss: 0.2272
Epoch 7/10, Batch 130/145, Loss: 0.0811
Epoch 7/10, Batch 140/145, Loss: 0.2543
Epoch 7/10, Train Loss: 0.2037, Valid Loss: 0.2320
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.3607
Epoch 8/10, Batch 20/145, Loss: 0.1506
Epoch 8/10, Batch 30/145, Loss: 0.1925
Epoch 8/10, Batch 40/145, Loss: 0.2327
Epoch 8/10, Batch 50/145, Loss: 0.2236
Epoch 8/10, Batch 60/145, Loss: 0.2420
Epoch 8/10, Batch 70/145, Loss: 0.1664
Epoch 8/10, Batch 80/145, Loss: 0.1909
Epoch 8/10, Batch 90/145, Loss: 0.1966
Epoch 8/10, Batch 100/145, Loss: 0.2436
Epoch 8/10, Batch 110/145, Loss: 0.1795
Epoch 8/10, Batch 120/145, Loss: 0.2415
Epoch 8/10, Batch 130/145, Loss: 0.1919
Epoch 8/10, Batch 140/145, Loss: 0.3378
Epoch 8/10, Train Loss: 0.2016, Valid Loss: 0.2323
Epoch 9/10, Batch 10/145, Loss: 0.4651
Epoch 9/10, Batch 20/145, Loss: 0.1329
Epoch 9/10, Batch 30/145, Loss: 0.1020
Epoch 9/10, Batch 40/145, Loss: 0.2665
Epoch 9/10, Batch 50/145, Loss: 0.1127
Epoch 9/10, Batch 60/145, Loss: 0.1992
Epoch 9/10, Batch 70/145, Loss: 0.0942
Epoch 9/10, Batch 80/145, Loss: 0.0391
Epoch 9/10, Batch 90/145, Loss: 0.1326
Epoch 9/10, Batch 100/145, Loss: 0.0832
Epoch 9/10, Batch 110/145, Loss: 0.2332
Epoch 9/10, Batch 120/145, Loss: 0.0449
Epoch 9/10, Batch 130/145, Loss: 0.1330
Epoch 9/10, Batch 140/145, Loss: 0.2844
Epoch 9/10, Train Loss: 0.1901, Valid Loss: 0.2345
Epoch 10/10, Batch 10/145, Loss: 0.1652
Epoch 10/10, Batch 20/145, Loss: 0.1568
Epoch 10/10, Batch 30/145, Loss: 0.2019
Epoch 10/10, Batch 40/145, Loss: 0.2063
Epoch 10/10, Batch 50/145, Loss: 0.2370
Epoch 10/10, Batch 60/145, Loss: 0.1334
Epoch 10/10, Batch 70/145, Loss: 0.2112
Epoch 10/10, Batch 80/145, Loss: 0.2364
Epoch 10/10, Batch 90/145, Loss: 0.0668
Epoch 10/10, Batch 100/145, Loss: 0.2389
Epoch 10/10, Batch 110/145, Loss: 0.1747
Epoch 10/10, Batch 120/145, Loss: 0.1213
Epoch 10/10, Batch 130/145, Loss: 0.1521
Epoch 10/10, Batch 140/145, Loss: 0.2359
Epoch 10/10, Train Loss: 0.1877, Valid Loss: 0.2247
Model saved!
Accuracy: 0.9147
Precision: 0.9128
Recall: 0.9147
F1-score: 0.9136
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4198
Epoch 1/10, Batch 20/145, Loss: 0.9312
Epoch 1/10, Batch 30/145, Loss: 0.9251
Epoch 1/10, Batch 40/145, Loss: 0.9062
Epoch 1/10, Batch 50/145, Loss: 0.6238
Epoch 1/10, Batch 60/145, Loss: 0.6221
Epoch 1/10, Batch 70/145, Loss: 0.5000
Epoch 1/10, Batch 80/145, Loss: 0.6641
Epoch 1/10, Batch 90/145, Loss: 0.4558
Epoch 1/10, Batch 100/145, Loss: 0.5395
Epoch 1/10, Batch 110/145, Loss: 0.4736
Epoch 1/10, Batch 120/145, Loss: 0.5159
Epoch 1/10, Batch 130/145, Loss: 0.4971
Epoch 1/10, Batch 140/145, Loss: 0.3789
Epoch 1/10, Train Loss: 0.6748, Valid Loss: 0.3663
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3493
Epoch 2/10, Batch 20/145, Loss: 0.3902
Epoch 2/10, Batch 30/145, Loss: 0.2410
Epoch 2/10, Batch 40/145, Loss: 0.3673
Epoch 2/10, Batch 50/145, Loss: 0.2776
Epoch 2/10, Batch 60/145, Loss: 0.4338
Epoch 2/10, Batch 70/145, Loss: 0.3671
Epoch 2/10, Batch 80/145, Loss: 0.2582
Epoch 2/10, Batch 90/145, Loss: 0.2472
Epoch 2/10, Batch 100/145, Loss: 0.4277
Epoch 2/10, Batch 110/145, Loss: 0.5658
Epoch 2/10, Batch 120/145, Loss: 0.4589
Epoch 2/10, Batch 130/145, Loss: 0.2573
Epoch 2/10, Batch 140/145, Loss: 0.2607
Epoch 2/10, Train Loss: 0.3583, Valid Loss: 0.2847
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3145
Epoch 3/10, Batch 20/145, Loss: 0.4073
Epoch 3/10, Batch 30/145, Loss: 0.4985
Epoch 3/10, Batch 40/145, Loss: 0.2475
Epoch 3/10, Batch 50/145, Loss: 0.3987
Epoch 3/10, Batch 60/145, Loss: 0.2958
Epoch 3/10, Batch 70/145, Loss: 0.3678
Epoch 3/10, Batch 80/145, Loss: 0.2545
Epoch 3/10, Batch 90/145, Loss: 0.3100
Epoch 3/10, Batch 100/145, Loss: 0.1774
Epoch 3/10, Batch 110/145, Loss: 0.3081
Epoch 3/10, Batch 120/145, Loss: 0.2716
Epoch 3/10, Batch 130/145, Loss: 0.3037
Epoch 3/10, Batch 140/145, Loss: 0.1979
Epoch 3/10, Train Loss: 0.2934, Valid Loss: 0.2523
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2607
Epoch 4/10, Batch 20/145, Loss: 0.2562
Epoch 4/10, Batch 30/145, Loss: 0.1319
Epoch 4/10, Batch 40/145, Loss: 0.1591
Epoch 4/10, Batch 50/145, Loss: 0.2121
Epoch 4/10, Batch 60/145, Loss: 0.4874
Epoch 4/10, Batch 70/145, Loss: 0.2862
Epoch 4/10, Batch 80/145, Loss: 0.1580
Epoch 4/10, Batch 90/145, Loss: 0.2184
Epoch 4/10, Batch 100/145, Loss: 0.2909
Epoch 4/10, Batch 110/145, Loss: 0.1598
Epoch 4/10, Batch 120/145, Loss: 0.2015
Epoch 4/10, Batch 130/145, Loss: 0.2280
Epoch 4/10, Batch 140/145, Loss: 0.1358
Epoch 4/10, Train Loss: 0.2637, Valid Loss: 0.2394
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2346
Epoch 5/10, Batch 20/145, Loss: 0.1210
Epoch 5/10, Batch 30/145, Loss: 0.3415
Epoch 5/10, Batch 40/145, Loss: 0.1295
Epoch 5/10, Batch 50/145, Loss: 0.2482
Epoch 5/10, Batch 60/145, Loss: 0.2410
Epoch 5/10, Batch 70/145, Loss: 0.2495
Epoch 5/10, Batch 80/145, Loss: 0.3129
Epoch 5/10, Batch 90/145, Loss: 0.3964
Epoch 5/10, Batch 100/145, Loss: 0.2360
Epoch 5/10, Batch 110/145, Loss: 0.3523
Epoch 5/10, Batch 120/145, Loss: 0.2995
Epoch 5/10, Batch 130/145, Loss: 0.2050
Epoch 5/10, Batch 140/145, Loss: 0.3342
Epoch 5/10, Train Loss: 0.2513, Valid Loss: 0.2308
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1599
Epoch 6/10, Batch 20/145, Loss: 0.3370
Epoch 6/10, Batch 30/145, Loss: 0.2551
Epoch 6/10, Batch 40/145, Loss: 0.1390
Epoch 6/10, Batch 50/145, Loss: 0.4041
Epoch 6/10, Batch 60/145, Loss: 0.2240
Epoch 6/10, Batch 70/145, Loss: 0.2039
Epoch 6/10, Batch 80/145, Loss: 0.2287
Epoch 6/10, Batch 90/145, Loss: 0.3782
Epoch 6/10, Batch 100/145, Loss: 0.1949
Epoch 6/10, Batch 110/145, Loss: 0.1593
Epoch 6/10, Batch 120/145, Loss: 0.4366
Epoch 6/10, Batch 130/145, Loss: 0.1145
Epoch 6/10, Batch 140/145, Loss: 0.2107
Epoch 6/10, Train Loss: 0.2339, Valid Loss: 0.2211
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2974
Epoch 7/10, Batch 20/145, Loss: 0.2482
Epoch 7/10, Batch 30/145, Loss: 0.2261
Epoch 7/10, Batch 40/145, Loss: 0.1681
Epoch 7/10, Batch 50/145, Loss: 0.3303
Epoch 7/10, Batch 60/145, Loss: 0.1235
Epoch 7/10, Batch 70/145, Loss: 0.1711
Epoch 7/10, Batch 80/145, Loss: 0.4435
Epoch 7/10, Batch 90/145, Loss: 0.1461
Epoch 7/10, Batch 100/145, Loss: 0.2098
Epoch 7/10, Batch 110/145, Loss: 0.1766
Epoch 7/10, Batch 120/145, Loss: 0.1775
Epoch 7/10, Batch 130/145, Loss: 0.1218
Epoch 7/10, Batch 140/145, Loss: 0.3278
Epoch 7/10, Train Loss: 0.2127, Valid Loss: 0.2199
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1974
Epoch 8/10, Batch 20/145, Loss: 0.2572
Epoch 8/10, Batch 30/145, Loss: 0.2607
Epoch 8/10, Batch 40/145, Loss: 0.1274
Epoch 8/10, Batch 50/145, Loss: 0.3155
Epoch 8/10, Batch 60/145, Loss: 0.1790
Epoch 8/10, Batch 70/145, Loss: 0.2911
Epoch 8/10, Batch 80/145, Loss: 0.1576
Epoch 8/10, Batch 90/145, Loss: 0.3953
Epoch 8/10, Batch 100/145, Loss: 0.2959
Epoch 8/10, Batch 110/145, Loss: 0.2051
Epoch 8/10, Batch 120/145, Loss: 0.3261
Epoch 8/10, Batch 130/145, Loss: 0.1832
Epoch 8/10, Batch 140/145, Loss: 0.2681
Epoch 8/10, Train Loss: 0.2048, Valid Loss: 0.2137
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1668
Epoch 9/10, Batch 20/145, Loss: 0.1992
Epoch 9/10, Batch 30/145, Loss: 0.1346
Epoch 9/10, Batch 40/145, Loss: 0.1651
Epoch 9/10, Batch 50/145, Loss: 0.0775
Epoch 9/10, Batch 60/145, Loss: 0.2311
Epoch 9/10, Batch 70/145, Loss: 0.1679
Epoch 9/10, Batch 80/145, Loss: 0.0615
Epoch 9/10, Batch 90/145, Loss: 0.2195
Epoch 9/10, Batch 100/145, Loss: 0.1465
Epoch 9/10, Batch 110/145, Loss: 0.1890
Epoch 9/10, Batch 120/145, Loss: 0.2014
Epoch 9/10, Batch 130/145, Loss: 0.2279
Epoch 9/10, Batch 140/145, Loss: 0.1827
Epoch 9/10, Train Loss: 0.2038, Valid Loss: 0.2113
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1557
Epoch 10/10, Batch 20/145, Loss: 0.1899
Epoch 10/10, Batch 30/145, Loss: 0.1770
Epoch 10/10, Batch 40/145, Loss: 0.3198
Epoch 10/10, Batch 50/145, Loss: 0.2714
Epoch 10/10, Batch 60/145, Loss: 0.2023
Epoch 10/10, Batch 70/145, Loss: 0.3315
Epoch 10/10, Batch 80/145, Loss: 0.1720
Epoch 10/10, Batch 90/145, Loss: 0.1758
Epoch 10/10, Batch 100/145, Loss: 0.1569
Epoch 10/10, Batch 110/145, Loss: 0.2499
Epoch 10/10, Batch 120/145, Loss: 0.2112
Epoch 10/10, Batch 130/145, Loss: 0.2121
Epoch 10/10, Batch 140/145, Loss: 0.3371
Epoch 10/10, Train Loss: 0.2032, Valid Loss: 0.2060
Model saved!
Accuracy: 0.9171
Precision: 0.9146
Recall: 0.9171
F1-score: 0.9154
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4181
Epoch 1/10, Batch 20/145, Loss: 0.9177
Epoch 1/10, Batch 30/145, Loss: 0.8931
Epoch 1/10, Batch 40/145, Loss: 0.8512
Epoch 1/10, Batch 50/145, Loss: 0.8039
Epoch 1/10, Batch 60/145, Loss: 0.5498
Epoch 1/10, Batch 70/145, Loss: 0.4815
Epoch 1/10, Batch 80/145, Loss: 0.6176
Epoch 1/10, Batch 90/145, Loss: 0.4677
Epoch 1/10, Batch 100/145, Loss: 0.5863
Epoch 1/10, Batch 110/145, Loss: 0.4337
Epoch 1/10, Batch 120/145, Loss: 0.4772
Epoch 1/10, Batch 130/145, Loss: 0.5539
Epoch 1/10, Batch 140/145, Loss: 0.2938
Epoch 1/10, Train Loss: 0.6746, Valid Loss: 0.3902
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3741
Epoch 2/10, Batch 20/145, Loss: 0.3733
Epoch 2/10, Batch 30/145, Loss: 0.2702
Epoch 2/10, Batch 40/145, Loss: 0.4347
Epoch 2/10, Batch 50/145, Loss: 0.4559
Epoch 2/10, Batch 60/145, Loss: 0.4286
Epoch 2/10, Batch 70/145, Loss: 0.4016
Epoch 2/10, Batch 80/145, Loss: 0.3162
Epoch 2/10, Batch 90/145, Loss: 0.2555
Epoch 2/10, Batch 100/145, Loss: 0.3526
Epoch 2/10, Batch 110/145, Loss: 0.3929
Epoch 2/10, Batch 120/145, Loss: 0.3292
Epoch 2/10, Batch 130/145, Loss: 0.3452
Epoch 2/10, Batch 140/145, Loss: 0.1887
Epoch 2/10, Train Loss: 0.3520, Valid Loss: 0.3102
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2742
Epoch 3/10, Batch 20/145, Loss: 0.2381
Epoch 3/10, Batch 30/145, Loss: 0.4041
Epoch 3/10, Batch 40/145, Loss: 0.1902
Epoch 3/10, Batch 50/145, Loss: 0.1864
Epoch 3/10, Batch 60/145, Loss: 0.3481
Epoch 3/10, Batch 70/145, Loss: 0.3712
Epoch 3/10, Batch 80/145, Loss: 0.2291
Epoch 3/10, Batch 90/145, Loss: 0.2173
Epoch 3/10, Batch 100/145, Loss: 0.2739
Epoch 3/10, Batch 110/145, Loss: 0.3148
Epoch 3/10, Batch 120/145, Loss: 0.1982
Epoch 3/10, Batch 130/145, Loss: 0.3502
Epoch 3/10, Batch 140/145, Loss: 0.2546
Epoch 3/10, Train Loss: 0.2938, Valid Loss: 0.2752
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3343
Epoch 4/10, Batch 20/145, Loss: 0.3630
Epoch 4/10, Batch 30/145, Loss: 0.2289
Epoch 4/10, Batch 40/145, Loss: 0.3140
Epoch 4/10, Batch 50/145, Loss: 0.1457
Epoch 4/10, Batch 60/145, Loss: 0.2000
Epoch 4/10, Batch 70/145, Loss: 0.2086
Epoch 4/10, Batch 80/145, Loss: 0.1331
Epoch 4/10, Batch 90/145, Loss: 0.2040
Epoch 4/10, Batch 100/145, Loss: 0.3569
Epoch 4/10, Batch 110/145, Loss: 0.2326
Epoch 4/10, Batch 120/145, Loss: 0.1991
Epoch 4/10, Batch 130/145, Loss: 0.1684
Epoch 4/10, Batch 140/145, Loss: 0.1393
Epoch 4/10, Train Loss: 0.2592, Valid Loss: 0.2682
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3055
Epoch 5/10, Batch 20/145, Loss: 0.0740
Epoch 5/10, Batch 30/145, Loss: 0.2307
Epoch 5/10, Batch 40/145, Loss: 0.1543
Epoch 5/10, Batch 50/145, Loss: 0.2852
Epoch 5/10, Batch 60/145, Loss: 0.3140
Epoch 5/10, Batch 70/145, Loss: 0.2121
Epoch 5/10, Batch 80/145, Loss: 0.1910
Epoch 5/10, Batch 90/145, Loss: 0.3749
Epoch 5/10, Batch 100/145, Loss: 0.1409
Epoch 5/10, Batch 110/145, Loss: 0.1582
Epoch 5/10, Batch 120/145, Loss: 0.2460
Epoch 5/10, Batch 130/145, Loss: 0.2098
Epoch 5/10, Batch 140/145, Loss: 0.1439
Epoch 5/10, Train Loss: 0.2383, Valid Loss: 0.2559
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2698
Epoch 6/10, Batch 20/145, Loss: 0.7058
Epoch 6/10, Batch 30/145, Loss: 0.2948
Epoch 6/10, Batch 40/145, Loss: 0.3287
Epoch 6/10, Batch 50/145, Loss: 0.3447
Epoch 6/10, Batch 60/145, Loss: 0.1543
Epoch 6/10, Batch 70/145, Loss: 0.2200
Epoch 6/10, Batch 80/145, Loss: 0.3817
Epoch 6/10, Batch 90/145, Loss: 0.4213
Epoch 6/10, Batch 100/145, Loss: 0.2292
Epoch 6/10, Batch 110/145, Loss: 0.2227
Epoch 6/10, Batch 120/145, Loss: 0.1476
Epoch 6/10, Batch 130/145, Loss: 0.1838
Epoch 6/10, Batch 140/145, Loss: 0.3263
Epoch 6/10, Train Loss: 0.2289, Valid Loss: 0.2482
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1759
Epoch 7/10, Batch 20/145, Loss: 0.3807
Epoch 7/10, Batch 30/145, Loss: 0.2029
Epoch 7/10, Batch 40/145, Loss: 0.3806
Epoch 7/10, Batch 50/145, Loss: 0.1267
Epoch 7/10, Batch 60/145, Loss: 0.0676
Epoch 7/10, Batch 70/145, Loss: 0.0738
Epoch 7/10, Batch 80/145, Loss: 0.5003
Epoch 7/10, Batch 90/145, Loss: 0.2756
Epoch 7/10, Batch 100/145, Loss: 0.1731
Epoch 7/10, Batch 110/145, Loss: 0.2105
Epoch 7/10, Batch 120/145, Loss: 0.2371
Epoch 7/10, Batch 130/145, Loss: 0.2159
Epoch 7/10, Batch 140/145, Loss: 0.1946
Epoch 7/10, Train Loss: 0.2126, Valid Loss: 0.2445
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2869
Epoch 8/10, Batch 20/145, Loss: 0.4279
Epoch 8/10, Batch 30/145, Loss: 0.1910
Epoch 8/10, Batch 40/145, Loss: 0.2776
Epoch 8/10, Batch 50/145, Loss: 0.1580
Epoch 8/10, Batch 60/145, Loss: 0.1649
Epoch 8/10, Batch 70/145, Loss: 0.2033
Epoch 8/10, Batch 80/145, Loss: 0.1997
Epoch 8/10, Batch 90/145, Loss: 0.1983
Epoch 8/10, Batch 100/145, Loss: 0.1907
Epoch 8/10, Batch 110/145, Loss: 0.1481
Epoch 8/10, Batch 120/145, Loss: 0.1527
Epoch 8/10, Batch 130/145, Loss: 0.1794
Epoch 8/10, Batch 140/145, Loss: 0.2358
Epoch 8/10, Train Loss: 0.2011, Valid Loss: 0.2391
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2495
Epoch 9/10, Batch 20/145, Loss: 0.2086
Epoch 9/10, Batch 30/145, Loss: 0.1831
Epoch 9/10, Batch 40/145, Loss: 0.1883
Epoch 9/10, Batch 50/145, Loss: 0.0809
Epoch 9/10, Batch 60/145, Loss: 0.1668
Epoch 9/10, Batch 70/145, Loss: 0.3269
Epoch 9/10, Batch 80/145, Loss: 0.2888
Epoch 9/10, Batch 90/145, Loss: 0.2433
Epoch 9/10, Batch 100/145, Loss: 0.1957
Epoch 9/10, Batch 110/145, Loss: 0.1772
Epoch 9/10, Batch 120/145, Loss: 0.1794
Epoch 9/10, Batch 130/145, Loss: 0.1518
Epoch 9/10, Batch 140/145, Loss: 0.1627
Epoch 9/10, Train Loss: 0.1973, Valid Loss: 0.2376
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0728
Epoch 10/10, Batch 20/145, Loss: 0.1851
Epoch 10/10, Batch 30/145, Loss: 0.1653
Epoch 10/10, Batch 40/145, Loss: 0.2818
Epoch 10/10, Batch 50/145, Loss: 0.2315
Epoch 10/10, Batch 60/145, Loss: 0.0985
Epoch 10/10, Batch 70/145, Loss: 0.2222
Epoch 10/10, Batch 80/145, Loss: 0.3053
Epoch 10/10, Batch 90/145, Loss: 0.1745
Epoch 10/10, Batch 100/145, Loss: 0.2648
Epoch 10/10, Batch 110/145, Loss: 0.2441
Epoch 10/10, Batch 120/145, Loss: 0.3204
Epoch 10/10, Batch 130/145, Loss: 0.1310
Epoch 10/10, Batch 140/145, Loss: 0.2970
Epoch 10/10, Train Loss: 0.1874, Valid Loss: 0.2346
Model saved!
Accuracy: 0.9217
Precision: 0.9196
Recall: 0.9217
F1-score: 0.9198
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3826
Epoch 1/10, Batch 20/145, Loss: 0.9293
Epoch 1/10, Batch 30/145, Loss: 0.9391
Epoch 1/10, Batch 40/145, Loss: 0.7517
Epoch 1/10, Batch 50/145, Loss: 0.7116
Epoch 1/10, Batch 60/145, Loss: 0.7203
Epoch 1/10, Batch 70/145, Loss: 0.4511
Epoch 1/10, Batch 80/145, Loss: 0.5324
Epoch 1/10, Batch 90/145, Loss: 0.5705
Epoch 1/10, Batch 100/145, Loss: 0.4755
Epoch 1/10, Batch 110/145, Loss: 0.4275
Epoch 1/10, Batch 120/145, Loss: 0.4621
Epoch 1/10, Batch 130/145, Loss: 0.4804
Epoch 1/10, Batch 140/145, Loss: 0.3845
Epoch 1/10, Train Loss: 0.6772, Valid Loss: 0.3982
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3104
Epoch 2/10, Batch 20/145, Loss: 0.2844
Epoch 2/10, Batch 30/145, Loss: 0.2583
Epoch 2/10, Batch 40/145, Loss: 0.3627
Epoch 2/10, Batch 50/145, Loss: 0.3178
Epoch 2/10, Batch 60/145, Loss: 0.2803
Epoch 2/10, Batch 70/145, Loss: 0.3494
Epoch 2/10, Batch 80/145, Loss: 0.2924
Epoch 2/10, Batch 90/145, Loss: 0.3477
Epoch 2/10, Batch 100/145, Loss: 0.1688
Epoch 2/10, Batch 110/145, Loss: 0.2086
Epoch 2/10, Batch 120/145, Loss: 0.3761
Epoch 2/10, Batch 130/145, Loss: 0.2575
Epoch 2/10, Batch 140/145, Loss: 0.3960
Epoch 2/10, Train Loss: 0.3484, Valid Loss: 0.3119
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3297
Epoch 3/10, Batch 20/145, Loss: 0.3246
Epoch 3/10, Batch 30/145, Loss: 0.2779
Epoch 3/10, Batch 40/145, Loss: 0.1682
Epoch 3/10, Batch 50/145, Loss: 0.1701
Epoch 3/10, Batch 60/145, Loss: 0.4009
Epoch 3/10, Batch 70/145, Loss: 0.3935
Epoch 3/10, Batch 80/145, Loss: 0.2106
Epoch 3/10, Batch 90/145, Loss: 0.2490
Epoch 3/10, Batch 100/145, Loss: 0.4261
Epoch 3/10, Batch 110/145, Loss: 0.1404
Epoch 3/10, Batch 120/145, Loss: 0.2641
Epoch 3/10, Batch 130/145, Loss: 0.4516
Epoch 3/10, Batch 140/145, Loss: 0.4074
Epoch 3/10, Train Loss: 0.2875, Valid Loss: 0.2765
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3745
Epoch 4/10, Batch 20/145, Loss: 0.3854
Epoch 4/10, Batch 30/145, Loss: 0.2402
Epoch 4/10, Batch 40/145, Loss: 0.0676
Epoch 4/10, Batch 50/145, Loss: 0.1535
Epoch 4/10, Batch 60/145, Loss: 0.2164
Epoch 4/10, Batch 70/145, Loss: 0.3558
Epoch 4/10, Batch 80/145, Loss: 0.2085
Epoch 4/10, Batch 90/145, Loss: 0.1902
Epoch 4/10, Batch 100/145, Loss: 0.2983
Epoch 4/10, Batch 110/145, Loss: 0.1837
Epoch 4/10, Batch 120/145, Loss: 0.2010
Epoch 4/10, Batch 130/145, Loss: 0.1171
Epoch 4/10, Batch 140/145, Loss: 0.1020
Epoch 4/10, Train Loss: 0.2531, Valid Loss: 0.2683
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1637
Epoch 5/10, Batch 20/145, Loss: 0.1495
Epoch 5/10, Batch 30/145, Loss: 0.3185
Epoch 5/10, Batch 40/145, Loss: 0.1518
Epoch 5/10, Batch 50/145, Loss: 0.1186
Epoch 5/10, Batch 60/145, Loss: 0.1801
Epoch 5/10, Batch 70/145, Loss: 0.1498
Epoch 5/10, Batch 80/145, Loss: 0.1338
Epoch 5/10, Batch 90/145, Loss: 0.3422
Epoch 5/10, Batch 100/145, Loss: 0.1503
Epoch 5/10, Batch 110/145, Loss: 0.1878
Epoch 5/10, Batch 120/145, Loss: 0.2686
Epoch 5/10, Batch 130/145, Loss: 0.3214
Epoch 5/10, Batch 140/145, Loss: 0.2188
Epoch 5/10, Train Loss: 0.2417, Valid Loss: 0.2526
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2408
Epoch 6/10, Batch 20/145, Loss: 0.4424
Epoch 6/10, Batch 30/145, Loss: 0.3106
Epoch 6/10, Batch 40/145, Loss: 0.2029
Epoch 6/10, Batch 50/145, Loss: 0.2890
Epoch 6/10, Batch 60/145, Loss: 0.1489
Epoch 6/10, Batch 70/145, Loss: 0.0848
Epoch 6/10, Batch 80/145, Loss: 0.2843
Epoch 6/10, Batch 90/145, Loss: 0.3077
Epoch 6/10, Batch 100/145, Loss: 0.2734
Epoch 6/10, Batch 110/145, Loss: 0.1968
Epoch 6/10, Batch 120/145, Loss: 0.3447
Epoch 6/10, Batch 130/145, Loss: 0.2417
Epoch 6/10, Batch 140/145, Loss: 0.1572
Epoch 6/10, Train Loss: 0.2257, Valid Loss: 0.2439
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3033
Epoch 7/10, Batch 20/145, Loss: 0.3852
Epoch 7/10, Batch 30/145, Loss: 0.2682
Epoch 7/10, Batch 40/145, Loss: 0.3935
Epoch 7/10, Batch 50/145, Loss: 0.1343
Epoch 7/10, Batch 60/145, Loss: 0.1048
Epoch 7/10, Batch 70/145, Loss: 0.1854
Epoch 7/10, Batch 80/145, Loss: 0.3824
Epoch 7/10, Batch 90/145, Loss: 0.1125
Epoch 7/10, Batch 100/145, Loss: 0.0742
Epoch 7/10, Batch 110/145, Loss: 0.1662
Epoch 7/10, Batch 120/145, Loss: 0.1974
Epoch 7/10, Batch 130/145, Loss: 0.2421
Epoch 7/10, Batch 140/145, Loss: 0.2217
Epoch 7/10, Train Loss: 0.2106, Valid Loss: 0.2324
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1460
Epoch 8/10, Batch 20/145, Loss: 0.2438
Epoch 8/10, Batch 30/145, Loss: 0.2926
Epoch 8/10, Batch 40/145, Loss: 0.1165
Epoch 8/10, Batch 50/145, Loss: 0.1225
Epoch 8/10, Batch 60/145, Loss: 0.2178
Epoch 8/10, Batch 70/145, Loss: 0.1819
Epoch 8/10, Batch 80/145, Loss: 0.2258
Epoch 8/10, Batch 90/145, Loss: 0.4089
Epoch 8/10, Batch 100/145, Loss: 0.2258
Epoch 8/10, Batch 110/145, Loss: 0.1986
Epoch 8/10, Batch 120/145, Loss: 0.1558
Epoch 8/10, Batch 130/145, Loss: 0.0896
Epoch 8/10, Batch 140/145, Loss: 0.2079
Epoch 8/10, Train Loss: 0.2042, Valid Loss: 0.2301
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.4203
Epoch 9/10, Batch 20/145, Loss: 0.1711
Epoch 9/10, Batch 30/145, Loss: 0.1692
Epoch 9/10, Batch 40/145, Loss: 0.1791
Epoch 9/10, Batch 50/145, Loss: 0.2979
Epoch 9/10, Batch 60/145, Loss: 0.1195
Epoch 9/10, Batch 70/145, Loss: 0.3032
Epoch 9/10, Batch 80/145, Loss: 0.1984
Epoch 9/10, Batch 90/145, Loss: 0.1569
Epoch 9/10, Batch 100/145, Loss: 0.1131
Epoch 9/10, Batch 110/145, Loss: 0.1198
Epoch 9/10, Batch 120/145, Loss: 0.1087
Epoch 9/10, Batch 130/145, Loss: 0.3181
Epoch 9/10, Batch 140/145, Loss: 0.1993
Epoch 9/10, Train Loss: 0.1978, Valid Loss: 0.2346
Epoch 10/10, Batch 10/145, Loss: 0.2155
Epoch 10/10, Batch 20/145, Loss: 0.1593
Epoch 10/10, Batch 30/145, Loss: 0.2887
Epoch 10/10, Batch 40/145, Loss: 0.1210
Epoch 10/10, Batch 50/145, Loss: 0.1678
Epoch 10/10, Batch 60/145, Loss: 0.1482
Epoch 10/10, Batch 70/145, Loss: 0.1806
Epoch 10/10, Batch 80/145, Loss: 0.2809
Epoch 10/10, Batch 90/145, Loss: 0.1787
Epoch 10/10, Batch 100/145, Loss: 0.1747
Epoch 10/10, Batch 110/145, Loss: 0.1816
Epoch 10/10, Batch 120/145, Loss: 0.2707
Epoch 10/10, Batch 130/145, Loss: 0.1218
Epoch 10/10, Batch 140/145, Loss: 0.1851
Epoch 10/10, Train Loss: 0.1866, Valid Loss: 0.2358
Accuracy: 0.9194
Precision: 0.9177
Recall: 0.9194
F1-score: 0.9182
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3901
Epoch 1/10, Batch 20/145, Loss: 0.9932
Epoch 1/10, Batch 30/145, Loss: 0.9056
Epoch 1/10, Batch 40/145, Loss: 0.7940
Epoch 1/10, Batch 50/145, Loss: 0.7012
Epoch 1/10, Batch 60/145, Loss: 0.6048
Epoch 1/10, Batch 70/145, Loss: 0.5755
Epoch 1/10, Batch 80/145, Loss: 0.5283
Epoch 1/10, Batch 90/145, Loss: 0.4585
Epoch 1/10, Batch 100/145, Loss: 0.5394
Epoch 1/10, Batch 110/145, Loss: 0.4830
Epoch 1/10, Batch 120/145, Loss: 0.5588
Epoch 1/10, Batch 130/145, Loss: 0.5015
Epoch 1/10, Batch 140/145, Loss: 0.3100
Epoch 1/10, Train Loss: 0.6752, Valid Loss: 0.3870
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4160
Epoch 2/10, Batch 20/145, Loss: 0.2568
Epoch 2/10, Batch 30/145, Loss: 0.3470
Epoch 2/10, Batch 40/145, Loss: 0.4296
Epoch 2/10, Batch 50/145, Loss: 0.3274
Epoch 2/10, Batch 60/145, Loss: 0.3030
Epoch 2/10, Batch 70/145, Loss: 0.3185
Epoch 2/10, Batch 80/145, Loss: 0.4079
Epoch 2/10, Batch 90/145, Loss: 0.2122
Epoch 2/10, Batch 100/145, Loss: 0.3424
Epoch 2/10, Batch 110/145, Loss: 0.2693
Epoch 2/10, Batch 120/145, Loss: 0.2670
Epoch 2/10, Batch 130/145, Loss: 0.1597
Epoch 2/10, Batch 140/145, Loss: 0.1431
Epoch 2/10, Train Loss: 0.3503, Valid Loss: 0.3036
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2645
Epoch 3/10, Batch 20/145, Loss: 0.2417
Epoch 3/10, Batch 30/145, Loss: 0.2240
Epoch 3/10, Batch 40/145, Loss: 0.2230
Epoch 3/10, Batch 50/145, Loss: 0.3053
Epoch 3/10, Batch 60/145, Loss: 0.5246
Epoch 3/10, Batch 70/145, Loss: 0.2887
Epoch 3/10, Batch 80/145, Loss: 0.1647
Epoch 3/10, Batch 90/145, Loss: 0.3118
Epoch 3/10, Batch 100/145, Loss: 0.1904
Epoch 3/10, Batch 110/145, Loss: 0.1338
Epoch 3/10, Batch 120/145, Loss: 0.3570
Epoch 3/10, Batch 130/145, Loss: 0.3305
Epoch 3/10, Batch 140/145, Loss: 0.3230
Epoch 3/10, Train Loss: 0.2921, Valid Loss: 0.2775
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4189
Epoch 4/10, Batch 20/145, Loss: 0.2995
Epoch 4/10, Batch 30/145, Loss: 0.2496
Epoch 4/10, Batch 40/145, Loss: 0.1161
Epoch 4/10, Batch 50/145, Loss: 0.2268
Epoch 4/10, Batch 60/145, Loss: 0.2042
Epoch 4/10, Batch 70/145, Loss: 0.1746
Epoch 4/10, Batch 80/145, Loss: 0.2371
Epoch 4/10, Batch 90/145, Loss: 0.1788
Epoch 4/10, Batch 100/145, Loss: 0.3029
Epoch 4/10, Batch 110/145, Loss: 0.2268
Epoch 4/10, Batch 120/145, Loss: 0.1617
Epoch 4/10, Batch 130/145, Loss: 0.1855
Epoch 4/10, Batch 140/145, Loss: 0.2445
Epoch 4/10, Train Loss: 0.2532, Valid Loss: 0.2580
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1899
Epoch 5/10, Batch 20/145, Loss: 0.1815
Epoch 5/10, Batch 30/145, Loss: 0.1518
Epoch 5/10, Batch 40/145, Loss: 0.2063
Epoch 5/10, Batch 50/145, Loss: 0.2052
Epoch 5/10, Batch 60/145, Loss: 0.4164
Epoch 5/10, Batch 70/145, Loss: 0.1713
Epoch 5/10, Batch 80/145, Loss: 0.2175
Epoch 5/10, Batch 90/145, Loss: 0.2770
Epoch 5/10, Batch 100/145, Loss: 0.1682
Epoch 5/10, Batch 110/145, Loss: 0.1658
Epoch 5/10, Batch 120/145, Loss: 0.2944
Epoch 5/10, Batch 130/145, Loss: 0.1845
Epoch 5/10, Batch 140/145, Loss: 0.2085
Epoch 5/10, Train Loss: 0.2439, Valid Loss: 0.2461
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3059
Epoch 6/10, Batch 20/145, Loss: 0.2689
Epoch 6/10, Batch 30/145, Loss: 0.3578
Epoch 6/10, Batch 40/145, Loss: 0.1354
Epoch 6/10, Batch 50/145, Loss: 0.2602
Epoch 6/10, Batch 60/145, Loss: 0.2462
Epoch 6/10, Batch 70/145, Loss: 0.1402
Epoch 6/10, Batch 80/145, Loss: 0.2504
Epoch 6/10, Batch 90/145, Loss: 0.2594
Epoch 6/10, Batch 100/145, Loss: 0.2683
Epoch 6/10, Batch 110/145, Loss: 0.2868
Epoch 6/10, Batch 120/145, Loss: 0.1610
Epoch 6/10, Batch 130/145, Loss: 0.3907
Epoch 6/10, Batch 140/145, Loss: 0.2346
Epoch 6/10, Train Loss: 0.2261, Valid Loss: 0.2395
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1682
Epoch 7/10, Batch 20/145, Loss: 0.3197
Epoch 7/10, Batch 30/145, Loss: 0.1186
Epoch 7/10, Batch 40/145, Loss: 0.2570
Epoch 7/10, Batch 50/145, Loss: 0.1458
Epoch 7/10, Batch 60/145, Loss: 0.1847
Epoch 7/10, Batch 70/145, Loss: 0.2022
Epoch 7/10, Batch 80/145, Loss: 0.4158
Epoch 7/10, Batch 90/145, Loss: 0.1851
Epoch 7/10, Batch 100/145, Loss: 0.3315
Epoch 7/10, Batch 110/145, Loss: 0.1420
Epoch 7/10, Batch 120/145, Loss: 0.2315
Epoch 7/10, Batch 130/145, Loss: 0.1115
Epoch 7/10, Batch 140/145, Loss: 0.4149
Epoch 7/10, Train Loss: 0.2060, Valid Loss: 0.2344
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1271
Epoch 8/10, Batch 20/145, Loss: 0.2858
Epoch 8/10, Batch 30/145, Loss: 0.2282
Epoch 8/10, Batch 40/145, Loss: 0.2099
Epoch 8/10, Batch 50/145, Loss: 0.2483
Epoch 8/10, Batch 60/145, Loss: 0.1556
Epoch 8/10, Batch 70/145, Loss: 0.2096
Epoch 8/10, Batch 80/145, Loss: 0.1532
Epoch 8/10, Batch 90/145, Loss: 0.3367
Epoch 8/10, Batch 100/145, Loss: 0.0870
Epoch 8/10, Batch 110/145, Loss: 0.2273
Epoch 8/10, Batch 120/145, Loss: 0.1562
Epoch 8/10, Batch 130/145, Loss: 0.2777
Epoch 8/10, Batch 140/145, Loss: 0.1360
Epoch 8/10, Train Loss: 0.2004, Valid Loss: 0.2359
Epoch 9/10, Batch 10/145, Loss: 0.2631
Epoch 9/10, Batch 20/145, Loss: 0.1675
Epoch 9/10, Batch 30/145, Loss: 0.1474
Epoch 9/10, Batch 40/145, Loss: 0.1047
Epoch 9/10, Batch 50/145, Loss: 0.3417
Epoch 9/10, Batch 60/145, Loss: 0.1594
Epoch 9/10, Batch 70/145, Loss: 0.1152
Epoch 9/10, Batch 80/145, Loss: 0.1143
Epoch 9/10, Batch 90/145, Loss: 0.1956
Epoch 9/10, Batch 100/145, Loss: 0.1506
Epoch 9/10, Batch 110/145, Loss: 0.2975
Epoch 9/10, Batch 120/145, Loss: 0.0602
Epoch 9/10, Batch 130/145, Loss: 0.2054
Epoch 9/10, Batch 140/145, Loss: 0.1985
Epoch 9/10, Train Loss: 0.1972, Valid Loss: 0.2284
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1055
Epoch 10/10, Batch 20/145, Loss: 0.0736
Epoch 10/10, Batch 30/145, Loss: 0.1453
Epoch 10/10, Batch 40/145, Loss: 0.2171
Epoch 10/10, Batch 50/145, Loss: 0.2384
Epoch 10/10, Batch 60/145, Loss: 0.1161
Epoch 10/10, Batch 70/145, Loss: 0.3130
Epoch 10/10, Batch 80/145, Loss: 0.2131
Epoch 10/10, Batch 90/145, Loss: 0.1192
Epoch 10/10, Batch 100/145, Loss: 0.1818
Epoch 10/10, Batch 110/145, Loss: 0.1303
Epoch 10/10, Batch 120/145, Loss: 0.2146
Epoch 10/10, Batch 130/145, Loss: 0.2784
Epoch 10/10, Batch 140/145, Loss: 0.1316
Epoch 10/10, Train Loss: 0.1890, Valid Loss: 0.2259
Model saved!
Accuracy: 0.9147
Precision: 0.9120
Recall: 0.9147
F1-score: 0.9121
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4000
Epoch 1/10, Batch 20/145, Loss: 0.9909
Epoch 1/10, Batch 30/145, Loss: 0.8819
Epoch 1/10, Batch 40/145, Loss: 0.9279
Epoch 1/10, Batch 50/145, Loss: 0.7551
Epoch 1/10, Batch 60/145, Loss: 0.5583
Epoch 1/10, Batch 70/145, Loss: 0.4778
Epoch 1/10, Batch 80/145, Loss: 0.7040
Epoch 1/10, Batch 90/145, Loss: 0.3330
Epoch 1/10, Batch 100/145, Loss: 0.4881
Epoch 1/10, Batch 110/145, Loss: 0.4600
Epoch 1/10, Batch 120/145, Loss: 0.6364
Epoch 1/10, Batch 130/145, Loss: 0.5888
Epoch 1/10, Batch 140/145, Loss: 0.4037
Epoch 1/10, Train Loss: 0.6859, Valid Loss: 0.3984
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3972
Epoch 2/10, Batch 20/145, Loss: 0.3803
Epoch 2/10, Batch 30/145, Loss: 0.3303
Epoch 2/10, Batch 40/145, Loss: 0.3372
Epoch 2/10, Batch 50/145, Loss: 0.3753
Epoch 2/10, Batch 60/145, Loss: 0.2543
Epoch 2/10, Batch 70/145, Loss: 0.3481
Epoch 2/10, Batch 80/145, Loss: 0.2094
Epoch 2/10, Batch 90/145, Loss: 0.4179
Epoch 2/10, Batch 100/145, Loss: 0.3785
Epoch 2/10, Batch 110/145, Loss: 0.4469
Epoch 2/10, Batch 120/145, Loss: 0.4677
Epoch 2/10, Batch 130/145, Loss: 0.3936
Epoch 2/10, Batch 140/145, Loss: 0.3843
Epoch 2/10, Train Loss: 0.3561, Valid Loss: 0.3087
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1216
Epoch 3/10, Batch 20/145, Loss: 0.2317
Epoch 3/10, Batch 30/145, Loss: 0.4671
Epoch 3/10, Batch 40/145, Loss: 0.2017
Epoch 3/10, Batch 50/145, Loss: 0.2277
Epoch 3/10, Batch 60/145, Loss: 0.3559
Epoch 3/10, Batch 70/145, Loss: 0.3994
Epoch 3/10, Batch 80/145, Loss: 0.1569
Epoch 3/10, Batch 90/145, Loss: 0.3814
Epoch 3/10, Batch 100/145, Loss: 0.3479
Epoch 3/10, Batch 110/145, Loss: 0.1526
Epoch 3/10, Batch 120/145, Loss: 0.1956
Epoch 3/10, Batch 130/145, Loss: 0.4506
Epoch 3/10, Batch 140/145, Loss: 0.2180
Epoch 3/10, Train Loss: 0.2942, Valid Loss: 0.2810
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1833
Epoch 4/10, Batch 20/145, Loss: 0.2295
Epoch 4/10, Batch 30/145, Loss: 0.2227
Epoch 4/10, Batch 40/145, Loss: 0.2348
Epoch 4/10, Batch 50/145, Loss: 0.1460
Epoch 4/10, Batch 60/145, Loss: 0.2167
Epoch 4/10, Batch 70/145, Loss: 0.2426
Epoch 4/10, Batch 80/145, Loss: 0.1366
Epoch 4/10, Batch 90/145, Loss: 0.1980
Epoch 4/10, Batch 100/145, Loss: 0.3860
Epoch 4/10, Batch 110/145, Loss: 0.1422
Epoch 4/10, Batch 120/145, Loss: 0.3179
Epoch 4/10, Batch 130/145, Loss: 0.1522
Epoch 4/10, Batch 140/145, Loss: 0.2797
Epoch 4/10, Train Loss: 0.2565, Valid Loss: 0.2744
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1933
Epoch 5/10, Batch 20/145, Loss: 0.1124
Epoch 5/10, Batch 30/145, Loss: 0.2231
Epoch 5/10, Batch 40/145, Loss: 0.1678
Epoch 5/10, Batch 50/145, Loss: 0.2184
Epoch 5/10, Batch 60/145, Loss: 0.2254
Epoch 5/10, Batch 70/145, Loss: 0.3710
Epoch 5/10, Batch 80/145, Loss: 0.2396
Epoch 5/10, Batch 90/145, Loss: 0.2990
Epoch 5/10, Batch 100/145, Loss: 0.1327
Epoch 5/10, Batch 110/145, Loss: 0.1443
Epoch 5/10, Batch 120/145, Loss: 0.2463
Epoch 5/10, Batch 130/145, Loss: 0.2873
Epoch 5/10, Batch 140/145, Loss: 0.1213
Epoch 5/10, Train Loss: 0.2452, Valid Loss: 0.2676
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2668
Epoch 6/10, Batch 20/145, Loss: 0.4706
Epoch 6/10, Batch 30/145, Loss: 0.3671
Epoch 6/10, Batch 40/145, Loss: 0.1690
Epoch 6/10, Batch 50/145, Loss: 0.3248
Epoch 6/10, Batch 60/145, Loss: 0.2542
Epoch 6/10, Batch 70/145, Loss: 0.1231
Epoch 6/10, Batch 80/145, Loss: 0.2986
Epoch 6/10, Batch 90/145, Loss: 0.3949
Epoch 6/10, Batch 100/145, Loss: 0.2433
Epoch 6/10, Batch 110/145, Loss: 0.1534
Epoch 6/10, Batch 120/145, Loss: 0.3171
Epoch 6/10, Batch 130/145, Loss: 0.3517
Epoch 6/10, Batch 140/145, Loss: 0.1718
Epoch 6/10, Train Loss: 0.2268, Valid Loss: 0.2509
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3301
Epoch 7/10, Batch 20/145, Loss: 0.3062
Epoch 7/10, Batch 30/145, Loss: 0.2383
Epoch 7/10, Batch 40/145, Loss: 0.3955
Epoch 7/10, Batch 50/145, Loss: 0.2481
Epoch 7/10, Batch 60/145, Loss: 0.0930
Epoch 7/10, Batch 70/145, Loss: 0.2973
Epoch 7/10, Batch 80/145, Loss: 0.2842
Epoch 7/10, Batch 90/145, Loss: 0.2942
Epoch 7/10, Batch 100/145, Loss: 0.2305
Epoch 7/10, Batch 110/145, Loss: 0.1532
Epoch 7/10, Batch 120/145, Loss: 0.3299
Epoch 7/10, Batch 130/145, Loss: 0.1020
Epoch 7/10, Batch 140/145, Loss: 0.1496
Epoch 7/10, Train Loss: 0.2105, Valid Loss: 0.2512
Epoch 8/10, Batch 10/145, Loss: 0.2556
Epoch 8/10, Batch 20/145, Loss: 0.1635
Epoch 8/10, Batch 30/145, Loss: 0.1992
Epoch 8/10, Batch 40/145, Loss: 0.1616
Epoch 8/10, Batch 50/145, Loss: 0.1237
Epoch 8/10, Batch 60/145, Loss: 0.2692
Epoch 8/10, Batch 70/145, Loss: 0.1317
Epoch 8/10, Batch 80/145, Loss: 0.1556
Epoch 8/10, Batch 90/145, Loss: 0.3486
Epoch 8/10, Batch 100/145, Loss: 0.2334
Epoch 8/10, Batch 110/145, Loss: 0.1723
Epoch 8/10, Batch 120/145, Loss: 0.2021
Epoch 8/10, Batch 130/145, Loss: 0.1771
Epoch 8/10, Batch 140/145, Loss: 0.2023
Epoch 8/10, Train Loss: 0.2062, Valid Loss: 0.2469
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3400
Epoch 9/10, Batch 20/145, Loss: 0.1691
Epoch 9/10, Batch 30/145, Loss: 0.2153
Epoch 9/10, Batch 40/145, Loss: 0.3113
Epoch 9/10, Batch 50/145, Loss: 0.1281
Epoch 9/10, Batch 60/145, Loss: 0.2258
Epoch 9/10, Batch 70/145, Loss: 0.1962
Epoch 9/10, Batch 80/145, Loss: 0.0951
Epoch 9/10, Batch 90/145, Loss: 0.3545
Epoch 9/10, Batch 100/145, Loss: 0.1766
Epoch 9/10, Batch 110/145, Loss: 0.3077
Epoch 9/10, Batch 120/145, Loss: 0.1538
Epoch 9/10, Batch 130/145, Loss: 0.2350
Epoch 9/10, Batch 140/145, Loss: 0.1770
Epoch 9/10, Train Loss: 0.1995, Valid Loss: 0.2447
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1212
Epoch 10/10, Batch 20/145, Loss: 0.1696
Epoch 10/10, Batch 30/145, Loss: 0.0939
Epoch 10/10, Batch 40/145, Loss: 0.1621
Epoch 10/10, Batch 50/145, Loss: 0.1773
Epoch 10/10, Batch 60/145, Loss: 0.1134
Epoch 10/10, Batch 70/145, Loss: 0.3084
Epoch 10/10, Batch 80/145, Loss: 0.1343
Epoch 10/10, Batch 90/145, Loss: 0.1450
Epoch 10/10, Batch 100/145, Loss: 0.2107
Epoch 10/10, Batch 110/145, Loss: 0.2463
Epoch 10/10, Batch 120/145, Loss: 0.1609
Epoch 10/10, Batch 130/145, Loss: 0.2043
Epoch 10/10, Batch 140/145, Loss: 0.2604
Epoch 10/10, Train Loss: 0.1931, Valid Loss: 0.2398
Model saved!
Accuracy: 0.9147
Precision: 0.9127
Recall: 0.9147
F1-score: 0.9117
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3225
Epoch 1/10, Batch 20/145, Loss: 0.8879
Epoch 1/10, Batch 30/145, Loss: 0.9221
Epoch 1/10, Batch 40/145, Loss: 0.8319
Epoch 1/10, Batch 50/145, Loss: 0.6465
Epoch 1/10, Batch 60/145, Loss: 0.7184
Epoch 1/10, Batch 70/145, Loss: 0.5443
Epoch 1/10, Batch 80/145, Loss: 0.6318
Epoch 1/10, Batch 90/145, Loss: 0.5304
Epoch 1/10, Batch 100/145, Loss: 0.5149
Epoch 1/10, Batch 110/145, Loss: 0.3209
Epoch 1/10, Batch 120/145, Loss: 0.4949
Epoch 1/10, Batch 130/145, Loss: 0.6237
Epoch 1/10, Batch 140/145, Loss: 0.3165
Epoch 1/10, Train Loss: 0.6762, Valid Loss: 0.3754
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3916
Epoch 2/10, Batch 20/145, Loss: 0.3850
Epoch 2/10, Batch 30/145, Loss: 0.1989
Epoch 2/10, Batch 40/145, Loss: 0.3590
Epoch 2/10, Batch 50/145, Loss: 0.2617
Epoch 2/10, Batch 60/145, Loss: 0.5382
Epoch 2/10, Batch 70/145, Loss: 0.2654
Epoch 2/10, Batch 80/145, Loss: 0.3616
Epoch 2/10, Batch 90/145, Loss: 0.2675
Epoch 2/10, Batch 100/145, Loss: 0.2398
Epoch 2/10, Batch 110/145, Loss: 0.3183
Epoch 2/10, Batch 120/145, Loss: 0.2207
Epoch 2/10, Batch 130/145, Loss: 0.3715
Epoch 2/10, Batch 140/145, Loss: 0.3779
Epoch 2/10, Train Loss: 0.3511, Valid Loss: 0.2890
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2584
Epoch 3/10, Batch 20/145, Loss: 0.1879
Epoch 3/10, Batch 30/145, Loss: 0.2994
Epoch 3/10, Batch 40/145, Loss: 0.1981
Epoch 3/10, Batch 50/145, Loss: 0.1492
Epoch 3/10, Batch 60/145, Loss: 0.2225
Epoch 3/10, Batch 70/145, Loss: 0.3305
Epoch 3/10, Batch 80/145, Loss: 0.2888
Epoch 3/10, Batch 90/145, Loss: 0.3084
Epoch 3/10, Batch 100/145, Loss: 0.1889
Epoch 3/10, Batch 110/145, Loss: 0.3429
Epoch 3/10, Batch 120/145, Loss: 0.1665
Epoch 3/10, Batch 130/145, Loss: 0.4820
Epoch 3/10, Batch 140/145, Loss: 0.2995
Epoch 3/10, Train Loss: 0.2939, Valid Loss: 0.2579
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4096
Epoch 4/10, Batch 20/145, Loss: 0.3203
Epoch 4/10, Batch 30/145, Loss: 0.1400
Epoch 4/10, Batch 40/145, Loss: 0.2146
Epoch 4/10, Batch 50/145, Loss: 0.1167
Epoch 4/10, Batch 60/145, Loss: 0.2099
Epoch 4/10, Batch 70/145, Loss: 0.1465
Epoch 4/10, Batch 80/145, Loss: 0.1648
Epoch 4/10, Batch 90/145, Loss: 0.3043
Epoch 4/10, Batch 100/145, Loss: 0.4614
Epoch 4/10, Batch 110/145, Loss: 0.1562
Epoch 4/10, Batch 120/145, Loss: 0.1435
Epoch 4/10, Batch 130/145, Loss: 0.2301
Epoch 4/10, Batch 140/145, Loss: 0.1393
Epoch 4/10, Train Loss: 0.2549, Valid Loss: 0.2523
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2382
Epoch 5/10, Batch 20/145, Loss: 0.1048
Epoch 5/10, Batch 30/145, Loss: 0.2502
Epoch 5/10, Batch 40/145, Loss: 0.1332
Epoch 5/10, Batch 50/145, Loss: 0.2466
Epoch 5/10, Batch 60/145, Loss: 0.1377
Epoch 5/10, Batch 70/145, Loss: 0.1377
Epoch 5/10, Batch 80/145, Loss: 0.2563
Epoch 5/10, Batch 90/145, Loss: 0.2659
Epoch 5/10, Batch 100/145, Loss: 0.2596
Epoch 5/10, Batch 110/145, Loss: 0.2416
Epoch 5/10, Batch 120/145, Loss: 0.3167
Epoch 5/10, Batch 130/145, Loss: 0.2588
Epoch 5/10, Batch 140/145, Loss: 0.2149
Epoch 5/10, Train Loss: 0.2346, Valid Loss: 0.2364
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2854
Epoch 6/10, Batch 20/145, Loss: 0.2568
Epoch 6/10, Batch 30/145, Loss: 0.2183
Epoch 6/10, Batch 40/145, Loss: 0.1682
Epoch 6/10, Batch 50/145, Loss: 0.3799
Epoch 6/10, Batch 60/145, Loss: 0.3341
Epoch 6/10, Batch 70/145, Loss: 0.1507
Epoch 6/10, Batch 80/145, Loss: 0.1494
Epoch 6/10, Batch 90/145, Loss: 0.2574
Epoch 6/10, Batch 100/145, Loss: 0.2815
Epoch 6/10, Batch 110/145, Loss: 0.1104
Epoch 6/10, Batch 120/145, Loss: 0.2236
Epoch 6/10, Batch 130/145, Loss: 0.1671
Epoch 6/10, Batch 140/145, Loss: 0.2277
Epoch 6/10, Train Loss: 0.2256, Valid Loss: 0.2295
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2175
Epoch 7/10, Batch 20/145, Loss: 0.2165
Epoch 7/10, Batch 30/145, Loss: 0.2663
Epoch 7/10, Batch 40/145, Loss: 0.1913
Epoch 7/10, Batch 50/145, Loss: 0.2224
Epoch 7/10, Batch 60/145, Loss: 0.1722
Epoch 7/10, Batch 70/145, Loss: 0.2405
Epoch 7/10, Batch 80/145, Loss: 0.3688
Epoch 7/10, Batch 90/145, Loss: 0.1946
Epoch 7/10, Batch 100/145, Loss: 0.1184
Epoch 7/10, Batch 110/145, Loss: 0.3207
Epoch 7/10, Batch 120/145, Loss: 0.2169
Epoch 7/10, Batch 130/145, Loss: 0.1334
Epoch 7/10, Batch 140/145, Loss: 0.2336
Epoch 7/10, Train Loss: 0.2067, Valid Loss: 0.2264
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1808
Epoch 8/10, Batch 20/145, Loss: 0.3063
Epoch 8/10, Batch 30/145, Loss: 0.2330
Epoch 8/10, Batch 40/145, Loss: 0.1513
Epoch 8/10, Batch 50/145, Loss: 0.2486
Epoch 8/10, Batch 60/145, Loss: 0.2095
Epoch 8/10, Batch 70/145, Loss: 0.2541
Epoch 8/10, Batch 80/145, Loss: 0.2562
Epoch 8/10, Batch 90/145, Loss: 0.2570
Epoch 8/10, Batch 100/145, Loss: 0.1430
Epoch 8/10, Batch 110/145, Loss: 0.2234
Epoch 8/10, Batch 120/145, Loss: 0.2492
Epoch 8/10, Batch 130/145, Loss: 0.1079
Epoch 8/10, Batch 140/145, Loss: 0.1829
Epoch 8/10, Train Loss: 0.2009, Valid Loss: 0.2189
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2381
Epoch 9/10, Batch 20/145, Loss: 0.1035
Epoch 9/10, Batch 30/145, Loss: 0.1533
Epoch 9/10, Batch 40/145, Loss: 0.1430
Epoch 9/10, Batch 50/145, Loss: 0.1182
Epoch 9/10, Batch 60/145, Loss: 0.2784
Epoch 9/10, Batch 70/145, Loss: 0.2352
Epoch 9/10, Batch 80/145, Loss: 0.1126
Epoch 9/10, Batch 90/145, Loss: 0.2366
Epoch 9/10, Batch 100/145, Loss: 0.1664
Epoch 9/10, Batch 110/145, Loss: 0.2738
Epoch 9/10, Batch 120/145, Loss: 0.1692
Epoch 9/10, Batch 130/145, Loss: 0.1965
Epoch 9/10, Batch 140/145, Loss: 0.2100
Epoch 9/10, Train Loss: 0.1943, Valid Loss: 0.2187
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0733
Epoch 10/10, Batch 20/145, Loss: 0.1114
Epoch 10/10, Batch 30/145, Loss: 0.0699
Epoch 10/10, Batch 40/145, Loss: 0.1629
Epoch 10/10, Batch 50/145, Loss: 0.3362
Epoch 10/10, Batch 60/145, Loss: 0.1173
Epoch 10/10, Batch 70/145, Loss: 0.2711
Epoch 10/10, Batch 80/145, Loss: 0.1325
Epoch 10/10, Batch 90/145, Loss: 0.1392
Epoch 10/10, Batch 100/145, Loss: 0.0951
Epoch 10/10, Batch 110/145, Loss: 0.1714
Epoch 10/10, Batch 120/145, Loss: 0.2514
Epoch 10/10, Batch 130/145, Loss: 0.1058
Epoch 10/10, Batch 140/145, Loss: 0.2018
Epoch 10/10, Train Loss: 0.1882, Valid Loss: 0.2195
Accuracy: 0.9159
Precision: 0.9138
Recall: 0.9159
F1-score: 0.9145
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3660
Epoch 1/10, Batch 20/145, Loss: 0.9415
Epoch 1/10, Batch 30/145, Loss: 0.8874
Epoch 1/10, Batch 40/145, Loss: 0.7537
Epoch 1/10, Batch 50/145, Loss: 0.6808
Epoch 1/10, Batch 60/145, Loss: 0.7109
Epoch 1/10, Batch 70/145, Loss: 0.5198
Epoch 1/10, Batch 80/145, Loss: 0.6819
Epoch 1/10, Batch 90/145, Loss: 0.4220
Epoch 1/10, Batch 100/145, Loss: 0.3843
Epoch 1/10, Batch 110/145, Loss: 0.4537
Epoch 1/10, Batch 120/145, Loss: 0.4440
Epoch 1/10, Batch 130/145, Loss: 0.5159
Epoch 1/10, Batch 140/145, Loss: 0.4548
Epoch 1/10, Train Loss: 0.6769, Valid Loss: 0.3730
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3180
Epoch 2/10, Batch 20/145, Loss: 0.4221
Epoch 2/10, Batch 30/145, Loss: 0.2543
Epoch 2/10, Batch 40/145, Loss: 0.3924
Epoch 2/10, Batch 50/145, Loss: 0.2192
Epoch 2/10, Batch 60/145, Loss: 0.3273
Epoch 2/10, Batch 70/145, Loss: 0.3717
Epoch 2/10, Batch 80/145, Loss: 0.3478
Epoch 2/10, Batch 90/145, Loss: 0.2582
Epoch 2/10, Batch 100/145, Loss: 0.3579
Epoch 2/10, Batch 110/145, Loss: 0.3165
Epoch 2/10, Batch 120/145, Loss: 0.3116
Epoch 2/10, Batch 130/145, Loss: 0.2434
Epoch 2/10, Batch 140/145, Loss: 0.3555
Epoch 2/10, Train Loss: 0.3465, Valid Loss: 0.2955
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2426
Epoch 3/10, Batch 20/145, Loss: 0.3512
Epoch 3/10, Batch 30/145, Loss: 0.3658
Epoch 3/10, Batch 40/145, Loss: 0.2496
Epoch 3/10, Batch 50/145, Loss: 0.1756
Epoch 3/10, Batch 60/145, Loss: 0.3185
Epoch 3/10, Batch 70/145, Loss: 0.4859
Epoch 3/10, Batch 80/145, Loss: 0.1120
Epoch 3/10, Batch 90/145, Loss: 0.2753
Epoch 3/10, Batch 100/145, Loss: 0.1759
Epoch 3/10, Batch 110/145, Loss: 0.1993
Epoch 3/10, Batch 120/145, Loss: 0.4907
Epoch 3/10, Batch 130/145, Loss: 0.2484
Epoch 3/10, Batch 140/145, Loss: 0.3016
Epoch 3/10, Train Loss: 0.2866, Valid Loss: 0.2654
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3253
Epoch 4/10, Batch 20/145, Loss: 0.3589
Epoch 4/10, Batch 30/145, Loss: 0.2535
Epoch 4/10, Batch 40/145, Loss: 0.1282
Epoch 4/10, Batch 50/145, Loss: 0.2650
Epoch 4/10, Batch 60/145, Loss: 0.3269
Epoch 4/10, Batch 70/145, Loss: 0.3085
Epoch 4/10, Batch 80/145, Loss: 0.1382
Epoch 4/10, Batch 90/145, Loss: 0.2389
Epoch 4/10, Batch 100/145, Loss: 0.4321
Epoch 4/10, Batch 110/145, Loss: 0.1607
Epoch 4/10, Batch 120/145, Loss: 0.2282
Epoch 4/10, Batch 130/145, Loss: 0.3158
Epoch 4/10, Batch 140/145, Loss: 0.0898
Epoch 4/10, Train Loss: 0.2604, Valid Loss: 0.2481
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1436
Epoch 5/10, Batch 20/145, Loss: 0.1689
Epoch 5/10, Batch 30/145, Loss: 0.2484
Epoch 5/10, Batch 40/145, Loss: 0.1769
Epoch 5/10, Batch 50/145, Loss: 0.1297
Epoch 5/10, Batch 60/145, Loss: 0.2041
Epoch 5/10, Batch 70/145, Loss: 0.1854
Epoch 5/10, Batch 80/145, Loss: 0.1380
Epoch 5/10, Batch 90/145, Loss: 0.5333
Epoch 5/10, Batch 100/145, Loss: 0.1211
Epoch 5/10, Batch 110/145, Loss: 0.1600
Epoch 5/10, Batch 120/145, Loss: 0.2709
Epoch 5/10, Batch 130/145, Loss: 0.2097
Epoch 5/10, Batch 140/145, Loss: 0.2591
Epoch 5/10, Train Loss: 0.2425, Valid Loss: 0.2515
Epoch 6/10, Batch 10/145, Loss: 0.1788
Epoch 6/10, Batch 20/145, Loss: 0.2287
Epoch 6/10, Batch 30/145, Loss: 0.4227
Epoch 6/10, Batch 40/145, Loss: 0.1841
Epoch 6/10, Batch 50/145, Loss: 0.3174
Epoch 6/10, Batch 60/145, Loss: 0.3001
Epoch 6/10, Batch 70/145, Loss: 0.2369
Epoch 6/10, Batch 80/145, Loss: 0.1763
Epoch 6/10, Batch 90/145, Loss: 0.1386
Epoch 6/10, Batch 100/145, Loss: 0.3630
Epoch 6/10, Batch 110/145, Loss: 0.2200
Epoch 6/10, Batch 120/145, Loss: 0.2377
Epoch 6/10, Batch 130/145, Loss: 0.1821
Epoch 6/10, Batch 140/145, Loss: 0.1097
Epoch 6/10, Train Loss: 0.2328, Valid Loss: 0.2332
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3617
Epoch 7/10, Batch 20/145, Loss: 0.3495
Epoch 7/10, Batch 30/145, Loss: 0.2084
Epoch 7/10, Batch 40/145, Loss: 0.2805
Epoch 7/10, Batch 50/145, Loss: 0.2810
Epoch 7/10, Batch 60/145, Loss: 0.1417
Epoch 7/10, Batch 70/145, Loss: 0.1156
Epoch 7/10, Batch 80/145, Loss: 0.3207
Epoch 7/10, Batch 90/145, Loss: 0.1677
Epoch 7/10, Batch 100/145, Loss: 0.1547
Epoch 7/10, Batch 110/145, Loss: 0.1081
Epoch 7/10, Batch 120/145, Loss: 0.2207
Epoch 7/10, Batch 130/145, Loss: 0.1622
Epoch 7/10, Batch 140/145, Loss: 0.1852
Epoch 7/10, Train Loss: 0.2096, Valid Loss: 0.2306
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1619
Epoch 8/10, Batch 20/145, Loss: 0.3537
Epoch 8/10, Batch 30/145, Loss: 0.3506
Epoch 8/10, Batch 40/145, Loss: 0.0808
Epoch 8/10, Batch 50/145, Loss: 0.2535
Epoch 8/10, Batch 60/145, Loss: 0.3640
Epoch 8/10, Batch 70/145, Loss: 0.2407
Epoch 8/10, Batch 80/145, Loss: 0.1208
Epoch 8/10, Batch 90/145, Loss: 0.1234
Epoch 8/10, Batch 100/145, Loss: 0.1291
Epoch 8/10, Batch 110/145, Loss: 0.1405
Epoch 8/10, Batch 120/145, Loss: 0.1722
Epoch 8/10, Batch 130/145, Loss: 0.1621
Epoch 8/10, Batch 140/145, Loss: 0.4001
Epoch 8/10, Train Loss: 0.2153, Valid Loss: 0.2242
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3775
Epoch 9/10, Batch 20/145, Loss: 0.1442
Epoch 9/10, Batch 30/145, Loss: 0.0908
Epoch 9/10, Batch 40/145, Loss: 0.2484
Epoch 9/10, Batch 50/145, Loss: 0.2278
Epoch 9/10, Batch 60/145, Loss: 0.0910
Epoch 9/10, Batch 70/145, Loss: 0.1141
Epoch 9/10, Batch 80/145, Loss: 0.0888
Epoch 9/10, Batch 90/145, Loss: 0.1643
Epoch 9/10, Batch 100/145, Loss: 0.0884
Epoch 9/10, Batch 110/145, Loss: 0.4270
Epoch 9/10, Batch 120/145, Loss: 0.2001
Epoch 9/10, Batch 130/145, Loss: 0.3837
Epoch 9/10, Batch 140/145, Loss: 0.1667
Epoch 9/10, Train Loss: 0.1999, Valid Loss: 0.2232
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1499
Epoch 10/10, Batch 20/145, Loss: 0.1142
Epoch 10/10, Batch 30/145, Loss: 0.1291
Epoch 10/10, Batch 40/145, Loss: 0.1269
Epoch 10/10, Batch 50/145, Loss: 0.1232
Epoch 10/10, Batch 60/145, Loss: 0.1639
Epoch 10/10, Batch 70/145, Loss: 0.2205
Epoch 10/10, Batch 80/145, Loss: 0.1461
Epoch 10/10, Batch 90/145, Loss: 0.3463
Epoch 10/10, Batch 100/145, Loss: 0.2047
Epoch 10/10, Batch 110/145, Loss: 0.2619
Epoch 10/10, Batch 120/145, Loss: 0.1931
Epoch 10/10, Batch 130/145, Loss: 0.2168
Epoch 10/10, Batch 140/145, Loss: 0.1156
Epoch 10/10, Train Loss: 0.1900, Valid Loss: 0.2205
Model saved!
Accuracy: 0.9194
Precision: 0.9165
Recall: 0.9194
F1-score: 0.9170
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3681
Epoch 1/10, Batch 20/145, Loss: 0.8854
Epoch 1/10, Batch 30/145, Loss: 0.9472
Epoch 1/10, Batch 40/145, Loss: 0.8027
Epoch 1/10, Batch 50/145, Loss: 0.7855
Epoch 1/10, Batch 60/145, Loss: 0.5783
Epoch 1/10, Batch 70/145, Loss: 0.5887
Epoch 1/10, Batch 80/145, Loss: 0.5481
Epoch 1/10, Batch 90/145, Loss: 0.4923
Epoch 1/10, Batch 100/145, Loss: 0.3657
Epoch 1/10, Batch 110/145, Loss: 0.5276
Epoch 1/10, Batch 120/145, Loss: 0.4385
Epoch 1/10, Batch 130/145, Loss: 0.4863
Epoch 1/10, Batch 140/145, Loss: 0.3832
Epoch 1/10, Train Loss: 0.6684, Valid Loss: 0.3805
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2768
Epoch 2/10, Batch 20/145, Loss: 0.4342
Epoch 2/10, Batch 30/145, Loss: 0.2630
Epoch 2/10, Batch 40/145, Loss: 0.4349
Epoch 2/10, Batch 50/145, Loss: 0.3189
Epoch 2/10, Batch 60/145, Loss: 0.3552
Epoch 2/10, Batch 70/145, Loss: 0.3305
Epoch 2/10, Batch 80/145, Loss: 0.3614
Epoch 2/10, Batch 90/145, Loss: 0.2933
Epoch 2/10, Batch 100/145, Loss: 0.2300
Epoch 2/10, Batch 110/145, Loss: 0.2920
Epoch 2/10, Batch 120/145, Loss: 0.3631
Epoch 2/10, Batch 130/145, Loss: 0.3586
Epoch 2/10, Batch 140/145, Loss: 0.2893
Epoch 2/10, Train Loss: 0.3421, Valid Loss: 0.3012
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2150
Epoch 3/10, Batch 20/145, Loss: 0.2338
Epoch 3/10, Batch 30/145, Loss: 0.3399
Epoch 3/10, Batch 40/145, Loss: 0.2227
Epoch 3/10, Batch 50/145, Loss: 0.1589
Epoch 3/10, Batch 60/145, Loss: 0.3777
Epoch 3/10, Batch 70/145, Loss: 0.3116
Epoch 3/10, Batch 80/145, Loss: 0.2704
Epoch 3/10, Batch 90/145, Loss: 0.2524
Epoch 3/10, Batch 100/145, Loss: 0.3903
Epoch 3/10, Batch 110/145, Loss: 0.1387
Epoch 3/10, Batch 120/145, Loss: 0.2526
Epoch 3/10, Batch 130/145, Loss: 0.3038
Epoch 3/10, Batch 140/145, Loss: 0.1408
Epoch 3/10, Train Loss: 0.2818, Valid Loss: 0.2765
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2673
Epoch 4/10, Batch 20/145, Loss: 0.3284
Epoch 4/10, Batch 30/145, Loss: 0.2496
Epoch 4/10, Batch 40/145, Loss: 0.1221
Epoch 4/10, Batch 50/145, Loss: 0.2119
Epoch 4/10, Batch 60/145, Loss: 0.2257
Epoch 4/10, Batch 70/145, Loss: 0.1472
Epoch 4/10, Batch 80/145, Loss: 0.3859
Epoch 4/10, Batch 90/145, Loss: 0.2407
Epoch 4/10, Batch 100/145, Loss: 0.3312
Epoch 4/10, Batch 110/145, Loss: 0.2138
Epoch 4/10, Batch 120/145, Loss: 0.2531
Epoch 4/10, Batch 130/145, Loss: 0.1239
Epoch 4/10, Batch 140/145, Loss: 0.1760
Epoch 4/10, Train Loss: 0.2492, Valid Loss: 0.2630
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2093
Epoch 5/10, Batch 20/145, Loss: 0.2462
Epoch 5/10, Batch 30/145, Loss: 0.2414
Epoch 5/10, Batch 40/145, Loss: 0.2331
Epoch 5/10, Batch 50/145, Loss: 0.1790
Epoch 5/10, Batch 60/145, Loss: 0.2147
Epoch 5/10, Batch 70/145, Loss: 0.1963
Epoch 5/10, Batch 80/145, Loss: 0.1681
Epoch 5/10, Batch 90/145, Loss: 0.2612
Epoch 5/10, Batch 100/145, Loss: 0.2347
Epoch 5/10, Batch 110/145, Loss: 0.1742
Epoch 5/10, Batch 120/145, Loss: 0.4665
Epoch 5/10, Batch 130/145, Loss: 0.1431
Epoch 5/10, Batch 140/145, Loss: 0.1611
Epoch 5/10, Train Loss: 0.2322, Valid Loss: 0.2516
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2339
Epoch 6/10, Batch 20/145, Loss: 0.4730
Epoch 6/10, Batch 30/145, Loss: 0.2887
Epoch 6/10, Batch 40/145, Loss: 0.1190
Epoch 6/10, Batch 50/145, Loss: 0.3263
Epoch 6/10, Batch 60/145, Loss: 0.2523
Epoch 6/10, Batch 70/145, Loss: 0.1555
Epoch 6/10, Batch 80/145, Loss: 0.2356
Epoch 6/10, Batch 90/145, Loss: 0.1461
Epoch 6/10, Batch 100/145, Loss: 0.5908
Epoch 6/10, Batch 110/145, Loss: 0.2216
Epoch 6/10, Batch 120/145, Loss: 0.2546
Epoch 6/10, Batch 130/145, Loss: 0.0739
Epoch 6/10, Batch 140/145, Loss: 0.1520
Epoch 6/10, Train Loss: 0.2142, Valid Loss: 0.2475
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2525
Epoch 7/10, Batch 20/145, Loss: 0.3865
Epoch 7/10, Batch 30/145, Loss: 0.1470
Epoch 7/10, Batch 40/145, Loss: 0.2466
Epoch 7/10, Batch 50/145, Loss: 0.1322
Epoch 7/10, Batch 60/145, Loss: 0.2589
Epoch 7/10, Batch 70/145, Loss: 0.2242
Epoch 7/10, Batch 80/145, Loss: 0.2088
Epoch 7/10, Batch 90/145, Loss: 0.1602
Epoch 7/10, Batch 100/145, Loss: 0.1065
Epoch 7/10, Batch 110/145, Loss: 0.3358
Epoch 7/10, Batch 120/145, Loss: 0.1106
Epoch 7/10, Batch 130/145, Loss: 0.1022
Epoch 7/10, Batch 140/145, Loss: 0.2903
Epoch 7/10, Train Loss: 0.2016, Valid Loss: 0.2388
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2801
Epoch 8/10, Batch 20/145, Loss: 0.2493
Epoch 8/10, Batch 30/145, Loss: 0.2726
Epoch 8/10, Batch 40/145, Loss: 0.1592
Epoch 8/10, Batch 50/145, Loss: 0.1308
Epoch 8/10, Batch 60/145, Loss: 0.2511
Epoch 8/10, Batch 70/145, Loss: 0.2253
Epoch 8/10, Batch 80/145, Loss: 0.1216
Epoch 8/10, Batch 90/145, Loss: 0.2399
Epoch 8/10, Batch 100/145, Loss: 0.1142
Epoch 8/10, Batch 110/145, Loss: 0.4333
Epoch 8/10, Batch 120/145, Loss: 0.0740
Epoch 8/10, Batch 130/145, Loss: 0.1782
Epoch 8/10, Batch 140/145, Loss: 0.2937
Epoch 8/10, Train Loss: 0.1938, Valid Loss: 0.2382
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3050
Epoch 9/10, Batch 20/145, Loss: 0.1441
Epoch 9/10, Batch 30/145, Loss: 0.1739
Epoch 9/10, Batch 40/145, Loss: 0.1739
Epoch 9/10, Batch 50/145, Loss: 0.1000
Epoch 9/10, Batch 60/145, Loss: 0.3195
Epoch 9/10, Batch 70/145, Loss: 0.1815
Epoch 9/10, Batch 80/145, Loss: 0.0847
Epoch 9/10, Batch 90/145, Loss: 0.2819
Epoch 9/10, Batch 100/145, Loss: 0.1175
Epoch 9/10, Batch 110/145, Loss: 0.2794
Epoch 9/10, Batch 120/145, Loss: 0.0447
Epoch 9/10, Batch 130/145, Loss: 0.1918
Epoch 9/10, Batch 140/145, Loss: 0.2256
Epoch 9/10, Train Loss: 0.2013, Valid Loss: 0.2364
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2337
Epoch 10/10, Batch 20/145, Loss: 0.2797
Epoch 10/10, Batch 30/145, Loss: 0.1161
Epoch 10/10, Batch 40/145, Loss: 0.2077
Epoch 10/10, Batch 50/145, Loss: 0.3226
Epoch 10/10, Batch 60/145, Loss: 0.2213
Epoch 10/10, Batch 70/145, Loss: 0.1430
Epoch 10/10, Batch 80/145, Loss: 0.2229
Epoch 10/10, Batch 90/145, Loss: 0.1579
Epoch 10/10, Batch 100/145, Loss: 0.1948
Epoch 10/10, Batch 110/145, Loss: 0.1516
Epoch 10/10, Batch 120/145, Loss: 0.1651
Epoch 10/10, Batch 130/145, Loss: 0.1085
Epoch 10/10, Batch 140/145, Loss: 0.1481
Epoch 10/10, Train Loss: 0.1834, Valid Loss: 0.2341
Model saved!
Accuracy: 0.9252
Precision: 0.9234
Recall: 0.9252
F1-score: 0.9237
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3729
Epoch 1/10, Batch 20/145, Loss: 0.8719
Epoch 1/10, Batch 30/145, Loss: 0.8850
Epoch 1/10, Batch 40/145, Loss: 0.7542
Epoch 1/10, Batch 50/145, Loss: 0.7647
Epoch 1/10, Batch 60/145, Loss: 0.5916
Epoch 1/10, Batch 70/145, Loss: 0.4224
Epoch 1/10, Batch 80/145, Loss: 0.5670
Epoch 1/10, Batch 90/145, Loss: 0.4892
Epoch 1/10, Batch 100/145, Loss: 0.5695
Epoch 1/10, Batch 110/145, Loss: 0.3953
Epoch 1/10, Batch 120/145, Loss: 0.5776
Epoch 1/10, Batch 130/145, Loss: 0.4906
Epoch 1/10, Batch 140/145, Loss: 0.3874
Epoch 1/10, Train Loss: 0.6753, Valid Loss: 0.3772
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4673
Epoch 2/10, Batch 20/145, Loss: 0.3095
Epoch 2/10, Batch 30/145, Loss: 0.2670
Epoch 2/10, Batch 40/145, Loss: 0.4234
Epoch 2/10, Batch 50/145, Loss: 0.2756
Epoch 2/10, Batch 60/145, Loss: 0.3968
Epoch 2/10, Batch 70/145, Loss: 0.3892
Epoch 2/10, Batch 80/145, Loss: 0.3187
Epoch 2/10, Batch 90/145, Loss: 0.3493
Epoch 2/10, Batch 100/145, Loss: 0.3372
Epoch 2/10, Batch 110/145, Loss: 0.3737
Epoch 2/10, Batch 120/145, Loss: 0.4481
Epoch 2/10, Batch 130/145, Loss: 0.3146
Epoch 2/10, Batch 140/145, Loss: 0.2712
Epoch 2/10, Train Loss: 0.3510, Valid Loss: 0.2924
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2074
Epoch 3/10, Batch 20/145, Loss: 0.2544
Epoch 3/10, Batch 30/145, Loss: 0.3969
Epoch 3/10, Batch 40/145, Loss: 0.2227
Epoch 3/10, Batch 50/145, Loss: 0.2150
Epoch 3/10, Batch 60/145, Loss: 0.3307
Epoch 3/10, Batch 70/145, Loss: 0.5710
Epoch 3/10, Batch 80/145, Loss: 0.2241
Epoch 3/10, Batch 90/145, Loss: 0.5037
Epoch 3/10, Batch 100/145, Loss: 0.3714
Epoch 3/10, Batch 110/145, Loss: 0.3752
Epoch 3/10, Batch 120/145, Loss: 0.2177
Epoch 3/10, Batch 130/145, Loss: 0.3536
Epoch 3/10, Batch 140/145, Loss: 0.1621
Epoch 3/10, Train Loss: 0.2914, Valid Loss: 0.2628
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.5876
Epoch 4/10, Batch 20/145, Loss: 0.2559
Epoch 4/10, Batch 30/145, Loss: 0.1558
Epoch 4/10, Batch 40/145, Loss: 0.1901
Epoch 4/10, Batch 50/145, Loss: 0.1996
Epoch 4/10, Batch 60/145, Loss: 0.2635
Epoch 4/10, Batch 70/145, Loss: 0.2626
Epoch 4/10, Batch 80/145, Loss: 0.2366
Epoch 4/10, Batch 90/145, Loss: 0.2042
Epoch 4/10, Batch 100/145, Loss: 0.3690
Epoch 4/10, Batch 110/145, Loss: 0.1750
Epoch 4/10, Batch 120/145, Loss: 0.2724
Epoch 4/10, Batch 130/145, Loss: 0.1510
Epoch 4/10, Batch 140/145, Loss: 0.1593
Epoch 4/10, Train Loss: 0.2514, Valid Loss: 0.2508
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1658
Epoch 5/10, Batch 20/145, Loss: 0.3130
Epoch 5/10, Batch 30/145, Loss: 0.1887
Epoch 5/10, Batch 40/145, Loss: 0.2641
Epoch 5/10, Batch 50/145, Loss: 0.2207
Epoch 5/10, Batch 60/145, Loss: 0.2804
Epoch 5/10, Batch 70/145, Loss: 0.1787
Epoch 5/10, Batch 80/145, Loss: 0.2030
Epoch 5/10, Batch 90/145, Loss: 0.1861
Epoch 5/10, Batch 100/145, Loss: 0.3035
Epoch 5/10, Batch 110/145, Loss: 0.2075
Epoch 5/10, Batch 120/145, Loss: 0.4261
Epoch 5/10, Batch 130/145, Loss: 0.1185
Epoch 5/10, Batch 140/145, Loss: 0.3222
Epoch 5/10, Train Loss: 0.2407, Valid Loss: 0.2497
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2500
Epoch 6/10, Batch 20/145, Loss: 0.5253
Epoch 6/10, Batch 30/145, Loss: 0.2781
Epoch 6/10, Batch 40/145, Loss: 0.2442
Epoch 6/10, Batch 50/145, Loss: 0.4097
Epoch 6/10, Batch 60/145, Loss: 0.2135
Epoch 6/10, Batch 70/145, Loss: 0.1924
Epoch 6/10, Batch 80/145, Loss: 0.1337
Epoch 6/10, Batch 90/145, Loss: 0.4228
Epoch 6/10, Batch 100/145, Loss: 0.4540
Epoch 6/10, Batch 110/145, Loss: 0.3007
Epoch 6/10, Batch 120/145, Loss: 0.2877
Epoch 6/10, Batch 130/145, Loss: 0.1518
Epoch 6/10, Batch 140/145, Loss: 0.1064
Epoch 6/10, Train Loss: 0.2218, Valid Loss: 0.2326
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3438
Epoch 7/10, Batch 20/145, Loss: 0.2698
Epoch 7/10, Batch 30/145, Loss: 0.1798
Epoch 7/10, Batch 40/145, Loss: 0.3126
Epoch 7/10, Batch 50/145, Loss: 0.1614
Epoch 7/10, Batch 60/145, Loss: 0.2060
Epoch 7/10, Batch 70/145, Loss: 0.1549
Epoch 7/10, Batch 80/145, Loss: 0.3150
Epoch 7/10, Batch 90/145, Loss: 0.1036
Epoch 7/10, Batch 100/145, Loss: 0.1564
Epoch 7/10, Batch 110/145, Loss: 0.1010
Epoch 7/10, Batch 120/145, Loss: 0.1344
Epoch 7/10, Batch 130/145, Loss: 0.1220
Epoch 7/10, Batch 140/145, Loss: 0.3422
Epoch 7/10, Train Loss: 0.2115, Valid Loss: 0.2347
Epoch 8/10, Batch 10/145, Loss: 0.1835
Epoch 8/10, Batch 20/145, Loss: 0.2945
Epoch 8/10, Batch 30/145, Loss: 0.1102
Epoch 8/10, Batch 40/145, Loss: 0.0813
Epoch 8/10, Batch 50/145, Loss: 0.2203
Epoch 8/10, Batch 60/145, Loss: 0.1435
Epoch 8/10, Batch 70/145, Loss: 0.2258
Epoch 8/10, Batch 80/145, Loss: 0.4108
Epoch 8/10, Batch 90/145, Loss: 0.1935
Epoch 8/10, Batch 100/145, Loss: 0.0867
Epoch 8/10, Batch 110/145, Loss: 0.2128
Epoch 8/10, Batch 120/145, Loss: 0.0953
Epoch 8/10, Batch 130/145, Loss: 0.1989
Epoch 8/10, Batch 140/145, Loss: 0.2815
Epoch 8/10, Train Loss: 0.2084, Valid Loss: 0.2273
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3424
Epoch 9/10, Batch 20/145, Loss: 0.2165
Epoch 9/10, Batch 30/145, Loss: 0.2147
Epoch 9/10, Batch 40/145, Loss: 0.2187
Epoch 9/10, Batch 50/145, Loss: 0.2172
Epoch 9/10, Batch 60/145, Loss: 0.2826
Epoch 9/10, Batch 70/145, Loss: 0.2216
Epoch 9/10, Batch 80/145, Loss: 0.0570
Epoch 9/10, Batch 90/145, Loss: 0.5010
Epoch 9/10, Batch 100/145, Loss: 0.1187
Epoch 9/10, Batch 110/145, Loss: 0.2005
Epoch 9/10, Batch 120/145, Loss: 0.1363
Epoch 9/10, Batch 130/145, Loss: 0.1403
Epoch 9/10, Batch 140/145, Loss: 0.2723
Epoch 9/10, Train Loss: 0.1964, Valid Loss: 0.2247
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1802
Epoch 10/10, Batch 20/145, Loss: 0.1110
Epoch 10/10, Batch 30/145, Loss: 0.0404
Epoch 10/10, Batch 40/145, Loss: 0.1878
Epoch 10/10, Batch 50/145, Loss: 0.1818
Epoch 10/10, Batch 60/145, Loss: 0.1232
Epoch 10/10, Batch 70/145, Loss: 0.3063
Epoch 10/10, Batch 80/145, Loss: 0.1016
Epoch 10/10, Batch 90/145, Loss: 0.3209
Epoch 10/10, Batch 100/145, Loss: 0.1016
Epoch 10/10, Batch 110/145, Loss: 0.2121
Epoch 10/10, Batch 120/145, Loss: 0.2892
Epoch 10/10, Batch 130/145, Loss: 0.0928
Epoch 10/10, Batch 140/145, Loss: 0.2320
Epoch 10/10, Train Loss: 0.1917, Valid Loss: 0.2217
Model saved!
Accuracy: 0.9194
Precision: 0.9165
Recall: 0.9194
F1-score: 0.9174
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3824
Epoch 1/10, Batch 20/145, Loss: 0.9638
Epoch 1/10, Batch 30/145, Loss: 0.9445
Epoch 1/10, Batch 40/145, Loss: 0.7446
Epoch 1/10, Batch 50/145, Loss: 0.7350
Epoch 1/10, Batch 60/145, Loss: 0.6248
Epoch 1/10, Batch 70/145, Loss: 0.4152
Epoch 1/10, Batch 80/145, Loss: 0.4786
Epoch 1/10, Batch 90/145, Loss: 0.4784
Epoch 1/10, Batch 100/145, Loss: 0.4982
Epoch 1/10, Batch 110/145, Loss: 0.3724
Epoch 1/10, Batch 120/145, Loss: 0.6738
Epoch 1/10, Batch 130/145, Loss: 0.4355
Epoch 1/10, Batch 140/145, Loss: 0.3944
Epoch 1/10, Train Loss: 0.6776, Valid Loss: 0.3540
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2737
Epoch 2/10, Batch 20/145, Loss: 0.4802
Epoch 2/10, Batch 30/145, Loss: 0.4074
Epoch 2/10, Batch 40/145, Loss: 0.3479
Epoch 2/10, Batch 50/145, Loss: 0.2778
Epoch 2/10, Batch 60/145, Loss: 0.3178
Epoch 2/10, Batch 70/145, Loss: 0.2925
Epoch 2/10, Batch 80/145, Loss: 0.2636
Epoch 2/10, Batch 90/145, Loss: 0.3494
Epoch 2/10, Batch 100/145, Loss: 0.4718
Epoch 2/10, Batch 110/145, Loss: 0.5566
Epoch 2/10, Batch 120/145, Loss: 0.4102
Epoch 2/10, Batch 130/145, Loss: 0.3177
Epoch 2/10, Batch 140/145, Loss: 0.4285
Epoch 2/10, Train Loss: 0.3557, Valid Loss: 0.2730
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1742
Epoch 3/10, Batch 20/145, Loss: 0.3344
Epoch 3/10, Batch 30/145, Loss: 0.4279
Epoch 3/10, Batch 40/145, Loss: 0.2469
Epoch 3/10, Batch 50/145, Loss: 0.3371
Epoch 3/10, Batch 60/145, Loss: 0.3493
Epoch 3/10, Batch 70/145, Loss: 0.3565
Epoch 3/10, Batch 80/145, Loss: 0.2574
Epoch 3/10, Batch 90/145, Loss: 0.1770
Epoch 3/10, Batch 100/145, Loss: 0.2256
Epoch 3/10, Batch 110/145, Loss: 0.2712
Epoch 3/10, Batch 120/145, Loss: 0.3578
Epoch 3/10, Batch 130/145, Loss: 0.2998
Epoch 3/10, Batch 140/145, Loss: 0.2059
Epoch 3/10, Train Loss: 0.3000, Valid Loss: 0.2367
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2036
Epoch 4/10, Batch 20/145, Loss: 0.3359
Epoch 4/10, Batch 30/145, Loss: 0.2706
Epoch 4/10, Batch 40/145, Loss: 0.1731
Epoch 4/10, Batch 50/145, Loss: 0.1681
Epoch 4/10, Batch 60/145, Loss: 0.2569
Epoch 4/10, Batch 70/145, Loss: 0.3302
Epoch 4/10, Batch 80/145, Loss: 0.1307
Epoch 4/10, Batch 90/145, Loss: 0.1922
Epoch 4/10, Batch 100/145, Loss: 0.2570
Epoch 4/10, Batch 110/145, Loss: 0.1848
Epoch 4/10, Batch 120/145, Loss: 0.1801
Epoch 4/10, Batch 130/145, Loss: 0.2137
Epoch 4/10, Batch 140/145, Loss: 0.2868
Epoch 4/10, Train Loss: 0.2626, Valid Loss: 0.2229
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2520
Epoch 5/10, Batch 20/145, Loss: 0.1311
Epoch 5/10, Batch 30/145, Loss: 0.3686
Epoch 5/10, Batch 40/145, Loss: 0.1533
Epoch 5/10, Batch 50/145, Loss: 0.3081
Epoch 5/10, Batch 60/145, Loss: 0.2347
Epoch 5/10, Batch 70/145, Loss: 0.1966
Epoch 5/10, Batch 80/145, Loss: 0.1199
Epoch 5/10, Batch 90/145, Loss: 0.3292
Epoch 5/10, Batch 100/145, Loss: 0.2522
Epoch 5/10, Batch 110/145, Loss: 0.3158
Epoch 5/10, Batch 120/145, Loss: 0.4390
Epoch 5/10, Batch 130/145, Loss: 0.1199
Epoch 5/10, Batch 140/145, Loss: 0.2619
Epoch 5/10, Train Loss: 0.2532, Valid Loss: 0.2163
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1083
Epoch 6/10, Batch 20/145, Loss: 0.2829
Epoch 6/10, Batch 30/145, Loss: 0.3654
Epoch 6/10, Batch 40/145, Loss: 0.2302
Epoch 6/10, Batch 50/145, Loss: 0.4346
Epoch 6/10, Batch 60/145, Loss: 0.2111
Epoch 6/10, Batch 70/145, Loss: 0.1926
Epoch 6/10, Batch 80/145, Loss: 0.1319
Epoch 6/10, Batch 90/145, Loss: 0.3838
Epoch 6/10, Batch 100/145, Loss: 0.2848
Epoch 6/10, Batch 110/145, Loss: 0.2837
Epoch 6/10, Batch 120/145, Loss: 0.2098
Epoch 6/10, Batch 130/145, Loss: 0.1755
Epoch 6/10, Batch 140/145, Loss: 0.2801
Epoch 6/10, Train Loss: 0.2370, Valid Loss: 0.1979
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1899
Epoch 7/10, Batch 20/145, Loss: 0.2109
Epoch 7/10, Batch 30/145, Loss: 0.3351
Epoch 7/10, Batch 40/145, Loss: 0.3515
Epoch 7/10, Batch 50/145, Loss: 0.2067
Epoch 7/10, Batch 60/145, Loss: 0.3050
Epoch 7/10, Batch 70/145, Loss: 0.2819
Epoch 7/10, Batch 80/145, Loss: 0.2723
Epoch 7/10, Batch 90/145, Loss: 0.2284
Epoch 7/10, Batch 100/145, Loss: 0.2463
Epoch 7/10, Batch 110/145, Loss: 0.3022
Epoch 7/10, Batch 120/145, Loss: 0.3416
Epoch 7/10, Batch 130/145, Loss: 0.1461
Epoch 7/10, Batch 140/145, Loss: 0.1436
Epoch 7/10, Train Loss: 0.2239, Valid Loss: 0.1972
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2850
Epoch 8/10, Batch 20/145, Loss: 0.5089
Epoch 8/10, Batch 30/145, Loss: 0.2390
Epoch 8/10, Batch 40/145, Loss: 0.1758
Epoch 8/10, Batch 50/145, Loss: 0.2612
Epoch 8/10, Batch 60/145, Loss: 0.2025
Epoch 8/10, Batch 70/145, Loss: 0.4204
Epoch 8/10, Batch 80/145, Loss: 0.1588
Epoch 8/10, Batch 90/145, Loss: 0.3600
Epoch 8/10, Batch 100/145, Loss: 0.3667
Epoch 8/10, Batch 110/145, Loss: 0.2403
Epoch 8/10, Batch 120/145, Loss: 0.1530
Epoch 8/10, Batch 130/145, Loss: 0.2342
Epoch 8/10, Batch 140/145, Loss: 0.2169
Epoch 8/10, Train Loss: 0.2147, Valid Loss: 0.1926
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3509
Epoch 9/10, Batch 20/145, Loss: 0.0773
Epoch 9/10, Batch 30/145, Loss: 0.1489
Epoch 9/10, Batch 40/145, Loss: 0.3172
Epoch 9/10, Batch 50/145, Loss: 0.2540
Epoch 9/10, Batch 60/145, Loss: 0.3688
Epoch 9/10, Batch 70/145, Loss: 0.0968
Epoch 9/10, Batch 80/145, Loss: 0.1634
Epoch 9/10, Batch 90/145, Loss: 0.3188
Epoch 9/10, Batch 100/145, Loss: 0.1545
Epoch 9/10, Batch 110/145, Loss: 0.3257
Epoch 9/10, Batch 120/145, Loss: 0.2143
Epoch 9/10, Batch 130/145, Loss: 0.3190
Epoch 9/10, Batch 140/145, Loss: 0.1480
Epoch 9/10, Train Loss: 0.2110, Valid Loss: 0.1849
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1124
Epoch 10/10, Batch 20/145, Loss: 0.0889
Epoch 10/10, Batch 30/145, Loss: 0.1536
Epoch 10/10, Batch 40/145, Loss: 0.1139
Epoch 10/10, Batch 50/145, Loss: 0.2749
Epoch 10/10, Batch 60/145, Loss: 0.0674
Epoch 10/10, Batch 70/145, Loss: 0.2643
Epoch 10/10, Batch 80/145, Loss: 0.1986
Epoch 10/10, Batch 90/145, Loss: 0.0835
Epoch 10/10, Batch 100/145, Loss: 0.3014
Epoch 10/10, Batch 110/145, Loss: 0.2503
Epoch 10/10, Batch 120/145, Loss: 0.5367
Epoch 10/10, Batch 130/145, Loss: 0.1323
Epoch 10/10, Batch 140/145, Loss: 0.1768
Epoch 10/10, Train Loss: 0.2018, Valid Loss: 0.1883
Accuracy: 0.9182
Precision: 0.9174
Recall: 0.9182
F1-score: 0.9176
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.2899
Epoch 1/10, Batch 20/145, Loss: 0.9754
Epoch 1/10, Batch 30/145, Loss: 0.8206
Epoch 1/10, Batch 40/145, Loss: 0.8195
Epoch 1/10, Batch 50/145, Loss: 0.7683
Epoch 1/10, Batch 60/145, Loss: 0.7258
Epoch 1/10, Batch 70/145, Loss: 0.5116
Epoch 1/10, Batch 80/145, Loss: 0.4731
Epoch 1/10, Batch 90/145, Loss: 0.4713
Epoch 1/10, Batch 100/145, Loss: 0.5726
Epoch 1/10, Batch 110/145, Loss: 0.3982
Epoch 1/10, Batch 120/145, Loss: 0.5768
Epoch 1/10, Batch 130/145, Loss: 0.4511
Epoch 1/10, Batch 140/145, Loss: 0.4505
Epoch 1/10, Train Loss: 0.6751, Valid Loss: 0.3704
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2768
Epoch 2/10, Batch 20/145, Loss: 0.3212
Epoch 2/10, Batch 30/145, Loss: 0.2879
Epoch 2/10, Batch 40/145, Loss: 0.4098
Epoch 2/10, Batch 50/145, Loss: 0.3030
Epoch 2/10, Batch 60/145, Loss: 0.3680
Epoch 2/10, Batch 70/145, Loss: 0.4980
Epoch 2/10, Batch 80/145, Loss: 0.3835
Epoch 2/10, Batch 90/145, Loss: 0.2380
Epoch 2/10, Batch 100/145, Loss: 0.3246
Epoch 2/10, Batch 110/145, Loss: 0.4039
Epoch 2/10, Batch 120/145, Loss: 0.3003
Epoch 2/10, Batch 130/145, Loss: 0.4573
Epoch 2/10, Batch 140/145, Loss: 0.4876
Epoch 2/10, Train Loss: 0.3553, Valid Loss: 0.2933
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2454
Epoch 3/10, Batch 20/145, Loss: 0.2162
Epoch 3/10, Batch 30/145, Loss: 0.4170
Epoch 3/10, Batch 40/145, Loss: 0.2550
Epoch 3/10, Batch 50/145, Loss: 0.1899
Epoch 3/10, Batch 60/145, Loss: 0.6907
Epoch 3/10, Batch 70/145, Loss: 0.3178
Epoch 3/10, Batch 80/145, Loss: 0.1763
Epoch 3/10, Batch 90/145, Loss: 0.2533
Epoch 3/10, Batch 100/145, Loss: 0.2912
Epoch 3/10, Batch 110/145, Loss: 0.3368
Epoch 3/10, Batch 120/145, Loss: 0.1301
Epoch 3/10, Batch 130/145, Loss: 0.4784
Epoch 3/10, Batch 140/145, Loss: 0.4305
Epoch 3/10, Train Loss: 0.2993, Valid Loss: 0.2642
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2556
Epoch 4/10, Batch 20/145, Loss: 0.3906
Epoch 4/10, Batch 30/145, Loss: 0.3285
Epoch 4/10, Batch 40/145, Loss: 0.1375
Epoch 4/10, Batch 50/145, Loss: 0.1884
Epoch 4/10, Batch 60/145, Loss: 0.3190
Epoch 4/10, Batch 70/145, Loss: 0.2112
Epoch 4/10, Batch 80/145, Loss: 0.1487
Epoch 4/10, Batch 90/145, Loss: 0.2022
Epoch 4/10, Batch 100/145, Loss: 0.2781
Epoch 4/10, Batch 110/145, Loss: 0.1004
Epoch 4/10, Batch 120/145, Loss: 0.1188
Epoch 4/10, Batch 130/145, Loss: 0.2307
Epoch 4/10, Batch 140/145, Loss: 0.1509
Epoch 4/10, Train Loss: 0.2597, Valid Loss: 0.2371
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2165
Epoch 5/10, Batch 20/145, Loss: 0.2220
Epoch 5/10, Batch 30/145, Loss: 0.2272
Epoch 5/10, Batch 40/145, Loss: 0.3069
Epoch 5/10, Batch 50/145, Loss: 0.1663
Epoch 5/10, Batch 60/145, Loss: 0.3284
Epoch 5/10, Batch 70/145, Loss: 0.2721
Epoch 5/10, Batch 80/145, Loss: 0.2748
Epoch 5/10, Batch 90/145, Loss: 0.3612
Epoch 5/10, Batch 100/145, Loss: 0.2419
Epoch 5/10, Batch 110/145, Loss: 0.1754
Epoch 5/10, Batch 120/145, Loss: 0.3434
Epoch 5/10, Batch 130/145, Loss: 0.1888
Epoch 5/10, Batch 140/145, Loss: 0.1782
Epoch 5/10, Train Loss: 0.2422, Valid Loss: 0.2244
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2306
Epoch 6/10, Batch 20/145, Loss: 0.4211
Epoch 6/10, Batch 30/145, Loss: 0.3993
Epoch 6/10, Batch 40/145, Loss: 0.1713
Epoch 6/10, Batch 50/145, Loss: 0.3078
Epoch 6/10, Batch 60/145, Loss: 0.4209
Epoch 6/10, Batch 70/145, Loss: 0.1603
Epoch 6/10, Batch 80/145, Loss: 0.2151
Epoch 6/10, Batch 90/145, Loss: 0.2540
Epoch 6/10, Batch 100/145, Loss: 0.2368
Epoch 6/10, Batch 110/145, Loss: 0.2632
Epoch 6/10, Batch 120/145, Loss: 0.2504
Epoch 6/10, Batch 130/145, Loss: 0.1961
Epoch 6/10, Batch 140/145, Loss: 0.2167
Epoch 6/10, Train Loss: 0.2392, Valid Loss: 0.2200
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3829
Epoch 7/10, Batch 20/145, Loss: 0.2033
Epoch 7/10, Batch 30/145, Loss: 0.1855
Epoch 7/10, Batch 40/145, Loss: 0.2649
Epoch 7/10, Batch 50/145, Loss: 0.3234
Epoch 7/10, Batch 60/145, Loss: 0.1370
Epoch 7/10, Batch 70/145, Loss: 0.1353
Epoch 7/10, Batch 80/145, Loss: 0.4832
Epoch 7/10, Batch 90/145, Loss: 0.2276
Epoch 7/10, Batch 100/145, Loss: 0.2333
Epoch 7/10, Batch 110/145, Loss: 0.1485
Epoch 7/10, Batch 120/145, Loss: 0.1650
Epoch 7/10, Batch 130/145, Loss: 0.1319
Epoch 7/10, Batch 140/145, Loss: 0.2329
Epoch 7/10, Train Loss: 0.2199, Valid Loss: 0.2118
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2544
Epoch 8/10, Batch 20/145, Loss: 0.3529
Epoch 8/10, Batch 30/145, Loss: 0.2193
Epoch 8/10, Batch 40/145, Loss: 0.2010
Epoch 8/10, Batch 50/145, Loss: 0.2822
Epoch 8/10, Batch 60/145, Loss: 0.2017
Epoch 8/10, Batch 70/145, Loss: 0.3452
Epoch 8/10, Batch 80/145, Loss: 0.3252
Epoch 8/10, Batch 90/145, Loss: 0.2741
Epoch 8/10, Batch 100/145, Loss: 0.4554
Epoch 8/10, Batch 110/145, Loss: 0.2243
Epoch 8/10, Batch 120/145, Loss: 0.1259
Epoch 8/10, Batch 130/145, Loss: 0.1094
Epoch 8/10, Batch 140/145, Loss: 0.1735
Epoch 8/10, Train Loss: 0.2075, Valid Loss: 0.2153
Epoch 9/10, Batch 10/145, Loss: 0.3113
Epoch 9/10, Batch 20/145, Loss: 0.2159
Epoch 9/10, Batch 30/145, Loss: 0.3281
Epoch 9/10, Batch 40/145, Loss: 0.1708
Epoch 9/10, Batch 50/145, Loss: 0.1462
Epoch 9/10, Batch 60/145, Loss: 0.3054
Epoch 9/10, Batch 70/145, Loss: 0.1699
Epoch 9/10, Batch 80/145, Loss: 0.1048
Epoch 9/10, Batch 90/145, Loss: 0.3772
Epoch 9/10, Batch 100/145, Loss: 0.1263
Epoch 9/10, Batch 110/145, Loss: 0.2390
Epoch 9/10, Batch 120/145, Loss: 0.1794
Epoch 9/10, Batch 130/145, Loss: 0.2469
Epoch 9/10, Batch 140/145, Loss: 0.3420
Epoch 9/10, Train Loss: 0.2107, Valid Loss: 0.2111
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1317
Epoch 10/10, Batch 20/145, Loss: 0.1394
Epoch 10/10, Batch 30/145, Loss: 0.1239
Epoch 10/10, Batch 40/145, Loss: 0.1178
Epoch 10/10, Batch 50/145, Loss: 0.2056
Epoch 10/10, Batch 60/145, Loss: 0.2172
Epoch 10/10, Batch 70/145, Loss: 0.3919
Epoch 10/10, Batch 80/145, Loss: 0.1578
Epoch 10/10, Batch 90/145, Loss: 0.1613
Epoch 10/10, Batch 100/145, Loss: 0.1628
Epoch 10/10, Batch 110/145, Loss: 0.2010
Epoch 10/10, Batch 120/145, Loss: 0.2211
Epoch 10/10, Batch 130/145, Loss: 0.1522
Epoch 10/10, Batch 140/145, Loss: 0.1431
Epoch 10/10, Train Loss: 0.1968, Valid Loss: 0.2056
Model saved!
Accuracy: 0.9217
Precision: 0.9185
Recall: 0.9217
F1-score: 0.9194
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3386
Epoch 1/10, Batch 20/145, Loss: 0.9981
Epoch 1/10, Batch 30/145, Loss: 0.8951
Epoch 1/10, Batch 40/145, Loss: 0.9086
Epoch 1/10, Batch 50/145, Loss: 0.5711
Epoch 1/10, Batch 60/145, Loss: 0.6865
Epoch 1/10, Batch 70/145, Loss: 0.4698
Epoch 1/10, Batch 80/145, Loss: 0.5980
Epoch 1/10, Batch 90/145, Loss: 0.4275
Epoch 1/10, Batch 100/145, Loss: 0.6197
Epoch 1/10, Batch 110/145, Loss: 0.3274
Epoch 1/10, Batch 120/145, Loss: 0.5482
Epoch 1/10, Batch 130/145, Loss: 0.4862
Epoch 1/10, Batch 140/145, Loss: 0.2547
Epoch 1/10, Train Loss: 0.6725, Valid Loss: 0.3756
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2880
Epoch 2/10, Batch 20/145, Loss: 0.2795
Epoch 2/10, Batch 30/145, Loss: 0.4013
Epoch 2/10, Batch 40/145, Loss: 0.3333
Epoch 2/10, Batch 50/145, Loss: 0.2549
Epoch 2/10, Batch 60/145, Loss: 0.4738
Epoch 2/10, Batch 70/145, Loss: 0.3706
Epoch 2/10, Batch 80/145, Loss: 0.2351
Epoch 2/10, Batch 90/145, Loss: 0.3645
Epoch 2/10, Batch 100/145, Loss: 0.1842
Epoch 2/10, Batch 110/145, Loss: 0.3343
Epoch 2/10, Batch 120/145, Loss: 0.3591
Epoch 2/10, Batch 130/145, Loss: 0.2903
Epoch 2/10, Batch 140/145, Loss: 0.2181
Epoch 2/10, Train Loss: 0.3565, Valid Loss: 0.2915
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2944
Epoch 3/10, Batch 20/145, Loss: 0.2805
Epoch 3/10, Batch 30/145, Loss: 0.3251
Epoch 3/10, Batch 40/145, Loss: 0.2148
Epoch 3/10, Batch 50/145, Loss: 0.2598
Epoch 3/10, Batch 60/145, Loss: 0.5550
Epoch 3/10, Batch 70/145, Loss: 0.4574
Epoch 3/10, Batch 80/145, Loss: 0.1975
Epoch 3/10, Batch 90/145, Loss: 0.2485
Epoch 3/10, Batch 100/145, Loss: 0.2316
Epoch 3/10, Batch 110/145, Loss: 0.4347
Epoch 3/10, Batch 120/145, Loss: 0.2746
Epoch 3/10, Batch 130/145, Loss: 0.2638
Epoch 3/10, Batch 140/145, Loss: 0.1705
Epoch 3/10, Train Loss: 0.2940, Valid Loss: 0.2586
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3963
Epoch 4/10, Batch 20/145, Loss: 0.3468
Epoch 4/10, Batch 30/145, Loss: 0.3949
Epoch 4/10, Batch 40/145, Loss: 0.1418
Epoch 4/10, Batch 50/145, Loss: 0.2244
Epoch 4/10, Batch 60/145, Loss: 0.2590
Epoch 4/10, Batch 70/145, Loss: 0.1485
Epoch 4/10, Batch 80/145, Loss: 0.1832
Epoch 4/10, Batch 90/145, Loss: 0.2226
Epoch 4/10, Batch 100/145, Loss: 0.2778
Epoch 4/10, Batch 110/145, Loss: 0.2951
Epoch 4/10, Batch 120/145, Loss: 0.3309
Epoch 4/10, Batch 130/145, Loss: 0.1394
Epoch 4/10, Batch 140/145, Loss: 0.1931
Epoch 4/10, Train Loss: 0.2529, Valid Loss: 0.2452
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.0634
Epoch 5/10, Batch 20/145, Loss: 0.2477
Epoch 5/10, Batch 30/145, Loss: 0.2027
Epoch 5/10, Batch 40/145, Loss: 0.1963
Epoch 5/10, Batch 50/145, Loss: 0.1609
Epoch 5/10, Batch 60/145, Loss: 0.1167
Epoch 5/10, Batch 70/145, Loss: 0.1861
Epoch 5/10, Batch 80/145, Loss: 0.1322
Epoch 5/10, Batch 90/145, Loss: 0.2540
Epoch 5/10, Batch 100/145, Loss: 0.2948
Epoch 5/10, Batch 110/145, Loss: 0.3511
Epoch 5/10, Batch 120/145, Loss: 0.2729
Epoch 5/10, Batch 130/145, Loss: 0.1509
Epoch 5/10, Batch 140/145, Loss: 0.2502
Epoch 5/10, Train Loss: 0.2381, Valid Loss: 0.2305
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1665
Epoch 6/10, Batch 20/145, Loss: 0.4735
Epoch 6/10, Batch 30/145, Loss: 0.2649
Epoch 6/10, Batch 40/145, Loss: 0.1390
Epoch 6/10, Batch 50/145, Loss: 0.2672
Epoch 6/10, Batch 60/145, Loss: 0.1510
Epoch 6/10, Batch 70/145, Loss: 0.1908
Epoch 6/10, Batch 80/145, Loss: 0.2008
Epoch 6/10, Batch 90/145, Loss: 0.2537
Epoch 6/10, Batch 100/145, Loss: 0.2349
Epoch 6/10, Batch 110/145, Loss: 0.1481
Epoch 6/10, Batch 120/145, Loss: 0.1789
Epoch 6/10, Batch 130/145, Loss: 0.2203
Epoch 6/10, Batch 140/145, Loss: 0.1922
Epoch 6/10, Train Loss: 0.2247, Valid Loss: 0.2220
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2632
Epoch 7/10, Batch 20/145, Loss: 0.1184
Epoch 7/10, Batch 30/145, Loss: 0.3308
Epoch 7/10, Batch 40/145, Loss: 0.3228
Epoch 7/10, Batch 50/145, Loss: 0.1835
Epoch 7/10, Batch 60/145, Loss: 0.1813
Epoch 7/10, Batch 70/145, Loss: 0.2713
Epoch 7/10, Batch 80/145, Loss: 0.5509
Epoch 7/10, Batch 90/145, Loss: 0.1521
Epoch 7/10, Batch 100/145, Loss: 0.3507
Epoch 7/10, Batch 110/145, Loss: 0.1866
Epoch 7/10, Batch 120/145, Loss: 0.1809
Epoch 7/10, Batch 130/145, Loss: 0.0733
Epoch 7/10, Batch 140/145, Loss: 0.2004
Epoch 7/10, Train Loss: 0.2105, Valid Loss: 0.2120
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1583
Epoch 8/10, Batch 20/145, Loss: 0.1841
Epoch 8/10, Batch 30/145, Loss: 0.2088
Epoch 8/10, Batch 40/145, Loss: 0.1825
Epoch 8/10, Batch 50/145, Loss: 0.2837
Epoch 8/10, Batch 60/145, Loss: 0.2359
Epoch 8/10, Batch 70/145, Loss: 0.3494
Epoch 8/10, Batch 80/145, Loss: 0.2783
Epoch 8/10, Batch 90/145, Loss: 0.2843
Epoch 8/10, Batch 100/145, Loss: 0.1966
Epoch 8/10, Batch 110/145, Loss: 0.1744
Epoch 8/10, Batch 120/145, Loss: 0.2595
Epoch 8/10, Batch 130/145, Loss: 0.4650
Epoch 8/10, Batch 140/145, Loss: 0.2322
Epoch 8/10, Train Loss: 0.2061, Valid Loss: 0.2123
Epoch 9/10, Batch 10/145, Loss: 0.3074
Epoch 9/10, Batch 20/145, Loss: 0.2501
Epoch 9/10, Batch 30/145, Loss: 0.0852
Epoch 9/10, Batch 40/145, Loss: 0.2929
Epoch 9/10, Batch 50/145, Loss: 0.0986
Epoch 9/10, Batch 60/145, Loss: 0.3403
Epoch 9/10, Batch 70/145, Loss: 0.2850
Epoch 9/10, Batch 80/145, Loss: 0.2635
Epoch 9/10, Batch 90/145, Loss: 0.2299
Epoch 9/10, Batch 100/145, Loss: 0.1100
Epoch 9/10, Batch 110/145, Loss: 0.2096
Epoch 9/10, Batch 120/145, Loss: 0.1012
Epoch 9/10, Batch 130/145, Loss: 0.2623
Epoch 9/10, Batch 140/145, Loss: 0.2111
Epoch 9/10, Train Loss: 0.1996, Valid Loss: 0.2060
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1149
Epoch 10/10, Batch 20/145, Loss: 0.1714
Epoch 10/10, Batch 30/145, Loss: 0.1798
Epoch 10/10, Batch 40/145, Loss: 0.2150
Epoch 10/10, Batch 50/145, Loss: 0.2444
Epoch 10/10, Batch 60/145, Loss: 0.1946
Epoch 10/10, Batch 70/145, Loss: 0.2872
Epoch 10/10, Batch 80/145, Loss: 0.1656
Epoch 10/10, Batch 90/145, Loss: 0.1139
Epoch 10/10, Batch 100/145, Loss: 0.1931
Epoch 10/10, Batch 110/145, Loss: 0.2199
Epoch 10/10, Batch 120/145, Loss: 0.1489
Epoch 10/10, Batch 130/145, Loss: 0.2264
Epoch 10/10, Batch 140/145, Loss: 0.2813
Epoch 10/10, Train Loss: 0.1891, Valid Loss: 0.2101
Accuracy: 0.9182
Precision: 0.9160
Recall: 0.9182
F1-score: 0.9165
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3615
Epoch 1/10, Batch 20/145, Loss: 0.9891
Epoch 1/10, Batch 30/145, Loss: 1.0232
Epoch 1/10, Batch 40/145, Loss: 0.7788
Epoch 1/10, Batch 50/145, Loss: 0.6878
Epoch 1/10, Batch 60/145, Loss: 0.7321
Epoch 1/10, Batch 70/145, Loss: 0.4190
Epoch 1/10, Batch 80/145, Loss: 0.5077
Epoch 1/10, Batch 90/145, Loss: 0.4971
Epoch 1/10, Batch 100/145, Loss: 0.5575
Epoch 1/10, Batch 110/145, Loss: 0.3418
Epoch 1/10, Batch 120/145, Loss: 0.5403
Epoch 1/10, Batch 130/145, Loss: 0.4249
Epoch 1/10, Batch 140/145, Loss: 0.3480
Epoch 1/10, Train Loss: 0.6729, Valid Loss: 0.3677
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2949
Epoch 2/10, Batch 20/145, Loss: 0.3235
Epoch 2/10, Batch 30/145, Loss: 0.4261
Epoch 2/10, Batch 40/145, Loss: 0.4407
Epoch 2/10, Batch 50/145, Loss: 0.2332
Epoch 2/10, Batch 60/145, Loss: 0.3657
Epoch 2/10, Batch 70/145, Loss: 0.4289
Epoch 2/10, Batch 80/145, Loss: 0.3057
Epoch 2/10, Batch 90/145, Loss: 0.2644
Epoch 2/10, Batch 100/145, Loss: 0.2447
Epoch 2/10, Batch 110/145, Loss: 0.4783
Epoch 2/10, Batch 120/145, Loss: 0.3442
Epoch 2/10, Batch 130/145, Loss: 0.3499
Epoch 2/10, Batch 140/145, Loss: 0.3356
Epoch 2/10, Train Loss: 0.3453, Valid Loss: 0.2819
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2761
Epoch 3/10, Batch 20/145, Loss: 0.2111
Epoch 3/10, Batch 30/145, Loss: 0.2770
Epoch 3/10, Batch 40/145, Loss: 0.2111
Epoch 3/10, Batch 50/145, Loss: 0.2222
Epoch 3/10, Batch 60/145, Loss: 0.3257
Epoch 3/10, Batch 70/145, Loss: 0.3957
Epoch 3/10, Batch 80/145, Loss: 0.2457
Epoch 3/10, Batch 90/145, Loss: 0.1845
Epoch 3/10, Batch 100/145, Loss: 0.2656
Epoch 3/10, Batch 110/145, Loss: 0.2350
Epoch 3/10, Batch 120/145, Loss: 0.2596
Epoch 3/10, Batch 130/145, Loss: 0.3125
Epoch 3/10, Batch 140/145, Loss: 0.2116
Epoch 3/10, Train Loss: 0.2860, Valid Loss: 0.2505
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3960
Epoch 4/10, Batch 20/145, Loss: 0.2555
Epoch 4/10, Batch 30/145, Loss: 0.3508
Epoch 4/10, Batch 40/145, Loss: 0.0549
Epoch 4/10, Batch 50/145, Loss: 0.2099
Epoch 4/10, Batch 60/145, Loss: 0.1562
Epoch 4/10, Batch 70/145, Loss: 0.1423
Epoch 4/10, Batch 80/145, Loss: 0.2602
Epoch 4/10, Batch 90/145, Loss: 0.3419
Epoch 4/10, Batch 100/145, Loss: 0.3963
Epoch 4/10, Batch 110/145, Loss: 0.1178
Epoch 4/10, Batch 120/145, Loss: 0.5551
Epoch 4/10, Batch 130/145, Loss: 0.2455
Epoch 4/10, Batch 140/145, Loss: 0.1492
Epoch 4/10, Train Loss: 0.2548, Valid Loss: 0.2355
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2380
Epoch 5/10, Batch 20/145, Loss: 0.1812
Epoch 5/10, Batch 30/145, Loss: 0.1745
Epoch 5/10, Batch 40/145, Loss: 0.2075
Epoch 5/10, Batch 50/145, Loss: 0.1677
Epoch 5/10, Batch 60/145, Loss: 0.2180
Epoch 5/10, Batch 70/145, Loss: 0.2221
Epoch 5/10, Batch 80/145, Loss: 0.2337
Epoch 5/10, Batch 90/145, Loss: 0.2520
Epoch 5/10, Batch 100/145, Loss: 0.2230
Epoch 5/10, Batch 110/145, Loss: 0.1472
Epoch 5/10, Batch 120/145, Loss: 0.1782
Epoch 5/10, Batch 130/145, Loss: 0.1663
Epoch 5/10, Batch 140/145, Loss: 0.1265
Epoch 5/10, Train Loss: 0.2370, Valid Loss: 0.2280
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1146
Epoch 6/10, Batch 20/145, Loss: 0.4412
Epoch 6/10, Batch 30/145, Loss: 0.2946
Epoch 6/10, Batch 40/145, Loss: 0.1964
Epoch 6/10, Batch 50/145, Loss: 0.4689
Epoch 6/10, Batch 60/145, Loss: 0.2354
Epoch 6/10, Batch 70/145, Loss: 0.1958
Epoch 6/10, Batch 80/145, Loss: 0.1955
Epoch 6/10, Batch 90/145, Loss: 0.2428
Epoch 6/10, Batch 100/145, Loss: 0.2580
Epoch 6/10, Batch 110/145, Loss: 0.1921
Epoch 6/10, Batch 120/145, Loss: 0.2321
Epoch 6/10, Batch 130/145, Loss: 0.3252
Epoch 6/10, Batch 140/145, Loss: 0.1642
Epoch 6/10, Train Loss: 0.2238, Valid Loss: 0.2160
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1291
Epoch 7/10, Batch 20/145, Loss: 0.1605
Epoch 7/10, Batch 30/145, Loss: 0.1724
Epoch 7/10, Batch 40/145, Loss: 0.3903
Epoch 7/10, Batch 50/145, Loss: 0.1382
Epoch 7/10, Batch 60/145, Loss: 0.2146
Epoch 7/10, Batch 70/145, Loss: 0.1635
Epoch 7/10, Batch 80/145, Loss: 0.4456
Epoch 7/10, Batch 90/145, Loss: 0.2206
Epoch 7/10, Batch 100/145, Loss: 0.1787
Epoch 7/10, Batch 110/145, Loss: 0.2205
Epoch 7/10, Batch 120/145, Loss: 0.2514
Epoch 7/10, Batch 130/145, Loss: 0.0884
Epoch 7/10, Batch 140/145, Loss: 0.1486
Epoch 7/10, Train Loss: 0.2102, Valid Loss: 0.2060
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2187
Epoch 8/10, Batch 20/145, Loss: 0.0819
Epoch 8/10, Batch 30/145, Loss: 0.2843
Epoch 8/10, Batch 40/145, Loss: 0.1492
Epoch 8/10, Batch 50/145, Loss: 0.1883
Epoch 8/10, Batch 60/145, Loss: 0.2101
Epoch 8/10, Batch 70/145, Loss: 0.1924
Epoch 8/10, Batch 80/145, Loss: 0.3017
Epoch 8/10, Batch 90/145, Loss: 0.3839
Epoch 8/10, Batch 100/145, Loss: 0.3582
Epoch 8/10, Batch 110/145, Loss: 0.1422
Epoch 8/10, Batch 120/145, Loss: 0.2449
Epoch 8/10, Batch 130/145, Loss: 0.1348
Epoch 8/10, Batch 140/145, Loss: 0.2023
Epoch 8/10, Train Loss: 0.2096, Valid Loss: 0.2133
Epoch 9/10, Batch 10/145, Loss: 0.2983
Epoch 9/10, Batch 20/145, Loss: 0.0881
Epoch 9/10, Batch 30/145, Loss: 0.2098
Epoch 9/10, Batch 40/145, Loss: 0.1836
Epoch 9/10, Batch 50/145, Loss: 0.2051
Epoch 9/10, Batch 60/145, Loss: 0.2743
Epoch 9/10, Batch 70/145, Loss: 0.2252
Epoch 9/10, Batch 80/145, Loss: 0.1952
Epoch 9/10, Batch 90/145, Loss: 0.2317
Epoch 9/10, Batch 100/145, Loss: 0.1198
Epoch 9/10, Batch 110/145, Loss: 0.1354
Epoch 9/10, Batch 120/145, Loss: 0.1198
Epoch 9/10, Batch 130/145, Loss: 0.1880
Epoch 9/10, Batch 140/145, Loss: 0.2934
Epoch 9/10, Train Loss: 0.2023, Valid Loss: 0.2097
Epoch 10/10, Batch 10/145, Loss: 0.2281
Epoch 10/10, Batch 20/145, Loss: 0.1879
Epoch 10/10, Batch 30/145, Loss: 0.1531
Epoch 10/10, Batch 40/145, Loss: 0.3336
Epoch 10/10, Batch 50/145, Loss: 0.1781
Epoch 10/10, Batch 60/145, Loss: 0.1372
Epoch 10/10, Batch 70/145, Loss: 0.1786
Epoch 10/10, Batch 80/145, Loss: 0.2727
Epoch 10/10, Batch 90/145, Loss: 0.0636
Epoch 10/10, Batch 100/145, Loss: 0.2279
Epoch 10/10, Batch 110/145, Loss: 0.1305
Epoch 10/10, Batch 120/145, Loss: 0.1899
Epoch 10/10, Batch 130/145, Loss: 0.1632
Epoch 10/10, Batch 140/145, Loss: 0.2682
Epoch 10/10, Train Loss: 0.1913, Valid Loss: 0.2043
Model saved!
Accuracy: 0.9171
Precision: 0.9153
Recall: 0.9171
F1-score: 0.9138
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3291
Epoch 1/10, Batch 20/145, Loss: 1.0108
Epoch 1/10, Batch 30/145, Loss: 0.8566
Epoch 1/10, Batch 40/145, Loss: 0.7310
Epoch 1/10, Batch 50/145, Loss: 0.7434
Epoch 1/10, Batch 60/145, Loss: 0.6497
Epoch 1/10, Batch 70/145, Loss: 0.5412
Epoch 1/10, Batch 80/145, Loss: 0.5362
Epoch 1/10, Batch 90/145, Loss: 0.4738
Epoch 1/10, Batch 100/145, Loss: 0.4948
Epoch 1/10, Batch 110/145, Loss: 0.3667
Epoch 1/10, Batch 120/145, Loss: 0.4771
Epoch 1/10, Batch 130/145, Loss: 0.4778
Epoch 1/10, Batch 140/145, Loss: 0.3495
Epoch 1/10, Train Loss: 0.6812, Valid Loss: 0.3698
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4391
Epoch 2/10, Batch 20/145, Loss: 0.2552
Epoch 2/10, Batch 30/145, Loss: 0.4249
Epoch 2/10, Batch 40/145, Loss: 0.5311
Epoch 2/10, Batch 50/145, Loss: 0.4086
Epoch 2/10, Batch 60/145, Loss: 0.4615
Epoch 2/10, Batch 70/145, Loss: 0.3637
Epoch 2/10, Batch 80/145, Loss: 0.2282
Epoch 2/10, Batch 90/145, Loss: 0.3282
Epoch 2/10, Batch 100/145, Loss: 0.3410
Epoch 2/10, Batch 110/145, Loss: 0.4320
Epoch 2/10, Batch 120/145, Loss: 0.3870
Epoch 2/10, Batch 130/145, Loss: 0.2876
Epoch 2/10, Batch 140/145, Loss: 0.3934
Epoch 2/10, Train Loss: 0.3588, Valid Loss: 0.2931
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2645
Epoch 3/10, Batch 20/145, Loss: 0.3528
Epoch 3/10, Batch 30/145, Loss: 0.3678
Epoch 3/10, Batch 40/145, Loss: 0.1594
Epoch 3/10, Batch 50/145, Loss: 0.2328
Epoch 3/10, Batch 60/145, Loss: 0.2955
Epoch 3/10, Batch 70/145, Loss: 0.4707
Epoch 3/10, Batch 80/145, Loss: 0.2367
Epoch 3/10, Batch 90/145, Loss: 0.2647
Epoch 3/10, Batch 100/145, Loss: 0.2644
Epoch 3/10, Batch 110/145, Loss: 0.3109
Epoch 3/10, Batch 120/145, Loss: 0.3196
Epoch 3/10, Batch 130/145, Loss: 0.2435
Epoch 3/10, Batch 140/145, Loss: 0.3810
Epoch 3/10, Train Loss: 0.2994, Valid Loss: 0.2515
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2097
Epoch 4/10, Batch 20/145, Loss: 0.4191
Epoch 4/10, Batch 30/145, Loss: 0.2914
Epoch 4/10, Batch 40/145, Loss: 0.2071
Epoch 4/10, Batch 50/145, Loss: 0.1727
Epoch 4/10, Batch 60/145, Loss: 0.3189
Epoch 4/10, Batch 70/145, Loss: 0.1850
Epoch 4/10, Batch 80/145, Loss: 0.1966
Epoch 4/10, Batch 90/145, Loss: 0.3688
Epoch 4/10, Batch 100/145, Loss: 0.3740
Epoch 4/10, Batch 110/145, Loss: 0.1209
Epoch 4/10, Batch 120/145, Loss: 0.2653
Epoch 4/10, Batch 130/145, Loss: 0.2480
Epoch 4/10, Batch 140/145, Loss: 0.1445
Epoch 4/10, Train Loss: 0.2645, Valid Loss: 0.2442
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1322
Epoch 5/10, Batch 20/145, Loss: 0.1678
Epoch 5/10, Batch 30/145, Loss: 0.3218
Epoch 5/10, Batch 40/145, Loss: 0.1566
Epoch 5/10, Batch 50/145, Loss: 0.2533
Epoch 5/10, Batch 60/145, Loss: 0.3034
Epoch 5/10, Batch 70/145, Loss: 0.2212
Epoch 5/10, Batch 80/145, Loss: 0.4233
Epoch 5/10, Batch 90/145, Loss: 0.2188
Epoch 5/10, Batch 100/145, Loss: 0.1956
Epoch 5/10, Batch 110/145, Loss: 0.2253
Epoch 5/10, Batch 120/145, Loss: 0.3779
Epoch 5/10, Batch 130/145, Loss: 0.1165
Epoch 5/10, Batch 140/145, Loss: 0.2201
Epoch 5/10, Train Loss: 0.2490, Valid Loss: 0.2258
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1632
Epoch 6/10, Batch 20/145, Loss: 0.3774
Epoch 6/10, Batch 30/145, Loss: 0.1908
Epoch 6/10, Batch 40/145, Loss: 0.1814
Epoch 6/10, Batch 50/145, Loss: 0.1853
Epoch 6/10, Batch 60/145, Loss: 0.2536
Epoch 6/10, Batch 70/145, Loss: 0.1062
Epoch 6/10, Batch 80/145, Loss: 0.0708
Epoch 6/10, Batch 90/145, Loss: 0.2187
Epoch 6/10, Batch 100/145, Loss: 0.3051
Epoch 6/10, Batch 110/145, Loss: 0.3380
Epoch 6/10, Batch 120/145, Loss: 0.2665
Epoch 6/10, Batch 130/145, Loss: 0.1749
Epoch 6/10, Batch 140/145, Loss: 0.0896
Epoch 6/10, Train Loss: 0.2305, Valid Loss: 0.2192
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3463
Epoch 7/10, Batch 20/145, Loss: 0.2724
Epoch 7/10, Batch 30/145, Loss: 0.2233
Epoch 7/10, Batch 40/145, Loss: 0.3187
Epoch 7/10, Batch 50/145, Loss: 0.1415
Epoch 7/10, Batch 60/145, Loss: 0.0855
Epoch 7/10, Batch 70/145, Loss: 0.2737
Epoch 7/10, Batch 80/145, Loss: 0.3834
Epoch 7/10, Batch 90/145, Loss: 0.1761
Epoch 7/10, Batch 100/145, Loss: 0.1256
Epoch 7/10, Batch 110/145, Loss: 0.1230
Epoch 7/10, Batch 120/145, Loss: 0.1128
Epoch 7/10, Batch 130/145, Loss: 0.1916
Epoch 7/10, Batch 140/145, Loss: 0.3988
Epoch 7/10, Train Loss: 0.2186, Valid Loss: 0.2080
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1789
Epoch 8/10, Batch 20/145, Loss: 0.1349
Epoch 8/10, Batch 30/145, Loss: 0.2161
Epoch 8/10, Batch 40/145, Loss: 0.2010
Epoch 8/10, Batch 50/145, Loss: 0.2440
Epoch 8/10, Batch 60/145, Loss: 0.2240
Epoch 8/10, Batch 70/145, Loss: 0.5434
Epoch 8/10, Batch 80/145, Loss: 0.2568
Epoch 8/10, Batch 90/145, Loss: 0.3057
Epoch 8/10, Batch 100/145, Loss: 0.3741
Epoch 8/10, Batch 110/145, Loss: 0.2526
Epoch 8/10, Batch 120/145, Loss: 0.1551
Epoch 8/10, Batch 130/145, Loss: 0.1996
Epoch 8/10, Batch 140/145, Loss: 0.1801
Epoch 8/10, Train Loss: 0.2180, Valid Loss: 0.2055
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2750
Epoch 9/10, Batch 20/145, Loss: 0.3177
Epoch 9/10, Batch 30/145, Loss: 0.1426
Epoch 9/10, Batch 40/145, Loss: 0.4263
Epoch 9/10, Batch 50/145, Loss: 0.1352
Epoch 9/10, Batch 60/145, Loss: 0.3510
Epoch 9/10, Batch 70/145, Loss: 0.0900
Epoch 9/10, Batch 80/145, Loss: 0.1232
Epoch 9/10, Batch 90/145, Loss: 0.1996
Epoch 9/10, Batch 100/145, Loss: 0.2140
Epoch 9/10, Batch 110/145, Loss: 0.2769
Epoch 9/10, Batch 120/145, Loss: 0.0353
Epoch 9/10, Batch 130/145, Loss: 0.1991
Epoch 9/10, Batch 140/145, Loss: 0.1463
Epoch 9/10, Train Loss: 0.2060, Valid Loss: 0.2018
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1419
Epoch 10/10, Batch 20/145, Loss: 0.1798
Epoch 10/10, Batch 30/145, Loss: 0.2407
Epoch 10/10, Batch 40/145, Loss: 0.1075
Epoch 10/10, Batch 50/145, Loss: 0.1696
Epoch 10/10, Batch 60/145, Loss: 0.1150
Epoch 10/10, Batch 70/145, Loss: 0.1698
Epoch 10/10, Batch 80/145, Loss: 0.1876
Epoch 10/10, Batch 90/145, Loss: 0.0708
Epoch 10/10, Batch 100/145, Loss: 0.1429
Epoch 10/10, Batch 110/145, Loss: 0.1833
Epoch 10/10, Batch 120/145, Loss: 0.2523
Epoch 10/10, Batch 130/145, Loss: 0.2364
Epoch 10/10, Batch 140/145, Loss: 0.1944
Epoch 10/10, Train Loss: 0.1933, Valid Loss: 0.1965
Model saved!
Accuracy: 0.9159
Precision: 0.9133
Recall: 0.9159
F1-score: 0.9139
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4859
Epoch 1/10, Batch 20/145, Loss: 0.9542
Epoch 1/10, Batch 30/145, Loss: 0.8444
Epoch 1/10, Batch 40/145, Loss: 0.8174
Epoch 1/10, Batch 50/145, Loss: 0.7287
Epoch 1/10, Batch 60/145, Loss: 0.6772
Epoch 1/10, Batch 70/145, Loss: 0.4057
Epoch 1/10, Batch 80/145, Loss: 0.6694
Epoch 1/10, Batch 90/145, Loss: 0.3849
Epoch 1/10, Batch 100/145, Loss: 0.4925
Epoch 1/10, Batch 110/145, Loss: 0.5440
Epoch 1/10, Batch 120/145, Loss: 0.7702
Epoch 1/10, Batch 130/145, Loss: 0.4914
Epoch 1/10, Batch 140/145, Loss: 0.3406
Epoch 1/10, Train Loss: 0.6807, Valid Loss: 0.3632
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4145
Epoch 2/10, Batch 20/145, Loss: 0.3179
Epoch 2/10, Batch 30/145, Loss: 0.4326
Epoch 2/10, Batch 40/145, Loss: 0.4596
Epoch 2/10, Batch 50/145, Loss: 0.2200
Epoch 2/10, Batch 60/145, Loss: 0.3384
Epoch 2/10, Batch 70/145, Loss: 0.2888
Epoch 2/10, Batch 80/145, Loss: 0.3265
Epoch 2/10, Batch 90/145, Loss: 0.2336
Epoch 2/10, Batch 100/145, Loss: 0.3057
Epoch 2/10, Batch 110/145, Loss: 0.2460
Epoch 2/10, Batch 120/145, Loss: 0.3411
Epoch 2/10, Batch 130/145, Loss: 0.2106
Epoch 2/10, Batch 140/145, Loss: 0.2891
Epoch 2/10, Train Loss: 0.3581, Valid Loss: 0.2727
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2843
Epoch 3/10, Batch 20/145, Loss: 0.3180
Epoch 3/10, Batch 30/145, Loss: 0.3263
Epoch 3/10, Batch 40/145, Loss: 0.3305
Epoch 3/10, Batch 50/145, Loss: 0.3386
Epoch 3/10, Batch 60/145, Loss: 0.3286
Epoch 3/10, Batch 70/145, Loss: 0.3564
Epoch 3/10, Batch 80/145, Loss: 0.2178
Epoch 3/10, Batch 90/145, Loss: 0.2079
Epoch 3/10, Batch 100/145, Loss: 0.2830
Epoch 3/10, Batch 110/145, Loss: 0.2335
Epoch 3/10, Batch 120/145, Loss: 0.3188
Epoch 3/10, Batch 130/145, Loss: 0.3424
Epoch 3/10, Batch 140/145, Loss: 0.3401
Epoch 3/10, Train Loss: 0.2920, Valid Loss: 0.2405
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2399
Epoch 4/10, Batch 20/145, Loss: 0.3164
Epoch 4/10, Batch 30/145, Loss: 0.2763
Epoch 4/10, Batch 40/145, Loss: 0.2898
Epoch 4/10, Batch 50/145, Loss: 0.1602
Epoch 4/10, Batch 60/145, Loss: 0.3229
Epoch 4/10, Batch 70/145, Loss: 0.2871
Epoch 4/10, Batch 80/145, Loss: 0.4313
Epoch 4/10, Batch 90/145, Loss: 0.3583
Epoch 4/10, Batch 100/145, Loss: 0.2374
Epoch 4/10, Batch 110/145, Loss: 0.1529
Epoch 4/10, Batch 120/145, Loss: 0.2038
Epoch 4/10, Batch 130/145, Loss: 0.1952
Epoch 4/10, Batch 140/145, Loss: 0.2172
Epoch 4/10, Train Loss: 0.2613, Valid Loss: 0.2284
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2306
Epoch 5/10, Batch 20/145, Loss: 0.1232
Epoch 5/10, Batch 30/145, Loss: 0.1751
Epoch 5/10, Batch 40/145, Loss: 0.3561
Epoch 5/10, Batch 50/145, Loss: 0.1271
Epoch 5/10, Batch 60/145, Loss: 0.2169
Epoch 5/10, Batch 70/145, Loss: 0.4458
Epoch 5/10, Batch 80/145, Loss: 0.1930
Epoch 5/10, Batch 90/145, Loss: 0.3951
Epoch 5/10, Batch 100/145, Loss: 0.1992
Epoch 5/10, Batch 110/145, Loss: 0.1987
Epoch 5/10, Batch 120/145, Loss: 0.2436
Epoch 5/10, Batch 130/145, Loss: 0.1615
Epoch 5/10, Batch 140/145, Loss: 0.1683
Epoch 5/10, Train Loss: 0.2511, Valid Loss: 0.2222
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1180
Epoch 6/10, Batch 20/145, Loss: 0.4598
Epoch 6/10, Batch 30/145, Loss: 0.3775
Epoch 6/10, Batch 40/145, Loss: 0.2214
Epoch 6/10, Batch 50/145, Loss: 0.3811
Epoch 6/10, Batch 60/145, Loss: 0.1900
Epoch 6/10, Batch 70/145, Loss: 0.1716
Epoch 6/10, Batch 80/145, Loss: 0.1846
Epoch 6/10, Batch 90/145, Loss: 0.3797
Epoch 6/10, Batch 100/145, Loss: 0.1982
Epoch 6/10, Batch 110/145, Loss: 0.1289
Epoch 6/10, Batch 120/145, Loss: 0.3744
Epoch 6/10, Batch 130/145, Loss: 0.2541
Epoch 6/10, Batch 140/145, Loss: 0.1483
Epoch 6/10, Train Loss: 0.2340, Valid Loss: 0.2081
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2379
Epoch 7/10, Batch 20/145, Loss: 0.2901
Epoch 7/10, Batch 30/145, Loss: 0.2111
Epoch 7/10, Batch 40/145, Loss: 0.3115
Epoch 7/10, Batch 50/145, Loss: 0.2217
Epoch 7/10, Batch 60/145, Loss: 0.2702
Epoch 7/10, Batch 70/145, Loss: 0.1877
Epoch 7/10, Batch 80/145, Loss: 0.3041
Epoch 7/10, Batch 90/145, Loss: 0.2176
Epoch 7/10, Batch 100/145, Loss: 0.1973
Epoch 7/10, Batch 110/145, Loss: 0.1323
Epoch 7/10, Batch 120/145, Loss: 0.1981
Epoch 7/10, Batch 130/145, Loss: 0.1171
Epoch 7/10, Batch 140/145, Loss: 0.2576
Epoch 7/10, Train Loss: 0.2171, Valid Loss: 0.2062
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2868
Epoch 8/10, Batch 20/145, Loss: 0.3013
Epoch 8/10, Batch 30/145, Loss: 0.1811
Epoch 8/10, Batch 40/145, Loss: 0.0689
Epoch 8/10, Batch 50/145, Loss: 0.2256
Epoch 8/10, Batch 60/145, Loss: 0.2008
Epoch 8/10, Batch 70/145, Loss: 0.4173
Epoch 8/10, Batch 80/145, Loss: 0.1229
Epoch 8/10, Batch 90/145, Loss: 0.3277
Epoch 8/10, Batch 100/145, Loss: 0.1590
Epoch 8/10, Batch 110/145, Loss: 0.1117
Epoch 8/10, Batch 120/145, Loss: 0.1703
Epoch 8/10, Batch 130/145, Loss: 0.1984
Epoch 8/10, Batch 140/145, Loss: 0.1278
Epoch 8/10, Train Loss: 0.2147, Valid Loss: 0.1992
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2217
Epoch 9/10, Batch 20/145, Loss: 0.2089
Epoch 9/10, Batch 30/145, Loss: 0.2532
Epoch 9/10, Batch 40/145, Loss: 0.1865
Epoch 9/10, Batch 50/145, Loss: 0.1765
Epoch 9/10, Batch 60/145, Loss: 0.3316
Epoch 9/10, Batch 70/145, Loss: 0.1067
Epoch 9/10, Batch 80/145, Loss: 0.1680
Epoch 9/10, Batch 90/145, Loss: 0.1966
Epoch 9/10, Batch 100/145, Loss: 0.1385
Epoch 9/10, Batch 110/145, Loss: 0.2144
Epoch 9/10, Batch 120/145, Loss: 0.1189
Epoch 9/10, Batch 130/145, Loss: 0.1892
Epoch 9/10, Batch 140/145, Loss: 0.1691
Epoch 9/10, Train Loss: 0.2017, Valid Loss: 0.1973
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0997
Epoch 10/10, Batch 20/145, Loss: 0.1371
Epoch 10/10, Batch 30/145, Loss: 0.0656
Epoch 10/10, Batch 40/145, Loss: 0.1235
Epoch 10/10, Batch 50/145, Loss: 0.1672
Epoch 10/10, Batch 60/145, Loss: 0.2662
Epoch 10/10, Batch 70/145, Loss: 0.1802
Epoch 10/10, Batch 80/145, Loss: 0.1387
Epoch 10/10, Batch 90/145, Loss: 0.2556
Epoch 10/10, Batch 100/145, Loss: 0.0940
Epoch 10/10, Batch 110/145, Loss: 0.1456
Epoch 10/10, Batch 120/145, Loss: 0.1739
Epoch 10/10, Batch 130/145, Loss: 0.2249
Epoch 10/10, Batch 140/145, Loss: 0.2273
Epoch 10/10, Train Loss: 0.1915, Valid Loss: 0.1986
Accuracy: 0.9171
Precision: 0.9150
Recall: 0.9171
F1-score: 0.9157
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3883
Epoch 1/10, Batch 20/145, Loss: 0.9597
Epoch 1/10, Batch 30/145, Loss: 0.9827
Epoch 1/10, Batch 40/145, Loss: 0.7258
Epoch 1/10, Batch 50/145, Loss: 0.8467
Epoch 1/10, Batch 60/145, Loss: 0.7317
Epoch 1/10, Batch 70/145, Loss: 0.5315
Epoch 1/10, Batch 80/145, Loss: 0.5374
Epoch 1/10, Batch 90/145, Loss: 0.3420
Epoch 1/10, Batch 100/145, Loss: 0.4936
Epoch 1/10, Batch 110/145, Loss: 0.3240
Epoch 1/10, Batch 120/145, Loss: 0.6894
Epoch 1/10, Batch 130/145, Loss: 0.3611
Epoch 1/10, Batch 140/145, Loss: 0.3448
Epoch 1/10, Train Loss: 0.6773, Valid Loss: 0.3731
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3401
Epoch 2/10, Batch 20/145, Loss: 0.3457
Epoch 2/10, Batch 30/145, Loss: 0.2704
Epoch 2/10, Batch 40/145, Loss: 0.4187
Epoch 2/10, Batch 50/145, Loss: 0.3688
Epoch 2/10, Batch 60/145, Loss: 0.3834
Epoch 2/10, Batch 70/145, Loss: 0.3023
Epoch 2/10, Batch 80/145, Loss: 0.2564
Epoch 2/10, Batch 90/145, Loss: 0.2689
Epoch 2/10, Batch 100/145, Loss: 0.3694
Epoch 2/10, Batch 110/145, Loss: 0.4555
Epoch 2/10, Batch 120/145, Loss: 0.5205
Epoch 2/10, Batch 130/145, Loss: 0.1991
Epoch 2/10, Batch 140/145, Loss: 0.2182
Epoch 2/10, Train Loss: 0.3487, Valid Loss: 0.2898
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2791
Epoch 3/10, Batch 20/145, Loss: 0.1647
Epoch 3/10, Batch 30/145, Loss: 0.4723
Epoch 3/10, Batch 40/145, Loss: 0.2067
Epoch 3/10, Batch 50/145, Loss: 0.1982
Epoch 3/10, Batch 60/145, Loss: 0.1697
Epoch 3/10, Batch 70/145, Loss: 0.5381
Epoch 3/10, Batch 80/145, Loss: 0.1746
Epoch 3/10, Batch 90/145, Loss: 0.2764
Epoch 3/10, Batch 100/145, Loss: 0.2969
Epoch 3/10, Batch 110/145, Loss: 0.1990
Epoch 3/10, Batch 120/145, Loss: 0.2054
Epoch 3/10, Batch 130/145, Loss: 0.3001
Epoch 3/10, Batch 140/145, Loss: 0.3199
Epoch 3/10, Train Loss: 0.2937, Valid Loss: 0.2683
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2196
Epoch 4/10, Batch 20/145, Loss: 0.2789
Epoch 4/10, Batch 30/145, Loss: 0.4573
Epoch 4/10, Batch 40/145, Loss: 0.1300
Epoch 4/10, Batch 50/145, Loss: 0.1499
Epoch 4/10, Batch 60/145, Loss: 0.2544
Epoch 4/10, Batch 70/145, Loss: 0.3074
Epoch 4/10, Batch 80/145, Loss: 0.2117
Epoch 4/10, Batch 90/145, Loss: 0.1728
Epoch 4/10, Batch 100/145, Loss: 0.2015
Epoch 4/10, Batch 110/145, Loss: 0.1591
Epoch 4/10, Batch 120/145, Loss: 0.2232
Epoch 4/10, Batch 130/145, Loss: 0.1389
Epoch 4/10, Batch 140/145, Loss: 0.1795
Epoch 4/10, Train Loss: 0.2551, Valid Loss: 0.2480
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1949
Epoch 5/10, Batch 20/145, Loss: 0.0789
Epoch 5/10, Batch 30/145, Loss: 0.3337
Epoch 5/10, Batch 40/145, Loss: 0.1967
Epoch 5/10, Batch 50/145, Loss: 0.3207
Epoch 5/10, Batch 60/145, Loss: 0.1364
Epoch 5/10, Batch 70/145, Loss: 0.1831
Epoch 5/10, Batch 80/145, Loss: 0.2824
Epoch 5/10, Batch 90/145, Loss: 0.3688
Epoch 5/10, Batch 100/145, Loss: 0.1646
Epoch 5/10, Batch 110/145, Loss: 0.2413
Epoch 5/10, Batch 120/145, Loss: 0.2748
Epoch 5/10, Batch 130/145, Loss: 0.1842
Epoch 5/10, Batch 140/145, Loss: 0.1078
Epoch 5/10, Train Loss: 0.2408, Valid Loss: 0.2359
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1115
Epoch 6/10, Batch 20/145, Loss: 0.3580
Epoch 6/10, Batch 30/145, Loss: 0.3145
Epoch 6/10, Batch 40/145, Loss: 0.0953
Epoch 6/10, Batch 50/145, Loss: 0.3899
Epoch 6/10, Batch 60/145, Loss: 0.1346
Epoch 6/10, Batch 70/145, Loss: 0.1760
Epoch 6/10, Batch 80/145, Loss: 0.2702
Epoch 6/10, Batch 90/145, Loss: 0.2232
Epoch 6/10, Batch 100/145, Loss: 0.2081
Epoch 6/10, Batch 110/145, Loss: 0.1994
Epoch 6/10, Batch 120/145, Loss: 0.1035
Epoch 6/10, Batch 130/145, Loss: 0.2579
Epoch 6/10, Batch 140/145, Loss: 0.3934
Epoch 6/10, Train Loss: 0.2181, Valid Loss: 0.2263
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1553
Epoch 7/10, Batch 20/145, Loss: 0.2343
Epoch 7/10, Batch 30/145, Loss: 0.4222
Epoch 7/10, Batch 40/145, Loss: 0.3869
Epoch 7/10, Batch 50/145, Loss: 0.3043
Epoch 7/10, Batch 60/145, Loss: 0.1865
Epoch 7/10, Batch 70/145, Loss: 0.4246
Epoch 7/10, Batch 80/145, Loss: 0.4464
Epoch 7/10, Batch 90/145, Loss: 0.2367
Epoch 7/10, Batch 100/145, Loss: 0.0781
Epoch 7/10, Batch 110/145, Loss: 0.1223
Epoch 7/10, Batch 120/145, Loss: 0.2330
Epoch 7/10, Batch 130/145, Loss: 0.0836
Epoch 7/10, Batch 140/145, Loss: 0.3233
Epoch 7/10, Train Loss: 0.2007, Valid Loss: 0.2332
Epoch 8/10, Batch 10/145, Loss: 0.2784
Epoch 8/10, Batch 20/145, Loss: 0.1569
Epoch 8/10, Batch 30/145, Loss: 0.1836
Epoch 8/10, Batch 40/145, Loss: 0.1495
Epoch 8/10, Batch 50/145, Loss: 0.1598
Epoch 8/10, Batch 60/145, Loss: 0.2642
Epoch 8/10, Batch 70/145, Loss: 0.2396
Epoch 8/10, Batch 80/145, Loss: 0.3388
Epoch 8/10, Batch 90/145, Loss: 0.2765
Epoch 8/10, Batch 100/145, Loss: 0.1094
Epoch 8/10, Batch 110/145, Loss: 0.2325
Epoch 8/10, Batch 120/145, Loss: 0.2225
Epoch 8/10, Batch 130/145, Loss: 0.1709
Epoch 8/10, Batch 140/145, Loss: 0.1736
Epoch 8/10, Train Loss: 0.2004, Valid Loss: 0.2227
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2513
Epoch 9/10, Batch 20/145, Loss: 0.1358
Epoch 9/10, Batch 30/145, Loss: 0.1103
Epoch 9/10, Batch 40/145, Loss: 0.1584
Epoch 9/10, Batch 50/145, Loss: 0.1203
Epoch 9/10, Batch 60/145, Loss: 0.1612
Epoch 9/10, Batch 70/145, Loss: 0.1646
Epoch 9/10, Batch 80/145, Loss: 0.1408
Epoch 9/10, Batch 90/145, Loss: 0.2253
Epoch 9/10, Batch 100/145, Loss: 0.2083
Epoch 9/10, Batch 110/145, Loss: 0.2946
Epoch 9/10, Batch 120/145, Loss: 0.1891
Epoch 9/10, Batch 130/145, Loss: 0.1363
Epoch 9/10, Batch 140/145, Loss: 0.2902
Epoch 9/10, Train Loss: 0.1910, Valid Loss: 0.2167
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0847
Epoch 10/10, Batch 20/145, Loss: 0.1355
Epoch 10/10, Batch 30/145, Loss: 0.1741
Epoch 10/10, Batch 40/145, Loss: 0.2998
Epoch 10/10, Batch 50/145, Loss: 0.2997
Epoch 10/10, Batch 60/145, Loss: 0.1304
Epoch 10/10, Batch 70/145, Loss: 0.1316
Epoch 10/10, Batch 80/145, Loss: 0.1913
Epoch 10/10, Batch 90/145, Loss: 0.0708
Epoch 10/10, Batch 100/145, Loss: 0.3179
Epoch 10/10, Batch 110/145, Loss: 0.2316
Epoch 10/10, Batch 120/145, Loss: 0.1614
Epoch 10/10, Batch 130/145, Loss: 0.1032
Epoch 10/10, Batch 140/145, Loss: 0.2493
Epoch 10/10, Train Loss: 0.1892, Valid Loss: 0.2262
Accuracy: 0.9206
Precision: 0.9185
Recall: 0.9206
F1-score: 0.9192
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3777
Epoch 1/10, Batch 20/145, Loss: 0.9619
Epoch 1/10, Batch 30/145, Loss: 0.9522
Epoch 1/10, Batch 40/145, Loss: 0.7917
Epoch 1/10, Batch 50/145, Loss: 0.6883
Epoch 1/10, Batch 60/145, Loss: 0.6967
Epoch 1/10, Batch 70/145, Loss: 0.5036
Epoch 1/10, Batch 80/145, Loss: 0.5704
Epoch 1/10, Batch 90/145, Loss: 0.4229
Epoch 1/10, Batch 100/145, Loss: 0.4909
Epoch 1/10, Batch 110/145, Loss: 0.4788
Epoch 1/10, Batch 120/145, Loss: 0.4314
Epoch 1/10, Batch 130/145, Loss: 0.5507
Epoch 1/10, Batch 140/145, Loss: 0.2841
Epoch 1/10, Train Loss: 0.6811, Valid Loss: 0.3808
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2961
Epoch 2/10, Batch 20/145, Loss: 0.3009
Epoch 2/10, Batch 30/145, Loss: 0.3577
Epoch 2/10, Batch 40/145, Loss: 0.4139
Epoch 2/10, Batch 50/145, Loss: 0.3969
Epoch 2/10, Batch 60/145, Loss: 0.4064
Epoch 2/10, Batch 70/145, Loss: 0.3904
Epoch 2/10, Batch 80/145, Loss: 0.2665
Epoch 2/10, Batch 90/145, Loss: 0.2415
Epoch 2/10, Batch 100/145, Loss: 0.3397
Epoch 2/10, Batch 110/145, Loss: 0.3116
Epoch 2/10, Batch 120/145, Loss: 0.3477
Epoch 2/10, Batch 130/145, Loss: 0.2419
Epoch 2/10, Batch 140/145, Loss: 0.3605
Epoch 2/10, Train Loss: 0.3531, Valid Loss: 0.2962
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1535
Epoch 3/10, Batch 20/145, Loss: 0.2410
Epoch 3/10, Batch 30/145, Loss: 0.3853
Epoch 3/10, Batch 40/145, Loss: 0.2762
Epoch 3/10, Batch 50/145, Loss: 0.1996
Epoch 3/10, Batch 60/145, Loss: 0.5487
Epoch 3/10, Batch 70/145, Loss: 0.3784
Epoch 3/10, Batch 80/145, Loss: 0.3202
Epoch 3/10, Batch 90/145, Loss: 0.4931
Epoch 3/10, Batch 100/145, Loss: 0.2071
Epoch 3/10, Batch 110/145, Loss: 0.2041
Epoch 3/10, Batch 120/145, Loss: 0.1603
Epoch 3/10, Batch 130/145, Loss: 0.4555
Epoch 3/10, Batch 140/145, Loss: 0.1827
Epoch 3/10, Train Loss: 0.2940, Valid Loss: 0.2643
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3484
Epoch 4/10, Batch 20/145, Loss: 0.4363
Epoch 4/10, Batch 30/145, Loss: 0.3280
Epoch 4/10, Batch 40/145, Loss: 0.1400
Epoch 4/10, Batch 50/145, Loss: 0.1318
Epoch 4/10, Batch 60/145, Loss: 0.1963
Epoch 4/10, Batch 70/145, Loss: 0.1818
Epoch 4/10, Batch 80/145, Loss: 0.1220
Epoch 4/10, Batch 90/145, Loss: 0.2616
Epoch 4/10, Batch 100/145, Loss: 0.2723
Epoch 4/10, Batch 110/145, Loss: 0.0964
Epoch 4/10, Batch 120/145, Loss: 0.1362
Epoch 4/10, Batch 130/145, Loss: 0.2580
Epoch 4/10, Batch 140/145, Loss: 0.1744
Epoch 4/10, Train Loss: 0.2599, Valid Loss: 0.2490
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1408
Epoch 5/10, Batch 20/145, Loss: 0.1680
Epoch 5/10, Batch 30/145, Loss: 0.2216
Epoch 5/10, Batch 40/145, Loss: 0.3249
Epoch 5/10, Batch 50/145, Loss: 0.2567
Epoch 5/10, Batch 60/145, Loss: 0.2295
Epoch 5/10, Batch 70/145, Loss: 0.0988
Epoch 5/10, Batch 80/145, Loss: 0.1418
Epoch 5/10, Batch 90/145, Loss: 0.2113
Epoch 5/10, Batch 100/145, Loss: 0.2549
Epoch 5/10, Batch 110/145, Loss: 0.3091
Epoch 5/10, Batch 120/145, Loss: 0.3569
Epoch 5/10, Batch 130/145, Loss: 0.2036
Epoch 5/10, Batch 140/145, Loss: 0.2906
Epoch 5/10, Train Loss: 0.2444, Valid Loss: 0.2452
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2189
Epoch 6/10, Batch 20/145, Loss: 0.5074
Epoch 6/10, Batch 30/145, Loss: 0.2375
Epoch 6/10, Batch 40/145, Loss: 0.1479
Epoch 6/10, Batch 50/145, Loss: 0.3582
Epoch 6/10, Batch 60/145, Loss: 0.3201
Epoch 6/10, Batch 70/145, Loss: 0.1770
Epoch 6/10, Batch 80/145, Loss: 0.1455
Epoch 6/10, Batch 90/145, Loss: 0.2761
Epoch 6/10, Batch 100/145, Loss: 0.4679
Epoch 6/10, Batch 110/145, Loss: 0.2116
Epoch 6/10, Batch 120/145, Loss: 0.2012
Epoch 6/10, Batch 130/145, Loss: 0.3842
Epoch 6/10, Batch 140/145, Loss: 0.2623
Epoch 6/10, Train Loss: 0.2312, Valid Loss: 0.2248
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1287
Epoch 7/10, Batch 20/145, Loss: 0.4180
Epoch 7/10, Batch 30/145, Loss: 0.1719
Epoch 7/10, Batch 40/145, Loss: 0.2153
Epoch 7/10, Batch 50/145, Loss: 0.2049
Epoch 7/10, Batch 60/145, Loss: 0.1254
Epoch 7/10, Batch 70/145, Loss: 0.2357
Epoch 7/10, Batch 80/145, Loss: 0.2804
Epoch 7/10, Batch 90/145, Loss: 0.1741
Epoch 7/10, Batch 100/145, Loss: 0.1723
Epoch 7/10, Batch 110/145, Loss: 0.1269
Epoch 7/10, Batch 120/145, Loss: 0.2857
Epoch 7/10, Batch 130/145, Loss: 0.1076
Epoch 7/10, Batch 140/145, Loss: 0.1743
Epoch 7/10, Train Loss: 0.2180, Valid Loss: 0.2244
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2165
Epoch 8/10, Batch 20/145, Loss: 0.2325
Epoch 8/10, Batch 30/145, Loss: 0.1963
Epoch 8/10, Batch 40/145, Loss: 0.2310
Epoch 8/10, Batch 50/145, Loss: 0.1369
Epoch 8/10, Batch 60/145, Loss: 0.1850
Epoch 8/10, Batch 70/145, Loss: 0.1952
Epoch 8/10, Batch 80/145, Loss: 0.1574
Epoch 8/10, Batch 90/145, Loss: 0.2323
Epoch 8/10, Batch 100/145, Loss: 0.1812
Epoch 8/10, Batch 110/145, Loss: 0.1875
Epoch 8/10, Batch 120/145, Loss: 0.1710
Epoch 8/10, Batch 130/145, Loss: 0.2862
Epoch 8/10, Batch 140/145, Loss: 0.1711
Epoch 8/10, Train Loss: 0.2077, Valid Loss: 0.2153
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.4532
Epoch 9/10, Batch 20/145, Loss: 0.1757
Epoch 9/10, Batch 30/145, Loss: 0.1510
Epoch 9/10, Batch 40/145, Loss: 0.2645
Epoch 9/10, Batch 50/145, Loss: 0.1709
Epoch 9/10, Batch 60/145, Loss: 0.1475
Epoch 9/10, Batch 70/145, Loss: 0.2015
Epoch 9/10, Batch 80/145, Loss: 0.1152
Epoch 9/10, Batch 90/145, Loss: 0.2125
Epoch 9/10, Batch 100/145, Loss: 0.1196
Epoch 9/10, Batch 110/145, Loss: 0.1570
Epoch 9/10, Batch 120/145, Loss: 0.1390
Epoch 9/10, Batch 130/145, Loss: 0.1624
Epoch 9/10, Batch 140/145, Loss: 0.2517
Epoch 9/10, Train Loss: 0.2035, Valid Loss: 0.2110
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0849
Epoch 10/10, Batch 20/145, Loss: 0.1579
Epoch 10/10, Batch 30/145, Loss: 0.1352
Epoch 10/10, Batch 40/145, Loss: 0.1051
Epoch 10/10, Batch 50/145, Loss: 0.3089
Epoch 10/10, Batch 60/145, Loss: 0.1420
Epoch 10/10, Batch 70/145, Loss: 0.3415
Epoch 10/10, Batch 80/145, Loss: 0.1115
Epoch 10/10, Batch 90/145, Loss: 0.1553
Epoch 10/10, Batch 100/145, Loss: 0.1263
Epoch 10/10, Batch 110/145, Loss: 0.1822
Epoch 10/10, Batch 120/145, Loss: 0.1102
Epoch 10/10, Batch 130/145, Loss: 0.2092
Epoch 10/10, Batch 140/145, Loss: 0.2361
Epoch 10/10, Train Loss: 0.1977, Valid Loss: 0.2103
Model saved!
Accuracy: 0.9229
Precision: 0.9207
Recall: 0.9229
F1-score: 0.9211
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4182
Epoch 1/10, Batch 20/145, Loss: 0.8528
Epoch 1/10, Batch 30/145, Loss: 0.8385
Epoch 1/10, Batch 40/145, Loss: 0.7511
Epoch 1/10, Batch 50/145, Loss: 0.7470
Epoch 1/10, Batch 60/145, Loss: 0.6277
Epoch 1/10, Batch 70/145, Loss: 0.4267
Epoch 1/10, Batch 80/145, Loss: 0.4917
Epoch 1/10, Batch 90/145, Loss: 0.5702
Epoch 1/10, Batch 100/145, Loss: 0.5928
Epoch 1/10, Batch 110/145, Loss: 0.3449
Epoch 1/10, Batch 120/145, Loss: 0.6824
Epoch 1/10, Batch 130/145, Loss: 0.6445
Epoch 1/10, Batch 140/145, Loss: 0.4617
Epoch 1/10, Train Loss: 0.6757, Valid Loss: 0.3887
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2804
Epoch 2/10, Batch 20/145, Loss: 0.3579
Epoch 2/10, Batch 30/145, Loss: 0.3269
Epoch 2/10, Batch 40/145, Loss: 0.3467
Epoch 2/10, Batch 50/145, Loss: 0.2572
Epoch 2/10, Batch 60/145, Loss: 0.3597
Epoch 2/10, Batch 70/145, Loss: 0.2765
Epoch 2/10, Batch 80/145, Loss: 0.3225
Epoch 2/10, Batch 90/145, Loss: 0.3760
Epoch 2/10, Batch 100/145, Loss: 0.3330
Epoch 2/10, Batch 110/145, Loss: 0.3524
Epoch 2/10, Batch 120/145, Loss: 0.3154
Epoch 2/10, Batch 130/145, Loss: 0.2223
Epoch 2/10, Batch 140/145, Loss: 0.2254
Epoch 2/10, Train Loss: 0.3477, Valid Loss: 0.3033
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2440
Epoch 3/10, Batch 20/145, Loss: 0.2053
Epoch 3/10, Batch 30/145, Loss: 0.4529
Epoch 3/10, Batch 40/145, Loss: 0.2085
Epoch 3/10, Batch 50/145, Loss: 0.2679
Epoch 3/10, Batch 60/145, Loss: 0.3879
Epoch 3/10, Batch 70/145, Loss: 0.4345
Epoch 3/10, Batch 80/145, Loss: 0.3113
Epoch 3/10, Batch 90/145, Loss: 0.3550
Epoch 3/10, Batch 100/145, Loss: 0.3225
Epoch 3/10, Batch 110/145, Loss: 0.3157
Epoch 3/10, Batch 120/145, Loss: 0.3409
Epoch 3/10, Batch 130/145, Loss: 0.4347
Epoch 3/10, Batch 140/145, Loss: 0.2857
Epoch 3/10, Train Loss: 0.2894, Valid Loss: 0.2680
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2812
Epoch 4/10, Batch 20/145, Loss: 0.2811
Epoch 4/10, Batch 30/145, Loss: 0.2341
Epoch 4/10, Batch 40/145, Loss: 0.2290
Epoch 4/10, Batch 50/145, Loss: 0.1414
Epoch 4/10, Batch 60/145, Loss: 0.3316
Epoch 4/10, Batch 70/145, Loss: 0.2372
Epoch 4/10, Batch 80/145, Loss: 0.2167
Epoch 4/10, Batch 90/145, Loss: 0.1998
Epoch 4/10, Batch 100/145, Loss: 0.3863
Epoch 4/10, Batch 110/145, Loss: 0.1237
Epoch 4/10, Batch 120/145, Loss: 0.2369
Epoch 4/10, Batch 130/145, Loss: 0.1761
Epoch 4/10, Batch 140/145, Loss: 0.1580
Epoch 4/10, Train Loss: 0.2569, Valid Loss: 0.2536
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2003
Epoch 5/10, Batch 20/145, Loss: 0.1919
Epoch 5/10, Batch 30/145, Loss: 0.3269
Epoch 5/10, Batch 40/145, Loss: 0.1785
Epoch 5/10, Batch 50/145, Loss: 0.1945
Epoch 5/10, Batch 60/145, Loss: 0.1657
Epoch 5/10, Batch 70/145, Loss: 0.1829
Epoch 5/10, Batch 80/145, Loss: 0.1532
Epoch 5/10, Batch 90/145, Loss: 0.2016
Epoch 5/10, Batch 100/145, Loss: 0.1484
Epoch 5/10, Batch 110/145, Loss: 0.2672
Epoch 5/10, Batch 120/145, Loss: 0.2224
Epoch 5/10, Batch 130/145, Loss: 0.1865
Epoch 5/10, Batch 140/145, Loss: 0.2748
Epoch 5/10, Train Loss: 0.2456, Valid Loss: 0.2421
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1877
Epoch 6/10, Batch 20/145, Loss: 0.5962
Epoch 6/10, Batch 30/145, Loss: 0.2693
Epoch 6/10, Batch 40/145, Loss: 0.1275
Epoch 6/10, Batch 50/145, Loss: 0.2197
Epoch 6/10, Batch 60/145, Loss: 0.2775
Epoch 6/10, Batch 70/145, Loss: 0.2073
Epoch 6/10, Batch 80/145, Loss: 0.4022
Epoch 6/10, Batch 90/145, Loss: 0.2928
Epoch 6/10, Batch 100/145, Loss: 0.3596
Epoch 6/10, Batch 110/145, Loss: 0.2634
Epoch 6/10, Batch 120/145, Loss: 0.3511
Epoch 6/10, Batch 130/145, Loss: 0.1817
Epoch 6/10, Batch 140/145, Loss: 0.1802
Epoch 6/10, Train Loss: 0.2284, Valid Loss: 0.2320
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1910
Epoch 7/10, Batch 20/145, Loss: 0.3627
Epoch 7/10, Batch 30/145, Loss: 0.1761
Epoch 7/10, Batch 40/145, Loss: 0.2103
Epoch 7/10, Batch 50/145, Loss: 0.1552
Epoch 7/10, Batch 60/145, Loss: 0.1322
Epoch 7/10, Batch 70/145, Loss: 0.1254
Epoch 7/10, Batch 80/145, Loss: 0.3072
Epoch 7/10, Batch 90/145, Loss: 0.2226
Epoch 7/10, Batch 100/145, Loss: 0.1749
Epoch 7/10, Batch 110/145, Loss: 0.0893
Epoch 7/10, Batch 120/145, Loss: 0.1701
Epoch 7/10, Batch 130/145, Loss: 0.1294
Epoch 7/10, Batch 140/145, Loss: 0.2122
Epoch 7/10, Train Loss: 0.2143, Valid Loss: 0.2260
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1260
Epoch 8/10, Batch 20/145, Loss: 0.1610
Epoch 8/10, Batch 30/145, Loss: 0.3869
Epoch 8/10, Batch 40/145, Loss: 0.1698
Epoch 8/10, Batch 50/145, Loss: 0.2996
Epoch 8/10, Batch 60/145, Loss: 0.1960
Epoch 8/10, Batch 70/145, Loss: 0.2621
Epoch 8/10, Batch 80/145, Loss: 0.1991
Epoch 8/10, Batch 90/145, Loss: 0.4424
Epoch 8/10, Batch 100/145, Loss: 0.1536
Epoch 8/10, Batch 110/145, Loss: 0.1377
Epoch 8/10, Batch 120/145, Loss: 0.2116
Epoch 8/10, Batch 130/145, Loss: 0.1497
Epoch 8/10, Batch 140/145, Loss: 0.3400
Epoch 8/10, Train Loss: 0.2057, Valid Loss: 0.2268
Epoch 9/10, Batch 10/145, Loss: 0.2907
Epoch 9/10, Batch 20/145, Loss: 0.2063
Epoch 9/10, Batch 30/145, Loss: 0.1406
Epoch 9/10, Batch 40/145, Loss: 0.2925
Epoch 9/10, Batch 50/145, Loss: 0.4008
Epoch 9/10, Batch 60/145, Loss: 0.0893
Epoch 9/10, Batch 70/145, Loss: 0.1304
Epoch 9/10, Batch 80/145, Loss: 0.0476
Epoch 9/10, Batch 90/145, Loss: 0.2131
Epoch 9/10, Batch 100/145, Loss: 0.2710
Epoch 9/10, Batch 110/145, Loss: 0.2987
Epoch 9/10, Batch 120/145, Loss: 0.1216
Epoch 9/10, Batch 130/145, Loss: 0.1507
Epoch 9/10, Batch 140/145, Loss: 0.2128
Epoch 9/10, Train Loss: 0.2025, Valid Loss: 0.2213
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2152
Epoch 10/10, Batch 20/145, Loss: 0.2012
Epoch 10/10, Batch 30/145, Loss: 0.2850
Epoch 10/10, Batch 40/145, Loss: 0.1543
Epoch 10/10, Batch 50/145, Loss: 0.2732
Epoch 10/10, Batch 60/145, Loss: 0.1834
Epoch 10/10, Batch 70/145, Loss: 0.2591
Epoch 10/10, Batch 80/145, Loss: 0.1737
Epoch 10/10, Batch 90/145, Loss: 0.1137
Epoch 10/10, Batch 100/145, Loss: 0.1940
Epoch 10/10, Batch 110/145, Loss: 0.2503
Epoch 10/10, Batch 120/145, Loss: 0.2158
Epoch 10/10, Batch 130/145, Loss: 0.1324
Epoch 10/10, Batch 140/145, Loss: 0.1829
Epoch 10/10, Train Loss: 0.1897, Valid Loss: 0.2204
Model saved!
Accuracy: 0.9241
Precision: 0.9217
Recall: 0.9241
F1-score: 0.9221
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4704
Epoch 1/10, Batch 20/145, Loss: 1.0358
Epoch 1/10, Batch 30/145, Loss: 0.9192
Epoch 1/10, Batch 40/145, Loss: 0.7298
Epoch 1/10, Batch 50/145, Loss: 0.7574
Epoch 1/10, Batch 60/145, Loss: 0.6892
Epoch 1/10, Batch 70/145, Loss: 0.4986
Epoch 1/10, Batch 80/145, Loss: 0.7339
Epoch 1/10, Batch 90/145, Loss: 0.5136
Epoch 1/10, Batch 100/145, Loss: 0.4664
Epoch 1/10, Batch 110/145, Loss: 0.3255
Epoch 1/10, Batch 120/145, Loss: 0.6639
Epoch 1/10, Batch 130/145, Loss: 0.5956
Epoch 1/10, Batch 140/145, Loss: 0.3951
Epoch 1/10, Train Loss: 0.6842, Valid Loss: 0.3825
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3042
Epoch 2/10, Batch 20/145, Loss: 0.2695
Epoch 2/10, Batch 30/145, Loss: 0.3309
Epoch 2/10, Batch 40/145, Loss: 0.6014
Epoch 2/10, Batch 50/145, Loss: 0.4026
Epoch 2/10, Batch 60/145, Loss: 0.2472
Epoch 2/10, Batch 70/145, Loss: 0.3478
Epoch 2/10, Batch 80/145, Loss: 0.3261
Epoch 2/10, Batch 90/145, Loss: 0.2417
Epoch 2/10, Batch 100/145, Loss: 0.4994
Epoch 2/10, Batch 110/145, Loss: 0.4241
Epoch 2/10, Batch 120/145, Loss: 0.2122
Epoch 2/10, Batch 130/145, Loss: 0.3748
Epoch 2/10, Batch 140/145, Loss: 0.3116
Epoch 2/10, Train Loss: 0.3553, Valid Loss: 0.2980
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.4095
Epoch 3/10, Batch 20/145, Loss: 0.2747
Epoch 3/10, Batch 30/145, Loss: 0.3536
Epoch 3/10, Batch 40/145, Loss: 0.2328
Epoch 3/10, Batch 50/145, Loss: 0.3852
Epoch 3/10, Batch 60/145, Loss: 0.2534
Epoch 3/10, Batch 70/145, Loss: 0.4711
Epoch 3/10, Batch 80/145, Loss: 0.1863
Epoch 3/10, Batch 90/145, Loss: 0.3251
Epoch 3/10, Batch 100/145, Loss: 0.2983
Epoch 3/10, Batch 110/145, Loss: 0.2620
Epoch 3/10, Batch 120/145, Loss: 0.1651
Epoch 3/10, Batch 130/145, Loss: 0.3470
Epoch 3/10, Batch 140/145, Loss: 0.2234
Epoch 3/10, Train Loss: 0.2957, Valid Loss: 0.2665
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2116
Epoch 4/10, Batch 20/145, Loss: 0.2924
Epoch 4/10, Batch 30/145, Loss: 0.3974
Epoch 4/10, Batch 40/145, Loss: 0.1842
Epoch 4/10, Batch 50/145, Loss: 0.1131
Epoch 4/10, Batch 60/145, Loss: 0.3495
Epoch 4/10, Batch 70/145, Loss: 0.2861
Epoch 4/10, Batch 80/145, Loss: 0.2740
Epoch 4/10, Batch 90/145, Loss: 0.2174
Epoch 4/10, Batch 100/145, Loss: 0.5304
Epoch 4/10, Batch 110/145, Loss: 0.1845
Epoch 4/10, Batch 120/145, Loss: 0.2459
Epoch 4/10, Batch 130/145, Loss: 0.1494
Epoch 4/10, Batch 140/145, Loss: 0.1914
Epoch 4/10, Train Loss: 0.2691, Valid Loss: 0.2607
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1503
Epoch 5/10, Batch 20/145, Loss: 0.1078
Epoch 5/10, Batch 30/145, Loss: 0.2345
Epoch 5/10, Batch 40/145, Loss: 0.1285
Epoch 5/10, Batch 50/145, Loss: 0.2010
Epoch 5/10, Batch 60/145, Loss: 0.1776
Epoch 5/10, Batch 70/145, Loss: 0.1962
Epoch 5/10, Batch 80/145, Loss: 0.0992
Epoch 5/10, Batch 90/145, Loss: 0.1570
Epoch 5/10, Batch 100/145, Loss: 0.1678
Epoch 5/10, Batch 110/145, Loss: 0.1800
Epoch 5/10, Batch 120/145, Loss: 0.5751
Epoch 5/10, Batch 130/145, Loss: 0.1921
Epoch 5/10, Batch 140/145, Loss: 0.2100
Epoch 5/10, Train Loss: 0.2470, Valid Loss: 0.2353
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2536
Epoch 6/10, Batch 20/145, Loss: 0.2794
Epoch 6/10, Batch 30/145, Loss: 0.2547
Epoch 6/10, Batch 40/145, Loss: 0.1930
Epoch 6/10, Batch 50/145, Loss: 0.2919
Epoch 6/10, Batch 60/145, Loss: 0.2893
Epoch 6/10, Batch 70/145, Loss: 0.1115
Epoch 6/10, Batch 80/145, Loss: 0.2077
Epoch 6/10, Batch 90/145, Loss: 0.1918
Epoch 6/10, Batch 100/145, Loss: 0.4607
Epoch 6/10, Batch 110/145, Loss: 0.3002
Epoch 6/10, Batch 120/145, Loss: 0.2435
Epoch 6/10, Batch 130/145, Loss: 0.2486
Epoch 6/10, Batch 140/145, Loss: 0.2517
Epoch 6/10, Train Loss: 0.2330, Valid Loss: 0.2312
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2479
Epoch 7/10, Batch 20/145, Loss: 0.1905
Epoch 7/10, Batch 30/145, Loss: 0.2515
Epoch 7/10, Batch 40/145, Loss: 0.2390
Epoch 7/10, Batch 50/145, Loss: 0.1447
Epoch 7/10, Batch 60/145, Loss: 0.1621
Epoch 7/10, Batch 70/145, Loss: 0.1806
Epoch 7/10, Batch 80/145, Loss: 0.2536
Epoch 7/10, Batch 90/145, Loss: 0.0895
Epoch 7/10, Batch 100/145, Loss: 0.2939
Epoch 7/10, Batch 110/145, Loss: 0.2778
Epoch 7/10, Batch 120/145, Loss: 0.1574
Epoch 7/10, Batch 130/145, Loss: 0.1597
Epoch 7/10, Batch 140/145, Loss: 0.2935
Epoch 7/10, Train Loss: 0.2168, Valid Loss: 0.2263
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1240
Epoch 8/10, Batch 20/145, Loss: 0.3954
Epoch 8/10, Batch 30/145, Loss: 0.2213
Epoch 8/10, Batch 40/145, Loss: 0.0790
Epoch 8/10, Batch 50/145, Loss: 0.2288
Epoch 8/10, Batch 60/145, Loss: 0.3603
Epoch 8/10, Batch 70/145, Loss: 0.3088
Epoch 8/10, Batch 80/145, Loss: 0.3515
Epoch 8/10, Batch 90/145, Loss: 0.2042
Epoch 8/10, Batch 100/145, Loss: 0.1308
Epoch 8/10, Batch 110/145, Loss: 0.2011
Epoch 8/10, Batch 120/145, Loss: 0.1670
Epoch 8/10, Batch 130/145, Loss: 0.3450
Epoch 8/10, Batch 140/145, Loss: 0.1652
Epoch 8/10, Train Loss: 0.2180, Valid Loss: 0.2267
Epoch 9/10, Batch 10/145, Loss: 0.2940
Epoch 9/10, Batch 20/145, Loss: 0.1925
Epoch 9/10, Batch 30/145, Loss: 0.1950
Epoch 9/10, Batch 40/145, Loss: 0.2936
Epoch 9/10, Batch 50/145, Loss: 0.1638
Epoch 9/10, Batch 60/145, Loss: 0.2310
Epoch 9/10, Batch 70/145, Loss: 0.1785
Epoch 9/10, Batch 80/145, Loss: 0.1417
Epoch 9/10, Batch 90/145, Loss: 0.1995
Epoch 9/10, Batch 100/145, Loss: 0.1208
Epoch 9/10, Batch 110/145, Loss: 0.2163
Epoch 9/10, Batch 120/145, Loss: 0.0956
Epoch 9/10, Batch 130/145, Loss: 0.2370
Epoch 9/10, Batch 140/145, Loss: 0.3440
Epoch 9/10, Train Loss: 0.2051, Valid Loss: 0.2139
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0896
Epoch 10/10, Batch 20/145, Loss: 0.0964
Epoch 10/10, Batch 30/145, Loss: 0.0566
Epoch 10/10, Batch 40/145, Loss: 0.1618
Epoch 10/10, Batch 50/145, Loss: 0.3191
Epoch 10/10, Batch 60/145, Loss: 0.1698
Epoch 10/10, Batch 70/145, Loss: 0.3010
Epoch 10/10, Batch 80/145, Loss: 0.2211
Epoch 10/10, Batch 90/145, Loss: 0.0840
Epoch 10/10, Batch 100/145, Loss: 0.2520
Epoch 10/10, Batch 110/145, Loss: 0.2313
Epoch 10/10, Batch 120/145, Loss: 0.1857
Epoch 10/10, Batch 130/145, Loss: 0.1518
Epoch 10/10, Batch 140/145, Loss: 0.3846
Epoch 10/10, Train Loss: 0.1975, Valid Loss: 0.2166
Accuracy: 0.9194
Precision: 0.9175
Recall: 0.9194
F1-score: 0.9182
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4218
Epoch 1/10, Batch 20/145, Loss: 0.9307
Epoch 1/10, Batch 30/145, Loss: 0.8803
Epoch 1/10, Batch 40/145, Loss: 0.8093
Epoch 1/10, Batch 50/145, Loss: 0.6831
Epoch 1/10, Batch 60/145, Loss: 0.5426
Epoch 1/10, Batch 70/145, Loss: 0.4443
Epoch 1/10, Batch 80/145, Loss: 0.4790
Epoch 1/10, Batch 90/145, Loss: 0.4144
Epoch 1/10, Batch 100/145, Loss: 0.4336
Epoch 1/10, Batch 110/145, Loss: 0.3875
Epoch 1/10, Batch 120/145, Loss: 0.6166
Epoch 1/10, Batch 130/145, Loss: 0.6848
Epoch 1/10, Batch 140/145, Loss: 0.4434
Epoch 1/10, Train Loss: 0.6732, Valid Loss: 0.3708
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3730
Epoch 2/10, Batch 20/145, Loss: 0.5024
Epoch 2/10, Batch 30/145, Loss: 0.3459
Epoch 2/10, Batch 40/145, Loss: 0.3828
Epoch 2/10, Batch 50/145, Loss: 0.3375
Epoch 2/10, Batch 60/145, Loss: 0.2360
Epoch 2/10, Batch 70/145, Loss: 0.3711
Epoch 2/10, Batch 80/145, Loss: 0.4946
Epoch 2/10, Batch 90/145, Loss: 0.4707
Epoch 2/10, Batch 100/145, Loss: 0.2349
Epoch 2/10, Batch 110/145, Loss: 0.2631
Epoch 2/10, Batch 120/145, Loss: 0.4006
Epoch 2/10, Batch 130/145, Loss: 0.2901
Epoch 2/10, Batch 140/145, Loss: 0.4427
Epoch 2/10, Train Loss: 0.3569, Valid Loss: 0.2854
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3123
Epoch 3/10, Batch 20/145, Loss: 0.2600
Epoch 3/10, Batch 30/145, Loss: 0.4209
Epoch 3/10, Batch 40/145, Loss: 0.2890
Epoch 3/10, Batch 50/145, Loss: 0.4115
Epoch 3/10, Batch 60/145, Loss: 0.3638
Epoch 3/10, Batch 70/145, Loss: 0.4066
Epoch 3/10, Batch 80/145, Loss: 0.2176
Epoch 3/10, Batch 90/145, Loss: 0.1548
Epoch 3/10, Batch 100/145, Loss: 0.1618
Epoch 3/10, Batch 110/145, Loss: 0.1644
Epoch 3/10, Batch 120/145, Loss: 0.4007
Epoch 3/10, Batch 130/145, Loss: 0.2014
Epoch 3/10, Batch 140/145, Loss: 0.2453
Epoch 3/10, Train Loss: 0.2933, Valid Loss: 0.2501
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4910
Epoch 4/10, Batch 20/145, Loss: 0.2702
Epoch 4/10, Batch 30/145, Loss: 0.3112
Epoch 4/10, Batch 40/145, Loss: 0.2032
Epoch 4/10, Batch 50/145, Loss: 0.1503
Epoch 4/10, Batch 60/145, Loss: 0.2004
Epoch 4/10, Batch 70/145, Loss: 0.0886
Epoch 4/10, Batch 80/145, Loss: 0.2756
Epoch 4/10, Batch 90/145, Loss: 0.1554
Epoch 4/10, Batch 100/145, Loss: 0.1739
Epoch 4/10, Batch 110/145, Loss: 0.1968
Epoch 4/10, Batch 120/145, Loss: 0.3064
Epoch 4/10, Batch 130/145, Loss: 0.2052
Epoch 4/10, Batch 140/145, Loss: 0.2825
Epoch 4/10, Train Loss: 0.2590, Valid Loss: 0.2383
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2606
Epoch 5/10, Batch 20/145, Loss: 0.2911
Epoch 5/10, Batch 30/145, Loss: 0.3359
Epoch 5/10, Batch 40/145, Loss: 0.1381
Epoch 5/10, Batch 50/145, Loss: 0.1929
Epoch 5/10, Batch 60/145, Loss: 0.2821
Epoch 5/10, Batch 70/145, Loss: 0.2483
Epoch 5/10, Batch 80/145, Loss: 0.1323
Epoch 5/10, Batch 90/145, Loss: 0.3435
Epoch 5/10, Batch 100/145, Loss: 0.2485
Epoch 5/10, Batch 110/145, Loss: 0.1179
Epoch 5/10, Batch 120/145, Loss: 0.2130
Epoch 5/10, Batch 130/145, Loss: 0.1187
Epoch 5/10, Batch 140/145, Loss: 0.2070
Epoch 5/10, Train Loss: 0.2473, Valid Loss: 0.2244
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2513
Epoch 6/10, Batch 20/145, Loss: 0.4918
Epoch 6/10, Batch 30/145, Loss: 0.2972
Epoch 6/10, Batch 40/145, Loss: 0.2665
Epoch 6/10, Batch 50/145, Loss: 0.3260
Epoch 6/10, Batch 60/145, Loss: 0.1783
Epoch 6/10, Batch 70/145, Loss: 0.2105
Epoch 6/10, Batch 80/145, Loss: 0.1992
Epoch 6/10, Batch 90/145, Loss: 0.3107
Epoch 6/10, Batch 100/145, Loss: 0.3708
Epoch 6/10, Batch 110/145, Loss: 0.4645
Epoch 6/10, Batch 120/145, Loss: 0.2566
Epoch 6/10, Batch 130/145, Loss: 0.1232
Epoch 6/10, Batch 140/145, Loss: 0.1243
Epoch 6/10, Train Loss: 0.2258, Valid Loss: 0.2188
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3191
Epoch 7/10, Batch 20/145, Loss: 0.2739
Epoch 7/10, Batch 30/145, Loss: 0.3344
Epoch 7/10, Batch 40/145, Loss: 0.4060
Epoch 7/10, Batch 50/145, Loss: 0.3568
Epoch 7/10, Batch 60/145, Loss: 0.1409
Epoch 7/10, Batch 70/145, Loss: 0.1625
Epoch 7/10, Batch 80/145, Loss: 0.3891
Epoch 7/10, Batch 90/145, Loss: 0.1483
Epoch 7/10, Batch 100/145, Loss: 0.1844
Epoch 7/10, Batch 110/145, Loss: 0.1137
Epoch 7/10, Batch 120/145, Loss: 0.2134
Epoch 7/10, Batch 130/145, Loss: 0.1402
Epoch 7/10, Batch 140/145, Loss: 0.1728
Epoch 7/10, Train Loss: 0.2158, Valid Loss: 0.2133
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2412
Epoch 8/10, Batch 20/145, Loss: 0.1848
Epoch 8/10, Batch 30/145, Loss: 0.2734
Epoch 8/10, Batch 40/145, Loss: 0.2485
Epoch 8/10, Batch 50/145, Loss: 0.1641
Epoch 8/10, Batch 60/145, Loss: 0.1014
Epoch 8/10, Batch 70/145, Loss: 0.2758
Epoch 8/10, Batch 80/145, Loss: 0.1917
Epoch 8/10, Batch 90/145, Loss: 0.3727
Epoch 8/10, Batch 100/145, Loss: 0.3283
Epoch 8/10, Batch 110/145, Loss: 0.1616
Epoch 8/10, Batch 120/145, Loss: 0.1607
Epoch 8/10, Batch 130/145, Loss: 0.1269
Epoch 8/10, Batch 140/145, Loss: 0.2262
Epoch 8/10, Train Loss: 0.2092, Valid Loss: 0.2060
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3083
Epoch 9/10, Batch 20/145, Loss: 0.2755
Epoch 9/10, Batch 30/145, Loss: 0.2190
Epoch 9/10, Batch 40/145, Loss: 0.1945
Epoch 9/10, Batch 50/145, Loss: 0.1844
Epoch 9/10, Batch 60/145, Loss: 0.1926
Epoch 9/10, Batch 70/145, Loss: 0.1628
Epoch 9/10, Batch 80/145, Loss: 0.1995
Epoch 9/10, Batch 90/145, Loss: 0.2574
Epoch 9/10, Batch 100/145, Loss: 0.1344
Epoch 9/10, Batch 110/145, Loss: 0.3222
Epoch 9/10, Batch 120/145, Loss: 0.2585
Epoch 9/10, Batch 130/145, Loss: 0.1219
Epoch 9/10, Batch 140/145, Loss: 0.2334
Epoch 9/10, Train Loss: 0.1999, Valid Loss: 0.2056
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1195
Epoch 10/10, Batch 20/145, Loss: 0.1589
Epoch 10/10, Batch 30/145, Loss: 0.0906
Epoch 10/10, Batch 40/145, Loss: 0.1100
Epoch 10/10, Batch 50/145, Loss: 0.2865
Epoch 10/10, Batch 60/145, Loss: 0.0644
Epoch 10/10, Batch 70/145, Loss: 0.2579
Epoch 10/10, Batch 80/145, Loss: 0.2505
Epoch 10/10, Batch 90/145, Loss: 0.1494
Epoch 10/10, Batch 100/145, Loss: 0.1271
Epoch 10/10, Batch 110/145, Loss: 0.2651
Epoch 10/10, Batch 120/145, Loss: 0.1927
Epoch 10/10, Batch 130/145, Loss: 0.1474
Epoch 10/10, Batch 140/145, Loss: 0.1824
Epoch 10/10, Train Loss: 0.1871, Valid Loss: 0.2031
Model saved!
Accuracy: 0.9182
Precision: 0.9166
Recall: 0.9182
F1-score: 0.9153
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3847
Epoch 1/10, Batch 20/145, Loss: 0.9586
Epoch 1/10, Batch 30/145, Loss: 0.9522
Epoch 1/10, Batch 40/145, Loss: 0.7714
Epoch 1/10, Batch 50/145, Loss: 0.7536
Epoch 1/10, Batch 60/145, Loss: 0.5879
Epoch 1/10, Batch 70/145, Loss: 0.5273
Epoch 1/10, Batch 80/145, Loss: 0.5715
Epoch 1/10, Batch 90/145, Loss: 0.4609
Epoch 1/10, Batch 100/145, Loss: 0.5347
Epoch 1/10, Batch 110/145, Loss: 0.5174
Epoch 1/10, Batch 120/145, Loss: 0.5966
Epoch 1/10, Batch 130/145, Loss: 0.5203
Epoch 1/10, Batch 140/145, Loss: 0.3673
Epoch 1/10, Train Loss: 0.6840, Valid Loss: 0.3656
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2663
Epoch 2/10, Batch 20/145, Loss: 0.2831
Epoch 2/10, Batch 30/145, Loss: 0.3168
Epoch 2/10, Batch 40/145, Loss: 0.4784
Epoch 2/10, Batch 50/145, Loss: 0.2709
Epoch 2/10, Batch 60/145, Loss: 0.3648
Epoch 2/10, Batch 70/145, Loss: 0.4343
Epoch 2/10, Batch 80/145, Loss: 0.2499
Epoch 2/10, Batch 90/145, Loss: 0.2322
Epoch 2/10, Batch 100/145, Loss: 0.3188
Epoch 2/10, Batch 110/145, Loss: 0.3335
Epoch 2/10, Batch 120/145, Loss: 0.4507
Epoch 2/10, Batch 130/145, Loss: 0.3225
Epoch 2/10, Batch 140/145, Loss: 0.4677
Epoch 2/10, Train Loss: 0.3576, Valid Loss: 0.2854
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1851
Epoch 3/10, Batch 20/145, Loss: 0.2127
Epoch 3/10, Batch 30/145, Loss: 0.4288
Epoch 3/10, Batch 40/145, Loss: 0.2413
Epoch 3/10, Batch 50/145, Loss: 0.3370
Epoch 3/10, Batch 60/145, Loss: 0.2979
Epoch 3/10, Batch 70/145, Loss: 0.2808
Epoch 3/10, Batch 80/145, Loss: 0.1992
Epoch 3/10, Batch 90/145, Loss: 0.2182
Epoch 3/10, Batch 100/145, Loss: 0.2458
Epoch 3/10, Batch 110/145, Loss: 0.1870
Epoch 3/10, Batch 120/145, Loss: 0.2125
Epoch 3/10, Batch 130/145, Loss: 0.4773
Epoch 3/10, Batch 140/145, Loss: 0.4051
Epoch 3/10, Train Loss: 0.2958, Valid Loss: 0.2494
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4004
Epoch 4/10, Batch 20/145, Loss: 0.2389
Epoch 4/10, Batch 30/145, Loss: 0.3061
Epoch 4/10, Batch 40/145, Loss: 0.3419
Epoch 4/10, Batch 50/145, Loss: 0.3476
Epoch 4/10, Batch 60/145, Loss: 0.1814
Epoch 4/10, Batch 70/145, Loss: 0.2534
Epoch 4/10, Batch 80/145, Loss: 0.2765
Epoch 4/10, Batch 90/145, Loss: 0.2222
Epoch 4/10, Batch 100/145, Loss: 0.5140
Epoch 4/10, Batch 110/145, Loss: 0.1780
Epoch 4/10, Batch 120/145, Loss: 0.3117
Epoch 4/10, Batch 130/145, Loss: 0.1734
Epoch 4/10, Batch 140/145, Loss: 0.1969
Epoch 4/10, Train Loss: 0.2684, Valid Loss: 0.2346
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2070
Epoch 5/10, Batch 20/145, Loss: 0.1489
Epoch 5/10, Batch 30/145, Loss: 0.2085
Epoch 5/10, Batch 40/145, Loss: 0.1771
Epoch 5/10, Batch 50/145, Loss: 0.2454
Epoch 5/10, Batch 60/145, Loss: 0.1920
Epoch 5/10, Batch 70/145, Loss: 0.1500
Epoch 5/10, Batch 80/145, Loss: 0.2952
Epoch 5/10, Batch 90/145, Loss: 0.3372
Epoch 5/10, Batch 100/145, Loss: 0.2306
Epoch 5/10, Batch 110/145, Loss: 0.2744
Epoch 5/10, Batch 120/145, Loss: 0.4317
Epoch 5/10, Batch 130/145, Loss: 0.1706
Epoch 5/10, Batch 140/145, Loss: 0.1366
Epoch 5/10, Train Loss: 0.2523, Valid Loss: 0.2315
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1592
Epoch 6/10, Batch 20/145, Loss: 0.4776
Epoch 6/10, Batch 30/145, Loss: 0.2201
Epoch 6/10, Batch 40/145, Loss: 0.0602
Epoch 6/10, Batch 50/145, Loss: 0.4079
Epoch 6/10, Batch 60/145, Loss: 0.1982
Epoch 6/10, Batch 70/145, Loss: 0.2903
Epoch 6/10, Batch 80/145, Loss: 0.2103
Epoch 6/10, Batch 90/145, Loss: 0.2805
Epoch 6/10, Batch 100/145, Loss: 0.4216
Epoch 6/10, Batch 110/145, Loss: 0.2254
Epoch 6/10, Batch 120/145, Loss: 0.1590
Epoch 6/10, Batch 130/145, Loss: 0.1887
Epoch 6/10, Batch 140/145, Loss: 0.2253
Epoch 6/10, Train Loss: 0.2310, Valid Loss: 0.2144
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1888
Epoch 7/10, Batch 20/145, Loss: 0.2129
Epoch 7/10, Batch 30/145, Loss: 0.3385
Epoch 7/10, Batch 40/145, Loss: 0.1772
Epoch 7/10, Batch 50/145, Loss: 0.1101
Epoch 7/10, Batch 60/145, Loss: 0.1759
Epoch 7/10, Batch 70/145, Loss: 0.1669
Epoch 7/10, Batch 80/145, Loss: 0.3508
Epoch 7/10, Batch 90/145, Loss: 0.2218
Epoch 7/10, Batch 100/145, Loss: 0.1841
Epoch 7/10, Batch 110/145, Loss: 0.1229
Epoch 7/10, Batch 120/145, Loss: 0.1810
Epoch 7/10, Batch 130/145, Loss: 0.1634
Epoch 7/10, Batch 140/145, Loss: 0.3427
Epoch 7/10, Train Loss: 0.2151, Valid Loss: 0.2140
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2131
Epoch 8/10, Batch 20/145, Loss: 0.1850
Epoch 8/10, Batch 30/145, Loss: 0.3213
Epoch 8/10, Batch 40/145, Loss: 0.2463
Epoch 8/10, Batch 50/145, Loss: 0.1604
Epoch 8/10, Batch 60/145, Loss: 0.1328
Epoch 8/10, Batch 70/145, Loss: 0.2265
Epoch 8/10, Batch 80/145, Loss: 0.1641
Epoch 8/10, Batch 90/145, Loss: 0.3932
Epoch 8/10, Batch 100/145, Loss: 0.3060
Epoch 8/10, Batch 110/145, Loss: 0.2180
Epoch 8/10, Batch 120/145, Loss: 0.1498
Epoch 8/10, Batch 130/145, Loss: 0.2974
Epoch 8/10, Batch 140/145, Loss: 0.2349
Epoch 8/10, Train Loss: 0.2168, Valid Loss: 0.2065
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2547
Epoch 9/10, Batch 20/145, Loss: 0.1889
Epoch 9/10, Batch 30/145, Loss: 0.1709
Epoch 9/10, Batch 40/145, Loss: 0.2884
Epoch 9/10, Batch 50/145, Loss: 0.1291
Epoch 9/10, Batch 60/145, Loss: 0.1555
Epoch 9/10, Batch 70/145, Loss: 0.1202
Epoch 9/10, Batch 80/145, Loss: 0.1725
Epoch 9/10, Batch 90/145, Loss: 0.1981
Epoch 9/10, Batch 100/145, Loss: 0.2199
Epoch 9/10, Batch 110/145, Loss: 0.2137
Epoch 9/10, Batch 120/145, Loss: 0.0712
Epoch 9/10, Batch 130/145, Loss: 0.3097
Epoch 9/10, Batch 140/145, Loss: 0.1519
Epoch 9/10, Train Loss: 0.2015, Valid Loss: 0.2031
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1066
Epoch 10/10, Batch 20/145, Loss: 0.1241
Epoch 10/10, Batch 30/145, Loss: 0.2224
Epoch 10/10, Batch 40/145, Loss: 0.1821
Epoch 10/10, Batch 50/145, Loss: 0.2596
Epoch 10/10, Batch 60/145, Loss: 0.2101
Epoch 10/10, Batch 70/145, Loss: 0.2499
Epoch 10/10, Batch 80/145, Loss: 0.1499
Epoch 10/10, Batch 90/145, Loss: 0.0638
Epoch 10/10, Batch 100/145, Loss: 0.3512
Epoch 10/10, Batch 110/145, Loss: 0.1308
Epoch 10/10, Batch 120/145, Loss: 0.1526
Epoch 10/10, Batch 130/145, Loss: 0.1553
Epoch 10/10, Batch 140/145, Loss: 0.1568
Epoch 10/10, Train Loss: 0.1993, Valid Loss: 0.2037
Accuracy: 0.9182
Precision: 0.9171
Recall: 0.9182
F1-score: 0.9167
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4886
Epoch 1/10, Batch 20/145, Loss: 0.9431
Epoch 1/10, Batch 30/145, Loss: 0.9049
Epoch 1/10, Batch 40/145, Loss: 0.7411
Epoch 1/10, Batch 50/145, Loss: 0.6169
Epoch 1/10, Batch 60/145, Loss: 0.6279
Epoch 1/10, Batch 70/145, Loss: 0.4655
Epoch 1/10, Batch 80/145, Loss: 0.5087
Epoch 1/10, Batch 90/145, Loss: 0.4535
Epoch 1/10, Batch 100/145, Loss: 0.4834
Epoch 1/10, Batch 110/145, Loss: 0.3517
Epoch 1/10, Batch 120/145, Loss: 0.7789
Epoch 1/10, Batch 130/145, Loss: 0.5217
Epoch 1/10, Batch 140/145, Loss: 0.4235
Epoch 1/10, Train Loss: 0.6797, Valid Loss: 0.3958
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2668
Epoch 2/10, Batch 20/145, Loss: 0.3577
Epoch 2/10, Batch 30/145, Loss: 0.4444
Epoch 2/10, Batch 40/145, Loss: 0.5266
Epoch 2/10, Batch 50/145, Loss: 0.3289
Epoch 2/10, Batch 60/145, Loss: 0.4847
Epoch 2/10, Batch 70/145, Loss: 0.3383
Epoch 2/10, Batch 80/145, Loss: 0.4186
Epoch 2/10, Batch 90/145, Loss: 0.3954
Epoch 2/10, Batch 100/145, Loss: 0.3265
Epoch 2/10, Batch 110/145, Loss: 0.3194
Epoch 2/10, Batch 120/145, Loss: 0.4208
Epoch 2/10, Batch 130/145, Loss: 0.3328
Epoch 2/10, Batch 140/145, Loss: 0.3377
Epoch 2/10, Train Loss: 0.3604, Valid Loss: 0.3120
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3463
Epoch 3/10, Batch 20/145, Loss: 0.2211
Epoch 3/10, Batch 30/145, Loss: 0.3669
Epoch 3/10, Batch 40/145, Loss: 0.1573
Epoch 3/10, Batch 50/145, Loss: 0.3964
Epoch 3/10, Batch 60/145, Loss: 0.3784
Epoch 3/10, Batch 70/145, Loss: 0.4297
Epoch 3/10, Batch 80/145, Loss: 0.3439
Epoch 3/10, Batch 90/145, Loss: 0.2062
Epoch 3/10, Batch 100/145, Loss: 0.1434
Epoch 3/10, Batch 110/145, Loss: 0.1218
Epoch 3/10, Batch 120/145, Loss: 0.2022
Epoch 3/10, Batch 130/145, Loss: 0.2090
Epoch 3/10, Batch 140/145, Loss: 0.3078
Epoch 3/10, Train Loss: 0.3009, Valid Loss: 0.2769
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4097
Epoch 4/10, Batch 20/145, Loss: 0.3614
Epoch 4/10, Batch 30/145, Loss: 0.2561
Epoch 4/10, Batch 40/145, Loss: 0.3025
Epoch 4/10, Batch 50/145, Loss: 0.2185
Epoch 4/10, Batch 60/145, Loss: 0.3613
Epoch 4/10, Batch 70/145, Loss: 0.2450
Epoch 4/10, Batch 80/145, Loss: 0.1296
Epoch 4/10, Batch 90/145, Loss: 0.2113
Epoch 4/10, Batch 100/145, Loss: 0.3718
Epoch 4/10, Batch 110/145, Loss: 0.2993
Epoch 4/10, Batch 120/145, Loss: 0.1737
Epoch 4/10, Batch 130/145, Loss: 0.1626
Epoch 4/10, Batch 140/145, Loss: 0.2171
Epoch 4/10, Train Loss: 0.2629, Valid Loss: 0.2614
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2009
Epoch 5/10, Batch 20/145, Loss: 0.1294
Epoch 5/10, Batch 30/145, Loss: 0.2022
Epoch 5/10, Batch 40/145, Loss: 0.2642
Epoch 5/10, Batch 50/145, Loss: 0.3330
Epoch 5/10, Batch 60/145, Loss: 0.1925
Epoch 5/10, Batch 70/145, Loss: 0.3077
Epoch 5/10, Batch 80/145, Loss: 0.2011
Epoch 5/10, Batch 90/145, Loss: 0.2900
Epoch 5/10, Batch 100/145, Loss: 0.2125
Epoch 5/10, Batch 110/145, Loss: 0.2244
Epoch 5/10, Batch 120/145, Loss: 0.3006
Epoch 5/10, Batch 130/145, Loss: 0.1858
Epoch 5/10, Batch 140/145, Loss: 0.2608
Epoch 5/10, Train Loss: 0.2513, Valid Loss: 0.2559
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1984
Epoch 6/10, Batch 20/145, Loss: 0.2760
Epoch 6/10, Batch 30/145, Loss: 0.3216
Epoch 6/10, Batch 40/145, Loss: 0.2001
Epoch 6/10, Batch 50/145, Loss: 0.3165
Epoch 6/10, Batch 60/145, Loss: 0.1540
Epoch 6/10, Batch 70/145, Loss: 0.1051
Epoch 6/10, Batch 80/145, Loss: 0.2234
Epoch 6/10, Batch 90/145, Loss: 0.3662
Epoch 6/10, Batch 100/145, Loss: 0.3184
Epoch 6/10, Batch 110/145, Loss: 0.2221
Epoch 6/10, Batch 120/145, Loss: 0.2250
Epoch 6/10, Batch 130/145, Loss: 0.1123
Epoch 6/10, Batch 140/145, Loss: 0.2545
Epoch 6/10, Train Loss: 0.2323, Valid Loss: 0.2360
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2826
Epoch 7/10, Batch 20/145, Loss: 0.2021
Epoch 7/10, Batch 30/145, Loss: 0.2869
Epoch 7/10, Batch 40/145, Loss: 0.2630
Epoch 7/10, Batch 50/145, Loss: 0.1181
Epoch 7/10, Batch 60/145, Loss: 0.1399
Epoch 7/10, Batch 70/145, Loss: 0.0918
Epoch 7/10, Batch 80/145, Loss: 0.4488
Epoch 7/10, Batch 90/145, Loss: 0.1727
Epoch 7/10, Batch 100/145, Loss: 0.1930
Epoch 7/10, Batch 110/145, Loss: 0.1628
Epoch 7/10, Batch 120/145, Loss: 0.2204
Epoch 7/10, Batch 130/145, Loss: 0.1980
Epoch 7/10, Batch 140/145, Loss: 0.2448
Epoch 7/10, Train Loss: 0.2188, Valid Loss: 0.2346
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2112
Epoch 8/10, Batch 20/145, Loss: 0.3092
Epoch 8/10, Batch 30/145, Loss: 0.1294
Epoch 8/10, Batch 40/145, Loss: 0.1570
Epoch 8/10, Batch 50/145, Loss: 0.2575
Epoch 8/10, Batch 60/145, Loss: 0.1435
Epoch 8/10, Batch 70/145, Loss: 0.2298
Epoch 8/10, Batch 80/145, Loss: 0.0924
Epoch 8/10, Batch 90/145, Loss: 0.2559
Epoch 8/10, Batch 100/145, Loss: 0.2818
Epoch 8/10, Batch 110/145, Loss: 0.2122
Epoch 8/10, Batch 120/145, Loss: 0.2388
Epoch 8/10, Batch 130/145, Loss: 0.2033
Epoch 8/10, Batch 140/145, Loss: 0.2161
Epoch 8/10, Train Loss: 0.2130, Valid Loss: 0.2382
Epoch 9/10, Batch 10/145, Loss: 0.1788
Epoch 9/10, Batch 20/145, Loss: 0.1811
Epoch 9/10, Batch 30/145, Loss: 0.1290
Epoch 9/10, Batch 40/145, Loss: 0.3346
Epoch 9/10, Batch 50/145, Loss: 0.3298
Epoch 9/10, Batch 60/145, Loss: 0.2643
Epoch 9/10, Batch 70/145, Loss: 0.1745
Epoch 9/10, Batch 80/145, Loss: 0.0734
Epoch 9/10, Batch 90/145, Loss: 0.3314
Epoch 9/10, Batch 100/145, Loss: 0.3053
Epoch 9/10, Batch 110/145, Loss: 0.6322
Epoch 9/10, Batch 120/145, Loss: 0.1860
Epoch 9/10, Batch 130/145, Loss: 0.2051
Epoch 9/10, Batch 140/145, Loss: 0.2368
Epoch 9/10, Train Loss: 0.2089, Valid Loss: 0.2311
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0970
Epoch 10/10, Batch 20/145, Loss: 0.3161
Epoch 10/10, Batch 30/145, Loss: 0.1791
Epoch 10/10, Batch 40/145, Loss: 0.0558
Epoch 10/10, Batch 50/145, Loss: 0.2113
Epoch 10/10, Batch 60/145, Loss: 0.1670
Epoch 10/10, Batch 70/145, Loss: 0.2711
Epoch 10/10, Batch 80/145, Loss: 0.3350
Epoch 10/10, Batch 90/145, Loss: 0.1706
Epoch 10/10, Batch 100/145, Loss: 0.2520
Epoch 10/10, Batch 110/145, Loss: 0.2290
Epoch 10/10, Batch 120/145, Loss: 0.1981
Epoch 10/10, Batch 130/145, Loss: 0.0920
Epoch 10/10, Batch 140/145, Loss: 0.2073
Epoch 10/10, Train Loss: 0.2025, Valid Loss: 0.2294
Model saved!
Accuracy: 0.9276
Precision: 0.9257
Recall: 0.9276
F1-score: 0.9264
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4323
Epoch 1/10, Batch 20/145, Loss: 0.9453
Epoch 1/10, Batch 30/145, Loss: 0.8639
Epoch 1/10, Batch 40/145, Loss: 0.8008
Epoch 1/10, Batch 50/145, Loss: 0.7555
Epoch 1/10, Batch 60/145, Loss: 0.6856
Epoch 1/10, Batch 70/145, Loss: 0.4518
Epoch 1/10, Batch 80/145, Loss: 0.5558
Epoch 1/10, Batch 90/145, Loss: 0.4324
Epoch 1/10, Batch 100/145, Loss: 0.4209
Epoch 1/10, Batch 110/145, Loss: 0.4790
Epoch 1/10, Batch 120/145, Loss: 0.6908
Epoch 1/10, Batch 130/145, Loss: 0.6239
Epoch 1/10, Batch 140/145, Loss: 0.3331
Epoch 1/10, Train Loss: 0.6766, Valid Loss: 0.3732
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2836
Epoch 2/10, Batch 20/145, Loss: 0.3187
Epoch 2/10, Batch 30/145, Loss: 0.2879
Epoch 2/10, Batch 40/145, Loss: 0.3788
Epoch 2/10, Batch 50/145, Loss: 0.2641
Epoch 2/10, Batch 60/145, Loss: 0.3145
Epoch 2/10, Batch 70/145, Loss: 0.3217
Epoch 2/10, Batch 80/145, Loss: 0.2283
Epoch 2/10, Batch 90/145, Loss: 0.2307
Epoch 2/10, Batch 100/145, Loss: 0.5043
Epoch 2/10, Batch 110/145, Loss: 0.3976
Epoch 2/10, Batch 120/145, Loss: 0.3869
Epoch 2/10, Batch 130/145, Loss: 0.2601
Epoch 2/10, Batch 140/145, Loss: 0.2212
Epoch 2/10, Train Loss: 0.3493, Valid Loss: 0.2882
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2822
Epoch 3/10, Batch 20/145, Loss: 0.1905
Epoch 3/10, Batch 30/145, Loss: 0.3199
Epoch 3/10, Batch 40/145, Loss: 0.2595
Epoch 3/10, Batch 50/145, Loss: 0.2981
Epoch 3/10, Batch 60/145, Loss: 0.2908
Epoch 3/10, Batch 70/145, Loss: 0.3150
Epoch 3/10, Batch 80/145, Loss: 0.2551
Epoch 3/10, Batch 90/145, Loss: 0.2732
Epoch 3/10, Batch 100/145, Loss: 0.1690
Epoch 3/10, Batch 110/145, Loss: 0.2049
Epoch 3/10, Batch 120/145, Loss: 0.3858
Epoch 3/10, Batch 130/145, Loss: 0.3130
Epoch 3/10, Batch 140/145, Loss: 0.2985
Epoch 3/10, Train Loss: 0.2938, Valid Loss: 0.2582
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3764
Epoch 4/10, Batch 20/145, Loss: 0.2056
Epoch 4/10, Batch 30/145, Loss: 0.3505
Epoch 4/10, Batch 40/145, Loss: 0.1785
Epoch 4/10, Batch 50/145, Loss: 0.1588
Epoch 4/10, Batch 60/145, Loss: 0.2102
Epoch 4/10, Batch 70/145, Loss: 0.2401
Epoch 4/10, Batch 80/145, Loss: 0.2896
Epoch 4/10, Batch 90/145, Loss: 0.2698
Epoch 4/10, Batch 100/145, Loss: 0.2908
Epoch 4/10, Batch 110/145, Loss: 0.1308
Epoch 4/10, Batch 120/145, Loss: 0.3990
Epoch 4/10, Batch 130/145, Loss: 0.1599
Epoch 4/10, Batch 140/145, Loss: 0.1974
Epoch 4/10, Train Loss: 0.2610, Valid Loss: 0.2415
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1845
Epoch 5/10, Batch 20/145, Loss: 0.1031
Epoch 5/10, Batch 30/145, Loss: 0.3398
Epoch 5/10, Batch 40/145, Loss: 0.1339
Epoch 5/10, Batch 50/145, Loss: 0.2426
Epoch 5/10, Batch 60/145, Loss: 0.2630
Epoch 5/10, Batch 70/145, Loss: 0.2411
Epoch 5/10, Batch 80/145, Loss: 0.1601
Epoch 5/10, Batch 90/145, Loss: 0.3149
Epoch 5/10, Batch 100/145, Loss: 0.2937
Epoch 5/10, Batch 110/145, Loss: 0.1513
Epoch 5/10, Batch 120/145, Loss: 0.3601
Epoch 5/10, Batch 130/145, Loss: 0.1106
Epoch 5/10, Batch 140/145, Loss: 0.1437
Epoch 5/10, Train Loss: 0.2388, Valid Loss: 0.2355
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2325
Epoch 6/10, Batch 20/145, Loss: 0.3862
Epoch 6/10, Batch 30/145, Loss: 0.2158
Epoch 6/10, Batch 40/145, Loss: 0.2299
Epoch 6/10, Batch 50/145, Loss: 0.3466
Epoch 6/10, Batch 60/145, Loss: 0.2953
Epoch 6/10, Batch 70/145, Loss: 0.1114
Epoch 6/10, Batch 80/145, Loss: 0.2295
Epoch 6/10, Batch 90/145, Loss: 0.2115
Epoch 6/10, Batch 100/145, Loss: 0.4728
Epoch 6/10, Batch 110/145, Loss: 0.2162
Epoch 6/10, Batch 120/145, Loss: 0.1438
Epoch 6/10, Batch 130/145, Loss: 0.2174
Epoch 6/10, Batch 140/145, Loss: 0.2647
Epoch 6/10, Train Loss: 0.2245, Valid Loss: 0.2255
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1695
Epoch 7/10, Batch 20/145, Loss: 0.1993
Epoch 7/10, Batch 30/145, Loss: 0.1493
Epoch 7/10, Batch 40/145, Loss: 0.4402
Epoch 7/10, Batch 50/145, Loss: 0.2152
Epoch 7/10, Batch 60/145, Loss: 0.2396
Epoch 7/10, Batch 70/145, Loss: 0.1693
Epoch 7/10, Batch 80/145, Loss: 0.4546
Epoch 7/10, Batch 90/145, Loss: 0.1138
Epoch 7/10, Batch 100/145, Loss: 0.2246
Epoch 7/10, Batch 110/145, Loss: 0.0944
Epoch 7/10, Batch 120/145, Loss: 0.1468
Epoch 7/10, Batch 130/145, Loss: 0.1359
Epoch 7/10, Batch 140/145, Loss: 0.0905
Epoch 7/10, Train Loss: 0.2155, Valid Loss: 0.2240
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1813
Epoch 8/10, Batch 20/145, Loss: 0.2234
Epoch 8/10, Batch 30/145, Loss: 0.1961
Epoch 8/10, Batch 40/145, Loss: 0.2501
Epoch 8/10, Batch 50/145, Loss: 0.3824
Epoch 8/10, Batch 60/145, Loss: 0.2458
Epoch 8/10, Batch 70/145, Loss: 0.2152
Epoch 8/10, Batch 80/145, Loss: 0.2224
Epoch 8/10, Batch 90/145, Loss: 0.6687
Epoch 8/10, Batch 100/145, Loss: 0.1278
Epoch 8/10, Batch 110/145, Loss: 0.1806
Epoch 8/10, Batch 120/145, Loss: 0.2643
Epoch 8/10, Batch 130/145, Loss: 0.1689
Epoch 8/10, Batch 140/145, Loss: 0.3033
Epoch 8/10, Train Loss: 0.2077, Valid Loss: 0.2195
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3077
Epoch 9/10, Batch 20/145, Loss: 0.1546
Epoch 9/10, Batch 30/145, Loss: 0.1552
Epoch 9/10, Batch 40/145, Loss: 0.1149
Epoch 9/10, Batch 50/145, Loss: 0.1348
Epoch 9/10, Batch 60/145, Loss: 0.1600
Epoch 9/10, Batch 70/145, Loss: 0.1819
Epoch 9/10, Batch 80/145, Loss: 0.1546
Epoch 9/10, Batch 90/145, Loss: 0.3444
Epoch 9/10, Batch 100/145, Loss: 0.2179
Epoch 9/10, Batch 110/145, Loss: 0.2570
Epoch 9/10, Batch 120/145, Loss: 0.0804
Epoch 9/10, Batch 130/145, Loss: 0.1919
Epoch 9/10, Batch 140/145, Loss: 0.3460
Epoch 9/10, Train Loss: 0.1997, Valid Loss: 0.2166
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1216
Epoch 10/10, Batch 20/145, Loss: 0.1286
Epoch 10/10, Batch 30/145, Loss: 0.1050
Epoch 10/10, Batch 40/145, Loss: 0.1605
Epoch 10/10, Batch 50/145, Loss: 0.1960
Epoch 10/10, Batch 60/145, Loss: 0.1182
Epoch 10/10, Batch 70/145, Loss: 0.1818
Epoch 10/10, Batch 80/145, Loss: 0.2201
Epoch 10/10, Batch 90/145, Loss: 0.1943
Epoch 10/10, Batch 100/145, Loss: 0.2269
Epoch 10/10, Batch 110/145, Loss: 0.1276
Epoch 10/10, Batch 120/145, Loss: 0.1759
Epoch 10/10, Batch 130/145, Loss: 0.2181
Epoch 10/10, Batch 140/145, Loss: 0.2066
Epoch 10/10, Train Loss: 0.1945, Valid Loss: 0.2132
Model saved!
Accuracy: 0.9206
Precision: 0.9175
Recall: 0.9206
F1-score: 0.9184
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3901
Epoch 1/10, Batch 20/145, Loss: 0.9569
Epoch 1/10, Batch 30/145, Loss: 0.8934
Epoch 1/10, Batch 40/145, Loss: 0.7629
Epoch 1/10, Batch 50/145, Loss: 0.7850
Epoch 1/10, Batch 60/145, Loss: 0.6914
Epoch 1/10, Batch 70/145, Loss: 0.4861
Epoch 1/10, Batch 80/145, Loss: 0.5786
Epoch 1/10, Batch 90/145, Loss: 0.4328
Epoch 1/10, Batch 100/145, Loss: 0.4161
Epoch 1/10, Batch 110/145, Loss: 0.3656
Epoch 1/10, Batch 120/145, Loss: 0.5364
Epoch 1/10, Batch 130/145, Loss: 0.6609
Epoch 1/10, Batch 140/145, Loss: 0.3017
Epoch 1/10, Train Loss: 0.6811, Valid Loss: 0.3633
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3121
Epoch 2/10, Batch 20/145, Loss: 0.3607
Epoch 2/10, Batch 30/145, Loss: 0.3458
Epoch 2/10, Batch 40/145, Loss: 0.4602
Epoch 2/10, Batch 50/145, Loss: 0.2708
Epoch 2/10, Batch 60/145, Loss: 0.2849
Epoch 2/10, Batch 70/145, Loss: 0.2967
Epoch 2/10, Batch 80/145, Loss: 0.3659
Epoch 2/10, Batch 90/145, Loss: 0.5217
Epoch 2/10, Batch 100/145, Loss: 0.2701
Epoch 2/10, Batch 110/145, Loss: 0.5353
Epoch 2/10, Batch 120/145, Loss: 0.2324
Epoch 2/10, Batch 130/145, Loss: 0.3194
Epoch 2/10, Batch 140/145, Loss: 0.2614
Epoch 2/10, Train Loss: 0.3539, Valid Loss: 0.2884
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2351
Epoch 3/10, Batch 20/145, Loss: 0.2468
Epoch 3/10, Batch 30/145, Loss: 0.4483
Epoch 3/10, Batch 40/145, Loss: 0.2170
Epoch 3/10, Batch 50/145, Loss: 0.2609
Epoch 3/10, Batch 60/145, Loss: 0.2969
Epoch 3/10, Batch 70/145, Loss: 0.4571
Epoch 3/10, Batch 80/145, Loss: 0.2664
Epoch 3/10, Batch 90/145, Loss: 0.1937
Epoch 3/10, Batch 100/145, Loss: 0.1630
Epoch 3/10, Batch 110/145, Loss: 0.3324
Epoch 3/10, Batch 120/145, Loss: 0.2189
Epoch 3/10, Batch 130/145, Loss: 0.3837
Epoch 3/10, Batch 140/145, Loss: 0.2539
Epoch 3/10, Train Loss: 0.2898, Valid Loss: 0.2599
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2970
Epoch 4/10, Batch 20/145, Loss: 0.3349
Epoch 4/10, Batch 30/145, Loss: 0.2551
Epoch 4/10, Batch 40/145, Loss: 0.1284
Epoch 4/10, Batch 50/145, Loss: 0.1927
Epoch 4/10, Batch 60/145, Loss: 0.2019
Epoch 4/10, Batch 70/145, Loss: 0.1726
Epoch 4/10, Batch 80/145, Loss: 0.2841
Epoch 4/10, Batch 90/145, Loss: 0.1005
Epoch 4/10, Batch 100/145, Loss: 0.3443
Epoch 4/10, Batch 110/145, Loss: 0.2304
Epoch 4/10, Batch 120/145, Loss: 0.3442
Epoch 4/10, Batch 130/145, Loss: 0.2867
Epoch 4/10, Batch 140/145, Loss: 0.2617
Epoch 4/10, Train Loss: 0.2595, Valid Loss: 0.2507
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1423
Epoch 5/10, Batch 20/145, Loss: 0.1473
Epoch 5/10, Batch 30/145, Loss: 0.1497
Epoch 5/10, Batch 40/145, Loss: 0.1363
Epoch 5/10, Batch 50/145, Loss: 0.2221
Epoch 5/10, Batch 60/145, Loss: 0.2247
Epoch 5/10, Batch 70/145, Loss: 0.1539
Epoch 5/10, Batch 80/145, Loss: 0.1737
Epoch 5/10, Batch 90/145, Loss: 0.3403
Epoch 5/10, Batch 100/145, Loss: 0.3227
Epoch 5/10, Batch 110/145, Loss: 0.2178
Epoch 5/10, Batch 120/145, Loss: 0.4037
Epoch 5/10, Batch 130/145, Loss: 0.2063
Epoch 5/10, Batch 140/145, Loss: 0.2819
Epoch 5/10, Train Loss: 0.2408, Valid Loss: 0.2450
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1513
Epoch 6/10, Batch 20/145, Loss: 0.5658
Epoch 6/10, Batch 30/145, Loss: 0.1419
Epoch 6/10, Batch 40/145, Loss: 0.2862
Epoch 6/10, Batch 50/145, Loss: 0.2651
Epoch 6/10, Batch 60/145, Loss: 0.1618
Epoch 6/10, Batch 70/145, Loss: 0.0799
Epoch 6/10, Batch 80/145, Loss: 0.1965
Epoch 6/10, Batch 90/145, Loss: 0.2723
Epoch 6/10, Batch 100/145, Loss: 0.3852
Epoch 6/10, Batch 110/145, Loss: 0.2937
Epoch 6/10, Batch 120/145, Loss: 0.2665
Epoch 6/10, Batch 130/145, Loss: 0.2080
Epoch 6/10, Batch 140/145, Loss: 0.1947
Epoch 6/10, Train Loss: 0.2272, Valid Loss: 0.2291
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1287
Epoch 7/10, Batch 20/145, Loss: 0.3840
Epoch 7/10, Batch 30/145, Loss: 0.3412
Epoch 7/10, Batch 40/145, Loss: 0.2767
Epoch 7/10, Batch 50/145, Loss: 0.2324
Epoch 7/10, Batch 60/145, Loss: 0.1261
Epoch 7/10, Batch 70/145, Loss: 0.1372
Epoch 7/10, Batch 80/145, Loss: 0.3217
Epoch 7/10, Batch 90/145, Loss: 0.2178
Epoch 7/10, Batch 100/145, Loss: 0.1415
Epoch 7/10, Batch 110/145, Loss: 0.2404
Epoch 7/10, Batch 120/145, Loss: 0.1827
Epoch 7/10, Batch 130/145, Loss: 0.0981
Epoch 7/10, Batch 140/145, Loss: 0.2535
Epoch 7/10, Train Loss: 0.2142, Valid Loss: 0.2329
Epoch 8/10, Batch 10/145, Loss: 0.1927
Epoch 8/10, Batch 20/145, Loss: 0.2095
Epoch 8/10, Batch 30/145, Loss: 0.2303
Epoch 8/10, Batch 40/145, Loss: 0.1916
Epoch 8/10, Batch 50/145, Loss: 0.1937
Epoch 8/10, Batch 60/145, Loss: 0.4253
Epoch 8/10, Batch 70/145, Loss: 0.2248
Epoch 8/10, Batch 80/145, Loss: 0.1255
Epoch 8/10, Batch 90/145, Loss: 0.1965
Epoch 8/10, Batch 100/145, Loss: 0.1537
Epoch 8/10, Batch 110/145, Loss: 0.1907
Epoch 8/10, Batch 120/145, Loss: 0.2522
Epoch 8/10, Batch 130/145, Loss: 0.1797
Epoch 8/10, Batch 140/145, Loss: 0.1260
Epoch 8/10, Train Loss: 0.2062, Valid Loss: 0.2195
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3295
Epoch 9/10, Batch 20/145, Loss: 0.1469
Epoch 9/10, Batch 30/145, Loss: 0.0820
Epoch 9/10, Batch 40/145, Loss: 0.2883
Epoch 9/10, Batch 50/145, Loss: 0.2866
Epoch 9/10, Batch 60/145, Loss: 0.2894
Epoch 9/10, Batch 70/145, Loss: 0.1700
Epoch 9/10, Batch 80/145, Loss: 0.1961
Epoch 9/10, Batch 90/145, Loss: 0.1611
Epoch 9/10, Batch 100/145, Loss: 0.2226
Epoch 9/10, Batch 110/145, Loss: 0.1971
Epoch 9/10, Batch 120/145, Loss: 0.1089
Epoch 9/10, Batch 130/145, Loss: 0.1029
Epoch 9/10, Batch 140/145, Loss: 0.1786
Epoch 9/10, Train Loss: 0.1976, Valid Loss: 0.2232
Epoch 10/10, Batch 10/145, Loss: 0.1054
Epoch 10/10, Batch 20/145, Loss: 0.2827
Epoch 10/10, Batch 30/145, Loss: 0.2531
Epoch 10/10, Batch 40/145, Loss: 0.1063
Epoch 10/10, Batch 50/145, Loss: 0.1947
Epoch 10/10, Batch 60/145, Loss: 0.1083
Epoch 10/10, Batch 70/145, Loss: 0.3864
Epoch 10/10, Batch 80/145, Loss: 0.2148
Epoch 10/10, Batch 90/145, Loss: 0.2036
Epoch 10/10, Batch 100/145, Loss: 0.1579
Epoch 10/10, Batch 110/145, Loss: 0.1981
Epoch 10/10, Batch 120/145, Loss: 0.1967
Epoch 10/10, Batch 130/145, Loss: 0.1276
Epoch 10/10, Batch 140/145, Loss: 0.1120
Epoch 10/10, Train Loss: 0.1926, Valid Loss: 0.2261
Accuracy: 0.9147
Precision: 0.9136
Recall: 0.9147
F1-score: 0.9132
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3422
Epoch 1/10, Batch 20/145, Loss: 0.9993
Epoch 1/10, Batch 30/145, Loss: 1.0148
Epoch 1/10, Batch 40/145, Loss: 0.8703
Epoch 1/10, Batch 50/145, Loss: 0.6461
Epoch 1/10, Batch 60/145, Loss: 0.6073
Epoch 1/10, Batch 70/145, Loss: 0.4560
Epoch 1/10, Batch 80/145, Loss: 0.4722
Epoch 1/10, Batch 90/145, Loss: 0.6134
Epoch 1/10, Batch 100/145, Loss: 0.5665
Epoch 1/10, Batch 110/145, Loss: 0.3131
Epoch 1/10, Batch 120/145, Loss: 0.5325
Epoch 1/10, Batch 130/145, Loss: 0.4911
Epoch 1/10, Batch 140/145, Loss: 0.3796
Epoch 1/10, Train Loss: 0.6728, Valid Loss: 0.3695
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2748
Epoch 2/10, Batch 20/145, Loss: 0.4335
Epoch 2/10, Batch 30/145, Loss: 0.2903
Epoch 2/10, Batch 40/145, Loss: 0.3799
Epoch 2/10, Batch 50/145, Loss: 0.2886
Epoch 2/10, Batch 60/145, Loss: 0.3936
Epoch 2/10, Batch 70/145, Loss: 0.3744
Epoch 2/10, Batch 80/145, Loss: 0.3331
Epoch 2/10, Batch 90/145, Loss: 0.1781
Epoch 2/10, Batch 100/145, Loss: 0.3001
Epoch 2/10, Batch 110/145, Loss: 0.3419
Epoch 2/10, Batch 120/145, Loss: 0.3094
Epoch 2/10, Batch 130/145, Loss: 0.4398
Epoch 2/10, Batch 140/145, Loss: 0.4561
Epoch 2/10, Train Loss: 0.3468, Valid Loss: 0.2899
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2477
Epoch 3/10, Batch 20/145, Loss: 0.3264
Epoch 3/10, Batch 30/145, Loss: 0.5353
Epoch 3/10, Batch 40/145, Loss: 0.2174
Epoch 3/10, Batch 50/145, Loss: 0.2073
Epoch 3/10, Batch 60/145, Loss: 0.2596
Epoch 3/10, Batch 70/145, Loss: 0.3964
Epoch 3/10, Batch 80/145, Loss: 0.2215
Epoch 3/10, Batch 90/145, Loss: 0.2226
Epoch 3/10, Batch 100/145, Loss: 0.3041
Epoch 3/10, Batch 110/145, Loss: 0.1656
Epoch 3/10, Batch 120/145, Loss: 0.1912
Epoch 3/10, Batch 130/145, Loss: 0.5135
Epoch 3/10, Batch 140/145, Loss: 0.2968
Epoch 3/10, Train Loss: 0.2881, Valid Loss: 0.2563
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2633
Epoch 4/10, Batch 20/145, Loss: 0.2674
Epoch 4/10, Batch 30/145, Loss: 0.2840
Epoch 4/10, Batch 40/145, Loss: 0.1244
Epoch 4/10, Batch 50/145, Loss: 0.2215
Epoch 4/10, Batch 60/145, Loss: 0.3459
Epoch 4/10, Batch 70/145, Loss: 0.3820
Epoch 4/10, Batch 80/145, Loss: 0.2232
Epoch 4/10, Batch 90/145, Loss: 0.1835
Epoch 4/10, Batch 100/145, Loss: 0.3885
Epoch 4/10, Batch 110/145, Loss: 0.1551
Epoch 4/10, Batch 120/145, Loss: 0.5006
Epoch 4/10, Batch 130/145, Loss: 0.1646
Epoch 4/10, Batch 140/145, Loss: 0.2400
Epoch 4/10, Train Loss: 0.2529, Valid Loss: 0.2425
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2030
Epoch 5/10, Batch 20/145, Loss: 0.3755
Epoch 5/10, Batch 30/145, Loss: 0.2878
Epoch 5/10, Batch 40/145, Loss: 0.1928
Epoch 5/10, Batch 50/145, Loss: 0.2732
Epoch 5/10, Batch 60/145, Loss: 0.2814
Epoch 5/10, Batch 70/145, Loss: 0.1901
Epoch 5/10, Batch 80/145, Loss: 0.0858
Epoch 5/10, Batch 90/145, Loss: 0.2936
Epoch 5/10, Batch 100/145, Loss: 0.1979
Epoch 5/10, Batch 110/145, Loss: 0.1614
Epoch 5/10, Batch 120/145, Loss: 0.2954
Epoch 5/10, Batch 130/145, Loss: 0.2329
Epoch 5/10, Batch 140/145, Loss: 0.2005
Epoch 5/10, Train Loss: 0.2396, Valid Loss: 0.2420
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2560
Epoch 6/10, Batch 20/145, Loss: 0.3326
Epoch 6/10, Batch 30/145, Loss: 0.2679
Epoch 6/10, Batch 40/145, Loss: 0.3054
Epoch 6/10, Batch 50/145, Loss: 0.3982
Epoch 6/10, Batch 60/145, Loss: 0.1778
Epoch 6/10, Batch 70/145, Loss: 0.2376
Epoch 6/10, Batch 80/145, Loss: 0.3125
Epoch 6/10, Batch 90/145, Loss: 0.3132
Epoch 6/10, Batch 100/145, Loss: 0.2630
Epoch 6/10, Batch 110/145, Loss: 0.2339
Epoch 6/10, Batch 120/145, Loss: 0.2767
Epoch 6/10, Batch 130/145, Loss: 0.1486
Epoch 6/10, Batch 140/145, Loss: 0.2609
Epoch 6/10, Train Loss: 0.2271, Valid Loss: 0.2227
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2470
Epoch 7/10, Batch 20/145, Loss: 0.2308
Epoch 7/10, Batch 30/145, Loss: 0.2433
Epoch 7/10, Batch 40/145, Loss: 0.4252
Epoch 7/10, Batch 50/145, Loss: 0.1801
Epoch 7/10, Batch 60/145, Loss: 0.1501
Epoch 7/10, Batch 70/145, Loss: 0.1557
Epoch 7/10, Batch 80/145, Loss: 0.3803
Epoch 7/10, Batch 90/145, Loss: 0.2561
Epoch 7/10, Batch 100/145, Loss: 0.2279
Epoch 7/10, Batch 110/145, Loss: 0.1451
Epoch 7/10, Batch 120/145, Loss: 0.1158
Epoch 7/10, Batch 130/145, Loss: 0.1488
Epoch 7/10, Batch 140/145, Loss: 0.0860
Epoch 7/10, Train Loss: 0.2074, Valid Loss: 0.2253
Epoch 8/10, Batch 10/145, Loss: 0.1837
Epoch 8/10, Batch 20/145, Loss: 0.4594
Epoch 8/10, Batch 30/145, Loss: 0.1164
Epoch 8/10, Batch 40/145, Loss: 0.1440
Epoch 8/10, Batch 50/145, Loss: 0.3242
Epoch 8/10, Batch 60/145, Loss: 0.2707
Epoch 8/10, Batch 70/145, Loss: 0.1980
Epoch 8/10, Batch 80/145, Loss: 0.1424
Epoch 8/10, Batch 90/145, Loss: 0.1834
Epoch 8/10, Batch 100/145, Loss: 0.1386
Epoch 8/10, Batch 110/145, Loss: 0.1817
Epoch 8/10, Batch 120/145, Loss: 0.2058
Epoch 8/10, Batch 130/145, Loss: 0.1338
Epoch 8/10, Batch 140/145, Loss: 0.3844
Epoch 8/10, Train Loss: 0.1925, Valid Loss: 0.2216
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1482
Epoch 9/10, Batch 20/145, Loss: 0.1685
Epoch 9/10, Batch 30/145, Loss: 0.0928
Epoch 9/10, Batch 40/145, Loss: 0.4127
Epoch 9/10, Batch 50/145, Loss: 0.1406
Epoch 9/10, Batch 60/145, Loss: 0.2510
Epoch 9/10, Batch 70/145, Loss: 0.3004
Epoch 9/10, Batch 80/145, Loss: 0.0961
Epoch 9/10, Batch 90/145, Loss: 0.1707
Epoch 9/10, Batch 100/145, Loss: 0.1327
Epoch 9/10, Batch 110/145, Loss: 0.1923
Epoch 9/10, Batch 120/145, Loss: 0.0942
Epoch 9/10, Batch 130/145, Loss: 0.1123
Epoch 9/10, Batch 140/145, Loss: 0.2471
Epoch 9/10, Train Loss: 0.1937, Valid Loss: 0.2282
Epoch 10/10, Batch 10/145, Loss: 0.1300
Epoch 10/10, Batch 20/145, Loss: 0.1406
Epoch 10/10, Batch 30/145, Loss: 0.1602
Epoch 10/10, Batch 40/145, Loss: 0.1909
Epoch 10/10, Batch 50/145, Loss: 0.2234
Epoch 10/10, Batch 60/145, Loss: 0.1486
Epoch 10/10, Batch 70/145, Loss: 0.4121
Epoch 10/10, Batch 80/145, Loss: 0.1986
Epoch 10/10, Batch 90/145, Loss: 0.1623
Epoch 10/10, Batch 100/145, Loss: 0.1501
Epoch 10/10, Batch 110/145, Loss: 0.2621
Epoch 10/10, Batch 120/145, Loss: 0.1687
Epoch 10/10, Batch 130/145, Loss: 0.2270
Epoch 10/10, Batch 140/145, Loss: 0.2491
Epoch 10/10, Train Loss: 0.1959, Valid Loss: 0.2245
Accuracy: 0.9229
Precision: 0.9210
Recall: 0.9229
F1-score: 0.9209
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4277
Epoch 1/10, Batch 20/145, Loss: 1.0041
Epoch 1/10, Batch 30/145, Loss: 0.8678
Epoch 1/10, Batch 40/145, Loss: 0.7458
Epoch 1/10, Batch 50/145, Loss: 0.7745
Epoch 1/10, Batch 60/145, Loss: 0.5959
Epoch 1/10, Batch 70/145, Loss: 0.4950
Epoch 1/10, Batch 80/145, Loss: 0.6431
Epoch 1/10, Batch 90/145, Loss: 0.4529
Epoch 1/10, Batch 100/145, Loss: 0.5106
Epoch 1/10, Batch 110/145, Loss: 0.5061
Epoch 1/10, Batch 120/145, Loss: 0.6335
Epoch 1/10, Batch 130/145, Loss: 0.4370
Epoch 1/10, Batch 140/145, Loss: 0.3804
Epoch 1/10, Train Loss: 0.6746, Valid Loss: 0.3629
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2277
Epoch 2/10, Batch 20/145, Loss: 0.3641
Epoch 2/10, Batch 30/145, Loss: 0.3778
Epoch 2/10, Batch 40/145, Loss: 0.4168
Epoch 2/10, Batch 50/145, Loss: 0.3041
Epoch 2/10, Batch 60/145, Loss: 0.4094
Epoch 2/10, Batch 70/145, Loss: 0.3261
Epoch 2/10, Batch 80/145, Loss: 0.2634
Epoch 2/10, Batch 90/145, Loss: 0.4629
Epoch 2/10, Batch 100/145, Loss: 0.1968
Epoch 2/10, Batch 110/145, Loss: 0.4144
Epoch 2/10, Batch 120/145, Loss: 0.4490
Epoch 2/10, Batch 130/145, Loss: 0.1957
Epoch 2/10, Batch 140/145, Loss: 0.2571
Epoch 2/10, Train Loss: 0.3492, Valid Loss: 0.2854
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3256
Epoch 3/10, Batch 20/145, Loss: 0.2706
Epoch 3/10, Batch 30/145, Loss: 0.3949
Epoch 3/10, Batch 40/145, Loss: 0.2503
Epoch 3/10, Batch 50/145, Loss: 0.2638
Epoch 3/10, Batch 60/145, Loss: 0.3732
Epoch 3/10, Batch 70/145, Loss: 0.4253
Epoch 3/10, Batch 80/145, Loss: 0.1783
Epoch 3/10, Batch 90/145, Loss: 0.4606
Epoch 3/10, Batch 100/145, Loss: 0.2540
Epoch 3/10, Batch 110/145, Loss: 0.2964
Epoch 3/10, Batch 120/145, Loss: 0.1969
Epoch 3/10, Batch 130/145, Loss: 0.3946
Epoch 3/10, Batch 140/145, Loss: 0.3814
Epoch 3/10, Train Loss: 0.2916, Valid Loss: 0.2505
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2569
Epoch 4/10, Batch 20/145, Loss: 0.2540
Epoch 4/10, Batch 30/145, Loss: 0.1535
Epoch 4/10, Batch 40/145, Loss: 0.1476
Epoch 4/10, Batch 50/145, Loss: 0.1231
Epoch 4/10, Batch 60/145, Loss: 0.2885
Epoch 4/10, Batch 70/145, Loss: 0.1838
Epoch 4/10, Batch 80/145, Loss: 0.1978
Epoch 4/10, Batch 90/145, Loss: 0.1761
Epoch 4/10, Batch 100/145, Loss: 0.1995
Epoch 4/10, Batch 110/145, Loss: 0.1196
Epoch 4/10, Batch 120/145, Loss: 0.2191
Epoch 4/10, Batch 130/145, Loss: 0.1840
Epoch 4/10, Batch 140/145, Loss: 0.1453
Epoch 4/10, Train Loss: 0.2586, Valid Loss: 0.2450
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2459
Epoch 5/10, Batch 20/145, Loss: 0.1293
Epoch 5/10, Batch 30/145, Loss: 0.2401
Epoch 5/10, Batch 40/145, Loss: 0.1305
Epoch 5/10, Batch 50/145, Loss: 0.1831
Epoch 5/10, Batch 60/145, Loss: 0.2431
Epoch 5/10, Batch 70/145, Loss: 0.2227
Epoch 5/10, Batch 80/145, Loss: 0.2414
Epoch 5/10, Batch 90/145, Loss: 0.2292
Epoch 5/10, Batch 100/145, Loss: 0.2265
Epoch 5/10, Batch 110/145, Loss: 0.1783
Epoch 5/10, Batch 120/145, Loss: 0.2064
Epoch 5/10, Batch 130/145, Loss: 0.1218
Epoch 5/10, Batch 140/145, Loss: 0.1320
Epoch 5/10, Train Loss: 0.2359, Valid Loss: 0.2347
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1649
Epoch 6/10, Batch 20/145, Loss: 0.3368
Epoch 6/10, Batch 30/145, Loss: 0.2991
Epoch 6/10, Batch 40/145, Loss: 0.3629
Epoch 6/10, Batch 50/145, Loss: 0.2805
Epoch 6/10, Batch 60/145, Loss: 0.1366
Epoch 6/10, Batch 70/145, Loss: 0.0854
Epoch 6/10, Batch 80/145, Loss: 0.1795
Epoch 6/10, Batch 90/145, Loss: 0.2262
Epoch 6/10, Batch 100/145, Loss: 0.3206
Epoch 6/10, Batch 110/145, Loss: 0.2222
Epoch 6/10, Batch 120/145, Loss: 0.2190
Epoch 6/10, Batch 130/145, Loss: 0.3456
Epoch 6/10, Batch 140/145, Loss: 0.2402
Epoch 6/10, Train Loss: 0.2198, Valid Loss: 0.2251
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1345
Epoch 7/10, Batch 20/145, Loss: 0.2381
Epoch 7/10, Batch 30/145, Loss: 0.2204
Epoch 7/10, Batch 40/145, Loss: 0.2936
Epoch 7/10, Batch 50/145, Loss: 0.2709
Epoch 7/10, Batch 60/145, Loss: 0.1403
Epoch 7/10, Batch 70/145, Loss: 0.1283
Epoch 7/10, Batch 80/145, Loss: 0.4613
Epoch 7/10, Batch 90/145, Loss: 0.2609
Epoch 7/10, Batch 100/145, Loss: 0.2389
Epoch 7/10, Batch 110/145, Loss: 0.1770
Epoch 7/10, Batch 120/145, Loss: 0.1558
Epoch 7/10, Batch 130/145, Loss: 0.1317
Epoch 7/10, Batch 140/145, Loss: 0.4156
Epoch 7/10, Train Loss: 0.2083, Valid Loss: 0.2183
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1963
Epoch 8/10, Batch 20/145, Loss: 0.2248
Epoch 8/10, Batch 30/145, Loss: 0.2165
Epoch 8/10, Batch 40/145, Loss: 0.2974
Epoch 8/10, Batch 50/145, Loss: 0.3049
Epoch 8/10, Batch 60/145, Loss: 0.1814
Epoch 8/10, Batch 70/145, Loss: 0.1903
Epoch 8/10, Batch 80/145, Loss: 0.2805
Epoch 8/10, Batch 90/145, Loss: 0.3952
Epoch 8/10, Batch 100/145, Loss: 0.0885
Epoch 8/10, Batch 110/145, Loss: 0.2355
Epoch 8/10, Batch 120/145, Loss: 0.3251
Epoch 8/10, Batch 130/145, Loss: 0.1765
Epoch 8/10, Batch 140/145, Loss: 0.1997
Epoch 8/10, Train Loss: 0.2017, Valid Loss: 0.2121
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2599
Epoch 9/10, Batch 20/145, Loss: 0.1850
Epoch 9/10, Batch 30/145, Loss: 0.1507
Epoch 9/10, Batch 40/145, Loss: 0.1356
Epoch 9/10, Batch 50/145, Loss: 0.1660
Epoch 9/10, Batch 60/145, Loss: 0.2250
Epoch 9/10, Batch 70/145, Loss: 0.1491
Epoch 9/10, Batch 80/145, Loss: 0.1025
Epoch 9/10, Batch 90/145, Loss: 0.2351
Epoch 9/10, Batch 100/145, Loss: 0.1476
Epoch 9/10, Batch 110/145, Loss: 0.3242
Epoch 9/10, Batch 120/145, Loss: 0.0862
Epoch 9/10, Batch 130/145, Loss: 0.1094
Epoch 9/10, Batch 140/145, Loss: 0.1102
Epoch 9/10, Train Loss: 0.1960, Valid Loss: 0.2092
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1405
Epoch 10/10, Batch 20/145, Loss: 0.0821
Epoch 10/10, Batch 30/145, Loss: 0.0736
Epoch 10/10, Batch 40/145, Loss: 0.1605
Epoch 10/10, Batch 50/145, Loss: 0.1930
Epoch 10/10, Batch 60/145, Loss: 0.1325
Epoch 10/10, Batch 70/145, Loss: 0.3557
Epoch 10/10, Batch 80/145, Loss: 0.3574
Epoch 10/10, Batch 90/145, Loss: 0.1384
Epoch 10/10, Batch 100/145, Loss: 0.1573
Epoch 10/10, Batch 110/145, Loss: 0.1147
Epoch 10/10, Batch 120/145, Loss: 0.2217
Epoch 10/10, Batch 130/145, Loss: 0.1576
Epoch 10/10, Batch 140/145, Loss: 0.2443
Epoch 10/10, Train Loss: 0.1900, Valid Loss: 0.2052
Model saved!
Accuracy: 0.9206
Precision: 0.9188
Recall: 0.9206
F1-score: 0.9195
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4111
Epoch 1/10, Batch 20/145, Loss: 0.9199
Epoch 1/10, Batch 30/145, Loss: 0.8825
Epoch 1/10, Batch 40/145, Loss: 0.8119
Epoch 1/10, Batch 50/145, Loss: 0.7437
Epoch 1/10, Batch 60/145, Loss: 0.6512
Epoch 1/10, Batch 70/145, Loss: 0.3623
Epoch 1/10, Batch 80/145, Loss: 0.5235
Epoch 1/10, Batch 90/145, Loss: 0.4145
Epoch 1/10, Batch 100/145, Loss: 0.3603
Epoch 1/10, Batch 110/145, Loss: 0.3693
Epoch 1/10, Batch 120/145, Loss: 0.5873
Epoch 1/10, Batch 130/145, Loss: 0.5849
Epoch 1/10, Batch 140/145, Loss: 0.4357
Epoch 1/10, Train Loss: 0.6740, Valid Loss: 0.3908
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2636
Epoch 2/10, Batch 20/145, Loss: 0.3888
Epoch 2/10, Batch 30/145, Loss: 0.3055
Epoch 2/10, Batch 40/145, Loss: 0.4350
Epoch 2/10, Batch 50/145, Loss: 0.3484
Epoch 2/10, Batch 60/145, Loss: 0.4419
Epoch 2/10, Batch 70/145, Loss: 0.3152
Epoch 2/10, Batch 80/145, Loss: 0.1708
Epoch 2/10, Batch 90/145, Loss: 0.3147
Epoch 2/10, Batch 100/145, Loss: 0.3213
Epoch 2/10, Batch 110/145, Loss: 0.4056
Epoch 2/10, Batch 120/145, Loss: 0.3263
Epoch 2/10, Batch 130/145, Loss: 0.3220
Epoch 2/10, Batch 140/145, Loss: 0.3346
Epoch 2/10, Train Loss: 0.3538, Valid Loss: 0.3101
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2729
Epoch 3/10, Batch 20/145, Loss: 0.1730
Epoch 3/10, Batch 30/145, Loss: 0.4161
Epoch 3/10, Batch 40/145, Loss: 0.2288
Epoch 3/10, Batch 50/145, Loss: 0.1875
Epoch 3/10, Batch 60/145, Loss: 0.4090
Epoch 3/10, Batch 70/145, Loss: 0.3115
Epoch 3/10, Batch 80/145, Loss: 0.2128
Epoch 3/10, Batch 90/145, Loss: 0.2548
Epoch 3/10, Batch 100/145, Loss: 0.1850
Epoch 3/10, Batch 110/145, Loss: 0.2659
Epoch 3/10, Batch 120/145, Loss: 0.1675
Epoch 3/10, Batch 130/145, Loss: 0.4560
Epoch 3/10, Batch 140/145, Loss: 0.2531
Epoch 3/10, Train Loss: 0.2861, Valid Loss: 0.2817
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3652
Epoch 4/10, Batch 20/145, Loss: 0.2662
Epoch 4/10, Batch 30/145, Loss: 0.2889
Epoch 4/10, Batch 40/145, Loss: 0.3287
Epoch 4/10, Batch 50/145, Loss: 0.1334
Epoch 4/10, Batch 60/145, Loss: 0.1947
Epoch 4/10, Batch 70/145, Loss: 0.2069
Epoch 4/10, Batch 80/145, Loss: 0.3962
Epoch 4/10, Batch 90/145, Loss: 0.1994
Epoch 4/10, Batch 100/145, Loss: 0.2328
Epoch 4/10, Batch 110/145, Loss: 0.1734
Epoch 4/10, Batch 120/145, Loss: 0.1525
Epoch 4/10, Batch 130/145, Loss: 0.2216
Epoch 4/10, Batch 140/145, Loss: 0.1277
Epoch 4/10, Train Loss: 0.2573, Valid Loss: 0.2694
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2007
Epoch 5/10, Batch 20/145, Loss: 0.1493
Epoch 5/10, Batch 30/145, Loss: 0.3022
Epoch 5/10, Batch 40/145, Loss: 0.2141
Epoch 5/10, Batch 50/145, Loss: 0.1788
Epoch 5/10, Batch 60/145, Loss: 0.2133
Epoch 5/10, Batch 70/145, Loss: 0.5445
Epoch 5/10, Batch 80/145, Loss: 0.1947
Epoch 5/10, Batch 90/145, Loss: 0.2765
Epoch 5/10, Batch 100/145, Loss: 0.2605
Epoch 5/10, Batch 110/145, Loss: 0.1986
Epoch 5/10, Batch 120/145, Loss: 0.3855
Epoch 5/10, Batch 130/145, Loss: 0.1610
Epoch 5/10, Batch 140/145, Loss: 0.2332
Epoch 5/10, Train Loss: 0.2483, Valid Loss: 0.2564
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2005
Epoch 6/10, Batch 20/145, Loss: 0.5578
Epoch 6/10, Batch 30/145, Loss: 0.2674
Epoch 6/10, Batch 40/145, Loss: 0.2067
Epoch 6/10, Batch 50/145, Loss: 0.2981
Epoch 6/10, Batch 60/145, Loss: 0.2418
Epoch 6/10, Batch 70/145, Loss: 0.2254
Epoch 6/10, Batch 80/145, Loss: 0.1090
Epoch 6/10, Batch 90/145, Loss: 0.1231
Epoch 6/10, Batch 100/145, Loss: 0.2280
Epoch 6/10, Batch 110/145, Loss: 0.1591
Epoch 6/10, Batch 120/145, Loss: 0.1635
Epoch 6/10, Batch 130/145, Loss: 0.1799
Epoch 6/10, Batch 140/145, Loss: 0.1333
Epoch 6/10, Train Loss: 0.2272, Valid Loss: 0.2477
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1962
Epoch 7/10, Batch 20/145, Loss: 0.3252
Epoch 7/10, Batch 30/145, Loss: 0.1550
Epoch 7/10, Batch 40/145, Loss: 0.3823
Epoch 7/10, Batch 50/145, Loss: 0.1403
Epoch 7/10, Batch 60/145, Loss: 0.1376
Epoch 7/10, Batch 70/145, Loss: 0.1043
Epoch 7/10, Batch 80/145, Loss: 0.3134
Epoch 7/10, Batch 90/145, Loss: 0.2156
Epoch 7/10, Batch 100/145, Loss: 0.1210
Epoch 7/10, Batch 110/145, Loss: 0.2473
Epoch 7/10, Batch 120/145, Loss: 0.2176
Epoch 7/10, Batch 130/145, Loss: 0.1563
Epoch 7/10, Batch 140/145, Loss: 0.2641
Epoch 7/10, Train Loss: 0.2112, Valid Loss: 0.2380
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2166
Epoch 8/10, Batch 20/145, Loss: 0.1465
Epoch 8/10, Batch 30/145, Loss: 0.1779
Epoch 8/10, Batch 40/145, Loss: 0.1702
Epoch 8/10, Batch 50/145, Loss: 0.3241
Epoch 8/10, Batch 60/145, Loss: 0.4486
Epoch 8/10, Batch 70/145, Loss: 0.2597
Epoch 8/10, Batch 80/145, Loss: 0.2772
Epoch 8/10, Batch 90/145, Loss: 0.4671
Epoch 8/10, Batch 100/145, Loss: 0.4188
Epoch 8/10, Batch 110/145, Loss: 0.3536
Epoch 8/10, Batch 120/145, Loss: 0.2121
Epoch 8/10, Batch 130/145, Loss: 0.1245
Epoch 8/10, Batch 140/145, Loss: 0.1638
Epoch 8/10, Train Loss: 0.2104, Valid Loss: 0.2397
Epoch 9/10, Batch 10/145, Loss: 0.3090
Epoch 9/10, Batch 20/145, Loss: 0.1904
Epoch 9/10, Batch 30/145, Loss: 0.0922
Epoch 9/10, Batch 40/145, Loss: 0.1375
Epoch 9/10, Batch 50/145, Loss: 0.2011
Epoch 9/10, Batch 60/145, Loss: 0.3148
Epoch 9/10, Batch 70/145, Loss: 0.1314
Epoch 9/10, Batch 80/145, Loss: 0.1322
Epoch 9/10, Batch 90/145, Loss: 0.3444
Epoch 9/10, Batch 100/145, Loss: 0.1426
Epoch 9/10, Batch 110/145, Loss: 0.3328
Epoch 9/10, Batch 120/145, Loss: 0.1698
Epoch 9/10, Batch 130/145, Loss: 0.2234
Epoch 9/10, Batch 140/145, Loss: 0.2860
Epoch 9/10, Train Loss: 0.2061, Valid Loss: 0.2396
Epoch 10/10, Batch 10/145, Loss: 0.1912
Epoch 10/10, Batch 20/145, Loss: 0.2477
Epoch 10/10, Batch 30/145, Loss: 0.1380
Epoch 10/10, Batch 40/145, Loss: 0.0988
Epoch 10/10, Batch 50/145, Loss: 0.1535
Epoch 10/10, Batch 60/145, Loss: 0.1628
Epoch 10/10, Batch 70/145, Loss: 0.2626
Epoch 10/10, Batch 80/145, Loss: 0.2412
Epoch 10/10, Batch 90/145, Loss: 0.2114
Epoch 10/10, Batch 100/145, Loss: 0.1022
Epoch 10/10, Batch 110/145, Loss: 0.2010
Epoch 10/10, Batch 120/145, Loss: 0.0916
Epoch 10/10, Batch 130/145, Loss: 0.1810
Epoch 10/10, Batch 140/145, Loss: 0.1137
Epoch 10/10, Train Loss: 0.1886, Valid Loss: 0.2414
Accuracy: 0.9159
Precision: 0.9133
Recall: 0.9159
F1-score: 0.9140
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3657
Epoch 1/10, Batch 20/145, Loss: 0.8678
Epoch 1/10, Batch 30/145, Loss: 0.9722
Epoch 1/10, Batch 40/145, Loss: 0.7766
Epoch 1/10, Batch 50/145, Loss: 0.7552
Epoch 1/10, Batch 60/145, Loss: 0.6968
Epoch 1/10, Batch 70/145, Loss: 0.5627
Epoch 1/10, Batch 80/145, Loss: 0.4602
Epoch 1/10, Batch 90/145, Loss: 0.5118
Epoch 1/10, Batch 100/145, Loss: 0.5221
Epoch 1/10, Batch 110/145, Loss: 0.4404
Epoch 1/10, Batch 120/145, Loss: 0.4328
Epoch 1/10, Batch 130/145, Loss: 0.5661
Epoch 1/10, Batch 140/145, Loss: 0.3817
Epoch 1/10, Train Loss: 0.6802, Valid Loss: 0.3855
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4719
Epoch 2/10, Batch 20/145, Loss: 0.2843
Epoch 2/10, Batch 30/145, Loss: 0.2640
Epoch 2/10, Batch 40/145, Loss: 0.4956
Epoch 2/10, Batch 50/145, Loss: 0.3067
Epoch 2/10, Batch 60/145, Loss: 0.3682
Epoch 2/10, Batch 70/145, Loss: 0.2965
Epoch 2/10, Batch 80/145, Loss: 0.3238
Epoch 2/10, Batch 90/145, Loss: 0.3306
Epoch 2/10, Batch 100/145, Loss: 0.5540
Epoch 2/10, Batch 110/145, Loss: 0.5291
Epoch 2/10, Batch 120/145, Loss: 0.3308
Epoch 2/10, Batch 130/145, Loss: 0.2407
Epoch 2/10, Batch 140/145, Loss: 0.3900
Epoch 2/10, Train Loss: 0.3563, Valid Loss: 0.3035
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2822
Epoch 3/10, Batch 20/145, Loss: 0.2180
Epoch 3/10, Batch 30/145, Loss: 0.4766
Epoch 3/10, Batch 40/145, Loss: 0.1273
Epoch 3/10, Batch 50/145, Loss: 0.2803
Epoch 3/10, Batch 60/145, Loss: 0.3725
Epoch 3/10, Batch 70/145, Loss: 0.3797
Epoch 3/10, Batch 80/145, Loss: 0.2660
Epoch 3/10, Batch 90/145, Loss: 0.5115
Epoch 3/10, Batch 100/145, Loss: 0.2129
Epoch 3/10, Batch 110/145, Loss: 0.3053
Epoch 3/10, Batch 120/145, Loss: 0.3558
Epoch 3/10, Batch 130/145, Loss: 0.3196
Epoch 3/10, Batch 140/145, Loss: 0.3506
Epoch 3/10, Train Loss: 0.2963, Valid Loss: 0.2732
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2795
Epoch 4/10, Batch 20/145, Loss: 0.3083
Epoch 4/10, Batch 30/145, Loss: 0.3345
Epoch 4/10, Batch 40/145, Loss: 0.3193
Epoch 4/10, Batch 50/145, Loss: 0.1245
Epoch 4/10, Batch 60/145, Loss: 0.2902
Epoch 4/10, Batch 70/145, Loss: 0.2335
Epoch 4/10, Batch 80/145, Loss: 0.2286
Epoch 4/10, Batch 90/145, Loss: 0.3765
Epoch 4/10, Batch 100/145, Loss: 0.2976
Epoch 4/10, Batch 110/145, Loss: 0.1378
Epoch 4/10, Batch 120/145, Loss: 0.1869
Epoch 4/10, Batch 130/145, Loss: 0.2676
Epoch 4/10, Batch 140/145, Loss: 0.3083
Epoch 4/10, Train Loss: 0.2616, Valid Loss: 0.2621
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1451
Epoch 5/10, Batch 20/145, Loss: 0.1710
Epoch 5/10, Batch 30/145, Loss: 0.2760
Epoch 5/10, Batch 40/145, Loss: 0.3214
Epoch 5/10, Batch 50/145, Loss: 0.2687
Epoch 5/10, Batch 60/145, Loss: 0.2449
Epoch 5/10, Batch 70/145, Loss: 0.2175
Epoch 5/10, Batch 80/145, Loss: 0.1424
Epoch 5/10, Batch 90/145, Loss: 0.1680
Epoch 5/10, Batch 100/145, Loss: 0.2019
Epoch 5/10, Batch 110/145, Loss: 0.2866
Epoch 5/10, Batch 120/145, Loss: 0.2789
Epoch 5/10, Batch 130/145, Loss: 0.2823
Epoch 5/10, Batch 140/145, Loss: 0.2705
Epoch 5/10, Train Loss: 0.2466, Valid Loss: 0.2469
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3133
Epoch 6/10, Batch 20/145, Loss: 0.4855
Epoch 6/10, Batch 30/145, Loss: 0.3695
Epoch 6/10, Batch 40/145, Loss: 0.1767
Epoch 6/10, Batch 50/145, Loss: 0.3378
Epoch 6/10, Batch 60/145, Loss: 0.1898
Epoch 6/10, Batch 70/145, Loss: 0.2474
Epoch 6/10, Batch 80/145, Loss: 0.2127
Epoch 6/10, Batch 90/145, Loss: 0.1824
Epoch 6/10, Batch 100/145, Loss: 0.2500
Epoch 6/10, Batch 110/145, Loss: 0.1235
Epoch 6/10, Batch 120/145, Loss: 0.3266
Epoch 6/10, Batch 130/145, Loss: 0.1043
Epoch 6/10, Batch 140/145, Loss: 0.1792
Epoch 6/10, Train Loss: 0.2331, Valid Loss: 0.2358
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2226
Epoch 7/10, Batch 20/145, Loss: 0.3262
Epoch 7/10, Batch 30/145, Loss: 0.3128
Epoch 7/10, Batch 40/145, Loss: 0.3504
Epoch 7/10, Batch 50/145, Loss: 0.2366
Epoch 7/10, Batch 60/145, Loss: 0.1782
Epoch 7/10, Batch 70/145, Loss: 0.1326
Epoch 7/10, Batch 80/145, Loss: 0.4136
Epoch 7/10, Batch 90/145, Loss: 0.1166
Epoch 7/10, Batch 100/145, Loss: 0.2258
Epoch 7/10, Batch 110/145, Loss: 0.2653
Epoch 7/10, Batch 120/145, Loss: 0.2655
Epoch 7/10, Batch 130/145, Loss: 0.1240
Epoch 7/10, Batch 140/145, Loss: 0.2067
Epoch 7/10, Train Loss: 0.2151, Valid Loss: 0.2328
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2794
Epoch 8/10, Batch 20/145, Loss: 0.2623
Epoch 8/10, Batch 30/145, Loss: 0.1198
Epoch 8/10, Batch 40/145, Loss: 0.1111
Epoch 8/10, Batch 50/145, Loss: 0.2303
Epoch 8/10, Batch 60/145, Loss: 0.1627
Epoch 8/10, Batch 70/145, Loss: 0.3721
Epoch 8/10, Batch 80/145, Loss: 0.2713
Epoch 8/10, Batch 90/145, Loss: 0.4725
Epoch 8/10, Batch 100/145, Loss: 0.3526
Epoch 8/10, Batch 110/145, Loss: 0.2400
Epoch 8/10, Batch 120/145, Loss: 0.2578
Epoch 8/10, Batch 130/145, Loss: 0.1211
Epoch 8/10, Batch 140/145, Loss: 0.2906
Epoch 8/10, Train Loss: 0.2128, Valid Loss: 0.2308
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3800
Epoch 9/10, Batch 20/145, Loss: 0.1305
Epoch 9/10, Batch 30/145, Loss: 0.1708
Epoch 9/10, Batch 40/145, Loss: 0.2521
Epoch 9/10, Batch 50/145, Loss: 0.2119
Epoch 9/10, Batch 60/145, Loss: 0.2601
Epoch 9/10, Batch 70/145, Loss: 0.2314
Epoch 9/10, Batch 80/145, Loss: 0.0916
Epoch 9/10, Batch 90/145, Loss: 0.2477
Epoch 9/10, Batch 100/145, Loss: 0.1199
Epoch 9/10, Batch 110/145, Loss: 0.3593
Epoch 9/10, Batch 120/145, Loss: 0.0781
Epoch 9/10, Batch 130/145, Loss: 0.2048
Epoch 9/10, Batch 140/145, Loss: 0.2628
Epoch 9/10, Train Loss: 0.2032, Valid Loss: 0.2246
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1397
Epoch 10/10, Batch 20/145, Loss: 0.3684
Epoch 10/10, Batch 30/145, Loss: 0.1246
Epoch 10/10, Batch 40/145, Loss: 0.0879
Epoch 10/10, Batch 50/145, Loss: 0.1538
Epoch 10/10, Batch 60/145, Loss: 0.2167
Epoch 10/10, Batch 70/145, Loss: 0.2464
Epoch 10/10, Batch 80/145, Loss: 0.1768
Epoch 10/10, Batch 90/145, Loss: 0.1363
Epoch 10/10, Batch 100/145, Loss: 0.1417
Epoch 10/10, Batch 110/145, Loss: 0.1558
Epoch 10/10, Batch 120/145, Loss: 0.2585
Epoch 10/10, Batch 130/145, Loss: 0.2063
Epoch 10/10, Batch 140/145, Loss: 0.2632
Epoch 10/10, Train Loss: 0.1911, Valid Loss: 0.2228
Model saved!
Accuracy: 0.9136
Precision: 0.9104
Recall: 0.9136
F1-score: 0.9105
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3046
Epoch 1/10, Batch 20/145, Loss: 0.9422
Epoch 1/10, Batch 30/145, Loss: 0.9193
Epoch 1/10, Batch 40/145, Loss: 0.7409
Epoch 1/10, Batch 50/145, Loss: 0.7033
Epoch 1/10, Batch 60/145, Loss: 0.7163
Epoch 1/10, Batch 70/145, Loss: 0.5707
Epoch 1/10, Batch 80/145, Loss: 0.6457
Epoch 1/10, Batch 90/145, Loss: 0.3969
Epoch 1/10, Batch 100/145, Loss: 0.4338
Epoch 1/10, Batch 110/145, Loss: 0.6550
Epoch 1/10, Batch 120/145, Loss: 0.5055
Epoch 1/10, Batch 130/145, Loss: 0.4683
Epoch 1/10, Batch 140/145, Loss: 0.3625
Epoch 1/10, Train Loss: 0.6814, Valid Loss: 0.3793
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3187
Epoch 2/10, Batch 20/145, Loss: 0.3355
Epoch 2/10, Batch 30/145, Loss: 0.3200
Epoch 2/10, Batch 40/145, Loss: 0.5651
Epoch 2/10, Batch 50/145, Loss: 0.2923
Epoch 2/10, Batch 60/145, Loss: 0.3518
Epoch 2/10, Batch 70/145, Loss: 0.3056
Epoch 2/10, Batch 80/145, Loss: 0.3289
Epoch 2/10, Batch 90/145, Loss: 0.4223
Epoch 2/10, Batch 100/145, Loss: 0.3069
Epoch 2/10, Batch 110/145, Loss: 0.3083
Epoch 2/10, Batch 120/145, Loss: 0.4805
Epoch 2/10, Batch 130/145, Loss: 0.3205
Epoch 2/10, Batch 140/145, Loss: 0.2872
Epoch 2/10, Train Loss: 0.3541, Valid Loss: 0.2933
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2064
Epoch 3/10, Batch 20/145, Loss: 0.3007
Epoch 3/10, Batch 30/145, Loss: 0.3586
Epoch 3/10, Batch 40/145, Loss: 0.2008
Epoch 3/10, Batch 50/145, Loss: 0.2385
Epoch 3/10, Batch 60/145, Loss: 0.3193
Epoch 3/10, Batch 70/145, Loss: 0.3100
Epoch 3/10, Batch 80/145, Loss: 0.2632
Epoch 3/10, Batch 90/145, Loss: 0.3045
Epoch 3/10, Batch 100/145, Loss: 0.3625
Epoch 3/10, Batch 110/145, Loss: 0.2920
Epoch 3/10, Batch 120/145, Loss: 0.2737
Epoch 3/10, Batch 130/145, Loss: 0.2643
Epoch 3/10, Batch 140/145, Loss: 0.2882
Epoch 3/10, Train Loss: 0.2912, Valid Loss: 0.2597
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4059
Epoch 4/10, Batch 20/145, Loss: 0.2342
Epoch 4/10, Batch 30/145, Loss: 0.1555
Epoch 4/10, Batch 40/145, Loss: 0.4364
Epoch 4/10, Batch 50/145, Loss: 0.1706
Epoch 4/10, Batch 60/145, Loss: 0.2580
Epoch 4/10, Batch 70/145, Loss: 0.2109
Epoch 4/10, Batch 80/145, Loss: 0.2167
Epoch 4/10, Batch 90/145, Loss: 0.2767
Epoch 4/10, Batch 100/145, Loss: 0.2907
Epoch 4/10, Batch 110/145, Loss: 0.1154
Epoch 4/10, Batch 120/145, Loss: 0.3072
Epoch 4/10, Batch 130/145, Loss: 0.3746
Epoch 4/10, Batch 140/145, Loss: 0.0923
Epoch 4/10, Train Loss: 0.2581, Valid Loss: 0.2482
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1520
Epoch 5/10, Batch 20/145, Loss: 0.1838
Epoch 5/10, Batch 30/145, Loss: 0.3313
Epoch 5/10, Batch 40/145, Loss: 0.1480
Epoch 5/10, Batch 50/145, Loss: 0.1771
Epoch 5/10, Batch 60/145, Loss: 0.2448
Epoch 5/10, Batch 70/145, Loss: 0.2446
Epoch 5/10, Batch 80/145, Loss: 0.1864
Epoch 5/10, Batch 90/145, Loss: 0.5462
Epoch 5/10, Batch 100/145, Loss: 0.1966
Epoch 5/10, Batch 110/145, Loss: 0.1892
Epoch 5/10, Batch 120/145, Loss: 0.3732
Epoch 5/10, Batch 130/145, Loss: 0.1050
Epoch 5/10, Batch 140/145, Loss: 0.1458
Epoch 5/10, Train Loss: 0.2513, Valid Loss: 0.2407
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1918
Epoch 6/10, Batch 20/145, Loss: 0.2534
Epoch 6/10, Batch 30/145, Loss: 0.4354
Epoch 6/10, Batch 40/145, Loss: 0.1691
Epoch 6/10, Batch 50/145, Loss: 0.4264
Epoch 6/10, Batch 60/145, Loss: 0.1404
Epoch 6/10, Batch 70/145, Loss: 0.2377
Epoch 6/10, Batch 80/145, Loss: 0.3178
Epoch 6/10, Batch 90/145, Loss: 0.3023
Epoch 6/10, Batch 100/145, Loss: 0.2807
Epoch 6/10, Batch 110/145, Loss: 0.2284
Epoch 6/10, Batch 120/145, Loss: 0.2737
Epoch 6/10, Batch 130/145, Loss: 0.0885
Epoch 6/10, Batch 140/145, Loss: 0.2813
Epoch 6/10, Train Loss: 0.2270, Valid Loss: 0.2292
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2335
Epoch 7/10, Batch 20/145, Loss: 0.1797
Epoch 7/10, Batch 30/145, Loss: 0.3214
Epoch 7/10, Batch 40/145, Loss: 0.2820
Epoch 7/10, Batch 50/145, Loss: 0.1006
Epoch 7/10, Batch 60/145, Loss: 0.1655
Epoch 7/10, Batch 70/145, Loss: 0.1269
Epoch 7/10, Batch 80/145, Loss: 0.3454
Epoch 7/10, Batch 90/145, Loss: 0.1647
Epoch 7/10, Batch 100/145, Loss: 0.2793
Epoch 7/10, Batch 110/145, Loss: 0.2619
Epoch 7/10, Batch 120/145, Loss: 0.1402
Epoch 7/10, Batch 130/145, Loss: 0.1857
Epoch 7/10, Batch 140/145, Loss: 0.2877
Epoch 7/10, Train Loss: 0.2184, Valid Loss: 0.2239
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1539
Epoch 8/10, Batch 20/145, Loss: 0.1219
Epoch 8/10, Batch 30/145, Loss: 0.2084
Epoch 8/10, Batch 40/145, Loss: 0.1966
Epoch 8/10, Batch 50/145, Loss: 0.2247
Epoch 8/10, Batch 60/145, Loss: 0.2165
Epoch 8/10, Batch 70/145, Loss: 0.2218
Epoch 8/10, Batch 80/145, Loss: 0.2023
Epoch 8/10, Batch 90/145, Loss: 0.1605
Epoch 8/10, Batch 100/145, Loss: 0.2290
Epoch 8/10, Batch 110/145, Loss: 0.2001
Epoch 8/10, Batch 120/145, Loss: 0.1360
Epoch 8/10, Batch 130/145, Loss: 0.1598
Epoch 8/10, Batch 140/145, Loss: 0.1169
Epoch 8/10, Train Loss: 0.2050, Valid Loss: 0.2202
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2198
Epoch 9/10, Batch 20/145, Loss: 0.1665
Epoch 9/10, Batch 30/145, Loss: 0.2058
Epoch 9/10, Batch 40/145, Loss: 0.2300
Epoch 9/10, Batch 50/145, Loss: 0.0816
Epoch 9/10, Batch 60/145, Loss: 0.4204
Epoch 9/10, Batch 70/145, Loss: 0.3121
Epoch 9/10, Batch 80/145, Loss: 0.0965
Epoch 9/10, Batch 90/145, Loss: 0.2513
Epoch 9/10, Batch 100/145, Loss: 0.1412
Epoch 9/10, Batch 110/145, Loss: 0.1094
Epoch 9/10, Batch 120/145, Loss: 0.2517
Epoch 9/10, Batch 130/145, Loss: 0.2957
Epoch 9/10, Batch 140/145, Loss: 0.1533
Epoch 9/10, Train Loss: 0.1987, Valid Loss: 0.2187
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0560
Epoch 10/10, Batch 20/145, Loss: 0.1244
Epoch 10/10, Batch 30/145, Loss: 0.1262
Epoch 10/10, Batch 40/145, Loss: 0.1190
Epoch 10/10, Batch 50/145, Loss: 0.2180
Epoch 10/10, Batch 60/145, Loss: 0.1917
Epoch 10/10, Batch 70/145, Loss: 0.2531
Epoch 10/10, Batch 80/145, Loss: 0.1607
Epoch 10/10, Batch 90/145, Loss: 0.2017
Epoch 10/10, Batch 100/145, Loss: 0.2311
Epoch 10/10, Batch 110/145, Loss: 0.4177
Epoch 10/10, Batch 120/145, Loss: 0.2355
Epoch 10/10, Batch 130/145, Loss: 0.1377
Epoch 10/10, Batch 140/145, Loss: 0.2275
Epoch 10/10, Train Loss: 0.1960, Valid Loss: 0.2233
Accuracy: 0.9252
Precision: 0.9239
Recall: 0.9252
F1-score: 0.9244
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3753
Epoch 1/10, Batch 20/145, Loss: 0.8787
Epoch 1/10, Batch 30/145, Loss: 0.9210
Epoch 1/10, Batch 40/145, Loss: 0.6961
Epoch 1/10, Batch 50/145, Loss: 0.7982
Epoch 1/10, Batch 60/145, Loss: 0.5880
Epoch 1/10, Batch 70/145, Loss: 0.4556
Epoch 1/10, Batch 80/145, Loss: 0.4788
Epoch 1/10, Batch 90/145, Loss: 0.3205
Epoch 1/10, Batch 100/145, Loss: 0.4148
Epoch 1/10, Batch 110/145, Loss: 0.4351
Epoch 1/10, Batch 120/145, Loss: 0.6230
Epoch 1/10, Batch 130/145, Loss: 0.4411
Epoch 1/10, Batch 140/145, Loss: 0.4761
Epoch 1/10, Train Loss: 0.6793, Valid Loss: 0.3743
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3121
Epoch 2/10, Batch 20/145, Loss: 0.3519
Epoch 2/10, Batch 30/145, Loss: 0.3910
Epoch 2/10, Batch 40/145, Loss: 0.4188
Epoch 2/10, Batch 50/145, Loss: 0.3451
Epoch 2/10, Batch 60/145, Loss: 0.4609
Epoch 2/10, Batch 70/145, Loss: 0.2781
Epoch 2/10, Batch 80/145, Loss: 0.3338
Epoch 2/10, Batch 90/145, Loss: 0.2801
Epoch 2/10, Batch 100/145, Loss: 0.2857
Epoch 2/10, Batch 110/145, Loss: 0.3919
Epoch 2/10, Batch 120/145, Loss: 0.3445
Epoch 2/10, Batch 130/145, Loss: 0.2975
Epoch 2/10, Batch 140/145, Loss: 0.3663
Epoch 2/10, Train Loss: 0.3583, Valid Loss: 0.2913
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2112
Epoch 3/10, Batch 20/145, Loss: 0.4077
Epoch 3/10, Batch 30/145, Loss: 0.3791
Epoch 3/10, Batch 40/145, Loss: 0.3518
Epoch 3/10, Batch 50/145, Loss: 0.3423
Epoch 3/10, Batch 60/145, Loss: 0.3675
Epoch 3/10, Batch 70/145, Loss: 0.2514
Epoch 3/10, Batch 80/145, Loss: 0.1994
Epoch 3/10, Batch 90/145, Loss: 0.1720
Epoch 3/10, Batch 100/145, Loss: 0.3188
Epoch 3/10, Batch 110/145, Loss: 0.1346
Epoch 3/10, Batch 120/145, Loss: 0.4028
Epoch 3/10, Batch 130/145, Loss: 0.4078
Epoch 3/10, Batch 140/145, Loss: 0.2494
Epoch 3/10, Train Loss: 0.2920, Valid Loss: 0.2638
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2270
Epoch 4/10, Batch 20/145, Loss: 0.2487
Epoch 4/10, Batch 30/145, Loss: 0.2784
Epoch 4/10, Batch 40/145, Loss: 0.1705
Epoch 4/10, Batch 50/145, Loss: 0.1728
Epoch 4/10, Batch 60/145, Loss: 0.3259
Epoch 4/10, Batch 70/145, Loss: 0.1652
Epoch 4/10, Batch 80/145, Loss: 0.1905
Epoch 4/10, Batch 90/145, Loss: 0.2169
Epoch 4/10, Batch 100/145, Loss: 0.4319
Epoch 4/10, Batch 110/145, Loss: 0.1013
Epoch 4/10, Batch 120/145, Loss: 0.1389
Epoch 4/10, Batch 130/145, Loss: 0.1189
Epoch 4/10, Batch 140/145, Loss: 0.2030
Epoch 4/10, Train Loss: 0.2609, Valid Loss: 0.2486
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2275
Epoch 5/10, Batch 20/145, Loss: 0.0802
Epoch 5/10, Batch 30/145, Loss: 0.2082
Epoch 5/10, Batch 40/145, Loss: 0.1036
Epoch 5/10, Batch 50/145, Loss: 0.2495
Epoch 5/10, Batch 60/145, Loss: 0.1088
Epoch 5/10, Batch 70/145, Loss: 0.1193
Epoch 5/10, Batch 80/145, Loss: 0.1963
Epoch 5/10, Batch 90/145, Loss: 0.4067
Epoch 5/10, Batch 100/145, Loss: 0.3332
Epoch 5/10, Batch 110/145, Loss: 0.1753
Epoch 5/10, Batch 120/145, Loss: 0.3726
Epoch 5/10, Batch 130/145, Loss: 0.1928
Epoch 5/10, Batch 140/145, Loss: 0.1471
Epoch 5/10, Train Loss: 0.2427, Valid Loss: 0.2307
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1762
Epoch 6/10, Batch 20/145, Loss: 0.3972
Epoch 6/10, Batch 30/145, Loss: 0.1993
Epoch 6/10, Batch 40/145, Loss: 0.2666
Epoch 6/10, Batch 50/145, Loss: 0.2262
Epoch 6/10, Batch 60/145, Loss: 0.1521
Epoch 6/10, Batch 70/145, Loss: 0.2081
Epoch 6/10, Batch 80/145, Loss: 0.2595
Epoch 6/10, Batch 90/145, Loss: 0.1486
Epoch 6/10, Batch 100/145, Loss: 0.1632
Epoch 6/10, Batch 110/145, Loss: 0.1851
Epoch 6/10, Batch 120/145, Loss: 0.5958
Epoch 6/10, Batch 130/145, Loss: 0.1930
Epoch 6/10, Batch 140/145, Loss: 0.1446
Epoch 6/10, Train Loss: 0.2314, Valid Loss: 0.2276
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2265
Epoch 7/10, Batch 20/145, Loss: 0.3097
Epoch 7/10, Batch 30/145, Loss: 0.1201
Epoch 7/10, Batch 40/145, Loss: 0.2507
Epoch 7/10, Batch 50/145, Loss: 0.2222
Epoch 7/10, Batch 60/145, Loss: 0.2242
Epoch 7/10, Batch 70/145, Loss: 0.1912
Epoch 7/10, Batch 80/145, Loss: 0.3013
Epoch 7/10, Batch 90/145, Loss: 0.2569
Epoch 7/10, Batch 100/145, Loss: 0.3578
Epoch 7/10, Batch 110/145, Loss: 0.1951
Epoch 7/10, Batch 120/145, Loss: 0.3187
Epoch 7/10, Batch 130/145, Loss: 0.1248
Epoch 7/10, Batch 140/145, Loss: 0.3330
Epoch 7/10, Train Loss: 0.2203, Valid Loss: 0.2188
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1486
Epoch 8/10, Batch 20/145, Loss: 0.1503
Epoch 8/10, Batch 30/145, Loss: 0.1311
Epoch 8/10, Batch 40/145, Loss: 0.1949
Epoch 8/10, Batch 50/145, Loss: 0.2586
Epoch 8/10, Batch 60/145, Loss: 0.2820
Epoch 8/10, Batch 70/145, Loss: 0.3845
Epoch 8/10, Batch 80/145, Loss: 0.1651
Epoch 8/10, Batch 90/145, Loss: 0.2222
Epoch 8/10, Batch 100/145, Loss: 0.2044
Epoch 8/10, Batch 110/145, Loss: 0.1930
Epoch 8/10, Batch 120/145, Loss: 0.2954
Epoch 8/10, Batch 130/145, Loss: 0.1776
Epoch 8/10, Batch 140/145, Loss: 0.3863
Epoch 8/10, Train Loss: 0.2112, Valid Loss: 0.2163
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2843
Epoch 9/10, Batch 20/145, Loss: 0.2016
Epoch 9/10, Batch 30/145, Loss: 0.1323
Epoch 9/10, Batch 40/145, Loss: 0.1552
Epoch 9/10, Batch 50/145, Loss: 0.2753
Epoch 9/10, Batch 60/145, Loss: 0.2119
Epoch 9/10, Batch 70/145, Loss: 0.1892
Epoch 9/10, Batch 80/145, Loss: 0.0934
Epoch 9/10, Batch 90/145, Loss: 0.2703
Epoch 9/10, Batch 100/145, Loss: 0.2504
Epoch 9/10, Batch 110/145, Loss: 0.3769
Epoch 9/10, Batch 120/145, Loss: 0.1525
Epoch 9/10, Batch 130/145, Loss: 0.2349
Epoch 9/10, Batch 140/145, Loss: 0.1883
Epoch 9/10, Train Loss: 0.2040, Valid Loss: 0.2151
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1342
Epoch 10/10, Batch 20/145, Loss: 0.1057
Epoch 10/10, Batch 30/145, Loss: 0.2998
Epoch 10/10, Batch 40/145, Loss: 0.1729
Epoch 10/10, Batch 50/145, Loss: 0.2683
Epoch 10/10, Batch 60/145, Loss: 0.2706
Epoch 10/10, Batch 70/145, Loss: 0.1765
Epoch 10/10, Batch 80/145, Loss: 0.2586
Epoch 10/10, Batch 90/145, Loss: 0.1332
Epoch 10/10, Batch 100/145, Loss: 0.2822
Epoch 10/10, Batch 110/145, Loss: 0.2129
Epoch 10/10, Batch 120/145, Loss: 0.0835
Epoch 10/10, Batch 130/145, Loss: 0.1608
Epoch 10/10, Batch 140/145, Loss: 0.0983
Epoch 10/10, Train Loss: 0.2027, Valid Loss: 0.2112
Model saved!
Accuracy: 0.9112
Precision: 0.9086
Recall: 0.9112
F1-score: 0.9096
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3250
Epoch 1/10, Batch 20/145, Loss: 0.9500
Epoch 1/10, Batch 30/145, Loss: 0.9382
Epoch 1/10, Batch 40/145, Loss: 0.7612
Epoch 1/10, Batch 50/145, Loss: 0.6841
Epoch 1/10, Batch 60/145, Loss: 0.7388
Epoch 1/10, Batch 70/145, Loss: 0.5734
Epoch 1/10, Batch 80/145, Loss: 0.4938
Epoch 1/10, Batch 90/145, Loss: 0.4481
Epoch 1/10, Batch 100/145, Loss: 0.5445
Epoch 1/10, Batch 110/145, Loss: 0.3975
Epoch 1/10, Batch 120/145, Loss: 0.5149
Epoch 1/10, Batch 130/145, Loss: 0.5508
Epoch 1/10, Batch 140/145, Loss: 0.3652
Epoch 1/10, Train Loss: 0.6771, Valid Loss: 0.3754
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3405
Epoch 2/10, Batch 20/145, Loss: 0.3806
Epoch 2/10, Batch 30/145, Loss: 0.2277
Epoch 2/10, Batch 40/145, Loss: 0.4168
Epoch 2/10, Batch 50/145, Loss: 0.3121
Epoch 2/10, Batch 60/145, Loss: 0.3856
Epoch 2/10, Batch 70/145, Loss: 0.2514
Epoch 2/10, Batch 80/145, Loss: 0.2406
Epoch 2/10, Batch 90/145, Loss: 0.3825
Epoch 2/10, Batch 100/145, Loss: 0.3021
Epoch 2/10, Batch 110/145, Loss: 0.2526
Epoch 2/10, Batch 120/145, Loss: 0.2484
Epoch 2/10, Batch 130/145, Loss: 0.2972
Epoch 2/10, Batch 140/145, Loss: 0.3657
Epoch 2/10, Train Loss: 0.3522, Valid Loss: 0.2976
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1919
Epoch 3/10, Batch 20/145, Loss: 0.2076
Epoch 3/10, Batch 30/145, Loss: 0.3610
Epoch 3/10, Batch 40/145, Loss: 0.1291
Epoch 3/10, Batch 50/145, Loss: 0.2798
Epoch 3/10, Batch 60/145, Loss: 0.3879
Epoch 3/10, Batch 70/145, Loss: 0.3229
Epoch 3/10, Batch 80/145, Loss: 0.2317
Epoch 3/10, Batch 90/145, Loss: 0.3514
Epoch 3/10, Batch 100/145, Loss: 0.2213
Epoch 3/10, Batch 110/145, Loss: 0.3277
Epoch 3/10, Batch 120/145, Loss: 0.2608
Epoch 3/10, Batch 130/145, Loss: 0.3524
Epoch 3/10, Batch 140/145, Loss: 0.2518
Epoch 3/10, Train Loss: 0.2946, Valid Loss: 0.2664
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3299
Epoch 4/10, Batch 20/145, Loss: 0.2529
Epoch 4/10, Batch 30/145, Loss: 0.2681
Epoch 4/10, Batch 40/145, Loss: 0.2542
Epoch 4/10, Batch 50/145, Loss: 0.2560
Epoch 4/10, Batch 60/145, Loss: 0.2889
Epoch 4/10, Batch 70/145, Loss: 0.3048
Epoch 4/10, Batch 80/145, Loss: 0.2188
Epoch 4/10, Batch 90/145, Loss: 0.2387
Epoch 4/10, Batch 100/145, Loss: 0.2437
Epoch 4/10, Batch 110/145, Loss: 0.0796
Epoch 4/10, Batch 120/145, Loss: 0.3406
Epoch 4/10, Batch 130/145, Loss: 0.2095
Epoch 4/10, Batch 140/145, Loss: 0.1747
Epoch 4/10, Train Loss: 0.2644, Valid Loss: 0.2544
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1837
Epoch 5/10, Batch 20/145, Loss: 0.1994
Epoch 5/10, Batch 30/145, Loss: 0.1683
Epoch 5/10, Batch 40/145, Loss: 0.1227
Epoch 5/10, Batch 50/145, Loss: 0.3461
Epoch 5/10, Batch 60/145, Loss: 0.3467
Epoch 5/10, Batch 70/145, Loss: 0.1870
Epoch 5/10, Batch 80/145, Loss: 0.1339
Epoch 5/10, Batch 90/145, Loss: 0.2626
Epoch 5/10, Batch 100/145, Loss: 0.1752
Epoch 5/10, Batch 110/145, Loss: 0.1088
Epoch 5/10, Batch 120/145, Loss: 0.3250
Epoch 5/10, Batch 130/145, Loss: 0.3015
Epoch 5/10, Batch 140/145, Loss: 0.2590
Epoch 5/10, Train Loss: 0.2502, Valid Loss: 0.2448
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1555
Epoch 6/10, Batch 20/145, Loss: 0.3737
Epoch 6/10, Batch 30/145, Loss: 0.2738
Epoch 6/10, Batch 40/145, Loss: 0.3271
Epoch 6/10, Batch 50/145, Loss: 0.2901
Epoch 6/10, Batch 60/145, Loss: 0.2614
Epoch 6/10, Batch 70/145, Loss: 0.2318
Epoch 6/10, Batch 80/145, Loss: 0.2945
Epoch 6/10, Batch 90/145, Loss: 0.4494
Epoch 6/10, Batch 100/145, Loss: 0.2456
Epoch 6/10, Batch 110/145, Loss: 0.2478
Epoch 6/10, Batch 120/145, Loss: 0.3084
Epoch 6/10, Batch 130/145, Loss: 0.1263
Epoch 6/10, Batch 140/145, Loss: 0.2005
Epoch 6/10, Train Loss: 0.2285, Valid Loss: 0.2340
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2361
Epoch 7/10, Batch 20/145, Loss: 0.3259
Epoch 7/10, Batch 30/145, Loss: 0.1541
Epoch 7/10, Batch 40/145, Loss: 0.3506
Epoch 7/10, Batch 50/145, Loss: 0.2054
Epoch 7/10, Batch 60/145, Loss: 0.1283
Epoch 7/10, Batch 70/145, Loss: 0.3461
Epoch 7/10, Batch 80/145, Loss: 0.3463
Epoch 7/10, Batch 90/145, Loss: 0.1702
Epoch 7/10, Batch 100/145, Loss: 0.1188
Epoch 7/10, Batch 110/145, Loss: 0.1696
Epoch 7/10, Batch 120/145, Loss: 0.1457
Epoch 7/10, Batch 130/145, Loss: 0.1045
Epoch 7/10, Batch 140/145, Loss: 0.2059
Epoch 7/10, Train Loss: 0.2162, Valid Loss: 0.2276
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2094
Epoch 8/10, Batch 20/145, Loss: 0.2940
Epoch 8/10, Batch 30/145, Loss: 0.3826
Epoch 8/10, Batch 40/145, Loss: 0.3000
Epoch 8/10, Batch 50/145, Loss: 0.2398
Epoch 8/10, Batch 60/145, Loss: 0.2143
Epoch 8/10, Batch 70/145, Loss: 0.1734
Epoch 8/10, Batch 80/145, Loss: 0.2716
Epoch 8/10, Batch 90/145, Loss: 0.2834
Epoch 8/10, Batch 100/145, Loss: 0.2245
Epoch 8/10, Batch 110/145, Loss: 0.4887
Epoch 8/10, Batch 120/145, Loss: 0.2694
Epoch 8/10, Batch 130/145, Loss: 0.2990
Epoch 8/10, Batch 140/145, Loss: 0.2205
Epoch 8/10, Train Loss: 0.2143, Valid Loss: 0.2201
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2761
Epoch 9/10, Batch 20/145, Loss: 0.2651
Epoch 9/10, Batch 30/145, Loss: 0.1493
Epoch 9/10, Batch 40/145, Loss: 0.1580
Epoch 9/10, Batch 50/145, Loss: 0.1801
Epoch 9/10, Batch 60/145, Loss: 0.2622
Epoch 9/10, Batch 70/145, Loss: 0.3288
Epoch 9/10, Batch 80/145, Loss: 0.1476
Epoch 9/10, Batch 90/145, Loss: 0.2226
Epoch 9/10, Batch 100/145, Loss: 0.2050
Epoch 9/10, Batch 110/145, Loss: 0.2767
Epoch 9/10, Batch 120/145, Loss: 0.0714
Epoch 9/10, Batch 130/145, Loss: 0.1124
Epoch 9/10, Batch 140/145, Loss: 0.1628
Epoch 9/10, Train Loss: 0.2060, Valid Loss: 0.2202
Epoch 10/10, Batch 10/145, Loss: 0.1231
Epoch 10/10, Batch 20/145, Loss: 0.1446
Epoch 10/10, Batch 30/145, Loss: 0.1255
Epoch 10/10, Batch 40/145, Loss: 0.1890
Epoch 10/10, Batch 50/145, Loss: 0.2414
Epoch 10/10, Batch 60/145, Loss: 0.0971
Epoch 10/10, Batch 70/145, Loss: 0.2987
Epoch 10/10, Batch 80/145, Loss: 0.1059
Epoch 10/10, Batch 90/145, Loss: 0.1539
Epoch 10/10, Batch 100/145, Loss: 0.1706
Epoch 10/10, Batch 110/145, Loss: 0.1005
Epoch 10/10, Batch 120/145, Loss: 0.2669
Epoch 10/10, Batch 130/145, Loss: 0.1613
Epoch 10/10, Batch 140/145, Loss: 0.2840
Epoch 10/10, Train Loss: 0.1963, Valid Loss: 0.2178
Model saved!
Accuracy: 0.9206
Precision: 0.9174
Recall: 0.9206
F1-score: 0.9174
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4364
Epoch 1/10, Batch 20/145, Loss: 0.9903
Epoch 1/10, Batch 30/145, Loss: 0.9294
Epoch 1/10, Batch 40/145, Loss: 0.8411
Epoch 1/10, Batch 50/145, Loss: 0.6826
Epoch 1/10, Batch 60/145, Loss: 0.7230
Epoch 1/10, Batch 70/145, Loss: 0.4776
Epoch 1/10, Batch 80/145, Loss: 0.5702
Epoch 1/10, Batch 90/145, Loss: 0.4166
Epoch 1/10, Batch 100/145, Loss: 0.4759
Epoch 1/10, Batch 110/145, Loss: 0.4668
Epoch 1/10, Batch 120/145, Loss: 0.6265
Epoch 1/10, Batch 130/145, Loss: 0.3929
Epoch 1/10, Batch 140/145, Loss: 0.3760
Epoch 1/10, Train Loss: 0.6880, Valid Loss: 0.3761
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3496
Epoch 2/10, Batch 20/145, Loss: 0.3329
Epoch 2/10, Batch 30/145, Loss: 0.2281
Epoch 2/10, Batch 40/145, Loss: 0.4728
Epoch 2/10, Batch 50/145, Loss: 0.5193
Epoch 2/10, Batch 60/145, Loss: 0.4129
Epoch 2/10, Batch 70/145, Loss: 0.4748
Epoch 2/10, Batch 80/145, Loss: 0.2763
Epoch 2/10, Batch 90/145, Loss: 0.3105
Epoch 2/10, Batch 100/145, Loss: 0.2979
Epoch 2/10, Batch 110/145, Loss: 0.4152
Epoch 2/10, Batch 120/145, Loss: 0.3457
Epoch 2/10, Batch 130/145, Loss: 0.3286
Epoch 2/10, Batch 140/145, Loss: 0.3048
Epoch 2/10, Train Loss: 0.3638, Valid Loss: 0.2964
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2119
Epoch 3/10, Batch 20/145, Loss: 0.2361
Epoch 3/10, Batch 30/145, Loss: 0.3065
Epoch 3/10, Batch 40/145, Loss: 0.1966
Epoch 3/10, Batch 50/145, Loss: 0.2247
Epoch 3/10, Batch 60/145, Loss: 0.4965
Epoch 3/10, Batch 70/145, Loss: 0.4058
Epoch 3/10, Batch 80/145, Loss: 0.2193
Epoch 3/10, Batch 90/145, Loss: 0.2777
Epoch 3/10, Batch 100/145, Loss: 0.2474
Epoch 3/10, Batch 110/145, Loss: 0.2084
Epoch 3/10, Batch 120/145, Loss: 0.3070
Epoch 3/10, Batch 130/145, Loss: 0.4358
Epoch 3/10, Batch 140/145, Loss: 0.3334
Epoch 3/10, Train Loss: 0.3004, Valid Loss: 0.2621
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2250
Epoch 4/10, Batch 20/145, Loss: 0.3885
Epoch 4/10, Batch 30/145, Loss: 0.4483
Epoch 4/10, Batch 40/145, Loss: 0.2072
Epoch 4/10, Batch 50/145, Loss: 0.1235
Epoch 4/10, Batch 60/145, Loss: 0.2488
Epoch 4/10, Batch 70/145, Loss: 0.2929
Epoch 4/10, Batch 80/145, Loss: 0.1832
Epoch 4/10, Batch 90/145, Loss: 0.2829
Epoch 4/10, Batch 100/145, Loss: 0.2350
Epoch 4/10, Batch 110/145, Loss: 0.1268
Epoch 4/10, Batch 120/145, Loss: 0.2187
Epoch 4/10, Batch 130/145, Loss: 0.1445
Epoch 4/10, Batch 140/145, Loss: 0.2002
Epoch 4/10, Train Loss: 0.2587, Valid Loss: 0.2515
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2229
Epoch 5/10, Batch 20/145, Loss: 0.1454
Epoch 5/10, Batch 30/145, Loss: 0.2853
Epoch 5/10, Batch 40/145, Loss: 0.2089
Epoch 5/10, Batch 50/145, Loss: 0.1854
Epoch 5/10, Batch 60/145, Loss: 0.1528
Epoch 5/10, Batch 70/145, Loss: 0.2289
Epoch 5/10, Batch 80/145, Loss: 0.2430
Epoch 5/10, Batch 90/145, Loss: 0.2632
Epoch 5/10, Batch 100/145, Loss: 0.3961
Epoch 5/10, Batch 110/145, Loss: 0.1419
Epoch 5/10, Batch 120/145, Loss: 0.3084
Epoch 5/10, Batch 130/145, Loss: 0.0965
Epoch 5/10, Batch 140/145, Loss: 0.1384
Epoch 5/10, Train Loss: 0.2467, Valid Loss: 0.2436
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1893
Epoch 6/10, Batch 20/145, Loss: 0.2825
Epoch 6/10, Batch 30/145, Loss: 0.2086
Epoch 6/10, Batch 40/145, Loss: 0.1301
Epoch 6/10, Batch 50/145, Loss: 0.4337
Epoch 6/10, Batch 60/145, Loss: 0.1380
Epoch 6/10, Batch 70/145, Loss: 0.1068
Epoch 6/10, Batch 80/145, Loss: 0.2271
Epoch 6/10, Batch 90/145, Loss: 0.2488
Epoch 6/10, Batch 100/145, Loss: 0.2601
Epoch 6/10, Batch 110/145, Loss: 0.1512
Epoch 6/10, Batch 120/145, Loss: 0.3374
Epoch 6/10, Batch 130/145, Loss: 0.1902
Epoch 6/10, Batch 140/145, Loss: 0.2311
Epoch 6/10, Train Loss: 0.2358, Valid Loss: 0.2343
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1340
Epoch 7/10, Batch 20/145, Loss: 0.2636
Epoch 7/10, Batch 30/145, Loss: 0.2064
Epoch 7/10, Batch 40/145, Loss: 0.4224
Epoch 7/10, Batch 50/145, Loss: 0.1940
Epoch 7/10, Batch 60/145, Loss: 0.1685
Epoch 7/10, Batch 70/145, Loss: 0.2609
Epoch 7/10, Batch 80/145, Loss: 0.6971
Epoch 7/10, Batch 90/145, Loss: 0.3236
Epoch 7/10, Batch 100/145, Loss: 0.2193
Epoch 7/10, Batch 110/145, Loss: 0.1491
Epoch 7/10, Batch 120/145, Loss: 0.3984
Epoch 7/10, Batch 130/145, Loss: 0.1124
Epoch 7/10, Batch 140/145, Loss: 0.3650
Epoch 7/10, Train Loss: 0.2185, Valid Loss: 0.2302
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.3325
Epoch 8/10, Batch 20/145, Loss: 0.2338
Epoch 8/10, Batch 30/145, Loss: 0.3194
Epoch 8/10, Batch 40/145, Loss: 0.1443
Epoch 8/10, Batch 50/145, Loss: 0.1851
Epoch 8/10, Batch 60/145, Loss: 0.1775
Epoch 8/10, Batch 70/145, Loss: 0.4134
Epoch 8/10, Batch 80/145, Loss: 0.1030
Epoch 8/10, Batch 90/145, Loss: 0.3490
Epoch 8/10, Batch 100/145, Loss: 0.2421
Epoch 8/10, Batch 110/145, Loss: 0.4629
Epoch 8/10, Batch 120/145, Loss: 0.1666
Epoch 8/10, Batch 130/145, Loss: 0.1686
Epoch 8/10, Batch 140/145, Loss: 0.1364
Epoch 8/10, Train Loss: 0.2051, Valid Loss: 0.2272
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3150
Epoch 9/10, Batch 20/145, Loss: 0.1826
Epoch 9/10, Batch 30/145, Loss: 0.1366
Epoch 9/10, Batch 40/145, Loss: 0.1583
Epoch 9/10, Batch 50/145, Loss: 0.2123
Epoch 9/10, Batch 60/145, Loss: 0.1369
Epoch 9/10, Batch 70/145, Loss: 0.1866
Epoch 9/10, Batch 80/145, Loss: 0.2163
Epoch 9/10, Batch 90/145, Loss: 0.2750
Epoch 9/10, Batch 100/145, Loss: 0.1289
Epoch 9/10, Batch 110/145, Loss: 0.1995
Epoch 9/10, Batch 120/145, Loss: 0.0904
Epoch 9/10, Batch 130/145, Loss: 0.2339
Epoch 9/10, Batch 140/145, Loss: 0.2201
Epoch 9/10, Train Loss: 0.2013, Valid Loss: 0.2221
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1763
Epoch 10/10, Batch 20/145, Loss: 0.1191
Epoch 10/10, Batch 30/145, Loss: 0.1067
Epoch 10/10, Batch 40/145, Loss: 0.1219
Epoch 10/10, Batch 50/145, Loss: 0.2699
Epoch 10/10, Batch 60/145, Loss: 0.1159
Epoch 10/10, Batch 70/145, Loss: 0.2778
Epoch 10/10, Batch 80/145, Loss: 0.1719
Epoch 10/10, Batch 90/145, Loss: 0.1853
Epoch 10/10, Batch 100/145, Loss: 0.1704
Epoch 10/10, Batch 110/145, Loss: 0.2396
Epoch 10/10, Batch 120/145, Loss: 0.3282
Epoch 10/10, Batch 130/145, Loss: 0.3021
Epoch 10/10, Batch 140/145, Loss: 0.1824
Epoch 10/10, Train Loss: 0.1845, Valid Loss: 0.2220
Model saved!
Accuracy: 0.9100
Precision: 0.9070
Recall: 0.9100
F1-score: 0.9075
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3560
Epoch 1/10, Batch 20/145, Loss: 1.0595
Epoch 1/10, Batch 30/145, Loss: 0.8837
Epoch 1/10, Batch 40/145, Loss: 0.8018
Epoch 1/10, Batch 50/145, Loss: 0.7119
Epoch 1/10, Batch 60/145, Loss: 0.6723
Epoch 1/10, Batch 70/145, Loss: 0.4680
Epoch 1/10, Batch 80/145, Loss: 0.5940
Epoch 1/10, Batch 90/145, Loss: 0.3294
Epoch 1/10, Batch 100/145, Loss: 0.6021
Epoch 1/10, Batch 110/145, Loss: 0.3920
Epoch 1/10, Batch 120/145, Loss: 0.7080
Epoch 1/10, Batch 130/145, Loss: 0.5213
Epoch 1/10, Batch 140/145, Loss: 0.5912
Epoch 1/10, Train Loss: 0.6792, Valid Loss: 0.3823
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2659
Epoch 2/10, Batch 20/145, Loss: 0.3835
Epoch 2/10, Batch 30/145, Loss: 0.2969
Epoch 2/10, Batch 40/145, Loss: 0.3222
Epoch 2/10, Batch 50/145, Loss: 0.2262
Epoch 2/10, Batch 60/145, Loss: 0.3922
Epoch 2/10, Batch 70/145, Loss: 0.3732
Epoch 2/10, Batch 80/145, Loss: 0.3950
Epoch 2/10, Batch 90/145, Loss: 0.3777
Epoch 2/10, Batch 100/145, Loss: 0.2284
Epoch 2/10, Batch 110/145, Loss: 0.2731
Epoch 2/10, Batch 120/145, Loss: 0.3765
Epoch 2/10, Batch 130/145, Loss: 0.2500
Epoch 2/10, Batch 140/145, Loss: 0.3407
Epoch 2/10, Train Loss: 0.3556, Valid Loss: 0.3090
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2185
Epoch 3/10, Batch 20/145, Loss: 0.2851
Epoch 3/10, Batch 30/145, Loss: 0.3582
Epoch 3/10, Batch 40/145, Loss: 0.2884
Epoch 3/10, Batch 50/145, Loss: 0.3784
Epoch 3/10, Batch 60/145, Loss: 0.3177
Epoch 3/10, Batch 70/145, Loss: 0.2726
Epoch 3/10, Batch 80/145, Loss: 0.1504
Epoch 3/10, Batch 90/145, Loss: 0.2137
Epoch 3/10, Batch 100/145, Loss: 0.3440
Epoch 3/10, Batch 110/145, Loss: 0.3012
Epoch 3/10, Batch 120/145, Loss: 0.2899
Epoch 3/10, Batch 130/145, Loss: 0.2792
Epoch 3/10, Batch 140/145, Loss: 0.2185
Epoch 3/10, Train Loss: 0.2896, Valid Loss: 0.2705
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1933
Epoch 4/10, Batch 20/145, Loss: 0.1919
Epoch 4/10, Batch 30/145, Loss: 0.3060
Epoch 4/10, Batch 40/145, Loss: 0.1607
Epoch 4/10, Batch 50/145, Loss: 0.3080
Epoch 4/10, Batch 60/145, Loss: 0.2373
Epoch 4/10, Batch 70/145, Loss: 0.2839
Epoch 4/10, Batch 80/145, Loss: 0.2514
Epoch 4/10, Batch 90/145, Loss: 0.3003
Epoch 4/10, Batch 100/145, Loss: 0.2410
Epoch 4/10, Batch 110/145, Loss: 0.2107
Epoch 4/10, Batch 120/145, Loss: 0.1358
Epoch 4/10, Batch 130/145, Loss: 0.1880
Epoch 4/10, Batch 140/145, Loss: 0.1500
Epoch 4/10, Train Loss: 0.2537, Valid Loss: 0.2623
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1851
Epoch 5/10, Batch 20/145, Loss: 0.1140
Epoch 5/10, Batch 30/145, Loss: 0.2386
Epoch 5/10, Batch 40/145, Loss: 0.1737
Epoch 5/10, Batch 50/145, Loss: 0.2595
Epoch 5/10, Batch 60/145, Loss: 0.1447
Epoch 5/10, Batch 70/145, Loss: 0.3301
Epoch 5/10, Batch 80/145, Loss: 0.2303
Epoch 5/10, Batch 90/145, Loss: 0.3006
Epoch 5/10, Batch 100/145, Loss: 0.2274
Epoch 5/10, Batch 110/145, Loss: 0.1605
Epoch 5/10, Batch 120/145, Loss: 0.3814
Epoch 5/10, Batch 130/145, Loss: 0.1505
Epoch 5/10, Batch 140/145, Loss: 0.2270
Epoch 5/10, Train Loss: 0.2410, Valid Loss: 0.2492
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1742
Epoch 6/10, Batch 20/145, Loss: 0.3476
Epoch 6/10, Batch 30/145, Loss: 0.1579
Epoch 6/10, Batch 40/145, Loss: 0.1303
Epoch 6/10, Batch 50/145, Loss: 0.5570
Epoch 6/10, Batch 60/145, Loss: 0.2637
Epoch 6/10, Batch 70/145, Loss: 0.3546
Epoch 6/10, Batch 80/145, Loss: 0.2033
Epoch 6/10, Batch 90/145, Loss: 0.3405
Epoch 6/10, Batch 100/145, Loss: 0.2539
Epoch 6/10, Batch 110/145, Loss: 0.0924
Epoch 6/10, Batch 120/145, Loss: 0.2634
Epoch 6/10, Batch 130/145, Loss: 0.0912
Epoch 6/10, Batch 140/145, Loss: 0.1770
Epoch 6/10, Train Loss: 0.2259, Valid Loss: 0.2384
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2145
Epoch 7/10, Batch 20/145, Loss: 0.3238
Epoch 7/10, Batch 30/145, Loss: 0.2092
Epoch 7/10, Batch 40/145, Loss: 0.3708
Epoch 7/10, Batch 50/145, Loss: 0.1690
Epoch 7/10, Batch 60/145, Loss: 0.3167
Epoch 7/10, Batch 70/145, Loss: 0.1157
Epoch 7/10, Batch 80/145, Loss: 0.3478
Epoch 7/10, Batch 90/145, Loss: 0.1381
Epoch 7/10, Batch 100/145, Loss: 0.1546
Epoch 7/10, Batch 110/145, Loss: 0.0919
Epoch 7/10, Batch 120/145, Loss: 0.4093
Epoch 7/10, Batch 130/145, Loss: 0.1655
Epoch 7/10, Batch 140/145, Loss: 0.1646
Epoch 7/10, Train Loss: 0.2159, Valid Loss: 0.2379
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1932
Epoch 8/10, Batch 20/145, Loss: 0.1077
Epoch 8/10, Batch 30/145, Loss: 0.1783
Epoch 8/10, Batch 40/145, Loss: 0.1763
Epoch 8/10, Batch 50/145, Loss: 0.1921
Epoch 8/10, Batch 60/145, Loss: 0.1496
Epoch 8/10, Batch 70/145, Loss: 0.2391
Epoch 8/10, Batch 80/145, Loss: 0.3015
Epoch 8/10, Batch 90/145, Loss: 0.3038
Epoch 8/10, Batch 100/145, Loss: 0.2048
Epoch 8/10, Batch 110/145, Loss: 0.1849
Epoch 8/10, Batch 120/145, Loss: 0.2347
Epoch 8/10, Batch 130/145, Loss: 0.0796
Epoch 8/10, Batch 140/145, Loss: 0.3225
Epoch 8/10, Train Loss: 0.1985, Valid Loss: 0.2434
Epoch 9/10, Batch 10/145, Loss: 0.4696
Epoch 9/10, Batch 20/145, Loss: 0.1790
Epoch 9/10, Batch 30/145, Loss: 0.2296
Epoch 9/10, Batch 40/145, Loss: 0.1582
Epoch 9/10, Batch 50/145, Loss: 0.1487
Epoch 9/10, Batch 60/145, Loss: 0.1880
Epoch 9/10, Batch 70/145, Loss: 0.2069
Epoch 9/10, Batch 80/145, Loss: 0.0597
Epoch 9/10, Batch 90/145, Loss: 0.3674
Epoch 9/10, Batch 100/145, Loss: 0.1997
Epoch 9/10, Batch 110/145, Loss: 0.1553
Epoch 9/10, Batch 120/145, Loss: 0.0709
Epoch 9/10, Batch 130/145, Loss: 0.2513
Epoch 9/10, Batch 140/145, Loss: 0.3092
Epoch 9/10, Train Loss: 0.1924, Valid Loss: 0.2327
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0628
Epoch 10/10, Batch 20/145, Loss: 0.0604
Epoch 10/10, Batch 30/145, Loss: 0.1981
Epoch 10/10, Batch 40/145, Loss: 0.2044
Epoch 10/10, Batch 50/145, Loss: 0.1554
Epoch 10/10, Batch 60/145, Loss: 0.0961
Epoch 10/10, Batch 70/145, Loss: 0.2115
Epoch 10/10, Batch 80/145, Loss: 0.1197
Epoch 10/10, Batch 90/145, Loss: 0.1689
Epoch 10/10, Batch 100/145, Loss: 0.2252
Epoch 10/10, Batch 110/145, Loss: 0.1664
Epoch 10/10, Batch 120/145, Loss: 0.1236
Epoch 10/10, Batch 130/145, Loss: 0.1675
Epoch 10/10, Batch 140/145, Loss: 0.2371
Epoch 10/10, Train Loss: 0.1864, Valid Loss: 0.2398
Accuracy: 0.9182
Precision: 0.9168
Recall: 0.9182
F1-score: 0.9168
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4060
Epoch 1/10, Batch 20/145, Loss: 0.9700
Epoch 1/10, Batch 30/145, Loss: 0.8982
Epoch 1/10, Batch 40/145, Loss: 0.7846
Epoch 1/10, Batch 50/145, Loss: 0.6781
Epoch 1/10, Batch 60/145, Loss: 0.6718
Epoch 1/10, Batch 70/145, Loss: 0.5144
Epoch 1/10, Batch 80/145, Loss: 0.6291
Epoch 1/10, Batch 90/145, Loss: 0.4304
Epoch 1/10, Batch 100/145, Loss: 0.3755
Epoch 1/10, Batch 110/145, Loss: 0.3796
Epoch 1/10, Batch 120/145, Loss: 0.5920
Epoch 1/10, Batch 130/145, Loss: 0.4203
Epoch 1/10, Batch 140/145, Loss: 0.3239
Epoch 1/10, Train Loss: 0.6822, Valid Loss: 0.3851
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4002
Epoch 2/10, Batch 20/145, Loss: 0.2668
Epoch 2/10, Batch 30/145, Loss: 0.2330
Epoch 2/10, Batch 40/145, Loss: 0.5572
Epoch 2/10, Batch 50/145, Loss: 0.3814
Epoch 2/10, Batch 60/145, Loss: 0.4401
Epoch 2/10, Batch 70/145, Loss: 0.2878
Epoch 2/10, Batch 80/145, Loss: 0.2470
Epoch 2/10, Batch 90/145, Loss: 0.2424
Epoch 2/10, Batch 100/145, Loss: 0.3813
Epoch 2/10, Batch 110/145, Loss: 0.3243
Epoch 2/10, Batch 120/145, Loss: 0.4390
Epoch 2/10, Batch 130/145, Loss: 0.2290
Epoch 2/10, Batch 140/145, Loss: 0.2213
Epoch 2/10, Train Loss: 0.3543, Valid Loss: 0.3041
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.4106
Epoch 3/10, Batch 20/145, Loss: 0.3297
Epoch 3/10, Batch 30/145, Loss: 0.3515
Epoch 3/10, Batch 40/145, Loss: 0.3118
Epoch 3/10, Batch 50/145, Loss: 0.2424
Epoch 3/10, Batch 60/145, Loss: 0.4293
Epoch 3/10, Batch 70/145, Loss: 0.4104
Epoch 3/10, Batch 80/145, Loss: 0.2093
Epoch 3/10, Batch 90/145, Loss: 0.2440
Epoch 3/10, Batch 100/145, Loss: 0.1528
Epoch 3/10, Batch 110/145, Loss: 0.2186
Epoch 3/10, Batch 120/145, Loss: 0.2625
Epoch 3/10, Batch 130/145, Loss: 0.2610
Epoch 3/10, Batch 140/145, Loss: 0.3155
Epoch 3/10, Train Loss: 0.2913, Valid Loss: 0.2656
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3182
Epoch 4/10, Batch 20/145, Loss: 0.2616
Epoch 4/10, Batch 30/145, Loss: 0.3077
Epoch 4/10, Batch 40/145, Loss: 0.2134
Epoch 4/10, Batch 50/145, Loss: 0.1752
Epoch 4/10, Batch 60/145, Loss: 0.3812
Epoch 4/10, Batch 70/145, Loss: 0.2835
Epoch 4/10, Batch 80/145, Loss: 0.2215
Epoch 4/10, Batch 90/145, Loss: 0.2338
Epoch 4/10, Batch 100/145, Loss: 0.3169
Epoch 4/10, Batch 110/145, Loss: 0.0753
Epoch 4/10, Batch 120/145, Loss: 0.3824
Epoch 4/10, Batch 130/145, Loss: 0.2014
Epoch 4/10, Batch 140/145, Loss: 0.2677
Epoch 4/10, Train Loss: 0.2576, Valid Loss: 0.2507
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3057
Epoch 5/10, Batch 20/145, Loss: 0.2189
Epoch 5/10, Batch 30/145, Loss: 0.2060
Epoch 5/10, Batch 40/145, Loss: 0.2075
Epoch 5/10, Batch 50/145, Loss: 0.1439
Epoch 5/10, Batch 60/145, Loss: 0.3067
Epoch 5/10, Batch 70/145, Loss: 0.2115
Epoch 5/10, Batch 80/145, Loss: 0.2577
Epoch 5/10, Batch 90/145, Loss: 0.2510
Epoch 5/10, Batch 100/145, Loss: 0.3211
Epoch 5/10, Batch 110/145, Loss: 0.1735
Epoch 5/10, Batch 120/145, Loss: 0.3208
Epoch 5/10, Batch 130/145, Loss: 0.1279
Epoch 5/10, Batch 140/145, Loss: 0.2577
Epoch 5/10, Train Loss: 0.2487, Valid Loss: 0.2442
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2461
Epoch 6/10, Batch 20/145, Loss: 0.2797
Epoch 6/10, Batch 30/145, Loss: 0.3137
Epoch 6/10, Batch 40/145, Loss: 0.2277
Epoch 6/10, Batch 50/145, Loss: 0.2656
Epoch 6/10, Batch 60/145, Loss: 0.0929
Epoch 6/10, Batch 70/145, Loss: 0.3213
Epoch 6/10, Batch 80/145, Loss: 0.1710
Epoch 6/10, Batch 90/145, Loss: 0.1751
Epoch 6/10, Batch 100/145, Loss: 0.2349
Epoch 6/10, Batch 110/145, Loss: 0.1312
Epoch 6/10, Batch 120/145, Loss: 0.2840
Epoch 6/10, Batch 130/145, Loss: 0.1011
Epoch 6/10, Batch 140/145, Loss: 0.1403
Epoch 6/10, Train Loss: 0.2218, Valid Loss: 0.2328
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2829
Epoch 7/10, Batch 20/145, Loss: 0.1880
Epoch 7/10, Batch 30/145, Loss: 0.2188
Epoch 7/10, Batch 40/145, Loss: 0.2867
Epoch 7/10, Batch 50/145, Loss: 0.1709
Epoch 7/10, Batch 60/145, Loss: 0.1001
Epoch 7/10, Batch 70/145, Loss: 0.1048
Epoch 7/10, Batch 80/145, Loss: 0.4871
Epoch 7/10, Batch 90/145, Loss: 0.2780
Epoch 7/10, Batch 100/145, Loss: 0.1919
Epoch 7/10, Batch 110/145, Loss: 0.1357
Epoch 7/10, Batch 120/145, Loss: 0.2414
Epoch 7/10, Batch 130/145, Loss: 0.1225
Epoch 7/10, Batch 140/145, Loss: 0.1962
Epoch 7/10, Train Loss: 0.2066, Valid Loss: 0.2211
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2431
Epoch 8/10, Batch 20/145, Loss: 0.2353
Epoch 8/10, Batch 30/145, Loss: 0.1210
Epoch 8/10, Batch 40/145, Loss: 0.1162
Epoch 8/10, Batch 50/145, Loss: 0.3391
Epoch 8/10, Batch 60/145, Loss: 0.2866
Epoch 8/10, Batch 70/145, Loss: 0.1429
Epoch 8/10, Batch 80/145, Loss: 0.1151
Epoch 8/10, Batch 90/145, Loss: 0.5910
Epoch 8/10, Batch 100/145, Loss: 0.1280
Epoch 8/10, Batch 110/145, Loss: 0.3002
Epoch 8/10, Batch 120/145, Loss: 0.0914
Epoch 8/10, Batch 130/145, Loss: 0.1877
Epoch 8/10, Batch 140/145, Loss: 0.1472
Epoch 8/10, Train Loss: 0.2058, Valid Loss: 0.2194
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2505
Epoch 9/10, Batch 20/145, Loss: 0.2114
Epoch 9/10, Batch 30/145, Loss: 0.1349
Epoch 9/10, Batch 40/145, Loss: 0.2384
Epoch 9/10, Batch 50/145, Loss: 0.1109
Epoch 9/10, Batch 60/145, Loss: 0.1227
Epoch 9/10, Batch 70/145, Loss: 0.0854
Epoch 9/10, Batch 80/145, Loss: 0.1008
Epoch 9/10, Batch 90/145, Loss: 0.3855
Epoch 9/10, Batch 100/145, Loss: 0.1824
Epoch 9/10, Batch 110/145, Loss: 0.1863
Epoch 9/10, Batch 120/145, Loss: 0.1112
Epoch 9/10, Batch 130/145, Loss: 0.1501
Epoch 9/10, Batch 140/145, Loss: 0.3370
Epoch 9/10, Train Loss: 0.1992, Valid Loss: 0.2222
Epoch 10/10, Batch 10/145, Loss: 0.1041
Epoch 10/10, Batch 20/145, Loss: 0.1239
Epoch 10/10, Batch 30/145, Loss: 0.1690
Epoch 10/10, Batch 40/145, Loss: 0.1545
Epoch 10/10, Batch 50/145, Loss: 0.1598
Epoch 10/10, Batch 60/145, Loss: 0.1510
Epoch 10/10, Batch 70/145, Loss: 0.1632
Epoch 10/10, Batch 80/145, Loss: 0.1762
Epoch 10/10, Batch 90/145, Loss: 0.1879
Epoch 10/10, Batch 100/145, Loss: 0.1437
Epoch 10/10, Batch 110/145, Loss: 0.1540
Epoch 10/10, Batch 120/145, Loss: 0.1153
Epoch 10/10, Batch 130/145, Loss: 0.1729
Epoch 10/10, Batch 140/145, Loss: 0.1315
Epoch 10/10, Train Loss: 0.1903, Valid Loss: 0.2228
Accuracy: 0.9252
Precision: 0.9231
Recall: 0.9252
F1-score: 0.9237
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4291
Epoch 1/10, Batch 20/145, Loss: 0.9221
Epoch 1/10, Batch 30/145, Loss: 0.9537
Epoch 1/10, Batch 40/145, Loss: 0.7287
Epoch 1/10, Batch 50/145, Loss: 0.6760
Epoch 1/10, Batch 60/145, Loss: 0.6586
Epoch 1/10, Batch 70/145, Loss: 0.4421
Epoch 1/10, Batch 80/145, Loss: 0.5568
Epoch 1/10, Batch 90/145, Loss: 0.4726
Epoch 1/10, Batch 100/145, Loss: 0.4582
Epoch 1/10, Batch 110/145, Loss: 0.4733
Epoch 1/10, Batch 120/145, Loss: 0.5769
Epoch 1/10, Batch 130/145, Loss: 0.5638
Epoch 1/10, Batch 140/145, Loss: 0.3593
Epoch 1/10, Train Loss: 0.6822, Valid Loss: 0.3544
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3015
Epoch 2/10, Batch 20/145, Loss: 0.4137
Epoch 2/10, Batch 30/145, Loss: 0.3497
Epoch 2/10, Batch 40/145, Loss: 0.3716
Epoch 2/10, Batch 50/145, Loss: 0.3184
Epoch 2/10, Batch 60/145, Loss: 0.4160
Epoch 2/10, Batch 70/145, Loss: 0.3891
Epoch 2/10, Batch 80/145, Loss: 0.2539
Epoch 2/10, Batch 90/145, Loss: 0.4218
Epoch 2/10, Batch 100/145, Loss: 0.4359
Epoch 2/10, Batch 110/145, Loss: 0.3603
Epoch 2/10, Batch 120/145, Loss: 0.4168
Epoch 2/10, Batch 130/145, Loss: 0.3362
Epoch 2/10, Batch 140/145, Loss: 0.3106
Epoch 2/10, Train Loss: 0.3585, Valid Loss: 0.2759
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3011
Epoch 3/10, Batch 20/145, Loss: 0.2285
Epoch 3/10, Batch 30/145, Loss: 0.3637
Epoch 3/10, Batch 40/145, Loss: 0.3736
Epoch 3/10, Batch 50/145, Loss: 0.3864
Epoch 3/10, Batch 60/145, Loss: 0.2884
Epoch 3/10, Batch 70/145, Loss: 0.4617
Epoch 3/10, Batch 80/145, Loss: 0.3549
Epoch 3/10, Batch 90/145, Loss: 0.2094
Epoch 3/10, Batch 100/145, Loss: 0.2219
Epoch 3/10, Batch 110/145, Loss: 0.2044
Epoch 3/10, Batch 120/145, Loss: 0.2226
Epoch 3/10, Batch 130/145, Loss: 0.2871
Epoch 3/10, Batch 140/145, Loss: 0.2549
Epoch 3/10, Train Loss: 0.2940, Valid Loss: 0.2398
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3198
Epoch 4/10, Batch 20/145, Loss: 0.2369
Epoch 4/10, Batch 30/145, Loss: 0.2595
Epoch 4/10, Batch 40/145, Loss: 0.0942
Epoch 4/10, Batch 50/145, Loss: 0.2083
Epoch 4/10, Batch 60/145, Loss: 0.4359
Epoch 4/10, Batch 70/145, Loss: 0.1722
Epoch 4/10, Batch 80/145, Loss: 0.1772
Epoch 4/10, Batch 90/145, Loss: 0.1309
Epoch 4/10, Batch 100/145, Loss: 0.3294
Epoch 4/10, Batch 110/145, Loss: 0.1731
Epoch 4/10, Batch 120/145, Loss: 0.1921
Epoch 4/10, Batch 130/145, Loss: 0.2286
Epoch 4/10, Batch 140/145, Loss: 0.1652
Epoch 4/10, Train Loss: 0.2676, Valid Loss: 0.2248
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2105
Epoch 5/10, Batch 20/145, Loss: 0.1468
Epoch 5/10, Batch 30/145, Loss: 0.2762
Epoch 5/10, Batch 40/145, Loss: 0.2634
Epoch 5/10, Batch 50/145, Loss: 0.2472
Epoch 5/10, Batch 60/145, Loss: 0.1206
Epoch 5/10, Batch 70/145, Loss: 0.1355
Epoch 5/10, Batch 80/145, Loss: 0.3096
Epoch 5/10, Batch 90/145, Loss: 0.4083
Epoch 5/10, Batch 100/145, Loss: 0.2537
Epoch 5/10, Batch 110/145, Loss: 0.1128
Epoch 5/10, Batch 120/145, Loss: 0.2716
Epoch 5/10, Batch 130/145, Loss: 0.1933
Epoch 5/10, Batch 140/145, Loss: 0.1584
Epoch 5/10, Train Loss: 0.2542, Valid Loss: 0.2101
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2168
Epoch 6/10, Batch 20/145, Loss: 0.2558
Epoch 6/10, Batch 30/145, Loss: 0.4228
Epoch 6/10, Batch 40/145, Loss: 0.3193
Epoch 6/10, Batch 50/145, Loss: 0.3474
Epoch 6/10, Batch 60/145, Loss: 0.1541
Epoch 6/10, Batch 70/145, Loss: 0.2024
Epoch 6/10, Batch 80/145, Loss: 0.2899
Epoch 6/10, Batch 90/145, Loss: 0.3499
Epoch 6/10, Batch 100/145, Loss: 0.2144
Epoch 6/10, Batch 110/145, Loss: 0.3582
Epoch 6/10, Batch 120/145, Loss: 0.3622
Epoch 6/10, Batch 130/145, Loss: 0.1910
Epoch 6/10, Batch 140/145, Loss: 0.1034
Epoch 6/10, Train Loss: 0.2325, Valid Loss: 0.2077
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2122
Epoch 7/10, Batch 20/145, Loss: 0.2800
Epoch 7/10, Batch 30/145, Loss: 0.2270
Epoch 7/10, Batch 40/145, Loss: 0.4646
Epoch 7/10, Batch 50/145, Loss: 0.1178
Epoch 7/10, Batch 60/145, Loss: 0.2250
Epoch 7/10, Batch 70/145, Loss: 0.1666
Epoch 7/10, Batch 80/145, Loss: 0.4256
Epoch 7/10, Batch 90/145, Loss: 0.2443
Epoch 7/10, Batch 100/145, Loss: 0.1477
Epoch 7/10, Batch 110/145, Loss: 0.1707
Epoch 7/10, Batch 120/145, Loss: 0.2030
Epoch 7/10, Batch 130/145, Loss: 0.1797
Epoch 7/10, Batch 140/145, Loss: 0.5713
Epoch 7/10, Train Loss: 0.2234, Valid Loss: 0.1955
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.3111
Epoch 8/10, Batch 20/145, Loss: 0.2258
Epoch 8/10, Batch 30/145, Loss: 0.2520
Epoch 8/10, Batch 40/145, Loss: 0.2007
Epoch 8/10, Batch 50/145, Loss: 0.3095
Epoch 8/10, Batch 60/145, Loss: 0.2314
Epoch 8/10, Batch 70/145, Loss: 0.3251
Epoch 8/10, Batch 80/145, Loss: 0.2664
Epoch 8/10, Batch 90/145, Loss: 0.3456
Epoch 8/10, Batch 100/145, Loss: 0.1170
Epoch 8/10, Batch 110/145, Loss: 0.2587
Epoch 8/10, Batch 120/145, Loss: 0.1640
Epoch 8/10, Batch 130/145, Loss: 0.1241
Epoch 8/10, Batch 140/145, Loss: 0.3137
Epoch 8/10, Train Loss: 0.2118, Valid Loss: 0.2016
Epoch 9/10, Batch 10/145, Loss: 0.3593
Epoch 9/10, Batch 20/145, Loss: 0.1441
Epoch 9/10, Batch 30/145, Loss: 0.1824
Epoch 9/10, Batch 40/145, Loss: 0.2772
Epoch 9/10, Batch 50/145, Loss: 0.1444
Epoch 9/10, Batch 60/145, Loss: 0.2726
Epoch 9/10, Batch 70/145, Loss: 0.1952
Epoch 9/10, Batch 80/145, Loss: 0.1306
Epoch 9/10, Batch 90/145, Loss: 0.1922
Epoch 9/10, Batch 100/145, Loss: 0.1709
Epoch 9/10, Batch 110/145, Loss: 0.2005
Epoch 9/10, Batch 120/145, Loss: 0.1558
Epoch 9/10, Batch 130/145, Loss: 0.3796
Epoch 9/10, Batch 140/145, Loss: 0.1652
Epoch 9/10, Train Loss: 0.2109, Valid Loss: 0.1909
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0619
Epoch 10/10, Batch 20/145, Loss: 0.0901
Epoch 10/10, Batch 30/145, Loss: 0.2175
Epoch 10/10, Batch 40/145, Loss: 0.1055
Epoch 10/10, Batch 50/145, Loss: 0.3608
Epoch 10/10, Batch 60/145, Loss: 0.1690
Epoch 10/10, Batch 70/145, Loss: 0.2225
Epoch 10/10, Batch 80/145, Loss: 0.1193
Epoch 10/10, Batch 90/145, Loss: 0.1571
Epoch 10/10, Batch 100/145, Loss: 0.1055
Epoch 10/10, Batch 110/145, Loss: 0.1605
Epoch 10/10, Batch 120/145, Loss: 0.2382
Epoch 10/10, Batch 130/145, Loss: 0.1620
Epoch 10/10, Batch 140/145, Loss: 0.2495
Epoch 10/10, Train Loss: 0.2073, Valid Loss: 0.1933
Accuracy: 0.9287
Precision: 0.9276
Recall: 0.9287
F1-score: 0.9280
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4310
Epoch 1/10, Batch 20/145, Loss: 0.8815
Epoch 1/10, Batch 30/145, Loss: 0.8384
Epoch 1/10, Batch 40/145, Loss: 0.8079
Epoch 1/10, Batch 50/145, Loss: 0.8792
Epoch 1/10, Batch 60/145, Loss: 0.6076
Epoch 1/10, Batch 70/145, Loss: 0.4497
Epoch 1/10, Batch 80/145, Loss: 0.5664
Epoch 1/10, Batch 90/145, Loss: 0.3616
Epoch 1/10, Batch 100/145, Loss: 0.4500
Epoch 1/10, Batch 110/145, Loss: 0.4324
Epoch 1/10, Batch 120/145, Loss: 0.6267
Epoch 1/10, Batch 130/145, Loss: 0.4529
Epoch 1/10, Batch 140/145, Loss: 0.2969
Epoch 1/10, Train Loss: 0.6735, Valid Loss: 0.3896
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3337
Epoch 2/10, Batch 20/145, Loss: 0.2604
Epoch 2/10, Batch 30/145, Loss: 0.4407
Epoch 2/10, Batch 40/145, Loss: 0.4682
Epoch 2/10, Batch 50/145, Loss: 0.2854
Epoch 2/10, Batch 60/145, Loss: 0.3199
Epoch 2/10, Batch 70/145, Loss: 0.3746
Epoch 2/10, Batch 80/145, Loss: 0.2533
Epoch 2/10, Batch 90/145, Loss: 0.4032
Epoch 2/10, Batch 100/145, Loss: 0.2661
Epoch 2/10, Batch 110/145, Loss: 0.3203
Epoch 2/10, Batch 120/145, Loss: 0.4334
Epoch 2/10, Batch 130/145, Loss: 0.3381
Epoch 2/10, Batch 140/145, Loss: 0.3030
Epoch 2/10, Train Loss: 0.3466, Valid Loss: 0.3080
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1938
Epoch 3/10, Batch 20/145, Loss: 0.1683
Epoch 3/10, Batch 30/145, Loss: 0.2917
Epoch 3/10, Batch 40/145, Loss: 0.1764
Epoch 3/10, Batch 50/145, Loss: 0.1751
Epoch 3/10, Batch 60/145, Loss: 0.2738
Epoch 3/10, Batch 70/145, Loss: 0.3048
Epoch 3/10, Batch 80/145, Loss: 0.2998
Epoch 3/10, Batch 90/145, Loss: 0.2477
Epoch 3/10, Batch 100/145, Loss: 0.2964
Epoch 3/10, Batch 110/145, Loss: 0.3311
Epoch 3/10, Batch 120/145, Loss: 0.3615
Epoch 3/10, Batch 130/145, Loss: 0.3488
Epoch 3/10, Batch 140/145, Loss: 0.2414
Epoch 3/10, Train Loss: 0.2851, Valid Loss: 0.2806
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4158
Epoch 4/10, Batch 20/145, Loss: 0.2592
Epoch 4/10, Batch 30/145, Loss: 0.2202
Epoch 4/10, Batch 40/145, Loss: 0.1402
Epoch 4/10, Batch 50/145, Loss: 0.1741
Epoch 4/10, Batch 60/145, Loss: 0.2332
Epoch 4/10, Batch 70/145, Loss: 0.1523
Epoch 4/10, Batch 80/145, Loss: 0.2669
Epoch 4/10, Batch 90/145, Loss: 0.1913
Epoch 4/10, Batch 100/145, Loss: 0.3592
Epoch 4/10, Batch 110/145, Loss: 0.2311
Epoch 4/10, Batch 120/145, Loss: 0.1416
Epoch 4/10, Batch 130/145, Loss: 0.1990
Epoch 4/10, Batch 140/145, Loss: 0.1563
Epoch 4/10, Train Loss: 0.2549, Valid Loss: 0.2720
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2130
Epoch 5/10, Batch 20/145, Loss: 0.2070
Epoch 5/10, Batch 30/145, Loss: 0.3439
Epoch 5/10, Batch 40/145, Loss: 0.1919
Epoch 5/10, Batch 50/145, Loss: 0.2233
Epoch 5/10, Batch 60/145, Loss: 0.3553
Epoch 5/10, Batch 70/145, Loss: 0.2225
Epoch 5/10, Batch 80/145, Loss: 0.1947
Epoch 5/10, Batch 90/145, Loss: 0.4309
Epoch 5/10, Batch 100/145, Loss: 0.1754
Epoch 5/10, Batch 110/145, Loss: 0.3190
Epoch 5/10, Batch 120/145, Loss: 0.2636
Epoch 5/10, Batch 130/145, Loss: 0.1576
Epoch 5/10, Batch 140/145, Loss: 0.1622
Epoch 5/10, Train Loss: 0.2460, Valid Loss: 0.2573
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1620
Epoch 6/10, Batch 20/145, Loss: 0.3855
Epoch 6/10, Batch 30/145, Loss: 0.3962
Epoch 6/10, Batch 40/145, Loss: 0.1831
Epoch 6/10, Batch 50/145, Loss: 0.2704
Epoch 6/10, Batch 60/145, Loss: 0.1603
Epoch 6/10, Batch 70/145, Loss: 0.0728
Epoch 6/10, Batch 80/145, Loss: 0.1466
Epoch 6/10, Batch 90/145, Loss: 0.2564
Epoch 6/10, Batch 100/145, Loss: 0.4101
Epoch 6/10, Batch 110/145, Loss: 0.2847
Epoch 6/10, Batch 120/145, Loss: 0.3012
Epoch 6/10, Batch 130/145, Loss: 0.1478
Epoch 6/10, Batch 140/145, Loss: 0.2370
Epoch 6/10, Train Loss: 0.2260, Valid Loss: 0.2552
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2279
Epoch 7/10, Batch 20/145, Loss: 0.2630
Epoch 7/10, Batch 30/145, Loss: 0.1080
Epoch 7/10, Batch 40/145, Loss: 0.2199
Epoch 7/10, Batch 50/145, Loss: 0.1159
Epoch 7/10, Batch 60/145, Loss: 0.2819
Epoch 7/10, Batch 70/145, Loss: 0.1380
Epoch 7/10, Batch 80/145, Loss: 0.4540
Epoch 7/10, Batch 90/145, Loss: 0.2018
Epoch 7/10, Batch 100/145, Loss: 0.0706
Epoch 7/10, Batch 110/145, Loss: 0.1805
Epoch 7/10, Batch 120/145, Loss: 0.1713
Epoch 7/10, Batch 130/145, Loss: 0.1292
Epoch 7/10, Batch 140/145, Loss: 0.3926
Epoch 7/10, Train Loss: 0.2155, Valid Loss: 0.2493
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2664
Epoch 8/10, Batch 20/145, Loss: 0.2623
Epoch 8/10, Batch 30/145, Loss: 0.2995
Epoch 8/10, Batch 40/145, Loss: 0.2599
Epoch 8/10, Batch 50/145, Loss: 0.2686
Epoch 8/10, Batch 60/145, Loss: 0.2141
Epoch 8/10, Batch 70/145, Loss: 0.2904
Epoch 8/10, Batch 80/145, Loss: 0.1455
Epoch 8/10, Batch 90/145, Loss: 0.2236
Epoch 8/10, Batch 100/145, Loss: 0.2848
Epoch 8/10, Batch 110/145, Loss: 0.2019
Epoch 8/10, Batch 120/145, Loss: 0.1132
Epoch 8/10, Batch 130/145, Loss: 0.2395
Epoch 8/10, Batch 140/145, Loss: 0.3146
Epoch 8/10, Train Loss: 0.2059, Valid Loss: 0.2453
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2374
Epoch 9/10, Batch 20/145, Loss: 0.2182
Epoch 9/10, Batch 30/145, Loss: 0.1639
Epoch 9/10, Batch 40/145, Loss: 0.3781
Epoch 9/10, Batch 50/145, Loss: 0.1987
Epoch 9/10, Batch 60/145, Loss: 0.3316
Epoch 9/10, Batch 70/145, Loss: 0.1247
Epoch 9/10, Batch 80/145, Loss: 0.1294
Epoch 9/10, Batch 90/145, Loss: 0.1625
Epoch 9/10, Batch 100/145, Loss: 0.1684
Epoch 9/10, Batch 110/145, Loss: 0.2442
Epoch 9/10, Batch 120/145, Loss: 0.0948
Epoch 9/10, Batch 130/145, Loss: 0.3550
Epoch 9/10, Batch 140/145, Loss: 0.2429
Epoch 9/10, Train Loss: 0.2005, Valid Loss: 0.2401
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1029
Epoch 10/10, Batch 20/145, Loss: 0.1680
Epoch 10/10, Batch 30/145, Loss: 0.1353
Epoch 10/10, Batch 40/145, Loss: 0.0984
Epoch 10/10, Batch 50/145, Loss: 0.2579
Epoch 10/10, Batch 60/145, Loss: 0.0929
Epoch 10/10, Batch 70/145, Loss: 0.2934
Epoch 10/10, Batch 80/145, Loss: 0.1531
Epoch 10/10, Batch 90/145, Loss: 0.0774
Epoch 10/10, Batch 100/145, Loss: 0.2130
Epoch 10/10, Batch 110/145, Loss: 0.1742
Epoch 10/10, Batch 120/145, Loss: 0.2517
Epoch 10/10, Batch 130/145, Loss: 0.1857
Epoch 10/10, Batch 140/145, Loss: 0.0962
Epoch 10/10, Train Loss: 0.1931, Valid Loss: 0.2413
Accuracy: 0.9264
Precision: 0.9244
Recall: 0.9264
F1-score: 0.9250
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4057
Epoch 1/10, Batch 20/145, Loss: 0.9841
Epoch 1/10, Batch 30/145, Loss: 0.8623
Epoch 1/10, Batch 40/145, Loss: 0.7257
Epoch 1/10, Batch 50/145, Loss: 0.6416
Epoch 1/10, Batch 60/145, Loss: 0.7116
Epoch 1/10, Batch 70/145, Loss: 0.5558
Epoch 1/10, Batch 80/145, Loss: 0.7675
Epoch 1/10, Batch 90/145, Loss: 0.3672
Epoch 1/10, Batch 100/145, Loss: 0.4303
Epoch 1/10, Batch 110/145, Loss: 0.3437
Epoch 1/10, Batch 120/145, Loss: 0.4440
Epoch 1/10, Batch 130/145, Loss: 0.6146
Epoch 1/10, Batch 140/145, Loss: 0.3453
Epoch 1/10, Train Loss: 0.6814, Valid Loss: 0.3791
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3150
Epoch 2/10, Batch 20/145, Loss: 0.3828
Epoch 2/10, Batch 30/145, Loss: 0.3133
Epoch 2/10, Batch 40/145, Loss: 0.5033
Epoch 2/10, Batch 50/145, Loss: 0.2168
Epoch 2/10, Batch 60/145, Loss: 0.3755
Epoch 2/10, Batch 70/145, Loss: 0.3410
Epoch 2/10, Batch 80/145, Loss: 0.3441
Epoch 2/10, Batch 90/145, Loss: 0.4108
Epoch 2/10, Batch 100/145, Loss: 0.3020
Epoch 2/10, Batch 110/145, Loss: 0.3038
Epoch 2/10, Batch 120/145, Loss: 0.3676
Epoch 2/10, Batch 130/145, Loss: 0.2203
Epoch 2/10, Batch 140/145, Loss: 0.2464
Epoch 2/10, Train Loss: 0.3546, Valid Loss: 0.2945
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3176
Epoch 3/10, Batch 20/145, Loss: 0.2698
Epoch 3/10, Batch 30/145, Loss: 0.2766
Epoch 3/10, Batch 40/145, Loss: 0.2088
Epoch 3/10, Batch 50/145, Loss: 0.2707
Epoch 3/10, Batch 60/145, Loss: 0.3483
Epoch 3/10, Batch 70/145, Loss: 0.5928
Epoch 3/10, Batch 80/145, Loss: 0.1814
Epoch 3/10, Batch 90/145, Loss: 0.2740
Epoch 3/10, Batch 100/145, Loss: 0.2804
Epoch 3/10, Batch 110/145, Loss: 0.2387
Epoch 3/10, Batch 120/145, Loss: 0.2085
Epoch 3/10, Batch 130/145, Loss: 0.3897
Epoch 3/10, Batch 140/145, Loss: 0.2267
Epoch 3/10, Train Loss: 0.2952, Valid Loss: 0.2582
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2809
Epoch 4/10, Batch 20/145, Loss: 0.2437
Epoch 4/10, Batch 30/145, Loss: 0.2293
Epoch 4/10, Batch 40/145, Loss: 0.4026
Epoch 4/10, Batch 50/145, Loss: 0.2746
Epoch 4/10, Batch 60/145, Loss: 0.1561
Epoch 4/10, Batch 70/145, Loss: 0.2166
Epoch 4/10, Batch 80/145, Loss: 0.2018
Epoch 4/10, Batch 90/145, Loss: 0.3262
Epoch 4/10, Batch 100/145, Loss: 0.2790
Epoch 4/10, Batch 110/145, Loss: 0.1772
Epoch 4/10, Batch 120/145, Loss: 0.2305
Epoch 4/10, Batch 130/145, Loss: 0.2423
Epoch 4/10, Batch 140/145, Loss: 0.2304
Epoch 4/10, Train Loss: 0.2564, Valid Loss: 0.2490
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2801
Epoch 5/10, Batch 20/145, Loss: 0.1823
Epoch 5/10, Batch 30/145, Loss: 0.3389
Epoch 5/10, Batch 40/145, Loss: 0.2115
Epoch 5/10, Batch 50/145, Loss: 0.1255
Epoch 5/10, Batch 60/145, Loss: 0.1540
Epoch 5/10, Batch 70/145, Loss: 0.2679
Epoch 5/10, Batch 80/145, Loss: 0.3199
Epoch 5/10, Batch 90/145, Loss: 0.4703
Epoch 5/10, Batch 100/145, Loss: 0.2377
Epoch 5/10, Batch 110/145, Loss: 0.2041
Epoch 5/10, Batch 120/145, Loss: 0.2951
Epoch 5/10, Batch 130/145, Loss: 0.1928
Epoch 5/10, Batch 140/145, Loss: 0.2187
Epoch 5/10, Train Loss: 0.2473, Valid Loss: 0.2412
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1948
Epoch 6/10, Batch 20/145, Loss: 0.3751
Epoch 6/10, Batch 30/145, Loss: 0.2779
Epoch 6/10, Batch 40/145, Loss: 0.2162
Epoch 6/10, Batch 50/145, Loss: 0.2638
Epoch 6/10, Batch 60/145, Loss: 0.2049
Epoch 6/10, Batch 70/145, Loss: 0.1716
Epoch 6/10, Batch 80/145, Loss: 0.1423
Epoch 6/10, Batch 90/145, Loss: 0.3174
Epoch 6/10, Batch 100/145, Loss: 0.2473
Epoch 6/10, Batch 110/145, Loss: 0.2025
Epoch 6/10, Batch 120/145, Loss: 0.1671
Epoch 6/10, Batch 130/145, Loss: 0.1435
Epoch 6/10, Batch 140/145, Loss: 0.1221
Epoch 6/10, Train Loss: 0.2327, Valid Loss: 0.2272
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2138
Epoch 7/10, Batch 20/145, Loss: 0.3925
Epoch 7/10, Batch 30/145, Loss: 0.1292
Epoch 7/10, Batch 40/145, Loss: 0.1564
Epoch 7/10, Batch 50/145, Loss: 0.2733
Epoch 7/10, Batch 60/145, Loss: 0.1475
Epoch 7/10, Batch 70/145, Loss: 0.2032
Epoch 7/10, Batch 80/145, Loss: 0.5943
Epoch 7/10, Batch 90/145, Loss: 0.2067
Epoch 7/10, Batch 100/145, Loss: 0.2124
Epoch 7/10, Batch 110/145, Loss: 0.1107
Epoch 7/10, Batch 120/145, Loss: 0.1756
Epoch 7/10, Batch 130/145, Loss: 0.1658
Epoch 7/10, Batch 140/145, Loss: 0.3217
Epoch 7/10, Train Loss: 0.2209, Valid Loss: 0.2282
Epoch 8/10, Batch 10/145, Loss: 0.1436
Epoch 8/10, Batch 20/145, Loss: 0.2108
Epoch 8/10, Batch 30/145, Loss: 0.2674
Epoch 8/10, Batch 40/145, Loss: 0.1315
Epoch 8/10, Batch 50/145, Loss: 0.2094
Epoch 8/10, Batch 60/145, Loss: 0.2085
Epoch 8/10, Batch 70/145, Loss: 0.2391
Epoch 8/10, Batch 80/145, Loss: 0.1746
Epoch 8/10, Batch 90/145, Loss: 0.2213
Epoch 8/10, Batch 100/145, Loss: 0.3585
Epoch 8/10, Batch 110/145, Loss: 0.1620
Epoch 8/10, Batch 120/145, Loss: 0.2963
Epoch 8/10, Batch 130/145, Loss: 0.1123
Epoch 8/10, Batch 140/145, Loss: 0.2588
Epoch 8/10, Train Loss: 0.2105, Valid Loss: 0.2177
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3267
Epoch 9/10, Batch 20/145, Loss: 0.1590
Epoch 9/10, Batch 30/145, Loss: 0.1778
Epoch 9/10, Batch 40/145, Loss: 0.2047
Epoch 9/10, Batch 50/145, Loss: 0.1341
Epoch 9/10, Batch 60/145, Loss: 0.1970
Epoch 9/10, Batch 70/145, Loss: 0.1026
Epoch 9/10, Batch 80/145, Loss: 0.1563
Epoch 9/10, Batch 90/145, Loss: 0.1425
Epoch 9/10, Batch 100/145, Loss: 0.2780
Epoch 9/10, Batch 110/145, Loss: 0.2516
Epoch 9/10, Batch 120/145, Loss: 0.0953
Epoch 9/10, Batch 130/145, Loss: 0.1670
Epoch 9/10, Batch 140/145, Loss: 0.2920
Epoch 9/10, Train Loss: 0.2118, Valid Loss: 0.2179
Epoch 10/10, Batch 10/145, Loss: 0.0895
Epoch 10/10, Batch 20/145, Loss: 0.2949
Epoch 10/10, Batch 30/145, Loss: 0.1226
Epoch 10/10, Batch 40/145, Loss: 0.1985
Epoch 10/10, Batch 50/145, Loss: 0.1939
Epoch 10/10, Batch 60/145, Loss: 0.0880
Epoch 10/10, Batch 70/145, Loss: 0.2128
Epoch 10/10, Batch 80/145, Loss: 0.2132
Epoch 10/10, Batch 90/145, Loss: 0.1357
Epoch 10/10, Batch 100/145, Loss: 0.1589
Epoch 10/10, Batch 110/145, Loss: 0.1478
Epoch 10/10, Batch 120/145, Loss: 0.1438
Epoch 10/10, Batch 130/145, Loss: 0.1798
Epoch 10/10, Batch 140/145, Loss: 0.1304
Epoch 10/10, Train Loss: 0.2018, Valid Loss: 0.2107
Model saved!
Accuracy: 0.9171
Precision: 0.9143
Recall: 0.9171
F1-score: 0.9153
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3610
Epoch 1/10, Batch 20/145, Loss: 0.8684
Epoch 1/10, Batch 30/145, Loss: 0.9143
Epoch 1/10, Batch 40/145, Loss: 0.7326
Epoch 1/10, Batch 50/145, Loss: 0.7152
Epoch 1/10, Batch 60/145, Loss: 0.6785
Epoch 1/10, Batch 70/145, Loss: 0.4736
Epoch 1/10, Batch 80/145, Loss: 0.4566
Epoch 1/10, Batch 90/145, Loss: 0.3530
Epoch 1/10, Batch 100/145, Loss: 0.5154
Epoch 1/10, Batch 110/145, Loss: 0.3953
Epoch 1/10, Batch 120/145, Loss: 0.4931
Epoch 1/10, Batch 130/145, Loss: 0.5515
Epoch 1/10, Batch 140/145, Loss: 0.2930
Epoch 1/10, Train Loss: 0.6709, Valid Loss: 0.3837
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3941
Epoch 2/10, Batch 20/145, Loss: 0.4052
Epoch 2/10, Batch 30/145, Loss: 0.2113
Epoch 2/10, Batch 40/145, Loss: 0.5484
Epoch 2/10, Batch 50/145, Loss: 0.3476
Epoch 2/10, Batch 60/145, Loss: 0.2766
Epoch 2/10, Batch 70/145, Loss: 0.3582
Epoch 2/10, Batch 80/145, Loss: 0.3278
Epoch 2/10, Batch 90/145, Loss: 0.4140
Epoch 2/10, Batch 100/145, Loss: 0.3257
Epoch 2/10, Batch 110/145, Loss: 0.3505
Epoch 2/10, Batch 120/145, Loss: 0.3274
Epoch 2/10, Batch 130/145, Loss: 0.2890
Epoch 2/10, Batch 140/145, Loss: 0.1610
Epoch 2/10, Train Loss: 0.3514, Valid Loss: 0.3002
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2525
Epoch 3/10, Batch 20/145, Loss: 0.3362
Epoch 3/10, Batch 30/145, Loss: 0.4244
Epoch 3/10, Batch 40/145, Loss: 0.2338
Epoch 3/10, Batch 50/145, Loss: 0.1605
Epoch 3/10, Batch 60/145, Loss: 0.3701
Epoch 3/10, Batch 70/145, Loss: 0.2775
Epoch 3/10, Batch 80/145, Loss: 0.2853
Epoch 3/10, Batch 90/145, Loss: 0.2714
Epoch 3/10, Batch 100/145, Loss: 0.3100
Epoch 3/10, Batch 110/145, Loss: 0.2031
Epoch 3/10, Batch 120/145, Loss: 0.3498
Epoch 3/10, Batch 130/145, Loss: 0.2040
Epoch 3/10, Batch 140/145, Loss: 0.1884
Epoch 3/10, Train Loss: 0.2854, Valid Loss: 0.2669
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2047
Epoch 4/10, Batch 20/145, Loss: 0.2070
Epoch 4/10, Batch 30/145, Loss: 0.2456
Epoch 4/10, Batch 40/145, Loss: 0.2055
Epoch 4/10, Batch 50/145, Loss: 0.1848
Epoch 4/10, Batch 60/145, Loss: 0.1252
Epoch 4/10, Batch 70/145, Loss: 0.3014
Epoch 4/10, Batch 80/145, Loss: 0.1592
Epoch 4/10, Batch 90/145, Loss: 0.1834
Epoch 4/10, Batch 100/145, Loss: 0.2978
Epoch 4/10, Batch 110/145, Loss: 0.1722
Epoch 4/10, Batch 120/145, Loss: 0.4737
Epoch 4/10, Batch 130/145, Loss: 0.1216
Epoch 4/10, Batch 140/145, Loss: 0.1575
Epoch 4/10, Train Loss: 0.2568, Valid Loss: 0.2551
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1348
Epoch 5/10, Batch 20/145, Loss: 0.1180
Epoch 5/10, Batch 30/145, Loss: 0.2901
Epoch 5/10, Batch 40/145, Loss: 0.1263
Epoch 5/10, Batch 50/145, Loss: 0.2158
Epoch 5/10, Batch 60/145, Loss: 0.2592
Epoch 5/10, Batch 70/145, Loss: 0.3356
Epoch 5/10, Batch 80/145, Loss: 0.1854
Epoch 5/10, Batch 90/145, Loss: 0.4067
Epoch 5/10, Batch 100/145, Loss: 0.1819
Epoch 5/10, Batch 110/145, Loss: 0.2441
Epoch 5/10, Batch 120/145, Loss: 0.2336
Epoch 5/10, Batch 130/145, Loss: 0.1049
Epoch 5/10, Batch 140/145, Loss: 0.3393
Epoch 5/10, Train Loss: 0.2436, Valid Loss: 0.2506
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1385
Epoch 6/10, Batch 20/145, Loss: 0.2820
Epoch 6/10, Batch 30/145, Loss: 0.3298
Epoch 6/10, Batch 40/145, Loss: 0.1581
Epoch 6/10, Batch 50/145, Loss: 0.3643
Epoch 6/10, Batch 60/145, Loss: 0.1312
Epoch 6/10, Batch 70/145, Loss: 0.1615
Epoch 6/10, Batch 80/145, Loss: 0.1678
Epoch 6/10, Batch 90/145, Loss: 0.3140
Epoch 6/10, Batch 100/145, Loss: 0.2423
Epoch 6/10, Batch 110/145, Loss: 0.1708
Epoch 6/10, Batch 120/145, Loss: 0.2890
Epoch 6/10, Batch 130/145, Loss: 0.1012
Epoch 6/10, Batch 140/145, Loss: 0.1963
Epoch 6/10, Train Loss: 0.2245, Valid Loss: 0.2319
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2042
Epoch 7/10, Batch 20/145, Loss: 0.2246
Epoch 7/10, Batch 30/145, Loss: 0.1447
Epoch 7/10, Batch 40/145, Loss: 0.2912
Epoch 7/10, Batch 50/145, Loss: 0.3049
Epoch 7/10, Batch 60/145, Loss: 0.1715
Epoch 7/10, Batch 70/145, Loss: 0.2808
Epoch 7/10, Batch 80/145, Loss: 0.3263
Epoch 7/10, Batch 90/145, Loss: 0.2116
Epoch 7/10, Batch 100/145, Loss: 0.1747
Epoch 7/10, Batch 110/145, Loss: 0.2344
Epoch 7/10, Batch 120/145, Loss: 0.1610
Epoch 7/10, Batch 130/145, Loss: 0.0969
Epoch 7/10, Batch 140/145, Loss: 0.2631
Epoch 7/10, Train Loss: 0.2117, Valid Loss: 0.2315
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0892
Epoch 8/10, Batch 20/145, Loss: 0.2120
Epoch 8/10, Batch 30/145, Loss: 0.2909
Epoch 8/10, Batch 40/145, Loss: 0.1557
Epoch 8/10, Batch 50/145, Loss: 0.2202
Epoch 8/10, Batch 60/145, Loss: 0.3476
Epoch 8/10, Batch 70/145, Loss: 0.2910
Epoch 8/10, Batch 80/145, Loss: 0.0872
Epoch 8/10, Batch 90/145, Loss: 0.2947
Epoch 8/10, Batch 100/145, Loss: 0.1853
Epoch 8/10, Batch 110/145, Loss: 0.1884
Epoch 8/10, Batch 120/145, Loss: 0.1194
Epoch 8/10, Batch 130/145, Loss: 0.1051
Epoch 8/10, Batch 140/145, Loss: 0.3751
Epoch 8/10, Train Loss: 0.2049, Valid Loss: 0.2247
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2286
Epoch 9/10, Batch 20/145, Loss: 0.1058
Epoch 9/10, Batch 30/145, Loss: 0.3120
Epoch 9/10, Batch 40/145, Loss: 0.1931
Epoch 9/10, Batch 50/145, Loss: 0.1232
Epoch 9/10, Batch 60/145, Loss: 0.1444
Epoch 9/10, Batch 70/145, Loss: 0.1852
Epoch 9/10, Batch 80/145, Loss: 0.1759
Epoch 9/10, Batch 90/145, Loss: 0.2561
Epoch 9/10, Batch 100/145, Loss: 0.1052
Epoch 9/10, Batch 110/145, Loss: 0.1581
Epoch 9/10, Batch 120/145, Loss: 0.1921
Epoch 9/10, Batch 130/145, Loss: 0.1730
Epoch 9/10, Batch 140/145, Loss: 0.5283
Epoch 9/10, Train Loss: 0.1906, Valid Loss: 0.2213
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1213
Epoch 10/10, Batch 20/145, Loss: 0.1436
Epoch 10/10, Batch 30/145, Loss: 0.2122
Epoch 10/10, Batch 40/145, Loss: 0.1444
Epoch 10/10, Batch 50/145, Loss: 0.2078
Epoch 10/10, Batch 60/145, Loss: 0.2566
Epoch 10/10, Batch 70/145, Loss: 0.2000
Epoch 10/10, Batch 80/145, Loss: 0.2527
Epoch 10/10, Batch 90/145, Loss: 0.0774
Epoch 10/10, Batch 100/145, Loss: 0.2488
Epoch 10/10, Batch 110/145, Loss: 0.1054
Epoch 10/10, Batch 120/145, Loss: 0.3312
Epoch 10/10, Batch 130/145, Loss: 0.1236
Epoch 10/10, Batch 140/145, Loss: 0.3074
Epoch 10/10, Train Loss: 0.1918, Valid Loss: 0.2212
Model saved!
Accuracy: 0.9136
Precision: 0.9101
Recall: 0.9136
F1-score: 0.9106
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3845
Epoch 1/10, Batch 20/145, Loss: 0.9724
Epoch 1/10, Batch 30/145, Loss: 0.8895
Epoch 1/10, Batch 40/145, Loss: 0.7600
Epoch 1/10, Batch 50/145, Loss: 0.7520
Epoch 1/10, Batch 60/145, Loss: 0.6876
Epoch 1/10, Batch 70/145, Loss: 0.3948
Epoch 1/10, Batch 80/145, Loss: 0.6520
Epoch 1/10, Batch 90/145, Loss: 0.3235
Epoch 1/10, Batch 100/145, Loss: 0.5358
Epoch 1/10, Batch 110/145, Loss: 0.3891
Epoch 1/10, Batch 120/145, Loss: 0.6512
Epoch 1/10, Batch 130/145, Loss: 0.4820
Epoch 1/10, Batch 140/145, Loss: 0.2906
Epoch 1/10, Train Loss: 0.6820, Valid Loss: 0.3781
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4694
Epoch 2/10, Batch 20/145, Loss: 0.3593
Epoch 2/10, Batch 30/145, Loss: 0.2845
Epoch 2/10, Batch 40/145, Loss: 0.3733
Epoch 2/10, Batch 50/145, Loss: 0.2717
Epoch 2/10, Batch 60/145, Loss: 0.3989
Epoch 2/10, Batch 70/145, Loss: 0.2959
Epoch 2/10, Batch 80/145, Loss: 0.3895
Epoch 2/10, Batch 90/145, Loss: 0.3275
Epoch 2/10, Batch 100/145, Loss: 0.2613
Epoch 2/10, Batch 110/145, Loss: 0.3902
Epoch 2/10, Batch 120/145, Loss: 0.5822
Epoch 2/10, Batch 130/145, Loss: 0.2736
Epoch 2/10, Batch 140/145, Loss: 0.2970
Epoch 2/10, Train Loss: 0.3553, Valid Loss: 0.2984
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.4033
Epoch 3/10, Batch 20/145, Loss: 0.1953
Epoch 3/10, Batch 30/145, Loss: 0.2500
Epoch 3/10, Batch 40/145, Loss: 0.2408
Epoch 3/10, Batch 50/145, Loss: 0.2668
Epoch 3/10, Batch 60/145, Loss: 0.2782
Epoch 3/10, Batch 70/145, Loss: 0.2649
Epoch 3/10, Batch 80/145, Loss: 0.3066
Epoch 3/10, Batch 90/145, Loss: 0.2920
Epoch 3/10, Batch 100/145, Loss: 0.2772
Epoch 3/10, Batch 110/145, Loss: 0.1366
Epoch 3/10, Batch 120/145, Loss: 0.3766
Epoch 3/10, Batch 130/145, Loss: 0.2719
Epoch 3/10, Batch 140/145, Loss: 0.2846
Epoch 3/10, Train Loss: 0.2919, Valid Loss: 0.2680
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2998
Epoch 4/10, Batch 20/145, Loss: 0.2242
Epoch 4/10, Batch 30/145, Loss: 0.1462
Epoch 4/10, Batch 40/145, Loss: 0.1854
Epoch 4/10, Batch 50/145, Loss: 0.3168
Epoch 4/10, Batch 60/145, Loss: 0.1357
Epoch 4/10, Batch 70/145, Loss: 0.1057
Epoch 4/10, Batch 80/145, Loss: 0.2048
Epoch 4/10, Batch 90/145, Loss: 0.2654
Epoch 4/10, Batch 100/145, Loss: 0.3194
Epoch 4/10, Batch 110/145, Loss: 0.1907
Epoch 4/10, Batch 120/145, Loss: 0.3181
Epoch 4/10, Batch 130/145, Loss: 0.1138
Epoch 4/10, Batch 140/145, Loss: 0.1388
Epoch 4/10, Train Loss: 0.2582, Valid Loss: 0.2586
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3048
Epoch 5/10, Batch 20/145, Loss: 0.1923
Epoch 5/10, Batch 30/145, Loss: 0.2113
Epoch 5/10, Batch 40/145, Loss: 0.1751
Epoch 5/10, Batch 50/145, Loss: 0.3096
Epoch 5/10, Batch 60/145, Loss: 0.2288
Epoch 5/10, Batch 70/145, Loss: 0.2119
Epoch 5/10, Batch 80/145, Loss: 0.2465
Epoch 5/10, Batch 90/145, Loss: 0.5128
Epoch 5/10, Batch 100/145, Loss: 0.1673
Epoch 5/10, Batch 110/145, Loss: 0.1193
Epoch 5/10, Batch 120/145, Loss: 0.2565
Epoch 5/10, Batch 130/145, Loss: 0.2324
Epoch 5/10, Batch 140/145, Loss: 0.1210
Epoch 5/10, Train Loss: 0.2438, Valid Loss: 0.2432
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2245
Epoch 6/10, Batch 20/145, Loss: 0.4604
Epoch 6/10, Batch 30/145, Loss: 0.2266
Epoch 6/10, Batch 40/145, Loss: 0.1452
Epoch 6/10, Batch 50/145, Loss: 0.2671
Epoch 6/10, Batch 60/145, Loss: 0.1506
Epoch 6/10, Batch 70/145, Loss: 0.0586
Epoch 6/10, Batch 80/145, Loss: 0.1116
Epoch 6/10, Batch 90/145, Loss: 0.2665
Epoch 6/10, Batch 100/145, Loss: 0.3294
Epoch 6/10, Batch 110/145, Loss: 0.2630
Epoch 6/10, Batch 120/145, Loss: 0.3955
Epoch 6/10, Batch 130/145, Loss: 0.2162
Epoch 6/10, Batch 140/145, Loss: 0.0980
Epoch 6/10, Train Loss: 0.2218, Valid Loss: 0.2346
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2656
Epoch 7/10, Batch 20/145, Loss: 0.3865
Epoch 7/10, Batch 30/145, Loss: 0.1708
Epoch 7/10, Batch 40/145, Loss: 0.3705
Epoch 7/10, Batch 50/145, Loss: 0.3208
Epoch 7/10, Batch 60/145, Loss: 0.1037
Epoch 7/10, Batch 70/145, Loss: 0.1557
Epoch 7/10, Batch 80/145, Loss: 0.2310
Epoch 7/10, Batch 90/145, Loss: 0.1960
Epoch 7/10, Batch 100/145, Loss: 0.1141
Epoch 7/10, Batch 110/145, Loss: 0.1030
Epoch 7/10, Batch 120/145, Loss: 0.0807
Epoch 7/10, Batch 130/145, Loss: 0.1126
Epoch 7/10, Batch 140/145, Loss: 0.2512
Epoch 7/10, Train Loss: 0.2090, Valid Loss: 0.2344
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2123
Epoch 8/10, Batch 20/145, Loss: 0.2052
Epoch 8/10, Batch 30/145, Loss: 0.0944
Epoch 8/10, Batch 40/145, Loss: 0.3085
Epoch 8/10, Batch 50/145, Loss: 0.1752
Epoch 8/10, Batch 60/145, Loss: 0.2296
Epoch 8/10, Batch 70/145, Loss: 0.2357
Epoch 8/10, Batch 80/145, Loss: 0.1500
Epoch 8/10, Batch 90/145, Loss: 0.1638
Epoch 8/10, Batch 100/145, Loss: 0.1228
Epoch 8/10, Batch 110/145, Loss: 0.3842
Epoch 8/10, Batch 120/145, Loss: 0.0744
Epoch 8/10, Batch 130/145, Loss: 0.2694
Epoch 8/10, Batch 140/145, Loss: 0.1849
Epoch 8/10, Train Loss: 0.2058, Valid Loss: 0.2256
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2777
Epoch 9/10, Batch 20/145, Loss: 0.3209
Epoch 9/10, Batch 30/145, Loss: 0.2578
Epoch 9/10, Batch 40/145, Loss: 0.2841
Epoch 9/10, Batch 50/145, Loss: 0.0603
Epoch 9/10, Batch 60/145, Loss: 0.1611
Epoch 9/10, Batch 70/145, Loss: 0.1238
Epoch 9/10, Batch 80/145, Loss: 0.0980
Epoch 9/10, Batch 90/145, Loss: 0.1942
Epoch 9/10, Batch 100/145, Loss: 0.1389
Epoch 9/10, Batch 110/145, Loss: 0.1719
Epoch 9/10, Batch 120/145, Loss: 0.1721
Epoch 9/10, Batch 130/145, Loss: 0.1197
Epoch 9/10, Batch 140/145, Loss: 0.4074
Epoch 9/10, Train Loss: 0.2029, Valid Loss: 0.2217
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2455
Epoch 10/10, Batch 20/145, Loss: 0.1355
Epoch 10/10, Batch 30/145, Loss: 0.2574
Epoch 10/10, Batch 40/145, Loss: 0.0773
Epoch 10/10, Batch 50/145, Loss: 0.1538
Epoch 10/10, Batch 60/145, Loss: 0.1074
Epoch 10/10, Batch 70/145, Loss: 0.3312
Epoch 10/10, Batch 80/145, Loss: 0.1035
Epoch 10/10, Batch 90/145, Loss: 0.3078
Epoch 10/10, Batch 100/145, Loss: 0.1047
Epoch 10/10, Batch 110/145, Loss: 0.2433
Epoch 10/10, Batch 120/145, Loss: 0.4206
Epoch 10/10, Batch 130/145, Loss: 0.1415
Epoch 10/10, Batch 140/145, Loss: 0.3535
Epoch 10/10, Train Loss: 0.1901, Valid Loss: 0.2184
Model saved!
Accuracy: 0.9182
Precision: 0.9149
Recall: 0.9182
F1-score: 0.9155
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3635
Epoch 1/10, Batch 20/145, Loss: 0.9013
Epoch 1/10, Batch 30/145, Loss: 0.8855
Epoch 1/10, Batch 40/145, Loss: 0.7083
Epoch 1/10, Batch 50/145, Loss: 0.6997
Epoch 1/10, Batch 60/145, Loss: 0.5784
Epoch 1/10, Batch 70/145, Loss: 0.3958
Epoch 1/10, Batch 80/145, Loss: 0.5388
Epoch 1/10, Batch 90/145, Loss: 0.2702
Epoch 1/10, Batch 100/145, Loss: 0.5426
Epoch 1/10, Batch 110/145, Loss: 0.3403
Epoch 1/10, Batch 120/145, Loss: 0.4304
Epoch 1/10, Batch 130/145, Loss: 0.5047
Epoch 1/10, Batch 140/145, Loss: 0.3979
Epoch 1/10, Train Loss: 0.6781, Valid Loss: 0.3852
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3796
Epoch 2/10, Batch 20/145, Loss: 0.3506
Epoch 2/10, Batch 30/145, Loss: 0.2735
Epoch 2/10, Batch 40/145, Loss: 0.4268
Epoch 2/10, Batch 50/145, Loss: 0.3821
Epoch 2/10, Batch 60/145, Loss: 0.3469
Epoch 2/10, Batch 70/145, Loss: 0.3581
Epoch 2/10, Batch 80/145, Loss: 0.2839
Epoch 2/10, Batch 90/145, Loss: 0.2375
Epoch 2/10, Batch 100/145, Loss: 0.2181
Epoch 2/10, Batch 110/145, Loss: 0.3339
Epoch 2/10, Batch 120/145, Loss: 0.2979
Epoch 2/10, Batch 130/145, Loss: 0.3154
Epoch 2/10, Batch 140/145, Loss: 0.4047
Epoch 2/10, Train Loss: 0.3539, Valid Loss: 0.3012
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1864
Epoch 3/10, Batch 20/145, Loss: 0.2252
Epoch 3/10, Batch 30/145, Loss: 0.4259
Epoch 3/10, Batch 40/145, Loss: 0.1496
Epoch 3/10, Batch 50/145, Loss: 0.2521
Epoch 3/10, Batch 60/145, Loss: 0.2857
Epoch 3/10, Batch 70/145, Loss: 0.2801
Epoch 3/10, Batch 80/145, Loss: 0.4403
Epoch 3/10, Batch 90/145, Loss: 0.3537
Epoch 3/10, Batch 100/145, Loss: 0.3246
Epoch 3/10, Batch 110/145, Loss: 0.2952
Epoch 3/10, Batch 120/145, Loss: 0.3191
Epoch 3/10, Batch 130/145, Loss: 0.3293
Epoch 3/10, Batch 140/145, Loss: 0.2476
Epoch 3/10, Train Loss: 0.2923, Valid Loss: 0.2744
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4214
Epoch 4/10, Batch 20/145, Loss: 0.1675
Epoch 4/10, Batch 30/145, Loss: 0.3077
Epoch 4/10, Batch 40/145, Loss: 0.1063
Epoch 4/10, Batch 50/145, Loss: 0.2196
Epoch 4/10, Batch 60/145, Loss: 0.3532
Epoch 4/10, Batch 70/145, Loss: 0.1468
Epoch 4/10, Batch 80/145, Loss: 0.2801
Epoch 4/10, Batch 90/145, Loss: 0.2027
Epoch 4/10, Batch 100/145, Loss: 0.2710
Epoch 4/10, Batch 110/145, Loss: 0.2257
Epoch 4/10, Batch 120/145, Loss: 0.2102
Epoch 4/10, Batch 130/145, Loss: 0.1149
Epoch 4/10, Batch 140/145, Loss: 0.1910
Epoch 4/10, Train Loss: 0.2623, Valid Loss: 0.2569
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1425
Epoch 5/10, Batch 20/145, Loss: 0.3457
Epoch 5/10, Batch 30/145, Loss: 0.2640
Epoch 5/10, Batch 40/145, Loss: 0.0910
Epoch 5/10, Batch 50/145, Loss: 0.1562
Epoch 5/10, Batch 60/145, Loss: 0.1289
Epoch 5/10, Batch 70/145, Loss: 0.1139
Epoch 5/10, Batch 80/145, Loss: 0.1855
Epoch 5/10, Batch 90/145, Loss: 0.1638
Epoch 5/10, Batch 100/145, Loss: 0.2654
Epoch 5/10, Batch 110/145, Loss: 0.2883
Epoch 5/10, Batch 120/145, Loss: 0.3681
Epoch 5/10, Batch 130/145, Loss: 0.2185
Epoch 5/10, Batch 140/145, Loss: 0.1700
Epoch 5/10, Train Loss: 0.2399, Valid Loss: 0.2514
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2322
Epoch 6/10, Batch 20/145, Loss: 0.4776
Epoch 6/10, Batch 30/145, Loss: 0.4468
Epoch 6/10, Batch 40/145, Loss: 0.0964
Epoch 6/10, Batch 50/145, Loss: 0.3603
Epoch 6/10, Batch 60/145, Loss: 0.1930
Epoch 6/10, Batch 70/145, Loss: 0.1561
Epoch 6/10, Batch 80/145, Loss: 0.2265
Epoch 6/10, Batch 90/145, Loss: 0.2684
Epoch 6/10, Batch 100/145, Loss: 0.2165
Epoch 6/10, Batch 110/145, Loss: 0.2921
Epoch 6/10, Batch 120/145, Loss: 0.1694
Epoch 6/10, Batch 130/145, Loss: 0.0934
Epoch 6/10, Batch 140/145, Loss: 0.2112
Epoch 6/10, Train Loss: 0.2256, Valid Loss: 0.2406
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1907
Epoch 7/10, Batch 20/145, Loss: 0.2246
Epoch 7/10, Batch 30/145, Loss: 0.2498
Epoch 7/10, Batch 40/145, Loss: 0.3285
Epoch 7/10, Batch 50/145, Loss: 0.1616
Epoch 7/10, Batch 60/145, Loss: 0.2122
Epoch 7/10, Batch 70/145, Loss: 0.1814
Epoch 7/10, Batch 80/145, Loss: 0.4909
Epoch 7/10, Batch 90/145, Loss: 0.1885
Epoch 7/10, Batch 100/145, Loss: 0.1625
Epoch 7/10, Batch 110/145, Loss: 0.1854
Epoch 7/10, Batch 120/145, Loss: 0.2076
Epoch 7/10, Batch 130/145, Loss: 0.0886
Epoch 7/10, Batch 140/145, Loss: 0.2565
Epoch 7/10, Train Loss: 0.2100, Valid Loss: 0.2376
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.3066
Epoch 8/10, Batch 20/145, Loss: 0.1872
Epoch 8/10, Batch 30/145, Loss: 0.3298
Epoch 8/10, Batch 40/145, Loss: 0.2380
Epoch 8/10, Batch 50/145, Loss: 0.1983
Epoch 8/10, Batch 60/145, Loss: 0.0996
Epoch 8/10, Batch 70/145, Loss: 0.1986
Epoch 8/10, Batch 80/145, Loss: 0.1624
Epoch 8/10, Batch 90/145, Loss: 0.3579
Epoch 8/10, Batch 100/145, Loss: 0.2387
Epoch 8/10, Batch 110/145, Loss: 0.1568
Epoch 8/10, Batch 120/145, Loss: 0.2116
Epoch 8/10, Batch 130/145, Loss: 0.0885
Epoch 8/10, Batch 140/145, Loss: 0.3654
Epoch 8/10, Train Loss: 0.2068, Valid Loss: 0.2364
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2402
Epoch 9/10, Batch 20/145, Loss: 0.1655
Epoch 9/10, Batch 30/145, Loss: 0.2885
Epoch 9/10, Batch 40/145, Loss: 0.2128
Epoch 9/10, Batch 50/145, Loss: 0.1279
Epoch 9/10, Batch 60/145, Loss: 0.1447
Epoch 9/10, Batch 70/145, Loss: 0.1548
Epoch 9/10, Batch 80/145, Loss: 0.2213
Epoch 9/10, Batch 90/145, Loss: 0.2471
Epoch 9/10, Batch 100/145, Loss: 0.1352
Epoch 9/10, Batch 110/145, Loss: 0.2710
Epoch 9/10, Batch 120/145, Loss: 0.1653
Epoch 9/10, Batch 130/145, Loss: 0.2490
Epoch 9/10, Batch 140/145, Loss: 0.3033
Epoch 9/10, Train Loss: 0.1966, Valid Loss: 0.2402
Epoch 10/10, Batch 10/145, Loss: 0.0699
Epoch 10/10, Batch 20/145, Loss: 0.1648
Epoch 10/10, Batch 30/145, Loss: 0.0631
Epoch 10/10, Batch 40/145, Loss: 0.0635
Epoch 10/10, Batch 50/145, Loss: 0.1355
Epoch 10/10, Batch 60/145, Loss: 0.2194
Epoch 10/10, Batch 70/145, Loss: 0.1798
Epoch 10/10, Batch 80/145, Loss: 0.1740
Epoch 10/10, Batch 90/145, Loss: 0.1616
Epoch 10/10, Batch 100/145, Loss: 0.1563
Epoch 10/10, Batch 110/145, Loss: 0.1530
Epoch 10/10, Batch 120/145, Loss: 0.1855
Epoch 10/10, Batch 130/145, Loss: 0.1927
Epoch 10/10, Batch 140/145, Loss: 0.1864
Epoch 10/10, Train Loss: 0.1865, Valid Loss: 0.2304
Model saved!
Accuracy: 0.9206
Precision: 0.9188
Recall: 0.9206
F1-score: 0.9188
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3818
Epoch 1/10, Batch 20/145, Loss: 0.9177
Epoch 1/10, Batch 30/145, Loss: 0.9750
Epoch 1/10, Batch 40/145, Loss: 0.8691
Epoch 1/10, Batch 50/145, Loss: 0.6235
Epoch 1/10, Batch 60/145, Loss: 0.5717
Epoch 1/10, Batch 70/145, Loss: 0.4473
Epoch 1/10, Batch 80/145, Loss: 0.4727
Epoch 1/10, Batch 90/145, Loss: 0.4268
Epoch 1/10, Batch 100/145, Loss: 0.4916
Epoch 1/10, Batch 110/145, Loss: 0.4194
Epoch 1/10, Batch 120/145, Loss: 0.6118
Epoch 1/10, Batch 130/145, Loss: 0.3793
Epoch 1/10, Batch 140/145, Loss: 0.3607
Epoch 1/10, Train Loss: 0.6775, Valid Loss: 0.4015
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3604
Epoch 2/10, Batch 20/145, Loss: 0.2463
Epoch 2/10, Batch 30/145, Loss: 0.2746
Epoch 2/10, Batch 40/145, Loss: 0.4556
Epoch 2/10, Batch 50/145, Loss: 0.3593
Epoch 2/10, Batch 60/145, Loss: 0.4067
Epoch 2/10, Batch 70/145, Loss: 0.3532
Epoch 2/10, Batch 80/145, Loss: 0.3451
Epoch 2/10, Batch 90/145, Loss: 0.3482
Epoch 2/10, Batch 100/145, Loss: 0.2515
Epoch 2/10, Batch 110/145, Loss: 0.3441
Epoch 2/10, Batch 120/145, Loss: 0.2820
Epoch 2/10, Batch 130/145, Loss: 0.3389
Epoch 2/10, Batch 140/145, Loss: 0.3633
Epoch 2/10, Train Loss: 0.3560, Valid Loss: 0.3074
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2148
Epoch 3/10, Batch 20/145, Loss: 0.2889
Epoch 3/10, Batch 30/145, Loss: 0.3826
Epoch 3/10, Batch 40/145, Loss: 0.2028
Epoch 3/10, Batch 50/145, Loss: 0.1276
Epoch 3/10, Batch 60/145, Loss: 0.4394
Epoch 3/10, Batch 70/145, Loss: 0.3297
Epoch 3/10, Batch 80/145, Loss: 0.2985
Epoch 3/10, Batch 90/145, Loss: 0.3782
Epoch 3/10, Batch 100/145, Loss: 0.2993
Epoch 3/10, Batch 110/145, Loss: 0.3239
Epoch 3/10, Batch 120/145, Loss: 0.2034
Epoch 3/10, Batch 130/145, Loss: 0.2250
Epoch 3/10, Batch 140/145, Loss: 0.1953
Epoch 3/10, Train Loss: 0.2982, Valid Loss: 0.2770
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2673
Epoch 4/10, Batch 20/145, Loss: 0.3117
Epoch 4/10, Batch 30/145, Loss: 0.3672
Epoch 4/10, Batch 40/145, Loss: 0.2586
Epoch 4/10, Batch 50/145, Loss: 0.2114
Epoch 4/10, Batch 60/145, Loss: 0.1837
Epoch 4/10, Batch 70/145, Loss: 0.1385
Epoch 4/10, Batch 80/145, Loss: 0.1159
Epoch 4/10, Batch 90/145, Loss: 0.2731
Epoch 4/10, Batch 100/145, Loss: 0.2806
Epoch 4/10, Batch 110/145, Loss: 0.1470
Epoch 4/10, Batch 120/145, Loss: 0.2568
Epoch 4/10, Batch 130/145, Loss: 0.1164
Epoch 4/10, Batch 140/145, Loss: 0.1704
Epoch 4/10, Train Loss: 0.2567, Valid Loss: 0.2634
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1660
Epoch 5/10, Batch 20/145, Loss: 0.1093
Epoch 5/10, Batch 30/145, Loss: 0.2472
Epoch 5/10, Batch 40/145, Loss: 0.2308
Epoch 5/10, Batch 50/145, Loss: 0.1610
Epoch 5/10, Batch 60/145, Loss: 0.1775
Epoch 5/10, Batch 70/145, Loss: 0.1783
Epoch 5/10, Batch 80/145, Loss: 0.2544
Epoch 5/10, Batch 90/145, Loss: 0.3352
Epoch 5/10, Batch 100/145, Loss: 0.2223
Epoch 5/10, Batch 110/145, Loss: 0.2338
Epoch 5/10, Batch 120/145, Loss: 0.1689
Epoch 5/10, Batch 130/145, Loss: 0.1635
Epoch 5/10, Batch 140/145, Loss: 0.2041
Epoch 5/10, Train Loss: 0.2427, Valid Loss: 0.2529
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1457
Epoch 6/10, Batch 20/145, Loss: 0.3212
Epoch 6/10, Batch 30/145, Loss: 0.3464
Epoch 6/10, Batch 40/145, Loss: 0.2780
Epoch 6/10, Batch 50/145, Loss: 0.3720
Epoch 6/10, Batch 60/145, Loss: 0.1594
Epoch 6/10, Batch 70/145, Loss: 0.1004
Epoch 6/10, Batch 80/145, Loss: 0.2359
Epoch 6/10, Batch 90/145, Loss: 0.2914
Epoch 6/10, Batch 100/145, Loss: 0.2602
Epoch 6/10, Batch 110/145, Loss: 0.1533
Epoch 6/10, Batch 120/145, Loss: 0.4993
Epoch 6/10, Batch 130/145, Loss: 0.2307
Epoch 6/10, Batch 140/145, Loss: 0.1736
Epoch 6/10, Train Loss: 0.2271, Valid Loss: 0.2435
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1217
Epoch 7/10, Batch 20/145, Loss: 0.2149
Epoch 7/10, Batch 30/145, Loss: 0.2400
Epoch 7/10, Batch 40/145, Loss: 0.3537
Epoch 7/10, Batch 50/145, Loss: 0.1786
Epoch 7/10, Batch 60/145, Loss: 0.2151
Epoch 7/10, Batch 70/145, Loss: 0.1557
Epoch 7/10, Batch 80/145, Loss: 0.3149
Epoch 7/10, Batch 90/145, Loss: 0.1556
Epoch 7/10, Batch 100/145, Loss: 0.2170
Epoch 7/10, Batch 110/145, Loss: 0.1184
Epoch 7/10, Batch 120/145, Loss: 0.5054
Epoch 7/10, Batch 130/145, Loss: 0.0979
Epoch 7/10, Batch 140/145, Loss: 0.1920
Epoch 7/10, Train Loss: 0.2153, Valid Loss: 0.2366
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1272
Epoch 8/10, Batch 20/145, Loss: 0.1834
Epoch 8/10, Batch 30/145, Loss: 0.1992
Epoch 8/10, Batch 40/145, Loss: 0.0964
Epoch 8/10, Batch 50/145, Loss: 0.2275
Epoch 8/10, Batch 60/145, Loss: 0.1436
Epoch 8/10, Batch 70/145, Loss: 0.1628
Epoch 8/10, Batch 80/145, Loss: 0.0855
Epoch 8/10, Batch 90/145, Loss: 0.2025
Epoch 8/10, Batch 100/145, Loss: 0.4648
Epoch 8/10, Batch 110/145, Loss: 0.3102
Epoch 8/10, Batch 120/145, Loss: 0.2494
Epoch 8/10, Batch 130/145, Loss: 0.1119
Epoch 8/10, Batch 140/145, Loss: 0.1318
Epoch 8/10, Train Loss: 0.2063, Valid Loss: 0.2315
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3750
Epoch 9/10, Batch 20/145, Loss: 0.3192
Epoch 9/10, Batch 30/145, Loss: 0.1643
Epoch 9/10, Batch 40/145, Loss: 0.1861
Epoch 9/10, Batch 50/145, Loss: 0.3340
Epoch 9/10, Batch 60/145, Loss: 0.2060
Epoch 9/10, Batch 70/145, Loss: 0.2131
Epoch 9/10, Batch 80/145, Loss: 0.0694
Epoch 9/10, Batch 90/145, Loss: 0.2039
Epoch 9/10, Batch 100/145, Loss: 0.2818
Epoch 9/10, Batch 110/145, Loss: 0.1822
Epoch 9/10, Batch 120/145, Loss: 0.1643
Epoch 9/10, Batch 130/145, Loss: 0.0775
Epoch 9/10, Batch 140/145, Loss: 0.3042
Epoch 9/10, Train Loss: 0.2024, Valid Loss: 0.2269
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0841
Epoch 10/10, Batch 20/145, Loss: 0.1364
Epoch 10/10, Batch 30/145, Loss: 0.2885
Epoch 10/10, Batch 40/145, Loss: 0.1597
Epoch 10/10, Batch 50/145, Loss: 0.1934
Epoch 10/10, Batch 60/145, Loss: 0.2742
Epoch 10/10, Batch 70/145, Loss: 0.2137
Epoch 10/10, Batch 80/145, Loss: 0.2284
Epoch 10/10, Batch 90/145, Loss: 0.0667
Epoch 10/10, Batch 100/145, Loss: 0.2505
Epoch 10/10, Batch 110/145, Loss: 0.3728
Epoch 10/10, Batch 120/145, Loss: 0.1350
Epoch 10/10, Batch 130/145, Loss: 0.2020
Epoch 10/10, Batch 140/145, Loss: 0.2168
Epoch 10/10, Train Loss: 0.1975, Valid Loss: 0.2251
Model saved!
Accuracy: 0.9206
Precision: 0.9176
Recall: 0.9206
F1-score: 0.9186
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4498
Epoch 1/10, Batch 20/145, Loss: 1.0184
Epoch 1/10, Batch 30/145, Loss: 0.9625
Epoch 1/10, Batch 40/145, Loss: 0.7898
Epoch 1/10, Batch 50/145, Loss: 0.7836
Epoch 1/10, Batch 60/145, Loss: 0.6224
Epoch 1/10, Batch 70/145, Loss: 0.6540
Epoch 1/10, Batch 80/145, Loss: 0.6307
Epoch 1/10, Batch 90/145, Loss: 0.4659
Epoch 1/10, Batch 100/145, Loss: 0.4581
Epoch 1/10, Batch 110/145, Loss: 0.3471
Epoch 1/10, Batch 120/145, Loss: 0.5652
Epoch 1/10, Batch 130/145, Loss: 0.5239
Epoch 1/10, Batch 140/145, Loss: 0.3958
Epoch 1/10, Train Loss: 0.6800, Valid Loss: 0.3702
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3470
Epoch 2/10, Batch 20/145, Loss: 0.3251
Epoch 2/10, Batch 30/145, Loss: 0.3410
Epoch 2/10, Batch 40/145, Loss: 0.3878
Epoch 2/10, Batch 50/145, Loss: 0.3711
Epoch 2/10, Batch 60/145, Loss: 0.3769
Epoch 2/10, Batch 70/145, Loss: 0.3113
Epoch 2/10, Batch 80/145, Loss: 0.2685
Epoch 2/10, Batch 90/145, Loss: 0.3446
Epoch 2/10, Batch 100/145, Loss: 0.3422
Epoch 2/10, Batch 110/145, Loss: 0.4306
Epoch 2/10, Batch 120/145, Loss: 0.3979
Epoch 2/10, Batch 130/145, Loss: 0.3109
Epoch 2/10, Batch 140/145, Loss: 0.3733
Epoch 2/10, Train Loss: 0.3600, Valid Loss: 0.2968
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2460
Epoch 3/10, Batch 20/145, Loss: 0.4320
Epoch 3/10, Batch 30/145, Loss: 0.2733
Epoch 3/10, Batch 40/145, Loss: 0.2342
Epoch 3/10, Batch 50/145, Loss: 0.2548
Epoch 3/10, Batch 60/145, Loss: 0.3510
Epoch 3/10, Batch 70/145, Loss: 0.2651
Epoch 3/10, Batch 80/145, Loss: 0.2375
Epoch 3/10, Batch 90/145, Loss: 0.1509
Epoch 3/10, Batch 100/145, Loss: 0.2539
Epoch 3/10, Batch 110/145, Loss: 0.2689
Epoch 3/10, Batch 120/145, Loss: 0.3570
Epoch 3/10, Batch 130/145, Loss: 0.3530
Epoch 3/10, Batch 140/145, Loss: 0.2604
Epoch 3/10, Train Loss: 0.2997, Valid Loss: 0.2648
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3419
Epoch 4/10, Batch 20/145, Loss: 0.3305
Epoch 4/10, Batch 30/145, Loss: 0.2902
Epoch 4/10, Batch 40/145, Loss: 0.2333
Epoch 4/10, Batch 50/145, Loss: 0.1124
Epoch 4/10, Batch 60/145, Loss: 0.2433
Epoch 4/10, Batch 70/145, Loss: 0.2544
Epoch 4/10, Batch 80/145, Loss: 0.2175
Epoch 4/10, Batch 90/145, Loss: 0.1692
Epoch 4/10, Batch 100/145, Loss: 0.4774
Epoch 4/10, Batch 110/145, Loss: 0.3693
Epoch 4/10, Batch 120/145, Loss: 0.3122
Epoch 4/10, Batch 130/145, Loss: 0.1061
Epoch 4/10, Batch 140/145, Loss: 0.2180
Epoch 4/10, Train Loss: 0.2638, Valid Loss: 0.2504
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2384
Epoch 5/10, Batch 20/145, Loss: 0.1405
Epoch 5/10, Batch 30/145, Loss: 0.1960
Epoch 5/10, Batch 40/145, Loss: 0.1461
Epoch 5/10, Batch 50/145, Loss: 0.1731
Epoch 5/10, Batch 60/145, Loss: 0.1980
Epoch 5/10, Batch 70/145, Loss: 0.1180
Epoch 5/10, Batch 80/145, Loss: 0.2109
Epoch 5/10, Batch 90/145, Loss: 0.2900
Epoch 5/10, Batch 100/145, Loss: 0.2128
Epoch 5/10, Batch 110/145, Loss: 0.1896
Epoch 5/10, Batch 120/145, Loss: 0.3691
Epoch 5/10, Batch 130/145, Loss: 0.1817
Epoch 5/10, Batch 140/145, Loss: 0.1566
Epoch 5/10, Train Loss: 0.2423, Valid Loss: 0.2378
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2444
Epoch 6/10, Batch 20/145, Loss: 0.4370
Epoch 6/10, Batch 30/145, Loss: 0.2300
Epoch 6/10, Batch 40/145, Loss: 0.1183
Epoch 6/10, Batch 50/145, Loss: 0.2288
Epoch 6/10, Batch 60/145, Loss: 0.2230
Epoch 6/10, Batch 70/145, Loss: 0.1916
Epoch 6/10, Batch 80/145, Loss: 0.3903
Epoch 6/10, Batch 90/145, Loss: 0.2640
Epoch 6/10, Batch 100/145, Loss: 0.3158
Epoch 6/10, Batch 110/145, Loss: 0.1747
Epoch 6/10, Batch 120/145, Loss: 0.4039
Epoch 6/10, Batch 130/145, Loss: 0.1420
Epoch 6/10, Batch 140/145, Loss: 0.1526
Epoch 6/10, Train Loss: 0.2288, Valid Loss: 0.2272
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2478
Epoch 7/10, Batch 20/145, Loss: 0.1873
Epoch 7/10, Batch 30/145, Loss: 0.1401
Epoch 7/10, Batch 40/145, Loss: 0.3341
Epoch 7/10, Batch 50/145, Loss: 0.1041
Epoch 7/10, Batch 60/145, Loss: 0.1197
Epoch 7/10, Batch 70/145, Loss: 0.0902
Epoch 7/10, Batch 80/145, Loss: 0.5905
Epoch 7/10, Batch 90/145, Loss: 0.1650
Epoch 7/10, Batch 100/145, Loss: 0.1142
Epoch 7/10, Batch 110/145, Loss: 0.1103
Epoch 7/10, Batch 120/145, Loss: 0.1886
Epoch 7/10, Batch 130/145, Loss: 0.1355
Epoch 7/10, Batch 140/145, Loss: 0.1249
Epoch 7/10, Train Loss: 0.2178, Valid Loss: 0.2171
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1516
Epoch 8/10, Batch 20/145, Loss: 0.2233
Epoch 8/10, Batch 30/145, Loss: 0.2285
Epoch 8/10, Batch 40/145, Loss: 0.1764
Epoch 8/10, Batch 50/145, Loss: 0.2865
Epoch 8/10, Batch 60/145, Loss: 0.1754
Epoch 8/10, Batch 70/145, Loss: 0.2443
Epoch 8/10, Batch 80/145, Loss: 0.1356
Epoch 8/10, Batch 90/145, Loss: 0.5426
Epoch 8/10, Batch 100/145, Loss: 0.1368
Epoch 8/10, Batch 110/145, Loss: 0.0981
Epoch 8/10, Batch 120/145, Loss: 0.1728
Epoch 8/10, Batch 130/145, Loss: 0.1334
Epoch 8/10, Batch 140/145, Loss: 0.1503
Epoch 8/10, Train Loss: 0.2144, Valid Loss: 0.2161
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2615
Epoch 9/10, Batch 20/145, Loss: 0.1786
Epoch 9/10, Batch 30/145, Loss: 0.1524
Epoch 9/10, Batch 40/145, Loss: 0.3238
Epoch 9/10, Batch 50/145, Loss: 0.2090
Epoch 9/10, Batch 60/145, Loss: 0.1693
Epoch 9/10, Batch 70/145, Loss: 0.2326
Epoch 9/10, Batch 80/145, Loss: 0.0884
Epoch 9/10, Batch 90/145, Loss: 0.1824
Epoch 9/10, Batch 100/145, Loss: 0.1354
Epoch 9/10, Batch 110/145, Loss: 0.2075
Epoch 9/10, Batch 120/145, Loss: 0.1510
Epoch 9/10, Batch 130/145, Loss: 0.2013
Epoch 9/10, Batch 140/145, Loss: 0.1829
Epoch 9/10, Train Loss: 0.2033, Valid Loss: 0.2146
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1710
Epoch 10/10, Batch 20/145, Loss: 0.1800
Epoch 10/10, Batch 30/145, Loss: 0.1855
Epoch 10/10, Batch 40/145, Loss: 0.1497
Epoch 10/10, Batch 50/145, Loss: 0.1855
Epoch 10/10, Batch 60/145, Loss: 0.1213
Epoch 10/10, Batch 70/145, Loss: 0.3995
Epoch 10/10, Batch 80/145, Loss: 0.0949
Epoch 10/10, Batch 90/145, Loss: 0.1463
Epoch 10/10, Batch 100/145, Loss: 0.1343
Epoch 10/10, Batch 110/145, Loss: 0.0856
Epoch 10/10, Batch 120/145, Loss: 0.1866
Epoch 10/10, Batch 130/145, Loss: 0.1479
Epoch 10/10, Batch 140/145, Loss: 0.2041
Epoch 10/10, Train Loss: 0.2005, Valid Loss: 0.2162
Accuracy: 0.9229
Precision: 0.9213
Recall: 0.9229
F1-score: 0.9217
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3844
Epoch 1/10, Batch 20/145, Loss: 0.9089
Epoch 1/10, Batch 30/145, Loss: 0.8745
Epoch 1/10, Batch 40/145, Loss: 0.9102
Epoch 1/10, Batch 50/145, Loss: 0.6905
Epoch 1/10, Batch 60/145, Loss: 0.6843
Epoch 1/10, Batch 70/145, Loss: 0.4161
Epoch 1/10, Batch 80/145, Loss: 0.5712
Epoch 1/10, Batch 90/145, Loss: 0.3676
Epoch 1/10, Batch 100/145, Loss: 0.4770
Epoch 1/10, Batch 110/145, Loss: 0.4772
Epoch 1/10, Batch 120/145, Loss: 0.6432
Epoch 1/10, Batch 130/145, Loss: 0.3963
Epoch 1/10, Batch 140/145, Loss: 0.3698
Epoch 1/10, Train Loss: 0.6733, Valid Loss: 0.4196
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3363
Epoch 2/10, Batch 20/145, Loss: 0.2888
Epoch 2/10, Batch 30/145, Loss: 0.1459
Epoch 2/10, Batch 40/145, Loss: 0.3718
Epoch 2/10, Batch 50/145, Loss: 0.3227
Epoch 2/10, Batch 60/145, Loss: 0.3744
Epoch 2/10, Batch 70/145, Loss: 0.3382
Epoch 2/10, Batch 80/145, Loss: 0.2307
Epoch 2/10, Batch 90/145, Loss: 0.2713
Epoch 2/10, Batch 100/145, Loss: 0.3217
Epoch 2/10, Batch 110/145, Loss: 0.3358
Epoch 2/10, Batch 120/145, Loss: 0.3451
Epoch 2/10, Batch 130/145, Loss: 0.2698
Epoch 2/10, Batch 140/145, Loss: 0.1749
Epoch 2/10, Train Loss: 0.3457, Valid Loss: 0.3323
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3616
Epoch 3/10, Batch 20/145, Loss: 0.2389
Epoch 3/10, Batch 30/145, Loss: 0.3878
Epoch 3/10, Batch 40/145, Loss: 0.1467
Epoch 3/10, Batch 50/145, Loss: 0.1405
Epoch 3/10, Batch 60/145, Loss: 0.1790
Epoch 3/10, Batch 70/145, Loss: 0.5334
Epoch 3/10, Batch 80/145, Loss: 0.2120
Epoch 3/10, Batch 90/145, Loss: 0.2962
Epoch 3/10, Batch 100/145, Loss: 0.2681
Epoch 3/10, Batch 110/145, Loss: 0.3306
Epoch 3/10, Batch 120/145, Loss: 0.3554
Epoch 3/10, Batch 130/145, Loss: 0.5959
Epoch 3/10, Batch 140/145, Loss: 0.2649
Epoch 3/10, Train Loss: 0.2851, Valid Loss: 0.2963
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2656
Epoch 4/10, Batch 20/145, Loss: 0.3102
Epoch 4/10, Batch 30/145, Loss: 0.3639
Epoch 4/10, Batch 40/145, Loss: 0.2655
Epoch 4/10, Batch 50/145, Loss: 0.1186
Epoch 4/10, Batch 60/145, Loss: 0.1955
Epoch 4/10, Batch 70/145, Loss: 0.3203
Epoch 4/10, Batch 80/145, Loss: 0.2144
Epoch 4/10, Batch 90/145, Loss: 0.2481
Epoch 4/10, Batch 100/145, Loss: 0.1839
Epoch 4/10, Batch 110/145, Loss: 0.1156
Epoch 4/10, Batch 120/145, Loss: 0.1697
Epoch 4/10, Batch 130/145, Loss: 0.2090
Epoch 4/10, Batch 140/145, Loss: 0.1835
Epoch 4/10, Train Loss: 0.2501, Valid Loss: 0.2852
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1693
Epoch 5/10, Batch 20/145, Loss: 0.0962
Epoch 5/10, Batch 30/145, Loss: 0.2280
Epoch 5/10, Batch 40/145, Loss: 0.3130
Epoch 5/10, Batch 50/145, Loss: 0.2952
Epoch 5/10, Batch 60/145, Loss: 0.0825
Epoch 5/10, Batch 70/145, Loss: 0.1697
Epoch 5/10, Batch 80/145, Loss: 0.1794
Epoch 5/10, Batch 90/145, Loss: 0.3207
Epoch 5/10, Batch 100/145, Loss: 0.2091
Epoch 5/10, Batch 110/145, Loss: 0.1935
Epoch 5/10, Batch 120/145, Loss: 0.3044
Epoch 5/10, Batch 130/145, Loss: 0.3333
Epoch 5/10, Batch 140/145, Loss: 0.1562
Epoch 5/10, Train Loss: 0.2368, Valid Loss: 0.2756
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2329
Epoch 6/10, Batch 20/145, Loss: 0.4496
Epoch 6/10, Batch 30/145, Loss: 0.2100
Epoch 6/10, Batch 40/145, Loss: 0.1079
Epoch 6/10, Batch 50/145, Loss: 0.1944
Epoch 6/10, Batch 60/145, Loss: 0.1334
Epoch 6/10, Batch 70/145, Loss: 0.1910
Epoch 6/10, Batch 80/145, Loss: 0.1181
Epoch 6/10, Batch 90/145, Loss: 0.2578
Epoch 6/10, Batch 100/145, Loss: 0.2299
Epoch 6/10, Batch 110/145, Loss: 0.1819
Epoch 6/10, Batch 120/145, Loss: 0.2636
Epoch 6/10, Batch 130/145, Loss: 0.1678
Epoch 6/10, Batch 140/145, Loss: 0.1060
Epoch 6/10, Train Loss: 0.2180, Valid Loss: 0.2684
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1632
Epoch 7/10, Batch 20/145, Loss: 0.1839
Epoch 7/10, Batch 30/145, Loss: 0.2314
Epoch 7/10, Batch 40/145, Loss: 0.3596
Epoch 7/10, Batch 50/145, Loss: 0.2351
Epoch 7/10, Batch 60/145, Loss: 0.2367
Epoch 7/10, Batch 70/145, Loss: 0.2463
Epoch 7/10, Batch 80/145, Loss: 0.3666
Epoch 7/10, Batch 90/145, Loss: 0.1495
Epoch 7/10, Batch 100/145, Loss: 0.1382
Epoch 7/10, Batch 110/145, Loss: 0.2191
Epoch 7/10, Batch 120/145, Loss: 0.1600
Epoch 7/10, Batch 130/145, Loss: 0.1210
Epoch 7/10, Batch 140/145, Loss: 0.1365
Epoch 7/10, Train Loss: 0.2063, Valid Loss: 0.2608
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2758
Epoch 8/10, Batch 20/145, Loss: 0.1861
Epoch 8/10, Batch 30/145, Loss: 0.5370
Epoch 8/10, Batch 40/145, Loss: 0.1317
Epoch 8/10, Batch 50/145, Loss: 0.3077
Epoch 8/10, Batch 60/145, Loss: 0.3162
Epoch 8/10, Batch 70/145, Loss: 0.2046
Epoch 8/10, Batch 80/145, Loss: 0.2572
Epoch 8/10, Batch 90/145, Loss: 0.4343
Epoch 8/10, Batch 100/145, Loss: 0.2353
Epoch 8/10, Batch 110/145, Loss: 0.2520
Epoch 8/10, Batch 120/145, Loss: 0.1608
Epoch 8/10, Batch 130/145, Loss: 0.2775
Epoch 8/10, Batch 140/145, Loss: 0.2490
Epoch 8/10, Train Loss: 0.2049, Valid Loss: 0.2586
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2587
Epoch 9/10, Batch 20/145, Loss: 0.1707
Epoch 9/10, Batch 30/145, Loss: 0.1479
Epoch 9/10, Batch 40/145, Loss: 0.1858
Epoch 9/10, Batch 50/145, Loss: 0.1598
Epoch 9/10, Batch 60/145, Loss: 0.1288
Epoch 9/10, Batch 70/145, Loss: 0.1926
Epoch 9/10, Batch 80/145, Loss: 0.1227
Epoch 9/10, Batch 90/145, Loss: 0.3193
Epoch 9/10, Batch 100/145, Loss: 0.1712
Epoch 9/10, Batch 110/145, Loss: 0.2833
Epoch 9/10, Batch 120/145, Loss: 0.0721
Epoch 9/10, Batch 130/145, Loss: 0.1100
Epoch 9/10, Batch 140/145, Loss: 0.3025
Epoch 9/10, Train Loss: 0.1897, Valid Loss: 0.2644
Epoch 10/10, Batch 10/145, Loss: 0.1385
Epoch 10/10, Batch 20/145, Loss: 0.1539
Epoch 10/10, Batch 30/145, Loss: 0.0603
Epoch 10/10, Batch 40/145, Loss: 0.0919
Epoch 10/10, Batch 50/145, Loss: 0.1781
Epoch 10/10, Batch 60/145, Loss: 0.1008
Epoch 10/10, Batch 70/145, Loss: 0.3049
Epoch 10/10, Batch 80/145, Loss: 0.1658
Epoch 10/10, Batch 90/145, Loss: 0.1678
Epoch 10/10, Batch 100/145, Loss: 0.1988
Epoch 10/10, Batch 110/145, Loss: 0.1808
Epoch 10/10, Batch 120/145, Loss: 0.2103
Epoch 10/10, Batch 130/145, Loss: 0.2921
Epoch 10/10, Batch 140/145, Loss: 0.2076
Epoch 10/10, Train Loss: 0.1860, Valid Loss: 0.2525
Model saved!
Accuracy: 0.9136
Precision: 0.9100
Recall: 0.9136
F1-score: 0.9109
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4331
Epoch 1/10, Batch 20/145, Loss: 0.8982
Epoch 1/10, Batch 30/145, Loss: 0.8503
Epoch 1/10, Batch 40/145, Loss: 0.7841
Epoch 1/10, Batch 50/145, Loss: 0.7063
Epoch 1/10, Batch 60/145, Loss: 0.5975
Epoch 1/10, Batch 70/145, Loss: 0.5265
Epoch 1/10, Batch 80/145, Loss: 0.5785
Epoch 1/10, Batch 90/145, Loss: 0.4271
Epoch 1/10, Batch 100/145, Loss: 0.4666
Epoch 1/10, Batch 110/145, Loss: 0.4293
Epoch 1/10, Batch 120/145, Loss: 0.5365
Epoch 1/10, Batch 130/145, Loss: 0.4189
Epoch 1/10, Batch 140/145, Loss: 0.2616
Epoch 1/10, Train Loss: 0.6807, Valid Loss: 0.3705
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3622
Epoch 2/10, Batch 20/145, Loss: 0.4729
Epoch 2/10, Batch 30/145, Loss: 0.3150
Epoch 2/10, Batch 40/145, Loss: 0.5090
Epoch 2/10, Batch 50/145, Loss: 0.3501
Epoch 2/10, Batch 60/145, Loss: 0.3499
Epoch 2/10, Batch 70/145, Loss: 0.3103
Epoch 2/10, Batch 80/145, Loss: 0.3390
Epoch 2/10, Batch 90/145, Loss: 0.2669
Epoch 2/10, Batch 100/145, Loss: 0.2872
Epoch 2/10, Batch 110/145, Loss: 0.2444
Epoch 2/10, Batch 120/145, Loss: 0.4166
Epoch 2/10, Batch 130/145, Loss: 0.3629
Epoch 2/10, Batch 140/145, Loss: 0.3048
Epoch 2/10, Train Loss: 0.3569, Valid Loss: 0.2905
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3296
Epoch 3/10, Batch 20/145, Loss: 0.4084
Epoch 3/10, Batch 30/145, Loss: 0.3763
Epoch 3/10, Batch 40/145, Loss: 0.1912
Epoch 3/10, Batch 50/145, Loss: 0.2074
Epoch 3/10, Batch 60/145, Loss: 0.2763
Epoch 3/10, Batch 70/145, Loss: 0.3171
Epoch 3/10, Batch 80/145, Loss: 0.3693
Epoch 3/10, Batch 90/145, Loss: 0.2483
Epoch 3/10, Batch 100/145, Loss: 0.3126
Epoch 3/10, Batch 110/145, Loss: 0.2880
Epoch 3/10, Batch 120/145, Loss: 0.2079
Epoch 3/10, Batch 130/145, Loss: 0.3194
Epoch 3/10, Batch 140/145, Loss: 0.3740
Epoch 3/10, Train Loss: 0.2963, Valid Loss: 0.2621
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3759
Epoch 4/10, Batch 20/145, Loss: 0.3112
Epoch 4/10, Batch 30/145, Loss: 0.2775
Epoch 4/10, Batch 40/145, Loss: 0.1447
Epoch 4/10, Batch 50/145, Loss: 0.1998
Epoch 4/10, Batch 60/145, Loss: 0.2589
Epoch 4/10, Batch 70/145, Loss: 0.1551
Epoch 4/10, Batch 80/145, Loss: 0.1911
Epoch 4/10, Batch 90/145, Loss: 0.2117
Epoch 4/10, Batch 100/145, Loss: 0.2569
Epoch 4/10, Batch 110/145, Loss: 0.2975
Epoch 4/10, Batch 120/145, Loss: 0.1781
Epoch 4/10, Batch 130/145, Loss: 0.1288
Epoch 4/10, Batch 140/145, Loss: 0.0993
Epoch 4/10, Train Loss: 0.2602, Valid Loss: 0.2419
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1697
Epoch 5/10, Batch 20/145, Loss: 0.2268
Epoch 5/10, Batch 30/145, Loss: 0.3682
Epoch 5/10, Batch 40/145, Loss: 0.0979
Epoch 5/10, Batch 50/145, Loss: 0.2213
Epoch 5/10, Batch 60/145, Loss: 0.1239
Epoch 5/10, Batch 70/145, Loss: 0.1589
Epoch 5/10, Batch 80/145, Loss: 0.1642
Epoch 5/10, Batch 90/145, Loss: 0.2561
Epoch 5/10, Batch 100/145, Loss: 0.3221
Epoch 5/10, Batch 110/145, Loss: 0.1852
Epoch 5/10, Batch 120/145, Loss: 0.3542
Epoch 5/10, Batch 130/145, Loss: 0.1439
Epoch 5/10, Batch 140/145, Loss: 0.1603
Epoch 5/10, Train Loss: 0.2471, Valid Loss: 0.2354
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1976
Epoch 6/10, Batch 20/145, Loss: 0.5255
Epoch 6/10, Batch 30/145, Loss: 0.4301
Epoch 6/10, Batch 40/145, Loss: 0.1736
Epoch 6/10, Batch 50/145, Loss: 0.3957
Epoch 6/10, Batch 60/145, Loss: 0.1879
Epoch 6/10, Batch 70/145, Loss: 0.1201
Epoch 6/10, Batch 80/145, Loss: 0.1394
Epoch 6/10, Batch 90/145, Loss: 0.2841
Epoch 6/10, Batch 100/145, Loss: 0.3043
Epoch 6/10, Batch 110/145, Loss: 0.2297
Epoch 6/10, Batch 120/145, Loss: 0.2306
Epoch 6/10, Batch 130/145, Loss: 0.1884
Epoch 6/10, Batch 140/145, Loss: 0.1615
Epoch 6/10, Train Loss: 0.2282, Valid Loss: 0.2253
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1356
Epoch 7/10, Batch 20/145, Loss: 0.3500
Epoch 7/10, Batch 30/145, Loss: 0.2894
Epoch 7/10, Batch 40/145, Loss: 0.3806
Epoch 7/10, Batch 50/145, Loss: 0.1226
Epoch 7/10, Batch 60/145, Loss: 0.1782
Epoch 7/10, Batch 70/145, Loss: 0.1682
Epoch 7/10, Batch 80/145, Loss: 0.3070
Epoch 7/10, Batch 90/145, Loss: 0.0761
Epoch 7/10, Batch 100/145, Loss: 0.2382
Epoch 7/10, Batch 110/145, Loss: 0.1441
Epoch 7/10, Batch 120/145, Loss: 0.1489
Epoch 7/10, Batch 130/145, Loss: 0.1221
Epoch 7/10, Batch 140/145, Loss: 0.2964
Epoch 7/10, Train Loss: 0.2135, Valid Loss: 0.2247
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1997
Epoch 8/10, Batch 20/145, Loss: 0.2023
Epoch 8/10, Batch 30/145, Loss: 0.2149
Epoch 8/10, Batch 40/145, Loss: 0.2373
Epoch 8/10, Batch 50/145, Loss: 0.3075
Epoch 8/10, Batch 60/145, Loss: 0.2043
Epoch 8/10, Batch 70/145, Loss: 0.2270
Epoch 8/10, Batch 80/145, Loss: 0.1523
Epoch 8/10, Batch 90/145, Loss: 0.2149
Epoch 8/10, Batch 100/145, Loss: 0.2294
Epoch 8/10, Batch 110/145, Loss: 0.3048
Epoch 8/10, Batch 120/145, Loss: 0.1754
Epoch 8/10, Batch 130/145, Loss: 0.2718
Epoch 8/10, Batch 140/145, Loss: 0.2299
Epoch 8/10, Train Loss: 0.2080, Valid Loss: 0.2167
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1656
Epoch 9/10, Batch 20/145, Loss: 0.2081
Epoch 9/10, Batch 30/145, Loss: 0.1446
Epoch 9/10, Batch 40/145, Loss: 0.2746
Epoch 9/10, Batch 50/145, Loss: 0.1576
Epoch 9/10, Batch 60/145, Loss: 0.3807
Epoch 9/10, Batch 70/145, Loss: 0.1839
Epoch 9/10, Batch 80/145, Loss: 0.0880
Epoch 9/10, Batch 90/145, Loss: 0.1485
Epoch 9/10, Batch 100/145, Loss: 0.1136
Epoch 9/10, Batch 110/145, Loss: 0.2776
Epoch 9/10, Batch 120/145, Loss: 0.1463
Epoch 9/10, Batch 130/145, Loss: 0.2062
Epoch 9/10, Batch 140/145, Loss: 0.1498
Epoch 9/10, Train Loss: 0.2010, Valid Loss: 0.2160
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1288
Epoch 10/10, Batch 20/145, Loss: 0.1315
Epoch 10/10, Batch 30/145, Loss: 0.2176
Epoch 10/10, Batch 40/145, Loss: 0.0702
Epoch 10/10, Batch 50/145, Loss: 0.2679
Epoch 10/10, Batch 60/145, Loss: 0.1024
Epoch 10/10, Batch 70/145, Loss: 0.2903
Epoch 10/10, Batch 80/145, Loss: 0.1824
Epoch 10/10, Batch 90/145, Loss: 0.2120
Epoch 10/10, Batch 100/145, Loss: 0.2274
Epoch 10/10, Batch 110/145, Loss: 0.1899
Epoch 10/10, Batch 120/145, Loss: 0.2682
Epoch 10/10, Batch 130/145, Loss: 0.2394
Epoch 10/10, Batch 140/145, Loss: 0.2460
Epoch 10/10, Train Loss: 0.1886, Valid Loss: 0.2147
Model saved!
Accuracy: 0.9136
Precision: 0.9098
Recall: 0.9136
F1-score: 0.9107
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3375
Epoch 1/10, Batch 20/145, Loss: 0.9294
Epoch 1/10, Batch 30/145, Loss: 0.9599
Epoch 1/10, Batch 40/145, Loss: 0.9485
Epoch 1/10, Batch 50/145, Loss: 0.8218
Epoch 1/10, Batch 60/145, Loss: 0.5598
Epoch 1/10, Batch 70/145, Loss: 0.5049
Epoch 1/10, Batch 80/145, Loss: 0.5877
Epoch 1/10, Batch 90/145, Loss: 0.4371
Epoch 1/10, Batch 100/145, Loss: 0.4771
Epoch 1/10, Batch 110/145, Loss: 0.4070
Epoch 1/10, Batch 120/145, Loss: 0.5464
Epoch 1/10, Batch 130/145, Loss: 0.4744
Epoch 1/10, Batch 140/145, Loss: 0.2940
Epoch 1/10, Train Loss: 0.6761, Valid Loss: 0.3818
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2447
Epoch 2/10, Batch 20/145, Loss: 0.3002
Epoch 2/10, Batch 30/145, Loss: 0.2851
Epoch 2/10, Batch 40/145, Loss: 0.5523
Epoch 2/10, Batch 50/145, Loss: 0.2158
Epoch 2/10, Batch 60/145, Loss: 0.4134
Epoch 2/10, Batch 70/145, Loss: 0.3828
Epoch 2/10, Batch 80/145, Loss: 0.3047
Epoch 2/10, Batch 90/145, Loss: 0.2817
Epoch 2/10, Batch 100/145, Loss: 0.2597
Epoch 2/10, Batch 110/145, Loss: 0.4039
Epoch 2/10, Batch 120/145, Loss: 0.2571
Epoch 2/10, Batch 130/145, Loss: 0.3544
Epoch 2/10, Batch 140/145, Loss: 0.4357
Epoch 2/10, Train Loss: 0.3463, Valid Loss: 0.2942
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2106
Epoch 3/10, Batch 20/145, Loss: 0.2605
Epoch 3/10, Batch 30/145, Loss: 0.4538
Epoch 3/10, Batch 40/145, Loss: 0.2538
Epoch 3/10, Batch 50/145, Loss: 0.3268
Epoch 3/10, Batch 60/145, Loss: 0.2703
Epoch 3/10, Batch 70/145, Loss: 0.2675
Epoch 3/10, Batch 80/145, Loss: 0.2713
Epoch 3/10, Batch 90/145, Loss: 0.3146
Epoch 3/10, Batch 100/145, Loss: 0.3172
Epoch 3/10, Batch 110/145, Loss: 0.3621
Epoch 3/10, Batch 120/145, Loss: 0.2907
Epoch 3/10, Batch 130/145, Loss: 0.2705
Epoch 3/10, Batch 140/145, Loss: 0.2966
Epoch 3/10, Train Loss: 0.2882, Valid Loss: 0.2624
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3132
Epoch 4/10, Batch 20/145, Loss: 0.4059
Epoch 4/10, Batch 30/145, Loss: 0.2038
Epoch 4/10, Batch 40/145, Loss: 0.1230
Epoch 4/10, Batch 50/145, Loss: 0.1837
Epoch 4/10, Batch 60/145, Loss: 0.2927
Epoch 4/10, Batch 70/145, Loss: 0.1831
Epoch 4/10, Batch 80/145, Loss: 0.1274
Epoch 4/10, Batch 90/145, Loss: 0.2496
Epoch 4/10, Batch 100/145, Loss: 0.2008
Epoch 4/10, Batch 110/145, Loss: 0.1884
Epoch 4/10, Batch 120/145, Loss: 0.4430
Epoch 4/10, Batch 130/145, Loss: 0.1223
Epoch 4/10, Batch 140/145, Loss: 0.2633
Epoch 4/10, Train Loss: 0.2524, Valid Loss: 0.2488
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1042
Epoch 5/10, Batch 20/145, Loss: 0.0844
Epoch 5/10, Batch 30/145, Loss: 0.1085
Epoch 5/10, Batch 40/145, Loss: 0.1409
Epoch 5/10, Batch 50/145, Loss: 0.2665
Epoch 5/10, Batch 60/145, Loss: 0.1779
Epoch 5/10, Batch 70/145, Loss: 0.1348
Epoch 5/10, Batch 80/145, Loss: 0.2239
Epoch 5/10, Batch 90/145, Loss: 0.2599
Epoch 5/10, Batch 100/145, Loss: 0.3161
Epoch 5/10, Batch 110/145, Loss: 0.1479
Epoch 5/10, Batch 120/145, Loss: 0.2830
Epoch 5/10, Batch 130/145, Loss: 0.1759
Epoch 5/10, Batch 140/145, Loss: 0.1648
Epoch 5/10, Train Loss: 0.2380, Valid Loss: 0.2373
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2488
Epoch 6/10, Batch 20/145, Loss: 0.4551
Epoch 6/10, Batch 30/145, Loss: 0.2355
Epoch 6/10, Batch 40/145, Loss: 0.1004
Epoch 6/10, Batch 50/145, Loss: 0.2148
Epoch 6/10, Batch 60/145, Loss: 0.1475
Epoch 6/10, Batch 70/145, Loss: 0.2199
Epoch 6/10, Batch 80/145, Loss: 0.2509
Epoch 6/10, Batch 90/145, Loss: 0.2451
Epoch 6/10, Batch 100/145, Loss: 0.3511
Epoch 6/10, Batch 110/145, Loss: 0.1767
Epoch 6/10, Batch 120/145, Loss: 0.3561
Epoch 6/10, Batch 130/145, Loss: 0.2279
Epoch 6/10, Batch 140/145, Loss: 0.1692
Epoch 6/10, Train Loss: 0.2204, Valid Loss: 0.2321
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2283
Epoch 7/10, Batch 20/145, Loss: 0.2613
Epoch 7/10, Batch 30/145, Loss: 0.2034
Epoch 7/10, Batch 40/145, Loss: 0.3767
Epoch 7/10, Batch 50/145, Loss: 0.0945
Epoch 7/10, Batch 60/145, Loss: 0.1509
Epoch 7/10, Batch 70/145, Loss: 0.0899
Epoch 7/10, Batch 80/145, Loss: 0.3192
Epoch 7/10, Batch 90/145, Loss: 0.2400
Epoch 7/10, Batch 100/145, Loss: 0.1852
Epoch 7/10, Batch 110/145, Loss: 0.1189
Epoch 7/10, Batch 120/145, Loss: 0.3727
Epoch 7/10, Batch 130/145, Loss: 0.1926
Epoch 7/10, Batch 140/145, Loss: 0.1945
Epoch 7/10, Train Loss: 0.2109, Valid Loss: 0.2318
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1648
Epoch 8/10, Batch 20/145, Loss: 0.2521
Epoch 8/10, Batch 30/145, Loss: 0.2439
Epoch 8/10, Batch 40/145, Loss: 0.2168
Epoch 8/10, Batch 50/145, Loss: 0.3585
Epoch 8/10, Batch 60/145, Loss: 0.2325
Epoch 8/10, Batch 70/145, Loss: 0.2666
Epoch 8/10, Batch 80/145, Loss: 0.1207
Epoch 8/10, Batch 90/145, Loss: 0.3768
Epoch 8/10, Batch 100/145, Loss: 0.1071
Epoch 8/10, Batch 110/145, Loss: 0.2407
Epoch 8/10, Batch 120/145, Loss: 0.1622
Epoch 8/10, Batch 130/145, Loss: 0.1889
Epoch 8/10, Batch 140/145, Loss: 0.2021
Epoch 8/10, Train Loss: 0.2082, Valid Loss: 0.2239
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.4788
Epoch 9/10, Batch 20/145, Loss: 0.2303
Epoch 9/10, Batch 30/145, Loss: 0.1096
Epoch 9/10, Batch 40/145, Loss: 0.2152
Epoch 9/10, Batch 50/145, Loss: 0.1657
Epoch 9/10, Batch 60/145, Loss: 0.2697
Epoch 9/10, Batch 70/145, Loss: 0.1414
Epoch 9/10, Batch 80/145, Loss: 0.0915
Epoch 9/10, Batch 90/145, Loss: 0.3566
Epoch 9/10, Batch 100/145, Loss: 0.3057
Epoch 9/10, Batch 110/145, Loss: 0.1825
Epoch 9/10, Batch 120/145, Loss: 0.1245
Epoch 9/10, Batch 130/145, Loss: 0.1462
Epoch 9/10, Batch 140/145, Loss: 0.4160
Epoch 9/10, Train Loss: 0.1956, Valid Loss: 0.2168
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0857
Epoch 10/10, Batch 20/145, Loss: 0.2658
Epoch 10/10, Batch 30/145, Loss: 0.1402
Epoch 10/10, Batch 40/145, Loss: 0.2930
Epoch 10/10, Batch 50/145, Loss: 0.2278
Epoch 10/10, Batch 60/145, Loss: 0.1145
Epoch 10/10, Batch 70/145, Loss: 0.3398
Epoch 10/10, Batch 80/145, Loss: 0.1963
Epoch 10/10, Batch 90/145, Loss: 0.1871
Epoch 10/10, Batch 100/145, Loss: 0.3964
Epoch 10/10, Batch 110/145, Loss: 0.2060
Epoch 10/10, Batch 120/145, Loss: 0.1413
Epoch 10/10, Batch 130/145, Loss: 0.1114
Epoch 10/10, Batch 140/145, Loss: 0.1483
Epoch 10/10, Train Loss: 0.1913, Valid Loss: 0.2148
Model saved!
Accuracy: 0.9206
Precision: 0.9177
Recall: 0.9206
F1-score: 0.9181
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4055
Epoch 1/10, Batch 20/145, Loss: 0.9422
Epoch 1/10, Batch 30/145, Loss: 0.8652
Epoch 1/10, Batch 40/145, Loss: 0.7468
Epoch 1/10, Batch 50/145, Loss: 0.6223
Epoch 1/10, Batch 60/145, Loss: 0.7283
Epoch 1/10, Batch 70/145, Loss: 0.4939
Epoch 1/10, Batch 80/145, Loss: 0.6429
Epoch 1/10, Batch 90/145, Loss: 0.4989
Epoch 1/10, Batch 100/145, Loss: 0.4823
Epoch 1/10, Batch 110/145, Loss: 0.3554
Epoch 1/10, Batch 120/145, Loss: 0.5341
Epoch 1/10, Batch 130/145, Loss: 0.4764
Epoch 1/10, Batch 140/145, Loss: 0.3134
Epoch 1/10, Train Loss: 0.6770, Valid Loss: 0.3632
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4379
Epoch 2/10, Batch 20/145, Loss: 0.3267
Epoch 2/10, Batch 30/145, Loss: 0.3159
Epoch 2/10, Batch 40/145, Loss: 0.4962
Epoch 2/10, Batch 50/145, Loss: 0.2283
Epoch 2/10, Batch 60/145, Loss: 0.3948
Epoch 2/10, Batch 70/145, Loss: 0.3117
Epoch 2/10, Batch 80/145, Loss: 0.4860
Epoch 2/10, Batch 90/145, Loss: 0.3604
Epoch 2/10, Batch 100/145, Loss: 0.2822
Epoch 2/10, Batch 110/145, Loss: 0.4403
Epoch 2/10, Batch 120/145, Loss: 0.3604
Epoch 2/10, Batch 130/145, Loss: 0.2437
Epoch 2/10, Batch 140/145, Loss: 0.3189
Epoch 2/10, Train Loss: 0.3467, Valid Loss: 0.2849
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3224
Epoch 3/10, Batch 20/145, Loss: 0.2785
Epoch 3/10, Batch 30/145, Loss: 0.1963
Epoch 3/10, Batch 40/145, Loss: 0.2435
Epoch 3/10, Batch 50/145, Loss: 0.1420
Epoch 3/10, Batch 60/145, Loss: 0.3648
Epoch 3/10, Batch 70/145, Loss: 0.3854
Epoch 3/10, Batch 80/145, Loss: 0.2861
Epoch 3/10, Batch 90/145, Loss: 0.3434
Epoch 3/10, Batch 100/145, Loss: 0.1907
Epoch 3/10, Batch 110/145, Loss: 0.2085
Epoch 3/10, Batch 120/145, Loss: 0.2485
Epoch 3/10, Batch 130/145, Loss: 0.3076
Epoch 3/10, Batch 140/145, Loss: 0.2761
Epoch 3/10, Train Loss: 0.2866, Valid Loss: 0.2540
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2894
Epoch 4/10, Batch 20/145, Loss: 0.4139
Epoch 4/10, Batch 30/145, Loss: 0.2831
Epoch 4/10, Batch 40/145, Loss: 0.1520
Epoch 4/10, Batch 50/145, Loss: 0.2086
Epoch 4/10, Batch 60/145, Loss: 0.4087
Epoch 4/10, Batch 70/145, Loss: 0.1877
Epoch 4/10, Batch 80/145, Loss: 0.1493
Epoch 4/10, Batch 90/145, Loss: 0.2059
Epoch 4/10, Batch 100/145, Loss: 0.2261
Epoch 4/10, Batch 110/145, Loss: 0.1469
Epoch 4/10, Batch 120/145, Loss: 0.1916
Epoch 4/10, Batch 130/145, Loss: 0.1474
Epoch 4/10, Batch 140/145, Loss: 0.1570
Epoch 4/10, Train Loss: 0.2499, Valid Loss: 0.2398
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1792
Epoch 5/10, Batch 20/145, Loss: 0.0871
Epoch 5/10, Batch 30/145, Loss: 0.3265
Epoch 5/10, Batch 40/145, Loss: 0.1208
Epoch 5/10, Batch 50/145, Loss: 0.1872
Epoch 5/10, Batch 60/145, Loss: 0.2420
Epoch 5/10, Batch 70/145, Loss: 0.2135
Epoch 5/10, Batch 80/145, Loss: 0.2036
Epoch 5/10, Batch 90/145, Loss: 0.4060
Epoch 5/10, Batch 100/145, Loss: 0.3557
Epoch 5/10, Batch 110/145, Loss: 0.2020
Epoch 5/10, Batch 120/145, Loss: 0.2273
Epoch 5/10, Batch 130/145, Loss: 0.2270
Epoch 5/10, Batch 140/145, Loss: 0.1321
Epoch 5/10, Train Loss: 0.2332, Valid Loss: 0.2305
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1009
Epoch 6/10, Batch 20/145, Loss: 0.3152
Epoch 6/10, Batch 30/145, Loss: 0.3462
Epoch 6/10, Batch 40/145, Loss: 0.3443
Epoch 6/10, Batch 50/145, Loss: 0.2786
Epoch 6/10, Batch 60/145, Loss: 0.1988
Epoch 6/10, Batch 70/145, Loss: 0.1358
Epoch 6/10, Batch 80/145, Loss: 0.1777
Epoch 6/10, Batch 90/145, Loss: 0.2190
Epoch 6/10, Batch 100/145, Loss: 0.1672
Epoch 6/10, Batch 110/145, Loss: 0.2458
Epoch 6/10, Batch 120/145, Loss: 0.1915
Epoch 6/10, Batch 130/145, Loss: 0.1155
Epoch 6/10, Batch 140/145, Loss: 0.1607
Epoch 6/10, Train Loss: 0.2154, Valid Loss: 0.2255
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2976
Epoch 7/10, Batch 20/145, Loss: 0.2368
Epoch 7/10, Batch 30/145, Loss: 0.1703
Epoch 7/10, Batch 40/145, Loss: 0.3013
Epoch 7/10, Batch 50/145, Loss: 0.1935
Epoch 7/10, Batch 60/145, Loss: 0.0987
Epoch 7/10, Batch 70/145, Loss: 0.2111
Epoch 7/10, Batch 80/145, Loss: 0.1212
Epoch 7/10, Batch 90/145, Loss: 0.1124
Epoch 7/10, Batch 100/145, Loss: 0.1207
Epoch 7/10, Batch 110/145, Loss: 0.0859
Epoch 7/10, Batch 120/145, Loss: 0.2564
Epoch 7/10, Batch 130/145, Loss: 0.1053
Epoch 7/10, Batch 140/145, Loss: 0.2091
Epoch 7/10, Train Loss: 0.2100, Valid Loss: 0.2212
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2127
Epoch 8/10, Batch 20/145, Loss: 0.2597
Epoch 8/10, Batch 30/145, Loss: 0.2307
Epoch 8/10, Batch 40/145, Loss: 0.2576
Epoch 8/10, Batch 50/145, Loss: 0.2699
Epoch 8/10, Batch 60/145, Loss: 0.2052
Epoch 8/10, Batch 70/145, Loss: 0.2914
Epoch 8/10, Batch 80/145, Loss: 0.1814
Epoch 8/10, Batch 90/145, Loss: 0.2673
Epoch 8/10, Batch 100/145, Loss: 0.1763
Epoch 8/10, Batch 110/145, Loss: 0.3228
Epoch 8/10, Batch 120/145, Loss: 0.1055
Epoch 8/10, Batch 130/145, Loss: 0.1489
Epoch 8/10, Batch 140/145, Loss: 0.1773
Epoch 8/10, Train Loss: 0.2017, Valid Loss: 0.2192
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2647
Epoch 9/10, Batch 20/145, Loss: 0.1001
Epoch 9/10, Batch 30/145, Loss: 0.1457
Epoch 9/10, Batch 40/145, Loss: 0.1476
Epoch 9/10, Batch 50/145, Loss: 0.1998
Epoch 9/10, Batch 60/145, Loss: 0.5080
Epoch 9/10, Batch 70/145, Loss: 0.1833
Epoch 9/10, Batch 80/145, Loss: 0.1431
Epoch 9/10, Batch 90/145, Loss: 0.4097
Epoch 9/10, Batch 100/145, Loss: 0.1313
Epoch 9/10, Batch 110/145, Loss: 0.1358
Epoch 9/10, Batch 120/145, Loss: 0.0860
Epoch 9/10, Batch 130/145, Loss: 0.1364
Epoch 9/10, Batch 140/145, Loss: 0.1937
Epoch 9/10, Train Loss: 0.1929, Valid Loss: 0.2127
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1365
Epoch 10/10, Batch 20/145, Loss: 0.1250
Epoch 10/10, Batch 30/145, Loss: 0.1926
Epoch 10/10, Batch 40/145, Loss: 0.1113
Epoch 10/10, Batch 50/145, Loss: 0.2519
Epoch 10/10, Batch 60/145, Loss: 0.1500
Epoch 10/10, Batch 70/145, Loss: 0.1659
Epoch 10/10, Batch 80/145, Loss: 0.2267
Epoch 10/10, Batch 90/145, Loss: 0.1498
Epoch 10/10, Batch 100/145, Loss: 0.2489
Epoch 10/10, Batch 110/145, Loss: 0.1540
Epoch 10/10, Batch 120/145, Loss: 0.1202
Epoch 10/10, Batch 130/145, Loss: 0.1025
Epoch 10/10, Batch 140/145, Loss: 0.1217
Epoch 10/10, Train Loss: 0.1832, Valid Loss: 0.2136
Accuracy: 0.9217
Precision: 0.9208
Recall: 0.9217
F1-score: 0.9212
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3847
Epoch 1/10, Batch 20/145, Loss: 0.9453
Epoch 1/10, Batch 30/145, Loss: 0.8773
Epoch 1/10, Batch 40/145, Loss: 0.7330
Epoch 1/10, Batch 50/145, Loss: 0.7119
Epoch 1/10, Batch 60/145, Loss: 0.6473
Epoch 1/10, Batch 70/145, Loss: 0.3604
Epoch 1/10, Batch 80/145, Loss: 0.5017
Epoch 1/10, Batch 90/145, Loss: 0.4702
Epoch 1/10, Batch 100/145, Loss: 0.4426
Epoch 1/10, Batch 110/145, Loss: 0.5898
Epoch 1/10, Batch 120/145, Loss: 0.5407
Epoch 1/10, Batch 130/145, Loss: 0.5413
Epoch 1/10, Batch 140/145, Loss: 0.3767
Epoch 1/10, Train Loss: 0.6800, Valid Loss: 0.3842
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3094
Epoch 2/10, Batch 20/145, Loss: 0.3505
Epoch 2/10, Batch 30/145, Loss: 0.2698
Epoch 2/10, Batch 40/145, Loss: 0.5705
Epoch 2/10, Batch 50/145, Loss: 0.5147
Epoch 2/10, Batch 60/145, Loss: 0.4626
Epoch 2/10, Batch 70/145, Loss: 0.3324
Epoch 2/10, Batch 80/145, Loss: 0.3544
Epoch 2/10, Batch 90/145, Loss: 0.3962
Epoch 2/10, Batch 100/145, Loss: 0.3493
Epoch 2/10, Batch 110/145, Loss: 0.1976
Epoch 2/10, Batch 120/145, Loss: 0.3915
Epoch 2/10, Batch 130/145, Loss: 0.3295
Epoch 2/10, Batch 140/145, Loss: 0.3292
Epoch 2/10, Train Loss: 0.3555, Valid Loss: 0.2998
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2842
Epoch 3/10, Batch 20/145, Loss: 0.2941
Epoch 3/10, Batch 30/145, Loss: 0.3402
Epoch 3/10, Batch 40/145, Loss: 0.2403
Epoch 3/10, Batch 50/145, Loss: 0.1890
Epoch 3/10, Batch 60/145, Loss: 0.3780
Epoch 3/10, Batch 70/145, Loss: 0.2364
Epoch 3/10, Batch 80/145, Loss: 0.2669
Epoch 3/10, Batch 90/145, Loss: 0.1665
Epoch 3/10, Batch 100/145, Loss: 0.2816
Epoch 3/10, Batch 110/145, Loss: 0.2426
Epoch 3/10, Batch 120/145, Loss: 0.3192
Epoch 3/10, Batch 130/145, Loss: 0.3553
Epoch 3/10, Batch 140/145, Loss: 0.2638
Epoch 3/10, Train Loss: 0.2968, Valid Loss: 0.2589
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3955
Epoch 4/10, Batch 20/145, Loss: 0.2336
Epoch 4/10, Batch 30/145, Loss: 0.2380
Epoch 4/10, Batch 40/145, Loss: 0.1866
Epoch 4/10, Batch 50/145, Loss: 0.1072
Epoch 4/10, Batch 60/145, Loss: 0.2598
Epoch 4/10, Batch 70/145, Loss: 0.1222
Epoch 4/10, Batch 80/145, Loss: 0.1497
Epoch 4/10, Batch 90/145, Loss: 0.2055
Epoch 4/10, Batch 100/145, Loss: 0.3006
Epoch 4/10, Batch 110/145, Loss: 0.1471
Epoch 4/10, Batch 120/145, Loss: 0.3109
Epoch 4/10, Batch 130/145, Loss: 0.2412
Epoch 4/10, Batch 140/145, Loss: 0.2497
Epoch 4/10, Train Loss: 0.2602, Valid Loss: 0.2487
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1774
Epoch 5/10, Batch 20/145, Loss: 0.2714
Epoch 5/10, Batch 30/145, Loss: 0.3296
Epoch 5/10, Batch 40/145, Loss: 0.2540
Epoch 5/10, Batch 50/145, Loss: 0.3129
Epoch 5/10, Batch 60/145, Loss: 0.1765
Epoch 5/10, Batch 70/145, Loss: 0.2376
Epoch 5/10, Batch 80/145, Loss: 0.2235
Epoch 5/10, Batch 90/145, Loss: 0.1260
Epoch 5/10, Batch 100/145, Loss: 0.2345
Epoch 5/10, Batch 110/145, Loss: 0.1755
Epoch 5/10, Batch 120/145, Loss: 0.3500
Epoch 5/10, Batch 130/145, Loss: 0.1548
Epoch 5/10, Batch 140/145, Loss: 0.2310
Epoch 5/10, Train Loss: 0.2416, Valid Loss: 0.2309
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1921
Epoch 6/10, Batch 20/145, Loss: 0.4070
Epoch 6/10, Batch 30/145, Loss: 0.4026
Epoch 6/10, Batch 40/145, Loss: 0.2387
Epoch 6/10, Batch 50/145, Loss: 0.3607
Epoch 6/10, Batch 60/145, Loss: 0.1893
Epoch 6/10, Batch 70/145, Loss: 0.2228
Epoch 6/10, Batch 80/145, Loss: 0.2272
Epoch 6/10, Batch 90/145, Loss: 0.3934
Epoch 6/10, Batch 100/145, Loss: 0.5836
Epoch 6/10, Batch 110/145, Loss: 0.1889
Epoch 6/10, Batch 120/145, Loss: 0.4540
Epoch 6/10, Batch 130/145, Loss: 0.1989
Epoch 6/10, Batch 140/145, Loss: 0.2018
Epoch 6/10, Train Loss: 0.2267, Valid Loss: 0.2269
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3308
Epoch 7/10, Batch 20/145, Loss: 0.3051
Epoch 7/10, Batch 30/145, Loss: 0.1822
Epoch 7/10, Batch 40/145, Loss: 0.2004
Epoch 7/10, Batch 50/145, Loss: 0.1654
Epoch 7/10, Batch 60/145, Loss: 0.2615
Epoch 7/10, Batch 70/145, Loss: 0.1498
Epoch 7/10, Batch 80/145, Loss: 0.4033
Epoch 7/10, Batch 90/145, Loss: 0.1541
Epoch 7/10, Batch 100/145, Loss: 0.1845
Epoch 7/10, Batch 110/145, Loss: 0.2647
Epoch 7/10, Batch 120/145, Loss: 0.2380
Epoch 7/10, Batch 130/145, Loss: 0.1502
Epoch 7/10, Batch 140/145, Loss: 0.2073
Epoch 7/10, Train Loss: 0.2190, Valid Loss: 0.2185
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.3952
Epoch 8/10, Batch 20/145, Loss: 0.1490
Epoch 8/10, Batch 30/145, Loss: 0.3470
Epoch 8/10, Batch 40/145, Loss: 0.2768
Epoch 8/10, Batch 50/145, Loss: 0.1998
Epoch 8/10, Batch 60/145, Loss: 0.1711
Epoch 8/10, Batch 70/145, Loss: 0.3731
Epoch 8/10, Batch 80/145, Loss: 0.1830
Epoch 8/10, Batch 90/145, Loss: 0.2047
Epoch 8/10, Batch 100/145, Loss: 0.2110
Epoch 8/10, Batch 110/145, Loss: 0.1923
Epoch 8/10, Batch 120/145, Loss: 0.4309
Epoch 8/10, Batch 130/145, Loss: 0.0975
Epoch 8/10, Batch 140/145, Loss: 0.1466
Epoch 8/10, Train Loss: 0.2153, Valid Loss: 0.2152
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1758
Epoch 9/10, Batch 20/145, Loss: 0.1685
Epoch 9/10, Batch 30/145, Loss: 0.1230
Epoch 9/10, Batch 40/145, Loss: 0.2865
Epoch 9/10, Batch 50/145, Loss: 0.1177
Epoch 9/10, Batch 60/145, Loss: 0.2445
Epoch 9/10, Batch 70/145, Loss: 0.2741
Epoch 9/10, Batch 80/145, Loss: 0.1381
Epoch 9/10, Batch 90/145, Loss: 0.3030
Epoch 9/10, Batch 100/145, Loss: 0.1472
Epoch 9/10, Batch 110/145, Loss: 0.5562
Epoch 9/10, Batch 120/145, Loss: 0.1343
Epoch 9/10, Batch 130/145, Loss: 0.1495
Epoch 9/10, Batch 140/145, Loss: 0.2535
Epoch 9/10, Train Loss: 0.2045, Valid Loss: 0.2144
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2876
Epoch 10/10, Batch 20/145, Loss: 0.1568
Epoch 10/10, Batch 30/145, Loss: 0.1965
Epoch 10/10, Batch 40/145, Loss: 0.1356
Epoch 10/10, Batch 50/145, Loss: 0.2568
Epoch 10/10, Batch 60/145, Loss: 0.0870
Epoch 10/10, Batch 70/145, Loss: 0.1399
Epoch 10/10, Batch 80/145, Loss: 0.2114
Epoch 10/10, Batch 90/145, Loss: 0.0893
Epoch 10/10, Batch 100/145, Loss: 0.3949
Epoch 10/10, Batch 110/145, Loss: 0.1031
Epoch 10/10, Batch 120/145, Loss: 0.2264
Epoch 10/10, Batch 130/145, Loss: 0.2767
Epoch 10/10, Batch 140/145, Loss: 0.1937
Epoch 10/10, Train Loss: 0.1984, Valid Loss: 0.2075
Model saved!
Accuracy: 0.9229
Precision: 0.9216
Recall: 0.9229
F1-score: 0.9220
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4688
Epoch 1/10, Batch 20/145, Loss: 0.9024
Epoch 1/10, Batch 30/145, Loss: 0.8622
Epoch 1/10, Batch 40/145, Loss: 0.7618
Epoch 1/10, Batch 50/145, Loss: 0.6865
Epoch 1/10, Batch 60/145, Loss: 0.5871
Epoch 1/10, Batch 70/145, Loss: 0.4501
Epoch 1/10, Batch 80/145, Loss: 0.5121
Epoch 1/10, Batch 90/145, Loss: 0.4625
Epoch 1/10, Batch 100/145, Loss: 0.6316
Epoch 1/10, Batch 110/145, Loss: 0.5715
Epoch 1/10, Batch 120/145, Loss: 0.6754
Epoch 1/10, Batch 130/145, Loss: 0.7829
Epoch 1/10, Batch 140/145, Loss: 0.3909
Epoch 1/10, Train Loss: 0.6851, Valid Loss: 0.3586
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3259
Epoch 2/10, Batch 20/145, Loss: 0.2925
Epoch 2/10, Batch 30/145, Loss: 0.3423
Epoch 2/10, Batch 40/145, Loss: 0.6124
Epoch 2/10, Batch 50/145, Loss: 0.3211
Epoch 2/10, Batch 60/145, Loss: 0.3605
Epoch 2/10, Batch 70/145, Loss: 0.3045
Epoch 2/10, Batch 80/145, Loss: 0.1898
Epoch 2/10, Batch 90/145, Loss: 0.3502
Epoch 2/10, Batch 100/145, Loss: 0.2476
Epoch 2/10, Batch 110/145, Loss: 0.2120
Epoch 2/10, Batch 120/145, Loss: 0.3990
Epoch 2/10, Batch 130/145, Loss: 0.2293
Epoch 2/10, Batch 140/145, Loss: 0.3108
Epoch 2/10, Train Loss: 0.3554, Valid Loss: 0.2761
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3194
Epoch 3/10, Batch 20/145, Loss: 0.2676
Epoch 3/10, Batch 30/145, Loss: 0.3895
Epoch 3/10, Batch 40/145, Loss: 0.2922
Epoch 3/10, Batch 50/145, Loss: 0.3667
Epoch 3/10, Batch 60/145, Loss: 0.4114
Epoch 3/10, Batch 70/145, Loss: 0.2809
Epoch 3/10, Batch 80/145, Loss: 0.1502
Epoch 3/10, Batch 90/145, Loss: 0.1819
Epoch 3/10, Batch 100/145, Loss: 0.2555
Epoch 3/10, Batch 110/145, Loss: 0.3825
Epoch 3/10, Batch 120/145, Loss: 0.1191
Epoch 3/10, Batch 130/145, Loss: 0.3091
Epoch 3/10, Batch 140/145, Loss: 0.2223
Epoch 3/10, Train Loss: 0.2958, Valid Loss: 0.2433
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4153
Epoch 4/10, Batch 20/145, Loss: 0.2521
Epoch 4/10, Batch 30/145, Loss: 0.3173
Epoch 4/10, Batch 40/145, Loss: 0.3895
Epoch 4/10, Batch 50/145, Loss: 0.1701
Epoch 4/10, Batch 60/145, Loss: 0.2141
Epoch 4/10, Batch 70/145, Loss: 0.1690
Epoch 4/10, Batch 80/145, Loss: 0.1927
Epoch 4/10, Batch 90/145, Loss: 0.2785
Epoch 4/10, Batch 100/145, Loss: 0.4134
Epoch 4/10, Batch 110/145, Loss: 0.2157
Epoch 4/10, Batch 120/145, Loss: 0.1949
Epoch 4/10, Batch 130/145, Loss: 0.1580
Epoch 4/10, Batch 140/145, Loss: 0.1437
Epoch 4/10, Train Loss: 0.2636, Valid Loss: 0.2306
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1306
Epoch 5/10, Batch 20/145, Loss: 0.1565
Epoch 5/10, Batch 30/145, Loss: 0.4175
Epoch 5/10, Batch 40/145, Loss: 0.1369
Epoch 5/10, Batch 50/145, Loss: 0.2575
Epoch 5/10, Batch 60/145, Loss: 0.2272
Epoch 5/10, Batch 70/145, Loss: 0.1584
Epoch 5/10, Batch 80/145, Loss: 0.1678
Epoch 5/10, Batch 90/145, Loss: 0.3048
Epoch 5/10, Batch 100/145, Loss: 0.2274
Epoch 5/10, Batch 110/145, Loss: 0.2328
Epoch 5/10, Batch 120/145, Loss: 0.3433
Epoch 5/10, Batch 130/145, Loss: 0.2721
Epoch 5/10, Batch 140/145, Loss: 0.1502
Epoch 5/10, Train Loss: 0.2489, Valid Loss: 0.2285
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.0916
Epoch 6/10, Batch 20/145, Loss: 0.4035
Epoch 6/10, Batch 30/145, Loss: 0.2633
Epoch 6/10, Batch 40/145, Loss: 0.1995
Epoch 6/10, Batch 50/145, Loss: 0.3813
Epoch 6/10, Batch 60/145, Loss: 0.2469
Epoch 6/10, Batch 70/145, Loss: 0.1493
Epoch 6/10, Batch 80/145, Loss: 0.2648
Epoch 6/10, Batch 90/145, Loss: 0.3006
Epoch 6/10, Batch 100/145, Loss: 0.2422
Epoch 6/10, Batch 110/145, Loss: 0.2953
Epoch 6/10, Batch 120/145, Loss: 0.2546
Epoch 6/10, Batch 130/145, Loss: 0.2144
Epoch 6/10, Batch 140/145, Loss: 0.1763
Epoch 6/10, Train Loss: 0.2274, Valid Loss: 0.2077
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3828
Epoch 7/10, Batch 20/145, Loss: 0.1708
Epoch 7/10, Batch 30/145, Loss: 0.1924
Epoch 7/10, Batch 40/145, Loss: 0.5193
Epoch 7/10, Batch 50/145, Loss: 0.2514
Epoch 7/10, Batch 60/145, Loss: 0.1068
Epoch 7/10, Batch 70/145, Loss: 0.1004
Epoch 7/10, Batch 80/145, Loss: 0.4681
Epoch 7/10, Batch 90/145, Loss: 0.1939
Epoch 7/10, Batch 100/145, Loss: 0.2204
Epoch 7/10, Batch 110/145, Loss: 0.1792
Epoch 7/10, Batch 120/145, Loss: 0.3748
Epoch 7/10, Batch 130/145, Loss: 0.1276
Epoch 7/10, Batch 140/145, Loss: 0.2008
Epoch 7/10, Train Loss: 0.2214, Valid Loss: 0.2023
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2659
Epoch 8/10, Batch 20/145, Loss: 0.2435
Epoch 8/10, Batch 30/145, Loss: 0.2062
Epoch 8/10, Batch 40/145, Loss: 0.1099
Epoch 8/10, Batch 50/145, Loss: 0.3381
Epoch 8/10, Batch 60/145, Loss: 0.1516
Epoch 8/10, Batch 70/145, Loss: 0.1848
Epoch 8/10, Batch 80/145, Loss: 0.2303
Epoch 8/10, Batch 90/145, Loss: 0.3351
Epoch 8/10, Batch 100/145, Loss: 0.2908
Epoch 8/10, Batch 110/145, Loss: 0.1980
Epoch 8/10, Batch 120/145, Loss: 0.3949
Epoch 8/10, Batch 130/145, Loss: 0.2312
Epoch 8/10, Batch 140/145, Loss: 0.1814
Epoch 8/10, Train Loss: 0.2082, Valid Loss: 0.1997
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2506
Epoch 9/10, Batch 20/145, Loss: 0.1902
Epoch 9/10, Batch 30/145, Loss: 0.1160
Epoch 9/10, Batch 40/145, Loss: 0.1386
Epoch 9/10, Batch 50/145, Loss: 0.3599
Epoch 9/10, Batch 60/145, Loss: 0.1389
Epoch 9/10, Batch 70/145, Loss: 0.0776
Epoch 9/10, Batch 80/145, Loss: 0.1951
Epoch 9/10, Batch 90/145, Loss: 0.1704
Epoch 9/10, Batch 100/145, Loss: 0.2165
Epoch 9/10, Batch 110/145, Loss: 0.4254
Epoch 9/10, Batch 120/145, Loss: 0.1925
Epoch 9/10, Batch 130/145, Loss: 0.1460
Epoch 9/10, Batch 140/145, Loss: 0.3139
Epoch 9/10, Train Loss: 0.2062, Valid Loss: 0.2012
Epoch 10/10, Batch 10/145, Loss: 0.1252
Epoch 10/10, Batch 20/145, Loss: 0.1875
Epoch 10/10, Batch 30/145, Loss: 0.0996
Epoch 10/10, Batch 40/145, Loss: 0.2561
Epoch 10/10, Batch 50/145, Loss: 0.2457
Epoch 10/10, Batch 60/145, Loss: 0.1890
Epoch 10/10, Batch 70/145, Loss: 0.3137
Epoch 10/10, Batch 80/145, Loss: 0.3266
Epoch 10/10, Batch 90/145, Loss: 0.1578
Epoch 10/10, Batch 100/145, Loss: 0.2177
Epoch 10/10, Batch 110/145, Loss: 0.0632
Epoch 10/10, Batch 120/145, Loss: 0.2741
Epoch 10/10, Batch 130/145, Loss: 0.1656
Epoch 10/10, Batch 140/145, Loss: 0.3185
Epoch 10/10, Train Loss: 0.1941, Valid Loss: 0.1978
Model saved!
Accuracy: 0.9171
Precision: 0.9144
Recall: 0.9171
F1-score: 0.9140
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3564
Epoch 1/10, Batch 20/145, Loss: 0.9061
Epoch 1/10, Batch 30/145, Loss: 0.9157
Epoch 1/10, Batch 40/145, Loss: 0.8728
Epoch 1/10, Batch 50/145, Loss: 0.6683
Epoch 1/10, Batch 60/145, Loss: 0.6339
Epoch 1/10, Batch 70/145, Loss: 0.4832
Epoch 1/10, Batch 80/145, Loss: 0.5920
Epoch 1/10, Batch 90/145, Loss: 0.4649
Epoch 1/10, Batch 100/145, Loss: 0.3941
Epoch 1/10, Batch 110/145, Loss: 0.3465
Epoch 1/10, Batch 120/145, Loss: 0.5984
Epoch 1/10, Batch 130/145, Loss: 0.5485
Epoch 1/10, Batch 140/145, Loss: 0.4354
Epoch 1/10, Train Loss: 0.6752, Valid Loss: 0.3717
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4506
Epoch 2/10, Batch 20/145, Loss: 0.3371
Epoch 2/10, Batch 30/145, Loss: 0.3185
Epoch 2/10, Batch 40/145, Loss: 0.4348
Epoch 2/10, Batch 50/145, Loss: 0.3478
Epoch 2/10, Batch 60/145, Loss: 0.3443
Epoch 2/10, Batch 70/145, Loss: 0.3687
Epoch 2/10, Batch 80/145, Loss: 0.2778
Epoch 2/10, Batch 90/145, Loss: 0.4062
Epoch 2/10, Batch 100/145, Loss: 0.3479
Epoch 2/10, Batch 110/145, Loss: 0.3837
Epoch 2/10, Batch 120/145, Loss: 0.3024
Epoch 2/10, Batch 130/145, Loss: 0.3006
Epoch 2/10, Batch 140/145, Loss: 0.2700
Epoch 2/10, Train Loss: 0.3495, Valid Loss: 0.2874
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2319
Epoch 3/10, Batch 20/145, Loss: 0.2405
Epoch 3/10, Batch 30/145, Loss: 0.2485
Epoch 3/10, Batch 40/145, Loss: 0.1887
Epoch 3/10, Batch 50/145, Loss: 0.2243
Epoch 3/10, Batch 60/145, Loss: 0.3175
Epoch 3/10, Batch 70/145, Loss: 0.3317
Epoch 3/10, Batch 80/145, Loss: 0.2824
Epoch 3/10, Batch 90/145, Loss: 0.3622
Epoch 3/10, Batch 100/145, Loss: 0.1828
Epoch 3/10, Batch 110/145, Loss: 0.2520
Epoch 3/10, Batch 120/145, Loss: 0.1582
Epoch 3/10, Batch 130/145, Loss: 0.3950
Epoch 3/10, Batch 140/145, Loss: 0.2440
Epoch 3/10, Train Loss: 0.2918, Valid Loss: 0.2585
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3766
Epoch 4/10, Batch 20/145, Loss: 0.3470
Epoch 4/10, Batch 30/145, Loss: 0.3854
Epoch 4/10, Batch 40/145, Loss: 0.1947
Epoch 4/10, Batch 50/145, Loss: 0.2322
Epoch 4/10, Batch 60/145, Loss: 0.2392
Epoch 4/10, Batch 70/145, Loss: 0.1030
Epoch 4/10, Batch 80/145, Loss: 0.1177
Epoch 4/10, Batch 90/145, Loss: 0.2434
Epoch 4/10, Batch 100/145, Loss: 0.3943
Epoch 4/10, Batch 110/145, Loss: 0.1320
Epoch 4/10, Batch 120/145, Loss: 0.2630
Epoch 4/10, Batch 130/145, Loss: 0.1547
Epoch 4/10, Batch 140/145, Loss: 0.1847
Epoch 4/10, Train Loss: 0.2561, Valid Loss: 0.2391
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3006
Epoch 5/10, Batch 20/145, Loss: 0.1838
Epoch 5/10, Batch 30/145, Loss: 0.2780
Epoch 5/10, Batch 40/145, Loss: 0.1648
Epoch 5/10, Batch 50/145, Loss: 0.1158
Epoch 5/10, Batch 60/145, Loss: 0.0911
Epoch 5/10, Batch 70/145, Loss: 0.3942
Epoch 5/10, Batch 80/145, Loss: 0.2271
Epoch 5/10, Batch 90/145, Loss: 0.4544
Epoch 5/10, Batch 100/145, Loss: 0.1301
Epoch 5/10, Batch 110/145, Loss: 0.2159
Epoch 5/10, Batch 120/145, Loss: 0.1551
Epoch 5/10, Batch 130/145, Loss: 0.2506
Epoch 5/10, Batch 140/145, Loss: 0.1602
Epoch 5/10, Train Loss: 0.2415, Valid Loss: 0.2257
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2453
Epoch 6/10, Batch 20/145, Loss: 0.2651
Epoch 6/10, Batch 30/145, Loss: 0.3495
Epoch 6/10, Batch 40/145, Loss: 0.1519
Epoch 6/10, Batch 50/145, Loss: 0.4802
Epoch 6/10, Batch 60/145, Loss: 0.1637
Epoch 6/10, Batch 70/145, Loss: 0.0949
Epoch 6/10, Batch 80/145, Loss: 0.2587
Epoch 6/10, Batch 90/145, Loss: 0.3641
Epoch 6/10, Batch 100/145, Loss: 0.2287
Epoch 6/10, Batch 110/145, Loss: 0.3549
Epoch 6/10, Batch 120/145, Loss: 0.3816
Epoch 6/10, Batch 130/145, Loss: 0.1788
Epoch 6/10, Batch 140/145, Loss: 0.2017
Epoch 6/10, Train Loss: 0.2220, Valid Loss: 0.2196
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2932
Epoch 7/10, Batch 20/145, Loss: 0.2975
Epoch 7/10, Batch 30/145, Loss: 0.3124
Epoch 7/10, Batch 40/145, Loss: 0.2649
Epoch 7/10, Batch 50/145, Loss: 0.2224
Epoch 7/10, Batch 60/145, Loss: 0.1552
Epoch 7/10, Batch 70/145, Loss: 0.2082
Epoch 7/10, Batch 80/145, Loss: 0.3331
Epoch 7/10, Batch 90/145, Loss: 0.1793
Epoch 7/10, Batch 100/145, Loss: 0.1468
Epoch 7/10, Batch 110/145, Loss: 0.2644
Epoch 7/10, Batch 120/145, Loss: 0.2533
Epoch 7/10, Batch 130/145, Loss: 0.0956
Epoch 7/10, Batch 140/145, Loss: 0.3016
Epoch 7/10, Train Loss: 0.2139, Valid Loss: 0.2123
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1544
Epoch 8/10, Batch 20/145, Loss: 0.4044
Epoch 8/10, Batch 30/145, Loss: 0.3313
Epoch 8/10, Batch 40/145, Loss: 0.1382
Epoch 8/10, Batch 50/145, Loss: 0.2323
Epoch 8/10, Batch 60/145, Loss: 0.1090
Epoch 8/10, Batch 70/145, Loss: 0.1821
Epoch 8/10, Batch 80/145, Loss: 0.1314
Epoch 8/10, Batch 90/145, Loss: 0.3790
Epoch 8/10, Batch 100/145, Loss: 0.1705
Epoch 8/10, Batch 110/145, Loss: 0.2346
Epoch 8/10, Batch 120/145, Loss: 0.2702
Epoch 8/10, Batch 130/145, Loss: 0.1875
Epoch 8/10, Batch 140/145, Loss: 0.4050
Epoch 8/10, Train Loss: 0.2028, Valid Loss: 0.2109
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3815
Epoch 9/10, Batch 20/145, Loss: 0.3423
Epoch 9/10, Batch 30/145, Loss: 0.1344
Epoch 9/10, Batch 40/145, Loss: 0.2175
Epoch 9/10, Batch 50/145, Loss: 0.1681
Epoch 9/10, Batch 60/145, Loss: 0.3917
Epoch 9/10, Batch 70/145, Loss: 0.1282
Epoch 9/10, Batch 80/145, Loss: 0.1015
Epoch 9/10, Batch 90/145, Loss: 0.2991
Epoch 9/10, Batch 100/145, Loss: 0.1951
Epoch 9/10, Batch 110/145, Loss: 0.3602
Epoch 9/10, Batch 120/145, Loss: 0.1762
Epoch 9/10, Batch 130/145, Loss: 0.2828
Epoch 9/10, Batch 140/145, Loss: 0.3041
Epoch 9/10, Train Loss: 0.2047, Valid Loss: 0.2059
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0633
Epoch 10/10, Batch 20/145, Loss: 0.2151
Epoch 10/10, Batch 30/145, Loss: 0.1332
Epoch 10/10, Batch 40/145, Loss: 0.1169
Epoch 10/10, Batch 50/145, Loss: 0.1795
Epoch 10/10, Batch 60/145, Loss: 0.1573
Epoch 10/10, Batch 70/145, Loss: 0.2452
Epoch 10/10, Batch 80/145, Loss: 0.0788
Epoch 10/10, Batch 90/145, Loss: 0.0967
Epoch 10/10, Batch 100/145, Loss: 0.1853
Epoch 10/10, Batch 110/145, Loss: 0.3582
Epoch 10/10, Batch 120/145, Loss: 0.3269
Epoch 10/10, Batch 130/145, Loss: 0.0573
Epoch 10/10, Batch 140/145, Loss: 0.2324
Epoch 10/10, Train Loss: 0.1932, Valid Loss: 0.2055
Model saved!
Accuracy: 0.9194
Precision: 0.9170
Recall: 0.9194
F1-score: 0.9177
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4095
Epoch 1/10, Batch 20/145, Loss: 0.9296
Epoch 1/10, Batch 30/145, Loss: 0.8360
Epoch 1/10, Batch 40/145, Loss: 0.7902
Epoch 1/10, Batch 50/145, Loss: 0.6965
Epoch 1/10, Batch 60/145, Loss: 0.5945
Epoch 1/10, Batch 70/145, Loss: 0.4703
Epoch 1/10, Batch 80/145, Loss: 0.6053
Epoch 1/10, Batch 90/145, Loss: 0.4817
Epoch 1/10, Batch 100/145, Loss: 0.4842
Epoch 1/10, Batch 110/145, Loss: 0.5481
Epoch 1/10, Batch 120/145, Loss: 0.5996
Epoch 1/10, Batch 130/145, Loss: 0.4023
Epoch 1/10, Batch 140/145, Loss: 0.3439
Epoch 1/10, Train Loss: 0.6776, Valid Loss: 0.3815
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4149
Epoch 2/10, Batch 20/145, Loss: 0.3530
Epoch 2/10, Batch 30/145, Loss: 0.3167
Epoch 2/10, Batch 40/145, Loss: 0.3768
Epoch 2/10, Batch 50/145, Loss: 0.3521
Epoch 2/10, Batch 60/145, Loss: 0.3882
Epoch 2/10, Batch 70/145, Loss: 0.3581
Epoch 2/10, Batch 80/145, Loss: 0.3932
Epoch 2/10, Batch 90/145, Loss: 0.3194
Epoch 2/10, Batch 100/145, Loss: 0.2414
Epoch 2/10, Batch 110/145, Loss: 0.3807
Epoch 2/10, Batch 120/145, Loss: 0.3372
Epoch 2/10, Batch 130/145, Loss: 0.2834
Epoch 2/10, Batch 140/145, Loss: 0.3162
Epoch 2/10, Train Loss: 0.3511, Valid Loss: 0.3071
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2450
Epoch 3/10, Batch 20/145, Loss: 0.2976
Epoch 3/10, Batch 30/145, Loss: 0.3098
Epoch 3/10, Batch 40/145, Loss: 0.2123
Epoch 3/10, Batch 50/145, Loss: 0.2921
Epoch 3/10, Batch 60/145, Loss: 0.4542
Epoch 3/10, Batch 70/145, Loss: 0.3645
Epoch 3/10, Batch 80/145, Loss: 0.3722
Epoch 3/10, Batch 90/145, Loss: 0.3286
Epoch 3/10, Batch 100/145, Loss: 0.2296
Epoch 3/10, Batch 110/145, Loss: 0.3456
Epoch 3/10, Batch 120/145, Loss: 0.1935
Epoch 3/10, Batch 130/145, Loss: 0.4869
Epoch 3/10, Batch 140/145, Loss: 0.2123
Epoch 3/10, Train Loss: 0.2837, Valid Loss: 0.2734
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3596
Epoch 4/10, Batch 20/145, Loss: 0.3145
Epoch 4/10, Batch 30/145, Loss: 0.1943
Epoch 4/10, Batch 40/145, Loss: 0.1501
Epoch 4/10, Batch 50/145, Loss: 0.1138
Epoch 4/10, Batch 60/145, Loss: 0.2505
Epoch 4/10, Batch 70/145, Loss: 0.1665
Epoch 4/10, Batch 80/145, Loss: 0.1814
Epoch 4/10, Batch 90/145, Loss: 0.3083
Epoch 4/10, Batch 100/145, Loss: 0.3450
Epoch 4/10, Batch 110/145, Loss: 0.2264
Epoch 4/10, Batch 120/145, Loss: 0.2513
Epoch 4/10, Batch 130/145, Loss: 0.2547
Epoch 4/10, Batch 140/145, Loss: 0.1603
Epoch 4/10, Train Loss: 0.2466, Valid Loss: 0.2687
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1730
Epoch 5/10, Batch 20/145, Loss: 0.1206
Epoch 5/10, Batch 30/145, Loss: 0.2723
Epoch 5/10, Batch 40/145, Loss: 0.3179
Epoch 5/10, Batch 50/145, Loss: 0.2899
Epoch 5/10, Batch 60/145, Loss: 0.2112
Epoch 5/10, Batch 70/145, Loss: 0.1805
Epoch 5/10, Batch 80/145, Loss: 0.1984
Epoch 5/10, Batch 90/145, Loss: 0.2128
Epoch 5/10, Batch 100/145, Loss: 0.2640
Epoch 5/10, Batch 110/145, Loss: 0.1831
Epoch 5/10, Batch 120/145, Loss: 0.2054
Epoch 5/10, Batch 130/145, Loss: 0.1749
Epoch 5/10, Batch 140/145, Loss: 0.3654
Epoch 5/10, Train Loss: 0.2424, Valid Loss: 0.2588
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1368
Epoch 6/10, Batch 20/145, Loss: 0.3515
Epoch 6/10, Batch 30/145, Loss: 0.4232
Epoch 6/10, Batch 40/145, Loss: 0.1216
Epoch 6/10, Batch 50/145, Loss: 0.2959
Epoch 6/10, Batch 60/145, Loss: 0.1515
Epoch 6/10, Batch 70/145, Loss: 0.1540
Epoch 6/10, Batch 80/145, Loss: 0.1510
Epoch 6/10, Batch 90/145, Loss: 0.2772
Epoch 6/10, Batch 100/145, Loss: 0.3634
Epoch 6/10, Batch 110/145, Loss: 0.1087
Epoch 6/10, Batch 120/145, Loss: 0.2461
Epoch 6/10, Batch 130/145, Loss: 0.2173
Epoch 6/10, Batch 140/145, Loss: 0.2500
Epoch 6/10, Train Loss: 0.2209, Valid Loss: 0.2484
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2114
Epoch 7/10, Batch 20/145, Loss: 0.3547
Epoch 7/10, Batch 30/145, Loss: 0.2460
Epoch 7/10, Batch 40/145, Loss: 0.3456
Epoch 7/10, Batch 50/145, Loss: 0.3562
Epoch 7/10, Batch 60/145, Loss: 0.0978
Epoch 7/10, Batch 70/145, Loss: 0.1635
Epoch 7/10, Batch 80/145, Loss: 0.2127
Epoch 7/10, Batch 90/145, Loss: 0.1049
Epoch 7/10, Batch 100/145, Loss: 0.2204
Epoch 7/10, Batch 110/145, Loss: 0.1685
Epoch 7/10, Batch 120/145, Loss: 0.2538
Epoch 7/10, Batch 130/145, Loss: 0.0683
Epoch 7/10, Batch 140/145, Loss: 0.2788
Epoch 7/10, Train Loss: 0.2053, Valid Loss: 0.2425
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2604
Epoch 8/10, Batch 20/145, Loss: 0.1547
Epoch 8/10, Batch 30/145, Loss: 0.1543
Epoch 8/10, Batch 40/145, Loss: 0.2684
Epoch 8/10, Batch 50/145, Loss: 0.1335
Epoch 8/10, Batch 60/145, Loss: 0.1630
Epoch 8/10, Batch 70/145, Loss: 0.3146
Epoch 8/10, Batch 80/145, Loss: 0.1473
Epoch 8/10, Batch 90/145, Loss: 0.3096
Epoch 8/10, Batch 100/145, Loss: 0.3163
Epoch 8/10, Batch 110/145, Loss: 0.2968
Epoch 8/10, Batch 120/145, Loss: 0.1313
Epoch 8/10, Batch 130/145, Loss: 0.1637
Epoch 8/10, Batch 140/145, Loss: 0.2818
Epoch 8/10, Train Loss: 0.2001, Valid Loss: 0.2452
Epoch 9/10, Batch 10/145, Loss: 0.2254
Epoch 9/10, Batch 20/145, Loss: 0.0842
Epoch 9/10, Batch 30/145, Loss: 0.1263
Epoch 9/10, Batch 40/145, Loss: 0.3058
Epoch 9/10, Batch 50/145, Loss: 0.1772
Epoch 9/10, Batch 60/145, Loss: 0.2260
Epoch 9/10, Batch 70/145, Loss: 0.1362
Epoch 9/10, Batch 80/145, Loss: 0.1025
Epoch 9/10, Batch 90/145, Loss: 0.2253
Epoch 9/10, Batch 100/145, Loss: 0.2394
Epoch 9/10, Batch 110/145, Loss: 0.1360
Epoch 9/10, Batch 120/145, Loss: 0.0631
Epoch 9/10, Batch 130/145, Loss: 0.2365
Epoch 9/10, Batch 140/145, Loss: 0.2571
Epoch 9/10, Train Loss: 0.1929, Valid Loss: 0.2432
Epoch 10/10, Batch 10/145, Loss: 0.1870
Epoch 10/10, Batch 20/145, Loss: 0.1482
Epoch 10/10, Batch 30/145, Loss: 0.1578
Epoch 10/10, Batch 40/145, Loss: 0.0688
Epoch 10/10, Batch 50/145, Loss: 0.1645
Epoch 10/10, Batch 60/145, Loss: 0.2324
Epoch 10/10, Batch 70/145, Loss: 0.3273
Epoch 10/10, Batch 80/145, Loss: 0.1920
Epoch 10/10, Batch 90/145, Loss: 0.1324
Epoch 10/10, Batch 100/145, Loss: 0.0776
Epoch 10/10, Batch 110/145, Loss: 0.1619
Epoch 10/10, Batch 120/145, Loss: 0.2645
Epoch 10/10, Batch 130/145, Loss: 0.2181
Epoch 10/10, Batch 140/145, Loss: 0.2585
Epoch 10/10, Train Loss: 0.1879, Valid Loss: 0.2431
Accuracy: 0.9159
Precision: 0.9129
Recall: 0.9159
F1-score: 0.9138
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3531
Epoch 1/10, Batch 20/145, Loss: 0.9765
Epoch 1/10, Batch 30/145, Loss: 0.8700
Epoch 1/10, Batch 40/145, Loss: 0.7056
Epoch 1/10, Batch 50/145, Loss: 0.6749
Epoch 1/10, Batch 60/145, Loss: 0.6411
Epoch 1/10, Batch 70/145, Loss: 0.5841
Epoch 1/10, Batch 80/145, Loss: 0.4708
Epoch 1/10, Batch 90/145, Loss: 0.4461
Epoch 1/10, Batch 100/145, Loss: 0.5892
Epoch 1/10, Batch 110/145, Loss: 0.3928
Epoch 1/10, Batch 120/145, Loss: 0.4446
Epoch 1/10, Batch 130/145, Loss: 0.4956
Epoch 1/10, Batch 140/145, Loss: 0.4473
Epoch 1/10, Train Loss: 0.6802, Valid Loss: 0.3561
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3539
Epoch 2/10, Batch 20/145, Loss: 0.4373
Epoch 2/10, Batch 30/145, Loss: 0.3446
Epoch 2/10, Batch 40/145, Loss: 0.5496
Epoch 2/10, Batch 50/145, Loss: 0.3828
Epoch 2/10, Batch 60/145, Loss: 0.2959
Epoch 2/10, Batch 70/145, Loss: 0.2906
Epoch 2/10, Batch 80/145, Loss: 0.2597
Epoch 2/10, Batch 90/145, Loss: 0.4053
Epoch 2/10, Batch 100/145, Loss: 0.3616
Epoch 2/10, Batch 110/145, Loss: 0.2596
Epoch 2/10, Batch 120/145, Loss: 0.3227
Epoch 2/10, Batch 130/145, Loss: 0.2884
Epoch 2/10, Batch 140/145, Loss: 0.3099
Epoch 2/10, Train Loss: 0.3522, Valid Loss: 0.2736
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2391
Epoch 3/10, Batch 20/145, Loss: 0.3706
Epoch 3/10, Batch 30/145, Loss: 0.4325
Epoch 3/10, Batch 40/145, Loss: 0.2385
Epoch 3/10, Batch 50/145, Loss: 0.2621
Epoch 3/10, Batch 60/145, Loss: 0.4101
Epoch 3/10, Batch 70/145, Loss: 0.4126
Epoch 3/10, Batch 80/145, Loss: 0.2214
Epoch 3/10, Batch 90/145, Loss: 0.3437
Epoch 3/10, Batch 100/145, Loss: 0.3087
Epoch 3/10, Batch 110/145, Loss: 0.3234
Epoch 3/10, Batch 120/145, Loss: 0.1613
Epoch 3/10, Batch 130/145, Loss: 0.4284
Epoch 3/10, Batch 140/145, Loss: 0.2288
Epoch 3/10, Train Loss: 0.2997, Valid Loss: 0.2493
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3093
Epoch 4/10, Batch 20/145, Loss: 0.4080
Epoch 4/10, Batch 30/145, Loss: 0.2725
Epoch 4/10, Batch 40/145, Loss: 0.1159
Epoch 4/10, Batch 50/145, Loss: 0.1941
Epoch 4/10, Batch 60/145, Loss: 0.3088
Epoch 4/10, Batch 70/145, Loss: 0.2288
Epoch 4/10, Batch 80/145, Loss: 0.1232
Epoch 4/10, Batch 90/145, Loss: 0.2551
Epoch 4/10, Batch 100/145, Loss: 0.2158
Epoch 4/10, Batch 110/145, Loss: 0.2112
Epoch 4/10, Batch 120/145, Loss: 0.3038
Epoch 4/10, Batch 130/145, Loss: 0.2966
Epoch 4/10, Batch 140/145, Loss: 0.1376
Epoch 4/10, Train Loss: 0.2585, Valid Loss: 0.2334
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1772
Epoch 5/10, Batch 20/145, Loss: 0.2082
Epoch 5/10, Batch 30/145, Loss: 0.2662
Epoch 5/10, Batch 40/145, Loss: 0.2134
Epoch 5/10, Batch 50/145, Loss: 0.1865
Epoch 5/10, Batch 60/145, Loss: 0.3434
Epoch 5/10, Batch 70/145, Loss: 0.1745
Epoch 5/10, Batch 80/145, Loss: 0.1625
Epoch 5/10, Batch 90/145, Loss: 0.2136
Epoch 5/10, Batch 100/145, Loss: 0.1087
Epoch 5/10, Batch 110/145, Loss: 0.2338
Epoch 5/10, Batch 120/145, Loss: 0.2789
Epoch 5/10, Batch 130/145, Loss: 0.3259
Epoch 5/10, Batch 140/145, Loss: 0.1590
Epoch 5/10, Train Loss: 0.2479, Valid Loss: 0.2185
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2039
Epoch 6/10, Batch 20/145, Loss: 0.2886
Epoch 6/10, Batch 30/145, Loss: 0.2099
Epoch 6/10, Batch 40/145, Loss: 0.1484
Epoch 6/10, Batch 50/145, Loss: 0.3615
Epoch 6/10, Batch 60/145, Loss: 0.4467
Epoch 6/10, Batch 70/145, Loss: 0.1162
Epoch 6/10, Batch 80/145, Loss: 0.2270
Epoch 6/10, Batch 90/145, Loss: 0.2547
Epoch 6/10, Batch 100/145, Loss: 0.2752
Epoch 6/10, Batch 110/145, Loss: 0.2966
Epoch 6/10, Batch 120/145, Loss: 0.1889
Epoch 6/10, Batch 130/145, Loss: 0.2487
Epoch 6/10, Batch 140/145, Loss: 0.2339
Epoch 6/10, Train Loss: 0.2355, Valid Loss: 0.2057
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1817
Epoch 7/10, Batch 20/145, Loss: 0.2494
Epoch 7/10, Batch 30/145, Loss: 0.3564
Epoch 7/10, Batch 40/145, Loss: 0.2656
Epoch 7/10, Batch 50/145, Loss: 0.3904
Epoch 7/10, Batch 60/145, Loss: 0.2032
Epoch 7/10, Batch 70/145, Loss: 0.1128
Epoch 7/10, Batch 80/145, Loss: 0.4273
Epoch 7/10, Batch 90/145, Loss: 0.1512
Epoch 7/10, Batch 100/145, Loss: 0.0911
Epoch 7/10, Batch 110/145, Loss: 0.2003
Epoch 7/10, Batch 120/145, Loss: 0.1450
Epoch 7/10, Batch 130/145, Loss: 0.1602
Epoch 7/10, Batch 140/145, Loss: 0.3173
Epoch 7/10, Train Loss: 0.2172, Valid Loss: 0.2018
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2739
Epoch 8/10, Batch 20/145, Loss: 0.2811
Epoch 8/10, Batch 30/145, Loss: 0.2641
Epoch 8/10, Batch 40/145, Loss: 0.2000
Epoch 8/10, Batch 50/145, Loss: 0.2030
Epoch 8/10, Batch 60/145, Loss: 0.1909
Epoch 8/10, Batch 70/145, Loss: 0.4027
Epoch 8/10, Batch 80/145, Loss: 0.2174
Epoch 8/10, Batch 90/145, Loss: 0.2870
Epoch 8/10, Batch 100/145, Loss: 0.1291
Epoch 8/10, Batch 110/145, Loss: 0.1741
Epoch 8/10, Batch 120/145, Loss: 0.1894
Epoch 8/10, Batch 130/145, Loss: 0.2345
Epoch 8/10, Batch 140/145, Loss: 0.1680
Epoch 8/10, Train Loss: 0.2112, Valid Loss: 0.1980
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3648
Epoch 9/10, Batch 20/145, Loss: 0.2477
Epoch 9/10, Batch 30/145, Loss: 0.1373
Epoch 9/10, Batch 40/145, Loss: 0.2758
Epoch 9/10, Batch 50/145, Loss: 0.1452
Epoch 9/10, Batch 60/145, Loss: 0.3148
Epoch 9/10, Batch 70/145, Loss: 0.1098
Epoch 9/10, Batch 80/145, Loss: 0.1516
Epoch 9/10, Batch 90/145, Loss: 0.0998
Epoch 9/10, Batch 100/145, Loss: 0.1405
Epoch 9/10, Batch 110/145, Loss: 0.2434
Epoch 9/10, Batch 120/145, Loss: 0.1012
Epoch 9/10, Batch 130/145, Loss: 0.1455
Epoch 9/10, Batch 140/145, Loss: 0.1329
Epoch 9/10, Train Loss: 0.2036, Valid Loss: 0.1907
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1248
Epoch 10/10, Batch 20/145, Loss: 0.1672
Epoch 10/10, Batch 30/145, Loss: 0.0844
Epoch 10/10, Batch 40/145, Loss: 0.0958
Epoch 10/10, Batch 50/145, Loss: 0.2728
Epoch 10/10, Batch 60/145, Loss: 0.1448
Epoch 10/10, Batch 70/145, Loss: 0.4514
Epoch 10/10, Batch 80/145, Loss: 0.1690
Epoch 10/10, Batch 90/145, Loss: 0.3733
Epoch 10/10, Batch 100/145, Loss: 0.2010
Epoch 10/10, Batch 110/145, Loss: 0.1115
Epoch 10/10, Batch 120/145, Loss: 0.4617
Epoch 10/10, Batch 130/145, Loss: 0.1697
Epoch 10/10, Batch 140/145, Loss: 0.2228
Epoch 10/10, Train Loss: 0.1922, Valid Loss: 0.1918
Accuracy: 0.9206
Precision: 0.9191
Recall: 0.9206
F1-score: 0.9196
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3652
Epoch 1/10, Batch 20/145, Loss: 0.9109
Epoch 1/10, Batch 30/145, Loss: 0.8636
Epoch 1/10, Batch 40/145, Loss: 0.7659
Epoch 1/10, Batch 50/145, Loss: 0.8528
Epoch 1/10, Batch 60/145, Loss: 0.5069
Epoch 1/10, Batch 70/145, Loss: 0.4547
Epoch 1/10, Batch 80/145, Loss: 0.5093
Epoch 1/10, Batch 90/145, Loss: 0.4011
Epoch 1/10, Batch 100/145, Loss: 0.4013
Epoch 1/10, Batch 110/145, Loss: 0.3831
Epoch 1/10, Batch 120/145, Loss: 0.3971
Epoch 1/10, Batch 130/145, Loss: 0.5959
Epoch 1/10, Batch 140/145, Loss: 0.3955
Epoch 1/10, Train Loss: 0.6744, Valid Loss: 0.3635
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2418
Epoch 2/10, Batch 20/145, Loss: 0.3807
Epoch 2/10, Batch 30/145, Loss: 0.2802
Epoch 2/10, Batch 40/145, Loss: 0.3244
Epoch 2/10, Batch 50/145, Loss: 0.2715
Epoch 2/10, Batch 60/145, Loss: 0.5461
Epoch 2/10, Batch 70/145, Loss: 0.3463
Epoch 2/10, Batch 80/145, Loss: 0.3373
Epoch 2/10, Batch 90/145, Loss: 0.2200
Epoch 2/10, Batch 100/145, Loss: 0.3699
Epoch 2/10, Batch 110/145, Loss: 0.2838
Epoch 2/10, Batch 120/145, Loss: 0.4506
Epoch 2/10, Batch 130/145, Loss: 0.2770
Epoch 2/10, Batch 140/145, Loss: 0.2556
Epoch 2/10, Train Loss: 0.3529, Valid Loss: 0.2866
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3380
Epoch 3/10, Batch 20/145, Loss: 0.2291
Epoch 3/10, Batch 30/145, Loss: 0.2827
Epoch 3/10, Batch 40/145, Loss: 0.2889
Epoch 3/10, Batch 50/145, Loss: 0.3322
Epoch 3/10, Batch 60/145, Loss: 0.2205
Epoch 3/10, Batch 70/145, Loss: 0.2961
Epoch 3/10, Batch 80/145, Loss: 0.3877
Epoch 3/10, Batch 90/145, Loss: 0.3878
Epoch 3/10, Batch 100/145, Loss: 0.1904
Epoch 3/10, Batch 110/145, Loss: 0.2765
Epoch 3/10, Batch 120/145, Loss: 0.2760
Epoch 3/10, Batch 130/145, Loss: 0.3899
Epoch 3/10, Batch 140/145, Loss: 0.3570
Epoch 3/10, Train Loss: 0.2938, Valid Loss: 0.2534
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4108
Epoch 4/10, Batch 20/145, Loss: 0.5265
Epoch 4/10, Batch 30/145, Loss: 0.3317
Epoch 4/10, Batch 40/145, Loss: 0.1626
Epoch 4/10, Batch 50/145, Loss: 0.1614
Epoch 4/10, Batch 60/145, Loss: 0.2218
Epoch 4/10, Batch 70/145, Loss: 0.2938
Epoch 4/10, Batch 80/145, Loss: 0.1903
Epoch 4/10, Batch 90/145, Loss: 0.2314
Epoch 4/10, Batch 100/145, Loss: 0.3763
Epoch 4/10, Batch 110/145, Loss: 0.1304
Epoch 4/10, Batch 120/145, Loss: 0.3584
Epoch 4/10, Batch 130/145, Loss: 0.2984
Epoch 4/10, Batch 140/145, Loss: 0.1104
Epoch 4/10, Train Loss: 0.2563, Valid Loss: 0.2389
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2226
Epoch 5/10, Batch 20/145, Loss: 0.1721
Epoch 5/10, Batch 30/145, Loss: 0.1941
Epoch 5/10, Batch 40/145, Loss: 0.1287
Epoch 5/10, Batch 50/145, Loss: 0.2870
Epoch 5/10, Batch 60/145, Loss: 0.3070
Epoch 5/10, Batch 70/145, Loss: 0.2735
Epoch 5/10, Batch 80/145, Loss: 0.1912
Epoch 5/10, Batch 90/145, Loss: 0.4679
Epoch 5/10, Batch 100/145, Loss: 0.0984
Epoch 5/10, Batch 110/145, Loss: 0.1243
Epoch 5/10, Batch 120/145, Loss: 0.3072
Epoch 5/10, Batch 130/145, Loss: 0.1025
Epoch 5/10, Batch 140/145, Loss: 0.3569
Epoch 5/10, Train Loss: 0.2519, Valid Loss: 0.2328
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1592
Epoch 6/10, Batch 20/145, Loss: 0.3807
Epoch 6/10, Batch 30/145, Loss: 0.3141
Epoch 6/10, Batch 40/145, Loss: 0.1283
Epoch 6/10, Batch 50/145, Loss: 0.2339
Epoch 6/10, Batch 60/145, Loss: 0.1602
Epoch 6/10, Batch 70/145, Loss: 0.1340
Epoch 6/10, Batch 80/145, Loss: 0.1521
Epoch 6/10, Batch 90/145, Loss: 0.1529
Epoch 6/10, Batch 100/145, Loss: 0.4417
Epoch 6/10, Batch 110/145, Loss: 0.2407
Epoch 6/10, Batch 120/145, Loss: 0.1685
Epoch 6/10, Batch 130/145, Loss: 0.1570
Epoch 6/10, Batch 140/145, Loss: 0.1050
Epoch 6/10, Train Loss: 0.2357, Valid Loss: 0.2253
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2847
Epoch 7/10, Batch 20/145, Loss: 0.3101
Epoch 7/10, Batch 30/145, Loss: 0.2574
Epoch 7/10, Batch 40/145, Loss: 0.2963
Epoch 7/10, Batch 50/145, Loss: 0.2209
Epoch 7/10, Batch 60/145, Loss: 0.2125
Epoch 7/10, Batch 70/145, Loss: 0.2147
Epoch 7/10, Batch 80/145, Loss: 0.3431
Epoch 7/10, Batch 90/145, Loss: 0.2649
Epoch 7/10, Batch 100/145, Loss: 0.2368
Epoch 7/10, Batch 110/145, Loss: 0.1327
Epoch 7/10, Batch 120/145, Loss: 0.2459
Epoch 7/10, Batch 130/145, Loss: 0.1476
Epoch 7/10, Batch 140/145, Loss: 0.2505
Epoch 7/10, Train Loss: 0.2128, Valid Loss: 0.2218
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.3093
Epoch 8/10, Batch 20/145, Loss: 0.2190
Epoch 8/10, Batch 30/145, Loss: 0.2579
Epoch 8/10, Batch 40/145, Loss: 0.1833
Epoch 8/10, Batch 50/145, Loss: 0.1786
Epoch 8/10, Batch 60/145, Loss: 0.1164
Epoch 8/10, Batch 70/145, Loss: 0.2664
Epoch 8/10, Batch 80/145, Loss: 0.2607
Epoch 8/10, Batch 90/145, Loss: 0.3163
Epoch 8/10, Batch 100/145, Loss: 0.1959
Epoch 8/10, Batch 110/145, Loss: 0.3423
Epoch 8/10, Batch 120/145, Loss: 0.1356
Epoch 8/10, Batch 130/145, Loss: 0.1509
Epoch 8/10, Batch 140/145, Loss: 0.2210
Epoch 8/10, Train Loss: 0.2091, Valid Loss: 0.2154
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2674
Epoch 9/10, Batch 20/145, Loss: 0.3125
Epoch 9/10, Batch 30/145, Loss: 0.1367
Epoch 9/10, Batch 40/145, Loss: 0.5493
Epoch 9/10, Batch 50/145, Loss: 0.1751
Epoch 9/10, Batch 60/145, Loss: 0.4133
Epoch 9/10, Batch 70/145, Loss: 0.1652
Epoch 9/10, Batch 80/145, Loss: 0.1334
Epoch 9/10, Batch 90/145, Loss: 0.1912
Epoch 9/10, Batch 100/145, Loss: 0.0767
Epoch 9/10, Batch 110/145, Loss: 0.3617
Epoch 9/10, Batch 120/145, Loss: 0.1039
Epoch 9/10, Batch 130/145, Loss: 0.1351
Epoch 9/10, Batch 140/145, Loss: 0.1411
Epoch 9/10, Train Loss: 0.2072, Valid Loss: 0.2141
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0966
Epoch 10/10, Batch 20/145, Loss: 0.2004
Epoch 10/10, Batch 30/145, Loss: 0.0780
Epoch 10/10, Batch 40/145, Loss: 0.1863
Epoch 10/10, Batch 50/145, Loss: 0.1813
Epoch 10/10, Batch 60/145, Loss: 0.0668
Epoch 10/10, Batch 70/145, Loss: 0.2088
Epoch 10/10, Batch 80/145, Loss: 0.1431
Epoch 10/10, Batch 90/145, Loss: 0.2050
Epoch 10/10, Batch 100/145, Loss: 0.2383
Epoch 10/10, Batch 110/145, Loss: 0.2507
Epoch 10/10, Batch 120/145, Loss: 0.2137
Epoch 10/10, Batch 130/145, Loss: 0.1224
Epoch 10/10, Batch 140/145, Loss: 0.1904
Epoch 10/10, Train Loss: 0.1902, Valid Loss: 0.2102
Model saved!
Accuracy: 0.9171
Precision: 0.9136
Recall: 0.9171
F1-score: 0.9146
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3760
Epoch 1/10, Batch 20/145, Loss: 0.9222
Epoch 1/10, Batch 30/145, Loss: 0.8785
Epoch 1/10, Batch 40/145, Loss: 0.8395
Epoch 1/10, Batch 50/145, Loss: 0.7742
Epoch 1/10, Batch 60/145, Loss: 0.5782
Epoch 1/10, Batch 70/145, Loss: 0.4757
Epoch 1/10, Batch 80/145, Loss: 0.5671
Epoch 1/10, Batch 90/145, Loss: 0.4045
Epoch 1/10, Batch 100/145, Loss: 0.3955
Epoch 1/10, Batch 110/145, Loss: 0.5790
Epoch 1/10, Batch 120/145, Loss: 0.5445
Epoch 1/10, Batch 130/145, Loss: 0.5577
Epoch 1/10, Batch 140/145, Loss: 0.3875
Epoch 1/10, Train Loss: 0.6734, Valid Loss: 0.3780
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.5221
Epoch 2/10, Batch 20/145, Loss: 0.4080
Epoch 2/10, Batch 30/145, Loss: 0.2591
Epoch 2/10, Batch 40/145, Loss: 0.3718
Epoch 2/10, Batch 50/145, Loss: 0.2777
Epoch 2/10, Batch 60/145, Loss: 0.4216
Epoch 2/10, Batch 70/145, Loss: 0.4383
Epoch 2/10, Batch 80/145, Loss: 0.1912
Epoch 2/10, Batch 90/145, Loss: 0.4862
Epoch 2/10, Batch 100/145, Loss: 0.2547
Epoch 2/10, Batch 110/145, Loss: 0.3439
Epoch 2/10, Batch 120/145, Loss: 0.5432
Epoch 2/10, Batch 130/145, Loss: 0.2756
Epoch 2/10, Batch 140/145, Loss: 0.2303
Epoch 2/10, Train Loss: 0.3500, Valid Loss: 0.3008
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2125
Epoch 3/10, Batch 20/145, Loss: 0.2489
Epoch 3/10, Batch 30/145, Loss: 0.4081
Epoch 3/10, Batch 40/145, Loss: 0.3086
Epoch 3/10, Batch 50/145, Loss: 0.3265
Epoch 3/10, Batch 60/145, Loss: 0.3077
Epoch 3/10, Batch 70/145, Loss: 0.3186
Epoch 3/10, Batch 80/145, Loss: 0.3122
Epoch 3/10, Batch 90/145, Loss: 0.2173
Epoch 3/10, Batch 100/145, Loss: 0.3369
Epoch 3/10, Batch 110/145, Loss: 0.2312
Epoch 3/10, Batch 120/145, Loss: 0.2799
Epoch 3/10, Batch 130/145, Loss: 0.3306
Epoch 3/10, Batch 140/145, Loss: 0.2677
Epoch 3/10, Train Loss: 0.2894, Valid Loss: 0.2689
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4107
Epoch 4/10, Batch 20/145, Loss: 0.3080
Epoch 4/10, Batch 30/145, Loss: 0.2647
Epoch 4/10, Batch 40/145, Loss: 0.1031
Epoch 4/10, Batch 50/145, Loss: 0.2209
Epoch 4/10, Batch 60/145, Loss: 0.2788
Epoch 4/10, Batch 70/145, Loss: 0.2077
Epoch 4/10, Batch 80/145, Loss: 0.2012
Epoch 4/10, Batch 90/145, Loss: 0.2904
Epoch 4/10, Batch 100/145, Loss: 0.3015
Epoch 4/10, Batch 110/145, Loss: 0.1687
Epoch 4/10, Batch 120/145, Loss: 0.2521
Epoch 4/10, Batch 130/145, Loss: 0.0907
Epoch 4/10, Batch 140/145, Loss: 0.0788
Epoch 4/10, Train Loss: 0.2594, Valid Loss: 0.2552
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1202
Epoch 5/10, Batch 20/145, Loss: 0.1081
Epoch 5/10, Batch 30/145, Loss: 0.3612
Epoch 5/10, Batch 40/145, Loss: 0.1563
Epoch 5/10, Batch 50/145, Loss: 0.3319
Epoch 5/10, Batch 60/145, Loss: 0.2249
Epoch 5/10, Batch 70/145, Loss: 0.2950
Epoch 5/10, Batch 80/145, Loss: 0.1508
Epoch 5/10, Batch 90/145, Loss: 0.4902
Epoch 5/10, Batch 100/145, Loss: 0.1934
Epoch 5/10, Batch 110/145, Loss: 0.1315
Epoch 5/10, Batch 120/145, Loss: 0.4605
Epoch 5/10, Batch 130/145, Loss: 0.1003
Epoch 5/10, Batch 140/145, Loss: 0.3357
Epoch 5/10, Train Loss: 0.2415, Valid Loss: 0.2497
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1655
Epoch 6/10, Batch 20/145, Loss: 0.3479
Epoch 6/10, Batch 30/145, Loss: 0.2649
Epoch 6/10, Batch 40/145, Loss: 0.2656
Epoch 6/10, Batch 50/145, Loss: 0.2994
Epoch 6/10, Batch 60/145, Loss: 0.1806
Epoch 6/10, Batch 70/145, Loss: 0.1161
Epoch 6/10, Batch 80/145, Loss: 0.1217
Epoch 6/10, Batch 90/145, Loss: 0.3666
Epoch 6/10, Batch 100/145, Loss: 0.1673
Epoch 6/10, Batch 110/145, Loss: 0.1624
Epoch 6/10, Batch 120/145, Loss: 0.3786
Epoch 6/10, Batch 130/145, Loss: 0.2263
Epoch 6/10, Batch 140/145, Loss: 0.3291
Epoch 6/10, Train Loss: 0.2277, Valid Loss: 0.2330
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2382
Epoch 7/10, Batch 20/145, Loss: 0.2845
Epoch 7/10, Batch 30/145, Loss: 0.1805
Epoch 7/10, Batch 40/145, Loss: 0.3528
Epoch 7/10, Batch 50/145, Loss: 0.1477
Epoch 7/10, Batch 60/145, Loss: 0.1582
Epoch 7/10, Batch 70/145, Loss: 0.1005
Epoch 7/10, Batch 80/145, Loss: 0.2984
Epoch 7/10, Batch 90/145, Loss: 0.1622
Epoch 7/10, Batch 100/145, Loss: 0.1411
Epoch 7/10, Batch 110/145, Loss: 0.1823
Epoch 7/10, Batch 120/145, Loss: 0.2399
Epoch 7/10, Batch 130/145, Loss: 0.1295
Epoch 7/10, Batch 140/145, Loss: 0.4757
Epoch 7/10, Train Loss: 0.2118, Valid Loss: 0.2323
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1672
Epoch 8/10, Batch 20/145, Loss: 0.1744
Epoch 8/10, Batch 30/145, Loss: 0.1741
Epoch 8/10, Batch 40/145, Loss: 0.1141
Epoch 8/10, Batch 50/145, Loss: 0.2995
Epoch 8/10, Batch 60/145, Loss: 0.2721
Epoch 8/10, Batch 70/145, Loss: 0.2381
Epoch 8/10, Batch 80/145, Loss: 0.2091
Epoch 8/10, Batch 90/145, Loss: 0.3549
Epoch 8/10, Batch 100/145, Loss: 0.3047
Epoch 8/10, Batch 110/145, Loss: 0.1862
Epoch 8/10, Batch 120/145, Loss: 0.1066
Epoch 8/10, Batch 130/145, Loss: 0.1982
Epoch 8/10, Batch 140/145, Loss: 0.2745
Epoch 8/10, Train Loss: 0.2059, Valid Loss: 0.2264
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.4385
Epoch 9/10, Batch 20/145, Loss: 0.2545
Epoch 9/10, Batch 30/145, Loss: 0.1678
Epoch 9/10, Batch 40/145, Loss: 0.3589
Epoch 9/10, Batch 50/145, Loss: 0.0889
Epoch 9/10, Batch 60/145, Loss: 0.1794
Epoch 9/10, Batch 70/145, Loss: 0.1793
Epoch 9/10, Batch 80/145, Loss: 0.1488
Epoch 9/10, Batch 90/145, Loss: 0.2817
Epoch 9/10, Batch 100/145, Loss: 0.2290
Epoch 9/10, Batch 110/145, Loss: 0.2006
Epoch 9/10, Batch 120/145, Loss: 0.2703
Epoch 9/10, Batch 130/145, Loss: 0.1784
Epoch 9/10, Batch 140/145, Loss: 0.1241
Epoch 9/10, Train Loss: 0.2026, Valid Loss: 0.2203
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2087
Epoch 10/10, Batch 20/145, Loss: 0.1829
Epoch 10/10, Batch 30/145, Loss: 0.1219
Epoch 10/10, Batch 40/145, Loss: 0.1713
Epoch 10/10, Batch 50/145, Loss: 0.4382
Epoch 10/10, Batch 60/145, Loss: 0.2414
Epoch 10/10, Batch 70/145, Loss: 0.2129
Epoch 10/10, Batch 80/145, Loss: 0.1309
Epoch 10/10, Batch 90/145, Loss: 0.1587
Epoch 10/10, Batch 100/145, Loss: 0.2608
Epoch 10/10, Batch 110/145, Loss: 0.2283
Epoch 10/10, Batch 120/145, Loss: 0.1858
Epoch 10/10, Batch 130/145, Loss: 0.2080
Epoch 10/10, Batch 140/145, Loss: 0.2289
Epoch 10/10, Train Loss: 0.1971, Valid Loss: 0.2208
Accuracy: 0.9159
Precision: 0.9134
Recall: 0.9159
F1-score: 0.9141
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3601
Epoch 1/10, Batch 20/145, Loss: 0.9261
Epoch 1/10, Batch 30/145, Loss: 0.9634
Epoch 1/10, Batch 40/145, Loss: 0.7892
Epoch 1/10, Batch 50/145, Loss: 0.7979
Epoch 1/10, Batch 60/145, Loss: 0.6427
Epoch 1/10, Batch 70/145, Loss: 0.4181
Epoch 1/10, Batch 80/145, Loss: 0.5482
Epoch 1/10, Batch 90/145, Loss: 0.4847
Epoch 1/10, Batch 100/145, Loss: 0.4692
Epoch 1/10, Batch 110/145, Loss: 0.5579
Epoch 1/10, Batch 120/145, Loss: 0.5263
Epoch 1/10, Batch 130/145, Loss: 0.6131
Epoch 1/10, Batch 140/145, Loss: 0.4091
Epoch 1/10, Train Loss: 0.6797, Valid Loss: 0.3890
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3576
Epoch 2/10, Batch 20/145, Loss: 0.3097
Epoch 2/10, Batch 30/145, Loss: 0.3256
Epoch 2/10, Batch 40/145, Loss: 0.4218
Epoch 2/10, Batch 50/145, Loss: 0.4293
Epoch 2/10, Batch 60/145, Loss: 0.3536
Epoch 2/10, Batch 70/145, Loss: 0.3919
Epoch 2/10, Batch 80/145, Loss: 0.2267
Epoch 2/10, Batch 90/145, Loss: 0.2871
Epoch 2/10, Batch 100/145, Loss: 0.2728
Epoch 2/10, Batch 110/145, Loss: 0.2805
Epoch 2/10, Batch 120/145, Loss: 0.3102
Epoch 2/10, Batch 130/145, Loss: 0.3325
Epoch 2/10, Batch 140/145, Loss: 0.2388
Epoch 2/10, Train Loss: 0.3561, Valid Loss: 0.3099
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3492
Epoch 3/10, Batch 20/145, Loss: 0.3206
Epoch 3/10, Batch 30/145, Loss: 0.2880
Epoch 3/10, Batch 40/145, Loss: 0.2551
Epoch 3/10, Batch 50/145, Loss: 0.2009
Epoch 3/10, Batch 60/145, Loss: 0.4504
Epoch 3/10, Batch 70/145, Loss: 0.2761
Epoch 3/10, Batch 80/145, Loss: 0.1281
Epoch 3/10, Batch 90/145, Loss: 0.1513
Epoch 3/10, Batch 100/145, Loss: 0.4241
Epoch 3/10, Batch 110/145, Loss: 0.2732
Epoch 3/10, Batch 120/145, Loss: 0.2554
Epoch 3/10, Batch 130/145, Loss: 0.5851
Epoch 3/10, Batch 140/145, Loss: 0.2352
Epoch 3/10, Train Loss: 0.2953, Valid Loss: 0.2788
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2694
Epoch 4/10, Batch 20/145, Loss: 0.2562
Epoch 4/10, Batch 30/145, Loss: 0.2854
Epoch 4/10, Batch 40/145, Loss: 0.2620
Epoch 4/10, Batch 50/145, Loss: 0.2642
Epoch 4/10, Batch 60/145, Loss: 0.3124
Epoch 4/10, Batch 70/145, Loss: 0.2078
Epoch 4/10, Batch 80/145, Loss: 0.1675
Epoch 4/10, Batch 90/145, Loss: 0.1946
Epoch 4/10, Batch 100/145, Loss: 0.2251
Epoch 4/10, Batch 110/145, Loss: 0.2547
Epoch 4/10, Batch 120/145, Loss: 0.3457
Epoch 4/10, Batch 130/145, Loss: 0.2612
Epoch 4/10, Batch 140/145, Loss: 0.1990
Epoch 4/10, Train Loss: 0.2606, Valid Loss: 0.2620
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2136
Epoch 5/10, Batch 20/145, Loss: 0.0877
Epoch 5/10, Batch 30/145, Loss: 0.1964
Epoch 5/10, Batch 40/145, Loss: 0.2900
Epoch 5/10, Batch 50/145, Loss: 0.1944
Epoch 5/10, Batch 60/145, Loss: 0.1807
Epoch 5/10, Batch 70/145, Loss: 0.2566
Epoch 5/10, Batch 80/145, Loss: 0.1449
Epoch 5/10, Batch 90/145, Loss: 0.3501
Epoch 5/10, Batch 100/145, Loss: 0.3205
Epoch 5/10, Batch 110/145, Loss: 0.2018
Epoch 5/10, Batch 120/145, Loss: 0.4012
Epoch 5/10, Batch 130/145, Loss: 0.1219
Epoch 5/10, Batch 140/145, Loss: 0.1632
Epoch 5/10, Train Loss: 0.2461, Valid Loss: 0.2623
Epoch 6/10, Batch 10/145, Loss: 0.2027
Epoch 6/10, Batch 20/145, Loss: 0.3863
Epoch 6/10, Batch 30/145, Loss: 0.3073
Epoch 6/10, Batch 40/145, Loss: 0.1540
Epoch 6/10, Batch 50/145, Loss: 0.3621
Epoch 6/10, Batch 60/145, Loss: 0.1364
Epoch 6/10, Batch 70/145, Loss: 0.4335
Epoch 6/10, Batch 80/145, Loss: 0.1594
Epoch 6/10, Batch 90/145, Loss: 0.2771
Epoch 6/10, Batch 100/145, Loss: 0.3097
Epoch 6/10, Batch 110/145, Loss: 0.1867
Epoch 6/10, Batch 120/145, Loss: 0.1243
Epoch 6/10, Batch 130/145, Loss: 0.2659
Epoch 6/10, Batch 140/145, Loss: 0.1321
Epoch 6/10, Train Loss: 0.2264, Valid Loss: 0.2415
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1563
Epoch 7/10, Batch 20/145, Loss: 0.2046
Epoch 7/10, Batch 30/145, Loss: 0.3538
Epoch 7/10, Batch 40/145, Loss: 0.2803
Epoch 7/10, Batch 50/145, Loss: 0.1748
Epoch 7/10, Batch 60/145, Loss: 0.1471
Epoch 7/10, Batch 70/145, Loss: 0.2279
Epoch 7/10, Batch 80/145, Loss: 0.2216
Epoch 7/10, Batch 90/145, Loss: 0.1729
Epoch 7/10, Batch 100/145, Loss: 0.2894
Epoch 7/10, Batch 110/145, Loss: 0.1903
Epoch 7/10, Batch 120/145, Loss: 0.2649
Epoch 7/10, Batch 130/145, Loss: 0.1588
Epoch 7/10, Batch 140/145, Loss: 0.2341
Epoch 7/10, Train Loss: 0.2191, Valid Loss: 0.2411
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1919
Epoch 8/10, Batch 20/145, Loss: 0.2581
Epoch 8/10, Batch 30/145, Loss: 0.2215
Epoch 8/10, Batch 40/145, Loss: 0.2164
Epoch 8/10, Batch 50/145, Loss: 0.2415
Epoch 8/10, Batch 60/145, Loss: 0.3309
Epoch 8/10, Batch 70/145, Loss: 0.2453
Epoch 8/10, Batch 80/145, Loss: 0.1971
Epoch 8/10, Batch 90/145, Loss: 0.3444
Epoch 8/10, Batch 100/145, Loss: 0.1985
Epoch 8/10, Batch 110/145, Loss: 0.1275
Epoch 8/10, Batch 120/145, Loss: 0.1647
Epoch 8/10, Batch 130/145, Loss: 0.0773
Epoch 8/10, Batch 140/145, Loss: 0.1937
Epoch 8/10, Train Loss: 0.2055, Valid Loss: 0.2296
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2885
Epoch 9/10, Batch 20/145, Loss: 0.1398
Epoch 9/10, Batch 30/145, Loss: 0.1844
Epoch 9/10, Batch 40/145, Loss: 0.1624
Epoch 9/10, Batch 50/145, Loss: 0.2551
Epoch 9/10, Batch 60/145, Loss: 0.1111
Epoch 9/10, Batch 70/145, Loss: 0.3403
Epoch 9/10, Batch 80/145, Loss: 0.0812
Epoch 9/10, Batch 90/145, Loss: 0.2539
Epoch 9/10, Batch 100/145, Loss: 0.1717
Epoch 9/10, Batch 110/145, Loss: 0.3859
Epoch 9/10, Batch 120/145, Loss: 0.0969
Epoch 9/10, Batch 130/145, Loss: 0.3101
Epoch 9/10, Batch 140/145, Loss: 0.3355
Epoch 9/10, Train Loss: 0.1962, Valid Loss: 0.2330
Epoch 10/10, Batch 10/145, Loss: 0.1258
Epoch 10/10, Batch 20/145, Loss: 0.1320
Epoch 10/10, Batch 30/145, Loss: 0.1753
Epoch 10/10, Batch 40/145, Loss: 0.1973
Epoch 10/10, Batch 50/145, Loss: 0.1414
Epoch 10/10, Batch 60/145, Loss: 0.1221
Epoch 10/10, Batch 70/145, Loss: 0.3076
Epoch 10/10, Batch 80/145, Loss: 0.1629
Epoch 10/10, Batch 90/145, Loss: 0.2164
Epoch 10/10, Batch 100/145, Loss: 0.1093
Epoch 10/10, Batch 110/145, Loss: 0.1585
Epoch 10/10, Batch 120/145, Loss: 0.3801
Epoch 10/10, Batch 130/145, Loss: 0.1099
Epoch 10/10, Batch 140/145, Loss: 0.2962
Epoch 10/10, Train Loss: 0.1874, Valid Loss: 0.2334
Accuracy: 0.9147
Precision: 0.9138
Recall: 0.9147
F1-score: 0.9134
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4110
Epoch 1/10, Batch 20/145, Loss: 0.9549
Epoch 1/10, Batch 30/145, Loss: 0.8957
Epoch 1/10, Batch 40/145, Loss: 0.8635
Epoch 1/10, Batch 50/145, Loss: 0.6187
Epoch 1/10, Batch 60/145, Loss: 0.6599
Epoch 1/10, Batch 70/145, Loss: 0.3963
Epoch 1/10, Batch 80/145, Loss: 0.6830
Epoch 1/10, Batch 90/145, Loss: 0.5603
Epoch 1/10, Batch 100/145, Loss: 0.4545
Epoch 1/10, Batch 110/145, Loss: 0.4627
Epoch 1/10, Batch 120/145, Loss: 0.5541
Epoch 1/10, Batch 130/145, Loss: 0.4179
Epoch 1/10, Batch 140/145, Loss: 0.3129
Epoch 1/10, Train Loss: 0.6781, Valid Loss: 0.3912
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3710
Epoch 2/10, Batch 20/145, Loss: 0.3860
Epoch 2/10, Batch 30/145, Loss: 0.3365
Epoch 2/10, Batch 40/145, Loss: 0.3913
Epoch 2/10, Batch 50/145, Loss: 0.2896
Epoch 2/10, Batch 60/145, Loss: 0.4901
Epoch 2/10, Batch 70/145, Loss: 0.3193
Epoch 2/10, Batch 80/145, Loss: 0.3219
Epoch 2/10, Batch 90/145, Loss: 0.2757
Epoch 2/10, Batch 100/145, Loss: 0.2993
Epoch 2/10, Batch 110/145, Loss: 0.2963
Epoch 2/10, Batch 120/145, Loss: 0.3531
Epoch 2/10, Batch 130/145, Loss: 0.2320
Epoch 2/10, Batch 140/145, Loss: 0.3213
Epoch 2/10, Train Loss: 0.3539, Valid Loss: 0.3104
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2800
Epoch 3/10, Batch 20/145, Loss: 0.2862
Epoch 3/10, Batch 30/145, Loss: 0.2718
Epoch 3/10, Batch 40/145, Loss: 0.2370
Epoch 3/10, Batch 50/145, Loss: 0.2628
Epoch 3/10, Batch 60/145, Loss: 0.4448
Epoch 3/10, Batch 70/145, Loss: 0.4839
Epoch 3/10, Batch 80/145, Loss: 0.2503
Epoch 3/10, Batch 90/145, Loss: 0.2250
Epoch 3/10, Batch 100/145, Loss: 0.3290
Epoch 3/10, Batch 110/145, Loss: 0.2120
Epoch 3/10, Batch 120/145, Loss: 0.3869
Epoch 3/10, Batch 130/145, Loss: 0.4473
Epoch 3/10, Batch 140/145, Loss: 0.2573
Epoch 3/10, Train Loss: 0.2903, Valid Loss: 0.2769
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.5330
Epoch 4/10, Batch 20/145, Loss: 0.3223
Epoch 4/10, Batch 30/145, Loss: 0.2856
Epoch 4/10, Batch 40/145, Loss: 0.1438
Epoch 4/10, Batch 50/145, Loss: 0.2673
Epoch 4/10, Batch 60/145, Loss: 0.3242
Epoch 4/10, Batch 70/145, Loss: 0.1770
Epoch 4/10, Batch 80/145, Loss: 0.2204
Epoch 4/10, Batch 90/145, Loss: 0.2720
Epoch 4/10, Batch 100/145, Loss: 0.2951
Epoch 4/10, Batch 110/145, Loss: 0.2157
Epoch 4/10, Batch 120/145, Loss: 0.2868
Epoch 4/10, Batch 130/145, Loss: 0.1285
Epoch 4/10, Batch 140/145, Loss: 0.0788
Epoch 4/10, Train Loss: 0.2554, Valid Loss: 0.2581
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2698
Epoch 5/10, Batch 20/145, Loss: 0.1249
Epoch 5/10, Batch 30/145, Loss: 0.3116
Epoch 5/10, Batch 40/145, Loss: 0.1162
Epoch 5/10, Batch 50/145, Loss: 0.2705
Epoch 5/10, Batch 60/145, Loss: 0.2759
Epoch 5/10, Batch 70/145, Loss: 0.1827
Epoch 5/10, Batch 80/145, Loss: 0.1875
Epoch 5/10, Batch 90/145, Loss: 0.3105
Epoch 5/10, Batch 100/145, Loss: 0.1252
Epoch 5/10, Batch 110/145, Loss: 0.0956
Epoch 5/10, Batch 120/145, Loss: 0.3590
Epoch 5/10, Batch 130/145, Loss: 0.3609
Epoch 5/10, Batch 140/145, Loss: 0.1601
Epoch 5/10, Train Loss: 0.2439, Valid Loss: 0.2490
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1207
Epoch 6/10, Batch 20/145, Loss: 0.3199
Epoch 6/10, Batch 30/145, Loss: 0.4078
Epoch 6/10, Batch 40/145, Loss: 0.3110
Epoch 6/10, Batch 50/145, Loss: 0.2642
Epoch 6/10, Batch 60/145, Loss: 0.0923
Epoch 6/10, Batch 70/145, Loss: 0.3056
Epoch 6/10, Batch 80/145, Loss: 0.2277
Epoch 6/10, Batch 90/145, Loss: 0.1642
Epoch 6/10, Batch 100/145, Loss: 0.5923
Epoch 6/10, Batch 110/145, Loss: 0.2007
Epoch 6/10, Batch 120/145, Loss: 0.2133
Epoch 6/10, Batch 130/145, Loss: 0.2140
Epoch 6/10, Batch 140/145, Loss: 0.1959
Epoch 6/10, Train Loss: 0.2281, Valid Loss: 0.2468
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2512
Epoch 7/10, Batch 20/145, Loss: 0.3320
Epoch 7/10, Batch 30/145, Loss: 0.2325
Epoch 7/10, Batch 40/145, Loss: 0.2566
Epoch 7/10, Batch 50/145, Loss: 0.2167
Epoch 7/10, Batch 60/145, Loss: 0.1141
Epoch 7/10, Batch 70/145, Loss: 0.1672
Epoch 7/10, Batch 80/145, Loss: 0.3217
Epoch 7/10, Batch 90/145, Loss: 0.1656
Epoch 7/10, Batch 100/145, Loss: 0.2518
Epoch 7/10, Batch 110/145, Loss: 0.0828
Epoch 7/10, Batch 120/145, Loss: 0.1942
Epoch 7/10, Batch 130/145, Loss: 0.1255
Epoch 7/10, Batch 140/145, Loss: 0.1933
Epoch 7/10, Train Loss: 0.2124, Valid Loss: 0.2363
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1241
Epoch 8/10, Batch 20/145, Loss: 0.2423
Epoch 8/10, Batch 30/145, Loss: 0.2907
Epoch 8/10, Batch 40/145, Loss: 0.2790
Epoch 8/10, Batch 50/145, Loss: 0.1625
Epoch 8/10, Batch 60/145, Loss: 0.2638
Epoch 8/10, Batch 70/145, Loss: 0.3142
Epoch 8/10, Batch 80/145, Loss: 0.2730
Epoch 8/10, Batch 90/145, Loss: 0.3477
Epoch 8/10, Batch 100/145, Loss: 0.1571
Epoch 8/10, Batch 110/145, Loss: 0.2558
Epoch 8/10, Batch 120/145, Loss: 0.2267
Epoch 8/10, Batch 130/145, Loss: 0.2022
Epoch 8/10, Batch 140/145, Loss: 0.3575
Epoch 8/10, Train Loss: 0.2073, Valid Loss: 0.2383
Epoch 9/10, Batch 10/145, Loss: 0.2576
Epoch 9/10, Batch 20/145, Loss: 0.1543
Epoch 9/10, Batch 30/145, Loss: 0.1479
Epoch 9/10, Batch 40/145, Loss: 0.2702
Epoch 9/10, Batch 50/145, Loss: 0.1935
Epoch 9/10, Batch 60/145, Loss: 0.1916
Epoch 9/10, Batch 70/145, Loss: 0.1777
Epoch 9/10, Batch 80/145, Loss: 0.0696
Epoch 9/10, Batch 90/145, Loss: 0.3270
Epoch 9/10, Batch 100/145, Loss: 0.1684
Epoch 9/10, Batch 110/145, Loss: 0.2449
Epoch 9/10, Batch 120/145, Loss: 0.1136
Epoch 9/10, Batch 130/145, Loss: 0.3015
Epoch 9/10, Batch 140/145, Loss: 0.3569
Epoch 9/10, Train Loss: 0.1989, Valid Loss: 0.2308
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1211
Epoch 10/10, Batch 20/145, Loss: 0.1723
Epoch 10/10, Batch 30/145, Loss: 0.1928
Epoch 10/10, Batch 40/145, Loss: 0.1696
Epoch 10/10, Batch 50/145, Loss: 0.2862
Epoch 10/10, Batch 60/145, Loss: 0.1995
Epoch 10/10, Batch 70/145, Loss: 0.1417
Epoch 10/10, Batch 80/145, Loss: 0.1378
Epoch 10/10, Batch 90/145, Loss: 0.1963
Epoch 10/10, Batch 100/145, Loss: 0.2737
Epoch 10/10, Batch 110/145, Loss: 0.1902
Epoch 10/10, Batch 120/145, Loss: 0.3151
Epoch 10/10, Batch 130/145, Loss: 0.2817
Epoch 10/10, Batch 140/145, Loss: 0.2755
Epoch 10/10, Train Loss: 0.1933, Valid Loss: 0.2310
Accuracy: 0.9206
Precision: 0.9193
Recall: 0.9206
F1-score: 0.9195
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3715
Epoch 1/10, Batch 20/145, Loss: 0.9341
Epoch 1/10, Batch 30/145, Loss: 0.8429
Epoch 1/10, Batch 40/145, Loss: 0.8572
Epoch 1/10, Batch 50/145, Loss: 0.7814
Epoch 1/10, Batch 60/145, Loss: 0.5976
Epoch 1/10, Batch 70/145, Loss: 0.5033
Epoch 1/10, Batch 80/145, Loss: 0.5157
Epoch 1/10, Batch 90/145, Loss: 0.3960
Epoch 1/10, Batch 100/145, Loss: 0.5850
Epoch 1/10, Batch 110/145, Loss: 0.4161
Epoch 1/10, Batch 120/145, Loss: 0.5798
Epoch 1/10, Batch 130/145, Loss: 0.5216
Epoch 1/10, Batch 140/145, Loss: 0.3916
Epoch 1/10, Train Loss: 0.6710, Valid Loss: 0.4118
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3682
Epoch 2/10, Batch 20/145, Loss: 0.3158
Epoch 2/10, Batch 30/145, Loss: 0.3441
Epoch 2/10, Batch 40/145, Loss: 0.3347
Epoch 2/10, Batch 50/145, Loss: 0.2929
Epoch 2/10, Batch 60/145, Loss: 0.3604
Epoch 2/10, Batch 70/145, Loss: 0.3845
Epoch 2/10, Batch 80/145, Loss: 0.2765
Epoch 2/10, Batch 90/145, Loss: 0.1753
Epoch 2/10, Batch 100/145, Loss: 0.3872
Epoch 2/10, Batch 110/145, Loss: 0.3586
Epoch 2/10, Batch 120/145, Loss: 0.4927
Epoch 2/10, Batch 130/145, Loss: 0.1722
Epoch 2/10, Batch 140/145, Loss: 0.3626
Epoch 2/10, Train Loss: 0.3472, Valid Loss: 0.3354
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2827
Epoch 3/10, Batch 20/145, Loss: 0.2783
Epoch 3/10, Batch 30/145, Loss: 0.3249
Epoch 3/10, Batch 40/145, Loss: 0.2606
Epoch 3/10, Batch 50/145, Loss: 0.2951
Epoch 3/10, Batch 60/145, Loss: 0.3979
Epoch 3/10, Batch 70/145, Loss: 0.2876
Epoch 3/10, Batch 80/145, Loss: 0.2796
Epoch 3/10, Batch 90/145, Loss: 0.2727
Epoch 3/10, Batch 100/145, Loss: 0.3071
Epoch 3/10, Batch 110/145, Loss: 0.0963
Epoch 3/10, Batch 120/145, Loss: 0.3045
Epoch 3/10, Batch 130/145, Loss: 0.3782
Epoch 3/10, Batch 140/145, Loss: 0.2391
Epoch 3/10, Train Loss: 0.2882, Valid Loss: 0.3039
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4839
Epoch 4/10, Batch 20/145, Loss: 0.3946
Epoch 4/10, Batch 30/145, Loss: 0.3288
Epoch 4/10, Batch 40/145, Loss: 0.2158
Epoch 4/10, Batch 50/145, Loss: 0.1368
Epoch 4/10, Batch 60/145, Loss: 0.3763
Epoch 4/10, Batch 70/145, Loss: 0.2139
Epoch 4/10, Batch 80/145, Loss: 0.3226
Epoch 4/10, Batch 90/145, Loss: 0.2150
Epoch 4/10, Batch 100/145, Loss: 0.2659
Epoch 4/10, Batch 110/145, Loss: 0.1631
Epoch 4/10, Batch 120/145, Loss: 0.1348
Epoch 4/10, Batch 130/145, Loss: 0.2114
Epoch 4/10, Batch 140/145, Loss: 0.2127
Epoch 4/10, Train Loss: 0.2611, Valid Loss: 0.2855
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1457
Epoch 5/10, Batch 20/145, Loss: 0.3048
Epoch 5/10, Batch 30/145, Loss: 0.1981
Epoch 5/10, Batch 40/145, Loss: 0.1638
Epoch 5/10, Batch 50/145, Loss: 0.2337
Epoch 5/10, Batch 60/145, Loss: 0.4089
Epoch 5/10, Batch 70/145, Loss: 0.2818
Epoch 5/10, Batch 80/145, Loss: 0.1184
Epoch 5/10, Batch 90/145, Loss: 0.3447
Epoch 5/10, Batch 100/145, Loss: 0.2662
Epoch 5/10, Batch 110/145, Loss: 0.1544
Epoch 5/10, Batch 120/145, Loss: 0.3200
Epoch 5/10, Batch 130/145, Loss: 0.1350
Epoch 5/10, Batch 140/145, Loss: 0.1399
Epoch 5/10, Train Loss: 0.2387, Valid Loss: 0.2794
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3100
Epoch 6/10, Batch 20/145, Loss: 0.4841
Epoch 6/10, Batch 30/145, Loss: 0.4176
Epoch 6/10, Batch 40/145, Loss: 0.1642
Epoch 6/10, Batch 50/145, Loss: 0.2762
Epoch 6/10, Batch 60/145, Loss: 0.1167
Epoch 6/10, Batch 70/145, Loss: 0.1629
Epoch 6/10, Batch 80/145, Loss: 0.0963
Epoch 6/10, Batch 90/145, Loss: 0.1947
Epoch 6/10, Batch 100/145, Loss: 0.3388
Epoch 6/10, Batch 110/145, Loss: 0.3074
Epoch 6/10, Batch 120/145, Loss: 0.3335
Epoch 6/10, Batch 130/145, Loss: 0.2208
Epoch 6/10, Batch 140/145, Loss: 0.0784
Epoch 6/10, Train Loss: 0.2235, Valid Loss: 0.2701
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2714
Epoch 7/10, Batch 20/145, Loss: 0.2692
Epoch 7/10, Batch 30/145, Loss: 0.1689
Epoch 7/10, Batch 40/145, Loss: 0.3487
Epoch 7/10, Batch 50/145, Loss: 0.1446
Epoch 7/10, Batch 60/145, Loss: 0.1342
Epoch 7/10, Batch 70/145, Loss: 0.1587
Epoch 7/10, Batch 80/145, Loss: 0.3992
Epoch 7/10, Batch 90/145, Loss: 0.2486
Epoch 7/10, Batch 100/145, Loss: 0.1862
Epoch 7/10, Batch 110/145, Loss: 0.0602
Epoch 7/10, Batch 120/145, Loss: 0.2140
Epoch 7/10, Batch 130/145, Loss: 0.1465
Epoch 7/10, Batch 140/145, Loss: 0.4532
Epoch 7/10, Train Loss: 0.2135, Valid Loss: 0.2611
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1738
Epoch 8/10, Batch 20/145, Loss: 0.1620
Epoch 8/10, Batch 30/145, Loss: 0.1854
Epoch 8/10, Batch 40/145, Loss: 0.2465
Epoch 8/10, Batch 50/145, Loss: 0.1511
Epoch 8/10, Batch 60/145, Loss: 0.1711
Epoch 8/10, Batch 70/145, Loss: 0.1764
Epoch 8/10, Batch 80/145, Loss: 0.2115
Epoch 8/10, Batch 90/145, Loss: 0.2141
Epoch 8/10, Batch 100/145, Loss: 0.0647
Epoch 8/10, Batch 110/145, Loss: 0.1951
Epoch 8/10, Batch 120/145, Loss: 0.1095
Epoch 8/10, Batch 130/145, Loss: 0.2597
Epoch 8/10, Batch 140/145, Loss: 0.1562
Epoch 8/10, Train Loss: 0.2071, Valid Loss: 0.2590
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3764
Epoch 9/10, Batch 20/145, Loss: 0.1929
Epoch 9/10, Batch 30/145, Loss: 0.0806
Epoch 9/10, Batch 40/145, Loss: 0.2503
Epoch 9/10, Batch 50/145, Loss: 0.1693
Epoch 9/10, Batch 60/145, Loss: 0.2021
Epoch 9/10, Batch 70/145, Loss: 0.1546
Epoch 9/10, Batch 80/145, Loss: 0.1604
Epoch 9/10, Batch 90/145, Loss: 0.2972
Epoch 9/10, Batch 100/145, Loss: 0.2093
Epoch 9/10, Batch 110/145, Loss: 0.2793
Epoch 9/10, Batch 120/145, Loss: 0.1564
Epoch 9/10, Batch 130/145, Loss: 0.2042
Epoch 9/10, Batch 140/145, Loss: 0.1497
Epoch 9/10, Train Loss: 0.2011, Valid Loss: 0.2563
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1202
Epoch 10/10, Batch 20/145, Loss: 0.1312
Epoch 10/10, Batch 30/145, Loss: 0.0702
Epoch 10/10, Batch 40/145, Loss: 0.1331
Epoch 10/10, Batch 50/145, Loss: 0.2342
Epoch 10/10, Batch 60/145, Loss: 0.1277
Epoch 10/10, Batch 70/145, Loss: 0.2249
Epoch 10/10, Batch 80/145, Loss: 0.1201
Epoch 10/10, Batch 90/145, Loss: 0.1577
Epoch 10/10, Batch 100/145, Loss: 0.1792
Epoch 10/10, Batch 110/145, Loss: 0.2555
Epoch 10/10, Batch 120/145, Loss: 0.2288
Epoch 10/10, Batch 130/145, Loss: 0.1294
Epoch 10/10, Batch 140/145, Loss: 0.1241
Epoch 10/10, Train Loss: 0.1862, Valid Loss: 0.2601
Accuracy: 0.9217
Precision: 0.9197
Recall: 0.9217
F1-score: 0.9204
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3721
Epoch 1/10, Batch 20/145, Loss: 0.9468
Epoch 1/10, Batch 30/145, Loss: 0.8741
Epoch 1/10, Batch 40/145, Loss: 0.9138
Epoch 1/10, Batch 50/145, Loss: 0.6818
Epoch 1/10, Batch 60/145, Loss: 0.5826
Epoch 1/10, Batch 70/145, Loss: 0.5114
Epoch 1/10, Batch 80/145, Loss: 0.8147
Epoch 1/10, Batch 90/145, Loss: 0.3606
Epoch 1/10, Batch 100/145, Loss: 0.5633
Epoch 1/10, Batch 110/145, Loss: 0.4490
Epoch 1/10, Batch 120/145, Loss: 0.4936
Epoch 1/10, Batch 130/145, Loss: 0.3915
Epoch 1/10, Batch 140/145, Loss: 0.3542
Epoch 1/10, Train Loss: 0.6831, Valid Loss: 0.3602
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3465
Epoch 2/10, Batch 20/145, Loss: 0.3838
Epoch 2/10, Batch 30/145, Loss: 0.3970
Epoch 2/10, Batch 40/145, Loss: 0.3534
Epoch 2/10, Batch 50/145, Loss: 0.3201
Epoch 2/10, Batch 60/145, Loss: 0.4032
Epoch 2/10, Batch 70/145, Loss: 0.3603
Epoch 2/10, Batch 80/145, Loss: 0.3323
Epoch 2/10, Batch 90/145, Loss: 0.3621
Epoch 2/10, Batch 100/145, Loss: 0.2422
Epoch 2/10, Batch 110/145, Loss: 0.2326
Epoch 2/10, Batch 120/145, Loss: 0.3317
Epoch 2/10, Batch 130/145, Loss: 0.2507
Epoch 2/10, Batch 140/145, Loss: 0.4084
Epoch 2/10, Train Loss: 0.3575, Valid Loss: 0.2794
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2426
Epoch 3/10, Batch 20/145, Loss: 0.5516
Epoch 3/10, Batch 30/145, Loss: 0.4273
Epoch 3/10, Batch 40/145, Loss: 0.2074
Epoch 3/10, Batch 50/145, Loss: 0.2767
Epoch 3/10, Batch 60/145, Loss: 0.4415
Epoch 3/10, Batch 70/145, Loss: 0.2804
Epoch 3/10, Batch 80/145, Loss: 0.2974
Epoch 3/10, Batch 90/145, Loss: 0.4553
Epoch 3/10, Batch 100/145, Loss: 0.2232
Epoch 3/10, Batch 110/145, Loss: 0.2566
Epoch 3/10, Batch 120/145, Loss: 0.2241
Epoch 3/10, Batch 130/145, Loss: 0.3497
Epoch 3/10, Batch 140/145, Loss: 0.2813
Epoch 3/10, Train Loss: 0.2977, Valid Loss: 0.2533
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3485
Epoch 4/10, Batch 20/145, Loss: 0.3133
Epoch 4/10, Batch 30/145, Loss: 0.1911
Epoch 4/10, Batch 40/145, Loss: 0.2855
Epoch 4/10, Batch 50/145, Loss: 0.2694
Epoch 4/10, Batch 60/145, Loss: 0.2346
Epoch 4/10, Batch 70/145, Loss: 0.2804
Epoch 4/10, Batch 80/145, Loss: 0.1010
Epoch 4/10, Batch 90/145, Loss: 0.3152
Epoch 4/10, Batch 100/145, Loss: 0.3457
Epoch 4/10, Batch 110/145, Loss: 0.1820
Epoch 4/10, Batch 120/145, Loss: 0.1847
Epoch 4/10, Batch 130/145, Loss: 0.1740
Epoch 4/10, Batch 140/145, Loss: 0.1622
Epoch 4/10, Train Loss: 0.2646, Valid Loss: 0.2373
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2533
Epoch 5/10, Batch 20/145, Loss: 0.1808
Epoch 5/10, Batch 30/145, Loss: 0.3279
Epoch 5/10, Batch 40/145, Loss: 0.2412
Epoch 5/10, Batch 50/145, Loss: 0.1688
Epoch 5/10, Batch 60/145, Loss: 0.2164
Epoch 5/10, Batch 70/145, Loss: 0.1354
Epoch 5/10, Batch 80/145, Loss: 0.2576
Epoch 5/10, Batch 90/145, Loss: 0.3240
Epoch 5/10, Batch 100/145, Loss: 0.1599
Epoch 5/10, Batch 110/145, Loss: 0.3119
Epoch 5/10, Batch 120/145, Loss: 0.2859
Epoch 5/10, Batch 130/145, Loss: 0.2972
Epoch 5/10, Batch 140/145, Loss: 0.1470
Epoch 5/10, Train Loss: 0.2495, Valid Loss: 0.2256
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2256
Epoch 6/10, Batch 20/145, Loss: 0.3266
Epoch 6/10, Batch 30/145, Loss: 0.3511
Epoch 6/10, Batch 40/145, Loss: 0.1554
Epoch 6/10, Batch 50/145, Loss: 0.2963
Epoch 6/10, Batch 60/145, Loss: 0.1969
Epoch 6/10, Batch 70/145, Loss: 0.1884
Epoch 6/10, Batch 80/145, Loss: 0.0960
Epoch 6/10, Batch 90/145, Loss: 0.2234
Epoch 6/10, Batch 100/145, Loss: 0.5529
Epoch 6/10, Batch 110/145, Loss: 0.1731
Epoch 6/10, Batch 120/145, Loss: 0.3548
Epoch 6/10, Batch 130/145, Loss: 0.0947
Epoch 6/10, Batch 140/145, Loss: 0.2286
Epoch 6/10, Train Loss: 0.2336, Valid Loss: 0.2164
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2304
Epoch 7/10, Batch 20/145, Loss: 0.3023
Epoch 7/10, Batch 30/145, Loss: 0.2625
Epoch 7/10, Batch 40/145, Loss: 0.2873
Epoch 7/10, Batch 50/145, Loss: 0.1133
Epoch 7/10, Batch 60/145, Loss: 0.2155
Epoch 7/10, Batch 70/145, Loss: 0.1926
Epoch 7/10, Batch 80/145, Loss: 0.4929
Epoch 7/10, Batch 90/145, Loss: 0.0976
Epoch 7/10, Batch 100/145, Loss: 0.1510
Epoch 7/10, Batch 110/145, Loss: 0.1517
Epoch 7/10, Batch 120/145, Loss: 0.3069
Epoch 7/10, Batch 130/145, Loss: 0.1239
Epoch 7/10, Batch 140/145, Loss: 0.3912
Epoch 7/10, Train Loss: 0.2194, Valid Loss: 0.2153
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1415
Epoch 8/10, Batch 20/145, Loss: 0.1324
Epoch 8/10, Batch 30/145, Loss: 0.1997
Epoch 8/10, Batch 40/145, Loss: 0.1832
Epoch 8/10, Batch 50/145, Loss: 0.2192
Epoch 8/10, Batch 60/145, Loss: 0.1248
Epoch 8/10, Batch 70/145, Loss: 0.3046
Epoch 8/10, Batch 80/145, Loss: 0.1865
Epoch 8/10, Batch 90/145, Loss: 0.5273
Epoch 8/10, Batch 100/145, Loss: 0.2455
Epoch 8/10, Batch 110/145, Loss: 0.1932
Epoch 8/10, Batch 120/145, Loss: 0.1663
Epoch 8/10, Batch 130/145, Loss: 0.1191
Epoch 8/10, Batch 140/145, Loss: 0.1635
Epoch 8/10, Train Loss: 0.2128, Valid Loss: 0.2119
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3201
Epoch 9/10, Batch 20/145, Loss: 0.2940
Epoch 9/10, Batch 30/145, Loss: 0.2463
Epoch 9/10, Batch 40/145, Loss: 0.1123
Epoch 9/10, Batch 50/145, Loss: 0.2662
Epoch 9/10, Batch 60/145, Loss: 0.3313
Epoch 9/10, Batch 70/145, Loss: 0.1532
Epoch 9/10, Batch 80/145, Loss: 0.1151
Epoch 9/10, Batch 90/145, Loss: 0.1851
Epoch 9/10, Batch 100/145, Loss: 0.0948
Epoch 9/10, Batch 110/145, Loss: 0.1984
Epoch 9/10, Batch 120/145, Loss: 0.1736
Epoch 9/10, Batch 130/145, Loss: 0.2206
Epoch 9/10, Batch 140/145, Loss: 0.2179
Epoch 9/10, Train Loss: 0.2047, Valid Loss: 0.2095
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1216
Epoch 10/10, Batch 20/145, Loss: 0.2080
Epoch 10/10, Batch 30/145, Loss: 0.0970
Epoch 10/10, Batch 40/145, Loss: 0.0917
Epoch 10/10, Batch 50/145, Loss: 0.2718
Epoch 10/10, Batch 60/145, Loss: 0.1601
Epoch 10/10, Batch 70/145, Loss: 0.3230
Epoch 10/10, Batch 80/145, Loss: 0.2052
Epoch 10/10, Batch 90/145, Loss: 0.1601
Epoch 10/10, Batch 100/145, Loss: 0.1379
Epoch 10/10, Batch 110/145, Loss: 0.0891
Epoch 10/10, Batch 120/145, Loss: 0.2516
Epoch 10/10, Batch 130/145, Loss: 0.2309
Epoch 10/10, Batch 140/145, Loss: 0.1952
Epoch 10/10, Train Loss: 0.1985, Valid Loss: 0.2099
Accuracy: 0.9217
Precision: 0.9202
Recall: 0.9217
F1-score: 0.9204
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4098
Epoch 1/10, Batch 20/145, Loss: 0.8664
Epoch 1/10, Batch 30/145, Loss: 0.9248
Epoch 1/10, Batch 40/145, Loss: 0.7529
Epoch 1/10, Batch 50/145, Loss: 0.7037
Epoch 1/10, Batch 60/145, Loss: 0.5729
Epoch 1/10, Batch 70/145, Loss: 0.4233
Epoch 1/10, Batch 80/145, Loss: 0.6071
Epoch 1/10, Batch 90/145, Loss: 0.3787
Epoch 1/10, Batch 100/145, Loss: 0.4616
Epoch 1/10, Batch 110/145, Loss: 0.3957
Epoch 1/10, Batch 120/145, Loss: 0.5748
Epoch 1/10, Batch 130/145, Loss: 0.3657
Epoch 1/10, Batch 140/145, Loss: 0.5022
Epoch 1/10, Train Loss: 0.6880, Valid Loss: 0.3737
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3543
Epoch 2/10, Batch 20/145, Loss: 0.4005
Epoch 2/10, Batch 30/145, Loss: 0.2605
Epoch 2/10, Batch 40/145, Loss: 0.4725
Epoch 2/10, Batch 50/145, Loss: 0.4713
Epoch 2/10, Batch 60/145, Loss: 0.3570
Epoch 2/10, Batch 70/145, Loss: 0.2750
Epoch 2/10, Batch 80/145, Loss: 0.3496
Epoch 2/10, Batch 90/145, Loss: 0.3638
Epoch 2/10, Batch 100/145, Loss: 0.2399
Epoch 2/10, Batch 110/145, Loss: 0.2779
Epoch 2/10, Batch 120/145, Loss: 0.3486
Epoch 2/10, Batch 130/145, Loss: 0.3584
Epoch 2/10, Batch 140/145, Loss: 0.3473
Epoch 2/10, Train Loss: 0.3620, Valid Loss: 0.2891
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2046
Epoch 3/10, Batch 20/145, Loss: 0.2546
Epoch 3/10, Batch 30/145, Loss: 0.3204
Epoch 3/10, Batch 40/145, Loss: 0.2942
Epoch 3/10, Batch 50/145, Loss: 0.2943
Epoch 3/10, Batch 60/145, Loss: 0.5208
Epoch 3/10, Batch 70/145, Loss: 0.3246
Epoch 3/10, Batch 80/145, Loss: 0.1333
Epoch 3/10, Batch 90/145, Loss: 0.4129
Epoch 3/10, Batch 100/145, Loss: 0.3577
Epoch 3/10, Batch 110/145, Loss: 0.2474
Epoch 3/10, Batch 120/145, Loss: 0.3857
Epoch 3/10, Batch 130/145, Loss: 0.3813
Epoch 3/10, Batch 140/145, Loss: 0.2551
Epoch 3/10, Train Loss: 0.2971, Valid Loss: 0.2525
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2245
Epoch 4/10, Batch 20/145, Loss: 0.2170
Epoch 4/10, Batch 30/145, Loss: 0.2719
Epoch 4/10, Batch 40/145, Loss: 0.1740
Epoch 4/10, Batch 50/145, Loss: 0.1998
Epoch 4/10, Batch 60/145, Loss: 0.3047
Epoch 4/10, Batch 70/145, Loss: 0.2765
Epoch 4/10, Batch 80/145, Loss: 0.1862
Epoch 4/10, Batch 90/145, Loss: 0.2074
Epoch 4/10, Batch 100/145, Loss: 0.3111
Epoch 4/10, Batch 110/145, Loss: 0.1212
Epoch 4/10, Batch 120/145, Loss: 0.2367
Epoch 4/10, Batch 130/145, Loss: 0.1157
Epoch 4/10, Batch 140/145, Loss: 0.2139
Epoch 4/10, Train Loss: 0.2605, Valid Loss: 0.2512
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1808
Epoch 5/10, Batch 20/145, Loss: 0.1273
Epoch 5/10, Batch 30/145, Loss: 0.2393
Epoch 5/10, Batch 40/145, Loss: 0.2335
Epoch 5/10, Batch 50/145, Loss: 0.1647
Epoch 5/10, Batch 60/145, Loss: 0.2146
Epoch 5/10, Batch 70/145, Loss: 0.2406
Epoch 5/10, Batch 80/145, Loss: 0.3012
Epoch 5/10, Batch 90/145, Loss: 0.2379
Epoch 5/10, Batch 100/145, Loss: 0.3281
Epoch 5/10, Batch 110/145, Loss: 0.1058
Epoch 5/10, Batch 120/145, Loss: 0.4018
Epoch 5/10, Batch 130/145, Loss: 0.2558
Epoch 5/10, Batch 140/145, Loss: 0.1863
Epoch 5/10, Train Loss: 0.2497, Valid Loss: 0.2309
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2897
Epoch 6/10, Batch 20/145, Loss: 0.3470
Epoch 6/10, Batch 30/145, Loss: 0.2323
Epoch 6/10, Batch 40/145, Loss: 0.1759
Epoch 6/10, Batch 50/145, Loss: 0.2460
Epoch 6/10, Batch 60/145, Loss: 0.1024
Epoch 6/10, Batch 70/145, Loss: 0.1771
Epoch 6/10, Batch 80/145, Loss: 0.1562
Epoch 6/10, Batch 90/145, Loss: 0.2159
Epoch 6/10, Batch 100/145, Loss: 0.3107
Epoch 6/10, Batch 110/145, Loss: 0.1296
Epoch 6/10, Batch 120/145, Loss: 0.3169
Epoch 6/10, Batch 130/145, Loss: 0.2930
Epoch 6/10, Batch 140/145, Loss: 0.1965
Epoch 6/10, Train Loss: 0.2346, Valid Loss: 0.2199
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2199
Epoch 7/10, Batch 20/145, Loss: 0.2155
Epoch 7/10, Batch 30/145, Loss: 0.2024
Epoch 7/10, Batch 40/145, Loss: 0.2989
Epoch 7/10, Batch 50/145, Loss: 0.2844
Epoch 7/10, Batch 60/145, Loss: 0.3584
Epoch 7/10, Batch 70/145, Loss: 0.1181
Epoch 7/10, Batch 80/145, Loss: 0.2503
Epoch 7/10, Batch 90/145, Loss: 0.1114
Epoch 7/10, Batch 100/145, Loss: 0.3063
Epoch 7/10, Batch 110/145, Loss: 0.1880
Epoch 7/10, Batch 120/145, Loss: 0.1753
Epoch 7/10, Batch 130/145, Loss: 0.0968
Epoch 7/10, Batch 140/145, Loss: 0.3831
Epoch 7/10, Train Loss: 0.2180, Valid Loss: 0.2206
Epoch 8/10, Batch 10/145, Loss: 0.2061
Epoch 8/10, Batch 20/145, Loss: 0.1613
Epoch 8/10, Batch 30/145, Loss: 0.1227
Epoch 8/10, Batch 40/145, Loss: 0.2552
Epoch 8/10, Batch 50/145, Loss: 0.3514
Epoch 8/10, Batch 60/145, Loss: 0.2270
Epoch 8/10, Batch 70/145, Loss: 0.2235
Epoch 8/10, Batch 80/145, Loss: 0.1689
Epoch 8/10, Batch 90/145, Loss: 0.4895
Epoch 8/10, Batch 100/145, Loss: 0.1893
Epoch 8/10, Batch 110/145, Loss: 0.1826
Epoch 8/10, Batch 120/145, Loss: 0.2345
Epoch 8/10, Batch 130/145, Loss: 0.1579
Epoch 8/10, Batch 140/145, Loss: 0.3920
Epoch 8/10, Train Loss: 0.2150, Valid Loss: 0.2146
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2742
Epoch 9/10, Batch 20/145, Loss: 0.2380
Epoch 9/10, Batch 30/145, Loss: 0.1162
Epoch 9/10, Batch 40/145, Loss: 0.3209
Epoch 9/10, Batch 50/145, Loss: 0.2272
Epoch 9/10, Batch 60/145, Loss: 0.2137
Epoch 9/10, Batch 70/145, Loss: 0.1986
Epoch 9/10, Batch 80/145, Loss: 0.2039
Epoch 9/10, Batch 90/145, Loss: 0.2806
Epoch 9/10, Batch 100/145, Loss: 0.1086
Epoch 9/10, Batch 110/145, Loss: 0.3271
Epoch 9/10, Batch 120/145, Loss: 0.2115
Epoch 9/10, Batch 130/145, Loss: 0.2552
Epoch 9/10, Batch 140/145, Loss: 0.3381
Epoch 9/10, Train Loss: 0.2027, Valid Loss: 0.2112
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1246
Epoch 10/10, Batch 20/145, Loss: 0.2408
Epoch 10/10, Batch 30/145, Loss: 0.0729
Epoch 10/10, Batch 40/145, Loss: 0.1027
Epoch 10/10, Batch 50/145, Loss: 0.1855
Epoch 10/10, Batch 60/145, Loss: 0.0748
Epoch 10/10, Batch 70/145, Loss: 0.2322
Epoch 10/10, Batch 80/145, Loss: 0.3592
Epoch 10/10, Batch 90/145, Loss: 0.1370
Epoch 10/10, Batch 100/145, Loss: 0.2739
Epoch 10/10, Batch 110/145, Loss: 0.1885
Epoch 10/10, Batch 120/145, Loss: 0.2346
Epoch 10/10, Batch 130/145, Loss: 0.2608
Epoch 10/10, Batch 140/145, Loss: 0.1363
Epoch 10/10, Train Loss: 0.1954, Valid Loss: 0.2132
Accuracy: 0.9159
Precision: 0.9136
Recall: 0.9159
F1-score: 0.9143
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4207
Epoch 1/10, Batch 20/145, Loss: 0.8844
Epoch 1/10, Batch 30/145, Loss: 0.9632
Epoch 1/10, Batch 40/145, Loss: 0.7972
Epoch 1/10, Batch 50/145, Loss: 0.7722
Epoch 1/10, Batch 60/145, Loss: 0.6639
Epoch 1/10, Batch 70/145, Loss: 0.4121
Epoch 1/10, Batch 80/145, Loss: 0.4278
Epoch 1/10, Batch 90/145, Loss: 0.3745
Epoch 1/10, Batch 100/145, Loss: 0.4560
Epoch 1/10, Batch 110/145, Loss: 0.3588
Epoch 1/10, Batch 120/145, Loss: 0.5688
Epoch 1/10, Batch 130/145, Loss: 0.5146
Epoch 1/10, Batch 140/145, Loss: 0.3772
Epoch 1/10, Train Loss: 0.6771, Valid Loss: 0.4064
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3401
Epoch 2/10, Batch 20/145, Loss: 0.1718
Epoch 2/10, Batch 30/145, Loss: 0.2381
Epoch 2/10, Batch 40/145, Loss: 0.5706
Epoch 2/10, Batch 50/145, Loss: 0.3696
Epoch 2/10, Batch 60/145, Loss: 0.3958
Epoch 2/10, Batch 70/145, Loss: 0.3450
Epoch 2/10, Batch 80/145, Loss: 0.2119
Epoch 2/10, Batch 90/145, Loss: 0.3251
Epoch 2/10, Batch 100/145, Loss: 0.3817
Epoch 2/10, Batch 110/145, Loss: 0.4605
Epoch 2/10, Batch 120/145, Loss: 0.4397
Epoch 2/10, Batch 130/145, Loss: 0.3553
Epoch 2/10, Batch 140/145, Loss: 0.2795
Epoch 2/10, Train Loss: 0.3527, Valid Loss: 0.3179
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3079
Epoch 3/10, Batch 20/145, Loss: 0.3858
Epoch 3/10, Batch 30/145, Loss: 0.3604
Epoch 3/10, Batch 40/145, Loss: 0.2865
Epoch 3/10, Batch 50/145, Loss: 0.3232
Epoch 3/10, Batch 60/145, Loss: 0.4420
Epoch 3/10, Batch 70/145, Loss: 0.4259
Epoch 3/10, Batch 80/145, Loss: 0.4303
Epoch 3/10, Batch 90/145, Loss: 0.3201
Epoch 3/10, Batch 100/145, Loss: 0.3950
Epoch 3/10, Batch 110/145, Loss: 0.2017
Epoch 3/10, Batch 120/145, Loss: 0.2009
Epoch 3/10, Batch 130/145, Loss: 0.3243
Epoch 3/10, Batch 140/145, Loss: 0.2695
Epoch 3/10, Train Loss: 0.2912, Valid Loss: 0.2849
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2984
Epoch 4/10, Batch 20/145, Loss: 0.2249
Epoch 4/10, Batch 30/145, Loss: 0.2785
Epoch 4/10, Batch 40/145, Loss: 0.1132
Epoch 4/10, Batch 50/145, Loss: 0.1649
Epoch 4/10, Batch 60/145, Loss: 0.4421
Epoch 4/10, Batch 70/145, Loss: 0.1961
Epoch 4/10, Batch 80/145, Loss: 0.1654
Epoch 4/10, Batch 90/145, Loss: 0.1662
Epoch 4/10, Batch 100/145, Loss: 0.2749
Epoch 4/10, Batch 110/145, Loss: 0.1143
Epoch 4/10, Batch 120/145, Loss: 0.4502
Epoch 4/10, Batch 130/145, Loss: 0.2021
Epoch 4/10, Batch 140/145, Loss: 0.2626
Epoch 4/10, Train Loss: 0.2528, Valid Loss: 0.2745
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2261
Epoch 5/10, Batch 20/145, Loss: 0.1205
Epoch 5/10, Batch 30/145, Loss: 0.2462
Epoch 5/10, Batch 40/145, Loss: 0.2425
Epoch 5/10, Batch 50/145, Loss: 0.1811
Epoch 5/10, Batch 60/145, Loss: 0.1348
Epoch 5/10, Batch 70/145, Loss: 0.2608
Epoch 5/10, Batch 80/145, Loss: 0.2526
Epoch 5/10, Batch 90/145, Loss: 0.4486
Epoch 5/10, Batch 100/145, Loss: 0.1312
Epoch 5/10, Batch 110/145, Loss: 0.1973
Epoch 5/10, Batch 120/145, Loss: 0.2064
Epoch 5/10, Batch 130/145, Loss: 0.1017
Epoch 5/10, Batch 140/145, Loss: 0.1732
Epoch 5/10, Train Loss: 0.2470, Valid Loss: 0.2622
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3151
Epoch 6/10, Batch 20/145, Loss: 0.2952
Epoch 6/10, Batch 30/145, Loss: 0.3424
Epoch 6/10, Batch 40/145, Loss: 0.1878
Epoch 6/10, Batch 50/145, Loss: 0.2662
Epoch 6/10, Batch 60/145, Loss: 0.1167
Epoch 6/10, Batch 70/145, Loss: 0.3407
Epoch 6/10, Batch 80/145, Loss: 0.1729
Epoch 6/10, Batch 90/145, Loss: 0.3174
Epoch 6/10, Batch 100/145, Loss: 0.1937
Epoch 6/10, Batch 110/145, Loss: 0.1824
Epoch 6/10, Batch 120/145, Loss: 0.2201
Epoch 6/10, Batch 130/145, Loss: 0.1734
Epoch 6/10, Batch 140/145, Loss: 0.1425
Epoch 6/10, Train Loss: 0.2258, Valid Loss: 0.2565
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1742
Epoch 7/10, Batch 20/145, Loss: 0.2913
Epoch 7/10, Batch 30/145, Loss: 0.1848
Epoch 7/10, Batch 40/145, Loss: 0.2953
Epoch 7/10, Batch 50/145, Loss: 0.1443
Epoch 7/10, Batch 60/145, Loss: 0.1379
Epoch 7/10, Batch 70/145, Loss: 0.1670
Epoch 7/10, Batch 80/145, Loss: 0.4650
Epoch 7/10, Batch 90/145, Loss: 0.2076
Epoch 7/10, Batch 100/145, Loss: 0.2000
Epoch 7/10, Batch 110/145, Loss: 0.1336
Epoch 7/10, Batch 120/145, Loss: 0.2516
Epoch 7/10, Batch 130/145, Loss: 0.1556
Epoch 7/10, Batch 140/145, Loss: 0.2826
Epoch 7/10, Train Loss: 0.2108, Valid Loss: 0.2435
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1972
Epoch 8/10, Batch 20/145, Loss: 0.2070
Epoch 8/10, Batch 30/145, Loss: 0.2211
Epoch 8/10, Batch 40/145, Loss: 0.1946
Epoch 8/10, Batch 50/145, Loss: 0.2781
Epoch 8/10, Batch 60/145, Loss: 0.2177
Epoch 8/10, Batch 70/145, Loss: 0.3999
Epoch 8/10, Batch 80/145, Loss: 0.2173
Epoch 8/10, Batch 90/145, Loss: 0.3353
Epoch 8/10, Batch 100/145, Loss: 0.2513
Epoch 8/10, Batch 110/145, Loss: 0.2465
Epoch 8/10, Batch 120/145, Loss: 0.1141
Epoch 8/10, Batch 130/145, Loss: 0.1866
Epoch 8/10, Batch 140/145, Loss: 0.1092
Epoch 8/10, Train Loss: 0.2045, Valid Loss: 0.2379
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1702
Epoch 9/10, Batch 20/145, Loss: 0.1756
Epoch 9/10, Batch 30/145, Loss: 0.2370
Epoch 9/10, Batch 40/145, Loss: 0.2389
Epoch 9/10, Batch 50/145, Loss: 0.0894
Epoch 9/10, Batch 60/145, Loss: 0.3140
Epoch 9/10, Batch 70/145, Loss: 0.1565
Epoch 9/10, Batch 80/145, Loss: 0.0788
Epoch 9/10, Batch 90/145, Loss: 0.1874
Epoch 9/10, Batch 100/145, Loss: 0.1522
Epoch 9/10, Batch 110/145, Loss: 0.2407
Epoch 9/10, Batch 120/145, Loss: 0.1455
Epoch 9/10, Batch 130/145, Loss: 0.1328
Epoch 9/10, Batch 140/145, Loss: 0.1947
Epoch 9/10, Train Loss: 0.1957, Valid Loss: 0.2364
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1323
Epoch 10/10, Batch 20/145, Loss: 0.1046
Epoch 10/10, Batch 30/145, Loss: 0.1070
Epoch 10/10, Batch 40/145, Loss: 0.0979
Epoch 10/10, Batch 50/145, Loss: 0.3476
Epoch 10/10, Batch 60/145, Loss: 0.1824
Epoch 10/10, Batch 70/145, Loss: 0.2736
Epoch 10/10, Batch 80/145, Loss: 0.1906
Epoch 10/10, Batch 90/145, Loss: 0.1158
Epoch 10/10, Batch 100/145, Loss: 0.2346
Epoch 10/10, Batch 110/145, Loss: 0.1777
Epoch 10/10, Batch 120/145, Loss: 0.2286
Epoch 10/10, Batch 130/145, Loss: 0.1377
Epoch 10/10, Batch 140/145, Loss: 0.3136
Epoch 10/10, Train Loss: 0.1932, Valid Loss: 0.2311
Model saved!
Accuracy: 0.9182
Precision: 0.9149
Recall: 0.9182
F1-score: 0.9156
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3696
Epoch 1/10, Batch 20/145, Loss: 0.9253
Epoch 1/10, Batch 30/145, Loss: 0.8143
Epoch 1/10, Batch 40/145, Loss: 0.8433
Epoch 1/10, Batch 50/145, Loss: 0.7302
Epoch 1/10, Batch 60/145, Loss: 0.6439
Epoch 1/10, Batch 70/145, Loss: 0.3584
Epoch 1/10, Batch 80/145, Loss: 0.4929
Epoch 1/10, Batch 90/145, Loss: 0.4031
Epoch 1/10, Batch 100/145, Loss: 0.5501
Epoch 1/10, Batch 110/145, Loss: 0.4103
Epoch 1/10, Batch 120/145, Loss: 0.4686
Epoch 1/10, Batch 130/145, Loss: 0.4306
Epoch 1/10, Batch 140/145, Loss: 0.2590
Epoch 1/10, Train Loss: 0.6815, Valid Loss: 0.3762
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2552
Epoch 2/10, Batch 20/145, Loss: 0.2465
Epoch 2/10, Batch 30/145, Loss: 0.3832
Epoch 2/10, Batch 40/145, Loss: 0.3753
Epoch 2/10, Batch 50/145, Loss: 0.3009
Epoch 2/10, Batch 60/145, Loss: 0.3618
Epoch 2/10, Batch 70/145, Loss: 0.3420
Epoch 2/10, Batch 80/145, Loss: 0.2887
Epoch 2/10, Batch 90/145, Loss: 0.3142
Epoch 2/10, Batch 100/145, Loss: 0.3930
Epoch 2/10, Batch 110/145, Loss: 0.3775
Epoch 2/10, Batch 120/145, Loss: 0.5825
Epoch 2/10, Batch 130/145, Loss: 0.3274
Epoch 2/10, Batch 140/145, Loss: 0.3242
Epoch 2/10, Train Loss: 0.3550, Valid Loss: 0.2975
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1840
Epoch 3/10, Batch 20/145, Loss: 0.3987
Epoch 3/10, Batch 30/145, Loss: 0.4126
Epoch 3/10, Batch 40/145, Loss: 0.3477
Epoch 3/10, Batch 50/145, Loss: 0.2057
Epoch 3/10, Batch 60/145, Loss: 0.2913
Epoch 3/10, Batch 70/145, Loss: 0.3947
Epoch 3/10, Batch 80/145, Loss: 0.3578
Epoch 3/10, Batch 90/145, Loss: 0.2381
Epoch 3/10, Batch 100/145, Loss: 0.3382
Epoch 3/10, Batch 110/145, Loss: 0.1873
Epoch 3/10, Batch 120/145, Loss: 0.1863
Epoch 3/10, Batch 130/145, Loss: 0.4098
Epoch 3/10, Batch 140/145, Loss: 0.2365
Epoch 3/10, Train Loss: 0.2979, Valid Loss: 0.2671
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3892
Epoch 4/10, Batch 20/145, Loss: 0.3422
Epoch 4/10, Batch 30/145, Loss: 0.2443
Epoch 4/10, Batch 40/145, Loss: 0.0697
Epoch 4/10, Batch 50/145, Loss: 0.3097
Epoch 4/10, Batch 60/145, Loss: 0.3212
Epoch 4/10, Batch 70/145, Loss: 0.2277
Epoch 4/10, Batch 80/145, Loss: 0.1974
Epoch 4/10, Batch 90/145, Loss: 0.2469
Epoch 4/10, Batch 100/145, Loss: 0.3209
Epoch 4/10, Batch 110/145, Loss: 0.1294
Epoch 4/10, Batch 120/145, Loss: 0.4374
Epoch 4/10, Batch 130/145, Loss: 0.1007
Epoch 4/10, Batch 140/145, Loss: 0.1256
Epoch 4/10, Train Loss: 0.2603, Valid Loss: 0.2605
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2517
Epoch 5/10, Batch 20/145, Loss: 0.1412
Epoch 5/10, Batch 30/145, Loss: 0.1997
Epoch 5/10, Batch 40/145, Loss: 0.0677
Epoch 5/10, Batch 50/145, Loss: 0.2025
Epoch 5/10, Batch 60/145, Loss: 0.2652
Epoch 5/10, Batch 70/145, Loss: 0.1643
Epoch 5/10, Batch 80/145, Loss: 0.2161
Epoch 5/10, Batch 90/145, Loss: 0.4152
Epoch 5/10, Batch 100/145, Loss: 0.3006
Epoch 5/10, Batch 110/145, Loss: 0.2116
Epoch 5/10, Batch 120/145, Loss: 0.3556
Epoch 5/10, Batch 130/145, Loss: 0.1066
Epoch 5/10, Batch 140/145, Loss: 0.3382
Epoch 5/10, Train Loss: 0.2432, Valid Loss: 0.2441
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1955
Epoch 6/10, Batch 20/145, Loss: 0.6098
Epoch 6/10, Batch 30/145, Loss: 0.3900
Epoch 6/10, Batch 40/145, Loss: 0.2389
Epoch 6/10, Batch 50/145, Loss: 0.3054
Epoch 6/10, Batch 60/145, Loss: 0.2822
Epoch 6/10, Batch 70/145, Loss: 0.3393
Epoch 6/10, Batch 80/145, Loss: 0.1546
Epoch 6/10, Batch 90/145, Loss: 0.2858
Epoch 6/10, Batch 100/145, Loss: 0.2961
Epoch 6/10, Batch 110/145, Loss: 0.2066
Epoch 6/10, Batch 120/145, Loss: 0.2735
Epoch 6/10, Batch 130/145, Loss: 0.1949
Epoch 6/10, Batch 140/145, Loss: 0.1248
Epoch 6/10, Train Loss: 0.2281, Valid Loss: 0.2440
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1868
Epoch 7/10, Batch 20/145, Loss: 0.3067
Epoch 7/10, Batch 30/145, Loss: 0.2473
Epoch 7/10, Batch 40/145, Loss: 0.3452
Epoch 7/10, Batch 50/145, Loss: 0.1524
Epoch 7/10, Batch 60/145, Loss: 0.1276
Epoch 7/10, Batch 70/145, Loss: 0.1647
Epoch 7/10, Batch 80/145, Loss: 0.3020
Epoch 7/10, Batch 90/145, Loss: 0.3757
Epoch 7/10, Batch 100/145, Loss: 0.1896
Epoch 7/10, Batch 110/145, Loss: 0.2624
Epoch 7/10, Batch 120/145, Loss: 0.2415
Epoch 7/10, Batch 130/145, Loss: 0.1596
Epoch 7/10, Batch 140/145, Loss: 0.1859
Epoch 7/10, Train Loss: 0.2158, Valid Loss: 0.2342
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2233
Epoch 8/10, Batch 20/145, Loss: 0.2554
Epoch 8/10, Batch 30/145, Loss: 0.2460
Epoch 8/10, Batch 40/145, Loss: 0.4346
Epoch 8/10, Batch 50/145, Loss: 0.3304
Epoch 8/10, Batch 60/145, Loss: 0.2639
Epoch 8/10, Batch 70/145, Loss: 0.3536
Epoch 8/10, Batch 80/145, Loss: 0.1132
Epoch 8/10, Batch 90/145, Loss: 0.3228
Epoch 8/10, Batch 100/145, Loss: 0.2164
Epoch 8/10, Batch 110/145, Loss: 0.1348
Epoch 8/10, Batch 120/145, Loss: 0.1186
Epoch 8/10, Batch 130/145, Loss: 0.1147
Epoch 8/10, Batch 140/145, Loss: 0.1192
Epoch 8/10, Train Loss: 0.2065, Valid Loss: 0.2319
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1730
Epoch 9/10, Batch 20/145, Loss: 0.2194
Epoch 9/10, Batch 30/145, Loss: 0.2607
Epoch 9/10, Batch 40/145, Loss: 0.2367
Epoch 9/10, Batch 50/145, Loss: 0.2510
Epoch 9/10, Batch 60/145, Loss: 0.2189
Epoch 9/10, Batch 70/145, Loss: 0.3033
Epoch 9/10, Batch 80/145, Loss: 0.1123
Epoch 9/10, Batch 90/145, Loss: 0.1850
Epoch 9/10, Batch 100/145, Loss: 0.1841
Epoch 9/10, Batch 110/145, Loss: 0.2311
Epoch 9/10, Batch 120/145, Loss: 0.2212
Epoch 9/10, Batch 130/145, Loss: 0.2513
Epoch 9/10, Batch 140/145, Loss: 0.2042
Epoch 9/10, Train Loss: 0.2022, Valid Loss: 0.2282
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1619
Epoch 10/10, Batch 20/145, Loss: 0.1327
Epoch 10/10, Batch 30/145, Loss: 0.2434
Epoch 10/10, Batch 40/145, Loss: 0.0888
Epoch 10/10, Batch 50/145, Loss: 0.3221
Epoch 10/10, Batch 60/145, Loss: 0.2410
Epoch 10/10, Batch 70/145, Loss: 0.3689
Epoch 10/10, Batch 80/145, Loss: 0.2397
Epoch 10/10, Batch 90/145, Loss: 0.2469
Epoch 10/10, Batch 100/145, Loss: 0.1717
Epoch 10/10, Batch 110/145, Loss: 0.1498
Epoch 10/10, Batch 120/145, Loss: 0.3446
Epoch 10/10, Batch 130/145, Loss: 0.1201
Epoch 10/10, Batch 140/145, Loss: 0.2605
Epoch 10/10, Train Loss: 0.2009, Valid Loss: 0.2224
Model saved!
Accuracy: 0.9182
Precision: 0.9155
Recall: 0.9182
F1-score: 0.9163
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4068
Epoch 1/10, Batch 20/145, Loss: 0.9350
Epoch 1/10, Batch 30/145, Loss: 0.8364
Epoch 1/10, Batch 40/145, Loss: 0.7350
Epoch 1/10, Batch 50/145, Loss: 0.6543
Epoch 1/10, Batch 60/145, Loss: 0.6273
Epoch 1/10, Batch 70/145, Loss: 0.5090
Epoch 1/10, Batch 80/145, Loss: 0.5802
Epoch 1/10, Batch 90/145, Loss: 0.4590
Epoch 1/10, Batch 100/145, Loss: 0.5148
Epoch 1/10, Batch 110/145, Loss: 0.5330
Epoch 1/10, Batch 120/145, Loss: 0.5954
Epoch 1/10, Batch 130/145, Loss: 0.5714
Epoch 1/10, Batch 140/145, Loss: 0.2970
Epoch 1/10, Train Loss: 0.6774, Valid Loss: 0.3710
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3020
Epoch 2/10, Batch 20/145, Loss: 0.2951
Epoch 2/10, Batch 30/145, Loss: 0.3991
Epoch 2/10, Batch 40/145, Loss: 0.5026
Epoch 2/10, Batch 50/145, Loss: 0.2909
Epoch 2/10, Batch 60/145, Loss: 0.3628
Epoch 2/10, Batch 70/145, Loss: 0.3104
Epoch 2/10, Batch 80/145, Loss: 0.2978
Epoch 2/10, Batch 90/145, Loss: 0.3249
Epoch 2/10, Batch 100/145, Loss: 0.2464
Epoch 2/10, Batch 110/145, Loss: 0.3600
Epoch 2/10, Batch 120/145, Loss: 0.4504
Epoch 2/10, Batch 130/145, Loss: 0.3788
Epoch 2/10, Batch 140/145, Loss: 0.2280
Epoch 2/10, Train Loss: 0.3501, Valid Loss: 0.2892
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2785
Epoch 3/10, Batch 20/145, Loss: 0.3376
Epoch 3/10, Batch 30/145, Loss: 0.2982
Epoch 3/10, Batch 40/145, Loss: 0.3205
Epoch 3/10, Batch 50/145, Loss: 0.2084
Epoch 3/10, Batch 60/145, Loss: 0.2568
Epoch 3/10, Batch 70/145, Loss: 0.3114
Epoch 3/10, Batch 80/145, Loss: 0.2604
Epoch 3/10, Batch 90/145, Loss: 0.3532
Epoch 3/10, Batch 100/145, Loss: 0.2643
Epoch 3/10, Batch 110/145, Loss: 0.3421
Epoch 3/10, Batch 120/145, Loss: 0.1516
Epoch 3/10, Batch 130/145, Loss: 0.2457
Epoch 3/10, Batch 140/145, Loss: 0.1720
Epoch 3/10, Train Loss: 0.2900, Valid Loss: 0.2587
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2190
Epoch 4/10, Batch 20/145, Loss: 0.2272
Epoch 4/10, Batch 30/145, Loss: 0.1455
Epoch 4/10, Batch 40/145, Loss: 0.1399
Epoch 4/10, Batch 50/145, Loss: 0.3087
Epoch 4/10, Batch 60/145, Loss: 0.4380
Epoch 4/10, Batch 70/145, Loss: 0.2111
Epoch 4/10, Batch 80/145, Loss: 0.1300
Epoch 4/10, Batch 90/145, Loss: 0.2729
Epoch 4/10, Batch 100/145, Loss: 0.1520
Epoch 4/10, Batch 110/145, Loss: 0.1049
Epoch 4/10, Batch 120/145, Loss: 0.2135
Epoch 4/10, Batch 130/145, Loss: 0.2125
Epoch 4/10, Batch 140/145, Loss: 0.1365
Epoch 4/10, Train Loss: 0.2534, Valid Loss: 0.2504
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1863
Epoch 5/10, Batch 20/145, Loss: 0.1791
Epoch 5/10, Batch 30/145, Loss: 0.4123
Epoch 5/10, Batch 40/145, Loss: 0.1270
Epoch 5/10, Batch 50/145, Loss: 0.1625
Epoch 5/10, Batch 60/145, Loss: 0.1734
Epoch 5/10, Batch 70/145, Loss: 0.1977
Epoch 5/10, Batch 80/145, Loss: 0.1415
Epoch 5/10, Batch 90/145, Loss: 0.2773
Epoch 5/10, Batch 100/145, Loss: 0.2322
Epoch 5/10, Batch 110/145, Loss: 0.2963
Epoch 5/10, Batch 120/145, Loss: 0.1764
Epoch 5/10, Batch 130/145, Loss: 0.1715
Epoch 5/10, Batch 140/145, Loss: 0.1236
Epoch 5/10, Train Loss: 0.2405, Valid Loss: 0.2389
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1587
Epoch 6/10, Batch 20/145, Loss: 0.2840
Epoch 6/10, Batch 30/145, Loss: 0.4067
Epoch 6/10, Batch 40/145, Loss: 0.1562
Epoch 6/10, Batch 50/145, Loss: 0.2366
Epoch 6/10, Batch 60/145, Loss: 0.3195
Epoch 6/10, Batch 70/145, Loss: 0.1412
Epoch 6/10, Batch 80/145, Loss: 0.1339
Epoch 6/10, Batch 90/145, Loss: 0.2038
Epoch 6/10, Batch 100/145, Loss: 0.4435
Epoch 6/10, Batch 110/145, Loss: 0.2417
Epoch 6/10, Batch 120/145, Loss: 0.3430
Epoch 6/10, Batch 130/145, Loss: 0.2073
Epoch 6/10, Batch 140/145, Loss: 0.3762
Epoch 6/10, Train Loss: 0.2249, Valid Loss: 0.2324
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2278
Epoch 7/10, Batch 20/145, Loss: 0.2253
Epoch 7/10, Batch 30/145, Loss: 0.3759
Epoch 7/10, Batch 40/145, Loss: 0.2456
Epoch 7/10, Batch 50/145, Loss: 0.1124
Epoch 7/10, Batch 60/145, Loss: 0.2543
Epoch 7/10, Batch 70/145, Loss: 0.2012
Epoch 7/10, Batch 80/145, Loss: 0.4295
Epoch 7/10, Batch 90/145, Loss: 0.3312
Epoch 7/10, Batch 100/145, Loss: 0.1869
Epoch 7/10, Batch 110/145, Loss: 0.1601
Epoch 7/10, Batch 120/145, Loss: 0.1705
Epoch 7/10, Batch 130/145, Loss: 0.2108
Epoch 7/10, Batch 140/145, Loss: 0.2411
Epoch 7/10, Train Loss: 0.2120, Valid Loss: 0.2247
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1357
Epoch 8/10, Batch 20/145, Loss: 0.1303
Epoch 8/10, Batch 30/145, Loss: 0.1958
Epoch 8/10, Batch 40/145, Loss: 0.1147
Epoch 8/10, Batch 50/145, Loss: 0.2606
Epoch 8/10, Batch 60/145, Loss: 0.1375
Epoch 8/10, Batch 70/145, Loss: 0.2685
Epoch 8/10, Batch 80/145, Loss: 0.1686
Epoch 8/10, Batch 90/145, Loss: 0.4186
Epoch 8/10, Batch 100/145, Loss: 0.2480
Epoch 8/10, Batch 110/145, Loss: 0.4426
Epoch 8/10, Batch 120/145, Loss: 0.1166
Epoch 8/10, Batch 130/145, Loss: 0.3518
Epoch 8/10, Batch 140/145, Loss: 0.2650
Epoch 8/10, Train Loss: 0.2064, Valid Loss: 0.2195
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2010
Epoch 9/10, Batch 20/145, Loss: 0.2267
Epoch 9/10, Batch 30/145, Loss: 0.2713
Epoch 9/10, Batch 40/145, Loss: 0.2140
Epoch 9/10, Batch 50/145, Loss: 0.1440
Epoch 9/10, Batch 60/145, Loss: 0.0967
Epoch 9/10, Batch 70/145, Loss: 0.2436
Epoch 9/10, Batch 80/145, Loss: 0.0731
Epoch 9/10, Batch 90/145, Loss: 0.2735
Epoch 9/10, Batch 100/145, Loss: 0.1192
Epoch 9/10, Batch 110/145, Loss: 0.2387
Epoch 9/10, Batch 120/145, Loss: 0.1218
Epoch 9/10, Batch 130/145, Loss: 0.1255
Epoch 9/10, Batch 140/145, Loss: 0.1852
Epoch 9/10, Train Loss: 0.1925, Valid Loss: 0.2237
Epoch 10/10, Batch 10/145, Loss: 0.2366
Epoch 10/10, Batch 20/145, Loss: 0.1419
Epoch 10/10, Batch 30/145, Loss: 0.1907
Epoch 10/10, Batch 40/145, Loss: 0.1337
Epoch 10/10, Batch 50/145, Loss: 0.1692
Epoch 10/10, Batch 60/145, Loss: 0.1330
Epoch 10/10, Batch 70/145, Loss: 0.4007
Epoch 10/10, Batch 80/145, Loss: 0.1561
Epoch 10/10, Batch 90/145, Loss: 0.1034
Epoch 10/10, Batch 100/145, Loss: 0.1520
Epoch 10/10, Batch 110/145, Loss: 0.1530
Epoch 10/10, Batch 120/145, Loss: 0.2200
Epoch 10/10, Batch 130/145, Loss: 0.1709
Epoch 10/10, Batch 140/145, Loss: 0.1309
Epoch 10/10, Train Loss: 0.1894, Valid Loss: 0.2142
Model saved!
Accuracy: 0.9194
Precision: 0.9169
Recall: 0.9194
F1-score: 0.9174
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4189
Epoch 1/10, Batch 20/145, Loss: 0.9851
Epoch 1/10, Batch 30/145, Loss: 0.8968
Epoch 1/10, Batch 40/145, Loss: 0.6662
Epoch 1/10, Batch 50/145, Loss: 0.7228
Epoch 1/10, Batch 60/145, Loss: 0.5191
Epoch 1/10, Batch 70/145, Loss: 0.3642
Epoch 1/10, Batch 80/145, Loss: 0.6386
Epoch 1/10, Batch 90/145, Loss: 0.4474
Epoch 1/10, Batch 100/145, Loss: 0.4857
Epoch 1/10, Batch 110/145, Loss: 0.3706
Epoch 1/10, Batch 120/145, Loss: 0.5687
Epoch 1/10, Batch 130/145, Loss: 0.5170
Epoch 1/10, Batch 140/145, Loss: 0.5359
Epoch 1/10, Train Loss: 0.6745, Valid Loss: 0.3664
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3668
Epoch 2/10, Batch 20/145, Loss: 0.2893
Epoch 2/10, Batch 30/145, Loss: 0.4541
Epoch 2/10, Batch 40/145, Loss: 0.4309
Epoch 2/10, Batch 50/145, Loss: 0.3577
Epoch 2/10, Batch 60/145, Loss: 0.3652
Epoch 2/10, Batch 70/145, Loss: 0.3046
Epoch 2/10, Batch 80/145, Loss: 0.3057
Epoch 2/10, Batch 90/145, Loss: 0.3034
Epoch 2/10, Batch 100/145, Loss: 0.2417
Epoch 2/10, Batch 110/145, Loss: 0.4038
Epoch 2/10, Batch 120/145, Loss: 0.4198
Epoch 2/10, Batch 130/145, Loss: 0.3418
Epoch 2/10, Batch 140/145, Loss: 0.2259
Epoch 2/10, Train Loss: 0.3568, Valid Loss: 0.2854
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3791
Epoch 3/10, Batch 20/145, Loss: 0.3241
Epoch 3/10, Batch 30/145, Loss: 0.3315
Epoch 3/10, Batch 40/145, Loss: 0.2527
Epoch 3/10, Batch 50/145, Loss: 0.2339
Epoch 3/10, Batch 60/145, Loss: 0.4070
Epoch 3/10, Batch 70/145, Loss: 0.2419
Epoch 3/10, Batch 80/145, Loss: 0.3900
Epoch 3/10, Batch 90/145, Loss: 0.2781
Epoch 3/10, Batch 100/145, Loss: 0.2085
Epoch 3/10, Batch 110/145, Loss: 0.2660
Epoch 3/10, Batch 120/145, Loss: 0.3166
Epoch 3/10, Batch 130/145, Loss: 0.4361
Epoch 3/10, Batch 140/145, Loss: 0.3943
Epoch 3/10, Train Loss: 0.2931, Valid Loss: 0.2534
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2607
Epoch 4/10, Batch 20/145, Loss: 0.5000
Epoch 4/10, Batch 30/145, Loss: 0.3324
Epoch 4/10, Batch 40/145, Loss: 0.1547
Epoch 4/10, Batch 50/145, Loss: 0.1523
Epoch 4/10, Batch 60/145, Loss: 0.2799
Epoch 4/10, Batch 70/145, Loss: 0.2906
Epoch 4/10, Batch 80/145, Loss: 0.2122
Epoch 4/10, Batch 90/145, Loss: 0.3686
Epoch 4/10, Batch 100/145, Loss: 0.3489
Epoch 4/10, Batch 110/145, Loss: 0.1257
Epoch 4/10, Batch 120/145, Loss: 0.2372
Epoch 4/10, Batch 130/145, Loss: 0.1460
Epoch 4/10, Batch 140/145, Loss: 0.1496
Epoch 4/10, Train Loss: 0.2597, Valid Loss: 0.2380
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2167
Epoch 5/10, Batch 20/145, Loss: 0.1499
Epoch 5/10, Batch 30/145, Loss: 0.1150
Epoch 5/10, Batch 40/145, Loss: 0.1253
Epoch 5/10, Batch 50/145, Loss: 0.1383
Epoch 5/10, Batch 60/145, Loss: 0.2050
Epoch 5/10, Batch 70/145, Loss: 0.1748
Epoch 5/10, Batch 80/145, Loss: 0.2545
Epoch 5/10, Batch 90/145, Loss: 0.4146
Epoch 5/10, Batch 100/145, Loss: 0.2733
Epoch 5/10, Batch 110/145, Loss: 0.0849
Epoch 5/10, Batch 120/145, Loss: 0.4876
Epoch 5/10, Batch 130/145, Loss: 0.2096
Epoch 5/10, Batch 140/145, Loss: 0.1771
Epoch 5/10, Train Loss: 0.2454, Valid Loss: 0.2341
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2730
Epoch 6/10, Batch 20/145, Loss: 0.5198
Epoch 6/10, Batch 30/145, Loss: 0.4534
Epoch 6/10, Batch 40/145, Loss: 0.2282
Epoch 6/10, Batch 50/145, Loss: 0.2880
Epoch 6/10, Batch 60/145, Loss: 0.1378
Epoch 6/10, Batch 70/145, Loss: 0.1524
Epoch 6/10, Batch 80/145, Loss: 0.2375
Epoch 6/10, Batch 90/145, Loss: 0.3576
Epoch 6/10, Batch 100/145, Loss: 0.1897
Epoch 6/10, Batch 110/145, Loss: 0.1690
Epoch 6/10, Batch 120/145, Loss: 0.3921
Epoch 6/10, Batch 130/145, Loss: 0.1514
Epoch 6/10, Batch 140/145, Loss: 0.1462
Epoch 6/10, Train Loss: 0.2286, Valid Loss: 0.2235
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1907
Epoch 7/10, Batch 20/145, Loss: 0.2523
Epoch 7/10, Batch 30/145, Loss: 0.3248
Epoch 7/10, Batch 40/145, Loss: 0.3596
Epoch 7/10, Batch 50/145, Loss: 0.1725
Epoch 7/10, Batch 60/145, Loss: 0.1302
Epoch 7/10, Batch 70/145, Loss: 0.1508
Epoch 7/10, Batch 80/145, Loss: 0.3955
Epoch 7/10, Batch 90/145, Loss: 0.3016
Epoch 7/10, Batch 100/145, Loss: 0.1863
Epoch 7/10, Batch 110/145, Loss: 0.2708
Epoch 7/10, Batch 120/145, Loss: 0.2073
Epoch 7/10, Batch 130/145, Loss: 0.1154
Epoch 7/10, Batch 140/145, Loss: 0.3050
Epoch 7/10, Train Loss: 0.2117, Valid Loss: 0.2168
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2030
Epoch 8/10, Batch 20/145, Loss: 0.3540
Epoch 8/10, Batch 30/145, Loss: 0.2606
Epoch 8/10, Batch 40/145, Loss: 0.2007
Epoch 8/10, Batch 50/145, Loss: 0.1124
Epoch 8/10, Batch 60/145, Loss: 0.2199
Epoch 8/10, Batch 70/145, Loss: 0.4444
Epoch 8/10, Batch 80/145, Loss: 0.3224
Epoch 8/10, Batch 90/145, Loss: 0.2020
Epoch 8/10, Batch 100/145, Loss: 0.3452
Epoch 8/10, Batch 110/145, Loss: 0.3282
Epoch 8/10, Batch 120/145, Loss: 0.1990
Epoch 8/10, Batch 130/145, Loss: 0.1118
Epoch 8/10, Batch 140/145, Loss: 0.2894
Epoch 8/10, Train Loss: 0.2079, Valid Loss: 0.2148
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.4261
Epoch 9/10, Batch 20/145, Loss: 0.2308
Epoch 9/10, Batch 30/145, Loss: 0.2806
Epoch 9/10, Batch 40/145, Loss: 0.2277
Epoch 9/10, Batch 50/145, Loss: 0.1496
Epoch 9/10, Batch 60/145, Loss: 0.1401
Epoch 9/10, Batch 70/145, Loss: 0.1013
Epoch 9/10, Batch 80/145, Loss: 0.1878
Epoch 9/10, Batch 90/145, Loss: 0.1475
Epoch 9/10, Batch 100/145, Loss: 0.2175
Epoch 9/10, Batch 110/145, Loss: 0.2409
Epoch 9/10, Batch 120/145, Loss: 0.1594
Epoch 9/10, Batch 130/145, Loss: 0.2855
Epoch 9/10, Batch 140/145, Loss: 0.3166
Epoch 9/10, Train Loss: 0.2034, Valid Loss: 0.2128
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0567
Epoch 10/10, Batch 20/145, Loss: 0.2481
Epoch 10/10, Batch 30/145, Loss: 0.1717
Epoch 10/10, Batch 40/145, Loss: 0.1480
Epoch 10/10, Batch 50/145, Loss: 0.2024
Epoch 10/10, Batch 60/145, Loss: 0.1272
Epoch 10/10, Batch 70/145, Loss: 0.2621
Epoch 10/10, Batch 80/145, Loss: 0.3034
Epoch 10/10, Batch 90/145, Loss: 0.0883
Epoch 10/10, Batch 100/145, Loss: 0.2828
Epoch 10/10, Batch 110/145, Loss: 0.1336
Epoch 10/10, Batch 120/145, Loss: 0.1921
Epoch 10/10, Batch 130/145, Loss: 0.1036
Epoch 10/10, Batch 140/145, Loss: 0.2682
Epoch 10/10, Train Loss: 0.1979, Valid Loss: 0.2077
Model saved!
Accuracy: 0.9112
Precision: 0.9080
Recall: 0.9112
F1-score: 0.9082
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3820
Epoch 1/10, Batch 20/145, Loss: 0.9599
Epoch 1/10, Batch 30/145, Loss: 0.9085
Epoch 1/10, Batch 40/145, Loss: 0.7743
Epoch 1/10, Batch 50/145, Loss: 0.6553
Epoch 1/10, Batch 60/145, Loss: 0.5247
Epoch 1/10, Batch 70/145, Loss: 0.4609
Epoch 1/10, Batch 80/145, Loss: 0.5748
Epoch 1/10, Batch 90/145, Loss: 0.3680
Epoch 1/10, Batch 100/145, Loss: 0.4886
Epoch 1/10, Batch 110/145, Loss: 0.4533
Epoch 1/10, Batch 120/145, Loss: 0.7002
Epoch 1/10, Batch 130/145, Loss: 0.6386
Epoch 1/10, Batch 140/145, Loss: 0.4585
Epoch 1/10, Train Loss: 0.6854, Valid Loss: 0.3942
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3801
Epoch 2/10, Batch 20/145, Loss: 0.3855
Epoch 2/10, Batch 30/145, Loss: 0.2646
Epoch 2/10, Batch 40/145, Loss: 0.3566
Epoch 2/10, Batch 50/145, Loss: 0.2300
Epoch 2/10, Batch 60/145, Loss: 0.3361
Epoch 2/10, Batch 70/145, Loss: 0.3971
Epoch 2/10, Batch 80/145, Loss: 0.2498
Epoch 2/10, Batch 90/145, Loss: 0.3011
Epoch 2/10, Batch 100/145, Loss: 0.3309
Epoch 2/10, Batch 110/145, Loss: 0.3408
Epoch 2/10, Batch 120/145, Loss: 0.2584
Epoch 2/10, Batch 130/145, Loss: 0.2728
Epoch 2/10, Batch 140/145, Loss: 0.3625
Epoch 2/10, Train Loss: 0.3563, Valid Loss: 0.3002
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2555
Epoch 3/10, Batch 20/145, Loss: 0.2450
Epoch 3/10, Batch 30/145, Loss: 0.2567
Epoch 3/10, Batch 40/145, Loss: 0.2387
Epoch 3/10, Batch 50/145, Loss: 0.2831
Epoch 3/10, Batch 60/145, Loss: 0.2968
Epoch 3/10, Batch 70/145, Loss: 0.3249
Epoch 3/10, Batch 80/145, Loss: 0.2475
Epoch 3/10, Batch 90/145, Loss: 0.3143
Epoch 3/10, Batch 100/145, Loss: 0.2748
Epoch 3/10, Batch 110/145, Loss: 0.2068
Epoch 3/10, Batch 120/145, Loss: 0.2000
Epoch 3/10, Batch 130/145, Loss: 0.3216
Epoch 3/10, Batch 140/145, Loss: 0.2104
Epoch 3/10, Train Loss: 0.2911, Valid Loss: 0.2687
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2982
Epoch 4/10, Batch 20/145, Loss: 0.3047
Epoch 4/10, Batch 30/145, Loss: 0.2986
Epoch 4/10, Batch 40/145, Loss: 0.2248
Epoch 4/10, Batch 50/145, Loss: 0.2365
Epoch 4/10, Batch 60/145, Loss: 0.2121
Epoch 4/10, Batch 70/145, Loss: 0.1257
Epoch 4/10, Batch 80/145, Loss: 0.1732
Epoch 4/10, Batch 90/145, Loss: 0.3596
Epoch 4/10, Batch 100/145, Loss: 0.2520
Epoch 4/10, Batch 110/145, Loss: 0.2177
Epoch 4/10, Batch 120/145, Loss: 0.2878
Epoch 4/10, Batch 130/145, Loss: 0.1766
Epoch 4/10, Batch 140/145, Loss: 0.1476
Epoch 4/10, Train Loss: 0.2542, Valid Loss: 0.2557
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1804
Epoch 5/10, Batch 20/145, Loss: 0.1298
Epoch 5/10, Batch 30/145, Loss: 0.3470
Epoch 5/10, Batch 40/145, Loss: 0.2364
Epoch 5/10, Batch 50/145, Loss: 0.2074
Epoch 5/10, Batch 60/145, Loss: 0.2055
Epoch 5/10, Batch 70/145, Loss: 0.2957
Epoch 5/10, Batch 80/145, Loss: 0.2097
Epoch 5/10, Batch 90/145, Loss: 0.2860
Epoch 5/10, Batch 100/145, Loss: 0.1734
Epoch 5/10, Batch 110/145, Loss: 0.1659
Epoch 5/10, Batch 120/145, Loss: 0.3217
Epoch 5/10, Batch 130/145, Loss: 0.2369
Epoch 5/10, Batch 140/145, Loss: 0.2023
Epoch 5/10, Train Loss: 0.2395, Valid Loss: 0.2393
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2661
Epoch 6/10, Batch 20/145, Loss: 0.4415
Epoch 6/10, Batch 30/145, Loss: 0.1717
Epoch 6/10, Batch 40/145, Loss: 0.1722
Epoch 6/10, Batch 50/145, Loss: 0.3781
Epoch 6/10, Batch 60/145, Loss: 0.1739
Epoch 6/10, Batch 70/145, Loss: 0.1287
Epoch 6/10, Batch 80/145, Loss: 0.1460
Epoch 6/10, Batch 90/145, Loss: 0.3157
Epoch 6/10, Batch 100/145, Loss: 0.1343
Epoch 6/10, Batch 110/145, Loss: 0.3317
Epoch 6/10, Batch 120/145, Loss: 0.5004
Epoch 6/10, Batch 130/145, Loss: 0.1409
Epoch 6/10, Batch 140/145, Loss: 0.1256
Epoch 6/10, Train Loss: 0.2250, Valid Loss: 0.2323
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3336
Epoch 7/10, Batch 20/145, Loss: 0.2039
Epoch 7/10, Batch 30/145, Loss: 0.1334
Epoch 7/10, Batch 40/145, Loss: 0.4111
Epoch 7/10, Batch 50/145, Loss: 0.2526
Epoch 7/10, Batch 60/145, Loss: 0.2303
Epoch 7/10, Batch 70/145, Loss: 0.2749
Epoch 7/10, Batch 80/145, Loss: 0.4849
Epoch 7/10, Batch 90/145, Loss: 0.1228
Epoch 7/10, Batch 100/145, Loss: 0.3898
Epoch 7/10, Batch 110/145, Loss: 0.2355
Epoch 7/10, Batch 120/145, Loss: 0.1857
Epoch 7/10, Batch 130/145, Loss: 0.0905
Epoch 7/10, Batch 140/145, Loss: 0.1152
Epoch 7/10, Train Loss: 0.2161, Valid Loss: 0.2230
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1950
Epoch 8/10, Batch 20/145, Loss: 0.1541
Epoch 8/10, Batch 30/145, Loss: 0.2283
Epoch 8/10, Batch 40/145, Loss: 0.2822
Epoch 8/10, Batch 50/145, Loss: 0.2391
Epoch 8/10, Batch 60/145, Loss: 0.1649
Epoch 8/10, Batch 70/145, Loss: 0.2133
Epoch 8/10, Batch 80/145, Loss: 0.2814
Epoch 8/10, Batch 90/145, Loss: 0.2269
Epoch 8/10, Batch 100/145, Loss: 0.4324
Epoch 8/10, Batch 110/145, Loss: 0.2379
Epoch 8/10, Batch 120/145, Loss: 0.1169
Epoch 8/10, Batch 130/145, Loss: 0.1461
Epoch 8/10, Batch 140/145, Loss: 0.2262
Epoch 8/10, Train Loss: 0.2087, Valid Loss: 0.2229
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3672
Epoch 9/10, Batch 20/145, Loss: 0.2193
Epoch 9/10, Batch 30/145, Loss: 0.1756
Epoch 9/10, Batch 40/145, Loss: 0.1598
Epoch 9/10, Batch 50/145, Loss: 0.1587
Epoch 9/10, Batch 60/145, Loss: 0.2330
Epoch 9/10, Batch 70/145, Loss: 0.2102
Epoch 9/10, Batch 80/145, Loss: 0.0862
Epoch 9/10, Batch 90/145, Loss: 0.2590
Epoch 9/10, Batch 100/145, Loss: 0.1391
Epoch 9/10, Batch 110/145, Loss: 0.2310
Epoch 9/10, Batch 120/145, Loss: 0.2136
Epoch 9/10, Batch 130/145, Loss: 0.2702
Epoch 9/10, Batch 140/145, Loss: 0.2470
Epoch 9/10, Train Loss: 0.1932, Valid Loss: 0.2169
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1384
Epoch 10/10, Batch 20/145, Loss: 0.2004
Epoch 10/10, Batch 30/145, Loss: 0.1925
Epoch 10/10, Batch 40/145, Loss: 0.0699
Epoch 10/10, Batch 50/145, Loss: 0.1955
Epoch 10/10, Batch 60/145, Loss: 0.0736
Epoch 10/10, Batch 70/145, Loss: 0.1867
Epoch 10/10, Batch 80/145, Loss: 0.1336
Epoch 10/10, Batch 90/145, Loss: 0.1113
Epoch 10/10, Batch 100/145, Loss: 0.1667
Epoch 10/10, Batch 110/145, Loss: 0.2618
Epoch 10/10, Batch 120/145, Loss: 0.3160
Epoch 10/10, Batch 130/145, Loss: 0.1306
Epoch 10/10, Batch 140/145, Loss: 0.2799
Epoch 10/10, Train Loss: 0.1928, Valid Loss: 0.2180
Accuracy: 0.9229
Precision: 0.9210
Recall: 0.9229
F1-score: 0.9217
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3905
Epoch 1/10, Batch 20/145, Loss: 0.8700
Epoch 1/10, Batch 30/145, Loss: 0.9169
Epoch 1/10, Batch 40/145, Loss: 0.7680
Epoch 1/10, Batch 50/145, Loss: 0.7812
Epoch 1/10, Batch 60/145, Loss: 0.7024
Epoch 1/10, Batch 70/145, Loss: 0.3493
Epoch 1/10, Batch 80/145, Loss: 0.6584
Epoch 1/10, Batch 90/145, Loss: 0.5288
Epoch 1/10, Batch 100/145, Loss: 0.4819
Epoch 1/10, Batch 110/145, Loss: 0.5474
Epoch 1/10, Batch 120/145, Loss: 0.6187
Epoch 1/10, Batch 130/145, Loss: 0.4607
Epoch 1/10, Batch 140/145, Loss: 0.3519
Epoch 1/10, Train Loss: 0.6831, Valid Loss: 0.3899
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2938
Epoch 2/10, Batch 20/145, Loss: 0.3002
Epoch 2/10, Batch 30/145, Loss: 0.2330
Epoch 2/10, Batch 40/145, Loss: 0.5160
Epoch 2/10, Batch 50/145, Loss: 0.3483
Epoch 2/10, Batch 60/145, Loss: 0.3716
Epoch 2/10, Batch 70/145, Loss: 0.3000
Epoch 2/10, Batch 80/145, Loss: 0.2949
Epoch 2/10, Batch 90/145, Loss: 0.3936
Epoch 2/10, Batch 100/145, Loss: 0.3632
Epoch 2/10, Batch 110/145, Loss: 0.3335
Epoch 2/10, Batch 120/145, Loss: 0.4117
Epoch 2/10, Batch 130/145, Loss: 0.3702
Epoch 2/10, Batch 140/145, Loss: 0.3331
Epoch 2/10, Train Loss: 0.3549, Valid Loss: 0.3098
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2685
Epoch 3/10, Batch 20/145, Loss: 0.2774
Epoch 3/10, Batch 30/145, Loss: 0.3287
Epoch 3/10, Batch 40/145, Loss: 0.1843
Epoch 3/10, Batch 50/145, Loss: 0.2929
Epoch 3/10, Batch 60/145, Loss: 0.5538
Epoch 3/10, Batch 70/145, Loss: 0.4211
Epoch 3/10, Batch 80/145, Loss: 0.4195
Epoch 3/10, Batch 90/145, Loss: 0.1436
Epoch 3/10, Batch 100/145, Loss: 0.2508
Epoch 3/10, Batch 110/145, Loss: 0.2035
Epoch 3/10, Batch 120/145, Loss: 0.1553
Epoch 3/10, Batch 130/145, Loss: 0.4023
Epoch 3/10, Batch 140/145, Loss: 0.2327
Epoch 3/10, Train Loss: 0.2956, Valid Loss: 0.2685
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2511
Epoch 4/10, Batch 20/145, Loss: 0.2527
Epoch 4/10, Batch 30/145, Loss: 0.2491
Epoch 4/10, Batch 40/145, Loss: 0.1104
Epoch 4/10, Batch 50/145, Loss: 0.1759
Epoch 4/10, Batch 60/145, Loss: 0.1366
Epoch 4/10, Batch 70/145, Loss: 0.2598
Epoch 4/10, Batch 80/145, Loss: 0.1328
Epoch 4/10, Batch 90/145, Loss: 0.2324
Epoch 4/10, Batch 100/145, Loss: 0.4692
Epoch 4/10, Batch 110/145, Loss: 0.1287
Epoch 4/10, Batch 120/145, Loss: 0.1279
Epoch 4/10, Batch 130/145, Loss: 0.1617
Epoch 4/10, Batch 140/145, Loss: 0.1882
Epoch 4/10, Train Loss: 0.2583, Valid Loss: 0.2585
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1925
Epoch 5/10, Batch 20/145, Loss: 0.0724
Epoch 5/10, Batch 30/145, Loss: 0.1928
Epoch 5/10, Batch 40/145, Loss: 0.2354
Epoch 5/10, Batch 50/145, Loss: 0.2481
Epoch 5/10, Batch 60/145, Loss: 0.2676
Epoch 5/10, Batch 70/145, Loss: 0.3006
Epoch 5/10, Batch 80/145, Loss: 0.3381
Epoch 5/10, Batch 90/145, Loss: 0.2896
Epoch 5/10, Batch 100/145, Loss: 0.1691
Epoch 5/10, Batch 110/145, Loss: 0.3151
Epoch 5/10, Batch 120/145, Loss: 0.1848
Epoch 5/10, Batch 130/145, Loss: 0.1148
Epoch 5/10, Batch 140/145, Loss: 0.2969
Epoch 5/10, Train Loss: 0.2498, Valid Loss: 0.2489
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1874
Epoch 6/10, Batch 20/145, Loss: 0.4542
Epoch 6/10, Batch 30/145, Loss: 0.1974
Epoch 6/10, Batch 40/145, Loss: 0.2406
Epoch 6/10, Batch 50/145, Loss: 0.2778
Epoch 6/10, Batch 60/145, Loss: 0.1993
Epoch 6/10, Batch 70/145, Loss: 0.0784
Epoch 6/10, Batch 80/145, Loss: 0.1153
Epoch 6/10, Batch 90/145, Loss: 0.3204
Epoch 6/10, Batch 100/145, Loss: 0.2269
Epoch 6/10, Batch 110/145, Loss: 0.2507
Epoch 6/10, Batch 120/145, Loss: 0.1930
Epoch 6/10, Batch 130/145, Loss: 0.1996
Epoch 6/10, Batch 140/145, Loss: 0.1531
Epoch 6/10, Train Loss: 0.2288, Valid Loss: 0.2318
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2888
Epoch 7/10, Batch 20/145, Loss: 0.3799
Epoch 7/10, Batch 30/145, Loss: 0.2237
Epoch 7/10, Batch 40/145, Loss: 0.4573
Epoch 7/10, Batch 50/145, Loss: 0.2566
Epoch 7/10, Batch 60/145, Loss: 0.1943
Epoch 7/10, Batch 70/145, Loss: 0.1152
Epoch 7/10, Batch 80/145, Loss: 0.4430
Epoch 7/10, Batch 90/145, Loss: 0.2052
Epoch 7/10, Batch 100/145, Loss: 0.2630
Epoch 7/10, Batch 110/145, Loss: 0.1248
Epoch 7/10, Batch 120/145, Loss: 0.3426
Epoch 7/10, Batch 130/145, Loss: 0.1190
Epoch 7/10, Batch 140/145, Loss: 0.2125
Epoch 7/10, Train Loss: 0.2152, Valid Loss: 0.2276
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1893
Epoch 8/10, Batch 20/145, Loss: 0.2571
Epoch 8/10, Batch 30/145, Loss: 0.2627
Epoch 8/10, Batch 40/145, Loss: 0.1288
Epoch 8/10, Batch 50/145, Loss: 0.1461
Epoch 8/10, Batch 60/145, Loss: 0.1322
Epoch 8/10, Batch 70/145, Loss: 0.2253
Epoch 8/10, Batch 80/145, Loss: 0.1401
Epoch 8/10, Batch 90/145, Loss: 0.1792
Epoch 8/10, Batch 100/145, Loss: 0.1248
Epoch 8/10, Batch 110/145, Loss: 0.3099
Epoch 8/10, Batch 120/145, Loss: 0.1777
Epoch 8/10, Batch 130/145, Loss: 0.1548
Epoch 8/10, Batch 140/145, Loss: 0.2120
Epoch 8/10, Train Loss: 0.2154, Valid Loss: 0.2222
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3346
Epoch 9/10, Batch 20/145, Loss: 0.1836
Epoch 9/10, Batch 30/145, Loss: 0.0392
Epoch 9/10, Batch 40/145, Loss: 0.2184
Epoch 9/10, Batch 50/145, Loss: 0.1499
Epoch 9/10, Batch 60/145, Loss: 0.4082
Epoch 9/10, Batch 70/145, Loss: 0.2180
Epoch 9/10, Batch 80/145, Loss: 0.0826
Epoch 9/10, Batch 90/145, Loss: 0.3106
Epoch 9/10, Batch 100/145, Loss: 0.2564
Epoch 9/10, Batch 110/145, Loss: 0.1107
Epoch 9/10, Batch 120/145, Loss: 0.1528
Epoch 9/10, Batch 130/145, Loss: 0.2630
Epoch 9/10, Batch 140/145, Loss: 0.4831
Epoch 9/10, Train Loss: 0.2026, Valid Loss: 0.2209
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1083
Epoch 10/10, Batch 20/145, Loss: 0.2475
Epoch 10/10, Batch 30/145, Loss: 0.1530
Epoch 10/10, Batch 40/145, Loss: 0.1047
Epoch 10/10, Batch 50/145, Loss: 0.1443
Epoch 10/10, Batch 60/145, Loss: 0.1734
Epoch 10/10, Batch 70/145, Loss: 0.3003
Epoch 10/10, Batch 80/145, Loss: 0.1402
Epoch 10/10, Batch 90/145, Loss: 0.1177
Epoch 10/10, Batch 100/145, Loss: 0.1564
Epoch 10/10, Batch 110/145, Loss: 0.3821
Epoch 10/10, Batch 120/145, Loss: 0.1283
Epoch 10/10, Batch 130/145, Loss: 0.1339
Epoch 10/10, Batch 140/145, Loss: 0.2397
Epoch 10/10, Train Loss: 0.1952, Valid Loss: 0.2199
Model saved!
Accuracy: 0.9194
Precision: 0.9176
Recall: 0.9194
F1-score: 0.9179
Memory Allocated after cleanup: 17.76 MB
End time: 2025-02-25 13:05:49.652290
Duration: 12:44:23


Mejor accuracy al acabar el algoritmo: 0.9287


Fitness check:

Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4311
Epoch 1/10, Batch 20/145, Loss: 0.9616
Epoch 1/10, Batch 30/145, Loss: 0.9228
Epoch 1/10, Batch 40/145, Loss: 0.8104
Epoch 1/10, Batch 50/145, Loss: 0.7674
Epoch 1/10, Batch 60/145, Loss: 0.6743
Epoch 1/10, Batch 70/145, Loss: 0.5267
Epoch 1/10, Batch 80/145, Loss: 0.4838
Epoch 1/10, Batch 90/145, Loss: 0.4161
Epoch 1/10, Batch 100/145, Loss: 0.4915
Epoch 1/10, Batch 110/145, Loss: 0.5302
Epoch 1/10, Batch 120/145, Loss: 0.4526
Epoch 1/10, Batch 130/145, Loss: 0.4489
Epoch 1/10, Batch 140/145, Loss: 0.3330
Epoch 1/10, Train Loss: 0.6757, Valid Loss: 0.3925
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3254
Epoch 2/10, Batch 20/145, Loss: 0.3657
Epoch 2/10, Batch 30/145, Loss: 0.3225
Epoch 2/10, Batch 40/145, Loss: 0.5074
Epoch 2/10, Batch 50/145, Loss: 0.4052
Epoch 2/10, Batch 60/145, Loss: 0.3869
Epoch 2/10, Batch 70/145, Loss: 0.1491
Epoch 2/10, Batch 80/145, Loss: 0.1983
Epoch 2/10, Batch 90/145, Loss: 0.2995
Epoch 2/10, Batch 100/145, Loss: 0.5211
Epoch 2/10, Batch 110/145, Loss: 0.3784
Epoch 2/10, Batch 120/145, Loss: 0.3262
Epoch 2/10, Batch 130/145, Loss: 0.3424
Epoch 2/10, Batch 140/145, Loss: 0.3523
Epoch 2/10, Train Loss: 0.3463, Valid Loss: 0.3048
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1783
Epoch 3/10, Batch 20/145, Loss: 0.3113
Epoch 3/10, Batch 30/145, Loss: 0.3218
Epoch 3/10, Batch 40/145, Loss: 0.1774
Epoch 3/10, Batch 50/145, Loss: 0.2810
Epoch 3/10, Batch 60/145, Loss: 0.4806
Epoch 3/10, Batch 70/145, Loss: 0.4032
Epoch 3/10, Batch 80/145, Loss: 0.3846
Epoch 3/10, Batch 90/145, Loss: 0.1837
Epoch 3/10, Batch 100/145, Loss: 0.1875
Epoch 3/10, Batch 110/145, Loss: 0.1858
Epoch 3/10, Batch 120/145, Loss: 0.2611
Epoch 3/10, Batch 130/145, Loss: 0.2033
Epoch 3/10, Batch 140/145, Loss: 0.2345
Epoch 3/10, Train Loss: 0.2906, Valid Loss: 0.2679
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2839
Epoch 4/10, Batch 20/145, Loss: 0.2532
Epoch 4/10, Batch 30/145, Loss: 0.4785
Epoch 4/10, Batch 40/145, Loss: 0.1256
Epoch 4/10, Batch 50/145, Loss: 0.1632
Epoch 4/10, Batch 60/145, Loss: 0.1995
Epoch 4/10, Batch 70/145, Loss: 0.1293
Epoch 4/10, Batch 80/145, Loss: 0.1949
Epoch 4/10, Batch 90/145, Loss: 0.2685
Epoch 4/10, Batch 100/145, Loss: 0.2774
Epoch 4/10, Batch 110/145, Loss: 0.1412
Epoch 4/10, Batch 120/145, Loss: 0.2706
Epoch 4/10, Batch 130/145, Loss: 0.2322
Epoch 4/10, Batch 140/145, Loss: 0.3093
Epoch 4/10, Train Loss: 0.2557, Valid Loss: 0.2555
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2054
Epoch 5/10, Batch 20/145, Loss: 0.1637
Epoch 5/10, Batch 30/145, Loss: 0.1686
Epoch 5/10, Batch 40/145, Loss: 0.1929
Epoch 5/10, Batch 50/145, Loss: 0.2520
Epoch 5/10, Batch 60/145, Loss: 0.1706
Epoch 5/10, Batch 70/145, Loss: 0.1976
Epoch 5/10, Batch 80/145, Loss: 0.1647
Epoch 5/10, Batch 90/145, Loss: 0.2430
Epoch 5/10, Batch 100/145, Loss: 0.2068
Epoch 5/10, Batch 110/145, Loss: 0.1814
Epoch 5/10, Batch 120/145, Loss: 0.4700
Epoch 5/10, Batch 130/145, Loss: 0.1892
Epoch 5/10, Batch 140/145, Loss: 0.2479
Epoch 5/10, Train Loss: 0.2391, Valid Loss: 0.2442
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2076
Epoch 6/10, Batch 20/145, Loss: 0.3134
Epoch 6/10, Batch 30/145, Loss: 0.3248
Epoch 6/10, Batch 40/145, Loss: 0.1981
Epoch 6/10, Batch 50/145, Loss: 0.3375
Epoch 6/10, Batch 60/145, Loss: 0.1895
Epoch 6/10, Batch 70/145, Loss: 0.2050
Epoch 6/10, Batch 80/145, Loss: 0.2170
Epoch 6/10, Batch 90/145, Loss: 0.2125
Epoch 6/10, Batch 100/145, Loss: 0.2354
Epoch 6/10, Batch 110/145, Loss: 0.3546
Epoch 6/10, Batch 120/145, Loss: 0.3845
Epoch 6/10, Batch 130/145, Loss: 0.2488
Epoch 6/10, Batch 140/145, Loss: 0.1860
Epoch 6/10, Train Loss: 0.2267, Valid Loss: 0.2378
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1839
Epoch 7/10, Batch 20/145, Loss: 0.3663
Epoch 7/10, Batch 30/145, Loss: 0.2244
Epoch 7/10, Batch 40/145, Loss: 0.4811
Epoch 7/10, Batch 50/145, Loss: 0.1690
Epoch 7/10, Batch 60/145, Loss: 0.2454
Epoch 7/10, Batch 70/145, Loss: 0.1544
Epoch 7/10, Batch 80/145, Loss: 0.3918
Epoch 7/10, Batch 90/145, Loss: 0.1616
Epoch 7/10, Batch 100/145, Loss: 0.0836
Epoch 7/10, Batch 110/145, Loss: 0.1671
Epoch 7/10, Batch 120/145, Loss: 0.1705
Epoch 7/10, Batch 130/145, Loss: 0.0796
Epoch 7/10, Batch 140/145, Loss: 0.3510
Epoch 7/10, Train Loss: 0.2088, Valid Loss: 0.2276
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2412
Epoch 8/10, Batch 20/145, Loss: 0.2948
Epoch 8/10, Batch 30/145, Loss: 0.1081
Epoch 8/10, Batch 40/145, Loss: 0.1333
Epoch 8/10, Batch 50/145, Loss: 0.2011
Epoch 8/10, Batch 60/145, Loss: 0.2563
Epoch 8/10, Batch 70/145, Loss: 0.2360
Epoch 8/10, Batch 80/145, Loss: 0.1806
Epoch 8/10, Batch 90/145, Loss: 0.4012
Epoch 8/10, Batch 100/145, Loss: 0.0794
Epoch 8/10, Batch 110/145, Loss: 0.2269
Epoch 8/10, Batch 120/145, Loss: 0.2529
Epoch 8/10, Batch 130/145, Loss: 0.1519
Epoch 8/10, Batch 140/145, Loss: 0.1779
Epoch 8/10, Train Loss: 0.2061, Valid Loss: 0.2292
Epoch 9/10, Batch 10/145, Loss: 0.4017
Epoch 9/10, Batch 20/145, Loss: 0.3095
Epoch 9/10, Batch 30/145, Loss: 0.1702
Epoch 9/10, Batch 40/145, Loss: 0.2115
Epoch 9/10, Batch 50/145, Loss: 0.1576
Epoch 9/10, Batch 60/145, Loss: 0.4660
Epoch 9/10, Batch 70/145, Loss: 0.2070
Epoch 9/10, Batch 80/145, Loss: 0.1350
Epoch 9/10, Batch 90/145, Loss: 0.3264
Epoch 9/10, Batch 100/145, Loss: 0.1031
Epoch 9/10, Batch 110/145, Loss: 0.1399
Epoch 9/10, Batch 120/145, Loss: 0.0907
Epoch 9/10, Batch 130/145, Loss: 0.1275
Epoch 9/10, Batch 140/145, Loss: 0.2377
Epoch 9/10, Train Loss: 0.1961, Valid Loss: 0.2230
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0776
Epoch 10/10, Batch 20/145, Loss: 0.1394
Epoch 10/10, Batch 30/145, Loss: 0.1394
Epoch 10/10, Batch 40/145, Loss: 0.2013
Epoch 10/10, Batch 50/145, Loss: 0.2641
Epoch 10/10, Batch 60/145, Loss: 0.2311
Epoch 10/10, Batch 70/145, Loss: 0.2708
Epoch 10/10, Batch 80/145, Loss: 0.1011
Epoch 10/10, Batch 90/145, Loss: 0.1243
Epoch 10/10, Batch 100/145, Loss: 0.1640
Epoch 10/10, Batch 110/145, Loss: 0.2337
Epoch 10/10, Batch 120/145, Loss: 0.1586
Epoch 10/10, Batch 130/145, Loss: 0.2499
Epoch 10/10, Batch 140/145, Loss: 0.2567
Epoch 10/10, Train Loss: 0.1899, Valid Loss: 0.2189
Model saved!
Accuracy: 0.9287
Precision: 0.9268
Recall: 0.9287
F1-score: 0.9269
Memory Allocated after cleanup: 17.76 MB


Mejor accuracy encontrado: 0.9287


--------------------------------------mobilenet  BUSQUEDA LOCAL  10%-------------------------------------------------
Start time: 2025-02-25 13:13:39.545579
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2236
Epoch 1/10, Batch 20/20, Loss: 1.1540
Epoch 1/10, Train Loss: 1.3028, Valid Loss: 0.9503
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8083
Epoch 2/10, Batch 20/20, Loss: 0.9378
Epoch 2/10, Train Loss: 0.8865, Valid Loss: 0.6755
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6640
Epoch 3/10, Batch 20/20, Loss: 0.7956
Epoch 3/10, Train Loss: 0.6715, Valid Loss: 0.5556
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7553
Epoch 4/10, Batch 20/20, Loss: 0.4010
Epoch 4/10, Train Loss: 0.5465, Valid Loss: 0.4788
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4686
Epoch 5/10, Batch 20/20, Loss: 0.4579
Epoch 5/10, Train Loss: 0.4752, Valid Loss: 0.4291
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5622
Epoch 6/10, Batch 20/20, Loss: 0.9023
Epoch 6/10, Train Loss: 0.4775, Valid Loss: 0.3940
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4852
Epoch 7/10, Batch 20/20, Loss: 0.4387
Epoch 7/10, Train Loss: 0.4010, Valid Loss: 0.3741
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2853
Epoch 8/10, Batch 20/20, Loss: 0.1734
Epoch 8/10, Train Loss: 0.3627, Valid Loss: 0.3527
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5397
Epoch 9/10, Batch 20/20, Loss: 0.6046
Epoch 9/10, Train Loss: 0.3536, Valid Loss: 0.3349
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2193
Epoch 10/10, Batch 20/20, Loss: 0.5169
Epoch 10/10, Train Loss: 0.3158, Valid Loss: 0.3213
Model saved!
Accuracy: 0.8890
Precision: 0.8835
Recall: 0.8890
F1-score: 0.8848
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2427
Epoch 1/10, Batch 20/20, Loss: 1.2224
Epoch 1/10, Train Loss: 1.2945, Valid Loss: 0.9109
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8094
Epoch 2/10, Batch 20/20, Loss: 0.9256
Epoch 2/10, Train Loss: 0.8528, Valid Loss: 0.6418
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4577
Epoch 3/10, Batch 20/20, Loss: 0.6947
Epoch 3/10, Train Loss: 0.6342, Valid Loss: 0.5161
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6802
Epoch 4/10, Batch 20/20, Loss: 0.7985
Epoch 4/10, Train Loss: 0.5311, Valid Loss: 0.4366
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4918
Epoch 5/10, Batch 20/20, Loss: 0.4237
Epoch 5/10, Train Loss: 0.4487, Valid Loss: 0.3970
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5780
Epoch 6/10, Batch 20/20, Loss: 0.5103
Epoch 6/10, Train Loss: 0.4091, Valid Loss: 0.3631
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.5649
Epoch 7/10, Batch 20/20, Loss: 0.5579
Epoch 7/10, Train Loss: 0.3863, Valid Loss: 0.3447
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3128
Epoch 8/10, Batch 20/20, Loss: 0.5078
Epoch 8/10, Train Loss: 0.3457, Valid Loss: 0.3288
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4746
Epoch 9/10, Batch 20/20, Loss: 0.3005
Epoch 9/10, Train Loss: 0.3197, Valid Loss: 0.3116
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1565
Epoch 10/10, Batch 20/20, Loss: 0.2413
Epoch 10/10, Train Loss: 0.2696, Valid Loss: 0.3067
Model saved!
Accuracy: 0.8750
Precision: 0.8686
Recall: 0.8750
F1-score: 0.8698
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2361
Epoch 1/10, Batch 20/20, Loss: 1.2158
Epoch 1/10, Train Loss: 1.3074, Valid Loss: 0.9274
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8742
Epoch 2/10, Batch 20/20, Loss: 1.0369
Epoch 2/10, Train Loss: 0.8631, Valid Loss: 0.6611
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5278
Epoch 3/10, Batch 20/20, Loss: 0.7348
Epoch 3/10, Train Loss: 0.6377, Valid Loss: 0.5288
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7036
Epoch 4/10, Batch 20/20, Loss: 0.4875
Epoch 4/10, Train Loss: 0.5305, Valid Loss: 0.4682
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3083
Epoch 5/10, Batch 20/20, Loss: 0.3531
Epoch 5/10, Train Loss: 0.4249, Valid Loss: 0.4196
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4360
Epoch 6/10, Batch 20/20, Loss: 0.7375
Epoch 6/10, Train Loss: 0.4081, Valid Loss: 0.3841
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4320
Epoch 7/10, Batch 20/20, Loss: 0.4759
Epoch 7/10, Train Loss: 0.3636, Valid Loss: 0.3670
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2878
Epoch 8/10, Batch 20/20, Loss: 0.3832
Epoch 8/10, Train Loss: 0.3155, Valid Loss: 0.3506
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4782
Epoch 9/10, Batch 20/20, Loss: 0.6007
Epoch 9/10, Train Loss: 0.3222, Valid Loss: 0.3430
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2783
Epoch 10/10, Batch 20/20, Loss: 0.5214
Epoch 10/10, Train Loss: 0.2744, Valid Loss: 0.3273
Model saved!
Accuracy: 0.8914
Precision: 0.8869
Recall: 0.8914
F1-score: 0.8872
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 3. Fitness: 0.8914
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2053
Epoch 1/10, Batch 20/20, Loss: 1.2457
Epoch 1/10, Train Loss: 1.3123, Valid Loss: 0.9416
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8475
Epoch 2/10, Batch 20/20, Loss: 0.8142
Epoch 2/10, Train Loss: 0.8521, Valid Loss: 0.6654
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6497
Epoch 3/10, Batch 20/20, Loss: 0.8691
Epoch 3/10, Train Loss: 0.6557, Valid Loss: 0.5390
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6888
Epoch 4/10, Batch 20/20, Loss: 0.6470
Epoch 4/10, Train Loss: 0.5365, Valid Loss: 0.4570
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5662
Epoch 5/10, Batch 20/20, Loss: 0.3569
Epoch 5/10, Train Loss: 0.4536, Valid Loss: 0.4353
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5404
Epoch 6/10, Batch 20/20, Loss: 0.6606
Epoch 6/10, Train Loss: 0.4356, Valid Loss: 0.3756
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4979
Epoch 7/10, Batch 20/20, Loss: 0.3080
Epoch 7/10, Train Loss: 0.3726, Valid Loss: 0.3647
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3332
Epoch 8/10, Batch 20/20, Loss: 0.3284
Epoch 8/10, Train Loss: 0.3404, Valid Loss: 0.3480
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3725
Epoch 9/10, Batch 20/20, Loss: 0.7984
Epoch 9/10, Train Loss: 0.3440, Valid Loss: 0.3402
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2446
Epoch 10/10, Batch 20/20, Loss: 0.2452
Epoch 10/10, Train Loss: 0.2763, Valid Loss: 0.3135
Model saved!
Accuracy: 0.8890
Precision: 0.8838
Recall: 0.8890
F1-score: 0.8837
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2659
Epoch 1/10, Batch 20/20, Loss: 1.0879
Epoch 1/10, Train Loss: 1.3020, Valid Loss: 1.0046
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8641
Epoch 2/10, Batch 20/20, Loss: 1.0664
Epoch 2/10, Train Loss: 0.8667, Valid Loss: 0.7265
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6677
Epoch 3/10, Batch 20/20, Loss: 0.9319
Epoch 3/10, Train Loss: 0.6614, Valid Loss: 0.5953
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6875
Epoch 4/10, Batch 20/20, Loss: 0.3239
Epoch 4/10, Train Loss: 0.5377, Valid Loss: 0.5195
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4690
Epoch 5/10, Batch 20/20, Loss: 0.4215
Epoch 5/10, Train Loss: 0.4604, Valid Loss: 0.4695
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4861
Epoch 6/10, Batch 20/20, Loss: 0.6511
Epoch 6/10, Train Loss: 0.4348, Valid Loss: 0.4116
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3890
Epoch 7/10, Batch 20/20, Loss: 0.2727
Epoch 7/10, Train Loss: 0.3725, Valid Loss: 0.3925
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3978
Epoch 8/10, Batch 20/20, Loss: 0.5128
Epoch 8/10, Train Loss: 0.3626, Valid Loss: 0.3645
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5073
Epoch 9/10, Batch 20/20, Loss: 0.4483
Epoch 9/10, Train Loss: 0.3363, Valid Loss: 0.3551
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2776
Epoch 10/10, Batch 20/20, Loss: 0.4378
Epoch 10/10, Train Loss: 0.2965, Valid Loss: 0.3304
Model saved!
Accuracy: 0.8890
Precision: 0.8835
Recall: 0.8890
F1-score: 0.8846
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2759
Epoch 1/10, Batch 20/20, Loss: 1.2580
Epoch 1/10, Train Loss: 1.2970, Valid Loss: 0.9255
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8778
Epoch 2/10, Batch 20/20, Loss: 0.9152
Epoch 2/10, Train Loss: 0.8559, Valid Loss: 0.6588
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5084
Epoch 3/10, Batch 20/20, Loss: 0.8326
Epoch 3/10, Train Loss: 0.6395, Valid Loss: 0.5316
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6640
Epoch 4/10, Batch 20/20, Loss: 0.3545
Epoch 4/10, Train Loss: 0.5164, Valid Loss: 0.4670
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4907
Epoch 5/10, Batch 20/20, Loss: 0.2800
Epoch 5/10, Train Loss: 0.4424, Valid Loss: 0.4150
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4819
Epoch 6/10, Batch 20/20, Loss: 0.5643
Epoch 6/10, Train Loss: 0.4225, Valid Loss: 0.3795
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4102
Epoch 7/10, Batch 20/20, Loss: 0.4831
Epoch 7/10, Train Loss: 0.3673, Valid Loss: 0.3551
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3819
Epoch 8/10, Batch 20/20, Loss: 0.1418
Epoch 8/10, Train Loss: 0.3251, Valid Loss: 0.3342
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4182
Epoch 9/10, Batch 20/20, Loss: 0.4760
Epoch 9/10, Train Loss: 0.3276, Valid Loss: 0.3266
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2414
Epoch 10/10, Batch 20/20, Loss: 0.2476
Epoch 10/10, Train Loss: 0.2635, Valid Loss: 0.3061
Model saved!
Accuracy: 0.8832
Precision: 0.8773
Recall: 0.8832
F1-score: 0.8791
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1627
Epoch 1/10, Batch 20/20, Loss: 1.3200
Epoch 1/10, Train Loss: 1.3037, Valid Loss: 0.9614
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8116
Epoch 2/10, Batch 20/20, Loss: 0.6374
Epoch 2/10, Train Loss: 0.8290, Valid Loss: 0.6858
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5488
Epoch 3/10, Batch 20/20, Loss: 0.6344
Epoch 3/10, Train Loss: 0.6017, Valid Loss: 0.5636
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6579
Epoch 4/10, Batch 20/20, Loss: 0.2260
Epoch 4/10, Train Loss: 0.4927, Valid Loss: 0.4862
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4820
Epoch 5/10, Batch 20/20, Loss: 0.2994
Epoch 5/10, Train Loss: 0.4206, Valid Loss: 0.4444
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6603
Epoch 6/10, Batch 20/20, Loss: 0.6015
Epoch 6/10, Train Loss: 0.4102, Valid Loss: 0.4099
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3510
Epoch 7/10, Batch 20/20, Loss: 0.3112
Epoch 7/10, Train Loss: 0.3571, Valid Loss: 0.3879
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2993
Epoch 8/10, Batch 20/20, Loss: 0.2122
Epoch 8/10, Train Loss: 0.3111, Valid Loss: 0.3639
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4416
Epoch 9/10, Batch 20/20, Loss: 0.4877
Epoch 9/10, Train Loss: 0.2960, Valid Loss: 0.3669
Epoch 10/10, Batch 10/20, Loss: 0.2079
Epoch 10/10, Batch 20/20, Loss: 0.2146
Epoch 10/10, Train Loss: 0.2555, Valid Loss: 0.3395
Model saved!
Accuracy: 0.8925
Precision: 0.8875
Recall: 0.8925
F1-score: 0.8893
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 7. Fitness: 0.8925
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3916
Epoch 1/10, Batch 20/20, Loss: 1.2118
Epoch 1/10, Train Loss: 1.3214, Valid Loss: 1.0127
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9793
Epoch 2/10, Batch 20/20, Loss: 1.0319
Epoch 2/10, Train Loss: 0.8864, Valid Loss: 0.7458
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5519
Epoch 3/10, Batch 20/20, Loss: 0.8248
Epoch 3/10, Train Loss: 0.6701, Valid Loss: 0.6091
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6756
Epoch 4/10, Batch 20/20, Loss: 0.7789
Epoch 4/10, Train Loss: 0.5552, Valid Loss: 0.5254
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4125
Epoch 5/10, Batch 20/20, Loss: 0.6476
Epoch 5/10, Train Loss: 0.4703, Valid Loss: 0.4757
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4947
Epoch 6/10, Batch 20/20, Loss: 0.4406
Epoch 6/10, Train Loss: 0.4218, Valid Loss: 0.4424
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4947
Epoch 7/10, Batch 20/20, Loss: 0.5212
Epoch 7/10, Train Loss: 0.3963, Valid Loss: 0.4128
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4410
Epoch 8/10, Batch 20/20, Loss: 0.2553
Epoch 8/10, Train Loss: 0.3446, Valid Loss: 0.3877
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4442
Epoch 9/10, Batch 20/20, Loss: 0.4619
Epoch 9/10, Train Loss: 0.3342, Valid Loss: 0.3739
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2156
Epoch 10/10, Batch 20/20, Loss: 0.2341
Epoch 10/10, Train Loss: 0.2809, Valid Loss: 0.3535
Model saved!
Accuracy: 0.8867
Precision: 0.8815
Recall: 0.8867
F1-score: 0.8826
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1986
Epoch 1/10, Batch 20/20, Loss: 1.2803
Epoch 1/10, Train Loss: 1.2897, Valid Loss: 0.9503
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8621
Epoch 2/10, Batch 20/20, Loss: 0.8137
Epoch 2/10, Train Loss: 0.8225, Valid Loss: 0.6873
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6401
Epoch 3/10, Batch 20/20, Loss: 0.6125
Epoch 3/10, Train Loss: 0.6121, Valid Loss: 0.5676
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6458
Epoch 4/10, Batch 20/20, Loss: 0.5338
Epoch 4/10, Train Loss: 0.5069, Valid Loss: 0.4863
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5017
Epoch 5/10, Batch 20/20, Loss: 0.3024
Epoch 5/10, Train Loss: 0.4140, Valid Loss: 0.4446
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5414
Epoch 6/10, Batch 20/20, Loss: 0.6591
Epoch 6/10, Train Loss: 0.4231, Valid Loss: 0.4011
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4946
Epoch 7/10, Batch 20/20, Loss: 0.3191
Epoch 7/10, Train Loss: 0.3575, Valid Loss: 0.3790
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3656
Epoch 8/10, Batch 20/20, Loss: 0.2548
Epoch 8/10, Train Loss: 0.3268, Valid Loss: 0.3529
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4767
Epoch 9/10, Batch 20/20, Loss: 0.5246
Epoch 9/10, Train Loss: 0.3213, Valid Loss: 0.3441
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3731
Epoch 10/10, Batch 20/20, Loss: 0.2267
Epoch 10/10, Train Loss: 0.2619, Valid Loss: 0.3260
Model saved!
Accuracy: 0.8738
Precision: 0.8697
Recall: 0.8738
F1-score: 0.8706
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3641
Epoch 1/10, Batch 20/20, Loss: 1.1686
Epoch 1/10, Train Loss: 1.3125, Valid Loss: 0.9533
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8731
Epoch 2/10, Batch 20/20, Loss: 0.8794
Epoch 2/10, Train Loss: 0.8738, Valid Loss: 0.6907
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5447
Epoch 3/10, Batch 20/20, Loss: 1.1367
Epoch 3/10, Train Loss: 0.6636, Valid Loss: 0.5677
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6904
Epoch 4/10, Batch 20/20, Loss: 0.4505
Epoch 4/10, Train Loss: 0.5336, Valid Loss: 0.4902
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5281
Epoch 5/10, Batch 20/20, Loss: 0.6108
Epoch 5/10, Train Loss: 0.4668, Valid Loss: 0.4520
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.3522
Epoch 6/10, Batch 20/20, Loss: 0.6201
Epoch 6/10, Train Loss: 0.4351, Valid Loss: 0.4125
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3605
Epoch 7/10, Batch 20/20, Loss: 0.4821
Epoch 7/10, Train Loss: 0.3788, Valid Loss: 0.3910
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3822
Epoch 8/10, Batch 20/20, Loss: 0.2758
Epoch 8/10, Train Loss: 0.3376, Valid Loss: 0.3810
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5030
Epoch 9/10, Batch 20/20, Loss: 0.8385
Epoch 9/10, Train Loss: 0.3558, Valid Loss: 0.3665
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3940
Epoch 10/10, Batch 20/20, Loss: 0.2305
Epoch 10/10, Train Loss: 0.2883, Valid Loss: 0.3486
Model saved!
Accuracy: 0.8937
Precision: 0.8908
Recall: 0.8937
F1-score: 0.8916
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 10. Fitness: 0.8937
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3180
Epoch 1/10, Batch 20/20, Loss: 1.1851
Epoch 1/10, Train Loss: 1.3160, Valid Loss: 0.9968
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9291
Epoch 2/10, Batch 20/20, Loss: 0.9083
Epoch 2/10, Train Loss: 0.8785, Valid Loss: 0.7329
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5837
Epoch 3/10, Batch 20/20, Loss: 0.7064
Epoch 3/10, Train Loss: 0.6520, Valid Loss: 0.6085
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7689
Epoch 4/10, Batch 20/20, Loss: 0.5293
Epoch 4/10, Train Loss: 0.5320, Valid Loss: 0.5401
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5011
Epoch 5/10, Batch 20/20, Loss: 0.3638
Epoch 5/10, Train Loss: 0.4504, Valid Loss: 0.4969
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5502
Epoch 6/10, Batch 20/20, Loss: 0.5344
Epoch 6/10, Train Loss: 0.4207, Valid Loss: 0.4651
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4386
Epoch 7/10, Batch 20/20, Loss: 0.4595
Epoch 7/10, Train Loss: 0.3782, Valid Loss: 0.4470
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2996
Epoch 8/10, Batch 20/20, Loss: 0.2170
Epoch 8/10, Train Loss: 0.3289, Valid Loss: 0.4304
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4351
Epoch 9/10, Batch 20/20, Loss: 0.7904
Epoch 9/10, Train Loss: 0.3362, Valid Loss: 0.4171
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2612
Epoch 10/10, Batch 20/20, Loss: 0.3534
Epoch 10/10, Train Loss: 0.3008, Valid Loss: 0.4057
Model saved!
Accuracy: 0.8879
Precision: 0.8830
Recall: 0.8879
F1-score: 0.8847
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2468
Epoch 1/10, Batch 20/20, Loss: 1.0576
Epoch 1/10, Train Loss: 1.2945, Valid Loss: 0.9343
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8884
Epoch 2/10, Batch 20/20, Loss: 0.9690
Epoch 2/10, Train Loss: 0.8572, Valid Loss: 0.6562
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6108
Epoch 3/10, Batch 20/20, Loss: 1.0586
Epoch 3/10, Train Loss: 0.6584, Valid Loss: 0.5328
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6602
Epoch 4/10, Batch 20/20, Loss: 0.4335
Epoch 4/10, Train Loss: 0.5256, Valid Loss: 0.4583
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3742
Epoch 5/10, Batch 20/20, Loss: 0.5797
Epoch 5/10, Train Loss: 0.4548, Valid Loss: 0.4182
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5733
Epoch 6/10, Batch 20/20, Loss: 0.7810
Epoch 6/10, Train Loss: 0.4238, Valid Loss: 0.3879
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.5563
Epoch 7/10, Batch 20/20, Loss: 0.3712
Epoch 7/10, Train Loss: 0.3672, Valid Loss: 0.3642
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3136
Epoch 8/10, Batch 20/20, Loss: 0.2280
Epoch 8/10, Train Loss: 0.3311, Valid Loss: 0.3421
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4546
Epoch 9/10, Batch 20/20, Loss: 0.6081
Epoch 9/10, Train Loss: 0.3266, Valid Loss: 0.3235
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2443
Epoch 10/10, Batch 20/20, Loss: 0.2220
Epoch 10/10, Train Loss: 0.2785, Valid Loss: 0.3194
Model saved!
Accuracy: 0.8750
Precision: 0.8687
Recall: 0.8750
F1-score: 0.8708
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2631
Epoch 1/10, Batch 20/20, Loss: 1.3243
Epoch 1/10, Train Loss: 1.3204, Valid Loss: 0.9337
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9010
Epoch 2/10, Batch 20/20, Loss: 0.9860
Epoch 2/10, Train Loss: 0.8778, Valid Loss: 0.6603
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6179
Epoch 3/10, Batch 20/20, Loss: 0.7493
Epoch 3/10, Train Loss: 0.6535, Valid Loss: 0.5384
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6986
Epoch 4/10, Batch 20/20, Loss: 0.6711
Epoch 4/10, Train Loss: 0.5477, Valid Loss: 0.4646
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5327
Epoch 5/10, Batch 20/20, Loss: 0.8873
Epoch 5/10, Train Loss: 0.4736, Valid Loss: 0.4250
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5355
Epoch 6/10, Batch 20/20, Loss: 0.8136
Epoch 6/10, Train Loss: 0.4481, Valid Loss: 0.3893
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4132
Epoch 7/10, Batch 20/20, Loss: 0.6526
Epoch 7/10, Train Loss: 0.3946, Valid Loss: 0.3771
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3063
Epoch 8/10, Batch 20/20, Loss: 0.4397
Epoch 8/10, Train Loss: 0.3449, Valid Loss: 0.3562
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4056
Epoch 9/10, Batch 20/20, Loss: 0.3171
Epoch 9/10, Train Loss: 0.3387, Valid Loss: 0.3478
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2429
Epoch 10/10, Batch 20/20, Loss: 0.3929
Epoch 10/10, Train Loss: 0.2918, Valid Loss: 0.3364
Model saved!
Accuracy: 0.8867
Precision: 0.8832
Recall: 0.8867
F1-score: 0.8830
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2848
Epoch 1/10, Batch 20/20, Loss: 1.0720
Epoch 1/10, Train Loss: 1.2926, Valid Loss: 1.0014
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9262
Epoch 2/10, Batch 20/20, Loss: 0.8214
Epoch 2/10, Train Loss: 0.8528, Valid Loss: 0.7375
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5222
Epoch 3/10, Batch 20/20, Loss: 0.8795
Epoch 3/10, Train Loss: 0.6272, Valid Loss: 0.6288
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7566
Epoch 4/10, Batch 20/20, Loss: 0.4139
Epoch 4/10, Train Loss: 0.5241, Valid Loss: 0.5530
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4475
Epoch 5/10, Batch 20/20, Loss: 0.3102
Epoch 5/10, Train Loss: 0.4236, Valid Loss: 0.5011
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4192
Epoch 6/10, Batch 20/20, Loss: 0.7277
Epoch 6/10, Train Loss: 0.4256, Valid Loss: 0.4698
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3048
Epoch 7/10, Batch 20/20, Loss: 0.9326
Epoch 7/10, Train Loss: 0.3834, Valid Loss: 0.4542
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3234
Epoch 8/10, Batch 20/20, Loss: 0.3089
Epoch 8/10, Train Loss: 0.3302, Valid Loss: 0.4288
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4401
Epoch 9/10, Batch 20/20, Loss: 0.4089
Epoch 9/10, Train Loss: 0.3195, Valid Loss: 0.4202
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2661
Epoch 10/10, Batch 20/20, Loss: 0.2475
Epoch 10/10, Train Loss: 0.2745, Valid Loss: 0.3987
Model saved!
Accuracy: 0.8914
Precision: 0.8873
Recall: 0.8914
F1-score: 0.8885
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2453
Epoch 1/10, Batch 20/20, Loss: 1.1689
Epoch 1/10, Train Loss: 1.3153, Valid Loss: 0.9574
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9106
Epoch 2/10, Batch 20/20, Loss: 0.9697
Epoch 2/10, Train Loss: 0.8740, Valid Loss: 0.6757
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5191
Epoch 3/10, Batch 20/20, Loss: 0.9566
Epoch 3/10, Train Loss: 0.6437, Valid Loss: 0.5499
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6712
Epoch 4/10, Batch 20/20, Loss: 0.4213
Epoch 4/10, Train Loss: 0.5241, Valid Loss: 0.4779
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4506
Epoch 5/10, Batch 20/20, Loss: 0.4761
Epoch 5/10, Train Loss: 0.4554, Valid Loss: 0.4385
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4594
Epoch 6/10, Batch 20/20, Loss: 0.9119
Epoch 6/10, Train Loss: 0.4393, Valid Loss: 0.4020
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4702
Epoch 7/10, Batch 20/20, Loss: 0.3609
Epoch 7/10, Train Loss: 0.3698, Valid Loss: 0.3886
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3138
Epoch 8/10, Batch 20/20, Loss: 0.4015
Epoch 8/10, Train Loss: 0.3341, Valid Loss: 0.3665
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4006
Epoch 9/10, Batch 20/20, Loss: 0.7999
Epoch 9/10, Train Loss: 0.3335, Valid Loss: 0.3635
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2263
Epoch 10/10, Batch 20/20, Loss: 0.1542
Epoch 10/10, Train Loss: 0.2653, Valid Loss: 0.3424
Model saved!
Accuracy: 0.8855
Precision: 0.8810
Recall: 0.8855
F1-score: 0.8818
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3489
Epoch 1/10, Batch 20/20, Loss: 1.2167
Epoch 1/10, Train Loss: 1.3062, Valid Loss: 0.9718
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8052
Epoch 2/10, Batch 20/20, Loss: 0.8611
Epoch 2/10, Train Loss: 0.8558, Valid Loss: 0.6956
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5681
Epoch 3/10, Batch 20/20, Loss: 0.8429
Epoch 3/10, Train Loss: 0.6424, Valid Loss: 0.5652
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7284
Epoch 4/10, Batch 20/20, Loss: 0.5923
Epoch 4/10, Train Loss: 0.5277, Valid Loss: 0.4881
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3736
Epoch 5/10, Batch 20/20, Loss: 0.5782
Epoch 5/10, Train Loss: 0.4465, Valid Loss: 0.4303
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4857
Epoch 6/10, Batch 20/20, Loss: 0.5469
Epoch 6/10, Train Loss: 0.4181, Valid Loss: 0.4007
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3481
Epoch 7/10, Batch 20/20, Loss: 0.4613
Epoch 7/10, Train Loss: 0.3716, Valid Loss: 0.3736
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3013
Epoch 8/10, Batch 20/20, Loss: 0.2357
Epoch 8/10, Train Loss: 0.3326, Valid Loss: 0.3490
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3547
Epoch 9/10, Batch 20/20, Loss: 0.5331
Epoch 9/10, Train Loss: 0.3308, Valid Loss: 0.3355
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2349
Epoch 10/10, Batch 20/20, Loss: 0.4189
Epoch 10/10, Train Loss: 0.2902, Valid Loss: 0.3233
Model saved!
Accuracy: 0.8902
Precision: 0.8849
Recall: 0.8902
F1-score: 0.8861
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2368
Epoch 1/10, Batch 20/20, Loss: 1.1358
Epoch 1/10, Train Loss: 1.3005, Valid Loss: 0.9381
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8418
Epoch 2/10, Batch 20/20, Loss: 0.8076
Epoch 2/10, Train Loss: 0.8352, Valid Loss: 0.6687
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5892
Epoch 3/10, Batch 20/20, Loss: 0.9384
Epoch 3/10, Train Loss: 0.6304, Valid Loss: 0.5398
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6158
Epoch 4/10, Batch 20/20, Loss: 0.3093
Epoch 4/10, Train Loss: 0.5052, Valid Loss: 0.4732
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4472
Epoch 5/10, Batch 20/20, Loss: 0.3647
Epoch 5/10, Train Loss: 0.4262, Valid Loss: 0.4377
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4350
Epoch 6/10, Batch 20/20, Loss: 0.3318
Epoch 6/10, Train Loss: 0.3935, Valid Loss: 0.3927
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3312
Epoch 7/10, Batch 20/20, Loss: 0.3769
Epoch 7/10, Train Loss: 0.3595, Valid Loss: 0.3817
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3384
Epoch 8/10, Batch 20/20, Loss: 0.3757
Epoch 8/10, Train Loss: 0.3299, Valid Loss: 0.3545
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5291
Epoch 9/10, Batch 20/20, Loss: 0.7717
Epoch 9/10, Train Loss: 0.3245, Valid Loss: 0.3451
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2968
Epoch 10/10, Batch 20/20, Loss: 0.2951
Epoch 10/10, Train Loss: 0.2724, Valid Loss: 0.3317
Model saved!
Accuracy: 0.8832
Precision: 0.8775
Recall: 0.8832
F1-score: 0.8796
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2959
Epoch 1/10, Batch 20/20, Loss: 1.3180
Epoch 1/10, Train Loss: 1.3142, Valid Loss: 0.9803
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7806
Epoch 2/10, Batch 20/20, Loss: 0.7755
Epoch 2/10, Train Loss: 0.8533, Valid Loss: 0.7110
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5774
Epoch 3/10, Batch 20/20, Loss: 0.7818
Epoch 3/10, Train Loss: 0.6523, Valid Loss: 0.5777
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5468
Epoch 4/10, Batch 20/20, Loss: 0.3449
Epoch 4/10, Train Loss: 0.5275, Valid Loss: 0.4958
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4141
Epoch 5/10, Batch 20/20, Loss: 0.5387
Epoch 5/10, Train Loss: 0.4454, Valid Loss: 0.4403
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6333
Epoch 6/10, Batch 20/20, Loss: 0.6056
Epoch 6/10, Train Loss: 0.4271, Valid Loss: 0.3948
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.5206
Epoch 7/10, Batch 20/20, Loss: 0.3062
Epoch 7/10, Train Loss: 0.3733, Valid Loss: 0.3681
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2883
Epoch 8/10, Batch 20/20, Loss: 0.1458
Epoch 8/10, Train Loss: 0.3400, Valid Loss: 0.3561
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5209
Epoch 9/10, Batch 20/20, Loss: 0.5237
Epoch 9/10, Train Loss: 0.3423, Valid Loss: 0.3294
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2374
Epoch 10/10, Batch 20/20, Loss: 0.2270
Epoch 10/10, Train Loss: 0.2827, Valid Loss: 0.3209
Model saved!
Accuracy: 0.8902
Precision: 0.8872
Recall: 0.8902
F1-score: 0.8850
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2619
Epoch 1/10, Batch 20/20, Loss: 1.1813
Epoch 1/10, Train Loss: 1.3191, Valid Loss: 0.9900
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0193
Epoch 2/10, Batch 20/20, Loss: 0.9558
Epoch 2/10, Train Loss: 0.8943, Valid Loss: 0.7147
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6353
Epoch 3/10, Batch 20/20, Loss: 0.9204
Epoch 3/10, Train Loss: 0.6833, Valid Loss: 0.5662
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.8444
Epoch 4/10, Batch 20/20, Loss: 0.4063
Epoch 4/10, Train Loss: 0.5641, Valid Loss: 0.4854
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5318
Epoch 5/10, Batch 20/20, Loss: 0.4971
Epoch 5/10, Train Loss: 0.4836, Valid Loss: 0.4278
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6086
Epoch 6/10, Batch 20/20, Loss: 0.4636
Epoch 6/10, Train Loss: 0.4630, Valid Loss: 0.3857
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3958
Epoch 7/10, Batch 20/20, Loss: 0.5581
Epoch 7/10, Train Loss: 0.4091, Valid Loss: 0.3526
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3115
Epoch 8/10, Batch 20/20, Loss: 0.2708
Epoch 8/10, Train Loss: 0.3770, Valid Loss: 0.3389
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3669
Epoch 9/10, Batch 20/20, Loss: 0.6194
Epoch 9/10, Train Loss: 0.3501, Valid Loss: 0.3149
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2197
Epoch 10/10, Batch 20/20, Loss: 0.5051
Epoch 10/10, Train Loss: 0.3251, Valid Loss: 0.2996
Model saved!
Accuracy: 0.8937
Precision: 0.8879
Recall: 0.8937
F1-score: 0.8876
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2495
Epoch 1/10, Batch 20/20, Loss: 1.1279
Epoch 1/10, Train Loss: 1.3060, Valid Loss: 0.9585
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8901
Epoch 2/10, Batch 20/20, Loss: 0.8156
Epoch 2/10, Train Loss: 0.8527, Valid Loss: 0.6871
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6117
Epoch 3/10, Batch 20/20, Loss: 0.6793
Epoch 3/10, Train Loss: 0.6370, Valid Loss: 0.5562
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7169
Epoch 4/10, Batch 20/20, Loss: 0.4059
Epoch 4/10, Train Loss: 0.5175, Valid Loss: 0.4901
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5092
Epoch 5/10, Batch 20/20, Loss: 0.4142
Epoch 5/10, Train Loss: 0.4296, Valid Loss: 0.4490
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6109
Epoch 6/10, Batch 20/20, Loss: 0.6262
Epoch 6/10, Train Loss: 0.4176, Valid Loss: 0.4073
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3596
Epoch 7/10, Batch 20/20, Loss: 0.4221
Epoch 7/10, Train Loss: 0.3592, Valid Loss: 0.3918
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2647
Epoch 8/10, Batch 20/20, Loss: 0.2508
Epoch 8/10, Train Loss: 0.3299, Valid Loss: 0.3632
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4777
Epoch 9/10, Batch 20/20, Loss: 0.5345
Epoch 9/10, Train Loss: 0.3191, Valid Loss: 0.3496
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2986
Epoch 10/10, Batch 20/20, Loss: 0.3641
Epoch 10/10, Train Loss: 0.2762, Valid Loss: 0.3357
Model saved!
Accuracy: 0.8890
Precision: 0.8848
Recall: 0.8890
F1-score: 0.8860
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2600
Epoch 1/10, Batch 20/20, Loss: 1.2132
Epoch 1/10, Train Loss: 1.2936, Valid Loss: 0.9512
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8263
Epoch 2/10, Batch 20/20, Loss: 0.7571
Epoch 2/10, Train Loss: 0.8339, Valid Loss: 0.6679
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5135
Epoch 3/10, Batch 20/20, Loss: 0.7176
Epoch 3/10, Train Loss: 0.6269, Valid Loss: 0.5321
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6913
Epoch 4/10, Batch 20/20, Loss: 0.4053
Epoch 4/10, Train Loss: 0.5059, Valid Loss: 0.4572
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4050
Epoch 5/10, Batch 20/20, Loss: 0.4793
Epoch 5/10, Train Loss: 0.4195, Valid Loss: 0.4083
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4731
Epoch 6/10, Batch 20/20, Loss: 0.5481
Epoch 6/10, Train Loss: 0.4085, Valid Loss: 0.3711
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2970
Epoch 7/10, Batch 20/20, Loss: 0.3228
Epoch 7/10, Train Loss: 0.3532, Valid Loss: 0.3494
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3118
Epoch 8/10, Batch 20/20, Loss: 0.2077
Epoch 8/10, Train Loss: 0.3191, Valid Loss: 0.3269
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4005
Epoch 9/10, Batch 20/20, Loss: 0.4720
Epoch 9/10, Train Loss: 0.2965, Valid Loss: 0.3181
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3352
Epoch 10/10, Batch 20/20, Loss: 0.3648
Epoch 10/10, Train Loss: 0.2787, Valid Loss: 0.3094
Model saved!
Accuracy: 0.8890
Precision: 0.8833
Recall: 0.8890
F1-score: 0.8850
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1831
Epoch 1/10, Batch 20/20, Loss: 1.2854
Epoch 1/10, Train Loss: 1.3004, Valid Loss: 0.9581
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8542
Epoch 2/10, Batch 20/20, Loss: 0.9391
Epoch 2/10, Train Loss: 0.8508, Valid Loss: 0.6953
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5213
Epoch 3/10, Batch 20/20, Loss: 1.0492
Epoch 3/10, Train Loss: 0.6671, Valid Loss: 0.5708
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7695
Epoch 4/10, Batch 20/20, Loss: 0.5105
Epoch 4/10, Train Loss: 0.5347, Valid Loss: 0.4960
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.6419
Epoch 5/10, Batch 20/20, Loss: 0.3640
Epoch 5/10, Train Loss: 0.4472, Valid Loss: 0.4401
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5928
Epoch 6/10, Batch 20/20, Loss: 0.7979
Epoch 6/10, Train Loss: 0.4559, Valid Loss: 0.4123
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3370
Epoch 7/10, Batch 20/20, Loss: 0.6534
Epoch 7/10, Train Loss: 0.3838, Valid Loss: 0.3825
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3698
Epoch 8/10, Batch 20/20, Loss: 0.3202
Epoch 8/10, Train Loss: 0.3605, Valid Loss: 0.3650
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4295
Epoch 9/10, Batch 20/20, Loss: 0.7106
Epoch 9/10, Train Loss: 0.3540, Valid Loss: 0.3476
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2988
Epoch 10/10, Batch 20/20, Loss: 0.1758
Epoch 10/10, Train Loss: 0.3037, Valid Loss: 0.3284
Model saved!
Accuracy: 0.8797
Precision: 0.8735
Recall: 0.8797
F1-score: 0.8753
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2598
Epoch 1/10, Batch 20/20, Loss: 1.2636
Epoch 1/10, Train Loss: 1.3121, Valid Loss: 0.9581
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9042
Epoch 2/10, Batch 20/20, Loss: 0.9027
Epoch 2/10, Train Loss: 0.8718, Valid Loss: 0.6900
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5523
Epoch 3/10, Batch 20/20, Loss: 0.8109
Epoch 3/10, Train Loss: 0.6570, Valid Loss: 0.5650
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.8297
Epoch 4/10, Batch 20/20, Loss: 0.5470
Epoch 4/10, Train Loss: 0.5532, Valid Loss: 0.4992
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5454
Epoch 5/10, Batch 20/20, Loss: 0.4686
Epoch 5/10, Train Loss: 0.4671, Valid Loss: 0.4422
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4546
Epoch 6/10, Batch 20/20, Loss: 0.7163
Epoch 6/10, Train Loss: 0.4369, Valid Loss: 0.4120
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3866
Epoch 7/10, Batch 20/20, Loss: 0.6216
Epoch 7/10, Train Loss: 0.3949, Valid Loss: 0.3780
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3952
Epoch 8/10, Batch 20/20, Loss: 0.3925
Epoch 8/10, Train Loss: 0.3501, Valid Loss: 0.3625
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4409
Epoch 9/10, Batch 20/20, Loss: 0.5909
Epoch 9/10, Train Loss: 0.3431, Valid Loss: 0.3498
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.4025
Epoch 10/10, Batch 20/20, Loss: 0.4078
Epoch 10/10, Train Loss: 0.3086, Valid Loss: 0.3415
Model saved!
Accuracy: 0.8995
Precision: 0.8950
Recall: 0.8995
F1-score: 0.8958
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 23. Fitness: 0.8995
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2680
Epoch 1/10, Batch 20/20, Loss: 1.1252
Epoch 1/10, Train Loss: 1.3107, Valid Loss: 0.9712
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9011
Epoch 2/10, Batch 20/20, Loss: 0.9281
Epoch 2/10, Train Loss: 0.8786, Valid Loss: 0.6907
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5826
Epoch 3/10, Batch 20/20, Loss: 0.8038
Epoch 3/10, Train Loss: 0.6662, Valid Loss: 0.5482
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7517
Epoch 4/10, Batch 20/20, Loss: 0.5885
Epoch 4/10, Train Loss: 0.5462, Valid Loss: 0.4718
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4963
Epoch 5/10, Batch 20/20, Loss: 0.5410
Epoch 5/10, Train Loss: 0.4776, Valid Loss: 0.4261
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5895
Epoch 6/10, Batch 20/20, Loss: 0.5487
Epoch 6/10, Train Loss: 0.4391, Valid Loss: 0.3954
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4338
Epoch 7/10, Batch 20/20, Loss: 0.8147
Epoch 7/10, Train Loss: 0.4087, Valid Loss: 0.3654
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3122
Epoch 8/10, Batch 20/20, Loss: 0.6616
Epoch 8/10, Train Loss: 0.3793, Valid Loss: 0.3513
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5050
Epoch 9/10, Batch 20/20, Loss: 0.5950
Epoch 9/10, Train Loss: 0.3521, Valid Loss: 0.3247
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2359
Epoch 10/10, Batch 20/20, Loss: 0.2510
Epoch 10/10, Train Loss: 0.2987, Valid Loss: 0.3272
Accuracy: 0.8867
Precision: 0.8826
Recall: 0.8867
F1-score: 0.8839
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1603
Epoch 1/10, Batch 20/20, Loss: 1.2383
Epoch 1/10, Train Loss: 1.2859, Valid Loss: 0.9221
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8141
Epoch 2/10, Batch 20/20, Loss: 0.9761
Epoch 2/10, Train Loss: 0.8209, Valid Loss: 0.6600
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4960
Epoch 3/10, Batch 20/20, Loss: 0.6820
Epoch 3/10, Train Loss: 0.5981, Valid Loss: 0.5216
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7524
Epoch 4/10, Batch 20/20, Loss: 0.4156
Epoch 4/10, Train Loss: 0.4979, Valid Loss: 0.4469
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4347
Epoch 5/10, Batch 20/20, Loss: 0.3142
Epoch 5/10, Train Loss: 0.4093, Valid Loss: 0.3979
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5038
Epoch 6/10, Batch 20/20, Loss: 0.4475
Epoch 6/10, Train Loss: 0.3852, Valid Loss: 0.3661
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4137
Epoch 7/10, Batch 20/20, Loss: 0.4427
Epoch 7/10, Train Loss: 0.3513, Valid Loss: 0.3392
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2776
Epoch 8/10, Batch 20/20, Loss: 0.1825
Epoch 8/10, Train Loss: 0.3064, Valid Loss: 0.3181
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4489
Epoch 9/10, Batch 20/20, Loss: 0.5484
Epoch 9/10, Train Loss: 0.3034, Valid Loss: 0.3044
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2551
Epoch 10/10, Batch 20/20, Loss: 0.2843
Epoch 10/10, Train Loss: 0.2554, Valid Loss: 0.2968
Model saved!
Accuracy: 0.8832
Precision: 0.8787
Recall: 0.8832
F1-score: 0.8779
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2395
Epoch 1/10, Batch 20/20, Loss: 1.1272
Epoch 1/10, Train Loss: 1.2990, Valid Loss: 0.9719
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8354
Epoch 2/10, Batch 20/20, Loss: 1.1120
Epoch 2/10, Train Loss: 0.8620, Valid Loss: 0.7235
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5707
Epoch 3/10, Batch 20/20, Loss: 0.6994
Epoch 3/10, Train Loss: 0.6482, Valid Loss: 0.6099
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7764
Epoch 4/10, Batch 20/20, Loss: 0.4269
Epoch 4/10, Train Loss: 0.5412, Valid Loss: 0.5469
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3969
Epoch 5/10, Batch 20/20, Loss: 0.4871
Epoch 5/10, Train Loss: 0.4596, Valid Loss: 0.5134
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.7379
Epoch 6/10, Batch 20/20, Loss: 0.5050
Epoch 6/10, Train Loss: 0.4465, Valid Loss: 0.4806
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3539
Epoch 7/10, Batch 20/20, Loss: 0.5573
Epoch 7/10, Train Loss: 0.3983, Valid Loss: 0.4607
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2959
Epoch 8/10, Batch 20/20, Loss: 0.3586
Epoch 8/10, Train Loss: 0.3622, Valid Loss: 0.4396
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4660
Epoch 9/10, Batch 20/20, Loss: 0.6230
Epoch 9/10, Train Loss: 0.3416, Valid Loss: 0.4370
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2827
Epoch 10/10, Batch 20/20, Loss: 0.3694
Epoch 10/10, Train Loss: 0.2961, Valid Loss: 0.4297
Model saved!
Accuracy: 0.8820
Precision: 0.8753
Recall: 0.8820
F1-score: 0.8762
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2799
Epoch 1/10, Batch 20/20, Loss: 1.0835
Epoch 1/10, Train Loss: 1.3036, Valid Loss: 0.9740
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9755
Epoch 2/10, Batch 20/20, Loss: 1.2384
Epoch 2/10, Train Loss: 0.8600, Valid Loss: 0.7369
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6292
Epoch 3/10, Batch 20/20, Loss: 0.7442
Epoch 3/10, Train Loss: 0.6327, Valid Loss: 0.6210
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7249
Epoch 4/10, Batch 20/20, Loss: 0.2814
Epoch 4/10, Train Loss: 0.5149, Valid Loss: 0.5528
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4748
Epoch 5/10, Batch 20/20, Loss: 0.3707
Epoch 5/10, Train Loss: 0.4399, Valid Loss: 0.5048
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4315
Epoch 6/10, Batch 20/20, Loss: 0.5072
Epoch 6/10, Train Loss: 0.4181, Valid Loss: 0.4701
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4598
Epoch 7/10, Batch 20/20, Loss: 0.5025
Epoch 7/10, Train Loss: 0.3862, Valid Loss: 0.4505
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2956
Epoch 8/10, Batch 20/20, Loss: 0.3664
Epoch 8/10, Train Loss: 0.3448, Valid Loss: 0.4404
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5436
Epoch 9/10, Batch 20/20, Loss: 0.3315
Epoch 9/10, Train Loss: 0.3266, Valid Loss: 0.4204
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2526
Epoch 10/10, Batch 20/20, Loss: 0.2254
Epoch 10/10, Train Loss: 0.2823, Valid Loss: 0.4145
Model saved!
Accuracy: 0.8867
Precision: 0.8819
Recall: 0.8867
F1-score: 0.8827
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2504
Epoch 1/10, Batch 20/20, Loss: 1.1771
Epoch 1/10, Train Loss: 1.3073, Valid Loss: 0.9447
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8667
Epoch 2/10, Batch 20/20, Loss: 1.1151
Epoch 2/10, Train Loss: 0.8568, Valid Loss: 0.6725
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6046
Epoch 3/10, Batch 20/20, Loss: 0.6839
Epoch 3/10, Train Loss: 0.6282, Valid Loss: 0.5447
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7317
Epoch 4/10, Batch 20/20, Loss: 0.3923
Epoch 4/10, Train Loss: 0.5306, Valid Loss: 0.4766
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4454
Epoch 5/10, Batch 20/20, Loss: 0.2859
Epoch 5/10, Train Loss: 0.4373, Valid Loss: 0.4302
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5087
Epoch 6/10, Batch 20/20, Loss: 0.2771
Epoch 6/10, Train Loss: 0.4078, Valid Loss: 0.3911
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3473
Epoch 7/10, Batch 20/20, Loss: 0.2728
Epoch 7/10, Train Loss: 0.3766, Valid Loss: 0.3652
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2346
Epoch 8/10, Batch 20/20, Loss: 0.2001
Epoch 8/10, Train Loss: 0.3341, Valid Loss: 0.3542
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4646
Epoch 9/10, Batch 20/20, Loss: 0.7904
Epoch 9/10, Train Loss: 0.3402, Valid Loss: 0.3422
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2160
Epoch 10/10, Batch 20/20, Loss: 0.4277
Epoch 10/10, Train Loss: 0.2793, Valid Loss: 0.3309
Model saved!
Accuracy: 0.8879
Precision: 0.8831
Recall: 0.8879
F1-score: 0.8842
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2463
Epoch 1/10, Batch 20/20, Loss: 1.1516
Epoch 1/10, Train Loss: 1.2878, Valid Loss: 0.9658
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9344
Epoch 2/10, Batch 20/20, Loss: 0.9372
Epoch 2/10, Train Loss: 0.8459, Valid Loss: 0.6875
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5589
Epoch 3/10, Batch 20/20, Loss: 0.7581
Epoch 3/10, Train Loss: 0.6382, Valid Loss: 0.5611
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6656
Epoch 4/10, Batch 20/20, Loss: 0.3425
Epoch 4/10, Train Loss: 0.5190, Valid Loss: 0.4850
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4799
Epoch 5/10, Batch 20/20, Loss: 0.3282
Epoch 5/10, Train Loss: 0.4425, Valid Loss: 0.4430
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.3879
Epoch 6/10, Batch 20/20, Loss: 0.3814
Epoch 6/10, Train Loss: 0.4082, Valid Loss: 0.3987
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4197
Epoch 7/10, Batch 20/20, Loss: 0.4885
Epoch 7/10, Train Loss: 0.3734, Valid Loss: 0.3773
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2607
Epoch 8/10, Batch 20/20, Loss: 0.1952
Epoch 8/10, Train Loss: 0.3298, Valid Loss: 0.3703
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4244
Epoch 9/10, Batch 20/20, Loss: 0.6943
Epoch 9/10, Train Loss: 0.3365, Valid Loss: 0.3466
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2757
Epoch 10/10, Batch 20/20, Loss: 0.2628
Epoch 10/10, Train Loss: 0.2796, Valid Loss: 0.3376
Model saved!
Accuracy: 0.8808
Precision: 0.8824
Recall: 0.8808
F1-score: 0.8795
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2636
Epoch 1/10, Batch 20/20, Loss: 1.1795
Epoch 1/10, Train Loss: 1.2916, Valid Loss: 0.9776
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8739
Epoch 2/10, Batch 20/20, Loss: 1.1309
Epoch 2/10, Train Loss: 0.8557, Valid Loss: 0.7284
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4711
Epoch 3/10, Batch 20/20, Loss: 0.9832
Epoch 3/10, Train Loss: 0.6359, Valid Loss: 0.5982
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5792
Epoch 4/10, Batch 20/20, Loss: 0.4052
Epoch 4/10, Train Loss: 0.5065, Valid Loss: 0.5367
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5377
Epoch 5/10, Batch 20/20, Loss: 0.5437
Epoch 5/10, Train Loss: 0.4336, Valid Loss: 0.4754
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5084
Epoch 6/10, Batch 20/20, Loss: 0.5247
Epoch 6/10, Train Loss: 0.4160, Valid Loss: 0.4562
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3128
Epoch 7/10, Batch 20/20, Loss: 0.5435
Epoch 7/10, Train Loss: 0.3647, Valid Loss: 0.4406
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3177
Epoch 8/10, Batch 20/20, Loss: 0.2878
Epoch 8/10, Train Loss: 0.3435, Valid Loss: 0.4121
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5189
Epoch 9/10, Batch 20/20, Loss: 0.7652
Epoch 9/10, Train Loss: 0.3399, Valid Loss: 0.4085
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2126
Epoch 10/10, Batch 20/20, Loss: 0.2353
Epoch 10/10, Train Loss: 0.2761, Valid Loss: 0.3862
Model saved!
Accuracy: 0.8820
Precision: 0.8754
Recall: 0.8820
F1-score: 0.8773
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2681
Epoch 1/10, Batch 20/20, Loss: 1.1289
Epoch 1/10, Train Loss: 1.2991, Valid Loss: 0.9582
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9563
Epoch 2/10, Batch 20/20, Loss: 0.8687
Epoch 2/10, Train Loss: 0.8658, Valid Loss: 0.7042
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5801
Epoch 3/10, Batch 20/20, Loss: 0.8256
Epoch 3/10, Train Loss: 0.6561, Valid Loss: 0.5716
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7408
Epoch 4/10, Batch 20/20, Loss: 0.4777
Epoch 4/10, Train Loss: 0.5381, Valid Loss: 0.5048
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3973
Epoch 5/10, Batch 20/20, Loss: 0.4902
Epoch 5/10, Train Loss: 0.4580, Valid Loss: 0.4629
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4660
Epoch 6/10, Batch 20/20, Loss: 0.5320
Epoch 6/10, Train Loss: 0.4295, Valid Loss: 0.4219
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3864
Epoch 7/10, Batch 20/20, Loss: 0.6528
Epoch 7/10, Train Loss: 0.3785, Valid Loss: 0.4040
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3249
Epoch 8/10, Batch 20/20, Loss: 0.2693
Epoch 8/10, Train Loss: 0.3461, Valid Loss: 0.3856
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4675
Epoch 9/10, Batch 20/20, Loss: 0.7469
Epoch 9/10, Train Loss: 0.3429, Valid Loss: 0.3788
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3002
Epoch 10/10, Batch 20/20, Loss: 0.5098
Epoch 10/10, Train Loss: 0.2971, Valid Loss: 0.3657
Model saved!
Accuracy: 0.8949
Precision: 0.8932
Recall: 0.8949
F1-score: 0.8923
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1991
Epoch 1/10, Batch 20/20, Loss: 1.2928
Epoch 1/10, Train Loss: 1.3059, Valid Loss: 0.9104
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8656
Epoch 2/10, Batch 20/20, Loss: 1.1088
Epoch 2/10, Train Loss: 0.8584, Valid Loss: 0.6535
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5054
Epoch 3/10, Batch 20/20, Loss: 0.8263
Epoch 3/10, Train Loss: 0.6438, Valid Loss: 0.5263
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7055
Epoch 4/10, Batch 20/20, Loss: 0.3024
Epoch 4/10, Train Loss: 0.5108, Valid Loss: 0.4461
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4645
Epoch 5/10, Batch 20/20, Loss: 0.5759
Epoch 5/10, Train Loss: 0.4323, Valid Loss: 0.3941
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5070
Epoch 6/10, Batch 20/20, Loss: 0.6786
Epoch 6/10, Train Loss: 0.4214, Valid Loss: 0.3576
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4076
Epoch 7/10, Batch 20/20, Loss: 0.5302
Epoch 7/10, Train Loss: 0.3722, Valid Loss: 0.3373
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3462
Epoch 8/10, Batch 20/20, Loss: 0.2775
Epoch 8/10, Train Loss: 0.3196, Valid Loss: 0.3118
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4639
Epoch 9/10, Batch 20/20, Loss: 0.5113
Epoch 9/10, Train Loss: 0.3128, Valid Loss: 0.2931
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3228
Epoch 10/10, Batch 20/20, Loss: 0.1785
Epoch 10/10, Train Loss: 0.2609, Valid Loss: 0.2855
Model saved!
Accuracy: 0.8925
Precision: 0.8882
Recall: 0.8925
F1-score: 0.8897
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2296
Epoch 1/10, Batch 20/20, Loss: 1.3465
Epoch 1/10, Train Loss: 1.3012, Valid Loss: 0.9548
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8218
Epoch 2/10, Batch 20/20, Loss: 1.0399
Epoch 2/10, Train Loss: 0.8473, Valid Loss: 0.6976
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5456
Epoch 3/10, Batch 20/20, Loss: 0.7985
Epoch 3/10, Train Loss: 0.6299, Valid Loss: 0.5481
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6901
Epoch 4/10, Batch 20/20, Loss: 0.4453
Epoch 4/10, Train Loss: 0.5080, Valid Loss: 0.4751
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3752
Epoch 5/10, Batch 20/20, Loss: 0.4396
Epoch 5/10, Train Loss: 0.4431, Valid Loss: 0.4329
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4663
Epoch 6/10, Batch 20/20, Loss: 0.4712
Epoch 6/10, Train Loss: 0.4029, Valid Loss: 0.3903
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4249
Epoch 7/10, Batch 20/20, Loss: 0.4373
Epoch 7/10, Train Loss: 0.3722, Valid Loss: 0.3693
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2369
Epoch 8/10, Batch 20/20, Loss: 0.2722
Epoch 8/10, Train Loss: 0.3293, Valid Loss: 0.3567
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4993
Epoch 9/10, Batch 20/20, Loss: 0.5927
Epoch 9/10, Train Loss: 0.3107, Valid Loss: 0.3327
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2755
Epoch 10/10, Batch 20/20, Loss: 0.4468
Epoch 10/10, Train Loss: 0.2750, Valid Loss: 0.3208
Model saved!
Accuracy: 0.8867
Precision: 0.8829
Recall: 0.8867
F1-score: 0.8825
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3141
Epoch 1/10, Batch 20/20, Loss: 1.2665
Epoch 1/10, Train Loss: 1.3236, Valid Loss: 0.9670
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9130
Epoch 2/10, Batch 20/20, Loss: 0.8960
Epoch 2/10, Train Loss: 0.8674, Valid Loss: 0.6926
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5577
Epoch 3/10, Batch 20/20, Loss: 1.3559
Epoch 3/10, Train Loss: 0.6742, Valid Loss: 0.5640
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.8032
Epoch 4/10, Batch 20/20, Loss: 0.4674
Epoch 4/10, Train Loss: 0.5426, Valid Loss: 0.4874
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3841
Epoch 5/10, Batch 20/20, Loss: 0.3828
Epoch 5/10, Train Loss: 0.4585, Valid Loss: 0.4449
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4597
Epoch 6/10, Batch 20/20, Loss: 0.5743
Epoch 6/10, Train Loss: 0.4400, Valid Loss: 0.3984
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3828
Epoch 7/10, Batch 20/20, Loss: 0.4427
Epoch 7/10, Train Loss: 0.3868, Valid Loss: 0.3736
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3151
Epoch 8/10, Batch 20/20, Loss: 0.3049
Epoch 8/10, Train Loss: 0.3481, Valid Loss: 0.3621
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5614
Epoch 9/10, Batch 20/20, Loss: 0.8109
Epoch 9/10, Train Loss: 0.3556, Valid Loss: 0.3439
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2349
Epoch 10/10, Batch 20/20, Loss: 0.2795
Epoch 10/10, Train Loss: 0.2904, Valid Loss: 0.3336
Model saved!
Accuracy: 0.8902
Precision: 0.8873
Recall: 0.8902
F1-score: 0.8878
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2230
Epoch 1/10, Batch 20/20, Loss: 1.2592
Epoch 1/10, Train Loss: 1.3171, Valid Loss: 0.9713
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8393
Epoch 2/10, Batch 20/20, Loss: 0.8427
Epoch 2/10, Train Loss: 0.8726, Valid Loss: 0.6869
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5526
Epoch 3/10, Batch 20/20, Loss: 0.8815
Epoch 3/10, Train Loss: 0.6679, Valid Loss: 0.5594
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7397
Epoch 4/10, Batch 20/20, Loss: 0.5544
Epoch 4/10, Train Loss: 0.5474, Valid Loss: 0.4879
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5031
Epoch 5/10, Batch 20/20, Loss: 0.7179
Epoch 5/10, Train Loss: 0.4680, Valid Loss: 0.4350
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5023
Epoch 6/10, Batch 20/20, Loss: 0.5136
Epoch 6/10, Train Loss: 0.4358, Valid Loss: 0.3995
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4041
Epoch 7/10, Batch 20/20, Loss: 0.2750
Epoch 7/10, Train Loss: 0.3872, Valid Loss: 0.3744
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3597
Epoch 8/10, Batch 20/20, Loss: 0.2440
Epoch 8/10, Train Loss: 0.3450, Valid Loss: 0.3525
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4257
Epoch 9/10, Batch 20/20, Loss: 0.8650
Epoch 9/10, Train Loss: 0.3621, Valid Loss: 0.3342
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2568
Epoch 10/10, Batch 20/20, Loss: 0.3232
Epoch 10/10, Train Loss: 0.3076, Valid Loss: 0.3283
Model saved!
Accuracy: 0.8960
Precision: 0.8918
Recall: 0.8960
F1-score: 0.8934
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2098
Epoch 1/10, Batch 20/20, Loss: 1.3487
Epoch 1/10, Train Loss: 1.2889, Valid Loss: 0.9473
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7269
Epoch 2/10, Batch 20/20, Loss: 0.9612
Epoch 2/10, Train Loss: 0.8275, Valid Loss: 0.7133
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4863
Epoch 3/10, Batch 20/20, Loss: 0.7065
Epoch 3/10, Train Loss: 0.6053, Valid Loss: 0.5804
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7334
Epoch 4/10, Batch 20/20, Loss: 0.3735
Epoch 4/10, Train Loss: 0.4963, Valid Loss: 0.5250
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4096
Epoch 5/10, Batch 20/20, Loss: 0.2998
Epoch 5/10, Train Loss: 0.4142, Valid Loss: 0.4753
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4455
Epoch 6/10, Batch 20/20, Loss: 0.7045
Epoch 6/10, Train Loss: 0.4061, Valid Loss: 0.4290
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3780
Epoch 7/10, Batch 20/20, Loss: 0.5011
Epoch 7/10, Train Loss: 0.3574, Valid Loss: 0.4167
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3238
Epoch 8/10, Batch 20/20, Loss: 0.1515
Epoch 8/10, Train Loss: 0.3166, Valid Loss: 0.3819
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4424
Epoch 9/10, Batch 20/20, Loss: 0.4353
Epoch 9/10, Train Loss: 0.2999, Valid Loss: 0.3850
Epoch 10/10, Batch 10/20, Loss: 0.2239
Epoch 10/10, Batch 20/20, Loss: 0.2972
Epoch 10/10, Train Loss: 0.2635, Valid Loss: 0.3515
Model saved!
Accuracy: 0.8808
Precision: 0.8749
Recall: 0.8808
F1-score: 0.8761
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2484
Epoch 1/10, Batch 20/20, Loss: 1.1809
Epoch 1/10, Train Loss: 1.3033, Valid Loss: 0.9275
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8007
Epoch 2/10, Batch 20/20, Loss: 0.7559
Epoch 2/10, Train Loss: 0.8232, Valid Loss: 0.6472
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5276
Epoch 3/10, Batch 20/20, Loss: 0.5119
Epoch 3/10, Train Loss: 0.6044, Valid Loss: 0.5101
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6625
Epoch 4/10, Batch 20/20, Loss: 0.4560
Epoch 4/10, Train Loss: 0.4981, Valid Loss: 0.4377
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4136
Epoch 5/10, Batch 20/20, Loss: 0.4843
Epoch 5/10, Train Loss: 0.4273, Valid Loss: 0.3912
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5611
Epoch 6/10, Batch 20/20, Loss: 0.5977
Epoch 6/10, Train Loss: 0.4156, Valid Loss: 0.3545
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4346
Epoch 7/10, Batch 20/20, Loss: 0.4220
Epoch 7/10, Train Loss: 0.3464, Valid Loss: 0.3358
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2740
Epoch 8/10, Batch 20/20, Loss: 0.3397
Epoch 8/10, Train Loss: 0.3225, Valid Loss: 0.3111
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4275
Epoch 9/10, Batch 20/20, Loss: 0.4477
Epoch 9/10, Train Loss: 0.3153, Valid Loss: 0.2980
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2407
Epoch 10/10, Batch 20/20, Loss: 0.2572
Epoch 10/10, Train Loss: 0.2686, Valid Loss: 0.2919
Model saved!
Accuracy: 0.8820
Precision: 0.8744
Recall: 0.8820
F1-score: 0.8756
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2104
Epoch 1/10, Batch 20/20, Loss: 1.2896
Epoch 1/10, Train Loss: 1.2954, Valid Loss: 0.9390
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8178
Epoch 2/10, Batch 20/20, Loss: 1.0116
Epoch 2/10, Train Loss: 0.8392, Valid Loss: 0.6686
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4898
Epoch 3/10, Batch 20/20, Loss: 0.7982
Epoch 3/10, Train Loss: 0.6153, Valid Loss: 0.5284
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6465
Epoch 4/10, Batch 20/20, Loss: 0.4972
Epoch 4/10, Train Loss: 0.5129, Valid Loss: 0.4570
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.2754
Epoch 5/10, Batch 20/20, Loss: 0.2645
Epoch 5/10, Train Loss: 0.4063, Valid Loss: 0.4004
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5406
Epoch 6/10, Batch 20/20, Loss: 0.5082
Epoch 6/10, Train Loss: 0.4051, Valid Loss: 0.3715
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4624
Epoch 7/10, Batch 20/20, Loss: 0.3148
Epoch 7/10, Train Loss: 0.3527, Valid Loss: 0.3393
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2763
Epoch 8/10, Batch 20/20, Loss: 0.4289
Epoch 8/10, Train Loss: 0.3146, Valid Loss: 0.3221
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4280
Epoch 9/10, Batch 20/20, Loss: 0.5441
Epoch 9/10, Train Loss: 0.3072, Valid Loss: 0.3045
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1754
Epoch 10/10, Batch 20/20, Loss: 0.2223
Epoch 10/10, Train Loss: 0.2557, Valid Loss: 0.2938
Model saved!
Accuracy: 0.8843
Precision: 0.8777
Recall: 0.8843
F1-score: 0.8774
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1504
Epoch 1/10, Batch 20/20, Loss: 1.1664
Epoch 1/10, Train Loss: 1.2800, Valid Loss: 0.9241
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8107
Epoch 2/10, Batch 20/20, Loss: 0.8493
Epoch 2/10, Train Loss: 0.8254, Valid Loss: 0.6594
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5722
Epoch 3/10, Batch 20/20, Loss: 0.7026
Epoch 3/10, Train Loss: 0.6096, Valid Loss: 0.5168
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5696
Epoch 4/10, Batch 20/20, Loss: 0.3243
Epoch 4/10, Train Loss: 0.4980, Valid Loss: 0.4465
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4278
Epoch 5/10, Batch 20/20, Loss: 0.4118
Epoch 5/10, Train Loss: 0.4013, Valid Loss: 0.4016
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4414
Epoch 6/10, Batch 20/20, Loss: 0.6351
Epoch 6/10, Train Loss: 0.3879, Valid Loss: 0.3599
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.2794
Epoch 7/10, Batch 20/20, Loss: 0.3972
Epoch 7/10, Train Loss: 0.3421, Valid Loss: 0.3494
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3458
Epoch 8/10, Batch 20/20, Loss: 0.2443
Epoch 8/10, Train Loss: 0.2978, Valid Loss: 0.3324
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4559
Epoch 9/10, Batch 20/20, Loss: 0.7526
Epoch 9/10, Train Loss: 0.2993, Valid Loss: 0.3146
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2372
Epoch 10/10, Batch 20/20, Loss: 0.2527
Epoch 10/10, Train Loss: 0.2505, Valid Loss: 0.3029
Model saved!
Accuracy: 0.8902
Precision: 0.8859
Recall: 0.8902
F1-score: 0.8865
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1754
Epoch 1/10, Batch 20/20, Loss: 1.1265
Epoch 1/10, Train Loss: 1.2980, Valid Loss: 0.9417
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7848
Epoch 2/10, Batch 20/20, Loss: 0.9918
Epoch 2/10, Train Loss: 0.8465, Valid Loss: 0.6724
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5722
Epoch 3/10, Batch 20/20, Loss: 1.0636
Epoch 3/10, Train Loss: 0.6387, Valid Loss: 0.5474
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6642
Epoch 4/10, Batch 20/20, Loss: 0.4812
Epoch 4/10, Train Loss: 0.5177, Valid Loss: 0.4802
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4356
Epoch 5/10, Batch 20/20, Loss: 0.2032
Epoch 5/10, Train Loss: 0.4224, Valid Loss: 0.4268
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.7019
Epoch 6/10, Batch 20/20, Loss: 0.4541
Epoch 6/10, Train Loss: 0.4113, Valid Loss: 0.3933
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4495
Epoch 7/10, Batch 20/20, Loss: 0.3107
Epoch 7/10, Train Loss: 0.3683, Valid Loss: 0.3640
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3266
Epoch 8/10, Batch 20/20, Loss: 0.4209
Epoch 8/10, Train Loss: 0.3340, Valid Loss: 0.3418
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3938
Epoch 9/10, Batch 20/20, Loss: 0.6584
Epoch 9/10, Train Loss: 0.3265, Valid Loss: 0.3343
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2606
Epoch 10/10, Batch 20/20, Loss: 0.1942
Epoch 10/10, Train Loss: 0.2720, Valid Loss: 0.3282
Model saved!
Accuracy: 0.8820
Precision: 0.8779
Recall: 0.8820
F1-score: 0.8791
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3184
Epoch 1/10, Batch 20/20, Loss: 1.1352
Epoch 1/10, Train Loss: 1.2960, Valid Loss: 0.9603
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8762
Epoch 2/10, Batch 20/20, Loss: 0.9815
Epoch 2/10, Train Loss: 0.8535, Valid Loss: 0.7020
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4910
Epoch 3/10, Batch 20/20, Loss: 0.8414
Epoch 3/10, Train Loss: 0.6271, Valid Loss: 0.5768
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7662
Epoch 4/10, Batch 20/20, Loss: 0.4059
Epoch 4/10, Train Loss: 0.5000, Valid Loss: 0.4953
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5393
Epoch 5/10, Batch 20/20, Loss: 0.3055
Epoch 5/10, Train Loss: 0.4263, Valid Loss: 0.4524
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4684
Epoch 6/10, Batch 20/20, Loss: 0.4076
Epoch 6/10, Train Loss: 0.3909, Valid Loss: 0.4184
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4681
Epoch 7/10, Batch 20/20, Loss: 0.5442
Epoch 7/10, Train Loss: 0.3672, Valid Loss: 0.3926
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3065
Epoch 8/10, Batch 20/20, Loss: 0.2753
Epoch 8/10, Train Loss: 0.3273, Valid Loss: 0.3780
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3684
Epoch 9/10, Batch 20/20, Loss: 0.9687
Epoch 9/10, Train Loss: 0.3236, Valid Loss: 0.3622
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3615
Epoch 10/10, Batch 20/20, Loss: 0.2966
Epoch 10/10, Train Loss: 0.2712, Valid Loss: 0.3567
Model saved!
Accuracy: 0.8785
Precision: 0.8728
Recall: 0.8785
F1-score: 0.8743
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2208
Epoch 1/10, Batch 20/20, Loss: 1.2011
Epoch 1/10, Train Loss: 1.2960, Valid Loss: 0.9394
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9835
Epoch 2/10, Batch 20/20, Loss: 0.8931
Epoch 2/10, Train Loss: 0.8517, Valid Loss: 0.6794
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5362
Epoch 3/10, Batch 20/20, Loss: 0.6209
Epoch 3/10, Train Loss: 0.6340, Valid Loss: 0.5447
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6435
Epoch 4/10, Batch 20/20, Loss: 0.4102
Epoch 4/10, Train Loss: 0.5241, Valid Loss: 0.4747
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4732
Epoch 5/10, Batch 20/20, Loss: 0.4058
Epoch 5/10, Train Loss: 0.4408, Valid Loss: 0.4308
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5768
Epoch 6/10, Batch 20/20, Loss: 0.7305
Epoch 6/10, Train Loss: 0.4236, Valid Loss: 0.4006
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4385
Epoch 7/10, Batch 20/20, Loss: 0.3978
Epoch 7/10, Train Loss: 0.3739, Valid Loss: 0.3813
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4693
Epoch 8/10, Batch 20/20, Loss: 0.3403
Epoch 8/10, Train Loss: 0.3435, Valid Loss: 0.3497
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5470
Epoch 9/10, Batch 20/20, Loss: 0.6464
Epoch 9/10, Train Loss: 0.3294, Valid Loss: 0.3398
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2617
Epoch 10/10, Batch 20/20, Loss: 0.2650
Epoch 10/10, Train Loss: 0.2738, Valid Loss: 0.3221
Model saved!
Accuracy: 0.8879
Precision: 0.8826
Recall: 0.8879
F1-score: 0.8841
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2593
Epoch 1/10, Batch 20/20, Loss: 1.3073
Epoch 1/10, Train Loss: 1.3011, Valid Loss: 0.9301
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9237
Epoch 2/10, Batch 20/20, Loss: 1.0460
Epoch 2/10, Train Loss: 0.8393, Valid Loss: 0.6650
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6278
Epoch 3/10, Batch 20/20, Loss: 0.5248
Epoch 3/10, Train Loss: 0.6141, Valid Loss: 0.5388
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6693
Epoch 4/10, Batch 20/20, Loss: 0.5692
Epoch 4/10, Train Loss: 0.5168, Valid Loss: 0.4604
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4358
Epoch 5/10, Batch 20/20, Loss: 0.2871
Epoch 5/10, Train Loss: 0.4303, Valid Loss: 0.4110
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5958
Epoch 6/10, Batch 20/20, Loss: 0.7244
Epoch 6/10, Train Loss: 0.4207, Valid Loss: 0.3753
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4143
Epoch 7/10, Batch 20/20, Loss: 0.4628
Epoch 7/10, Train Loss: 0.3619, Valid Loss: 0.3524
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2095
Epoch 8/10, Batch 20/20, Loss: 0.2532
Epoch 8/10, Train Loss: 0.3214, Valid Loss: 0.3332
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4240
Epoch 9/10, Batch 20/20, Loss: 0.5974
Epoch 9/10, Train Loss: 0.3243, Valid Loss: 0.3190
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2064
Epoch 10/10, Batch 20/20, Loss: 0.3097
Epoch 10/10, Train Loss: 0.2692, Valid Loss: 0.3045
Model saved!
Accuracy: 0.8867
Precision: 0.8812
Recall: 0.8867
F1-score: 0.8824
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2694
Epoch 1/10, Batch 20/20, Loss: 1.2269
Epoch 1/10, Train Loss: 1.3208, Valid Loss: 1.0027
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9314
Epoch 2/10, Batch 20/20, Loss: 1.0088
Epoch 2/10, Train Loss: 0.8878, Valid Loss: 0.7556
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5543
Epoch 3/10, Batch 20/20, Loss: 0.9298
Epoch 3/10, Train Loss: 0.6843, Valid Loss: 0.6325
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6767
Epoch 4/10, Batch 20/20, Loss: 0.5262
Epoch 4/10, Train Loss: 0.5709, Valid Loss: 0.5585
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5267
Epoch 5/10, Batch 20/20, Loss: 0.3748
Epoch 5/10, Train Loss: 0.4588, Valid Loss: 0.5116
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5383
Epoch 6/10, Batch 20/20, Loss: 0.4306
Epoch 6/10, Train Loss: 0.4545, Valid Loss: 0.4603
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.5038
Epoch 7/10, Batch 20/20, Loss: 0.5707
Epoch 7/10, Train Loss: 0.4102, Valid Loss: 0.4503
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3214
Epoch 8/10, Batch 20/20, Loss: 0.2199
Epoch 8/10, Train Loss: 0.3720, Valid Loss: 0.4326
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4745
Epoch 9/10, Batch 20/20, Loss: 0.6662
Epoch 9/10, Train Loss: 0.3597, Valid Loss: 0.4144
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2637
Epoch 10/10, Batch 20/20, Loss: 0.2197
Epoch 10/10, Train Loss: 0.3044, Valid Loss: 0.4020
Model saved!
Accuracy: 0.8843
Precision: 0.8810
Recall: 0.8843
F1-score: 0.8808
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2381
Epoch 1/10, Batch 20/20, Loss: 1.1615
Epoch 1/10, Train Loss: 1.3194, Valid Loss: 0.9731
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8952
Epoch 2/10, Batch 20/20, Loss: 0.9126
Epoch 2/10, Train Loss: 0.8654, Valid Loss: 0.6986
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5435
Epoch 3/10, Batch 20/20, Loss: 0.6410
Epoch 3/10, Train Loss: 0.6454, Valid Loss: 0.5647
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7298
Epoch 4/10, Batch 20/20, Loss: 0.4096
Epoch 4/10, Train Loss: 0.5236, Valid Loss: 0.4933
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4010
Epoch 5/10, Batch 20/20, Loss: 0.4695
Epoch 5/10, Train Loss: 0.4501, Valid Loss: 0.4499
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6746
Epoch 6/10, Batch 20/20, Loss: 0.4119
Epoch 6/10, Train Loss: 0.4243, Valid Loss: 0.4101
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4531
Epoch 7/10, Batch 20/20, Loss: 0.3213
Epoch 7/10, Train Loss: 0.3719, Valid Loss: 0.3815
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2966
Epoch 8/10, Batch 20/20, Loss: 0.3470
Epoch 8/10, Train Loss: 0.3412, Valid Loss: 0.3662
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5650
Epoch 9/10, Batch 20/20, Loss: 0.7715
Epoch 9/10, Train Loss: 0.3445, Valid Loss: 0.3496
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2415
Epoch 10/10, Batch 20/20, Loss: 0.3828
Epoch 10/10, Train Loss: 0.2951, Valid Loss: 0.3332
Model saved!
Accuracy: 0.8843
Precision: 0.8788
Recall: 0.8843
F1-score: 0.8802
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3043
Epoch 1/10, Batch 20/20, Loss: 1.1985
Epoch 1/10, Train Loss: 1.3196, Valid Loss: 0.9579
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8884
Epoch 2/10, Batch 20/20, Loss: 1.0736
Epoch 2/10, Train Loss: 0.8816, Valid Loss: 0.6747
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5472
Epoch 3/10, Batch 20/20, Loss: 0.6565
Epoch 3/10, Train Loss: 0.6433, Valid Loss: 0.5389
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6958
Epoch 4/10, Batch 20/20, Loss: 0.6095
Epoch 4/10, Train Loss: 0.5339, Valid Loss: 0.4762
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4475
Epoch 5/10, Batch 20/20, Loss: 0.8846
Epoch 5/10, Train Loss: 0.4686, Valid Loss: 0.4256
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6038
Epoch 6/10, Batch 20/20, Loss: 0.6389
Epoch 6/10, Train Loss: 0.4346, Valid Loss: 0.4003
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3839
Epoch 7/10, Batch 20/20, Loss: 0.2120
Epoch 7/10, Train Loss: 0.3736, Valid Loss: 0.3815
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3325
Epoch 8/10, Batch 20/20, Loss: 0.3558
Epoch 8/10, Train Loss: 0.3515, Valid Loss: 0.3713
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3457
Epoch 9/10, Batch 20/20, Loss: 0.5477
Epoch 9/10, Train Loss: 0.3342, Valid Loss: 0.3523
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2215
Epoch 10/10, Batch 20/20, Loss: 0.1692
Epoch 10/10, Train Loss: 0.2692, Valid Loss: 0.3398
Model saved!
Accuracy: 0.8972
Precision: 0.8934
Recall: 0.8972
F1-score: 0.8939
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2390
Epoch 1/10, Batch 20/20, Loss: 1.0875
Epoch 1/10, Train Loss: 1.2876, Valid Loss: 0.9344
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8101
Epoch 2/10, Batch 20/20, Loss: 0.8372
Epoch 2/10, Train Loss: 0.8330, Valid Loss: 0.6428
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5377
Epoch 3/10, Batch 20/20, Loss: 0.7787
Epoch 3/10, Train Loss: 0.6247, Valid Loss: 0.5116
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7106
Epoch 4/10, Batch 20/20, Loss: 0.4885
Epoch 4/10, Train Loss: 0.5015, Valid Loss: 0.4499
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3735
Epoch 5/10, Batch 20/20, Loss: 0.3220
Epoch 5/10, Train Loss: 0.4347, Valid Loss: 0.3947
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4396
Epoch 6/10, Batch 20/20, Loss: 0.5301
Epoch 6/10, Train Loss: 0.4049, Valid Loss: 0.3536
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3657
Epoch 7/10, Batch 20/20, Loss: 0.4393
Epoch 7/10, Train Loss: 0.3622, Valid Loss: 0.3347
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3440
Epoch 8/10, Batch 20/20, Loss: 0.3291
Epoch 8/10, Train Loss: 0.3280, Valid Loss: 0.3177
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5665
Epoch 9/10, Batch 20/20, Loss: 0.5621
Epoch 9/10, Train Loss: 0.3160, Valid Loss: 0.3047
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2197
Epoch 10/10, Batch 20/20, Loss: 0.2037
Epoch 10/10, Train Loss: 0.2681, Valid Loss: 0.2961
Model saved!
Accuracy: 0.8808
Precision: 0.8741
Recall: 0.8808
F1-score: 0.8751
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2136
Epoch 1/10, Batch 20/20, Loss: 1.1923
Epoch 1/10, Train Loss: 1.3077, Valid Loss: 0.9087
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7979
Epoch 2/10, Batch 20/20, Loss: 0.9198
Epoch 2/10, Train Loss: 0.8546, Valid Loss: 0.6482
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4928
Epoch 3/10, Batch 20/20, Loss: 0.8393
Epoch 3/10, Train Loss: 0.6361, Valid Loss: 0.5108
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.8471
Epoch 4/10, Batch 20/20, Loss: 0.3904
Epoch 4/10, Train Loss: 0.5135, Valid Loss: 0.4425
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3879
Epoch 5/10, Batch 20/20, Loss: 0.3958
Epoch 5/10, Train Loss: 0.4407, Valid Loss: 0.4019
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5084
Epoch 6/10, Batch 20/20, Loss: 0.5304
Epoch 6/10, Train Loss: 0.4188, Valid Loss: 0.3713
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3065
Epoch 7/10, Batch 20/20, Loss: 0.6062
Epoch 7/10, Train Loss: 0.3929, Valid Loss: 0.3445
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2252
Epoch 8/10, Batch 20/20, Loss: 0.3592
Epoch 8/10, Train Loss: 0.3220, Valid Loss: 0.3259
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4964
Epoch 9/10, Batch 20/20, Loss: 0.6032
Epoch 9/10, Train Loss: 0.3182, Valid Loss: 0.3120
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2390
Epoch 10/10, Batch 20/20, Loss: 0.4023
Epoch 10/10, Train Loss: 0.2687, Valid Loss: 0.3019
Model saved!
Accuracy: 0.8797
Precision: 0.8716
Recall: 0.8797
F1-score: 0.8725
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2447
Epoch 1/10, Batch 20/20, Loss: 1.2388
Epoch 1/10, Train Loss: 1.2940, Valid Loss: 0.9134
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8395
Epoch 2/10, Batch 20/20, Loss: 1.1159
Epoch 2/10, Train Loss: 0.8568, Valid Loss: 0.6402
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5505
Epoch 3/10, Batch 20/20, Loss: 0.6885
Epoch 3/10, Train Loss: 0.6424, Valid Loss: 0.5092
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6769
Epoch 4/10, Batch 20/20, Loss: 0.5351
Epoch 4/10, Train Loss: 0.5306, Valid Loss: 0.4273
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3785
Epoch 5/10, Batch 20/20, Loss: 0.3501
Epoch 5/10, Train Loss: 0.4398, Valid Loss: 0.3812
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4125
Epoch 6/10, Batch 20/20, Loss: 0.8059
Epoch 6/10, Train Loss: 0.4389, Valid Loss: 0.3417
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3530
Epoch 7/10, Batch 20/20, Loss: 0.3878
Epoch 7/10, Train Loss: 0.3739, Valid Loss: 0.3165
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3377
Epoch 8/10, Batch 20/20, Loss: 0.6091
Epoch 8/10, Train Loss: 0.3531, Valid Loss: 0.2869
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4494
Epoch 9/10, Batch 20/20, Loss: 0.3836
Epoch 9/10, Train Loss: 0.3103, Valid Loss: 0.2784
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3051
Epoch 10/10, Batch 20/20, Loss: 0.3560
Epoch 10/10, Train Loss: 0.2791, Valid Loss: 0.2599
Model saved!
Accuracy: 0.8925
Precision: 0.8877
Recall: 0.8925
F1-score: 0.8886
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2250
Epoch 1/10, Batch 20/20, Loss: 1.1362
Epoch 1/10, Train Loss: 1.2883, Valid Loss: 0.9171
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7870
Epoch 2/10, Batch 20/20, Loss: 0.8593
Epoch 2/10, Train Loss: 0.8388, Valid Loss: 0.6254
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5541
Epoch 3/10, Batch 20/20, Loss: 0.9385
Epoch 3/10, Train Loss: 0.6395, Valid Loss: 0.4909
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7482
Epoch 4/10, Batch 20/20, Loss: 0.3794
Epoch 4/10, Train Loss: 0.5124, Valid Loss: 0.4058
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3842
Epoch 5/10, Batch 20/20, Loss: 0.7057
Epoch 5/10, Train Loss: 0.4497, Valid Loss: 0.3534
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5401
Epoch 6/10, Batch 20/20, Loss: 0.5409
Epoch 6/10, Train Loss: 0.4259, Valid Loss: 0.3232
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3429
Epoch 7/10, Batch 20/20, Loss: 0.5982
Epoch 7/10, Train Loss: 0.3731, Valid Loss: 0.2932
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2319
Epoch 8/10, Batch 20/20, Loss: 0.2657
Epoch 8/10, Train Loss: 0.3301, Valid Loss: 0.2718
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5317
Epoch 9/10, Batch 20/20, Loss: 0.3620
Epoch 9/10, Train Loss: 0.3151, Valid Loss: 0.2533
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1858
Epoch 10/10, Batch 20/20, Loss: 0.2105
Epoch 10/10, Train Loss: 0.2681, Valid Loss: 0.2404
Model saved!
Accuracy: 0.8949
Precision: 0.8900
Recall: 0.8949
F1-score: 0.8911
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3224
Epoch 1/10, Batch 20/20, Loss: 1.1343
Epoch 1/10, Train Loss: 1.3119, Valid Loss: 0.9676
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9584
Epoch 2/10, Batch 20/20, Loss: 0.7050
Epoch 2/10, Train Loss: 0.8575, Valid Loss: 0.6979
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6150
Epoch 3/10, Batch 20/20, Loss: 0.6129
Epoch 3/10, Train Loss: 0.6395, Valid Loss: 0.5694
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5435
Epoch 4/10, Batch 20/20, Loss: 0.3184
Epoch 4/10, Train Loss: 0.5236, Valid Loss: 0.5018
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5067
Epoch 5/10, Batch 20/20, Loss: 0.5825
Epoch 5/10, Train Loss: 0.4528, Valid Loss: 0.4584
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5206
Epoch 6/10, Batch 20/20, Loss: 0.5293
Epoch 6/10, Train Loss: 0.4298, Valid Loss: 0.4163
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4042
Epoch 7/10, Batch 20/20, Loss: 0.4547
Epoch 7/10, Train Loss: 0.3944, Valid Loss: 0.3954
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3150
Epoch 8/10, Batch 20/20, Loss: 0.4371
Epoch 8/10, Train Loss: 0.3413, Valid Loss: 0.3728
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.6110
Epoch 9/10, Batch 20/20, Loss: 0.4944
Epoch 9/10, Train Loss: 0.3386, Valid Loss: 0.3701
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2289
Epoch 10/10, Batch 20/20, Loss: 0.2520
Epoch 10/10, Train Loss: 0.2701, Valid Loss: 0.3565
Model saved!
Accuracy: 0.8937
Precision: 0.8893
Recall: 0.8937
F1-score: 0.8906
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2469
Epoch 1/10, Batch 20/20, Loss: 1.2671
Epoch 1/10, Train Loss: 1.3138, Valid Loss: 0.9931
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7751
Epoch 2/10, Batch 20/20, Loss: 0.8419
Epoch 2/10, Train Loss: 0.8377, Valid Loss: 0.7153
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6268
Epoch 3/10, Batch 20/20, Loss: 0.9191
Epoch 3/10, Train Loss: 0.6242, Valid Loss: 0.5840
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6331
Epoch 4/10, Batch 20/20, Loss: 0.5036
Epoch 4/10, Train Loss: 0.5118, Valid Loss: 0.5162
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4767
Epoch 5/10, Batch 20/20, Loss: 0.3980
Epoch 5/10, Train Loss: 0.4329, Valid Loss: 0.4615
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5122
Epoch 6/10, Batch 20/20, Loss: 0.5106
Epoch 6/10, Train Loss: 0.4108, Valid Loss: 0.4308
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3763
Epoch 7/10, Batch 20/20, Loss: 0.6073
Epoch 7/10, Train Loss: 0.3783, Valid Loss: 0.3941
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3107
Epoch 8/10, Batch 20/20, Loss: 0.3648
Epoch 8/10, Train Loss: 0.3271, Valid Loss: 0.3828
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4212
Epoch 9/10, Batch 20/20, Loss: 0.4406
Epoch 9/10, Train Loss: 0.3156, Valid Loss: 0.3594
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2582
Epoch 10/10, Batch 20/20, Loss: 0.3062
Epoch 10/10, Train Loss: 0.2720, Valid Loss: 0.3568
Model saved!
Accuracy: 0.8820
Precision: 0.8762
Recall: 0.8820
F1-score: 0.8775
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2945
Epoch 1/10, Batch 20/20, Loss: 1.1379
Epoch 1/10, Train Loss: 1.3060, Valid Loss: 0.9829
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9205
Epoch 2/10, Batch 20/20, Loss: 0.9136
Epoch 2/10, Train Loss: 0.8691, Valid Loss: 0.7261
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4870
Epoch 3/10, Batch 20/20, Loss: 0.8144
Epoch 3/10, Train Loss: 0.6406, Valid Loss: 0.6079
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6593
Epoch 4/10, Batch 20/20, Loss: 0.4031
Epoch 4/10, Train Loss: 0.5252, Valid Loss: 0.5394
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4164
Epoch 5/10, Batch 20/20, Loss: 0.4180
Epoch 5/10, Train Loss: 0.4499, Valid Loss: 0.5003
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4506
Epoch 6/10, Batch 20/20, Loss: 0.5525
Epoch 6/10, Train Loss: 0.4167, Valid Loss: 0.4636
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4378
Epoch 7/10, Batch 20/20, Loss: 0.4909
Epoch 7/10, Train Loss: 0.3767, Valid Loss: 0.4444
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2457
Epoch 8/10, Batch 20/20, Loss: 0.4130
Epoch 8/10, Train Loss: 0.3441, Valid Loss: 0.4385
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4501
Epoch 9/10, Batch 20/20, Loss: 0.6271
Epoch 9/10, Train Loss: 0.3321, Valid Loss: 0.4109
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3132
Epoch 10/10, Batch 20/20, Loss: 0.6472
Epoch 10/10, Train Loss: 0.3003, Valid Loss: 0.4077
Model saved!
Accuracy: 0.8808
Precision: 0.8779
Recall: 0.8808
F1-score: 0.8791
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1871
Epoch 1/10, Batch 20/20, Loss: 1.1656
Epoch 1/10, Train Loss: 1.2937, Valid Loss: 0.9313
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7546
Epoch 2/10, Batch 20/20, Loss: 0.8864
Epoch 2/10, Train Loss: 0.8371, Valid Loss: 0.6642
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5570
Epoch 3/10, Batch 20/20, Loss: 0.5885
Epoch 3/10, Train Loss: 0.6236, Valid Loss: 0.5257
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6475
Epoch 4/10, Batch 20/20, Loss: 0.3944
Epoch 4/10, Train Loss: 0.5136, Valid Loss: 0.4674
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4727
Epoch 5/10, Batch 20/20, Loss: 0.3892
Epoch 5/10, Train Loss: 0.4232, Valid Loss: 0.4116
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4487
Epoch 6/10, Batch 20/20, Loss: 0.6684
Epoch 6/10, Train Loss: 0.4111, Valid Loss: 0.3943
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4616
Epoch 7/10, Batch 20/20, Loss: 0.3786
Epoch 7/10, Train Loss: 0.3711, Valid Loss: 0.3680
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3072
Epoch 8/10, Batch 20/20, Loss: 0.2430
Epoch 8/10, Train Loss: 0.3226, Valid Loss: 0.3528
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4945
Epoch 9/10, Batch 20/20, Loss: 0.4957
Epoch 9/10, Train Loss: 0.3128, Valid Loss: 0.3258
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1967
Epoch 10/10, Batch 20/20, Loss: 0.2155
Epoch 10/10, Train Loss: 0.2643, Valid Loss: 0.3201
Model saved!
Accuracy: 0.8925
Precision: 0.8876
Recall: 0.8925
F1-score: 0.8891
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2997
Epoch 1/10, Batch 20/20, Loss: 1.1700
Epoch 1/10, Train Loss: 1.3046, Valid Loss: 0.9517
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8847
Epoch 2/10, Batch 20/20, Loss: 1.1159
Epoch 2/10, Train Loss: 0.8489, Valid Loss: 0.6893
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5375
Epoch 3/10, Batch 20/20, Loss: 0.5848
Epoch 3/10, Train Loss: 0.6114, Valid Loss: 0.5734
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6100
Epoch 4/10, Batch 20/20, Loss: 0.4893
Epoch 4/10, Train Loss: 0.5134, Valid Loss: 0.5114
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4346
Epoch 5/10, Batch 20/20, Loss: 0.6062
Epoch 5/10, Train Loss: 0.4307, Valid Loss: 0.4667
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4655
Epoch 6/10, Batch 20/20, Loss: 0.6624
Epoch 6/10, Train Loss: 0.4224, Valid Loss: 0.4369
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4204
Epoch 7/10, Batch 20/20, Loss: 0.2136
Epoch 7/10, Train Loss: 0.3518, Valid Loss: 0.4239
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2827
Epoch 8/10, Batch 20/20, Loss: 0.3754
Epoch 8/10, Train Loss: 0.3230, Valid Loss: 0.4085
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5175
Epoch 9/10, Batch 20/20, Loss: 0.5838
Epoch 9/10, Train Loss: 0.3162, Valid Loss: 0.4031
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2614
Epoch 10/10, Batch 20/20, Loss: 0.1908
Epoch 10/10, Train Loss: 0.2620, Valid Loss: 0.3914
Model saved!
Accuracy: 0.8855
Precision: 0.8801
Recall: 0.8855
F1-score: 0.8817
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2394
Epoch 1/10, Batch 20/20, Loss: 1.3026
Epoch 1/10, Train Loss: 1.3125, Valid Loss: 0.9147
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8940
Epoch 2/10, Batch 20/20, Loss: 0.8802
Epoch 2/10, Train Loss: 0.8428, Valid Loss: 0.6222
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6474
Epoch 3/10, Batch 20/20, Loss: 0.6801
Epoch 3/10, Train Loss: 0.6273, Valid Loss: 0.4822
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7520
Epoch 4/10, Batch 20/20, Loss: 0.4316
Epoch 4/10, Train Loss: 0.5053, Valid Loss: 0.4049
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4918
Epoch 5/10, Batch 20/20, Loss: 0.3938
Epoch 5/10, Train Loss: 0.4194, Valid Loss: 0.3571
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5350
Epoch 6/10, Batch 20/20, Loss: 0.5635
Epoch 6/10, Train Loss: 0.4131, Valid Loss: 0.3169
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3549
Epoch 7/10, Batch 20/20, Loss: 0.3150
Epoch 7/10, Train Loss: 0.3489, Valid Loss: 0.2890
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2648
Epoch 8/10, Batch 20/20, Loss: 0.3925
Epoch 8/10, Train Loss: 0.3149, Valid Loss: 0.2770
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4667
Epoch 9/10, Batch 20/20, Loss: 0.5727
Epoch 9/10, Train Loss: 0.3199, Valid Loss: 0.2593
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2915
Epoch 10/10, Batch 20/20, Loss: 0.4588
Epoch 10/10, Train Loss: 0.2671, Valid Loss: 0.2465
Model saved!
Accuracy: 0.8914
Precision: 0.8859
Recall: 0.8914
F1-score: 0.8859
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2961
Epoch 1/10, Batch 20/20, Loss: 1.2507
Epoch 1/10, Train Loss: 1.3056, Valid Loss: 0.9393
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8692
Epoch 2/10, Batch 20/20, Loss: 0.9821
Epoch 2/10, Train Loss: 0.8639, Valid Loss: 0.6822
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5414
Epoch 3/10, Batch 20/20, Loss: 0.7756
Epoch 3/10, Train Loss: 0.6559, Valid Loss: 0.5608
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6924
Epoch 4/10, Batch 20/20, Loss: 0.4005
Epoch 4/10, Train Loss: 0.5398, Valid Loss: 0.4899
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4323
Epoch 5/10, Batch 20/20, Loss: 0.4354
Epoch 5/10, Train Loss: 0.4659, Valid Loss: 0.4418
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5054
Epoch 6/10, Batch 20/20, Loss: 0.6764
Epoch 6/10, Train Loss: 0.4402, Valid Loss: 0.4046
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4618
Epoch 7/10, Batch 20/20, Loss: 0.3429
Epoch 7/10, Train Loss: 0.3971, Valid Loss: 0.3830
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3722
Epoch 8/10, Batch 20/20, Loss: 0.3140
Epoch 8/10, Train Loss: 0.3585, Valid Loss: 0.3518
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5469
Epoch 9/10, Batch 20/20, Loss: 0.6044
Epoch 9/10, Train Loss: 0.3491, Valid Loss: 0.3459
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1916
Epoch 10/10, Batch 20/20, Loss: 0.1887
Epoch 10/10, Train Loss: 0.2896, Valid Loss: 0.3388
Model saved!
Accuracy: 0.8808
Precision: 0.8779
Recall: 0.8808
F1-score: 0.8771
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3000
Epoch 1/10, Batch 20/20, Loss: 1.1440
Epoch 1/10, Train Loss: 1.3180, Valid Loss: 0.9670
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9786
Epoch 2/10, Batch 20/20, Loss: 0.8540
Epoch 2/10, Train Loss: 0.8889, Valid Loss: 0.6950
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5498
Epoch 3/10, Batch 20/20, Loss: 0.8661
Epoch 3/10, Train Loss: 0.6731, Valid Loss: 0.5636
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7393
Epoch 4/10, Batch 20/20, Loss: 0.5985
Epoch 4/10, Train Loss: 0.5653, Valid Loss: 0.4879
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.6480
Epoch 5/10, Batch 20/20, Loss: 0.7081
Epoch 5/10, Train Loss: 0.4971, Valid Loss: 0.4448
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5869
Epoch 6/10, Batch 20/20, Loss: 0.7569
Epoch 6/10, Train Loss: 0.4686, Valid Loss: 0.3998
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4672
Epoch 7/10, Batch 20/20, Loss: 0.4626
Epoch 7/10, Train Loss: 0.4084, Valid Loss: 0.3765
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3107
Epoch 8/10, Batch 20/20, Loss: 0.4703
Epoch 8/10, Train Loss: 0.3692, Valid Loss: 0.3612
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5414
Epoch 9/10, Batch 20/20, Loss: 0.5377
Epoch 9/10, Train Loss: 0.3564, Valid Loss: 0.3451
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3453
Epoch 10/10, Batch 20/20, Loss: 0.2805
Epoch 10/10, Train Loss: 0.3155, Valid Loss: 0.3304
Model saved!
Accuracy: 0.8879
Precision: 0.8872
Recall: 0.8879
F1-score: 0.8868
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2817
Epoch 1/10, Batch 20/20, Loss: 1.3077
Epoch 1/10, Train Loss: 1.3152, Valid Loss: 0.9592
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8578
Epoch 2/10, Batch 20/20, Loss: 0.8489
Epoch 2/10, Train Loss: 0.8671, Valid Loss: 0.6718
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4925
Epoch 3/10, Batch 20/20, Loss: 0.6244
Epoch 3/10, Train Loss: 0.6465, Valid Loss: 0.5396
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6443
Epoch 4/10, Batch 20/20, Loss: 0.5086
Epoch 4/10, Train Loss: 0.5330, Valid Loss: 0.4651
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.6119
Epoch 5/10, Batch 20/20, Loss: 0.6485
Epoch 5/10, Train Loss: 0.4585, Valid Loss: 0.4070
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6187
Epoch 6/10, Batch 20/20, Loss: 0.6104
Epoch 6/10, Train Loss: 0.4480, Valid Loss: 0.3670
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3320
Epoch 7/10, Batch 20/20, Loss: 0.3859
Epoch 7/10, Train Loss: 0.3800, Valid Loss: 0.3421
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2671
Epoch 8/10, Batch 20/20, Loss: 0.3158
Epoch 8/10, Train Loss: 0.3465, Valid Loss: 0.3158
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3614
Epoch 9/10, Batch 20/20, Loss: 0.4012
Epoch 9/10, Train Loss: 0.3237, Valid Loss: 0.2989
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3886
Epoch 10/10, Batch 20/20, Loss: 0.2332
Epoch 10/10, Train Loss: 0.2906, Valid Loss: 0.2838
Model saved!
Accuracy: 0.8937
Precision: 0.8883
Recall: 0.8937
F1-score: 0.8893
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2863
Epoch 1/10, Batch 20/20, Loss: 1.1349
Epoch 1/10, Train Loss: 1.2834, Valid Loss: 0.9774
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8039
Epoch 2/10, Batch 20/20, Loss: 0.6818
Epoch 2/10, Train Loss: 0.8075, Valid Loss: 0.7050
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5655
Epoch 3/10, Batch 20/20, Loss: 0.9721
Epoch 3/10, Train Loss: 0.6197, Valid Loss: 0.5867
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6846
Epoch 4/10, Batch 20/20, Loss: 0.6701
Epoch 4/10, Train Loss: 0.5135, Valid Loss: 0.5110
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3933
Epoch 5/10, Batch 20/20, Loss: 0.3322
Epoch 5/10, Train Loss: 0.4262, Valid Loss: 0.4601
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4873
Epoch 6/10, Batch 20/20, Loss: 0.4684
Epoch 6/10, Train Loss: 0.4170, Valid Loss: 0.4234
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4509
Epoch 7/10, Batch 20/20, Loss: 0.7985
Epoch 7/10, Train Loss: 0.3721, Valid Loss: 0.4037
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3709
Epoch 8/10, Batch 20/20, Loss: 0.3547
Epoch 8/10, Train Loss: 0.3298, Valid Loss: 0.3834
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4910
Epoch 9/10, Batch 20/20, Loss: 0.4205
Epoch 9/10, Train Loss: 0.3179, Valid Loss: 0.3719
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2392
Epoch 10/10, Batch 20/20, Loss: 0.3954
Epoch 10/10, Train Loss: 0.2680, Valid Loss: 0.3543
Model saved!
Accuracy: 0.8855
Precision: 0.8806
Recall: 0.8855
F1-score: 0.8822
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2405
Epoch 1/10, Batch 20/20, Loss: 1.1339
Epoch 1/10, Train Loss: 1.2898, Valid Loss: 0.9123
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7615
Epoch 2/10, Batch 20/20, Loss: 0.9662
Epoch 2/10, Train Loss: 0.8494, Valid Loss: 0.6505
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5209
Epoch 3/10, Batch 20/20, Loss: 1.0736
Epoch 3/10, Train Loss: 0.6395, Valid Loss: 0.5352
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.8028
Epoch 4/10, Batch 20/20, Loss: 0.3079
Epoch 4/10, Train Loss: 0.5056, Valid Loss: 0.4675
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3954
Epoch 5/10, Batch 20/20, Loss: 0.5664
Epoch 5/10, Train Loss: 0.4363, Valid Loss: 0.4289
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4380
Epoch 6/10, Batch 20/20, Loss: 0.5681
Epoch 6/10, Train Loss: 0.4119, Valid Loss: 0.3995
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3282
Epoch 7/10, Batch 20/20, Loss: 0.4747
Epoch 7/10, Train Loss: 0.3761, Valid Loss: 0.3782
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3044
Epoch 8/10, Batch 20/20, Loss: 0.2996
Epoch 8/10, Train Loss: 0.3444, Valid Loss: 0.3696
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4849
Epoch 9/10, Batch 20/20, Loss: 0.8275
Epoch 9/10, Train Loss: 0.3264, Valid Loss: 0.3557
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3055
Epoch 10/10, Batch 20/20, Loss: 0.1576
Epoch 10/10, Train Loss: 0.2652, Valid Loss: 0.3499
Model saved!
Accuracy: 0.8785
Precision: 0.8719
Recall: 0.8785
F1-score: 0.8740
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2645
Epoch 1/10, Batch 20/20, Loss: 1.2340
Epoch 1/10, Train Loss: 1.2929, Valid Loss: 0.9138
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8179
Epoch 2/10, Batch 20/20, Loss: 0.7856
Epoch 2/10, Train Loss: 0.8298, Valid Loss: 0.6515
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5602
Epoch 3/10, Batch 20/20, Loss: 0.6866
Epoch 3/10, Train Loss: 0.6227, Valid Loss: 0.5232
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7105
Epoch 4/10, Batch 20/20, Loss: 0.6707
Epoch 4/10, Train Loss: 0.5152, Valid Loss: 0.4571
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4313
Epoch 5/10, Batch 20/20, Loss: 0.3064
Epoch 5/10, Train Loss: 0.4203, Valid Loss: 0.3963
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4901
Epoch 6/10, Batch 20/20, Loss: 0.3880
Epoch 6/10, Train Loss: 0.3815, Valid Loss: 0.3769
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4449
Epoch 7/10, Batch 20/20, Loss: 0.3783
Epoch 7/10, Train Loss: 0.3539, Valid Loss: 0.3579
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2727
Epoch 8/10, Batch 20/20, Loss: 0.3398
Epoch 8/10, Train Loss: 0.3170, Valid Loss: 0.3374
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5294
Epoch 9/10, Batch 20/20, Loss: 0.6185
Epoch 9/10, Train Loss: 0.3064, Valid Loss: 0.3316
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2692
Epoch 10/10, Batch 20/20, Loss: 0.3275
Epoch 10/10, Train Loss: 0.2692, Valid Loss: 0.3164
Model saved!
Accuracy: 0.8937
Precision: 0.8878
Recall: 0.8937
F1-score: 0.8890
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2570
Epoch 1/10, Batch 20/20, Loss: 1.1309
Epoch 1/10, Train Loss: 1.3013, Valid Loss: 0.9786
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8166
Epoch 2/10, Batch 20/20, Loss: 1.1518
Epoch 2/10, Train Loss: 0.8581, Valid Loss: 0.7202
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5113
Epoch 3/10, Batch 20/20, Loss: 0.6366
Epoch 3/10, Train Loss: 0.6317, Valid Loss: 0.5858
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.8007
Epoch 4/10, Batch 20/20, Loss: 0.5486
Epoch 4/10, Train Loss: 0.5313, Valid Loss: 0.5205
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3790
Epoch 5/10, Batch 20/20, Loss: 0.4997
Epoch 5/10, Train Loss: 0.4536, Valid Loss: 0.4631
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5373
Epoch 6/10, Batch 20/20, Loss: 0.5110
Epoch 6/10, Train Loss: 0.4250, Valid Loss: 0.4416
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3996
Epoch 7/10, Batch 20/20, Loss: 0.5296
Epoch 7/10, Train Loss: 0.3920, Valid Loss: 0.4066
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3472
Epoch 8/10, Batch 20/20, Loss: 0.4781
Epoch 8/10, Train Loss: 0.3461, Valid Loss: 0.3945
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4907
Epoch 9/10, Batch 20/20, Loss: 0.3459
Epoch 9/10, Train Loss: 0.3239, Valid Loss: 0.3664
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2290
Epoch 10/10, Batch 20/20, Loss: 0.3824
Epoch 10/10, Train Loss: 0.2796, Valid Loss: 0.3591
Model saved!
Accuracy: 0.8867
Precision: 0.8825
Recall: 0.8867
F1-score: 0.8837
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1146
Epoch 1/10, Batch 20/20, Loss: 1.1552
Epoch 1/10, Train Loss: 1.2714, Valid Loss: 0.9192
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7911
Epoch 2/10, Batch 20/20, Loss: 1.0437
Epoch 2/10, Train Loss: 0.8061, Valid Loss: 0.6358
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4412
Epoch 3/10, Batch 20/20, Loss: 0.5570
Epoch 3/10, Train Loss: 0.5710, Valid Loss: 0.5145
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6770
Epoch 4/10, Batch 20/20, Loss: 0.3917
Epoch 4/10, Train Loss: 0.4648, Valid Loss: 0.4455
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5185
Epoch 5/10, Batch 20/20, Loss: 0.3828
Epoch 5/10, Train Loss: 0.3901, Valid Loss: 0.4056
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4497
Epoch 6/10, Batch 20/20, Loss: 0.4685
Epoch 6/10, Train Loss: 0.3710, Valid Loss: 0.3735
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4385
Epoch 7/10, Batch 20/20, Loss: 0.7828
Epoch 7/10, Train Loss: 0.3426, Valid Loss: 0.3571
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2245
Epoch 8/10, Batch 20/20, Loss: 0.3082
Epoch 8/10, Train Loss: 0.2848, Valid Loss: 0.3301
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3623
Epoch 9/10, Batch 20/20, Loss: 0.4471
Epoch 9/10, Train Loss: 0.2730, Valid Loss: 0.3304
Epoch 10/10, Batch 10/20, Loss: 0.1999
Epoch 10/10, Batch 20/20, Loss: 0.1630
Epoch 10/10, Train Loss: 0.2289, Valid Loss: 0.3149
Model saved!
Accuracy: 0.8797
Precision: 0.8737
Recall: 0.8797
F1-score: 0.8735
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3009
Epoch 1/10, Batch 20/20, Loss: 1.3769
Epoch 1/10, Train Loss: 1.3402, Valid Loss: 1.0197
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9288
Epoch 2/10, Batch 20/20, Loss: 1.1988
Epoch 2/10, Train Loss: 0.9117, Valid Loss: 0.7542
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6798
Epoch 3/10, Batch 20/20, Loss: 1.0468
Epoch 3/10, Train Loss: 0.7058, Valid Loss: 0.6258
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7719
Epoch 4/10, Batch 20/20, Loss: 0.3769
Epoch 4/10, Train Loss: 0.5598, Valid Loss: 0.5522
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4838
Epoch 5/10, Batch 20/20, Loss: 0.4136
Epoch 5/10, Train Loss: 0.4999, Valid Loss: 0.5104
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5811
Epoch 6/10, Batch 20/20, Loss: 0.5292
Epoch 6/10, Train Loss: 0.4818, Valid Loss: 0.4634
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4888
Epoch 7/10, Batch 20/20, Loss: 0.6392
Epoch 7/10, Train Loss: 0.4118, Valid Loss: 0.4438
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4514
Epoch 8/10, Batch 20/20, Loss: 0.3459
Epoch 8/10, Train Loss: 0.3836, Valid Loss: 0.4301
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4302
Epoch 9/10, Batch 20/20, Loss: 0.7102
Epoch 9/10, Train Loss: 0.3850, Valid Loss: 0.4121
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2687
Epoch 10/10, Batch 20/20, Loss: 0.1608
Epoch 10/10, Train Loss: 0.3084, Valid Loss: 0.3968
Model saved!
Accuracy: 0.8937
Precision: 0.8917
Recall: 0.8937
F1-score: 0.8888
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2308
Epoch 1/10, Batch 20/20, Loss: 1.2502
Epoch 1/10, Train Loss: 1.3031, Valid Loss: 0.9636
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8333
Epoch 2/10, Batch 20/20, Loss: 0.8543
Epoch 2/10, Train Loss: 0.8576, Valid Loss: 0.6843
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5633
Epoch 3/10, Batch 20/20, Loss: 0.7696
Epoch 3/10, Train Loss: 0.6428, Valid Loss: 0.5526
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7564
Epoch 4/10, Batch 20/20, Loss: 0.4631
Epoch 4/10, Train Loss: 0.5378, Valid Loss: 0.4665
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4084
Epoch 5/10, Batch 20/20, Loss: 0.6715
Epoch 5/10, Train Loss: 0.4695, Valid Loss: 0.4232
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4986
Epoch 6/10, Batch 20/20, Loss: 0.6715
Epoch 6/10, Train Loss: 0.4443, Valid Loss: 0.3852
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4665
Epoch 7/10, Batch 20/20, Loss: 0.4001
Epoch 7/10, Train Loss: 0.3860, Valid Loss: 0.3649
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2672
Epoch 8/10, Batch 20/20, Loss: 0.2300
Epoch 8/10, Train Loss: 0.3421, Valid Loss: 0.3469
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3817
Epoch 9/10, Batch 20/20, Loss: 0.7676
Epoch 9/10, Train Loss: 0.3452, Valid Loss: 0.3418
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3121
Epoch 10/10, Batch 20/20, Loss: 0.2009
Epoch 10/10, Train Loss: 0.2898, Valid Loss: 0.3255
Model saved!
Accuracy: 0.8890
Precision: 0.8839
Recall: 0.8890
F1-score: 0.8847
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2566
Epoch 1/10, Batch 20/20, Loss: 1.1172
Epoch 1/10, Train Loss: 1.2992, Valid Loss: 0.9795
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8987
Epoch 2/10, Batch 20/20, Loss: 0.8867
Epoch 2/10, Train Loss: 0.8423, Valid Loss: 0.7081
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6672
Epoch 3/10, Batch 20/20, Loss: 0.8299
Epoch 3/10, Train Loss: 0.6497, Valid Loss: 0.5837
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6361
Epoch 4/10, Batch 20/20, Loss: 0.6742
Epoch 4/10, Train Loss: 0.5387, Valid Loss: 0.5137
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4674
Epoch 5/10, Batch 20/20, Loss: 0.4505
Epoch 5/10, Train Loss: 0.4573, Valid Loss: 0.4609
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5516
Epoch 6/10, Batch 20/20, Loss: 0.6805
Epoch 6/10, Train Loss: 0.4424, Valid Loss: 0.4229
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4889
Epoch 7/10, Batch 20/20, Loss: 0.4857
Epoch 7/10, Train Loss: 0.3849, Valid Loss: 0.3953
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2492
Epoch 8/10, Batch 20/20, Loss: 0.2782
Epoch 8/10, Train Loss: 0.3500, Valid Loss: 0.3649
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4099
Epoch 9/10, Batch 20/20, Loss: 0.4764
Epoch 9/10, Train Loss: 0.3330, Valid Loss: 0.3597
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2232
Epoch 10/10, Batch 20/20, Loss: 0.2802
Epoch 10/10, Train Loss: 0.2979, Valid Loss: 0.3358
Model saved!
Accuracy: 0.8867
Precision: 0.8823
Recall: 0.8867
F1-score: 0.8839
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2128
Epoch 1/10, Batch 20/20, Loss: 1.3554
Epoch 1/10, Train Loss: 1.3309, Valid Loss: 0.9917
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8483
Epoch 2/10, Batch 20/20, Loss: 1.0332
Epoch 2/10, Train Loss: 0.8759, Valid Loss: 0.7255
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5509
Epoch 3/10, Batch 20/20, Loss: 0.5005
Epoch 3/10, Train Loss: 0.6387, Valid Loss: 0.5875
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6749
Epoch 4/10, Batch 20/20, Loss: 0.5494
Epoch 4/10, Train Loss: 0.5335, Valid Loss: 0.5209
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3974
Epoch 5/10, Batch 20/20, Loss: 0.6930
Epoch 5/10, Train Loss: 0.4526, Valid Loss: 0.4633
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5398
Epoch 6/10, Batch 20/20, Loss: 0.8207
Epoch 6/10, Train Loss: 0.4443, Valid Loss: 0.4308
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4146
Epoch 7/10, Batch 20/20, Loss: 0.3179
Epoch 7/10, Train Loss: 0.3788, Valid Loss: 0.4088
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3315
Epoch 8/10, Batch 20/20, Loss: 0.2060
Epoch 8/10, Train Loss: 0.3287, Valid Loss: 0.3828
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5224
Epoch 9/10, Batch 20/20, Loss: 0.8791
Epoch 9/10, Train Loss: 0.3495, Valid Loss: 0.3691
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2192
Epoch 10/10, Batch 20/20, Loss: 0.2366
Epoch 10/10, Train Loss: 0.2827, Valid Loss: 0.3578
Model saved!
Accuracy: 0.8984
Precision: 0.8935
Recall: 0.8984
F1-score: 0.8945
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2438
Epoch 1/10, Batch 20/20, Loss: 1.2242
Epoch 1/10, Train Loss: 1.3060, Valid Loss: 0.9111
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7834
Epoch 2/10, Batch 20/20, Loss: 1.0614
Epoch 2/10, Train Loss: 0.8533, Valid Loss: 0.6250
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5869
Epoch 3/10, Batch 20/20, Loss: 0.6724
Epoch 3/10, Train Loss: 0.6273, Valid Loss: 0.4875
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7832
Epoch 4/10, Batch 20/20, Loss: 0.6041
Epoch 4/10, Train Loss: 0.5146, Valid Loss: 0.4116
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3437
Epoch 5/10, Batch 20/20, Loss: 0.3803
Epoch 5/10, Train Loss: 0.4341, Valid Loss: 0.3575
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5685
Epoch 6/10, Batch 20/20, Loss: 0.5767
Epoch 6/10, Train Loss: 0.4247, Valid Loss: 0.3248
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3666
Epoch 7/10, Batch 20/20, Loss: 0.5775
Epoch 7/10, Train Loss: 0.3777, Valid Loss: 0.3049
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2629
Epoch 8/10, Batch 20/20, Loss: 0.4611
Epoch 8/10, Train Loss: 0.3301, Valid Loss: 0.2833
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4799
Epoch 9/10, Batch 20/20, Loss: 0.5255
Epoch 9/10, Train Loss: 0.3154, Valid Loss: 0.2680
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3134
Epoch 10/10, Batch 20/20, Loss: 0.2645
Epoch 10/10, Train Loss: 0.2747, Valid Loss: 0.2577
Model saved!
Accuracy: 0.8855
Precision: 0.8793
Recall: 0.8855
F1-score: 0.8813
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2956
Epoch 1/10, Batch 20/20, Loss: 1.0510
Epoch 1/10, Train Loss: 1.2889, Valid Loss: 0.9381
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8913
Epoch 2/10, Batch 20/20, Loss: 0.9091
Epoch 2/10, Train Loss: 0.8744, Valid Loss: 0.6454
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5615
Epoch 3/10, Batch 20/20, Loss: 0.8789
Epoch 3/10, Train Loss: 0.6577, Valid Loss: 0.5157
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6079
Epoch 4/10, Batch 20/20, Loss: 0.4542
Epoch 4/10, Train Loss: 0.5432, Valid Loss: 0.4265
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4850
Epoch 5/10, Batch 20/20, Loss: 0.6309
Epoch 5/10, Train Loss: 0.4714, Valid Loss: 0.3986
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4503
Epoch 6/10, Batch 20/20, Loss: 0.5561
Epoch 6/10, Train Loss: 0.4276, Valid Loss: 0.3426
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4006
Epoch 7/10, Batch 20/20, Loss: 0.3021
Epoch 7/10, Train Loss: 0.3849, Valid Loss: 0.3341
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2828
Epoch 8/10, Batch 20/20, Loss: 0.3144
Epoch 8/10, Train Loss: 0.3540, Valid Loss: 0.3175
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3617
Epoch 9/10, Batch 20/20, Loss: 0.7220
Epoch 9/10, Train Loss: 0.3421, Valid Loss: 0.2986
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2161
Epoch 10/10, Batch 20/20, Loss: 0.4739
Epoch 10/10, Train Loss: 0.3036, Valid Loss: 0.2879
Model saved!
Accuracy: 0.8937
Precision: 0.8890
Recall: 0.8937
F1-score: 0.8906
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1852
Epoch 1/10, Batch 20/20, Loss: 1.2429
Epoch 1/10, Train Loss: 1.2859, Valid Loss: 0.9100
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7892
Epoch 2/10, Batch 20/20, Loss: 0.7819
Epoch 2/10, Train Loss: 0.8250, Valid Loss: 0.6657
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5623
Epoch 3/10, Batch 20/20, Loss: 0.8154
Epoch 3/10, Train Loss: 0.6234, Valid Loss: 0.5554
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7381
Epoch 4/10, Batch 20/20, Loss: 0.3572
Epoch 4/10, Train Loss: 0.5131, Valid Loss: 0.4750
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4367
Epoch 5/10, Batch 20/20, Loss: 0.3805
Epoch 5/10, Train Loss: 0.4305, Valid Loss: 0.4236
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4590
Epoch 6/10, Batch 20/20, Loss: 0.4512
Epoch 6/10, Train Loss: 0.4075, Valid Loss: 0.4056
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4653
Epoch 7/10, Batch 20/20, Loss: 0.6185
Epoch 7/10, Train Loss: 0.3734, Valid Loss: 0.3710
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3074
Epoch 8/10, Batch 20/20, Loss: 0.2146
Epoch 8/10, Train Loss: 0.3240, Valid Loss: 0.3529
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4933
Epoch 9/10, Batch 20/20, Loss: 0.4695
Epoch 9/10, Train Loss: 0.3064, Valid Loss: 0.3347
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2607
Epoch 10/10, Batch 20/20, Loss: 0.3016
Epoch 10/10, Train Loss: 0.2765, Valid Loss: 0.3263
Model saved!
Accuracy: 0.8855
Precision: 0.8799
Recall: 0.8855
F1-score: 0.8807
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2121
Epoch 1/10, Batch 20/20, Loss: 1.3458
Epoch 1/10, Train Loss: 1.2849, Valid Loss: 0.9398
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8020
Epoch 2/10, Batch 20/20, Loss: 0.8063
Epoch 2/10, Train Loss: 0.8291, Valid Loss: 0.6789
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5893
Epoch 3/10, Batch 20/20, Loss: 0.8559
Epoch 3/10, Train Loss: 0.6225, Valid Loss: 0.5494
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6233
Epoch 4/10, Batch 20/20, Loss: 0.3318
Epoch 4/10, Train Loss: 0.4957, Valid Loss: 0.4816
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.2632
Epoch 5/10, Batch 20/20, Loss: 0.3995
Epoch 5/10, Train Loss: 0.4120, Valid Loss: 0.4452
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5057
Epoch 6/10, Batch 20/20, Loss: 0.3876
Epoch 6/10, Train Loss: 0.3875, Valid Loss: 0.4105
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3485
Epoch 7/10, Batch 20/20, Loss: 0.5941
Epoch 7/10, Train Loss: 0.3554, Valid Loss: 0.3780
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2779
Epoch 8/10, Batch 20/20, Loss: 0.2967
Epoch 8/10, Train Loss: 0.3102, Valid Loss: 0.3612
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5673
Epoch 9/10, Batch 20/20, Loss: 0.4347
Epoch 9/10, Train Loss: 0.3034, Valid Loss: 0.3497
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2385
Epoch 10/10, Batch 20/20, Loss: 0.1965
Epoch 10/10, Train Loss: 0.2509, Valid Loss: 0.3401
Model saved!
Accuracy: 0.8960
Precision: 0.8924
Recall: 0.8960
F1-score: 0.8928
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1819
Epoch 1/10, Batch 20/20, Loss: 1.1792
Epoch 1/10, Train Loss: 1.2903, Valid Loss: 0.9306
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9074
Epoch 2/10, Batch 20/20, Loss: 0.9679
Epoch 2/10, Train Loss: 0.8547, Valid Loss: 0.6423
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5952
Epoch 3/10, Batch 20/20, Loss: 0.7526
Epoch 3/10, Train Loss: 0.6381, Valid Loss: 0.5109
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7637
Epoch 4/10, Batch 20/20, Loss: 0.5702
Epoch 4/10, Train Loss: 0.5418, Valid Loss: 0.4393
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3396
Epoch 5/10, Batch 20/20, Loss: 0.4456
Epoch 5/10, Train Loss: 0.4371, Valid Loss: 0.3885
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4777
Epoch 6/10, Batch 20/20, Loss: 0.5453
Epoch 6/10, Train Loss: 0.4201, Valid Loss: 0.3479
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4417
Epoch 7/10, Batch 20/20, Loss: 0.4313
Epoch 7/10, Train Loss: 0.3712, Valid Loss: 0.3276
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3321
Epoch 8/10, Batch 20/20, Loss: 0.3340
Epoch 8/10, Train Loss: 0.3394, Valid Loss: 0.3049
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4358
Epoch 9/10, Batch 20/20, Loss: 0.5271
Epoch 9/10, Train Loss: 0.3254, Valid Loss: 0.2882
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2301
Epoch 10/10, Batch 20/20, Loss: 0.2792
Epoch 10/10, Train Loss: 0.2826, Valid Loss: 0.2716
Model saved!
Accuracy: 0.8773
Precision: 0.8734
Recall: 0.8773
F1-score: 0.8736
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2414
Epoch 1/10, Batch 20/20, Loss: 1.1163
Epoch 1/10, Train Loss: 1.2968, Valid Loss: 0.9635
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9029
Epoch 2/10, Batch 20/20, Loss: 0.9630
Epoch 2/10, Train Loss: 0.8564, Valid Loss: 0.7024
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6562
Epoch 3/10, Batch 20/20, Loss: 0.7740
Epoch 3/10, Train Loss: 0.6363, Valid Loss: 0.5789
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7762
Epoch 4/10, Batch 20/20, Loss: 0.4186
Epoch 4/10, Train Loss: 0.5199, Valid Loss: 0.5166
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4693
Epoch 5/10, Batch 20/20, Loss: 0.6324
Epoch 5/10, Train Loss: 0.4381, Valid Loss: 0.4823
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5952
Epoch 6/10, Batch 20/20, Loss: 0.6868
Epoch 6/10, Train Loss: 0.4243, Valid Loss: 0.4404
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3212
Epoch 7/10, Batch 20/20, Loss: 0.5229
Epoch 7/10, Train Loss: 0.3631, Valid Loss: 0.4195
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3096
Epoch 8/10, Batch 20/20, Loss: 0.6117
Epoch 8/10, Train Loss: 0.3488, Valid Loss: 0.4083
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5234
Epoch 9/10, Batch 20/20, Loss: 0.5938
Epoch 9/10, Train Loss: 0.3299, Valid Loss: 0.4006
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1483
Epoch 10/10, Batch 20/20, Loss: 0.2636
Epoch 10/10, Train Loss: 0.2768, Valid Loss: 0.3821
Model saved!
Accuracy: 0.8843
Precision: 0.8802
Recall: 0.8843
F1-score: 0.8803
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2434
Epoch 1/10, Batch 20/20, Loss: 1.2455
Epoch 1/10, Train Loss: 1.3167, Valid Loss: 0.9265
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9360
Epoch 2/10, Batch 20/20, Loss: 0.9146
Epoch 2/10, Train Loss: 0.8833, Valid Loss: 0.6663
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6359
Epoch 3/10, Batch 20/20, Loss: 0.5914
Epoch 3/10, Train Loss: 0.6513, Valid Loss: 0.5360
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6206
Epoch 4/10, Batch 20/20, Loss: 0.5245
Epoch 4/10, Train Loss: 0.5509, Valid Loss: 0.4592
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5679
Epoch 5/10, Batch 20/20, Loss: 0.6449
Epoch 5/10, Train Loss: 0.4751, Valid Loss: 0.4186
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6165
Epoch 6/10, Batch 20/20, Loss: 0.4476
Epoch 6/10, Train Loss: 0.4432, Valid Loss: 0.3876
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4216
Epoch 7/10, Batch 20/20, Loss: 0.5674
Epoch 7/10, Train Loss: 0.4083, Valid Loss: 0.3600
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3820
Epoch 8/10, Batch 20/20, Loss: 0.3578
Epoch 8/10, Train Loss: 0.3588, Valid Loss: 0.3460
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5545
Epoch 9/10, Batch 20/20, Loss: 0.5312
Epoch 9/10, Train Loss: 0.3524, Valid Loss: 0.3232
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2371
Epoch 10/10, Batch 20/20, Loss: 0.3361
Epoch 10/10, Train Loss: 0.2998, Valid Loss: 0.3124
Model saved!
Accuracy: 0.8832
Precision: 0.8796
Recall: 0.8832
F1-score: 0.8772
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2223
Epoch 1/10, Batch 20/20, Loss: 1.3478
Epoch 1/10, Train Loss: 1.3026, Valid Loss: 0.9366
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8612
Epoch 2/10, Batch 20/20, Loss: 0.8493
Epoch 2/10, Train Loss: 0.8502, Valid Loss: 0.6780
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5647
Epoch 3/10, Batch 20/20, Loss: 0.6993
Epoch 3/10, Train Loss: 0.6408, Valid Loss: 0.5495
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7586
Epoch 4/10, Batch 20/20, Loss: 0.2823
Epoch 4/10, Train Loss: 0.5057, Valid Loss: 0.4747
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5012
Epoch 5/10, Batch 20/20, Loss: 0.4477
Epoch 5/10, Train Loss: 0.4498, Valid Loss: 0.4364
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6015
Epoch 6/10, Batch 20/20, Loss: 0.4529
Epoch 6/10, Train Loss: 0.4209, Valid Loss: 0.3998
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3447
Epoch 7/10, Batch 20/20, Loss: 0.3526
Epoch 7/10, Train Loss: 0.3755, Valid Loss: 0.3789
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2530
Epoch 8/10, Batch 20/20, Loss: 0.1941
Epoch 8/10, Train Loss: 0.3261, Valid Loss: 0.3538
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4657
Epoch 9/10, Batch 20/20, Loss: 0.4485
Epoch 9/10, Train Loss: 0.3258, Valid Loss: 0.3441
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2790
Epoch 10/10, Batch 20/20, Loss: 0.2643
Epoch 10/10, Train Loss: 0.2746, Valid Loss: 0.3322
Model saved!
Accuracy: 0.8960
Precision: 0.8915
Recall: 0.8960
F1-score: 0.8928
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3807
Epoch 1/10, Batch 20/20, Loss: 1.1406
Epoch 1/10, Train Loss: 1.3199, Valid Loss: 0.9398
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8557
Epoch 2/10, Batch 20/20, Loss: 0.8449
Epoch 2/10, Train Loss: 0.8686, Valid Loss: 0.6450
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5565
Epoch 3/10, Batch 20/20, Loss: 0.9545
Epoch 3/10, Train Loss: 0.6591, Valid Loss: 0.5047
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7323
Epoch 4/10, Batch 20/20, Loss: 0.4941
Epoch 4/10, Train Loss: 0.5437, Valid Loss: 0.4148
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3671
Epoch 5/10, Batch 20/20, Loss: 0.5434
Epoch 5/10, Train Loss: 0.4721, Valid Loss: 0.3654
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5558
Epoch 6/10, Batch 20/20, Loss: 0.5155
Epoch 6/10, Train Loss: 0.4451, Valid Loss: 0.3264
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4418
Epoch 7/10, Batch 20/20, Loss: 0.3601
Epoch 7/10, Train Loss: 0.3909, Valid Loss: 0.2975
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4232
Epoch 8/10, Batch 20/20, Loss: 0.2384
Epoch 8/10, Train Loss: 0.3587, Valid Loss: 0.2791
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4380
Epoch 9/10, Batch 20/20, Loss: 0.6056
Epoch 9/10, Train Loss: 0.3426, Valid Loss: 0.2621
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2800
Epoch 10/10, Batch 20/20, Loss: 0.2269
Epoch 10/10, Train Loss: 0.2966, Valid Loss: 0.2519
Model saved!
Accuracy: 0.8984
Precision: 0.8916
Recall: 0.8984
F1-score: 0.8931
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2181
Epoch 1/10, Batch 20/20, Loss: 1.1258
Epoch 1/10, Train Loss: 1.2934, Valid Loss: 0.9425
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8412
Epoch 2/10, Batch 20/20, Loss: 0.8546
Epoch 2/10, Train Loss: 0.8401, Valid Loss: 0.6766
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5342
Epoch 3/10, Batch 20/20, Loss: 0.8298
Epoch 3/10, Train Loss: 0.6238, Valid Loss: 0.5391
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6565
Epoch 4/10, Batch 20/20, Loss: 0.6083
Epoch 4/10, Train Loss: 0.5188, Valid Loss: 0.4705
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4223
Epoch 5/10, Batch 20/20, Loss: 0.4813
Epoch 5/10, Train Loss: 0.4293, Valid Loss: 0.4281
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5376
Epoch 6/10, Batch 20/20, Loss: 0.4607
Epoch 6/10, Train Loss: 0.4024, Valid Loss: 0.3886
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4318
Epoch 7/10, Batch 20/20, Loss: 0.4068
Epoch 7/10, Train Loss: 0.3481, Valid Loss: 0.3661
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3235
Epoch 8/10, Batch 20/20, Loss: 0.3482
Epoch 8/10, Train Loss: 0.3180, Valid Loss: 0.3597
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4106
Epoch 9/10, Batch 20/20, Loss: 0.8283
Epoch 9/10, Train Loss: 0.3281, Valid Loss: 0.3331
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2202
Epoch 10/10, Batch 20/20, Loss: 0.2322
Epoch 10/10, Train Loss: 0.2688, Valid Loss: 0.3394
Accuracy: 0.8890
Precision: 0.8854
Recall: 0.8890
F1-score: 0.8862
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2526
Epoch 1/10, Batch 20/20, Loss: 1.2187
Epoch 1/10, Train Loss: 1.3097, Valid Loss: 0.9286
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8652
Epoch 2/10, Batch 20/20, Loss: 0.8052
Epoch 2/10, Train Loss: 0.8467, Valid Loss: 0.6388
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7005
Epoch 3/10, Batch 20/20, Loss: 0.8103
Epoch 3/10, Train Loss: 0.6341, Valid Loss: 0.5054
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6686
Epoch 4/10, Batch 20/20, Loss: 0.5039
Epoch 4/10, Train Loss: 0.5224, Valid Loss: 0.4306
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4243
Epoch 5/10, Batch 20/20, Loss: 0.4240
Epoch 5/10, Train Loss: 0.4437, Valid Loss: 0.3809
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5399
Epoch 6/10, Batch 20/20, Loss: 0.6665
Epoch 6/10, Train Loss: 0.4252, Valid Loss: 0.3436
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3562
Epoch 7/10, Batch 20/20, Loss: 0.5755
Epoch 7/10, Train Loss: 0.3862, Valid Loss: 0.3219
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2998
Epoch 8/10, Batch 20/20, Loss: 0.2682
Epoch 8/10, Train Loss: 0.3286, Valid Loss: 0.2944
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5130
Epoch 9/10, Batch 20/20, Loss: 0.6371
Epoch 9/10, Train Loss: 0.3376, Valid Loss: 0.2913
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2276
Epoch 10/10, Batch 20/20, Loss: 0.3503
Epoch 10/10, Train Loss: 0.2694, Valid Loss: 0.2650
Model saved!
Accuracy: 0.8960
Precision: 0.8899
Recall: 0.8960
F1-score: 0.8910
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1908
Epoch 1/10, Batch 20/20, Loss: 1.2318
Epoch 1/10, Train Loss: 1.2938, Valid Loss: 0.9355
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8973
Epoch 2/10, Batch 20/20, Loss: 0.8228
Epoch 2/10, Train Loss: 0.8515, Valid Loss: 0.6552
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6083
Epoch 3/10, Batch 20/20, Loss: 0.8942
Epoch 3/10, Train Loss: 0.6264, Valid Loss: 0.5311
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6710
Epoch 4/10, Batch 20/20, Loss: 0.5286
Epoch 4/10, Train Loss: 0.5196, Valid Loss: 0.4547
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4194
Epoch 5/10, Batch 20/20, Loss: 0.3934
Epoch 5/10, Train Loss: 0.4205, Valid Loss: 0.4025
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5300
Epoch 6/10, Batch 20/20, Loss: 0.4448
Epoch 6/10, Train Loss: 0.4051, Valid Loss: 0.3700
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3605
Epoch 7/10, Batch 20/20, Loss: 0.5743
Epoch 7/10, Train Loss: 0.3659, Valid Loss: 0.3498
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2458
Epoch 8/10, Batch 20/20, Loss: 0.3620
Epoch 8/10, Train Loss: 0.3302, Valid Loss: 0.3337
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3628
Epoch 9/10, Batch 20/20, Loss: 0.5822
Epoch 9/10, Train Loss: 0.3144, Valid Loss: 0.3223
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2626
Epoch 10/10, Batch 20/20, Loss: 0.3214
Epoch 10/10, Train Loss: 0.2593, Valid Loss: 0.3094
Model saved!
Accuracy: 0.8843
Precision: 0.8792
Recall: 0.8843
F1-score: 0.8804
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1340
Epoch 1/10, Batch 20/20, Loss: 1.3339
Epoch 1/10, Train Loss: 1.3043, Valid Loss: 0.9307
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9271
Epoch 2/10, Batch 20/20, Loss: 0.8921
Epoch 2/10, Train Loss: 0.8370, Valid Loss: 0.6701
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5228
Epoch 3/10, Batch 20/20, Loss: 0.6911
Epoch 3/10, Train Loss: 0.6170, Valid Loss: 0.5469
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6531
Epoch 4/10, Batch 20/20, Loss: 0.2989
Epoch 4/10, Train Loss: 0.4978, Valid Loss: 0.4691
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3757
Epoch 5/10, Batch 20/20, Loss: 0.4390
Epoch 5/10, Train Loss: 0.4286, Valid Loss: 0.4257
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5354
Epoch 6/10, Batch 20/20, Loss: 0.5886
Epoch 6/10, Train Loss: 0.4067, Valid Loss: 0.3903
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3691
Epoch 7/10, Batch 20/20, Loss: 0.6000
Epoch 7/10, Train Loss: 0.3612, Valid Loss: 0.3683
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3355
Epoch 8/10, Batch 20/20, Loss: 0.3585
Epoch 8/10, Train Loss: 0.3268, Valid Loss: 0.3514
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4471
Epoch 9/10, Batch 20/20, Loss: 0.3968
Epoch 9/10, Train Loss: 0.3047, Valid Loss: 0.3408
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2384
Epoch 10/10, Batch 20/20, Loss: 0.4742
Epoch 10/10, Train Loss: 0.2699, Valid Loss: 0.3331
Model saved!
Accuracy: 0.8902
Precision: 0.8849
Recall: 0.8902
F1-score: 0.8863
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2321
Epoch 1/10, Batch 20/20, Loss: 1.1819
Epoch 1/10, Train Loss: 1.2860, Valid Loss: 0.9432
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9207
Epoch 2/10, Batch 20/20, Loss: 0.9041
Epoch 2/10, Train Loss: 0.8304, Valid Loss: 0.6750
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5897
Epoch 3/10, Batch 20/20, Loss: 0.4870
Epoch 3/10, Train Loss: 0.6077, Valid Loss: 0.5330
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6416
Epoch 4/10, Batch 20/20, Loss: 0.5122
Epoch 4/10, Train Loss: 0.5024, Valid Loss: 0.4633
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4285
Epoch 5/10, Batch 20/20, Loss: 0.5924
Epoch 5/10, Train Loss: 0.4366, Valid Loss: 0.4113
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4957
Epoch 6/10, Batch 20/20, Loss: 0.4506
Epoch 6/10, Train Loss: 0.4042, Valid Loss: 0.3676
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3370
Epoch 7/10, Batch 20/20, Loss: 0.4084
Epoch 7/10, Train Loss: 0.3660, Valid Loss: 0.3431
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2597
Epoch 8/10, Batch 20/20, Loss: 0.2640
Epoch 8/10, Train Loss: 0.3286, Valid Loss: 0.3236
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4132
Epoch 9/10, Batch 20/20, Loss: 0.7104
Epoch 9/10, Train Loss: 0.3243, Valid Loss: 0.3010
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2175
Epoch 10/10, Batch 20/20, Loss: 0.3577
Epoch 10/10, Train Loss: 0.2680, Valid Loss: 0.2976
Model saved!
Accuracy: 0.8879
Precision: 0.8850
Recall: 0.8879
F1-score: 0.8845
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2830
Epoch 1/10, Batch 20/20, Loss: 1.1731
Epoch 1/10, Train Loss: 1.3036, Valid Loss: 0.9923
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9863
Epoch 2/10, Batch 20/20, Loss: 0.9750
Epoch 2/10, Train Loss: 0.8665, Valid Loss: 0.7220
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6322
Epoch 3/10, Batch 20/20, Loss: 0.7465
Epoch 3/10, Train Loss: 0.6558, Valid Loss: 0.6086
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.8096
Epoch 4/10, Batch 20/20, Loss: 0.5053
Epoch 4/10, Train Loss: 0.5557, Valid Loss: 0.5306
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5553
Epoch 5/10, Batch 20/20, Loss: 0.3971
Epoch 5/10, Train Loss: 0.4630, Valid Loss: 0.4924
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5919
Epoch 6/10, Batch 20/20, Loss: 0.5557
Epoch 6/10, Train Loss: 0.4592, Valid Loss: 0.4578
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4574
Epoch 7/10, Batch 20/20, Loss: 0.4489
Epoch 7/10, Train Loss: 0.3943, Valid Loss: 0.4297
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3777
Epoch 8/10, Batch 20/20, Loss: 0.2856
Epoch 8/10, Train Loss: 0.3645, Valid Loss: 0.4168
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4746
Epoch 9/10, Batch 20/20, Loss: 0.5223
Epoch 9/10, Train Loss: 0.3550, Valid Loss: 0.3947
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2950
Epoch 10/10, Batch 20/20, Loss: 0.2323
Epoch 10/10, Train Loss: 0.3080, Valid Loss: 0.3881
Model saved!
Accuracy: 0.8727
Precision: 0.8725
Recall: 0.8727
F1-score: 0.8711
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2112
Epoch 1/10, Batch 20/20, Loss: 1.0931
Epoch 1/10, Train Loss: 1.2900, Valid Loss: 0.9530
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8163
Epoch 2/10, Batch 20/20, Loss: 0.7455
Epoch 2/10, Train Loss: 0.8395, Valid Loss: 0.6784
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4857
Epoch 3/10, Batch 20/20, Loss: 0.8369
Epoch 3/10, Train Loss: 0.6315, Valid Loss: 0.5541
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6305
Epoch 4/10, Batch 20/20, Loss: 0.4545
Epoch 4/10, Train Loss: 0.5128, Valid Loss: 0.4818
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5001
Epoch 5/10, Batch 20/20, Loss: 0.2957
Epoch 5/10, Train Loss: 0.4358, Valid Loss: 0.4371
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5485
Epoch 6/10, Batch 20/20, Loss: 0.6143
Epoch 6/10, Train Loss: 0.4105, Valid Loss: 0.3937
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4915
Epoch 7/10, Batch 20/20, Loss: 0.5904
Epoch 7/10, Train Loss: 0.3752, Valid Loss: 0.3636
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3606
Epoch 8/10, Batch 20/20, Loss: 0.3787
Epoch 8/10, Train Loss: 0.3336, Valid Loss: 0.3464
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4990
Epoch 9/10, Batch 20/20, Loss: 0.5092
Epoch 9/10, Train Loss: 0.3168, Valid Loss: 0.3320
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1738
Epoch 10/10, Batch 20/20, Loss: 0.2760
Epoch 10/10, Train Loss: 0.2670, Valid Loss: 0.3151
Model saved!
Accuracy: 0.8890
Precision: 0.8834
Recall: 0.8890
F1-score: 0.8840
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2094
Epoch 1/10, Batch 20/20, Loss: 1.1921
Epoch 1/10, Train Loss: 1.3091, Valid Loss: 0.9605
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8798
Epoch 2/10, Batch 20/20, Loss: 1.0611
Epoch 2/10, Train Loss: 0.8651, Valid Loss: 0.7182
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6523
Epoch 3/10, Batch 20/20, Loss: 0.6036
Epoch 3/10, Train Loss: 0.6276, Valid Loss: 0.5856
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6324
Epoch 4/10, Batch 20/20, Loss: 0.5319
Epoch 4/10, Train Loss: 0.5378, Valid Loss: 0.4995
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4554
Epoch 5/10, Batch 20/20, Loss: 0.3888
Epoch 5/10, Train Loss: 0.4430, Valid Loss: 0.4461
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5410
Epoch 6/10, Batch 20/20, Loss: 0.7319
Epoch 6/10, Train Loss: 0.4287, Valid Loss: 0.4089
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4261
Epoch 7/10, Batch 20/20, Loss: 0.3930
Epoch 7/10, Train Loss: 0.3725, Valid Loss: 0.3976
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2626
Epoch 8/10, Batch 20/20, Loss: 0.2977
Epoch 8/10, Train Loss: 0.3412, Valid Loss: 0.3724
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3879
Epoch 9/10, Batch 20/20, Loss: 0.4651
Epoch 9/10, Train Loss: 0.3259, Valid Loss: 0.3680
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2835
Epoch 10/10, Batch 20/20, Loss: 0.3372
Epoch 10/10, Train Loss: 0.2646, Valid Loss: 0.3470
Model saved!
Accuracy: 0.8902
Precision: 0.8853
Recall: 0.8902
F1-score: 0.8834
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3006
Epoch 1/10, Batch 20/20, Loss: 1.2030
Epoch 1/10, Train Loss: 1.3268, Valid Loss: 0.9916
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9770
Epoch 2/10, Batch 20/20, Loss: 0.9026
Epoch 2/10, Train Loss: 0.8729, Valid Loss: 0.7155
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6696
Epoch 3/10, Batch 20/20, Loss: 0.7791
Epoch 3/10, Train Loss: 0.6478, Valid Loss: 0.5852
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6994
Epoch 4/10, Batch 20/20, Loss: 0.5742
Epoch 4/10, Train Loss: 0.5440, Valid Loss: 0.5201
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5014
Epoch 5/10, Batch 20/20, Loss: 0.8030
Epoch 5/10, Train Loss: 0.4692, Valid Loss: 0.4818
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5286
Epoch 6/10, Batch 20/20, Loss: 0.7700
Epoch 6/10, Train Loss: 0.4365, Valid Loss: 0.4428
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4069
Epoch 7/10, Batch 20/20, Loss: 0.5777
Epoch 7/10, Train Loss: 0.3995, Valid Loss: 0.4238
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2814
Epoch 8/10, Batch 20/20, Loss: 0.1496
Epoch 8/10, Train Loss: 0.3413, Valid Loss: 0.3971
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4747
Epoch 9/10, Batch 20/20, Loss: 0.7954
Epoch 9/10, Train Loss: 0.3542, Valid Loss: 0.3971
Epoch 10/10, Batch 10/20, Loss: 0.2768
Epoch 10/10, Batch 20/20, Loss: 0.1327
Epoch 10/10, Train Loss: 0.2832, Valid Loss: 0.3885
Model saved!
Accuracy: 0.8879
Precision: 0.8857
Recall: 0.8879
F1-score: 0.8846
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.3317
Epoch 1/10, Batch 20/20, Loss: 1.0572
Epoch 1/10, Train Loss: 1.3281, Valid Loss: 0.9386
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9824
Epoch 2/10, Batch 20/20, Loss: 1.1083
Epoch 2/10, Train Loss: 0.8984, Valid Loss: 0.6764
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5420
Epoch 3/10, Batch 20/20, Loss: 0.6013
Epoch 3/10, Train Loss: 0.6657, Valid Loss: 0.5488
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6405
Epoch 4/10, Batch 20/20, Loss: 0.4515
Epoch 4/10, Train Loss: 0.5567, Valid Loss: 0.4947
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5232
Epoch 5/10, Batch 20/20, Loss: 0.5860
Epoch 5/10, Train Loss: 0.4753, Valid Loss: 0.4395
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4159
Epoch 6/10, Batch 20/20, Loss: 0.7252
Epoch 6/10, Train Loss: 0.4712, Valid Loss: 0.4104
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4227
Epoch 7/10, Batch 20/20, Loss: 0.4566
Epoch 7/10, Train Loss: 0.4055, Valid Loss: 0.3899
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4008
Epoch 8/10, Batch 20/20, Loss: 0.2862
Epoch 8/10, Train Loss: 0.3600, Valid Loss: 0.3656
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4982
Epoch 9/10, Batch 20/20, Loss: 0.7189
Epoch 9/10, Train Loss: 0.3568, Valid Loss: 0.3598
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2614
Epoch 10/10, Batch 20/20, Loss: 0.2608
Epoch 10/10, Train Loss: 0.2984, Valid Loss: 0.3478
Model saved!
Accuracy: 0.8855
Precision: 0.8819
Recall: 0.8855
F1-score: 0.8833
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2529
Epoch 1/10, Batch 20/20, Loss: 1.2093
Epoch 1/10, Train Loss: 1.3125, Valid Loss: 0.9465
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8753
Epoch 2/10, Batch 20/20, Loss: 0.9161
Epoch 2/10, Train Loss: 0.8640, Valid Loss: 0.6862
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6108
Epoch 3/10, Batch 20/20, Loss: 0.6780
Epoch 3/10, Train Loss: 0.6426, Valid Loss: 0.5563
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6998
Epoch 4/10, Batch 20/20, Loss: 0.4385
Epoch 4/10, Train Loss: 0.5330, Valid Loss: 0.4854
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4443
Epoch 5/10, Batch 20/20, Loss: 0.3760
Epoch 5/10, Train Loss: 0.4475, Valid Loss: 0.4346
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5762
Epoch 6/10, Batch 20/20, Loss: 0.5217
Epoch 6/10, Train Loss: 0.4339, Valid Loss: 0.3957
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3624
Epoch 7/10, Batch 20/20, Loss: 0.4631
Epoch 7/10, Train Loss: 0.3954, Valid Loss: 0.3643
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3035
Epoch 8/10, Batch 20/20, Loss: 0.4877
Epoch 8/10, Train Loss: 0.3506, Valid Loss: 0.3515
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3842
Epoch 9/10, Batch 20/20, Loss: 0.7463
Epoch 9/10, Train Loss: 0.3515, Valid Loss: 0.3352
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2995
Epoch 10/10, Batch 20/20, Loss: 0.2206
Epoch 10/10, Train Loss: 0.2909, Valid Loss: 0.3340
Model saved!
Accuracy: 0.8808
Precision: 0.8765
Recall: 0.8808
F1-score: 0.8756
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1507
Epoch 1/10, Batch 20/20, Loss: 1.2247
Epoch 1/10, Train Loss: 1.2850, Valid Loss: 0.9284
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9192
Epoch 2/10, Batch 20/20, Loss: 0.8802
Epoch 2/10, Train Loss: 0.8264, Valid Loss: 0.6780
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4860
Epoch 3/10, Batch 20/20, Loss: 0.8665
Epoch 3/10, Train Loss: 0.6149, Valid Loss: 0.5445
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.8330
Epoch 4/10, Batch 20/20, Loss: 0.4616
Epoch 4/10, Train Loss: 0.5040, Valid Loss: 0.4784
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3916
Epoch 5/10, Batch 20/20, Loss: 0.3515
Epoch 5/10, Train Loss: 0.4146, Valid Loss: 0.4261
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4321
Epoch 6/10, Batch 20/20, Loss: 0.3106
Epoch 6/10, Train Loss: 0.3895, Valid Loss: 0.3992
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3772
Epoch 7/10, Batch 20/20, Loss: 0.4865
Epoch 7/10, Train Loss: 0.3704, Valid Loss: 0.3630
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3849
Epoch 8/10, Batch 20/20, Loss: 0.2229
Epoch 8/10, Train Loss: 0.3131, Valid Loss: 0.3541
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4384
Epoch 9/10, Batch 20/20, Loss: 0.6101
Epoch 9/10, Train Loss: 0.3147, Valid Loss: 0.3245
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3252
Epoch 10/10, Batch 20/20, Loss: 0.2335
Epoch 10/10, Train Loss: 0.2580, Valid Loss: 0.3296
Accuracy: 0.8843
Precision: 0.8808
Recall: 0.8843
F1-score: 0.8822
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2004
Epoch 1/10, Batch 20/20, Loss: 1.3236
Epoch 1/10, Train Loss: 1.3041, Valid Loss: 0.9618
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8452
Epoch 2/10, Batch 20/20, Loss: 1.0164
Epoch 2/10, Train Loss: 0.8535, Valid Loss: 0.6959
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5751
Epoch 3/10, Batch 20/20, Loss: 0.6744
Epoch 3/10, Train Loss: 0.6314, Valid Loss: 0.5631
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6582
Epoch 4/10, Batch 20/20, Loss: 0.6375
Epoch 4/10, Train Loss: 0.5292, Valid Loss: 0.4894
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4801
Epoch 5/10, Batch 20/20, Loss: 0.4217
Epoch 5/10, Train Loss: 0.4443, Valid Loss: 0.4411
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5178
Epoch 6/10, Batch 20/20, Loss: 0.6896
Epoch 6/10, Train Loss: 0.4225, Valid Loss: 0.4172
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4925
Epoch 7/10, Batch 20/20, Loss: 0.3290
Epoch 7/10, Train Loss: 0.3782, Valid Loss: 0.3905
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2710
Epoch 8/10, Batch 20/20, Loss: 0.3709
Epoch 8/10, Train Loss: 0.3279, Valid Loss: 0.3791
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4705
Epoch 9/10, Batch 20/20, Loss: 0.6836
Epoch 9/10, Train Loss: 0.3294, Valid Loss: 0.3521
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2817
Epoch 10/10, Batch 20/20, Loss: 0.3084
Epoch 10/10, Train Loss: 0.2776, Valid Loss: 0.3574
Accuracy: 0.8855
Precision: 0.8781
Recall: 0.8855
F1-score: 0.8792
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2200
Epoch 1/10, Batch 20/20, Loss: 1.0892
Epoch 1/10, Train Loss: 1.2779, Valid Loss: 0.9338
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8485
Epoch 2/10, Batch 20/20, Loss: 1.0213
Epoch 2/10, Train Loss: 0.8437, Valid Loss: 0.6583
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5735
Epoch 3/10, Batch 20/20, Loss: 0.8190
Epoch 3/10, Train Loss: 0.6280, Valid Loss: 0.5279
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6393
Epoch 4/10, Batch 20/20, Loss: 0.3187
Epoch 4/10, Train Loss: 0.5064, Valid Loss: 0.4661
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4013
Epoch 5/10, Batch 20/20, Loss: 0.5835
Epoch 5/10, Train Loss: 0.4479, Valid Loss: 0.4124
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.6126
Epoch 6/10, Batch 20/20, Loss: 0.5014
Epoch 6/10, Train Loss: 0.4288, Valid Loss: 0.3774
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4455
Epoch 7/10, Batch 20/20, Loss: 0.4040
Epoch 7/10, Train Loss: 0.3591, Valid Loss: 0.3542
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2284
Epoch 8/10, Batch 20/20, Loss: 0.2295
Epoch 8/10, Train Loss: 0.3339, Valid Loss: 0.3350
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5658
Epoch 9/10, Batch 20/20, Loss: 0.5679
Epoch 9/10, Train Loss: 0.3317, Valid Loss: 0.3263
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2436
Epoch 10/10, Batch 20/20, Loss: 0.2895
Epoch 10/10, Train Loss: 0.2784, Valid Loss: 0.3047
Model saved!
Accuracy: 0.8879
Precision: 0.8840
Recall: 0.8879
F1-score: 0.8844
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2389
Epoch 1/10, Batch 20/20, Loss: 1.1992
Epoch 1/10, Train Loss: 1.3225, Valid Loss: 0.9315
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8221
Epoch 2/10, Batch 20/20, Loss: 0.9542
Epoch 2/10, Train Loss: 0.8727, Valid Loss: 0.6851
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5547
Epoch 3/10, Batch 20/20, Loss: 0.6662
Epoch 3/10, Train Loss: 0.6448, Valid Loss: 0.5564
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7049
Epoch 4/10, Batch 20/20, Loss: 0.5263
Epoch 4/10, Train Loss: 0.5334, Valid Loss: 0.4866
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5206
Epoch 5/10, Batch 20/20, Loss: 0.3544
Epoch 5/10, Train Loss: 0.4534, Valid Loss: 0.4316
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.7517
Epoch 6/10, Batch 20/20, Loss: 0.5923
Epoch 6/10, Train Loss: 0.4381, Valid Loss: 0.4047
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3845
Epoch 7/10, Batch 20/20, Loss: 0.3358
Epoch 7/10, Train Loss: 0.3880, Valid Loss: 0.3825
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4141
Epoch 8/10, Batch 20/20, Loss: 0.3980
Epoch 8/10, Train Loss: 0.3486, Valid Loss: 0.3673
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4327
Epoch 9/10, Batch 20/20, Loss: 0.4756
Epoch 9/10, Train Loss: 0.3362, Valid Loss: 0.3423
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2510
Epoch 10/10, Batch 20/20, Loss: 0.4114
Epoch 10/10, Train Loss: 0.3040, Valid Loss: 0.3403
Model saved!
Accuracy: 0.8949
Precision: 0.8912
Recall: 0.8949
F1-score: 0.8897
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2485
Epoch 1/10, Batch 20/20, Loss: 1.1311
Epoch 1/10, Train Loss: 1.3100, Valid Loss: 0.9547
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9092
Epoch 2/10, Batch 20/20, Loss: 0.9833
Epoch 2/10, Train Loss: 0.8698, Valid Loss: 0.6654
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5457
Epoch 3/10, Batch 20/20, Loss: 0.6947
Epoch 3/10, Train Loss: 0.6517, Valid Loss: 0.5292
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7620
Epoch 4/10, Batch 20/20, Loss: 0.4358
Epoch 4/10, Train Loss: 0.5397, Valid Loss: 0.4594
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3911
Epoch 5/10, Batch 20/20, Loss: 0.6975
Epoch 5/10, Train Loss: 0.4773, Valid Loss: 0.4126
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.8071
Epoch 6/10, Batch 20/20, Loss: 0.6073
Epoch 6/10, Train Loss: 0.4420, Valid Loss: 0.3813
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.5176
Epoch 7/10, Batch 20/20, Loss: 0.5898
Epoch 7/10, Train Loss: 0.3904, Valid Loss: 0.3675
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4000
Epoch 8/10, Batch 20/20, Loss: 0.2166
Epoch 8/10, Train Loss: 0.3560, Valid Loss: 0.3439
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5393
Epoch 9/10, Batch 20/20, Loss: 0.4989
Epoch 9/10, Train Loss: 0.3390, Valid Loss: 0.3381
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2841
Epoch 10/10, Batch 20/20, Loss: 0.3343
Epoch 10/10, Train Loss: 0.2977, Valid Loss: 0.3281
Model saved!
Accuracy: 0.8843
Precision: 0.8794
Recall: 0.8843
F1-score: 0.8799
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2265
Epoch 1/10, Batch 20/20, Loss: 1.3088
Epoch 1/10, Train Loss: 1.3192, Valid Loss: 0.9471
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8392
Epoch 2/10, Batch 20/20, Loss: 0.9708
Epoch 2/10, Train Loss: 0.8745, Valid Loss: 0.6646
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5896
Epoch 3/10, Batch 20/20, Loss: 0.5867
Epoch 3/10, Train Loss: 0.6536, Valid Loss: 0.5285
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6986
Epoch 4/10, Batch 20/20, Loss: 0.4066
Epoch 4/10, Train Loss: 0.5384, Valid Loss: 0.4557
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4843
Epoch 5/10, Batch 20/20, Loss: 0.6156
Epoch 5/10, Train Loss: 0.4594, Valid Loss: 0.4045
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5575
Epoch 6/10, Batch 20/20, Loss: 0.7602
Epoch 6/10, Train Loss: 0.4468, Valid Loss: 0.3643
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4765
Epoch 7/10, Batch 20/20, Loss: 0.2678
Epoch 7/10, Train Loss: 0.3896, Valid Loss: 0.3487
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2201
Epoch 8/10, Batch 20/20, Loss: 0.3154
Epoch 8/10, Train Loss: 0.3525, Valid Loss: 0.3211
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5135
Epoch 9/10, Batch 20/20, Loss: 0.7908
Epoch 9/10, Train Loss: 0.3577, Valid Loss: 0.3125
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3092
Epoch 10/10, Batch 20/20, Loss: 0.2299
Epoch 10/10, Train Loss: 0.2937, Valid Loss: 0.3064
Model saved!
Accuracy: 0.8972
Precision: 0.8937
Recall: 0.8972
F1-score: 0.8948
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2687
Epoch 1/10, Batch 20/20, Loss: 1.4006
Epoch 1/10, Train Loss: 1.3038, Valid Loss: 0.9764
Model saved!
Epoch 2/10, Batch 10/20, Loss: 1.0178
Epoch 2/10, Batch 20/20, Loss: 1.0695
Epoch 2/10, Train Loss: 0.8586, Valid Loss: 0.6922
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6241
Epoch 3/10, Batch 20/20, Loss: 0.9446
Epoch 3/10, Train Loss: 0.6482, Valid Loss: 0.5639
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7695
Epoch 4/10, Batch 20/20, Loss: 0.5757
Epoch 4/10, Train Loss: 0.5321, Valid Loss: 0.4852
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4336
Epoch 5/10, Batch 20/20, Loss: 0.4988
Epoch 5/10, Train Loss: 0.4447, Valid Loss: 0.4539
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5103
Epoch 6/10, Batch 20/20, Loss: 0.5795
Epoch 6/10, Train Loss: 0.4229, Valid Loss: 0.4085
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3199
Epoch 7/10, Batch 20/20, Loss: 0.6877
Epoch 7/10, Train Loss: 0.3651, Valid Loss: 0.3990
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2076
Epoch 8/10, Batch 20/20, Loss: 0.2556
Epoch 8/10, Train Loss: 0.3390, Valid Loss: 0.3748
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3930
Epoch 9/10, Batch 20/20, Loss: 0.4521
Epoch 9/10, Train Loss: 0.3277, Valid Loss: 0.3640
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2159
Epoch 10/10, Batch 20/20, Loss: 0.3873
Epoch 10/10, Train Loss: 0.2964, Valid Loss: 0.3432
Model saved!
Accuracy: 0.8972
Precision: 0.8931
Recall: 0.8972
F1-score: 0.8938
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2387
Epoch 1/10, Batch 20/20, Loss: 1.2329
Epoch 1/10, Train Loss: 1.3085, Valid Loss: 0.9680
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7936
Epoch 2/10, Batch 20/20, Loss: 0.8384
Epoch 2/10, Train Loss: 0.8451, Valid Loss: 0.6959
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.7047
Epoch 3/10, Batch 20/20, Loss: 0.8113
Epoch 3/10, Train Loss: 0.6307, Valid Loss: 0.5791
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5684
Epoch 4/10, Batch 20/20, Loss: 0.4187
Epoch 4/10, Train Loss: 0.5264, Valid Loss: 0.5095
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.3444
Epoch 5/10, Batch 20/20, Loss: 0.4450
Epoch 5/10, Train Loss: 0.4247, Valid Loss: 0.4685
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5659
Epoch 6/10, Batch 20/20, Loss: 0.7143
Epoch 6/10, Train Loss: 0.4183, Valid Loss: 0.4273
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3610
Epoch 7/10, Batch 20/20, Loss: 0.2100
Epoch 7/10, Train Loss: 0.3502, Valid Loss: 0.4202
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3028
Epoch 8/10, Batch 20/20, Loss: 0.1719
Epoch 8/10, Train Loss: 0.3160, Valid Loss: 0.3972
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3795
Epoch 9/10, Batch 20/20, Loss: 0.5630
Epoch 9/10, Train Loss: 0.3190, Valid Loss: 0.3909
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.1840
Epoch 10/10, Batch 20/20, Loss: 0.2084
Epoch 10/10, Train Loss: 0.2680, Valid Loss: 0.3749
Model saved!
Accuracy: 0.8843
Precision: 0.8813
Recall: 0.8843
F1-score: 0.8781
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.1887
Epoch 1/10, Batch 20/20, Loss: 1.2324
Epoch 1/10, Train Loss: 1.3106, Valid Loss: 0.9394
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8284
Epoch 2/10, Batch 20/20, Loss: 0.8005
Epoch 2/10, Train Loss: 0.8565, Valid Loss: 0.6618
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5320
Epoch 3/10, Batch 20/20, Loss: 0.9133
Epoch 3/10, Train Loss: 0.6470, Valid Loss: 0.5263
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6712
Epoch 4/10, Batch 20/20, Loss: 0.4416
Epoch 4/10, Train Loss: 0.5247, Valid Loss: 0.4542
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5574
Epoch 5/10, Batch 20/20, Loss: 0.4898
Epoch 5/10, Train Loss: 0.4477, Valid Loss: 0.4076
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5343
Epoch 6/10, Batch 20/20, Loss: 0.6816
Epoch 6/10, Train Loss: 0.4299, Valid Loss: 0.3693
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4161
Epoch 7/10, Batch 20/20, Loss: 0.3780
Epoch 7/10, Train Loss: 0.3705, Valid Loss: 0.3387
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.3137
Epoch 8/10, Batch 20/20, Loss: 0.2579
Epoch 8/10, Train Loss: 0.3269, Valid Loss: 0.3230
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.5784
Epoch 9/10, Batch 20/20, Loss: 0.7917
Epoch 9/10, Train Loss: 0.3325, Valid Loss: 0.3001
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.2669
Epoch 10/10, Batch 20/20, Loss: 0.4870
Epoch 10/10, Train Loss: 0.2787, Valid Loss: 0.2983
Model saved!
Accuracy: 0.8867
Precision: 0.8815
Recall: 0.8867
F1-score: 0.8822
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2868
Epoch 1/10, Batch 20/20, Loss: 1.0654
Epoch 1/10, Train Loss: 1.2895, Valid Loss: 0.9559
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8129
Epoch 2/10, Batch 20/20, Loss: 0.8831
Epoch 2/10, Train Loss: 0.8557, Valid Loss: 0.6635
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4917
Epoch 3/10, Batch 20/20, Loss: 1.0430
Epoch 3/10, Train Loss: 0.6356, Valid Loss: 0.5318
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5945
Epoch 4/10, Batch 20/20, Loss: 0.3372
Epoch 4/10, Train Loss: 0.5163, Valid Loss: 0.4675
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4717
Epoch 5/10, Batch 20/20, Loss: 0.5221
Epoch 5/10, Train Loss: 0.4487, Valid Loss: 0.4208
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5381
Epoch 6/10, Batch 20/20, Loss: 0.8111
Epoch 6/10, Train Loss: 0.4368, Valid Loss: 0.3725
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4661
Epoch 7/10, Batch 20/20, Loss: 0.4420
Epoch 7/10, Train Loss: 0.3732, Valid Loss: 0.3582
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4308
Epoch 8/10, Batch 20/20, Loss: 0.4004
Epoch 8/10, Train Loss: 0.3340, Valid Loss: 0.3404
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3614
Epoch 9/10, Batch 20/20, Loss: 1.0122
Epoch 9/10, Train Loss: 0.3490, Valid Loss: 0.3300
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3651
Epoch 10/10, Batch 20/20, Loss: 0.2117
Epoch 10/10, Train Loss: 0.2739, Valid Loss: 0.3136
Model saved!
Accuracy: 0.9030
Precision: 0.9004
Recall: 0.9030
F1-score: 0.9010
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 98. Fitness: 0.9030
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2951
Epoch 1/10, Batch 20/20, Loss: 1.3037
Epoch 1/10, Train Loss: 1.3078, Valid Loss: 0.9788
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.9585
Epoch 2/10, Batch 20/20, Loss: 1.0868
Epoch 2/10, Train Loss: 0.8550, Valid Loss: 0.7051
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.6114
Epoch 3/10, Batch 20/20, Loss: 0.8286
Epoch 3/10, Train Loss: 0.6399, Valid Loss: 0.5729
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.6840
Epoch 4/10, Batch 20/20, Loss: 0.3853
Epoch 4/10, Train Loss: 0.5253, Valid Loss: 0.5062
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.6178
Epoch 5/10, Batch 20/20, Loss: 0.4871
Epoch 5/10, Train Loss: 0.4503, Valid Loss: 0.4685
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.4565
Epoch 6/10, Batch 20/20, Loss: 0.4589
Epoch 6/10, Train Loss: 0.4131, Valid Loss: 0.4291
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3571
Epoch 7/10, Batch 20/20, Loss: 0.4503
Epoch 7/10, Train Loss: 0.3714, Valid Loss: 0.4062
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4411
Epoch 8/10, Batch 20/20, Loss: 0.1850
Epoch 8/10, Train Loss: 0.3342, Valid Loss: 0.3850
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.4264
Epoch 9/10, Batch 20/20, Loss: 0.6657
Epoch 9/10, Train Loss: 0.3365, Valid Loss: 0.3633
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3170
Epoch 10/10, Batch 20/20, Loss: 0.3137
Epoch 10/10, Train Loss: 0.2954, Valid Loss: 0.3598
Model saved!
Accuracy: 0.8867
Precision: 0.8824
Recall: 0.8867
F1-score: 0.8812
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2243
Epoch 1/10, Batch 20/20, Loss: 1.2497
Epoch 1/10, Train Loss: 1.3021, Valid Loss: 0.9083
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.7408
Epoch 2/10, Batch 20/20, Loss: 0.9880
Epoch 2/10, Train Loss: 0.8449, Valid Loss: 0.6373
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.5870
Epoch 3/10, Batch 20/20, Loss: 0.7967
Epoch 3/10, Train Loss: 0.6435, Valid Loss: 0.5122
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.7791
Epoch 4/10, Batch 20/20, Loss: 0.4240
Epoch 4/10, Train Loss: 0.5309, Valid Loss: 0.4447
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.5436
Epoch 5/10, Batch 20/20, Loss: 0.7043
Epoch 5/10, Train Loss: 0.4530, Valid Loss: 0.3991
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5192
Epoch 6/10, Batch 20/20, Loss: 0.7137
Epoch 6/10, Train Loss: 0.4279, Valid Loss: 0.3501
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.3084
Epoch 7/10, Batch 20/20, Loss: 0.3385
Epoch 7/10, Train Loss: 0.3671, Valid Loss: 0.3429
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.2573
Epoch 8/10, Batch 20/20, Loss: 0.2774
Epoch 8/10, Train Loss: 0.3359, Valid Loss: 0.3220
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.6530
Epoch 9/10, Batch 20/20, Loss: 0.6421
Epoch 9/10, Train Loss: 0.3273, Valid Loss: 0.3221
Epoch 10/10, Batch 10/20, Loss: 0.2433
Epoch 10/10, Batch 20/20, Loss: 0.2164
Epoch 10/10, Train Loss: 0.2748, Valid Loss: 0.3026
Model saved!
Accuracy: 0.8902
Precision: 0.8871
Recall: 0.8902
F1-score: 0.8874
Memory Allocated after cleanup: 17.76 MB
End time: 2025-02-25 15:09:41.088335
Duration: 1:56:01


Mejor accuracy al acabar el algoritmo: 0.9030


Fitness check:

Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/20, Loss: 1.2868
Epoch 1/10, Batch 20/20, Loss: 1.0654
Epoch 1/10, Train Loss: 1.2895, Valid Loss: 0.9559
Model saved!
Epoch 2/10, Batch 10/20, Loss: 0.8129
Epoch 2/10, Batch 20/20, Loss: 0.8831
Epoch 2/10, Train Loss: 0.8557, Valid Loss: 0.6635
Model saved!
Epoch 3/10, Batch 10/20, Loss: 0.4917
Epoch 3/10, Batch 20/20, Loss: 1.0430
Epoch 3/10, Train Loss: 0.6356, Valid Loss: 0.5318
Model saved!
Epoch 4/10, Batch 10/20, Loss: 0.5945
Epoch 4/10, Batch 20/20, Loss: 0.3372
Epoch 4/10, Train Loss: 0.5163, Valid Loss: 0.4675
Model saved!
Epoch 5/10, Batch 10/20, Loss: 0.4717
Epoch 5/10, Batch 20/20, Loss: 0.5221
Epoch 5/10, Train Loss: 0.4487, Valid Loss: 0.4208
Model saved!
Epoch 6/10, Batch 10/20, Loss: 0.5381
Epoch 6/10, Batch 20/20, Loss: 0.8111
Epoch 6/10, Train Loss: 0.4368, Valid Loss: 0.3725
Model saved!
Epoch 7/10, Batch 10/20, Loss: 0.4661
Epoch 7/10, Batch 20/20, Loss: 0.4420
Epoch 7/10, Train Loss: 0.3732, Valid Loss: 0.3582
Model saved!
Epoch 8/10, Batch 10/20, Loss: 0.4308
Epoch 8/10, Batch 20/20, Loss: 0.4004
Epoch 8/10, Train Loss: 0.3340, Valid Loss: 0.3404
Model saved!
Epoch 9/10, Batch 10/20, Loss: 0.3614
Epoch 9/10, Batch 20/20, Loss: 1.0122
Epoch 9/10, Train Loss: 0.3490, Valid Loss: 0.3300
Model saved!
Epoch 10/10, Batch 10/20, Loss: 0.3651
Epoch 10/10, Batch 20/20, Loss: 0.2117
Epoch 10/10, Train Loss: 0.2739, Valid Loss: 0.3136
Model saved!
Accuracy: 0.9030
Precision: 0.9004
Recall: 0.9030
F1-score: 0.9010
Memory Allocated after cleanup: 17.76 MB


Mejor accuracy encontrado: 0.9030


--------------------------------------mobilenet  BUSQUEDA LOCAL  25%-------------------------------------------------
Start time: 2025-02-25 15:10:52.467084
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2846
Epoch 1/10, Batch 20/49, Loss: 1.0402
Epoch 1/10, Batch 30/49, Loss: 0.7902
Epoch 1/10, Batch 40/49, Loss: 0.7678
Epoch 1/10, Train Loss: 1.0089, Valid Loss: 0.6946
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6741
Epoch 2/10, Batch 20/49, Loss: 0.4570
Epoch 2/10, Batch 30/49, Loss: 0.4402
Epoch 2/10, Batch 40/49, Loss: 0.4394
Epoch 2/10, Train Loss: 0.5490, Valid Loss: 0.5365
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4854
Epoch 3/10, Batch 20/49, Loss: 0.3769
Epoch 3/10, Batch 30/49, Loss: 0.4415
Epoch 3/10, Batch 40/49, Loss: 0.3373
Epoch 3/10, Train Loss: 0.4359, Valid Loss: 0.4908
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3874
Epoch 4/10, Batch 20/49, Loss: 0.4391
Epoch 4/10, Batch 30/49, Loss: 0.2011
Epoch 4/10, Batch 40/49, Loss: 0.2791
Epoch 4/10, Train Loss: 0.3698, Valid Loss: 0.4449
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2163
Epoch 5/10, Batch 20/49, Loss: 0.3228
Epoch 5/10, Batch 30/49, Loss: 0.2761
Epoch 5/10, Batch 40/49, Loss: 0.3403
Epoch 5/10, Train Loss: 0.3186, Valid Loss: 0.4265
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3395
Epoch 6/10, Batch 20/49, Loss: 0.3042
Epoch 6/10, Batch 30/49, Loss: 0.2601
Epoch 6/10, Batch 40/49, Loss: 0.3355
Epoch 6/10, Train Loss: 0.2958, Valid Loss: 0.4317
Epoch 7/10, Batch 10/49, Loss: 0.1866
Epoch 7/10, Batch 20/49, Loss: 0.1695
Epoch 7/10, Batch 30/49, Loss: 0.2288
Epoch 7/10, Batch 40/49, Loss: 0.1825
Epoch 7/10, Train Loss: 0.2673, Valid Loss: 0.4431
Epoch 8/10, Batch 10/49, Loss: 0.2310
Epoch 8/10, Batch 20/49, Loss: 0.2198
Epoch 8/10, Batch 30/49, Loss: 0.3365
Epoch 8/10, Batch 40/49, Loss: 0.1728
Epoch 8/10, Train Loss: 0.2638, Valid Loss: 0.4135
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2377
Epoch 9/10, Batch 20/49, Loss: 0.1761
Epoch 9/10, Batch 30/49, Loss: 0.5047
Epoch 9/10, Batch 40/49, Loss: 0.2196
Epoch 9/10, Train Loss: 0.2377, Valid Loss: 0.4023
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3032
Epoch 10/10, Batch 20/49, Loss: 0.1962
Epoch 10/10, Batch 30/49, Loss: 0.1886
Epoch 10/10, Batch 40/49, Loss: 0.1836
Epoch 10/10, Train Loss: 0.2168, Valid Loss: 0.3952
Model saved!
Accuracy: 0.9065
Precision: 0.9040
Recall: 0.9065
F1-score: 0.9050
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2959
Epoch 1/10, Batch 20/49, Loss: 1.0207
Epoch 1/10, Batch 30/49, Loss: 0.8506
Epoch 1/10, Batch 40/49, Loss: 0.8447
Epoch 1/10, Train Loss: 0.9891, Valid Loss: 0.6316
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6492
Epoch 2/10, Batch 20/49, Loss: 0.4501
Epoch 2/10, Batch 30/49, Loss: 0.5260
Epoch 2/10, Batch 40/49, Loss: 0.7287
Epoch 2/10, Train Loss: 0.5484, Valid Loss: 0.4544
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3897
Epoch 3/10, Batch 20/49, Loss: 0.4807
Epoch 3/10, Batch 30/49, Loss: 0.3753
Epoch 3/10, Batch 40/49, Loss: 0.3282
Epoch 3/10, Train Loss: 0.4248, Valid Loss: 0.3841
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3752
Epoch 4/10, Batch 20/49, Loss: 0.3045
Epoch 4/10, Batch 30/49, Loss: 0.2099
Epoch 4/10, Batch 40/49, Loss: 0.3480
Epoch 4/10, Train Loss: 0.3615, Valid Loss: 0.3408
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3158
Epoch 5/10, Batch 20/49, Loss: 0.1660
Epoch 5/10, Batch 30/49, Loss: 0.3058
Epoch 5/10, Batch 40/49, Loss: 0.3773
Epoch 5/10, Train Loss: 0.3154, Valid Loss: 0.3170
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1988
Epoch 6/10, Batch 20/49, Loss: 0.3490
Epoch 6/10, Batch 30/49, Loss: 0.2438
Epoch 6/10, Batch 40/49, Loss: 0.1693
Epoch 6/10, Train Loss: 0.2972, Valid Loss: 0.3041
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2824
Epoch 7/10, Batch 20/49, Loss: 0.3343
Epoch 7/10, Batch 30/49, Loss: 0.4004
Epoch 7/10, Batch 40/49, Loss: 0.2197
Epoch 7/10, Train Loss: 0.2801, Valid Loss: 0.2986
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1734
Epoch 8/10, Batch 20/49, Loss: 0.2133
Epoch 8/10, Batch 30/49, Loss: 0.2813
Epoch 8/10, Batch 40/49, Loss: 0.2705
Epoch 8/10, Train Loss: 0.2527, Valid Loss: 0.2823
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1249
Epoch 9/10, Batch 20/49, Loss: 0.2554
Epoch 9/10, Batch 30/49, Loss: 0.6447
Epoch 9/10, Batch 40/49, Loss: 0.1685
Epoch 9/10, Train Loss: 0.2537, Valid Loss: 0.2764
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1572
Epoch 10/10, Batch 20/49, Loss: 0.1555
Epoch 10/10, Batch 30/49, Loss: 0.2169
Epoch 10/10, Batch 40/49, Loss: 0.1973
Epoch 10/10, Train Loss: 0.2312, Valid Loss: 0.2612
Model saved!
Accuracy: 0.9065
Precision: 0.9034
Recall: 0.9065
F1-score: 0.9032
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2626
Epoch 1/10, Batch 20/49, Loss: 1.1435
Epoch 1/10, Batch 30/49, Loss: 0.7700
Epoch 1/10, Batch 40/49, Loss: 0.7319
Epoch 1/10, Train Loss: 1.0147, Valid Loss: 0.6986
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7939
Epoch 2/10, Batch 20/49, Loss: 0.4275
Epoch 2/10, Batch 30/49, Loss: 0.4375
Epoch 2/10, Batch 40/49, Loss: 0.5131
Epoch 2/10, Train Loss: 0.5584, Valid Loss: 0.5348
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5696
Epoch 3/10, Batch 20/49, Loss: 0.3883
Epoch 3/10, Batch 30/49, Loss: 0.3555
Epoch 3/10, Batch 40/49, Loss: 0.4992
Epoch 3/10, Train Loss: 0.4310, Valid Loss: 0.4585
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2258
Epoch 4/10, Batch 20/49, Loss: 0.3828
Epoch 4/10, Batch 30/49, Loss: 0.2276
Epoch 4/10, Batch 40/49, Loss: 0.3263
Epoch 4/10, Train Loss: 0.3708, Valid Loss: 0.3950
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3272
Epoch 5/10, Batch 20/49, Loss: 0.2436
Epoch 5/10, Batch 30/49, Loss: 0.2649
Epoch 5/10, Batch 40/49, Loss: 0.3163
Epoch 5/10, Train Loss: 0.3231, Valid Loss: 0.3868
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2435
Epoch 6/10, Batch 20/49, Loss: 0.2421
Epoch 6/10, Batch 30/49, Loss: 0.4728
Epoch 6/10, Batch 40/49, Loss: 0.4250
Epoch 6/10, Train Loss: 0.2956, Valid Loss: 0.3845
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3324
Epoch 7/10, Batch 20/49, Loss: 0.3007
Epoch 7/10, Batch 30/49, Loss: 0.2317
Epoch 7/10, Batch 40/49, Loss: 0.1495
Epoch 7/10, Train Loss: 0.2686, Valid Loss: 0.3787
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2359
Epoch 8/10, Batch 20/49, Loss: 0.1975
Epoch 8/10, Batch 30/49, Loss: 0.3291
Epoch 8/10, Batch 40/49, Loss: 0.1903
Epoch 8/10, Train Loss: 0.2634, Valid Loss: 0.3513
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1632
Epoch 9/10, Batch 20/49, Loss: 0.3094
Epoch 9/10, Batch 30/49, Loss: 0.4774
Epoch 9/10, Batch 40/49, Loss: 0.3295
Epoch 9/10, Train Loss: 0.2481, Valid Loss: 0.3471
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2503
Epoch 10/10, Batch 20/49, Loss: 0.0694
Epoch 10/10, Batch 30/49, Loss: 0.1619
Epoch 10/10, Batch 40/49, Loss: 0.2577
Epoch 10/10, Train Loss: 0.2172, Valid Loss: 0.3194
Model saved!
Accuracy: 0.9007
Precision: 0.8997
Recall: 0.9007
F1-score: 0.8965
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2158
Epoch 1/10, Batch 20/49, Loss: 1.0887
Epoch 1/10, Batch 30/49, Loss: 0.8648
Epoch 1/10, Batch 40/49, Loss: 0.6202
Epoch 1/10, Train Loss: 0.9796, Valid Loss: 0.6211
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7037
Epoch 2/10, Batch 20/49, Loss: 0.4787
Epoch 2/10, Batch 30/49, Loss: 0.4864
Epoch 2/10, Batch 40/49, Loss: 0.4695
Epoch 2/10, Train Loss: 0.5269, Valid Loss: 0.4574
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4814
Epoch 3/10, Batch 20/49, Loss: 0.4222
Epoch 3/10, Batch 30/49, Loss: 0.3786
Epoch 3/10, Batch 40/49, Loss: 0.3522
Epoch 3/10, Train Loss: 0.4089, Valid Loss: 0.3907
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3617
Epoch 4/10, Batch 20/49, Loss: 0.3220
Epoch 4/10, Batch 30/49, Loss: 0.3952
Epoch 4/10, Batch 40/49, Loss: 0.3071
Epoch 4/10, Train Loss: 0.3635, Valid Loss: 0.3461
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3798
Epoch 5/10, Batch 20/49, Loss: 0.1873
Epoch 5/10, Batch 30/49, Loss: 0.2254
Epoch 5/10, Batch 40/49, Loss: 0.1649
Epoch 5/10, Train Loss: 0.3009, Valid Loss: 0.3266
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2342
Epoch 6/10, Batch 20/49, Loss: 0.3782
Epoch 6/10, Batch 30/49, Loss: 0.3959
Epoch 6/10, Batch 40/49, Loss: 0.1770
Epoch 6/10, Train Loss: 0.2914, Valid Loss: 0.3274
Epoch 7/10, Batch 10/49, Loss: 0.2338
Epoch 7/10, Batch 20/49, Loss: 0.3038
Epoch 7/10, Batch 30/49, Loss: 0.3125
Epoch 7/10, Batch 40/49, Loss: 0.1243
Epoch 7/10, Train Loss: 0.2584, Valid Loss: 0.3143
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3435
Epoch 8/10, Batch 20/49, Loss: 0.1671
Epoch 8/10, Batch 30/49, Loss: 0.1638
Epoch 8/10, Batch 40/49, Loss: 0.2162
Epoch 8/10, Train Loss: 0.2459, Valid Loss: 0.2987
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.0969
Epoch 9/10, Batch 20/49, Loss: 0.2561
Epoch 9/10, Batch 30/49, Loss: 0.5037
Epoch 9/10, Batch 40/49, Loss: 0.1331
Epoch 9/10, Train Loss: 0.2346, Valid Loss: 0.2864
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2705
Epoch 10/10, Batch 20/49, Loss: 0.1476
Epoch 10/10, Batch 30/49, Loss: 0.1476
Epoch 10/10, Batch 40/49, Loss: 0.1894
Epoch 10/10, Train Loss: 0.2090, Valid Loss: 0.2887
Accuracy: 0.9030
Precision: 0.8997
Recall: 0.9030
F1-score: 0.9011
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3618
Epoch 1/10, Batch 20/49, Loss: 1.1435
Epoch 1/10, Batch 30/49, Loss: 0.7699
Epoch 1/10, Batch 40/49, Loss: 0.7984
Epoch 1/10, Train Loss: 1.0137, Valid Loss: 0.6572
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7218
Epoch 2/10, Batch 20/49, Loss: 0.4654
Epoch 2/10, Batch 30/49, Loss: 0.5895
Epoch 2/10, Batch 40/49, Loss: 0.6128
Epoch 2/10, Train Loss: 0.5504, Valid Loss: 0.4664
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4351
Epoch 3/10, Batch 20/49, Loss: 0.4033
Epoch 3/10, Batch 30/49, Loss: 0.4137
Epoch 3/10, Batch 40/49, Loss: 0.2724
Epoch 3/10, Train Loss: 0.4284, Valid Loss: 0.4018
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2159
Epoch 4/10, Batch 20/49, Loss: 0.3832
Epoch 4/10, Batch 30/49, Loss: 0.2938
Epoch 4/10, Batch 40/49, Loss: 0.2298
Epoch 4/10, Train Loss: 0.3710, Valid Loss: 0.3542
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3761
Epoch 5/10, Batch 20/49, Loss: 0.3270
Epoch 5/10, Batch 30/49, Loss: 0.2700
Epoch 5/10, Batch 40/49, Loss: 0.2303
Epoch 5/10, Train Loss: 0.3224, Valid Loss: 0.3288
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1585
Epoch 6/10, Batch 20/49, Loss: 0.3107
Epoch 6/10, Batch 30/49, Loss: 0.4072
Epoch 6/10, Batch 40/49, Loss: 0.4106
Epoch 6/10, Train Loss: 0.2968, Valid Loss: 0.3197
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2469
Epoch 7/10, Batch 20/49, Loss: 0.1653
Epoch 7/10, Batch 30/49, Loss: 0.3568
Epoch 7/10, Batch 40/49, Loss: 0.3223
Epoch 7/10, Train Loss: 0.2734, Valid Loss: 0.3114
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1176
Epoch 8/10, Batch 20/49, Loss: 0.2761
Epoch 8/10, Batch 30/49, Loss: 0.3747
Epoch 8/10, Batch 40/49, Loss: 0.2130
Epoch 8/10, Train Loss: 0.2556, Valid Loss: 0.2909
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1859
Epoch 9/10, Batch 20/49, Loss: 0.2376
Epoch 9/10, Batch 30/49, Loss: 0.4540
Epoch 9/10, Batch 40/49, Loss: 0.1579
Epoch 9/10, Train Loss: 0.2423, Valid Loss: 0.2815
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2510
Epoch 10/10, Batch 20/49, Loss: 0.1153
Epoch 10/10, Batch 30/49, Loss: 0.3022
Epoch 10/10, Batch 40/49, Loss: 0.1954
Epoch 10/10, Train Loss: 0.2236, Valid Loss: 0.2785
Model saved!
Accuracy: 0.9054
Precision: 0.9009
Recall: 0.9054
F1-score: 0.9012
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2773
Epoch 1/10, Batch 20/49, Loss: 1.0309
Epoch 1/10, Batch 30/49, Loss: 0.8626
Epoch 1/10, Batch 40/49, Loss: 0.7697
Epoch 1/10, Train Loss: 1.0051, Valid Loss: 0.6395
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7545
Epoch 2/10, Batch 20/49, Loss: 0.4869
Epoch 2/10, Batch 30/49, Loss: 0.4453
Epoch 2/10, Batch 40/49, Loss: 0.4980
Epoch 2/10, Train Loss: 0.5533, Valid Loss: 0.4719
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.2771
Epoch 3/10, Batch 20/49, Loss: 0.4153
Epoch 3/10, Batch 30/49, Loss: 0.4027
Epoch 3/10, Batch 40/49, Loss: 0.3343
Epoch 3/10, Train Loss: 0.4197, Valid Loss: 0.3933
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2716
Epoch 4/10, Batch 20/49, Loss: 0.4299
Epoch 4/10, Batch 30/49, Loss: 0.2181
Epoch 4/10, Batch 40/49, Loss: 0.2545
Epoch 4/10, Train Loss: 0.3648, Valid Loss: 0.3519
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3266
Epoch 5/10, Batch 20/49, Loss: 0.3565
Epoch 5/10, Batch 30/49, Loss: 0.3117
Epoch 5/10, Batch 40/49, Loss: 0.2103
Epoch 5/10, Train Loss: 0.3087, Valid Loss: 0.3292
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2731
Epoch 6/10, Batch 20/49, Loss: 0.2791
Epoch 6/10, Batch 30/49, Loss: 0.2437
Epoch 6/10, Batch 40/49, Loss: 0.2726
Epoch 6/10, Train Loss: 0.2893, Valid Loss: 0.3160
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3354
Epoch 7/10, Batch 20/49, Loss: 0.1750
Epoch 7/10, Batch 30/49, Loss: 0.4348
Epoch 7/10, Batch 40/49, Loss: 0.1871
Epoch 7/10, Train Loss: 0.2622, Valid Loss: 0.3105
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1274
Epoch 8/10, Batch 20/49, Loss: 0.2883
Epoch 8/10, Batch 30/49, Loss: 0.2969
Epoch 8/10, Batch 40/49, Loss: 0.2203
Epoch 8/10, Train Loss: 0.2486, Valid Loss: 0.3021
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1807
Epoch 9/10, Batch 20/49, Loss: 0.3492
Epoch 9/10, Batch 30/49, Loss: 0.3666
Epoch 9/10, Batch 40/49, Loss: 0.2273
Epoch 9/10, Train Loss: 0.2472, Valid Loss: 0.2959
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3004
Epoch 10/10, Batch 20/49, Loss: 0.1119
Epoch 10/10, Batch 30/49, Loss: 0.3512
Epoch 10/10, Batch 40/49, Loss: 0.0940
Epoch 10/10, Train Loss: 0.2215, Valid Loss: 0.2806
Model saved!
Accuracy: 0.8937
Precision: 0.8896
Recall: 0.8937
F1-score: 0.8869
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2428
Epoch 1/10, Batch 20/49, Loss: 1.1411
Epoch 1/10, Batch 30/49, Loss: 0.8869
Epoch 1/10, Batch 40/49, Loss: 0.7184
Epoch 1/10, Train Loss: 0.9943, Valid Loss: 0.6344
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5732
Epoch 2/10, Batch 20/49, Loss: 0.6679
Epoch 2/10, Batch 30/49, Loss: 0.5301
Epoch 2/10, Batch 40/49, Loss: 0.5025
Epoch 2/10, Train Loss: 0.5362, Valid Loss: 0.4680
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4468
Epoch 3/10, Batch 20/49, Loss: 0.4004
Epoch 3/10, Batch 30/49, Loss: 0.3768
Epoch 3/10, Batch 40/49, Loss: 0.4132
Epoch 3/10, Train Loss: 0.4184, Valid Loss: 0.3882
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4142
Epoch 4/10, Batch 20/49, Loss: 0.5254
Epoch 4/10, Batch 30/49, Loss: 0.2674
Epoch 4/10, Batch 40/49, Loss: 0.3726
Epoch 4/10, Train Loss: 0.3639, Valid Loss: 0.3420
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2723
Epoch 5/10, Batch 20/49, Loss: 0.2218
Epoch 5/10, Batch 30/49, Loss: 0.2189
Epoch 5/10, Batch 40/49, Loss: 0.2252
Epoch 5/10, Train Loss: 0.3130, Valid Loss: 0.3164
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2122
Epoch 6/10, Batch 20/49, Loss: 0.2690
Epoch 6/10, Batch 30/49, Loss: 0.3876
Epoch 6/10, Batch 40/49, Loss: 0.3051
Epoch 6/10, Train Loss: 0.2910, Valid Loss: 0.3170
Epoch 7/10, Batch 10/49, Loss: 0.3081
Epoch 7/10, Batch 20/49, Loss: 0.2840
Epoch 7/10, Batch 30/49, Loss: 0.3116
Epoch 7/10, Batch 40/49, Loss: 0.1782
Epoch 7/10, Train Loss: 0.2749, Valid Loss: 0.3042
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2413
Epoch 8/10, Batch 20/49, Loss: 0.3123
Epoch 8/10, Batch 30/49, Loss: 0.3004
Epoch 8/10, Batch 40/49, Loss: 0.1713
Epoch 8/10, Train Loss: 0.2479, Valid Loss: 0.2910
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1583
Epoch 9/10, Batch 20/49, Loss: 0.2118
Epoch 9/10, Batch 30/49, Loss: 0.3276
Epoch 9/10, Batch 40/49, Loss: 0.1336
Epoch 9/10, Train Loss: 0.2476, Valid Loss: 0.2835
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.0839
Epoch 10/10, Batch 20/49, Loss: 0.2348
Epoch 10/10, Batch 30/49, Loss: 0.2469
Epoch 10/10, Batch 40/49, Loss: 0.3035
Epoch 10/10, Train Loss: 0.2141, Valid Loss: 0.2629
Model saved!
Accuracy: 0.8949
Precision: 0.8926
Recall: 0.8949
F1-score: 0.8913
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2605
Epoch 1/10, Batch 20/49, Loss: 1.0499
Epoch 1/10, Batch 30/49, Loss: 0.7624
Epoch 1/10, Batch 40/49, Loss: 0.7986
Epoch 1/10, Train Loss: 0.9910, Valid Loss: 0.6236
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6945
Epoch 2/10, Batch 20/49, Loss: 0.4719
Epoch 2/10, Batch 30/49, Loss: 0.4411
Epoch 2/10, Batch 40/49, Loss: 0.6698
Epoch 2/10, Train Loss: 0.5344, Valid Loss: 0.4561
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4115
Epoch 3/10, Batch 20/49, Loss: 0.4378
Epoch 3/10, Batch 30/49, Loss: 0.2751
Epoch 3/10, Batch 40/49, Loss: 0.3095
Epoch 3/10, Train Loss: 0.4186, Valid Loss: 0.3934
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3296
Epoch 4/10, Batch 20/49, Loss: 0.4005
Epoch 4/10, Batch 30/49, Loss: 0.2791
Epoch 4/10, Batch 40/49, Loss: 0.4081
Epoch 4/10, Train Loss: 0.3645, Valid Loss: 0.3519
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3888
Epoch 5/10, Batch 20/49, Loss: 0.2464
Epoch 5/10, Batch 30/49, Loss: 0.2918
Epoch 5/10, Batch 40/49, Loss: 0.1983
Epoch 5/10, Train Loss: 0.3082, Valid Loss: 0.3255
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2371
Epoch 6/10, Batch 20/49, Loss: 0.1986
Epoch 6/10, Batch 30/49, Loss: 0.3768
Epoch 6/10, Batch 40/49, Loss: 0.2198
Epoch 6/10, Train Loss: 0.2878, Valid Loss: 0.3102
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3156
Epoch 7/10, Batch 20/49, Loss: 0.1743
Epoch 7/10, Batch 30/49, Loss: 0.3731
Epoch 7/10, Batch 40/49, Loss: 0.1860
Epoch 7/10, Train Loss: 0.2655, Valid Loss: 0.3007
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2614
Epoch 8/10, Batch 20/49, Loss: 0.2186
Epoch 8/10, Batch 30/49, Loss: 0.2736
Epoch 8/10, Batch 40/49, Loss: 0.1674
Epoch 8/10, Train Loss: 0.2570, Valid Loss: 0.2889
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2549
Epoch 9/10, Batch 20/49, Loss: 0.1749
Epoch 9/10, Batch 30/49, Loss: 0.5412
Epoch 9/10, Batch 40/49, Loss: 0.1625
Epoch 9/10, Train Loss: 0.2332, Valid Loss: 0.2940
Epoch 10/10, Batch 10/49, Loss: 0.2187
Epoch 10/10, Batch 20/49, Loss: 0.1849
Epoch 10/10, Batch 30/49, Loss: 0.3143
Epoch 10/10, Batch 40/49, Loss: 0.1205
Epoch 10/10, Train Loss: 0.2122, Valid Loss: 0.2990
Accuracy: 0.9019
Precision: 0.8983
Recall: 0.9019
F1-score: 0.8981
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3061
Epoch 1/10, Batch 20/49, Loss: 1.1347
Epoch 1/10, Batch 30/49, Loss: 0.9096
Epoch 1/10, Batch 40/49, Loss: 0.7089
Epoch 1/10, Train Loss: 1.0085, Valid Loss: 0.6832
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6175
Epoch 2/10, Batch 20/49, Loss: 0.4699
Epoch 2/10, Batch 30/49, Loss: 0.4734
Epoch 2/10, Batch 40/49, Loss: 0.5545
Epoch 2/10, Train Loss: 0.5397, Valid Loss: 0.5252
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4125
Epoch 3/10, Batch 20/49, Loss: 0.3409
Epoch 3/10, Batch 30/49, Loss: 0.3289
Epoch 3/10, Batch 40/49, Loss: 0.4485
Epoch 3/10, Train Loss: 0.4298, Valid Loss: 0.4631
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2406
Epoch 4/10, Batch 20/49, Loss: 0.4798
Epoch 4/10, Batch 30/49, Loss: 0.2452
Epoch 4/10, Batch 40/49, Loss: 0.2973
Epoch 4/10, Train Loss: 0.3728, Valid Loss: 0.4082
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3039
Epoch 5/10, Batch 20/49, Loss: 0.2869
Epoch 5/10, Batch 30/49, Loss: 0.2535
Epoch 5/10, Batch 40/49, Loss: 0.3948
Epoch 5/10, Train Loss: 0.3342, Valid Loss: 0.3907
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2222
Epoch 6/10, Batch 20/49, Loss: 0.3001
Epoch 6/10, Batch 30/49, Loss: 0.4063
Epoch 6/10, Batch 40/49, Loss: 0.2691
Epoch 6/10, Train Loss: 0.3044, Valid Loss: 0.3819
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2106
Epoch 7/10, Batch 20/49, Loss: 0.2385
Epoch 7/10, Batch 30/49, Loss: 0.3954
Epoch 7/10, Batch 40/49, Loss: 0.2998
Epoch 7/10, Train Loss: 0.2929, Valid Loss: 0.3832
Epoch 8/10, Batch 10/49, Loss: 0.2428
Epoch 8/10, Batch 20/49, Loss: 0.3080
Epoch 8/10, Batch 30/49, Loss: 0.3146
Epoch 8/10, Batch 40/49, Loss: 0.2301
Epoch 8/10, Train Loss: 0.2554, Valid Loss: 0.3598
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1922
Epoch 9/10, Batch 20/49, Loss: 0.1822
Epoch 9/10, Batch 30/49, Loss: 0.4880
Epoch 9/10, Batch 40/49, Loss: 0.1265
Epoch 9/10, Train Loss: 0.2438, Valid Loss: 0.3445
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1605
Epoch 10/10, Batch 20/49, Loss: 0.1920
Epoch 10/10, Batch 30/49, Loss: 0.2139
Epoch 10/10, Batch 40/49, Loss: 0.2638
Epoch 10/10, Train Loss: 0.2216, Valid Loss: 0.3433
Model saved!
Accuracy: 0.9100
Precision: 0.9065
Recall: 0.9100
F1-score: 0.9078
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 9. Fitness: 0.9100
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3140
Epoch 1/10, Batch 20/49, Loss: 1.0280
Epoch 1/10, Batch 30/49, Loss: 0.8767
Epoch 1/10, Batch 40/49, Loss: 0.7680
Epoch 1/10, Train Loss: 0.9929, Valid Loss: 0.7107
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6138
Epoch 2/10, Batch 20/49, Loss: 0.5377
Epoch 2/10, Batch 30/49, Loss: 0.5150
Epoch 2/10, Batch 40/49, Loss: 0.4493
Epoch 2/10, Train Loss: 0.5288, Valid Loss: 0.5350
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5320
Epoch 3/10, Batch 20/49, Loss: 0.5038
Epoch 3/10, Batch 30/49, Loss: 0.4422
Epoch 3/10, Batch 40/49, Loss: 0.3740
Epoch 3/10, Train Loss: 0.4213, Valid Loss: 0.4683
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2684
Epoch 4/10, Batch 20/49, Loss: 0.4639
Epoch 4/10, Batch 30/49, Loss: 0.4569
Epoch 4/10, Batch 40/49, Loss: 0.2927
Epoch 4/10, Train Loss: 0.3654, Valid Loss: 0.4330
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2972
Epoch 5/10, Batch 20/49, Loss: 0.3825
Epoch 5/10, Batch 30/49, Loss: 0.3242
Epoch 5/10, Batch 40/49, Loss: 0.1783
Epoch 5/10, Train Loss: 0.3064, Valid Loss: 0.4174
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2302
Epoch 6/10, Batch 20/49, Loss: 0.1907
Epoch 6/10, Batch 30/49, Loss: 0.2257
Epoch 6/10, Batch 40/49, Loss: 0.2650
Epoch 6/10, Train Loss: 0.2851, Valid Loss: 0.3987
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2034
Epoch 7/10, Batch 20/49, Loss: 0.2220
Epoch 7/10, Batch 30/49, Loss: 0.3276
Epoch 7/10, Batch 40/49, Loss: 0.2948
Epoch 7/10, Train Loss: 0.2705, Valid Loss: 0.3865
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1876
Epoch 8/10, Batch 20/49, Loss: 0.2409
Epoch 8/10, Batch 30/49, Loss: 0.2259
Epoch 8/10, Batch 40/49, Loss: 0.1799
Epoch 8/10, Train Loss: 0.2537, Valid Loss: 0.3744
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2106
Epoch 9/10, Batch 20/49, Loss: 0.2178
Epoch 9/10, Batch 30/49, Loss: 0.4632
Epoch 9/10, Batch 40/49, Loss: 0.1197
Epoch 9/10, Train Loss: 0.2347, Valid Loss: 0.3506
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2605
Epoch 10/10, Batch 20/49, Loss: 0.1916
Epoch 10/10, Batch 30/49, Loss: 0.2654
Epoch 10/10, Batch 40/49, Loss: 0.1878
Epoch 10/10, Train Loss: 0.2140, Valid Loss: 0.3398
Model saved!
Accuracy: 0.9100
Precision: 0.9064
Recall: 0.9100
F1-score: 0.9072
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3088
Epoch 1/10, Batch 20/49, Loss: 0.9428
Epoch 1/10, Batch 30/49, Loss: 0.8239
Epoch 1/10, Batch 40/49, Loss: 0.7057
Epoch 1/10, Train Loss: 0.9826, Valid Loss: 0.6781
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7092
Epoch 2/10, Batch 20/49, Loss: 0.3695
Epoch 2/10, Batch 30/49, Loss: 0.4144
Epoch 2/10, Batch 40/49, Loss: 0.4473
Epoch 2/10, Train Loss: 0.5301, Valid Loss: 0.5179
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3577
Epoch 3/10, Batch 20/49, Loss: 0.4045
Epoch 3/10, Batch 30/49, Loss: 0.5082
Epoch 3/10, Batch 40/49, Loss: 0.2582
Epoch 3/10, Train Loss: 0.4117, Valid Loss: 0.4483
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3138
Epoch 4/10, Batch 20/49, Loss: 0.2366
Epoch 4/10, Batch 30/49, Loss: 0.1994
Epoch 4/10, Batch 40/49, Loss: 0.3557
Epoch 4/10, Train Loss: 0.3717, Valid Loss: 0.3992
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2637
Epoch 5/10, Batch 20/49, Loss: 0.2387
Epoch 5/10, Batch 30/49, Loss: 0.2843
Epoch 5/10, Batch 40/49, Loss: 0.1402
Epoch 5/10, Train Loss: 0.2954, Valid Loss: 0.3877
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2446
Epoch 6/10, Batch 20/49, Loss: 0.2568
Epoch 6/10, Batch 30/49, Loss: 0.2623
Epoch 6/10, Batch 40/49, Loss: 0.3193
Epoch 6/10, Train Loss: 0.2912, Valid Loss: 0.3669
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3101
Epoch 7/10, Batch 20/49, Loss: 0.1488
Epoch 7/10, Batch 30/49, Loss: 0.5401
Epoch 7/10, Batch 40/49, Loss: 0.1404
Epoch 7/10, Train Loss: 0.2732, Valid Loss: 0.3639
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3070
Epoch 8/10, Batch 20/49, Loss: 0.2659
Epoch 8/10, Batch 30/49, Loss: 0.1710
Epoch 8/10, Batch 40/49, Loss: 0.2357
Epoch 8/10, Train Loss: 0.2467, Valid Loss: 0.3377
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1845
Epoch 9/10, Batch 20/49, Loss: 0.2251
Epoch 9/10, Batch 30/49, Loss: 0.3241
Epoch 9/10, Batch 40/49, Loss: 0.1967
Epoch 9/10, Train Loss: 0.2510, Valid Loss: 0.3259
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2396
Epoch 10/10, Batch 20/49, Loss: 0.1493
Epoch 10/10, Batch 30/49, Loss: 0.2309
Epoch 10/10, Batch 40/49, Loss: 0.2465
Epoch 10/10, Train Loss: 0.2143, Valid Loss: 0.3154
Model saved!
Accuracy: 0.9077
Precision: 0.9040
Recall: 0.9077
F1-score: 0.9046
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2495
Epoch 1/10, Batch 20/49, Loss: 1.0976
Epoch 1/10, Batch 30/49, Loss: 0.8333
Epoch 1/10, Batch 40/49, Loss: 0.7821
Epoch 1/10, Train Loss: 0.9936, Valid Loss: 0.6909
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5648
Epoch 2/10, Batch 20/49, Loss: 0.5367
Epoch 2/10, Batch 30/49, Loss: 0.4645
Epoch 2/10, Batch 40/49, Loss: 0.3776
Epoch 2/10, Train Loss: 0.5268, Valid Loss: 0.5304
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3420
Epoch 3/10, Batch 20/49, Loss: 0.5026
Epoch 3/10, Batch 30/49, Loss: 0.3641
Epoch 3/10, Batch 40/49, Loss: 0.3702
Epoch 3/10, Train Loss: 0.4195, Valid Loss: 0.4675
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2857
Epoch 4/10, Batch 20/49, Loss: 0.3177
Epoch 4/10, Batch 30/49, Loss: 0.3238
Epoch 4/10, Batch 40/49, Loss: 0.2677
Epoch 4/10, Train Loss: 0.3668, Valid Loss: 0.4054
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3314
Epoch 5/10, Batch 20/49, Loss: 0.2034
Epoch 5/10, Batch 30/49, Loss: 0.2659
Epoch 5/10, Batch 40/49, Loss: 0.1938
Epoch 5/10, Train Loss: 0.3158, Valid Loss: 0.4132
Epoch 6/10, Batch 10/49, Loss: 0.2078
Epoch 6/10, Batch 20/49, Loss: 0.3981
Epoch 6/10, Batch 30/49, Loss: 0.3134
Epoch 6/10, Batch 40/49, Loss: 0.1409
Epoch 6/10, Train Loss: 0.2840, Valid Loss: 0.4036
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2779
Epoch 7/10, Batch 20/49, Loss: 0.3507
Epoch 7/10, Batch 30/49, Loss: 0.4082
Epoch 7/10, Batch 40/49, Loss: 0.3343
Epoch 7/10, Train Loss: 0.2676, Valid Loss: 0.3984
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2276
Epoch 8/10, Batch 20/49, Loss: 0.1774
Epoch 8/10, Batch 30/49, Loss: 0.1590
Epoch 8/10, Batch 40/49, Loss: 0.1475
Epoch 8/10, Train Loss: 0.2528, Valid Loss: 0.3781
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1562
Epoch 9/10, Batch 20/49, Loss: 0.2422
Epoch 9/10, Batch 30/49, Loss: 0.4606
Epoch 9/10, Batch 40/49, Loss: 0.2040
Epoch 9/10, Train Loss: 0.2398, Valid Loss: 0.3846
Epoch 10/10, Batch 10/49, Loss: 0.1796
Epoch 10/10, Batch 20/49, Loss: 0.1909
Epoch 10/10, Batch 30/49, Loss: 0.2300
Epoch 10/10, Batch 40/49, Loss: 0.1793
Epoch 10/10, Train Loss: 0.2107, Valid Loss: 0.3721
Model saved!
Accuracy: 0.9089
Precision: 0.9052
Recall: 0.9089
F1-score: 0.9063
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2966
Epoch 1/10, Batch 20/49, Loss: 1.0332
Epoch 1/10, Batch 30/49, Loss: 0.8605
Epoch 1/10, Batch 40/49, Loss: 0.7256
Epoch 1/10, Train Loss: 0.9977, Valid Loss: 0.6525
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6231
Epoch 2/10, Batch 20/49, Loss: 0.4955
Epoch 2/10, Batch 30/49, Loss: 0.5640
Epoch 2/10, Batch 40/49, Loss: 0.5442
Epoch 2/10, Train Loss: 0.5380, Valid Loss: 0.4916
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4907
Epoch 3/10, Batch 20/49, Loss: 0.5049
Epoch 3/10, Batch 30/49, Loss: 0.3391
Epoch 3/10, Batch 40/49, Loss: 0.3904
Epoch 3/10, Train Loss: 0.4345, Valid Loss: 0.4234
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2829
Epoch 4/10, Batch 20/49, Loss: 0.4203
Epoch 4/10, Batch 30/49, Loss: 0.3039
Epoch 4/10, Batch 40/49, Loss: 0.3043
Epoch 4/10, Train Loss: 0.3698, Valid Loss: 0.3695
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2227
Epoch 5/10, Batch 20/49, Loss: 0.3475
Epoch 5/10, Batch 30/49, Loss: 0.2690
Epoch 5/10, Batch 40/49, Loss: 0.2578
Epoch 5/10, Train Loss: 0.3198, Valid Loss: 0.3422
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2488
Epoch 6/10, Batch 20/49, Loss: 0.2470
Epoch 6/10, Batch 30/49, Loss: 0.2670
Epoch 6/10, Batch 40/49, Loss: 0.2528
Epoch 6/10, Train Loss: 0.2910, Valid Loss: 0.3242
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2577
Epoch 7/10, Batch 20/49, Loss: 0.2004
Epoch 7/10, Batch 30/49, Loss: 0.3708
Epoch 7/10, Batch 40/49, Loss: 0.1605
Epoch 7/10, Train Loss: 0.2775, Valid Loss: 0.3188
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2495
Epoch 8/10, Batch 20/49, Loss: 0.2033
Epoch 8/10, Batch 30/49, Loss: 0.2603
Epoch 8/10, Batch 40/49, Loss: 0.1633
Epoch 8/10, Train Loss: 0.2571, Valid Loss: 0.3030
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1305
Epoch 9/10, Batch 20/49, Loss: 0.2815
Epoch 9/10, Batch 30/49, Loss: 0.4339
Epoch 9/10, Batch 40/49, Loss: 0.2146
Epoch 9/10, Train Loss: 0.2409, Valid Loss: 0.2850
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2351
Epoch 10/10, Batch 20/49, Loss: 0.1458
Epoch 10/10, Batch 30/49, Loss: 0.2684
Epoch 10/10, Batch 40/49, Loss: 0.2042
Epoch 10/10, Train Loss: 0.2121, Valid Loss: 0.2768
Model saved!
Accuracy: 0.9100
Precision: 0.9069
Recall: 0.9100
F1-score: 0.9069
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2646
Epoch 1/10, Batch 20/49, Loss: 1.0730
Epoch 1/10, Batch 30/49, Loss: 0.7768
Epoch 1/10, Batch 40/49, Loss: 0.8266
Epoch 1/10, Train Loss: 1.0070, Valid Loss: 0.5944
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6250
Epoch 2/10, Batch 20/49, Loss: 0.4788
Epoch 2/10, Batch 30/49, Loss: 0.6508
Epoch 2/10, Batch 40/49, Loss: 0.6158
Epoch 2/10, Train Loss: 0.5343, Valid Loss: 0.4251
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4084
Epoch 3/10, Batch 20/49, Loss: 0.3215
Epoch 3/10, Batch 30/49, Loss: 0.4254
Epoch 3/10, Batch 40/49, Loss: 0.2925
Epoch 3/10, Train Loss: 0.4060, Valid Loss: 0.3540
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3160
Epoch 4/10, Batch 20/49, Loss: 0.3342
Epoch 4/10, Batch 30/49, Loss: 0.2844
Epoch 4/10, Batch 40/49, Loss: 0.3005
Epoch 4/10, Train Loss: 0.3521, Valid Loss: 0.3120
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2553
Epoch 5/10, Batch 20/49, Loss: 0.2215
Epoch 5/10, Batch 30/49, Loss: 0.2300
Epoch 5/10, Batch 40/49, Loss: 0.2249
Epoch 5/10, Train Loss: 0.3059, Valid Loss: 0.2901
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2203
Epoch 6/10, Batch 20/49, Loss: 0.2245
Epoch 6/10, Batch 30/49, Loss: 0.2489
Epoch 6/10, Batch 40/49, Loss: 0.2142
Epoch 6/10, Train Loss: 0.2769, Valid Loss: 0.2832
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1527
Epoch 7/10, Batch 20/49, Loss: 0.1568
Epoch 7/10, Batch 30/49, Loss: 0.2963
Epoch 7/10, Batch 40/49, Loss: 0.1717
Epoch 7/10, Train Loss: 0.2621, Valid Loss: 0.2860
Epoch 8/10, Batch 10/49, Loss: 0.1965
Epoch 8/10, Batch 20/49, Loss: 0.2910
Epoch 8/10, Batch 30/49, Loss: 0.2822
Epoch 8/10, Batch 40/49, Loss: 0.2627
Epoch 8/10, Train Loss: 0.2444, Valid Loss: 0.2652
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1968
Epoch 9/10, Batch 20/49, Loss: 0.1033
Epoch 9/10, Batch 30/49, Loss: 0.4336
Epoch 9/10, Batch 40/49, Loss: 0.1131
Epoch 9/10, Train Loss: 0.2335, Valid Loss: 0.2574
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2751
Epoch 10/10, Batch 20/49, Loss: 0.2657
Epoch 10/10, Batch 30/49, Loss: 0.2145
Epoch 10/10, Batch 40/49, Loss: 0.2178
Epoch 10/10, Train Loss: 0.2129, Valid Loss: 0.2493
Model saved!
Accuracy: 0.9019
Precision: 0.8995
Recall: 0.9019
F1-score: 0.8989
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2284
Epoch 1/10, Batch 20/49, Loss: 1.0113
Epoch 1/10, Batch 30/49, Loss: 0.9609
Epoch 1/10, Batch 40/49, Loss: 0.7285
Epoch 1/10, Train Loss: 1.0063, Valid Loss: 0.6910
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6097
Epoch 2/10, Batch 20/49, Loss: 0.5187
Epoch 2/10, Batch 30/49, Loss: 0.5962
Epoch 2/10, Batch 40/49, Loss: 0.5732
Epoch 2/10, Train Loss: 0.5346, Valid Loss: 0.5138
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4297
Epoch 3/10, Batch 20/49, Loss: 0.3456
Epoch 3/10, Batch 30/49, Loss: 0.3764
Epoch 3/10, Batch 40/49, Loss: 0.5308
Epoch 3/10, Train Loss: 0.4236, Valid Loss: 0.4315
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3466
Epoch 4/10, Batch 20/49, Loss: 0.4107
Epoch 4/10, Batch 30/49, Loss: 0.2242
Epoch 4/10, Batch 40/49, Loss: 0.3840
Epoch 4/10, Train Loss: 0.3706, Valid Loss: 0.3883
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2415
Epoch 5/10, Batch 20/49, Loss: 0.2567
Epoch 5/10, Batch 30/49, Loss: 0.2504
Epoch 5/10, Batch 40/49, Loss: 0.1901
Epoch 5/10, Train Loss: 0.3034, Valid Loss: 0.3642
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2333
Epoch 6/10, Batch 20/49, Loss: 0.3076
Epoch 6/10, Batch 30/49, Loss: 0.2871
Epoch 6/10, Batch 40/49, Loss: 0.2434
Epoch 6/10, Train Loss: 0.2962, Valid Loss: 0.3412
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2486
Epoch 7/10, Batch 20/49, Loss: 0.1965
Epoch 7/10, Batch 30/49, Loss: 0.4407
Epoch 7/10, Batch 40/49, Loss: 0.2643
Epoch 7/10, Train Loss: 0.2775, Valid Loss: 0.3500
Epoch 8/10, Batch 10/49, Loss: 0.2495
Epoch 8/10, Batch 20/49, Loss: 0.3005
Epoch 8/10, Batch 30/49, Loss: 0.2601
Epoch 8/10, Batch 40/49, Loss: 0.2225
Epoch 8/10, Train Loss: 0.2634, Valid Loss: 0.3349
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1730
Epoch 9/10, Batch 20/49, Loss: 0.2454
Epoch 9/10, Batch 30/49, Loss: 0.3691
Epoch 9/10, Batch 40/49, Loss: 0.1793
Epoch 9/10, Train Loss: 0.2418, Valid Loss: 0.3204
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2019
Epoch 10/10, Batch 20/49, Loss: 0.1274
Epoch 10/10, Batch 30/49, Loss: 0.2968
Epoch 10/10, Batch 40/49, Loss: 0.2691
Epoch 10/10, Train Loss: 0.2155, Valid Loss: 0.3177
Model saved!
Accuracy: 0.9065
Precision: 0.9033
Recall: 0.9065
F1-score: 0.9033
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3026
Epoch 1/10, Batch 20/49, Loss: 1.0401
Epoch 1/10, Batch 30/49, Loss: 0.8155
Epoch 1/10, Batch 40/49, Loss: 0.6502
Epoch 1/10, Train Loss: 0.9932, Valid Loss: 0.6521
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7882
Epoch 2/10, Batch 20/49, Loss: 0.4568
Epoch 2/10, Batch 30/49, Loss: 0.4633
Epoch 2/10, Batch 40/49, Loss: 0.5266
Epoch 2/10, Train Loss: 0.5345, Valid Loss: 0.4934
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4047
Epoch 3/10, Batch 20/49, Loss: 0.3914
Epoch 3/10, Batch 30/49, Loss: 0.2817
Epoch 3/10, Batch 40/49, Loss: 0.3747
Epoch 3/10, Train Loss: 0.4143, Valid Loss: 0.4258
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2632
Epoch 4/10, Batch 20/49, Loss: 0.4339
Epoch 4/10, Batch 30/49, Loss: 0.2826
Epoch 4/10, Batch 40/49, Loss: 0.2889
Epoch 4/10, Train Loss: 0.3592, Valid Loss: 0.3717
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2886
Epoch 5/10, Batch 20/49, Loss: 0.3016
Epoch 5/10, Batch 30/49, Loss: 0.2046
Epoch 5/10, Batch 40/49, Loss: 0.3392
Epoch 5/10, Train Loss: 0.3112, Valid Loss: 0.3445
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2296
Epoch 6/10, Batch 20/49, Loss: 0.2172
Epoch 6/10, Batch 30/49, Loss: 0.3115
Epoch 6/10, Batch 40/49, Loss: 0.3081
Epoch 6/10, Train Loss: 0.2901, Valid Loss: 0.3484
Epoch 7/10, Batch 10/49, Loss: 0.2532
Epoch 7/10, Batch 20/49, Loss: 0.3117
Epoch 7/10, Batch 30/49, Loss: 0.3564
Epoch 7/10, Batch 40/49, Loss: 0.1519
Epoch 7/10, Train Loss: 0.2608, Valid Loss: 0.3392
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2960
Epoch 8/10, Batch 20/49, Loss: 0.2338
Epoch 8/10, Batch 30/49, Loss: 0.3326
Epoch 8/10, Batch 40/49, Loss: 0.2251
Epoch 8/10, Train Loss: 0.2554, Valid Loss: 0.3251
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2043
Epoch 9/10, Batch 20/49, Loss: 0.2609
Epoch 9/10, Batch 30/49, Loss: 0.4454
Epoch 9/10, Batch 40/49, Loss: 0.1897
Epoch 9/10, Train Loss: 0.2334, Valid Loss: 0.3152
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1850
Epoch 10/10, Batch 20/49, Loss: 0.1391
Epoch 10/10, Batch 30/49, Loss: 0.4101
Epoch 10/10, Batch 40/49, Loss: 0.1764
Epoch 10/10, Train Loss: 0.2093, Valid Loss: 0.3009
Model saved!
Accuracy: 0.9042
Precision: 0.9007
Recall: 0.9042
F1-score: 0.9005
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2852
Epoch 1/10, Batch 20/49, Loss: 1.0674
Epoch 1/10, Batch 30/49, Loss: 0.8443
Epoch 1/10, Batch 40/49, Loss: 0.6928
Epoch 1/10, Train Loss: 1.0005, Valid Loss: 0.6617
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7323
Epoch 2/10, Batch 20/49, Loss: 0.4990
Epoch 2/10, Batch 30/49, Loss: 0.6542
Epoch 2/10, Batch 40/49, Loss: 0.5472
Epoch 2/10, Train Loss: 0.5442, Valid Loss: 0.4949
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4796
Epoch 3/10, Batch 20/49, Loss: 0.4313
Epoch 3/10, Batch 30/49, Loss: 0.3627
Epoch 3/10, Batch 40/49, Loss: 0.3230
Epoch 3/10, Train Loss: 0.4368, Valid Loss: 0.4121
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2581
Epoch 4/10, Batch 20/49, Loss: 0.3067
Epoch 4/10, Batch 30/49, Loss: 0.2422
Epoch 4/10, Batch 40/49, Loss: 0.3246
Epoch 4/10, Train Loss: 0.3803, Valid Loss: 0.3625
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2921
Epoch 5/10, Batch 20/49, Loss: 0.2927
Epoch 5/10, Batch 30/49, Loss: 0.2069
Epoch 5/10, Batch 40/49, Loss: 0.2964
Epoch 5/10, Train Loss: 0.3112, Valid Loss: 0.3382
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2127
Epoch 6/10, Batch 20/49, Loss: 0.2655
Epoch 6/10, Batch 30/49, Loss: 0.3121
Epoch 6/10, Batch 40/49, Loss: 0.3268
Epoch 6/10, Train Loss: 0.3003, Valid Loss: 0.3276
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2162
Epoch 7/10, Batch 20/49, Loss: 0.3384
Epoch 7/10, Batch 30/49, Loss: 0.6632
Epoch 7/10, Batch 40/49, Loss: 0.2521
Epoch 7/10, Train Loss: 0.2740, Valid Loss: 0.3201
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2138
Epoch 8/10, Batch 20/49, Loss: 0.2115
Epoch 8/10, Batch 30/49, Loss: 0.3797
Epoch 8/10, Batch 40/49, Loss: 0.1896
Epoch 8/10, Train Loss: 0.2663, Valid Loss: 0.3037
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1266
Epoch 9/10, Batch 20/49, Loss: 0.1490
Epoch 9/10, Batch 30/49, Loss: 0.3585
Epoch 9/10, Batch 40/49, Loss: 0.2024
Epoch 9/10, Train Loss: 0.2556, Valid Loss: 0.2944
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1553
Epoch 10/10, Batch 20/49, Loss: 0.2577
Epoch 10/10, Batch 30/49, Loss: 0.1336
Epoch 10/10, Batch 40/49, Loss: 0.1562
Epoch 10/10, Train Loss: 0.2247, Valid Loss: 0.2876
Model saved!
Accuracy: 0.9054
Precision: 0.9021
Recall: 0.9054
F1-score: 0.9019
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3042
Epoch 1/10, Batch 20/49, Loss: 0.9466
Epoch 1/10, Batch 30/49, Loss: 0.8556
Epoch 1/10, Batch 40/49, Loss: 0.7469
Epoch 1/10, Train Loss: 1.0024, Valid Loss: 0.6450
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7427
Epoch 2/10, Batch 20/49, Loss: 0.5145
Epoch 2/10, Batch 30/49, Loss: 0.6383
Epoch 2/10, Batch 40/49, Loss: 0.5270
Epoch 2/10, Train Loss: 0.5355, Valid Loss: 0.4692
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4466
Epoch 3/10, Batch 20/49, Loss: 0.3950
Epoch 3/10, Batch 30/49, Loss: 0.4351
Epoch 3/10, Batch 40/49, Loss: 0.4585
Epoch 3/10, Train Loss: 0.4115, Valid Loss: 0.3946
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2002
Epoch 4/10, Batch 20/49, Loss: 0.4567
Epoch 4/10, Batch 30/49, Loss: 0.1935
Epoch 4/10, Batch 40/49, Loss: 0.2114
Epoch 4/10, Train Loss: 0.3576, Valid Loss: 0.3540
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2390
Epoch 5/10, Batch 20/49, Loss: 0.3421
Epoch 5/10, Batch 30/49, Loss: 0.2173
Epoch 5/10, Batch 40/49, Loss: 0.1291
Epoch 5/10, Train Loss: 0.3037, Valid Loss: 0.3225
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2040
Epoch 6/10, Batch 20/49, Loss: 0.2653
Epoch 6/10, Batch 30/49, Loss: 0.4041
Epoch 6/10, Batch 40/49, Loss: 0.3098
Epoch 6/10, Train Loss: 0.2907, Valid Loss: 0.3149
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2640
Epoch 7/10, Batch 20/49, Loss: 0.2229
Epoch 7/10, Batch 30/49, Loss: 0.2527
Epoch 7/10, Batch 40/49, Loss: 0.2857
Epoch 7/10, Train Loss: 0.2681, Valid Loss: 0.3025
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2920
Epoch 8/10, Batch 20/49, Loss: 0.2039
Epoch 8/10, Batch 30/49, Loss: 0.2173
Epoch 8/10, Batch 40/49, Loss: 0.1230
Epoch 8/10, Train Loss: 0.2408, Valid Loss: 0.2917
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1597
Epoch 9/10, Batch 20/49, Loss: 0.2145
Epoch 9/10, Batch 30/49, Loss: 0.4538
Epoch 9/10, Batch 40/49, Loss: 0.1643
Epoch 9/10, Train Loss: 0.2334, Valid Loss: 0.2823
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1564
Epoch 10/10, Batch 20/49, Loss: 0.1474
Epoch 10/10, Batch 30/49, Loss: 0.2041
Epoch 10/10, Batch 40/49, Loss: 0.3663
Epoch 10/10, Train Loss: 0.2064, Valid Loss: 0.2749
Model saved!
Accuracy: 0.9077
Precision: 0.9047
Recall: 0.9077
F1-score: 0.9051
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2898
Epoch 1/10, Batch 20/49, Loss: 1.0944
Epoch 1/10, Batch 30/49, Loss: 0.8344
Epoch 1/10, Batch 40/49, Loss: 0.7866
Epoch 1/10, Train Loss: 1.0049, Valid Loss: 0.6799
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7068
Epoch 2/10, Batch 20/49, Loss: 0.5260
Epoch 2/10, Batch 30/49, Loss: 0.5782
Epoch 2/10, Batch 40/49, Loss: 0.5345
Epoch 2/10, Train Loss: 0.5473, Valid Loss: 0.5114
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3920
Epoch 3/10, Batch 20/49, Loss: 0.4800
Epoch 3/10, Batch 30/49, Loss: 0.3512
Epoch 3/10, Batch 40/49, Loss: 0.4608
Epoch 3/10, Train Loss: 0.4329, Valid Loss: 0.4514
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3485
Epoch 4/10, Batch 20/49, Loss: 0.4829
Epoch 4/10, Batch 30/49, Loss: 0.3750
Epoch 4/10, Batch 40/49, Loss: 0.3303
Epoch 4/10, Train Loss: 0.3717, Valid Loss: 0.4134
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2142
Epoch 5/10, Batch 20/49, Loss: 0.2541
Epoch 5/10, Batch 30/49, Loss: 0.2289
Epoch 5/10, Batch 40/49, Loss: 0.3434
Epoch 5/10, Train Loss: 0.3175, Valid Loss: 0.3975
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3386
Epoch 6/10, Batch 20/49, Loss: 0.3671
Epoch 6/10, Batch 30/49, Loss: 0.2116
Epoch 6/10, Batch 40/49, Loss: 0.2072
Epoch 6/10, Train Loss: 0.2990, Valid Loss: 0.3852
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2249
Epoch 7/10, Batch 20/49, Loss: 0.1208
Epoch 7/10, Batch 30/49, Loss: 0.3155
Epoch 7/10, Batch 40/49, Loss: 0.2048
Epoch 7/10, Train Loss: 0.2789, Valid Loss: 0.3739
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2844
Epoch 8/10, Batch 20/49, Loss: 0.2799
Epoch 8/10, Batch 30/49, Loss: 0.3440
Epoch 8/10, Batch 40/49, Loss: 0.2674
Epoch 8/10, Train Loss: 0.2647, Valid Loss: 0.3589
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1788
Epoch 9/10, Batch 20/49, Loss: 0.2320
Epoch 9/10, Batch 30/49, Loss: 0.4827
Epoch 9/10, Batch 40/49, Loss: 0.1201
Epoch 9/10, Train Loss: 0.2442, Valid Loss: 0.3590
Epoch 10/10, Batch 10/49, Loss: 0.2979
Epoch 10/10, Batch 20/49, Loss: 0.1391
Epoch 10/10, Batch 30/49, Loss: 0.2952
Epoch 10/10, Batch 40/49, Loss: 0.2276
Epoch 10/10, Train Loss: 0.2195, Valid Loss: 0.3448
Model saved!
Accuracy: 0.9089
Precision: 0.9059
Recall: 0.9089
F1-score: 0.9059
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2891
Epoch 1/10, Batch 20/49, Loss: 1.1054
Epoch 1/10, Batch 30/49, Loss: 0.7667
Epoch 1/10, Batch 40/49, Loss: 0.7937
Epoch 1/10, Train Loss: 1.0078, Valid Loss: 0.6361
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6878
Epoch 2/10, Batch 20/49, Loss: 0.4750
Epoch 2/10, Batch 30/49, Loss: 0.5981
Epoch 2/10, Batch 40/49, Loss: 0.5393
Epoch 2/10, Train Loss: 0.5617, Valid Loss: 0.4801
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5555
Epoch 3/10, Batch 20/49, Loss: 0.4644
Epoch 3/10, Batch 30/49, Loss: 0.3543
Epoch 3/10, Batch 40/49, Loss: 0.4515
Epoch 3/10, Train Loss: 0.4308, Valid Loss: 0.3855
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2459
Epoch 4/10, Batch 20/49, Loss: 0.3825
Epoch 4/10, Batch 30/49, Loss: 0.2578
Epoch 4/10, Batch 40/49, Loss: 0.2704
Epoch 4/10, Train Loss: 0.3873, Valid Loss: 0.3480
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3428
Epoch 5/10, Batch 20/49, Loss: 0.2409
Epoch 5/10, Batch 30/49, Loss: 0.1993
Epoch 5/10, Batch 40/49, Loss: 0.2603
Epoch 5/10, Train Loss: 0.3273, Valid Loss: 0.3135
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2935
Epoch 6/10, Batch 20/49, Loss: 0.3607
Epoch 6/10, Batch 30/49, Loss: 0.3331
Epoch 6/10, Batch 40/49, Loss: 0.3630
Epoch 6/10, Train Loss: 0.3142, Valid Loss: 0.2950
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3724
Epoch 7/10, Batch 20/49, Loss: 0.3866
Epoch 7/10, Batch 30/49, Loss: 0.4263
Epoch 7/10, Batch 40/49, Loss: 0.1376
Epoch 7/10, Train Loss: 0.2995, Valid Loss: 0.2911
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1749
Epoch 8/10, Batch 20/49, Loss: 0.4661
Epoch 8/10, Batch 30/49, Loss: 0.2340
Epoch 8/10, Batch 40/49, Loss: 0.2260
Epoch 8/10, Train Loss: 0.2837, Valid Loss: 0.2792
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2019
Epoch 9/10, Batch 20/49, Loss: 0.3074
Epoch 9/10, Batch 30/49, Loss: 0.4485
Epoch 9/10, Batch 40/49, Loss: 0.1724
Epoch 9/10, Train Loss: 0.2495, Valid Loss: 0.2681
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3227
Epoch 10/10, Batch 20/49, Loss: 0.1521
Epoch 10/10, Batch 30/49, Loss: 0.2612
Epoch 10/10, Batch 40/49, Loss: 0.2957
Epoch 10/10, Train Loss: 0.2297, Valid Loss: 0.2671
Model saved!
Accuracy: 0.9089
Precision: 0.9067
Recall: 0.9089
F1-score: 0.9057
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2665
Epoch 1/10, Batch 20/49, Loss: 1.0318
Epoch 1/10, Batch 30/49, Loss: 0.7443
Epoch 1/10, Batch 40/49, Loss: 0.7087
Epoch 1/10, Train Loss: 1.0087, Valid Loss: 0.6665
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6943
Epoch 2/10, Batch 20/49, Loss: 0.4619
Epoch 2/10, Batch 30/49, Loss: 0.5250
Epoch 2/10, Batch 40/49, Loss: 0.4899
Epoch 2/10, Train Loss: 0.5454, Valid Loss: 0.5204
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5734
Epoch 3/10, Batch 20/49, Loss: 0.4125
Epoch 3/10, Batch 30/49, Loss: 0.4429
Epoch 3/10, Batch 40/49, Loss: 0.5043
Epoch 3/10, Train Loss: 0.4236, Valid Loss: 0.4725
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2082
Epoch 4/10, Batch 20/49, Loss: 0.3257
Epoch 4/10, Batch 30/49, Loss: 0.2670
Epoch 4/10, Batch 40/49, Loss: 0.3469
Epoch 4/10, Train Loss: 0.3683, Valid Loss: 0.4259
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3599
Epoch 5/10, Batch 20/49, Loss: 0.2665
Epoch 5/10, Batch 30/49, Loss: 0.2024
Epoch 5/10, Batch 40/49, Loss: 0.1907
Epoch 5/10, Train Loss: 0.3161, Valid Loss: 0.4209
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2366
Epoch 6/10, Batch 20/49, Loss: 0.4464
Epoch 6/10, Batch 30/49, Loss: 0.3747
Epoch 6/10, Batch 40/49, Loss: 0.4609
Epoch 6/10, Train Loss: 0.3009, Valid Loss: 0.4076
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2625
Epoch 7/10, Batch 20/49, Loss: 0.2087
Epoch 7/10, Batch 30/49, Loss: 0.3843
Epoch 7/10, Batch 40/49, Loss: 0.1883
Epoch 7/10, Train Loss: 0.2786, Valid Loss: 0.4194
Epoch 8/10, Batch 10/49, Loss: 0.2058
Epoch 8/10, Batch 20/49, Loss: 0.2410
Epoch 8/10, Batch 30/49, Loss: 0.1684
Epoch 8/10, Batch 40/49, Loss: 0.3268
Epoch 8/10, Train Loss: 0.2564, Valid Loss: 0.4012
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1472
Epoch 9/10, Batch 20/49, Loss: 0.2647
Epoch 9/10, Batch 30/49, Loss: 0.5818
Epoch 9/10, Batch 40/49, Loss: 0.2224
Epoch 9/10, Train Loss: 0.2547, Valid Loss: 0.3918
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2403
Epoch 10/10, Batch 20/49, Loss: 0.2266
Epoch 10/10, Batch 30/49, Loss: 0.2258
Epoch 10/10, Batch 40/49, Loss: 0.2720
Epoch 10/10, Train Loss: 0.2204, Valid Loss: 0.3942
Accuracy: 0.9030
Precision: 0.8982
Recall: 0.9030
F1-score: 0.8998
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2391
Epoch 1/10, Batch 20/49, Loss: 1.0496
Epoch 1/10, Batch 30/49, Loss: 0.8542
Epoch 1/10, Batch 40/49, Loss: 0.7861
Epoch 1/10, Train Loss: 1.0088, Valid Loss: 0.6296
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5530
Epoch 2/10, Batch 20/49, Loss: 0.5129
Epoch 2/10, Batch 30/49, Loss: 0.6267
Epoch 2/10, Batch 40/49, Loss: 0.4456
Epoch 2/10, Train Loss: 0.5554, Valid Loss: 0.4566
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5435
Epoch 3/10, Batch 20/49, Loss: 0.4523
Epoch 3/10, Batch 30/49, Loss: 0.4482
Epoch 3/10, Batch 40/49, Loss: 0.6060
Epoch 3/10, Train Loss: 0.4401, Valid Loss: 0.3827
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3531
Epoch 4/10, Batch 20/49, Loss: 0.4231
Epoch 4/10, Batch 30/49, Loss: 0.2716
Epoch 4/10, Batch 40/49, Loss: 0.2726
Epoch 4/10, Train Loss: 0.3694, Valid Loss: 0.3471
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3376
Epoch 5/10, Batch 20/49, Loss: 0.2165
Epoch 5/10, Batch 30/49, Loss: 0.2468
Epoch 5/10, Batch 40/49, Loss: 0.1971
Epoch 5/10, Train Loss: 0.3252, Valid Loss: 0.3124
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1689
Epoch 6/10, Batch 20/49, Loss: 0.2848
Epoch 6/10, Batch 30/49, Loss: 0.2805
Epoch 6/10, Batch 40/49, Loss: 0.2343
Epoch 6/10, Train Loss: 0.2936, Valid Loss: 0.3099
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3164
Epoch 7/10, Batch 20/49, Loss: 0.1611
Epoch 7/10, Batch 30/49, Loss: 0.4051
Epoch 7/10, Batch 40/49, Loss: 0.2278
Epoch 7/10, Train Loss: 0.2813, Valid Loss: 0.2988
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1871
Epoch 8/10, Batch 20/49, Loss: 0.3505
Epoch 8/10, Batch 30/49, Loss: 0.2248
Epoch 8/10, Batch 40/49, Loss: 0.2361
Epoch 8/10, Train Loss: 0.2631, Valid Loss: 0.2897
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2142
Epoch 9/10, Batch 20/49, Loss: 0.1514
Epoch 9/10, Batch 30/49, Loss: 0.3827
Epoch 9/10, Batch 40/49, Loss: 0.1843
Epoch 9/10, Train Loss: 0.2557, Valid Loss: 0.2845
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1387
Epoch 10/10, Batch 20/49, Loss: 0.2263
Epoch 10/10, Batch 30/49, Loss: 0.2551
Epoch 10/10, Batch 40/49, Loss: 0.2604
Epoch 10/10, Train Loss: 0.2229, Valid Loss: 0.2846
Accuracy: 0.9065
Precision: 0.9029
Recall: 0.9065
F1-score: 0.9038
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3280
Epoch 1/10, Batch 20/49, Loss: 1.0339
Epoch 1/10, Batch 30/49, Loss: 0.7532
Epoch 1/10, Batch 40/49, Loss: 0.8418
Epoch 1/10, Train Loss: 0.9940, Valid Loss: 0.6148
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6709
Epoch 2/10, Batch 20/49, Loss: 0.5014
Epoch 2/10, Batch 30/49, Loss: 0.5224
Epoch 2/10, Batch 40/49, Loss: 0.6317
Epoch 2/10, Train Loss: 0.5442, Valid Loss: 0.4336
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3574
Epoch 3/10, Batch 20/49, Loss: 0.4650
Epoch 3/10, Batch 30/49, Loss: 0.3147
Epoch 3/10, Batch 40/49, Loss: 0.3871
Epoch 3/10, Train Loss: 0.4251, Valid Loss: 0.3588
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2932
Epoch 4/10, Batch 20/49, Loss: 0.4252
Epoch 4/10, Batch 30/49, Loss: 0.3474
Epoch 4/10, Batch 40/49, Loss: 0.2575
Epoch 4/10, Train Loss: 0.3631, Valid Loss: 0.3218
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3631
Epoch 5/10, Batch 20/49, Loss: 0.3557
Epoch 5/10, Batch 30/49, Loss: 0.3546
Epoch 5/10, Batch 40/49, Loss: 0.2016
Epoch 5/10, Train Loss: 0.3134, Valid Loss: 0.2916
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2173
Epoch 6/10, Batch 20/49, Loss: 0.2983
Epoch 6/10, Batch 30/49, Loss: 0.2709
Epoch 6/10, Batch 40/49, Loss: 0.2527
Epoch 6/10, Train Loss: 0.2905, Valid Loss: 0.2783
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1769
Epoch 7/10, Batch 20/49, Loss: 0.1644
Epoch 7/10, Batch 30/49, Loss: 0.2949
Epoch 7/10, Batch 40/49, Loss: 0.1675
Epoch 7/10, Train Loss: 0.2711, Valid Loss: 0.2658
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1702
Epoch 8/10, Batch 20/49, Loss: 0.3496
Epoch 8/10, Batch 30/49, Loss: 0.1876
Epoch 8/10, Batch 40/49, Loss: 0.2220
Epoch 8/10, Train Loss: 0.2514, Valid Loss: 0.2527
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1684
Epoch 9/10, Batch 20/49, Loss: 0.3474
Epoch 9/10, Batch 30/49, Loss: 0.4061
Epoch 9/10, Batch 40/49, Loss: 0.1662
Epoch 9/10, Train Loss: 0.2436, Valid Loss: 0.2514
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1971
Epoch 10/10, Batch 20/49, Loss: 0.1335
Epoch 10/10, Batch 30/49, Loss: 0.2607
Epoch 10/10, Batch 40/49, Loss: 0.1273
Epoch 10/10, Train Loss: 0.2074, Valid Loss: 0.2455
Model saved!
Accuracy: 0.9065
Precision: 0.9042
Recall: 0.9065
F1-score: 0.9029
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2899
Epoch 1/10, Batch 20/49, Loss: 1.0153
Epoch 1/10, Batch 30/49, Loss: 0.8526
Epoch 1/10, Batch 40/49, Loss: 0.7914
Epoch 1/10, Train Loss: 0.9988, Valid Loss: 0.6730
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7184
Epoch 2/10, Batch 20/49, Loss: 0.4669
Epoch 2/10, Batch 30/49, Loss: 0.5794
Epoch 2/10, Batch 40/49, Loss: 0.6481
Epoch 2/10, Train Loss: 0.5362, Valid Loss: 0.4944
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5892
Epoch 3/10, Batch 20/49, Loss: 0.3219
Epoch 3/10, Batch 30/49, Loss: 0.3596
Epoch 3/10, Batch 40/49, Loss: 0.2634
Epoch 3/10, Train Loss: 0.4242, Valid Loss: 0.4274
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3281
Epoch 4/10, Batch 20/49, Loss: 0.4333
Epoch 4/10, Batch 30/49, Loss: 0.1935
Epoch 4/10, Batch 40/49, Loss: 0.3481
Epoch 4/10, Train Loss: 0.3683, Valid Loss: 0.3881
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2322
Epoch 5/10, Batch 20/49, Loss: 0.3433
Epoch 5/10, Batch 30/49, Loss: 0.2154
Epoch 5/10, Batch 40/49, Loss: 0.2300
Epoch 5/10, Train Loss: 0.3046, Valid Loss: 0.3591
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3218
Epoch 6/10, Batch 20/49, Loss: 0.3372
Epoch 6/10, Batch 30/49, Loss: 0.2729
Epoch 6/10, Batch 40/49, Loss: 0.2501
Epoch 6/10, Train Loss: 0.2833, Valid Loss: 0.3488
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2227
Epoch 7/10, Batch 20/49, Loss: 0.2249
Epoch 7/10, Batch 30/49, Loss: 0.3391
Epoch 7/10, Batch 40/49, Loss: 0.2050
Epoch 7/10, Train Loss: 0.2679, Valid Loss: 0.3429
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3822
Epoch 8/10, Batch 20/49, Loss: 0.2032
Epoch 8/10, Batch 30/49, Loss: 0.2358
Epoch 8/10, Batch 40/49, Loss: 0.1827
Epoch 8/10, Train Loss: 0.2513, Valid Loss: 0.3249
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2712
Epoch 9/10, Batch 20/49, Loss: 0.2451
Epoch 9/10, Batch 30/49, Loss: 0.3766
Epoch 9/10, Batch 40/49, Loss: 0.2319
Epoch 9/10, Train Loss: 0.2355, Valid Loss: 0.3173
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3153
Epoch 10/10, Batch 20/49, Loss: 0.2391
Epoch 10/10, Batch 30/49, Loss: 0.2108
Epoch 10/10, Batch 40/49, Loss: 0.2428
Epoch 10/10, Train Loss: 0.2032, Valid Loss: 0.3265
Accuracy: 0.9089
Precision: 0.9067
Recall: 0.9089
F1-score: 0.9076
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1881
Epoch 1/10, Batch 20/49, Loss: 1.0642
Epoch 1/10, Batch 30/49, Loss: 0.8905
Epoch 1/10, Batch 40/49, Loss: 0.8363
Epoch 1/10, Train Loss: 0.9935, Valid Loss: 0.6649
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7404
Epoch 2/10, Batch 20/49, Loss: 0.4912
Epoch 2/10, Batch 30/49, Loss: 0.5149
Epoch 2/10, Batch 40/49, Loss: 0.3826
Epoch 2/10, Train Loss: 0.5511, Valid Loss: 0.5021
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5769
Epoch 3/10, Batch 20/49, Loss: 0.4496
Epoch 3/10, Batch 30/49, Loss: 0.3336
Epoch 3/10, Batch 40/49, Loss: 0.3818
Epoch 3/10, Train Loss: 0.4325, Valid Loss: 0.4456
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2599
Epoch 4/10, Batch 20/49, Loss: 0.3317
Epoch 4/10, Batch 30/49, Loss: 0.3035
Epoch 4/10, Batch 40/49, Loss: 0.3286
Epoch 4/10, Train Loss: 0.3749, Valid Loss: 0.4097
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4372
Epoch 5/10, Batch 20/49, Loss: 0.2831
Epoch 5/10, Batch 30/49, Loss: 0.3155
Epoch 5/10, Batch 40/49, Loss: 0.2052
Epoch 5/10, Train Loss: 0.3221, Valid Loss: 0.3854
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3978
Epoch 6/10, Batch 20/49, Loss: 0.2836
Epoch 6/10, Batch 30/49, Loss: 0.3238
Epoch 6/10, Batch 40/49, Loss: 0.2111
Epoch 6/10, Train Loss: 0.3007, Valid Loss: 0.3659
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2899
Epoch 7/10, Batch 20/49, Loss: 0.2986
Epoch 7/10, Batch 30/49, Loss: 0.3277
Epoch 7/10, Batch 40/49, Loss: 0.4124
Epoch 7/10, Train Loss: 0.2814, Valid Loss: 0.3638
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1479
Epoch 8/10, Batch 20/49, Loss: 0.2407
Epoch 8/10, Batch 30/49, Loss: 0.1859
Epoch 8/10, Batch 40/49, Loss: 0.1806
Epoch 8/10, Train Loss: 0.2717, Valid Loss: 0.3475
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1088
Epoch 9/10, Batch 20/49, Loss: 0.3695
Epoch 9/10, Batch 30/49, Loss: 0.3100
Epoch 9/10, Batch 40/49, Loss: 0.2515
Epoch 9/10, Train Loss: 0.2526, Valid Loss: 0.3524
Epoch 10/10, Batch 10/49, Loss: 0.2413
Epoch 10/10, Batch 20/49, Loss: 0.1441
Epoch 10/10, Batch 30/49, Loss: 0.2419
Epoch 10/10, Batch 40/49, Loss: 0.1813
Epoch 10/10, Train Loss: 0.2353, Valid Loss: 0.3414
Model saved!
Accuracy: 0.9077
Precision: 0.9049
Recall: 0.9077
F1-score: 0.9057
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1972
Epoch 1/10, Batch 20/49, Loss: 0.9884
Epoch 1/10, Batch 30/49, Loss: 0.7406
Epoch 1/10, Batch 40/49, Loss: 0.7119
Epoch 1/10, Train Loss: 0.9854, Valid Loss: 0.6958
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6182
Epoch 2/10, Batch 20/49, Loss: 0.4707
Epoch 2/10, Batch 30/49, Loss: 0.5917
Epoch 2/10, Batch 40/49, Loss: 0.5091
Epoch 2/10, Train Loss: 0.5280, Valid Loss: 0.5233
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4171
Epoch 3/10, Batch 20/49, Loss: 0.3983
Epoch 3/10, Batch 30/49, Loss: 0.4353
Epoch 3/10, Batch 40/49, Loss: 0.4881
Epoch 3/10, Train Loss: 0.4075, Valid Loss: 0.4382
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2284
Epoch 4/10, Batch 20/49, Loss: 0.3514
Epoch 4/10, Batch 30/49, Loss: 0.1889
Epoch 4/10, Batch 40/49, Loss: 0.2506
Epoch 4/10, Train Loss: 0.3532, Valid Loss: 0.3845
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4868
Epoch 5/10, Batch 20/49, Loss: 0.1663
Epoch 5/10, Batch 30/49, Loss: 0.2932
Epoch 5/10, Batch 40/49, Loss: 0.2746
Epoch 5/10, Train Loss: 0.3092, Valid Loss: 0.3571
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1837
Epoch 6/10, Batch 20/49, Loss: 0.3058
Epoch 6/10, Batch 30/49, Loss: 0.3098
Epoch 6/10, Batch 40/49, Loss: 0.4081
Epoch 6/10, Train Loss: 0.2815, Valid Loss: 0.3443
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2132
Epoch 7/10, Batch 20/49, Loss: 0.3330
Epoch 7/10, Batch 30/49, Loss: 0.4332
Epoch 7/10, Batch 40/49, Loss: 0.2773
Epoch 7/10, Train Loss: 0.2617, Valid Loss: 0.3366
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2124
Epoch 8/10, Batch 20/49, Loss: 0.2553
Epoch 8/10, Batch 30/49, Loss: 0.2485
Epoch 8/10, Batch 40/49, Loss: 0.2201
Epoch 8/10, Train Loss: 0.2424, Valid Loss: 0.3209
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1476
Epoch 9/10, Batch 20/49, Loss: 0.2135
Epoch 9/10, Batch 30/49, Loss: 0.4674
Epoch 9/10, Batch 40/49, Loss: 0.2069
Epoch 9/10, Train Loss: 0.2199, Valid Loss: 0.3204
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2449
Epoch 10/10, Batch 20/49, Loss: 0.2010
Epoch 10/10, Batch 30/49, Loss: 0.3909
Epoch 10/10, Batch 40/49, Loss: 0.1449
Epoch 10/10, Train Loss: 0.2057, Valid Loss: 0.3011
Model saved!
Accuracy: 0.9100
Precision: 0.9068
Recall: 0.9100
F1-score: 0.9072
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2489
Epoch 1/10, Batch 20/49, Loss: 1.1312
Epoch 1/10, Batch 30/49, Loss: 0.8743
Epoch 1/10, Batch 40/49, Loss: 0.7807
Epoch 1/10, Train Loss: 0.9916, Valid Loss: 0.6542
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6439
Epoch 2/10, Batch 20/49, Loss: 0.4711
Epoch 2/10, Batch 30/49, Loss: 0.4261
Epoch 2/10, Batch 40/49, Loss: 0.4867
Epoch 2/10, Train Loss: 0.5293, Valid Loss: 0.5020
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4050
Epoch 3/10, Batch 20/49, Loss: 0.3191
Epoch 3/10, Batch 30/49, Loss: 0.3284
Epoch 3/10, Batch 40/49, Loss: 0.3078
Epoch 3/10, Train Loss: 0.4085, Valid Loss: 0.4372
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2388
Epoch 4/10, Batch 20/49, Loss: 0.3341
Epoch 4/10, Batch 30/49, Loss: 0.2311
Epoch 4/10, Batch 40/49, Loss: 0.3230
Epoch 4/10, Train Loss: 0.3487, Valid Loss: 0.3942
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.1825
Epoch 5/10, Batch 20/49, Loss: 0.1434
Epoch 5/10, Batch 30/49, Loss: 0.3087
Epoch 5/10, Batch 40/49, Loss: 0.2040
Epoch 5/10, Train Loss: 0.2967, Valid Loss: 0.3642
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1710
Epoch 6/10, Batch 20/49, Loss: 0.2066
Epoch 6/10, Batch 30/49, Loss: 0.3898
Epoch 6/10, Batch 40/49, Loss: 0.2620
Epoch 6/10, Train Loss: 0.2801, Valid Loss: 0.3656
Epoch 7/10, Batch 10/49, Loss: 0.3036
Epoch 7/10, Batch 20/49, Loss: 0.1260
Epoch 7/10, Batch 30/49, Loss: 0.3425
Epoch 7/10, Batch 40/49, Loss: 0.2269
Epoch 7/10, Train Loss: 0.2636, Valid Loss: 0.3671
Epoch 8/10, Batch 10/49, Loss: 0.3069
Epoch 8/10, Batch 20/49, Loss: 0.2628
Epoch 8/10, Batch 30/49, Loss: 0.2786
Epoch 8/10, Batch 40/49, Loss: 0.2128
Epoch 8/10, Train Loss: 0.2429, Valid Loss: 0.3202
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2002
Epoch 9/10, Batch 20/49, Loss: 0.2403
Epoch 9/10, Batch 30/49, Loss: 0.2773
Epoch 9/10, Batch 40/49, Loss: 0.2248
Epoch 9/10, Train Loss: 0.2262, Valid Loss: 0.3279
Epoch 10/10, Batch 10/49, Loss: 0.1851
Epoch 10/10, Batch 20/49, Loss: 0.1704
Epoch 10/10, Batch 30/49, Loss: 0.2624
Epoch 10/10, Batch 40/49, Loss: 0.2241
Epoch 10/10, Train Loss: 0.2059, Valid Loss: 0.3061
Model saved!
Accuracy: 0.9100
Precision: 0.9069
Recall: 0.9100
F1-score: 0.9078
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3255
Epoch 1/10, Batch 20/49, Loss: 1.0686
Epoch 1/10, Batch 30/49, Loss: 0.9234
Epoch 1/10, Batch 40/49, Loss: 0.7774
Epoch 1/10, Train Loss: 0.9927, Valid Loss: 0.6774
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5615
Epoch 2/10, Batch 20/49, Loss: 0.4482
Epoch 2/10, Batch 30/49, Loss: 0.5015
Epoch 2/10, Batch 40/49, Loss: 0.5811
Epoch 2/10, Train Loss: 0.5321, Valid Loss: 0.5294
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4468
Epoch 3/10, Batch 20/49, Loss: 0.4299
Epoch 3/10, Batch 30/49, Loss: 0.4232
Epoch 3/10, Batch 40/49, Loss: 0.2748
Epoch 3/10, Train Loss: 0.4136, Valid Loss: 0.4612
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3178
Epoch 4/10, Batch 20/49, Loss: 0.4055
Epoch 4/10, Batch 30/49, Loss: 0.2596
Epoch 4/10, Batch 40/49, Loss: 0.2180
Epoch 4/10, Train Loss: 0.3667, Valid Loss: 0.4246
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4354
Epoch 5/10, Batch 20/49, Loss: 0.1934
Epoch 5/10, Batch 30/49, Loss: 0.2592
Epoch 5/10, Batch 40/49, Loss: 0.3477
Epoch 5/10, Train Loss: 0.3045, Valid Loss: 0.4078
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3031
Epoch 6/10, Batch 20/49, Loss: 0.2548
Epoch 6/10, Batch 30/49, Loss: 0.3085
Epoch 6/10, Batch 40/49, Loss: 0.2442
Epoch 6/10, Train Loss: 0.2810, Valid Loss: 0.4037
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2649
Epoch 7/10, Batch 20/49, Loss: 0.1760
Epoch 7/10, Batch 30/49, Loss: 0.4944
Epoch 7/10, Batch 40/49, Loss: 0.3175
Epoch 7/10, Train Loss: 0.2714, Valid Loss: 0.4014
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2327
Epoch 8/10, Batch 20/49, Loss: 0.1690
Epoch 8/10, Batch 30/49, Loss: 0.2891
Epoch 8/10, Batch 40/49, Loss: 0.1427
Epoch 8/10, Train Loss: 0.2507, Valid Loss: 0.3916
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2072
Epoch 9/10, Batch 20/49, Loss: 0.2363
Epoch 9/10, Batch 30/49, Loss: 0.6699
Epoch 9/10, Batch 40/49, Loss: 0.2841
Epoch 9/10, Train Loss: 0.2387, Valid Loss: 0.3790
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2520
Epoch 10/10, Batch 20/49, Loss: 0.2348
Epoch 10/10, Batch 30/49, Loss: 0.3633
Epoch 10/10, Batch 40/49, Loss: 0.1927
Epoch 10/10, Train Loss: 0.2027, Valid Loss: 0.3470
Model saved!
Accuracy: 0.8984
Precision: 0.8964
Recall: 0.8984
F1-score: 0.8935
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2027
Epoch 1/10, Batch 20/49, Loss: 1.0986
Epoch 1/10, Batch 30/49, Loss: 0.9010
Epoch 1/10, Batch 40/49, Loss: 0.7980
Epoch 1/10, Train Loss: 0.9973, Valid Loss: 0.6164
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6494
Epoch 2/10, Batch 20/49, Loss: 0.5407
Epoch 2/10, Batch 30/49, Loss: 0.5784
Epoch 2/10, Batch 40/49, Loss: 0.6138
Epoch 2/10, Train Loss: 0.5320, Valid Loss: 0.4448
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4132
Epoch 3/10, Batch 20/49, Loss: 0.3013
Epoch 3/10, Batch 30/49, Loss: 0.3297
Epoch 3/10, Batch 40/49, Loss: 0.3808
Epoch 3/10, Train Loss: 0.4096, Valid Loss: 0.3680
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2840
Epoch 4/10, Batch 20/49, Loss: 0.3499
Epoch 4/10, Batch 30/49, Loss: 0.2219
Epoch 4/10, Batch 40/49, Loss: 0.1797
Epoch 4/10, Train Loss: 0.3561, Valid Loss: 0.3326
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3390
Epoch 5/10, Batch 20/49, Loss: 0.2146
Epoch 5/10, Batch 30/49, Loss: 0.1772
Epoch 5/10, Batch 40/49, Loss: 0.1988
Epoch 5/10, Train Loss: 0.2979, Valid Loss: 0.3145
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1868
Epoch 6/10, Batch 20/49, Loss: 0.2764
Epoch 6/10, Batch 30/49, Loss: 0.3636
Epoch 6/10, Batch 40/49, Loss: 0.3540
Epoch 6/10, Train Loss: 0.2828, Valid Loss: 0.3007
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3060
Epoch 7/10, Batch 20/49, Loss: 0.1834
Epoch 7/10, Batch 30/49, Loss: 0.2836
Epoch 7/10, Batch 40/49, Loss: 0.1509
Epoch 7/10, Train Loss: 0.2609, Valid Loss: 0.2938
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2487
Epoch 8/10, Batch 20/49, Loss: 0.2745
Epoch 8/10, Batch 30/49, Loss: 0.3224
Epoch 8/10, Batch 40/49, Loss: 0.2332
Epoch 8/10, Train Loss: 0.2482, Valid Loss: 0.2849
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1796
Epoch 9/10, Batch 20/49, Loss: 0.3136
Epoch 9/10, Batch 30/49, Loss: 0.3659
Epoch 9/10, Batch 40/49, Loss: 0.1200
Epoch 9/10, Train Loss: 0.2340, Valid Loss: 0.2785
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2142
Epoch 10/10, Batch 20/49, Loss: 0.1709
Epoch 10/10, Batch 30/49, Loss: 0.2219
Epoch 10/10, Batch 40/49, Loss: 0.2925
Epoch 10/10, Train Loss: 0.2131, Valid Loss: 0.2716
Model saved!
Accuracy: 0.9077
Precision: 0.9035
Recall: 0.9077
F1-score: 0.9044
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3001
Epoch 1/10, Batch 20/49, Loss: 1.0419
Epoch 1/10, Batch 30/49, Loss: 0.8848
Epoch 1/10, Batch 40/49, Loss: 0.7468
Epoch 1/10, Train Loss: 1.0047, Valid Loss: 0.6825
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.8357
Epoch 2/10, Batch 20/49, Loss: 0.5750
Epoch 2/10, Batch 30/49, Loss: 0.4915
Epoch 2/10, Batch 40/49, Loss: 0.5980
Epoch 2/10, Train Loss: 0.5304, Valid Loss: 0.4964
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3870
Epoch 3/10, Batch 20/49, Loss: 0.4912
Epoch 3/10, Batch 30/49, Loss: 0.3444
Epoch 3/10, Batch 40/49, Loss: 0.3438
Epoch 3/10, Train Loss: 0.4124, Valid Loss: 0.4363
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.1948
Epoch 4/10, Batch 20/49, Loss: 0.2948
Epoch 4/10, Batch 30/49, Loss: 0.2072
Epoch 4/10, Batch 40/49, Loss: 0.2874
Epoch 4/10, Train Loss: 0.3443, Valid Loss: 0.3947
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3183
Epoch 5/10, Batch 20/49, Loss: 0.3091
Epoch 5/10, Batch 30/49, Loss: 0.2359
Epoch 5/10, Batch 40/49, Loss: 0.2479
Epoch 5/10, Train Loss: 0.2949, Valid Loss: 0.3774
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1955
Epoch 6/10, Batch 20/49, Loss: 0.2444
Epoch 6/10, Batch 30/49, Loss: 0.3135
Epoch 6/10, Batch 40/49, Loss: 0.2152
Epoch 6/10, Train Loss: 0.2722, Valid Loss: 0.3511
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2519
Epoch 7/10, Batch 20/49, Loss: 0.3188
Epoch 7/10, Batch 30/49, Loss: 0.3184
Epoch 7/10, Batch 40/49, Loss: 0.2636
Epoch 7/10, Train Loss: 0.2557, Valid Loss: 0.3477
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2265
Epoch 8/10, Batch 20/49, Loss: 0.3046
Epoch 8/10, Batch 30/49, Loss: 0.2532
Epoch 8/10, Batch 40/49, Loss: 0.2079
Epoch 8/10, Train Loss: 0.2345, Valid Loss: 0.3390
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1366
Epoch 9/10, Batch 20/49, Loss: 0.2566
Epoch 9/10, Batch 30/49, Loss: 0.3124
Epoch 9/10, Batch 40/49, Loss: 0.2073
Epoch 9/10, Train Loss: 0.2339, Valid Loss: 0.3220
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1987
Epoch 10/10, Batch 20/49, Loss: 0.1973
Epoch 10/10, Batch 30/49, Loss: 0.2529
Epoch 10/10, Batch 40/49, Loss: 0.0981
Epoch 10/10, Train Loss: 0.2042, Valid Loss: 0.3214
Model saved!
Accuracy: 0.9124
Precision: 0.9089
Recall: 0.9124
F1-score: 0.9096
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 30. Fitness: 0.9124
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2394
Epoch 1/10, Batch 20/49, Loss: 1.0830
Epoch 1/10, Batch 30/49, Loss: 0.7995
Epoch 1/10, Batch 40/49, Loss: 0.7250
Epoch 1/10, Train Loss: 1.0060, Valid Loss: 0.6443
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6975
Epoch 2/10, Batch 20/49, Loss: 0.5280
Epoch 2/10, Batch 30/49, Loss: 0.5775
Epoch 2/10, Batch 40/49, Loss: 0.5605
Epoch 2/10, Train Loss: 0.5341, Valid Loss: 0.4664
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4070
Epoch 3/10, Batch 20/49, Loss: 0.4341
Epoch 3/10, Batch 30/49, Loss: 0.4398
Epoch 3/10, Batch 40/49, Loss: 0.2281
Epoch 3/10, Train Loss: 0.4186, Valid Loss: 0.3966
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3213
Epoch 4/10, Batch 20/49, Loss: 0.4026
Epoch 4/10, Batch 30/49, Loss: 0.2483
Epoch 4/10, Batch 40/49, Loss: 0.3454
Epoch 4/10, Train Loss: 0.3588, Valid Loss: 0.3511
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3613
Epoch 5/10, Batch 20/49, Loss: 0.2133
Epoch 5/10, Batch 30/49, Loss: 0.2261
Epoch 5/10, Batch 40/49, Loss: 0.3305
Epoch 5/10, Train Loss: 0.3143, Valid Loss: 0.3247
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2215
Epoch 6/10, Batch 20/49, Loss: 0.2899
Epoch 6/10, Batch 30/49, Loss: 0.3401
Epoch 6/10, Batch 40/49, Loss: 0.2091
Epoch 6/10, Train Loss: 0.3006, Valid Loss: 0.3129
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2697
Epoch 7/10, Batch 20/49, Loss: 0.2208
Epoch 7/10, Batch 30/49, Loss: 0.5614
Epoch 7/10, Batch 40/49, Loss: 0.2431
Epoch 7/10, Train Loss: 0.2816, Valid Loss: 0.2990
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2126
Epoch 8/10, Batch 20/49, Loss: 0.3153
Epoch 8/10, Batch 30/49, Loss: 0.2239
Epoch 8/10, Batch 40/49, Loss: 0.2522
Epoch 8/10, Train Loss: 0.2551, Valid Loss: 0.2903
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1400
Epoch 9/10, Batch 20/49, Loss: 0.1335
Epoch 9/10, Batch 30/49, Loss: 0.4622
Epoch 9/10, Batch 40/49, Loss: 0.1882
Epoch 9/10, Train Loss: 0.2343, Valid Loss: 0.2734
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1751
Epoch 10/10, Batch 20/49, Loss: 0.1118
Epoch 10/10, Batch 30/49, Loss: 0.2017
Epoch 10/10, Batch 40/49, Loss: 0.1620
Epoch 10/10, Train Loss: 0.2078, Valid Loss: 0.2713
Model saved!
Accuracy: 0.9089
Precision: 0.9057
Recall: 0.9089
F1-score: 0.9054
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2519
Epoch 1/10, Batch 20/49, Loss: 0.9814
Epoch 1/10, Batch 30/49, Loss: 0.9165
Epoch 1/10, Batch 40/49, Loss: 0.8058
Epoch 1/10, Train Loss: 1.0109, Valid Loss: 0.6837
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6828
Epoch 2/10, Batch 20/49, Loss: 0.4781
Epoch 2/10, Batch 30/49, Loss: 0.4799
Epoch 2/10, Batch 40/49, Loss: 0.6206
Epoch 2/10, Train Loss: 0.5504, Valid Loss: 0.5209
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4399
Epoch 3/10, Batch 20/49, Loss: 0.3453
Epoch 3/10, Batch 30/49, Loss: 0.3950
Epoch 3/10, Batch 40/49, Loss: 0.3689
Epoch 3/10, Train Loss: 0.4351, Valid Loss: 0.4659
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2609
Epoch 4/10, Batch 20/49, Loss: 0.3363
Epoch 4/10, Batch 30/49, Loss: 0.2811
Epoch 4/10, Batch 40/49, Loss: 0.2144
Epoch 4/10, Train Loss: 0.3777, Valid Loss: 0.3995
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3196
Epoch 5/10, Batch 20/49, Loss: 0.2700
Epoch 5/10, Batch 30/49, Loss: 0.3304
Epoch 5/10, Batch 40/49, Loss: 0.2449
Epoch 5/10, Train Loss: 0.3263, Valid Loss: 0.3958
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2586
Epoch 6/10, Batch 20/49, Loss: 0.5052
Epoch 6/10, Batch 30/49, Loss: 0.3640
Epoch 6/10, Batch 40/49, Loss: 0.4248
Epoch 6/10, Train Loss: 0.2994, Valid Loss: 0.3995
Epoch 7/10, Batch 10/49, Loss: 0.1821
Epoch 7/10, Batch 20/49, Loss: 0.2231
Epoch 7/10, Batch 30/49, Loss: 0.3553
Epoch 7/10, Batch 40/49, Loss: 0.2923
Epoch 7/10, Train Loss: 0.2837, Valid Loss: 0.3859
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2573
Epoch 8/10, Batch 20/49, Loss: 0.2998
Epoch 8/10, Batch 30/49, Loss: 0.2761
Epoch 8/10, Batch 40/49, Loss: 0.2156
Epoch 8/10, Train Loss: 0.2675, Valid Loss: 0.3555
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1796
Epoch 9/10, Batch 20/49, Loss: 0.1664
Epoch 9/10, Batch 30/49, Loss: 0.4129
Epoch 9/10, Batch 40/49, Loss: 0.1611
Epoch 9/10, Train Loss: 0.2556, Valid Loss: 0.3424
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2055
Epoch 10/10, Batch 20/49, Loss: 0.1150
Epoch 10/10, Batch 30/49, Loss: 0.2427
Epoch 10/10, Batch 40/49, Loss: 0.3833
Epoch 10/10, Train Loss: 0.2272, Valid Loss: 0.3239
Model saved!
Accuracy: 0.9042
Precision: 0.8994
Recall: 0.9042
F1-score: 0.8999
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2810
Epoch 1/10, Batch 20/49, Loss: 1.0614
Epoch 1/10, Batch 30/49, Loss: 0.8629
Epoch 1/10, Batch 40/49, Loss: 0.7990
Epoch 1/10, Train Loss: 1.0079, Valid Loss: 0.6834
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5977
Epoch 2/10, Batch 20/49, Loss: 0.4999
Epoch 2/10, Batch 30/49, Loss: 0.6928
Epoch 2/10, Batch 40/49, Loss: 0.5998
Epoch 2/10, Train Loss: 0.5332, Valid Loss: 0.4969
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4507
Epoch 3/10, Batch 20/49, Loss: 0.4084
Epoch 3/10, Batch 30/49, Loss: 0.4664
Epoch 3/10, Batch 40/49, Loss: 0.2801
Epoch 3/10, Train Loss: 0.4137, Valid Loss: 0.4425
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2551
Epoch 4/10, Batch 20/49, Loss: 0.3499
Epoch 4/10, Batch 30/49, Loss: 0.2367
Epoch 4/10, Batch 40/49, Loss: 0.1910
Epoch 4/10, Train Loss: 0.3526, Valid Loss: 0.3769
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2158
Epoch 5/10, Batch 20/49, Loss: 0.2042
Epoch 5/10, Batch 30/49, Loss: 0.2134
Epoch 5/10, Batch 40/49, Loss: 0.1410
Epoch 5/10, Train Loss: 0.2985, Valid Loss: 0.3505
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2036
Epoch 6/10, Batch 20/49, Loss: 0.3369
Epoch 6/10, Batch 30/49, Loss: 0.3876
Epoch 6/10, Batch 40/49, Loss: 0.2472
Epoch 6/10, Train Loss: 0.2736, Valid Loss: 0.3417
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3860
Epoch 7/10, Batch 20/49, Loss: 0.1991
Epoch 7/10, Batch 30/49, Loss: 0.3727
Epoch 7/10, Batch 40/49, Loss: 0.2477
Epoch 7/10, Train Loss: 0.2693, Valid Loss: 0.3435
Epoch 8/10, Batch 10/49, Loss: 0.2458
Epoch 8/10, Batch 20/49, Loss: 0.1761
Epoch 8/10, Batch 30/49, Loss: 0.3364
Epoch 8/10, Batch 40/49, Loss: 0.3587
Epoch 8/10, Train Loss: 0.2489, Valid Loss: 0.3158
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.0972
Epoch 9/10, Batch 20/49, Loss: 0.2013
Epoch 9/10, Batch 30/49, Loss: 0.3888
Epoch 9/10, Batch 40/49, Loss: 0.2354
Epoch 9/10, Train Loss: 0.2352, Valid Loss: 0.3095
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1626
Epoch 10/10, Batch 20/49, Loss: 0.1525
Epoch 10/10, Batch 30/49, Loss: 0.2858
Epoch 10/10, Batch 40/49, Loss: 0.1607
Epoch 10/10, Train Loss: 0.2065, Valid Loss: 0.3052
Model saved!
Accuracy: 0.9019
Precision: 0.8996
Recall: 0.9019
F1-score: 0.8995
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2826
Epoch 1/10, Batch 20/49, Loss: 1.0467
Epoch 1/10, Batch 30/49, Loss: 0.9032
Epoch 1/10, Batch 40/49, Loss: 0.7852
Epoch 1/10, Train Loss: 0.9958, Valid Loss: 0.6476
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6972
Epoch 2/10, Batch 20/49, Loss: 0.4338
Epoch 2/10, Batch 30/49, Loss: 0.4556
Epoch 2/10, Batch 40/49, Loss: 0.4729
Epoch 2/10, Train Loss: 0.5304, Valid Loss: 0.4640
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5092
Epoch 3/10, Batch 20/49, Loss: 0.3680
Epoch 3/10, Batch 30/49, Loss: 0.3568
Epoch 3/10, Batch 40/49, Loss: 0.4823
Epoch 3/10, Train Loss: 0.4101, Valid Loss: 0.3868
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2341
Epoch 4/10, Batch 20/49, Loss: 0.3510
Epoch 4/10, Batch 30/49, Loss: 0.1736
Epoch 4/10, Batch 40/49, Loss: 0.2711
Epoch 4/10, Train Loss: 0.3545, Valid Loss: 0.3283
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3153
Epoch 5/10, Batch 20/49, Loss: 0.2790
Epoch 5/10, Batch 30/49, Loss: 0.2186
Epoch 5/10, Batch 40/49, Loss: 0.2218
Epoch 5/10, Train Loss: 0.2981, Valid Loss: 0.3050
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2028
Epoch 6/10, Batch 20/49, Loss: 0.2440
Epoch 6/10, Batch 30/49, Loss: 0.4276
Epoch 6/10, Batch 40/49, Loss: 0.2992
Epoch 6/10, Train Loss: 0.2844, Valid Loss: 0.2950
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2812
Epoch 7/10, Batch 20/49, Loss: 0.1670
Epoch 7/10, Batch 30/49, Loss: 0.3473
Epoch 7/10, Batch 40/49, Loss: 0.2320
Epoch 7/10, Train Loss: 0.2595, Valid Loss: 0.2881
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1588
Epoch 8/10, Batch 20/49, Loss: 0.2532
Epoch 8/10, Batch 30/49, Loss: 0.2899
Epoch 8/10, Batch 40/49, Loss: 0.1410
Epoch 8/10, Train Loss: 0.2480, Valid Loss: 0.2649
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2133
Epoch 9/10, Batch 20/49, Loss: 0.1716
Epoch 9/10, Batch 30/49, Loss: 0.5383
Epoch 9/10, Batch 40/49, Loss: 0.1532
Epoch 9/10, Train Loss: 0.2309, Valid Loss: 0.2545
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1503
Epoch 10/10, Batch 20/49, Loss: 0.1984
Epoch 10/10, Batch 30/49, Loss: 0.3804
Epoch 10/10, Batch 40/49, Loss: 0.1968
Epoch 10/10, Train Loss: 0.2037, Valid Loss: 0.2422
Model saved!
Accuracy: 0.9042
Precision: 0.9006
Recall: 0.9042
F1-score: 0.9019
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2865
Epoch 1/10, Batch 20/49, Loss: 1.0481
Epoch 1/10, Batch 30/49, Loss: 0.8721
Epoch 1/10, Batch 40/49, Loss: 0.6824
Epoch 1/10, Train Loss: 0.9925, Valid Loss: 0.6368
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6728
Epoch 2/10, Batch 20/49, Loss: 0.3786
Epoch 2/10, Batch 30/49, Loss: 0.5859
Epoch 2/10, Batch 40/49, Loss: 0.5501
Epoch 2/10, Train Loss: 0.5319, Valid Loss: 0.4498
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4379
Epoch 3/10, Batch 20/49, Loss: 0.3327
Epoch 3/10, Batch 30/49, Loss: 0.4017
Epoch 3/10, Batch 40/49, Loss: 0.4278
Epoch 3/10, Train Loss: 0.4085, Valid Loss: 0.3798
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3315
Epoch 4/10, Batch 20/49, Loss: 0.3162
Epoch 4/10, Batch 30/49, Loss: 0.2314
Epoch 4/10, Batch 40/49, Loss: 0.1789
Epoch 4/10, Train Loss: 0.3534, Valid Loss: 0.3227
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3288
Epoch 5/10, Batch 20/49, Loss: 0.2392
Epoch 5/10, Batch 30/49, Loss: 0.2431
Epoch 5/10, Batch 40/49, Loss: 0.2782
Epoch 5/10, Train Loss: 0.2899, Valid Loss: 0.2959
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1827
Epoch 6/10, Batch 20/49, Loss: 0.3835
Epoch 6/10, Batch 30/49, Loss: 0.3095
Epoch 6/10, Batch 40/49, Loss: 0.2456
Epoch 6/10, Train Loss: 0.2757, Valid Loss: 0.2897
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1814
Epoch 7/10, Batch 20/49, Loss: 0.2692
Epoch 7/10, Batch 30/49, Loss: 0.4135
Epoch 7/10, Batch 40/49, Loss: 0.1942
Epoch 7/10, Train Loss: 0.2510, Valid Loss: 0.2858
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1607
Epoch 8/10, Batch 20/49, Loss: 0.2828
Epoch 8/10, Batch 30/49, Loss: 0.2388
Epoch 8/10, Batch 40/49, Loss: 0.1054
Epoch 8/10, Train Loss: 0.2443, Valid Loss: 0.2665
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1399
Epoch 9/10, Batch 20/49, Loss: 0.2934
Epoch 9/10, Batch 30/49, Loss: 0.4744
Epoch 9/10, Batch 40/49, Loss: 0.1099
Epoch 9/10, Train Loss: 0.2340, Valid Loss: 0.2559
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1331
Epoch 10/10, Batch 20/49, Loss: 0.1385
Epoch 10/10, Batch 30/49, Loss: 0.3493
Epoch 10/10, Batch 40/49, Loss: 0.2920
Epoch 10/10, Train Loss: 0.2070, Valid Loss: 0.2419
Model saved!
Accuracy: 0.9065
Precision: 0.9029
Recall: 0.9065
F1-score: 0.9022
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2768
Epoch 1/10, Batch 20/49, Loss: 1.1584
Epoch 1/10, Batch 30/49, Loss: 0.8338
Epoch 1/10, Batch 40/49, Loss: 0.8054
Epoch 1/10, Train Loss: 1.0192, Valid Loss: 0.6770
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7714
Epoch 2/10, Batch 20/49, Loss: 0.4544
Epoch 2/10, Batch 30/49, Loss: 0.6890
Epoch 2/10, Batch 40/49, Loss: 0.6113
Epoch 2/10, Train Loss: 0.5502, Valid Loss: 0.5027
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3080
Epoch 3/10, Batch 20/49, Loss: 0.5734
Epoch 3/10, Batch 30/49, Loss: 0.3912
Epoch 3/10, Batch 40/49, Loss: 0.3805
Epoch 3/10, Train Loss: 0.4348, Valid Loss: 0.4332
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2613
Epoch 4/10, Batch 20/49, Loss: 0.3377
Epoch 4/10, Batch 30/49, Loss: 0.2671
Epoch 4/10, Batch 40/49, Loss: 0.2696
Epoch 4/10, Train Loss: 0.3672, Valid Loss: 0.3711
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3953
Epoch 5/10, Batch 20/49, Loss: 0.3418
Epoch 5/10, Batch 30/49, Loss: 0.2153
Epoch 5/10, Batch 40/49, Loss: 0.2279
Epoch 5/10, Train Loss: 0.3178, Valid Loss: 0.3662
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1961
Epoch 6/10, Batch 20/49, Loss: 0.1430
Epoch 6/10, Batch 30/49, Loss: 0.3060
Epoch 6/10, Batch 40/49, Loss: 0.1314
Epoch 6/10, Train Loss: 0.2977, Valid Loss: 0.3512
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2574
Epoch 7/10, Batch 20/49, Loss: 0.3482
Epoch 7/10, Batch 30/49, Loss: 0.2397
Epoch 7/10, Batch 40/49, Loss: 0.2084
Epoch 7/10, Train Loss: 0.2717, Valid Loss: 0.3451
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3497
Epoch 8/10, Batch 20/49, Loss: 0.2519
Epoch 8/10, Batch 30/49, Loss: 0.2228
Epoch 8/10, Batch 40/49, Loss: 0.1457
Epoch 8/10, Train Loss: 0.2523, Valid Loss: 0.3371
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2048
Epoch 9/10, Batch 20/49, Loss: 0.4282
Epoch 9/10, Batch 30/49, Loss: 0.5145
Epoch 9/10, Batch 40/49, Loss: 0.1629
Epoch 9/10, Train Loss: 0.2419, Valid Loss: 0.3388
Epoch 10/10, Batch 10/49, Loss: 0.0981
Epoch 10/10, Batch 20/49, Loss: 0.1890
Epoch 10/10, Batch 30/49, Loss: 0.2307
Epoch 10/10, Batch 40/49, Loss: 0.1495
Epoch 10/10, Train Loss: 0.2203, Valid Loss: 0.3124
Model saved!
Accuracy: 0.9089
Precision: 0.9053
Recall: 0.9089
F1-score: 0.9051
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2018
Epoch 1/10, Batch 20/49, Loss: 1.0270
Epoch 1/10, Batch 30/49, Loss: 0.7366
Epoch 1/10, Batch 40/49, Loss: 0.9430
Epoch 1/10, Train Loss: 0.9822, Valid Loss: 0.6209
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7376
Epoch 2/10, Batch 20/49, Loss: 0.3921
Epoch 2/10, Batch 30/49, Loss: 0.4872
Epoch 2/10, Batch 40/49, Loss: 0.5040
Epoch 2/10, Train Loss: 0.5356, Valid Loss: 0.4373
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5094
Epoch 3/10, Batch 20/49, Loss: 0.4169
Epoch 3/10, Batch 30/49, Loss: 0.3163
Epoch 3/10, Batch 40/49, Loss: 0.3263
Epoch 3/10, Train Loss: 0.4057, Valid Loss: 0.3639
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2648
Epoch 4/10, Batch 20/49, Loss: 0.3707
Epoch 4/10, Batch 30/49, Loss: 0.3470
Epoch 4/10, Batch 40/49, Loss: 0.3517
Epoch 4/10, Train Loss: 0.3604, Valid Loss: 0.3110
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2970
Epoch 5/10, Batch 20/49, Loss: 0.1826
Epoch 5/10, Batch 30/49, Loss: 0.3087
Epoch 5/10, Batch 40/49, Loss: 0.1586
Epoch 5/10, Train Loss: 0.3054, Valid Loss: 0.2918
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2184
Epoch 6/10, Batch 20/49, Loss: 0.1872
Epoch 6/10, Batch 30/49, Loss: 0.2477
Epoch 6/10, Batch 40/49, Loss: 0.2396
Epoch 6/10, Train Loss: 0.2836, Valid Loss: 0.2824
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2374
Epoch 7/10, Batch 20/49, Loss: 0.2261
Epoch 7/10, Batch 30/49, Loss: 0.3229
Epoch 7/10, Batch 40/49, Loss: 0.3233
Epoch 7/10, Train Loss: 0.2659, Valid Loss: 0.2712
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2062
Epoch 8/10, Batch 20/49, Loss: 0.2917
Epoch 8/10, Batch 30/49, Loss: 0.2746
Epoch 8/10, Batch 40/49, Loss: 0.2231
Epoch 8/10, Train Loss: 0.2470, Valid Loss: 0.2594
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1382
Epoch 9/10, Batch 20/49, Loss: 0.2210
Epoch 9/10, Batch 30/49, Loss: 0.5535
Epoch 9/10, Batch 40/49, Loss: 0.1154
Epoch 9/10, Train Loss: 0.2413, Valid Loss: 0.2519
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1873
Epoch 10/10, Batch 20/49, Loss: 0.1005
Epoch 10/10, Batch 30/49, Loss: 0.1799
Epoch 10/10, Batch 40/49, Loss: 0.2175
Epoch 10/10, Train Loss: 0.2086, Valid Loss: 0.2458
Model saved!
Accuracy: 0.9171
Precision: 0.9143
Recall: 0.9171
F1-score: 0.9144
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 37. Fitness: 0.9171
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2637
Epoch 1/10, Batch 20/49, Loss: 1.0112
Epoch 1/10, Batch 30/49, Loss: 0.8741
Epoch 1/10, Batch 40/49, Loss: 0.6857
Epoch 1/10, Train Loss: 0.9824, Valid Loss: 0.6176
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6266
Epoch 2/10, Batch 20/49, Loss: 0.4211
Epoch 2/10, Batch 30/49, Loss: 0.5632
Epoch 2/10, Batch 40/49, Loss: 0.4242
Epoch 2/10, Train Loss: 0.5271, Valid Loss: 0.4449
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4148
Epoch 3/10, Batch 20/49, Loss: 0.3748
Epoch 3/10, Batch 30/49, Loss: 0.3795
Epoch 3/10, Batch 40/49, Loss: 0.2940
Epoch 3/10, Train Loss: 0.4019, Valid Loss: 0.3781
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2579
Epoch 4/10, Batch 20/49, Loss: 0.3726
Epoch 4/10, Batch 30/49, Loss: 0.3015
Epoch 4/10, Batch 40/49, Loss: 0.3011
Epoch 4/10, Train Loss: 0.3353, Valid Loss: 0.3298
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2221
Epoch 5/10, Batch 20/49, Loss: 0.3303
Epoch 5/10, Batch 30/49, Loss: 0.2103
Epoch 5/10, Batch 40/49, Loss: 0.3531
Epoch 5/10, Train Loss: 0.2946, Valid Loss: 0.3094
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1523
Epoch 6/10, Batch 20/49, Loss: 0.2118
Epoch 6/10, Batch 30/49, Loss: 0.4046
Epoch 6/10, Batch 40/49, Loss: 0.2690
Epoch 6/10, Train Loss: 0.2666, Valid Loss: 0.2911
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2875
Epoch 7/10, Batch 20/49, Loss: 0.1836
Epoch 7/10, Batch 30/49, Loss: 0.2812
Epoch 7/10, Batch 40/49, Loss: 0.2660
Epoch 7/10, Train Loss: 0.2384, Valid Loss: 0.2872
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3292
Epoch 8/10, Batch 20/49, Loss: 0.2574
Epoch 8/10, Batch 30/49, Loss: 0.2670
Epoch 8/10, Batch 40/49, Loss: 0.1206
Epoch 8/10, Train Loss: 0.2348, Valid Loss: 0.2720
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2035
Epoch 9/10, Batch 20/49, Loss: 0.1904
Epoch 9/10, Batch 30/49, Loss: 0.3511
Epoch 9/10, Batch 40/49, Loss: 0.2270
Epoch 9/10, Train Loss: 0.2163, Valid Loss: 0.2683
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2725
Epoch 10/10, Batch 20/49, Loss: 0.1555
Epoch 10/10, Batch 30/49, Loss: 0.3648
Epoch 10/10, Batch 40/49, Loss: 0.1402
Epoch 10/10, Train Loss: 0.1956, Valid Loss: 0.2596
Model saved!
Accuracy: 0.8995
Precision: 0.8955
Recall: 0.8995
F1-score: 0.8960
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2766
Epoch 1/10, Batch 20/49, Loss: 1.0501
Epoch 1/10, Batch 30/49, Loss: 0.7692
Epoch 1/10, Batch 40/49, Loss: 0.7405
Epoch 1/10, Train Loss: 0.9853, Valid Loss: 0.6276
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5499
Epoch 2/10, Batch 20/49, Loss: 0.4702
Epoch 2/10, Batch 30/49, Loss: 0.5225
Epoch 2/10, Batch 40/49, Loss: 0.5449
Epoch 2/10, Train Loss: 0.5190, Valid Loss: 0.4476
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3634
Epoch 3/10, Batch 20/49, Loss: 0.4269
Epoch 3/10, Batch 30/49, Loss: 0.4251
Epoch 3/10, Batch 40/49, Loss: 0.3542
Epoch 3/10, Train Loss: 0.3950, Valid Loss: 0.3839
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3384
Epoch 4/10, Batch 20/49, Loss: 0.4062
Epoch 4/10, Batch 30/49, Loss: 0.2800
Epoch 4/10, Batch 40/49, Loss: 0.2441
Epoch 4/10, Train Loss: 0.3362, Valid Loss: 0.3219
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3833
Epoch 5/10, Batch 20/49, Loss: 0.2910
Epoch 5/10, Batch 30/49, Loss: 0.2745
Epoch 5/10, Batch 40/49, Loss: 0.3159
Epoch 5/10, Train Loss: 0.2884, Valid Loss: 0.2895
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1617
Epoch 6/10, Batch 20/49, Loss: 0.2809
Epoch 6/10, Batch 30/49, Loss: 0.3564
Epoch 6/10, Batch 40/49, Loss: 0.2724
Epoch 6/10, Train Loss: 0.2624, Valid Loss: 0.2830
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2777
Epoch 7/10, Batch 20/49, Loss: 0.1608
Epoch 7/10, Batch 30/49, Loss: 0.2421
Epoch 7/10, Batch 40/49, Loss: 0.1535
Epoch 7/10, Train Loss: 0.2348, Valid Loss: 0.2658
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2563
Epoch 8/10, Batch 20/49, Loss: 0.1620
Epoch 8/10, Batch 30/49, Loss: 0.3393
Epoch 8/10, Batch 40/49, Loss: 0.1933
Epoch 8/10, Train Loss: 0.2352, Valid Loss: 0.2528
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1162
Epoch 9/10, Batch 20/49, Loss: 0.1636
Epoch 9/10, Batch 30/49, Loss: 0.6819
Epoch 9/10, Batch 40/49, Loss: 0.1878
Epoch 9/10, Train Loss: 0.2133, Valid Loss: 0.2408
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1944
Epoch 10/10, Batch 20/49, Loss: 0.1216
Epoch 10/10, Batch 30/49, Loss: 0.2196
Epoch 10/10, Batch 40/49, Loss: 0.2164
Epoch 10/10, Train Loss: 0.1942, Valid Loss: 0.2285
Model saved!
Accuracy: 0.9054
Precision: 0.9031
Recall: 0.9054
F1-score: 0.9005
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3330
Epoch 1/10, Batch 20/49, Loss: 1.0815
Epoch 1/10, Batch 30/49, Loss: 0.8874
Epoch 1/10, Batch 40/49, Loss: 0.6946
Epoch 1/10, Train Loss: 0.9978, Valid Loss: 0.6752
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6980
Epoch 2/10, Batch 20/49, Loss: 0.4044
Epoch 2/10, Batch 30/49, Loss: 0.6054
Epoch 2/10, Batch 40/49, Loss: 0.5078
Epoch 2/10, Train Loss: 0.5339, Valid Loss: 0.5251
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4291
Epoch 3/10, Batch 20/49, Loss: 0.3408
Epoch 3/10, Batch 30/49, Loss: 0.4392
Epoch 3/10, Batch 40/49, Loss: 0.4470
Epoch 3/10, Train Loss: 0.4123, Valid Loss: 0.4736
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2590
Epoch 4/10, Batch 20/49, Loss: 0.3888
Epoch 4/10, Batch 30/49, Loss: 0.2390
Epoch 4/10, Batch 40/49, Loss: 0.2921
Epoch 4/10, Train Loss: 0.3567, Valid Loss: 0.4089
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2592
Epoch 5/10, Batch 20/49, Loss: 0.1340
Epoch 5/10, Batch 30/49, Loss: 0.3860
Epoch 5/10, Batch 40/49, Loss: 0.2689
Epoch 5/10, Train Loss: 0.2970, Valid Loss: 0.3968
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1783
Epoch 6/10, Batch 20/49, Loss: 0.3567
Epoch 6/10, Batch 30/49, Loss: 0.3353
Epoch 6/10, Batch 40/49, Loss: 0.2235
Epoch 6/10, Train Loss: 0.2768, Valid Loss: 0.4050
Epoch 7/10, Batch 10/49, Loss: 0.1962
Epoch 7/10, Batch 20/49, Loss: 0.1410
Epoch 7/10, Batch 30/49, Loss: 0.3918
Epoch 7/10, Batch 40/49, Loss: 0.1935
Epoch 7/10, Train Loss: 0.2580, Valid Loss: 0.3804
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1928
Epoch 8/10, Batch 20/49, Loss: 0.3224
Epoch 8/10, Batch 30/49, Loss: 0.2699
Epoch 8/10, Batch 40/49, Loss: 0.1842
Epoch 8/10, Train Loss: 0.2427, Valid Loss: 0.3786
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1493
Epoch 9/10, Batch 20/49, Loss: 0.3331
Epoch 9/10, Batch 30/49, Loss: 0.5254
Epoch 9/10, Batch 40/49, Loss: 0.1887
Epoch 9/10, Train Loss: 0.2360, Valid Loss: 0.3695
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2848
Epoch 10/10, Batch 20/49, Loss: 0.1527
Epoch 10/10, Batch 30/49, Loss: 0.1933
Epoch 10/10, Batch 40/49, Loss: 0.2424
Epoch 10/10, Train Loss: 0.2085, Valid Loss: 0.3559
Model saved!
Accuracy: 0.8995
Precision: 0.8953
Recall: 0.8995
F1-score: 0.8952
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2738
Epoch 1/10, Batch 20/49, Loss: 1.0210
Epoch 1/10, Batch 30/49, Loss: 0.8213
Epoch 1/10, Batch 40/49, Loss: 0.7686
Epoch 1/10, Train Loss: 1.0033, Valid Loss: 0.6104
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6205
Epoch 2/10, Batch 20/49, Loss: 0.5696
Epoch 2/10, Batch 30/49, Loss: 0.5823
Epoch 2/10, Batch 40/49, Loss: 0.4795
Epoch 2/10, Train Loss: 0.5516, Valid Loss: 0.4324
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4269
Epoch 3/10, Batch 20/49, Loss: 0.4588
Epoch 3/10, Batch 30/49, Loss: 0.4123
Epoch 3/10, Batch 40/49, Loss: 0.3411
Epoch 3/10, Train Loss: 0.4230, Valid Loss: 0.3555
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2591
Epoch 4/10, Batch 20/49, Loss: 0.4869
Epoch 4/10, Batch 30/49, Loss: 0.3191
Epoch 4/10, Batch 40/49, Loss: 0.2681
Epoch 4/10, Train Loss: 0.3845, Valid Loss: 0.3101
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2387
Epoch 5/10, Batch 20/49, Loss: 0.1781
Epoch 5/10, Batch 30/49, Loss: 0.2175
Epoch 5/10, Batch 40/49, Loss: 0.2833
Epoch 5/10, Train Loss: 0.3267, Valid Loss: 0.2884
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1969
Epoch 6/10, Batch 20/49, Loss: 0.3353
Epoch 6/10, Batch 30/49, Loss: 0.2310
Epoch 6/10, Batch 40/49, Loss: 0.1961
Epoch 6/10, Train Loss: 0.2983, Valid Loss: 0.2719
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2127
Epoch 7/10, Batch 20/49, Loss: 0.2324
Epoch 7/10, Batch 30/49, Loss: 0.3611
Epoch 7/10, Batch 40/49, Loss: 0.1122
Epoch 7/10, Train Loss: 0.2818, Valid Loss: 0.2662
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2951
Epoch 8/10, Batch 20/49, Loss: 0.2371
Epoch 8/10, Batch 30/49, Loss: 0.2160
Epoch 8/10, Batch 40/49, Loss: 0.1940
Epoch 8/10, Train Loss: 0.2736, Valid Loss: 0.2464
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2316
Epoch 9/10, Batch 20/49, Loss: 0.1739
Epoch 9/10, Batch 30/49, Loss: 0.6289
Epoch 9/10, Batch 40/49, Loss: 0.2844
Epoch 9/10, Train Loss: 0.2587, Valid Loss: 0.2406
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2208
Epoch 10/10, Batch 20/49, Loss: 0.1801
Epoch 10/10, Batch 30/49, Loss: 0.3093
Epoch 10/10, Batch 40/49, Loss: 0.2506
Epoch 10/10, Train Loss: 0.2223, Valid Loss: 0.2306
Model saved!
Accuracy: 0.8949
Precision: 0.8904
Recall: 0.8949
F1-score: 0.8916
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2149
Epoch 1/10, Batch 20/49, Loss: 0.9827
Epoch 1/10, Batch 30/49, Loss: 0.7978
Epoch 1/10, Batch 40/49, Loss: 0.8240
Epoch 1/10, Train Loss: 0.9804, Valid Loss: 0.6388
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6936
Epoch 2/10, Batch 20/49, Loss: 0.4009
Epoch 2/10, Batch 30/49, Loss: 0.5232
Epoch 2/10, Batch 40/49, Loss: 0.5530
Epoch 2/10, Train Loss: 0.5254, Valid Loss: 0.4700
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3652
Epoch 3/10, Batch 20/49, Loss: 0.4757
Epoch 3/10, Batch 30/49, Loss: 0.4455
Epoch 3/10, Batch 40/49, Loss: 0.3529
Epoch 3/10, Train Loss: 0.4047, Valid Loss: 0.3798
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2143
Epoch 4/10, Batch 20/49, Loss: 0.3660
Epoch 4/10, Batch 30/49, Loss: 0.2218
Epoch 4/10, Batch 40/49, Loss: 0.3886
Epoch 4/10, Train Loss: 0.3565, Valid Loss: 0.3247
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2943
Epoch 5/10, Batch 20/49, Loss: 0.2161
Epoch 5/10, Batch 30/49, Loss: 0.2517
Epoch 5/10, Batch 40/49, Loss: 0.2055
Epoch 5/10, Train Loss: 0.2929, Valid Loss: 0.2944
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2867
Epoch 6/10, Batch 20/49, Loss: 0.2502
Epoch 6/10, Batch 30/49, Loss: 0.3851
Epoch 6/10, Batch 40/49, Loss: 0.2672
Epoch 6/10, Train Loss: 0.2830, Valid Loss: 0.2829
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2279
Epoch 7/10, Batch 20/49, Loss: 0.3349
Epoch 7/10, Batch 30/49, Loss: 0.2508
Epoch 7/10, Batch 40/49, Loss: 0.1382
Epoch 7/10, Train Loss: 0.2562, Valid Loss: 0.2941
Epoch 8/10, Batch 10/49, Loss: 0.2237
Epoch 8/10, Batch 20/49, Loss: 0.2803
Epoch 8/10, Batch 30/49, Loss: 0.2475
Epoch 8/10, Batch 40/49, Loss: 0.3394
Epoch 8/10, Train Loss: 0.2474, Valid Loss: 0.2632
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2371
Epoch 9/10, Batch 20/49, Loss: 0.1290
Epoch 9/10, Batch 30/49, Loss: 0.5365
Epoch 9/10, Batch 40/49, Loss: 0.2104
Epoch 9/10, Train Loss: 0.2293, Valid Loss: 0.2485
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2280
Epoch 10/10, Batch 20/49, Loss: 0.1230
Epoch 10/10, Batch 30/49, Loss: 0.1667
Epoch 10/10, Batch 40/49, Loss: 0.2214
Epoch 10/10, Train Loss: 0.2098, Valid Loss: 0.2280
Model saved!
Accuracy: 0.9030
Precision: 0.8998
Recall: 0.9030
F1-score: 0.8992
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2134
Epoch 1/10, Batch 20/49, Loss: 1.0678
Epoch 1/10, Batch 30/49, Loss: 0.8389
Epoch 1/10, Batch 40/49, Loss: 0.7195
Epoch 1/10, Train Loss: 0.9899, Valid Loss: 0.6518
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6273
Epoch 2/10, Batch 20/49, Loss: 0.4864
Epoch 2/10, Batch 30/49, Loss: 0.4679
Epoch 2/10, Batch 40/49, Loss: 0.5218
Epoch 2/10, Train Loss: 0.5269, Valid Loss: 0.4948
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4174
Epoch 3/10, Batch 20/49, Loss: 0.4746
Epoch 3/10, Batch 30/49, Loss: 0.4995
Epoch 3/10, Batch 40/49, Loss: 0.3035
Epoch 3/10, Train Loss: 0.4124, Valid Loss: 0.4242
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2971
Epoch 4/10, Batch 20/49, Loss: 0.4293
Epoch 4/10, Batch 30/49, Loss: 0.2442
Epoch 4/10, Batch 40/49, Loss: 0.2721
Epoch 4/10, Train Loss: 0.3610, Valid Loss: 0.3938
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.1624
Epoch 5/10, Batch 20/49, Loss: 0.2457
Epoch 5/10, Batch 30/49, Loss: 0.2248
Epoch 5/10, Batch 40/49, Loss: 0.2541
Epoch 5/10, Train Loss: 0.2996, Valid Loss: 0.3504
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2170
Epoch 6/10, Batch 20/49, Loss: 0.2443
Epoch 6/10, Batch 30/49, Loss: 0.3033
Epoch 6/10, Batch 40/49, Loss: 0.2045
Epoch 6/10, Train Loss: 0.2863, Valid Loss: 0.3515
Epoch 7/10, Batch 10/49, Loss: 0.2510
Epoch 7/10, Batch 20/49, Loss: 0.2454
Epoch 7/10, Batch 30/49, Loss: 0.3150
Epoch 7/10, Batch 40/49, Loss: 0.1761
Epoch 7/10, Train Loss: 0.2545, Valid Loss: 0.3343
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2030
Epoch 8/10, Batch 20/49, Loss: 0.2036
Epoch 8/10, Batch 30/49, Loss: 0.1713
Epoch 8/10, Batch 40/49, Loss: 0.1795
Epoch 8/10, Train Loss: 0.2506, Valid Loss: 0.3319
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.0956
Epoch 9/10, Batch 20/49, Loss: 0.4286
Epoch 9/10, Batch 30/49, Loss: 0.6086
Epoch 9/10, Batch 40/49, Loss: 0.2207
Epoch 9/10, Train Loss: 0.2320, Valid Loss: 0.3074
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1732
Epoch 10/10, Batch 20/49, Loss: 0.1421
Epoch 10/10, Batch 30/49, Loss: 0.2363
Epoch 10/10, Batch 40/49, Loss: 0.1390
Epoch 10/10, Train Loss: 0.2141, Valid Loss: 0.3100
Accuracy: 0.9042
Precision: 0.9009
Recall: 0.9042
F1-score: 0.9006
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2305
Epoch 1/10, Batch 20/49, Loss: 1.0288
Epoch 1/10, Batch 30/49, Loss: 0.8270
Epoch 1/10, Batch 40/49, Loss: 0.7745
Epoch 1/10, Train Loss: 0.9939, Valid Loss: 0.6865
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7300
Epoch 2/10, Batch 20/49, Loss: 0.5158
Epoch 2/10, Batch 30/49, Loss: 0.4128
Epoch 2/10, Batch 40/49, Loss: 0.5578
Epoch 2/10, Train Loss: 0.5372, Valid Loss: 0.5190
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4356
Epoch 3/10, Batch 20/49, Loss: 0.3871
Epoch 3/10, Batch 30/49, Loss: 0.3055
Epoch 3/10, Batch 40/49, Loss: 0.3370
Epoch 3/10, Train Loss: 0.4099, Valid Loss: 0.4402
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3197
Epoch 4/10, Batch 20/49, Loss: 0.4131
Epoch 4/10, Batch 30/49, Loss: 0.1881
Epoch 4/10, Batch 40/49, Loss: 0.3611
Epoch 4/10, Train Loss: 0.3590, Valid Loss: 0.4045
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2369
Epoch 5/10, Batch 20/49, Loss: 0.2577
Epoch 5/10, Batch 30/49, Loss: 0.3330
Epoch 5/10, Batch 40/49, Loss: 0.3537
Epoch 5/10, Train Loss: 0.2930, Valid Loss: 0.3535
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2190
Epoch 6/10, Batch 20/49, Loss: 0.2041
Epoch 6/10, Batch 30/49, Loss: 0.2391
Epoch 6/10, Batch 40/49, Loss: 0.2644
Epoch 6/10, Train Loss: 0.2805, Valid Loss: 0.3589
Epoch 7/10, Batch 10/49, Loss: 0.2381
Epoch 7/10, Batch 20/49, Loss: 0.2334
Epoch 7/10, Batch 30/49, Loss: 0.4096
Epoch 7/10, Batch 40/49, Loss: 0.2256
Epoch 7/10, Train Loss: 0.2599, Valid Loss: 0.3335
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2081
Epoch 8/10, Batch 20/49, Loss: 0.2712
Epoch 8/10, Batch 30/49, Loss: 0.1646
Epoch 8/10, Batch 40/49, Loss: 0.2553
Epoch 8/10, Train Loss: 0.2366, Valid Loss: 0.3260
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1461
Epoch 9/10, Batch 20/49, Loss: 0.1401
Epoch 9/10, Batch 30/49, Loss: 0.3348
Epoch 9/10, Batch 40/49, Loss: 0.1784
Epoch 9/10, Train Loss: 0.2327, Valid Loss: 0.3214
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2008
Epoch 10/10, Batch 20/49, Loss: 0.0933
Epoch 10/10, Batch 30/49, Loss: 0.2123
Epoch 10/10, Batch 40/49, Loss: 0.2381
Epoch 10/10, Train Loss: 0.2029, Valid Loss: 0.3128
Model saved!
Accuracy: 0.9112
Precision: 0.9083
Recall: 0.9112
F1-score: 0.9084
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2630
Epoch 1/10, Batch 20/49, Loss: 1.0478
Epoch 1/10, Batch 30/49, Loss: 0.8627
Epoch 1/10, Batch 40/49, Loss: 0.7373
Epoch 1/10, Train Loss: 1.0061, Valid Loss: 0.6727
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5587
Epoch 2/10, Batch 20/49, Loss: 0.4687
Epoch 2/10, Batch 30/49, Loss: 0.6405
Epoch 2/10, Batch 40/49, Loss: 0.5314
Epoch 2/10, Train Loss: 0.5413, Valid Loss: 0.5177
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4525
Epoch 3/10, Batch 20/49, Loss: 0.5587
Epoch 3/10, Batch 30/49, Loss: 0.3636
Epoch 3/10, Batch 40/49, Loss: 0.3508
Epoch 3/10, Train Loss: 0.4343, Valid Loss: 0.4535
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2822
Epoch 4/10, Batch 20/49, Loss: 0.4141
Epoch 4/10, Batch 30/49, Loss: 0.2439
Epoch 4/10, Batch 40/49, Loss: 0.4176
Epoch 4/10, Train Loss: 0.3774, Valid Loss: 0.3762
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3966
Epoch 5/10, Batch 20/49, Loss: 0.2117
Epoch 5/10, Batch 30/49, Loss: 0.2637
Epoch 5/10, Batch 40/49, Loss: 0.2548
Epoch 5/10, Train Loss: 0.3247, Valid Loss: 0.3513
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1626
Epoch 6/10, Batch 20/49, Loss: 0.2990
Epoch 6/10, Batch 30/49, Loss: 0.4065
Epoch 6/10, Batch 40/49, Loss: 0.2445
Epoch 6/10, Train Loss: 0.3075, Valid Loss: 0.3384
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3987
Epoch 7/10, Batch 20/49, Loss: 0.2669
Epoch 7/10, Batch 30/49, Loss: 0.3938
Epoch 7/10, Batch 40/49, Loss: 0.1229
Epoch 7/10, Train Loss: 0.2767, Valid Loss: 0.3430
Epoch 8/10, Batch 10/49, Loss: 0.2537
Epoch 8/10, Batch 20/49, Loss: 0.2535
Epoch 8/10, Batch 30/49, Loss: 0.2614
Epoch 8/10, Batch 40/49, Loss: 0.1872
Epoch 8/10, Train Loss: 0.2508, Valid Loss: 0.3206
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1994
Epoch 9/10, Batch 20/49, Loss: 0.5064
Epoch 9/10, Batch 30/49, Loss: 0.4869
Epoch 9/10, Batch 40/49, Loss: 0.2015
Epoch 9/10, Train Loss: 0.2463, Valid Loss: 0.2807
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2877
Epoch 10/10, Batch 20/49, Loss: 0.1977
Epoch 10/10, Batch 30/49, Loss: 0.2971
Epoch 10/10, Batch 40/49, Loss: 0.2639
Epoch 10/10, Train Loss: 0.2107, Valid Loss: 0.2724
Model saved!
Accuracy: 0.9019
Precision: 0.8972
Recall: 0.9019
F1-score: 0.8977
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2999
Epoch 1/10, Batch 20/49, Loss: 0.9799
Epoch 1/10, Batch 30/49, Loss: 0.9023
Epoch 1/10, Batch 40/49, Loss: 0.6870
Epoch 1/10, Train Loss: 0.9946, Valid Loss: 0.6339
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6137
Epoch 2/10, Batch 20/49, Loss: 0.5179
Epoch 2/10, Batch 30/49, Loss: 0.5814
Epoch 2/10, Batch 40/49, Loss: 0.4738
Epoch 2/10, Train Loss: 0.5402, Valid Loss: 0.4743
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4474
Epoch 3/10, Batch 20/49, Loss: 0.5068
Epoch 3/10, Batch 30/49, Loss: 0.3460
Epoch 3/10, Batch 40/49, Loss: 0.3237
Epoch 3/10, Train Loss: 0.4221, Valid Loss: 0.4019
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4086
Epoch 4/10, Batch 20/49, Loss: 0.3349
Epoch 4/10, Batch 30/49, Loss: 0.2384
Epoch 4/10, Batch 40/49, Loss: 0.3709
Epoch 4/10, Train Loss: 0.3632, Valid Loss: 0.3593
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2095
Epoch 5/10, Batch 20/49, Loss: 0.3615
Epoch 5/10, Batch 30/49, Loss: 0.1504
Epoch 5/10, Batch 40/49, Loss: 0.2387
Epoch 5/10, Train Loss: 0.3021, Valid Loss: 0.3388
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2328
Epoch 6/10, Batch 20/49, Loss: 0.2042
Epoch 6/10, Batch 30/49, Loss: 0.2893
Epoch 6/10, Batch 40/49, Loss: 0.3005
Epoch 6/10, Train Loss: 0.2853, Valid Loss: 0.3326
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2802
Epoch 7/10, Batch 20/49, Loss: 0.2266
Epoch 7/10, Batch 30/49, Loss: 0.3694
Epoch 7/10, Batch 40/49, Loss: 0.1793
Epoch 7/10, Train Loss: 0.2651, Valid Loss: 0.3387
Epoch 8/10, Batch 10/49, Loss: 0.2553
Epoch 8/10, Batch 20/49, Loss: 0.1899
Epoch 8/10, Batch 30/49, Loss: 0.2502
Epoch 8/10, Batch 40/49, Loss: 0.2867
Epoch 8/10, Train Loss: 0.2509, Valid Loss: 0.3144
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1640
Epoch 9/10, Batch 20/49, Loss: 0.1204
Epoch 9/10, Batch 30/49, Loss: 0.4711
Epoch 9/10, Batch 40/49, Loss: 0.1948
Epoch 9/10, Train Loss: 0.2545, Valid Loss: 0.3049
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1870
Epoch 10/10, Batch 20/49, Loss: 0.1078
Epoch 10/10, Batch 30/49, Loss: 0.2211
Epoch 10/10, Batch 40/49, Loss: 0.3229
Epoch 10/10, Train Loss: 0.2079, Valid Loss: 0.2976
Model saved!
Accuracy: 0.9077
Precision: 0.9040
Recall: 0.9077
F1-score: 0.9034
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2286
Epoch 1/10, Batch 20/49, Loss: 1.0339
Epoch 1/10, Batch 30/49, Loss: 0.8194
Epoch 1/10, Batch 40/49, Loss: 0.8073
Epoch 1/10, Train Loss: 0.9930, Valid Loss: 0.6669
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.8146
Epoch 2/10, Batch 20/49, Loss: 0.4937
Epoch 2/10, Batch 30/49, Loss: 0.5380
Epoch 2/10, Batch 40/49, Loss: 0.4115
Epoch 2/10, Train Loss: 0.5307, Valid Loss: 0.4889
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3688
Epoch 3/10, Batch 20/49, Loss: 0.4392
Epoch 3/10, Batch 30/49, Loss: 0.3334
Epoch 3/10, Batch 40/49, Loss: 0.2786
Epoch 3/10, Train Loss: 0.4134, Valid Loss: 0.4309
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3620
Epoch 4/10, Batch 20/49, Loss: 0.3978
Epoch 4/10, Batch 30/49, Loss: 0.2087
Epoch 4/10, Batch 40/49, Loss: 0.2226
Epoch 4/10, Train Loss: 0.3572, Valid Loss: 0.3657
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2389
Epoch 5/10, Batch 20/49, Loss: 0.2052
Epoch 5/10, Batch 30/49, Loss: 0.2724
Epoch 5/10, Batch 40/49, Loss: 0.2145
Epoch 5/10, Train Loss: 0.2975, Valid Loss: 0.3438
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3301
Epoch 6/10, Batch 20/49, Loss: 0.3093
Epoch 6/10, Batch 30/49, Loss: 0.2060
Epoch 6/10, Batch 40/49, Loss: 0.3566
Epoch 6/10, Train Loss: 0.2753, Valid Loss: 0.3351
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3056
Epoch 7/10, Batch 20/49, Loss: 0.2764
Epoch 7/10, Batch 30/49, Loss: 0.3155
Epoch 7/10, Batch 40/49, Loss: 0.2202
Epoch 7/10, Train Loss: 0.2689, Valid Loss: 0.3332
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2009
Epoch 8/10, Batch 20/49, Loss: 0.2126
Epoch 8/10, Batch 30/49, Loss: 0.2431
Epoch 8/10, Batch 40/49, Loss: 0.1873
Epoch 8/10, Train Loss: 0.2506, Valid Loss: 0.3302
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2280
Epoch 9/10, Batch 20/49, Loss: 0.1800
Epoch 9/10, Batch 30/49, Loss: 0.4398
Epoch 9/10, Batch 40/49, Loss: 0.1820
Epoch 9/10, Train Loss: 0.2470, Valid Loss: 0.3041
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1798
Epoch 10/10, Batch 20/49, Loss: 0.2157
Epoch 10/10, Batch 30/49, Loss: 0.2361
Epoch 10/10, Batch 40/49, Loss: 0.1615
Epoch 10/10, Train Loss: 0.2117, Valid Loss: 0.2988
Model saved!
Accuracy: 0.9007
Precision: 0.8971
Recall: 0.9007
F1-score: 0.8977
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2565
Epoch 1/10, Batch 20/49, Loss: 1.0957
Epoch 1/10, Batch 30/49, Loss: 0.7701
Epoch 1/10, Batch 40/49, Loss: 0.7851
Epoch 1/10, Train Loss: 0.9920, Valid Loss: 0.6502
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6848
Epoch 2/10, Batch 20/49, Loss: 0.4547
Epoch 2/10, Batch 30/49, Loss: 0.5078
Epoch 2/10, Batch 40/49, Loss: 0.4407
Epoch 2/10, Train Loss: 0.5328, Valid Loss: 0.4991
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3750
Epoch 3/10, Batch 20/49, Loss: 0.3969
Epoch 3/10, Batch 30/49, Loss: 0.4084
Epoch 3/10, Batch 40/49, Loss: 0.2841
Epoch 3/10, Train Loss: 0.4196, Valid Loss: 0.4485
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3618
Epoch 4/10, Batch 20/49, Loss: 0.3040
Epoch 4/10, Batch 30/49, Loss: 0.1856
Epoch 4/10, Batch 40/49, Loss: 0.2942
Epoch 4/10, Train Loss: 0.3536, Valid Loss: 0.3936
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2549
Epoch 5/10, Batch 20/49, Loss: 0.2163
Epoch 5/10, Batch 30/49, Loss: 0.2550
Epoch 5/10, Batch 40/49, Loss: 0.1944
Epoch 5/10, Train Loss: 0.2972, Valid Loss: 0.3688
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1952
Epoch 6/10, Batch 20/49, Loss: 0.2434
Epoch 6/10, Batch 30/49, Loss: 0.3670
Epoch 6/10, Batch 40/49, Loss: 0.2266
Epoch 6/10, Train Loss: 0.2856, Valid Loss: 0.3664
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2748
Epoch 7/10, Batch 20/49, Loss: 0.3659
Epoch 7/10, Batch 30/49, Loss: 0.2794
Epoch 7/10, Batch 40/49, Loss: 0.2264
Epoch 7/10, Train Loss: 0.2642, Valid Loss: 0.3666
Epoch 8/10, Batch 10/49, Loss: 0.2919
Epoch 8/10, Batch 20/49, Loss: 0.2740
Epoch 8/10, Batch 30/49, Loss: 0.2075
Epoch 8/10, Batch 40/49, Loss: 0.1978
Epoch 8/10, Train Loss: 0.2503, Valid Loss: 0.3441
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1099
Epoch 9/10, Batch 20/49, Loss: 0.2375
Epoch 9/10, Batch 30/49, Loss: 0.5912
Epoch 9/10, Batch 40/49, Loss: 0.2189
Epoch 9/10, Train Loss: 0.2404, Valid Loss: 0.3312
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2528
Epoch 10/10, Batch 20/49, Loss: 0.1571
Epoch 10/10, Batch 30/49, Loss: 0.2591
Epoch 10/10, Batch 40/49, Loss: 0.2733
Epoch 10/10, Train Loss: 0.2096, Valid Loss: 0.3165
Model saved!
Accuracy: 0.9124
Precision: 0.9110
Recall: 0.9124
F1-score: 0.9100
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2475
Epoch 1/10, Batch 20/49, Loss: 1.1011
Epoch 1/10, Batch 30/49, Loss: 0.8086
Epoch 1/10, Batch 40/49, Loss: 0.6998
Epoch 1/10, Train Loss: 0.9959, Valid Loss: 0.6260
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6099
Epoch 2/10, Batch 20/49, Loss: 0.5399
Epoch 2/10, Batch 30/49, Loss: 0.4146
Epoch 2/10, Batch 40/49, Loss: 0.5716
Epoch 2/10, Train Loss: 0.5398, Valid Loss: 0.4430
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3303
Epoch 3/10, Batch 20/49, Loss: 0.4020
Epoch 3/10, Batch 30/49, Loss: 0.3634
Epoch 3/10, Batch 40/49, Loss: 0.3266
Epoch 3/10, Train Loss: 0.4223, Valid Loss: 0.3934
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3260
Epoch 4/10, Batch 20/49, Loss: 0.3898
Epoch 4/10, Batch 30/49, Loss: 0.2164
Epoch 4/10, Batch 40/49, Loss: 0.2967
Epoch 4/10, Train Loss: 0.3574, Valid Loss: 0.3323
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3126
Epoch 5/10, Batch 20/49, Loss: 0.2385
Epoch 5/10, Batch 30/49, Loss: 0.2033
Epoch 5/10, Batch 40/49, Loss: 0.2080
Epoch 5/10, Train Loss: 0.3048, Valid Loss: 0.3220
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1655
Epoch 6/10, Batch 20/49, Loss: 0.2388
Epoch 6/10, Batch 30/49, Loss: 0.3759
Epoch 6/10, Batch 40/49, Loss: 0.3268
Epoch 6/10, Train Loss: 0.2859, Valid Loss: 0.3172
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2449
Epoch 7/10, Batch 20/49, Loss: 0.2339
Epoch 7/10, Batch 30/49, Loss: 0.2990
Epoch 7/10, Batch 40/49, Loss: 0.2709
Epoch 7/10, Train Loss: 0.2590, Valid Loss: 0.3233
Epoch 8/10, Batch 10/49, Loss: 0.2973
Epoch 8/10, Batch 20/49, Loss: 0.2175
Epoch 8/10, Batch 30/49, Loss: 0.3539
Epoch 8/10, Batch 40/49, Loss: 0.2841
Epoch 8/10, Train Loss: 0.2497, Valid Loss: 0.2985
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1391
Epoch 9/10, Batch 20/49, Loss: 0.2318
Epoch 9/10, Batch 30/49, Loss: 0.3794
Epoch 9/10, Batch 40/49, Loss: 0.2849
Epoch 9/10, Train Loss: 0.2241, Valid Loss: 0.2944
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2546
Epoch 10/10, Batch 20/49, Loss: 0.1761
Epoch 10/10, Batch 30/49, Loss: 0.1747
Epoch 10/10, Batch 40/49, Loss: 0.1470
Epoch 10/10, Train Loss: 0.2109, Valid Loss: 0.2818
Model saved!
Accuracy: 0.9065
Precision: 0.9020
Recall: 0.9065
F1-score: 0.9026
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2719
Epoch 1/10, Batch 20/49, Loss: 1.0336
Epoch 1/10, Batch 30/49, Loss: 0.8025
Epoch 1/10, Batch 40/49, Loss: 0.7564
Epoch 1/10, Train Loss: 0.9979, Valid Loss: 0.6844
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5844
Epoch 2/10, Batch 20/49, Loss: 0.5418
Epoch 2/10, Batch 30/49, Loss: 0.5456
Epoch 2/10, Batch 40/49, Loss: 0.4996
Epoch 2/10, Train Loss: 0.5435, Valid Loss: 0.4925
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5864
Epoch 3/10, Batch 20/49, Loss: 0.3957
Epoch 3/10, Batch 30/49, Loss: 0.4779
Epoch 3/10, Batch 40/49, Loss: 0.3515
Epoch 3/10, Train Loss: 0.4146, Valid Loss: 0.4298
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2870
Epoch 4/10, Batch 20/49, Loss: 0.4180
Epoch 4/10, Batch 30/49, Loss: 0.2739
Epoch 4/10, Batch 40/49, Loss: 0.2376
Epoch 4/10, Train Loss: 0.3530, Valid Loss: 0.3812
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2144
Epoch 5/10, Batch 20/49, Loss: 0.3618
Epoch 5/10, Batch 30/49, Loss: 0.3349
Epoch 5/10, Batch 40/49, Loss: 0.2562
Epoch 5/10, Train Loss: 0.2983, Valid Loss: 0.3530
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2596
Epoch 6/10, Batch 20/49, Loss: 0.3309
Epoch 6/10, Batch 30/49, Loss: 0.3151
Epoch 6/10, Batch 40/49, Loss: 0.4221
Epoch 6/10, Train Loss: 0.2802, Valid Loss: 0.3380
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2525
Epoch 7/10, Batch 20/49, Loss: 0.2108
Epoch 7/10, Batch 30/49, Loss: 0.3512
Epoch 7/10, Batch 40/49, Loss: 0.1859
Epoch 7/10, Train Loss: 0.2602, Valid Loss: 0.3385
Epoch 8/10, Batch 10/49, Loss: 0.1452
Epoch 8/10, Batch 20/49, Loss: 0.1681
Epoch 8/10, Batch 30/49, Loss: 0.3480
Epoch 8/10, Batch 40/49, Loss: 0.2300
Epoch 8/10, Train Loss: 0.2452, Valid Loss: 0.3094
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1815
Epoch 9/10, Batch 20/49, Loss: 0.2461
Epoch 9/10, Batch 30/49, Loss: 0.4360
Epoch 9/10, Batch 40/49, Loss: 0.2664
Epoch 9/10, Train Loss: 0.2345, Valid Loss: 0.2965
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1725
Epoch 10/10, Batch 20/49, Loss: 0.1457
Epoch 10/10, Batch 30/49, Loss: 0.2750
Epoch 10/10, Batch 40/49, Loss: 0.1544
Epoch 10/10, Train Loss: 0.2092, Valid Loss: 0.2901
Model saved!
Accuracy: 0.9065
Precision: 0.9034
Recall: 0.9065
F1-score: 0.9035
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3737
Epoch 1/10, Batch 20/49, Loss: 1.0163
Epoch 1/10, Batch 30/49, Loss: 0.7583
Epoch 1/10, Batch 40/49, Loss: 0.7595
Epoch 1/10, Train Loss: 0.9851, Valid Loss: 0.6365
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5891
Epoch 2/10, Batch 20/49, Loss: 0.4915
Epoch 2/10, Batch 30/49, Loss: 0.5464
Epoch 2/10, Batch 40/49, Loss: 0.4834
Epoch 2/10, Train Loss: 0.5291, Valid Loss: 0.4578
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3122
Epoch 3/10, Batch 20/49, Loss: 0.4991
Epoch 3/10, Batch 30/49, Loss: 0.4347
Epoch 3/10, Batch 40/49, Loss: 0.3869
Epoch 3/10, Train Loss: 0.4118, Valid Loss: 0.3953
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2186
Epoch 4/10, Batch 20/49, Loss: 0.4513
Epoch 4/10, Batch 30/49, Loss: 0.3703
Epoch 4/10, Batch 40/49, Loss: 0.2998
Epoch 4/10, Train Loss: 0.3623, Valid Loss: 0.3320
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2726
Epoch 5/10, Batch 20/49, Loss: 0.2247
Epoch 5/10, Batch 30/49, Loss: 0.4028
Epoch 5/10, Batch 40/49, Loss: 0.2081
Epoch 5/10, Train Loss: 0.3033, Valid Loss: 0.3114
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2258
Epoch 6/10, Batch 20/49, Loss: 0.4324
Epoch 6/10, Batch 30/49, Loss: 0.2658
Epoch 6/10, Batch 40/49, Loss: 0.3615
Epoch 6/10, Train Loss: 0.2789, Valid Loss: 0.2891
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3897
Epoch 7/10, Batch 20/49, Loss: 0.1838
Epoch 7/10, Batch 30/49, Loss: 0.3401
Epoch 7/10, Batch 40/49, Loss: 0.2415
Epoch 7/10, Train Loss: 0.2582, Valid Loss: 0.2996
Epoch 8/10, Batch 10/49, Loss: 0.2821
Epoch 8/10, Batch 20/49, Loss: 0.1437
Epoch 8/10, Batch 30/49, Loss: 0.2319
Epoch 8/10, Batch 40/49, Loss: 0.2123
Epoch 8/10, Train Loss: 0.2423, Valid Loss: 0.2736
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2513
Epoch 9/10, Batch 20/49, Loss: 0.2255
Epoch 9/10, Batch 30/49, Loss: 0.3332
Epoch 9/10, Batch 40/49, Loss: 0.1630
Epoch 9/10, Train Loss: 0.2335, Valid Loss: 0.2545
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2847
Epoch 10/10, Batch 20/49, Loss: 0.1430
Epoch 10/10, Batch 30/49, Loss: 0.1739
Epoch 10/10, Batch 40/49, Loss: 0.2375
Epoch 10/10, Train Loss: 0.2135, Valid Loss: 0.2455
Model saved!
Accuracy: 0.8995
Precision: 0.8995
Recall: 0.8995
F1-score: 0.8935
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3520
Epoch 1/10, Batch 20/49, Loss: 1.0260
Epoch 1/10, Batch 30/49, Loss: 0.7861
Epoch 1/10, Batch 40/49, Loss: 0.7754
Epoch 1/10, Train Loss: 1.0030, Valid Loss: 0.6607
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.8479
Epoch 2/10, Batch 20/49, Loss: 0.3704
Epoch 2/10, Batch 30/49, Loss: 0.5272
Epoch 2/10, Batch 40/49, Loss: 0.4956
Epoch 2/10, Train Loss: 0.5347, Valid Loss: 0.4914
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4691
Epoch 3/10, Batch 20/49, Loss: 0.3374
Epoch 3/10, Batch 30/49, Loss: 0.5384
Epoch 3/10, Batch 40/49, Loss: 0.3364
Epoch 3/10, Train Loss: 0.4211, Valid Loss: 0.4272
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2105
Epoch 4/10, Batch 20/49, Loss: 0.3814
Epoch 4/10, Batch 30/49, Loss: 0.3003
Epoch 4/10, Batch 40/49, Loss: 0.2535
Epoch 4/10, Train Loss: 0.3479, Valid Loss: 0.3851
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4440
Epoch 5/10, Batch 20/49, Loss: 0.2951
Epoch 5/10, Batch 30/49, Loss: 0.3915
Epoch 5/10, Batch 40/49, Loss: 0.2597
Epoch 5/10, Train Loss: 0.3082, Valid Loss: 0.3559
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3028
Epoch 6/10, Batch 20/49, Loss: 0.2034
Epoch 6/10, Batch 30/49, Loss: 0.2708
Epoch 6/10, Batch 40/49, Loss: 0.2852
Epoch 6/10, Train Loss: 0.2909, Valid Loss: 0.3525
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2404
Epoch 7/10, Batch 20/49, Loss: 0.0932
Epoch 7/10, Batch 30/49, Loss: 0.3962
Epoch 7/10, Batch 40/49, Loss: 0.1971
Epoch 7/10, Train Loss: 0.2664, Valid Loss: 0.3461
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2503
Epoch 8/10, Batch 20/49, Loss: 0.1808
Epoch 8/10, Batch 30/49, Loss: 0.2170
Epoch 8/10, Batch 40/49, Loss: 0.2394
Epoch 8/10, Train Loss: 0.2496, Valid Loss: 0.3255
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1434
Epoch 9/10, Batch 20/49, Loss: 0.2003
Epoch 9/10, Batch 30/49, Loss: 0.4660
Epoch 9/10, Batch 40/49, Loss: 0.1472
Epoch 9/10, Train Loss: 0.2340, Valid Loss: 0.3172
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2986
Epoch 10/10, Batch 20/49, Loss: 0.1723
Epoch 10/10, Batch 30/49, Loss: 0.2971
Epoch 10/10, Batch 40/49, Loss: 0.1573
Epoch 10/10, Train Loss: 0.2144, Valid Loss: 0.3112
Model saved!
Accuracy: 0.9077
Precision: 0.9065
Recall: 0.9077
F1-score: 0.9038
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1911
Epoch 1/10, Batch 20/49, Loss: 1.0439
Epoch 1/10, Batch 30/49, Loss: 0.7750
Epoch 1/10, Batch 40/49, Loss: 0.7643
Epoch 1/10, Train Loss: 0.9899, Valid Loss: 0.6825
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5758
Epoch 2/10, Batch 20/49, Loss: 0.4431
Epoch 2/10, Batch 30/49, Loss: 0.5044
Epoch 2/10, Batch 40/49, Loss: 0.5122
Epoch 2/10, Train Loss: 0.5307, Valid Loss: 0.4965
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4214
Epoch 3/10, Batch 20/49, Loss: 0.3990
Epoch 3/10, Batch 30/49, Loss: 0.5178
Epoch 3/10, Batch 40/49, Loss: 0.2977
Epoch 3/10, Train Loss: 0.4197, Valid Loss: 0.4392
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2071
Epoch 4/10, Batch 20/49, Loss: 0.4980
Epoch 4/10, Batch 30/49, Loss: 0.4404
Epoch 4/10, Batch 40/49, Loss: 0.2396
Epoch 4/10, Train Loss: 0.3498, Valid Loss: 0.3913
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2975
Epoch 5/10, Batch 20/49, Loss: 0.2839
Epoch 5/10, Batch 30/49, Loss: 0.3249
Epoch 5/10, Batch 40/49, Loss: 0.2814
Epoch 5/10, Train Loss: 0.3046, Valid Loss: 0.3639
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2141
Epoch 6/10, Batch 20/49, Loss: 0.2018
Epoch 6/10, Batch 30/49, Loss: 0.2343
Epoch 6/10, Batch 40/49, Loss: 0.2535
Epoch 6/10, Train Loss: 0.2811, Valid Loss: 0.3535
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3387
Epoch 7/10, Batch 20/49, Loss: 0.4288
Epoch 7/10, Batch 30/49, Loss: 0.3919
Epoch 7/10, Batch 40/49, Loss: 0.2167
Epoch 7/10, Train Loss: 0.2645, Valid Loss: 0.3458
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1930
Epoch 8/10, Batch 20/49, Loss: 0.2172
Epoch 8/10, Batch 30/49, Loss: 0.2262
Epoch 8/10, Batch 40/49, Loss: 0.1353
Epoch 8/10, Train Loss: 0.2573, Valid Loss: 0.3278
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1163
Epoch 9/10, Batch 20/49, Loss: 0.3168
Epoch 9/10, Batch 30/49, Loss: 0.4774
Epoch 9/10, Batch 40/49, Loss: 0.1644
Epoch 9/10, Train Loss: 0.2352, Valid Loss: 0.3046
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1985
Epoch 10/10, Batch 20/49, Loss: 0.0776
Epoch 10/10, Batch 30/49, Loss: 0.3331
Epoch 10/10, Batch 40/49, Loss: 0.1742
Epoch 10/10, Train Loss: 0.2087, Valid Loss: 0.2984
Model saved!
Accuracy: 0.9019
Precision: 0.8988
Recall: 0.9019
F1-score: 0.8980
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2677
Epoch 1/10, Batch 20/49, Loss: 1.0726
Epoch 1/10, Batch 30/49, Loss: 0.8413
Epoch 1/10, Batch 40/49, Loss: 0.7333
Epoch 1/10, Train Loss: 0.9928, Valid Loss: 0.6786
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6841
Epoch 2/10, Batch 20/49, Loss: 0.5043
Epoch 2/10, Batch 30/49, Loss: 0.4818
Epoch 2/10, Batch 40/49, Loss: 0.6098
Epoch 2/10, Train Loss: 0.5237, Valid Loss: 0.4961
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3316
Epoch 3/10, Batch 20/49, Loss: 0.4878
Epoch 3/10, Batch 30/49, Loss: 0.5548
Epoch 3/10, Batch 40/49, Loss: 0.3044
Epoch 3/10, Train Loss: 0.4167, Valid Loss: 0.4223
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2481
Epoch 4/10, Batch 20/49, Loss: 0.3845
Epoch 4/10, Batch 30/49, Loss: 0.3359
Epoch 4/10, Batch 40/49, Loss: 0.2627
Epoch 4/10, Train Loss: 0.3600, Valid Loss: 0.3795
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3361
Epoch 5/10, Batch 20/49, Loss: 0.2596
Epoch 5/10, Batch 30/49, Loss: 0.1799
Epoch 5/10, Batch 40/49, Loss: 0.2000
Epoch 5/10, Train Loss: 0.3057, Valid Loss: 0.3599
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2294
Epoch 6/10, Batch 20/49, Loss: 0.3096
Epoch 6/10, Batch 30/49, Loss: 0.3049
Epoch 6/10, Batch 40/49, Loss: 0.1972
Epoch 6/10, Train Loss: 0.2768, Valid Loss: 0.3479
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2670
Epoch 7/10, Batch 20/49, Loss: 0.2334
Epoch 7/10, Batch 30/49, Loss: 0.2943
Epoch 7/10, Batch 40/49, Loss: 0.1410
Epoch 7/10, Train Loss: 0.2579, Valid Loss: 0.3303
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3727
Epoch 8/10, Batch 20/49, Loss: 0.2663
Epoch 8/10, Batch 30/49, Loss: 0.3200
Epoch 8/10, Batch 40/49, Loss: 0.3044
Epoch 8/10, Train Loss: 0.2500, Valid Loss: 0.3253
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2103
Epoch 9/10, Batch 20/49, Loss: 0.1484
Epoch 9/10, Batch 30/49, Loss: 0.4552
Epoch 9/10, Batch 40/49, Loss: 0.1448
Epoch 9/10, Train Loss: 0.2287, Valid Loss: 0.3161
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2347
Epoch 10/10, Batch 20/49, Loss: 0.1851
Epoch 10/10, Batch 30/49, Loss: 0.1950
Epoch 10/10, Batch 40/49, Loss: 0.3499
Epoch 10/10, Train Loss: 0.2000, Valid Loss: 0.2965
Model saved!
Accuracy: 0.9077
Precision: 0.9041
Recall: 0.9077
F1-score: 0.9043
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2435
Epoch 1/10, Batch 20/49, Loss: 1.0545
Epoch 1/10, Batch 30/49, Loss: 0.8041
Epoch 1/10, Batch 40/49, Loss: 0.8551
Epoch 1/10, Train Loss: 0.9873, Valid Loss: 0.6452
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6664
Epoch 2/10, Batch 20/49, Loss: 0.4947
Epoch 2/10, Batch 30/49, Loss: 0.6065
Epoch 2/10, Batch 40/49, Loss: 0.4259
Epoch 2/10, Train Loss: 0.5281, Valid Loss: 0.4617
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4762
Epoch 3/10, Batch 20/49, Loss: 0.2494
Epoch 3/10, Batch 30/49, Loss: 0.2990
Epoch 3/10, Batch 40/49, Loss: 0.2671
Epoch 3/10, Train Loss: 0.4057, Valid Loss: 0.4031
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2660
Epoch 4/10, Batch 20/49, Loss: 0.3171
Epoch 4/10, Batch 30/49, Loss: 0.3491
Epoch 4/10, Batch 40/49, Loss: 0.2528
Epoch 4/10, Train Loss: 0.3510, Valid Loss: 0.3531
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2593
Epoch 5/10, Batch 20/49, Loss: 0.3664
Epoch 5/10, Batch 30/49, Loss: 0.3211
Epoch 5/10, Batch 40/49, Loss: 0.1901
Epoch 5/10, Train Loss: 0.2979, Valid Loss: 0.3312
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3146
Epoch 6/10, Batch 20/49, Loss: 0.2990
Epoch 6/10, Batch 30/49, Loss: 0.2088
Epoch 6/10, Batch 40/49, Loss: 0.2667
Epoch 6/10, Train Loss: 0.2748, Valid Loss: 0.3173
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2658
Epoch 7/10, Batch 20/49, Loss: 0.2055
Epoch 7/10, Batch 30/49, Loss: 0.2434
Epoch 7/10, Batch 40/49, Loss: 0.1083
Epoch 7/10, Train Loss: 0.2598, Valid Loss: 0.3127
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2596
Epoch 8/10, Batch 20/49, Loss: 0.1740
Epoch 8/10, Batch 30/49, Loss: 0.3020
Epoch 8/10, Batch 40/49, Loss: 0.1282
Epoch 8/10, Train Loss: 0.2475, Valid Loss: 0.2970
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1429
Epoch 9/10, Batch 20/49, Loss: 0.2235
Epoch 9/10, Batch 30/49, Loss: 0.5660
Epoch 9/10, Batch 40/49, Loss: 0.1454
Epoch 9/10, Train Loss: 0.2329, Valid Loss: 0.2917
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2169
Epoch 10/10, Batch 20/49, Loss: 0.1143
Epoch 10/10, Batch 30/49, Loss: 0.2326
Epoch 10/10, Batch 40/49, Loss: 0.4104
Epoch 10/10, Train Loss: 0.2008, Valid Loss: 0.2879
Model saved!
Accuracy: 0.9112
Precision: 0.9063
Recall: 0.9112
F1-score: 0.9066
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2541
Epoch 1/10, Batch 20/49, Loss: 0.9802
Epoch 1/10, Batch 30/49, Loss: 0.7799
Epoch 1/10, Batch 40/49, Loss: 0.8261
Epoch 1/10, Train Loss: 0.9856, Valid Loss: 0.6323
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7681
Epoch 2/10, Batch 20/49, Loss: 0.4635
Epoch 2/10, Batch 30/49, Loss: 0.5430
Epoch 2/10, Batch 40/49, Loss: 0.6570
Epoch 2/10, Train Loss: 0.5370, Valid Loss: 0.4651
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4522
Epoch 3/10, Batch 20/49, Loss: 0.4263
Epoch 3/10, Batch 30/49, Loss: 0.4238
Epoch 3/10, Batch 40/49, Loss: 0.2751
Epoch 3/10, Train Loss: 0.4144, Valid Loss: 0.3859
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2901
Epoch 4/10, Batch 20/49, Loss: 0.3907
Epoch 4/10, Batch 30/49, Loss: 0.2056
Epoch 4/10, Batch 40/49, Loss: 0.2575
Epoch 4/10, Train Loss: 0.3513, Valid Loss: 0.3454
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.1877
Epoch 5/10, Batch 20/49, Loss: 0.1769
Epoch 5/10, Batch 30/49, Loss: 0.2644
Epoch 5/10, Batch 40/49, Loss: 0.3377
Epoch 5/10, Train Loss: 0.3011, Valid Loss: 0.3251
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2236
Epoch 6/10, Batch 20/49, Loss: 0.2894
Epoch 6/10, Batch 30/49, Loss: 0.3804
Epoch 6/10, Batch 40/49, Loss: 0.2465
Epoch 6/10, Train Loss: 0.2888, Valid Loss: 0.3189
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3243
Epoch 7/10, Batch 20/49, Loss: 0.2392
Epoch 7/10, Batch 30/49, Loss: 0.2497
Epoch 7/10, Batch 40/49, Loss: 0.2002
Epoch 7/10, Train Loss: 0.2637, Valid Loss: 0.3208
Epoch 8/10, Batch 10/49, Loss: 0.2500
Epoch 8/10, Batch 20/49, Loss: 0.2058
Epoch 8/10, Batch 30/49, Loss: 0.2612
Epoch 8/10, Batch 40/49, Loss: 0.1968
Epoch 8/10, Train Loss: 0.2506, Valid Loss: 0.2972
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1611
Epoch 9/10, Batch 20/49, Loss: 0.2359
Epoch 9/10, Batch 30/49, Loss: 0.4661
Epoch 9/10, Batch 40/49, Loss: 0.1760
Epoch 9/10, Train Loss: 0.2337, Valid Loss: 0.2890
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3135
Epoch 10/10, Batch 20/49, Loss: 0.1358
Epoch 10/10, Batch 30/49, Loss: 0.2186
Epoch 10/10, Batch 40/49, Loss: 0.2316
Epoch 10/10, Train Loss: 0.2184, Valid Loss: 0.2821
Model saved!
Accuracy: 0.8984
Precision: 0.8935
Recall: 0.8984
F1-score: 0.8945
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2680
Epoch 1/10, Batch 20/49, Loss: 1.0564
Epoch 1/10, Batch 30/49, Loss: 0.7671
Epoch 1/10, Batch 40/49, Loss: 0.8011
Epoch 1/10, Train Loss: 1.0175, Valid Loss: 0.6711
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5976
Epoch 2/10, Batch 20/49, Loss: 0.5422
Epoch 2/10, Batch 30/49, Loss: 0.6291
Epoch 2/10, Batch 40/49, Loss: 0.6716
Epoch 2/10, Train Loss: 0.5514, Valid Loss: 0.4954
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5229
Epoch 3/10, Batch 20/49, Loss: 0.4663
Epoch 3/10, Batch 30/49, Loss: 0.3776
Epoch 3/10, Batch 40/49, Loss: 0.4180
Epoch 3/10, Train Loss: 0.4242, Valid Loss: 0.4282
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4276
Epoch 4/10, Batch 20/49, Loss: 0.4170
Epoch 4/10, Batch 30/49, Loss: 0.2984
Epoch 4/10, Batch 40/49, Loss: 0.3374
Epoch 4/10, Train Loss: 0.3798, Valid Loss: 0.3892
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3121
Epoch 5/10, Batch 20/49, Loss: 0.3023
Epoch 5/10, Batch 30/49, Loss: 0.3057
Epoch 5/10, Batch 40/49, Loss: 0.2259
Epoch 5/10, Train Loss: 0.3122, Valid Loss: 0.3697
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2292
Epoch 6/10, Batch 20/49, Loss: 0.3426
Epoch 6/10, Batch 30/49, Loss: 0.4293
Epoch 6/10, Batch 40/49, Loss: 0.2369
Epoch 6/10, Train Loss: 0.2932, Valid Loss: 0.3515
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2540
Epoch 7/10, Batch 20/49, Loss: 0.1786
Epoch 7/10, Batch 30/49, Loss: 0.6334
Epoch 7/10, Batch 40/49, Loss: 0.3329
Epoch 7/10, Train Loss: 0.2709, Valid Loss: 0.3509
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2100
Epoch 8/10, Batch 20/49, Loss: 0.2191
Epoch 8/10, Batch 30/49, Loss: 0.3579
Epoch 8/10, Batch 40/49, Loss: 0.2977
Epoch 8/10, Train Loss: 0.2565, Valid Loss: 0.3336
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1646
Epoch 9/10, Batch 20/49, Loss: 0.3032
Epoch 9/10, Batch 30/49, Loss: 0.3724
Epoch 9/10, Batch 40/49, Loss: 0.1388
Epoch 9/10, Train Loss: 0.2395, Valid Loss: 0.3276
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2666
Epoch 10/10, Batch 20/49, Loss: 0.1004
Epoch 10/10, Batch 30/49, Loss: 0.2514
Epoch 10/10, Batch 40/49, Loss: 0.1980
Epoch 10/10, Train Loss: 0.2170, Valid Loss: 0.3120
Model saved!
Accuracy: 0.8995
Precision: 0.8943
Recall: 0.8995
F1-score: 0.8959
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2914
Epoch 1/10, Batch 20/49, Loss: 0.9710
Epoch 1/10, Batch 30/49, Loss: 0.8738
Epoch 1/10, Batch 40/49, Loss: 0.6960
Epoch 1/10, Train Loss: 0.9983, Valid Loss: 0.6361
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5982
Epoch 2/10, Batch 20/49, Loss: 0.4800
Epoch 2/10, Batch 30/49, Loss: 0.5229
Epoch 2/10, Batch 40/49, Loss: 0.5033
Epoch 2/10, Train Loss: 0.5282, Valid Loss: 0.4820
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3689
Epoch 3/10, Batch 20/49, Loss: 0.3111
Epoch 3/10, Batch 30/49, Loss: 0.2877
Epoch 3/10, Batch 40/49, Loss: 0.5133
Epoch 3/10, Train Loss: 0.4151, Valid Loss: 0.4028
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2127
Epoch 4/10, Batch 20/49, Loss: 0.3774
Epoch 4/10, Batch 30/49, Loss: 0.2520
Epoch 4/10, Batch 40/49, Loss: 0.3307
Epoch 4/10, Train Loss: 0.3579, Valid Loss: 0.3628
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2990
Epoch 5/10, Batch 20/49, Loss: 0.1992
Epoch 5/10, Batch 30/49, Loss: 0.2654
Epoch 5/10, Batch 40/49, Loss: 0.2018
Epoch 5/10, Train Loss: 0.2998, Valid Loss: 0.3478
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2301
Epoch 6/10, Batch 20/49, Loss: 0.3518
Epoch 6/10, Batch 30/49, Loss: 0.2487
Epoch 6/10, Batch 40/49, Loss: 0.1898
Epoch 6/10, Train Loss: 0.2852, Valid Loss: 0.3309
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2841
Epoch 7/10, Batch 20/49, Loss: 0.1619
Epoch 7/10, Batch 30/49, Loss: 0.6047
Epoch 7/10, Batch 40/49, Loss: 0.2921
Epoch 7/10, Train Loss: 0.2667, Valid Loss: 0.3235
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2103
Epoch 8/10, Batch 20/49, Loss: 0.3029
Epoch 8/10, Batch 30/49, Loss: 0.2397
Epoch 8/10, Batch 40/49, Loss: 0.2001
Epoch 8/10, Train Loss: 0.2397, Valid Loss: 0.3026
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2253
Epoch 9/10, Batch 20/49, Loss: 0.1224
Epoch 9/10, Batch 30/49, Loss: 0.3744
Epoch 9/10, Batch 40/49, Loss: 0.1691
Epoch 9/10, Train Loss: 0.2298, Valid Loss: 0.2941
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2900
Epoch 10/10, Batch 20/49, Loss: 0.1597
Epoch 10/10, Batch 30/49, Loss: 0.1849
Epoch 10/10, Batch 40/49, Loss: 0.3007
Epoch 10/10, Train Loss: 0.2137, Valid Loss: 0.2846
Model saved!
Accuracy: 0.9112
Precision: 0.9085
Recall: 0.9112
F1-score: 0.9096
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2850
Epoch 1/10, Batch 20/49, Loss: 0.9756
Epoch 1/10, Batch 30/49, Loss: 0.7202
Epoch 1/10, Batch 40/49, Loss: 0.6852
Epoch 1/10, Train Loss: 0.9977, Valid Loss: 0.6714
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6589
Epoch 2/10, Batch 20/49, Loss: 0.4490
Epoch 2/10, Batch 30/49, Loss: 0.5056
Epoch 2/10, Batch 40/49, Loss: 0.3419
Epoch 2/10, Train Loss: 0.5296, Valid Loss: 0.4983
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3396
Epoch 3/10, Batch 20/49, Loss: 0.4561
Epoch 3/10, Batch 30/49, Loss: 0.3347
Epoch 3/10, Batch 40/49, Loss: 0.3613
Epoch 3/10, Train Loss: 0.4058, Valid Loss: 0.4229
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3404
Epoch 4/10, Batch 20/49, Loss: 0.3598
Epoch 4/10, Batch 30/49, Loss: 0.2349
Epoch 4/10, Batch 40/49, Loss: 0.2871
Epoch 4/10, Train Loss: 0.3543, Valid Loss: 0.3723
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2685
Epoch 5/10, Batch 20/49, Loss: 0.2537
Epoch 5/10, Batch 30/49, Loss: 0.3562
Epoch 5/10, Batch 40/49, Loss: 0.1980
Epoch 5/10, Train Loss: 0.2985, Valid Loss: 0.3472
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2137
Epoch 6/10, Batch 20/49, Loss: 0.2681
Epoch 6/10, Batch 30/49, Loss: 0.2690
Epoch 6/10, Batch 40/49, Loss: 0.2456
Epoch 6/10, Train Loss: 0.2750, Valid Loss: 0.3323
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2842
Epoch 7/10, Batch 20/49, Loss: 0.2607
Epoch 7/10, Batch 30/49, Loss: 0.2921
Epoch 7/10, Batch 40/49, Loss: 0.2857
Epoch 7/10, Train Loss: 0.2551, Valid Loss: 0.3160
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2827
Epoch 8/10, Batch 20/49, Loss: 0.1742
Epoch 8/10, Batch 30/49, Loss: 0.2186
Epoch 8/10, Batch 40/49, Loss: 0.2593
Epoch 8/10, Train Loss: 0.2422, Valid Loss: 0.3134
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2310
Epoch 9/10, Batch 20/49, Loss: 0.2510
Epoch 9/10, Batch 30/49, Loss: 0.4307
Epoch 9/10, Batch 40/49, Loss: 0.2442
Epoch 9/10, Train Loss: 0.2256, Valid Loss: 0.3031
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2347
Epoch 10/10, Batch 20/49, Loss: 0.2108
Epoch 10/10, Batch 30/49, Loss: 0.2259
Epoch 10/10, Batch 40/49, Loss: 0.1690
Epoch 10/10, Train Loss: 0.1988, Valid Loss: 0.2820
Model saved!
Accuracy: 0.9007
Precision: 0.8971
Recall: 0.9007
F1-score: 0.8961
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2759
Epoch 1/10, Batch 20/49, Loss: 1.0537
Epoch 1/10, Batch 30/49, Loss: 0.8246
Epoch 1/10, Batch 40/49, Loss: 0.7702
Epoch 1/10, Train Loss: 0.9983, Valid Loss: 0.6588
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6077
Epoch 2/10, Batch 20/49, Loss: 0.4547
Epoch 2/10, Batch 30/49, Loss: 0.5028
Epoch 2/10, Batch 40/49, Loss: 0.5361
Epoch 2/10, Train Loss: 0.5336, Valid Loss: 0.4745
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3219
Epoch 3/10, Batch 20/49, Loss: 0.4227
Epoch 3/10, Batch 30/49, Loss: 0.3897
Epoch 3/10, Batch 40/49, Loss: 0.3322
Epoch 3/10, Train Loss: 0.4153, Valid Loss: 0.3888
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2804
Epoch 4/10, Batch 20/49, Loss: 0.4490
Epoch 4/10, Batch 30/49, Loss: 0.2583
Epoch 4/10, Batch 40/49, Loss: 0.2642
Epoch 4/10, Train Loss: 0.3541, Valid Loss: 0.3513
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3204
Epoch 5/10, Batch 20/49, Loss: 0.2387
Epoch 5/10, Batch 30/49, Loss: 0.3159
Epoch 5/10, Batch 40/49, Loss: 0.2156
Epoch 5/10, Train Loss: 0.3080, Valid Loss: 0.3165
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2058
Epoch 6/10, Batch 20/49, Loss: 0.3248
Epoch 6/10, Batch 30/49, Loss: 0.2404
Epoch 6/10, Batch 40/49, Loss: 0.2861
Epoch 6/10, Train Loss: 0.2906, Valid Loss: 0.2942
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2897
Epoch 7/10, Batch 20/49, Loss: 0.1380
Epoch 7/10, Batch 30/49, Loss: 0.3275
Epoch 7/10, Batch 40/49, Loss: 0.1945
Epoch 7/10, Train Loss: 0.2637, Valid Loss: 0.2913
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2670
Epoch 8/10, Batch 20/49, Loss: 0.3378
Epoch 8/10, Batch 30/49, Loss: 0.1860
Epoch 8/10, Batch 40/49, Loss: 0.2049
Epoch 8/10, Train Loss: 0.2525, Valid Loss: 0.2796
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2775
Epoch 9/10, Batch 20/49, Loss: 0.2030
Epoch 9/10, Batch 30/49, Loss: 0.4677
Epoch 9/10, Batch 40/49, Loss: 0.1664
Epoch 9/10, Train Loss: 0.2412, Valid Loss: 0.2616
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1580
Epoch 10/10, Batch 20/49, Loss: 0.1822
Epoch 10/10, Batch 30/49, Loss: 0.2855
Epoch 10/10, Batch 40/49, Loss: 0.2451
Epoch 10/10, Train Loss: 0.2160, Valid Loss: 0.2581
Model saved!
Accuracy: 0.9136
Precision: 0.9115
Recall: 0.9136
F1-score: 0.9111
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2281
Epoch 1/10, Batch 20/49, Loss: 0.9599
Epoch 1/10, Batch 30/49, Loss: 0.7761
Epoch 1/10, Batch 40/49, Loss: 0.7171
Epoch 1/10, Train Loss: 1.0023, Valid Loss: 0.6349
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6227
Epoch 2/10, Batch 20/49, Loss: 0.4498
Epoch 2/10, Batch 30/49, Loss: 0.4631
Epoch 2/10, Batch 40/49, Loss: 0.4926
Epoch 2/10, Train Loss: 0.5358, Valid Loss: 0.4497
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4388
Epoch 3/10, Batch 20/49, Loss: 0.4133
Epoch 3/10, Batch 30/49, Loss: 0.4669
Epoch 3/10, Batch 40/49, Loss: 0.3708
Epoch 3/10, Train Loss: 0.4041, Valid Loss: 0.3585
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3324
Epoch 4/10, Batch 20/49, Loss: 0.3308
Epoch 4/10, Batch 30/49, Loss: 0.2275
Epoch 4/10, Batch 40/49, Loss: 0.2927
Epoch 4/10, Train Loss: 0.3594, Valid Loss: 0.3259
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2739
Epoch 5/10, Batch 20/49, Loss: 0.2404
Epoch 5/10, Batch 30/49, Loss: 0.2140
Epoch 5/10, Batch 40/49, Loss: 0.2297
Epoch 5/10, Train Loss: 0.3040, Valid Loss: 0.2965
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3471
Epoch 6/10, Batch 20/49, Loss: 0.3524
Epoch 6/10, Batch 30/49, Loss: 0.2345
Epoch 6/10, Batch 40/49, Loss: 0.2855
Epoch 6/10, Train Loss: 0.2831, Valid Loss: 0.2836
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2009
Epoch 7/10, Batch 20/49, Loss: 0.2213
Epoch 7/10, Batch 30/49, Loss: 0.3153
Epoch 7/10, Batch 40/49, Loss: 0.2200
Epoch 7/10, Train Loss: 0.2659, Valid Loss: 0.2779
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2125
Epoch 8/10, Batch 20/49, Loss: 0.2428
Epoch 8/10, Batch 30/49, Loss: 0.2098
Epoch 8/10, Batch 40/49, Loss: 0.2173
Epoch 8/10, Train Loss: 0.2412, Valid Loss: 0.2738
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2169
Epoch 9/10, Batch 20/49, Loss: 0.3747
Epoch 9/10, Batch 30/49, Loss: 0.3506
Epoch 9/10, Batch 40/49, Loss: 0.1466
Epoch 9/10, Train Loss: 0.2435, Valid Loss: 0.2579
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1597
Epoch 10/10, Batch 20/49, Loss: 0.1466
Epoch 10/10, Batch 30/49, Loss: 0.2371
Epoch 10/10, Batch 40/49, Loss: 0.2833
Epoch 10/10, Train Loss: 0.2121, Valid Loss: 0.2518
Model saved!
Accuracy: 0.9042
Precision: 0.9029
Recall: 0.9042
F1-score: 0.8987
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2764
Epoch 1/10, Batch 20/49, Loss: 1.0437
Epoch 1/10, Batch 30/49, Loss: 0.8101
Epoch 1/10, Batch 40/49, Loss: 0.6824
Epoch 1/10, Train Loss: 0.9811, Valid Loss: 0.6330
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6465
Epoch 2/10, Batch 20/49, Loss: 0.4467
Epoch 2/10, Batch 30/49, Loss: 0.5860
Epoch 2/10, Batch 40/49, Loss: 0.3967
Epoch 2/10, Train Loss: 0.5197, Valid Loss: 0.4505
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5230
Epoch 3/10, Batch 20/49, Loss: 0.3228
Epoch 3/10, Batch 30/49, Loss: 0.4020
Epoch 3/10, Batch 40/49, Loss: 0.2857
Epoch 3/10, Train Loss: 0.4068, Valid Loss: 0.3699
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2497
Epoch 4/10, Batch 20/49, Loss: 0.3999
Epoch 4/10, Batch 30/49, Loss: 0.2479
Epoch 4/10, Batch 40/49, Loss: 0.1940
Epoch 4/10, Train Loss: 0.3452, Valid Loss: 0.3257
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2059
Epoch 5/10, Batch 20/49, Loss: 0.1291
Epoch 5/10, Batch 30/49, Loss: 0.3046
Epoch 5/10, Batch 40/49, Loss: 0.3171
Epoch 5/10, Train Loss: 0.2925, Valid Loss: 0.2924
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1718
Epoch 6/10, Batch 20/49, Loss: 0.1260
Epoch 6/10, Batch 30/49, Loss: 0.3316
Epoch 6/10, Batch 40/49, Loss: 0.2838
Epoch 6/10, Train Loss: 0.2726, Valid Loss: 0.2716
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1942
Epoch 7/10, Batch 20/49, Loss: 0.1353
Epoch 7/10, Batch 30/49, Loss: 0.2289
Epoch 7/10, Batch 40/49, Loss: 0.3437
Epoch 7/10, Train Loss: 0.2502, Valid Loss: 0.2639
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.4059
Epoch 8/10, Batch 20/49, Loss: 0.2070
Epoch 8/10, Batch 30/49, Loss: 0.2150
Epoch 8/10, Batch 40/49, Loss: 0.1952
Epoch 8/10, Train Loss: 0.2392, Valid Loss: 0.2442
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1534
Epoch 9/10, Batch 20/49, Loss: 0.1776
Epoch 9/10, Batch 30/49, Loss: 0.5479
Epoch 9/10, Batch 40/49, Loss: 0.2353
Epoch 9/10, Train Loss: 0.2333, Valid Loss: 0.2387
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2577
Epoch 10/10, Batch 20/49, Loss: 0.1366
Epoch 10/10, Batch 30/49, Loss: 0.1675
Epoch 10/10, Batch 40/49, Loss: 0.1687
Epoch 10/10, Train Loss: 0.2027, Valid Loss: 0.2339
Model saved!
Accuracy: 0.9100
Precision: 0.9057
Recall: 0.9100
F1-score: 0.9068
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3084
Epoch 1/10, Batch 20/49, Loss: 1.0845
Epoch 1/10, Batch 30/49, Loss: 0.8251
Epoch 1/10, Batch 40/49, Loss: 0.8037
Epoch 1/10, Train Loss: 0.9959, Valid Loss: 0.6003
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6061
Epoch 2/10, Batch 20/49, Loss: 0.4322
Epoch 2/10, Batch 30/49, Loss: 0.4752
Epoch 2/10, Batch 40/49, Loss: 0.4984
Epoch 2/10, Train Loss: 0.5301, Valid Loss: 0.4413
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5193
Epoch 3/10, Batch 20/49, Loss: 0.5166
Epoch 3/10, Batch 30/49, Loss: 0.3699
Epoch 3/10, Batch 40/49, Loss: 0.4093
Epoch 3/10, Train Loss: 0.4176, Valid Loss: 0.3729
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3171
Epoch 4/10, Batch 20/49, Loss: 0.4440
Epoch 4/10, Batch 30/49, Loss: 0.2201
Epoch 4/10, Batch 40/49, Loss: 0.2778
Epoch 4/10, Train Loss: 0.3426, Valid Loss: 0.3285
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2207
Epoch 5/10, Batch 20/49, Loss: 0.2197
Epoch 5/10, Batch 30/49, Loss: 0.3008
Epoch 5/10, Batch 40/49, Loss: 0.1980
Epoch 5/10, Train Loss: 0.2984, Valid Loss: 0.3201
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2551
Epoch 6/10, Batch 20/49, Loss: 0.2051
Epoch 6/10, Batch 30/49, Loss: 0.2455
Epoch 6/10, Batch 40/49, Loss: 0.2750
Epoch 6/10, Train Loss: 0.2833, Valid Loss: 0.3087
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3317
Epoch 7/10, Batch 20/49, Loss: 0.1955
Epoch 7/10, Batch 30/49, Loss: 0.3058
Epoch 7/10, Batch 40/49, Loss: 0.2164
Epoch 7/10, Train Loss: 0.2403, Valid Loss: 0.3255
Epoch 8/10, Batch 10/49, Loss: 0.2388
Epoch 8/10, Batch 20/49, Loss: 0.3333
Epoch 8/10, Batch 30/49, Loss: 0.2248
Epoch 8/10, Batch 40/49, Loss: 0.2308
Epoch 8/10, Train Loss: 0.2409, Valid Loss: 0.2892
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1418
Epoch 9/10, Batch 20/49, Loss: 0.3111
Epoch 9/10, Batch 30/49, Loss: 0.5652
Epoch 9/10, Batch 40/49, Loss: 0.1811
Epoch 9/10, Train Loss: 0.2259, Valid Loss: 0.2851
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2601
Epoch 10/10, Batch 20/49, Loss: 0.1064
Epoch 10/10, Batch 30/49, Loss: 0.2539
Epoch 10/10, Batch 40/49, Loss: 0.1820
Epoch 10/10, Train Loss: 0.2085, Valid Loss: 0.2773
Model saved!
Accuracy: 0.8937
Precision: 0.8905
Recall: 0.8937
F1-score: 0.8892
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2743
Epoch 1/10, Batch 20/49, Loss: 1.0448
Epoch 1/10, Batch 30/49, Loss: 0.8564
Epoch 1/10, Batch 40/49, Loss: 0.6993
Epoch 1/10, Train Loss: 0.9866, Valid Loss: 0.6733
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6373
Epoch 2/10, Batch 20/49, Loss: 0.4867
Epoch 2/10, Batch 30/49, Loss: 0.4465
Epoch 2/10, Batch 40/49, Loss: 0.5111
Epoch 2/10, Train Loss: 0.5300, Valid Loss: 0.4822
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3917
Epoch 3/10, Batch 20/49, Loss: 0.3617
Epoch 3/10, Batch 30/49, Loss: 0.3799
Epoch 3/10, Batch 40/49, Loss: 0.2788
Epoch 3/10, Train Loss: 0.4102, Valid Loss: 0.4057
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3610
Epoch 4/10, Batch 20/49, Loss: 0.3487
Epoch 4/10, Batch 30/49, Loss: 0.3697
Epoch 4/10, Batch 40/49, Loss: 0.2882
Epoch 4/10, Train Loss: 0.3484, Valid Loss: 0.3482
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3422
Epoch 5/10, Batch 20/49, Loss: 0.2282
Epoch 5/10, Batch 30/49, Loss: 0.2549
Epoch 5/10, Batch 40/49, Loss: 0.2094
Epoch 5/10, Train Loss: 0.3014, Valid Loss: 0.3175
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2087
Epoch 6/10, Batch 20/49, Loss: 0.2217
Epoch 6/10, Batch 30/49, Loss: 0.3161
Epoch 6/10, Batch 40/49, Loss: 0.2601
Epoch 6/10, Train Loss: 0.2834, Valid Loss: 0.3158
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2015
Epoch 7/10, Batch 20/49, Loss: 0.1781
Epoch 7/10, Batch 30/49, Loss: 0.4043
Epoch 7/10, Batch 40/49, Loss: 0.1435
Epoch 7/10, Train Loss: 0.2633, Valid Loss: 0.3044
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2570
Epoch 8/10, Batch 20/49, Loss: 0.2307
Epoch 8/10, Batch 30/49, Loss: 0.3013
Epoch 8/10, Batch 40/49, Loss: 0.2464
Epoch 8/10, Train Loss: 0.2373, Valid Loss: 0.2840
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2466
Epoch 9/10, Batch 20/49, Loss: 0.1926
Epoch 9/10, Batch 30/49, Loss: 0.5349
Epoch 9/10, Batch 40/49, Loss: 0.2203
Epoch 9/10, Train Loss: 0.2214, Valid Loss: 0.2686
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1525
Epoch 10/10, Batch 20/49, Loss: 0.1492
Epoch 10/10, Batch 30/49, Loss: 0.3737
Epoch 10/10, Batch 40/49, Loss: 0.2511
Epoch 10/10, Train Loss: 0.2073, Valid Loss: 0.2677
Model saved!
Accuracy: 0.9030
Precision: 0.8988
Recall: 0.9030
F1-score: 0.8989
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2717
Epoch 1/10, Batch 20/49, Loss: 1.0039
Epoch 1/10, Batch 30/49, Loss: 0.8221
Epoch 1/10, Batch 40/49, Loss: 0.6994
Epoch 1/10, Train Loss: 0.9953, Valid Loss: 0.6053
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7367
Epoch 2/10, Batch 20/49, Loss: 0.4101
Epoch 2/10, Batch 30/49, Loss: 0.5907
Epoch 2/10, Batch 40/49, Loss: 0.4641
Epoch 2/10, Train Loss: 0.5262, Valid Loss: 0.4359
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3103
Epoch 3/10, Batch 20/49, Loss: 0.5072
Epoch 3/10, Batch 30/49, Loss: 0.3657
Epoch 3/10, Batch 40/49, Loss: 0.3269
Epoch 3/10, Train Loss: 0.4107, Valid Loss: 0.3660
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2184
Epoch 4/10, Batch 20/49, Loss: 0.3978
Epoch 4/10, Batch 30/49, Loss: 0.2326
Epoch 4/10, Batch 40/49, Loss: 0.2177
Epoch 4/10, Train Loss: 0.3455, Valid Loss: 0.3281
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3447
Epoch 5/10, Batch 20/49, Loss: 0.3079
Epoch 5/10, Batch 30/49, Loss: 0.2723
Epoch 5/10, Batch 40/49, Loss: 0.3135
Epoch 5/10, Train Loss: 0.3007, Valid Loss: 0.2982
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3252
Epoch 6/10, Batch 20/49, Loss: 0.2694
Epoch 6/10, Batch 30/49, Loss: 0.3405
Epoch 6/10, Batch 40/49, Loss: 0.1705
Epoch 6/10, Train Loss: 0.2756, Valid Loss: 0.2820
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3939
Epoch 7/10, Batch 20/49, Loss: 0.1790
Epoch 7/10, Batch 30/49, Loss: 0.2118
Epoch 7/10, Batch 40/49, Loss: 0.2432
Epoch 7/10, Train Loss: 0.2538, Valid Loss: 0.2718
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1883
Epoch 8/10, Batch 20/49, Loss: 0.2020
Epoch 8/10, Batch 30/49, Loss: 0.3188
Epoch 8/10, Batch 40/49, Loss: 0.2659
Epoch 8/10, Train Loss: 0.2428, Valid Loss: 0.2655
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1391
Epoch 9/10, Batch 20/49, Loss: 0.1285
Epoch 9/10, Batch 30/49, Loss: 0.5923
Epoch 9/10, Batch 40/49, Loss: 0.1624
Epoch 9/10, Train Loss: 0.2326, Valid Loss: 0.2514
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3243
Epoch 10/10, Batch 20/49, Loss: 0.1490
Epoch 10/10, Batch 30/49, Loss: 0.3485
Epoch 10/10, Batch 40/49, Loss: 0.1829
Epoch 10/10, Train Loss: 0.2074, Valid Loss: 0.2451
Model saved!
Accuracy: 0.9054
Precision: 0.9024
Recall: 0.9054
F1-score: 0.9026
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1908
Epoch 1/10, Batch 20/49, Loss: 1.0647
Epoch 1/10, Batch 30/49, Loss: 0.8441
Epoch 1/10, Batch 40/49, Loss: 0.7931
Epoch 1/10, Train Loss: 0.9962, Valid Loss: 0.6368
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.8056
Epoch 2/10, Batch 20/49, Loss: 0.4697
Epoch 2/10, Batch 30/49, Loss: 0.5459
Epoch 2/10, Batch 40/49, Loss: 0.4146
Epoch 2/10, Train Loss: 0.5275, Valid Loss: 0.4731
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4230
Epoch 3/10, Batch 20/49, Loss: 0.5203
Epoch 3/10, Batch 30/49, Loss: 0.3164
Epoch 3/10, Batch 40/49, Loss: 0.2117
Epoch 3/10, Train Loss: 0.4045, Valid Loss: 0.3812
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3079
Epoch 4/10, Batch 20/49, Loss: 0.3886
Epoch 4/10, Batch 30/49, Loss: 0.2914
Epoch 4/10, Batch 40/49, Loss: 0.2887
Epoch 4/10, Train Loss: 0.3524, Valid Loss: 0.3496
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2940
Epoch 5/10, Batch 20/49, Loss: 0.1945
Epoch 5/10, Batch 30/49, Loss: 0.2013
Epoch 5/10, Batch 40/49, Loss: 0.2161
Epoch 5/10, Train Loss: 0.2904, Valid Loss: 0.3178
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2107
Epoch 6/10, Batch 20/49, Loss: 0.3736
Epoch 6/10, Batch 30/49, Loss: 0.2472
Epoch 6/10, Batch 40/49, Loss: 0.2977
Epoch 6/10, Train Loss: 0.2680, Valid Loss: 0.3062
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2530
Epoch 7/10, Batch 20/49, Loss: 0.2279
Epoch 7/10, Batch 30/49, Loss: 0.2414
Epoch 7/10, Batch 40/49, Loss: 0.2967
Epoch 7/10, Train Loss: 0.2551, Valid Loss: 0.2973
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1737
Epoch 8/10, Batch 20/49, Loss: 0.1873
Epoch 8/10, Batch 30/49, Loss: 0.1380
Epoch 8/10, Batch 40/49, Loss: 0.1516
Epoch 8/10, Train Loss: 0.2316, Valid Loss: 0.2821
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2257
Epoch 9/10, Batch 20/49, Loss: 0.2147
Epoch 9/10, Batch 30/49, Loss: 0.4126
Epoch 9/10, Batch 40/49, Loss: 0.1650
Epoch 9/10, Train Loss: 0.2347, Valid Loss: 0.2663
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2221
Epoch 10/10, Batch 20/49, Loss: 0.1654
Epoch 10/10, Batch 30/49, Loss: 0.3412
Epoch 10/10, Batch 40/49, Loss: 0.1309
Epoch 10/10, Train Loss: 0.1951, Valid Loss: 0.2702
Accuracy: 0.9019
Precision: 0.8983
Recall: 0.9019
F1-score: 0.8997
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2328
Epoch 1/10, Batch 20/49, Loss: 0.9996
Epoch 1/10, Batch 30/49, Loss: 0.8112
Epoch 1/10, Batch 40/49, Loss: 0.6750
Epoch 1/10, Train Loss: 0.9906, Valid Loss: 0.6510
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6741
Epoch 2/10, Batch 20/49, Loss: 0.5512
Epoch 2/10, Batch 30/49, Loss: 0.4825
Epoch 2/10, Batch 40/49, Loss: 0.5838
Epoch 2/10, Train Loss: 0.5270, Valid Loss: 0.4611
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.6006
Epoch 3/10, Batch 20/49, Loss: 0.2840
Epoch 3/10, Batch 30/49, Loss: 0.3413
Epoch 3/10, Batch 40/49, Loss: 0.3854
Epoch 3/10, Train Loss: 0.4083, Valid Loss: 0.3978
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3355
Epoch 4/10, Batch 20/49, Loss: 0.3575
Epoch 4/10, Batch 30/49, Loss: 0.3014
Epoch 4/10, Batch 40/49, Loss: 0.2597
Epoch 4/10, Train Loss: 0.3615, Valid Loss: 0.3425
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3866
Epoch 5/10, Batch 20/49, Loss: 0.2383
Epoch 5/10, Batch 30/49, Loss: 0.2388
Epoch 5/10, Batch 40/49, Loss: 0.2089
Epoch 5/10, Train Loss: 0.2988, Valid Loss: 0.3248
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3113
Epoch 6/10, Batch 20/49, Loss: 0.2917
Epoch 6/10, Batch 30/49, Loss: 0.2770
Epoch 6/10, Batch 40/49, Loss: 0.2202
Epoch 6/10, Train Loss: 0.2725, Valid Loss: 0.3253
Epoch 7/10, Batch 10/49, Loss: 0.2266
Epoch 7/10, Batch 20/49, Loss: 0.3339
Epoch 7/10, Batch 30/49, Loss: 0.3439
Epoch 7/10, Batch 40/49, Loss: 0.3039
Epoch 7/10, Train Loss: 0.2596, Valid Loss: 0.3146
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2006
Epoch 8/10, Batch 20/49, Loss: 0.2677
Epoch 8/10, Batch 30/49, Loss: 0.1383
Epoch 8/10, Batch 40/49, Loss: 0.1535
Epoch 8/10, Train Loss: 0.2507, Valid Loss: 0.2894
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2814
Epoch 9/10, Batch 20/49, Loss: 0.1604
Epoch 9/10, Batch 30/49, Loss: 0.4259
Epoch 9/10, Batch 40/49, Loss: 0.1143
Epoch 9/10, Train Loss: 0.2225, Valid Loss: 0.2916
Epoch 10/10, Batch 10/49, Loss: 0.2433
Epoch 10/10, Batch 20/49, Loss: 0.1502
Epoch 10/10, Batch 30/49, Loss: 0.3765
Epoch 10/10, Batch 40/49, Loss: 0.2858
Epoch 10/10, Train Loss: 0.2129, Valid Loss: 0.2721
Model saved!
Accuracy: 0.9077
Precision: 0.9033
Recall: 0.9077
F1-score: 0.9043
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3149
Epoch 1/10, Batch 20/49, Loss: 1.0092
Epoch 1/10, Batch 30/49, Loss: 0.8776
Epoch 1/10, Batch 40/49, Loss: 0.7809
Epoch 1/10, Train Loss: 1.0071, Valid Loss: 0.6467
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7704
Epoch 2/10, Batch 20/49, Loss: 0.4387
Epoch 2/10, Batch 30/49, Loss: 0.4753
Epoch 2/10, Batch 40/49, Loss: 0.5531
Epoch 2/10, Train Loss: 0.5398, Valid Loss: 0.4776
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3988
Epoch 3/10, Batch 20/49, Loss: 0.5063
Epoch 3/10, Batch 30/49, Loss: 0.4502
Epoch 3/10, Batch 40/49, Loss: 0.2356
Epoch 3/10, Train Loss: 0.4126, Valid Loss: 0.4123
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3541
Epoch 4/10, Batch 20/49, Loss: 0.4221
Epoch 4/10, Batch 30/49, Loss: 0.3021
Epoch 4/10, Batch 40/49, Loss: 0.2303
Epoch 4/10, Train Loss: 0.3607, Valid Loss: 0.3737
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3725
Epoch 5/10, Batch 20/49, Loss: 0.2002
Epoch 5/10, Batch 30/49, Loss: 0.3148
Epoch 5/10, Batch 40/49, Loss: 0.1808
Epoch 5/10, Train Loss: 0.3082, Valid Loss: 0.3513
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1519
Epoch 6/10, Batch 20/49, Loss: 0.1652
Epoch 6/10, Batch 30/49, Loss: 0.3908
Epoch 6/10, Batch 40/49, Loss: 0.3230
Epoch 6/10, Train Loss: 0.2848, Valid Loss: 0.3418
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2051
Epoch 7/10, Batch 20/49, Loss: 0.2657
Epoch 7/10, Batch 30/49, Loss: 0.4924
Epoch 7/10, Batch 40/49, Loss: 0.1877
Epoch 7/10, Train Loss: 0.2577, Valid Loss: 0.3373
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1605
Epoch 8/10, Batch 20/49, Loss: 0.1644
Epoch 8/10, Batch 30/49, Loss: 0.2164
Epoch 8/10, Batch 40/49, Loss: 0.1701
Epoch 8/10, Train Loss: 0.2523, Valid Loss: 0.3309
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1749
Epoch 9/10, Batch 20/49, Loss: 0.1638
Epoch 9/10, Batch 30/49, Loss: 0.4221
Epoch 9/10, Batch 40/49, Loss: 0.1475
Epoch 9/10, Train Loss: 0.2307, Valid Loss: 0.3201
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2266
Epoch 10/10, Batch 20/49, Loss: 0.0843
Epoch 10/10, Batch 30/49, Loss: 0.1728
Epoch 10/10, Batch 40/49, Loss: 0.2983
Epoch 10/10, Train Loss: 0.2028, Valid Loss: 0.3057
Model saved!
Accuracy: 0.9019
Precision: 0.8982
Recall: 0.9019
F1-score: 0.8982
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2674
Epoch 1/10, Batch 20/49, Loss: 1.0329
Epoch 1/10, Batch 30/49, Loss: 0.7865
Epoch 1/10, Batch 40/49, Loss: 0.7329
Epoch 1/10, Train Loss: 0.9844, Valid Loss: 0.6421
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6163
Epoch 2/10, Batch 20/49, Loss: 0.3751
Epoch 2/10, Batch 30/49, Loss: 0.5542
Epoch 2/10, Batch 40/49, Loss: 0.5598
Epoch 2/10, Train Loss: 0.5203, Valid Loss: 0.4451
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4258
Epoch 3/10, Batch 20/49, Loss: 0.4209
Epoch 3/10, Batch 30/49, Loss: 0.3524
Epoch 3/10, Batch 40/49, Loss: 0.3230
Epoch 3/10, Train Loss: 0.4029, Valid Loss: 0.3732
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3255
Epoch 4/10, Batch 20/49, Loss: 0.2987
Epoch 4/10, Batch 30/49, Loss: 0.3310
Epoch 4/10, Batch 40/49, Loss: 0.3160
Epoch 4/10, Train Loss: 0.3479, Valid Loss: 0.3412
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2980
Epoch 5/10, Batch 20/49, Loss: 0.2262
Epoch 5/10, Batch 30/49, Loss: 0.3251
Epoch 5/10, Batch 40/49, Loss: 0.2232
Epoch 5/10, Train Loss: 0.2980, Valid Loss: 0.3024
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3190
Epoch 6/10, Batch 20/49, Loss: 0.2224
Epoch 6/10, Batch 30/49, Loss: 0.3191
Epoch 6/10, Batch 40/49, Loss: 0.2056
Epoch 6/10, Train Loss: 0.2661, Valid Loss: 0.2833
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2350
Epoch 7/10, Batch 20/49, Loss: 0.1972
Epoch 7/10, Batch 30/49, Loss: 0.2612
Epoch 7/10, Batch 40/49, Loss: 0.1962
Epoch 7/10, Train Loss: 0.2540, Valid Loss: 0.2819
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2029
Epoch 8/10, Batch 20/49, Loss: 0.1603
Epoch 8/10, Batch 30/49, Loss: 0.2264
Epoch 8/10, Batch 40/49, Loss: 0.4261
Epoch 8/10, Train Loss: 0.2391, Valid Loss: 0.2624
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2873
Epoch 9/10, Batch 20/49, Loss: 0.2232
Epoch 9/10, Batch 30/49, Loss: 0.3592
Epoch 9/10, Batch 40/49, Loss: 0.1797
Epoch 9/10, Train Loss: 0.2251, Valid Loss: 0.2716
Epoch 10/10, Batch 10/49, Loss: 0.2677
Epoch 10/10, Batch 20/49, Loss: 0.1316
Epoch 10/10, Batch 30/49, Loss: 0.1619
Epoch 10/10, Batch 40/49, Loss: 0.1554
Epoch 10/10, Train Loss: 0.1932, Valid Loss: 0.2563
Model saved!
Accuracy: 0.9136
Precision: 0.9102
Recall: 0.9136
F1-score: 0.9107
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2486
Epoch 1/10, Batch 20/49, Loss: 1.0842
Epoch 1/10, Batch 30/49, Loss: 0.7846
Epoch 1/10, Batch 40/49, Loss: 0.8085
Epoch 1/10, Train Loss: 0.9880, Valid Loss: 0.6323
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5968
Epoch 2/10, Batch 20/49, Loss: 0.4611
Epoch 2/10, Batch 30/49, Loss: 0.4842
Epoch 2/10, Batch 40/49, Loss: 0.4387
Epoch 2/10, Train Loss: 0.5262, Valid Loss: 0.4533
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4248
Epoch 3/10, Batch 20/49, Loss: 0.4192
Epoch 3/10, Batch 30/49, Loss: 0.3435
Epoch 3/10, Batch 40/49, Loss: 0.2847
Epoch 3/10, Train Loss: 0.4022, Valid Loss: 0.3811
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3354
Epoch 4/10, Batch 20/49, Loss: 0.3610
Epoch 4/10, Batch 30/49, Loss: 0.2712
Epoch 4/10, Batch 40/49, Loss: 0.2687
Epoch 4/10, Train Loss: 0.3485, Valid Loss: 0.3380
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3578
Epoch 5/10, Batch 20/49, Loss: 0.3119
Epoch 5/10, Batch 30/49, Loss: 0.3615
Epoch 5/10, Batch 40/49, Loss: 0.2225
Epoch 5/10, Train Loss: 0.2925, Valid Loss: 0.3090
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3440
Epoch 6/10, Batch 20/49, Loss: 0.1844
Epoch 6/10, Batch 30/49, Loss: 0.3146
Epoch 6/10, Batch 40/49, Loss: 0.2144
Epoch 6/10, Train Loss: 0.2679, Valid Loss: 0.3045
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2352
Epoch 7/10, Batch 20/49, Loss: 0.2066
Epoch 7/10, Batch 30/49, Loss: 0.3072
Epoch 7/10, Batch 40/49, Loss: 0.1965
Epoch 7/10, Train Loss: 0.2495, Valid Loss: 0.2980
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3224
Epoch 8/10, Batch 20/49, Loss: 0.2815
Epoch 8/10, Batch 30/49, Loss: 0.2202
Epoch 8/10, Batch 40/49, Loss: 0.1712
Epoch 8/10, Train Loss: 0.2298, Valid Loss: 0.2809
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2088
Epoch 9/10, Batch 20/49, Loss: 0.1531
Epoch 9/10, Batch 30/49, Loss: 0.4889
Epoch 9/10, Batch 40/49, Loss: 0.1849
Epoch 9/10, Train Loss: 0.2147, Valid Loss: 0.2686
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3330
Epoch 10/10, Batch 20/49, Loss: 0.1461
Epoch 10/10, Batch 30/49, Loss: 0.1711
Epoch 10/10, Batch 40/49, Loss: 0.1822
Epoch 10/10, Train Loss: 0.1997, Valid Loss: 0.2614
Model saved!
Accuracy: 0.9089
Precision: 0.9045
Recall: 0.9089
F1-score: 0.9048
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2350
Epoch 1/10, Batch 20/49, Loss: 0.9690
Epoch 1/10, Batch 30/49, Loss: 0.8594
Epoch 1/10, Batch 40/49, Loss: 0.8597
Epoch 1/10, Train Loss: 0.9768, Valid Loss: 0.6326
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5841
Epoch 2/10, Batch 20/49, Loss: 0.3890
Epoch 2/10, Batch 30/49, Loss: 0.7575
Epoch 2/10, Batch 40/49, Loss: 0.6000
Epoch 2/10, Train Loss: 0.5225, Valid Loss: 0.4586
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3097
Epoch 3/10, Batch 20/49, Loss: 0.4542
Epoch 3/10, Batch 30/49, Loss: 0.3598
Epoch 3/10, Batch 40/49, Loss: 0.2214
Epoch 3/10, Train Loss: 0.4102, Valid Loss: 0.3965
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2398
Epoch 4/10, Batch 20/49, Loss: 0.5055
Epoch 4/10, Batch 30/49, Loss: 0.2284
Epoch 4/10, Batch 40/49, Loss: 0.3670
Epoch 4/10, Train Loss: 0.3577, Valid Loss: 0.3326
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3248
Epoch 5/10, Batch 20/49, Loss: 0.2066
Epoch 5/10, Batch 30/49, Loss: 0.2456
Epoch 5/10, Batch 40/49, Loss: 0.2801
Epoch 5/10, Train Loss: 0.2891, Valid Loss: 0.3091
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1725
Epoch 6/10, Batch 20/49, Loss: 0.3696
Epoch 6/10, Batch 30/49, Loss: 0.3921
Epoch 6/10, Batch 40/49, Loss: 0.2333
Epoch 6/10, Train Loss: 0.2775, Valid Loss: 0.2959
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2025
Epoch 7/10, Batch 20/49, Loss: 0.1026
Epoch 7/10, Batch 30/49, Loss: 0.3965
Epoch 7/10, Batch 40/49, Loss: 0.2465
Epoch 7/10, Train Loss: 0.2531, Valid Loss: 0.2919
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3019
Epoch 8/10, Batch 20/49, Loss: 0.2556
Epoch 8/10, Batch 30/49, Loss: 0.4032
Epoch 8/10, Batch 40/49, Loss: 0.1955
Epoch 8/10, Train Loss: 0.2439, Valid Loss: 0.2779
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2227
Epoch 9/10, Batch 20/49, Loss: 0.2358
Epoch 9/10, Batch 30/49, Loss: 0.5379
Epoch 9/10, Batch 40/49, Loss: 0.1574
Epoch 9/10, Train Loss: 0.2268, Valid Loss: 0.2571
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2450
Epoch 10/10, Batch 20/49, Loss: 0.1571
Epoch 10/10, Batch 30/49, Loss: 0.3398
Epoch 10/10, Batch 40/49, Loss: 0.2239
Epoch 10/10, Train Loss: 0.1962, Valid Loss: 0.2426
Model saved!
Accuracy: 0.8984
Precision: 0.8935
Recall: 0.8984
F1-score: 0.8940
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3117
Epoch 1/10, Batch 20/49, Loss: 1.0245
Epoch 1/10, Batch 30/49, Loss: 0.9153
Epoch 1/10, Batch 40/49, Loss: 0.6759
Epoch 1/10, Train Loss: 1.0046, Valid Loss: 0.6523
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5665
Epoch 2/10, Batch 20/49, Loss: 0.4078
Epoch 2/10, Batch 30/49, Loss: 0.5341
Epoch 2/10, Batch 40/49, Loss: 0.4991
Epoch 2/10, Train Loss: 0.5432, Valid Loss: 0.4711
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4637
Epoch 3/10, Batch 20/49, Loss: 0.4183
Epoch 3/10, Batch 30/49, Loss: 0.4136
Epoch 3/10, Batch 40/49, Loss: 0.2483
Epoch 3/10, Train Loss: 0.4204, Valid Loss: 0.4110
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2720
Epoch 4/10, Batch 20/49, Loss: 0.4477
Epoch 4/10, Batch 30/49, Loss: 0.3075
Epoch 4/10, Batch 40/49, Loss: 0.2618
Epoch 4/10, Train Loss: 0.3512, Valid Loss: 0.3461
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2265
Epoch 5/10, Batch 20/49, Loss: 0.2575
Epoch 5/10, Batch 30/49, Loss: 0.1949
Epoch 5/10, Batch 40/49, Loss: 0.1656
Epoch 5/10, Train Loss: 0.3081, Valid Loss: 0.3232
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2252
Epoch 6/10, Batch 20/49, Loss: 0.3095
Epoch 6/10, Batch 30/49, Loss: 0.3810
Epoch 6/10, Batch 40/49, Loss: 0.2405
Epoch 6/10, Train Loss: 0.2786, Valid Loss: 0.3113
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2726
Epoch 7/10, Batch 20/49, Loss: 0.2033
Epoch 7/10, Batch 30/49, Loss: 0.4433
Epoch 7/10, Batch 40/49, Loss: 0.2030
Epoch 7/10, Train Loss: 0.2603, Valid Loss: 0.3001
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2580
Epoch 8/10, Batch 20/49, Loss: 0.3301
Epoch 8/10, Batch 30/49, Loss: 0.3576
Epoch 8/10, Batch 40/49, Loss: 0.2249
Epoch 8/10, Train Loss: 0.2490, Valid Loss: 0.2876
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1252
Epoch 9/10, Batch 20/49, Loss: 0.3488
Epoch 9/10, Batch 30/49, Loss: 0.4765
Epoch 9/10, Batch 40/49, Loss: 0.1775
Epoch 9/10, Train Loss: 0.2298, Valid Loss: 0.2788
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1397
Epoch 10/10, Batch 20/49, Loss: 0.1245
Epoch 10/10, Batch 30/49, Loss: 0.2730
Epoch 10/10, Batch 40/49, Loss: 0.1774
Epoch 10/10, Train Loss: 0.2056, Valid Loss: 0.2705
Model saved!
Accuracy: 0.8960
Precision: 0.8920
Recall: 0.8960
F1-score: 0.8908
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3025
Epoch 1/10, Batch 20/49, Loss: 0.9944
Epoch 1/10, Batch 30/49, Loss: 0.7901
Epoch 1/10, Batch 40/49, Loss: 0.7825
Epoch 1/10, Train Loss: 0.9915, Valid Loss: 0.6965
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6526
Epoch 2/10, Batch 20/49, Loss: 0.4678
Epoch 2/10, Batch 30/49, Loss: 0.5577
Epoch 2/10, Batch 40/49, Loss: 0.5166
Epoch 2/10, Train Loss: 0.5233, Valid Loss: 0.5523
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4622
Epoch 3/10, Batch 20/49, Loss: 0.4117
Epoch 3/10, Batch 30/49, Loss: 0.3474
Epoch 3/10, Batch 40/49, Loss: 0.5298
Epoch 3/10, Train Loss: 0.4108, Valid Loss: 0.5137
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2265
Epoch 4/10, Batch 20/49, Loss: 0.4341
Epoch 4/10, Batch 30/49, Loss: 0.3202
Epoch 4/10, Batch 40/49, Loss: 0.2605
Epoch 4/10, Train Loss: 0.3454, Valid Loss: 0.4606
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4363
Epoch 5/10, Batch 20/49, Loss: 0.3096
Epoch 5/10, Batch 30/49, Loss: 0.2419
Epoch 5/10, Batch 40/49, Loss: 0.2318
Epoch 5/10, Train Loss: 0.2969, Valid Loss: 0.4813
Epoch 6/10, Batch 10/49, Loss: 0.1942
Epoch 6/10, Batch 20/49, Loss: 0.2624
Epoch 6/10, Batch 30/49, Loss: 0.3435
Epoch 6/10, Batch 40/49, Loss: 0.2037
Epoch 6/10, Train Loss: 0.2828, Valid Loss: 0.4834
Epoch 7/10, Batch 10/49, Loss: 0.2800
Epoch 7/10, Batch 20/49, Loss: 0.2064
Epoch 7/10, Batch 30/49, Loss: 0.2263
Epoch 7/10, Batch 40/49, Loss: 0.2480
Epoch 7/10, Train Loss: 0.2725, Valid Loss: 0.4987
Epoch 8/10, Batch 10/49, Loss: 0.2043
Epoch 8/10, Batch 20/49, Loss: 0.1736
Epoch 8/10, Batch 30/49, Loss: 0.2436
Epoch 8/10, Batch 40/49, Loss: 0.1739
Epoch 8/10, Train Loss: 0.2442, Valid Loss: 0.4389
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1004
Epoch 9/10, Batch 20/49, Loss: 0.1219
Epoch 9/10, Batch 30/49, Loss: 0.5338
Epoch 9/10, Batch 40/49, Loss: 0.1179
Epoch 9/10, Train Loss: 0.2273, Valid Loss: 0.4387
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2570
Epoch 10/10, Batch 20/49, Loss: 0.1763
Epoch 10/10, Batch 30/49, Loss: 0.1951
Epoch 10/10, Batch 40/49, Loss: 0.1938
Epoch 10/10, Train Loss: 0.2064, Valid Loss: 0.4164
Model saved!
Accuracy: 0.9100
Precision: 0.9069
Recall: 0.9100
F1-score: 0.9078
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2620
Epoch 1/10, Batch 20/49, Loss: 1.0253
Epoch 1/10, Batch 30/49, Loss: 0.8570
Epoch 1/10, Batch 40/49, Loss: 0.6987
Epoch 1/10, Train Loss: 0.9987, Valid Loss: 0.6386
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5841
Epoch 2/10, Batch 20/49, Loss: 0.5658
Epoch 2/10, Batch 30/49, Loss: 0.4657
Epoch 2/10, Batch 40/49, Loss: 0.5948
Epoch 2/10, Train Loss: 0.5230, Valid Loss: 0.4628
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5354
Epoch 3/10, Batch 20/49, Loss: 0.2803
Epoch 3/10, Batch 30/49, Loss: 0.3839
Epoch 3/10, Batch 40/49, Loss: 0.3378
Epoch 3/10, Train Loss: 0.4040, Valid Loss: 0.3897
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2925
Epoch 4/10, Batch 20/49, Loss: 0.3775
Epoch 4/10, Batch 30/49, Loss: 0.3401
Epoch 4/10, Batch 40/49, Loss: 0.1747
Epoch 4/10, Train Loss: 0.3535, Valid Loss: 0.3498
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2084
Epoch 5/10, Batch 20/49, Loss: 0.2255
Epoch 5/10, Batch 30/49, Loss: 0.1496
Epoch 5/10, Batch 40/49, Loss: 0.3033
Epoch 5/10, Train Loss: 0.2950, Valid Loss: 0.3158
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2414
Epoch 6/10, Batch 20/49, Loss: 0.2614
Epoch 6/10, Batch 30/49, Loss: 0.2678
Epoch 6/10, Batch 40/49, Loss: 0.2728
Epoch 6/10, Train Loss: 0.2703, Valid Loss: 0.3029
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2278
Epoch 7/10, Batch 20/49, Loss: 0.2548
Epoch 7/10, Batch 30/49, Loss: 0.3229
Epoch 7/10, Batch 40/49, Loss: 0.1700
Epoch 7/10, Train Loss: 0.2412, Valid Loss: 0.3025
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2037
Epoch 8/10, Batch 20/49, Loss: 0.1840
Epoch 8/10, Batch 30/49, Loss: 0.2291
Epoch 8/10, Batch 40/49, Loss: 0.1767
Epoch 8/10, Train Loss: 0.2328, Valid Loss: 0.2847
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2281
Epoch 9/10, Batch 20/49, Loss: 0.1373
Epoch 9/10, Batch 30/49, Loss: 0.5886
Epoch 9/10, Batch 40/49, Loss: 0.1929
Epoch 9/10, Train Loss: 0.2274, Valid Loss: 0.2807
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2481
Epoch 10/10, Batch 20/49, Loss: 0.2022
Epoch 10/10, Batch 30/49, Loss: 0.2202
Epoch 10/10, Batch 40/49, Loss: 0.1763
Epoch 10/10, Train Loss: 0.1991, Valid Loss: 0.2705
Model saved!
Accuracy: 0.9065
Precision: 0.9048
Recall: 0.9065
F1-score: 0.9037
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2204
Epoch 1/10, Batch 20/49, Loss: 1.0188
Epoch 1/10, Batch 30/49, Loss: 0.7850
Epoch 1/10, Batch 40/49, Loss: 0.7285
Epoch 1/10, Train Loss: 0.9994, Valid Loss: 0.7637
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6124
Epoch 2/10, Batch 20/49, Loss: 0.5357
Epoch 2/10, Batch 30/49, Loss: 0.5930
Epoch 2/10, Batch 40/49, Loss: 0.5816
Epoch 2/10, Train Loss: 0.5428, Valid Loss: 0.6145
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4530
Epoch 3/10, Batch 20/49, Loss: 0.4703
Epoch 3/10, Batch 30/49, Loss: 0.3102
Epoch 3/10, Batch 40/49, Loss: 0.4002
Epoch 3/10, Train Loss: 0.4202, Valid Loss: 0.5536
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3861
Epoch 4/10, Batch 20/49, Loss: 0.3719
Epoch 4/10, Batch 30/49, Loss: 0.2132
Epoch 4/10, Batch 40/49, Loss: 0.2727
Epoch 4/10, Train Loss: 0.3670, Valid Loss: 0.5024
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3524
Epoch 5/10, Batch 20/49, Loss: 0.2449
Epoch 5/10, Batch 30/49, Loss: 0.2917
Epoch 5/10, Batch 40/49, Loss: 0.2185
Epoch 5/10, Train Loss: 0.3157, Valid Loss: 0.4905
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2988
Epoch 6/10, Batch 20/49, Loss: 0.3607
Epoch 6/10, Batch 30/49, Loss: 0.3744
Epoch 6/10, Batch 40/49, Loss: 0.2031
Epoch 6/10, Train Loss: 0.2869, Valid Loss: 0.4785
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2464
Epoch 7/10, Batch 20/49, Loss: 0.2856
Epoch 7/10, Batch 30/49, Loss: 0.4416
Epoch 7/10, Batch 40/49, Loss: 0.2513
Epoch 7/10, Train Loss: 0.2654, Valid Loss: 0.4626
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3786
Epoch 8/10, Batch 20/49, Loss: 0.2500
Epoch 8/10, Batch 30/49, Loss: 0.2134
Epoch 8/10, Batch 40/49, Loss: 0.1800
Epoch 8/10, Train Loss: 0.2488, Valid Loss: 0.4400
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2970
Epoch 9/10, Batch 20/49, Loss: 0.1601
Epoch 9/10, Batch 30/49, Loss: 0.4366
Epoch 9/10, Batch 40/49, Loss: 0.2046
Epoch 9/10, Train Loss: 0.2386, Valid Loss: 0.4245
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1567
Epoch 10/10, Batch 20/49, Loss: 0.1773
Epoch 10/10, Batch 30/49, Loss: 0.2512
Epoch 10/10, Batch 40/49, Loss: 0.2390
Epoch 10/10, Train Loss: 0.2229, Valid Loss: 0.4085
Model saved!
Accuracy: 0.9112
Precision: 0.9073
Recall: 0.9112
F1-score: 0.9077
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2695
Epoch 1/10, Batch 20/49, Loss: 0.9183
Epoch 1/10, Batch 30/49, Loss: 0.8415
Epoch 1/10, Batch 40/49, Loss: 0.7667
Epoch 1/10, Train Loss: 1.0051, Valid Loss: 0.6512
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6895
Epoch 2/10, Batch 20/49, Loss: 0.5030
Epoch 2/10, Batch 30/49, Loss: 0.4500
Epoch 2/10, Batch 40/49, Loss: 0.5408
Epoch 2/10, Train Loss: 0.5397, Valid Loss: 0.4866
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4954
Epoch 3/10, Batch 20/49, Loss: 0.4206
Epoch 3/10, Batch 30/49, Loss: 0.4290
Epoch 3/10, Batch 40/49, Loss: 0.3241
Epoch 3/10, Train Loss: 0.4286, Valid Loss: 0.4234
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3204
Epoch 4/10, Batch 20/49, Loss: 0.5226
Epoch 4/10, Batch 30/49, Loss: 0.3011
Epoch 4/10, Batch 40/49, Loss: 0.2272
Epoch 4/10, Train Loss: 0.3655, Valid Loss: 0.3602
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2795
Epoch 5/10, Batch 20/49, Loss: 0.2584
Epoch 5/10, Batch 30/49, Loss: 0.3387
Epoch 5/10, Batch 40/49, Loss: 0.1996
Epoch 5/10, Train Loss: 0.3126, Valid Loss: 0.3418
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1651
Epoch 6/10, Batch 20/49, Loss: 0.2473
Epoch 6/10, Batch 30/49, Loss: 0.3261
Epoch 6/10, Batch 40/49, Loss: 0.3342
Epoch 6/10, Train Loss: 0.2906, Valid Loss: 0.3388
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2821
Epoch 7/10, Batch 20/49, Loss: 0.2038
Epoch 7/10, Batch 30/49, Loss: 0.3100
Epoch 7/10, Batch 40/49, Loss: 0.1079
Epoch 7/10, Train Loss: 0.2643, Valid Loss: 0.3360
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3000
Epoch 8/10, Batch 20/49, Loss: 0.1446
Epoch 8/10, Batch 30/49, Loss: 0.3179
Epoch 8/10, Batch 40/49, Loss: 0.2657
Epoch 8/10, Train Loss: 0.2608, Valid Loss: 0.3068
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1579
Epoch 9/10, Batch 20/49, Loss: 0.2323
Epoch 9/10, Batch 30/49, Loss: 0.3818
Epoch 9/10, Batch 40/49, Loss: 0.1444
Epoch 9/10, Train Loss: 0.2526, Valid Loss: 0.2847
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2254
Epoch 10/10, Batch 20/49, Loss: 0.1571
Epoch 10/10, Batch 30/49, Loss: 0.2264
Epoch 10/10, Batch 40/49, Loss: 0.1418
Epoch 10/10, Train Loss: 0.2215, Valid Loss: 0.2798
Model saved!
Accuracy: 0.9077
Precision: 0.9049
Recall: 0.9077
F1-score: 0.9028
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1968
Epoch 1/10, Batch 20/49, Loss: 1.0264
Epoch 1/10, Batch 30/49, Loss: 0.8675
Epoch 1/10, Batch 40/49, Loss: 0.8047
Epoch 1/10, Train Loss: 1.0219, Valid Loss: 0.6670
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6669
Epoch 2/10, Batch 20/49, Loss: 0.4531
Epoch 2/10, Batch 30/49, Loss: 0.4359
Epoch 2/10, Batch 40/49, Loss: 0.4892
Epoch 2/10, Train Loss: 0.5472, Valid Loss: 0.4977
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5601
Epoch 3/10, Batch 20/49, Loss: 0.3897
Epoch 3/10, Batch 30/49, Loss: 0.3613
Epoch 3/10, Batch 40/49, Loss: 0.2804
Epoch 3/10, Train Loss: 0.4226, Valid Loss: 0.4313
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.4632
Epoch 4/10, Batch 20/49, Loss: 0.3540
Epoch 4/10, Batch 30/49, Loss: 0.1952
Epoch 4/10, Batch 40/49, Loss: 0.3105
Epoch 4/10, Train Loss: 0.3766, Valid Loss: 0.3964
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4120
Epoch 5/10, Batch 20/49, Loss: 0.2691
Epoch 5/10, Batch 30/49, Loss: 0.3021
Epoch 5/10, Batch 40/49, Loss: 0.2283
Epoch 5/10, Train Loss: 0.3110, Valid Loss: 0.3650
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1980
Epoch 6/10, Batch 20/49, Loss: 0.2828
Epoch 6/10, Batch 30/49, Loss: 0.3129
Epoch 6/10, Batch 40/49, Loss: 0.2738
Epoch 6/10, Train Loss: 0.2777, Valid Loss: 0.3586
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2413
Epoch 7/10, Batch 20/49, Loss: 0.2871
Epoch 7/10, Batch 30/49, Loss: 0.3816
Epoch 7/10, Batch 40/49, Loss: 0.3834
Epoch 7/10, Train Loss: 0.2680, Valid Loss: 0.3495
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2363
Epoch 8/10, Batch 20/49, Loss: 0.2775
Epoch 8/10, Batch 30/49, Loss: 0.2937
Epoch 8/10, Batch 40/49, Loss: 0.1913
Epoch 8/10, Train Loss: 0.2527, Valid Loss: 0.3314
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1977
Epoch 9/10, Batch 20/49, Loss: 0.2369
Epoch 9/10, Batch 30/49, Loss: 0.5083
Epoch 9/10, Batch 40/49, Loss: 0.1592
Epoch 9/10, Train Loss: 0.2424, Valid Loss: 0.3267
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2350
Epoch 10/10, Batch 20/49, Loss: 0.1163
Epoch 10/10, Batch 30/49, Loss: 0.3382
Epoch 10/10, Batch 40/49, Loss: 0.2965
Epoch 10/10, Train Loss: 0.2188, Valid Loss: 0.3223
Model saved!
Accuracy: 0.9100
Precision: 0.9062
Recall: 0.9100
F1-score: 0.9054
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2806
Epoch 1/10, Batch 20/49, Loss: 1.0350
Epoch 1/10, Batch 30/49, Loss: 0.7999
Epoch 1/10, Batch 40/49, Loss: 0.7295
Epoch 1/10, Train Loss: 0.9960, Valid Loss: 0.6704
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5830
Epoch 2/10, Batch 20/49, Loss: 0.4715
Epoch 2/10, Batch 30/49, Loss: 0.5214
Epoch 2/10, Batch 40/49, Loss: 0.5280
Epoch 2/10, Train Loss: 0.5316, Valid Loss: 0.5137
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4261
Epoch 3/10, Batch 20/49, Loss: 0.4154
Epoch 3/10, Batch 30/49, Loss: 0.2605
Epoch 3/10, Batch 40/49, Loss: 0.4916
Epoch 3/10, Train Loss: 0.4212, Valid Loss: 0.4516
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2163
Epoch 4/10, Batch 20/49, Loss: 0.3695
Epoch 4/10, Batch 30/49, Loss: 0.2710
Epoch 4/10, Batch 40/49, Loss: 0.3766
Epoch 4/10, Train Loss: 0.3535, Valid Loss: 0.3949
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3873
Epoch 5/10, Batch 20/49, Loss: 0.2325
Epoch 5/10, Batch 30/49, Loss: 0.2890
Epoch 5/10, Batch 40/49, Loss: 0.2477
Epoch 5/10, Train Loss: 0.3092, Valid Loss: 0.3820
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2291
Epoch 6/10, Batch 20/49, Loss: 0.2659
Epoch 6/10, Batch 30/49, Loss: 0.3510
Epoch 6/10, Batch 40/49, Loss: 0.2481
Epoch 6/10, Train Loss: 0.2780, Valid Loss: 0.3826
Epoch 7/10, Batch 10/49, Loss: 0.1687
Epoch 7/10, Batch 20/49, Loss: 0.4232
Epoch 7/10, Batch 30/49, Loss: 0.4334
Epoch 7/10, Batch 40/49, Loss: 0.1202
Epoch 7/10, Train Loss: 0.2601, Valid Loss: 0.3762
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3060
Epoch 8/10, Batch 20/49, Loss: 0.2863
Epoch 8/10, Batch 30/49, Loss: 0.3710
Epoch 8/10, Batch 40/49, Loss: 0.2321
Epoch 8/10, Train Loss: 0.2551, Valid Loss: 0.3799
Epoch 9/10, Batch 10/49, Loss: 0.1610
Epoch 9/10, Batch 20/49, Loss: 0.1900
Epoch 9/10, Batch 30/49, Loss: 0.4699
Epoch 9/10, Batch 40/49, Loss: 0.2097
Epoch 9/10, Train Loss: 0.2346, Valid Loss: 0.3617
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2123
Epoch 10/10, Batch 20/49, Loss: 0.1639
Epoch 10/10, Batch 30/49, Loss: 0.1554
Epoch 10/10, Batch 40/49, Loss: 0.2571
Epoch 10/10, Train Loss: 0.2116, Valid Loss: 0.3446
Model saved!
Accuracy: 0.9019
Precision: 0.8990
Recall: 0.9019
F1-score: 0.8979
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2595
Epoch 1/10, Batch 20/49, Loss: 0.9725
Epoch 1/10, Batch 30/49, Loss: 0.7414
Epoch 1/10, Batch 40/49, Loss: 0.8144
Epoch 1/10, Train Loss: 0.9942, Valid Loss: 0.5981
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6419
Epoch 2/10, Batch 20/49, Loss: 0.5544
Epoch 2/10, Batch 30/49, Loss: 0.5203
Epoch 2/10, Batch 40/49, Loss: 0.4044
Epoch 2/10, Train Loss: 0.5371, Valid Loss: 0.4179
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4568
Epoch 3/10, Batch 20/49, Loss: 0.3996
Epoch 3/10, Batch 30/49, Loss: 0.3603
Epoch 3/10, Batch 40/49, Loss: 0.3232
Epoch 3/10, Train Loss: 0.4081, Valid Loss: 0.3466
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2447
Epoch 4/10, Batch 20/49, Loss: 0.3097
Epoch 4/10, Batch 30/49, Loss: 0.2589
Epoch 4/10, Batch 40/49, Loss: 0.1997
Epoch 4/10, Train Loss: 0.3574, Valid Loss: 0.3148
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3417
Epoch 5/10, Batch 20/49, Loss: 0.2605
Epoch 5/10, Batch 30/49, Loss: 0.2088
Epoch 5/10, Batch 40/49, Loss: 0.1761
Epoch 5/10, Train Loss: 0.3071, Valid Loss: 0.2872
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2485
Epoch 6/10, Batch 20/49, Loss: 0.2515
Epoch 6/10, Batch 30/49, Loss: 0.2663
Epoch 6/10, Batch 40/49, Loss: 0.3041
Epoch 6/10, Train Loss: 0.2714, Valid Loss: 0.2805
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1822
Epoch 7/10, Batch 20/49, Loss: 0.1914
Epoch 7/10, Batch 30/49, Loss: 0.3447
Epoch 7/10, Batch 40/49, Loss: 0.1359
Epoch 7/10, Train Loss: 0.2512, Valid Loss: 0.2715
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2008
Epoch 8/10, Batch 20/49, Loss: 0.1584
Epoch 8/10, Batch 30/49, Loss: 0.2133
Epoch 8/10, Batch 40/49, Loss: 0.2194
Epoch 8/10, Train Loss: 0.2461, Valid Loss: 0.2594
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1382
Epoch 9/10, Batch 20/49, Loss: 0.2930
Epoch 9/10, Batch 30/49, Loss: 0.4527
Epoch 9/10, Batch 40/49, Loss: 0.1809
Epoch 9/10, Train Loss: 0.2297, Valid Loss: 0.2520
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2184
Epoch 10/10, Batch 20/49, Loss: 0.1160
Epoch 10/10, Batch 30/49, Loss: 0.4375
Epoch 10/10, Batch 40/49, Loss: 0.2245
Epoch 10/10, Train Loss: 0.1972, Valid Loss: 0.2452
Model saved!
Accuracy: 0.9159
Precision: 0.9132
Recall: 0.9159
F1-score: 0.9142
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3004
Epoch 1/10, Batch 20/49, Loss: 1.0229
Epoch 1/10, Batch 30/49, Loss: 0.8068
Epoch 1/10, Batch 40/49, Loss: 0.7138
Epoch 1/10, Train Loss: 1.0019, Valid Loss: 0.6787
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6201
Epoch 2/10, Batch 20/49, Loss: 0.4683
Epoch 2/10, Batch 30/49, Loss: 0.5205
Epoch 2/10, Batch 40/49, Loss: 0.4826
Epoch 2/10, Train Loss: 0.5363, Valid Loss: 0.5358
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4496
Epoch 3/10, Batch 20/49, Loss: 0.3927
Epoch 3/10, Batch 30/49, Loss: 0.5270
Epoch 3/10, Batch 40/49, Loss: 0.7190
Epoch 3/10, Train Loss: 0.4218, Valid Loss: 0.4824
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2197
Epoch 4/10, Batch 20/49, Loss: 0.3366
Epoch 4/10, Batch 30/49, Loss: 0.2958
Epoch 4/10, Batch 40/49, Loss: 0.1958
Epoch 4/10, Train Loss: 0.3581, Valid Loss: 0.4490
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3613
Epoch 5/10, Batch 20/49, Loss: 0.2433
Epoch 5/10, Batch 30/49, Loss: 0.2386
Epoch 5/10, Batch 40/49, Loss: 0.2211
Epoch 5/10, Train Loss: 0.3001, Valid Loss: 0.4590
Epoch 6/10, Batch 10/49, Loss: 0.1510
Epoch 6/10, Batch 20/49, Loss: 0.3289
Epoch 6/10, Batch 30/49, Loss: 0.2684
Epoch 6/10, Batch 40/49, Loss: 0.3178
Epoch 6/10, Train Loss: 0.2768, Valid Loss: 0.4688
Epoch 7/10, Batch 10/49, Loss: 0.2240
Epoch 7/10, Batch 20/49, Loss: 0.2399
Epoch 7/10, Batch 30/49, Loss: 0.3734
Epoch 7/10, Batch 40/49, Loss: 0.2148
Epoch 7/10, Train Loss: 0.2586, Valid Loss: 0.4877
Epoch 8/10, Batch 10/49, Loss: 0.1957
Epoch 8/10, Batch 20/49, Loss: 0.2528
Epoch 8/10, Batch 30/49, Loss: 0.1559
Epoch 8/10, Batch 40/49, Loss: 0.1558
Epoch 8/10, Train Loss: 0.2444, Valid Loss: 0.4445
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1105
Epoch 9/10, Batch 20/49, Loss: 0.1988
Epoch 9/10, Batch 30/49, Loss: 0.5790
Epoch 9/10, Batch 40/49, Loss: 0.1706
Epoch 9/10, Train Loss: 0.2400, Valid Loss: 0.4641
Epoch 10/10, Batch 10/49, Loss: 0.1563
Epoch 10/10, Batch 20/49, Loss: 0.1975
Epoch 10/10, Batch 30/49, Loss: 0.2831
Epoch 10/10, Batch 40/49, Loss: 0.2532
Epoch 10/10, Train Loss: 0.2134, Valid Loss: 0.4459
Accuracy: 0.9054
Precision: 0.9011
Recall: 0.9054
F1-score: 0.9017
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2162
Epoch 1/10, Batch 20/49, Loss: 1.0389
Epoch 1/10, Batch 30/49, Loss: 0.7594
Epoch 1/10, Batch 40/49, Loss: 0.7222
Epoch 1/10, Train Loss: 1.0133, Valid Loss: 0.6307
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6417
Epoch 2/10, Batch 20/49, Loss: 0.4621
Epoch 2/10, Batch 30/49, Loss: 0.5351
Epoch 2/10, Batch 40/49, Loss: 0.4728
Epoch 2/10, Train Loss: 0.5455, Valid Loss: 0.4501
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4392
Epoch 3/10, Batch 20/49, Loss: 0.4032
Epoch 3/10, Batch 30/49, Loss: 0.3764
Epoch 3/10, Batch 40/49, Loss: 0.3571
Epoch 3/10, Train Loss: 0.4289, Valid Loss: 0.3836
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2506
Epoch 4/10, Batch 20/49, Loss: 0.4419
Epoch 4/10, Batch 30/49, Loss: 0.3119
Epoch 4/10, Batch 40/49, Loss: 0.3237
Epoch 4/10, Train Loss: 0.3605, Valid Loss: 0.3304
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2930
Epoch 5/10, Batch 20/49, Loss: 0.3025
Epoch 5/10, Batch 30/49, Loss: 0.3013
Epoch 5/10, Batch 40/49, Loss: 0.2863
Epoch 5/10, Train Loss: 0.3132, Valid Loss: 0.3058
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2197
Epoch 6/10, Batch 20/49, Loss: 0.2028
Epoch 6/10, Batch 30/49, Loss: 0.3056
Epoch 6/10, Batch 40/49, Loss: 0.4278
Epoch 6/10, Train Loss: 0.2855, Valid Loss: 0.2873
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2506
Epoch 7/10, Batch 20/49, Loss: 0.3195
Epoch 7/10, Batch 30/49, Loss: 0.2493
Epoch 7/10, Batch 40/49, Loss: 0.1419
Epoch 7/10, Train Loss: 0.2657, Valid Loss: 0.2825
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2567
Epoch 8/10, Batch 20/49, Loss: 0.3129
Epoch 8/10, Batch 30/49, Loss: 0.3000
Epoch 8/10, Batch 40/49, Loss: 0.3009
Epoch 8/10, Train Loss: 0.2490, Valid Loss: 0.2726
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2627
Epoch 9/10, Batch 20/49, Loss: 0.4230
Epoch 9/10, Batch 30/49, Loss: 0.4323
Epoch 9/10, Batch 40/49, Loss: 0.1788
Epoch 9/10, Train Loss: 0.2388, Valid Loss: 0.2661
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2040
Epoch 10/10, Batch 20/49, Loss: 0.1565
Epoch 10/10, Batch 30/49, Loss: 0.3511
Epoch 10/10, Batch 40/49, Loss: 0.1998
Epoch 10/10, Train Loss: 0.2222, Valid Loss: 0.2619
Model saved!
Accuracy: 0.9054
Precision: 0.9029
Recall: 0.9054
F1-score: 0.9012
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2718
Epoch 1/10, Batch 20/49, Loss: 1.0330
Epoch 1/10, Batch 30/49, Loss: 0.8301
Epoch 1/10, Batch 40/49, Loss: 0.7708
Epoch 1/10, Train Loss: 1.0173, Valid Loss: 0.6304
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7332
Epoch 2/10, Batch 20/49, Loss: 0.5055
Epoch 2/10, Batch 30/49, Loss: 0.6583
Epoch 2/10, Batch 40/49, Loss: 0.5795
Epoch 2/10, Train Loss: 0.5533, Valid Loss: 0.4531
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4978
Epoch 3/10, Batch 20/49, Loss: 0.3820
Epoch 3/10, Batch 30/49, Loss: 0.3191
Epoch 3/10, Batch 40/49, Loss: 0.3911
Epoch 3/10, Train Loss: 0.4287, Valid Loss: 0.3837
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2349
Epoch 4/10, Batch 20/49, Loss: 0.5731
Epoch 4/10, Batch 30/49, Loss: 0.2727
Epoch 4/10, Batch 40/49, Loss: 0.2970
Epoch 4/10, Train Loss: 0.3831, Valid Loss: 0.3337
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3732
Epoch 5/10, Batch 20/49, Loss: 0.2491
Epoch 5/10, Batch 30/49, Loss: 0.2449
Epoch 5/10, Batch 40/49, Loss: 0.2563
Epoch 5/10, Train Loss: 0.3224, Valid Loss: 0.3209
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2518
Epoch 6/10, Batch 20/49, Loss: 0.2516
Epoch 6/10, Batch 30/49, Loss: 0.3615
Epoch 6/10, Batch 40/49, Loss: 0.2684
Epoch 6/10, Train Loss: 0.3078, Valid Loss: 0.3058
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2757
Epoch 7/10, Batch 20/49, Loss: 0.1599
Epoch 7/10, Batch 30/49, Loss: 0.3561
Epoch 7/10, Batch 40/49, Loss: 0.1807
Epoch 7/10, Train Loss: 0.2802, Valid Loss: 0.2991
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.3317
Epoch 8/10, Batch 20/49, Loss: 0.2164
Epoch 8/10, Batch 30/49, Loss: 0.2626
Epoch 8/10, Batch 40/49, Loss: 0.2247
Epoch 8/10, Train Loss: 0.2642, Valid Loss: 0.2869
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1465
Epoch 9/10, Batch 20/49, Loss: 0.2656
Epoch 9/10, Batch 30/49, Loss: 0.4927
Epoch 9/10, Batch 40/49, Loss: 0.2248
Epoch 9/10, Train Loss: 0.2475, Valid Loss: 0.2783
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1711
Epoch 10/10, Batch 20/49, Loss: 0.1875
Epoch 10/10, Batch 30/49, Loss: 0.3019
Epoch 10/10, Batch 40/49, Loss: 0.2670
Epoch 10/10, Train Loss: 0.2257, Valid Loss: 0.2640
Model saved!
Accuracy: 0.9112
Precision: 0.9082
Recall: 0.9112
F1-score: 0.9083
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3442
Epoch 1/10, Batch 20/49, Loss: 1.0032
Epoch 1/10, Batch 30/49, Loss: 0.8542
Epoch 1/10, Batch 40/49, Loss: 0.7249
Epoch 1/10, Train Loss: 1.0022, Valid Loss: 0.6446
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6491
Epoch 2/10, Batch 20/49, Loss: 0.4842
Epoch 2/10, Batch 30/49, Loss: 0.4450
Epoch 2/10, Batch 40/49, Loss: 0.6159
Epoch 2/10, Train Loss: 0.5449, Valid Loss: 0.4615
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3490
Epoch 3/10, Batch 20/49, Loss: 0.4369
Epoch 3/10, Batch 30/49, Loss: 0.3486
Epoch 3/10, Batch 40/49, Loss: 0.4896
Epoch 3/10, Train Loss: 0.4184, Valid Loss: 0.4002
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3744
Epoch 4/10, Batch 20/49, Loss: 0.5076
Epoch 4/10, Batch 30/49, Loss: 0.2915
Epoch 4/10, Batch 40/49, Loss: 0.3443
Epoch 4/10, Train Loss: 0.3593, Valid Loss: 0.3367
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2821
Epoch 5/10, Batch 20/49, Loss: 0.2562
Epoch 5/10, Batch 30/49, Loss: 0.4790
Epoch 5/10, Batch 40/49, Loss: 0.1770
Epoch 5/10, Train Loss: 0.3041, Valid Loss: 0.3146
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2257
Epoch 6/10, Batch 20/49, Loss: 0.4065
Epoch 6/10, Batch 30/49, Loss: 0.3870
Epoch 6/10, Batch 40/49, Loss: 0.2610
Epoch 6/10, Train Loss: 0.2849, Valid Loss: 0.2982
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3047
Epoch 7/10, Batch 20/49, Loss: 0.1449
Epoch 7/10, Batch 30/49, Loss: 0.3383
Epoch 7/10, Batch 40/49, Loss: 0.1947
Epoch 7/10, Train Loss: 0.2626, Valid Loss: 0.3011
Epoch 8/10, Batch 10/49, Loss: 0.3611
Epoch 8/10, Batch 20/49, Loss: 0.1777
Epoch 8/10, Batch 30/49, Loss: 0.3294
Epoch 8/10, Batch 40/49, Loss: 0.2704
Epoch 8/10, Train Loss: 0.2667, Valid Loss: 0.2767
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1178
Epoch 9/10, Batch 20/49, Loss: 0.1481
Epoch 9/10, Batch 30/49, Loss: 0.5041
Epoch 9/10, Batch 40/49, Loss: 0.2667
Epoch 9/10, Train Loss: 0.2366, Valid Loss: 0.2649
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1772
Epoch 10/10, Batch 20/49, Loss: 0.3261
Epoch 10/10, Batch 30/49, Loss: 0.3817
Epoch 10/10, Batch 40/49, Loss: 0.1708
Epoch 10/10, Train Loss: 0.2220, Valid Loss: 0.2531
Model saved!
Accuracy: 0.9065
Precision: 0.9019
Recall: 0.9065
F1-score: 0.9023
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2801
Epoch 1/10, Batch 20/49, Loss: 1.0562
Epoch 1/10, Batch 30/49, Loss: 0.8403
Epoch 1/10, Batch 40/49, Loss: 0.7146
Epoch 1/10, Train Loss: 0.9919, Valid Loss: 0.6723
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7495
Epoch 2/10, Batch 20/49, Loss: 0.4822
Epoch 2/10, Batch 30/49, Loss: 0.5593
Epoch 2/10, Batch 40/49, Loss: 0.4362
Epoch 2/10, Train Loss: 0.5220, Valid Loss: 0.5173
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3746
Epoch 3/10, Batch 20/49, Loss: 0.4126
Epoch 3/10, Batch 30/49, Loss: 0.3208
Epoch 3/10, Batch 40/49, Loss: 0.3197
Epoch 3/10, Train Loss: 0.4071, Valid Loss: 0.4454
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2745
Epoch 4/10, Batch 20/49, Loss: 0.4742
Epoch 4/10, Batch 30/49, Loss: 0.3114
Epoch 4/10, Batch 40/49, Loss: 0.3017
Epoch 4/10, Train Loss: 0.3483, Valid Loss: 0.3786
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3332
Epoch 5/10, Batch 20/49, Loss: 0.2220
Epoch 5/10, Batch 30/49, Loss: 0.3166
Epoch 5/10, Batch 40/49, Loss: 0.1689
Epoch 5/10, Train Loss: 0.2928, Valid Loss: 0.3533
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2974
Epoch 6/10, Batch 20/49, Loss: 0.1904
Epoch 6/10, Batch 30/49, Loss: 0.1678
Epoch 6/10, Batch 40/49, Loss: 0.2064
Epoch 6/10, Train Loss: 0.2676, Valid Loss: 0.3610
Epoch 7/10, Batch 10/49, Loss: 0.1751
Epoch 7/10, Batch 20/49, Loss: 0.2425
Epoch 7/10, Batch 30/49, Loss: 0.2700
Epoch 7/10, Batch 40/49, Loss: 0.2635
Epoch 7/10, Train Loss: 0.2600, Valid Loss: 0.3455
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1694
Epoch 8/10, Batch 20/49, Loss: 0.2801
Epoch 8/10, Batch 30/49, Loss: 0.2448
Epoch 8/10, Batch 40/49, Loss: 0.2367
Epoch 8/10, Train Loss: 0.2383, Valid Loss: 0.3341
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2334
Epoch 9/10, Batch 20/49, Loss: 0.1838
Epoch 9/10, Batch 30/49, Loss: 0.4227
Epoch 9/10, Batch 40/49, Loss: 0.2313
Epoch 9/10, Train Loss: 0.2311, Valid Loss: 0.3071
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1525
Epoch 10/10, Batch 20/49, Loss: 0.1943
Epoch 10/10, Batch 30/49, Loss: 0.2630
Epoch 10/10, Batch 40/49, Loss: 0.2207
Epoch 10/10, Train Loss: 0.2023, Valid Loss: 0.3110
Accuracy: 0.9019
Precision: 0.8977
Recall: 0.9019
F1-score: 0.8991
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2446
Epoch 1/10, Batch 20/49, Loss: 0.9972
Epoch 1/10, Batch 30/49, Loss: 0.8073
Epoch 1/10, Batch 40/49, Loss: 0.7054
Epoch 1/10, Train Loss: 0.9784, Valid Loss: 0.6559
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6970
Epoch 2/10, Batch 20/49, Loss: 0.4053
Epoch 2/10, Batch 30/49, Loss: 0.5232
Epoch 2/10, Batch 40/49, Loss: 0.4514
Epoch 2/10, Train Loss: 0.5063, Valid Loss: 0.4895
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3364
Epoch 3/10, Batch 20/49, Loss: 0.5172
Epoch 3/10, Batch 30/49, Loss: 0.4303
Epoch 3/10, Batch 40/49, Loss: 0.2527
Epoch 3/10, Train Loss: 0.4017, Valid Loss: 0.4353
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2639
Epoch 4/10, Batch 20/49, Loss: 0.3080
Epoch 4/10, Batch 30/49, Loss: 0.2436
Epoch 4/10, Batch 40/49, Loss: 0.3100
Epoch 4/10, Train Loss: 0.3289, Valid Loss: 0.3788
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3433
Epoch 5/10, Batch 20/49, Loss: 0.3265
Epoch 5/10, Batch 30/49, Loss: 0.3144
Epoch 5/10, Batch 40/49, Loss: 0.2004
Epoch 5/10, Train Loss: 0.2846, Valid Loss: 0.3726
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2225
Epoch 6/10, Batch 20/49, Loss: 0.2421
Epoch 6/10, Batch 30/49, Loss: 0.2861
Epoch 6/10, Batch 40/49, Loss: 0.2620
Epoch 6/10, Train Loss: 0.2666, Valid Loss: 0.3545
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2040
Epoch 7/10, Batch 20/49, Loss: 0.1157
Epoch 7/10, Batch 30/49, Loss: 0.4245
Epoch 7/10, Batch 40/49, Loss: 0.1547
Epoch 7/10, Train Loss: 0.2452, Valid Loss: 0.3565
Epoch 8/10, Batch 10/49, Loss: 0.2073
Epoch 8/10, Batch 20/49, Loss: 0.2047
Epoch 8/10, Batch 30/49, Loss: 0.2866
Epoch 8/10, Batch 40/49, Loss: 0.1385
Epoch 8/10, Train Loss: 0.2341, Valid Loss: 0.3495
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1276
Epoch 9/10, Batch 20/49, Loss: 0.2864
Epoch 9/10, Batch 30/49, Loss: 0.3677
Epoch 9/10, Batch 40/49, Loss: 0.1441
Epoch 9/10, Train Loss: 0.2144, Valid Loss: 0.3351
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2752
Epoch 10/10, Batch 20/49, Loss: 0.1833
Epoch 10/10, Batch 30/49, Loss: 0.2655
Epoch 10/10, Batch 40/49, Loss: 0.1856
Epoch 10/10, Train Loss: 0.2034, Valid Loss: 0.3134
Model saved!
Accuracy: 0.8972
Precision: 0.8933
Recall: 0.8972
F1-score: 0.8933
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.1966
Epoch 1/10, Batch 20/49, Loss: 1.0317
Epoch 1/10, Batch 30/49, Loss: 0.7644
Epoch 1/10, Batch 40/49, Loss: 0.7810
Epoch 1/10, Train Loss: 0.9907, Valid Loss: 0.6347
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6177
Epoch 2/10, Batch 20/49, Loss: 0.4391
Epoch 2/10, Batch 30/49, Loss: 0.5892
Epoch 2/10, Batch 40/49, Loss: 0.4785
Epoch 2/10, Train Loss: 0.5312, Valid Loss: 0.4462
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3135
Epoch 3/10, Batch 20/49, Loss: 0.4312
Epoch 3/10, Batch 30/49, Loss: 0.4483
Epoch 3/10, Batch 40/49, Loss: 0.3773
Epoch 3/10, Train Loss: 0.4215, Valid Loss: 0.3644
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3088
Epoch 4/10, Batch 20/49, Loss: 0.4532
Epoch 4/10, Batch 30/49, Loss: 0.2526
Epoch 4/10, Batch 40/49, Loss: 0.3014
Epoch 4/10, Train Loss: 0.3555, Valid Loss: 0.3385
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3135
Epoch 5/10, Batch 20/49, Loss: 0.2072
Epoch 5/10, Batch 30/49, Loss: 0.2244
Epoch 5/10, Batch 40/49, Loss: 0.3091
Epoch 5/10, Train Loss: 0.3118, Valid Loss: 0.3016
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2030
Epoch 6/10, Batch 20/49, Loss: 0.2560
Epoch 6/10, Batch 30/49, Loss: 0.2989
Epoch 6/10, Batch 40/49, Loss: 0.2244
Epoch 6/10, Train Loss: 0.2787, Valid Loss: 0.2854
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1818
Epoch 7/10, Batch 20/49, Loss: 0.2625
Epoch 7/10, Batch 30/49, Loss: 0.3481
Epoch 7/10, Batch 40/49, Loss: 0.2407
Epoch 7/10, Train Loss: 0.2619, Valid Loss: 0.2716
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1831
Epoch 8/10, Batch 20/49, Loss: 0.1920
Epoch 8/10, Batch 30/49, Loss: 0.2270
Epoch 8/10, Batch 40/49, Loss: 0.2383
Epoch 8/10, Train Loss: 0.2541, Valid Loss: 0.2582
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2174
Epoch 9/10, Batch 20/49, Loss: 0.2227
Epoch 9/10, Batch 30/49, Loss: 0.4696
Epoch 9/10, Batch 40/49, Loss: 0.1419
Epoch 9/10, Train Loss: 0.2328, Valid Loss: 0.2522
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2854
Epoch 10/10, Batch 20/49, Loss: 0.2304
Epoch 10/10, Batch 30/49, Loss: 0.3141
Epoch 10/10, Batch 40/49, Loss: 0.2491
Epoch 10/10, Train Loss: 0.2118, Valid Loss: 0.2492
Model saved!
Accuracy: 0.9100
Precision: 0.9082
Recall: 0.9100
F1-score: 0.9057
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2709
Epoch 1/10, Batch 20/49, Loss: 1.0983
Epoch 1/10, Batch 30/49, Loss: 0.8472
Epoch 1/10, Batch 40/49, Loss: 0.8085
Epoch 1/10, Train Loss: 0.9995, Valid Loss: 0.6803
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6558
Epoch 2/10, Batch 20/49, Loss: 0.4190
Epoch 2/10, Batch 30/49, Loss: 0.6114
Epoch 2/10, Batch 40/49, Loss: 0.6904
Epoch 2/10, Train Loss: 0.5425, Valid Loss: 0.5123
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5533
Epoch 3/10, Batch 20/49, Loss: 0.5346
Epoch 3/10, Batch 30/49, Loss: 0.4604
Epoch 3/10, Batch 40/49, Loss: 0.3236
Epoch 3/10, Train Loss: 0.4223, Valid Loss: 0.4509
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3912
Epoch 4/10, Batch 20/49, Loss: 0.3871
Epoch 4/10, Batch 30/49, Loss: 0.2488
Epoch 4/10, Batch 40/49, Loss: 0.3465
Epoch 4/10, Train Loss: 0.3630, Valid Loss: 0.4048
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3035
Epoch 5/10, Batch 20/49, Loss: 0.2783
Epoch 5/10, Batch 30/49, Loss: 0.3817
Epoch 5/10, Batch 40/49, Loss: 0.2844
Epoch 5/10, Train Loss: 0.3036, Valid Loss: 0.3869
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2525
Epoch 6/10, Batch 20/49, Loss: 0.3963
Epoch 6/10, Batch 30/49, Loss: 0.3116
Epoch 6/10, Batch 40/49, Loss: 0.2383
Epoch 6/10, Train Loss: 0.2867, Valid Loss: 0.3796
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2527
Epoch 7/10, Batch 20/49, Loss: 0.2197
Epoch 7/10, Batch 30/49, Loss: 0.4083
Epoch 7/10, Batch 40/49, Loss: 0.1520
Epoch 7/10, Train Loss: 0.2704, Valid Loss: 0.3686
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2009
Epoch 8/10, Batch 20/49, Loss: 0.2016
Epoch 8/10, Batch 30/49, Loss: 0.3906
Epoch 8/10, Batch 40/49, Loss: 0.2423
Epoch 8/10, Train Loss: 0.2553, Valid Loss: 0.3589
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1591
Epoch 9/10, Batch 20/49, Loss: 0.2887
Epoch 9/10, Batch 30/49, Loss: 0.4652
Epoch 9/10, Batch 40/49, Loss: 0.1731
Epoch 9/10, Train Loss: 0.2544, Valid Loss: 0.3547
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1973
Epoch 10/10, Batch 20/49, Loss: 0.1815
Epoch 10/10, Batch 30/49, Loss: 0.1949
Epoch 10/10, Batch 40/49, Loss: 0.2355
Epoch 10/10, Train Loss: 0.2161, Valid Loss: 0.3442
Model saved!
Accuracy: 0.9030
Precision: 0.8982
Recall: 0.9030
F1-score: 0.8982
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2776
Epoch 1/10, Batch 20/49, Loss: 1.0904
Epoch 1/10, Batch 30/49, Loss: 0.8594
Epoch 1/10, Batch 40/49, Loss: 0.7766
Epoch 1/10, Train Loss: 1.0018, Valid Loss: 0.6626
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7120
Epoch 2/10, Batch 20/49, Loss: 0.4600
Epoch 2/10, Batch 30/49, Loss: 0.5666
Epoch 2/10, Batch 40/49, Loss: 0.5409
Epoch 2/10, Train Loss: 0.5351, Valid Loss: 0.4821
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4012
Epoch 3/10, Batch 20/49, Loss: 0.4963
Epoch 3/10, Batch 30/49, Loss: 0.4517
Epoch 3/10, Batch 40/49, Loss: 0.4239
Epoch 3/10, Train Loss: 0.4160, Valid Loss: 0.4139
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2391
Epoch 4/10, Batch 20/49, Loss: 0.5040
Epoch 4/10, Batch 30/49, Loss: 0.2583
Epoch 4/10, Batch 40/49, Loss: 0.2457
Epoch 4/10, Train Loss: 0.3608, Valid Loss: 0.3719
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2842
Epoch 5/10, Batch 20/49, Loss: 0.2006
Epoch 5/10, Batch 30/49, Loss: 0.2578
Epoch 5/10, Batch 40/49, Loss: 0.1785
Epoch 5/10, Train Loss: 0.2913, Valid Loss: 0.3462
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2671
Epoch 6/10, Batch 20/49, Loss: 0.3756
Epoch 6/10, Batch 30/49, Loss: 0.2826
Epoch 6/10, Batch 40/49, Loss: 0.3704
Epoch 6/10, Train Loss: 0.2879, Valid Loss: 0.3247
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2167
Epoch 7/10, Batch 20/49, Loss: 0.3601
Epoch 7/10, Batch 30/49, Loss: 0.2959
Epoch 7/10, Batch 40/49, Loss: 0.2489
Epoch 7/10, Train Loss: 0.2606, Valid Loss: 0.3312
Epoch 8/10, Batch 10/49, Loss: 0.1808
Epoch 8/10, Batch 20/49, Loss: 0.3783
Epoch 8/10, Batch 30/49, Loss: 0.1988
Epoch 8/10, Batch 40/49, Loss: 0.2206
Epoch 8/10, Train Loss: 0.2440, Valid Loss: 0.3142
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2013
Epoch 9/10, Batch 20/49, Loss: 0.1205
Epoch 9/10, Batch 30/49, Loss: 0.4194
Epoch 9/10, Batch 40/49, Loss: 0.2105
Epoch 9/10, Train Loss: 0.2240, Valid Loss: 0.3151
Epoch 10/10, Batch 10/49, Loss: 0.2892
Epoch 10/10, Batch 20/49, Loss: 0.1958
Epoch 10/10, Batch 30/49, Loss: 0.2773
Epoch 10/10, Batch 40/49, Loss: 0.1717
Epoch 10/10, Train Loss: 0.2046, Valid Loss: 0.2882
Model saved!
Accuracy: 0.9100
Precision: 0.9060
Recall: 0.9100
F1-score: 0.9069
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2650
Epoch 1/10, Batch 20/49, Loss: 1.0599
Epoch 1/10, Batch 30/49, Loss: 0.7958
Epoch 1/10, Batch 40/49, Loss: 0.6787
Epoch 1/10, Train Loss: 0.9895, Valid Loss: 0.5735
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6717
Epoch 2/10, Batch 20/49, Loss: 0.5298
Epoch 2/10, Batch 30/49, Loss: 0.4935
Epoch 2/10, Batch 40/49, Loss: 0.5013
Epoch 2/10, Train Loss: 0.5267, Valid Loss: 0.4030
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3676
Epoch 3/10, Batch 20/49, Loss: 0.4682
Epoch 3/10, Batch 30/49, Loss: 0.2991
Epoch 3/10, Batch 40/49, Loss: 0.3253
Epoch 3/10, Train Loss: 0.3991, Valid Loss: 0.3312
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3062
Epoch 4/10, Batch 20/49, Loss: 0.3058
Epoch 4/10, Batch 30/49, Loss: 0.3028
Epoch 4/10, Batch 40/49, Loss: 0.2688
Epoch 4/10, Train Loss: 0.3399, Valid Loss: 0.2967
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3294
Epoch 5/10, Batch 20/49, Loss: 0.3592
Epoch 5/10, Batch 30/49, Loss: 0.2126
Epoch 5/10, Batch 40/49, Loss: 0.1521
Epoch 5/10, Train Loss: 0.2928, Valid Loss: 0.2779
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2077
Epoch 6/10, Batch 20/49, Loss: 0.1738
Epoch 6/10, Batch 30/49, Loss: 0.2599
Epoch 6/10, Batch 40/49, Loss: 0.1710
Epoch 6/10, Train Loss: 0.2696, Valid Loss: 0.2674
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.1500
Epoch 7/10, Batch 20/49, Loss: 0.2233
Epoch 7/10, Batch 30/49, Loss: 0.2941
Epoch 7/10, Batch 40/49, Loss: 0.1783
Epoch 7/10, Train Loss: 0.2467, Valid Loss: 0.2602
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2718
Epoch 8/10, Batch 20/49, Loss: 0.3220
Epoch 8/10, Batch 30/49, Loss: 0.2582
Epoch 8/10, Batch 40/49, Loss: 0.3157
Epoch 8/10, Train Loss: 0.2362, Valid Loss: 0.2527
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2166
Epoch 9/10, Batch 20/49, Loss: 0.1089
Epoch 9/10, Batch 30/49, Loss: 0.4456
Epoch 9/10, Batch 40/49, Loss: 0.1363
Epoch 9/10, Train Loss: 0.2094, Valid Loss: 0.2477
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2284
Epoch 10/10, Batch 20/49, Loss: 0.0982
Epoch 10/10, Batch 30/49, Loss: 0.1979
Epoch 10/10, Batch 40/49, Loss: 0.2039
Epoch 10/10, Train Loss: 0.1957, Valid Loss: 0.2341
Model saved!
Accuracy: 0.9019
Precision: 0.8980
Recall: 0.9019
F1-score: 0.8978
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2814
Epoch 1/10, Batch 20/49, Loss: 1.0278
Epoch 1/10, Batch 30/49, Loss: 0.7750
Epoch 1/10, Batch 40/49, Loss: 0.6264
Epoch 1/10, Train Loss: 0.9712, Valid Loss: 0.6564
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6589
Epoch 2/10, Batch 20/49, Loss: 0.4067
Epoch 2/10, Batch 30/49, Loss: 0.3881
Epoch 2/10, Batch 40/49, Loss: 0.5989
Epoch 2/10, Train Loss: 0.5119, Valid Loss: 0.4986
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4261
Epoch 3/10, Batch 20/49, Loss: 0.4168
Epoch 3/10, Batch 30/49, Loss: 0.3443
Epoch 3/10, Batch 40/49, Loss: 0.3813
Epoch 3/10, Train Loss: 0.4089, Valid Loss: 0.4297
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2744
Epoch 4/10, Batch 20/49, Loss: 0.3851
Epoch 4/10, Batch 30/49, Loss: 0.2619
Epoch 4/10, Batch 40/49, Loss: 0.2516
Epoch 4/10, Train Loss: 0.3451, Valid Loss: 0.3802
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2597
Epoch 5/10, Batch 20/49, Loss: 0.2298
Epoch 5/10, Batch 30/49, Loss: 0.2174
Epoch 5/10, Batch 40/49, Loss: 0.2102
Epoch 5/10, Train Loss: 0.2960, Valid Loss: 0.3637
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1786
Epoch 6/10, Batch 20/49, Loss: 0.3674
Epoch 6/10, Batch 30/49, Loss: 0.3220
Epoch 6/10, Batch 40/49, Loss: 0.2663
Epoch 6/10, Train Loss: 0.2696, Valid Loss: 0.3460
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2148
Epoch 7/10, Batch 20/49, Loss: 0.1370
Epoch 7/10, Batch 30/49, Loss: 0.5063
Epoch 7/10, Batch 40/49, Loss: 0.1833
Epoch 7/10, Train Loss: 0.2502, Valid Loss: 0.3522
Epoch 8/10, Batch 10/49, Loss: 0.1928
Epoch 8/10, Batch 20/49, Loss: 0.1868
Epoch 8/10, Batch 30/49, Loss: 0.1827
Epoch 8/10, Batch 40/49, Loss: 0.2037
Epoch 8/10, Train Loss: 0.2352, Valid Loss: 0.3216
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1108
Epoch 9/10, Batch 20/49, Loss: 0.2832
Epoch 9/10, Batch 30/49, Loss: 0.4046
Epoch 9/10, Batch 40/49, Loss: 0.2230
Epoch 9/10, Train Loss: 0.2148, Valid Loss: 0.3081
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2161
Epoch 10/10, Batch 20/49, Loss: 0.2241
Epoch 10/10, Batch 30/49, Loss: 0.2433
Epoch 10/10, Batch 40/49, Loss: 0.1851
Epoch 10/10, Train Loss: 0.2044, Valid Loss: 0.3068
Model saved!
Accuracy: 0.9007
Precision: 0.8967
Recall: 0.9007
F1-score: 0.8968
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2451
Epoch 1/10, Batch 20/49, Loss: 1.0382
Epoch 1/10, Batch 30/49, Loss: 0.8957
Epoch 1/10, Batch 40/49, Loss: 0.6944
Epoch 1/10, Train Loss: 0.9738, Valid Loss: 0.6401
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5494
Epoch 2/10, Batch 20/49, Loss: 0.4671
Epoch 2/10, Batch 30/49, Loss: 0.4608
Epoch 2/10, Batch 40/49, Loss: 0.3504
Epoch 2/10, Train Loss: 0.5123, Valid Loss: 0.4742
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3460
Epoch 3/10, Batch 20/49, Loss: 0.4980
Epoch 3/10, Batch 30/49, Loss: 0.3886
Epoch 3/10, Batch 40/49, Loss: 0.2873
Epoch 3/10, Train Loss: 0.3955, Valid Loss: 0.4036
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3095
Epoch 4/10, Batch 20/49, Loss: 0.4937
Epoch 4/10, Batch 30/49, Loss: 0.2418
Epoch 4/10, Batch 40/49, Loss: 0.2474
Epoch 4/10, Train Loss: 0.3419, Valid Loss: 0.3539
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2615
Epoch 5/10, Batch 20/49, Loss: 0.2381
Epoch 5/10, Batch 30/49, Loss: 0.2871
Epoch 5/10, Batch 40/49, Loss: 0.2685
Epoch 5/10, Train Loss: 0.2858, Valid Loss: 0.3289
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1402
Epoch 6/10, Batch 20/49, Loss: 0.1705
Epoch 6/10, Batch 30/49, Loss: 0.2298
Epoch 6/10, Batch 40/49, Loss: 0.2870
Epoch 6/10, Train Loss: 0.2689, Valid Loss: 0.3162
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2200
Epoch 7/10, Batch 20/49, Loss: 0.2611
Epoch 7/10, Batch 30/49, Loss: 0.2652
Epoch 7/10, Batch 40/49, Loss: 0.2341
Epoch 7/10, Train Loss: 0.2509, Valid Loss: 0.3051
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2322
Epoch 8/10, Batch 20/49, Loss: 0.1866
Epoch 8/10, Batch 30/49, Loss: 0.3174
Epoch 8/10, Batch 40/49, Loss: 0.2010
Epoch 8/10, Train Loss: 0.2314, Valid Loss: 0.2813
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1703
Epoch 9/10, Batch 20/49, Loss: 0.2546
Epoch 9/10, Batch 30/49, Loss: 0.4530
Epoch 9/10, Batch 40/49, Loss: 0.1356
Epoch 9/10, Train Loss: 0.2243, Valid Loss: 0.2667
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1599
Epoch 10/10, Batch 20/49, Loss: 0.1004
Epoch 10/10, Batch 30/49, Loss: 0.3029
Epoch 10/10, Batch 40/49, Loss: 0.1469
Epoch 10/10, Train Loss: 0.1917, Valid Loss: 0.2622
Model saved!
Accuracy: 0.9112
Precision: 0.9075
Recall: 0.9112
F1-score: 0.9088
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2663
Epoch 1/10, Batch 20/49, Loss: 0.9385
Epoch 1/10, Batch 30/49, Loss: 0.8506
Epoch 1/10, Batch 40/49, Loss: 0.7405
Epoch 1/10, Train Loss: 0.9957, Valid Loss: 0.6692
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7127
Epoch 2/10, Batch 20/49, Loss: 0.4693
Epoch 2/10, Batch 30/49, Loss: 0.5930
Epoch 2/10, Batch 40/49, Loss: 0.6552
Epoch 2/10, Train Loss: 0.5426, Valid Loss: 0.4910
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5025
Epoch 3/10, Batch 20/49, Loss: 0.5199
Epoch 3/10, Batch 30/49, Loss: 0.3934
Epoch 3/10, Batch 40/49, Loss: 0.3504
Epoch 3/10, Train Loss: 0.4260, Valid Loss: 0.4071
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3547
Epoch 4/10, Batch 20/49, Loss: 0.4703
Epoch 4/10, Batch 30/49, Loss: 0.2395
Epoch 4/10, Batch 40/49, Loss: 0.3157
Epoch 4/10, Train Loss: 0.3670, Valid Loss: 0.3577
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2352
Epoch 5/10, Batch 20/49, Loss: 0.3659
Epoch 5/10, Batch 30/49, Loss: 0.3274
Epoch 5/10, Batch 40/49, Loss: 0.3438
Epoch 5/10, Train Loss: 0.3267, Valid Loss: 0.3279
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2686
Epoch 6/10, Batch 20/49, Loss: 0.2245
Epoch 6/10, Batch 30/49, Loss: 0.3869
Epoch 6/10, Batch 40/49, Loss: 0.2578
Epoch 6/10, Train Loss: 0.2863, Valid Loss: 0.3274
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3584
Epoch 7/10, Batch 20/49, Loss: 0.1952
Epoch 7/10, Batch 30/49, Loss: 0.3293
Epoch 7/10, Batch 40/49, Loss: 0.3001
Epoch 7/10, Train Loss: 0.2771, Valid Loss: 0.3193
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2475
Epoch 8/10, Batch 20/49, Loss: 0.1411
Epoch 8/10, Batch 30/49, Loss: 0.2863
Epoch 8/10, Batch 40/49, Loss: 0.2596
Epoch 8/10, Train Loss: 0.2604, Valid Loss: 0.2970
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2000
Epoch 9/10, Batch 20/49, Loss: 0.2590
Epoch 9/10, Batch 30/49, Loss: 0.4193
Epoch 9/10, Batch 40/49, Loss: 0.2016
Epoch 9/10, Train Loss: 0.2438, Valid Loss: 0.2789
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2145
Epoch 10/10, Batch 20/49, Loss: 0.1100
Epoch 10/10, Batch 30/49, Loss: 0.2744
Epoch 10/10, Batch 40/49, Loss: 0.2275
Epoch 10/10, Train Loss: 0.2255, Valid Loss: 0.2655
Model saved!
Accuracy: 0.9054
Precision: 0.9005
Recall: 0.9054
F1-score: 0.9009
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2841
Epoch 1/10, Batch 20/49, Loss: 0.9509
Epoch 1/10, Batch 30/49, Loss: 0.8296
Epoch 1/10, Batch 40/49, Loss: 0.8239
Epoch 1/10, Train Loss: 0.9908, Valid Loss: 0.6451
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.5226
Epoch 2/10, Batch 20/49, Loss: 0.4026
Epoch 2/10, Batch 30/49, Loss: 0.5215
Epoch 2/10, Batch 40/49, Loss: 0.6409
Epoch 2/10, Train Loss: 0.5353, Valid Loss: 0.4711
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.3848
Epoch 3/10, Batch 20/49, Loss: 0.4071
Epoch 3/10, Batch 30/49, Loss: 0.4322
Epoch 3/10, Batch 40/49, Loss: 0.4691
Epoch 3/10, Train Loss: 0.4120, Valid Loss: 0.3967
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3230
Epoch 4/10, Batch 20/49, Loss: 0.3243
Epoch 4/10, Batch 30/49, Loss: 0.3352
Epoch 4/10, Batch 40/49, Loss: 0.3597
Epoch 4/10, Train Loss: 0.3565, Valid Loss: 0.3476
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2683
Epoch 5/10, Batch 20/49, Loss: 0.1908
Epoch 5/10, Batch 30/49, Loss: 0.1937
Epoch 5/10, Batch 40/49, Loss: 0.2761
Epoch 5/10, Train Loss: 0.3130, Valid Loss: 0.3255
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1625
Epoch 6/10, Batch 20/49, Loss: 0.3620
Epoch 6/10, Batch 30/49, Loss: 0.3075
Epoch 6/10, Batch 40/49, Loss: 0.3598
Epoch 6/10, Train Loss: 0.2922, Valid Loss: 0.2978
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2434
Epoch 7/10, Batch 20/49, Loss: 0.2768
Epoch 7/10, Batch 30/49, Loss: 0.3950
Epoch 7/10, Batch 40/49, Loss: 0.3372
Epoch 7/10, Train Loss: 0.2697, Valid Loss: 0.2948
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1936
Epoch 8/10, Batch 20/49, Loss: 0.4325
Epoch 8/10, Batch 30/49, Loss: 0.1702
Epoch 8/10, Batch 40/49, Loss: 0.2591
Epoch 8/10, Train Loss: 0.2536, Valid Loss: 0.2778
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1303
Epoch 9/10, Batch 20/49, Loss: 0.3896
Epoch 9/10, Batch 30/49, Loss: 0.4630
Epoch 9/10, Batch 40/49, Loss: 0.2938
Epoch 9/10, Train Loss: 0.2466, Valid Loss: 0.2676
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3667
Epoch 10/10, Batch 20/49, Loss: 0.2148
Epoch 10/10, Batch 30/49, Loss: 0.3228
Epoch 10/10, Batch 40/49, Loss: 0.1751
Epoch 10/10, Train Loss: 0.2151, Valid Loss: 0.2583
Model saved!
Accuracy: 0.9042
Precision: 0.9005
Recall: 0.9042
F1-score: 0.9000
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2624
Epoch 1/10, Batch 20/49, Loss: 1.0956
Epoch 1/10, Batch 30/49, Loss: 0.8447
Epoch 1/10, Batch 40/49, Loss: 0.7065
Epoch 1/10, Train Loss: 1.0045, Valid Loss: 0.6274
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6099
Epoch 2/10, Batch 20/49, Loss: 0.4717
Epoch 2/10, Batch 30/49, Loss: 0.4824
Epoch 2/10, Batch 40/49, Loss: 0.4323
Epoch 2/10, Train Loss: 0.5457, Valid Loss: 0.4309
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5158
Epoch 3/10, Batch 20/49, Loss: 0.3030
Epoch 3/10, Batch 30/49, Loss: 0.4051
Epoch 3/10, Batch 40/49, Loss: 0.3728
Epoch 3/10, Train Loss: 0.4223, Valid Loss: 0.3420
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3030
Epoch 4/10, Batch 20/49, Loss: 0.4017
Epoch 4/10, Batch 30/49, Loss: 0.3365
Epoch 4/10, Batch 40/49, Loss: 0.3642
Epoch 4/10, Train Loss: 0.3714, Valid Loss: 0.2923
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.3752
Epoch 5/10, Batch 20/49, Loss: 0.2802
Epoch 5/10, Batch 30/49, Loss: 0.2702
Epoch 5/10, Batch 40/49, Loss: 0.2222
Epoch 5/10, Train Loss: 0.3157, Valid Loss: 0.2714
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2671
Epoch 6/10, Batch 20/49, Loss: 0.2435
Epoch 6/10, Batch 30/49, Loss: 0.3951
Epoch 6/10, Batch 40/49, Loss: 0.3093
Epoch 6/10, Train Loss: 0.2913, Valid Loss: 0.2583
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2835
Epoch 7/10, Batch 20/49, Loss: 0.2452
Epoch 7/10, Batch 30/49, Loss: 0.4096
Epoch 7/10, Batch 40/49, Loss: 0.3175
Epoch 7/10, Train Loss: 0.2714, Valid Loss: 0.2455
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2301
Epoch 8/10, Batch 20/49, Loss: 0.2535
Epoch 8/10, Batch 30/49, Loss: 0.2370
Epoch 8/10, Batch 40/49, Loss: 0.1670
Epoch 8/10, Train Loss: 0.2559, Valid Loss: 0.2317
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2155
Epoch 9/10, Batch 20/49, Loss: 0.1692
Epoch 9/10, Batch 30/49, Loss: 0.5758
Epoch 9/10, Batch 40/49, Loss: 0.1642
Epoch 9/10, Train Loss: 0.2294, Valid Loss: 0.2122
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.3362
Epoch 10/10, Batch 20/49, Loss: 0.1198
Epoch 10/10, Batch 30/49, Loss: 0.1942
Epoch 10/10, Batch 40/49, Loss: 0.1337
Epoch 10/10, Train Loss: 0.2146, Valid Loss: 0.2132
Accuracy: 0.9089
Precision: 0.9042
Recall: 0.9089
F1-score: 0.9057
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3208
Epoch 1/10, Batch 20/49, Loss: 1.1063
Epoch 1/10, Batch 30/49, Loss: 0.8002
Epoch 1/10, Batch 40/49, Loss: 0.8142
Epoch 1/10, Train Loss: 1.0001, Valid Loss: 0.6330
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6456
Epoch 2/10, Batch 20/49, Loss: 0.5165
Epoch 2/10, Batch 30/49, Loss: 0.5513
Epoch 2/10, Batch 40/49, Loss: 0.5901
Epoch 2/10, Train Loss: 0.5359, Valid Loss: 0.4585
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4165
Epoch 3/10, Batch 20/49, Loss: 0.5363
Epoch 3/10, Batch 30/49, Loss: 0.4836
Epoch 3/10, Batch 40/49, Loss: 0.3693
Epoch 3/10, Train Loss: 0.4176, Valid Loss: 0.3873
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2893
Epoch 4/10, Batch 20/49, Loss: 0.4609
Epoch 4/10, Batch 30/49, Loss: 0.1888
Epoch 4/10, Batch 40/49, Loss: 0.2656
Epoch 4/10, Train Loss: 0.3648, Valid Loss: 0.3394
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2750
Epoch 5/10, Batch 20/49, Loss: 0.3440
Epoch 5/10, Batch 30/49, Loss: 0.2050
Epoch 5/10, Batch 40/49, Loss: 0.2346
Epoch 5/10, Train Loss: 0.3142, Valid Loss: 0.3053
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3233
Epoch 6/10, Batch 20/49, Loss: 0.2028
Epoch 6/10, Batch 30/49, Loss: 0.3501
Epoch 6/10, Batch 40/49, Loss: 0.4340
Epoch 6/10, Train Loss: 0.2931, Valid Loss: 0.2996
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3841
Epoch 7/10, Batch 20/49, Loss: 0.2148
Epoch 7/10, Batch 30/49, Loss: 0.4178
Epoch 7/10, Batch 40/49, Loss: 0.2589
Epoch 7/10, Train Loss: 0.2646, Valid Loss: 0.2868
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2577
Epoch 8/10, Batch 20/49, Loss: 0.2355
Epoch 8/10, Batch 30/49, Loss: 0.2236
Epoch 8/10, Batch 40/49, Loss: 0.1656
Epoch 8/10, Train Loss: 0.2539, Valid Loss: 0.2727
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2459
Epoch 9/10, Batch 20/49, Loss: 0.2941
Epoch 9/10, Batch 30/49, Loss: 0.2953
Epoch 9/10, Batch 40/49, Loss: 0.2061
Epoch 9/10, Train Loss: 0.2366, Valid Loss: 0.2621
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1284
Epoch 10/10, Batch 20/49, Loss: 0.1597
Epoch 10/10, Batch 30/49, Loss: 0.2692
Epoch 10/10, Batch 40/49, Loss: 0.1993
Epoch 10/10, Train Loss: 0.2121, Valid Loss: 0.2463
Model saved!
Accuracy: 0.9042
Precision: 0.8994
Recall: 0.9042
F1-score: 0.8996
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2273
Epoch 1/10, Batch 20/49, Loss: 1.0300
Epoch 1/10, Batch 30/49, Loss: 0.8521
Epoch 1/10, Batch 40/49, Loss: 0.7725
Epoch 1/10, Train Loss: 1.0018, Valid Loss: 0.6365
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6696
Epoch 2/10, Batch 20/49, Loss: 0.4720
Epoch 2/10, Batch 30/49, Loss: 0.5827
Epoch 2/10, Batch 40/49, Loss: 0.4774
Epoch 2/10, Train Loss: 0.5422, Valid Loss: 0.4670
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4547
Epoch 3/10, Batch 20/49, Loss: 0.4489
Epoch 3/10, Batch 30/49, Loss: 0.4890
Epoch 3/10, Batch 40/49, Loss: 0.2589
Epoch 3/10, Train Loss: 0.4226, Valid Loss: 0.4104
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3248
Epoch 4/10, Batch 20/49, Loss: 0.3875
Epoch 4/10, Batch 30/49, Loss: 0.1882
Epoch 4/10, Batch 40/49, Loss: 0.2911
Epoch 4/10, Train Loss: 0.3652, Valid Loss: 0.3660
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.4438
Epoch 5/10, Batch 20/49, Loss: 0.2764
Epoch 5/10, Batch 30/49, Loss: 0.2751
Epoch 5/10, Batch 40/49, Loss: 0.2008
Epoch 5/10, Train Loss: 0.3039, Valid Loss: 0.3510
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1862
Epoch 6/10, Batch 20/49, Loss: 0.3707
Epoch 6/10, Batch 30/49, Loss: 0.3974
Epoch 6/10, Batch 40/49, Loss: 0.1934
Epoch 6/10, Train Loss: 0.2752, Valid Loss: 0.3560
Epoch 7/10, Batch 10/49, Loss: 0.2942
Epoch 7/10, Batch 20/49, Loss: 0.1815
Epoch 7/10, Batch 30/49, Loss: 0.2427
Epoch 7/10, Batch 40/49, Loss: 0.1645
Epoch 7/10, Train Loss: 0.2614, Valid Loss: 0.3404
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1703
Epoch 8/10, Batch 20/49, Loss: 0.3424
Epoch 8/10, Batch 30/49, Loss: 0.3513
Epoch 8/10, Batch 40/49, Loss: 0.1307
Epoch 8/10, Train Loss: 0.2506, Valid Loss: 0.3256
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2130
Epoch 9/10, Batch 20/49, Loss: 0.1908
Epoch 9/10, Batch 30/49, Loss: 0.4695
Epoch 9/10, Batch 40/49, Loss: 0.1667
Epoch 9/10, Train Loss: 0.2309, Valid Loss: 0.3165
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1724
Epoch 10/10, Batch 20/49, Loss: 0.1458
Epoch 10/10, Batch 30/49, Loss: 0.3524
Epoch 10/10, Batch 40/49, Loss: 0.1345
Epoch 10/10, Train Loss: 0.2060, Valid Loss: 0.2998
Model saved!
Accuracy: 0.9019
Precision: 0.8980
Recall: 0.9019
F1-score: 0.8983
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3158
Epoch 1/10, Batch 20/49, Loss: 1.0574
Epoch 1/10, Batch 30/49, Loss: 0.7487
Epoch 1/10, Batch 40/49, Loss: 0.6869
Epoch 1/10, Train Loss: 0.9867, Valid Loss: 0.6075
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6355
Epoch 2/10, Batch 20/49, Loss: 0.5037
Epoch 2/10, Batch 30/49, Loss: 0.5648
Epoch 2/10, Batch 40/49, Loss: 0.6212
Epoch 2/10, Train Loss: 0.5245, Valid Loss: 0.4462
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.6627
Epoch 3/10, Batch 20/49, Loss: 0.3182
Epoch 3/10, Batch 30/49, Loss: 0.2477
Epoch 3/10, Batch 40/49, Loss: 0.3465
Epoch 3/10, Train Loss: 0.4077, Valid Loss: 0.3673
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.3200
Epoch 4/10, Batch 20/49, Loss: 0.3343
Epoch 4/10, Batch 30/49, Loss: 0.2819
Epoch 4/10, Batch 40/49, Loss: 0.2361
Epoch 4/10, Train Loss: 0.3577, Valid Loss: 0.3197
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2380
Epoch 5/10, Batch 20/49, Loss: 0.5227
Epoch 5/10, Batch 30/49, Loss: 0.3274
Epoch 5/10, Batch 40/49, Loss: 0.2290
Epoch 5/10, Train Loss: 0.2997, Valid Loss: 0.2970
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.1759
Epoch 6/10, Batch 20/49, Loss: 0.2098
Epoch 6/10, Batch 30/49, Loss: 0.3825
Epoch 6/10, Batch 40/49, Loss: 0.2059
Epoch 6/10, Train Loss: 0.2810, Valid Loss: 0.2895
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2201
Epoch 7/10, Batch 20/49, Loss: 0.1855
Epoch 7/10, Batch 30/49, Loss: 0.4677
Epoch 7/10, Batch 40/49, Loss: 0.3316
Epoch 7/10, Train Loss: 0.2646, Valid Loss: 0.2841
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2025
Epoch 8/10, Batch 20/49, Loss: 0.2493
Epoch 8/10, Batch 30/49, Loss: 0.3139
Epoch 8/10, Batch 40/49, Loss: 0.2428
Epoch 8/10, Train Loss: 0.2445, Valid Loss: 0.2677
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1775
Epoch 9/10, Batch 20/49, Loss: 0.2885
Epoch 9/10, Batch 30/49, Loss: 0.5845
Epoch 9/10, Batch 40/49, Loss: 0.1401
Epoch 9/10, Train Loss: 0.2385, Valid Loss: 0.2514
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2230
Epoch 10/10, Batch 20/49, Loss: 0.2067
Epoch 10/10, Batch 30/49, Loss: 0.2072
Epoch 10/10, Batch 40/49, Loss: 0.1523
Epoch 10/10, Train Loss: 0.2025, Valid Loss: 0.2473
Model saved!
Accuracy: 0.9042
Precision: 0.9034
Recall: 0.9042
F1-score: 0.9006
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2945
Epoch 1/10, Batch 20/49, Loss: 0.9761
Epoch 1/10, Batch 30/49, Loss: 0.8408
Epoch 1/10, Batch 40/49, Loss: 0.6717
Epoch 1/10, Train Loss: 0.9799, Valid Loss: 0.6321
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6011
Epoch 2/10, Batch 20/49, Loss: 0.4239
Epoch 2/10, Batch 30/49, Loss: 0.5824
Epoch 2/10, Batch 40/49, Loss: 0.6619
Epoch 2/10, Train Loss: 0.5248, Valid Loss: 0.4423
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4738
Epoch 3/10, Batch 20/49, Loss: 0.4471
Epoch 3/10, Batch 30/49, Loss: 0.2901
Epoch 3/10, Batch 40/49, Loss: 0.2712
Epoch 3/10, Train Loss: 0.3964, Valid Loss: 0.3679
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2668
Epoch 4/10, Batch 20/49, Loss: 0.4371
Epoch 4/10, Batch 30/49, Loss: 0.2708
Epoch 4/10, Batch 40/49, Loss: 0.2914
Epoch 4/10, Train Loss: 0.3502, Valid Loss: 0.3194
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.1897
Epoch 5/10, Batch 20/49, Loss: 0.2604
Epoch 5/10, Batch 30/49, Loss: 0.2269
Epoch 5/10, Batch 40/49, Loss: 0.2453
Epoch 5/10, Train Loss: 0.2895, Valid Loss: 0.2944
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.3405
Epoch 6/10, Batch 20/49, Loss: 0.2700
Epoch 6/10, Batch 30/49, Loss: 0.3500
Epoch 6/10, Batch 40/49, Loss: 0.2068
Epoch 6/10, Train Loss: 0.2701, Valid Loss: 0.2740
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2142
Epoch 7/10, Batch 20/49, Loss: 0.2336
Epoch 7/10, Batch 30/49, Loss: 0.2662
Epoch 7/10, Batch 40/49, Loss: 0.1850
Epoch 7/10, Train Loss: 0.2436, Valid Loss: 0.2640
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1767
Epoch 8/10, Batch 20/49, Loss: 0.1297
Epoch 8/10, Batch 30/49, Loss: 0.2182
Epoch 8/10, Batch 40/49, Loss: 0.2166
Epoch 8/10, Train Loss: 0.2360, Valid Loss: 0.2439
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1647
Epoch 9/10, Batch 20/49, Loss: 0.1455
Epoch 9/10, Batch 30/49, Loss: 0.5956
Epoch 9/10, Batch 40/49, Loss: 0.1363
Epoch 9/10, Train Loss: 0.2263, Valid Loss: 0.2394
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1576
Epoch 10/10, Batch 20/49, Loss: 0.1784
Epoch 10/10, Batch 30/49, Loss: 0.2468
Epoch 10/10, Batch 40/49, Loss: 0.1149
Epoch 10/10, Train Loss: 0.2002, Valid Loss: 0.2379
Model saved!
Accuracy: 0.9054
Precision: 0.9019
Recall: 0.9054
F1-score: 0.9020
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.3201
Epoch 1/10, Batch 20/49, Loss: 1.0499
Epoch 1/10, Batch 30/49, Loss: 0.8301
Epoch 1/10, Batch 40/49, Loss: 0.7747
Epoch 1/10, Train Loss: 1.0058, Valid Loss: 0.5892
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7311
Epoch 2/10, Batch 20/49, Loss: 0.4841
Epoch 2/10, Batch 30/49, Loss: 0.5160
Epoch 2/10, Batch 40/49, Loss: 0.4350
Epoch 2/10, Train Loss: 0.5421, Valid Loss: 0.4315
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4777
Epoch 3/10, Batch 20/49, Loss: 0.5369
Epoch 3/10, Batch 30/49, Loss: 0.3199
Epoch 3/10, Batch 40/49, Loss: 0.2741
Epoch 3/10, Train Loss: 0.4280, Valid Loss: 0.3616
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2837
Epoch 4/10, Batch 20/49, Loss: 0.4282
Epoch 4/10, Batch 30/49, Loss: 0.2366
Epoch 4/10, Batch 40/49, Loss: 0.2638
Epoch 4/10, Train Loss: 0.3691, Valid Loss: 0.3191
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2734
Epoch 5/10, Batch 20/49, Loss: 0.3160
Epoch 5/10, Batch 30/49, Loss: 0.2930
Epoch 5/10, Batch 40/49, Loss: 0.2688
Epoch 5/10, Train Loss: 0.3165, Valid Loss: 0.3078
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2960
Epoch 6/10, Batch 20/49, Loss: 0.1918
Epoch 6/10, Batch 30/49, Loss: 0.3989
Epoch 6/10, Batch 40/49, Loss: 0.2610
Epoch 6/10, Train Loss: 0.2891, Valid Loss: 0.2939
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.3890
Epoch 7/10, Batch 20/49, Loss: 0.2443
Epoch 7/10, Batch 30/49, Loss: 0.3026
Epoch 7/10, Batch 40/49, Loss: 0.2150
Epoch 7/10, Train Loss: 0.2738, Valid Loss: 0.2825
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2989
Epoch 8/10, Batch 20/49, Loss: 0.3103
Epoch 8/10, Batch 30/49, Loss: 0.2596
Epoch 8/10, Batch 40/49, Loss: 0.1741
Epoch 8/10, Train Loss: 0.2520, Valid Loss: 0.2760
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.2978
Epoch 9/10, Batch 20/49, Loss: 0.3889
Epoch 9/10, Batch 30/49, Loss: 0.2981
Epoch 9/10, Batch 40/49, Loss: 0.1981
Epoch 9/10, Train Loss: 0.2254, Valid Loss: 0.2680
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2728
Epoch 10/10, Batch 20/49, Loss: 0.1198
Epoch 10/10, Batch 30/49, Loss: 0.2884
Epoch 10/10, Batch 40/49, Loss: 0.1556
Epoch 10/10, Train Loss: 0.2234, Valid Loss: 0.2572
Model saved!
Accuracy: 0.9112
Precision: 0.9080
Recall: 0.9112
F1-score: 0.9078
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2511
Epoch 1/10, Batch 20/49, Loss: 1.0553
Epoch 1/10, Batch 30/49, Loss: 0.7829
Epoch 1/10, Batch 40/49, Loss: 0.8495
Epoch 1/10, Train Loss: 0.9958, Valid Loss: 0.6327
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.6626
Epoch 2/10, Batch 20/49, Loss: 0.5379
Epoch 2/10, Batch 30/49, Loss: 0.5085
Epoch 2/10, Batch 40/49, Loss: 0.4867
Epoch 2/10, Train Loss: 0.5455, Valid Loss: 0.4530
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.4106
Epoch 3/10, Batch 20/49, Loss: 0.4177
Epoch 3/10, Batch 30/49, Loss: 0.3555
Epoch 3/10, Batch 40/49, Loss: 0.4107
Epoch 3/10, Train Loss: 0.4081, Valid Loss: 0.3825
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2876
Epoch 4/10, Batch 20/49, Loss: 0.4257
Epoch 4/10, Batch 30/49, Loss: 0.2977
Epoch 4/10, Batch 40/49, Loss: 0.2485
Epoch 4/10, Train Loss: 0.3579, Valid Loss: 0.3439
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2296
Epoch 5/10, Batch 20/49, Loss: 0.2948
Epoch 5/10, Batch 30/49, Loss: 0.2555
Epoch 5/10, Batch 40/49, Loss: 0.2658
Epoch 5/10, Train Loss: 0.3019, Valid Loss: 0.3170
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2688
Epoch 6/10, Batch 20/49, Loss: 0.2593
Epoch 6/10, Batch 30/49, Loss: 0.3051
Epoch 6/10, Batch 40/49, Loss: 0.3020
Epoch 6/10, Train Loss: 0.2751, Valid Loss: 0.3017
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2616
Epoch 7/10, Batch 20/49, Loss: 0.1894
Epoch 7/10, Batch 30/49, Loss: 0.2967
Epoch 7/10, Batch 40/49, Loss: 0.1812
Epoch 7/10, Train Loss: 0.2506, Valid Loss: 0.2948
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.1674
Epoch 8/10, Batch 20/49, Loss: 0.1794
Epoch 8/10, Batch 30/49, Loss: 0.2612
Epoch 8/10, Batch 40/49, Loss: 0.2629
Epoch 8/10, Train Loss: 0.2504, Valid Loss: 0.2969
Epoch 9/10, Batch 10/49, Loss: 0.2331
Epoch 9/10, Batch 20/49, Loss: 0.2297
Epoch 9/10, Batch 30/49, Loss: 0.2886
Epoch 9/10, Batch 40/49, Loss: 0.1644
Epoch 9/10, Train Loss: 0.2295, Valid Loss: 0.2833
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.2115
Epoch 10/10, Batch 20/49, Loss: 0.1196
Epoch 10/10, Batch 30/49, Loss: 0.2679
Epoch 10/10, Batch 40/49, Loss: 0.2083
Epoch 10/10, Train Loss: 0.1990, Valid Loss: 0.2810
Model saved!
Accuracy: 0.9054
Precision: 0.9012
Recall: 0.9054
F1-score: 0.9003
Memory Allocated after cleanup: 17.76 MB
End time: 2025-02-25 19:33:18.454656
Duration: 4:22:25


Mejor accuracy al acabar el algoritmo: 0.9171


Fitness check:

Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/49, Loss: 1.2018
Epoch 1/10, Batch 20/49, Loss: 1.0270
Epoch 1/10, Batch 30/49, Loss: 0.7366
Epoch 1/10, Batch 40/49, Loss: 0.9430
Epoch 1/10, Train Loss: 0.9822, Valid Loss: 0.6209
Model saved!
Epoch 2/10, Batch 10/49, Loss: 0.7376
Epoch 2/10, Batch 20/49, Loss: 0.3921
Epoch 2/10, Batch 30/49, Loss: 0.4872
Epoch 2/10, Batch 40/49, Loss: 0.5040
Epoch 2/10, Train Loss: 0.5356, Valid Loss: 0.4373
Model saved!
Epoch 3/10, Batch 10/49, Loss: 0.5094
Epoch 3/10, Batch 20/49, Loss: 0.4169
Epoch 3/10, Batch 30/49, Loss: 0.3163
Epoch 3/10, Batch 40/49, Loss: 0.3263
Epoch 3/10, Train Loss: 0.4057, Valid Loss: 0.3639
Model saved!
Epoch 4/10, Batch 10/49, Loss: 0.2648
Epoch 4/10, Batch 20/49, Loss: 0.3707
Epoch 4/10, Batch 30/49, Loss: 0.3470
Epoch 4/10, Batch 40/49, Loss: 0.3517
Epoch 4/10, Train Loss: 0.3604, Valid Loss: 0.3110
Model saved!
Epoch 5/10, Batch 10/49, Loss: 0.2970
Epoch 5/10, Batch 20/49, Loss: 0.1826
Epoch 5/10, Batch 30/49, Loss: 0.3087
Epoch 5/10, Batch 40/49, Loss: 0.1586
Epoch 5/10, Train Loss: 0.3054, Valid Loss: 0.2918
Model saved!
Epoch 6/10, Batch 10/49, Loss: 0.2184
Epoch 6/10, Batch 20/49, Loss: 0.1872
Epoch 6/10, Batch 30/49, Loss: 0.2477
Epoch 6/10, Batch 40/49, Loss: 0.2396
Epoch 6/10, Train Loss: 0.2836, Valid Loss: 0.2824
Model saved!
Epoch 7/10, Batch 10/49, Loss: 0.2374
Epoch 7/10, Batch 20/49, Loss: 0.2261
Epoch 7/10, Batch 30/49, Loss: 0.3229
Epoch 7/10, Batch 40/49, Loss: 0.3233
Epoch 7/10, Train Loss: 0.2659, Valid Loss: 0.2712
Model saved!
Epoch 8/10, Batch 10/49, Loss: 0.2062
Epoch 8/10, Batch 20/49, Loss: 0.2917
Epoch 8/10, Batch 30/49, Loss: 0.2746
Epoch 8/10, Batch 40/49, Loss: 0.2231
Epoch 8/10, Train Loss: 0.2470, Valid Loss: 0.2594
Model saved!
Epoch 9/10, Batch 10/49, Loss: 0.1382
Epoch 9/10, Batch 20/49, Loss: 0.2210
Epoch 9/10, Batch 30/49, Loss: 0.5535
Epoch 9/10, Batch 40/49, Loss: 0.1154
Epoch 9/10, Train Loss: 0.2413, Valid Loss: 0.2519
Model saved!
Epoch 10/10, Batch 10/49, Loss: 0.1873
Epoch 10/10, Batch 20/49, Loss: 0.1005
Epoch 10/10, Batch 30/49, Loss: 0.1799
Epoch 10/10, Batch 40/49, Loss: 0.2175
Epoch 10/10, Train Loss: 0.2086, Valid Loss: 0.2458
Model saved!
Accuracy: 0.9171
Precision: 0.9143
Recall: 0.9171
F1-score: 0.9144
Memory Allocated after cleanup: 17.76 MB


Mejor accuracy encontrado: 0.9171


--------------------------------------mobilenet  BUSQUEDA LOCAL  50%-------------------------------------------------
Start time: 2025-02-25 19:35:55.125144
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4518
Epoch 1/10, Batch 20/97, Loss: 0.9353
Epoch 1/10, Batch 30/97, Loss: 0.8851
Epoch 1/10, Batch 40/97, Loss: 0.7571
Epoch 1/10, Batch 50/97, Loss: 0.6339
Epoch 1/10, Batch 60/97, Loss: 0.5984
Epoch 1/10, Batch 70/97, Loss: 0.6678
Epoch 1/10, Batch 80/97, Loss: 0.4635
Epoch 1/10, Batch 90/97, Loss: 0.5123
Epoch 1/10, Train Loss: 0.7820, Valid Loss: 0.4497
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4706
Epoch 2/10, Batch 20/97, Loss: 0.4052
Epoch 2/10, Batch 30/97, Loss: 0.3695
Epoch 2/10, Batch 40/97, Loss: 0.3808
Epoch 2/10, Batch 50/97, Loss: 0.4643
Epoch 2/10, Batch 60/97, Loss: 0.4259
Epoch 2/10, Batch 70/97, Loss: 0.2600
Epoch 2/10, Batch 80/97, Loss: 0.5268
Epoch 2/10, Batch 90/97, Loss: 0.4278
Epoch 2/10, Train Loss: 0.3990, Valid Loss: 0.3522
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3822
Epoch 3/10, Batch 20/97, Loss: 0.3441
Epoch 3/10, Batch 30/97, Loss: 0.2863
Epoch 3/10, Batch 40/97, Loss: 0.3339
Epoch 3/10, Batch 50/97, Loss: 0.2133
Epoch 3/10, Batch 60/97, Loss: 0.2377
Epoch 3/10, Batch 70/97, Loss: 0.2434
Epoch 3/10, Batch 80/97, Loss: 0.2360
Epoch 3/10, Batch 90/97, Loss: 0.1914
Epoch 3/10, Train Loss: 0.3316, Valid Loss: 0.2963
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3470
Epoch 4/10, Batch 20/97, Loss: 0.2143
Epoch 4/10, Batch 30/97, Loss: 0.5408
Epoch 4/10, Batch 40/97, Loss: 0.2316
Epoch 4/10, Batch 50/97, Loss: 0.2607
Epoch 4/10, Batch 60/97, Loss: 0.2506
Epoch 4/10, Batch 70/97, Loss: 0.1870
Epoch 4/10, Batch 80/97, Loss: 0.2427
Epoch 4/10, Batch 90/97, Loss: 0.3094
Epoch 4/10, Train Loss: 0.2953, Valid Loss: 0.2677
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2221
Epoch 5/10, Batch 20/97, Loss: 0.1416
Epoch 5/10, Batch 30/97, Loss: 0.2242
Epoch 5/10, Batch 40/97, Loss: 0.1370
Epoch 5/10, Batch 50/97, Loss: 0.2545
Epoch 5/10, Batch 60/97, Loss: 0.3426
Epoch 5/10, Batch 70/97, Loss: 0.1819
Epoch 5/10, Batch 80/97, Loss: 0.3086
Epoch 5/10, Batch 90/97, Loss: 0.4024
Epoch 5/10, Train Loss: 0.2641, Valid Loss: 0.2580
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3173
Epoch 6/10, Batch 20/97, Loss: 0.2600
Epoch 6/10, Batch 30/97, Loss: 0.1912
Epoch 6/10, Batch 40/97, Loss: 0.3124
Epoch 6/10, Batch 50/97, Loss: 0.2209
Epoch 6/10, Batch 60/97, Loss: 0.2164
Epoch 6/10, Batch 70/97, Loss: 0.2673
Epoch 6/10, Batch 80/97, Loss: 0.2096
Epoch 6/10, Batch 90/97, Loss: 0.2174
Epoch 6/10, Train Loss: 0.2498, Valid Loss: 0.2467
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2285
Epoch 7/10, Batch 20/97, Loss: 0.1512
Epoch 7/10, Batch 30/97, Loss: 0.1535
Epoch 7/10, Batch 40/97, Loss: 0.1240
Epoch 7/10, Batch 50/97, Loss: 0.2169
Epoch 7/10, Batch 60/97, Loss: 0.4316
Epoch 7/10, Batch 70/97, Loss: 0.1177
Epoch 7/10, Batch 80/97, Loss: 0.2054
Epoch 7/10, Batch 90/97, Loss: 0.3124
Epoch 7/10, Train Loss: 0.2547, Valid Loss: 0.2380
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1273
Epoch 8/10, Batch 20/97, Loss: 0.1509
Epoch 8/10, Batch 30/97, Loss: 0.0729
Epoch 8/10, Batch 40/97, Loss: 0.0690
Epoch 8/10, Batch 50/97, Loss: 0.1631
Epoch 8/10, Batch 60/97, Loss: 0.3090
Epoch 8/10, Batch 70/97, Loss: 0.2214
Epoch 8/10, Batch 80/97, Loss: 0.2234
Epoch 8/10, Batch 90/97, Loss: 0.1890
Epoch 8/10, Train Loss: 0.2264, Valid Loss: 0.2284
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2036
Epoch 9/10, Batch 20/97, Loss: 0.1513
Epoch 9/10, Batch 30/97, Loss: 0.1392
Epoch 9/10, Batch 40/97, Loss: 0.1699
Epoch 9/10, Batch 50/97, Loss: 0.2091
Epoch 9/10, Batch 60/97, Loss: 0.2330
Epoch 9/10, Batch 70/97, Loss: 0.1331
Epoch 9/10, Batch 80/97, Loss: 0.1622
Epoch 9/10, Batch 90/97, Loss: 0.2287
Epoch 9/10, Train Loss: 0.2155, Valid Loss: 0.2306
Epoch 10/10, Batch 10/97, Loss: 0.2543
Epoch 10/10, Batch 20/97, Loss: 0.2197
Epoch 10/10, Batch 30/97, Loss: 0.1148
Epoch 10/10, Batch 40/97, Loss: 0.1696
Epoch 10/10, Batch 50/97, Loss: 0.3632
Epoch 10/10, Batch 60/97, Loss: 0.1021
Epoch 10/10, Batch 70/97, Loss: 0.3314
Epoch 10/10, Batch 80/97, Loss: 0.1518
Epoch 10/10, Batch 90/97, Loss: 0.1222
Epoch 10/10, Train Loss: 0.2082, Valid Loss: 0.2188
Model saved!
Accuracy: 0.9159
Precision: 0.9151
Recall: 0.9159
F1-score: 0.9149
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4566
Epoch 1/10, Batch 20/97, Loss: 0.9889
Epoch 1/10, Batch 30/97, Loss: 0.8017
Epoch 1/10, Batch 40/97, Loss: 0.7054
Epoch 1/10, Batch 50/97, Loss: 0.6690
Epoch 1/10, Batch 60/97, Loss: 0.6525
Epoch 1/10, Batch 70/97, Loss: 0.5751
Epoch 1/10, Batch 80/97, Loss: 0.5028
Epoch 1/10, Batch 90/97, Loss: 0.4854
Epoch 1/10, Train Loss: 0.7720, Valid Loss: 0.4590
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3912
Epoch 2/10, Batch 20/97, Loss: 0.3445
Epoch 2/10, Batch 30/97, Loss: 0.4060
Epoch 2/10, Batch 40/97, Loss: 0.3834
Epoch 2/10, Batch 50/97, Loss: 0.6513
Epoch 2/10, Batch 60/97, Loss: 0.3660
Epoch 2/10, Batch 70/97, Loss: 0.2659
Epoch 2/10, Batch 80/97, Loss: 0.2394
Epoch 2/10, Batch 90/97, Loss: 0.5357
Epoch 2/10, Train Loss: 0.3884, Valid Loss: 0.3598
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2758
Epoch 3/10, Batch 20/97, Loss: 0.2498
Epoch 3/10, Batch 30/97, Loss: 0.3055
Epoch 3/10, Batch 40/97, Loss: 0.3809
Epoch 3/10, Batch 50/97, Loss: 0.3976
Epoch 3/10, Batch 60/97, Loss: 0.1971
Epoch 3/10, Batch 70/97, Loss: 0.2352
Epoch 3/10, Batch 80/97, Loss: 0.4786
Epoch 3/10, Batch 90/97, Loss: 0.2567
Epoch 3/10, Train Loss: 0.3242, Valid Loss: 0.3280
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2471
Epoch 4/10, Batch 20/97, Loss: 0.2733
Epoch 4/10, Batch 30/97, Loss: 0.2303
Epoch 4/10, Batch 40/97, Loss: 0.3948
Epoch 4/10, Batch 50/97, Loss: 0.2289
Epoch 4/10, Batch 60/97, Loss: 0.1760
Epoch 4/10, Batch 70/97, Loss: 0.1849
Epoch 4/10, Batch 80/97, Loss: 0.1745
Epoch 4/10, Batch 90/97, Loss: 0.1663
Epoch 4/10, Train Loss: 0.2930, Valid Loss: 0.3030
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3908
Epoch 5/10, Batch 20/97, Loss: 0.2228
Epoch 5/10, Batch 30/97, Loss: 0.1179
Epoch 5/10, Batch 40/97, Loss: 0.3293
Epoch 5/10, Batch 50/97, Loss: 0.2464
Epoch 5/10, Batch 60/97, Loss: 0.2831
Epoch 5/10, Batch 70/97, Loss: 0.1758
Epoch 5/10, Batch 80/97, Loss: 0.3801
Epoch 5/10, Batch 90/97, Loss: 0.3696
Epoch 5/10, Train Loss: 0.2519, Valid Loss: 0.2833
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2052
Epoch 6/10, Batch 20/97, Loss: 0.2975
Epoch 6/10, Batch 30/97, Loss: 0.1388
Epoch 6/10, Batch 40/97, Loss: 0.3074
Epoch 6/10, Batch 50/97, Loss: 0.1483
Epoch 6/10, Batch 60/97, Loss: 0.1571
Epoch 6/10, Batch 70/97, Loss: 0.2151
Epoch 6/10, Batch 80/97, Loss: 0.1066
Epoch 6/10, Batch 90/97, Loss: 0.2242
Epoch 6/10, Train Loss: 0.2375, Valid Loss: 0.2773
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4030
Epoch 7/10, Batch 20/97, Loss: 0.0893
Epoch 7/10, Batch 30/97, Loss: 0.1954
Epoch 7/10, Batch 40/97, Loss: 0.1155
Epoch 7/10, Batch 50/97, Loss: 0.3328
Epoch 7/10, Batch 60/97, Loss: 0.2738
Epoch 7/10, Batch 70/97, Loss: 0.1543
Epoch 7/10, Batch 80/97, Loss: 0.2197
Epoch 7/10, Batch 90/97, Loss: 0.3508
Epoch 7/10, Train Loss: 0.2390, Valid Loss: 0.2680
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1926
Epoch 8/10, Batch 20/97, Loss: 0.2445
Epoch 8/10, Batch 30/97, Loss: 0.1177
Epoch 8/10, Batch 40/97, Loss: 0.1923
Epoch 8/10, Batch 50/97, Loss: 0.2302
Epoch 8/10, Batch 60/97, Loss: 0.2112
Epoch 8/10, Batch 70/97, Loss: 0.2293
Epoch 8/10, Batch 80/97, Loss: 0.1682
Epoch 8/10, Batch 90/97, Loss: 0.1295
Epoch 8/10, Train Loss: 0.2168, Valid Loss: 0.2641
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1013
Epoch 9/10, Batch 20/97, Loss: 0.1732
Epoch 9/10, Batch 30/97, Loss: 0.2753
Epoch 9/10, Batch 40/97, Loss: 0.1359
Epoch 9/10, Batch 50/97, Loss: 0.3170
Epoch 9/10, Batch 60/97, Loss: 0.1234
Epoch 9/10, Batch 70/97, Loss: 0.1269
Epoch 9/10, Batch 80/97, Loss: 0.1372
Epoch 9/10, Batch 90/97, Loss: 0.1456
Epoch 9/10, Train Loss: 0.2109, Valid Loss: 0.2624
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3451
Epoch 10/10, Batch 20/97, Loss: 0.2665
Epoch 10/10, Batch 30/97, Loss: 0.2732
Epoch 10/10, Batch 40/97, Loss: 0.1885
Epoch 10/10, Batch 50/97, Loss: 0.2045
Epoch 10/10, Batch 60/97, Loss: 0.1401
Epoch 10/10, Batch 70/97, Loss: 0.2395
Epoch 10/10, Batch 80/97, Loss: 0.2391
Epoch 10/10, Batch 90/97, Loss: 0.2035
Epoch 10/10, Train Loss: 0.2013, Valid Loss: 0.2563
Model saved!
Accuracy: 0.9171
Precision: 0.9147
Recall: 0.9171
F1-score: 0.9154
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 2. Fitness: 0.9171
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5025
Epoch 1/10, Batch 20/97, Loss: 1.0359
Epoch 1/10, Batch 30/97, Loss: 0.8094
Epoch 1/10, Batch 40/97, Loss: 0.7429
Epoch 1/10, Batch 50/97, Loss: 0.5378
Epoch 1/10, Batch 60/97, Loss: 0.6741
Epoch 1/10, Batch 70/97, Loss: 0.4573
Epoch 1/10, Batch 80/97, Loss: 0.4177
Epoch 1/10, Batch 90/97, Loss: 0.4381
Epoch 1/10, Train Loss: 0.7751, Valid Loss: 0.4403
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5603
Epoch 2/10, Batch 20/97, Loss: 0.4201
Epoch 2/10, Batch 30/97, Loss: 0.5283
Epoch 2/10, Batch 40/97, Loss: 0.4214
Epoch 2/10, Batch 50/97, Loss: 0.7185
Epoch 2/10, Batch 60/97, Loss: 0.3690
Epoch 2/10, Batch 70/97, Loss: 0.3851
Epoch 2/10, Batch 80/97, Loss: 0.2949
Epoch 2/10, Batch 90/97, Loss: 0.4258
Epoch 2/10, Train Loss: 0.3945, Valid Loss: 0.3227
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3755
Epoch 3/10, Batch 20/97, Loss: 0.2499
Epoch 3/10, Batch 30/97, Loss: 0.3814
Epoch 3/10, Batch 40/97, Loss: 0.2479
Epoch 3/10, Batch 50/97, Loss: 0.1825
Epoch 3/10, Batch 60/97, Loss: 0.3772
Epoch 3/10, Batch 70/97, Loss: 0.2317
Epoch 3/10, Batch 80/97, Loss: 0.3210
Epoch 3/10, Batch 90/97, Loss: 0.2687
Epoch 3/10, Train Loss: 0.3270, Valid Loss: 0.2830
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3004
Epoch 4/10, Batch 20/97, Loss: 0.1689
Epoch 4/10, Batch 30/97, Loss: 0.3480
Epoch 4/10, Batch 40/97, Loss: 0.2983
Epoch 4/10, Batch 50/97, Loss: 0.3305
Epoch 4/10, Batch 60/97, Loss: 0.1852
Epoch 4/10, Batch 70/97, Loss: 0.2670
Epoch 4/10, Batch 80/97, Loss: 0.2808
Epoch 4/10, Batch 90/97, Loss: 0.3085
Epoch 4/10, Train Loss: 0.2932, Valid Loss: 0.2628
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2296
Epoch 5/10, Batch 20/97, Loss: 0.1776
Epoch 5/10, Batch 30/97, Loss: 0.2074
Epoch 5/10, Batch 40/97, Loss: 0.1762
Epoch 5/10, Batch 50/97, Loss: 0.2366
Epoch 5/10, Batch 60/97, Loss: 0.1933
Epoch 5/10, Batch 70/97, Loss: 0.2743
Epoch 5/10, Batch 80/97, Loss: 0.3426
Epoch 5/10, Batch 90/97, Loss: 0.2185
Epoch 5/10, Train Loss: 0.2599, Valid Loss: 0.2461
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1235
Epoch 6/10, Batch 20/97, Loss: 0.4504
Epoch 6/10, Batch 30/97, Loss: 0.2696
Epoch 6/10, Batch 40/97, Loss: 0.2847
Epoch 6/10, Batch 50/97, Loss: 0.2302
Epoch 6/10, Batch 60/97, Loss: 0.2408
Epoch 6/10, Batch 70/97, Loss: 0.1406
Epoch 6/10, Batch 80/97, Loss: 0.2493
Epoch 6/10, Batch 90/97, Loss: 0.2229
Epoch 6/10, Train Loss: 0.2431, Valid Loss: 0.2333
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2292
Epoch 7/10, Batch 20/97, Loss: 0.1783
Epoch 7/10, Batch 30/97, Loss: 0.2491
Epoch 7/10, Batch 40/97, Loss: 0.2072
Epoch 7/10, Batch 50/97, Loss: 0.3086
Epoch 7/10, Batch 60/97, Loss: 0.4376
Epoch 7/10, Batch 70/97, Loss: 0.1643
Epoch 7/10, Batch 80/97, Loss: 0.3019
Epoch 7/10, Batch 90/97, Loss: 0.2577
Epoch 7/10, Train Loss: 0.2453, Valid Loss: 0.2316
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1613
Epoch 8/10, Batch 20/97, Loss: 0.1651
Epoch 8/10, Batch 30/97, Loss: 0.1259
Epoch 8/10, Batch 40/97, Loss: 0.2265
Epoch 8/10, Batch 50/97, Loss: 0.3310
Epoch 8/10, Batch 60/97, Loss: 0.1769
Epoch 8/10, Batch 70/97, Loss: 0.3110
Epoch 8/10, Batch 80/97, Loss: 0.2827
Epoch 8/10, Batch 90/97, Loss: 0.2618
Epoch 8/10, Train Loss: 0.2275, Valid Loss: 0.2248
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2601
Epoch 9/10, Batch 20/97, Loss: 0.0959
Epoch 9/10, Batch 30/97, Loss: 0.1775
Epoch 9/10, Batch 40/97, Loss: 0.3526
Epoch 9/10, Batch 50/97, Loss: 0.1148
Epoch 9/10, Batch 60/97, Loss: 0.1211
Epoch 9/10, Batch 70/97, Loss: 0.2200
Epoch 9/10, Batch 80/97, Loss: 0.1159
Epoch 9/10, Batch 90/97, Loss: 0.1836
Epoch 9/10, Train Loss: 0.2168, Valid Loss: 0.2214
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2279
Epoch 10/10, Batch 20/97, Loss: 0.0780
Epoch 10/10, Batch 30/97, Loss: 0.2292
Epoch 10/10, Batch 40/97, Loss: 0.2675
Epoch 10/10, Batch 50/97, Loss: 0.2429
Epoch 10/10, Batch 60/97, Loss: 0.0590
Epoch 10/10, Batch 70/97, Loss: 0.1853
Epoch 10/10, Batch 80/97, Loss: 0.2152
Epoch 10/10, Batch 90/97, Loss: 0.2055
Epoch 10/10, Train Loss: 0.2021, Valid Loss: 0.2157
Model saved!
Accuracy: 0.9124
Precision: 0.9098
Recall: 0.9124
F1-score: 0.9097
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5537
Epoch 1/10, Batch 20/97, Loss: 1.0136
Epoch 1/10, Batch 30/97, Loss: 0.8597
Epoch 1/10, Batch 40/97, Loss: 0.7135
Epoch 1/10, Batch 50/97, Loss: 0.6491
Epoch 1/10, Batch 60/97, Loss: 0.6106
Epoch 1/10, Batch 70/97, Loss: 0.4391
Epoch 1/10, Batch 80/97, Loss: 0.5163
Epoch 1/10, Batch 90/97, Loss: 0.5565
Epoch 1/10, Train Loss: 0.7763, Valid Loss: 0.4039
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3992
Epoch 2/10, Batch 20/97, Loss: 0.5027
Epoch 2/10, Batch 30/97, Loss: 0.4485
Epoch 2/10, Batch 40/97, Loss: 0.2774
Epoch 2/10, Batch 50/97, Loss: 0.5290
Epoch 2/10, Batch 60/97, Loss: 0.3055
Epoch 2/10, Batch 70/97, Loss: 0.3784
Epoch 2/10, Batch 80/97, Loss: 0.4103
Epoch 2/10, Batch 90/97, Loss: 0.2939
Epoch 2/10, Train Loss: 0.3950, Valid Loss: 0.2962
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3074
Epoch 3/10, Batch 20/97, Loss: 0.3136
Epoch 3/10, Batch 30/97, Loss: 0.3419
Epoch 3/10, Batch 40/97, Loss: 0.1789
Epoch 3/10, Batch 50/97, Loss: 0.2703
Epoch 3/10, Batch 60/97, Loss: 0.1842
Epoch 3/10, Batch 70/97, Loss: 0.1872
Epoch 3/10, Batch 80/97, Loss: 0.2488
Epoch 3/10, Batch 90/97, Loss: 0.2993
Epoch 3/10, Train Loss: 0.3296, Valid Loss: 0.2592
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3848
Epoch 4/10, Batch 20/97, Loss: 0.2959
Epoch 4/10, Batch 30/97, Loss: 0.3030
Epoch 4/10, Batch 40/97, Loss: 0.3008
Epoch 4/10, Batch 50/97, Loss: 0.2256
Epoch 4/10, Batch 60/97, Loss: 0.1991
Epoch 4/10, Batch 70/97, Loss: 0.2533
Epoch 4/10, Batch 80/97, Loss: 0.1931
Epoch 4/10, Batch 90/97, Loss: 0.3201
Epoch 4/10, Train Loss: 0.2886, Valid Loss: 0.2342
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2542
Epoch 5/10, Batch 20/97, Loss: 0.1638
Epoch 5/10, Batch 30/97, Loss: 0.1785
Epoch 5/10, Batch 40/97, Loss: 0.2271
Epoch 5/10, Batch 50/97, Loss: 0.2657
Epoch 5/10, Batch 60/97, Loss: 0.3235
Epoch 5/10, Batch 70/97, Loss: 0.1578
Epoch 5/10, Batch 80/97, Loss: 0.4566
Epoch 5/10, Batch 90/97, Loss: 0.3341
Epoch 5/10, Train Loss: 0.2693, Valid Loss: 0.2257
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1559
Epoch 6/10, Batch 20/97, Loss: 0.2940
Epoch 6/10, Batch 30/97, Loss: 0.2010
Epoch 6/10, Batch 40/97, Loss: 0.2387
Epoch 6/10, Batch 50/97, Loss: 0.1925
Epoch 6/10, Batch 60/97, Loss: 0.2894
Epoch 6/10, Batch 70/97, Loss: 0.2489
Epoch 6/10, Batch 80/97, Loss: 0.2274
Epoch 6/10, Batch 90/97, Loss: 0.2108
Epoch 6/10, Train Loss: 0.2442, Valid Loss: 0.2183
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2729
Epoch 7/10, Batch 20/97, Loss: 0.1768
Epoch 7/10, Batch 30/97, Loss: 0.1638
Epoch 7/10, Batch 40/97, Loss: 0.2423
Epoch 7/10, Batch 50/97, Loss: 0.1518
Epoch 7/10, Batch 60/97, Loss: 0.4934
Epoch 7/10, Batch 70/97, Loss: 0.1825
Epoch 7/10, Batch 80/97, Loss: 0.1537
Epoch 7/10, Batch 90/97, Loss: 0.2009
Epoch 7/10, Train Loss: 0.2491, Valid Loss: 0.2066
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2132
Epoch 8/10, Batch 20/97, Loss: 0.2084
Epoch 8/10, Batch 30/97, Loss: 0.2159
Epoch 8/10, Batch 40/97, Loss: 0.1445
Epoch 8/10, Batch 50/97, Loss: 0.2573
Epoch 8/10, Batch 60/97, Loss: 0.1266
Epoch 8/10, Batch 70/97, Loss: 0.2305
Epoch 8/10, Batch 80/97, Loss: 0.1473
Epoch 8/10, Batch 90/97, Loss: 0.2148
Epoch 8/10, Train Loss: 0.2239, Valid Loss: 0.2022
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1619
Epoch 9/10, Batch 20/97, Loss: 0.0926
Epoch 9/10, Batch 30/97, Loss: 0.2401
Epoch 9/10, Batch 40/97, Loss: 0.2298
Epoch 9/10, Batch 50/97, Loss: 0.3045
Epoch 9/10, Batch 60/97, Loss: 0.2206
Epoch 9/10, Batch 70/97, Loss: 0.2246
Epoch 9/10, Batch 80/97, Loss: 0.0908
Epoch 9/10, Batch 90/97, Loss: 0.2761
Epoch 9/10, Train Loss: 0.2139, Valid Loss: 0.2007
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2674
Epoch 10/10, Batch 20/97, Loss: 0.1528
Epoch 10/10, Batch 30/97, Loss: 0.1900
Epoch 10/10, Batch 40/97, Loss: 0.2396
Epoch 10/10, Batch 50/97, Loss: 0.2750
Epoch 10/10, Batch 60/97, Loss: 0.1580
Epoch 10/10, Batch 70/97, Loss: 0.1624
Epoch 10/10, Batch 80/97, Loss: 0.2616
Epoch 10/10, Batch 90/97, Loss: 0.1079
Epoch 10/10, Train Loss: 0.2099, Valid Loss: 0.1968
Model saved!
Accuracy: 0.9136
Precision: 0.9110
Recall: 0.9136
F1-score: 0.9113
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5059
Epoch 1/10, Batch 20/97, Loss: 0.9398
Epoch 1/10, Batch 30/97, Loss: 0.8267
Epoch 1/10, Batch 40/97, Loss: 0.7284
Epoch 1/10, Batch 50/97, Loss: 0.6631
Epoch 1/10, Batch 60/97, Loss: 0.5933
Epoch 1/10, Batch 70/97, Loss: 0.6687
Epoch 1/10, Batch 80/97, Loss: 0.5728
Epoch 1/10, Batch 90/97, Loss: 0.4506
Epoch 1/10, Train Loss: 0.7731, Valid Loss: 0.4408
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3687
Epoch 2/10, Batch 20/97, Loss: 0.6362
Epoch 2/10, Batch 30/97, Loss: 0.2865
Epoch 2/10, Batch 40/97, Loss: 0.3914
Epoch 2/10, Batch 50/97, Loss: 0.6822
Epoch 2/10, Batch 60/97, Loss: 0.3021
Epoch 2/10, Batch 70/97, Loss: 0.2165
Epoch 2/10, Batch 80/97, Loss: 0.3503
Epoch 2/10, Batch 90/97, Loss: 0.6396
Epoch 2/10, Train Loss: 0.3917, Valid Loss: 0.3283
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2864
Epoch 3/10, Batch 20/97, Loss: 0.2526
Epoch 3/10, Batch 30/97, Loss: 0.3347
Epoch 3/10, Batch 40/97, Loss: 0.2873
Epoch 3/10, Batch 50/97, Loss: 0.3384
Epoch 3/10, Batch 60/97, Loss: 0.2591
Epoch 3/10, Batch 70/97, Loss: 0.2436
Epoch 3/10, Batch 80/97, Loss: 0.2468
Epoch 3/10, Batch 90/97, Loss: 0.4799
Epoch 3/10, Train Loss: 0.3241, Valid Loss: 0.2791
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2110
Epoch 4/10, Batch 20/97, Loss: 0.2838
Epoch 4/10, Batch 30/97, Loss: 0.3278
Epoch 4/10, Batch 40/97, Loss: 0.2386
Epoch 4/10, Batch 50/97, Loss: 0.2029
Epoch 4/10, Batch 60/97, Loss: 0.2201
Epoch 4/10, Batch 70/97, Loss: 0.2326
Epoch 4/10, Batch 80/97, Loss: 0.2222
Epoch 4/10, Batch 90/97, Loss: 0.2882
Epoch 4/10, Train Loss: 0.2808, Valid Loss: 0.2550
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1362
Epoch 5/10, Batch 20/97, Loss: 0.2576
Epoch 5/10, Batch 30/97, Loss: 0.2173
Epoch 5/10, Batch 40/97, Loss: 0.1319
Epoch 5/10, Batch 50/97, Loss: 0.2687
Epoch 5/10, Batch 60/97, Loss: 0.3165
Epoch 5/10, Batch 70/97, Loss: 0.2276
Epoch 5/10, Batch 80/97, Loss: 0.2713
Epoch 5/10, Batch 90/97, Loss: 0.4685
Epoch 5/10, Train Loss: 0.2599, Valid Loss: 0.2477
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2535
Epoch 6/10, Batch 20/97, Loss: 0.1706
Epoch 6/10, Batch 30/97, Loss: 0.2646
Epoch 6/10, Batch 40/97, Loss: 0.2003
Epoch 6/10, Batch 50/97, Loss: 0.1666
Epoch 6/10, Batch 60/97, Loss: 0.2215
Epoch 6/10, Batch 70/97, Loss: 0.2230
Epoch 6/10, Batch 80/97, Loss: 0.2229
Epoch 6/10, Batch 90/97, Loss: 0.2757
Epoch 6/10, Train Loss: 0.2394, Valid Loss: 0.2315
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3054
Epoch 7/10, Batch 20/97, Loss: 0.1086
Epoch 7/10, Batch 30/97, Loss: 0.2033
Epoch 7/10, Batch 40/97, Loss: 0.1382
Epoch 7/10, Batch 50/97, Loss: 0.0951
Epoch 7/10, Batch 60/97, Loss: 0.2734
Epoch 7/10, Batch 70/97, Loss: 0.2296
Epoch 7/10, Batch 80/97, Loss: 0.2462
Epoch 7/10, Batch 90/97, Loss: 0.1694
Epoch 7/10, Train Loss: 0.2433, Valid Loss: 0.2213
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1377
Epoch 8/10, Batch 20/97, Loss: 0.1156
Epoch 8/10, Batch 30/97, Loss: 0.3145
Epoch 8/10, Batch 40/97, Loss: 0.1285
Epoch 8/10, Batch 50/97, Loss: 0.1527
Epoch 8/10, Batch 60/97, Loss: 0.1568
Epoch 8/10, Batch 70/97, Loss: 0.2341
Epoch 8/10, Batch 80/97, Loss: 0.2589
Epoch 8/10, Batch 90/97, Loss: 0.1770
Epoch 8/10, Train Loss: 0.2233, Valid Loss: 0.2149
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1526
Epoch 9/10, Batch 20/97, Loss: 0.1951
Epoch 9/10, Batch 30/97, Loss: 0.2685
Epoch 9/10, Batch 40/97, Loss: 0.2347
Epoch 9/10, Batch 50/97, Loss: 0.1684
Epoch 9/10, Batch 60/97, Loss: 0.1946
Epoch 9/10, Batch 70/97, Loss: 0.1974
Epoch 9/10, Batch 80/97, Loss: 0.2574
Epoch 9/10, Batch 90/97, Loss: 0.2651
Epoch 9/10, Train Loss: 0.2178, Valid Loss: 0.2232
Epoch 10/10, Batch 10/97, Loss: 0.3200
Epoch 10/10, Batch 20/97, Loss: 0.1356
Epoch 10/10, Batch 30/97, Loss: 0.3211
Epoch 10/10, Batch 40/97, Loss: 0.1503
Epoch 10/10, Batch 50/97, Loss: 0.2061
Epoch 10/10, Batch 60/97, Loss: 0.0976
Epoch 10/10, Batch 70/97, Loss: 0.1252
Epoch 10/10, Batch 80/97, Loss: 0.2535
Epoch 10/10, Batch 90/97, Loss: 0.2419
Epoch 10/10, Train Loss: 0.1989, Valid Loss: 0.2075
Model saved!
Accuracy: 0.9100
Precision: 0.9076
Recall: 0.9100
F1-score: 0.9081
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4821
Epoch 1/10, Batch 20/97, Loss: 1.0354
Epoch 1/10, Batch 30/97, Loss: 0.9761
Epoch 1/10, Batch 40/97, Loss: 0.8707
Epoch 1/10, Batch 50/97, Loss: 0.7461
Epoch 1/10, Batch 60/97, Loss: 0.6823
Epoch 1/10, Batch 70/97, Loss: 0.5129
Epoch 1/10, Batch 80/97, Loss: 0.5552
Epoch 1/10, Batch 90/97, Loss: 0.4670
Epoch 1/10, Train Loss: 0.7792, Valid Loss: 0.4379
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4147
Epoch 2/10, Batch 20/97, Loss: 0.5417
Epoch 2/10, Batch 30/97, Loss: 0.4137
Epoch 2/10, Batch 40/97, Loss: 0.3583
Epoch 2/10, Batch 50/97, Loss: 0.6915
Epoch 2/10, Batch 60/97, Loss: 0.4162
Epoch 2/10, Batch 70/97, Loss: 0.3208
Epoch 2/10, Batch 80/97, Loss: 0.3957
Epoch 2/10, Batch 90/97, Loss: 0.2814
Epoch 2/10, Train Loss: 0.4007, Valid Loss: 0.3349
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3582
Epoch 3/10, Batch 20/97, Loss: 0.2521
Epoch 3/10, Batch 30/97, Loss: 0.2277
Epoch 3/10, Batch 40/97, Loss: 0.2759
Epoch 3/10, Batch 50/97, Loss: 0.2618
Epoch 3/10, Batch 60/97, Loss: 0.2713
Epoch 3/10, Batch 70/97, Loss: 0.2879
Epoch 3/10, Batch 80/97, Loss: 0.2758
Epoch 3/10, Batch 90/97, Loss: 0.2857
Epoch 3/10, Train Loss: 0.3320, Valid Loss: 0.2932
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2256
Epoch 4/10, Batch 20/97, Loss: 0.3511
Epoch 4/10, Batch 30/97, Loss: 0.3017
Epoch 4/10, Batch 40/97, Loss: 0.2165
Epoch 4/10, Batch 50/97, Loss: 0.2130
Epoch 4/10, Batch 60/97, Loss: 0.2455
Epoch 4/10, Batch 70/97, Loss: 0.2456
Epoch 4/10, Batch 80/97, Loss: 0.3099
Epoch 4/10, Batch 90/97, Loss: 0.2594
Epoch 4/10, Train Loss: 0.2908, Valid Loss: 0.2631
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2782
Epoch 5/10, Batch 20/97, Loss: 0.1819
Epoch 5/10, Batch 30/97, Loss: 0.1190
Epoch 5/10, Batch 40/97, Loss: 0.1436
Epoch 5/10, Batch 50/97, Loss: 0.2121
Epoch 5/10, Batch 60/97, Loss: 0.2419
Epoch 5/10, Batch 70/97, Loss: 0.1877
Epoch 5/10, Batch 80/97, Loss: 0.3035
Epoch 5/10, Batch 90/97, Loss: 0.2712
Epoch 5/10, Train Loss: 0.2553, Valid Loss: 0.2563
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1747
Epoch 6/10, Batch 20/97, Loss: 0.1808
Epoch 6/10, Batch 30/97, Loss: 0.1819
Epoch 6/10, Batch 40/97, Loss: 0.2110
Epoch 6/10, Batch 50/97, Loss: 0.1821
Epoch 6/10, Batch 60/97, Loss: 0.3133
Epoch 6/10, Batch 70/97, Loss: 0.2189
Epoch 6/10, Batch 80/97, Loss: 0.2211
Epoch 6/10, Batch 90/97, Loss: 0.2764
Epoch 6/10, Train Loss: 0.2541, Valid Loss: 0.2486
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3238
Epoch 7/10, Batch 20/97, Loss: 0.1177
Epoch 7/10, Batch 30/97, Loss: 0.1710
Epoch 7/10, Batch 40/97, Loss: 0.2596
Epoch 7/10, Batch 50/97, Loss: 0.3470
Epoch 7/10, Batch 60/97, Loss: 0.3893
Epoch 7/10, Batch 70/97, Loss: 0.1993
Epoch 7/10, Batch 80/97, Loss: 0.1903
Epoch 7/10, Batch 90/97, Loss: 0.1605
Epoch 7/10, Train Loss: 0.2470, Valid Loss: 0.2407
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1824
Epoch 8/10, Batch 20/97, Loss: 0.2517
Epoch 8/10, Batch 30/97, Loss: 0.1948
Epoch 8/10, Batch 40/97, Loss: 0.3927
Epoch 8/10, Batch 50/97, Loss: 0.3103
Epoch 8/10, Batch 60/97, Loss: 0.1687
Epoch 8/10, Batch 70/97, Loss: 0.3301
Epoch 8/10, Batch 80/97, Loss: 0.2293
Epoch 8/10, Batch 90/97, Loss: 0.2785
Epoch 8/10, Train Loss: 0.2246, Valid Loss: 0.2353
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0912
Epoch 9/10, Batch 20/97, Loss: 0.1413
Epoch 9/10, Batch 30/97, Loss: 0.2080
Epoch 9/10, Batch 40/97, Loss: 0.1451
Epoch 9/10, Batch 50/97, Loss: 0.1695
Epoch 9/10, Batch 60/97, Loss: 0.0959
Epoch 9/10, Batch 70/97, Loss: 0.1885
Epoch 9/10, Batch 80/97, Loss: 0.2171
Epoch 9/10, Batch 90/97, Loss: 0.2633
Epoch 9/10, Train Loss: 0.2055, Valid Loss: 0.2264
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3899
Epoch 10/10, Batch 20/97, Loss: 0.1995
Epoch 10/10, Batch 30/97, Loss: 0.2918
Epoch 10/10, Batch 40/97, Loss: 0.1146
Epoch 10/10, Batch 50/97, Loss: 0.2656
Epoch 10/10, Batch 60/97, Loss: 0.0839
Epoch 10/10, Batch 70/97, Loss: 0.1629
Epoch 10/10, Batch 80/97, Loss: 0.2879
Epoch 10/10, Batch 90/97, Loss: 0.1755
Epoch 10/10, Train Loss: 0.1980, Valid Loss: 0.2267
Accuracy: 0.9171
Precision: 0.9149
Recall: 0.9171
F1-score: 0.9156
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4959
Epoch 1/10, Batch 20/97, Loss: 0.9513
Epoch 1/10, Batch 30/97, Loss: 0.9078
Epoch 1/10, Batch 40/97, Loss: 0.7137
Epoch 1/10, Batch 50/97, Loss: 0.5738
Epoch 1/10, Batch 60/97, Loss: 0.6532
Epoch 1/10, Batch 70/97, Loss: 0.5737
Epoch 1/10, Batch 80/97, Loss: 0.6262
Epoch 1/10, Batch 90/97, Loss: 0.6168
Epoch 1/10, Train Loss: 0.7745, Valid Loss: 0.4555
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5120
Epoch 2/10, Batch 20/97, Loss: 0.4125
Epoch 2/10, Batch 30/97, Loss: 0.3476
Epoch 2/10, Batch 40/97, Loss: 0.5529
Epoch 2/10, Batch 50/97, Loss: 0.6003
Epoch 2/10, Batch 60/97, Loss: 0.3867
Epoch 2/10, Batch 70/97, Loss: 0.2000
Epoch 2/10, Batch 80/97, Loss: 0.4126
Epoch 2/10, Batch 90/97, Loss: 0.3011
Epoch 2/10, Train Loss: 0.4102, Valid Loss: 0.3594
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4143
Epoch 3/10, Batch 20/97, Loss: 0.1877
Epoch 3/10, Batch 30/97, Loss: 0.2385
Epoch 3/10, Batch 40/97, Loss: 0.3305
Epoch 3/10, Batch 50/97, Loss: 0.2588
Epoch 3/10, Batch 60/97, Loss: 0.2215
Epoch 3/10, Batch 70/97, Loss: 0.2255
Epoch 3/10, Batch 80/97, Loss: 0.3126
Epoch 3/10, Batch 90/97, Loss: 0.4047
Epoch 3/10, Train Loss: 0.3340, Valid Loss: 0.3151
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2325
Epoch 4/10, Batch 20/97, Loss: 0.2327
Epoch 4/10, Batch 30/97, Loss: 0.2792
Epoch 4/10, Batch 40/97, Loss: 0.3209
Epoch 4/10, Batch 50/97, Loss: 0.1692
Epoch 4/10, Batch 60/97, Loss: 0.2473
Epoch 4/10, Batch 70/97, Loss: 0.2197
Epoch 4/10, Batch 80/97, Loss: 0.2800
Epoch 4/10, Batch 90/97, Loss: 0.2490
Epoch 4/10, Train Loss: 0.3005, Valid Loss: 0.2950
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2141
Epoch 5/10, Batch 20/97, Loss: 0.1818
Epoch 5/10, Batch 30/97, Loss: 0.1782
Epoch 5/10, Batch 40/97, Loss: 0.2172
Epoch 5/10, Batch 50/97, Loss: 0.2798
Epoch 5/10, Batch 60/97, Loss: 0.2905
Epoch 5/10, Batch 70/97, Loss: 0.1565
Epoch 5/10, Batch 80/97, Loss: 0.2067
Epoch 5/10, Batch 90/97, Loss: 0.2947
Epoch 5/10, Train Loss: 0.2737, Valid Loss: 0.2778
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2251
Epoch 6/10, Batch 20/97, Loss: 0.1702
Epoch 6/10, Batch 30/97, Loss: 0.1649
Epoch 6/10, Batch 40/97, Loss: 0.3060
Epoch 6/10, Batch 50/97, Loss: 0.2347
Epoch 6/10, Batch 60/97, Loss: 0.2871
Epoch 6/10, Batch 70/97, Loss: 0.1706
Epoch 6/10, Batch 80/97, Loss: 0.1335
Epoch 6/10, Batch 90/97, Loss: 0.1429
Epoch 6/10, Train Loss: 0.2637, Valid Loss: 0.2738
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3612
Epoch 7/10, Batch 20/97, Loss: 0.1832
Epoch 7/10, Batch 30/97, Loss: 0.2362
Epoch 7/10, Batch 40/97, Loss: 0.1392
Epoch 7/10, Batch 50/97, Loss: 0.2185
Epoch 7/10, Batch 60/97, Loss: 0.2479
Epoch 7/10, Batch 70/97, Loss: 0.2976
Epoch 7/10, Batch 80/97, Loss: 0.2717
Epoch 7/10, Batch 90/97, Loss: 0.2414
Epoch 7/10, Train Loss: 0.2519, Valid Loss: 0.2601
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1111
Epoch 8/10, Batch 20/97, Loss: 0.2140
Epoch 8/10, Batch 30/97, Loss: 0.2883
Epoch 8/10, Batch 40/97, Loss: 0.1817
Epoch 8/10, Batch 50/97, Loss: 0.1602
Epoch 8/10, Batch 60/97, Loss: 0.1781
Epoch 8/10, Batch 70/97, Loss: 0.3144
Epoch 8/10, Batch 80/97, Loss: 0.2035
Epoch 8/10, Batch 90/97, Loss: 0.2540
Epoch 8/10, Train Loss: 0.2301, Valid Loss: 0.2566
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1599
Epoch 9/10, Batch 20/97, Loss: 0.1025
Epoch 9/10, Batch 30/97, Loss: 0.1951
Epoch 9/10, Batch 40/97, Loss: 0.1151
Epoch 9/10, Batch 50/97, Loss: 0.3067
Epoch 9/10, Batch 60/97, Loss: 0.2190
Epoch 9/10, Batch 70/97, Loss: 0.1766
Epoch 9/10, Batch 80/97, Loss: 0.2044
Epoch 9/10, Batch 90/97, Loss: 0.2595
Epoch 9/10, Train Loss: 0.2190, Valid Loss: 0.2525
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2720
Epoch 10/10, Batch 20/97, Loss: 0.1835
Epoch 10/10, Batch 30/97, Loss: 0.2026
Epoch 10/10, Batch 40/97, Loss: 0.2001
Epoch 10/10, Batch 50/97, Loss: 0.2992
Epoch 10/10, Batch 60/97, Loss: 0.2226
Epoch 10/10, Batch 70/97, Loss: 0.0973
Epoch 10/10, Batch 80/97, Loss: 0.1778
Epoch 10/10, Batch 90/97, Loss: 0.1101
Epoch 10/10, Train Loss: 0.2043, Valid Loss: 0.2447
Model saved!
Accuracy: 0.9182
Precision: 0.9167
Recall: 0.9182
F1-score: 0.9167
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 7. Fitness: 0.9182
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4869
Epoch 1/10, Batch 20/97, Loss: 0.9937
Epoch 1/10, Batch 30/97, Loss: 0.8346
Epoch 1/10, Batch 40/97, Loss: 0.7856
Epoch 1/10, Batch 50/97, Loss: 0.6121
Epoch 1/10, Batch 60/97, Loss: 0.5412
Epoch 1/10, Batch 70/97, Loss: 0.5310
Epoch 1/10, Batch 80/97, Loss: 0.4252
Epoch 1/10, Batch 90/97, Loss: 0.4650
Epoch 1/10, Train Loss: 0.7799, Valid Loss: 0.4528
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4253
Epoch 2/10, Batch 20/97, Loss: 0.4447
Epoch 2/10, Batch 30/97, Loss: 0.4057
Epoch 2/10, Batch 40/97, Loss: 0.3883
Epoch 2/10, Batch 50/97, Loss: 0.5007
Epoch 2/10, Batch 60/97, Loss: 0.3968
Epoch 2/10, Batch 70/97, Loss: 0.3124
Epoch 2/10, Batch 80/97, Loss: 0.3148
Epoch 2/10, Batch 90/97, Loss: 0.5020
Epoch 2/10, Train Loss: 0.4016, Valid Loss: 0.3497
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3701
Epoch 3/10, Batch 20/97, Loss: 0.2938
Epoch 3/10, Batch 30/97, Loss: 0.2498
Epoch 3/10, Batch 40/97, Loss: 0.3314
Epoch 3/10, Batch 50/97, Loss: 0.2352
Epoch 3/10, Batch 60/97, Loss: 0.2510
Epoch 3/10, Batch 70/97, Loss: 0.3371
Epoch 3/10, Batch 80/97, Loss: 0.3048
Epoch 3/10, Batch 90/97, Loss: 0.2145
Epoch 3/10, Train Loss: 0.3266, Valid Loss: 0.3077
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3094
Epoch 4/10, Batch 20/97, Loss: 0.2453
Epoch 4/10, Batch 30/97, Loss: 0.3726
Epoch 4/10, Batch 40/97, Loss: 0.3295
Epoch 4/10, Batch 50/97, Loss: 0.1776
Epoch 4/10, Batch 60/97, Loss: 0.2068
Epoch 4/10, Batch 70/97, Loss: 0.4277
Epoch 4/10, Batch 80/97, Loss: 0.3108
Epoch 4/10, Batch 90/97, Loss: 0.2362
Epoch 4/10, Train Loss: 0.2920, Valid Loss: 0.2893
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1591
Epoch 5/10, Batch 20/97, Loss: 0.3678
Epoch 5/10, Batch 30/97, Loss: 0.1697
Epoch 5/10, Batch 40/97, Loss: 0.1977
Epoch 5/10, Batch 50/97, Loss: 0.2567
Epoch 5/10, Batch 60/97, Loss: 0.2709
Epoch 5/10, Batch 70/97, Loss: 0.1681
Epoch 5/10, Batch 80/97, Loss: 0.3301
Epoch 5/10, Batch 90/97, Loss: 0.4504
Epoch 5/10, Train Loss: 0.2603, Valid Loss: 0.2827
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1111
Epoch 6/10, Batch 20/97, Loss: 0.1865
Epoch 6/10, Batch 30/97, Loss: 0.2581
Epoch 6/10, Batch 40/97, Loss: 0.2213
Epoch 6/10, Batch 50/97, Loss: 0.1938
Epoch 6/10, Batch 60/97, Loss: 0.1883
Epoch 6/10, Batch 70/97, Loss: 0.1736
Epoch 6/10, Batch 80/97, Loss: 0.0973
Epoch 6/10, Batch 90/97, Loss: 0.2706
Epoch 6/10, Train Loss: 0.2473, Valid Loss: 0.2753
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3591
Epoch 7/10, Batch 20/97, Loss: 0.1132
Epoch 7/10, Batch 30/97, Loss: 0.2972
Epoch 7/10, Batch 40/97, Loss: 0.3306
Epoch 7/10, Batch 50/97, Loss: 0.2022
Epoch 7/10, Batch 60/97, Loss: 0.3016
Epoch 7/10, Batch 70/97, Loss: 0.1203
Epoch 7/10, Batch 80/97, Loss: 0.2399
Epoch 7/10, Batch 90/97, Loss: 0.2202
Epoch 7/10, Train Loss: 0.2515, Valid Loss: 0.2652
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2531
Epoch 8/10, Batch 20/97, Loss: 0.1162
Epoch 8/10, Batch 30/97, Loss: 0.2156
Epoch 8/10, Batch 40/97, Loss: 0.1413
Epoch 8/10, Batch 50/97, Loss: 0.1753
Epoch 8/10, Batch 60/97, Loss: 0.2570
Epoch 8/10, Batch 70/97, Loss: 0.3498
Epoch 8/10, Batch 80/97, Loss: 0.2661
Epoch 8/10, Batch 90/97, Loss: 0.1405
Epoch 8/10, Train Loss: 0.2262, Valid Loss: 0.2627
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1278
Epoch 9/10, Batch 20/97, Loss: 0.1665
Epoch 9/10, Batch 30/97, Loss: 0.2795
Epoch 9/10, Batch 40/97, Loss: 0.1645
Epoch 9/10, Batch 50/97, Loss: 0.1947
Epoch 9/10, Batch 60/97, Loss: 0.3982
Epoch 9/10, Batch 70/97, Loss: 0.1238
Epoch 9/10, Batch 80/97, Loss: 0.0965
Epoch 9/10, Batch 90/97, Loss: 0.3059
Epoch 9/10, Train Loss: 0.2087, Valid Loss: 0.2712
Epoch 10/10, Batch 10/97, Loss: 0.2324
Epoch 10/10, Batch 20/97, Loss: 0.1948
Epoch 10/10, Batch 30/97, Loss: 0.1663
Epoch 10/10, Batch 40/97, Loss: 0.2325
Epoch 10/10, Batch 50/97, Loss: 0.3198
Epoch 10/10, Batch 60/97, Loss: 0.1808
Epoch 10/10, Batch 70/97, Loss: 0.1208
Epoch 10/10, Batch 80/97, Loss: 0.1609
Epoch 10/10, Batch 90/97, Loss: 0.1465
Epoch 10/10, Train Loss: 0.2052, Valid Loss: 0.2547
Model saved!
Accuracy: 0.9217
Precision: 0.9199
Recall: 0.9217
F1-score: 0.9205
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 8. Fitness: 0.9217
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4366
Epoch 1/10, Batch 20/97, Loss: 1.0084
Epoch 1/10, Batch 30/97, Loss: 0.9391
Epoch 1/10, Batch 40/97, Loss: 0.6787
Epoch 1/10, Batch 50/97, Loss: 0.6362
Epoch 1/10, Batch 60/97, Loss: 0.6753
Epoch 1/10, Batch 70/97, Loss: 0.5419
Epoch 1/10, Batch 80/97, Loss: 0.5017
Epoch 1/10, Batch 90/97, Loss: 0.4938
Epoch 1/10, Train Loss: 0.7761, Valid Loss: 0.4669
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4795
Epoch 2/10, Batch 20/97, Loss: 0.5498
Epoch 2/10, Batch 30/97, Loss: 0.4045
Epoch 2/10, Batch 40/97, Loss: 0.5935
Epoch 2/10, Batch 50/97, Loss: 0.5323
Epoch 2/10, Batch 60/97, Loss: 0.2823
Epoch 2/10, Batch 70/97, Loss: 0.3250
Epoch 2/10, Batch 80/97, Loss: 0.3193
Epoch 2/10, Batch 90/97, Loss: 0.4104
Epoch 2/10, Train Loss: 0.4038, Valid Loss: 0.3618
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2431
Epoch 3/10, Batch 20/97, Loss: 0.3255
Epoch 3/10, Batch 30/97, Loss: 0.3143
Epoch 3/10, Batch 40/97, Loss: 0.2711
Epoch 3/10, Batch 50/97, Loss: 0.3023
Epoch 3/10, Batch 60/97, Loss: 0.2047
Epoch 3/10, Batch 70/97, Loss: 0.2939
Epoch 3/10, Batch 80/97, Loss: 0.2111
Epoch 3/10, Batch 90/97, Loss: 0.2255
Epoch 3/10, Train Loss: 0.3274, Valid Loss: 0.3158
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2732
Epoch 4/10, Batch 20/97, Loss: 0.2276
Epoch 4/10, Batch 30/97, Loss: 0.3695
Epoch 4/10, Batch 40/97, Loss: 0.2798
Epoch 4/10, Batch 50/97, Loss: 0.1513
Epoch 4/10, Batch 60/97, Loss: 0.2273
Epoch 4/10, Batch 70/97, Loss: 0.2487
Epoch 4/10, Batch 80/97, Loss: 0.3638
Epoch 4/10, Batch 90/97, Loss: 0.2949
Epoch 4/10, Train Loss: 0.2948, Valid Loss: 0.2974
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2259
Epoch 5/10, Batch 20/97, Loss: 0.2015
Epoch 5/10, Batch 30/97, Loss: 0.3082
Epoch 5/10, Batch 40/97, Loss: 0.2099
Epoch 5/10, Batch 50/97, Loss: 0.2737
Epoch 5/10, Batch 60/97, Loss: 0.2379
Epoch 5/10, Batch 70/97, Loss: 0.2043
Epoch 5/10, Batch 80/97, Loss: 0.3926
Epoch 5/10, Batch 90/97, Loss: 0.3505
Epoch 5/10, Train Loss: 0.2579, Valid Loss: 0.2795
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2009
Epoch 6/10, Batch 20/97, Loss: 0.3149
Epoch 6/10, Batch 30/97, Loss: 0.1236
Epoch 6/10, Batch 40/97, Loss: 0.2810
Epoch 6/10, Batch 50/97, Loss: 0.2299
Epoch 6/10, Batch 60/97, Loss: 0.2213
Epoch 6/10, Batch 70/97, Loss: 0.2027
Epoch 6/10, Batch 80/97, Loss: 0.2686
Epoch 6/10, Batch 90/97, Loss: 0.3448
Epoch 6/10, Train Loss: 0.2524, Valid Loss: 0.2736
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2350
Epoch 7/10, Batch 20/97, Loss: 0.3060
Epoch 7/10, Batch 30/97, Loss: 0.1423
Epoch 7/10, Batch 40/97, Loss: 0.2197
Epoch 7/10, Batch 50/97, Loss: 0.2221
Epoch 7/10, Batch 60/97, Loss: 0.4635
Epoch 7/10, Batch 70/97, Loss: 0.2485
Epoch 7/10, Batch 80/97, Loss: 0.2136
Epoch 7/10, Batch 90/97, Loss: 0.2030
Epoch 7/10, Train Loss: 0.2520, Valid Loss: 0.2632
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1674
Epoch 8/10, Batch 20/97, Loss: 0.1529
Epoch 8/10, Batch 30/97, Loss: 0.1718
Epoch 8/10, Batch 40/97, Loss: 0.1717
Epoch 8/10, Batch 50/97, Loss: 0.3795
Epoch 8/10, Batch 60/97, Loss: 0.2859
Epoch 8/10, Batch 70/97, Loss: 0.3047
Epoch 8/10, Batch 80/97, Loss: 0.1619
Epoch 8/10, Batch 90/97, Loss: 0.1556
Epoch 8/10, Train Loss: 0.2317, Valid Loss: 0.2538
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1241
Epoch 9/10, Batch 20/97, Loss: 0.1257
Epoch 9/10, Batch 30/97, Loss: 0.3306
Epoch 9/10, Batch 40/97, Loss: 0.2001
Epoch 9/10, Batch 50/97, Loss: 0.2745
Epoch 9/10, Batch 60/97, Loss: 0.2532
Epoch 9/10, Batch 70/97, Loss: 0.1675
Epoch 9/10, Batch 80/97, Loss: 0.2256
Epoch 9/10, Batch 90/97, Loss: 0.2127
Epoch 9/10, Train Loss: 0.2221, Valid Loss: 0.2554
Epoch 10/10, Batch 10/97, Loss: 0.1654
Epoch 10/10, Batch 20/97, Loss: 0.0951
Epoch 10/10, Batch 30/97, Loss: 0.1712
Epoch 10/10, Batch 40/97, Loss: 0.1314
Epoch 10/10, Batch 50/97, Loss: 0.2279
Epoch 10/10, Batch 60/97, Loss: 0.1320
Epoch 10/10, Batch 70/97, Loss: 0.1352
Epoch 10/10, Batch 80/97, Loss: 0.1889
Epoch 10/10, Batch 90/97, Loss: 0.1547
Epoch 10/10, Train Loss: 0.2076, Valid Loss: 0.2584
Accuracy: 0.9182
Precision: 0.9167
Recall: 0.9182
F1-score: 0.9161
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4658
Epoch 1/10, Batch 20/97, Loss: 0.9789
Epoch 1/10, Batch 30/97, Loss: 0.9322
Epoch 1/10, Batch 40/97, Loss: 0.6830
Epoch 1/10, Batch 50/97, Loss: 0.5028
Epoch 1/10, Batch 60/97, Loss: 0.5354
Epoch 1/10, Batch 70/97, Loss: 0.5145
Epoch 1/10, Batch 80/97, Loss: 0.4264
Epoch 1/10, Batch 90/97, Loss: 0.4923
Epoch 1/10, Train Loss: 0.7762, Valid Loss: 0.4695
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3905
Epoch 2/10, Batch 20/97, Loss: 0.7543
Epoch 2/10, Batch 30/97, Loss: 0.4195
Epoch 2/10, Batch 40/97, Loss: 0.4145
Epoch 2/10, Batch 50/97, Loss: 0.4617
Epoch 2/10, Batch 60/97, Loss: 0.3322
Epoch 2/10, Batch 70/97, Loss: 0.2699
Epoch 2/10, Batch 80/97, Loss: 0.3195
Epoch 2/10, Batch 90/97, Loss: 0.2096
Epoch 2/10, Train Loss: 0.4032, Valid Loss: 0.3672
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3337
Epoch 3/10, Batch 20/97, Loss: 0.2091
Epoch 3/10, Batch 30/97, Loss: 0.1835
Epoch 3/10, Batch 40/97, Loss: 0.2676
Epoch 3/10, Batch 50/97, Loss: 0.3747
Epoch 3/10, Batch 60/97, Loss: 0.2303
Epoch 3/10, Batch 70/97, Loss: 0.2999
Epoch 3/10, Batch 80/97, Loss: 0.2800
Epoch 3/10, Batch 90/97, Loss: 0.3390
Epoch 3/10, Train Loss: 0.3257, Valid Loss: 0.3248
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3471
Epoch 4/10, Batch 20/97, Loss: 0.2295
Epoch 4/10, Batch 30/97, Loss: 0.3390
Epoch 4/10, Batch 40/97, Loss: 0.5026
Epoch 4/10, Batch 50/97, Loss: 0.1702
Epoch 4/10, Batch 60/97, Loss: 0.1419
Epoch 4/10, Batch 70/97, Loss: 0.4049
Epoch 4/10, Batch 80/97, Loss: 0.2000
Epoch 4/10, Batch 90/97, Loss: 0.2865
Epoch 4/10, Train Loss: 0.2834, Valid Loss: 0.3060
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1952
Epoch 5/10, Batch 20/97, Loss: 0.2015
Epoch 5/10, Batch 30/97, Loss: 0.1367
Epoch 5/10, Batch 40/97, Loss: 0.3402
Epoch 5/10, Batch 50/97, Loss: 0.2158
Epoch 5/10, Batch 60/97, Loss: 0.1270
Epoch 5/10, Batch 70/97, Loss: 0.1934
Epoch 5/10, Batch 80/97, Loss: 0.2270
Epoch 5/10, Batch 90/97, Loss: 0.3044
Epoch 5/10, Train Loss: 0.2604, Valid Loss: 0.2869
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1562
Epoch 6/10, Batch 20/97, Loss: 0.2346
Epoch 6/10, Batch 30/97, Loss: 0.2720
Epoch 6/10, Batch 40/97, Loss: 0.4405
Epoch 6/10, Batch 50/97, Loss: 0.2186
Epoch 6/10, Batch 60/97, Loss: 0.2854
Epoch 6/10, Batch 70/97, Loss: 0.2295
Epoch 6/10, Batch 80/97, Loss: 0.1448
Epoch 6/10, Batch 90/97, Loss: 0.4210
Epoch 6/10, Train Loss: 0.2352, Valid Loss: 0.2751
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3321
Epoch 7/10, Batch 20/97, Loss: 0.1064
Epoch 7/10, Batch 30/97, Loss: 0.2008
Epoch 7/10, Batch 40/97, Loss: 0.2161
Epoch 7/10, Batch 50/97, Loss: 0.2688
Epoch 7/10, Batch 60/97, Loss: 0.2735
Epoch 7/10, Batch 70/97, Loss: 0.2032
Epoch 7/10, Batch 80/97, Loss: 0.2093
Epoch 7/10, Batch 90/97, Loss: 0.3251
Epoch 7/10, Train Loss: 0.2384, Valid Loss: 0.2714
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1857
Epoch 8/10, Batch 20/97, Loss: 0.2257
Epoch 8/10, Batch 30/97, Loss: 0.1549
Epoch 8/10, Batch 40/97, Loss: 0.3125
Epoch 8/10, Batch 50/97, Loss: 0.1898
Epoch 8/10, Batch 60/97, Loss: 0.1531
Epoch 8/10, Batch 70/97, Loss: 0.3850
Epoch 8/10, Batch 80/97, Loss: 0.1583
Epoch 8/10, Batch 90/97, Loss: 0.1759
Epoch 8/10, Train Loss: 0.2234, Valid Loss: 0.2657
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1060
Epoch 9/10, Batch 20/97, Loss: 0.1641
Epoch 9/10, Batch 30/97, Loss: 0.3494
Epoch 9/10, Batch 40/97, Loss: 0.1152
Epoch 9/10, Batch 50/97, Loss: 0.2252
Epoch 9/10, Batch 60/97, Loss: 0.3554
Epoch 9/10, Batch 70/97, Loss: 0.0887
Epoch 9/10, Batch 80/97, Loss: 0.2250
Epoch 9/10, Batch 90/97, Loss: 0.2300
Epoch 9/10, Train Loss: 0.2054, Valid Loss: 0.2649
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2873
Epoch 10/10, Batch 20/97, Loss: 0.2123
Epoch 10/10, Batch 30/97, Loss: 0.2141
Epoch 10/10, Batch 40/97, Loss: 0.3128
Epoch 10/10, Batch 50/97, Loss: 0.2309
Epoch 10/10, Batch 60/97, Loss: 0.2256
Epoch 10/10, Batch 70/97, Loss: 0.1315
Epoch 10/10, Batch 80/97, Loss: 0.1337
Epoch 10/10, Batch 90/97, Loss: 0.1152
Epoch 10/10, Train Loss: 0.2027, Valid Loss: 0.2591
Model saved!
Accuracy: 0.9136
Precision: 0.9108
Recall: 0.9136
F1-score: 0.9117
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5208
Epoch 1/10, Batch 20/97, Loss: 1.0612
Epoch 1/10, Batch 30/97, Loss: 0.9417
Epoch 1/10, Batch 40/97, Loss: 0.6659
Epoch 1/10, Batch 50/97, Loss: 0.6094
Epoch 1/10, Batch 60/97, Loss: 0.6292
Epoch 1/10, Batch 70/97, Loss: 0.4908
Epoch 1/10, Batch 80/97, Loss: 0.5151
Epoch 1/10, Batch 90/97, Loss: 0.5087
Epoch 1/10, Train Loss: 0.7806, Valid Loss: 0.4108
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3795
Epoch 2/10, Batch 20/97, Loss: 0.4316
Epoch 2/10, Batch 30/97, Loss: 0.4527
Epoch 2/10, Batch 40/97, Loss: 0.3203
Epoch 2/10, Batch 50/97, Loss: 0.5177
Epoch 2/10, Batch 60/97, Loss: 0.4599
Epoch 2/10, Batch 70/97, Loss: 0.3647
Epoch 2/10, Batch 80/97, Loss: 0.4594
Epoch 2/10, Batch 90/97, Loss: 0.3467
Epoch 2/10, Train Loss: 0.4016, Valid Loss: 0.3142
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3109
Epoch 3/10, Batch 20/97, Loss: 0.3540
Epoch 3/10, Batch 30/97, Loss: 0.2947
Epoch 3/10, Batch 40/97, Loss: 0.2325
Epoch 3/10, Batch 50/97, Loss: 0.2419
Epoch 3/10, Batch 60/97, Loss: 0.2004
Epoch 3/10, Batch 70/97, Loss: 0.1919
Epoch 3/10, Batch 80/97, Loss: 0.3419
Epoch 3/10, Batch 90/97, Loss: 0.4181
Epoch 3/10, Train Loss: 0.3256, Valid Loss: 0.2749
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3481
Epoch 4/10, Batch 20/97, Loss: 0.3259
Epoch 4/10, Batch 30/97, Loss: 0.3578
Epoch 4/10, Batch 40/97, Loss: 0.4242
Epoch 4/10, Batch 50/97, Loss: 0.2182
Epoch 4/10, Batch 60/97, Loss: 0.2294
Epoch 4/10, Batch 70/97, Loss: 0.1724
Epoch 4/10, Batch 80/97, Loss: 0.3023
Epoch 4/10, Batch 90/97, Loss: 0.3372
Epoch 4/10, Train Loss: 0.2968, Valid Loss: 0.2578
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2607
Epoch 5/10, Batch 20/97, Loss: 0.2396
Epoch 5/10, Batch 30/97, Loss: 0.1327
Epoch 5/10, Batch 40/97, Loss: 0.1710
Epoch 5/10, Batch 50/97, Loss: 0.2644
Epoch 5/10, Batch 60/97, Loss: 0.2339
Epoch 5/10, Batch 70/97, Loss: 0.1545
Epoch 5/10, Batch 80/97, Loss: 0.2728
Epoch 5/10, Batch 90/97, Loss: 0.3258
Epoch 5/10, Train Loss: 0.2660, Valid Loss: 0.2438
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1577
Epoch 6/10, Batch 20/97, Loss: 0.2658
Epoch 6/10, Batch 30/97, Loss: 0.1676
Epoch 6/10, Batch 40/97, Loss: 0.2167
Epoch 6/10, Batch 50/97, Loss: 0.2056
Epoch 6/10, Batch 60/97, Loss: 0.2074
Epoch 6/10, Batch 70/97, Loss: 0.2167
Epoch 6/10, Batch 80/97, Loss: 0.2653
Epoch 6/10, Batch 90/97, Loss: 0.2419
Epoch 6/10, Train Loss: 0.2467, Valid Loss: 0.2358
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1708
Epoch 7/10, Batch 20/97, Loss: 0.1339
Epoch 7/10, Batch 30/97, Loss: 0.1464
Epoch 7/10, Batch 40/97, Loss: 0.1185
Epoch 7/10, Batch 50/97, Loss: 0.1558
Epoch 7/10, Batch 60/97, Loss: 0.2155
Epoch 7/10, Batch 70/97, Loss: 0.3705
Epoch 7/10, Batch 80/97, Loss: 0.3278
Epoch 7/10, Batch 90/97, Loss: 0.3002
Epoch 7/10, Train Loss: 0.2454, Valid Loss: 0.2286
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1289
Epoch 8/10, Batch 20/97, Loss: 0.1455
Epoch 8/10, Batch 30/97, Loss: 0.1577
Epoch 8/10, Batch 40/97, Loss: 0.1376
Epoch 8/10, Batch 50/97, Loss: 0.1996
Epoch 8/10, Batch 60/97, Loss: 0.1748
Epoch 8/10, Batch 70/97, Loss: 0.3200
Epoch 8/10, Batch 80/97, Loss: 0.1677
Epoch 8/10, Batch 90/97, Loss: 0.1903
Epoch 8/10, Train Loss: 0.2192, Valid Loss: 0.2283
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2073
Epoch 9/10, Batch 20/97, Loss: 0.1852
Epoch 9/10, Batch 30/97, Loss: 0.2884
Epoch 9/10, Batch 40/97, Loss: 0.0925
Epoch 9/10, Batch 50/97, Loss: 0.1479
Epoch 9/10, Batch 60/97, Loss: 0.3301
Epoch 9/10, Batch 70/97, Loss: 0.1968
Epoch 9/10, Batch 80/97, Loss: 0.1915
Epoch 9/10, Batch 90/97, Loss: 0.1307
Epoch 9/10, Train Loss: 0.2151, Valid Loss: 0.2253
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2424
Epoch 10/10, Batch 20/97, Loss: 0.1313
Epoch 10/10, Batch 30/97, Loss: 0.2347
Epoch 10/10, Batch 40/97, Loss: 0.1797
Epoch 10/10, Batch 50/97, Loss: 0.3875
Epoch 10/10, Batch 60/97, Loss: 0.1484
Epoch 10/10, Batch 70/97, Loss: 0.1995
Epoch 10/10, Batch 80/97, Loss: 0.1830
Epoch 10/10, Batch 90/97, Loss: 0.1714
Epoch 10/10, Train Loss: 0.2030, Valid Loss: 0.2191
Model saved!
Accuracy: 0.9206
Precision: 0.9185
Recall: 0.9206
F1-score: 0.9191
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4477
Epoch 1/10, Batch 20/97, Loss: 1.0057
Epoch 1/10, Batch 30/97, Loss: 0.7956
Epoch 1/10, Batch 40/97, Loss: 0.7231
Epoch 1/10, Batch 50/97, Loss: 0.6584
Epoch 1/10, Batch 60/97, Loss: 0.6101
Epoch 1/10, Batch 70/97, Loss: 0.5539
Epoch 1/10, Batch 80/97, Loss: 0.4780
Epoch 1/10, Batch 90/97, Loss: 0.5300
Epoch 1/10, Train Loss: 0.7760, Valid Loss: 0.4343
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3203
Epoch 2/10, Batch 20/97, Loss: 0.3112
Epoch 2/10, Batch 30/97, Loss: 0.5246
Epoch 2/10, Batch 40/97, Loss: 0.4692
Epoch 2/10, Batch 50/97, Loss: 0.4623
Epoch 2/10, Batch 60/97, Loss: 0.4652
Epoch 2/10, Batch 70/97, Loss: 0.2549
Epoch 2/10, Batch 80/97, Loss: 0.4090
Epoch 2/10, Batch 90/97, Loss: 0.4610
Epoch 2/10, Train Loss: 0.3941, Valid Loss: 0.3434
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.5318
Epoch 3/10, Batch 20/97, Loss: 0.2601
Epoch 3/10, Batch 30/97, Loss: 0.2556
Epoch 3/10, Batch 40/97, Loss: 0.2963
Epoch 3/10, Batch 50/97, Loss: 0.2058
Epoch 3/10, Batch 60/97, Loss: 0.2439
Epoch 3/10, Batch 70/97, Loss: 0.3666
Epoch 3/10, Batch 80/97, Loss: 0.2468
Epoch 3/10, Batch 90/97, Loss: 0.2953
Epoch 3/10, Train Loss: 0.3317, Valid Loss: 0.3049
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2895
Epoch 4/10, Batch 20/97, Loss: 0.2933
Epoch 4/10, Batch 30/97, Loss: 0.2855
Epoch 4/10, Batch 40/97, Loss: 0.3168
Epoch 4/10, Batch 50/97, Loss: 0.2299
Epoch 4/10, Batch 60/97, Loss: 0.1647
Epoch 4/10, Batch 70/97, Loss: 0.3138
Epoch 4/10, Batch 80/97, Loss: 0.2613
Epoch 4/10, Batch 90/97, Loss: 0.2961
Epoch 4/10, Train Loss: 0.2902, Valid Loss: 0.2827
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2792
Epoch 5/10, Batch 20/97, Loss: 0.0770
Epoch 5/10, Batch 30/97, Loss: 0.1334
Epoch 5/10, Batch 40/97, Loss: 0.1506
Epoch 5/10, Batch 50/97, Loss: 0.2265
Epoch 5/10, Batch 60/97, Loss: 0.2587
Epoch 5/10, Batch 70/97, Loss: 0.1427
Epoch 5/10, Batch 80/97, Loss: 0.1756
Epoch 5/10, Batch 90/97, Loss: 0.2581
Epoch 5/10, Train Loss: 0.2559, Valid Loss: 0.2754
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2501
Epoch 6/10, Batch 20/97, Loss: 0.2620
Epoch 6/10, Batch 30/97, Loss: 0.1812
Epoch 6/10, Batch 40/97, Loss: 0.2443
Epoch 6/10, Batch 50/97, Loss: 0.1796
Epoch 6/10, Batch 60/97, Loss: 0.2222
Epoch 6/10, Batch 70/97, Loss: 0.2965
Epoch 6/10, Batch 80/97, Loss: 0.1155
Epoch 6/10, Batch 90/97, Loss: 0.1747
Epoch 6/10, Train Loss: 0.2331, Valid Loss: 0.2629
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4428
Epoch 7/10, Batch 20/97, Loss: 0.1100
Epoch 7/10, Batch 30/97, Loss: 0.2739
Epoch 7/10, Batch 40/97, Loss: 0.1883
Epoch 7/10, Batch 50/97, Loss: 0.3556
Epoch 7/10, Batch 60/97, Loss: 0.3828
Epoch 7/10, Batch 70/97, Loss: 0.1460
Epoch 7/10, Batch 80/97, Loss: 0.2040
Epoch 7/10, Batch 90/97, Loss: 0.2148
Epoch 7/10, Train Loss: 0.2462, Valid Loss: 0.2637
Epoch 8/10, Batch 10/97, Loss: 0.2077
Epoch 8/10, Batch 20/97, Loss: 0.1301
Epoch 8/10, Batch 30/97, Loss: 0.1721
Epoch 8/10, Batch 40/97, Loss: 0.1778
Epoch 8/10, Batch 50/97, Loss: 0.3257
Epoch 8/10, Batch 60/97, Loss: 0.2118
Epoch 8/10, Batch 70/97, Loss: 0.3038
Epoch 8/10, Batch 80/97, Loss: 0.1528
Epoch 8/10, Batch 90/97, Loss: 0.2246
Epoch 8/10, Train Loss: 0.2237, Valid Loss: 0.2705
Epoch 9/10, Batch 10/97, Loss: 0.1089
Epoch 9/10, Batch 20/97, Loss: 0.0546
Epoch 9/10, Batch 30/97, Loss: 0.2415
Epoch 9/10, Batch 40/97, Loss: 0.1497
Epoch 9/10, Batch 50/97, Loss: 0.1963
Epoch 9/10, Batch 60/97, Loss: 0.0637
Epoch 9/10, Batch 70/97, Loss: 0.1716
Epoch 9/10, Batch 80/97, Loss: 0.2290
Epoch 9/10, Batch 90/97, Loss: 0.2134
Epoch 9/10, Train Loss: 0.2069, Valid Loss: 0.2494
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2802
Epoch 10/10, Batch 20/97, Loss: 0.2421
Epoch 10/10, Batch 30/97, Loss: 0.1525
Epoch 10/10, Batch 40/97, Loss: 0.2273
Epoch 10/10, Batch 50/97, Loss: 0.2671
Epoch 10/10, Batch 60/97, Loss: 0.1177
Epoch 10/10, Batch 70/97, Loss: 0.1833
Epoch 10/10, Batch 80/97, Loss: 0.0792
Epoch 10/10, Batch 90/97, Loss: 0.2433
Epoch 10/10, Train Loss: 0.1999, Valid Loss: 0.2478
Model saved!
Accuracy: 0.9229
Precision: 0.9208
Recall: 0.9229
F1-score: 0.9215
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 12. Fitness: 0.9229
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4609
Epoch 1/10, Batch 20/97, Loss: 0.9933
Epoch 1/10, Batch 30/97, Loss: 0.8723
Epoch 1/10, Batch 40/97, Loss: 0.7441
Epoch 1/10, Batch 50/97, Loss: 0.7034
Epoch 1/10, Batch 60/97, Loss: 0.5723
Epoch 1/10, Batch 70/97, Loss: 0.5245
Epoch 1/10, Batch 80/97, Loss: 0.5309
Epoch 1/10, Batch 90/97, Loss: 0.6539
Epoch 1/10, Train Loss: 0.7740, Valid Loss: 0.4561
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3456
Epoch 2/10, Batch 20/97, Loss: 0.6705
Epoch 2/10, Batch 30/97, Loss: 0.4767
Epoch 2/10, Batch 40/97, Loss: 0.3952
Epoch 2/10, Batch 50/97, Loss: 0.6369
Epoch 2/10, Batch 60/97, Loss: 0.3549
Epoch 2/10, Batch 70/97, Loss: 0.3166
Epoch 2/10, Batch 80/97, Loss: 0.1893
Epoch 2/10, Batch 90/97, Loss: 0.3017
Epoch 2/10, Train Loss: 0.3921, Valid Loss: 0.3502
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4214
Epoch 3/10, Batch 20/97, Loss: 0.2776
Epoch 3/10, Batch 30/97, Loss: 0.2764
Epoch 3/10, Batch 40/97, Loss: 0.4085
Epoch 3/10, Batch 50/97, Loss: 0.2463
Epoch 3/10, Batch 60/97, Loss: 0.3239
Epoch 3/10, Batch 70/97, Loss: 0.2127
Epoch 3/10, Batch 80/97, Loss: 0.3479
Epoch 3/10, Batch 90/97, Loss: 0.2452
Epoch 3/10, Train Loss: 0.3223, Valid Loss: 0.3013
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2407
Epoch 4/10, Batch 20/97, Loss: 0.3293
Epoch 4/10, Batch 30/97, Loss: 0.2407
Epoch 4/10, Batch 40/97, Loss: 0.2803
Epoch 4/10, Batch 50/97, Loss: 0.3260
Epoch 4/10, Batch 60/97, Loss: 0.2033
Epoch 4/10, Batch 70/97, Loss: 0.2716
Epoch 4/10, Batch 80/97, Loss: 0.2276
Epoch 4/10, Batch 90/97, Loss: 0.2784
Epoch 4/10, Train Loss: 0.2790, Valid Loss: 0.2824
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1780
Epoch 5/10, Batch 20/97, Loss: 0.1376
Epoch 5/10, Batch 30/97, Loss: 0.1484
Epoch 5/10, Batch 40/97, Loss: 0.1863
Epoch 5/10, Batch 50/97, Loss: 0.3413
Epoch 5/10, Batch 60/97, Loss: 0.2514
Epoch 5/10, Batch 70/97, Loss: 0.2575
Epoch 5/10, Batch 80/97, Loss: 0.3956
Epoch 5/10, Batch 90/97, Loss: 0.4276
Epoch 5/10, Train Loss: 0.2586, Valid Loss: 0.2572
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3571
Epoch 6/10, Batch 20/97, Loss: 0.1730
Epoch 6/10, Batch 30/97, Loss: 0.2284
Epoch 6/10, Batch 40/97, Loss: 0.4234
Epoch 6/10, Batch 50/97, Loss: 0.2058
Epoch 6/10, Batch 60/97, Loss: 0.2651
Epoch 6/10, Batch 70/97, Loss: 0.2520
Epoch 6/10, Batch 80/97, Loss: 0.1703
Epoch 6/10, Batch 90/97, Loss: 0.2780
Epoch 6/10, Train Loss: 0.2370, Valid Loss: 0.2649
Epoch 7/10, Batch 10/97, Loss: 0.3342
Epoch 7/10, Batch 20/97, Loss: 0.1175
Epoch 7/10, Batch 30/97, Loss: 0.1605
Epoch 7/10, Batch 40/97, Loss: 0.2281
Epoch 7/10, Batch 50/97, Loss: 0.1977
Epoch 7/10, Batch 60/97, Loss: 0.4470
Epoch 7/10, Batch 70/97, Loss: 0.1548
Epoch 7/10, Batch 80/97, Loss: 0.2168
Epoch 7/10, Batch 90/97, Loss: 0.2066
Epoch 7/10, Train Loss: 0.2329, Valid Loss: 0.2417
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2838
Epoch 8/10, Batch 20/97, Loss: 0.2196
Epoch 8/10, Batch 30/97, Loss: 0.1685
Epoch 8/10, Batch 40/97, Loss: 0.1571
Epoch 8/10, Batch 50/97, Loss: 0.2310
Epoch 8/10, Batch 60/97, Loss: 0.0953
Epoch 8/10, Batch 70/97, Loss: 0.2675
Epoch 8/10, Batch 80/97, Loss: 0.2128
Epoch 8/10, Batch 90/97, Loss: 0.1041
Epoch 8/10, Train Loss: 0.2155, Valid Loss: 0.2366
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.3228
Epoch 9/10, Batch 20/97, Loss: 0.2618
Epoch 9/10, Batch 30/97, Loss: 0.2347
Epoch 9/10, Batch 40/97, Loss: 0.0544
Epoch 9/10, Batch 50/97, Loss: 0.2218
Epoch 9/10, Batch 60/97, Loss: 0.2051
Epoch 9/10, Batch 70/97, Loss: 0.1650
Epoch 9/10, Batch 80/97, Loss: 0.1329
Epoch 9/10, Batch 90/97, Loss: 0.2304
Epoch 9/10, Train Loss: 0.2012, Valid Loss: 0.2433
Epoch 10/10, Batch 10/97, Loss: 0.1366
Epoch 10/10, Batch 20/97, Loss: 0.1840
Epoch 10/10, Batch 30/97, Loss: 0.1768
Epoch 10/10, Batch 40/97, Loss: 0.2382
Epoch 10/10, Batch 50/97, Loss: 0.2332
Epoch 10/10, Batch 60/97, Loss: 0.1053
Epoch 10/10, Batch 70/97, Loss: 0.1959
Epoch 10/10, Batch 80/97, Loss: 0.0859
Epoch 10/10, Batch 90/97, Loss: 0.2420
Epoch 10/10, Train Loss: 0.1942, Valid Loss: 0.2321
Model saved!
Accuracy: 0.9311
Precision: 0.9307
Recall: 0.9311
F1-score: 0.9308
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 13. Fitness: 0.9311
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4545
Epoch 1/10, Batch 20/97, Loss: 0.9652
Epoch 1/10, Batch 30/97, Loss: 0.8737
Epoch 1/10, Batch 40/97, Loss: 0.6510
Epoch 1/10, Batch 50/97, Loss: 0.6250
Epoch 1/10, Batch 60/97, Loss: 0.6613
Epoch 1/10, Batch 70/97, Loss: 0.4500
Epoch 1/10, Batch 80/97, Loss: 0.4792
Epoch 1/10, Batch 90/97, Loss: 0.4457
Epoch 1/10, Train Loss: 0.7747, Valid Loss: 0.4437
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3305
Epoch 2/10, Batch 20/97, Loss: 0.4345
Epoch 2/10, Batch 30/97, Loss: 0.4119
Epoch 2/10, Batch 40/97, Loss: 0.4551
Epoch 2/10, Batch 50/97, Loss: 0.5523
Epoch 2/10, Batch 60/97, Loss: 0.4572
Epoch 2/10, Batch 70/97, Loss: 0.2731
Epoch 2/10, Batch 80/97, Loss: 0.3289
Epoch 2/10, Batch 90/97, Loss: 0.3349
Epoch 2/10, Train Loss: 0.3956, Valid Loss: 0.3298
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2550
Epoch 3/10, Batch 20/97, Loss: 0.2831
Epoch 3/10, Batch 30/97, Loss: 0.2142
Epoch 3/10, Batch 40/97, Loss: 0.2493
Epoch 3/10, Batch 50/97, Loss: 0.3496
Epoch 3/10, Batch 60/97, Loss: 0.5026
Epoch 3/10, Batch 70/97, Loss: 0.1619
Epoch 3/10, Batch 80/97, Loss: 0.4784
Epoch 3/10, Batch 90/97, Loss: 0.2132
Epoch 3/10, Train Loss: 0.3237, Valid Loss: 0.2997
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2884
Epoch 4/10, Batch 20/97, Loss: 0.2002
Epoch 4/10, Batch 30/97, Loss: 0.3876
Epoch 4/10, Batch 40/97, Loss: 0.2540
Epoch 4/10, Batch 50/97, Loss: 0.4125
Epoch 4/10, Batch 60/97, Loss: 0.1941
Epoch 4/10, Batch 70/97, Loss: 0.1362
Epoch 4/10, Batch 80/97, Loss: 0.1697
Epoch 4/10, Batch 90/97, Loss: 0.2914
Epoch 4/10, Train Loss: 0.2877, Valid Loss: 0.2710
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3313
Epoch 5/10, Batch 20/97, Loss: 0.2285
Epoch 5/10, Batch 30/97, Loss: 0.2175
Epoch 5/10, Batch 40/97, Loss: 0.0737
Epoch 5/10, Batch 50/97, Loss: 0.1433
Epoch 5/10, Batch 60/97, Loss: 0.2754
Epoch 5/10, Batch 70/97, Loss: 0.2594
Epoch 5/10, Batch 80/97, Loss: 0.2103
Epoch 5/10, Batch 90/97, Loss: 0.3110
Epoch 5/10, Train Loss: 0.2554, Valid Loss: 0.2560
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2626
Epoch 6/10, Batch 20/97, Loss: 0.2673
Epoch 6/10, Batch 30/97, Loss: 0.1314
Epoch 6/10, Batch 40/97, Loss: 0.2429
Epoch 6/10, Batch 50/97, Loss: 0.2346
Epoch 6/10, Batch 60/97, Loss: 0.2158
Epoch 6/10, Batch 70/97, Loss: 0.1586
Epoch 6/10, Batch 80/97, Loss: 0.2419
Epoch 6/10, Batch 90/97, Loss: 0.1683
Epoch 6/10, Train Loss: 0.2360, Valid Loss: 0.2503
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3483
Epoch 7/10, Batch 20/97, Loss: 0.1766
Epoch 7/10, Batch 30/97, Loss: 0.1940
Epoch 7/10, Batch 40/97, Loss: 0.1026
Epoch 7/10, Batch 50/97, Loss: 0.2437
Epoch 7/10, Batch 60/97, Loss: 0.2421
Epoch 7/10, Batch 70/97, Loss: 0.1215
Epoch 7/10, Batch 80/97, Loss: 0.3094
Epoch 7/10, Batch 90/97, Loss: 0.2564
Epoch 7/10, Train Loss: 0.2374, Valid Loss: 0.2425
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1353
Epoch 8/10, Batch 20/97, Loss: 0.1262
Epoch 8/10, Batch 30/97, Loss: 0.1090
Epoch 8/10, Batch 40/97, Loss: 0.1621
Epoch 8/10, Batch 50/97, Loss: 0.2675
Epoch 8/10, Batch 60/97, Loss: 0.1914
Epoch 8/10, Batch 70/97, Loss: 0.3962
Epoch 8/10, Batch 80/97, Loss: 0.1741
Epoch 8/10, Batch 90/97, Loss: 0.2089
Epoch 8/10, Train Loss: 0.2104, Valid Loss: 0.2373
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1941
Epoch 9/10, Batch 20/97, Loss: 0.1846
Epoch 9/10, Batch 30/97, Loss: 0.2038
Epoch 9/10, Batch 40/97, Loss: 0.1527
Epoch 9/10, Batch 50/97, Loss: 0.1391
Epoch 9/10, Batch 60/97, Loss: 0.2819
Epoch 9/10, Batch 70/97, Loss: 0.1706
Epoch 9/10, Batch 80/97, Loss: 0.2723
Epoch 9/10, Batch 90/97, Loss: 0.2108
Epoch 9/10, Train Loss: 0.2060, Valid Loss: 0.2359
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2480
Epoch 10/10, Batch 20/97, Loss: 0.1073
Epoch 10/10, Batch 30/97, Loss: 0.1692
Epoch 10/10, Batch 40/97, Loss: 0.2277
Epoch 10/10, Batch 50/97, Loss: 0.3324
Epoch 10/10, Batch 60/97, Loss: 0.1589
Epoch 10/10, Batch 70/97, Loss: 0.1451
Epoch 10/10, Batch 80/97, Loss: 0.1827
Epoch 10/10, Batch 90/97, Loss: 0.2229
Epoch 10/10, Train Loss: 0.2040, Valid Loss: 0.2280
Model saved!
Accuracy: 0.9217
Precision: 0.9195
Recall: 0.9217
F1-score: 0.9201
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4379
Epoch 1/10, Batch 20/97, Loss: 1.0391
Epoch 1/10, Batch 30/97, Loss: 0.8624
Epoch 1/10, Batch 40/97, Loss: 0.7230
Epoch 1/10, Batch 50/97, Loss: 0.5275
Epoch 1/10, Batch 60/97, Loss: 0.6587
Epoch 1/10, Batch 70/97, Loss: 0.4803
Epoch 1/10, Batch 80/97, Loss: 0.4754
Epoch 1/10, Batch 90/97, Loss: 0.5104
Epoch 1/10, Train Loss: 0.7783, Valid Loss: 0.4216
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3501
Epoch 2/10, Batch 20/97, Loss: 0.4888
Epoch 2/10, Batch 30/97, Loss: 0.5024
Epoch 2/10, Batch 40/97, Loss: 0.2878
Epoch 2/10, Batch 50/97, Loss: 0.4586
Epoch 2/10, Batch 60/97, Loss: 0.3098
Epoch 2/10, Batch 70/97, Loss: 0.2543
Epoch 2/10, Batch 80/97, Loss: 0.3054
Epoch 2/10, Batch 90/97, Loss: 0.4831
Epoch 2/10, Train Loss: 0.4000, Valid Loss: 0.3146
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2639
Epoch 3/10, Batch 20/97, Loss: 0.3723
Epoch 3/10, Batch 30/97, Loss: 0.3422
Epoch 3/10, Batch 40/97, Loss: 0.2783
Epoch 3/10, Batch 50/97, Loss: 0.3272
Epoch 3/10, Batch 60/97, Loss: 0.3083
Epoch 3/10, Batch 70/97, Loss: 0.2285
Epoch 3/10, Batch 80/97, Loss: 0.3802
Epoch 3/10, Batch 90/97, Loss: 0.2038
Epoch 3/10, Train Loss: 0.3294, Valid Loss: 0.2785
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2340
Epoch 4/10, Batch 20/97, Loss: 0.2778
Epoch 4/10, Batch 30/97, Loss: 0.4175
Epoch 4/10, Batch 40/97, Loss: 0.1701
Epoch 4/10, Batch 50/97, Loss: 0.2615
Epoch 4/10, Batch 60/97, Loss: 0.2321
Epoch 4/10, Batch 70/97, Loss: 0.1319
Epoch 4/10, Batch 80/97, Loss: 0.2753
Epoch 4/10, Batch 90/97, Loss: 0.3390
Epoch 4/10, Train Loss: 0.2899, Valid Loss: 0.2597
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3320
Epoch 5/10, Batch 20/97, Loss: 0.2154
Epoch 5/10, Batch 30/97, Loss: 0.1323
Epoch 5/10, Batch 40/97, Loss: 0.2238
Epoch 5/10, Batch 50/97, Loss: 0.3199
Epoch 5/10, Batch 60/97, Loss: 0.1840
Epoch 5/10, Batch 70/97, Loss: 0.2523
Epoch 5/10, Batch 80/97, Loss: 0.1760
Epoch 5/10, Batch 90/97, Loss: 0.4790
Epoch 5/10, Train Loss: 0.2641, Valid Loss: 0.2448
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3199
Epoch 6/10, Batch 20/97, Loss: 0.2370
Epoch 6/10, Batch 30/97, Loss: 0.2310
Epoch 6/10, Batch 40/97, Loss: 0.3018
Epoch 6/10, Batch 50/97, Loss: 0.1889
Epoch 6/10, Batch 60/97, Loss: 0.1846
Epoch 6/10, Batch 70/97, Loss: 0.2072
Epoch 6/10, Batch 80/97, Loss: 0.1789
Epoch 6/10, Batch 90/97, Loss: 0.3727
Epoch 6/10, Train Loss: 0.2436, Valid Loss: 0.2338
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2937
Epoch 7/10, Batch 20/97, Loss: 0.1947
Epoch 7/10, Batch 30/97, Loss: 0.2908
Epoch 7/10, Batch 40/97, Loss: 0.1767
Epoch 7/10, Batch 50/97, Loss: 0.1806
Epoch 7/10, Batch 60/97, Loss: 0.2705
Epoch 7/10, Batch 70/97, Loss: 0.2015
Epoch 7/10, Batch 80/97, Loss: 0.0972
Epoch 7/10, Batch 90/97, Loss: 0.1979
Epoch 7/10, Train Loss: 0.2450, Valid Loss: 0.2260
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1974
Epoch 8/10, Batch 20/97, Loss: 0.1679
Epoch 8/10, Batch 30/97, Loss: 0.2020
Epoch 8/10, Batch 40/97, Loss: 0.2150
Epoch 8/10, Batch 50/97, Loss: 0.3134
Epoch 8/10, Batch 60/97, Loss: 0.0991
Epoch 8/10, Batch 70/97, Loss: 0.3148
Epoch 8/10, Batch 80/97, Loss: 0.2112
Epoch 8/10, Batch 90/97, Loss: 0.2334
Epoch 8/10, Train Loss: 0.2202, Valid Loss: 0.2294
Epoch 9/10, Batch 10/97, Loss: 0.1278
Epoch 9/10, Batch 20/97, Loss: 0.2221
Epoch 9/10, Batch 30/97, Loss: 0.1977
Epoch 9/10, Batch 40/97, Loss: 0.1417
Epoch 9/10, Batch 50/97, Loss: 0.3286
Epoch 9/10, Batch 60/97, Loss: 0.2663
Epoch 9/10, Batch 70/97, Loss: 0.1619
Epoch 9/10, Batch 80/97, Loss: 0.1791
Epoch 9/10, Batch 90/97, Loss: 0.2733
Epoch 9/10, Train Loss: 0.2105, Valid Loss: 0.2199
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2471
Epoch 10/10, Batch 20/97, Loss: 0.1548
Epoch 10/10, Batch 30/97, Loss: 0.1603
Epoch 10/10, Batch 40/97, Loss: 0.2413
Epoch 10/10, Batch 50/97, Loss: 0.2452
Epoch 10/10, Batch 60/97, Loss: 0.2017
Epoch 10/10, Batch 70/97, Loss: 0.2191
Epoch 10/10, Batch 80/97, Loss: 0.1760
Epoch 10/10, Batch 90/97, Loss: 0.1042
Epoch 10/10, Train Loss: 0.1985, Valid Loss: 0.2068
Model saved!
Accuracy: 0.9206
Precision: 0.9184
Recall: 0.9206
F1-score: 0.9190
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4269
Epoch 1/10, Batch 20/97, Loss: 0.9929
Epoch 1/10, Batch 30/97, Loss: 0.8424
Epoch 1/10, Batch 40/97, Loss: 0.7031
Epoch 1/10, Batch 50/97, Loss: 0.6882
Epoch 1/10, Batch 60/97, Loss: 0.6433
Epoch 1/10, Batch 70/97, Loss: 0.4920
Epoch 1/10, Batch 80/97, Loss: 0.3723
Epoch 1/10, Batch 90/97, Loss: 0.5344
Epoch 1/10, Train Loss: 0.7790, Valid Loss: 0.4670
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4170
Epoch 2/10, Batch 20/97, Loss: 0.5923
Epoch 2/10, Batch 30/97, Loss: 0.4279
Epoch 2/10, Batch 40/97, Loss: 0.3137
Epoch 2/10, Batch 50/97, Loss: 0.5888
Epoch 2/10, Batch 60/97, Loss: 0.2806
Epoch 2/10, Batch 70/97, Loss: 0.2330
Epoch 2/10, Batch 80/97, Loss: 0.2741
Epoch 2/10, Batch 90/97, Loss: 0.4547
Epoch 2/10, Train Loss: 0.3949, Valid Loss: 0.3574
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4366
Epoch 3/10, Batch 20/97, Loss: 0.2517
Epoch 3/10, Batch 30/97, Loss: 0.2829
Epoch 3/10, Batch 40/97, Loss: 0.3558
Epoch 3/10, Batch 50/97, Loss: 0.2684
Epoch 3/10, Batch 60/97, Loss: 0.2144
Epoch 3/10, Batch 70/97, Loss: 0.2840
Epoch 3/10, Batch 80/97, Loss: 0.2342
Epoch 3/10, Batch 90/97, Loss: 0.2486
Epoch 3/10, Train Loss: 0.3230, Valid Loss: 0.3232
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2568
Epoch 4/10, Batch 20/97, Loss: 0.4080
Epoch 4/10, Batch 30/97, Loss: 0.4516
Epoch 4/10, Batch 40/97, Loss: 0.4647
Epoch 4/10, Batch 50/97, Loss: 0.1646
Epoch 4/10, Batch 60/97, Loss: 0.1327
Epoch 4/10, Batch 70/97, Loss: 0.3746
Epoch 4/10, Batch 80/97, Loss: 0.1622
Epoch 4/10, Batch 90/97, Loss: 0.2862
Epoch 4/10, Train Loss: 0.2842, Valid Loss: 0.2894
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2643
Epoch 5/10, Batch 20/97, Loss: 0.1907
Epoch 5/10, Batch 30/97, Loss: 0.1521
Epoch 5/10, Batch 40/97, Loss: 0.1109
Epoch 5/10, Batch 50/97, Loss: 0.2871
Epoch 5/10, Batch 60/97, Loss: 0.2225
Epoch 5/10, Batch 70/97, Loss: 0.1481
Epoch 5/10, Batch 80/97, Loss: 0.1580
Epoch 5/10, Batch 90/97, Loss: 0.3767
Epoch 5/10, Train Loss: 0.2625, Valid Loss: 0.2803
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3210
Epoch 6/10, Batch 20/97, Loss: 0.2345
Epoch 6/10, Batch 30/97, Loss: 0.1999
Epoch 6/10, Batch 40/97, Loss: 0.1424
Epoch 6/10, Batch 50/97, Loss: 0.2896
Epoch 6/10, Batch 60/97, Loss: 0.1241
Epoch 6/10, Batch 70/97, Loss: 0.3413
Epoch 6/10, Batch 80/97, Loss: 0.0881
Epoch 6/10, Batch 90/97, Loss: 0.1526
Epoch 6/10, Train Loss: 0.2419, Valid Loss: 0.2798
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.5523
Epoch 7/10, Batch 20/97, Loss: 0.0713
Epoch 7/10, Batch 30/97, Loss: 0.1973
Epoch 7/10, Batch 40/97, Loss: 0.1653
Epoch 7/10, Batch 50/97, Loss: 0.1898
Epoch 7/10, Batch 60/97, Loss: 0.2931
Epoch 7/10, Batch 70/97, Loss: 0.1267
Epoch 7/10, Batch 80/97, Loss: 0.2281
Epoch 7/10, Batch 90/97, Loss: 0.2444
Epoch 7/10, Train Loss: 0.2419, Valid Loss: 0.2631
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.3055
Epoch 8/10, Batch 20/97, Loss: 0.2956
Epoch 8/10, Batch 30/97, Loss: 0.1884
Epoch 8/10, Batch 40/97, Loss: 0.1522
Epoch 8/10, Batch 50/97, Loss: 0.3046
Epoch 8/10, Batch 60/97, Loss: 0.1766
Epoch 8/10, Batch 70/97, Loss: 0.2851
Epoch 8/10, Batch 80/97, Loss: 0.2036
Epoch 8/10, Batch 90/97, Loss: 0.1856
Epoch 8/10, Train Loss: 0.2129, Valid Loss: 0.2632
Epoch 9/10, Batch 10/97, Loss: 0.0685
Epoch 9/10, Batch 20/97, Loss: 0.2287
Epoch 9/10, Batch 30/97, Loss: 0.2387
Epoch 9/10, Batch 40/97, Loss: 0.1130
Epoch 9/10, Batch 50/97, Loss: 0.1344
Epoch 9/10, Batch 60/97, Loss: 0.1476
Epoch 9/10, Batch 70/97, Loss: 0.1527
Epoch 9/10, Batch 80/97, Loss: 0.1195
Epoch 9/10, Batch 90/97, Loss: 0.2289
Epoch 9/10, Train Loss: 0.2042, Valid Loss: 0.2625
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2023
Epoch 10/10, Batch 20/97, Loss: 0.1936
Epoch 10/10, Batch 30/97, Loss: 0.1493
Epoch 10/10, Batch 40/97, Loss: 0.2412
Epoch 10/10, Batch 50/97, Loss: 0.2480
Epoch 10/10, Batch 60/97, Loss: 0.1581
Epoch 10/10, Batch 70/97, Loss: 0.1779
Epoch 10/10, Batch 80/97, Loss: 0.1298
Epoch 10/10, Batch 90/97, Loss: 0.2321
Epoch 10/10, Train Loss: 0.1925, Valid Loss: 0.2487
Model saved!
Accuracy: 0.9171
Precision: 0.9155
Recall: 0.9171
F1-score: 0.9142
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4525
Epoch 1/10, Batch 20/97, Loss: 1.0002
Epoch 1/10, Batch 30/97, Loss: 0.8305
Epoch 1/10, Batch 40/97, Loss: 0.6607
Epoch 1/10, Batch 50/97, Loss: 0.5469
Epoch 1/10, Batch 60/97, Loss: 0.6485
Epoch 1/10, Batch 70/97, Loss: 0.4429
Epoch 1/10, Batch 80/97, Loss: 0.4836
Epoch 1/10, Batch 90/97, Loss: 0.6087
Epoch 1/10, Train Loss: 0.7668, Valid Loss: 0.4345
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3327
Epoch 2/10, Batch 20/97, Loss: 0.4266
Epoch 2/10, Batch 30/97, Loss: 0.3755
Epoch 2/10, Batch 40/97, Loss: 0.4775
Epoch 2/10, Batch 50/97, Loss: 0.5397
Epoch 2/10, Batch 60/97, Loss: 0.3190
Epoch 2/10, Batch 70/97, Loss: 0.3267
Epoch 2/10, Batch 80/97, Loss: 0.2790
Epoch 2/10, Batch 90/97, Loss: 0.3309
Epoch 2/10, Train Loss: 0.3856, Valid Loss: 0.3305
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2920
Epoch 3/10, Batch 20/97, Loss: 0.2829
Epoch 3/10, Batch 30/97, Loss: 0.2795
Epoch 3/10, Batch 40/97, Loss: 0.1751
Epoch 3/10, Batch 50/97, Loss: 0.1540
Epoch 3/10, Batch 60/97, Loss: 0.1852
Epoch 3/10, Batch 70/97, Loss: 0.1906
Epoch 3/10, Batch 80/97, Loss: 0.3529
Epoch 3/10, Batch 90/97, Loss: 0.3042
Epoch 3/10, Train Loss: 0.3146, Valid Loss: 0.2954
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2537
Epoch 4/10, Batch 20/97, Loss: 0.2580
Epoch 4/10, Batch 30/97, Loss: 0.4279
Epoch 4/10, Batch 40/97, Loss: 0.3706
Epoch 4/10, Batch 50/97, Loss: 0.2574
Epoch 4/10, Batch 60/97, Loss: 0.1176
Epoch 4/10, Batch 70/97, Loss: 0.2065
Epoch 4/10, Batch 80/97, Loss: 0.3137
Epoch 4/10, Batch 90/97, Loss: 0.1792
Epoch 4/10, Train Loss: 0.2824, Valid Loss: 0.2711
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2406
Epoch 5/10, Batch 20/97, Loss: 0.2387
Epoch 5/10, Batch 30/97, Loss: 0.1341
Epoch 5/10, Batch 40/97, Loss: 0.1929
Epoch 5/10, Batch 50/97, Loss: 0.1809
Epoch 5/10, Batch 60/97, Loss: 0.2761
Epoch 5/10, Batch 70/97, Loss: 0.1528
Epoch 5/10, Batch 80/97, Loss: 0.3189
Epoch 5/10, Batch 90/97, Loss: 0.3894
Epoch 5/10, Train Loss: 0.2516, Valid Loss: 0.2600
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2324
Epoch 6/10, Batch 20/97, Loss: 0.2023
Epoch 6/10, Batch 30/97, Loss: 0.2019
Epoch 6/10, Batch 40/97, Loss: 0.3058
Epoch 6/10, Batch 50/97, Loss: 0.2768
Epoch 6/10, Batch 60/97, Loss: 0.2411
Epoch 6/10, Batch 70/97, Loss: 0.3800
Epoch 6/10, Batch 80/97, Loss: 0.1354
Epoch 6/10, Batch 90/97, Loss: 0.2886
Epoch 6/10, Train Loss: 0.2364, Valid Loss: 0.2455
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2079
Epoch 7/10, Batch 20/97, Loss: 0.0932
Epoch 7/10, Batch 30/97, Loss: 0.1248
Epoch 7/10, Batch 40/97, Loss: 0.1963
Epoch 7/10, Batch 50/97, Loss: 0.3487
Epoch 7/10, Batch 60/97, Loss: 0.2795
Epoch 7/10, Batch 70/97, Loss: 0.1090
Epoch 7/10, Batch 80/97, Loss: 0.1371
Epoch 7/10, Batch 90/97, Loss: 0.1903
Epoch 7/10, Train Loss: 0.2303, Valid Loss: 0.2361
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1400
Epoch 8/10, Batch 20/97, Loss: 0.2111
Epoch 8/10, Batch 30/97, Loss: 0.2045
Epoch 8/10, Batch 40/97, Loss: 0.1220
Epoch 8/10, Batch 50/97, Loss: 0.2512
Epoch 8/10, Batch 60/97, Loss: 0.1713
Epoch 8/10, Batch 70/97, Loss: 0.2897
Epoch 8/10, Batch 80/97, Loss: 0.1479
Epoch 8/10, Batch 90/97, Loss: 0.1109
Epoch 8/10, Train Loss: 0.2157, Valid Loss: 0.2428
Epoch 9/10, Batch 10/97, Loss: 0.1279
Epoch 9/10, Batch 20/97, Loss: 0.0984
Epoch 9/10, Batch 30/97, Loss: 0.1134
Epoch 9/10, Batch 40/97, Loss: 0.1391
Epoch 9/10, Batch 50/97, Loss: 0.2302
Epoch 9/10, Batch 60/97, Loss: 0.2914
Epoch 9/10, Batch 70/97, Loss: 0.1972
Epoch 9/10, Batch 80/97, Loss: 0.1981
Epoch 9/10, Batch 90/97, Loss: 0.1665
Epoch 9/10, Train Loss: 0.1948, Valid Loss: 0.2395
Epoch 10/10, Batch 10/97, Loss: 0.2230
Epoch 10/10, Batch 20/97, Loss: 0.0915
Epoch 10/10, Batch 30/97, Loss: 0.1091
Epoch 10/10, Batch 40/97, Loss: 0.3184
Epoch 10/10, Batch 50/97, Loss: 0.3257
Epoch 10/10, Batch 60/97, Loss: 0.2225
Epoch 10/10, Batch 70/97, Loss: 0.1543
Epoch 10/10, Batch 80/97, Loss: 0.1388
Epoch 10/10, Batch 90/97, Loss: 0.0993
Epoch 10/10, Train Loss: 0.1954, Valid Loss: 0.2305
Model saved!
Accuracy: 0.9217
Precision: 0.9198
Recall: 0.9217
F1-score: 0.9204
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4600
Epoch 1/10, Batch 20/97, Loss: 1.0534
Epoch 1/10, Batch 30/97, Loss: 0.8547
Epoch 1/10, Batch 40/97, Loss: 0.7210
Epoch 1/10, Batch 50/97, Loss: 0.5232
Epoch 1/10, Batch 60/97, Loss: 0.6516
Epoch 1/10, Batch 70/97, Loss: 0.6025
Epoch 1/10, Batch 80/97, Loss: 0.4273
Epoch 1/10, Batch 90/97, Loss: 0.5709
Epoch 1/10, Train Loss: 0.7720, Valid Loss: 0.4506
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3459
Epoch 2/10, Batch 20/97, Loss: 0.4531
Epoch 2/10, Batch 30/97, Loss: 0.4220
Epoch 2/10, Batch 40/97, Loss: 0.3820
Epoch 2/10, Batch 50/97, Loss: 0.4317
Epoch 2/10, Batch 60/97, Loss: 0.3504
Epoch 2/10, Batch 70/97, Loss: 0.3810
Epoch 2/10, Batch 80/97, Loss: 0.3202
Epoch 2/10, Batch 90/97, Loss: 0.3199
Epoch 2/10, Train Loss: 0.3948, Valid Loss: 0.3433
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2399
Epoch 3/10, Batch 20/97, Loss: 0.3599
Epoch 3/10, Batch 30/97, Loss: 0.2161
Epoch 3/10, Batch 40/97, Loss: 0.3222
Epoch 3/10, Batch 50/97, Loss: 0.2885
Epoch 3/10, Batch 60/97, Loss: 0.3666
Epoch 3/10, Batch 70/97, Loss: 0.2773
Epoch 3/10, Batch 80/97, Loss: 0.5019
Epoch 3/10, Batch 90/97, Loss: 0.2326
Epoch 3/10, Train Loss: 0.3191, Valid Loss: 0.3146
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4246
Epoch 4/10, Batch 20/97, Loss: 0.3122
Epoch 4/10, Batch 30/97, Loss: 0.2933
Epoch 4/10, Batch 40/97, Loss: 0.2504
Epoch 4/10, Batch 50/97, Loss: 0.2183
Epoch 4/10, Batch 60/97, Loss: 0.1234
Epoch 4/10, Batch 70/97, Loss: 0.2139
Epoch 4/10, Batch 80/97, Loss: 0.2994
Epoch 4/10, Batch 90/97, Loss: 0.2917
Epoch 4/10, Train Loss: 0.2836, Valid Loss: 0.2852
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2745
Epoch 5/10, Batch 20/97, Loss: 0.2139
Epoch 5/10, Batch 30/97, Loss: 0.1580
Epoch 5/10, Batch 40/97, Loss: 0.2386
Epoch 5/10, Batch 50/97, Loss: 0.1892
Epoch 5/10, Batch 60/97, Loss: 0.2411
Epoch 5/10, Batch 70/97, Loss: 0.1548
Epoch 5/10, Batch 80/97, Loss: 0.4734
Epoch 5/10, Batch 90/97, Loss: 0.2928
Epoch 5/10, Train Loss: 0.2537, Valid Loss: 0.2769
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1594
Epoch 6/10, Batch 20/97, Loss: 0.2651
Epoch 6/10, Batch 30/97, Loss: 0.3573
Epoch 6/10, Batch 40/97, Loss: 0.2147
Epoch 6/10, Batch 50/97, Loss: 0.1184
Epoch 6/10, Batch 60/97, Loss: 0.2160
Epoch 6/10, Batch 70/97, Loss: 0.3018
Epoch 6/10, Batch 80/97, Loss: 0.2262
Epoch 6/10, Batch 90/97, Loss: 0.3023
Epoch 6/10, Train Loss: 0.2426, Valid Loss: 0.2579
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3813
Epoch 7/10, Batch 20/97, Loss: 0.1780
Epoch 7/10, Batch 30/97, Loss: 0.1271
Epoch 7/10, Batch 40/97, Loss: 0.1461
Epoch 7/10, Batch 50/97, Loss: 0.2610
Epoch 7/10, Batch 60/97, Loss: 0.3493
Epoch 7/10, Batch 70/97, Loss: 0.2313
Epoch 7/10, Batch 80/97, Loss: 0.1369
Epoch 7/10, Batch 90/97, Loss: 0.2580
Epoch 7/10, Train Loss: 0.2409, Valid Loss: 0.2561
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1625
Epoch 8/10, Batch 20/97, Loss: 0.2018
Epoch 8/10, Batch 30/97, Loss: 0.1587
Epoch 8/10, Batch 40/97, Loss: 0.1405
Epoch 8/10, Batch 50/97, Loss: 0.3202
Epoch 8/10, Batch 60/97, Loss: 0.1081
Epoch 8/10, Batch 70/97, Loss: 0.1313
Epoch 8/10, Batch 80/97, Loss: 0.1760
Epoch 8/10, Batch 90/97, Loss: 0.2394
Epoch 8/10, Train Loss: 0.2123, Valid Loss: 0.2529
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1139
Epoch 9/10, Batch 20/97, Loss: 0.1538
Epoch 9/10, Batch 30/97, Loss: 0.3404
Epoch 9/10, Batch 40/97, Loss: 0.0560
Epoch 9/10, Batch 50/97, Loss: 0.2175
Epoch 9/10, Batch 60/97, Loss: 0.1527
Epoch 9/10, Batch 70/97, Loss: 0.2532
Epoch 9/10, Batch 80/97, Loss: 0.1747
Epoch 9/10, Batch 90/97, Loss: 0.2708
Epoch 9/10, Train Loss: 0.2039, Valid Loss: 0.2474
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2440
Epoch 10/10, Batch 20/97, Loss: 0.1622
Epoch 10/10, Batch 30/97, Loss: 0.1468
Epoch 10/10, Batch 40/97, Loss: 0.2791
Epoch 10/10, Batch 50/97, Loss: 0.1870
Epoch 10/10, Batch 60/97, Loss: 0.1625
Epoch 10/10, Batch 70/97, Loss: 0.1148
Epoch 10/10, Batch 80/97, Loss: 0.1695
Epoch 10/10, Batch 90/97, Loss: 0.2119
Epoch 10/10, Train Loss: 0.1867, Valid Loss: 0.2432
Model saved!
Accuracy: 0.9217
Precision: 0.9192
Recall: 0.9217
F1-score: 0.9199
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4688
Epoch 1/10, Batch 20/97, Loss: 0.9904
Epoch 1/10, Batch 30/97, Loss: 0.8926
Epoch 1/10, Batch 40/97, Loss: 0.6881
Epoch 1/10, Batch 50/97, Loss: 0.6358
Epoch 1/10, Batch 60/97, Loss: 0.6041
Epoch 1/10, Batch 70/97, Loss: 0.5384
Epoch 1/10, Batch 80/97, Loss: 0.4681
Epoch 1/10, Batch 90/97, Loss: 0.5806
Epoch 1/10, Train Loss: 0.7800, Valid Loss: 0.4274
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4046
Epoch 2/10, Batch 20/97, Loss: 0.6096
Epoch 2/10, Batch 30/97, Loss: 0.3272
Epoch 2/10, Batch 40/97, Loss: 0.3725
Epoch 2/10, Batch 50/97, Loss: 0.4871
Epoch 2/10, Batch 60/97, Loss: 0.3962
Epoch 2/10, Batch 70/97, Loss: 0.3180
Epoch 2/10, Batch 80/97, Loss: 0.2756
Epoch 2/10, Batch 90/97, Loss: 0.3706
Epoch 2/10, Train Loss: 0.4035, Valid Loss: 0.3268
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3375
Epoch 3/10, Batch 20/97, Loss: 0.2518
Epoch 3/10, Batch 30/97, Loss: 0.3333
Epoch 3/10, Batch 40/97, Loss: 0.2694
Epoch 3/10, Batch 50/97, Loss: 0.2359
Epoch 3/10, Batch 60/97, Loss: 0.3296
Epoch 3/10, Batch 70/97, Loss: 0.2507
Epoch 3/10, Batch 80/97, Loss: 0.2931
Epoch 3/10, Batch 90/97, Loss: 0.1611
Epoch 3/10, Train Loss: 0.3310, Valid Loss: 0.2855
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2670
Epoch 4/10, Batch 20/97, Loss: 0.1671
Epoch 4/10, Batch 30/97, Loss: 0.2829
Epoch 4/10, Batch 40/97, Loss: 0.2506
Epoch 4/10, Batch 50/97, Loss: 0.2395
Epoch 4/10, Batch 60/97, Loss: 0.1450
Epoch 4/10, Batch 70/97, Loss: 0.1804
Epoch 4/10, Batch 80/97, Loss: 0.2893
Epoch 4/10, Batch 90/97, Loss: 0.1854
Epoch 4/10, Train Loss: 0.2889, Valid Loss: 0.2599
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1304
Epoch 5/10, Batch 20/97, Loss: 0.1606
Epoch 5/10, Batch 30/97, Loss: 0.2499
Epoch 5/10, Batch 40/97, Loss: 0.1360
Epoch 5/10, Batch 50/97, Loss: 0.2120
Epoch 5/10, Batch 60/97, Loss: 0.1908
Epoch 5/10, Batch 70/97, Loss: 0.3176
Epoch 5/10, Batch 80/97, Loss: 0.4179
Epoch 5/10, Batch 90/97, Loss: 0.3565
Epoch 5/10, Train Loss: 0.2656, Valid Loss: 0.2583
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2108
Epoch 6/10, Batch 20/97, Loss: 0.1736
Epoch 6/10, Batch 30/97, Loss: 0.2073
Epoch 6/10, Batch 40/97, Loss: 0.2942
Epoch 6/10, Batch 50/97, Loss: 0.1400
Epoch 6/10, Batch 60/97, Loss: 0.2133
Epoch 6/10, Batch 70/97, Loss: 0.1653
Epoch 6/10, Batch 80/97, Loss: 0.1175
Epoch 6/10, Batch 90/97, Loss: 0.1962
Epoch 6/10, Train Loss: 0.2358, Valid Loss: 0.2476
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3419
Epoch 7/10, Batch 20/97, Loss: 0.1703
Epoch 7/10, Batch 30/97, Loss: 0.1622
Epoch 7/10, Batch 40/97, Loss: 0.2178
Epoch 7/10, Batch 50/97, Loss: 0.1249
Epoch 7/10, Batch 60/97, Loss: 0.2675
Epoch 7/10, Batch 70/97, Loss: 0.1788
Epoch 7/10, Batch 80/97, Loss: 0.1685
Epoch 7/10, Batch 90/97, Loss: 0.3107
Epoch 7/10, Train Loss: 0.2462, Valid Loss: 0.2419
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2631
Epoch 8/10, Batch 20/97, Loss: 0.2131
Epoch 8/10, Batch 30/97, Loss: 0.1660
Epoch 8/10, Batch 40/97, Loss: 0.2189
Epoch 8/10, Batch 50/97, Loss: 0.2584
Epoch 8/10, Batch 60/97, Loss: 0.1482
Epoch 8/10, Batch 70/97, Loss: 0.2609
Epoch 8/10, Batch 80/97, Loss: 0.2159
Epoch 8/10, Batch 90/97, Loss: 0.2398
Epoch 8/10, Train Loss: 0.2234, Valid Loss: 0.2422
Epoch 9/10, Batch 10/97, Loss: 0.2151
Epoch 9/10, Batch 20/97, Loss: 0.1152
Epoch 9/10, Batch 30/97, Loss: 0.1699
Epoch 9/10, Batch 40/97, Loss: 0.1577
Epoch 9/10, Batch 50/97, Loss: 0.3400
Epoch 9/10, Batch 60/97, Loss: 0.2270
Epoch 9/10, Batch 70/97, Loss: 0.1677
Epoch 9/10, Batch 80/97, Loss: 0.3395
Epoch 9/10, Batch 90/97, Loss: 0.2311
Epoch 9/10, Train Loss: 0.2109, Valid Loss: 0.2453
Epoch 10/10, Batch 10/97, Loss: 0.2105
Epoch 10/10, Batch 20/97, Loss: 0.0580
Epoch 10/10, Batch 30/97, Loss: 0.1911
Epoch 10/10, Batch 40/97, Loss: 0.1741
Epoch 10/10, Batch 50/97, Loss: 0.2987
Epoch 10/10, Batch 60/97, Loss: 0.1042
Epoch 10/10, Batch 70/97, Loss: 0.1699
Epoch 10/10, Batch 80/97, Loss: 0.2123
Epoch 10/10, Batch 90/97, Loss: 0.1482
Epoch 10/10, Train Loss: 0.1947, Valid Loss: 0.2411
Model saved!
Accuracy: 0.9100
Precision: 0.9074
Recall: 0.9100
F1-score: 0.9081
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4746
Epoch 1/10, Batch 20/97, Loss: 1.0254
Epoch 1/10, Batch 30/97, Loss: 0.8141
Epoch 1/10, Batch 40/97, Loss: 0.7741
Epoch 1/10, Batch 50/97, Loss: 0.7746
Epoch 1/10, Batch 60/97, Loss: 0.6138
Epoch 1/10, Batch 70/97, Loss: 0.6436
Epoch 1/10, Batch 80/97, Loss: 0.4671
Epoch 1/10, Batch 90/97, Loss: 0.6461
Epoch 1/10, Train Loss: 0.7796, Valid Loss: 0.4135
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3345
Epoch 2/10, Batch 20/97, Loss: 0.5295
Epoch 2/10, Batch 30/97, Loss: 0.4245
Epoch 2/10, Batch 40/97, Loss: 0.4159
Epoch 2/10, Batch 50/97, Loss: 0.7007
Epoch 2/10, Batch 60/97, Loss: 0.2739
Epoch 2/10, Batch 70/97, Loss: 0.2320
Epoch 2/10, Batch 80/97, Loss: 0.3765
Epoch 2/10, Batch 90/97, Loss: 0.2645
Epoch 2/10, Train Loss: 0.3998, Valid Loss: 0.3052
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3555
Epoch 3/10, Batch 20/97, Loss: 0.3685
Epoch 3/10, Batch 30/97, Loss: 0.3316
Epoch 3/10, Batch 40/97, Loss: 0.3389
Epoch 3/10, Batch 50/97, Loss: 0.2101
Epoch 3/10, Batch 60/97, Loss: 0.2041
Epoch 3/10, Batch 70/97, Loss: 0.1786
Epoch 3/10, Batch 80/97, Loss: 0.3801
Epoch 3/10, Batch 90/97, Loss: 0.3036
Epoch 3/10, Train Loss: 0.3211, Valid Loss: 0.2613
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2024
Epoch 4/10, Batch 20/97, Loss: 0.1796
Epoch 4/10, Batch 30/97, Loss: 0.3265
Epoch 4/10, Batch 40/97, Loss: 0.2910
Epoch 4/10, Batch 50/97, Loss: 0.1298
Epoch 4/10, Batch 60/97, Loss: 0.1802
Epoch 4/10, Batch 70/97, Loss: 0.2050
Epoch 4/10, Batch 80/97, Loss: 0.2476
Epoch 4/10, Batch 90/97, Loss: 0.2254
Epoch 4/10, Train Loss: 0.2880, Valid Loss: 0.2372
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1425
Epoch 5/10, Batch 20/97, Loss: 0.1882
Epoch 5/10, Batch 30/97, Loss: 0.1790
Epoch 5/10, Batch 40/97, Loss: 0.1495
Epoch 5/10, Batch 50/97, Loss: 0.1633
Epoch 5/10, Batch 60/97, Loss: 0.1858
Epoch 5/10, Batch 70/97, Loss: 0.1490
Epoch 5/10, Batch 80/97, Loss: 0.2130
Epoch 5/10, Batch 90/97, Loss: 0.3251
Epoch 5/10, Train Loss: 0.2573, Valid Loss: 0.2235
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2547
Epoch 6/10, Batch 20/97, Loss: 0.1834
Epoch 6/10, Batch 30/97, Loss: 0.1271
Epoch 6/10, Batch 40/97, Loss: 0.2815
Epoch 6/10, Batch 50/97, Loss: 0.2031
Epoch 6/10, Batch 60/97, Loss: 0.2747
Epoch 6/10, Batch 70/97, Loss: 0.2299
Epoch 6/10, Batch 80/97, Loss: 0.2152
Epoch 6/10, Batch 90/97, Loss: 0.2096
Epoch 6/10, Train Loss: 0.2340, Valid Loss: 0.2093
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2474
Epoch 7/10, Batch 20/97, Loss: 0.1486
Epoch 7/10, Batch 30/97, Loss: 0.2091
Epoch 7/10, Batch 40/97, Loss: 0.1134
Epoch 7/10, Batch 50/97, Loss: 0.2322
Epoch 7/10, Batch 60/97, Loss: 0.3341
Epoch 7/10, Batch 70/97, Loss: 0.2168
Epoch 7/10, Batch 80/97, Loss: 0.2422
Epoch 7/10, Batch 90/97, Loss: 0.1900
Epoch 7/10, Train Loss: 0.2383, Valid Loss: 0.2067
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1215
Epoch 8/10, Batch 20/97, Loss: 0.2071
Epoch 8/10, Batch 30/97, Loss: 0.1267
Epoch 8/10, Batch 40/97, Loss: 0.1595
Epoch 8/10, Batch 50/97, Loss: 0.3114
Epoch 8/10, Batch 60/97, Loss: 0.1516
Epoch 8/10, Batch 70/97, Loss: 0.2596
Epoch 8/10, Batch 80/97, Loss: 0.1949
Epoch 8/10, Batch 90/97, Loss: 0.1206
Epoch 8/10, Train Loss: 0.2114, Valid Loss: 0.2013
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.3198
Epoch 9/10, Batch 20/97, Loss: 0.1053
Epoch 9/10, Batch 30/97, Loss: 0.2018
Epoch 9/10, Batch 40/97, Loss: 0.0868
Epoch 9/10, Batch 50/97, Loss: 0.1464
Epoch 9/10, Batch 60/97, Loss: 0.2743
Epoch 9/10, Batch 70/97, Loss: 0.1583
Epoch 9/10, Batch 80/97, Loss: 0.2257
Epoch 9/10, Batch 90/97, Loss: 0.1473
Epoch 9/10, Train Loss: 0.2045, Valid Loss: 0.1955
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3662
Epoch 10/10, Batch 20/97, Loss: 0.1707
Epoch 10/10, Batch 30/97, Loss: 0.1473
Epoch 10/10, Batch 40/97, Loss: 0.3196
Epoch 10/10, Batch 50/97, Loss: 0.2519
Epoch 10/10, Batch 60/97, Loss: 0.1339
Epoch 10/10, Batch 70/97, Loss: 0.2562
Epoch 10/10, Batch 80/97, Loss: 0.2746
Epoch 10/10, Batch 90/97, Loss: 0.1379
Epoch 10/10, Train Loss: 0.1978, Valid Loss: 0.1893
Model saved!
Accuracy: 0.9147
Precision: 0.9126
Recall: 0.9147
F1-score: 0.9132
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4306
Epoch 1/10, Batch 20/97, Loss: 1.0358
Epoch 1/10, Batch 30/97, Loss: 0.8742
Epoch 1/10, Batch 40/97, Loss: 0.7149
Epoch 1/10, Batch 50/97, Loss: 0.6448
Epoch 1/10, Batch 60/97, Loss: 0.6435
Epoch 1/10, Batch 70/97, Loss: 0.5376
Epoch 1/10, Batch 80/97, Loss: 0.4621
Epoch 1/10, Batch 90/97, Loss: 0.4051
Epoch 1/10, Train Loss: 0.7701, Valid Loss: 0.4610
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3097
Epoch 2/10, Batch 20/97, Loss: 0.4652
Epoch 2/10, Batch 30/97, Loss: 0.4585
Epoch 2/10, Batch 40/97, Loss: 0.5435
Epoch 2/10, Batch 50/97, Loss: 0.4416
Epoch 2/10, Batch 60/97, Loss: 0.3060
Epoch 2/10, Batch 70/97, Loss: 0.2598
Epoch 2/10, Batch 80/97, Loss: 0.3793
Epoch 2/10, Batch 90/97, Loss: 0.2549
Epoch 2/10, Train Loss: 0.3830, Valid Loss: 0.3664
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2997
Epoch 3/10, Batch 20/97, Loss: 0.3740
Epoch 3/10, Batch 30/97, Loss: 0.3121
Epoch 3/10, Batch 40/97, Loss: 0.3571
Epoch 3/10, Batch 50/97, Loss: 0.3798
Epoch 3/10, Batch 60/97, Loss: 0.2230
Epoch 3/10, Batch 70/97, Loss: 0.1808
Epoch 3/10, Batch 80/97, Loss: 0.3285
Epoch 3/10, Batch 90/97, Loss: 0.2969
Epoch 3/10, Train Loss: 0.3134, Valid Loss: 0.3230
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2656
Epoch 4/10, Batch 20/97, Loss: 0.2638
Epoch 4/10, Batch 30/97, Loss: 0.2639
Epoch 4/10, Batch 40/97, Loss: 0.2241
Epoch 4/10, Batch 50/97, Loss: 0.2276
Epoch 4/10, Batch 60/97, Loss: 0.2130
Epoch 4/10, Batch 70/97, Loss: 0.2095
Epoch 4/10, Batch 80/97, Loss: 0.2335
Epoch 4/10, Batch 90/97, Loss: 0.1863
Epoch 4/10, Train Loss: 0.2683, Valid Loss: 0.3066
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1181
Epoch 5/10, Batch 20/97, Loss: 0.1501
Epoch 5/10, Batch 30/97, Loss: 0.2508
Epoch 5/10, Batch 40/97, Loss: 0.1029
Epoch 5/10, Batch 50/97, Loss: 0.1894
Epoch 5/10, Batch 60/97, Loss: 0.2099
Epoch 5/10, Batch 70/97, Loss: 0.2231
Epoch 5/10, Batch 80/97, Loss: 0.2297
Epoch 5/10, Batch 90/97, Loss: 0.3006
Epoch 5/10, Train Loss: 0.2396, Valid Loss: 0.2931
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3059
Epoch 6/10, Batch 20/97, Loss: 0.2181
Epoch 6/10, Batch 30/97, Loss: 0.2342
Epoch 6/10, Batch 40/97, Loss: 0.2292
Epoch 6/10, Batch 50/97, Loss: 0.2937
Epoch 6/10, Batch 60/97, Loss: 0.2735
Epoch 6/10, Batch 70/97, Loss: 0.2542
Epoch 6/10, Batch 80/97, Loss: 0.2209
Epoch 6/10, Batch 90/97, Loss: 0.1632
Epoch 6/10, Train Loss: 0.2351, Valid Loss: 0.2848
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3423
Epoch 7/10, Batch 20/97, Loss: 0.0987
Epoch 7/10, Batch 30/97, Loss: 0.1368
Epoch 7/10, Batch 40/97, Loss: 0.1160
Epoch 7/10, Batch 50/97, Loss: 0.2025
Epoch 7/10, Batch 60/97, Loss: 0.2721
Epoch 7/10, Batch 70/97, Loss: 0.2734
Epoch 7/10, Batch 80/97, Loss: 0.1545
Epoch 7/10, Batch 90/97, Loss: 0.2476
Epoch 7/10, Train Loss: 0.2255, Valid Loss: 0.2686
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2111
Epoch 8/10, Batch 20/97, Loss: 0.1160
Epoch 8/10, Batch 30/97, Loss: 0.1140
Epoch 8/10, Batch 40/97, Loss: 0.2517
Epoch 8/10, Batch 50/97, Loss: 0.1715
Epoch 8/10, Batch 60/97, Loss: 0.1647
Epoch 8/10, Batch 70/97, Loss: 0.2169
Epoch 8/10, Batch 80/97, Loss: 0.1396
Epoch 8/10, Batch 90/97, Loss: 0.1026
Epoch 8/10, Train Loss: 0.1991, Valid Loss: 0.2658
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1287
Epoch 9/10, Batch 20/97, Loss: 0.1686
Epoch 9/10, Batch 30/97, Loss: 0.2856
Epoch 9/10, Batch 40/97, Loss: 0.1053
Epoch 9/10, Batch 50/97, Loss: 0.3292
Epoch 9/10, Batch 60/97, Loss: 0.1680
Epoch 9/10, Batch 70/97, Loss: 0.1027
Epoch 9/10, Batch 80/97, Loss: 0.1795
Epoch 9/10, Batch 90/97, Loss: 0.1668
Epoch 9/10, Train Loss: 0.1917, Valid Loss: 0.2607
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2411
Epoch 10/10, Batch 20/97, Loss: 0.1573
Epoch 10/10, Batch 30/97, Loss: 0.1050
Epoch 10/10, Batch 40/97, Loss: 0.1013
Epoch 10/10, Batch 50/97, Loss: 0.4051
Epoch 10/10, Batch 60/97, Loss: 0.1708
Epoch 10/10, Batch 70/97, Loss: 0.1927
Epoch 10/10, Batch 80/97, Loss: 0.2232
Epoch 10/10, Batch 90/97, Loss: 0.1563
Epoch 10/10, Train Loss: 0.1851, Valid Loss: 0.2527
Model saved!
Accuracy: 0.9194
Precision: 0.9179
Recall: 0.9194
F1-score: 0.9181
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4965
Epoch 1/10, Batch 20/97, Loss: 0.9528
Epoch 1/10, Batch 30/97, Loss: 0.9237
Epoch 1/10, Batch 40/97, Loss: 0.7474
Epoch 1/10, Batch 50/97, Loss: 0.6431
Epoch 1/10, Batch 60/97, Loss: 0.5653
Epoch 1/10, Batch 70/97, Loss: 0.5091
Epoch 1/10, Batch 80/97, Loss: 0.5245
Epoch 1/10, Batch 90/97, Loss: 0.5863
Epoch 1/10, Train Loss: 0.7722, Valid Loss: 0.4430
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5325
Epoch 2/10, Batch 20/97, Loss: 0.6151
Epoch 2/10, Batch 30/97, Loss: 0.4769
Epoch 2/10, Batch 40/97, Loss: 0.3384
Epoch 2/10, Batch 50/97, Loss: 0.6425
Epoch 2/10, Batch 60/97, Loss: 0.3706
Epoch 2/10, Batch 70/97, Loss: 0.3260
Epoch 2/10, Batch 80/97, Loss: 0.2463
Epoch 2/10, Batch 90/97, Loss: 0.3536
Epoch 2/10, Train Loss: 0.4002, Valid Loss: 0.3506
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3204
Epoch 3/10, Batch 20/97, Loss: 0.3231
Epoch 3/10, Batch 30/97, Loss: 0.2977
Epoch 3/10, Batch 40/97, Loss: 0.2885
Epoch 3/10, Batch 50/97, Loss: 0.1760
Epoch 3/10, Batch 60/97, Loss: 0.2065
Epoch 3/10, Batch 70/97, Loss: 0.1785
Epoch 3/10, Batch 80/97, Loss: 0.2816
Epoch 3/10, Batch 90/97, Loss: 0.2983
Epoch 3/10, Train Loss: 0.3156, Valid Loss: 0.3191
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2624
Epoch 4/10, Batch 20/97, Loss: 0.2118
Epoch 4/10, Batch 30/97, Loss: 0.2735
Epoch 4/10, Batch 40/97, Loss: 0.2772
Epoch 4/10, Batch 50/97, Loss: 0.2130
Epoch 4/10, Batch 60/97, Loss: 0.2531
Epoch 4/10, Batch 70/97, Loss: 0.2805
Epoch 4/10, Batch 80/97, Loss: 0.2944
Epoch 4/10, Batch 90/97, Loss: 0.1216
Epoch 4/10, Train Loss: 0.2827, Valid Loss: 0.2968
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3102
Epoch 5/10, Batch 20/97, Loss: 0.1738
Epoch 5/10, Batch 30/97, Loss: 0.1724
Epoch 5/10, Batch 40/97, Loss: 0.1347
Epoch 5/10, Batch 50/97, Loss: 0.1977
Epoch 5/10, Batch 60/97, Loss: 0.1827
Epoch 5/10, Batch 70/97, Loss: 0.2557
Epoch 5/10, Batch 80/97, Loss: 0.3639
Epoch 5/10, Batch 90/97, Loss: 0.3276
Epoch 5/10, Train Loss: 0.2559, Valid Loss: 0.2803
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1373
Epoch 6/10, Batch 20/97, Loss: 0.4792
Epoch 6/10, Batch 30/97, Loss: 0.4289
Epoch 6/10, Batch 40/97, Loss: 0.3260
Epoch 6/10, Batch 50/97, Loss: 0.3239
Epoch 6/10, Batch 60/97, Loss: 0.2001
Epoch 6/10, Batch 70/97, Loss: 0.1979
Epoch 6/10, Batch 80/97, Loss: 0.1695
Epoch 6/10, Batch 90/97, Loss: 0.2809
Epoch 6/10, Train Loss: 0.2385, Valid Loss: 0.2795
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2020
Epoch 7/10, Batch 20/97, Loss: 0.1155
Epoch 7/10, Batch 30/97, Loss: 0.1291
Epoch 7/10, Batch 40/97, Loss: 0.1274
Epoch 7/10, Batch 50/97, Loss: 0.2737
Epoch 7/10, Batch 60/97, Loss: 0.2420
Epoch 7/10, Batch 70/97, Loss: 0.2250
Epoch 7/10, Batch 80/97, Loss: 0.2235
Epoch 7/10, Batch 90/97, Loss: 0.4239
Epoch 7/10, Train Loss: 0.2343, Valid Loss: 0.2705
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1023
Epoch 8/10, Batch 20/97, Loss: 0.1298
Epoch 8/10, Batch 30/97, Loss: 0.1768
Epoch 8/10, Batch 40/97, Loss: 0.1839
Epoch 8/10, Batch 50/97, Loss: 0.1751
Epoch 8/10, Batch 60/97, Loss: 0.1569
Epoch 8/10, Batch 70/97, Loss: 0.1706
Epoch 8/10, Batch 80/97, Loss: 0.0917
Epoch 8/10, Batch 90/97, Loss: 0.1804
Epoch 8/10, Train Loss: 0.2118, Valid Loss: 0.2626
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1768
Epoch 9/10, Batch 20/97, Loss: 0.1241
Epoch 9/10, Batch 30/97, Loss: 0.2676
Epoch 9/10, Batch 40/97, Loss: 0.0794
Epoch 9/10, Batch 50/97, Loss: 0.4081
Epoch 9/10, Batch 60/97, Loss: 0.1838
Epoch 9/10, Batch 70/97, Loss: 0.2028
Epoch 9/10, Batch 80/97, Loss: 0.1895
Epoch 9/10, Batch 90/97, Loss: 0.2860
Epoch 9/10, Train Loss: 0.2078, Valid Loss: 0.2726
Epoch 10/10, Batch 10/97, Loss: 0.2296
Epoch 10/10, Batch 20/97, Loss: 0.1685
Epoch 10/10, Batch 30/97, Loss: 0.2302
Epoch 10/10, Batch 40/97, Loss: 0.1306
Epoch 10/10, Batch 50/97, Loss: 0.1566
Epoch 10/10, Batch 60/97, Loss: 0.2003
Epoch 10/10, Batch 70/97, Loss: 0.1989
Epoch 10/10, Batch 80/97, Loss: 0.1779
Epoch 10/10, Batch 90/97, Loss: 0.1597
Epoch 10/10, Train Loss: 0.1886, Valid Loss: 0.2620
Model saved!
Accuracy: 0.9241
Precision: 0.9219
Recall: 0.9241
F1-score: 0.9226
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4161
Epoch 1/10, Batch 20/97, Loss: 1.0017
Epoch 1/10, Batch 30/97, Loss: 0.9684
Epoch 1/10, Batch 40/97, Loss: 0.9262
Epoch 1/10, Batch 50/97, Loss: 0.6821
Epoch 1/10, Batch 60/97, Loss: 0.5381
Epoch 1/10, Batch 70/97, Loss: 0.5126
Epoch 1/10, Batch 80/97, Loss: 0.4490
Epoch 1/10, Batch 90/97, Loss: 0.5403
Epoch 1/10, Train Loss: 0.7814, Valid Loss: 0.4326
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5549
Epoch 2/10, Batch 20/97, Loss: 0.4768
Epoch 2/10, Batch 30/97, Loss: 0.3935
Epoch 2/10, Batch 40/97, Loss: 0.4698
Epoch 2/10, Batch 50/97, Loss: 0.6400
Epoch 2/10, Batch 60/97, Loss: 0.4025
Epoch 2/10, Batch 70/97, Loss: 0.3434
Epoch 2/10, Batch 80/97, Loss: 0.3121
Epoch 2/10, Batch 90/97, Loss: 0.3461
Epoch 2/10, Train Loss: 0.3967, Valid Loss: 0.3228
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3068
Epoch 3/10, Batch 20/97, Loss: 0.2191
Epoch 3/10, Batch 30/97, Loss: 0.2882
Epoch 3/10, Batch 40/97, Loss: 0.2928
Epoch 3/10, Batch 50/97, Loss: 0.2757
Epoch 3/10, Batch 60/97, Loss: 0.3048
Epoch 3/10, Batch 70/97, Loss: 0.1547
Epoch 3/10, Batch 80/97, Loss: 0.3525
Epoch 3/10, Batch 90/97, Loss: 0.1896
Epoch 3/10, Train Loss: 0.3165, Valid Loss: 0.2793
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3502
Epoch 4/10, Batch 20/97, Loss: 0.2988
Epoch 4/10, Batch 30/97, Loss: 0.2365
Epoch 4/10, Batch 40/97, Loss: 0.2860
Epoch 4/10, Batch 50/97, Loss: 0.2181
Epoch 4/10, Batch 60/97, Loss: 0.2255
Epoch 4/10, Batch 70/97, Loss: 0.1419
Epoch 4/10, Batch 80/97, Loss: 0.1937
Epoch 4/10, Batch 90/97, Loss: 0.4055
Epoch 4/10, Train Loss: 0.2784, Valid Loss: 0.2569
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1279
Epoch 5/10, Batch 20/97, Loss: 0.2726
Epoch 5/10, Batch 30/97, Loss: 0.0982
Epoch 5/10, Batch 40/97, Loss: 0.1642
Epoch 5/10, Batch 50/97, Loss: 0.1697
Epoch 5/10, Batch 60/97, Loss: 0.2850
Epoch 5/10, Batch 70/97, Loss: 0.1880
Epoch 5/10, Batch 80/97, Loss: 0.3964
Epoch 5/10, Batch 90/97, Loss: 0.2822
Epoch 5/10, Train Loss: 0.2528, Valid Loss: 0.2436
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1963
Epoch 6/10, Batch 20/97, Loss: 0.2142
Epoch 6/10, Batch 30/97, Loss: 0.1520
Epoch 6/10, Batch 40/97, Loss: 0.2470
Epoch 6/10, Batch 50/97, Loss: 0.1714
Epoch 6/10, Batch 60/97, Loss: 0.2497
Epoch 6/10, Batch 70/97, Loss: 0.3176
Epoch 6/10, Batch 80/97, Loss: 0.2448
Epoch 6/10, Batch 90/97, Loss: 0.2529
Epoch 6/10, Train Loss: 0.2317, Valid Loss: 0.2384
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2640
Epoch 7/10, Batch 20/97, Loss: 0.1220
Epoch 7/10, Batch 30/97, Loss: 0.0979
Epoch 7/10, Batch 40/97, Loss: 0.1785
Epoch 7/10, Batch 50/97, Loss: 0.3062
Epoch 7/10, Batch 60/97, Loss: 0.2775
Epoch 7/10, Batch 70/97, Loss: 0.0774
Epoch 7/10, Batch 80/97, Loss: 0.1695
Epoch 7/10, Batch 90/97, Loss: 0.1517
Epoch 7/10, Train Loss: 0.2359, Valid Loss: 0.2233
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1681
Epoch 8/10, Batch 20/97, Loss: 0.1721
Epoch 8/10, Batch 30/97, Loss: 0.0989
Epoch 8/10, Batch 40/97, Loss: 0.1199
Epoch 8/10, Batch 50/97, Loss: 0.1703
Epoch 8/10, Batch 60/97, Loss: 0.0851
Epoch 8/10, Batch 70/97, Loss: 0.2512
Epoch 8/10, Batch 80/97, Loss: 0.1053
Epoch 8/10, Batch 90/97, Loss: 0.1275
Epoch 8/10, Train Loss: 0.2026, Valid Loss: 0.2204
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1190
Epoch 9/10, Batch 20/97, Loss: 0.1370
Epoch 9/10, Batch 30/97, Loss: 0.3028
Epoch 9/10, Batch 40/97, Loss: 0.1671
Epoch 9/10, Batch 50/97, Loss: 0.2518
Epoch 9/10, Batch 60/97, Loss: 0.1296
Epoch 9/10, Batch 70/97, Loss: 0.1373
Epoch 9/10, Batch 80/97, Loss: 0.1604
Epoch 9/10, Batch 90/97, Loss: 0.1548
Epoch 9/10, Train Loss: 0.1969, Valid Loss: 0.2123
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2471
Epoch 10/10, Batch 20/97, Loss: 0.1306
Epoch 10/10, Batch 30/97, Loss: 0.1883
Epoch 10/10, Batch 40/97, Loss: 0.2418
Epoch 10/10, Batch 50/97, Loss: 0.2222
Epoch 10/10, Batch 60/97, Loss: 0.2870
Epoch 10/10, Batch 70/97, Loss: 0.0737
Epoch 10/10, Batch 80/97, Loss: 0.2509
Epoch 10/10, Batch 90/97, Loss: 0.1712
Epoch 10/10, Train Loss: 0.1908, Valid Loss: 0.2075
Model saved!
Accuracy: 0.9194
Precision: 0.9177
Recall: 0.9194
F1-score: 0.9180
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4884
Epoch 1/10, Batch 20/97, Loss: 0.9825
Epoch 1/10, Batch 30/97, Loss: 0.8890
Epoch 1/10, Batch 40/97, Loss: 0.7252
Epoch 1/10, Batch 50/97, Loss: 0.6618
Epoch 1/10, Batch 60/97, Loss: 0.5906
Epoch 1/10, Batch 70/97, Loss: 0.4763
Epoch 1/10, Batch 80/97, Loss: 0.4910
Epoch 1/10, Batch 90/97, Loss: 0.5504
Epoch 1/10, Train Loss: 0.7777, Valid Loss: 0.4405
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4603
Epoch 2/10, Batch 20/97, Loss: 0.4807
Epoch 2/10, Batch 30/97, Loss: 0.4294
Epoch 2/10, Batch 40/97, Loss: 0.5127
Epoch 2/10, Batch 50/97, Loss: 0.5853
Epoch 2/10, Batch 60/97, Loss: 0.4103
Epoch 2/10, Batch 70/97, Loss: 0.3317
Epoch 2/10, Batch 80/97, Loss: 0.2953
Epoch 2/10, Batch 90/97, Loss: 0.4156
Epoch 2/10, Train Loss: 0.3996, Valid Loss: 0.3332
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4566
Epoch 3/10, Batch 20/97, Loss: 0.3004
Epoch 3/10, Batch 30/97, Loss: 0.2198
Epoch 3/10, Batch 40/97, Loss: 0.4578
Epoch 3/10, Batch 50/97, Loss: 0.2790
Epoch 3/10, Batch 60/97, Loss: 0.2390
Epoch 3/10, Batch 70/97, Loss: 0.1954
Epoch 3/10, Batch 80/97, Loss: 0.2761
Epoch 3/10, Batch 90/97, Loss: 0.2229
Epoch 3/10, Train Loss: 0.3345, Valid Loss: 0.2915
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2037
Epoch 4/10, Batch 20/97, Loss: 0.2680
Epoch 4/10, Batch 30/97, Loss: 0.2795
Epoch 4/10, Batch 40/97, Loss: 0.2393
Epoch 4/10, Batch 50/97, Loss: 0.1297
Epoch 4/10, Batch 60/97, Loss: 0.2467
Epoch 4/10, Batch 70/97, Loss: 0.1826
Epoch 4/10, Batch 80/97, Loss: 0.4356
Epoch 4/10, Batch 90/97, Loss: 0.2915
Epoch 4/10, Train Loss: 0.2979, Valid Loss: 0.2753
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1450
Epoch 5/10, Batch 20/97, Loss: 0.1890
Epoch 5/10, Batch 30/97, Loss: 0.2310
Epoch 5/10, Batch 40/97, Loss: 0.1756
Epoch 5/10, Batch 50/97, Loss: 0.3768
Epoch 5/10, Batch 60/97, Loss: 0.3703
Epoch 5/10, Batch 70/97, Loss: 0.3462
Epoch 5/10, Batch 80/97, Loss: 0.2864
Epoch 5/10, Batch 90/97, Loss: 0.4022
Epoch 5/10, Train Loss: 0.2676, Valid Loss: 0.2742
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3215
Epoch 6/10, Batch 20/97, Loss: 0.2192
Epoch 6/10, Batch 30/97, Loss: 0.2221
Epoch 6/10, Batch 40/97, Loss: 0.2747
Epoch 6/10, Batch 50/97, Loss: 0.1621
Epoch 6/10, Batch 60/97, Loss: 0.1411
Epoch 6/10, Batch 70/97, Loss: 0.3302
Epoch 6/10, Batch 80/97, Loss: 0.1720
Epoch 6/10, Batch 90/97, Loss: 0.3072
Epoch 6/10, Train Loss: 0.2502, Valid Loss: 0.2535
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3417
Epoch 7/10, Batch 20/97, Loss: 0.1528
Epoch 7/10, Batch 30/97, Loss: 0.1720
Epoch 7/10, Batch 40/97, Loss: 0.1427
Epoch 7/10, Batch 50/97, Loss: 0.2228
Epoch 7/10, Batch 60/97, Loss: 0.3326
Epoch 7/10, Batch 70/97, Loss: 0.1887
Epoch 7/10, Batch 80/97, Loss: 0.2030
Epoch 7/10, Batch 90/97, Loss: 0.2516
Epoch 7/10, Train Loss: 0.2440, Valid Loss: 0.2464
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1125
Epoch 8/10, Batch 20/97, Loss: 0.1611
Epoch 8/10, Batch 30/97, Loss: 0.1425
Epoch 8/10, Batch 40/97, Loss: 0.2009
Epoch 8/10, Batch 50/97, Loss: 0.3170
Epoch 8/10, Batch 60/97, Loss: 0.1867
Epoch 8/10, Batch 70/97, Loss: 0.2100
Epoch 8/10, Batch 80/97, Loss: 0.1038
Epoch 8/10, Batch 90/97, Loss: 0.1497
Epoch 8/10, Train Loss: 0.2240, Valid Loss: 0.2443
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0895
Epoch 9/10, Batch 20/97, Loss: 0.1469
Epoch 9/10, Batch 30/97, Loss: 0.2119
Epoch 9/10, Batch 40/97, Loss: 0.2648
Epoch 9/10, Batch 50/97, Loss: 0.2972
Epoch 9/10, Batch 60/97, Loss: 0.1919
Epoch 9/10, Batch 70/97, Loss: 0.2118
Epoch 9/10, Batch 80/97, Loss: 0.1864
Epoch 9/10, Batch 90/97, Loss: 0.1988
Epoch 9/10, Train Loss: 0.2130, Valid Loss: 0.2430
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2560
Epoch 10/10, Batch 20/97, Loss: 0.1869
Epoch 10/10, Batch 30/97, Loss: 0.2991
Epoch 10/10, Batch 40/97, Loss: 0.3133
Epoch 10/10, Batch 50/97, Loss: 0.2248
Epoch 10/10, Batch 60/97, Loss: 0.0995
Epoch 10/10, Batch 70/97, Loss: 0.2390
Epoch 10/10, Batch 80/97, Loss: 0.2206
Epoch 10/10, Batch 90/97, Loss: 0.1866
Epoch 10/10, Train Loss: 0.2143, Valid Loss: 0.2276
Model saved!
Accuracy: 0.9159
Precision: 0.9142
Recall: 0.9159
F1-score: 0.9144
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4277
Epoch 1/10, Batch 20/97, Loss: 1.0092
Epoch 1/10, Batch 30/97, Loss: 0.8834
Epoch 1/10, Batch 40/97, Loss: 0.8165
Epoch 1/10, Batch 50/97, Loss: 0.6100
Epoch 1/10, Batch 60/97, Loss: 0.6502
Epoch 1/10, Batch 70/97, Loss: 0.4511
Epoch 1/10, Batch 80/97, Loss: 0.4224
Epoch 1/10, Batch 90/97, Loss: 0.4803
Epoch 1/10, Train Loss: 0.7797, Valid Loss: 0.4404
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4283
Epoch 2/10, Batch 20/97, Loss: 0.4098
Epoch 2/10, Batch 30/97, Loss: 0.4772
Epoch 2/10, Batch 40/97, Loss: 0.6069
Epoch 2/10, Batch 50/97, Loss: 0.5404
Epoch 2/10, Batch 60/97, Loss: 0.3457
Epoch 2/10, Batch 70/97, Loss: 0.3116
Epoch 2/10, Batch 80/97, Loss: 0.2978
Epoch 2/10, Batch 90/97, Loss: 0.3390
Epoch 2/10, Train Loss: 0.4056, Valid Loss: 0.3445
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3812
Epoch 3/10, Batch 20/97, Loss: 0.2366
Epoch 3/10, Batch 30/97, Loss: 0.3051
Epoch 3/10, Batch 40/97, Loss: 0.4135
Epoch 3/10, Batch 50/97, Loss: 0.2230
Epoch 3/10, Batch 60/97, Loss: 0.2294
Epoch 3/10, Batch 70/97, Loss: 0.2778
Epoch 3/10, Batch 80/97, Loss: 0.2183
Epoch 3/10, Batch 90/97, Loss: 0.2493
Epoch 3/10, Train Loss: 0.3286, Valid Loss: 0.2942
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2755
Epoch 4/10, Batch 20/97, Loss: 0.2079
Epoch 4/10, Batch 30/97, Loss: 0.3673
Epoch 4/10, Batch 40/97, Loss: 0.2055
Epoch 4/10, Batch 50/97, Loss: 0.1841
Epoch 4/10, Batch 60/97, Loss: 0.2542
Epoch 4/10, Batch 70/97, Loss: 0.2297
Epoch 4/10, Batch 80/97, Loss: 0.1863
Epoch 4/10, Batch 90/97, Loss: 0.2673
Epoch 4/10, Train Loss: 0.2901, Valid Loss: 0.2687
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2243
Epoch 5/10, Batch 20/97, Loss: 0.1796
Epoch 5/10, Batch 30/97, Loss: 0.1824
Epoch 5/10, Batch 40/97, Loss: 0.1555
Epoch 5/10, Batch 50/97, Loss: 0.2155
Epoch 5/10, Batch 60/97, Loss: 0.2154
Epoch 5/10, Batch 70/97, Loss: 0.1424
Epoch 5/10, Batch 80/97, Loss: 0.3603
Epoch 5/10, Batch 90/97, Loss: 0.4083
Epoch 5/10, Train Loss: 0.2605, Valid Loss: 0.2597
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2825
Epoch 6/10, Batch 20/97, Loss: 0.2426
Epoch 6/10, Batch 30/97, Loss: 0.2252
Epoch 6/10, Batch 40/97, Loss: 0.2810
Epoch 6/10, Batch 50/97, Loss: 0.1459
Epoch 6/10, Batch 60/97, Loss: 0.1826
Epoch 6/10, Batch 70/97, Loss: 0.2331
Epoch 6/10, Batch 80/97, Loss: 0.1702
Epoch 6/10, Batch 90/97, Loss: 0.1842
Epoch 6/10, Train Loss: 0.2438, Valid Loss: 0.2553
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3108
Epoch 7/10, Batch 20/97, Loss: 0.1589
Epoch 7/10, Batch 30/97, Loss: 0.1304
Epoch 7/10, Batch 40/97, Loss: 0.1698
Epoch 7/10, Batch 50/97, Loss: 0.1860
Epoch 7/10, Batch 60/97, Loss: 0.3267
Epoch 7/10, Batch 70/97, Loss: 0.2778
Epoch 7/10, Batch 80/97, Loss: 0.2347
Epoch 7/10, Batch 90/97, Loss: 0.2038
Epoch 7/10, Train Loss: 0.2465, Valid Loss: 0.2356
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1915
Epoch 8/10, Batch 20/97, Loss: 0.1423
Epoch 8/10, Batch 30/97, Loss: 0.2251
Epoch 8/10, Batch 40/97, Loss: 0.0937
Epoch 8/10, Batch 50/97, Loss: 0.2645
Epoch 8/10, Batch 60/97, Loss: 0.1623
Epoch 8/10, Batch 70/97, Loss: 0.3184
Epoch 8/10, Batch 80/97, Loss: 0.1254
Epoch 8/10, Batch 90/97, Loss: 0.2439
Epoch 8/10, Train Loss: 0.2226, Valid Loss: 0.2471
Epoch 9/10, Batch 10/97, Loss: 0.1741
Epoch 9/10, Batch 20/97, Loss: 0.0514
Epoch 9/10, Batch 30/97, Loss: 0.1542
Epoch 9/10, Batch 40/97, Loss: 0.0888
Epoch 9/10, Batch 50/97, Loss: 0.2492
Epoch 9/10, Batch 60/97, Loss: 0.1523
Epoch 9/10, Batch 70/97, Loss: 0.2082
Epoch 9/10, Batch 80/97, Loss: 0.1813
Epoch 9/10, Batch 90/97, Loss: 0.2484
Epoch 9/10, Train Loss: 0.2018, Valid Loss: 0.2362
Epoch 10/10, Batch 10/97, Loss: 0.1804
Epoch 10/10, Batch 20/97, Loss: 0.1686
Epoch 10/10, Batch 30/97, Loss: 0.1500
Epoch 10/10, Batch 40/97, Loss: 0.2708
Epoch 10/10, Batch 50/97, Loss: 0.2421
Epoch 10/10, Batch 60/97, Loss: 0.0971
Epoch 10/10, Batch 70/97, Loss: 0.0917
Epoch 10/10, Batch 80/97, Loss: 0.0936
Epoch 10/10, Batch 90/97, Loss: 0.1286
Epoch 10/10, Train Loss: 0.2053, Valid Loss: 0.2305
Model saved!
Accuracy: 0.9241
Precision: 0.9224
Recall: 0.9241
F1-score: 0.9229
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4819
Epoch 1/10, Batch 20/97, Loss: 1.0283
Epoch 1/10, Batch 30/97, Loss: 0.9215
Epoch 1/10, Batch 40/97, Loss: 0.7077
Epoch 1/10, Batch 50/97, Loss: 0.6052
Epoch 1/10, Batch 60/97, Loss: 0.6291
Epoch 1/10, Batch 70/97, Loss: 0.5059
Epoch 1/10, Batch 80/97, Loss: 0.5497
Epoch 1/10, Batch 90/97, Loss: 0.4972
Epoch 1/10, Train Loss: 0.7718, Valid Loss: 0.4270
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4550
Epoch 2/10, Batch 20/97, Loss: 0.5478
Epoch 2/10, Batch 30/97, Loss: 0.4466
Epoch 2/10, Batch 40/97, Loss: 0.5519
Epoch 2/10, Batch 50/97, Loss: 0.6144
Epoch 2/10, Batch 60/97, Loss: 0.3380
Epoch 2/10, Batch 70/97, Loss: 0.2914
Epoch 2/10, Batch 80/97, Loss: 0.3335
Epoch 2/10, Batch 90/97, Loss: 0.2760
Epoch 2/10, Train Loss: 0.3967, Valid Loss: 0.3238
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3925
Epoch 3/10, Batch 20/97, Loss: 0.3272
Epoch 3/10, Batch 30/97, Loss: 0.2389
Epoch 3/10, Batch 40/97, Loss: 0.2967
Epoch 3/10, Batch 50/97, Loss: 0.3204
Epoch 3/10, Batch 60/97, Loss: 0.2895
Epoch 3/10, Batch 70/97, Loss: 0.1751
Epoch 3/10, Batch 80/97, Loss: 0.4078
Epoch 3/10, Batch 90/97, Loss: 0.2068
Epoch 3/10, Train Loss: 0.3207, Valid Loss: 0.2840
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3988
Epoch 4/10, Batch 20/97, Loss: 0.2470
Epoch 4/10, Batch 30/97, Loss: 0.2645
Epoch 4/10, Batch 40/97, Loss: 0.2365
Epoch 4/10, Batch 50/97, Loss: 0.1954
Epoch 4/10, Batch 60/97, Loss: 0.1255
Epoch 4/10, Batch 70/97, Loss: 0.1539
Epoch 4/10, Batch 80/97, Loss: 0.2751
Epoch 4/10, Batch 90/97, Loss: 0.2082
Epoch 4/10, Train Loss: 0.2842, Valid Loss: 0.2712
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2051
Epoch 5/10, Batch 20/97, Loss: 0.2799
Epoch 5/10, Batch 30/97, Loss: 0.1332
Epoch 5/10, Batch 40/97, Loss: 0.1754
Epoch 5/10, Batch 50/97, Loss: 0.3623
Epoch 5/10, Batch 60/97, Loss: 0.2071
Epoch 5/10, Batch 70/97, Loss: 0.2385
Epoch 5/10, Batch 80/97, Loss: 0.1740
Epoch 5/10, Batch 90/97, Loss: 0.5122
Epoch 5/10, Train Loss: 0.2655, Valid Loss: 0.2584
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2454
Epoch 6/10, Batch 20/97, Loss: 0.2700
Epoch 6/10, Batch 30/97, Loss: 0.1056
Epoch 6/10, Batch 40/97, Loss: 0.3810
Epoch 6/10, Batch 50/97, Loss: 0.2889
Epoch 6/10, Batch 60/97, Loss: 0.2312
Epoch 6/10, Batch 70/97, Loss: 0.2975
Epoch 6/10, Batch 80/97, Loss: 0.1811
Epoch 6/10, Batch 90/97, Loss: 0.1846
Epoch 6/10, Train Loss: 0.2409, Valid Loss: 0.2484
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3285
Epoch 7/10, Batch 20/97, Loss: 0.1553
Epoch 7/10, Batch 30/97, Loss: 0.2424
Epoch 7/10, Batch 40/97, Loss: 0.1892
Epoch 7/10, Batch 50/97, Loss: 0.2973
Epoch 7/10, Batch 60/97, Loss: 0.3487
Epoch 7/10, Batch 70/97, Loss: 0.1400
Epoch 7/10, Batch 80/97, Loss: 0.2051
Epoch 7/10, Batch 90/97, Loss: 0.2223
Epoch 7/10, Train Loss: 0.2433, Valid Loss: 0.2385
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.3580
Epoch 8/10, Batch 20/97, Loss: 0.1697
Epoch 8/10, Batch 30/97, Loss: 0.2536
Epoch 8/10, Batch 40/97, Loss: 0.1976
Epoch 8/10, Batch 50/97, Loss: 0.2070
Epoch 8/10, Batch 60/97, Loss: 0.1274
Epoch 8/10, Batch 70/97, Loss: 0.1823
Epoch 8/10, Batch 80/97, Loss: 0.1050
Epoch 8/10, Batch 90/97, Loss: 0.2524
Epoch 8/10, Train Loss: 0.2122, Valid Loss: 0.2467
Epoch 9/10, Batch 10/97, Loss: 0.2690
Epoch 9/10, Batch 20/97, Loss: 0.1471
Epoch 9/10, Batch 30/97, Loss: 0.3342
Epoch 9/10, Batch 40/97, Loss: 0.1183
Epoch 9/10, Batch 50/97, Loss: 0.2162
Epoch 9/10, Batch 60/97, Loss: 0.3665
Epoch 9/10, Batch 70/97, Loss: 0.2215
Epoch 9/10, Batch 80/97, Loss: 0.1704
Epoch 9/10, Batch 90/97, Loss: 0.2240
Epoch 9/10, Train Loss: 0.2109, Valid Loss: 0.2404
Epoch 10/10, Batch 10/97, Loss: 0.2058
Epoch 10/10, Batch 20/97, Loss: 0.1303
Epoch 10/10, Batch 30/97, Loss: 0.1622
Epoch 10/10, Batch 40/97, Loss: 0.2402
Epoch 10/10, Batch 50/97, Loss: 0.4852
Epoch 10/10, Batch 60/97, Loss: 0.1358
Epoch 10/10, Batch 70/97, Loss: 0.0946
Epoch 10/10, Batch 80/97, Loss: 0.1861
Epoch 10/10, Batch 90/97, Loss: 0.0849
Epoch 10/10, Train Loss: 0.1995, Valid Loss: 0.2341
Model saved!
Accuracy: 0.9077
Precision: 0.9048
Recall: 0.9077
F1-score: 0.9041
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4699
Epoch 1/10, Batch 20/97, Loss: 1.0097
Epoch 1/10, Batch 30/97, Loss: 0.8140
Epoch 1/10, Batch 40/97, Loss: 0.6754
Epoch 1/10, Batch 50/97, Loss: 0.6254
Epoch 1/10, Batch 60/97, Loss: 0.6253
Epoch 1/10, Batch 70/97, Loss: 0.5038
Epoch 1/10, Batch 80/97, Loss: 0.5806
Epoch 1/10, Batch 90/97, Loss: 0.5417
Epoch 1/10, Train Loss: 0.7861, Valid Loss: 0.4417
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4449
Epoch 2/10, Batch 20/97, Loss: 0.4794
Epoch 2/10, Batch 30/97, Loss: 0.4825
Epoch 2/10, Batch 40/97, Loss: 0.4615
Epoch 2/10, Batch 50/97, Loss: 0.7537
Epoch 2/10, Batch 60/97, Loss: 0.3974
Epoch 2/10, Batch 70/97, Loss: 0.3559
Epoch 2/10, Batch 80/97, Loss: 0.1814
Epoch 2/10, Batch 90/97, Loss: 0.4280
Epoch 2/10, Train Loss: 0.4098, Valid Loss: 0.3437
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2324
Epoch 3/10, Batch 20/97, Loss: 0.2269
Epoch 3/10, Batch 30/97, Loss: 0.4731
Epoch 3/10, Batch 40/97, Loss: 0.3424
Epoch 3/10, Batch 50/97, Loss: 0.3885
Epoch 3/10, Batch 60/97, Loss: 0.2569
Epoch 3/10, Batch 70/97, Loss: 0.3254
Epoch 3/10, Batch 80/97, Loss: 0.3713
Epoch 3/10, Batch 90/97, Loss: 0.3196
Epoch 3/10, Train Loss: 0.3311, Valid Loss: 0.2953
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1843
Epoch 4/10, Batch 20/97, Loss: 0.2292
Epoch 4/10, Batch 30/97, Loss: 0.3474
Epoch 4/10, Batch 40/97, Loss: 0.4697
Epoch 4/10, Batch 50/97, Loss: 0.3003
Epoch 4/10, Batch 60/97, Loss: 0.1336
Epoch 4/10, Batch 70/97, Loss: 0.1681
Epoch 4/10, Batch 80/97, Loss: 0.2237
Epoch 4/10, Batch 90/97, Loss: 0.3269
Epoch 4/10, Train Loss: 0.3015, Valid Loss: 0.2808
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2301
Epoch 5/10, Batch 20/97, Loss: 0.3123
Epoch 5/10, Batch 30/97, Loss: 0.2694
Epoch 5/10, Batch 40/97, Loss: 0.1670
Epoch 5/10, Batch 50/97, Loss: 0.2138
Epoch 5/10, Batch 60/97, Loss: 0.2595
Epoch 5/10, Batch 70/97, Loss: 0.1734
Epoch 5/10, Batch 80/97, Loss: 0.2872
Epoch 5/10, Batch 90/97, Loss: 0.3916
Epoch 5/10, Train Loss: 0.2682, Valid Loss: 0.2655
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3824
Epoch 6/10, Batch 20/97, Loss: 0.3611
Epoch 6/10, Batch 30/97, Loss: 0.2400
Epoch 6/10, Batch 40/97, Loss: 0.3650
Epoch 6/10, Batch 50/97, Loss: 0.2284
Epoch 6/10, Batch 60/97, Loss: 0.1518
Epoch 6/10, Batch 70/97, Loss: 0.1669
Epoch 6/10, Batch 80/97, Loss: 0.2521
Epoch 6/10, Batch 90/97, Loss: 0.2096
Epoch 6/10, Train Loss: 0.2548, Valid Loss: 0.2563
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3061
Epoch 7/10, Batch 20/97, Loss: 0.1970
Epoch 7/10, Batch 30/97, Loss: 0.1589
Epoch 7/10, Batch 40/97, Loss: 0.2448
Epoch 7/10, Batch 50/97, Loss: 0.1829
Epoch 7/10, Batch 60/97, Loss: 0.2325
Epoch 7/10, Batch 70/97, Loss: 0.2071
Epoch 7/10, Batch 80/97, Loss: 0.2109
Epoch 7/10, Batch 90/97, Loss: 0.2165
Epoch 7/10, Train Loss: 0.2477, Valid Loss: 0.2467
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2200
Epoch 8/10, Batch 20/97, Loss: 0.1903
Epoch 8/10, Batch 30/97, Loss: 0.1034
Epoch 8/10, Batch 40/97, Loss: 0.1197
Epoch 8/10, Batch 50/97, Loss: 0.2577
Epoch 8/10, Batch 60/97, Loss: 0.1310
Epoch 8/10, Batch 70/97, Loss: 0.1991
Epoch 8/10, Batch 80/97, Loss: 0.0917
Epoch 8/10, Batch 90/97, Loss: 0.2219
Epoch 8/10, Train Loss: 0.2257, Valid Loss: 0.2481
Epoch 9/10, Batch 10/97, Loss: 0.0662
Epoch 9/10, Batch 20/97, Loss: 0.1122
Epoch 9/10, Batch 30/97, Loss: 0.1767
Epoch 9/10, Batch 40/97, Loss: 0.1961
Epoch 9/10, Batch 50/97, Loss: 0.1989
Epoch 9/10, Batch 60/97, Loss: 0.1926
Epoch 9/10, Batch 70/97, Loss: 0.1472
Epoch 9/10, Batch 80/97, Loss: 0.1502
Epoch 9/10, Batch 90/97, Loss: 0.1637
Epoch 9/10, Train Loss: 0.2131, Valid Loss: 0.2449
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2905
Epoch 10/10, Batch 20/97, Loss: 0.1586
Epoch 10/10, Batch 30/97, Loss: 0.1723
Epoch 10/10, Batch 40/97, Loss: 0.3318
Epoch 10/10, Batch 50/97, Loss: 0.3013
Epoch 10/10, Batch 60/97, Loss: 0.2006
Epoch 10/10, Batch 70/97, Loss: 0.2129
Epoch 10/10, Batch 80/97, Loss: 0.2258
Epoch 10/10, Batch 90/97, Loss: 0.1810
Epoch 10/10, Train Loss: 0.1983, Valid Loss: 0.2331
Model saved!
Accuracy: 0.9217
Precision: 0.9187
Recall: 0.9217
F1-score: 0.9195
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4815
Epoch 1/10, Batch 20/97, Loss: 0.9941
Epoch 1/10, Batch 30/97, Loss: 0.8526
Epoch 1/10, Batch 40/97, Loss: 0.7284
Epoch 1/10, Batch 50/97, Loss: 0.6307
Epoch 1/10, Batch 60/97, Loss: 0.6551
Epoch 1/10, Batch 70/97, Loss: 0.4287
Epoch 1/10, Batch 80/97, Loss: 0.4913
Epoch 1/10, Batch 90/97, Loss: 0.4745
Epoch 1/10, Train Loss: 0.7801, Valid Loss: 0.4245
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3712
Epoch 2/10, Batch 20/97, Loss: 0.4428
Epoch 2/10, Batch 30/97, Loss: 0.4489
Epoch 2/10, Batch 40/97, Loss: 0.6392
Epoch 2/10, Batch 50/97, Loss: 0.5354
Epoch 2/10, Batch 60/97, Loss: 0.4754
Epoch 2/10, Batch 70/97, Loss: 0.3464
Epoch 2/10, Batch 80/97, Loss: 0.2957
Epoch 2/10, Batch 90/97, Loss: 0.2743
Epoch 2/10, Train Loss: 0.3979, Valid Loss: 0.3214
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2721
Epoch 3/10, Batch 20/97, Loss: 0.4298
Epoch 3/10, Batch 30/97, Loss: 0.3361
Epoch 3/10, Batch 40/97, Loss: 0.3141
Epoch 3/10, Batch 50/97, Loss: 0.3566
Epoch 3/10, Batch 60/97, Loss: 0.2829
Epoch 3/10, Batch 70/97, Loss: 0.2363
Epoch 3/10, Batch 80/97, Loss: 0.3716
Epoch 3/10, Batch 90/97, Loss: 0.2666
Epoch 3/10, Train Loss: 0.3250, Valid Loss: 0.2792
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2572
Epoch 4/10, Batch 20/97, Loss: 0.3642
Epoch 4/10, Batch 30/97, Loss: 0.2715
Epoch 4/10, Batch 40/97, Loss: 0.2231
Epoch 4/10, Batch 50/97, Loss: 0.2672
Epoch 4/10, Batch 60/97, Loss: 0.1606
Epoch 4/10, Batch 70/97, Loss: 0.1682
Epoch 4/10, Batch 80/97, Loss: 0.2838
Epoch 4/10, Batch 90/97, Loss: 0.1970
Epoch 4/10, Train Loss: 0.2905, Valid Loss: 0.2584
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2161
Epoch 5/10, Batch 20/97, Loss: 0.1526
Epoch 5/10, Batch 30/97, Loss: 0.1079
Epoch 5/10, Batch 40/97, Loss: 0.1382
Epoch 5/10, Batch 50/97, Loss: 0.2048
Epoch 5/10, Batch 60/97, Loss: 0.1815
Epoch 5/10, Batch 70/97, Loss: 0.2712
Epoch 5/10, Batch 80/97, Loss: 0.3073
Epoch 5/10, Batch 90/97, Loss: 0.3249
Epoch 5/10, Train Loss: 0.2568, Valid Loss: 0.2349
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1947
Epoch 6/10, Batch 20/97, Loss: 0.2392
Epoch 6/10, Batch 30/97, Loss: 0.1682
Epoch 6/10, Batch 40/97, Loss: 0.2122
Epoch 6/10, Batch 50/97, Loss: 0.2085
Epoch 6/10, Batch 60/97, Loss: 0.1985
Epoch 6/10, Batch 70/97, Loss: 0.2144
Epoch 6/10, Batch 80/97, Loss: 0.1544
Epoch 6/10, Batch 90/97, Loss: 0.2814
Epoch 6/10, Train Loss: 0.2426, Valid Loss: 0.2336
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2887
Epoch 7/10, Batch 20/97, Loss: 0.1922
Epoch 7/10, Batch 30/97, Loss: 0.2016
Epoch 7/10, Batch 40/97, Loss: 0.1983
Epoch 7/10, Batch 50/97, Loss: 0.1334
Epoch 7/10, Batch 60/97, Loss: 0.3696
Epoch 7/10, Batch 70/97, Loss: 0.1857
Epoch 7/10, Batch 80/97, Loss: 0.1220
Epoch 7/10, Batch 90/97, Loss: 0.2813
Epoch 7/10, Train Loss: 0.2424, Valid Loss: 0.2205
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1250
Epoch 8/10, Batch 20/97, Loss: 0.1369
Epoch 8/10, Batch 30/97, Loss: 0.2084
Epoch 8/10, Batch 40/97, Loss: 0.1608
Epoch 8/10, Batch 50/97, Loss: 0.2646
Epoch 8/10, Batch 60/97, Loss: 0.1114
Epoch 8/10, Batch 70/97, Loss: 0.3028
Epoch 8/10, Batch 80/97, Loss: 0.0751
Epoch 8/10, Batch 90/97, Loss: 0.1277
Epoch 8/10, Train Loss: 0.2190, Valid Loss: 0.2200
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1606
Epoch 9/10, Batch 20/97, Loss: 0.2133
Epoch 9/10, Batch 30/97, Loss: 0.3293
Epoch 9/10, Batch 40/97, Loss: 0.1338
Epoch 9/10, Batch 50/97, Loss: 0.1699
Epoch 9/10, Batch 60/97, Loss: 0.2515
Epoch 9/10, Batch 70/97, Loss: 0.2990
Epoch 9/10, Batch 80/97, Loss: 0.1772
Epoch 9/10, Batch 90/97, Loss: 0.1301
Epoch 9/10, Train Loss: 0.2134, Valid Loss: 0.2188
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2410
Epoch 10/10, Batch 20/97, Loss: 0.1964
Epoch 10/10, Batch 30/97, Loss: 0.1662
Epoch 10/10, Batch 40/97, Loss: 0.2044
Epoch 10/10, Batch 50/97, Loss: 0.3307
Epoch 10/10, Batch 60/97, Loss: 0.1530
Epoch 10/10, Batch 70/97, Loss: 0.1546
Epoch 10/10, Batch 80/97, Loss: 0.1813
Epoch 10/10, Batch 90/97, Loss: 0.1641
Epoch 10/10, Train Loss: 0.2014, Valid Loss: 0.2053
Model saved!
Accuracy: 0.9206
Precision: 0.9184
Recall: 0.9206
F1-score: 0.9190
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4754
Epoch 1/10, Batch 20/97, Loss: 1.0187
Epoch 1/10, Batch 30/97, Loss: 0.8381
Epoch 1/10, Batch 40/97, Loss: 0.7972
Epoch 1/10, Batch 50/97, Loss: 0.6039
Epoch 1/10, Batch 60/97, Loss: 0.5960
Epoch 1/10, Batch 70/97, Loss: 0.5101
Epoch 1/10, Batch 80/97, Loss: 0.5363
Epoch 1/10, Batch 90/97, Loss: 0.5190
Epoch 1/10, Train Loss: 0.7745, Valid Loss: 0.4252
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5295
Epoch 2/10, Batch 20/97, Loss: 0.4999
Epoch 2/10, Batch 30/97, Loss: 0.4237
Epoch 2/10, Batch 40/97, Loss: 0.4688
Epoch 2/10, Batch 50/97, Loss: 0.4907
Epoch 2/10, Batch 60/97, Loss: 0.3295
Epoch 2/10, Batch 70/97, Loss: 0.2737
Epoch 2/10, Batch 80/97, Loss: 0.3695
Epoch 2/10, Batch 90/97, Loss: 0.3184
Epoch 2/10, Train Loss: 0.3998, Valid Loss: 0.3192
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3341
Epoch 3/10, Batch 20/97, Loss: 0.2821
Epoch 3/10, Batch 30/97, Loss: 0.2188
Epoch 3/10, Batch 40/97, Loss: 0.2420
Epoch 3/10, Batch 50/97, Loss: 0.2679
Epoch 3/10, Batch 60/97, Loss: 0.2096
Epoch 3/10, Batch 70/97, Loss: 0.2067
Epoch 3/10, Batch 80/97, Loss: 0.2225
Epoch 3/10, Batch 90/97, Loss: 0.2960
Epoch 3/10, Train Loss: 0.3301, Valid Loss: 0.2805
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2240
Epoch 4/10, Batch 20/97, Loss: 0.2054
Epoch 4/10, Batch 30/97, Loss: 0.3535
Epoch 4/10, Batch 40/97, Loss: 0.3082
Epoch 4/10, Batch 50/97, Loss: 0.2061
Epoch 4/10, Batch 60/97, Loss: 0.2020
Epoch 4/10, Batch 70/97, Loss: 0.1314
Epoch 4/10, Batch 80/97, Loss: 0.2191
Epoch 4/10, Batch 90/97, Loss: 0.2591
Epoch 4/10, Train Loss: 0.2843, Valid Loss: 0.2658
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2317
Epoch 5/10, Batch 20/97, Loss: 0.1919
Epoch 5/10, Batch 30/97, Loss: 0.1569
Epoch 5/10, Batch 40/97, Loss: 0.0753
Epoch 5/10, Batch 50/97, Loss: 0.3054
Epoch 5/10, Batch 60/97, Loss: 0.1480
Epoch 5/10, Batch 70/97, Loss: 0.1589
Epoch 5/10, Batch 80/97, Loss: 0.2368
Epoch 5/10, Batch 90/97, Loss: 0.3464
Epoch 5/10, Train Loss: 0.2573, Valid Loss: 0.2509
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2154
Epoch 6/10, Batch 20/97, Loss: 0.1839
Epoch 6/10, Batch 30/97, Loss: 0.1520
Epoch 6/10, Batch 40/97, Loss: 0.2877
Epoch 6/10, Batch 50/97, Loss: 0.2224
Epoch 6/10, Batch 60/97, Loss: 0.1821
Epoch 6/10, Batch 70/97, Loss: 0.1557
Epoch 6/10, Batch 80/97, Loss: 0.2381
Epoch 6/10, Batch 90/97, Loss: 0.1651
Epoch 6/10, Train Loss: 0.2379, Valid Loss: 0.2469
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3295
Epoch 7/10, Batch 20/97, Loss: 0.1293
Epoch 7/10, Batch 30/97, Loss: 0.1463
Epoch 7/10, Batch 40/97, Loss: 0.2194
Epoch 7/10, Batch 50/97, Loss: 0.1611
Epoch 7/10, Batch 60/97, Loss: 0.3718
Epoch 7/10, Batch 70/97, Loss: 0.1608
Epoch 7/10, Batch 80/97, Loss: 0.2432
Epoch 7/10, Batch 90/97, Loss: 0.2394
Epoch 7/10, Train Loss: 0.2458, Valid Loss: 0.2391
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1756
Epoch 8/10, Batch 20/97, Loss: 0.1307
Epoch 8/10, Batch 30/97, Loss: 0.0950
Epoch 8/10, Batch 40/97, Loss: 0.2284
Epoch 8/10, Batch 50/97, Loss: 0.3417
Epoch 8/10, Batch 60/97, Loss: 0.1782
Epoch 8/10, Batch 70/97, Loss: 0.2601
Epoch 8/10, Batch 80/97, Loss: 0.1615
Epoch 8/10, Batch 90/97, Loss: 0.2589
Epoch 8/10, Train Loss: 0.2108, Valid Loss: 0.2318
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2166
Epoch 9/10, Batch 20/97, Loss: 0.1018
Epoch 9/10, Batch 30/97, Loss: 0.3235
Epoch 9/10, Batch 40/97, Loss: 0.1300
Epoch 9/10, Batch 50/97, Loss: 0.1981
Epoch 9/10, Batch 60/97, Loss: 0.2149
Epoch 9/10, Batch 70/97, Loss: 0.2807
Epoch 9/10, Batch 80/97, Loss: 0.1427
Epoch 9/10, Batch 90/97, Loss: 0.1495
Epoch 9/10, Train Loss: 0.2029, Valid Loss: 0.2329
Epoch 10/10, Batch 10/97, Loss: 0.2868
Epoch 10/10, Batch 20/97, Loss: 0.1865
Epoch 10/10, Batch 30/97, Loss: 0.2042
Epoch 10/10, Batch 40/97, Loss: 0.4804
Epoch 10/10, Batch 50/97, Loss: 0.2599
Epoch 10/10, Batch 60/97, Loss: 0.1580
Epoch 10/10, Batch 70/97, Loss: 0.1288
Epoch 10/10, Batch 80/97, Loss: 0.1864
Epoch 10/10, Batch 90/97, Loss: 0.0915
Epoch 10/10, Train Loss: 0.1918, Valid Loss: 0.2367
Accuracy: 0.9136
Precision: 0.9125
Recall: 0.9136
F1-score: 0.9113
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4598
Epoch 1/10, Batch 20/97, Loss: 0.9540
Epoch 1/10, Batch 30/97, Loss: 0.8219
Epoch 1/10, Batch 40/97, Loss: 0.7314
Epoch 1/10, Batch 50/97, Loss: 0.6332
Epoch 1/10, Batch 60/97, Loss: 0.6522
Epoch 1/10, Batch 70/97, Loss: 0.4932
Epoch 1/10, Batch 80/97, Loss: 0.5580
Epoch 1/10, Batch 90/97, Loss: 0.6839
Epoch 1/10, Train Loss: 0.7775, Valid Loss: 0.4303
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4009
Epoch 2/10, Batch 20/97, Loss: 0.4633
Epoch 2/10, Batch 30/97, Loss: 0.5064
Epoch 2/10, Batch 40/97, Loss: 0.4563
Epoch 2/10, Batch 50/97, Loss: 0.5129
Epoch 2/10, Batch 60/97, Loss: 0.3811
Epoch 2/10, Batch 70/97, Loss: 0.2262
Epoch 2/10, Batch 80/97, Loss: 0.2936
Epoch 2/10, Batch 90/97, Loss: 0.3846
Epoch 2/10, Train Loss: 0.4060, Valid Loss: 0.3146
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3761
Epoch 3/10, Batch 20/97, Loss: 0.3530
Epoch 3/10, Batch 30/97, Loss: 0.2062
Epoch 3/10, Batch 40/97, Loss: 0.1281
Epoch 3/10, Batch 50/97, Loss: 0.3675
Epoch 3/10, Batch 60/97, Loss: 0.3841
Epoch 3/10, Batch 70/97, Loss: 0.1659
Epoch 3/10, Batch 80/97, Loss: 0.2706
Epoch 3/10, Batch 90/97, Loss: 0.2562
Epoch 3/10, Train Loss: 0.3309, Valid Loss: 0.2776
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2714
Epoch 4/10, Batch 20/97, Loss: 0.2715
Epoch 4/10, Batch 30/97, Loss: 0.3693
Epoch 4/10, Batch 40/97, Loss: 0.3024
Epoch 4/10, Batch 50/97, Loss: 0.1428
Epoch 4/10, Batch 60/97, Loss: 0.1842
Epoch 4/10, Batch 70/97, Loss: 0.3108
Epoch 4/10, Batch 80/97, Loss: 0.1652
Epoch 4/10, Batch 90/97, Loss: 0.2569
Epoch 4/10, Train Loss: 0.2898, Valid Loss: 0.2516
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2767
Epoch 5/10, Batch 20/97, Loss: 0.1569
Epoch 5/10, Batch 30/97, Loss: 0.1482
Epoch 5/10, Batch 40/97, Loss: 0.1143
Epoch 5/10, Batch 50/97, Loss: 0.2039
Epoch 5/10, Batch 60/97, Loss: 0.2093
Epoch 5/10, Batch 70/97, Loss: 0.1233
Epoch 5/10, Batch 80/97, Loss: 0.2641
Epoch 5/10, Batch 90/97, Loss: 0.2985
Epoch 5/10, Train Loss: 0.2586, Valid Loss: 0.2362
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2984
Epoch 6/10, Batch 20/97, Loss: 0.3279
Epoch 6/10, Batch 30/97, Loss: 0.2736
Epoch 6/10, Batch 40/97, Loss: 0.2544
Epoch 6/10, Batch 50/97, Loss: 0.2300
Epoch 6/10, Batch 60/97, Loss: 0.2133
Epoch 6/10, Batch 70/97, Loss: 0.1797
Epoch 6/10, Batch 80/97, Loss: 0.2100
Epoch 6/10, Batch 90/97, Loss: 0.2414
Epoch 6/10, Train Loss: 0.2444, Valid Loss: 0.2266
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3222
Epoch 7/10, Batch 20/97, Loss: 0.1165
Epoch 7/10, Batch 30/97, Loss: 0.2156
Epoch 7/10, Batch 40/97, Loss: 0.1639
Epoch 7/10, Batch 50/97, Loss: 0.1942
Epoch 7/10, Batch 60/97, Loss: 0.2411
Epoch 7/10, Batch 70/97, Loss: 0.1941
Epoch 7/10, Batch 80/97, Loss: 0.1882
Epoch 7/10, Batch 90/97, Loss: 0.2672
Epoch 7/10, Train Loss: 0.2430, Valid Loss: 0.2105
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1753
Epoch 8/10, Batch 20/97, Loss: 0.2064
Epoch 8/10, Batch 30/97, Loss: 0.2053
Epoch 8/10, Batch 40/97, Loss: 0.1077
Epoch 8/10, Batch 50/97, Loss: 0.2363
Epoch 8/10, Batch 60/97, Loss: 0.1181
Epoch 8/10, Batch 70/97, Loss: 0.3510
Epoch 8/10, Batch 80/97, Loss: 0.3801
Epoch 8/10, Batch 90/97, Loss: 0.0967
Epoch 8/10, Train Loss: 0.2299, Valid Loss: 0.2130
Epoch 9/10, Batch 10/97, Loss: 0.1391
Epoch 9/10, Batch 20/97, Loss: 0.1092
Epoch 9/10, Batch 30/97, Loss: 0.2106
Epoch 9/10, Batch 40/97, Loss: 0.1302
Epoch 9/10, Batch 50/97, Loss: 0.2142
Epoch 9/10, Batch 60/97, Loss: 0.1512
Epoch 9/10, Batch 70/97, Loss: 0.2041
Epoch 9/10, Batch 80/97, Loss: 0.1421
Epoch 9/10, Batch 90/97, Loss: 0.2062
Epoch 9/10, Train Loss: 0.2070, Valid Loss: 0.2166
Epoch 10/10, Batch 10/97, Loss: 0.2079
Epoch 10/10, Batch 20/97, Loss: 0.1412
Epoch 10/10, Batch 30/97, Loss: 0.1858
Epoch 10/10, Batch 40/97, Loss: 0.2246
Epoch 10/10, Batch 50/97, Loss: 0.3943
Epoch 10/10, Batch 60/97, Loss: 0.1087
Epoch 10/10, Batch 70/97, Loss: 0.1953
Epoch 10/10, Batch 80/97, Loss: 0.1546
Epoch 10/10, Batch 90/97, Loss: 0.1573
Epoch 10/10, Train Loss: 0.1993, Valid Loss: 0.2042
Model saved!
Accuracy: 0.9124
Precision: 0.9100
Recall: 0.9124
F1-score: 0.9100
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5170
Epoch 1/10, Batch 20/97, Loss: 0.9836
Epoch 1/10, Batch 30/97, Loss: 0.9006
Epoch 1/10, Batch 40/97, Loss: 0.6140
Epoch 1/10, Batch 50/97, Loss: 0.6209
Epoch 1/10, Batch 60/97, Loss: 0.6121
Epoch 1/10, Batch 70/97, Loss: 0.4656
Epoch 1/10, Batch 80/97, Loss: 0.5599
Epoch 1/10, Batch 90/97, Loss: 0.6268
Epoch 1/10, Train Loss: 0.7720, Valid Loss: 0.4273
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.2300
Epoch 2/10, Batch 20/97, Loss: 0.4392
Epoch 2/10, Batch 30/97, Loss: 0.3350
Epoch 2/10, Batch 40/97, Loss: 0.5468
Epoch 2/10, Batch 50/97, Loss: 0.5939
Epoch 2/10, Batch 60/97, Loss: 0.3203
Epoch 2/10, Batch 70/97, Loss: 0.3565
Epoch 2/10, Batch 80/97, Loss: 0.4620
Epoch 2/10, Batch 90/97, Loss: 0.2673
Epoch 2/10, Train Loss: 0.3912, Valid Loss: 0.3318
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3677
Epoch 3/10, Batch 20/97, Loss: 0.3003
Epoch 3/10, Batch 30/97, Loss: 0.3401
Epoch 3/10, Batch 40/97, Loss: 0.4504
Epoch 3/10, Batch 50/97, Loss: 0.3200
Epoch 3/10, Batch 60/97, Loss: 0.3123
Epoch 3/10, Batch 70/97, Loss: 0.4754
Epoch 3/10, Batch 80/97, Loss: 0.2710
Epoch 3/10, Batch 90/97, Loss: 0.2341
Epoch 3/10, Train Loss: 0.3226, Valid Loss: 0.2826
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2855
Epoch 4/10, Batch 20/97, Loss: 0.2643
Epoch 4/10, Batch 30/97, Loss: 0.3637
Epoch 4/10, Batch 40/97, Loss: 0.2358
Epoch 4/10, Batch 50/97, Loss: 0.2212
Epoch 4/10, Batch 60/97, Loss: 0.1875
Epoch 4/10, Batch 70/97, Loss: 0.2071
Epoch 4/10, Batch 80/97, Loss: 0.2900
Epoch 4/10, Batch 90/97, Loss: 0.2310
Epoch 4/10, Train Loss: 0.2841, Valid Loss: 0.2578
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3032
Epoch 5/10, Batch 20/97, Loss: 0.2420
Epoch 5/10, Batch 30/97, Loss: 0.1709
Epoch 5/10, Batch 40/97, Loss: 0.1790
Epoch 5/10, Batch 50/97, Loss: 0.1585
Epoch 5/10, Batch 60/97, Loss: 0.4950
Epoch 5/10, Batch 70/97, Loss: 0.1340
Epoch 5/10, Batch 80/97, Loss: 0.2912
Epoch 5/10, Batch 90/97, Loss: 0.2954
Epoch 5/10, Train Loss: 0.2560, Valid Loss: 0.2414
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2048
Epoch 6/10, Batch 20/97, Loss: 0.2093
Epoch 6/10, Batch 30/97, Loss: 0.2970
Epoch 6/10, Batch 40/97, Loss: 0.2258
Epoch 6/10, Batch 50/97, Loss: 0.2442
Epoch 6/10, Batch 60/97, Loss: 0.2797
Epoch 6/10, Batch 70/97, Loss: 0.3052
Epoch 6/10, Batch 80/97, Loss: 0.2225
Epoch 6/10, Batch 90/97, Loss: 0.2567
Epoch 6/10, Train Loss: 0.2347, Valid Loss: 0.2288
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2337
Epoch 7/10, Batch 20/97, Loss: 0.1565
Epoch 7/10, Batch 30/97, Loss: 0.1571
Epoch 7/10, Batch 40/97, Loss: 0.2394
Epoch 7/10, Batch 50/97, Loss: 0.2243
Epoch 7/10, Batch 60/97, Loss: 0.3062
Epoch 7/10, Batch 70/97, Loss: 0.1833
Epoch 7/10, Batch 80/97, Loss: 0.2837
Epoch 7/10, Batch 90/97, Loss: 0.3611
Epoch 7/10, Train Loss: 0.2362, Valid Loss: 0.2180
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.3088
Epoch 8/10, Batch 20/97, Loss: 0.2528
Epoch 8/10, Batch 30/97, Loss: 0.1905
Epoch 8/10, Batch 40/97, Loss: 0.2232
Epoch 8/10, Batch 50/97, Loss: 0.3269
Epoch 8/10, Batch 60/97, Loss: 0.1082
Epoch 8/10, Batch 70/97, Loss: 0.2772
Epoch 8/10, Batch 80/97, Loss: 0.1220
Epoch 8/10, Batch 90/97, Loss: 0.2015
Epoch 8/10, Train Loss: 0.2180, Valid Loss: 0.2145
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1471
Epoch 9/10, Batch 20/97, Loss: 0.1250
Epoch 9/10, Batch 30/97, Loss: 0.2228
Epoch 9/10, Batch 40/97, Loss: 0.0722
Epoch 9/10, Batch 50/97, Loss: 0.3946
Epoch 9/10, Batch 60/97, Loss: 0.2511
Epoch 9/10, Batch 70/97, Loss: 0.1563
Epoch 9/10, Batch 80/97, Loss: 0.2605
Epoch 9/10, Batch 90/97, Loss: 0.1451
Epoch 9/10, Train Loss: 0.2018, Valid Loss: 0.2102
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2058
Epoch 10/10, Batch 20/97, Loss: 0.0896
Epoch 10/10, Batch 30/97, Loss: 0.1742
Epoch 10/10, Batch 40/97, Loss: 0.3154
Epoch 10/10, Batch 50/97, Loss: 0.2925
Epoch 10/10, Batch 60/97, Loss: 0.2379
Epoch 10/10, Batch 70/97, Loss: 0.1811
Epoch 10/10, Batch 80/97, Loss: 0.2096
Epoch 10/10, Batch 90/97, Loss: 0.1774
Epoch 10/10, Train Loss: 0.1995, Valid Loss: 0.2036
Model saved!
Accuracy: 0.9229
Precision: 0.9208
Recall: 0.9229
F1-score: 0.9211
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4849
Epoch 1/10, Batch 20/97, Loss: 1.0001
Epoch 1/10, Batch 30/97, Loss: 0.8959
Epoch 1/10, Batch 40/97, Loss: 0.7599
Epoch 1/10, Batch 50/97, Loss: 0.7108
Epoch 1/10, Batch 60/97, Loss: 0.4631
Epoch 1/10, Batch 70/97, Loss: 0.5105
Epoch 1/10, Batch 80/97, Loss: 0.4631
Epoch 1/10, Batch 90/97, Loss: 0.5084
Epoch 1/10, Train Loss: 0.7708, Valid Loss: 0.4445
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3741
Epoch 2/10, Batch 20/97, Loss: 0.5077
Epoch 2/10, Batch 30/97, Loss: 0.3841
Epoch 2/10, Batch 40/97, Loss: 0.3853
Epoch 2/10, Batch 50/97, Loss: 0.5721
Epoch 2/10, Batch 60/97, Loss: 0.2854
Epoch 2/10, Batch 70/97, Loss: 0.2512
Epoch 2/10, Batch 80/97, Loss: 0.3286
Epoch 2/10, Batch 90/97, Loss: 0.3669
Epoch 2/10, Train Loss: 0.3893, Valid Loss: 0.3477
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2437
Epoch 3/10, Batch 20/97, Loss: 0.2368
Epoch 3/10, Batch 30/97, Loss: 0.2479
Epoch 3/10, Batch 40/97, Loss: 0.3514
Epoch 3/10, Batch 50/97, Loss: 0.2952
Epoch 3/10, Batch 60/97, Loss: 0.3539
Epoch 3/10, Batch 70/97, Loss: 0.1795
Epoch 3/10, Batch 80/97, Loss: 0.5189
Epoch 3/10, Batch 90/97, Loss: 0.2395
Epoch 3/10, Train Loss: 0.3163, Valid Loss: 0.2976
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3089
Epoch 4/10, Batch 20/97, Loss: 0.2268
Epoch 4/10, Batch 30/97, Loss: 0.6029
Epoch 4/10, Batch 40/97, Loss: 0.2078
Epoch 4/10, Batch 50/97, Loss: 0.2289
Epoch 4/10, Batch 60/97, Loss: 0.1824
Epoch 4/10, Batch 70/97, Loss: 0.1736
Epoch 4/10, Batch 80/97, Loss: 0.3171
Epoch 4/10, Batch 90/97, Loss: 0.2038
Epoch 4/10, Train Loss: 0.2778, Valid Loss: 0.2887
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3412
Epoch 5/10, Batch 20/97, Loss: 0.2550
Epoch 5/10, Batch 30/97, Loss: 0.1244
Epoch 5/10, Batch 40/97, Loss: 0.1554
Epoch 5/10, Batch 50/97, Loss: 0.2811
Epoch 5/10, Batch 60/97, Loss: 0.2190
Epoch 5/10, Batch 70/97, Loss: 0.1985
Epoch 5/10, Batch 80/97, Loss: 0.1421
Epoch 5/10, Batch 90/97, Loss: 0.2775
Epoch 5/10, Train Loss: 0.2572, Valid Loss: 0.2686
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2003
Epoch 6/10, Batch 20/97, Loss: 0.1000
Epoch 6/10, Batch 30/97, Loss: 0.1639
Epoch 6/10, Batch 40/97, Loss: 0.2007
Epoch 6/10, Batch 50/97, Loss: 0.1882
Epoch 6/10, Batch 60/97, Loss: 0.1769
Epoch 6/10, Batch 70/97, Loss: 0.2666
Epoch 6/10, Batch 80/97, Loss: 0.0864
Epoch 6/10, Batch 90/97, Loss: 0.3510
Epoch 6/10, Train Loss: 0.2352, Valid Loss: 0.2604
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4555
Epoch 7/10, Batch 20/97, Loss: 0.2051
Epoch 7/10, Batch 30/97, Loss: 0.1865
Epoch 7/10, Batch 40/97, Loss: 0.1064
Epoch 7/10, Batch 50/97, Loss: 0.2366
Epoch 7/10, Batch 60/97, Loss: 0.2639
Epoch 7/10, Batch 70/97, Loss: 0.1150
Epoch 7/10, Batch 80/97, Loss: 0.1194
Epoch 7/10, Batch 90/97, Loss: 0.2634
Epoch 7/10, Train Loss: 0.2338, Valid Loss: 0.2510
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.0875
Epoch 8/10, Batch 20/97, Loss: 0.1880
Epoch 8/10, Batch 30/97, Loss: 0.1659
Epoch 8/10, Batch 40/97, Loss: 0.1890
Epoch 8/10, Batch 50/97, Loss: 0.1392
Epoch 8/10, Batch 60/97, Loss: 0.1461
Epoch 8/10, Batch 70/97, Loss: 0.5094
Epoch 8/10, Batch 80/97, Loss: 0.0943
Epoch 8/10, Batch 90/97, Loss: 0.1388
Epoch 8/10, Train Loss: 0.2153, Valid Loss: 0.2618
Epoch 9/10, Batch 10/97, Loss: 0.0844
Epoch 9/10, Batch 20/97, Loss: 0.2303
Epoch 9/10, Batch 30/97, Loss: 0.2770
Epoch 9/10, Batch 40/97, Loss: 0.1292
Epoch 9/10, Batch 50/97, Loss: 0.1866
Epoch 9/10, Batch 60/97, Loss: 0.1505
Epoch 9/10, Batch 70/97, Loss: 0.1356
Epoch 9/10, Batch 80/97, Loss: 0.1107
Epoch 9/10, Batch 90/97, Loss: 0.1773
Epoch 9/10, Train Loss: 0.2047, Valid Loss: 0.2548
Epoch 10/10, Batch 10/97, Loss: 0.1891
Epoch 10/10, Batch 20/97, Loss: 0.2366
Epoch 10/10, Batch 30/97, Loss: 0.2465
Epoch 10/10, Batch 40/97, Loss: 0.1462
Epoch 10/10, Batch 50/97, Loss: 0.1451
Epoch 10/10, Batch 60/97, Loss: 0.1452
Epoch 10/10, Batch 70/97, Loss: 0.1863
Epoch 10/10, Batch 80/97, Loss: 0.1843
Epoch 10/10, Batch 90/97, Loss: 0.1388
Epoch 10/10, Train Loss: 0.1917, Valid Loss: 0.2418
Model saved!
Accuracy: 0.9159
Precision: 0.9138
Recall: 0.9159
F1-score: 0.9147
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4729
Epoch 1/10, Batch 20/97, Loss: 1.0024
Epoch 1/10, Batch 30/97, Loss: 0.8528
Epoch 1/10, Batch 40/97, Loss: 0.7310
Epoch 1/10, Batch 50/97, Loss: 0.5080
Epoch 1/10, Batch 60/97, Loss: 0.5632
Epoch 1/10, Batch 70/97, Loss: 0.4682
Epoch 1/10, Batch 80/97, Loss: 0.4713
Epoch 1/10, Batch 90/97, Loss: 0.5510
Epoch 1/10, Train Loss: 0.7692, Valid Loss: 0.4425
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4990
Epoch 2/10, Batch 20/97, Loss: 0.4399
Epoch 2/10, Batch 30/97, Loss: 0.3167
Epoch 2/10, Batch 40/97, Loss: 0.3591
Epoch 2/10, Batch 50/97, Loss: 0.6440
Epoch 2/10, Batch 60/97, Loss: 0.2917
Epoch 2/10, Batch 70/97, Loss: 0.2599
Epoch 2/10, Batch 80/97, Loss: 0.2854
Epoch 2/10, Batch 90/97, Loss: 0.2666
Epoch 2/10, Train Loss: 0.3907, Valid Loss: 0.3420
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3225
Epoch 3/10, Batch 20/97, Loss: 0.2138
Epoch 3/10, Batch 30/97, Loss: 0.3699
Epoch 3/10, Batch 40/97, Loss: 0.2598
Epoch 3/10, Batch 50/97, Loss: 0.3353
Epoch 3/10, Batch 60/97, Loss: 0.2111
Epoch 3/10, Batch 70/97, Loss: 0.1866
Epoch 3/10, Batch 80/97, Loss: 0.3136
Epoch 3/10, Batch 90/97, Loss: 0.2988
Epoch 3/10, Train Loss: 0.3244, Valid Loss: 0.2958
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3313
Epoch 4/10, Batch 20/97, Loss: 0.2693
Epoch 4/10, Batch 30/97, Loss: 0.2272
Epoch 4/10, Batch 40/97, Loss: 0.2049
Epoch 4/10, Batch 50/97, Loss: 0.1937
Epoch 4/10, Batch 60/97, Loss: 0.1522
Epoch 4/10, Batch 70/97, Loss: 0.3070
Epoch 4/10, Batch 80/97, Loss: 0.2535
Epoch 4/10, Batch 90/97, Loss: 0.3479
Epoch 4/10, Train Loss: 0.2824, Valid Loss: 0.2809
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1935
Epoch 5/10, Batch 20/97, Loss: 0.3194
Epoch 5/10, Batch 30/97, Loss: 0.2753
Epoch 5/10, Batch 40/97, Loss: 0.1717
Epoch 5/10, Batch 50/97, Loss: 0.0811
Epoch 5/10, Batch 60/97, Loss: 0.2141
Epoch 5/10, Batch 70/97, Loss: 0.3169
Epoch 5/10, Batch 80/97, Loss: 0.2124
Epoch 5/10, Batch 90/97, Loss: 0.3206
Epoch 5/10, Train Loss: 0.2515, Valid Loss: 0.2658
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1937
Epoch 6/10, Batch 20/97, Loss: 0.2905
Epoch 6/10, Batch 30/97, Loss: 0.1520
Epoch 6/10, Batch 40/97, Loss: 0.2945
Epoch 6/10, Batch 50/97, Loss: 0.2158
Epoch 6/10, Batch 60/97, Loss: 0.1457
Epoch 6/10, Batch 70/97, Loss: 0.1564
Epoch 6/10, Batch 80/97, Loss: 0.1551
Epoch 6/10, Batch 90/97, Loss: 0.2407
Epoch 6/10, Train Loss: 0.2429, Valid Loss: 0.2586
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4043
Epoch 7/10, Batch 20/97, Loss: 0.2165
Epoch 7/10, Batch 30/97, Loss: 0.1849
Epoch 7/10, Batch 40/97, Loss: 0.1812
Epoch 7/10, Batch 50/97, Loss: 0.1681
Epoch 7/10, Batch 60/97, Loss: 0.1765
Epoch 7/10, Batch 70/97, Loss: 0.2282
Epoch 7/10, Batch 80/97, Loss: 0.2020
Epoch 7/10, Batch 90/97, Loss: 0.2400
Epoch 7/10, Train Loss: 0.2400, Valid Loss: 0.2520
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1757
Epoch 8/10, Batch 20/97, Loss: 0.1395
Epoch 8/10, Batch 30/97, Loss: 0.0917
Epoch 8/10, Batch 40/97, Loss: 0.1669
Epoch 8/10, Batch 50/97, Loss: 0.2303
Epoch 8/10, Batch 60/97, Loss: 0.1340
Epoch 8/10, Batch 70/97, Loss: 0.2432
Epoch 8/10, Batch 80/97, Loss: 0.2079
Epoch 8/10, Batch 90/97, Loss: 0.1609
Epoch 8/10, Train Loss: 0.2201, Valid Loss: 0.2390
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0990
Epoch 9/10, Batch 20/97, Loss: 0.0847
Epoch 9/10, Batch 30/97, Loss: 0.2293
Epoch 9/10, Batch 40/97, Loss: 0.1358
Epoch 9/10, Batch 50/97, Loss: 0.2391
Epoch 9/10, Batch 60/97, Loss: 0.2049
Epoch 9/10, Batch 70/97, Loss: 0.2578
Epoch 9/10, Batch 80/97, Loss: 0.1793
Epoch 9/10, Batch 90/97, Loss: 0.2418
Epoch 9/10, Train Loss: 0.1959, Valid Loss: 0.2401
Epoch 10/10, Batch 10/97, Loss: 0.2307
Epoch 10/10, Batch 20/97, Loss: 0.0819
Epoch 10/10, Batch 30/97, Loss: 0.1472
Epoch 10/10, Batch 40/97, Loss: 0.2876
Epoch 10/10, Batch 50/97, Loss: 0.4838
Epoch 10/10, Batch 60/97, Loss: 0.2373
Epoch 10/10, Batch 70/97, Loss: 0.2054
Epoch 10/10, Batch 80/97, Loss: 0.1723
Epoch 10/10, Batch 90/97, Loss: 0.2186
Epoch 10/10, Train Loss: 0.1918, Valid Loss: 0.2289
Model saved!
Accuracy: 0.9217
Precision: 0.9201
Recall: 0.9217
F1-score: 0.9206
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4831
Epoch 1/10, Batch 20/97, Loss: 0.9876
Epoch 1/10, Batch 30/97, Loss: 0.8951
Epoch 1/10, Batch 40/97, Loss: 0.6398
Epoch 1/10, Batch 50/97, Loss: 0.5913
Epoch 1/10, Batch 60/97, Loss: 0.5380
Epoch 1/10, Batch 70/97, Loss: 0.5117
Epoch 1/10, Batch 80/97, Loss: 0.3617
Epoch 1/10, Batch 90/97, Loss: 0.5466
Epoch 1/10, Train Loss: 0.7632, Valid Loss: 0.4373
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4548
Epoch 2/10, Batch 20/97, Loss: 0.4668
Epoch 2/10, Batch 30/97, Loss: 0.3275
Epoch 2/10, Batch 40/97, Loss: 0.4719
Epoch 2/10, Batch 50/97, Loss: 0.6481
Epoch 2/10, Batch 60/97, Loss: 0.3351
Epoch 2/10, Batch 70/97, Loss: 0.4169
Epoch 2/10, Batch 80/97, Loss: 0.3634
Epoch 2/10, Batch 90/97, Loss: 0.4088
Epoch 2/10, Train Loss: 0.3886, Valid Loss: 0.3324
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3284
Epoch 3/10, Batch 20/97, Loss: 0.3819
Epoch 3/10, Batch 30/97, Loss: 0.2770
Epoch 3/10, Batch 40/97, Loss: 0.3342
Epoch 3/10, Batch 50/97, Loss: 0.2278
Epoch 3/10, Batch 60/97, Loss: 0.1830
Epoch 3/10, Batch 70/97, Loss: 0.1602
Epoch 3/10, Batch 80/97, Loss: 0.2455
Epoch 3/10, Batch 90/97, Loss: 0.3318
Epoch 3/10, Train Loss: 0.3179, Valid Loss: 0.2814
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3075
Epoch 4/10, Batch 20/97, Loss: 0.3261
Epoch 4/10, Batch 30/97, Loss: 0.2918
Epoch 4/10, Batch 40/97, Loss: 0.2621
Epoch 4/10, Batch 50/97, Loss: 0.2151
Epoch 4/10, Batch 60/97, Loss: 0.2486
Epoch 4/10, Batch 70/97, Loss: 0.2004
Epoch 4/10, Batch 80/97, Loss: 0.2343
Epoch 4/10, Batch 90/97, Loss: 0.2076
Epoch 4/10, Train Loss: 0.2761, Valid Loss: 0.2594
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1683
Epoch 5/10, Batch 20/97, Loss: 0.1824
Epoch 5/10, Batch 30/97, Loss: 0.1830
Epoch 5/10, Batch 40/97, Loss: 0.1286
Epoch 5/10, Batch 50/97, Loss: 0.2007
Epoch 5/10, Batch 60/97, Loss: 0.1998
Epoch 5/10, Batch 70/97, Loss: 0.2493
Epoch 5/10, Batch 80/97, Loss: 0.2181
Epoch 5/10, Batch 90/97, Loss: 0.4859
Epoch 5/10, Train Loss: 0.2611, Valid Loss: 0.2404
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1822
Epoch 6/10, Batch 20/97, Loss: 0.1851
Epoch 6/10, Batch 30/97, Loss: 0.2024
Epoch 6/10, Batch 40/97, Loss: 0.3377
Epoch 6/10, Batch 50/97, Loss: 0.1682
Epoch 6/10, Batch 60/97, Loss: 0.2670
Epoch 6/10, Batch 70/97, Loss: 0.1192
Epoch 6/10, Batch 80/97, Loss: 0.2534
Epoch 6/10, Batch 90/97, Loss: 0.2029
Epoch 6/10, Train Loss: 0.2374, Valid Loss: 0.2383
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4217
Epoch 7/10, Batch 20/97, Loss: 0.1472
Epoch 7/10, Batch 30/97, Loss: 0.1959
Epoch 7/10, Batch 40/97, Loss: 0.2154
Epoch 7/10, Batch 50/97, Loss: 0.2025
Epoch 7/10, Batch 60/97, Loss: 0.3044
Epoch 7/10, Batch 70/97, Loss: 0.2303
Epoch 7/10, Batch 80/97, Loss: 0.1593
Epoch 7/10, Batch 90/97, Loss: 0.1341
Epoch 7/10, Train Loss: 0.2375, Valid Loss: 0.2231
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1103
Epoch 8/10, Batch 20/97, Loss: 0.1991
Epoch 8/10, Batch 30/97, Loss: 0.1988
Epoch 8/10, Batch 40/97, Loss: 0.1306
Epoch 8/10, Batch 50/97, Loss: 0.1861
Epoch 8/10, Batch 60/97, Loss: 0.0887
Epoch 8/10, Batch 70/97, Loss: 0.4275
Epoch 8/10, Batch 80/97, Loss: 0.0834
Epoch 8/10, Batch 90/97, Loss: 0.1651
Epoch 8/10, Train Loss: 0.2240, Valid Loss: 0.2253
Epoch 9/10, Batch 10/97, Loss: 0.2688
Epoch 9/10, Batch 20/97, Loss: 0.1307
Epoch 9/10, Batch 30/97, Loss: 0.2786
Epoch 9/10, Batch 40/97, Loss: 0.1710
Epoch 9/10, Batch 50/97, Loss: 0.2205
Epoch 9/10, Batch 60/97, Loss: 0.1905
Epoch 9/10, Batch 70/97, Loss: 0.1919
Epoch 9/10, Batch 80/97, Loss: 0.2430
Epoch 9/10, Batch 90/97, Loss: 0.2148
Epoch 9/10, Train Loss: 0.2130, Valid Loss: 0.2249
Epoch 10/10, Batch 10/97, Loss: 0.1862
Epoch 10/10, Batch 20/97, Loss: 0.1587
Epoch 10/10, Batch 30/97, Loss: 0.1183
Epoch 10/10, Batch 40/97, Loss: 0.2486
Epoch 10/10, Batch 50/97, Loss: 0.2521
Epoch 10/10, Batch 60/97, Loss: 0.1849
Epoch 10/10, Batch 70/97, Loss: 0.1363
Epoch 10/10, Batch 80/97, Loss: 0.2945
Epoch 10/10, Batch 90/97, Loss: 0.1433
Epoch 10/10, Train Loss: 0.1918, Valid Loss: 0.2068
Model saved!
Accuracy: 0.9171
Precision: 0.9145
Recall: 0.9171
F1-score: 0.9151
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4390
Epoch 1/10, Batch 20/97, Loss: 1.0269
Epoch 1/10, Batch 30/97, Loss: 0.8576
Epoch 1/10, Batch 40/97, Loss: 0.7494
Epoch 1/10, Batch 50/97, Loss: 0.5994
Epoch 1/10, Batch 60/97, Loss: 0.5738
Epoch 1/10, Batch 70/97, Loss: 0.4868
Epoch 1/10, Batch 80/97, Loss: 0.4164
Epoch 1/10, Batch 90/97, Loss: 0.4832
Epoch 1/10, Train Loss: 0.7826, Valid Loss: 0.4511
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.2957
Epoch 2/10, Batch 20/97, Loss: 0.5441
Epoch 2/10, Batch 30/97, Loss: 0.3413
Epoch 2/10, Batch 40/97, Loss: 0.5663
Epoch 2/10, Batch 50/97, Loss: 0.4905
Epoch 2/10, Batch 60/97, Loss: 0.3414
Epoch 2/10, Batch 70/97, Loss: 0.3336
Epoch 2/10, Batch 80/97, Loss: 0.3542
Epoch 2/10, Batch 90/97, Loss: 0.4201
Epoch 2/10, Train Loss: 0.3996, Valid Loss: 0.3527
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3129
Epoch 3/10, Batch 20/97, Loss: 0.2903
Epoch 3/10, Batch 30/97, Loss: 0.2518
Epoch 3/10, Batch 40/97, Loss: 0.1576
Epoch 3/10, Batch 50/97, Loss: 0.3052
Epoch 3/10, Batch 60/97, Loss: 0.1696
Epoch 3/10, Batch 70/97, Loss: 0.2075
Epoch 3/10, Batch 80/97, Loss: 0.3951
Epoch 3/10, Batch 90/97, Loss: 0.2291
Epoch 3/10, Train Loss: 0.3286, Valid Loss: 0.3077
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3134
Epoch 4/10, Batch 20/97, Loss: 0.2091
Epoch 4/10, Batch 30/97, Loss: 0.3499
Epoch 4/10, Batch 40/97, Loss: 0.1903
Epoch 4/10, Batch 50/97, Loss: 0.2711
Epoch 4/10, Batch 60/97, Loss: 0.2438
Epoch 4/10, Batch 70/97, Loss: 0.3121
Epoch 4/10, Batch 80/97, Loss: 0.1703
Epoch 4/10, Batch 90/97, Loss: 0.4272
Epoch 4/10, Train Loss: 0.2921, Valid Loss: 0.2992
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2422
Epoch 5/10, Batch 20/97, Loss: 0.1621
Epoch 5/10, Batch 30/97, Loss: 0.2389
Epoch 5/10, Batch 40/97, Loss: 0.1705
Epoch 5/10, Batch 50/97, Loss: 0.2979
Epoch 5/10, Batch 60/97, Loss: 0.3084
Epoch 5/10, Batch 70/97, Loss: 0.1194
Epoch 5/10, Batch 80/97, Loss: 0.1649
Epoch 5/10, Batch 90/97, Loss: 0.5368
Epoch 5/10, Train Loss: 0.2634, Valid Loss: 0.2809
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3075
Epoch 6/10, Batch 20/97, Loss: 0.3116
Epoch 6/10, Batch 30/97, Loss: 0.1753
Epoch 6/10, Batch 40/97, Loss: 0.3155
Epoch 6/10, Batch 50/97, Loss: 0.1869
Epoch 6/10, Batch 60/97, Loss: 0.3771
Epoch 6/10, Batch 70/97, Loss: 0.1187
Epoch 6/10, Batch 80/97, Loss: 0.2169
Epoch 6/10, Batch 90/97, Loss: 0.4215
Epoch 6/10, Train Loss: 0.2464, Valid Loss: 0.2719
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2391
Epoch 7/10, Batch 20/97, Loss: 0.2331
Epoch 7/10, Batch 30/97, Loss: 0.2038
Epoch 7/10, Batch 40/97, Loss: 0.2302
Epoch 7/10, Batch 50/97, Loss: 0.2319
Epoch 7/10, Batch 60/97, Loss: 0.4336
Epoch 7/10, Batch 70/97, Loss: 0.2292
Epoch 7/10, Batch 80/97, Loss: 0.1488
Epoch 7/10, Batch 90/97, Loss: 0.1966
Epoch 7/10, Train Loss: 0.2447, Valid Loss: 0.2605
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1926
Epoch 8/10, Batch 20/97, Loss: 0.1344
Epoch 8/10, Batch 30/97, Loss: 0.1287
Epoch 8/10, Batch 40/97, Loss: 0.3361
Epoch 8/10, Batch 50/97, Loss: 0.2011
Epoch 8/10, Batch 60/97, Loss: 0.1476
Epoch 8/10, Batch 70/97, Loss: 0.2785
Epoch 8/10, Batch 80/97, Loss: 0.1220
Epoch 8/10, Batch 90/97, Loss: 0.1102
Epoch 8/10, Train Loss: 0.2276, Valid Loss: 0.2575
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1347
Epoch 9/10, Batch 20/97, Loss: 0.0927
Epoch 9/10, Batch 30/97, Loss: 0.3186
Epoch 9/10, Batch 40/97, Loss: 0.1923
Epoch 9/10, Batch 50/97, Loss: 0.2342
Epoch 9/10, Batch 60/97, Loss: 0.1187
Epoch 9/10, Batch 70/97, Loss: 0.1372
Epoch 9/10, Batch 80/97, Loss: 0.1874
Epoch 9/10, Batch 90/97, Loss: 0.1947
Epoch 9/10, Train Loss: 0.2158, Valid Loss: 0.2564
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2424
Epoch 10/10, Batch 20/97, Loss: 0.1931
Epoch 10/10, Batch 30/97, Loss: 0.1181
Epoch 10/10, Batch 40/97, Loss: 0.1845
Epoch 10/10, Batch 50/97, Loss: 0.2984
Epoch 10/10, Batch 60/97, Loss: 0.1721
Epoch 10/10, Batch 70/97, Loss: 0.1588
Epoch 10/10, Batch 80/97, Loss: 0.2268
Epoch 10/10, Batch 90/97, Loss: 0.2286
Epoch 10/10, Train Loss: 0.2032, Valid Loss: 0.2518
Model saved!
Accuracy: 0.9171
Precision: 0.9137
Recall: 0.9171
F1-score: 0.9141
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4665
Epoch 1/10, Batch 20/97, Loss: 0.9449
Epoch 1/10, Batch 30/97, Loss: 0.8501
Epoch 1/10, Batch 40/97, Loss: 0.6721
Epoch 1/10, Batch 50/97, Loss: 0.6221
Epoch 1/10, Batch 60/97, Loss: 0.5731
Epoch 1/10, Batch 70/97, Loss: 0.5301
Epoch 1/10, Batch 80/97, Loss: 0.4657
Epoch 1/10, Batch 90/97, Loss: 0.4911
Epoch 1/10, Train Loss: 0.7705, Valid Loss: 0.4381
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3933
Epoch 2/10, Batch 20/97, Loss: 0.5440
Epoch 2/10, Batch 30/97, Loss: 0.3674
Epoch 2/10, Batch 40/97, Loss: 0.4390
Epoch 2/10, Batch 50/97, Loss: 0.6178
Epoch 2/10, Batch 60/97, Loss: 0.3524
Epoch 2/10, Batch 70/97, Loss: 0.4024
Epoch 2/10, Batch 80/97, Loss: 0.3969
Epoch 2/10, Batch 90/97, Loss: 0.2323
Epoch 2/10, Train Loss: 0.3947, Valid Loss: 0.3345
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3454
Epoch 3/10, Batch 20/97, Loss: 0.3450
Epoch 3/10, Batch 30/97, Loss: 0.3250
Epoch 3/10, Batch 40/97, Loss: 0.1986
Epoch 3/10, Batch 50/97, Loss: 0.3768
Epoch 3/10, Batch 60/97, Loss: 0.1782
Epoch 3/10, Batch 70/97, Loss: 0.2954
Epoch 3/10, Batch 80/97, Loss: 0.4078
Epoch 3/10, Batch 90/97, Loss: 0.2473
Epoch 3/10, Train Loss: 0.3249, Valid Loss: 0.2926
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2443
Epoch 4/10, Batch 20/97, Loss: 0.2665
Epoch 4/10, Batch 30/97, Loss: 0.3087
Epoch 4/10, Batch 40/97, Loss: 0.2163
Epoch 4/10, Batch 50/97, Loss: 0.2178
Epoch 4/10, Batch 60/97, Loss: 0.2012
Epoch 4/10, Batch 70/97, Loss: 0.2966
Epoch 4/10, Batch 80/97, Loss: 0.2151
Epoch 4/10, Batch 90/97, Loss: 0.3587
Epoch 4/10, Train Loss: 0.2833, Valid Loss: 0.2682
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2304
Epoch 5/10, Batch 20/97, Loss: 0.1500
Epoch 5/10, Batch 30/97, Loss: 0.1232
Epoch 5/10, Batch 40/97, Loss: 0.1373
Epoch 5/10, Batch 50/97, Loss: 0.3386
Epoch 5/10, Batch 60/97, Loss: 0.2392
Epoch 5/10, Batch 70/97, Loss: 0.2734
Epoch 5/10, Batch 80/97, Loss: 0.4223
Epoch 5/10, Batch 90/97, Loss: 0.3650
Epoch 5/10, Train Loss: 0.2523, Valid Loss: 0.2518
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3074
Epoch 6/10, Batch 20/97, Loss: 0.1482
Epoch 6/10, Batch 30/97, Loss: 0.1587
Epoch 6/10, Batch 40/97, Loss: 0.2856
Epoch 6/10, Batch 50/97, Loss: 0.1884
Epoch 6/10, Batch 60/97, Loss: 0.3901
Epoch 6/10, Batch 70/97, Loss: 0.1681
Epoch 6/10, Batch 80/97, Loss: 0.2142
Epoch 6/10, Batch 90/97, Loss: 0.2450
Epoch 6/10, Train Loss: 0.2360, Valid Loss: 0.2378
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3570
Epoch 7/10, Batch 20/97, Loss: 0.1435
Epoch 7/10, Batch 30/97, Loss: 0.2922
Epoch 7/10, Batch 40/97, Loss: 0.2193
Epoch 7/10, Batch 50/97, Loss: 0.3007
Epoch 7/10, Batch 60/97, Loss: 0.2045
Epoch 7/10, Batch 70/97, Loss: 0.1836
Epoch 7/10, Batch 80/97, Loss: 0.2437
Epoch 7/10, Batch 90/97, Loss: 0.2938
Epoch 7/10, Train Loss: 0.2407, Valid Loss: 0.2388
Epoch 8/10, Batch 10/97, Loss: 0.1226
Epoch 8/10, Batch 20/97, Loss: 0.2183
Epoch 8/10, Batch 30/97, Loss: 0.1434
Epoch 8/10, Batch 40/97, Loss: 0.2381
Epoch 8/10, Batch 50/97, Loss: 0.2523
Epoch 8/10, Batch 60/97, Loss: 0.0892
Epoch 8/10, Batch 70/97, Loss: 0.3151
Epoch 8/10, Batch 80/97, Loss: 0.1041
Epoch 8/10, Batch 90/97, Loss: 0.1541
Epoch 8/10, Train Loss: 0.2162, Valid Loss: 0.2316
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1466
Epoch 9/10, Batch 20/97, Loss: 0.1326
Epoch 9/10, Batch 30/97, Loss: 0.2819
Epoch 9/10, Batch 40/97, Loss: 0.0823
Epoch 9/10, Batch 50/97, Loss: 0.2347
Epoch 9/10, Batch 60/97, Loss: 0.1718
Epoch 9/10, Batch 70/97, Loss: 0.2934
Epoch 9/10, Batch 80/97, Loss: 0.2007
Epoch 9/10, Batch 90/97, Loss: 0.2493
Epoch 9/10, Train Loss: 0.1991, Valid Loss: 0.2240
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3143
Epoch 10/10, Batch 20/97, Loss: 0.1727
Epoch 10/10, Batch 30/97, Loss: 0.1244
Epoch 10/10, Batch 40/97, Loss: 0.1256
Epoch 10/10, Batch 50/97, Loss: 0.4040
Epoch 10/10, Batch 60/97, Loss: 0.1614
Epoch 10/10, Batch 70/97, Loss: 0.2104
Epoch 10/10, Batch 80/97, Loss: 0.2541
Epoch 10/10, Batch 90/97, Loss: 0.1468
Epoch 10/10, Train Loss: 0.1878, Valid Loss: 0.2216
Model saved!
Accuracy: 0.9217
Precision: 0.9199
Recall: 0.9217
F1-score: 0.9198
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5113
Epoch 1/10, Batch 20/97, Loss: 0.9688
Epoch 1/10, Batch 30/97, Loss: 0.8477
Epoch 1/10, Batch 40/97, Loss: 0.6234
Epoch 1/10, Batch 50/97, Loss: 0.5456
Epoch 1/10, Batch 60/97, Loss: 0.5960
Epoch 1/10, Batch 70/97, Loss: 0.6859
Epoch 1/10, Batch 80/97, Loss: 0.4123
Epoch 1/10, Batch 90/97, Loss: 0.4796
Epoch 1/10, Train Loss: 0.7658, Valid Loss: 0.4529
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4504
Epoch 2/10, Batch 20/97, Loss: 0.6650
Epoch 2/10, Batch 30/97, Loss: 0.5408
Epoch 2/10, Batch 40/97, Loss: 0.3474
Epoch 2/10, Batch 50/97, Loss: 0.5334
Epoch 2/10, Batch 60/97, Loss: 0.3530
Epoch 2/10, Batch 70/97, Loss: 0.3750
Epoch 2/10, Batch 80/97, Loss: 0.3776
Epoch 2/10, Batch 90/97, Loss: 0.3211
Epoch 2/10, Train Loss: 0.3858, Valid Loss: 0.3515
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2852
Epoch 3/10, Batch 20/97, Loss: 0.2648
Epoch 3/10, Batch 30/97, Loss: 0.3144
Epoch 3/10, Batch 40/97, Loss: 0.2170
Epoch 3/10, Batch 50/97, Loss: 0.2920
Epoch 3/10, Batch 60/97, Loss: 0.2771
Epoch 3/10, Batch 70/97, Loss: 0.2188
Epoch 3/10, Batch 80/97, Loss: 0.3249
Epoch 3/10, Batch 90/97, Loss: 0.2875
Epoch 3/10, Train Loss: 0.3097, Valid Loss: 0.3128
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1550
Epoch 4/10, Batch 20/97, Loss: 0.4222
Epoch 4/10, Batch 30/97, Loss: 0.3637
Epoch 4/10, Batch 40/97, Loss: 0.3441
Epoch 4/10, Batch 50/97, Loss: 0.2067
Epoch 4/10, Batch 60/97, Loss: 0.1719
Epoch 4/10, Batch 70/97, Loss: 0.3378
Epoch 4/10, Batch 80/97, Loss: 0.3613
Epoch 4/10, Batch 90/97, Loss: 0.2351
Epoch 4/10, Train Loss: 0.2718, Valid Loss: 0.2902
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2328
Epoch 5/10, Batch 20/97, Loss: 0.2146
Epoch 5/10, Batch 30/97, Loss: 0.0952
Epoch 5/10, Batch 40/97, Loss: 0.0802
Epoch 5/10, Batch 50/97, Loss: 0.2145
Epoch 5/10, Batch 60/97, Loss: 0.1887
Epoch 5/10, Batch 70/97, Loss: 0.1751
Epoch 5/10, Batch 80/97, Loss: 0.1965
Epoch 5/10, Batch 90/97, Loss: 0.3140
Epoch 5/10, Train Loss: 0.2483, Valid Loss: 0.2797
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2213
Epoch 6/10, Batch 20/97, Loss: 0.1796
Epoch 6/10, Batch 30/97, Loss: 0.2172
Epoch 6/10, Batch 40/97, Loss: 0.2555
Epoch 6/10, Batch 50/97, Loss: 0.1586
Epoch 6/10, Batch 60/97, Loss: 0.2684
Epoch 6/10, Batch 70/97, Loss: 0.3052
Epoch 6/10, Batch 80/97, Loss: 0.1807
Epoch 6/10, Batch 90/97, Loss: 0.3538
Epoch 6/10, Train Loss: 0.2286, Valid Loss: 0.2822
Epoch 7/10, Batch 10/97, Loss: 0.4503
Epoch 7/10, Batch 20/97, Loss: 0.1203
Epoch 7/10, Batch 30/97, Loss: 0.1404
Epoch 7/10, Batch 40/97, Loss: 0.1709
Epoch 7/10, Batch 50/97, Loss: 0.3147
Epoch 7/10, Batch 60/97, Loss: 0.3294
Epoch 7/10, Batch 70/97, Loss: 0.1529
Epoch 7/10, Batch 80/97, Loss: 0.1133
Epoch 7/10, Batch 90/97, Loss: 0.1194
Epoch 7/10, Train Loss: 0.2218, Valid Loss: 0.2735
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2946
Epoch 8/10, Batch 20/97, Loss: 0.1703
Epoch 8/10, Batch 30/97, Loss: 0.2078
Epoch 8/10, Batch 40/97, Loss: 0.1851
Epoch 8/10, Batch 50/97, Loss: 0.1572
Epoch 8/10, Batch 60/97, Loss: 0.1467
Epoch 8/10, Batch 70/97, Loss: 0.3518
Epoch 8/10, Batch 80/97, Loss: 0.1899
Epoch 8/10, Batch 90/97, Loss: 0.1127
Epoch 8/10, Train Loss: 0.2123, Valid Loss: 0.2623
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0856
Epoch 9/10, Batch 20/97, Loss: 0.1260
Epoch 9/10, Batch 30/97, Loss: 0.2862
Epoch 9/10, Batch 40/97, Loss: 0.1134
Epoch 9/10, Batch 50/97, Loss: 0.2153
Epoch 9/10, Batch 60/97, Loss: 0.2370
Epoch 9/10, Batch 70/97, Loss: 0.1700
Epoch 9/10, Batch 80/97, Loss: 0.1935
Epoch 9/10, Batch 90/97, Loss: 0.2468
Epoch 9/10, Train Loss: 0.1939, Valid Loss: 0.2600
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2258
Epoch 10/10, Batch 20/97, Loss: 0.1777
Epoch 10/10, Batch 30/97, Loss: 0.2118
Epoch 10/10, Batch 40/97, Loss: 0.1501
Epoch 10/10, Batch 50/97, Loss: 0.2106
Epoch 10/10, Batch 60/97, Loss: 0.1678
Epoch 10/10, Batch 70/97, Loss: 0.2232
Epoch 10/10, Batch 80/97, Loss: 0.1723
Epoch 10/10, Batch 90/97, Loss: 0.2384
Epoch 10/10, Train Loss: 0.1846, Valid Loss: 0.2510
Model saved!
Accuracy: 0.9182
Precision: 0.9161
Recall: 0.9182
F1-score: 0.9167
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4632
Epoch 1/10, Batch 20/97, Loss: 0.9441
Epoch 1/10, Batch 30/97, Loss: 0.8974
Epoch 1/10, Batch 40/97, Loss: 0.7196
Epoch 1/10, Batch 50/97, Loss: 0.5659
Epoch 1/10, Batch 60/97, Loss: 0.5338
Epoch 1/10, Batch 70/97, Loss: 0.5179
Epoch 1/10, Batch 80/97, Loss: 0.4518
Epoch 1/10, Batch 90/97, Loss: 0.3904
Epoch 1/10, Train Loss: 0.7678, Valid Loss: 0.4303
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4074
Epoch 2/10, Batch 20/97, Loss: 0.4065
Epoch 2/10, Batch 30/97, Loss: 0.3484
Epoch 2/10, Batch 40/97, Loss: 0.3333
Epoch 2/10, Batch 50/97, Loss: 0.6092
Epoch 2/10, Batch 60/97, Loss: 0.2673
Epoch 2/10, Batch 70/97, Loss: 0.3228
Epoch 2/10, Batch 80/97, Loss: 0.3822
Epoch 2/10, Batch 90/97, Loss: 0.2643
Epoch 2/10, Train Loss: 0.3884, Valid Loss: 0.3189
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3439
Epoch 3/10, Batch 20/97, Loss: 0.2955
Epoch 3/10, Batch 30/97, Loss: 0.3114
Epoch 3/10, Batch 40/97, Loss: 0.3089
Epoch 3/10, Batch 50/97, Loss: 0.2519
Epoch 3/10, Batch 60/97, Loss: 0.3153
Epoch 3/10, Batch 70/97, Loss: 0.2207
Epoch 3/10, Batch 80/97, Loss: 0.3065
Epoch 3/10, Batch 90/97, Loss: 0.2519
Epoch 3/10, Train Loss: 0.3099, Valid Loss: 0.2760
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1763
Epoch 4/10, Batch 20/97, Loss: 0.3521
Epoch 4/10, Batch 30/97, Loss: 0.3670
Epoch 4/10, Batch 40/97, Loss: 0.3174
Epoch 4/10, Batch 50/97, Loss: 0.0929
Epoch 4/10, Batch 60/97, Loss: 0.1488
Epoch 4/10, Batch 70/97, Loss: 0.1555
Epoch 4/10, Batch 80/97, Loss: 0.3959
Epoch 4/10, Batch 90/97, Loss: 0.3825
Epoch 4/10, Train Loss: 0.2817, Valid Loss: 0.2549
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3792
Epoch 5/10, Batch 20/97, Loss: 0.2470
Epoch 5/10, Batch 30/97, Loss: 0.2754
Epoch 5/10, Batch 40/97, Loss: 0.1220
Epoch 5/10, Batch 50/97, Loss: 0.3241
Epoch 5/10, Batch 60/97, Loss: 0.1538
Epoch 5/10, Batch 70/97, Loss: 0.1973
Epoch 5/10, Batch 80/97, Loss: 0.2503
Epoch 5/10, Batch 90/97, Loss: 0.3191
Epoch 5/10, Train Loss: 0.2499, Valid Loss: 0.2404
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1841
Epoch 6/10, Batch 20/97, Loss: 0.1713
Epoch 6/10, Batch 30/97, Loss: 0.2469
Epoch 6/10, Batch 40/97, Loss: 0.2618
Epoch 6/10, Batch 50/97, Loss: 0.3057
Epoch 6/10, Batch 60/97, Loss: 0.4179
Epoch 6/10, Batch 70/97, Loss: 0.1947
Epoch 6/10, Batch 80/97, Loss: 0.2208
Epoch 6/10, Batch 90/97, Loss: 0.1860
Epoch 6/10, Train Loss: 0.2401, Valid Loss: 0.2272
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3184
Epoch 7/10, Batch 20/97, Loss: 0.1412
Epoch 7/10, Batch 30/97, Loss: 0.1282
Epoch 7/10, Batch 40/97, Loss: 0.1899
Epoch 7/10, Batch 50/97, Loss: 0.2047
Epoch 7/10, Batch 60/97, Loss: 0.2355
Epoch 7/10, Batch 70/97, Loss: 0.0819
Epoch 7/10, Batch 80/97, Loss: 0.2163
Epoch 7/10, Batch 90/97, Loss: 0.2097
Epoch 7/10, Train Loss: 0.2310, Valid Loss: 0.2174
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1024
Epoch 8/10, Batch 20/97, Loss: 0.2573
Epoch 8/10, Batch 30/97, Loss: 0.1494
Epoch 8/10, Batch 40/97, Loss: 0.1571
Epoch 8/10, Batch 50/97, Loss: 0.1483
Epoch 8/10, Batch 60/97, Loss: 0.1434
Epoch 8/10, Batch 70/97, Loss: 0.2873
Epoch 8/10, Batch 80/97, Loss: 0.1389
Epoch 8/10, Batch 90/97, Loss: 0.2176
Epoch 8/10, Train Loss: 0.2158, Valid Loss: 0.2154
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1226
Epoch 9/10, Batch 20/97, Loss: 0.1314
Epoch 9/10, Batch 30/97, Loss: 0.2026
Epoch 9/10, Batch 40/97, Loss: 0.1140
Epoch 9/10, Batch 50/97, Loss: 0.1461
Epoch 9/10, Batch 60/97, Loss: 0.1342
Epoch 9/10, Batch 70/97, Loss: 0.1979
Epoch 9/10, Batch 80/97, Loss: 0.1226
Epoch 9/10, Batch 90/97, Loss: 0.2003
Epoch 9/10, Train Loss: 0.2012, Valid Loss: 0.2133
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2443
Epoch 10/10, Batch 20/97, Loss: 0.1413
Epoch 10/10, Batch 30/97, Loss: 0.1102
Epoch 10/10, Batch 40/97, Loss: 0.1444
Epoch 10/10, Batch 50/97, Loss: 0.2715
Epoch 10/10, Batch 60/97, Loss: 0.1261
Epoch 10/10, Batch 70/97, Loss: 0.1594
Epoch 10/10, Batch 80/97, Loss: 0.2160
Epoch 10/10, Batch 90/97, Loss: 0.0938
Epoch 10/10, Train Loss: 0.1911, Valid Loss: 0.2085
Model saved!
Accuracy: 0.9217
Precision: 0.9202
Recall: 0.9217
F1-score: 0.9206
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4560
Epoch 1/10, Batch 20/97, Loss: 1.0674
Epoch 1/10, Batch 30/97, Loss: 0.8901
Epoch 1/10, Batch 40/97, Loss: 0.8397
Epoch 1/10, Batch 50/97, Loss: 0.6970
Epoch 1/10, Batch 60/97, Loss: 0.5715
Epoch 1/10, Batch 70/97, Loss: 0.4883
Epoch 1/10, Batch 80/97, Loss: 0.4489
Epoch 1/10, Batch 90/97, Loss: 0.4836
Epoch 1/10, Train Loss: 0.7743, Valid Loss: 0.4449
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4889
Epoch 2/10, Batch 20/97, Loss: 0.4122
Epoch 2/10, Batch 30/97, Loss: 0.4612
Epoch 2/10, Batch 40/97, Loss: 0.3131
Epoch 2/10, Batch 50/97, Loss: 0.5549
Epoch 2/10, Batch 60/97, Loss: 0.3085
Epoch 2/10, Batch 70/97, Loss: 0.2706
Epoch 2/10, Batch 80/97, Loss: 0.3418
Epoch 2/10, Batch 90/97, Loss: 0.2701
Epoch 2/10, Train Loss: 0.4017, Valid Loss: 0.3308
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4539
Epoch 3/10, Batch 20/97, Loss: 0.3663
Epoch 3/10, Batch 30/97, Loss: 0.2310
Epoch 3/10, Batch 40/97, Loss: 0.2103
Epoch 3/10, Batch 50/97, Loss: 0.3918
Epoch 3/10, Batch 60/97, Loss: 0.2621
Epoch 3/10, Batch 70/97, Loss: 0.2769
Epoch 3/10, Batch 80/97, Loss: 0.2842
Epoch 3/10, Batch 90/97, Loss: 0.2158
Epoch 3/10, Train Loss: 0.3266, Valid Loss: 0.2887
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2533
Epoch 4/10, Batch 20/97, Loss: 0.1847
Epoch 4/10, Batch 30/97, Loss: 0.4455
Epoch 4/10, Batch 40/97, Loss: 0.3137
Epoch 4/10, Batch 50/97, Loss: 0.2349
Epoch 4/10, Batch 60/97, Loss: 0.2313
Epoch 4/10, Batch 70/97, Loss: 0.3433
Epoch 4/10, Batch 80/97, Loss: 0.2849
Epoch 4/10, Batch 90/97, Loss: 0.2723
Epoch 4/10, Train Loss: 0.2927, Valid Loss: 0.2658
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3424
Epoch 5/10, Batch 20/97, Loss: 0.2100
Epoch 5/10, Batch 30/97, Loss: 0.1702
Epoch 5/10, Batch 40/97, Loss: 0.1020
Epoch 5/10, Batch 50/97, Loss: 0.2386
Epoch 5/10, Batch 60/97, Loss: 0.2013
Epoch 5/10, Batch 70/97, Loss: 0.2287
Epoch 5/10, Batch 80/97, Loss: 0.2674
Epoch 5/10, Batch 90/97, Loss: 0.3793
Epoch 5/10, Train Loss: 0.2584, Valid Loss: 0.2527
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2076
Epoch 6/10, Batch 20/97, Loss: 0.1629
Epoch 6/10, Batch 30/97, Loss: 0.2603
Epoch 6/10, Batch 40/97, Loss: 0.2565
Epoch 6/10, Batch 50/97, Loss: 0.2047
Epoch 6/10, Batch 60/97, Loss: 0.3541
Epoch 6/10, Batch 70/97, Loss: 0.2115
Epoch 6/10, Batch 80/97, Loss: 0.1928
Epoch 6/10, Batch 90/97, Loss: 0.2245
Epoch 6/10, Train Loss: 0.2374, Valid Loss: 0.2455
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.7829
Epoch 7/10, Batch 20/97, Loss: 0.1131
Epoch 7/10, Batch 30/97, Loss: 0.2548
Epoch 7/10, Batch 40/97, Loss: 0.1846
Epoch 7/10, Batch 50/97, Loss: 0.1982
Epoch 7/10, Batch 60/97, Loss: 0.2322
Epoch 7/10, Batch 70/97, Loss: 0.1374
Epoch 7/10, Batch 80/97, Loss: 0.1661
Epoch 7/10, Batch 90/97, Loss: 0.2667
Epoch 7/10, Train Loss: 0.2510, Valid Loss: 0.2452
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1591
Epoch 8/10, Batch 20/97, Loss: 0.1589
Epoch 8/10, Batch 30/97, Loss: 0.2302
Epoch 8/10, Batch 40/97, Loss: 0.1377
Epoch 8/10, Batch 50/97, Loss: 0.3537
Epoch 8/10, Batch 60/97, Loss: 0.0652
Epoch 8/10, Batch 70/97, Loss: 0.2486
Epoch 8/10, Batch 80/97, Loss: 0.2625
Epoch 8/10, Batch 90/97, Loss: 0.1974
Epoch 8/10, Train Loss: 0.2207, Valid Loss: 0.2360
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0988
Epoch 9/10, Batch 20/97, Loss: 0.1312
Epoch 9/10, Batch 30/97, Loss: 0.2510
Epoch 9/10, Batch 40/97, Loss: 0.1590
Epoch 9/10, Batch 50/97, Loss: 0.1863
Epoch 9/10, Batch 60/97, Loss: 0.2542
Epoch 9/10, Batch 70/97, Loss: 0.1933
Epoch 9/10, Batch 80/97, Loss: 0.1313
Epoch 9/10, Batch 90/97, Loss: 0.2643
Epoch 9/10, Train Loss: 0.2137, Valid Loss: 0.2323
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2552
Epoch 10/10, Batch 20/97, Loss: 0.1103
Epoch 10/10, Batch 30/97, Loss: 0.1999
Epoch 10/10, Batch 40/97, Loss: 0.1817
Epoch 10/10, Batch 50/97, Loss: 0.3714
Epoch 10/10, Batch 60/97, Loss: 0.1707
Epoch 10/10, Batch 70/97, Loss: 0.0927
Epoch 10/10, Batch 80/97, Loss: 0.1244
Epoch 10/10, Batch 90/97, Loss: 0.1162
Epoch 10/10, Train Loss: 0.1973, Valid Loss: 0.2254
Model saved!
Accuracy: 0.9171
Precision: 0.9152
Recall: 0.9171
F1-score: 0.9159
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5438
Epoch 1/10, Batch 20/97, Loss: 1.0263
Epoch 1/10, Batch 30/97, Loss: 0.8785
Epoch 1/10, Batch 40/97, Loss: 0.6748
Epoch 1/10, Batch 50/97, Loss: 0.6414
Epoch 1/10, Batch 60/97, Loss: 0.5357
Epoch 1/10, Batch 70/97, Loss: 0.5467
Epoch 1/10, Batch 80/97, Loss: 0.4532
Epoch 1/10, Batch 90/97, Loss: 0.5176
Epoch 1/10, Train Loss: 0.7679, Valid Loss: 0.4458
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3012
Epoch 2/10, Batch 20/97, Loss: 0.4577
Epoch 2/10, Batch 30/97, Loss: 0.4282
Epoch 2/10, Batch 40/97, Loss: 0.3741
Epoch 2/10, Batch 50/97, Loss: 0.6133
Epoch 2/10, Batch 60/97, Loss: 0.2692
Epoch 2/10, Batch 70/97, Loss: 0.2514
Epoch 2/10, Batch 80/97, Loss: 0.2754
Epoch 2/10, Batch 90/97, Loss: 0.3898
Epoch 2/10, Train Loss: 0.3831, Valid Loss: 0.3372
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4617
Epoch 3/10, Batch 20/97, Loss: 0.1817
Epoch 3/10, Batch 30/97, Loss: 0.1597
Epoch 3/10, Batch 40/97, Loss: 0.1953
Epoch 3/10, Batch 50/97, Loss: 0.3479
Epoch 3/10, Batch 60/97, Loss: 0.1955
Epoch 3/10, Batch 70/97, Loss: 0.2852
Epoch 3/10, Batch 80/97, Loss: 0.3088
Epoch 3/10, Batch 90/97, Loss: 0.1515
Epoch 3/10, Train Loss: 0.3119, Valid Loss: 0.2979
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2075
Epoch 4/10, Batch 20/97, Loss: 0.3055
Epoch 4/10, Batch 30/97, Loss: 0.4452
Epoch 4/10, Batch 40/97, Loss: 0.3377
Epoch 4/10, Batch 50/97, Loss: 0.2344
Epoch 4/10, Batch 60/97, Loss: 0.2169
Epoch 4/10, Batch 70/97, Loss: 0.2047
Epoch 4/10, Batch 80/97, Loss: 0.3301
Epoch 4/10, Batch 90/97, Loss: 0.3035
Epoch 4/10, Train Loss: 0.2685, Valid Loss: 0.2708
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2705
Epoch 5/10, Batch 20/97, Loss: 0.1139
Epoch 5/10, Batch 30/97, Loss: 0.1014
Epoch 5/10, Batch 40/97, Loss: 0.1317
Epoch 5/10, Batch 50/97, Loss: 0.3263
Epoch 5/10, Batch 60/97, Loss: 0.1571
Epoch 5/10, Batch 70/97, Loss: 0.1996
Epoch 5/10, Batch 80/97, Loss: 0.3403
Epoch 5/10, Batch 90/97, Loss: 0.1922
Epoch 5/10, Train Loss: 0.2438, Valid Loss: 0.2605
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1361
Epoch 6/10, Batch 20/97, Loss: 0.1345
Epoch 6/10, Batch 30/97, Loss: 0.2404
Epoch 6/10, Batch 40/97, Loss: 0.2406
Epoch 6/10, Batch 50/97, Loss: 0.1833
Epoch 6/10, Batch 60/97, Loss: 0.2251
Epoch 6/10, Batch 70/97, Loss: 0.2786
Epoch 6/10, Batch 80/97, Loss: 0.1066
Epoch 6/10, Batch 90/97, Loss: 0.0742
Epoch 6/10, Train Loss: 0.2268, Valid Loss: 0.2520
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1682
Epoch 7/10, Batch 20/97, Loss: 0.1554
Epoch 7/10, Batch 30/97, Loss: 0.1371
Epoch 7/10, Batch 40/97, Loss: 0.2828
Epoch 7/10, Batch 50/97, Loss: 0.2823
Epoch 7/10, Batch 60/97, Loss: 0.2877
Epoch 7/10, Batch 70/97, Loss: 0.1695
Epoch 7/10, Batch 80/97, Loss: 0.2157
Epoch 7/10, Batch 90/97, Loss: 0.1724
Epoch 7/10, Train Loss: 0.2334, Valid Loss: 0.2422
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1035
Epoch 8/10, Batch 20/97, Loss: 0.0853
Epoch 8/10, Batch 30/97, Loss: 0.1531
Epoch 8/10, Batch 40/97, Loss: 0.0937
Epoch 8/10, Batch 50/97, Loss: 0.1458
Epoch 8/10, Batch 60/97, Loss: 0.1983
Epoch 8/10, Batch 70/97, Loss: 0.3476
Epoch 8/10, Batch 80/97, Loss: 0.1507
Epoch 8/10, Batch 90/97, Loss: 0.1431
Epoch 8/10, Train Loss: 0.2108, Valid Loss: 0.2335
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0919
Epoch 9/10, Batch 20/97, Loss: 0.1210
Epoch 9/10, Batch 30/97, Loss: 0.1965
Epoch 9/10, Batch 40/97, Loss: 0.1815
Epoch 9/10, Batch 50/97, Loss: 0.2168
Epoch 9/10, Batch 60/97, Loss: 0.1734
Epoch 9/10, Batch 70/97, Loss: 0.1577
Epoch 9/10, Batch 80/97, Loss: 0.1359
Epoch 9/10, Batch 90/97, Loss: 0.1257
Epoch 9/10, Train Loss: 0.1924, Valid Loss: 0.2279
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3486
Epoch 10/10, Batch 20/97, Loss: 0.2087
Epoch 10/10, Batch 30/97, Loss: 0.1748
Epoch 10/10, Batch 40/97, Loss: 0.2519
Epoch 10/10, Batch 50/97, Loss: 0.3996
Epoch 10/10, Batch 60/97, Loss: 0.1672
Epoch 10/10, Batch 70/97, Loss: 0.1300
Epoch 10/10, Batch 80/97, Loss: 0.1009
Epoch 10/10, Batch 90/97, Loss: 0.1899
Epoch 10/10, Train Loss: 0.1889, Valid Loss: 0.2180
Model saved!
Accuracy: 0.9241
Precision: 0.9226
Recall: 0.9241
F1-score: 0.9229
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4856
Epoch 1/10, Batch 20/97, Loss: 1.0077
Epoch 1/10, Batch 30/97, Loss: 0.8868
Epoch 1/10, Batch 40/97, Loss: 0.8265
Epoch 1/10, Batch 50/97, Loss: 0.6583
Epoch 1/10, Batch 60/97, Loss: 0.6500
Epoch 1/10, Batch 70/97, Loss: 0.5474
Epoch 1/10, Batch 80/97, Loss: 0.6354
Epoch 1/10, Batch 90/97, Loss: 0.5046
Epoch 1/10, Train Loss: 0.7854, Valid Loss: 0.4194
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3957
Epoch 2/10, Batch 20/97, Loss: 0.5881
Epoch 2/10, Batch 30/97, Loss: 0.5101
Epoch 2/10, Batch 40/97, Loss: 0.4254
Epoch 2/10, Batch 50/97, Loss: 0.5950
Epoch 2/10, Batch 60/97, Loss: 0.4625
Epoch 2/10, Batch 70/97, Loss: 0.3265
Epoch 2/10, Batch 80/97, Loss: 0.3983
Epoch 2/10, Batch 90/97, Loss: 0.3768
Epoch 2/10, Train Loss: 0.4068, Valid Loss: 0.3023
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3538
Epoch 3/10, Batch 20/97, Loss: 0.2201
Epoch 3/10, Batch 30/97, Loss: 0.2495
Epoch 3/10, Batch 40/97, Loss: 0.2471
Epoch 3/10, Batch 50/97, Loss: 0.2562
Epoch 3/10, Batch 60/97, Loss: 0.2577
Epoch 3/10, Batch 70/97, Loss: 0.2264
Epoch 3/10, Batch 80/97, Loss: 0.3500
Epoch 3/10, Batch 90/97, Loss: 0.1531
Epoch 3/10, Train Loss: 0.3329, Valid Loss: 0.2628
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3054
Epoch 4/10, Batch 20/97, Loss: 0.2639
Epoch 4/10, Batch 30/97, Loss: 0.2529
Epoch 4/10, Batch 40/97, Loss: 0.3032
Epoch 4/10, Batch 50/97, Loss: 0.1342
Epoch 4/10, Batch 60/97, Loss: 0.1782
Epoch 4/10, Batch 70/97, Loss: 0.2676
Epoch 4/10, Batch 80/97, Loss: 0.2934
Epoch 4/10, Batch 90/97, Loss: 0.2508
Epoch 4/10, Train Loss: 0.2887, Valid Loss: 0.2391
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3021
Epoch 5/10, Batch 20/97, Loss: 0.1462
Epoch 5/10, Batch 30/97, Loss: 0.1596
Epoch 5/10, Batch 40/97, Loss: 0.1438
Epoch 5/10, Batch 50/97, Loss: 0.2176
Epoch 5/10, Batch 60/97, Loss: 0.2583
Epoch 5/10, Batch 70/97, Loss: 0.2180
Epoch 5/10, Batch 80/97, Loss: 0.2970
Epoch 5/10, Batch 90/97, Loss: 0.3061
Epoch 5/10, Train Loss: 0.2633, Valid Loss: 0.2221
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2933
Epoch 6/10, Batch 20/97, Loss: 0.1673
Epoch 6/10, Batch 30/97, Loss: 0.1607
Epoch 6/10, Batch 40/97, Loss: 0.2552
Epoch 6/10, Batch 50/97, Loss: 0.2057
Epoch 6/10, Batch 60/97, Loss: 0.3377
Epoch 6/10, Batch 70/97, Loss: 0.1747
Epoch 6/10, Batch 80/97, Loss: 0.1304
Epoch 6/10, Batch 90/97, Loss: 0.2386
Epoch 6/10, Train Loss: 0.2461, Valid Loss: 0.2023
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2620
Epoch 7/10, Batch 20/97, Loss: 0.0593
Epoch 7/10, Batch 30/97, Loss: 0.2990
Epoch 7/10, Batch 40/97, Loss: 0.1991
Epoch 7/10, Batch 50/97, Loss: 0.1800
Epoch 7/10, Batch 60/97, Loss: 0.2872
Epoch 7/10, Batch 70/97, Loss: 0.4106
Epoch 7/10, Batch 80/97, Loss: 0.2379
Epoch 7/10, Batch 90/97, Loss: 0.2544
Epoch 7/10, Train Loss: 0.2439, Valid Loss: 0.1909
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1879
Epoch 8/10, Batch 20/97, Loss: 0.2282
Epoch 8/10, Batch 30/97, Loss: 0.2732
Epoch 8/10, Batch 40/97, Loss: 0.1536
Epoch 8/10, Batch 50/97, Loss: 0.4159
Epoch 8/10, Batch 60/97, Loss: 0.1566
Epoch 8/10, Batch 70/97, Loss: 0.3820
Epoch 8/10, Batch 80/97, Loss: 0.2012
Epoch 8/10, Batch 90/97, Loss: 0.1225
Epoch 8/10, Train Loss: 0.2286, Valid Loss: 0.1883
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1213
Epoch 9/10, Batch 20/97, Loss: 0.0960
Epoch 9/10, Batch 30/97, Loss: 0.2217
Epoch 9/10, Batch 40/97, Loss: 0.1143
Epoch 9/10, Batch 50/97, Loss: 0.1282
Epoch 9/10, Batch 60/97, Loss: 0.1405
Epoch 9/10, Batch 70/97, Loss: 0.1313
Epoch 9/10, Batch 80/97, Loss: 0.1765
Epoch 9/10, Batch 90/97, Loss: 0.2761
Epoch 9/10, Train Loss: 0.2134, Valid Loss: 0.1896
Epoch 10/10, Batch 10/97, Loss: 0.2286
Epoch 10/10, Batch 20/97, Loss: 0.2429
Epoch 10/10, Batch 30/97, Loss: 0.1541
Epoch 10/10, Batch 40/97, Loss: 0.2998
Epoch 10/10, Batch 50/97, Loss: 0.1978
Epoch 10/10, Batch 60/97, Loss: 0.1489
Epoch 10/10, Batch 70/97, Loss: 0.1801
Epoch 10/10, Batch 80/97, Loss: 0.2840
Epoch 10/10, Batch 90/97, Loss: 0.2233
Epoch 10/10, Train Loss: 0.2079, Valid Loss: 0.1761
Model saved!
Accuracy: 0.9171
Precision: 0.9138
Recall: 0.9171
F1-score: 0.9145
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4570
Epoch 1/10, Batch 20/97, Loss: 1.0248
Epoch 1/10, Batch 30/97, Loss: 0.8639
Epoch 1/10, Batch 40/97, Loss: 0.7657
Epoch 1/10, Batch 50/97, Loss: 0.7065
Epoch 1/10, Batch 60/97, Loss: 0.5256
Epoch 1/10, Batch 70/97, Loss: 0.6249
Epoch 1/10, Batch 80/97, Loss: 0.4614
Epoch 1/10, Batch 90/97, Loss: 0.4364
Epoch 1/10, Train Loss: 0.7760, Valid Loss: 0.4795
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4201
Epoch 2/10, Batch 20/97, Loss: 0.5334
Epoch 2/10, Batch 30/97, Loss: 0.4450
Epoch 2/10, Batch 40/97, Loss: 0.2665
Epoch 2/10, Batch 50/97, Loss: 0.5890
Epoch 2/10, Batch 60/97, Loss: 0.3288
Epoch 2/10, Batch 70/97, Loss: 0.3813
Epoch 2/10, Batch 80/97, Loss: 0.3795
Epoch 2/10, Batch 90/97, Loss: 0.3042
Epoch 2/10, Train Loss: 0.3990, Valid Loss: 0.3726
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4632
Epoch 3/10, Batch 20/97, Loss: 0.4087
Epoch 3/10, Batch 30/97, Loss: 0.2676
Epoch 3/10, Batch 40/97, Loss: 0.2984
Epoch 3/10, Batch 50/97, Loss: 0.4048
Epoch 3/10, Batch 60/97, Loss: 0.2264
Epoch 3/10, Batch 70/97, Loss: 0.2287
Epoch 3/10, Batch 80/97, Loss: 0.3324
Epoch 3/10, Batch 90/97, Loss: 0.1236
Epoch 3/10, Train Loss: 0.3289, Valid Loss: 0.3240
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3380
Epoch 4/10, Batch 20/97, Loss: 0.2332
Epoch 4/10, Batch 30/97, Loss: 0.2637
Epoch 4/10, Batch 40/97, Loss: 0.2218
Epoch 4/10, Batch 50/97, Loss: 0.2017
Epoch 4/10, Batch 60/97, Loss: 0.1498
Epoch 4/10, Batch 70/97, Loss: 0.2611
Epoch 4/10, Batch 80/97, Loss: 0.2322
Epoch 4/10, Batch 90/97, Loss: 0.3348
Epoch 4/10, Train Loss: 0.2906, Valid Loss: 0.2953
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1906
Epoch 5/10, Batch 20/97, Loss: 0.2270
Epoch 5/10, Batch 30/97, Loss: 0.2043
Epoch 5/10, Batch 40/97, Loss: 0.2159
Epoch 5/10, Batch 50/97, Loss: 0.3466
Epoch 5/10, Batch 60/97, Loss: 0.2004
Epoch 5/10, Batch 70/97, Loss: 0.2885
Epoch 5/10, Batch 80/97, Loss: 0.3865
Epoch 5/10, Batch 90/97, Loss: 0.4959
Epoch 5/10, Train Loss: 0.2652, Valid Loss: 0.2762
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1774
Epoch 6/10, Batch 20/97, Loss: 0.2580
Epoch 6/10, Batch 30/97, Loss: 0.3250
Epoch 6/10, Batch 40/97, Loss: 0.2331
Epoch 6/10, Batch 50/97, Loss: 0.2249
Epoch 6/10, Batch 60/97, Loss: 0.2975
Epoch 6/10, Batch 70/97, Loss: 0.3145
Epoch 6/10, Batch 80/97, Loss: 0.2601
Epoch 6/10, Batch 90/97, Loss: 0.2395
Epoch 6/10, Train Loss: 0.2473, Valid Loss: 0.2633
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3983
Epoch 7/10, Batch 20/97, Loss: 0.0660
Epoch 7/10, Batch 30/97, Loss: 0.2979
Epoch 7/10, Batch 40/97, Loss: 0.2095
Epoch 7/10, Batch 50/97, Loss: 0.3121
Epoch 7/10, Batch 60/97, Loss: 0.3102
Epoch 7/10, Batch 70/97, Loss: 0.1399
Epoch 7/10, Batch 80/97, Loss: 0.1611
Epoch 7/10, Batch 90/97, Loss: 0.2564
Epoch 7/10, Train Loss: 0.2492, Valid Loss: 0.2523
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1692
Epoch 8/10, Batch 20/97, Loss: 0.1578
Epoch 8/10, Batch 30/97, Loss: 0.1320
Epoch 8/10, Batch 40/97, Loss: 0.2205
Epoch 8/10, Batch 50/97, Loss: 0.2185
Epoch 8/10, Batch 60/97, Loss: 0.0888
Epoch 8/10, Batch 70/97, Loss: 0.2328
Epoch 8/10, Batch 80/97, Loss: 0.1038
Epoch 8/10, Batch 90/97, Loss: 0.2180
Epoch 8/10, Train Loss: 0.2251, Valid Loss: 0.2555
Epoch 9/10, Batch 10/97, Loss: 0.0507
Epoch 9/10, Batch 20/97, Loss: 0.1023
Epoch 9/10, Batch 30/97, Loss: 0.2666
Epoch 9/10, Batch 40/97, Loss: 0.0990
Epoch 9/10, Batch 50/97, Loss: 0.3658
Epoch 9/10, Batch 60/97, Loss: 0.1010
Epoch 9/10, Batch 70/97, Loss: 0.1830
Epoch 9/10, Batch 80/97, Loss: 0.1256
Epoch 9/10, Batch 90/97, Loss: 0.3279
Epoch 9/10, Train Loss: 0.2188, Valid Loss: 0.2385
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2761
Epoch 10/10, Batch 20/97, Loss: 0.2404
Epoch 10/10, Batch 30/97, Loss: 0.1860
Epoch 10/10, Batch 40/97, Loss: 0.2405
Epoch 10/10, Batch 50/97, Loss: 0.3719
Epoch 10/10, Batch 60/97, Loss: 0.2090
Epoch 10/10, Batch 70/97, Loss: 0.2184
Epoch 10/10, Batch 80/97, Loss: 0.2031
Epoch 10/10, Batch 90/97, Loss: 0.1346
Epoch 10/10, Train Loss: 0.2055, Valid Loss: 0.2346
Model saved!
Accuracy: 0.9206
Precision: 0.9185
Recall: 0.9206
F1-score: 0.9190
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4877
Epoch 1/10, Batch 20/97, Loss: 0.9954
Epoch 1/10, Batch 30/97, Loss: 0.8324
Epoch 1/10, Batch 40/97, Loss: 0.6441
Epoch 1/10, Batch 50/97, Loss: 0.6310
Epoch 1/10, Batch 60/97, Loss: 0.4972
Epoch 1/10, Batch 70/97, Loss: 0.5536
Epoch 1/10, Batch 80/97, Loss: 0.4560
Epoch 1/10, Batch 90/97, Loss: 0.5075
Epoch 1/10, Train Loss: 0.7718, Valid Loss: 0.4569
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3811
Epoch 2/10, Batch 20/97, Loss: 0.4830
Epoch 2/10, Batch 30/97, Loss: 0.4414
Epoch 2/10, Batch 40/97, Loss: 0.4124
Epoch 2/10, Batch 50/97, Loss: 0.6237
Epoch 2/10, Batch 60/97, Loss: 0.3508
Epoch 2/10, Batch 70/97, Loss: 0.4389
Epoch 2/10, Batch 80/97, Loss: 0.2893
Epoch 2/10, Batch 90/97, Loss: 0.2734
Epoch 2/10, Train Loss: 0.3951, Valid Loss: 0.3578
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3821
Epoch 3/10, Batch 20/97, Loss: 0.3541
Epoch 3/10, Batch 30/97, Loss: 0.3770
Epoch 3/10, Batch 40/97, Loss: 0.2399
Epoch 3/10, Batch 50/97, Loss: 0.2591
Epoch 3/10, Batch 60/97, Loss: 0.2234
Epoch 3/10, Batch 70/97, Loss: 0.2819
Epoch 3/10, Batch 80/97, Loss: 0.3898
Epoch 3/10, Batch 90/97, Loss: 0.3829
Epoch 3/10, Train Loss: 0.3231, Valid Loss: 0.3172
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3019
Epoch 4/10, Batch 20/97, Loss: 0.3372
Epoch 4/10, Batch 30/97, Loss: 0.4148
Epoch 4/10, Batch 40/97, Loss: 0.2281
Epoch 4/10, Batch 50/97, Loss: 0.1563
Epoch 4/10, Batch 60/97, Loss: 0.1424
Epoch 4/10, Batch 70/97, Loss: 0.3109
Epoch 4/10, Batch 80/97, Loss: 0.2738
Epoch 4/10, Batch 90/97, Loss: 0.3257
Epoch 4/10, Train Loss: 0.2842, Valid Loss: 0.2998
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2931
Epoch 5/10, Batch 20/97, Loss: 0.1771
Epoch 5/10, Batch 30/97, Loss: 0.1688
Epoch 5/10, Batch 40/97, Loss: 0.1644
Epoch 5/10, Batch 50/97, Loss: 0.3133
Epoch 5/10, Batch 60/97, Loss: 0.3033
Epoch 5/10, Batch 70/97, Loss: 0.1523
Epoch 5/10, Batch 80/97, Loss: 0.3823
Epoch 5/10, Batch 90/97, Loss: 0.2454
Epoch 5/10, Train Loss: 0.2591, Valid Loss: 0.2844
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2492
Epoch 6/10, Batch 20/97, Loss: 0.1655
Epoch 6/10, Batch 30/97, Loss: 0.1729
Epoch 6/10, Batch 40/97, Loss: 0.2128
Epoch 6/10, Batch 50/97, Loss: 0.2398
Epoch 6/10, Batch 60/97, Loss: 0.2554
Epoch 6/10, Batch 70/97, Loss: 0.1913
Epoch 6/10, Batch 80/97, Loss: 0.1492
Epoch 6/10, Batch 90/97, Loss: 0.3701
Epoch 6/10, Train Loss: 0.2379, Valid Loss: 0.2836
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3158
Epoch 7/10, Batch 20/97, Loss: 0.1787
Epoch 7/10, Batch 30/97, Loss: 0.1258
Epoch 7/10, Batch 40/97, Loss: 0.1895
Epoch 7/10, Batch 50/97, Loss: 0.1535
Epoch 7/10, Batch 60/97, Loss: 0.1443
Epoch 7/10, Batch 70/97, Loss: 0.0986
Epoch 7/10, Batch 80/97, Loss: 0.2174
Epoch 7/10, Batch 90/97, Loss: 0.2212
Epoch 7/10, Train Loss: 0.2399, Valid Loss: 0.2732
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1493
Epoch 8/10, Batch 20/97, Loss: 0.1242
Epoch 8/10, Batch 30/97, Loss: 0.1832
Epoch 8/10, Batch 40/97, Loss: 0.2910
Epoch 8/10, Batch 50/97, Loss: 0.2436
Epoch 8/10, Batch 60/97, Loss: 0.1516
Epoch 8/10, Batch 70/97, Loss: 0.3480
Epoch 8/10, Batch 80/97, Loss: 0.1473
Epoch 8/10, Batch 90/97, Loss: 0.0740
Epoch 8/10, Train Loss: 0.2189, Valid Loss: 0.2599
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1422
Epoch 9/10, Batch 20/97, Loss: 0.2203
Epoch 9/10, Batch 30/97, Loss: 0.2124
Epoch 9/10, Batch 40/97, Loss: 0.1315
Epoch 9/10, Batch 50/97, Loss: 0.2828
Epoch 9/10, Batch 60/97, Loss: 0.2498
Epoch 9/10, Batch 70/97, Loss: 0.1522
Epoch 9/10, Batch 80/97, Loss: 0.1689
Epoch 9/10, Batch 90/97, Loss: 0.2262
Epoch 9/10, Train Loss: 0.2078, Valid Loss: 0.2699
Epoch 10/10, Batch 10/97, Loss: 0.2310
Epoch 10/10, Batch 20/97, Loss: 0.2895
Epoch 10/10, Batch 30/97, Loss: 0.1686
Epoch 10/10, Batch 40/97, Loss: 0.1404
Epoch 10/10, Batch 50/97, Loss: 0.2936
Epoch 10/10, Batch 60/97, Loss: 0.2100
Epoch 10/10, Batch 70/97, Loss: 0.1727
Epoch 10/10, Batch 80/97, Loss: 0.2218
Epoch 10/10, Batch 90/97, Loss: 0.0999
Epoch 10/10, Train Loss: 0.1957, Valid Loss: 0.2646
Accuracy: 0.9124
Precision: 0.9089
Recall: 0.9124
F1-score: 0.9100
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5426
Epoch 1/10, Batch 20/97, Loss: 0.9387
Epoch 1/10, Batch 30/97, Loss: 0.8978
Epoch 1/10, Batch 40/97, Loss: 0.6991
Epoch 1/10, Batch 50/97, Loss: 0.6213
Epoch 1/10, Batch 60/97, Loss: 0.7375
Epoch 1/10, Batch 70/97, Loss: 0.4790
Epoch 1/10, Batch 80/97, Loss: 0.4502
Epoch 1/10, Batch 90/97, Loss: 0.4955
Epoch 1/10, Train Loss: 0.7799, Valid Loss: 0.4574
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3723
Epoch 2/10, Batch 20/97, Loss: 0.6474
Epoch 2/10, Batch 30/97, Loss: 0.3897
Epoch 2/10, Batch 40/97, Loss: 0.4441
Epoch 2/10, Batch 50/97, Loss: 0.6167
Epoch 2/10, Batch 60/97, Loss: 0.2772
Epoch 2/10, Batch 70/97, Loss: 0.3148
Epoch 2/10, Batch 80/97, Loss: 0.2536
Epoch 2/10, Batch 90/97, Loss: 0.4182
Epoch 2/10, Train Loss: 0.4054, Valid Loss: 0.3456
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2634
Epoch 3/10, Batch 20/97, Loss: 0.3636
Epoch 3/10, Batch 30/97, Loss: 0.2794
Epoch 3/10, Batch 40/97, Loss: 0.3080
Epoch 3/10, Batch 50/97, Loss: 0.2835
Epoch 3/10, Batch 60/97, Loss: 0.1927
Epoch 3/10, Batch 70/97, Loss: 0.2212
Epoch 3/10, Batch 80/97, Loss: 0.3461
Epoch 3/10, Batch 90/97, Loss: 0.3226
Epoch 3/10, Train Loss: 0.3328, Valid Loss: 0.3038
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4173
Epoch 4/10, Batch 20/97, Loss: 0.3475
Epoch 4/10, Batch 30/97, Loss: 0.3943
Epoch 4/10, Batch 40/97, Loss: 0.2109
Epoch 4/10, Batch 50/97, Loss: 0.2914
Epoch 4/10, Batch 60/97, Loss: 0.2746
Epoch 4/10, Batch 70/97, Loss: 0.2137
Epoch 4/10, Batch 80/97, Loss: 0.3324
Epoch 4/10, Batch 90/97, Loss: 0.2023
Epoch 4/10, Train Loss: 0.2926, Valid Loss: 0.2822
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2849
Epoch 5/10, Batch 20/97, Loss: 0.3367
Epoch 5/10, Batch 30/97, Loss: 0.1161
Epoch 5/10, Batch 40/97, Loss: 0.1242
Epoch 5/10, Batch 50/97, Loss: 0.1906
Epoch 5/10, Batch 60/97, Loss: 0.2316
Epoch 5/10, Batch 70/97, Loss: 0.1752
Epoch 5/10, Batch 80/97, Loss: 0.2523
Epoch 5/10, Batch 90/97, Loss: 0.4941
Epoch 5/10, Train Loss: 0.2694, Valid Loss: 0.2680
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2151
Epoch 6/10, Batch 20/97, Loss: 0.1580
Epoch 6/10, Batch 30/97, Loss: 0.2649
Epoch 6/10, Batch 40/97, Loss: 0.2647
Epoch 6/10, Batch 50/97, Loss: 0.1845
Epoch 6/10, Batch 60/97, Loss: 0.2176
Epoch 6/10, Batch 70/97, Loss: 0.3862
Epoch 6/10, Batch 80/97, Loss: 0.1649
Epoch 6/10, Batch 90/97, Loss: 0.3651
Epoch 6/10, Train Loss: 0.2443, Valid Loss: 0.2594
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.5934
Epoch 7/10, Batch 20/97, Loss: 0.1944
Epoch 7/10, Batch 30/97, Loss: 0.4117
Epoch 7/10, Batch 40/97, Loss: 0.1765
Epoch 7/10, Batch 50/97, Loss: 0.1960
Epoch 7/10, Batch 60/97, Loss: 0.2334
Epoch 7/10, Batch 70/97, Loss: 0.1424
Epoch 7/10, Batch 80/97, Loss: 0.1702
Epoch 7/10, Batch 90/97, Loss: 0.4057
Epoch 7/10, Train Loss: 0.2464, Valid Loss: 0.2590
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2487
Epoch 8/10, Batch 20/97, Loss: 0.1873
Epoch 8/10, Batch 30/97, Loss: 0.2066
Epoch 8/10, Batch 40/97, Loss: 0.2932
Epoch 8/10, Batch 50/97, Loss: 0.1965
Epoch 8/10, Batch 60/97, Loss: 0.3009
Epoch 8/10, Batch 70/97, Loss: 0.2153
Epoch 8/10, Batch 80/97, Loss: 0.1859
Epoch 8/10, Batch 90/97, Loss: 0.1726
Epoch 8/10, Train Loss: 0.2232, Valid Loss: 0.2550
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0876
Epoch 9/10, Batch 20/97, Loss: 0.1030
Epoch 9/10, Batch 30/97, Loss: 0.1802
Epoch 9/10, Batch 40/97, Loss: 0.0702
Epoch 9/10, Batch 50/97, Loss: 0.1575
Epoch 9/10, Batch 60/97, Loss: 0.1518
Epoch 9/10, Batch 70/97, Loss: 0.3430
Epoch 9/10, Batch 80/97, Loss: 0.1893
Epoch 9/10, Batch 90/97, Loss: 0.1206
Epoch 9/10, Train Loss: 0.2201, Valid Loss: 0.2529
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2731
Epoch 10/10, Batch 20/97, Loss: 0.1466
Epoch 10/10, Batch 30/97, Loss: 0.2336
Epoch 10/10, Batch 40/97, Loss: 0.1666
Epoch 10/10, Batch 50/97, Loss: 0.1808
Epoch 10/10, Batch 60/97, Loss: 0.0855
Epoch 10/10, Batch 70/97, Loss: 0.2859
Epoch 10/10, Batch 80/97, Loss: 0.1491
Epoch 10/10, Batch 90/97, Loss: 0.3815
Epoch 10/10, Train Loss: 0.1998, Valid Loss: 0.2516
Model saved!
Accuracy: 0.9206
Precision: 0.9191
Recall: 0.9206
F1-score: 0.9184
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4560
Epoch 1/10, Batch 20/97, Loss: 0.9862
Epoch 1/10, Batch 30/97, Loss: 0.8836
Epoch 1/10, Batch 40/97, Loss: 0.8683
Epoch 1/10, Batch 50/97, Loss: 0.7102
Epoch 1/10, Batch 60/97, Loss: 0.5919
Epoch 1/10, Batch 70/97, Loss: 0.4891
Epoch 1/10, Batch 80/97, Loss: 0.3646
Epoch 1/10, Batch 90/97, Loss: 0.5617
Epoch 1/10, Train Loss: 0.7705, Valid Loss: 0.4457
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3686
Epoch 2/10, Batch 20/97, Loss: 0.4381
Epoch 2/10, Batch 30/97, Loss: 0.4788
Epoch 2/10, Batch 40/97, Loss: 0.4170
Epoch 2/10, Batch 50/97, Loss: 0.6180
Epoch 2/10, Batch 60/97, Loss: 0.3224
Epoch 2/10, Batch 70/97, Loss: 0.3865
Epoch 2/10, Batch 80/97, Loss: 0.3647
Epoch 2/10, Batch 90/97, Loss: 0.3975
Epoch 2/10, Train Loss: 0.4050, Valid Loss: 0.3373
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2579
Epoch 3/10, Batch 20/97, Loss: 0.3077
Epoch 3/10, Batch 30/97, Loss: 0.3048
Epoch 3/10, Batch 40/97, Loss: 0.2659
Epoch 3/10, Batch 50/97, Loss: 0.3228
Epoch 3/10, Batch 60/97, Loss: 0.1817
Epoch 3/10, Batch 70/97, Loss: 0.1975
Epoch 3/10, Batch 80/97, Loss: 0.3973
Epoch 3/10, Batch 90/97, Loss: 0.3187
Epoch 3/10, Train Loss: 0.3312, Valid Loss: 0.2854
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2890
Epoch 4/10, Batch 20/97, Loss: 0.4609
Epoch 4/10, Batch 30/97, Loss: 0.2382
Epoch 4/10, Batch 40/97, Loss: 0.2347
Epoch 4/10, Batch 50/97, Loss: 0.2267
Epoch 4/10, Batch 60/97, Loss: 0.1099
Epoch 4/10, Batch 70/97, Loss: 0.3219
Epoch 4/10, Batch 80/97, Loss: 0.1965
Epoch 4/10, Batch 90/97, Loss: 0.3010
Epoch 4/10, Train Loss: 0.2899, Valid Loss: 0.2624
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2525
Epoch 5/10, Batch 20/97, Loss: 0.2439
Epoch 5/10, Batch 30/97, Loss: 0.1573
Epoch 5/10, Batch 40/97, Loss: 0.2526
Epoch 5/10, Batch 50/97, Loss: 0.2735
Epoch 5/10, Batch 60/97, Loss: 0.2147
Epoch 5/10, Batch 70/97, Loss: 0.3180
Epoch 5/10, Batch 80/97, Loss: 0.4354
Epoch 5/10, Batch 90/97, Loss: 0.4086
Epoch 5/10, Train Loss: 0.2641, Valid Loss: 0.2437
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2531
Epoch 6/10, Batch 20/97, Loss: 0.2085
Epoch 6/10, Batch 30/97, Loss: 0.2331
Epoch 6/10, Batch 40/97, Loss: 0.2833
Epoch 6/10, Batch 50/97, Loss: 0.2421
Epoch 6/10, Batch 60/97, Loss: 0.4478
Epoch 6/10, Batch 70/97, Loss: 0.4212
Epoch 6/10, Batch 80/97, Loss: 0.1838
Epoch 6/10, Batch 90/97, Loss: 0.1738
Epoch 6/10, Train Loss: 0.2453, Valid Loss: 0.2429
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2967
Epoch 7/10, Batch 20/97, Loss: 0.1184
Epoch 7/10, Batch 30/97, Loss: 0.1393
Epoch 7/10, Batch 40/97, Loss: 0.2490
Epoch 7/10, Batch 50/97, Loss: 0.2208
Epoch 7/10, Batch 60/97, Loss: 0.1763
Epoch 7/10, Batch 70/97, Loss: 0.1713
Epoch 7/10, Batch 80/97, Loss: 0.2089
Epoch 7/10, Batch 90/97, Loss: 0.3590
Epoch 7/10, Train Loss: 0.2363, Valid Loss: 0.2331
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2119
Epoch 8/10, Batch 20/97, Loss: 0.1340
Epoch 8/10, Batch 30/97, Loss: 0.1363
Epoch 8/10, Batch 40/97, Loss: 0.1831
Epoch 8/10, Batch 50/97, Loss: 0.2878
Epoch 8/10, Batch 60/97, Loss: 0.1315
Epoch 8/10, Batch 70/97, Loss: 0.2701
Epoch 8/10, Batch 80/97, Loss: 0.1359
Epoch 8/10, Batch 90/97, Loss: 0.1295
Epoch 8/10, Train Loss: 0.2218, Valid Loss: 0.2225
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0938
Epoch 9/10, Batch 20/97, Loss: 0.1066
Epoch 9/10, Batch 30/97, Loss: 0.2605
Epoch 9/10, Batch 40/97, Loss: 0.1379
Epoch 9/10, Batch 50/97, Loss: 0.3091
Epoch 9/10, Batch 60/97, Loss: 0.1996
Epoch 9/10, Batch 70/97, Loss: 0.2973
Epoch 9/10, Batch 80/97, Loss: 0.2347
Epoch 9/10, Batch 90/97, Loss: 0.2079
Epoch 9/10, Train Loss: 0.2178, Valid Loss: 0.2179
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2678
Epoch 10/10, Batch 20/97, Loss: 0.1261
Epoch 10/10, Batch 30/97, Loss: 0.1775
Epoch 10/10, Batch 40/97, Loss: 0.3099
Epoch 10/10, Batch 50/97, Loss: 0.2335
Epoch 10/10, Batch 60/97, Loss: 0.1965
Epoch 10/10, Batch 70/97, Loss: 0.1265
Epoch 10/10, Batch 80/97, Loss: 0.1626
Epoch 10/10, Batch 90/97, Loss: 0.1450
Epoch 10/10, Train Loss: 0.2058, Valid Loss: 0.2145
Model saved!
Accuracy: 0.9241
Precision: 0.9226
Recall: 0.9241
F1-score: 0.9233
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4967
Epoch 1/10, Batch 20/97, Loss: 1.0069
Epoch 1/10, Batch 30/97, Loss: 0.9310
Epoch 1/10, Batch 40/97, Loss: 0.7850
Epoch 1/10, Batch 50/97, Loss: 0.6009
Epoch 1/10, Batch 60/97, Loss: 0.6699
Epoch 1/10, Batch 70/97, Loss: 0.4826
Epoch 1/10, Batch 80/97, Loss: 0.4470
Epoch 1/10, Batch 90/97, Loss: 0.6057
Epoch 1/10, Train Loss: 0.7720, Valid Loss: 0.4510
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4539
Epoch 2/10, Batch 20/97, Loss: 0.5109
Epoch 2/10, Batch 30/97, Loss: 0.3594
Epoch 2/10, Batch 40/97, Loss: 0.4366
Epoch 2/10, Batch 50/97, Loss: 0.5215
Epoch 2/10, Batch 60/97, Loss: 0.2213
Epoch 2/10, Batch 70/97, Loss: 0.2615
Epoch 2/10, Batch 80/97, Loss: 0.3711
Epoch 2/10, Batch 90/97, Loss: 0.4183
Epoch 2/10, Train Loss: 0.3933, Valid Loss: 0.3491
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3125
Epoch 3/10, Batch 20/97, Loss: 0.4264
Epoch 3/10, Batch 30/97, Loss: 0.2017
Epoch 3/10, Batch 40/97, Loss: 0.3277
Epoch 3/10, Batch 50/97, Loss: 0.2303
Epoch 3/10, Batch 60/97, Loss: 0.2346
Epoch 3/10, Batch 70/97, Loss: 0.1546
Epoch 3/10, Batch 80/97, Loss: 0.2850
Epoch 3/10, Batch 90/97, Loss: 0.2369
Epoch 3/10, Train Loss: 0.3231, Valid Loss: 0.3085
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2228
Epoch 4/10, Batch 20/97, Loss: 0.2067
Epoch 4/10, Batch 30/97, Loss: 0.3972
Epoch 4/10, Batch 40/97, Loss: 0.3680
Epoch 4/10, Batch 50/97, Loss: 0.2003
Epoch 4/10, Batch 60/97, Loss: 0.1467
Epoch 4/10, Batch 70/97, Loss: 0.1504
Epoch 4/10, Batch 80/97, Loss: 0.2225
Epoch 4/10, Batch 90/97, Loss: 0.2963
Epoch 4/10, Train Loss: 0.2843, Valid Loss: 0.2839
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2962
Epoch 5/10, Batch 20/97, Loss: 0.2149
Epoch 5/10, Batch 30/97, Loss: 0.3002
Epoch 5/10, Batch 40/97, Loss: 0.1713
Epoch 5/10, Batch 50/97, Loss: 0.1454
Epoch 5/10, Batch 60/97, Loss: 0.2896
Epoch 5/10, Batch 70/97, Loss: 0.2258
Epoch 5/10, Batch 80/97, Loss: 0.3253
Epoch 5/10, Batch 90/97, Loss: 0.3386
Epoch 5/10, Train Loss: 0.2589, Valid Loss: 0.2732
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1923
Epoch 6/10, Batch 20/97, Loss: 0.1253
Epoch 6/10, Batch 30/97, Loss: 0.2039
Epoch 6/10, Batch 40/97, Loss: 0.2441
Epoch 6/10, Batch 50/97, Loss: 0.1925
Epoch 6/10, Batch 60/97, Loss: 0.2580
Epoch 6/10, Batch 70/97, Loss: 0.3025
Epoch 6/10, Batch 80/97, Loss: 0.1893
Epoch 6/10, Batch 90/97, Loss: 0.2917
Epoch 6/10, Train Loss: 0.2344, Valid Loss: 0.2602
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2283
Epoch 7/10, Batch 20/97, Loss: 0.2470
Epoch 7/10, Batch 30/97, Loss: 0.1684
Epoch 7/10, Batch 40/97, Loss: 0.2965
Epoch 7/10, Batch 50/97, Loss: 0.1660
Epoch 7/10, Batch 60/97, Loss: 0.2284
Epoch 7/10, Batch 70/97, Loss: 0.1720
Epoch 7/10, Batch 80/97, Loss: 0.1024
Epoch 7/10, Batch 90/97, Loss: 0.4582
Epoch 7/10, Train Loss: 0.2427, Valid Loss: 0.2565
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2017
Epoch 8/10, Batch 20/97, Loss: 0.1576
Epoch 8/10, Batch 30/97, Loss: 0.1107
Epoch 8/10, Batch 40/97, Loss: 0.2926
Epoch 8/10, Batch 50/97, Loss: 0.2556
Epoch 8/10, Batch 60/97, Loss: 0.0826
Epoch 8/10, Batch 70/97, Loss: 0.2718
Epoch 8/10, Batch 80/97, Loss: 0.3439
Epoch 8/10, Batch 90/97, Loss: 0.1357
Epoch 8/10, Train Loss: 0.2146, Valid Loss: 0.2581
Epoch 9/10, Batch 10/97, Loss: 0.1780
Epoch 9/10, Batch 20/97, Loss: 0.1445
Epoch 9/10, Batch 30/97, Loss: 0.2418
Epoch 9/10, Batch 40/97, Loss: 0.1516
Epoch 9/10, Batch 50/97, Loss: 0.1436
Epoch 9/10, Batch 60/97, Loss: 0.1924
Epoch 9/10, Batch 70/97, Loss: 0.1995
Epoch 9/10, Batch 80/97, Loss: 0.1220
Epoch 9/10, Batch 90/97, Loss: 0.3061
Epoch 9/10, Train Loss: 0.2042, Valid Loss: 0.2490
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2550
Epoch 10/10, Batch 20/97, Loss: 0.1031
Epoch 10/10, Batch 30/97, Loss: 0.1897
Epoch 10/10, Batch 40/97, Loss: 0.2674
Epoch 10/10, Batch 50/97, Loss: 0.2863
Epoch 10/10, Batch 60/97, Loss: 0.1810
Epoch 10/10, Batch 70/97, Loss: 0.0943
Epoch 10/10, Batch 80/97, Loss: 0.3032
Epoch 10/10, Batch 90/97, Loss: 0.1654
Epoch 10/10, Train Loss: 0.1911, Valid Loss: 0.2422
Model saved!
Accuracy: 0.9206
Precision: 0.9189
Recall: 0.9206
F1-score: 0.9191
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4731
Epoch 1/10, Batch 20/97, Loss: 0.9644
Epoch 1/10, Batch 30/97, Loss: 0.9051
Epoch 1/10, Batch 40/97, Loss: 0.6956
Epoch 1/10, Batch 50/97, Loss: 0.6603
Epoch 1/10, Batch 60/97, Loss: 0.5910
Epoch 1/10, Batch 70/97, Loss: 0.4707
Epoch 1/10, Batch 80/97, Loss: 0.5012
Epoch 1/10, Batch 90/97, Loss: 0.5901
Epoch 1/10, Train Loss: 0.7749, Valid Loss: 0.4139
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3153
Epoch 2/10, Batch 20/97, Loss: 0.4442
Epoch 2/10, Batch 30/97, Loss: 0.5243
Epoch 2/10, Batch 40/97, Loss: 0.4161
Epoch 2/10, Batch 50/97, Loss: 0.7128
Epoch 2/10, Batch 60/97, Loss: 0.3721
Epoch 2/10, Batch 70/97, Loss: 0.3491
Epoch 2/10, Batch 80/97, Loss: 0.2455
Epoch 2/10, Batch 90/97, Loss: 0.4165
Epoch 2/10, Train Loss: 0.3920, Valid Loss: 0.3142
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3738
Epoch 3/10, Batch 20/97, Loss: 0.2632
Epoch 3/10, Batch 30/97, Loss: 0.2387
Epoch 3/10, Batch 40/97, Loss: 0.4153
Epoch 3/10, Batch 50/97, Loss: 0.3022
Epoch 3/10, Batch 60/97, Loss: 0.3344
Epoch 3/10, Batch 70/97, Loss: 0.2194
Epoch 3/10, Batch 80/97, Loss: 0.2785
Epoch 3/10, Batch 90/97, Loss: 0.3370
Epoch 3/10, Train Loss: 0.3210, Valid Loss: 0.2720
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2992
Epoch 4/10, Batch 20/97, Loss: 0.2576
Epoch 4/10, Batch 30/97, Loss: 0.4505
Epoch 4/10, Batch 40/97, Loss: 0.3573
Epoch 4/10, Batch 50/97, Loss: 0.1772
Epoch 4/10, Batch 60/97, Loss: 0.1777
Epoch 4/10, Batch 70/97, Loss: 0.2897
Epoch 4/10, Batch 80/97, Loss: 0.2696
Epoch 4/10, Batch 90/97, Loss: 0.2050
Epoch 4/10, Train Loss: 0.2800, Valid Loss: 0.2646
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2355
Epoch 5/10, Batch 20/97, Loss: 0.1651
Epoch 5/10, Batch 30/97, Loss: 0.2846
Epoch 5/10, Batch 40/97, Loss: 0.2392
Epoch 5/10, Batch 50/97, Loss: 0.2050
Epoch 5/10, Batch 60/97, Loss: 0.2497
Epoch 5/10, Batch 70/97, Loss: 0.2534
Epoch 5/10, Batch 80/97, Loss: 0.2899
Epoch 5/10, Batch 90/97, Loss: 0.3315
Epoch 5/10, Train Loss: 0.2589, Valid Loss: 0.2468
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1655
Epoch 6/10, Batch 20/97, Loss: 0.2031
Epoch 6/10, Batch 30/97, Loss: 0.1740
Epoch 6/10, Batch 40/97, Loss: 0.3095
Epoch 6/10, Batch 50/97, Loss: 0.1937
Epoch 6/10, Batch 60/97, Loss: 0.2456
Epoch 6/10, Batch 70/97, Loss: 0.2456
Epoch 6/10, Batch 80/97, Loss: 0.1396
Epoch 6/10, Batch 90/97, Loss: 0.3248
Epoch 6/10, Train Loss: 0.2303, Valid Loss: 0.2459
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2372
Epoch 7/10, Batch 20/97, Loss: 0.2389
Epoch 7/10, Batch 30/97, Loss: 0.2361
Epoch 7/10, Batch 40/97, Loss: 0.2224
Epoch 7/10, Batch 50/97, Loss: 0.3015
Epoch 7/10, Batch 60/97, Loss: 0.4308
Epoch 7/10, Batch 70/97, Loss: 0.1459
Epoch 7/10, Batch 80/97, Loss: 0.1503
Epoch 7/10, Batch 90/97, Loss: 0.2007
Epoch 7/10, Train Loss: 0.2352, Valid Loss: 0.2333
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1127
Epoch 8/10, Batch 20/97, Loss: 0.2505
Epoch 8/10, Batch 30/97, Loss: 0.1815
Epoch 8/10, Batch 40/97, Loss: 0.1851
Epoch 8/10, Batch 50/97, Loss: 0.2143
Epoch 8/10, Batch 60/97, Loss: 0.0872
Epoch 8/10, Batch 70/97, Loss: 0.2836
Epoch 8/10, Batch 80/97, Loss: 0.1404
Epoch 8/10, Batch 90/97, Loss: 0.1958
Epoch 8/10, Train Loss: 0.2086, Valid Loss: 0.2287
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1625
Epoch 9/10, Batch 20/97, Loss: 0.1239
Epoch 9/10, Batch 30/97, Loss: 0.3294
Epoch 9/10, Batch 40/97, Loss: 0.1709
Epoch 9/10, Batch 50/97, Loss: 0.2274
Epoch 9/10, Batch 60/97, Loss: 0.0868
Epoch 9/10, Batch 70/97, Loss: 0.1268
Epoch 9/10, Batch 80/97, Loss: 0.1805
Epoch 9/10, Batch 90/97, Loss: 0.1070
Epoch 9/10, Train Loss: 0.2007, Valid Loss: 0.2298
Epoch 10/10, Batch 10/97, Loss: 0.2102
Epoch 10/10, Batch 20/97, Loss: 0.0866
Epoch 10/10, Batch 30/97, Loss: 0.1378
Epoch 10/10, Batch 40/97, Loss: 0.1580
Epoch 10/10, Batch 50/97, Loss: 0.2302
Epoch 10/10, Batch 60/97, Loss: 0.2495
Epoch 10/10, Batch 70/97, Loss: 0.1563
Epoch 10/10, Batch 80/97, Loss: 0.2669
Epoch 10/10, Batch 90/97, Loss: 0.1077
Epoch 10/10, Train Loss: 0.1921, Valid Loss: 0.2298
Accuracy: 0.9147
Precision: 0.9129
Recall: 0.9147
F1-score: 0.9129
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4036
Epoch 1/10, Batch 20/97, Loss: 0.9226
Epoch 1/10, Batch 30/97, Loss: 0.9015
Epoch 1/10, Batch 40/97, Loss: 0.7827
Epoch 1/10, Batch 50/97, Loss: 0.5590
Epoch 1/10, Batch 60/97, Loss: 0.5454
Epoch 1/10, Batch 70/97, Loss: 0.5016
Epoch 1/10, Batch 80/97, Loss: 0.6220
Epoch 1/10, Batch 90/97, Loss: 0.5570
Epoch 1/10, Train Loss: 0.7716, Valid Loss: 0.4355
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4469
Epoch 2/10, Batch 20/97, Loss: 0.4352
Epoch 2/10, Batch 30/97, Loss: 0.4503
Epoch 2/10, Batch 40/97, Loss: 0.5797
Epoch 2/10, Batch 50/97, Loss: 0.5487
Epoch 2/10, Batch 60/97, Loss: 0.3648
Epoch 2/10, Batch 70/97, Loss: 0.2823
Epoch 2/10, Batch 80/97, Loss: 0.2718
Epoch 2/10, Batch 90/97, Loss: 0.3238
Epoch 2/10, Train Loss: 0.3978, Valid Loss: 0.3286
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4771
Epoch 3/10, Batch 20/97, Loss: 0.2847
Epoch 3/10, Batch 30/97, Loss: 0.2821
Epoch 3/10, Batch 40/97, Loss: 0.2574
Epoch 3/10, Batch 50/97, Loss: 0.3082
Epoch 3/10, Batch 60/97, Loss: 0.2482
Epoch 3/10, Batch 70/97, Loss: 0.2368
Epoch 3/10, Batch 80/97, Loss: 0.2982
Epoch 3/10, Batch 90/97, Loss: 0.3691
Epoch 3/10, Train Loss: 0.3202, Valid Loss: 0.2818
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3170
Epoch 4/10, Batch 20/97, Loss: 0.2555
Epoch 4/10, Batch 30/97, Loss: 0.2745
Epoch 4/10, Batch 40/97, Loss: 0.2526
Epoch 4/10, Batch 50/97, Loss: 0.2538
Epoch 4/10, Batch 60/97, Loss: 0.2152
Epoch 4/10, Batch 70/97, Loss: 0.2659
Epoch 4/10, Batch 80/97, Loss: 0.2319
Epoch 4/10, Batch 90/97, Loss: 0.1814
Epoch 4/10, Train Loss: 0.2803, Valid Loss: 0.2578
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3119
Epoch 5/10, Batch 20/97, Loss: 0.2337
Epoch 5/10, Batch 30/97, Loss: 0.1891
Epoch 5/10, Batch 40/97, Loss: 0.1992
Epoch 5/10, Batch 50/97, Loss: 0.2614
Epoch 5/10, Batch 60/97, Loss: 0.2457
Epoch 5/10, Batch 70/97, Loss: 0.2006
Epoch 5/10, Batch 80/97, Loss: 0.2380
Epoch 5/10, Batch 90/97, Loss: 0.1861
Epoch 5/10, Train Loss: 0.2534, Valid Loss: 0.2542
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3708
Epoch 6/10, Batch 20/97, Loss: 0.2289
Epoch 6/10, Batch 30/97, Loss: 0.1459
Epoch 6/10, Batch 40/97, Loss: 0.3127
Epoch 6/10, Batch 50/97, Loss: 0.2579
Epoch 6/10, Batch 60/97, Loss: 0.2290
Epoch 6/10, Batch 70/97, Loss: 0.2002
Epoch 6/10, Batch 80/97, Loss: 0.1621
Epoch 6/10, Batch 90/97, Loss: 0.2499
Epoch 6/10, Train Loss: 0.2429, Valid Loss: 0.2327
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3471
Epoch 7/10, Batch 20/97, Loss: 0.1918
Epoch 7/10, Batch 30/97, Loss: 0.2025
Epoch 7/10, Batch 40/97, Loss: 0.1278
Epoch 7/10, Batch 50/97, Loss: 0.3139
Epoch 7/10, Batch 60/97, Loss: 0.2884
Epoch 7/10, Batch 70/97, Loss: 0.2697
Epoch 7/10, Batch 80/97, Loss: 0.2321
Epoch 7/10, Batch 90/97, Loss: 0.2601
Epoch 7/10, Train Loss: 0.2477, Valid Loss: 0.2339
Epoch 8/10, Batch 10/97, Loss: 0.1279
Epoch 8/10, Batch 20/97, Loss: 0.1835
Epoch 8/10, Batch 30/97, Loss: 0.1126
Epoch 8/10, Batch 40/97, Loss: 0.1922
Epoch 8/10, Batch 50/97, Loss: 0.1601
Epoch 8/10, Batch 60/97, Loss: 0.2266
Epoch 8/10, Batch 70/97, Loss: 0.1966
Epoch 8/10, Batch 80/97, Loss: 0.1179
Epoch 8/10, Batch 90/97, Loss: 0.1131
Epoch 8/10, Train Loss: 0.2148, Valid Loss: 0.2109
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1536
Epoch 9/10, Batch 20/97, Loss: 0.1667
Epoch 9/10, Batch 30/97, Loss: 0.3588
Epoch 9/10, Batch 40/97, Loss: 0.2281
Epoch 9/10, Batch 50/97, Loss: 0.4008
Epoch 9/10, Batch 60/97, Loss: 0.3060
Epoch 9/10, Batch 70/97, Loss: 0.2326
Epoch 9/10, Batch 80/97, Loss: 0.3549
Epoch 9/10, Batch 90/97, Loss: 0.2557
Epoch 9/10, Train Loss: 0.2110, Valid Loss: 0.2129
Epoch 10/10, Batch 10/97, Loss: 0.2373
Epoch 10/10, Batch 20/97, Loss: 0.1383
Epoch 10/10, Batch 30/97, Loss: 0.1493
Epoch 10/10, Batch 40/97, Loss: 0.2291
Epoch 10/10, Batch 50/97, Loss: 0.2883
Epoch 10/10, Batch 60/97, Loss: 0.2049
Epoch 10/10, Batch 70/97, Loss: 0.2572
Epoch 10/10, Batch 80/97, Loss: 0.2024
Epoch 10/10, Batch 90/97, Loss: 0.1149
Epoch 10/10, Train Loss: 0.2036, Valid Loss: 0.2052
Model saved!
Accuracy: 0.9159
Precision: 0.9141
Recall: 0.9159
F1-score: 0.9144
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4978
Epoch 1/10, Batch 20/97, Loss: 1.0916
Epoch 1/10, Batch 30/97, Loss: 0.8206
Epoch 1/10, Batch 40/97, Loss: 0.6998
Epoch 1/10, Batch 50/97, Loss: 0.6630
Epoch 1/10, Batch 60/97, Loss: 0.6876
Epoch 1/10, Batch 70/97, Loss: 0.4307
Epoch 1/10, Batch 80/97, Loss: 0.4964
Epoch 1/10, Batch 90/97, Loss: 0.5242
Epoch 1/10, Train Loss: 0.7764, Valid Loss: 0.4396
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4393
Epoch 2/10, Batch 20/97, Loss: 0.4626
Epoch 2/10, Batch 30/97, Loss: 0.4729
Epoch 2/10, Batch 40/97, Loss: 0.4230
Epoch 2/10, Batch 50/97, Loss: 0.6704
Epoch 2/10, Batch 60/97, Loss: 0.4698
Epoch 2/10, Batch 70/97, Loss: 0.2260
Epoch 2/10, Batch 80/97, Loss: 0.2715
Epoch 2/10, Batch 90/97, Loss: 0.2650
Epoch 2/10, Train Loss: 0.4019, Valid Loss: 0.3237
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3623
Epoch 3/10, Batch 20/97, Loss: 0.3070
Epoch 3/10, Batch 30/97, Loss: 0.2279
Epoch 3/10, Batch 40/97, Loss: 0.2518
Epoch 3/10, Batch 50/97, Loss: 0.2759
Epoch 3/10, Batch 60/97, Loss: 0.2562
Epoch 3/10, Batch 70/97, Loss: 0.1962
Epoch 3/10, Batch 80/97, Loss: 0.4057
Epoch 3/10, Batch 90/97, Loss: 0.1880
Epoch 3/10, Train Loss: 0.3274, Valid Loss: 0.2769
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1924
Epoch 4/10, Batch 20/97, Loss: 0.2102
Epoch 4/10, Batch 30/97, Loss: 0.2467
Epoch 4/10, Batch 40/97, Loss: 0.2473
Epoch 4/10, Batch 50/97, Loss: 0.1712
Epoch 4/10, Batch 60/97, Loss: 0.1522
Epoch 4/10, Batch 70/97, Loss: 0.1741
Epoch 4/10, Batch 80/97, Loss: 0.2012
Epoch 4/10, Batch 90/97, Loss: 0.2273
Epoch 4/10, Train Loss: 0.2887, Valid Loss: 0.2566
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1800
Epoch 5/10, Batch 20/97, Loss: 0.1752
Epoch 5/10, Batch 30/97, Loss: 0.2185
Epoch 5/10, Batch 40/97, Loss: 0.3543
Epoch 5/10, Batch 50/97, Loss: 0.2064
Epoch 5/10, Batch 60/97, Loss: 0.1546
Epoch 5/10, Batch 70/97, Loss: 0.2665
Epoch 5/10, Batch 80/97, Loss: 0.3142
Epoch 5/10, Batch 90/97, Loss: 0.2741
Epoch 5/10, Train Loss: 0.2662, Valid Loss: 0.2491
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2547
Epoch 6/10, Batch 20/97, Loss: 0.2312
Epoch 6/10, Batch 30/97, Loss: 0.2696
Epoch 6/10, Batch 40/97, Loss: 0.3002
Epoch 6/10, Batch 50/97, Loss: 0.1784
Epoch 6/10, Batch 60/97, Loss: 0.3236
Epoch 6/10, Batch 70/97, Loss: 0.3649
Epoch 6/10, Batch 80/97, Loss: 0.1725
Epoch 6/10, Batch 90/97, Loss: 0.3461
Epoch 6/10, Train Loss: 0.2490, Valid Loss: 0.2293
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2319
Epoch 7/10, Batch 20/97, Loss: 0.1978
Epoch 7/10, Batch 30/97, Loss: 0.1796
Epoch 7/10, Batch 40/97, Loss: 0.2846
Epoch 7/10, Batch 50/97, Loss: 0.2771
Epoch 7/10, Batch 60/97, Loss: 0.3548
Epoch 7/10, Batch 70/97, Loss: 0.1933
Epoch 7/10, Batch 80/97, Loss: 0.3072
Epoch 7/10, Batch 90/97, Loss: 0.2738
Epoch 7/10, Train Loss: 0.2410, Valid Loss: 0.2221
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.3348
Epoch 8/10, Batch 20/97, Loss: 0.0951
Epoch 8/10, Batch 30/97, Loss: 0.2084
Epoch 8/10, Batch 40/97, Loss: 0.1348
Epoch 8/10, Batch 50/97, Loss: 0.3216
Epoch 8/10, Batch 60/97, Loss: 0.1173
Epoch 8/10, Batch 70/97, Loss: 0.2184
Epoch 8/10, Batch 80/97, Loss: 0.1880
Epoch 8/10, Batch 90/97, Loss: 0.1466
Epoch 8/10, Train Loss: 0.2175, Valid Loss: 0.2132
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0999
Epoch 9/10, Batch 20/97, Loss: 0.1745
Epoch 9/10, Batch 30/97, Loss: 0.3066
Epoch 9/10, Batch 40/97, Loss: 0.1704
Epoch 9/10, Batch 50/97, Loss: 0.2970
Epoch 9/10, Batch 60/97, Loss: 0.2795
Epoch 9/10, Batch 70/97, Loss: 0.1066
Epoch 9/10, Batch 80/97, Loss: 0.2055
Epoch 9/10, Batch 90/97, Loss: 0.2205
Epoch 9/10, Train Loss: 0.2114, Valid Loss: 0.2097
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2379
Epoch 10/10, Batch 20/97, Loss: 0.0805
Epoch 10/10, Batch 30/97, Loss: 0.1898
Epoch 10/10, Batch 40/97, Loss: 0.1404
Epoch 10/10, Batch 50/97, Loss: 0.2566
Epoch 10/10, Batch 60/97, Loss: 0.1559
Epoch 10/10, Batch 70/97, Loss: 0.1535
Epoch 10/10, Batch 80/97, Loss: 0.2208
Epoch 10/10, Batch 90/97, Loss: 0.1512
Epoch 10/10, Train Loss: 0.1963, Valid Loss: 0.2038
Model saved!
Accuracy: 0.9182
Precision: 0.9162
Recall: 0.9182
F1-score: 0.9170
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5708
Epoch 1/10, Batch 20/97, Loss: 1.0846
Epoch 1/10, Batch 30/97, Loss: 0.9128
Epoch 1/10, Batch 40/97, Loss: 0.7569
Epoch 1/10, Batch 50/97, Loss: 0.5587
Epoch 1/10, Batch 60/97, Loss: 0.6508
Epoch 1/10, Batch 70/97, Loss: 0.5615
Epoch 1/10, Batch 80/97, Loss: 0.3562
Epoch 1/10, Batch 90/97, Loss: 0.6031
Epoch 1/10, Train Loss: 0.7723, Valid Loss: 0.4403
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4587
Epoch 2/10, Batch 20/97, Loss: 0.4991
Epoch 2/10, Batch 30/97, Loss: 0.4625
Epoch 2/10, Batch 40/97, Loss: 0.2959
Epoch 2/10, Batch 50/97, Loss: 0.5318
Epoch 2/10, Batch 60/97, Loss: 0.5343
Epoch 2/10, Batch 70/97, Loss: 0.2801
Epoch 2/10, Batch 80/97, Loss: 0.2007
Epoch 2/10, Batch 90/97, Loss: 0.3267
Epoch 2/10, Train Loss: 0.3924, Valid Loss: 0.3502
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2979
Epoch 3/10, Batch 20/97, Loss: 0.2227
Epoch 3/10, Batch 30/97, Loss: 0.2148
Epoch 3/10, Batch 40/97, Loss: 0.3140
Epoch 3/10, Batch 50/97, Loss: 0.1992
Epoch 3/10, Batch 60/97, Loss: 0.2568
Epoch 3/10, Batch 70/97, Loss: 0.2876
Epoch 3/10, Batch 80/97, Loss: 0.2169
Epoch 3/10, Batch 90/97, Loss: 0.3792
Epoch 3/10, Train Loss: 0.3160, Valid Loss: 0.3090
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3109
Epoch 4/10, Batch 20/97, Loss: 0.2154
Epoch 4/10, Batch 30/97, Loss: 0.3074
Epoch 4/10, Batch 40/97, Loss: 0.4043
Epoch 4/10, Batch 50/97, Loss: 0.2006
Epoch 4/10, Batch 60/97, Loss: 0.0814
Epoch 4/10, Batch 70/97, Loss: 0.1807
Epoch 4/10, Batch 80/97, Loss: 0.2610
Epoch 4/10, Batch 90/97, Loss: 0.2045
Epoch 4/10, Train Loss: 0.2759, Valid Loss: 0.2887
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3304
Epoch 5/10, Batch 20/97, Loss: 0.2061
Epoch 5/10, Batch 30/97, Loss: 0.1825
Epoch 5/10, Batch 40/97, Loss: 0.3566
Epoch 5/10, Batch 50/97, Loss: 0.3490
Epoch 5/10, Batch 60/97, Loss: 0.2041
Epoch 5/10, Batch 70/97, Loss: 0.1881
Epoch 5/10, Batch 80/97, Loss: 0.4824
Epoch 5/10, Batch 90/97, Loss: 0.3017
Epoch 5/10, Train Loss: 0.2495, Valid Loss: 0.2752
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1369
Epoch 6/10, Batch 20/97, Loss: 0.4166
Epoch 6/10, Batch 30/97, Loss: 0.2000
Epoch 6/10, Batch 40/97, Loss: 0.2905
Epoch 6/10, Batch 50/97, Loss: 0.1544
Epoch 6/10, Batch 60/97, Loss: 0.3001
Epoch 6/10, Batch 70/97, Loss: 0.2348
Epoch 6/10, Batch 80/97, Loss: 0.1666
Epoch 6/10, Batch 90/97, Loss: 0.3346
Epoch 6/10, Train Loss: 0.2218, Valid Loss: 0.2690
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3122
Epoch 7/10, Batch 20/97, Loss: 0.1920
Epoch 7/10, Batch 30/97, Loss: 0.0943
Epoch 7/10, Batch 40/97, Loss: 0.2545
Epoch 7/10, Batch 50/97, Loss: 0.1354
Epoch 7/10, Batch 60/97, Loss: 0.1868
Epoch 7/10, Batch 70/97, Loss: 0.2117
Epoch 7/10, Batch 80/97, Loss: 0.1571
Epoch 7/10, Batch 90/97, Loss: 0.2872
Epoch 7/10, Train Loss: 0.2331, Valid Loss: 0.2610
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1765
Epoch 8/10, Batch 20/97, Loss: 0.2304
Epoch 8/10, Batch 30/97, Loss: 0.0851
Epoch 8/10, Batch 40/97, Loss: 0.1274
Epoch 8/10, Batch 50/97, Loss: 0.2063
Epoch 8/10, Batch 60/97, Loss: 0.1515
Epoch 8/10, Batch 70/97, Loss: 0.2554
Epoch 8/10, Batch 80/97, Loss: 0.2598
Epoch 8/10, Batch 90/97, Loss: 0.1232
Epoch 8/10, Train Loss: 0.2124, Valid Loss: 0.2583
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1836
Epoch 9/10, Batch 20/97, Loss: 0.1299
Epoch 9/10, Batch 30/97, Loss: 0.3204
Epoch 9/10, Batch 40/97, Loss: 0.1412
Epoch 9/10, Batch 50/97, Loss: 0.2427
Epoch 9/10, Batch 60/97, Loss: 0.1834
Epoch 9/10, Batch 70/97, Loss: 0.2176
Epoch 9/10, Batch 80/97, Loss: 0.2035
Epoch 9/10, Batch 90/97, Loss: 0.1579
Epoch 9/10, Train Loss: 0.2001, Valid Loss: 0.2567
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2968
Epoch 10/10, Batch 20/97, Loss: 0.1483
Epoch 10/10, Batch 30/97, Loss: 0.1657
Epoch 10/10, Batch 40/97, Loss: 0.2178
Epoch 10/10, Batch 50/97, Loss: 0.1267
Epoch 10/10, Batch 60/97, Loss: 0.1606
Epoch 10/10, Batch 70/97, Loss: 0.2364
Epoch 10/10, Batch 80/97, Loss: 0.0621
Epoch 10/10, Batch 90/97, Loss: 0.1242
Epoch 10/10, Train Loss: 0.1795, Valid Loss: 0.2598
Accuracy: 0.9182
Precision: 0.9160
Recall: 0.9182
F1-score: 0.9166
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4714
Epoch 1/10, Batch 20/97, Loss: 0.9877
Epoch 1/10, Batch 30/97, Loss: 0.9406
Epoch 1/10, Batch 40/97, Loss: 0.7317
Epoch 1/10, Batch 50/97, Loss: 0.6225
Epoch 1/10, Batch 60/97, Loss: 0.6093
Epoch 1/10, Batch 70/97, Loss: 0.4309
Epoch 1/10, Batch 80/97, Loss: 0.5295
Epoch 1/10, Batch 90/97, Loss: 0.4028
Epoch 1/10, Train Loss: 0.7728, Valid Loss: 0.4247
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3479
Epoch 2/10, Batch 20/97, Loss: 0.3812
Epoch 2/10, Batch 30/97, Loss: 0.2965
Epoch 2/10, Batch 40/97, Loss: 0.4256
Epoch 2/10, Batch 50/97, Loss: 0.4887
Epoch 2/10, Batch 60/97, Loss: 0.2865
Epoch 2/10, Batch 70/97, Loss: 0.2600
Epoch 2/10, Batch 80/97, Loss: 0.2925
Epoch 2/10, Batch 90/97, Loss: 0.2790
Epoch 2/10, Train Loss: 0.3873, Valid Loss: 0.3171
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2568
Epoch 3/10, Batch 20/97, Loss: 0.2188
Epoch 3/10, Batch 30/97, Loss: 0.2477
Epoch 3/10, Batch 40/97, Loss: 0.2856
Epoch 3/10, Batch 50/97, Loss: 0.3288
Epoch 3/10, Batch 60/97, Loss: 0.2771
Epoch 3/10, Batch 70/97, Loss: 0.3572
Epoch 3/10, Batch 80/97, Loss: 0.2614
Epoch 3/10, Batch 90/97, Loss: 0.3030
Epoch 3/10, Train Loss: 0.3165, Valid Loss: 0.2699
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2833
Epoch 4/10, Batch 20/97, Loss: 0.2428
Epoch 4/10, Batch 30/97, Loss: 0.3314
Epoch 4/10, Batch 40/97, Loss: 0.2666
Epoch 4/10, Batch 50/97, Loss: 0.2497
Epoch 4/10, Batch 60/97, Loss: 0.1037
Epoch 4/10, Batch 70/97, Loss: 0.2878
Epoch 4/10, Batch 80/97, Loss: 0.1560
Epoch 4/10, Batch 90/97, Loss: 0.2107
Epoch 4/10, Train Loss: 0.2729, Valid Loss: 0.2501
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3461
Epoch 5/10, Batch 20/97, Loss: 0.1290
Epoch 5/10, Batch 30/97, Loss: 0.1642
Epoch 5/10, Batch 40/97, Loss: 0.1888
Epoch 5/10, Batch 50/97, Loss: 0.2576
Epoch 5/10, Batch 60/97, Loss: 0.2491
Epoch 5/10, Batch 70/97, Loss: 0.1646
Epoch 5/10, Batch 80/97, Loss: 0.1887
Epoch 5/10, Batch 90/97, Loss: 0.3892
Epoch 5/10, Train Loss: 0.2566, Valid Loss: 0.2334
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2024
Epoch 6/10, Batch 20/97, Loss: 0.2075
Epoch 6/10, Batch 30/97, Loss: 0.1154
Epoch 6/10, Batch 40/97, Loss: 0.2740
Epoch 6/10, Batch 50/97, Loss: 0.1580
Epoch 6/10, Batch 60/97, Loss: 0.2612
Epoch 6/10, Batch 70/97, Loss: 0.2683
Epoch 6/10, Batch 80/97, Loss: 0.1247
Epoch 6/10, Batch 90/97, Loss: 0.2616
Epoch 6/10, Train Loss: 0.2379, Valid Loss: 0.2315
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2808
Epoch 7/10, Batch 20/97, Loss: 0.1403
Epoch 7/10, Batch 30/97, Loss: 0.1773
Epoch 7/10, Batch 40/97, Loss: 0.1873
Epoch 7/10, Batch 50/97, Loss: 0.2978
Epoch 7/10, Batch 60/97, Loss: 0.2099
Epoch 7/10, Batch 70/97, Loss: 0.1143
Epoch 7/10, Batch 80/97, Loss: 0.1560
Epoch 7/10, Batch 90/97, Loss: 0.2151
Epoch 7/10, Train Loss: 0.2375, Valid Loss: 0.2183
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1528
Epoch 8/10, Batch 20/97, Loss: 0.2574
Epoch 8/10, Batch 30/97, Loss: 0.1600
Epoch 8/10, Batch 40/97, Loss: 0.1083
Epoch 8/10, Batch 50/97, Loss: 0.1891
Epoch 8/10, Batch 60/97, Loss: 0.1528
Epoch 8/10, Batch 70/97, Loss: 0.3578
Epoch 8/10, Batch 80/97, Loss: 0.2038
Epoch 8/10, Batch 90/97, Loss: 0.2474
Epoch 8/10, Train Loss: 0.2147, Valid Loss: 0.2162
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1860
Epoch 9/10, Batch 20/97, Loss: 0.1634
Epoch 9/10, Batch 30/97, Loss: 0.2873
Epoch 9/10, Batch 40/97, Loss: 0.1483
Epoch 9/10, Batch 50/97, Loss: 0.4142
Epoch 9/10, Batch 60/97, Loss: 0.2264
Epoch 9/10, Batch 70/97, Loss: 0.1177
Epoch 9/10, Batch 80/97, Loss: 0.2574
Epoch 9/10, Batch 90/97, Loss: 0.2292
Epoch 9/10, Train Loss: 0.1962, Valid Loss: 0.2112
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2820
Epoch 10/10, Batch 20/97, Loss: 0.1216
Epoch 10/10, Batch 30/97, Loss: 0.1970
Epoch 10/10, Batch 40/97, Loss: 0.2551
Epoch 10/10, Batch 50/97, Loss: 0.3053
Epoch 10/10, Batch 60/97, Loss: 0.1631
Epoch 10/10, Batch 70/97, Loss: 0.2185
Epoch 10/10, Batch 80/97, Loss: 0.1392
Epoch 10/10, Batch 90/97, Loss: 0.1819
Epoch 10/10, Train Loss: 0.1924, Valid Loss: 0.2036
Model saved!
Accuracy: 0.9217
Precision: 0.9203
Recall: 0.9217
F1-score: 0.9209
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4907
Epoch 1/10, Batch 20/97, Loss: 0.9821
Epoch 1/10, Batch 30/97, Loss: 0.8934
Epoch 1/10, Batch 40/97, Loss: 0.8181
Epoch 1/10, Batch 50/97, Loss: 0.5976
Epoch 1/10, Batch 60/97, Loss: 0.5499
Epoch 1/10, Batch 70/97, Loss: 0.4675
Epoch 1/10, Batch 80/97, Loss: 0.5272
Epoch 1/10, Batch 90/97, Loss: 0.4688
Epoch 1/10, Train Loss: 0.7691, Valid Loss: 0.4392
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5811
Epoch 2/10, Batch 20/97, Loss: 0.3924
Epoch 2/10, Batch 30/97, Loss: 0.4186
Epoch 2/10, Batch 40/97, Loss: 0.4534
Epoch 2/10, Batch 50/97, Loss: 0.6102
Epoch 2/10, Batch 60/97, Loss: 0.2090
Epoch 2/10, Batch 70/97, Loss: 0.2992
Epoch 2/10, Batch 80/97, Loss: 0.3409
Epoch 2/10, Batch 90/97, Loss: 0.3626
Epoch 2/10, Train Loss: 0.3969, Valid Loss: 0.3430
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2346
Epoch 3/10, Batch 20/97, Loss: 0.2389
Epoch 3/10, Batch 30/97, Loss: 0.2133
Epoch 3/10, Batch 40/97, Loss: 0.2599
Epoch 3/10, Batch 50/97, Loss: 0.3133
Epoch 3/10, Batch 60/97, Loss: 0.2831
Epoch 3/10, Batch 70/97, Loss: 0.2151
Epoch 3/10, Batch 80/97, Loss: 0.3101
Epoch 3/10, Batch 90/97, Loss: 0.4460
Epoch 3/10, Train Loss: 0.3182, Valid Loss: 0.3054
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2606
Epoch 4/10, Batch 20/97, Loss: 0.3742
Epoch 4/10, Batch 30/97, Loss: 0.3312
Epoch 4/10, Batch 40/97, Loss: 0.4328
Epoch 4/10, Batch 50/97, Loss: 0.2702
Epoch 4/10, Batch 60/97, Loss: 0.2280
Epoch 4/10, Batch 70/97, Loss: 0.2099
Epoch 4/10, Batch 80/97, Loss: 0.2809
Epoch 4/10, Batch 90/97, Loss: 0.2358
Epoch 4/10, Train Loss: 0.2790, Valid Loss: 0.2827
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2177
Epoch 5/10, Batch 20/97, Loss: 0.1124
Epoch 5/10, Batch 30/97, Loss: 0.1515
Epoch 5/10, Batch 40/97, Loss: 0.1507
Epoch 5/10, Batch 50/97, Loss: 0.2284
Epoch 5/10, Batch 60/97, Loss: 0.2276
Epoch 5/10, Batch 70/97, Loss: 0.2720
Epoch 5/10, Batch 80/97, Loss: 0.2451
Epoch 5/10, Batch 90/97, Loss: 0.2960
Epoch 5/10, Train Loss: 0.2598, Valid Loss: 0.2726
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1872
Epoch 6/10, Batch 20/97, Loss: 0.2061
Epoch 6/10, Batch 30/97, Loss: 0.2437
Epoch 6/10, Batch 40/97, Loss: 0.2603
Epoch 6/10, Batch 50/97, Loss: 0.2047
Epoch 6/10, Batch 60/97, Loss: 0.1836
Epoch 6/10, Batch 70/97, Loss: 0.2095
Epoch 6/10, Batch 80/97, Loss: 0.1098
Epoch 6/10, Batch 90/97, Loss: 0.2305
Epoch 6/10, Train Loss: 0.2370, Valid Loss: 0.2672
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.1771
Epoch 7/10, Batch 20/97, Loss: 0.1632
Epoch 7/10, Batch 30/97, Loss: 0.1017
Epoch 7/10, Batch 40/97, Loss: 0.1525
Epoch 7/10, Batch 50/97, Loss: 0.3082
Epoch 7/10, Batch 60/97, Loss: 0.2759
Epoch 7/10, Batch 70/97, Loss: 0.1521
Epoch 7/10, Batch 80/97, Loss: 0.1541
Epoch 7/10, Batch 90/97, Loss: 0.2061
Epoch 7/10, Train Loss: 0.2350, Valid Loss: 0.2535
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2088
Epoch 8/10, Batch 20/97, Loss: 0.2001
Epoch 8/10, Batch 30/97, Loss: 0.1274
Epoch 8/10, Batch 40/97, Loss: 0.1018
Epoch 8/10, Batch 50/97, Loss: 0.1695
Epoch 8/10, Batch 60/97, Loss: 0.1419
Epoch 8/10, Batch 70/97, Loss: 0.1814
Epoch 8/10, Batch 80/97, Loss: 0.1075
Epoch 8/10, Batch 90/97, Loss: 0.2150
Epoch 8/10, Train Loss: 0.2105, Valid Loss: 0.2451
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1698
Epoch 9/10, Batch 20/97, Loss: 0.1575
Epoch 9/10, Batch 30/97, Loss: 0.2255
Epoch 9/10, Batch 40/97, Loss: 0.3066
Epoch 9/10, Batch 50/97, Loss: 0.2031
Epoch 9/10, Batch 60/97, Loss: 0.3551
Epoch 9/10, Batch 70/97, Loss: 0.2592
Epoch 9/10, Batch 80/97, Loss: 0.1679
Epoch 9/10, Batch 90/97, Loss: 0.1100
Epoch 9/10, Train Loss: 0.2047, Valid Loss: 0.2483
Epoch 10/10, Batch 10/97, Loss: 0.2387
Epoch 10/10, Batch 20/97, Loss: 0.1694
Epoch 10/10, Batch 30/97, Loss: 0.1376
Epoch 10/10, Batch 40/97, Loss: 0.2189
Epoch 10/10, Batch 50/97, Loss: 0.3505
Epoch 10/10, Batch 60/97, Loss: 0.0999
Epoch 10/10, Batch 70/97, Loss: 0.2239
Epoch 10/10, Batch 80/97, Loss: 0.2401
Epoch 10/10, Batch 90/97, Loss: 0.1070
Epoch 10/10, Train Loss: 0.1941, Valid Loss: 0.2371
Model saved!
Accuracy: 0.9171
Precision: 0.9147
Recall: 0.9171
F1-score: 0.9149
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4364
Epoch 1/10, Batch 20/97, Loss: 1.0333
Epoch 1/10, Batch 30/97, Loss: 0.8849
Epoch 1/10, Batch 40/97, Loss: 0.6704
Epoch 1/10, Batch 50/97, Loss: 0.6851
Epoch 1/10, Batch 60/97, Loss: 0.6693
Epoch 1/10, Batch 70/97, Loss: 0.4801
Epoch 1/10, Batch 80/97, Loss: 0.5791
Epoch 1/10, Batch 90/97, Loss: 0.4174
Epoch 1/10, Train Loss: 0.7772, Valid Loss: 0.4297
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3481
Epoch 2/10, Batch 20/97, Loss: 0.4228
Epoch 2/10, Batch 30/97, Loss: 0.4590
Epoch 2/10, Batch 40/97, Loss: 0.4814
Epoch 2/10, Batch 50/97, Loss: 0.6057
Epoch 2/10, Batch 60/97, Loss: 0.3838
Epoch 2/10, Batch 70/97, Loss: 0.3149
Epoch 2/10, Batch 80/97, Loss: 0.2280
Epoch 2/10, Batch 90/97, Loss: 0.3901
Epoch 2/10, Train Loss: 0.3918, Valid Loss: 0.3308
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2390
Epoch 3/10, Batch 20/97, Loss: 0.2344
Epoch 3/10, Batch 30/97, Loss: 0.2619
Epoch 3/10, Batch 40/97, Loss: 0.2756
Epoch 3/10, Batch 50/97, Loss: 0.2972
Epoch 3/10, Batch 60/97, Loss: 0.1981
Epoch 3/10, Batch 70/97, Loss: 0.1716
Epoch 3/10, Batch 80/97, Loss: 0.3417
Epoch 3/10, Batch 90/97, Loss: 0.2455
Epoch 3/10, Train Loss: 0.3299, Valid Loss: 0.2848
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2845
Epoch 4/10, Batch 20/97, Loss: 0.3654
Epoch 4/10, Batch 30/97, Loss: 0.3325
Epoch 4/10, Batch 40/97, Loss: 0.1623
Epoch 4/10, Batch 50/97, Loss: 0.2177
Epoch 4/10, Batch 60/97, Loss: 0.1718
Epoch 4/10, Batch 70/97, Loss: 0.2446
Epoch 4/10, Batch 80/97, Loss: 0.2576
Epoch 4/10, Batch 90/97, Loss: 0.3790
Epoch 4/10, Train Loss: 0.2834, Valid Loss: 0.2701
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2261
Epoch 5/10, Batch 20/97, Loss: 0.1483
Epoch 5/10, Batch 30/97, Loss: 0.2803
Epoch 5/10, Batch 40/97, Loss: 0.0922
Epoch 5/10, Batch 50/97, Loss: 0.2491
Epoch 5/10, Batch 60/97, Loss: 0.2263
Epoch 5/10, Batch 70/97, Loss: 0.2080
Epoch 5/10, Batch 80/97, Loss: 0.2004
Epoch 5/10, Batch 90/97, Loss: 0.3992
Epoch 5/10, Train Loss: 0.2620, Valid Loss: 0.2552
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2666
Epoch 6/10, Batch 20/97, Loss: 0.2268
Epoch 6/10, Batch 30/97, Loss: 0.2706
Epoch 6/10, Batch 40/97, Loss: 0.3177
Epoch 6/10, Batch 50/97, Loss: 0.2073
Epoch 6/10, Batch 60/97, Loss: 0.2579
Epoch 6/10, Batch 70/97, Loss: 0.2653
Epoch 6/10, Batch 80/97, Loss: 0.1904
Epoch 6/10, Batch 90/97, Loss: 0.2137
Epoch 6/10, Train Loss: 0.2385, Valid Loss: 0.2470
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2195
Epoch 7/10, Batch 20/97, Loss: 0.1704
Epoch 7/10, Batch 30/97, Loss: 0.2610
Epoch 7/10, Batch 40/97, Loss: 0.1822
Epoch 7/10, Batch 50/97, Loss: 0.2678
Epoch 7/10, Batch 60/97, Loss: 0.1839
Epoch 7/10, Batch 70/97, Loss: 0.1908
Epoch 7/10, Batch 80/97, Loss: 0.2418
Epoch 7/10, Batch 90/97, Loss: 0.4234
Epoch 7/10, Train Loss: 0.2488, Valid Loss: 0.2347
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1409
Epoch 8/10, Batch 20/97, Loss: 0.1451
Epoch 8/10, Batch 30/97, Loss: 0.1030
Epoch 8/10, Batch 40/97, Loss: 0.2691
Epoch 8/10, Batch 50/97, Loss: 0.1575
Epoch 8/10, Batch 60/97, Loss: 0.1204
Epoch 8/10, Batch 70/97, Loss: 0.1851
Epoch 8/10, Batch 80/97, Loss: 0.1334
Epoch 8/10, Batch 90/97, Loss: 0.1784
Epoch 8/10, Train Loss: 0.2137, Valid Loss: 0.2372
Epoch 9/10, Batch 10/97, Loss: 0.1481
Epoch 9/10, Batch 20/97, Loss: 0.1611
Epoch 9/10, Batch 30/97, Loss: 0.2401
Epoch 9/10, Batch 40/97, Loss: 0.1982
Epoch 9/10, Batch 50/97, Loss: 0.1784
Epoch 9/10, Batch 60/97, Loss: 0.2237
Epoch 9/10, Batch 70/97, Loss: 0.1799
Epoch 9/10, Batch 80/97, Loss: 0.1419
Epoch 9/10, Batch 90/97, Loss: 0.2715
Epoch 9/10, Train Loss: 0.2092, Valid Loss: 0.2374
Epoch 10/10, Batch 10/97, Loss: 0.1482
Epoch 10/10, Batch 20/97, Loss: 0.1571
Epoch 10/10, Batch 30/97, Loss: 0.1148
Epoch 10/10, Batch 40/97, Loss: 0.2066
Epoch 10/10, Batch 50/97, Loss: 0.4448
Epoch 10/10, Batch 60/97, Loss: 0.2094
Epoch 10/10, Batch 70/97, Loss: 0.1403
Epoch 10/10, Batch 80/97, Loss: 0.1306
Epoch 10/10, Batch 90/97, Loss: 0.1959
Epoch 10/10, Train Loss: 0.1993, Valid Loss: 0.2279
Model saved!
Accuracy: 0.9206
Precision: 0.9182
Recall: 0.9206
F1-score: 0.9189
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4811
Epoch 1/10, Batch 20/97, Loss: 1.0811
Epoch 1/10, Batch 30/97, Loss: 0.7799
Epoch 1/10, Batch 40/97, Loss: 0.7817
Epoch 1/10, Batch 50/97, Loss: 0.5296
Epoch 1/10, Batch 60/97, Loss: 0.7123
Epoch 1/10, Batch 70/97, Loss: 0.5948
Epoch 1/10, Batch 80/97, Loss: 0.4238
Epoch 1/10, Batch 90/97, Loss: 0.4133
Epoch 1/10, Train Loss: 0.7703, Valid Loss: 0.4253
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3986
Epoch 2/10, Batch 20/97, Loss: 0.4497
Epoch 2/10, Batch 30/97, Loss: 0.3377
Epoch 2/10, Batch 40/97, Loss: 0.5269
Epoch 2/10, Batch 50/97, Loss: 0.5523
Epoch 2/10, Batch 60/97, Loss: 0.4399
Epoch 2/10, Batch 70/97, Loss: 0.2585
Epoch 2/10, Batch 80/97, Loss: 0.3248
Epoch 2/10, Batch 90/97, Loss: 0.3458
Epoch 2/10, Train Loss: 0.3949, Valid Loss: 0.3184
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2784
Epoch 3/10, Batch 20/97, Loss: 0.2418
Epoch 3/10, Batch 30/97, Loss: 0.3434
Epoch 3/10, Batch 40/97, Loss: 0.1773
Epoch 3/10, Batch 50/97, Loss: 0.3942
Epoch 3/10, Batch 60/97, Loss: 0.2002
Epoch 3/10, Batch 70/97, Loss: 0.2261
Epoch 3/10, Batch 80/97, Loss: 0.4314
Epoch 3/10, Batch 90/97, Loss: 0.2125
Epoch 3/10, Train Loss: 0.3196, Valid Loss: 0.2785
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2021
Epoch 4/10, Batch 20/97, Loss: 0.4053
Epoch 4/10, Batch 30/97, Loss: 0.4261
Epoch 4/10, Batch 40/97, Loss: 0.4659
Epoch 4/10, Batch 50/97, Loss: 0.1649
Epoch 4/10, Batch 60/97, Loss: 0.1405
Epoch 4/10, Batch 70/97, Loss: 0.2251
Epoch 4/10, Batch 80/97, Loss: 0.2920
Epoch 4/10, Batch 90/97, Loss: 0.2968
Epoch 4/10, Train Loss: 0.2847, Valid Loss: 0.2562
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1474
Epoch 5/10, Batch 20/97, Loss: 0.2631
Epoch 5/10, Batch 30/97, Loss: 0.2267
Epoch 5/10, Batch 40/97, Loss: 0.1482
Epoch 5/10, Batch 50/97, Loss: 0.2050
Epoch 5/10, Batch 60/97, Loss: 0.2867
Epoch 5/10, Batch 70/97, Loss: 0.2094
Epoch 5/10, Batch 80/97, Loss: 0.4264
Epoch 5/10, Batch 90/97, Loss: 0.2988
Epoch 5/10, Train Loss: 0.2598, Valid Loss: 0.2410
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2404
Epoch 6/10, Batch 20/97, Loss: 0.2866
Epoch 6/10, Batch 30/97, Loss: 0.3130
Epoch 6/10, Batch 40/97, Loss: 0.2480
Epoch 6/10, Batch 50/97, Loss: 0.2282
Epoch 6/10, Batch 60/97, Loss: 0.2038
Epoch 6/10, Batch 70/97, Loss: 0.2584
Epoch 6/10, Batch 80/97, Loss: 0.2118
Epoch 6/10, Batch 90/97, Loss: 0.1773
Epoch 6/10, Train Loss: 0.2378, Valid Loss: 0.2336
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3133
Epoch 7/10, Batch 20/97, Loss: 0.1706
Epoch 7/10, Batch 30/97, Loss: 0.2139
Epoch 7/10, Batch 40/97, Loss: 0.1616
Epoch 7/10, Batch 50/97, Loss: 0.2454
Epoch 7/10, Batch 60/97, Loss: 0.2608
Epoch 7/10, Batch 70/97, Loss: 0.2519
Epoch 7/10, Batch 80/97, Loss: 0.2088
Epoch 7/10, Batch 90/97, Loss: 0.3803
Epoch 7/10, Train Loss: 0.2385, Valid Loss: 0.2163
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1175
Epoch 8/10, Batch 20/97, Loss: 0.1357
Epoch 8/10, Batch 30/97, Loss: 0.1461
Epoch 8/10, Batch 40/97, Loss: 0.1940
Epoch 8/10, Batch 50/97, Loss: 0.1783
Epoch 8/10, Batch 60/97, Loss: 0.1069
Epoch 8/10, Batch 70/97, Loss: 0.2933
Epoch 8/10, Batch 80/97, Loss: 0.1200
Epoch 8/10, Batch 90/97, Loss: 0.2148
Epoch 8/10, Train Loss: 0.2177, Valid Loss: 0.2127
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1405
Epoch 9/10, Batch 20/97, Loss: 0.1403
Epoch 9/10, Batch 30/97, Loss: 0.1899
Epoch 9/10, Batch 40/97, Loss: 0.1604
Epoch 9/10, Batch 50/97, Loss: 0.1726
Epoch 9/10, Batch 60/97, Loss: 0.1992
Epoch 9/10, Batch 70/97, Loss: 0.3220
Epoch 9/10, Batch 80/97, Loss: 0.1721
Epoch 9/10, Batch 90/97, Loss: 0.3311
Epoch 9/10, Train Loss: 0.2046, Valid Loss: 0.2106
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2290
Epoch 10/10, Batch 20/97, Loss: 0.2203
Epoch 10/10, Batch 30/97, Loss: 0.1909
Epoch 10/10, Batch 40/97, Loss: 0.4691
Epoch 10/10, Batch 50/97, Loss: 0.2142
Epoch 10/10, Batch 60/97, Loss: 0.1206
Epoch 10/10, Batch 70/97, Loss: 0.2594
Epoch 10/10, Batch 80/97, Loss: 0.3119
Epoch 10/10, Batch 90/97, Loss: 0.1629
Epoch 10/10, Train Loss: 0.1931, Valid Loss: 0.2027
Model saved!
Accuracy: 0.9252
Precision: 0.9237
Recall: 0.9252
F1-score: 0.9243
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5722
Epoch 1/10, Batch 20/97, Loss: 1.0110
Epoch 1/10, Batch 30/97, Loss: 0.9520
Epoch 1/10, Batch 40/97, Loss: 0.6736
Epoch 1/10, Batch 50/97, Loss: 0.5740
Epoch 1/10, Batch 60/97, Loss: 0.5822
Epoch 1/10, Batch 70/97, Loss: 0.4723
Epoch 1/10, Batch 80/97, Loss: 0.5244
Epoch 1/10, Batch 90/97, Loss: 0.5488
Epoch 1/10, Train Loss: 0.7818, Valid Loss: 0.4524
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4120
Epoch 2/10, Batch 20/97, Loss: 0.5523
Epoch 2/10, Batch 30/97, Loss: 0.4850
Epoch 2/10, Batch 40/97, Loss: 0.3903
Epoch 2/10, Batch 50/97, Loss: 0.5125
Epoch 2/10, Batch 60/97, Loss: 0.2861
Epoch 2/10, Batch 70/97, Loss: 0.4150
Epoch 2/10, Batch 80/97, Loss: 0.3207
Epoch 2/10, Batch 90/97, Loss: 0.2424
Epoch 2/10, Train Loss: 0.3939, Valid Loss: 0.3405
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2527
Epoch 3/10, Batch 20/97, Loss: 0.2841
Epoch 3/10, Batch 30/97, Loss: 0.2593
Epoch 3/10, Batch 40/97, Loss: 0.1869
Epoch 3/10, Batch 50/97, Loss: 0.2558
Epoch 3/10, Batch 60/97, Loss: 0.1880
Epoch 3/10, Batch 70/97, Loss: 0.3487
Epoch 3/10, Batch 80/97, Loss: 0.3425
Epoch 3/10, Batch 90/97, Loss: 0.2598
Epoch 3/10, Train Loss: 0.3231, Valid Loss: 0.2999
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2629
Epoch 4/10, Batch 20/97, Loss: 0.2411
Epoch 4/10, Batch 30/97, Loss: 0.3646
Epoch 4/10, Batch 40/97, Loss: 0.2197
Epoch 4/10, Batch 50/97, Loss: 0.1922
Epoch 4/10, Batch 60/97, Loss: 0.0910
Epoch 4/10, Batch 70/97, Loss: 0.1652
Epoch 4/10, Batch 80/97, Loss: 0.3556
Epoch 4/10, Batch 90/97, Loss: 0.2512
Epoch 4/10, Train Loss: 0.2790, Valid Loss: 0.2776
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2347
Epoch 5/10, Batch 20/97, Loss: 0.2509
Epoch 5/10, Batch 30/97, Loss: 0.1454
Epoch 5/10, Batch 40/97, Loss: 0.1440
Epoch 5/10, Batch 50/97, Loss: 0.1144
Epoch 5/10, Batch 60/97, Loss: 0.3246
Epoch 5/10, Batch 70/97, Loss: 0.2021
Epoch 5/10, Batch 80/97, Loss: 0.3046
Epoch 5/10, Batch 90/97, Loss: 0.3880
Epoch 5/10, Train Loss: 0.2605, Valid Loss: 0.2651
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2739
Epoch 6/10, Batch 20/97, Loss: 0.2007
Epoch 6/10, Batch 30/97, Loss: 0.1796
Epoch 6/10, Batch 40/97, Loss: 0.2773
Epoch 6/10, Batch 50/97, Loss: 0.1640
Epoch 6/10, Batch 60/97, Loss: 0.1977
Epoch 6/10, Batch 70/97, Loss: 0.2297
Epoch 6/10, Batch 80/97, Loss: 0.2169
Epoch 6/10, Batch 90/97, Loss: 0.1965
Epoch 6/10, Train Loss: 0.2379, Valid Loss: 0.2549
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2716
Epoch 7/10, Batch 20/97, Loss: 0.1374
Epoch 7/10, Batch 30/97, Loss: 0.1459
Epoch 7/10, Batch 40/97, Loss: 0.2591
Epoch 7/10, Batch 50/97, Loss: 0.2499
Epoch 7/10, Batch 60/97, Loss: 0.4762
Epoch 7/10, Batch 70/97, Loss: 0.2995
Epoch 7/10, Batch 80/97, Loss: 0.1644
Epoch 7/10, Batch 90/97, Loss: 0.2733
Epoch 7/10, Train Loss: 0.2414, Valid Loss: 0.2488
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1716
Epoch 8/10, Batch 20/97, Loss: 0.1683
Epoch 8/10, Batch 30/97, Loss: 0.1523
Epoch 8/10, Batch 40/97, Loss: 0.1582
Epoch 8/10, Batch 50/97, Loss: 0.1395
Epoch 8/10, Batch 60/97, Loss: 0.1271
Epoch 8/10, Batch 70/97, Loss: 0.1566
Epoch 8/10, Batch 80/97, Loss: 0.1286
Epoch 8/10, Batch 90/97, Loss: 0.1546
Epoch 8/10, Train Loss: 0.2117, Valid Loss: 0.2414
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1623
Epoch 9/10, Batch 20/97, Loss: 0.1453
Epoch 9/10, Batch 30/97, Loss: 0.3173
Epoch 9/10, Batch 40/97, Loss: 0.0506
Epoch 9/10, Batch 50/97, Loss: 0.1997
Epoch 9/10, Batch 60/97, Loss: 0.2390
Epoch 9/10, Batch 70/97, Loss: 0.2066
Epoch 9/10, Batch 80/97, Loss: 0.1981
Epoch 9/10, Batch 90/97, Loss: 0.1477
Epoch 9/10, Train Loss: 0.2045, Valid Loss: 0.2391
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3762
Epoch 10/10, Batch 20/97, Loss: 0.2157
Epoch 10/10, Batch 30/97, Loss: 0.2437
Epoch 10/10, Batch 40/97, Loss: 0.2014
Epoch 10/10, Batch 50/97, Loss: 0.2239
Epoch 10/10, Batch 60/97, Loss: 0.1394
Epoch 10/10, Batch 70/97, Loss: 0.1191
Epoch 10/10, Batch 80/97, Loss: 0.4050
Epoch 10/10, Batch 90/97, Loss: 0.1697
Epoch 10/10, Train Loss: 0.1991, Valid Loss: 0.2369
Model saved!
Accuracy: 0.9241
Precision: 0.9226
Recall: 0.9241
F1-score: 0.9227
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4101
Epoch 1/10, Batch 20/97, Loss: 1.0219
Epoch 1/10, Batch 30/97, Loss: 0.8980
Epoch 1/10, Batch 40/97, Loss: 0.6725
Epoch 1/10, Batch 50/97, Loss: 0.5808
Epoch 1/10, Batch 60/97, Loss: 0.6266
Epoch 1/10, Batch 70/97, Loss: 0.4431
Epoch 1/10, Batch 80/97, Loss: 0.4218
Epoch 1/10, Batch 90/97, Loss: 0.6034
Epoch 1/10, Train Loss: 0.7731, Valid Loss: 0.4435
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3407
Epoch 2/10, Batch 20/97, Loss: 0.3895
Epoch 2/10, Batch 30/97, Loss: 0.4892
Epoch 2/10, Batch 40/97, Loss: 0.3954
Epoch 2/10, Batch 50/97, Loss: 0.5315
Epoch 2/10, Batch 60/97, Loss: 0.3978
Epoch 2/10, Batch 70/97, Loss: 0.2852
Epoch 2/10, Batch 80/97, Loss: 0.3608
Epoch 2/10, Batch 90/97, Loss: 0.3739
Epoch 2/10, Train Loss: 0.3904, Valid Loss: 0.3296
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2741
Epoch 3/10, Batch 20/97, Loss: 0.3239
Epoch 3/10, Batch 30/97, Loss: 0.1918
Epoch 3/10, Batch 40/97, Loss: 0.1616
Epoch 3/10, Batch 50/97, Loss: 0.3756
Epoch 3/10, Batch 60/97, Loss: 0.2865
Epoch 3/10, Batch 70/97, Loss: 0.2784
Epoch 3/10, Batch 80/97, Loss: 0.3193
Epoch 3/10, Batch 90/97, Loss: 0.3034
Epoch 3/10, Train Loss: 0.3209, Valid Loss: 0.2886
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3599
Epoch 4/10, Batch 20/97, Loss: 0.2310
Epoch 4/10, Batch 30/97, Loss: 0.2968
Epoch 4/10, Batch 40/97, Loss: 0.2750
Epoch 4/10, Batch 50/97, Loss: 0.2885
Epoch 4/10, Batch 60/97, Loss: 0.1358
Epoch 4/10, Batch 70/97, Loss: 0.2549
Epoch 4/10, Batch 80/97, Loss: 0.2385
Epoch 4/10, Batch 90/97, Loss: 0.3007
Epoch 4/10, Train Loss: 0.2847, Valid Loss: 0.2650
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2157
Epoch 5/10, Batch 20/97, Loss: 0.2071
Epoch 5/10, Batch 30/97, Loss: 0.1372
Epoch 5/10, Batch 40/97, Loss: 0.1716
Epoch 5/10, Batch 50/97, Loss: 0.1562
Epoch 5/10, Batch 60/97, Loss: 0.2330
Epoch 5/10, Batch 70/97, Loss: 0.3552
Epoch 5/10, Batch 80/97, Loss: 0.2995
Epoch 5/10, Batch 90/97, Loss: 0.3800
Epoch 5/10, Train Loss: 0.2491, Valid Loss: 0.2451
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1660
Epoch 6/10, Batch 20/97, Loss: 0.2300
Epoch 6/10, Batch 30/97, Loss: 0.1435
Epoch 6/10, Batch 40/97, Loss: 0.3132
Epoch 6/10, Batch 50/97, Loss: 0.1291
Epoch 6/10, Batch 60/97, Loss: 0.1553
Epoch 6/10, Batch 70/97, Loss: 0.1649
Epoch 6/10, Batch 80/97, Loss: 0.2478
Epoch 6/10, Batch 90/97, Loss: 0.2952
Epoch 6/10, Train Loss: 0.2349, Valid Loss: 0.2390
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2825
Epoch 7/10, Batch 20/97, Loss: 0.2001
Epoch 7/10, Batch 30/97, Loss: 0.1778
Epoch 7/10, Batch 40/97, Loss: 0.1577
Epoch 7/10, Batch 50/97, Loss: 0.2462
Epoch 7/10, Batch 60/97, Loss: 0.3919
Epoch 7/10, Batch 70/97, Loss: 0.3766
Epoch 7/10, Batch 80/97, Loss: 0.2584
Epoch 7/10, Batch 90/97, Loss: 0.2397
Epoch 7/10, Train Loss: 0.2424, Valid Loss: 0.2271
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1600
Epoch 8/10, Batch 20/97, Loss: 0.3278
Epoch 8/10, Batch 30/97, Loss: 0.2403
Epoch 8/10, Batch 40/97, Loss: 0.1722
Epoch 8/10, Batch 50/97, Loss: 0.1720
Epoch 8/10, Batch 60/97, Loss: 0.1257
Epoch 8/10, Batch 70/97, Loss: 0.4240
Epoch 8/10, Batch 80/97, Loss: 0.1450
Epoch 8/10, Batch 90/97, Loss: 0.1474
Epoch 8/10, Train Loss: 0.2178, Valid Loss: 0.2189
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1738
Epoch 9/10, Batch 20/97, Loss: 0.0650
Epoch 9/10, Batch 30/97, Loss: 0.3852
Epoch 9/10, Batch 40/97, Loss: 0.1157
Epoch 9/10, Batch 50/97, Loss: 0.1888
Epoch 9/10, Batch 60/97, Loss: 0.1806
Epoch 9/10, Batch 70/97, Loss: 0.1269
Epoch 9/10, Batch 80/97, Loss: 0.1447
Epoch 9/10, Batch 90/97, Loss: 0.2234
Epoch 9/10, Train Loss: 0.2005, Valid Loss: 0.2232
Epoch 10/10, Batch 10/97, Loss: 0.1799
Epoch 10/10, Batch 20/97, Loss: 0.1749
Epoch 10/10, Batch 30/97, Loss: 0.2403
Epoch 10/10, Batch 40/97, Loss: 0.1383
Epoch 10/10, Batch 50/97, Loss: 0.2255
Epoch 10/10, Batch 60/97, Loss: 0.1977
Epoch 10/10, Batch 70/97, Loss: 0.2551
Epoch 10/10, Batch 80/97, Loss: 0.1290
Epoch 10/10, Batch 90/97, Loss: 0.1680
Epoch 10/10, Train Loss: 0.1915, Valid Loss: 0.2103
Model saved!
Accuracy: 0.9182
Precision: 0.9159
Recall: 0.9182
F1-score: 0.9165
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4286
Epoch 1/10, Batch 20/97, Loss: 0.9496
Epoch 1/10, Batch 30/97, Loss: 0.9139
Epoch 1/10, Batch 40/97, Loss: 0.7774
Epoch 1/10, Batch 50/97, Loss: 0.6316
Epoch 1/10, Batch 60/97, Loss: 0.4843
Epoch 1/10, Batch 70/97, Loss: 0.5713
Epoch 1/10, Batch 80/97, Loss: 0.4620
Epoch 1/10, Batch 90/97, Loss: 0.5580
Epoch 1/10, Train Loss: 0.7718, Valid Loss: 0.4499
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3975
Epoch 2/10, Batch 20/97, Loss: 0.4662
Epoch 2/10, Batch 30/97, Loss: 0.3779
Epoch 2/10, Batch 40/97, Loss: 0.3821
Epoch 2/10, Batch 50/97, Loss: 0.5182
Epoch 2/10, Batch 60/97, Loss: 0.3756
Epoch 2/10, Batch 70/97, Loss: 0.2985
Epoch 2/10, Batch 80/97, Loss: 0.2879
Epoch 2/10, Batch 90/97, Loss: 0.2789
Epoch 2/10, Train Loss: 0.3982, Valid Loss: 0.3491
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2004
Epoch 3/10, Batch 20/97, Loss: 0.3652
Epoch 3/10, Batch 30/97, Loss: 0.2444
Epoch 3/10, Batch 40/97, Loss: 0.3907
Epoch 3/10, Batch 50/97, Loss: 0.2772
Epoch 3/10, Batch 60/97, Loss: 0.2424
Epoch 3/10, Batch 70/97, Loss: 0.2053
Epoch 3/10, Batch 80/97, Loss: 0.2735
Epoch 3/10, Batch 90/97, Loss: 0.2078
Epoch 3/10, Train Loss: 0.3215, Valid Loss: 0.3069
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3636
Epoch 4/10, Batch 20/97, Loss: 0.3332
Epoch 4/10, Batch 30/97, Loss: 0.3637
Epoch 4/10, Batch 40/97, Loss: 0.3016
Epoch 4/10, Batch 50/97, Loss: 0.2054
Epoch 4/10, Batch 60/97, Loss: 0.2096
Epoch 4/10, Batch 70/97, Loss: 0.2442
Epoch 4/10, Batch 80/97, Loss: 0.2063
Epoch 4/10, Batch 90/97, Loss: 0.2455
Epoch 4/10, Train Loss: 0.2827, Valid Loss: 0.2851
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2881
Epoch 5/10, Batch 20/97, Loss: 0.2485
Epoch 5/10, Batch 30/97, Loss: 0.1486
Epoch 5/10, Batch 40/97, Loss: 0.1347
Epoch 5/10, Batch 50/97, Loss: 0.1750
Epoch 5/10, Batch 60/97, Loss: 0.2878
Epoch 5/10, Batch 70/97, Loss: 0.2472
Epoch 5/10, Batch 80/97, Loss: 0.4312
Epoch 5/10, Batch 90/97, Loss: 0.3270
Epoch 5/10, Train Loss: 0.2588, Valid Loss: 0.2734
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3081
Epoch 6/10, Batch 20/97, Loss: 0.2338
Epoch 6/10, Batch 30/97, Loss: 0.2753
Epoch 6/10, Batch 40/97, Loss: 0.1962
Epoch 6/10, Batch 50/97, Loss: 0.2397
Epoch 6/10, Batch 60/97, Loss: 0.2489
Epoch 6/10, Batch 70/97, Loss: 0.3693
Epoch 6/10, Batch 80/97, Loss: 0.1357
Epoch 6/10, Batch 90/97, Loss: 0.2432
Epoch 6/10, Train Loss: 0.2348, Valid Loss: 0.2689
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2769
Epoch 7/10, Batch 20/97, Loss: 0.1024
Epoch 7/10, Batch 30/97, Loss: 0.3734
Epoch 7/10, Batch 40/97, Loss: 0.1347
Epoch 7/10, Batch 50/97, Loss: 0.4003
Epoch 7/10, Batch 60/97, Loss: 0.3326
Epoch 7/10, Batch 70/97, Loss: 0.1840
Epoch 7/10, Batch 80/97, Loss: 0.2039
Epoch 7/10, Batch 90/97, Loss: 0.1703
Epoch 7/10, Train Loss: 0.2333, Valid Loss: 0.2649
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1801
Epoch 8/10, Batch 20/97, Loss: 0.2325
Epoch 8/10, Batch 30/97, Loss: 0.0917
Epoch 8/10, Batch 40/97, Loss: 0.1919
Epoch 8/10, Batch 50/97, Loss: 0.1585
Epoch 8/10, Batch 60/97, Loss: 0.1021
Epoch 8/10, Batch 70/97, Loss: 0.2304
Epoch 8/10, Batch 80/97, Loss: 0.1653
Epoch 8/10, Batch 90/97, Loss: 0.1595
Epoch 8/10, Train Loss: 0.2213, Valid Loss: 0.2485
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1431
Epoch 9/10, Batch 20/97, Loss: 0.1510
Epoch 9/10, Batch 30/97, Loss: 0.3921
Epoch 9/10, Batch 40/97, Loss: 0.1550
Epoch 9/10, Batch 50/97, Loss: 0.2306
Epoch 9/10, Batch 60/97, Loss: 0.1641
Epoch 9/10, Batch 70/97, Loss: 0.2121
Epoch 9/10, Batch 80/97, Loss: 0.1446
Epoch 9/10, Batch 90/97, Loss: 0.3947
Epoch 9/10, Train Loss: 0.2079, Valid Loss: 0.2563
Epoch 10/10, Batch 10/97, Loss: 0.2223
Epoch 10/10, Batch 20/97, Loss: 0.1749
Epoch 10/10, Batch 30/97, Loss: 0.1667
Epoch 10/10, Batch 40/97, Loss: 0.1667
Epoch 10/10, Batch 50/97, Loss: 0.2460
Epoch 10/10, Batch 60/97, Loss: 0.2712
Epoch 10/10, Batch 70/97, Loss: 0.1150
Epoch 10/10, Batch 80/97, Loss: 0.2432
Epoch 10/10, Batch 90/97, Loss: 0.1945
Epoch 10/10, Train Loss: 0.2010, Valid Loss: 0.2479
Model saved!
Accuracy: 0.9159
Precision: 0.9135
Recall: 0.9159
F1-score: 0.9136
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4488
Epoch 1/10, Batch 20/97, Loss: 1.0406
Epoch 1/10, Batch 30/97, Loss: 0.9381
Epoch 1/10, Batch 40/97, Loss: 0.7382
Epoch 1/10, Batch 50/97, Loss: 0.5523
Epoch 1/10, Batch 60/97, Loss: 0.6813
Epoch 1/10, Batch 70/97, Loss: 0.6017
Epoch 1/10, Batch 80/97, Loss: 0.3933
Epoch 1/10, Batch 90/97, Loss: 0.5265
Epoch 1/10, Train Loss: 0.7752, Valid Loss: 0.4677
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4455
Epoch 2/10, Batch 20/97, Loss: 0.4253
Epoch 2/10, Batch 30/97, Loss: 0.3320
Epoch 2/10, Batch 40/97, Loss: 0.3857
Epoch 2/10, Batch 50/97, Loss: 0.4066
Epoch 2/10, Batch 60/97, Loss: 0.3570
Epoch 2/10, Batch 70/97, Loss: 0.3187
Epoch 2/10, Batch 80/97, Loss: 0.3658
Epoch 2/10, Batch 90/97, Loss: 0.3052
Epoch 2/10, Train Loss: 0.3988, Valid Loss: 0.3528
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2849
Epoch 3/10, Batch 20/97, Loss: 0.3970
Epoch 3/10, Batch 30/97, Loss: 0.3968
Epoch 3/10, Batch 40/97, Loss: 0.2848
Epoch 3/10, Batch 50/97, Loss: 0.2854
Epoch 3/10, Batch 60/97, Loss: 0.4006
Epoch 3/10, Batch 70/97, Loss: 0.1332
Epoch 3/10, Batch 80/97, Loss: 0.1871
Epoch 3/10, Batch 90/97, Loss: 0.3044
Epoch 3/10, Train Loss: 0.3300, Valid Loss: 0.3076
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3357
Epoch 4/10, Batch 20/97, Loss: 0.2198
Epoch 4/10, Batch 30/97, Loss: 0.4373
Epoch 4/10, Batch 40/97, Loss: 0.2547
Epoch 4/10, Batch 50/97, Loss: 0.1992
Epoch 4/10, Batch 60/97, Loss: 0.2154
Epoch 4/10, Batch 70/97, Loss: 0.2019
Epoch 4/10, Batch 80/97, Loss: 0.2660
Epoch 4/10, Batch 90/97, Loss: 0.3479
Epoch 4/10, Train Loss: 0.2902, Valid Loss: 0.2824
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2622
Epoch 5/10, Batch 20/97, Loss: 0.1956
Epoch 5/10, Batch 30/97, Loss: 0.1513
Epoch 5/10, Batch 40/97, Loss: 0.1232
Epoch 5/10, Batch 50/97, Loss: 0.1985
Epoch 5/10, Batch 60/97, Loss: 0.2478
Epoch 5/10, Batch 70/97, Loss: 0.2652
Epoch 5/10, Batch 80/97, Loss: 0.2048
Epoch 5/10, Batch 90/97, Loss: 0.4535
Epoch 5/10, Train Loss: 0.2668, Valid Loss: 0.2724
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1378
Epoch 6/10, Batch 20/97, Loss: 0.2914
Epoch 6/10, Batch 30/97, Loss: 0.2806
Epoch 6/10, Batch 40/97, Loss: 0.2762
Epoch 6/10, Batch 50/97, Loss: 0.2456
Epoch 6/10, Batch 60/97, Loss: 0.1947
Epoch 6/10, Batch 70/97, Loss: 0.2272
Epoch 6/10, Batch 80/97, Loss: 0.1088
Epoch 6/10, Batch 90/97, Loss: 0.1742
Epoch 6/10, Train Loss: 0.2416, Valid Loss: 0.2636
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2235
Epoch 7/10, Batch 20/97, Loss: 0.2515
Epoch 7/10, Batch 30/97, Loss: 0.1998
Epoch 7/10, Batch 40/97, Loss: 0.1795
Epoch 7/10, Batch 50/97, Loss: 0.2777
Epoch 7/10, Batch 60/97, Loss: 0.2550
Epoch 7/10, Batch 70/97, Loss: 0.2750
Epoch 7/10, Batch 80/97, Loss: 0.1365
Epoch 7/10, Batch 90/97, Loss: 0.2118
Epoch 7/10, Train Loss: 0.2498, Valid Loss: 0.2509
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1242
Epoch 8/10, Batch 20/97, Loss: 0.2461
Epoch 8/10, Batch 30/97, Loss: 0.1346
Epoch 8/10, Batch 40/97, Loss: 0.1504
Epoch 8/10, Batch 50/97, Loss: 0.2292
Epoch 8/10, Batch 60/97, Loss: 0.2372
Epoch 8/10, Batch 70/97, Loss: 0.2905
Epoch 8/10, Batch 80/97, Loss: 0.1706
Epoch 8/10, Batch 90/97, Loss: 0.2410
Epoch 8/10, Train Loss: 0.2228, Valid Loss: 0.2523
Epoch 9/10, Batch 10/97, Loss: 0.1534
Epoch 9/10, Batch 20/97, Loss: 0.1532
Epoch 9/10, Batch 30/97, Loss: 0.1959
Epoch 9/10, Batch 40/97, Loss: 0.1836
Epoch 9/10, Batch 50/97, Loss: 0.1820
Epoch 9/10, Batch 60/97, Loss: 0.1258
Epoch 9/10, Batch 70/97, Loss: 0.1730
Epoch 9/10, Batch 80/97, Loss: 0.1428
Epoch 9/10, Batch 90/97, Loss: 0.1668
Epoch 9/10, Train Loss: 0.2157, Valid Loss: 0.2407
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1468
Epoch 10/10, Batch 20/97, Loss: 0.1208
Epoch 10/10, Batch 30/97, Loss: 0.1570
Epoch 10/10, Batch 40/97, Loss: 0.1683
Epoch 10/10, Batch 50/97, Loss: 0.2643
Epoch 10/10, Batch 60/97, Loss: 0.3147
Epoch 10/10, Batch 70/97, Loss: 0.1837
Epoch 10/10, Batch 80/97, Loss: 0.3669
Epoch 10/10, Batch 90/97, Loss: 0.1287
Epoch 10/10, Train Loss: 0.2009, Valid Loss: 0.2354
Model saved!
Accuracy: 0.9194
Precision: 0.9174
Recall: 0.9194
F1-score: 0.9181
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5183
Epoch 1/10, Batch 20/97, Loss: 0.9390
Epoch 1/10, Batch 30/97, Loss: 0.8745
Epoch 1/10, Batch 40/97, Loss: 0.7936
Epoch 1/10, Batch 50/97, Loss: 0.5810
Epoch 1/10, Batch 60/97, Loss: 0.5642
Epoch 1/10, Batch 70/97, Loss: 0.6709
Epoch 1/10, Batch 80/97, Loss: 0.5277
Epoch 1/10, Batch 90/97, Loss: 0.5568
Epoch 1/10, Train Loss: 0.7765, Valid Loss: 0.4561
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3541
Epoch 2/10, Batch 20/97, Loss: 0.4799
Epoch 2/10, Batch 30/97, Loss: 0.4044
Epoch 2/10, Batch 40/97, Loss: 0.5283
Epoch 2/10, Batch 50/97, Loss: 0.6035
Epoch 2/10, Batch 60/97, Loss: 0.4197
Epoch 2/10, Batch 70/97, Loss: 0.2073
Epoch 2/10, Batch 80/97, Loss: 0.2446
Epoch 2/10, Batch 90/97, Loss: 0.4303
Epoch 2/10, Train Loss: 0.3946, Valid Loss: 0.3492
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3017
Epoch 3/10, Batch 20/97, Loss: 0.2152
Epoch 3/10, Batch 30/97, Loss: 0.2503
Epoch 3/10, Batch 40/97, Loss: 0.1740
Epoch 3/10, Batch 50/97, Loss: 0.2511
Epoch 3/10, Batch 60/97, Loss: 0.2626
Epoch 3/10, Batch 70/97, Loss: 0.1396
Epoch 3/10, Batch 80/97, Loss: 0.2614
Epoch 3/10, Batch 90/97, Loss: 0.2805
Epoch 3/10, Train Loss: 0.3209, Valid Loss: 0.3072
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1986
Epoch 4/10, Batch 20/97, Loss: 0.2894
Epoch 4/10, Batch 30/97, Loss: 0.3886
Epoch 4/10, Batch 40/97, Loss: 0.2462
Epoch 4/10, Batch 50/97, Loss: 0.1646
Epoch 4/10, Batch 60/97, Loss: 0.1070
Epoch 4/10, Batch 70/97, Loss: 0.2505
Epoch 4/10, Batch 80/97, Loss: 0.2941
Epoch 4/10, Batch 90/97, Loss: 0.1693
Epoch 4/10, Train Loss: 0.2805, Valid Loss: 0.2864
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2715
Epoch 5/10, Batch 20/97, Loss: 0.2662
Epoch 5/10, Batch 30/97, Loss: 0.1487
Epoch 5/10, Batch 40/97, Loss: 0.2529
Epoch 5/10, Batch 50/97, Loss: 0.2670
Epoch 5/10, Batch 60/97, Loss: 0.3069
Epoch 5/10, Batch 70/97, Loss: 0.1742
Epoch 5/10, Batch 80/97, Loss: 0.2238
Epoch 5/10, Batch 90/97, Loss: 0.3076
Epoch 5/10, Train Loss: 0.2538, Valid Loss: 0.2819
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2931
Epoch 6/10, Batch 20/97, Loss: 0.1300
Epoch 6/10, Batch 30/97, Loss: 0.3539
Epoch 6/10, Batch 40/97, Loss: 0.2338
Epoch 6/10, Batch 50/97, Loss: 0.2540
Epoch 6/10, Batch 60/97, Loss: 0.3149
Epoch 6/10, Batch 70/97, Loss: 0.2042
Epoch 6/10, Batch 80/97, Loss: 0.1787
Epoch 6/10, Batch 90/97, Loss: 0.2414
Epoch 6/10, Train Loss: 0.2368, Valid Loss: 0.2751
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2580
Epoch 7/10, Batch 20/97, Loss: 0.0733
Epoch 7/10, Batch 30/97, Loss: 0.2588
Epoch 7/10, Batch 40/97, Loss: 0.3162
Epoch 7/10, Batch 50/97, Loss: 0.2090
Epoch 7/10, Batch 60/97, Loss: 0.3328
Epoch 7/10, Batch 70/97, Loss: 0.0922
Epoch 7/10, Batch 80/97, Loss: 0.1922
Epoch 7/10, Batch 90/97, Loss: 0.4097
Epoch 7/10, Train Loss: 0.2380, Valid Loss: 0.2642
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1976
Epoch 8/10, Batch 20/97, Loss: 0.1825
Epoch 8/10, Batch 30/97, Loss: 0.0809
Epoch 8/10, Batch 40/97, Loss: 0.2783
Epoch 8/10, Batch 50/97, Loss: 0.2463
Epoch 8/10, Batch 60/97, Loss: 0.2395
Epoch 8/10, Batch 70/97, Loss: 0.2932
Epoch 8/10, Batch 80/97, Loss: 0.0993
Epoch 8/10, Batch 90/97, Loss: 0.1307
Epoch 8/10, Train Loss: 0.2150, Valid Loss: 0.2562
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1018
Epoch 9/10, Batch 20/97, Loss: 0.1781
Epoch 9/10, Batch 30/97, Loss: 0.3061
Epoch 9/10, Batch 40/97, Loss: 0.1036
Epoch 9/10, Batch 50/97, Loss: 0.3345
Epoch 9/10, Batch 60/97, Loss: 0.1914
Epoch 9/10, Batch 70/97, Loss: 0.1739
Epoch 9/10, Batch 80/97, Loss: 0.1028
Epoch 9/10, Batch 90/97, Loss: 0.1259
Epoch 9/10, Train Loss: 0.2050, Valid Loss: 0.2608
Epoch 10/10, Batch 10/97, Loss: 0.2521
Epoch 10/10, Batch 20/97, Loss: 0.1117
Epoch 10/10, Batch 30/97, Loss: 0.2289
Epoch 10/10, Batch 40/97, Loss: 0.2184
Epoch 10/10, Batch 50/97, Loss: 0.2940
Epoch 10/10, Batch 60/97, Loss: 0.2170
Epoch 10/10, Batch 70/97, Loss: 0.2263
Epoch 10/10, Batch 80/97, Loss: 0.1342
Epoch 10/10, Batch 90/97, Loss: 0.0971
Epoch 10/10, Train Loss: 0.1991, Valid Loss: 0.2508
Model saved!
Accuracy: 0.9194
Precision: 0.9181
Recall: 0.9194
F1-score: 0.9177
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5302
Epoch 1/10, Batch 20/97, Loss: 0.9718
Epoch 1/10, Batch 30/97, Loss: 0.8229
Epoch 1/10, Batch 40/97, Loss: 0.7061
Epoch 1/10, Batch 50/97, Loss: 0.6131
Epoch 1/10, Batch 60/97, Loss: 0.7502
Epoch 1/10, Batch 70/97, Loss: 0.4063
Epoch 1/10, Batch 80/97, Loss: 0.3880
Epoch 1/10, Batch 90/97, Loss: 0.6139
Epoch 1/10, Train Loss: 0.7699, Valid Loss: 0.4271
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3436
Epoch 2/10, Batch 20/97, Loss: 0.5069
Epoch 2/10, Batch 30/97, Loss: 0.3590
Epoch 2/10, Batch 40/97, Loss: 0.4570
Epoch 2/10, Batch 50/97, Loss: 0.6061
Epoch 2/10, Batch 60/97, Loss: 0.2575
Epoch 2/10, Batch 70/97, Loss: 0.3683
Epoch 2/10, Batch 80/97, Loss: 0.2839
Epoch 2/10, Batch 90/97, Loss: 0.4066
Epoch 2/10, Train Loss: 0.3987, Valid Loss: 0.3223
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3788
Epoch 3/10, Batch 20/97, Loss: 0.3214
Epoch 3/10, Batch 30/97, Loss: 0.3548
Epoch 3/10, Batch 40/97, Loss: 0.2381
Epoch 3/10, Batch 50/97, Loss: 0.2705
Epoch 3/10, Batch 60/97, Loss: 0.2780
Epoch 3/10, Batch 70/97, Loss: 0.3962
Epoch 3/10, Batch 80/97, Loss: 0.3288
Epoch 3/10, Batch 90/97, Loss: 0.3743
Epoch 3/10, Train Loss: 0.3265, Valid Loss: 0.2833
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2752
Epoch 4/10, Batch 20/97, Loss: 0.2555
Epoch 4/10, Batch 30/97, Loss: 0.3266
Epoch 4/10, Batch 40/97, Loss: 0.2252
Epoch 4/10, Batch 50/97, Loss: 0.3032
Epoch 4/10, Batch 60/97, Loss: 0.2081
Epoch 4/10, Batch 70/97, Loss: 0.2149
Epoch 4/10, Batch 80/97, Loss: 0.1358
Epoch 4/10, Batch 90/97, Loss: 0.2622
Epoch 4/10, Train Loss: 0.2906, Valid Loss: 0.2636
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2107
Epoch 5/10, Batch 20/97, Loss: 0.2589
Epoch 5/10, Batch 30/97, Loss: 0.2435
Epoch 5/10, Batch 40/97, Loss: 0.1858
Epoch 5/10, Batch 50/97, Loss: 0.2385
Epoch 5/10, Batch 60/97, Loss: 0.3106
Epoch 5/10, Batch 70/97, Loss: 0.1616
Epoch 5/10, Batch 80/97, Loss: 0.3313
Epoch 5/10, Batch 90/97, Loss: 0.2922
Epoch 5/10, Train Loss: 0.2568, Valid Loss: 0.2500
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3105
Epoch 6/10, Batch 20/97, Loss: 0.1302
Epoch 6/10, Batch 30/97, Loss: 0.2329
Epoch 6/10, Batch 40/97, Loss: 0.1517
Epoch 6/10, Batch 50/97, Loss: 0.2180
Epoch 6/10, Batch 60/97, Loss: 0.2474
Epoch 6/10, Batch 70/97, Loss: 0.2088
Epoch 6/10, Batch 80/97, Loss: 0.1473
Epoch 6/10, Batch 90/97, Loss: 0.2949
Epoch 6/10, Train Loss: 0.2433, Valid Loss: 0.2423
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2310
Epoch 7/10, Batch 20/97, Loss: 0.1553
Epoch 7/10, Batch 30/97, Loss: 0.1816
Epoch 7/10, Batch 40/97, Loss: 0.1693
Epoch 7/10, Batch 50/97, Loss: 0.2144
Epoch 7/10, Batch 60/97, Loss: 0.3257
Epoch 7/10, Batch 70/97, Loss: 0.3029
Epoch 7/10, Batch 80/97, Loss: 0.3002
Epoch 7/10, Batch 90/97, Loss: 0.2237
Epoch 7/10, Train Loss: 0.2374, Valid Loss: 0.2282
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1328
Epoch 8/10, Batch 20/97, Loss: 0.2327
Epoch 8/10, Batch 30/97, Loss: 0.2167
Epoch 8/10, Batch 40/97, Loss: 0.1218
Epoch 8/10, Batch 50/97, Loss: 0.1812
Epoch 8/10, Batch 60/97, Loss: 0.2360
Epoch 8/10, Batch 70/97, Loss: 0.2825
Epoch 8/10, Batch 80/97, Loss: 0.1874
Epoch 8/10, Batch 90/97, Loss: 0.0621
Epoch 8/10, Train Loss: 0.2173, Valid Loss: 0.2241
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1073
Epoch 9/10, Batch 20/97, Loss: 0.1272
Epoch 9/10, Batch 30/97, Loss: 0.2358
Epoch 9/10, Batch 40/97, Loss: 0.2451
Epoch 9/10, Batch 50/97, Loss: 0.1924
Epoch 9/10, Batch 60/97, Loss: 0.1404
Epoch 9/10, Batch 70/97, Loss: 0.2218
Epoch 9/10, Batch 80/97, Loss: 0.2010
Epoch 9/10, Batch 90/97, Loss: 0.1389
Epoch 9/10, Train Loss: 0.2170, Valid Loss: 0.2226
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2355
Epoch 10/10, Batch 20/97, Loss: 0.1751
Epoch 10/10, Batch 30/97, Loss: 0.1537
Epoch 10/10, Batch 40/97, Loss: 0.2320
Epoch 10/10, Batch 50/97, Loss: 0.2666
Epoch 10/10, Batch 60/97, Loss: 0.1561
Epoch 10/10, Batch 70/97, Loss: 0.1242
Epoch 10/10, Batch 80/97, Loss: 0.1941
Epoch 10/10, Batch 90/97, Loss: 0.1903
Epoch 10/10, Train Loss: 0.2030, Valid Loss: 0.2206
Model saved!
Accuracy: 0.9100
Precision: 0.9065
Recall: 0.9100
F1-score: 0.9076
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4459
Epoch 1/10, Batch 20/97, Loss: 1.0102
Epoch 1/10, Batch 30/97, Loss: 0.8177
Epoch 1/10, Batch 40/97, Loss: 0.6912
Epoch 1/10, Batch 50/97, Loss: 0.6632
Epoch 1/10, Batch 60/97, Loss: 0.6405
Epoch 1/10, Batch 70/97, Loss: 0.5357
Epoch 1/10, Batch 80/97, Loss: 0.4008
Epoch 1/10, Batch 90/97, Loss: 0.5766
Epoch 1/10, Train Loss: 0.7779, Valid Loss: 0.4210
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3896
Epoch 2/10, Batch 20/97, Loss: 0.3952
Epoch 2/10, Batch 30/97, Loss: 0.3591
Epoch 2/10, Batch 40/97, Loss: 0.3879
Epoch 2/10, Batch 50/97, Loss: 0.5614
Epoch 2/10, Batch 60/97, Loss: 0.3392
Epoch 2/10, Batch 70/97, Loss: 0.3356
Epoch 2/10, Batch 80/97, Loss: 0.3167
Epoch 2/10, Batch 90/97, Loss: 0.4225
Epoch 2/10, Train Loss: 0.4022, Valid Loss: 0.3158
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2758
Epoch 3/10, Batch 20/97, Loss: 0.4100
Epoch 3/10, Batch 30/97, Loss: 0.3006
Epoch 3/10, Batch 40/97, Loss: 0.2664
Epoch 3/10, Batch 50/97, Loss: 0.2648
Epoch 3/10, Batch 60/97, Loss: 0.1766
Epoch 3/10, Batch 70/97, Loss: 0.2179
Epoch 3/10, Batch 80/97, Loss: 0.4367
Epoch 3/10, Batch 90/97, Loss: 0.2071
Epoch 3/10, Train Loss: 0.3225, Valid Loss: 0.2829
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2365
Epoch 4/10, Batch 20/97, Loss: 0.2356
Epoch 4/10, Batch 30/97, Loss: 0.2987
Epoch 4/10, Batch 40/97, Loss: 0.2794
Epoch 4/10, Batch 50/97, Loss: 0.1724
Epoch 4/10, Batch 60/97, Loss: 0.1066
Epoch 4/10, Batch 70/97, Loss: 0.2046
Epoch 4/10, Batch 80/97, Loss: 0.3116
Epoch 4/10, Batch 90/97, Loss: 0.3509
Epoch 4/10, Train Loss: 0.2867, Valid Loss: 0.2591
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3432
Epoch 5/10, Batch 20/97, Loss: 0.2609
Epoch 5/10, Batch 30/97, Loss: 0.1614
Epoch 5/10, Batch 40/97, Loss: 0.1241
Epoch 5/10, Batch 50/97, Loss: 0.2069
Epoch 5/10, Batch 60/97, Loss: 0.1862
Epoch 5/10, Batch 70/97, Loss: 0.3199
Epoch 5/10, Batch 80/97, Loss: 0.4035
Epoch 5/10, Batch 90/97, Loss: 0.3810
Epoch 5/10, Train Loss: 0.2575, Valid Loss: 0.2448
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1824
Epoch 6/10, Batch 20/97, Loss: 0.1170
Epoch 6/10, Batch 30/97, Loss: 0.3133
Epoch 6/10, Batch 40/97, Loss: 0.3262
Epoch 6/10, Batch 50/97, Loss: 0.2174
Epoch 6/10, Batch 60/97, Loss: 0.2272
Epoch 6/10, Batch 70/97, Loss: 0.2243
Epoch 6/10, Batch 80/97, Loss: 0.1312
Epoch 6/10, Batch 90/97, Loss: 0.2950
Epoch 6/10, Train Loss: 0.2395, Valid Loss: 0.2328
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3797
Epoch 7/10, Batch 20/97, Loss: 0.2239
Epoch 7/10, Batch 30/97, Loss: 0.2953
Epoch 7/10, Batch 40/97, Loss: 0.2271
Epoch 7/10, Batch 50/97, Loss: 0.1388
Epoch 7/10, Batch 60/97, Loss: 0.2088
Epoch 7/10, Batch 70/97, Loss: 0.2645
Epoch 7/10, Batch 80/97, Loss: 0.1566
Epoch 7/10, Batch 90/97, Loss: 0.3343
Epoch 7/10, Train Loss: 0.2412, Valid Loss: 0.2345
Epoch 8/10, Batch 10/97, Loss: 0.2022
Epoch 8/10, Batch 20/97, Loss: 0.1940
Epoch 8/10, Batch 30/97, Loss: 0.1733
Epoch 8/10, Batch 40/97, Loss: 0.2006
Epoch 8/10, Batch 50/97, Loss: 0.1250
Epoch 8/10, Batch 60/97, Loss: 0.1378
Epoch 8/10, Batch 70/97, Loss: 0.1905
Epoch 8/10, Batch 80/97, Loss: 0.2443
Epoch 8/10, Batch 90/97, Loss: 0.1469
Epoch 8/10, Train Loss: 0.2208, Valid Loss: 0.2282
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1323
Epoch 9/10, Batch 20/97, Loss: 0.2419
Epoch 9/10, Batch 30/97, Loss: 0.3156
Epoch 9/10, Batch 40/97, Loss: 0.1567
Epoch 9/10, Batch 50/97, Loss: 0.1632
Epoch 9/10, Batch 60/97, Loss: 0.1857
Epoch 9/10, Batch 70/97, Loss: 0.1623
Epoch 9/10, Batch 80/97, Loss: 0.2052
Epoch 9/10, Batch 90/97, Loss: 0.2740
Epoch 9/10, Train Loss: 0.2082, Valid Loss: 0.2257
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3042
Epoch 10/10, Batch 20/97, Loss: 0.1155
Epoch 10/10, Batch 30/97, Loss: 0.0958
Epoch 10/10, Batch 40/97, Loss: 0.1487
Epoch 10/10, Batch 50/97, Loss: 0.2370
Epoch 10/10, Batch 60/97, Loss: 0.1175
Epoch 10/10, Batch 70/97, Loss: 0.1459
Epoch 10/10, Batch 80/97, Loss: 0.2171
Epoch 10/10, Batch 90/97, Loss: 0.2932
Epoch 10/10, Train Loss: 0.2005, Valid Loss: 0.2233
Model saved!
Accuracy: 0.9276
Precision: 0.9265
Recall: 0.9276
F1-score: 0.9269
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4944
Epoch 1/10, Batch 20/97, Loss: 1.0252
Epoch 1/10, Batch 30/97, Loss: 0.9060
Epoch 1/10, Batch 40/97, Loss: 0.7416
Epoch 1/10, Batch 50/97, Loss: 0.6458
Epoch 1/10, Batch 60/97, Loss: 0.4907
Epoch 1/10, Batch 70/97, Loss: 0.5273
Epoch 1/10, Batch 80/97, Loss: 0.5179
Epoch 1/10, Batch 90/97, Loss: 0.5320
Epoch 1/10, Train Loss: 0.7841, Valid Loss: 0.4456
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4730
Epoch 2/10, Batch 20/97, Loss: 0.6034
Epoch 2/10, Batch 30/97, Loss: 0.3702
Epoch 2/10, Batch 40/97, Loss: 0.4732
Epoch 2/10, Batch 50/97, Loss: 0.6086
Epoch 2/10, Batch 60/97, Loss: 0.3533
Epoch 2/10, Batch 70/97, Loss: 0.2533
Epoch 2/10, Batch 80/97, Loss: 0.3598
Epoch 2/10, Batch 90/97, Loss: 0.2319
Epoch 2/10, Train Loss: 0.3942, Valid Loss: 0.3405
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4226
Epoch 3/10, Batch 20/97, Loss: 0.2864
Epoch 3/10, Batch 30/97, Loss: 0.1892
Epoch 3/10, Batch 40/97, Loss: 0.4538
Epoch 3/10, Batch 50/97, Loss: 0.2824
Epoch 3/10, Batch 60/97, Loss: 0.2668
Epoch 3/10, Batch 70/97, Loss: 0.1815
Epoch 3/10, Batch 80/97, Loss: 0.2271
Epoch 3/10, Batch 90/97, Loss: 0.2407
Epoch 3/10, Train Loss: 0.3229, Valid Loss: 0.3061
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4228
Epoch 4/10, Batch 20/97, Loss: 0.1623
Epoch 4/10, Batch 30/97, Loss: 0.4340
Epoch 4/10, Batch 40/97, Loss: 0.1932
Epoch 4/10, Batch 50/97, Loss: 0.1478
Epoch 4/10, Batch 60/97, Loss: 0.1569
Epoch 4/10, Batch 70/97, Loss: 0.1899
Epoch 4/10, Batch 80/97, Loss: 0.3223
Epoch 4/10, Batch 90/97, Loss: 0.2228
Epoch 4/10, Train Loss: 0.2799, Valid Loss: 0.2728
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1685
Epoch 5/10, Batch 20/97, Loss: 0.2829
Epoch 5/10, Batch 30/97, Loss: 0.1445
Epoch 5/10, Batch 40/97, Loss: 0.1092
Epoch 5/10, Batch 50/97, Loss: 0.1988
Epoch 5/10, Batch 60/97, Loss: 0.1979
Epoch 5/10, Batch 70/97, Loss: 0.2674
Epoch 5/10, Batch 80/97, Loss: 0.1621
Epoch 5/10, Batch 90/97, Loss: 0.3285
Epoch 5/10, Train Loss: 0.2468, Valid Loss: 0.2673
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2933
Epoch 6/10, Batch 20/97, Loss: 0.2231
Epoch 6/10, Batch 30/97, Loss: 0.1233
Epoch 6/10, Batch 40/97, Loss: 0.4207
Epoch 6/10, Batch 50/97, Loss: 0.2904
Epoch 6/10, Batch 60/97, Loss: 0.1862
Epoch 6/10, Batch 70/97, Loss: 0.2529
Epoch 6/10, Batch 80/97, Loss: 0.2319
Epoch 6/10, Batch 90/97, Loss: 0.2132
Epoch 6/10, Train Loss: 0.2392, Valid Loss: 0.2573
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4698
Epoch 7/10, Batch 20/97, Loss: 0.1734
Epoch 7/10, Batch 30/97, Loss: 0.1757
Epoch 7/10, Batch 40/97, Loss: 0.1266
Epoch 7/10, Batch 50/97, Loss: 0.2246
Epoch 7/10, Batch 60/97, Loss: 0.3045
Epoch 7/10, Batch 70/97, Loss: 0.1645
Epoch 7/10, Batch 80/97, Loss: 0.2453
Epoch 7/10, Batch 90/97, Loss: 0.2206
Epoch 7/10, Train Loss: 0.2331, Valid Loss: 0.2493
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2268
Epoch 8/10, Batch 20/97, Loss: 0.1650
Epoch 8/10, Batch 30/97, Loss: 0.3256
Epoch 8/10, Batch 40/97, Loss: 0.2204
Epoch 8/10, Batch 50/97, Loss: 0.1625
Epoch 8/10, Batch 60/97, Loss: 0.2580
Epoch 8/10, Batch 70/97, Loss: 0.3069
Epoch 8/10, Batch 80/97, Loss: 0.1388
Epoch 8/10, Batch 90/97, Loss: 0.1189
Epoch 8/10, Train Loss: 0.2203, Valid Loss: 0.2391
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1670
Epoch 9/10, Batch 20/97, Loss: 0.1922
Epoch 9/10, Batch 30/97, Loss: 0.2339
Epoch 9/10, Batch 40/97, Loss: 0.1206
Epoch 9/10, Batch 50/97, Loss: 0.1492
Epoch 9/10, Batch 60/97, Loss: 0.1369
Epoch 9/10, Batch 70/97, Loss: 0.1394
Epoch 9/10, Batch 80/97, Loss: 0.1855
Epoch 9/10, Batch 90/97, Loss: 0.2123
Epoch 9/10, Train Loss: 0.1953, Valid Loss: 0.2431
Epoch 10/10, Batch 10/97, Loss: 0.2719
Epoch 10/10, Batch 20/97, Loss: 0.1431
Epoch 10/10, Batch 30/97, Loss: 0.2945
Epoch 10/10, Batch 40/97, Loss: 0.2191
Epoch 10/10, Batch 50/97, Loss: 0.2439
Epoch 10/10, Batch 60/97, Loss: 0.1551
Epoch 10/10, Batch 70/97, Loss: 0.1772
Epoch 10/10, Batch 80/97, Loss: 0.1577
Epoch 10/10, Batch 90/97, Loss: 0.2215
Epoch 10/10, Train Loss: 0.1931, Valid Loss: 0.2387
Model saved!
Accuracy: 0.9112
Precision: 0.9084
Recall: 0.9112
F1-score: 0.9093
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4116
Epoch 1/10, Batch 20/97, Loss: 0.9741
Epoch 1/10, Batch 30/97, Loss: 0.9011
Epoch 1/10, Batch 40/97, Loss: 0.7828
Epoch 1/10, Batch 50/97, Loss: 0.6053
Epoch 1/10, Batch 60/97, Loss: 0.5713
Epoch 1/10, Batch 70/97, Loss: 0.4542
Epoch 1/10, Batch 80/97, Loss: 0.4661
Epoch 1/10, Batch 90/97, Loss: 0.5415
Epoch 1/10, Train Loss: 0.7760, Valid Loss: 0.4344
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3817
Epoch 2/10, Batch 20/97, Loss: 0.4978
Epoch 2/10, Batch 30/97, Loss: 0.4462
Epoch 2/10, Batch 40/97, Loss: 0.3840
Epoch 2/10, Batch 50/97, Loss: 0.6588
Epoch 2/10, Batch 60/97, Loss: 0.3154
Epoch 2/10, Batch 70/97, Loss: 0.3394
Epoch 2/10, Batch 80/97, Loss: 0.3641
Epoch 2/10, Batch 90/97, Loss: 0.3031
Epoch 2/10, Train Loss: 0.3935, Valid Loss: 0.3340
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2360
Epoch 3/10, Batch 20/97, Loss: 0.2325
Epoch 3/10, Batch 30/97, Loss: 0.1792
Epoch 3/10, Batch 40/97, Loss: 0.2400
Epoch 3/10, Batch 50/97, Loss: 0.3106
Epoch 3/10, Batch 60/97, Loss: 0.3142
Epoch 3/10, Batch 70/97, Loss: 0.2590
Epoch 3/10, Batch 80/97, Loss: 0.3534
Epoch 3/10, Batch 90/97, Loss: 0.3020
Epoch 3/10, Train Loss: 0.3192, Valid Loss: 0.2896
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3392
Epoch 4/10, Batch 20/97, Loss: 0.2252
Epoch 4/10, Batch 30/97, Loss: 0.6264
Epoch 4/10, Batch 40/97, Loss: 0.2569
Epoch 4/10, Batch 50/97, Loss: 0.0964
Epoch 4/10, Batch 60/97, Loss: 0.2235
Epoch 4/10, Batch 70/97, Loss: 0.2596
Epoch 4/10, Batch 80/97, Loss: 0.1702
Epoch 4/10, Batch 90/97, Loss: 0.2445
Epoch 4/10, Train Loss: 0.2833, Valid Loss: 0.2633
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1725
Epoch 5/10, Batch 20/97, Loss: 0.2222
Epoch 5/10, Batch 30/97, Loss: 0.1712
Epoch 5/10, Batch 40/97, Loss: 0.2582
Epoch 5/10, Batch 50/97, Loss: 0.2706
Epoch 5/10, Batch 60/97, Loss: 0.2469
Epoch 5/10, Batch 70/97, Loss: 0.1825
Epoch 5/10, Batch 80/97, Loss: 0.2776
Epoch 5/10, Batch 90/97, Loss: 0.3436
Epoch 5/10, Train Loss: 0.2555, Valid Loss: 0.2505
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2809
Epoch 6/10, Batch 20/97, Loss: 0.2012
Epoch 6/10, Batch 30/97, Loss: 0.1615
Epoch 6/10, Batch 40/97, Loss: 0.4053
Epoch 6/10, Batch 50/97, Loss: 0.1282
Epoch 6/10, Batch 60/97, Loss: 0.3015
Epoch 6/10, Batch 70/97, Loss: 0.2421
Epoch 6/10, Batch 80/97, Loss: 0.3292
Epoch 6/10, Batch 90/97, Loss: 0.3299
Epoch 6/10, Train Loss: 0.2374, Valid Loss: 0.2417
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2452
Epoch 7/10, Batch 20/97, Loss: 0.0943
Epoch 7/10, Batch 30/97, Loss: 0.0890
Epoch 7/10, Batch 40/97, Loss: 0.1266
Epoch 7/10, Batch 50/97, Loss: 0.1703
Epoch 7/10, Batch 60/97, Loss: 0.2627
Epoch 7/10, Batch 70/97, Loss: 0.1989
Epoch 7/10, Batch 80/97, Loss: 0.1870
Epoch 7/10, Batch 90/97, Loss: 0.2636
Epoch 7/10, Train Loss: 0.2376, Valid Loss: 0.2364
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1437
Epoch 8/10, Batch 20/97, Loss: 0.1464
Epoch 8/10, Batch 30/97, Loss: 0.0908
Epoch 8/10, Batch 40/97, Loss: 0.1355
Epoch 8/10, Batch 50/97, Loss: 0.1020
Epoch 8/10, Batch 60/97, Loss: 0.1436
Epoch 8/10, Batch 70/97, Loss: 0.4109
Epoch 8/10, Batch 80/97, Loss: 0.1406
Epoch 8/10, Batch 90/97, Loss: 0.1667
Epoch 8/10, Train Loss: 0.2186, Valid Loss: 0.2283
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1492
Epoch 9/10, Batch 20/97, Loss: 0.2150
Epoch 9/10, Batch 30/97, Loss: 0.3022
Epoch 9/10, Batch 40/97, Loss: 0.2229
Epoch 9/10, Batch 50/97, Loss: 0.2307
Epoch 9/10, Batch 60/97, Loss: 0.1161
Epoch 9/10, Batch 70/97, Loss: 0.2042
Epoch 9/10, Batch 80/97, Loss: 0.1649
Epoch 9/10, Batch 90/97, Loss: 0.1834
Epoch 9/10, Train Loss: 0.1949, Valid Loss: 0.2234
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2293
Epoch 10/10, Batch 20/97, Loss: 0.0859
Epoch 10/10, Batch 30/97, Loss: 0.1518
Epoch 10/10, Batch 40/97, Loss: 0.2639
Epoch 10/10, Batch 50/97, Loss: 0.1681
Epoch 10/10, Batch 60/97, Loss: 0.1243
Epoch 10/10, Batch 70/97, Loss: 0.3277
Epoch 10/10, Batch 80/97, Loss: 0.2437
Epoch 10/10, Batch 90/97, Loss: 0.1193
Epoch 10/10, Train Loss: 0.1907, Valid Loss: 0.2160
Model saved!
Accuracy: 0.9194
Precision: 0.9163
Recall: 0.9194
F1-score: 0.9171
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4320
Epoch 1/10, Batch 20/97, Loss: 1.0120
Epoch 1/10, Batch 30/97, Loss: 0.9251
Epoch 1/10, Batch 40/97, Loss: 0.6675
Epoch 1/10, Batch 50/97, Loss: 0.6673
Epoch 1/10, Batch 60/97, Loss: 0.5176
Epoch 1/10, Batch 70/97, Loss: 0.5299
Epoch 1/10, Batch 80/97, Loss: 0.3736
Epoch 1/10, Batch 90/97, Loss: 0.5287
Epoch 1/10, Train Loss: 0.7749, Valid Loss: 0.4500
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4812
Epoch 2/10, Batch 20/97, Loss: 0.5257
Epoch 2/10, Batch 30/97, Loss: 0.4502
Epoch 2/10, Batch 40/97, Loss: 0.5119
Epoch 2/10, Batch 50/97, Loss: 0.6849
Epoch 2/10, Batch 60/97, Loss: 0.2761
Epoch 2/10, Batch 70/97, Loss: 0.4069
Epoch 2/10, Batch 80/97, Loss: 0.3823
Epoch 2/10, Batch 90/97, Loss: 0.2888
Epoch 2/10, Train Loss: 0.3952, Valid Loss: 0.3496
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3077
Epoch 3/10, Batch 20/97, Loss: 0.4502
Epoch 3/10, Batch 30/97, Loss: 0.2723
Epoch 3/10, Batch 40/97, Loss: 0.3444
Epoch 3/10, Batch 50/97, Loss: 0.2953
Epoch 3/10, Batch 60/97, Loss: 0.3425
Epoch 3/10, Batch 70/97, Loss: 0.1292
Epoch 3/10, Batch 80/97, Loss: 0.3072
Epoch 3/10, Batch 90/97, Loss: 0.2874
Epoch 3/10, Train Loss: 0.3184, Valid Loss: 0.3026
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3699
Epoch 4/10, Batch 20/97, Loss: 0.3167
Epoch 4/10, Batch 30/97, Loss: 0.3167
Epoch 4/10, Batch 40/97, Loss: 0.2775
Epoch 4/10, Batch 50/97, Loss: 0.1907
Epoch 4/10, Batch 60/97, Loss: 0.1073
Epoch 4/10, Batch 70/97, Loss: 0.2211
Epoch 4/10, Batch 80/97, Loss: 0.2689
Epoch 4/10, Batch 90/97, Loss: 0.2690
Epoch 4/10, Train Loss: 0.2815, Valid Loss: 0.2804
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1695
Epoch 5/10, Batch 20/97, Loss: 0.2461
Epoch 5/10, Batch 30/97, Loss: 0.2745
Epoch 5/10, Batch 40/97, Loss: 0.1134
Epoch 5/10, Batch 50/97, Loss: 0.2557
Epoch 5/10, Batch 60/97, Loss: 0.2128
Epoch 5/10, Batch 70/97, Loss: 0.1957
Epoch 5/10, Batch 80/97, Loss: 0.3367
Epoch 5/10, Batch 90/97, Loss: 0.4997
Epoch 5/10, Train Loss: 0.2600, Valid Loss: 0.2619
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3627
Epoch 6/10, Batch 20/97, Loss: 0.2488
Epoch 6/10, Batch 30/97, Loss: 0.1373
Epoch 6/10, Batch 40/97, Loss: 0.2284
Epoch 6/10, Batch 50/97, Loss: 0.2356
Epoch 6/10, Batch 60/97, Loss: 0.1587
Epoch 6/10, Batch 70/97, Loss: 0.2350
Epoch 6/10, Batch 80/97, Loss: 0.2174
Epoch 6/10, Batch 90/97, Loss: 0.1967
Epoch 6/10, Train Loss: 0.2399, Valid Loss: 0.2632
Epoch 7/10, Batch 10/97, Loss: 0.3275
Epoch 7/10, Batch 20/97, Loss: 0.1113
Epoch 7/10, Batch 30/97, Loss: 0.2484
Epoch 7/10, Batch 40/97, Loss: 0.2651
Epoch 7/10, Batch 50/97, Loss: 0.2059
Epoch 7/10, Batch 60/97, Loss: 0.2991
Epoch 7/10, Batch 70/97, Loss: 0.2841
Epoch 7/10, Batch 80/97, Loss: 0.1892
Epoch 7/10, Batch 90/97, Loss: 0.2107
Epoch 7/10, Train Loss: 0.2396, Valid Loss: 0.2499
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2046
Epoch 8/10, Batch 20/97, Loss: 0.1614
Epoch 8/10, Batch 30/97, Loss: 0.2196
Epoch 8/10, Batch 40/97, Loss: 0.2290
Epoch 8/10, Batch 50/97, Loss: 0.2679
Epoch 8/10, Batch 60/97, Loss: 0.1586
Epoch 8/10, Batch 70/97, Loss: 0.3245
Epoch 8/10, Batch 80/97, Loss: 0.1210
Epoch 8/10, Batch 90/97, Loss: 0.1892
Epoch 8/10, Train Loss: 0.2185, Valid Loss: 0.2477
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1413
Epoch 9/10, Batch 20/97, Loss: 0.1008
Epoch 9/10, Batch 30/97, Loss: 0.2207
Epoch 9/10, Batch 40/97, Loss: 0.0960
Epoch 9/10, Batch 50/97, Loss: 0.1482
Epoch 9/10, Batch 60/97, Loss: 0.1161
Epoch 9/10, Batch 70/97, Loss: 0.1376
Epoch 9/10, Batch 80/97, Loss: 0.2156
Epoch 9/10, Batch 90/97, Loss: 0.1809
Epoch 9/10, Train Loss: 0.2022, Valid Loss: 0.2448
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2580
Epoch 10/10, Batch 20/97, Loss: 0.2299
Epoch 10/10, Batch 30/97, Loss: 0.3625
Epoch 10/10, Batch 40/97, Loss: 0.1818
Epoch 10/10, Batch 50/97, Loss: 0.2367
Epoch 10/10, Batch 60/97, Loss: 0.1538
Epoch 10/10, Batch 70/97, Loss: 0.3336
Epoch 10/10, Batch 80/97, Loss: 0.3754
Epoch 10/10, Batch 90/97, Loss: 0.1878
Epoch 10/10, Train Loss: 0.1962, Valid Loss: 0.2354
Model saved!
Accuracy: 0.9147
Precision: 0.9123
Recall: 0.9147
F1-score: 0.9125
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5166
Epoch 1/10, Batch 20/97, Loss: 1.0126
Epoch 1/10, Batch 30/97, Loss: 0.8918
Epoch 1/10, Batch 40/97, Loss: 0.8398
Epoch 1/10, Batch 50/97, Loss: 0.6130
Epoch 1/10, Batch 60/97, Loss: 0.6014
Epoch 1/10, Batch 70/97, Loss: 0.6647
Epoch 1/10, Batch 80/97, Loss: 0.5163
Epoch 1/10, Batch 90/97, Loss: 0.4831
Epoch 1/10, Train Loss: 0.7757, Valid Loss: 0.4549
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3212
Epoch 2/10, Batch 20/97, Loss: 0.3690
Epoch 2/10, Batch 30/97, Loss: 0.4892
Epoch 2/10, Batch 40/97, Loss: 0.4793
Epoch 2/10, Batch 50/97, Loss: 0.5626
Epoch 2/10, Batch 60/97, Loss: 0.4799
Epoch 2/10, Batch 70/97, Loss: 0.3563
Epoch 2/10, Batch 80/97, Loss: 0.2029
Epoch 2/10, Batch 90/97, Loss: 0.3466
Epoch 2/10, Train Loss: 0.3921, Valid Loss: 0.3440
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3074
Epoch 3/10, Batch 20/97, Loss: 0.3039
Epoch 3/10, Batch 30/97, Loss: 0.3352
Epoch 3/10, Batch 40/97, Loss: 0.3745
Epoch 3/10, Batch 50/97, Loss: 0.3258
Epoch 3/10, Batch 60/97, Loss: 0.1638
Epoch 3/10, Batch 70/97, Loss: 0.2638
Epoch 3/10, Batch 80/97, Loss: 0.3373
Epoch 3/10, Batch 90/97, Loss: 0.2255
Epoch 3/10, Train Loss: 0.3224, Valid Loss: 0.3208
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1356
Epoch 4/10, Batch 20/97, Loss: 0.1606
Epoch 4/10, Batch 30/97, Loss: 0.2488
Epoch 4/10, Batch 40/97, Loss: 0.2555
Epoch 4/10, Batch 50/97, Loss: 0.1861
Epoch 4/10, Batch 60/97, Loss: 0.1589
Epoch 4/10, Batch 70/97, Loss: 0.2478
Epoch 4/10, Batch 80/97, Loss: 0.2291
Epoch 4/10, Batch 90/97, Loss: 0.2132
Epoch 4/10, Train Loss: 0.2843, Valid Loss: 0.2898
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2251
Epoch 5/10, Batch 20/97, Loss: 0.2299
Epoch 5/10, Batch 30/97, Loss: 0.1745
Epoch 5/10, Batch 40/97, Loss: 0.2328
Epoch 5/10, Batch 50/97, Loss: 0.1521
Epoch 5/10, Batch 60/97, Loss: 0.2616
Epoch 5/10, Batch 70/97, Loss: 0.2607
Epoch 5/10, Batch 80/97, Loss: 0.2734
Epoch 5/10, Batch 90/97, Loss: 0.3218
Epoch 5/10, Train Loss: 0.2486, Valid Loss: 0.2711
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1760
Epoch 6/10, Batch 20/97, Loss: 0.2101
Epoch 6/10, Batch 30/97, Loss: 0.1390
Epoch 6/10, Batch 40/97, Loss: 0.2195
Epoch 6/10, Batch 50/97, Loss: 0.2361
Epoch 6/10, Batch 60/97, Loss: 0.2753
Epoch 6/10, Batch 70/97, Loss: 0.2131
Epoch 6/10, Batch 80/97, Loss: 0.1534
Epoch 6/10, Batch 90/97, Loss: 0.1820
Epoch 6/10, Train Loss: 0.2403, Valid Loss: 0.2592
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2061
Epoch 7/10, Batch 20/97, Loss: 0.1429
Epoch 7/10, Batch 30/97, Loss: 0.1332
Epoch 7/10, Batch 40/97, Loss: 0.2483
Epoch 7/10, Batch 50/97, Loss: 0.1771
Epoch 7/10, Batch 60/97, Loss: 0.4170
Epoch 7/10, Batch 70/97, Loss: 0.2127
Epoch 7/10, Batch 80/97, Loss: 0.2513
Epoch 7/10, Batch 90/97, Loss: 0.3588
Epoch 7/10, Train Loss: 0.2363, Valid Loss: 0.2617
Epoch 8/10, Batch 10/97, Loss: 0.3494
Epoch 8/10, Batch 20/97, Loss: 0.2555
Epoch 8/10, Batch 30/97, Loss: 0.1258
Epoch 8/10, Batch 40/97, Loss: 0.1963
Epoch 8/10, Batch 50/97, Loss: 0.1857
Epoch 8/10, Batch 60/97, Loss: 0.1898
Epoch 8/10, Batch 70/97, Loss: 0.2994
Epoch 8/10, Batch 80/97, Loss: 0.1682
Epoch 8/10, Batch 90/97, Loss: 0.2403
Epoch 8/10, Train Loss: 0.2090, Valid Loss: 0.2444
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1444
Epoch 9/10, Batch 20/97, Loss: 0.1528
Epoch 9/10, Batch 30/97, Loss: 0.3013
Epoch 9/10, Batch 40/97, Loss: 0.2118
Epoch 9/10, Batch 50/97, Loss: 0.2600
Epoch 9/10, Batch 60/97, Loss: 0.0710
Epoch 9/10, Batch 70/97, Loss: 0.1794
Epoch 9/10, Batch 80/97, Loss: 0.1830
Epoch 9/10, Batch 90/97, Loss: 0.2491
Epoch 9/10, Train Loss: 0.1970, Valid Loss: 0.2426
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1860
Epoch 10/10, Batch 20/97, Loss: 0.1142
Epoch 10/10, Batch 30/97, Loss: 0.1388
Epoch 10/10, Batch 40/97, Loss: 0.2121
Epoch 10/10, Batch 50/97, Loss: 0.3747
Epoch 10/10, Batch 60/97, Loss: 0.1379
Epoch 10/10, Batch 70/97, Loss: 0.1339
Epoch 10/10, Batch 80/97, Loss: 0.3813
Epoch 10/10, Batch 90/97, Loss: 0.1524
Epoch 10/10, Train Loss: 0.1951, Valid Loss: 0.2462
Accuracy: 0.9182
Precision: 0.9155
Recall: 0.9182
F1-score: 0.9161
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4378
Epoch 1/10, Batch 20/97, Loss: 0.9939
Epoch 1/10, Batch 30/97, Loss: 0.8939
Epoch 1/10, Batch 40/97, Loss: 0.7206
Epoch 1/10, Batch 50/97, Loss: 0.7907
Epoch 1/10, Batch 60/97, Loss: 0.6351
Epoch 1/10, Batch 70/97, Loss: 0.6066
Epoch 1/10, Batch 80/97, Loss: 0.6522
Epoch 1/10, Batch 90/97, Loss: 0.4725
Epoch 1/10, Train Loss: 0.7744, Valid Loss: 0.4455
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4830
Epoch 2/10, Batch 20/97, Loss: 0.4149
Epoch 2/10, Batch 30/97, Loss: 0.3492
Epoch 2/10, Batch 40/97, Loss: 0.5942
Epoch 2/10, Batch 50/97, Loss: 0.5899
Epoch 2/10, Batch 60/97, Loss: 0.2504
Epoch 2/10, Batch 70/97, Loss: 0.3882
Epoch 2/10, Batch 80/97, Loss: 0.4130
Epoch 2/10, Batch 90/97, Loss: 0.3174
Epoch 2/10, Train Loss: 0.4012, Valid Loss: 0.3353
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3252
Epoch 3/10, Batch 20/97, Loss: 0.3514
Epoch 3/10, Batch 30/97, Loss: 0.2587
Epoch 3/10, Batch 40/97, Loss: 0.3248
Epoch 3/10, Batch 50/97, Loss: 0.1873
Epoch 3/10, Batch 60/97, Loss: 0.2745
Epoch 3/10, Batch 70/97, Loss: 0.2071
Epoch 3/10, Batch 80/97, Loss: 0.3635
Epoch 3/10, Batch 90/97, Loss: 0.2019
Epoch 3/10, Train Loss: 0.3302, Valid Loss: 0.2825
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2129
Epoch 4/10, Batch 20/97, Loss: 0.1787
Epoch 4/10, Batch 30/97, Loss: 0.4683
Epoch 4/10, Batch 40/97, Loss: 0.3155
Epoch 4/10, Batch 50/97, Loss: 0.1756
Epoch 4/10, Batch 60/97, Loss: 0.1972
Epoch 4/10, Batch 70/97, Loss: 0.2596
Epoch 4/10, Batch 80/97, Loss: 0.4278
Epoch 4/10, Batch 90/97, Loss: 0.2290
Epoch 4/10, Train Loss: 0.2956, Valid Loss: 0.2644
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2340
Epoch 5/10, Batch 20/97, Loss: 0.1162
Epoch 5/10, Batch 30/97, Loss: 0.1657
Epoch 5/10, Batch 40/97, Loss: 0.1556
Epoch 5/10, Batch 50/97, Loss: 0.3012
Epoch 5/10, Batch 60/97, Loss: 0.3201
Epoch 5/10, Batch 70/97, Loss: 0.3574
Epoch 5/10, Batch 80/97, Loss: 0.3703
Epoch 5/10, Batch 90/97, Loss: 0.4643
Epoch 5/10, Train Loss: 0.2643, Valid Loss: 0.2554
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3401
Epoch 6/10, Batch 20/97, Loss: 0.2511
Epoch 6/10, Batch 30/97, Loss: 0.1061
Epoch 6/10, Batch 40/97, Loss: 0.3432
Epoch 6/10, Batch 50/97, Loss: 0.3596
Epoch 6/10, Batch 60/97, Loss: 0.2990
Epoch 6/10, Batch 70/97, Loss: 0.1788
Epoch 6/10, Batch 80/97, Loss: 0.1818
Epoch 6/10, Batch 90/97, Loss: 0.2226
Epoch 6/10, Train Loss: 0.2414, Valid Loss: 0.2405
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4670
Epoch 7/10, Batch 20/97, Loss: 0.1176
Epoch 7/10, Batch 30/97, Loss: 0.2370
Epoch 7/10, Batch 40/97, Loss: 0.1801
Epoch 7/10, Batch 50/97, Loss: 0.1825
Epoch 7/10, Batch 60/97, Loss: 0.3478
Epoch 7/10, Batch 70/97, Loss: 0.3877
Epoch 7/10, Batch 80/97, Loss: 0.3084
Epoch 7/10, Batch 90/97, Loss: 0.2892
Epoch 7/10, Train Loss: 0.2523, Valid Loss: 0.2277
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1540
Epoch 8/10, Batch 20/97, Loss: 0.1415
Epoch 8/10, Batch 30/97, Loss: 0.1722
Epoch 8/10, Batch 40/97, Loss: 0.1535
Epoch 8/10, Batch 50/97, Loss: 0.1254
Epoch 8/10, Batch 60/97, Loss: 0.2705
Epoch 8/10, Batch 70/97, Loss: 0.2344
Epoch 8/10, Batch 80/97, Loss: 0.0787
Epoch 8/10, Batch 90/97, Loss: 0.1418
Epoch 8/10, Train Loss: 0.2248, Valid Loss: 0.2244
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1467
Epoch 9/10, Batch 20/97, Loss: 0.0841
Epoch 9/10, Batch 30/97, Loss: 0.2726
Epoch 9/10, Batch 40/97, Loss: 0.1566
Epoch 9/10, Batch 50/97, Loss: 0.2627
Epoch 9/10, Batch 60/97, Loss: 0.3263
Epoch 9/10, Batch 70/97, Loss: 0.2779
Epoch 9/10, Batch 80/97, Loss: 0.1440
Epoch 9/10, Batch 90/97, Loss: 0.1960
Epoch 9/10, Train Loss: 0.2043, Valid Loss: 0.2231
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3337
Epoch 10/10, Batch 20/97, Loss: 0.2155
Epoch 10/10, Batch 30/97, Loss: 0.1743
Epoch 10/10, Batch 40/97, Loss: 0.1310
Epoch 10/10, Batch 50/97, Loss: 0.2013
Epoch 10/10, Batch 60/97, Loss: 0.1750
Epoch 10/10, Batch 70/97, Loss: 0.2451
Epoch 10/10, Batch 80/97, Loss: 0.2008
Epoch 10/10, Batch 90/97, Loss: 0.1553
Epoch 10/10, Train Loss: 0.1968, Valid Loss: 0.2193
Model saved!
Accuracy: 0.9194
Precision: 0.9173
Recall: 0.9194
F1-score: 0.9180
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5096
Epoch 1/10, Batch 20/97, Loss: 1.0393
Epoch 1/10, Batch 30/97, Loss: 0.8466
Epoch 1/10, Batch 40/97, Loss: 0.7903
Epoch 1/10, Batch 50/97, Loss: 0.6928
Epoch 1/10, Batch 60/97, Loss: 0.6618
Epoch 1/10, Batch 70/97, Loss: 0.4877
Epoch 1/10, Batch 80/97, Loss: 0.5134
Epoch 1/10, Batch 90/97, Loss: 0.4729
Epoch 1/10, Train Loss: 0.7755, Valid Loss: 0.4565
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3997
Epoch 2/10, Batch 20/97, Loss: 0.4557
Epoch 2/10, Batch 30/97, Loss: 0.4592
Epoch 2/10, Batch 40/97, Loss: 0.4239
Epoch 2/10, Batch 50/97, Loss: 0.5852
Epoch 2/10, Batch 60/97, Loss: 0.4168
Epoch 2/10, Batch 70/97, Loss: 0.2585
Epoch 2/10, Batch 80/97, Loss: 0.3257
Epoch 2/10, Batch 90/97, Loss: 0.2941
Epoch 2/10, Train Loss: 0.3959, Valid Loss: 0.3545
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3403
Epoch 3/10, Batch 20/97, Loss: 0.3016
Epoch 3/10, Batch 30/97, Loss: 0.2338
Epoch 3/10, Batch 40/97, Loss: 0.2598
Epoch 3/10, Batch 50/97, Loss: 0.2781
Epoch 3/10, Batch 60/97, Loss: 0.3257
Epoch 3/10, Batch 70/97, Loss: 0.2070
Epoch 3/10, Batch 80/97, Loss: 0.3742
Epoch 3/10, Batch 90/97, Loss: 0.2021
Epoch 3/10, Train Loss: 0.3235, Valid Loss: 0.3121
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2494
Epoch 4/10, Batch 20/97, Loss: 0.1684
Epoch 4/10, Batch 30/97, Loss: 0.2533
Epoch 4/10, Batch 40/97, Loss: 0.2790
Epoch 4/10, Batch 50/97, Loss: 0.1852
Epoch 4/10, Batch 60/97, Loss: 0.2004
Epoch 4/10, Batch 70/97, Loss: 0.2148
Epoch 4/10, Batch 80/97, Loss: 0.2263
Epoch 4/10, Batch 90/97, Loss: 0.2895
Epoch 4/10, Train Loss: 0.2806, Valid Loss: 0.2836
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1644
Epoch 5/10, Batch 20/97, Loss: 0.1915
Epoch 5/10, Batch 30/97, Loss: 0.3199
Epoch 5/10, Batch 40/97, Loss: 0.2932
Epoch 5/10, Batch 50/97, Loss: 0.3045
Epoch 5/10, Batch 60/97, Loss: 0.2934
Epoch 5/10, Batch 70/97, Loss: 0.2159
Epoch 5/10, Batch 80/97, Loss: 0.1743
Epoch 5/10, Batch 90/97, Loss: 0.2924
Epoch 5/10, Train Loss: 0.2513, Valid Loss: 0.2702
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1876
Epoch 6/10, Batch 20/97, Loss: 0.2236
Epoch 6/10, Batch 30/97, Loss: 0.2056
Epoch 6/10, Batch 40/97, Loss: 0.3187
Epoch 6/10, Batch 50/97, Loss: 0.1726
Epoch 6/10, Batch 60/97, Loss: 0.3686
Epoch 6/10, Batch 70/97, Loss: 0.2098
Epoch 6/10, Batch 80/97, Loss: 0.1181
Epoch 6/10, Batch 90/97, Loss: 0.3541
Epoch 6/10, Train Loss: 0.2393, Valid Loss: 0.2658
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3150
Epoch 7/10, Batch 20/97, Loss: 0.1559
Epoch 7/10, Batch 30/97, Loss: 0.1725
Epoch 7/10, Batch 40/97, Loss: 0.1678
Epoch 7/10, Batch 50/97, Loss: 0.2138
Epoch 7/10, Batch 60/97, Loss: 0.3049
Epoch 7/10, Batch 70/97, Loss: 0.1757
Epoch 7/10, Batch 80/97, Loss: 0.1831
Epoch 7/10, Batch 90/97, Loss: 0.3438
Epoch 7/10, Train Loss: 0.2385, Valid Loss: 0.2505
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1366
Epoch 8/10, Batch 20/97, Loss: 0.1600
Epoch 8/10, Batch 30/97, Loss: 0.1434
Epoch 8/10, Batch 40/97, Loss: 0.1528
Epoch 8/10, Batch 50/97, Loss: 0.2012
Epoch 8/10, Batch 60/97, Loss: 0.0977
Epoch 8/10, Batch 70/97, Loss: 0.2398
Epoch 8/10, Batch 80/97, Loss: 0.1129
Epoch 8/10, Batch 90/97, Loss: 0.1996
Epoch 8/10, Train Loss: 0.2083, Valid Loss: 0.2407
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1667
Epoch 9/10, Batch 20/97, Loss: 0.0927
Epoch 9/10, Batch 30/97, Loss: 0.2763
Epoch 9/10, Batch 40/97, Loss: 0.1338
Epoch 9/10, Batch 50/97, Loss: 0.3671
Epoch 9/10, Batch 60/97, Loss: 0.1552
Epoch 9/10, Batch 70/97, Loss: 0.3251
Epoch 9/10, Batch 80/97, Loss: 0.1326
Epoch 9/10, Batch 90/97, Loss: 0.2041
Epoch 9/10, Train Loss: 0.2046, Valid Loss: 0.2390
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2748
Epoch 10/10, Batch 20/97, Loss: 0.1523
Epoch 10/10, Batch 30/97, Loss: 0.1162
Epoch 10/10, Batch 40/97, Loss: 0.2349
Epoch 10/10, Batch 50/97, Loss: 0.1519
Epoch 10/10, Batch 60/97, Loss: 0.2389
Epoch 10/10, Batch 70/97, Loss: 0.1038
Epoch 10/10, Batch 80/97, Loss: 0.1500
Epoch 10/10, Batch 90/97, Loss: 0.2105
Epoch 10/10, Train Loss: 0.1943, Valid Loss: 0.2325
Model saved!
Accuracy: 0.9194
Precision: 0.9178
Recall: 0.9194
F1-score: 0.9181
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4224
Epoch 1/10, Batch 20/97, Loss: 1.0412
Epoch 1/10, Batch 30/97, Loss: 0.8919
Epoch 1/10, Batch 40/97, Loss: 0.6509
Epoch 1/10, Batch 50/97, Loss: 0.5944
Epoch 1/10, Batch 60/97, Loss: 0.5395
Epoch 1/10, Batch 70/97, Loss: 0.5630
Epoch 1/10, Batch 80/97, Loss: 0.4542
Epoch 1/10, Batch 90/97, Loss: 0.5055
Epoch 1/10, Train Loss: 0.7711, Valid Loss: 0.4279
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3967
Epoch 2/10, Batch 20/97, Loss: 0.4563
Epoch 2/10, Batch 30/97, Loss: 0.4146
Epoch 2/10, Batch 40/97, Loss: 0.3417
Epoch 2/10, Batch 50/97, Loss: 0.5647
Epoch 2/10, Batch 60/97, Loss: 0.2915
Epoch 2/10, Batch 70/97, Loss: 0.3238
Epoch 2/10, Batch 80/97, Loss: 0.2340
Epoch 2/10, Batch 90/97, Loss: 0.3668
Epoch 2/10, Train Loss: 0.3903, Valid Loss: 0.3320
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3580
Epoch 3/10, Batch 20/97, Loss: 0.4136
Epoch 3/10, Batch 30/97, Loss: 0.2173
Epoch 3/10, Batch 40/97, Loss: 0.3306
Epoch 3/10, Batch 50/97, Loss: 0.2184
Epoch 3/10, Batch 60/97, Loss: 0.3719
Epoch 3/10, Batch 70/97, Loss: 0.2232
Epoch 3/10, Batch 80/97, Loss: 0.3825
Epoch 3/10, Batch 90/97, Loss: 0.2340
Epoch 3/10, Train Loss: 0.3185, Valid Loss: 0.2912
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3169
Epoch 4/10, Batch 20/97, Loss: 0.1883
Epoch 4/10, Batch 30/97, Loss: 0.3198
Epoch 4/10, Batch 40/97, Loss: 0.2479
Epoch 4/10, Batch 50/97, Loss: 0.1753
Epoch 4/10, Batch 60/97, Loss: 0.1992
Epoch 4/10, Batch 70/97, Loss: 0.2293
Epoch 4/10, Batch 80/97, Loss: 0.2915
Epoch 4/10, Batch 90/97, Loss: 0.2751
Epoch 4/10, Train Loss: 0.2799, Valid Loss: 0.2664
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3149
Epoch 5/10, Batch 20/97, Loss: 0.1879
Epoch 5/10, Batch 30/97, Loss: 0.1534
Epoch 5/10, Batch 40/97, Loss: 0.1430
Epoch 5/10, Batch 50/97, Loss: 0.2333
Epoch 5/10, Batch 60/97, Loss: 0.2277
Epoch 5/10, Batch 70/97, Loss: 0.2277
Epoch 5/10, Batch 80/97, Loss: 0.2567
Epoch 5/10, Batch 90/97, Loss: 0.4092
Epoch 5/10, Train Loss: 0.2533, Valid Loss: 0.2538
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1481
Epoch 6/10, Batch 20/97, Loss: 0.2441
Epoch 6/10, Batch 30/97, Loss: 0.2555
Epoch 6/10, Batch 40/97, Loss: 0.3372
Epoch 6/10, Batch 50/97, Loss: 0.2094
Epoch 6/10, Batch 60/97, Loss: 0.3400
Epoch 6/10, Batch 70/97, Loss: 0.2911
Epoch 6/10, Batch 80/97, Loss: 0.1956
Epoch 6/10, Batch 90/97, Loss: 0.2228
Epoch 6/10, Train Loss: 0.2376, Valid Loss: 0.2493
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2632
Epoch 7/10, Batch 20/97, Loss: 0.2030
Epoch 7/10, Batch 30/97, Loss: 0.1476
Epoch 7/10, Batch 40/97, Loss: 0.2221
Epoch 7/10, Batch 50/97, Loss: 0.1356
Epoch 7/10, Batch 60/97, Loss: 0.3822
Epoch 7/10, Batch 70/97, Loss: 0.3174
Epoch 7/10, Batch 80/97, Loss: 0.2142
Epoch 7/10, Batch 90/97, Loss: 0.1513
Epoch 7/10, Train Loss: 0.2364, Valid Loss: 0.2390
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1300
Epoch 8/10, Batch 20/97, Loss: 0.2328
Epoch 8/10, Batch 30/97, Loss: 0.1107
Epoch 8/10, Batch 40/97, Loss: 0.1446
Epoch 8/10, Batch 50/97, Loss: 0.3997
Epoch 8/10, Batch 60/97, Loss: 0.1593
Epoch 8/10, Batch 70/97, Loss: 0.2568
Epoch 8/10, Batch 80/97, Loss: 0.2158
Epoch 8/10, Batch 90/97, Loss: 0.1327
Epoch 8/10, Train Loss: 0.2120, Valid Loss: 0.2473
Epoch 9/10, Batch 10/97, Loss: 0.1692
Epoch 9/10, Batch 20/97, Loss: 0.1107
Epoch 9/10, Batch 30/97, Loss: 0.2297
Epoch 9/10, Batch 40/97, Loss: 0.1481
Epoch 9/10, Batch 50/97, Loss: 0.1772
Epoch 9/10, Batch 60/97, Loss: 0.1609
Epoch 9/10, Batch 70/97, Loss: 0.1540
Epoch 9/10, Batch 80/97, Loss: 0.1591
Epoch 9/10, Batch 90/97, Loss: 0.1732
Epoch 9/10, Train Loss: 0.2012, Valid Loss: 0.2439
Epoch 10/10, Batch 10/97, Loss: 0.2196
Epoch 10/10, Batch 20/97, Loss: 0.1996
Epoch 10/10, Batch 30/97, Loss: 0.1594
Epoch 10/10, Batch 40/97, Loss: 0.2427
Epoch 10/10, Batch 50/97, Loss: 0.2844
Epoch 10/10, Batch 60/97, Loss: 0.1048
Epoch 10/10, Batch 70/97, Loss: 0.2166
Epoch 10/10, Batch 80/97, Loss: 0.2665
Epoch 10/10, Batch 90/97, Loss: 0.1291
Epoch 10/10, Train Loss: 0.1936, Valid Loss: 0.2349
Model saved!
Accuracy: 0.9147
Precision: 0.9121
Recall: 0.9147
F1-score: 0.9129
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5119
Epoch 1/10, Batch 20/97, Loss: 1.0203
Epoch 1/10, Batch 30/97, Loss: 0.8982
Epoch 1/10, Batch 40/97, Loss: 0.7385
Epoch 1/10, Batch 50/97, Loss: 0.6074
Epoch 1/10, Batch 60/97, Loss: 0.5644
Epoch 1/10, Batch 70/97, Loss: 0.4680
Epoch 1/10, Batch 80/97, Loss: 0.4413
Epoch 1/10, Batch 90/97, Loss: 0.5323
Epoch 1/10, Train Loss: 0.7736, Valid Loss: 0.4318
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3619
Epoch 2/10, Batch 20/97, Loss: 0.4277
Epoch 2/10, Batch 30/97, Loss: 0.4230
Epoch 2/10, Batch 40/97, Loss: 0.4239
Epoch 2/10, Batch 50/97, Loss: 0.6489
Epoch 2/10, Batch 60/97, Loss: 0.2301
Epoch 2/10, Batch 70/97, Loss: 0.3623
Epoch 2/10, Batch 80/97, Loss: 0.3243
Epoch 2/10, Batch 90/97, Loss: 0.2506
Epoch 2/10, Train Loss: 0.3981, Valid Loss: 0.3252
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2756
Epoch 3/10, Batch 20/97, Loss: 0.3600
Epoch 3/10, Batch 30/97, Loss: 0.3034
Epoch 3/10, Batch 40/97, Loss: 0.3040
Epoch 3/10, Batch 50/97, Loss: 0.2103
Epoch 3/10, Batch 60/97, Loss: 0.1919
Epoch 3/10, Batch 70/97, Loss: 0.2339
Epoch 3/10, Batch 80/97, Loss: 0.2541
Epoch 3/10, Batch 90/97, Loss: 0.2992
Epoch 3/10, Train Loss: 0.3288, Valid Loss: 0.2894
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2154
Epoch 4/10, Batch 20/97, Loss: 0.2246
Epoch 4/10, Batch 30/97, Loss: 0.3353
Epoch 4/10, Batch 40/97, Loss: 0.3334
Epoch 4/10, Batch 50/97, Loss: 0.1299
Epoch 4/10, Batch 60/97, Loss: 0.1840
Epoch 4/10, Batch 70/97, Loss: 0.2321
Epoch 4/10, Batch 80/97, Loss: 0.3396
Epoch 4/10, Batch 90/97, Loss: 0.2799
Epoch 4/10, Train Loss: 0.2861, Valid Loss: 0.2621
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2143
Epoch 5/10, Batch 20/97, Loss: 0.2421
Epoch 5/10, Batch 30/97, Loss: 0.1168
Epoch 5/10, Batch 40/97, Loss: 0.1824
Epoch 5/10, Batch 50/97, Loss: 0.2099
Epoch 5/10, Batch 60/97, Loss: 0.2553
Epoch 5/10, Batch 70/97, Loss: 0.1564
Epoch 5/10, Batch 80/97, Loss: 0.2951
Epoch 5/10, Batch 90/97, Loss: 0.3270
Epoch 5/10, Train Loss: 0.2559, Valid Loss: 0.2481
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1432
Epoch 6/10, Batch 20/97, Loss: 0.1784
Epoch 6/10, Batch 30/97, Loss: 0.1620
Epoch 6/10, Batch 40/97, Loss: 0.2505
Epoch 6/10, Batch 50/97, Loss: 0.1224
Epoch 6/10, Batch 60/97, Loss: 0.1870
Epoch 6/10, Batch 70/97, Loss: 0.2256
Epoch 6/10, Batch 80/97, Loss: 0.2784
Epoch 6/10, Batch 90/97, Loss: 0.2141
Epoch 6/10, Train Loss: 0.2358, Valid Loss: 0.2413
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4690
Epoch 7/10, Batch 20/97, Loss: 0.0965
Epoch 7/10, Batch 30/97, Loss: 0.3362
Epoch 7/10, Batch 40/97, Loss: 0.1901
Epoch 7/10, Batch 50/97, Loss: 0.1726
Epoch 7/10, Batch 60/97, Loss: 0.3648
Epoch 7/10, Batch 70/97, Loss: 0.1746
Epoch 7/10, Batch 80/97, Loss: 0.1922
Epoch 7/10, Batch 90/97, Loss: 0.2727
Epoch 7/10, Train Loss: 0.2439, Valid Loss: 0.2430
Epoch 8/10, Batch 10/97, Loss: 0.2115
Epoch 8/10, Batch 20/97, Loss: 0.2874
Epoch 8/10, Batch 30/97, Loss: 0.2590
Epoch 8/10, Batch 40/97, Loss: 0.1844
Epoch 8/10, Batch 50/97, Loss: 0.1812
Epoch 8/10, Batch 60/97, Loss: 0.1995
Epoch 8/10, Batch 70/97, Loss: 0.3083
Epoch 8/10, Batch 80/97, Loss: 0.0983
Epoch 8/10, Batch 90/97, Loss: 0.2169
Epoch 8/10, Train Loss: 0.2102, Valid Loss: 0.2315
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1884
Epoch 9/10, Batch 20/97, Loss: 0.1100
Epoch 9/10, Batch 30/97, Loss: 0.2935
Epoch 9/10, Batch 40/97, Loss: 0.2605
Epoch 9/10, Batch 50/97, Loss: 0.0922
Epoch 9/10, Batch 60/97, Loss: 0.2420
Epoch 9/10, Batch 70/97, Loss: 0.2688
Epoch 9/10, Batch 80/97, Loss: 0.1514
Epoch 9/10, Batch 90/97, Loss: 0.3288
Epoch 9/10, Train Loss: 0.2044, Valid Loss: 0.2275
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1828
Epoch 10/10, Batch 20/97, Loss: 0.1863
Epoch 10/10, Batch 30/97, Loss: 0.1578
Epoch 10/10, Batch 40/97, Loss: 0.2133
Epoch 10/10, Batch 50/97, Loss: 0.2354
Epoch 10/10, Batch 60/97, Loss: 0.1926
Epoch 10/10, Batch 70/97, Loss: 0.1892
Epoch 10/10, Batch 80/97, Loss: 0.1653
Epoch 10/10, Batch 90/97, Loss: 0.2199
Epoch 10/10, Train Loss: 0.1949, Valid Loss: 0.2189
Model saved!
Accuracy: 0.9147
Precision: 0.9121
Recall: 0.9147
F1-score: 0.9125
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5007
Epoch 1/10, Batch 20/97, Loss: 1.0057
Epoch 1/10, Batch 30/97, Loss: 0.8794
Epoch 1/10, Batch 40/97, Loss: 0.7004
Epoch 1/10, Batch 50/97, Loss: 0.6855
Epoch 1/10, Batch 60/97, Loss: 0.6170
Epoch 1/10, Batch 70/97, Loss: 0.4224
Epoch 1/10, Batch 80/97, Loss: 0.4713
Epoch 1/10, Batch 90/97, Loss: 0.5067
Epoch 1/10, Train Loss: 0.7697, Valid Loss: 0.4447
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5015
Epoch 2/10, Batch 20/97, Loss: 0.3459
Epoch 2/10, Batch 30/97, Loss: 0.3707
Epoch 2/10, Batch 40/97, Loss: 0.3966
Epoch 2/10, Batch 50/97, Loss: 0.5779
Epoch 2/10, Batch 60/97, Loss: 0.3435
Epoch 2/10, Batch 70/97, Loss: 0.4212
Epoch 2/10, Batch 80/97, Loss: 0.3337
Epoch 2/10, Batch 90/97, Loss: 0.4167
Epoch 2/10, Train Loss: 0.3878, Valid Loss: 0.3337
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2797
Epoch 3/10, Batch 20/97, Loss: 0.2986
Epoch 3/10, Batch 30/97, Loss: 0.2725
Epoch 3/10, Batch 40/97, Loss: 0.2492
Epoch 3/10, Batch 50/97, Loss: 0.2827
Epoch 3/10, Batch 60/97, Loss: 0.1632
Epoch 3/10, Batch 70/97, Loss: 0.1967
Epoch 3/10, Batch 80/97, Loss: 0.3397
Epoch 3/10, Batch 90/97, Loss: 0.2814
Epoch 3/10, Train Loss: 0.3227, Valid Loss: 0.2922
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3575
Epoch 4/10, Batch 20/97, Loss: 0.1894
Epoch 4/10, Batch 30/97, Loss: 0.5075
Epoch 4/10, Batch 40/97, Loss: 0.3390
Epoch 4/10, Batch 50/97, Loss: 0.1266
Epoch 4/10, Batch 60/97, Loss: 0.1596
Epoch 4/10, Batch 70/97, Loss: 0.2539
Epoch 4/10, Batch 80/97, Loss: 0.1328
Epoch 4/10, Batch 90/97, Loss: 0.1911
Epoch 4/10, Train Loss: 0.2856, Valid Loss: 0.2652
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2174
Epoch 5/10, Batch 20/97, Loss: 0.1420
Epoch 5/10, Batch 30/97, Loss: 0.1155
Epoch 5/10, Batch 40/97, Loss: 0.1480
Epoch 5/10, Batch 50/97, Loss: 0.2547
Epoch 5/10, Batch 60/97, Loss: 0.2319
Epoch 5/10, Batch 70/97, Loss: 0.2094
Epoch 5/10, Batch 80/97, Loss: 0.1951
Epoch 5/10, Batch 90/97, Loss: 0.2852
Epoch 5/10, Train Loss: 0.2556, Valid Loss: 0.2503
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1231
Epoch 6/10, Batch 20/97, Loss: 0.2098
Epoch 6/10, Batch 30/97, Loss: 0.3255
Epoch 6/10, Batch 40/97, Loss: 0.3159
Epoch 6/10, Batch 50/97, Loss: 0.1302
Epoch 6/10, Batch 60/97, Loss: 0.2594
Epoch 6/10, Batch 70/97, Loss: 0.2765
Epoch 6/10, Batch 80/97, Loss: 0.2652
Epoch 6/10, Batch 90/97, Loss: 0.2579
Epoch 6/10, Train Loss: 0.2391, Valid Loss: 0.2521
Epoch 7/10, Batch 10/97, Loss: 0.3680
Epoch 7/10, Batch 20/97, Loss: 0.1074
Epoch 7/10, Batch 30/97, Loss: 0.2266
Epoch 7/10, Batch 40/97, Loss: 0.1169
Epoch 7/10, Batch 50/97, Loss: 0.1797
Epoch 7/10, Batch 60/97, Loss: 0.3708
Epoch 7/10, Batch 70/97, Loss: 0.0971
Epoch 7/10, Batch 80/97, Loss: 0.2305
Epoch 7/10, Batch 90/97, Loss: 0.1818
Epoch 7/10, Train Loss: 0.2443, Valid Loss: 0.2490
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1197
Epoch 8/10, Batch 20/97, Loss: 0.2714
Epoch 8/10, Batch 30/97, Loss: 0.1379
Epoch 8/10, Batch 40/97, Loss: 0.1628
Epoch 8/10, Batch 50/97, Loss: 0.1862
Epoch 8/10, Batch 60/97, Loss: 0.1891
Epoch 8/10, Batch 70/97, Loss: 0.1946
Epoch 8/10, Batch 80/97, Loss: 0.1231
Epoch 8/10, Batch 90/97, Loss: 0.1370
Epoch 8/10, Train Loss: 0.2165, Valid Loss: 0.2345
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1361
Epoch 9/10, Batch 20/97, Loss: 0.1850
Epoch 9/10, Batch 30/97, Loss: 0.1940
Epoch 9/10, Batch 40/97, Loss: 0.2005
Epoch 9/10, Batch 50/97, Loss: 0.2259
Epoch 9/10, Batch 60/97, Loss: 0.1364
Epoch 9/10, Batch 70/97, Loss: 0.1597
Epoch 9/10, Batch 80/97, Loss: 0.1110
Epoch 9/10, Batch 90/97, Loss: 0.2355
Epoch 9/10, Train Loss: 0.2060, Valid Loss: 0.2304
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2334
Epoch 10/10, Batch 20/97, Loss: 0.1486
Epoch 10/10, Batch 30/97, Loss: 0.1593
Epoch 10/10, Batch 40/97, Loss: 0.2061
Epoch 10/10, Batch 50/97, Loss: 0.2517
Epoch 10/10, Batch 60/97, Loss: 0.1046
Epoch 10/10, Batch 70/97, Loss: 0.2085
Epoch 10/10, Batch 80/97, Loss: 0.1470
Epoch 10/10, Batch 90/97, Loss: 0.1590
Epoch 10/10, Train Loss: 0.1953, Valid Loss: 0.2255
Model saved!
Accuracy: 0.9159
Precision: 0.9138
Recall: 0.9159
F1-score: 0.9142
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5464
Epoch 1/10, Batch 20/97, Loss: 1.0273
Epoch 1/10, Batch 30/97, Loss: 0.8980
Epoch 1/10, Batch 40/97, Loss: 0.6677
Epoch 1/10, Batch 50/97, Loss: 0.6388
Epoch 1/10, Batch 60/97, Loss: 0.5764
Epoch 1/10, Batch 70/97, Loss: 0.4417
Epoch 1/10, Batch 80/97, Loss: 0.4193
Epoch 1/10, Batch 90/97, Loss: 0.5862
Epoch 1/10, Train Loss: 0.7681, Valid Loss: 0.4589
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3227
Epoch 2/10, Batch 20/97, Loss: 0.4827
Epoch 2/10, Batch 30/97, Loss: 0.4362
Epoch 2/10, Batch 40/97, Loss: 0.5580
Epoch 2/10, Batch 50/97, Loss: 0.5443
Epoch 2/10, Batch 60/97, Loss: 0.2990
Epoch 2/10, Batch 70/97, Loss: 0.2805
Epoch 2/10, Batch 80/97, Loss: 0.3019
Epoch 2/10, Batch 90/97, Loss: 0.5035
Epoch 2/10, Train Loss: 0.3926, Valid Loss: 0.3487
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2921
Epoch 3/10, Batch 20/97, Loss: 0.2073
Epoch 3/10, Batch 30/97, Loss: 0.3430
Epoch 3/10, Batch 40/97, Loss: 0.2130
Epoch 3/10, Batch 50/97, Loss: 0.1927
Epoch 3/10, Batch 60/97, Loss: 0.2188
Epoch 3/10, Batch 70/97, Loss: 0.2782
Epoch 3/10, Batch 80/97, Loss: 0.3942
Epoch 3/10, Batch 90/97, Loss: 0.2751
Epoch 3/10, Train Loss: 0.3135, Valid Loss: 0.3079
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2396
Epoch 4/10, Batch 20/97, Loss: 0.1398
Epoch 4/10, Batch 30/97, Loss: 0.3777
Epoch 4/10, Batch 40/97, Loss: 0.2457
Epoch 4/10, Batch 50/97, Loss: 0.2350
Epoch 4/10, Batch 60/97, Loss: 0.1824
Epoch 4/10, Batch 70/97, Loss: 0.2014
Epoch 4/10, Batch 80/97, Loss: 0.1223
Epoch 4/10, Batch 90/97, Loss: 0.3352
Epoch 4/10, Train Loss: 0.2794, Valid Loss: 0.2860
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3360
Epoch 5/10, Batch 20/97, Loss: 0.2920
Epoch 5/10, Batch 30/97, Loss: 0.2965
Epoch 5/10, Batch 40/97, Loss: 0.1538
Epoch 5/10, Batch 50/97, Loss: 0.2050
Epoch 5/10, Batch 60/97, Loss: 0.1694
Epoch 5/10, Batch 70/97, Loss: 0.1244
Epoch 5/10, Batch 80/97, Loss: 0.2481
Epoch 5/10, Batch 90/97, Loss: 0.4415
Epoch 5/10, Train Loss: 0.2537, Valid Loss: 0.2764
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2722
Epoch 6/10, Batch 20/97, Loss: 0.2357
Epoch 6/10, Batch 30/97, Loss: 0.1821
Epoch 6/10, Batch 40/97, Loss: 0.2370
Epoch 6/10, Batch 50/97, Loss: 0.2596
Epoch 6/10, Batch 60/97, Loss: 0.2276
Epoch 6/10, Batch 70/97, Loss: 0.2878
Epoch 6/10, Batch 80/97, Loss: 0.1744
Epoch 6/10, Batch 90/97, Loss: 0.1400
Epoch 6/10, Train Loss: 0.2322, Valid Loss: 0.2775
Epoch 7/10, Batch 10/97, Loss: 0.3680
Epoch 7/10, Batch 20/97, Loss: 0.1514
Epoch 7/10, Batch 30/97, Loss: 0.1134
Epoch 7/10, Batch 40/97, Loss: 0.1106
Epoch 7/10, Batch 50/97, Loss: 0.2592
Epoch 7/10, Batch 60/97, Loss: 0.3227
Epoch 7/10, Batch 70/97, Loss: 0.2862
Epoch 7/10, Batch 80/97, Loss: 0.2188
Epoch 7/10, Batch 90/97, Loss: 0.2550
Epoch 7/10, Train Loss: 0.2389, Valid Loss: 0.2508
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2373
Epoch 8/10, Batch 20/97, Loss: 0.2357
Epoch 8/10, Batch 30/97, Loss: 0.1749
Epoch 8/10, Batch 40/97, Loss: 0.2397
Epoch 8/10, Batch 50/97, Loss: 0.1697
Epoch 8/10, Batch 60/97, Loss: 0.1246
Epoch 8/10, Batch 70/97, Loss: 0.1935
Epoch 8/10, Batch 80/97, Loss: 0.1762
Epoch 8/10, Batch 90/97, Loss: 0.0943
Epoch 8/10, Train Loss: 0.2101, Valid Loss: 0.2491
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2246
Epoch 9/10, Batch 20/97, Loss: 0.1148
Epoch 9/10, Batch 30/97, Loss: 0.2011
Epoch 9/10, Batch 40/97, Loss: 0.1975
Epoch 9/10, Batch 50/97, Loss: 0.4573
Epoch 9/10, Batch 60/97, Loss: 0.1638
Epoch 9/10, Batch 70/97, Loss: 0.1381
Epoch 9/10, Batch 80/97, Loss: 0.1722
Epoch 9/10, Batch 90/97, Loss: 0.1182
Epoch 9/10, Train Loss: 0.2093, Valid Loss: 0.2505
Epoch 10/10, Batch 10/97, Loss: 0.1797
Epoch 10/10, Batch 20/97, Loss: 0.1727
Epoch 10/10, Batch 30/97, Loss: 0.2137
Epoch 10/10, Batch 40/97, Loss: 0.1559
Epoch 10/10, Batch 50/97, Loss: 0.3526
Epoch 10/10, Batch 60/97, Loss: 0.1536
Epoch 10/10, Batch 70/97, Loss: 0.1393
Epoch 10/10, Batch 80/97, Loss: 0.1303
Epoch 10/10, Batch 90/97, Loss: 0.1225
Epoch 10/10, Train Loss: 0.1963, Valid Loss: 0.2436
Model saved!
Accuracy: 0.9206
Precision: 0.9181
Recall: 0.9206
F1-score: 0.9189
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5044
Epoch 1/10, Batch 20/97, Loss: 1.0358
Epoch 1/10, Batch 30/97, Loss: 0.9185
Epoch 1/10, Batch 40/97, Loss: 0.6662
Epoch 1/10, Batch 50/97, Loss: 0.5488
Epoch 1/10, Batch 60/97, Loss: 0.5225
Epoch 1/10, Batch 70/97, Loss: 0.5517
Epoch 1/10, Batch 80/97, Loss: 0.4497
Epoch 1/10, Batch 90/97, Loss: 0.4508
Epoch 1/10, Train Loss: 0.7758, Valid Loss: 0.4460
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3879
Epoch 2/10, Batch 20/97, Loss: 0.3787
Epoch 2/10, Batch 30/97, Loss: 0.4474
Epoch 2/10, Batch 40/97, Loss: 0.4068
Epoch 2/10, Batch 50/97, Loss: 0.5929
Epoch 2/10, Batch 60/97, Loss: 0.2876
Epoch 2/10, Batch 70/97, Loss: 0.3324
Epoch 2/10, Batch 80/97, Loss: 0.3065
Epoch 2/10, Batch 90/97, Loss: 0.3353
Epoch 2/10, Train Loss: 0.4013, Valid Loss: 0.3423
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3225
Epoch 3/10, Batch 20/97, Loss: 0.3402
Epoch 3/10, Batch 30/97, Loss: 0.3108
Epoch 3/10, Batch 40/97, Loss: 0.2924
Epoch 3/10, Batch 50/97, Loss: 0.3325
Epoch 3/10, Batch 60/97, Loss: 0.2677
Epoch 3/10, Batch 70/97, Loss: 0.2314
Epoch 3/10, Batch 80/97, Loss: 0.3074
Epoch 3/10, Batch 90/97, Loss: 0.2647
Epoch 3/10, Train Loss: 0.3215, Valid Loss: 0.2926
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.4112
Epoch 4/10, Batch 20/97, Loss: 0.3160
Epoch 4/10, Batch 30/97, Loss: 0.5457
Epoch 4/10, Batch 40/97, Loss: 0.2255
Epoch 4/10, Batch 50/97, Loss: 0.1940
Epoch 4/10, Batch 60/97, Loss: 0.2400
Epoch 4/10, Batch 70/97, Loss: 0.2232
Epoch 4/10, Batch 80/97, Loss: 0.2819
Epoch 4/10, Batch 90/97, Loss: 0.4667
Epoch 4/10, Train Loss: 0.2870, Valid Loss: 0.2724
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2795
Epoch 5/10, Batch 20/97, Loss: 0.1999
Epoch 5/10, Batch 30/97, Loss: 0.1585
Epoch 5/10, Batch 40/97, Loss: 0.1325
Epoch 5/10, Batch 50/97, Loss: 0.2376
Epoch 5/10, Batch 60/97, Loss: 0.1642
Epoch 5/10, Batch 70/97, Loss: 0.1997
Epoch 5/10, Batch 80/97, Loss: 0.2631
Epoch 5/10, Batch 90/97, Loss: 0.2449
Epoch 5/10, Train Loss: 0.2620, Valid Loss: 0.2598
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2196
Epoch 6/10, Batch 20/97, Loss: 0.2462
Epoch 6/10, Batch 30/97, Loss: 0.2355
Epoch 6/10, Batch 40/97, Loss: 0.3701
Epoch 6/10, Batch 50/97, Loss: 0.1882
Epoch 6/10, Batch 60/97, Loss: 0.1765
Epoch 6/10, Batch 70/97, Loss: 0.3352
Epoch 6/10, Batch 80/97, Loss: 0.2985
Epoch 6/10, Batch 90/97, Loss: 0.2243
Epoch 6/10, Train Loss: 0.2459, Valid Loss: 0.2447
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2996
Epoch 7/10, Batch 20/97, Loss: 0.1128
Epoch 7/10, Batch 30/97, Loss: 0.1640
Epoch 7/10, Batch 40/97, Loss: 0.1922
Epoch 7/10, Batch 50/97, Loss: 0.2398
Epoch 7/10, Batch 60/97, Loss: 0.4020
Epoch 7/10, Batch 70/97, Loss: 0.2258
Epoch 7/10, Batch 80/97, Loss: 0.3037
Epoch 7/10, Batch 90/97, Loss: 0.1893
Epoch 7/10, Train Loss: 0.2414, Valid Loss: 0.2325
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1185
Epoch 8/10, Batch 20/97, Loss: 0.2514
Epoch 8/10, Batch 30/97, Loss: 0.2266
Epoch 8/10, Batch 40/97, Loss: 0.1938
Epoch 8/10, Batch 50/97, Loss: 0.1972
Epoch 8/10, Batch 60/97, Loss: 0.2573
Epoch 8/10, Batch 70/97, Loss: 0.2334
Epoch 8/10, Batch 80/97, Loss: 0.1856
Epoch 8/10, Batch 90/97, Loss: 0.1619
Epoch 8/10, Train Loss: 0.2117, Valid Loss: 0.2538
Epoch 9/10, Batch 10/97, Loss: 0.1628
Epoch 9/10, Batch 20/97, Loss: 0.0931
Epoch 9/10, Batch 30/97, Loss: 0.3237
Epoch 9/10, Batch 40/97, Loss: 0.1047
Epoch 9/10, Batch 50/97, Loss: 0.2896
Epoch 9/10, Batch 60/97, Loss: 0.1989
Epoch 9/10, Batch 70/97, Loss: 0.1347
Epoch 9/10, Batch 80/97, Loss: 0.2408
Epoch 9/10, Batch 90/97, Loss: 0.3842
Epoch 9/10, Train Loss: 0.2097, Valid Loss: 0.2295
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3409
Epoch 10/10, Batch 20/97, Loss: 0.1143
Epoch 10/10, Batch 30/97, Loss: 0.0976
Epoch 10/10, Batch 40/97, Loss: 0.1295
Epoch 10/10, Batch 50/97, Loss: 0.4079
Epoch 10/10, Batch 60/97, Loss: 0.1670
Epoch 10/10, Batch 70/97, Loss: 0.1678
Epoch 10/10, Batch 80/97, Loss: 0.2576
Epoch 10/10, Batch 90/97, Loss: 0.2182
Epoch 10/10, Train Loss: 0.1854, Valid Loss: 0.2209
Model saved!
Accuracy: 0.9252
Precision: 0.9236
Recall: 0.9252
F1-score: 0.9243
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4255
Epoch 1/10, Batch 20/97, Loss: 1.0365
Epoch 1/10, Batch 30/97, Loss: 0.9124
Epoch 1/10, Batch 40/97, Loss: 0.7105
Epoch 1/10, Batch 50/97, Loss: 0.6699
Epoch 1/10, Batch 60/97, Loss: 0.6271
Epoch 1/10, Batch 70/97, Loss: 0.4583
Epoch 1/10, Batch 80/97, Loss: 0.4919
Epoch 1/10, Batch 90/97, Loss: 0.4006
Epoch 1/10, Train Loss: 0.7674, Valid Loss: 0.4350
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3799
Epoch 2/10, Batch 20/97, Loss: 0.4181
Epoch 2/10, Batch 30/97, Loss: 0.5438
Epoch 2/10, Batch 40/97, Loss: 0.3864
Epoch 2/10, Batch 50/97, Loss: 0.6282
Epoch 2/10, Batch 60/97, Loss: 0.3305
Epoch 2/10, Batch 70/97, Loss: 0.2720
Epoch 2/10, Batch 80/97, Loss: 0.3259
Epoch 2/10, Batch 90/97, Loss: 0.3698
Epoch 2/10, Train Loss: 0.3873, Valid Loss: 0.3387
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3361
Epoch 3/10, Batch 20/97, Loss: 0.2816
Epoch 3/10, Batch 30/97, Loss: 0.3061
Epoch 3/10, Batch 40/97, Loss: 0.2728
Epoch 3/10, Batch 50/97, Loss: 0.3233
Epoch 3/10, Batch 60/97, Loss: 0.2340
Epoch 3/10, Batch 70/97, Loss: 0.2076
Epoch 3/10, Batch 80/97, Loss: 0.2294
Epoch 3/10, Batch 90/97, Loss: 0.3622
Epoch 3/10, Train Loss: 0.3152, Valid Loss: 0.3007
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2286
Epoch 4/10, Batch 20/97, Loss: 0.1878
Epoch 4/10, Batch 30/97, Loss: 0.3890
Epoch 4/10, Batch 40/97, Loss: 0.4369
Epoch 4/10, Batch 50/97, Loss: 0.2475
Epoch 4/10, Batch 60/97, Loss: 0.2161
Epoch 4/10, Batch 70/97, Loss: 0.3060
Epoch 4/10, Batch 80/97, Loss: 0.2943
Epoch 4/10, Batch 90/97, Loss: 0.1960
Epoch 4/10, Train Loss: 0.2802, Valid Loss: 0.2729
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2104
Epoch 5/10, Batch 20/97, Loss: 0.3366
Epoch 5/10, Batch 30/97, Loss: 0.1714
Epoch 5/10, Batch 40/97, Loss: 0.1064
Epoch 5/10, Batch 50/97, Loss: 0.1657
Epoch 5/10, Batch 60/97, Loss: 0.2664
Epoch 5/10, Batch 70/97, Loss: 0.2470
Epoch 5/10, Batch 80/97, Loss: 0.5357
Epoch 5/10, Batch 90/97, Loss: 0.2979
Epoch 5/10, Train Loss: 0.2512, Valid Loss: 0.2656
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1596
Epoch 6/10, Batch 20/97, Loss: 0.1664
Epoch 6/10, Batch 30/97, Loss: 0.1413
Epoch 6/10, Batch 40/97, Loss: 0.2821
Epoch 6/10, Batch 50/97, Loss: 0.1541
Epoch 6/10, Batch 60/97, Loss: 0.2100
Epoch 6/10, Batch 70/97, Loss: 0.2840
Epoch 6/10, Batch 80/97, Loss: 0.0945
Epoch 6/10, Batch 90/97, Loss: 0.2076
Epoch 6/10, Train Loss: 0.2292, Valid Loss: 0.2538
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4358
Epoch 7/10, Batch 20/97, Loss: 0.1092
Epoch 7/10, Batch 30/97, Loss: 0.1095
Epoch 7/10, Batch 40/97, Loss: 0.2569
Epoch 7/10, Batch 50/97, Loss: 0.4178
Epoch 7/10, Batch 60/97, Loss: 0.3471
Epoch 7/10, Batch 70/97, Loss: 0.2216
Epoch 7/10, Batch 80/97, Loss: 0.2235
Epoch 7/10, Batch 90/97, Loss: 0.2594
Epoch 7/10, Train Loss: 0.2389, Valid Loss: 0.2484
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1772
Epoch 8/10, Batch 20/97, Loss: 0.2639
Epoch 8/10, Batch 30/97, Loss: 0.1101
Epoch 8/10, Batch 40/97, Loss: 0.1335
Epoch 8/10, Batch 50/97, Loss: 0.1592
Epoch 8/10, Batch 60/97, Loss: 0.1850
Epoch 8/10, Batch 70/97, Loss: 0.2022
Epoch 8/10, Batch 80/97, Loss: 0.1706
Epoch 8/10, Batch 90/97, Loss: 0.1001
Epoch 8/10, Train Loss: 0.2081, Valid Loss: 0.2456
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2356
Epoch 9/10, Batch 20/97, Loss: 0.1411
Epoch 9/10, Batch 30/97, Loss: 0.1512
Epoch 9/10, Batch 40/97, Loss: 0.1105
Epoch 9/10, Batch 50/97, Loss: 0.2573
Epoch 9/10, Batch 60/97, Loss: 0.1843
Epoch 9/10, Batch 70/97, Loss: 0.1753
Epoch 9/10, Batch 80/97, Loss: 0.1593
Epoch 9/10, Batch 90/97, Loss: 0.1145
Epoch 9/10, Train Loss: 0.1893, Valid Loss: 0.2443
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2294
Epoch 10/10, Batch 20/97, Loss: 0.0880
Epoch 10/10, Batch 30/97, Loss: 0.2628
Epoch 10/10, Batch 40/97, Loss: 0.1499
Epoch 10/10, Batch 50/97, Loss: 0.1941
Epoch 10/10, Batch 60/97, Loss: 0.1802
Epoch 10/10, Batch 70/97, Loss: 0.2264
Epoch 10/10, Batch 80/97, Loss: 0.1187
Epoch 10/10, Batch 90/97, Loss: 0.0932
Epoch 10/10, Train Loss: 0.1871, Valid Loss: 0.2358
Model saved!
Accuracy: 0.9182
Precision: 0.9160
Recall: 0.9182
F1-score: 0.9166
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4794
Epoch 1/10, Batch 20/97, Loss: 0.9783
Epoch 1/10, Batch 30/97, Loss: 0.7971
Epoch 1/10, Batch 40/97, Loss: 0.7332
Epoch 1/10, Batch 50/97, Loss: 0.5066
Epoch 1/10, Batch 60/97, Loss: 0.5775
Epoch 1/10, Batch 70/97, Loss: 0.4985
Epoch 1/10, Batch 80/97, Loss: 0.4812
Epoch 1/10, Batch 90/97, Loss: 0.4831
Epoch 1/10, Train Loss: 0.7692, Valid Loss: 0.4501
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4389
Epoch 2/10, Batch 20/97, Loss: 0.4191
Epoch 2/10, Batch 30/97, Loss: 0.3692
Epoch 2/10, Batch 40/97, Loss: 0.4166
Epoch 2/10, Batch 50/97, Loss: 0.5555
Epoch 2/10, Batch 60/97, Loss: 0.4231
Epoch 2/10, Batch 70/97, Loss: 0.2097
Epoch 2/10, Batch 80/97, Loss: 0.2924
Epoch 2/10, Batch 90/97, Loss: 0.3354
Epoch 2/10, Train Loss: 0.3950, Valid Loss: 0.3331
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4442
Epoch 3/10, Batch 20/97, Loss: 0.2475
Epoch 3/10, Batch 30/97, Loss: 0.2320
Epoch 3/10, Batch 40/97, Loss: 0.2565
Epoch 3/10, Batch 50/97, Loss: 0.2960
Epoch 3/10, Batch 60/97, Loss: 0.2523
Epoch 3/10, Batch 70/97, Loss: 0.1844
Epoch 3/10, Batch 80/97, Loss: 0.2088
Epoch 3/10, Batch 90/97, Loss: 0.3201
Epoch 3/10, Train Loss: 0.3225, Valid Loss: 0.2953
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2732
Epoch 4/10, Batch 20/97, Loss: 0.3024
Epoch 4/10, Batch 30/97, Loss: 0.2938
Epoch 4/10, Batch 40/97, Loss: 0.3058
Epoch 4/10, Batch 50/97, Loss: 0.1659
Epoch 4/10, Batch 60/97, Loss: 0.2404
Epoch 4/10, Batch 70/97, Loss: 0.1804
Epoch 4/10, Batch 80/97, Loss: 0.3135
Epoch 4/10, Batch 90/97, Loss: 0.2695
Epoch 4/10, Train Loss: 0.2909, Valid Loss: 0.2683
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2011
Epoch 5/10, Batch 20/97, Loss: 0.1891
Epoch 5/10, Batch 30/97, Loss: 0.2500
Epoch 5/10, Batch 40/97, Loss: 0.1955
Epoch 5/10, Batch 50/97, Loss: 0.3393
Epoch 5/10, Batch 60/97, Loss: 0.2601
Epoch 5/10, Batch 70/97, Loss: 0.2207
Epoch 5/10, Batch 80/97, Loss: 0.2690
Epoch 5/10, Batch 90/97, Loss: 0.3680
Epoch 5/10, Train Loss: 0.2558, Valid Loss: 0.2614
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1881
Epoch 6/10, Batch 20/97, Loss: 0.2749
Epoch 6/10, Batch 30/97, Loss: 0.1633
Epoch 6/10, Batch 40/97, Loss: 0.2710
Epoch 6/10, Batch 50/97, Loss: 0.2366
Epoch 6/10, Batch 60/97, Loss: 0.2219
Epoch 6/10, Batch 70/97, Loss: 0.1890
Epoch 6/10, Batch 80/97, Loss: 0.1567
Epoch 6/10, Batch 90/97, Loss: 0.2160
Epoch 6/10, Train Loss: 0.2361, Valid Loss: 0.2441
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2492
Epoch 7/10, Batch 20/97, Loss: 0.2491
Epoch 7/10, Batch 30/97, Loss: 0.1484
Epoch 7/10, Batch 40/97, Loss: 0.2472
Epoch 7/10, Batch 50/97, Loss: 0.1918
Epoch 7/10, Batch 60/97, Loss: 0.2262
Epoch 7/10, Batch 70/97, Loss: 0.2908
Epoch 7/10, Batch 80/97, Loss: 0.2517
Epoch 7/10, Batch 90/97, Loss: 0.3386
Epoch 7/10, Train Loss: 0.2358, Valid Loss: 0.2383
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1548
Epoch 8/10, Batch 20/97, Loss: 0.1279
Epoch 8/10, Batch 30/97, Loss: 0.1869
Epoch 8/10, Batch 40/97, Loss: 0.1483
Epoch 8/10, Batch 50/97, Loss: 0.3188
Epoch 8/10, Batch 60/97, Loss: 0.1639
Epoch 8/10, Batch 70/97, Loss: 0.2159
Epoch 8/10, Batch 80/97, Loss: 0.1983
Epoch 8/10, Batch 90/97, Loss: 0.2314
Epoch 8/10, Train Loss: 0.2126, Valid Loss: 0.2328
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1814
Epoch 9/10, Batch 20/97, Loss: 0.1076
Epoch 9/10, Batch 30/97, Loss: 0.3622
Epoch 9/10, Batch 40/97, Loss: 0.1085
Epoch 9/10, Batch 50/97, Loss: 0.1712
Epoch 9/10, Batch 60/97, Loss: 0.1687
Epoch 9/10, Batch 70/97, Loss: 0.2785
Epoch 9/10, Batch 80/97, Loss: 0.2932
Epoch 9/10, Batch 90/97, Loss: 0.2180
Epoch 9/10, Train Loss: 0.2035, Valid Loss: 0.2277
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3281
Epoch 10/10, Batch 20/97, Loss: 0.0838
Epoch 10/10, Batch 30/97, Loss: 0.1530
Epoch 10/10, Batch 40/97, Loss: 0.2673
Epoch 10/10, Batch 50/97, Loss: 0.2090
Epoch 10/10, Batch 60/97, Loss: 0.1983
Epoch 10/10, Batch 70/97, Loss: 0.2749
Epoch 10/10, Batch 80/97, Loss: 0.1528
Epoch 10/10, Batch 90/97, Loss: 0.1266
Epoch 10/10, Train Loss: 0.1911, Valid Loss: 0.2323
Accuracy: 0.9194
Precision: 0.9173
Recall: 0.9194
F1-score: 0.9181
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4603
Epoch 1/10, Batch 20/97, Loss: 0.9523
Epoch 1/10, Batch 30/97, Loss: 0.8817
Epoch 1/10, Batch 40/97, Loss: 0.7704
Epoch 1/10, Batch 50/97, Loss: 0.6554
Epoch 1/10, Batch 60/97, Loss: 0.5521
Epoch 1/10, Batch 70/97, Loss: 0.5018
Epoch 1/10, Batch 80/97, Loss: 0.4937
Epoch 1/10, Batch 90/97, Loss: 0.5093
Epoch 1/10, Train Loss: 0.7803, Valid Loss: 0.4395
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3829
Epoch 2/10, Batch 20/97, Loss: 0.5005
Epoch 2/10, Batch 30/97, Loss: 0.4339
Epoch 2/10, Batch 40/97, Loss: 0.3905
Epoch 2/10, Batch 50/97, Loss: 0.4126
Epoch 2/10, Batch 60/97, Loss: 0.3443
Epoch 2/10, Batch 70/97, Loss: 0.2771
Epoch 2/10, Batch 80/97, Loss: 0.3551
Epoch 2/10, Batch 90/97, Loss: 0.4535
Epoch 2/10, Train Loss: 0.3945, Valid Loss: 0.3383
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3877
Epoch 3/10, Batch 20/97, Loss: 0.3707
Epoch 3/10, Batch 30/97, Loss: 0.4116
Epoch 3/10, Batch 40/97, Loss: 0.2243
Epoch 3/10, Batch 50/97, Loss: 0.1797
Epoch 3/10, Batch 60/97, Loss: 0.2256
Epoch 3/10, Batch 70/97, Loss: 0.2193
Epoch 3/10, Batch 80/97, Loss: 0.2265
Epoch 3/10, Batch 90/97, Loss: 0.1921
Epoch 3/10, Train Loss: 0.3268, Valid Loss: 0.2918
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3403
Epoch 4/10, Batch 20/97, Loss: 0.2358
Epoch 4/10, Batch 30/97, Loss: 0.3076
Epoch 4/10, Batch 40/97, Loss: 0.4113
Epoch 4/10, Batch 50/97, Loss: 0.2047
Epoch 4/10, Batch 60/97, Loss: 0.1816
Epoch 4/10, Batch 70/97, Loss: 0.1471
Epoch 4/10, Batch 80/97, Loss: 0.1912
Epoch 4/10, Batch 90/97, Loss: 0.2131
Epoch 4/10, Train Loss: 0.2856, Valid Loss: 0.2633
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2653
Epoch 5/10, Batch 20/97, Loss: 0.2309
Epoch 5/10, Batch 30/97, Loss: 0.1561
Epoch 5/10, Batch 40/97, Loss: 0.1667
Epoch 5/10, Batch 50/97, Loss: 0.1980
Epoch 5/10, Batch 60/97, Loss: 0.3471
Epoch 5/10, Batch 70/97, Loss: 0.3016
Epoch 5/10, Batch 80/97, Loss: 0.3096
Epoch 5/10, Batch 90/97, Loss: 0.3828
Epoch 5/10, Train Loss: 0.2624, Valid Loss: 0.2502
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1446
Epoch 6/10, Batch 20/97, Loss: 0.2016
Epoch 6/10, Batch 30/97, Loss: 0.1521
Epoch 6/10, Batch 40/97, Loss: 0.2797
Epoch 6/10, Batch 50/97, Loss: 0.1689
Epoch 6/10, Batch 60/97, Loss: 0.1899
Epoch 6/10, Batch 70/97, Loss: 0.2144
Epoch 6/10, Batch 80/97, Loss: 0.2085
Epoch 6/10, Batch 90/97, Loss: 0.1995
Epoch 6/10, Train Loss: 0.2397, Valid Loss: 0.2439
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2323
Epoch 7/10, Batch 20/97, Loss: 0.1235
Epoch 7/10, Batch 30/97, Loss: 0.1398
Epoch 7/10, Batch 40/97, Loss: 0.2814
Epoch 7/10, Batch 50/97, Loss: 0.1956
Epoch 7/10, Batch 60/97, Loss: 0.3790
Epoch 7/10, Batch 70/97, Loss: 0.2451
Epoch 7/10, Batch 80/97, Loss: 0.2858
Epoch 7/10, Batch 90/97, Loss: 0.3703
Epoch 7/10, Train Loss: 0.2477, Valid Loss: 0.2307
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1969
Epoch 8/10, Batch 20/97, Loss: 0.1360
Epoch 8/10, Batch 30/97, Loss: 0.2177
Epoch 8/10, Batch 40/97, Loss: 0.0984
Epoch 8/10, Batch 50/97, Loss: 0.2644
Epoch 8/10, Batch 60/97, Loss: 0.1555
Epoch 8/10, Batch 70/97, Loss: 0.3090
Epoch 8/10, Batch 80/97, Loss: 0.2814
Epoch 8/10, Batch 90/97, Loss: 0.2892
Epoch 8/10, Train Loss: 0.2260, Valid Loss: 0.2323
Epoch 9/10, Batch 10/97, Loss: 0.0826
Epoch 9/10, Batch 20/97, Loss: 0.0774
Epoch 9/10, Batch 30/97, Loss: 0.2154
Epoch 9/10, Batch 40/97, Loss: 0.1202
Epoch 9/10, Batch 50/97, Loss: 0.2816
Epoch 9/10, Batch 60/97, Loss: 0.1817
Epoch 9/10, Batch 70/97, Loss: 0.1844
Epoch 9/10, Batch 80/97, Loss: 0.2709
Epoch 9/10, Batch 90/97, Loss: 0.1335
Epoch 9/10, Train Loss: 0.2171, Valid Loss: 0.2302
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2029
Epoch 10/10, Batch 20/97, Loss: 0.1296
Epoch 10/10, Batch 30/97, Loss: 0.1479
Epoch 10/10, Batch 40/97, Loss: 0.1759
Epoch 10/10, Batch 50/97, Loss: 0.3236
Epoch 10/10, Batch 60/97, Loss: 0.2790
Epoch 10/10, Batch 70/97, Loss: 0.1845
Epoch 10/10, Batch 80/97, Loss: 0.3152
Epoch 10/10, Batch 90/97, Loss: 0.1455
Epoch 10/10, Train Loss: 0.2027, Valid Loss: 0.2234
Model saved!
Accuracy: 0.9206
Precision: 0.9184
Recall: 0.9206
F1-score: 0.9189
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4773
Epoch 1/10, Batch 20/97, Loss: 0.9745
Epoch 1/10, Batch 30/97, Loss: 0.8898
Epoch 1/10, Batch 40/97, Loss: 0.7250
Epoch 1/10, Batch 50/97, Loss: 0.6183
Epoch 1/10, Batch 60/97, Loss: 0.5072
Epoch 1/10, Batch 70/97, Loss: 0.5359
Epoch 1/10, Batch 80/97, Loss: 0.4523
Epoch 1/10, Batch 90/97, Loss: 0.4539
Epoch 1/10, Train Loss: 0.7771, Valid Loss: 0.4402
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4778
Epoch 2/10, Batch 20/97, Loss: 0.5078
Epoch 2/10, Batch 30/97, Loss: 0.3416
Epoch 2/10, Batch 40/97, Loss: 0.3888
Epoch 2/10, Batch 50/97, Loss: 0.5131
Epoch 2/10, Batch 60/97, Loss: 0.3550
Epoch 2/10, Batch 70/97, Loss: 0.2538
Epoch 2/10, Batch 80/97, Loss: 0.4484
Epoch 2/10, Batch 90/97, Loss: 0.3645
Epoch 2/10, Train Loss: 0.3973, Valid Loss: 0.3361
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3497
Epoch 3/10, Batch 20/97, Loss: 0.3028
Epoch 3/10, Batch 30/97, Loss: 0.1828
Epoch 3/10, Batch 40/97, Loss: 0.3574
Epoch 3/10, Batch 50/97, Loss: 0.3424
Epoch 3/10, Batch 60/97, Loss: 0.3169
Epoch 3/10, Batch 70/97, Loss: 0.2193
Epoch 3/10, Batch 80/97, Loss: 0.3375
Epoch 3/10, Batch 90/97, Loss: 0.3046
Epoch 3/10, Train Loss: 0.3225, Valid Loss: 0.2989
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2623
Epoch 4/10, Batch 20/97, Loss: 0.2156
Epoch 4/10, Batch 30/97, Loss: 0.3292
Epoch 4/10, Batch 40/97, Loss: 0.2727
Epoch 4/10, Batch 50/97, Loss: 0.1661
Epoch 4/10, Batch 60/97, Loss: 0.1073
Epoch 4/10, Batch 70/97, Loss: 0.2310
Epoch 4/10, Batch 80/97, Loss: 0.2618
Epoch 4/10, Batch 90/97, Loss: 0.2237
Epoch 4/10, Train Loss: 0.2867, Valid Loss: 0.2821
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2471
Epoch 5/10, Batch 20/97, Loss: 0.1887
Epoch 5/10, Batch 30/97, Loss: 0.1205
Epoch 5/10, Batch 40/97, Loss: 0.1580
Epoch 5/10, Batch 50/97, Loss: 0.2093
Epoch 5/10, Batch 60/97, Loss: 0.2272
Epoch 5/10, Batch 70/97, Loss: 0.2831
Epoch 5/10, Batch 80/97, Loss: 0.3189
Epoch 5/10, Batch 90/97, Loss: 0.1956
Epoch 5/10, Train Loss: 0.2577, Valid Loss: 0.2741
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2086
Epoch 6/10, Batch 20/97, Loss: 0.1604
Epoch 6/10, Batch 30/97, Loss: 0.1447
Epoch 6/10, Batch 40/97, Loss: 0.4287
Epoch 6/10, Batch 50/97, Loss: 0.2161
Epoch 6/10, Batch 60/97, Loss: 0.2593
Epoch 6/10, Batch 70/97, Loss: 0.2154
Epoch 6/10, Batch 80/97, Loss: 0.1432
Epoch 6/10, Batch 90/97, Loss: 0.1726
Epoch 6/10, Train Loss: 0.2375, Valid Loss: 0.2702
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3435
Epoch 7/10, Batch 20/97, Loss: 0.2133
Epoch 7/10, Batch 30/97, Loss: 0.1067
Epoch 7/10, Batch 40/97, Loss: 0.1411
Epoch 7/10, Batch 50/97, Loss: 0.2946
Epoch 7/10, Batch 60/97, Loss: 0.2299
Epoch 7/10, Batch 70/97, Loss: 0.2760
Epoch 7/10, Batch 80/97, Loss: 0.2217
Epoch 7/10, Batch 90/97, Loss: 0.2900
Epoch 7/10, Train Loss: 0.2428, Valid Loss: 0.2675
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2623
Epoch 8/10, Batch 20/97, Loss: 0.1616
Epoch 8/10, Batch 30/97, Loss: 0.1917
Epoch 8/10, Batch 40/97, Loss: 0.1794
Epoch 8/10, Batch 50/97, Loss: 0.1904
Epoch 8/10, Batch 60/97, Loss: 0.2573
Epoch 8/10, Batch 70/97, Loss: 0.1884
Epoch 8/10, Batch 80/97, Loss: 0.1591
Epoch 8/10, Batch 90/97, Loss: 0.1138
Epoch 8/10, Train Loss: 0.2145, Valid Loss: 0.2590
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0844
Epoch 9/10, Batch 20/97, Loss: 0.0720
Epoch 9/10, Batch 30/97, Loss: 0.1894
Epoch 9/10, Batch 40/97, Loss: 0.2066
Epoch 9/10, Batch 50/97, Loss: 0.1616
Epoch 9/10, Batch 60/97, Loss: 0.2158
Epoch 9/10, Batch 70/97, Loss: 0.2372
Epoch 9/10, Batch 80/97, Loss: 0.1152
Epoch 9/10, Batch 90/97, Loss: 0.1768
Epoch 9/10, Train Loss: 0.2024, Valid Loss: 0.2724
Epoch 10/10, Batch 10/97, Loss: 0.2137
Epoch 10/10, Batch 20/97, Loss: 0.2381
Epoch 10/10, Batch 30/97, Loss: 0.2573
Epoch 10/10, Batch 40/97, Loss: 0.1221
Epoch 10/10, Batch 50/97, Loss: 0.3006
Epoch 10/10, Batch 60/97, Loss: 0.2260
Epoch 10/10, Batch 70/97, Loss: 0.1636
Epoch 10/10, Batch 80/97, Loss: 0.3058
Epoch 10/10, Batch 90/97, Loss: 0.1974
Epoch 10/10, Train Loss: 0.2025, Valid Loss: 0.2622
Accuracy: 0.9217
Precision: 0.9199
Recall: 0.9217
F1-score: 0.9200
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4635
Epoch 1/10, Batch 20/97, Loss: 0.9937
Epoch 1/10, Batch 30/97, Loss: 0.8805
Epoch 1/10, Batch 40/97, Loss: 0.6562
Epoch 1/10, Batch 50/97, Loss: 0.5828
Epoch 1/10, Batch 60/97, Loss: 0.5487
Epoch 1/10, Batch 70/97, Loss: 0.5762
Epoch 1/10, Batch 80/97, Loss: 0.5461
Epoch 1/10, Batch 90/97, Loss: 0.5320
Epoch 1/10, Train Loss: 0.7722, Valid Loss: 0.4358
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4128
Epoch 2/10, Batch 20/97, Loss: 0.5871
Epoch 2/10, Batch 30/97, Loss: 0.4093
Epoch 2/10, Batch 40/97, Loss: 0.3033
Epoch 2/10, Batch 50/97, Loss: 0.5586
Epoch 2/10, Batch 60/97, Loss: 0.3609
Epoch 2/10, Batch 70/97, Loss: 0.3704
Epoch 2/10, Batch 80/97, Loss: 0.3931
Epoch 2/10, Batch 90/97, Loss: 0.2689
Epoch 2/10, Train Loss: 0.3950, Valid Loss: 0.3428
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2443
Epoch 3/10, Batch 20/97, Loss: 0.3853
Epoch 3/10, Batch 30/97, Loss: 0.2004
Epoch 3/10, Batch 40/97, Loss: 0.2408
Epoch 3/10, Batch 50/97, Loss: 0.2514
Epoch 3/10, Batch 60/97, Loss: 0.4050
Epoch 3/10, Batch 70/97, Loss: 0.2146
Epoch 3/10, Batch 80/97, Loss: 0.1909
Epoch 3/10, Batch 90/97, Loss: 0.3899
Epoch 3/10, Train Loss: 0.3127, Valid Loss: 0.2990
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3242
Epoch 4/10, Batch 20/97, Loss: 0.2152
Epoch 4/10, Batch 30/97, Loss: 0.4566
Epoch 4/10, Batch 40/97, Loss: 0.3448
Epoch 4/10, Batch 50/97, Loss: 0.2928
Epoch 4/10, Batch 60/97, Loss: 0.2211
Epoch 4/10, Batch 70/97, Loss: 0.2075
Epoch 4/10, Batch 80/97, Loss: 0.1050
Epoch 4/10, Batch 90/97, Loss: 0.2359
Epoch 4/10, Train Loss: 0.2820, Valid Loss: 0.2858
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1722
Epoch 5/10, Batch 20/97, Loss: 0.1039
Epoch 5/10, Batch 30/97, Loss: 0.1292
Epoch 5/10, Batch 40/97, Loss: 0.1402
Epoch 5/10, Batch 50/97, Loss: 0.1445
Epoch 5/10, Batch 60/97, Loss: 0.3004
Epoch 5/10, Batch 70/97, Loss: 0.3095
Epoch 5/10, Batch 80/97, Loss: 0.3540
Epoch 5/10, Batch 90/97, Loss: 0.2963
Epoch 5/10, Train Loss: 0.2484, Valid Loss: 0.2606
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3235
Epoch 6/10, Batch 20/97, Loss: 0.1598
Epoch 6/10, Batch 30/97, Loss: 0.1381
Epoch 6/10, Batch 40/97, Loss: 0.2218
Epoch 6/10, Batch 50/97, Loss: 0.1456
Epoch 6/10, Batch 60/97, Loss: 0.2574
Epoch 6/10, Batch 70/97, Loss: 0.1312
Epoch 6/10, Batch 80/97, Loss: 0.1184
Epoch 6/10, Batch 90/97, Loss: 0.2469
Epoch 6/10, Train Loss: 0.2350, Valid Loss: 0.2601
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3367
Epoch 7/10, Batch 20/97, Loss: 0.1212
Epoch 7/10, Batch 30/97, Loss: 0.2214
Epoch 7/10, Batch 40/97, Loss: 0.1630
Epoch 7/10, Batch 50/97, Loss: 0.1850
Epoch 7/10, Batch 60/97, Loss: 0.3535
Epoch 7/10, Batch 70/97, Loss: 0.2760
Epoch 7/10, Batch 80/97, Loss: 0.1917
Epoch 7/10, Batch 90/97, Loss: 0.2592
Epoch 7/10, Train Loss: 0.2404, Valid Loss: 0.2496
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1575
Epoch 8/10, Batch 20/97, Loss: 0.1559
Epoch 8/10, Batch 30/97, Loss: 0.2382
Epoch 8/10, Batch 40/97, Loss: 0.1552
Epoch 8/10, Batch 50/97, Loss: 0.2134
Epoch 8/10, Batch 60/97, Loss: 0.1419
Epoch 8/10, Batch 70/97, Loss: 0.2944
Epoch 8/10, Batch 80/97, Loss: 0.1414
Epoch 8/10, Batch 90/97, Loss: 0.1709
Epoch 8/10, Train Loss: 0.2090, Valid Loss: 0.2535
Epoch 9/10, Batch 10/97, Loss: 0.0984
Epoch 9/10, Batch 20/97, Loss: 0.2647
Epoch 9/10, Batch 30/97, Loss: 0.2529
Epoch 9/10, Batch 40/97, Loss: 0.1447
Epoch 9/10, Batch 50/97, Loss: 0.3033
Epoch 9/10, Batch 60/97, Loss: 0.1897
Epoch 9/10, Batch 70/97, Loss: 0.1932
Epoch 9/10, Batch 80/97, Loss: 0.1817
Epoch 9/10, Batch 90/97, Loss: 0.2426
Epoch 9/10, Train Loss: 0.1970, Valid Loss: 0.2344
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.4107
Epoch 10/10, Batch 20/97, Loss: 0.1675
Epoch 10/10, Batch 30/97, Loss: 0.1413
Epoch 10/10, Batch 40/97, Loss: 0.2296
Epoch 10/10, Batch 50/97, Loss: 0.2080
Epoch 10/10, Batch 60/97, Loss: 0.1476
Epoch 10/10, Batch 70/97, Loss: 0.1210
Epoch 10/10, Batch 80/97, Loss: 0.2378
Epoch 10/10, Batch 90/97, Loss: 0.1929
Epoch 10/10, Train Loss: 0.1979, Valid Loss: 0.2376
Accuracy: 0.9206
Precision: 0.9189
Recall: 0.9206
F1-score: 0.9194
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4757
Epoch 1/10, Batch 20/97, Loss: 1.0222
Epoch 1/10, Batch 30/97, Loss: 0.8520
Epoch 1/10, Batch 40/97, Loss: 0.7187
Epoch 1/10, Batch 50/97, Loss: 0.7361
Epoch 1/10, Batch 60/97, Loss: 0.6065
Epoch 1/10, Batch 70/97, Loss: 0.4491
Epoch 1/10, Batch 80/97, Loss: 0.4973
Epoch 1/10, Batch 90/97, Loss: 0.7675
Epoch 1/10, Train Loss: 0.7785, Valid Loss: 0.4433
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3528
Epoch 2/10, Batch 20/97, Loss: 0.5309
Epoch 2/10, Batch 30/97, Loss: 0.4209
Epoch 2/10, Batch 40/97, Loss: 0.5030
Epoch 2/10, Batch 50/97, Loss: 0.5022
Epoch 2/10, Batch 60/97, Loss: 0.4615
Epoch 2/10, Batch 70/97, Loss: 0.4639
Epoch 2/10, Batch 80/97, Loss: 0.3053
Epoch 2/10, Batch 90/97, Loss: 0.4438
Epoch 2/10, Train Loss: 0.3976, Valid Loss: 0.3365
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3090
Epoch 3/10, Batch 20/97, Loss: 0.2769
Epoch 3/10, Batch 30/97, Loss: 0.2180
Epoch 3/10, Batch 40/97, Loss: 0.2431
Epoch 3/10, Batch 50/97, Loss: 0.2788
Epoch 3/10, Batch 60/97, Loss: 0.2249
Epoch 3/10, Batch 70/97, Loss: 0.1655
Epoch 3/10, Batch 80/97, Loss: 0.3553
Epoch 3/10, Batch 90/97, Loss: 0.1867
Epoch 3/10, Train Loss: 0.3272, Valid Loss: 0.2926
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2107
Epoch 4/10, Batch 20/97, Loss: 0.1618
Epoch 4/10, Batch 30/97, Loss: 0.1842
Epoch 4/10, Batch 40/97, Loss: 0.3310
Epoch 4/10, Batch 50/97, Loss: 0.1597
Epoch 4/10, Batch 60/97, Loss: 0.1526
Epoch 4/10, Batch 70/97, Loss: 0.2025
Epoch 4/10, Batch 80/97, Loss: 0.2351
Epoch 4/10, Batch 90/97, Loss: 0.2395
Epoch 4/10, Train Loss: 0.2965, Valid Loss: 0.2725
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2042
Epoch 5/10, Batch 20/97, Loss: 0.2163
Epoch 5/10, Batch 30/97, Loss: 0.2358
Epoch 5/10, Batch 40/97, Loss: 0.0784
Epoch 5/10, Batch 50/97, Loss: 0.2532
Epoch 5/10, Batch 60/97, Loss: 0.2146
Epoch 5/10, Batch 70/97, Loss: 0.2654
Epoch 5/10, Batch 80/97, Loss: 0.6407
Epoch 5/10, Batch 90/97, Loss: 0.2828
Epoch 5/10, Train Loss: 0.2552, Valid Loss: 0.2526
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2035
Epoch 6/10, Batch 20/97, Loss: 0.1894
Epoch 6/10, Batch 30/97, Loss: 0.2385
Epoch 6/10, Batch 40/97, Loss: 0.3350
Epoch 6/10, Batch 50/97, Loss: 0.1942
Epoch 6/10, Batch 60/97, Loss: 0.1856
Epoch 6/10, Batch 70/97, Loss: 0.3308
Epoch 6/10, Batch 80/97, Loss: 0.0790
Epoch 6/10, Batch 90/97, Loss: 0.2589
Epoch 6/10, Train Loss: 0.2394, Valid Loss: 0.2496
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3881
Epoch 7/10, Batch 20/97, Loss: 0.1928
Epoch 7/10, Batch 30/97, Loss: 0.1250
Epoch 7/10, Batch 40/97, Loss: 0.2867
Epoch 7/10, Batch 50/97, Loss: 0.1425
Epoch 7/10, Batch 60/97, Loss: 0.2445
Epoch 7/10, Batch 70/97, Loss: 0.2173
Epoch 7/10, Batch 80/97, Loss: 0.1364
Epoch 7/10, Batch 90/97, Loss: 0.2025
Epoch 7/10, Train Loss: 0.2430, Valid Loss: 0.2401
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2991
Epoch 8/10, Batch 20/97, Loss: 0.1470
Epoch 8/10, Batch 30/97, Loss: 0.0926
Epoch 8/10, Batch 40/97, Loss: 0.2152
Epoch 8/10, Batch 50/97, Loss: 0.1951
Epoch 8/10, Batch 60/97, Loss: 0.1364
Epoch 8/10, Batch 70/97, Loss: 0.3140
Epoch 8/10, Batch 80/97, Loss: 0.1540
Epoch 8/10, Batch 90/97, Loss: 0.2740
Epoch 8/10, Train Loss: 0.2181, Valid Loss: 0.2323
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.3441
Epoch 9/10, Batch 20/97, Loss: 0.1178
Epoch 9/10, Batch 30/97, Loss: 0.2924
Epoch 9/10, Batch 40/97, Loss: 0.1416
Epoch 9/10, Batch 50/97, Loss: 0.1792
Epoch 9/10, Batch 60/97, Loss: 0.2785
Epoch 9/10, Batch 70/97, Loss: 0.3063
Epoch 9/10, Batch 80/97, Loss: 0.1967
Epoch 9/10, Batch 90/97, Loss: 0.2372
Epoch 9/10, Train Loss: 0.2096, Valid Loss: 0.2296
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.4552
Epoch 10/10, Batch 20/97, Loss: 0.1115
Epoch 10/10, Batch 30/97, Loss: 0.0942
Epoch 10/10, Batch 40/97, Loss: 0.2575
Epoch 10/10, Batch 50/97, Loss: 0.1794
Epoch 10/10, Batch 60/97, Loss: 0.1267
Epoch 10/10, Batch 70/97, Loss: 0.1259
Epoch 10/10, Batch 80/97, Loss: 0.1567
Epoch 10/10, Batch 90/97, Loss: 0.2379
Epoch 10/10, Train Loss: 0.1950, Valid Loss: 0.2193
Model saved!
Accuracy: 0.9241
Precision: 0.9220
Recall: 0.9241
F1-score: 0.9224
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5290
Epoch 1/10, Batch 20/97, Loss: 0.9918
Epoch 1/10, Batch 30/97, Loss: 0.8953
Epoch 1/10, Batch 40/97, Loss: 0.6325
Epoch 1/10, Batch 50/97, Loss: 0.6895
Epoch 1/10, Batch 60/97, Loss: 0.5279
Epoch 1/10, Batch 70/97, Loss: 0.6001
Epoch 1/10, Batch 80/97, Loss: 0.5333
Epoch 1/10, Batch 90/97, Loss: 0.4909
Epoch 1/10, Train Loss: 0.7701, Valid Loss: 0.4173
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.2959
Epoch 2/10, Batch 20/97, Loss: 0.4500
Epoch 2/10, Batch 30/97, Loss: 0.5016
Epoch 2/10, Batch 40/97, Loss: 0.4034
Epoch 2/10, Batch 50/97, Loss: 0.6113
Epoch 2/10, Batch 60/97, Loss: 0.2796
Epoch 2/10, Batch 70/97, Loss: 0.3036
Epoch 2/10, Batch 80/97, Loss: 0.2215
Epoch 2/10, Batch 90/97, Loss: 0.3477
Epoch 2/10, Train Loss: 0.3947, Valid Loss: 0.3110
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3147
Epoch 3/10, Batch 20/97, Loss: 0.2631
Epoch 3/10, Batch 30/97, Loss: 0.2435
Epoch 3/10, Batch 40/97, Loss: 0.2409
Epoch 3/10, Batch 50/97, Loss: 0.1907
Epoch 3/10, Batch 60/97, Loss: 0.2776
Epoch 3/10, Batch 70/97, Loss: 0.2648
Epoch 3/10, Batch 80/97, Loss: 0.2682
Epoch 3/10, Batch 90/97, Loss: 0.2960
Epoch 3/10, Train Loss: 0.3190, Valid Loss: 0.2673
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2454
Epoch 4/10, Batch 20/97, Loss: 0.2031
Epoch 4/10, Batch 30/97, Loss: 0.3031
Epoch 4/10, Batch 40/97, Loss: 0.2534
Epoch 4/10, Batch 50/97, Loss: 0.0978
Epoch 4/10, Batch 60/97, Loss: 0.1643
Epoch 4/10, Batch 70/97, Loss: 0.2817
Epoch 4/10, Batch 80/97, Loss: 0.2564
Epoch 4/10, Batch 90/97, Loss: 0.2676
Epoch 4/10, Train Loss: 0.2877, Valid Loss: 0.2459
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1819
Epoch 5/10, Batch 20/97, Loss: 0.3098
Epoch 5/10, Batch 30/97, Loss: 0.2504
Epoch 5/10, Batch 40/97, Loss: 0.1707
Epoch 5/10, Batch 50/97, Loss: 0.2796
Epoch 5/10, Batch 60/97, Loss: 0.1190
Epoch 5/10, Batch 70/97, Loss: 0.1802
Epoch 5/10, Batch 80/97, Loss: 0.2521
Epoch 5/10, Batch 90/97, Loss: 0.4334
Epoch 5/10, Train Loss: 0.2612, Valid Loss: 0.2335
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1492
Epoch 6/10, Batch 20/97, Loss: 0.2912
Epoch 6/10, Batch 30/97, Loss: 0.1652
Epoch 6/10, Batch 40/97, Loss: 0.3749
Epoch 6/10, Batch 50/97, Loss: 0.1579
Epoch 6/10, Batch 60/97, Loss: 0.2368
Epoch 6/10, Batch 70/97, Loss: 0.2648
Epoch 6/10, Batch 80/97, Loss: 0.3109
Epoch 6/10, Batch 90/97, Loss: 0.1411
Epoch 6/10, Train Loss: 0.2407, Valid Loss: 0.2347
Epoch 7/10, Batch 10/97, Loss: 0.3534
Epoch 7/10, Batch 20/97, Loss: 0.1238
Epoch 7/10, Batch 30/97, Loss: 0.2645
Epoch 7/10, Batch 40/97, Loss: 0.2447
Epoch 7/10, Batch 50/97, Loss: 0.1873
Epoch 7/10, Batch 60/97, Loss: 0.2267
Epoch 7/10, Batch 70/97, Loss: 0.2015
Epoch 7/10, Batch 80/97, Loss: 0.3438
Epoch 7/10, Batch 90/97, Loss: 0.2627
Epoch 7/10, Train Loss: 0.2418, Valid Loss: 0.2205
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2340
Epoch 8/10, Batch 20/97, Loss: 0.2578
Epoch 8/10, Batch 30/97, Loss: 0.1186
Epoch 8/10, Batch 40/97, Loss: 0.0863
Epoch 8/10, Batch 50/97, Loss: 0.1515
Epoch 8/10, Batch 60/97, Loss: 0.1295
Epoch 8/10, Batch 70/97, Loss: 0.2420
Epoch 8/10, Batch 80/97, Loss: 0.2092
Epoch 8/10, Batch 90/97, Loss: 0.1245
Epoch 8/10, Train Loss: 0.2178, Valid Loss: 0.2096
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1429
Epoch 9/10, Batch 20/97, Loss: 0.0906
Epoch 9/10, Batch 30/97, Loss: 0.2161
Epoch 9/10, Batch 40/97, Loss: 0.1097
Epoch 9/10, Batch 50/97, Loss: 0.2757
Epoch 9/10, Batch 60/97, Loss: 0.3107
Epoch 9/10, Batch 70/97, Loss: 0.1776
Epoch 9/10, Batch 80/97, Loss: 0.2279
Epoch 9/10, Batch 90/97, Loss: 0.2974
Epoch 9/10, Train Loss: 0.2067, Valid Loss: 0.2161
Epoch 10/10, Batch 10/97, Loss: 0.2799
Epoch 10/10, Batch 20/97, Loss: 0.2655
Epoch 10/10, Batch 30/97, Loss: 0.2016
Epoch 10/10, Batch 40/97, Loss: 0.2707
Epoch 10/10, Batch 50/97, Loss: 0.2189
Epoch 10/10, Batch 60/97, Loss: 0.1287
Epoch 10/10, Batch 70/97, Loss: 0.1245
Epoch 10/10, Batch 80/97, Loss: 0.2328
Epoch 10/10, Batch 90/97, Loss: 0.1794
Epoch 10/10, Train Loss: 0.1972, Valid Loss: 0.2077
Model saved!
Accuracy: 0.9217
Precision: 0.9193
Recall: 0.9217
F1-score: 0.9201
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4788
Epoch 1/10, Batch 20/97, Loss: 1.0507
Epoch 1/10, Batch 30/97, Loss: 0.8768
Epoch 1/10, Batch 40/97, Loss: 0.8014
Epoch 1/10, Batch 50/97, Loss: 0.6135
Epoch 1/10, Batch 60/97, Loss: 0.6844
Epoch 1/10, Batch 70/97, Loss: 0.4320
Epoch 1/10, Batch 80/97, Loss: 0.5485
Epoch 1/10, Batch 90/97, Loss: 0.4894
Epoch 1/10, Train Loss: 0.7754, Valid Loss: 0.4381
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4127
Epoch 2/10, Batch 20/97, Loss: 0.4371
Epoch 2/10, Batch 30/97, Loss: 0.3658
Epoch 2/10, Batch 40/97, Loss: 0.3339
Epoch 2/10, Batch 50/97, Loss: 0.6584
Epoch 2/10, Batch 60/97, Loss: 0.3881
Epoch 2/10, Batch 70/97, Loss: 0.3808
Epoch 2/10, Batch 80/97, Loss: 0.2767
Epoch 2/10, Batch 90/97, Loss: 0.2974
Epoch 2/10, Train Loss: 0.3929, Valid Loss: 0.3403
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2840
Epoch 3/10, Batch 20/97, Loss: 0.2411
Epoch 3/10, Batch 30/97, Loss: 0.2195
Epoch 3/10, Batch 40/97, Loss: 0.3333
Epoch 3/10, Batch 50/97, Loss: 0.2919
Epoch 3/10, Batch 60/97, Loss: 0.2968
Epoch 3/10, Batch 70/97, Loss: 0.1896
Epoch 3/10, Batch 80/97, Loss: 0.2733
Epoch 3/10, Batch 90/97, Loss: 0.2833
Epoch 3/10, Train Loss: 0.3152, Valid Loss: 0.3015
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3600
Epoch 4/10, Batch 20/97, Loss: 0.2788
Epoch 4/10, Batch 30/97, Loss: 0.3159
Epoch 4/10, Batch 40/97, Loss: 0.3080
Epoch 4/10, Batch 50/97, Loss: 0.2299
Epoch 4/10, Batch 60/97, Loss: 0.1399
Epoch 4/10, Batch 70/97, Loss: 0.2343
Epoch 4/10, Batch 80/97, Loss: 0.3290
Epoch 4/10, Batch 90/97, Loss: 0.3211
Epoch 4/10, Train Loss: 0.2842, Valid Loss: 0.2741
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1094
Epoch 5/10, Batch 20/97, Loss: 0.2479
Epoch 5/10, Batch 30/97, Loss: 0.1380
Epoch 5/10, Batch 40/97, Loss: 0.1856
Epoch 5/10, Batch 50/97, Loss: 0.1539
Epoch 5/10, Batch 60/97, Loss: 0.2465
Epoch 5/10, Batch 70/97, Loss: 0.2486
Epoch 5/10, Batch 80/97, Loss: 0.2137
Epoch 5/10, Batch 90/97, Loss: 0.2388
Epoch 5/10, Train Loss: 0.2499, Valid Loss: 0.2622
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2590
Epoch 6/10, Batch 20/97, Loss: 0.2270
Epoch 6/10, Batch 30/97, Loss: 0.2383
Epoch 6/10, Batch 40/97, Loss: 0.3106
Epoch 6/10, Batch 50/97, Loss: 0.1540
Epoch 6/10, Batch 60/97, Loss: 0.2418
Epoch 6/10, Batch 70/97, Loss: 0.1569
Epoch 6/10, Batch 80/97, Loss: 0.1562
Epoch 6/10, Batch 90/97, Loss: 0.2079
Epoch 6/10, Train Loss: 0.2403, Valid Loss: 0.2576
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2511
Epoch 7/10, Batch 20/97, Loss: 0.1745
Epoch 7/10, Batch 30/97, Loss: 0.2341
Epoch 7/10, Batch 40/97, Loss: 0.2608
Epoch 7/10, Batch 50/97, Loss: 0.3176
Epoch 7/10, Batch 60/97, Loss: 0.2360
Epoch 7/10, Batch 70/97, Loss: 0.1319
Epoch 7/10, Batch 80/97, Loss: 0.2375
Epoch 7/10, Batch 90/97, Loss: 0.2879
Epoch 7/10, Train Loss: 0.2329, Valid Loss: 0.2401
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1370
Epoch 8/10, Batch 20/97, Loss: 0.1390
Epoch 8/10, Batch 30/97, Loss: 0.1201
Epoch 8/10, Batch 40/97, Loss: 0.2408
Epoch 8/10, Batch 50/97, Loss: 0.1968
Epoch 8/10, Batch 60/97, Loss: 0.1626
Epoch 8/10, Batch 70/97, Loss: 0.2039
Epoch 8/10, Batch 80/97, Loss: 0.1039
Epoch 8/10, Batch 90/97, Loss: 0.1309
Epoch 8/10, Train Loss: 0.2093, Valid Loss: 0.2428
Epoch 9/10, Batch 10/97, Loss: 0.1033
Epoch 9/10, Batch 20/97, Loss: 0.2150
Epoch 9/10, Batch 30/97, Loss: 0.3114
Epoch 9/10, Batch 40/97, Loss: 0.1054
Epoch 9/10, Batch 50/97, Loss: 0.2365
Epoch 9/10, Batch 60/97, Loss: 0.2182
Epoch 9/10, Batch 70/97, Loss: 0.2076
Epoch 9/10, Batch 80/97, Loss: 0.2217
Epoch 9/10, Batch 90/97, Loss: 0.3049
Epoch 9/10, Train Loss: 0.2078, Valid Loss: 0.2381
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3198
Epoch 10/10, Batch 20/97, Loss: 0.1134
Epoch 10/10, Batch 30/97, Loss: 0.1623
Epoch 10/10, Batch 40/97, Loss: 0.2387
Epoch 10/10, Batch 50/97, Loss: 0.1878
Epoch 10/10, Batch 60/97, Loss: 0.0889
Epoch 10/10, Batch 70/97, Loss: 0.2291
Epoch 10/10, Batch 80/97, Loss: 0.1734
Epoch 10/10, Batch 90/97, Loss: 0.2853
Epoch 10/10, Train Loss: 0.1957, Valid Loss: 0.2338
Model saved!
Accuracy: 0.9147
Precision: 0.9122
Recall: 0.9147
F1-score: 0.9131
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4168
Epoch 1/10, Batch 20/97, Loss: 0.9940
Epoch 1/10, Batch 30/97, Loss: 0.7924
Epoch 1/10, Batch 40/97, Loss: 0.8073
Epoch 1/10, Batch 50/97, Loss: 0.6150
Epoch 1/10, Batch 60/97, Loss: 0.5476
Epoch 1/10, Batch 70/97, Loss: 0.4229
Epoch 1/10, Batch 80/97, Loss: 0.5162
Epoch 1/10, Batch 90/97, Loss: 0.5363
Epoch 1/10, Train Loss: 0.7768, Valid Loss: 0.4196
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3631
Epoch 2/10, Batch 20/97, Loss: 0.6284
Epoch 2/10, Batch 30/97, Loss: 0.2946
Epoch 2/10, Batch 40/97, Loss: 0.4438
Epoch 2/10, Batch 50/97, Loss: 0.6454
Epoch 2/10, Batch 60/97, Loss: 0.1917
Epoch 2/10, Batch 70/97, Loss: 0.2762
Epoch 2/10, Batch 80/97, Loss: 0.2964
Epoch 2/10, Batch 90/97, Loss: 0.3411
Epoch 2/10, Train Loss: 0.4001, Valid Loss: 0.3148
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2577
Epoch 3/10, Batch 20/97, Loss: 0.3773
Epoch 3/10, Batch 30/97, Loss: 0.2528
Epoch 3/10, Batch 40/97, Loss: 0.3130
Epoch 3/10, Batch 50/97, Loss: 0.3516
Epoch 3/10, Batch 60/97, Loss: 0.2646
Epoch 3/10, Batch 70/97, Loss: 0.2929
Epoch 3/10, Batch 80/97, Loss: 0.4862
Epoch 3/10, Batch 90/97, Loss: 0.2720
Epoch 3/10, Train Loss: 0.3196, Valid Loss: 0.2719
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1870
Epoch 4/10, Batch 20/97, Loss: 0.2298
Epoch 4/10, Batch 30/97, Loss: 0.2791
Epoch 4/10, Batch 40/97, Loss: 0.2818
Epoch 4/10, Batch 50/97, Loss: 0.1942
Epoch 4/10, Batch 60/97, Loss: 0.1617
Epoch 4/10, Batch 70/97, Loss: 0.1770
Epoch 4/10, Batch 80/97, Loss: 0.2453
Epoch 4/10, Batch 90/97, Loss: 0.1817
Epoch 4/10, Train Loss: 0.2841, Valid Loss: 0.2596
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1841
Epoch 5/10, Batch 20/97, Loss: 0.1920
Epoch 5/10, Batch 30/97, Loss: 0.1928
Epoch 5/10, Batch 40/97, Loss: 0.1759
Epoch 5/10, Batch 50/97, Loss: 0.3927
Epoch 5/10, Batch 60/97, Loss: 0.2850
Epoch 5/10, Batch 70/97, Loss: 0.2315
Epoch 5/10, Batch 80/97, Loss: 0.3703
Epoch 5/10, Batch 90/97, Loss: 0.2719
Epoch 5/10, Train Loss: 0.2549, Valid Loss: 0.2474
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2135
Epoch 6/10, Batch 20/97, Loss: 0.1209
Epoch 6/10, Batch 30/97, Loss: 0.1699
Epoch 6/10, Batch 40/97, Loss: 0.3522
Epoch 6/10, Batch 50/97, Loss: 0.2128
Epoch 6/10, Batch 60/97, Loss: 0.1705
Epoch 6/10, Batch 70/97, Loss: 0.2394
Epoch 6/10, Batch 80/97, Loss: 0.1327
Epoch 6/10, Batch 90/97, Loss: 0.2972
Epoch 6/10, Train Loss: 0.2422, Valid Loss: 0.2428
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2352
Epoch 7/10, Batch 20/97, Loss: 0.1618
Epoch 7/10, Batch 30/97, Loss: 0.1992
Epoch 7/10, Batch 40/97, Loss: 0.1707
Epoch 7/10, Batch 50/97, Loss: 0.2106
Epoch 7/10, Batch 60/97, Loss: 0.2588
Epoch 7/10, Batch 70/97, Loss: 0.2004
Epoch 7/10, Batch 80/97, Loss: 0.1093
Epoch 7/10, Batch 90/97, Loss: 0.2160
Epoch 7/10, Train Loss: 0.2384, Valid Loss: 0.2299
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1172
Epoch 8/10, Batch 20/97, Loss: 0.3398
Epoch 8/10, Batch 30/97, Loss: 0.1595
Epoch 8/10, Batch 40/97, Loss: 0.2416
Epoch 8/10, Batch 50/97, Loss: 0.2695
Epoch 8/10, Batch 60/97, Loss: 0.1282
Epoch 8/10, Batch 70/97, Loss: 0.3298
Epoch 8/10, Batch 80/97, Loss: 0.1222
Epoch 8/10, Batch 90/97, Loss: 0.1566
Epoch 8/10, Train Loss: 0.2152, Valid Loss: 0.2276
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0784
Epoch 9/10, Batch 20/97, Loss: 0.0966
Epoch 9/10, Batch 30/97, Loss: 0.1541
Epoch 9/10, Batch 40/97, Loss: 0.0652
Epoch 9/10, Batch 50/97, Loss: 0.2570
Epoch 9/10, Batch 60/97, Loss: 0.2984
Epoch 9/10, Batch 70/97, Loss: 0.2002
Epoch 9/10, Batch 80/97, Loss: 0.1438
Epoch 9/10, Batch 90/97, Loss: 0.1992
Epoch 9/10, Train Loss: 0.2090, Valid Loss: 0.2281
Epoch 10/10, Batch 10/97, Loss: 0.3016
Epoch 10/10, Batch 20/97, Loss: 0.2505
Epoch 10/10, Batch 30/97, Loss: 0.1486
Epoch 10/10, Batch 40/97, Loss: 0.1171
Epoch 10/10, Batch 50/97, Loss: 0.3425
Epoch 10/10, Batch 60/97, Loss: 0.1623
Epoch 10/10, Batch 70/97, Loss: 0.1220
Epoch 10/10, Batch 80/97, Loss: 0.2196
Epoch 10/10, Batch 90/97, Loss: 0.2408
Epoch 10/10, Train Loss: 0.1957, Valid Loss: 0.2263
Model saved!
Accuracy: 0.9182
Precision: 0.9153
Recall: 0.9182
F1-score: 0.9160
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4765
Epoch 1/10, Batch 20/97, Loss: 1.0184
Epoch 1/10, Batch 30/97, Loss: 0.9230
Epoch 1/10, Batch 40/97, Loss: 0.7060
Epoch 1/10, Batch 50/97, Loss: 0.6862
Epoch 1/10, Batch 60/97, Loss: 0.4817
Epoch 1/10, Batch 70/97, Loss: 0.6105
Epoch 1/10, Batch 80/97, Loss: 0.4490
Epoch 1/10, Batch 90/97, Loss: 0.4088
Epoch 1/10, Train Loss: 0.7727, Valid Loss: 0.4320
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4278
Epoch 2/10, Batch 20/97, Loss: 0.5325
Epoch 2/10, Batch 30/97, Loss: 0.3292
Epoch 2/10, Batch 40/97, Loss: 0.4344
Epoch 2/10, Batch 50/97, Loss: 0.6285
Epoch 2/10, Batch 60/97, Loss: 0.4341
Epoch 2/10, Batch 70/97, Loss: 0.2506
Epoch 2/10, Batch 80/97, Loss: 0.3686
Epoch 2/10, Batch 90/97, Loss: 0.4193
Epoch 2/10, Train Loss: 0.3955, Valid Loss: 0.3304
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2728
Epoch 3/10, Batch 20/97, Loss: 0.2864
Epoch 3/10, Batch 30/97, Loss: 0.3246
Epoch 3/10, Batch 40/97, Loss: 0.2263
Epoch 3/10, Batch 50/97, Loss: 0.3053
Epoch 3/10, Batch 60/97, Loss: 0.2751
Epoch 3/10, Batch 70/97, Loss: 0.2420
Epoch 3/10, Batch 80/97, Loss: 0.3367
Epoch 3/10, Batch 90/97, Loss: 0.3188
Epoch 3/10, Train Loss: 0.3222, Valid Loss: 0.2761
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2366
Epoch 4/10, Batch 20/97, Loss: 0.3231
Epoch 4/10, Batch 30/97, Loss: 0.3671
Epoch 4/10, Batch 40/97, Loss: 0.2990
Epoch 4/10, Batch 50/97, Loss: 0.1382
Epoch 4/10, Batch 60/97, Loss: 0.2004
Epoch 4/10, Batch 70/97, Loss: 0.2593
Epoch 4/10, Batch 80/97, Loss: 0.2916
Epoch 4/10, Batch 90/97, Loss: 0.2224
Epoch 4/10, Train Loss: 0.2757, Valid Loss: 0.2516
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2598
Epoch 5/10, Batch 20/97, Loss: 0.1301
Epoch 5/10, Batch 30/97, Loss: 0.2131
Epoch 5/10, Batch 40/97, Loss: 0.2892
Epoch 5/10, Batch 50/97, Loss: 0.1253
Epoch 5/10, Batch 60/97, Loss: 0.2784
Epoch 5/10, Batch 70/97, Loss: 0.1693
Epoch 5/10, Batch 80/97, Loss: 0.2453
Epoch 5/10, Batch 90/97, Loss: 0.3299
Epoch 5/10, Train Loss: 0.2608, Valid Loss: 0.2411
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1475
Epoch 6/10, Batch 20/97, Loss: 0.1035
Epoch 6/10, Batch 30/97, Loss: 0.1051
Epoch 6/10, Batch 40/97, Loss: 0.3146
Epoch 6/10, Batch 50/97, Loss: 0.1796
Epoch 6/10, Batch 60/97, Loss: 0.3826
Epoch 6/10, Batch 70/97, Loss: 0.2261
Epoch 6/10, Batch 80/97, Loss: 0.1863
Epoch 6/10, Batch 90/97, Loss: 0.1950
Epoch 6/10, Train Loss: 0.2361, Valid Loss: 0.2300
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4241
Epoch 7/10, Batch 20/97, Loss: 0.1512
Epoch 7/10, Batch 30/97, Loss: 0.2225
Epoch 7/10, Batch 40/97, Loss: 0.1933
Epoch 7/10, Batch 50/97, Loss: 0.2447
Epoch 7/10, Batch 60/97, Loss: 0.3569
Epoch 7/10, Batch 70/97, Loss: 0.1781
Epoch 7/10, Batch 80/97, Loss: 0.1379
Epoch 7/10, Batch 90/97, Loss: 0.1822
Epoch 7/10, Train Loss: 0.2321, Valid Loss: 0.2261
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1536
Epoch 8/10, Batch 20/97, Loss: 0.2637
Epoch 8/10, Batch 30/97, Loss: 0.0985
Epoch 8/10, Batch 40/97, Loss: 0.2638
Epoch 8/10, Batch 50/97, Loss: 0.1792
Epoch 8/10, Batch 60/97, Loss: 0.1876
Epoch 8/10, Batch 70/97, Loss: 0.1793
Epoch 8/10, Batch 80/97, Loss: 0.1375
Epoch 8/10, Batch 90/97, Loss: 0.3191
Epoch 8/10, Train Loss: 0.2164, Valid Loss: 0.2203
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1194
Epoch 9/10, Batch 20/97, Loss: 0.1382
Epoch 9/10, Batch 30/97, Loss: 0.3470
Epoch 9/10, Batch 40/97, Loss: 0.2001
Epoch 9/10, Batch 50/97, Loss: 0.4502
Epoch 9/10, Batch 60/97, Loss: 0.1982
Epoch 9/10, Batch 70/97, Loss: 0.1314
Epoch 9/10, Batch 80/97, Loss: 0.2009
Epoch 9/10, Batch 90/97, Loss: 0.2449
Epoch 9/10, Train Loss: 0.2058, Valid Loss: 0.2248
Epoch 10/10, Batch 10/97, Loss: 0.1685
Epoch 10/10, Batch 20/97, Loss: 0.1393
Epoch 10/10, Batch 30/97, Loss: 0.2094
Epoch 10/10, Batch 40/97, Loss: 0.1299
Epoch 10/10, Batch 50/97, Loss: 0.2171
Epoch 10/10, Batch 60/97, Loss: 0.1419
Epoch 10/10, Batch 70/97, Loss: 0.1054
Epoch 10/10, Batch 80/97, Loss: 0.1764
Epoch 10/10, Batch 90/97, Loss: 0.1488
Epoch 10/10, Train Loss: 0.1940, Valid Loss: 0.2029
Model saved!
Accuracy: 0.9276
Precision: 0.9259
Recall: 0.9276
F1-score: 0.9265
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4832
Epoch 1/10, Batch 20/97, Loss: 1.0382
Epoch 1/10, Batch 30/97, Loss: 0.9203
Epoch 1/10, Batch 40/97, Loss: 0.8246
Epoch 1/10, Batch 50/97, Loss: 0.5175
Epoch 1/10, Batch 60/97, Loss: 0.5279
Epoch 1/10, Batch 70/97, Loss: 0.5206
Epoch 1/10, Batch 80/97, Loss: 0.4430
Epoch 1/10, Batch 90/97, Loss: 0.5005
Epoch 1/10, Train Loss: 0.7738, Valid Loss: 0.4136
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3595
Epoch 2/10, Batch 20/97, Loss: 0.5068
Epoch 2/10, Batch 30/97, Loss: 0.4193
Epoch 2/10, Batch 40/97, Loss: 0.4116
Epoch 2/10, Batch 50/97, Loss: 0.5669
Epoch 2/10, Batch 60/97, Loss: 0.2892
Epoch 2/10, Batch 70/97, Loss: 0.3283
Epoch 2/10, Batch 80/97, Loss: 0.4185
Epoch 2/10, Batch 90/97, Loss: 0.3394
Epoch 2/10, Train Loss: 0.3937, Valid Loss: 0.3098
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3508
Epoch 3/10, Batch 20/97, Loss: 0.3574
Epoch 3/10, Batch 30/97, Loss: 0.2646
Epoch 3/10, Batch 40/97, Loss: 0.2919
Epoch 3/10, Batch 50/97, Loss: 0.2739
Epoch 3/10, Batch 60/97, Loss: 0.2748
Epoch 3/10, Batch 70/97, Loss: 0.1925
Epoch 3/10, Batch 80/97, Loss: 0.3742
Epoch 3/10, Batch 90/97, Loss: 0.2941
Epoch 3/10, Train Loss: 0.3189, Valid Loss: 0.2644
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3567
Epoch 4/10, Batch 20/97, Loss: 0.2237
Epoch 4/10, Batch 30/97, Loss: 0.4380
Epoch 4/10, Batch 40/97, Loss: 0.1962
Epoch 4/10, Batch 50/97, Loss: 0.1695
Epoch 4/10, Batch 60/97, Loss: 0.1488
Epoch 4/10, Batch 70/97, Loss: 0.1949
Epoch 4/10, Batch 80/97, Loss: 0.2323
Epoch 4/10, Batch 90/97, Loss: 0.3607
Epoch 4/10, Train Loss: 0.2851, Valid Loss: 0.2492
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2021
Epoch 5/10, Batch 20/97, Loss: 0.3466
Epoch 5/10, Batch 30/97, Loss: 0.1980
Epoch 5/10, Batch 40/97, Loss: 0.2912
Epoch 5/10, Batch 50/97, Loss: 0.2816
Epoch 5/10, Batch 60/97, Loss: 0.1903
Epoch 5/10, Batch 70/97, Loss: 0.2477
Epoch 5/10, Batch 80/97, Loss: 0.4009
Epoch 5/10, Batch 90/97, Loss: 0.2671
Epoch 5/10, Train Loss: 0.2610, Valid Loss: 0.2321
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2618
Epoch 6/10, Batch 20/97, Loss: 0.2344
Epoch 6/10, Batch 30/97, Loss: 0.1486
Epoch 6/10, Batch 40/97, Loss: 0.3900
Epoch 6/10, Batch 50/97, Loss: 0.1778
Epoch 6/10, Batch 60/97, Loss: 0.1855
Epoch 6/10, Batch 70/97, Loss: 0.1500
Epoch 6/10, Batch 80/97, Loss: 0.1378
Epoch 6/10, Batch 90/97, Loss: 0.2334
Epoch 6/10, Train Loss: 0.2460, Valid Loss: 0.2322
Epoch 7/10, Batch 10/97, Loss: 0.4386
Epoch 7/10, Batch 20/97, Loss: 0.1375
Epoch 7/10, Batch 30/97, Loss: 0.1987
Epoch 7/10, Batch 40/97, Loss: 0.1905
Epoch 7/10, Batch 50/97, Loss: 0.2446
Epoch 7/10, Batch 60/97, Loss: 0.3744
Epoch 7/10, Batch 70/97, Loss: 0.1154
Epoch 7/10, Batch 80/97, Loss: 0.3193
Epoch 7/10, Batch 90/97, Loss: 0.1274
Epoch 7/10, Train Loss: 0.2489, Valid Loss: 0.2123
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1317
Epoch 8/10, Batch 20/97, Loss: 0.2339
Epoch 8/10, Batch 30/97, Loss: 0.1599
Epoch 8/10, Batch 40/97, Loss: 0.1563
Epoch 8/10, Batch 50/97, Loss: 0.2098
Epoch 8/10, Batch 60/97, Loss: 0.2086
Epoch 8/10, Batch 70/97, Loss: 0.2149
Epoch 8/10, Batch 80/97, Loss: 0.2205
Epoch 8/10, Batch 90/97, Loss: 0.1083
Epoch 8/10, Train Loss: 0.2187, Valid Loss: 0.2173
Epoch 9/10, Batch 10/97, Loss: 0.1299
Epoch 9/10, Batch 20/97, Loss: 0.1464
Epoch 9/10, Batch 30/97, Loss: 0.2992
Epoch 9/10, Batch 40/97, Loss: 0.0881
Epoch 9/10, Batch 50/97, Loss: 0.2282
Epoch 9/10, Batch 60/97, Loss: 0.1574
Epoch 9/10, Batch 70/97, Loss: 0.2382
Epoch 9/10, Batch 80/97, Loss: 0.2073
Epoch 9/10, Batch 90/97, Loss: 0.3470
Epoch 9/10, Train Loss: 0.2104, Valid Loss: 0.2165
Epoch 10/10, Batch 10/97, Loss: 0.2113
Epoch 10/10, Batch 20/97, Loss: 0.1260
Epoch 10/10, Batch 30/97, Loss: 0.1638
Epoch 10/10, Batch 40/97, Loss: 0.1363
Epoch 10/10, Batch 50/97, Loss: 0.1941
Epoch 10/10, Batch 60/97, Loss: 0.1819
Epoch 10/10, Batch 70/97, Loss: 0.2506
Epoch 10/10, Batch 80/97, Loss: 0.2575
Epoch 10/10, Batch 90/97, Loss: 0.1523
Epoch 10/10, Train Loss: 0.1991, Valid Loss: 0.2126
Accuracy: 0.9124
Precision: 0.9095
Recall: 0.9124
F1-score: 0.9105
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4783
Epoch 1/10, Batch 20/97, Loss: 0.9973
Epoch 1/10, Batch 30/97, Loss: 0.8854
Epoch 1/10, Batch 40/97, Loss: 0.8909
Epoch 1/10, Batch 50/97, Loss: 0.6344
Epoch 1/10, Batch 60/97, Loss: 0.5657
Epoch 1/10, Batch 70/97, Loss: 0.5405
Epoch 1/10, Batch 80/97, Loss: 0.5393
Epoch 1/10, Batch 90/97, Loss: 0.5942
Epoch 1/10, Train Loss: 0.7767, Valid Loss: 0.4453
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3863
Epoch 2/10, Batch 20/97, Loss: 0.5811
Epoch 2/10, Batch 30/97, Loss: 0.4543
Epoch 2/10, Batch 40/97, Loss: 0.3721
Epoch 2/10, Batch 50/97, Loss: 0.5237
Epoch 2/10, Batch 60/97, Loss: 0.3818
Epoch 2/10, Batch 70/97, Loss: 0.2544
Epoch 2/10, Batch 80/97, Loss: 0.2951
Epoch 2/10, Batch 90/97, Loss: 0.4118
Epoch 2/10, Train Loss: 0.3983, Valid Loss: 0.3310
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3074
Epoch 3/10, Batch 20/97, Loss: 0.2649
Epoch 3/10, Batch 30/97, Loss: 0.3667
Epoch 3/10, Batch 40/97, Loss: 0.2535
Epoch 3/10, Batch 50/97, Loss: 0.2722
Epoch 3/10, Batch 60/97, Loss: 0.2422
Epoch 3/10, Batch 70/97, Loss: 0.1681
Epoch 3/10, Batch 80/97, Loss: 0.4959
Epoch 3/10, Batch 90/97, Loss: 0.1770
Epoch 3/10, Train Loss: 0.3256, Valid Loss: 0.2852
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2957
Epoch 4/10, Batch 20/97, Loss: 0.3206
Epoch 4/10, Batch 30/97, Loss: 0.4403
Epoch 4/10, Batch 40/97, Loss: 0.2583
Epoch 4/10, Batch 50/97, Loss: 0.1608
Epoch 4/10, Batch 60/97, Loss: 0.1732
Epoch 4/10, Batch 70/97, Loss: 0.2948
Epoch 4/10, Batch 80/97, Loss: 0.2865
Epoch 4/10, Batch 90/97, Loss: 0.2857
Epoch 4/10, Train Loss: 0.2834, Valid Loss: 0.2688
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2793
Epoch 5/10, Batch 20/97, Loss: 0.2092
Epoch 5/10, Batch 30/97, Loss: 0.1478
Epoch 5/10, Batch 40/97, Loss: 0.2052
Epoch 5/10, Batch 50/97, Loss: 0.3378
Epoch 5/10, Batch 60/97, Loss: 0.2051
Epoch 5/10, Batch 70/97, Loss: 0.2781
Epoch 5/10, Batch 80/97, Loss: 0.1752
Epoch 5/10, Batch 90/97, Loss: 0.4359
Epoch 5/10, Train Loss: 0.2565, Valid Loss: 0.2518
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1388
Epoch 6/10, Batch 20/97, Loss: 0.1861
Epoch 6/10, Batch 30/97, Loss: 0.2660
Epoch 6/10, Batch 40/97, Loss: 0.2420
Epoch 6/10, Batch 50/97, Loss: 0.3677
Epoch 6/10, Batch 60/97, Loss: 0.2041
Epoch 6/10, Batch 70/97, Loss: 0.2749
Epoch 6/10, Batch 80/97, Loss: 0.1320
Epoch 6/10, Batch 90/97, Loss: 0.3299
Epoch 6/10, Train Loss: 0.2406, Valid Loss: 0.2393
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3535
Epoch 7/10, Batch 20/97, Loss: 0.1687
Epoch 7/10, Batch 30/97, Loss: 0.2053
Epoch 7/10, Batch 40/97, Loss: 0.2059
Epoch 7/10, Batch 50/97, Loss: 0.1637
Epoch 7/10, Batch 60/97, Loss: 0.2209
Epoch 7/10, Batch 70/97, Loss: 0.1240
Epoch 7/10, Batch 80/97, Loss: 0.2763
Epoch 7/10, Batch 90/97, Loss: 0.2852
Epoch 7/10, Train Loss: 0.2405, Valid Loss: 0.2342
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2682
Epoch 8/10, Batch 20/97, Loss: 0.1127
Epoch 8/10, Batch 30/97, Loss: 0.1313
Epoch 8/10, Batch 40/97, Loss: 0.2104
Epoch 8/10, Batch 50/97, Loss: 0.1943
Epoch 8/10, Batch 60/97, Loss: 0.2291
Epoch 8/10, Batch 70/97, Loss: 0.2896
Epoch 8/10, Batch 80/97, Loss: 0.0981
Epoch 8/10, Batch 90/97, Loss: 0.1413
Epoch 8/10, Train Loss: 0.2184, Valid Loss: 0.2267
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1088
Epoch 9/10, Batch 20/97, Loss: 0.2033
Epoch 9/10, Batch 30/97, Loss: 0.3308
Epoch 9/10, Batch 40/97, Loss: 0.1973
Epoch 9/10, Batch 50/97, Loss: 0.2087
Epoch 9/10, Batch 60/97, Loss: 0.2634
Epoch 9/10, Batch 70/97, Loss: 0.2391
Epoch 9/10, Batch 80/97, Loss: 0.0940
Epoch 9/10, Batch 90/97, Loss: 0.1575
Epoch 9/10, Train Loss: 0.2022, Valid Loss: 0.2286
Epoch 10/10, Batch 10/97, Loss: 0.2320
Epoch 10/10, Batch 20/97, Loss: 0.1008
Epoch 10/10, Batch 30/97, Loss: 0.2500
Epoch 10/10, Batch 40/97, Loss: 0.1731
Epoch 10/10, Batch 50/97, Loss: 0.2315
Epoch 10/10, Batch 60/97, Loss: 0.1565
Epoch 10/10, Batch 70/97, Loss: 0.0914
Epoch 10/10, Batch 80/97, Loss: 0.2035
Epoch 10/10, Batch 90/97, Loss: 0.2433
Epoch 10/10, Train Loss: 0.1940, Valid Loss: 0.2230
Model saved!
Accuracy: 0.9159
Precision: 0.9137
Recall: 0.9159
F1-score: 0.9143
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4865
Epoch 1/10, Batch 20/97, Loss: 0.9896
Epoch 1/10, Batch 30/97, Loss: 0.8964
Epoch 1/10, Batch 40/97, Loss: 0.6658
Epoch 1/10, Batch 50/97, Loss: 0.6096
Epoch 1/10, Batch 60/97, Loss: 0.5642
Epoch 1/10, Batch 70/97, Loss: 0.5605
Epoch 1/10, Batch 80/97, Loss: 0.5417
Epoch 1/10, Batch 90/97, Loss: 0.6046
Epoch 1/10, Train Loss: 0.7816, Valid Loss: 0.4430
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3649
Epoch 2/10, Batch 20/97, Loss: 0.4522
Epoch 2/10, Batch 30/97, Loss: 0.3983
Epoch 2/10, Batch 40/97, Loss: 0.3281
Epoch 2/10, Batch 50/97, Loss: 0.6901
Epoch 2/10, Batch 60/97, Loss: 0.3754
Epoch 2/10, Batch 70/97, Loss: 0.3232
Epoch 2/10, Batch 80/97, Loss: 0.3444
Epoch 2/10, Batch 90/97, Loss: 0.4726
Epoch 2/10, Train Loss: 0.4016, Valid Loss: 0.3333
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4033
Epoch 3/10, Batch 20/97, Loss: 0.2904
Epoch 3/10, Batch 30/97, Loss: 0.2503
Epoch 3/10, Batch 40/97, Loss: 0.3674
Epoch 3/10, Batch 50/97, Loss: 0.2150
Epoch 3/10, Batch 60/97, Loss: 0.2868
Epoch 3/10, Batch 70/97, Loss: 0.1836
Epoch 3/10, Batch 80/97, Loss: 0.3701
Epoch 3/10, Batch 90/97, Loss: 0.1914
Epoch 3/10, Train Loss: 0.3199, Valid Loss: 0.2886
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2718
Epoch 4/10, Batch 20/97, Loss: 0.3261
Epoch 4/10, Batch 30/97, Loss: 0.3582
Epoch 4/10, Batch 40/97, Loss: 0.3159
Epoch 4/10, Batch 50/97, Loss: 0.2531
Epoch 4/10, Batch 60/97, Loss: 0.2352
Epoch 4/10, Batch 70/97, Loss: 0.4053
Epoch 4/10, Batch 80/97, Loss: 0.1853
Epoch 4/10, Batch 90/97, Loss: 0.2198
Epoch 4/10, Train Loss: 0.2879, Valid Loss: 0.2731
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1826
Epoch 5/10, Batch 20/97, Loss: 0.1848
Epoch 5/10, Batch 30/97, Loss: 0.0839
Epoch 5/10, Batch 40/97, Loss: 0.1867
Epoch 5/10, Batch 50/97, Loss: 0.2209
Epoch 5/10, Batch 60/97, Loss: 0.3878
Epoch 5/10, Batch 70/97, Loss: 0.2706
Epoch 5/10, Batch 80/97, Loss: 0.2337
Epoch 5/10, Batch 90/97, Loss: 0.3163
Epoch 5/10, Train Loss: 0.2518, Valid Loss: 0.2572
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3416
Epoch 6/10, Batch 20/97, Loss: 0.2057
Epoch 6/10, Batch 30/97, Loss: 0.2297
Epoch 6/10, Batch 40/97, Loss: 0.3939
Epoch 6/10, Batch 50/97, Loss: 0.2043
Epoch 6/10, Batch 60/97, Loss: 0.3729
Epoch 6/10, Batch 70/97, Loss: 0.1845
Epoch 6/10, Batch 80/97, Loss: 0.1850
Epoch 6/10, Batch 90/97, Loss: 0.3126
Epoch 6/10, Train Loss: 0.2417, Valid Loss: 0.2480
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2965
Epoch 7/10, Batch 20/97, Loss: 0.1669
Epoch 7/10, Batch 30/97, Loss: 0.2009
Epoch 7/10, Batch 40/97, Loss: 0.2128
Epoch 7/10, Batch 50/97, Loss: 0.1371
Epoch 7/10, Batch 60/97, Loss: 0.2525
Epoch 7/10, Batch 70/97, Loss: 0.1730
Epoch 7/10, Batch 80/97, Loss: 0.2424
Epoch 7/10, Batch 90/97, Loss: 0.2051
Epoch 7/10, Train Loss: 0.2341, Valid Loss: 0.2413
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2631
Epoch 8/10, Batch 20/97, Loss: 0.1480
Epoch 8/10, Batch 30/97, Loss: 0.1206
Epoch 8/10, Batch 40/97, Loss: 0.1611
Epoch 8/10, Batch 50/97, Loss: 0.1546
Epoch 8/10, Batch 60/97, Loss: 0.1928
Epoch 8/10, Batch 70/97, Loss: 0.3179
Epoch 8/10, Batch 80/97, Loss: 0.1216
Epoch 8/10, Batch 90/97, Loss: 0.1475
Epoch 8/10, Train Loss: 0.2207, Valid Loss: 0.2475
Epoch 9/10, Batch 10/97, Loss: 0.1650
Epoch 9/10, Batch 20/97, Loss: 0.1366
Epoch 9/10, Batch 30/97, Loss: 0.2766
Epoch 9/10, Batch 40/97, Loss: 0.2374
Epoch 9/10, Batch 50/97, Loss: 0.2235
Epoch 9/10, Batch 60/97, Loss: 0.4007
Epoch 9/10, Batch 70/97, Loss: 0.2162
Epoch 9/10, Batch 80/97, Loss: 0.1580
Epoch 9/10, Batch 90/97, Loss: 0.2619
Epoch 9/10, Train Loss: 0.2115, Valid Loss: 0.2393
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2857
Epoch 10/10, Batch 20/97, Loss: 0.2397
Epoch 10/10, Batch 30/97, Loss: 0.1323
Epoch 10/10, Batch 40/97, Loss: 0.3251
Epoch 10/10, Batch 50/97, Loss: 0.1364
Epoch 10/10, Batch 60/97, Loss: 0.1090
Epoch 10/10, Batch 70/97, Loss: 0.1755
Epoch 10/10, Batch 80/97, Loss: 0.1930
Epoch 10/10, Batch 90/97, Loss: 0.1185
Epoch 10/10, Train Loss: 0.1975, Valid Loss: 0.2315
Model saved!
Accuracy: 0.9276
Precision: 0.9254
Recall: 0.9276
F1-score: 0.9262
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4143
Epoch 1/10, Batch 20/97, Loss: 0.9989
Epoch 1/10, Batch 30/97, Loss: 0.9756
Epoch 1/10, Batch 40/97, Loss: 0.7479
Epoch 1/10, Batch 50/97, Loss: 0.5710
Epoch 1/10, Batch 60/97, Loss: 0.5989
Epoch 1/10, Batch 70/97, Loss: 0.4186
Epoch 1/10, Batch 80/97, Loss: 0.4767
Epoch 1/10, Batch 90/97, Loss: 0.5235
Epoch 1/10, Train Loss: 0.7639, Valid Loss: 0.4595
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3060
Epoch 2/10, Batch 20/97, Loss: 0.5036
Epoch 2/10, Batch 30/97, Loss: 0.3306
Epoch 2/10, Batch 40/97, Loss: 0.3025
Epoch 2/10, Batch 50/97, Loss: 0.5144
Epoch 2/10, Batch 60/97, Loss: 0.3916
Epoch 2/10, Batch 70/97, Loss: 0.3504
Epoch 2/10, Batch 80/97, Loss: 0.2831
Epoch 2/10, Batch 90/97, Loss: 0.2986
Epoch 2/10, Train Loss: 0.3841, Valid Loss: 0.3548
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3880
Epoch 3/10, Batch 20/97, Loss: 0.2789
Epoch 3/10, Batch 30/97, Loss: 0.1813
Epoch 3/10, Batch 40/97, Loss: 0.2709
Epoch 3/10, Batch 50/97, Loss: 0.2927
Epoch 3/10, Batch 60/97, Loss: 0.2147
Epoch 3/10, Batch 70/97, Loss: 0.1382
Epoch 3/10, Batch 80/97, Loss: 0.2299
Epoch 3/10, Batch 90/97, Loss: 0.2867
Epoch 3/10, Train Loss: 0.3176, Valid Loss: 0.3080
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2137
Epoch 4/10, Batch 20/97, Loss: 0.4523
Epoch 4/10, Batch 30/97, Loss: 0.3619
Epoch 4/10, Batch 40/97, Loss: 0.2912
Epoch 4/10, Batch 50/97, Loss: 0.0825
Epoch 4/10, Batch 60/97, Loss: 0.1006
Epoch 4/10, Batch 70/97, Loss: 0.3400
Epoch 4/10, Batch 80/97, Loss: 0.2407
Epoch 4/10, Batch 90/97, Loss: 0.2029
Epoch 4/10, Train Loss: 0.2793, Valid Loss: 0.2906
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2818
Epoch 5/10, Batch 20/97, Loss: 0.2430
Epoch 5/10, Batch 30/97, Loss: 0.2200
Epoch 5/10, Batch 40/97, Loss: 0.1396
Epoch 5/10, Batch 50/97, Loss: 0.2847
Epoch 5/10, Batch 60/97, Loss: 0.2185
Epoch 5/10, Batch 70/97, Loss: 0.2338
Epoch 5/10, Batch 80/97, Loss: 0.2347
Epoch 5/10, Batch 90/97, Loss: 0.3021
Epoch 5/10, Train Loss: 0.2519, Valid Loss: 0.2736
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1423
Epoch 6/10, Batch 20/97, Loss: 0.2028
Epoch 6/10, Batch 30/97, Loss: 0.1292
Epoch 6/10, Batch 40/97, Loss: 0.1831
Epoch 6/10, Batch 50/97, Loss: 0.2421
Epoch 6/10, Batch 60/97, Loss: 0.2291
Epoch 6/10, Batch 70/97, Loss: 0.1877
Epoch 6/10, Batch 80/97, Loss: 0.1319
Epoch 6/10, Batch 90/97, Loss: 0.2725
Epoch 6/10, Train Loss: 0.2373, Valid Loss: 0.2595
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3344
Epoch 7/10, Batch 20/97, Loss: 0.1172
Epoch 7/10, Batch 30/97, Loss: 0.3507
Epoch 7/10, Batch 40/97, Loss: 0.1468
Epoch 7/10, Batch 50/97, Loss: 0.1030
Epoch 7/10, Batch 60/97, Loss: 0.4173
Epoch 7/10, Batch 70/97, Loss: 0.4183
Epoch 7/10, Batch 80/97, Loss: 0.1796
Epoch 7/10, Batch 90/97, Loss: 0.2596
Epoch 7/10, Train Loss: 0.2325, Valid Loss: 0.2549
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1422
Epoch 8/10, Batch 20/97, Loss: 0.1058
Epoch 8/10, Batch 30/97, Loss: 0.1111
Epoch 8/10, Batch 40/97, Loss: 0.2736
Epoch 8/10, Batch 50/97, Loss: 0.2875
Epoch 8/10, Batch 60/97, Loss: 0.1637
Epoch 8/10, Batch 70/97, Loss: 0.2621
Epoch 8/10, Batch 80/97, Loss: 0.2442
Epoch 8/10, Batch 90/97, Loss: 0.1505
Epoch 8/10, Train Loss: 0.2150, Valid Loss: 0.2475
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1184
Epoch 9/10, Batch 20/97, Loss: 0.0951
Epoch 9/10, Batch 30/97, Loss: 0.3595
Epoch 9/10, Batch 40/97, Loss: 0.1189
Epoch 9/10, Batch 50/97, Loss: 0.4127
Epoch 9/10, Batch 60/97, Loss: 0.1648
Epoch 9/10, Batch 70/97, Loss: 0.2635
Epoch 9/10, Batch 80/97, Loss: 0.2175
Epoch 9/10, Batch 90/97, Loss: 0.1996
Epoch 9/10, Train Loss: 0.2041, Valid Loss: 0.2428
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1162
Epoch 10/10, Batch 20/97, Loss: 0.1923
Epoch 10/10, Batch 30/97, Loss: 0.1835
Epoch 10/10, Batch 40/97, Loss: 0.2242
Epoch 10/10, Batch 50/97, Loss: 0.3013
Epoch 10/10, Batch 60/97, Loss: 0.1730
Epoch 10/10, Batch 70/97, Loss: 0.2027
Epoch 10/10, Batch 80/97, Loss: 0.1376
Epoch 10/10, Batch 90/97, Loss: 0.1551
Epoch 10/10, Train Loss: 0.1964, Valid Loss: 0.2343
Model saved!
Accuracy: 0.9229
Precision: 0.9200
Recall: 0.9229
F1-score: 0.9208
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4636
Epoch 1/10, Batch 20/97, Loss: 0.9886
Epoch 1/10, Batch 30/97, Loss: 0.9296
Epoch 1/10, Batch 40/97, Loss: 0.7277
Epoch 1/10, Batch 50/97, Loss: 0.6681
Epoch 1/10, Batch 60/97, Loss: 0.5892
Epoch 1/10, Batch 70/97, Loss: 0.5091
Epoch 1/10, Batch 80/97, Loss: 0.4650
Epoch 1/10, Batch 90/97, Loss: 0.4838
Epoch 1/10, Train Loss: 0.7602, Valid Loss: 0.4556
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.2939
Epoch 2/10, Batch 20/97, Loss: 0.4748
Epoch 2/10, Batch 30/97, Loss: 0.3725
Epoch 2/10, Batch 40/97, Loss: 0.3430
Epoch 2/10, Batch 50/97, Loss: 0.5864
Epoch 2/10, Batch 60/97, Loss: 0.3369
Epoch 2/10, Batch 70/97, Loss: 0.3315
Epoch 2/10, Batch 80/97, Loss: 0.3806
Epoch 2/10, Batch 90/97, Loss: 0.2319
Epoch 2/10, Train Loss: 0.3858, Valid Loss: 0.3502
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3739
Epoch 3/10, Batch 20/97, Loss: 0.2764
Epoch 3/10, Batch 30/97, Loss: 0.2280
Epoch 3/10, Batch 40/97, Loss: 0.3468
Epoch 3/10, Batch 50/97, Loss: 0.2689
Epoch 3/10, Batch 60/97, Loss: 0.2325
Epoch 3/10, Batch 70/97, Loss: 0.1962
Epoch 3/10, Batch 80/97, Loss: 0.2819
Epoch 3/10, Batch 90/97, Loss: 0.3102
Epoch 3/10, Train Loss: 0.3117, Valid Loss: 0.3074
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1611
Epoch 4/10, Batch 20/97, Loss: 0.2141
Epoch 4/10, Batch 30/97, Loss: 0.2980
Epoch 4/10, Batch 40/97, Loss: 0.2583
Epoch 4/10, Batch 50/97, Loss: 0.1214
Epoch 4/10, Batch 60/97, Loss: 0.1858
Epoch 4/10, Batch 70/97, Loss: 0.2564
Epoch 4/10, Batch 80/97, Loss: 0.2235
Epoch 4/10, Batch 90/97, Loss: 0.2327
Epoch 4/10, Train Loss: 0.2777, Valid Loss: 0.2826
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2161
Epoch 5/10, Batch 20/97, Loss: 0.1636
Epoch 5/10, Batch 30/97, Loss: 0.1739
Epoch 5/10, Batch 40/97, Loss: 0.1253
Epoch 5/10, Batch 50/97, Loss: 0.2473
Epoch 5/10, Batch 60/97, Loss: 0.1914
Epoch 5/10, Batch 70/97, Loss: 0.1613
Epoch 5/10, Batch 80/97, Loss: 0.2231
Epoch 5/10, Batch 90/97, Loss: 0.2587
Epoch 5/10, Train Loss: 0.2396, Valid Loss: 0.2741
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3050
Epoch 6/10, Batch 20/97, Loss: 0.2451
Epoch 6/10, Batch 30/97, Loss: 0.1828
Epoch 6/10, Batch 40/97, Loss: 0.3120
Epoch 6/10, Batch 50/97, Loss: 0.2700
Epoch 6/10, Batch 60/97, Loss: 0.2243
Epoch 6/10, Batch 70/97, Loss: 0.2447
Epoch 6/10, Batch 80/97, Loss: 0.3524
Epoch 6/10, Batch 90/97, Loss: 0.1749
Epoch 6/10, Train Loss: 0.2296, Valid Loss: 0.2702
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2025
Epoch 7/10, Batch 20/97, Loss: 0.1099
Epoch 7/10, Batch 30/97, Loss: 0.1330
Epoch 7/10, Batch 40/97, Loss: 0.2052
Epoch 7/10, Batch 50/97, Loss: 0.1066
Epoch 7/10, Batch 60/97, Loss: 0.3467
Epoch 7/10, Batch 70/97, Loss: 0.1362
Epoch 7/10, Batch 80/97, Loss: 0.2023
Epoch 7/10, Batch 90/97, Loss: 0.2162
Epoch 7/10, Train Loss: 0.2283, Valid Loss: 0.2543
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1454
Epoch 8/10, Batch 20/97, Loss: 0.1436
Epoch 8/10, Batch 30/97, Loss: 0.2176
Epoch 8/10, Batch 40/97, Loss: 0.2276
Epoch 8/10, Batch 50/97, Loss: 0.2948
Epoch 8/10, Batch 60/97, Loss: 0.1193
Epoch 8/10, Batch 70/97, Loss: 0.3087
Epoch 8/10, Batch 80/97, Loss: 0.1631
Epoch 8/10, Batch 90/97, Loss: 0.1274
Epoch 8/10, Train Loss: 0.2090, Valid Loss: 0.2530
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1598
Epoch 9/10, Batch 20/97, Loss: 0.2378
Epoch 9/10, Batch 30/97, Loss: 0.2076
Epoch 9/10, Batch 40/97, Loss: 0.1162
Epoch 9/10, Batch 50/97, Loss: 0.2239
Epoch 9/10, Batch 60/97, Loss: 0.1679
Epoch 9/10, Batch 70/97, Loss: 0.2215
Epoch 9/10, Batch 80/97, Loss: 0.2556
Epoch 9/10, Batch 90/97, Loss: 0.3743
Epoch 9/10, Train Loss: 0.2006, Valid Loss: 0.2495
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2212
Epoch 10/10, Batch 20/97, Loss: 0.2835
Epoch 10/10, Batch 30/97, Loss: 0.1694
Epoch 10/10, Batch 40/97, Loss: 0.2121
Epoch 10/10, Batch 50/97, Loss: 0.2848
Epoch 10/10, Batch 60/97, Loss: 0.0556
Epoch 10/10, Batch 70/97, Loss: 0.3102
Epoch 10/10, Batch 80/97, Loss: 0.0922
Epoch 10/10, Batch 90/97, Loss: 0.1653
Epoch 10/10, Train Loss: 0.1870, Valid Loss: 0.2398
Model saved!
Accuracy: 0.9182
Precision: 0.9152
Recall: 0.9182
F1-score: 0.9159
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4866
Epoch 1/10, Batch 20/97, Loss: 1.0405
Epoch 1/10, Batch 30/97, Loss: 0.8423
Epoch 1/10, Batch 40/97, Loss: 0.7211
Epoch 1/10, Batch 50/97, Loss: 0.5759
Epoch 1/10, Batch 60/97, Loss: 0.7244
Epoch 1/10, Batch 70/97, Loss: 0.4921
Epoch 1/10, Batch 80/97, Loss: 0.4984
Epoch 1/10, Batch 90/97, Loss: 0.6421
Epoch 1/10, Train Loss: 0.7696, Valid Loss: 0.4246
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3350
Epoch 2/10, Batch 20/97, Loss: 0.4604
Epoch 2/10, Batch 30/97, Loss: 0.3880
Epoch 2/10, Batch 40/97, Loss: 0.5395
Epoch 2/10, Batch 50/97, Loss: 0.5400
Epoch 2/10, Batch 60/97, Loss: 0.2692
Epoch 2/10, Batch 70/97, Loss: 0.2712
Epoch 2/10, Batch 80/97, Loss: 0.3817
Epoch 2/10, Batch 90/97, Loss: 0.3105
Epoch 2/10, Train Loss: 0.3955, Valid Loss: 0.3118
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2805
Epoch 3/10, Batch 20/97, Loss: 0.2458
Epoch 3/10, Batch 30/97, Loss: 0.2589
Epoch 3/10, Batch 40/97, Loss: 0.2046
Epoch 3/10, Batch 50/97, Loss: 0.1750
Epoch 3/10, Batch 60/97, Loss: 0.3941
Epoch 3/10, Batch 70/97, Loss: 0.2944
Epoch 3/10, Batch 80/97, Loss: 0.3431
Epoch 3/10, Batch 90/97, Loss: 0.3397
Epoch 3/10, Train Loss: 0.3199, Valid Loss: 0.2729
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3531
Epoch 4/10, Batch 20/97, Loss: 0.2306
Epoch 4/10, Batch 30/97, Loss: 0.2248
Epoch 4/10, Batch 40/97, Loss: 0.2462
Epoch 4/10, Batch 50/97, Loss: 0.1962
Epoch 4/10, Batch 60/97, Loss: 0.1825
Epoch 4/10, Batch 70/97, Loss: 0.2772
Epoch 4/10, Batch 80/97, Loss: 0.2948
Epoch 4/10, Batch 90/97, Loss: 0.3009
Epoch 4/10, Train Loss: 0.2789, Valid Loss: 0.2511
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2275
Epoch 5/10, Batch 20/97, Loss: 0.1988
Epoch 5/10, Batch 30/97, Loss: 0.2150
Epoch 5/10, Batch 40/97, Loss: 0.2167
Epoch 5/10, Batch 50/97, Loss: 0.2996
Epoch 5/10, Batch 60/97, Loss: 0.2793
Epoch 5/10, Batch 70/97, Loss: 0.2420
Epoch 5/10, Batch 80/97, Loss: 0.2821
Epoch 5/10, Batch 90/97, Loss: 0.2952
Epoch 5/10, Train Loss: 0.2558, Valid Loss: 0.2397
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2122
Epoch 6/10, Batch 20/97, Loss: 0.1543
Epoch 6/10, Batch 30/97, Loss: 0.2345
Epoch 6/10, Batch 40/97, Loss: 0.1899
Epoch 6/10, Batch 50/97, Loss: 0.1547
Epoch 6/10, Batch 60/97, Loss: 0.1681
Epoch 6/10, Batch 70/97, Loss: 0.1919
Epoch 6/10, Batch 80/97, Loss: 0.1645
Epoch 6/10, Batch 90/97, Loss: 0.1767
Epoch 6/10, Train Loss: 0.2255, Valid Loss: 0.2303
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2820
Epoch 7/10, Batch 20/97, Loss: 0.1902
Epoch 7/10, Batch 30/97, Loss: 0.2514
Epoch 7/10, Batch 40/97, Loss: 0.1383
Epoch 7/10, Batch 50/97, Loss: 0.2724
Epoch 7/10, Batch 60/97, Loss: 0.2434
Epoch 7/10, Batch 70/97, Loss: 0.1721
Epoch 7/10, Batch 80/97, Loss: 0.2169
Epoch 7/10, Batch 90/97, Loss: 0.1334
Epoch 7/10, Train Loss: 0.2369, Valid Loss: 0.2276
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.0988
Epoch 8/10, Batch 20/97, Loss: 0.1292
Epoch 8/10, Batch 30/97, Loss: 0.0841
Epoch 8/10, Batch 40/97, Loss: 0.1822
Epoch 8/10, Batch 50/97, Loss: 0.2381
Epoch 8/10, Batch 60/97, Loss: 0.2040
Epoch 8/10, Batch 70/97, Loss: 0.2450
Epoch 8/10, Batch 80/97, Loss: 0.1067
Epoch 8/10, Batch 90/97, Loss: 0.1213
Epoch 8/10, Train Loss: 0.2149, Valid Loss: 0.2173
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1934
Epoch 9/10, Batch 20/97, Loss: 0.1074
Epoch 9/10, Batch 30/97, Loss: 0.3229
Epoch 9/10, Batch 40/97, Loss: 0.1379
Epoch 9/10, Batch 50/97, Loss: 0.3167
Epoch 9/10, Batch 60/97, Loss: 0.0974
Epoch 9/10, Batch 70/97, Loss: 0.3642
Epoch 9/10, Batch 80/97, Loss: 0.1174
Epoch 9/10, Batch 90/97, Loss: 0.1151
Epoch 9/10, Train Loss: 0.2012, Valid Loss: 0.2145
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.3147
Epoch 10/10, Batch 20/97, Loss: 0.1110
Epoch 10/10, Batch 30/97, Loss: 0.1506
Epoch 10/10, Batch 40/97, Loss: 0.1032
Epoch 10/10, Batch 50/97, Loss: 0.2728
Epoch 10/10, Batch 60/97, Loss: 0.0739
Epoch 10/10, Batch 70/97, Loss: 0.1608
Epoch 10/10, Batch 80/97, Loss: 0.1897
Epoch 10/10, Batch 90/97, Loss: 0.2281
Epoch 10/10, Train Loss: 0.1993, Valid Loss: 0.2117
Model saved!
Accuracy: 0.9136
Precision: 0.9104
Recall: 0.9136
F1-score: 0.9112
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4564
Epoch 1/10, Batch 20/97, Loss: 1.0394
Epoch 1/10, Batch 30/97, Loss: 0.8739
Epoch 1/10, Batch 40/97, Loss: 0.7275
Epoch 1/10, Batch 50/97, Loss: 0.5479
Epoch 1/10, Batch 60/97, Loss: 0.5857
Epoch 1/10, Batch 70/97, Loss: 0.4697
Epoch 1/10, Batch 80/97, Loss: 0.3539
Epoch 1/10, Batch 90/97, Loss: 0.5656
Epoch 1/10, Train Loss: 0.7702, Valid Loss: 0.4074
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4654
Epoch 2/10, Batch 20/97, Loss: 0.3939
Epoch 2/10, Batch 30/97, Loss: 0.2850
Epoch 2/10, Batch 40/97, Loss: 0.3519
Epoch 2/10, Batch 50/97, Loss: 0.5602
Epoch 2/10, Batch 60/97, Loss: 0.4935
Epoch 2/10, Batch 70/97, Loss: 0.3121
Epoch 2/10, Batch 80/97, Loss: 0.3469
Epoch 2/10, Batch 90/97, Loss: 0.3643
Epoch 2/10, Train Loss: 0.3858, Valid Loss: 0.3137
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2806
Epoch 3/10, Batch 20/97, Loss: 0.3181
Epoch 3/10, Batch 30/97, Loss: 0.1574
Epoch 3/10, Batch 40/97, Loss: 0.3023
Epoch 3/10, Batch 50/97, Loss: 0.4011
Epoch 3/10, Batch 60/97, Loss: 0.1932
Epoch 3/10, Batch 70/97, Loss: 0.3119
Epoch 3/10, Batch 80/97, Loss: 0.3338
Epoch 3/10, Batch 90/97, Loss: 0.3959
Epoch 3/10, Train Loss: 0.3173, Valid Loss: 0.2717
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2771
Epoch 4/10, Batch 20/97, Loss: 0.2139
Epoch 4/10, Batch 30/97, Loss: 0.2410
Epoch 4/10, Batch 40/97, Loss: 0.3441
Epoch 4/10, Batch 50/97, Loss: 0.1492
Epoch 4/10, Batch 60/97, Loss: 0.1978
Epoch 4/10, Batch 70/97, Loss: 0.1978
Epoch 4/10, Batch 80/97, Loss: 0.2736
Epoch 4/10, Batch 90/97, Loss: 0.2833
Epoch 4/10, Train Loss: 0.2732, Valid Loss: 0.2562
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2321
Epoch 5/10, Batch 20/97, Loss: 0.2968
Epoch 5/10, Batch 30/97, Loss: 0.1269
Epoch 5/10, Batch 40/97, Loss: 0.1409
Epoch 5/10, Batch 50/97, Loss: 0.1621
Epoch 5/10, Batch 60/97, Loss: 0.1270
Epoch 5/10, Batch 70/97, Loss: 0.2755
Epoch 5/10, Batch 80/97, Loss: 0.4809
Epoch 5/10, Batch 90/97, Loss: 0.3104
Epoch 5/10, Train Loss: 0.2464, Valid Loss: 0.2434
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.4960
Epoch 6/10, Batch 20/97, Loss: 0.1415
Epoch 6/10, Batch 30/97, Loss: 0.2744
Epoch 6/10, Batch 40/97, Loss: 0.2620
Epoch 6/10, Batch 50/97, Loss: 0.1890
Epoch 6/10, Batch 60/97, Loss: 0.2140
Epoch 6/10, Batch 70/97, Loss: 0.2292
Epoch 6/10, Batch 80/97, Loss: 0.3081
Epoch 6/10, Batch 90/97, Loss: 0.2382
Epoch 6/10, Train Loss: 0.2307, Valid Loss: 0.2362
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4137
Epoch 7/10, Batch 20/97, Loss: 0.1174
Epoch 7/10, Batch 30/97, Loss: 0.1177
Epoch 7/10, Batch 40/97, Loss: 0.2044
Epoch 7/10, Batch 50/97, Loss: 0.2206
Epoch 7/10, Batch 60/97, Loss: 0.2605
Epoch 7/10, Batch 70/97, Loss: 0.2316
Epoch 7/10, Batch 80/97, Loss: 0.1823
Epoch 7/10, Batch 90/97, Loss: 0.1898
Epoch 7/10, Train Loss: 0.2327, Valid Loss: 0.2273
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2551
Epoch 8/10, Batch 20/97, Loss: 0.1056
Epoch 8/10, Batch 30/97, Loss: 0.0697
Epoch 8/10, Batch 40/97, Loss: 0.2048
Epoch 8/10, Batch 50/97, Loss: 0.1599
Epoch 8/10, Batch 60/97, Loss: 0.3031
Epoch 8/10, Batch 70/97, Loss: 0.3557
Epoch 8/10, Batch 80/97, Loss: 0.0907
Epoch 8/10, Batch 90/97, Loss: 0.1084
Epoch 8/10, Train Loss: 0.2074, Valid Loss: 0.2232
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1358
Epoch 9/10, Batch 20/97, Loss: 0.0952
Epoch 9/10, Batch 30/97, Loss: 0.1629
Epoch 9/10, Batch 40/97, Loss: 0.1449
Epoch 9/10, Batch 50/97, Loss: 0.1409
Epoch 9/10, Batch 60/97, Loss: 0.1435
Epoch 9/10, Batch 70/97, Loss: 0.3061
Epoch 9/10, Batch 80/97, Loss: 0.1989
Epoch 9/10, Batch 90/97, Loss: 0.2286
Epoch 9/10, Train Loss: 0.2006, Valid Loss: 0.2217
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2018
Epoch 10/10, Batch 20/97, Loss: 0.2166
Epoch 10/10, Batch 30/97, Loss: 0.1970
Epoch 10/10, Batch 40/97, Loss: 0.2888
Epoch 10/10, Batch 50/97, Loss: 0.2874
Epoch 10/10, Batch 60/97, Loss: 0.1364
Epoch 10/10, Batch 70/97, Loss: 0.1931
Epoch 10/10, Batch 80/97, Loss: 0.2018
Epoch 10/10, Batch 90/97, Loss: 0.1612
Epoch 10/10, Train Loss: 0.1842, Valid Loss: 0.2119
Model saved!
Accuracy: 0.9206
Precision: 0.9182
Recall: 0.9206
F1-score: 0.9187
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4578
Epoch 1/10, Batch 20/97, Loss: 0.9988
Epoch 1/10, Batch 30/97, Loss: 0.8610
Epoch 1/10, Batch 40/97, Loss: 0.7297
Epoch 1/10, Batch 50/97, Loss: 0.6064
Epoch 1/10, Batch 60/97, Loss: 0.7163
Epoch 1/10, Batch 70/97, Loss: 0.5412
Epoch 1/10, Batch 80/97, Loss: 0.4473
Epoch 1/10, Batch 90/97, Loss: 0.4224
Epoch 1/10, Train Loss: 0.7783, Valid Loss: 0.4302
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4227
Epoch 2/10, Batch 20/97, Loss: 0.4336
Epoch 2/10, Batch 30/97, Loss: 0.3632
Epoch 2/10, Batch 40/97, Loss: 0.4239
Epoch 2/10, Batch 50/97, Loss: 0.5818
Epoch 2/10, Batch 60/97, Loss: 0.4159
Epoch 2/10, Batch 70/97, Loss: 0.3584
Epoch 2/10, Batch 80/97, Loss: 0.2143
Epoch 2/10, Batch 90/97, Loss: 0.2256
Epoch 2/10, Train Loss: 0.3970, Valid Loss: 0.3187
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4034
Epoch 3/10, Batch 20/97, Loss: 0.2873
Epoch 3/10, Batch 30/97, Loss: 0.3450
Epoch 3/10, Batch 40/97, Loss: 0.3270
Epoch 3/10, Batch 50/97, Loss: 0.2761
Epoch 3/10, Batch 60/97, Loss: 0.3013
Epoch 3/10, Batch 70/97, Loss: 0.1803
Epoch 3/10, Batch 80/97, Loss: 0.4206
Epoch 3/10, Batch 90/97, Loss: 0.2826
Epoch 3/10, Train Loss: 0.3247, Valid Loss: 0.2806
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3542
Epoch 4/10, Batch 20/97, Loss: 0.2955
Epoch 4/10, Batch 30/97, Loss: 0.3689
Epoch 4/10, Batch 40/97, Loss: 0.2674
Epoch 4/10, Batch 50/97, Loss: 0.2112
Epoch 4/10, Batch 60/97, Loss: 0.3887
Epoch 4/10, Batch 70/97, Loss: 0.2625
Epoch 4/10, Batch 80/97, Loss: 0.2385
Epoch 4/10, Batch 90/97, Loss: 0.4118
Epoch 4/10, Train Loss: 0.2925, Valid Loss: 0.2574
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3915
Epoch 5/10, Batch 20/97, Loss: 0.2676
Epoch 5/10, Batch 30/97, Loss: 0.2217
Epoch 5/10, Batch 40/97, Loss: 0.3332
Epoch 5/10, Batch 50/97, Loss: 0.1962
Epoch 5/10, Batch 60/97, Loss: 0.1362
Epoch 5/10, Batch 70/97, Loss: 0.2589
Epoch 5/10, Batch 80/97, Loss: 0.2192
Epoch 5/10, Batch 90/97, Loss: 0.3433
Epoch 5/10, Train Loss: 0.2527, Valid Loss: 0.2499
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2476
Epoch 6/10, Batch 20/97, Loss: 0.2706
Epoch 6/10, Batch 30/97, Loss: 0.2379
Epoch 6/10, Batch 40/97, Loss: 0.2204
Epoch 6/10, Batch 50/97, Loss: 0.3093
Epoch 6/10, Batch 60/97, Loss: 0.1490
Epoch 6/10, Batch 70/97, Loss: 0.2945
Epoch 6/10, Batch 80/97, Loss: 0.1347
Epoch 6/10, Batch 90/97, Loss: 0.1805
Epoch 6/10, Train Loss: 0.2407, Valid Loss: 0.2326
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4024
Epoch 7/10, Batch 20/97, Loss: 0.4106
Epoch 7/10, Batch 30/97, Loss: 0.0874
Epoch 7/10, Batch 40/97, Loss: 0.1768
Epoch 7/10, Batch 50/97, Loss: 0.1233
Epoch 7/10, Batch 60/97, Loss: 0.1456
Epoch 7/10, Batch 70/97, Loss: 0.2804
Epoch 7/10, Batch 80/97, Loss: 0.1273
Epoch 7/10, Batch 90/97, Loss: 0.2042
Epoch 7/10, Train Loss: 0.2381, Valid Loss: 0.2256
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2399
Epoch 8/10, Batch 20/97, Loss: 0.2705
Epoch 8/10, Batch 30/97, Loss: 0.0947
Epoch 8/10, Batch 40/97, Loss: 0.1733
Epoch 8/10, Batch 50/97, Loss: 0.2483
Epoch 8/10, Batch 60/97, Loss: 0.2337
Epoch 8/10, Batch 70/97, Loss: 0.2025
Epoch 8/10, Batch 80/97, Loss: 0.1517
Epoch 8/10, Batch 90/97, Loss: 0.2158
Epoch 8/10, Train Loss: 0.2225, Valid Loss: 0.2185
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1580
Epoch 9/10, Batch 20/97, Loss: 0.1218
Epoch 9/10, Batch 30/97, Loss: 0.3138
Epoch 9/10, Batch 40/97, Loss: 0.1600
Epoch 9/10, Batch 50/97, Loss: 0.2000
Epoch 9/10, Batch 60/97, Loss: 0.1921
Epoch 9/10, Batch 70/97, Loss: 0.2329
Epoch 9/10, Batch 80/97, Loss: 0.2084
Epoch 9/10, Batch 90/97, Loss: 0.1633
Epoch 9/10, Train Loss: 0.2168, Valid Loss: 0.2247
Epoch 10/10, Batch 10/97, Loss: 0.1984
Epoch 10/10, Batch 20/97, Loss: 0.1619
Epoch 10/10, Batch 30/97, Loss: 0.1617
Epoch 10/10, Batch 40/97, Loss: 0.1863
Epoch 10/10, Batch 50/97, Loss: 0.2831
Epoch 10/10, Batch 60/97, Loss: 0.1565
Epoch 10/10, Batch 70/97, Loss: 0.3603
Epoch 10/10, Batch 80/97, Loss: 0.2124
Epoch 10/10, Batch 90/97, Loss: 0.1418
Epoch 10/10, Train Loss: 0.2002, Valid Loss: 0.2127
Model saved!
Accuracy: 0.9182
Precision: 0.9172
Recall: 0.9182
F1-score: 0.9172
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4428
Epoch 1/10, Batch 20/97, Loss: 1.0039
Epoch 1/10, Batch 30/97, Loss: 0.8542
Epoch 1/10, Batch 40/97, Loss: 0.7928
Epoch 1/10, Batch 50/97, Loss: 0.5129
Epoch 1/10, Batch 60/97, Loss: 0.5515
Epoch 1/10, Batch 70/97, Loss: 0.4494
Epoch 1/10, Batch 80/97, Loss: 0.5562
Epoch 1/10, Batch 90/97, Loss: 0.4874
Epoch 1/10, Train Loss: 0.7757, Valid Loss: 0.4168
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3726
Epoch 2/10, Batch 20/97, Loss: 0.5493
Epoch 2/10, Batch 30/97, Loss: 0.3672
Epoch 2/10, Batch 40/97, Loss: 0.2869
Epoch 2/10, Batch 50/97, Loss: 0.3771
Epoch 2/10, Batch 60/97, Loss: 0.3655
Epoch 2/10, Batch 70/97, Loss: 0.3744
Epoch 2/10, Batch 80/97, Loss: 0.3212
Epoch 2/10, Batch 90/97, Loss: 0.3829
Epoch 2/10, Train Loss: 0.4023, Valid Loss: 0.3037
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3232
Epoch 3/10, Batch 20/97, Loss: 0.3823
Epoch 3/10, Batch 30/97, Loss: 0.3188
Epoch 3/10, Batch 40/97, Loss: 0.2316
Epoch 3/10, Batch 50/97, Loss: 0.4143
Epoch 3/10, Batch 60/97, Loss: 0.2947
Epoch 3/10, Batch 70/97, Loss: 0.1744
Epoch 3/10, Batch 80/97, Loss: 0.2975
Epoch 3/10, Batch 90/97, Loss: 0.1817
Epoch 3/10, Train Loss: 0.3290, Valid Loss: 0.2616
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3214
Epoch 4/10, Batch 20/97, Loss: 0.1556
Epoch 4/10, Batch 30/97, Loss: 0.4087
Epoch 4/10, Batch 40/97, Loss: 0.2826
Epoch 4/10, Batch 50/97, Loss: 0.2152
Epoch 4/10, Batch 60/97, Loss: 0.1422
Epoch 4/10, Batch 70/97, Loss: 0.2495
Epoch 4/10, Batch 80/97, Loss: 0.2675
Epoch 4/10, Batch 90/97, Loss: 0.2586
Epoch 4/10, Train Loss: 0.2997, Valid Loss: 0.2358
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3109
Epoch 5/10, Batch 20/97, Loss: 0.3356
Epoch 5/10, Batch 30/97, Loss: 0.2624
Epoch 5/10, Batch 40/97, Loss: 0.1257
Epoch 5/10, Batch 50/97, Loss: 0.2476
Epoch 5/10, Batch 60/97, Loss: 0.1651
Epoch 5/10, Batch 70/97, Loss: 0.2114
Epoch 5/10, Batch 80/97, Loss: 0.2482
Epoch 5/10, Batch 90/97, Loss: 0.3835
Epoch 5/10, Train Loss: 0.2533, Valid Loss: 0.2178
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2483
Epoch 6/10, Batch 20/97, Loss: 0.1482
Epoch 6/10, Batch 30/97, Loss: 0.2632
Epoch 6/10, Batch 40/97, Loss: 0.2982
Epoch 6/10, Batch 50/97, Loss: 0.2042
Epoch 6/10, Batch 60/97, Loss: 0.2026
Epoch 6/10, Batch 70/97, Loss: 0.2939
Epoch 6/10, Batch 80/97, Loss: 0.1862
Epoch 6/10, Batch 90/97, Loss: 0.2219
Epoch 6/10, Train Loss: 0.2462, Valid Loss: 0.2099
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4358
Epoch 7/10, Batch 20/97, Loss: 0.2198
Epoch 7/10, Batch 30/97, Loss: 0.1390
Epoch 7/10, Batch 40/97, Loss: 0.2093
Epoch 7/10, Batch 50/97, Loss: 0.1676
Epoch 7/10, Batch 60/97, Loss: 0.3637
Epoch 7/10, Batch 70/97, Loss: 0.3340
Epoch 7/10, Batch 80/97, Loss: 0.1850
Epoch 7/10, Batch 90/97, Loss: 0.3577
Epoch 7/10, Train Loss: 0.2492, Valid Loss: 0.2020
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2629
Epoch 8/10, Batch 20/97, Loss: 0.1784
Epoch 8/10, Batch 30/97, Loss: 0.2055
Epoch 8/10, Batch 40/97, Loss: 0.2827
Epoch 8/10, Batch 50/97, Loss: 0.1881
Epoch 8/10, Batch 60/97, Loss: 0.1377
Epoch 8/10, Batch 70/97, Loss: 0.2616
Epoch 8/10, Batch 80/97, Loss: 0.2042
Epoch 8/10, Batch 90/97, Loss: 0.2839
Epoch 8/10, Train Loss: 0.2222, Valid Loss: 0.2036
Epoch 9/10, Batch 10/97, Loss: 0.0627
Epoch 9/10, Batch 20/97, Loss: 0.0965
Epoch 9/10, Batch 30/97, Loss: 0.3518
Epoch 9/10, Batch 40/97, Loss: 0.1685
Epoch 9/10, Batch 50/97, Loss: 0.2681
Epoch 9/10, Batch 60/97, Loss: 0.1360
Epoch 9/10, Batch 70/97, Loss: 0.2457
Epoch 9/10, Batch 80/97, Loss: 0.1534
Epoch 9/10, Batch 90/97, Loss: 0.2980
Epoch 9/10, Train Loss: 0.2115, Valid Loss: 0.1970
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2385
Epoch 10/10, Batch 20/97, Loss: 0.3002
Epoch 10/10, Batch 30/97, Loss: 0.1339
Epoch 10/10, Batch 40/97, Loss: 0.5262
Epoch 10/10, Batch 50/97, Loss: 0.2685
Epoch 10/10, Batch 60/97, Loss: 0.0817
Epoch 10/10, Batch 70/97, Loss: 0.1943
Epoch 10/10, Batch 80/97, Loss: 0.1596
Epoch 10/10, Batch 90/97, Loss: 0.1412
Epoch 10/10, Train Loss: 0.2025, Valid Loss: 0.1899
Model saved!
Accuracy: 0.9182
Precision: 0.9169
Recall: 0.9182
F1-score: 0.9167
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4743
Epoch 1/10, Batch 20/97, Loss: 1.0635
Epoch 1/10, Batch 30/97, Loss: 0.8948
Epoch 1/10, Batch 40/97, Loss: 0.7428
Epoch 1/10, Batch 50/97, Loss: 0.7327
Epoch 1/10, Batch 60/97, Loss: 0.5973
Epoch 1/10, Batch 70/97, Loss: 0.4900
Epoch 1/10, Batch 80/97, Loss: 0.4896
Epoch 1/10, Batch 90/97, Loss: 0.5571
Epoch 1/10, Train Loss: 0.7904, Valid Loss: 0.4404
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3847
Epoch 2/10, Batch 20/97, Loss: 0.4609
Epoch 2/10, Batch 30/97, Loss: 0.4876
Epoch 2/10, Batch 40/97, Loss: 0.5008
Epoch 2/10, Batch 50/97, Loss: 0.4899
Epoch 2/10, Batch 60/97, Loss: 0.3688
Epoch 2/10, Batch 70/97, Loss: 0.2795
Epoch 2/10, Batch 80/97, Loss: 0.2325
Epoch 2/10, Batch 90/97, Loss: 0.4203
Epoch 2/10, Train Loss: 0.4006, Valid Loss: 0.3353
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2544
Epoch 3/10, Batch 20/97, Loss: 0.3540
Epoch 3/10, Batch 30/97, Loss: 0.2768
Epoch 3/10, Batch 40/97, Loss: 0.2868
Epoch 3/10, Batch 50/97, Loss: 0.2515
Epoch 3/10, Batch 60/97, Loss: 0.1973
Epoch 3/10, Batch 70/97, Loss: 0.3256
Epoch 3/10, Batch 80/97, Loss: 0.4713
Epoch 3/10, Batch 90/97, Loss: 0.3573
Epoch 3/10, Train Loss: 0.3314, Valid Loss: 0.2952
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2345
Epoch 4/10, Batch 20/97, Loss: 0.3881
Epoch 4/10, Batch 30/97, Loss: 0.4043
Epoch 4/10, Batch 40/97, Loss: 0.3413
Epoch 4/10, Batch 50/97, Loss: 0.1876
Epoch 4/10, Batch 60/97, Loss: 0.1327
Epoch 4/10, Batch 70/97, Loss: 0.3099
Epoch 4/10, Batch 80/97, Loss: 0.2309
Epoch 4/10, Batch 90/97, Loss: 0.2970
Epoch 4/10, Train Loss: 0.2941, Valid Loss: 0.2750
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3542
Epoch 5/10, Batch 20/97, Loss: 0.2224
Epoch 5/10, Batch 30/97, Loss: 0.1863
Epoch 5/10, Batch 40/97, Loss: 0.1700
Epoch 5/10, Batch 50/97, Loss: 0.1475
Epoch 5/10, Batch 60/97, Loss: 0.2508
Epoch 5/10, Batch 70/97, Loss: 0.2287
Epoch 5/10, Batch 80/97, Loss: 0.1997
Epoch 5/10, Batch 90/97, Loss: 0.3034
Epoch 5/10, Train Loss: 0.2644, Valid Loss: 0.2571
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3447
Epoch 6/10, Batch 20/97, Loss: 0.3546
Epoch 6/10, Batch 30/97, Loss: 0.1284
Epoch 6/10, Batch 40/97, Loss: 0.3446
Epoch 6/10, Batch 50/97, Loss: 0.2512
Epoch 6/10, Batch 60/97, Loss: 0.4018
Epoch 6/10, Batch 70/97, Loss: 0.3772
Epoch 6/10, Batch 80/97, Loss: 0.1575
Epoch 6/10, Batch 90/97, Loss: 0.2365
Epoch 6/10, Train Loss: 0.2498, Valid Loss: 0.2557
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2714
Epoch 7/10, Batch 20/97, Loss: 0.1865
Epoch 7/10, Batch 30/97, Loss: 0.1596
Epoch 7/10, Batch 40/97, Loss: 0.2569
Epoch 7/10, Batch 50/97, Loss: 0.2974
Epoch 7/10, Batch 60/97, Loss: 0.3340
Epoch 7/10, Batch 70/97, Loss: 0.3331
Epoch 7/10, Batch 80/97, Loss: 0.2346
Epoch 7/10, Batch 90/97, Loss: 0.1404
Epoch 7/10, Train Loss: 0.2533, Valid Loss: 0.2420
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1615
Epoch 8/10, Batch 20/97, Loss: 0.1390
Epoch 8/10, Batch 30/97, Loss: 0.1401
Epoch 8/10, Batch 40/97, Loss: 0.0902
Epoch 8/10, Batch 50/97, Loss: 0.2253
Epoch 8/10, Batch 60/97, Loss: 0.1539
Epoch 8/10, Batch 70/97, Loss: 0.2480
Epoch 8/10, Batch 80/97, Loss: 0.3134
Epoch 8/10, Batch 90/97, Loss: 0.1690
Epoch 8/10, Train Loss: 0.2285, Valid Loss: 0.2399
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2581
Epoch 9/10, Batch 20/97, Loss: 0.2050
Epoch 9/10, Batch 30/97, Loss: 0.1921
Epoch 9/10, Batch 40/97, Loss: 0.2512
Epoch 9/10, Batch 50/97, Loss: 0.2809
Epoch 9/10, Batch 60/97, Loss: 0.1734
Epoch 9/10, Batch 70/97, Loss: 0.1238
Epoch 9/10, Batch 80/97, Loss: 0.1808
Epoch 9/10, Batch 90/97, Loss: 0.1638
Epoch 9/10, Train Loss: 0.2136, Valid Loss: 0.2430
Epoch 10/10, Batch 10/97, Loss: 0.2181
Epoch 10/10, Batch 20/97, Loss: 0.2565
Epoch 10/10, Batch 30/97, Loss: 0.1825
Epoch 10/10, Batch 40/97, Loss: 0.2904
Epoch 10/10, Batch 50/97, Loss: 0.3125
Epoch 10/10, Batch 60/97, Loss: 0.1363
Epoch 10/10, Batch 70/97, Loss: 0.1072
Epoch 10/10, Batch 80/97, Loss: 0.2261
Epoch 10/10, Batch 90/97, Loss: 0.2532
Epoch 10/10, Train Loss: 0.2039, Valid Loss: 0.2396
Model saved!
Accuracy: 0.9147
Precision: 0.9120
Recall: 0.9147
F1-score: 0.9121
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5286
Epoch 1/10, Batch 20/97, Loss: 1.0370
Epoch 1/10, Batch 30/97, Loss: 0.8613
Epoch 1/10, Batch 40/97, Loss: 0.7599
Epoch 1/10, Batch 50/97, Loss: 0.6260
Epoch 1/10, Batch 60/97, Loss: 0.5401
Epoch 1/10, Batch 70/97, Loss: 0.6403
Epoch 1/10, Batch 80/97, Loss: 0.3934
Epoch 1/10, Batch 90/97, Loss: 0.4651
Epoch 1/10, Train Loss: 0.7756, Valid Loss: 0.4269
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4220
Epoch 2/10, Batch 20/97, Loss: 0.6231
Epoch 2/10, Batch 30/97, Loss: 0.4894
Epoch 2/10, Batch 40/97, Loss: 0.3821
Epoch 2/10, Batch 50/97, Loss: 0.6409
Epoch 2/10, Batch 60/97, Loss: 0.2869
Epoch 2/10, Batch 70/97, Loss: 0.2857
Epoch 2/10, Batch 80/97, Loss: 0.2818
Epoch 2/10, Batch 90/97, Loss: 0.3379
Epoch 2/10, Train Loss: 0.3987, Valid Loss: 0.3269
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2731
Epoch 3/10, Batch 20/97, Loss: 0.2634
Epoch 3/10, Batch 30/97, Loss: 0.3196
Epoch 3/10, Batch 40/97, Loss: 0.2860
Epoch 3/10, Batch 50/97, Loss: 0.2435
Epoch 3/10, Batch 60/97, Loss: 0.1373
Epoch 3/10, Batch 70/97, Loss: 0.2487
Epoch 3/10, Batch 80/97, Loss: 0.4343
Epoch 3/10, Batch 90/97, Loss: 0.1870
Epoch 3/10, Train Loss: 0.3247, Valid Loss: 0.2934
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3558
Epoch 4/10, Batch 20/97, Loss: 0.2936
Epoch 4/10, Batch 30/97, Loss: 0.2274
Epoch 4/10, Batch 40/97, Loss: 0.3248
Epoch 4/10, Batch 50/97, Loss: 0.2910
Epoch 4/10, Batch 60/97, Loss: 0.1580
Epoch 4/10, Batch 70/97, Loss: 0.2714
Epoch 4/10, Batch 80/97, Loss: 0.3899
Epoch 4/10, Batch 90/97, Loss: 0.1497
Epoch 4/10, Train Loss: 0.2912, Valid Loss: 0.2658
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3324
Epoch 5/10, Batch 20/97, Loss: 0.1678
Epoch 5/10, Batch 30/97, Loss: 0.1633
Epoch 5/10, Batch 40/97, Loss: 0.2913
Epoch 5/10, Batch 50/97, Loss: 0.2515
Epoch 5/10, Batch 60/97, Loss: 0.2807
Epoch 5/10, Batch 70/97, Loss: 0.2219
Epoch 5/10, Batch 80/97, Loss: 0.2104
Epoch 5/10, Batch 90/97, Loss: 0.4412
Epoch 5/10, Train Loss: 0.2624, Valid Loss: 0.2549
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1574
Epoch 6/10, Batch 20/97, Loss: 0.2434
Epoch 6/10, Batch 30/97, Loss: 0.2190
Epoch 6/10, Batch 40/97, Loss: 0.2874
Epoch 6/10, Batch 50/97, Loss: 0.2567
Epoch 6/10, Batch 60/97, Loss: 0.3185
Epoch 6/10, Batch 70/97, Loss: 0.2959
Epoch 6/10, Batch 80/97, Loss: 0.1461
Epoch 6/10, Batch 90/97, Loss: 0.3846
Epoch 6/10, Train Loss: 0.2365, Valid Loss: 0.2432
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.4239
Epoch 7/10, Batch 20/97, Loss: 0.2698
Epoch 7/10, Batch 30/97, Loss: 0.1583
Epoch 7/10, Batch 40/97, Loss: 0.2265
Epoch 7/10, Batch 50/97, Loss: 0.2356
Epoch 7/10, Batch 60/97, Loss: 0.2470
Epoch 7/10, Batch 70/97, Loss: 0.2493
Epoch 7/10, Batch 80/97, Loss: 0.1782
Epoch 7/10, Batch 90/97, Loss: 0.1306
Epoch 7/10, Train Loss: 0.2484, Valid Loss: 0.2333
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1583
Epoch 8/10, Batch 20/97, Loss: 0.1498
Epoch 8/10, Batch 30/97, Loss: 0.1440
Epoch 8/10, Batch 40/97, Loss: 0.3669
Epoch 8/10, Batch 50/97, Loss: 0.3236
Epoch 8/10, Batch 60/97, Loss: 0.2175
Epoch 8/10, Batch 70/97, Loss: 0.1758
Epoch 8/10, Batch 80/97, Loss: 0.1854
Epoch 8/10, Batch 90/97, Loss: 0.1839
Epoch 8/10, Train Loss: 0.2176, Valid Loss: 0.2251
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2177
Epoch 9/10, Batch 20/97, Loss: 0.0923
Epoch 9/10, Batch 30/97, Loss: 0.3011
Epoch 9/10, Batch 40/97, Loss: 0.1937
Epoch 9/10, Batch 50/97, Loss: 0.2876
Epoch 9/10, Batch 60/97, Loss: 0.2052
Epoch 9/10, Batch 70/97, Loss: 0.1409
Epoch 9/10, Batch 80/97, Loss: 0.2900
Epoch 9/10, Batch 90/97, Loss: 0.2734
Epoch 9/10, Train Loss: 0.2044, Valid Loss: 0.2249
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1369
Epoch 10/10, Batch 20/97, Loss: 0.0636
Epoch 10/10, Batch 30/97, Loss: 0.2164
Epoch 10/10, Batch 40/97, Loss: 0.2679
Epoch 10/10, Batch 50/97, Loss: 0.3535
Epoch 10/10, Batch 60/97, Loss: 0.1472
Epoch 10/10, Batch 70/97, Loss: 0.3167
Epoch 10/10, Batch 80/97, Loss: 0.1029
Epoch 10/10, Batch 90/97, Loss: 0.1439
Epoch 10/10, Train Loss: 0.1936, Valid Loss: 0.2131
Model saved!
Accuracy: 0.9217
Precision: 0.9197
Recall: 0.9217
F1-score: 0.9203
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5011
Epoch 1/10, Batch 20/97, Loss: 0.9694
Epoch 1/10, Batch 30/97, Loss: 0.9387
Epoch 1/10, Batch 40/97, Loss: 0.6979
Epoch 1/10, Batch 50/97, Loss: 0.7192
Epoch 1/10, Batch 60/97, Loss: 0.6179
Epoch 1/10, Batch 70/97, Loss: 0.4932
Epoch 1/10, Batch 80/97, Loss: 0.4391
Epoch 1/10, Batch 90/97, Loss: 0.5258
Epoch 1/10, Train Loss: 0.7758, Valid Loss: 0.4616
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4075
Epoch 2/10, Batch 20/97, Loss: 0.5022
Epoch 2/10, Batch 30/97, Loss: 0.3313
Epoch 2/10, Batch 40/97, Loss: 0.5455
Epoch 2/10, Batch 50/97, Loss: 0.6424
Epoch 2/10, Batch 60/97, Loss: 0.2977
Epoch 2/10, Batch 70/97, Loss: 0.3138
Epoch 2/10, Batch 80/97, Loss: 0.2547
Epoch 2/10, Batch 90/97, Loss: 0.3338
Epoch 2/10, Train Loss: 0.4051, Valid Loss: 0.3616
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3419
Epoch 3/10, Batch 20/97, Loss: 0.3985
Epoch 3/10, Batch 30/97, Loss: 0.2111
Epoch 3/10, Batch 40/97, Loss: 0.3311
Epoch 3/10, Batch 50/97, Loss: 0.2288
Epoch 3/10, Batch 60/97, Loss: 0.3092
Epoch 3/10, Batch 70/97, Loss: 0.2400
Epoch 3/10, Batch 80/97, Loss: 0.2425
Epoch 3/10, Batch 90/97, Loss: 0.2417
Epoch 3/10, Train Loss: 0.3279, Valid Loss: 0.3217
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2628
Epoch 4/10, Batch 20/97, Loss: 0.3640
Epoch 4/10, Batch 30/97, Loss: 0.1836
Epoch 4/10, Batch 40/97, Loss: 0.3385
Epoch 4/10, Batch 50/97, Loss: 0.2398
Epoch 4/10, Batch 60/97, Loss: 0.1295
Epoch 4/10, Batch 70/97, Loss: 0.2995
Epoch 4/10, Batch 80/97, Loss: 0.2143
Epoch 4/10, Batch 90/97, Loss: 0.1441
Epoch 4/10, Train Loss: 0.2856, Valid Loss: 0.2931
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1643
Epoch 5/10, Batch 20/97, Loss: 0.1949
Epoch 5/10, Batch 30/97, Loss: 0.2645
Epoch 5/10, Batch 40/97, Loss: 0.1833
Epoch 5/10, Batch 50/97, Loss: 0.2040
Epoch 5/10, Batch 60/97, Loss: 0.1777
Epoch 5/10, Batch 70/97, Loss: 0.1995
Epoch 5/10, Batch 80/97, Loss: 0.1513
Epoch 5/10, Batch 90/97, Loss: 0.4646
Epoch 5/10, Train Loss: 0.2679, Valid Loss: 0.2792
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2610
Epoch 6/10, Batch 20/97, Loss: 0.1306
Epoch 6/10, Batch 30/97, Loss: 0.2014
Epoch 6/10, Batch 40/97, Loss: 0.4032
Epoch 6/10, Batch 50/97, Loss: 0.2113
Epoch 6/10, Batch 60/97, Loss: 0.1929
Epoch 6/10, Batch 70/97, Loss: 0.2479
Epoch 6/10, Batch 80/97, Loss: 0.2289
Epoch 6/10, Batch 90/97, Loss: 0.1897
Epoch 6/10, Train Loss: 0.2439, Valid Loss: 0.2687
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3937
Epoch 7/10, Batch 20/97, Loss: 0.1635
Epoch 7/10, Batch 30/97, Loss: 0.1870
Epoch 7/10, Batch 40/97, Loss: 0.1743
Epoch 7/10, Batch 50/97, Loss: 0.2333
Epoch 7/10, Batch 60/97, Loss: 0.4475
Epoch 7/10, Batch 70/97, Loss: 0.2558
Epoch 7/10, Batch 80/97, Loss: 0.2145
Epoch 7/10, Batch 90/97, Loss: 0.2045
Epoch 7/10, Train Loss: 0.2478, Valid Loss: 0.2594
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.4027
Epoch 8/10, Batch 20/97, Loss: 0.1263
Epoch 8/10, Batch 30/97, Loss: 0.1407
Epoch 8/10, Batch 40/97, Loss: 0.2947
Epoch 8/10, Batch 50/97, Loss: 0.2469
Epoch 8/10, Batch 60/97, Loss: 0.1379
Epoch 8/10, Batch 70/97, Loss: 0.3198
Epoch 8/10, Batch 80/97, Loss: 0.1770
Epoch 8/10, Batch 90/97, Loss: 0.2210
Epoch 8/10, Train Loss: 0.2255, Valid Loss: 0.2494
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.1503
Epoch 9/10, Batch 20/97, Loss: 0.1263
Epoch 9/10, Batch 30/97, Loss: 0.2656
Epoch 9/10, Batch 40/97, Loss: 0.1075
Epoch 9/10, Batch 50/97, Loss: 0.2835
Epoch 9/10, Batch 60/97, Loss: 0.3644
Epoch 9/10, Batch 70/97, Loss: 0.1138
Epoch 9/10, Batch 80/97, Loss: 0.2130
Epoch 9/10, Batch 90/97, Loss: 0.1333
Epoch 9/10, Train Loss: 0.2183, Valid Loss: 0.2420
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.2496
Epoch 10/10, Batch 20/97, Loss: 0.2569
Epoch 10/10, Batch 30/97, Loss: 0.2140
Epoch 10/10, Batch 40/97, Loss: 0.1380
Epoch 10/10, Batch 50/97, Loss: 0.2777
Epoch 10/10, Batch 60/97, Loss: 0.1041
Epoch 10/10, Batch 70/97, Loss: 0.1248
Epoch 10/10, Batch 80/97, Loss: 0.2074
Epoch 10/10, Batch 90/97, Loss: 0.1142
Epoch 10/10, Train Loss: 0.2017, Valid Loss: 0.2390
Model saved!
Accuracy: 0.9206
Precision: 0.9189
Recall: 0.9206
F1-score: 0.9190
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5279
Epoch 1/10, Batch 20/97, Loss: 1.0564
Epoch 1/10, Batch 30/97, Loss: 1.0002
Epoch 1/10, Batch 40/97, Loss: 0.7821
Epoch 1/10, Batch 50/97, Loss: 0.5746
Epoch 1/10, Batch 60/97, Loss: 0.6088
Epoch 1/10, Batch 70/97, Loss: 0.6256
Epoch 1/10, Batch 80/97, Loss: 0.4870
Epoch 1/10, Batch 90/97, Loss: 0.5111
Epoch 1/10, Train Loss: 0.7859, Valid Loss: 0.4500
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3865
Epoch 2/10, Batch 20/97, Loss: 0.4940
Epoch 2/10, Batch 30/97, Loss: 0.5208
Epoch 2/10, Batch 40/97, Loss: 0.4184
Epoch 2/10, Batch 50/97, Loss: 0.6166
Epoch 2/10, Batch 60/97, Loss: 0.3630
Epoch 2/10, Batch 70/97, Loss: 0.4445
Epoch 2/10, Batch 80/97, Loss: 0.3018
Epoch 2/10, Batch 90/97, Loss: 0.3460
Epoch 2/10, Train Loss: 0.4090, Valid Loss: 0.3500
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2153
Epoch 3/10, Batch 20/97, Loss: 0.1992
Epoch 3/10, Batch 30/97, Loss: 0.1914
Epoch 3/10, Batch 40/97, Loss: 0.2527
Epoch 3/10, Batch 50/97, Loss: 0.2362
Epoch 3/10, Batch 60/97, Loss: 0.2235
Epoch 3/10, Batch 70/97, Loss: 0.2896
Epoch 3/10, Batch 80/97, Loss: 0.4151
Epoch 3/10, Batch 90/97, Loss: 0.2606
Epoch 3/10, Train Loss: 0.3329, Valid Loss: 0.3080
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2373
Epoch 4/10, Batch 20/97, Loss: 0.2800
Epoch 4/10, Batch 30/97, Loss: 0.2933
Epoch 4/10, Batch 40/97, Loss: 0.2114
Epoch 4/10, Batch 50/97, Loss: 0.2499
Epoch 4/10, Batch 60/97, Loss: 0.1692
Epoch 4/10, Batch 70/97, Loss: 0.1243
Epoch 4/10, Batch 80/97, Loss: 0.3494
Epoch 4/10, Batch 90/97, Loss: 0.3720
Epoch 4/10, Train Loss: 0.2940, Valid Loss: 0.2870
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1638
Epoch 5/10, Batch 20/97, Loss: 0.2008
Epoch 5/10, Batch 30/97, Loss: 0.1629
Epoch 5/10, Batch 40/97, Loss: 0.1535
Epoch 5/10, Batch 50/97, Loss: 0.1600
Epoch 5/10, Batch 60/97, Loss: 0.2936
Epoch 5/10, Batch 70/97, Loss: 0.3271
Epoch 5/10, Batch 80/97, Loss: 0.4270
Epoch 5/10, Batch 90/97, Loss: 0.3983
Epoch 5/10, Train Loss: 0.2665, Valid Loss: 0.2725
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1488
Epoch 6/10, Batch 20/97, Loss: 0.1771
Epoch 6/10, Batch 30/97, Loss: 0.2390
Epoch 6/10, Batch 40/97, Loss: 0.3235
Epoch 6/10, Batch 50/97, Loss: 0.1649
Epoch 6/10, Batch 60/97, Loss: 0.2178
Epoch 6/10, Batch 70/97, Loss: 0.2996
Epoch 6/10, Batch 80/97, Loss: 0.2213
Epoch 6/10, Batch 90/97, Loss: 0.3080
Epoch 6/10, Train Loss: 0.2508, Valid Loss: 0.2695
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2089
Epoch 7/10, Batch 20/97, Loss: 0.1337
Epoch 7/10, Batch 30/97, Loss: 0.2100
Epoch 7/10, Batch 40/97, Loss: 0.1724
Epoch 7/10, Batch 50/97, Loss: 0.1231
Epoch 7/10, Batch 60/97, Loss: 0.3658
Epoch 7/10, Batch 70/97, Loss: 0.1895
Epoch 7/10, Batch 80/97, Loss: 0.2998
Epoch 7/10, Batch 90/97, Loss: 0.3240
Epoch 7/10, Train Loss: 0.2504, Valid Loss: 0.2498
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1596
Epoch 8/10, Batch 20/97, Loss: 0.3730
Epoch 8/10, Batch 30/97, Loss: 0.1366
Epoch 8/10, Batch 40/97, Loss: 0.0987
Epoch 8/10, Batch 50/97, Loss: 0.2669
Epoch 8/10, Batch 60/97, Loss: 0.1174
Epoch 8/10, Batch 70/97, Loss: 0.1500
Epoch 8/10, Batch 80/97, Loss: 0.1590
Epoch 8/10, Batch 90/97, Loss: 0.1732
Epoch 8/10, Train Loss: 0.2285, Valid Loss: 0.2582
Epoch 9/10, Batch 10/97, Loss: 0.1221
Epoch 9/10, Batch 20/97, Loss: 0.2065
Epoch 9/10, Batch 30/97, Loss: 0.1903
Epoch 9/10, Batch 40/97, Loss: 0.1693
Epoch 9/10, Batch 50/97, Loss: 0.2037
Epoch 9/10, Batch 60/97, Loss: 0.1306
Epoch 9/10, Batch 70/97, Loss: 0.3062
Epoch 9/10, Batch 80/97, Loss: 0.2078
Epoch 9/10, Batch 90/97, Loss: 0.2142
Epoch 9/10, Train Loss: 0.2137, Valid Loss: 0.2534
Epoch 10/10, Batch 10/97, Loss: 0.2367
Epoch 10/10, Batch 20/97, Loss: 0.1371
Epoch 10/10, Batch 30/97, Loss: 0.1518
Epoch 10/10, Batch 40/97, Loss: 0.2301
Epoch 10/10, Batch 50/97, Loss: 0.2467
Epoch 10/10, Batch 60/97, Loss: 0.1615
Epoch 10/10, Batch 70/97, Loss: 0.2079
Epoch 10/10, Batch 80/97, Loss: 0.2498
Epoch 10/10, Batch 90/97, Loss: 0.1078
Epoch 10/10, Train Loss: 0.2092, Valid Loss: 0.2435
Model saved!
Accuracy: 0.9159
Precision: 0.9146
Recall: 0.9159
F1-score: 0.9149
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5012
Epoch 1/10, Batch 20/97, Loss: 1.0050
Epoch 1/10, Batch 30/97, Loss: 0.8788
Epoch 1/10, Batch 40/97, Loss: 0.6133
Epoch 1/10, Batch 50/97, Loss: 0.6187
Epoch 1/10, Batch 60/97, Loss: 0.6226
Epoch 1/10, Batch 70/97, Loss: 0.5245
Epoch 1/10, Batch 80/97, Loss: 0.5743
Epoch 1/10, Batch 90/97, Loss: 0.5788
Epoch 1/10, Train Loss: 0.7777, Valid Loss: 0.4496
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3097
Epoch 2/10, Batch 20/97, Loss: 0.4995
Epoch 2/10, Batch 30/97, Loss: 0.3315
Epoch 2/10, Batch 40/97, Loss: 0.4050
Epoch 2/10, Batch 50/97, Loss: 0.6279
Epoch 2/10, Batch 60/97, Loss: 0.3787
Epoch 2/10, Batch 70/97, Loss: 0.2563
Epoch 2/10, Batch 80/97, Loss: 0.2264
Epoch 2/10, Batch 90/97, Loss: 0.2501
Epoch 2/10, Train Loss: 0.3937, Valid Loss: 0.3408
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3105
Epoch 3/10, Batch 20/97, Loss: 0.3111
Epoch 3/10, Batch 30/97, Loss: 0.4288
Epoch 3/10, Batch 40/97, Loss: 0.2492
Epoch 3/10, Batch 50/97, Loss: 0.2756
Epoch 3/10, Batch 60/97, Loss: 0.3201
Epoch 3/10, Batch 70/97, Loss: 0.2563
Epoch 3/10, Batch 80/97, Loss: 0.3225
Epoch 3/10, Batch 90/97, Loss: 0.2566
Epoch 3/10, Train Loss: 0.3230, Valid Loss: 0.2994
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3380
Epoch 4/10, Batch 20/97, Loss: 0.4193
Epoch 4/10, Batch 30/97, Loss: 0.4802
Epoch 4/10, Batch 40/97, Loss: 0.2724
Epoch 4/10, Batch 50/97, Loss: 0.1930
Epoch 4/10, Batch 60/97, Loss: 0.0991
Epoch 4/10, Batch 70/97, Loss: 0.2995
Epoch 4/10, Batch 80/97, Loss: 0.1908
Epoch 4/10, Batch 90/97, Loss: 0.3329
Epoch 4/10, Train Loss: 0.2853, Valid Loss: 0.2714
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.3166
Epoch 5/10, Batch 20/97, Loss: 0.1724
Epoch 5/10, Batch 30/97, Loss: 0.1618
Epoch 5/10, Batch 40/97, Loss: 0.1850
Epoch 5/10, Batch 50/97, Loss: 0.1958
Epoch 5/10, Batch 60/97, Loss: 0.1769
Epoch 5/10, Batch 70/97, Loss: 0.2643
Epoch 5/10, Batch 80/97, Loss: 0.2600
Epoch 5/10, Batch 90/97, Loss: 0.2205
Epoch 5/10, Train Loss: 0.2558, Valid Loss: 0.2645
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2298
Epoch 6/10, Batch 20/97, Loss: 0.2104
Epoch 6/10, Batch 30/97, Loss: 0.1510
Epoch 6/10, Batch 40/97, Loss: 0.4147
Epoch 6/10, Batch 50/97, Loss: 0.1130
Epoch 6/10, Batch 60/97, Loss: 0.3053
Epoch 6/10, Batch 70/97, Loss: 0.1293
Epoch 6/10, Batch 80/97, Loss: 0.2593
Epoch 6/10, Batch 90/97, Loss: 0.1431
Epoch 6/10, Train Loss: 0.2345, Valid Loss: 0.2476
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2567
Epoch 7/10, Batch 20/97, Loss: 0.1063
Epoch 7/10, Batch 30/97, Loss: 0.1435
Epoch 7/10, Batch 40/97, Loss: 0.1547
Epoch 7/10, Batch 50/97, Loss: 0.2398
Epoch 7/10, Batch 60/97, Loss: 0.2508
Epoch 7/10, Batch 70/97, Loss: 0.1731
Epoch 7/10, Batch 80/97, Loss: 0.2873
Epoch 7/10, Batch 90/97, Loss: 0.3009
Epoch 7/10, Train Loss: 0.2384, Valid Loss: 0.2399
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.1908
Epoch 8/10, Batch 20/97, Loss: 0.2040
Epoch 8/10, Batch 30/97, Loss: 0.1571
Epoch 8/10, Batch 40/97, Loss: 0.1234
Epoch 8/10, Batch 50/97, Loss: 0.1341
Epoch 8/10, Batch 60/97, Loss: 0.2258
Epoch 8/10, Batch 70/97, Loss: 0.2000
Epoch 8/10, Batch 80/97, Loss: 0.0726
Epoch 8/10, Batch 90/97, Loss: 0.1070
Epoch 8/10, Train Loss: 0.2178, Valid Loss: 0.2260
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0556
Epoch 9/10, Batch 20/97, Loss: 0.0878
Epoch 9/10, Batch 30/97, Loss: 0.4122
Epoch 9/10, Batch 40/97, Loss: 0.1086
Epoch 9/10, Batch 50/97, Loss: 0.2906
Epoch 9/10, Batch 60/97, Loss: 0.2463
Epoch 9/10, Batch 70/97, Loss: 0.1050
Epoch 9/10, Batch 80/97, Loss: 0.3095
Epoch 9/10, Batch 90/97, Loss: 0.2842
Epoch 9/10, Train Loss: 0.2145, Valid Loss: 0.2269
Epoch 10/10, Batch 10/97, Loss: 0.4348
Epoch 10/10, Batch 20/97, Loss: 0.1723
Epoch 10/10, Batch 30/97, Loss: 0.1992
Epoch 10/10, Batch 40/97, Loss: 0.1581
Epoch 10/10, Batch 50/97, Loss: 0.2197
Epoch 10/10, Batch 60/97, Loss: 0.1225
Epoch 10/10, Batch 70/97, Loss: 0.2687
Epoch 10/10, Batch 80/97, Loss: 0.2271
Epoch 10/10, Batch 90/97, Loss: 0.1811
Epoch 10/10, Train Loss: 0.1989, Valid Loss: 0.2192
Model saved!
Accuracy: 0.9147
Precision: 0.9119
Recall: 0.9147
F1-score: 0.9125
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5290
Epoch 1/10, Batch 20/97, Loss: 1.0154
Epoch 1/10, Batch 30/97, Loss: 0.8272
Epoch 1/10, Batch 40/97, Loss: 0.7586
Epoch 1/10, Batch 50/97, Loss: 0.6727
Epoch 1/10, Batch 60/97, Loss: 0.5898
Epoch 1/10, Batch 70/97, Loss: 0.5009
Epoch 1/10, Batch 80/97, Loss: 0.4763
Epoch 1/10, Batch 90/97, Loss: 0.5785
Epoch 1/10, Train Loss: 0.7741, Valid Loss: 0.4206
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3964
Epoch 2/10, Batch 20/97, Loss: 0.4416
Epoch 2/10, Batch 30/97, Loss: 0.4071
Epoch 2/10, Batch 40/97, Loss: 0.5636
Epoch 2/10, Batch 50/97, Loss: 0.5530
Epoch 2/10, Batch 60/97, Loss: 0.2982
Epoch 2/10, Batch 70/97, Loss: 0.3823
Epoch 2/10, Batch 80/97, Loss: 0.4197
Epoch 2/10, Batch 90/97, Loss: 0.2443
Epoch 2/10, Train Loss: 0.4023, Valid Loss: 0.3162
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2950
Epoch 3/10, Batch 20/97, Loss: 0.2629
Epoch 3/10, Batch 30/97, Loss: 0.2026
Epoch 3/10, Batch 40/97, Loss: 0.2249
Epoch 3/10, Batch 50/97, Loss: 0.2814
Epoch 3/10, Batch 60/97, Loss: 0.3103
Epoch 3/10, Batch 70/97, Loss: 0.3439
Epoch 3/10, Batch 80/97, Loss: 0.2718
Epoch 3/10, Batch 90/97, Loss: 0.1580
Epoch 3/10, Train Loss: 0.3231, Valid Loss: 0.2725
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.3182
Epoch 4/10, Batch 20/97, Loss: 0.1856
Epoch 4/10, Batch 30/97, Loss: 0.3186
Epoch 4/10, Batch 40/97, Loss: 0.2287
Epoch 4/10, Batch 50/97, Loss: 0.1189
Epoch 4/10, Batch 60/97, Loss: 0.1771
Epoch 4/10, Batch 70/97, Loss: 0.2940
Epoch 4/10, Batch 80/97, Loss: 0.2377
Epoch 4/10, Batch 90/97, Loss: 0.2906
Epoch 4/10, Train Loss: 0.2866, Valid Loss: 0.2512
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2985
Epoch 5/10, Batch 20/97, Loss: 0.1677
Epoch 5/10, Batch 30/97, Loss: 0.2300
Epoch 5/10, Batch 40/97, Loss: 0.1310
Epoch 5/10, Batch 50/97, Loss: 0.2107
Epoch 5/10, Batch 60/97, Loss: 0.2630
Epoch 5/10, Batch 70/97, Loss: 0.2179
Epoch 5/10, Batch 80/97, Loss: 0.2408
Epoch 5/10, Batch 90/97, Loss: 0.3671
Epoch 5/10, Train Loss: 0.2554, Valid Loss: 0.2355
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.1567
Epoch 6/10, Batch 20/97, Loss: 0.2372
Epoch 6/10, Batch 30/97, Loss: 0.2180
Epoch 6/10, Batch 40/97, Loss: 0.1754
Epoch 6/10, Batch 50/97, Loss: 0.3696
Epoch 6/10, Batch 60/97, Loss: 0.2512
Epoch 6/10, Batch 70/97, Loss: 0.2292
Epoch 6/10, Batch 80/97, Loss: 0.2080
Epoch 6/10, Batch 90/97, Loss: 0.2533
Epoch 6/10, Train Loss: 0.2448, Valid Loss: 0.2347
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3638
Epoch 7/10, Batch 20/97, Loss: 0.1175
Epoch 7/10, Batch 30/97, Loss: 0.3128
Epoch 7/10, Batch 40/97, Loss: 0.2614
Epoch 7/10, Batch 50/97, Loss: 0.2634
Epoch 7/10, Batch 60/97, Loss: 0.2993
Epoch 7/10, Batch 70/97, Loss: 0.1619
Epoch 7/10, Batch 80/97, Loss: 0.2610
Epoch 7/10, Batch 90/97, Loss: 0.3455
Epoch 7/10, Train Loss: 0.2439, Valid Loss: 0.2252
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.4103
Epoch 8/10, Batch 20/97, Loss: 0.1537
Epoch 8/10, Batch 30/97, Loss: 0.1664
Epoch 8/10, Batch 40/97, Loss: 0.1337
Epoch 8/10, Batch 50/97, Loss: 0.2026
Epoch 8/10, Batch 60/97, Loss: 0.1160
Epoch 8/10, Batch 70/97, Loss: 0.3342
Epoch 8/10, Batch 80/97, Loss: 0.1620
Epoch 8/10, Batch 90/97, Loss: 0.1417
Epoch 8/10, Train Loss: 0.2210, Valid Loss: 0.2144
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0975
Epoch 9/10, Batch 20/97, Loss: 0.1072
Epoch 9/10, Batch 30/97, Loss: 0.2268
Epoch 9/10, Batch 40/97, Loss: 0.2417
Epoch 9/10, Batch 50/97, Loss: 0.1947
Epoch 9/10, Batch 60/97, Loss: 0.1712
Epoch 9/10, Batch 70/97, Loss: 0.2421
Epoch 9/10, Batch 80/97, Loss: 0.2173
Epoch 9/10, Batch 90/97, Loss: 0.2402
Epoch 9/10, Train Loss: 0.2016, Valid Loss: 0.2152
Epoch 10/10, Batch 10/97, Loss: 0.4018
Epoch 10/10, Batch 20/97, Loss: 0.0888
Epoch 10/10, Batch 30/97, Loss: 0.2029
Epoch 10/10, Batch 40/97, Loss: 0.2020
Epoch 10/10, Batch 50/97, Loss: 0.3504
Epoch 10/10, Batch 60/97, Loss: 0.1936
Epoch 10/10, Batch 70/97, Loss: 0.2795
Epoch 10/10, Batch 80/97, Loss: 0.2879
Epoch 10/10, Batch 90/97, Loss: 0.2455
Epoch 10/10, Train Loss: 0.2022, Valid Loss: 0.2112
Model saved!
Accuracy: 0.9194
Precision: 0.9174
Recall: 0.9194
F1-score: 0.9177
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4973
Epoch 1/10, Batch 20/97, Loss: 1.0364
Epoch 1/10, Batch 30/97, Loss: 0.8293
Epoch 1/10, Batch 40/97, Loss: 0.6849
Epoch 1/10, Batch 50/97, Loss: 0.7276
Epoch 1/10, Batch 60/97, Loss: 0.5181
Epoch 1/10, Batch 70/97, Loss: 0.5227
Epoch 1/10, Batch 80/97, Loss: 0.4763
Epoch 1/10, Batch 90/97, Loss: 0.4869
Epoch 1/10, Train Loss: 0.7752, Valid Loss: 0.4171
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4517
Epoch 2/10, Batch 20/97, Loss: 0.5514
Epoch 2/10, Batch 30/97, Loss: 0.3680
Epoch 2/10, Batch 40/97, Loss: 0.3874
Epoch 2/10, Batch 50/97, Loss: 0.5264
Epoch 2/10, Batch 60/97, Loss: 0.3503
Epoch 2/10, Batch 70/97, Loss: 0.3120
Epoch 2/10, Batch 80/97, Loss: 0.3390
Epoch 2/10, Batch 90/97, Loss: 0.2716
Epoch 2/10, Train Loss: 0.3945, Valid Loss: 0.3116
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.2495
Epoch 3/10, Batch 20/97, Loss: 0.3318
Epoch 3/10, Batch 30/97, Loss: 0.3036
Epoch 3/10, Batch 40/97, Loss: 0.2931
Epoch 3/10, Batch 50/97, Loss: 0.2842
Epoch 3/10, Batch 60/97, Loss: 0.2280
Epoch 3/10, Batch 70/97, Loss: 0.2386
Epoch 3/10, Batch 80/97, Loss: 0.2176
Epoch 3/10, Batch 90/97, Loss: 0.3282
Epoch 3/10, Train Loss: 0.3185, Valid Loss: 0.2711
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2961
Epoch 4/10, Batch 20/97, Loss: 0.2197
Epoch 4/10, Batch 30/97, Loss: 0.3372
Epoch 4/10, Batch 40/97, Loss: 0.1928
Epoch 4/10, Batch 50/97, Loss: 0.1677
Epoch 4/10, Batch 60/97, Loss: 0.1353
Epoch 4/10, Batch 70/97, Loss: 0.2163
Epoch 4/10, Batch 80/97, Loss: 0.4949
Epoch 4/10, Batch 90/97, Loss: 0.3538
Epoch 4/10, Train Loss: 0.2828, Valid Loss: 0.2486
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2133
Epoch 5/10, Batch 20/97, Loss: 0.2855
Epoch 5/10, Batch 30/97, Loss: 0.2699
Epoch 5/10, Batch 40/97, Loss: 0.1497
Epoch 5/10, Batch 50/97, Loss: 0.2217
Epoch 5/10, Batch 60/97, Loss: 0.1520
Epoch 5/10, Batch 70/97, Loss: 0.2117
Epoch 5/10, Batch 80/97, Loss: 0.3025
Epoch 5/10, Batch 90/97, Loss: 0.3129
Epoch 5/10, Train Loss: 0.2573, Valid Loss: 0.2410
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2921
Epoch 6/10, Batch 20/97, Loss: 0.1351
Epoch 6/10, Batch 30/97, Loss: 0.1195
Epoch 6/10, Batch 40/97, Loss: 0.3486
Epoch 6/10, Batch 50/97, Loss: 0.2601
Epoch 6/10, Batch 60/97, Loss: 0.2749
Epoch 6/10, Batch 70/97, Loss: 0.4191
Epoch 6/10, Batch 80/97, Loss: 0.1506
Epoch 6/10, Batch 90/97, Loss: 0.1731
Epoch 6/10, Train Loss: 0.2445, Valid Loss: 0.2331
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3441
Epoch 7/10, Batch 20/97, Loss: 0.1836
Epoch 7/10, Batch 30/97, Loss: 0.1429
Epoch 7/10, Batch 40/97, Loss: 0.2250
Epoch 7/10, Batch 50/97, Loss: 0.3221
Epoch 7/10, Batch 60/97, Loss: 0.2996
Epoch 7/10, Batch 70/97, Loss: 0.1181
Epoch 7/10, Batch 80/97, Loss: 0.2014
Epoch 7/10, Batch 90/97, Loss: 0.3099
Epoch 7/10, Train Loss: 0.2338, Valid Loss: 0.2201
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2253
Epoch 8/10, Batch 20/97, Loss: 0.1867
Epoch 8/10, Batch 30/97, Loss: 0.1481
Epoch 8/10, Batch 40/97, Loss: 0.1246
Epoch 8/10, Batch 50/97, Loss: 0.1796
Epoch 8/10, Batch 60/97, Loss: 0.1381
Epoch 8/10, Batch 70/97, Loss: 0.2362
Epoch 8/10, Batch 80/97, Loss: 0.1352
Epoch 8/10, Batch 90/97, Loss: 0.2564
Epoch 8/10, Train Loss: 0.2111, Valid Loss: 0.2193
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2265
Epoch 9/10, Batch 20/97, Loss: 0.1875
Epoch 9/10, Batch 30/97, Loss: 0.2578
Epoch 9/10, Batch 40/97, Loss: 0.1608
Epoch 9/10, Batch 50/97, Loss: 0.1907
Epoch 9/10, Batch 60/97, Loss: 0.1778
Epoch 9/10, Batch 70/97, Loss: 0.1669
Epoch 9/10, Batch 80/97, Loss: 0.3057
Epoch 9/10, Batch 90/97, Loss: 0.1543
Epoch 9/10, Train Loss: 0.2003, Valid Loss: 0.2118
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1769
Epoch 10/10, Batch 20/97, Loss: 0.1422
Epoch 10/10, Batch 30/97, Loss: 0.1898
Epoch 10/10, Batch 40/97, Loss: 0.1844
Epoch 10/10, Batch 50/97, Loss: 0.2195
Epoch 10/10, Batch 60/97, Loss: 0.2176
Epoch 10/10, Batch 70/97, Loss: 0.1924
Epoch 10/10, Batch 80/97, Loss: 0.1907
Epoch 10/10, Batch 90/97, Loss: 0.0744
Epoch 10/10, Train Loss: 0.1981, Valid Loss: 0.2100
Model saved!
Accuracy: 0.9159
Precision: 0.9137
Recall: 0.9159
F1-score: 0.9142
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.5012
Epoch 1/10, Batch 20/97, Loss: 1.0087
Epoch 1/10, Batch 30/97, Loss: 0.9638
Epoch 1/10, Batch 40/97, Loss: 0.6621
Epoch 1/10, Batch 50/97, Loss: 0.5802
Epoch 1/10, Batch 60/97, Loss: 0.5330
Epoch 1/10, Batch 70/97, Loss: 0.5475
Epoch 1/10, Batch 80/97, Loss: 0.4938
Epoch 1/10, Batch 90/97, Loss: 0.5516
Epoch 1/10, Train Loss: 0.7749, Valid Loss: 0.4215
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.4706
Epoch 2/10, Batch 20/97, Loss: 0.3801
Epoch 2/10, Batch 30/97, Loss: 0.3090
Epoch 2/10, Batch 40/97, Loss: 0.4559
Epoch 2/10, Batch 50/97, Loss: 0.5387
Epoch 2/10, Batch 60/97, Loss: 0.3109
Epoch 2/10, Batch 70/97, Loss: 0.3192
Epoch 2/10, Batch 80/97, Loss: 0.2267
Epoch 2/10, Batch 90/97, Loss: 0.2447
Epoch 2/10, Train Loss: 0.3968, Valid Loss: 0.3146
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3443
Epoch 3/10, Batch 20/97, Loss: 0.2194
Epoch 3/10, Batch 30/97, Loss: 0.2052
Epoch 3/10, Batch 40/97, Loss: 0.2602
Epoch 3/10, Batch 50/97, Loss: 0.3252
Epoch 3/10, Batch 60/97, Loss: 0.3298
Epoch 3/10, Batch 70/97, Loss: 0.2050
Epoch 3/10, Batch 80/97, Loss: 0.4577
Epoch 3/10, Batch 90/97, Loss: 0.2563
Epoch 3/10, Train Loss: 0.3302, Valid Loss: 0.2770
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2457
Epoch 4/10, Batch 20/97, Loss: 0.2666
Epoch 4/10, Batch 30/97, Loss: 0.3514
Epoch 4/10, Batch 40/97, Loss: 0.2523
Epoch 4/10, Batch 50/97, Loss: 0.1886
Epoch 4/10, Batch 60/97, Loss: 0.1480
Epoch 4/10, Batch 70/97, Loss: 0.4294
Epoch 4/10, Batch 80/97, Loss: 0.1697
Epoch 4/10, Batch 90/97, Loss: 0.2257
Epoch 4/10, Train Loss: 0.2902, Valid Loss: 0.2506
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2411
Epoch 5/10, Batch 20/97, Loss: 0.1592
Epoch 5/10, Batch 30/97, Loss: 0.1309
Epoch 5/10, Batch 40/97, Loss: 0.0798
Epoch 5/10, Batch 50/97, Loss: 0.1681
Epoch 5/10, Batch 60/97, Loss: 0.1945
Epoch 5/10, Batch 70/97, Loss: 0.1740
Epoch 5/10, Batch 80/97, Loss: 0.3217
Epoch 5/10, Batch 90/97, Loss: 0.4297
Epoch 5/10, Train Loss: 0.2577, Valid Loss: 0.2323
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.4065
Epoch 6/10, Batch 20/97, Loss: 0.1299
Epoch 6/10, Batch 30/97, Loss: 0.1425
Epoch 6/10, Batch 40/97, Loss: 0.2598
Epoch 6/10, Batch 50/97, Loss: 0.2336
Epoch 6/10, Batch 60/97, Loss: 0.1872
Epoch 6/10, Batch 70/97, Loss: 0.3093
Epoch 6/10, Batch 80/97, Loss: 0.1966
Epoch 6/10, Batch 90/97, Loss: 0.3027
Epoch 6/10, Train Loss: 0.2473, Valid Loss: 0.2233
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.2972
Epoch 7/10, Batch 20/97, Loss: 0.2453
Epoch 7/10, Batch 30/97, Loss: 0.1601
Epoch 7/10, Batch 40/97, Loss: 0.1861
Epoch 7/10, Batch 50/97, Loss: 0.2889
Epoch 7/10, Batch 60/97, Loss: 0.3274
Epoch 7/10, Batch 70/97, Loss: 0.2098
Epoch 7/10, Batch 80/97, Loss: 0.1116
Epoch 7/10, Batch 90/97, Loss: 0.1494
Epoch 7/10, Train Loss: 0.2436, Valid Loss: 0.2180
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2271
Epoch 8/10, Batch 20/97, Loss: 0.1767
Epoch 8/10, Batch 30/97, Loss: 0.2719
Epoch 8/10, Batch 40/97, Loss: 0.2092
Epoch 8/10, Batch 50/97, Loss: 0.2759
Epoch 8/10, Batch 60/97, Loss: 0.2235
Epoch 8/10, Batch 70/97, Loss: 0.4040
Epoch 8/10, Batch 80/97, Loss: 0.2035
Epoch 8/10, Batch 90/97, Loss: 0.1664
Epoch 8/10, Train Loss: 0.2275, Valid Loss: 0.2161
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.2570
Epoch 9/10, Batch 20/97, Loss: 0.1176
Epoch 9/10, Batch 30/97, Loss: 0.2072
Epoch 9/10, Batch 40/97, Loss: 0.1872
Epoch 9/10, Batch 50/97, Loss: 0.1284
Epoch 9/10, Batch 60/97, Loss: 0.1701
Epoch 9/10, Batch 70/97, Loss: 0.1473
Epoch 9/10, Batch 80/97, Loss: 0.1900
Epoch 9/10, Batch 90/97, Loss: 0.1792
Epoch 9/10, Train Loss: 0.2046, Valid Loss: 0.2084
Model saved!
Epoch 10/10, Batch 10/97, Loss: 0.1854
Epoch 10/10, Batch 20/97, Loss: 0.2064
Epoch 10/10, Batch 30/97, Loss: 0.1797
Epoch 10/10, Batch 40/97, Loss: 0.1554
Epoch 10/10, Batch 50/97, Loss: 0.2716
Epoch 10/10, Batch 60/97, Loss: 0.1826
Epoch 10/10, Batch 70/97, Loss: 0.2086
Epoch 10/10, Batch 80/97, Loss: 0.1818
Epoch 10/10, Batch 90/97, Loss: 0.3593
Epoch 10/10, Train Loss: 0.1958, Valid Loss: 0.2088
Accuracy: 0.9136
Precision: 0.9104
Recall: 0.9136
F1-score: 0.9114
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4990
Epoch 1/10, Batch 20/97, Loss: 1.0341
Epoch 1/10, Batch 30/97, Loss: 0.8894
Epoch 1/10, Batch 40/97, Loss: 0.6568
Epoch 1/10, Batch 50/97, Loss: 0.6487
Epoch 1/10, Batch 60/97, Loss: 0.6269
Epoch 1/10, Batch 70/97, Loss: 0.5724
Epoch 1/10, Batch 80/97, Loss: 0.5052
Epoch 1/10, Batch 90/97, Loss: 0.4748
Epoch 1/10, Train Loss: 0.7685, Valid Loss: 0.4289
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.5504
Epoch 2/10, Batch 20/97, Loss: 0.4230
Epoch 2/10, Batch 30/97, Loss: 0.4095
Epoch 2/10, Batch 40/97, Loss: 0.3482
Epoch 2/10, Batch 50/97, Loss: 0.6844
Epoch 2/10, Batch 60/97, Loss: 0.3138
Epoch 2/10, Batch 70/97, Loss: 0.4209
Epoch 2/10, Batch 80/97, Loss: 0.2992
Epoch 2/10, Batch 90/97, Loss: 0.2882
Epoch 2/10, Train Loss: 0.3895, Valid Loss: 0.3200
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.3947
Epoch 3/10, Batch 20/97, Loss: 0.3494
Epoch 3/10, Batch 30/97, Loss: 0.3858
Epoch 3/10, Batch 40/97, Loss: 0.3779
Epoch 3/10, Batch 50/97, Loss: 0.2399
Epoch 3/10, Batch 60/97, Loss: 0.2452
Epoch 3/10, Batch 70/97, Loss: 0.1464
Epoch 3/10, Batch 80/97, Loss: 0.2500
Epoch 3/10, Batch 90/97, Loss: 0.2883
Epoch 3/10, Train Loss: 0.3143, Valid Loss: 0.2773
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.1643
Epoch 4/10, Batch 20/97, Loss: 0.2346
Epoch 4/10, Batch 30/97, Loss: 0.3532
Epoch 4/10, Batch 40/97, Loss: 0.2558
Epoch 4/10, Batch 50/97, Loss: 0.2009
Epoch 4/10, Batch 60/97, Loss: 0.1159
Epoch 4/10, Batch 70/97, Loss: 0.2041
Epoch 4/10, Batch 80/97, Loss: 0.1847
Epoch 4/10, Batch 90/97, Loss: 0.2692
Epoch 4/10, Train Loss: 0.2779, Valid Loss: 0.2560
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.2064
Epoch 5/10, Batch 20/97, Loss: 0.2321
Epoch 5/10, Batch 30/97, Loss: 0.2005
Epoch 5/10, Batch 40/97, Loss: 0.3096
Epoch 5/10, Batch 50/97, Loss: 0.2036
Epoch 5/10, Batch 60/97, Loss: 0.2536
Epoch 5/10, Batch 70/97, Loss: 0.1840
Epoch 5/10, Batch 80/97, Loss: 0.3909
Epoch 5/10, Batch 90/97, Loss: 0.3751
Epoch 5/10, Train Loss: 0.2583, Valid Loss: 0.2399
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.2646
Epoch 6/10, Batch 20/97, Loss: 0.2586
Epoch 6/10, Batch 30/97, Loss: 0.1460
Epoch 6/10, Batch 40/97, Loss: 0.2932
Epoch 6/10, Batch 50/97, Loss: 0.2300
Epoch 6/10, Batch 60/97, Loss: 0.2597
Epoch 6/10, Batch 70/97, Loss: 0.3157
Epoch 6/10, Batch 80/97, Loss: 0.1935
Epoch 6/10, Batch 90/97, Loss: 0.2228
Epoch 6/10, Train Loss: 0.2290, Valid Loss: 0.2341
Model saved!
Epoch 7/10, Batch 10/97, Loss: 0.3753
Epoch 7/10, Batch 20/97, Loss: 0.2337
Epoch 7/10, Batch 30/97, Loss: 0.1650
Epoch 7/10, Batch 40/97, Loss: 0.1803
Epoch 7/10, Batch 50/97, Loss: 0.3001
Epoch 7/10, Batch 60/97, Loss: 0.3495
Epoch 7/10, Batch 70/97, Loss: 0.1813
Epoch 7/10, Batch 80/97, Loss: 0.2198
Epoch 7/10, Batch 90/97, Loss: 0.1860
Epoch 7/10, Train Loss: 0.2439, Valid Loss: 0.2295
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.3580
Epoch 8/10, Batch 20/97, Loss: 0.1226
Epoch 8/10, Batch 30/97, Loss: 0.1398
Epoch 8/10, Batch 40/97, Loss: 0.1371
Epoch 8/10, Batch 50/97, Loss: 0.3576
Epoch 8/10, Batch 60/97, Loss: 0.1482
Epoch 8/10, Batch 70/97, Loss: 0.4466
Epoch 8/10, Batch 80/97, Loss: 0.1723
Epoch 8/10, Batch 90/97, Loss: 0.1756
Epoch 8/10, Train Loss: 0.2091, Valid Loss: 0.2152
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.0895
Epoch 9/10, Batch 20/97, Loss: 0.1433
Epoch 9/10, Batch 30/97, Loss: 0.3503
Epoch 9/10, Batch 40/97, Loss: 0.0386
Epoch 9/10, Batch 50/97, Loss: 0.2601
Epoch 9/10, Batch 60/97, Loss: 0.1755
Epoch 9/10, Batch 70/97, Loss: 0.1733
Epoch 9/10, Batch 80/97, Loss: 0.0956
Epoch 9/10, Batch 90/97, Loss: 0.2131
Epoch 9/10, Train Loss: 0.1992, Valid Loss: 0.2189
Epoch 10/10, Batch 10/97, Loss: 0.2378
Epoch 10/10, Batch 20/97, Loss: 0.1187
Epoch 10/10, Batch 30/97, Loss: 0.2658
Epoch 10/10, Batch 40/97, Loss: 0.1157
Epoch 10/10, Batch 50/97, Loss: 0.2443
Epoch 10/10, Batch 60/97, Loss: 0.1152
Epoch 10/10, Batch 70/97, Loss: 0.1660
Epoch 10/10, Batch 80/97, Loss: 0.1823
Epoch 10/10, Batch 90/97, Loss: 0.0910
Epoch 10/10, Train Loss: 0.1870, Valid Loss: 0.2105
Model saved!
Accuracy: 0.9241
Precision: 0.9219
Recall: 0.9241
F1-score: 0.9228
Memory Allocated after cleanup: 17.76 MB
End time: 2025-02-26 04:01:42.531143
Duration: 8:25:47


Mejor accuracy al acabar el algoritmo: 0.9311


Fitness check:

Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/97, Loss: 1.4609
Epoch 1/10, Batch 20/97, Loss: 0.9933
Epoch 1/10, Batch 30/97, Loss: 0.8723
Epoch 1/10, Batch 40/97, Loss: 0.7441
Epoch 1/10, Batch 50/97, Loss: 0.7034
Epoch 1/10, Batch 60/97, Loss: 0.5723
Epoch 1/10, Batch 70/97, Loss: 0.5245
Epoch 1/10, Batch 80/97, Loss: 0.5309
Epoch 1/10, Batch 90/97, Loss: 0.6539
Epoch 1/10, Train Loss: 0.7740, Valid Loss: 0.4561
Model saved!
Epoch 2/10, Batch 10/97, Loss: 0.3456
Epoch 2/10, Batch 20/97, Loss: 0.6705
Epoch 2/10, Batch 30/97, Loss: 0.4767
Epoch 2/10, Batch 40/97, Loss: 0.3952
Epoch 2/10, Batch 50/97, Loss: 0.6369
Epoch 2/10, Batch 60/97, Loss: 0.3549
Epoch 2/10, Batch 70/97, Loss: 0.3166
Epoch 2/10, Batch 80/97, Loss: 0.1893
Epoch 2/10, Batch 90/97, Loss: 0.3017
Epoch 2/10, Train Loss: 0.3921, Valid Loss: 0.3502
Model saved!
Epoch 3/10, Batch 10/97, Loss: 0.4214
Epoch 3/10, Batch 20/97, Loss: 0.2776
Epoch 3/10, Batch 30/97, Loss: 0.2764
Epoch 3/10, Batch 40/97, Loss: 0.4085
Epoch 3/10, Batch 50/97, Loss: 0.2463
Epoch 3/10, Batch 60/97, Loss: 0.3239
Epoch 3/10, Batch 70/97, Loss: 0.2127
Epoch 3/10, Batch 80/97, Loss: 0.3479
Epoch 3/10, Batch 90/97, Loss: 0.2452
Epoch 3/10, Train Loss: 0.3223, Valid Loss: 0.3013
Model saved!
Epoch 4/10, Batch 10/97, Loss: 0.2407
Epoch 4/10, Batch 20/97, Loss: 0.3293
Epoch 4/10, Batch 30/97, Loss: 0.2407
Epoch 4/10, Batch 40/97, Loss: 0.2803
Epoch 4/10, Batch 50/97, Loss: 0.3260
Epoch 4/10, Batch 60/97, Loss: 0.2033
Epoch 4/10, Batch 70/97, Loss: 0.2716
Epoch 4/10, Batch 80/97, Loss: 0.2276
Epoch 4/10, Batch 90/97, Loss: 0.2784
Epoch 4/10, Train Loss: 0.2790, Valid Loss: 0.2824
Model saved!
Epoch 5/10, Batch 10/97, Loss: 0.1780
Epoch 5/10, Batch 20/97, Loss: 0.1376
Epoch 5/10, Batch 30/97, Loss: 0.1484
Epoch 5/10, Batch 40/97, Loss: 0.1863
Epoch 5/10, Batch 50/97, Loss: 0.3413
Epoch 5/10, Batch 60/97, Loss: 0.2514
Epoch 5/10, Batch 70/97, Loss: 0.2575
Epoch 5/10, Batch 80/97, Loss: 0.3956
Epoch 5/10, Batch 90/97, Loss: 0.4276
Epoch 5/10, Train Loss: 0.2586, Valid Loss: 0.2572
Model saved!
Epoch 6/10, Batch 10/97, Loss: 0.3571
Epoch 6/10, Batch 20/97, Loss: 0.1730
Epoch 6/10, Batch 30/97, Loss: 0.2284
Epoch 6/10, Batch 40/97, Loss: 0.4234
Epoch 6/10, Batch 50/97, Loss: 0.2058
Epoch 6/10, Batch 60/97, Loss: 0.2651
Epoch 6/10, Batch 70/97, Loss: 0.2520
Epoch 6/10, Batch 80/97, Loss: 0.1703
Epoch 6/10, Batch 90/97, Loss: 0.2780
Epoch 6/10, Train Loss: 0.2370, Valid Loss: 0.2649
Epoch 7/10, Batch 10/97, Loss: 0.3342
Epoch 7/10, Batch 20/97, Loss: 0.1175
Epoch 7/10, Batch 30/97, Loss: 0.1605
Epoch 7/10, Batch 40/97, Loss: 0.2281
Epoch 7/10, Batch 50/97, Loss: 0.1977
Epoch 7/10, Batch 60/97, Loss: 0.4470
Epoch 7/10, Batch 70/97, Loss: 0.1548
Epoch 7/10, Batch 80/97, Loss: 0.2168
Epoch 7/10, Batch 90/97, Loss: 0.2066
Epoch 7/10, Train Loss: 0.2329, Valid Loss: 0.2417
Model saved!
Epoch 8/10, Batch 10/97, Loss: 0.2838
Epoch 8/10, Batch 20/97, Loss: 0.2196
Epoch 8/10, Batch 30/97, Loss: 0.1685
Epoch 8/10, Batch 40/97, Loss: 0.1571
Epoch 8/10, Batch 50/97, Loss: 0.2310
Epoch 8/10, Batch 60/97, Loss: 0.0953
Epoch 8/10, Batch 70/97, Loss: 0.2675
Epoch 8/10, Batch 80/97, Loss: 0.2128
Epoch 8/10, Batch 90/97, Loss: 0.1041
Epoch 8/10, Train Loss: 0.2155, Valid Loss: 0.2366
Model saved!
Epoch 9/10, Batch 10/97, Loss: 0.3228
Epoch 9/10, Batch 20/97, Loss: 0.2618
Epoch 9/10, Batch 30/97, Loss: 0.2347
Epoch 9/10, Batch 40/97, Loss: 0.0544
Epoch 9/10, Batch 50/97, Loss: 0.2218
Epoch 9/10, Batch 60/97, Loss: 0.2051
Epoch 9/10, Batch 70/97, Loss: 0.1650
Epoch 9/10, Batch 80/97, Loss: 0.1329
Epoch 9/10, Batch 90/97, Loss: 0.2304
Epoch 9/10, Train Loss: 0.2012, Valid Loss: 0.2433
Epoch 10/10, Batch 10/97, Loss: 0.1366
Epoch 10/10, Batch 20/97, Loss: 0.1840
Epoch 10/10, Batch 30/97, Loss: 0.1768
Epoch 10/10, Batch 40/97, Loss: 0.2382
Epoch 10/10, Batch 50/97, Loss: 0.2332
Epoch 10/10, Batch 60/97, Loss: 0.1053
Epoch 10/10, Batch 70/97, Loss: 0.1959
Epoch 10/10, Batch 80/97, Loss: 0.0859
Epoch 10/10, Batch 90/97, Loss: 0.2420
Epoch 10/10, Train Loss: 0.1942, Valid Loss: 0.2321
Model saved!
Accuracy: 0.9311
Precision: 0.9307
Recall: 0.9311
F1-score: 0.9308
Memory Allocated after cleanup: 17.76 MB


Mejor accuracy encontrado: 0.9311


--------------------------------------mobilenet  BUSQUEDA LOCAL  75%-------------------------------------------------
Start time: 2025-02-26 04:06:44.370101
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3545
Epoch 1/10, Batch 20/145, Loss: 0.9193
Epoch 1/10, Batch 30/145, Loss: 0.8653
Epoch 1/10, Batch 40/145, Loss: 0.8330
Epoch 1/10, Batch 50/145, Loss: 0.6957
Epoch 1/10, Batch 60/145, Loss: 0.6106
Epoch 1/10, Batch 70/145, Loss: 0.5735
Epoch 1/10, Batch 80/145, Loss: 0.5733
Epoch 1/10, Batch 90/145, Loss: 0.3887
Epoch 1/10, Batch 100/145, Loss: 0.5454
Epoch 1/10, Batch 110/145, Loss: 0.3599
Epoch 1/10, Batch 120/145, Loss: 0.5295
Epoch 1/10, Batch 130/145, Loss: 0.5119
Epoch 1/10, Batch 140/145, Loss: 0.4275
Epoch 1/10, Train Loss: 0.6762, Valid Loss: 0.3756
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3725
Epoch 2/10, Batch 20/145, Loss: 0.2775
Epoch 2/10, Batch 30/145, Loss: 0.4544
Epoch 2/10, Batch 40/145, Loss: 0.5660
Epoch 2/10, Batch 50/145, Loss: 0.3010
Epoch 2/10, Batch 60/145, Loss: 0.3518
Epoch 2/10, Batch 70/145, Loss: 0.3099
Epoch 2/10, Batch 80/145, Loss: 0.4757
Epoch 2/10, Batch 90/145, Loss: 0.3720
Epoch 2/10, Batch 100/145, Loss: 0.2222
Epoch 2/10, Batch 110/145, Loss: 0.3655
Epoch 2/10, Batch 120/145, Loss: 0.4086
Epoch 2/10, Batch 130/145, Loss: 0.3277
Epoch 2/10, Batch 140/145, Loss: 0.3230
Epoch 2/10, Train Loss: 0.3528, Valid Loss: 0.3004
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1938
Epoch 3/10, Batch 20/145, Loss: 0.2190
Epoch 3/10, Batch 30/145, Loss: 0.4096
Epoch 3/10, Batch 40/145, Loss: 0.1597
Epoch 3/10, Batch 50/145, Loss: 0.1574
Epoch 3/10, Batch 60/145, Loss: 0.5587
Epoch 3/10, Batch 70/145, Loss: 0.2660
Epoch 3/10, Batch 80/145, Loss: 0.2646
Epoch 3/10, Batch 90/145, Loss: 0.2170
Epoch 3/10, Batch 100/145, Loss: 0.2392
Epoch 3/10, Batch 110/145, Loss: 0.3025
Epoch 3/10, Batch 120/145, Loss: 0.3623
Epoch 3/10, Batch 130/145, Loss: 0.3043
Epoch 3/10, Batch 140/145, Loss: 0.2376
Epoch 3/10, Train Loss: 0.2970, Valid Loss: 0.2718
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2325
Epoch 4/10, Batch 20/145, Loss: 0.2937
Epoch 4/10, Batch 30/145, Loss: 0.2937
Epoch 4/10, Batch 40/145, Loss: 0.1683
Epoch 4/10, Batch 50/145, Loss: 0.3266
Epoch 4/10, Batch 60/145, Loss: 0.3411
Epoch 4/10, Batch 70/145, Loss: 0.2845
Epoch 4/10, Batch 80/145, Loss: 0.2623
Epoch 4/10, Batch 90/145, Loss: 0.2855
Epoch 4/10, Batch 100/145, Loss: 0.4074
Epoch 4/10, Batch 110/145, Loss: 0.2024
Epoch 4/10, Batch 120/145, Loss: 0.2727
Epoch 4/10, Batch 130/145, Loss: 0.1450
Epoch 4/10, Batch 140/145, Loss: 0.1748
Epoch 4/10, Train Loss: 0.2571, Valid Loss: 0.2575
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3366
Epoch 5/10, Batch 20/145, Loss: 0.1528
Epoch 5/10, Batch 30/145, Loss: 0.3742
Epoch 5/10, Batch 40/145, Loss: 0.0990
Epoch 5/10, Batch 50/145, Loss: 0.2145
Epoch 5/10, Batch 60/145, Loss: 0.1616
Epoch 5/10, Batch 70/145, Loss: 0.2471
Epoch 5/10, Batch 80/145, Loss: 0.2162
Epoch 5/10, Batch 90/145, Loss: 0.1624
Epoch 5/10, Batch 100/145, Loss: 0.1899
Epoch 5/10, Batch 110/145, Loss: 0.1925
Epoch 5/10, Batch 120/145, Loss: 0.3574
Epoch 5/10, Batch 130/145, Loss: 0.1641
Epoch 5/10, Batch 140/145, Loss: 0.1935
Epoch 5/10, Train Loss: 0.2482, Valid Loss: 0.2447
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1102
Epoch 6/10, Batch 20/145, Loss: 0.3923
Epoch 6/10, Batch 30/145, Loss: 0.3341
Epoch 6/10, Batch 40/145, Loss: 0.1967
Epoch 6/10, Batch 50/145, Loss: 0.3943
Epoch 6/10, Batch 60/145, Loss: 0.1342
Epoch 6/10, Batch 70/145, Loss: 0.1507
Epoch 6/10, Batch 80/145, Loss: 0.1583
Epoch 6/10, Batch 90/145, Loss: 0.3802
Epoch 6/10, Batch 100/145, Loss: 0.2094
Epoch 6/10, Batch 110/145, Loss: 0.2159
Epoch 6/10, Batch 120/145, Loss: 0.3169
Epoch 6/10, Batch 130/145, Loss: 0.2278
Epoch 6/10, Batch 140/145, Loss: 0.1892
Epoch 6/10, Train Loss: 0.2264, Valid Loss: 0.2339
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1357
Epoch 7/10, Batch 20/145, Loss: 0.3730
Epoch 7/10, Batch 30/145, Loss: 0.3426
Epoch 7/10, Batch 40/145, Loss: 0.2676
Epoch 7/10, Batch 50/145, Loss: 0.2661
Epoch 7/10, Batch 60/145, Loss: 0.3774
Epoch 7/10, Batch 70/145, Loss: 0.2349
Epoch 7/10, Batch 80/145, Loss: 0.3721
Epoch 7/10, Batch 90/145, Loss: 0.1293
Epoch 7/10, Batch 100/145, Loss: 0.1519
Epoch 7/10, Batch 110/145, Loss: 0.1317
Epoch 7/10, Batch 120/145, Loss: 0.1508
Epoch 7/10, Batch 130/145, Loss: 0.1345
Epoch 7/10, Batch 140/145, Loss: 0.2248
Epoch 7/10, Train Loss: 0.2170, Valid Loss: 0.2333
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1885
Epoch 8/10, Batch 20/145, Loss: 0.5501
Epoch 8/10, Batch 30/145, Loss: 0.1882
Epoch 8/10, Batch 40/145, Loss: 0.2537
Epoch 8/10, Batch 50/145, Loss: 0.4333
Epoch 8/10, Batch 60/145, Loss: 0.2433
Epoch 8/10, Batch 70/145, Loss: 0.2698
Epoch 8/10, Batch 80/145, Loss: 0.2141
Epoch 8/10, Batch 90/145, Loss: 0.2120
Epoch 8/10, Batch 100/145, Loss: 0.2659
Epoch 8/10, Batch 110/145, Loss: 0.1279
Epoch 8/10, Batch 120/145, Loss: 0.1338
Epoch 8/10, Batch 130/145, Loss: 0.2703
Epoch 8/10, Batch 140/145, Loss: 0.2531
Epoch 8/10, Train Loss: 0.2031, Valid Loss: 0.2223
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2665
Epoch 9/10, Batch 20/145, Loss: 0.2005
Epoch 9/10, Batch 30/145, Loss: 0.1547
Epoch 9/10, Batch 40/145, Loss: 0.1598
Epoch 9/10, Batch 50/145, Loss: 0.2211
Epoch 9/10, Batch 60/145, Loss: 0.2101
Epoch 9/10, Batch 70/145, Loss: 0.2518
Epoch 9/10, Batch 80/145, Loss: 0.2457
Epoch 9/10, Batch 90/145, Loss: 0.4095
Epoch 9/10, Batch 100/145, Loss: 0.1593
Epoch 9/10, Batch 110/145, Loss: 0.2245
Epoch 9/10, Batch 120/145, Loss: 0.1295
Epoch 9/10, Batch 130/145, Loss: 0.1440
Epoch 9/10, Batch 140/145, Loss: 0.1208
Epoch 9/10, Train Loss: 0.1965, Valid Loss: 0.2234
Epoch 10/10, Batch 10/145, Loss: 0.1051
Epoch 10/10, Batch 20/145, Loss: 0.2110
Epoch 10/10, Batch 30/145, Loss: 0.0826
Epoch 10/10, Batch 40/145, Loss: 0.1095
Epoch 10/10, Batch 50/145, Loss: 0.1923
Epoch 10/10, Batch 60/145, Loss: 0.1032
Epoch 10/10, Batch 70/145, Loss: 0.3006
Epoch 10/10, Batch 80/145, Loss: 0.2502
Epoch 10/10, Batch 90/145, Loss: 0.1182
Epoch 10/10, Batch 100/145, Loss: 0.1661
Epoch 10/10, Batch 110/145, Loss: 0.1892
Epoch 10/10, Batch 120/145, Loss: 0.1682
Epoch 10/10, Batch 130/145, Loss: 0.1184
Epoch 10/10, Batch 140/145, Loss: 0.1985
Epoch 10/10, Train Loss: 0.1878, Valid Loss: 0.2239
Accuracy: 0.9136
Precision: 0.9113
Recall: 0.9136
F1-score: 0.9119
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4349
Epoch 1/10, Batch 20/145, Loss: 0.9098
Epoch 1/10, Batch 30/145, Loss: 0.9434
Epoch 1/10, Batch 40/145, Loss: 0.7810
Epoch 1/10, Batch 50/145, Loss: 0.7890
Epoch 1/10, Batch 60/145, Loss: 0.7001
Epoch 1/10, Batch 70/145, Loss: 0.4264
Epoch 1/10, Batch 80/145, Loss: 0.7621
Epoch 1/10, Batch 90/145, Loss: 0.3190
Epoch 1/10, Batch 100/145, Loss: 0.4587
Epoch 1/10, Batch 110/145, Loss: 0.3718
Epoch 1/10, Batch 120/145, Loss: 0.5557
Epoch 1/10, Batch 130/145, Loss: 0.5491
Epoch 1/10, Batch 140/145, Loss: 0.5220
Epoch 1/10, Train Loss: 0.6822, Valid Loss: 0.3646
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3729
Epoch 2/10, Batch 20/145, Loss: 0.2634
Epoch 2/10, Batch 30/145, Loss: 0.2834
Epoch 2/10, Batch 40/145, Loss: 0.3863
Epoch 2/10, Batch 50/145, Loss: 0.4461
Epoch 2/10, Batch 60/145, Loss: 0.3633
Epoch 2/10, Batch 70/145, Loss: 0.3415
Epoch 2/10, Batch 80/145, Loss: 0.3462
Epoch 2/10, Batch 90/145, Loss: 0.2569
Epoch 2/10, Batch 100/145, Loss: 0.2789
Epoch 2/10, Batch 110/145, Loss: 0.3190
Epoch 2/10, Batch 120/145, Loss: 0.3811
Epoch 2/10, Batch 130/145, Loss: 0.2068
Epoch 2/10, Batch 140/145, Loss: 0.3773
Epoch 2/10, Train Loss: 0.3539, Valid Loss: 0.2738
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1607
Epoch 3/10, Batch 20/145, Loss: 0.4165
Epoch 3/10, Batch 30/145, Loss: 0.3540
Epoch 3/10, Batch 40/145, Loss: 0.1607
Epoch 3/10, Batch 50/145, Loss: 0.2449
Epoch 3/10, Batch 60/145, Loss: 0.3840
Epoch 3/10, Batch 70/145, Loss: 0.3175
Epoch 3/10, Batch 80/145, Loss: 0.2948
Epoch 3/10, Batch 90/145, Loss: 0.3414
Epoch 3/10, Batch 100/145, Loss: 0.2326
Epoch 3/10, Batch 110/145, Loss: 0.1235
Epoch 3/10, Batch 120/145, Loss: 0.2685
Epoch 3/10, Batch 130/145, Loss: 0.3452
Epoch 3/10, Batch 140/145, Loss: 0.2461
Epoch 3/10, Train Loss: 0.3017, Valid Loss: 0.2386
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4323
Epoch 4/10, Batch 20/145, Loss: 0.1553
Epoch 4/10, Batch 30/145, Loss: 0.2463
Epoch 4/10, Batch 40/145, Loss: 0.2271
Epoch 4/10, Batch 50/145, Loss: 0.3467
Epoch 4/10, Batch 60/145, Loss: 0.3296
Epoch 4/10, Batch 70/145, Loss: 0.2018
Epoch 4/10, Batch 80/145, Loss: 0.1787
Epoch 4/10, Batch 90/145, Loss: 0.2362
Epoch 4/10, Batch 100/145, Loss: 0.4413
Epoch 4/10, Batch 110/145, Loss: 0.2927
Epoch 4/10, Batch 120/145, Loss: 0.1709
Epoch 4/10, Batch 130/145, Loss: 0.1617
Epoch 4/10, Batch 140/145, Loss: 0.1119
Epoch 4/10, Train Loss: 0.2599, Valid Loss: 0.2269
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2194
Epoch 5/10, Batch 20/145, Loss: 0.2035
Epoch 5/10, Batch 30/145, Loss: 0.3507
Epoch 5/10, Batch 40/145, Loss: 0.1480
Epoch 5/10, Batch 50/145, Loss: 0.1721
Epoch 5/10, Batch 60/145, Loss: 0.3333
Epoch 5/10, Batch 70/145, Loss: 0.1002
Epoch 5/10, Batch 80/145, Loss: 0.0886
Epoch 5/10, Batch 90/145, Loss: 0.3966
Epoch 5/10, Batch 100/145, Loss: 0.1210
Epoch 5/10, Batch 110/145, Loss: 0.1074
Epoch 5/10, Batch 120/145, Loss: 0.4109
Epoch 5/10, Batch 130/145, Loss: 0.2340
Epoch 5/10, Batch 140/145, Loss: 0.2263
Epoch 5/10, Train Loss: 0.2497, Valid Loss: 0.2124
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1121
Epoch 6/10, Batch 20/145, Loss: 0.5693
Epoch 6/10, Batch 30/145, Loss: 0.4433
Epoch 6/10, Batch 40/145, Loss: 0.1797
Epoch 6/10, Batch 50/145, Loss: 0.2196
Epoch 6/10, Batch 60/145, Loss: 0.1906
Epoch 6/10, Batch 70/145, Loss: 0.1744
Epoch 6/10, Batch 80/145, Loss: 0.1137
Epoch 6/10, Batch 90/145, Loss: 0.2886
Epoch 6/10, Batch 100/145, Loss: 0.2801
Epoch 6/10, Batch 110/145, Loss: 0.1950
Epoch 6/10, Batch 120/145, Loss: 0.4597
Epoch 6/10, Batch 130/145, Loss: 0.2334
Epoch 6/10, Batch 140/145, Loss: 0.1505
Epoch 6/10, Train Loss: 0.2346, Valid Loss: 0.2048
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3042
Epoch 7/10, Batch 20/145, Loss: 0.5321
Epoch 7/10, Batch 30/145, Loss: 0.2322
Epoch 7/10, Batch 40/145, Loss: 0.2534
Epoch 7/10, Batch 50/145, Loss: 0.1944
Epoch 7/10, Batch 60/145, Loss: 0.1786
Epoch 7/10, Batch 70/145, Loss: 0.0936
Epoch 7/10, Batch 80/145, Loss: 0.3194
Epoch 7/10, Batch 90/145, Loss: 0.3120
Epoch 7/10, Batch 100/145, Loss: 0.3116
Epoch 7/10, Batch 110/145, Loss: 0.1819
Epoch 7/10, Batch 120/145, Loss: 0.3096
Epoch 7/10, Batch 130/145, Loss: 0.1677
Epoch 7/10, Batch 140/145, Loss: 0.3817
Epoch 7/10, Train Loss: 0.2225, Valid Loss: 0.1930
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1816
Epoch 8/10, Batch 20/145, Loss: 0.3240
Epoch 8/10, Batch 30/145, Loss: 0.2174
Epoch 8/10, Batch 40/145, Loss: 0.1854
Epoch 8/10, Batch 50/145, Loss: 0.1877
Epoch 8/10, Batch 60/145, Loss: 0.1819
Epoch 8/10, Batch 70/145, Loss: 0.1532
Epoch 8/10, Batch 80/145, Loss: 0.2709
Epoch 8/10, Batch 90/145, Loss: 0.2716
Epoch 8/10, Batch 100/145, Loss: 0.3545
Epoch 8/10, Batch 110/145, Loss: 0.2822
Epoch 8/10, Batch 120/145, Loss: 0.1746
Epoch 8/10, Batch 130/145, Loss: 0.0955
Epoch 8/10, Batch 140/145, Loss: 0.1643
Epoch 8/10, Train Loss: 0.2119, Valid Loss: 0.1904
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.4178
Epoch 9/10, Batch 20/145, Loss: 0.2186
Epoch 9/10, Batch 30/145, Loss: 0.2048
Epoch 9/10, Batch 40/145, Loss: 0.2900
Epoch 9/10, Batch 50/145, Loss: 0.1377
Epoch 9/10, Batch 60/145, Loss: 0.3017
Epoch 9/10, Batch 70/145, Loss: 0.2419
Epoch 9/10, Batch 80/145, Loss: 0.0703
Epoch 9/10, Batch 90/145, Loss: 0.1777
Epoch 9/10, Batch 100/145, Loss: 0.2118
Epoch 9/10, Batch 110/145, Loss: 0.1939
Epoch 9/10, Batch 120/145, Loss: 0.1524
Epoch 9/10, Batch 130/145, Loss: 0.1354
Epoch 9/10, Batch 140/145, Loss: 0.1924
Epoch 9/10, Train Loss: 0.2100, Valid Loss: 0.1908
Epoch 10/10, Batch 10/145, Loss: 0.1227
Epoch 10/10, Batch 20/145, Loss: 0.1442
Epoch 10/10, Batch 30/145, Loss: 0.1000
Epoch 10/10, Batch 40/145, Loss: 0.1716
Epoch 10/10, Batch 50/145, Loss: 0.2672
Epoch 10/10, Batch 60/145, Loss: 0.0778
Epoch 10/10, Batch 70/145, Loss: 0.1827
Epoch 10/10, Batch 80/145, Loss: 0.1547
Epoch 10/10, Batch 90/145, Loss: 0.0764
Epoch 10/10, Batch 100/145, Loss: 0.2524
Epoch 10/10, Batch 110/145, Loss: 0.1020
Epoch 10/10, Batch 120/145, Loss: 0.2034
Epoch 10/10, Batch 130/145, Loss: 0.2026
Epoch 10/10, Batch 140/145, Loss: 0.4004
Epoch 10/10, Train Loss: 0.1925, Valid Loss: 0.1811
Model saved!
Accuracy: 0.9182
Precision: 0.9162
Recall: 0.9182
F1-score: 0.9159
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 2. Fitness: 0.9182
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3598
Epoch 1/10, Batch 20/145, Loss: 0.9771
Epoch 1/10, Batch 30/145, Loss: 0.8492
Epoch 1/10, Batch 40/145, Loss: 0.8908
Epoch 1/10, Batch 50/145, Loss: 0.8344
Epoch 1/10, Batch 60/145, Loss: 0.6495
Epoch 1/10, Batch 70/145, Loss: 0.4730
Epoch 1/10, Batch 80/145, Loss: 0.5367
Epoch 1/10, Batch 90/145, Loss: 0.5342
Epoch 1/10, Batch 100/145, Loss: 0.5105
Epoch 1/10, Batch 110/145, Loss: 0.4858
Epoch 1/10, Batch 120/145, Loss: 0.6436
Epoch 1/10, Batch 130/145, Loss: 0.5491
Epoch 1/10, Batch 140/145, Loss: 0.3945
Epoch 1/10, Train Loss: 0.6679, Valid Loss: 0.3672
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4824
Epoch 2/10, Batch 20/145, Loss: 0.3700
Epoch 2/10, Batch 30/145, Loss: 0.2972
Epoch 2/10, Batch 40/145, Loss: 0.3700
Epoch 2/10, Batch 50/145, Loss: 0.3541
Epoch 2/10, Batch 60/145, Loss: 0.4634
Epoch 2/10, Batch 70/145, Loss: 0.3330
Epoch 2/10, Batch 80/145, Loss: 0.3546
Epoch 2/10, Batch 90/145, Loss: 0.4542
Epoch 2/10, Batch 100/145, Loss: 0.2898
Epoch 2/10, Batch 110/145, Loss: 0.2597
Epoch 2/10, Batch 120/145, Loss: 0.4323
Epoch 2/10, Batch 130/145, Loss: 0.3135
Epoch 2/10, Batch 140/145, Loss: 0.3322
Epoch 2/10, Train Loss: 0.3464, Valid Loss: 0.2927
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1652
Epoch 3/10, Batch 20/145, Loss: 0.2280
Epoch 3/10, Batch 30/145, Loss: 0.4459
Epoch 3/10, Batch 40/145, Loss: 0.2798
Epoch 3/10, Batch 50/145, Loss: 0.2619
Epoch 3/10, Batch 60/145, Loss: 0.2666
Epoch 3/10, Batch 70/145, Loss: 0.3744
Epoch 3/10, Batch 80/145, Loss: 0.1504
Epoch 3/10, Batch 90/145, Loss: 0.3288
Epoch 3/10, Batch 100/145, Loss: 0.3853
Epoch 3/10, Batch 110/145, Loss: 0.4073
Epoch 3/10, Batch 120/145, Loss: 0.2185
Epoch 3/10, Batch 130/145, Loss: 0.5136
Epoch 3/10, Batch 140/145, Loss: 0.2900
Epoch 3/10, Train Loss: 0.2864, Valid Loss: 0.2594
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2998
Epoch 4/10, Batch 20/145, Loss: 0.2148
Epoch 4/10, Batch 30/145, Loss: 0.3479
Epoch 4/10, Batch 40/145, Loss: 0.1471
Epoch 4/10, Batch 50/145, Loss: 0.3622
Epoch 4/10, Batch 60/145, Loss: 0.3621
Epoch 4/10, Batch 70/145, Loss: 0.2112
Epoch 4/10, Batch 80/145, Loss: 0.2603
Epoch 4/10, Batch 90/145, Loss: 0.1877
Epoch 4/10, Batch 100/145, Loss: 0.3435
Epoch 4/10, Batch 110/145, Loss: 0.2025
Epoch 4/10, Batch 120/145, Loss: 0.2156
Epoch 4/10, Batch 130/145, Loss: 0.1406
Epoch 4/10, Batch 140/145, Loss: 0.2214
Epoch 4/10, Train Loss: 0.2547, Valid Loss: 0.2528
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3680
Epoch 5/10, Batch 20/145, Loss: 0.1810
Epoch 5/10, Batch 30/145, Loss: 0.2027
Epoch 5/10, Batch 40/145, Loss: 0.1220
Epoch 5/10, Batch 50/145, Loss: 0.1817
Epoch 5/10, Batch 60/145, Loss: 0.1669
Epoch 5/10, Batch 70/145, Loss: 0.1662
Epoch 5/10, Batch 80/145, Loss: 0.1954
Epoch 5/10, Batch 90/145, Loss: 0.3201
Epoch 5/10, Batch 100/145, Loss: 0.3032
Epoch 5/10, Batch 110/145, Loss: 0.1381
Epoch 5/10, Batch 120/145, Loss: 0.2655
Epoch 5/10, Batch 130/145, Loss: 0.3683
Epoch 5/10, Batch 140/145, Loss: 0.2025
Epoch 5/10, Train Loss: 0.2375, Valid Loss: 0.2357
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.0932
Epoch 6/10, Batch 20/145, Loss: 0.3392
Epoch 6/10, Batch 30/145, Loss: 0.3492
Epoch 6/10, Batch 40/145, Loss: 0.1711
Epoch 6/10, Batch 50/145, Loss: 0.5095
Epoch 6/10, Batch 60/145, Loss: 0.1772
Epoch 6/10, Batch 70/145, Loss: 0.0901
Epoch 6/10, Batch 80/145, Loss: 0.2130
Epoch 6/10, Batch 90/145, Loss: 0.3376
Epoch 6/10, Batch 100/145, Loss: 0.3033
Epoch 6/10, Batch 110/145, Loss: 0.3404
Epoch 6/10, Batch 120/145, Loss: 0.1950
Epoch 6/10, Batch 130/145, Loss: 0.2537
Epoch 6/10, Batch 140/145, Loss: 0.2511
Epoch 6/10, Train Loss: 0.2237, Valid Loss: 0.2302
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1702
Epoch 7/10, Batch 20/145, Loss: 0.2721
Epoch 7/10, Batch 30/145, Loss: 0.0811
Epoch 7/10, Batch 40/145, Loss: 0.3949
Epoch 7/10, Batch 50/145, Loss: 0.1018
Epoch 7/10, Batch 60/145, Loss: 0.0821
Epoch 7/10, Batch 70/145, Loss: 0.1354
Epoch 7/10, Batch 80/145, Loss: 0.3539
Epoch 7/10, Batch 90/145, Loss: 0.1019
Epoch 7/10, Batch 100/145, Loss: 0.1494
Epoch 7/10, Batch 110/145, Loss: 0.0608
Epoch 7/10, Batch 120/145, Loss: 0.1566
Epoch 7/10, Batch 130/145, Loss: 0.2057
Epoch 7/10, Batch 140/145, Loss: 0.2325
Epoch 7/10, Train Loss: 0.2061, Valid Loss: 0.2255
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1938
Epoch 8/10, Batch 20/145, Loss: 0.1384
Epoch 8/10, Batch 30/145, Loss: 0.1092
Epoch 8/10, Batch 40/145, Loss: 0.2031
Epoch 8/10, Batch 50/145, Loss: 0.1308
Epoch 8/10, Batch 60/145, Loss: 0.2054
Epoch 8/10, Batch 70/145, Loss: 0.2028
Epoch 8/10, Batch 80/145, Loss: 0.2122
Epoch 8/10, Batch 90/145, Loss: 0.2264
Epoch 8/10, Batch 100/145, Loss: 0.1716
Epoch 8/10, Batch 110/145, Loss: 0.2556
Epoch 8/10, Batch 120/145, Loss: 0.2042
Epoch 8/10, Batch 130/145, Loss: 0.0662
Epoch 8/10, Batch 140/145, Loss: 0.2300
Epoch 8/10, Train Loss: 0.1968, Valid Loss: 0.2331
Epoch 9/10, Batch 10/145, Loss: 0.2416
Epoch 9/10, Batch 20/145, Loss: 0.2589
Epoch 9/10, Batch 30/145, Loss: 0.2613
Epoch 9/10, Batch 40/145, Loss: 0.1573
Epoch 9/10, Batch 50/145, Loss: 0.2530
Epoch 9/10, Batch 60/145, Loss: 0.2748
Epoch 9/10, Batch 70/145, Loss: 0.0723
Epoch 9/10, Batch 80/145, Loss: 0.0937
Epoch 9/10, Batch 90/145, Loss: 0.3002
Epoch 9/10, Batch 100/145, Loss: 0.1468
Epoch 9/10, Batch 110/145, Loss: 0.1599
Epoch 9/10, Batch 120/145, Loss: 0.1191
Epoch 9/10, Batch 130/145, Loss: 0.1704
Epoch 9/10, Batch 140/145, Loss: 0.2597
Epoch 9/10, Train Loss: 0.1933, Valid Loss: 0.2192
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1170
Epoch 10/10, Batch 20/145, Loss: 0.1810
Epoch 10/10, Batch 30/145, Loss: 0.1627
Epoch 10/10, Batch 40/145, Loss: 0.1306
Epoch 10/10, Batch 50/145, Loss: 0.2251
Epoch 10/10, Batch 60/145, Loss: 0.2335
Epoch 10/10, Batch 70/145, Loss: 0.2252
Epoch 10/10, Batch 80/145, Loss: 0.2437
Epoch 10/10, Batch 90/145, Loss: 0.0492
Epoch 10/10, Batch 100/145, Loss: 0.1075
Epoch 10/10, Batch 110/145, Loss: 0.1372
Epoch 10/10, Batch 120/145, Loss: 0.2394
Epoch 10/10, Batch 130/145, Loss: 0.1135
Epoch 10/10, Batch 140/145, Loss: 0.1047
Epoch 10/10, Train Loss: 0.1880, Valid Loss: 0.2133
Model saved!
Accuracy: 0.9241
Precision: 0.9219
Recall: 0.9241
F1-score: 0.9226
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 3. Fitness: 0.9241
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3691
Epoch 1/10, Batch 20/145, Loss: 0.8962
Epoch 1/10, Batch 30/145, Loss: 0.8451
Epoch 1/10, Batch 40/145, Loss: 0.9330
Epoch 1/10, Batch 50/145, Loss: 0.7562
Epoch 1/10, Batch 60/145, Loss: 0.5919
Epoch 1/10, Batch 70/145, Loss: 0.4585
Epoch 1/10, Batch 80/145, Loss: 0.6475
Epoch 1/10, Batch 90/145, Loss: 0.3899
Epoch 1/10, Batch 100/145, Loss: 0.4719
Epoch 1/10, Batch 110/145, Loss: 0.4555
Epoch 1/10, Batch 120/145, Loss: 0.6275
Epoch 1/10, Batch 130/145, Loss: 0.5294
Epoch 1/10, Batch 140/145, Loss: 0.3451
Epoch 1/10, Train Loss: 0.6758, Valid Loss: 0.3962
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3310
Epoch 2/10, Batch 20/145, Loss: 0.3769
Epoch 2/10, Batch 30/145, Loss: 0.3511
Epoch 2/10, Batch 40/145, Loss: 0.4535
Epoch 2/10, Batch 50/145, Loss: 0.3296
Epoch 2/10, Batch 60/145, Loss: 0.3800
Epoch 2/10, Batch 70/145, Loss: 0.4531
Epoch 2/10, Batch 80/145, Loss: 0.3239
Epoch 2/10, Batch 90/145, Loss: 0.3821
Epoch 2/10, Batch 100/145, Loss: 0.3943
Epoch 2/10, Batch 110/145, Loss: 0.3510
Epoch 2/10, Batch 120/145, Loss: 0.2896
Epoch 2/10, Batch 130/145, Loss: 0.3524
Epoch 2/10, Batch 140/145, Loss: 0.2223
Epoch 2/10, Train Loss: 0.3533, Valid Loss: 0.3262
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1827
Epoch 3/10, Batch 20/145, Loss: 0.3987
Epoch 3/10, Batch 30/145, Loss: 0.3093
Epoch 3/10, Batch 40/145, Loss: 0.2805
Epoch 3/10, Batch 50/145, Loss: 0.1946
Epoch 3/10, Batch 60/145, Loss: 0.4581
Epoch 3/10, Batch 70/145, Loss: 0.4438
Epoch 3/10, Batch 80/145, Loss: 0.1885
Epoch 3/10, Batch 90/145, Loss: 0.2319
Epoch 3/10, Batch 100/145, Loss: 0.1959
Epoch 3/10, Batch 110/145, Loss: 0.1571
Epoch 3/10, Batch 120/145, Loss: 0.4018
Epoch 3/10, Batch 130/145, Loss: 0.3050
Epoch 3/10, Batch 140/145, Loss: 0.3296
Epoch 3/10, Train Loss: 0.2897, Valid Loss: 0.2916
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3434
Epoch 4/10, Batch 20/145, Loss: 0.2509
Epoch 4/10, Batch 30/145, Loss: 0.2682
Epoch 4/10, Batch 40/145, Loss: 0.1877
Epoch 4/10, Batch 50/145, Loss: 0.1006
Epoch 4/10, Batch 60/145, Loss: 0.2630
Epoch 4/10, Batch 70/145, Loss: 0.1744
Epoch 4/10, Batch 80/145, Loss: 0.3726
Epoch 4/10, Batch 90/145, Loss: 0.3473
Epoch 4/10, Batch 100/145, Loss: 0.3422
Epoch 4/10, Batch 110/145, Loss: 0.1993
Epoch 4/10, Batch 120/145, Loss: 0.3336
Epoch 4/10, Batch 130/145, Loss: 0.2757
Epoch 4/10, Batch 140/145, Loss: 0.2147
Epoch 4/10, Train Loss: 0.2569, Valid Loss: 0.2766
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1804
Epoch 5/10, Batch 20/145, Loss: 0.2038
Epoch 5/10, Batch 30/145, Loss: 0.1954
Epoch 5/10, Batch 40/145, Loss: 0.2621
Epoch 5/10, Batch 50/145, Loss: 0.3009
Epoch 5/10, Batch 60/145, Loss: 0.3273
Epoch 5/10, Batch 70/145, Loss: 0.1945
Epoch 5/10, Batch 80/145, Loss: 0.2250
Epoch 5/10, Batch 90/145, Loss: 0.2549
Epoch 5/10, Batch 100/145, Loss: 0.2686
Epoch 5/10, Batch 110/145, Loss: 0.2062
Epoch 5/10, Batch 120/145, Loss: 0.3270
Epoch 5/10, Batch 130/145, Loss: 0.0898
Epoch 5/10, Batch 140/145, Loss: 0.1790
Epoch 5/10, Train Loss: 0.2437, Valid Loss: 0.2676
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1314
Epoch 6/10, Batch 20/145, Loss: 0.3903
Epoch 6/10, Batch 30/145, Loss: 0.2808
Epoch 6/10, Batch 40/145, Loss: 0.1698
Epoch 6/10, Batch 50/145, Loss: 0.4712
Epoch 6/10, Batch 60/145, Loss: 0.2571
Epoch 6/10, Batch 70/145, Loss: 0.1821
Epoch 6/10, Batch 80/145, Loss: 0.2084
Epoch 6/10, Batch 90/145, Loss: 0.3454
Epoch 6/10, Batch 100/145, Loss: 0.2446
Epoch 6/10, Batch 110/145, Loss: 0.2615
Epoch 6/10, Batch 120/145, Loss: 0.4209
Epoch 6/10, Batch 130/145, Loss: 0.1486
Epoch 6/10, Batch 140/145, Loss: 0.1114
Epoch 6/10, Train Loss: 0.2231, Valid Loss: 0.2680
Epoch 7/10, Batch 10/145, Loss: 0.2477
Epoch 7/10, Batch 20/145, Loss: 0.2680
Epoch 7/10, Batch 30/145, Loss: 0.1353
Epoch 7/10, Batch 40/145, Loss: 0.2046
Epoch 7/10, Batch 50/145, Loss: 0.1687
Epoch 7/10, Batch 60/145, Loss: 0.0926
Epoch 7/10, Batch 70/145, Loss: 0.2075
Epoch 7/10, Batch 80/145, Loss: 0.2146
Epoch 7/10, Batch 90/145, Loss: 0.3580
Epoch 7/10, Batch 100/145, Loss: 0.1067
Epoch 7/10, Batch 110/145, Loss: 0.1631
Epoch 7/10, Batch 120/145, Loss: 0.2267
Epoch 7/10, Batch 130/145, Loss: 0.1089
Epoch 7/10, Batch 140/145, Loss: 0.3394
Epoch 7/10, Train Loss: 0.2188, Valid Loss: 0.2611
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1080
Epoch 8/10, Batch 20/145, Loss: 0.1436
Epoch 8/10, Batch 30/145, Loss: 0.2907
Epoch 8/10, Batch 40/145, Loss: 0.1882
Epoch 8/10, Batch 50/145, Loss: 0.1973
Epoch 8/10, Batch 60/145, Loss: 0.2403
Epoch 8/10, Batch 70/145, Loss: 0.2482
Epoch 8/10, Batch 80/145, Loss: 0.1110
Epoch 8/10, Batch 90/145, Loss: 0.1868
Epoch 8/10, Batch 100/145, Loss: 0.2675
Epoch 8/10, Batch 110/145, Loss: 0.1485
Epoch 8/10, Batch 120/145, Loss: 0.1198
Epoch 8/10, Batch 130/145, Loss: 0.1560
Epoch 8/10, Batch 140/145, Loss: 0.1420
Epoch 8/10, Train Loss: 0.2008, Valid Loss: 0.2546
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3171
Epoch 9/10, Batch 20/145, Loss: 0.1227
Epoch 9/10, Batch 30/145, Loss: 0.2783
Epoch 9/10, Batch 40/145, Loss: 0.1383
Epoch 9/10, Batch 50/145, Loss: 0.1435
Epoch 9/10, Batch 60/145, Loss: 0.1355
Epoch 9/10, Batch 70/145, Loss: 0.1697
Epoch 9/10, Batch 80/145, Loss: 0.1123
Epoch 9/10, Batch 90/145, Loss: 0.2092
Epoch 9/10, Batch 100/145, Loss: 0.1044
Epoch 9/10, Batch 110/145, Loss: 0.3750
Epoch 9/10, Batch 120/145, Loss: 0.0780
Epoch 9/10, Batch 130/145, Loss: 0.0948
Epoch 9/10, Batch 140/145, Loss: 0.2073
Epoch 9/10, Train Loss: 0.1948, Valid Loss: 0.2553
Epoch 10/10, Batch 10/145, Loss: 0.1038
Epoch 10/10, Batch 20/145, Loss: 0.0815
Epoch 10/10, Batch 30/145, Loss: 0.0822
Epoch 10/10, Batch 40/145, Loss: 0.0941
Epoch 10/10, Batch 50/145, Loss: 0.2046
Epoch 10/10, Batch 60/145, Loss: 0.1178
Epoch 10/10, Batch 70/145, Loss: 0.2256
Epoch 10/10, Batch 80/145, Loss: 0.1925
Epoch 10/10, Batch 90/145, Loss: 0.1073
Epoch 10/10, Batch 100/145, Loss: 0.1715
Epoch 10/10, Batch 110/145, Loss: 0.2088
Epoch 10/10, Batch 120/145, Loss: 0.1690
Epoch 10/10, Batch 130/145, Loss: 0.1814
Epoch 10/10, Batch 140/145, Loss: 0.1469
Epoch 10/10, Train Loss: 0.1886, Valid Loss: 0.2543
Model saved!
Accuracy: 0.9194
Precision: 0.9164
Recall: 0.9194
F1-score: 0.9174
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3291
Epoch 1/10, Batch 20/145, Loss: 0.9290
Epoch 1/10, Batch 30/145, Loss: 0.8570
Epoch 1/10, Batch 40/145, Loss: 0.7812
Epoch 1/10, Batch 50/145, Loss: 0.6407
Epoch 1/10, Batch 60/145, Loss: 0.6351
Epoch 1/10, Batch 70/145, Loss: 0.4843
Epoch 1/10, Batch 80/145, Loss: 0.6031
Epoch 1/10, Batch 90/145, Loss: 0.4394
Epoch 1/10, Batch 100/145, Loss: 0.4133
Epoch 1/10, Batch 110/145, Loss: 0.3577
Epoch 1/10, Batch 120/145, Loss: 0.5808
Epoch 1/10, Batch 130/145, Loss: 0.4437
Epoch 1/10, Batch 140/145, Loss: 0.3519
Epoch 1/10, Train Loss: 0.6757, Valid Loss: 0.3754
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2935
Epoch 2/10, Batch 20/145, Loss: 0.3535
Epoch 2/10, Batch 30/145, Loss: 0.2921
Epoch 2/10, Batch 40/145, Loss: 0.5009
Epoch 2/10, Batch 50/145, Loss: 0.2932
Epoch 2/10, Batch 60/145, Loss: 0.4001
Epoch 2/10, Batch 70/145, Loss: 0.2863
Epoch 2/10, Batch 80/145, Loss: 0.2741
Epoch 2/10, Batch 90/145, Loss: 0.3381
Epoch 2/10, Batch 100/145, Loss: 0.2689
Epoch 2/10, Batch 110/145, Loss: 0.2964
Epoch 2/10, Batch 120/145, Loss: 0.2414
Epoch 2/10, Batch 130/145, Loss: 0.2633
Epoch 2/10, Batch 140/145, Loss: 0.4190
Epoch 2/10, Train Loss: 0.3480, Valid Loss: 0.2907
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1841
Epoch 3/10, Batch 20/145, Loss: 0.1949
Epoch 3/10, Batch 30/145, Loss: 0.2676
Epoch 3/10, Batch 40/145, Loss: 0.2020
Epoch 3/10, Batch 50/145, Loss: 0.3456
Epoch 3/10, Batch 60/145, Loss: 0.2805
Epoch 3/10, Batch 70/145, Loss: 0.2256
Epoch 3/10, Batch 80/145, Loss: 0.3180
Epoch 3/10, Batch 90/145, Loss: 0.2195
Epoch 3/10, Batch 100/145, Loss: 0.1944
Epoch 3/10, Batch 110/145, Loss: 0.3348
Epoch 3/10, Batch 120/145, Loss: 0.1801
Epoch 3/10, Batch 130/145, Loss: 0.5092
Epoch 3/10, Batch 140/145, Loss: 0.3201
Epoch 3/10, Train Loss: 0.2894, Valid Loss: 0.2592
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2494
Epoch 4/10, Batch 20/145, Loss: 0.2898
Epoch 4/10, Batch 30/145, Loss: 0.3576
Epoch 4/10, Batch 40/145, Loss: 0.1914
Epoch 4/10, Batch 50/145, Loss: 0.2679
Epoch 4/10, Batch 60/145, Loss: 0.3297
Epoch 4/10, Batch 70/145, Loss: 0.1449
Epoch 4/10, Batch 80/145, Loss: 0.1805
Epoch 4/10, Batch 90/145, Loss: 0.2629
Epoch 4/10, Batch 100/145, Loss: 0.2543
Epoch 4/10, Batch 110/145, Loss: 0.2189
Epoch 4/10, Batch 120/145, Loss: 0.2304
Epoch 4/10, Batch 130/145, Loss: 0.3582
Epoch 4/10, Batch 140/145, Loss: 0.1018
Epoch 4/10, Train Loss: 0.2514, Valid Loss: 0.2418
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1743
Epoch 5/10, Batch 20/145, Loss: 0.0876
Epoch 5/10, Batch 30/145, Loss: 0.2064
Epoch 5/10, Batch 40/145, Loss: 0.1708
Epoch 5/10, Batch 50/145, Loss: 0.2550
Epoch 5/10, Batch 60/145, Loss: 0.2315
Epoch 5/10, Batch 70/145, Loss: 0.2422
Epoch 5/10, Batch 80/145, Loss: 0.2231
Epoch 5/10, Batch 90/145, Loss: 0.1605
Epoch 5/10, Batch 100/145, Loss: 0.2961
Epoch 5/10, Batch 110/145, Loss: 0.3316
Epoch 5/10, Batch 120/145, Loss: 0.3935
Epoch 5/10, Batch 130/145, Loss: 0.1762
Epoch 5/10, Batch 140/145, Loss: 0.1670
Epoch 5/10, Train Loss: 0.2392, Valid Loss: 0.2311
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2141
Epoch 6/10, Batch 20/145, Loss: 0.4299
Epoch 6/10, Batch 30/145, Loss: 0.2880
Epoch 6/10, Batch 40/145, Loss: 0.1158
Epoch 6/10, Batch 50/145, Loss: 0.4841
Epoch 6/10, Batch 60/145, Loss: 0.1791
Epoch 6/10, Batch 70/145, Loss: 0.1733
Epoch 6/10, Batch 80/145, Loss: 0.4394
Epoch 6/10, Batch 90/145, Loss: 0.3703
Epoch 6/10, Batch 100/145, Loss: 0.2918
Epoch 6/10, Batch 110/145, Loss: 0.1490
Epoch 6/10, Batch 120/145, Loss: 0.1435
Epoch 6/10, Batch 130/145, Loss: 0.1608
Epoch 6/10, Batch 140/145, Loss: 0.2528
Epoch 6/10, Train Loss: 0.2244, Valid Loss: 0.2249
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2946
Epoch 7/10, Batch 20/145, Loss: 0.3268
Epoch 7/10, Batch 30/145, Loss: 0.3995
Epoch 7/10, Batch 40/145, Loss: 0.3294
Epoch 7/10, Batch 50/145, Loss: 0.2878
Epoch 7/10, Batch 60/145, Loss: 0.1062
Epoch 7/10, Batch 70/145, Loss: 0.1517
Epoch 7/10, Batch 80/145, Loss: 0.1996
Epoch 7/10, Batch 90/145, Loss: 0.1796
Epoch 7/10, Batch 100/145, Loss: 0.2805
Epoch 7/10, Batch 110/145, Loss: 0.1230
Epoch 7/10, Batch 120/145, Loss: 0.2176
Epoch 7/10, Batch 130/145, Loss: 0.1384
Epoch 7/10, Batch 140/145, Loss: 0.2246
Epoch 7/10, Train Loss: 0.2086, Valid Loss: 0.2209
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1807
Epoch 8/10, Batch 20/145, Loss: 0.2513
Epoch 8/10, Batch 30/145, Loss: 0.2902
Epoch 8/10, Batch 40/145, Loss: 0.0898
Epoch 8/10, Batch 50/145, Loss: 0.1715
Epoch 8/10, Batch 60/145, Loss: 0.1499
Epoch 8/10, Batch 70/145, Loss: 0.1367
Epoch 8/10, Batch 80/145, Loss: 0.2631
Epoch 8/10, Batch 90/145, Loss: 0.3848
Epoch 8/10, Batch 100/145, Loss: 0.1961
Epoch 8/10, Batch 110/145, Loss: 0.2270
Epoch 8/10, Batch 120/145, Loss: 0.2794
Epoch 8/10, Batch 130/145, Loss: 0.1173
Epoch 8/10, Batch 140/145, Loss: 0.1629
Epoch 8/10, Train Loss: 0.2050, Valid Loss: 0.2162
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3313
Epoch 9/10, Batch 20/145, Loss: 0.1565
Epoch 9/10, Batch 30/145, Loss: 0.2428
Epoch 9/10, Batch 40/145, Loss: 0.1700
Epoch 9/10, Batch 50/145, Loss: 0.1432
Epoch 9/10, Batch 60/145, Loss: 0.2917
Epoch 9/10, Batch 70/145, Loss: 0.1949
Epoch 9/10, Batch 80/145, Loss: 0.1952
Epoch 9/10, Batch 90/145, Loss: 0.3648
Epoch 9/10, Batch 100/145, Loss: 0.1534
Epoch 9/10, Batch 110/145, Loss: 0.1767
Epoch 9/10, Batch 120/145, Loss: 0.0532
Epoch 9/10, Batch 130/145, Loss: 0.1973
Epoch 9/10, Batch 140/145, Loss: 0.3311
Epoch 9/10, Train Loss: 0.1920, Valid Loss: 0.2149
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1588
Epoch 10/10, Batch 20/145, Loss: 0.1597
Epoch 10/10, Batch 30/145, Loss: 0.1018
Epoch 10/10, Batch 40/145, Loss: 0.1753
Epoch 10/10, Batch 50/145, Loss: 0.2647
Epoch 10/10, Batch 60/145, Loss: 0.0926
Epoch 10/10, Batch 70/145, Loss: 0.1904
Epoch 10/10, Batch 80/145, Loss: 0.1345
Epoch 10/10, Batch 90/145, Loss: 0.1681
Epoch 10/10, Batch 100/145, Loss: 0.2109
Epoch 10/10, Batch 110/145, Loss: 0.2187
Epoch 10/10, Batch 120/145, Loss: 0.1141
Epoch 10/10, Batch 130/145, Loss: 0.0772
Epoch 10/10, Batch 140/145, Loss: 0.1781
Epoch 10/10, Train Loss: 0.1908, Valid Loss: 0.2125
Model saved!
Accuracy: 0.9229
Precision: 0.9212
Recall: 0.9229
F1-score: 0.9207
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3986
Epoch 1/10, Batch 20/145, Loss: 0.9567
Epoch 1/10, Batch 30/145, Loss: 0.9989
Epoch 1/10, Batch 40/145, Loss: 0.7985
Epoch 1/10, Batch 50/145, Loss: 0.7186
Epoch 1/10, Batch 60/145, Loss: 0.5855
Epoch 1/10, Batch 70/145, Loss: 0.5550
Epoch 1/10, Batch 80/145, Loss: 0.4319
Epoch 1/10, Batch 90/145, Loss: 0.4694
Epoch 1/10, Batch 100/145, Loss: 0.4813
Epoch 1/10, Batch 110/145, Loss: 0.4893
Epoch 1/10, Batch 120/145, Loss: 0.4477
Epoch 1/10, Batch 130/145, Loss: 0.4895
Epoch 1/10, Batch 140/145, Loss: 0.3078
Epoch 1/10, Train Loss: 0.6748, Valid Loss: 0.3588
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4102
Epoch 2/10, Batch 20/145, Loss: 0.3063
Epoch 2/10, Batch 30/145, Loss: 0.2730
Epoch 2/10, Batch 40/145, Loss: 0.4285
Epoch 2/10, Batch 50/145, Loss: 0.2741
Epoch 2/10, Batch 60/145, Loss: 0.3466
Epoch 2/10, Batch 70/145, Loss: 0.3661
Epoch 2/10, Batch 80/145, Loss: 0.3394
Epoch 2/10, Batch 90/145, Loss: 0.2974
Epoch 2/10, Batch 100/145, Loss: 0.3011
Epoch 2/10, Batch 110/145, Loss: 0.3476
Epoch 2/10, Batch 120/145, Loss: 0.3395
Epoch 2/10, Batch 130/145, Loss: 0.3328
Epoch 2/10, Batch 140/145, Loss: 0.2269
Epoch 2/10, Train Loss: 0.3525, Valid Loss: 0.2829
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1717
Epoch 3/10, Batch 20/145, Loss: 0.3012
Epoch 3/10, Batch 30/145, Loss: 0.2614
Epoch 3/10, Batch 40/145, Loss: 0.1779
Epoch 3/10, Batch 50/145, Loss: 0.1713
Epoch 3/10, Batch 60/145, Loss: 0.3049
Epoch 3/10, Batch 70/145, Loss: 0.4895
Epoch 3/10, Batch 80/145, Loss: 0.1852
Epoch 3/10, Batch 90/145, Loss: 0.2066
Epoch 3/10, Batch 100/145, Loss: 0.2448
Epoch 3/10, Batch 110/145, Loss: 0.2025
Epoch 3/10, Batch 120/145, Loss: 0.1561
Epoch 3/10, Batch 130/145, Loss: 0.3706
Epoch 3/10, Batch 140/145, Loss: 0.2754
Epoch 3/10, Train Loss: 0.2868, Valid Loss: 0.2570
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3324
Epoch 4/10, Batch 20/145, Loss: 0.3612
Epoch 4/10, Batch 30/145, Loss: 0.3778
Epoch 4/10, Batch 40/145, Loss: 0.1454
Epoch 4/10, Batch 50/145, Loss: 0.1059
Epoch 4/10, Batch 60/145, Loss: 0.2710
Epoch 4/10, Batch 70/145, Loss: 0.2509
Epoch 4/10, Batch 80/145, Loss: 0.2375
Epoch 4/10, Batch 90/145, Loss: 0.2428
Epoch 4/10, Batch 100/145, Loss: 0.3744
Epoch 4/10, Batch 110/145, Loss: 0.1323
Epoch 4/10, Batch 120/145, Loss: 0.2703
Epoch 4/10, Batch 130/145, Loss: 0.1592
Epoch 4/10, Batch 140/145, Loss: 0.1333
Epoch 4/10, Train Loss: 0.2548, Valid Loss: 0.2333
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1858
Epoch 5/10, Batch 20/145, Loss: 0.3571
Epoch 5/10, Batch 30/145, Loss: 0.2730
Epoch 5/10, Batch 40/145, Loss: 0.1391
Epoch 5/10, Batch 50/145, Loss: 0.1749
Epoch 5/10, Batch 60/145, Loss: 0.2616
Epoch 5/10, Batch 70/145, Loss: 0.1687
Epoch 5/10, Batch 80/145, Loss: 0.1796
Epoch 5/10, Batch 90/145, Loss: 0.2832
Epoch 5/10, Batch 100/145, Loss: 0.1602
Epoch 5/10, Batch 110/145, Loss: 0.1489
Epoch 5/10, Batch 120/145, Loss: 0.3625
Epoch 5/10, Batch 130/145, Loss: 0.1764
Epoch 5/10, Batch 140/145, Loss: 0.1620
Epoch 5/10, Train Loss: 0.2453, Valid Loss: 0.2280
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1312
Epoch 6/10, Batch 20/145, Loss: 0.3117
Epoch 6/10, Batch 30/145, Loss: 0.3314
Epoch 6/10, Batch 40/145, Loss: 0.1836
Epoch 6/10, Batch 50/145, Loss: 0.4303
Epoch 6/10, Batch 60/145, Loss: 0.2233
Epoch 6/10, Batch 70/145, Loss: 0.0940
Epoch 6/10, Batch 80/145, Loss: 0.2941
Epoch 6/10, Batch 90/145, Loss: 0.2275
Epoch 6/10, Batch 100/145, Loss: 0.4320
Epoch 6/10, Batch 110/145, Loss: 0.1306
Epoch 6/10, Batch 120/145, Loss: 0.2561
Epoch 6/10, Batch 130/145, Loss: 0.1497
Epoch 6/10, Batch 140/145, Loss: 0.1456
Epoch 6/10, Train Loss: 0.2260, Valid Loss: 0.2165
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1282
Epoch 7/10, Batch 20/145, Loss: 0.2408
Epoch 7/10, Batch 30/145, Loss: 0.2677
Epoch 7/10, Batch 40/145, Loss: 0.2318
Epoch 7/10, Batch 50/145, Loss: 0.1100
Epoch 7/10, Batch 60/145, Loss: 0.1441
Epoch 7/10, Batch 70/145, Loss: 0.2545
Epoch 7/10, Batch 80/145, Loss: 0.2739
Epoch 7/10, Batch 90/145, Loss: 0.0809
Epoch 7/10, Batch 100/145, Loss: 0.1519
Epoch 7/10, Batch 110/145, Loss: 0.1760
Epoch 7/10, Batch 120/145, Loss: 0.2320
Epoch 7/10, Batch 130/145, Loss: 0.1399
Epoch 7/10, Batch 140/145, Loss: 0.1415
Epoch 7/10, Train Loss: 0.2114, Valid Loss: 0.2096
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2742
Epoch 8/10, Batch 20/145, Loss: 0.1037
Epoch 8/10, Batch 30/145, Loss: 0.2299
Epoch 8/10, Batch 40/145, Loss: 0.2836
Epoch 8/10, Batch 50/145, Loss: 0.1174
Epoch 8/10, Batch 60/145, Loss: 0.2006
Epoch 8/10, Batch 70/145, Loss: 0.2531
Epoch 8/10, Batch 80/145, Loss: 0.2849
Epoch 8/10, Batch 90/145, Loss: 0.4371
Epoch 8/10, Batch 100/145, Loss: 0.0991
Epoch 8/10, Batch 110/145, Loss: 0.2133
Epoch 8/10, Batch 120/145, Loss: 0.1882
Epoch 8/10, Batch 130/145, Loss: 0.1600
Epoch 8/10, Batch 140/145, Loss: 0.2505
Epoch 8/10, Train Loss: 0.2073, Valid Loss: 0.2052
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3214
Epoch 9/10, Batch 20/145, Loss: 0.1938
Epoch 9/10, Batch 30/145, Loss: 0.1805
Epoch 9/10, Batch 40/145, Loss: 0.2889
Epoch 9/10, Batch 50/145, Loss: 0.2654
Epoch 9/10, Batch 60/145, Loss: 0.1935
Epoch 9/10, Batch 70/145, Loss: 0.0866
Epoch 9/10, Batch 80/145, Loss: 0.0421
Epoch 9/10, Batch 90/145, Loss: 0.1535
Epoch 9/10, Batch 100/145, Loss: 0.1203
Epoch 9/10, Batch 110/145, Loss: 0.1949
Epoch 9/10, Batch 120/145, Loss: 0.0739
Epoch 9/10, Batch 130/145, Loss: 0.1807
Epoch 9/10, Batch 140/145, Loss: 0.1951
Epoch 9/10, Train Loss: 0.1968, Valid Loss: 0.2073
Epoch 10/10, Batch 10/145, Loss: 0.0833
Epoch 10/10, Batch 20/145, Loss: 0.2630
Epoch 10/10, Batch 30/145, Loss: 0.1107
Epoch 10/10, Batch 40/145, Loss: 0.0973
Epoch 10/10, Batch 50/145, Loss: 0.1944
Epoch 10/10, Batch 60/145, Loss: 0.1761
Epoch 10/10, Batch 70/145, Loss: 0.3150
Epoch 10/10, Batch 80/145, Loss: 0.2471
Epoch 10/10, Batch 90/145, Loss: 0.2025
Epoch 10/10, Batch 100/145, Loss: 0.2156
Epoch 10/10, Batch 110/145, Loss: 0.4188
Epoch 10/10, Batch 120/145, Loss: 0.1775
Epoch 10/10, Batch 130/145, Loss: 0.1024
Epoch 10/10, Batch 140/145, Loss: 0.1884
Epoch 10/10, Train Loss: 0.1970, Valid Loss: 0.2005
Model saved!
Accuracy: 0.9194
Precision: 0.9173
Recall: 0.9194
F1-score: 0.9168
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3969
Epoch 1/10, Batch 20/145, Loss: 1.0104
Epoch 1/10, Batch 30/145, Loss: 0.8843
Epoch 1/10, Batch 40/145, Loss: 0.8211
Epoch 1/10, Batch 50/145, Loss: 0.6544
Epoch 1/10, Batch 60/145, Loss: 0.5877
Epoch 1/10, Batch 70/145, Loss: 0.3541
Epoch 1/10, Batch 80/145, Loss: 0.5723
Epoch 1/10, Batch 90/145, Loss: 0.3069
Epoch 1/10, Batch 100/145, Loss: 0.4848
Epoch 1/10, Batch 110/145, Loss: 0.3036
Epoch 1/10, Batch 120/145, Loss: 0.6054
Epoch 1/10, Batch 130/145, Loss: 0.4476
Epoch 1/10, Batch 140/145, Loss: 0.5010
Epoch 1/10, Train Loss: 0.6721, Valid Loss: 0.3737
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3216
Epoch 2/10, Batch 20/145, Loss: 0.3508
Epoch 2/10, Batch 30/145, Loss: 0.3450
Epoch 2/10, Batch 40/145, Loss: 0.4007
Epoch 2/10, Batch 50/145, Loss: 0.4056
Epoch 2/10, Batch 60/145, Loss: 0.3408
Epoch 2/10, Batch 70/145, Loss: 0.2974
Epoch 2/10, Batch 80/145, Loss: 0.2558
Epoch 2/10, Batch 90/145, Loss: 0.2844
Epoch 2/10, Batch 100/145, Loss: 0.2877
Epoch 2/10, Batch 110/145, Loss: 0.3806
Epoch 2/10, Batch 120/145, Loss: 0.5533
Epoch 2/10, Batch 130/145, Loss: 0.2676
Epoch 2/10, Batch 140/145, Loss: 0.2022
Epoch 2/10, Train Loss: 0.3490, Valid Loss: 0.2955
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3624
Epoch 3/10, Batch 20/145, Loss: 0.2802
Epoch 3/10, Batch 30/145, Loss: 0.3574
Epoch 3/10, Batch 40/145, Loss: 0.1562
Epoch 3/10, Batch 50/145, Loss: 0.2177
Epoch 3/10, Batch 60/145, Loss: 0.2876
Epoch 3/10, Batch 70/145, Loss: 0.3792
Epoch 3/10, Batch 80/145, Loss: 0.2797
Epoch 3/10, Batch 90/145, Loss: 0.2772
Epoch 3/10, Batch 100/145, Loss: 0.3734
Epoch 3/10, Batch 110/145, Loss: 0.5671
Epoch 3/10, Batch 120/145, Loss: 0.2520
Epoch 3/10, Batch 130/145, Loss: 0.2841
Epoch 3/10, Batch 140/145, Loss: 0.1882
Epoch 3/10, Train Loss: 0.2909, Valid Loss: 0.2603
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4191
Epoch 4/10, Batch 20/145, Loss: 0.1873
Epoch 4/10, Batch 30/145, Loss: 0.2061
Epoch 4/10, Batch 40/145, Loss: 0.1482
Epoch 4/10, Batch 50/145, Loss: 0.1872
Epoch 4/10, Batch 60/145, Loss: 0.2265
Epoch 4/10, Batch 70/145, Loss: 0.1975
Epoch 4/10, Batch 80/145, Loss: 0.1498
Epoch 4/10, Batch 90/145, Loss: 0.2117
Epoch 4/10, Batch 100/145, Loss: 0.1846
Epoch 4/10, Batch 110/145, Loss: 0.2083
Epoch 4/10, Batch 120/145, Loss: 0.2413
Epoch 4/10, Batch 130/145, Loss: 0.2739
Epoch 4/10, Batch 140/145, Loss: 0.1349
Epoch 4/10, Train Loss: 0.2598, Valid Loss: 0.2475
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1366
Epoch 5/10, Batch 20/145, Loss: 0.1756
Epoch 5/10, Batch 30/145, Loss: 0.2487
Epoch 5/10, Batch 40/145, Loss: 0.1214
Epoch 5/10, Batch 50/145, Loss: 0.1553
Epoch 5/10, Batch 60/145, Loss: 0.2485
Epoch 5/10, Batch 70/145, Loss: 0.1831
Epoch 5/10, Batch 80/145, Loss: 0.2098
Epoch 5/10, Batch 90/145, Loss: 0.3105
Epoch 5/10, Batch 100/145, Loss: 0.3776
Epoch 5/10, Batch 110/145, Loss: 0.2424
Epoch 5/10, Batch 120/145, Loss: 0.2796
Epoch 5/10, Batch 130/145, Loss: 0.1960
Epoch 5/10, Batch 140/145, Loss: 0.1107
Epoch 5/10, Train Loss: 0.2457, Valid Loss: 0.2403
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2234
Epoch 6/10, Batch 20/145, Loss: 0.3934
Epoch 6/10, Batch 30/145, Loss: 0.3342
Epoch 6/10, Batch 40/145, Loss: 0.1652
Epoch 6/10, Batch 50/145, Loss: 0.4376
Epoch 6/10, Batch 60/145, Loss: 0.3253
Epoch 6/10, Batch 70/145, Loss: 0.1015
Epoch 6/10, Batch 80/145, Loss: 0.1779
Epoch 6/10, Batch 90/145, Loss: 0.3840
Epoch 6/10, Batch 100/145, Loss: 0.4839
Epoch 6/10, Batch 110/145, Loss: 0.2768
Epoch 6/10, Batch 120/145, Loss: 0.2825
Epoch 6/10, Batch 130/145, Loss: 0.1647
Epoch 6/10, Batch 140/145, Loss: 0.0963
Epoch 6/10, Train Loss: 0.2294, Valid Loss: 0.2240
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1511
Epoch 7/10, Batch 20/145, Loss: 0.2849
Epoch 7/10, Batch 30/145, Loss: 0.2233
Epoch 7/10, Batch 40/145, Loss: 0.3743
Epoch 7/10, Batch 50/145, Loss: 0.1592
Epoch 7/10, Batch 60/145, Loss: 0.1457
Epoch 7/10, Batch 70/145, Loss: 0.0775
Epoch 7/10, Batch 80/145, Loss: 0.3666
Epoch 7/10, Batch 90/145, Loss: 0.1542
Epoch 7/10, Batch 100/145, Loss: 0.1703
Epoch 7/10, Batch 110/145, Loss: 0.1551
Epoch 7/10, Batch 120/145, Loss: 0.1621
Epoch 7/10, Batch 130/145, Loss: 0.1175
Epoch 7/10, Batch 140/145, Loss: 0.2632
Epoch 7/10, Train Loss: 0.2093, Valid Loss: 0.2209
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2331
Epoch 8/10, Batch 20/145, Loss: 0.3132
Epoch 8/10, Batch 30/145, Loss: 0.1198
Epoch 8/10, Batch 40/145, Loss: 0.2762
Epoch 8/10, Batch 50/145, Loss: 0.1911
Epoch 8/10, Batch 60/145, Loss: 0.2132
Epoch 8/10, Batch 70/145, Loss: 0.1931
Epoch 8/10, Batch 80/145, Loss: 0.2021
Epoch 8/10, Batch 90/145, Loss: 0.2867
Epoch 8/10, Batch 100/145, Loss: 0.1515
Epoch 8/10, Batch 110/145, Loss: 0.1583
Epoch 8/10, Batch 120/145, Loss: 0.2256
Epoch 8/10, Batch 130/145, Loss: 0.1014
Epoch 8/10, Batch 140/145, Loss: 0.2133
Epoch 8/10, Train Loss: 0.2082, Valid Loss: 0.2182
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1418
Epoch 9/10, Batch 20/145, Loss: 0.1554
Epoch 9/10, Batch 30/145, Loss: 0.2014
Epoch 9/10, Batch 40/145, Loss: 0.1212
Epoch 9/10, Batch 50/145, Loss: 0.2243
Epoch 9/10, Batch 60/145, Loss: 0.2461
Epoch 9/10, Batch 70/145, Loss: 0.3544
Epoch 9/10, Batch 80/145, Loss: 0.1073
Epoch 9/10, Batch 90/145, Loss: 0.2086
Epoch 9/10, Batch 100/145, Loss: 0.1358
Epoch 9/10, Batch 110/145, Loss: 0.1884
Epoch 9/10, Batch 120/145, Loss: 0.1380
Epoch 9/10, Batch 130/145, Loss: 0.3226
Epoch 9/10, Batch 140/145, Loss: 0.3565
Epoch 9/10, Train Loss: 0.1965, Valid Loss: 0.2163
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1477
Epoch 10/10, Batch 20/145, Loss: 0.1311
Epoch 10/10, Batch 30/145, Loss: 0.0854
Epoch 10/10, Batch 40/145, Loss: 0.1220
Epoch 10/10, Batch 50/145, Loss: 0.3425
Epoch 10/10, Batch 60/145, Loss: 0.2366
Epoch 10/10, Batch 70/145, Loss: 0.1570
Epoch 10/10, Batch 80/145, Loss: 0.1491
Epoch 10/10, Batch 90/145, Loss: 0.0700
Epoch 10/10, Batch 100/145, Loss: 0.2385
Epoch 10/10, Batch 110/145, Loss: 0.1445
Epoch 10/10, Batch 120/145, Loss: 0.2099
Epoch 10/10, Batch 130/145, Loss: 0.1419
Epoch 10/10, Batch 140/145, Loss: 0.3032
Epoch 10/10, Train Loss: 0.1893, Valid Loss: 0.2131
Model saved!
Accuracy: 0.9182
Precision: 0.9149
Recall: 0.9182
F1-score: 0.9158
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.2805
Epoch 1/10, Batch 20/145, Loss: 0.8818
Epoch 1/10, Batch 30/145, Loss: 0.9259
Epoch 1/10, Batch 40/145, Loss: 0.8653
Epoch 1/10, Batch 50/145, Loss: 0.7219
Epoch 1/10, Batch 60/145, Loss: 0.6546
Epoch 1/10, Batch 70/145, Loss: 0.4280
Epoch 1/10, Batch 80/145, Loss: 0.4544
Epoch 1/10, Batch 90/145, Loss: 0.4354
Epoch 1/10, Batch 100/145, Loss: 0.4879
Epoch 1/10, Batch 110/145, Loss: 0.3171
Epoch 1/10, Batch 120/145, Loss: 0.5545
Epoch 1/10, Batch 130/145, Loss: 0.5124
Epoch 1/10, Batch 140/145, Loss: 0.4492
Epoch 1/10, Train Loss: 0.6711, Valid Loss: 0.3806
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2970
Epoch 2/10, Batch 20/145, Loss: 0.4051
Epoch 2/10, Batch 30/145, Loss: 0.3485
Epoch 2/10, Batch 40/145, Loss: 0.4568
Epoch 2/10, Batch 50/145, Loss: 0.3296
Epoch 2/10, Batch 60/145, Loss: 0.3348
Epoch 2/10, Batch 70/145, Loss: 0.4600
Epoch 2/10, Batch 80/145, Loss: 0.2582
Epoch 2/10, Batch 90/145, Loss: 0.2252
Epoch 2/10, Batch 100/145, Loss: 0.3385
Epoch 2/10, Batch 110/145, Loss: 0.4117
Epoch 2/10, Batch 120/145, Loss: 0.3477
Epoch 2/10, Batch 130/145, Loss: 0.3544
Epoch 2/10, Batch 140/145, Loss: 0.2464
Epoch 2/10, Train Loss: 0.3484, Valid Loss: 0.3047
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2364
Epoch 3/10, Batch 20/145, Loss: 0.2681
Epoch 3/10, Batch 30/145, Loss: 0.4201
Epoch 3/10, Batch 40/145, Loss: 0.3884
Epoch 3/10, Batch 50/145, Loss: 0.1941
Epoch 3/10, Batch 60/145, Loss: 0.2872
Epoch 3/10, Batch 70/145, Loss: 0.2647
Epoch 3/10, Batch 80/145, Loss: 0.2336
Epoch 3/10, Batch 90/145, Loss: 0.3483
Epoch 3/10, Batch 100/145, Loss: 0.2104
Epoch 3/10, Batch 110/145, Loss: 0.2236
Epoch 3/10, Batch 120/145, Loss: 0.1544
Epoch 3/10, Batch 130/145, Loss: 0.4240
Epoch 3/10, Batch 140/145, Loss: 0.3053
Epoch 3/10, Train Loss: 0.2858, Valid Loss: 0.2718
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3838
Epoch 4/10, Batch 20/145, Loss: 0.1497
Epoch 4/10, Batch 30/145, Loss: 0.2143
Epoch 4/10, Batch 40/145, Loss: 0.2008
Epoch 4/10, Batch 50/145, Loss: 0.1418
Epoch 4/10, Batch 60/145, Loss: 0.3390
Epoch 4/10, Batch 70/145, Loss: 0.1426
Epoch 4/10, Batch 80/145, Loss: 0.1175
Epoch 4/10, Batch 90/145, Loss: 0.2459
Epoch 4/10, Batch 100/145, Loss: 0.3307
Epoch 4/10, Batch 110/145, Loss: 0.1312
Epoch 4/10, Batch 120/145, Loss: 0.1995
Epoch 4/10, Batch 130/145, Loss: 0.1335
Epoch 4/10, Batch 140/145, Loss: 0.1977
Epoch 4/10, Train Loss: 0.2564, Valid Loss: 0.2563
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1620
Epoch 5/10, Batch 20/145, Loss: 0.0825
Epoch 5/10, Batch 30/145, Loss: 0.2903
Epoch 5/10, Batch 40/145, Loss: 0.2170
Epoch 5/10, Batch 50/145, Loss: 0.1904
Epoch 5/10, Batch 60/145, Loss: 0.1810
Epoch 5/10, Batch 70/145, Loss: 0.2041
Epoch 5/10, Batch 80/145, Loss: 0.1842
Epoch 5/10, Batch 90/145, Loss: 0.3292
Epoch 5/10, Batch 100/145, Loss: 0.2543
Epoch 5/10, Batch 110/145, Loss: 0.2709
Epoch 5/10, Batch 120/145, Loss: 0.2521
Epoch 5/10, Batch 130/145, Loss: 0.2237
Epoch 5/10, Batch 140/145, Loss: 0.2544
Epoch 5/10, Train Loss: 0.2373, Valid Loss: 0.2543
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1813
Epoch 6/10, Batch 20/145, Loss: 0.4362
Epoch 6/10, Batch 30/145, Loss: 0.2658
Epoch 6/10, Batch 40/145, Loss: 0.1264
Epoch 6/10, Batch 50/145, Loss: 0.2684
Epoch 6/10, Batch 60/145, Loss: 0.2445
Epoch 6/10, Batch 70/145, Loss: 0.2863
Epoch 6/10, Batch 80/145, Loss: 0.2181
Epoch 6/10, Batch 90/145, Loss: 0.3790
Epoch 6/10, Batch 100/145, Loss: 0.2348
Epoch 6/10, Batch 110/145, Loss: 0.3468
Epoch 6/10, Batch 120/145, Loss: 0.3110
Epoch 6/10, Batch 130/145, Loss: 0.2768
Epoch 6/10, Batch 140/145, Loss: 0.1452
Epoch 6/10, Train Loss: 0.2227, Valid Loss: 0.2379
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.0734
Epoch 7/10, Batch 20/145, Loss: 0.3325
Epoch 7/10, Batch 30/145, Loss: 0.2813
Epoch 7/10, Batch 40/145, Loss: 0.3704
Epoch 7/10, Batch 50/145, Loss: 0.3937
Epoch 7/10, Batch 60/145, Loss: 0.1969
Epoch 7/10, Batch 70/145, Loss: 0.3153
Epoch 7/10, Batch 80/145, Loss: 0.3917
Epoch 7/10, Batch 90/145, Loss: 0.3937
Epoch 7/10, Batch 100/145, Loss: 0.1540
Epoch 7/10, Batch 110/145, Loss: 0.0918
Epoch 7/10, Batch 120/145, Loss: 0.1818
Epoch 7/10, Batch 130/145, Loss: 0.0664
Epoch 7/10, Batch 140/145, Loss: 0.2991
Epoch 7/10, Train Loss: 0.2155, Valid Loss: 0.2357
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1908
Epoch 8/10, Batch 20/145, Loss: 0.2194
Epoch 8/10, Batch 30/145, Loss: 0.2186
Epoch 8/10, Batch 40/145, Loss: 0.2926
Epoch 8/10, Batch 50/145, Loss: 0.1780
Epoch 8/10, Batch 60/145, Loss: 0.2049
Epoch 8/10, Batch 70/145, Loss: 0.2551
Epoch 8/10, Batch 80/145, Loss: 0.2083
Epoch 8/10, Batch 90/145, Loss: 0.1757
Epoch 8/10, Batch 100/145, Loss: 0.1225
Epoch 8/10, Batch 110/145, Loss: 0.2188
Epoch 8/10, Batch 120/145, Loss: 0.1914
Epoch 8/10, Batch 130/145, Loss: 0.2079
Epoch 8/10, Batch 140/145, Loss: 0.1950
Epoch 8/10, Train Loss: 0.2063, Valid Loss: 0.2282
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3713
Epoch 9/10, Batch 20/145, Loss: 0.2184
Epoch 9/10, Batch 30/145, Loss: 0.1329
Epoch 9/10, Batch 40/145, Loss: 0.2292
Epoch 9/10, Batch 50/145, Loss: 0.1263
Epoch 9/10, Batch 60/145, Loss: 0.3759
Epoch 9/10, Batch 70/145, Loss: 0.1726
Epoch 9/10, Batch 80/145, Loss: 0.0848
Epoch 9/10, Batch 90/145, Loss: 0.1649
Epoch 9/10, Batch 100/145, Loss: 0.0792
Epoch 9/10, Batch 110/145, Loss: 0.3215
Epoch 9/10, Batch 120/145, Loss: 0.1095
Epoch 9/10, Batch 130/145, Loss: 0.1784
Epoch 9/10, Batch 140/145, Loss: 0.1455
Epoch 9/10, Train Loss: 0.1941, Valid Loss: 0.2243
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1077
Epoch 10/10, Batch 20/145, Loss: 0.1177
Epoch 10/10, Batch 30/145, Loss: 0.1259
Epoch 10/10, Batch 40/145, Loss: 0.2942
Epoch 10/10, Batch 50/145, Loss: 0.1397
Epoch 10/10, Batch 60/145, Loss: 0.1801
Epoch 10/10, Batch 70/145, Loss: 0.2182
Epoch 10/10, Batch 80/145, Loss: 0.0742
Epoch 10/10, Batch 90/145, Loss: 0.1837
Epoch 10/10, Batch 100/145, Loss: 0.1510
Epoch 10/10, Batch 110/145, Loss: 0.1324
Epoch 10/10, Batch 120/145, Loss: 0.3142
Epoch 10/10, Batch 130/145, Loss: 0.1187
Epoch 10/10, Batch 140/145, Loss: 0.1762
Epoch 10/10, Train Loss: 0.1839, Valid Loss: 0.2231
Model saved!
Accuracy: 0.9112
Precision: 0.9088
Recall: 0.9112
F1-score: 0.9082
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3821
Epoch 1/10, Batch 20/145, Loss: 0.9976
Epoch 1/10, Batch 30/145, Loss: 0.9191
Epoch 1/10, Batch 40/145, Loss: 0.8548
Epoch 1/10, Batch 50/145, Loss: 0.7779
Epoch 1/10, Batch 60/145, Loss: 0.6573
Epoch 1/10, Batch 70/145, Loss: 0.4277
Epoch 1/10, Batch 80/145, Loss: 0.5538
Epoch 1/10, Batch 90/145, Loss: 0.4844
Epoch 1/10, Batch 100/145, Loss: 0.4680
Epoch 1/10, Batch 110/145, Loss: 0.4413
Epoch 1/10, Batch 120/145, Loss: 0.5139
Epoch 1/10, Batch 130/145, Loss: 0.5361
Epoch 1/10, Batch 140/145, Loss: 0.3157
Epoch 1/10, Train Loss: 0.6710, Valid Loss: 0.3664
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3426
Epoch 2/10, Batch 20/145, Loss: 0.4285
Epoch 2/10, Batch 30/145, Loss: 0.2713
Epoch 2/10, Batch 40/145, Loss: 0.4538
Epoch 2/10, Batch 50/145, Loss: 0.3138
Epoch 2/10, Batch 60/145, Loss: 0.4231
Epoch 2/10, Batch 70/145, Loss: 0.3061
Epoch 2/10, Batch 80/145, Loss: 0.5417
Epoch 2/10, Batch 90/145, Loss: 0.4167
Epoch 2/10, Batch 100/145, Loss: 0.2321
Epoch 2/10, Batch 110/145, Loss: 0.4640
Epoch 2/10, Batch 120/145, Loss: 0.2548
Epoch 2/10, Batch 130/145, Loss: 0.2643
Epoch 2/10, Batch 140/145, Loss: 0.3418
Epoch 2/10, Train Loss: 0.3525, Valid Loss: 0.2836
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2865
Epoch 3/10, Batch 20/145, Loss: 0.2745
Epoch 3/10, Batch 30/145, Loss: 0.3657
Epoch 3/10, Batch 40/145, Loss: 0.1412
Epoch 3/10, Batch 50/145, Loss: 0.1783
Epoch 3/10, Batch 60/145, Loss: 0.3247
Epoch 3/10, Batch 70/145, Loss: 0.4359
Epoch 3/10, Batch 80/145, Loss: 0.1957
Epoch 3/10, Batch 90/145, Loss: 0.2848
Epoch 3/10, Batch 100/145, Loss: 0.1515
Epoch 3/10, Batch 110/145, Loss: 0.1661
Epoch 3/10, Batch 120/145, Loss: 0.4715
Epoch 3/10, Batch 130/145, Loss: 0.5142
Epoch 3/10, Batch 140/145, Loss: 0.3183
Epoch 3/10, Train Loss: 0.2952, Valid Loss: 0.2508
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3798
Epoch 4/10, Batch 20/145, Loss: 0.2994
Epoch 4/10, Batch 30/145, Loss: 0.3463
Epoch 4/10, Batch 40/145, Loss: 0.4199
Epoch 4/10, Batch 50/145, Loss: 0.1695
Epoch 4/10, Batch 60/145, Loss: 0.2706
Epoch 4/10, Batch 70/145, Loss: 0.1346
Epoch 4/10, Batch 80/145, Loss: 0.1692
Epoch 4/10, Batch 90/145, Loss: 0.2866
Epoch 4/10, Batch 100/145, Loss: 0.3126
Epoch 4/10, Batch 110/145, Loss: 0.1728
Epoch 4/10, Batch 120/145, Loss: 0.1585
Epoch 4/10, Batch 130/145, Loss: 0.2091
Epoch 4/10, Batch 140/145, Loss: 0.1301
Epoch 4/10, Train Loss: 0.2636, Valid Loss: 0.2412
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1586
Epoch 5/10, Batch 20/145, Loss: 0.1600
Epoch 5/10, Batch 30/145, Loss: 0.2355
Epoch 5/10, Batch 40/145, Loss: 0.1498
Epoch 5/10, Batch 50/145, Loss: 0.1409
Epoch 5/10, Batch 60/145, Loss: 0.1933
Epoch 5/10, Batch 70/145, Loss: 0.1157
Epoch 5/10, Batch 80/145, Loss: 0.2128
Epoch 5/10, Batch 90/145, Loss: 0.2479
Epoch 5/10, Batch 100/145, Loss: 0.3772
Epoch 5/10, Batch 110/145, Loss: 0.1636
Epoch 5/10, Batch 120/145, Loss: 0.3727
Epoch 5/10, Batch 130/145, Loss: 0.1949
Epoch 5/10, Batch 140/145, Loss: 0.1207
Epoch 5/10, Train Loss: 0.2387, Valid Loss: 0.2237
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2324
Epoch 6/10, Batch 20/145, Loss: 0.4422
Epoch 6/10, Batch 30/145, Loss: 0.3804
Epoch 6/10, Batch 40/145, Loss: 0.1425
Epoch 6/10, Batch 50/145, Loss: 0.3114
Epoch 6/10, Batch 60/145, Loss: 0.2170
Epoch 6/10, Batch 70/145, Loss: 0.1423
Epoch 6/10, Batch 80/145, Loss: 0.1753
Epoch 6/10, Batch 90/145, Loss: 0.3205
Epoch 6/10, Batch 100/145, Loss: 0.2285
Epoch 6/10, Batch 110/145, Loss: 0.2591
Epoch 6/10, Batch 120/145, Loss: 0.1906
Epoch 6/10, Batch 130/145, Loss: 0.2244
Epoch 6/10, Batch 140/145, Loss: 0.1215
Epoch 6/10, Train Loss: 0.2315, Valid Loss: 0.2223
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2773
Epoch 7/10, Batch 20/145, Loss: 0.2588
Epoch 7/10, Batch 30/145, Loss: 0.1945
Epoch 7/10, Batch 40/145, Loss: 0.4261
Epoch 7/10, Batch 50/145, Loss: 0.1423
Epoch 7/10, Batch 60/145, Loss: 0.1501
Epoch 7/10, Batch 70/145, Loss: 0.1998
Epoch 7/10, Batch 80/145, Loss: 0.4168
Epoch 7/10, Batch 90/145, Loss: 0.2015
Epoch 7/10, Batch 100/145, Loss: 0.1978
Epoch 7/10, Batch 110/145, Loss: 0.2927
Epoch 7/10, Batch 120/145, Loss: 0.1508
Epoch 7/10, Batch 130/145, Loss: 0.1067
Epoch 7/10, Batch 140/145, Loss: 0.2781
Epoch 7/10, Train Loss: 0.2161, Valid Loss: 0.2176
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1101
Epoch 8/10, Batch 20/145, Loss: 0.2065
Epoch 8/10, Batch 30/145, Loss: 0.2941
Epoch 8/10, Batch 40/145, Loss: 0.2143
Epoch 8/10, Batch 50/145, Loss: 0.1824
Epoch 8/10, Batch 60/145, Loss: 0.2434
Epoch 8/10, Batch 70/145, Loss: 0.1130
Epoch 8/10, Batch 80/145, Loss: 0.2390
Epoch 8/10, Batch 90/145, Loss: 0.3959
Epoch 8/10, Batch 100/145, Loss: 0.2451
Epoch 8/10, Batch 110/145, Loss: 0.1942
Epoch 8/10, Batch 120/145, Loss: 0.1690
Epoch 8/10, Batch 130/145, Loss: 0.1948
Epoch 8/10, Batch 140/145, Loss: 0.2692
Epoch 8/10, Train Loss: 0.2070, Valid Loss: 0.2101
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3035
Epoch 9/10, Batch 20/145, Loss: 0.1245
Epoch 9/10, Batch 30/145, Loss: 0.2777
Epoch 9/10, Batch 40/145, Loss: 0.1732
Epoch 9/10, Batch 50/145, Loss: 0.0685
Epoch 9/10, Batch 60/145, Loss: 0.2129
Epoch 9/10, Batch 70/145, Loss: 0.1762
Epoch 9/10, Batch 80/145, Loss: 0.1698
Epoch 9/10, Batch 90/145, Loss: 0.2993
Epoch 9/10, Batch 100/145, Loss: 0.2036
Epoch 9/10, Batch 110/145, Loss: 0.1566
Epoch 9/10, Batch 120/145, Loss: 0.0999
Epoch 9/10, Batch 130/145, Loss: 0.1474
Epoch 9/10, Batch 140/145, Loss: 0.1327
Epoch 9/10, Train Loss: 0.1993, Valid Loss: 0.2076
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1190
Epoch 10/10, Batch 20/145, Loss: 0.2340
Epoch 10/10, Batch 30/145, Loss: 0.1509
Epoch 10/10, Batch 40/145, Loss: 0.1299
Epoch 10/10, Batch 50/145, Loss: 0.2166
Epoch 10/10, Batch 60/145, Loss: 0.2466
Epoch 10/10, Batch 70/145, Loss: 0.2637
Epoch 10/10, Batch 80/145, Loss: 0.1996
Epoch 10/10, Batch 90/145, Loss: 0.1687
Epoch 10/10, Batch 100/145, Loss: 0.2212
Epoch 10/10, Batch 110/145, Loss: 0.2296
Epoch 10/10, Batch 120/145, Loss: 0.1965
Epoch 10/10, Batch 130/145, Loss: 0.2786
Epoch 10/10, Batch 140/145, Loss: 0.2624
Epoch 10/10, Train Loss: 0.1978, Valid Loss: 0.2136
Accuracy: 0.9217
Precision: 0.9190
Recall: 0.9217
F1-score: 0.9199
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4172
Epoch 1/10, Batch 20/145, Loss: 1.0031
Epoch 1/10, Batch 30/145, Loss: 1.0054
Epoch 1/10, Batch 40/145, Loss: 0.8138
Epoch 1/10, Batch 50/145, Loss: 0.6753
Epoch 1/10, Batch 60/145, Loss: 0.6716
Epoch 1/10, Batch 70/145, Loss: 0.4325
Epoch 1/10, Batch 80/145, Loss: 0.5760
Epoch 1/10, Batch 90/145, Loss: 0.4830
Epoch 1/10, Batch 100/145, Loss: 0.4688
Epoch 1/10, Batch 110/145, Loss: 0.6363
Epoch 1/10, Batch 120/145, Loss: 0.6680
Epoch 1/10, Batch 130/145, Loss: 0.4708
Epoch 1/10, Batch 140/145, Loss: 0.3054
Epoch 1/10, Train Loss: 0.6808, Valid Loss: 0.3619
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3412
Epoch 2/10, Batch 20/145, Loss: 0.3664
Epoch 2/10, Batch 30/145, Loss: 0.2588
Epoch 2/10, Batch 40/145, Loss: 0.5850
Epoch 2/10, Batch 50/145, Loss: 0.2522
Epoch 2/10, Batch 60/145, Loss: 0.3447
Epoch 2/10, Batch 70/145, Loss: 0.3561
Epoch 2/10, Batch 80/145, Loss: 0.4318
Epoch 2/10, Batch 90/145, Loss: 0.2914
Epoch 2/10, Batch 100/145, Loss: 0.2550
Epoch 2/10, Batch 110/145, Loss: 0.3641
Epoch 2/10, Batch 120/145, Loss: 0.2899
Epoch 2/10, Batch 130/145, Loss: 0.3069
Epoch 2/10, Batch 140/145, Loss: 0.2899
Epoch 2/10, Train Loss: 0.3537, Valid Loss: 0.2766
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2754
Epoch 3/10, Batch 20/145, Loss: 0.2119
Epoch 3/10, Batch 30/145, Loss: 0.4770
Epoch 3/10, Batch 40/145, Loss: 0.2629
Epoch 3/10, Batch 50/145, Loss: 0.2056
Epoch 3/10, Batch 60/145, Loss: 0.2161
Epoch 3/10, Batch 70/145, Loss: 0.4426
Epoch 3/10, Batch 80/145, Loss: 0.1848
Epoch 3/10, Batch 90/145, Loss: 0.1930
Epoch 3/10, Batch 100/145, Loss: 0.3292
Epoch 3/10, Batch 110/145, Loss: 0.1255
Epoch 3/10, Batch 120/145, Loss: 0.4224
Epoch 3/10, Batch 130/145, Loss: 0.3482
Epoch 3/10, Batch 140/145, Loss: 0.2786
Epoch 3/10, Train Loss: 0.2913, Valid Loss: 0.2459
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3462
Epoch 4/10, Batch 20/145, Loss: 0.2451
Epoch 4/10, Batch 30/145, Loss: 0.2304
Epoch 4/10, Batch 40/145, Loss: 0.2901
Epoch 4/10, Batch 50/145, Loss: 0.2443
Epoch 4/10, Batch 60/145, Loss: 0.2840
Epoch 4/10, Batch 70/145, Loss: 0.2708
Epoch 4/10, Batch 80/145, Loss: 0.0993
Epoch 4/10, Batch 90/145, Loss: 0.1713
Epoch 4/10, Batch 100/145, Loss: 0.4610
Epoch 4/10, Batch 110/145, Loss: 0.1382
Epoch 4/10, Batch 120/145, Loss: 0.2176
Epoch 4/10, Batch 130/145, Loss: 0.1849
Epoch 4/10, Batch 140/145, Loss: 0.0775
Epoch 4/10, Train Loss: 0.2578, Valid Loss: 0.2272
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1053
Epoch 5/10, Batch 20/145, Loss: 0.1634
Epoch 5/10, Batch 30/145, Loss: 0.3127
Epoch 5/10, Batch 40/145, Loss: 0.1663
Epoch 5/10, Batch 50/145, Loss: 0.2239
Epoch 5/10, Batch 60/145, Loss: 0.1439
Epoch 5/10, Batch 70/145, Loss: 0.1995
Epoch 5/10, Batch 80/145, Loss: 0.2650
Epoch 5/10, Batch 90/145, Loss: 0.1711
Epoch 5/10, Batch 100/145, Loss: 0.1272
Epoch 5/10, Batch 110/145, Loss: 0.2101
Epoch 5/10, Batch 120/145, Loss: 0.2674
Epoch 5/10, Batch 130/145, Loss: 0.2269
Epoch 5/10, Batch 140/145, Loss: 0.1202
Epoch 5/10, Train Loss: 0.2387, Valid Loss: 0.2234
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2450
Epoch 6/10, Batch 20/145, Loss: 0.4192
Epoch 6/10, Batch 30/145, Loss: 0.2615
Epoch 6/10, Batch 40/145, Loss: 0.1833
Epoch 6/10, Batch 50/145, Loss: 0.3977
Epoch 6/10, Batch 60/145, Loss: 0.2637
Epoch 6/10, Batch 70/145, Loss: 0.1973
Epoch 6/10, Batch 80/145, Loss: 0.2278
Epoch 6/10, Batch 90/145, Loss: 0.3178
Epoch 6/10, Batch 100/145, Loss: 0.1904
Epoch 6/10, Batch 110/145, Loss: 0.3977
Epoch 6/10, Batch 120/145, Loss: 0.3211
Epoch 6/10, Batch 130/145, Loss: 0.2009
Epoch 6/10, Batch 140/145, Loss: 0.3769
Epoch 6/10, Train Loss: 0.2284, Valid Loss: 0.2084
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2083
Epoch 7/10, Batch 20/145, Loss: 0.3839
Epoch 7/10, Batch 30/145, Loss: 0.2318
Epoch 7/10, Batch 40/145, Loss: 0.4675
Epoch 7/10, Batch 50/145, Loss: 0.4340
Epoch 7/10, Batch 60/145, Loss: 0.1544
Epoch 7/10, Batch 70/145, Loss: 0.1516
Epoch 7/10, Batch 80/145, Loss: 0.2602
Epoch 7/10, Batch 90/145, Loss: 0.1376
Epoch 7/10, Batch 100/145, Loss: 0.1383
Epoch 7/10, Batch 110/145, Loss: 0.2232
Epoch 7/10, Batch 120/145, Loss: 0.2261
Epoch 7/10, Batch 130/145, Loss: 0.1882
Epoch 7/10, Batch 140/145, Loss: 0.2741
Epoch 7/10, Train Loss: 0.2120, Valid Loss: 0.2062
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1910
Epoch 8/10, Batch 20/145, Loss: 0.2295
Epoch 8/10, Batch 30/145, Loss: 0.2936
Epoch 8/10, Batch 40/145, Loss: 0.2071
Epoch 8/10, Batch 50/145, Loss: 0.3642
Epoch 8/10, Batch 60/145, Loss: 0.2420
Epoch 8/10, Batch 70/145, Loss: 0.2204
Epoch 8/10, Batch 80/145, Loss: 0.2687
Epoch 8/10, Batch 90/145, Loss: 0.1591
Epoch 8/10, Batch 100/145, Loss: 0.1755
Epoch 8/10, Batch 110/145, Loss: 0.1883
Epoch 8/10, Batch 120/145, Loss: 0.1656
Epoch 8/10, Batch 130/145, Loss: 0.2243
Epoch 8/10, Batch 140/145, Loss: 0.2409
Epoch 8/10, Train Loss: 0.2063, Valid Loss: 0.1924
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2423
Epoch 9/10, Batch 20/145, Loss: 0.1524
Epoch 9/10, Batch 30/145, Loss: 0.1452
Epoch 9/10, Batch 40/145, Loss: 0.2970
Epoch 9/10, Batch 50/145, Loss: 0.2538
Epoch 9/10, Batch 60/145, Loss: 0.2016
Epoch 9/10, Batch 70/145, Loss: 0.2124
Epoch 9/10, Batch 80/145, Loss: 0.1077
Epoch 9/10, Batch 90/145, Loss: 0.1145
Epoch 9/10, Batch 100/145, Loss: 0.1417
Epoch 9/10, Batch 110/145, Loss: 0.1848
Epoch 9/10, Batch 120/145, Loss: 0.1461
Epoch 9/10, Batch 130/145, Loss: 0.1841
Epoch 9/10, Batch 140/145, Loss: 0.1676
Epoch 9/10, Train Loss: 0.2012, Valid Loss: 0.1914
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1699
Epoch 10/10, Batch 20/145, Loss: 0.2180
Epoch 10/10, Batch 30/145, Loss: 0.2798
Epoch 10/10, Batch 40/145, Loss: 0.1122
Epoch 10/10, Batch 50/145, Loss: 0.2190
Epoch 10/10, Batch 60/145, Loss: 0.1065
Epoch 10/10, Batch 70/145, Loss: 0.2441
Epoch 10/10, Batch 80/145, Loss: 0.0683
Epoch 10/10, Batch 90/145, Loss: 0.0907
Epoch 10/10, Batch 100/145, Loss: 0.0759
Epoch 10/10, Batch 110/145, Loss: 0.1670
Epoch 10/10, Batch 120/145, Loss: 0.1707
Epoch 10/10, Batch 130/145, Loss: 0.2085
Epoch 10/10, Batch 140/145, Loss: 0.1655
Epoch 10/10, Train Loss: 0.1961, Valid Loss: 0.1878
Model saved!
Accuracy: 0.9217
Precision: 0.9193
Recall: 0.9217
F1-score: 0.9199
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4326
Epoch 1/10, Batch 20/145, Loss: 0.9512
Epoch 1/10, Batch 30/145, Loss: 1.0083
Epoch 1/10, Batch 40/145, Loss: 0.8561
Epoch 1/10, Batch 50/145, Loss: 0.7880
Epoch 1/10, Batch 60/145, Loss: 0.6281
Epoch 1/10, Batch 70/145, Loss: 0.4221
Epoch 1/10, Batch 80/145, Loss: 0.6130
Epoch 1/10, Batch 90/145, Loss: 0.3627
Epoch 1/10, Batch 100/145, Loss: 0.5024
Epoch 1/10, Batch 110/145, Loss: 0.4211
Epoch 1/10, Batch 120/145, Loss: 0.5472
Epoch 1/10, Batch 130/145, Loss: 0.4619
Epoch 1/10, Batch 140/145, Loss: 0.3515
Epoch 1/10, Train Loss: 0.6767, Valid Loss: 0.3889
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3326
Epoch 2/10, Batch 20/145, Loss: 0.3714
Epoch 2/10, Batch 30/145, Loss: 0.2423
Epoch 2/10, Batch 40/145, Loss: 0.3990
Epoch 2/10, Batch 50/145, Loss: 0.2848
Epoch 2/10, Batch 60/145, Loss: 0.4054
Epoch 2/10, Batch 70/145, Loss: 0.4087
Epoch 2/10, Batch 80/145, Loss: 0.3054
Epoch 2/10, Batch 90/145, Loss: 0.2820
Epoch 2/10, Batch 100/145, Loss: 0.3146
Epoch 2/10, Batch 110/145, Loss: 0.4226
Epoch 2/10, Batch 120/145, Loss: 0.3647
Epoch 2/10, Batch 130/145, Loss: 0.1917
Epoch 2/10, Batch 140/145, Loss: 0.3710
Epoch 2/10, Train Loss: 0.3493, Valid Loss: 0.3065
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1636
Epoch 3/10, Batch 20/145, Loss: 0.1991
Epoch 3/10, Batch 30/145, Loss: 0.2973
Epoch 3/10, Batch 40/145, Loss: 0.2089
Epoch 3/10, Batch 50/145, Loss: 0.2952
Epoch 3/10, Batch 60/145, Loss: 0.4302
Epoch 3/10, Batch 70/145, Loss: 0.3052
Epoch 3/10, Batch 80/145, Loss: 0.2714
Epoch 3/10, Batch 90/145, Loss: 0.4969
Epoch 3/10, Batch 100/145, Loss: 0.2226
Epoch 3/10, Batch 110/145, Loss: 0.2161
Epoch 3/10, Batch 120/145, Loss: 0.4519
Epoch 3/10, Batch 130/145, Loss: 0.3736
Epoch 3/10, Batch 140/145, Loss: 0.3351
Epoch 3/10, Train Loss: 0.2926, Valid Loss: 0.2670
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2864
Epoch 4/10, Batch 20/145, Loss: 0.2466
Epoch 4/10, Batch 30/145, Loss: 0.2929
Epoch 4/10, Batch 40/145, Loss: 0.2221
Epoch 4/10, Batch 50/145, Loss: 0.1509
Epoch 4/10, Batch 60/145, Loss: 0.2568
Epoch 4/10, Batch 70/145, Loss: 0.1333
Epoch 4/10, Batch 80/145, Loss: 0.1444
Epoch 4/10, Batch 90/145, Loss: 0.2241
Epoch 4/10, Batch 100/145, Loss: 0.3824
Epoch 4/10, Batch 110/145, Loss: 0.2120
Epoch 4/10, Batch 120/145, Loss: 0.1838
Epoch 4/10, Batch 130/145, Loss: 0.3283
Epoch 4/10, Batch 140/145, Loss: 0.1706
Epoch 4/10, Train Loss: 0.2555, Valid Loss: 0.2517
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1406
Epoch 5/10, Batch 20/145, Loss: 0.2259
Epoch 5/10, Batch 30/145, Loss: 0.3727
Epoch 5/10, Batch 40/145, Loss: 0.2266
Epoch 5/10, Batch 50/145, Loss: 0.2045
Epoch 5/10, Batch 60/145, Loss: 0.1897
Epoch 5/10, Batch 70/145, Loss: 0.2787
Epoch 5/10, Batch 80/145, Loss: 0.2162
Epoch 5/10, Batch 90/145, Loss: 0.2191
Epoch 5/10, Batch 100/145, Loss: 0.1832
Epoch 5/10, Batch 110/145, Loss: 0.1593
Epoch 5/10, Batch 120/145, Loss: 0.3304
Epoch 5/10, Batch 130/145, Loss: 0.2081
Epoch 5/10, Batch 140/145, Loss: 0.2171
Epoch 5/10, Train Loss: 0.2414, Valid Loss: 0.2446
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1328
Epoch 6/10, Batch 20/145, Loss: 0.2873
Epoch 6/10, Batch 30/145, Loss: 0.3634
Epoch 6/10, Batch 40/145, Loss: 0.1670
Epoch 6/10, Batch 50/145, Loss: 0.3549
Epoch 6/10, Batch 60/145, Loss: 0.2731
Epoch 6/10, Batch 70/145, Loss: 0.1381
Epoch 6/10, Batch 80/145, Loss: 0.1414
Epoch 6/10, Batch 90/145, Loss: 0.3225
Epoch 6/10, Batch 100/145, Loss: 0.3108
Epoch 6/10, Batch 110/145, Loss: 0.1988
Epoch 6/10, Batch 120/145, Loss: 0.2644
Epoch 6/10, Batch 130/145, Loss: 0.3829
Epoch 6/10, Batch 140/145, Loss: 0.1357
Epoch 6/10, Train Loss: 0.2241, Valid Loss: 0.2335
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2781
Epoch 7/10, Batch 20/145, Loss: 0.3283
Epoch 7/10, Batch 30/145, Loss: 0.2756
Epoch 7/10, Batch 40/145, Loss: 0.3009
Epoch 7/10, Batch 50/145, Loss: 0.1724
Epoch 7/10, Batch 60/145, Loss: 0.1992
Epoch 7/10, Batch 70/145, Loss: 0.1468
Epoch 7/10, Batch 80/145, Loss: 0.3133
Epoch 7/10, Batch 90/145, Loss: 0.2462
Epoch 7/10, Batch 100/145, Loss: 0.1160
Epoch 7/10, Batch 110/145, Loss: 0.1860
Epoch 7/10, Batch 120/145, Loss: 0.1968
Epoch 7/10, Batch 130/145, Loss: 0.0929
Epoch 7/10, Batch 140/145, Loss: 0.1921
Epoch 7/10, Train Loss: 0.2057, Valid Loss: 0.2358
Epoch 8/10, Batch 10/145, Loss: 0.1739
Epoch 8/10, Batch 20/145, Loss: 0.1946
Epoch 8/10, Batch 30/145, Loss: 0.1226
Epoch 8/10, Batch 40/145, Loss: 0.1868
Epoch 8/10, Batch 50/145, Loss: 0.2432
Epoch 8/10, Batch 60/145, Loss: 0.1299
Epoch 8/10, Batch 70/145, Loss: 0.2358
Epoch 8/10, Batch 80/145, Loss: 0.2149
Epoch 8/10, Batch 90/145, Loss: 0.1999
Epoch 8/10, Batch 100/145, Loss: 0.1818
Epoch 8/10, Batch 110/145, Loss: 0.3341
Epoch 8/10, Batch 120/145, Loss: 0.2674
Epoch 8/10, Batch 130/145, Loss: 0.1214
Epoch 8/10, Batch 140/145, Loss: 0.0922
Epoch 8/10, Train Loss: 0.2037, Valid Loss: 0.2231
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2744
Epoch 9/10, Batch 20/145, Loss: 0.1840
Epoch 9/10, Batch 30/145, Loss: 0.0906
Epoch 9/10, Batch 40/145, Loss: 0.1966
Epoch 9/10, Batch 50/145, Loss: 0.1118
Epoch 9/10, Batch 60/145, Loss: 0.2411
Epoch 9/10, Batch 70/145, Loss: 0.1297
Epoch 9/10, Batch 80/145, Loss: 0.0956
Epoch 9/10, Batch 90/145, Loss: 0.1200
Epoch 9/10, Batch 100/145, Loss: 0.2056
Epoch 9/10, Batch 110/145, Loss: 0.2418
Epoch 9/10, Batch 120/145, Loss: 0.0765
Epoch 9/10, Batch 130/145, Loss: 0.2468
Epoch 9/10, Batch 140/145, Loss: 0.1301
Epoch 9/10, Train Loss: 0.1951, Valid Loss: 0.2213
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2902
Epoch 10/10, Batch 20/145, Loss: 0.1058
Epoch 10/10, Batch 30/145, Loss: 0.0884
Epoch 10/10, Batch 40/145, Loss: 0.1592
Epoch 10/10, Batch 50/145, Loss: 0.2574
Epoch 10/10, Batch 60/145, Loss: 0.1581
Epoch 10/10, Batch 70/145, Loss: 0.2603
Epoch 10/10, Batch 80/145, Loss: 0.1578
Epoch 10/10, Batch 90/145, Loss: 0.0874
Epoch 10/10, Batch 100/145, Loss: 0.1666
Epoch 10/10, Batch 110/145, Loss: 0.2562
Epoch 10/10, Batch 120/145, Loss: 0.2391
Epoch 10/10, Batch 130/145, Loss: 0.1726
Epoch 10/10, Batch 140/145, Loss: 0.2354
Epoch 10/10, Train Loss: 0.1821, Valid Loss: 0.2191
Model saved!
Accuracy: 0.9252
Precision: 0.9232
Recall: 0.9252
F1-score: 0.9236
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 11. Fitness: 0.9252
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3393
Epoch 1/10, Batch 20/145, Loss: 0.9511
Epoch 1/10, Batch 30/145, Loss: 0.8132
Epoch 1/10, Batch 40/145, Loss: 0.7652
Epoch 1/10, Batch 50/145, Loss: 0.7300
Epoch 1/10, Batch 60/145, Loss: 0.6345
Epoch 1/10, Batch 70/145, Loss: 0.4010
Epoch 1/10, Batch 80/145, Loss: 0.7294
Epoch 1/10, Batch 90/145, Loss: 0.4106
Epoch 1/10, Batch 100/145, Loss: 0.4102
Epoch 1/10, Batch 110/145, Loss: 0.4155
Epoch 1/10, Batch 120/145, Loss: 0.4499
Epoch 1/10, Batch 130/145, Loss: 0.6073
Epoch 1/10, Batch 140/145, Loss: 0.4591
Epoch 1/10, Train Loss: 0.6684, Valid Loss: 0.3619
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3992
Epoch 2/10, Batch 20/145, Loss: 0.3467
Epoch 2/10, Batch 30/145, Loss: 0.3308
Epoch 2/10, Batch 40/145, Loss: 0.4361
Epoch 2/10, Batch 50/145, Loss: 0.2945
Epoch 2/10, Batch 60/145, Loss: 0.2763
Epoch 2/10, Batch 70/145, Loss: 0.5520
Epoch 2/10, Batch 80/145, Loss: 0.2572
Epoch 2/10, Batch 90/145, Loss: 0.2862
Epoch 2/10, Batch 100/145, Loss: 0.2308
Epoch 2/10, Batch 110/145, Loss: 0.3573
Epoch 2/10, Batch 120/145, Loss: 0.2675
Epoch 2/10, Batch 130/145, Loss: 0.3522
Epoch 2/10, Batch 140/145, Loss: 0.2465
Epoch 2/10, Train Loss: 0.3481, Valid Loss: 0.2772
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2412
Epoch 3/10, Batch 20/145, Loss: 0.1372
Epoch 3/10, Batch 30/145, Loss: 0.4909
Epoch 3/10, Batch 40/145, Loss: 0.3133
Epoch 3/10, Batch 50/145, Loss: 0.2661
Epoch 3/10, Batch 60/145, Loss: 0.4731
Epoch 3/10, Batch 70/145, Loss: 0.3375
Epoch 3/10, Batch 80/145, Loss: 0.2831
Epoch 3/10, Batch 90/145, Loss: 0.3291
Epoch 3/10, Batch 100/145, Loss: 0.2347
Epoch 3/10, Batch 110/145, Loss: 0.2245
Epoch 3/10, Batch 120/145, Loss: 0.2376
Epoch 3/10, Batch 130/145, Loss: 0.2334
Epoch 3/10, Batch 140/145, Loss: 0.2196
Epoch 3/10, Train Loss: 0.2922, Valid Loss: 0.2467
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2274
Epoch 4/10, Batch 20/145, Loss: 0.4817
Epoch 4/10, Batch 30/145, Loss: 0.2383
Epoch 4/10, Batch 40/145, Loss: 0.1838
Epoch 4/10, Batch 50/145, Loss: 0.1634
Epoch 4/10, Batch 60/145, Loss: 0.3112
Epoch 4/10, Batch 70/145, Loss: 0.1077
Epoch 4/10, Batch 80/145, Loss: 0.1609
Epoch 4/10, Batch 90/145, Loss: 0.1248
Epoch 4/10, Batch 100/145, Loss: 0.3810
Epoch 4/10, Batch 110/145, Loss: 0.0994
Epoch 4/10, Batch 120/145, Loss: 0.2283
Epoch 4/10, Batch 130/145, Loss: 0.2289
Epoch 4/10, Batch 140/145, Loss: 0.1600
Epoch 4/10, Train Loss: 0.2561, Valid Loss: 0.2333
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1835
Epoch 5/10, Batch 20/145, Loss: 0.1271
Epoch 5/10, Batch 30/145, Loss: 0.1706
Epoch 5/10, Batch 40/145, Loss: 0.1784
Epoch 5/10, Batch 50/145, Loss: 0.2887
Epoch 5/10, Batch 60/145, Loss: 0.2307
Epoch 5/10, Batch 70/145, Loss: 0.1452
Epoch 5/10, Batch 80/145, Loss: 0.2999
Epoch 5/10, Batch 90/145, Loss: 0.2784
Epoch 5/10, Batch 100/145, Loss: 0.2070
Epoch 5/10, Batch 110/145, Loss: 0.1546
Epoch 5/10, Batch 120/145, Loss: 0.2780
Epoch 5/10, Batch 130/145, Loss: 0.1830
Epoch 5/10, Batch 140/145, Loss: 0.2186
Epoch 5/10, Train Loss: 0.2411, Valid Loss: 0.2190
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1578
Epoch 6/10, Batch 20/145, Loss: 0.5507
Epoch 6/10, Batch 30/145, Loss: 0.1615
Epoch 6/10, Batch 40/145, Loss: 0.1980
Epoch 6/10, Batch 50/145, Loss: 0.3866
Epoch 6/10, Batch 60/145, Loss: 0.1103
Epoch 6/10, Batch 70/145, Loss: 0.1483
Epoch 6/10, Batch 80/145, Loss: 0.2816
Epoch 6/10, Batch 90/145, Loss: 0.1713
Epoch 6/10, Batch 100/145, Loss: 0.2090
Epoch 6/10, Batch 110/145, Loss: 0.1367
Epoch 6/10, Batch 120/145, Loss: 0.1721
Epoch 6/10, Batch 130/145, Loss: 0.0800
Epoch 6/10, Batch 140/145, Loss: 0.0890
Epoch 6/10, Train Loss: 0.2291, Valid Loss: 0.2082
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2532
Epoch 7/10, Batch 20/145, Loss: 0.3316
Epoch 7/10, Batch 30/145, Loss: 0.2389
Epoch 7/10, Batch 40/145, Loss: 0.2266
Epoch 7/10, Batch 50/145, Loss: 0.1964
Epoch 7/10, Batch 60/145, Loss: 0.1674
Epoch 7/10, Batch 70/145, Loss: 0.1398
Epoch 7/10, Batch 80/145, Loss: 0.3273
Epoch 7/10, Batch 90/145, Loss: 0.0951
Epoch 7/10, Batch 100/145, Loss: 0.0520
Epoch 7/10, Batch 110/145, Loss: 0.1036
Epoch 7/10, Batch 120/145, Loss: 0.2436
Epoch 7/10, Batch 130/145, Loss: 0.0593
Epoch 7/10, Batch 140/145, Loss: 0.2684
Epoch 7/10, Train Loss: 0.2115, Valid Loss: 0.2056
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1534
Epoch 8/10, Batch 20/145, Loss: 0.2563
Epoch 8/10, Batch 30/145, Loss: 0.2128
Epoch 8/10, Batch 40/145, Loss: 0.1702
Epoch 8/10, Batch 50/145, Loss: 0.3106
Epoch 8/10, Batch 60/145, Loss: 0.1750
Epoch 8/10, Batch 70/145, Loss: 0.4812
Epoch 8/10, Batch 80/145, Loss: 0.1555
Epoch 8/10, Batch 90/145, Loss: 0.2587
Epoch 8/10, Batch 100/145, Loss: 0.2877
Epoch 8/10, Batch 110/145, Loss: 0.2240
Epoch 8/10, Batch 120/145, Loss: 0.2358
Epoch 8/10, Batch 130/145, Loss: 0.1774
Epoch 8/10, Batch 140/145, Loss: 0.3860
Epoch 8/10, Train Loss: 0.2007, Valid Loss: 0.2031
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.4857
Epoch 9/10, Batch 20/145, Loss: 0.0968
Epoch 9/10, Batch 30/145, Loss: 0.2134
Epoch 9/10, Batch 40/145, Loss: 0.2479
Epoch 9/10, Batch 50/145, Loss: 0.1298
Epoch 9/10, Batch 60/145, Loss: 0.2314
Epoch 9/10, Batch 70/145, Loss: 0.1573
Epoch 9/10, Batch 80/145, Loss: 0.0812
Epoch 9/10, Batch 90/145, Loss: 0.2680
Epoch 9/10, Batch 100/145, Loss: 0.1795
Epoch 9/10, Batch 110/145, Loss: 0.1305
Epoch 9/10, Batch 120/145, Loss: 0.1243
Epoch 9/10, Batch 130/145, Loss: 0.1946
Epoch 9/10, Batch 140/145, Loss: 0.3991
Epoch 9/10, Train Loss: 0.1986, Valid Loss: 0.2047
Epoch 10/10, Batch 10/145, Loss: 0.1079
Epoch 10/10, Batch 20/145, Loss: 0.1991
Epoch 10/10, Batch 30/145, Loss: 0.1025
Epoch 10/10, Batch 40/145, Loss: 0.1114
Epoch 10/10, Batch 50/145, Loss: 0.3643
Epoch 10/10, Batch 60/145, Loss: 0.2483
Epoch 10/10, Batch 70/145, Loss: 0.1618
Epoch 10/10, Batch 80/145, Loss: 0.1619
Epoch 10/10, Batch 90/145, Loss: 0.1457
Epoch 10/10, Batch 100/145, Loss: 0.3696
Epoch 10/10, Batch 110/145, Loss: 0.1966
Epoch 10/10, Batch 120/145, Loss: 0.1910
Epoch 10/10, Batch 130/145, Loss: 0.1623
Epoch 10/10, Batch 140/145, Loss: 0.1794
Epoch 10/10, Train Loss: 0.1932, Valid Loss: 0.2013
Model saved!
Accuracy: 0.9182
Precision: 0.9152
Recall: 0.9182
F1-score: 0.9152
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.2716
Epoch 1/10, Batch 20/145, Loss: 0.9810
Epoch 1/10, Batch 30/145, Loss: 0.9334
Epoch 1/10, Batch 40/145, Loss: 0.7436
Epoch 1/10, Batch 50/145, Loss: 0.6781
Epoch 1/10, Batch 60/145, Loss: 0.6272
Epoch 1/10, Batch 70/145, Loss: 0.5254
Epoch 1/10, Batch 80/145, Loss: 0.6387
Epoch 1/10, Batch 90/145, Loss: 0.4434
Epoch 1/10, Batch 100/145, Loss: 0.4787
Epoch 1/10, Batch 110/145, Loss: 0.3568
Epoch 1/10, Batch 120/145, Loss: 0.6719
Epoch 1/10, Batch 130/145, Loss: 0.3083
Epoch 1/10, Batch 140/145, Loss: 0.4736
Epoch 1/10, Train Loss: 0.6766, Valid Loss: 0.3914
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3758
Epoch 2/10, Batch 20/145, Loss: 0.3598
Epoch 2/10, Batch 30/145, Loss: 0.2249
Epoch 2/10, Batch 40/145, Loss: 0.4182
Epoch 2/10, Batch 50/145, Loss: 0.4032
Epoch 2/10, Batch 60/145, Loss: 0.3195
Epoch 2/10, Batch 70/145, Loss: 0.2932
Epoch 2/10, Batch 80/145, Loss: 0.3545
Epoch 2/10, Batch 90/145, Loss: 0.3853
Epoch 2/10, Batch 100/145, Loss: 0.3534
Epoch 2/10, Batch 110/145, Loss: 0.3745
Epoch 2/10, Batch 120/145, Loss: 0.4497
Epoch 2/10, Batch 130/145, Loss: 0.2919
Epoch 2/10, Batch 140/145, Loss: 0.2369
Epoch 2/10, Train Loss: 0.3508, Valid Loss: 0.3105
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1756
Epoch 3/10, Batch 20/145, Loss: 0.2858
Epoch 3/10, Batch 30/145, Loss: 0.4187
Epoch 3/10, Batch 40/145, Loss: 0.2621
Epoch 3/10, Batch 50/145, Loss: 0.2720
Epoch 3/10, Batch 60/145, Loss: 0.2181
Epoch 3/10, Batch 70/145, Loss: 0.4684
Epoch 3/10, Batch 80/145, Loss: 0.1538
Epoch 3/10, Batch 90/145, Loss: 0.2999
Epoch 3/10, Batch 100/145, Loss: 0.2434
Epoch 3/10, Batch 110/145, Loss: 0.2344
Epoch 3/10, Batch 120/145, Loss: 0.3275
Epoch 3/10, Batch 130/145, Loss: 0.3964
Epoch 3/10, Batch 140/145, Loss: 0.1979
Epoch 3/10, Train Loss: 0.2870, Valid Loss: 0.2754
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4020
Epoch 4/10, Batch 20/145, Loss: 0.2523
Epoch 4/10, Batch 30/145, Loss: 0.1935
Epoch 4/10, Batch 40/145, Loss: 0.1548
Epoch 4/10, Batch 50/145, Loss: 0.1862
Epoch 4/10, Batch 60/145, Loss: 0.3889
Epoch 4/10, Batch 70/145, Loss: 0.2873
Epoch 4/10, Batch 80/145, Loss: 0.1441
Epoch 4/10, Batch 90/145, Loss: 0.2166
Epoch 4/10, Batch 100/145, Loss: 0.2864
Epoch 4/10, Batch 110/145, Loss: 0.0933
Epoch 4/10, Batch 120/145, Loss: 0.2748
Epoch 4/10, Batch 130/145, Loss: 0.1758
Epoch 4/10, Batch 140/145, Loss: 0.1488
Epoch 4/10, Train Loss: 0.2584, Valid Loss: 0.2582
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2925
Epoch 5/10, Batch 20/145, Loss: 0.1618
Epoch 5/10, Batch 30/145, Loss: 0.2620
Epoch 5/10, Batch 40/145, Loss: 0.1904
Epoch 5/10, Batch 50/145, Loss: 0.2180
Epoch 5/10, Batch 60/145, Loss: 0.2451
Epoch 5/10, Batch 70/145, Loss: 0.2344
Epoch 5/10, Batch 80/145, Loss: 0.2427
Epoch 5/10, Batch 90/145, Loss: 0.3775
Epoch 5/10, Batch 100/145, Loss: 0.2080
Epoch 5/10, Batch 110/145, Loss: 0.2399
Epoch 5/10, Batch 120/145, Loss: 0.4895
Epoch 5/10, Batch 130/145, Loss: 0.2646
Epoch 5/10, Batch 140/145, Loss: 0.1506
Epoch 5/10, Train Loss: 0.2385, Valid Loss: 0.2466
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1136
Epoch 6/10, Batch 20/145, Loss: 0.2470
Epoch 6/10, Batch 30/145, Loss: 0.2418
Epoch 6/10, Batch 40/145, Loss: 0.2400
Epoch 6/10, Batch 50/145, Loss: 0.5665
Epoch 6/10, Batch 60/145, Loss: 0.2204
Epoch 6/10, Batch 70/145, Loss: 0.1825
Epoch 6/10, Batch 80/145, Loss: 0.1806
Epoch 6/10, Batch 90/145, Loss: 0.3155
Epoch 6/10, Batch 100/145, Loss: 0.3445
Epoch 6/10, Batch 110/145, Loss: 0.2534
Epoch 6/10, Batch 120/145, Loss: 0.2741
Epoch 6/10, Batch 130/145, Loss: 0.0889
Epoch 6/10, Batch 140/145, Loss: 0.2116
Epoch 6/10, Train Loss: 0.2273, Valid Loss: 0.2350
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1727
Epoch 7/10, Batch 20/145, Loss: 0.2559
Epoch 7/10, Batch 30/145, Loss: 0.1374
Epoch 7/10, Batch 40/145, Loss: 0.3483
Epoch 7/10, Batch 50/145, Loss: 0.1561
Epoch 7/10, Batch 60/145, Loss: 0.2011
Epoch 7/10, Batch 70/145, Loss: 0.1611
Epoch 7/10, Batch 80/145, Loss: 0.4362
Epoch 7/10, Batch 90/145, Loss: 0.1044
Epoch 7/10, Batch 100/145, Loss: 0.0819
Epoch 7/10, Batch 110/145, Loss: 0.1760
Epoch 7/10, Batch 120/145, Loss: 0.1401
Epoch 7/10, Batch 130/145, Loss: 0.1334
Epoch 7/10, Batch 140/145, Loss: 0.2831
Epoch 7/10, Train Loss: 0.2183, Valid Loss: 0.2329
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1034
Epoch 8/10, Batch 20/145, Loss: 0.2023
Epoch 8/10, Batch 30/145, Loss: 0.2185
Epoch 8/10, Batch 40/145, Loss: 0.1706
Epoch 8/10, Batch 50/145, Loss: 0.1487
Epoch 8/10, Batch 60/145, Loss: 0.2544
Epoch 8/10, Batch 70/145, Loss: 0.3099
Epoch 8/10, Batch 80/145, Loss: 0.2673
Epoch 8/10, Batch 90/145, Loss: 0.1935
Epoch 8/10, Batch 100/145, Loss: 0.3420
Epoch 8/10, Batch 110/145, Loss: 0.1846
Epoch 8/10, Batch 120/145, Loss: 0.2316
Epoch 8/10, Batch 130/145, Loss: 0.2247
Epoch 8/10, Batch 140/145, Loss: 0.2504
Epoch 8/10, Train Loss: 0.2068, Valid Loss: 0.2334
Epoch 9/10, Batch 10/145, Loss: 0.3902
Epoch 9/10, Batch 20/145, Loss: 0.1197
Epoch 9/10, Batch 30/145, Loss: 0.2654
Epoch 9/10, Batch 40/145, Loss: 0.4467
Epoch 9/10, Batch 50/145, Loss: 0.1187
Epoch 9/10, Batch 60/145, Loss: 0.4659
Epoch 9/10, Batch 70/145, Loss: 0.1493
Epoch 9/10, Batch 80/145, Loss: 0.0765
Epoch 9/10, Batch 90/145, Loss: 0.3200
Epoch 9/10, Batch 100/145, Loss: 0.1512
Epoch 9/10, Batch 110/145, Loss: 0.4360
Epoch 9/10, Batch 120/145, Loss: 0.0902
Epoch 9/10, Batch 130/145, Loss: 0.1330
Epoch 9/10, Batch 140/145, Loss: 0.1753
Epoch 9/10, Train Loss: 0.1891, Valid Loss: 0.2225
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0746
Epoch 10/10, Batch 20/145, Loss: 0.0844
Epoch 10/10, Batch 30/145, Loss: 0.0557
Epoch 10/10, Batch 40/145, Loss: 0.3308
Epoch 10/10, Batch 50/145, Loss: 0.1966
Epoch 10/10, Batch 60/145, Loss: 0.2228
Epoch 10/10, Batch 70/145, Loss: 0.3805
Epoch 10/10, Batch 80/145, Loss: 0.2042
Epoch 10/10, Batch 90/145, Loss: 0.1389
Epoch 10/10, Batch 100/145, Loss: 0.1226
Epoch 10/10, Batch 110/145, Loss: 0.2966
Epoch 10/10, Batch 120/145, Loss: 0.2663
Epoch 10/10, Batch 130/145, Loss: 0.1401
Epoch 10/10, Batch 140/145, Loss: 0.2067
Epoch 10/10, Train Loss: 0.1899, Valid Loss: 0.2242
Accuracy: 0.9241
Precision: 0.9229
Recall: 0.9241
F1-score: 0.9226
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3631
Epoch 1/10, Batch 20/145, Loss: 0.8820
Epoch 1/10, Batch 30/145, Loss: 0.9163
Epoch 1/10, Batch 40/145, Loss: 0.8030
Epoch 1/10, Batch 50/145, Loss: 0.6964
Epoch 1/10, Batch 60/145, Loss: 0.6529
Epoch 1/10, Batch 70/145, Loss: 0.4941
Epoch 1/10, Batch 80/145, Loss: 0.6056
Epoch 1/10, Batch 90/145, Loss: 0.5165
Epoch 1/10, Batch 100/145, Loss: 0.5144
Epoch 1/10, Batch 110/145, Loss: 0.4674
Epoch 1/10, Batch 120/145, Loss: 0.4702
Epoch 1/10, Batch 130/145, Loss: 0.5108
Epoch 1/10, Batch 140/145, Loss: 0.3434
Epoch 1/10, Train Loss: 0.6783, Valid Loss: 0.3814
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2745
Epoch 2/10, Batch 20/145, Loss: 0.3958
Epoch 2/10, Batch 30/145, Loss: 0.2282
Epoch 2/10, Batch 40/145, Loss: 0.3178
Epoch 2/10, Batch 50/145, Loss: 0.3758
Epoch 2/10, Batch 60/145, Loss: 0.4593
Epoch 2/10, Batch 70/145, Loss: 0.3172
Epoch 2/10, Batch 80/145, Loss: 0.3865
Epoch 2/10, Batch 90/145, Loss: 0.2791
Epoch 2/10, Batch 100/145, Loss: 0.2556
Epoch 2/10, Batch 110/145, Loss: 0.2697
Epoch 2/10, Batch 120/145, Loss: 0.3824
Epoch 2/10, Batch 130/145, Loss: 0.3034
Epoch 2/10, Batch 140/145, Loss: 0.2993
Epoch 2/10, Train Loss: 0.3522, Valid Loss: 0.3010
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2880
Epoch 3/10, Batch 20/145, Loss: 0.2817
Epoch 3/10, Batch 30/145, Loss: 0.3311
Epoch 3/10, Batch 40/145, Loss: 0.1738
Epoch 3/10, Batch 50/145, Loss: 0.1415
Epoch 3/10, Batch 60/145, Loss: 0.3883
Epoch 3/10, Batch 70/145, Loss: 0.4842
Epoch 3/10, Batch 80/145, Loss: 0.3292
Epoch 3/10, Batch 90/145, Loss: 0.4231
Epoch 3/10, Batch 100/145, Loss: 0.2197
Epoch 3/10, Batch 110/145, Loss: 0.3641
Epoch 3/10, Batch 120/145, Loss: 0.2302
Epoch 3/10, Batch 130/145, Loss: 0.3234
Epoch 3/10, Batch 140/145, Loss: 0.2904
Epoch 3/10, Train Loss: 0.2899, Valid Loss: 0.2687
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4325
Epoch 4/10, Batch 20/145, Loss: 0.2313
Epoch 4/10, Batch 30/145, Loss: 0.2767
Epoch 4/10, Batch 40/145, Loss: 0.1467
Epoch 4/10, Batch 50/145, Loss: 0.2678
Epoch 4/10, Batch 60/145, Loss: 0.1584
Epoch 4/10, Batch 70/145, Loss: 0.1995
Epoch 4/10, Batch 80/145, Loss: 0.2639
Epoch 4/10, Batch 90/145, Loss: 0.1897
Epoch 4/10, Batch 100/145, Loss: 0.5114
Epoch 4/10, Batch 110/145, Loss: 0.1917
Epoch 4/10, Batch 120/145, Loss: 0.1306
Epoch 4/10, Batch 130/145, Loss: 0.1877
Epoch 4/10, Batch 140/145, Loss: 0.1101
Epoch 4/10, Train Loss: 0.2576, Valid Loss: 0.2561
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2251
Epoch 5/10, Batch 20/145, Loss: 0.0884
Epoch 5/10, Batch 30/145, Loss: 0.2583
Epoch 5/10, Batch 40/145, Loss: 0.1430
Epoch 5/10, Batch 50/145, Loss: 0.2459
Epoch 5/10, Batch 60/145, Loss: 0.1233
Epoch 5/10, Batch 70/145, Loss: 0.1870
Epoch 5/10, Batch 80/145, Loss: 0.1754
Epoch 5/10, Batch 90/145, Loss: 0.2981
Epoch 5/10, Batch 100/145, Loss: 0.1961
Epoch 5/10, Batch 110/145, Loss: 0.1030
Epoch 5/10, Batch 120/145, Loss: 0.3499
Epoch 5/10, Batch 130/145, Loss: 0.2196
Epoch 5/10, Batch 140/145, Loss: 0.1087
Epoch 5/10, Train Loss: 0.2408, Valid Loss: 0.2533
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1513
Epoch 6/10, Batch 20/145, Loss: 0.4166
Epoch 6/10, Batch 30/145, Loss: 0.2130
Epoch 6/10, Batch 40/145, Loss: 0.1582
Epoch 6/10, Batch 50/145, Loss: 0.1953
Epoch 6/10, Batch 60/145, Loss: 0.2634
Epoch 6/10, Batch 70/145, Loss: 0.1484
Epoch 6/10, Batch 80/145, Loss: 0.1401
Epoch 6/10, Batch 90/145, Loss: 0.1419
Epoch 6/10, Batch 100/145, Loss: 0.2269
Epoch 6/10, Batch 110/145, Loss: 0.1561
Epoch 6/10, Batch 120/145, Loss: 0.2795
Epoch 6/10, Batch 130/145, Loss: 0.2687
Epoch 6/10, Batch 140/145, Loss: 0.1155
Epoch 6/10, Train Loss: 0.2260, Valid Loss: 0.2409
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1853
Epoch 7/10, Batch 20/145, Loss: 0.2548
Epoch 7/10, Batch 30/145, Loss: 0.4193
Epoch 7/10, Batch 40/145, Loss: 0.2809
Epoch 7/10, Batch 50/145, Loss: 0.2423
Epoch 7/10, Batch 60/145, Loss: 0.1245
Epoch 7/10, Batch 70/145, Loss: 0.1381
Epoch 7/10, Batch 80/145, Loss: 0.3419
Epoch 7/10, Batch 90/145, Loss: 0.1878
Epoch 7/10, Batch 100/145, Loss: 0.1875
Epoch 7/10, Batch 110/145, Loss: 0.1086
Epoch 7/10, Batch 120/145, Loss: 0.3432
Epoch 7/10, Batch 130/145, Loss: 0.1077
Epoch 7/10, Batch 140/145, Loss: 0.1655
Epoch 7/10, Train Loss: 0.2091, Valid Loss: 0.2411
Epoch 8/10, Batch 10/145, Loss: 0.1045
Epoch 8/10, Batch 20/145, Loss: 0.1579
Epoch 8/10, Batch 30/145, Loss: 0.1933
Epoch 8/10, Batch 40/145, Loss: 0.1916
Epoch 8/10, Batch 50/145, Loss: 0.2112
Epoch 8/10, Batch 60/145, Loss: 0.2458
Epoch 8/10, Batch 70/145, Loss: 0.2041
Epoch 8/10, Batch 80/145, Loss: 0.3026
Epoch 8/10, Batch 90/145, Loss: 0.2845
Epoch 8/10, Batch 100/145, Loss: 0.1499
Epoch 8/10, Batch 110/145, Loss: 0.1489
Epoch 8/10, Batch 120/145, Loss: 0.2044
Epoch 8/10, Batch 130/145, Loss: 0.1044
Epoch 8/10, Batch 140/145, Loss: 0.2295
Epoch 8/10, Train Loss: 0.2026, Valid Loss: 0.2306
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2905
Epoch 9/10, Batch 20/145, Loss: 0.1163
Epoch 9/10, Batch 30/145, Loss: 0.0864
Epoch 9/10, Batch 40/145, Loss: 0.2007
Epoch 9/10, Batch 50/145, Loss: 0.0713
Epoch 9/10, Batch 60/145, Loss: 0.2917
Epoch 9/10, Batch 70/145, Loss: 0.0562
Epoch 9/10, Batch 80/145, Loss: 0.1119
Epoch 9/10, Batch 90/145, Loss: 0.1552
Epoch 9/10, Batch 100/145, Loss: 0.2805
Epoch 9/10, Batch 110/145, Loss: 0.1947
Epoch 9/10, Batch 120/145, Loss: 0.1282
Epoch 9/10, Batch 130/145, Loss: 0.4082
Epoch 9/10, Batch 140/145, Loss: 0.1575
Epoch 9/10, Train Loss: 0.1952, Valid Loss: 0.2338
Epoch 10/10, Batch 10/145, Loss: 0.1387
Epoch 10/10, Batch 20/145, Loss: 0.1328
Epoch 10/10, Batch 30/145, Loss: 0.1112
Epoch 10/10, Batch 40/145, Loss: 0.1104
Epoch 10/10, Batch 50/145, Loss: 0.1498
Epoch 10/10, Batch 60/145, Loss: 0.1526
Epoch 10/10, Batch 70/145, Loss: 0.2046
Epoch 10/10, Batch 80/145, Loss: 0.1026
Epoch 10/10, Batch 90/145, Loss: 0.0759
Epoch 10/10, Batch 100/145, Loss: 0.1147
Epoch 10/10, Batch 110/145, Loss: 0.1322
Epoch 10/10, Batch 120/145, Loss: 0.2952
Epoch 10/10, Batch 130/145, Loss: 0.1378
Epoch 10/10, Batch 140/145, Loss: 0.1878
Epoch 10/10, Train Loss: 0.1854, Valid Loss: 0.2266
Model saved!
Accuracy: 0.9194
Precision: 0.9169
Recall: 0.9194
F1-score: 0.9170
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3302
Epoch 1/10, Batch 20/145, Loss: 0.9545
Epoch 1/10, Batch 30/145, Loss: 0.8944
Epoch 1/10, Batch 40/145, Loss: 0.8504
Epoch 1/10, Batch 50/145, Loss: 0.8016
Epoch 1/10, Batch 60/145, Loss: 0.6245
Epoch 1/10, Batch 70/145, Loss: 0.4073
Epoch 1/10, Batch 80/145, Loss: 0.5185
Epoch 1/10, Batch 90/145, Loss: 0.3789
Epoch 1/10, Batch 100/145, Loss: 0.4044
Epoch 1/10, Batch 110/145, Loss: 0.4114
Epoch 1/10, Batch 120/145, Loss: 0.5297
Epoch 1/10, Batch 130/145, Loss: 0.5220
Epoch 1/10, Batch 140/145, Loss: 0.3963
Epoch 1/10, Train Loss: 0.6750, Valid Loss: 0.3859
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3836
Epoch 2/10, Batch 20/145, Loss: 0.3355
Epoch 2/10, Batch 30/145, Loss: 0.3458
Epoch 2/10, Batch 40/145, Loss: 0.3557
Epoch 2/10, Batch 50/145, Loss: 0.2563
Epoch 2/10, Batch 60/145, Loss: 0.3029
Epoch 2/10, Batch 70/145, Loss: 0.2626
Epoch 2/10, Batch 80/145, Loss: 0.2931
Epoch 2/10, Batch 90/145, Loss: 0.2829
Epoch 2/10, Batch 100/145, Loss: 0.2827
Epoch 2/10, Batch 110/145, Loss: 0.4488
Epoch 2/10, Batch 120/145, Loss: 0.3691
Epoch 2/10, Batch 130/145, Loss: 0.4260
Epoch 2/10, Batch 140/145, Loss: 0.2965
Epoch 2/10, Train Loss: 0.3480, Valid Loss: 0.3061
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1798
Epoch 3/10, Batch 20/145, Loss: 0.1240
Epoch 3/10, Batch 30/145, Loss: 0.3109
Epoch 3/10, Batch 40/145, Loss: 0.2456
Epoch 3/10, Batch 50/145, Loss: 0.2893
Epoch 3/10, Batch 60/145, Loss: 0.3145
Epoch 3/10, Batch 70/145, Loss: 0.2890
Epoch 3/10, Batch 80/145, Loss: 0.2050
Epoch 3/10, Batch 90/145, Loss: 0.2672
Epoch 3/10, Batch 100/145, Loss: 0.2524
Epoch 3/10, Batch 110/145, Loss: 0.2336
Epoch 3/10, Batch 120/145, Loss: 0.3481
Epoch 3/10, Batch 130/145, Loss: 0.2612
Epoch 3/10, Batch 140/145, Loss: 0.2323
Epoch 3/10, Train Loss: 0.2922, Valid Loss: 0.2740
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2682
Epoch 4/10, Batch 20/145, Loss: 0.2558
Epoch 4/10, Batch 30/145, Loss: 0.4040
Epoch 4/10, Batch 40/145, Loss: 0.1604
Epoch 4/10, Batch 50/145, Loss: 0.3667
Epoch 4/10, Batch 60/145, Loss: 0.3678
Epoch 4/10, Batch 70/145, Loss: 0.1634
Epoch 4/10, Batch 80/145, Loss: 0.1581
Epoch 4/10, Batch 90/145, Loss: 0.3318
Epoch 4/10, Batch 100/145, Loss: 0.3576
Epoch 4/10, Batch 110/145, Loss: 0.1784
Epoch 4/10, Batch 120/145, Loss: 0.1428
Epoch 4/10, Batch 130/145, Loss: 0.0941
Epoch 4/10, Batch 140/145, Loss: 0.2166
Epoch 4/10, Train Loss: 0.2513, Valid Loss: 0.2653
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1610
Epoch 5/10, Batch 20/145, Loss: 0.1368
Epoch 5/10, Batch 30/145, Loss: 0.3311
Epoch 5/10, Batch 40/145, Loss: 0.0786
Epoch 5/10, Batch 50/145, Loss: 0.2007
Epoch 5/10, Batch 60/145, Loss: 0.2376
Epoch 5/10, Batch 70/145, Loss: 0.2526
Epoch 5/10, Batch 80/145, Loss: 0.2906
Epoch 5/10, Batch 90/145, Loss: 0.2463
Epoch 5/10, Batch 100/145, Loss: 0.1967
Epoch 5/10, Batch 110/145, Loss: 0.2893
Epoch 5/10, Batch 120/145, Loss: 0.1810
Epoch 5/10, Batch 130/145, Loss: 0.1539
Epoch 5/10, Batch 140/145, Loss: 0.1693
Epoch 5/10, Train Loss: 0.2368, Valid Loss: 0.2557
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2096
Epoch 6/10, Batch 20/145, Loss: 0.3145
Epoch 6/10, Batch 30/145, Loss: 0.3486
Epoch 6/10, Batch 40/145, Loss: 0.1397
Epoch 6/10, Batch 50/145, Loss: 0.3239
Epoch 6/10, Batch 60/145, Loss: 0.1354
Epoch 6/10, Batch 70/145, Loss: 0.2206
Epoch 6/10, Batch 80/145, Loss: 0.2592
Epoch 6/10, Batch 90/145, Loss: 0.2481
Epoch 6/10, Batch 100/145, Loss: 0.2575
Epoch 6/10, Batch 110/145, Loss: 0.2471
Epoch 6/10, Batch 120/145, Loss: 0.2607
Epoch 6/10, Batch 130/145, Loss: 0.2303
Epoch 6/10, Batch 140/145, Loss: 0.2122
Epoch 6/10, Train Loss: 0.2169, Valid Loss: 0.2493
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1536
Epoch 7/10, Batch 20/145, Loss: 0.2530
Epoch 7/10, Batch 30/145, Loss: 0.1712
Epoch 7/10, Batch 40/145, Loss: 0.3237
Epoch 7/10, Batch 50/145, Loss: 0.1876
Epoch 7/10, Batch 60/145, Loss: 0.1239
Epoch 7/10, Batch 70/145, Loss: 0.0999
Epoch 7/10, Batch 80/145, Loss: 0.3810
Epoch 7/10, Batch 90/145, Loss: 0.3763
Epoch 7/10, Batch 100/145, Loss: 0.2162
Epoch 7/10, Batch 110/145, Loss: 0.1027
Epoch 7/10, Batch 120/145, Loss: 0.2533
Epoch 7/10, Batch 130/145, Loss: 0.1268
Epoch 7/10, Batch 140/145, Loss: 0.3441
Epoch 7/10, Train Loss: 0.2065, Valid Loss: 0.2477
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1825
Epoch 8/10, Batch 20/145, Loss: 0.1952
Epoch 8/10, Batch 30/145, Loss: 0.2289
Epoch 8/10, Batch 40/145, Loss: 0.1853
Epoch 8/10, Batch 50/145, Loss: 0.2827
Epoch 8/10, Batch 60/145, Loss: 0.1772
Epoch 8/10, Batch 70/145, Loss: 0.1654
Epoch 8/10, Batch 80/145, Loss: 0.1330
Epoch 8/10, Batch 90/145, Loss: 0.2502
Epoch 8/10, Batch 100/145, Loss: 0.2482
Epoch 8/10, Batch 110/145, Loss: 0.1474
Epoch 8/10, Batch 120/145, Loss: 0.2099
Epoch 8/10, Batch 130/145, Loss: 0.1679
Epoch 8/10, Batch 140/145, Loss: 0.2212
Epoch 8/10, Train Loss: 0.2006, Valid Loss: 0.2398
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2168
Epoch 9/10, Batch 20/145, Loss: 0.1962
Epoch 9/10, Batch 30/145, Loss: 0.4880
Epoch 9/10, Batch 40/145, Loss: 0.2075
Epoch 9/10, Batch 50/145, Loss: 0.1846
Epoch 9/10, Batch 60/145, Loss: 0.2599
Epoch 9/10, Batch 70/145, Loss: 0.3206
Epoch 9/10, Batch 80/145, Loss: 0.1367
Epoch 9/10, Batch 90/145, Loss: 0.3295
Epoch 9/10, Batch 100/145, Loss: 0.0789
Epoch 9/10, Batch 110/145, Loss: 0.1417
Epoch 9/10, Batch 120/145, Loss: 0.0760
Epoch 9/10, Batch 130/145, Loss: 0.0948
Epoch 9/10, Batch 140/145, Loss: 0.2318
Epoch 9/10, Train Loss: 0.1960, Valid Loss: 0.2427
Epoch 10/10, Batch 10/145, Loss: 0.2278
Epoch 10/10, Batch 20/145, Loss: 0.0949
Epoch 10/10, Batch 30/145, Loss: 0.1490
Epoch 10/10, Batch 40/145, Loss: 0.1788
Epoch 10/10, Batch 50/145, Loss: 0.1404
Epoch 10/10, Batch 60/145, Loss: 0.1210
Epoch 10/10, Batch 70/145, Loss: 0.1550
Epoch 10/10, Batch 80/145, Loss: 0.1891
Epoch 10/10, Batch 90/145, Loss: 0.1117
Epoch 10/10, Batch 100/145, Loss: 0.1963
Epoch 10/10, Batch 110/145, Loss: 0.3744
Epoch 10/10, Batch 120/145, Loss: 0.2149
Epoch 10/10, Batch 130/145, Loss: 0.1304
Epoch 10/10, Batch 140/145, Loss: 0.0596
Epoch 10/10, Train Loss: 0.1900, Valid Loss: 0.2458
Accuracy: 0.9241
Precision: 0.9219
Recall: 0.9241
F1-score: 0.9225
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3342
Epoch 1/10, Batch 20/145, Loss: 0.9349
Epoch 1/10, Batch 30/145, Loss: 0.8895
Epoch 1/10, Batch 40/145, Loss: 0.9632
Epoch 1/10, Batch 50/145, Loss: 0.6574
Epoch 1/10, Batch 60/145, Loss: 0.6788
Epoch 1/10, Batch 70/145, Loss: 0.5163
Epoch 1/10, Batch 80/145, Loss: 0.6924
Epoch 1/10, Batch 90/145, Loss: 0.5348
Epoch 1/10, Batch 100/145, Loss: 0.4608
Epoch 1/10, Batch 110/145, Loss: 0.6006
Epoch 1/10, Batch 120/145, Loss: 0.5257
Epoch 1/10, Batch 130/145, Loss: 0.4977
Epoch 1/10, Batch 140/145, Loss: 0.3706
Epoch 1/10, Train Loss: 0.6810, Valid Loss: 0.3988
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3775
Epoch 2/10, Batch 20/145, Loss: 0.2407
Epoch 2/10, Batch 30/145, Loss: 0.3378
Epoch 2/10, Batch 40/145, Loss: 0.4418
Epoch 2/10, Batch 50/145, Loss: 0.3294
Epoch 2/10, Batch 60/145, Loss: 0.5244
Epoch 2/10, Batch 70/145, Loss: 0.3114
Epoch 2/10, Batch 80/145, Loss: 0.4905
Epoch 2/10, Batch 90/145, Loss: 0.4367
Epoch 2/10, Batch 100/145, Loss: 0.2019
Epoch 2/10, Batch 110/145, Loss: 0.2961
Epoch 2/10, Batch 120/145, Loss: 0.3983
Epoch 2/10, Batch 130/145, Loss: 0.2697
Epoch 2/10, Batch 140/145, Loss: 0.3706
Epoch 2/10, Train Loss: 0.3550, Valid Loss: 0.3110
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3386
Epoch 3/10, Batch 20/145, Loss: 0.3262
Epoch 3/10, Batch 30/145, Loss: 0.3860
Epoch 3/10, Batch 40/145, Loss: 0.2796
Epoch 3/10, Batch 50/145, Loss: 0.2713
Epoch 3/10, Batch 60/145, Loss: 0.3532
Epoch 3/10, Batch 70/145, Loss: 0.2637
Epoch 3/10, Batch 80/145, Loss: 0.1476
Epoch 3/10, Batch 90/145, Loss: 0.2712
Epoch 3/10, Batch 100/145, Loss: 0.2479
Epoch 3/10, Batch 110/145, Loss: 0.1896
Epoch 3/10, Batch 120/145, Loss: 0.2767
Epoch 3/10, Batch 130/145, Loss: 0.3260
Epoch 3/10, Batch 140/145, Loss: 0.2475
Epoch 3/10, Train Loss: 0.2951, Valid Loss: 0.2805
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2921
Epoch 4/10, Batch 20/145, Loss: 0.3254
Epoch 4/10, Batch 30/145, Loss: 0.2520
Epoch 4/10, Batch 40/145, Loss: 0.0890
Epoch 4/10, Batch 50/145, Loss: 0.2609
Epoch 4/10, Batch 60/145, Loss: 0.1533
Epoch 4/10, Batch 70/145, Loss: 0.3212
Epoch 4/10, Batch 80/145, Loss: 0.1399
Epoch 4/10, Batch 90/145, Loss: 0.1838
Epoch 4/10, Batch 100/145, Loss: 0.2262
Epoch 4/10, Batch 110/145, Loss: 0.1946
Epoch 4/10, Batch 120/145, Loss: 0.3021
Epoch 4/10, Batch 130/145, Loss: 0.1948
Epoch 4/10, Batch 140/145, Loss: 0.2440
Epoch 4/10, Train Loss: 0.2610, Valid Loss: 0.2670
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1304
Epoch 5/10, Batch 20/145, Loss: 0.2186
Epoch 5/10, Batch 30/145, Loss: 0.2935
Epoch 5/10, Batch 40/145, Loss: 0.2391
Epoch 5/10, Batch 50/145, Loss: 0.2834
Epoch 5/10, Batch 60/145, Loss: 0.1723
Epoch 5/10, Batch 70/145, Loss: 0.2471
Epoch 5/10, Batch 80/145, Loss: 0.3973
Epoch 5/10, Batch 90/145, Loss: 0.2859
Epoch 5/10, Batch 100/145, Loss: 0.1503
Epoch 5/10, Batch 110/145, Loss: 0.2102
Epoch 5/10, Batch 120/145, Loss: 0.2985
Epoch 5/10, Batch 130/145, Loss: 0.3040
Epoch 5/10, Batch 140/145, Loss: 0.1246
Epoch 5/10, Train Loss: 0.2442, Valid Loss: 0.2510
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1144
Epoch 6/10, Batch 20/145, Loss: 0.5819
Epoch 6/10, Batch 30/145, Loss: 0.4767
Epoch 6/10, Batch 40/145, Loss: 0.2327
Epoch 6/10, Batch 50/145, Loss: 0.3881
Epoch 6/10, Batch 60/145, Loss: 0.2134
Epoch 6/10, Batch 70/145, Loss: 0.1580
Epoch 6/10, Batch 80/145, Loss: 0.4255
Epoch 6/10, Batch 90/145, Loss: 0.2047
Epoch 6/10, Batch 100/145, Loss: 0.1914
Epoch 6/10, Batch 110/145, Loss: 0.2677
Epoch 6/10, Batch 120/145, Loss: 0.1985
Epoch 6/10, Batch 130/145, Loss: 0.1427
Epoch 6/10, Batch 140/145, Loss: 0.2461
Epoch 6/10, Train Loss: 0.2301, Valid Loss: 0.2433
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.4100
Epoch 7/10, Batch 20/145, Loss: 0.3352
Epoch 7/10, Batch 30/145, Loss: 0.2046
Epoch 7/10, Batch 40/145, Loss: 0.3953
Epoch 7/10, Batch 50/145, Loss: 0.1094
Epoch 7/10, Batch 60/145, Loss: 0.1945
Epoch 7/10, Batch 70/145, Loss: 0.0981
Epoch 7/10, Batch 80/145, Loss: 0.2540
Epoch 7/10, Batch 90/145, Loss: 0.2651
Epoch 7/10, Batch 100/145, Loss: 0.0667
Epoch 7/10, Batch 110/145, Loss: 0.1739
Epoch 7/10, Batch 120/145, Loss: 0.3228
Epoch 7/10, Batch 130/145, Loss: 0.0978
Epoch 7/10, Batch 140/145, Loss: 0.2840
Epoch 7/10, Train Loss: 0.2156, Valid Loss: 0.2434
Epoch 8/10, Batch 10/145, Loss: 0.2418
Epoch 8/10, Batch 20/145, Loss: 0.1869
Epoch 8/10, Batch 30/145, Loss: 0.1078
Epoch 8/10, Batch 40/145, Loss: 0.1243
Epoch 8/10, Batch 50/145, Loss: 0.2073
Epoch 8/10, Batch 60/145, Loss: 0.1607
Epoch 8/10, Batch 70/145, Loss: 0.2682
Epoch 8/10, Batch 80/145, Loss: 0.1820
Epoch 8/10, Batch 90/145, Loss: 0.2115
Epoch 8/10, Batch 100/145, Loss: 0.2413
Epoch 8/10, Batch 110/145, Loss: 0.1560
Epoch 8/10, Batch 120/145, Loss: 0.1924
Epoch 8/10, Batch 130/145, Loss: 0.1213
Epoch 8/10, Batch 140/145, Loss: 0.1710
Epoch 8/10, Train Loss: 0.2028, Valid Loss: 0.2408
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3237
Epoch 9/10, Batch 20/145, Loss: 0.3408
Epoch 9/10, Batch 30/145, Loss: 0.1592
Epoch 9/10, Batch 40/145, Loss: 0.2074
Epoch 9/10, Batch 50/145, Loss: 0.2214
Epoch 9/10, Batch 60/145, Loss: 0.1851
Epoch 9/10, Batch 70/145, Loss: 0.0997
Epoch 9/10, Batch 80/145, Loss: 0.2905
Epoch 9/10, Batch 90/145, Loss: 0.2563
Epoch 9/10, Batch 100/145, Loss: 0.2645
Epoch 9/10, Batch 110/145, Loss: 0.2113
Epoch 9/10, Batch 120/145, Loss: 0.0980
Epoch 9/10, Batch 130/145, Loss: 0.2452
Epoch 9/10, Batch 140/145, Loss: 0.1495
Epoch 9/10, Train Loss: 0.1972, Valid Loss: 0.2339
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1550
Epoch 10/10, Batch 20/145, Loss: 0.1393
Epoch 10/10, Batch 30/145, Loss: 0.1025
Epoch 10/10, Batch 40/145, Loss: 0.1596
Epoch 10/10, Batch 50/145, Loss: 0.2290
Epoch 10/10, Batch 60/145, Loss: 0.0750
Epoch 10/10, Batch 70/145, Loss: 0.2934
Epoch 10/10, Batch 80/145, Loss: 0.1866
Epoch 10/10, Batch 90/145, Loss: 0.1532
Epoch 10/10, Batch 100/145, Loss: 0.2078
Epoch 10/10, Batch 110/145, Loss: 0.1059
Epoch 10/10, Batch 120/145, Loss: 0.3089
Epoch 10/10, Batch 130/145, Loss: 0.1647
Epoch 10/10, Batch 140/145, Loss: 0.0712
Epoch 10/10, Train Loss: 0.1889, Valid Loss: 0.2282
Model saved!
Accuracy: 0.9194
Precision: 0.9174
Recall: 0.9194
F1-score: 0.9179
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4070
Epoch 1/10, Batch 20/145, Loss: 0.9386
Epoch 1/10, Batch 30/145, Loss: 0.8482
Epoch 1/10, Batch 40/145, Loss: 0.7472
Epoch 1/10, Batch 50/145, Loss: 0.7892
Epoch 1/10, Batch 60/145, Loss: 0.6178
Epoch 1/10, Batch 70/145, Loss: 0.5155
Epoch 1/10, Batch 80/145, Loss: 0.6005
Epoch 1/10, Batch 90/145, Loss: 0.2989
Epoch 1/10, Batch 100/145, Loss: 0.3852
Epoch 1/10, Batch 110/145, Loss: 0.4044
Epoch 1/10, Batch 120/145, Loss: 0.5538
Epoch 1/10, Batch 130/145, Loss: 0.4406
Epoch 1/10, Batch 140/145, Loss: 0.3132
Epoch 1/10, Train Loss: 0.6764, Valid Loss: 0.3789
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3384
Epoch 2/10, Batch 20/145, Loss: 0.4118
Epoch 2/10, Batch 30/145, Loss: 0.2830
Epoch 2/10, Batch 40/145, Loss: 0.4216
Epoch 2/10, Batch 50/145, Loss: 0.3362
Epoch 2/10, Batch 60/145, Loss: 0.2998
Epoch 2/10, Batch 70/145, Loss: 0.3884
Epoch 2/10, Batch 80/145, Loss: 0.2427
Epoch 2/10, Batch 90/145, Loss: 0.2602
Epoch 2/10, Batch 100/145, Loss: 0.3212
Epoch 2/10, Batch 110/145, Loss: 0.3204
Epoch 2/10, Batch 120/145, Loss: 0.3288
Epoch 2/10, Batch 130/145, Loss: 0.2623
Epoch 2/10, Batch 140/145, Loss: 0.2972
Epoch 2/10, Train Loss: 0.3497, Valid Loss: 0.3019
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3065
Epoch 3/10, Batch 20/145, Loss: 0.3022
Epoch 3/10, Batch 30/145, Loss: 0.4413
Epoch 3/10, Batch 40/145, Loss: 0.2579
Epoch 3/10, Batch 50/145, Loss: 0.2457
Epoch 3/10, Batch 60/145, Loss: 0.3951
Epoch 3/10, Batch 70/145, Loss: 0.1817
Epoch 3/10, Batch 80/145, Loss: 0.2184
Epoch 3/10, Batch 90/145, Loss: 0.3305
Epoch 3/10, Batch 100/145, Loss: 0.2812
Epoch 3/10, Batch 110/145, Loss: 0.2035
Epoch 3/10, Batch 120/145, Loss: 0.2174
Epoch 3/10, Batch 130/145, Loss: 0.3721
Epoch 3/10, Batch 140/145, Loss: 0.4036
Epoch 3/10, Train Loss: 0.2920, Valid Loss: 0.2697
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3383
Epoch 4/10, Batch 20/145, Loss: 0.2980
Epoch 4/10, Batch 30/145, Loss: 0.3718
Epoch 4/10, Batch 40/145, Loss: 0.2225
Epoch 4/10, Batch 50/145, Loss: 0.1362
Epoch 4/10, Batch 60/145, Loss: 0.1869
Epoch 4/10, Batch 70/145, Loss: 0.1528
Epoch 4/10, Batch 80/145, Loss: 0.1763
Epoch 4/10, Batch 90/145, Loss: 0.3696
Epoch 4/10, Batch 100/145, Loss: 0.3092
Epoch 4/10, Batch 110/145, Loss: 0.1829
Epoch 4/10, Batch 120/145, Loss: 0.2099
Epoch 4/10, Batch 130/145, Loss: 0.1741
Epoch 4/10, Batch 140/145, Loss: 0.1311
Epoch 4/10, Train Loss: 0.2584, Valid Loss: 0.2564
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2060
Epoch 5/10, Batch 20/145, Loss: 0.1118
Epoch 5/10, Batch 30/145, Loss: 0.3863
Epoch 5/10, Batch 40/145, Loss: 0.1445
Epoch 5/10, Batch 50/145, Loss: 0.2311
Epoch 5/10, Batch 60/145, Loss: 0.1669
Epoch 5/10, Batch 70/145, Loss: 0.4967
Epoch 5/10, Batch 80/145, Loss: 0.2517
Epoch 5/10, Batch 90/145, Loss: 0.2005
Epoch 5/10, Batch 100/145, Loss: 0.2286
Epoch 5/10, Batch 110/145, Loss: 0.2613
Epoch 5/10, Batch 120/145, Loss: 0.2654
Epoch 5/10, Batch 130/145, Loss: 0.2489
Epoch 5/10, Batch 140/145, Loss: 0.1892
Epoch 5/10, Train Loss: 0.2425, Valid Loss: 0.2445
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2291
Epoch 6/10, Batch 20/145, Loss: 0.3866
Epoch 6/10, Batch 30/145, Loss: 0.2566
Epoch 6/10, Batch 40/145, Loss: 0.1391
Epoch 6/10, Batch 50/145, Loss: 0.2326
Epoch 6/10, Batch 60/145, Loss: 0.2893
Epoch 6/10, Batch 70/145, Loss: 0.1247
Epoch 6/10, Batch 80/145, Loss: 0.0707
Epoch 6/10, Batch 90/145, Loss: 0.1748
Epoch 6/10, Batch 100/145, Loss: 0.3447
Epoch 6/10, Batch 110/145, Loss: 0.2219
Epoch 6/10, Batch 120/145, Loss: 0.3130
Epoch 6/10, Batch 130/145, Loss: 0.1221
Epoch 6/10, Batch 140/145, Loss: 0.1108
Epoch 6/10, Train Loss: 0.2255, Valid Loss: 0.2340
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2393
Epoch 7/10, Batch 20/145, Loss: 0.1895
Epoch 7/10, Batch 30/145, Loss: 0.2288
Epoch 7/10, Batch 40/145, Loss: 0.2251
Epoch 7/10, Batch 50/145, Loss: 0.3919
Epoch 7/10, Batch 60/145, Loss: 0.0515
Epoch 7/10, Batch 70/145, Loss: 0.2653
Epoch 7/10, Batch 80/145, Loss: 0.4535
Epoch 7/10, Batch 90/145, Loss: 0.2267
Epoch 7/10, Batch 100/145, Loss: 0.1775
Epoch 7/10, Batch 110/145, Loss: 0.1547
Epoch 7/10, Batch 120/145, Loss: 0.2334
Epoch 7/10, Batch 130/145, Loss: 0.2593
Epoch 7/10, Batch 140/145, Loss: 0.2264
Epoch 7/10, Train Loss: 0.2101, Valid Loss: 0.2248
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2040
Epoch 8/10, Batch 20/145, Loss: 0.2954
Epoch 8/10, Batch 30/145, Loss: 0.2235
Epoch 8/10, Batch 40/145, Loss: 0.3123
Epoch 8/10, Batch 50/145, Loss: 0.1304
Epoch 8/10, Batch 60/145, Loss: 0.4094
Epoch 8/10, Batch 70/145, Loss: 0.2183
Epoch 8/10, Batch 80/145, Loss: 0.1127
Epoch 8/10, Batch 90/145, Loss: 0.2399
Epoch 8/10, Batch 100/145, Loss: 0.2526
Epoch 8/10, Batch 110/145, Loss: 0.1629
Epoch 8/10, Batch 120/145, Loss: 0.1833
Epoch 8/10, Batch 130/145, Loss: 0.1694
Epoch 8/10, Batch 140/145, Loss: 0.2673
Epoch 8/10, Train Loss: 0.2045, Valid Loss: 0.2210
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2580
Epoch 9/10, Batch 20/145, Loss: 0.2340
Epoch 9/10, Batch 30/145, Loss: 0.2608
Epoch 9/10, Batch 40/145, Loss: 0.1907
Epoch 9/10, Batch 50/145, Loss: 0.1450
Epoch 9/10, Batch 60/145, Loss: 0.1954
Epoch 9/10, Batch 70/145, Loss: 0.1856
Epoch 9/10, Batch 80/145, Loss: 0.0498
Epoch 9/10, Batch 90/145, Loss: 0.1920
Epoch 9/10, Batch 100/145, Loss: 0.2322
Epoch 9/10, Batch 110/145, Loss: 0.2238
Epoch 9/10, Batch 120/145, Loss: 0.2468
Epoch 9/10, Batch 130/145, Loss: 0.1168
Epoch 9/10, Batch 140/145, Loss: 0.2455
Epoch 9/10, Train Loss: 0.1934, Valid Loss: 0.2202
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0973
Epoch 10/10, Batch 20/145, Loss: 0.1404
Epoch 10/10, Batch 30/145, Loss: 0.0919
Epoch 10/10, Batch 40/145, Loss: 0.0943
Epoch 10/10, Batch 50/145, Loss: 0.1452
Epoch 10/10, Batch 60/145, Loss: 0.1076
Epoch 10/10, Batch 70/145, Loss: 0.5515
Epoch 10/10, Batch 80/145, Loss: 0.1245
Epoch 10/10, Batch 90/145, Loss: 0.2577
Epoch 10/10, Batch 100/145, Loss: 0.2613
Epoch 10/10, Batch 110/145, Loss: 0.1174
Epoch 10/10, Batch 120/145, Loss: 0.2286
Epoch 10/10, Batch 130/145, Loss: 0.2869
Epoch 10/10, Batch 140/145, Loss: 0.0616
Epoch 10/10, Train Loss: 0.1942, Valid Loss: 0.2168
Model saved!
Accuracy: 0.9206
Precision: 0.9180
Recall: 0.9206
F1-score: 0.9181
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4532
Epoch 1/10, Batch 20/145, Loss: 0.9756
Epoch 1/10, Batch 30/145, Loss: 0.8795
Epoch 1/10, Batch 40/145, Loss: 0.8697
Epoch 1/10, Batch 50/145, Loss: 0.6658
Epoch 1/10, Batch 60/145, Loss: 0.6714
Epoch 1/10, Batch 70/145, Loss: 0.4664
Epoch 1/10, Batch 80/145, Loss: 0.5938
Epoch 1/10, Batch 90/145, Loss: 0.3754
Epoch 1/10, Batch 100/145, Loss: 0.3962
Epoch 1/10, Batch 110/145, Loss: 0.4923
Epoch 1/10, Batch 120/145, Loss: 0.6923
Epoch 1/10, Batch 130/145, Loss: 0.5341
Epoch 1/10, Batch 140/145, Loss: 0.3538
Epoch 1/10, Train Loss: 0.6878, Valid Loss: 0.3689
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3081
Epoch 2/10, Batch 20/145, Loss: 0.3388
Epoch 2/10, Batch 30/145, Loss: 0.3384
Epoch 2/10, Batch 40/145, Loss: 0.4247
Epoch 2/10, Batch 50/145, Loss: 0.2724
Epoch 2/10, Batch 60/145, Loss: 0.3170
Epoch 2/10, Batch 70/145, Loss: 0.3248
Epoch 2/10, Batch 80/145, Loss: 0.2432
Epoch 2/10, Batch 90/145, Loss: 0.3265
Epoch 2/10, Batch 100/145, Loss: 0.2600
Epoch 2/10, Batch 110/145, Loss: 0.3241
Epoch 2/10, Batch 120/145, Loss: 0.3557
Epoch 2/10, Batch 130/145, Loss: 0.3131
Epoch 2/10, Batch 140/145, Loss: 0.3782
Epoch 2/10, Train Loss: 0.3606, Valid Loss: 0.2733
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2854
Epoch 3/10, Batch 20/145, Loss: 0.2484
Epoch 3/10, Batch 30/145, Loss: 0.3603
Epoch 3/10, Batch 40/145, Loss: 0.1962
Epoch 3/10, Batch 50/145, Loss: 0.3408
Epoch 3/10, Batch 60/145, Loss: 0.3969
Epoch 3/10, Batch 70/145, Loss: 0.3900
Epoch 3/10, Batch 80/145, Loss: 0.1878
Epoch 3/10, Batch 90/145, Loss: 0.3209
Epoch 3/10, Batch 100/145, Loss: 0.2894
Epoch 3/10, Batch 110/145, Loss: 0.1397
Epoch 3/10, Batch 120/145, Loss: 0.3076
Epoch 3/10, Batch 130/145, Loss: 0.3196
Epoch 3/10, Batch 140/145, Loss: 0.2426
Epoch 3/10, Train Loss: 0.2956, Valid Loss: 0.2401
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2478
Epoch 4/10, Batch 20/145, Loss: 0.3138
Epoch 4/10, Batch 30/145, Loss: 0.1696
Epoch 4/10, Batch 40/145, Loss: 0.1963
Epoch 4/10, Batch 50/145, Loss: 0.1790
Epoch 4/10, Batch 60/145, Loss: 0.1654
Epoch 4/10, Batch 70/145, Loss: 0.2761
Epoch 4/10, Batch 80/145, Loss: 0.2438
Epoch 4/10, Batch 90/145, Loss: 0.2095
Epoch 4/10, Batch 100/145, Loss: 0.3931
Epoch 4/10, Batch 110/145, Loss: 0.1712
Epoch 4/10, Batch 120/145, Loss: 0.2549
Epoch 4/10, Batch 130/145, Loss: 0.1514
Epoch 4/10, Batch 140/145, Loss: 0.2012
Epoch 4/10, Train Loss: 0.2622, Valid Loss: 0.2272
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2495
Epoch 5/10, Batch 20/145, Loss: 0.2881
Epoch 5/10, Batch 30/145, Loss: 0.2345
Epoch 5/10, Batch 40/145, Loss: 0.1940
Epoch 5/10, Batch 50/145, Loss: 0.1917
Epoch 5/10, Batch 60/145, Loss: 0.1678
Epoch 5/10, Batch 70/145, Loss: 0.2741
Epoch 5/10, Batch 80/145, Loss: 0.2341
Epoch 5/10, Batch 90/145, Loss: 0.2096
Epoch 5/10, Batch 100/145, Loss: 0.1625
Epoch 5/10, Batch 110/145, Loss: 0.2209
Epoch 5/10, Batch 120/145, Loss: 0.1892
Epoch 5/10, Batch 130/145, Loss: 0.1727
Epoch 5/10, Batch 140/145, Loss: 0.2372
Epoch 5/10, Train Loss: 0.2498, Valid Loss: 0.2123
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2103
Epoch 6/10, Batch 20/145, Loss: 0.3092
Epoch 6/10, Batch 30/145, Loss: 0.2919
Epoch 6/10, Batch 40/145, Loss: 0.1515
Epoch 6/10, Batch 50/145, Loss: 0.4104
Epoch 6/10, Batch 60/145, Loss: 0.3013
Epoch 6/10, Batch 70/145, Loss: 0.2059
Epoch 6/10, Batch 80/145, Loss: 0.1459
Epoch 6/10, Batch 90/145, Loss: 0.4684
Epoch 6/10, Batch 100/145, Loss: 0.3007
Epoch 6/10, Batch 110/145, Loss: 0.1608
Epoch 6/10, Batch 120/145, Loss: 0.2404
Epoch 6/10, Batch 130/145, Loss: 0.0825
Epoch 6/10, Batch 140/145, Loss: 0.1540
Epoch 6/10, Train Loss: 0.2282, Valid Loss: 0.2050
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1268
Epoch 7/10, Batch 20/145, Loss: 0.1794
Epoch 7/10, Batch 30/145, Loss: 0.3180
Epoch 7/10, Batch 40/145, Loss: 0.3264
Epoch 7/10, Batch 50/145, Loss: 0.2084
Epoch 7/10, Batch 60/145, Loss: 0.1957
Epoch 7/10, Batch 70/145, Loss: 0.1599
Epoch 7/10, Batch 80/145, Loss: 0.3420
Epoch 7/10, Batch 90/145, Loss: 0.3476
Epoch 7/10, Batch 100/145, Loss: 0.4184
Epoch 7/10, Batch 110/145, Loss: 0.1440
Epoch 7/10, Batch 120/145, Loss: 0.1803
Epoch 7/10, Batch 130/145, Loss: 0.0938
Epoch 7/10, Batch 140/145, Loss: 0.4612
Epoch 7/10, Train Loss: 0.2239, Valid Loss: 0.2012
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1557
Epoch 8/10, Batch 20/145, Loss: 0.1922
Epoch 8/10, Batch 30/145, Loss: 0.2096
Epoch 8/10, Batch 40/145, Loss: 0.1280
Epoch 8/10, Batch 50/145, Loss: 0.2991
Epoch 8/10, Batch 60/145, Loss: 0.3230
Epoch 8/10, Batch 70/145, Loss: 0.1897
Epoch 8/10, Batch 80/145, Loss: 0.2248
Epoch 8/10, Batch 90/145, Loss: 0.2844
Epoch 8/10, Batch 100/145, Loss: 0.2081
Epoch 8/10, Batch 110/145, Loss: 0.2061
Epoch 8/10, Batch 120/145, Loss: 0.1232
Epoch 8/10, Batch 130/145, Loss: 0.2760
Epoch 8/10, Batch 140/145, Loss: 0.2178
Epoch 8/10, Train Loss: 0.2126, Valid Loss: 0.1944
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1459
Epoch 9/10, Batch 20/145, Loss: 0.2255
Epoch 9/10, Batch 30/145, Loss: 0.1262
Epoch 9/10, Batch 40/145, Loss: 0.2446
Epoch 9/10, Batch 50/145, Loss: 0.2707
Epoch 9/10, Batch 60/145, Loss: 0.3495
Epoch 9/10, Batch 70/145, Loss: 0.1273
Epoch 9/10, Batch 80/145, Loss: 0.1916
Epoch 9/10, Batch 90/145, Loss: 0.2339
Epoch 9/10, Batch 100/145, Loss: 0.2599
Epoch 9/10, Batch 110/145, Loss: 0.3872
Epoch 9/10, Batch 120/145, Loss: 0.0593
Epoch 9/10, Batch 130/145, Loss: 0.3281
Epoch 9/10, Batch 140/145, Loss: 0.2400
Epoch 9/10, Train Loss: 0.2059, Valid Loss: 0.1917
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1034
Epoch 10/10, Batch 20/145, Loss: 0.1142
Epoch 10/10, Batch 30/145, Loss: 0.0921
Epoch 10/10, Batch 40/145, Loss: 0.1400
Epoch 10/10, Batch 50/145, Loss: 0.2731
Epoch 10/10, Batch 60/145, Loss: 0.1029
Epoch 10/10, Batch 70/145, Loss: 0.4011
Epoch 10/10, Batch 80/145, Loss: 0.1785
Epoch 10/10, Batch 90/145, Loss: 0.2021
Epoch 10/10, Batch 100/145, Loss: 0.1569
Epoch 10/10, Batch 110/145, Loss: 0.1557
Epoch 10/10, Batch 120/145, Loss: 0.1536
Epoch 10/10, Batch 130/145, Loss: 0.1311
Epoch 10/10, Batch 140/145, Loss: 0.2068
Epoch 10/10, Train Loss: 0.1987, Valid Loss: 0.1871
Model saved!
Accuracy: 0.9182
Precision: 0.9155
Recall: 0.9182
F1-score: 0.9163
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4082
Epoch 1/10, Batch 20/145, Loss: 0.9793
Epoch 1/10, Batch 30/145, Loss: 0.9216
Epoch 1/10, Batch 40/145, Loss: 0.7076
Epoch 1/10, Batch 50/145, Loss: 0.6747
Epoch 1/10, Batch 60/145, Loss: 0.6732
Epoch 1/10, Batch 70/145, Loss: 0.4318
Epoch 1/10, Batch 80/145, Loss: 0.5255
Epoch 1/10, Batch 90/145, Loss: 0.4618
Epoch 1/10, Batch 100/145, Loss: 0.4003
Epoch 1/10, Batch 110/145, Loss: 0.4686
Epoch 1/10, Batch 120/145, Loss: 0.5805
Epoch 1/10, Batch 130/145, Loss: 0.5924
Epoch 1/10, Batch 140/145, Loss: 0.3992
Epoch 1/10, Train Loss: 0.6767, Valid Loss: 0.3792
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3499
Epoch 2/10, Batch 20/145, Loss: 0.3333
Epoch 2/10, Batch 30/145, Loss: 0.2600
Epoch 2/10, Batch 40/145, Loss: 0.5354
Epoch 2/10, Batch 50/145, Loss: 0.2520
Epoch 2/10, Batch 60/145, Loss: 0.3482
Epoch 2/10, Batch 70/145, Loss: 0.3072
Epoch 2/10, Batch 80/145, Loss: 0.3287
Epoch 2/10, Batch 90/145, Loss: 0.2190
Epoch 2/10, Batch 100/145, Loss: 0.2482
Epoch 2/10, Batch 110/145, Loss: 0.3672
Epoch 2/10, Batch 120/145, Loss: 0.2562
Epoch 2/10, Batch 130/145, Loss: 0.3037
Epoch 2/10, Batch 140/145, Loss: 0.3248
Epoch 2/10, Train Loss: 0.3482, Valid Loss: 0.2992
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2795
Epoch 3/10, Batch 20/145, Loss: 0.2172
Epoch 3/10, Batch 30/145, Loss: 0.3032
Epoch 3/10, Batch 40/145, Loss: 0.2064
Epoch 3/10, Batch 50/145, Loss: 0.1679
Epoch 3/10, Batch 60/145, Loss: 0.3206
Epoch 3/10, Batch 70/145, Loss: 0.4462
Epoch 3/10, Batch 80/145, Loss: 0.2652
Epoch 3/10, Batch 90/145, Loss: 0.2002
Epoch 3/10, Batch 100/145, Loss: 0.4653
Epoch 3/10, Batch 110/145, Loss: 0.3724
Epoch 3/10, Batch 120/145, Loss: 0.2617
Epoch 3/10, Batch 130/145, Loss: 0.4206
Epoch 3/10, Batch 140/145, Loss: 0.1856
Epoch 3/10, Train Loss: 0.2907, Valid Loss: 0.2684
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3297
Epoch 4/10, Batch 20/145, Loss: 0.3233
Epoch 4/10, Batch 30/145, Loss: 0.1905
Epoch 4/10, Batch 40/145, Loss: 0.1611
Epoch 4/10, Batch 50/145, Loss: 0.1731
Epoch 4/10, Batch 60/145, Loss: 0.2794
Epoch 4/10, Batch 70/145, Loss: 0.3154
Epoch 4/10, Batch 80/145, Loss: 0.1986
Epoch 4/10, Batch 90/145, Loss: 0.2001
Epoch 4/10, Batch 100/145, Loss: 0.2565
Epoch 4/10, Batch 110/145, Loss: 0.1462
Epoch 4/10, Batch 120/145, Loss: 0.4038
Epoch 4/10, Batch 130/145, Loss: 0.3252
Epoch 4/10, Batch 140/145, Loss: 0.1055
Epoch 4/10, Train Loss: 0.2523, Valid Loss: 0.2536
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2207
Epoch 5/10, Batch 20/145, Loss: 0.1557
Epoch 5/10, Batch 30/145, Loss: 0.2242
Epoch 5/10, Batch 40/145, Loss: 0.1575
Epoch 5/10, Batch 50/145, Loss: 0.2326
Epoch 5/10, Batch 60/145, Loss: 0.2002
Epoch 5/10, Batch 70/145, Loss: 0.1905
Epoch 5/10, Batch 80/145, Loss: 0.2697
Epoch 5/10, Batch 90/145, Loss: 0.2191
Epoch 5/10, Batch 100/145, Loss: 0.2168
Epoch 5/10, Batch 110/145, Loss: 0.1400
Epoch 5/10, Batch 120/145, Loss: 0.1818
Epoch 5/10, Batch 130/145, Loss: 0.1450
Epoch 5/10, Batch 140/145, Loss: 0.1720
Epoch 5/10, Train Loss: 0.2437, Valid Loss: 0.2397
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1647
Epoch 6/10, Batch 20/145, Loss: 0.2456
Epoch 6/10, Batch 30/145, Loss: 0.1596
Epoch 6/10, Batch 40/145, Loss: 0.1385
Epoch 6/10, Batch 50/145, Loss: 0.3941
Epoch 6/10, Batch 60/145, Loss: 0.2496
Epoch 6/10, Batch 70/145, Loss: 0.2622
Epoch 6/10, Batch 80/145, Loss: 0.1569
Epoch 6/10, Batch 90/145, Loss: 0.1464
Epoch 6/10, Batch 100/145, Loss: 0.2042
Epoch 6/10, Batch 110/145, Loss: 0.1465
Epoch 6/10, Batch 120/145, Loss: 0.2552
Epoch 6/10, Batch 130/145, Loss: 0.4268
Epoch 6/10, Batch 140/145, Loss: 0.1779
Epoch 6/10, Train Loss: 0.2284, Valid Loss: 0.2346
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2001
Epoch 7/10, Batch 20/145, Loss: 0.2880
Epoch 7/10, Batch 30/145, Loss: 0.2315
Epoch 7/10, Batch 40/145, Loss: 0.2457
Epoch 7/10, Batch 50/145, Loss: 0.1112
Epoch 7/10, Batch 60/145, Loss: 0.1821
Epoch 7/10, Batch 70/145, Loss: 0.3096
Epoch 7/10, Batch 80/145, Loss: 0.3353
Epoch 7/10, Batch 90/145, Loss: 0.2180
Epoch 7/10, Batch 100/145, Loss: 0.1966
Epoch 7/10, Batch 110/145, Loss: 0.1941
Epoch 7/10, Batch 120/145, Loss: 0.1898
Epoch 7/10, Batch 130/145, Loss: 0.1008
Epoch 7/10, Batch 140/145, Loss: 0.3281
Epoch 7/10, Train Loss: 0.2157, Valid Loss: 0.2322
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1799
Epoch 8/10, Batch 20/145, Loss: 0.4683
Epoch 8/10, Batch 30/145, Loss: 0.3306
Epoch 8/10, Batch 40/145, Loss: 0.1827
Epoch 8/10, Batch 50/145, Loss: 0.2508
Epoch 8/10, Batch 60/145, Loss: 0.2866
Epoch 8/10, Batch 70/145, Loss: 0.2050
Epoch 8/10, Batch 80/145, Loss: 0.2027
Epoch 8/10, Batch 90/145, Loss: 0.2237
Epoch 8/10, Batch 100/145, Loss: 0.2110
Epoch 8/10, Batch 110/145, Loss: 0.2086
Epoch 8/10, Batch 120/145, Loss: 0.2683
Epoch 8/10, Batch 130/145, Loss: 0.2616
Epoch 8/10, Batch 140/145, Loss: 0.1504
Epoch 8/10, Train Loss: 0.2133, Valid Loss: 0.2272
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2602
Epoch 9/10, Batch 20/145, Loss: 0.2039
Epoch 9/10, Batch 30/145, Loss: 0.0627
Epoch 9/10, Batch 40/145, Loss: 0.1145
Epoch 9/10, Batch 50/145, Loss: 0.2201
Epoch 9/10, Batch 60/145, Loss: 0.1453
Epoch 9/10, Batch 70/145, Loss: 0.1327
Epoch 9/10, Batch 80/145, Loss: 0.1062
Epoch 9/10, Batch 90/145, Loss: 0.3624
Epoch 9/10, Batch 100/145, Loss: 0.1681
Epoch 9/10, Batch 110/145, Loss: 0.2105
Epoch 9/10, Batch 120/145, Loss: 0.1133
Epoch 9/10, Batch 130/145, Loss: 0.2274
Epoch 9/10, Batch 140/145, Loss: 0.1470
Epoch 9/10, Train Loss: 0.2026, Valid Loss: 0.2233
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1394
Epoch 10/10, Batch 20/145, Loss: 0.1730
Epoch 10/10, Batch 30/145, Loss: 0.2312
Epoch 10/10, Batch 40/145, Loss: 0.0870
Epoch 10/10, Batch 50/145, Loss: 0.2603
Epoch 10/10, Batch 60/145, Loss: 0.1955
Epoch 10/10, Batch 70/145, Loss: 0.1695
Epoch 10/10, Batch 80/145, Loss: 0.1786
Epoch 10/10, Batch 90/145, Loss: 0.1394
Epoch 10/10, Batch 100/145, Loss: 0.1620
Epoch 10/10, Batch 110/145, Loss: 0.2617
Epoch 10/10, Batch 120/145, Loss: 0.1509
Epoch 10/10, Batch 130/145, Loss: 0.1354
Epoch 10/10, Batch 140/145, Loss: 0.1687
Epoch 10/10, Train Loss: 0.1991, Valid Loss: 0.2253
Accuracy: 0.9276
Precision: 0.9259
Recall: 0.9276
F1-score: 0.9261
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 19. Fitness: 0.9276
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4383
Epoch 1/10, Batch 20/145, Loss: 1.0000
Epoch 1/10, Batch 30/145, Loss: 0.9873
Epoch 1/10, Batch 40/145, Loss: 0.7810
Epoch 1/10, Batch 50/145, Loss: 0.7520
Epoch 1/10, Batch 60/145, Loss: 0.6221
Epoch 1/10, Batch 70/145, Loss: 0.4891
Epoch 1/10, Batch 80/145, Loss: 0.6027
Epoch 1/10, Batch 90/145, Loss: 0.4567
Epoch 1/10, Batch 100/145, Loss: 0.3990
Epoch 1/10, Batch 110/145, Loss: 0.5889
Epoch 1/10, Batch 120/145, Loss: 0.4819
Epoch 1/10, Batch 130/145, Loss: 0.4491
Epoch 1/10, Batch 140/145, Loss: 0.4218
Epoch 1/10, Train Loss: 0.6798, Valid Loss: 0.4031
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3906
Epoch 2/10, Batch 20/145, Loss: 0.2627
Epoch 2/10, Batch 30/145, Loss: 0.3700
Epoch 2/10, Batch 40/145, Loss: 0.4550
Epoch 2/10, Batch 50/145, Loss: 0.4446
Epoch 2/10, Batch 60/145, Loss: 0.3522
Epoch 2/10, Batch 70/145, Loss: 0.3028
Epoch 2/10, Batch 80/145, Loss: 0.2280
Epoch 2/10, Batch 90/145, Loss: 0.5235
Epoch 2/10, Batch 100/145, Loss: 0.2819
Epoch 2/10, Batch 110/145, Loss: 0.2974
Epoch 2/10, Batch 120/145, Loss: 0.3842
Epoch 2/10, Batch 130/145, Loss: 0.2809
Epoch 2/10, Batch 140/145, Loss: 0.2009
Epoch 2/10, Train Loss: 0.3514, Valid Loss: 0.3257
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1622
Epoch 3/10, Batch 20/145, Loss: 0.4010
Epoch 3/10, Batch 30/145, Loss: 0.3673
Epoch 3/10, Batch 40/145, Loss: 0.2426
Epoch 3/10, Batch 50/145, Loss: 0.1591
Epoch 3/10, Batch 60/145, Loss: 0.2969
Epoch 3/10, Batch 70/145, Loss: 0.3945
Epoch 3/10, Batch 80/145, Loss: 0.2403
Epoch 3/10, Batch 90/145, Loss: 0.3435
Epoch 3/10, Batch 100/145, Loss: 0.2623
Epoch 3/10, Batch 110/145, Loss: 0.2147
Epoch 3/10, Batch 120/145, Loss: 0.1650
Epoch 3/10, Batch 130/145, Loss: 0.4084
Epoch 3/10, Batch 140/145, Loss: 0.1856
Epoch 3/10, Train Loss: 0.2934, Valid Loss: 0.2944
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2927
Epoch 4/10, Batch 20/145, Loss: 0.3916
Epoch 4/10, Batch 30/145, Loss: 0.4214
Epoch 4/10, Batch 40/145, Loss: 0.1488
Epoch 4/10, Batch 50/145, Loss: 0.1525
Epoch 4/10, Batch 60/145, Loss: 0.3381
Epoch 4/10, Batch 70/145, Loss: 0.2183
Epoch 4/10, Batch 80/145, Loss: 0.2505
Epoch 4/10, Batch 90/145, Loss: 0.3136
Epoch 4/10, Batch 100/145, Loss: 0.3198
Epoch 4/10, Batch 110/145, Loss: 0.1436
Epoch 4/10, Batch 120/145, Loss: 0.3498
Epoch 4/10, Batch 130/145, Loss: 0.1326
Epoch 4/10, Batch 140/145, Loss: 0.2028
Epoch 4/10, Train Loss: 0.2564, Valid Loss: 0.2827
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1954
Epoch 5/10, Batch 20/145, Loss: 0.1799
Epoch 5/10, Batch 30/145, Loss: 0.2819
Epoch 5/10, Batch 40/145, Loss: 0.1499
Epoch 5/10, Batch 50/145, Loss: 0.2250
Epoch 5/10, Batch 60/145, Loss: 0.2445
Epoch 5/10, Batch 70/145, Loss: 0.2203
Epoch 5/10, Batch 80/145, Loss: 0.1994
Epoch 5/10, Batch 90/145, Loss: 0.2787
Epoch 5/10, Batch 100/145, Loss: 0.1650
Epoch 5/10, Batch 110/145, Loss: 0.1894
Epoch 5/10, Batch 120/145, Loss: 0.3471
Epoch 5/10, Batch 130/145, Loss: 0.1642
Epoch 5/10, Batch 140/145, Loss: 0.2780
Epoch 5/10, Train Loss: 0.2455, Valid Loss: 0.2743
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1161
Epoch 6/10, Batch 20/145, Loss: 0.3273
Epoch 6/10, Batch 30/145, Loss: 0.3163
Epoch 6/10, Batch 40/145, Loss: 0.1422
Epoch 6/10, Batch 50/145, Loss: 0.3310
Epoch 6/10, Batch 60/145, Loss: 0.1150
Epoch 6/10, Batch 70/145, Loss: 0.3952
Epoch 6/10, Batch 80/145, Loss: 0.1721
Epoch 6/10, Batch 90/145, Loss: 0.4219
Epoch 6/10, Batch 100/145, Loss: 0.3854
Epoch 6/10, Batch 110/145, Loss: 0.2480
Epoch 6/10, Batch 120/145, Loss: 0.2544
Epoch 6/10, Batch 130/145, Loss: 0.1465
Epoch 6/10, Batch 140/145, Loss: 0.2108
Epoch 6/10, Train Loss: 0.2270, Valid Loss: 0.2720
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1702
Epoch 7/10, Batch 20/145, Loss: 0.2649
Epoch 7/10, Batch 30/145, Loss: 0.1675
Epoch 7/10, Batch 40/145, Loss: 0.2638
Epoch 7/10, Batch 50/145, Loss: 0.2463
Epoch 7/10, Batch 60/145, Loss: 0.1668
Epoch 7/10, Batch 70/145, Loss: 0.0610
Epoch 7/10, Batch 80/145, Loss: 0.6342
Epoch 7/10, Batch 90/145, Loss: 0.1685
Epoch 7/10, Batch 100/145, Loss: 0.1236
Epoch 7/10, Batch 110/145, Loss: 0.1149
Epoch 7/10, Batch 120/145, Loss: 0.2094
Epoch 7/10, Batch 130/145, Loss: 0.2424
Epoch 7/10, Batch 140/145, Loss: 0.4200
Epoch 7/10, Train Loss: 0.2165, Valid Loss: 0.2640
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1553
Epoch 8/10, Batch 20/145, Loss: 0.3016
Epoch 8/10, Batch 30/145, Loss: 0.2080
Epoch 8/10, Batch 40/145, Loss: 0.1396
Epoch 8/10, Batch 50/145, Loss: 0.2851
Epoch 8/10, Batch 60/145, Loss: 0.2398
Epoch 8/10, Batch 70/145, Loss: 0.2366
Epoch 8/10, Batch 80/145, Loss: 0.3747
Epoch 8/10, Batch 90/145, Loss: 0.2544
Epoch 8/10, Batch 100/145, Loss: 0.1968
Epoch 8/10, Batch 110/145, Loss: 0.1132
Epoch 8/10, Batch 120/145, Loss: 0.1496
Epoch 8/10, Batch 130/145, Loss: 0.1288
Epoch 8/10, Batch 140/145, Loss: 0.2261
Epoch 8/10, Train Loss: 0.2090, Valid Loss: 0.2567
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2631
Epoch 9/10, Batch 20/145, Loss: 0.1244
Epoch 9/10, Batch 30/145, Loss: 0.0887
Epoch 9/10, Batch 40/145, Loss: 0.1897
Epoch 9/10, Batch 50/145, Loss: 0.1258
Epoch 9/10, Batch 60/145, Loss: 0.1820
Epoch 9/10, Batch 70/145, Loss: 0.1853
Epoch 9/10, Batch 80/145, Loss: 0.0958
Epoch 9/10, Batch 90/145, Loss: 0.3040
Epoch 9/10, Batch 100/145, Loss: 0.1736
Epoch 9/10, Batch 110/145, Loss: 0.2371
Epoch 9/10, Batch 120/145, Loss: 0.1962
Epoch 9/10, Batch 130/145, Loss: 0.0968
Epoch 9/10, Batch 140/145, Loss: 0.1617
Epoch 9/10, Train Loss: 0.1964, Valid Loss: 0.2555
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1130
Epoch 10/10, Batch 20/145, Loss: 0.1968
Epoch 10/10, Batch 30/145, Loss: 0.2099
Epoch 10/10, Batch 40/145, Loss: 0.0947
Epoch 10/10, Batch 50/145, Loss: 0.2054
Epoch 10/10, Batch 60/145, Loss: 0.0619
Epoch 10/10, Batch 70/145, Loss: 0.2307
Epoch 10/10, Batch 80/145, Loss: 0.1488
Epoch 10/10, Batch 90/145, Loss: 0.2620
Epoch 10/10, Batch 100/145, Loss: 0.3445
Epoch 10/10, Batch 110/145, Loss: 0.2021
Epoch 10/10, Batch 120/145, Loss: 0.1552
Epoch 10/10, Batch 130/145, Loss: 0.1821
Epoch 10/10, Batch 140/145, Loss: 0.2129
Epoch 10/10, Train Loss: 0.1857, Valid Loss: 0.2544
Model saved!
Accuracy: 0.9206
Precision: 0.9182
Recall: 0.9206
F1-score: 0.9182
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3976
Epoch 1/10, Batch 20/145, Loss: 0.9537
Epoch 1/10, Batch 30/145, Loss: 0.9372
Epoch 1/10, Batch 40/145, Loss: 0.7504
Epoch 1/10, Batch 50/145, Loss: 0.6919
Epoch 1/10, Batch 60/145, Loss: 0.5695
Epoch 1/10, Batch 70/145, Loss: 0.4471
Epoch 1/10, Batch 80/145, Loss: 0.4998
Epoch 1/10, Batch 90/145, Loss: 0.5069
Epoch 1/10, Batch 100/145, Loss: 0.4288
Epoch 1/10, Batch 110/145, Loss: 0.4581
Epoch 1/10, Batch 120/145, Loss: 0.5388
Epoch 1/10, Batch 130/145, Loss: 0.5628
Epoch 1/10, Batch 140/145, Loss: 0.3437
Epoch 1/10, Train Loss: 0.6774, Valid Loss: 0.3871
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4435
Epoch 2/10, Batch 20/145, Loss: 0.2849
Epoch 2/10, Batch 30/145, Loss: 0.2959
Epoch 2/10, Batch 40/145, Loss: 0.4766
Epoch 2/10, Batch 50/145, Loss: 0.2858
Epoch 2/10, Batch 60/145, Loss: 0.4002
Epoch 2/10, Batch 70/145, Loss: 0.3326
Epoch 2/10, Batch 80/145, Loss: 0.2667
Epoch 2/10, Batch 90/145, Loss: 0.2616
Epoch 2/10, Batch 100/145, Loss: 0.2390
Epoch 2/10, Batch 110/145, Loss: 0.2656
Epoch 2/10, Batch 120/145, Loss: 0.2561
Epoch 2/10, Batch 130/145, Loss: 0.2584
Epoch 2/10, Batch 140/145, Loss: 0.3310
Epoch 2/10, Train Loss: 0.3513, Valid Loss: 0.2995
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2153
Epoch 3/10, Batch 20/145, Loss: 0.2859
Epoch 3/10, Batch 30/145, Loss: 0.4063
Epoch 3/10, Batch 40/145, Loss: 0.1857
Epoch 3/10, Batch 50/145, Loss: 0.1998
Epoch 3/10, Batch 60/145, Loss: 0.5235
Epoch 3/10, Batch 70/145, Loss: 0.2701
Epoch 3/10, Batch 80/145, Loss: 0.1873
Epoch 3/10, Batch 90/145, Loss: 0.2416
Epoch 3/10, Batch 100/145, Loss: 0.3559
Epoch 3/10, Batch 110/145, Loss: 0.3706
Epoch 3/10, Batch 120/145, Loss: 0.3359
Epoch 3/10, Batch 130/145, Loss: 0.2805
Epoch 3/10, Batch 140/145, Loss: 0.2789
Epoch 3/10, Train Loss: 0.2948, Valid Loss: 0.2694
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3234
Epoch 4/10, Batch 20/145, Loss: 0.3960
Epoch 4/10, Batch 30/145, Loss: 0.2197
Epoch 4/10, Batch 40/145, Loss: 0.1590
Epoch 4/10, Batch 50/145, Loss: 0.1870
Epoch 4/10, Batch 60/145, Loss: 0.2775
Epoch 4/10, Batch 70/145, Loss: 0.2455
Epoch 4/10, Batch 80/145, Loss: 0.1399
Epoch 4/10, Batch 90/145, Loss: 0.3620
Epoch 4/10, Batch 100/145, Loss: 0.3170
Epoch 4/10, Batch 110/145, Loss: 0.1891
Epoch 4/10, Batch 120/145, Loss: 0.1421
Epoch 4/10, Batch 130/145, Loss: 0.2051
Epoch 4/10, Batch 140/145, Loss: 0.1195
Epoch 4/10, Train Loss: 0.2586, Valid Loss: 0.2594
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1998
Epoch 5/10, Batch 20/145, Loss: 0.0822
Epoch 5/10, Batch 30/145, Loss: 0.1510
Epoch 5/10, Batch 40/145, Loss: 0.0761
Epoch 5/10, Batch 50/145, Loss: 0.3445
Epoch 5/10, Batch 60/145, Loss: 0.1172
Epoch 5/10, Batch 70/145, Loss: 0.2645
Epoch 5/10, Batch 80/145, Loss: 0.2115
Epoch 5/10, Batch 90/145, Loss: 0.2982
Epoch 5/10, Batch 100/145, Loss: 0.2099
Epoch 5/10, Batch 110/145, Loss: 0.2543
Epoch 5/10, Batch 120/145, Loss: 0.2738
Epoch 5/10, Batch 130/145, Loss: 0.1683
Epoch 5/10, Batch 140/145, Loss: 0.1493
Epoch 5/10, Train Loss: 0.2371, Valid Loss: 0.2419
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2705
Epoch 6/10, Batch 20/145, Loss: 0.4191
Epoch 6/10, Batch 30/145, Loss: 0.2372
Epoch 6/10, Batch 40/145, Loss: 0.1872
Epoch 6/10, Batch 50/145, Loss: 0.3798
Epoch 6/10, Batch 60/145, Loss: 0.2985
Epoch 6/10, Batch 70/145, Loss: 0.1565
Epoch 6/10, Batch 80/145, Loss: 0.1931
Epoch 6/10, Batch 90/145, Loss: 0.3527
Epoch 6/10, Batch 100/145, Loss: 0.2872
Epoch 6/10, Batch 110/145, Loss: 0.1695
Epoch 6/10, Batch 120/145, Loss: 0.3015
Epoch 6/10, Batch 130/145, Loss: 0.2075
Epoch 6/10, Batch 140/145, Loss: 0.2022
Epoch 6/10, Train Loss: 0.2246, Valid Loss: 0.2336
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1942
Epoch 7/10, Batch 20/145, Loss: 0.2725
Epoch 7/10, Batch 30/145, Loss: 0.1853
Epoch 7/10, Batch 40/145, Loss: 0.2137
Epoch 7/10, Batch 50/145, Loss: 0.2808
Epoch 7/10, Batch 60/145, Loss: 0.1451
Epoch 7/10, Batch 70/145, Loss: 0.2485
Epoch 7/10, Batch 80/145, Loss: 0.3256
Epoch 7/10, Batch 90/145, Loss: 0.1248
Epoch 7/10, Batch 100/145, Loss: 0.1966
Epoch 7/10, Batch 110/145, Loss: 0.2171
Epoch 7/10, Batch 120/145, Loss: 0.1426
Epoch 7/10, Batch 130/145, Loss: 0.1585
Epoch 7/10, Batch 140/145, Loss: 0.2860
Epoch 7/10, Train Loss: 0.2117, Valid Loss: 0.2329
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2654
Epoch 8/10, Batch 20/145, Loss: 0.1674
Epoch 8/10, Batch 30/145, Loss: 0.2432
Epoch 8/10, Batch 40/145, Loss: 0.1787
Epoch 8/10, Batch 50/145, Loss: 0.2544
Epoch 8/10, Batch 60/145, Loss: 0.2262
Epoch 8/10, Batch 70/145, Loss: 0.2158
Epoch 8/10, Batch 80/145, Loss: 0.1952
Epoch 8/10, Batch 90/145, Loss: 0.5543
Epoch 8/10, Batch 100/145, Loss: 0.1405
Epoch 8/10, Batch 110/145, Loss: 0.2278
Epoch 8/10, Batch 120/145, Loss: 0.1722
Epoch 8/10, Batch 130/145, Loss: 0.2600
Epoch 8/10, Batch 140/145, Loss: 0.2521
Epoch 8/10, Train Loss: 0.2057, Valid Loss: 0.2217
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3447
Epoch 9/10, Batch 20/145, Loss: 0.1896
Epoch 9/10, Batch 30/145, Loss: 0.2877
Epoch 9/10, Batch 40/145, Loss: 0.1617
Epoch 9/10, Batch 50/145, Loss: 0.1681
Epoch 9/10, Batch 60/145, Loss: 0.2443
Epoch 9/10, Batch 70/145, Loss: 0.2429
Epoch 9/10, Batch 80/145, Loss: 0.1587
Epoch 9/10, Batch 90/145, Loss: 0.1498
Epoch 9/10, Batch 100/145, Loss: 0.1071
Epoch 9/10, Batch 110/145, Loss: 0.3510
Epoch 9/10, Batch 120/145, Loss: 0.1172
Epoch 9/10, Batch 130/145, Loss: 0.1380
Epoch 9/10, Batch 140/145, Loss: 0.3439
Epoch 9/10, Train Loss: 0.2003, Valid Loss: 0.2200
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0533
Epoch 10/10, Batch 20/145, Loss: 0.3034
Epoch 10/10, Batch 30/145, Loss: 0.0757
Epoch 10/10, Batch 40/145, Loss: 0.0797
Epoch 10/10, Batch 50/145, Loss: 0.2040
Epoch 10/10, Batch 60/145, Loss: 0.2569
Epoch 10/10, Batch 70/145, Loss: 0.1268
Epoch 10/10, Batch 80/145, Loss: 0.2327
Epoch 10/10, Batch 90/145, Loss: 0.0672
Epoch 10/10, Batch 100/145, Loss: 0.1110
Epoch 10/10, Batch 110/145, Loss: 0.3268
Epoch 10/10, Batch 120/145, Loss: 0.1621
Epoch 10/10, Batch 130/145, Loss: 0.1644
Epoch 10/10, Batch 140/145, Loss: 0.2111
Epoch 10/10, Train Loss: 0.1920, Valid Loss: 0.2140
Model saved!
Accuracy: 0.9229
Precision: 0.9205
Recall: 0.9229
F1-score: 0.9208
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3783
Epoch 1/10, Batch 20/145, Loss: 0.9272
Epoch 1/10, Batch 30/145, Loss: 1.0353
Epoch 1/10, Batch 40/145, Loss: 0.7175
Epoch 1/10, Batch 50/145, Loss: 0.6766
Epoch 1/10, Batch 60/145, Loss: 0.5915
Epoch 1/10, Batch 70/145, Loss: 0.4678
Epoch 1/10, Batch 80/145, Loss: 0.5937
Epoch 1/10, Batch 90/145, Loss: 0.4687
Epoch 1/10, Batch 100/145, Loss: 0.4805
Epoch 1/10, Batch 110/145, Loss: 0.5236
Epoch 1/10, Batch 120/145, Loss: 0.6445
Epoch 1/10, Batch 130/145, Loss: 0.5357
Epoch 1/10, Batch 140/145, Loss: 0.4024
Epoch 1/10, Train Loss: 0.6796, Valid Loss: 0.3812
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4140
Epoch 2/10, Batch 20/145, Loss: 0.3790
Epoch 2/10, Batch 30/145, Loss: 0.3512
Epoch 2/10, Batch 40/145, Loss: 0.4386
Epoch 2/10, Batch 50/145, Loss: 0.4775
Epoch 2/10, Batch 60/145, Loss: 0.3716
Epoch 2/10, Batch 70/145, Loss: 0.3938
Epoch 2/10, Batch 80/145, Loss: 0.3295
Epoch 2/10, Batch 90/145, Loss: 0.2969
Epoch 2/10, Batch 100/145, Loss: 0.2920
Epoch 2/10, Batch 110/145, Loss: 0.3794
Epoch 2/10, Batch 120/145, Loss: 0.3257
Epoch 2/10, Batch 130/145, Loss: 0.2966
Epoch 2/10, Batch 140/145, Loss: 0.2525
Epoch 2/10, Train Loss: 0.3552, Valid Loss: 0.2920
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3643
Epoch 3/10, Batch 20/145, Loss: 0.3145
Epoch 3/10, Batch 30/145, Loss: 0.2727
Epoch 3/10, Batch 40/145, Loss: 0.2069
Epoch 3/10, Batch 50/145, Loss: 0.2741
Epoch 3/10, Batch 60/145, Loss: 0.3397
Epoch 3/10, Batch 70/145, Loss: 0.5227
Epoch 3/10, Batch 80/145, Loss: 0.2087
Epoch 3/10, Batch 90/145, Loss: 0.2538
Epoch 3/10, Batch 100/145, Loss: 0.2794
Epoch 3/10, Batch 110/145, Loss: 0.2916
Epoch 3/10, Batch 120/145, Loss: 0.1523
Epoch 3/10, Batch 130/145, Loss: 0.4322
Epoch 3/10, Batch 140/145, Loss: 0.3872
Epoch 3/10, Train Loss: 0.2901, Valid Loss: 0.2666
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3403
Epoch 4/10, Batch 20/145, Loss: 0.2225
Epoch 4/10, Batch 30/145, Loss: 0.1979
Epoch 4/10, Batch 40/145, Loss: 0.1634
Epoch 4/10, Batch 50/145, Loss: 0.2268
Epoch 4/10, Batch 60/145, Loss: 0.2621
Epoch 4/10, Batch 70/145, Loss: 0.1452
Epoch 4/10, Batch 80/145, Loss: 0.1808
Epoch 4/10, Batch 90/145, Loss: 0.3082
Epoch 4/10, Batch 100/145, Loss: 0.3524
Epoch 4/10, Batch 110/145, Loss: 0.1217
Epoch 4/10, Batch 120/145, Loss: 0.2982
Epoch 4/10, Batch 130/145, Loss: 0.2604
Epoch 4/10, Batch 140/145, Loss: 0.1050
Epoch 4/10, Train Loss: 0.2584, Valid Loss: 0.2500
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3294
Epoch 5/10, Batch 20/145, Loss: 0.1027
Epoch 5/10, Batch 30/145, Loss: 0.3946
Epoch 5/10, Batch 40/145, Loss: 0.1086
Epoch 5/10, Batch 50/145, Loss: 0.3515
Epoch 5/10, Batch 60/145, Loss: 0.4715
Epoch 5/10, Batch 70/145, Loss: 0.2377
Epoch 5/10, Batch 80/145, Loss: 0.2538
Epoch 5/10, Batch 90/145, Loss: 0.2715
Epoch 5/10, Batch 100/145, Loss: 0.2721
Epoch 5/10, Batch 110/145, Loss: 0.1845
Epoch 5/10, Batch 120/145, Loss: 0.2242
Epoch 5/10, Batch 130/145, Loss: 0.1527
Epoch 5/10, Batch 140/145, Loss: 0.2001
Epoch 5/10, Train Loss: 0.2415, Valid Loss: 0.2452
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1130
Epoch 6/10, Batch 20/145, Loss: 0.3051
Epoch 6/10, Batch 30/145, Loss: 0.1921
Epoch 6/10, Batch 40/145, Loss: 0.1244
Epoch 6/10, Batch 50/145, Loss: 0.3201
Epoch 6/10, Batch 60/145, Loss: 0.2291
Epoch 6/10, Batch 70/145, Loss: 0.1438
Epoch 6/10, Batch 80/145, Loss: 0.1939
Epoch 6/10, Batch 90/145, Loss: 0.1924
Epoch 6/10, Batch 100/145, Loss: 0.2705
Epoch 6/10, Batch 110/145, Loss: 0.3512
Epoch 6/10, Batch 120/145, Loss: 0.2046
Epoch 6/10, Batch 130/145, Loss: 0.3558
Epoch 6/10, Batch 140/145, Loss: 0.2317
Epoch 6/10, Train Loss: 0.2251, Valid Loss: 0.2324
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2605
Epoch 7/10, Batch 20/145, Loss: 0.1889
Epoch 7/10, Batch 30/145, Loss: 0.2249
Epoch 7/10, Batch 40/145, Loss: 0.3354
Epoch 7/10, Batch 50/145, Loss: 0.3370
Epoch 7/10, Batch 60/145, Loss: 0.1972
Epoch 7/10, Batch 70/145, Loss: 0.2520
Epoch 7/10, Batch 80/145, Loss: 0.3291
Epoch 7/10, Batch 90/145, Loss: 0.1942
Epoch 7/10, Batch 100/145, Loss: 0.2037
Epoch 7/10, Batch 110/145, Loss: 0.2081
Epoch 7/10, Batch 120/145, Loss: 0.1789
Epoch 7/10, Batch 130/145, Loss: 0.0895
Epoch 7/10, Batch 140/145, Loss: 0.2862
Epoch 7/10, Train Loss: 0.2144, Valid Loss: 0.2360
Epoch 8/10, Batch 10/145, Loss: 0.2025
Epoch 8/10, Batch 20/145, Loss: 0.2967
Epoch 8/10, Batch 30/145, Loss: 0.2886
Epoch 8/10, Batch 40/145, Loss: 0.2498
Epoch 8/10, Batch 50/145, Loss: 0.2359
Epoch 8/10, Batch 60/145, Loss: 0.1325
Epoch 8/10, Batch 70/145, Loss: 0.2882
Epoch 8/10, Batch 80/145, Loss: 0.3017
Epoch 8/10, Batch 90/145, Loss: 0.1573
Epoch 8/10, Batch 100/145, Loss: 0.1615
Epoch 8/10, Batch 110/145, Loss: 0.3349
Epoch 8/10, Batch 120/145, Loss: 0.1045
Epoch 8/10, Batch 130/145, Loss: 0.1945
Epoch 8/10, Batch 140/145, Loss: 0.4734
Epoch 8/10, Train Loss: 0.2063, Valid Loss: 0.2339
Epoch 9/10, Batch 10/145, Loss: 0.4082
Epoch 9/10, Batch 20/145, Loss: 0.0920
Epoch 9/10, Batch 30/145, Loss: 0.1823
Epoch 9/10, Batch 40/145, Loss: 0.1453
Epoch 9/10, Batch 50/145, Loss: 0.0806
Epoch 9/10, Batch 60/145, Loss: 0.2490
Epoch 9/10, Batch 70/145, Loss: 0.2357
Epoch 9/10, Batch 80/145, Loss: 0.0891
Epoch 9/10, Batch 90/145, Loss: 0.2267
Epoch 9/10, Batch 100/145, Loss: 0.1964
Epoch 9/10, Batch 110/145, Loss: 0.3133
Epoch 9/10, Batch 120/145, Loss: 0.2417
Epoch 9/10, Batch 130/145, Loss: 0.2122
Epoch 9/10, Batch 140/145, Loss: 0.2292
Epoch 9/10, Train Loss: 0.1979, Valid Loss: 0.2261
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1646
Epoch 10/10, Batch 20/145, Loss: 0.1695
Epoch 10/10, Batch 30/145, Loss: 0.1489
Epoch 10/10, Batch 40/145, Loss: 0.0946
Epoch 10/10, Batch 50/145, Loss: 0.1972
Epoch 10/10, Batch 60/145, Loss: 0.0810
Epoch 10/10, Batch 70/145, Loss: 0.2280
Epoch 10/10, Batch 80/145, Loss: 0.2234
Epoch 10/10, Batch 90/145, Loss: 0.2719
Epoch 10/10, Batch 100/145, Loss: 0.1578
Epoch 10/10, Batch 110/145, Loss: 0.1070
Epoch 10/10, Batch 120/145, Loss: 0.1903
Epoch 10/10, Batch 130/145, Loss: 0.1701
Epoch 10/10, Batch 140/145, Loss: 0.1684
Epoch 10/10, Train Loss: 0.1846, Valid Loss: 0.2247
Model saved!
Accuracy: 0.9264
Precision: 0.9242
Recall: 0.9264
F1-score: 0.9249
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4274
Epoch 1/10, Batch 20/145, Loss: 0.9731
Epoch 1/10, Batch 30/145, Loss: 0.9027
Epoch 1/10, Batch 40/145, Loss: 0.8305
Epoch 1/10, Batch 50/145, Loss: 0.7871
Epoch 1/10, Batch 60/145, Loss: 0.6251
Epoch 1/10, Batch 70/145, Loss: 0.4186
Epoch 1/10, Batch 80/145, Loss: 0.4887
Epoch 1/10, Batch 90/145, Loss: 0.5431
Epoch 1/10, Batch 100/145, Loss: 0.4811
Epoch 1/10, Batch 110/145, Loss: 0.4607
Epoch 1/10, Batch 120/145, Loss: 0.4075
Epoch 1/10, Batch 130/145, Loss: 0.3966
Epoch 1/10, Batch 140/145, Loss: 0.3567
Epoch 1/10, Train Loss: 0.6789, Valid Loss: 0.3961
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3479
Epoch 2/10, Batch 20/145, Loss: 0.2502
Epoch 2/10, Batch 30/145, Loss: 0.3907
Epoch 2/10, Batch 40/145, Loss: 0.3928
Epoch 2/10, Batch 50/145, Loss: 0.3957
Epoch 2/10, Batch 60/145, Loss: 0.4412
Epoch 2/10, Batch 70/145, Loss: 0.3846
Epoch 2/10, Batch 80/145, Loss: 0.2116
Epoch 2/10, Batch 90/145, Loss: 0.2955
Epoch 2/10, Batch 100/145, Loss: 0.2286
Epoch 2/10, Batch 110/145, Loss: 0.4037
Epoch 2/10, Batch 120/145, Loss: 0.2811
Epoch 2/10, Batch 130/145, Loss: 0.2865
Epoch 2/10, Batch 140/145, Loss: 0.2456
Epoch 2/10, Train Loss: 0.3506, Valid Loss: 0.3122
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2646
Epoch 3/10, Batch 20/145, Loss: 0.2145
Epoch 3/10, Batch 30/145, Loss: 0.2089
Epoch 3/10, Batch 40/145, Loss: 0.2590
Epoch 3/10, Batch 50/145, Loss: 0.1514
Epoch 3/10, Batch 60/145, Loss: 0.3497
Epoch 3/10, Batch 70/145, Loss: 0.2240
Epoch 3/10, Batch 80/145, Loss: 0.1935
Epoch 3/10, Batch 90/145, Loss: 0.3241
Epoch 3/10, Batch 100/145, Loss: 0.1889
Epoch 3/10, Batch 110/145, Loss: 0.2137
Epoch 3/10, Batch 120/145, Loss: 0.1954
Epoch 3/10, Batch 130/145, Loss: 0.2696
Epoch 3/10, Batch 140/145, Loss: 0.3291
Epoch 3/10, Train Loss: 0.2916, Valid Loss: 0.2845
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2949
Epoch 4/10, Batch 20/145, Loss: 0.2643
Epoch 4/10, Batch 30/145, Loss: 0.1778
Epoch 4/10, Batch 40/145, Loss: 0.3059
Epoch 4/10, Batch 50/145, Loss: 0.2909
Epoch 4/10, Batch 60/145, Loss: 0.2841
Epoch 4/10, Batch 70/145, Loss: 0.1612
Epoch 4/10, Batch 80/145, Loss: 0.2359
Epoch 4/10, Batch 90/145, Loss: 0.2965
Epoch 4/10, Batch 100/145, Loss: 0.3757
Epoch 4/10, Batch 110/145, Loss: 0.1368
Epoch 4/10, Batch 120/145, Loss: 0.1948
Epoch 4/10, Batch 130/145, Loss: 0.1513
Epoch 4/10, Batch 140/145, Loss: 0.1653
Epoch 4/10, Train Loss: 0.2598, Valid Loss: 0.2748
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1535
Epoch 5/10, Batch 20/145, Loss: 0.1532
Epoch 5/10, Batch 30/145, Loss: 0.3181
Epoch 5/10, Batch 40/145, Loss: 0.2172
Epoch 5/10, Batch 50/145, Loss: 0.2440
Epoch 5/10, Batch 60/145, Loss: 0.2756
Epoch 5/10, Batch 70/145, Loss: 0.2759
Epoch 5/10, Batch 80/145, Loss: 0.0969
Epoch 5/10, Batch 90/145, Loss: 0.1844
Epoch 5/10, Batch 100/145, Loss: 0.2045
Epoch 5/10, Batch 110/145, Loss: 0.1342
Epoch 5/10, Batch 120/145, Loss: 0.3846
Epoch 5/10, Batch 130/145, Loss: 0.2287
Epoch 5/10, Batch 140/145, Loss: 0.1222
Epoch 5/10, Train Loss: 0.2403, Valid Loss: 0.2582
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1797
Epoch 6/10, Batch 20/145, Loss: 0.3297
Epoch 6/10, Batch 30/145, Loss: 0.1611
Epoch 6/10, Batch 40/145, Loss: 0.2066
Epoch 6/10, Batch 50/145, Loss: 0.3758
Epoch 6/10, Batch 60/145, Loss: 0.1064
Epoch 6/10, Batch 70/145, Loss: 0.1027
Epoch 6/10, Batch 80/145, Loss: 0.1264
Epoch 6/10, Batch 90/145, Loss: 0.4157
Epoch 6/10, Batch 100/145, Loss: 0.2511
Epoch 6/10, Batch 110/145, Loss: 0.1532
Epoch 6/10, Batch 120/145, Loss: 0.2457
Epoch 6/10, Batch 130/145, Loss: 0.1029
Epoch 6/10, Batch 140/145, Loss: 0.2207
Epoch 6/10, Train Loss: 0.2291, Valid Loss: 0.2500
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2963
Epoch 7/10, Batch 20/145, Loss: 0.4086
Epoch 7/10, Batch 30/145, Loss: 0.2263
Epoch 7/10, Batch 40/145, Loss: 0.2833
Epoch 7/10, Batch 50/145, Loss: 0.2134
Epoch 7/10, Batch 60/145, Loss: 0.1803
Epoch 7/10, Batch 70/145, Loss: 0.2345
Epoch 7/10, Batch 80/145, Loss: 0.5494
Epoch 7/10, Batch 90/145, Loss: 0.3131
Epoch 7/10, Batch 100/145, Loss: 0.0901
Epoch 7/10, Batch 110/145, Loss: 0.2658
Epoch 7/10, Batch 120/145, Loss: 0.0665
Epoch 7/10, Batch 130/145, Loss: 0.0931
Epoch 7/10, Batch 140/145, Loss: 0.3498
Epoch 7/10, Train Loss: 0.2136, Valid Loss: 0.2501
Epoch 8/10, Batch 10/145, Loss: 0.2337
Epoch 8/10, Batch 20/145, Loss: 0.1934
Epoch 8/10, Batch 30/145, Loss: 0.1410
Epoch 8/10, Batch 40/145, Loss: 0.1548
Epoch 8/10, Batch 50/145, Loss: 0.2398
Epoch 8/10, Batch 60/145, Loss: 0.1590
Epoch 8/10, Batch 70/145, Loss: 0.2340
Epoch 8/10, Batch 80/145, Loss: 0.1817
Epoch 8/10, Batch 90/145, Loss: 0.2499
Epoch 8/10, Batch 100/145, Loss: 0.1970
Epoch 8/10, Batch 110/145, Loss: 0.1910
Epoch 8/10, Batch 120/145, Loss: 0.3741
Epoch 8/10, Batch 130/145, Loss: 0.1518
Epoch 8/10, Batch 140/145, Loss: 0.1636
Epoch 8/10, Train Loss: 0.2068, Valid Loss: 0.2448
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1517
Epoch 9/10, Batch 20/145, Loss: 0.2271
Epoch 9/10, Batch 30/145, Loss: 0.3304
Epoch 9/10, Batch 40/145, Loss: 0.1048
Epoch 9/10, Batch 50/145, Loss: 0.2033
Epoch 9/10, Batch 60/145, Loss: 0.1622
Epoch 9/10, Batch 70/145, Loss: 0.1827
Epoch 9/10, Batch 80/145, Loss: 0.1764
Epoch 9/10, Batch 90/145, Loss: 0.2510
Epoch 9/10, Batch 100/145, Loss: 0.1356
Epoch 9/10, Batch 110/145, Loss: 0.3184
Epoch 9/10, Batch 120/145, Loss: 0.1569
Epoch 9/10, Batch 130/145, Loss: 0.2547
Epoch 9/10, Batch 140/145, Loss: 0.2105
Epoch 9/10, Train Loss: 0.2003, Valid Loss: 0.2436
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1418
Epoch 10/10, Batch 20/145, Loss: 0.1517
Epoch 10/10, Batch 30/145, Loss: 0.1308
Epoch 10/10, Batch 40/145, Loss: 0.1272
Epoch 10/10, Batch 50/145, Loss: 0.2145
Epoch 10/10, Batch 60/145, Loss: 0.0677
Epoch 10/10, Batch 70/145, Loss: 0.2806
Epoch 10/10, Batch 80/145, Loss: 0.2718
Epoch 10/10, Batch 90/145, Loss: 0.1923
Epoch 10/10, Batch 100/145, Loss: 0.0795
Epoch 10/10, Batch 110/145, Loss: 0.1342
Epoch 10/10, Batch 120/145, Loss: 0.2026
Epoch 10/10, Batch 130/145, Loss: 0.1799
Epoch 10/10, Batch 140/145, Loss: 0.2247
Epoch 10/10, Train Loss: 0.1830, Valid Loss: 0.2437
Accuracy: 0.9171
Precision: 0.9154
Recall: 0.9171
F1-score: 0.9157
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4438
Epoch 1/10, Batch 20/145, Loss: 0.9741
Epoch 1/10, Batch 30/145, Loss: 0.9553
Epoch 1/10, Batch 40/145, Loss: 0.6783
Epoch 1/10, Batch 50/145, Loss: 0.6933
Epoch 1/10, Batch 60/145, Loss: 0.6131
Epoch 1/10, Batch 70/145, Loss: 0.4266
Epoch 1/10, Batch 80/145, Loss: 0.5748
Epoch 1/10, Batch 90/145, Loss: 0.4705
Epoch 1/10, Batch 100/145, Loss: 0.5587
Epoch 1/10, Batch 110/145, Loss: 0.3262
Epoch 1/10, Batch 120/145, Loss: 0.5275
Epoch 1/10, Batch 130/145, Loss: 0.5339
Epoch 1/10, Batch 140/145, Loss: 0.4227
Epoch 1/10, Train Loss: 0.6781, Valid Loss: 0.3586
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2626
Epoch 2/10, Batch 20/145, Loss: 0.3412
Epoch 2/10, Batch 30/145, Loss: 0.2689
Epoch 2/10, Batch 40/145, Loss: 0.5202
Epoch 2/10, Batch 50/145, Loss: 0.2313
Epoch 2/10, Batch 60/145, Loss: 0.3652
Epoch 2/10, Batch 70/145, Loss: 0.2831
Epoch 2/10, Batch 80/145, Loss: 0.3619
Epoch 2/10, Batch 90/145, Loss: 0.3324
Epoch 2/10, Batch 100/145, Loss: 0.1982
Epoch 2/10, Batch 110/145, Loss: 0.4466
Epoch 2/10, Batch 120/145, Loss: 0.4433
Epoch 2/10, Batch 130/145, Loss: 0.2454
Epoch 2/10, Batch 140/145, Loss: 0.3451
Epoch 2/10, Train Loss: 0.3528, Valid Loss: 0.2790
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1868
Epoch 3/10, Batch 20/145, Loss: 0.2029
Epoch 3/10, Batch 30/145, Loss: 0.3329
Epoch 3/10, Batch 40/145, Loss: 0.2748
Epoch 3/10, Batch 50/145, Loss: 0.2923
Epoch 3/10, Batch 60/145, Loss: 0.4221
Epoch 3/10, Batch 70/145, Loss: 0.4590
Epoch 3/10, Batch 80/145, Loss: 0.2742
Epoch 3/10, Batch 90/145, Loss: 0.2691
Epoch 3/10, Batch 100/145, Loss: 0.2659
Epoch 3/10, Batch 110/145, Loss: 0.1274
Epoch 3/10, Batch 120/145, Loss: 0.2486
Epoch 3/10, Batch 130/145, Loss: 0.3095
Epoch 3/10, Batch 140/145, Loss: 0.2319
Epoch 3/10, Train Loss: 0.2915, Valid Loss: 0.2497
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2967
Epoch 4/10, Batch 20/145, Loss: 0.1994
Epoch 4/10, Batch 30/145, Loss: 0.3628
Epoch 4/10, Batch 40/145, Loss: 0.1080
Epoch 4/10, Batch 50/145, Loss: 0.3408
Epoch 4/10, Batch 60/145, Loss: 0.5157
Epoch 4/10, Batch 70/145, Loss: 0.1969
Epoch 4/10, Batch 80/145, Loss: 0.1977
Epoch 4/10, Batch 90/145, Loss: 0.2496
Epoch 4/10, Batch 100/145, Loss: 0.2771
Epoch 4/10, Batch 110/145, Loss: 0.0734
Epoch 4/10, Batch 120/145, Loss: 0.1761
Epoch 4/10, Batch 130/145, Loss: 0.1152
Epoch 4/10, Batch 140/145, Loss: 0.1494
Epoch 4/10, Train Loss: 0.2568, Valid Loss: 0.2344
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2222
Epoch 5/10, Batch 20/145, Loss: 0.2151
Epoch 5/10, Batch 30/145, Loss: 0.1516
Epoch 5/10, Batch 40/145, Loss: 0.0693
Epoch 5/10, Batch 50/145, Loss: 0.1973
Epoch 5/10, Batch 60/145, Loss: 0.1909
Epoch 5/10, Batch 70/145, Loss: 0.1193
Epoch 5/10, Batch 80/145, Loss: 0.1648
Epoch 5/10, Batch 90/145, Loss: 0.1609
Epoch 5/10, Batch 100/145, Loss: 0.1930
Epoch 5/10, Batch 110/145, Loss: 0.2430
Epoch 5/10, Batch 120/145, Loss: 0.2766
Epoch 5/10, Batch 130/145, Loss: 0.1751
Epoch 5/10, Batch 140/145, Loss: 0.3359
Epoch 5/10, Train Loss: 0.2408, Valid Loss: 0.2314
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2006
Epoch 6/10, Batch 20/145, Loss: 0.5467
Epoch 6/10, Batch 30/145, Loss: 0.2375
Epoch 6/10, Batch 40/145, Loss: 0.2117
Epoch 6/10, Batch 50/145, Loss: 0.2285
Epoch 6/10, Batch 60/145, Loss: 0.1937
Epoch 6/10, Batch 70/145, Loss: 0.1227
Epoch 6/10, Batch 80/145, Loss: 0.1233
Epoch 6/10, Batch 90/145, Loss: 0.2156
Epoch 6/10, Batch 100/145, Loss: 0.2438
Epoch 6/10, Batch 110/145, Loss: 0.2644
Epoch 6/10, Batch 120/145, Loss: 0.2161
Epoch 6/10, Batch 130/145, Loss: 0.1893
Epoch 6/10, Batch 140/145, Loss: 0.1172
Epoch 6/10, Train Loss: 0.2244, Valid Loss: 0.2150
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1842
Epoch 7/10, Batch 20/145, Loss: 0.4299
Epoch 7/10, Batch 30/145, Loss: 0.3467
Epoch 7/10, Batch 40/145, Loss: 0.2241
Epoch 7/10, Batch 50/145, Loss: 0.2197
Epoch 7/10, Batch 60/145, Loss: 0.1729
Epoch 7/10, Batch 70/145, Loss: 0.1339
Epoch 7/10, Batch 80/145, Loss: 0.3496
Epoch 7/10, Batch 90/145, Loss: 0.1162
Epoch 7/10, Batch 100/145, Loss: 0.2198
Epoch 7/10, Batch 110/145, Loss: 0.1411
Epoch 7/10, Batch 120/145, Loss: 0.1797
Epoch 7/10, Batch 130/145, Loss: 0.2008
Epoch 7/10, Batch 140/145, Loss: 0.2417
Epoch 7/10, Train Loss: 0.2158, Valid Loss: 0.2127
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1650
Epoch 8/10, Batch 20/145, Loss: 0.1895
Epoch 8/10, Batch 30/145, Loss: 0.3256
Epoch 8/10, Batch 40/145, Loss: 0.1630
Epoch 8/10, Batch 50/145, Loss: 0.1992
Epoch 8/10, Batch 60/145, Loss: 0.2527
Epoch 8/10, Batch 70/145, Loss: 0.2595
Epoch 8/10, Batch 80/145, Loss: 0.2374
Epoch 8/10, Batch 90/145, Loss: 0.3485
Epoch 8/10, Batch 100/145, Loss: 0.1330
Epoch 8/10, Batch 110/145, Loss: 0.1713
Epoch 8/10, Batch 120/145, Loss: 0.1821
Epoch 8/10, Batch 130/145, Loss: 0.3066
Epoch 8/10, Batch 140/145, Loss: 0.1819
Epoch 8/10, Train Loss: 0.2052, Valid Loss: 0.2055
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1748
Epoch 9/10, Batch 20/145, Loss: 0.1227
Epoch 9/10, Batch 30/145, Loss: 0.1929
Epoch 9/10, Batch 40/145, Loss: 0.1634
Epoch 9/10, Batch 50/145, Loss: 0.1204
Epoch 9/10, Batch 60/145, Loss: 0.2540
Epoch 9/10, Batch 70/145, Loss: 0.0932
Epoch 9/10, Batch 80/145, Loss: 0.1321
Epoch 9/10, Batch 90/145, Loss: 0.1464
Epoch 9/10, Batch 100/145, Loss: 0.2671
Epoch 9/10, Batch 110/145, Loss: 0.1196
Epoch 9/10, Batch 120/145, Loss: 0.1487
Epoch 9/10, Batch 130/145, Loss: 0.4396
Epoch 9/10, Batch 140/145, Loss: 0.1723
Epoch 9/10, Train Loss: 0.1996, Valid Loss: 0.2086
Epoch 10/10, Batch 10/145, Loss: 0.0949
Epoch 10/10, Batch 20/145, Loss: 0.2027
Epoch 10/10, Batch 30/145, Loss: 0.2417
Epoch 10/10, Batch 40/145, Loss: 0.1486
Epoch 10/10, Batch 50/145, Loss: 0.2914
Epoch 10/10, Batch 60/145, Loss: 0.0996
Epoch 10/10, Batch 70/145, Loss: 0.3779
Epoch 10/10, Batch 80/145, Loss: 0.2204
Epoch 10/10, Batch 90/145, Loss: 0.1988
Epoch 10/10, Batch 100/145, Loss: 0.1576
Epoch 10/10, Batch 110/145, Loss: 0.1785
Epoch 10/10, Batch 120/145, Loss: 0.3139
Epoch 10/10, Batch 130/145, Loss: 0.0900
Epoch 10/10, Batch 140/145, Loss: 0.2246
Epoch 10/10, Train Loss: 0.1925, Valid Loss: 0.2054
Model saved!
Accuracy: 0.9100
Precision: 0.9070
Recall: 0.9100
F1-score: 0.9077
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3440
Epoch 1/10, Batch 20/145, Loss: 0.8905
Epoch 1/10, Batch 30/145, Loss: 0.9419
Epoch 1/10, Batch 40/145, Loss: 0.8523
Epoch 1/10, Batch 50/145, Loss: 0.7889
Epoch 1/10, Batch 60/145, Loss: 0.6358
Epoch 1/10, Batch 70/145, Loss: 0.3930
Epoch 1/10, Batch 80/145, Loss: 0.5887
Epoch 1/10, Batch 90/145, Loss: 0.5312
Epoch 1/10, Batch 100/145, Loss: 0.4731
Epoch 1/10, Batch 110/145, Loss: 0.5364
Epoch 1/10, Batch 120/145, Loss: 0.5846
Epoch 1/10, Batch 130/145, Loss: 0.5237
Epoch 1/10, Batch 140/145, Loss: 0.3777
Epoch 1/10, Train Loss: 0.6786, Valid Loss: 0.3646
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4692
Epoch 2/10, Batch 20/145, Loss: 0.2666
Epoch 2/10, Batch 30/145, Loss: 0.2620
Epoch 2/10, Batch 40/145, Loss: 0.5105
Epoch 2/10, Batch 50/145, Loss: 0.2897
Epoch 2/10, Batch 60/145, Loss: 0.3181
Epoch 2/10, Batch 70/145, Loss: 0.2958
Epoch 2/10, Batch 80/145, Loss: 0.2471
Epoch 2/10, Batch 90/145, Loss: 0.4442
Epoch 2/10, Batch 100/145, Loss: 0.3514
Epoch 2/10, Batch 110/145, Loss: 0.4300
Epoch 2/10, Batch 120/145, Loss: 0.3413
Epoch 2/10, Batch 130/145, Loss: 0.4280
Epoch 2/10, Batch 140/145, Loss: 0.5111
Epoch 2/10, Train Loss: 0.3510, Valid Loss: 0.2877
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2602
Epoch 3/10, Batch 20/145, Loss: 0.2848
Epoch 3/10, Batch 30/145, Loss: 0.3273
Epoch 3/10, Batch 40/145, Loss: 0.2722
Epoch 3/10, Batch 50/145, Loss: 0.1834
Epoch 3/10, Batch 60/145, Loss: 0.2506
Epoch 3/10, Batch 70/145, Loss: 0.4464
Epoch 3/10, Batch 80/145, Loss: 0.1429
Epoch 3/10, Batch 90/145, Loss: 0.1890
Epoch 3/10, Batch 100/145, Loss: 0.5571
Epoch 3/10, Batch 110/145, Loss: 0.2380
Epoch 3/10, Batch 120/145, Loss: 0.2220
Epoch 3/10, Batch 130/145, Loss: 0.2948
Epoch 3/10, Batch 140/145, Loss: 0.2840
Epoch 3/10, Train Loss: 0.2891, Valid Loss: 0.2528
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1754
Epoch 4/10, Batch 20/145, Loss: 0.2532
Epoch 4/10, Batch 30/145, Loss: 0.3190
Epoch 4/10, Batch 40/145, Loss: 0.2376
Epoch 4/10, Batch 50/145, Loss: 0.2348
Epoch 4/10, Batch 60/145, Loss: 0.1610
Epoch 4/10, Batch 70/145, Loss: 0.2263
Epoch 4/10, Batch 80/145, Loss: 0.1515
Epoch 4/10, Batch 90/145, Loss: 0.2604
Epoch 4/10, Batch 100/145, Loss: 0.3623
Epoch 4/10, Batch 110/145, Loss: 0.2145
Epoch 4/10, Batch 120/145, Loss: 0.2078
Epoch 4/10, Batch 130/145, Loss: 0.2470
Epoch 4/10, Batch 140/145, Loss: 0.2500
Epoch 4/10, Train Loss: 0.2509, Valid Loss: 0.2436
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2091
Epoch 5/10, Batch 20/145, Loss: 0.1140
Epoch 5/10, Batch 30/145, Loss: 0.3306
Epoch 5/10, Batch 40/145, Loss: 0.1147
Epoch 5/10, Batch 50/145, Loss: 0.2434
Epoch 5/10, Batch 60/145, Loss: 0.1591
Epoch 5/10, Batch 70/145, Loss: 0.2104
Epoch 5/10, Batch 80/145, Loss: 0.1605
Epoch 5/10, Batch 90/145, Loss: 0.3300
Epoch 5/10, Batch 100/145, Loss: 0.2638
Epoch 5/10, Batch 110/145, Loss: 0.1909
Epoch 5/10, Batch 120/145, Loss: 0.2790
Epoch 5/10, Batch 130/145, Loss: 0.3245
Epoch 5/10, Batch 140/145, Loss: 0.2342
Epoch 5/10, Train Loss: 0.2406, Valid Loss: 0.2401
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2382
Epoch 6/10, Batch 20/145, Loss: 0.3811
Epoch 6/10, Batch 30/145, Loss: 0.1982
Epoch 6/10, Batch 40/145, Loss: 0.1553
Epoch 6/10, Batch 50/145, Loss: 0.1656
Epoch 6/10, Batch 60/145, Loss: 0.2138
Epoch 6/10, Batch 70/145, Loss: 0.2655
Epoch 6/10, Batch 80/145, Loss: 0.1615
Epoch 6/10, Batch 90/145, Loss: 0.2834
Epoch 6/10, Batch 100/145, Loss: 0.2065
Epoch 6/10, Batch 110/145, Loss: 0.2442
Epoch 6/10, Batch 120/145, Loss: 0.2148
Epoch 6/10, Batch 130/145, Loss: 0.3195
Epoch 6/10, Batch 140/145, Loss: 0.2198
Epoch 6/10, Train Loss: 0.2244, Valid Loss: 0.2173
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2227
Epoch 7/10, Batch 20/145, Loss: 0.3292
Epoch 7/10, Batch 30/145, Loss: 0.3480
Epoch 7/10, Batch 40/145, Loss: 0.3157
Epoch 7/10, Batch 50/145, Loss: 0.3091
Epoch 7/10, Batch 60/145, Loss: 0.1780
Epoch 7/10, Batch 70/145, Loss: 0.1370
Epoch 7/10, Batch 80/145, Loss: 0.3854
Epoch 7/10, Batch 90/145, Loss: 0.2668
Epoch 7/10, Batch 100/145, Loss: 0.2488
Epoch 7/10, Batch 110/145, Loss: 0.1055
Epoch 7/10, Batch 120/145, Loss: 0.2499
Epoch 7/10, Batch 130/145, Loss: 0.0613
Epoch 7/10, Batch 140/145, Loss: 0.3175
Epoch 7/10, Train Loss: 0.2090, Valid Loss: 0.2168
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1182
Epoch 8/10, Batch 20/145, Loss: 0.2579
Epoch 8/10, Batch 30/145, Loss: 0.2237
Epoch 8/10, Batch 40/145, Loss: 0.1494
Epoch 8/10, Batch 50/145, Loss: 0.3550
Epoch 8/10, Batch 60/145, Loss: 0.1552
Epoch 8/10, Batch 70/145, Loss: 0.2011
Epoch 8/10, Batch 80/145, Loss: 0.2908
Epoch 8/10, Batch 90/145, Loss: 0.3270
Epoch 8/10, Batch 100/145, Loss: 0.1807
Epoch 8/10, Batch 110/145, Loss: 0.1807
Epoch 8/10, Batch 120/145, Loss: 0.2113
Epoch 8/10, Batch 130/145, Loss: 0.1640
Epoch 8/10, Batch 140/145, Loss: 0.5184
Epoch 8/10, Train Loss: 0.2025, Valid Loss: 0.2127
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1537
Epoch 9/10, Batch 20/145, Loss: 0.1569
Epoch 9/10, Batch 30/145, Loss: 0.0989
Epoch 9/10, Batch 40/145, Loss: 0.3285
Epoch 9/10, Batch 50/145, Loss: 0.0620
Epoch 9/10, Batch 60/145, Loss: 0.1177
Epoch 9/10, Batch 70/145, Loss: 0.2400
Epoch 9/10, Batch 80/145, Loss: 0.1437
Epoch 9/10, Batch 90/145, Loss: 0.2771
Epoch 9/10, Batch 100/145, Loss: 0.1818
Epoch 9/10, Batch 110/145, Loss: 0.2434
Epoch 9/10, Batch 120/145, Loss: 0.1019
Epoch 9/10, Batch 130/145, Loss: 0.1779
Epoch 9/10, Batch 140/145, Loss: 0.3932
Epoch 9/10, Train Loss: 0.2051, Valid Loss: 0.2095
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0872
Epoch 10/10, Batch 20/145, Loss: 0.0894
Epoch 10/10, Batch 30/145, Loss: 0.1393
Epoch 10/10, Batch 40/145, Loss: 0.1170
Epoch 10/10, Batch 50/145, Loss: 0.3039
Epoch 10/10, Batch 60/145, Loss: 0.0717
Epoch 10/10, Batch 70/145, Loss: 0.2587
Epoch 10/10, Batch 80/145, Loss: 0.1322
Epoch 10/10, Batch 90/145, Loss: 0.0572
Epoch 10/10, Batch 100/145, Loss: 0.1038
Epoch 10/10, Batch 110/145, Loss: 0.2874
Epoch 10/10, Batch 120/145, Loss: 0.2114
Epoch 10/10, Batch 130/145, Loss: 0.1762
Epoch 10/10, Batch 140/145, Loss: 0.2308
Epoch 10/10, Train Loss: 0.1880, Valid Loss: 0.2049
Model saved!
Accuracy: 0.9264
Precision: 0.9245
Recall: 0.9264
F1-score: 0.9252
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3985
Epoch 1/10, Batch 20/145, Loss: 0.9312
Epoch 1/10, Batch 30/145, Loss: 0.8739
Epoch 1/10, Batch 40/145, Loss: 0.7187
Epoch 1/10, Batch 50/145, Loss: 0.6866
Epoch 1/10, Batch 60/145, Loss: 0.6202
Epoch 1/10, Batch 70/145, Loss: 0.4368
Epoch 1/10, Batch 80/145, Loss: 0.4951
Epoch 1/10, Batch 90/145, Loss: 0.4441
Epoch 1/10, Batch 100/145, Loss: 0.4631
Epoch 1/10, Batch 110/145, Loss: 0.3148
Epoch 1/10, Batch 120/145, Loss: 0.5804
Epoch 1/10, Batch 130/145, Loss: 0.4476
Epoch 1/10, Batch 140/145, Loss: 0.3582
Epoch 1/10, Train Loss: 0.6783, Valid Loss: 0.3867
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4711
Epoch 2/10, Batch 20/145, Loss: 0.3625
Epoch 2/10, Batch 30/145, Loss: 0.2304
Epoch 2/10, Batch 40/145, Loss: 0.4546
Epoch 2/10, Batch 50/145, Loss: 0.4433
Epoch 2/10, Batch 60/145, Loss: 0.3435
Epoch 2/10, Batch 70/145, Loss: 0.3249
Epoch 2/10, Batch 80/145, Loss: 0.3216
Epoch 2/10, Batch 90/145, Loss: 0.4055
Epoch 2/10, Batch 100/145, Loss: 0.2661
Epoch 2/10, Batch 110/145, Loss: 0.2734
Epoch 2/10, Batch 120/145, Loss: 0.3714
Epoch 2/10, Batch 130/145, Loss: 0.2343
Epoch 2/10, Batch 140/145, Loss: 0.2026
Epoch 2/10, Train Loss: 0.3537, Valid Loss: 0.3043
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2147
Epoch 3/10, Batch 20/145, Loss: 0.3431
Epoch 3/10, Batch 30/145, Loss: 0.2434
Epoch 3/10, Batch 40/145, Loss: 0.1778
Epoch 3/10, Batch 50/145, Loss: 0.2056
Epoch 3/10, Batch 60/145, Loss: 0.2627
Epoch 3/10, Batch 70/145, Loss: 0.3839
Epoch 3/10, Batch 80/145, Loss: 0.4808
Epoch 3/10, Batch 90/145, Loss: 0.1630
Epoch 3/10, Batch 100/145, Loss: 0.2924
Epoch 3/10, Batch 110/145, Loss: 0.2053
Epoch 3/10, Batch 120/145, Loss: 0.4234
Epoch 3/10, Batch 130/145, Loss: 0.4069
Epoch 3/10, Batch 140/145, Loss: 0.2540
Epoch 3/10, Train Loss: 0.3009, Valid Loss: 0.2722
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3473
Epoch 4/10, Batch 20/145, Loss: 0.2345
Epoch 4/10, Batch 30/145, Loss: 0.3165
Epoch 4/10, Batch 40/145, Loss: 0.2841
Epoch 4/10, Batch 50/145, Loss: 0.2514
Epoch 4/10, Batch 60/145, Loss: 0.3420
Epoch 4/10, Batch 70/145, Loss: 0.2214
Epoch 4/10, Batch 80/145, Loss: 0.1936
Epoch 4/10, Batch 90/145, Loss: 0.2289
Epoch 4/10, Batch 100/145, Loss: 0.3225
Epoch 4/10, Batch 110/145, Loss: 0.2443
Epoch 4/10, Batch 120/145, Loss: 0.2032
Epoch 4/10, Batch 130/145, Loss: 0.1178
Epoch 4/10, Batch 140/145, Loss: 0.0920
Epoch 4/10, Train Loss: 0.2575, Valid Loss: 0.2584
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1440
Epoch 5/10, Batch 20/145, Loss: 0.1512
Epoch 5/10, Batch 30/145, Loss: 0.2427
Epoch 5/10, Batch 40/145, Loss: 0.2444
Epoch 5/10, Batch 50/145, Loss: 0.1695
Epoch 5/10, Batch 60/145, Loss: 0.2258
Epoch 5/10, Batch 70/145, Loss: 0.2000
Epoch 5/10, Batch 80/145, Loss: 0.2006
Epoch 5/10, Batch 90/145, Loss: 0.3066
Epoch 5/10, Batch 100/145, Loss: 0.1544
Epoch 5/10, Batch 110/145, Loss: 0.1847
Epoch 5/10, Batch 120/145, Loss: 0.2200
Epoch 5/10, Batch 130/145, Loss: 0.1785
Epoch 5/10, Batch 140/145, Loss: 0.2053
Epoch 5/10, Train Loss: 0.2425, Valid Loss: 0.2534
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1479
Epoch 6/10, Batch 20/145, Loss: 0.3364
Epoch 6/10, Batch 30/145, Loss: 0.2789
Epoch 6/10, Batch 40/145, Loss: 0.1886
Epoch 6/10, Batch 50/145, Loss: 0.3953
Epoch 6/10, Batch 60/145, Loss: 0.2748
Epoch 6/10, Batch 70/145, Loss: 0.1086
Epoch 6/10, Batch 80/145, Loss: 0.2257
Epoch 6/10, Batch 90/145, Loss: 0.2909
Epoch 6/10, Batch 100/145, Loss: 0.2566
Epoch 6/10, Batch 110/145, Loss: 0.2244
Epoch 6/10, Batch 120/145, Loss: 0.2127
Epoch 6/10, Batch 130/145, Loss: 0.1821
Epoch 6/10, Batch 140/145, Loss: 0.1250
Epoch 6/10, Train Loss: 0.2270, Valid Loss: 0.2385
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2595
Epoch 7/10, Batch 20/145, Loss: 0.2652
Epoch 7/10, Batch 30/145, Loss: 0.2524
Epoch 7/10, Batch 40/145, Loss: 0.2386
Epoch 7/10, Batch 50/145, Loss: 0.2274
Epoch 7/10, Batch 60/145, Loss: 0.1832
Epoch 7/10, Batch 70/145, Loss: 0.1741
Epoch 7/10, Batch 80/145, Loss: 0.3390
Epoch 7/10, Batch 90/145, Loss: 0.1960
Epoch 7/10, Batch 100/145, Loss: 0.1053
Epoch 7/10, Batch 110/145, Loss: 0.2713
Epoch 7/10, Batch 120/145, Loss: 0.1958
Epoch 7/10, Batch 130/145, Loss: 0.1293
Epoch 7/10, Batch 140/145, Loss: 0.2840
Epoch 7/10, Train Loss: 0.2131, Valid Loss: 0.2314
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1669
Epoch 8/10, Batch 20/145, Loss: 0.1993
Epoch 8/10, Batch 30/145, Loss: 0.2606
Epoch 8/10, Batch 40/145, Loss: 0.2927
Epoch 8/10, Batch 50/145, Loss: 0.1492
Epoch 8/10, Batch 60/145, Loss: 0.1616
Epoch 8/10, Batch 70/145, Loss: 0.3441
Epoch 8/10, Batch 80/145, Loss: 0.1937
Epoch 8/10, Batch 90/145, Loss: 0.3565
Epoch 8/10, Batch 100/145, Loss: 0.1233
Epoch 8/10, Batch 110/145, Loss: 0.2649
Epoch 8/10, Batch 120/145, Loss: 0.3471
Epoch 8/10, Batch 130/145, Loss: 0.1850
Epoch 8/10, Batch 140/145, Loss: 0.1951
Epoch 8/10, Train Loss: 0.2049, Valid Loss: 0.2264
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1058
Epoch 9/10, Batch 20/145, Loss: 0.1155
Epoch 9/10, Batch 30/145, Loss: 0.1585
Epoch 9/10, Batch 40/145, Loss: 0.1390
Epoch 9/10, Batch 50/145, Loss: 0.1121
Epoch 9/10, Batch 60/145, Loss: 0.2200
Epoch 9/10, Batch 70/145, Loss: 0.2051
Epoch 9/10, Batch 80/145, Loss: 0.1147
Epoch 9/10, Batch 90/145, Loss: 0.1064
Epoch 9/10, Batch 100/145, Loss: 0.1633
Epoch 9/10, Batch 110/145, Loss: 0.4112
Epoch 9/10, Batch 120/145, Loss: 0.1564
Epoch 9/10, Batch 130/145, Loss: 0.1580
Epoch 9/10, Batch 140/145, Loss: 0.0801
Epoch 9/10, Train Loss: 0.2021, Valid Loss: 0.2270
Epoch 10/10, Batch 10/145, Loss: 0.1754
Epoch 10/10, Batch 20/145, Loss: 0.2289
Epoch 10/10, Batch 30/145, Loss: 0.2791
Epoch 10/10, Batch 40/145, Loss: 0.1136
Epoch 10/10, Batch 50/145, Loss: 0.1383
Epoch 10/10, Batch 60/145, Loss: 0.1730
Epoch 10/10, Batch 70/145, Loss: 0.2465
Epoch 10/10, Batch 80/145, Loss: 0.1403
Epoch 10/10, Batch 90/145, Loss: 0.1646
Epoch 10/10, Batch 100/145, Loss: 0.1337
Epoch 10/10, Batch 110/145, Loss: 0.1441
Epoch 10/10, Batch 120/145, Loss: 0.2571
Epoch 10/10, Batch 130/145, Loss: 0.1745
Epoch 10/10, Batch 140/145, Loss: 0.1977
Epoch 10/10, Train Loss: 0.1931, Valid Loss: 0.2210
Model saved!
Accuracy: 0.9229
Precision: 0.9204
Recall: 0.9229
F1-score: 0.9212
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4612
Epoch 1/10, Batch 20/145, Loss: 1.0442
Epoch 1/10, Batch 30/145, Loss: 1.0168
Epoch 1/10, Batch 40/145, Loss: 0.8143
Epoch 1/10, Batch 50/145, Loss: 0.6629
Epoch 1/10, Batch 60/145, Loss: 0.5509
Epoch 1/10, Batch 70/145, Loss: 0.4091
Epoch 1/10, Batch 80/145, Loss: 0.5449
Epoch 1/10, Batch 90/145, Loss: 0.4378
Epoch 1/10, Batch 100/145, Loss: 0.3754
Epoch 1/10, Batch 110/145, Loss: 0.4288
Epoch 1/10, Batch 120/145, Loss: 0.5308
Epoch 1/10, Batch 130/145, Loss: 0.6579
Epoch 1/10, Batch 140/145, Loss: 0.3499
Epoch 1/10, Train Loss: 0.6753, Valid Loss: 0.3915
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3566
Epoch 2/10, Batch 20/145, Loss: 0.2832
Epoch 2/10, Batch 30/145, Loss: 0.2843
Epoch 2/10, Batch 40/145, Loss: 0.4876
Epoch 2/10, Batch 50/145, Loss: 0.2925
Epoch 2/10, Batch 60/145, Loss: 0.3843
Epoch 2/10, Batch 70/145, Loss: 0.2839
Epoch 2/10, Batch 80/145, Loss: 0.3210
Epoch 2/10, Batch 90/145, Loss: 0.3246
Epoch 2/10, Batch 100/145, Loss: 0.2703
Epoch 2/10, Batch 110/145, Loss: 0.2742
Epoch 2/10, Batch 120/145, Loss: 0.4300
Epoch 2/10, Batch 130/145, Loss: 0.3360
Epoch 2/10, Batch 140/145, Loss: 0.2188
Epoch 2/10, Train Loss: 0.3501, Valid Loss: 0.3107
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2013
Epoch 3/10, Batch 20/145, Loss: 0.2581
Epoch 3/10, Batch 30/145, Loss: 0.3950
Epoch 3/10, Batch 40/145, Loss: 0.2329
Epoch 3/10, Batch 50/145, Loss: 0.2532
Epoch 3/10, Batch 60/145, Loss: 0.4309
Epoch 3/10, Batch 70/145, Loss: 0.1856
Epoch 3/10, Batch 80/145, Loss: 0.1575
Epoch 3/10, Batch 90/145, Loss: 0.3021
Epoch 3/10, Batch 100/145, Loss: 0.2781
Epoch 3/10, Batch 110/145, Loss: 0.2038
Epoch 3/10, Batch 120/145, Loss: 0.1424
Epoch 3/10, Batch 130/145, Loss: 0.3008
Epoch 3/10, Batch 140/145, Loss: 0.2151
Epoch 3/10, Train Loss: 0.2897, Valid Loss: 0.2820
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3622
Epoch 4/10, Batch 20/145, Loss: 0.3444
Epoch 4/10, Batch 30/145, Loss: 0.2840
Epoch 4/10, Batch 40/145, Loss: 0.1506
Epoch 4/10, Batch 50/145, Loss: 0.1826
Epoch 4/10, Batch 60/145, Loss: 0.1671
Epoch 4/10, Batch 70/145, Loss: 0.1444
Epoch 4/10, Batch 80/145, Loss: 0.1325
Epoch 4/10, Batch 90/145, Loss: 0.1891
Epoch 4/10, Batch 100/145, Loss: 0.4219
Epoch 4/10, Batch 110/145, Loss: 0.1775
Epoch 4/10, Batch 120/145, Loss: 0.3495
Epoch 4/10, Batch 130/145, Loss: 0.2330
Epoch 4/10, Batch 140/145, Loss: 0.0934
Epoch 4/10, Train Loss: 0.2540, Valid Loss: 0.2675
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1639
Epoch 5/10, Batch 20/145, Loss: 0.1555
Epoch 5/10, Batch 30/145, Loss: 0.1748
Epoch 5/10, Batch 40/145, Loss: 0.1728
Epoch 5/10, Batch 50/145, Loss: 0.1879
Epoch 5/10, Batch 60/145, Loss: 0.1956
Epoch 5/10, Batch 70/145, Loss: 0.2086
Epoch 5/10, Batch 80/145, Loss: 0.1863
Epoch 5/10, Batch 90/145, Loss: 0.3512
Epoch 5/10, Batch 100/145, Loss: 0.2954
Epoch 5/10, Batch 110/145, Loss: 0.2387
Epoch 5/10, Batch 120/145, Loss: 0.3118
Epoch 5/10, Batch 130/145, Loss: 0.1096
Epoch 5/10, Batch 140/145, Loss: 0.2273
Epoch 5/10, Train Loss: 0.2455, Valid Loss: 0.2559
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1070
Epoch 6/10, Batch 20/145, Loss: 0.2313
Epoch 6/10, Batch 30/145, Loss: 0.1723
Epoch 6/10, Batch 40/145, Loss: 0.1468
Epoch 6/10, Batch 50/145, Loss: 0.3858
Epoch 6/10, Batch 60/145, Loss: 0.1777
Epoch 6/10, Batch 70/145, Loss: 0.1710
Epoch 6/10, Batch 80/145, Loss: 0.1588
Epoch 6/10, Batch 90/145, Loss: 0.2435
Epoch 6/10, Batch 100/145, Loss: 0.2871
Epoch 6/10, Batch 110/145, Loss: 0.2094
Epoch 6/10, Batch 120/145, Loss: 0.2750
Epoch 6/10, Batch 130/145, Loss: 0.1238
Epoch 6/10, Batch 140/145, Loss: 0.2305
Epoch 6/10, Train Loss: 0.2280, Valid Loss: 0.2411
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2754
Epoch 7/10, Batch 20/145, Loss: 0.1621
Epoch 7/10, Batch 30/145, Loss: 0.1828
Epoch 7/10, Batch 40/145, Loss: 0.2438
Epoch 7/10, Batch 50/145, Loss: 0.4010
Epoch 7/10, Batch 60/145, Loss: 0.1884
Epoch 7/10, Batch 70/145, Loss: 0.1077
Epoch 7/10, Batch 80/145, Loss: 0.5162
Epoch 7/10, Batch 90/145, Loss: 0.1582
Epoch 7/10, Batch 100/145, Loss: 0.1663
Epoch 7/10, Batch 110/145, Loss: 0.3062
Epoch 7/10, Batch 120/145, Loss: 0.2819
Epoch 7/10, Batch 130/145, Loss: 0.0700
Epoch 7/10, Batch 140/145, Loss: 0.3053
Epoch 7/10, Train Loss: 0.2165, Valid Loss: 0.2389
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2395
Epoch 8/10, Batch 20/145, Loss: 0.3538
Epoch 8/10, Batch 30/145, Loss: 0.2923
Epoch 8/10, Batch 40/145, Loss: 0.1042
Epoch 8/10, Batch 50/145, Loss: 0.1926
Epoch 8/10, Batch 60/145, Loss: 0.2701
Epoch 8/10, Batch 70/145, Loss: 0.1999
Epoch 8/10, Batch 80/145, Loss: 0.2376
Epoch 8/10, Batch 90/145, Loss: 0.5250
Epoch 8/10, Batch 100/145, Loss: 0.1862
Epoch 8/10, Batch 110/145, Loss: 0.1388
Epoch 8/10, Batch 120/145, Loss: 0.2252
Epoch 8/10, Batch 130/145, Loss: 0.1451
Epoch 8/10, Batch 140/145, Loss: 0.1918
Epoch 8/10, Train Loss: 0.2015, Valid Loss: 0.2389
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2436
Epoch 9/10, Batch 20/145, Loss: 0.1342
Epoch 9/10, Batch 30/145, Loss: 0.2501
Epoch 9/10, Batch 40/145, Loss: 0.2129
Epoch 9/10, Batch 50/145, Loss: 0.0785
Epoch 9/10, Batch 60/145, Loss: 0.1790
Epoch 9/10, Batch 70/145, Loss: 0.2201
Epoch 9/10, Batch 80/145, Loss: 0.1417
Epoch 9/10, Batch 90/145, Loss: 0.1734
Epoch 9/10, Batch 100/145, Loss: 0.1371
Epoch 9/10, Batch 110/145, Loss: 0.3788
Epoch 9/10, Batch 120/145, Loss: 0.1780
Epoch 9/10, Batch 130/145, Loss: 0.2839
Epoch 9/10, Batch 140/145, Loss: 0.1925
Epoch 9/10, Train Loss: 0.1974, Valid Loss: 0.2317
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1190
Epoch 10/10, Batch 20/145, Loss: 0.1319
Epoch 10/10, Batch 30/145, Loss: 0.1392
Epoch 10/10, Batch 40/145, Loss: 0.1752
Epoch 10/10, Batch 50/145, Loss: 0.1246
Epoch 10/10, Batch 60/145, Loss: 0.2017
Epoch 10/10, Batch 70/145, Loss: 0.1950
Epoch 10/10, Batch 80/145, Loss: 0.1090
Epoch 10/10, Batch 90/145, Loss: 0.1122
Epoch 10/10, Batch 100/145, Loss: 0.1115
Epoch 10/10, Batch 110/145, Loss: 0.1395
Epoch 10/10, Batch 120/145, Loss: 0.1867
Epoch 10/10, Batch 130/145, Loss: 0.1083
Epoch 10/10, Batch 140/145, Loss: 0.2641
Epoch 10/10, Train Loss: 0.1870, Valid Loss: 0.2313
Model saved!
Accuracy: 0.9171
Precision: 0.9140
Recall: 0.9171
F1-score: 0.9142
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4406
Epoch 1/10, Batch 20/145, Loss: 0.9881
Epoch 1/10, Batch 30/145, Loss: 0.9517
Epoch 1/10, Batch 40/145, Loss: 0.8402
Epoch 1/10, Batch 50/145, Loss: 0.7091
Epoch 1/10, Batch 60/145, Loss: 0.6551
Epoch 1/10, Batch 70/145, Loss: 0.5561
Epoch 1/10, Batch 80/145, Loss: 0.4705
Epoch 1/10, Batch 90/145, Loss: 0.3451
Epoch 1/10, Batch 100/145, Loss: 0.4226
Epoch 1/10, Batch 110/145, Loss: 0.5030
Epoch 1/10, Batch 120/145, Loss: 0.5057
Epoch 1/10, Batch 130/145, Loss: 0.4387
Epoch 1/10, Batch 140/145, Loss: 0.3155
Epoch 1/10, Train Loss: 0.6808, Valid Loss: 0.3994
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2826
Epoch 2/10, Batch 20/145, Loss: 0.2557
Epoch 2/10, Batch 30/145, Loss: 0.5027
Epoch 2/10, Batch 40/145, Loss: 0.5177
Epoch 2/10, Batch 50/145, Loss: 0.3953
Epoch 2/10, Batch 60/145, Loss: 0.3212
Epoch 2/10, Batch 70/145, Loss: 0.3545
Epoch 2/10, Batch 80/145, Loss: 0.2741
Epoch 2/10, Batch 90/145, Loss: 0.3161
Epoch 2/10, Batch 100/145, Loss: 0.5337
Epoch 2/10, Batch 110/145, Loss: 0.3022
Epoch 2/10, Batch 120/145, Loss: 0.2842
Epoch 2/10, Batch 130/145, Loss: 0.3222
Epoch 2/10, Batch 140/145, Loss: 0.3141
Epoch 2/10, Train Loss: 0.3522, Valid Loss: 0.3279
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1771
Epoch 3/10, Batch 20/145, Loss: 0.4282
Epoch 3/10, Batch 30/145, Loss: 0.2693
Epoch 3/10, Batch 40/145, Loss: 0.2139
Epoch 3/10, Batch 50/145, Loss: 0.2443
Epoch 3/10, Batch 60/145, Loss: 0.5082
Epoch 3/10, Batch 70/145, Loss: 0.3656
Epoch 3/10, Batch 80/145, Loss: 0.1451
Epoch 3/10, Batch 90/145, Loss: 0.3375
Epoch 3/10, Batch 100/145, Loss: 0.1769
Epoch 3/10, Batch 110/145, Loss: 0.2139
Epoch 3/10, Batch 120/145, Loss: 0.1722
Epoch 3/10, Batch 130/145, Loss: 0.3372
Epoch 3/10, Batch 140/145, Loss: 0.2289
Epoch 3/10, Train Loss: 0.2964, Valid Loss: 0.3004
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3038
Epoch 4/10, Batch 20/145, Loss: 0.3305
Epoch 4/10, Batch 30/145, Loss: 0.3415
Epoch 4/10, Batch 40/145, Loss: 0.1597
Epoch 4/10, Batch 50/145, Loss: 0.1796
Epoch 4/10, Batch 60/145, Loss: 0.1772
Epoch 4/10, Batch 70/145, Loss: 0.1501
Epoch 4/10, Batch 80/145, Loss: 0.1358
Epoch 4/10, Batch 90/145, Loss: 0.2513
Epoch 4/10, Batch 100/145, Loss: 0.2368
Epoch 4/10, Batch 110/145, Loss: 0.1084
Epoch 4/10, Batch 120/145, Loss: 0.1884
Epoch 4/10, Batch 130/145, Loss: 0.1046
Epoch 4/10, Batch 140/145, Loss: 0.3033
Epoch 4/10, Train Loss: 0.2597, Valid Loss: 0.2911
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2497
Epoch 5/10, Batch 20/145, Loss: 0.1016
Epoch 5/10, Batch 30/145, Loss: 0.2060
Epoch 5/10, Batch 40/145, Loss: 0.1713
Epoch 5/10, Batch 50/145, Loss: 0.2823
Epoch 5/10, Batch 60/145, Loss: 0.3520
Epoch 5/10, Batch 70/145, Loss: 0.2395
Epoch 5/10, Batch 80/145, Loss: 0.1751
Epoch 5/10, Batch 90/145, Loss: 0.5013
Epoch 5/10, Batch 100/145, Loss: 0.1338
Epoch 5/10, Batch 110/145, Loss: 0.1876
Epoch 5/10, Batch 120/145, Loss: 0.3547
Epoch 5/10, Batch 130/145, Loss: 0.2113
Epoch 5/10, Batch 140/145, Loss: 0.1982
Epoch 5/10, Train Loss: 0.2386, Valid Loss: 0.2888
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2467
Epoch 6/10, Batch 20/145, Loss: 0.3734
Epoch 6/10, Batch 30/145, Loss: 0.2920
Epoch 6/10, Batch 40/145, Loss: 0.1090
Epoch 6/10, Batch 50/145, Loss: 0.2084
Epoch 6/10, Batch 60/145, Loss: 0.1390
Epoch 6/10, Batch 70/145, Loss: 0.0651
Epoch 6/10, Batch 80/145, Loss: 0.2509
Epoch 6/10, Batch 90/145, Loss: 0.2571
Epoch 6/10, Batch 100/145, Loss: 0.1460
Epoch 6/10, Batch 110/145, Loss: 0.1869
Epoch 6/10, Batch 120/145, Loss: 0.4128
Epoch 6/10, Batch 130/145, Loss: 0.1005
Epoch 6/10, Batch 140/145, Loss: 0.1479
Epoch 6/10, Train Loss: 0.2237, Valid Loss: 0.2720
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2050
Epoch 7/10, Batch 20/145, Loss: 0.2924
Epoch 7/10, Batch 30/145, Loss: 0.2402
Epoch 7/10, Batch 40/145, Loss: 0.1870
Epoch 7/10, Batch 50/145, Loss: 0.3262
Epoch 7/10, Batch 60/145, Loss: 0.1760
Epoch 7/10, Batch 70/145, Loss: 0.1751
Epoch 7/10, Batch 80/145, Loss: 0.2497
Epoch 7/10, Batch 90/145, Loss: 0.2319
Epoch 7/10, Batch 100/145, Loss: 0.1862
Epoch 7/10, Batch 110/145, Loss: 0.1284
Epoch 7/10, Batch 120/145, Loss: 0.2621
Epoch 7/10, Batch 130/145, Loss: 0.1641
Epoch 7/10, Batch 140/145, Loss: 0.2234
Epoch 7/10, Train Loss: 0.2133, Valid Loss: 0.2678
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2222
Epoch 8/10, Batch 20/145, Loss: 0.2957
Epoch 8/10, Batch 30/145, Loss: 0.3142
Epoch 8/10, Batch 40/145, Loss: 0.2965
Epoch 8/10, Batch 50/145, Loss: 0.2148
Epoch 8/10, Batch 60/145, Loss: 0.1199
Epoch 8/10, Batch 70/145, Loss: 0.2968
Epoch 8/10, Batch 80/145, Loss: 0.1954
Epoch 8/10, Batch 90/145, Loss: 0.1730
Epoch 8/10, Batch 100/145, Loss: 0.1739
Epoch 8/10, Batch 110/145, Loss: 0.1436
Epoch 8/10, Batch 120/145, Loss: 0.2506
Epoch 8/10, Batch 130/145, Loss: 0.2124
Epoch 8/10, Batch 140/145, Loss: 0.3659
Epoch 8/10, Train Loss: 0.2057, Valid Loss: 0.2664
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2922
Epoch 9/10, Batch 20/145, Loss: 0.1386
Epoch 9/10, Batch 30/145, Loss: 0.0975
Epoch 9/10, Batch 40/145, Loss: 0.1601
Epoch 9/10, Batch 50/145, Loss: 0.2347
Epoch 9/10, Batch 60/145, Loss: 0.1983
Epoch 9/10, Batch 70/145, Loss: 0.1723
Epoch 9/10, Batch 80/145, Loss: 0.0858
Epoch 9/10, Batch 90/145, Loss: 0.2617
Epoch 9/10, Batch 100/145, Loss: 0.1752
Epoch 9/10, Batch 110/145, Loss: 0.2097
Epoch 9/10, Batch 120/145, Loss: 0.0800
Epoch 9/10, Batch 130/145, Loss: 0.3434
Epoch 9/10, Batch 140/145, Loss: 0.3388
Epoch 9/10, Train Loss: 0.1961, Valid Loss: 0.2594
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1794
Epoch 10/10, Batch 20/145, Loss: 0.1610
Epoch 10/10, Batch 30/145, Loss: 0.1539
Epoch 10/10, Batch 40/145, Loss: 0.0981
Epoch 10/10, Batch 50/145, Loss: 0.2733
Epoch 10/10, Batch 60/145, Loss: 0.1443
Epoch 10/10, Batch 70/145, Loss: 0.3020
Epoch 10/10, Batch 80/145, Loss: 0.1418
Epoch 10/10, Batch 90/145, Loss: 0.1608
Epoch 10/10, Batch 100/145, Loss: 0.1620
Epoch 10/10, Batch 110/145, Loss: 0.1100
Epoch 10/10, Batch 120/145, Loss: 0.2075
Epoch 10/10, Batch 130/145, Loss: 0.2685
Epoch 10/10, Batch 140/145, Loss: 0.1901
Epoch 10/10, Train Loss: 0.1833, Valid Loss: 0.2621
Accuracy: 0.9229
Precision: 0.9210
Recall: 0.9229
F1-score: 0.9217
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3748
Epoch 1/10, Batch 20/145, Loss: 1.0304
Epoch 1/10, Batch 30/145, Loss: 0.8634
Epoch 1/10, Batch 40/145, Loss: 0.7955
Epoch 1/10, Batch 50/145, Loss: 0.6960
Epoch 1/10, Batch 60/145, Loss: 0.6897
Epoch 1/10, Batch 70/145, Loss: 0.4364
Epoch 1/10, Batch 80/145, Loss: 0.6031
Epoch 1/10, Batch 90/145, Loss: 0.3717
Epoch 1/10, Batch 100/145, Loss: 0.6067
Epoch 1/10, Batch 110/145, Loss: 0.3969
Epoch 1/10, Batch 120/145, Loss: 0.5922
Epoch 1/10, Batch 130/145, Loss: 0.3757
Epoch 1/10, Batch 140/145, Loss: 0.2487
Epoch 1/10, Train Loss: 0.6773, Valid Loss: 0.4035
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3163
Epoch 2/10, Batch 20/145, Loss: 0.2676
Epoch 2/10, Batch 30/145, Loss: 0.3524
Epoch 2/10, Batch 40/145, Loss: 0.3909
Epoch 2/10, Batch 50/145, Loss: 0.2414
Epoch 2/10, Batch 60/145, Loss: 0.6331
Epoch 2/10, Batch 70/145, Loss: 0.4159
Epoch 2/10, Batch 80/145, Loss: 0.3668
Epoch 2/10, Batch 90/145, Loss: 0.2807
Epoch 2/10, Batch 100/145, Loss: 0.1864
Epoch 2/10, Batch 110/145, Loss: 0.2387
Epoch 2/10, Batch 120/145, Loss: 0.4301
Epoch 2/10, Batch 130/145, Loss: 0.2650
Epoch 2/10, Batch 140/145, Loss: 0.3780
Epoch 2/10, Train Loss: 0.3495, Valid Loss: 0.3150
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1186
Epoch 3/10, Batch 20/145, Loss: 0.3032
Epoch 3/10, Batch 30/145, Loss: 0.4968
Epoch 3/10, Batch 40/145, Loss: 0.1889
Epoch 3/10, Batch 50/145, Loss: 0.2394
Epoch 3/10, Batch 60/145, Loss: 0.2886
Epoch 3/10, Batch 70/145, Loss: 0.3010
Epoch 3/10, Batch 80/145, Loss: 0.2713
Epoch 3/10, Batch 90/145, Loss: 0.2980
Epoch 3/10, Batch 100/145, Loss: 0.1971
Epoch 3/10, Batch 110/145, Loss: 0.2489
Epoch 3/10, Batch 120/145, Loss: 0.2396
Epoch 3/10, Batch 130/145, Loss: 0.2843
Epoch 3/10, Batch 140/145, Loss: 0.2761
Epoch 3/10, Train Loss: 0.2914, Valid Loss: 0.2796
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4248
Epoch 4/10, Batch 20/145, Loss: 0.2336
Epoch 4/10, Batch 30/145, Loss: 0.2225
Epoch 4/10, Batch 40/145, Loss: 0.1659
Epoch 4/10, Batch 50/145, Loss: 0.2346
Epoch 4/10, Batch 60/145, Loss: 0.1536
Epoch 4/10, Batch 70/145, Loss: 0.2071
Epoch 4/10, Batch 80/145, Loss: 0.1567
Epoch 4/10, Batch 90/145, Loss: 0.1987
Epoch 4/10, Batch 100/145, Loss: 0.2750
Epoch 4/10, Batch 110/145, Loss: 0.0757
Epoch 4/10, Batch 120/145, Loss: 0.3480
Epoch 4/10, Batch 130/145, Loss: 0.2281
Epoch 4/10, Batch 140/145, Loss: 0.1401
Epoch 4/10, Train Loss: 0.2551, Valid Loss: 0.2666
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2449
Epoch 5/10, Batch 20/145, Loss: 0.1162
Epoch 5/10, Batch 30/145, Loss: 0.1391
Epoch 5/10, Batch 40/145, Loss: 0.1753
Epoch 5/10, Batch 50/145, Loss: 0.1801
Epoch 5/10, Batch 60/145, Loss: 0.2847
Epoch 5/10, Batch 70/145, Loss: 0.1627
Epoch 5/10, Batch 80/145, Loss: 0.1748
Epoch 5/10, Batch 90/145, Loss: 0.2208
Epoch 5/10, Batch 100/145, Loss: 0.1928
Epoch 5/10, Batch 110/145, Loss: 0.2524
Epoch 5/10, Batch 120/145, Loss: 0.1857
Epoch 5/10, Batch 130/145, Loss: 0.1579
Epoch 5/10, Batch 140/145, Loss: 0.1699
Epoch 5/10, Train Loss: 0.2389, Valid Loss: 0.2550
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1225
Epoch 6/10, Batch 20/145, Loss: 0.5131
Epoch 6/10, Batch 30/145, Loss: 0.4094
Epoch 6/10, Batch 40/145, Loss: 0.3767
Epoch 6/10, Batch 50/145, Loss: 0.3035
Epoch 6/10, Batch 60/145, Loss: 0.2340
Epoch 6/10, Batch 70/145, Loss: 0.2566
Epoch 6/10, Batch 80/145, Loss: 0.2702
Epoch 6/10, Batch 90/145, Loss: 0.3990
Epoch 6/10, Batch 100/145, Loss: 0.2130
Epoch 6/10, Batch 110/145, Loss: 0.0974
Epoch 6/10, Batch 120/145, Loss: 0.2159
Epoch 6/10, Batch 130/145, Loss: 0.1609
Epoch 6/10, Batch 140/145, Loss: 0.1337
Epoch 6/10, Train Loss: 0.2255, Valid Loss: 0.2471
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1465
Epoch 7/10, Batch 20/145, Loss: 0.2989
Epoch 7/10, Batch 30/145, Loss: 0.1591
Epoch 7/10, Batch 40/145, Loss: 0.2822
Epoch 7/10, Batch 50/145, Loss: 0.1712
Epoch 7/10, Batch 60/145, Loss: 0.1886
Epoch 7/10, Batch 70/145, Loss: 0.0970
Epoch 7/10, Batch 80/145, Loss: 0.3250
Epoch 7/10, Batch 90/145, Loss: 0.2884
Epoch 7/10, Batch 100/145, Loss: 0.2699
Epoch 7/10, Batch 110/145, Loss: 0.1496
Epoch 7/10, Batch 120/145, Loss: 0.2969
Epoch 7/10, Batch 130/145, Loss: 0.1783
Epoch 7/10, Batch 140/145, Loss: 0.1840
Epoch 7/10, Train Loss: 0.2078, Valid Loss: 0.2425
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2012
Epoch 8/10, Batch 20/145, Loss: 0.1161
Epoch 8/10, Batch 30/145, Loss: 0.1462
Epoch 8/10, Batch 40/145, Loss: 0.2967
Epoch 8/10, Batch 50/145, Loss: 0.1836
Epoch 8/10, Batch 60/145, Loss: 0.3988
Epoch 8/10, Batch 70/145, Loss: 0.3339
Epoch 8/10, Batch 80/145, Loss: 0.0998
Epoch 8/10, Batch 90/145, Loss: 0.2585
Epoch 8/10, Batch 100/145, Loss: 0.1371
Epoch 8/10, Batch 110/145, Loss: 0.1894
Epoch 8/10, Batch 120/145, Loss: 0.2443
Epoch 8/10, Batch 130/145, Loss: 0.2729
Epoch 8/10, Batch 140/145, Loss: 0.1887
Epoch 8/10, Train Loss: 0.2092, Valid Loss: 0.2346
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.4437
Epoch 9/10, Batch 20/145, Loss: 0.1902
Epoch 9/10, Batch 30/145, Loss: 0.1300
Epoch 9/10, Batch 40/145, Loss: 0.2008
Epoch 9/10, Batch 50/145, Loss: 0.1552
Epoch 9/10, Batch 60/145, Loss: 0.1263
Epoch 9/10, Batch 70/145, Loss: 0.1516
Epoch 9/10, Batch 80/145, Loss: 0.0491
Epoch 9/10, Batch 90/145, Loss: 0.0998
Epoch 9/10, Batch 100/145, Loss: 0.1356
Epoch 9/10, Batch 110/145, Loss: 0.1317
Epoch 9/10, Batch 120/145, Loss: 0.1819
Epoch 9/10, Batch 130/145, Loss: 0.2892
Epoch 9/10, Batch 140/145, Loss: 0.3230
Epoch 9/10, Train Loss: 0.1948, Valid Loss: 0.2397
Epoch 10/10, Batch 10/145, Loss: 0.1235
Epoch 10/10, Batch 20/145, Loss: 0.1693
Epoch 10/10, Batch 30/145, Loss: 0.1912
Epoch 10/10, Batch 40/145, Loss: 0.1909
Epoch 10/10, Batch 50/145, Loss: 0.1523
Epoch 10/10, Batch 60/145, Loss: 0.1625
Epoch 10/10, Batch 70/145, Loss: 0.1357
Epoch 10/10, Batch 80/145, Loss: 0.1415
Epoch 10/10, Batch 90/145, Loss: 0.2244
Epoch 10/10, Batch 100/145, Loss: 0.1297
Epoch 10/10, Batch 110/145, Loss: 0.2704
Epoch 10/10, Batch 120/145, Loss: 0.1566
Epoch 10/10, Batch 130/145, Loss: 0.0894
Epoch 10/10, Batch 140/145, Loss: 0.3303
Epoch 10/10, Train Loss: 0.1931, Valid Loss: 0.2339
Model saved!
Accuracy: 0.9252
Precision: 0.9230
Recall: 0.9252
F1-score: 0.9232
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3847
Epoch 1/10, Batch 20/145, Loss: 0.9750
Epoch 1/10, Batch 30/145, Loss: 1.0036
Epoch 1/10, Batch 40/145, Loss: 0.8280
Epoch 1/10, Batch 50/145, Loss: 0.6456
Epoch 1/10, Batch 60/145, Loss: 0.5113
Epoch 1/10, Batch 70/145, Loss: 0.5093
Epoch 1/10, Batch 80/145, Loss: 0.4654
Epoch 1/10, Batch 90/145, Loss: 0.4600
Epoch 1/10, Batch 100/145, Loss: 0.4415
Epoch 1/10, Batch 110/145, Loss: 0.4044
Epoch 1/10, Batch 120/145, Loss: 0.5003
Epoch 1/10, Batch 130/145, Loss: 0.4014
Epoch 1/10, Batch 140/145, Loss: 0.3106
Epoch 1/10, Train Loss: 0.6752, Valid Loss: 0.3716
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3427
Epoch 2/10, Batch 20/145, Loss: 0.4171
Epoch 2/10, Batch 30/145, Loss: 0.2373
Epoch 2/10, Batch 40/145, Loss: 0.4545
Epoch 2/10, Batch 50/145, Loss: 0.2533
Epoch 2/10, Batch 60/145, Loss: 0.4267
Epoch 2/10, Batch 70/145, Loss: 0.3076
Epoch 2/10, Batch 80/145, Loss: 0.4291
Epoch 2/10, Batch 90/145, Loss: 0.4455
Epoch 2/10, Batch 100/145, Loss: 0.3756
Epoch 2/10, Batch 110/145, Loss: 0.4153
Epoch 2/10, Batch 120/145, Loss: 0.3354
Epoch 2/10, Batch 130/145, Loss: 0.3077
Epoch 2/10, Batch 140/145, Loss: 0.3690
Epoch 2/10, Train Loss: 0.3547, Valid Loss: 0.2881
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2872
Epoch 3/10, Batch 20/145, Loss: 0.2236
Epoch 3/10, Batch 30/145, Loss: 0.2524
Epoch 3/10, Batch 40/145, Loss: 0.1773
Epoch 3/10, Batch 50/145, Loss: 0.2244
Epoch 3/10, Batch 60/145, Loss: 0.3996
Epoch 3/10, Batch 70/145, Loss: 0.3193
Epoch 3/10, Batch 80/145, Loss: 0.1908
Epoch 3/10, Batch 90/145, Loss: 0.2999
Epoch 3/10, Batch 100/145, Loss: 0.2608
Epoch 3/10, Batch 110/145, Loss: 0.2088
Epoch 3/10, Batch 120/145, Loss: 0.3330
Epoch 3/10, Batch 130/145, Loss: 0.4024
Epoch 3/10, Batch 140/145, Loss: 0.1695
Epoch 3/10, Train Loss: 0.2968, Valid Loss: 0.2485
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2509
Epoch 4/10, Batch 20/145, Loss: 0.2425
Epoch 4/10, Batch 30/145, Loss: 0.2317
Epoch 4/10, Batch 40/145, Loss: 0.2989
Epoch 4/10, Batch 50/145, Loss: 0.2969
Epoch 4/10, Batch 60/145, Loss: 0.2670
Epoch 4/10, Batch 70/145, Loss: 0.2584
Epoch 4/10, Batch 80/145, Loss: 0.1897
Epoch 4/10, Batch 90/145, Loss: 0.3176
Epoch 4/10, Batch 100/145, Loss: 0.2165
Epoch 4/10, Batch 110/145, Loss: 0.1633
Epoch 4/10, Batch 120/145, Loss: 0.2296
Epoch 4/10, Batch 130/145, Loss: 0.1623
Epoch 4/10, Batch 140/145, Loss: 0.1759
Epoch 4/10, Train Loss: 0.2575, Valid Loss: 0.2372
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2242
Epoch 5/10, Batch 20/145, Loss: 0.1424
Epoch 5/10, Batch 30/145, Loss: 0.3209
Epoch 5/10, Batch 40/145, Loss: 0.3000
Epoch 5/10, Batch 50/145, Loss: 0.1785
Epoch 5/10, Batch 60/145, Loss: 0.2510
Epoch 5/10, Batch 70/145, Loss: 0.4279
Epoch 5/10, Batch 80/145, Loss: 0.2073
Epoch 5/10, Batch 90/145, Loss: 0.2873
Epoch 5/10, Batch 100/145, Loss: 0.1442
Epoch 5/10, Batch 110/145, Loss: 0.2727
Epoch 5/10, Batch 120/145, Loss: 0.4279
Epoch 5/10, Batch 130/145, Loss: 0.2485
Epoch 5/10, Batch 140/145, Loss: 0.2592
Epoch 5/10, Train Loss: 0.2508, Valid Loss: 0.2332
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1538
Epoch 6/10, Batch 20/145, Loss: 0.3500
Epoch 6/10, Batch 30/145, Loss: 0.2135
Epoch 6/10, Batch 40/145, Loss: 0.1477
Epoch 6/10, Batch 50/145, Loss: 0.3730
Epoch 6/10, Batch 60/145, Loss: 0.2496
Epoch 6/10, Batch 70/145, Loss: 0.1584
Epoch 6/10, Batch 80/145, Loss: 0.1421
Epoch 6/10, Batch 90/145, Loss: 0.4213
Epoch 6/10, Batch 100/145, Loss: 0.2878
Epoch 6/10, Batch 110/145, Loss: 0.1744
Epoch 6/10, Batch 120/145, Loss: 0.2012
Epoch 6/10, Batch 130/145, Loss: 0.2471
Epoch 6/10, Batch 140/145, Loss: 0.3152
Epoch 6/10, Train Loss: 0.2338, Valid Loss: 0.2162
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2343
Epoch 7/10, Batch 20/145, Loss: 0.1864
Epoch 7/10, Batch 30/145, Loss: 0.2073
Epoch 7/10, Batch 40/145, Loss: 0.3271
Epoch 7/10, Batch 50/145, Loss: 0.0935
Epoch 7/10, Batch 60/145, Loss: 0.1396
Epoch 7/10, Batch 70/145, Loss: 0.1392
Epoch 7/10, Batch 80/145, Loss: 0.4467
Epoch 7/10, Batch 90/145, Loss: 0.1545
Epoch 7/10, Batch 100/145, Loss: 0.1808
Epoch 7/10, Batch 110/145, Loss: 0.1278
Epoch 7/10, Batch 120/145, Loss: 0.1319
Epoch 7/10, Batch 130/145, Loss: 0.1396
Epoch 7/10, Batch 140/145, Loss: 0.3364
Epoch 7/10, Train Loss: 0.2150, Valid Loss: 0.2136
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1182
Epoch 8/10, Batch 20/145, Loss: 0.1709
Epoch 8/10, Batch 30/145, Loss: 0.2025
Epoch 8/10, Batch 40/145, Loss: 0.1784
Epoch 8/10, Batch 50/145, Loss: 0.2763
Epoch 8/10, Batch 60/145, Loss: 0.2542
Epoch 8/10, Batch 70/145, Loss: 0.3531
Epoch 8/10, Batch 80/145, Loss: 0.2205
Epoch 8/10, Batch 90/145, Loss: 0.2590
Epoch 8/10, Batch 100/145, Loss: 0.2351
Epoch 8/10, Batch 110/145, Loss: 0.1378
Epoch 8/10, Batch 120/145, Loss: 0.1633
Epoch 8/10, Batch 130/145, Loss: 0.1780
Epoch 8/10, Batch 140/145, Loss: 0.1820
Epoch 8/10, Train Loss: 0.2040, Valid Loss: 0.2065
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3293
Epoch 9/10, Batch 20/145, Loss: 0.2486
Epoch 9/10, Batch 30/145, Loss: 0.0835
Epoch 9/10, Batch 40/145, Loss: 0.1990
Epoch 9/10, Batch 50/145, Loss: 0.0887
Epoch 9/10, Batch 60/145, Loss: 0.2336
Epoch 9/10, Batch 70/145, Loss: 0.2424
Epoch 9/10, Batch 80/145, Loss: 0.1379
Epoch 9/10, Batch 90/145, Loss: 0.2615
Epoch 9/10, Batch 100/145, Loss: 0.2169
Epoch 9/10, Batch 110/145, Loss: 0.1353
Epoch 9/10, Batch 120/145, Loss: 0.1032
Epoch 9/10, Batch 130/145, Loss: 0.1175
Epoch 9/10, Batch 140/145, Loss: 0.1766
Epoch 9/10, Train Loss: 0.2033, Valid Loss: 0.2027
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0823
Epoch 10/10, Batch 20/145, Loss: 0.2872
Epoch 10/10, Batch 30/145, Loss: 0.1713
Epoch 10/10, Batch 40/145, Loss: 0.1513
Epoch 10/10, Batch 50/145, Loss: 0.2153
Epoch 10/10, Batch 60/145, Loss: 0.1742
Epoch 10/10, Batch 70/145, Loss: 0.3612
Epoch 10/10, Batch 80/145, Loss: 0.1013
Epoch 10/10, Batch 90/145, Loss: 0.1860
Epoch 10/10, Batch 100/145, Loss: 0.1584
Epoch 10/10, Batch 110/145, Loss: 0.1712
Epoch 10/10, Batch 120/145, Loss: 0.2021
Epoch 10/10, Batch 130/145, Loss: 0.1760
Epoch 10/10, Batch 140/145, Loss: 0.2890
Epoch 10/10, Train Loss: 0.2007, Valid Loss: 0.1953
Model saved!
Accuracy: 0.9159
Precision: 0.9129
Recall: 0.9159
F1-score: 0.9134
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3640
Epoch 1/10, Batch 20/145, Loss: 0.9625
Epoch 1/10, Batch 30/145, Loss: 0.8561
Epoch 1/10, Batch 40/145, Loss: 0.8621
Epoch 1/10, Batch 50/145, Loss: 0.7013
Epoch 1/10, Batch 60/145, Loss: 0.5021
Epoch 1/10, Batch 70/145, Loss: 0.4602
Epoch 1/10, Batch 80/145, Loss: 0.5946
Epoch 1/10, Batch 90/145, Loss: 0.5415
Epoch 1/10, Batch 100/145, Loss: 0.4939
Epoch 1/10, Batch 110/145, Loss: 0.4272
Epoch 1/10, Batch 120/145, Loss: 0.5289
Epoch 1/10, Batch 130/145, Loss: 0.4726
Epoch 1/10, Batch 140/145, Loss: 0.3444
Epoch 1/10, Train Loss: 0.6713, Valid Loss: 0.3758
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3158
Epoch 2/10, Batch 20/145, Loss: 0.4679
Epoch 2/10, Batch 30/145, Loss: 0.3759
Epoch 2/10, Batch 40/145, Loss: 0.4765
Epoch 2/10, Batch 50/145, Loss: 0.3251
Epoch 2/10, Batch 60/145, Loss: 0.3710
Epoch 2/10, Batch 70/145, Loss: 0.2622
Epoch 2/10, Batch 80/145, Loss: 0.3666
Epoch 2/10, Batch 90/145, Loss: 0.4750
Epoch 2/10, Batch 100/145, Loss: 0.3451
Epoch 2/10, Batch 110/145, Loss: 0.3851
Epoch 2/10, Batch 120/145, Loss: 0.5385
Epoch 2/10, Batch 130/145, Loss: 0.2315
Epoch 2/10, Batch 140/145, Loss: 0.3374
Epoch 2/10, Train Loss: 0.3505, Valid Loss: 0.2930
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2409
Epoch 3/10, Batch 20/145, Loss: 0.2780
Epoch 3/10, Batch 30/145, Loss: 0.2653
Epoch 3/10, Batch 40/145, Loss: 0.1831
Epoch 3/10, Batch 50/145, Loss: 0.2631
Epoch 3/10, Batch 60/145, Loss: 0.2339
Epoch 3/10, Batch 70/145, Loss: 0.2811
Epoch 3/10, Batch 80/145, Loss: 0.1729
Epoch 3/10, Batch 90/145, Loss: 0.1699
Epoch 3/10, Batch 100/145, Loss: 0.3694
Epoch 3/10, Batch 110/145, Loss: 0.1996
Epoch 3/10, Batch 120/145, Loss: 0.2718
Epoch 3/10, Batch 130/145, Loss: 0.2792
Epoch 3/10, Batch 140/145, Loss: 0.1828
Epoch 3/10, Train Loss: 0.2888, Valid Loss: 0.2670
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2620
Epoch 4/10, Batch 20/145, Loss: 0.2208
Epoch 4/10, Batch 30/145, Loss: 0.3614
Epoch 4/10, Batch 40/145, Loss: 0.1742
Epoch 4/10, Batch 50/145, Loss: 0.2272
Epoch 4/10, Batch 60/145, Loss: 0.2594
Epoch 4/10, Batch 70/145, Loss: 0.1850
Epoch 4/10, Batch 80/145, Loss: 0.2019
Epoch 4/10, Batch 90/145, Loss: 0.1211
Epoch 4/10, Batch 100/145, Loss: 0.2391
Epoch 4/10, Batch 110/145, Loss: 0.1747
Epoch 4/10, Batch 120/145, Loss: 0.1966
Epoch 4/10, Batch 130/145, Loss: 0.1547
Epoch 4/10, Batch 140/145, Loss: 0.1337
Epoch 4/10, Train Loss: 0.2567, Valid Loss: 0.2455
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1816
Epoch 5/10, Batch 20/145, Loss: 0.1297
Epoch 5/10, Batch 30/145, Loss: 0.2842
Epoch 5/10, Batch 40/145, Loss: 0.2014
Epoch 5/10, Batch 50/145, Loss: 0.3838
Epoch 5/10, Batch 60/145, Loss: 0.2176
Epoch 5/10, Batch 70/145, Loss: 0.2335
Epoch 5/10, Batch 80/145, Loss: 0.3216
Epoch 5/10, Batch 90/145, Loss: 0.2337
Epoch 5/10, Batch 100/145, Loss: 0.2706
Epoch 5/10, Batch 110/145, Loss: 0.1524
Epoch 5/10, Batch 120/145, Loss: 0.2842
Epoch 5/10, Batch 130/145, Loss: 0.1332
Epoch 5/10, Batch 140/145, Loss: 0.1486
Epoch 5/10, Train Loss: 0.2408, Valid Loss: 0.2406
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2020
Epoch 6/10, Batch 20/145, Loss: 0.3341
Epoch 6/10, Batch 30/145, Loss: 0.3253
Epoch 6/10, Batch 40/145, Loss: 0.2893
Epoch 6/10, Batch 50/145, Loss: 0.2667
Epoch 6/10, Batch 60/145, Loss: 0.2821
Epoch 6/10, Batch 70/145, Loss: 0.1269
Epoch 6/10, Batch 80/145, Loss: 0.1509
Epoch 6/10, Batch 90/145, Loss: 0.3139
Epoch 6/10, Batch 100/145, Loss: 0.2796
Epoch 6/10, Batch 110/145, Loss: 0.2170
Epoch 6/10, Batch 120/145, Loss: 0.2527
Epoch 6/10, Batch 130/145, Loss: 0.1507
Epoch 6/10, Batch 140/145, Loss: 0.1915
Epoch 6/10, Train Loss: 0.2280, Valid Loss: 0.2245
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2831
Epoch 7/10, Batch 20/145, Loss: 0.2679
Epoch 7/10, Batch 30/145, Loss: 0.1910
Epoch 7/10, Batch 40/145, Loss: 0.4200
Epoch 7/10, Batch 50/145, Loss: 0.0944
Epoch 7/10, Batch 60/145, Loss: 0.1557
Epoch 7/10, Batch 70/145, Loss: 0.1182
Epoch 7/10, Batch 80/145, Loss: 0.2752
Epoch 7/10, Batch 90/145, Loss: 0.2340
Epoch 7/10, Batch 100/145, Loss: 0.2251
Epoch 7/10, Batch 110/145, Loss: 0.1221
Epoch 7/10, Batch 120/145, Loss: 0.3693
Epoch 7/10, Batch 130/145, Loss: 0.0903
Epoch 7/10, Batch 140/145, Loss: 0.2244
Epoch 7/10, Train Loss: 0.2081, Valid Loss: 0.2196
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2222
Epoch 8/10, Batch 20/145, Loss: 0.1671
Epoch 8/10, Batch 30/145, Loss: 0.3738
Epoch 8/10, Batch 40/145, Loss: 0.4564
Epoch 8/10, Batch 50/145, Loss: 0.1583
Epoch 8/10, Batch 60/145, Loss: 0.1860
Epoch 8/10, Batch 70/145, Loss: 0.1413
Epoch 8/10, Batch 80/145, Loss: 0.2608
Epoch 8/10, Batch 90/145, Loss: 0.1664
Epoch 8/10, Batch 100/145, Loss: 0.1966
Epoch 8/10, Batch 110/145, Loss: 0.3139
Epoch 8/10, Batch 120/145, Loss: 0.2328
Epoch 8/10, Batch 130/145, Loss: 0.2431
Epoch 8/10, Batch 140/145, Loss: 0.0843
Epoch 8/10, Train Loss: 0.2089, Valid Loss: 0.2151
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3152
Epoch 9/10, Batch 20/145, Loss: 0.1951
Epoch 9/10, Batch 30/145, Loss: 0.1643
Epoch 9/10, Batch 40/145, Loss: 0.1376
Epoch 9/10, Batch 50/145, Loss: 0.1430
Epoch 9/10, Batch 60/145, Loss: 0.3345
Epoch 9/10, Batch 70/145, Loss: 0.1718
Epoch 9/10, Batch 80/145, Loss: 0.1046
Epoch 9/10, Batch 90/145, Loss: 0.2791
Epoch 9/10, Batch 100/145, Loss: 0.1415
Epoch 9/10, Batch 110/145, Loss: 0.3769
Epoch 9/10, Batch 120/145, Loss: 0.0613
Epoch 9/10, Batch 130/145, Loss: 0.1949
Epoch 9/10, Batch 140/145, Loss: 0.0926
Epoch 9/10, Train Loss: 0.2017, Valid Loss: 0.2130
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2633
Epoch 10/10, Batch 20/145, Loss: 0.1010
Epoch 10/10, Batch 30/145, Loss: 0.0986
Epoch 10/10, Batch 40/145, Loss: 0.1610
Epoch 10/10, Batch 50/145, Loss: 0.1468
Epoch 10/10, Batch 60/145, Loss: 0.1074
Epoch 10/10, Batch 70/145, Loss: 0.3530
Epoch 10/10, Batch 80/145, Loss: 0.1588
Epoch 10/10, Batch 90/145, Loss: 0.2169
Epoch 10/10, Batch 100/145, Loss: 0.0924
Epoch 10/10, Batch 110/145, Loss: 0.1968
Epoch 10/10, Batch 120/145, Loss: 0.2536
Epoch 10/10, Batch 130/145, Loss: 0.1975
Epoch 10/10, Batch 140/145, Loss: 0.1749
Epoch 10/10, Train Loss: 0.1886, Valid Loss: 0.2071
Model saved!
Accuracy: 0.9241
Precision: 0.9220
Recall: 0.9241
F1-score: 0.9225
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3766
Epoch 1/10, Batch 20/145, Loss: 0.9481
Epoch 1/10, Batch 30/145, Loss: 0.8484
Epoch 1/10, Batch 40/145, Loss: 0.7754
Epoch 1/10, Batch 50/145, Loss: 0.6104
Epoch 1/10, Batch 60/145, Loss: 0.6532
Epoch 1/10, Batch 70/145, Loss: 0.5295
Epoch 1/10, Batch 80/145, Loss: 0.6214
Epoch 1/10, Batch 90/145, Loss: 0.3869
Epoch 1/10, Batch 100/145, Loss: 0.4569
Epoch 1/10, Batch 110/145, Loss: 0.5498
Epoch 1/10, Batch 120/145, Loss: 0.3977
Epoch 1/10, Batch 130/145, Loss: 0.6110
Epoch 1/10, Batch 140/145, Loss: 0.4214
Epoch 1/10, Train Loss: 0.6751, Valid Loss: 0.3905
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3583
Epoch 2/10, Batch 20/145, Loss: 0.3326
Epoch 2/10, Batch 30/145, Loss: 0.2464
Epoch 2/10, Batch 40/145, Loss: 0.5458
Epoch 2/10, Batch 50/145, Loss: 0.4740
Epoch 2/10, Batch 60/145, Loss: 0.3336
Epoch 2/10, Batch 70/145, Loss: 0.2166
Epoch 2/10, Batch 80/145, Loss: 0.4187
Epoch 2/10, Batch 90/145, Loss: 0.3922
Epoch 2/10, Batch 100/145, Loss: 0.2838
Epoch 2/10, Batch 110/145, Loss: 0.2434
Epoch 2/10, Batch 120/145, Loss: 0.4389
Epoch 2/10, Batch 130/145, Loss: 0.2511
Epoch 2/10, Batch 140/145, Loss: 0.2007
Epoch 2/10, Train Loss: 0.3567, Valid Loss: 0.3147
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2061
Epoch 3/10, Batch 20/145, Loss: 0.3184
Epoch 3/10, Batch 30/145, Loss: 0.3789
Epoch 3/10, Batch 40/145, Loss: 0.1676
Epoch 3/10, Batch 50/145, Loss: 0.2529
Epoch 3/10, Batch 60/145, Loss: 0.5223
Epoch 3/10, Batch 70/145, Loss: 0.3935
Epoch 3/10, Batch 80/145, Loss: 0.2528
Epoch 3/10, Batch 90/145, Loss: 0.2647
Epoch 3/10, Batch 100/145, Loss: 0.2914
Epoch 3/10, Batch 110/145, Loss: 0.2013
Epoch 3/10, Batch 120/145, Loss: 0.3094
Epoch 3/10, Batch 130/145, Loss: 0.3192
Epoch 3/10, Batch 140/145, Loss: 0.1778
Epoch 3/10, Train Loss: 0.2975, Valid Loss: 0.2785
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2822
Epoch 4/10, Batch 20/145, Loss: 0.2313
Epoch 4/10, Batch 30/145, Loss: 0.3880
Epoch 4/10, Batch 40/145, Loss: 0.1639
Epoch 4/10, Batch 50/145, Loss: 0.2027
Epoch 4/10, Batch 60/145, Loss: 0.2165
Epoch 4/10, Batch 70/145, Loss: 0.1575
Epoch 4/10, Batch 80/145, Loss: 0.2075
Epoch 4/10, Batch 90/145, Loss: 0.2427
Epoch 4/10, Batch 100/145, Loss: 0.4284
Epoch 4/10, Batch 110/145, Loss: 0.1533
Epoch 4/10, Batch 120/145, Loss: 0.2343
Epoch 4/10, Batch 130/145, Loss: 0.1232
Epoch 4/10, Batch 140/145, Loss: 0.1454
Epoch 4/10, Train Loss: 0.2598, Valid Loss: 0.2712
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1907
Epoch 5/10, Batch 20/145, Loss: 0.1827
Epoch 5/10, Batch 30/145, Loss: 0.2673
Epoch 5/10, Batch 40/145, Loss: 0.1645
Epoch 5/10, Batch 50/145, Loss: 0.1482
Epoch 5/10, Batch 60/145, Loss: 0.4294
Epoch 5/10, Batch 70/145, Loss: 0.2170
Epoch 5/10, Batch 80/145, Loss: 0.1525
Epoch 5/10, Batch 90/145, Loss: 0.4253
Epoch 5/10, Batch 100/145, Loss: 0.1622
Epoch 5/10, Batch 110/145, Loss: 0.2133
Epoch 5/10, Batch 120/145, Loss: 0.1932
Epoch 5/10, Batch 130/145, Loss: 0.1210
Epoch 5/10, Batch 140/145, Loss: 0.1426
Epoch 5/10, Train Loss: 0.2475, Valid Loss: 0.2550
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2207
Epoch 6/10, Batch 20/145, Loss: 0.2528
Epoch 6/10, Batch 30/145, Loss: 0.2979
Epoch 6/10, Batch 40/145, Loss: 0.2285
Epoch 6/10, Batch 50/145, Loss: 0.3524
Epoch 6/10, Batch 60/145, Loss: 0.2772
Epoch 6/10, Batch 70/145, Loss: 0.1634
Epoch 6/10, Batch 80/145, Loss: 0.1993
Epoch 6/10, Batch 90/145, Loss: 0.2339
Epoch 6/10, Batch 100/145, Loss: 0.1919
Epoch 6/10, Batch 110/145, Loss: 0.3979
Epoch 6/10, Batch 120/145, Loss: 0.1896
Epoch 6/10, Batch 130/145, Loss: 0.2426
Epoch 6/10, Batch 140/145, Loss: 0.1858
Epoch 6/10, Train Loss: 0.2324, Valid Loss: 0.2439
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3739
Epoch 7/10, Batch 20/145, Loss: 0.2170
Epoch 7/10, Batch 30/145, Loss: 0.2891
Epoch 7/10, Batch 40/145, Loss: 0.2315
Epoch 7/10, Batch 50/145, Loss: 0.1643
Epoch 7/10, Batch 60/145, Loss: 0.2255
Epoch 7/10, Batch 70/145, Loss: 0.1467
Epoch 7/10, Batch 80/145, Loss: 0.4096
Epoch 7/10, Batch 90/145, Loss: 0.2847
Epoch 7/10, Batch 100/145, Loss: 0.1044
Epoch 7/10, Batch 110/145, Loss: 0.1088
Epoch 7/10, Batch 120/145, Loss: 0.2300
Epoch 7/10, Batch 130/145, Loss: 0.0980
Epoch 7/10, Batch 140/145, Loss: 0.3082
Epoch 7/10, Train Loss: 0.2177, Valid Loss: 0.2361
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1682
Epoch 8/10, Batch 20/145, Loss: 0.2742
Epoch 8/10, Batch 30/145, Loss: 0.3760
Epoch 8/10, Batch 40/145, Loss: 0.2789
Epoch 8/10, Batch 50/145, Loss: 0.3160
Epoch 8/10, Batch 60/145, Loss: 0.2245
Epoch 8/10, Batch 70/145, Loss: 0.1824
Epoch 8/10, Batch 80/145, Loss: 0.2108
Epoch 8/10, Batch 90/145, Loss: 0.2611
Epoch 8/10, Batch 100/145, Loss: 0.2422
Epoch 8/10, Batch 110/145, Loss: 0.3136
Epoch 8/10, Batch 120/145, Loss: 0.1086
Epoch 8/10, Batch 130/145, Loss: 0.1498
Epoch 8/10, Batch 140/145, Loss: 0.2705
Epoch 8/10, Train Loss: 0.2041, Valid Loss: 0.2361
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3330
Epoch 9/10, Batch 20/145, Loss: 0.1245
Epoch 9/10, Batch 30/145, Loss: 0.0586
Epoch 9/10, Batch 40/145, Loss: 0.2238
Epoch 9/10, Batch 50/145, Loss: 0.1892
Epoch 9/10, Batch 60/145, Loss: 0.2999
Epoch 9/10, Batch 70/145, Loss: 0.0942
Epoch 9/10, Batch 80/145, Loss: 0.1248
Epoch 9/10, Batch 90/145, Loss: 0.2979
Epoch 9/10, Batch 100/145, Loss: 0.1297
Epoch 9/10, Batch 110/145, Loss: 0.0908
Epoch 9/10, Batch 120/145, Loss: 0.2203
Epoch 9/10, Batch 130/145, Loss: 0.2091
Epoch 9/10, Batch 140/145, Loss: 0.3713
Epoch 9/10, Train Loss: 0.1980, Valid Loss: 0.2331
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2271
Epoch 10/10, Batch 20/145, Loss: 0.1880
Epoch 10/10, Batch 30/145, Loss: 0.1755
Epoch 10/10, Batch 40/145, Loss: 0.0940
Epoch 10/10, Batch 50/145, Loss: 0.1900
Epoch 10/10, Batch 60/145, Loss: 0.3159
Epoch 10/10, Batch 70/145, Loss: 0.1952
Epoch 10/10, Batch 80/145, Loss: 0.1505
Epoch 10/10, Batch 90/145, Loss: 0.1463
Epoch 10/10, Batch 100/145, Loss: 0.1785
Epoch 10/10, Batch 110/145, Loss: 0.2105
Epoch 10/10, Batch 120/145, Loss: 0.2114
Epoch 10/10, Batch 130/145, Loss: 0.1051
Epoch 10/10, Batch 140/145, Loss: 0.2059
Epoch 10/10, Train Loss: 0.1911, Valid Loss: 0.2306
Model saved!
Accuracy: 0.9264
Precision: 0.9246
Recall: 0.9264
F1-score: 0.9252
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4251
Epoch 1/10, Batch 20/145, Loss: 0.9633
Epoch 1/10, Batch 30/145, Loss: 0.8711
Epoch 1/10, Batch 40/145, Loss: 0.7550
Epoch 1/10, Batch 50/145, Loss: 0.8373
Epoch 1/10, Batch 60/145, Loss: 0.6282
Epoch 1/10, Batch 70/145, Loss: 0.4932
Epoch 1/10, Batch 80/145, Loss: 0.6484
Epoch 1/10, Batch 90/145, Loss: 0.5155
Epoch 1/10, Batch 100/145, Loss: 0.5425
Epoch 1/10, Batch 110/145, Loss: 0.5178
Epoch 1/10, Batch 120/145, Loss: 0.5614
Epoch 1/10, Batch 130/145, Loss: 0.5502
Epoch 1/10, Batch 140/145, Loss: 0.3720
Epoch 1/10, Train Loss: 0.6778, Valid Loss: 0.3960
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3324
Epoch 2/10, Batch 20/145, Loss: 0.2824
Epoch 2/10, Batch 30/145, Loss: 0.2896
Epoch 2/10, Batch 40/145, Loss: 0.3592
Epoch 2/10, Batch 50/145, Loss: 0.3738
Epoch 2/10, Batch 60/145, Loss: 0.3532
Epoch 2/10, Batch 70/145, Loss: 0.4151
Epoch 2/10, Batch 80/145, Loss: 0.2452
Epoch 2/10, Batch 90/145, Loss: 0.2192
Epoch 2/10, Batch 100/145, Loss: 0.2909
Epoch 2/10, Batch 110/145, Loss: 0.4369
Epoch 2/10, Batch 120/145, Loss: 0.3756
Epoch 2/10, Batch 130/145, Loss: 0.3285
Epoch 2/10, Batch 140/145, Loss: 0.2060
Epoch 2/10, Train Loss: 0.3492, Valid Loss: 0.3125
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2459
Epoch 3/10, Batch 20/145, Loss: 0.2942
Epoch 3/10, Batch 30/145, Loss: 0.2937
Epoch 3/10, Batch 40/145, Loss: 0.3406
Epoch 3/10, Batch 50/145, Loss: 0.4061
Epoch 3/10, Batch 60/145, Loss: 0.3917
Epoch 3/10, Batch 70/145, Loss: 0.3032
Epoch 3/10, Batch 80/145, Loss: 0.1016
Epoch 3/10, Batch 90/145, Loss: 0.4739
Epoch 3/10, Batch 100/145, Loss: 0.3449
Epoch 3/10, Batch 110/145, Loss: 0.2061
Epoch 3/10, Batch 120/145, Loss: 0.2384
Epoch 3/10, Batch 130/145, Loss: 0.3533
Epoch 3/10, Batch 140/145, Loss: 0.2587
Epoch 3/10, Train Loss: 0.2873, Valid Loss: 0.2800
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3657
Epoch 4/10, Batch 20/145, Loss: 0.3255
Epoch 4/10, Batch 30/145, Loss: 0.3442
Epoch 4/10, Batch 40/145, Loss: 0.1907
Epoch 4/10, Batch 50/145, Loss: 0.1948
Epoch 4/10, Batch 60/145, Loss: 0.3179
Epoch 4/10, Batch 70/145, Loss: 0.4477
Epoch 4/10, Batch 80/145, Loss: 0.1845
Epoch 4/10, Batch 90/145, Loss: 0.2630
Epoch 4/10, Batch 100/145, Loss: 0.4545
Epoch 4/10, Batch 110/145, Loss: 0.1098
Epoch 4/10, Batch 120/145, Loss: 0.2087
Epoch 4/10, Batch 130/145, Loss: 0.0782
Epoch 4/10, Batch 140/145, Loss: 0.2687
Epoch 4/10, Train Loss: 0.2586, Valid Loss: 0.2642
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1236
Epoch 5/10, Batch 20/145, Loss: 0.1484
Epoch 5/10, Batch 30/145, Loss: 0.1786
Epoch 5/10, Batch 40/145, Loss: 0.1446
Epoch 5/10, Batch 50/145, Loss: 0.4525
Epoch 5/10, Batch 60/145, Loss: 0.1437
Epoch 5/10, Batch 70/145, Loss: 0.2253
Epoch 5/10, Batch 80/145, Loss: 0.1764
Epoch 5/10, Batch 90/145, Loss: 0.2947
Epoch 5/10, Batch 100/145, Loss: 0.2519
Epoch 5/10, Batch 110/145, Loss: 0.1817
Epoch 5/10, Batch 120/145, Loss: 0.5499
Epoch 5/10, Batch 130/145, Loss: 0.1466
Epoch 5/10, Batch 140/145, Loss: 0.2742
Epoch 5/10, Train Loss: 0.2387, Valid Loss: 0.2634
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1925
Epoch 6/10, Batch 20/145, Loss: 0.3509
Epoch 6/10, Batch 30/145, Loss: 0.2691
Epoch 6/10, Batch 40/145, Loss: 0.0983
Epoch 6/10, Batch 50/145, Loss: 0.3039
Epoch 6/10, Batch 60/145, Loss: 0.2741
Epoch 6/10, Batch 70/145, Loss: 0.0965
Epoch 6/10, Batch 80/145, Loss: 0.1952
Epoch 6/10, Batch 90/145, Loss: 0.3206
Epoch 6/10, Batch 100/145, Loss: 0.2251
Epoch 6/10, Batch 110/145, Loss: 0.1180
Epoch 6/10, Batch 120/145, Loss: 0.1899
Epoch 6/10, Batch 130/145, Loss: 0.2699
Epoch 6/10, Batch 140/145, Loss: 0.0702
Epoch 6/10, Train Loss: 0.2275, Valid Loss: 0.2439
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1418
Epoch 7/10, Batch 20/145, Loss: 0.2485
Epoch 7/10, Batch 30/145, Loss: 0.2797
Epoch 7/10, Batch 40/145, Loss: 0.3628
Epoch 7/10, Batch 50/145, Loss: 0.3509
Epoch 7/10, Batch 60/145, Loss: 0.1214
Epoch 7/10, Batch 70/145, Loss: 0.1595
Epoch 7/10, Batch 80/145, Loss: 0.3785
Epoch 7/10, Batch 90/145, Loss: 0.1673
Epoch 7/10, Batch 100/145, Loss: 0.1429
Epoch 7/10, Batch 110/145, Loss: 0.2330
Epoch 7/10, Batch 120/145, Loss: 0.4841
Epoch 7/10, Batch 130/145, Loss: 0.1325
Epoch 7/10, Batch 140/145, Loss: 0.3803
Epoch 7/10, Train Loss: 0.2121, Valid Loss: 0.2446
Epoch 8/10, Batch 10/145, Loss: 0.1897
Epoch 8/10, Batch 20/145, Loss: 0.2145
Epoch 8/10, Batch 30/145, Loss: 0.2760
Epoch 8/10, Batch 40/145, Loss: 0.1394
Epoch 8/10, Batch 50/145, Loss: 0.2325
Epoch 8/10, Batch 60/145, Loss: 0.3322
Epoch 8/10, Batch 70/145, Loss: 0.1451
Epoch 8/10, Batch 80/145, Loss: 0.3182
Epoch 8/10, Batch 90/145, Loss: 0.4252
Epoch 8/10, Batch 100/145, Loss: 0.0957
Epoch 8/10, Batch 110/145, Loss: 0.1526
Epoch 8/10, Batch 120/145, Loss: 0.1915
Epoch 8/10, Batch 130/145, Loss: 0.2270
Epoch 8/10, Batch 140/145, Loss: 0.1777
Epoch 8/10, Train Loss: 0.2099, Valid Loss: 0.2407
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2998
Epoch 9/10, Batch 20/145, Loss: 0.1495
Epoch 9/10, Batch 30/145, Loss: 0.1305
Epoch 9/10, Batch 40/145, Loss: 0.1030
Epoch 9/10, Batch 50/145, Loss: 0.3207
Epoch 9/10, Batch 60/145, Loss: 0.1608
Epoch 9/10, Batch 70/145, Loss: 0.2624
Epoch 9/10, Batch 80/145, Loss: 0.1047
Epoch 9/10, Batch 90/145, Loss: 0.3154
Epoch 9/10, Batch 100/145, Loss: 0.2218
Epoch 9/10, Batch 110/145, Loss: 0.3075
Epoch 9/10, Batch 120/145, Loss: 0.2261
Epoch 9/10, Batch 130/145, Loss: 0.3297
Epoch 9/10, Batch 140/145, Loss: 0.1494
Epoch 9/10, Train Loss: 0.1971, Valid Loss: 0.2384
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1299
Epoch 10/10, Batch 20/145, Loss: 0.2102
Epoch 10/10, Batch 30/145, Loss: 0.1443
Epoch 10/10, Batch 40/145, Loss: 0.1183
Epoch 10/10, Batch 50/145, Loss: 0.1825
Epoch 10/10, Batch 60/145, Loss: 0.1371
Epoch 10/10, Batch 70/145, Loss: 0.2231
Epoch 10/10, Batch 80/145, Loss: 0.1983
Epoch 10/10, Batch 90/145, Loss: 0.0931
Epoch 10/10, Batch 100/145, Loss: 0.2166
Epoch 10/10, Batch 110/145, Loss: 0.1967
Epoch 10/10, Batch 120/145, Loss: 0.3008
Epoch 10/10, Batch 130/145, Loss: 0.2718
Epoch 10/10, Batch 140/145, Loss: 0.1462
Epoch 10/10, Train Loss: 0.1963, Valid Loss: 0.2310
Model saved!
Accuracy: 0.9264
Precision: 0.9245
Recall: 0.9264
F1-score: 0.9248
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3691
Epoch 1/10, Batch 20/145, Loss: 0.8899
Epoch 1/10, Batch 30/145, Loss: 0.9096
Epoch 1/10, Batch 40/145, Loss: 0.8123
Epoch 1/10, Batch 50/145, Loss: 0.7650
Epoch 1/10, Batch 60/145, Loss: 0.6206
Epoch 1/10, Batch 70/145, Loss: 0.4788
Epoch 1/10, Batch 80/145, Loss: 0.6729
Epoch 1/10, Batch 90/145, Loss: 0.3662
Epoch 1/10, Batch 100/145, Loss: 0.5015
Epoch 1/10, Batch 110/145, Loss: 0.3812
Epoch 1/10, Batch 120/145, Loss: 0.6260
Epoch 1/10, Batch 130/145, Loss: 0.4938
Epoch 1/10, Batch 140/145, Loss: 0.4566
Epoch 1/10, Train Loss: 0.6823, Valid Loss: 0.3609
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3466
Epoch 2/10, Batch 20/145, Loss: 0.4992
Epoch 2/10, Batch 30/145, Loss: 0.3319
Epoch 2/10, Batch 40/145, Loss: 0.3933
Epoch 2/10, Batch 50/145, Loss: 0.3747
Epoch 2/10, Batch 60/145, Loss: 0.3006
Epoch 2/10, Batch 70/145, Loss: 0.3917
Epoch 2/10, Batch 80/145, Loss: 0.3884
Epoch 2/10, Batch 90/145, Loss: 0.3259
Epoch 2/10, Batch 100/145, Loss: 0.3149
Epoch 2/10, Batch 110/145, Loss: 0.3909
Epoch 2/10, Batch 120/145, Loss: 0.4240
Epoch 2/10, Batch 130/145, Loss: 0.2421
Epoch 2/10, Batch 140/145, Loss: 0.3275
Epoch 2/10, Train Loss: 0.3571, Valid Loss: 0.2709
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2094
Epoch 3/10, Batch 20/145, Loss: 0.2431
Epoch 3/10, Batch 30/145, Loss: 0.3891
Epoch 3/10, Batch 40/145, Loss: 0.3343
Epoch 3/10, Batch 50/145, Loss: 0.2762
Epoch 3/10, Batch 60/145, Loss: 0.2541
Epoch 3/10, Batch 70/145, Loss: 0.4953
Epoch 3/10, Batch 80/145, Loss: 0.2575
Epoch 3/10, Batch 90/145, Loss: 0.1368
Epoch 3/10, Batch 100/145, Loss: 0.3734
Epoch 3/10, Batch 110/145, Loss: 0.2589
Epoch 3/10, Batch 120/145, Loss: 0.2402
Epoch 3/10, Batch 130/145, Loss: 0.3048
Epoch 3/10, Batch 140/145, Loss: 0.4080
Epoch 3/10, Train Loss: 0.2996, Valid Loss: 0.2481
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2602
Epoch 4/10, Batch 20/145, Loss: 0.2623
Epoch 4/10, Batch 30/145, Loss: 0.4141
Epoch 4/10, Batch 40/145, Loss: 0.1188
Epoch 4/10, Batch 50/145, Loss: 0.3244
Epoch 4/10, Batch 60/145, Loss: 0.2816
Epoch 4/10, Batch 70/145, Loss: 0.1508
Epoch 4/10, Batch 80/145, Loss: 0.1953
Epoch 4/10, Batch 90/145, Loss: 0.1967
Epoch 4/10, Batch 100/145, Loss: 0.2786
Epoch 4/10, Batch 110/145, Loss: 0.2439
Epoch 4/10, Batch 120/145, Loss: 0.3196
Epoch 4/10, Batch 130/145, Loss: 0.1610
Epoch 4/10, Batch 140/145, Loss: 0.1018
Epoch 4/10, Train Loss: 0.2643, Valid Loss: 0.2329
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1648
Epoch 5/10, Batch 20/145, Loss: 0.1551
Epoch 5/10, Batch 30/145, Loss: 0.4122
Epoch 5/10, Batch 40/145, Loss: 0.2011
Epoch 5/10, Batch 50/145, Loss: 0.2265
Epoch 5/10, Batch 60/145, Loss: 0.1475
Epoch 5/10, Batch 70/145, Loss: 0.2940
Epoch 5/10, Batch 80/145, Loss: 0.1832
Epoch 5/10, Batch 90/145, Loss: 0.3904
Epoch 5/10, Batch 100/145, Loss: 0.1560
Epoch 5/10, Batch 110/145, Loss: 0.1868
Epoch 5/10, Batch 120/145, Loss: 0.2905
Epoch 5/10, Batch 130/145, Loss: 0.1959
Epoch 5/10, Batch 140/145, Loss: 0.1395
Epoch 5/10, Train Loss: 0.2513, Valid Loss: 0.2287
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1630
Epoch 6/10, Batch 20/145, Loss: 0.2444
Epoch 6/10, Batch 30/145, Loss: 0.5100
Epoch 6/10, Batch 40/145, Loss: 0.0903
Epoch 6/10, Batch 50/145, Loss: 0.4646
Epoch 6/10, Batch 60/145, Loss: 0.3608
Epoch 6/10, Batch 70/145, Loss: 0.2698
Epoch 6/10, Batch 80/145, Loss: 0.1948
Epoch 6/10, Batch 90/145, Loss: 0.3197
Epoch 6/10, Batch 100/145, Loss: 0.2264
Epoch 6/10, Batch 110/145, Loss: 0.3024
Epoch 6/10, Batch 120/145, Loss: 0.3230
Epoch 6/10, Batch 130/145, Loss: 0.2662
Epoch 6/10, Batch 140/145, Loss: 0.1325
Epoch 6/10, Train Loss: 0.2308, Valid Loss: 0.2093
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2861
Epoch 7/10, Batch 20/145, Loss: 0.2150
Epoch 7/10, Batch 30/145, Loss: 0.1498
Epoch 7/10, Batch 40/145, Loss: 0.2809
Epoch 7/10, Batch 50/145, Loss: 0.1786
Epoch 7/10, Batch 60/145, Loss: 0.2739
Epoch 7/10, Batch 70/145, Loss: 0.1614
Epoch 7/10, Batch 80/145, Loss: 0.3285
Epoch 7/10, Batch 90/145, Loss: 0.1117
Epoch 7/10, Batch 100/145, Loss: 0.1740
Epoch 7/10, Batch 110/145, Loss: 0.0856
Epoch 7/10, Batch 120/145, Loss: 0.1840
Epoch 7/10, Batch 130/145, Loss: 0.0704
Epoch 7/10, Batch 140/145, Loss: 0.1204
Epoch 7/10, Train Loss: 0.2193, Valid Loss: 0.2069
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2469
Epoch 8/10, Batch 20/145, Loss: 0.3371
Epoch 8/10, Batch 30/145, Loss: 0.2423
Epoch 8/10, Batch 40/145, Loss: 0.2965
Epoch 8/10, Batch 50/145, Loss: 0.2553
Epoch 8/10, Batch 60/145, Loss: 0.2836
Epoch 8/10, Batch 70/145, Loss: 0.3497
Epoch 8/10, Batch 80/145, Loss: 0.2641
Epoch 8/10, Batch 90/145, Loss: 0.5618
Epoch 8/10, Batch 100/145, Loss: 0.1472
Epoch 8/10, Batch 110/145, Loss: 0.2343
Epoch 8/10, Batch 120/145, Loss: 0.1237
Epoch 8/10, Batch 130/145, Loss: 0.1306
Epoch 8/10, Batch 140/145, Loss: 0.3542
Epoch 8/10, Train Loss: 0.2112, Valid Loss: 0.2001
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1964
Epoch 9/10, Batch 20/145, Loss: 0.2684
Epoch 9/10, Batch 30/145, Loss: 0.0951
Epoch 9/10, Batch 40/145, Loss: 0.0750
Epoch 9/10, Batch 50/145, Loss: 0.1448
Epoch 9/10, Batch 60/145, Loss: 0.2638
Epoch 9/10, Batch 70/145, Loss: 0.2631
Epoch 9/10, Batch 80/145, Loss: 0.1312
Epoch 9/10, Batch 90/145, Loss: 0.1399
Epoch 9/10, Batch 100/145, Loss: 0.1078
Epoch 9/10, Batch 110/145, Loss: 0.2627
Epoch 9/10, Batch 120/145, Loss: 0.2650
Epoch 9/10, Batch 130/145, Loss: 0.1036
Epoch 9/10, Batch 140/145, Loss: 0.3483
Epoch 9/10, Train Loss: 0.2056, Valid Loss: 0.2023
Epoch 10/10, Batch 10/145, Loss: 0.0732
Epoch 10/10, Batch 20/145, Loss: 0.1409
Epoch 10/10, Batch 30/145, Loss: 0.1113
Epoch 10/10, Batch 40/145, Loss: 0.2145
Epoch 10/10, Batch 50/145, Loss: 0.2408
Epoch 10/10, Batch 60/145, Loss: 0.1679
Epoch 10/10, Batch 70/145, Loss: 0.2933
Epoch 10/10, Batch 80/145, Loss: 0.1683
Epoch 10/10, Batch 90/145, Loss: 0.1657
Epoch 10/10, Batch 100/145, Loss: 0.1140
Epoch 10/10, Batch 110/145, Loss: 0.1208
Epoch 10/10, Batch 120/145, Loss: 0.1822
Epoch 10/10, Batch 130/145, Loss: 0.3376
Epoch 10/10, Batch 140/145, Loss: 0.2750
Epoch 10/10, Train Loss: 0.2003, Valid Loss: 0.1922
Model saved!
Accuracy: 0.9241
Precision: 0.9222
Recall: 0.9241
F1-score: 0.9221
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4817
Epoch 1/10, Batch 20/145, Loss: 1.0743
Epoch 1/10, Batch 30/145, Loss: 0.7910
Epoch 1/10, Batch 40/145, Loss: 0.7889
Epoch 1/10, Batch 50/145, Loss: 0.8165
Epoch 1/10, Batch 60/145, Loss: 0.6220
Epoch 1/10, Batch 70/145, Loss: 0.4879
Epoch 1/10, Batch 80/145, Loss: 0.5686
Epoch 1/10, Batch 90/145, Loss: 0.5030
Epoch 1/10, Batch 100/145, Loss: 0.6190
Epoch 1/10, Batch 110/145, Loss: 0.3989
Epoch 1/10, Batch 120/145, Loss: 0.4878
Epoch 1/10, Batch 130/145, Loss: 0.4536
Epoch 1/10, Batch 140/145, Loss: 0.3476
Epoch 1/10, Train Loss: 0.6774, Valid Loss: 0.3864
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2986
Epoch 2/10, Batch 20/145, Loss: 0.5194
Epoch 2/10, Batch 30/145, Loss: 0.2678
Epoch 2/10, Batch 40/145, Loss: 0.6134
Epoch 2/10, Batch 50/145, Loss: 0.3623
Epoch 2/10, Batch 60/145, Loss: 0.3879
Epoch 2/10, Batch 70/145, Loss: 0.4511
Epoch 2/10, Batch 80/145, Loss: 0.3237
Epoch 2/10, Batch 90/145, Loss: 0.3253
Epoch 2/10, Batch 100/145, Loss: 0.2753
Epoch 2/10, Batch 110/145, Loss: 0.3568
Epoch 2/10, Batch 120/145, Loss: 0.3210
Epoch 2/10, Batch 130/145, Loss: 0.4874
Epoch 2/10, Batch 140/145, Loss: 0.3384
Epoch 2/10, Train Loss: 0.3504, Valid Loss: 0.3034
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3668
Epoch 3/10, Batch 20/145, Loss: 0.2429
Epoch 3/10, Batch 30/145, Loss: 0.4263
Epoch 3/10, Batch 40/145, Loss: 0.3710
Epoch 3/10, Batch 50/145, Loss: 0.1662
Epoch 3/10, Batch 60/145, Loss: 0.3679
Epoch 3/10, Batch 70/145, Loss: 0.3309
Epoch 3/10, Batch 80/145, Loss: 0.2354
Epoch 3/10, Batch 90/145, Loss: 0.1998
Epoch 3/10, Batch 100/145, Loss: 0.3740
Epoch 3/10, Batch 110/145, Loss: 0.3781
Epoch 3/10, Batch 120/145, Loss: 0.1662
Epoch 3/10, Batch 130/145, Loss: 0.2875
Epoch 3/10, Batch 140/145, Loss: 0.1689
Epoch 3/10, Train Loss: 0.2934, Valid Loss: 0.2729
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3714
Epoch 4/10, Batch 20/145, Loss: 0.3721
Epoch 4/10, Batch 30/145, Loss: 0.3249
Epoch 4/10, Batch 40/145, Loss: 0.3190
Epoch 4/10, Batch 50/145, Loss: 0.2047
Epoch 4/10, Batch 60/145, Loss: 0.1335
Epoch 4/10, Batch 70/145, Loss: 0.3178
Epoch 4/10, Batch 80/145, Loss: 0.3217
Epoch 4/10, Batch 90/145, Loss: 0.2748
Epoch 4/10, Batch 100/145, Loss: 0.3129
Epoch 4/10, Batch 110/145, Loss: 0.1762
Epoch 4/10, Batch 120/145, Loss: 0.2139
Epoch 4/10, Batch 130/145, Loss: 0.2488
Epoch 4/10, Batch 140/145, Loss: 0.3602
Epoch 4/10, Train Loss: 0.2610, Valid Loss: 0.2588
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1501
Epoch 5/10, Batch 20/145, Loss: 0.1076
Epoch 5/10, Batch 30/145, Loss: 0.2797
Epoch 5/10, Batch 40/145, Loss: 0.1453
Epoch 5/10, Batch 50/145, Loss: 0.2130
Epoch 5/10, Batch 60/145, Loss: 0.1760
Epoch 5/10, Batch 70/145, Loss: 0.2736
Epoch 5/10, Batch 80/145, Loss: 0.0979
Epoch 5/10, Batch 90/145, Loss: 0.2465
Epoch 5/10, Batch 100/145, Loss: 0.3994
Epoch 5/10, Batch 110/145, Loss: 0.7420
Epoch 5/10, Batch 120/145, Loss: 0.3076
Epoch 5/10, Batch 130/145, Loss: 0.1144
Epoch 5/10, Batch 140/145, Loss: 0.2085
Epoch 5/10, Train Loss: 0.2444, Valid Loss: 0.2482
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1556
Epoch 6/10, Batch 20/145, Loss: 0.3716
Epoch 6/10, Batch 30/145, Loss: 0.3278
Epoch 6/10, Batch 40/145, Loss: 0.1413
Epoch 6/10, Batch 50/145, Loss: 0.2173
Epoch 6/10, Batch 60/145, Loss: 0.1295
Epoch 6/10, Batch 70/145, Loss: 0.1348
Epoch 6/10, Batch 80/145, Loss: 0.2168
Epoch 6/10, Batch 90/145, Loss: 0.4317
Epoch 6/10, Batch 100/145, Loss: 0.2807
Epoch 6/10, Batch 110/145, Loss: 0.1804
Epoch 6/10, Batch 120/145, Loss: 0.2054
Epoch 6/10, Batch 130/145, Loss: 0.1848
Epoch 6/10, Batch 140/145, Loss: 0.1443
Epoch 6/10, Train Loss: 0.2340, Valid Loss: 0.2414
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1513
Epoch 7/10, Batch 20/145, Loss: 0.4586
Epoch 7/10, Batch 30/145, Loss: 0.3452
Epoch 7/10, Batch 40/145, Loss: 0.2874
Epoch 7/10, Batch 50/145, Loss: 0.2063
Epoch 7/10, Batch 60/145, Loss: 0.1065
Epoch 7/10, Batch 70/145, Loss: 0.1590
Epoch 7/10, Batch 80/145, Loss: 0.3937
Epoch 7/10, Batch 90/145, Loss: 0.0933
Epoch 7/10, Batch 100/145, Loss: 0.1689
Epoch 7/10, Batch 110/145, Loss: 0.1612
Epoch 7/10, Batch 120/145, Loss: 0.2588
Epoch 7/10, Batch 130/145, Loss: 0.2114
Epoch 7/10, Batch 140/145, Loss: 0.3145
Epoch 7/10, Train Loss: 0.2184, Valid Loss: 0.2264
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1325
Epoch 8/10, Batch 20/145, Loss: 0.3956
Epoch 8/10, Batch 30/145, Loss: 0.2623
Epoch 8/10, Batch 40/145, Loss: 0.2295
Epoch 8/10, Batch 50/145, Loss: 0.2793
Epoch 8/10, Batch 60/145, Loss: 0.2331
Epoch 8/10, Batch 70/145, Loss: 0.2934
Epoch 8/10, Batch 80/145, Loss: 0.2170
Epoch 8/10, Batch 90/145, Loss: 0.3261
Epoch 8/10, Batch 100/145, Loss: 0.2277
Epoch 8/10, Batch 110/145, Loss: 0.1370
Epoch 8/10, Batch 120/145, Loss: 0.1349
Epoch 8/10, Batch 130/145, Loss: 0.2210
Epoch 8/10, Batch 140/145, Loss: 0.1545
Epoch 8/10, Train Loss: 0.2122, Valid Loss: 0.2260
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2975
Epoch 9/10, Batch 20/145, Loss: 0.1922
Epoch 9/10, Batch 30/145, Loss: 0.1245
Epoch 9/10, Batch 40/145, Loss: 0.1745
Epoch 9/10, Batch 50/145, Loss: 0.1024
Epoch 9/10, Batch 60/145, Loss: 0.3409
Epoch 9/10, Batch 70/145, Loss: 0.0953
Epoch 9/10, Batch 80/145, Loss: 0.0870
Epoch 9/10, Batch 90/145, Loss: 0.1526
Epoch 9/10, Batch 100/145, Loss: 0.2216
Epoch 9/10, Batch 110/145, Loss: 0.1972
Epoch 9/10, Batch 120/145, Loss: 0.1385
Epoch 9/10, Batch 130/145, Loss: 0.1550
Epoch 9/10, Batch 140/145, Loss: 0.2371
Epoch 9/10, Train Loss: 0.2038, Valid Loss: 0.2290
Epoch 10/10, Batch 10/145, Loss: 0.2045
Epoch 10/10, Batch 20/145, Loss: 0.1701
Epoch 10/10, Batch 30/145, Loss: 0.2016
Epoch 10/10, Batch 40/145, Loss: 0.0893
Epoch 10/10, Batch 50/145, Loss: 0.1413
Epoch 10/10, Batch 60/145, Loss: 0.1487
Epoch 10/10, Batch 70/145, Loss: 0.1595
Epoch 10/10, Batch 80/145, Loss: 0.1341
Epoch 10/10, Batch 90/145, Loss: 0.1774
Epoch 10/10, Batch 100/145, Loss: 0.1632
Epoch 10/10, Batch 110/145, Loss: 0.1802
Epoch 10/10, Batch 120/145, Loss: 0.1770
Epoch 10/10, Batch 130/145, Loss: 0.2488
Epoch 10/10, Batch 140/145, Loss: 0.1640
Epoch 10/10, Train Loss: 0.1892, Valid Loss: 0.2196
Model saved!
Accuracy: 0.9194
Precision: 0.9177
Recall: 0.9194
F1-score: 0.9175
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3852
Epoch 1/10, Batch 20/145, Loss: 0.9019
Epoch 1/10, Batch 30/145, Loss: 0.9057
Epoch 1/10, Batch 40/145, Loss: 0.8323
Epoch 1/10, Batch 50/145, Loss: 0.7237
Epoch 1/10, Batch 60/145, Loss: 0.5523
Epoch 1/10, Batch 70/145, Loss: 0.4458
Epoch 1/10, Batch 80/145, Loss: 0.5555
Epoch 1/10, Batch 90/145, Loss: 0.3902
Epoch 1/10, Batch 100/145, Loss: 0.5170
Epoch 1/10, Batch 110/145, Loss: 0.3922
Epoch 1/10, Batch 120/145, Loss: 0.5480
Epoch 1/10, Batch 130/145, Loss: 0.4509
Epoch 1/10, Batch 140/145, Loss: 0.3074
Epoch 1/10, Train Loss: 0.6729, Valid Loss: 0.3912
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3015
Epoch 2/10, Batch 20/145, Loss: 0.2692
Epoch 2/10, Batch 30/145, Loss: 0.2866
Epoch 2/10, Batch 40/145, Loss: 0.3870
Epoch 2/10, Batch 50/145, Loss: 0.4041
Epoch 2/10, Batch 60/145, Loss: 0.3831
Epoch 2/10, Batch 70/145, Loss: 0.3358
Epoch 2/10, Batch 80/145, Loss: 0.2102
Epoch 2/10, Batch 90/145, Loss: 0.2617
Epoch 2/10, Batch 100/145, Loss: 0.2902
Epoch 2/10, Batch 110/145, Loss: 0.3054
Epoch 2/10, Batch 120/145, Loss: 0.4049
Epoch 2/10, Batch 130/145, Loss: 0.2402
Epoch 2/10, Batch 140/145, Loss: 0.2459
Epoch 2/10, Train Loss: 0.3537, Valid Loss: 0.3087
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2648
Epoch 3/10, Batch 20/145, Loss: 0.3233
Epoch 3/10, Batch 30/145, Loss: 0.4092
Epoch 3/10, Batch 40/145, Loss: 0.1774
Epoch 3/10, Batch 50/145, Loss: 0.2448
Epoch 3/10, Batch 60/145, Loss: 0.3879
Epoch 3/10, Batch 70/145, Loss: 0.4949
Epoch 3/10, Batch 80/145, Loss: 0.2504
Epoch 3/10, Batch 90/145, Loss: 0.3072
Epoch 3/10, Batch 100/145, Loss: 0.2778
Epoch 3/10, Batch 110/145, Loss: 0.1749
Epoch 3/10, Batch 120/145, Loss: 0.1955
Epoch 3/10, Batch 130/145, Loss: 0.4087
Epoch 3/10, Batch 140/145, Loss: 0.2033
Epoch 3/10, Train Loss: 0.2903, Valid Loss: 0.2787
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2722
Epoch 4/10, Batch 20/145, Loss: 0.2100
Epoch 4/10, Batch 30/145, Loss: 0.1952
Epoch 4/10, Batch 40/145, Loss: 0.1771
Epoch 4/10, Batch 50/145, Loss: 0.1253
Epoch 4/10, Batch 60/145, Loss: 0.3096
Epoch 4/10, Batch 70/145, Loss: 0.3656
Epoch 4/10, Batch 80/145, Loss: 0.0976
Epoch 4/10, Batch 90/145, Loss: 0.3261
Epoch 4/10, Batch 100/145, Loss: 0.3061
Epoch 4/10, Batch 110/145, Loss: 0.1157
Epoch 4/10, Batch 120/145, Loss: 0.2411
Epoch 4/10, Batch 130/145, Loss: 0.2992
Epoch 4/10, Batch 140/145, Loss: 0.1645
Epoch 4/10, Train Loss: 0.2559, Valid Loss: 0.2621
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1439
Epoch 5/10, Batch 20/145, Loss: 0.1056
Epoch 5/10, Batch 30/145, Loss: 0.1771
Epoch 5/10, Batch 40/145, Loss: 0.1581
Epoch 5/10, Batch 50/145, Loss: 0.1300
Epoch 5/10, Batch 60/145, Loss: 0.2520
Epoch 5/10, Batch 70/145, Loss: 0.2247
Epoch 5/10, Batch 80/145, Loss: 0.2576
Epoch 5/10, Batch 90/145, Loss: 0.2002
Epoch 5/10, Batch 100/145, Loss: 0.1342
Epoch 5/10, Batch 110/145, Loss: 0.1491
Epoch 5/10, Batch 120/145, Loss: 0.2781
Epoch 5/10, Batch 130/145, Loss: 0.3320
Epoch 5/10, Batch 140/145, Loss: 0.1871
Epoch 5/10, Train Loss: 0.2409, Valid Loss: 0.2518
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2113
Epoch 6/10, Batch 20/145, Loss: 0.3060
Epoch 6/10, Batch 30/145, Loss: 0.3387
Epoch 6/10, Batch 40/145, Loss: 0.1906
Epoch 6/10, Batch 50/145, Loss: 0.2655
Epoch 6/10, Batch 60/145, Loss: 0.2247
Epoch 6/10, Batch 70/145, Loss: 0.1183
Epoch 6/10, Batch 80/145, Loss: 0.1173
Epoch 6/10, Batch 90/145, Loss: 0.2447
Epoch 6/10, Batch 100/145, Loss: 0.2182
Epoch 6/10, Batch 110/145, Loss: 0.2362
Epoch 6/10, Batch 120/145, Loss: 0.5634
Epoch 6/10, Batch 130/145, Loss: 0.1221
Epoch 6/10, Batch 140/145, Loss: 0.1659
Epoch 6/10, Train Loss: 0.2308, Valid Loss: 0.2448
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3736
Epoch 7/10, Batch 20/145, Loss: 0.2884
Epoch 7/10, Batch 30/145, Loss: 0.2414
Epoch 7/10, Batch 40/145, Loss: 0.3152
Epoch 7/10, Batch 50/145, Loss: 0.1851
Epoch 7/10, Batch 60/145, Loss: 0.2758
Epoch 7/10, Batch 70/145, Loss: 0.1784
Epoch 7/10, Batch 80/145, Loss: 0.3575
Epoch 7/10, Batch 90/145, Loss: 0.1453
Epoch 7/10, Batch 100/145, Loss: 0.1254
Epoch 7/10, Batch 110/145, Loss: 0.1588
Epoch 7/10, Batch 120/145, Loss: 0.2542
Epoch 7/10, Batch 130/145, Loss: 0.0642
Epoch 7/10, Batch 140/145, Loss: 0.2257
Epoch 7/10, Train Loss: 0.2116, Valid Loss: 0.2394
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1614
Epoch 8/10, Batch 20/145, Loss: 0.1506
Epoch 8/10, Batch 30/145, Loss: 0.2704
Epoch 8/10, Batch 40/145, Loss: 0.3777
Epoch 8/10, Batch 50/145, Loss: 0.3507
Epoch 8/10, Batch 60/145, Loss: 0.2207
Epoch 8/10, Batch 70/145, Loss: 0.1112
Epoch 8/10, Batch 80/145, Loss: 0.3316
Epoch 8/10, Batch 90/145, Loss: 0.2735
Epoch 8/10, Batch 100/145, Loss: 0.1812
Epoch 8/10, Batch 110/145, Loss: 0.2721
Epoch 8/10, Batch 120/145, Loss: 0.1741
Epoch 8/10, Batch 130/145, Loss: 0.1028
Epoch 8/10, Batch 140/145, Loss: 0.1525
Epoch 8/10, Train Loss: 0.2107, Valid Loss: 0.2361
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2778
Epoch 9/10, Batch 20/145, Loss: 0.1403
Epoch 9/10, Batch 30/145, Loss: 0.1324
Epoch 9/10, Batch 40/145, Loss: 0.1005
Epoch 9/10, Batch 50/145, Loss: 0.1319
Epoch 9/10, Batch 60/145, Loss: 0.1965
Epoch 9/10, Batch 70/145, Loss: 0.1989
Epoch 9/10, Batch 80/145, Loss: 0.1140
Epoch 9/10, Batch 90/145, Loss: 0.1810
Epoch 9/10, Batch 100/145, Loss: 0.1343
Epoch 9/10, Batch 110/145, Loss: 0.4244
Epoch 9/10, Batch 120/145, Loss: 0.3503
Epoch 9/10, Batch 130/145, Loss: 0.2434
Epoch 9/10, Batch 140/145, Loss: 0.2264
Epoch 9/10, Train Loss: 0.1975, Valid Loss: 0.2349
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1171
Epoch 10/10, Batch 20/145, Loss: 0.1536
Epoch 10/10, Batch 30/145, Loss: 0.0896
Epoch 10/10, Batch 40/145, Loss: 0.1263
Epoch 10/10, Batch 50/145, Loss: 0.2349
Epoch 10/10, Batch 60/145, Loss: 0.2284
Epoch 10/10, Batch 70/145, Loss: 0.1382
Epoch 10/10, Batch 80/145, Loss: 0.0847
Epoch 10/10, Batch 90/145, Loss: 0.1406
Epoch 10/10, Batch 100/145, Loss: 0.1920
Epoch 10/10, Batch 110/145, Loss: 0.1334
Epoch 10/10, Batch 120/145, Loss: 0.2083
Epoch 10/10, Batch 130/145, Loss: 0.2269
Epoch 10/10, Batch 140/145, Loss: 0.1530
Epoch 10/10, Train Loss: 0.1909, Valid Loss: 0.2269
Model saved!
Accuracy: 0.9194
Precision: 0.9174
Recall: 0.9194
F1-score: 0.9181
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4026
Epoch 1/10, Batch 20/145, Loss: 0.9326
Epoch 1/10, Batch 30/145, Loss: 0.9414
Epoch 1/10, Batch 40/145, Loss: 0.7584
Epoch 1/10, Batch 50/145, Loss: 0.6827
Epoch 1/10, Batch 60/145, Loss: 0.6103
Epoch 1/10, Batch 70/145, Loss: 0.4158
Epoch 1/10, Batch 80/145, Loss: 0.6564
Epoch 1/10, Batch 90/145, Loss: 0.5090
Epoch 1/10, Batch 100/145, Loss: 0.4992
Epoch 1/10, Batch 110/145, Loss: 0.5539
Epoch 1/10, Batch 120/145, Loss: 0.5853
Epoch 1/10, Batch 130/145, Loss: 0.5222
Epoch 1/10, Batch 140/145, Loss: 0.3737
Epoch 1/10, Train Loss: 0.6723, Valid Loss: 0.3770
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3409
Epoch 2/10, Batch 20/145, Loss: 0.4377
Epoch 2/10, Batch 30/145, Loss: 0.2825
Epoch 2/10, Batch 40/145, Loss: 0.3641
Epoch 2/10, Batch 50/145, Loss: 0.4959
Epoch 2/10, Batch 60/145, Loss: 0.2542
Epoch 2/10, Batch 70/145, Loss: 0.3061
Epoch 2/10, Batch 80/145, Loss: 0.3007
Epoch 2/10, Batch 90/145, Loss: 0.2762
Epoch 2/10, Batch 100/145, Loss: 0.3064
Epoch 2/10, Batch 110/145, Loss: 0.2443
Epoch 2/10, Batch 120/145, Loss: 0.2384
Epoch 2/10, Batch 130/145, Loss: 0.2479
Epoch 2/10, Batch 140/145, Loss: 0.3170
Epoch 2/10, Train Loss: 0.3528, Valid Loss: 0.2984
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2495
Epoch 3/10, Batch 20/145, Loss: 0.2975
Epoch 3/10, Batch 30/145, Loss: 0.3217
Epoch 3/10, Batch 40/145, Loss: 0.1754
Epoch 3/10, Batch 50/145, Loss: 0.3354
Epoch 3/10, Batch 60/145, Loss: 0.3907
Epoch 3/10, Batch 70/145, Loss: 0.3049
Epoch 3/10, Batch 80/145, Loss: 0.3290
Epoch 3/10, Batch 90/145, Loss: 0.1548
Epoch 3/10, Batch 100/145, Loss: 0.2709
Epoch 3/10, Batch 110/145, Loss: 0.4327
Epoch 3/10, Batch 120/145, Loss: 0.2502
Epoch 3/10, Batch 130/145, Loss: 0.2913
Epoch 3/10, Batch 140/145, Loss: 0.2672
Epoch 3/10, Train Loss: 0.2885, Valid Loss: 0.2656
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3532
Epoch 4/10, Batch 20/145, Loss: 0.4169
Epoch 4/10, Batch 30/145, Loss: 0.1926
Epoch 4/10, Batch 40/145, Loss: 0.3246
Epoch 4/10, Batch 50/145, Loss: 0.2201
Epoch 4/10, Batch 60/145, Loss: 0.1978
Epoch 4/10, Batch 70/145, Loss: 0.1962
Epoch 4/10, Batch 80/145, Loss: 0.2276
Epoch 4/10, Batch 90/145, Loss: 0.3435
Epoch 4/10, Batch 100/145, Loss: 0.4015
Epoch 4/10, Batch 110/145, Loss: 0.2267
Epoch 4/10, Batch 120/145, Loss: 0.2100
Epoch 4/10, Batch 130/145, Loss: 0.2712
Epoch 4/10, Batch 140/145, Loss: 0.2588
Epoch 4/10, Train Loss: 0.2586, Valid Loss: 0.2533
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1822
Epoch 5/10, Batch 20/145, Loss: 0.1935
Epoch 5/10, Batch 30/145, Loss: 0.1844
Epoch 5/10, Batch 40/145, Loss: 0.1174
Epoch 5/10, Batch 50/145, Loss: 0.2690
Epoch 5/10, Batch 60/145, Loss: 0.1439
Epoch 5/10, Batch 70/145, Loss: 0.2739
Epoch 5/10, Batch 80/145, Loss: 0.1551
Epoch 5/10, Batch 90/145, Loss: 0.2499
Epoch 5/10, Batch 100/145, Loss: 0.1509
Epoch 5/10, Batch 110/145, Loss: 0.1472
Epoch 5/10, Batch 120/145, Loss: 0.2659
Epoch 5/10, Batch 130/145, Loss: 0.1775
Epoch 5/10, Batch 140/145, Loss: 0.2109
Epoch 5/10, Train Loss: 0.2492, Valid Loss: 0.2467
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1532
Epoch 6/10, Batch 20/145, Loss: 0.6765
Epoch 6/10, Batch 30/145, Loss: 0.2435
Epoch 6/10, Batch 40/145, Loss: 0.1257
Epoch 6/10, Batch 50/145, Loss: 0.3075
Epoch 6/10, Batch 60/145, Loss: 0.2860
Epoch 6/10, Batch 70/145, Loss: 0.1002
Epoch 6/10, Batch 80/145, Loss: 0.3043
Epoch 6/10, Batch 90/145, Loss: 0.2415
Epoch 6/10, Batch 100/145, Loss: 0.2265
Epoch 6/10, Batch 110/145, Loss: 0.2118
Epoch 6/10, Batch 120/145, Loss: 0.2172
Epoch 6/10, Batch 130/145, Loss: 0.1865
Epoch 6/10, Batch 140/145, Loss: 0.1083
Epoch 6/10, Train Loss: 0.2325, Valid Loss: 0.2383
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3039
Epoch 7/10, Batch 20/145, Loss: 0.1697
Epoch 7/10, Batch 30/145, Loss: 0.2359
Epoch 7/10, Batch 40/145, Loss: 0.4076
Epoch 7/10, Batch 50/145, Loss: 0.1585
Epoch 7/10, Batch 60/145, Loss: 0.1362
Epoch 7/10, Batch 70/145, Loss: 0.2865
Epoch 7/10, Batch 80/145, Loss: 0.4681
Epoch 7/10, Batch 90/145, Loss: 0.1682
Epoch 7/10, Batch 100/145, Loss: 0.1735
Epoch 7/10, Batch 110/145, Loss: 0.2753
Epoch 7/10, Batch 120/145, Loss: 0.1088
Epoch 7/10, Batch 130/145, Loss: 0.1366
Epoch 7/10, Batch 140/145, Loss: 0.1995
Epoch 7/10, Train Loss: 0.2168, Valid Loss: 0.2313
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2879
Epoch 8/10, Batch 20/145, Loss: 0.1795
Epoch 8/10, Batch 30/145, Loss: 0.2645
Epoch 8/10, Batch 40/145, Loss: 0.1274
Epoch 8/10, Batch 50/145, Loss: 0.2464
Epoch 8/10, Batch 60/145, Loss: 0.2934
Epoch 8/10, Batch 70/145, Loss: 0.1919
Epoch 8/10, Batch 80/145, Loss: 0.2741
Epoch 8/10, Batch 90/145, Loss: 0.3981
Epoch 8/10, Batch 100/145, Loss: 0.1608
Epoch 8/10, Batch 110/145, Loss: 0.1794
Epoch 8/10, Batch 120/145, Loss: 0.1648
Epoch 8/10, Batch 130/145, Loss: 0.2093
Epoch 8/10, Batch 140/145, Loss: 0.2739
Epoch 8/10, Train Loss: 0.2085, Valid Loss: 0.2262
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2111
Epoch 9/10, Batch 20/145, Loss: 0.1456
Epoch 9/10, Batch 30/145, Loss: 0.1059
Epoch 9/10, Batch 40/145, Loss: 0.2650
Epoch 9/10, Batch 50/145, Loss: 0.0786
Epoch 9/10, Batch 60/145, Loss: 0.2580
Epoch 9/10, Batch 70/145, Loss: 0.1244
Epoch 9/10, Batch 80/145, Loss: 0.1021
Epoch 9/10, Batch 90/145, Loss: 0.2029
Epoch 9/10, Batch 100/145, Loss: 0.1437
Epoch 9/10, Batch 110/145, Loss: 0.1768
Epoch 9/10, Batch 120/145, Loss: 0.1620
Epoch 9/10, Batch 130/145, Loss: 0.4408
Epoch 9/10, Batch 140/145, Loss: 0.4026
Epoch 9/10, Train Loss: 0.2029, Valid Loss: 0.2224
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1188
Epoch 10/10, Batch 20/145, Loss: 0.1374
Epoch 10/10, Batch 30/145, Loss: 0.1146
Epoch 10/10, Batch 40/145, Loss: 0.0660
Epoch 10/10, Batch 50/145, Loss: 0.2008
Epoch 10/10, Batch 60/145, Loss: 0.1339
Epoch 10/10, Batch 70/145, Loss: 0.3379
Epoch 10/10, Batch 80/145, Loss: 0.2484
Epoch 10/10, Batch 90/145, Loss: 0.1481
Epoch 10/10, Batch 100/145, Loss: 0.2233
Epoch 10/10, Batch 110/145, Loss: 0.1872
Epoch 10/10, Batch 120/145, Loss: 0.1645
Epoch 10/10, Batch 130/145, Loss: 0.1405
Epoch 10/10, Batch 140/145, Loss: 0.1734
Epoch 10/10, Train Loss: 0.1882, Valid Loss: 0.2200
Model saved!
Accuracy: 0.9252
Precision: 0.9231
Recall: 0.9252
F1-score: 0.9238
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3734
Epoch 1/10, Batch 20/145, Loss: 0.9443
Epoch 1/10, Batch 30/145, Loss: 0.9091
Epoch 1/10, Batch 40/145, Loss: 0.8885
Epoch 1/10, Batch 50/145, Loss: 0.7054
Epoch 1/10, Batch 60/145, Loss: 0.6797
Epoch 1/10, Batch 70/145, Loss: 0.5107
Epoch 1/10, Batch 80/145, Loss: 0.6229
Epoch 1/10, Batch 90/145, Loss: 0.4776
Epoch 1/10, Batch 100/145, Loss: 0.5306
Epoch 1/10, Batch 110/145, Loss: 0.3852
Epoch 1/10, Batch 120/145, Loss: 0.6161
Epoch 1/10, Batch 130/145, Loss: 0.5241
Epoch 1/10, Batch 140/145, Loss: 0.4352
Epoch 1/10, Train Loss: 0.6767, Valid Loss: 0.3696
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2930
Epoch 2/10, Batch 20/145, Loss: 0.4808
Epoch 2/10, Batch 30/145, Loss: 0.3543
Epoch 2/10, Batch 40/145, Loss: 0.3783
Epoch 2/10, Batch 50/145, Loss: 0.2761
Epoch 2/10, Batch 60/145, Loss: 0.2465
Epoch 2/10, Batch 70/145, Loss: 0.2864
Epoch 2/10, Batch 80/145, Loss: 0.3030
Epoch 2/10, Batch 90/145, Loss: 0.2970
Epoch 2/10, Batch 100/145, Loss: 0.2115
Epoch 2/10, Batch 110/145, Loss: 0.4094
Epoch 2/10, Batch 120/145, Loss: 0.3410
Epoch 2/10, Batch 130/145, Loss: 0.3109
Epoch 2/10, Batch 140/145, Loss: 0.6095
Epoch 2/10, Train Loss: 0.3491, Valid Loss: 0.2912
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3183
Epoch 3/10, Batch 20/145, Loss: 0.2213
Epoch 3/10, Batch 30/145, Loss: 0.3959
Epoch 3/10, Batch 40/145, Loss: 0.2315
Epoch 3/10, Batch 50/145, Loss: 0.1540
Epoch 3/10, Batch 60/145, Loss: 0.4331
Epoch 3/10, Batch 70/145, Loss: 0.4712
Epoch 3/10, Batch 80/145, Loss: 0.2740
Epoch 3/10, Batch 90/145, Loss: 0.2898
Epoch 3/10, Batch 100/145, Loss: 0.2846
Epoch 3/10, Batch 110/145, Loss: 0.2546
Epoch 3/10, Batch 120/145, Loss: 0.2182
Epoch 3/10, Batch 130/145, Loss: 0.1905
Epoch 3/10, Batch 140/145, Loss: 0.2073
Epoch 3/10, Train Loss: 0.2885, Valid Loss: 0.2625
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1974
Epoch 4/10, Batch 20/145, Loss: 0.2200
Epoch 4/10, Batch 30/145, Loss: 0.4484
Epoch 4/10, Batch 40/145, Loss: 0.1599
Epoch 4/10, Batch 50/145, Loss: 0.3041
Epoch 4/10, Batch 60/145, Loss: 0.2197
Epoch 4/10, Batch 70/145, Loss: 0.1002
Epoch 4/10, Batch 80/145, Loss: 0.0949
Epoch 4/10, Batch 90/145, Loss: 0.1745
Epoch 4/10, Batch 100/145, Loss: 0.4152
Epoch 4/10, Batch 110/145, Loss: 0.0821
Epoch 4/10, Batch 120/145, Loss: 0.2211
Epoch 4/10, Batch 130/145, Loss: 0.2027
Epoch 4/10, Batch 140/145, Loss: 0.1309
Epoch 4/10, Train Loss: 0.2572, Valid Loss: 0.2492
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2612
Epoch 5/10, Batch 20/145, Loss: 0.2375
Epoch 5/10, Batch 30/145, Loss: 0.2801
Epoch 5/10, Batch 40/145, Loss: 0.2008
Epoch 5/10, Batch 50/145, Loss: 0.3352
Epoch 5/10, Batch 60/145, Loss: 0.1851
Epoch 5/10, Batch 70/145, Loss: 0.1626
Epoch 5/10, Batch 80/145, Loss: 0.2585
Epoch 5/10, Batch 90/145, Loss: 0.2600
Epoch 5/10, Batch 100/145, Loss: 0.2070
Epoch 5/10, Batch 110/145, Loss: 0.2600
Epoch 5/10, Batch 120/145, Loss: 0.3174
Epoch 5/10, Batch 130/145, Loss: 0.1614
Epoch 5/10, Batch 140/145, Loss: 0.2673
Epoch 5/10, Train Loss: 0.2460, Valid Loss: 0.2362
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1895
Epoch 6/10, Batch 20/145, Loss: 0.4537
Epoch 6/10, Batch 30/145, Loss: 0.3011
Epoch 6/10, Batch 40/145, Loss: 0.1906
Epoch 6/10, Batch 50/145, Loss: 0.3900
Epoch 6/10, Batch 60/145, Loss: 0.1394
Epoch 6/10, Batch 70/145, Loss: 0.1171
Epoch 6/10, Batch 80/145, Loss: 0.2606
Epoch 6/10, Batch 90/145, Loss: 0.2232
Epoch 6/10, Batch 100/145, Loss: 0.3402
Epoch 6/10, Batch 110/145, Loss: 0.2077
Epoch 6/10, Batch 120/145, Loss: 0.2320
Epoch 6/10, Batch 130/145, Loss: 0.2270
Epoch 6/10, Batch 140/145, Loss: 0.1872
Epoch 6/10, Train Loss: 0.2251, Valid Loss: 0.2267
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1478
Epoch 7/10, Batch 20/145, Loss: 0.2215
Epoch 7/10, Batch 30/145, Loss: 0.2090
Epoch 7/10, Batch 40/145, Loss: 0.5142
Epoch 7/10, Batch 50/145, Loss: 0.1481
Epoch 7/10, Batch 60/145, Loss: 0.0730
Epoch 7/10, Batch 70/145, Loss: 0.1369
Epoch 7/10, Batch 80/145, Loss: 0.3286
Epoch 7/10, Batch 90/145, Loss: 0.2005
Epoch 7/10, Batch 100/145, Loss: 0.2232
Epoch 7/10, Batch 110/145, Loss: 0.1841
Epoch 7/10, Batch 120/145, Loss: 0.1050
Epoch 7/10, Batch 130/145, Loss: 0.2012
Epoch 7/10, Batch 140/145, Loss: 0.2737
Epoch 7/10, Train Loss: 0.2119, Valid Loss: 0.2291
Epoch 8/10, Batch 10/145, Loss: 0.0733
Epoch 8/10, Batch 20/145, Loss: 0.1358
Epoch 8/10, Batch 30/145, Loss: 0.1287
Epoch 8/10, Batch 40/145, Loss: 0.0833
Epoch 8/10, Batch 50/145, Loss: 0.2126
Epoch 8/10, Batch 60/145, Loss: 0.1972
Epoch 8/10, Batch 70/145, Loss: 0.2621
Epoch 8/10, Batch 80/145, Loss: 0.1394
Epoch 8/10, Batch 90/145, Loss: 0.5759
Epoch 8/10, Batch 100/145, Loss: 0.2763
Epoch 8/10, Batch 110/145, Loss: 0.1733
Epoch 8/10, Batch 120/145, Loss: 0.2079
Epoch 8/10, Batch 130/145, Loss: 0.1908
Epoch 8/10, Batch 140/145, Loss: 0.2105
Epoch 8/10, Train Loss: 0.2050, Valid Loss: 0.2207
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3420
Epoch 9/10, Batch 20/145, Loss: 0.1892
Epoch 9/10, Batch 30/145, Loss: 0.2496
Epoch 9/10, Batch 40/145, Loss: 0.3084
Epoch 9/10, Batch 50/145, Loss: 0.2343
Epoch 9/10, Batch 60/145, Loss: 0.2608
Epoch 9/10, Batch 70/145, Loss: 0.1849
Epoch 9/10, Batch 80/145, Loss: 0.1716
Epoch 9/10, Batch 90/145, Loss: 0.2897
Epoch 9/10, Batch 100/145, Loss: 0.2215
Epoch 9/10, Batch 110/145, Loss: 0.2612
Epoch 9/10, Batch 120/145, Loss: 0.0853
Epoch 9/10, Batch 130/145, Loss: 0.3251
Epoch 9/10, Batch 140/145, Loss: 0.1142
Epoch 9/10, Train Loss: 0.2003, Valid Loss: 0.2163
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1009
Epoch 10/10, Batch 20/145, Loss: 0.1952
Epoch 10/10, Batch 30/145, Loss: 0.1405
Epoch 10/10, Batch 40/145, Loss: 0.1797
Epoch 10/10, Batch 50/145, Loss: 0.1799
Epoch 10/10, Batch 60/145, Loss: 0.2593
Epoch 10/10, Batch 70/145, Loss: 0.1728
Epoch 10/10, Batch 80/145, Loss: 0.1437
Epoch 10/10, Batch 90/145, Loss: 0.0773
Epoch 10/10, Batch 100/145, Loss: 0.1747
Epoch 10/10, Batch 110/145, Loss: 0.2341
Epoch 10/10, Batch 120/145, Loss: 0.2522
Epoch 10/10, Batch 130/145, Loss: 0.0576
Epoch 10/10, Batch 140/145, Loss: 0.1517
Epoch 10/10, Train Loss: 0.1859, Valid Loss: 0.2234
Accuracy: 0.9147
Precision: 0.9124
Recall: 0.9147
F1-score: 0.9132
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4028
Epoch 1/10, Batch 20/145, Loss: 0.9591
Epoch 1/10, Batch 30/145, Loss: 0.8897
Epoch 1/10, Batch 40/145, Loss: 0.7574
Epoch 1/10, Batch 50/145, Loss: 0.8268
Epoch 1/10, Batch 60/145, Loss: 0.5943
Epoch 1/10, Batch 70/145, Loss: 0.4148
Epoch 1/10, Batch 80/145, Loss: 0.5091
Epoch 1/10, Batch 90/145, Loss: 0.4876
Epoch 1/10, Batch 100/145, Loss: 0.5234
Epoch 1/10, Batch 110/145, Loss: 0.3863
Epoch 1/10, Batch 120/145, Loss: 0.4911
Epoch 1/10, Batch 130/145, Loss: 0.5445
Epoch 1/10, Batch 140/145, Loss: 0.3433
Epoch 1/10, Train Loss: 0.6789, Valid Loss: 0.3965
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3548
Epoch 2/10, Batch 20/145, Loss: 0.3870
Epoch 2/10, Batch 30/145, Loss: 0.3789
Epoch 2/10, Batch 40/145, Loss: 0.4745
Epoch 2/10, Batch 50/145, Loss: 0.4432
Epoch 2/10, Batch 60/145, Loss: 0.4132
Epoch 2/10, Batch 70/145, Loss: 0.2902
Epoch 2/10, Batch 80/145, Loss: 0.3659
Epoch 2/10, Batch 90/145, Loss: 0.3983
Epoch 2/10, Batch 100/145, Loss: 0.2946
Epoch 2/10, Batch 110/145, Loss: 0.4543
Epoch 2/10, Batch 120/145, Loss: 0.5034
Epoch 2/10, Batch 130/145, Loss: 0.2903
Epoch 2/10, Batch 140/145, Loss: 0.2460
Epoch 2/10, Train Loss: 0.3493, Valid Loss: 0.3103
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1677
Epoch 3/10, Batch 20/145, Loss: 0.3466
Epoch 3/10, Batch 30/145, Loss: 0.3702
Epoch 3/10, Batch 40/145, Loss: 0.3211
Epoch 3/10, Batch 50/145, Loss: 0.2313
Epoch 3/10, Batch 60/145, Loss: 0.2746
Epoch 3/10, Batch 70/145, Loss: 0.3473
Epoch 3/10, Batch 80/145, Loss: 0.2866
Epoch 3/10, Batch 90/145, Loss: 0.1799
Epoch 3/10, Batch 100/145, Loss: 0.2802
Epoch 3/10, Batch 110/145, Loss: 0.1561
Epoch 3/10, Batch 120/145, Loss: 0.1616
Epoch 3/10, Batch 130/145, Loss: 0.3461
Epoch 3/10, Batch 140/145, Loss: 0.2470
Epoch 3/10, Train Loss: 0.2877, Valid Loss: 0.2793
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3605
Epoch 4/10, Batch 20/145, Loss: 0.3126
Epoch 4/10, Batch 30/145, Loss: 0.2904
Epoch 4/10, Batch 40/145, Loss: 0.1283
Epoch 4/10, Batch 50/145, Loss: 0.3133
Epoch 4/10, Batch 60/145, Loss: 0.2300
Epoch 4/10, Batch 70/145, Loss: 0.2476
Epoch 4/10, Batch 80/145, Loss: 0.1109
Epoch 4/10, Batch 90/145, Loss: 0.2620
Epoch 4/10, Batch 100/145, Loss: 0.2035
Epoch 4/10, Batch 110/145, Loss: 0.2465
Epoch 4/10, Batch 120/145, Loss: 0.3082
Epoch 4/10, Batch 130/145, Loss: 0.2070
Epoch 4/10, Batch 140/145, Loss: 0.1483
Epoch 4/10, Train Loss: 0.2607, Valid Loss: 0.2656
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2976
Epoch 5/10, Batch 20/145, Loss: 0.2776
Epoch 5/10, Batch 30/145, Loss: 0.2366
Epoch 5/10, Batch 40/145, Loss: 0.1721
Epoch 5/10, Batch 50/145, Loss: 0.2014
Epoch 5/10, Batch 60/145, Loss: 0.1952
Epoch 5/10, Batch 70/145, Loss: 0.2082
Epoch 5/10, Batch 80/145, Loss: 0.1140
Epoch 5/10, Batch 90/145, Loss: 0.3579
Epoch 5/10, Batch 100/145, Loss: 0.1684
Epoch 5/10, Batch 110/145, Loss: 0.1021
Epoch 5/10, Batch 120/145, Loss: 0.3811
Epoch 5/10, Batch 130/145, Loss: 0.2422
Epoch 5/10, Batch 140/145, Loss: 0.2013
Epoch 5/10, Train Loss: 0.2394, Valid Loss: 0.2580
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1778
Epoch 6/10, Batch 20/145, Loss: 0.3312
Epoch 6/10, Batch 30/145, Loss: 0.3888
Epoch 6/10, Batch 40/145, Loss: 0.3343
Epoch 6/10, Batch 50/145, Loss: 0.3522
Epoch 6/10, Batch 60/145, Loss: 0.2100
Epoch 6/10, Batch 70/145, Loss: 0.1377
Epoch 6/10, Batch 80/145, Loss: 0.1312
Epoch 6/10, Batch 90/145, Loss: 0.3064
Epoch 6/10, Batch 100/145, Loss: 0.2596
Epoch 6/10, Batch 110/145, Loss: 0.3379
Epoch 6/10, Batch 120/145, Loss: 0.2367
Epoch 6/10, Batch 130/145, Loss: 0.1950
Epoch 6/10, Batch 140/145, Loss: 0.1485
Epoch 6/10, Train Loss: 0.2268, Valid Loss: 0.2451
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2211
Epoch 7/10, Batch 20/145, Loss: 0.3420
Epoch 7/10, Batch 30/145, Loss: 0.1077
Epoch 7/10, Batch 40/145, Loss: 0.4754
Epoch 7/10, Batch 50/145, Loss: 0.1382
Epoch 7/10, Batch 60/145, Loss: 0.3077
Epoch 7/10, Batch 70/145, Loss: 0.1926
Epoch 7/10, Batch 80/145, Loss: 0.5642
Epoch 7/10, Batch 90/145, Loss: 0.1905
Epoch 7/10, Batch 100/145, Loss: 0.0796
Epoch 7/10, Batch 110/145, Loss: 0.1554
Epoch 7/10, Batch 120/145, Loss: 0.4157
Epoch 7/10, Batch 130/145, Loss: 0.1802
Epoch 7/10, Batch 140/145, Loss: 0.2393
Epoch 7/10, Train Loss: 0.2066, Valid Loss: 0.2324
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1385
Epoch 8/10, Batch 20/145, Loss: 0.4692
Epoch 8/10, Batch 30/145, Loss: 0.1991
Epoch 8/10, Batch 40/145, Loss: 0.1514
Epoch 8/10, Batch 50/145, Loss: 0.2093
Epoch 8/10, Batch 60/145, Loss: 0.2247
Epoch 8/10, Batch 70/145, Loss: 0.1847
Epoch 8/10, Batch 80/145, Loss: 0.1859
Epoch 8/10, Batch 90/145, Loss: 0.2327
Epoch 8/10, Batch 100/145, Loss: 0.2321
Epoch 8/10, Batch 110/145, Loss: 0.2173
Epoch 8/10, Batch 120/145, Loss: 0.2376
Epoch 8/10, Batch 130/145, Loss: 0.1469
Epoch 8/10, Batch 140/145, Loss: 0.1049
Epoch 8/10, Train Loss: 0.2111, Valid Loss: 0.2276
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2571
Epoch 9/10, Batch 20/145, Loss: 0.0760
Epoch 9/10, Batch 30/145, Loss: 0.1310
Epoch 9/10, Batch 40/145, Loss: 0.1475
Epoch 9/10, Batch 50/145, Loss: 0.1163
Epoch 9/10, Batch 60/145, Loss: 0.2070
Epoch 9/10, Batch 70/145, Loss: 0.2722
Epoch 9/10, Batch 80/145, Loss: 0.1365
Epoch 9/10, Batch 90/145, Loss: 0.2041
Epoch 9/10, Batch 100/145, Loss: 0.1375
Epoch 9/10, Batch 110/145, Loss: 0.2787
Epoch 9/10, Batch 120/145, Loss: 0.1301
Epoch 9/10, Batch 130/145, Loss: 0.2807
Epoch 9/10, Batch 140/145, Loss: 0.2378
Epoch 9/10, Train Loss: 0.1971, Valid Loss: 0.2250
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2619
Epoch 10/10, Batch 20/145, Loss: 0.1394
Epoch 10/10, Batch 30/145, Loss: 0.1427
Epoch 10/10, Batch 40/145, Loss: 0.1627
Epoch 10/10, Batch 50/145, Loss: 0.2589
Epoch 10/10, Batch 60/145, Loss: 0.0810
Epoch 10/10, Batch 70/145, Loss: 0.1917
Epoch 10/10, Batch 80/145, Loss: 0.1677
Epoch 10/10, Batch 90/145, Loss: 0.0925
Epoch 10/10, Batch 100/145, Loss: 0.2228
Epoch 10/10, Batch 110/145, Loss: 0.0573
Epoch 10/10, Batch 120/145, Loss: 0.1766
Epoch 10/10, Batch 130/145, Loss: 0.1807
Epoch 10/10, Batch 140/145, Loss: 0.2186
Epoch 10/10, Train Loss: 0.1869, Valid Loss: 0.2245
Model saved!
Accuracy: 0.9147
Precision: 0.9125
Recall: 0.9147
F1-score: 0.9122
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3684
Epoch 1/10, Batch 20/145, Loss: 0.9402
Epoch 1/10, Batch 30/145, Loss: 0.8673
Epoch 1/10, Batch 40/145, Loss: 0.8781
Epoch 1/10, Batch 50/145, Loss: 0.6754
Epoch 1/10, Batch 60/145, Loss: 0.6292
Epoch 1/10, Batch 70/145, Loss: 0.6479
Epoch 1/10, Batch 80/145, Loss: 0.7080
Epoch 1/10, Batch 90/145, Loss: 0.4790
Epoch 1/10, Batch 100/145, Loss: 0.4830
Epoch 1/10, Batch 110/145, Loss: 0.4126
Epoch 1/10, Batch 120/145, Loss: 0.5774
Epoch 1/10, Batch 130/145, Loss: 0.6166
Epoch 1/10, Batch 140/145, Loss: 0.4450
Epoch 1/10, Train Loss: 0.6813, Valid Loss: 0.3706
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4786
Epoch 2/10, Batch 20/145, Loss: 0.2806
Epoch 2/10, Batch 30/145, Loss: 0.2309
Epoch 2/10, Batch 40/145, Loss: 0.4367
Epoch 2/10, Batch 50/145, Loss: 0.3274
Epoch 2/10, Batch 60/145, Loss: 0.4831
Epoch 2/10, Batch 70/145, Loss: 0.3839
Epoch 2/10, Batch 80/145, Loss: 0.4569
Epoch 2/10, Batch 90/145, Loss: 0.3470
Epoch 2/10, Batch 100/145, Loss: 0.3245
Epoch 2/10, Batch 110/145, Loss: 0.3085
Epoch 2/10, Batch 120/145, Loss: 0.2662
Epoch 2/10, Batch 130/145, Loss: 0.2975
Epoch 2/10, Batch 140/145, Loss: 0.3305
Epoch 2/10, Train Loss: 0.3522, Valid Loss: 0.2932
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2353
Epoch 3/10, Batch 20/145, Loss: 0.2488
Epoch 3/10, Batch 30/145, Loss: 0.4448
Epoch 3/10, Batch 40/145, Loss: 0.2804
Epoch 3/10, Batch 50/145, Loss: 0.3044
Epoch 3/10, Batch 60/145, Loss: 0.4547
Epoch 3/10, Batch 70/145, Loss: 0.3206
Epoch 3/10, Batch 80/145, Loss: 0.1883
Epoch 3/10, Batch 90/145, Loss: 0.1946
Epoch 3/10, Batch 100/145, Loss: 0.2160
Epoch 3/10, Batch 110/145, Loss: 0.2534
Epoch 3/10, Batch 120/145, Loss: 0.3579
Epoch 3/10, Batch 130/145, Loss: 0.2808
Epoch 3/10, Batch 140/145, Loss: 0.2187
Epoch 3/10, Train Loss: 0.2880, Valid Loss: 0.2663
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2792
Epoch 4/10, Batch 20/145, Loss: 0.3761
Epoch 4/10, Batch 30/145, Loss: 0.2756
Epoch 4/10, Batch 40/145, Loss: 0.2164
Epoch 4/10, Batch 50/145, Loss: 0.2282
Epoch 4/10, Batch 60/145, Loss: 0.2496
Epoch 4/10, Batch 70/145, Loss: 0.1661
Epoch 4/10, Batch 80/145, Loss: 0.1937
Epoch 4/10, Batch 90/145, Loss: 0.1647
Epoch 4/10, Batch 100/145, Loss: 0.1971
Epoch 4/10, Batch 110/145, Loss: 0.1571
Epoch 4/10, Batch 120/145, Loss: 0.1962
Epoch 4/10, Batch 130/145, Loss: 0.1658
Epoch 4/10, Batch 140/145, Loss: 0.2295
Epoch 4/10, Train Loss: 0.2552, Valid Loss: 0.2484
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2521
Epoch 5/10, Batch 20/145, Loss: 0.2102
Epoch 5/10, Batch 30/145, Loss: 0.1731
Epoch 5/10, Batch 40/145, Loss: 0.1380
Epoch 5/10, Batch 50/145, Loss: 0.1955
Epoch 5/10, Batch 60/145, Loss: 0.2135
Epoch 5/10, Batch 70/145, Loss: 0.1615
Epoch 5/10, Batch 80/145, Loss: 0.4995
Epoch 5/10, Batch 90/145, Loss: 0.3686
Epoch 5/10, Batch 100/145, Loss: 0.3116
Epoch 5/10, Batch 110/145, Loss: 0.0942
Epoch 5/10, Batch 120/145, Loss: 0.2078
Epoch 5/10, Batch 130/145, Loss: 0.1647
Epoch 5/10, Batch 140/145, Loss: 0.1042
Epoch 5/10, Train Loss: 0.2411, Valid Loss: 0.2408
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1022
Epoch 6/10, Batch 20/145, Loss: 0.2742
Epoch 6/10, Batch 30/145, Loss: 0.2822
Epoch 6/10, Batch 40/145, Loss: 0.1015
Epoch 6/10, Batch 50/145, Loss: 0.3878
Epoch 6/10, Batch 60/145, Loss: 0.1987
Epoch 6/10, Batch 70/145, Loss: 0.1970
Epoch 6/10, Batch 80/145, Loss: 0.1935
Epoch 6/10, Batch 90/145, Loss: 0.3799
Epoch 6/10, Batch 100/145, Loss: 0.3650
Epoch 6/10, Batch 110/145, Loss: 0.2208
Epoch 6/10, Batch 120/145, Loss: 0.2446
Epoch 6/10, Batch 130/145, Loss: 0.1895
Epoch 6/10, Batch 140/145, Loss: 0.1619
Epoch 6/10, Train Loss: 0.2265, Valid Loss: 0.2311
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3557
Epoch 7/10, Batch 20/145, Loss: 0.2891
Epoch 7/10, Batch 30/145, Loss: 0.1917
Epoch 7/10, Batch 40/145, Loss: 0.3107
Epoch 7/10, Batch 50/145, Loss: 0.1297
Epoch 7/10, Batch 60/145, Loss: 0.1638
Epoch 7/10, Batch 70/145, Loss: 0.1380
Epoch 7/10, Batch 80/145, Loss: 0.3758
Epoch 7/10, Batch 90/145, Loss: 0.0910
Epoch 7/10, Batch 100/145, Loss: 0.2979
Epoch 7/10, Batch 110/145, Loss: 0.1500
Epoch 7/10, Batch 120/145, Loss: 0.1626
Epoch 7/10, Batch 130/145, Loss: 0.1222
Epoch 7/10, Batch 140/145, Loss: 0.2737
Epoch 7/10, Train Loss: 0.2153, Valid Loss: 0.2239
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.3132
Epoch 8/10, Batch 20/145, Loss: 0.2769
Epoch 8/10, Batch 30/145, Loss: 0.3360
Epoch 8/10, Batch 40/145, Loss: 0.2566
Epoch 8/10, Batch 50/145, Loss: 0.2708
Epoch 8/10, Batch 60/145, Loss: 0.2517
Epoch 8/10, Batch 70/145, Loss: 0.2063
Epoch 8/10, Batch 80/145, Loss: 0.2359
Epoch 8/10, Batch 90/145, Loss: 0.2082
Epoch 8/10, Batch 100/145, Loss: 0.1740
Epoch 8/10, Batch 110/145, Loss: 0.1570
Epoch 8/10, Batch 120/145, Loss: 0.1559
Epoch 8/10, Batch 130/145, Loss: 0.0966
Epoch 8/10, Batch 140/145, Loss: 0.1314
Epoch 8/10, Train Loss: 0.2050, Valid Loss: 0.2251
Epoch 9/10, Batch 10/145, Loss: 0.2199
Epoch 9/10, Batch 20/145, Loss: 0.1533
Epoch 9/10, Batch 30/145, Loss: 0.1164
Epoch 9/10, Batch 40/145, Loss: 0.2420
Epoch 9/10, Batch 50/145, Loss: 0.1464
Epoch 9/10, Batch 60/145, Loss: 0.1229
Epoch 9/10, Batch 70/145, Loss: 0.2039
Epoch 9/10, Batch 80/145, Loss: 0.2130
Epoch 9/10, Batch 90/145, Loss: 0.2099
Epoch 9/10, Batch 100/145, Loss: 0.1442
Epoch 9/10, Batch 110/145, Loss: 0.1318
Epoch 9/10, Batch 120/145, Loss: 0.1502
Epoch 9/10, Batch 130/145, Loss: 0.2377
Epoch 9/10, Batch 140/145, Loss: 0.1814
Epoch 9/10, Train Loss: 0.1974, Valid Loss: 0.2171
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0377
Epoch 10/10, Batch 20/145, Loss: 0.1300
Epoch 10/10, Batch 30/145, Loss: 0.2629
Epoch 10/10, Batch 40/145, Loss: 0.0608
Epoch 10/10, Batch 50/145, Loss: 0.2514
Epoch 10/10, Batch 60/145, Loss: 0.3099
Epoch 10/10, Batch 70/145, Loss: 0.4147
Epoch 10/10, Batch 80/145, Loss: 0.1363
Epoch 10/10, Batch 90/145, Loss: 0.3931
Epoch 10/10, Batch 100/145, Loss: 0.3100
Epoch 10/10, Batch 110/145, Loss: 0.2121
Epoch 10/10, Batch 120/145, Loss: 0.2348
Epoch 10/10, Batch 130/145, Loss: 0.1399
Epoch 10/10, Batch 140/145, Loss: 0.1390
Epoch 10/10, Train Loss: 0.1963, Valid Loss: 0.2199
Accuracy: 0.9287
Precision: 0.9275
Recall: 0.9287
F1-score: 0.9280
Memory Allocated after cleanup: 17.76 MB
Nueva mejor solución encontrada en evaluación 40. Fitness: 0.9287
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3892
Epoch 1/10, Batch 20/145, Loss: 0.9507
Epoch 1/10, Batch 30/145, Loss: 0.9702
Epoch 1/10, Batch 40/145, Loss: 0.8691
Epoch 1/10, Batch 50/145, Loss: 0.7658
Epoch 1/10, Batch 60/145, Loss: 0.6786
Epoch 1/10, Batch 70/145, Loss: 0.4098
Epoch 1/10, Batch 80/145, Loss: 0.4697
Epoch 1/10, Batch 90/145, Loss: 0.4217
Epoch 1/10, Batch 100/145, Loss: 0.4342
Epoch 1/10, Batch 110/145, Loss: 0.4332
Epoch 1/10, Batch 120/145, Loss: 0.4054
Epoch 1/10, Batch 130/145, Loss: 0.5251
Epoch 1/10, Batch 140/145, Loss: 0.4784
Epoch 1/10, Train Loss: 0.6786, Valid Loss: 0.3679
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4424
Epoch 2/10, Batch 20/145, Loss: 0.3123
Epoch 2/10, Batch 30/145, Loss: 0.3356
Epoch 2/10, Batch 40/145, Loss: 0.4422
Epoch 2/10, Batch 50/145, Loss: 0.3333
Epoch 2/10, Batch 60/145, Loss: 0.3078
Epoch 2/10, Batch 70/145, Loss: 0.2335
Epoch 2/10, Batch 80/145, Loss: 0.2649
Epoch 2/10, Batch 90/145, Loss: 0.2737
Epoch 2/10, Batch 100/145, Loss: 0.3721
Epoch 2/10, Batch 110/145, Loss: 0.2675
Epoch 2/10, Batch 120/145, Loss: 0.3699
Epoch 2/10, Batch 130/145, Loss: 0.2372
Epoch 2/10, Batch 140/145, Loss: 0.2841
Epoch 2/10, Train Loss: 0.3471, Valid Loss: 0.2913
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1812
Epoch 3/10, Batch 20/145, Loss: 0.1694
Epoch 3/10, Batch 30/145, Loss: 0.4117
Epoch 3/10, Batch 40/145, Loss: 0.2034
Epoch 3/10, Batch 50/145, Loss: 0.2078
Epoch 3/10, Batch 60/145, Loss: 0.3401
Epoch 3/10, Batch 70/145, Loss: 0.3786
Epoch 3/10, Batch 80/145, Loss: 0.2676
Epoch 3/10, Batch 90/145, Loss: 0.5878
Epoch 3/10, Batch 100/145, Loss: 0.3400
Epoch 3/10, Batch 110/145, Loss: 0.3289
Epoch 3/10, Batch 120/145, Loss: 0.1331
Epoch 3/10, Batch 130/145, Loss: 0.2531
Epoch 3/10, Batch 140/145, Loss: 0.2975
Epoch 3/10, Train Loss: 0.2873, Valid Loss: 0.2605
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2103
Epoch 4/10, Batch 20/145, Loss: 0.1697
Epoch 4/10, Batch 30/145, Loss: 0.2859
Epoch 4/10, Batch 40/145, Loss: 0.0937
Epoch 4/10, Batch 50/145, Loss: 0.1715
Epoch 4/10, Batch 60/145, Loss: 0.3258
Epoch 4/10, Batch 70/145, Loss: 0.1898
Epoch 4/10, Batch 80/145, Loss: 0.2248
Epoch 4/10, Batch 90/145, Loss: 0.1881
Epoch 4/10, Batch 100/145, Loss: 0.2513
Epoch 4/10, Batch 110/145, Loss: 0.1047
Epoch 4/10, Batch 120/145, Loss: 0.1912
Epoch 4/10, Batch 130/145, Loss: 0.1657
Epoch 4/10, Batch 140/145, Loss: 0.1196
Epoch 4/10, Train Loss: 0.2554, Valid Loss: 0.2530
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2259
Epoch 5/10, Batch 20/145, Loss: 0.1051
Epoch 5/10, Batch 30/145, Loss: 0.2026
Epoch 5/10, Batch 40/145, Loss: 0.1764
Epoch 5/10, Batch 50/145, Loss: 0.2002
Epoch 5/10, Batch 60/145, Loss: 0.1746
Epoch 5/10, Batch 70/145, Loss: 0.3002
Epoch 5/10, Batch 80/145, Loss: 0.3612
Epoch 5/10, Batch 90/145, Loss: 0.2468
Epoch 5/10, Batch 100/145, Loss: 0.2241
Epoch 5/10, Batch 110/145, Loss: 0.1430
Epoch 5/10, Batch 120/145, Loss: 0.2804
Epoch 5/10, Batch 130/145, Loss: 0.1812
Epoch 5/10, Batch 140/145, Loss: 0.2005
Epoch 5/10, Train Loss: 0.2384, Valid Loss: 0.2444
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1152
Epoch 6/10, Batch 20/145, Loss: 0.2945
Epoch 6/10, Batch 30/145, Loss: 0.3059
Epoch 6/10, Batch 40/145, Loss: 0.1666
Epoch 6/10, Batch 50/145, Loss: 0.3762
Epoch 6/10, Batch 60/145, Loss: 0.1619
Epoch 6/10, Batch 70/145, Loss: 0.0790
Epoch 6/10, Batch 80/145, Loss: 0.1626
Epoch 6/10, Batch 90/145, Loss: 0.3107
Epoch 6/10, Batch 100/145, Loss: 0.1663
Epoch 6/10, Batch 110/145, Loss: 0.4555
Epoch 6/10, Batch 120/145, Loss: 0.3112
Epoch 6/10, Batch 130/145, Loss: 0.2176
Epoch 6/10, Batch 140/145, Loss: 0.1487
Epoch 6/10, Train Loss: 0.2227, Valid Loss: 0.2348
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1189
Epoch 7/10, Batch 20/145, Loss: 0.3484
Epoch 7/10, Batch 30/145, Loss: 0.3043
Epoch 7/10, Batch 40/145, Loss: 0.4082
Epoch 7/10, Batch 50/145, Loss: 0.0918
Epoch 7/10, Batch 60/145, Loss: 0.2241
Epoch 7/10, Batch 70/145, Loss: 0.1945
Epoch 7/10, Batch 80/145, Loss: 0.4258
Epoch 7/10, Batch 90/145, Loss: 0.1357
Epoch 7/10, Batch 100/145, Loss: 0.1483
Epoch 7/10, Batch 110/145, Loss: 0.1736
Epoch 7/10, Batch 120/145, Loss: 0.2720
Epoch 7/10, Batch 130/145, Loss: 0.1635
Epoch 7/10, Batch 140/145, Loss: 0.2285
Epoch 7/10, Train Loss: 0.2063, Valid Loss: 0.2249
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0879
Epoch 8/10, Batch 20/145, Loss: 0.2548
Epoch 8/10, Batch 30/145, Loss: 0.1689
Epoch 8/10, Batch 40/145, Loss: 0.2112
Epoch 8/10, Batch 50/145, Loss: 0.2660
Epoch 8/10, Batch 60/145, Loss: 0.3015
Epoch 8/10, Batch 70/145, Loss: 0.3286
Epoch 8/10, Batch 80/145, Loss: 0.2244
Epoch 8/10, Batch 90/145, Loss: 0.3924
Epoch 8/10, Batch 100/145, Loss: 0.1692
Epoch 8/10, Batch 110/145, Loss: 0.1450
Epoch 8/10, Batch 120/145, Loss: 0.1484
Epoch 8/10, Batch 130/145, Loss: 0.3530
Epoch 8/10, Batch 140/145, Loss: 0.1285
Epoch 8/10, Train Loss: 0.1980, Valid Loss: 0.2211
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2646
Epoch 9/10, Batch 20/145, Loss: 0.3243
Epoch 9/10, Batch 30/145, Loss: 0.2329
Epoch 9/10, Batch 40/145, Loss: 0.2745
Epoch 9/10, Batch 50/145, Loss: 0.1417
Epoch 9/10, Batch 60/145, Loss: 0.2378
Epoch 9/10, Batch 70/145, Loss: 0.1143
Epoch 9/10, Batch 80/145, Loss: 0.0985
Epoch 9/10, Batch 90/145, Loss: 0.2076
Epoch 9/10, Batch 100/145, Loss: 0.0939
Epoch 9/10, Batch 110/145, Loss: 0.1973
Epoch 9/10, Batch 120/145, Loss: 0.0871
Epoch 9/10, Batch 130/145, Loss: 0.1722
Epoch 9/10, Batch 140/145, Loss: 0.1035
Epoch 9/10, Train Loss: 0.1936, Valid Loss: 0.2171
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0816
Epoch 10/10, Batch 20/145, Loss: 0.1614
Epoch 10/10, Batch 30/145, Loss: 0.0883
Epoch 10/10, Batch 40/145, Loss: 0.1417
Epoch 10/10, Batch 50/145, Loss: 0.1540
Epoch 10/10, Batch 60/145, Loss: 0.1888
Epoch 10/10, Batch 70/145, Loss: 0.3827
Epoch 10/10, Batch 80/145, Loss: 0.0625
Epoch 10/10, Batch 90/145, Loss: 0.1202
Epoch 10/10, Batch 100/145, Loss: 0.1025
Epoch 10/10, Batch 110/145, Loss: 0.1170
Epoch 10/10, Batch 120/145, Loss: 0.1187
Epoch 10/10, Batch 130/145, Loss: 0.1159
Epoch 10/10, Batch 140/145, Loss: 0.2738
Epoch 10/10, Train Loss: 0.1843, Valid Loss: 0.2178
Accuracy: 0.9171
Precision: 0.9157
Recall: 0.9171
F1-score: 0.9161
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3819
Epoch 1/10, Batch 20/145, Loss: 0.9648
Epoch 1/10, Batch 30/145, Loss: 0.8602
Epoch 1/10, Batch 40/145, Loss: 0.8024
Epoch 1/10, Batch 50/145, Loss: 0.6371
Epoch 1/10, Batch 60/145, Loss: 0.6515
Epoch 1/10, Batch 70/145, Loss: 0.4822
Epoch 1/10, Batch 80/145, Loss: 0.5012
Epoch 1/10, Batch 90/145, Loss: 0.3509
Epoch 1/10, Batch 100/145, Loss: 0.4089
Epoch 1/10, Batch 110/145, Loss: 0.4352
Epoch 1/10, Batch 120/145, Loss: 0.4347
Epoch 1/10, Batch 130/145, Loss: 0.5769
Epoch 1/10, Batch 140/145, Loss: 0.4436
Epoch 1/10, Train Loss: 0.6751, Valid Loss: 0.3946
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3455
Epoch 2/10, Batch 20/145, Loss: 0.2759
Epoch 2/10, Batch 30/145, Loss: 0.2410
Epoch 2/10, Batch 40/145, Loss: 0.3765
Epoch 2/10, Batch 50/145, Loss: 0.2704
Epoch 2/10, Batch 60/145, Loss: 0.3753
Epoch 2/10, Batch 70/145, Loss: 0.3214
Epoch 2/10, Batch 80/145, Loss: 0.2055
Epoch 2/10, Batch 90/145, Loss: 0.5113
Epoch 2/10, Batch 100/145, Loss: 0.2124
Epoch 2/10, Batch 110/145, Loss: 0.3506
Epoch 2/10, Batch 120/145, Loss: 0.4487
Epoch 2/10, Batch 130/145, Loss: 0.2640
Epoch 2/10, Batch 140/145, Loss: 0.2263
Epoch 2/10, Train Loss: 0.3501, Valid Loss: 0.3164
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2182
Epoch 3/10, Batch 20/145, Loss: 0.3387
Epoch 3/10, Batch 30/145, Loss: 0.2979
Epoch 3/10, Batch 40/145, Loss: 0.3397
Epoch 3/10, Batch 50/145, Loss: 0.3690
Epoch 3/10, Batch 60/145, Loss: 0.4103
Epoch 3/10, Batch 70/145, Loss: 0.4511
Epoch 3/10, Batch 80/145, Loss: 0.2441
Epoch 3/10, Batch 90/145, Loss: 0.3205
Epoch 3/10, Batch 100/145, Loss: 0.3149
Epoch 3/10, Batch 110/145, Loss: 0.2573
Epoch 3/10, Batch 120/145, Loss: 0.2860
Epoch 3/10, Batch 130/145, Loss: 0.4143
Epoch 3/10, Batch 140/145, Loss: 0.2065
Epoch 3/10, Train Loss: 0.2877, Valid Loss: 0.2863
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2247
Epoch 4/10, Batch 20/145, Loss: 0.1530
Epoch 4/10, Batch 30/145, Loss: 0.2959
Epoch 4/10, Batch 40/145, Loss: 0.2402
Epoch 4/10, Batch 50/145, Loss: 0.1682
Epoch 4/10, Batch 60/145, Loss: 0.2958
Epoch 4/10, Batch 70/145, Loss: 0.2061
Epoch 4/10, Batch 80/145, Loss: 0.3825
Epoch 4/10, Batch 90/145, Loss: 0.2138
Epoch 4/10, Batch 100/145, Loss: 0.4359
Epoch 4/10, Batch 110/145, Loss: 0.1479
Epoch 4/10, Batch 120/145, Loss: 0.1953
Epoch 4/10, Batch 130/145, Loss: 0.1450
Epoch 4/10, Batch 140/145, Loss: 0.1282
Epoch 4/10, Train Loss: 0.2597, Valid Loss: 0.2715
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2116
Epoch 5/10, Batch 20/145, Loss: 0.1215
Epoch 5/10, Batch 30/145, Loss: 0.3940
Epoch 5/10, Batch 40/145, Loss: 0.1826
Epoch 5/10, Batch 50/145, Loss: 0.2169
Epoch 5/10, Batch 60/145, Loss: 0.3744
Epoch 5/10, Batch 70/145, Loss: 0.2725
Epoch 5/10, Batch 80/145, Loss: 0.2983
Epoch 5/10, Batch 90/145, Loss: 0.1440
Epoch 5/10, Batch 100/145, Loss: 0.1528
Epoch 5/10, Batch 110/145, Loss: 0.2159
Epoch 5/10, Batch 120/145, Loss: 0.3077
Epoch 5/10, Batch 130/145, Loss: 0.1644
Epoch 5/10, Batch 140/145, Loss: 0.2476
Epoch 5/10, Train Loss: 0.2396, Valid Loss: 0.2621
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1809
Epoch 6/10, Batch 20/145, Loss: 0.2772
Epoch 6/10, Batch 30/145, Loss: 0.2611
Epoch 6/10, Batch 40/145, Loss: 0.1109
Epoch 6/10, Batch 50/145, Loss: 0.3648
Epoch 6/10, Batch 60/145, Loss: 0.1807
Epoch 6/10, Batch 70/145, Loss: 0.1323
Epoch 6/10, Batch 80/145, Loss: 0.1789
Epoch 6/10, Batch 90/145, Loss: 0.2358
Epoch 6/10, Batch 100/145, Loss: 0.0832
Epoch 6/10, Batch 110/145, Loss: 0.2576
Epoch 6/10, Batch 120/145, Loss: 0.3755
Epoch 6/10, Batch 130/145, Loss: 0.1483
Epoch 6/10, Batch 140/145, Loss: 0.0850
Epoch 6/10, Train Loss: 0.2246, Valid Loss: 0.2551
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1324
Epoch 7/10, Batch 20/145, Loss: 0.1530
Epoch 7/10, Batch 30/145, Loss: 0.1464
Epoch 7/10, Batch 40/145, Loss: 0.4218
Epoch 7/10, Batch 50/145, Loss: 0.3272
Epoch 7/10, Batch 60/145, Loss: 0.1489
Epoch 7/10, Batch 70/145, Loss: 0.1561
Epoch 7/10, Batch 80/145, Loss: 0.5323
Epoch 7/10, Batch 90/145, Loss: 0.2246
Epoch 7/10, Batch 100/145, Loss: 0.1901
Epoch 7/10, Batch 110/145, Loss: 0.1651
Epoch 7/10, Batch 120/145, Loss: 0.3902
Epoch 7/10, Batch 130/145, Loss: 0.0652
Epoch 7/10, Batch 140/145, Loss: 0.4007
Epoch 7/10, Train Loss: 0.2134, Valid Loss: 0.2432
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2494
Epoch 8/10, Batch 20/145, Loss: 0.1006
Epoch 8/10, Batch 30/145, Loss: 0.2465
Epoch 8/10, Batch 40/145, Loss: 0.3107
Epoch 8/10, Batch 50/145, Loss: 0.2033
Epoch 8/10, Batch 60/145, Loss: 0.2763
Epoch 8/10, Batch 70/145, Loss: 0.2389
Epoch 8/10, Batch 80/145, Loss: 0.1896
Epoch 8/10, Batch 90/145, Loss: 0.3496
Epoch 8/10, Batch 100/145, Loss: 0.0872
Epoch 8/10, Batch 110/145, Loss: 0.1637
Epoch 8/10, Batch 120/145, Loss: 0.2509
Epoch 8/10, Batch 130/145, Loss: 0.1378
Epoch 8/10, Batch 140/145, Loss: 0.1984
Epoch 8/10, Train Loss: 0.2006, Valid Loss: 0.2379
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3963
Epoch 9/10, Batch 20/145, Loss: 0.2090
Epoch 9/10, Batch 30/145, Loss: 0.2372
Epoch 9/10, Batch 40/145, Loss: 0.1359
Epoch 9/10, Batch 50/145, Loss: 0.1747
Epoch 9/10, Batch 60/145, Loss: 0.1766
Epoch 9/10, Batch 70/145, Loss: 0.2306
Epoch 9/10, Batch 80/145, Loss: 0.1643
Epoch 9/10, Batch 90/145, Loss: 0.2166
Epoch 9/10, Batch 100/145, Loss: 0.1463
Epoch 9/10, Batch 110/145, Loss: 0.2586
Epoch 9/10, Batch 120/145, Loss: 0.0746
Epoch 9/10, Batch 130/145, Loss: 0.2521
Epoch 9/10, Batch 140/145, Loss: 0.1433
Epoch 9/10, Train Loss: 0.1969, Valid Loss: 0.2388
Epoch 10/10, Batch 10/145, Loss: 0.0822
Epoch 10/10, Batch 20/145, Loss: 0.0838
Epoch 10/10, Batch 30/145, Loss: 0.1699
Epoch 10/10, Batch 40/145, Loss: 0.2024
Epoch 10/10, Batch 50/145, Loss: 0.1648
Epoch 10/10, Batch 60/145, Loss: 0.1376
Epoch 10/10, Batch 70/145, Loss: 0.2814
Epoch 10/10, Batch 80/145, Loss: 0.0818
Epoch 10/10, Batch 90/145, Loss: 0.1470
Epoch 10/10, Batch 100/145, Loss: 0.2792
Epoch 10/10, Batch 110/145, Loss: 0.1096
Epoch 10/10, Batch 120/145, Loss: 0.1494
Epoch 10/10, Batch 130/145, Loss: 0.1918
Epoch 10/10, Batch 140/145, Loss: 0.1539
Epoch 10/10, Train Loss: 0.1845, Valid Loss: 0.2332
Model saved!
Accuracy: 0.9159
Precision: 0.9135
Recall: 0.9159
F1-score: 0.9141
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4384
Epoch 1/10, Batch 20/145, Loss: 0.9828
Epoch 1/10, Batch 30/145, Loss: 0.9029
Epoch 1/10, Batch 40/145, Loss: 0.8908
Epoch 1/10, Batch 50/145, Loss: 0.7234
Epoch 1/10, Batch 60/145, Loss: 0.6003
Epoch 1/10, Batch 70/145, Loss: 0.3671
Epoch 1/10, Batch 80/145, Loss: 0.5836
Epoch 1/10, Batch 90/145, Loss: 0.4089
Epoch 1/10, Batch 100/145, Loss: 0.4835
Epoch 1/10, Batch 110/145, Loss: 0.4470
Epoch 1/10, Batch 120/145, Loss: 0.6659
Epoch 1/10, Batch 130/145, Loss: 0.4347
Epoch 1/10, Batch 140/145, Loss: 0.3738
Epoch 1/10, Train Loss: 0.6751, Valid Loss: 0.3990
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2886
Epoch 2/10, Batch 20/145, Loss: 0.3789
Epoch 2/10, Batch 30/145, Loss: 0.3864
Epoch 2/10, Batch 40/145, Loss: 0.3351
Epoch 2/10, Batch 50/145, Loss: 0.4797
Epoch 2/10, Batch 60/145, Loss: 0.3398
Epoch 2/10, Batch 70/145, Loss: 0.4396
Epoch 2/10, Batch 80/145, Loss: 0.2455
Epoch 2/10, Batch 90/145, Loss: 0.3412
Epoch 2/10, Batch 100/145, Loss: 0.5148
Epoch 2/10, Batch 110/145, Loss: 0.4573
Epoch 2/10, Batch 120/145, Loss: 0.4416
Epoch 2/10, Batch 130/145, Loss: 0.2154
Epoch 2/10, Batch 140/145, Loss: 0.3860
Epoch 2/10, Train Loss: 0.3557, Valid Loss: 0.3144
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1390
Epoch 3/10, Batch 20/145, Loss: 0.3335
Epoch 3/10, Batch 30/145, Loss: 0.2717
Epoch 3/10, Batch 40/145, Loss: 0.2877
Epoch 3/10, Batch 50/145, Loss: 0.2687
Epoch 3/10, Batch 60/145, Loss: 0.4880
Epoch 3/10, Batch 70/145, Loss: 0.3996
Epoch 3/10, Batch 80/145, Loss: 0.2452
Epoch 3/10, Batch 90/145, Loss: 0.2591
Epoch 3/10, Batch 100/145, Loss: 0.3223
Epoch 3/10, Batch 110/145, Loss: 0.2395
Epoch 3/10, Batch 120/145, Loss: 0.1782
Epoch 3/10, Batch 130/145, Loss: 0.5210
Epoch 3/10, Batch 140/145, Loss: 0.3636
Epoch 3/10, Train Loss: 0.2903, Valid Loss: 0.2817
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3594
Epoch 4/10, Batch 20/145, Loss: 0.2607
Epoch 4/10, Batch 30/145, Loss: 0.1998
Epoch 4/10, Batch 40/145, Loss: 0.3343
Epoch 4/10, Batch 50/145, Loss: 0.1545
Epoch 4/10, Batch 60/145, Loss: 0.1692
Epoch 4/10, Batch 70/145, Loss: 0.2224
Epoch 4/10, Batch 80/145, Loss: 0.1570
Epoch 4/10, Batch 90/145, Loss: 0.3208
Epoch 4/10, Batch 100/145, Loss: 0.4184
Epoch 4/10, Batch 110/145, Loss: 0.2018
Epoch 4/10, Batch 120/145, Loss: 0.2257
Epoch 4/10, Batch 130/145, Loss: 0.2578
Epoch 4/10, Batch 140/145, Loss: 0.1141
Epoch 4/10, Train Loss: 0.2650, Valid Loss: 0.2662
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1586
Epoch 5/10, Batch 20/145, Loss: 0.1586
Epoch 5/10, Batch 30/145, Loss: 0.2038
Epoch 5/10, Batch 40/145, Loss: 0.2490
Epoch 5/10, Batch 50/145, Loss: 0.1890
Epoch 5/10, Batch 60/145, Loss: 0.1818
Epoch 5/10, Batch 70/145, Loss: 0.2790
Epoch 5/10, Batch 80/145, Loss: 0.1283
Epoch 5/10, Batch 90/145, Loss: 0.2327
Epoch 5/10, Batch 100/145, Loss: 0.2599
Epoch 5/10, Batch 110/145, Loss: 0.1776
Epoch 5/10, Batch 120/145, Loss: 0.1892
Epoch 5/10, Batch 130/145, Loss: 0.2979
Epoch 5/10, Batch 140/145, Loss: 0.2449
Epoch 5/10, Train Loss: 0.2490, Valid Loss: 0.2486
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2424
Epoch 6/10, Batch 20/145, Loss: 0.4080
Epoch 6/10, Batch 30/145, Loss: 0.2464
Epoch 6/10, Batch 40/145, Loss: 0.2906
Epoch 6/10, Batch 50/145, Loss: 0.3328
Epoch 6/10, Batch 60/145, Loss: 0.1779
Epoch 6/10, Batch 70/145, Loss: 0.1558
Epoch 6/10, Batch 80/145, Loss: 0.2056
Epoch 6/10, Batch 90/145, Loss: 0.2228
Epoch 6/10, Batch 100/145, Loss: 0.2987
Epoch 6/10, Batch 110/145, Loss: 0.1635
Epoch 6/10, Batch 120/145, Loss: 0.2269
Epoch 6/10, Batch 130/145, Loss: 0.2790
Epoch 6/10, Batch 140/145, Loss: 0.4183
Epoch 6/10, Train Loss: 0.2301, Valid Loss: 0.2482
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2143
Epoch 7/10, Batch 20/145, Loss: 0.2680
Epoch 7/10, Batch 30/145, Loss: 0.2346
Epoch 7/10, Batch 40/145, Loss: 0.4559
Epoch 7/10, Batch 50/145, Loss: 0.2474
Epoch 7/10, Batch 60/145, Loss: 0.1705
Epoch 7/10, Batch 70/145, Loss: 0.1760
Epoch 7/10, Batch 80/145, Loss: 0.3376
Epoch 7/10, Batch 90/145, Loss: 0.1991
Epoch 7/10, Batch 100/145, Loss: 0.1139
Epoch 7/10, Batch 110/145, Loss: 0.1006
Epoch 7/10, Batch 120/145, Loss: 0.1969
Epoch 7/10, Batch 130/145, Loss: 0.1656
Epoch 7/10, Batch 140/145, Loss: 0.4273
Epoch 7/10, Train Loss: 0.2117, Valid Loss: 0.2433
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1649
Epoch 8/10, Batch 20/145, Loss: 0.2461
Epoch 8/10, Batch 30/145, Loss: 0.2727
Epoch 8/10, Batch 40/145, Loss: 0.1613
Epoch 8/10, Batch 50/145, Loss: 0.2558
Epoch 8/10, Batch 60/145, Loss: 0.1163
Epoch 8/10, Batch 70/145, Loss: 0.2913
Epoch 8/10, Batch 80/145, Loss: 0.2778
Epoch 8/10, Batch 90/145, Loss: 0.3104
Epoch 8/10, Batch 100/145, Loss: 0.2665
Epoch 8/10, Batch 110/145, Loss: 0.2630
Epoch 8/10, Batch 120/145, Loss: 0.0691
Epoch 8/10, Batch 130/145, Loss: 0.2169
Epoch 8/10, Batch 140/145, Loss: 0.2803
Epoch 8/10, Train Loss: 0.2097, Valid Loss: 0.2356
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2796
Epoch 9/10, Batch 20/145, Loss: 0.1915
Epoch 9/10, Batch 30/145, Loss: 0.1515
Epoch 9/10, Batch 40/145, Loss: 0.4995
Epoch 9/10, Batch 50/145, Loss: 0.0831
Epoch 9/10, Batch 60/145, Loss: 0.1536
Epoch 9/10, Batch 70/145, Loss: 0.2949
Epoch 9/10, Batch 80/145, Loss: 0.2839
Epoch 9/10, Batch 90/145, Loss: 0.1281
Epoch 9/10, Batch 100/145, Loss: 0.1794
Epoch 9/10, Batch 110/145, Loss: 0.5393
Epoch 9/10, Batch 120/145, Loss: 0.0739
Epoch 9/10, Batch 130/145, Loss: 0.1302
Epoch 9/10, Batch 140/145, Loss: 0.2317
Epoch 9/10, Train Loss: 0.1979, Valid Loss: 0.2356
Epoch 10/10, Batch 10/145, Loss: 0.2430
Epoch 10/10, Batch 20/145, Loss: 0.0752
Epoch 10/10, Batch 30/145, Loss: 0.1172
Epoch 10/10, Batch 40/145, Loss: 0.1900
Epoch 10/10, Batch 50/145, Loss: 0.2111
Epoch 10/10, Batch 60/145, Loss: 0.0834
Epoch 10/10, Batch 70/145, Loss: 0.2713
Epoch 10/10, Batch 80/145, Loss: 0.1267
Epoch 10/10, Batch 90/145, Loss: 0.0972
Epoch 10/10, Batch 100/145, Loss: 0.2035
Epoch 10/10, Batch 110/145, Loss: 0.2614
Epoch 10/10, Batch 120/145, Loss: 0.1514
Epoch 10/10, Batch 130/145, Loss: 0.2336
Epoch 10/10, Batch 140/145, Loss: 0.2044
Epoch 10/10, Train Loss: 0.1939, Valid Loss: 0.2295
Model saved!
Accuracy: 0.9159
Precision: 0.9143
Recall: 0.9159
F1-score: 0.9140
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4153
Epoch 1/10, Batch 20/145, Loss: 0.9692
Epoch 1/10, Batch 30/145, Loss: 0.8986
Epoch 1/10, Batch 40/145, Loss: 0.9314
Epoch 1/10, Batch 50/145, Loss: 0.8469
Epoch 1/10, Batch 60/145, Loss: 0.7719
Epoch 1/10, Batch 70/145, Loss: 0.5148
Epoch 1/10, Batch 80/145, Loss: 0.5920
Epoch 1/10, Batch 90/145, Loss: 0.4610
Epoch 1/10, Batch 100/145, Loss: 0.5366
Epoch 1/10, Batch 110/145, Loss: 0.4309
Epoch 1/10, Batch 120/145, Loss: 0.5384
Epoch 1/10, Batch 130/145, Loss: 0.5798
Epoch 1/10, Batch 140/145, Loss: 0.3482
Epoch 1/10, Train Loss: 0.6778, Valid Loss: 0.3775
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3655
Epoch 2/10, Batch 20/145, Loss: 0.2588
Epoch 2/10, Batch 30/145, Loss: 0.2435
Epoch 2/10, Batch 40/145, Loss: 0.4290
Epoch 2/10, Batch 50/145, Loss: 0.4909
Epoch 2/10, Batch 60/145, Loss: 0.4126
Epoch 2/10, Batch 70/145, Loss: 0.3929
Epoch 2/10, Batch 80/145, Loss: 0.2261
Epoch 2/10, Batch 90/145, Loss: 0.2516
Epoch 2/10, Batch 100/145, Loss: 0.3882
Epoch 2/10, Batch 110/145, Loss: 0.2982
Epoch 2/10, Batch 120/145, Loss: 0.4251
Epoch 2/10, Batch 130/145, Loss: 0.2835
Epoch 2/10, Batch 140/145, Loss: 0.3033
Epoch 2/10, Train Loss: 0.3524, Valid Loss: 0.2959
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2202
Epoch 3/10, Batch 20/145, Loss: 0.2993
Epoch 3/10, Batch 30/145, Loss: 0.3564
Epoch 3/10, Batch 40/145, Loss: 0.2240
Epoch 3/10, Batch 50/145, Loss: 0.4392
Epoch 3/10, Batch 60/145, Loss: 0.2935
Epoch 3/10, Batch 70/145, Loss: 0.3308
Epoch 3/10, Batch 80/145, Loss: 0.1644
Epoch 3/10, Batch 90/145, Loss: 0.3567
Epoch 3/10, Batch 100/145, Loss: 0.3075
Epoch 3/10, Batch 110/145, Loss: 0.1821
Epoch 3/10, Batch 120/145, Loss: 0.3732
Epoch 3/10, Batch 130/145, Loss: 0.3387
Epoch 3/10, Batch 140/145, Loss: 0.1554
Epoch 3/10, Train Loss: 0.2899, Valid Loss: 0.2664
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3663
Epoch 4/10, Batch 20/145, Loss: 0.2633
Epoch 4/10, Batch 30/145, Loss: 0.3305
Epoch 4/10, Batch 40/145, Loss: 0.1960
Epoch 4/10, Batch 50/145, Loss: 0.1539
Epoch 4/10, Batch 60/145, Loss: 0.2298
Epoch 4/10, Batch 70/145, Loss: 0.2353
Epoch 4/10, Batch 80/145, Loss: 0.2150
Epoch 4/10, Batch 90/145, Loss: 0.1818
Epoch 4/10, Batch 100/145, Loss: 0.2058
Epoch 4/10, Batch 110/145, Loss: 0.0758
Epoch 4/10, Batch 120/145, Loss: 0.2164
Epoch 4/10, Batch 130/145, Loss: 0.2291
Epoch 4/10, Batch 140/145, Loss: 0.2032
Epoch 4/10, Train Loss: 0.2534, Valid Loss: 0.2554
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1856
Epoch 5/10, Batch 20/145, Loss: 0.2093
Epoch 5/10, Batch 30/145, Loss: 0.3222
Epoch 5/10, Batch 40/145, Loss: 0.2039
Epoch 5/10, Batch 50/145, Loss: 0.1154
Epoch 5/10, Batch 60/145, Loss: 0.2746
Epoch 5/10, Batch 70/145, Loss: 0.2396
Epoch 5/10, Batch 80/145, Loss: 0.3775
Epoch 5/10, Batch 90/145, Loss: 0.2296
Epoch 5/10, Batch 100/145, Loss: 0.2038
Epoch 5/10, Batch 110/145, Loss: 0.1130
Epoch 5/10, Batch 120/145, Loss: 0.4077
Epoch 5/10, Batch 130/145, Loss: 0.2043
Epoch 5/10, Batch 140/145, Loss: 0.2914
Epoch 5/10, Train Loss: 0.2397, Valid Loss: 0.2468
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2074
Epoch 6/10, Batch 20/145, Loss: 0.3608
Epoch 6/10, Batch 30/145, Loss: 0.2568
Epoch 6/10, Batch 40/145, Loss: 0.2471
Epoch 6/10, Batch 50/145, Loss: 0.3372
Epoch 6/10, Batch 60/145, Loss: 0.2001
Epoch 6/10, Batch 70/145, Loss: 0.1271
Epoch 6/10, Batch 80/145, Loss: 0.2710
Epoch 6/10, Batch 90/145, Loss: 0.3898
Epoch 6/10, Batch 100/145, Loss: 0.2113
Epoch 6/10, Batch 110/145, Loss: 0.4238
Epoch 6/10, Batch 120/145, Loss: 0.3061
Epoch 6/10, Batch 130/145, Loss: 0.1430
Epoch 6/10, Batch 140/145, Loss: 0.1706
Epoch 6/10, Train Loss: 0.2224, Valid Loss: 0.2386
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2097
Epoch 7/10, Batch 20/145, Loss: 0.3715
Epoch 7/10, Batch 30/145, Loss: 0.2875
Epoch 7/10, Batch 40/145, Loss: 0.3074
Epoch 7/10, Batch 50/145, Loss: 0.1110
Epoch 7/10, Batch 60/145, Loss: 0.2103
Epoch 7/10, Batch 70/145, Loss: 0.2079
Epoch 7/10, Batch 80/145, Loss: 0.4437
Epoch 7/10, Batch 90/145, Loss: 0.1573
Epoch 7/10, Batch 100/145, Loss: 0.2038
Epoch 7/10, Batch 110/145, Loss: 0.4004
Epoch 7/10, Batch 120/145, Loss: 0.2364
Epoch 7/10, Batch 130/145, Loss: 0.2086
Epoch 7/10, Batch 140/145, Loss: 0.2027
Epoch 7/10, Train Loss: 0.2104, Valid Loss: 0.2294
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1037
Epoch 8/10, Batch 20/145, Loss: 0.2164
Epoch 8/10, Batch 30/145, Loss: 0.4176
Epoch 8/10, Batch 40/145, Loss: 0.1630
Epoch 8/10, Batch 50/145, Loss: 0.2795
Epoch 8/10, Batch 60/145, Loss: 0.1489
Epoch 8/10, Batch 70/145, Loss: 0.1800
Epoch 8/10, Batch 80/145, Loss: 0.3497
Epoch 8/10, Batch 90/145, Loss: 0.2538
Epoch 8/10, Batch 100/145, Loss: 0.3458
Epoch 8/10, Batch 110/145, Loss: 0.0865
Epoch 8/10, Batch 120/145, Loss: 0.1980
Epoch 8/10, Batch 130/145, Loss: 0.2270
Epoch 8/10, Batch 140/145, Loss: 0.1986
Epoch 8/10, Train Loss: 0.2079, Valid Loss: 0.2261
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2727
Epoch 9/10, Batch 20/145, Loss: 0.1715
Epoch 9/10, Batch 30/145, Loss: 0.1658
Epoch 9/10, Batch 40/145, Loss: 0.1616
Epoch 9/10, Batch 50/145, Loss: 0.1559
Epoch 9/10, Batch 60/145, Loss: 0.1845
Epoch 9/10, Batch 70/145, Loss: 0.1469
Epoch 9/10, Batch 80/145, Loss: 0.1631
Epoch 9/10, Batch 90/145, Loss: 0.2748
Epoch 9/10, Batch 100/145, Loss: 0.1802
Epoch 9/10, Batch 110/145, Loss: 0.2372
Epoch 9/10, Batch 120/145, Loss: 0.1103
Epoch 9/10, Batch 130/145, Loss: 0.0704
Epoch 9/10, Batch 140/145, Loss: 0.3204
Epoch 9/10, Train Loss: 0.1957, Valid Loss: 0.2295
Epoch 10/10, Batch 10/145, Loss: 0.1889
Epoch 10/10, Batch 20/145, Loss: 0.1887
Epoch 10/10, Batch 30/145, Loss: 0.1725
Epoch 10/10, Batch 40/145, Loss: 0.2048
Epoch 10/10, Batch 50/145, Loss: 0.1631
Epoch 10/10, Batch 60/145, Loss: 0.1140
Epoch 10/10, Batch 70/145, Loss: 0.2152
Epoch 10/10, Batch 80/145, Loss: 0.1065
Epoch 10/10, Batch 90/145, Loss: 0.2326
Epoch 10/10, Batch 100/145, Loss: 0.2876
Epoch 10/10, Batch 110/145, Loss: 0.1451
Epoch 10/10, Batch 120/145, Loss: 0.1305
Epoch 10/10, Batch 130/145, Loss: 0.1194
Epoch 10/10, Batch 140/145, Loss: 0.3795
Epoch 10/10, Train Loss: 0.1847, Valid Loss: 0.2220
Model saved!
Accuracy: 0.9206
Precision: 0.9177
Recall: 0.9206
F1-score: 0.9185
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4185
Epoch 1/10, Batch 20/145, Loss: 0.9096
Epoch 1/10, Batch 30/145, Loss: 0.8842
Epoch 1/10, Batch 40/145, Loss: 0.8515
Epoch 1/10, Batch 50/145, Loss: 0.6800
Epoch 1/10, Batch 60/145, Loss: 0.6907
Epoch 1/10, Batch 70/145, Loss: 0.5165
Epoch 1/10, Batch 80/145, Loss: 0.5795
Epoch 1/10, Batch 90/145, Loss: 0.3281
Epoch 1/10, Batch 100/145, Loss: 0.4968
Epoch 1/10, Batch 110/145, Loss: 0.4077
Epoch 1/10, Batch 120/145, Loss: 0.4966
Epoch 1/10, Batch 130/145, Loss: 0.5196
Epoch 1/10, Batch 140/145, Loss: 0.4561
Epoch 1/10, Train Loss: 0.6787, Valid Loss: 0.3991
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4278
Epoch 2/10, Batch 20/145, Loss: 0.4389
Epoch 2/10, Batch 30/145, Loss: 0.3575
Epoch 2/10, Batch 40/145, Loss: 0.4834
Epoch 2/10, Batch 50/145, Loss: 0.4025
Epoch 2/10, Batch 60/145, Loss: 0.4342
Epoch 2/10, Batch 70/145, Loss: 0.3585
Epoch 2/10, Batch 80/145, Loss: 0.2056
Epoch 2/10, Batch 90/145, Loss: 0.4410
Epoch 2/10, Batch 100/145, Loss: 0.2392
Epoch 2/10, Batch 110/145, Loss: 0.3913
Epoch 2/10, Batch 120/145, Loss: 0.4058
Epoch 2/10, Batch 130/145, Loss: 0.3312
Epoch 2/10, Batch 140/145, Loss: 0.2135
Epoch 2/10, Train Loss: 0.3491, Valid Loss: 0.3245
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2928
Epoch 3/10, Batch 20/145, Loss: 0.3283
Epoch 3/10, Batch 30/145, Loss: 0.3111
Epoch 3/10, Batch 40/145, Loss: 0.1554
Epoch 3/10, Batch 50/145, Loss: 0.1766
Epoch 3/10, Batch 60/145, Loss: 0.5039
Epoch 3/10, Batch 70/145, Loss: 0.2857
Epoch 3/10, Batch 80/145, Loss: 0.1738
Epoch 3/10, Batch 90/145, Loss: 0.2459
Epoch 3/10, Batch 100/145, Loss: 0.2079
Epoch 3/10, Batch 110/145, Loss: 0.2551
Epoch 3/10, Batch 120/145, Loss: 0.1657
Epoch 3/10, Batch 130/145, Loss: 0.3531
Epoch 3/10, Batch 140/145, Loss: 0.2337
Epoch 3/10, Train Loss: 0.2887, Valid Loss: 0.2918
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2890
Epoch 4/10, Batch 20/145, Loss: 0.3974
Epoch 4/10, Batch 30/145, Loss: 0.2724
Epoch 4/10, Batch 40/145, Loss: 0.3922
Epoch 4/10, Batch 50/145, Loss: 0.2170
Epoch 4/10, Batch 60/145, Loss: 0.2449
Epoch 4/10, Batch 70/145, Loss: 0.1823
Epoch 4/10, Batch 80/145, Loss: 0.2494
Epoch 4/10, Batch 90/145, Loss: 0.2166
Epoch 4/10, Batch 100/145, Loss: 0.3586
Epoch 4/10, Batch 110/145, Loss: 0.1388
Epoch 4/10, Batch 120/145, Loss: 0.2496
Epoch 4/10, Batch 130/145, Loss: 0.3668
Epoch 4/10, Batch 140/145, Loss: 0.2060
Epoch 4/10, Train Loss: 0.2516, Valid Loss: 0.2788
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2895
Epoch 5/10, Batch 20/145, Loss: 0.2086
Epoch 5/10, Batch 30/145, Loss: 0.2620
Epoch 5/10, Batch 40/145, Loss: 0.1119
Epoch 5/10, Batch 50/145, Loss: 0.1350
Epoch 5/10, Batch 60/145, Loss: 0.2840
Epoch 5/10, Batch 70/145, Loss: 0.2090
Epoch 5/10, Batch 80/145, Loss: 0.2745
Epoch 5/10, Batch 90/145, Loss: 0.2856
Epoch 5/10, Batch 100/145, Loss: 0.3878
Epoch 5/10, Batch 110/145, Loss: 0.3440
Epoch 5/10, Batch 120/145, Loss: 0.2571
Epoch 5/10, Batch 130/145, Loss: 0.1467
Epoch 5/10, Batch 140/145, Loss: 0.1026
Epoch 5/10, Train Loss: 0.2424, Valid Loss: 0.2733
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1191
Epoch 6/10, Batch 20/145, Loss: 0.5158
Epoch 6/10, Batch 30/145, Loss: 0.3002
Epoch 6/10, Batch 40/145, Loss: 0.2169
Epoch 6/10, Batch 50/145, Loss: 0.2100
Epoch 6/10, Batch 60/145, Loss: 0.1673
Epoch 6/10, Batch 70/145, Loss: 0.1397
Epoch 6/10, Batch 80/145, Loss: 0.2346
Epoch 6/10, Batch 90/145, Loss: 0.2623
Epoch 6/10, Batch 100/145, Loss: 0.2840
Epoch 6/10, Batch 110/145, Loss: 0.1721
Epoch 6/10, Batch 120/145, Loss: 0.2176
Epoch 6/10, Batch 130/145, Loss: 0.1136
Epoch 6/10, Batch 140/145, Loss: 0.1345
Epoch 6/10, Train Loss: 0.2259, Valid Loss: 0.2624
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2427
Epoch 7/10, Batch 20/145, Loss: 0.3134
Epoch 7/10, Batch 30/145, Loss: 0.2410
Epoch 7/10, Batch 40/145, Loss: 0.1677
Epoch 7/10, Batch 50/145, Loss: 0.1412
Epoch 7/10, Batch 60/145, Loss: 0.2184
Epoch 7/10, Batch 70/145, Loss: 0.0964
Epoch 7/10, Batch 80/145, Loss: 0.3229
Epoch 7/10, Batch 90/145, Loss: 0.2388
Epoch 7/10, Batch 100/145, Loss: 0.1215
Epoch 7/10, Batch 110/145, Loss: 0.3404
Epoch 7/10, Batch 120/145, Loss: 0.2423
Epoch 7/10, Batch 130/145, Loss: 0.2375
Epoch 7/10, Batch 140/145, Loss: 0.2952
Epoch 7/10, Train Loss: 0.2078, Valid Loss: 0.2585
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2663
Epoch 8/10, Batch 20/145, Loss: 0.1338
Epoch 8/10, Batch 30/145, Loss: 0.1722
Epoch 8/10, Batch 40/145, Loss: 0.1977
Epoch 8/10, Batch 50/145, Loss: 0.1308
Epoch 8/10, Batch 60/145, Loss: 0.1664
Epoch 8/10, Batch 70/145, Loss: 0.1276
Epoch 8/10, Batch 80/145, Loss: 0.3519
Epoch 8/10, Batch 90/145, Loss: 0.2458
Epoch 8/10, Batch 100/145, Loss: 0.0910
Epoch 8/10, Batch 110/145, Loss: 0.1717
Epoch 8/10, Batch 120/145, Loss: 0.3658
Epoch 8/10, Batch 130/145, Loss: 0.1954
Epoch 8/10, Batch 140/145, Loss: 0.1947
Epoch 8/10, Train Loss: 0.1929, Valid Loss: 0.2581
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3339
Epoch 9/10, Batch 20/145, Loss: 0.1705
Epoch 9/10, Batch 30/145, Loss: 0.1974
Epoch 9/10, Batch 40/145, Loss: 0.1944
Epoch 9/10, Batch 50/145, Loss: 0.0947
Epoch 9/10, Batch 60/145, Loss: 0.2612
Epoch 9/10, Batch 70/145, Loss: 0.1929
Epoch 9/10, Batch 80/145, Loss: 0.1412
Epoch 9/10, Batch 90/145, Loss: 0.2233
Epoch 9/10, Batch 100/145, Loss: 0.1176
Epoch 9/10, Batch 110/145, Loss: 0.1099
Epoch 9/10, Batch 120/145, Loss: 0.1811
Epoch 9/10, Batch 130/145, Loss: 0.2046
Epoch 9/10, Batch 140/145, Loss: 0.1458
Epoch 9/10, Train Loss: 0.1907, Valid Loss: 0.2571
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1142
Epoch 10/10, Batch 20/145, Loss: 0.1832
Epoch 10/10, Batch 30/145, Loss: 0.1381
Epoch 10/10, Batch 40/145, Loss: 0.1192
Epoch 10/10, Batch 50/145, Loss: 0.1843
Epoch 10/10, Batch 60/145, Loss: 0.1667
Epoch 10/10, Batch 70/145, Loss: 0.2362
Epoch 10/10, Batch 80/145, Loss: 0.2701
Epoch 10/10, Batch 90/145, Loss: 0.2124
Epoch 10/10, Batch 100/145, Loss: 0.1280
Epoch 10/10, Batch 110/145, Loss: 0.1739
Epoch 10/10, Batch 120/145, Loss: 0.2606
Epoch 10/10, Batch 130/145, Loss: 0.2151
Epoch 10/10, Batch 140/145, Loss: 0.2156
Epoch 10/10, Train Loss: 0.1981, Valid Loss: 0.2550
Model saved!
Accuracy: 0.9264
Precision: 0.9244
Recall: 0.9264
F1-score: 0.9247
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4002
Epoch 1/10, Batch 20/145, Loss: 0.8666
Epoch 1/10, Batch 30/145, Loss: 0.9854
Epoch 1/10, Batch 40/145, Loss: 0.8902
Epoch 1/10, Batch 50/145, Loss: 0.7614
Epoch 1/10, Batch 60/145, Loss: 0.6598
Epoch 1/10, Batch 70/145, Loss: 0.4634
Epoch 1/10, Batch 80/145, Loss: 0.6387
Epoch 1/10, Batch 90/145, Loss: 0.4844
Epoch 1/10, Batch 100/145, Loss: 0.4732
Epoch 1/10, Batch 110/145, Loss: 0.3733
Epoch 1/10, Batch 120/145, Loss: 0.6010
Epoch 1/10, Batch 130/145, Loss: 0.4569
Epoch 1/10, Batch 140/145, Loss: 0.3998
Epoch 1/10, Train Loss: 0.6836, Valid Loss: 0.3781
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2878
Epoch 2/10, Batch 20/145, Loss: 0.3305
Epoch 2/10, Batch 30/145, Loss: 0.2976
Epoch 2/10, Batch 40/145, Loss: 0.3739
Epoch 2/10, Batch 50/145, Loss: 0.4795
Epoch 2/10, Batch 60/145, Loss: 0.3851
Epoch 2/10, Batch 70/145, Loss: 0.3383
Epoch 2/10, Batch 80/145, Loss: 0.3839
Epoch 2/10, Batch 90/145, Loss: 0.2172
Epoch 2/10, Batch 100/145, Loss: 0.2614
Epoch 2/10, Batch 110/145, Loss: 0.3457
Epoch 2/10, Batch 120/145, Loss: 0.5426
Epoch 2/10, Batch 130/145, Loss: 0.3480
Epoch 2/10, Batch 140/145, Loss: 0.3121
Epoch 2/10, Train Loss: 0.3519, Valid Loss: 0.2927
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1962
Epoch 3/10, Batch 20/145, Loss: 0.1790
Epoch 3/10, Batch 30/145, Loss: 0.3582
Epoch 3/10, Batch 40/145, Loss: 0.2521
Epoch 3/10, Batch 50/145, Loss: 0.2126
Epoch 3/10, Batch 60/145, Loss: 0.2987
Epoch 3/10, Batch 70/145, Loss: 0.3977
Epoch 3/10, Batch 80/145, Loss: 0.3048
Epoch 3/10, Batch 90/145, Loss: 0.2270
Epoch 3/10, Batch 100/145, Loss: 0.2252
Epoch 3/10, Batch 110/145, Loss: 0.3550
Epoch 3/10, Batch 120/145, Loss: 0.2704
Epoch 3/10, Batch 130/145, Loss: 0.4170
Epoch 3/10, Batch 140/145, Loss: 0.4021
Epoch 3/10, Train Loss: 0.2976, Valid Loss: 0.2636
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4646
Epoch 4/10, Batch 20/145, Loss: 0.3129
Epoch 4/10, Batch 30/145, Loss: 0.2795
Epoch 4/10, Batch 40/145, Loss: 0.2818
Epoch 4/10, Batch 50/145, Loss: 0.1254
Epoch 4/10, Batch 60/145, Loss: 0.4017
Epoch 4/10, Batch 70/145, Loss: 0.1691
Epoch 4/10, Batch 80/145, Loss: 0.1685
Epoch 4/10, Batch 90/145, Loss: 0.1379
Epoch 4/10, Batch 100/145, Loss: 0.3094
Epoch 4/10, Batch 110/145, Loss: 0.1130
Epoch 4/10, Batch 120/145, Loss: 0.2217
Epoch 4/10, Batch 130/145, Loss: 0.2302
Epoch 4/10, Batch 140/145, Loss: 0.1380
Epoch 4/10, Train Loss: 0.2595, Valid Loss: 0.2471
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2588
Epoch 5/10, Batch 20/145, Loss: 0.2055
Epoch 5/10, Batch 30/145, Loss: 0.2208
Epoch 5/10, Batch 40/145, Loss: 0.1484
Epoch 5/10, Batch 50/145, Loss: 0.1239
Epoch 5/10, Batch 60/145, Loss: 0.1909
Epoch 5/10, Batch 70/145, Loss: 0.1653
Epoch 5/10, Batch 80/145, Loss: 0.1809
Epoch 5/10, Batch 90/145, Loss: 0.1767
Epoch 5/10, Batch 100/145, Loss: 0.2169
Epoch 5/10, Batch 110/145, Loss: 0.2211
Epoch 5/10, Batch 120/145, Loss: 0.2912
Epoch 5/10, Batch 130/145, Loss: 0.1524
Epoch 5/10, Batch 140/145, Loss: 0.1341
Epoch 5/10, Train Loss: 0.2427, Valid Loss: 0.2394
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1866
Epoch 6/10, Batch 20/145, Loss: 0.3664
Epoch 6/10, Batch 30/145, Loss: 0.2850
Epoch 6/10, Batch 40/145, Loss: 0.1753
Epoch 6/10, Batch 50/145, Loss: 0.3934
Epoch 6/10, Batch 60/145, Loss: 0.1609
Epoch 6/10, Batch 70/145, Loss: 0.1373
Epoch 6/10, Batch 80/145, Loss: 0.3189
Epoch 6/10, Batch 90/145, Loss: 0.1859
Epoch 6/10, Batch 100/145, Loss: 0.2145
Epoch 6/10, Batch 110/145, Loss: 0.2024
Epoch 6/10, Batch 120/145, Loss: 0.3012
Epoch 6/10, Batch 130/145, Loss: 0.1249
Epoch 6/10, Batch 140/145, Loss: 0.2143
Epoch 6/10, Train Loss: 0.2328, Valid Loss: 0.2301
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1835
Epoch 7/10, Batch 20/145, Loss: 0.3061
Epoch 7/10, Batch 30/145, Loss: 0.3277
Epoch 7/10, Batch 40/145, Loss: 0.3603
Epoch 7/10, Batch 50/145, Loss: 0.4022
Epoch 7/10, Batch 60/145, Loss: 0.1800
Epoch 7/10, Batch 70/145, Loss: 0.1289
Epoch 7/10, Batch 80/145, Loss: 0.4435
Epoch 7/10, Batch 90/145, Loss: 0.0753
Epoch 7/10, Batch 100/145, Loss: 0.1375
Epoch 7/10, Batch 110/145, Loss: 0.2863
Epoch 7/10, Batch 120/145, Loss: 0.1100
Epoch 7/10, Batch 130/145, Loss: 0.1089
Epoch 7/10, Batch 140/145, Loss: 0.3856
Epoch 7/10, Train Loss: 0.2153, Valid Loss: 0.2245
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2177
Epoch 8/10, Batch 20/145, Loss: 0.2078
Epoch 8/10, Batch 30/145, Loss: 0.3460
Epoch 8/10, Batch 40/145, Loss: 0.1850
Epoch 8/10, Batch 50/145, Loss: 0.2690
Epoch 8/10, Batch 60/145, Loss: 0.2336
Epoch 8/10, Batch 70/145, Loss: 0.1607
Epoch 8/10, Batch 80/145, Loss: 0.2744
Epoch 8/10, Batch 90/145, Loss: 0.1488
Epoch 8/10, Batch 100/145, Loss: 0.3279
Epoch 8/10, Batch 110/145, Loss: 0.1597
Epoch 8/10, Batch 120/145, Loss: 0.2368
Epoch 8/10, Batch 130/145, Loss: 0.2522
Epoch 8/10, Batch 140/145, Loss: 0.2059
Epoch 8/10, Train Loss: 0.2175, Valid Loss: 0.2161
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2458
Epoch 9/10, Batch 20/145, Loss: 0.1800
Epoch 9/10, Batch 30/145, Loss: 0.1305
Epoch 9/10, Batch 40/145, Loss: 0.1567
Epoch 9/10, Batch 50/145, Loss: 0.0965
Epoch 9/10, Batch 60/145, Loss: 0.2748
Epoch 9/10, Batch 70/145, Loss: 0.2277
Epoch 9/10, Batch 80/145, Loss: 0.1396
Epoch 9/10, Batch 90/145, Loss: 0.2734
Epoch 9/10, Batch 100/145, Loss: 0.1735
Epoch 9/10, Batch 110/145, Loss: 0.2627
Epoch 9/10, Batch 120/145, Loss: 0.1309
Epoch 9/10, Batch 130/145, Loss: 0.1030
Epoch 9/10, Batch 140/145, Loss: 0.1822
Epoch 9/10, Train Loss: 0.2053, Valid Loss: 0.2169
Epoch 10/10, Batch 10/145, Loss: 0.1211
Epoch 10/10, Batch 20/145, Loss: 0.1314
Epoch 10/10, Batch 30/145, Loss: 0.1062
Epoch 10/10, Batch 40/145, Loss: 0.2657
Epoch 10/10, Batch 50/145, Loss: 0.2158
Epoch 10/10, Batch 60/145, Loss: 0.0827
Epoch 10/10, Batch 70/145, Loss: 0.2697
Epoch 10/10, Batch 80/145, Loss: 0.1765
Epoch 10/10, Batch 90/145, Loss: 0.2780
Epoch 10/10, Batch 100/145, Loss: 0.1363
Epoch 10/10, Batch 110/145, Loss: 0.1181
Epoch 10/10, Batch 120/145, Loss: 0.1364
Epoch 10/10, Batch 130/145, Loss: 0.1260
Epoch 10/10, Batch 140/145, Loss: 0.0873
Epoch 10/10, Train Loss: 0.1938, Valid Loss: 0.2119
Model saved!
Accuracy: 0.9124
Precision: 0.9091
Recall: 0.9124
F1-score: 0.9087
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4415
Epoch 1/10, Batch 20/145, Loss: 0.9307
Epoch 1/10, Batch 30/145, Loss: 0.9417
Epoch 1/10, Batch 40/145, Loss: 0.6748
Epoch 1/10, Batch 50/145, Loss: 0.6183
Epoch 1/10, Batch 60/145, Loss: 0.6200
Epoch 1/10, Batch 70/145, Loss: 0.6078
Epoch 1/10, Batch 80/145, Loss: 0.5824
Epoch 1/10, Batch 90/145, Loss: 0.4233
Epoch 1/10, Batch 100/145, Loss: 0.4613
Epoch 1/10, Batch 110/145, Loss: 0.5370
Epoch 1/10, Batch 120/145, Loss: 0.8037
Epoch 1/10, Batch 130/145, Loss: 0.5249
Epoch 1/10, Batch 140/145, Loss: 0.3348
Epoch 1/10, Train Loss: 0.6782, Valid Loss: 0.3725
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2976
Epoch 2/10, Batch 20/145, Loss: 0.3977
Epoch 2/10, Batch 30/145, Loss: 0.3589
Epoch 2/10, Batch 40/145, Loss: 0.4406
Epoch 2/10, Batch 50/145, Loss: 0.3809
Epoch 2/10, Batch 60/145, Loss: 0.3818
Epoch 2/10, Batch 70/145, Loss: 0.3266
Epoch 2/10, Batch 80/145, Loss: 0.3766
Epoch 2/10, Batch 90/145, Loss: 0.4616
Epoch 2/10, Batch 100/145, Loss: 0.3707
Epoch 2/10, Batch 110/145, Loss: 0.3830
Epoch 2/10, Batch 120/145, Loss: 0.3580
Epoch 2/10, Batch 130/145, Loss: 0.2906
Epoch 2/10, Batch 140/145, Loss: 0.2425
Epoch 2/10, Train Loss: 0.3534, Valid Loss: 0.2907
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3205
Epoch 3/10, Batch 20/145, Loss: 0.2960
Epoch 3/10, Batch 30/145, Loss: 0.3214
Epoch 3/10, Batch 40/145, Loss: 0.2556
Epoch 3/10, Batch 50/145, Loss: 0.3290
Epoch 3/10, Batch 60/145, Loss: 0.3134
Epoch 3/10, Batch 70/145, Loss: 0.3849
Epoch 3/10, Batch 80/145, Loss: 0.3131
Epoch 3/10, Batch 90/145, Loss: 0.3018
Epoch 3/10, Batch 100/145, Loss: 0.2001
Epoch 3/10, Batch 110/145, Loss: 0.5124
Epoch 3/10, Batch 120/145, Loss: 0.2284
Epoch 3/10, Batch 130/145, Loss: 0.3318
Epoch 3/10, Batch 140/145, Loss: 0.3330
Epoch 3/10, Train Loss: 0.2960, Valid Loss: 0.2538
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3693
Epoch 4/10, Batch 20/145, Loss: 0.2406
Epoch 4/10, Batch 30/145, Loss: 0.3433
Epoch 4/10, Batch 40/145, Loss: 0.2667
Epoch 4/10, Batch 50/145, Loss: 0.1452
Epoch 4/10, Batch 60/145, Loss: 0.1395
Epoch 4/10, Batch 70/145, Loss: 0.1702
Epoch 4/10, Batch 80/145, Loss: 0.2426
Epoch 4/10, Batch 90/145, Loss: 0.2602
Epoch 4/10, Batch 100/145, Loss: 0.2691
Epoch 4/10, Batch 110/145, Loss: 0.1633
Epoch 4/10, Batch 120/145, Loss: 0.2094
Epoch 4/10, Batch 130/145, Loss: 0.3279
Epoch 4/10, Batch 140/145, Loss: 0.1343
Epoch 4/10, Train Loss: 0.2543, Valid Loss: 0.2434
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1601
Epoch 5/10, Batch 20/145, Loss: 0.0910
Epoch 5/10, Batch 30/145, Loss: 0.3835
Epoch 5/10, Batch 40/145, Loss: 0.2593
Epoch 5/10, Batch 50/145, Loss: 0.3021
Epoch 5/10, Batch 60/145, Loss: 0.3129
Epoch 5/10, Batch 70/145, Loss: 0.3187
Epoch 5/10, Batch 80/145, Loss: 0.1762
Epoch 5/10, Batch 90/145, Loss: 0.3566
Epoch 5/10, Batch 100/145, Loss: 0.3103
Epoch 5/10, Batch 110/145, Loss: 0.1949
Epoch 5/10, Batch 120/145, Loss: 0.2452
Epoch 5/10, Batch 130/145, Loss: 0.1678
Epoch 5/10, Batch 140/145, Loss: 0.1632
Epoch 5/10, Train Loss: 0.2472, Valid Loss: 0.2351
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1334
Epoch 6/10, Batch 20/145, Loss: 0.4821
Epoch 6/10, Batch 30/145, Loss: 0.1996
Epoch 6/10, Batch 40/145, Loss: 0.1192
Epoch 6/10, Batch 50/145, Loss: 0.3742
Epoch 6/10, Batch 60/145, Loss: 0.1835
Epoch 6/10, Batch 70/145, Loss: 0.1135
Epoch 6/10, Batch 80/145, Loss: 0.2333
Epoch 6/10, Batch 90/145, Loss: 0.3399
Epoch 6/10, Batch 100/145, Loss: 0.2662
Epoch 6/10, Batch 110/145, Loss: 0.1754
Epoch 6/10, Batch 120/145, Loss: 0.2569
Epoch 6/10, Batch 130/145, Loss: 0.1367
Epoch 6/10, Batch 140/145, Loss: 0.1253
Epoch 6/10, Train Loss: 0.2259, Valid Loss: 0.2244
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3132
Epoch 7/10, Batch 20/145, Loss: 0.2149
Epoch 7/10, Batch 30/145, Loss: 0.3316
Epoch 7/10, Batch 40/145, Loss: 0.3464
Epoch 7/10, Batch 50/145, Loss: 0.1338
Epoch 7/10, Batch 60/145, Loss: 0.1719
Epoch 7/10, Batch 70/145, Loss: 0.1090
Epoch 7/10, Batch 80/145, Loss: 0.4023
Epoch 7/10, Batch 90/145, Loss: 0.1462
Epoch 7/10, Batch 100/145, Loss: 0.2200
Epoch 7/10, Batch 110/145, Loss: 0.1229
Epoch 7/10, Batch 120/145, Loss: 0.3744
Epoch 7/10, Batch 130/145, Loss: 0.2107
Epoch 7/10, Batch 140/145, Loss: 0.1216
Epoch 7/10, Train Loss: 0.2098, Valid Loss: 0.2206
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1724
Epoch 8/10, Batch 20/145, Loss: 0.3413
Epoch 8/10, Batch 30/145, Loss: 0.3370
Epoch 8/10, Batch 40/145, Loss: 0.1283
Epoch 8/10, Batch 50/145, Loss: 0.2784
Epoch 8/10, Batch 60/145, Loss: 0.3823
Epoch 8/10, Batch 70/145, Loss: 0.1672
Epoch 8/10, Batch 80/145, Loss: 0.2330
Epoch 8/10, Batch 90/145, Loss: 0.1841
Epoch 8/10, Batch 100/145, Loss: 0.3317
Epoch 8/10, Batch 110/145, Loss: 0.1551
Epoch 8/10, Batch 120/145, Loss: 0.2923
Epoch 8/10, Batch 130/145, Loss: 0.1375
Epoch 8/10, Batch 140/145, Loss: 0.1369
Epoch 8/10, Train Loss: 0.2077, Valid Loss: 0.2132
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2921
Epoch 9/10, Batch 20/145, Loss: 0.3761
Epoch 9/10, Batch 30/145, Loss: 0.2288
Epoch 9/10, Batch 40/145, Loss: 0.1719
Epoch 9/10, Batch 50/145, Loss: 0.2214
Epoch 9/10, Batch 60/145, Loss: 0.1611
Epoch 9/10, Batch 70/145, Loss: 0.2427
Epoch 9/10, Batch 80/145, Loss: 0.0854
Epoch 9/10, Batch 90/145, Loss: 0.2378
Epoch 9/10, Batch 100/145, Loss: 0.2888
Epoch 9/10, Batch 110/145, Loss: 0.2523
Epoch 9/10, Batch 120/145, Loss: 0.2053
Epoch 9/10, Batch 130/145, Loss: 0.1828
Epoch 9/10, Batch 140/145, Loss: 0.1943
Epoch 9/10, Train Loss: 0.1977, Valid Loss: 0.2096
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1250
Epoch 10/10, Batch 20/145, Loss: 0.2002
Epoch 10/10, Batch 30/145, Loss: 0.1140
Epoch 10/10, Batch 40/145, Loss: 0.1635
Epoch 10/10, Batch 50/145, Loss: 0.1876
Epoch 10/10, Batch 60/145, Loss: 0.0757
Epoch 10/10, Batch 70/145, Loss: 0.3262
Epoch 10/10, Batch 80/145, Loss: 0.1855
Epoch 10/10, Batch 90/145, Loss: 0.2302
Epoch 10/10, Batch 100/145, Loss: 0.3390
Epoch 10/10, Batch 110/145, Loss: 0.2088
Epoch 10/10, Batch 120/145, Loss: 0.3298
Epoch 10/10, Batch 130/145, Loss: 0.1699
Epoch 10/10, Batch 140/145, Loss: 0.1281
Epoch 10/10, Train Loss: 0.1981, Valid Loss: 0.2093
Model saved!
Accuracy: 0.9206
Precision: 0.9188
Recall: 0.9206
F1-score: 0.9190
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4460
Epoch 1/10, Batch 20/145, Loss: 0.8848
Epoch 1/10, Batch 30/145, Loss: 0.8411
Epoch 1/10, Batch 40/145, Loss: 0.8531
Epoch 1/10, Batch 50/145, Loss: 0.8283
Epoch 1/10, Batch 60/145, Loss: 0.6630
Epoch 1/10, Batch 70/145, Loss: 0.3927
Epoch 1/10, Batch 80/145, Loss: 0.5174
Epoch 1/10, Batch 90/145, Loss: 0.4391
Epoch 1/10, Batch 100/145, Loss: 0.6114
Epoch 1/10, Batch 110/145, Loss: 0.4726
Epoch 1/10, Batch 120/145, Loss: 0.5843
Epoch 1/10, Batch 130/145, Loss: 0.5570
Epoch 1/10, Batch 140/145, Loss: 0.4828
Epoch 1/10, Train Loss: 0.6846, Valid Loss: 0.3746
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2863
Epoch 2/10, Batch 20/145, Loss: 0.4193
Epoch 2/10, Batch 30/145, Loss: 0.3143
Epoch 2/10, Batch 40/145, Loss: 0.4602
Epoch 2/10, Batch 50/145, Loss: 0.4768
Epoch 2/10, Batch 60/145, Loss: 0.3610
Epoch 2/10, Batch 70/145, Loss: 0.3522
Epoch 2/10, Batch 80/145, Loss: 0.3921
Epoch 2/10, Batch 90/145, Loss: 0.3500
Epoch 2/10, Batch 100/145, Loss: 0.1953
Epoch 2/10, Batch 110/145, Loss: 0.3287
Epoch 2/10, Batch 120/145, Loss: 0.3424
Epoch 2/10, Batch 130/145, Loss: 0.2762
Epoch 2/10, Batch 140/145, Loss: 0.3151
Epoch 2/10, Train Loss: 0.3607, Valid Loss: 0.2993
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2745
Epoch 3/10, Batch 20/145, Loss: 0.2175
Epoch 3/10, Batch 30/145, Loss: 0.4051
Epoch 3/10, Batch 40/145, Loss: 0.2379
Epoch 3/10, Batch 50/145, Loss: 0.2888
Epoch 3/10, Batch 60/145, Loss: 0.4037
Epoch 3/10, Batch 70/145, Loss: 0.4759
Epoch 3/10, Batch 80/145, Loss: 0.2136
Epoch 3/10, Batch 90/145, Loss: 0.3065
Epoch 3/10, Batch 100/145, Loss: 0.3120
Epoch 3/10, Batch 110/145, Loss: 0.2980
Epoch 3/10, Batch 120/145, Loss: 0.3041
Epoch 3/10, Batch 130/145, Loss: 0.4100
Epoch 3/10, Batch 140/145, Loss: 0.4233
Epoch 3/10, Train Loss: 0.2963, Valid Loss: 0.2569
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2506
Epoch 4/10, Batch 20/145, Loss: 0.3500
Epoch 4/10, Batch 30/145, Loss: 0.2051
Epoch 4/10, Batch 40/145, Loss: 0.3667
Epoch 4/10, Batch 50/145, Loss: 0.2454
Epoch 4/10, Batch 60/145, Loss: 0.2806
Epoch 4/10, Batch 70/145, Loss: 0.3366
Epoch 4/10, Batch 80/145, Loss: 0.1156
Epoch 4/10, Batch 90/145, Loss: 0.2741
Epoch 4/10, Batch 100/145, Loss: 0.4487
Epoch 4/10, Batch 110/145, Loss: 0.2579
Epoch 4/10, Batch 120/145, Loss: 0.1313
Epoch 4/10, Batch 130/145, Loss: 0.3076
Epoch 4/10, Batch 140/145, Loss: 0.1992
Epoch 4/10, Train Loss: 0.2630, Valid Loss: 0.2499
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1911
Epoch 5/10, Batch 20/145, Loss: 0.1075
Epoch 5/10, Batch 30/145, Loss: 0.2746
Epoch 5/10, Batch 40/145, Loss: 0.2040
Epoch 5/10, Batch 50/145, Loss: 0.2858
Epoch 5/10, Batch 60/145, Loss: 0.2391
Epoch 5/10, Batch 70/145, Loss: 0.2059
Epoch 5/10, Batch 80/145, Loss: 0.2871
Epoch 5/10, Batch 90/145, Loss: 0.1958
Epoch 5/10, Batch 100/145, Loss: 0.4066
Epoch 5/10, Batch 110/145, Loss: 0.1946
Epoch 5/10, Batch 120/145, Loss: 0.3268
Epoch 5/10, Batch 130/145, Loss: 0.2766
Epoch 5/10, Batch 140/145, Loss: 0.4189
Epoch 5/10, Train Loss: 0.2534, Valid Loss: 0.2387
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2057
Epoch 6/10, Batch 20/145, Loss: 0.3702
Epoch 6/10, Batch 30/145, Loss: 0.2104
Epoch 6/10, Batch 40/145, Loss: 0.1643
Epoch 6/10, Batch 50/145, Loss: 0.3648
Epoch 6/10, Batch 60/145, Loss: 0.1485
Epoch 6/10, Batch 70/145, Loss: 0.1767
Epoch 6/10, Batch 80/145, Loss: 0.1203
Epoch 6/10, Batch 90/145, Loss: 0.2865
Epoch 6/10, Batch 100/145, Loss: 0.2425
Epoch 6/10, Batch 110/145, Loss: 0.2336
Epoch 6/10, Batch 120/145, Loss: 0.2011
Epoch 6/10, Batch 130/145, Loss: 0.1449
Epoch 6/10, Batch 140/145, Loss: 0.2050
Epoch 6/10, Train Loss: 0.2315, Valid Loss: 0.2334
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2310
Epoch 7/10, Batch 20/145, Loss: 0.3198
Epoch 7/10, Batch 30/145, Loss: 0.3067
Epoch 7/10, Batch 40/145, Loss: 0.4273
Epoch 7/10, Batch 50/145, Loss: 0.1838
Epoch 7/10, Batch 60/145, Loss: 0.2157
Epoch 7/10, Batch 70/145, Loss: 0.1822
Epoch 7/10, Batch 80/145, Loss: 0.3286
Epoch 7/10, Batch 90/145, Loss: 0.0954
Epoch 7/10, Batch 100/145, Loss: 0.1956
Epoch 7/10, Batch 110/145, Loss: 0.0905
Epoch 7/10, Batch 120/145, Loss: 0.2534
Epoch 7/10, Batch 130/145, Loss: 0.1619
Epoch 7/10, Batch 140/145, Loss: 0.1099
Epoch 7/10, Train Loss: 0.2202, Valid Loss: 0.2181
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1680
Epoch 8/10, Batch 20/145, Loss: 0.1953
Epoch 8/10, Batch 30/145, Loss: 0.2664
Epoch 8/10, Batch 40/145, Loss: 0.0677
Epoch 8/10, Batch 50/145, Loss: 0.3730
Epoch 8/10, Batch 60/145, Loss: 0.1478
Epoch 8/10, Batch 70/145, Loss: 0.3273
Epoch 8/10, Batch 80/145, Loss: 0.2085
Epoch 8/10, Batch 90/145, Loss: 0.2146
Epoch 8/10, Batch 100/145, Loss: 0.4697
Epoch 8/10, Batch 110/145, Loss: 0.2237
Epoch 8/10, Batch 120/145, Loss: 0.3359
Epoch 8/10, Batch 130/145, Loss: 0.3219
Epoch 8/10, Batch 140/145, Loss: 0.3473
Epoch 8/10, Train Loss: 0.2173, Valid Loss: 0.2174
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3185
Epoch 9/10, Batch 20/145, Loss: 0.1217
Epoch 9/10, Batch 30/145, Loss: 0.1420
Epoch 9/10, Batch 40/145, Loss: 0.1895
Epoch 9/10, Batch 50/145, Loss: 0.1632
Epoch 9/10, Batch 60/145, Loss: 0.3943
Epoch 9/10, Batch 70/145, Loss: 0.2237
Epoch 9/10, Batch 80/145, Loss: 0.1417
Epoch 9/10, Batch 90/145, Loss: 0.1043
Epoch 9/10, Batch 100/145, Loss: 0.1334
Epoch 9/10, Batch 110/145, Loss: 0.3167
Epoch 9/10, Batch 120/145, Loss: 0.1292
Epoch 9/10, Batch 130/145, Loss: 0.2660
Epoch 9/10, Batch 140/145, Loss: 0.3320
Epoch 9/10, Train Loss: 0.2123, Valid Loss: 0.2152
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1312
Epoch 10/10, Batch 20/145, Loss: 0.1346
Epoch 10/10, Batch 30/145, Loss: 0.1931
Epoch 10/10, Batch 40/145, Loss: 0.1384
Epoch 10/10, Batch 50/145, Loss: 0.1711
Epoch 10/10, Batch 60/145, Loss: 0.1118
Epoch 10/10, Batch 70/145, Loss: 0.2685
Epoch 10/10, Batch 80/145, Loss: 0.1696
Epoch 10/10, Batch 90/145, Loss: 0.1955
Epoch 10/10, Batch 100/145, Loss: 0.1946
Epoch 10/10, Batch 110/145, Loss: 0.2022
Epoch 10/10, Batch 120/145, Loss: 0.1978
Epoch 10/10, Batch 130/145, Loss: 0.2661
Epoch 10/10, Batch 140/145, Loss: 0.1681
Epoch 10/10, Train Loss: 0.1962, Valid Loss: 0.2098
Model saved!
Accuracy: 0.9276
Precision: 0.9258
Recall: 0.9276
F1-score: 0.9265
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3807
Epoch 1/10, Batch 20/145, Loss: 0.9082
Epoch 1/10, Batch 30/145, Loss: 0.8603
Epoch 1/10, Batch 40/145, Loss: 0.8095
Epoch 1/10, Batch 50/145, Loss: 0.7227
Epoch 1/10, Batch 60/145, Loss: 0.5120
Epoch 1/10, Batch 70/145, Loss: 0.4057
Epoch 1/10, Batch 80/145, Loss: 0.6096
Epoch 1/10, Batch 90/145, Loss: 0.2898
Epoch 1/10, Batch 100/145, Loss: 0.6225
Epoch 1/10, Batch 110/145, Loss: 0.3743
Epoch 1/10, Batch 120/145, Loss: 0.5770
Epoch 1/10, Batch 130/145, Loss: 0.4738
Epoch 1/10, Batch 140/145, Loss: 0.4538
Epoch 1/10, Train Loss: 0.6876, Valid Loss: 0.3839
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3698
Epoch 2/10, Batch 20/145, Loss: 0.3931
Epoch 2/10, Batch 30/145, Loss: 0.3104
Epoch 2/10, Batch 40/145, Loss: 0.3371
Epoch 2/10, Batch 50/145, Loss: 0.3421
Epoch 2/10, Batch 60/145, Loss: 0.4105
Epoch 2/10, Batch 70/145, Loss: 0.3725
Epoch 2/10, Batch 80/145, Loss: 0.2315
Epoch 2/10, Batch 90/145, Loss: 0.2653
Epoch 2/10, Batch 100/145, Loss: 0.3978
Epoch 2/10, Batch 110/145, Loss: 0.3885
Epoch 2/10, Batch 120/145, Loss: 0.4022
Epoch 2/10, Batch 130/145, Loss: 0.1524
Epoch 2/10, Batch 140/145, Loss: 0.3539
Epoch 2/10, Train Loss: 0.3628, Valid Loss: 0.2916
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2227
Epoch 3/10, Batch 20/145, Loss: 0.2073
Epoch 3/10, Batch 30/145, Loss: 0.4588
Epoch 3/10, Batch 40/145, Loss: 0.3998
Epoch 3/10, Batch 50/145, Loss: 0.3382
Epoch 3/10, Batch 60/145, Loss: 0.4372
Epoch 3/10, Batch 70/145, Loss: 0.2799
Epoch 3/10, Batch 80/145, Loss: 0.2831
Epoch 3/10, Batch 90/145, Loss: 0.3043
Epoch 3/10, Batch 100/145, Loss: 0.3769
Epoch 3/10, Batch 110/145, Loss: 0.1962
Epoch 3/10, Batch 120/145, Loss: 0.3143
Epoch 3/10, Batch 130/145, Loss: 0.3264
Epoch 3/10, Batch 140/145, Loss: 0.2789
Epoch 3/10, Train Loss: 0.3037, Valid Loss: 0.2539
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3539
Epoch 4/10, Batch 20/145, Loss: 0.3019
Epoch 4/10, Batch 30/145, Loss: 0.3019
Epoch 4/10, Batch 40/145, Loss: 0.2764
Epoch 4/10, Batch 50/145, Loss: 0.2309
Epoch 4/10, Batch 60/145, Loss: 0.3765
Epoch 4/10, Batch 70/145, Loss: 0.1550
Epoch 4/10, Batch 80/145, Loss: 0.2585
Epoch 4/10, Batch 90/145, Loss: 0.1606
Epoch 4/10, Batch 100/145, Loss: 0.4293
Epoch 4/10, Batch 110/145, Loss: 0.2471
Epoch 4/10, Batch 120/145, Loss: 0.1544
Epoch 4/10, Batch 130/145, Loss: 0.2185
Epoch 4/10, Batch 140/145, Loss: 0.1183
Epoch 4/10, Train Loss: 0.2667, Valid Loss: 0.2359
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2138
Epoch 5/10, Batch 20/145, Loss: 0.2364
Epoch 5/10, Batch 30/145, Loss: 0.3732
Epoch 5/10, Batch 40/145, Loss: 0.1516
Epoch 5/10, Batch 50/145, Loss: 0.1959
Epoch 5/10, Batch 60/145, Loss: 0.2433
Epoch 5/10, Batch 70/145, Loss: 0.1637
Epoch 5/10, Batch 80/145, Loss: 0.1921
Epoch 5/10, Batch 90/145, Loss: 0.3686
Epoch 5/10, Batch 100/145, Loss: 0.1807
Epoch 5/10, Batch 110/145, Loss: 0.3647
Epoch 5/10, Batch 120/145, Loss: 0.2410
Epoch 5/10, Batch 130/145, Loss: 0.2853
Epoch 5/10, Batch 140/145, Loss: 0.1220
Epoch 5/10, Train Loss: 0.2552, Valid Loss: 0.2285
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1475
Epoch 6/10, Batch 20/145, Loss: 0.5047
Epoch 6/10, Batch 30/145, Loss: 0.3351
Epoch 6/10, Batch 40/145, Loss: 0.3333
Epoch 6/10, Batch 50/145, Loss: 0.2971
Epoch 6/10, Batch 60/145, Loss: 0.4066
Epoch 6/10, Batch 70/145, Loss: 0.1297
Epoch 6/10, Batch 80/145, Loss: 0.1174
Epoch 6/10, Batch 90/145, Loss: 0.2997
Epoch 6/10, Batch 100/145, Loss: 0.3871
Epoch 6/10, Batch 110/145, Loss: 0.2896
Epoch 6/10, Batch 120/145, Loss: 0.2900
Epoch 6/10, Batch 130/145, Loss: 0.1905
Epoch 6/10, Batch 140/145, Loss: 0.2140
Epoch 6/10, Train Loss: 0.2400, Valid Loss: 0.2215
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2777
Epoch 7/10, Batch 20/145, Loss: 0.2788
Epoch 7/10, Batch 30/145, Loss: 0.1868
Epoch 7/10, Batch 40/145, Loss: 0.3276
Epoch 7/10, Batch 50/145, Loss: 0.1288
Epoch 7/10, Batch 60/145, Loss: 0.1572
Epoch 7/10, Batch 70/145, Loss: 0.3172
Epoch 7/10, Batch 80/145, Loss: 0.3811
Epoch 7/10, Batch 90/145, Loss: 0.2709
Epoch 7/10, Batch 100/145, Loss: 0.1823
Epoch 7/10, Batch 110/145, Loss: 0.0846
Epoch 7/10, Batch 120/145, Loss: 0.2800
Epoch 7/10, Batch 130/145, Loss: 0.2302
Epoch 7/10, Batch 140/145, Loss: 0.2077
Epoch 7/10, Train Loss: 0.2228, Valid Loss: 0.2118
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1709
Epoch 8/10, Batch 20/145, Loss: 0.2785
Epoch 8/10, Batch 30/145, Loss: 0.3872
Epoch 8/10, Batch 40/145, Loss: 0.2166
Epoch 8/10, Batch 50/145, Loss: 0.2806
Epoch 8/10, Batch 60/145, Loss: 0.1697
Epoch 8/10, Batch 70/145, Loss: 0.2941
Epoch 8/10, Batch 80/145, Loss: 0.1321
Epoch 8/10, Batch 90/145, Loss: 0.2903
Epoch 8/10, Batch 100/145, Loss: 0.1713
Epoch 8/10, Batch 110/145, Loss: 0.3055
Epoch 8/10, Batch 120/145, Loss: 0.1586
Epoch 8/10, Batch 130/145, Loss: 0.3530
Epoch 8/10, Batch 140/145, Loss: 0.1545
Epoch 8/10, Train Loss: 0.2141, Valid Loss: 0.2064
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1967
Epoch 9/10, Batch 20/145, Loss: 0.2403
Epoch 9/10, Batch 30/145, Loss: 0.1560
Epoch 9/10, Batch 40/145, Loss: 0.3413
Epoch 9/10, Batch 50/145, Loss: 0.1170
Epoch 9/10, Batch 60/145, Loss: 0.1860
Epoch 9/10, Batch 70/145, Loss: 0.2619
Epoch 9/10, Batch 80/145, Loss: 0.1099
Epoch 9/10, Batch 90/145, Loss: 0.3527
Epoch 9/10, Batch 100/145, Loss: 0.2638
Epoch 9/10, Batch 110/145, Loss: 0.4039
Epoch 9/10, Batch 120/145, Loss: 0.1259
Epoch 9/10, Batch 130/145, Loss: 0.2639
Epoch 9/10, Batch 140/145, Loss: 0.3623
Epoch 9/10, Train Loss: 0.2102, Valid Loss: 0.2060
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1947
Epoch 10/10, Batch 20/145, Loss: 0.1979
Epoch 10/10, Batch 30/145, Loss: 0.0877
Epoch 10/10, Batch 40/145, Loss: 0.0729
Epoch 10/10, Batch 50/145, Loss: 0.1199
Epoch 10/10, Batch 60/145, Loss: 0.2470
Epoch 10/10, Batch 70/145, Loss: 0.2783
Epoch 10/10, Batch 80/145, Loss: 0.1972
Epoch 10/10, Batch 90/145, Loss: 0.3003
Epoch 10/10, Batch 100/145, Loss: 0.1104
Epoch 10/10, Batch 110/145, Loss: 0.2118
Epoch 10/10, Batch 120/145, Loss: 0.2812
Epoch 10/10, Batch 130/145, Loss: 0.1268
Epoch 10/10, Batch 140/145, Loss: 0.5376
Epoch 10/10, Train Loss: 0.2072, Valid Loss: 0.2065
Accuracy: 0.9171
Precision: 0.9149
Recall: 0.9171
F1-score: 0.9154
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3574
Epoch 1/10, Batch 20/145, Loss: 0.8855
Epoch 1/10, Batch 30/145, Loss: 1.0312
Epoch 1/10, Batch 40/145, Loss: 0.8936
Epoch 1/10, Batch 50/145, Loss: 0.6388
Epoch 1/10, Batch 60/145, Loss: 0.6371
Epoch 1/10, Batch 70/145, Loss: 0.4390
Epoch 1/10, Batch 80/145, Loss: 0.5087
Epoch 1/10, Batch 90/145, Loss: 0.4762
Epoch 1/10, Batch 100/145, Loss: 0.4967
Epoch 1/10, Batch 110/145, Loss: 0.5198
Epoch 1/10, Batch 120/145, Loss: 0.6965
Epoch 1/10, Batch 130/145, Loss: 0.5054
Epoch 1/10, Batch 140/145, Loss: 0.3766
Epoch 1/10, Train Loss: 0.6709, Valid Loss: 0.3866
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3443
Epoch 2/10, Batch 20/145, Loss: 0.3883
Epoch 2/10, Batch 30/145, Loss: 0.2609
Epoch 2/10, Batch 40/145, Loss: 0.4595
Epoch 2/10, Batch 50/145, Loss: 0.2782
Epoch 2/10, Batch 60/145, Loss: 0.3109
Epoch 2/10, Batch 70/145, Loss: 0.2522
Epoch 2/10, Batch 80/145, Loss: 0.3311
Epoch 2/10, Batch 90/145, Loss: 0.3288
Epoch 2/10, Batch 100/145, Loss: 0.2774
Epoch 2/10, Batch 110/145, Loss: 0.3640
Epoch 2/10, Batch 120/145, Loss: 0.4264
Epoch 2/10, Batch 130/145, Loss: 0.2349
Epoch 2/10, Batch 140/145, Loss: 0.4074
Epoch 2/10, Train Loss: 0.3451, Valid Loss: 0.3059
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2435
Epoch 3/10, Batch 20/145, Loss: 0.2890
Epoch 3/10, Batch 30/145, Loss: 0.3841
Epoch 3/10, Batch 40/145, Loss: 0.1753
Epoch 3/10, Batch 50/145, Loss: 0.2621
Epoch 3/10, Batch 60/145, Loss: 0.3094
Epoch 3/10, Batch 70/145, Loss: 0.4947
Epoch 3/10, Batch 80/145, Loss: 0.2191
Epoch 3/10, Batch 90/145, Loss: 0.3884
Epoch 3/10, Batch 100/145, Loss: 0.1930
Epoch 3/10, Batch 110/145, Loss: 0.3341
Epoch 3/10, Batch 120/145, Loss: 0.2089
Epoch 3/10, Batch 130/145, Loss: 0.3312
Epoch 3/10, Batch 140/145, Loss: 0.1918
Epoch 3/10, Train Loss: 0.2861, Valid Loss: 0.2698
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3433
Epoch 4/10, Batch 20/145, Loss: 0.1627
Epoch 4/10, Batch 30/145, Loss: 0.3339
Epoch 4/10, Batch 40/145, Loss: 0.1709
Epoch 4/10, Batch 50/145, Loss: 0.3015
Epoch 4/10, Batch 60/145, Loss: 0.2266
Epoch 4/10, Batch 70/145, Loss: 0.3146
Epoch 4/10, Batch 80/145, Loss: 0.2003
Epoch 4/10, Batch 90/145, Loss: 0.1993
Epoch 4/10, Batch 100/145, Loss: 0.2519
Epoch 4/10, Batch 110/145, Loss: 0.2751
Epoch 4/10, Batch 120/145, Loss: 0.3053
Epoch 4/10, Batch 130/145, Loss: 0.1397
Epoch 4/10, Batch 140/145, Loss: 0.1276
Epoch 4/10, Train Loss: 0.2524, Valid Loss: 0.2573
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1473
Epoch 5/10, Batch 20/145, Loss: 0.1851
Epoch 5/10, Batch 30/145, Loss: 0.1453
Epoch 5/10, Batch 40/145, Loss: 0.1280
Epoch 5/10, Batch 50/145, Loss: 0.2130
Epoch 5/10, Batch 60/145, Loss: 0.2746
Epoch 5/10, Batch 70/145, Loss: 0.3014
Epoch 5/10, Batch 80/145, Loss: 0.1821
Epoch 5/10, Batch 90/145, Loss: 0.2130
Epoch 5/10, Batch 100/145, Loss: 0.2550
Epoch 5/10, Batch 110/145, Loss: 0.3164
Epoch 5/10, Batch 120/145, Loss: 0.3329
Epoch 5/10, Batch 130/145, Loss: 0.1559
Epoch 5/10, Batch 140/145, Loss: 0.2067
Epoch 5/10, Train Loss: 0.2345, Valid Loss: 0.2573
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1499
Epoch 6/10, Batch 20/145, Loss: 0.3685
Epoch 6/10, Batch 30/145, Loss: 0.1956
Epoch 6/10, Batch 40/145, Loss: 0.1726
Epoch 6/10, Batch 50/145, Loss: 0.2577
Epoch 6/10, Batch 60/145, Loss: 0.1988
Epoch 6/10, Batch 70/145, Loss: 0.1402
Epoch 6/10, Batch 80/145, Loss: 0.1349
Epoch 6/10, Batch 90/145, Loss: 0.1683
Epoch 6/10, Batch 100/145, Loss: 0.2435
Epoch 6/10, Batch 110/145, Loss: 0.4237
Epoch 6/10, Batch 120/145, Loss: 0.2307
Epoch 6/10, Batch 130/145, Loss: 0.1974
Epoch 6/10, Batch 140/145, Loss: 0.2263
Epoch 6/10, Train Loss: 0.2205, Valid Loss: 0.2433
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3355
Epoch 7/10, Batch 20/145, Loss: 0.1957
Epoch 7/10, Batch 30/145, Loss: 0.1741
Epoch 7/10, Batch 40/145, Loss: 0.4063
Epoch 7/10, Batch 50/145, Loss: 0.1255
Epoch 7/10, Batch 60/145, Loss: 0.1148
Epoch 7/10, Batch 70/145, Loss: 0.1410
Epoch 7/10, Batch 80/145, Loss: 0.2322
Epoch 7/10, Batch 90/145, Loss: 0.2905
Epoch 7/10, Batch 100/145, Loss: 0.1062
Epoch 7/10, Batch 110/145, Loss: 0.2222
Epoch 7/10, Batch 120/145, Loss: 0.1881
Epoch 7/10, Batch 130/145, Loss: 0.1590
Epoch 7/10, Batch 140/145, Loss: 0.2241
Epoch 7/10, Train Loss: 0.2064, Valid Loss: 0.2432
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1603
Epoch 8/10, Batch 20/145, Loss: 0.3573
Epoch 8/10, Batch 30/145, Loss: 0.1553
Epoch 8/10, Batch 40/145, Loss: 0.3852
Epoch 8/10, Batch 50/145, Loss: 0.1976
Epoch 8/10, Batch 60/145, Loss: 0.2280
Epoch 8/10, Batch 70/145, Loss: 0.2538
Epoch 8/10, Batch 80/145, Loss: 0.1818
Epoch 8/10, Batch 90/145, Loss: 0.3133
Epoch 8/10, Batch 100/145, Loss: 0.1023
Epoch 8/10, Batch 110/145, Loss: 0.2141
Epoch 8/10, Batch 120/145, Loss: 0.3307
Epoch 8/10, Batch 130/145, Loss: 0.0842
Epoch 8/10, Batch 140/145, Loss: 0.2704
Epoch 8/10, Train Loss: 0.1988, Valid Loss: 0.2341
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2554
Epoch 9/10, Batch 20/145, Loss: 0.3482
Epoch 9/10, Batch 30/145, Loss: 0.1772
Epoch 9/10, Batch 40/145, Loss: 0.3594
Epoch 9/10, Batch 50/145, Loss: 0.2228
Epoch 9/10, Batch 60/145, Loss: 0.2936
Epoch 9/10, Batch 70/145, Loss: 0.1729
Epoch 9/10, Batch 80/145, Loss: 0.0915
Epoch 9/10, Batch 90/145, Loss: 0.1247
Epoch 9/10, Batch 100/145, Loss: 0.0825
Epoch 9/10, Batch 110/145, Loss: 0.1771
Epoch 9/10, Batch 120/145, Loss: 0.0953
Epoch 9/10, Batch 130/145, Loss: 0.2323
Epoch 9/10, Batch 140/145, Loss: 0.1092
Epoch 9/10, Train Loss: 0.1921, Valid Loss: 0.2320
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1337
Epoch 10/10, Batch 20/145, Loss: 0.0940
Epoch 10/10, Batch 30/145, Loss: 0.0664
Epoch 10/10, Batch 40/145, Loss: 0.0684
Epoch 10/10, Batch 50/145, Loss: 0.1143
Epoch 10/10, Batch 60/145, Loss: 0.1277
Epoch 10/10, Batch 70/145, Loss: 0.2228
Epoch 10/10, Batch 80/145, Loss: 0.2074
Epoch 10/10, Batch 90/145, Loss: 0.1031
Epoch 10/10, Batch 100/145, Loss: 0.1336
Epoch 10/10, Batch 110/145, Loss: 0.2279
Epoch 10/10, Batch 120/145, Loss: 0.2563
Epoch 10/10, Batch 130/145, Loss: 0.2792
Epoch 10/10, Batch 140/145, Loss: 0.1694
Epoch 10/10, Train Loss: 0.1853, Valid Loss: 0.2315
Model saved!
Accuracy: 0.9147
Precision: 0.9109
Recall: 0.9147
F1-score: 0.9114
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3300
Epoch 1/10, Batch 20/145, Loss: 0.9487
Epoch 1/10, Batch 30/145, Loss: 0.9607
Epoch 1/10, Batch 40/145, Loss: 0.8514
Epoch 1/10, Batch 50/145, Loss: 0.7128
Epoch 1/10, Batch 60/145, Loss: 0.6298
Epoch 1/10, Batch 70/145, Loss: 0.4516
Epoch 1/10, Batch 80/145, Loss: 0.7033
Epoch 1/10, Batch 90/145, Loss: 0.4282
Epoch 1/10, Batch 100/145, Loss: 0.5310
Epoch 1/10, Batch 110/145, Loss: 0.4504
Epoch 1/10, Batch 120/145, Loss: 0.6273
Epoch 1/10, Batch 130/145, Loss: 0.5241
Epoch 1/10, Batch 140/145, Loss: 0.2720
Epoch 1/10, Train Loss: 0.6804, Valid Loss: 0.3601
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3496
Epoch 2/10, Batch 20/145, Loss: 0.2960
Epoch 2/10, Batch 30/145, Loss: 0.3729
Epoch 2/10, Batch 40/145, Loss: 0.3634
Epoch 2/10, Batch 50/145, Loss: 0.4356
Epoch 2/10, Batch 60/145, Loss: 0.2987
Epoch 2/10, Batch 70/145, Loss: 0.3671
Epoch 2/10, Batch 80/145, Loss: 0.3778
Epoch 2/10, Batch 90/145, Loss: 0.2424
Epoch 2/10, Batch 100/145, Loss: 0.2542
Epoch 2/10, Batch 110/145, Loss: 0.3298
Epoch 2/10, Batch 120/145, Loss: 0.4889
Epoch 2/10, Batch 130/145, Loss: 0.4087
Epoch 2/10, Batch 140/145, Loss: 0.3319
Epoch 2/10, Train Loss: 0.3584, Valid Loss: 0.2838
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3175
Epoch 3/10, Batch 20/145, Loss: 0.2524
Epoch 3/10, Batch 30/145, Loss: 0.2736
Epoch 3/10, Batch 40/145, Loss: 0.2037
Epoch 3/10, Batch 50/145, Loss: 0.2579
Epoch 3/10, Batch 60/145, Loss: 0.3213
Epoch 3/10, Batch 70/145, Loss: 0.4728
Epoch 3/10, Batch 80/145, Loss: 0.3893
Epoch 3/10, Batch 90/145, Loss: 0.3271
Epoch 3/10, Batch 100/145, Loss: 0.3787
Epoch 3/10, Batch 110/145, Loss: 0.1739
Epoch 3/10, Batch 120/145, Loss: 0.1665
Epoch 3/10, Batch 130/145, Loss: 0.3279
Epoch 3/10, Batch 140/145, Loss: 0.3006
Epoch 3/10, Train Loss: 0.2981, Valid Loss: 0.2502
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3605
Epoch 4/10, Batch 20/145, Loss: 0.3269
Epoch 4/10, Batch 30/145, Loss: 0.1658
Epoch 4/10, Batch 40/145, Loss: 0.1398
Epoch 4/10, Batch 50/145, Loss: 0.2499
Epoch 4/10, Batch 60/145, Loss: 0.2560
Epoch 4/10, Batch 70/145, Loss: 0.2092
Epoch 4/10, Batch 80/145, Loss: 0.1993
Epoch 4/10, Batch 90/145, Loss: 0.1203
Epoch 4/10, Batch 100/145, Loss: 0.2835
Epoch 4/10, Batch 110/145, Loss: 0.1553
Epoch 4/10, Batch 120/145, Loss: 0.2455
Epoch 4/10, Batch 130/145, Loss: 0.1586
Epoch 4/10, Batch 140/145, Loss: 0.2038
Epoch 4/10, Train Loss: 0.2605, Valid Loss: 0.2345
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1495
Epoch 5/10, Batch 20/145, Loss: 0.1605
Epoch 5/10, Batch 30/145, Loss: 0.1638
Epoch 5/10, Batch 40/145, Loss: 0.1178
Epoch 5/10, Batch 50/145, Loss: 0.2674
Epoch 5/10, Batch 60/145, Loss: 0.2156
Epoch 5/10, Batch 70/145, Loss: 0.2358
Epoch 5/10, Batch 80/145, Loss: 0.1266
Epoch 5/10, Batch 90/145, Loss: 0.2168
Epoch 5/10, Batch 100/145, Loss: 0.2687
Epoch 5/10, Batch 110/145, Loss: 0.3014
Epoch 5/10, Batch 120/145, Loss: 0.4088
Epoch 5/10, Batch 130/145, Loss: 0.3163
Epoch 5/10, Batch 140/145, Loss: 0.2543
Epoch 5/10, Train Loss: 0.2434, Valid Loss: 0.2248
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1300
Epoch 6/10, Batch 20/145, Loss: 0.4190
Epoch 6/10, Batch 30/145, Loss: 0.2779
Epoch 6/10, Batch 40/145, Loss: 0.1954
Epoch 6/10, Batch 50/145, Loss: 0.2357
Epoch 6/10, Batch 60/145, Loss: 0.1624
Epoch 6/10, Batch 70/145, Loss: 0.2773
Epoch 6/10, Batch 80/145, Loss: 0.2633
Epoch 6/10, Batch 90/145, Loss: 0.3333
Epoch 6/10, Batch 100/145, Loss: 0.5081
Epoch 6/10, Batch 110/145, Loss: 0.1496
Epoch 6/10, Batch 120/145, Loss: 0.1299
Epoch 6/10, Batch 130/145, Loss: 0.1924
Epoch 6/10, Batch 140/145, Loss: 0.3026
Epoch 6/10, Train Loss: 0.2316, Valid Loss: 0.2166
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2367
Epoch 7/10, Batch 20/145, Loss: 0.3672
Epoch 7/10, Batch 30/145, Loss: 0.1178
Epoch 7/10, Batch 40/145, Loss: 0.1638
Epoch 7/10, Batch 50/145, Loss: 0.2818
Epoch 7/10, Batch 60/145, Loss: 0.2667
Epoch 7/10, Batch 70/145, Loss: 0.1646
Epoch 7/10, Batch 80/145, Loss: 0.2435
Epoch 7/10, Batch 90/145, Loss: 0.2555
Epoch 7/10, Batch 100/145, Loss: 0.1624
Epoch 7/10, Batch 110/145, Loss: 0.1100
Epoch 7/10, Batch 120/145, Loss: 0.1776
Epoch 7/10, Batch 130/145, Loss: 0.1502
Epoch 7/10, Batch 140/145, Loss: 0.1849
Epoch 7/10, Train Loss: 0.2117, Valid Loss: 0.2105
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1677
Epoch 8/10, Batch 20/145, Loss: 0.3049
Epoch 8/10, Batch 30/145, Loss: 0.1654
Epoch 8/10, Batch 40/145, Loss: 0.2776
Epoch 8/10, Batch 50/145, Loss: 0.1283
Epoch 8/10, Batch 60/145, Loss: 0.1753
Epoch 8/10, Batch 70/145, Loss: 0.3259
Epoch 8/10, Batch 80/145, Loss: 0.3374
Epoch 8/10, Batch 90/145, Loss: 0.3552
Epoch 8/10, Batch 100/145, Loss: 0.1650
Epoch 8/10, Batch 110/145, Loss: 0.3294
Epoch 8/10, Batch 120/145, Loss: 0.0795
Epoch 8/10, Batch 130/145, Loss: 0.1274
Epoch 8/10, Batch 140/145, Loss: 0.3507
Epoch 8/10, Train Loss: 0.2080, Valid Loss: 0.2081
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2974
Epoch 9/10, Batch 20/145, Loss: 0.1146
Epoch 9/10, Batch 30/145, Loss: 0.1022
Epoch 9/10, Batch 40/145, Loss: 0.1934
Epoch 9/10, Batch 50/145, Loss: 0.0950
Epoch 9/10, Batch 60/145, Loss: 0.5803
Epoch 9/10, Batch 70/145, Loss: 0.1829
Epoch 9/10, Batch 80/145, Loss: 0.1228
Epoch 9/10, Batch 90/145, Loss: 0.2580
Epoch 9/10, Batch 100/145, Loss: 0.1283
Epoch 9/10, Batch 110/145, Loss: 0.2492
Epoch 9/10, Batch 120/145, Loss: 0.1960
Epoch 9/10, Batch 130/145, Loss: 0.1272
Epoch 9/10, Batch 140/145, Loss: 0.1108
Epoch 9/10, Train Loss: 0.2057, Valid Loss: 0.2094
Epoch 10/10, Batch 10/145, Loss: 0.1134
Epoch 10/10, Batch 20/145, Loss: 0.2125
Epoch 10/10, Batch 30/145, Loss: 0.1475
Epoch 10/10, Batch 40/145, Loss: 0.0741
Epoch 10/10, Batch 50/145, Loss: 0.0918
Epoch 10/10, Batch 60/145, Loss: 0.1337
Epoch 10/10, Batch 70/145, Loss: 0.3647
Epoch 10/10, Batch 80/145, Loss: 0.0809
Epoch 10/10, Batch 90/145, Loss: 0.1204
Epoch 10/10, Batch 100/145, Loss: 0.1556
Epoch 10/10, Batch 110/145, Loss: 0.2193
Epoch 10/10, Batch 120/145, Loss: 0.2709
Epoch 10/10, Batch 130/145, Loss: 0.0983
Epoch 10/10, Batch 140/145, Loss: 0.2092
Epoch 10/10, Train Loss: 0.1952, Valid Loss: 0.2029
Model saved!
Accuracy: 0.9194
Precision: 0.9168
Recall: 0.9194
F1-score: 0.9174
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.2986
Epoch 1/10, Batch 20/145, Loss: 0.9559
Epoch 1/10, Batch 30/145, Loss: 0.8812
Epoch 1/10, Batch 40/145, Loss: 0.8298
Epoch 1/10, Batch 50/145, Loss: 0.6306
Epoch 1/10, Batch 60/145, Loss: 0.6965
Epoch 1/10, Batch 70/145, Loss: 0.5384
Epoch 1/10, Batch 80/145, Loss: 0.6261
Epoch 1/10, Batch 90/145, Loss: 0.5379
Epoch 1/10, Batch 100/145, Loss: 0.4453
Epoch 1/10, Batch 110/145, Loss: 0.5489
Epoch 1/10, Batch 120/145, Loss: 0.3457
Epoch 1/10, Batch 130/145, Loss: 0.5113
Epoch 1/10, Batch 140/145, Loss: 0.5310
Epoch 1/10, Train Loss: 0.6809, Valid Loss: 0.3789
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2765
Epoch 2/10, Batch 20/145, Loss: 0.3694
Epoch 2/10, Batch 30/145, Loss: 0.3813
Epoch 2/10, Batch 40/145, Loss: 0.5439
Epoch 2/10, Batch 50/145, Loss: 0.4662
Epoch 2/10, Batch 60/145, Loss: 0.3411
Epoch 2/10, Batch 70/145, Loss: 0.2991
Epoch 2/10, Batch 80/145, Loss: 0.2751
Epoch 2/10, Batch 90/145, Loss: 0.2197
Epoch 2/10, Batch 100/145, Loss: 0.3626
Epoch 2/10, Batch 110/145, Loss: 0.4652
Epoch 2/10, Batch 120/145, Loss: 0.4584
Epoch 2/10, Batch 130/145, Loss: 0.3718
Epoch 2/10, Batch 140/145, Loss: 0.1493
Epoch 2/10, Train Loss: 0.3546, Valid Loss: 0.2962
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2453
Epoch 3/10, Batch 20/145, Loss: 0.2135
Epoch 3/10, Batch 30/145, Loss: 0.3844
Epoch 3/10, Batch 40/145, Loss: 0.1769
Epoch 3/10, Batch 50/145, Loss: 0.2899
Epoch 3/10, Batch 60/145, Loss: 0.4373
Epoch 3/10, Batch 70/145, Loss: 0.4111
Epoch 3/10, Batch 80/145, Loss: 0.3202
Epoch 3/10, Batch 90/145, Loss: 0.2398
Epoch 3/10, Batch 100/145, Loss: 0.2739
Epoch 3/10, Batch 110/145, Loss: 0.1570
Epoch 3/10, Batch 120/145, Loss: 0.1471
Epoch 3/10, Batch 130/145, Loss: 0.3202
Epoch 3/10, Batch 140/145, Loss: 0.3828
Epoch 3/10, Train Loss: 0.2951, Valid Loss: 0.2668
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3805
Epoch 4/10, Batch 20/145, Loss: 0.2575
Epoch 4/10, Batch 30/145, Loss: 0.2222
Epoch 4/10, Batch 40/145, Loss: 0.1488
Epoch 4/10, Batch 50/145, Loss: 0.1700
Epoch 4/10, Batch 60/145, Loss: 0.2596
Epoch 4/10, Batch 70/145, Loss: 0.2211
Epoch 4/10, Batch 80/145, Loss: 0.1867
Epoch 4/10, Batch 90/145, Loss: 0.3129
Epoch 4/10, Batch 100/145, Loss: 0.2352
Epoch 4/10, Batch 110/145, Loss: 0.1320
Epoch 4/10, Batch 120/145, Loss: 0.2039
Epoch 4/10, Batch 130/145, Loss: 0.3995
Epoch 4/10, Batch 140/145, Loss: 0.1361
Epoch 4/10, Train Loss: 0.2578, Valid Loss: 0.2583
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1444
Epoch 5/10, Batch 20/145, Loss: 0.1716
Epoch 5/10, Batch 30/145, Loss: 0.2158
Epoch 5/10, Batch 40/145, Loss: 0.2317
Epoch 5/10, Batch 50/145, Loss: 0.2434
Epoch 5/10, Batch 60/145, Loss: 0.2811
Epoch 5/10, Batch 70/145, Loss: 0.1373
Epoch 5/10, Batch 80/145, Loss: 0.1768
Epoch 5/10, Batch 90/145, Loss: 0.1704
Epoch 5/10, Batch 100/145, Loss: 0.5044
Epoch 5/10, Batch 110/145, Loss: 0.2577
Epoch 5/10, Batch 120/145, Loss: 0.3566
Epoch 5/10, Batch 130/145, Loss: 0.2481
Epoch 5/10, Batch 140/145, Loss: 0.1608
Epoch 5/10, Train Loss: 0.2472, Valid Loss: 0.2473
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1873
Epoch 6/10, Batch 20/145, Loss: 0.3064
Epoch 6/10, Batch 30/145, Loss: 0.1599
Epoch 6/10, Batch 40/145, Loss: 0.1000
Epoch 6/10, Batch 50/145, Loss: 0.2723
Epoch 6/10, Batch 60/145, Loss: 0.2670
Epoch 6/10, Batch 70/145, Loss: 0.1738
Epoch 6/10, Batch 80/145, Loss: 0.1852
Epoch 6/10, Batch 90/145, Loss: 0.2802
Epoch 6/10, Batch 100/145, Loss: 0.2753
Epoch 6/10, Batch 110/145, Loss: 0.3571
Epoch 6/10, Batch 120/145, Loss: 0.1971
Epoch 6/10, Batch 130/145, Loss: 0.2434
Epoch 6/10, Batch 140/145, Loss: 0.1071
Epoch 6/10, Train Loss: 0.2257, Valid Loss: 0.2403
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2194
Epoch 7/10, Batch 20/145, Loss: 0.3482
Epoch 7/10, Batch 30/145, Loss: 0.1890
Epoch 7/10, Batch 40/145, Loss: 0.4071
Epoch 7/10, Batch 50/145, Loss: 0.1011
Epoch 7/10, Batch 60/145, Loss: 0.1618
Epoch 7/10, Batch 70/145, Loss: 0.1014
Epoch 7/10, Batch 80/145, Loss: 0.3846
Epoch 7/10, Batch 90/145, Loss: 0.1218
Epoch 7/10, Batch 100/145, Loss: 0.1150
Epoch 7/10, Batch 110/145, Loss: 0.2216
Epoch 7/10, Batch 120/145, Loss: 0.1997
Epoch 7/10, Batch 130/145, Loss: 0.1741
Epoch 7/10, Batch 140/145, Loss: 0.2482
Epoch 7/10, Train Loss: 0.2160, Valid Loss: 0.2311
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1788
Epoch 8/10, Batch 20/145, Loss: 0.1994
Epoch 8/10, Batch 30/145, Loss: 0.3007
Epoch 8/10, Batch 40/145, Loss: 0.2033
Epoch 8/10, Batch 50/145, Loss: 0.2629
Epoch 8/10, Batch 60/145, Loss: 0.1893
Epoch 8/10, Batch 70/145, Loss: 0.2972
Epoch 8/10, Batch 80/145, Loss: 0.2270
Epoch 8/10, Batch 90/145, Loss: 0.4166
Epoch 8/10, Batch 100/145, Loss: 0.1205
Epoch 8/10, Batch 110/145, Loss: 0.1529
Epoch 8/10, Batch 120/145, Loss: 0.1886
Epoch 8/10, Batch 130/145, Loss: 0.1768
Epoch 8/10, Batch 140/145, Loss: 0.1986
Epoch 8/10, Train Loss: 0.2065, Valid Loss: 0.2322
Epoch 9/10, Batch 10/145, Loss: 0.3603
Epoch 9/10, Batch 20/145, Loss: 0.1645
Epoch 9/10, Batch 30/145, Loss: 0.0693
Epoch 9/10, Batch 40/145, Loss: 0.1899
Epoch 9/10, Batch 50/145, Loss: 0.1861
Epoch 9/10, Batch 60/145, Loss: 0.1909
Epoch 9/10, Batch 70/145, Loss: 0.1919
Epoch 9/10, Batch 80/145, Loss: 0.2055
Epoch 9/10, Batch 90/145, Loss: 0.2580
Epoch 9/10, Batch 100/145, Loss: 0.2115
Epoch 9/10, Batch 110/145, Loss: 0.2245
Epoch 9/10, Batch 120/145, Loss: 0.1974
Epoch 9/10, Batch 130/145, Loss: 0.0794
Epoch 9/10, Batch 140/145, Loss: 0.2653
Epoch 9/10, Train Loss: 0.2007, Valid Loss: 0.2270
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1452
Epoch 10/10, Batch 20/145, Loss: 0.1710
Epoch 10/10, Batch 30/145, Loss: 0.0855
Epoch 10/10, Batch 40/145, Loss: 0.1051
Epoch 10/10, Batch 50/145, Loss: 0.2329
Epoch 10/10, Batch 60/145, Loss: 0.1890
Epoch 10/10, Batch 70/145, Loss: 0.2132
Epoch 10/10, Batch 80/145, Loss: 0.2022
Epoch 10/10, Batch 90/145, Loss: 0.1752
Epoch 10/10, Batch 100/145, Loss: 0.1534
Epoch 10/10, Batch 110/145, Loss: 0.2272
Epoch 10/10, Batch 120/145, Loss: 0.1456
Epoch 10/10, Batch 130/145, Loss: 0.1659
Epoch 10/10, Batch 140/145, Loss: 0.2843
Epoch 10/10, Train Loss: 0.1903, Valid Loss: 0.2307
Accuracy: 0.9229
Precision: 0.9214
Recall: 0.9229
F1-score: 0.9220
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4109
Epoch 1/10, Batch 20/145, Loss: 0.9676
Epoch 1/10, Batch 30/145, Loss: 0.9274
Epoch 1/10, Batch 40/145, Loss: 0.6969
Epoch 1/10, Batch 50/145, Loss: 0.6760
Epoch 1/10, Batch 60/145, Loss: 0.5955
Epoch 1/10, Batch 70/145, Loss: 0.5383
Epoch 1/10, Batch 80/145, Loss: 0.5361
Epoch 1/10, Batch 90/145, Loss: 0.5673
Epoch 1/10, Batch 100/145, Loss: 0.6043
Epoch 1/10, Batch 110/145, Loss: 0.6070
Epoch 1/10, Batch 120/145, Loss: 0.5767
Epoch 1/10, Batch 130/145, Loss: 0.4611
Epoch 1/10, Batch 140/145, Loss: 0.2668
Epoch 1/10, Train Loss: 0.6738, Valid Loss: 0.4023
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3971
Epoch 2/10, Batch 20/145, Loss: 0.2678
Epoch 2/10, Batch 30/145, Loss: 0.3187
Epoch 2/10, Batch 40/145, Loss: 0.4398
Epoch 2/10, Batch 50/145, Loss: 0.3172
Epoch 2/10, Batch 60/145, Loss: 0.2973
Epoch 2/10, Batch 70/145, Loss: 0.3126
Epoch 2/10, Batch 80/145, Loss: 0.3762
Epoch 2/10, Batch 90/145, Loss: 0.4290
Epoch 2/10, Batch 100/145, Loss: 0.2554
Epoch 2/10, Batch 110/145, Loss: 0.3086
Epoch 2/10, Batch 120/145, Loss: 0.2273
Epoch 2/10, Batch 130/145, Loss: 0.3225
Epoch 2/10, Batch 140/145, Loss: 0.4569
Epoch 2/10, Train Loss: 0.3477, Valid Loss: 0.3185
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2621
Epoch 3/10, Batch 20/145, Loss: 0.2039
Epoch 3/10, Batch 30/145, Loss: 0.3979
Epoch 3/10, Batch 40/145, Loss: 0.2693
Epoch 3/10, Batch 50/145, Loss: 0.3132
Epoch 3/10, Batch 60/145, Loss: 0.3308
Epoch 3/10, Batch 70/145, Loss: 0.2885
Epoch 3/10, Batch 80/145, Loss: 0.1852
Epoch 3/10, Batch 90/145, Loss: 0.2325
Epoch 3/10, Batch 100/145, Loss: 0.2503
Epoch 3/10, Batch 110/145, Loss: 0.4950
Epoch 3/10, Batch 120/145, Loss: 0.1366
Epoch 3/10, Batch 130/145, Loss: 0.4037
Epoch 3/10, Batch 140/145, Loss: 0.2697
Epoch 3/10, Train Loss: 0.2910, Valid Loss: 0.2958
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3587
Epoch 4/10, Batch 20/145, Loss: 0.2567
Epoch 4/10, Batch 30/145, Loss: 0.1957
Epoch 4/10, Batch 40/145, Loss: 0.1956
Epoch 4/10, Batch 50/145, Loss: 0.1929
Epoch 4/10, Batch 60/145, Loss: 0.3457
Epoch 4/10, Batch 70/145, Loss: 0.1931
Epoch 4/10, Batch 80/145, Loss: 0.2188
Epoch 4/10, Batch 90/145, Loss: 0.2629
Epoch 4/10, Batch 100/145, Loss: 0.2549
Epoch 4/10, Batch 110/145, Loss: 0.2260
Epoch 4/10, Batch 120/145, Loss: 0.1831
Epoch 4/10, Batch 130/145, Loss: 0.2963
Epoch 4/10, Batch 140/145, Loss: 0.2055
Epoch 4/10, Train Loss: 0.2635, Valid Loss: 0.2807
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1433
Epoch 5/10, Batch 20/145, Loss: 0.0980
Epoch 5/10, Batch 30/145, Loss: 0.3302
Epoch 5/10, Batch 40/145, Loss: 0.2489
Epoch 5/10, Batch 50/145, Loss: 0.3152
Epoch 5/10, Batch 60/145, Loss: 0.2020
Epoch 5/10, Batch 70/145, Loss: 0.2329
Epoch 5/10, Batch 80/145, Loss: 0.2126
Epoch 5/10, Batch 90/145, Loss: 0.3126
Epoch 5/10, Batch 100/145, Loss: 0.1444
Epoch 5/10, Batch 110/145, Loss: 0.3148
Epoch 5/10, Batch 120/145, Loss: 0.2717
Epoch 5/10, Batch 130/145, Loss: 0.1926
Epoch 5/10, Batch 140/145, Loss: 0.1009
Epoch 5/10, Train Loss: 0.2480, Valid Loss: 0.2632
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2606
Epoch 6/10, Batch 20/145, Loss: 0.2850
Epoch 6/10, Batch 30/145, Loss: 0.3161
Epoch 6/10, Batch 40/145, Loss: 0.1607
Epoch 6/10, Batch 50/145, Loss: 0.3072
Epoch 6/10, Batch 60/145, Loss: 0.2026
Epoch 6/10, Batch 70/145, Loss: 0.1386
Epoch 6/10, Batch 80/145, Loss: 0.1330
Epoch 6/10, Batch 90/145, Loss: 0.3602
Epoch 6/10, Batch 100/145, Loss: 0.1868
Epoch 6/10, Batch 110/145, Loss: 0.1684
Epoch 6/10, Batch 120/145, Loss: 0.2992
Epoch 6/10, Batch 130/145, Loss: 0.2610
Epoch 6/10, Batch 140/145, Loss: 0.3170
Epoch 6/10, Train Loss: 0.2253, Valid Loss: 0.2518
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.0948
Epoch 7/10, Batch 20/145, Loss: 0.5583
Epoch 7/10, Batch 30/145, Loss: 0.2341
Epoch 7/10, Batch 40/145, Loss: 0.2095
Epoch 7/10, Batch 50/145, Loss: 0.1735
Epoch 7/10, Batch 60/145, Loss: 0.0782
Epoch 7/10, Batch 70/145, Loss: 0.1480
Epoch 7/10, Batch 80/145, Loss: 0.3017
Epoch 7/10, Batch 90/145, Loss: 0.1464
Epoch 7/10, Batch 100/145, Loss: 0.0962
Epoch 7/10, Batch 110/145, Loss: 0.2892
Epoch 7/10, Batch 120/145, Loss: 0.1664
Epoch 7/10, Batch 130/145, Loss: 0.0813
Epoch 7/10, Batch 140/145, Loss: 0.2045
Epoch 7/10, Train Loss: 0.2139, Valid Loss: 0.2469
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2100
Epoch 8/10, Batch 20/145, Loss: 0.3190
Epoch 8/10, Batch 30/145, Loss: 0.2264
Epoch 8/10, Batch 40/145, Loss: 0.1971
Epoch 8/10, Batch 50/145, Loss: 0.1170
Epoch 8/10, Batch 60/145, Loss: 0.1516
Epoch 8/10, Batch 70/145, Loss: 0.3174
Epoch 8/10, Batch 80/145, Loss: 0.3070
Epoch 8/10, Batch 90/145, Loss: 0.3195
Epoch 8/10, Batch 100/145, Loss: 0.1988
Epoch 8/10, Batch 110/145, Loss: 0.3134
Epoch 8/10, Batch 120/145, Loss: 0.2125
Epoch 8/10, Batch 130/145, Loss: 0.0918
Epoch 8/10, Batch 140/145, Loss: 0.2123
Epoch 8/10, Train Loss: 0.2083, Valid Loss: 0.2424
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.4564
Epoch 9/10, Batch 20/145, Loss: 0.1762
Epoch 9/10, Batch 30/145, Loss: 0.1066
Epoch 9/10, Batch 40/145, Loss: 0.2690
Epoch 9/10, Batch 50/145, Loss: 0.2306
Epoch 9/10, Batch 60/145, Loss: 0.2610
Epoch 9/10, Batch 70/145, Loss: 0.1999
Epoch 9/10, Batch 80/145, Loss: 0.1123
Epoch 9/10, Batch 90/145, Loss: 0.1792
Epoch 9/10, Batch 100/145, Loss: 0.2718
Epoch 9/10, Batch 110/145, Loss: 0.2066
Epoch 9/10, Batch 120/145, Loss: 0.0944
Epoch 9/10, Batch 130/145, Loss: 0.2435
Epoch 9/10, Batch 140/145, Loss: 0.4099
Epoch 9/10, Train Loss: 0.2027, Valid Loss: 0.2341
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1048
Epoch 10/10, Batch 20/145, Loss: 0.2090
Epoch 10/10, Batch 30/145, Loss: 0.1755
Epoch 10/10, Batch 40/145, Loss: 0.0817
Epoch 10/10, Batch 50/145, Loss: 0.1247
Epoch 10/10, Batch 60/145, Loss: 0.1524
Epoch 10/10, Batch 70/145, Loss: 0.2418
Epoch 10/10, Batch 80/145, Loss: 0.1358
Epoch 10/10, Batch 90/145, Loss: 0.1915
Epoch 10/10, Batch 100/145, Loss: 0.1423
Epoch 10/10, Batch 110/145, Loss: 0.1122
Epoch 10/10, Batch 120/145, Loss: 0.1170
Epoch 10/10, Batch 130/145, Loss: 0.3039
Epoch 10/10, Batch 140/145, Loss: 0.2214
Epoch 10/10, Train Loss: 0.1885, Valid Loss: 0.2356
Accuracy: 0.9229
Precision: 0.9210
Recall: 0.9229
F1-score: 0.9215
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3998
Epoch 1/10, Batch 20/145, Loss: 0.9062
Epoch 1/10, Batch 30/145, Loss: 0.8199
Epoch 1/10, Batch 40/145, Loss: 0.8123
Epoch 1/10, Batch 50/145, Loss: 0.7333
Epoch 1/10, Batch 60/145, Loss: 0.5268
Epoch 1/10, Batch 70/145, Loss: 0.4592
Epoch 1/10, Batch 80/145, Loss: 0.6405
Epoch 1/10, Batch 90/145, Loss: 0.4183
Epoch 1/10, Batch 100/145, Loss: 0.5541
Epoch 1/10, Batch 110/145, Loss: 0.4844
Epoch 1/10, Batch 120/145, Loss: 0.5315
Epoch 1/10, Batch 130/145, Loss: 0.4954
Epoch 1/10, Batch 140/145, Loss: 0.3095
Epoch 1/10, Train Loss: 0.6822, Valid Loss: 0.3989
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4321
Epoch 2/10, Batch 20/145, Loss: 0.4279
Epoch 2/10, Batch 30/145, Loss: 0.2841
Epoch 2/10, Batch 40/145, Loss: 0.5209
Epoch 2/10, Batch 50/145, Loss: 0.3569
Epoch 2/10, Batch 60/145, Loss: 0.4071
Epoch 2/10, Batch 70/145, Loss: 0.3539
Epoch 2/10, Batch 80/145, Loss: 0.2946
Epoch 2/10, Batch 90/145, Loss: 0.3051
Epoch 2/10, Batch 100/145, Loss: 0.3259
Epoch 2/10, Batch 110/145, Loss: 0.4493
Epoch 2/10, Batch 120/145, Loss: 0.2752
Epoch 2/10, Batch 130/145, Loss: 0.2809
Epoch 2/10, Batch 140/145, Loss: 0.1868
Epoch 2/10, Train Loss: 0.3578, Valid Loss: 0.3147
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3249
Epoch 3/10, Batch 20/145, Loss: 0.3677
Epoch 3/10, Batch 30/145, Loss: 0.4227
Epoch 3/10, Batch 40/145, Loss: 0.2708
Epoch 3/10, Batch 50/145, Loss: 0.1774
Epoch 3/10, Batch 60/145, Loss: 0.4642
Epoch 3/10, Batch 70/145, Loss: 0.2463
Epoch 3/10, Batch 80/145, Loss: 0.1443
Epoch 3/10, Batch 90/145, Loss: 0.2443
Epoch 3/10, Batch 100/145, Loss: 0.2997
Epoch 3/10, Batch 110/145, Loss: 0.1986
Epoch 3/10, Batch 120/145, Loss: 0.2646
Epoch 3/10, Batch 130/145, Loss: 0.4857
Epoch 3/10, Batch 140/145, Loss: 0.2788
Epoch 3/10, Train Loss: 0.2987, Valid Loss: 0.2784
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4013
Epoch 4/10, Batch 20/145, Loss: 0.2575
Epoch 4/10, Batch 30/145, Loss: 0.4285
Epoch 4/10, Batch 40/145, Loss: 0.1638
Epoch 4/10, Batch 50/145, Loss: 0.1272
Epoch 4/10, Batch 60/145, Loss: 0.3014
Epoch 4/10, Batch 70/145, Loss: 0.2363
Epoch 4/10, Batch 80/145, Loss: 0.2144
Epoch 4/10, Batch 90/145, Loss: 0.2362
Epoch 4/10, Batch 100/145, Loss: 0.4665
Epoch 4/10, Batch 110/145, Loss: 0.1846
Epoch 4/10, Batch 120/145, Loss: 0.1777
Epoch 4/10, Batch 130/145, Loss: 0.1115
Epoch 4/10, Batch 140/145, Loss: 0.2561
Epoch 4/10, Train Loss: 0.2595, Valid Loss: 0.2571
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1975
Epoch 5/10, Batch 20/145, Loss: 0.0631
Epoch 5/10, Batch 30/145, Loss: 0.2852
Epoch 5/10, Batch 40/145, Loss: 0.1693
Epoch 5/10, Batch 50/145, Loss: 0.1968
Epoch 5/10, Batch 60/145, Loss: 0.2082
Epoch 5/10, Batch 70/145, Loss: 0.2087
Epoch 5/10, Batch 80/145, Loss: 0.3430
Epoch 5/10, Batch 90/145, Loss: 0.1928
Epoch 5/10, Batch 100/145, Loss: 0.2640
Epoch 5/10, Batch 110/145, Loss: 0.1495
Epoch 5/10, Batch 120/145, Loss: 0.3771
Epoch 5/10, Batch 130/145, Loss: 0.1910
Epoch 5/10, Batch 140/145, Loss: 0.1557
Epoch 5/10, Train Loss: 0.2430, Valid Loss: 0.2487
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1976
Epoch 6/10, Batch 20/145, Loss: 0.5224
Epoch 6/10, Batch 30/145, Loss: 0.2959
Epoch 6/10, Batch 40/145, Loss: 0.2128
Epoch 6/10, Batch 50/145, Loss: 0.2484
Epoch 6/10, Batch 60/145, Loss: 0.2073
Epoch 6/10, Batch 70/145, Loss: 0.2434
Epoch 6/10, Batch 80/145, Loss: 0.1310
Epoch 6/10, Batch 90/145, Loss: 0.2748
Epoch 6/10, Batch 100/145, Loss: 0.2566
Epoch 6/10, Batch 110/145, Loss: 0.2023
Epoch 6/10, Batch 120/145, Loss: 0.3627
Epoch 6/10, Batch 130/145, Loss: 0.1597
Epoch 6/10, Batch 140/145, Loss: 0.1952
Epoch 6/10, Train Loss: 0.2263, Valid Loss: 0.2395
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1982
Epoch 7/10, Batch 20/145, Loss: 0.3973
Epoch 7/10, Batch 30/145, Loss: 0.1994
Epoch 7/10, Batch 40/145, Loss: 0.1496
Epoch 7/10, Batch 50/145, Loss: 0.2206
Epoch 7/10, Batch 60/145, Loss: 0.1043
Epoch 7/10, Batch 70/145, Loss: 0.1620
Epoch 7/10, Batch 80/145, Loss: 0.4584
Epoch 7/10, Batch 90/145, Loss: 0.0915
Epoch 7/10, Batch 100/145, Loss: 0.1159
Epoch 7/10, Batch 110/145, Loss: 0.2133
Epoch 7/10, Batch 120/145, Loss: 0.2855
Epoch 7/10, Batch 130/145, Loss: 0.1920
Epoch 7/10, Batch 140/145, Loss: 0.1142
Epoch 7/10, Train Loss: 0.2156, Valid Loss: 0.2322
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1359
Epoch 8/10, Batch 20/145, Loss: 0.2455
Epoch 8/10, Batch 30/145, Loss: 0.2201
Epoch 8/10, Batch 40/145, Loss: 0.1234
Epoch 8/10, Batch 50/145, Loss: 0.1929
Epoch 8/10, Batch 60/145, Loss: 0.1960
Epoch 8/10, Batch 70/145, Loss: 0.3300
Epoch 8/10, Batch 80/145, Loss: 0.1554
Epoch 8/10, Batch 90/145, Loss: 0.2718
Epoch 8/10, Batch 100/145, Loss: 0.1779
Epoch 8/10, Batch 110/145, Loss: 0.1901
Epoch 8/10, Batch 120/145, Loss: 0.2007
Epoch 8/10, Batch 130/145, Loss: 0.1286
Epoch 8/10, Batch 140/145, Loss: 0.2600
Epoch 8/10, Train Loss: 0.2094, Valid Loss: 0.2303
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2410
Epoch 9/10, Batch 20/145, Loss: 0.1744
Epoch 9/10, Batch 30/145, Loss: 0.1206
Epoch 9/10, Batch 40/145, Loss: 0.1061
Epoch 9/10, Batch 50/145, Loss: 0.1753
Epoch 9/10, Batch 60/145, Loss: 0.3173
Epoch 9/10, Batch 70/145, Loss: 0.2137
Epoch 9/10, Batch 80/145, Loss: 0.0932
Epoch 9/10, Batch 90/145, Loss: 0.2081
Epoch 9/10, Batch 100/145, Loss: 0.1028
Epoch 9/10, Batch 110/145, Loss: 0.1910
Epoch 9/10, Batch 120/145, Loss: 0.1460
Epoch 9/10, Batch 130/145, Loss: 0.3691
Epoch 9/10, Batch 140/145, Loss: 0.3821
Epoch 9/10, Train Loss: 0.2056, Valid Loss: 0.2294
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1575
Epoch 10/10, Batch 20/145, Loss: 0.1706
Epoch 10/10, Batch 30/145, Loss: 0.1204
Epoch 10/10, Batch 40/145, Loss: 0.1904
Epoch 10/10, Batch 50/145, Loss: 0.1829
Epoch 10/10, Batch 60/145, Loss: 0.1776
Epoch 10/10, Batch 70/145, Loss: 0.1584
Epoch 10/10, Batch 80/145, Loss: 0.1300
Epoch 10/10, Batch 90/145, Loss: 0.1205
Epoch 10/10, Batch 100/145, Loss: 0.2204
Epoch 10/10, Batch 110/145, Loss: 0.2602
Epoch 10/10, Batch 120/145, Loss: 0.3412
Epoch 10/10, Batch 130/145, Loss: 0.2478
Epoch 10/10, Batch 140/145, Loss: 0.3385
Epoch 10/10, Train Loss: 0.1943, Valid Loss: 0.2232
Model saved!
Accuracy: 0.9276
Precision: 0.9254
Recall: 0.9276
F1-score: 0.9256
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4656
Epoch 1/10, Batch 20/145, Loss: 0.9424
Epoch 1/10, Batch 30/145, Loss: 0.9087
Epoch 1/10, Batch 40/145, Loss: 0.8181
Epoch 1/10, Batch 50/145, Loss: 0.5563
Epoch 1/10, Batch 60/145, Loss: 0.5771
Epoch 1/10, Batch 70/145, Loss: 0.4855
Epoch 1/10, Batch 80/145, Loss: 0.5947
Epoch 1/10, Batch 90/145, Loss: 0.3455
Epoch 1/10, Batch 100/145, Loss: 0.4294
Epoch 1/10, Batch 110/145, Loss: 0.3737
Epoch 1/10, Batch 120/145, Loss: 0.6677
Epoch 1/10, Batch 130/145, Loss: 0.4109
Epoch 1/10, Batch 140/145, Loss: 0.3567
Epoch 1/10, Train Loss: 0.6775, Valid Loss: 0.3712
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4717
Epoch 2/10, Batch 20/145, Loss: 0.2270
Epoch 2/10, Batch 30/145, Loss: 0.2063
Epoch 2/10, Batch 40/145, Loss: 0.5095
Epoch 2/10, Batch 50/145, Loss: 0.3365
Epoch 2/10, Batch 60/145, Loss: 0.4810
Epoch 2/10, Batch 70/145, Loss: 0.2357
Epoch 2/10, Batch 80/145, Loss: 0.3907
Epoch 2/10, Batch 90/145, Loss: 0.2155
Epoch 2/10, Batch 100/145, Loss: 0.2843
Epoch 2/10, Batch 110/145, Loss: 0.3480
Epoch 2/10, Batch 120/145, Loss: 0.4085
Epoch 2/10, Batch 130/145, Loss: 0.2112
Epoch 2/10, Batch 140/145, Loss: 0.2134
Epoch 2/10, Train Loss: 0.3542, Valid Loss: 0.2856
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2512
Epoch 3/10, Batch 20/145, Loss: 0.1717
Epoch 3/10, Batch 30/145, Loss: 0.4377
Epoch 3/10, Batch 40/145, Loss: 0.2976
Epoch 3/10, Batch 50/145, Loss: 0.3117
Epoch 3/10, Batch 60/145, Loss: 0.4305
Epoch 3/10, Batch 70/145, Loss: 0.3597
Epoch 3/10, Batch 80/145, Loss: 0.2824
Epoch 3/10, Batch 90/145, Loss: 0.2032
Epoch 3/10, Batch 100/145, Loss: 0.3194
Epoch 3/10, Batch 110/145, Loss: 0.1673
Epoch 3/10, Batch 120/145, Loss: 0.2892
Epoch 3/10, Batch 130/145, Loss: 0.3430
Epoch 3/10, Batch 140/145, Loss: 0.2806
Epoch 3/10, Train Loss: 0.2983, Valid Loss: 0.2566
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.1633
Epoch 4/10, Batch 20/145, Loss: 0.3151
Epoch 4/10, Batch 30/145, Loss: 0.3401
Epoch 4/10, Batch 40/145, Loss: 0.1285
Epoch 4/10, Batch 50/145, Loss: 0.1803
Epoch 4/10, Batch 60/145, Loss: 0.2748
Epoch 4/10, Batch 70/145, Loss: 0.1930
Epoch 4/10, Batch 80/145, Loss: 0.1546
Epoch 4/10, Batch 90/145, Loss: 0.2699
Epoch 4/10, Batch 100/145, Loss: 0.1318
Epoch 4/10, Batch 110/145, Loss: 0.1285
Epoch 4/10, Batch 120/145, Loss: 0.2743
Epoch 4/10, Batch 130/145, Loss: 0.1500
Epoch 4/10, Batch 140/145, Loss: 0.1738
Epoch 4/10, Train Loss: 0.2628, Valid Loss: 0.2432
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1968
Epoch 5/10, Batch 20/145, Loss: 0.1233
Epoch 5/10, Batch 30/145, Loss: 0.3447
Epoch 5/10, Batch 40/145, Loss: 0.1812
Epoch 5/10, Batch 50/145, Loss: 0.3496
Epoch 5/10, Batch 60/145, Loss: 0.2880
Epoch 5/10, Batch 70/145, Loss: 0.1174
Epoch 5/10, Batch 80/145, Loss: 0.1963
Epoch 5/10, Batch 90/145, Loss: 0.3150
Epoch 5/10, Batch 100/145, Loss: 0.1943
Epoch 5/10, Batch 110/145, Loss: 0.0709
Epoch 5/10, Batch 120/145, Loss: 0.4226
Epoch 5/10, Batch 130/145, Loss: 0.1870
Epoch 5/10, Batch 140/145, Loss: 0.2452
Epoch 5/10, Train Loss: 0.2455, Valid Loss: 0.2281
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2224
Epoch 6/10, Batch 20/145, Loss: 0.2234
Epoch 6/10, Batch 30/145, Loss: 0.3956
Epoch 6/10, Batch 40/145, Loss: 0.1824
Epoch 6/10, Batch 50/145, Loss: 0.3048
Epoch 6/10, Batch 60/145, Loss: 0.1862
Epoch 6/10, Batch 70/145, Loss: 0.1896
Epoch 6/10, Batch 80/145, Loss: 0.2582
Epoch 6/10, Batch 90/145, Loss: 0.2084
Epoch 6/10, Batch 100/145, Loss: 0.2322
Epoch 6/10, Batch 110/145, Loss: 0.1045
Epoch 6/10, Batch 120/145, Loss: 0.3823
Epoch 6/10, Batch 130/145, Loss: 0.1778
Epoch 6/10, Batch 140/145, Loss: 0.0491
Epoch 6/10, Train Loss: 0.2304, Valid Loss: 0.2224
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2192
Epoch 7/10, Batch 20/145, Loss: 0.3526
Epoch 7/10, Batch 30/145, Loss: 0.1854
Epoch 7/10, Batch 40/145, Loss: 0.2655
Epoch 7/10, Batch 50/145, Loss: 0.3333
Epoch 7/10, Batch 60/145, Loss: 0.2130
Epoch 7/10, Batch 70/145, Loss: 0.2228
Epoch 7/10, Batch 80/145, Loss: 0.4092
Epoch 7/10, Batch 90/145, Loss: 0.1062
Epoch 7/10, Batch 100/145, Loss: 0.1781
Epoch 7/10, Batch 110/145, Loss: 0.1088
Epoch 7/10, Batch 120/145, Loss: 0.1722
Epoch 7/10, Batch 130/145, Loss: 0.0833
Epoch 7/10, Batch 140/145, Loss: 0.2404
Epoch 7/10, Train Loss: 0.2111, Valid Loss: 0.2119
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1295
Epoch 8/10, Batch 20/145, Loss: 0.2918
Epoch 8/10, Batch 30/145, Loss: 0.1626
Epoch 8/10, Batch 40/145, Loss: 0.1009
Epoch 8/10, Batch 50/145, Loss: 0.1863
Epoch 8/10, Batch 60/145, Loss: 0.3858
Epoch 8/10, Batch 70/145, Loss: 0.2849
Epoch 8/10, Batch 80/145, Loss: 0.2098
Epoch 8/10, Batch 90/145, Loss: 0.3095
Epoch 8/10, Batch 100/145, Loss: 0.2835
Epoch 8/10, Batch 110/145, Loss: 0.1249
Epoch 8/10, Batch 120/145, Loss: 0.2103
Epoch 8/10, Batch 130/145, Loss: 0.1534
Epoch 8/10, Batch 140/145, Loss: 0.1516
Epoch 8/10, Train Loss: 0.2140, Valid Loss: 0.2074
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1742
Epoch 9/10, Batch 20/145, Loss: 0.1045
Epoch 9/10, Batch 30/145, Loss: 0.1788
Epoch 9/10, Batch 40/145, Loss: 0.3282
Epoch 9/10, Batch 50/145, Loss: 0.2276
Epoch 9/10, Batch 60/145, Loss: 0.2880
Epoch 9/10, Batch 70/145, Loss: 0.2912
Epoch 9/10, Batch 80/145, Loss: 0.1165
Epoch 9/10, Batch 90/145, Loss: 0.1553
Epoch 9/10, Batch 100/145, Loss: 0.1698
Epoch 9/10, Batch 110/145, Loss: 0.4397
Epoch 9/10, Batch 120/145, Loss: 0.1444
Epoch 9/10, Batch 130/145, Loss: 0.2045
Epoch 9/10, Batch 140/145, Loss: 0.1788
Epoch 9/10, Train Loss: 0.2038, Valid Loss: 0.2081
Epoch 10/10, Batch 10/145, Loss: 0.1276
Epoch 10/10, Batch 20/145, Loss: 0.0922
Epoch 10/10, Batch 30/145, Loss: 0.1066
Epoch 10/10, Batch 40/145, Loss: 0.1048
Epoch 10/10, Batch 50/145, Loss: 0.1837
Epoch 10/10, Batch 60/145, Loss: 0.1911
Epoch 10/10, Batch 70/145, Loss: 0.4239
Epoch 10/10, Batch 80/145, Loss: 0.1776
Epoch 10/10, Batch 90/145, Loss: 0.1199
Epoch 10/10, Batch 100/145, Loss: 0.2331
Epoch 10/10, Batch 110/145, Loss: 0.2341
Epoch 10/10, Batch 120/145, Loss: 0.3383
Epoch 10/10, Batch 130/145, Loss: 0.0902
Epoch 10/10, Batch 140/145, Loss: 0.3028
Epoch 10/10, Train Loss: 0.1991, Valid Loss: 0.2008
Model saved!
Accuracy: 0.9276
Precision: 0.9252
Recall: 0.9276
F1-score: 0.9260
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4742
Epoch 1/10, Batch 20/145, Loss: 0.8621
Epoch 1/10, Batch 30/145, Loss: 0.9266
Epoch 1/10, Batch 40/145, Loss: 0.7175
Epoch 1/10, Batch 50/145, Loss: 0.7536
Epoch 1/10, Batch 60/145, Loss: 0.5788
Epoch 1/10, Batch 70/145, Loss: 0.4126
Epoch 1/10, Batch 80/145, Loss: 0.5067
Epoch 1/10, Batch 90/145, Loss: 0.4208
Epoch 1/10, Batch 100/145, Loss: 0.5628
Epoch 1/10, Batch 110/145, Loss: 0.3862
Epoch 1/10, Batch 120/145, Loss: 0.5347
Epoch 1/10, Batch 130/145, Loss: 0.5655
Epoch 1/10, Batch 140/145, Loss: 0.4157
Epoch 1/10, Train Loss: 0.6823, Valid Loss: 0.3827
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.5064
Epoch 2/10, Batch 20/145, Loss: 0.2881
Epoch 2/10, Batch 30/145, Loss: 0.2588
Epoch 2/10, Batch 40/145, Loss: 0.3669
Epoch 2/10, Batch 50/145, Loss: 0.3676
Epoch 2/10, Batch 60/145, Loss: 0.4409
Epoch 2/10, Batch 70/145, Loss: 0.3140
Epoch 2/10, Batch 80/145, Loss: 0.3611
Epoch 2/10, Batch 90/145, Loss: 0.2672
Epoch 2/10, Batch 100/145, Loss: 0.4046
Epoch 2/10, Batch 110/145, Loss: 0.3369
Epoch 2/10, Batch 120/145, Loss: 0.2323
Epoch 2/10, Batch 130/145, Loss: 0.2568
Epoch 2/10, Batch 140/145, Loss: 0.4504
Epoch 2/10, Train Loss: 0.3581, Valid Loss: 0.2992
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2445
Epoch 3/10, Batch 20/145, Loss: 0.2027
Epoch 3/10, Batch 30/145, Loss: 0.3357
Epoch 3/10, Batch 40/145, Loss: 0.2238
Epoch 3/10, Batch 50/145, Loss: 0.2642
Epoch 3/10, Batch 60/145, Loss: 0.2600
Epoch 3/10, Batch 70/145, Loss: 0.3445
Epoch 3/10, Batch 80/145, Loss: 0.1988
Epoch 3/10, Batch 90/145, Loss: 0.2812
Epoch 3/10, Batch 100/145, Loss: 0.4328
Epoch 3/10, Batch 110/145, Loss: 0.1493
Epoch 3/10, Batch 120/145, Loss: 0.2284
Epoch 3/10, Batch 130/145, Loss: 0.1834
Epoch 3/10, Batch 140/145, Loss: 0.3323
Epoch 3/10, Train Loss: 0.2962, Valid Loss: 0.2630
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2806
Epoch 4/10, Batch 20/145, Loss: 0.2996
Epoch 4/10, Batch 30/145, Loss: 0.3724
Epoch 4/10, Batch 40/145, Loss: 0.2293
Epoch 4/10, Batch 50/145, Loss: 0.2385
Epoch 4/10, Batch 60/145, Loss: 0.3334
Epoch 4/10, Batch 70/145, Loss: 0.2059
Epoch 4/10, Batch 80/145, Loss: 0.3091
Epoch 4/10, Batch 90/145, Loss: 0.4698
Epoch 4/10, Batch 100/145, Loss: 0.3098
Epoch 4/10, Batch 110/145, Loss: 0.1289
Epoch 4/10, Batch 120/145, Loss: 0.3153
Epoch 4/10, Batch 130/145, Loss: 0.1197
Epoch 4/10, Batch 140/145, Loss: 0.2423
Epoch 4/10, Train Loss: 0.2626, Valid Loss: 0.2519
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1821
Epoch 5/10, Batch 20/145, Loss: 0.2380
Epoch 5/10, Batch 30/145, Loss: 0.3712
Epoch 5/10, Batch 40/145, Loss: 0.1133
Epoch 5/10, Batch 50/145, Loss: 0.2587
Epoch 5/10, Batch 60/145, Loss: 0.2883
Epoch 5/10, Batch 70/145, Loss: 0.3299
Epoch 5/10, Batch 80/145, Loss: 0.1564
Epoch 5/10, Batch 90/145, Loss: 0.2506
Epoch 5/10, Batch 100/145, Loss: 0.2683
Epoch 5/10, Batch 110/145, Loss: 0.1635
Epoch 5/10, Batch 120/145, Loss: 0.3372
Epoch 5/10, Batch 130/145, Loss: 0.2025
Epoch 5/10, Batch 140/145, Loss: 0.2368
Epoch 5/10, Train Loss: 0.2461, Valid Loss: 0.2371
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1781
Epoch 6/10, Batch 20/145, Loss: 0.3771
Epoch 6/10, Batch 30/145, Loss: 0.2990
Epoch 6/10, Batch 40/145, Loss: 0.1386
Epoch 6/10, Batch 50/145, Loss: 0.3190
Epoch 6/10, Batch 60/145, Loss: 0.2069
Epoch 6/10, Batch 70/145, Loss: 0.3062
Epoch 6/10, Batch 80/145, Loss: 0.1936
Epoch 6/10, Batch 90/145, Loss: 0.3157
Epoch 6/10, Batch 100/145, Loss: 0.2877
Epoch 6/10, Batch 110/145, Loss: 0.1566
Epoch 6/10, Batch 120/145, Loss: 0.2510
Epoch 6/10, Batch 130/145, Loss: 0.1566
Epoch 6/10, Batch 140/145, Loss: 0.2606
Epoch 6/10, Train Loss: 0.2320, Valid Loss: 0.2317
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3056
Epoch 7/10, Batch 20/145, Loss: 0.2030
Epoch 7/10, Batch 30/145, Loss: 0.1697
Epoch 7/10, Batch 40/145, Loss: 0.2832
Epoch 7/10, Batch 50/145, Loss: 0.1976
Epoch 7/10, Batch 60/145, Loss: 0.1373
Epoch 7/10, Batch 70/145, Loss: 0.1398
Epoch 7/10, Batch 80/145, Loss: 0.4155
Epoch 7/10, Batch 90/145, Loss: 0.2078
Epoch 7/10, Batch 100/145, Loss: 0.2542
Epoch 7/10, Batch 110/145, Loss: 0.2316
Epoch 7/10, Batch 120/145, Loss: 0.3028
Epoch 7/10, Batch 130/145, Loss: 0.1467
Epoch 7/10, Batch 140/145, Loss: 0.4229
Epoch 7/10, Train Loss: 0.2212, Valid Loss: 0.2224
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2303
Epoch 8/10, Batch 20/145, Loss: 0.2028
Epoch 8/10, Batch 30/145, Loss: 0.3993
Epoch 8/10, Batch 40/145, Loss: 0.2470
Epoch 8/10, Batch 50/145, Loss: 0.2584
Epoch 8/10, Batch 60/145, Loss: 0.1688
Epoch 8/10, Batch 70/145, Loss: 0.3432
Epoch 8/10, Batch 80/145, Loss: 0.1952
Epoch 8/10, Batch 90/145, Loss: 0.3252
Epoch 8/10, Batch 100/145, Loss: 0.1028
Epoch 8/10, Batch 110/145, Loss: 0.1657
Epoch 8/10, Batch 120/145, Loss: 0.1975
Epoch 8/10, Batch 130/145, Loss: 0.0930
Epoch 8/10, Batch 140/145, Loss: 0.1586
Epoch 8/10, Train Loss: 0.2160, Valid Loss: 0.2183
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3453
Epoch 9/10, Batch 20/145, Loss: 0.1607
Epoch 9/10, Batch 30/145, Loss: 0.1290
Epoch 9/10, Batch 40/145, Loss: 0.2083
Epoch 9/10, Batch 50/145, Loss: 0.1692
Epoch 9/10, Batch 60/145, Loss: 0.2969
Epoch 9/10, Batch 70/145, Loss: 0.1582
Epoch 9/10, Batch 80/145, Loss: 0.1240
Epoch 9/10, Batch 90/145, Loss: 0.4996
Epoch 9/10, Batch 100/145, Loss: 0.1756
Epoch 9/10, Batch 110/145, Loss: 0.2776
Epoch 9/10, Batch 120/145, Loss: 0.1118
Epoch 9/10, Batch 130/145, Loss: 0.1032
Epoch 9/10, Batch 140/145, Loss: 0.1930
Epoch 9/10, Train Loss: 0.2003, Valid Loss: 0.2231
Epoch 10/10, Batch 10/145, Loss: 0.1899
Epoch 10/10, Batch 20/145, Loss: 0.1913
Epoch 10/10, Batch 30/145, Loss: 0.1726
Epoch 10/10, Batch 40/145, Loss: 0.1335
Epoch 10/10, Batch 50/145, Loss: 0.2323
Epoch 10/10, Batch 60/145, Loss: 0.2055
Epoch 10/10, Batch 70/145, Loss: 0.3163
Epoch 10/10, Batch 80/145, Loss: 0.1453
Epoch 10/10, Batch 90/145, Loss: 0.0957
Epoch 10/10, Batch 100/145, Loss: 0.1765
Epoch 10/10, Batch 110/145, Loss: 0.2180
Epoch 10/10, Batch 120/145, Loss: 0.1651
Epoch 10/10, Batch 130/145, Loss: 0.2035
Epoch 10/10, Batch 140/145, Loss: 0.1289
Epoch 10/10, Train Loss: 0.2016, Valid Loss: 0.2161
Model saved!
Accuracy: 0.9182
Precision: 0.9157
Recall: 0.9182
F1-score: 0.9165
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3998
Epoch 1/10, Batch 20/145, Loss: 0.9415
Epoch 1/10, Batch 30/145, Loss: 0.8153
Epoch 1/10, Batch 40/145, Loss: 0.8247
Epoch 1/10, Batch 50/145, Loss: 0.6265
Epoch 1/10, Batch 60/145, Loss: 0.6449
Epoch 1/10, Batch 70/145, Loss: 0.5117
Epoch 1/10, Batch 80/145, Loss: 0.5777
Epoch 1/10, Batch 90/145, Loss: 0.3632
Epoch 1/10, Batch 100/145, Loss: 0.4721
Epoch 1/10, Batch 110/145, Loss: 0.3982
Epoch 1/10, Batch 120/145, Loss: 0.5518
Epoch 1/10, Batch 130/145, Loss: 0.5164
Epoch 1/10, Batch 140/145, Loss: 0.3178
Epoch 1/10, Train Loss: 0.6731, Valid Loss: 0.3980
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3543
Epoch 2/10, Batch 20/145, Loss: 0.2550
Epoch 2/10, Batch 30/145, Loss: 0.4830
Epoch 2/10, Batch 40/145, Loss: 0.4820
Epoch 2/10, Batch 50/145, Loss: 0.3739
Epoch 2/10, Batch 60/145, Loss: 0.3341
Epoch 2/10, Batch 70/145, Loss: 0.2869
Epoch 2/10, Batch 80/145, Loss: 0.4216
Epoch 2/10, Batch 90/145, Loss: 0.4495
Epoch 2/10, Batch 100/145, Loss: 0.2783
Epoch 2/10, Batch 110/145, Loss: 0.3167
Epoch 2/10, Batch 120/145, Loss: 0.4247
Epoch 2/10, Batch 130/145, Loss: 0.3899
Epoch 2/10, Batch 140/145, Loss: 0.1689
Epoch 2/10, Train Loss: 0.3500, Valid Loss: 0.3152
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2128
Epoch 3/10, Batch 20/145, Loss: 0.2051
Epoch 3/10, Batch 30/145, Loss: 0.3357
Epoch 3/10, Batch 40/145, Loss: 0.3330
Epoch 3/10, Batch 50/145, Loss: 0.1312
Epoch 3/10, Batch 60/145, Loss: 0.3762
Epoch 3/10, Batch 70/145, Loss: 0.3285
Epoch 3/10, Batch 80/145, Loss: 0.2909
Epoch 3/10, Batch 90/145, Loss: 0.4565
Epoch 3/10, Batch 100/145, Loss: 0.4515
Epoch 3/10, Batch 110/145, Loss: 0.3807
Epoch 3/10, Batch 120/145, Loss: 0.2382
Epoch 3/10, Batch 130/145, Loss: 0.4738
Epoch 3/10, Batch 140/145, Loss: 0.2427
Epoch 3/10, Train Loss: 0.2911, Valid Loss: 0.2865
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3274
Epoch 4/10, Batch 20/145, Loss: 0.3520
Epoch 4/10, Batch 30/145, Loss: 0.1870
Epoch 4/10, Batch 40/145, Loss: 0.2043
Epoch 4/10, Batch 50/145, Loss: 0.1685
Epoch 4/10, Batch 60/145, Loss: 0.4292
Epoch 4/10, Batch 70/145, Loss: 0.1792
Epoch 4/10, Batch 80/145, Loss: 0.2101
Epoch 4/10, Batch 90/145, Loss: 0.2089
Epoch 4/10, Batch 100/145, Loss: 0.3367
Epoch 4/10, Batch 110/145, Loss: 0.1661
Epoch 4/10, Batch 120/145, Loss: 0.2412
Epoch 4/10, Batch 130/145, Loss: 0.2951
Epoch 4/10, Batch 140/145, Loss: 0.2043
Epoch 4/10, Train Loss: 0.2573, Valid Loss: 0.2724
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2171
Epoch 5/10, Batch 20/145, Loss: 0.1366
Epoch 5/10, Batch 30/145, Loss: 0.3337
Epoch 5/10, Batch 40/145, Loss: 0.2341
Epoch 5/10, Batch 50/145, Loss: 0.1081
Epoch 5/10, Batch 60/145, Loss: 0.3115
Epoch 5/10, Batch 70/145, Loss: 0.3816
Epoch 5/10, Batch 80/145, Loss: 0.2420
Epoch 5/10, Batch 90/145, Loss: 0.2750
Epoch 5/10, Batch 100/145, Loss: 0.2798
Epoch 5/10, Batch 110/145, Loss: 0.1968
Epoch 5/10, Batch 120/145, Loss: 0.2980
Epoch 5/10, Batch 130/145, Loss: 0.1350
Epoch 5/10, Batch 140/145, Loss: 0.1858
Epoch 5/10, Train Loss: 0.2462, Valid Loss: 0.2592
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.0751
Epoch 6/10, Batch 20/145, Loss: 0.2354
Epoch 6/10, Batch 30/145, Loss: 0.3124
Epoch 6/10, Batch 40/145, Loss: 0.1455
Epoch 6/10, Batch 50/145, Loss: 0.3098
Epoch 6/10, Batch 60/145, Loss: 0.1701
Epoch 6/10, Batch 70/145, Loss: 0.2364
Epoch 6/10, Batch 80/145, Loss: 0.1374
Epoch 6/10, Batch 90/145, Loss: 0.2833
Epoch 6/10, Batch 100/145, Loss: 0.3078
Epoch 6/10, Batch 110/145, Loss: 0.2395
Epoch 6/10, Batch 120/145, Loss: 0.3707
Epoch 6/10, Batch 130/145, Loss: 0.3959
Epoch 6/10, Batch 140/145, Loss: 0.3466
Epoch 6/10, Train Loss: 0.2216, Valid Loss: 0.2481
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3085
Epoch 7/10, Batch 20/145, Loss: 0.1520
Epoch 7/10, Batch 30/145, Loss: 0.1340
Epoch 7/10, Batch 40/145, Loss: 0.2205
Epoch 7/10, Batch 50/145, Loss: 0.1493
Epoch 7/10, Batch 60/145, Loss: 0.1097
Epoch 7/10, Batch 70/145, Loss: 0.1667
Epoch 7/10, Batch 80/145, Loss: 0.4460
Epoch 7/10, Batch 90/145, Loss: 0.1060
Epoch 7/10, Batch 100/145, Loss: 0.1904
Epoch 7/10, Batch 110/145, Loss: 0.1239
Epoch 7/10, Batch 120/145, Loss: 0.1978
Epoch 7/10, Batch 130/145, Loss: 0.0854
Epoch 7/10, Batch 140/145, Loss: 0.1758
Epoch 7/10, Train Loss: 0.2079, Valid Loss: 0.2442
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2489
Epoch 8/10, Batch 20/145, Loss: 0.1821
Epoch 8/10, Batch 30/145, Loss: 0.3371
Epoch 8/10, Batch 40/145, Loss: 0.2441
Epoch 8/10, Batch 50/145, Loss: 0.3150
Epoch 8/10, Batch 60/145, Loss: 0.2335
Epoch 8/10, Batch 70/145, Loss: 0.2631
Epoch 8/10, Batch 80/145, Loss: 0.3171
Epoch 8/10, Batch 90/145, Loss: 0.2395
Epoch 8/10, Batch 100/145, Loss: 0.2531
Epoch 8/10, Batch 110/145, Loss: 0.2781
Epoch 8/10, Batch 120/145, Loss: 0.0530
Epoch 8/10, Batch 130/145, Loss: 0.1944
Epoch 8/10, Batch 140/145, Loss: 0.2055
Epoch 8/10, Train Loss: 0.2041, Valid Loss: 0.2404
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2622
Epoch 9/10, Batch 20/145, Loss: 0.1177
Epoch 9/10, Batch 30/145, Loss: 0.0899
Epoch 9/10, Batch 40/145, Loss: 0.1257
Epoch 9/10, Batch 50/145, Loss: 0.2002
Epoch 9/10, Batch 60/145, Loss: 0.3468
Epoch 9/10, Batch 70/145, Loss: 0.0980
Epoch 9/10, Batch 80/145, Loss: 0.1010
Epoch 9/10, Batch 90/145, Loss: 0.3889
Epoch 9/10, Batch 100/145, Loss: 0.0949
Epoch 9/10, Batch 110/145, Loss: 0.1834
Epoch 9/10, Batch 120/145, Loss: 0.1020
Epoch 9/10, Batch 130/145, Loss: 0.1013
Epoch 9/10, Batch 140/145, Loss: 0.1719
Epoch 9/10, Train Loss: 0.1975, Valid Loss: 0.2385
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1589
Epoch 10/10, Batch 20/145, Loss: 0.2464
Epoch 10/10, Batch 30/145, Loss: 0.2433
Epoch 10/10, Batch 40/145, Loss: 0.0731
Epoch 10/10, Batch 50/145, Loss: 0.1794
Epoch 10/10, Batch 60/145, Loss: 0.2462
Epoch 10/10, Batch 70/145, Loss: 0.2620
Epoch 10/10, Batch 80/145, Loss: 0.1454
Epoch 10/10, Batch 90/145, Loss: 0.1669
Epoch 10/10, Batch 100/145, Loss: 0.1598
Epoch 10/10, Batch 110/145, Loss: 0.1704
Epoch 10/10, Batch 120/145, Loss: 0.1870
Epoch 10/10, Batch 130/145, Loss: 0.1470
Epoch 10/10, Batch 140/145, Loss: 0.3703
Epoch 10/10, Train Loss: 0.1937, Valid Loss: 0.2328
Model saved!
Accuracy: 0.9182
Precision: 0.9159
Recall: 0.9182
F1-score: 0.9158
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3523
Epoch 1/10, Batch 20/145, Loss: 0.8920
Epoch 1/10, Batch 30/145, Loss: 0.9019
Epoch 1/10, Batch 40/145, Loss: 0.8552
Epoch 1/10, Batch 50/145, Loss: 0.7668
Epoch 1/10, Batch 60/145, Loss: 0.7329
Epoch 1/10, Batch 70/145, Loss: 0.4300
Epoch 1/10, Batch 80/145, Loss: 0.5933
Epoch 1/10, Batch 90/145, Loss: 0.4370
Epoch 1/10, Batch 100/145, Loss: 0.5026
Epoch 1/10, Batch 110/145, Loss: 0.4366
Epoch 1/10, Batch 120/145, Loss: 0.6087
Epoch 1/10, Batch 130/145, Loss: 0.5706
Epoch 1/10, Batch 140/145, Loss: 0.3499
Epoch 1/10, Train Loss: 0.6746, Valid Loss: 0.3622
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2457
Epoch 2/10, Batch 20/145, Loss: 0.3053
Epoch 2/10, Batch 30/145, Loss: 0.2425
Epoch 2/10, Batch 40/145, Loss: 0.5838
Epoch 2/10, Batch 50/145, Loss: 0.2955
Epoch 2/10, Batch 60/145, Loss: 0.4714
Epoch 2/10, Batch 70/145, Loss: 0.3230
Epoch 2/10, Batch 80/145, Loss: 0.4588
Epoch 2/10, Batch 90/145, Loss: 0.2881
Epoch 2/10, Batch 100/145, Loss: 0.2756
Epoch 2/10, Batch 110/145, Loss: 0.2755
Epoch 2/10, Batch 120/145, Loss: 0.3035
Epoch 2/10, Batch 130/145, Loss: 0.2958
Epoch 2/10, Batch 140/145, Loss: 0.3218
Epoch 2/10, Train Loss: 0.3594, Valid Loss: 0.2798
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3283
Epoch 3/10, Batch 20/145, Loss: 0.2101
Epoch 3/10, Batch 30/145, Loss: 0.4343
Epoch 3/10, Batch 40/145, Loss: 0.2032
Epoch 3/10, Batch 50/145, Loss: 0.2799
Epoch 3/10, Batch 60/145, Loss: 0.3480
Epoch 3/10, Batch 70/145, Loss: 0.3348
Epoch 3/10, Batch 80/145, Loss: 0.2214
Epoch 3/10, Batch 90/145, Loss: 0.3781
Epoch 3/10, Batch 100/145, Loss: 0.2928
Epoch 3/10, Batch 110/145, Loss: 0.2048
Epoch 3/10, Batch 120/145, Loss: 0.2467
Epoch 3/10, Batch 130/145, Loss: 0.3309
Epoch 3/10, Batch 140/145, Loss: 0.1429
Epoch 3/10, Train Loss: 0.2970, Valid Loss: 0.2438
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3281
Epoch 4/10, Batch 20/145, Loss: 0.2773
Epoch 4/10, Batch 30/145, Loss: 0.3740
Epoch 4/10, Batch 40/145, Loss: 0.1383
Epoch 4/10, Batch 50/145, Loss: 0.1783
Epoch 4/10, Batch 60/145, Loss: 0.2706
Epoch 4/10, Batch 70/145, Loss: 0.2627
Epoch 4/10, Batch 80/145, Loss: 0.1522
Epoch 4/10, Batch 90/145, Loss: 0.3305
Epoch 4/10, Batch 100/145, Loss: 0.2771
Epoch 4/10, Batch 110/145, Loss: 0.2148
Epoch 4/10, Batch 120/145, Loss: 0.1821
Epoch 4/10, Batch 130/145, Loss: 0.1557
Epoch 4/10, Batch 140/145, Loss: 0.2272
Epoch 4/10, Train Loss: 0.2651, Valid Loss: 0.2305
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1516
Epoch 5/10, Batch 20/145, Loss: 0.2346
Epoch 5/10, Batch 30/145, Loss: 0.2732
Epoch 5/10, Batch 40/145, Loss: 0.1940
Epoch 5/10, Batch 50/145, Loss: 0.1688
Epoch 5/10, Batch 60/145, Loss: 0.2077
Epoch 5/10, Batch 70/145, Loss: 0.2057
Epoch 5/10, Batch 80/145, Loss: 0.1003
Epoch 5/10, Batch 90/145, Loss: 0.2949
Epoch 5/10, Batch 100/145, Loss: 0.2890
Epoch 5/10, Batch 110/145, Loss: 0.1400
Epoch 5/10, Batch 120/145, Loss: 0.3982
Epoch 5/10, Batch 130/145, Loss: 0.1511
Epoch 5/10, Batch 140/145, Loss: 0.1961
Epoch 5/10, Train Loss: 0.2464, Valid Loss: 0.2208
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3052
Epoch 6/10, Batch 20/145, Loss: 0.4434
Epoch 6/10, Batch 30/145, Loss: 0.3584
Epoch 6/10, Batch 40/145, Loss: 0.1082
Epoch 6/10, Batch 50/145, Loss: 0.4937
Epoch 6/10, Batch 60/145, Loss: 0.1870
Epoch 6/10, Batch 70/145, Loss: 0.0996
Epoch 6/10, Batch 80/145, Loss: 0.1238
Epoch 6/10, Batch 90/145, Loss: 0.2340
Epoch 6/10, Batch 100/145, Loss: 0.2746
Epoch 6/10, Batch 110/145, Loss: 0.3316
Epoch 6/10, Batch 120/145, Loss: 0.3006
Epoch 6/10, Batch 130/145, Loss: 0.0858
Epoch 6/10, Batch 140/145, Loss: 0.1371
Epoch 6/10, Train Loss: 0.2301, Valid Loss: 0.2101
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3072
Epoch 7/10, Batch 20/145, Loss: 0.1821
Epoch 7/10, Batch 30/145, Loss: 0.1338
Epoch 7/10, Batch 40/145, Loss: 0.2369
Epoch 7/10, Batch 50/145, Loss: 0.1865
Epoch 7/10, Batch 60/145, Loss: 0.1197
Epoch 7/10, Batch 70/145, Loss: 0.1599
Epoch 7/10, Batch 80/145, Loss: 0.4125
Epoch 7/10, Batch 90/145, Loss: 0.3388
Epoch 7/10, Batch 100/145, Loss: 0.2637
Epoch 7/10, Batch 110/145, Loss: 0.1597
Epoch 7/10, Batch 120/145, Loss: 0.2659
Epoch 7/10, Batch 130/145, Loss: 0.0981
Epoch 7/10, Batch 140/145, Loss: 0.3262
Epoch 7/10, Train Loss: 0.2154, Valid Loss: 0.2077
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1280
Epoch 8/10, Batch 20/145, Loss: 0.1626
Epoch 8/10, Batch 30/145, Loss: 0.3622
Epoch 8/10, Batch 40/145, Loss: 0.2328
Epoch 8/10, Batch 50/145, Loss: 0.2982
Epoch 8/10, Batch 60/145, Loss: 0.2597
Epoch 8/10, Batch 70/145, Loss: 0.3634
Epoch 8/10, Batch 80/145, Loss: 0.4087
Epoch 8/10, Batch 90/145, Loss: 0.2335
Epoch 8/10, Batch 100/145, Loss: 0.1052
Epoch 8/10, Batch 110/145, Loss: 0.2171
Epoch 8/10, Batch 120/145, Loss: 0.1825
Epoch 8/10, Batch 130/145, Loss: 0.2138
Epoch 8/10, Batch 140/145, Loss: 0.2195
Epoch 8/10, Train Loss: 0.2002, Valid Loss: 0.2016
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1576
Epoch 9/10, Batch 20/145, Loss: 0.1436
Epoch 9/10, Batch 30/145, Loss: 0.1519
Epoch 9/10, Batch 40/145, Loss: 0.2116
Epoch 9/10, Batch 50/145, Loss: 0.3566
Epoch 9/10, Batch 60/145, Loss: 0.2526
Epoch 9/10, Batch 70/145, Loss: 0.0855
Epoch 9/10, Batch 80/145, Loss: 0.1883
Epoch 9/10, Batch 90/145, Loss: 0.1143
Epoch 9/10, Batch 100/145, Loss: 0.2526
Epoch 9/10, Batch 110/145, Loss: 0.3470
Epoch 9/10, Batch 120/145, Loss: 0.1312
Epoch 9/10, Batch 130/145, Loss: 0.1901
Epoch 9/10, Batch 140/145, Loss: 0.1140
Epoch 9/10, Train Loss: 0.2043, Valid Loss: 0.1988
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1471
Epoch 10/10, Batch 20/145, Loss: 0.2245
Epoch 10/10, Batch 30/145, Loss: 0.2386
Epoch 10/10, Batch 40/145, Loss: 0.1289
Epoch 10/10, Batch 50/145, Loss: 0.1598
Epoch 10/10, Batch 60/145, Loss: 0.1475
Epoch 10/10, Batch 70/145, Loss: 0.3087
Epoch 10/10, Batch 80/145, Loss: 0.2071
Epoch 10/10, Batch 90/145, Loss: 0.1128
Epoch 10/10, Batch 100/145, Loss: 0.2367
Epoch 10/10, Batch 110/145, Loss: 0.1805
Epoch 10/10, Batch 120/145, Loss: 0.3130
Epoch 10/10, Batch 130/145, Loss: 0.0870
Epoch 10/10, Batch 140/145, Loss: 0.3021
Epoch 10/10, Train Loss: 0.1946, Valid Loss: 0.1998
Accuracy: 0.9194
Precision: 0.9173
Recall: 0.9194
F1-score: 0.9179
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3140
Epoch 1/10, Batch 20/145, Loss: 0.9438
Epoch 1/10, Batch 30/145, Loss: 0.9118
Epoch 1/10, Batch 40/145, Loss: 0.8123
Epoch 1/10, Batch 50/145, Loss: 0.6316
Epoch 1/10, Batch 60/145, Loss: 0.7339
Epoch 1/10, Batch 70/145, Loss: 0.5752
Epoch 1/10, Batch 80/145, Loss: 0.6036
Epoch 1/10, Batch 90/145, Loss: 0.3484
Epoch 1/10, Batch 100/145, Loss: 0.5572
Epoch 1/10, Batch 110/145, Loss: 0.4423
Epoch 1/10, Batch 120/145, Loss: 0.6302
Epoch 1/10, Batch 130/145, Loss: 0.6022
Epoch 1/10, Batch 140/145, Loss: 0.3741
Epoch 1/10, Train Loss: 0.6727, Valid Loss: 0.3663
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.1944
Epoch 2/10, Batch 20/145, Loss: 0.3576
Epoch 2/10, Batch 30/145, Loss: 0.2745
Epoch 2/10, Batch 40/145, Loss: 0.4785
Epoch 2/10, Batch 50/145, Loss: 0.3841
Epoch 2/10, Batch 60/145, Loss: 0.3781
Epoch 2/10, Batch 70/145, Loss: 0.3463
Epoch 2/10, Batch 80/145, Loss: 0.3402
Epoch 2/10, Batch 90/145, Loss: 0.2615
Epoch 2/10, Batch 100/145, Loss: 0.2692
Epoch 2/10, Batch 110/145, Loss: 0.3610
Epoch 2/10, Batch 120/145, Loss: 0.3778
Epoch 2/10, Batch 130/145, Loss: 0.2821
Epoch 2/10, Batch 140/145, Loss: 0.2895
Epoch 2/10, Train Loss: 0.3533, Valid Loss: 0.2910
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1921
Epoch 3/10, Batch 20/145, Loss: 0.3440
Epoch 3/10, Batch 30/145, Loss: 0.3943
Epoch 3/10, Batch 40/145, Loss: 0.2436
Epoch 3/10, Batch 50/145, Loss: 0.2115
Epoch 3/10, Batch 60/145, Loss: 0.3566
Epoch 3/10, Batch 70/145, Loss: 0.4089
Epoch 3/10, Batch 80/145, Loss: 0.1863
Epoch 3/10, Batch 90/145, Loss: 0.2034
Epoch 3/10, Batch 100/145, Loss: 0.2420
Epoch 3/10, Batch 110/145, Loss: 0.2884
Epoch 3/10, Batch 120/145, Loss: 0.2905
Epoch 3/10, Batch 130/145, Loss: 0.2000
Epoch 3/10, Batch 140/145, Loss: 0.2100
Epoch 3/10, Train Loss: 0.2896, Valid Loss: 0.2571
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2488
Epoch 4/10, Batch 20/145, Loss: 0.4820
Epoch 4/10, Batch 30/145, Loss: 0.3341
Epoch 4/10, Batch 40/145, Loss: 0.1479
Epoch 4/10, Batch 50/145, Loss: 0.1137
Epoch 4/10, Batch 60/145, Loss: 0.2187
Epoch 4/10, Batch 70/145, Loss: 0.1935
Epoch 4/10, Batch 80/145, Loss: 0.1320
Epoch 4/10, Batch 90/145, Loss: 0.3587
Epoch 4/10, Batch 100/145, Loss: 0.2190
Epoch 4/10, Batch 110/145, Loss: 0.1986
Epoch 4/10, Batch 120/145, Loss: 0.2436
Epoch 4/10, Batch 130/145, Loss: 0.3216
Epoch 4/10, Batch 140/145, Loss: 0.1486
Epoch 4/10, Train Loss: 0.2598, Valid Loss: 0.2366
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2603
Epoch 5/10, Batch 20/145, Loss: 0.0977
Epoch 5/10, Batch 30/145, Loss: 0.1997
Epoch 5/10, Batch 40/145, Loss: 0.1500
Epoch 5/10, Batch 50/145, Loss: 0.3731
Epoch 5/10, Batch 60/145, Loss: 0.1884
Epoch 5/10, Batch 70/145, Loss: 0.2431
Epoch 5/10, Batch 80/145, Loss: 0.1401
Epoch 5/10, Batch 90/145, Loss: 0.3938
Epoch 5/10, Batch 100/145, Loss: 0.2997
Epoch 5/10, Batch 110/145, Loss: 0.2812
Epoch 5/10, Batch 120/145, Loss: 0.2556
Epoch 5/10, Batch 130/145, Loss: 0.1514
Epoch 5/10, Batch 140/145, Loss: 0.2645
Epoch 5/10, Train Loss: 0.2437, Valid Loss: 0.2320
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1476
Epoch 6/10, Batch 20/145, Loss: 0.2813
Epoch 6/10, Batch 30/145, Loss: 0.2110
Epoch 6/10, Batch 40/145, Loss: 0.1219
Epoch 6/10, Batch 50/145, Loss: 0.2243
Epoch 6/10, Batch 60/145, Loss: 0.1528
Epoch 6/10, Batch 70/145, Loss: 0.0893
Epoch 6/10, Batch 80/145, Loss: 0.2291
Epoch 6/10, Batch 90/145, Loss: 0.4061
Epoch 6/10, Batch 100/145, Loss: 0.1913
Epoch 6/10, Batch 110/145, Loss: 0.4139
Epoch 6/10, Batch 120/145, Loss: 0.3213
Epoch 6/10, Batch 130/145, Loss: 0.1525
Epoch 6/10, Batch 140/145, Loss: 0.1800
Epoch 6/10, Train Loss: 0.2318, Valid Loss: 0.2184
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2553
Epoch 7/10, Batch 20/145, Loss: 0.2096
Epoch 7/10, Batch 30/145, Loss: 0.2132
Epoch 7/10, Batch 40/145, Loss: 0.3587
Epoch 7/10, Batch 50/145, Loss: 0.2650
Epoch 7/10, Batch 60/145, Loss: 0.1913
Epoch 7/10, Batch 70/145, Loss: 0.1407
Epoch 7/10, Batch 80/145, Loss: 0.4081
Epoch 7/10, Batch 90/145, Loss: 0.1071
Epoch 7/10, Batch 100/145, Loss: 0.1342
Epoch 7/10, Batch 110/145, Loss: 0.3664
Epoch 7/10, Batch 120/145, Loss: 0.3750
Epoch 7/10, Batch 130/145, Loss: 0.1708
Epoch 7/10, Batch 140/145, Loss: 0.1552
Epoch 7/10, Train Loss: 0.2212, Valid Loss: 0.2216
Epoch 8/10, Batch 10/145, Loss: 0.0948
Epoch 8/10, Batch 20/145, Loss: 0.2068
Epoch 8/10, Batch 30/145, Loss: 0.3424
Epoch 8/10, Batch 40/145, Loss: 0.2384
Epoch 8/10, Batch 50/145, Loss: 0.2222
Epoch 8/10, Batch 60/145, Loss: 0.1544
Epoch 8/10, Batch 70/145, Loss: 0.2087
Epoch 8/10, Batch 80/145, Loss: 0.1670
Epoch 8/10, Batch 90/145, Loss: 0.3370
Epoch 8/10, Batch 100/145, Loss: 0.2158
Epoch 8/10, Batch 110/145, Loss: 0.3408
Epoch 8/10, Batch 120/145, Loss: 0.2083
Epoch 8/10, Batch 130/145, Loss: 0.1579
Epoch 8/10, Batch 140/145, Loss: 0.2138
Epoch 8/10, Train Loss: 0.2068, Valid Loss: 0.2145
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2079
Epoch 9/10, Batch 20/145, Loss: 0.2446
Epoch 9/10, Batch 30/145, Loss: 0.2255
Epoch 9/10, Batch 40/145, Loss: 0.2065
Epoch 9/10, Batch 50/145, Loss: 0.1509
Epoch 9/10, Batch 60/145, Loss: 0.2770
Epoch 9/10, Batch 70/145, Loss: 0.1922
Epoch 9/10, Batch 80/145, Loss: 0.1542
Epoch 9/10, Batch 90/145, Loss: 0.2110
Epoch 9/10, Batch 100/145, Loss: 0.2555
Epoch 9/10, Batch 110/145, Loss: 0.1870
Epoch 9/10, Batch 120/145, Loss: 0.2130
Epoch 9/10, Batch 130/145, Loss: 0.1527
Epoch 9/10, Batch 140/145, Loss: 0.2481
Epoch 9/10, Train Loss: 0.2006, Valid Loss: 0.2081
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1040
Epoch 10/10, Batch 20/145, Loss: 0.2671
Epoch 10/10, Batch 30/145, Loss: 0.0612
Epoch 10/10, Batch 40/145, Loss: 0.1757
Epoch 10/10, Batch 50/145, Loss: 0.1857
Epoch 10/10, Batch 60/145, Loss: 0.1861
Epoch 10/10, Batch 70/145, Loss: 0.3973
Epoch 10/10, Batch 80/145, Loss: 0.1960
Epoch 10/10, Batch 90/145, Loss: 0.1064
Epoch 10/10, Batch 100/145, Loss: 0.1825
Epoch 10/10, Batch 110/145, Loss: 0.3496
Epoch 10/10, Batch 120/145, Loss: 0.1504
Epoch 10/10, Batch 130/145, Loss: 0.1414
Epoch 10/10, Batch 140/145, Loss: 0.2819
Epoch 10/10, Train Loss: 0.1948, Valid Loss: 0.2129
Accuracy: 0.9206
Precision: 0.9181
Recall: 0.9206
F1-score: 0.9189
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4144
Epoch 1/10, Batch 20/145, Loss: 1.0675
Epoch 1/10, Batch 30/145, Loss: 0.9305
Epoch 1/10, Batch 40/145, Loss: 0.7965
Epoch 1/10, Batch 50/145, Loss: 0.6936
Epoch 1/10, Batch 60/145, Loss: 0.6103
Epoch 1/10, Batch 70/145, Loss: 0.3821
Epoch 1/10, Batch 80/145, Loss: 0.5315
Epoch 1/10, Batch 90/145, Loss: 0.4594
Epoch 1/10, Batch 100/145, Loss: 0.5446
Epoch 1/10, Batch 110/145, Loss: 0.4542
Epoch 1/10, Batch 120/145, Loss: 0.5616
Epoch 1/10, Batch 130/145, Loss: 0.5844
Epoch 1/10, Batch 140/145, Loss: 0.3850
Epoch 1/10, Train Loss: 0.6807, Valid Loss: 0.3852
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2985
Epoch 2/10, Batch 20/145, Loss: 0.3564
Epoch 2/10, Batch 30/145, Loss: 0.2851
Epoch 2/10, Batch 40/145, Loss: 0.3948
Epoch 2/10, Batch 50/145, Loss: 0.2665
Epoch 2/10, Batch 60/145, Loss: 0.3393
Epoch 2/10, Batch 70/145, Loss: 0.2430
Epoch 2/10, Batch 80/145, Loss: 0.2794
Epoch 2/10, Batch 90/145, Loss: 0.2023
Epoch 2/10, Batch 100/145, Loss: 0.3538
Epoch 2/10, Batch 110/145, Loss: 0.3822
Epoch 2/10, Batch 120/145, Loss: 0.2724
Epoch 2/10, Batch 130/145, Loss: 0.2488
Epoch 2/10, Batch 140/145, Loss: 0.2621
Epoch 2/10, Train Loss: 0.3500, Valid Loss: 0.3021
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2699
Epoch 3/10, Batch 20/145, Loss: 0.3019
Epoch 3/10, Batch 30/145, Loss: 0.4163
Epoch 3/10, Batch 40/145, Loss: 0.3686
Epoch 3/10, Batch 50/145, Loss: 0.2433
Epoch 3/10, Batch 60/145, Loss: 0.5600
Epoch 3/10, Batch 70/145, Loss: 0.3128
Epoch 3/10, Batch 80/145, Loss: 0.3363
Epoch 3/10, Batch 90/145, Loss: 0.3793
Epoch 3/10, Batch 100/145, Loss: 0.2657
Epoch 3/10, Batch 110/145, Loss: 0.3043
Epoch 3/10, Batch 120/145, Loss: 0.1774
Epoch 3/10, Batch 130/145, Loss: 0.4399
Epoch 3/10, Batch 140/145, Loss: 0.2482
Epoch 3/10, Train Loss: 0.2957, Valid Loss: 0.2689
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3836
Epoch 4/10, Batch 20/145, Loss: 0.2588
Epoch 4/10, Batch 30/145, Loss: 0.1582
Epoch 4/10, Batch 40/145, Loss: 0.1343
Epoch 4/10, Batch 50/145, Loss: 0.1699
Epoch 4/10, Batch 60/145, Loss: 0.2590
Epoch 4/10, Batch 70/145, Loss: 0.1913
Epoch 4/10, Batch 80/145, Loss: 0.1869
Epoch 4/10, Batch 90/145, Loss: 0.2301
Epoch 4/10, Batch 100/145, Loss: 0.3700
Epoch 4/10, Batch 110/145, Loss: 0.1946
Epoch 4/10, Batch 120/145, Loss: 0.1706
Epoch 4/10, Batch 130/145, Loss: 0.3892
Epoch 4/10, Batch 140/145, Loss: 0.1697
Epoch 4/10, Train Loss: 0.2585, Valid Loss: 0.2548
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1139
Epoch 5/10, Batch 20/145, Loss: 0.2056
Epoch 5/10, Batch 30/145, Loss: 0.2515
Epoch 5/10, Batch 40/145, Loss: 0.1734
Epoch 5/10, Batch 50/145, Loss: 0.1554
Epoch 5/10, Batch 60/145, Loss: 0.2903
Epoch 5/10, Batch 70/145, Loss: 0.1915
Epoch 5/10, Batch 80/145, Loss: 0.2820
Epoch 5/10, Batch 90/145, Loss: 0.3739
Epoch 5/10, Batch 100/145, Loss: 0.1950
Epoch 5/10, Batch 110/145, Loss: 0.2596
Epoch 5/10, Batch 120/145, Loss: 0.3064
Epoch 5/10, Batch 130/145, Loss: 0.2215
Epoch 5/10, Batch 140/145, Loss: 0.1822
Epoch 5/10, Train Loss: 0.2427, Valid Loss: 0.2398
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.0960
Epoch 6/10, Batch 20/145, Loss: 0.4022
Epoch 6/10, Batch 30/145, Loss: 0.3307
Epoch 6/10, Batch 40/145, Loss: 0.1392
Epoch 6/10, Batch 50/145, Loss: 0.3376
Epoch 6/10, Batch 60/145, Loss: 0.1414
Epoch 6/10, Batch 70/145, Loss: 0.1595
Epoch 6/10, Batch 80/145, Loss: 0.2033
Epoch 6/10, Batch 90/145, Loss: 0.2526
Epoch 6/10, Batch 100/145, Loss: 0.2362
Epoch 6/10, Batch 110/145, Loss: 0.1958
Epoch 6/10, Batch 120/145, Loss: 0.3185
Epoch 6/10, Batch 130/145, Loss: 0.1278
Epoch 6/10, Batch 140/145, Loss: 0.3259
Epoch 6/10, Train Loss: 0.2298, Valid Loss: 0.2311
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1759
Epoch 7/10, Batch 20/145, Loss: 0.4567
Epoch 7/10, Batch 30/145, Loss: 0.1853
Epoch 7/10, Batch 40/145, Loss: 0.3991
Epoch 7/10, Batch 50/145, Loss: 0.3748
Epoch 7/10, Batch 60/145, Loss: 0.1350
Epoch 7/10, Batch 70/145, Loss: 0.1059
Epoch 7/10, Batch 80/145, Loss: 0.3109
Epoch 7/10, Batch 90/145, Loss: 0.0759
Epoch 7/10, Batch 100/145, Loss: 0.2583
Epoch 7/10, Batch 110/145, Loss: 0.1720
Epoch 7/10, Batch 120/145, Loss: 0.1328
Epoch 7/10, Batch 130/145, Loss: 0.1950
Epoch 7/10, Batch 140/145, Loss: 0.3363
Epoch 7/10, Train Loss: 0.2117, Valid Loss: 0.2244
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2667
Epoch 8/10, Batch 20/145, Loss: 0.2624
Epoch 8/10, Batch 30/145, Loss: 0.2352
Epoch 8/10, Batch 40/145, Loss: 0.1989
Epoch 8/10, Batch 50/145, Loss: 0.2665
Epoch 8/10, Batch 60/145, Loss: 0.2464
Epoch 8/10, Batch 70/145, Loss: 0.2390
Epoch 8/10, Batch 80/145, Loss: 0.2015
Epoch 8/10, Batch 90/145, Loss: 0.4394
Epoch 8/10, Batch 100/145, Loss: 0.1590
Epoch 8/10, Batch 110/145, Loss: 0.2486
Epoch 8/10, Batch 120/145, Loss: 0.3263
Epoch 8/10, Batch 130/145, Loss: 0.1029
Epoch 8/10, Batch 140/145, Loss: 0.3408
Epoch 8/10, Train Loss: 0.2106, Valid Loss: 0.2255
Epoch 9/10, Batch 10/145, Loss: 0.2384
Epoch 9/10, Batch 20/145, Loss: 0.2071
Epoch 9/10, Batch 30/145, Loss: 0.1308
Epoch 9/10, Batch 40/145, Loss: 0.3064
Epoch 9/10, Batch 50/145, Loss: 0.1099
Epoch 9/10, Batch 60/145, Loss: 0.1727
Epoch 9/10, Batch 70/145, Loss: 0.1895
Epoch 9/10, Batch 80/145, Loss: 0.1289
Epoch 9/10, Batch 90/145, Loss: 0.1897
Epoch 9/10, Batch 100/145, Loss: 0.1964
Epoch 9/10, Batch 110/145, Loss: 0.2527
Epoch 9/10, Batch 120/145, Loss: 0.1209
Epoch 9/10, Batch 130/145, Loss: 0.2220
Epoch 9/10, Batch 140/145, Loss: 0.1293
Epoch 9/10, Train Loss: 0.1939, Valid Loss: 0.2178
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0972
Epoch 10/10, Batch 20/145, Loss: 0.2374
Epoch 10/10, Batch 30/145, Loss: 0.1150
Epoch 10/10, Batch 40/145, Loss: 0.1780
Epoch 10/10, Batch 50/145, Loss: 0.2749
Epoch 10/10, Batch 60/145, Loss: 0.1584
Epoch 10/10, Batch 70/145, Loss: 0.4633
Epoch 10/10, Batch 80/145, Loss: 0.3583
Epoch 10/10, Batch 90/145, Loss: 0.1296
Epoch 10/10, Batch 100/145, Loss: 0.2008
Epoch 10/10, Batch 110/145, Loss: 0.2732
Epoch 10/10, Batch 120/145, Loss: 0.2457
Epoch 10/10, Batch 130/145, Loss: 0.1721
Epoch 10/10, Batch 140/145, Loss: 0.1574
Epoch 10/10, Train Loss: 0.1884, Valid Loss: 0.2176
Model saved!
Accuracy: 0.9194
Precision: 0.9172
Recall: 0.9194
F1-score: 0.9176
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4020
Epoch 1/10, Batch 20/145, Loss: 0.9322
Epoch 1/10, Batch 30/145, Loss: 0.9247
Epoch 1/10, Batch 40/145, Loss: 0.7542
Epoch 1/10, Batch 50/145, Loss: 0.6923
Epoch 1/10, Batch 60/145, Loss: 0.6033
Epoch 1/10, Batch 70/145, Loss: 0.3578
Epoch 1/10, Batch 80/145, Loss: 0.4764
Epoch 1/10, Batch 90/145, Loss: 0.4841
Epoch 1/10, Batch 100/145, Loss: 0.5827
Epoch 1/10, Batch 110/145, Loss: 0.3712
Epoch 1/10, Batch 120/145, Loss: 0.4988
Epoch 1/10, Batch 130/145, Loss: 0.4901
Epoch 1/10, Batch 140/145, Loss: 0.4252
Epoch 1/10, Train Loss: 0.6712, Valid Loss: 0.3813
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4202
Epoch 2/10, Batch 20/145, Loss: 0.3534
Epoch 2/10, Batch 30/145, Loss: 0.2279
Epoch 2/10, Batch 40/145, Loss: 0.5128
Epoch 2/10, Batch 50/145, Loss: 0.2579
Epoch 2/10, Batch 60/145, Loss: 0.2268
Epoch 2/10, Batch 70/145, Loss: 0.4134
Epoch 2/10, Batch 80/145, Loss: 0.2753
Epoch 2/10, Batch 90/145, Loss: 0.2860
Epoch 2/10, Batch 100/145, Loss: 0.3127
Epoch 2/10, Batch 110/145, Loss: 0.4579
Epoch 2/10, Batch 120/145, Loss: 0.2874
Epoch 2/10, Batch 130/145, Loss: 0.1858
Epoch 2/10, Batch 140/145, Loss: 0.2609
Epoch 2/10, Train Loss: 0.3502, Valid Loss: 0.2951
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2225
Epoch 3/10, Batch 20/145, Loss: 0.2463
Epoch 3/10, Batch 30/145, Loss: 0.3487
Epoch 3/10, Batch 40/145, Loss: 0.1279
Epoch 3/10, Batch 50/145, Loss: 0.1778
Epoch 3/10, Batch 60/145, Loss: 0.4134
Epoch 3/10, Batch 70/145, Loss: 0.2710
Epoch 3/10, Batch 80/145, Loss: 0.3363
Epoch 3/10, Batch 90/145, Loss: 0.2385
Epoch 3/10, Batch 100/145, Loss: 0.3184
Epoch 3/10, Batch 110/145, Loss: 0.2626
Epoch 3/10, Batch 120/145, Loss: 0.3489
Epoch 3/10, Batch 130/145, Loss: 0.3270
Epoch 3/10, Batch 140/145, Loss: 0.1788
Epoch 3/10, Train Loss: 0.2875, Valid Loss: 0.2591
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3507
Epoch 4/10, Batch 20/145, Loss: 0.2344
Epoch 4/10, Batch 30/145, Loss: 0.2379
Epoch 4/10, Batch 40/145, Loss: 0.3332
Epoch 4/10, Batch 50/145, Loss: 0.1594
Epoch 4/10, Batch 60/145, Loss: 0.2431
Epoch 4/10, Batch 70/145, Loss: 0.1964
Epoch 4/10, Batch 80/145, Loss: 0.2293
Epoch 4/10, Batch 90/145, Loss: 0.1496
Epoch 4/10, Batch 100/145, Loss: 0.2895
Epoch 4/10, Batch 110/145, Loss: 0.1920
Epoch 4/10, Batch 120/145, Loss: 0.2385
Epoch 4/10, Batch 130/145, Loss: 0.1273
Epoch 4/10, Batch 140/145, Loss: 0.1610
Epoch 4/10, Train Loss: 0.2571, Valid Loss: 0.2455
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2183
Epoch 5/10, Batch 20/145, Loss: 0.1958
Epoch 5/10, Batch 30/145, Loss: 0.1893
Epoch 5/10, Batch 40/145, Loss: 0.1268
Epoch 5/10, Batch 50/145, Loss: 0.3049
Epoch 5/10, Batch 60/145, Loss: 0.4116
Epoch 5/10, Batch 70/145, Loss: 0.2314
Epoch 5/10, Batch 80/145, Loss: 0.1599
Epoch 5/10, Batch 90/145, Loss: 0.3040
Epoch 5/10, Batch 100/145, Loss: 0.1264
Epoch 5/10, Batch 110/145, Loss: 0.2995
Epoch 5/10, Batch 120/145, Loss: 0.2035
Epoch 5/10, Batch 130/145, Loss: 0.1923
Epoch 5/10, Batch 140/145, Loss: 0.2479
Epoch 5/10, Train Loss: 0.2408, Valid Loss: 0.2387
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1584
Epoch 6/10, Batch 20/145, Loss: 0.2282
Epoch 6/10, Batch 30/145, Loss: 0.3017
Epoch 6/10, Batch 40/145, Loss: 0.1628
Epoch 6/10, Batch 50/145, Loss: 0.3529
Epoch 6/10, Batch 60/145, Loss: 0.1451
Epoch 6/10, Batch 70/145, Loss: 0.1705
Epoch 6/10, Batch 80/145, Loss: 0.1768
Epoch 6/10, Batch 90/145, Loss: 0.2339
Epoch 6/10, Batch 100/145, Loss: 0.2541
Epoch 6/10, Batch 110/145, Loss: 0.2415
Epoch 6/10, Batch 120/145, Loss: 0.4192
Epoch 6/10, Batch 130/145, Loss: 0.1779
Epoch 6/10, Batch 140/145, Loss: 0.1937
Epoch 6/10, Train Loss: 0.2315, Valid Loss: 0.2292
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1630
Epoch 7/10, Batch 20/145, Loss: 0.2626
Epoch 7/10, Batch 30/145, Loss: 0.3038
Epoch 7/10, Batch 40/145, Loss: 0.2960
Epoch 7/10, Batch 50/145, Loss: 0.1052
Epoch 7/10, Batch 60/145, Loss: 0.2632
Epoch 7/10, Batch 70/145, Loss: 0.2065
Epoch 7/10, Batch 80/145, Loss: 0.2711
Epoch 7/10, Batch 90/145, Loss: 0.1441
Epoch 7/10, Batch 100/145, Loss: 0.2520
Epoch 7/10, Batch 110/145, Loss: 0.2187
Epoch 7/10, Batch 120/145, Loss: 0.2381
Epoch 7/10, Batch 130/145, Loss: 0.0940
Epoch 7/10, Batch 140/145, Loss: 0.3900
Epoch 7/10, Train Loss: 0.2106, Valid Loss: 0.2228
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2646
Epoch 8/10, Batch 20/145, Loss: 0.2379
Epoch 8/10, Batch 30/145, Loss: 0.1906
Epoch 8/10, Batch 40/145, Loss: 0.2482
Epoch 8/10, Batch 50/145, Loss: 0.2686
Epoch 8/10, Batch 60/145, Loss: 0.3704
Epoch 8/10, Batch 70/145, Loss: 0.2287
Epoch 8/10, Batch 80/145, Loss: 0.1448
Epoch 8/10, Batch 90/145, Loss: 0.2755
Epoch 8/10, Batch 100/145, Loss: 0.1702
Epoch 8/10, Batch 110/145, Loss: 0.1576
Epoch 8/10, Batch 120/145, Loss: 0.1084
Epoch 8/10, Batch 130/145, Loss: 0.1578
Epoch 8/10, Batch 140/145, Loss: 0.2227
Epoch 8/10, Train Loss: 0.2033, Valid Loss: 0.2266
Epoch 9/10, Batch 10/145, Loss: 0.2460
Epoch 9/10, Batch 20/145, Loss: 0.2137
Epoch 9/10, Batch 30/145, Loss: 0.1316
Epoch 9/10, Batch 40/145, Loss: 0.3094
Epoch 9/10, Batch 50/145, Loss: 0.1297
Epoch 9/10, Batch 60/145, Loss: 0.2600
Epoch 9/10, Batch 70/145, Loss: 0.1340
Epoch 9/10, Batch 80/145, Loss: 0.1182
Epoch 9/10, Batch 90/145, Loss: 0.1762
Epoch 9/10, Batch 100/145, Loss: 0.1625
Epoch 9/10, Batch 110/145, Loss: 0.1229
Epoch 9/10, Batch 120/145, Loss: 0.1033
Epoch 9/10, Batch 130/145, Loss: 0.1673
Epoch 9/10, Batch 140/145, Loss: 0.0950
Epoch 9/10, Train Loss: 0.2042, Valid Loss: 0.2168
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0766
Epoch 10/10, Batch 20/145, Loss: 0.1855
Epoch 10/10, Batch 30/145, Loss: 0.1562
Epoch 10/10, Batch 40/145, Loss: 0.1802
Epoch 10/10, Batch 50/145, Loss: 0.2964
Epoch 10/10, Batch 60/145, Loss: 0.1455
Epoch 10/10, Batch 70/145, Loss: 0.2946
Epoch 10/10, Batch 80/145, Loss: 0.2085
Epoch 10/10, Batch 90/145, Loss: 0.1321
Epoch 10/10, Batch 100/145, Loss: 0.2212
Epoch 10/10, Batch 110/145, Loss: 0.2195
Epoch 10/10, Batch 120/145, Loss: 0.2519
Epoch 10/10, Batch 130/145, Loss: 0.2236
Epoch 10/10, Batch 140/145, Loss: 0.2496
Epoch 10/10, Train Loss: 0.1966, Valid Loss: 0.2167
Model saved!
Accuracy: 0.9194
Precision: 0.9164
Recall: 0.9194
F1-score: 0.9169
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4371
Epoch 1/10, Batch 20/145, Loss: 0.9846
Epoch 1/10, Batch 30/145, Loss: 0.9006
Epoch 1/10, Batch 40/145, Loss: 0.7258
Epoch 1/10, Batch 50/145, Loss: 0.7754
Epoch 1/10, Batch 60/145, Loss: 0.6580
Epoch 1/10, Batch 70/145, Loss: 0.4855
Epoch 1/10, Batch 80/145, Loss: 0.4804
Epoch 1/10, Batch 90/145, Loss: 0.3705
Epoch 1/10, Batch 100/145, Loss: 0.3845
Epoch 1/10, Batch 110/145, Loss: 0.4935
Epoch 1/10, Batch 120/145, Loss: 0.5785
Epoch 1/10, Batch 130/145, Loss: 0.5293
Epoch 1/10, Batch 140/145, Loss: 0.5738
Epoch 1/10, Train Loss: 0.6758, Valid Loss: 0.3870
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3217
Epoch 2/10, Batch 20/145, Loss: 0.2670
Epoch 2/10, Batch 30/145, Loss: 0.2508
Epoch 2/10, Batch 40/145, Loss: 0.4645
Epoch 2/10, Batch 50/145, Loss: 0.3282
Epoch 2/10, Batch 60/145, Loss: 0.4108
Epoch 2/10, Batch 70/145, Loss: 0.3658
Epoch 2/10, Batch 80/145, Loss: 0.4044
Epoch 2/10, Batch 90/145, Loss: 0.3747
Epoch 2/10, Batch 100/145, Loss: 0.2366
Epoch 2/10, Batch 110/145, Loss: 0.3133
Epoch 2/10, Batch 120/145, Loss: 0.4052
Epoch 2/10, Batch 130/145, Loss: 0.4370
Epoch 2/10, Batch 140/145, Loss: 0.2721
Epoch 2/10, Train Loss: 0.3520, Valid Loss: 0.2979
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2501
Epoch 3/10, Batch 20/145, Loss: 0.4251
Epoch 3/10, Batch 30/145, Loss: 0.3785
Epoch 3/10, Batch 40/145, Loss: 0.1694
Epoch 3/10, Batch 50/145, Loss: 0.3014
Epoch 3/10, Batch 60/145, Loss: 0.2782
Epoch 3/10, Batch 70/145, Loss: 0.4551
Epoch 3/10, Batch 80/145, Loss: 0.3215
Epoch 3/10, Batch 90/145, Loss: 0.1766
Epoch 3/10, Batch 100/145, Loss: 0.3995
Epoch 3/10, Batch 110/145, Loss: 0.2267
Epoch 3/10, Batch 120/145, Loss: 0.4146
Epoch 3/10, Batch 130/145, Loss: 0.3812
Epoch 3/10, Batch 140/145, Loss: 0.2146
Epoch 3/10, Train Loss: 0.2920, Valid Loss: 0.2729
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3315
Epoch 4/10, Batch 20/145, Loss: 0.1975
Epoch 4/10, Batch 30/145, Loss: 0.2817
Epoch 4/10, Batch 40/145, Loss: 0.1902
Epoch 4/10, Batch 50/145, Loss: 0.1593
Epoch 4/10, Batch 60/145, Loss: 0.1649
Epoch 4/10, Batch 70/145, Loss: 0.2160
Epoch 4/10, Batch 80/145, Loss: 0.1140
Epoch 4/10, Batch 90/145, Loss: 0.1900
Epoch 4/10, Batch 100/145, Loss: 0.2890
Epoch 4/10, Batch 110/145, Loss: 0.1444
Epoch 4/10, Batch 120/145, Loss: 0.3627
Epoch 4/10, Batch 130/145, Loss: 0.1581
Epoch 4/10, Batch 140/145, Loss: 0.1742
Epoch 4/10, Train Loss: 0.2581, Valid Loss: 0.2567
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2050
Epoch 5/10, Batch 20/145, Loss: 0.1840
Epoch 5/10, Batch 30/145, Loss: 0.2289
Epoch 5/10, Batch 40/145, Loss: 0.1818
Epoch 5/10, Batch 50/145, Loss: 0.1494
Epoch 5/10, Batch 60/145, Loss: 0.3020
Epoch 5/10, Batch 70/145, Loss: 0.2792
Epoch 5/10, Batch 80/145, Loss: 0.3609
Epoch 5/10, Batch 90/145, Loss: 0.4514
Epoch 5/10, Batch 100/145, Loss: 0.3113
Epoch 5/10, Batch 110/145, Loss: 0.2843
Epoch 5/10, Batch 120/145, Loss: 0.1955
Epoch 5/10, Batch 130/145, Loss: 0.2268
Epoch 5/10, Batch 140/145, Loss: 0.3133
Epoch 5/10, Train Loss: 0.2422, Valid Loss: 0.2498
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1550
Epoch 6/10, Batch 20/145, Loss: 0.3429
Epoch 6/10, Batch 30/145, Loss: 0.3295
Epoch 6/10, Batch 40/145, Loss: 0.3629
Epoch 6/10, Batch 50/145, Loss: 0.3455
Epoch 6/10, Batch 60/145, Loss: 0.2927
Epoch 6/10, Batch 70/145, Loss: 0.1335
Epoch 6/10, Batch 80/145, Loss: 0.1359
Epoch 6/10, Batch 90/145, Loss: 0.3204
Epoch 6/10, Batch 100/145, Loss: 0.4933
Epoch 6/10, Batch 110/145, Loss: 0.2065
Epoch 6/10, Batch 120/145, Loss: 0.4126
Epoch 6/10, Batch 130/145, Loss: 0.3058
Epoch 6/10, Batch 140/145, Loss: 0.3696
Epoch 6/10, Train Loss: 0.2311, Valid Loss: 0.2458
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2960
Epoch 7/10, Batch 20/145, Loss: 0.3312
Epoch 7/10, Batch 30/145, Loss: 0.2809
Epoch 7/10, Batch 40/145, Loss: 0.3399
Epoch 7/10, Batch 50/145, Loss: 0.2138
Epoch 7/10, Batch 60/145, Loss: 0.1311
Epoch 7/10, Batch 70/145, Loss: 0.1154
Epoch 7/10, Batch 80/145, Loss: 0.3872
Epoch 7/10, Batch 90/145, Loss: 0.1405
Epoch 7/10, Batch 100/145, Loss: 0.2815
Epoch 7/10, Batch 110/145, Loss: 0.0755
Epoch 7/10, Batch 120/145, Loss: 0.1761
Epoch 7/10, Batch 130/145, Loss: 0.1560
Epoch 7/10, Batch 140/145, Loss: 0.1944
Epoch 7/10, Train Loss: 0.2146, Valid Loss: 0.2358
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1524
Epoch 8/10, Batch 20/145, Loss: 0.1462
Epoch 8/10, Batch 30/145, Loss: 0.2278
Epoch 8/10, Batch 40/145, Loss: 0.0998
Epoch 8/10, Batch 50/145, Loss: 0.1341
Epoch 8/10, Batch 60/145, Loss: 0.1828
Epoch 8/10, Batch 70/145, Loss: 0.1442
Epoch 8/10, Batch 80/145, Loss: 0.1726
Epoch 8/10, Batch 90/145, Loss: 0.1984
Epoch 8/10, Batch 100/145, Loss: 0.2298
Epoch 8/10, Batch 110/145, Loss: 0.1035
Epoch 8/10, Batch 120/145, Loss: 0.2589
Epoch 8/10, Batch 130/145, Loss: 0.2631
Epoch 8/10, Batch 140/145, Loss: 0.2904
Epoch 8/10, Train Loss: 0.2080, Valid Loss: 0.2336
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3309
Epoch 9/10, Batch 20/145, Loss: 0.2573
Epoch 9/10, Batch 30/145, Loss: 0.1243
Epoch 9/10, Batch 40/145, Loss: 0.2898
Epoch 9/10, Batch 50/145, Loss: 0.0594
Epoch 9/10, Batch 60/145, Loss: 0.3145
Epoch 9/10, Batch 70/145, Loss: 0.1509
Epoch 9/10, Batch 80/145, Loss: 0.1911
Epoch 9/10, Batch 90/145, Loss: 0.2537
Epoch 9/10, Batch 100/145, Loss: 0.1437
Epoch 9/10, Batch 110/145, Loss: 0.3275
Epoch 9/10, Batch 120/145, Loss: 0.0482
Epoch 9/10, Batch 130/145, Loss: 0.1999
Epoch 9/10, Batch 140/145, Loss: 0.0973
Epoch 9/10, Train Loss: 0.1998, Valid Loss: 0.2279
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1212
Epoch 10/10, Batch 20/145, Loss: 0.1652
Epoch 10/10, Batch 30/145, Loss: 0.1915
Epoch 10/10, Batch 40/145, Loss: 0.0695
Epoch 10/10, Batch 50/145, Loss: 0.2383
Epoch 10/10, Batch 60/145, Loss: 0.2230
Epoch 10/10, Batch 70/145, Loss: 0.2255
Epoch 10/10, Batch 80/145, Loss: 0.2664
Epoch 10/10, Batch 90/145, Loss: 0.0999
Epoch 10/10, Batch 100/145, Loss: 0.2307
Epoch 10/10, Batch 110/145, Loss: 0.1445
Epoch 10/10, Batch 120/145, Loss: 0.2947
Epoch 10/10, Batch 130/145, Loss: 0.0876
Epoch 10/10, Batch 140/145, Loss: 0.1160
Epoch 10/10, Train Loss: 0.1897, Valid Loss: 0.2294
Accuracy: 0.9194
Precision: 0.9175
Recall: 0.9194
F1-score: 0.9178
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3891
Epoch 1/10, Batch 20/145, Loss: 0.8741
Epoch 1/10, Batch 30/145, Loss: 0.9002
Epoch 1/10, Batch 40/145, Loss: 0.7980
Epoch 1/10, Batch 50/145, Loss: 0.8543
Epoch 1/10, Batch 60/145, Loss: 0.5993
Epoch 1/10, Batch 70/145, Loss: 0.5149
Epoch 1/10, Batch 80/145, Loss: 0.4780
Epoch 1/10, Batch 90/145, Loss: 0.4792
Epoch 1/10, Batch 100/145, Loss: 0.4576
Epoch 1/10, Batch 110/145, Loss: 0.4161
Epoch 1/10, Batch 120/145, Loss: 0.4987
Epoch 1/10, Batch 130/145, Loss: 0.5348
Epoch 1/10, Batch 140/145, Loss: 0.3657
Epoch 1/10, Train Loss: 0.6777, Valid Loss: 0.3745
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4455
Epoch 2/10, Batch 20/145, Loss: 0.3180
Epoch 2/10, Batch 30/145, Loss: 0.4257
Epoch 2/10, Batch 40/145, Loss: 0.6193
Epoch 2/10, Batch 50/145, Loss: 0.3395
Epoch 2/10, Batch 60/145, Loss: 0.4140
Epoch 2/10, Batch 70/145, Loss: 0.2566
Epoch 2/10, Batch 80/145, Loss: 0.2378
Epoch 2/10, Batch 90/145, Loss: 0.2813
Epoch 2/10, Batch 100/145, Loss: 0.2995
Epoch 2/10, Batch 110/145, Loss: 0.4228
Epoch 2/10, Batch 120/145, Loss: 0.2500
Epoch 2/10, Batch 130/145, Loss: 0.2199
Epoch 2/10, Batch 140/145, Loss: 0.2827
Epoch 2/10, Train Loss: 0.3517, Valid Loss: 0.2963
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2602
Epoch 3/10, Batch 20/145, Loss: 0.2095
Epoch 3/10, Batch 30/145, Loss: 0.3867
Epoch 3/10, Batch 40/145, Loss: 0.3194
Epoch 3/10, Batch 50/145, Loss: 0.1960
Epoch 3/10, Batch 60/145, Loss: 0.5489
Epoch 3/10, Batch 70/145, Loss: 0.2925
Epoch 3/10, Batch 80/145, Loss: 0.2393
Epoch 3/10, Batch 90/145, Loss: 0.2501
Epoch 3/10, Batch 100/145, Loss: 0.3354
Epoch 3/10, Batch 110/145, Loss: 0.1633
Epoch 3/10, Batch 120/145, Loss: 0.4295
Epoch 3/10, Batch 130/145, Loss: 0.2712
Epoch 3/10, Batch 140/145, Loss: 0.2677
Epoch 3/10, Train Loss: 0.2889, Valid Loss: 0.2541
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3798
Epoch 4/10, Batch 20/145, Loss: 0.2862
Epoch 4/10, Batch 30/145, Loss: 0.2592
Epoch 4/10, Batch 40/145, Loss: 0.2401
Epoch 4/10, Batch 50/145, Loss: 0.1384
Epoch 4/10, Batch 60/145, Loss: 0.3504
Epoch 4/10, Batch 70/145, Loss: 0.1197
Epoch 4/10, Batch 80/145, Loss: 0.2587
Epoch 4/10, Batch 90/145, Loss: 0.2098
Epoch 4/10, Batch 100/145, Loss: 0.2732
Epoch 4/10, Batch 110/145, Loss: 0.1601
Epoch 4/10, Batch 120/145, Loss: 0.2527
Epoch 4/10, Batch 130/145, Loss: 0.1637
Epoch 4/10, Batch 140/145, Loss: 0.1340
Epoch 4/10, Train Loss: 0.2528, Valid Loss: 0.2507
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1718
Epoch 5/10, Batch 20/145, Loss: 0.2733
Epoch 5/10, Batch 30/145, Loss: 0.2030
Epoch 5/10, Batch 40/145, Loss: 0.2063
Epoch 5/10, Batch 50/145, Loss: 0.1028
Epoch 5/10, Batch 60/145, Loss: 0.2279
Epoch 5/10, Batch 70/145, Loss: 0.1688
Epoch 5/10, Batch 80/145, Loss: 0.2298
Epoch 5/10, Batch 90/145, Loss: 0.3291
Epoch 5/10, Batch 100/145, Loss: 0.3019
Epoch 5/10, Batch 110/145, Loss: 0.1630
Epoch 5/10, Batch 120/145, Loss: 0.2977
Epoch 5/10, Batch 130/145, Loss: 0.1187
Epoch 5/10, Batch 140/145, Loss: 0.1718
Epoch 5/10, Train Loss: 0.2336, Valid Loss: 0.2438
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1532
Epoch 6/10, Batch 20/145, Loss: 0.3210
Epoch 6/10, Batch 30/145, Loss: 0.2853
Epoch 6/10, Batch 40/145, Loss: 0.1733
Epoch 6/10, Batch 50/145, Loss: 0.2682
Epoch 6/10, Batch 60/145, Loss: 0.1386
Epoch 6/10, Batch 70/145, Loss: 0.2743
Epoch 6/10, Batch 80/145, Loss: 0.1791
Epoch 6/10, Batch 90/145, Loss: 0.3197
Epoch 6/10, Batch 100/145, Loss: 0.3635
Epoch 6/10, Batch 110/145, Loss: 0.1866
Epoch 6/10, Batch 120/145, Loss: 0.2812
Epoch 6/10, Batch 130/145, Loss: 0.2881
Epoch 6/10, Batch 140/145, Loss: 0.1540
Epoch 6/10, Train Loss: 0.2201, Valid Loss: 0.2369
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.4588
Epoch 7/10, Batch 20/145, Loss: 0.2236
Epoch 7/10, Batch 30/145, Loss: 0.1701
Epoch 7/10, Batch 40/145, Loss: 0.3849
Epoch 7/10, Batch 50/145, Loss: 0.1155
Epoch 7/10, Batch 60/145, Loss: 0.1692
Epoch 7/10, Batch 70/145, Loss: 0.2059
Epoch 7/10, Batch 80/145, Loss: 0.3115
Epoch 7/10, Batch 90/145, Loss: 0.1988
Epoch 7/10, Batch 100/145, Loss: 0.1581
Epoch 7/10, Batch 110/145, Loss: 0.0997
Epoch 7/10, Batch 120/145, Loss: 0.1716
Epoch 7/10, Batch 130/145, Loss: 0.0808
Epoch 7/10, Batch 140/145, Loss: 0.3350
Epoch 7/10, Train Loss: 0.2040, Valid Loss: 0.2360
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2629
Epoch 8/10, Batch 20/145, Loss: 0.2122
Epoch 8/10, Batch 30/145, Loss: 0.2217
Epoch 8/10, Batch 40/145, Loss: 0.1561
Epoch 8/10, Batch 50/145, Loss: 0.2403
Epoch 8/10, Batch 60/145, Loss: 0.1653
Epoch 8/10, Batch 70/145, Loss: 0.2304
Epoch 8/10, Batch 80/145, Loss: 0.1374
Epoch 8/10, Batch 90/145, Loss: 0.2126
Epoch 8/10, Batch 100/145, Loss: 0.2397
Epoch 8/10, Batch 110/145, Loss: 0.2975
Epoch 8/10, Batch 120/145, Loss: 0.1901
Epoch 8/10, Batch 130/145, Loss: 0.1348
Epoch 8/10, Batch 140/145, Loss: 0.3376
Epoch 8/10, Train Loss: 0.2037, Valid Loss: 0.2291
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.4221
Epoch 9/10, Batch 20/145, Loss: 0.3849
Epoch 9/10, Batch 30/145, Loss: 0.1442
Epoch 9/10, Batch 40/145, Loss: 0.1359
Epoch 9/10, Batch 50/145, Loss: 0.1344
Epoch 9/10, Batch 60/145, Loss: 0.2771
Epoch 9/10, Batch 70/145, Loss: 0.1947
Epoch 9/10, Batch 80/145, Loss: 0.0800
Epoch 9/10, Batch 90/145, Loss: 0.2405
Epoch 9/10, Batch 100/145, Loss: 0.1884
Epoch 9/10, Batch 110/145, Loss: 0.3132
Epoch 9/10, Batch 120/145, Loss: 0.1620
Epoch 9/10, Batch 130/145, Loss: 0.1831
Epoch 9/10, Batch 140/145, Loss: 0.4023
Epoch 9/10, Train Loss: 0.1984, Valid Loss: 0.2277
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1526
Epoch 10/10, Batch 20/145, Loss: 0.1175
Epoch 10/10, Batch 30/145, Loss: 0.1167
Epoch 10/10, Batch 40/145, Loss: 0.1015
Epoch 10/10, Batch 50/145, Loss: 0.1961
Epoch 10/10, Batch 60/145, Loss: 0.3174
Epoch 10/10, Batch 70/145, Loss: 0.3127
Epoch 10/10, Batch 80/145, Loss: 0.1902
Epoch 10/10, Batch 90/145, Loss: 0.0854
Epoch 10/10, Batch 100/145, Loss: 0.1831
Epoch 10/10, Batch 110/145, Loss: 0.1969
Epoch 10/10, Batch 120/145, Loss: 0.1787
Epoch 10/10, Batch 130/145, Loss: 0.2256
Epoch 10/10, Batch 140/145, Loss: 0.1572
Epoch 10/10, Train Loss: 0.1866, Valid Loss: 0.2241
Model saved!
Accuracy: 0.9217
Precision: 0.9199
Recall: 0.9217
F1-score: 0.9197
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3643
Epoch 1/10, Batch 20/145, Loss: 0.8848
Epoch 1/10, Batch 30/145, Loss: 0.9619
Epoch 1/10, Batch 40/145, Loss: 0.6988
Epoch 1/10, Batch 50/145, Loss: 0.7630
Epoch 1/10, Batch 60/145, Loss: 0.5393
Epoch 1/10, Batch 70/145, Loss: 0.4921
Epoch 1/10, Batch 80/145, Loss: 0.5534
Epoch 1/10, Batch 90/145, Loss: 0.4239
Epoch 1/10, Batch 100/145, Loss: 0.4038
Epoch 1/10, Batch 110/145, Loss: 0.3053
Epoch 1/10, Batch 120/145, Loss: 0.5917
Epoch 1/10, Batch 130/145, Loss: 0.5564
Epoch 1/10, Batch 140/145, Loss: 0.3120
Epoch 1/10, Train Loss: 0.6753, Valid Loss: 0.3776
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3270
Epoch 2/10, Batch 20/145, Loss: 0.5420
Epoch 2/10, Batch 30/145, Loss: 0.3216
Epoch 2/10, Batch 40/145, Loss: 0.3803
Epoch 2/10, Batch 50/145, Loss: 0.3725
Epoch 2/10, Batch 60/145, Loss: 0.4762
Epoch 2/10, Batch 70/145, Loss: 0.3672
Epoch 2/10, Batch 80/145, Loss: 0.3582
Epoch 2/10, Batch 90/145, Loss: 0.3576
Epoch 2/10, Batch 100/145, Loss: 0.2013
Epoch 2/10, Batch 110/145, Loss: 0.4106
Epoch 2/10, Batch 120/145, Loss: 0.3264
Epoch 2/10, Batch 130/145, Loss: 0.3194
Epoch 2/10, Batch 140/145, Loss: 0.3732
Epoch 2/10, Train Loss: 0.3538, Valid Loss: 0.2960
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2313
Epoch 3/10, Batch 20/145, Loss: 0.2030
Epoch 3/10, Batch 30/145, Loss: 0.3763
Epoch 3/10, Batch 40/145, Loss: 0.2044
Epoch 3/10, Batch 50/145, Loss: 0.4053
Epoch 3/10, Batch 60/145, Loss: 0.4048
Epoch 3/10, Batch 70/145, Loss: 0.3861
Epoch 3/10, Batch 80/145, Loss: 0.2181
Epoch 3/10, Batch 90/145, Loss: 0.3187
Epoch 3/10, Batch 100/145, Loss: 0.3346
Epoch 3/10, Batch 110/145, Loss: 0.1980
Epoch 3/10, Batch 120/145, Loss: 0.3961
Epoch 3/10, Batch 130/145, Loss: 0.2842
Epoch 3/10, Batch 140/145, Loss: 0.1999
Epoch 3/10, Train Loss: 0.2972, Valid Loss: 0.2599
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2562
Epoch 4/10, Batch 20/145, Loss: 0.3724
Epoch 4/10, Batch 30/145, Loss: 0.2714
Epoch 4/10, Batch 40/145, Loss: 0.1608
Epoch 4/10, Batch 50/145, Loss: 0.1619
Epoch 4/10, Batch 60/145, Loss: 0.2512
Epoch 4/10, Batch 70/145, Loss: 0.1828
Epoch 4/10, Batch 80/145, Loss: 0.1107
Epoch 4/10, Batch 90/145, Loss: 0.1827
Epoch 4/10, Batch 100/145, Loss: 0.3678
Epoch 4/10, Batch 110/145, Loss: 0.1094
Epoch 4/10, Batch 120/145, Loss: 0.2351
Epoch 4/10, Batch 130/145, Loss: 0.1527
Epoch 4/10, Batch 140/145, Loss: 0.1874
Epoch 4/10, Train Loss: 0.2591, Valid Loss: 0.2480
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2967
Epoch 5/10, Batch 20/145, Loss: 0.1535
Epoch 5/10, Batch 30/145, Loss: 0.2024
Epoch 5/10, Batch 40/145, Loss: 0.1619
Epoch 5/10, Batch 50/145, Loss: 0.1500
Epoch 5/10, Batch 60/145, Loss: 0.2140
Epoch 5/10, Batch 70/145, Loss: 0.2723
Epoch 5/10, Batch 80/145, Loss: 0.2526
Epoch 5/10, Batch 90/145, Loss: 0.3970
Epoch 5/10, Batch 100/145, Loss: 0.1802
Epoch 5/10, Batch 110/145, Loss: 0.2077
Epoch 5/10, Batch 120/145, Loss: 0.2482
Epoch 5/10, Batch 130/145, Loss: 0.2040
Epoch 5/10, Batch 140/145, Loss: 0.2238
Epoch 5/10, Train Loss: 0.2479, Valid Loss: 0.2441
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2137
Epoch 6/10, Batch 20/145, Loss: 0.2412
Epoch 6/10, Batch 30/145, Loss: 0.4555
Epoch 6/10, Batch 40/145, Loss: 0.1915
Epoch 6/10, Batch 50/145, Loss: 0.3990
Epoch 6/10, Batch 60/145, Loss: 0.2746
Epoch 6/10, Batch 70/145, Loss: 0.1038
Epoch 6/10, Batch 80/145, Loss: 0.1326
Epoch 6/10, Batch 90/145, Loss: 0.1755
Epoch 6/10, Batch 100/145, Loss: 0.3806
Epoch 6/10, Batch 110/145, Loss: 0.2845
Epoch 6/10, Batch 120/145, Loss: 0.2734
Epoch 6/10, Batch 130/145, Loss: 0.1263
Epoch 6/10, Batch 140/145, Loss: 0.1304
Epoch 6/10, Train Loss: 0.2291, Valid Loss: 0.2320
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3333
Epoch 7/10, Batch 20/145, Loss: 0.4920
Epoch 7/10, Batch 30/145, Loss: 0.1953
Epoch 7/10, Batch 40/145, Loss: 0.3547
Epoch 7/10, Batch 50/145, Loss: 0.3584
Epoch 7/10, Batch 60/145, Loss: 0.1234
Epoch 7/10, Batch 70/145, Loss: 0.1315
Epoch 7/10, Batch 80/145, Loss: 0.4044
Epoch 7/10, Batch 90/145, Loss: 0.3177
Epoch 7/10, Batch 100/145, Loss: 0.2657
Epoch 7/10, Batch 110/145, Loss: 0.1963
Epoch 7/10, Batch 120/145, Loss: 0.2146
Epoch 7/10, Batch 130/145, Loss: 0.0881
Epoch 7/10, Batch 140/145, Loss: 0.3238
Epoch 7/10, Train Loss: 0.2236, Valid Loss: 0.2244
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1349
Epoch 8/10, Batch 20/145, Loss: 0.1560
Epoch 8/10, Batch 30/145, Loss: 0.1709
Epoch 8/10, Batch 40/145, Loss: 0.1282
Epoch 8/10, Batch 50/145, Loss: 0.3209
Epoch 8/10, Batch 60/145, Loss: 0.2102
Epoch 8/10, Batch 70/145, Loss: 0.1090
Epoch 8/10, Batch 80/145, Loss: 0.2868
Epoch 8/10, Batch 90/145, Loss: 0.3192
Epoch 8/10, Batch 100/145, Loss: 0.1699
Epoch 8/10, Batch 110/145, Loss: 0.2173
Epoch 8/10, Batch 120/145, Loss: 0.2015
Epoch 8/10, Batch 130/145, Loss: 0.1977
Epoch 8/10, Batch 140/145, Loss: 0.4990
Epoch 8/10, Train Loss: 0.2150, Valid Loss: 0.2204
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2171
Epoch 9/10, Batch 20/145, Loss: 0.1917
Epoch 9/10, Batch 30/145, Loss: 0.2145
Epoch 9/10, Batch 40/145, Loss: 0.3532
Epoch 9/10, Batch 50/145, Loss: 0.3177
Epoch 9/10, Batch 60/145, Loss: 0.2719
Epoch 9/10, Batch 70/145, Loss: 0.2126
Epoch 9/10, Batch 80/145, Loss: 0.1638
Epoch 9/10, Batch 90/145, Loss: 0.1205
Epoch 9/10, Batch 100/145, Loss: 0.1650
Epoch 9/10, Batch 110/145, Loss: 0.2468
Epoch 9/10, Batch 120/145, Loss: 0.0383
Epoch 9/10, Batch 130/145, Loss: 0.2942
Epoch 9/10, Batch 140/145, Loss: 0.1264
Epoch 9/10, Train Loss: 0.2025, Valid Loss: 0.2143
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1591
Epoch 10/10, Batch 20/145, Loss: 0.2616
Epoch 10/10, Batch 30/145, Loss: 0.0853
Epoch 10/10, Batch 40/145, Loss: 0.1349
Epoch 10/10, Batch 50/145, Loss: 0.2196
Epoch 10/10, Batch 60/145, Loss: 0.1720
Epoch 10/10, Batch 70/145, Loss: 0.1756
Epoch 10/10, Batch 80/145, Loss: 0.1756
Epoch 10/10, Batch 90/145, Loss: 0.2008
Epoch 10/10, Batch 100/145, Loss: 0.1392
Epoch 10/10, Batch 110/145, Loss: 0.1075
Epoch 10/10, Batch 120/145, Loss: 0.2131
Epoch 10/10, Batch 130/145, Loss: 0.1328
Epoch 10/10, Batch 140/145, Loss: 0.1106
Epoch 10/10, Train Loss: 0.1960, Valid Loss: 0.2114
Model saved!
Accuracy: 0.9206
Precision: 0.9179
Recall: 0.9206
F1-score: 0.9184
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3961
Epoch 1/10, Batch 20/145, Loss: 0.9001
Epoch 1/10, Batch 30/145, Loss: 0.8356
Epoch 1/10, Batch 40/145, Loss: 0.7706
Epoch 1/10, Batch 50/145, Loss: 0.7041
Epoch 1/10, Batch 60/145, Loss: 0.5827
Epoch 1/10, Batch 70/145, Loss: 0.4907
Epoch 1/10, Batch 80/145, Loss: 0.6529
Epoch 1/10, Batch 90/145, Loss: 0.4155
Epoch 1/10, Batch 100/145, Loss: 0.4645
Epoch 1/10, Batch 110/145, Loss: 0.3975
Epoch 1/10, Batch 120/145, Loss: 0.5924
Epoch 1/10, Batch 130/145, Loss: 0.6921
Epoch 1/10, Batch 140/145, Loss: 0.3468
Epoch 1/10, Train Loss: 0.6763, Valid Loss: 0.3715
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3447
Epoch 2/10, Batch 20/145, Loss: 0.2757
Epoch 2/10, Batch 30/145, Loss: 0.4321
Epoch 2/10, Batch 40/145, Loss: 0.4812
Epoch 2/10, Batch 50/145, Loss: 0.4001
Epoch 2/10, Batch 60/145, Loss: 0.3403
Epoch 2/10, Batch 70/145, Loss: 0.3545
Epoch 2/10, Batch 80/145, Loss: 0.4125
Epoch 2/10, Batch 90/145, Loss: 0.4137
Epoch 2/10, Batch 100/145, Loss: 0.2473
Epoch 2/10, Batch 110/145, Loss: 0.3643
Epoch 2/10, Batch 120/145, Loss: 0.4466
Epoch 2/10, Batch 130/145, Loss: 0.3776
Epoch 2/10, Batch 140/145, Loss: 0.2955
Epoch 2/10, Train Loss: 0.3545, Valid Loss: 0.2986
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2927
Epoch 3/10, Batch 20/145, Loss: 0.2182
Epoch 3/10, Batch 30/145, Loss: 0.2704
Epoch 3/10, Batch 40/145, Loss: 0.2593
Epoch 3/10, Batch 50/145, Loss: 0.2017
Epoch 3/10, Batch 60/145, Loss: 0.4008
Epoch 3/10, Batch 70/145, Loss: 0.3511
Epoch 3/10, Batch 80/145, Loss: 0.2356
Epoch 3/10, Batch 90/145, Loss: 0.2787
Epoch 3/10, Batch 100/145, Loss: 0.2439
Epoch 3/10, Batch 110/145, Loss: 0.2578
Epoch 3/10, Batch 120/145, Loss: 0.3123
Epoch 3/10, Batch 130/145, Loss: 0.4141
Epoch 3/10, Batch 140/145, Loss: 0.3087
Epoch 3/10, Train Loss: 0.2914, Valid Loss: 0.2728
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3855
Epoch 4/10, Batch 20/145, Loss: 0.2249
Epoch 4/10, Batch 30/145, Loss: 0.3893
Epoch 4/10, Batch 40/145, Loss: 0.1303
Epoch 4/10, Batch 50/145, Loss: 0.1176
Epoch 4/10, Batch 60/145, Loss: 0.3032
Epoch 4/10, Batch 70/145, Loss: 0.2669
Epoch 4/10, Batch 80/145, Loss: 0.1961
Epoch 4/10, Batch 90/145, Loss: 0.1571
Epoch 4/10, Batch 100/145, Loss: 0.3370
Epoch 4/10, Batch 110/145, Loss: 0.1104
Epoch 4/10, Batch 120/145, Loss: 0.3674
Epoch 4/10, Batch 130/145, Loss: 0.1450
Epoch 4/10, Batch 140/145, Loss: 0.1626
Epoch 4/10, Train Loss: 0.2621, Valid Loss: 0.2510
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1392
Epoch 5/10, Batch 20/145, Loss: 0.3044
Epoch 5/10, Batch 30/145, Loss: 0.1771
Epoch 5/10, Batch 40/145, Loss: 0.1516
Epoch 5/10, Batch 50/145, Loss: 0.2744
Epoch 5/10, Batch 60/145, Loss: 0.1836
Epoch 5/10, Batch 70/145, Loss: 0.1943
Epoch 5/10, Batch 80/145, Loss: 0.1248
Epoch 5/10, Batch 90/145, Loss: 0.3172
Epoch 5/10, Batch 100/145, Loss: 0.3419
Epoch 5/10, Batch 110/145, Loss: 0.2865
Epoch 5/10, Batch 120/145, Loss: 0.3291
Epoch 5/10, Batch 130/145, Loss: 0.1343
Epoch 5/10, Batch 140/145, Loss: 0.2248
Epoch 5/10, Train Loss: 0.2457, Valid Loss: 0.2508
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.0899
Epoch 6/10, Batch 20/145, Loss: 0.3258
Epoch 6/10, Batch 30/145, Loss: 0.3519
Epoch 6/10, Batch 40/145, Loss: 0.1754
Epoch 6/10, Batch 50/145, Loss: 0.2153
Epoch 6/10, Batch 60/145, Loss: 0.2595
Epoch 6/10, Batch 70/145, Loss: 0.0970
Epoch 6/10, Batch 80/145, Loss: 0.1499
Epoch 6/10, Batch 90/145, Loss: 0.3425
Epoch 6/10, Batch 100/145, Loss: 0.2892
Epoch 6/10, Batch 110/145, Loss: 0.2260
Epoch 6/10, Batch 120/145, Loss: 0.2164
Epoch 6/10, Batch 130/145, Loss: 0.1371
Epoch 6/10, Batch 140/145, Loss: 0.1429
Epoch 6/10, Train Loss: 0.2326, Valid Loss: 0.2314
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2758
Epoch 7/10, Batch 20/145, Loss: 0.1482
Epoch 7/10, Batch 30/145, Loss: 0.1397
Epoch 7/10, Batch 40/145, Loss: 0.3686
Epoch 7/10, Batch 50/145, Loss: 0.3692
Epoch 7/10, Batch 60/145, Loss: 0.1792
Epoch 7/10, Batch 70/145, Loss: 0.1731
Epoch 7/10, Batch 80/145, Loss: 0.3521
Epoch 7/10, Batch 90/145, Loss: 0.1915
Epoch 7/10, Batch 100/145, Loss: 0.1070
Epoch 7/10, Batch 110/145, Loss: 0.3088
Epoch 7/10, Batch 120/145, Loss: 0.2869
Epoch 7/10, Batch 130/145, Loss: 0.0957
Epoch 7/10, Batch 140/145, Loss: 0.1993
Epoch 7/10, Train Loss: 0.2156, Valid Loss: 0.2316
Epoch 8/10, Batch 10/145, Loss: 0.2146
Epoch 8/10, Batch 20/145, Loss: 0.1126
Epoch 8/10, Batch 30/145, Loss: 0.3126
Epoch 8/10, Batch 40/145, Loss: 0.1781
Epoch 8/10, Batch 50/145, Loss: 0.2200
Epoch 8/10, Batch 60/145, Loss: 0.1914
Epoch 8/10, Batch 70/145, Loss: 0.3642
Epoch 8/10, Batch 80/145, Loss: 0.2421
Epoch 8/10, Batch 90/145, Loss: 0.2298
Epoch 8/10, Batch 100/145, Loss: 0.1707
Epoch 8/10, Batch 110/145, Loss: 0.1500
Epoch 8/10, Batch 120/145, Loss: 0.1499
Epoch 8/10, Batch 130/145, Loss: 0.2808
Epoch 8/10, Batch 140/145, Loss: 0.1981
Epoch 8/10, Train Loss: 0.2065, Valid Loss: 0.2273
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.4037
Epoch 9/10, Batch 20/145, Loss: 0.1675
Epoch 9/10, Batch 30/145, Loss: 0.0955
Epoch 9/10, Batch 40/145, Loss: 0.2342
Epoch 9/10, Batch 50/145, Loss: 0.1352
Epoch 9/10, Batch 60/145, Loss: 0.3821
Epoch 9/10, Batch 70/145, Loss: 0.1377
Epoch 9/10, Batch 80/145, Loss: 0.1937
Epoch 9/10, Batch 90/145, Loss: 0.3094
Epoch 9/10, Batch 100/145, Loss: 0.1432
Epoch 9/10, Batch 110/145, Loss: 0.3138
Epoch 9/10, Batch 120/145, Loss: 0.1011
Epoch 9/10, Batch 130/145, Loss: 0.0917
Epoch 9/10, Batch 140/145, Loss: 0.2065
Epoch 9/10, Train Loss: 0.1971, Valid Loss: 0.2274
Epoch 10/10, Batch 10/145, Loss: 0.1215
Epoch 10/10, Batch 20/145, Loss: 0.1435
Epoch 10/10, Batch 30/145, Loss: 0.1488
Epoch 10/10, Batch 40/145, Loss: 0.1567
Epoch 10/10, Batch 50/145, Loss: 0.2160
Epoch 10/10, Batch 60/145, Loss: 0.1228
Epoch 10/10, Batch 70/145, Loss: 0.3969
Epoch 10/10, Batch 80/145, Loss: 0.2369
Epoch 10/10, Batch 90/145, Loss: 0.1848
Epoch 10/10, Batch 100/145, Loss: 0.1405
Epoch 10/10, Batch 110/145, Loss: 0.1127
Epoch 10/10, Batch 120/145, Loss: 0.1654
Epoch 10/10, Batch 130/145, Loss: 0.0943
Epoch 10/10, Batch 140/145, Loss: 0.1961
Epoch 10/10, Train Loss: 0.1924, Valid Loss: 0.2246
Model saved!
Accuracy: 0.9124
Precision: 0.9091
Recall: 0.9124
F1-score: 0.9097
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3243
Epoch 1/10, Batch 20/145, Loss: 0.9819
Epoch 1/10, Batch 30/145, Loss: 0.8674
Epoch 1/10, Batch 40/145, Loss: 0.8502
Epoch 1/10, Batch 50/145, Loss: 0.7773
Epoch 1/10, Batch 60/145, Loss: 0.6368
Epoch 1/10, Batch 70/145, Loss: 0.3508
Epoch 1/10, Batch 80/145, Loss: 0.5703
Epoch 1/10, Batch 90/145, Loss: 0.5202
Epoch 1/10, Batch 100/145, Loss: 0.5530
Epoch 1/10, Batch 110/145, Loss: 0.5699
Epoch 1/10, Batch 120/145, Loss: 0.5243
Epoch 1/10, Batch 130/145, Loss: 0.5372
Epoch 1/10, Batch 140/145, Loss: 0.3774
Epoch 1/10, Train Loss: 0.6721, Valid Loss: 0.3865
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2690
Epoch 2/10, Batch 20/145, Loss: 0.2507
Epoch 2/10, Batch 30/145, Loss: 0.2678
Epoch 2/10, Batch 40/145, Loss: 0.4829
Epoch 2/10, Batch 50/145, Loss: 0.3256
Epoch 2/10, Batch 60/145, Loss: 0.4107
Epoch 2/10, Batch 70/145, Loss: 0.3459
Epoch 2/10, Batch 80/145, Loss: 0.4287
Epoch 2/10, Batch 90/145, Loss: 0.3559
Epoch 2/10, Batch 100/145, Loss: 0.2864
Epoch 2/10, Batch 110/145, Loss: 0.3344
Epoch 2/10, Batch 120/145, Loss: 0.3448
Epoch 2/10, Batch 130/145, Loss: 0.3270
Epoch 2/10, Batch 140/145, Loss: 0.3256
Epoch 2/10, Train Loss: 0.3507, Valid Loss: 0.3022
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3804
Epoch 3/10, Batch 20/145, Loss: 0.2880
Epoch 3/10, Batch 30/145, Loss: 0.3427
Epoch 3/10, Batch 40/145, Loss: 0.2721
Epoch 3/10, Batch 50/145, Loss: 0.2150
Epoch 3/10, Batch 60/145, Loss: 0.3308
Epoch 3/10, Batch 70/145, Loss: 0.2600
Epoch 3/10, Batch 80/145, Loss: 0.3349
Epoch 3/10, Batch 90/145, Loss: 0.2109
Epoch 3/10, Batch 100/145, Loss: 0.2673
Epoch 3/10, Batch 110/145, Loss: 0.1487
Epoch 3/10, Batch 120/145, Loss: 0.2613
Epoch 3/10, Batch 130/145, Loss: 0.4697
Epoch 3/10, Batch 140/145, Loss: 0.3448
Epoch 3/10, Train Loss: 0.2862, Valid Loss: 0.2693
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4663
Epoch 4/10, Batch 20/145, Loss: 0.1752
Epoch 4/10, Batch 30/145, Loss: 0.2390
Epoch 4/10, Batch 40/145, Loss: 0.0849
Epoch 4/10, Batch 50/145, Loss: 0.2636
Epoch 4/10, Batch 60/145, Loss: 0.2893
Epoch 4/10, Batch 70/145, Loss: 0.2276
Epoch 4/10, Batch 80/145, Loss: 0.1126
Epoch 4/10, Batch 90/145, Loss: 0.1131
Epoch 4/10, Batch 100/145, Loss: 0.3093
Epoch 4/10, Batch 110/145, Loss: 0.1794
Epoch 4/10, Batch 120/145, Loss: 0.1580
Epoch 4/10, Batch 130/145, Loss: 0.1619
Epoch 4/10, Batch 140/145, Loss: 0.1451
Epoch 4/10, Train Loss: 0.2494, Valid Loss: 0.2535
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2133
Epoch 5/10, Batch 20/145, Loss: 0.1964
Epoch 5/10, Batch 30/145, Loss: 0.4267
Epoch 5/10, Batch 40/145, Loss: 0.1412
Epoch 5/10, Batch 50/145, Loss: 0.2174
Epoch 5/10, Batch 60/145, Loss: 0.2802
Epoch 5/10, Batch 70/145, Loss: 0.2123
Epoch 5/10, Batch 80/145, Loss: 0.3503
Epoch 5/10, Batch 90/145, Loss: 0.2126
Epoch 5/10, Batch 100/145, Loss: 0.2642
Epoch 5/10, Batch 110/145, Loss: 0.2379
Epoch 5/10, Batch 120/145, Loss: 0.2094
Epoch 5/10, Batch 130/145, Loss: 0.2090
Epoch 5/10, Batch 140/145, Loss: 0.2828
Epoch 5/10, Train Loss: 0.2377, Valid Loss: 0.2477
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1603
Epoch 6/10, Batch 20/145, Loss: 0.4185
Epoch 6/10, Batch 30/145, Loss: 0.2558
Epoch 6/10, Batch 40/145, Loss: 0.1990
Epoch 6/10, Batch 50/145, Loss: 0.2293
Epoch 6/10, Batch 60/145, Loss: 0.1130
Epoch 6/10, Batch 70/145, Loss: 0.1200
Epoch 6/10, Batch 80/145, Loss: 0.0923
Epoch 6/10, Batch 90/145, Loss: 0.2242
Epoch 6/10, Batch 100/145, Loss: 0.2568
Epoch 6/10, Batch 110/145, Loss: 0.2931
Epoch 6/10, Batch 120/145, Loss: 0.3158
Epoch 6/10, Batch 130/145, Loss: 0.2608
Epoch 6/10, Batch 140/145, Loss: 0.2049
Epoch 6/10, Train Loss: 0.2244, Valid Loss: 0.2291
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2357
Epoch 7/10, Batch 20/145, Loss: 0.2762
Epoch 7/10, Batch 30/145, Loss: 0.1475
Epoch 7/10, Batch 40/145, Loss: 0.4664
Epoch 7/10, Batch 50/145, Loss: 0.0750
Epoch 7/10, Batch 60/145, Loss: 0.1485
Epoch 7/10, Batch 70/145, Loss: 0.2224
Epoch 7/10, Batch 80/145, Loss: 0.2213
Epoch 7/10, Batch 90/145, Loss: 0.2475
Epoch 7/10, Batch 100/145, Loss: 0.1645
Epoch 7/10, Batch 110/145, Loss: 0.1489
Epoch 7/10, Batch 120/145, Loss: 0.3239
Epoch 7/10, Batch 130/145, Loss: 0.1748
Epoch 7/10, Batch 140/145, Loss: 0.2879
Epoch 7/10, Train Loss: 0.2092, Valid Loss: 0.2265
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1939
Epoch 8/10, Batch 20/145, Loss: 0.3092
Epoch 8/10, Batch 30/145, Loss: 0.1789
Epoch 8/10, Batch 40/145, Loss: 0.1931
Epoch 8/10, Batch 50/145, Loss: 0.3170
Epoch 8/10, Batch 60/145, Loss: 0.1974
Epoch 8/10, Batch 70/145, Loss: 0.2850
Epoch 8/10, Batch 80/145, Loss: 0.1779
Epoch 8/10, Batch 90/145, Loss: 0.5051
Epoch 8/10, Batch 100/145, Loss: 0.1769
Epoch 8/10, Batch 110/145, Loss: 0.2027
Epoch 8/10, Batch 120/145, Loss: 0.1490
Epoch 8/10, Batch 130/145, Loss: 0.2109
Epoch 8/10, Batch 140/145, Loss: 0.0908
Epoch 8/10, Train Loss: 0.2075, Valid Loss: 0.2248
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1854
Epoch 9/10, Batch 20/145, Loss: 0.3074
Epoch 9/10, Batch 30/145, Loss: 0.0981
Epoch 9/10, Batch 40/145, Loss: 0.1428
Epoch 9/10, Batch 50/145, Loss: 0.0959
Epoch 9/10, Batch 60/145, Loss: 0.2302
Epoch 9/10, Batch 70/145, Loss: 0.1783
Epoch 9/10, Batch 80/145, Loss: 0.1032
Epoch 9/10, Batch 90/145, Loss: 0.2194
Epoch 9/10, Batch 100/145, Loss: 0.1693
Epoch 9/10, Batch 110/145, Loss: 0.2889
Epoch 9/10, Batch 120/145, Loss: 0.1442
Epoch 9/10, Batch 130/145, Loss: 0.3645
Epoch 9/10, Batch 140/145, Loss: 0.1222
Epoch 9/10, Train Loss: 0.1957, Valid Loss: 0.2172
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1189
Epoch 10/10, Batch 20/145, Loss: 0.0829
Epoch 10/10, Batch 30/145, Loss: 0.2238
Epoch 10/10, Batch 40/145, Loss: 0.0788
Epoch 10/10, Batch 50/145, Loss: 0.1258
Epoch 10/10, Batch 60/145, Loss: 0.1055
Epoch 10/10, Batch 70/145, Loss: 0.3486
Epoch 10/10, Batch 80/145, Loss: 0.0774
Epoch 10/10, Batch 90/145, Loss: 0.1707
Epoch 10/10, Batch 100/145, Loss: 0.1656
Epoch 10/10, Batch 110/145, Loss: 0.1080
Epoch 10/10, Batch 120/145, Loss: 0.3132
Epoch 10/10, Batch 130/145, Loss: 0.2518
Epoch 10/10, Batch 140/145, Loss: 0.2628
Epoch 10/10, Train Loss: 0.1858, Valid Loss: 0.2155
Model saved!
Accuracy: 0.9217
Precision: 0.9194
Recall: 0.9217
F1-score: 0.9198
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4789
Epoch 1/10, Batch 20/145, Loss: 0.9954
Epoch 1/10, Batch 30/145, Loss: 0.8553
Epoch 1/10, Batch 40/145, Loss: 0.7995
Epoch 1/10, Batch 50/145, Loss: 0.7973
Epoch 1/10, Batch 60/145, Loss: 0.6451
Epoch 1/10, Batch 70/145, Loss: 0.4610
Epoch 1/10, Batch 80/145, Loss: 0.4752
Epoch 1/10, Batch 90/145, Loss: 0.4443
Epoch 1/10, Batch 100/145, Loss: 0.5298
Epoch 1/10, Batch 110/145, Loss: 0.4513
Epoch 1/10, Batch 120/145, Loss: 0.6185
Epoch 1/10, Batch 130/145, Loss: 0.4728
Epoch 1/10, Batch 140/145, Loss: 0.3106
Epoch 1/10, Train Loss: 0.6853, Valid Loss: 0.3887
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2783
Epoch 2/10, Batch 20/145, Loss: 0.3444
Epoch 2/10, Batch 30/145, Loss: 0.2696
Epoch 2/10, Batch 40/145, Loss: 0.5689
Epoch 2/10, Batch 50/145, Loss: 0.3345
Epoch 2/10, Batch 60/145, Loss: 0.4363
Epoch 2/10, Batch 70/145, Loss: 0.4457
Epoch 2/10, Batch 80/145, Loss: 0.2098
Epoch 2/10, Batch 90/145, Loss: 0.3001
Epoch 2/10, Batch 100/145, Loss: 0.1682
Epoch 2/10, Batch 110/145, Loss: 0.3417
Epoch 2/10, Batch 120/145, Loss: 0.3830
Epoch 2/10, Batch 130/145, Loss: 0.3180
Epoch 2/10, Batch 140/145, Loss: 0.2639
Epoch 2/10, Train Loss: 0.3612, Valid Loss: 0.3022
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2111
Epoch 3/10, Batch 20/145, Loss: 0.2623
Epoch 3/10, Batch 30/145, Loss: 0.3050
Epoch 3/10, Batch 40/145, Loss: 0.4181
Epoch 3/10, Batch 50/145, Loss: 0.1893
Epoch 3/10, Batch 60/145, Loss: 0.3863
Epoch 3/10, Batch 70/145, Loss: 0.4237
Epoch 3/10, Batch 80/145, Loss: 0.3687
Epoch 3/10, Batch 90/145, Loss: 0.4195
Epoch 3/10, Batch 100/145, Loss: 0.2832
Epoch 3/10, Batch 110/145, Loss: 0.1546
Epoch 3/10, Batch 120/145, Loss: 0.3169
Epoch 3/10, Batch 130/145, Loss: 0.3810
Epoch 3/10, Batch 140/145, Loss: 0.3812
Epoch 3/10, Train Loss: 0.2960, Valid Loss: 0.2652
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3350
Epoch 4/10, Batch 20/145, Loss: 0.1690
Epoch 4/10, Batch 30/145, Loss: 0.4579
Epoch 4/10, Batch 40/145, Loss: 0.3364
Epoch 4/10, Batch 50/145, Loss: 0.1510
Epoch 4/10, Batch 60/145, Loss: 0.2302
Epoch 4/10, Batch 70/145, Loss: 0.2594
Epoch 4/10, Batch 80/145, Loss: 0.2353
Epoch 4/10, Batch 90/145, Loss: 0.3168
Epoch 4/10, Batch 100/145, Loss: 0.3064
Epoch 4/10, Batch 110/145, Loss: 0.1672
Epoch 4/10, Batch 120/145, Loss: 0.2839
Epoch 4/10, Batch 130/145, Loss: 0.1722
Epoch 4/10, Batch 140/145, Loss: 0.1335
Epoch 4/10, Train Loss: 0.2590, Valid Loss: 0.2624
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2647
Epoch 5/10, Batch 20/145, Loss: 0.1274
Epoch 5/10, Batch 30/145, Loss: 0.2725
Epoch 5/10, Batch 40/145, Loss: 0.1080
Epoch 5/10, Batch 50/145, Loss: 0.1830
Epoch 5/10, Batch 60/145, Loss: 0.2316
Epoch 5/10, Batch 70/145, Loss: 0.3109
Epoch 5/10, Batch 80/145, Loss: 0.3389
Epoch 5/10, Batch 90/145, Loss: 0.2378
Epoch 5/10, Batch 100/145, Loss: 0.1468
Epoch 5/10, Batch 110/145, Loss: 0.2128
Epoch 5/10, Batch 120/145, Loss: 0.2433
Epoch 5/10, Batch 130/145, Loss: 0.1396
Epoch 5/10, Batch 140/145, Loss: 0.1334
Epoch 5/10, Train Loss: 0.2516, Valid Loss: 0.2450
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2276
Epoch 6/10, Batch 20/145, Loss: 0.4409
Epoch 6/10, Batch 30/145, Loss: 0.3184
Epoch 6/10, Batch 40/145, Loss: 0.0857
Epoch 6/10, Batch 50/145, Loss: 0.3482
Epoch 6/10, Batch 60/145, Loss: 0.2822
Epoch 6/10, Batch 70/145, Loss: 0.1930
Epoch 6/10, Batch 80/145, Loss: 0.1433
Epoch 6/10, Batch 90/145, Loss: 0.1859
Epoch 6/10, Batch 100/145, Loss: 0.2496
Epoch 6/10, Batch 110/145, Loss: 0.2809
Epoch 6/10, Batch 120/145, Loss: 0.2937
Epoch 6/10, Batch 130/145, Loss: 0.2252
Epoch 6/10, Batch 140/145, Loss: 0.1626
Epoch 6/10, Train Loss: 0.2326, Valid Loss: 0.2367
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3064
Epoch 7/10, Batch 20/145, Loss: 0.2917
Epoch 7/10, Batch 30/145, Loss: 0.1683
Epoch 7/10, Batch 40/145, Loss: 0.3435
Epoch 7/10, Batch 50/145, Loss: 0.1813
Epoch 7/10, Batch 60/145, Loss: 0.1051
Epoch 7/10, Batch 70/145, Loss: 0.1868
Epoch 7/10, Batch 80/145, Loss: 0.4525
Epoch 7/10, Batch 90/145, Loss: 0.1040
Epoch 7/10, Batch 100/145, Loss: 0.1477
Epoch 7/10, Batch 110/145, Loss: 0.2619
Epoch 7/10, Batch 120/145, Loss: 0.3524
Epoch 7/10, Batch 130/145, Loss: 0.1485
Epoch 7/10, Batch 140/145, Loss: 0.2441
Epoch 7/10, Train Loss: 0.2180, Valid Loss: 0.2294
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1781
Epoch 8/10, Batch 20/145, Loss: 0.1958
Epoch 8/10, Batch 30/145, Loss: 0.2098
Epoch 8/10, Batch 40/145, Loss: 0.2094
Epoch 8/10, Batch 50/145, Loss: 0.1796
Epoch 8/10, Batch 60/145, Loss: 0.1414
Epoch 8/10, Batch 70/145, Loss: 0.2403
Epoch 8/10, Batch 80/145, Loss: 0.1574
Epoch 8/10, Batch 90/145, Loss: 0.5065
Epoch 8/10, Batch 100/145, Loss: 0.2072
Epoch 8/10, Batch 110/145, Loss: 0.3161
Epoch 8/10, Batch 120/145, Loss: 0.4907
Epoch 8/10, Batch 130/145, Loss: 0.1292
Epoch 8/10, Batch 140/145, Loss: 0.2800
Epoch 8/10, Train Loss: 0.2136, Valid Loss: 0.2252
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1630
Epoch 9/10, Batch 20/145, Loss: 0.1679
Epoch 9/10, Batch 30/145, Loss: 0.2253
Epoch 9/10, Batch 40/145, Loss: 0.1951
Epoch 9/10, Batch 50/145, Loss: 0.2050
Epoch 9/10, Batch 60/145, Loss: 0.1698
Epoch 9/10, Batch 70/145, Loss: 0.1279
Epoch 9/10, Batch 80/145, Loss: 0.0672
Epoch 9/10, Batch 90/145, Loss: 0.3209
Epoch 9/10, Batch 100/145, Loss: 0.1903
Epoch 9/10, Batch 110/145, Loss: 0.2994
Epoch 9/10, Batch 120/145, Loss: 0.2229
Epoch 9/10, Batch 130/145, Loss: 0.2563
Epoch 9/10, Batch 140/145, Loss: 0.1471
Epoch 9/10, Train Loss: 0.2018, Valid Loss: 0.2255
Epoch 10/10, Batch 10/145, Loss: 0.0941
Epoch 10/10, Batch 20/145, Loss: 0.1443
Epoch 10/10, Batch 30/145, Loss: 0.1629
Epoch 10/10, Batch 40/145, Loss: 0.1508
Epoch 10/10, Batch 50/145, Loss: 0.2624
Epoch 10/10, Batch 60/145, Loss: 0.2797
Epoch 10/10, Batch 70/145, Loss: 0.1028
Epoch 10/10, Batch 80/145, Loss: 0.2491
Epoch 10/10, Batch 90/145, Loss: 0.2103
Epoch 10/10, Batch 100/145, Loss: 0.2808
Epoch 10/10, Batch 110/145, Loss: 0.2676
Epoch 10/10, Batch 120/145, Loss: 0.1539
Epoch 10/10, Batch 130/145, Loss: 0.1295
Epoch 10/10, Batch 140/145, Loss: 0.1939
Epoch 10/10, Train Loss: 0.1978, Valid Loss: 0.2211
Model saved!
Accuracy: 0.9182
Precision: 0.9159
Recall: 0.9182
F1-score: 0.9156
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4432
Epoch 1/10, Batch 20/145, Loss: 0.8923
Epoch 1/10, Batch 30/145, Loss: 0.9271
Epoch 1/10, Batch 40/145, Loss: 0.7973
Epoch 1/10, Batch 50/145, Loss: 0.7211
Epoch 1/10, Batch 60/145, Loss: 0.6147
Epoch 1/10, Batch 70/145, Loss: 0.5125
Epoch 1/10, Batch 80/145, Loss: 0.6317
Epoch 1/10, Batch 90/145, Loss: 0.3480
Epoch 1/10, Batch 100/145, Loss: 0.6724
Epoch 1/10, Batch 110/145, Loss: 0.4978
Epoch 1/10, Batch 120/145, Loss: 0.4919
Epoch 1/10, Batch 130/145, Loss: 0.6233
Epoch 1/10, Batch 140/145, Loss: 0.3179
Epoch 1/10, Train Loss: 0.6804, Valid Loss: 0.3785
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3316
Epoch 2/10, Batch 20/145, Loss: 0.4029
Epoch 2/10, Batch 30/145, Loss: 0.3972
Epoch 2/10, Batch 40/145, Loss: 0.5281
Epoch 2/10, Batch 50/145, Loss: 0.4457
Epoch 2/10, Batch 60/145, Loss: 0.5224
Epoch 2/10, Batch 70/145, Loss: 0.3564
Epoch 2/10, Batch 80/145, Loss: 0.4901
Epoch 2/10, Batch 90/145, Loss: 0.4095
Epoch 2/10, Batch 100/145, Loss: 0.4135
Epoch 2/10, Batch 110/145, Loss: 0.3557
Epoch 2/10, Batch 120/145, Loss: 0.3848
Epoch 2/10, Batch 130/145, Loss: 0.2445
Epoch 2/10, Batch 140/145, Loss: 0.2790
Epoch 2/10, Train Loss: 0.3588, Valid Loss: 0.2933
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3266
Epoch 3/10, Batch 20/145, Loss: 0.2798
Epoch 3/10, Batch 30/145, Loss: 0.3641
Epoch 3/10, Batch 40/145, Loss: 0.1441
Epoch 3/10, Batch 50/145, Loss: 0.2287
Epoch 3/10, Batch 60/145, Loss: 0.4100
Epoch 3/10, Batch 70/145, Loss: 0.4920
Epoch 3/10, Batch 80/145, Loss: 0.3221
Epoch 3/10, Batch 90/145, Loss: 0.2425
Epoch 3/10, Batch 100/145, Loss: 0.2458
Epoch 3/10, Batch 110/145, Loss: 0.2352
Epoch 3/10, Batch 120/145, Loss: 0.3794
Epoch 3/10, Batch 130/145, Loss: 0.2841
Epoch 3/10, Batch 140/145, Loss: 0.3015
Epoch 3/10, Train Loss: 0.2945, Valid Loss: 0.2613
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3393
Epoch 4/10, Batch 20/145, Loss: 0.2900
Epoch 4/10, Batch 30/145, Loss: 0.4185
Epoch 4/10, Batch 40/145, Loss: 0.2271
Epoch 4/10, Batch 50/145, Loss: 0.2202
Epoch 4/10, Batch 60/145, Loss: 0.2513
Epoch 4/10, Batch 70/145, Loss: 0.1962
Epoch 4/10, Batch 80/145, Loss: 0.2172
Epoch 4/10, Batch 90/145, Loss: 0.1216
Epoch 4/10, Batch 100/145, Loss: 0.4264
Epoch 4/10, Batch 110/145, Loss: 0.1163
Epoch 4/10, Batch 120/145, Loss: 0.2668
Epoch 4/10, Batch 130/145, Loss: 0.2045
Epoch 4/10, Batch 140/145, Loss: 0.1780
Epoch 4/10, Train Loss: 0.2619, Valid Loss: 0.2483
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2764
Epoch 5/10, Batch 20/145, Loss: 0.2642
Epoch 5/10, Batch 30/145, Loss: 0.1773
Epoch 5/10, Batch 40/145, Loss: 0.1116
Epoch 5/10, Batch 50/145, Loss: 0.1629
Epoch 5/10, Batch 60/145, Loss: 0.2081
Epoch 5/10, Batch 70/145, Loss: 0.2224
Epoch 5/10, Batch 80/145, Loss: 0.2477
Epoch 5/10, Batch 90/145, Loss: 0.2347
Epoch 5/10, Batch 100/145, Loss: 0.3409
Epoch 5/10, Batch 110/145, Loss: 0.2978
Epoch 5/10, Batch 120/145, Loss: 0.4621
Epoch 5/10, Batch 130/145, Loss: 0.1206
Epoch 5/10, Batch 140/145, Loss: 0.2690
Epoch 5/10, Train Loss: 0.2509, Valid Loss: 0.2287
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3683
Epoch 6/10, Batch 20/145, Loss: 0.2505
Epoch 6/10, Batch 30/145, Loss: 0.3831
Epoch 6/10, Batch 40/145, Loss: 0.2043
Epoch 6/10, Batch 50/145, Loss: 0.2415
Epoch 6/10, Batch 60/145, Loss: 0.2136
Epoch 6/10, Batch 70/145, Loss: 0.1293
Epoch 6/10, Batch 80/145, Loss: 0.1840
Epoch 6/10, Batch 90/145, Loss: 0.1831
Epoch 6/10, Batch 100/145, Loss: 0.2164
Epoch 6/10, Batch 110/145, Loss: 0.2284
Epoch 6/10, Batch 120/145, Loss: 0.1886
Epoch 6/10, Batch 130/145, Loss: 0.1222
Epoch 6/10, Batch 140/145, Loss: 0.1091
Epoch 6/10, Train Loss: 0.2298, Valid Loss: 0.2197
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3354
Epoch 7/10, Batch 20/145, Loss: 0.3094
Epoch 7/10, Batch 30/145, Loss: 0.2066
Epoch 7/10, Batch 40/145, Loss: 0.2803
Epoch 7/10, Batch 50/145, Loss: 0.1096
Epoch 7/10, Batch 60/145, Loss: 0.2124
Epoch 7/10, Batch 70/145, Loss: 0.1977
Epoch 7/10, Batch 80/145, Loss: 0.4664
Epoch 7/10, Batch 90/145, Loss: 0.1853
Epoch 7/10, Batch 100/145, Loss: 0.1963
Epoch 7/10, Batch 110/145, Loss: 0.2493
Epoch 7/10, Batch 120/145, Loss: 0.1914
Epoch 7/10, Batch 130/145, Loss: 0.1528
Epoch 7/10, Batch 140/145, Loss: 0.2493
Epoch 7/10, Train Loss: 0.2179, Valid Loss: 0.2121
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2881
Epoch 8/10, Batch 20/145, Loss: 0.3512
Epoch 8/10, Batch 30/145, Loss: 0.2971
Epoch 8/10, Batch 40/145, Loss: 0.2231
Epoch 8/10, Batch 50/145, Loss: 0.2758
Epoch 8/10, Batch 60/145, Loss: 0.2760
Epoch 8/10, Batch 70/145, Loss: 0.1899
Epoch 8/10, Batch 80/145, Loss: 0.2988
Epoch 8/10, Batch 90/145, Loss: 0.1987
Epoch 8/10, Batch 100/145, Loss: 0.2268
Epoch 8/10, Batch 110/145, Loss: 0.3525
Epoch 8/10, Batch 120/145, Loss: 0.1817
Epoch 8/10, Batch 130/145, Loss: 0.1960
Epoch 8/10, Batch 140/145, Loss: 0.3329
Epoch 8/10, Train Loss: 0.2160, Valid Loss: 0.2086
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2475
Epoch 9/10, Batch 20/145, Loss: 0.0964
Epoch 9/10, Batch 30/145, Loss: 0.0648
Epoch 9/10, Batch 40/145, Loss: 0.2732
Epoch 9/10, Batch 50/145, Loss: 0.1011
Epoch 9/10, Batch 60/145, Loss: 0.2755
Epoch 9/10, Batch 70/145, Loss: 0.2027
Epoch 9/10, Batch 80/145, Loss: 0.1176
Epoch 9/10, Batch 90/145, Loss: 0.2240
Epoch 9/10, Batch 100/145, Loss: 0.1541
Epoch 9/10, Batch 110/145, Loss: 0.1911
Epoch 9/10, Batch 120/145, Loss: 0.1554
Epoch 9/10, Batch 130/145, Loss: 0.1220
Epoch 9/10, Batch 140/145, Loss: 0.1931
Epoch 9/10, Train Loss: 0.1943, Valid Loss: 0.2071
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1724
Epoch 10/10, Batch 20/145, Loss: 0.1373
Epoch 10/10, Batch 30/145, Loss: 0.1036
Epoch 10/10, Batch 40/145, Loss: 0.1636
Epoch 10/10, Batch 50/145, Loss: 0.1856
Epoch 10/10, Batch 60/145, Loss: 0.1587
Epoch 10/10, Batch 70/145, Loss: 0.1226
Epoch 10/10, Batch 80/145, Loss: 0.2797
Epoch 10/10, Batch 90/145, Loss: 0.1643
Epoch 10/10, Batch 100/145, Loss: 0.1480
Epoch 10/10, Batch 110/145, Loss: 0.2854
Epoch 10/10, Batch 120/145, Loss: 0.1108
Epoch 10/10, Batch 130/145, Loss: 0.0967
Epoch 10/10, Batch 140/145, Loss: 0.2063
Epoch 10/10, Train Loss: 0.1953, Valid Loss: 0.2028
Model saved!
Accuracy: 0.9206
Precision: 0.9178
Recall: 0.9206
F1-score: 0.9184
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3807
Epoch 1/10, Batch 20/145, Loss: 0.8954
Epoch 1/10, Batch 30/145, Loss: 0.8851
Epoch 1/10, Batch 40/145, Loss: 0.7917
Epoch 1/10, Batch 50/145, Loss: 0.7622
Epoch 1/10, Batch 60/145, Loss: 0.6440
Epoch 1/10, Batch 70/145, Loss: 0.4746
Epoch 1/10, Batch 80/145, Loss: 0.5556
Epoch 1/10, Batch 90/145, Loss: 0.4990
Epoch 1/10, Batch 100/145, Loss: 0.4809
Epoch 1/10, Batch 110/145, Loss: 0.4507
Epoch 1/10, Batch 120/145, Loss: 0.5267
Epoch 1/10, Batch 130/145, Loss: 0.4783
Epoch 1/10, Batch 140/145, Loss: 0.4520
Epoch 1/10, Train Loss: 0.6751, Valid Loss: 0.3742
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2415
Epoch 2/10, Batch 20/145, Loss: 0.2524
Epoch 2/10, Batch 30/145, Loss: 0.3609
Epoch 2/10, Batch 40/145, Loss: 0.3846
Epoch 2/10, Batch 50/145, Loss: 0.3399
Epoch 2/10, Batch 60/145, Loss: 0.5315
Epoch 2/10, Batch 70/145, Loss: 0.2709
Epoch 2/10, Batch 80/145, Loss: 0.3308
Epoch 2/10, Batch 90/145, Loss: 0.3855
Epoch 2/10, Batch 100/145, Loss: 0.4672
Epoch 2/10, Batch 110/145, Loss: 0.3709
Epoch 2/10, Batch 120/145, Loss: 0.6035
Epoch 2/10, Batch 130/145, Loss: 0.3723
Epoch 2/10, Batch 140/145, Loss: 0.2403
Epoch 2/10, Train Loss: 0.3538, Valid Loss: 0.2887
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2686
Epoch 3/10, Batch 20/145, Loss: 0.2713
Epoch 3/10, Batch 30/145, Loss: 0.2951
Epoch 3/10, Batch 40/145, Loss: 0.2270
Epoch 3/10, Batch 50/145, Loss: 0.2764
Epoch 3/10, Batch 60/145, Loss: 0.3595
Epoch 3/10, Batch 70/145, Loss: 0.3762
Epoch 3/10, Batch 80/145, Loss: 0.2315
Epoch 3/10, Batch 90/145, Loss: 0.1719
Epoch 3/10, Batch 100/145, Loss: 0.2817
Epoch 3/10, Batch 110/145, Loss: 0.1877
Epoch 3/10, Batch 120/145, Loss: 0.2146
Epoch 3/10, Batch 130/145, Loss: 0.2090
Epoch 3/10, Batch 140/145, Loss: 0.2737
Epoch 3/10, Train Loss: 0.2960, Valid Loss: 0.2563
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2873
Epoch 4/10, Batch 20/145, Loss: 0.2789
Epoch 4/10, Batch 30/145, Loss: 0.2579
Epoch 4/10, Batch 40/145, Loss: 0.1870
Epoch 4/10, Batch 50/145, Loss: 0.1996
Epoch 4/10, Batch 60/145, Loss: 0.2178
Epoch 4/10, Batch 70/145, Loss: 0.2466
Epoch 4/10, Batch 80/145, Loss: 0.1404
Epoch 4/10, Batch 90/145, Loss: 0.2229
Epoch 4/10, Batch 100/145, Loss: 0.2860
Epoch 4/10, Batch 110/145, Loss: 0.1436
Epoch 4/10, Batch 120/145, Loss: 0.2814
Epoch 4/10, Batch 130/145, Loss: 0.2776
Epoch 4/10, Batch 140/145, Loss: 0.1631
Epoch 4/10, Train Loss: 0.2609, Valid Loss: 0.2464
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2993
Epoch 5/10, Batch 20/145, Loss: 0.1889
Epoch 5/10, Batch 30/145, Loss: 0.2211
Epoch 5/10, Batch 40/145, Loss: 0.2217
Epoch 5/10, Batch 50/145, Loss: 0.2103
Epoch 5/10, Batch 60/145, Loss: 0.1435
Epoch 5/10, Batch 70/145, Loss: 0.2646
Epoch 5/10, Batch 80/145, Loss: 0.1154
Epoch 5/10, Batch 90/145, Loss: 0.3417
Epoch 5/10, Batch 100/145, Loss: 0.1906
Epoch 5/10, Batch 110/145, Loss: 0.1677
Epoch 5/10, Batch 120/145, Loss: 0.5137
Epoch 5/10, Batch 130/145, Loss: 0.1736
Epoch 5/10, Batch 140/145, Loss: 0.2117
Epoch 5/10, Train Loss: 0.2489, Valid Loss: 0.2323
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1077
Epoch 6/10, Batch 20/145, Loss: 0.4684
Epoch 6/10, Batch 30/145, Loss: 0.2353
Epoch 6/10, Batch 40/145, Loss: 0.0466
Epoch 6/10, Batch 50/145, Loss: 0.2316
Epoch 6/10, Batch 60/145, Loss: 0.1947
Epoch 6/10, Batch 70/145, Loss: 0.0819
Epoch 6/10, Batch 80/145, Loss: 0.1097
Epoch 6/10, Batch 90/145, Loss: 0.2040
Epoch 6/10, Batch 100/145, Loss: 0.3357
Epoch 6/10, Batch 110/145, Loss: 0.1774
Epoch 6/10, Batch 120/145, Loss: 0.2772
Epoch 6/10, Batch 130/145, Loss: 0.2519
Epoch 6/10, Batch 140/145, Loss: 0.2031
Epoch 6/10, Train Loss: 0.2312, Valid Loss: 0.2320
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2141
Epoch 7/10, Batch 20/145, Loss: 0.2299
Epoch 7/10, Batch 30/145, Loss: 0.1574
Epoch 7/10, Batch 40/145, Loss: 0.2152
Epoch 7/10, Batch 50/145, Loss: 0.2230
Epoch 7/10, Batch 60/145, Loss: 0.3031
Epoch 7/10, Batch 70/145, Loss: 0.2320
Epoch 7/10, Batch 80/145, Loss: 0.4078
Epoch 7/10, Batch 90/145, Loss: 0.2176
Epoch 7/10, Batch 100/145, Loss: 0.1688
Epoch 7/10, Batch 110/145, Loss: 0.1881
Epoch 7/10, Batch 120/145, Loss: 0.3101
Epoch 7/10, Batch 130/145, Loss: 0.0879
Epoch 7/10, Batch 140/145, Loss: 0.2533
Epoch 7/10, Train Loss: 0.2133, Valid Loss: 0.2244
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1991
Epoch 8/10, Batch 20/145, Loss: 0.2775
Epoch 8/10, Batch 30/145, Loss: 0.3645
Epoch 8/10, Batch 40/145, Loss: 0.1584
Epoch 8/10, Batch 50/145, Loss: 0.3656
Epoch 8/10, Batch 60/145, Loss: 0.2623
Epoch 8/10, Batch 70/145, Loss: 0.3201
Epoch 8/10, Batch 80/145, Loss: 0.2560
Epoch 8/10, Batch 90/145, Loss: 0.3134
Epoch 8/10, Batch 100/145, Loss: 0.2685
Epoch 8/10, Batch 110/145, Loss: 0.2458
Epoch 8/10, Batch 120/145, Loss: 0.1949
Epoch 8/10, Batch 130/145, Loss: 0.2228
Epoch 8/10, Batch 140/145, Loss: 0.1724
Epoch 8/10, Train Loss: 0.2126, Valid Loss: 0.2276
Epoch 9/10, Batch 10/145, Loss: 0.3743
Epoch 9/10, Batch 20/145, Loss: 0.1279
Epoch 9/10, Batch 30/145, Loss: 0.1228
Epoch 9/10, Batch 40/145, Loss: 0.2167
Epoch 9/10, Batch 50/145, Loss: 0.1361
Epoch 9/10, Batch 60/145, Loss: 0.1659
Epoch 9/10, Batch 70/145, Loss: 0.1306
Epoch 9/10, Batch 80/145, Loss: 0.0713
Epoch 9/10, Batch 90/145, Loss: 0.2683
Epoch 9/10, Batch 100/145, Loss: 0.3847
Epoch 9/10, Batch 110/145, Loss: 0.1579
Epoch 9/10, Batch 120/145, Loss: 0.1656
Epoch 9/10, Batch 130/145, Loss: 0.2873
Epoch 9/10, Batch 140/145, Loss: 0.4519
Epoch 9/10, Train Loss: 0.2059, Valid Loss: 0.2202
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1853
Epoch 10/10, Batch 20/145, Loss: 0.1700
Epoch 10/10, Batch 30/145, Loss: 0.0910
Epoch 10/10, Batch 40/145, Loss: 0.1783
Epoch 10/10, Batch 50/145, Loss: 0.1559
Epoch 10/10, Batch 60/145, Loss: 0.2069
Epoch 10/10, Batch 70/145, Loss: 0.2147
Epoch 10/10, Batch 80/145, Loss: 0.2070
Epoch 10/10, Batch 90/145, Loss: 0.1600
Epoch 10/10, Batch 100/145, Loss: 0.2090
Epoch 10/10, Batch 110/145, Loss: 0.1378
Epoch 10/10, Batch 120/145, Loss: 0.2138
Epoch 10/10, Batch 130/145, Loss: 0.1147
Epoch 10/10, Batch 140/145, Loss: 0.2845
Epoch 10/10, Train Loss: 0.1931, Valid Loss: 0.2183
Model saved!
Accuracy: 0.9252
Precision: 0.9230
Recall: 0.9252
F1-score: 0.9234
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4035
Epoch 1/10, Batch 20/145, Loss: 0.9113
Epoch 1/10, Batch 30/145, Loss: 0.9326
Epoch 1/10, Batch 40/145, Loss: 0.7793
Epoch 1/10, Batch 50/145, Loss: 0.6860
Epoch 1/10, Batch 60/145, Loss: 0.6148
Epoch 1/10, Batch 70/145, Loss: 0.4196
Epoch 1/10, Batch 80/145, Loss: 0.5837
Epoch 1/10, Batch 90/145, Loss: 0.5231
Epoch 1/10, Batch 100/145, Loss: 0.3760
Epoch 1/10, Batch 110/145, Loss: 0.4454
Epoch 1/10, Batch 120/145, Loss: 0.5695
Epoch 1/10, Batch 130/145, Loss: 0.4503
Epoch 1/10, Batch 140/145, Loss: 0.2790
Epoch 1/10, Train Loss: 0.6790, Valid Loss: 0.3823
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4022
Epoch 2/10, Batch 20/145, Loss: 0.2398
Epoch 2/10, Batch 30/145, Loss: 0.3029
Epoch 2/10, Batch 40/145, Loss: 0.3807
Epoch 2/10, Batch 50/145, Loss: 0.2922
Epoch 2/10, Batch 60/145, Loss: 0.4976
Epoch 2/10, Batch 70/145, Loss: 0.3030
Epoch 2/10, Batch 80/145, Loss: 0.3582
Epoch 2/10, Batch 90/145, Loss: 0.2316
Epoch 2/10, Batch 100/145, Loss: 0.3597
Epoch 2/10, Batch 110/145, Loss: 0.3705
Epoch 2/10, Batch 120/145, Loss: 0.2505
Epoch 2/10, Batch 130/145, Loss: 0.3137
Epoch 2/10, Batch 140/145, Loss: 0.2593
Epoch 2/10, Train Loss: 0.3536, Valid Loss: 0.3006
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2148
Epoch 3/10, Batch 20/145, Loss: 0.2444
Epoch 3/10, Batch 30/145, Loss: 0.3313
Epoch 3/10, Batch 40/145, Loss: 0.2746
Epoch 3/10, Batch 50/145, Loss: 0.2560
Epoch 3/10, Batch 60/145, Loss: 0.4199
Epoch 3/10, Batch 70/145, Loss: 0.3671
Epoch 3/10, Batch 80/145, Loss: 0.1637
Epoch 3/10, Batch 90/145, Loss: 0.3354
Epoch 3/10, Batch 100/145, Loss: 0.2438
Epoch 3/10, Batch 110/145, Loss: 0.3073
Epoch 3/10, Batch 120/145, Loss: 0.2459
Epoch 3/10, Batch 130/145, Loss: 0.3530
Epoch 3/10, Batch 140/145, Loss: 0.2152
Epoch 3/10, Train Loss: 0.2968, Valid Loss: 0.2599
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3908
Epoch 4/10, Batch 20/145, Loss: 0.4038
Epoch 4/10, Batch 30/145, Loss: 0.2753
Epoch 4/10, Batch 40/145, Loss: 0.2100
Epoch 4/10, Batch 50/145, Loss: 0.1731
Epoch 4/10, Batch 60/145, Loss: 0.3029
Epoch 4/10, Batch 70/145, Loss: 0.2432
Epoch 4/10, Batch 80/145, Loss: 0.2130
Epoch 4/10, Batch 90/145, Loss: 0.1455
Epoch 4/10, Batch 100/145, Loss: 0.3085
Epoch 4/10, Batch 110/145, Loss: 0.1300
Epoch 4/10, Batch 120/145, Loss: 0.2357
Epoch 4/10, Batch 130/145, Loss: 0.1362
Epoch 4/10, Batch 140/145, Loss: 0.0816
Epoch 4/10, Train Loss: 0.2616, Valid Loss: 0.2495
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2866
Epoch 5/10, Batch 20/145, Loss: 0.0802
Epoch 5/10, Batch 30/145, Loss: 0.1702
Epoch 5/10, Batch 40/145, Loss: 0.2030
Epoch 5/10, Batch 50/145, Loss: 0.2500
Epoch 5/10, Batch 60/145, Loss: 0.1918
Epoch 5/10, Batch 70/145, Loss: 0.1281
Epoch 5/10, Batch 80/145, Loss: 0.2085
Epoch 5/10, Batch 90/145, Loss: 0.2412
Epoch 5/10, Batch 100/145, Loss: 0.1306
Epoch 5/10, Batch 110/145, Loss: 0.2106
Epoch 5/10, Batch 120/145, Loss: 0.3062
Epoch 5/10, Batch 130/145, Loss: 0.2311
Epoch 5/10, Batch 140/145, Loss: 0.2804
Epoch 5/10, Train Loss: 0.2450, Valid Loss: 0.2391
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1805
Epoch 6/10, Batch 20/145, Loss: 0.5177
Epoch 6/10, Batch 30/145, Loss: 0.2766
Epoch 6/10, Batch 40/145, Loss: 0.3030
Epoch 6/10, Batch 50/145, Loss: 0.2612
Epoch 6/10, Batch 60/145, Loss: 0.2017
Epoch 6/10, Batch 70/145, Loss: 0.1076
Epoch 6/10, Batch 80/145, Loss: 0.2051
Epoch 6/10, Batch 90/145, Loss: 0.3690
Epoch 6/10, Batch 100/145, Loss: 0.1796
Epoch 6/10, Batch 110/145, Loss: 0.2380
Epoch 6/10, Batch 120/145, Loss: 0.3440
Epoch 6/10, Batch 130/145, Loss: 0.1974
Epoch 6/10, Batch 140/145, Loss: 0.1438
Epoch 6/10, Train Loss: 0.2288, Valid Loss: 0.2266
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3485
Epoch 7/10, Batch 20/145, Loss: 0.2247
Epoch 7/10, Batch 30/145, Loss: 0.1927
Epoch 7/10, Batch 40/145, Loss: 0.4306
Epoch 7/10, Batch 50/145, Loss: 0.1138
Epoch 7/10, Batch 60/145, Loss: 0.1530
Epoch 7/10, Batch 70/145, Loss: 0.1240
Epoch 7/10, Batch 80/145, Loss: 0.5137
Epoch 7/10, Batch 90/145, Loss: 0.1365
Epoch 7/10, Batch 100/145, Loss: 0.1135
Epoch 7/10, Batch 110/145, Loss: 0.0802
Epoch 7/10, Batch 120/145, Loss: 0.2732
Epoch 7/10, Batch 130/145, Loss: 0.1341
Epoch 7/10, Batch 140/145, Loss: 0.1534
Epoch 7/10, Train Loss: 0.2120, Valid Loss: 0.2298
Epoch 8/10, Batch 10/145, Loss: 0.1733
Epoch 8/10, Batch 20/145, Loss: 0.2014
Epoch 8/10, Batch 30/145, Loss: 0.2311
Epoch 8/10, Batch 40/145, Loss: 0.1708
Epoch 8/10, Batch 50/145, Loss: 0.1925
Epoch 8/10, Batch 60/145, Loss: 0.3040
Epoch 8/10, Batch 70/145, Loss: 0.3804
Epoch 8/10, Batch 80/145, Loss: 0.1914
Epoch 8/10, Batch 90/145, Loss: 0.2969
Epoch 8/10, Batch 100/145, Loss: 0.2198
Epoch 8/10, Batch 110/145, Loss: 0.3713
Epoch 8/10, Batch 120/145, Loss: 0.2788
Epoch 8/10, Batch 130/145, Loss: 0.1441
Epoch 8/10, Batch 140/145, Loss: 0.1816
Epoch 8/10, Train Loss: 0.2097, Valid Loss: 0.2177
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3854
Epoch 9/10, Batch 20/145, Loss: 0.2103
Epoch 9/10, Batch 30/145, Loss: 0.1967
Epoch 9/10, Batch 40/145, Loss: 0.3252
Epoch 9/10, Batch 50/145, Loss: 0.1959
Epoch 9/10, Batch 60/145, Loss: 0.1828
Epoch 9/10, Batch 70/145, Loss: 0.2404
Epoch 9/10, Batch 80/145, Loss: 0.1043
Epoch 9/10, Batch 90/145, Loss: 0.4153
Epoch 9/10, Batch 100/145, Loss: 0.1819
Epoch 9/10, Batch 110/145, Loss: 0.2384
Epoch 9/10, Batch 120/145, Loss: 0.1535
Epoch 9/10, Batch 130/145, Loss: 0.3394
Epoch 9/10, Batch 140/145, Loss: 0.2022
Epoch 9/10, Train Loss: 0.1958, Valid Loss: 0.2152
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0629
Epoch 10/10, Batch 20/145, Loss: 0.0576
Epoch 10/10, Batch 30/145, Loss: 0.1117
Epoch 10/10, Batch 40/145, Loss: 0.1125
Epoch 10/10, Batch 50/145, Loss: 0.3658
Epoch 10/10, Batch 60/145, Loss: 0.1743
Epoch 10/10, Batch 70/145, Loss: 0.3622
Epoch 10/10, Batch 80/145, Loss: 0.1139
Epoch 10/10, Batch 90/145, Loss: 0.1874
Epoch 10/10, Batch 100/145, Loss: 0.2210
Epoch 10/10, Batch 110/145, Loss: 0.1785
Epoch 10/10, Batch 120/145, Loss: 0.1531
Epoch 10/10, Batch 130/145, Loss: 0.1057
Epoch 10/10, Batch 140/145, Loss: 0.1864
Epoch 10/10, Train Loss: 0.1890, Valid Loss: 0.2149
Model saved!
Accuracy: 0.9194
Precision: 0.9174
Recall: 0.9194
F1-score: 0.9174
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3496
Epoch 1/10, Batch 20/145, Loss: 0.9723
Epoch 1/10, Batch 30/145, Loss: 0.9014
Epoch 1/10, Batch 40/145, Loss: 0.8299
Epoch 1/10, Batch 50/145, Loss: 0.6741
Epoch 1/10, Batch 60/145, Loss: 0.5759
Epoch 1/10, Batch 70/145, Loss: 0.4272
Epoch 1/10, Batch 80/145, Loss: 0.5500
Epoch 1/10, Batch 90/145, Loss: 0.5087
Epoch 1/10, Batch 100/145, Loss: 0.5111
Epoch 1/10, Batch 110/145, Loss: 0.4082
Epoch 1/10, Batch 120/145, Loss: 0.4595
Epoch 1/10, Batch 130/145, Loss: 0.5312
Epoch 1/10, Batch 140/145, Loss: 0.3546
Epoch 1/10, Train Loss: 0.6788, Valid Loss: 0.3722
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3042
Epoch 2/10, Batch 20/145, Loss: 0.3251
Epoch 2/10, Batch 30/145, Loss: 0.2109
Epoch 2/10, Batch 40/145, Loss: 0.5624
Epoch 2/10, Batch 50/145, Loss: 0.3139
Epoch 2/10, Batch 60/145, Loss: 0.3470
Epoch 2/10, Batch 70/145, Loss: 0.3709
Epoch 2/10, Batch 80/145, Loss: 0.3804
Epoch 2/10, Batch 90/145, Loss: 0.2418
Epoch 2/10, Batch 100/145, Loss: 0.3121
Epoch 2/10, Batch 110/145, Loss: 0.3852
Epoch 2/10, Batch 120/145, Loss: 0.3896
Epoch 2/10, Batch 130/145, Loss: 0.1992
Epoch 2/10, Batch 140/145, Loss: 0.3651
Epoch 2/10, Train Loss: 0.3534, Valid Loss: 0.2976
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2547
Epoch 3/10, Batch 20/145, Loss: 0.2611
Epoch 3/10, Batch 30/145, Loss: 0.3597
Epoch 3/10, Batch 40/145, Loss: 0.1458
Epoch 3/10, Batch 50/145, Loss: 0.3902
Epoch 3/10, Batch 60/145, Loss: 0.2495
Epoch 3/10, Batch 70/145, Loss: 0.2218
Epoch 3/10, Batch 80/145, Loss: 0.2904
Epoch 3/10, Batch 90/145, Loss: 0.3342
Epoch 3/10, Batch 100/145, Loss: 0.3701
Epoch 3/10, Batch 110/145, Loss: 0.1855
Epoch 3/10, Batch 120/145, Loss: 0.2720
Epoch 3/10, Batch 130/145, Loss: 0.4073
Epoch 3/10, Batch 140/145, Loss: 0.2408
Epoch 3/10, Train Loss: 0.2938, Valid Loss: 0.2671
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2854
Epoch 4/10, Batch 20/145, Loss: 0.1223
Epoch 4/10, Batch 30/145, Loss: 0.3167
Epoch 4/10, Batch 40/145, Loss: 0.2824
Epoch 4/10, Batch 50/145, Loss: 0.2610
Epoch 4/10, Batch 60/145, Loss: 0.1731
Epoch 4/10, Batch 70/145, Loss: 0.1805
Epoch 4/10, Batch 80/145, Loss: 0.1850
Epoch 4/10, Batch 90/145, Loss: 0.0864
Epoch 4/10, Batch 100/145, Loss: 0.2645
Epoch 4/10, Batch 110/145, Loss: 0.1254
Epoch 4/10, Batch 120/145, Loss: 0.2307
Epoch 4/10, Batch 130/145, Loss: 0.1908
Epoch 4/10, Batch 140/145, Loss: 0.1809
Epoch 4/10, Train Loss: 0.2552, Valid Loss: 0.2514
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2244
Epoch 5/10, Batch 20/145, Loss: 0.2293
Epoch 5/10, Batch 30/145, Loss: 0.1705
Epoch 5/10, Batch 40/145, Loss: 0.2998
Epoch 5/10, Batch 50/145, Loss: 0.2027
Epoch 5/10, Batch 60/145, Loss: 0.3343
Epoch 5/10, Batch 70/145, Loss: 0.1633
Epoch 5/10, Batch 80/145, Loss: 0.1466
Epoch 5/10, Batch 90/145, Loss: 0.2873
Epoch 5/10, Batch 100/145, Loss: 0.1193
Epoch 5/10, Batch 110/145, Loss: 0.2277
Epoch 5/10, Batch 120/145, Loss: 0.3105
Epoch 5/10, Batch 130/145, Loss: 0.1246
Epoch 5/10, Batch 140/145, Loss: 0.3214
Epoch 5/10, Train Loss: 0.2442, Valid Loss: 0.2426
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2115
Epoch 6/10, Batch 20/145, Loss: 0.5113
Epoch 6/10, Batch 30/145, Loss: 0.1957
Epoch 6/10, Batch 40/145, Loss: 0.1413
Epoch 6/10, Batch 50/145, Loss: 0.2689
Epoch 6/10, Batch 60/145, Loss: 0.2611
Epoch 6/10, Batch 70/145, Loss: 0.1884
Epoch 6/10, Batch 80/145, Loss: 0.1975
Epoch 6/10, Batch 90/145, Loss: 0.2179
Epoch 6/10, Batch 100/145, Loss: 0.3025
Epoch 6/10, Batch 110/145, Loss: 0.2151
Epoch 6/10, Batch 120/145, Loss: 0.4719
Epoch 6/10, Batch 130/145, Loss: 0.0888
Epoch 6/10, Batch 140/145, Loss: 0.1640
Epoch 6/10, Train Loss: 0.2260, Valid Loss: 0.2334
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1904
Epoch 7/10, Batch 20/145, Loss: 0.1653
Epoch 7/10, Batch 30/145, Loss: 0.1189
Epoch 7/10, Batch 40/145, Loss: 0.3513
Epoch 7/10, Batch 50/145, Loss: 0.1376
Epoch 7/10, Batch 60/145, Loss: 0.2626
Epoch 7/10, Batch 70/145, Loss: 0.0698
Epoch 7/10, Batch 80/145, Loss: 0.3116
Epoch 7/10, Batch 90/145, Loss: 0.1799
Epoch 7/10, Batch 100/145, Loss: 0.2155
Epoch 7/10, Batch 110/145, Loss: 0.3072
Epoch 7/10, Batch 120/145, Loss: 0.1593
Epoch 7/10, Batch 130/145, Loss: 0.1266
Epoch 7/10, Batch 140/145, Loss: 0.3059
Epoch 7/10, Train Loss: 0.2066, Valid Loss: 0.2323
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2854
Epoch 8/10, Batch 20/145, Loss: 0.2956
Epoch 8/10, Batch 30/145, Loss: 0.2019
Epoch 8/10, Batch 40/145, Loss: 0.1817
Epoch 8/10, Batch 50/145, Loss: 0.4024
Epoch 8/10, Batch 60/145, Loss: 0.3094
Epoch 8/10, Batch 70/145, Loss: 0.3280
Epoch 8/10, Batch 80/145, Loss: 0.1509
Epoch 8/10, Batch 90/145, Loss: 0.2960
Epoch 8/10, Batch 100/145, Loss: 0.2293
Epoch 8/10, Batch 110/145, Loss: 0.1481
Epoch 8/10, Batch 120/145, Loss: 0.1810
Epoch 8/10, Batch 130/145, Loss: 0.1690
Epoch 8/10, Batch 140/145, Loss: 0.1351
Epoch 8/10, Train Loss: 0.2056, Valid Loss: 0.2357
Epoch 9/10, Batch 10/145, Loss: 0.3160
Epoch 9/10, Batch 20/145, Loss: 0.2328
Epoch 9/10, Batch 30/145, Loss: 0.1342
Epoch 9/10, Batch 40/145, Loss: 0.2039
Epoch 9/10, Batch 50/145, Loss: 0.1853
Epoch 9/10, Batch 60/145, Loss: 0.2386
Epoch 9/10, Batch 70/145, Loss: 0.1622
Epoch 9/10, Batch 80/145, Loss: 0.0950
Epoch 9/10, Batch 90/145, Loss: 0.2847
Epoch 9/10, Batch 100/145, Loss: 0.0764
Epoch 9/10, Batch 110/145, Loss: 0.3063
Epoch 9/10, Batch 120/145, Loss: 0.1354
Epoch 9/10, Batch 130/145, Loss: 0.2335
Epoch 9/10, Batch 140/145, Loss: 0.1628
Epoch 9/10, Train Loss: 0.1978, Valid Loss: 0.2305
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1932
Epoch 10/10, Batch 20/145, Loss: 0.2063
Epoch 10/10, Batch 30/145, Loss: 0.1352
Epoch 10/10, Batch 40/145, Loss: 0.1863
Epoch 10/10, Batch 50/145, Loss: 0.2117
Epoch 10/10, Batch 60/145, Loss: 0.1006
Epoch 10/10, Batch 70/145, Loss: 0.4220
Epoch 10/10, Batch 80/145, Loss: 0.1705
Epoch 10/10, Batch 90/145, Loss: 0.1173
Epoch 10/10, Batch 100/145, Loss: 0.2212
Epoch 10/10, Batch 110/145, Loss: 0.1652
Epoch 10/10, Batch 120/145, Loss: 0.2471
Epoch 10/10, Batch 130/145, Loss: 0.2071
Epoch 10/10, Batch 140/145, Loss: 0.1552
Epoch 10/10, Train Loss: 0.1952, Valid Loss: 0.2314
Accuracy: 0.9147
Precision: 0.9131
Recall: 0.9147
F1-score: 0.9133
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4539
Epoch 1/10, Batch 20/145, Loss: 0.9188
Epoch 1/10, Batch 30/145, Loss: 0.8561
Epoch 1/10, Batch 40/145, Loss: 0.7748
Epoch 1/10, Batch 50/145, Loss: 0.6474
Epoch 1/10, Batch 60/145, Loss: 0.6933
Epoch 1/10, Batch 70/145, Loss: 0.6023
Epoch 1/10, Batch 80/145, Loss: 0.6017
Epoch 1/10, Batch 90/145, Loss: 0.4020
Epoch 1/10, Batch 100/145, Loss: 0.5383
Epoch 1/10, Batch 110/145, Loss: 0.4072
Epoch 1/10, Batch 120/145, Loss: 0.6542
Epoch 1/10, Batch 130/145, Loss: 0.3933
Epoch 1/10, Batch 140/145, Loss: 0.2727
Epoch 1/10, Train Loss: 0.6899, Valid Loss: 0.3910
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4219
Epoch 2/10, Batch 20/145, Loss: 0.3269
Epoch 2/10, Batch 30/145, Loss: 0.3752
Epoch 2/10, Batch 40/145, Loss: 0.6116
Epoch 2/10, Batch 50/145, Loss: 0.4994
Epoch 2/10, Batch 60/145, Loss: 0.3275
Epoch 2/10, Batch 70/145, Loss: 0.3489
Epoch 2/10, Batch 80/145, Loss: 0.3776
Epoch 2/10, Batch 90/145, Loss: 0.3119
Epoch 2/10, Batch 100/145, Loss: 0.3571
Epoch 2/10, Batch 110/145, Loss: 0.3852
Epoch 2/10, Batch 120/145, Loss: 0.3622
Epoch 2/10, Batch 130/145, Loss: 0.2756
Epoch 2/10, Batch 140/145, Loss: 0.2398
Epoch 2/10, Train Loss: 0.3608, Valid Loss: 0.3160
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3350
Epoch 3/10, Batch 20/145, Loss: 0.2055
Epoch 3/10, Batch 30/145, Loss: 0.2710
Epoch 3/10, Batch 40/145, Loss: 0.2310
Epoch 3/10, Batch 50/145, Loss: 0.1452
Epoch 3/10, Batch 60/145, Loss: 0.4288
Epoch 3/10, Batch 70/145, Loss: 0.3380
Epoch 3/10, Batch 80/145, Loss: 0.4227
Epoch 3/10, Batch 90/145, Loss: 0.2797
Epoch 3/10, Batch 100/145, Loss: 0.2328
Epoch 3/10, Batch 110/145, Loss: 0.2008
Epoch 3/10, Batch 120/145, Loss: 0.1338
Epoch 3/10, Batch 130/145, Loss: 0.2067
Epoch 3/10, Batch 140/145, Loss: 0.1949
Epoch 3/10, Train Loss: 0.3022, Valid Loss: 0.2788
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3881
Epoch 4/10, Batch 20/145, Loss: 0.4707
Epoch 4/10, Batch 30/145, Loss: 0.2734
Epoch 4/10, Batch 40/145, Loss: 0.1400
Epoch 4/10, Batch 50/145, Loss: 0.1278
Epoch 4/10, Batch 60/145, Loss: 0.3390
Epoch 4/10, Batch 70/145, Loss: 0.1715
Epoch 4/10, Batch 80/145, Loss: 0.1920
Epoch 4/10, Batch 90/145, Loss: 0.2762
Epoch 4/10, Batch 100/145, Loss: 0.3239
Epoch 4/10, Batch 110/145, Loss: 0.1971
Epoch 4/10, Batch 120/145, Loss: 0.2493
Epoch 4/10, Batch 130/145, Loss: 0.1099
Epoch 4/10, Batch 140/145, Loss: 0.2541
Epoch 4/10, Train Loss: 0.2633, Valid Loss: 0.2620
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1750
Epoch 5/10, Batch 20/145, Loss: 0.2277
Epoch 5/10, Batch 30/145, Loss: 0.2262
Epoch 5/10, Batch 40/145, Loss: 0.1458
Epoch 5/10, Batch 50/145, Loss: 0.2111
Epoch 5/10, Batch 60/145, Loss: 0.2263
Epoch 5/10, Batch 70/145, Loss: 0.2985
Epoch 5/10, Batch 80/145, Loss: 0.1454
Epoch 5/10, Batch 90/145, Loss: 0.3337
Epoch 5/10, Batch 100/145, Loss: 0.2966
Epoch 5/10, Batch 110/145, Loss: 0.3527
Epoch 5/10, Batch 120/145, Loss: 0.2941
Epoch 5/10, Batch 130/145, Loss: 0.2272
Epoch 5/10, Batch 140/145, Loss: 0.1296
Epoch 5/10, Train Loss: 0.2465, Valid Loss: 0.2509
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1927
Epoch 6/10, Batch 20/145, Loss: 0.4285
Epoch 6/10, Batch 30/145, Loss: 0.2916
Epoch 6/10, Batch 40/145, Loss: 0.1379
Epoch 6/10, Batch 50/145, Loss: 0.3246
Epoch 6/10, Batch 60/145, Loss: 0.1779
Epoch 6/10, Batch 70/145, Loss: 0.2123
Epoch 6/10, Batch 80/145, Loss: 0.1534
Epoch 6/10, Batch 90/145, Loss: 0.1913
Epoch 6/10, Batch 100/145, Loss: 0.4290
Epoch 6/10, Batch 110/145, Loss: 0.1298
Epoch 6/10, Batch 120/145, Loss: 0.2307
Epoch 6/10, Batch 130/145, Loss: 0.1586
Epoch 6/10, Batch 140/145, Loss: 0.2966
Epoch 6/10, Train Loss: 0.2340, Valid Loss: 0.2472
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1642
Epoch 7/10, Batch 20/145, Loss: 0.3278
Epoch 7/10, Batch 30/145, Loss: 0.2548
Epoch 7/10, Batch 40/145, Loss: 0.3605
Epoch 7/10, Batch 50/145, Loss: 0.3231
Epoch 7/10, Batch 60/145, Loss: 0.1313
Epoch 7/10, Batch 70/145, Loss: 0.1999
Epoch 7/10, Batch 80/145, Loss: 0.3448
Epoch 7/10, Batch 90/145, Loss: 0.3586
Epoch 7/10, Batch 100/145, Loss: 0.2188
Epoch 7/10, Batch 110/145, Loss: 0.2586
Epoch 7/10, Batch 120/145, Loss: 0.2280
Epoch 7/10, Batch 130/145, Loss: 0.1789
Epoch 7/10, Batch 140/145, Loss: 0.2652
Epoch 7/10, Train Loss: 0.2182, Valid Loss: 0.2388
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1377
Epoch 8/10, Batch 20/145, Loss: 0.3215
Epoch 8/10, Batch 30/145, Loss: 0.2306
Epoch 8/10, Batch 40/145, Loss: 0.2009
Epoch 8/10, Batch 50/145, Loss: 0.0934
Epoch 8/10, Batch 60/145, Loss: 0.2846
Epoch 8/10, Batch 70/145, Loss: 0.1026
Epoch 8/10, Batch 80/145, Loss: 0.0875
Epoch 8/10, Batch 90/145, Loss: 0.1777
Epoch 8/10, Batch 100/145, Loss: 0.2782
Epoch 8/10, Batch 110/145, Loss: 0.2417
Epoch 8/10, Batch 120/145, Loss: 0.1950
Epoch 8/10, Batch 130/145, Loss: 0.1641
Epoch 8/10, Batch 140/145, Loss: 0.1877
Epoch 8/10, Train Loss: 0.2102, Valid Loss: 0.2276
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2849
Epoch 9/10, Batch 20/145, Loss: 0.2017
Epoch 9/10, Batch 30/145, Loss: 0.1599
Epoch 9/10, Batch 40/145, Loss: 0.1925
Epoch 9/10, Batch 50/145, Loss: 0.2030
Epoch 9/10, Batch 60/145, Loss: 0.3775
Epoch 9/10, Batch 70/145, Loss: 0.1587
Epoch 9/10, Batch 80/145, Loss: 0.1345
Epoch 9/10, Batch 90/145, Loss: 0.2012
Epoch 9/10, Batch 100/145, Loss: 0.1656
Epoch 9/10, Batch 110/145, Loss: 0.2534
Epoch 9/10, Batch 120/145, Loss: 0.2008
Epoch 9/10, Batch 130/145, Loss: 0.3462
Epoch 9/10, Batch 140/145, Loss: 0.2931
Epoch 9/10, Train Loss: 0.2047, Valid Loss: 0.2300
Epoch 10/10, Batch 10/145, Loss: 0.0645
Epoch 10/10, Batch 20/145, Loss: 0.1684
Epoch 10/10, Batch 30/145, Loss: 0.1435
Epoch 10/10, Batch 40/145, Loss: 0.1206
Epoch 10/10, Batch 50/145, Loss: 0.1393
Epoch 10/10, Batch 60/145, Loss: 0.1634
Epoch 10/10, Batch 70/145, Loss: 0.3132
Epoch 10/10, Batch 80/145, Loss: 0.2481
Epoch 10/10, Batch 90/145, Loss: 0.1299
Epoch 10/10, Batch 100/145, Loss: 0.1574
Epoch 10/10, Batch 110/145, Loss: 0.1517
Epoch 10/10, Batch 120/145, Loss: 0.1184
Epoch 10/10, Batch 130/145, Loss: 0.3284
Epoch 10/10, Batch 140/145, Loss: 0.1964
Epoch 10/10, Train Loss: 0.1978, Valid Loss: 0.2300
Accuracy: 0.9194
Precision: 0.9169
Recall: 0.9194
F1-score: 0.9177
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3228
Epoch 1/10, Batch 20/145, Loss: 1.0220
Epoch 1/10, Batch 30/145, Loss: 0.8545
Epoch 1/10, Batch 40/145, Loss: 0.8440
Epoch 1/10, Batch 50/145, Loss: 0.7192
Epoch 1/10, Batch 60/145, Loss: 0.7133
Epoch 1/10, Batch 70/145, Loss: 0.4139
Epoch 1/10, Batch 80/145, Loss: 0.5578
Epoch 1/10, Batch 90/145, Loss: 0.4187
Epoch 1/10, Batch 100/145, Loss: 0.4102
Epoch 1/10, Batch 110/145, Loss: 0.4378
Epoch 1/10, Batch 120/145, Loss: 0.6852
Epoch 1/10, Batch 130/145, Loss: 0.7388
Epoch 1/10, Batch 140/145, Loss: 0.3332
Epoch 1/10, Train Loss: 0.6790, Valid Loss: 0.3634
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3000
Epoch 2/10, Batch 20/145, Loss: 0.3928
Epoch 2/10, Batch 30/145, Loss: 0.3469
Epoch 2/10, Batch 40/145, Loss: 0.4711
Epoch 2/10, Batch 50/145, Loss: 0.2514
Epoch 2/10, Batch 60/145, Loss: 0.4360
Epoch 2/10, Batch 70/145, Loss: 0.3923
Epoch 2/10, Batch 80/145, Loss: 0.2108
Epoch 2/10, Batch 90/145, Loss: 0.3504
Epoch 2/10, Batch 100/145, Loss: 0.2766
Epoch 2/10, Batch 110/145, Loss: 0.4238
Epoch 2/10, Batch 120/145, Loss: 0.3792
Epoch 2/10, Batch 130/145, Loss: 0.2419
Epoch 2/10, Batch 140/145, Loss: 0.2237
Epoch 2/10, Train Loss: 0.3503, Valid Loss: 0.2816
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3630
Epoch 3/10, Batch 20/145, Loss: 0.4278
Epoch 3/10, Batch 30/145, Loss: 0.2591
Epoch 3/10, Batch 40/145, Loss: 0.2829
Epoch 3/10, Batch 50/145, Loss: 0.3494
Epoch 3/10, Batch 60/145, Loss: 0.2340
Epoch 3/10, Batch 70/145, Loss: 0.2206
Epoch 3/10, Batch 80/145, Loss: 0.1458
Epoch 3/10, Batch 90/145, Loss: 0.2994
Epoch 3/10, Batch 100/145, Loss: 0.2587
Epoch 3/10, Batch 110/145, Loss: 0.2275
Epoch 3/10, Batch 120/145, Loss: 0.1512
Epoch 3/10, Batch 130/145, Loss: 0.3827
Epoch 3/10, Batch 140/145, Loss: 0.2177
Epoch 3/10, Train Loss: 0.2905, Valid Loss: 0.2494
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4034
Epoch 4/10, Batch 20/145, Loss: 0.1943
Epoch 4/10, Batch 30/145, Loss: 0.2509
Epoch 4/10, Batch 40/145, Loss: 0.1713
Epoch 4/10, Batch 50/145, Loss: 0.1741
Epoch 4/10, Batch 60/145, Loss: 0.2906
Epoch 4/10, Batch 70/145, Loss: 0.2402
Epoch 4/10, Batch 80/145, Loss: 0.0847
Epoch 4/10, Batch 90/145, Loss: 0.2301
Epoch 4/10, Batch 100/145, Loss: 0.3642
Epoch 4/10, Batch 110/145, Loss: 0.1626
Epoch 4/10, Batch 120/145, Loss: 0.3960
Epoch 4/10, Batch 130/145, Loss: 0.3549
Epoch 4/10, Batch 140/145, Loss: 0.1197
Epoch 4/10, Train Loss: 0.2481, Valid Loss: 0.2388
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1839
Epoch 5/10, Batch 20/145, Loss: 0.1073
Epoch 5/10, Batch 30/145, Loss: 0.1106
Epoch 5/10, Batch 40/145, Loss: 0.0661
Epoch 5/10, Batch 50/145, Loss: 0.2541
Epoch 5/10, Batch 60/145, Loss: 0.2449
Epoch 5/10, Batch 70/145, Loss: 0.3484
Epoch 5/10, Batch 80/145, Loss: 0.1652
Epoch 5/10, Batch 90/145, Loss: 0.1362
Epoch 5/10, Batch 100/145, Loss: 0.1744
Epoch 5/10, Batch 110/145, Loss: 0.2276
Epoch 5/10, Batch 120/145, Loss: 0.2939
Epoch 5/10, Batch 130/145, Loss: 0.1697
Epoch 5/10, Batch 140/145, Loss: 0.3426
Epoch 5/10, Train Loss: 0.2356, Valid Loss: 0.2255
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1581
Epoch 6/10, Batch 20/145, Loss: 0.2743
Epoch 6/10, Batch 30/145, Loss: 0.1339
Epoch 6/10, Batch 40/145, Loss: 0.1647
Epoch 6/10, Batch 50/145, Loss: 0.4973
Epoch 6/10, Batch 60/145, Loss: 0.1988
Epoch 6/10, Batch 70/145, Loss: 0.2096
Epoch 6/10, Batch 80/145, Loss: 0.2852
Epoch 6/10, Batch 90/145, Loss: 0.2710
Epoch 6/10, Batch 100/145, Loss: 0.1769
Epoch 6/10, Batch 110/145, Loss: 0.4588
Epoch 6/10, Batch 120/145, Loss: 0.2335
Epoch 6/10, Batch 130/145, Loss: 0.1243
Epoch 6/10, Batch 140/145, Loss: 0.2398
Epoch 6/10, Train Loss: 0.2205, Valid Loss: 0.2208
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1815
Epoch 7/10, Batch 20/145, Loss: 0.3534
Epoch 7/10, Batch 30/145, Loss: 0.3311
Epoch 7/10, Batch 40/145, Loss: 0.3172
Epoch 7/10, Batch 50/145, Loss: 0.1769
Epoch 7/10, Batch 60/145, Loss: 0.2163
Epoch 7/10, Batch 70/145, Loss: 0.1216
Epoch 7/10, Batch 80/145, Loss: 0.3913
Epoch 7/10, Batch 90/145, Loss: 0.1365
Epoch 7/10, Batch 100/145, Loss: 0.1420
Epoch 7/10, Batch 110/145, Loss: 0.2092
Epoch 7/10, Batch 120/145, Loss: 0.1952
Epoch 7/10, Batch 130/145, Loss: 0.1341
Epoch 7/10, Batch 140/145, Loss: 0.3349
Epoch 7/10, Train Loss: 0.2108, Valid Loss: 0.2153
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.3175
Epoch 8/10, Batch 20/145, Loss: 0.2055
Epoch 8/10, Batch 30/145, Loss: 0.1217
Epoch 8/10, Batch 40/145, Loss: 0.0670
Epoch 8/10, Batch 50/145, Loss: 0.2025
Epoch 8/10, Batch 60/145, Loss: 0.2186
Epoch 8/10, Batch 70/145, Loss: 0.4515
Epoch 8/10, Batch 80/145, Loss: 0.2240
Epoch 8/10, Batch 90/145, Loss: 0.3970
Epoch 8/10, Batch 100/145, Loss: 0.2875
Epoch 8/10, Batch 110/145, Loss: 0.3531
Epoch 8/10, Batch 120/145, Loss: 0.1673
Epoch 8/10, Batch 130/145, Loss: 0.2155
Epoch 8/10, Batch 140/145, Loss: 0.1226
Epoch 8/10, Train Loss: 0.2027, Valid Loss: 0.2107
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1871
Epoch 9/10, Batch 20/145, Loss: 0.2235
Epoch 9/10, Batch 30/145, Loss: 0.1212
Epoch 9/10, Batch 40/145, Loss: 0.1546
Epoch 9/10, Batch 50/145, Loss: 0.1159
Epoch 9/10, Batch 60/145, Loss: 0.2185
Epoch 9/10, Batch 70/145, Loss: 0.2743
Epoch 9/10, Batch 80/145, Loss: 0.1433
Epoch 9/10, Batch 90/145, Loss: 0.2256
Epoch 9/10, Batch 100/145, Loss: 0.1479
Epoch 9/10, Batch 110/145, Loss: 0.2388
Epoch 9/10, Batch 120/145, Loss: 0.1863
Epoch 9/10, Batch 130/145, Loss: 0.0630
Epoch 9/10, Batch 140/145, Loss: 0.2286
Epoch 9/10, Train Loss: 0.1909, Valid Loss: 0.2085
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0979
Epoch 10/10, Batch 20/145, Loss: 0.1895
Epoch 10/10, Batch 30/145, Loss: 0.0950
Epoch 10/10, Batch 40/145, Loss: 0.0801
Epoch 10/10, Batch 50/145, Loss: 0.1913
Epoch 10/10, Batch 60/145, Loss: 0.0716
Epoch 10/10, Batch 70/145, Loss: 0.3460
Epoch 10/10, Batch 80/145, Loss: 0.1934
Epoch 10/10, Batch 90/145, Loss: 0.1749
Epoch 10/10, Batch 100/145, Loss: 0.1187
Epoch 10/10, Batch 110/145, Loss: 0.1359
Epoch 10/10, Batch 120/145, Loss: 0.2168
Epoch 10/10, Batch 130/145, Loss: 0.1766
Epoch 10/10, Batch 140/145, Loss: 0.1930
Epoch 10/10, Train Loss: 0.1881, Valid Loss: 0.2055
Model saved!
Accuracy: 0.9182
Precision: 0.9151
Recall: 0.9182
F1-score: 0.9152
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4034
Epoch 1/10, Batch 20/145, Loss: 0.8566
Epoch 1/10, Batch 30/145, Loss: 0.8999
Epoch 1/10, Batch 40/145, Loss: 0.7356
Epoch 1/10, Batch 50/145, Loss: 0.8629
Epoch 1/10, Batch 60/145, Loss: 0.5588
Epoch 1/10, Batch 70/145, Loss: 0.4872
Epoch 1/10, Batch 80/145, Loss: 0.5990
Epoch 1/10, Batch 90/145, Loss: 0.5271
Epoch 1/10, Batch 100/145, Loss: 0.4720
Epoch 1/10, Batch 110/145, Loss: 0.4325
Epoch 1/10, Batch 120/145, Loss: 0.6996
Epoch 1/10, Batch 130/145, Loss: 0.5354
Epoch 1/10, Batch 140/145, Loss: 0.4031
Epoch 1/10, Train Loss: 0.6857, Valid Loss: 0.3588
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4133
Epoch 2/10, Batch 20/145, Loss: 0.3437
Epoch 2/10, Batch 30/145, Loss: 0.2573
Epoch 2/10, Batch 40/145, Loss: 0.5163
Epoch 2/10, Batch 50/145, Loss: 0.3656
Epoch 2/10, Batch 60/145, Loss: 0.3274
Epoch 2/10, Batch 70/145, Loss: 0.4160
Epoch 2/10, Batch 80/145, Loss: 0.3732
Epoch 2/10, Batch 90/145, Loss: 0.2768
Epoch 2/10, Batch 100/145, Loss: 0.2335
Epoch 2/10, Batch 110/145, Loss: 0.3829
Epoch 2/10, Batch 120/145, Loss: 0.3107
Epoch 2/10, Batch 130/145, Loss: 0.1709
Epoch 2/10, Batch 140/145, Loss: 0.3366
Epoch 2/10, Train Loss: 0.3537, Valid Loss: 0.2789
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3792
Epoch 3/10, Batch 20/145, Loss: 0.2171
Epoch 3/10, Batch 30/145, Loss: 0.3594
Epoch 3/10, Batch 40/145, Loss: 0.3010
Epoch 3/10, Batch 50/145, Loss: 0.2914
Epoch 3/10, Batch 60/145, Loss: 0.4143
Epoch 3/10, Batch 70/145, Loss: 0.4397
Epoch 3/10, Batch 80/145, Loss: 0.2600
Epoch 3/10, Batch 90/145, Loss: 0.3664
Epoch 3/10, Batch 100/145, Loss: 0.3269
Epoch 3/10, Batch 110/145, Loss: 0.3512
Epoch 3/10, Batch 120/145, Loss: 0.2078
Epoch 3/10, Batch 130/145, Loss: 0.4100
Epoch 3/10, Batch 140/145, Loss: 0.2794
Epoch 3/10, Train Loss: 0.2986, Valid Loss: 0.2520
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3136
Epoch 4/10, Batch 20/145, Loss: 0.3697
Epoch 4/10, Batch 30/145, Loss: 0.4483
Epoch 4/10, Batch 40/145, Loss: 0.1212
Epoch 4/10, Batch 50/145, Loss: 0.2243
Epoch 4/10, Batch 60/145, Loss: 0.3114
Epoch 4/10, Batch 70/145, Loss: 0.1556
Epoch 4/10, Batch 80/145, Loss: 0.2651
Epoch 4/10, Batch 90/145, Loss: 0.2580
Epoch 4/10, Batch 100/145, Loss: 0.2459
Epoch 4/10, Batch 110/145, Loss: 0.0913
Epoch 4/10, Batch 120/145, Loss: 0.2874
Epoch 4/10, Batch 130/145, Loss: 0.1836
Epoch 4/10, Batch 140/145, Loss: 0.2252
Epoch 4/10, Train Loss: 0.2609, Valid Loss: 0.2382
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3492
Epoch 5/10, Batch 20/145, Loss: 0.1575
Epoch 5/10, Batch 30/145, Loss: 0.1595
Epoch 5/10, Batch 40/145, Loss: 0.2715
Epoch 5/10, Batch 50/145, Loss: 0.2491
Epoch 5/10, Batch 60/145, Loss: 0.2531
Epoch 5/10, Batch 70/145, Loss: 0.1844
Epoch 5/10, Batch 80/145, Loss: 0.2610
Epoch 5/10, Batch 90/145, Loss: 0.4362
Epoch 5/10, Batch 100/145, Loss: 0.2556
Epoch 5/10, Batch 110/145, Loss: 0.2987
Epoch 5/10, Batch 120/145, Loss: 0.2334
Epoch 5/10, Batch 130/145, Loss: 0.1171
Epoch 5/10, Batch 140/145, Loss: 0.1176
Epoch 5/10, Train Loss: 0.2497, Valid Loss: 0.2230
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1975
Epoch 6/10, Batch 20/145, Loss: 0.3116
Epoch 6/10, Batch 30/145, Loss: 0.2567
Epoch 6/10, Batch 40/145, Loss: 0.0663
Epoch 6/10, Batch 50/145, Loss: 0.3185
Epoch 6/10, Batch 60/145, Loss: 0.1316
Epoch 6/10, Batch 70/145, Loss: 0.2909
Epoch 6/10, Batch 80/145, Loss: 0.1520
Epoch 6/10, Batch 90/145, Loss: 0.3921
Epoch 6/10, Batch 100/145, Loss: 0.2331
Epoch 6/10, Batch 110/145, Loss: 0.1749
Epoch 6/10, Batch 120/145, Loss: 0.3677
Epoch 6/10, Batch 130/145, Loss: 0.0542
Epoch 6/10, Batch 140/145, Loss: 0.2356
Epoch 6/10, Train Loss: 0.2311, Valid Loss: 0.2216
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2023
Epoch 7/10, Batch 20/145, Loss: 0.3910
Epoch 7/10, Batch 30/145, Loss: 0.2530
Epoch 7/10, Batch 40/145, Loss: 0.4296
Epoch 7/10, Batch 50/145, Loss: 0.1397
Epoch 7/10, Batch 60/145, Loss: 0.1717
Epoch 7/10, Batch 70/145, Loss: 0.0970
Epoch 7/10, Batch 80/145, Loss: 0.6560
Epoch 7/10, Batch 90/145, Loss: 0.2202
Epoch 7/10, Batch 100/145, Loss: 0.1259
Epoch 7/10, Batch 110/145, Loss: 0.2694
Epoch 7/10, Batch 120/145, Loss: 0.2191
Epoch 7/10, Batch 130/145, Loss: 0.2190
Epoch 7/10, Batch 140/145, Loss: 0.3937
Epoch 7/10, Train Loss: 0.2223, Valid Loss: 0.2131
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1345
Epoch 8/10, Batch 20/145, Loss: 0.3702
Epoch 8/10, Batch 30/145, Loss: 0.2581
Epoch 8/10, Batch 40/145, Loss: 0.2465
Epoch 8/10, Batch 50/145, Loss: 0.2181
Epoch 8/10, Batch 60/145, Loss: 0.1270
Epoch 8/10, Batch 70/145, Loss: 0.2182
Epoch 8/10, Batch 80/145, Loss: 0.1198
Epoch 8/10, Batch 90/145, Loss: 0.4665
Epoch 8/10, Batch 100/145, Loss: 0.0785
Epoch 8/10, Batch 110/145, Loss: 0.1495
Epoch 8/10, Batch 120/145, Loss: 0.1660
Epoch 8/10, Batch 130/145, Loss: 0.2388
Epoch 8/10, Batch 140/145, Loss: 0.3976
Epoch 8/10, Train Loss: 0.2134, Valid Loss: 0.2112
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2541
Epoch 9/10, Batch 20/145, Loss: 0.1464
Epoch 9/10, Batch 30/145, Loss: 0.1592
Epoch 9/10, Batch 40/145, Loss: 0.1943
Epoch 9/10, Batch 50/145, Loss: 0.3465
Epoch 9/10, Batch 60/145, Loss: 0.0909
Epoch 9/10, Batch 70/145, Loss: 0.1878
Epoch 9/10, Batch 80/145, Loss: 0.0800
Epoch 9/10, Batch 90/145, Loss: 0.3405
Epoch 9/10, Batch 100/145, Loss: 0.1420
Epoch 9/10, Batch 110/145, Loss: 0.3034
Epoch 9/10, Batch 120/145, Loss: 0.0802
Epoch 9/10, Batch 130/145, Loss: 0.2272
Epoch 9/10, Batch 140/145, Loss: 0.4490
Epoch 9/10, Train Loss: 0.2067, Valid Loss: 0.2049
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1139
Epoch 10/10, Batch 20/145, Loss: 0.1840
Epoch 10/10, Batch 30/145, Loss: 0.2112
Epoch 10/10, Batch 40/145, Loss: 0.0730
Epoch 10/10, Batch 50/145, Loss: 0.1883
Epoch 10/10, Batch 60/145, Loss: 0.0634
Epoch 10/10, Batch 70/145, Loss: 0.3904
Epoch 10/10, Batch 80/145, Loss: 0.1925
Epoch 10/10, Batch 90/145, Loss: 0.2174
Epoch 10/10, Batch 100/145, Loss: 0.3431
Epoch 10/10, Batch 110/145, Loss: 0.1553
Epoch 10/10, Batch 120/145, Loss: 0.1958
Epoch 10/10, Batch 130/145, Loss: 0.1541
Epoch 10/10, Batch 140/145, Loss: 0.1714
Epoch 10/10, Train Loss: 0.1985, Valid Loss: 0.2003
Model saved!
Accuracy: 0.9229
Precision: 0.9203
Recall: 0.9229
F1-score: 0.9210
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3600
Epoch 1/10, Batch 20/145, Loss: 0.8995
Epoch 1/10, Batch 30/145, Loss: 0.8215
Epoch 1/10, Batch 40/145, Loss: 0.8607
Epoch 1/10, Batch 50/145, Loss: 0.7781
Epoch 1/10, Batch 60/145, Loss: 0.5640
Epoch 1/10, Batch 70/145, Loss: 0.5126
Epoch 1/10, Batch 80/145, Loss: 0.6280
Epoch 1/10, Batch 90/145, Loss: 0.6254
Epoch 1/10, Batch 100/145, Loss: 0.5820
Epoch 1/10, Batch 110/145, Loss: 0.4239
Epoch 1/10, Batch 120/145, Loss: 0.4849
Epoch 1/10, Batch 130/145, Loss: 0.7251
Epoch 1/10, Batch 140/145, Loss: 0.4750
Epoch 1/10, Train Loss: 0.6718, Valid Loss: 0.4000
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3717
Epoch 2/10, Batch 20/145, Loss: 0.3484
Epoch 2/10, Batch 30/145, Loss: 0.3717
Epoch 2/10, Batch 40/145, Loss: 0.4489
Epoch 2/10, Batch 50/145, Loss: 0.4419
Epoch 2/10, Batch 60/145, Loss: 0.4375
Epoch 2/10, Batch 70/145, Loss: 0.2756
Epoch 2/10, Batch 80/145, Loss: 0.2918
Epoch 2/10, Batch 90/145, Loss: 0.2030
Epoch 2/10, Batch 100/145, Loss: 0.1980
Epoch 2/10, Batch 110/145, Loss: 0.3477
Epoch 2/10, Batch 120/145, Loss: 0.2608
Epoch 2/10, Batch 130/145, Loss: 0.2749
Epoch 2/10, Batch 140/145, Loss: 0.2186
Epoch 2/10, Train Loss: 0.3499, Valid Loss: 0.3229
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3204
Epoch 3/10, Batch 20/145, Loss: 0.3647
Epoch 3/10, Batch 30/145, Loss: 0.4824
Epoch 3/10, Batch 40/145, Loss: 0.3048
Epoch 3/10, Batch 50/145, Loss: 0.2352
Epoch 3/10, Batch 60/145, Loss: 0.3003
Epoch 3/10, Batch 70/145, Loss: 0.3622
Epoch 3/10, Batch 80/145, Loss: 0.2832
Epoch 3/10, Batch 90/145, Loss: 0.3217
Epoch 3/10, Batch 100/145, Loss: 0.2466
Epoch 3/10, Batch 110/145, Loss: 0.2115
Epoch 3/10, Batch 120/145, Loss: 0.2062
Epoch 3/10, Batch 130/145, Loss: 0.3688
Epoch 3/10, Batch 140/145, Loss: 0.2080
Epoch 3/10, Train Loss: 0.2883, Valid Loss: 0.2884
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3389
Epoch 4/10, Batch 20/145, Loss: 0.3985
Epoch 4/10, Batch 30/145, Loss: 0.1813
Epoch 4/10, Batch 40/145, Loss: 0.1899
Epoch 4/10, Batch 50/145, Loss: 0.1742
Epoch 4/10, Batch 60/145, Loss: 0.2987
Epoch 4/10, Batch 70/145, Loss: 0.4103
Epoch 4/10, Batch 80/145, Loss: 0.3363
Epoch 4/10, Batch 90/145, Loss: 0.1852
Epoch 4/10, Batch 100/145, Loss: 0.3817
Epoch 4/10, Batch 110/145, Loss: 0.2160
Epoch 4/10, Batch 120/145, Loss: 0.2812
Epoch 4/10, Batch 130/145, Loss: 0.2818
Epoch 4/10, Batch 140/145, Loss: 0.2609
Epoch 4/10, Train Loss: 0.2612, Valid Loss: 0.2781
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1467
Epoch 5/10, Batch 20/145, Loss: 0.0812
Epoch 5/10, Batch 30/145, Loss: 0.2984
Epoch 5/10, Batch 40/145, Loss: 0.2210
Epoch 5/10, Batch 50/145, Loss: 0.1836
Epoch 5/10, Batch 60/145, Loss: 0.1794
Epoch 5/10, Batch 70/145, Loss: 0.1638
Epoch 5/10, Batch 80/145, Loss: 0.1228
Epoch 5/10, Batch 90/145, Loss: 0.3526
Epoch 5/10, Batch 100/145, Loss: 0.1763
Epoch 5/10, Batch 110/145, Loss: 0.0864
Epoch 5/10, Batch 120/145, Loss: 0.2587
Epoch 5/10, Batch 130/145, Loss: 0.2549
Epoch 5/10, Batch 140/145, Loss: 0.2524
Epoch 5/10, Train Loss: 0.2385, Valid Loss: 0.2726
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3236
Epoch 6/10, Batch 20/145, Loss: 0.3364
Epoch 6/10, Batch 30/145, Loss: 0.2926
Epoch 6/10, Batch 40/145, Loss: 0.2487
Epoch 6/10, Batch 50/145, Loss: 0.4272
Epoch 6/10, Batch 60/145, Loss: 0.1545
Epoch 6/10, Batch 70/145, Loss: 0.0791
Epoch 6/10, Batch 80/145, Loss: 0.1909
Epoch 6/10, Batch 90/145, Loss: 0.2015
Epoch 6/10, Batch 100/145, Loss: 0.2993
Epoch 6/10, Batch 110/145, Loss: 0.3494
Epoch 6/10, Batch 120/145, Loss: 0.2816
Epoch 6/10, Batch 130/145, Loss: 0.1303
Epoch 6/10, Batch 140/145, Loss: 0.1254
Epoch 6/10, Train Loss: 0.2266, Valid Loss: 0.2621
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3820
Epoch 7/10, Batch 20/145, Loss: 0.3042
Epoch 7/10, Batch 30/145, Loss: 0.1468
Epoch 7/10, Batch 40/145, Loss: 0.2476
Epoch 7/10, Batch 50/145, Loss: 0.1225
Epoch 7/10, Batch 60/145, Loss: 0.1836
Epoch 7/10, Batch 70/145, Loss: 0.1985
Epoch 7/10, Batch 80/145, Loss: 0.4247
Epoch 7/10, Batch 90/145, Loss: 0.1301
Epoch 7/10, Batch 100/145, Loss: 0.1772
Epoch 7/10, Batch 110/145, Loss: 0.1774
Epoch 7/10, Batch 120/145, Loss: 0.2276
Epoch 7/10, Batch 130/145, Loss: 0.0803
Epoch 7/10, Batch 140/145, Loss: 0.2480
Epoch 7/10, Train Loss: 0.2138, Valid Loss: 0.2542
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1625
Epoch 8/10, Batch 20/145, Loss: 0.3723
Epoch 8/10, Batch 30/145, Loss: 0.2030
Epoch 8/10, Batch 40/145, Loss: 0.1206
Epoch 8/10, Batch 50/145, Loss: 0.3641
Epoch 8/10, Batch 60/145, Loss: 0.1811
Epoch 8/10, Batch 70/145, Loss: 0.2998
Epoch 8/10, Batch 80/145, Loss: 0.2897
Epoch 8/10, Batch 90/145, Loss: 0.1323
Epoch 8/10, Batch 100/145, Loss: 0.1074
Epoch 8/10, Batch 110/145, Loss: 0.1851
Epoch 8/10, Batch 120/145, Loss: 0.2530
Epoch 8/10, Batch 130/145, Loss: 0.1765
Epoch 8/10, Batch 140/145, Loss: 0.1959
Epoch 8/10, Train Loss: 0.2076, Valid Loss: 0.2527
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1718
Epoch 9/10, Batch 20/145, Loss: 0.2406
Epoch 9/10, Batch 30/145, Loss: 0.1157
Epoch 9/10, Batch 40/145, Loss: 0.1969
Epoch 9/10, Batch 50/145, Loss: 0.1436
Epoch 9/10, Batch 60/145, Loss: 0.2917
Epoch 9/10, Batch 70/145, Loss: 0.2526
Epoch 9/10, Batch 80/145, Loss: 0.1033
Epoch 9/10, Batch 90/145, Loss: 0.3172
Epoch 9/10, Batch 100/145, Loss: 0.2082
Epoch 9/10, Batch 110/145, Loss: 0.3781
Epoch 9/10, Batch 120/145, Loss: 0.0584
Epoch 9/10, Batch 130/145, Loss: 0.1116
Epoch 9/10, Batch 140/145, Loss: 0.3574
Epoch 9/10, Train Loss: 0.1969, Valid Loss: 0.2520
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1273
Epoch 10/10, Batch 20/145, Loss: 0.0708
Epoch 10/10, Batch 30/145, Loss: 0.1143
Epoch 10/10, Batch 40/145, Loss: 0.2801
Epoch 10/10, Batch 50/145, Loss: 0.1640
Epoch 10/10, Batch 60/145, Loss: 0.2349
Epoch 10/10, Batch 70/145, Loss: 0.1200
Epoch 10/10, Batch 80/145, Loss: 0.1116
Epoch 10/10, Batch 90/145, Loss: 0.1427
Epoch 10/10, Batch 100/145, Loss: 0.1969
Epoch 10/10, Batch 110/145, Loss: 0.1849
Epoch 10/10, Batch 120/145, Loss: 0.1796
Epoch 10/10, Batch 130/145, Loss: 0.1243
Epoch 10/10, Batch 140/145, Loss: 0.1980
Epoch 10/10, Train Loss: 0.1968, Valid Loss: 0.2465
Model saved!
Accuracy: 0.9194
Precision: 0.9167
Recall: 0.9194
F1-score: 0.9169
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4224
Epoch 1/10, Batch 20/145, Loss: 0.9739
Epoch 1/10, Batch 30/145, Loss: 0.8494
Epoch 1/10, Batch 40/145, Loss: 0.8177
Epoch 1/10, Batch 50/145, Loss: 0.6424
Epoch 1/10, Batch 60/145, Loss: 0.6928
Epoch 1/10, Batch 70/145, Loss: 0.4532
Epoch 1/10, Batch 80/145, Loss: 0.7491
Epoch 1/10, Batch 90/145, Loss: 0.4527
Epoch 1/10, Batch 100/145, Loss: 0.5410
Epoch 1/10, Batch 110/145, Loss: 0.3728
Epoch 1/10, Batch 120/145, Loss: 0.5632
Epoch 1/10, Batch 130/145, Loss: 0.4781
Epoch 1/10, Batch 140/145, Loss: 0.3018
Epoch 1/10, Train Loss: 0.6811, Valid Loss: 0.3971
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4126
Epoch 2/10, Batch 20/145, Loss: 0.3782
Epoch 2/10, Batch 30/145, Loss: 0.3363
Epoch 2/10, Batch 40/145, Loss: 0.4463
Epoch 2/10, Batch 50/145, Loss: 0.3451
Epoch 2/10, Batch 60/145, Loss: 0.4127
Epoch 2/10, Batch 70/145, Loss: 0.3849
Epoch 2/10, Batch 80/145, Loss: 0.2855
Epoch 2/10, Batch 90/145, Loss: 0.2819
Epoch 2/10, Batch 100/145, Loss: 0.2980
Epoch 2/10, Batch 110/145, Loss: 0.3838
Epoch 2/10, Batch 120/145, Loss: 0.2430
Epoch 2/10, Batch 130/145, Loss: 0.3227
Epoch 2/10, Batch 140/145, Loss: 0.2658
Epoch 2/10, Train Loss: 0.3611, Valid Loss: 0.3041
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2535
Epoch 3/10, Batch 20/145, Loss: 0.2186
Epoch 3/10, Batch 30/145, Loss: 0.4970
Epoch 3/10, Batch 40/145, Loss: 0.2950
Epoch 3/10, Batch 50/145, Loss: 0.2281
Epoch 3/10, Batch 60/145, Loss: 0.4111
Epoch 3/10, Batch 70/145, Loss: 0.3889
Epoch 3/10, Batch 80/145, Loss: 0.2833
Epoch 3/10, Batch 90/145, Loss: 0.3123
Epoch 3/10, Batch 100/145, Loss: 0.3204
Epoch 3/10, Batch 110/145, Loss: 0.2151
Epoch 3/10, Batch 120/145, Loss: 0.3887
Epoch 3/10, Batch 130/145, Loss: 0.4107
Epoch 3/10, Batch 140/145, Loss: 0.3878
Epoch 3/10, Train Loss: 0.2962, Valid Loss: 0.2789
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3673
Epoch 4/10, Batch 20/145, Loss: 0.4067
Epoch 4/10, Batch 30/145, Loss: 0.2254
Epoch 4/10, Batch 40/145, Loss: 0.1855
Epoch 4/10, Batch 50/145, Loss: 0.1118
Epoch 4/10, Batch 60/145, Loss: 0.2214
Epoch 4/10, Batch 70/145, Loss: 0.2875
Epoch 4/10, Batch 80/145, Loss: 0.2636
Epoch 4/10, Batch 90/145, Loss: 0.3122
Epoch 4/10, Batch 100/145, Loss: 0.2593
Epoch 4/10, Batch 110/145, Loss: 0.1048
Epoch 4/10, Batch 120/145, Loss: 0.2066
Epoch 4/10, Batch 130/145, Loss: 0.2545
Epoch 4/10, Batch 140/145, Loss: 0.2032
Epoch 4/10, Train Loss: 0.2645, Valid Loss: 0.2687
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2755
Epoch 5/10, Batch 20/145, Loss: 0.1614
Epoch 5/10, Batch 30/145, Loss: 0.3489
Epoch 5/10, Batch 40/145, Loss: 0.1549
Epoch 5/10, Batch 50/145, Loss: 0.2347
Epoch 5/10, Batch 60/145, Loss: 0.4632
Epoch 5/10, Batch 70/145, Loss: 0.1787
Epoch 5/10, Batch 80/145, Loss: 0.2244
Epoch 5/10, Batch 90/145, Loss: 0.3474
Epoch 5/10, Batch 100/145, Loss: 0.2748
Epoch 5/10, Batch 110/145, Loss: 0.1754
Epoch 5/10, Batch 120/145, Loss: 0.3220
Epoch 5/10, Batch 130/145, Loss: 0.1791
Epoch 5/10, Batch 140/145, Loss: 0.2426
Epoch 5/10, Train Loss: 0.2445, Valid Loss: 0.2559
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1449
Epoch 6/10, Batch 20/145, Loss: 0.3503
Epoch 6/10, Batch 30/145, Loss: 0.2458
Epoch 6/10, Batch 40/145, Loss: 0.2083
Epoch 6/10, Batch 50/145, Loss: 0.3549
Epoch 6/10, Batch 60/145, Loss: 0.3155
Epoch 6/10, Batch 70/145, Loss: 0.1630
Epoch 6/10, Batch 80/145, Loss: 0.1527
Epoch 6/10, Batch 90/145, Loss: 0.2861
Epoch 6/10, Batch 100/145, Loss: 0.3449
Epoch 6/10, Batch 110/145, Loss: 0.2420
Epoch 6/10, Batch 120/145, Loss: 0.3086
Epoch 6/10, Batch 130/145, Loss: 0.2445
Epoch 6/10, Batch 140/145, Loss: 0.1306
Epoch 6/10, Train Loss: 0.2339, Valid Loss: 0.2471
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1853
Epoch 7/10, Batch 20/145, Loss: 0.3384
Epoch 7/10, Batch 30/145, Loss: 0.2439
Epoch 7/10, Batch 40/145, Loss: 0.2662
Epoch 7/10, Batch 50/145, Loss: 0.1495
Epoch 7/10, Batch 60/145, Loss: 0.2126
Epoch 7/10, Batch 70/145, Loss: 0.1669
Epoch 7/10, Batch 80/145, Loss: 0.4882
Epoch 7/10, Batch 90/145, Loss: 0.2821
Epoch 7/10, Batch 100/145, Loss: 0.1875
Epoch 7/10, Batch 110/145, Loss: 0.1883
Epoch 7/10, Batch 120/145, Loss: 0.1113
Epoch 7/10, Batch 130/145, Loss: 0.1497
Epoch 7/10, Batch 140/145, Loss: 0.2275
Epoch 7/10, Train Loss: 0.2189, Valid Loss: 0.2457
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2416
Epoch 8/10, Batch 20/145, Loss: 0.2298
Epoch 8/10, Batch 30/145, Loss: 0.1201
Epoch 8/10, Batch 40/145, Loss: 0.2563
Epoch 8/10, Batch 50/145, Loss: 0.2626
Epoch 8/10, Batch 60/145, Loss: 0.2539
Epoch 8/10, Batch 70/145, Loss: 0.2079
Epoch 8/10, Batch 80/145, Loss: 0.2255
Epoch 8/10, Batch 90/145, Loss: 0.2777
Epoch 8/10, Batch 100/145, Loss: 0.0939
Epoch 8/10, Batch 110/145, Loss: 0.2810
Epoch 8/10, Batch 120/145, Loss: 0.1880
Epoch 8/10, Batch 130/145, Loss: 0.1637
Epoch 8/10, Batch 140/145, Loss: 0.2585
Epoch 8/10, Train Loss: 0.2156, Valid Loss: 0.2419
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3683
Epoch 9/10, Batch 20/145, Loss: 0.2516
Epoch 9/10, Batch 30/145, Loss: 0.3007
Epoch 9/10, Batch 40/145, Loss: 0.2457
Epoch 9/10, Batch 50/145, Loss: 0.1129
Epoch 9/10, Batch 60/145, Loss: 0.2224
Epoch 9/10, Batch 70/145, Loss: 0.0905
Epoch 9/10, Batch 80/145, Loss: 0.1124
Epoch 9/10, Batch 90/145, Loss: 0.1560
Epoch 9/10, Batch 100/145, Loss: 0.1129
Epoch 9/10, Batch 110/145, Loss: 0.2128
Epoch 9/10, Batch 120/145, Loss: 0.1430
Epoch 9/10, Batch 130/145, Loss: 0.1627
Epoch 9/10, Batch 140/145, Loss: 0.1728
Epoch 9/10, Train Loss: 0.2033, Valid Loss: 0.2370
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1555
Epoch 10/10, Batch 20/145, Loss: 0.1188
Epoch 10/10, Batch 30/145, Loss: 0.1031
Epoch 10/10, Batch 40/145, Loss: 0.1451
Epoch 10/10, Batch 50/145, Loss: 0.1910
Epoch 10/10, Batch 60/145, Loss: 0.1191
Epoch 10/10, Batch 70/145, Loss: 0.4895
Epoch 10/10, Batch 80/145, Loss: 0.2416
Epoch 10/10, Batch 90/145, Loss: 0.1935
Epoch 10/10, Batch 100/145, Loss: 0.1797
Epoch 10/10, Batch 110/145, Loss: 0.1492
Epoch 10/10, Batch 120/145, Loss: 0.1845
Epoch 10/10, Batch 130/145, Loss: 0.1448
Epoch 10/10, Batch 140/145, Loss: 0.3946
Epoch 10/10, Train Loss: 0.1946, Valid Loss: 0.2375
Accuracy: 0.9229
Precision: 0.9216
Recall: 0.9229
F1-score: 0.9221
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4459
Epoch 1/10, Batch 20/145, Loss: 0.9640
Epoch 1/10, Batch 30/145, Loss: 0.9254
Epoch 1/10, Batch 40/145, Loss: 0.8287
Epoch 1/10, Batch 50/145, Loss: 0.7370
Epoch 1/10, Batch 60/145, Loss: 0.6495
Epoch 1/10, Batch 70/145, Loss: 0.5270
Epoch 1/10, Batch 80/145, Loss: 0.5408
Epoch 1/10, Batch 90/145, Loss: 0.3758
Epoch 1/10, Batch 100/145, Loss: 0.5693
Epoch 1/10, Batch 110/145, Loss: 0.3327
Epoch 1/10, Batch 120/145, Loss: 0.5452
Epoch 1/10, Batch 130/145, Loss: 0.5541
Epoch 1/10, Batch 140/145, Loss: 0.4619
Epoch 1/10, Train Loss: 0.6858, Valid Loss: 0.3638
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4908
Epoch 2/10, Batch 20/145, Loss: 0.5548
Epoch 2/10, Batch 30/145, Loss: 0.3897
Epoch 2/10, Batch 40/145, Loss: 0.4638
Epoch 2/10, Batch 50/145, Loss: 0.4031
Epoch 2/10, Batch 60/145, Loss: 0.4485
Epoch 2/10, Batch 70/145, Loss: 0.2003
Epoch 2/10, Batch 80/145, Loss: 0.3111
Epoch 2/10, Batch 90/145, Loss: 0.2983
Epoch 2/10, Batch 100/145, Loss: 0.2684
Epoch 2/10, Batch 110/145, Loss: 0.3587
Epoch 2/10, Batch 120/145, Loss: 0.3892
Epoch 2/10, Batch 130/145, Loss: 0.3517
Epoch 2/10, Batch 140/145, Loss: 0.3472
Epoch 2/10, Train Loss: 0.3633, Valid Loss: 0.2847
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3213
Epoch 3/10, Batch 20/145, Loss: 0.2464
Epoch 3/10, Batch 30/145, Loss: 0.4056
Epoch 3/10, Batch 40/145, Loss: 0.2652
Epoch 3/10, Batch 50/145, Loss: 0.2859
Epoch 3/10, Batch 60/145, Loss: 0.2714
Epoch 3/10, Batch 70/145, Loss: 0.3761
Epoch 3/10, Batch 80/145, Loss: 0.2804
Epoch 3/10, Batch 90/145, Loss: 0.2370
Epoch 3/10, Batch 100/145, Loss: 0.2564
Epoch 3/10, Batch 110/145, Loss: 0.1297
Epoch 3/10, Batch 120/145, Loss: 0.3247
Epoch 3/10, Batch 130/145, Loss: 0.4593
Epoch 3/10, Batch 140/145, Loss: 0.2470
Epoch 3/10, Train Loss: 0.2924, Valid Loss: 0.2529
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4252
Epoch 4/10, Batch 20/145, Loss: 0.3059
Epoch 4/10, Batch 30/145, Loss: 0.3283
Epoch 4/10, Batch 40/145, Loss: 0.2839
Epoch 4/10, Batch 50/145, Loss: 0.4005
Epoch 4/10, Batch 60/145, Loss: 0.3308
Epoch 4/10, Batch 70/145, Loss: 0.2745
Epoch 4/10, Batch 80/145, Loss: 0.2819
Epoch 4/10, Batch 90/145, Loss: 0.2634
Epoch 4/10, Batch 100/145, Loss: 0.3066
Epoch 4/10, Batch 110/145, Loss: 0.1863
Epoch 4/10, Batch 120/145, Loss: 0.1236
Epoch 4/10, Batch 130/145, Loss: 0.1376
Epoch 4/10, Batch 140/145, Loss: 0.1610
Epoch 4/10, Train Loss: 0.2623, Valid Loss: 0.2438
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1997
Epoch 5/10, Batch 20/145, Loss: 0.1980
Epoch 5/10, Batch 30/145, Loss: 0.2416
Epoch 5/10, Batch 40/145, Loss: 0.1472
Epoch 5/10, Batch 50/145, Loss: 0.2341
Epoch 5/10, Batch 60/145, Loss: 0.2347
Epoch 5/10, Batch 70/145, Loss: 0.1708
Epoch 5/10, Batch 80/145, Loss: 0.2419
Epoch 5/10, Batch 90/145, Loss: 0.3841
Epoch 5/10, Batch 100/145, Loss: 0.1672
Epoch 5/10, Batch 110/145, Loss: 0.1132
Epoch 5/10, Batch 120/145, Loss: 0.2914
Epoch 5/10, Batch 130/145, Loss: 0.2148
Epoch 5/10, Batch 140/145, Loss: 0.1458
Epoch 5/10, Train Loss: 0.2476, Valid Loss: 0.2341
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3643
Epoch 6/10, Batch 20/145, Loss: 0.4145
Epoch 6/10, Batch 30/145, Loss: 0.2152
Epoch 6/10, Batch 40/145, Loss: 0.2681
Epoch 6/10, Batch 50/145, Loss: 0.3382
Epoch 6/10, Batch 60/145, Loss: 0.1436
Epoch 6/10, Batch 70/145, Loss: 0.1127
Epoch 6/10, Batch 80/145, Loss: 0.1071
Epoch 6/10, Batch 90/145, Loss: 0.2433
Epoch 6/10, Batch 100/145, Loss: 0.3489
Epoch 6/10, Batch 110/145, Loss: 0.2950
Epoch 6/10, Batch 120/145, Loss: 0.1688
Epoch 6/10, Batch 130/145, Loss: 0.1276
Epoch 6/10, Batch 140/145, Loss: 0.1220
Epoch 6/10, Train Loss: 0.2311, Valid Loss: 0.2289
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3031
Epoch 7/10, Batch 20/145, Loss: 0.2103
Epoch 7/10, Batch 30/145, Loss: 0.2221
Epoch 7/10, Batch 40/145, Loss: 0.3048
Epoch 7/10, Batch 50/145, Loss: 0.3309
Epoch 7/10, Batch 60/145, Loss: 0.1418
Epoch 7/10, Batch 70/145, Loss: 0.1377
Epoch 7/10, Batch 80/145, Loss: 0.3212
Epoch 7/10, Batch 90/145, Loss: 0.1540
Epoch 7/10, Batch 100/145, Loss: 0.2030
Epoch 7/10, Batch 110/145, Loss: 0.3354
Epoch 7/10, Batch 120/145, Loss: 0.3413
Epoch 7/10, Batch 130/145, Loss: 0.1268
Epoch 7/10, Batch 140/145, Loss: 0.3417
Epoch 7/10, Train Loss: 0.2176, Valid Loss: 0.2149
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2586
Epoch 8/10, Batch 20/145, Loss: 0.1514
Epoch 8/10, Batch 30/145, Loss: 0.2346
Epoch 8/10, Batch 40/145, Loss: 0.1657
Epoch 8/10, Batch 50/145, Loss: 0.1753
Epoch 8/10, Batch 60/145, Loss: 0.1686
Epoch 8/10, Batch 70/145, Loss: 0.3410
Epoch 8/10, Batch 80/145, Loss: 0.1867
Epoch 8/10, Batch 90/145, Loss: 0.3150
Epoch 8/10, Batch 100/145, Loss: 0.2738
Epoch 8/10, Batch 110/145, Loss: 0.3966
Epoch 8/10, Batch 120/145, Loss: 0.2125
Epoch 8/10, Batch 130/145, Loss: 0.2204
Epoch 8/10, Batch 140/145, Loss: 0.1959
Epoch 8/10, Train Loss: 0.2089, Valid Loss: 0.2161
Epoch 9/10, Batch 10/145, Loss: 0.2256
Epoch 9/10, Batch 20/145, Loss: 0.1091
Epoch 9/10, Batch 30/145, Loss: 0.1197
Epoch 9/10, Batch 40/145, Loss: 0.1874
Epoch 9/10, Batch 50/145, Loss: 0.1431
Epoch 9/10, Batch 60/145, Loss: 0.2812
Epoch 9/10, Batch 70/145, Loss: 0.2067
Epoch 9/10, Batch 80/145, Loss: 0.0964
Epoch 9/10, Batch 90/145, Loss: 0.2094
Epoch 9/10, Batch 100/145, Loss: 0.2278
Epoch 9/10, Batch 110/145, Loss: 0.2919
Epoch 9/10, Batch 120/145, Loss: 0.1159
Epoch 9/10, Batch 130/145, Loss: 0.3089
Epoch 9/10, Batch 140/145, Loss: 0.3066
Epoch 9/10, Train Loss: 0.2029, Valid Loss: 0.2143
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1711
Epoch 10/10, Batch 20/145, Loss: 0.2008
Epoch 10/10, Batch 30/145, Loss: 0.1006
Epoch 10/10, Batch 40/145, Loss: 0.1208
Epoch 10/10, Batch 50/145, Loss: 0.2014
Epoch 10/10, Batch 60/145, Loss: 0.1585
Epoch 10/10, Batch 70/145, Loss: 0.3897
Epoch 10/10, Batch 80/145, Loss: 0.2171
Epoch 10/10, Batch 90/145, Loss: 0.1562
Epoch 10/10, Batch 100/145, Loss: 0.0899
Epoch 10/10, Batch 110/145, Loss: 0.2444
Epoch 10/10, Batch 120/145, Loss: 0.2593
Epoch 10/10, Batch 130/145, Loss: 0.1744
Epoch 10/10, Batch 140/145, Loss: 0.2556
Epoch 10/10, Train Loss: 0.1984, Valid Loss: 0.2136
Model saved!
Accuracy: 0.9136
Precision: 0.9103
Recall: 0.9136
F1-score: 0.9111
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4513
Epoch 1/10, Batch 20/145, Loss: 0.9260
Epoch 1/10, Batch 30/145, Loss: 0.8904
Epoch 1/10, Batch 40/145, Loss: 0.9487
Epoch 1/10, Batch 50/145, Loss: 0.6326
Epoch 1/10, Batch 60/145, Loss: 0.6271
Epoch 1/10, Batch 70/145, Loss: 0.4287
Epoch 1/10, Batch 80/145, Loss: 0.5962
Epoch 1/10, Batch 90/145, Loss: 0.3991
Epoch 1/10, Batch 100/145, Loss: 0.5373
Epoch 1/10, Batch 110/145, Loss: 0.4845
Epoch 1/10, Batch 120/145, Loss: 0.4431
Epoch 1/10, Batch 130/145, Loss: 0.4839
Epoch 1/10, Batch 140/145, Loss: 0.4018
Epoch 1/10, Train Loss: 0.6678, Valid Loss: 0.4001
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2622
Epoch 2/10, Batch 20/145, Loss: 0.3311
Epoch 2/10, Batch 30/145, Loss: 0.3631
Epoch 2/10, Batch 40/145, Loss: 0.3727
Epoch 2/10, Batch 50/145, Loss: 0.4379
Epoch 2/10, Batch 60/145, Loss: 0.3238
Epoch 2/10, Batch 70/145, Loss: 0.3725
Epoch 2/10, Batch 80/145, Loss: 0.2872
Epoch 2/10, Batch 90/145, Loss: 0.2059
Epoch 2/10, Batch 100/145, Loss: 0.3375
Epoch 2/10, Batch 110/145, Loss: 0.3242
Epoch 2/10, Batch 120/145, Loss: 0.2385
Epoch 2/10, Batch 130/145, Loss: 0.3234
Epoch 2/10, Batch 140/145, Loss: 0.2957
Epoch 2/10, Train Loss: 0.3428, Valid Loss: 0.3180
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2637
Epoch 3/10, Batch 20/145, Loss: 0.2345
Epoch 3/10, Batch 30/145, Loss: 0.3693
Epoch 3/10, Batch 40/145, Loss: 0.2937
Epoch 3/10, Batch 50/145, Loss: 0.2453
Epoch 3/10, Batch 60/145, Loss: 0.2544
Epoch 3/10, Batch 70/145, Loss: 0.4186
Epoch 3/10, Batch 80/145, Loss: 0.2556
Epoch 3/10, Batch 90/145, Loss: 0.2466
Epoch 3/10, Batch 100/145, Loss: 0.2207
Epoch 3/10, Batch 110/145, Loss: 0.3215
Epoch 3/10, Batch 120/145, Loss: 0.1863
Epoch 3/10, Batch 130/145, Loss: 0.3090
Epoch 3/10, Batch 140/145, Loss: 0.2177
Epoch 3/10, Train Loss: 0.2818, Valid Loss: 0.2884
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3326
Epoch 4/10, Batch 20/145, Loss: 0.3731
Epoch 4/10, Batch 30/145, Loss: 0.1900
Epoch 4/10, Batch 40/145, Loss: 0.2287
Epoch 4/10, Batch 50/145, Loss: 0.1514
Epoch 4/10, Batch 60/145, Loss: 0.2259
Epoch 4/10, Batch 70/145, Loss: 0.1567
Epoch 4/10, Batch 80/145, Loss: 0.2094
Epoch 4/10, Batch 90/145, Loss: 0.3090
Epoch 4/10, Batch 100/145, Loss: 0.3182
Epoch 4/10, Batch 110/145, Loss: 0.1230
Epoch 4/10, Batch 120/145, Loss: 0.2426
Epoch 4/10, Batch 130/145, Loss: 0.2467
Epoch 4/10, Batch 140/145, Loss: 0.0864
Epoch 4/10, Train Loss: 0.2475, Valid Loss: 0.2862
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1931
Epoch 5/10, Batch 20/145, Loss: 0.1399
Epoch 5/10, Batch 30/145, Loss: 0.3609
Epoch 5/10, Batch 40/145, Loss: 0.1309
Epoch 5/10, Batch 50/145, Loss: 0.2422
Epoch 5/10, Batch 60/145, Loss: 0.2128
Epoch 5/10, Batch 70/145, Loss: 0.2092
Epoch 5/10, Batch 80/145, Loss: 0.2307
Epoch 5/10, Batch 90/145, Loss: 0.2534
Epoch 5/10, Batch 100/145, Loss: 0.1262
Epoch 5/10, Batch 110/145, Loss: 0.2558
Epoch 5/10, Batch 120/145, Loss: 0.2337
Epoch 5/10, Batch 130/145, Loss: 0.3086
Epoch 5/10, Batch 140/145, Loss: 0.2251
Epoch 5/10, Train Loss: 0.2357, Valid Loss: 0.2749
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2325
Epoch 6/10, Batch 20/145, Loss: 0.3741
Epoch 6/10, Batch 30/145, Loss: 0.4642
Epoch 6/10, Batch 40/145, Loss: 0.1941
Epoch 6/10, Batch 50/145, Loss: 0.3363
Epoch 6/10, Batch 60/145, Loss: 0.1674
Epoch 6/10, Batch 70/145, Loss: 0.1036
Epoch 6/10, Batch 80/145, Loss: 0.2053
Epoch 6/10, Batch 90/145, Loss: 0.2838
Epoch 6/10, Batch 100/145, Loss: 0.2519
Epoch 6/10, Batch 110/145, Loss: 0.2196
Epoch 6/10, Batch 120/145, Loss: 0.1870
Epoch 6/10, Batch 130/145, Loss: 0.1628
Epoch 6/10, Batch 140/145, Loss: 0.1493
Epoch 6/10, Train Loss: 0.2212, Valid Loss: 0.2591
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1369
Epoch 7/10, Batch 20/145, Loss: 0.2575
Epoch 7/10, Batch 30/145, Loss: 0.3036
Epoch 7/10, Batch 40/145, Loss: 0.2895
Epoch 7/10, Batch 50/145, Loss: 0.2191
Epoch 7/10, Batch 60/145, Loss: 0.1171
Epoch 7/10, Batch 70/145, Loss: 0.1412
Epoch 7/10, Batch 80/145, Loss: 0.4903
Epoch 7/10, Batch 90/145, Loss: 0.2913
Epoch 7/10, Batch 100/145, Loss: 0.3028
Epoch 7/10, Batch 110/145, Loss: 0.1608
Epoch 7/10, Batch 120/145, Loss: 0.1901
Epoch 7/10, Batch 130/145, Loss: 0.1802
Epoch 7/10, Batch 140/145, Loss: 0.4465
Epoch 7/10, Train Loss: 0.2026, Valid Loss: 0.2604
Epoch 8/10, Batch 10/145, Loss: 0.1531
Epoch 8/10, Batch 20/145, Loss: 0.2260
Epoch 8/10, Batch 30/145, Loss: 0.1500
Epoch 8/10, Batch 40/145, Loss: 0.2992
Epoch 8/10, Batch 50/145, Loss: 0.2495
Epoch 8/10, Batch 60/145, Loss: 0.2196
Epoch 8/10, Batch 70/145, Loss: 0.2226
Epoch 8/10, Batch 80/145, Loss: 0.2460
Epoch 8/10, Batch 90/145, Loss: 0.4366
Epoch 8/10, Batch 100/145, Loss: 0.1895
Epoch 8/10, Batch 110/145, Loss: 0.2508
Epoch 8/10, Batch 120/145, Loss: 0.4399
Epoch 8/10, Batch 130/145, Loss: 0.2068
Epoch 8/10, Batch 140/145, Loss: 0.2688
Epoch 8/10, Train Loss: 0.1957, Valid Loss: 0.2601
Epoch 9/10, Batch 10/145, Loss: 0.3029
Epoch 9/10, Batch 20/145, Loss: 0.3268
Epoch 9/10, Batch 30/145, Loss: 0.1589
Epoch 9/10, Batch 40/145, Loss: 0.2214
Epoch 9/10, Batch 50/145, Loss: 0.2698
Epoch 9/10, Batch 60/145, Loss: 0.1527
Epoch 9/10, Batch 70/145, Loss: 0.1371
Epoch 9/10, Batch 80/145, Loss: 0.0975
Epoch 9/10, Batch 90/145, Loss: 0.2732
Epoch 9/10, Batch 100/145, Loss: 0.1099
Epoch 9/10, Batch 110/145, Loss: 0.1403
Epoch 9/10, Batch 120/145, Loss: 0.0683
Epoch 9/10, Batch 130/145, Loss: 0.3202
Epoch 9/10, Batch 140/145, Loss: 0.1526
Epoch 9/10, Train Loss: 0.1891, Valid Loss: 0.2549
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0975
Epoch 10/10, Batch 20/145, Loss: 0.2037
Epoch 10/10, Batch 30/145, Loss: 0.1258
Epoch 10/10, Batch 40/145, Loss: 0.2300
Epoch 10/10, Batch 50/145, Loss: 0.2646
Epoch 10/10, Batch 60/145, Loss: 0.1182
Epoch 10/10, Batch 70/145, Loss: 0.1862
Epoch 10/10, Batch 80/145, Loss: 0.2676
Epoch 10/10, Batch 90/145, Loss: 0.1715
Epoch 10/10, Batch 100/145, Loss: 0.1902
Epoch 10/10, Batch 110/145, Loss: 0.2279
Epoch 10/10, Batch 120/145, Loss: 0.2297
Epoch 10/10, Batch 130/145, Loss: 0.1471
Epoch 10/10, Batch 140/145, Loss: 0.2113
Epoch 10/10, Train Loss: 0.1850, Valid Loss: 0.2525
Model saved!
Accuracy: 0.9159
Precision: 0.9126
Recall: 0.9159
F1-score: 0.9129
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4144
Epoch 1/10, Batch 20/145, Loss: 0.9603
Epoch 1/10, Batch 30/145, Loss: 0.9091
Epoch 1/10, Batch 40/145, Loss: 0.8585
Epoch 1/10, Batch 50/145, Loss: 0.6679
Epoch 1/10, Batch 60/145, Loss: 0.5241
Epoch 1/10, Batch 70/145, Loss: 0.4566
Epoch 1/10, Batch 80/145, Loss: 0.6002
Epoch 1/10, Batch 90/145, Loss: 0.4514
Epoch 1/10, Batch 100/145, Loss: 0.6384
Epoch 1/10, Batch 110/145, Loss: 0.4184
Epoch 1/10, Batch 120/145, Loss: 0.4636
Epoch 1/10, Batch 130/145, Loss: 0.4516
Epoch 1/10, Batch 140/145, Loss: 0.3669
Epoch 1/10, Train Loss: 0.6820, Valid Loss: 0.3876
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3094
Epoch 2/10, Batch 20/145, Loss: 0.3946
Epoch 2/10, Batch 30/145, Loss: 0.3329
Epoch 2/10, Batch 40/145, Loss: 0.4229
Epoch 2/10, Batch 50/145, Loss: 0.3335
Epoch 2/10, Batch 60/145, Loss: 0.4999
Epoch 2/10, Batch 70/145, Loss: 0.4694
Epoch 2/10, Batch 80/145, Loss: 0.4015
Epoch 2/10, Batch 90/145, Loss: 0.5304
Epoch 2/10, Batch 100/145, Loss: 0.2544
Epoch 2/10, Batch 110/145, Loss: 0.3282
Epoch 2/10, Batch 120/145, Loss: 0.3953
Epoch 2/10, Batch 130/145, Loss: 0.2703
Epoch 2/10, Batch 140/145, Loss: 0.1999
Epoch 2/10, Train Loss: 0.3574, Valid Loss: 0.3008
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2768
Epoch 3/10, Batch 20/145, Loss: 0.3624
Epoch 3/10, Batch 30/145, Loss: 0.3298
Epoch 3/10, Batch 40/145, Loss: 0.2745
Epoch 3/10, Batch 50/145, Loss: 0.2877
Epoch 3/10, Batch 60/145, Loss: 0.3473
Epoch 3/10, Batch 70/145, Loss: 0.4366
Epoch 3/10, Batch 80/145, Loss: 0.3278
Epoch 3/10, Batch 90/145, Loss: 0.3579
Epoch 3/10, Batch 100/145, Loss: 0.1942
Epoch 3/10, Batch 110/145, Loss: 0.1355
Epoch 3/10, Batch 120/145, Loss: 0.1434
Epoch 3/10, Batch 130/145, Loss: 0.4104
Epoch 3/10, Batch 140/145, Loss: 0.2478
Epoch 3/10, Train Loss: 0.2984, Valid Loss: 0.2715
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2971
Epoch 4/10, Batch 20/145, Loss: 0.3725
Epoch 4/10, Batch 30/145, Loss: 0.3103
Epoch 4/10, Batch 40/145, Loss: 0.1922
Epoch 4/10, Batch 50/145, Loss: 0.1481
Epoch 4/10, Batch 60/145, Loss: 0.4916
Epoch 4/10, Batch 70/145, Loss: 0.1815
Epoch 4/10, Batch 80/145, Loss: 0.2330
Epoch 4/10, Batch 90/145, Loss: 0.2075
Epoch 4/10, Batch 100/145, Loss: 0.4180
Epoch 4/10, Batch 110/145, Loss: 0.1434
Epoch 4/10, Batch 120/145, Loss: 0.1067
Epoch 4/10, Batch 130/145, Loss: 0.1194
Epoch 4/10, Batch 140/145, Loss: 0.2253
Epoch 4/10, Train Loss: 0.2591, Valid Loss: 0.2577
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2865
Epoch 5/10, Batch 20/145, Loss: 0.3358
Epoch 5/10, Batch 30/145, Loss: 0.3011
Epoch 5/10, Batch 40/145, Loss: 0.2040
Epoch 5/10, Batch 50/145, Loss: 0.2768
Epoch 5/10, Batch 60/145, Loss: 0.2336
Epoch 5/10, Batch 70/145, Loss: 0.2061
Epoch 5/10, Batch 80/145, Loss: 0.2362
Epoch 5/10, Batch 90/145, Loss: 0.3582
Epoch 5/10, Batch 100/145, Loss: 0.1433
Epoch 5/10, Batch 110/145, Loss: 0.2783
Epoch 5/10, Batch 120/145, Loss: 0.3048
Epoch 5/10, Batch 130/145, Loss: 0.1705
Epoch 5/10, Batch 140/145, Loss: 0.1187
Epoch 5/10, Train Loss: 0.2499, Valid Loss: 0.2502
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2309
Epoch 6/10, Batch 20/145, Loss: 0.3175
Epoch 6/10, Batch 30/145, Loss: 0.2137
Epoch 6/10, Batch 40/145, Loss: 0.1757
Epoch 6/10, Batch 50/145, Loss: 0.1809
Epoch 6/10, Batch 60/145, Loss: 0.1162
Epoch 6/10, Batch 70/145, Loss: 0.1092
Epoch 6/10, Batch 80/145, Loss: 0.1801
Epoch 6/10, Batch 90/145, Loss: 0.1576
Epoch 6/10, Batch 100/145, Loss: 0.1510
Epoch 6/10, Batch 110/145, Loss: 0.2215
Epoch 6/10, Batch 120/145, Loss: 0.3061
Epoch 6/10, Batch 130/145, Loss: 0.1639
Epoch 6/10, Batch 140/145, Loss: 0.2524
Epoch 6/10, Train Loss: 0.2284, Valid Loss: 0.2359
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2159
Epoch 7/10, Batch 20/145, Loss: 0.3490
Epoch 7/10, Batch 30/145, Loss: 0.1651
Epoch 7/10, Batch 40/145, Loss: 0.3713
Epoch 7/10, Batch 50/145, Loss: 0.1792
Epoch 7/10, Batch 60/145, Loss: 0.2209
Epoch 7/10, Batch 70/145, Loss: 0.0751
Epoch 7/10, Batch 80/145, Loss: 0.3918
Epoch 7/10, Batch 90/145, Loss: 0.1159
Epoch 7/10, Batch 100/145, Loss: 0.1738
Epoch 7/10, Batch 110/145, Loss: 0.1217
Epoch 7/10, Batch 120/145, Loss: 0.2449
Epoch 7/10, Batch 130/145, Loss: 0.1111
Epoch 7/10, Batch 140/145, Loss: 0.2585
Epoch 7/10, Train Loss: 0.2166, Valid Loss: 0.2284
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2098
Epoch 8/10, Batch 20/145, Loss: 0.2080
Epoch 8/10, Batch 30/145, Loss: 0.3044
Epoch 8/10, Batch 40/145, Loss: 0.1726
Epoch 8/10, Batch 50/145, Loss: 0.1901
Epoch 8/10, Batch 60/145, Loss: 0.2009
Epoch 8/10, Batch 70/145, Loss: 0.3310
Epoch 8/10, Batch 80/145, Loss: 0.2731
Epoch 8/10, Batch 90/145, Loss: 0.3168
Epoch 8/10, Batch 100/145, Loss: 0.1824
Epoch 8/10, Batch 110/145, Loss: 0.3682
Epoch 8/10, Batch 120/145, Loss: 0.1491
Epoch 8/10, Batch 130/145, Loss: 0.1617
Epoch 8/10, Batch 140/145, Loss: 0.2846
Epoch 8/10, Train Loss: 0.2072, Valid Loss: 0.2247
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2153
Epoch 9/10, Batch 20/145, Loss: 0.0818
Epoch 9/10, Batch 30/145, Loss: 0.1035
Epoch 9/10, Batch 40/145, Loss: 0.2101
Epoch 9/10, Batch 50/145, Loss: 0.1872
Epoch 9/10, Batch 60/145, Loss: 0.2686
Epoch 9/10, Batch 70/145, Loss: 0.2338
Epoch 9/10, Batch 80/145, Loss: 0.1891
Epoch 9/10, Batch 90/145, Loss: 0.1473
Epoch 9/10, Batch 100/145, Loss: 0.1353
Epoch 9/10, Batch 110/145, Loss: 0.4567
Epoch 9/10, Batch 120/145, Loss: 0.0656
Epoch 9/10, Batch 130/145, Loss: 0.1092
Epoch 9/10, Batch 140/145, Loss: 0.2963
Epoch 9/10, Train Loss: 0.1989, Valid Loss: 0.2230
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1252
Epoch 10/10, Batch 20/145, Loss: 0.2560
Epoch 10/10, Batch 30/145, Loss: 0.1129
Epoch 10/10, Batch 40/145, Loss: 0.1305
Epoch 10/10, Batch 50/145, Loss: 0.2738
Epoch 10/10, Batch 60/145, Loss: 0.1936
Epoch 10/10, Batch 70/145, Loss: 0.4166
Epoch 10/10, Batch 80/145, Loss: 0.2250
Epoch 10/10, Batch 90/145, Loss: 0.2127
Epoch 10/10, Batch 100/145, Loss: 0.1553
Epoch 10/10, Batch 110/145, Loss: 0.0679
Epoch 10/10, Batch 120/145, Loss: 0.2555
Epoch 10/10, Batch 130/145, Loss: 0.1546
Epoch 10/10, Batch 140/145, Loss: 0.1700
Epoch 10/10, Train Loss: 0.1989, Valid Loss: 0.2270
Accuracy: 0.9182
Precision: 0.9186
Recall: 0.9182
F1-score: 0.9177
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4270
Epoch 1/10, Batch 20/145, Loss: 1.0429
Epoch 1/10, Batch 30/145, Loss: 0.9317
Epoch 1/10, Batch 40/145, Loss: 0.8704
Epoch 1/10, Batch 50/145, Loss: 0.8651
Epoch 1/10, Batch 60/145, Loss: 0.6912
Epoch 1/10, Batch 70/145, Loss: 0.5017
Epoch 1/10, Batch 80/145, Loss: 0.6587
Epoch 1/10, Batch 90/145, Loss: 0.4189
Epoch 1/10, Batch 100/145, Loss: 0.4041
Epoch 1/10, Batch 110/145, Loss: 0.4037
Epoch 1/10, Batch 120/145, Loss: 0.5976
Epoch 1/10, Batch 130/145, Loss: 0.6220
Epoch 1/10, Batch 140/145, Loss: 0.3437
Epoch 1/10, Train Loss: 0.6832, Valid Loss: 0.3682
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3310
Epoch 2/10, Batch 20/145, Loss: 0.3635
Epoch 2/10, Batch 30/145, Loss: 0.2197
Epoch 2/10, Batch 40/145, Loss: 0.4203
Epoch 2/10, Batch 50/145, Loss: 0.3535
Epoch 2/10, Batch 60/145, Loss: 0.3745
Epoch 2/10, Batch 70/145, Loss: 0.2674
Epoch 2/10, Batch 80/145, Loss: 0.2637
Epoch 2/10, Batch 90/145, Loss: 0.2864
Epoch 2/10, Batch 100/145, Loss: 0.2858
Epoch 2/10, Batch 110/145, Loss: 0.3823
Epoch 2/10, Batch 120/145, Loss: 0.3865
Epoch 2/10, Batch 130/145, Loss: 0.2551
Epoch 2/10, Batch 140/145, Loss: 0.3156
Epoch 2/10, Train Loss: 0.3586, Valid Loss: 0.2797
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2380
Epoch 3/10, Batch 20/145, Loss: 0.2342
Epoch 3/10, Batch 30/145, Loss: 0.4400
Epoch 3/10, Batch 40/145, Loss: 0.2231
Epoch 3/10, Batch 50/145, Loss: 0.2914
Epoch 3/10, Batch 60/145, Loss: 0.3185
Epoch 3/10, Batch 70/145, Loss: 0.4036
Epoch 3/10, Batch 80/145, Loss: 0.1858
Epoch 3/10, Batch 90/145, Loss: 0.3130
Epoch 3/10, Batch 100/145, Loss: 0.2288
Epoch 3/10, Batch 110/145, Loss: 0.1059
Epoch 3/10, Batch 120/145, Loss: 0.1841
Epoch 3/10, Batch 130/145, Loss: 0.5093
Epoch 3/10, Batch 140/145, Loss: 0.3601
Epoch 3/10, Train Loss: 0.2974, Valid Loss: 0.2466
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.5065
Epoch 4/10, Batch 20/145, Loss: 0.2578
Epoch 4/10, Batch 30/145, Loss: 0.2966
Epoch 4/10, Batch 40/145, Loss: 0.3184
Epoch 4/10, Batch 50/145, Loss: 0.1958
Epoch 4/10, Batch 60/145, Loss: 0.2274
Epoch 4/10, Batch 70/145, Loss: 0.3623
Epoch 4/10, Batch 80/145, Loss: 0.3177
Epoch 4/10, Batch 90/145, Loss: 0.2523
Epoch 4/10, Batch 100/145, Loss: 0.3811
Epoch 4/10, Batch 110/145, Loss: 0.3012
Epoch 4/10, Batch 120/145, Loss: 0.2845
Epoch 4/10, Batch 130/145, Loss: 0.1740
Epoch 4/10, Batch 140/145, Loss: 0.1512
Epoch 4/10, Train Loss: 0.2669, Valid Loss: 0.2377
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1307
Epoch 5/10, Batch 20/145, Loss: 0.1760
Epoch 5/10, Batch 30/145, Loss: 0.3047
Epoch 5/10, Batch 40/145, Loss: 0.1800
Epoch 5/10, Batch 50/145, Loss: 0.0972
Epoch 5/10, Batch 60/145, Loss: 0.2177
Epoch 5/10, Batch 70/145, Loss: 0.2131
Epoch 5/10, Batch 80/145, Loss: 0.3887
Epoch 5/10, Batch 90/145, Loss: 0.2060
Epoch 5/10, Batch 100/145, Loss: 0.2423
Epoch 5/10, Batch 110/145, Loss: 0.1735
Epoch 5/10, Batch 120/145, Loss: 0.3078
Epoch 5/10, Batch 130/145, Loss: 0.2464
Epoch 5/10, Batch 140/145, Loss: 0.1684
Epoch 5/10, Train Loss: 0.2450, Valid Loss: 0.2264
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1857
Epoch 6/10, Batch 20/145, Loss: 0.4516
Epoch 6/10, Batch 30/145, Loss: 0.3115
Epoch 6/10, Batch 40/145, Loss: 0.1588
Epoch 6/10, Batch 50/145, Loss: 0.2668
Epoch 6/10, Batch 60/145, Loss: 0.1264
Epoch 6/10, Batch 70/145, Loss: 0.1710
Epoch 6/10, Batch 80/145, Loss: 0.1442
Epoch 6/10, Batch 90/145, Loss: 0.2334
Epoch 6/10, Batch 100/145, Loss: 0.3576
Epoch 6/10, Batch 110/145, Loss: 0.2925
Epoch 6/10, Batch 120/145, Loss: 0.3338
Epoch 6/10, Batch 130/145, Loss: 0.3326
Epoch 6/10, Batch 140/145, Loss: 0.2286
Epoch 6/10, Train Loss: 0.2371, Valid Loss: 0.2154
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2085
Epoch 7/10, Batch 20/145, Loss: 0.5192
Epoch 7/10, Batch 30/145, Loss: 0.2665
Epoch 7/10, Batch 40/145, Loss: 0.4436
Epoch 7/10, Batch 50/145, Loss: 0.2759
Epoch 7/10, Batch 60/145, Loss: 0.1791
Epoch 7/10, Batch 70/145, Loss: 0.2653
Epoch 7/10, Batch 80/145, Loss: 0.5492
Epoch 7/10, Batch 90/145, Loss: 0.2296
Epoch 7/10, Batch 100/145, Loss: 0.1574
Epoch 7/10, Batch 110/145, Loss: 0.1173
Epoch 7/10, Batch 120/145, Loss: 0.3029
Epoch 7/10, Batch 130/145, Loss: 0.1101
Epoch 7/10, Batch 140/145, Loss: 0.3378
Epoch 7/10, Train Loss: 0.2135, Valid Loss: 0.2166
Epoch 8/10, Batch 10/145, Loss: 0.2908
Epoch 8/10, Batch 20/145, Loss: 0.1671
Epoch 8/10, Batch 30/145, Loss: 0.2759
Epoch 8/10, Batch 40/145, Loss: 0.1646
Epoch 8/10, Batch 50/145, Loss: 0.1471
Epoch 8/10, Batch 60/145, Loss: 0.1834
Epoch 8/10, Batch 70/145, Loss: 0.2327
Epoch 8/10, Batch 80/145, Loss: 0.2144
Epoch 8/10, Batch 90/145, Loss: 0.2484
Epoch 8/10, Batch 100/145, Loss: 0.3367
Epoch 8/10, Batch 110/145, Loss: 0.2001
Epoch 8/10, Batch 120/145, Loss: 0.2990
Epoch 8/10, Batch 130/145, Loss: 0.2140
Epoch 8/10, Batch 140/145, Loss: 0.1692
Epoch 8/10, Train Loss: 0.2124, Valid Loss: 0.2082
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3156
Epoch 9/10, Batch 20/145, Loss: 0.1818
Epoch 9/10, Batch 30/145, Loss: 0.2906
Epoch 9/10, Batch 40/145, Loss: 0.1316
Epoch 9/10, Batch 50/145, Loss: 0.1417
Epoch 9/10, Batch 60/145, Loss: 0.2800
Epoch 9/10, Batch 70/145, Loss: 0.0934
Epoch 9/10, Batch 80/145, Loss: 0.1020
Epoch 9/10, Batch 90/145, Loss: 0.1535
Epoch 9/10, Batch 100/145, Loss: 0.2198
Epoch 9/10, Batch 110/145, Loss: 0.2236
Epoch 9/10, Batch 120/145, Loss: 0.0676
Epoch 9/10, Batch 130/145, Loss: 0.1816
Epoch 9/10, Batch 140/145, Loss: 0.1903
Epoch 9/10, Train Loss: 0.2022, Valid Loss: 0.2174
Epoch 10/10, Batch 10/145, Loss: 0.1287
Epoch 10/10, Batch 20/145, Loss: 0.1144
Epoch 10/10, Batch 30/145, Loss: 0.1600
Epoch 10/10, Batch 40/145, Loss: 0.1077
Epoch 10/10, Batch 50/145, Loss: 0.1800
Epoch 10/10, Batch 60/145, Loss: 0.3284
Epoch 10/10, Batch 70/145, Loss: 0.3698
Epoch 10/10, Batch 80/145, Loss: 0.1023
Epoch 10/10, Batch 90/145, Loss: 0.1543
Epoch 10/10, Batch 100/145, Loss: 0.1301
Epoch 10/10, Batch 110/145, Loss: 0.1744
Epoch 10/10, Batch 120/145, Loss: 0.2715
Epoch 10/10, Batch 130/145, Loss: 0.0986
Epoch 10/10, Batch 140/145, Loss: 0.1779
Epoch 10/10, Train Loss: 0.1993, Valid Loss: 0.2115
Accuracy: 0.9171
Precision: 0.9153
Recall: 0.9171
F1-score: 0.9158
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4078
Epoch 1/10, Batch 20/145, Loss: 0.9352
Epoch 1/10, Batch 30/145, Loss: 0.9100
Epoch 1/10, Batch 40/145, Loss: 0.8019
Epoch 1/10, Batch 50/145, Loss: 0.6464
Epoch 1/10, Batch 60/145, Loss: 0.7187
Epoch 1/10, Batch 70/145, Loss: 0.4707
Epoch 1/10, Batch 80/145, Loss: 0.5086
Epoch 1/10, Batch 90/145, Loss: 0.3639
Epoch 1/10, Batch 100/145, Loss: 0.5307
Epoch 1/10, Batch 110/145, Loss: 0.4482
Epoch 1/10, Batch 120/145, Loss: 0.7767
Epoch 1/10, Batch 130/145, Loss: 0.4236
Epoch 1/10, Batch 140/145, Loss: 0.3190
Epoch 1/10, Train Loss: 0.6798, Valid Loss: 0.3663
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3574
Epoch 2/10, Batch 20/145, Loss: 0.4151
Epoch 2/10, Batch 30/145, Loss: 0.3689
Epoch 2/10, Batch 40/145, Loss: 0.4515
Epoch 2/10, Batch 50/145, Loss: 0.4057
Epoch 2/10, Batch 60/145, Loss: 0.3592
Epoch 2/10, Batch 70/145, Loss: 0.2448
Epoch 2/10, Batch 80/145, Loss: 0.2907
Epoch 2/10, Batch 90/145, Loss: 0.3464
Epoch 2/10, Batch 100/145, Loss: 0.4207
Epoch 2/10, Batch 110/145, Loss: 0.5024
Epoch 2/10, Batch 120/145, Loss: 0.2792
Epoch 2/10, Batch 130/145, Loss: 0.1987
Epoch 2/10, Batch 140/145, Loss: 0.3064
Epoch 2/10, Train Loss: 0.3575, Valid Loss: 0.2831
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2409
Epoch 3/10, Batch 20/145, Loss: 0.2418
Epoch 3/10, Batch 30/145, Loss: 0.3243
Epoch 3/10, Batch 40/145, Loss: 0.3421
Epoch 3/10, Batch 50/145, Loss: 0.2375
Epoch 3/10, Batch 60/145, Loss: 0.4036
Epoch 3/10, Batch 70/145, Loss: 0.3160
Epoch 3/10, Batch 80/145, Loss: 0.3541
Epoch 3/10, Batch 90/145, Loss: 0.2907
Epoch 3/10, Batch 100/145, Loss: 0.4095
Epoch 3/10, Batch 110/145, Loss: 0.1908
Epoch 3/10, Batch 120/145, Loss: 0.1881
Epoch 3/10, Batch 130/145, Loss: 0.3049
Epoch 3/10, Batch 140/145, Loss: 0.2128
Epoch 3/10, Train Loss: 0.2959, Valid Loss: 0.2501
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4587
Epoch 4/10, Batch 20/145, Loss: 0.5705
Epoch 4/10, Batch 30/145, Loss: 0.2514
Epoch 4/10, Batch 40/145, Loss: 0.2415
Epoch 4/10, Batch 50/145, Loss: 0.2149
Epoch 4/10, Batch 60/145, Loss: 0.1924
Epoch 4/10, Batch 70/145, Loss: 0.2295
Epoch 4/10, Batch 80/145, Loss: 0.2243
Epoch 4/10, Batch 90/145, Loss: 0.2132
Epoch 4/10, Batch 100/145, Loss: 0.1697
Epoch 4/10, Batch 110/145, Loss: 0.1138
Epoch 4/10, Batch 120/145, Loss: 0.2461
Epoch 4/10, Batch 130/145, Loss: 0.2330
Epoch 4/10, Batch 140/145, Loss: 0.1260
Epoch 4/10, Train Loss: 0.2623, Valid Loss: 0.2413
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1345
Epoch 5/10, Batch 20/145, Loss: 0.1686
Epoch 5/10, Batch 30/145, Loss: 0.1269
Epoch 5/10, Batch 40/145, Loss: 0.1657
Epoch 5/10, Batch 50/145, Loss: 0.2502
Epoch 5/10, Batch 60/145, Loss: 0.2092
Epoch 5/10, Batch 70/145, Loss: 0.1860
Epoch 5/10, Batch 80/145, Loss: 0.1707
Epoch 5/10, Batch 90/145, Loss: 0.2545
Epoch 5/10, Batch 100/145, Loss: 0.1564
Epoch 5/10, Batch 110/145, Loss: 0.1515
Epoch 5/10, Batch 120/145, Loss: 0.2586
Epoch 5/10, Batch 130/145, Loss: 0.1867
Epoch 5/10, Batch 140/145, Loss: 0.2922
Epoch 5/10, Train Loss: 0.2466, Valid Loss: 0.2291
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1943
Epoch 6/10, Batch 20/145, Loss: 0.3147
Epoch 6/10, Batch 30/145, Loss: 0.3657
Epoch 6/10, Batch 40/145, Loss: 0.1184
Epoch 6/10, Batch 50/145, Loss: 0.2748
Epoch 6/10, Batch 60/145, Loss: 0.1319
Epoch 6/10, Batch 70/145, Loss: 0.2044
Epoch 6/10, Batch 80/145, Loss: 0.1516
Epoch 6/10, Batch 90/145, Loss: 0.1977
Epoch 6/10, Batch 100/145, Loss: 0.4021
Epoch 6/10, Batch 110/145, Loss: 0.1536
Epoch 6/10, Batch 120/145, Loss: 0.2206
Epoch 6/10, Batch 130/145, Loss: 0.2071
Epoch 6/10, Batch 140/145, Loss: 0.4461
Epoch 6/10, Train Loss: 0.2285, Valid Loss: 0.2185
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3893
Epoch 7/10, Batch 20/145, Loss: 0.2217
Epoch 7/10, Batch 30/145, Loss: 0.2390
Epoch 7/10, Batch 40/145, Loss: 0.2757
Epoch 7/10, Batch 50/145, Loss: 0.1555
Epoch 7/10, Batch 60/145, Loss: 0.1954
Epoch 7/10, Batch 70/145, Loss: 0.2374
Epoch 7/10, Batch 80/145, Loss: 0.2583
Epoch 7/10, Batch 90/145, Loss: 0.1387
Epoch 7/10, Batch 100/145, Loss: 0.1260
Epoch 7/10, Batch 110/145, Loss: 0.0884
Epoch 7/10, Batch 120/145, Loss: 0.2730
Epoch 7/10, Batch 130/145, Loss: 0.1584
Epoch 7/10, Batch 140/145, Loss: 0.2020
Epoch 7/10, Train Loss: 0.2164, Valid Loss: 0.2126
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2128
Epoch 8/10, Batch 20/145, Loss: 0.3990
Epoch 8/10, Batch 30/145, Loss: 0.3208
Epoch 8/10, Batch 40/145, Loss: 0.1299
Epoch 8/10, Batch 50/145, Loss: 0.3043
Epoch 8/10, Batch 60/145, Loss: 0.1743
Epoch 8/10, Batch 70/145, Loss: 0.2072
Epoch 8/10, Batch 80/145, Loss: 0.1758
Epoch 8/10, Batch 90/145, Loss: 0.4715
Epoch 8/10, Batch 100/145, Loss: 0.1627
Epoch 8/10, Batch 110/145, Loss: 0.2987
Epoch 8/10, Batch 120/145, Loss: 0.2168
Epoch 8/10, Batch 130/145, Loss: 0.1266
Epoch 8/10, Batch 140/145, Loss: 0.1936
Epoch 8/10, Train Loss: 0.2145, Valid Loss: 0.2083
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1859
Epoch 9/10, Batch 20/145, Loss: 0.1930
Epoch 9/10, Batch 30/145, Loss: 0.1651
Epoch 9/10, Batch 40/145, Loss: 0.1416
Epoch 9/10, Batch 50/145, Loss: 0.2252
Epoch 9/10, Batch 60/145, Loss: 0.1670
Epoch 9/10, Batch 70/145, Loss: 0.2007
Epoch 9/10, Batch 80/145, Loss: 0.1290
Epoch 9/10, Batch 90/145, Loss: 0.2659
Epoch 9/10, Batch 100/145, Loss: 0.1165
Epoch 9/10, Batch 110/145, Loss: 0.4985
Epoch 9/10, Batch 120/145, Loss: 0.1186
Epoch 9/10, Batch 130/145, Loss: 0.1555
Epoch 9/10, Batch 140/145, Loss: 0.2007
Epoch 9/10, Train Loss: 0.2061, Valid Loss: 0.2065
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1553
Epoch 10/10, Batch 20/145, Loss: 0.1418
Epoch 10/10, Batch 30/145, Loss: 0.0789
Epoch 10/10, Batch 40/145, Loss: 0.1069
Epoch 10/10, Batch 50/145, Loss: 0.1631
Epoch 10/10, Batch 60/145, Loss: 0.2619
Epoch 10/10, Batch 70/145, Loss: 0.2202
Epoch 10/10, Batch 80/145, Loss: 0.1899
Epoch 10/10, Batch 90/145, Loss: 0.1942
Epoch 10/10, Batch 100/145, Loss: 0.2407
Epoch 10/10, Batch 110/145, Loss: 0.1132
Epoch 10/10, Batch 120/145, Loss: 0.2279
Epoch 10/10, Batch 130/145, Loss: 0.1693
Epoch 10/10, Batch 140/145, Loss: 0.1865
Epoch 10/10, Train Loss: 0.1995, Valid Loss: 0.2006
Model saved!
Accuracy: 0.9264
Precision: 0.9246
Recall: 0.9264
F1-score: 0.9253
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3737
Epoch 1/10, Batch 20/145, Loss: 0.9908
Epoch 1/10, Batch 30/145, Loss: 0.9485
Epoch 1/10, Batch 40/145, Loss: 0.9450
Epoch 1/10, Batch 50/145, Loss: 0.7614
Epoch 1/10, Batch 60/145, Loss: 0.6336
Epoch 1/10, Batch 70/145, Loss: 0.4249
Epoch 1/10, Batch 80/145, Loss: 0.5822
Epoch 1/10, Batch 90/145, Loss: 0.3316
Epoch 1/10, Batch 100/145, Loss: 0.5655
Epoch 1/10, Batch 110/145, Loss: 0.3705
Epoch 1/10, Batch 120/145, Loss: 0.4708
Epoch 1/10, Batch 130/145, Loss: 0.5891
Epoch 1/10, Batch 140/145, Loss: 0.4865
Epoch 1/10, Train Loss: 0.6712, Valid Loss: 0.3781
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2773
Epoch 2/10, Batch 20/145, Loss: 0.2740
Epoch 2/10, Batch 30/145, Loss: 0.3176
Epoch 2/10, Batch 40/145, Loss: 0.3418
Epoch 2/10, Batch 50/145, Loss: 0.2484
Epoch 2/10, Batch 60/145, Loss: 0.3555
Epoch 2/10, Batch 70/145, Loss: 0.3508
Epoch 2/10, Batch 80/145, Loss: 0.4913
Epoch 2/10, Batch 90/145, Loss: 0.2276
Epoch 2/10, Batch 100/145, Loss: 0.2068
Epoch 2/10, Batch 110/145, Loss: 0.3002
Epoch 2/10, Batch 120/145, Loss: 0.3601
Epoch 2/10, Batch 130/145, Loss: 0.3411
Epoch 2/10, Batch 140/145, Loss: 0.2956
Epoch 2/10, Train Loss: 0.3450, Valid Loss: 0.2969
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2431
Epoch 3/10, Batch 20/145, Loss: 0.3313
Epoch 3/10, Batch 30/145, Loss: 0.2249
Epoch 3/10, Batch 40/145, Loss: 0.2507
Epoch 3/10, Batch 50/145, Loss: 0.1329
Epoch 3/10, Batch 60/145, Loss: 0.4132
Epoch 3/10, Batch 70/145, Loss: 0.4639
Epoch 3/10, Batch 80/145, Loss: 0.2283
Epoch 3/10, Batch 90/145, Loss: 0.2457
Epoch 3/10, Batch 100/145, Loss: 0.1478
Epoch 3/10, Batch 110/145, Loss: 0.2406
Epoch 3/10, Batch 120/145, Loss: 0.2943
Epoch 3/10, Batch 130/145, Loss: 0.4211
Epoch 3/10, Batch 140/145, Loss: 0.2430
Epoch 3/10, Train Loss: 0.2860, Valid Loss: 0.2698
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2512
Epoch 4/10, Batch 20/145, Loss: 0.2005
Epoch 4/10, Batch 30/145, Loss: 0.3318
Epoch 4/10, Batch 40/145, Loss: 0.1333
Epoch 4/10, Batch 50/145, Loss: 0.1567
Epoch 4/10, Batch 60/145, Loss: 0.2908
Epoch 4/10, Batch 70/145, Loss: 0.2636
Epoch 4/10, Batch 80/145, Loss: 0.1650
Epoch 4/10, Batch 90/145, Loss: 0.2661
Epoch 4/10, Batch 100/145, Loss: 0.3047
Epoch 4/10, Batch 110/145, Loss: 0.1857
Epoch 4/10, Batch 120/145, Loss: 0.3525
Epoch 4/10, Batch 130/145, Loss: 0.1393
Epoch 4/10, Batch 140/145, Loss: 0.1163
Epoch 4/10, Train Loss: 0.2592, Valid Loss: 0.2513
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1464
Epoch 5/10, Batch 20/145, Loss: 0.3107
Epoch 5/10, Batch 30/145, Loss: 0.3685
Epoch 5/10, Batch 40/145, Loss: 0.1277
Epoch 5/10, Batch 50/145, Loss: 0.3221
Epoch 5/10, Batch 60/145, Loss: 0.2570
Epoch 5/10, Batch 70/145, Loss: 0.3091
Epoch 5/10, Batch 80/145, Loss: 0.1723
Epoch 5/10, Batch 90/145, Loss: 0.2133
Epoch 5/10, Batch 100/145, Loss: 0.2340
Epoch 5/10, Batch 110/145, Loss: 0.3810
Epoch 5/10, Batch 120/145, Loss: 0.2973
Epoch 5/10, Batch 130/145, Loss: 0.2570
Epoch 5/10, Batch 140/145, Loss: 0.3323
Epoch 5/10, Train Loss: 0.2384, Valid Loss: 0.2478
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1853
Epoch 6/10, Batch 20/145, Loss: 0.4822
Epoch 6/10, Batch 30/145, Loss: 0.4072
Epoch 6/10, Batch 40/145, Loss: 0.2507
Epoch 6/10, Batch 50/145, Loss: 0.3221
Epoch 6/10, Batch 60/145, Loss: 0.3345
Epoch 6/10, Batch 70/145, Loss: 0.2573
Epoch 6/10, Batch 80/145, Loss: 0.2469
Epoch 6/10, Batch 90/145, Loss: 0.1586
Epoch 6/10, Batch 100/145, Loss: 0.2560
Epoch 6/10, Batch 110/145, Loss: 0.2209
Epoch 6/10, Batch 120/145, Loss: 0.3609
Epoch 6/10, Batch 130/145, Loss: 0.1270
Epoch 6/10, Batch 140/145, Loss: 0.2965
Epoch 6/10, Train Loss: 0.2210, Valid Loss: 0.2331
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2704
Epoch 7/10, Batch 20/145, Loss: 0.2694
Epoch 7/10, Batch 30/145, Loss: 0.1705
Epoch 7/10, Batch 40/145, Loss: 0.3564
Epoch 7/10, Batch 50/145, Loss: 0.1918
Epoch 7/10, Batch 60/145, Loss: 0.1745
Epoch 7/10, Batch 70/145, Loss: 0.1439
Epoch 7/10, Batch 80/145, Loss: 0.4266
Epoch 7/10, Batch 90/145, Loss: 0.1376
Epoch 7/10, Batch 100/145, Loss: 0.1609
Epoch 7/10, Batch 110/145, Loss: 0.1331
Epoch 7/10, Batch 120/145, Loss: 0.1844
Epoch 7/10, Batch 130/145, Loss: 0.1567
Epoch 7/10, Batch 140/145, Loss: 0.3395
Epoch 7/10, Train Loss: 0.2100, Valid Loss: 0.2307
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1585
Epoch 8/10, Batch 20/145, Loss: 0.2012
Epoch 8/10, Batch 30/145, Loss: 0.1887
Epoch 8/10, Batch 40/145, Loss: 0.1227
Epoch 8/10, Batch 50/145, Loss: 0.1444
Epoch 8/10, Batch 60/145, Loss: 0.2796
Epoch 8/10, Batch 70/145, Loss: 0.3771
Epoch 8/10, Batch 80/145, Loss: 0.1806
Epoch 8/10, Batch 90/145, Loss: 0.1672
Epoch 8/10, Batch 100/145, Loss: 0.4022
Epoch 8/10, Batch 110/145, Loss: 0.3034
Epoch 8/10, Batch 120/145, Loss: 0.1521
Epoch 8/10, Batch 130/145, Loss: 0.2063
Epoch 8/10, Batch 140/145, Loss: 0.2970
Epoch 8/10, Train Loss: 0.2040, Valid Loss: 0.2259
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3740
Epoch 9/10, Batch 20/145, Loss: 0.2410
Epoch 9/10, Batch 30/145, Loss: 0.0517
Epoch 9/10, Batch 40/145, Loss: 0.1941
Epoch 9/10, Batch 50/145, Loss: 0.1278
Epoch 9/10, Batch 60/145, Loss: 0.2978
Epoch 9/10, Batch 70/145, Loss: 0.2232
Epoch 9/10, Batch 80/145, Loss: 0.1226
Epoch 9/10, Batch 90/145, Loss: 0.1858
Epoch 9/10, Batch 100/145, Loss: 0.1174
Epoch 9/10, Batch 110/145, Loss: 0.1026
Epoch 9/10, Batch 120/145, Loss: 0.1014
Epoch 9/10, Batch 130/145, Loss: 0.1858
Epoch 9/10, Batch 140/145, Loss: 0.3070
Epoch 9/10, Train Loss: 0.2002, Valid Loss: 0.2218
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0988
Epoch 10/10, Batch 20/145, Loss: 0.0901
Epoch 10/10, Batch 30/145, Loss: 0.1332
Epoch 10/10, Batch 40/145, Loss: 0.3212
Epoch 10/10, Batch 50/145, Loss: 0.2749
Epoch 10/10, Batch 60/145, Loss: 0.0964
Epoch 10/10, Batch 70/145, Loss: 0.2054
Epoch 10/10, Batch 80/145, Loss: 0.1749
Epoch 10/10, Batch 90/145, Loss: 0.1109
Epoch 10/10, Batch 100/145, Loss: 0.1396
Epoch 10/10, Batch 110/145, Loss: 0.2621
Epoch 10/10, Batch 120/145, Loss: 0.2013
Epoch 10/10, Batch 130/145, Loss: 0.1858
Epoch 10/10, Batch 140/145, Loss: 0.2846
Epoch 10/10, Train Loss: 0.1895, Valid Loss: 0.2217
Model saved!
Accuracy: 0.9182
Precision: 0.9152
Recall: 0.9182
F1-score: 0.9150
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4738
Epoch 1/10, Batch 20/145, Loss: 0.9928
Epoch 1/10, Batch 30/145, Loss: 0.8873
Epoch 1/10, Batch 40/145, Loss: 0.7092
Epoch 1/10, Batch 50/145, Loss: 0.9217
Epoch 1/10, Batch 60/145, Loss: 0.6189
Epoch 1/10, Batch 70/145, Loss: 0.4208
Epoch 1/10, Batch 80/145, Loss: 0.6165
Epoch 1/10, Batch 90/145, Loss: 0.5062
Epoch 1/10, Batch 100/145, Loss: 0.3979
Epoch 1/10, Batch 110/145, Loss: 0.5181
Epoch 1/10, Batch 120/145, Loss: 0.5262
Epoch 1/10, Batch 130/145, Loss: 0.5720
Epoch 1/10, Batch 140/145, Loss: 0.3798
Epoch 1/10, Train Loss: 0.6801, Valid Loss: 0.3714
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3070
Epoch 2/10, Batch 20/145, Loss: 0.2385
Epoch 2/10, Batch 30/145, Loss: 0.1934
Epoch 2/10, Batch 40/145, Loss: 0.3862
Epoch 2/10, Batch 50/145, Loss: 0.3633
Epoch 2/10, Batch 60/145, Loss: 0.3232
Epoch 2/10, Batch 70/145, Loss: 0.3076
Epoch 2/10, Batch 80/145, Loss: 0.2951
Epoch 2/10, Batch 90/145, Loss: 0.2381
Epoch 2/10, Batch 100/145, Loss: 0.3583
Epoch 2/10, Batch 110/145, Loss: 0.3193
Epoch 2/10, Batch 120/145, Loss: 0.3322
Epoch 2/10, Batch 130/145, Loss: 0.2582
Epoch 2/10, Batch 140/145, Loss: 0.3142
Epoch 2/10, Train Loss: 0.3552, Valid Loss: 0.2896
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2503
Epoch 3/10, Batch 20/145, Loss: 0.2434
Epoch 3/10, Batch 30/145, Loss: 0.4194
Epoch 3/10, Batch 40/145, Loss: 0.3395
Epoch 3/10, Batch 50/145, Loss: 0.2332
Epoch 3/10, Batch 60/145, Loss: 0.4134
Epoch 3/10, Batch 70/145, Loss: 0.2899
Epoch 3/10, Batch 80/145, Loss: 0.2664
Epoch 3/10, Batch 90/145, Loss: 0.3210
Epoch 3/10, Batch 100/145, Loss: 0.2694
Epoch 3/10, Batch 110/145, Loss: 0.2873
Epoch 3/10, Batch 120/145, Loss: 0.4137
Epoch 3/10, Batch 130/145, Loss: 0.3229
Epoch 3/10, Batch 140/145, Loss: 0.1608
Epoch 3/10, Train Loss: 0.2998, Valid Loss: 0.2504
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2598
Epoch 4/10, Batch 20/145, Loss: 0.2487
Epoch 4/10, Batch 30/145, Loss: 0.3388
Epoch 4/10, Batch 40/145, Loss: 0.2022
Epoch 4/10, Batch 50/145, Loss: 0.1801
Epoch 4/10, Batch 60/145, Loss: 0.2566
Epoch 4/10, Batch 70/145, Loss: 0.1212
Epoch 4/10, Batch 80/145, Loss: 0.1705
Epoch 4/10, Batch 90/145, Loss: 0.2411
Epoch 4/10, Batch 100/145, Loss: 0.1856
Epoch 4/10, Batch 110/145, Loss: 0.1756
Epoch 4/10, Batch 120/145, Loss: 0.2730
Epoch 4/10, Batch 130/145, Loss: 0.1902
Epoch 4/10, Batch 140/145, Loss: 0.1585
Epoch 4/10, Train Loss: 0.2579, Valid Loss: 0.2439
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2249
Epoch 5/10, Batch 20/145, Loss: 0.1181
Epoch 5/10, Batch 30/145, Loss: 0.2888
Epoch 5/10, Batch 40/145, Loss: 0.2003
Epoch 5/10, Batch 50/145, Loss: 0.2866
Epoch 5/10, Batch 60/145, Loss: 0.2835
Epoch 5/10, Batch 70/145, Loss: 0.1674
Epoch 5/10, Batch 80/145, Loss: 0.1249
Epoch 5/10, Batch 90/145, Loss: 0.3205
Epoch 5/10, Batch 100/145, Loss: 0.2278
Epoch 5/10, Batch 110/145, Loss: 0.1813
Epoch 5/10, Batch 120/145, Loss: 0.3842
Epoch 5/10, Batch 130/145, Loss: 0.2191
Epoch 5/10, Batch 140/145, Loss: 0.1560
Epoch 5/10, Train Loss: 0.2436, Valid Loss: 0.2241
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1262
Epoch 6/10, Batch 20/145, Loss: 0.2379
Epoch 6/10, Batch 30/145, Loss: 0.2954
Epoch 6/10, Batch 40/145, Loss: 0.1280
Epoch 6/10, Batch 50/145, Loss: 0.2468
Epoch 6/10, Batch 60/145, Loss: 0.1231
Epoch 6/10, Batch 70/145, Loss: 0.1519
Epoch 6/10, Batch 80/145, Loss: 0.1167
Epoch 6/10, Batch 90/145, Loss: 0.1934
Epoch 6/10, Batch 100/145, Loss: 0.1954
Epoch 6/10, Batch 110/145, Loss: 0.1605
Epoch 6/10, Batch 120/145, Loss: 0.3061
Epoch 6/10, Batch 130/145, Loss: 0.0936
Epoch 6/10, Batch 140/145, Loss: 0.1323
Epoch 6/10, Train Loss: 0.2301, Valid Loss: 0.2172
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2451
Epoch 7/10, Batch 20/145, Loss: 0.2363
Epoch 7/10, Batch 30/145, Loss: 0.2105
Epoch 7/10, Batch 40/145, Loss: 0.4461
Epoch 7/10, Batch 50/145, Loss: 0.1879
Epoch 7/10, Batch 60/145, Loss: 0.2056
Epoch 7/10, Batch 70/145, Loss: 0.1084
Epoch 7/10, Batch 80/145, Loss: 0.4532
Epoch 7/10, Batch 90/145, Loss: 0.1451
Epoch 7/10, Batch 100/145, Loss: 0.2373
Epoch 7/10, Batch 110/145, Loss: 0.2559
Epoch 7/10, Batch 120/145, Loss: 0.3054
Epoch 7/10, Batch 130/145, Loss: 0.1695
Epoch 7/10, Batch 140/145, Loss: 0.2582
Epoch 7/10, Train Loss: 0.2210, Valid Loss: 0.2164
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.0985
Epoch 8/10, Batch 20/145, Loss: 0.1064
Epoch 8/10, Batch 30/145, Loss: 0.1658
Epoch 8/10, Batch 40/145, Loss: 0.3188
Epoch 8/10, Batch 50/145, Loss: 0.3524
Epoch 8/10, Batch 60/145, Loss: 0.4217
Epoch 8/10, Batch 70/145, Loss: 0.3084
Epoch 8/10, Batch 80/145, Loss: 0.1438
Epoch 8/10, Batch 90/145, Loss: 0.3394
Epoch 8/10, Batch 100/145, Loss: 0.3079
Epoch 8/10, Batch 110/145, Loss: 0.2712
Epoch 8/10, Batch 120/145, Loss: 0.1936
Epoch 8/10, Batch 130/145, Loss: 0.4269
Epoch 8/10, Batch 140/145, Loss: 0.1020
Epoch 8/10, Train Loss: 0.2088, Valid Loss: 0.2105
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3317
Epoch 9/10, Batch 20/145, Loss: 0.1557
Epoch 9/10, Batch 30/145, Loss: 0.1953
Epoch 9/10, Batch 40/145, Loss: 0.1309
Epoch 9/10, Batch 50/145, Loss: 0.1022
Epoch 9/10, Batch 60/145, Loss: 0.3342
Epoch 9/10, Batch 70/145, Loss: 0.2840
Epoch 9/10, Batch 80/145, Loss: 0.1050
Epoch 9/10, Batch 90/145, Loss: 0.1835
Epoch 9/10, Batch 100/145, Loss: 0.2308
Epoch 9/10, Batch 110/145, Loss: 0.2559
Epoch 9/10, Batch 120/145, Loss: 0.0713
Epoch 9/10, Batch 130/145, Loss: 0.2032
Epoch 9/10, Batch 140/145, Loss: 0.2028
Epoch 9/10, Train Loss: 0.2011, Valid Loss: 0.2052
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1136
Epoch 10/10, Batch 20/145, Loss: 0.1151
Epoch 10/10, Batch 30/145, Loss: 0.1115
Epoch 10/10, Batch 40/145, Loss: 0.1508
Epoch 10/10, Batch 50/145, Loss: 0.4504
Epoch 10/10, Batch 60/145, Loss: 0.1713
Epoch 10/10, Batch 70/145, Loss: 0.2035
Epoch 10/10, Batch 80/145, Loss: 0.2198
Epoch 10/10, Batch 90/145, Loss: 0.2446
Epoch 10/10, Batch 100/145, Loss: 0.2053
Epoch 10/10, Batch 110/145, Loss: 0.1716
Epoch 10/10, Batch 120/145, Loss: 0.1846
Epoch 10/10, Batch 130/145, Loss: 0.2539
Epoch 10/10, Batch 140/145, Loss: 0.1588
Epoch 10/10, Train Loss: 0.1986, Valid Loss: 0.2010
Model saved!
Accuracy: 0.9194
Precision: 0.9173
Recall: 0.9194
F1-score: 0.9179
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3668
Epoch 1/10, Batch 20/145, Loss: 1.0248
Epoch 1/10, Batch 30/145, Loss: 0.8850
Epoch 1/10, Batch 40/145, Loss: 0.9135
Epoch 1/10, Batch 50/145, Loss: 0.8826
Epoch 1/10, Batch 60/145, Loss: 0.5781
Epoch 1/10, Batch 70/145, Loss: 0.5023
Epoch 1/10, Batch 80/145, Loss: 0.5242
Epoch 1/10, Batch 90/145, Loss: 0.3329
Epoch 1/10, Batch 100/145, Loss: 0.4202
Epoch 1/10, Batch 110/145, Loss: 0.3893
Epoch 1/10, Batch 120/145, Loss: 0.5908
Epoch 1/10, Batch 130/145, Loss: 0.4509
Epoch 1/10, Batch 140/145, Loss: 0.3258
Epoch 1/10, Train Loss: 0.6776, Valid Loss: 0.3862
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4258
Epoch 2/10, Batch 20/145, Loss: 0.2574
Epoch 2/10, Batch 30/145, Loss: 0.2632
Epoch 2/10, Batch 40/145, Loss: 0.4657
Epoch 2/10, Batch 50/145, Loss: 0.3328
Epoch 2/10, Batch 60/145, Loss: 0.4169
Epoch 2/10, Batch 70/145, Loss: 0.4499
Epoch 2/10, Batch 80/145, Loss: 0.2595
Epoch 2/10, Batch 90/145, Loss: 0.3575
Epoch 2/10, Batch 100/145, Loss: 0.4004
Epoch 2/10, Batch 110/145, Loss: 0.3264
Epoch 2/10, Batch 120/145, Loss: 0.2443
Epoch 2/10, Batch 130/145, Loss: 0.3792
Epoch 2/10, Batch 140/145, Loss: 0.1654
Epoch 2/10, Train Loss: 0.3474, Valid Loss: 0.3140
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1585
Epoch 3/10, Batch 20/145, Loss: 0.3075
Epoch 3/10, Batch 30/145, Loss: 0.2802
Epoch 3/10, Batch 40/145, Loss: 0.2581
Epoch 3/10, Batch 50/145, Loss: 0.2079
Epoch 3/10, Batch 60/145, Loss: 0.3610
Epoch 3/10, Batch 70/145, Loss: 0.2486
Epoch 3/10, Batch 80/145, Loss: 0.1937
Epoch 3/10, Batch 90/145, Loss: 0.2257
Epoch 3/10, Batch 100/145, Loss: 0.1459
Epoch 3/10, Batch 110/145, Loss: 0.3219
Epoch 3/10, Batch 120/145, Loss: 0.3714
Epoch 3/10, Batch 130/145, Loss: 0.2515
Epoch 3/10, Batch 140/145, Loss: 0.2092
Epoch 3/10, Train Loss: 0.2907, Valid Loss: 0.2734
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3833
Epoch 4/10, Batch 20/145, Loss: 0.2917
Epoch 4/10, Batch 30/145, Loss: 0.2721
Epoch 4/10, Batch 40/145, Loss: 0.1670
Epoch 4/10, Batch 50/145, Loss: 0.3078
Epoch 4/10, Batch 60/145, Loss: 0.1328
Epoch 4/10, Batch 70/145, Loss: 0.2979
Epoch 4/10, Batch 80/145, Loss: 0.1233
Epoch 4/10, Batch 90/145, Loss: 0.2625
Epoch 4/10, Batch 100/145, Loss: 0.2372
Epoch 4/10, Batch 110/145, Loss: 0.2406
Epoch 4/10, Batch 120/145, Loss: 0.2655
Epoch 4/10, Batch 130/145, Loss: 0.2003
Epoch 4/10, Batch 140/145, Loss: 0.1250
Epoch 4/10, Train Loss: 0.2545, Valid Loss: 0.2614
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1569
Epoch 5/10, Batch 20/145, Loss: 0.1829
Epoch 5/10, Batch 30/145, Loss: 0.2384
Epoch 5/10, Batch 40/145, Loss: 0.1816
Epoch 5/10, Batch 50/145, Loss: 0.1824
Epoch 5/10, Batch 60/145, Loss: 0.1338
Epoch 5/10, Batch 70/145, Loss: 0.3110
Epoch 5/10, Batch 80/145, Loss: 0.2059
Epoch 5/10, Batch 90/145, Loss: 0.3468
Epoch 5/10, Batch 100/145, Loss: 0.3531
Epoch 5/10, Batch 110/145, Loss: 0.2207
Epoch 5/10, Batch 120/145, Loss: 0.3378
Epoch 5/10, Batch 130/145, Loss: 0.1663
Epoch 5/10, Batch 140/145, Loss: 0.0959
Epoch 5/10, Train Loss: 0.2412, Valid Loss: 0.2538
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2213
Epoch 6/10, Batch 20/145, Loss: 0.6137
Epoch 6/10, Batch 30/145, Loss: 0.3090
Epoch 6/10, Batch 40/145, Loss: 0.2075
Epoch 6/10, Batch 50/145, Loss: 0.4082
Epoch 6/10, Batch 60/145, Loss: 0.3193
Epoch 6/10, Batch 70/145, Loss: 0.0505
Epoch 6/10, Batch 80/145, Loss: 0.1939
Epoch 6/10, Batch 90/145, Loss: 0.3655
Epoch 6/10, Batch 100/145, Loss: 0.1844
Epoch 6/10, Batch 110/145, Loss: 0.2439
Epoch 6/10, Batch 120/145, Loss: 0.2176
Epoch 6/10, Batch 130/145, Loss: 0.1996
Epoch 6/10, Batch 140/145, Loss: 0.1242
Epoch 6/10, Train Loss: 0.2260, Valid Loss: 0.2447
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3542
Epoch 7/10, Batch 20/145, Loss: 0.2657
Epoch 7/10, Batch 30/145, Loss: 0.2347
Epoch 7/10, Batch 40/145, Loss: 0.4045
Epoch 7/10, Batch 50/145, Loss: 0.2079
Epoch 7/10, Batch 60/145, Loss: 0.1457
Epoch 7/10, Batch 70/145, Loss: 0.2503
Epoch 7/10, Batch 80/145, Loss: 0.3002
Epoch 7/10, Batch 90/145, Loss: 0.1469
Epoch 7/10, Batch 100/145, Loss: 0.1881
Epoch 7/10, Batch 110/145, Loss: 0.1070
Epoch 7/10, Batch 120/145, Loss: 0.1638
Epoch 7/10, Batch 130/145, Loss: 0.0856
Epoch 7/10, Batch 140/145, Loss: 0.1616
Epoch 7/10, Train Loss: 0.2046, Valid Loss: 0.2410
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2688
Epoch 8/10, Batch 20/145, Loss: 0.1965
Epoch 8/10, Batch 30/145, Loss: 0.3802
Epoch 8/10, Batch 40/145, Loss: 0.2070
Epoch 8/10, Batch 50/145, Loss: 0.5159
Epoch 8/10, Batch 60/145, Loss: 0.4113
Epoch 8/10, Batch 70/145, Loss: 0.2278
Epoch 8/10, Batch 80/145, Loss: 0.2298
Epoch 8/10, Batch 90/145, Loss: 0.3571
Epoch 8/10, Batch 100/145, Loss: 0.2678
Epoch 8/10, Batch 110/145, Loss: 0.1804
Epoch 8/10, Batch 120/145, Loss: 0.2364
Epoch 8/10, Batch 130/145, Loss: 0.2621
Epoch 8/10, Batch 140/145, Loss: 0.1250
Epoch 8/10, Train Loss: 0.2034, Valid Loss: 0.2351
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3191
Epoch 9/10, Batch 20/145, Loss: 0.1652
Epoch 9/10, Batch 30/145, Loss: 0.1262
Epoch 9/10, Batch 40/145, Loss: 0.3092
Epoch 9/10, Batch 50/145, Loss: 0.1614
Epoch 9/10, Batch 60/145, Loss: 0.2836
Epoch 9/10, Batch 70/145, Loss: 0.2532
Epoch 9/10, Batch 80/145, Loss: 0.3417
Epoch 9/10, Batch 90/145, Loss: 0.1051
Epoch 9/10, Batch 100/145, Loss: 0.1010
Epoch 9/10, Batch 110/145, Loss: 0.2344
Epoch 9/10, Batch 120/145, Loss: 0.1780
Epoch 9/10, Batch 130/145, Loss: 0.2142
Epoch 9/10, Batch 140/145, Loss: 0.2000
Epoch 9/10, Train Loss: 0.1864, Valid Loss: 0.2307
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1381
Epoch 10/10, Batch 20/145, Loss: 0.2169
Epoch 10/10, Batch 30/145, Loss: 0.0577
Epoch 10/10, Batch 40/145, Loss: 0.1026
Epoch 10/10, Batch 50/145, Loss: 0.2699
Epoch 10/10, Batch 60/145, Loss: 0.2260
Epoch 10/10, Batch 70/145, Loss: 0.1754
Epoch 10/10, Batch 80/145, Loss: 0.2942
Epoch 10/10, Batch 90/145, Loss: 0.1393
Epoch 10/10, Batch 100/145, Loss: 0.3209
Epoch 10/10, Batch 110/145, Loss: 0.3215
Epoch 10/10, Batch 120/145, Loss: 0.1533
Epoch 10/10, Batch 130/145, Loss: 0.1783
Epoch 10/10, Batch 140/145, Loss: 0.2823
Epoch 10/10, Train Loss: 0.1887, Valid Loss: 0.2336
Accuracy: 0.9217
Precision: 0.9211
Recall: 0.9217
F1-score: 0.9212
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3606
Epoch 1/10, Batch 20/145, Loss: 0.9103
Epoch 1/10, Batch 30/145, Loss: 0.8433
Epoch 1/10, Batch 40/145, Loss: 0.7427
Epoch 1/10, Batch 50/145, Loss: 0.6766
Epoch 1/10, Batch 60/145, Loss: 0.5887
Epoch 1/10, Batch 70/145, Loss: 0.4734
Epoch 1/10, Batch 80/145, Loss: 0.5357
Epoch 1/10, Batch 90/145, Loss: 0.5117
Epoch 1/10, Batch 100/145, Loss: 0.4973
Epoch 1/10, Batch 110/145, Loss: 0.3520
Epoch 1/10, Batch 120/145, Loss: 0.5295
Epoch 1/10, Batch 130/145, Loss: 0.5767
Epoch 1/10, Batch 140/145, Loss: 0.2943
Epoch 1/10, Train Loss: 0.6816, Valid Loss: 0.3896
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4257
Epoch 2/10, Batch 20/145, Loss: 0.2875
Epoch 2/10, Batch 30/145, Loss: 0.3977
Epoch 2/10, Batch 40/145, Loss: 0.3702
Epoch 2/10, Batch 50/145, Loss: 0.3345
Epoch 2/10, Batch 60/145, Loss: 0.2540
Epoch 2/10, Batch 70/145, Loss: 0.4194
Epoch 2/10, Batch 80/145, Loss: 0.2920
Epoch 2/10, Batch 90/145, Loss: 0.4075
Epoch 2/10, Batch 100/145, Loss: 0.4055
Epoch 2/10, Batch 110/145, Loss: 0.4062
Epoch 2/10, Batch 120/145, Loss: 0.3776
Epoch 2/10, Batch 130/145, Loss: 0.2294
Epoch 2/10, Batch 140/145, Loss: 0.2383
Epoch 2/10, Train Loss: 0.3533, Valid Loss: 0.3052
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2846
Epoch 3/10, Batch 20/145, Loss: 0.2272
Epoch 3/10, Batch 30/145, Loss: 0.2974
Epoch 3/10, Batch 40/145, Loss: 0.1281
Epoch 3/10, Batch 50/145, Loss: 0.2620
Epoch 3/10, Batch 60/145, Loss: 0.3293
Epoch 3/10, Batch 70/145, Loss: 0.4535
Epoch 3/10, Batch 80/145, Loss: 0.3325
Epoch 3/10, Batch 90/145, Loss: 0.3770
Epoch 3/10, Batch 100/145, Loss: 0.2371
Epoch 3/10, Batch 110/145, Loss: 0.2372
Epoch 3/10, Batch 120/145, Loss: 0.3057
Epoch 3/10, Batch 130/145, Loss: 0.2815
Epoch 3/10, Batch 140/145, Loss: 0.3601
Epoch 3/10, Train Loss: 0.2942, Valid Loss: 0.2797
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3262
Epoch 4/10, Batch 20/145, Loss: 0.2608
Epoch 4/10, Batch 30/145, Loss: 0.2984
Epoch 4/10, Batch 40/145, Loss: 0.3101
Epoch 4/10, Batch 50/145, Loss: 0.1689
Epoch 4/10, Batch 60/145, Loss: 0.1612
Epoch 4/10, Batch 70/145, Loss: 0.1197
Epoch 4/10, Batch 80/145, Loss: 0.1589
Epoch 4/10, Batch 90/145, Loss: 0.2108
Epoch 4/10, Batch 100/145, Loss: 0.4136
Epoch 4/10, Batch 110/145, Loss: 0.2186
Epoch 4/10, Batch 120/145, Loss: 0.1927
Epoch 4/10, Batch 130/145, Loss: 0.1826
Epoch 4/10, Batch 140/145, Loss: 0.1274
Epoch 4/10, Train Loss: 0.2626, Valid Loss: 0.2611
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1630
Epoch 5/10, Batch 20/145, Loss: 0.3881
Epoch 5/10, Batch 30/145, Loss: 0.1712
Epoch 5/10, Batch 40/145, Loss: 0.1307
Epoch 5/10, Batch 50/145, Loss: 0.1821
Epoch 5/10, Batch 60/145, Loss: 0.1670
Epoch 5/10, Batch 70/145, Loss: 0.4203
Epoch 5/10, Batch 80/145, Loss: 0.1608
Epoch 5/10, Batch 90/145, Loss: 0.2027
Epoch 5/10, Batch 100/145, Loss: 0.1859
Epoch 5/10, Batch 110/145, Loss: 0.2628
Epoch 5/10, Batch 120/145, Loss: 0.3386
Epoch 5/10, Batch 130/145, Loss: 0.3556
Epoch 5/10, Batch 140/145, Loss: 0.2251
Epoch 5/10, Train Loss: 0.2447, Valid Loss: 0.2498
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1792
Epoch 6/10, Batch 20/145, Loss: 0.2755
Epoch 6/10, Batch 30/145, Loss: 0.3624
Epoch 6/10, Batch 40/145, Loss: 0.1632
Epoch 6/10, Batch 50/145, Loss: 0.3049
Epoch 6/10, Batch 60/145, Loss: 0.1706
Epoch 6/10, Batch 70/145, Loss: 0.1673
Epoch 6/10, Batch 80/145, Loss: 0.2334
Epoch 6/10, Batch 90/145, Loss: 0.2667
Epoch 6/10, Batch 100/145, Loss: 0.1502
Epoch 6/10, Batch 110/145, Loss: 0.1407
Epoch 6/10, Batch 120/145, Loss: 0.4890
Epoch 6/10, Batch 130/145, Loss: 0.3019
Epoch 6/10, Batch 140/145, Loss: 0.2158
Epoch 6/10, Train Loss: 0.2310, Valid Loss: 0.2442
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2146
Epoch 7/10, Batch 20/145, Loss: 0.2425
Epoch 7/10, Batch 30/145, Loss: 0.2253
Epoch 7/10, Batch 40/145, Loss: 0.2959
Epoch 7/10, Batch 50/145, Loss: 0.1286
Epoch 7/10, Batch 60/145, Loss: 0.1333
Epoch 7/10, Batch 70/145, Loss: 0.1311
Epoch 7/10, Batch 80/145, Loss: 0.2472
Epoch 7/10, Batch 90/145, Loss: 0.1611
Epoch 7/10, Batch 100/145, Loss: 0.2109
Epoch 7/10, Batch 110/145, Loss: 0.2435
Epoch 7/10, Batch 120/145, Loss: 0.2921
Epoch 7/10, Batch 130/145, Loss: 0.1065
Epoch 7/10, Batch 140/145, Loss: 0.3404
Epoch 7/10, Train Loss: 0.2200, Valid Loss: 0.2380
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1841
Epoch 8/10, Batch 20/145, Loss: 0.3296
Epoch 8/10, Batch 30/145, Loss: 0.3051
Epoch 8/10, Batch 40/145, Loss: 0.1599
Epoch 8/10, Batch 50/145, Loss: 0.2205
Epoch 8/10, Batch 60/145, Loss: 0.3734
Epoch 8/10, Batch 70/145, Loss: 0.3217
Epoch 8/10, Batch 80/145, Loss: 0.1877
Epoch 8/10, Batch 90/145, Loss: 0.1840
Epoch 8/10, Batch 100/145, Loss: 0.4472
Epoch 8/10, Batch 110/145, Loss: 0.2348
Epoch 8/10, Batch 120/145, Loss: 0.1385
Epoch 8/10, Batch 130/145, Loss: 0.1979
Epoch 8/10, Batch 140/145, Loss: 0.2797
Epoch 8/10, Train Loss: 0.2127, Valid Loss: 0.2402
Epoch 9/10, Batch 10/145, Loss: 0.1582
Epoch 9/10, Batch 20/145, Loss: 0.1819
Epoch 9/10, Batch 30/145, Loss: 0.1846
Epoch 9/10, Batch 40/145, Loss: 0.2839
Epoch 9/10, Batch 50/145, Loss: 0.2474
Epoch 9/10, Batch 60/145, Loss: 0.1847
Epoch 9/10, Batch 70/145, Loss: 0.1621
Epoch 9/10, Batch 80/145, Loss: 0.2180
Epoch 9/10, Batch 90/145, Loss: 0.2161
Epoch 9/10, Batch 100/145, Loss: 0.1084
Epoch 9/10, Batch 110/145, Loss: 0.3485
Epoch 9/10, Batch 120/145, Loss: 0.0596
Epoch 9/10, Batch 130/145, Loss: 0.1748
Epoch 9/10, Batch 140/145, Loss: 0.2747
Epoch 9/10, Train Loss: 0.1974, Valid Loss: 0.2366
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1587
Epoch 10/10, Batch 20/145, Loss: 0.2946
Epoch 10/10, Batch 30/145, Loss: 0.2255
Epoch 10/10, Batch 40/145, Loss: 0.1100
Epoch 10/10, Batch 50/145, Loss: 0.1426
Epoch 10/10, Batch 60/145, Loss: 0.1527
Epoch 10/10, Batch 70/145, Loss: 0.2901
Epoch 10/10, Batch 80/145, Loss: 0.1850
Epoch 10/10, Batch 90/145, Loss: 0.3001
Epoch 10/10, Batch 100/145, Loss: 0.1601
Epoch 10/10, Batch 110/145, Loss: 0.2240
Epoch 10/10, Batch 120/145, Loss: 0.2513
Epoch 10/10, Batch 130/145, Loss: 0.0961
Epoch 10/10, Batch 140/145, Loss: 0.1635
Epoch 10/10, Train Loss: 0.1936, Valid Loss: 0.2343
Model saved!
Accuracy: 0.9229
Precision: 0.9212
Recall: 0.9229
F1-score: 0.9205
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3724
Epoch 1/10, Batch 20/145, Loss: 0.9559
Epoch 1/10, Batch 30/145, Loss: 0.9593
Epoch 1/10, Batch 40/145, Loss: 0.8456
Epoch 1/10, Batch 50/145, Loss: 0.7116
Epoch 1/10, Batch 60/145, Loss: 0.6883
Epoch 1/10, Batch 70/145, Loss: 0.4826
Epoch 1/10, Batch 80/145, Loss: 0.5041
Epoch 1/10, Batch 90/145, Loss: 0.5367
Epoch 1/10, Batch 100/145, Loss: 0.5514
Epoch 1/10, Batch 110/145, Loss: 0.3501
Epoch 1/10, Batch 120/145, Loss: 0.6884
Epoch 1/10, Batch 130/145, Loss: 0.5675
Epoch 1/10, Batch 140/145, Loss: 0.3906
Epoch 1/10, Train Loss: 0.6823, Valid Loss: 0.3811
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3397
Epoch 2/10, Batch 20/145, Loss: 0.2794
Epoch 2/10, Batch 30/145, Loss: 0.2826
Epoch 2/10, Batch 40/145, Loss: 0.4996
Epoch 2/10, Batch 50/145, Loss: 0.3140
Epoch 2/10, Batch 60/145, Loss: 0.4623
Epoch 2/10, Batch 70/145, Loss: 0.4067
Epoch 2/10, Batch 80/145, Loss: 0.3747
Epoch 2/10, Batch 90/145, Loss: 0.2891
Epoch 2/10, Batch 100/145, Loss: 0.3688
Epoch 2/10, Batch 110/145, Loss: 0.2503
Epoch 2/10, Batch 120/145, Loss: 0.3135
Epoch 2/10, Batch 130/145, Loss: 0.3494
Epoch 2/10, Batch 140/145, Loss: 0.3553
Epoch 2/10, Train Loss: 0.3580, Valid Loss: 0.3000
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1772
Epoch 3/10, Batch 20/145, Loss: 0.3247
Epoch 3/10, Batch 30/145, Loss: 0.3666
Epoch 3/10, Batch 40/145, Loss: 0.2849
Epoch 3/10, Batch 50/145, Loss: 0.2618
Epoch 3/10, Batch 60/145, Loss: 0.2385
Epoch 3/10, Batch 70/145, Loss: 0.2876
Epoch 3/10, Batch 80/145, Loss: 0.1864
Epoch 3/10, Batch 90/145, Loss: 0.4838
Epoch 3/10, Batch 100/145, Loss: 0.2000
Epoch 3/10, Batch 110/145, Loss: 0.3234
Epoch 3/10, Batch 120/145, Loss: 0.2355
Epoch 3/10, Batch 130/145, Loss: 0.3461
Epoch 3/10, Batch 140/145, Loss: 0.2667
Epoch 3/10, Train Loss: 0.2942, Valid Loss: 0.2698
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3525
Epoch 4/10, Batch 20/145, Loss: 0.2167
Epoch 4/10, Batch 30/145, Loss: 0.3382
Epoch 4/10, Batch 40/145, Loss: 0.1390
Epoch 4/10, Batch 50/145, Loss: 0.2190
Epoch 4/10, Batch 60/145, Loss: 0.2029
Epoch 4/10, Batch 70/145, Loss: 0.1256
Epoch 4/10, Batch 80/145, Loss: 0.2012
Epoch 4/10, Batch 90/145, Loss: 0.3050
Epoch 4/10, Batch 100/145, Loss: 0.1220
Epoch 4/10, Batch 110/145, Loss: 0.1384
Epoch 4/10, Batch 120/145, Loss: 0.1830
Epoch 4/10, Batch 130/145, Loss: 0.1090
Epoch 4/10, Batch 140/145, Loss: 0.1371
Epoch 4/10, Train Loss: 0.2561, Valid Loss: 0.2619
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1891
Epoch 5/10, Batch 20/145, Loss: 0.1243
Epoch 5/10, Batch 30/145, Loss: 0.2849
Epoch 5/10, Batch 40/145, Loss: 0.1533
Epoch 5/10, Batch 50/145, Loss: 0.2496
Epoch 5/10, Batch 60/145, Loss: 0.4404
Epoch 5/10, Batch 70/145, Loss: 0.1446
Epoch 5/10, Batch 80/145, Loss: 0.1580
Epoch 5/10, Batch 90/145, Loss: 0.2877
Epoch 5/10, Batch 100/145, Loss: 0.1498
Epoch 5/10, Batch 110/145, Loss: 0.2852
Epoch 5/10, Batch 120/145, Loss: 0.4666
Epoch 5/10, Batch 130/145, Loss: 0.2421
Epoch 5/10, Batch 140/145, Loss: 0.1891
Epoch 5/10, Train Loss: 0.2455, Valid Loss: 0.2507
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2617
Epoch 6/10, Batch 20/145, Loss: 0.4676
Epoch 6/10, Batch 30/145, Loss: 0.3792
Epoch 6/10, Batch 40/145, Loss: 0.0981
Epoch 6/10, Batch 50/145, Loss: 0.2791
Epoch 6/10, Batch 60/145, Loss: 0.3292
Epoch 6/10, Batch 70/145, Loss: 0.0769
Epoch 6/10, Batch 80/145, Loss: 0.4097
Epoch 6/10, Batch 90/145, Loss: 0.1635
Epoch 6/10, Batch 100/145, Loss: 0.4405
Epoch 6/10, Batch 110/145, Loss: 0.2724
Epoch 6/10, Batch 120/145, Loss: 0.5151
Epoch 6/10, Batch 130/145, Loss: 0.1342
Epoch 6/10, Batch 140/145, Loss: 0.1233
Epoch 6/10, Train Loss: 0.2336, Valid Loss: 0.2394
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2667
Epoch 7/10, Batch 20/145, Loss: 0.2653
Epoch 7/10, Batch 30/145, Loss: 0.1969
Epoch 7/10, Batch 40/145, Loss: 0.2663
Epoch 7/10, Batch 50/145, Loss: 0.2422
Epoch 7/10, Batch 60/145, Loss: 0.1064
Epoch 7/10, Batch 70/145, Loss: 0.1533
Epoch 7/10, Batch 80/145, Loss: 0.3107
Epoch 7/10, Batch 90/145, Loss: 0.1773
Epoch 7/10, Batch 100/145, Loss: 0.3382
Epoch 7/10, Batch 110/145, Loss: 0.1632
Epoch 7/10, Batch 120/145, Loss: 0.2421
Epoch 7/10, Batch 130/145, Loss: 0.1305
Epoch 7/10, Batch 140/145, Loss: 0.2586
Epoch 7/10, Train Loss: 0.2151, Valid Loss: 0.2446
Epoch 8/10, Batch 10/145, Loss: 0.3856
Epoch 8/10, Batch 20/145, Loss: 0.1120
Epoch 8/10, Batch 30/145, Loss: 0.2237
Epoch 8/10, Batch 40/145, Loss: 0.3887
Epoch 8/10, Batch 50/145, Loss: 0.2904
Epoch 8/10, Batch 60/145, Loss: 0.2315
Epoch 8/10, Batch 70/145, Loss: 0.3493
Epoch 8/10, Batch 80/145, Loss: 0.2073
Epoch 8/10, Batch 90/145, Loss: 0.1243
Epoch 8/10, Batch 100/145, Loss: 0.3173
Epoch 8/10, Batch 110/145, Loss: 0.2447
Epoch 8/10, Batch 120/145, Loss: 0.1511
Epoch 8/10, Batch 130/145, Loss: 0.1772
Epoch 8/10, Batch 140/145, Loss: 0.2999
Epoch 8/10, Train Loss: 0.2120, Valid Loss: 0.2394
Epoch 9/10, Batch 10/145, Loss: 0.1866
Epoch 9/10, Batch 20/145, Loss: 0.1926
Epoch 9/10, Batch 30/145, Loss: 0.2129
Epoch 9/10, Batch 40/145, Loss: 0.2589
Epoch 9/10, Batch 50/145, Loss: 0.1559
Epoch 9/10, Batch 60/145, Loss: 0.1917
Epoch 9/10, Batch 70/145, Loss: 0.1219
Epoch 9/10, Batch 80/145, Loss: 0.1621
Epoch 9/10, Batch 90/145, Loss: 0.1423
Epoch 9/10, Batch 100/145, Loss: 0.1002
Epoch 9/10, Batch 110/145, Loss: 0.2877
Epoch 9/10, Batch 120/145, Loss: 0.0563
Epoch 9/10, Batch 130/145, Loss: 0.2300
Epoch 9/10, Batch 140/145, Loss: 0.2055
Epoch 9/10, Train Loss: 0.2006, Valid Loss: 0.2318
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0861
Epoch 10/10, Batch 20/145, Loss: 0.1280
Epoch 10/10, Batch 30/145, Loss: 0.1870
Epoch 10/10, Batch 40/145, Loss: 0.0940
Epoch 10/10, Batch 50/145, Loss: 0.1896
Epoch 10/10, Batch 60/145, Loss: 0.1393
Epoch 10/10, Batch 70/145, Loss: 0.2762
Epoch 10/10, Batch 80/145, Loss: 0.2429
Epoch 10/10, Batch 90/145, Loss: 0.1300
Epoch 10/10, Batch 100/145, Loss: 0.1330
Epoch 10/10, Batch 110/145, Loss: 0.3048
Epoch 10/10, Batch 120/145, Loss: 0.2354
Epoch 10/10, Batch 130/145, Loss: 0.1955
Epoch 10/10, Batch 140/145, Loss: 0.2110
Epoch 10/10, Train Loss: 0.1922, Valid Loss: 0.2342
Accuracy: 0.9241
Precision: 0.9225
Recall: 0.9241
F1-score: 0.9229
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.2917
Epoch 1/10, Batch 20/145, Loss: 0.9176
Epoch 1/10, Batch 30/145, Loss: 0.8155
Epoch 1/10, Batch 40/145, Loss: 0.8266
Epoch 1/10, Batch 50/145, Loss: 0.7724
Epoch 1/10, Batch 60/145, Loss: 0.5166
Epoch 1/10, Batch 70/145, Loss: 0.4363
Epoch 1/10, Batch 80/145, Loss: 0.6131
Epoch 1/10, Batch 90/145, Loss: 0.3504
Epoch 1/10, Batch 100/145, Loss: 0.4812
Epoch 1/10, Batch 110/145, Loss: 0.4350
Epoch 1/10, Batch 120/145, Loss: 0.4650
Epoch 1/10, Batch 130/145, Loss: 0.5834
Epoch 1/10, Batch 140/145, Loss: 0.3510
Epoch 1/10, Train Loss: 0.6665, Valid Loss: 0.3844
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3410
Epoch 2/10, Batch 20/145, Loss: 0.3403
Epoch 2/10, Batch 30/145, Loss: 0.3249
Epoch 2/10, Batch 40/145, Loss: 0.4498
Epoch 2/10, Batch 50/145, Loss: 0.2991
Epoch 2/10, Batch 60/145, Loss: 0.4523
Epoch 2/10, Batch 70/145, Loss: 0.2760
Epoch 2/10, Batch 80/145, Loss: 0.2832
Epoch 2/10, Batch 90/145, Loss: 0.3913
Epoch 2/10, Batch 100/145, Loss: 0.3263
Epoch 2/10, Batch 110/145, Loss: 0.3568
Epoch 2/10, Batch 120/145, Loss: 0.4629
Epoch 2/10, Batch 130/145, Loss: 0.4160
Epoch 2/10, Batch 140/145, Loss: 0.3114
Epoch 2/10, Train Loss: 0.3425, Valid Loss: 0.3024
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2228
Epoch 3/10, Batch 20/145, Loss: 0.1647
Epoch 3/10, Batch 30/145, Loss: 0.3092
Epoch 3/10, Batch 40/145, Loss: 0.1812
Epoch 3/10, Batch 50/145, Loss: 0.1270
Epoch 3/10, Batch 60/145, Loss: 0.2736
Epoch 3/10, Batch 70/145, Loss: 0.4130
Epoch 3/10, Batch 80/145, Loss: 0.2744
Epoch 3/10, Batch 90/145, Loss: 0.1890
Epoch 3/10, Batch 100/145, Loss: 0.2726
Epoch 3/10, Batch 110/145, Loss: 0.2188
Epoch 3/10, Batch 120/145, Loss: 0.2312
Epoch 3/10, Batch 130/145, Loss: 0.4538
Epoch 3/10, Batch 140/145, Loss: 0.2302
Epoch 3/10, Train Loss: 0.2868, Valid Loss: 0.2724
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3274
Epoch 4/10, Batch 20/145, Loss: 0.3556
Epoch 4/10, Batch 30/145, Loss: 0.1848
Epoch 4/10, Batch 40/145, Loss: 0.1636
Epoch 4/10, Batch 50/145, Loss: 0.3018
Epoch 4/10, Batch 60/145, Loss: 0.2523
Epoch 4/10, Batch 70/145, Loss: 0.2596
Epoch 4/10, Batch 80/145, Loss: 0.0794
Epoch 4/10, Batch 90/145, Loss: 0.2033
Epoch 4/10, Batch 100/145, Loss: 0.1723
Epoch 4/10, Batch 110/145, Loss: 0.1879
Epoch 4/10, Batch 120/145, Loss: 0.2714
Epoch 4/10, Batch 130/145, Loss: 0.1239
Epoch 4/10, Batch 140/145, Loss: 0.1693
Epoch 4/10, Train Loss: 0.2478, Valid Loss: 0.2582
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1393
Epoch 5/10, Batch 20/145, Loss: 0.2019
Epoch 5/10, Batch 30/145, Loss: 0.1825
Epoch 5/10, Batch 40/145, Loss: 0.1478
Epoch 5/10, Batch 50/145, Loss: 0.1646
Epoch 5/10, Batch 60/145, Loss: 0.2089
Epoch 5/10, Batch 70/145, Loss: 0.2037
Epoch 5/10, Batch 80/145, Loss: 0.1830
Epoch 5/10, Batch 90/145, Loss: 0.2348
Epoch 5/10, Batch 100/145, Loss: 0.2174
Epoch 5/10, Batch 110/145, Loss: 0.2205
Epoch 5/10, Batch 120/145, Loss: 0.4003
Epoch 5/10, Batch 130/145, Loss: 0.2128
Epoch 5/10, Batch 140/145, Loss: 0.1850
Epoch 5/10, Train Loss: 0.2390, Valid Loss: 0.2563
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2156
Epoch 6/10, Batch 20/145, Loss: 0.3867
Epoch 6/10, Batch 30/145, Loss: 0.3646
Epoch 6/10, Batch 40/145, Loss: 0.1345
Epoch 6/10, Batch 50/145, Loss: 0.3644
Epoch 6/10, Batch 60/145, Loss: 0.2814
Epoch 6/10, Batch 70/145, Loss: 0.0728
Epoch 6/10, Batch 80/145, Loss: 0.1417
Epoch 6/10, Batch 90/145, Loss: 0.2132
Epoch 6/10, Batch 100/145, Loss: 0.3584
Epoch 6/10, Batch 110/145, Loss: 0.2459
Epoch 6/10, Batch 120/145, Loss: 0.2606
Epoch 6/10, Batch 130/145, Loss: 0.2805
Epoch 6/10, Batch 140/145, Loss: 0.2817
Epoch 6/10, Train Loss: 0.2195, Valid Loss: 0.2354
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2867
Epoch 7/10, Batch 20/145, Loss: 0.2929
Epoch 7/10, Batch 30/145, Loss: 0.2405
Epoch 7/10, Batch 40/145, Loss: 0.1632
Epoch 7/10, Batch 50/145, Loss: 0.3216
Epoch 7/10, Batch 60/145, Loss: 0.3304
Epoch 7/10, Batch 70/145, Loss: 0.1988
Epoch 7/10, Batch 80/145, Loss: 0.4659
Epoch 7/10, Batch 90/145, Loss: 0.2722
Epoch 7/10, Batch 100/145, Loss: 0.2463
Epoch 7/10, Batch 110/145, Loss: 0.2466
Epoch 7/10, Batch 120/145, Loss: 0.2157
Epoch 7/10, Batch 130/145, Loss: 0.1239
Epoch 7/10, Batch 140/145, Loss: 0.2533
Epoch 7/10, Train Loss: 0.2049, Valid Loss: 0.2296
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2279
Epoch 8/10, Batch 20/145, Loss: 0.1377
Epoch 8/10, Batch 30/145, Loss: 0.2018
Epoch 8/10, Batch 40/145, Loss: 0.3248
Epoch 8/10, Batch 50/145, Loss: 0.3402
Epoch 8/10, Batch 60/145, Loss: 0.2845
Epoch 8/10, Batch 70/145, Loss: 0.3639
Epoch 8/10, Batch 80/145, Loss: 0.2101
Epoch 8/10, Batch 90/145, Loss: 0.2244
Epoch 8/10, Batch 100/145, Loss: 0.2548
Epoch 8/10, Batch 110/145, Loss: 0.1786
Epoch 8/10, Batch 120/145, Loss: 0.1913
Epoch 8/10, Batch 130/145, Loss: 0.1735
Epoch 8/10, Batch 140/145, Loss: 0.2244
Epoch 8/10, Train Loss: 0.2031, Valid Loss: 0.2260
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2804
Epoch 9/10, Batch 20/145, Loss: 0.2699
Epoch 9/10, Batch 30/145, Loss: 0.1971
Epoch 9/10, Batch 40/145, Loss: 0.1565
Epoch 9/10, Batch 50/145, Loss: 0.0902
Epoch 9/10, Batch 60/145, Loss: 0.3448
Epoch 9/10, Batch 70/145, Loss: 0.1988
Epoch 9/10, Batch 80/145, Loss: 0.2041
Epoch 9/10, Batch 90/145, Loss: 0.2763
Epoch 9/10, Batch 100/145, Loss: 0.2830
Epoch 9/10, Batch 110/145, Loss: 0.2169
Epoch 9/10, Batch 120/145, Loss: 0.1544
Epoch 9/10, Batch 130/145, Loss: 0.2961
Epoch 9/10, Batch 140/145, Loss: 0.1967
Epoch 9/10, Train Loss: 0.1928, Valid Loss: 0.2274
Epoch 10/10, Batch 10/145, Loss: 0.1439
Epoch 10/10, Batch 20/145, Loss: 0.0886
Epoch 10/10, Batch 30/145, Loss: 0.1300
Epoch 10/10, Batch 40/145, Loss: 0.1871
Epoch 10/10, Batch 50/145, Loss: 0.0959
Epoch 10/10, Batch 60/145, Loss: 0.1181
Epoch 10/10, Batch 70/145, Loss: 0.1750
Epoch 10/10, Batch 80/145, Loss: 0.1624
Epoch 10/10, Batch 90/145, Loss: 0.1059
Epoch 10/10, Batch 100/145, Loss: 0.1918
Epoch 10/10, Batch 110/145, Loss: 0.1674
Epoch 10/10, Batch 120/145, Loss: 0.1336
Epoch 10/10, Batch 130/145, Loss: 0.1567
Epoch 10/10, Batch 140/145, Loss: 0.3130
Epoch 10/10, Train Loss: 0.1863, Valid Loss: 0.2226
Model saved!
Accuracy: 0.9241
Precision: 0.9220
Recall: 0.9241
F1-score: 0.9223
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4003
Epoch 1/10, Batch 20/145, Loss: 0.9822
Epoch 1/10, Batch 30/145, Loss: 0.8889
Epoch 1/10, Batch 40/145, Loss: 0.7693
Epoch 1/10, Batch 50/145, Loss: 0.7082
Epoch 1/10, Batch 60/145, Loss: 0.7323
Epoch 1/10, Batch 70/145, Loss: 0.4461
Epoch 1/10, Batch 80/145, Loss: 0.5656
Epoch 1/10, Batch 90/145, Loss: 0.3908
Epoch 1/10, Batch 100/145, Loss: 0.4345
Epoch 1/10, Batch 110/145, Loss: 0.3093
Epoch 1/10, Batch 120/145, Loss: 0.5020
Epoch 1/10, Batch 130/145, Loss: 0.6211
Epoch 1/10, Batch 140/145, Loss: 0.3180
Epoch 1/10, Train Loss: 0.6727, Valid Loss: 0.3705
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4128
Epoch 2/10, Batch 20/145, Loss: 0.3253
Epoch 2/10, Batch 30/145, Loss: 0.4327
Epoch 2/10, Batch 40/145, Loss: 0.3973
Epoch 2/10, Batch 50/145, Loss: 0.3653
Epoch 2/10, Batch 60/145, Loss: 0.3481
Epoch 2/10, Batch 70/145, Loss: 0.2913
Epoch 2/10, Batch 80/145, Loss: 0.3469
Epoch 2/10, Batch 90/145, Loss: 0.3405
Epoch 2/10, Batch 100/145, Loss: 0.3151
Epoch 2/10, Batch 110/145, Loss: 0.2847
Epoch 2/10, Batch 120/145, Loss: 0.2976
Epoch 2/10, Batch 130/145, Loss: 0.2685
Epoch 2/10, Batch 140/145, Loss: 0.2870
Epoch 2/10, Train Loss: 0.3521, Valid Loss: 0.2938
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2673
Epoch 3/10, Batch 20/145, Loss: 0.3617
Epoch 3/10, Batch 30/145, Loss: 0.2651
Epoch 3/10, Batch 40/145, Loss: 0.3788
Epoch 3/10, Batch 50/145, Loss: 0.3673
Epoch 3/10, Batch 60/145, Loss: 0.2526
Epoch 3/10, Batch 70/145, Loss: 0.4172
Epoch 3/10, Batch 80/145, Loss: 0.1973
Epoch 3/10, Batch 90/145, Loss: 0.1699
Epoch 3/10, Batch 100/145, Loss: 0.4006
Epoch 3/10, Batch 110/145, Loss: 0.2384
Epoch 3/10, Batch 120/145, Loss: 0.2641
Epoch 3/10, Batch 130/145, Loss: 0.4802
Epoch 3/10, Batch 140/145, Loss: 0.3493
Epoch 3/10, Train Loss: 0.2908, Valid Loss: 0.2586
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.5034
Epoch 4/10, Batch 20/145, Loss: 0.2420
Epoch 4/10, Batch 30/145, Loss: 0.2365
Epoch 4/10, Batch 40/145, Loss: 0.1196
Epoch 4/10, Batch 50/145, Loss: 0.1692
Epoch 4/10, Batch 60/145, Loss: 0.2035
Epoch 4/10, Batch 70/145, Loss: 0.2278
Epoch 4/10, Batch 80/145, Loss: 0.2960
Epoch 4/10, Batch 90/145, Loss: 0.1790
Epoch 4/10, Batch 100/145, Loss: 0.3428
Epoch 4/10, Batch 110/145, Loss: 0.3678
Epoch 4/10, Batch 120/145, Loss: 0.2456
Epoch 4/10, Batch 130/145, Loss: 0.2049
Epoch 4/10, Batch 140/145, Loss: 0.1453
Epoch 4/10, Train Loss: 0.2571, Valid Loss: 0.2417
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1720
Epoch 5/10, Batch 20/145, Loss: 0.2174
Epoch 5/10, Batch 30/145, Loss: 0.3506
Epoch 5/10, Batch 40/145, Loss: 0.2181
Epoch 5/10, Batch 50/145, Loss: 0.1977
Epoch 5/10, Batch 60/145, Loss: 0.2340
Epoch 5/10, Batch 70/145, Loss: 0.1145
Epoch 5/10, Batch 80/145, Loss: 0.2477
Epoch 5/10, Batch 90/145, Loss: 0.2527
Epoch 5/10, Batch 100/145, Loss: 0.2760
Epoch 5/10, Batch 110/145, Loss: 0.1261
Epoch 5/10, Batch 120/145, Loss: 0.3742
Epoch 5/10, Batch 130/145, Loss: 0.2561
Epoch 5/10, Batch 140/145, Loss: 0.1890
Epoch 5/10, Train Loss: 0.2469, Valid Loss: 0.2322
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1321
Epoch 6/10, Batch 20/145, Loss: 0.5380
Epoch 6/10, Batch 30/145, Loss: 0.3675
Epoch 6/10, Batch 40/145, Loss: 0.1283
Epoch 6/10, Batch 50/145, Loss: 0.2516
Epoch 6/10, Batch 60/145, Loss: 0.2678
Epoch 6/10, Batch 70/145, Loss: 0.0958
Epoch 6/10, Batch 80/145, Loss: 0.1557
Epoch 6/10, Batch 90/145, Loss: 0.3482
Epoch 6/10, Batch 100/145, Loss: 0.2911
Epoch 6/10, Batch 110/145, Loss: 0.4252
Epoch 6/10, Batch 120/145, Loss: 0.2421
Epoch 6/10, Batch 130/145, Loss: 0.2635
Epoch 6/10, Batch 140/145, Loss: 0.2959
Epoch 6/10, Train Loss: 0.2249, Valid Loss: 0.2189
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3966
Epoch 7/10, Batch 20/145, Loss: 0.3938
Epoch 7/10, Batch 30/145, Loss: 0.2154
Epoch 7/10, Batch 40/145, Loss: 0.3054
Epoch 7/10, Batch 50/145, Loss: 0.2071
Epoch 7/10, Batch 60/145, Loss: 0.2175
Epoch 7/10, Batch 70/145, Loss: 0.0911
Epoch 7/10, Batch 80/145, Loss: 0.4548
Epoch 7/10, Batch 90/145, Loss: 0.2506
Epoch 7/10, Batch 100/145, Loss: 0.2183
Epoch 7/10, Batch 110/145, Loss: 0.3917
Epoch 7/10, Batch 120/145, Loss: 0.3612
Epoch 7/10, Batch 130/145, Loss: 0.1591
Epoch 7/10, Batch 140/145, Loss: 0.2945
Epoch 7/10, Train Loss: 0.2125, Valid Loss: 0.2149
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1660
Epoch 8/10, Batch 20/145, Loss: 0.2466
Epoch 8/10, Batch 30/145, Loss: 0.3683
Epoch 8/10, Batch 40/145, Loss: 0.2051
Epoch 8/10, Batch 50/145, Loss: 0.1100
Epoch 8/10, Batch 60/145, Loss: 0.1806
Epoch 8/10, Batch 70/145, Loss: 0.1624
Epoch 8/10, Batch 80/145, Loss: 0.0924
Epoch 8/10, Batch 90/145, Loss: 0.1661
Epoch 8/10, Batch 100/145, Loss: 0.1287
Epoch 8/10, Batch 110/145, Loss: 0.1884
Epoch 8/10, Batch 120/145, Loss: 0.1403
Epoch 8/10, Batch 130/145, Loss: 0.2239
Epoch 8/10, Batch 140/145, Loss: 0.1040
Epoch 8/10, Train Loss: 0.2072, Valid Loss: 0.2124
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3153
Epoch 9/10, Batch 20/145, Loss: 0.2053
Epoch 9/10, Batch 30/145, Loss: 0.1888
Epoch 9/10, Batch 40/145, Loss: 0.1326
Epoch 9/10, Batch 50/145, Loss: 0.1583
Epoch 9/10, Batch 60/145, Loss: 0.2220
Epoch 9/10, Batch 70/145, Loss: 0.1528
Epoch 9/10, Batch 80/145, Loss: 0.0969
Epoch 9/10, Batch 90/145, Loss: 0.4166
Epoch 9/10, Batch 100/145, Loss: 0.2360
Epoch 9/10, Batch 110/145, Loss: 0.2222
Epoch 9/10, Batch 120/145, Loss: 0.1200
Epoch 9/10, Batch 130/145, Loss: 0.0634
Epoch 9/10, Batch 140/145, Loss: 0.1194
Epoch 9/10, Train Loss: 0.2032, Valid Loss: 0.2097
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.2779
Epoch 10/10, Batch 20/145, Loss: 0.0807
Epoch 10/10, Batch 30/145, Loss: 0.1254
Epoch 10/10, Batch 40/145, Loss: 0.1188
Epoch 10/10, Batch 50/145, Loss: 0.1982
Epoch 10/10, Batch 60/145, Loss: 0.0939
Epoch 10/10, Batch 70/145, Loss: 0.3082
Epoch 10/10, Batch 80/145, Loss: 0.1991
Epoch 10/10, Batch 90/145, Loss: 0.0621
Epoch 10/10, Batch 100/145, Loss: 0.2415
Epoch 10/10, Batch 110/145, Loss: 0.1286
Epoch 10/10, Batch 120/145, Loss: 0.1692
Epoch 10/10, Batch 130/145, Loss: 0.1452
Epoch 10/10, Batch 140/145, Loss: 0.2059
Epoch 10/10, Train Loss: 0.1925, Valid Loss: 0.2072
Model saved!
Accuracy: 0.9252
Precision: 0.9234
Recall: 0.9252
F1-score: 0.9234
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3410
Epoch 1/10, Batch 20/145, Loss: 0.9910
Epoch 1/10, Batch 30/145, Loss: 0.8775
Epoch 1/10, Batch 40/145, Loss: 0.8223
Epoch 1/10, Batch 50/145, Loss: 0.7165
Epoch 1/10, Batch 60/145, Loss: 0.7106
Epoch 1/10, Batch 70/145, Loss: 0.4402
Epoch 1/10, Batch 80/145, Loss: 0.5624
Epoch 1/10, Batch 90/145, Loss: 0.4350
Epoch 1/10, Batch 100/145, Loss: 0.5434
Epoch 1/10, Batch 110/145, Loss: 0.3028
Epoch 1/10, Batch 120/145, Loss: 0.5791
Epoch 1/10, Batch 130/145, Loss: 0.5052
Epoch 1/10, Batch 140/145, Loss: 0.3195
Epoch 1/10, Train Loss: 0.6785, Valid Loss: 0.3590
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2632
Epoch 2/10, Batch 20/145, Loss: 0.3388
Epoch 2/10, Batch 30/145, Loss: 0.2841
Epoch 2/10, Batch 40/145, Loss: 0.4176
Epoch 2/10, Batch 50/145, Loss: 0.2260
Epoch 2/10, Batch 60/145, Loss: 0.4309
Epoch 2/10, Batch 70/145, Loss: 0.4628
Epoch 2/10, Batch 80/145, Loss: 0.3341
Epoch 2/10, Batch 90/145, Loss: 0.2580
Epoch 2/10, Batch 100/145, Loss: 0.2831
Epoch 2/10, Batch 110/145, Loss: 0.2975
Epoch 2/10, Batch 120/145, Loss: 0.4280
Epoch 2/10, Batch 130/145, Loss: 0.3646
Epoch 2/10, Batch 140/145, Loss: 0.3028
Epoch 2/10, Train Loss: 0.3502, Valid Loss: 0.2750
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.1975
Epoch 3/10, Batch 20/145, Loss: 0.2027
Epoch 3/10, Batch 30/145, Loss: 0.3459
Epoch 3/10, Batch 40/145, Loss: 0.4135
Epoch 3/10, Batch 50/145, Loss: 0.1490
Epoch 3/10, Batch 60/145, Loss: 0.3519
Epoch 3/10, Batch 70/145, Loss: 0.2822
Epoch 3/10, Batch 80/145, Loss: 0.3112
Epoch 3/10, Batch 90/145, Loss: 0.3676
Epoch 3/10, Batch 100/145, Loss: 0.2061
Epoch 3/10, Batch 110/145, Loss: 0.2090
Epoch 3/10, Batch 120/145, Loss: 0.1725
Epoch 3/10, Batch 130/145, Loss: 0.7085
Epoch 3/10, Batch 140/145, Loss: 0.1262
Epoch 3/10, Train Loss: 0.3001, Valid Loss: 0.2434
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2266
Epoch 4/10, Batch 20/145, Loss: 0.2059
Epoch 4/10, Batch 30/145, Loss: 0.3219
Epoch 4/10, Batch 40/145, Loss: 0.1399
Epoch 4/10, Batch 50/145, Loss: 0.2682
Epoch 4/10, Batch 60/145, Loss: 0.3326
Epoch 4/10, Batch 70/145, Loss: 0.2506
Epoch 4/10, Batch 80/145, Loss: 0.2753
Epoch 4/10, Batch 90/145, Loss: 0.2804
Epoch 4/10, Batch 100/145, Loss: 0.2123
Epoch 4/10, Batch 110/145, Loss: 0.2643
Epoch 4/10, Batch 120/145, Loss: 0.1922
Epoch 4/10, Batch 130/145, Loss: 0.2201
Epoch 4/10, Batch 140/145, Loss: 0.1318
Epoch 4/10, Train Loss: 0.2557, Valid Loss: 0.2318
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1590
Epoch 5/10, Batch 20/145, Loss: 0.1542
Epoch 5/10, Batch 30/145, Loss: 0.2010
Epoch 5/10, Batch 40/145, Loss: 0.1083
Epoch 5/10, Batch 50/145, Loss: 0.1446
Epoch 5/10, Batch 60/145, Loss: 0.2436
Epoch 5/10, Batch 70/145, Loss: 0.2392
Epoch 5/10, Batch 80/145, Loss: 0.2559
Epoch 5/10, Batch 90/145, Loss: 0.2358
Epoch 5/10, Batch 100/145, Loss: 0.1969
Epoch 5/10, Batch 110/145, Loss: 0.2182
Epoch 5/10, Batch 120/145, Loss: 0.2214
Epoch 5/10, Batch 130/145, Loss: 0.1883
Epoch 5/10, Batch 140/145, Loss: 0.1848
Epoch 5/10, Train Loss: 0.2429, Valid Loss: 0.2208
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.3143
Epoch 6/10, Batch 20/145, Loss: 0.3066
Epoch 6/10, Batch 30/145, Loss: 0.2837
Epoch 6/10, Batch 40/145, Loss: 0.1559
Epoch 6/10, Batch 50/145, Loss: 0.2743
Epoch 6/10, Batch 60/145, Loss: 0.2327
Epoch 6/10, Batch 70/145, Loss: 0.1843
Epoch 6/10, Batch 80/145, Loss: 0.1400
Epoch 6/10, Batch 90/145, Loss: 0.2205
Epoch 6/10, Batch 100/145, Loss: 0.2842
Epoch 6/10, Batch 110/145, Loss: 0.3867
Epoch 6/10, Batch 120/145, Loss: 0.1299
Epoch 6/10, Batch 130/145, Loss: 0.1643
Epoch 6/10, Batch 140/145, Loss: 0.1889
Epoch 6/10, Train Loss: 0.2267, Valid Loss: 0.2127
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2313
Epoch 7/10, Batch 20/145, Loss: 0.3109
Epoch 7/10, Batch 30/145, Loss: 0.2305
Epoch 7/10, Batch 40/145, Loss: 0.3672
Epoch 7/10, Batch 50/145, Loss: 0.1698
Epoch 7/10, Batch 60/145, Loss: 0.1059
Epoch 7/10, Batch 70/145, Loss: 0.1306
Epoch 7/10, Batch 80/145, Loss: 0.2460
Epoch 7/10, Batch 90/145, Loss: 0.2102
Epoch 7/10, Batch 100/145, Loss: 0.0990
Epoch 7/10, Batch 110/145, Loss: 0.1818
Epoch 7/10, Batch 120/145, Loss: 0.1972
Epoch 7/10, Batch 130/145, Loss: 0.1200
Epoch 7/10, Batch 140/145, Loss: 0.5628
Epoch 7/10, Train Loss: 0.2167, Valid Loss: 0.2038
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1734
Epoch 8/10, Batch 20/145, Loss: 0.3328
Epoch 8/10, Batch 30/145, Loss: 0.2843
Epoch 8/10, Batch 40/145, Loss: 0.2186
Epoch 8/10, Batch 50/145, Loss: 0.1988
Epoch 8/10, Batch 60/145, Loss: 0.2042
Epoch 8/10, Batch 70/145, Loss: 0.3833
Epoch 8/10, Batch 80/145, Loss: 0.1248
Epoch 8/10, Batch 90/145, Loss: 0.2500
Epoch 8/10, Batch 100/145, Loss: 0.2746
Epoch 8/10, Batch 110/145, Loss: 0.2078
Epoch 8/10, Batch 120/145, Loss: 0.1666
Epoch 8/10, Batch 130/145, Loss: 0.1352
Epoch 8/10, Batch 140/145, Loss: 0.1021
Epoch 8/10, Train Loss: 0.2093, Valid Loss: 0.2036
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.1429
Epoch 9/10, Batch 20/145, Loss: 0.2201
Epoch 9/10, Batch 30/145, Loss: 0.1247
Epoch 9/10, Batch 40/145, Loss: 0.2573
Epoch 9/10, Batch 50/145, Loss: 0.2609
Epoch 9/10, Batch 60/145, Loss: 0.1677
Epoch 9/10, Batch 70/145, Loss: 0.1572
Epoch 9/10, Batch 80/145, Loss: 0.0649
Epoch 9/10, Batch 90/145, Loss: 0.1727
Epoch 9/10, Batch 100/145, Loss: 0.1575
Epoch 9/10, Batch 110/145, Loss: 0.2094
Epoch 9/10, Batch 120/145, Loss: 0.0711
Epoch 9/10, Batch 130/145, Loss: 0.3420
Epoch 9/10, Batch 140/145, Loss: 0.1833
Epoch 9/10, Train Loss: 0.2001, Valid Loss: 0.2042
Epoch 10/10, Batch 10/145, Loss: 0.1249
Epoch 10/10, Batch 20/145, Loss: 0.1444
Epoch 10/10, Batch 30/145, Loss: 0.1845
Epoch 10/10, Batch 40/145, Loss: 0.2763
Epoch 10/10, Batch 50/145, Loss: 0.1603
Epoch 10/10, Batch 60/145, Loss: 0.1345
Epoch 10/10, Batch 70/145, Loss: 0.2848
Epoch 10/10, Batch 80/145, Loss: 0.3145
Epoch 10/10, Batch 90/145, Loss: 0.2253
Epoch 10/10, Batch 100/145, Loss: 0.2963
Epoch 10/10, Batch 110/145, Loss: 0.1120
Epoch 10/10, Batch 120/145, Loss: 0.2547
Epoch 10/10, Batch 130/145, Loss: 0.3442
Epoch 10/10, Batch 140/145, Loss: 0.2747
Epoch 10/10, Train Loss: 0.1931, Valid Loss: 0.1988
Model saved!
Accuracy: 0.9217
Precision: 0.9195
Recall: 0.9217
F1-score: 0.9193
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3830
Epoch 1/10, Batch 20/145, Loss: 0.9994
Epoch 1/10, Batch 30/145, Loss: 0.9651
Epoch 1/10, Batch 40/145, Loss: 0.8390
Epoch 1/10, Batch 50/145, Loss: 0.9192
Epoch 1/10, Batch 60/145, Loss: 0.5758
Epoch 1/10, Batch 70/145, Loss: 0.5035
Epoch 1/10, Batch 80/145, Loss: 0.4852
Epoch 1/10, Batch 90/145, Loss: 0.5230
Epoch 1/10, Batch 100/145, Loss: 0.3991
Epoch 1/10, Batch 110/145, Loss: 0.3984
Epoch 1/10, Batch 120/145, Loss: 0.4926
Epoch 1/10, Batch 130/145, Loss: 0.4993
Epoch 1/10, Batch 140/145, Loss: 0.3100
Epoch 1/10, Train Loss: 0.6790, Valid Loss: 0.3702
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3942
Epoch 2/10, Batch 20/145, Loss: 0.4196
Epoch 2/10, Batch 30/145, Loss: 0.3056
Epoch 2/10, Batch 40/145, Loss: 0.3888
Epoch 2/10, Batch 50/145, Loss: 0.4519
Epoch 2/10, Batch 60/145, Loss: 0.4930
Epoch 2/10, Batch 70/145, Loss: 0.2158
Epoch 2/10, Batch 80/145, Loss: 0.2603
Epoch 2/10, Batch 90/145, Loss: 0.2713
Epoch 2/10, Batch 100/145, Loss: 0.3184
Epoch 2/10, Batch 110/145, Loss: 0.5004
Epoch 2/10, Batch 120/145, Loss: 0.4274
Epoch 2/10, Batch 130/145, Loss: 0.1985
Epoch 2/10, Batch 140/145, Loss: 0.3758
Epoch 2/10, Train Loss: 0.3576, Valid Loss: 0.2895
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2591
Epoch 3/10, Batch 20/145, Loss: 0.2241
Epoch 3/10, Batch 30/145, Loss: 0.3382
Epoch 3/10, Batch 40/145, Loss: 0.3976
Epoch 3/10, Batch 50/145, Loss: 0.2018
Epoch 3/10, Batch 60/145, Loss: 0.5080
Epoch 3/10, Batch 70/145, Loss: 0.2361
Epoch 3/10, Batch 80/145, Loss: 0.3377
Epoch 3/10, Batch 90/145, Loss: 0.3187
Epoch 3/10, Batch 100/145, Loss: 0.1842
Epoch 3/10, Batch 110/145, Loss: 0.2068
Epoch 3/10, Batch 120/145, Loss: 0.1628
Epoch 3/10, Batch 130/145, Loss: 0.4047
Epoch 3/10, Batch 140/145, Loss: 0.2779
Epoch 3/10, Train Loss: 0.2965, Valid Loss: 0.2521
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2140
Epoch 4/10, Batch 20/145, Loss: 0.1913
Epoch 4/10, Batch 30/145, Loss: 0.3650
Epoch 4/10, Batch 40/145, Loss: 0.1333
Epoch 4/10, Batch 50/145, Loss: 0.1183
Epoch 4/10, Batch 60/145, Loss: 0.2721
Epoch 4/10, Batch 70/145, Loss: 0.2133
Epoch 4/10, Batch 80/145, Loss: 0.3005
Epoch 4/10, Batch 90/145, Loss: 0.3310
Epoch 4/10, Batch 100/145, Loss: 0.2769
Epoch 4/10, Batch 110/145, Loss: 0.2594
Epoch 4/10, Batch 120/145, Loss: 0.1200
Epoch 4/10, Batch 130/145, Loss: 0.3321
Epoch 4/10, Batch 140/145, Loss: 0.2814
Epoch 4/10, Train Loss: 0.2582, Valid Loss: 0.2422
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2159
Epoch 5/10, Batch 20/145, Loss: 0.1214
Epoch 5/10, Batch 30/145, Loss: 0.2206
Epoch 5/10, Batch 40/145, Loss: 0.1819
Epoch 5/10, Batch 50/145, Loss: 0.2312
Epoch 5/10, Batch 60/145, Loss: 0.2490
Epoch 5/10, Batch 70/145, Loss: 0.3127
Epoch 5/10, Batch 80/145, Loss: 0.1752
Epoch 5/10, Batch 90/145, Loss: 0.3484
Epoch 5/10, Batch 100/145, Loss: 0.2480
Epoch 5/10, Batch 110/145, Loss: 0.1951
Epoch 5/10, Batch 120/145, Loss: 0.2935
Epoch 5/10, Batch 130/145, Loss: 0.2787
Epoch 5/10, Batch 140/145, Loss: 0.2421
Epoch 5/10, Train Loss: 0.2446, Valid Loss: 0.2268
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1314
Epoch 6/10, Batch 20/145, Loss: 0.4601
Epoch 6/10, Batch 30/145, Loss: 0.3408
Epoch 6/10, Batch 40/145, Loss: 0.1053
Epoch 6/10, Batch 50/145, Loss: 0.2514
Epoch 6/10, Batch 60/145, Loss: 0.2367
Epoch 6/10, Batch 70/145, Loss: 0.1452
Epoch 6/10, Batch 80/145, Loss: 0.1031
Epoch 6/10, Batch 90/145, Loss: 0.3137
Epoch 6/10, Batch 100/145, Loss: 0.2940
Epoch 6/10, Batch 110/145, Loss: 0.1738
Epoch 6/10, Batch 120/145, Loss: 0.2227
Epoch 6/10, Batch 130/145, Loss: 0.1673
Epoch 6/10, Batch 140/145, Loss: 0.1974
Epoch 6/10, Train Loss: 0.2227, Valid Loss: 0.2198
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2566
Epoch 7/10, Batch 20/145, Loss: 0.3519
Epoch 7/10, Batch 30/145, Loss: 0.1629
Epoch 7/10, Batch 40/145, Loss: 0.2103
Epoch 7/10, Batch 50/145, Loss: 0.1336
Epoch 7/10, Batch 60/145, Loss: 0.1983
Epoch 7/10, Batch 70/145, Loss: 0.1404
Epoch 7/10, Batch 80/145, Loss: 0.3853
Epoch 7/10, Batch 90/145, Loss: 0.1445
Epoch 7/10, Batch 100/145, Loss: 0.2789
Epoch 7/10, Batch 110/145, Loss: 0.2204
Epoch 7/10, Batch 120/145, Loss: 0.2574
Epoch 7/10, Batch 130/145, Loss: 0.1041
Epoch 7/10, Batch 140/145, Loss: 0.2102
Epoch 7/10, Train Loss: 0.2079, Valid Loss: 0.2197
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2003
Epoch 8/10, Batch 20/145, Loss: 0.1441
Epoch 8/10, Batch 30/145, Loss: 0.2586
Epoch 8/10, Batch 40/145, Loss: 0.2536
Epoch 8/10, Batch 50/145, Loss: 0.3235
Epoch 8/10, Batch 60/145, Loss: 0.2008
Epoch 8/10, Batch 70/145, Loss: 0.2651
Epoch 8/10, Batch 80/145, Loss: 0.2968
Epoch 8/10, Batch 90/145, Loss: 0.3737
Epoch 8/10, Batch 100/145, Loss: 0.2245
Epoch 8/10, Batch 110/145, Loss: 0.1682
Epoch 8/10, Batch 120/145, Loss: 0.1106
Epoch 8/10, Batch 130/145, Loss: 0.1280
Epoch 8/10, Batch 140/145, Loss: 0.1969
Epoch 8/10, Train Loss: 0.2120, Valid Loss: 0.2160
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2696
Epoch 9/10, Batch 20/145, Loss: 0.2863
Epoch 9/10, Batch 30/145, Loss: 0.1822
Epoch 9/10, Batch 40/145, Loss: 0.2476
Epoch 9/10, Batch 50/145, Loss: 0.0903
Epoch 9/10, Batch 60/145, Loss: 0.2478
Epoch 9/10, Batch 70/145, Loss: 0.2468
Epoch 9/10, Batch 80/145, Loss: 0.0827
Epoch 9/10, Batch 90/145, Loss: 0.2031
Epoch 9/10, Batch 100/145, Loss: 0.1140
Epoch 9/10, Batch 110/145, Loss: 0.2090
Epoch 9/10, Batch 120/145, Loss: 0.2683
Epoch 9/10, Batch 130/145, Loss: 0.1532
Epoch 9/10, Batch 140/145, Loss: 0.1717
Epoch 9/10, Train Loss: 0.1990, Valid Loss: 0.2144
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0692
Epoch 10/10, Batch 20/145, Loss: 0.1264
Epoch 10/10, Batch 30/145, Loss: 0.1291
Epoch 10/10, Batch 40/145, Loss: 0.1775
Epoch 10/10, Batch 50/145, Loss: 0.2009
Epoch 10/10, Batch 60/145, Loss: 0.0951
Epoch 10/10, Batch 70/145, Loss: 0.2084
Epoch 10/10, Batch 80/145, Loss: 0.3427
Epoch 10/10, Batch 90/145, Loss: 0.2383
Epoch 10/10, Batch 100/145, Loss: 0.1903
Epoch 10/10, Batch 110/145, Loss: 0.2465
Epoch 10/10, Batch 120/145, Loss: 0.2847
Epoch 10/10, Batch 130/145, Loss: 0.1015
Epoch 10/10, Batch 140/145, Loss: 0.2353
Epoch 10/10, Train Loss: 0.1863, Valid Loss: 0.2114
Model saved!
Accuracy: 0.9171
Precision: 0.9142
Recall: 0.9171
F1-score: 0.9144
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4031
Epoch 1/10, Batch 20/145, Loss: 0.9122
Epoch 1/10, Batch 30/145, Loss: 0.9782
Epoch 1/10, Batch 40/145, Loss: 0.7786
Epoch 1/10, Batch 50/145, Loss: 0.7395
Epoch 1/10, Batch 60/145, Loss: 0.6345
Epoch 1/10, Batch 70/145, Loss: 0.5813
Epoch 1/10, Batch 80/145, Loss: 0.8149
Epoch 1/10, Batch 90/145, Loss: 0.5672
Epoch 1/10, Batch 100/145, Loss: 0.5326
Epoch 1/10, Batch 110/145, Loss: 0.3802
Epoch 1/10, Batch 120/145, Loss: 0.4463
Epoch 1/10, Batch 130/145, Loss: 0.4820
Epoch 1/10, Batch 140/145, Loss: 0.3649
Epoch 1/10, Train Loss: 0.6797, Valid Loss: 0.3640
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3108
Epoch 2/10, Batch 20/145, Loss: 0.3040
Epoch 2/10, Batch 30/145, Loss: 0.3317
Epoch 2/10, Batch 40/145, Loss: 0.3950
Epoch 2/10, Batch 50/145, Loss: 0.2413
Epoch 2/10, Batch 60/145, Loss: 0.3622
Epoch 2/10, Batch 70/145, Loss: 0.4589
Epoch 2/10, Batch 80/145, Loss: 0.4568
Epoch 2/10, Batch 90/145, Loss: 0.3011
Epoch 2/10, Batch 100/145, Loss: 0.3274
Epoch 2/10, Batch 110/145, Loss: 0.3685
Epoch 2/10, Batch 120/145, Loss: 0.3211
Epoch 2/10, Batch 130/145, Loss: 0.2966
Epoch 2/10, Batch 140/145, Loss: 0.2321
Epoch 2/10, Train Loss: 0.3563, Valid Loss: 0.2851
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3626
Epoch 3/10, Batch 20/145, Loss: 0.2406
Epoch 3/10, Batch 30/145, Loss: 0.5238
Epoch 3/10, Batch 40/145, Loss: 0.3584
Epoch 3/10, Batch 50/145, Loss: 0.1925
Epoch 3/10, Batch 60/145, Loss: 0.2690
Epoch 3/10, Batch 70/145, Loss: 0.3121
Epoch 3/10, Batch 80/145, Loss: 0.1457
Epoch 3/10, Batch 90/145, Loss: 0.2382
Epoch 3/10, Batch 100/145, Loss: 0.2623
Epoch 3/10, Batch 110/145, Loss: 0.1952
Epoch 3/10, Batch 120/145, Loss: 0.3309
Epoch 3/10, Batch 130/145, Loss: 0.3751
Epoch 3/10, Batch 140/145, Loss: 0.2477
Epoch 3/10, Train Loss: 0.2979, Valid Loss: 0.2592
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3780
Epoch 4/10, Batch 20/145, Loss: 0.4964
Epoch 4/10, Batch 30/145, Loss: 0.2598
Epoch 4/10, Batch 40/145, Loss: 0.1992
Epoch 4/10, Batch 50/145, Loss: 0.1386
Epoch 4/10, Batch 60/145, Loss: 0.3451
Epoch 4/10, Batch 70/145, Loss: 0.2555
Epoch 4/10, Batch 80/145, Loss: 0.2116
Epoch 4/10, Batch 90/145, Loss: 0.3372
Epoch 4/10, Batch 100/145, Loss: 0.4034
Epoch 4/10, Batch 110/145, Loss: 0.2715
Epoch 4/10, Batch 120/145, Loss: 0.4103
Epoch 4/10, Batch 130/145, Loss: 0.1672
Epoch 4/10, Batch 140/145, Loss: 0.1230
Epoch 4/10, Train Loss: 0.2606, Valid Loss: 0.2380
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2452
Epoch 5/10, Batch 20/145, Loss: 0.2957
Epoch 5/10, Batch 30/145, Loss: 0.2943
Epoch 5/10, Batch 40/145, Loss: 0.1802
Epoch 5/10, Batch 50/145, Loss: 0.1581
Epoch 5/10, Batch 60/145, Loss: 0.2469
Epoch 5/10, Batch 70/145, Loss: 0.2765
Epoch 5/10, Batch 80/145, Loss: 0.2224
Epoch 5/10, Batch 90/145, Loss: 0.3082
Epoch 5/10, Batch 100/145, Loss: 0.2680
Epoch 5/10, Batch 110/145, Loss: 0.1750
Epoch 5/10, Batch 120/145, Loss: 0.3067
Epoch 5/10, Batch 130/145, Loss: 0.2410
Epoch 5/10, Batch 140/145, Loss: 0.2322
Epoch 5/10, Train Loss: 0.2521, Valid Loss: 0.2350
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2138
Epoch 6/10, Batch 20/145, Loss: 0.4330
Epoch 6/10, Batch 30/145, Loss: 0.4626
Epoch 6/10, Batch 40/145, Loss: 0.1731
Epoch 6/10, Batch 50/145, Loss: 0.1979
Epoch 6/10, Batch 60/145, Loss: 0.2799
Epoch 6/10, Batch 70/145, Loss: 0.2407
Epoch 6/10, Batch 80/145, Loss: 0.2035
Epoch 6/10, Batch 90/145, Loss: 0.3803
Epoch 6/10, Batch 100/145, Loss: 0.2576
Epoch 6/10, Batch 110/145, Loss: 0.1671
Epoch 6/10, Batch 120/145, Loss: 0.2876
Epoch 6/10, Batch 130/145, Loss: 0.1327
Epoch 6/10, Batch 140/145, Loss: 0.1032
Epoch 6/10, Train Loss: 0.2324, Valid Loss: 0.2208
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2892
Epoch 7/10, Batch 20/145, Loss: 0.2486
Epoch 7/10, Batch 30/145, Loss: 0.2775
Epoch 7/10, Batch 40/145, Loss: 0.2936
Epoch 7/10, Batch 50/145, Loss: 0.1761
Epoch 7/10, Batch 60/145, Loss: 0.1608
Epoch 7/10, Batch 70/145, Loss: 0.1114
Epoch 7/10, Batch 80/145, Loss: 0.2997
Epoch 7/10, Batch 90/145, Loss: 0.1378
Epoch 7/10, Batch 100/145, Loss: 0.1221
Epoch 7/10, Batch 110/145, Loss: 0.0558
Epoch 7/10, Batch 120/145, Loss: 0.4839
Epoch 7/10, Batch 130/145, Loss: 0.0983
Epoch 7/10, Batch 140/145, Loss: 0.2259
Epoch 7/10, Train Loss: 0.2203, Valid Loss: 0.2226
Epoch 8/10, Batch 10/145, Loss: 0.1820
Epoch 8/10, Batch 20/145, Loss: 0.1705
Epoch 8/10, Batch 30/145, Loss: 0.3937
Epoch 8/10, Batch 40/145, Loss: 0.2025
Epoch 8/10, Batch 50/145, Loss: 0.2448
Epoch 8/10, Batch 60/145, Loss: 0.1605
Epoch 8/10, Batch 70/145, Loss: 0.2163
Epoch 8/10, Batch 80/145, Loss: 0.2388
Epoch 8/10, Batch 90/145, Loss: 0.3440
Epoch 8/10, Batch 100/145, Loss: 0.1582
Epoch 8/10, Batch 110/145, Loss: 0.5151
Epoch 8/10, Batch 120/145, Loss: 0.1564
Epoch 8/10, Batch 130/145, Loss: 0.2108
Epoch 8/10, Batch 140/145, Loss: 0.3771
Epoch 8/10, Train Loss: 0.2175, Valid Loss: 0.2151
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.4300
Epoch 9/10, Batch 20/145, Loss: 0.1057
Epoch 9/10, Batch 30/145, Loss: 0.0717
Epoch 9/10, Batch 40/145, Loss: 0.2118
Epoch 9/10, Batch 50/145, Loss: 0.1109
Epoch 9/10, Batch 60/145, Loss: 0.2740
Epoch 9/10, Batch 70/145, Loss: 0.2077
Epoch 9/10, Batch 80/145, Loss: 0.1394
Epoch 9/10, Batch 90/145, Loss: 0.3153
Epoch 9/10, Batch 100/145, Loss: 0.2503
Epoch 9/10, Batch 110/145, Loss: 0.2659
Epoch 9/10, Batch 120/145, Loss: 0.1393
Epoch 9/10, Batch 130/145, Loss: 0.1674
Epoch 9/10, Batch 140/145, Loss: 0.2304
Epoch 9/10, Train Loss: 0.1986, Valid Loss: 0.2075
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1251
Epoch 10/10, Batch 20/145, Loss: 0.1722
Epoch 10/10, Batch 30/145, Loss: 0.1110
Epoch 10/10, Batch 40/145, Loss: 0.1756
Epoch 10/10, Batch 50/145, Loss: 0.1748
Epoch 10/10, Batch 60/145, Loss: 0.1382
Epoch 10/10, Batch 70/145, Loss: 0.3440
Epoch 10/10, Batch 80/145, Loss: 0.1466
Epoch 10/10, Batch 90/145, Loss: 0.3321
Epoch 10/10, Batch 100/145, Loss: 0.1127
Epoch 10/10, Batch 110/145, Loss: 0.1914
Epoch 10/10, Batch 120/145, Loss: 0.3440
Epoch 10/10, Batch 130/145, Loss: 0.1096
Epoch 10/10, Batch 140/145, Loss: 0.2060
Epoch 10/10, Train Loss: 0.2039, Valid Loss: 0.2125
Accuracy: 0.9100
Precision: 0.9078
Recall: 0.9100
F1-score: 0.9084
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4288
Epoch 1/10, Batch 20/145, Loss: 0.9801
Epoch 1/10, Batch 30/145, Loss: 0.9597
Epoch 1/10, Batch 40/145, Loss: 0.7790
Epoch 1/10, Batch 50/145, Loss: 0.6640
Epoch 1/10, Batch 60/145, Loss: 0.5428
Epoch 1/10, Batch 70/145, Loss: 0.4598
Epoch 1/10, Batch 80/145, Loss: 0.5826
Epoch 1/10, Batch 90/145, Loss: 0.5201
Epoch 1/10, Batch 100/145, Loss: 0.5762
Epoch 1/10, Batch 110/145, Loss: 0.5703
Epoch 1/10, Batch 120/145, Loss: 0.7458
Epoch 1/10, Batch 130/145, Loss: 0.5704
Epoch 1/10, Batch 140/145, Loss: 0.3617
Epoch 1/10, Train Loss: 0.6882, Valid Loss: 0.3692
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2437
Epoch 2/10, Batch 20/145, Loss: 0.3847
Epoch 2/10, Batch 30/145, Loss: 0.2821
Epoch 2/10, Batch 40/145, Loss: 0.4724
Epoch 2/10, Batch 50/145, Loss: 0.2792
Epoch 2/10, Batch 60/145, Loss: 0.4266
Epoch 2/10, Batch 70/145, Loss: 0.3561
Epoch 2/10, Batch 80/145, Loss: 0.4859
Epoch 2/10, Batch 90/145, Loss: 0.2780
Epoch 2/10, Batch 100/145, Loss: 0.3143
Epoch 2/10, Batch 110/145, Loss: 0.3958
Epoch 2/10, Batch 120/145, Loss: 0.4330
Epoch 2/10, Batch 130/145, Loss: 0.2944
Epoch 2/10, Batch 140/145, Loss: 0.3311
Epoch 2/10, Train Loss: 0.3635, Valid Loss: 0.2918
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3311
Epoch 3/10, Batch 20/145, Loss: 0.3095
Epoch 3/10, Batch 30/145, Loss: 0.3563
Epoch 3/10, Batch 40/145, Loss: 0.2344
Epoch 3/10, Batch 50/145, Loss: 0.2374
Epoch 3/10, Batch 60/145, Loss: 0.3564
Epoch 3/10, Batch 70/145, Loss: 0.2678
Epoch 3/10, Batch 80/145, Loss: 0.1993
Epoch 3/10, Batch 90/145, Loss: 0.1544
Epoch 3/10, Batch 100/145, Loss: 0.3293
Epoch 3/10, Batch 110/145, Loss: 0.1625
Epoch 3/10, Batch 120/145, Loss: 0.3372
Epoch 3/10, Batch 130/145, Loss: 0.2723
Epoch 3/10, Batch 140/145, Loss: 0.3572
Epoch 3/10, Train Loss: 0.3040, Valid Loss: 0.2587
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4388
Epoch 4/10, Batch 20/145, Loss: 0.3685
Epoch 4/10, Batch 30/145, Loss: 0.2102
Epoch 4/10, Batch 40/145, Loss: 0.2788
Epoch 4/10, Batch 50/145, Loss: 0.1773
Epoch 4/10, Batch 60/145, Loss: 0.2283
Epoch 4/10, Batch 70/145, Loss: 0.4169
Epoch 4/10, Batch 80/145, Loss: 0.2872
Epoch 4/10, Batch 90/145, Loss: 0.1888
Epoch 4/10, Batch 100/145, Loss: 0.3208
Epoch 4/10, Batch 110/145, Loss: 0.2866
Epoch 4/10, Batch 120/145, Loss: 0.3284
Epoch 4/10, Batch 130/145, Loss: 0.1914
Epoch 4/10, Batch 140/145, Loss: 0.0852
Epoch 4/10, Train Loss: 0.2705, Valid Loss: 0.2442
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3156
Epoch 5/10, Batch 20/145, Loss: 0.2008
Epoch 5/10, Batch 30/145, Loss: 0.2884
Epoch 5/10, Batch 40/145, Loss: 0.3125
Epoch 5/10, Batch 50/145, Loss: 0.1843
Epoch 5/10, Batch 60/145, Loss: 0.1795
Epoch 5/10, Batch 70/145, Loss: 0.3595
Epoch 5/10, Batch 80/145, Loss: 0.1923
Epoch 5/10, Batch 90/145, Loss: 0.3506
Epoch 5/10, Batch 100/145, Loss: 0.1891
Epoch 5/10, Batch 110/145, Loss: 0.2132
Epoch 5/10, Batch 120/145, Loss: 0.2862
Epoch 5/10, Batch 130/145, Loss: 0.1978
Epoch 5/10, Batch 140/145, Loss: 0.2555
Epoch 5/10, Train Loss: 0.2594, Valid Loss: 0.2352
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2514
Epoch 6/10, Batch 20/145, Loss: 0.4751
Epoch 6/10, Batch 30/145, Loss: 0.2260
Epoch 6/10, Batch 40/145, Loss: 0.1347
Epoch 6/10, Batch 50/145, Loss: 0.2977
Epoch 6/10, Batch 60/145, Loss: 0.3553
Epoch 6/10, Batch 70/145, Loss: 0.1789
Epoch 6/10, Batch 80/145, Loss: 0.2104
Epoch 6/10, Batch 90/145, Loss: 0.3410
Epoch 6/10, Batch 100/145, Loss: 0.3177
Epoch 6/10, Batch 110/145, Loss: 0.2383
Epoch 6/10, Batch 120/145, Loss: 0.4753
Epoch 6/10, Batch 130/145, Loss: 0.2320
Epoch 6/10, Batch 140/145, Loss: 0.1541
Epoch 6/10, Train Loss: 0.2406, Valid Loss: 0.2240
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.4481
Epoch 7/10, Batch 20/145, Loss: 0.1412
Epoch 7/10, Batch 30/145, Loss: 0.2969
Epoch 7/10, Batch 40/145, Loss: 0.4422
Epoch 7/10, Batch 50/145, Loss: 0.2492
Epoch 7/10, Batch 60/145, Loss: 0.1183
Epoch 7/10, Batch 70/145, Loss: 0.1307
Epoch 7/10, Batch 80/145, Loss: 0.1996
Epoch 7/10, Batch 90/145, Loss: 0.1071
Epoch 7/10, Batch 100/145, Loss: 0.1679
Epoch 7/10, Batch 110/145, Loss: 0.2117
Epoch 7/10, Batch 120/145, Loss: 0.2413
Epoch 7/10, Batch 130/145, Loss: 0.1348
Epoch 7/10, Batch 140/145, Loss: 0.3572
Epoch 7/10, Train Loss: 0.2237, Valid Loss: 0.2144
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1950
Epoch 8/10, Batch 20/145, Loss: 0.2266
Epoch 8/10, Batch 30/145, Loss: 0.1979
Epoch 8/10, Batch 40/145, Loss: 0.1385
Epoch 8/10, Batch 50/145, Loss: 0.2983
Epoch 8/10, Batch 60/145, Loss: 0.2685
Epoch 8/10, Batch 70/145, Loss: 0.3676
Epoch 8/10, Batch 80/145, Loss: 0.2495
Epoch 8/10, Batch 90/145, Loss: 0.2143
Epoch 8/10, Batch 100/145, Loss: 0.2107
Epoch 8/10, Batch 110/145, Loss: 0.2019
Epoch 8/10, Batch 120/145, Loss: 0.1881
Epoch 8/10, Batch 130/145, Loss: 0.3176
Epoch 8/10, Batch 140/145, Loss: 0.1861
Epoch 8/10, Train Loss: 0.2235, Valid Loss: 0.2083
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3004
Epoch 9/10, Batch 20/145, Loss: 0.1414
Epoch 9/10, Batch 30/145, Loss: 0.1441
Epoch 9/10, Batch 40/145, Loss: 0.1380
Epoch 9/10, Batch 50/145, Loss: 0.2152
Epoch 9/10, Batch 60/145, Loss: 0.2805
Epoch 9/10, Batch 70/145, Loss: 0.2571
Epoch 9/10, Batch 80/145, Loss: 0.0788
Epoch 9/10, Batch 90/145, Loss: 0.2795
Epoch 9/10, Batch 100/145, Loss: 0.1589
Epoch 9/10, Batch 110/145, Loss: 0.2057
Epoch 9/10, Batch 120/145, Loss: 0.0800
Epoch 9/10, Batch 130/145, Loss: 0.4015
Epoch 9/10, Batch 140/145, Loss: 0.2905
Epoch 9/10, Train Loss: 0.2054, Valid Loss: 0.2126
Epoch 10/10, Batch 10/145, Loss: 0.1507
Epoch 10/10, Batch 20/145, Loss: 0.3589
Epoch 10/10, Batch 30/145, Loss: 0.0939
Epoch 10/10, Batch 40/145, Loss: 0.2699
Epoch 10/10, Batch 50/145, Loss: 0.3363
Epoch 10/10, Batch 60/145, Loss: 0.1374
Epoch 10/10, Batch 70/145, Loss: 0.1638
Epoch 10/10, Batch 80/145, Loss: 0.0849
Epoch 10/10, Batch 90/145, Loss: 0.2272
Epoch 10/10, Batch 100/145, Loss: 0.0923
Epoch 10/10, Batch 110/145, Loss: 0.1467
Epoch 10/10, Batch 120/145, Loss: 0.2286
Epoch 10/10, Batch 130/145, Loss: 0.1505
Epoch 10/10, Batch 140/145, Loss: 0.3220
Epoch 10/10, Train Loss: 0.2027, Valid Loss: 0.2141
Accuracy: 0.9100
Precision: 0.9068
Recall: 0.9100
F1-score: 0.9077
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3116
Epoch 1/10, Batch 20/145, Loss: 0.8847
Epoch 1/10, Batch 30/145, Loss: 0.8619
Epoch 1/10, Batch 40/145, Loss: 0.8055
Epoch 1/10, Batch 50/145, Loss: 0.6755
Epoch 1/10, Batch 60/145, Loss: 0.7457
Epoch 1/10, Batch 70/145, Loss: 0.4369
Epoch 1/10, Batch 80/145, Loss: 0.5565
Epoch 1/10, Batch 90/145, Loss: 0.5196
Epoch 1/10, Batch 100/145, Loss: 0.5248
Epoch 1/10, Batch 110/145, Loss: 0.4065
Epoch 1/10, Batch 120/145, Loss: 0.5027
Epoch 1/10, Batch 130/145, Loss: 0.4535
Epoch 1/10, Batch 140/145, Loss: 0.3196
Epoch 1/10, Train Loss: 0.6796, Valid Loss: 0.3620
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2519
Epoch 2/10, Batch 20/145, Loss: 0.3585
Epoch 2/10, Batch 30/145, Loss: 0.3359
Epoch 2/10, Batch 40/145, Loss: 0.5388
Epoch 2/10, Batch 50/145, Loss: 0.3258
Epoch 2/10, Batch 60/145, Loss: 0.4293
Epoch 2/10, Batch 70/145, Loss: 0.3529
Epoch 2/10, Batch 80/145, Loss: 0.4831
Epoch 2/10, Batch 90/145, Loss: 0.2759
Epoch 2/10, Batch 100/145, Loss: 0.2899
Epoch 2/10, Batch 110/145, Loss: 0.3776
Epoch 2/10, Batch 120/145, Loss: 0.4763
Epoch 2/10, Batch 130/145, Loss: 0.3662
Epoch 2/10, Batch 140/145, Loss: 0.2706
Epoch 2/10, Train Loss: 0.3541, Valid Loss: 0.2777
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2663
Epoch 3/10, Batch 20/145, Loss: 0.4467
Epoch 3/10, Batch 30/145, Loss: 0.4428
Epoch 3/10, Batch 40/145, Loss: 0.2348
Epoch 3/10, Batch 50/145, Loss: 0.2952
Epoch 3/10, Batch 60/145, Loss: 0.2680
Epoch 3/10, Batch 70/145, Loss: 0.5682
Epoch 3/10, Batch 80/145, Loss: 0.2528
Epoch 3/10, Batch 90/145, Loss: 0.2752
Epoch 3/10, Batch 100/145, Loss: 0.2531
Epoch 3/10, Batch 110/145, Loss: 0.2605
Epoch 3/10, Batch 120/145, Loss: 0.1998
Epoch 3/10, Batch 130/145, Loss: 0.2666
Epoch 3/10, Batch 140/145, Loss: 0.3615
Epoch 3/10, Train Loss: 0.2935, Valid Loss: 0.2446
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2968
Epoch 4/10, Batch 20/145, Loss: 0.1672
Epoch 4/10, Batch 30/145, Loss: 0.1960
Epoch 4/10, Batch 40/145, Loss: 0.2934
Epoch 4/10, Batch 50/145, Loss: 0.2555
Epoch 4/10, Batch 60/145, Loss: 0.2697
Epoch 4/10, Batch 70/145, Loss: 0.1477
Epoch 4/10, Batch 80/145, Loss: 0.3023
Epoch 4/10, Batch 90/145, Loss: 0.2588
Epoch 4/10, Batch 100/145, Loss: 0.3509
Epoch 4/10, Batch 110/145, Loss: 0.1815
Epoch 4/10, Batch 120/145, Loss: 0.2459
Epoch 4/10, Batch 130/145, Loss: 0.1860
Epoch 4/10, Batch 140/145, Loss: 0.1467
Epoch 4/10, Train Loss: 0.2564, Valid Loss: 0.2331
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1776
Epoch 5/10, Batch 20/145, Loss: 0.1396
Epoch 5/10, Batch 30/145, Loss: 0.2096
Epoch 5/10, Batch 40/145, Loss: 0.2220
Epoch 5/10, Batch 50/145, Loss: 0.2043
Epoch 5/10, Batch 60/145, Loss: 0.3637
Epoch 5/10, Batch 70/145, Loss: 0.1935
Epoch 5/10, Batch 80/145, Loss: 0.1014
Epoch 5/10, Batch 90/145, Loss: 0.3502
Epoch 5/10, Batch 100/145, Loss: 0.2505
Epoch 5/10, Batch 110/145, Loss: 0.1830
Epoch 5/10, Batch 120/145, Loss: 0.2668
Epoch 5/10, Batch 130/145, Loss: 0.2542
Epoch 5/10, Batch 140/145, Loss: 0.1973
Epoch 5/10, Train Loss: 0.2423, Valid Loss: 0.2146
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1226
Epoch 6/10, Batch 20/145, Loss: 0.4935
Epoch 6/10, Batch 30/145, Loss: 0.3367
Epoch 6/10, Batch 40/145, Loss: 0.2914
Epoch 6/10, Batch 50/145, Loss: 0.3256
Epoch 6/10, Batch 60/145, Loss: 0.2297
Epoch 6/10, Batch 70/145, Loss: 0.1412
Epoch 6/10, Batch 80/145, Loss: 0.1284
Epoch 6/10, Batch 90/145, Loss: 0.4438
Epoch 6/10, Batch 100/145, Loss: 0.2621
Epoch 6/10, Batch 110/145, Loss: 0.3678
Epoch 6/10, Batch 120/145, Loss: 0.2762
Epoch 6/10, Batch 130/145, Loss: 0.1298
Epoch 6/10, Batch 140/145, Loss: 0.1534
Epoch 6/10, Train Loss: 0.2313, Valid Loss: 0.2097
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2205
Epoch 7/10, Batch 20/145, Loss: 0.1980
Epoch 7/10, Batch 30/145, Loss: 0.1697
Epoch 7/10, Batch 40/145, Loss: 0.1929
Epoch 7/10, Batch 50/145, Loss: 0.1906
Epoch 7/10, Batch 60/145, Loss: 0.1424
Epoch 7/10, Batch 70/145, Loss: 0.1213
Epoch 7/10, Batch 80/145, Loss: 0.3767
Epoch 7/10, Batch 90/145, Loss: 0.1142
Epoch 7/10, Batch 100/145, Loss: 0.1234
Epoch 7/10, Batch 110/145, Loss: 0.2837
Epoch 7/10, Batch 120/145, Loss: 0.2352
Epoch 7/10, Batch 130/145, Loss: 0.2548
Epoch 7/10, Batch 140/145, Loss: 0.2751
Epoch 7/10, Train Loss: 0.2155, Valid Loss: 0.2057
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2383
Epoch 8/10, Batch 20/145, Loss: 0.0859
Epoch 8/10, Batch 30/145, Loss: 0.1789
Epoch 8/10, Batch 40/145, Loss: 0.1449
Epoch 8/10, Batch 50/145, Loss: 0.2976
Epoch 8/10, Batch 60/145, Loss: 0.1450
Epoch 8/10, Batch 70/145, Loss: 0.1761
Epoch 8/10, Batch 80/145, Loss: 0.3453
Epoch 8/10, Batch 90/145, Loss: 0.3312
Epoch 8/10, Batch 100/145, Loss: 0.2251
Epoch 8/10, Batch 110/145, Loss: 0.2753
Epoch 8/10, Batch 120/145, Loss: 0.0869
Epoch 8/10, Batch 130/145, Loss: 0.3315
Epoch 8/10, Batch 140/145, Loss: 0.1902
Epoch 8/10, Train Loss: 0.2095, Valid Loss: 0.2035
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3924
Epoch 9/10, Batch 20/145, Loss: 0.2206
Epoch 9/10, Batch 30/145, Loss: 0.1751
Epoch 9/10, Batch 40/145, Loss: 0.1726
Epoch 9/10, Batch 50/145, Loss: 0.1376
Epoch 9/10, Batch 60/145, Loss: 0.1989
Epoch 9/10, Batch 70/145, Loss: 0.1426
Epoch 9/10, Batch 80/145, Loss: 0.1946
Epoch 9/10, Batch 90/145, Loss: 0.2398
Epoch 9/10, Batch 100/145, Loss: 0.2286
Epoch 9/10, Batch 110/145, Loss: 0.2472
Epoch 9/10, Batch 120/145, Loss: 0.1183
Epoch 9/10, Batch 130/145, Loss: 0.1245
Epoch 9/10, Batch 140/145, Loss: 0.1062
Epoch 9/10, Train Loss: 0.1993, Valid Loss: 0.1961
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0545
Epoch 10/10, Batch 20/145, Loss: 0.1884
Epoch 10/10, Batch 30/145, Loss: 0.0593
Epoch 10/10, Batch 40/145, Loss: 0.0818
Epoch 10/10, Batch 50/145, Loss: 0.2958
Epoch 10/10, Batch 60/145, Loss: 0.1375
Epoch 10/10, Batch 70/145, Loss: 0.3627
Epoch 10/10, Batch 80/145, Loss: 0.0945
Epoch 10/10, Batch 90/145, Loss: 0.1241
Epoch 10/10, Batch 100/145, Loss: 0.1196
Epoch 10/10, Batch 110/145, Loss: 0.2879
Epoch 10/10, Batch 120/145, Loss: 0.2770
Epoch 10/10, Batch 130/145, Loss: 0.1739
Epoch 10/10, Batch 140/145, Loss: 0.3138
Epoch 10/10, Train Loss: 0.1866, Valid Loss: 0.1981
Accuracy: 0.9136
Precision: 0.9110
Recall: 0.9136
F1-score: 0.9113
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3881
Epoch 1/10, Batch 20/145, Loss: 0.9014
Epoch 1/10, Batch 30/145, Loss: 0.8953
Epoch 1/10, Batch 40/145, Loss: 0.8151
Epoch 1/10, Batch 50/145, Loss: 0.7014
Epoch 1/10, Batch 60/145, Loss: 0.5938
Epoch 1/10, Batch 70/145, Loss: 0.4537
Epoch 1/10, Batch 80/145, Loss: 0.6314
Epoch 1/10, Batch 90/145, Loss: 0.4751
Epoch 1/10, Batch 100/145, Loss: 0.4546
Epoch 1/10, Batch 110/145, Loss: 0.3033
Epoch 1/10, Batch 120/145, Loss: 0.7440
Epoch 1/10, Batch 130/145, Loss: 0.6739
Epoch 1/10, Batch 140/145, Loss: 0.4898
Epoch 1/10, Train Loss: 0.6816, Valid Loss: 0.3904
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3421
Epoch 2/10, Batch 20/145, Loss: 0.3965
Epoch 2/10, Batch 30/145, Loss: 0.2503
Epoch 2/10, Batch 40/145, Loss: 0.4916
Epoch 2/10, Batch 50/145, Loss: 0.3685
Epoch 2/10, Batch 60/145, Loss: 0.5273
Epoch 2/10, Batch 70/145, Loss: 0.3402
Epoch 2/10, Batch 80/145, Loss: 0.2706
Epoch 2/10, Batch 90/145, Loss: 0.2852
Epoch 2/10, Batch 100/145, Loss: 0.2165
Epoch 2/10, Batch 110/145, Loss: 0.3115
Epoch 2/10, Batch 120/145, Loss: 0.3484
Epoch 2/10, Batch 130/145, Loss: 0.2454
Epoch 2/10, Batch 140/145, Loss: 0.3712
Epoch 2/10, Train Loss: 0.3582, Valid Loss: 0.3055
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2979
Epoch 3/10, Batch 20/145, Loss: 0.2271
Epoch 3/10, Batch 30/145, Loss: 0.2978
Epoch 3/10, Batch 40/145, Loss: 0.2482
Epoch 3/10, Batch 50/145, Loss: 0.3429
Epoch 3/10, Batch 60/145, Loss: 0.3493
Epoch 3/10, Batch 70/145, Loss: 0.2823
Epoch 3/10, Batch 80/145, Loss: 0.3019
Epoch 3/10, Batch 90/145, Loss: 0.3273
Epoch 3/10, Batch 100/145, Loss: 0.3147
Epoch 3/10, Batch 110/145, Loss: 0.2042
Epoch 3/10, Batch 120/145, Loss: 0.1947
Epoch 3/10, Batch 130/145, Loss: 0.2753
Epoch 3/10, Batch 140/145, Loss: 0.1452
Epoch 3/10, Train Loss: 0.2947, Valid Loss: 0.2721
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4135
Epoch 4/10, Batch 20/145, Loss: 0.3343
Epoch 4/10, Batch 30/145, Loss: 0.2279
Epoch 4/10, Batch 40/145, Loss: 0.1765
Epoch 4/10, Batch 50/145, Loss: 0.1846
Epoch 4/10, Batch 60/145, Loss: 0.1493
Epoch 4/10, Batch 70/145, Loss: 0.2206
Epoch 4/10, Batch 80/145, Loss: 0.1103
Epoch 4/10, Batch 90/145, Loss: 0.2516
Epoch 4/10, Batch 100/145, Loss: 0.3277
Epoch 4/10, Batch 110/145, Loss: 0.1856
Epoch 4/10, Batch 120/145, Loss: 0.3052
Epoch 4/10, Batch 130/145, Loss: 0.1465
Epoch 4/10, Batch 140/145, Loss: 0.2834
Epoch 4/10, Train Loss: 0.2560, Valid Loss: 0.2571
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2191
Epoch 5/10, Batch 20/145, Loss: 0.1038
Epoch 5/10, Batch 30/145, Loss: 0.4009
Epoch 5/10, Batch 40/145, Loss: 0.1330
Epoch 5/10, Batch 50/145, Loss: 0.1793
Epoch 5/10, Batch 60/145, Loss: 0.1793
Epoch 5/10, Batch 70/145, Loss: 0.2910
Epoch 5/10, Batch 80/145, Loss: 0.1486
Epoch 5/10, Batch 90/145, Loss: 0.3658
Epoch 5/10, Batch 100/145, Loss: 0.2988
Epoch 5/10, Batch 110/145, Loss: 0.1981
Epoch 5/10, Batch 120/145, Loss: 0.2517
Epoch 5/10, Batch 130/145, Loss: 0.1913
Epoch 5/10, Batch 140/145, Loss: 0.2474
Epoch 5/10, Train Loss: 0.2441, Valid Loss: 0.2568
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1503
Epoch 6/10, Batch 20/145, Loss: 0.4043
Epoch 6/10, Batch 30/145, Loss: 0.4065
Epoch 6/10, Batch 40/145, Loss: 0.1463
Epoch 6/10, Batch 50/145, Loss: 0.2753
Epoch 6/10, Batch 60/145, Loss: 0.1154
Epoch 6/10, Batch 70/145, Loss: 0.1463
Epoch 6/10, Batch 80/145, Loss: 0.1295
Epoch 6/10, Batch 90/145, Loss: 0.2721
Epoch 6/10, Batch 100/145, Loss: 0.3091
Epoch 6/10, Batch 110/145, Loss: 0.2061
Epoch 6/10, Batch 120/145, Loss: 0.2726
Epoch 6/10, Batch 130/145, Loss: 0.2102
Epoch 6/10, Batch 140/145, Loss: 0.0764
Epoch 6/10, Train Loss: 0.2318, Valid Loss: 0.2437
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2358
Epoch 7/10, Batch 20/145, Loss: 0.2723
Epoch 7/10, Batch 30/145, Loss: 0.3283
Epoch 7/10, Batch 40/145, Loss: 0.4649
Epoch 7/10, Batch 50/145, Loss: 0.2253
Epoch 7/10, Batch 60/145, Loss: 0.1607
Epoch 7/10, Batch 70/145, Loss: 0.0956
Epoch 7/10, Batch 80/145, Loss: 0.4192
Epoch 7/10, Batch 90/145, Loss: 0.0982
Epoch 7/10, Batch 100/145, Loss: 0.2099
Epoch 7/10, Batch 110/145, Loss: 0.0778
Epoch 7/10, Batch 120/145, Loss: 0.2058
Epoch 7/10, Batch 130/145, Loss: 0.1175
Epoch 7/10, Batch 140/145, Loss: 0.1624
Epoch 7/10, Train Loss: 0.2137, Valid Loss: 0.2412
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1907
Epoch 8/10, Batch 20/145, Loss: 0.3697
Epoch 8/10, Batch 30/145, Loss: 0.1191
Epoch 8/10, Batch 40/145, Loss: 0.1455
Epoch 8/10, Batch 50/145, Loss: 0.2486
Epoch 8/10, Batch 60/145, Loss: 0.3450
Epoch 8/10, Batch 70/145, Loss: 0.1575
Epoch 8/10, Batch 80/145, Loss: 0.2540
Epoch 8/10, Batch 90/145, Loss: 0.2269
Epoch 8/10, Batch 100/145, Loss: 0.5682
Epoch 8/10, Batch 110/145, Loss: 0.2269
Epoch 8/10, Batch 120/145, Loss: 0.0900
Epoch 8/10, Batch 130/145, Loss: 0.2468
Epoch 8/10, Batch 140/145, Loss: 0.1760
Epoch 8/10, Train Loss: 0.2147, Valid Loss: 0.2340
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2456
Epoch 9/10, Batch 20/145, Loss: 0.1432
Epoch 9/10, Batch 30/145, Loss: 0.1834
Epoch 9/10, Batch 40/145, Loss: 0.1184
Epoch 9/10, Batch 50/145, Loss: 0.1761
Epoch 9/10, Batch 60/145, Loss: 0.3109
Epoch 9/10, Batch 70/145, Loss: 0.1967
Epoch 9/10, Batch 80/145, Loss: 0.1421
Epoch 9/10, Batch 90/145, Loss: 0.3432
Epoch 9/10, Batch 100/145, Loss: 0.1268
Epoch 9/10, Batch 110/145, Loss: 0.2582
Epoch 9/10, Batch 120/145, Loss: 0.1111
Epoch 9/10, Batch 130/145, Loss: 0.2873
Epoch 9/10, Batch 140/145, Loss: 0.1443
Epoch 9/10, Train Loss: 0.1974, Valid Loss: 0.2350
Epoch 10/10, Batch 10/145, Loss: 0.0858
Epoch 10/10, Batch 20/145, Loss: 0.1599
Epoch 10/10, Batch 30/145, Loss: 0.0865
Epoch 10/10, Batch 40/145, Loss: 0.1458
Epoch 10/10, Batch 50/145, Loss: 0.1922
Epoch 10/10, Batch 60/145, Loss: 0.2836
Epoch 10/10, Batch 70/145, Loss: 0.2913
Epoch 10/10, Batch 80/145, Loss: 0.2265
Epoch 10/10, Batch 90/145, Loss: 0.1182
Epoch 10/10, Batch 100/145, Loss: 0.1877
Epoch 10/10, Batch 110/145, Loss: 0.1469
Epoch 10/10, Batch 120/145, Loss: 0.2295
Epoch 10/10, Batch 130/145, Loss: 0.1182
Epoch 10/10, Batch 140/145, Loss: 0.3529
Epoch 10/10, Train Loss: 0.1967, Valid Loss: 0.2289
Model saved!
Accuracy: 0.9194
Precision: 0.9165
Recall: 0.9194
F1-score: 0.9173
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4476
Epoch 1/10, Batch 20/145, Loss: 0.9807
Epoch 1/10, Batch 30/145, Loss: 0.9557
Epoch 1/10, Batch 40/145, Loss: 0.8713
Epoch 1/10, Batch 50/145, Loss: 0.6250
Epoch 1/10, Batch 60/145, Loss: 0.5793
Epoch 1/10, Batch 70/145, Loss: 0.4645
Epoch 1/10, Batch 80/145, Loss: 0.5257
Epoch 1/10, Batch 90/145, Loss: 0.4376
Epoch 1/10, Batch 100/145, Loss: 0.3867
Epoch 1/10, Batch 110/145, Loss: 0.4654
Epoch 1/10, Batch 120/145, Loss: 0.6127
Epoch 1/10, Batch 130/145, Loss: 0.4649
Epoch 1/10, Batch 140/145, Loss: 0.3914
Epoch 1/10, Train Loss: 0.6761, Valid Loss: 0.3941
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.2621
Epoch 2/10, Batch 20/145, Loss: 0.3002
Epoch 2/10, Batch 30/145, Loss: 0.3011
Epoch 2/10, Batch 40/145, Loss: 0.4540
Epoch 2/10, Batch 50/145, Loss: 0.3386
Epoch 2/10, Batch 60/145, Loss: 0.6209
Epoch 2/10, Batch 70/145, Loss: 0.3973
Epoch 2/10, Batch 80/145, Loss: 0.3081
Epoch 2/10, Batch 90/145, Loss: 0.3253
Epoch 2/10, Batch 100/145, Loss: 0.4133
Epoch 2/10, Batch 110/145, Loss: 0.3144
Epoch 2/10, Batch 120/145, Loss: 0.3009
Epoch 2/10, Batch 130/145, Loss: 0.2819
Epoch 2/10, Batch 140/145, Loss: 0.2679
Epoch 2/10, Train Loss: 0.3459, Valid Loss: 0.3118
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2208
Epoch 3/10, Batch 20/145, Loss: 0.2374
Epoch 3/10, Batch 30/145, Loss: 0.3159
Epoch 3/10, Batch 40/145, Loss: 0.2772
Epoch 3/10, Batch 50/145, Loss: 0.3014
Epoch 3/10, Batch 60/145, Loss: 0.4745
Epoch 3/10, Batch 70/145, Loss: 0.4434
Epoch 3/10, Batch 80/145, Loss: 0.2381
Epoch 3/10, Batch 90/145, Loss: 0.2095
Epoch 3/10, Batch 100/145, Loss: 0.2298
Epoch 3/10, Batch 110/145, Loss: 0.2954
Epoch 3/10, Batch 120/145, Loss: 0.2521
Epoch 3/10, Batch 130/145, Loss: 0.4157
Epoch 3/10, Batch 140/145, Loss: 0.3403
Epoch 3/10, Train Loss: 0.2892, Valid Loss: 0.2757
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3102
Epoch 4/10, Batch 20/145, Loss: 0.2451
Epoch 4/10, Batch 30/145, Loss: 0.3556
Epoch 4/10, Batch 40/145, Loss: 0.2181
Epoch 4/10, Batch 50/145, Loss: 0.1767
Epoch 4/10, Batch 60/145, Loss: 0.1714
Epoch 4/10, Batch 70/145, Loss: 0.2014
Epoch 4/10, Batch 80/145, Loss: 0.1355
Epoch 4/10, Batch 90/145, Loss: 0.1975
Epoch 4/10, Batch 100/145, Loss: 0.1964
Epoch 4/10, Batch 110/145, Loss: 0.1434
Epoch 4/10, Batch 120/145, Loss: 0.1482
Epoch 4/10, Batch 130/145, Loss: 0.2471
Epoch 4/10, Batch 140/145, Loss: 0.2760
Epoch 4/10, Train Loss: 0.2531, Valid Loss: 0.2692
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2045
Epoch 5/10, Batch 20/145, Loss: 0.1011
Epoch 5/10, Batch 30/145, Loss: 0.2747
Epoch 5/10, Batch 40/145, Loss: 0.1868
Epoch 5/10, Batch 50/145, Loss: 0.1669
Epoch 5/10, Batch 60/145, Loss: 0.2694
Epoch 5/10, Batch 70/145, Loss: 0.1775
Epoch 5/10, Batch 80/145, Loss: 0.2307
Epoch 5/10, Batch 90/145, Loss: 0.3022
Epoch 5/10, Batch 100/145, Loss: 0.1538
Epoch 5/10, Batch 110/145, Loss: 0.1416
Epoch 5/10, Batch 120/145, Loss: 0.4468
Epoch 5/10, Batch 130/145, Loss: 0.1450
Epoch 5/10, Batch 140/145, Loss: 0.2914
Epoch 5/10, Train Loss: 0.2376, Valid Loss: 0.2591
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2435
Epoch 6/10, Batch 20/145, Loss: 0.4774
Epoch 6/10, Batch 30/145, Loss: 0.2715
Epoch 6/10, Batch 40/145, Loss: 0.1869
Epoch 6/10, Batch 50/145, Loss: 0.2706
Epoch 6/10, Batch 60/145, Loss: 0.1256
Epoch 6/10, Batch 70/145, Loss: 0.1658
Epoch 6/10, Batch 80/145, Loss: 0.2596
Epoch 6/10, Batch 90/145, Loss: 0.2132
Epoch 6/10, Batch 100/145, Loss: 0.1967
Epoch 6/10, Batch 110/145, Loss: 0.2663
Epoch 6/10, Batch 120/145, Loss: 0.2743
Epoch 6/10, Batch 130/145, Loss: 0.2227
Epoch 6/10, Batch 140/145, Loss: 0.1347
Epoch 6/10, Train Loss: 0.2241, Valid Loss: 0.2488
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1216
Epoch 7/10, Batch 20/145, Loss: 0.4068
Epoch 7/10, Batch 30/145, Loss: 0.1763
Epoch 7/10, Batch 40/145, Loss: 0.4733
Epoch 7/10, Batch 50/145, Loss: 0.1649
Epoch 7/10, Batch 60/145, Loss: 0.2141
Epoch 7/10, Batch 70/145, Loss: 0.2941
Epoch 7/10, Batch 80/145, Loss: 0.3972
Epoch 7/10, Batch 90/145, Loss: 0.1269
Epoch 7/10, Batch 100/145, Loss: 0.2897
Epoch 7/10, Batch 110/145, Loss: 0.2255
Epoch 7/10, Batch 120/145, Loss: 0.1724
Epoch 7/10, Batch 130/145, Loss: 0.1259
Epoch 7/10, Batch 140/145, Loss: 0.2340
Epoch 7/10, Train Loss: 0.2067, Valid Loss: 0.2426
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2305
Epoch 8/10, Batch 20/145, Loss: 0.2355
Epoch 8/10, Batch 30/145, Loss: 0.1579
Epoch 8/10, Batch 40/145, Loss: 0.1773
Epoch 8/10, Batch 50/145, Loss: 0.1143
Epoch 8/10, Batch 60/145, Loss: 0.1583
Epoch 8/10, Batch 70/145, Loss: 0.2908
Epoch 8/10, Batch 80/145, Loss: 0.2012
Epoch 8/10, Batch 90/145, Loss: 0.2140
Epoch 8/10, Batch 100/145, Loss: 0.2104
Epoch 8/10, Batch 110/145, Loss: 0.2443
Epoch 8/10, Batch 120/145, Loss: 0.1889
Epoch 8/10, Batch 130/145, Loss: 0.2233
Epoch 8/10, Batch 140/145, Loss: 0.1365
Epoch 8/10, Train Loss: 0.2013, Valid Loss: 0.2451
Epoch 9/10, Batch 10/145, Loss: 0.3332
Epoch 9/10, Batch 20/145, Loss: 0.1023
Epoch 9/10, Batch 30/145, Loss: 0.1806
Epoch 9/10, Batch 40/145, Loss: 0.1804
Epoch 9/10, Batch 50/145, Loss: 0.1556
Epoch 9/10, Batch 60/145, Loss: 0.1198
Epoch 9/10, Batch 70/145, Loss: 0.0987
Epoch 9/10, Batch 80/145, Loss: 0.1285
Epoch 9/10, Batch 90/145, Loss: 0.3648
Epoch 9/10, Batch 100/145, Loss: 0.1524
Epoch 9/10, Batch 110/145, Loss: 0.1838
Epoch 9/10, Batch 120/145, Loss: 0.1488
Epoch 9/10, Batch 130/145, Loss: 0.1998
Epoch 9/10, Batch 140/145, Loss: 0.3518
Epoch 9/10, Train Loss: 0.1980, Valid Loss: 0.2417
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1648
Epoch 10/10, Batch 20/145, Loss: 0.0968
Epoch 10/10, Batch 30/145, Loss: 0.1486
Epoch 10/10, Batch 40/145, Loss: 0.2347
Epoch 10/10, Batch 50/145, Loss: 0.1416
Epoch 10/10, Batch 60/145, Loss: 0.1921
Epoch 10/10, Batch 70/145, Loss: 0.3156
Epoch 10/10, Batch 80/145, Loss: 0.1414
Epoch 10/10, Batch 90/145, Loss: 0.2213
Epoch 10/10, Batch 100/145, Loss: 0.1530
Epoch 10/10, Batch 110/145, Loss: 0.1966
Epoch 10/10, Batch 120/145, Loss: 0.3431
Epoch 10/10, Batch 130/145, Loss: 0.1785
Epoch 10/10, Batch 140/145, Loss: 0.1467
Epoch 10/10, Train Loss: 0.1835, Valid Loss: 0.2353
Model saved!
Accuracy: 0.9182
Precision: 0.9157
Recall: 0.9182
F1-score: 0.9165
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.2942
Epoch 1/10, Batch 20/145, Loss: 0.8773
Epoch 1/10, Batch 30/145, Loss: 1.0125
Epoch 1/10, Batch 40/145, Loss: 0.8148
Epoch 1/10, Batch 50/145, Loss: 0.7537
Epoch 1/10, Batch 60/145, Loss: 0.6043
Epoch 1/10, Batch 70/145, Loss: 0.5051
Epoch 1/10, Batch 80/145, Loss: 0.6252
Epoch 1/10, Batch 90/145, Loss: 0.4117
Epoch 1/10, Batch 100/145, Loss: 0.5314
Epoch 1/10, Batch 110/145, Loss: 0.3289
Epoch 1/10, Batch 120/145, Loss: 0.4604
Epoch 1/10, Batch 130/145, Loss: 0.4106
Epoch 1/10, Batch 140/145, Loss: 0.4190
Epoch 1/10, Train Loss: 0.6713, Valid Loss: 0.3697
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3317
Epoch 2/10, Batch 20/145, Loss: 0.3377
Epoch 2/10, Batch 30/145, Loss: 0.3711
Epoch 2/10, Batch 40/145, Loss: 0.4800
Epoch 2/10, Batch 50/145, Loss: 0.2728
Epoch 2/10, Batch 60/145, Loss: 0.3662
Epoch 2/10, Batch 70/145, Loss: 0.2943
Epoch 2/10, Batch 80/145, Loss: 0.2583
Epoch 2/10, Batch 90/145, Loss: 0.2703
Epoch 2/10, Batch 100/145, Loss: 0.2495
Epoch 2/10, Batch 110/145, Loss: 0.3009
Epoch 2/10, Batch 120/145, Loss: 0.4389
Epoch 2/10, Batch 130/145, Loss: 0.2544
Epoch 2/10, Batch 140/145, Loss: 0.3050
Epoch 2/10, Train Loss: 0.3477, Valid Loss: 0.2843
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.3173
Epoch 3/10, Batch 20/145, Loss: 0.1971
Epoch 3/10, Batch 30/145, Loss: 0.3276
Epoch 3/10, Batch 40/145, Loss: 0.3083
Epoch 3/10, Batch 50/145, Loss: 0.2882
Epoch 3/10, Batch 60/145, Loss: 0.3757
Epoch 3/10, Batch 70/145, Loss: 0.3430
Epoch 3/10, Batch 80/145, Loss: 0.3922
Epoch 3/10, Batch 90/145, Loss: 0.3022
Epoch 3/10, Batch 100/145, Loss: 0.2323
Epoch 3/10, Batch 110/145, Loss: 0.2573
Epoch 3/10, Batch 120/145, Loss: 0.2504
Epoch 3/10, Batch 130/145, Loss: 0.2583
Epoch 3/10, Batch 140/145, Loss: 0.2363
Epoch 3/10, Train Loss: 0.2935, Valid Loss: 0.2581
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3550
Epoch 4/10, Batch 20/145, Loss: 0.2283
Epoch 4/10, Batch 30/145, Loss: 0.3274
Epoch 4/10, Batch 40/145, Loss: 0.1429
Epoch 4/10, Batch 50/145, Loss: 0.1713
Epoch 4/10, Batch 60/145, Loss: 0.2748
Epoch 4/10, Batch 70/145, Loss: 0.2499
Epoch 4/10, Batch 80/145, Loss: 0.1551
Epoch 4/10, Batch 90/145, Loss: 0.3245
Epoch 4/10, Batch 100/145, Loss: 0.3119
Epoch 4/10, Batch 110/145, Loss: 0.1544
Epoch 4/10, Batch 120/145, Loss: 0.2434
Epoch 4/10, Batch 130/145, Loss: 0.2564
Epoch 4/10, Batch 140/145, Loss: 0.0697
Epoch 4/10, Train Loss: 0.2553, Valid Loss: 0.2453
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1772
Epoch 5/10, Batch 20/145, Loss: 0.1742
Epoch 5/10, Batch 30/145, Loss: 0.1631
Epoch 5/10, Batch 40/145, Loss: 0.3427
Epoch 5/10, Batch 50/145, Loss: 0.2152
Epoch 5/10, Batch 60/145, Loss: 0.3133
Epoch 5/10, Batch 70/145, Loss: 0.1970
Epoch 5/10, Batch 80/145, Loss: 0.2527
Epoch 5/10, Batch 90/145, Loss: 0.3079
Epoch 5/10, Batch 100/145, Loss: 0.4271
Epoch 5/10, Batch 110/145, Loss: 0.1344
Epoch 5/10, Batch 120/145, Loss: 0.2086
Epoch 5/10, Batch 130/145, Loss: 0.1757
Epoch 5/10, Batch 140/145, Loss: 0.1134
Epoch 5/10, Train Loss: 0.2431, Valid Loss: 0.2415
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2354
Epoch 6/10, Batch 20/145, Loss: 0.4592
Epoch 6/10, Batch 30/145, Loss: 0.2089
Epoch 6/10, Batch 40/145, Loss: 0.1203
Epoch 6/10, Batch 50/145, Loss: 0.2954
Epoch 6/10, Batch 60/145, Loss: 0.2147
Epoch 6/10, Batch 70/145, Loss: 0.0749
Epoch 6/10, Batch 80/145, Loss: 0.1207
Epoch 6/10, Batch 90/145, Loss: 0.1420
Epoch 6/10, Batch 100/145, Loss: 0.2932
Epoch 6/10, Batch 110/145, Loss: 0.2522
Epoch 6/10, Batch 120/145, Loss: 0.2980
Epoch 6/10, Batch 130/145, Loss: 0.1304
Epoch 6/10, Batch 140/145, Loss: 0.1119
Epoch 6/10, Train Loss: 0.2361, Valid Loss: 0.2342
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2686
Epoch 7/10, Batch 20/145, Loss: 0.1819
Epoch 7/10, Batch 30/145, Loss: 0.1181
Epoch 7/10, Batch 40/145, Loss: 0.3928
Epoch 7/10, Batch 50/145, Loss: 0.4011
Epoch 7/10, Batch 60/145, Loss: 0.1331
Epoch 7/10, Batch 70/145, Loss: 0.1914
Epoch 7/10, Batch 80/145, Loss: 0.3268
Epoch 7/10, Batch 90/145, Loss: 0.3246
Epoch 7/10, Batch 100/145, Loss: 0.2395
Epoch 7/10, Batch 110/145, Loss: 0.1694
Epoch 7/10, Batch 120/145, Loss: 0.3220
Epoch 7/10, Batch 130/145, Loss: 0.0702
Epoch 7/10, Batch 140/145, Loss: 0.4138
Epoch 7/10, Train Loss: 0.2140, Valid Loss: 0.2292
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1514
Epoch 8/10, Batch 20/145, Loss: 0.2718
Epoch 8/10, Batch 30/145, Loss: 0.1234
Epoch 8/10, Batch 40/145, Loss: 0.1952
Epoch 8/10, Batch 50/145, Loss: 0.2543
Epoch 8/10, Batch 60/145, Loss: 0.2810
Epoch 8/10, Batch 70/145, Loss: 0.1999
Epoch 8/10, Batch 80/145, Loss: 0.2608
Epoch 8/10, Batch 90/145, Loss: 0.4152
Epoch 8/10, Batch 100/145, Loss: 0.3282
Epoch 8/10, Batch 110/145, Loss: 0.1236
Epoch 8/10, Batch 120/145, Loss: 0.1438
Epoch 8/10, Batch 130/145, Loss: 0.1349
Epoch 8/10, Batch 140/145, Loss: 0.1601
Epoch 8/10, Train Loss: 0.2014, Valid Loss: 0.2190
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3247
Epoch 9/10, Batch 20/145, Loss: 0.4641
Epoch 9/10, Batch 30/145, Loss: 0.0919
Epoch 9/10, Batch 40/145, Loss: 0.2138
Epoch 9/10, Batch 50/145, Loss: 0.1110
Epoch 9/10, Batch 60/145, Loss: 0.3657
Epoch 9/10, Batch 70/145, Loss: 0.1449
Epoch 9/10, Batch 80/145, Loss: 0.1259
Epoch 9/10, Batch 90/145, Loss: 0.2224
Epoch 9/10, Batch 100/145, Loss: 0.2504
Epoch 9/10, Batch 110/145, Loss: 0.2276
Epoch 9/10, Batch 120/145, Loss: 0.1006
Epoch 9/10, Batch 130/145, Loss: 0.2172
Epoch 9/10, Batch 140/145, Loss: 0.1686
Epoch 9/10, Train Loss: 0.1941, Valid Loss: 0.2224
Epoch 10/10, Batch 10/145, Loss: 0.1545
Epoch 10/10, Batch 20/145, Loss: 0.1809
Epoch 10/10, Batch 30/145, Loss: 0.1554
Epoch 10/10, Batch 40/145, Loss: 0.3958
Epoch 10/10, Batch 50/145, Loss: 0.3082
Epoch 10/10, Batch 60/145, Loss: 0.1900
Epoch 10/10, Batch 70/145, Loss: 0.3607
Epoch 10/10, Batch 80/145, Loss: 0.2403
Epoch 10/10, Batch 90/145, Loss: 0.1487
Epoch 10/10, Batch 100/145, Loss: 0.1475
Epoch 10/10, Batch 110/145, Loss: 0.1855
Epoch 10/10, Batch 120/145, Loss: 0.2257
Epoch 10/10, Batch 130/145, Loss: 0.1647
Epoch 10/10, Batch 140/145, Loss: 0.1515
Epoch 10/10, Train Loss: 0.1962, Valid Loss: 0.2184
Model saved!
Accuracy: 0.9112
Precision: 0.9082
Recall: 0.9112
F1-score: 0.9083
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4218
Epoch 1/10, Batch 20/145, Loss: 0.9666
Epoch 1/10, Batch 30/145, Loss: 0.8901
Epoch 1/10, Batch 40/145, Loss: 0.7913
Epoch 1/10, Batch 50/145, Loss: 0.7357
Epoch 1/10, Batch 60/145, Loss: 0.7440
Epoch 1/10, Batch 70/145, Loss: 0.5852
Epoch 1/10, Batch 80/145, Loss: 0.5946
Epoch 1/10, Batch 90/145, Loss: 0.4582
Epoch 1/10, Batch 100/145, Loss: 0.4778
Epoch 1/10, Batch 110/145, Loss: 0.4136
Epoch 1/10, Batch 120/145, Loss: 0.5352
Epoch 1/10, Batch 130/145, Loss: 0.3978
Epoch 1/10, Batch 140/145, Loss: 0.4564
Epoch 1/10, Train Loss: 0.6814, Valid Loss: 0.3636
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4318
Epoch 2/10, Batch 20/145, Loss: 0.3939
Epoch 2/10, Batch 30/145, Loss: 0.3590
Epoch 2/10, Batch 40/145, Loss: 0.4745
Epoch 2/10, Batch 50/145, Loss: 0.2559
Epoch 2/10, Batch 60/145, Loss: 0.2742
Epoch 2/10, Batch 70/145, Loss: 0.3087
Epoch 2/10, Batch 80/145, Loss: 0.3885
Epoch 2/10, Batch 90/145, Loss: 0.4198
Epoch 2/10, Batch 100/145, Loss: 0.3610
Epoch 2/10, Batch 110/145, Loss: 0.3460
Epoch 2/10, Batch 120/145, Loss: 0.4353
Epoch 2/10, Batch 130/145, Loss: 0.2821
Epoch 2/10, Batch 140/145, Loss: 0.2750
Epoch 2/10, Train Loss: 0.3502, Valid Loss: 0.2816
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2269
Epoch 3/10, Batch 20/145, Loss: 0.3852
Epoch 3/10, Batch 30/145, Loss: 0.5098
Epoch 3/10, Batch 40/145, Loss: 0.2629
Epoch 3/10, Batch 50/145, Loss: 0.3028
Epoch 3/10, Batch 60/145, Loss: 0.2121
Epoch 3/10, Batch 70/145, Loss: 0.4011
Epoch 3/10, Batch 80/145, Loss: 0.3341
Epoch 3/10, Batch 90/145, Loss: 0.2157
Epoch 3/10, Batch 100/145, Loss: 0.2936
Epoch 3/10, Batch 110/145, Loss: 0.2649
Epoch 3/10, Batch 120/145, Loss: 0.1907
Epoch 3/10, Batch 130/145, Loss: 0.2414
Epoch 3/10, Batch 140/145, Loss: 0.3002
Epoch 3/10, Train Loss: 0.2913, Valid Loss: 0.2432
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3041
Epoch 4/10, Batch 20/145, Loss: 0.2797
Epoch 4/10, Batch 30/145, Loss: 0.1882
Epoch 4/10, Batch 40/145, Loss: 0.2028
Epoch 4/10, Batch 50/145, Loss: 0.1046
Epoch 4/10, Batch 60/145, Loss: 0.3104
Epoch 4/10, Batch 70/145, Loss: 0.3270
Epoch 4/10, Batch 80/145, Loss: 0.1922
Epoch 4/10, Batch 90/145, Loss: 0.1674
Epoch 4/10, Batch 100/145, Loss: 0.3346
Epoch 4/10, Batch 110/145, Loss: 0.1427
Epoch 4/10, Batch 120/145, Loss: 0.3687
Epoch 4/10, Batch 130/145, Loss: 0.4167
Epoch 4/10, Batch 140/145, Loss: 0.0653
Epoch 4/10, Train Loss: 0.2592, Valid Loss: 0.2235
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.3981
Epoch 5/10, Batch 20/145, Loss: 0.2535
Epoch 5/10, Batch 30/145, Loss: 0.2334
Epoch 5/10, Batch 40/145, Loss: 0.1433
Epoch 5/10, Batch 50/145, Loss: 0.1483
Epoch 5/10, Batch 60/145, Loss: 0.3120
Epoch 5/10, Batch 70/145, Loss: 0.1802
Epoch 5/10, Batch 80/145, Loss: 0.1391
Epoch 5/10, Batch 90/145, Loss: 0.3520
Epoch 5/10, Batch 100/145, Loss: 0.2192
Epoch 5/10, Batch 110/145, Loss: 0.2568
Epoch 5/10, Batch 120/145, Loss: 0.3664
Epoch 5/10, Batch 130/145, Loss: 0.1545
Epoch 5/10, Batch 140/145, Loss: 0.3042
Epoch 5/10, Train Loss: 0.2448, Valid Loss: 0.2116
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.2415
Epoch 6/10, Batch 20/145, Loss: 0.4317
Epoch 6/10, Batch 30/145, Loss: 0.2425
Epoch 6/10, Batch 40/145, Loss: 0.1580
Epoch 6/10, Batch 50/145, Loss: 0.4548
Epoch 6/10, Batch 60/145, Loss: 0.2257
Epoch 6/10, Batch 70/145, Loss: 0.0763
Epoch 6/10, Batch 80/145, Loss: 0.2926
Epoch 6/10, Batch 90/145, Loss: 0.3616
Epoch 6/10, Batch 100/145, Loss: 0.3165
Epoch 6/10, Batch 110/145, Loss: 0.1729
Epoch 6/10, Batch 120/145, Loss: 0.2453
Epoch 6/10, Batch 130/145, Loss: 0.1040
Epoch 6/10, Batch 140/145, Loss: 0.1550
Epoch 6/10, Train Loss: 0.2295, Valid Loss: 0.2072
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2695
Epoch 7/10, Batch 20/145, Loss: 0.4594
Epoch 7/10, Batch 30/145, Loss: 0.1843
Epoch 7/10, Batch 40/145, Loss: 0.3637
Epoch 7/10, Batch 50/145, Loss: 0.0749
Epoch 7/10, Batch 60/145, Loss: 0.1832
Epoch 7/10, Batch 70/145, Loss: 0.3091
Epoch 7/10, Batch 80/145, Loss: 0.2723
Epoch 7/10, Batch 90/145, Loss: 0.2504
Epoch 7/10, Batch 100/145, Loss: 0.3004
Epoch 7/10, Batch 110/145, Loss: 0.1668
Epoch 7/10, Batch 120/145, Loss: 0.3256
Epoch 7/10, Batch 130/145, Loss: 0.1095
Epoch 7/10, Batch 140/145, Loss: 0.0941
Epoch 7/10, Train Loss: 0.2221, Valid Loss: 0.2022
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2730
Epoch 8/10, Batch 20/145, Loss: 0.2115
Epoch 8/10, Batch 30/145, Loss: 0.0867
Epoch 8/10, Batch 40/145, Loss: 0.2729
Epoch 8/10, Batch 50/145, Loss: 0.2007
Epoch 8/10, Batch 60/145, Loss: 0.2845
Epoch 8/10, Batch 70/145, Loss: 0.2649
Epoch 8/10, Batch 80/145, Loss: 0.2225
Epoch 8/10, Batch 90/145, Loss: 0.2543
Epoch 8/10, Batch 100/145, Loss: 0.2024
Epoch 8/10, Batch 110/145, Loss: 0.1653
Epoch 8/10, Batch 120/145, Loss: 0.1823
Epoch 8/10, Batch 130/145, Loss: 0.0779
Epoch 8/10, Batch 140/145, Loss: 0.4263
Epoch 8/10, Train Loss: 0.2119, Valid Loss: 0.1955
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3983
Epoch 9/10, Batch 20/145, Loss: 0.2043
Epoch 9/10, Batch 30/145, Loss: 0.2461
Epoch 9/10, Batch 40/145, Loss: 0.3107
Epoch 9/10, Batch 50/145, Loss: 0.1227
Epoch 9/10, Batch 60/145, Loss: 0.2254
Epoch 9/10, Batch 70/145, Loss: 0.3626
Epoch 9/10, Batch 80/145, Loss: 0.1654
Epoch 9/10, Batch 90/145, Loss: 0.2157
Epoch 9/10, Batch 100/145, Loss: 0.1995
Epoch 9/10, Batch 110/145, Loss: 0.2709
Epoch 9/10, Batch 120/145, Loss: 0.0988
Epoch 9/10, Batch 130/145, Loss: 0.0829
Epoch 9/10, Batch 140/145, Loss: 0.1775
Epoch 9/10, Train Loss: 0.2033, Valid Loss: 0.1890
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1905
Epoch 10/10, Batch 20/145, Loss: 0.1272
Epoch 10/10, Batch 30/145, Loss: 0.0855
Epoch 10/10, Batch 40/145, Loss: 0.1385
Epoch 10/10, Batch 50/145, Loss: 0.3178
Epoch 10/10, Batch 60/145, Loss: 0.1215
Epoch 10/10, Batch 70/145, Loss: 0.4060
Epoch 10/10, Batch 80/145, Loss: 0.1580
Epoch 10/10, Batch 90/145, Loss: 0.0885
Epoch 10/10, Batch 100/145, Loss: 0.1760
Epoch 10/10, Batch 110/145, Loss: 0.3549
Epoch 10/10, Batch 120/145, Loss: 0.2311
Epoch 10/10, Batch 130/145, Loss: 0.1275
Epoch 10/10, Batch 140/145, Loss: 0.1882
Epoch 10/10, Train Loss: 0.1919, Valid Loss: 0.1898
Accuracy: 0.9194
Precision: 0.9191
Recall: 0.9194
F1-score: 0.9191
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.4435
Epoch 1/10, Batch 20/145, Loss: 0.9695
Epoch 1/10, Batch 30/145, Loss: 0.8705
Epoch 1/10, Batch 40/145, Loss: 0.8032
Epoch 1/10, Batch 50/145, Loss: 0.7105
Epoch 1/10, Batch 60/145, Loss: 0.5434
Epoch 1/10, Batch 70/145, Loss: 0.4799
Epoch 1/10, Batch 80/145, Loss: 0.6538
Epoch 1/10, Batch 90/145, Loss: 0.4998
Epoch 1/10, Batch 100/145, Loss: 0.5048
Epoch 1/10, Batch 110/145, Loss: 0.3933
Epoch 1/10, Batch 120/145, Loss: 0.6163
Epoch 1/10, Batch 130/145, Loss: 0.6172
Epoch 1/10, Batch 140/145, Loss: 0.4450
Epoch 1/10, Train Loss: 0.6723, Valid Loss: 0.3819
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3454
Epoch 2/10, Batch 20/145, Loss: 0.3727
Epoch 2/10, Batch 30/145, Loss: 0.2430
Epoch 2/10, Batch 40/145, Loss: 0.3967
Epoch 2/10, Batch 50/145, Loss: 0.3977
Epoch 2/10, Batch 60/145, Loss: 0.2782
Epoch 2/10, Batch 70/145, Loss: 0.2430
Epoch 2/10, Batch 80/145, Loss: 0.3623
Epoch 2/10, Batch 90/145, Loss: 0.4322
Epoch 2/10, Batch 100/145, Loss: 0.2265
Epoch 2/10, Batch 110/145, Loss: 0.3362
Epoch 2/10, Batch 120/145, Loss: 0.2903
Epoch 2/10, Batch 130/145, Loss: 0.2746
Epoch 2/10, Batch 140/145, Loss: 0.3076
Epoch 2/10, Train Loss: 0.3515, Valid Loss: 0.2910
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2524
Epoch 3/10, Batch 20/145, Loss: 0.2461
Epoch 3/10, Batch 30/145, Loss: 0.3368
Epoch 3/10, Batch 40/145, Loss: 0.1381
Epoch 3/10, Batch 50/145, Loss: 0.4051
Epoch 3/10, Batch 60/145, Loss: 0.4360
Epoch 3/10, Batch 70/145, Loss: 0.3355
Epoch 3/10, Batch 80/145, Loss: 0.2354
Epoch 3/10, Batch 90/145, Loss: 0.4135
Epoch 3/10, Batch 100/145, Loss: 0.2608
Epoch 3/10, Batch 110/145, Loss: 0.1774
Epoch 3/10, Batch 120/145, Loss: 0.3099
Epoch 3/10, Batch 130/145, Loss: 0.3476
Epoch 3/10, Batch 140/145, Loss: 0.3232
Epoch 3/10, Train Loss: 0.2975, Valid Loss: 0.2577
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.4794
Epoch 4/10, Batch 20/145, Loss: 0.3475
Epoch 4/10, Batch 30/145, Loss: 0.2830
Epoch 4/10, Batch 40/145, Loss: 0.1910
Epoch 4/10, Batch 50/145, Loss: 0.2482
Epoch 4/10, Batch 60/145, Loss: 0.1349
Epoch 4/10, Batch 70/145, Loss: 0.1810
Epoch 4/10, Batch 80/145, Loss: 0.1985
Epoch 4/10, Batch 90/145, Loss: 0.2489
Epoch 4/10, Batch 100/145, Loss: 0.3258
Epoch 4/10, Batch 110/145, Loss: 0.1380
Epoch 4/10, Batch 120/145, Loss: 0.3557
Epoch 4/10, Batch 130/145, Loss: 0.1624
Epoch 4/10, Batch 140/145, Loss: 0.2572
Epoch 4/10, Train Loss: 0.2576, Valid Loss: 0.2469
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2325
Epoch 5/10, Batch 20/145, Loss: 0.3885
Epoch 5/10, Batch 30/145, Loss: 0.3586
Epoch 5/10, Batch 40/145, Loss: 0.2259
Epoch 5/10, Batch 50/145, Loss: 0.3208
Epoch 5/10, Batch 60/145, Loss: 0.1719
Epoch 5/10, Batch 70/145, Loss: 0.2717
Epoch 5/10, Batch 80/145, Loss: 0.1686
Epoch 5/10, Batch 90/145, Loss: 0.2963
Epoch 5/10, Batch 100/145, Loss: 0.3593
Epoch 5/10, Batch 110/145, Loss: 0.2039
Epoch 5/10, Batch 120/145, Loss: 0.2271
Epoch 5/10, Batch 130/145, Loss: 0.1748
Epoch 5/10, Batch 140/145, Loss: 0.1356
Epoch 5/10, Train Loss: 0.2489, Valid Loss: 0.2346
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.0887
Epoch 6/10, Batch 20/145, Loss: 0.2442
Epoch 6/10, Batch 30/145, Loss: 0.3387
Epoch 6/10, Batch 40/145, Loss: 0.1286
Epoch 6/10, Batch 50/145, Loss: 0.2978
Epoch 6/10, Batch 60/145, Loss: 0.1928
Epoch 6/10, Batch 70/145, Loss: 0.2969
Epoch 6/10, Batch 80/145, Loss: 0.2707
Epoch 6/10, Batch 90/145, Loss: 0.2344
Epoch 6/10, Batch 100/145, Loss: 0.2750
Epoch 6/10, Batch 110/145, Loss: 0.1674
Epoch 6/10, Batch 120/145, Loss: 0.3115
Epoch 6/10, Batch 130/145, Loss: 0.0984
Epoch 6/10, Batch 140/145, Loss: 0.1214
Epoch 6/10, Train Loss: 0.2236, Valid Loss: 0.2239
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2963
Epoch 7/10, Batch 20/145, Loss: 0.2691
Epoch 7/10, Batch 30/145, Loss: 0.2398
Epoch 7/10, Batch 40/145, Loss: 0.4767
Epoch 7/10, Batch 50/145, Loss: 0.1443
Epoch 7/10, Batch 60/145, Loss: 0.1780
Epoch 7/10, Batch 70/145, Loss: 0.1608
Epoch 7/10, Batch 80/145, Loss: 0.3813
Epoch 7/10, Batch 90/145, Loss: 0.2125
Epoch 7/10, Batch 100/145, Loss: 0.1653
Epoch 7/10, Batch 110/145, Loss: 0.1817
Epoch 7/10, Batch 120/145, Loss: 0.2636
Epoch 7/10, Batch 130/145, Loss: 0.0546
Epoch 7/10, Batch 140/145, Loss: 0.2328
Epoch 7/10, Train Loss: 0.2198, Valid Loss: 0.2203
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1854
Epoch 8/10, Batch 20/145, Loss: 0.2083
Epoch 8/10, Batch 30/145, Loss: 0.2263
Epoch 8/10, Batch 40/145, Loss: 0.1387
Epoch 8/10, Batch 50/145, Loss: 0.3951
Epoch 8/10, Batch 60/145, Loss: 0.3425
Epoch 8/10, Batch 70/145, Loss: 0.2663
Epoch 8/10, Batch 80/145, Loss: 0.2638
Epoch 8/10, Batch 90/145, Loss: 0.5055
Epoch 8/10, Batch 100/145, Loss: 0.2574
Epoch 8/10, Batch 110/145, Loss: 0.2404
Epoch 8/10, Batch 120/145, Loss: 0.1810
Epoch 8/10, Batch 130/145, Loss: 0.0770
Epoch 8/10, Batch 140/145, Loss: 0.2262
Epoch 8/10, Train Loss: 0.2145, Valid Loss: 0.2117
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.2981
Epoch 9/10, Batch 20/145, Loss: 0.1226
Epoch 9/10, Batch 30/145, Loss: 0.1380
Epoch 9/10, Batch 40/145, Loss: 0.1934
Epoch 9/10, Batch 50/145, Loss: 0.0839
Epoch 9/10, Batch 60/145, Loss: 0.1882
Epoch 9/10, Batch 70/145, Loss: 0.2628
Epoch 9/10, Batch 80/145, Loss: 0.0552
Epoch 9/10, Batch 90/145, Loss: 0.3417
Epoch 9/10, Batch 100/145, Loss: 0.1785
Epoch 9/10, Batch 110/145, Loss: 0.3495
Epoch 9/10, Batch 120/145, Loss: 0.1245
Epoch 9/10, Batch 130/145, Loss: 0.2561
Epoch 9/10, Batch 140/145, Loss: 0.1032
Epoch 9/10, Train Loss: 0.2011, Valid Loss: 0.2109
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0963
Epoch 10/10, Batch 20/145, Loss: 0.2163
Epoch 10/10, Batch 30/145, Loss: 0.0386
Epoch 10/10, Batch 40/145, Loss: 0.1524
Epoch 10/10, Batch 50/145, Loss: 0.2477
Epoch 10/10, Batch 60/145, Loss: 0.1078
Epoch 10/10, Batch 70/145, Loss: 0.3046
Epoch 10/10, Batch 80/145, Loss: 0.1124
Epoch 10/10, Batch 90/145, Loss: 0.1522
Epoch 10/10, Batch 100/145, Loss: 0.1799
Epoch 10/10, Batch 110/145, Loss: 0.1215
Epoch 10/10, Batch 120/145, Loss: 0.0654
Epoch 10/10, Batch 130/145, Loss: 0.1288
Epoch 10/10, Batch 140/145, Loss: 0.1297
Epoch 10/10, Train Loss: 0.1903, Valid Loss: 0.2047
Model saved!
Accuracy: 0.9206
Precision: 0.9176
Recall: 0.9206
F1-score: 0.9186
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3627
Epoch 1/10, Batch 20/145, Loss: 0.9552
Epoch 1/10, Batch 30/145, Loss: 0.8821
Epoch 1/10, Batch 40/145, Loss: 0.7235
Epoch 1/10, Batch 50/145, Loss: 0.7893
Epoch 1/10, Batch 60/145, Loss: 0.5884
Epoch 1/10, Batch 70/145, Loss: 0.4265
Epoch 1/10, Batch 80/145, Loss: 0.5881
Epoch 1/10, Batch 90/145, Loss: 0.4356
Epoch 1/10, Batch 100/145, Loss: 0.4880
Epoch 1/10, Batch 110/145, Loss: 0.3871
Epoch 1/10, Batch 120/145, Loss: 0.6124
Epoch 1/10, Batch 130/145, Loss: 0.6159
Epoch 1/10, Batch 140/145, Loss: 0.3683
Epoch 1/10, Train Loss: 0.6723, Valid Loss: 0.3989
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3017
Epoch 2/10, Batch 20/145, Loss: 0.2914
Epoch 2/10, Batch 30/145, Loss: 0.2746
Epoch 2/10, Batch 40/145, Loss: 0.3580
Epoch 2/10, Batch 50/145, Loss: 0.3782
Epoch 2/10, Batch 60/145, Loss: 0.4668
Epoch 2/10, Batch 70/145, Loss: 0.3229
Epoch 2/10, Batch 80/145, Loss: 0.4269
Epoch 2/10, Batch 90/145, Loss: 0.2130
Epoch 2/10, Batch 100/145, Loss: 0.3242
Epoch 2/10, Batch 110/145, Loss: 0.4267
Epoch 2/10, Batch 120/145, Loss: 0.4262
Epoch 2/10, Batch 130/145, Loss: 0.2491
Epoch 2/10, Batch 140/145, Loss: 0.2590
Epoch 2/10, Train Loss: 0.3486, Valid Loss: 0.3188
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2626
Epoch 3/10, Batch 20/145, Loss: 0.2743
Epoch 3/10, Batch 30/145, Loss: 0.3611
Epoch 3/10, Batch 40/145, Loss: 0.2682
Epoch 3/10, Batch 50/145, Loss: 0.1779
Epoch 3/10, Batch 60/145, Loss: 0.3641
Epoch 3/10, Batch 70/145, Loss: 0.4518
Epoch 3/10, Batch 80/145, Loss: 0.2439
Epoch 3/10, Batch 90/145, Loss: 0.2605
Epoch 3/10, Batch 100/145, Loss: 0.2393
Epoch 3/10, Batch 110/145, Loss: 0.1419
Epoch 3/10, Batch 120/145, Loss: 0.2785
Epoch 3/10, Batch 130/145, Loss: 0.3153
Epoch 3/10, Batch 140/145, Loss: 0.3373
Epoch 3/10, Train Loss: 0.2900, Valid Loss: 0.2793
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3144
Epoch 4/10, Batch 20/145, Loss: 0.3608
Epoch 4/10, Batch 30/145, Loss: 0.2586
Epoch 4/10, Batch 40/145, Loss: 0.2378
Epoch 4/10, Batch 50/145, Loss: 0.0919
Epoch 4/10, Batch 60/145, Loss: 0.2837
Epoch 4/10, Batch 70/145, Loss: 0.2129
Epoch 4/10, Batch 80/145, Loss: 0.1436
Epoch 4/10, Batch 90/145, Loss: 0.2577
Epoch 4/10, Batch 100/145, Loss: 0.2534
Epoch 4/10, Batch 110/145, Loss: 0.1744
Epoch 4/10, Batch 120/145, Loss: 0.2762
Epoch 4/10, Batch 130/145, Loss: 0.1509
Epoch 4/10, Batch 140/145, Loss: 0.1671
Epoch 4/10, Train Loss: 0.2607, Valid Loss: 0.2686
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.1949
Epoch 5/10, Batch 20/145, Loss: 0.1856
Epoch 5/10, Batch 30/145, Loss: 0.2260
Epoch 5/10, Batch 40/145, Loss: 0.1020
Epoch 5/10, Batch 50/145, Loss: 0.2064
Epoch 5/10, Batch 60/145, Loss: 0.2171
Epoch 5/10, Batch 70/145, Loss: 0.1184
Epoch 5/10, Batch 80/145, Loss: 0.1658
Epoch 5/10, Batch 90/145, Loss: 0.4011
Epoch 5/10, Batch 100/145, Loss: 0.2762
Epoch 5/10, Batch 110/145, Loss: 0.1732
Epoch 5/10, Batch 120/145, Loss: 0.2079
Epoch 5/10, Batch 130/145, Loss: 0.0998
Epoch 5/10, Batch 140/145, Loss: 0.1612
Epoch 5/10, Train Loss: 0.2387, Valid Loss: 0.2570
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1625
Epoch 6/10, Batch 20/145, Loss: 0.3811
Epoch 6/10, Batch 30/145, Loss: 0.4078
Epoch 6/10, Batch 40/145, Loss: 0.2455
Epoch 6/10, Batch 50/145, Loss: 0.3058
Epoch 6/10, Batch 60/145, Loss: 0.2699
Epoch 6/10, Batch 70/145, Loss: 0.1140
Epoch 6/10, Batch 80/145, Loss: 0.2100
Epoch 6/10, Batch 90/145, Loss: 0.1926
Epoch 6/10, Batch 100/145, Loss: 0.2685
Epoch 6/10, Batch 110/145, Loss: 0.3341
Epoch 6/10, Batch 120/145, Loss: 0.2774
Epoch 6/10, Batch 130/145, Loss: 0.2920
Epoch 6/10, Batch 140/145, Loss: 0.3518
Epoch 6/10, Train Loss: 0.2216, Valid Loss: 0.2504
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.1804
Epoch 7/10, Batch 20/145, Loss: 0.3157
Epoch 7/10, Batch 30/145, Loss: 0.1840
Epoch 7/10, Batch 40/145, Loss: 0.3530
Epoch 7/10, Batch 50/145, Loss: 0.2920
Epoch 7/10, Batch 60/145, Loss: 0.2094
Epoch 7/10, Batch 70/145, Loss: 0.2642
Epoch 7/10, Batch 80/145, Loss: 0.4474
Epoch 7/10, Batch 90/145, Loss: 0.1522
Epoch 7/10, Batch 100/145, Loss: 0.3391
Epoch 7/10, Batch 110/145, Loss: 0.2690
Epoch 7/10, Batch 120/145, Loss: 0.2329
Epoch 7/10, Batch 130/145, Loss: 0.1687
Epoch 7/10, Batch 140/145, Loss: 0.2016
Epoch 7/10, Train Loss: 0.2198, Valid Loss: 0.2330
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.1848
Epoch 8/10, Batch 20/145, Loss: 0.1995
Epoch 8/10, Batch 30/145, Loss: 0.1227
Epoch 8/10, Batch 40/145, Loss: 0.1053
Epoch 8/10, Batch 50/145, Loss: 0.1859
Epoch 8/10, Batch 60/145, Loss: 0.1437
Epoch 8/10, Batch 70/145, Loss: 0.2659
Epoch 8/10, Batch 80/145, Loss: 0.1499
Epoch 8/10, Batch 90/145, Loss: 0.4235
Epoch 8/10, Batch 100/145, Loss: 0.1239
Epoch 8/10, Batch 110/145, Loss: 0.1072
Epoch 8/10, Batch 120/145, Loss: 0.1807
Epoch 8/10, Batch 130/145, Loss: 0.1534
Epoch 8/10, Batch 140/145, Loss: 0.1419
Epoch 8/10, Train Loss: 0.2089, Valid Loss: 0.2302
Model saved!
Epoch 9/10, Batch 10/145, Loss: 0.3009
Epoch 9/10, Batch 20/145, Loss: 0.1249
Epoch 9/10, Batch 30/145, Loss: 0.1579
Epoch 9/10, Batch 40/145, Loss: 0.4213
Epoch 9/10, Batch 50/145, Loss: 0.2624
Epoch 9/10, Batch 60/145, Loss: 0.1526
Epoch 9/10, Batch 70/145, Loss: 0.1927
Epoch 9/10, Batch 80/145, Loss: 0.1394
Epoch 9/10, Batch 90/145, Loss: 0.2295
Epoch 9/10, Batch 100/145, Loss: 0.1478
Epoch 9/10, Batch 110/145, Loss: 0.1556
Epoch 9/10, Batch 120/145, Loss: 0.1378
Epoch 9/10, Batch 130/145, Loss: 0.1301
Epoch 9/10, Batch 140/145, Loss: 0.2485
Epoch 9/10, Train Loss: 0.1971, Valid Loss: 0.2278
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.1587
Epoch 10/10, Batch 20/145, Loss: 0.3038
Epoch 10/10, Batch 30/145, Loss: 0.1843
Epoch 10/10, Batch 40/145, Loss: 0.1381
Epoch 10/10, Batch 50/145, Loss: 0.1949
Epoch 10/10, Batch 60/145, Loss: 0.1229
Epoch 10/10, Batch 70/145, Loss: 0.1961
Epoch 10/10, Batch 80/145, Loss: 0.1359
Epoch 10/10, Batch 90/145, Loss: 0.1640
Epoch 10/10, Batch 100/145, Loss: 0.1467
Epoch 10/10, Batch 110/145, Loss: 0.1479
Epoch 10/10, Batch 120/145, Loss: 0.1596
Epoch 10/10, Batch 130/145, Loss: 0.0868
Epoch 10/10, Batch 140/145, Loss: 0.1459
Epoch 10/10, Train Loss: 0.1929, Valid Loss: 0.2299
Accuracy: 0.9241
Precision: 0.9227
Recall: 0.9241
F1-score: 0.9233
Memory Allocated after cleanup: 17.76 MB
Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3606
Epoch 1/10, Batch 20/145, Loss: 0.9910
Epoch 1/10, Batch 30/145, Loss: 0.8899
Epoch 1/10, Batch 40/145, Loss: 0.7955
Epoch 1/10, Batch 50/145, Loss: 0.6760
Epoch 1/10, Batch 60/145, Loss: 0.5719
Epoch 1/10, Batch 70/145, Loss: 0.4005
Epoch 1/10, Batch 80/145, Loss: 0.5575
Epoch 1/10, Batch 90/145, Loss: 0.4246
Epoch 1/10, Batch 100/145, Loss: 0.4835
Epoch 1/10, Batch 110/145, Loss: 0.3984
Epoch 1/10, Batch 120/145, Loss: 0.6351
Epoch 1/10, Batch 130/145, Loss: 0.5672
Epoch 1/10, Batch 140/145, Loss: 0.2967
Epoch 1/10, Train Loss: 0.6798, Valid Loss: 0.3888
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.3394
Epoch 2/10, Batch 20/145, Loss: 0.3567
Epoch 2/10, Batch 30/145, Loss: 0.3796
Epoch 2/10, Batch 40/145, Loss: 0.5069
Epoch 2/10, Batch 50/145, Loss: 0.4446
Epoch 2/10, Batch 60/145, Loss: 0.4470
Epoch 2/10, Batch 70/145, Loss: 0.3423
Epoch 2/10, Batch 80/145, Loss: 0.3742
Epoch 2/10, Batch 90/145, Loss: 0.2594
Epoch 2/10, Batch 100/145, Loss: 0.2050
Epoch 2/10, Batch 110/145, Loss: 0.4839
Epoch 2/10, Batch 120/145, Loss: 0.2981
Epoch 2/10, Batch 130/145, Loss: 0.2401
Epoch 2/10, Batch 140/145, Loss: 0.2147
Epoch 2/10, Train Loss: 0.3498, Valid Loss: 0.3021
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2327
Epoch 3/10, Batch 20/145, Loss: 0.2625
Epoch 3/10, Batch 30/145, Loss: 0.3092
Epoch 3/10, Batch 40/145, Loss: 0.3148
Epoch 3/10, Batch 50/145, Loss: 0.3576
Epoch 3/10, Batch 60/145, Loss: 0.3138
Epoch 3/10, Batch 70/145, Loss: 0.2982
Epoch 3/10, Batch 80/145, Loss: 0.2283
Epoch 3/10, Batch 90/145, Loss: 0.1653
Epoch 3/10, Batch 100/145, Loss: 0.2687
Epoch 3/10, Batch 110/145, Loss: 0.1939
Epoch 3/10, Batch 120/145, Loss: 0.2524
Epoch 3/10, Batch 130/145, Loss: 0.2904
Epoch 3/10, Batch 140/145, Loss: 0.1647
Epoch 3/10, Train Loss: 0.2890, Valid Loss: 0.2746
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.3142
Epoch 4/10, Batch 20/145, Loss: 0.3849
Epoch 4/10, Batch 30/145, Loss: 0.2767
Epoch 4/10, Batch 40/145, Loss: 0.3095
Epoch 4/10, Batch 50/145, Loss: 0.3433
Epoch 4/10, Batch 60/145, Loss: 0.3238
Epoch 4/10, Batch 70/145, Loss: 0.2159
Epoch 4/10, Batch 80/145, Loss: 0.1612
Epoch 4/10, Batch 90/145, Loss: 0.2454
Epoch 4/10, Batch 100/145, Loss: 0.3352
Epoch 4/10, Batch 110/145, Loss: 0.1644
Epoch 4/10, Batch 120/145, Loss: 0.2687
Epoch 4/10, Batch 130/145, Loss: 0.1884
Epoch 4/10, Batch 140/145, Loss: 0.1707
Epoch 4/10, Train Loss: 0.2573, Valid Loss: 0.2536
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2279
Epoch 5/10, Batch 20/145, Loss: 0.1960
Epoch 5/10, Batch 30/145, Loss: 0.1671
Epoch 5/10, Batch 40/145, Loss: 0.1393
Epoch 5/10, Batch 50/145, Loss: 0.2114
Epoch 5/10, Batch 60/145, Loss: 0.2649
Epoch 5/10, Batch 70/145, Loss: 0.1266
Epoch 5/10, Batch 80/145, Loss: 0.1686
Epoch 5/10, Batch 90/145, Loss: 0.2212
Epoch 5/10, Batch 100/145, Loss: 0.2213
Epoch 5/10, Batch 110/145, Loss: 0.1640
Epoch 5/10, Batch 120/145, Loss: 0.4905
Epoch 5/10, Batch 130/145, Loss: 0.1815
Epoch 5/10, Batch 140/145, Loss: 0.1784
Epoch 5/10, Train Loss: 0.2446, Valid Loss: 0.2503
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1999
Epoch 6/10, Batch 20/145, Loss: 0.3823
Epoch 6/10, Batch 30/145, Loss: 0.3759
Epoch 6/10, Batch 40/145, Loss: 0.1333
Epoch 6/10, Batch 50/145, Loss: 0.4121
Epoch 6/10, Batch 60/145, Loss: 0.1638
Epoch 6/10, Batch 70/145, Loss: 0.2114
Epoch 6/10, Batch 80/145, Loss: 0.2570
Epoch 6/10, Batch 90/145, Loss: 0.2056
Epoch 6/10, Batch 100/145, Loss: 0.3168
Epoch 6/10, Batch 110/145, Loss: 0.2031
Epoch 6/10, Batch 120/145, Loss: 0.2465
Epoch 6/10, Batch 130/145, Loss: 0.1954
Epoch 6/10, Batch 140/145, Loss: 0.1463
Epoch 6/10, Train Loss: 0.2197, Valid Loss: 0.2392
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.2389
Epoch 7/10, Batch 20/145, Loss: 0.2365
Epoch 7/10, Batch 30/145, Loss: 0.2349
Epoch 7/10, Batch 40/145, Loss: 0.2806
Epoch 7/10, Batch 50/145, Loss: 0.2016
Epoch 7/10, Batch 60/145, Loss: 0.1990
Epoch 7/10, Batch 70/145, Loss: 0.1468
Epoch 7/10, Batch 80/145, Loss: 0.2653
Epoch 7/10, Batch 90/145, Loss: 0.3748
Epoch 7/10, Batch 100/145, Loss: 0.1785
Epoch 7/10, Batch 110/145, Loss: 0.2855
Epoch 7/10, Batch 120/145, Loss: 0.1753
Epoch 7/10, Batch 130/145, Loss: 0.2123
Epoch 7/10, Batch 140/145, Loss: 0.1982
Epoch 7/10, Train Loss: 0.2039, Valid Loss: 0.2312
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.2844
Epoch 8/10, Batch 20/145, Loss: 0.2844
Epoch 8/10, Batch 30/145, Loss: 0.2570
Epoch 8/10, Batch 40/145, Loss: 0.2846
Epoch 8/10, Batch 50/145, Loss: 0.2492
Epoch 8/10, Batch 60/145, Loss: 0.1529
Epoch 8/10, Batch 70/145, Loss: 0.1884
Epoch 8/10, Batch 80/145, Loss: 0.2250
Epoch 8/10, Batch 90/145, Loss: 0.4666
Epoch 8/10, Batch 100/145, Loss: 0.2627
Epoch 8/10, Batch 110/145, Loss: 0.3061
Epoch 8/10, Batch 120/145, Loss: 0.1903
Epoch 8/10, Batch 130/145, Loss: 0.2114
Epoch 8/10, Batch 140/145, Loss: 0.1635
Epoch 8/10, Train Loss: 0.2043, Valid Loss: 0.2333
Epoch 9/10, Batch 10/145, Loss: 0.1319
Epoch 9/10, Batch 20/145, Loss: 0.2052
Epoch 9/10, Batch 30/145, Loss: 0.1026
Epoch 9/10, Batch 40/145, Loss: 0.2474
Epoch 9/10, Batch 50/145, Loss: 0.1259
Epoch 9/10, Batch 60/145, Loss: 0.2307
Epoch 9/10, Batch 70/145, Loss: 0.1247
Epoch 9/10, Batch 80/145, Loss: 0.1563
Epoch 9/10, Batch 90/145, Loss: 0.2009
Epoch 9/10, Batch 100/145, Loss: 0.0538
Epoch 9/10, Batch 110/145, Loss: 0.1607
Epoch 9/10, Batch 120/145, Loss: 0.1940
Epoch 9/10, Batch 130/145, Loss: 0.2438
Epoch 9/10, Batch 140/145, Loss: 0.1427
Epoch 9/10, Train Loss: 0.1965, Valid Loss: 0.2313
Epoch 10/10, Batch 10/145, Loss: 0.1646
Epoch 10/10, Batch 20/145, Loss: 0.1751
Epoch 10/10, Batch 30/145, Loss: 0.1450
Epoch 10/10, Batch 40/145, Loss: 0.1738
Epoch 10/10, Batch 50/145, Loss: 0.2585
Epoch 10/10, Batch 60/145, Loss: 0.0897
Epoch 10/10, Batch 70/145, Loss: 0.3645
Epoch 10/10, Batch 80/145, Loss: 0.1814
Epoch 10/10, Batch 90/145, Loss: 0.1855
Epoch 10/10, Batch 100/145, Loss: 0.1444
Epoch 10/10, Batch 110/145, Loss: 0.0742
Epoch 10/10, Batch 120/145, Loss: 0.3739
Epoch 10/10, Batch 130/145, Loss: 0.2012
Epoch 10/10, Batch 140/145, Loss: 0.1831
Epoch 10/10, Train Loss: 0.1905, Valid Loss: 0.2260
Model saved!
Accuracy: 0.9136
Precision: 0.9106
Recall: 0.9136
F1-score: 0.9107
Memory Allocated after cleanup: 17.76 MB
End time: 2025-02-26 17:10:09.454874
Duration: 13:03:25


Mejor accuracy al acabar el algoritmo: 0.9287


Fitness check:

Using device: cuda
GPU: NVIDIA TITAN X (Pascal)
Memory Allocated: 0.25 MB
No se encontró la carpeta de validación. Creando valid set desde train...
Datasets cargados correctamente.
Using device: cuda
Epoch 1/10, Batch 10/145, Loss: 1.3684
Epoch 1/10, Batch 20/145, Loss: 0.9402
Epoch 1/10, Batch 30/145, Loss: 0.8673
Epoch 1/10, Batch 40/145, Loss: 0.8781
Epoch 1/10, Batch 50/145, Loss: 0.6754
Epoch 1/10, Batch 60/145, Loss: 0.6292
Epoch 1/10, Batch 70/145, Loss: 0.6479
Epoch 1/10, Batch 80/145, Loss: 0.7080
Epoch 1/10, Batch 90/145, Loss: 0.4790
Epoch 1/10, Batch 100/145, Loss: 0.4830
Epoch 1/10, Batch 110/145, Loss: 0.4126
Epoch 1/10, Batch 120/145, Loss: 0.5774
Epoch 1/10, Batch 130/145, Loss: 0.6166
Epoch 1/10, Batch 140/145, Loss: 0.4450
Epoch 1/10, Train Loss: 0.6813, Valid Loss: 0.3706
Model saved!
Epoch 2/10, Batch 10/145, Loss: 0.4786
Epoch 2/10, Batch 20/145, Loss: 0.2806
Epoch 2/10, Batch 30/145, Loss: 0.2309
Epoch 2/10, Batch 40/145, Loss: 0.4367
Epoch 2/10, Batch 50/145, Loss: 0.3274
Epoch 2/10, Batch 60/145, Loss: 0.4831
Epoch 2/10, Batch 70/145, Loss: 0.3839
Epoch 2/10, Batch 80/145, Loss: 0.4569
Epoch 2/10, Batch 90/145, Loss: 0.3470
Epoch 2/10, Batch 100/145, Loss: 0.3245
Epoch 2/10, Batch 110/145, Loss: 0.3085
Epoch 2/10, Batch 120/145, Loss: 0.2662
Epoch 2/10, Batch 130/145, Loss: 0.2975
Epoch 2/10, Batch 140/145, Loss: 0.3305
Epoch 2/10, Train Loss: 0.3522, Valid Loss: 0.2932
Model saved!
Epoch 3/10, Batch 10/145, Loss: 0.2353
Epoch 3/10, Batch 20/145, Loss: 0.2488
Epoch 3/10, Batch 30/145, Loss: 0.4448
Epoch 3/10, Batch 40/145, Loss: 0.2804
Epoch 3/10, Batch 50/145, Loss: 0.3044
Epoch 3/10, Batch 60/145, Loss: 0.4547
Epoch 3/10, Batch 70/145, Loss: 0.3206
Epoch 3/10, Batch 80/145, Loss: 0.1883
Epoch 3/10, Batch 90/145, Loss: 0.1946
Epoch 3/10, Batch 100/145, Loss: 0.2160
Epoch 3/10, Batch 110/145, Loss: 0.2534
Epoch 3/10, Batch 120/145, Loss: 0.3579
Epoch 3/10, Batch 130/145, Loss: 0.2808
Epoch 3/10, Batch 140/145, Loss: 0.2187
Epoch 3/10, Train Loss: 0.2880, Valid Loss: 0.2663
Model saved!
Epoch 4/10, Batch 10/145, Loss: 0.2792
Epoch 4/10, Batch 20/145, Loss: 0.3761
Epoch 4/10, Batch 30/145, Loss: 0.2756
Epoch 4/10, Batch 40/145, Loss: 0.2164
Epoch 4/10, Batch 50/145, Loss: 0.2282
Epoch 4/10, Batch 60/145, Loss: 0.2496
Epoch 4/10, Batch 70/145, Loss: 0.1661
Epoch 4/10, Batch 80/145, Loss: 0.1937
Epoch 4/10, Batch 90/145, Loss: 0.1647
Epoch 4/10, Batch 100/145, Loss: 0.1971
Epoch 4/10, Batch 110/145, Loss: 0.1571
Epoch 4/10, Batch 120/145, Loss: 0.1962
Epoch 4/10, Batch 130/145, Loss: 0.1658
Epoch 4/10, Batch 140/145, Loss: 0.2295
Epoch 4/10, Train Loss: 0.2552, Valid Loss: 0.2484
Model saved!
Epoch 5/10, Batch 10/145, Loss: 0.2521
Epoch 5/10, Batch 20/145, Loss: 0.2102
Epoch 5/10, Batch 30/145, Loss: 0.1731
Epoch 5/10, Batch 40/145, Loss: 0.1380
Epoch 5/10, Batch 50/145, Loss: 0.1955
Epoch 5/10, Batch 60/145, Loss: 0.2135
Epoch 5/10, Batch 70/145, Loss: 0.1615
Epoch 5/10, Batch 80/145, Loss: 0.4995
Epoch 5/10, Batch 90/145, Loss: 0.3686
Epoch 5/10, Batch 100/145, Loss: 0.3116
Epoch 5/10, Batch 110/145, Loss: 0.0942
Epoch 5/10, Batch 120/145, Loss: 0.2078
Epoch 5/10, Batch 130/145, Loss: 0.1647
Epoch 5/10, Batch 140/145, Loss: 0.1042
Epoch 5/10, Train Loss: 0.2411, Valid Loss: 0.2408
Model saved!
Epoch 6/10, Batch 10/145, Loss: 0.1022
Epoch 6/10, Batch 20/145, Loss: 0.2742
Epoch 6/10, Batch 30/145, Loss: 0.2822
Epoch 6/10, Batch 40/145, Loss: 0.1015
Epoch 6/10, Batch 50/145, Loss: 0.3878
Epoch 6/10, Batch 60/145, Loss: 0.1987
Epoch 6/10, Batch 70/145, Loss: 0.1970
Epoch 6/10, Batch 80/145, Loss: 0.1935
Epoch 6/10, Batch 90/145, Loss: 0.3799
Epoch 6/10, Batch 100/145, Loss: 0.3650
Epoch 6/10, Batch 110/145, Loss: 0.2208
Epoch 6/10, Batch 120/145, Loss: 0.2446
Epoch 6/10, Batch 130/145, Loss: 0.1895
Epoch 6/10, Batch 140/145, Loss: 0.1619
Epoch 6/10, Train Loss: 0.2265, Valid Loss: 0.2311
Model saved!
Epoch 7/10, Batch 10/145, Loss: 0.3557
Epoch 7/10, Batch 20/145, Loss: 0.2891
Epoch 7/10, Batch 30/145, Loss: 0.1917
Epoch 7/10, Batch 40/145, Loss: 0.3107
Epoch 7/10, Batch 50/145, Loss: 0.1297
Epoch 7/10, Batch 60/145, Loss: 0.1638
Epoch 7/10, Batch 70/145, Loss: 0.1380
Epoch 7/10, Batch 80/145, Loss: 0.3758
Epoch 7/10, Batch 90/145, Loss: 0.0910
Epoch 7/10, Batch 100/145, Loss: 0.2979
Epoch 7/10, Batch 110/145, Loss: 0.1500
Epoch 7/10, Batch 120/145, Loss: 0.1626
Epoch 7/10, Batch 130/145, Loss: 0.1222
Epoch 7/10, Batch 140/145, Loss: 0.2737
Epoch 7/10, Train Loss: 0.2153, Valid Loss: 0.2239
Model saved!
Epoch 8/10, Batch 10/145, Loss: 0.3132
Epoch 8/10, Batch 20/145, Loss: 0.2769
Epoch 8/10, Batch 30/145, Loss: 0.3360
Epoch 8/10, Batch 40/145, Loss: 0.2566
Epoch 8/10, Batch 50/145, Loss: 0.2708
Epoch 8/10, Batch 60/145, Loss: 0.2517
Epoch 8/10, Batch 70/145, Loss: 0.2063
Epoch 8/10, Batch 80/145, Loss: 0.2359
Epoch 8/10, Batch 90/145, Loss: 0.2082
Epoch 8/10, Batch 100/145, Loss: 0.1740
Epoch 8/10, Batch 110/145, Loss: 0.1570
Epoch 8/10, Batch 120/145, Loss: 0.1559
Epoch 8/10, Batch 130/145, Loss: 0.0966
Epoch 8/10, Batch 140/145, Loss: 0.1314
Epoch 8/10, Train Loss: 0.2050, Valid Loss: 0.2251
Epoch 9/10, Batch 10/145, Loss: 0.2199
Epoch 9/10, Batch 20/145, Loss: 0.1533
Epoch 9/10, Batch 30/145, Loss: 0.1164
Epoch 9/10, Batch 40/145, Loss: 0.2420
Epoch 9/10, Batch 50/145, Loss: 0.1464
Epoch 9/10, Batch 60/145, Loss: 0.1229
Epoch 9/10, Batch 70/145, Loss: 0.2039
Epoch 9/10, Batch 80/145, Loss: 0.2130
Epoch 9/10, Batch 90/145, Loss: 0.2099
Epoch 9/10, Batch 100/145, Loss: 0.1442
Epoch 9/10, Batch 110/145, Loss: 0.1318
Epoch 9/10, Batch 120/145, Loss: 0.1502
Epoch 9/10, Batch 130/145, Loss: 0.2377
Epoch 9/10, Batch 140/145, Loss: 0.1814
Epoch 9/10, Train Loss: 0.1974, Valid Loss: 0.2171
Model saved!
Epoch 10/10, Batch 10/145, Loss: 0.0377
Epoch 10/10, Batch 20/145, Loss: 0.1300
Epoch 10/10, Batch 30/145, Loss: 0.2629
Epoch 10/10, Batch 40/145, Loss: 0.0608
Epoch 10/10, Batch 50/145, Loss: 0.2514
Epoch 10/10, Batch 60/145, Loss: 0.3099
Epoch 10/10, Batch 70/145, Loss: 0.4147
Epoch 10/10, Batch 80/145, Loss: 0.1363
Epoch 10/10, Batch 90/145, Loss: 0.3931
Epoch 10/10, Batch 100/145, Loss: 0.3100
Epoch 10/10, Batch 110/145, Loss: 0.2121
Epoch 10/10, Batch 120/145, Loss: 0.2348
Epoch 10/10, Batch 130/145, Loss: 0.1399
Epoch 10/10, Batch 140/145, Loss: 0.1390
Epoch 10/10, Train Loss: 0.1963, Valid Loss: 0.2199
Accuracy: 0.9287
Precision: 0.9275
Recall: 0.9287
F1-score: 0.9280
Memory Allocated after cleanup: 17.76 MB


Mejor accuracy encontrado: 0.9287
Se han generado los boxplots y guardado los resultados correctamente.
